- DOI: https://doi.org/10.1109/access.2020.3048415
  analysis: '>'
  authors:
  - Abhinav Sharma
  - Arpit Jain
  - Prateek Gupta
  - Vinay Chowdary
  citation_count: 272
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Journals & Magazines >IEEE Access >Volume: 9 Machine
    Learning Applications for Precision Agriculture: A Comprehensive Review Publisher:
    IEEE Cite This PDF Abhinav Sharma; Arpit Jain; Prateek Gupta; Vinay Chowdary All
    Authors 288 Cites in Papers 43783 Full Text Views Open Access Comment(s) Under
    a Creative Commons License Abstract Document Sections I. Introduction II. Impact
    of Artificial Intelligence and IoT in Agriculture III. Machine Learning Algorithms
    IV. Machine Learning Applications in Precision Agriculture V. IoT Applications
    in Precision Agriculture Show Full Outline Authors Figures References Citations
    Keywords Metrics Abstract: Agriculture plays a vital role in the economic growth
    of any country. With the increase of population, frequent changes in climatic
    conditions and limited resources, it becomes a challenging task to fulfil the
    food requirement of the present population. Precision agriculture also known as
    smart farming have emerged as an innovative tool to address current challenges
    in agricultural sustainability. The mechanism that drives this cutting edge technology
    is machine learning (ML). It gives the machine ability to learn without being
    explicitly programmed. ML together with IoT (Internet of Things) enabled farm
    machinery are key components of the next agriculture revolution. In this article,
    authors present a systematic review of ML applications in the field of agriculture.
    The areas that are focused are prediction of soil parameters such as organic carbon
    and moisture content, crop yield prediction, disease and weed detection in crops
    and species detection. ML with computer vision are reviewed for the classification
    of a different set of crop images in order to monitor the crop quality and yield
    assessment. This approach can be integrated for enhanced livestock production
    by predicting fertility patterns, diagnosing eating disorders, cattle behaviour
    based on ML models using data collected by collar sensors, etc. Intelligent irrigation
    which includes drip irrigation and intelligent harvesting techniques are also
    reviewed that reduces human labour to a great extent. This article demonstrates
    how knowledge-based agriculture can improve the sustainable productivity and quality
    of the product. A graphical abstract for Machine Learning Applications for Precision
    Agriculture: A Comprehensive Review. Published in: IEEE Access ( Volume: 9) Page(s):
    4843 - 4873 Date of Publication: 31 December 2020 Electronic ISSN: 2169-3536 DOI:
    10.1109/ACCESS.2020.3048415 Publisher: IEEE CCBY - IEEE is not the copyright holder
    of this material. Please follow the instructions via https://creativecommons.org/licenses/by/4.0/
    to obtain full-text articles and stipulations in the API documentation. Nomenclature
    AbbreviationExpansion AI Artificial Intelligence ML Machine Learning DL Deep Learning
    IoT Internet of Things GPS Global Positioning System UAV Unmanned Aerial Vehicle
    ASC Agriculture Supply Chain NLP Natural Language Processing SI Swarm Intelligence
    ANN Artificial Neural Network NN Neural Network K-Nearest kNN Neighbour SVM Support
    Vector Machines RNN Recurrent Neural Network ELM Extreme Learning Machines RELM
    Regularized Extreme Learning Machine XGBoost Extreme Gradient Boosting MLP Multi-Layer
    Perceptron CNN Convolutional Neural Network PCA Principal Component Analysis RBFN
    Radial Basis Function Network RF Random Forest GBM Gradient Boosting Model SVR
    Support Vector Regression BPNN Back Propagation Neural Network LS-SVM Least square
    support vector machine GRNN Generalized Regression Neural Networks RELM Residual
    Maximum Likelihood DBN Deep Belief Network RT Regression Tree MLR Multiple Linear
    Regression LASSO Least Absolute Shrinkage and Selection Operator Regression RIDGE
    Ridge Regression SNN Shallow Neural Network GCN Graph Convolutional Network GEP
    Gene Expressions Programming RCNN Regions-CNN GA Genetic Algorithm PSO Particle
    Swarm Optimization PLSR Partial Least Square Regression ANFIS Adaptive Neuro Fuzzy
    Inference System TCN Temporal Convolution Network SCC Somatic Cell Count OPF Optimum-Path
    Forest BVDV Bovine Viral Diarrhea Virus MC Moisture Content SOC Soil Organic Carbon
    TN Total Nitrogen SOM Soil Organic Matter NDVI Normalized Difference Vegetation
    Index CEC Cation Exchange Capacity ETc Estimation of evapotranspiration SOM Soil
    Organic Matter LAI Leaf-Area Index RGB Red Green Blue DW Accumulated Dry Weight
    VRI Variable Rate Irrigation ET Evapo-Transpiration EC Electrical Conductivity
    SCM Sub-Clinical Mastitis SI Scatter Index AWM Attribute Weighting Model AUC Area
    Under the Curve R Correlation Coefficient R2 Coefficient of Determination MSPE
    Mean Squared Prediction Error MAPE Mean Absolute Percentage Error MAE Mean Absolute
    Error RMSE Root Mean Square Error RRMSE Relative Root Mean Square Error RPD Residual
    Prediction Deviation ROC Receiver Operating Characteristic RMSD Root Mean Square
    Difference NS Nash–Sutcliffe coefficient WSN Wireless Sensor Network GWO Grey
    Wolf Optimization SPI Serial Peripheral Interface I2C Inter-Integrated Circuit
    UART Universal Asynchronous Receiver Transmitter USB Universal Serial Bus BLE
    Bluetooth Low Energy SECTION I. Introduction The population of the world will
    increase to 9.1 billion approximately thirty-four percent as of today by the end
    of 2050. Food requirement will increase by 70 percent and due to rapid urbanization,
    land availability for agriculture will decrease drastically in the coming years.
    India will be the most populated country by 2050 and presently it is already lagging
    the domestic food production. The main reason for reduced food production is the
    lack of planning, unpredictable weather conditions, improper harvesting and irrigation
    techniques and livestock mismanagement. In the last few years, nature has experienced
    a drastic change in weather conditions due to global warming. The average temperature
    of the earth has been increased due to which there is uncertainty in climatic
    conditions. Frequent droughts, heavy rainfall are the biggest challenge for poor
    farmers. According to the government of India annual economic survey, adverse
    climatic conditions, reduce the farmer’s income by 20-25%. Precision agriculture
    [1], [2] is one of the solutions to ensure food security for the entire world
    [3]. Precision agriculture also abbreviated as digital agriculture is a technology-enabled
    data-driven sustainable farm management system. It is basically the adoption of
    modern information technologies, software tools, and smart embedded devices for
    decision support in agriculture [4] as shown in figure 1. Mechanized agriculture
    and the green revolution are the two key components of the first and second agriculture
    revolution. Precision farming is an important part of the third agriculture revolution
    [5]. FIGURE 1. Precision agriculture. Show All John Deere introduced this technology
    in 1990 for the sowing of seeds and spraying of fertilizers using global positioning
    system (GPS) controlled tractors. The main focus of precision farming is to reduce
    the production cost and environmental effects to increase the farm’s profitability.
    Digital technologies such as IoT [6], AI, data analytics, cloud computing, and
    block-chain technology play a key role in precision agriculture. In precision
    farming, IoT based smart sensors are deployed in the agriculture land for collecting
    data related to soil nutrients, fertilizers, and water requirements as well as
    for analysing the crop growth. Autonomous and semi-autonomous devices such as
    an unmanned aerial vehicle (UAV) [7] and robots are used for identifying weed
    and disease in the plants using computer vision techniques. Satellite images are
    also used in precision agriculture for monitoring the field and identifying the
    diseases in the plants. The data obtained from the deployed sensors [8] are processed
    and analyzed using ML algorithms to make farming practice more controlled and
    optimized. ML algorithms are also used for weather and rainfall prediction based
    on the data obtained from sensors, climatic records, and satellite images. This
    could save the lives of thousands of farmers who commit suicide because of crop
    loss due to uncertainty in weather conditions. Smart livestock management is an
    important component of precision agriculture. It helps in monitoring the health,
    welfare, productivity, and reproduction of animals throughout their life cycle.
    Sensors and cameras monitor animal’s health and computer vision techniques help
    in making intelligent decisions such as stopping the communal spread of diseases.
    Autonomous tractors and automated irrigation systems provide modern farming solutions
    to farmers. The widespread utilization of precision farming across the world is
    due to the presence of innovative machine and deep learning (DL) algorithms, high-speed
    internet access, and efficient computational devices. In [10] authors have discussed
    applications of ML for sustainable agriculture supply chain (ASC) performance.
    Authors have presented a unique ML-ASC framework that can guide researchers and
    agriculture practitioners to understand the role and importance of digital technologies
    in the agriculture industry. In [11] authors reviewed different ML applications
    in agriculture and discussed how digital technologies will benefit the agriculture
    industry. In this paper, the authors have presented a comprehensive review of
    the ML application for precision agriculture. This review article will provide
    an insight into the research community about the adoption of digital practices
    in the agriculture management system. It is anticipated that government agencies
    will frame policies to promote precision farming across the world. The main contribution
    of the article is outlined as follows: Applications of artificial intelligence
    and IoT in precision agriculture are discussed along with their practical implications.
    Foundation of ML and DL algorithms which find their application in precision agriculture
    has been discussed. Performance comparison for various ML, DL algorithms in precision
    farming has been carried out based on the state-of-art literature. Assessment
    of artificial intelligence techniques in precision agriculture is outlined along
    with its statistical and performance analysis. Comparison of performance parameters
    of sensors used in IoT applications in precision agriculture is presented. Integration
    of wireless sensor network (WSN) with IoT and artificial intelligence in precision
    agriculture is discussed. Challenges and future trends of artificial intelligence
    in precision farming are briefly outlined. Table 1 highlights the major differences
    of this review article with other articles published in this field. The paper
    is organized as follows. Section 2 presents the impact of artificial intelligence
    (AI) and IoT in the field of agriculture. Section 3 briefly elucidate ML algorithms.
    In section 4 different ML applications in precision farming are briefly reviewed.
    Section 5 presents the IoT application in precision agriculture. Section 6 evaluates
    and access the knowledge-based agriculture system. Section 7 outlines the challenges
    and limitation of AI in precision agriculture. Section 8 presents the future trends
    of AI in precision agriculture. Section 9 provides conclusive remarks to summarize
    the paper. TABLE 1 Key Differences of the Article With Published Articles SECTION
    II. Impact of Artificial Intelligence and IoT in Agriculture The term AI was first
    coined in the Dartmouth conference in the year 1956 by John McCarthy and he defined
    it as a science and engineering of making intelligent machines or more specifically
    intelligent computer programs. AI technology provides computational intelligence
    to machines so that they can learn, understand and react according to the situation.
    ML, DL, natural language processing (NLP), swarm intelligence (SI), expert systems,
    fuzzy logic, and computer vision are the subfields of AI as shown in figure 2.
    This field finds endless applications across different sectors of human life.
    Intelligent AI programs are widely explored in health-care, agriculture, finance,
    robotics, e-commerce and the automation industry. Samsung, Apple, and other electronics
    giant companies announced that they will be utilizing this technology in every
    device they will manufacture in the near future. IoT is another emerging technology
    in which smart sensors, devices are interconnected through the internet. These
    smart sensors can be utilized to gather data across different disciplines such
    as solar plants, agriculture fields, disaster-prone areas, manufacturing industry
    for efficient resource utilization. With the increase in population over the year’s
    demand for agriculture products is increasing day by day. However, with limited
    land availability for farming and reduce interest among the young generation to
    adopt farming as their profession, it has become a challenging task for the agriculture
    industry to satisfy the food requirement of millions of people. Now, the agriculture
    industry is widely adopting smart technologies like IoT and AI to efficiently
    cultivate organic products in limited land areas as well as to overcome the traditional
    challenges of farmers. FIGURE 2. Artificial intelligence techniques. Show All
    IoT based smart farming system is built for monitoring soil nutrients and soil
    moisture using sensors. ML algorithms are explored for determining the optimum
    amount of fertilizers required for soils before the sowing of crops. Drones are
    revolutionizing the agriculture industry. These drones are cameras enabled and
    are used for different applications such as field and crop monitoring, spraying
    of pesticides, and drip irrigation. The images captured by the drones over the
    entire lifecycle of crops can be examined using DL and computer vision algorithms
    for disease and weed identification. Thereafter, these drones are used for spraying
    pesticides over the weeds and infected crops. Over the years uncertainty in weather
    conditions is the main concern of farmers. Drip irrigation using drones is an
    efficient AI-empowered irrigation system which is basically trained on weather
    pattern and can effectively reduce the water problems of farmers. AI-enabled robots
    can be used for harvesting the crops at a much faster pace and in large volumes.
    Robots can reduce human labour to a large extent and can be used along with drones
    for monitoring the field. Livestock management is another major concern for farmers.
    IoT based sensors can be deployed in the field for health monitoring of cattle.
    This information can be utilized for protecting the bunch of cattle from diseased
    cattle. NLP based virtual assistant applications like chatbots can update the
    farmers with the latest advancement in technologies for agriculture. Farmers can
    finds solutions for their problems and incorporate the latest technology in their
    farming for improving their field productivity. Thus, AI and IoT are the two major
    technologies that will play a vital role in the agriculture industry. SECTION
    III. Machine Learning Algorithms ML is the subfield of computer science that gives
    computers the ability to learn without being explicitly programmed. (Arthur Samuel,
    1959) [12]. Alan Turing in the year 1950 proposed the concept of learning machines
    and wrote a research article “The Turing Test for Machine Intelligence” [13].
    He performed a test and examined the machine’s ability to demonstrate intelligent
    behaviour similar to humans. A machine or intelligent computer program learns
    and extract knowledge from the data, builds a framework for making predictions
    or intelligent decisions. Thus, the ML process is divided into three key parts,
    i.e. data input, model building, and generalization as shown in figure 3. Generalization
    is the process for predicting the output for the inputs with which the algorithm
    has not been trained before. ML algorithms are mainly used to solve complex problems
    where human expertise fails such as weather prediction, spam filtering, disease
    identification in plants, pattern recognition. FIGURE 3. A Machine learning process.
    Show All Today, due to the availability of innovative algorithms and large data
    sets through internet resources industries and research communities are widely
    using ML algorithms for solving a diverse set of problems. DL is the subfield
    of the family of ML algorithms which is trained from large sets and uses an artificial
    neural network (ANN) to make intelligent decisions. ML algorithms are categorized
    as supervised learning, unsupervised learning, and reinforcement learning as shown
    in figure 4. Supervised learning as the name suggests is learning with the supervisor
    or teacher. This set of algorithms works with labeled data-set which means corresponding
    to each input there are outputs. The algorithm builds an input-output relationship
    with this labeled data set and thereafter generalize or predicts outputs for unseen
    inputs. Supervised learning algorithms used for predicting the categorical value
    are known as classification algorithms and the algorithms that are used for predicting
    the numerical value are known as regression algorithms. Unsupervised learning
    algorithms works with unlabelled data and discovers unknown objects by grouping
    similar objects. The goal of an unsupervised learning algorithm is to extract
    hidden knowledge from the training data set thus this approach is difficult to
    implement than supervised learning algorithms. Reinforcement learning is another
    approach that learns from the environment through reward and punishment. AlphaGo,
    a chess-playing game developed by DeepMind utilized reinforcement learning for
    defeating the world’s best chess-playing computer program. FIGURE 4. Categorization
    of machine learning algorithms. Show All In this paper the performance of different
    ML algorithms are analysed and discussed in the field of agriculture. Table 2
    presents different types of supervised, unsupervised and reinforcement learning
    algorithms utilized for soil and weather prediction, disease and weed identification,
    intelligent irrigation and harvesting techniques as well as livestock management.
    TABLE 2 Machine Learning Algorithms SECTION IV. Machine Learning Applications
    in Precision Agriculture In many countries, the farmers rely on the traditional
    ways of farming which is based on the reliability of the suggestions from the
    elderly and their experience. This method leaves farmers at the mercy of random
    climatic conditions which are already getting random due to global warming and
    uneven rainfall patterns. The manual spraying method for pesticides led to improper
    usage of resources and harms the environment. AI and IoT enabled precision agriculture
    removes the randomness and assist new age farmer to optimize every step of the
    farming process. Figure 5 (a) and (b) presents a pictorial view of traditional
    agriculture and technology enabled farm management system. FIGURE 5. (a) Traditional
    agriculture cycle (b) Precision agriculture cycle. Show All Gaitán [14] provided
    a systematic study of the impact of extreme weather events, such as hail events,
    cold waves, heat waves, and their impact on agricultural practices. The author
    reported floods, droughts, frost, hail, heatwaves, and pest outbreaks are impacted
    by climatic conditions. The AI systems are applicable in each farming operation
    as depicted in figure 4 and some of them even extend beyond the conventionally
    recognized steps. In this section we will discuss the state of art techniques
    proposed/implemented by various researchers and practitioners worldwide. A. Soil
    Properties and Weather Prediction Prediction of soil properties is the first and
    the most crucial step which influences the selection of crop, land preparation,
    selection of seed, crop yield, and selection of fertilizers /manure. The soil
    properties are directly related to the geographic and climatic conditions of the
    land in use and hence is an important factor to take into consideration. The soil
    properties prediction mostly consists of predicting nutrients in the soil, soil
    surface humidity, weather conditions during the lifecycle of the crop. Human activities
    have highly affected the properties of soil and hence our ability to cultivate
    the crops [15]. In general, there are 17 essential elements as listed in table
    3 which play an important role in plant growth [16]. The growth of crops depends
    on the nutrients available in a particular soil. The soil nutrients are mostly
    monitored by electric and electromagnetic sensors [8]. Depending on the nutrients
    farmers make informed decisions as to which crop is optimal for the land. However,
    the nutrients can be added through fertilizers, manure, etc. but with an additional
    cost. Some of them may also damage the environment and have an adverse effect
    on the soil cycle. TABLE 3 Essential Plant Nutrients [2] A scientific analysis
    of soil nutrients, soil moisture, pH is important for determining the soil properties.
    Acar et al. [17] employed an extreme learning machine (ELM) based regression model
    for prediction of soil surface humidity. The author selected two terrains having
    area 4 KM2 and 16 KM2 located in Dicle university campus for experimental analysis.
    The real-time field data was extracted using polarimetric Radarsat-2 data, which
    was pre-processed using the SNAP toolbox [18] and features were added with the
    help of local measurements by separating the field into square grids. Once the
    pre-processing and feature extraction is done the data is passed to ELM based
    regression model to predict the soil surface humidity. The algorithm was tested
    with 5 different kernel functions and the prediction was validated using leave-one-out
    cross-validation technique. The experimental results confirmed the lowest root
    mean square error (RMSE) of 2.19% when using ‘sine’ kernel function. Wang et al.
    [19] deployed soft sensors based on ELM for the measurement of nutrient solution
    composition in the soilless cultivation method. The soilless cultivation method
    is an emerging planting method. It is imperative to monitor the pH value, temperature
    and concentration changes in nutrient solution composition as the performance
    of soilless cultivation is highly dependent on these parameters. The significant
    variables in a nutrient solution cannot be measured directly hence these are determined
    with the help of auxiliary variables. The authors utilized conductivity, pH value,
    flow rate, and temperature measurements for auxiliary measurements. These auxiliary
    measurements are fed to a deep belief network-based ELM which predicts the values
    of significant variables. For experimental analysis, the authors deployed the
    model to measure the concentration of SO 2− 4 , and H 2 PO − 4 in a nutrient solution.
    The authors reported an average RMSE of 1.2414 for predictions in SO 2− 4 and
    RMSE of 0.8892 for prediction of H 2 PO − 4 . Park et al. [20] utilized ML algorithms
    to predict the soil moisture using data from MODIS. The authors downscaled the
    AMSR2 soil moisture to 1KM using random forest (RF) and Cubist algorithms. An
    ensemble of these algorithms was used to obtain soil moisture data. The results
    obtained through the ML methods were compared with the statistical ordinary least
    squares technique. The ML model exhibited a R 2 (coefficient of determination)
    of 0.96 and an RMSE of 0.06, whereas a R 2 of 0.47 and a RMSE of 0.16 was associated
    with the statistical ordinary least squares. Reda et al. [21] explored ML algorithms
    to estimate soil organic carbon (SOC) and total nitrogen (TN) in soil samples
    collected from four agricultural lands of Moroccan. Data set of near-infrared
    spectroscopy is utilized in comparison to traditional chemical methods as this
    technique reduces the computation time and resource utilization. The ensemble
    learning modeling algorithm presents the best performance among other regression
    models and back-propagation neural networks (BPNN) algorithm. The proposed algorithm
    presents R 2 of 0.96, RMSE of 1.92, performance to deviation (RPD) of 4.87 for
    SOC and R 2 of 0.94 and RMSE of 0.57, RPD of 4.91 for TN prediction. Morellos
    et al. [22] also utilized visible and infrared spectroscopy to determine TN, SOC,
    and moisture content (MC) in the arable field in Premslin Germany. Spectroscopy
    dataset is used for building the predictive ML model for estimating all three
    soil properties. Least square support vector machine (LS-SVM) and cubist ML algorithms
    outperform principal component regression and partial least square regression
    multivariate methods in terms of RMSE and residual prediction deviation (RPD).
    LS-SVM best predict SOC and MC with RMSE of 0.062 and 0.457, RPD of 2.24, and
    2.20. Cubist best predicts for TN with RMSE of 0.071 and RPD of 1.96. Andrade
    et al. [23] build ordinary least square regression, RF, cubist regression, XGboost
    prediction model for determining soil properties from portable X-ray fluorescence
    (pXRF) spectrometry dataset in Brazilian coastal plains. Three soil properties
    total nitrogen, soil organic matter (SOM), cation exchange capacity (CEC) were
    analyzed using RF, ordinary least squares regression (OLS), cubist regression
    (CR), XGBoost (XGB). RF algorithm gives the best performance with R 2 of 0.50
    for TN, R 2  0.75 for CEC and 0.56 for SOM. Deiss et al. [24] estimated the soil
    properties (clay, sand, pH, SOC) in northern Tanzania and USA Midwest from the
    spectroscopy dataset using ML algorithms. THE tuned SVM model outperforms the
    partial least square (PLS) regression model in terms of predicting all the soil
    parameters. Mahmoudzadeh et al. [25] explored the ML algorithm to predict SOC
    in the Kurdistan province of Iran. The simulation results suggest that RF accurately
    predicts SOC with R 2 of 0.60 and RMSE of 0.35% in comparison to SVM, kNN, Cubist,
    and Extreme Gradient Boosting (XGBoost) ML algorithm. The study also suggests
    that air temperature, annual rainfall, valley depth, texture of terrain surface
    are some of the important factors that influence SOC spread over the Kurdistan
    region. Veres et al. [26] explored DL architecture such as CNN for predicting
    the soil properties from the infra-red spectroscopy dataset. Benke et al. [27]
    predict soil electrical conductivity (EC) and SOC in different regional locations
    of Victoria, Australia using pedotransfer function (PTF) based on ML algorithm.
    PTF basically converts soil measurement into soil properties and provides inputs
    for ML simulation algorithms. In the proposed approach PTF use Generalised Linear
    Mixed Effects Model (GLMM) model and Residual Maximum Likelihood (REML) to predict‘
    the soil properties. Traditional approaches to soil properties and crop yield
    prediction require time-consuming field surveys and the deployment of expensive
    sensors. Khanal et al. [28] proposed an alternative approach in which the dataset
    for the prediction of soil properties and crop yield is generated using remotely
    sensed aerial images of agricultural land. Five soil properties, viz. pH value,
    magnesium (Mg), potassium (K), SOM, CEC, and crop yield were predicted using RF,
    SVM, Cubist, NN, Gradient Boosting Model (GBM) ML algorithms. NN presents the
    highest prediction accuracy for SOM having R 2 of 0.64, RMSE of 0.44 and CEC having
    R 2 of 0.67, RMSE of 2.35; SVM best predicts K having R 2 of 0.21, RMSE of 0.49
    and Mg having R 2 of 0.22, RMSE of 4.57; and GBM best predicts pH having R 2 of
    0.15, RMSE of 0.62. RF outperforms other algorithms in terms of crop yield prediction
    and presents higher accuracy having R 2 of 0.53 and RMSE of 0.97. Labrador et
    al. [29] estimate calcium and Mg content in soil using generalized regression
    NN and genetic algorithm (GA). The digital elevation model and satellite images
    were used as input to the prediction model for estimating the soil properties.
    Chlingaryan et al. [30] discussed different ML approaches used in precision agriculture
    for accurate crop yield prediction and soil nitrogen estimation over the last
    fifteen years. Ju-Young et al. [31] investigated a seasonal climatic forecasting
    model using regularized ELM to predict day-wise mean air temperature at field
    level for a period of 90 days. The authors selected data from Korea Metrological
    Administration using the Met GloSea5GC2 model [32]. The authors fed 240 days of
    forecast data and hindcast data from the ensemble based model to the RELM algorithm.
    The algorithm performance was evaluated by measuring: RMSE, mean absolute error
    (MAE) the model prediction vs the actual values. The authors achieved an RMSE
    in the range of 1.02 to 3.35 which outperformed the meteorological data which
    has an RMSE range of 1.61 to 3.37. Soil moisture content is an important parameter
    to acknowledge in the agriculture industry as it addresses precise irrigation
    scheduling. Stamenkovic et al. [33] build a support vector regression (SVR) prediction
    model to predict soil moisture content from remotely sensed hyperspectral images.
    Song et al. [34] proposed a macroscopic cellular automata (MCA) model and combined
    its deep belief network (DBN) to predict soil moisture content over a cornfield
    in northwest china. The simulation results of DBN-MCA outperforms the multi-layer
    perceptron (MLP)-MCA in terms of RMSE. Acheing [35] explored the SVR model (i.e.
    RBF), ANN, DNN for simulating soil water retention curve (SWRC) curve of loamy
    sand. Dataset of loamy sand subjected to wetting and drying condition is collected
    using a reflectometer and tensiometer. RBF based SVR model best predicts SWRC
    under both wet and dry conditions. Feng et al. [36] estimate soil temperature
    at various soil depths of Loess Plateau of China. Four different ML algorithms
    ELM, generalized regression neural networks (GRNN), backpropagation neural networks
    (BPNN), and RF were investigated for predicting the soil temperature. ML algorithms
    were trained with air temperature, wind speed, relative humidity, and vapour pressure
    and solar radiation as input parameters and the simulations show that ELM outperforms
    other ML algorithms in terms of RMSE, MAE, Nash–Sutcliffe coefficient (NS) and
    concordance correlation coefficient. Mohammadi et al. [37] explored ELM for predicting
    daily dew point temperature in different parts of Iran. This part of the world
    experience different climatic conditions throughout the year. The proposed model
    accurately predicts dew point temperature than SVM and ANN algorithms. Zhu et
    al. [38] accurately predict daily evapotranspiration in Northwest China using
    hybrid particle swarm optimization (PSO)-ELM model to optimize crop water requirement
    in agriculture. Alizamir et al. [39] accurately predicts soil temperature at different
    depths of 5, 10, 50 and 100 cm using ELM, ANN, classification and regression trees,
    group method of data handling using dataset obtained from Mersin station operated
    by Turkish Meteorological Service. The simulation results suggest that soil temperature
    can be estimated easily using air temperature upto depth of 50 cm while for depth
    of 100 cm additional information of solar radiation and wind speed is required.
    Rainfall prediction plays a critical role in the water resource management system,
    flood risk assessment, and the agriculture industry. Acknowledging the chaotic
    nature of rainfall, it is very difficult for statistical approaches to accurately
    predict the rainfall. Cramer et al. [40] evaluated the performance of seven ML
    algorithms for rainfall prediction. The statistical results show that the radial-basis
    function neural network (RBFNN) shows the best performance among other state of
    the art algorithms. Sierra and Jesus [41] predicted the rainfall in Tenerife,
    an island in Spain based on atmospheric synoptic patterns using different ML algorithms
    and found NN gave the best performance among other ML algorithms. Kamatchi and
    Parvathi [42] employed NN for weather prediction and proposed a hybrid recommender
    system for enhancing the success ratio of the system. Lazri et al. [43] build
    a multi-classifier model for estimating precipitation using MSG images (Meteosat
    second generation) and dataset obtained using radar. The proposed approach shows
    that the proposed multi-classifier improves the standard of classification. Shardoor
    and Rao [44] surveyed three different approaches i.e. ML techniques, data mining
    techniques, and satellite forecasting techniques for rainfall prediction. Table
    4 presents a comparative study of different ML algorithms for prediction of soil
    properties and weather prediction. TABLE 4 Different ML Algorithms for Prediction
    of Soil Properties and Weather Conditions B. Crop Yield Prediction A significant
    piece of information for any farmer is the prediction of crop yield and how the
    yield can be increased. pH value, soil type, and quality, weather pattern: temperature,
    rainfall, humidity, sunshine hours, fertilizers, and harvesting schedules are
    some of the parameters which play an important role in predicting the crop yield
    [45]. Scientifically manual farming can be considered as a feedback control system
    in which the corrective action is taken once a setback in a crop is observed.
    The crop yield will highly depend on the efficiency of the optimal utilization
    of the above-mentioned resources. If some kind of anomaly goes undetected in the
    initial stage may harm the crop yield in an unprecedented way. Singh et al. [46]
    assessed hailstorms on India’s wheat production and observes that in February
    and March 2015 alone the hailstorm events caused a decline of 8.4% in national
    wheat production. For financially weak farmers in a country such as India, where
    intermittent storage of harvested crops is a rare resource, accurate weather predictions
    may turn to be miraculous for farmers. ML models when systematically applied to
    a system act as feedforward control. With the help of accurate ML models, we can
    anticipate the factors which are going to affect the crop yield. Hence the corrective
    action can be taken before even an anomaly hits the crop production. Kamir et
    al. [47] used ML models to identify the yield gap hotspots in wheat production.
    Authors generated very high-resolution yield maps using data from various sources
    between 2009 and 2015. The data was collected from various sources:(a) NDVI time-series
    data across Australia using the MOD13Q1 data set [48], (b) rainfall and temperature
    data were collected from historic climate data at Australia bureau of metrology,
    (c) maps for observed grain yield were collected at source using intelligent harvesting
    machines. The dataset generated were tested with 9 ML algorithms: RF, XGBoost,
    Cubist, MLP, SVR, Gaussian Process, k-NN, and Multivariate Adaptive Regression
    Splines. The authors combined predictions from each of the algorithms into ensembles
    for prediction optimization [49]. Out of these algorithms, SVR with RBFNN outperformed
    other algorithms and investigators were able to achieve the yield estimate with
    an R 2  of 0.77 and an RMSE value of 0.55t ha −1 . The results were validated
    using 10-fold cross-validation techniques applied to the full data set. Aghighi
    et al. [50] used various advanced regression algorithms to predict the yield of
    silage maize crops. The authors selected maize fields located at Moghan Agro-Industrial
    and Animal Husbandry Company (MAIAHC), which is about 28,000 hectares’ area and
    located in Iran. The crop yield dataset was collected for around 40 silage maize
    fields were collected for a period from 2013-2015. In addition to it, the historic
    crop yield data the authors also gathered time-series NDVI data from Landsat 8
    OLI satellite. The data was fed to advanced regression algorithms: (a) Gaussian
    Process Regression, (b) SVR, (c) Boosted Regression tree (d) RF Regression models
    and the prediction form each of the regression models were compared and evaluated.
    Authors found out the boosted regression tree reported best evaluation parameters
    with an average R-value of higher than 0.87, and RMSE in a range of 8.5 to 11.10,
    with a mean value of 9.5 during the period 2013-14. Kuwata and Shibasaki [51]
    employed DL models to estimate the crop yield. Authors deployed SVR for predicting
    the yield of corn in Illinois. For input following dataset was employed by the
    authors: (a) 5 year moving average of corn crop yield, (b) The enhanced vegetation
    index is obtained using the MOD09A1 dataset MODIS satellite, and (c) Historic
    climatic data. The dataset was fed to support the vector regression model and
    the authors reported an RMSE of 8.204 and a correlation coefficient of 0.644 for
    the model. For result, validation authors conducted 10-fold cross-validation on
    the full data set. Kulkarni et al. [52] utilized DL models to predict rice crop
    yield. The authors utilized soil properties and nutrients measurements recorded
    over 31 years and historic rainfall data. The input data was fed to recurrent
    neural network models for crop yield prediction. For effective prediction the
    authors explored different activation functions viz. sigmoid, reLu, and linear
    in the neural network. Chu and Yu [53] builds an end to end summer and winter
    rice prediction model in 81 counties in the Guangxi Zhuang Autonomous Region,
    China. The proposed BBI model works in three stages, in the first stage the original
    area data and time series metrological data is pre-processed and its output works
    as input for the second stage where BPNN and RNN (recurrent neural network) learns
    deep spatial and temporal features from the input data. In the third stage, BPNN
    learns the relationship between deep features and rice yield to predict the summer
    and winter rice yields. The performance of the model is evaluated in terms of
    error and rate of convergence, the model presents lowest error values with MAE
    and RMSE of 0.0044 and 0.0057 for summer rice prediction and 0.0074 and 0.0192
    for winter rice prediction while the algorithm converges within 100 iterations.
    Feng et al. [54] proposed a hybrid approach for wheat yield prediction in new-south
    Wales in southeastern Australia. Multiple growth specific indicators, viz. agricultural
    production system simulators (APSIM), NDVI, and SPEI (Standardized Precipitation
    and Evapotranspiration Index) are used before the prediction of wheat yield using
    regression models (multiple linear regression (MLR) and RF). APSIM+ RF hybrid
    model presents the best performance among other predictors in terms of prediction
    accuracy. Cai et al. [55] integrated two data sources, i.e. climate data and satellite
    data over fourteen years to predict the wheat yield in Australia using ML algorithms
    (SVM, RF, and NN). Simulation results show that climate data provides distinctive
    information in comparison to satellite data for yield prediction with R 2 of around
    0.75. Planting the crops on accurate date plays an important role in improving
    productivity and reducing financial loss. Gumuscu et al. [56] explored three supervised
    ML algorithms; kNN, SVM, and decision trees for predicting planting dates; early,
    normal, and late for wheat crops in Turkey. The authors utilized climate data
    of the last 300 days to train ML algorithms and explored GA for feature selection.
    kNN classification ML algorithm shows robust performance and best predicts the
    planting dates of wheat crops. Several African, American, and Asian countries
    are the major producer of coffee in the world. Nevavuori et al. [57] explored
    a deep learning approach, i.e. CNN for wheat and barley yield prediction in the
    agriculture field of Pori, Finland. NDVI and RGB dataset obtained from cameras
    installed in UAV is used to train the six-layer CNN. RGB dataset best predicts
    the crop yield in CNN with MAE of 484.3 kgha−1 and mean absolute percentage error
    (MAPE) of 8.8%. Koirala et al. [58] reviewed deep learning approaches for fruit
    detection and yield estimation. CNN in the context of computer vision is widely
    used for feature extraction from images that provide useful insight to object
    detection and yield estimation. Kouadio, et al. [59] predicted the Robusta coffee
    yield using ML techniques from soil fertility dataset of Vietnam. ELM model outperforms
    multiple linear regression and RF algorithm with RMSE of 496.35 kg ha−1 and MAE
    of 326.40 kg ha−1. Gamboa et al. [60] predict the cocoa yield in Santander, Columbia
    using a generalized linear model (GLM) and SVM. In recent decades researchers
    have explored statistical and probabilistic models for crop yield prediction.
    Gyamerah et al. [61] proposed a novel robust probabilistic forecasting model based
    on quantile random forest and Epanechnikov kernel function (QRF-E) for crop yield
    prediction in Ghana. The proposed approach didn’t only predict discrete yield
    values but completely showcase probability descriptions for prediction interval
    for the two crops groundnut and millet. The simulation result shows the superior
    performance of the proposed algorithm in terms of prediction intervals coverage
    probability and prediction interval normalized average width under uncertain weather
    conditions. Peng et al. [62] explored remote sensed satellite-based Solar-Induced
    Chlorophyll Fluorescence (SIF) dataset for training ML algorithms to predict maize
    and soybean yield in the mid-west region of the United States. Simulation results
    show that non-linear algorithms such as SVM, ANN, RF best predict the crop yield
    in comparison to least absolute shrinkage and selection operator regression (LASSO)
    and ridge regression (RIDGE) algorithm. Khaki and Wang [63] predicted the hybrid
    maize yield with a dataset of 2,267 locations of the United States and Canada
    between the years 2008 to 2016 using deep neural networks (DNN). Genotype, weather,
    and soil properties were the three components used to train DNN. The proposed
    model accurately predicts the maize yield with RMSE of 12% of the average yield
    for predicted weather dataset and 11% of the average yield for perfect weather
    dataset and outperforms LASSO, shallow neural network (SNN) and regression tree
    (RT). Simulation results show that environmental factors have a large impact on
    the prediction accuracy of crop yield. In most areas of Africa, agriculture field
    data is scarcely available thus remotely sensed dataset is widely used for monitoring
    the field. Leroux et al. [64] explored the ML algorithm for predicting the maize
    yield in Burkina Faso with a remotely sensed dataset. A process-based crop model
    SARRO which is basically designed to simulate attainable agricultural yields under
    tropical conditions is used in this study. RF outperforms MLR in maize yield prediction
    with R 2 of 0.59 at the end of the season and 0.49 before two months of harvest.
    Li et al. [65] build a statistical model for predicting the rain-fed crop yield
    using climate, satellite, and country-specific datasets in the mid-west region
    of the USA. Maimaitijiang et al. [66] explored the potential of UAV with DNN for
    soybean yield prediction from the fields of Columbia, Missouri, USA. Multi-modal
    information such as canopy spectral, structural, and thermal features extracted
    from images obtained from the sensors installed on UAV is used as the input dataset
    for training DNN. The simulation result shows that DNN accurately predict the
    crop yield and outperforms partial least square regression (PLSR), RF, SVR algorithms
    with R 2 of 0.720 and RMSE of 15.9%. Zhang et al. [67] explored ANN for prediction
    of annual crop planting utilizing a historical cropland data layer (CDL) dataset
    of corn-belt of mid-west, USA. Kocian et al. [68] utilized both approaches to
    predict crop growth in greenhouses. IoT smart sensors are installed in the greenhouses
    to monitor different environmental parameters, soil properties and plant growth
    parameters such as leaf area index (LAI), accumulated dry weight (DW) and evapo-transpiration
    (ET). These parameters are in real-time send to the cloud through IoT devices
    and permit the implementation of an agriculture decision-support system. The probabilistic
    Bayesian network is explored in the proposed system to predict crop development
    parameters. Shahinfar and Kahn [69] explored ML algorithms for early prediction
    of adult wool growth in Merino sheep of Australia. Model Tree algorithms best
    predict the wool growth in comparison with NN with a correlation coefficient of
    0.93, 0.90, 0.94, 0.81 and 0.59, MAE of 0.48 kg, 0.41 kg, 0.92 μm , 6.91mm and
    6.82 N/ktex, for predicting Greasy Fleece Weight, adult Clean Fleece Weight, adult
    Fibre Diameter and adult Staple Length. Table 5 presents a comparative study of
    different ML algorithms for crop yield prediction. TABLE 5 Different ML Algorithms
    for Crop Yield Prediction C. Disease and Weed Detection Disease fungi, microorganisms,
    and bacteria take their energy from the plants they live on, which in turn affects
    the crop yield. If not detected at the right time may account for a huge economic
    loss to farmers. A lot of financial burden goes to a farmer in the form of pesticides,
    to get rid of diseases and restore the functioning of crops. Excessive use of
    pesticides also leads to environmental damage and the effects of the water and
    soil cycle of the agricultural land. Using an optimally designed AI system during
    crop growth period not only reduces the risk of crop disease and minimizes the
    economic impact, but it also results in minimizing the adverse impact of unsystematic
    farming on the environment. Sambasivan and Opiyo [70] used a CNN based DL model
    to detect disease in cassava crops for imbalanced datasets. The authors took a
    database of 10,000 labeled images that were pre-processed to improve the image
    contrast using contrast limited adaptive histogram equalization algorithm. The
    model evaluation was done using the performance metrics: confusion matrix, accuracy
    measure, precision measure, sensitivity, and F1 score. The authors reported a
    best-case accuracy of 99.30% and the lowest accuracy was reported as 76.9%. Ramcharan
    et al. [71] used DL algorithms to detect diseases in cassava crops. Authors deployed
    deep CNN to identify three different diseases and two types of pests from a set
    of 11,670 images dataset. Author’s utilized GoogLeNet algorithm based Inception
    v3 in Tensor Flow. The authors achieved efficiency in a range of 80% to 93.0%,
    and the validation of the results was done with the help of the confusion matrix.
    Mohanty et al. [72] employed DL methods to detect crop disease from the image
    dataset of plant leaves. The authors used a public database consisting of smartphone
    generated 54,306 images of diseased and healthy plants leaves. These images were
    resized to 256×256 pixels and were assigned 38 different class labels of crop-disease
    pair, and transformed into 3 datasets color, grayscale and segmented. The dataset
    was then fed to two of the most common deep CNNs: AlexNet [73] and GoogLeNet [74].
    The authors achieved an accuracy of 99.34% for GoogLeNet, and an accuracy of 85.53%
    for AlexNet network. The results were validated using F1 score, authors achieved
    a mean F1 score of 0.9886 for GoogLeNet, and a mean F1 score of 0.9848 for AlexNet.
    Amara et al. [75] used LeNet based CNN architecture for disease detection in banana
    leaves. Authors utilized data from open source local and digital libraries which
    were pre-processed and resized to 60×60 pixels, and the model was implemented
    for RGB as well as grayscale images. Hughes and Salathe [76] utilized this developed
    model for the identification of diseases in the images dataset. The authors achieved
    the best F1 score of 0.9971 for detection in RGB images and a score of 0.976 for
    grayscale images. Ferreira et al. [77] deployed CNN for the identification of
    weeds in soybean crops. The image dataset for soy plantation located at São José
    farm, Campo Grande Brazil was acquired using phantom DJI3 drone. The images are
    segmented using the SLIC algorithm into square grids. For training, the segmented
    images were manually annotated to their class. The segmented images dataset was
    fed to AlexNet (a convolution neural network) for classification. The performance
    of the AlexNet was compared with SVM, AdaBoost, and RF. To evaluate the performance
    of the AlexNet the model was fed with a balanced dataset and the authors reported
    an overall accuracy of above 90% and 96.3% images were correctly classified. Waheed
    et al. [78] proposed a cost-effective optimized dense CNN (DenseNet) for disease
    detection in corn leaves with an accuracy of 98.0%. Simulation results show that
    the proposed model outperforms other CNN models such as EfficientNet, VGG19Net,
    NASNet, and XceptionNet in terms of fewer parameters, accuracy, computation complexity,
    and computation time. Pereira et al. [79] proposed an expert system for identifying
    three species of aquatic weeds from aquatic weed leaves dataset based on their
    shape and supervised pattern recognition techniques. The author explored five
    shape descriptors with different shape-based skills viz. Beam Angle Statistics
    (BAS), Fourier Descriptors (FD), Moment Invariants (MI), Multi-scale Fractal dimension
    (MS), and Tensor Scale Descriptor (TSD) along with five ML algorithms viz. Optimum-Path
    Forest (OPF), SVM, Naive Bayes, ANN, MLP. Simulation results show that OPF using
    the BAS-100 descriptor presents the best results with a recognition rate of 96.41%
    in comparison to other approaches. Jiang et al. [80] proposed a semi-supervised
    CNN feature-based Graph Convolutional Network (GCN) for identifying weeds utilizing
    6000 images of corn, lettuce, radish, and mixed weed dataset. The proposed approach
    works in two parts, i.e. in the first part CNN model is used for feature extraction
    thereafter in the second part GCN graph is explored utilizing CNN feature dataset
    for extracting feature of an unlabelled dataset using labelled dataset. The proposed
    approach shows the best results in comparison with AlexNet, VGG16, and ResNet-101
    approaches with recognition accuracies of 97.80%, 99.37%, 98.93%, and 96.51% on
    four different weed datasets. Oppenheim and Shani [81] explored CNN for identifying
    four different types of diseases in potatoes. The simulation result shows that
    the model trained on 90% of the images and tested on 10% of images give the best
    results with 96% accuracy. Sugar beet contributes around 30% of world sugar production.
    Leaf spot diseases in sugar beet can create a loss of around 10 % to 50 % of yearly
    sugar yield. Rumpf et al. [82] proposed SVM with a radial basis function as a
    kernel based model for early detection and classification of three diseases Cercospora,
    leaf spot, leaf rust, and powdery mildew in sugar beet leaves. Diseased and non-diseased
    leaves were classified with an accuracy of 97% and three diseases were identified
    with accuracy higher than 86%. Ozguven and Adem [83] proposed updated faster R-CNN
    for leaf spot disease identification and classification in sugar beet. Leaf spot
    disease initially generates as small circular spots and later spread over the
    entire leaf surface. The proposed R-CNN architecture changes its parameters according
    to the images and the disease infected regions, which improves the overall classification
    rate to 95.48%. Bah et al. [84] explored CNN for weed detection in images obtained
    using UAV from bean and spinach fields. The proposed model first identifies the
    crop rows and then identifies the inter-crop row weeds which are used as a training
    dataset for CNN for crop and weed identification and classification. Kerkech et
    al. [85] identified the vine diseases from visible and infrared UAV images obtained
    in the Center Val de Loire region in France. A CNN model is trained with this
    dataset of images to classify each pixel according to different instances, namely,
    shadow, ground, healthy, and symptom. The model identifies with an accuracy of
    92% at grapevine-level and 87% at leaf level. Oslen et al. [86] explored robust
    deep learning models Inception-v3 and ResNet-50 for weed species identification
    and classification from a dataset of images collected in Australian rangeland.
    Simulation results show that the average classification performance of both the
    models is 95.1% and 95.7%. These results found fruitful for automatic real-time
    robotic weed control in the agricultural field. Sudars et al. [87] establish an
    experimental set up with RGB digital cameras in Latvia to collect images of the
    field having 6 food crops and 8 weed species grown in normal field conditions
    and controlled environment. This dataset can be utilized by deep learning algorithms
    for weed identification and classification. Sethy et al. [88] identified the rice
    leaf disease based on a hybrid CNN and SVM. In this model, CNN is explored for
    deep feature extraction from 5932 diseased rice leaf images and this data is used
    as input for SVM classifier. The resnet50 with SVM classification model best classify
    with respect to other models with F1 score of 0.9838. Garcia et al. [89] proposed
    an ML and DL learning hybrid approach for weed and crop identification in the
    agriculture fields of Greece. Image dataset of two crops tomato and cotton and
    two weeds black nightshade and velvetleaf was generated for training and testing
    of the model. Initially CNN (Xception, Inception-Resnet, Vignette’s, Mobilenet,
    and Densenet)) is used for feature extraction and this feature set is later used
    to train ML classifier (SVM, XGBoost and Logistic Regression) for classification.
    The simulation result shows that Densenet and Support Vector Machine outperforms
    other approaches with F1 score of 99.29%. Shah and Jain [90] identified the disease
    in cotton leaf through ANN with some image pre-processing techniques. Yu et al.
    [91] explored deep learning algorithms with a dataset of images for identifying
    dandelion, ground ivy, and spotted spurge in perennial ryegrass. Parraga-Alava
    et al. [92] generated a robusta coffee leaf image dataset (RoCoLe) for disease
    identification using ML algorithms. Glezakos et al. [93] proposed an innovative
    method to identify two viruses Tobacco Rattle Virus (TRV) and the Cucumber Green
    Mottle Mosaic Virus (CGMMV) in plants. In the proposed research Bio-Electric Recognition
    Assay (BERA) technique is utilized to obtain time-series information of the two
    viruses by measuring the waves through biosensors for 331s. This time-series data
    is preprocessed using GA to eliminate noise and for dimensionality reduction of
    a large dataset. Thereafter this meta-data is used to train MLP neural network
    classifier. The proposed model is tested against other ML classifiers via cross-validation.
    Ramesh and Vydeki [94] explored optimized deep NN with the Jaya algorithm for
    the identification of paddy leaf diseases. A dataset of rice plant leaves was
    taken from the agricultural field to identify and classify normal, bacterial blight,
    brown spot, sheath rot, and blast diseases. Simulation results show that the proposed
    model accurately classifies the diseased and normal images with an accuracy of
    98.9%, 95.78%, 92%, 94%, and 90.57% for blast affected, bacterial blight, sheath
    rot, brown spot, and normal rice leaf images. Chechlin’ ski et al. [95] explored
    CNN for weed identification in four plant species at different growth level and
    under varying light conditions. CNN architecture combines U-Net, MobileNets, DenseNet,
    and ResNet models for classification of weeds in crops. In [96]–[99] author has
    reviewed machine and deep learning techniques for weed, pests and disease identification,
    and classification in crops at different growth stages. Table 6 presents a comparative
    study of different ML algorithms for disease and weed identification. TABLE 6
    Different ML Algorithms for Disease and Weed Identification D. Drip Irrigation
    In the modern era, irrigation for crops has been improvised using the concept
    of drip irrigation [100], where the system consists of thin plastic tubes placed
    in or above the soil along the vertical rows of the plants for nurturing the water
    supply to the crops. Employing the proper operational management of drip irrigation,
    minimizes the utilization of water supply for crop production, and provides a
    better yield of crops. Socio-economic and environmental demands have widely appreciated
    in use of drip irrigation on farmlands for agriculture, especially for the high
    cost valued crops i.e., vegetables and fruits. Furthermore, drip irrigation is
    based on the low-pressure watering system in comparison to sprinkler systems;
    this makes the system more efficient in terms of energy consumption [101]. Various
    advantages have been observed using drip irrigation in agriculture over other
    irrigation systems which include sub-irrigation systems or sprinkler irrigation
    systems. These advantages are entitled to minimal usage of water supply, usage
    of soluble fertilizers through a drip irrigation system, automated system, minimization
    of soil erosion, uninterrupted activities, minimized weed problems, facilitation
    of double-cropping. Precision irrigation is another innovative approach in intelligent
    farming where it uses the water intelligently that further helps the farmers to
    achieve better yield in crops with minimal water usage. It can also be featured
    as providing the right amount of water, at the right time and the right place
    in the field. It focuses its implementation based on variable rate irrigation
    (VRI) methods employing drips or sprinklers. [102]–[104]. Advancements in the
    field of on-farm sensor technologies, weather forecasting, IoT based sensor detection
    system of vegetation and precision-based smart irrigation produces a huge size
    of data that ultimately benefits the farmers in optimizing the usage of water
    resources, improve the yield of crops and maximizes the profit of farmers [105].
    ML and DL and reinforcement learning are employed on the historical data and it
    provides various opportunities for real-time prediction and decision making purposes
    for smart irrigation which are solely based on the data collected by the sensors
    and IoT enabled systems [106]–[109]. Roberts et al. [110] have discussed that
    a sensor-based control system might create some bottleneck in terms of reducing
    the reliability of decision support tools on process-based crop models, which
    further may require costly calibration and affect in generating an uncertain representation
    of soil-plant-atmosphere processes. Further, ML techniques have been employed
    extremely well for protection analysis of hydrological processes i.e., soil moisture
    and groundwater levels [111], [112]. Li et al. [113] utilized ANN for estimating
    nitrate distribution in different types of soils under a drip irrigation system.
    Kavianand et al. [114] proposed a fully automated drip irrigation system based
    on the ARM9 processor along with different kinds of sensors equipped for monitoring
    the PH content and nitrogen content of the soil and controlling the irrigation
    of the field. Emmanuel et al. [115] establishes an experimental set-up in a greenhouse
    in Malaysia to monitor the growth of mustard leaf vegetable plants through IoT
    devices and alongside developed a data-driven model of drip irrigation system.
    Soil moisture, irrigation volume, evapotranspiration were measured through sensors
    and were given to the Raspberry Pi 3 controller for storing it in the cloud. This
    data was utilized by different predictive models ARX, BJ, and state-space models
    to predict soil moisture content for an optimized drip irrigation system. ARX
    model outperforms other predictive models in terms of MSE and response time. Seyedzadeh
    et al. [116] explored ML algorithms to optimize the uniform emitter discharge
    rate of drip irrigation system under varying pressure and temperature conditions.
    In this model operating pressure, water temperature, discharge coefficient, pressure
    exponent, and nominal discharge were taken as input parameters while ration of
    emitter discharge to nominal discharge is taken as output temperature. Authors
    explored four different ML algorithms for optimizing emitter discharge rate and
    simulation results show that LS-SVM presents best results with the least error
    of mean absolute error. Peng et al. [117] utilize soil moisture, soil electrical
    conductivity, air temperature, and light intensity parameters to build an optimized
    irrigation prediction model using backpropagation NN in China. The proposed prediction
    model presents good results with MSE of 0.00857724. The authors also identified
    an optimized layout and network arrangement for pipe in a drip irrigation system
    using computational fluid dynamics (CFD) software. The simulation results present
    that the H-shaped network layout is more suitable for field crop irrigation than
    the comb-shaped and fish bone-shaped layout. Drip irrigation system gives the
    best performance when the wetting front dimension, i.e. diameter, depth, and upward
    movement are optimized. Shiri et al. [118] explored soft-computing approaches
    viz., gene expressions programming (GEP), and RF techniques in modeling wetting
    front dimensions over different soil types for surface and sub-surface irrigation
    system. Proposed model, best predicts ETc with an improved correlation coefficient
    and decreases MSE and MAE. Elnesr and Alazba [119] explored ANN for predicting
    the wetting front dimensions from the dataset of a well-tested HYDRUS 2D/3D model.
    The simulation results show that the proposed model has a good correlation of
    0.93-0.99. Chang et al. [120] developed a smart irrigation model based on ML with
    the LoRa P2P network to learn the irrigation experiences from the expert farmers
    working on greenhouse organic crops. Singh et al. [121] have discussed an ML and
    IoT based model for soil moisture prediction during irrigation. Torres-Sanchez
    et al. [122] proposed a decision support system for irrigation management of citric
    crops in southeast Spain. In the proposed model smart sensors are deployed in
    the field to monitor water supplied previous week, weather data, soil water status,
    and based on this data three regression models SVM, RF, and Linear regression
    was trained to build the irrigation decision support system. RF best predicts
    with comparatively less prediction error. Hellín et al. [123] explored the Partial
    Least Square Regression (PLSR) and Adaptive Neuro-Fuzzy Inference System (ANFIS)
    model for building a smart irrigation decision support system crops in southeast
    Spain. Goumopoulos et al. [124] proposed a real-time adaptable intelligent and
    autonomous closed-loop irrigation management system. The authors built an experimental
    set-up in a greenhouse and deployed wireless sensors for monitoring the plant
    growth and environmental conditions along with plant growth control actuators.
    Estimation of evapotranspiration (ETc) plays a vital role in water resource management
    system. Chen et al. [125] estimate crop actual ETc from temporal convolution network
    (TCN) from the dataset of lysimeters for maize under drip irrigation with film
    mulch. Simulation results show that the proposed model best predicts ETc with
    an improved correlation coefficient and decreases MSE and MAE. Table 7 presents
    a comparative study of different ML algorithms for drip irrigation. TABLE 7 Different
    ML Algorithms for Drip Irrigation E. Livestock Production and Management Livestock
    production is basically related to the production and management of cattle i.e.,
    sheep, pigs, etc. for human consumption in terms of meat. Livestock production
    and their management are based on the farming parameters of these cattle i.e.,
    health, food, nutrition, and behaviour to optimize their production in such a
    way that the economic efficiency of this livestock can be maximized. In the present
    scenario, Artificial intelligence, IoT and Blockchain technologies [126] are widely
    explored to improves livestock sustainability and for analysis of their chewing
    habits, eating patterns, their movement patterns i.e., standing, moving, drinking
    and feeding habits, indicate the amount of stress the animal is going through
    which in turn helps in predicting the vulnerability to disease, weight gain, and
    production of the livestock. Furthermore, an ML-based weight predicting system
    can help in the estimation of their body weight 90–180 days before the slaughtering
    day. According to these analyses and estimations, farmers can change their diet
    plans and living conditions for their better growth in terms of health, behaviour,
    and weight gain which in turn will improve the economic efficiency of these livestock
    [127], [128]. Villeneuve et al. [129] build a decision support system that encounters
    not only real-time data but also expert knowledge for precision sheep farming.
    Livestock production and management can be further classified into two sub-categories,
    i.e., animal welfare and livestock production. Animal welfare generally deals
    with the animal’s health and their well-being; for this ML techniques are applied
    to their health monitoring feature for prospective of early disease detection.
    Whereas, livestock production employs the ML on the estimation of the balanced
    production of livestock for the producers to achieve economic benefits. Dutta
    et al. [130] described a procedure for the classification of cattle behaviour
    employing the ML techniques for data collection using collar-based sensors i.e.,
    magnetometers and three-axis accelerometers. In this study, events such as oestrus
    and dietary changes on cattle have been analyzed for their well-nutrition. Pegorini
    et al. [131] presented an automatic identification and classification of chewing
    habits of claves employing ML-based techniques for analysing their health and
    behavioural patterns. Ebrahimie et al. [132] proposed ML predictive model for
    estimating Sub-Clinical Mastitis (SCM) from milking parameters in dairy herds.
    Mastitis is an inflammatory disease that is widely affecting the dairy industry.
    Author’s explored four classification models decision trees, stump decision trees,
    parallel decision trees, and random forest to discover SCC independent of Somatic
    Cell Count (SCC) which is widely used to measure SCM worldwide. RF with Gini Index
    criteria best predicts SCM with an accuracy of 90%. Ebrahimie et al. [133] explored
    the attribute weighting model (AWM) for identifying lactose concentration and
    electrical conductivity in milk, which are two of the major indicators of SCM
    in dairy cattle. Hyde et al. [134] also explored RF to predict the route of transmission
    of germs and classify them into contagious (CONT) or environmental (ENV) with
    ENV further sub-classified into non-lactating “dry” period (EDP) or lactating
    period (EL). The simulation results show that an accuracy of 98% was achieved
    for discovering CONT vs ENV and 78% for discovering EDP and EL. Esener et al.
    [135] utilized spectral profiles dataset to discriminates CONT and ENV strains
    using GA, NN, and quick classifier. Ebrahimi et al. [136] predicted sub-clinical
    bovine mastitis using a large milking dataset collected through an automated in-line
    monitoring system in commercial New Zealand dairy farm. The simulation results
    show that GBM outperforms other ML model and best predict sub-clinical bovine
    mastitis with an accuracy of 84.9%. Sharifi et al. [137] explored meta-analysis
    and decision trees data mining tools to discover genes that can help to find mastitis
    in dairy cattle. Machado et al. [138] explored the RF model to identify factors
    influencing the occurrence of Bovine viral diarrhea virus (BVDV) viral disease
    in cattle in southern Brazil. The proposed approach identifies that insemination,
    the number of cattle in neighbouring farms, and routine rectal palpation are among
    the main factors of the occurrence of this disease. Matthews et al. [139] developed
    an ML-based automated monitoring system for tracking animal behaviour and movement
    i.e., standing, moving, feeding, and drinking by employing the depth video cameras
    and sensors. Qiao et al. [140] explored the DL technique Mask R-CNN for examining
    cattle health and welfare information in precision livestock management. The proposed
    model extract key features from image frames, enhance the image to remove non-uniform
    illumination shadow influences, segment image of cattle from the background image
    using the Mask R-CNN DL tool, and lastly extract cattle contour lines from the
    segmented image. The proposed approach outperforms SharpMask and DeepMask image
    segmentation models with mean pixel accuracy of 0.92 and an average distance error
    of 33.56 pixels. Liakos et al. [141] explored ML model for predicting healthy
    cattle and cattle suffering from lameness utilizing basic features of cattle which
    includes per day habits of cattle like steps taken, overall walking, lying, and
    eating habits. Morales et al. [142] employed a method based on SVM for early detection,
    warnings, and production issues of eggs in the poultry farms. The simulation results
    show that the proposed technique alerts a day before with an estimation accuracy
    of 0.9854. The identification of livestock is an important aspect of monitoring
    growth and animal welfare. Hansen et al. [143] explored deep learning techniques
    CNN for identifying pigs faces from the dataset of digital images of pigs obtained
    from commercial farm environment where the parameters such as dirt and lighting
    are highly unpredictable. The proposed approach accurately predicts the faces
    with an accuracy of 96.7%. Fenlon et al. [144] build a decision support system
    using predictive ML algorithms to provide calving assistance in the dairy industry.
    Four ML techniques multimodal regression, decision trees, RF, and NN were explored
    to predict three calving difficulties unassisted, slight assistance, and veterinary
    assistance. The simulation result shows that NN and multimodal regression models
    accurately classify 75% of calving difficulties with an average prediction error
    of 3.7% and 4.5%. Fenlon et al. [145] analyzed calving difficulties in dairy herds
    in Ireland using ML algorithms. A dataset of parity, log days in milk, inter-service
    interval, difficulties faced in the last calving, herd body conditions were built
    to predict conceptions using artificial insemination in the Iris dairy industry.
    Logistic regression outperforms RF, decision trees, and Naive Bayes in predicting
    conception using artificial insemination. Borchers et al. [146] explored RF, linear
    discriminant, and NN for calving prediction in dairy cattle by examining their
    behaviour which includes number the of steps, lying time, standing time, transition
    from one state to other and total motion 14 days before the predicted calving
    date. Although, the innovative algorithms play a crucial role in livestock management
    but combining livestock data with public data will improve precision livestock
    farming standards [147]. Table 8 presents a comparative study of different ML
    algorithms for livestock production and management. TABLE 8 Different ML Algorithms
    for Livestock Production and Management F. Intelligent Harvesting Techniques Smart
    harvesting systems helps the farmers to harvest agriculture goods by reducing
    human efforts. In this approach, technologies such as smart sensors, robotics,
    UAVs, and IoT devices [148], AI, and ML-based computer vision techniques are employed
    to intelligently harvest the crops. The research community has provided a comprehensive
    review of different intelligent techniques used to automate the agriculture industry
    [149]–[151] and have analyzed the potential and challenges of this decision support
    system [152]. In the last few years, different robots have been developed for
    harvesting fruits and vegetables [153]. Smart harvesting offers better insight
    into the crops and helps farmers to achieve the potential harvest of crops which
    leads to increased productivity. Smart harvesting system has numerous advantages
    in comparison to traditional harvesting approaches like it requires less labour,
    optimized crop yield, maximum probability, better insight into crops, reduced
    cost of harvesting, and cost-efficient production. A significant problem in the
    Japanese agriculture industry is a labour shortage. Sakai et al. [154] utilized
    machine vision for asparagus robot harvesting in Nagasaki prefecture. The speed
    of asparagus robot harvesting is three times faster than the human being. Since
    asparagus harvesting is modeled on their size and doesn’t require color properties
    thus laser sensor is used to collect 3D distance information in the proposed work.
    Monta et al. [155] also explored laser sensors along with color cameras for tomato
    harvesting through robots. Preter et al. [156] developed an autonomous system
    consisting of e-vehicle, cameras, robotic arm, localization system, gripper, quality
    monitoring, and logistic handling system, which can efficiently detect, plucks,
    and puts the strawberries in a box. The proposed robot prototype is fast enough
    to pluck the fruit in just 4 seconds. Hayashi et al. [157] practically evaluated
    the performance of strawberry harvesting robots in a greenhouse test field. The
    proposed autonomous system efficiently access the fruit position and its maturity
    level and pick the fruit with and without suction in a duration of two to three
    weeks without damaging the fruit. Horng et al. [158] proposed a smart harvesting
    system that employs IoT and smart image recognition systems for the detection
    of mature crops using object detection feature trained on MLP neural network.
    The mature crop can be harvested using a robotic arm whose movement is predicted
    using ML algorithms. Zhang et al. [159] explored Regions-CNN (RCNN) for multi-class
    canopy object detection in shake and catch the apple harvesting system. A dataset
    of RGB images was created in the commercial orchard using a Kinect v2 sensor and
    pre-trained RCNN is utilized for real-time detection of apple, branches, and trunks.
    The authors also developed an estimation algorithm to predict shaking location
    based on the results of RCNN. Spectral and thermal images have also been explored
    for the detection of fruits and vegetables [160], [161]. Zhang et al. [162] investigated
    eleven canopy parameters using principal component analysis (PCA) and classified
    the removal status of apples into mechanically harvested and mechanically unharvested.
    Zhang et al. [163] reviewed technology progress in the mechanical harvesting of
    apples which includes shake and catch, robots, and harvest assist platforms. Pise
    and Upadhye [164] explored Naive Bayes and SVM ML techniques for grading of harvested
    mangoes based on their color, size, features, quality, and maturity. Grading of
    fruits increases the profit of the agriculture and food industries. A mango image
    dataset comprising of three different colors red, green, and yellow is created
    and is used for training and testing the ML algorithm. The proposed approach presents
    limited scope as it can detect defects in a particular surface area which can
    be overcome by creating a dataset of rotational view images. Wu et al. [165] explored
    NN for recognition, classification of fruits and vegetables, and obstacle avoidance
    in a harvesting robot. Table 9 presents a comparative study of different ML algorithms
    for intelligent harvesting. TABLE 9 Different ML Algorithms for Intelligent Harvesting
    SECTION V. IoT Applications in Precision Agriculture Precision agriculture refers
    to a system with minimizing direct involvement of the caretaker/farmer except
    when there is an urgent need or an emergency i.e. when there is a failure in the
    system. IoT helps in maintaining the defined standards of parameters needed for
    day to day work in agriculture. The parameters can be measured using the required
    sensors and can be uploaded to an IoT cloud for remote monitoring so that the
    direct involvement of farmers is minimized. The IoT cloud can be used for control
    purposes also, say for example in detecting and avoiding animal intrusion in the
    agriculture field. Sensors are an integral part of IoT for precision agriculture
    without which the monitoring and controlling becomes next to impossible task.
    Figure 6 shows the trend search of keywords “IoT in agriculture” and “sensor in
    agriculture” on google in the last 10 years. Apart from monitoring and controlling,
    IoT in agriculture is also used as data-storage technology. Parameters like properties
    of soil, crop yield, seasonal behaviour data, temperature changes, etc can be
    stored on the IoT cloud which will be helpful in analyses, prediction, and deciding
    on estimated crop production. FIGURE 6. Google trend response for keywords IoT
    in agriculture and sensor in agriculture for the last 10 years. Show All A. Sensors
    for IoT in Precision Agriculture IoT is defined as the interconnection of things,
    where one example of a thing is a sensor. A group of sensors can communicate with
    every other sensor and thereby with the control center. A WSN in IoT has the benefits
    of increasing the efficiency of production, enhancing the yield quality, detecting
    and avoiding plant-eating pets, detecting the fires in the farms [166]. IoT has
    helped in increasing the scope of farming, animal, and pet rearing along with
    smart irrigation [167]. Sensors form an integral part of IoT architecture in agriculture.
    A sensor is defined as a transducer that converts the sensed parameter (soil moisture,
    for example) into the equivalent electrical signal. Depending on the nature of
    the output signal they generate, sensors are classified as analog or digital sensors.
    An analog sensor’s output needs to be converted to digital before it is being
    fed, processed by any IoT system. On the other hand, sensors that generate signals
    in digital form can be directly connected to any IoT system. Table 10 compares
    the list of some important sensors applicable in precision agriculture. Addressing
    the complete list of sensors available for precision agriculture is beyond the
    scope of this article, although, table 10 provides the list of sensors and their
    parameters that are very widely used and covers almost every aspect of IoT in
    agriculture. A pair of sensors and actuators can be used to collect information
    about some of the vital parameters of precision agriculture and react to perform
    predefined action whenever required. IoT plays an important role in assuring that
    the action performed happens instantaneously with minimum delay. The factors that
    can affect the real-time decision making and causes a delay is the tolerance of
    the measuring parameter and the communication protocol used. The operating temperature
    where the sensors are placed have a proportional effect on tolerance. An increase
    temperature on either side will increase the tolerance of the measuring parameter
    and sensor reading will deviate the value of the measurand from the actual value.
    The communication protocol is used to send the readings of the sensor to the microcontroller
    from where the value will be uploaded to the IoT cloud. The data rate of communication
    protocol decides the time required for this data transfer. TABLE 10 Sensor Parameters
    Used in Precision Agriculture B. Wireless Sensor Networks in Precision Agriculture
    WSN is the collection of spatially displaced sensor deployed to monitor the physical
    parameters of the environment and coordinating the collected data at central location.
    IoT transfers the recorded data to cloud which is further processed and analyzed
    through intelligent algorithms. In precision agriculture integration of artificial
    intelligence with WSN allows real time monitoring and intelligent decision making
    in agriculture fields. IoT sensor network which includes soil moisture senor,
    electrochemical sensor, optical sensors, etc. continuously monitor the field data
    and works as a training data for ML and DL algorithms. Edge computing enabled
    AI systems assist in reducing the amount of data to be uploaded to IoT cloud by
    identification of meaningful data to be communicated and discarding the redundant
    data. Intelligent processing of data generated from nodes result in better management
    of sensor network In [185] author utilized AI driven sensor network to classify
    land as suitable, more suitable, moderately suitable and unsuitable after every
    cultivation. In [186] author developed a power efficient WSN using Arduino microcontroller
    and ZigBee module to monitor and control essential parameters that effect crop
    growth such as soil and weather conditions in Florida, USA. In [187] author integrating
    sensor nodes with AI systems to reduce the power consumption of nodes by optimizing
    the performance and data transmission of respective nodes. RNN based Long-Short
    term (LSTM) network was built which increases the runtime of a single sensor and
    guarantees 180 days autonomous operation using Li-ion battery. The proposed system
    continuously monitors the growth dynamics of plant leaves. In [188] author presents
    an autonomous system built with low power sensor nodes and IoT based cloud platform
    to estimate level of phosphorous in soil through ANN. Author incorporates dynamic
    power management system to maintain balance between energy consumption and estimation
    accuracy. In [189] author presents GA optimized WSN for precision agriculture
    applications. Thus, we conclude that integrating artificial intelligence with
    WSN, IoT plays a key role in assuring the best yield of crops. SECTION VI. Assessment
    and Evaluation of Knowledge-Based Agriculture System In this section ML algorithms
    used by different researchers in the precision agriculture system are analyzed.
    The agriculture industry is facing many challenges across the world, and a knowledge-based
    agriculture system allows sustainable use of resources by the farmers aiming to
    get maximum output from the agriculture land. There are two basic stages in precision
    agriculture, i.e. pre-processing stage and processing stage. In the pre-processing
    phase market trends are studied and based on geographical conditions and soil
    properties of the land seeds are selected and the land is prepared for precision
    agriculture system. In the post-processing stage machine vision techniques are
    explored for disease and weed identification while intelligent techniques are
    used for irrigation and harvesting. In this article, author reviewed and discussed
    70 articles where multiple ML algorithms are presented for performance optimization
    of the agricultural cycle. Figure 7 shows the classification of articles based
    on different applications of precision agriculture. FIGURE 7. Classification based
    on agriculture cycle. Show All Figure 8 depicts the cumulative distribution of
    the ML and DL models used by researchers in precision agriculture. The graph depicts
    the broad categorisation of the techniques with their applications to agricultural
    cycle. It has been observed that in majority of the literature the researchers
    have applied multiple algorithms for classification and parameter prediction.
    Regression models and ANN together make up around 65% of the AI techniques employed
    by researchers. Hence, it is important to investigate the techniques used and
    compared by the authors. The individual best performing algorithms have already
    been covered in appropriate sections, however the figure 8 depicts the distribution
    of the various regression algorithms and DL models throughout the literature.
    ELM algorithm is widely explored in prediction of soil properties such as soil
    moisture, soil temperature, surface humidity, ETc. ANN accurately predicts the
    rainfall and crop yield across different regions of globe. DL based CNN model
    finds wide applications for accurate disease and weed classification in agriculture
    crops. ANN model best predicts the nitrate content and water requirement in drip
    irrigation system. SVM regression model estimates the emitter outflow discharge
    under varying temperature and pressure conditions. Decision Tree algorithm accurately
    identify the chewing habits and predicts SCM in dairy herds. CNN have widely explored
    for livestock identification. Metaheuristic optimized ML algorithms are also explored
    by researchers in precision agriculture. FIGURE 8. ML techniques used in precision
    agriculture applications. Show All In the reviewed articles, authors have used
    around 22 different regression algorithms for prediction, however 5 most commonly
    used algorithms are identified and depicted in the figure 9. Remaining 17 algorithms
    which are used either only for comparison or employed as a support algorithms
    have been classified into others. FIGURE 9. Regression algorithm in precision
    agriculture. Show All DL models have contributed significantly and outperforms
    ML classification algorithms in classification of crop disease and weed as well
    as for livestock diseases identification. Figure 10 shows CNN, ANN and RNN algorithms
    explored in precision agriculture. In the reviewed articles, authors have used
    around 10 different DL/NN algorithms for prediction/classification, however 8
    most commonly used algorithms are identified and depicted in the figure 10. Remaining
    2 (LeNet, and Caffee) algorithms which are used either only for comparison or
    employed as a support algorithms have been classified into others. FIGURE 10.
    Classification algorithm in precision agriculture. Show All A. Performance Comparison
    of ML Algorithms in Precision Agriculture The application of ML and DL algorithms
    highly depends on the agriculture cycle and the dataset involved. This section
    discusses the advantages and limitations of various ML and DL algorithms such
    as regression and classification algorithms based on the agriculture cycle involved.
    1) Soil Properties and Weather Prediction The application of AI techniques in
    prediction of soil parameters and weather is dependent on various factors. The
    researchers generally employ around 3 to 4 algorithms in for prediction and select
    the algorithms which has most accurate prediction and is robust to factors such
    as: noise, non-linearity, outliers etc. the most commonly employed algorithms
    are ELM, RF, SVR, and cubist algorithm. Advantages of using ML in prediction of
    soil properties and weather pattern: Non-linear dataset – these predictions often
    attributes a non-linear dataset which can be utilized for accurate prediction
    by regression algorithms such as: ELM, RF, SVR Large dataset – the dataset for
    is often obtained from satellite which can be well handled by the regression algorithms
    with less convergence time and accurate predictions. Insensitivity to outliers
    – Weather patterns often encounter outlier events which may affect the prediction
    accuracy, however algorithms such as ELM, NN are robust to outliers and provide
    accurate predictions. Accurate prediction – prediction of parameters using ML
    exhibit low error indices such as RMSE, and R2 which are standard measures of
    accuracy for statistical analysis. Challenges and limitations in prediction of
    soil properties and weather pattern: Varying geographical conditions poses a challenge
    for universal design of the prediction algorithms. Soil parameters prediction
    is highly dependent on the sample selection philosophy. Dataset selection and
    filtering is a challenge for researchers with non-computing background. 2) Crop
    Yield Prediction The application of AI techniques in prediction of crop yield
    is a mammoth task and lack of availability of a universal model makes designing
    of the algorithm challenging. The most promising algorithms for crop yield prediction
    are regression algorithms, and neural networks. Advantages of using ML in crop
    yield prediction: Complex dataset – crop yield prediction involves enormous dataset
    composing of satellite data and/or historic data. Faster and accurate predictions
    can be made by utilizing the AI techniques such as regression algorithms (SVR,
    RF) Neural networks (CNN). Parameter variation – the crop yield depends on a lot
    of parameters, like climatic factors, soil quality, NDVI, altitude, air parameters.
    The AI based prediction systems handle the parameters dependency efficiently.
    Accurate prediction – prediction of parameters using ML exhibit low error indices
    such as RMSE, and R2 which are standard measures of accuracy for statistical analysis.
    Challenges and limitations in prediction of crop yield: Varying parameters and
    complex datasets pose a challenge for universal design of the prediction algorithms.
    Dataset selection is critical due to the complexity; as an improper selection
    of data may result in underfit/overfit prediction pattern. 3) Disease and Weed
    Detection The applications of AI techniques in disease and weed detection primarily
    depends on the advances in image processing. CNN’s are the most prominent choice
    for building a disease identification system. Training dataset will govern the
    performance of the algorithm, although these are available in open-source format,
    users have to be cautious while using the dataset. Advantages of using ML in detection
    of weed and disease in a crop field: Prediction accuracy – AI offer accurate detection
    of disease and weeds with an accuracy of 99% which is better compared to manual/classical
    techniques. Robust prediction – the algorithms can predict the disease/weed even
    with smartphone images, which is commonly available with farmers. Easy configuration
    – with CNN being the most common and reliable technique, designing a disease/weed
    detection system is not a complex job unlike other systems discussed in text.
    Challenges and limitations in detection of weed and disease in a crop field: The
    accuracy of prediction depends on the quality of training dataset some of which
    is available as an open-source dataset, but is applicable to only a limited number
    of crops. Improperly labelled data may result in a disastrous prediction system,
    as the training of the system plays a major role in the performance of the system.
    Overtraining the model may result in a sensitive prediction system. 4) Drip Irrigation
    Smart irrigation systems are not only crop friendly but are environmental friendly
    too. The combination of IoT with the AI not only reduces the manual intervention
    but also utilizes the available in an optimum way to ensure no adverse effect
    to environment. Regression and Advantages of using ML in drip irrigation for an
    agricultural field: Optimum resource utilization – accurate estimation of irrigation
    requirements results in a system which optimizes the resource (water, electricity)
    utilization (NN algorithms). Crop protection – optimized irrigation practices
    minimizes water related damage to the crops and hence increases the crop yield.
    Robust to weather variations – an accurately designed AI based (Regression algorithms)
    irrigation system handles the random weather events in a better way when compared
    with the non-AI based irrigation methods. Challenges and limitations in drip irrigation
    for an agricultural field: Accurate prediction sometimes depends on the number
    of sensors and hence increases the initial investment of the farmers. An incorrect
    sensor placement in the filed affects the accuracy of the system, hence sensor
    optimization becomes imperative in designing a smart irrigation system. The architecture
    of prediction system highly depends on the dataset; hence no universal guidelines
    can be laid out for system design. 5) Livestock Production and Management The
    livestock management primarily focuses on the well-being of the farm animals and
    uses advanced image recognition (CNN) algorithms, and regression techniques to
    detect and predict the disease/ disease spread. Advantages of using ML in livestock
    production and management: Decreased risk of diseases – AI systems assists in
    identifying the livestock diseases and also helps in combating the disease, by
    predicting the root of diseases and transmission (Regression algorithms). Minimization
    of disease spread – timely diagnosis and treatment reduces the risk of spreading
    the disease. Psychological analysis – advanced image recognition and behavioural
    analysis (CNN techniques) help is detecting the stress in animals ensuring heath
    of the livestock. Challenges and limitations in drip irrigation for an agricultural
    field: With varying geographic and climatic conditions the attributes of the cattle
    and diseases changes hence, no universal system can be designed to cater to the
    diversities. Some viruses are difficult to predict even using the state-of-art
    prediction algorithms. 6) Intelligent Harvesting The applications of AI techniques
    in harvesting is primarily an assistive technology for automatic harvesting systems.
    Harvesting prediction system largely relies on the advances in image processing
    and CNN’s are the most prominent choice for building these systems. Advantages
    of using ML in intelligent harvesting: Assistive technology – AI in conjunction
    with existing harvesting robots exhibit high accuracy in harvesting. Image processing
    – the identification of harvesting relies on the state-of-art image processing
    algorithm (CNNs) and hence the developments in the image processing algorithms
    result in direct accuracy enhancement of intelligent harvesting techniques. Universal
    algorithms – the AI harvesting techniques largely depend on image recognition
    methods, hence CNNs can easily be deployed for implementing intelligent harvesting
    techniques. Challenges and limitations in intelligent harvesting: The accuracy
    of the prediction systems largely depends on the training dataset, hence accurately
    labelled dataset is a primary requirement of implementing an intelligent harvesting
    system. Inaccurate harvesting recognition system result in economic loss for farmers,
    as a delay in harvesting might lead to an overripe crop or early harvesting might
    lead to rejection of the product. SECTION VII. Challenges and Limitations of Artifical
    Intelligence in Precision Agriculture Artificial intelligence has the potential
    of playing an important role in meeting the food requirement of entire world.
    However, there are certain challenges which are hampering its adoption in agriculture
    industries which are outlined as follows: A recent government survey in India
    estimated that literacy rate of Indian farmers is very low therefore bridging
    the gap between farmers and technology is a challenging task. Farmers are less
    motivated to come out from their comfort zone and learn digital skills to improve
    their farming standards. Agriculture lands are mostly situated in rural areas.
    Implementation of IoT architecture and WSN which requires cloud services for data
    storage and analysis is a big issue in rural areas where reliable internet connectivity
    is not available. Accurate prediction and classification through cognitive ability
    of machines is difficult in varying geographical conditions. Initial set up of
    digital farming which includes hardware and software requires huge investment.
    Deployment of smart sensors and other electronic gadgets requires heavy energy
    consumption. SECTION VIII. Future Trends of Artifical Intelligence and IoT in
    Precision Agriculture Agriculture industry is globally US$5 trillion industry
    and now it has been revolutionized with artificial intelligence and IoT technologies.
    These innovative tools are assisting famers to improve crop yield, monitor soil
    parameters, livestock health and temperature conditions, control pests and improve
    other agriculture related tasks. Conventional ML and DL models such as SVM, RF,
    ANN finds difficult to accurately estimate soil parameters and weather conditions
    in varying ecosystem. Therefore, swarm intelligence optimized robust and adaptive
    ML and DL algorithms such as SVM-PSO, ANN-GWO algorithms can be explored to effectively
    forecast different parameters in precision agriculture. In large agriculture fields
    swarm intelligence inspired autonomous system can be built for crop health and
    growth monitoring. UAV swarm can be utilized for near real time field and livestock
    monitoring through computer vision and DL algorithms and accordingly swarm of
    UAV can be used for spraying of pesticides and fertilizers in the infected crops.
    Greenness of crops can be identified through UAVs installed cameras and an automated
    irrigation system can be built in large agriculture fields. Swarm of mobile robots
    can be used in the agriculture fields to efficiently automate task such as harvesting,
    weed identification and elimination, etc. Metaheuristic algorithms can be explored
    for nodes localization in agriculture fields in order to optimize the sensor deployment
    in the field and keep the minimize cost to farmers. Offline service chatbots can
    be built to assist farmers in developing countries where farmers don’t have good
    internet connectivity. These chatbots can assist farmers by providing timely advice
    based on expert recommendations and will help to resolve their specific farming
    problems. Artificial intelligence assisted renewable energy plants can be installed
    in agriculture lands to maximize the power output of clean energy in unpredictable
    weather conditions. This will allow for sustainable agricultural practices. Artificial
    intelligence can also be explored in vertical and soilless agriculture. In near
    future artificial intelligence systems, robotics and smart sensor technology will
    automate the whole farming process starting from seed sowing to intelligent fruits
    and vegetables harvesting and packaging. SECTION IX. Conclusion Precision agriculture
    is empowering the farmers with technology intending to get optimum outputs with
    precise inputs. IoT enabled smart sensors, actuators, satellite images, robots,
    drones are some of the key technological revolutions that boosted the agriculture
    industry. These components play a vital role in collecting real-time data and
    accordingly making decisions without human support. Artificial intelligence which
    is the automation of intelligent behaviour is continuously benefiting our planet
    and helping humans in various aspects of life. In this paper, authors have reviewed
    ML applications for precision agriculture. The impact of AI and IoT in smart farm
    management is discussed with a brief introduction to ML algorithms which are most
    commonly used in precision agriculture. Regression algorithms are the backbone
    for soil properties, weather, and crop yield prediction. DL algorithms such as
    CNN and ML classification algorithms such as SVM, Decision trees, and RF were
    explored for the identification of disease and weeds in the plants. Smart irrigation
    systems and harvesting techniques play an important component in precision agriculture
    as these techniques quickly complete the work and reduces human labour. Drones
    and robots enabled with a digital camera are employed for this work. Livestock
    management is an important concern for farmers across the world. Knowledge-based
    agriculture system which includes smart IoT devices and AI tools efficiently handle
    livestock management. As a scope of future work, NLP based chatbots can be built
    for famers and more ML, DL and hybrid algorithms can be explored in the agriculture
    industry for sustainable use of available resources. Authors Figures References
    Citations Keywords Metrics More Like This Internet of Things and Wireless Sensor
    Networks for Smart Agriculture Applications: A Survey IEEE Access Published: 2023
    Precision Agriculture Using Internet of Things and Wireless Sensor Networks 2023
    International Conference on Disruptive Technologies (ICDT) Published: 2023 Show
    More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS
    VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION
    AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE:
    +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help
    | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting
    | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s
    largest technical professional organization dedicated to advancing technology
    for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE access
  limitations: '>'
  pdf_link: https://ieeexplore.ieee.org/ielx7/6287639/9312710/09311735.pdf
  publication_year: 2021
  relevance_score1: 0
  relevance_score2: 0
  title: 'Machine Learning Applications for Precision Agriculture: A Comprehensive
    Review'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1016/j.atech.2022.100042
  analysis: '>'
  authors:
  - Rabiya Abbasi
  - Pablo Martı́nez
  - Rafiq Ahmad
  citation_count: 110
  full_citation: '>'
  full_text: '>

    Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords 1. Introduction 2. Research methodology 3.
    Digitization trends in agriculture 4. Agriculture 4.0 enabling technologies 5.
    Conclusions Declaration of Competing Interest Acknowledgements References Show
    full outline Cited by (119) Figures (16) Show 10 more figures Tables (13) Table
    1 Table 2 Table 3 Table 4 Table 5 Table 6 Show all tables Smart Agricultural Technology
    Volume 2, December 2022, 100042 The digitization of agricultural industry – a
    systematic literature review on agriculture 4.0 Author links open overlay panel
    Rabiya Abbasi a, Pablo Martinez b, Rafiq Ahmad a Show more Share Cite https://doi.org/10.1016/j.atech.2022.100042
    Get rights and content Under a Creative Commons license open access Highlights
    • SLR is conducted using PRISMA approach and148 articles are selected and critically
    analyzed. • The results show the extent of digital technologies adoption in agriculture.
    • The potential benefits of digital technologies and roadblocks hindering their
    implementation in agriculture sector are identified and discussed. • The study
    will positively impact the research around agriculture 4.0. Abstract Agriculture
    is considered one of the most important sectors that play a strategic role in
    ensuring food security. However, with the increasing world''s population, agri-food
    demands are growing — posing the need to switch from traditional agricultural
    methods to smart agriculture practices, also known as agriculture 4.0. To fully
    benefit from the potential of agriculture 4.0, it is significant to understand
    and address the problems and challenges associated with it. This study, therefore,
    aims to contribute to the development of agriculture 4.0 by investigating the
    emerging trends of digital technologies in the agricultural industry. For this
    purpose, a systematic literature review based on Protocol of Preferred Reporting
    Items for Systematic Reviews and Meta-Analyses is conducted to analyse the scientific
    literature related to crop farming published in the last decade. After applying
    the protocol, 148 papers were selected and the extent of digital technologies
    adoption in agriculture was examined in the context of service type, technology
    readiness level, and farm type. The results have shown that digital technologies
    such as autonomous robotic systems, internet of things, and machine learning are
    significantly explored and open-air farms are frequently considered in research
    studies (69%), contrary to indoor farms (31%). Moreover, it is observed that most
    use cases are still in the prototypical phase. Finally, potential roadblocks to
    the digitization of the agriculture sector were identified and classified at technical
    and socio-economic levels. This comprehensive review results in providing useful
    information on the current status of digital technologies in agriculture along
    with prospective future opportunities. Previous article in issue Next article
    in issue Keywords Agriculture 4.0Industry 4.0DigitizationConnectivityInternet
    of thingsSmart agricultural systems 1. Introduction 1.1. A global food security
    problem Food security is a multidimensional concept that alleviates hunger by
    ensuring a sustainable, nutritious food supply. It is characterized by a four-pillar
    model shown in Fig. 1, with each pillar intrinsic to ensure food security [1].
    Download : Download high-res image (262KB) Download : Download full-size image
    Fig. 1. Four-pillar model of food security by Food and Agriculture Organization
    of the United Nations. Download : Download high-res image (437KB) Download : Download
    full-size image Fig. 2. Agriculture value chain: stages and main functions. Due
    to several anthropogenic factors, such as rapid population growth, urbanization,
    industrialization, farmland loss, freshwater scarcity, and environmental degradation,
    food security is becoming a serious global issue. This is because these factors
    are also directly impacting agricultural industry which is a primary source of
    agri-food production around the world. It is anticipated that by 2050 global population
    will be increased from the current 7.7 billion to 9.2 billion, urban population
    will be rise by 66%, arable land will be declined by approximately 50 million
    hectares, global GHG emissions (source of CO2 – promote crop disease and pest
    growth) will be increased by 50%, agri-food production will be declined by 20%,
    and eventually, food demand will be increased by 59 to 98% – posing an imminent
    threat to food security and adequate food availability [2], [3], [4]. To satisfy
    the increasing food demands, agricultural practitioners worldwide will need to
    maximise the agricultural productivity involving crop and livestock farming. In
    this review paper, the focus is on crop farming that involves cultivation of both
    food and cash crops. A typical agri-food value chain depicting three primary stages,
    namely pre-field (pre-plantation stage), in-field (plantation and harvesting stage),
    and post-field (post-harvesting stage) involved in the production of agricultural
    products is shown in Fig. 2. All the stages play a vital role in the value chain
    but, in this review, the second stage ˝in-field˝ will be considered that involves
    several crop growing processes such as plowing, sowing, spraying, and harvesting,
    etc. These processes currently employ traditional agricultural practices that
    are labor-intensive, require arable land, time, and a substantial amount of water
    (for irrigation) – making it a challenge to produce enough agri-food [5]. A part
    of problem is also related to irregular use of pesticides and herbicides and misuse
    of available technology which cause harm to crop and eventually resulting in agricultural
    wastes [6]. These issues can be addressed by integrating sophisticated technologies
    and computer-based applications that ensure high crop yield, less water consumption,
    optimised pesticide/herbicide utilization, and enhanced crop quality. This is
    where the smart agriculture concept comes in. 1.2. Smart agriculture Industry
    4.0, also known as the fourth industrial revolution, is revolutionizing, and reshaping
    every industry. It is a strategic initiative characterized by a fusion of emerging
    disruptive digital technologies such as Internet of Things (IoT), big data and
    analytics (BDA), system integration (SI), cloud computing (CC), simulation, autonomous
    robotic systems (ARS), augmented reality (AR), artificial intelligence (AI), wireless
    sensor networks (WSN), cyber-physical system (CPS), digital twin (DT), and additive
    manufacturing (AM) to enable the digitization of the industry [7]. The integration
    of these technologies in agriculture is sparking the next generation industrial
    agriculture, namely, agriculture 4.0 – also termed smart agriculture, smart farming,
    or digital farming [7]. Smart agriculture provides farmers with a diverse set
    of tools (shown in Fig. 3) to address several agricultural food production challenges
    associated with farm productivity, environmental impact, food security, crop losses,
    and sustainability. For instance, with IoT-enabled systems consisting of WSNs,
    farmers can connect to farms remotely irrespective of place and time to monitor
    and control farm operations. Drones equipped with hyperspectral cameras can be
    used to collect data from heterogeneous sources on farmlands and autonomous robots
    can be used to support or accomplish repetitive tasks at farms. Data analytics
    techniques can be employed to analyze the gathered data with computer applications
    can be used to assist farmers in decision-making process. Likewise, a wide variety
    of parameters related to environmental factors, weed control, crop production
    status, water management, soil conditions, irrigation scheduling, herbicides,
    and pesticides, and controlled environment agriculture can be monitored and analyzed
    in smart agriculture to increase crop yields, minimize costs, enhance product
    quality, and maintain process inputs through the use of modern systems [8]. Download
    : Download high-res image (334KB) Download : Download full-size image Fig. 3.
    The concept of “Smart Agriculture”. 1.3. Research motivation and contribution
    The motivation for preparing this review stems from the fact that digital technologies
    in agricultural systems offer new strategic solutions for enhancing the efficiency
    and effectiveness of farms’ production. Moreover, digital transformation provides
    a way forward to implement modern farming practices such as vertical farming (hydroponics,
    aquaponics and aeroponics), which has the potential to overcome food security
    problems. But there is a set of problems and limitations associated with this
    transformation from the technical, socio-economic, and management standpoint that
    must be death to fully exploit the potential of agriculture 4.0 [9]. There are
    number of studies that have discussed emerging trends in the development of agriculture
    4.0 by providing succinct information on key applications, advantages, and corresponding
    research challenges of smart farming [9], [10], [11], [12], [13], [14], [15],
    [16], [17], [18]. The research focus of these studies is limited to either explaining
    more generic technical aspects while paying attention to only one or few digital
    technologies, and/or enhancing agricultural supply chain performance, and/or developing
    agriculture 4.0 definition, and/or achieving sustainable agronomy through precision
    agriculture, and/or proposing a smart farming framework. Nevertheless, these studies
    do not involve explicit discussion on the tools and techniques used to develop
    different systems and maturity level of these systems. There is also a lack of
    studies considering modern soilless farms such as hydroponics, aquaponics and
    aeroponics (indoor/outdoor) and implications of digital technologies in these
    farms. Hence, it is necessary to analyse the evolution of agriculture 4.0 from
    different perspectives to stimulate the discussion in the area. This study aims
    to present a holistic overview of digital technologies implemented in second stage
    of agricultural production value chain (in-field) for different types of farms
    as mentioned in section 1.1. The main theoretical contribution of the study involves
    analysis and dissemination of the tools and techniques employed, the farm type,
    the maturity level of the developed systems, along with potential roadblocks or
    inhibiting factors in development of agriculture 4.0. The reflections presented
    in the review will support researchers and agricultural practitioner in future
    research on agriculture 4.0. 1.4. Paper organization Following the introduction,
    the paper is structured as follows: Section 2 discusses the approach used to gather
    the relevant literature; then, Section 3 presents the statistical results obtained
    after a general analysis of the selected research studies; next, Section 4 provides
    a detailed overview of the core technologies used in the digitization of agriculture;
    after, Section 5 highlights the technical and socio-economic roadblocks to digital
    integration in agriculture; next, Section 6 outlines a discussion about the research
    questions followed by added value, considerations and future prospects related
    to agricultural digitization, and transition to agriculture 5.0; and lastly, Section
    8 concludes the review. 2. Research methodology A systematic literature review
    (SLR) is a tool used to manage the diverse knowledge and identify research related
    to a predetermined topic [19]. In this study, SLR is conducted to investigate
    the status of Industry 4.0 technologies in agricultural industry. Particularly,
    cases are searched where the term ‘agriculture’ appeared concurrently in the title,
    abstract, or keywords of an article with any of the ‘Industry 4.0 technologies”
    mentioned in section 1.2. Before conducting the SLR, a review protocol is defined
    to ensure a transparent and high-quality research process, which are the characteristics
    that make a literature review systematic [20]. The review protocol also helps
    to minimize bias by conducting exhaustive literature searches. This includes three
    steps: the formulation of the research questions, the definition of the search
    strategy, and the specification of inclusion and exclusion criteria. This paper
    uses a preferred reporting item for systematic reviews and meta-analysis (PRISMA)
    approach to conduct SLR. PRISMA is an evidence-based minimum set of items that
    are used to guide the development process of systematic literature reviews and
    other meta-analyses [19]. 2.1. Review protocol A review protocol (in Table 1)
    is defined before conducting the bibliographic analysis to identify, evaluate,
    and interpret results relevant to the research scope. First, research questions
    are formulated to provide insight into the analysis of published studies in the
    research area of interest from different dimensions. These questions need to be
    answered in the study. Next, the search strategy is defined, which helps identify
    appropriate keywords later in the search equation to identify the relevant information
    sources, such as academic databases and search engines that provide access to
    a massive amount of digital documentation. Three online research repositories
    are used to retrieve relevant studies: ScienceDirect1, Scopus2, and IEEE Xplore3.
    Finally, to refine the search results of each database, boundaries are set by
    predefining inclusion and exclusion criteria for further investigation and content
    assessments of selected publications. It involves, for instance, defining the
    time interval for the research process from 2011 to 2021 to limit the studies
    to those published in English, disregarding chapters of books and grey literature,
    such as reports and summaries of events and seminars. These last two steps of
    the review protocol allow the preliminary filtering of metadata sources and narrow
    down the scope of research. Table 1. Review protocol for systematic literature
    review. Review questions RQ1: Which Industry 4.0 technologies have been used in
    the literature for digitization of agriculture? RQ2: How and to what extent have
    these technologies been applied in the context of service type, tools and techniques
    used, system''s maturity level, and farm type? RQ3: What are the primary roadblocks
    in implementation of Industry 4.0 technologies for smart farming? Study selection
    criteria Inclusion criteria: • Peer-reviewed journal articles and conference papers.
    • Studies published during the period between 2011 and 2021. • Studies should
    provide answers to the research questions. • The article must include the title,
    year, source, abstract, and DOI. • Literature focussing on application of Industry
    4.0 technologies in crop plantation and harvesting activities particularly in-field
    processes. Exclusion criteria: • Summaries of events and seminars, book review,
    and editorial. • Literature focusing on application of Industry 4.0 technologies
    in livestock farming; pre-field processes such as genetic development, seed development
    and seed supplying; post-field stages such as crop distribution, food processing
    and consumption; and agri-food supply chain. • Studies published before 2011.
    • The publication is not available in full text. • The publication is not in English.
    Literature search Sources: Scopus, ScienceDirect, and IEEE Xplore for academic
    literature, citations in identified literature Search equation: (("agriculture*")
    AND ("Industry 4.0" OR “Digital Farming” OR “Intelligent Farming” OR “Smart Agriculture”
    OR “Agriculture 4.0” OR “Smart Farming” OR “Internet of Things” OR “IoT” OR “Cloud
    Computing” OR “Edge Computing” OR “Wireless Sensor Networks*” OR “Artificial Intelligence*”
    OR “Big Data*” OR “Data Analytics*” OR “Data Science*” OR “Cyber Physical System*”
    OR “Robotics*” OR “Computer Vision*” OR “Machine Learning*” OR “Deep Learning*”
    OR “Data Integration*”)) 2.2. Evaluation process The evaluation of the literature
    search process is done in four stages: identification, screening, eligibility,
    and inclusion, as detailed by the PRISMA flow diagram shown in Fig. 4. After initial
    metadata filtering through the application of search expression, a total of 3165
    records are found (1690 from Scopus, 926 from ScienceDirect, and 549 from IEEE
    Xplore), which are then consolidated for the removal of duplicate items in the
    identification stage. The number of publications after this step is reduced to
    2876. In the screening stage, the titles and abstracts of the papers are analyzed,
    and only 498 papers are selected for integral reading. In the third stage, full-text
    screening of these articles is performed to verify their eligibility in relation
    to the objective of this paper, which is to answer the research questions mentioned
    in Table 1. Of the 498 papers, 137 are found to be relevant for this review. Another
    11 are added through a cross-referencing approach, adding up to 148 papers selected
    in the final stage for further analysis. Download : Download high-res image (624KB)
    Download : Download full-size image Fig. 4. Four-step evaluation of literature
    search process (PRISMA). 2.3. Threats to validity i SLR replication: The presented
    SLR is susceptible to threats to validity because the current search is limited
    to only three online repositories. More publications could potentially be found
    if additional sources were explored. The process of SLR is described clearly in
    sub-sections 2.1 and 2.2, and hence, validity can be considered well addressed.
    However, in the case of replication of this SLR, it is possible that one can find
    slightly different publications. This difference would result from different personal
    choices during the screening and eligibility steps of PRISMA, but it is highly
    unlikely that the overall findings would change. ii Search string: the search
    string used to find the relevant studies cover the whole scope of SLR, but there
    is a possibility that valuable studies might have been missed. Additional keywords
    and synonyms with a broader search might return more studies. 3. Digitization
    trends in agriculture The year-wise distribution of the 148 articles from 2011
    to 2021 is represented in Fig. 5. Around 22% of the scientific publications in
    the last ten years were published in 2018. This reflects that the agricultural
    industry is making considerable progress in the context of the implementation
    of digital technologies, but the pace is still slow as compared to other domains
    such as healthcare, manufacturing, mining, automotive, energy, etc.,[15]. Download
    : Download high-res image (162KB) Download : Download full-size image Fig. 5.
    Year-wise distribution of selected research studies from 2011 to 2021. The breakdown
    of these publications with respect to digital technologies (mentioned in sub-section
    1.2) and targeted farm types is represented in Fig. 6. Download : Download high-res
    image (321KB) Download : Download full-size image Fig. 6. Technology-wise distribution
    of the 148 selected research studies. The farm type refers to the crop farming
    method considered while developing an application or framework. For instance,
    the farming method can be soil-based or soilless. The soil-based farming category
    involves open-air fields (traditional outdoor agricultural farms) and greenhouse
    farms (indoor). On the other hand, the soilless farming category involves modern
    farming practices such as aquaponics, aeroponics, and hydroponics (mostly indoor).
    The numbers at the top of the stacked column in Fig. 6 indicate the total number
    of studies that have used the particular technology to develop a smart agriculture
    system, whereas different colors of columns indicate the respective farm types.
    Use cases are from these publications are analysed, and conclusions are drawn.
    For instance, it is found that autonomous robotics systems (including unmanned
    guided vehicles and unmanned aerial vehicles (drones)), internet of things, and
    machine learning appear to be the widely applied technologies in the agricultural
    domain in the last decade. The same illustration suggests that big data, wireless
    sensor networks, cyber-physical systems, and digital twins are the emerging areas
    in agriculture. Moreover, open-air farms are the most frequently considered in
    research studies (69%), contrary to indoor farms (31%). For soilless farming systems
    (aquaponics, aeroponics, and hydroponics), only 22 publications are found, which
    insinuates that these modern farming practices are still in their infancy. Likewise,
    services of each use case are identified and are classified under nine different
    service categories, namely: i) crop management, CM (Estimation/ prediction of
    crop yield/ growth rate/ harvesting period and seed plantation/ harvesting/ pollination/
    spraying (fertilizer/ pesticide)); ii) crop quality management, CQM (fresh weight,
    green biomass, height, length, width, leaf density, piment content (chlorophyll)
    and phytochemical composition); iii) water and environment management, WEM (monitoring
    and control of flow rate, water level, water quality (nutrients), temperature,
    humidity, CO2, and weather forecast etc.); iv) irrigation management, IM (water
    stress detection and scheduling); v) farm management, FM (monitoring of farm operations,
    tracking and counting products, determining production efficiency, financial analysis,
    energy consumption analysis, technology integration and decisions implementation);
    vi) pest and disease management, PDM (pest identification and disease detection);
    vii) soil management, SM (moisture content, soil nutrients, fertilizer needs and
    application); viii) weed and unwanted vegetation management, WUVM (weed/unknown
    vegetation mapping, classification, and herbicides application); and ix) fruit
    detection and counting, FDC — as shown in Fig. 7. These categories illustrate
    the role of different digital technologies in smart farming. Upon analysis, it
    is found that crop management parameters, such as crop yield prediction, growth
    rate estimation, or evaluation of harvesting period are the most frequently researched
    areas for agriculture 4.0 in the last decade (29%), whereas very little heed is
    paid towards soil management (2%), fruit detection and counting (2%), and crop
    quality management (3%). Download : Download high-res image (561KB) Download :
    Download full-size image Fig. 7. Service-wise distribution of selected research
    studies: The technology readiness level (TRL) of all the use cases is examined
    using European Union''s TRL scale that partitions system''s maturity level into
    three generic levels [21]. The first level is conceptual, that represents European
    TRL 1–2 (use case is in conceptual phase), the second level is the prototype,
    which means European TRL 3–6 (use case is working even without the complete planned
    functionality), and the third level is deployed, that includes European TRL 7–9
    (use case is mature with all the possible functions). Fig. 8 depicts the TRL of
    each use case developed in selected studies. It is observed that little progress
    has been made in advancing smart agricultural systems beyond the concept and prototype
    levels to the commercial level. For instance, most use cases (129) are at the
    prototype level. Download : Download high-res image (269KB) Download : Download
    full-size image Fig. 8. Distribution of studies based on the service category
    and system''s maturity level. 4. Agriculture 4.0 enabling technologies This section
    provides critical insights towards answering RQ1 and RQ2 from Table 1. 4.1. Internet
    of Things driven agricultural systems Internet of things (IoT) refers to a cosmos
    of interrelated computing devices, sensors, appliances, and machines connected
    with the internet, each having unique identities and capabilities for performing
    remote sensing and monitoring [21]. The reference architecture of IoT with six
    layers, namely perception layer (hardware devices), network layer (communication),
    middleware layer (device management and interoperability), service layer (cloud
    computing), application layer (data integration and analytics), and end-user layer
    (user-interface), is shown in Fig.9. In the agricultural domain, IoT devices in
    the physical layer gather data related to environmental and crop parameters such
    as temperature, humidity, pH value, water level, leaf color, fresh leaf weight,
    etc. The transmission of this data takes place in the network layer, the design
    of which depends on the selection of suitable communication technologies relevant
    to the field size, farm location, and type of farming method. For instance, ZigBee,
    LoRa, and Sigfox are widely used and employed in outdoor fields because they are
    cheaper and have low energy consumption and a good transmission range [22,23].
    Despite being a secure technology, Bluetooth is only used in indoor farms as it
    offers a short transmission range [22]. Wi-Fi is not a promising technology for
    agricultural applications due to its high costs and high energy consumption [22].
    RFID (radio frequency identification) and NFC (near field communication) technologies,
    on the other hand, are increasingly being implemented in agricultural systems
    for tracking agricultural products [24]. GPRS or mobile communication technology
    (2G, 3G, and 4G) are used for periodic monitoring of environmental and soil parameters.
    In addition, communication protocols mostly used in the agricultural scenarios
    are HTTP, WWW, and SMTP. Likewise, to ensure interoperability and system security
    to their context-aware functionalities, middleware HYDRA and SMEPP are mostly
    employed in agricultural systems [25]. To store data, cloud computing techniques
    are employed in the service layer. This data is then used in the application layer
    to build smart applications used by farmers, agriculture experts, and supply chain
    professionals to enhance farm monitoring capacity and productivity. Download :
    Download high-res image (871KB) Download : Download full-size image Fig. 9. Six-layered
    architecture of Internet of Things (IoT), (adapted) [26]. The integration of IoT
    in agriculture is meant to empower farmers with the decision tools and automation
    technologies that seamlessly integrate knowledge, products, and services to achieve
    high productivity, quality, and profit. A multitude of studies is performed and
    put forward concerning the incubation of the IoT concepts in the agricultural
    sector. The main findings of some of the studies are presented in Table 2. Multiple
    technological issues and architectural problems have been addressed through the
    development of IoT-based agricultural systems. But most of these systems are either
    in a conceptual stage or in a prototype form (not commercial) at the moment. Focus
    is mainly laid on-farm management, irrigation control, crop growth, health monitoring,
    and disease detection. Some of these studies have also explained IoT implementation
    in modern agricultural systems such as vertical farming (soilless farming - aquaponics,
    hydroponics, and aeroponics) and greenhouse farming (soil-based). Moreover, most
    studies have focused on addressing a specific problem. Table 2. IoT-driven agricultural
    systems. Use case No. Service category Tools and techniques Farm type Maturity
    level Citations 1. CM WSN, CC, and reinforcement learning Greenhouse (soil-based)
    Deployed [27] 2. Sensors, actuators, and controllers Open-air Prototype [28] 3.
    Sensors, controllers, and mobile app Greenhouse (soil-based) Prototype [29] 4.
    Sensors, CC, BD analysis, and ML Greenhouse (soil-based) Prototype [30] 5. Sensors,
    and CC Aeroponics Prototype [31] 6. Sensors, actuators, and control system Aeroponics
    Prototype [32] 7. Weather boxes, sensors, and camera Open-air Prototype [33] 8.
    CQM IoT devices, LED lights, and software application Hydroponics Prototype [34]
    9. WEM Sensors, and CC Aquaponics Conceptual [35] 10. Sensors, Arduino board,
    and database Open-air Prototype [36] 11. Sensors, Arduino board, and database
    Greenhouse (soil-based) Prototype [37] 12. Sensors, CPS, edge, and cloud computing
    Hydroponics Prototype [38] 13. Sensors, electronic components, and network Aquaponics
    Prototype [39] 14. Sensors, Arduino, Raspberry Pi3, and deep neural network Hydroponics
    Prototype [40] 15. Sensors, and database Aquaponics Prototype [41] 16. Sensors,
    actuators, and CC Aquaponics Prototype [42] 17. Sensors, controllers, and mobile
    app Aquaponics Prototype [43] 18. IM WSN, fuzzy logic and neural network Open-air
    Prototype [44] 19. Sensor information unit, MQTT, HTTP, and neural network Greenhouse
    (soil-based) Prototype [45] 20. FM Sensors, controllers, web interface, and CC
    Open-air Conceptual [46] 21. Sensors, controllers, cloud, and Android application
    Open-air Prototype [47] 22. Sensors, IEEE, and GSM protocols Open-air Prototype
    [48] 23. PDM Sensors, controllers, and image processing Open-air Prototype [49]
    24. Cloud, camera, controllers, and K-mean clustering Open-air Prototype [50]
    25. WSN, controller, and cloud Open-air Prototype [51] 26. WSN, cloud storage,
    and agricultural knowledge base Open-air Prototype [52] 27. WSN, Hidden Markov
    Model, and SMS module Open-air Deployed [53] 28. Sensors, Image processing, k-mean
    clustering, and support vector machine Open-air Prototype [54] 4.2. Wireless sensor
    networks in agriculture Wireless sensor network (WSN) is regarded as a technology
    that is used within an IoT system. It can be defined as a group of spatially distributed
    sensors for monitoring the physical conditions of the environment, temporarily
    storing the collected data, and transmitting the gathered information at a central
    location [22]. The general architecture of WSN is shown in Fig. 10. A WSN for
    smart farming is made up of numerous sensor nodes connected through a wireless
    connection module. These nodes have a variety of abilities (e.g., processing,
    transmission, and sensation) that allow them to self-organize, self-configure,
    and self-diagnose. There are different types of WSNs, which are categorized depending
    on the environment where they are deployed. These include terrestrial wireless
    sensor networks (TWSNs), wireless underground sensor networks (WUSNs), underwater
    wireless sensor networks (UWSNs), wireless multimedia sensor networks (WMSNs),
    and mobile wireless sensor networks (MWSNs) [55]. In agricultural applications,
    TWSN and UWSN are widely used. In TWSNs, the nodes are deployed above the ground
    surface, consisting of sensors for gathering the surrounding data. The second
    variant of WSNs is its underground counterpart – WUSNs, where sensor nodes are
    planted inside the soil. In this setting, lower frequencies easily penetrate through
    the soil, whereas higher frequencies suffer severe attenuation [56]. Therefore,
    the network requires a higher number of nodes to cover a large area because of
    the limited communication radius. Many research articles are available in the
    literature that discusses the use of WSN for different outdoor and indoor farms’
    applications such as irrigation management, water quality assessment, and environmental
    monitoring. A summary of some of these articles is given in Table 3. These studies
    have focused on developing WSNs architectures that are simplified, low cost, energy-efficient
    and scalable. Yet, various factors associated with WSNs need further attention,
    such as minimum maintenance, robust and fault-tolerant architecture, and interoperability.
    Download : Download high-res image (135KB) Download : Download full-size image
    Fig. 10. General architecture wireless sensor network (WSN). Table 3. Use of WSNs
    in agricultural systems. Use case No. Service category Tools and techniques used
    Farm type Maturity level Citation 29. IM Soil-moisture and temperature sensors,
    web application, and photovoltaic panels Open-air Prototype [57] 30. Electronic
    board, sensor board and GPRS board. Open-air Prototype [58] 31. Wireless sensor
    nodes, and Zigbee Open-air Conceptual [59] 32. Moisture sensors, actuators, and
    GUI Greenhouse (soil-based) Prototype [60] 33. WEM Wireless communication, temperature,
    and humidity sensors Greenhouse (soil-based) Prototype [61] 34. Sensor nodes,
    gateway unit, database, ordinary kriging spatial interpolation (OKSI) algorithm
    Hydroponics Prototype [62] 35. Microcontrollers, wireless radio frequency and
    sensor nodes Greenhouse (soil-based) Prototype [63] 36. Wireless sensor nodes,
    communication network, and mobile application Aquaponics Prototype [64] 37. Arduino,
    wireless module with temperature, relative humidity, luminosity, and air pressure
    sensors Any farm Prototype [65] 38. Zigbee, Wi-fi and sensors Hydroponics Prototype
    [66] 4.3. Cloud computing in agriculture According to the National Institute of
    Standard and Technologies (NIST), cloud computing (CC) is defined as a model for
    enabling ubiquitous, convenient, on-demand network access to a shared pool of
    configurable computing resources (e.g., networks, servers, storage, applications,
    and services) that can be rapidly provisioned and released with minimal management
    effort or service provider interaction [67]. The main architecture of CC shown
    in Fig. 11 is comprised of four layers: datacenter (hardware), infrastructure,
    platform, and application [68]. Each of these layers is linked with specific cloud
    service models, which are classified as software as a service (SaaS), platform
    as a service (PaaS), and infrastructure as a service (IaaS). Cloud computing has
    gained great attention over the past decade in the agriculture sector because
    it provides: 1) inexpensive storage services for data gathered from different
    domains through WSNs and other preconfigured IoT devices, 2) large-scale computing
    systems to perform intelligent decision-making by transforming this raw data into
    useful knowledge, and 3) a secure platform to develop agricultural IoT applications
    [69]. In combination with IoT and WSN, CC is employed to develop different agricultural
    applications, most of which are presented in Tables 2 and 3. CC technology is
    also used to create operational farm management systems (FMSs) to support farmers
    and farm managers in efficient monitoring of farm operations Table 4. presents
    the salient features of some of these FMSs. Another topic of interest that is
    being explored in global research is related to the traceability of agri-product
    quality [70]. But only preliminary research has been attempted to explore traceability
    compliance with standards of food safety and quality. Download : Download high-res
    image (362KB) Download : Download full-size image Fig. 11. Architecture of cloud
    computing, adapted from [68]. Table 4. Cloud computing-based farm management systems.
    Use case No. Service category Tools used Farm type Maturity level Citation 39.
    FM Fuzzy logic, Java, HTML, Apache Karaf, etc.; Greenhouse (soil-based) Conceptual
    [71] 40. RFID, and mobile app Open-air Deployed [72] 41. MySQL, financial analysis
    tool and mobile app Open-air Conceptual [73] 42. Self-leveling scale, control
    box, LCD display, and RFID tags Open-air Conceptual [74] The cloud-based agricultural
    systems have the potential to solve problems of increasing food demands, environmental
    pollution caused by excessive use of pesticides and fertilizers, and the safety
    of agricultural products. These FMSs, however, do not have the capability to support
    run-time customization in relation to distinct requirements of farmers. Moreover,
    because most farm data is usually fragmented and dispersed, it is difficult to
    record farm activities properly in current FMSs applications [75]. 4.4. Edge/fog
    computing in agriculture The rapid development of IoT has led to the explosive
    growth of sensors and smart devices, generating large volumes of data. The processing
    and analysis of such an enormous amount of data in real-time are challenging because
    it increases the load on the cloud server and also reduces the response speed.
    Simply using a cloud server is not able to provide real-time response while handling
    such a large data set. Additionally, IoT applications are sensitive to network
    latency because they require a constant exchange of information between devices
    and the cloud, making CC unfeasible to handle these applications [23]. The emergence
    of the edge computing concept can resolve the problems associated with CC. This
    new computing model deploys computing and storage resources (such as cloudlets
    or fog nodes) at the edge of the network closer to data sources such as mobile
    devices or sensors. This way, it can facilitate real-time analytics while keeping
    data secure on the device [23]. Edge computing offers intriguing possibilities
    for smart agriculture, but the applications of this technology are only in their
    infancy in agricultural systems. Hence, few research studies are available in
    this area; see Table 5. Most of the edge computing-based agricultural systems
    discussed in these studies are prototypical and address a limited selection of
    problems in various agricultural domains. So far, interoperability and scalability
    issues have not received sufficient consideration. Table 5. Edge computing-based
    agricultural systems. Use case No. Service category Edge computing techniques
    used Farm type Maturity level Citation 43. FM Computation offloading Aeroponics
    Prototype [76] 44. Computation offloading (automated control) Hydroponics Prototype
    [77] 45. Computation offloading (alert generation) Any farm Prototype [78] 46.
    PDM Computation offloading Open-air Prototype [79] 47. WEM Latency reduction Any
    farm Prototype [80] 48. Computation offloading Aquaponics Prototype [81] 49. SM
    Computation offloading (data analysis) Open-air Prototype [82] 4.5. Autonomous
    robot systems in agriculture Autonomous robot systems (ARS) are intelligent machines
    capable of performing tasks, making decisions, and acting in real-time, with a
    high degree of autonomy (without external influence or without explicit human
    intervention) [83]. Interest in agricultural ARS (AARS) has grown significantly
    in recent years because of their ability to automate some practices in outdoor
    and indoor farms - including seeding, watering, fertilizing, spraying, plant monitoring
    and phenotyping, environmental monitoring, disease detection, weed and pest controlling,
    and harvesting [15]. The agricultural robots use a combination of emerging technologies
    such as computer vision, WSNs, satellite navigation systems (GPS), AI, CC, and
    IoT, thereby facilitating the farmers to enhance productivity and quality of agricultural
    products. AARS in smart farming can be mobile AARS, which can move throughout
    the working field, or fixed AARS [84]. Mobile AARSs are further classified into
    unmanned ground vehicles (UGVs) and 2) unnamed aerial vehicles (UAVs), which are
    explained in the following sections. 4.5.1. Unmanned ground vehicles in agriculture
    Unmanned ground vehicles (UGVs) are agricultural robots that operate on the ground
    without a human operator. The main components of UGVs generally include; a platform
    for locomotive apparatus and manipulator, sensors for navigation, a supervisory
    control system, an interface for the control system, the communication links for
    information exchange between devices, and a system architecture for integration
    between hardware and software agents [85]. The control architecture of UGV can
    be remote-operated (controlled by a human operator via the interface) or fully
    autonomous (operated without the need for a human controller based on artificial
    intelligence technologies) [85]. Likewise, locomotive systems can be based on
    wheels, tracks, or legs [85]. Despite high ground adaptability, intrinsic omnidirectionality
    and soil protection of legged robots, they are uncommon in agriculture. However,
    when combined with wheels (wheel-legged robots), these robots offer a disruptive
    locomotion system for smart farms. In addition to their needed characteristics
    for infield operations, UGV should fulfill certain requirements such as small
    size, maneuverability, resilience, efficiency, human-friendly interface, and safety
    – to enhance crop yields and farm productivity. Table 6 summarizes the diverse
    range of UGVs designed for agricultural operations. Table 6. Different types of
    UGVs designed for performing agricultural tasks. Use case No. Service category
    Primary function Tools and techniques used Locomotion system Farm type Maturity
    level Citation 50. WUVM Weed control Modules (Vision, spray, mechanical weeding),
    and classification algorithms Four-wheel-steering system (4WS). Open-air Prototype
    [86] 51. Vision system with Kinect v2 sensor, and random sample consensus algorithm
    Four-wheel-drive (4WD) Open-air Prototype [87] 52. PDM Pesticides spraying RGB
    camera, HMI, and LiDAR Four-wheel-drive (4WD) Open-air Prototype [88] 53. RGB
    camera, and laser Four-wheel-drive (4WD) Open-air Prototype [89] 54. Crop treatment
    Hyperspectral cameras, thermal and infrared detecting systems. Four-wheel steering
    system (4WS) Open-air Prototype [90] 55. CM Seed sowing Ultrasonic sensor, and
    PI controller Caterpillar treads Open-air Prototype [91] 56. Ultrasonic sensor,
    GSM module and actuators. Four-wheel-drive (4WD) Open-air Prototype [92] 57. Artificial
    pollination Sensing module, pollinator system, RGB camera and odometry. Four-wheel-drive
    (4WD) Open-air Prototype [93] 58. Harvesting RGB-D camera and RCNN Four-wheel-steering
    system (4WS). Open-air Prototype [94] 59. RGB camera and RCNN Four-wheel-drive
    (4WD). Open-air Prototype [95] Most of the agricultural robotic systems presented
    above have a 4WD locomotive system because it offers ease of construction and
    control. The drawback of 4WD is that the wheels are strongly affected by terrains
    containing stone elements and/or cavities [85]. Hence, it is significant to explore
    other mechanisms, such as legged or wheel-legged locomotive systems. Some robots
    have computer vision systems, but due to the difficulty of developing an accurate
    and reliable system that replaces manual labor, most of these robots are built
    with a low-cost computer vision system, that is, using conventional RGB cameras.
    Moreover, most of the systems mentioned above are still in the research phase,
    with no commercial use on a large scale. 4.5.2. Unmanned aerial vehicles in agriculture
    Unmanned aerial vehicles (UAVs) or aerial robots are aircrafts with no human pilot
    on board. Depending on the type of technology incorporated to fly (wing structure)
    and autonomy level, there is a wide variety of UAVs [96]. For instance, according
    to wing type, UAVs can be fixed-wing (planes), single-rotor (helicopter), hybrid
    system (vertical takeoff and landing), and multirotor (drone). Among these, drones
    (multi-rotor technology) which are lifted and propelled by four (quadrotor) or
    six (hex-rotor) rotors, have become increasingly popular in the agriculture sector
    due to their mechanical simplicity in comparison to helicopters, which rely on
    a much more sophisticated plate control mechanism [97]. Similarly, according to
    autonomy level, UAVs can be either teleoperated in which the pilot provides references
    to each actuator of the aircraft so as to control it, in the same manner, an onboard
    pilot would, or tele-commanded in which the aircraft relies on an automatic controller
    on board that is in charge of maintaining a stable flight [96]. Equipped with
    the appropriate sensors (vision, infrared, multispectral, and hyperspectral cameras,
    etc.), agricultural UAVs allow farmers to obtain data (vegetation, leaf area,
    and reflectance indexes) from their fields to study dynamic changes in crops that
    cannot be detected by scouting the ground [98]. This data permits farmers to infer
    information related to crop diseases, nutrient deficiencies, water level, and
    other crop growth parameters. With this information, farmers can plan possible
    remedies (irrigation, fertilization, weed control, etc.). Table 7 reviews some
    of the UAV-based systems used for different agricultural operations. Table 7.
    Different UAV based systems developed for performing different agricultural operations.
    Use case No. Service category Primary function UAV type Cameras/ sensors Flight
    altitude (m) Farm type Maturity level Citation 60. CQM Vegetation monitoring Hexacopter
    Hyper-spectral camera 30 Open-air Prototype [99] 61. Biomass monitoring Octocopter
    RGB-sensor 50 Open-air Prototype [100] 62. CM Real-time growth monitoring Quadcopter
    Digital camera 100 Open-air Prototype [101] 63. Photosynthetic active radiation
    mapping Fixed wing Multi-spectral camera 150 Open-air Prototype [102] 64. Remote
    sensing Helicopter Multi-spectral camera 15-70 Open-air Prototype [103] 65. Remote
    sensing and mapping RC plane Digital camera 100-400 Open-air Prototype [104] 66.
    Rice pollination Helicopter Wind speed sensor 1.15, 1.23, 1.33 Open-air Prototype
    [18] 67. Droplet distribution estimation Quadcopter Digital canopy imager 3.5,
    4, 4.5 Open-air Prototype [105] 68. UREA spraying Quadcopter Multi and hyper spectral
    cameras Few meters Open-air Prototype [106] 69. Pesticide spraying Quadcopter
    RF module 5, 10, 20 Open-air Prototype [107] 70. Pesticide spray application Helicopter
    Digital camera 3-4 Open-air Prototype [108] 71. Automatic spray control system
    Helicopter Image transmitter 5, 7, 9 Open-air Prototype [109] 72. WUVM Multi-temporal
    mapping of weed Quadcopter Digital camera 30, 60 Open-air Prototype [110] 73.
    Weed mapping and control Digital camera 30 Open-air Prototype [111] 74. IM Water
    status assessment Fixed wing Multi-spectral camera 200 Open-air Prototype [112]
    75. Water stress detection Fixed wing Micro-hyper spectral camera 575 Open-air
    Prototype [113] 76. Water stress investigation Fixed wing Digital camera 90 Open-air
    Prototype [114] 77. Assessing the effects of saline reclaimed waters and deficit
    irrigation on Citrus physiology Fixed wing Digital camera 100 Open-air Prototype
    [115] 78. Water status and irrigation assessment Quadcopter Multi-spectral camera
    30 Open-air Prototype [116] 79. PDM Phylloxera disease detection Hexacopter RGB
    and multi-spectral cameras 60, 100 Open-air Prototype [117] 80. Citrus greening
    disease detection Hexacopter Multi-spectral camera 100 Open-air Prototype [118]
    Most of the systems mentioned above are still in the research phase, with no commercial
    use on a large scale. Other problems with these UAVs are associated with battery
    and flight time [96]. At the moment, lithium-ion batteries are being used because
    their capacity is larger than that of conventional batteries. But an increase
    in battery capacity increases the drone weight, and now research is undergoing
    to address this issue. In addition, the existing UAVs have complex user interfaces,
    and only experts can use them to perform agricultural tasks. By improving the
    user interface making it human-centered with multimodal feedback will allow people
    who are older or unfamiliar with UAV technology to control it more easily. 4.6.
    Big data and analytics in agriculture Rapid developments in IoT and CC technologies
    have increased the magnitude of data immeasurably. This data, also referred to
    as Big Data (BD), includes textual content (i.e., structured, semi-structured,
    and unstructured), and multimedia content (e.g., videos, images, audio) [119].
    The process of examining this data to uncover hidden patterns, unknown correlations,
    market trends, customer preferences, and other useful information is referred
    to as big data analytics (BDA). Big data is typically characterized according
    to five dimensions defined by five Vs, which are displayed in Fig. 12 [120]. The
    paradigm of BD-driven smart agriculture is comparatively new, but the trend of
    this application is positive as it has the capacity to bring a revolutionary change
    in the food supply chain and food security through increased production. Agricultural
    big data is usually generated from various sectors and stages in agriculture,
    which can be collected either from agricultural fields through ground sensors,
    aerial vehicles, and ground vehicles using special cameras and sensors; from governmental
    bodies in the form of reports and regulations; from private organizations through
    online web services; from farmers in the form of knowledge through surveys; or
    from social media [120]. The data can be environmental (weather, climate, moisture
    level, etc.), biological (plant disease), or geo-spatial depending on the agricultural
    domain and differs in volume, velocity, and formats [121]. The gathered data is
    stored in a computer database and processed by computer algorithms for analyzing
    seed characteristics, weather patterns, soil properties (like pH or nutrient content),
    marketing and trade management, consumers’ behavior, and inventory management.
    A variety of techniques and tools are employed to analyze big data in agriculture.
    A summary of some of the studies is given in Table 8. Machine learning, cloud-based
    platforms, and modeling and simulation are the most commonly used techniques.
    Particularly, machine learning tools are used in prediction, clustering, and classification
    problems. Whereas cloud platforms are used for large-scale data storing, preprocessing,
    and visualization. There are still many potential areas that are not adequately
    covered in existing literature, where BDA can be applied to address various agricultural
    issues. For instance, these include data-intensive greenhouses and indoor vertical
    farming systems, quality control and health monitoring of crops in outdoor and
    indoor farms, genetic engineering, decision support platforms to assist farmers
    in the design of indoor vertical farms, and scientific models for policymakers
    to assist them in decision-making regarding the sustainability of the physical
    ecosystem. Lastly, most systems are still in the prototypical stage. Download
    : Download high-res image (437KB) Download : Download full-size image Fig. 12.
    Five dimensions of “Big Data”. Table 8. Big data tools and services in agriculture.
    Use case No. Service category Tools and techniques used Big data source Farm type
    Maturity level Citation 81. WEM Crop modelling and simulation, geospatial analysis
    Weather station, historical databases Open-air Conceptual [121] 82. CM Clustering,
    prediction, and classification Sensor, historical, and farmer data Open-air Conceptual
    [122] 83. Support vector machine Sensor data Open-air Conceptual [123] 84. IM
    Cloud-based application. Sensor data Hydroponics Prototype [124] 85. Cloud-based
    platform, and web services Sensor data, industry standards Open-air Conceptual
    [125] 4.7. Artificial intelligence in agriculture Artificial intelligence (AI)
    involves the development of theory and computer systems capable of performing
    tasks requiring human intelligence, such as sensorial perception and decision-making
    [126]. Combined with CC, IoT, and big data, AI, particularly in the facet of machine
    learning (ML) and deep learning (DL), is regarded as one of the key drivers behind
    the digitization of agriculture. These technologies have the potential to enhance
    crop production and improve real-time monitoring, harvesting, processing, and
    marketing [127]. Several intelligent agricultural systems are developed that use
    ML and DL algorithms to determine various parameters like weed detection, yield
    prediction, or disease identification. These systems are discussed in the next
    two sub-sections. 4.7.1. Machine learning in agriculture Machine learning (ML)
    techniques are broadly classified into three categories: 1) supervised learning
    (linear regression, regression trees, non-linear regression, Bayesian linear regression,
    polynomial regression, and support vector regression), 2) unsupervised learning
    (k-means clustering, hierarchal clustering, anomaly detection, neural networks
    (NN), principal component analysis, independent component analysis, a-priori algorithm
    and singular value decomposition (SVD)); and 3) reinforcement learning (Markov
    decision process (MDP) and Q learning) [128]. ML techniques and algorithms are
    implemented in the agriculture sector for crop yield prediction, disease, and
    weed detection, weather prediction (rainfall), soil properties estimation (type,
    moisture content, pH, temperature, etc.), water management, determination of the
    optimal amount of fertilizer, and livestock production and management [129] Table
    9. presents a list of publications where different ML algorithms are utilized
    for various agricultural applications. From the analysis of these articles, “crop
    yield prediction” is a widely explored area, and linear regression, neural network
    (NN), random forest (RF), and support vector machine (SVM) is the most used ML
    techniques to enable smart farming. The presented use cases are still in the research
    phase with no reported commercial usage at the moment. Moreover, it is also found
    that AI and ML techniques are sparsely explored in the greenhouse and indoor vertical
    farming systems, particularly hydroponics, aquaponics, and aeroponics. There are
    only a few publications available summarized in the same table where ML techniques
    are employed. Considering the digital transformation''s cyber-security and data
    privacy challenges, new approaches such as federated learning and privacy-preserving
    methods are being developed to enable digital farming [130]. These approaches
    build ML models from local parameters without sharing private data samples, thus
    mitigating security issues. Table 9. Machine learning-based agricultural systems.
    Use case No. Service category Data sources Algorithms used Farm type Maturity
    level Citation 86. CM Yield maps, climate, and temporal data. SVM with radial
    basis functions Open-air Prototype [131] 87. Vegetation dataset from Landsat 8
    OLI. Boosted regression tree, RF regression, support vector regression, and Gaussian
    process regression Open-air Prototype [132] 88. Historical soil and rainfall data
    Recurrent neural network Open-air Prototype [133] 89. Plot-scale wheat data Multiple
    linear regression and RF Open-air Prototype [134] 90. Temperature and rainfall
    records Artificial neural network Open-air Prototype [135] 91. Soil data, and
    satellite imagery Counter-propagation artificial neural networks Open-air Prototype
    [136] 92. Rainfall records RF Open-air Prototype [137] 93. Field survey data of
    64 farms SVM, RF, decision tree Open-air Prototype [138] 94. Tap water samples
    RF Hydroponics Prototype [139] 95. PDM Images from a strawberry greenhouse SVM
    Greenhouse (soil-based) Prototype [140] 96. Sensor data Least squares SVM Open-air
    Prototype [141] 97. Sensor data Decision trees Aquaponics Prototype [142] 98.
    WUVM Image data RF Open-air Prototype [143] 99. Images from a university farm.
    SVM Open-air Prototype [144] 100. SM 140 soil samples from top layer Least squares
    support vector machines Open-air Prototype [145] 101. Humidity data from Radarsat-2
    Extreme learning machine-based regression Open-air Prototype [146] 102. WEM Rainfall
    data Bayesian linear regression, boosted decision tree and decision forest regression,
    neural network regression Open-air Prototype [147] 103. Air temperature, wind
    speed, and solar radiation data Artificial neural network and SVM Greenhouse (soil-based)
    Prototype [148] 4.7.2. Deep learning in agriculture Deep learning (DL) represents
    the extension of classical ML that can solve complex problems (predictions and
    classification) particularly well and fast because more “depth” (complexity) is
    added into the model. The primary advantage of DL is feature learning which involves
    automatic extraction of features (high-level information) from large datasets
    [149]. Different DL algorithms are convolutional neural networks (CNNs), long
    short term memory (LSTM) networks, recurrent neural (RNN) networks, generative
    adversarial networks (GANs), radial basis function networks (RBFNs), multilayer
    perceptron (MLPs), feedforward artificial neural network (ANN), self-organizing
    maps (SOMs), deep belief networks (DBNs), restricted Boltzmann machines (RBMs),
    and autoencoders. A detailed description of these algorithms, popular architectures,
    and training platforms is available at various sources [150]. Fig. 13 illustrates
    an example of DL architecture of CNN [151]. In the agriculture sector, DL algorithms
    are mostly used to solve problems associated with computer vision applications
    that target the prediction of key parameters, such as crop yields, soil moisture
    content, weather conditions, and crop growth conditions; the detection of diseases,
    pests, and weed; and the identification of leaf or plant species [152]. Computer
    vision is an interdisciplinary field that has been gaining huge amounts of traction
    in recent years due to the surge in CNNs. It offers methods and techniques that
    allow the processing of digital images accurately and enables computers to interpret
    and understand the visual world [153]. A summary of agricultural applications
    using DL and computer vision techniques is given in Table 10. Among all the DL
    algorithms, CNNs or Convet and its variants are the most used algorithms in agricultural
    applications. The variants of CNN are region-based CNNs (RCNN), Fast-RCNN, Faster-RCNN,
    YOLO, and Mask-RCNN, among which the first four are mostly used to solve object
    detection problems. Mask-RCNN, on the other hand, is used to solve instance segmentation
    problems. The reader could refer to the existing bibliography for a detailed description
    of these algorithms and their applications [152]. Few studies have also used other
    DL techniques. Talking about datasets, most DL models are trained using images,
    and few models are trained using sensor data gathered from fields. This shows
    that DL can be applied to a wide variety of datasets. It is also observed that
    most of the work is done on outdoor farms, whereas next-generation farms (environment-controlled)
    are not extensively explored. Though DL has the potential to enable digital farming,
    most systems are still in the prototype phase. Additionally, the new challenges
    imposed by cyber-security and privacy issues require optimization of current DL
    and computer vision approaches. Download : Download high-res image (334KB) Download
    : Download full-size image Fig. 13. Example of CNN architecture. Table 10. Deep
    learning-based agricultural systems. Use case No. Service category Data sources
    Algorithms used Farm type Maturity level Citation 104. CM Satellite and weather
    data LSTM network Open-air Prototype [154] 105. Rice yield data, meteorology,
    and area data (81 counties). Back-Propagation neural networks and RNN Open-air
    Prototype [155] 106. Commercial fields’ images CNN Open-air Prototype [156] 107.
    Aerial orthoimages Faster RCNN Open-air Prototype [157] 108. Historical yields
    and greenhouse environmental parameters. Temporal CNN and RNN. Greenhouse (soil-based)
    Prototype [158] 109. Lettuce images from farm. CNN Greenhouse (soil-based) Prototype
    [159] 110. WEM Soil moisture data, and daily meteorological data RBMs Open-air
    Prototype [160] 111. CQM Images from the farm and Google search engine Mask-RCNN
    Aquaponics Prototype [161] 112. WUVM Weed and crop species images from 6 different
    datasets. CNN Open-air Prototype [162] 113. PDM Images collected from Internet.
    CNN Open-air Prototype [163] 114. Public dataset Deep CNN Open-air Prototype [164]
    115. Images from camera. Faster R-CNN, and single shot multibox detector Open-air
    Prototype [165] 116. Dataset with images of Walnut leaves CNN Open-air Prototype
    [166] 117. FDC RGB and multi-modal images Faster R-CNN Open-air Prototype [167]
    118. Images of oranges and green apples CNN Open-air Prototype [168] 119. Images
    of ripe young and expanding apples. YOLO-V3 Open-air Prototype [169] 4.8. Agricultural
    decision support systems A decision support system (DSS) can be defined as a smart
    system that supports decision-making to specific demands and problems by providing
    operational answers to stakeholders and potential users based on useful information
    extracted from raw data, documents, personal knowledge, and/or models [170]. DSS
    can be data-driven, model-driven, communication-driven, document-driven, and knowledge-driven.
    The salient features of these DSSs are available at following source [171]. Fig.
    14 presents the general architecture of a DSS, consisting of four fundamental
    components, each having its specific purpose. Download : Download high-res image
    (214KB) Download : Download full-size image Fig. 14. The general architecture
    of decision support system. Download : Download high-res image (400KB) Download
    : Download full-size image Fig. 15. 5C architecture for cyber-physical systems,
    (adapted) [187]. Due to the evolution of agriculture 4.0, the amount of farming
    data has increased immensely. To transfer this heterogenous data into practical
    knowledge, platforms like agricultural decision support systems (ADSS) are required
    to make evidence-based and precise decisions regarding farm operation and facility
    layout [172]. Over the past few years, ADSSs are gaining much attention in the
    agriculture sector. A number of ADSSs have been developed that focus on a variety
    of agricultural aspects, such as farm management, water management, and environmental
    management. Table 11 presents a summary of the ADSSs found in the literature.
    From this analysis, most ADSSs have been found to not consider expert knowledge,
    which is highly valuable as it allows to development of systems as per user''s
    needs. The other reported issues with some of these ADDSs are complex GUIs, inadequate
    re-planning components, a lack of prediction and forecast abilities, and a lack
    of ability to adapt to uncertain and dynamic factors. It is also worth noting
    that all the ADSSs are for outdoor agricultural systems and are in the research
    phase. In comparison, the application of ADSS in indoor soilless farming is still
    very much unexploited. Table 11. Agricultural decision support systems. Use case
    No. Service category Data sources Tools and techniques used Maturity level Farm
    type Citation 120. IM Environmental and crop data Partial least squares regression
    and adaptive neuro fuzzy inference system Prototype Open-air [173] 121. Crop and
    site data Fuzzy C-means algorithm Prototype Open-air [174] 122. WEM Meteorological
    and crop data Geographical information system (GIS) Prototype Open-air [175] 123.
    Environmental, economic, and crop data VEGPER, ONTO, SVAT-CN, EROSION, GLPROD
    Prototype Open-air [176] 124. FM Environmental and crop-related data B-patterns
    optimization algorithm Prototype Open-air [177] 125. Environmental and crop data
    Agent-based modeling, SVM and decision trees Prototype Aquaponics [178] 126. Environmental
    and crop data Object-oriented methodology Prototype Greenhouse (soil-based) [179]
    127. PDM Crop data Excel based algorithm Prototype Greenhouse (soil-based) [180]
    128. Environmental data Rule-based approach Conceptual Greenhouse (soil-based)
    [181] 129. Environmental data Rule-based approach Prototype Greenhouse (soil-based)
    [182] 130. WUVM 10 years weather data and a set of vegetation index. Rule-based
    application Prototype Open-air [183] 4.9. Agricultural cyber-physical systems
    As one of the main technologies of Industry 4.0, a cyber-physical system (CPS)
    refers to an automated distributed system that integrates physical processes with
    communication networks and computing infrastructures [184]. There are three standard
    CPS reference architecture models: namely, 5C, RAMI 4.0, and IIRA, and their detailed
    description is available at following source [185]. Among these, the 5C is a well-known
    reference model with widespread usage. The architecture of 5C consists of five
    levels which are represented in Fig. 15. CPS benefits from a variety of existing
    technologies such as agent systems, IoT, CC, augmented reality, big data, and
    ML [186]. Its implementation ensures scalability, adaptability, autonomy, reliability,
    resilience, safety, and security improvements. Download : Download high-res image
    (461KB) Download : Download full-size image Fig. 16. Schematic of a digital twinning
    process, (adapted) [199]. Agricultural field is regarded as one of the complex
    domains that can benefit from CPS technology. Agricultural cyber-physical systems
    (ACPSs) use advanced electronic technologies and agricultural facilities to build
    integrated farm management systems that interact with the physical environment
    to maintain an optimal growth environment for crops [188]. ACPSs collect the essential
    and appropriate data about climate, soil, and crops, with high accuracy and use
    it to manage watering, humidity, and plant health, etc. A variety of ACPSs has
    been developed for the management of different services, and their summary is
    given in Table 12. Looking at these ACPSs, most systems are still at the prototype
    and conceptual level. Moreover, most studies are conducted for outdoor farms,
    with only a few works published related to soil-based greenhouse systems. No study
    is found that is relevant to indoor soilless farming systems. ACPSs has attracted
    significant research interest because of their promising applications across different
    domains; deploying CPS models in real-life applications is still a challenge as
    it requires proper hardware and software [189]. Moreover, particular attention
    should be given to autonomy, robustness, and resilience while engineering ACPSs
    in order to handle the unpredictability of the environment and the uncertainty
    of the characteristics of agricultural facilities. There are multiple factors
    (humans, sensors, robots, crops, and data, among others) that impact ACPSs. To
    ensure a smooth operation while avoiding conflicts, errors, and disruptions, ACPSs
    need to be designed carefully and comprehensively. Table 12. Agricultural cyber-physical
    systems. Use case No. Service category Tools and techniques used Maturity level
    Farm type Citation 131. IM Integrated open geospatial web service Prototype Open-air
    [190] 132. Moisture sensors, and solenoid valves Prototype Greenhouse (soil-based)
    [191] 133. Sensor and sink nodes, network, and control centre Prototype Greenhouse
    (soil-based) [188] 134. Transceiver modules, multi-sensor array and weather forecasting
    system Prototype Open-air [186] 135. PDM ToxTrac and NS2 simulator Conceptual
    Open-air [192] 136. Sensors and cameras Prototype Greenhouse (soil-based) [193]
    137. Unmanned aircraft system Conceptual Open-air [194] 138. CM Multispectral
    terrestrial mobile and autonomous aerial mobile mechatronic systems, and GIS Conceptual
    Open-air [195] 139. Edge and cloud computing Prototype Open-air [196] 140. Sensors,
    actuators, Arduino, and Raspberry Pi Prototype Any farm [197] 4.10. Digital twins
    in agriculture Digital twin (DT) is a dynamic virtual replica of a real-life (physical)
    object of which it mirrors its behaviors and states over multiple stages of object''s
    lifecycle by using real-world data, simulation, and machine learning models, combined
    with data analytics to enable understanding, learning, and reasoning [198]. A
    complete description of the DT concept for any physical system requires consolidation
    and formalization of various characteristics, including the physical and virtual
    entities, the physical and virtual environments, the metrology, and realization
    modules that perform the physical to virtual and the virtual to physical connection
    or twinning, the twinning and twinning rate, and the physical and virtual processes
    [199]. The schematic showing the mapping of these characteristics is shown in
    Fig. 16. The DT concept has gained prominence due to the advances in the technologies
    such as the Internet of Things, big data, wireless sensor networks, and cloud
    computing. This is because these technologies allow real-time monitoring of physical
    twins at high spatial resolutions through both miniature devices and remote sensing
    that produce ever-increasing data streams [21]. The concept of DT in agricultural
    applications is rather immature as compared to other disciplines with its first
    references occurred in 2017; hence its added value has not yet been discussed
    extensively [21]. This is because framing is a highly complex and dynamic domain
    because of its dependence on natural conditions (climate, soil, humidity) and
    presence of living physical twins (plants and animals) and non-living physical
    twins (indoor farm buildings, grow beds, outdoor agricultural fields, agricultural
    machinery). The non-living physical twins interact directly or indirectly with
    plants and animals (living physical twins), thereby introducing more challenges
    for DT in agriculture. Whereas in other domains such as manufacturing DTs are
    mostly concerned with non-living physical twins. Table 13 summarises the agricultural
    DTs developed in the last 10 years. Table 13. Digital twins in agriculture Use
    case No. Service category Physical twin Tools and techniques used Maturity level
    Farm type Citation 141. WEM Aquaponics system and building IoT sensor system,
    and MQQT broker Prototype Aquaponics [200] 142. CM Agricultural product Sensor,
    network, and computational units Prototype Open-air [201] 143. FM Agricultural
    machinery ROS platform, Gazebo 3D and Open Street Maps Prototype Open-air [202]
    144. Farmland Sensor, network, and computational units Prototype Open-air [203]
    145. Agricultural farm/landscape Sensors, and PLCs Conceptual Open-air [204] 146.
    Agricultural building Sensors, GUI, and control centre Prototype Greenhouse (soil-based)
    [205] 147. PDM Crops (plants)/ Trees Mobile application and computational unit
    Deployed Open-air [206] 148. Trees planted on orchard IoT sensors, network, and
    computational units Prototype Open-air [207] The analysis shows that most studies
    have focused on open-air farming systems. Only one study is found that has proposed
    DT for soil-based vertical farming system and one study that implemented DT for
    soilless farming system (aquaponics). This might be because the design and management
    of modern farming systems are challenging. Moreover, most DTs are in the research
    phase with no commercial deployment at the moment. The reported benefits of the
    DT applications in agriculture are cost reductions, catastrophe prevention, clearer
    decision making, and efficient management operations, which can be applied to
    several agricultural subfields like plant and animal breeding, aquaponics, vertical
    farming, cropping systems, and livestock farming. While DT technology has great
    potential, achieving the synchronization between the physical entity and its digital
    counterpart is challenging. The complexity of this process is further amplified
    in agricultural systems due to the idiosyncrasies of living physical twins. Hence,
    implementation of agricultural DT should start with micro-farms, which can then
    be gradually enhanced to an intelligent and autonomous version by incorporating
    more components. 4.11. Roadblocks in digitization of agriculture industry This
    section provides an answer to RQ3 by listing a series of interconnected roadblocks
    hampering a larger adoption of digital technologies in the agriculture sector.
    After analysing 148 articles, 21 roadblocks are identified which can be categorized
    at technical and socio-economic levels. 4.12. Technical roadblocks • Interoperability:
    data is considered a cornerstone for the success of smart systems. Agricultural
    data usually comes from multiple heterogeneous sources such as thousands of individual
    farmlands, animal factories, and enterprise applications. This data can have diverse
    formats, making data integration complex. Hence, data interoperability is essential
    to enhance the value of this massively dispersed data after systematic data collection,
    storage, processing, and knowledge mining [208]. Likewise, for establishing effective
    communication between heterogeneous devices, they need to be interconnected and
    interoperable. With cross-technology communication, interoperability of the system
    can be improved [209]. • Standardization: to fully exploit the digital technologies
    for smart farming applications, standardization of the devices is essential. Output
    differences can occur because of misinterpretation and alterations from time to
    time. With standardization, the interoperability issues of the devices, applications,
    and systems can also be resolved [25]. • Dataquality: to produce meaningful results,
    data quality is also crucial along with data security, storage, and openness.
    The lack of decentralized data management systems is another roadblock hindering
    the adoption of smart farming practices [9]. This issue decreases the willingness
    of multiple actors to share agriculture data. • Hardwareimplementation: the deployment
    of a smart agricultural setup in large-scale open fields is extremely challenging.
    This is because all the hardware consisting of IoT devices, wireless sensor networks,
    sensor nodes, machinery, and equipment directly exposed to harsh environmental
    conditions such as heavy rainfall, high/low-temperature levels, extreme humidity,
    strong wind speeds and many other possible dangers which can destroy electronic
    circuits or disrupt their normal functionality [210]. A possible solution is to
    build an adequate casing for all the costly devices that is robust and durable
    enough to endure real field conditions [211]. • Adequatepower sources: typically,
    the wireless devices deployed at farms consistently operate for a long time and
    have limited battery life. A suitable energy saving scheme is necessary because,
    in case of any failure, instant battery replacement is complicated, especially
    in open-air farms where devices are strategically placed with minimum access [210].
    The possible solutions to optimize energy consumption are usage of low power sensors
    and, proper management of communication [24,212]. Wireless power transfer and
    self-supporting wireless system are other promising solutions to eliminate the
    need for battery replacement by recharging the batteries through electromagnetic
    waves. However, long-distance wireless charging is needed in most agricultural
    applications [9]. Ambient energy harvesting from rivers, fluid flow, movement
    of vehicles and, ground surface using sensor nodes offers another viable solution,
    but the converted electrical energy is limited at present – posing the need to
    improve power conversion efficiency [213]. • Reliability: The reliability of devices,
    as well as corresponding software applications, is crucial. This is because IoT
    devices need to gather and transfer the data based on which decisions are made
    using several software packages. Unreliable sensing, processing, and transmission
    can cause false monitoring data reports, long delays, and even data loss – eventually
    impacting the performance of agricultural system [25]. • Adaptability: agricultural
    environments are complex, dynamic, and rapidly changing. Hence, when designing
    a system, it is pertinent for the devices and applications to proactively adapt
    with the other entities under uncertain and dynamic factors - offering the needed
    performance [214]. • Robust wirelessarchitectures: wireless networks and communication
    technologies offer several benefits in terms of low cost, wide-area coverage,
    adequate networking flexibility, and high scalability. But dynamic agriculture
    environments such as temperature variations, living objects’ movements, and the
    presence of obstacles pose severe challenges to reliable wireless communication.
    For instance, fluctuations in the signal intensity occur due to the multipath
    propagation effects – causing unstable connectivity and inadequate data transmission
    [215]. These factors impact the performance of the agricultural system. Hence,
    there is a need for robust and fault-tolerant wireless architectures with appropriate
    location of sensor nodes, antenna height, network topology, and communication
    protocols that also require minimum maintenance [11]. • Interference: another
    challenge is wireless interference and degradation of the quality of service because
    of the dense deployment of IoT devices and wireless sensor networks. These issues
    can be mitigated with efficient channel scheduling between heterogeneous sensing
    devices, cognitive radio-assisted WSNs, and emerging networking primitives such
    as concurrent transmission [216]. Since agriculture devices are distributed at
    indoor greenhouses, outdoor farmlands, underground areas, or even water areas,
    cross-media communication between underground, underwater, and air is also required
    for the complete incorporation of smart technologies [217]. • Security and privacy:
    the distributed nature of smart agricultural systems brings potential vulnerabilities
    to cyber-attacks such as eavesdropping, data integrity, denial-of-service attacks,
    or other types of disruptions that may risk privacy, integrity, and availability
    of the system [218]. Cyber-security is a major challenge that needs to be addressed
    within the context of smart farming, with diverse privacy-preserving mechanisms
    and federated learning approaches [130]. • Compatibility: to achieve the standards
    of fragmentation and scalability, the models or software applications developed
    should be flexible and run on any machine installed in the agricultural system
    [13]. • Resource optimization: farmers require a resource optimization process
    to estimate the optimal number of IoT devices and gateways, cloud storage size,
    and amount of transmitted data to improve farm profitability. Since farms have
    different sizes and need distinct types of sensors to measure different variables,
    resource optimization is challenging [219]. Secondly, most of the farm management
    systems do not offer run-time customization in relation to the distinct requirements
    of farmers. Hence, complex mathematical models and algorithms are required to
    estimate adequate resource allocation [75]. • Scalability: the number of devices,
    machinery, and sensors installed at farms is increasing gradually due to advancements
    in technologies. To support these entities, gateways, network applications, and
    back-end databases should be reliable and scalable [220]. • Human-centereduserinterfaces:
    complex user interfaces of existing agricultural applications and devices are
    impeding smart farming practices. Most GUI is designed in a way that only experts
    can use to perform agricultural tasks. Improving the user interface by making
    it human-centered with multimodal feedback will allow a larger group of people
    to use it to perform different agricultural operations [96]. 4.13. Socio-economic
    roadblocks • Gap between farmers and researchers: the participation of farmers
    is a key factor toward the success of the digitization of the agricultural industry.
    Farmers face a lot of problems during the agri-food production process, which
    smart technologies could fix, but agricultural experts are not usually aware of
    these issues [16]. Moreover, to devise an adequate smart solution, first, it is
    important to fully understand the nature of problems. Hence, it is essential to
    bridge the gap between farmers, agricultural professionals, and AI researchers.
    • Costs associated with smart systems: the costs associated with the adoption
    of smart technologies and systems are the major deterrent in the digitization
    of the agricultural sector. These costs usually involve deployment, operating,
    and maintenance costs. The deployment costs of smart systems are usually very
    high as they involve; i) hardware installation such as autonomous robots and drones,
    WSNs, gateways, and base station infrastructure, etc., to perform certain farm
    operations, and ii) hiring the skilled labour [221]. Likewise, to facilitate data
    processing, management of IoT devices and equipment, and knowledge exchange, subscription
    of centralized networks and software packages is required, which ultimately increases
    the operating costs [222]. Though sometimes service providers offer free subscription
    packages with restricted features, the amount of storage capacity is limited.
    To ensure the adequate operations of the smart system, occasional maintenance
    is required, which then also adds up to total costs. Other types of costs associated
    with smart systems deployment could be environmental, ethical, and social costs.
    To overcome cost related roadblocks, initiatives focusing on cooperative farming
    are needed that provide; i) support services for better handling of costs and
    needed investments, and ii) hardware solutions to transform conventional equipment
    into smart farm-ready machinery to reduce high initial costs [222]. • Digital
    division: another factor that is slowing the digitization of the agricultural
    sector is the lack of knowledge of digital technologies and their applications.
    The majority of farmers have no idea about the significance of digital technologies,
    how to implement and use them, and which technology is suitable for their farm
    and meets their requirements [14]. Hence, it is essential to educate farmers about
    modern farming technologies and systems. Moreover, different strategies are needed
    to build tools using natural language that farmers with low education levels can
    easily understand [223]. • Return on investment: in agriculture, the profit margin
    is very important like other sectors. When it comes to the implementation of advanced
    technologies, farmers have concerns related to the time to recover the investment
    and to the difficulties in evaluating the advantages [12]. • Trust building: unlike
    in other disciplines, building trust regarding the effectiveness of smart technologies
    in agriculture is difficult because many decisions affect systems that involve
    living and non-living entities, and consequences can be hard to reverse [16].
    Additionally, insufficient proof of the impact of digital tools on-farm productivity
    further intensifies the current challenges. • Laws and regulations: different
    regions and countries have different legal frameworks which impact the implementation
    of digital technologies in the agriculture sector, particularly in monitoring
    and agri-food supply [70]. Likewise, regulations related to resource allocation
    (spectrum for wireless devices), data privacy, and security also vary from one
    country to another [70]. • Connectivity infrastructure: most less-developed countries
    usually have insufficient connectivity infrastructure that limits access to advanced
    digital tools that would help to turn data from heterogenous sources into valuable
    and actionable insights [10]. 4.14. Discussion This section discusses the main
    conclusions of RQ1, RQ2, and RQ3. In addition, added value, considerations, and
    future directions are also presented to ensure higher accuracy and great advancements
    in agricultural industry. 4.15. RQ1, RQ2 and RQ3 The present study tried to articulate
    the emerging digital technologies being implemented in agricultural industry to
    anticipate the future trajectories of agriculture 4.0. By looking at Table 2,
    Table 3, Table 4, Table 5, Table 6, Table 7, Table 8, Table 9, Table 10, Table
    11, Table 12, Table 13 in section 4, it can be seen some technologies such as
    big data and analytics, wireless sensor networks, cyber-physical systems, and
    digital twins are not significantly explored in agriculture. A reason for this
    gap could be that implementing advanced technologies with more complex operations
    can be expensive, at least in the early experimental phase of their adoption.
    Hence, the development of these technologies in agricultural industry should increase
    in the coming years. The results of SLR also show that IoT is significantly implemented
    in farms. This is due to the broad functionality of IoT such as in the monitoring,
    tracking and tracing, agriculture machinery, and precision agriculture [21]. It
    can be said that IoT is one of the main research objectives within the agriculture
    4.0 approaches. Nevertheless, only few studies have considered data security and
    reliability, scalability, and interoperability while developing an intelligent
    agricultural system. The research findings also demonstrated that most use cases
    are still in the prototype phase. The possible reason could be because most agricultural
    operations have to do with living subjects, like animals and plants or perishable
    products, and developing systems is harder than non-living human-made systems.
    Another reason might be that agriculture is a slow adopter of technology because
    of transdisciplinary nature of this field, and hence to develop intelligent systems,
    the agricultural community must become familiar will all the digital technologies.
    Lastly, variations in plant/crops’ species, and growth conditions also make digitization
    of agricultural systems complex [188]. The SLR findings also show that most of
    the systems are developed for open-air soil-based farms contrary to indoor farms
    (soilless and soil-based). This is due to complex design and management of indoor
    farms particularly soilless farms where parameters and factors (pH, air temperature,
    humidity, etc.) to be controlled are diverse [5]. But with introduction of digital
    technologies and data-driven computer applications in indoor farms, a more robust
    control of the process can be achieved. Furthermore, it is also revealed from
    SLR that limited research is conducted in three (soil management, fruit detection
    and counting and crop quality management) out of nine different service categories
    mentioned in section 3. This corroborates that substantial research and development
    is needed in some areas to ensure successful digitization of agriculture industry
    in developed countries as well as in developing countries. The complexity of agriculture
    ecosystem presents a series of interconnected roadblocks that hinder the full
    integration of digital technologies for agriculture 4.0 realization. Hence, it
    is essential to identify potential roadblocks in order to come up with strategic
    solutions to overcome them. This study is an attempt to explore what these roadblocks
    are. Based on analysis, 21 roadblocks were identified and classified at technical
    and socio-economic levels. These roadblocks are listed in section 5, which suggests
    what needs to be done for digitization of agricultural industry on larger scale.
    But it is still not known, to what extent elimination or mitigation of these roadblocks
    assist in successful integration of digital technologies. 4.16. Added value of
    agricultural digitization Based on analysis, several benefits that can motivate
    framers and other actors to support digitization of agricultural industry are
    identified and summarised below. The presented benefits have potential to maximise
    the farm''s productivity and enhance product quality, but they should not be considered
    a panacea for challenges associated with smart agriculture [222]. • Improved agility:
    digital technologies improve the agility of farm operations. Through real-time
    surveillance and forecast systems, farmers or agricultural experts can rapidly
    react to any potential fluctuations in environmental and water conditions to save
    crops [221]. • Green process: digital technologies make the farming process more
    environmentally friendly and climate-resilient by significantly reducing the usage
    of in-field fuel, nitrogen fertilizers, pesticides, and herbicides [224]. • Resource
    use efficiency: digital platforms can improve resource use efficiency by enhancing
    the quantity and quality of agricultural output and limiting the usage of water,
    energy, fertilizers, and pesticides [3]. • Time and cost savings: digital technologies
    enable significant time and cost savings by automating different operations, such
    as harvesting, sowing, or irrigation, controlling the application of fertilizers
    or pesticides, and scheduling the irrigation [225]. • Asset management: digital
    technologies allow real-time surveillance of farm properties and equipment to
    prevent theft, expedite component replacement and perform routine maintenance
    [10]. • Product safety: digital technologies ensure adequate farm productivity
    and guarantee a safe and nutritious supply of agri-food products by preventing
    fraud related to adulteration, counterfeit, and artificial enhancement [218].
    4.17. Considerations and future prospects The upcoming initiatives would result
    in significant improvements in the agricultural sector. But in order to make things
    sustainable for small and medium-scale growers, roadblocks mentioned in section
    5 need to be addressed first. Awareness campaigns highlighting the significance
    of smart agriculture at every level of the agricultural value chain and promoting
    innovative ways (such as gamification) to encourage stakeholders to take on an
    active role in the digital revolution can mitigate some of the mentioned roadblocks
    [9]. Government level initiatives, grants and endowments, public-private partnerships,
    the openness of data, and regional basis research work can also assist in coping
    with potential roadblocks. Lastly, a roadmap can be adopted while developing a
    smart agriculture system, starting from basic architecture with few components
    and simpler functionality, gradually adding components and functionality to develop
    a complex system with the full potential of digitization [21]. These considerations
    can pave the way for successful implementation of agriculture 4.0. The future
    prospects of digital technologies in smart agriculture involve using explainable
    artificial intelligence to monitor crop growth, estimate crop biomass, evaluate
    crop health, and control pests and diseases. Explainable AI fades away the traditional
    black-box concept of machine learning and enables understanding the reasons behind
    any specific decision [15]. Description of big data through common semantics and
    ontologies and the adoption of open standards have great potential to boost research
    and development towards smart farming . Similarly, to ensure enhanced connectivity
    and live streaming of crop data, 5G technology need to be extensively explored
    [6]. 5G technology will minimize internet costs and augment the overall user experience
    of farm management and food safety by performing accurate crop inspections remotely
    [226]. Furthermore, it will significantly bridge the gap between stakeholders
    by keeping them well informed on produce availability. Lastly, blockchain in combination
    with IoT and other technologies can be implemented to address the challenges related
    to data privacy and security [227]. 4.18. Transition to Agriculture 5.0 The industrial
    revolutions have always brought a breakthrough in the agricultural sector. As
    formally discussed in previous sections, agriculture 4.0 has great potential to
    counterbalance the growing food demands and prepare for future by reinforcing
    agricultural systems with WSN, IoT, AI, etc. While the realization of agriculture
    4.0 is still underway, there is already a talk about agriculture 5.0. Agriculture
    5.0 extends agriculture 4.0 with inclusion of industry 5.0 principles to produce
    healthy and affordable food while ensuring to prevent degradation of the ecosystems
    on which life depends [228]. The European Commission formally called for the Fifth
    Industrial Revolution (industry 5.0) in 2021 after observing that industry 4.0
    focuses less on the original principles of social fairness and sustainability
    but more on digitalization and AI-driven technologies for increasing the efficiency
    and flexibility [229]. Industry 5.0 complements and extends industry 4.0 concept
    to recognize the human-centricity, sustainability, and resilience [230]. It involves
    refining the collaborative interactions between humans and machines, reducing
    environmental impact through circular economy, and developing high degree of robustness
    in systems to achieve optimal balance between efficiency and productivity. The
    enabling technologies of industry 5.0 are Cobots (collaborative robots), smart
    materials with embedded bio-inspired sensors, digital twins, AI, energy efficient
    and secure data management, renewable energy sources, etc [229].. In agriculture
    5.0 settings, farm''s production efficiency and crop quality can be enhanced by
    assigning repetitive and monotonous tasks to the machines and the tasks which
    need critical thinking to the humans. For this purpose, similar to manufacturing
    sector cyber physical cognitive systems (CPCS) that observe/study the environment
    and take actions accordingly should be developed for agricultural sector. This
    may include collaborative farm robots which will work in the fields and assist
    crop producers in tedious tasks such as seed sowing and harvesting etc. Likewise,
    digital twins in agriculture 5.0 can also offer significant value by identifying
    technical issues in agricultural systems and overcoming them at a faster speed,
    detecting crop diseases, and making crop yield predictions at a higher accuracy
    rate. This shows that agriculture 5.0 has potential to pave a way for climate
    smart, sustainable and resilient agriculture but as of now, it is in the developing
    phase. 5. Conclusions Increased concerns about global food security have accelerated
    the need for next-generation industrial farms and intensive production methods
    in agriculture. At the forefront of this modern agricultural era, digital technologies
    offered by Industry 4.0 initiative are suggesting a myriad of creative solutions.
    The scientific community and researchers integrate disruptive technologies in
    conventional agriculture systems to increase crop yields, minimize costs, reduce
    wastes, and maintain process inputs. An SLR discussing the prevailing state of
    these technologies in the agriculture sector is presented in this study. After
    applying SLR protocol, 148 articles were considered from the time frame of the
    year 2011 to 2021. Various research questions pertaining to i) current and continuing
    research trends, ii) functionality, maturity level, farm type and tools and techniques
    used, iii) primary roadblocks, and iv) added value of digital technologies; were
    put forward and answered. Several conclusions are drawn such as integration of
    big data and analytics, wireless sensor networks, cyber-physical systems, and
    digital twins in agriculture is only in its infancy, and most use cases are in
    the prototype phase. Likewise, 21 roadblocks are identified and classified at
    technical and socioeconomic levels. To ensure the digitization of agricultural
    industry, these roadblocks must be analyzed and overcome. The added value of digital
    technologies in agriculture industry are also identified and presented in the
    study. Overall, this study contributes to the research being carried around agriculture
    4.0. The primary limitation of this review is twofold: firstly, only three online
    repositories are considered for literature search (Scopus, IEEE and Science Direct),
    and secondly additional keywords and synonyms might return more studies. In both
    scenarios, it is highly unlikely that the overall findings would change. For the
    future work, additional research databases and aspects can be considered to provide
    holistic overview of agricultural industry in terms of digitization. Moreover,
    studies targeting agriculture 5.0 in general will also be included. Declaration
    of Competing Interest The authors declare that they have no known competing financial
    interests or personal relationships that could have appeared to influence the
    work reported in this paper. Acknowledgements The authors acknowledge the financial
    support of this work by the Natural Sciences and Engineering Research Council
    of Canada (NSERC) (Grant File No. ALLRP 545537-19 and RGPIN-2017-04516). References
    [1] F Schierhorn, M. Elferink Global Demand for Food Is Rising. Can We Meet It?
    Harv Bus Rev, 7 (2017), p. 2016 Google Scholar [2] TY Kyaw, AK. Ng Smart Aquaponics
    System for Urban Farming Energy Procedia, 143 (2017), pp. 342-347, 10.1016/j.egypro.2017.12.694
    View PDFView articleView in ScopusGoogle Scholar [3] WK Mok, YX Tan, WN. Chen
    Technology innovations for food security in Singapore: A case study of future
    food systems for an increasingly natural resource-scarce world Trends Food Sci
    Technol, 102 (2020), pp. 155-168, 10.1016/j.tifs.2020.06.013 View PDFView articleView
    in ScopusGoogle Scholar [4] H Valin, RD Sands, D van der Mensbrugghe, GC Nelson,
    H Ahammad, E Blanc, et al. The future of food demand: Understanding differences
    in global economic models Agric Econ (United Kingdom), 45 (2014), pp. 51-67, 10.1111/agec.12089
    View in ScopusGoogle Scholar [5] R Abbasi, P Martinez, R. Ahmad An ontology model
    to represent aquaponics 4.0 system''s knowledge Inf Process Agric (2021), 10.1016/J.INPA.2021.12.001
    Google Scholar [6] R Abbasi, P Martinez, R. Ahmad An ontology model to support
    the automated design of aquaponic grow beds Procedia CIRP, 100 (2021), pp. 55-60,
    10.1016/j.procir.2021.05.009 View PDFView articleView in ScopusGoogle Scholar
    [7] G Aceto, V Persico, A. Pescapé A Survey on Information and Communication Technologies
    for Industry 4.0: State-of-the-Art, Taxonomies, Perspectives, and Challenges IEEE
    Commun Surv Tutorials (2019), 10.1109/COMST.2019.2938259 Google Scholar [8] A
    Gacar, H Aktas, B. Ozdogan Digital agriculture practices in the context of agriculture
    4.0. Pressacademia, 4 (2017), pp. 184-191, 10.17261/pressacademia.2017.448 Google
    Scholar [9] Y Liu, X Ma, L Shu, GP Hancke, AM. Abu-Mahfouz 0: Current Status,
    Enabling Technologies, and Research Challenges IEEE Trans Ind Informatics, 17
    (2021), pp. 4322-4334, 10.1109/TII.2020.3003910 View in ScopusGoogle Scholar [10]
    F da Silveira, FH Lermen, FG. Amaral An overview of agriculture 4.0 development:
    Systematic review of descriptions, technologies, barriers, advantages, and disadvantages
    Comput Electron Agric, 189 (2021), Article 106405, 10.1016/J.COMPAG.2021.106405
    View PDFView articleView in ScopusGoogle Scholar [11] G Idoje, T Dagiuklas, M.
    Iqbal Survey for smart farming technologies: Challenges and issues Comput Electr
    Eng, 92 (2021), Article 107104, 10.1016/J.COMPELECENG.2021.107104 View PDFView
    articleView in ScopusGoogle Scholar [12] J Miranda, P Ponce, A Molina, P. Wright
    Sensing, smart and sustainable technologies for Agri-Food 4.0 Comput Ind, 108
    (2019), pp. 21-36, 10.1016/J.COMPIND.2019.02.002 View PDFView articleView in ScopusGoogle
    Scholar [13] M Lezoche, H Panetto, J Kacprzyk, JE Hernandez Alemany Díaz MME.
    Agri-food 4.0: A survey of the supply chains and technologies for the future agriculture
    Comput Ind, 117 (2020), Article 103187, 10.1016/J.COMPIND.2020.103187 View PDFView
    articleView in ScopusGoogle Scholar [14] Bhakta I, Phadikar S, Majumder K. State-of-the-art
    technologies in precision agriculture: a systematic review 2019. https://doi.org/10.1002/jsfa.9693.
    Google Scholar [15] SO Araújo, RS Peres, J Barata, F Lidon, JC. Ramalho Characterising
    the Agriculture 4.0 Landscape—Emerging Trends, Challenges and Opportunities Agron,
    11 (2021), p. 667, 10.3390/AGRONOMY11040667 Page2021;11:667 View in ScopusGoogle
    Scholar [16] M Bacco, P Barsocchi, E Ferro, A Gotta, M. Ruggeri The Digitisation
    of Agriculture: a Survey of Research Activities on Smart Farming Array, 3–4 (2019),
    Article 100009, 10.1016/j.array.2019.100009 View PDFView articleView in ScopusGoogle
    Scholar [17] X Huang, C Zanni-Merk, B. Crémilleux Enhancing deep learning with
    semantics: An application to manufacturing time series analysis Procedia Comput
    Sci, 159 (2019), pp. 437-446, 10.1016/j.procs.2019.09.198 View PDFView articleView
    in ScopusGoogle Scholar [18] L Jiyu, Y Lan, W Jianwei, C Shengde, H Cong, L Qi,
    et al. Distribution law of rice pollen in the wind field of small UAV Int J Agric
    Biol Eng, 10 (2017), pp. 32-40, 10.25165/IJABE.V10I4.3103 Google Scholar [19]
    MJ Page, JE McKenzie, PM Bossuyt, I Boutron, TC Hoffmann, CD Mulrow, et al. The
    PRISMA 2020 statement: An updated guideline for reporting systematic reviews BMJ,
    372 (2021), 10.1136/BMJ.N71 Google Scholar [20] Ahmed MA, Ahsan I, Abbas M. Systematic
    Literature Review 2016:165–8. https://doi.org/10.1145/2987386.2987422. Google
    Scholar [21] C Pylianidis, S Osinga, IN. Athanasiadis Introducing digital twins
    to agriculture Comput Electron Agric, 184 (2021), Article 105942, 10.1016/J.COMPAG.2020.105942
    View PDFView articleView in ScopusGoogle Scholar [22] Shaikh ZA Aqeel-ur-Rehman,
    NA Shaikh, N Islam An integrated framework to develop context aware sensor grid
    for agriculture Aust J Basic Appl Sci (2010) Google Scholar [23] W Shi, J Cao,
    Q Zhang, Y Li, L. Xu Edge Computing: Vision and Challenges IEEE Internet Things
    J, 3 (2016), pp. 637-646, 10.1109/JIOT.2016.2579198 View in ScopusGoogle Scholar
    [24] A Tzounis, N Katsoulas, T Bartzanas, C. Kittas Internet of Things in agriculture,
    recent advances and future challenges Biosyst Eng, 164 (2017), pp. 31-48, 10.1016/J.BIOSYSTEMSENG.2017.09.007
    View PDFView articleView in ScopusGoogle Scholar [25] VP Kour, S. Arora Recent
    Developments of the Internet of Things in Agriculture: A Survey IEEE Access, 8
    (2020), pp. 129924-129957, 10.1109/ACCESS.2020.3009298 View in ScopusGoogle Scholar
    [26] R Saemaldahr, B Thapa, K Maikoo, EB. Fernandez Reference Architectures for
    the IoT: A Survey Lect Notes Data Eng Commun Technol, 72 (2020), pp. 635-646,
    10.1007/978-3-030-70713-2_58 Google Scholar [27] A Somov, D Shadrin, I Fastovets,
    A Nikitin, S Matveev, I Seledets, et al. Pervasive Agriculture: IoT-Enabled Greenhouse
    for Plant Growth Control IEEE Pervasive Comput, 17 (2018), pp. 65-75, 10.1109/MPRV.2018.2873849
    View in ScopusGoogle Scholar [28] B Yimwadsana, P Chanthapeth, C Lertthanyaphan,
    A. Pornvechamnuay An IoT controlled system for plant growth Proceeding 2018 7th
    ICT Int Student Proj Conf ICT-ISPC 2018 (2018), 10.1109/ICT-ISPC.2018.8523886
    Google Scholar [29] SN Nnadi, FE. Idachaba Design and Implementation of a Sustainable
    IOT Enabled Greenhouse Prototype IEEE 5G World Forum, 5GWF 2018 - Conf Proc (2018),
    pp. 457-461, 10.1109/5GWF.2018.8517006 View in ScopusGoogle Scholar [30] J Yang,
    M Liu, J Lu, Y Miao, MA Hossain, MF. Alhamid Botanical Internet of Things: Toward
    Smart Indoor Farming by Connecting People, Plant, Data and Clouds Mob Networks
    Appl, 23 (2018), pp. 188-202, 10.1007/S11036-017-0930-X View in ScopusGoogle Scholar
    [31] F Francis, PL Vishnu, M Jha, B. Rajaram IOT-Based Automated Aeroponics System
    Lect Notes Electr Eng Intell Embed Syst, 492 (2017), pp. 337-345, 10.1007/978-981-10-8575-8_32
    Google Scholar [32] CA Jamhari, WK Wibowo, AR Annisa, TM. Roffi Design and Implementation
    of IoT System for Aeroponic Chamber Temperature Monitoring Proceeding - 2020 3rd
    Int Conf Vocat Educ Electr Eng Strength Framew Soc 50 through Innov Educ Electr
    Eng Informatics Eng ICVEE 2020 (2020), 10.1109/ICVEE50212.2020.9243213 Google
    Scholar [33] KC Chang, PK Liu, ZW Kuo, SH. Liao Design of persimmon growing stage
    monitoring system using image recognition technique 2016 IEEE Int Conf Consum
    Electron ICCE-TW (2016 2016), 10.1109/ICCE-TW.2016.7520978 Google Scholar [34]
    Namgyel T, Siyang S, Khunarak C, Pobkrut T, Norbu J, Chaiyasit T, et al. IoT based
    hydroponic system with supplementary LED light for smart home farming of lettuce
    2019:221–4. https://doi.org/10.1109/ECTICON.2018.8619983. Google Scholar [35]
    M Manju, V Karthik, S Hariharan, B. Sreekar Real time monitoring of the environmental
    parameters of an aquaponic system based on internet of things ICONSTEM 2017 -
    Proc 3rd IEEE Int Conf Sci Technol Eng Manag 2017 (2018), pp. 943-948, 10.1109/ICONSTEM.2017.8261342
    -January Google Scholar [36] MS Mekala, P. Viswanathan CLAY-MIST: IoT-cloud enabled
    CMM index for smart agriculture monitoring system Measurement, 134 (2019), pp.
    236-244, 10.1016/J.MEASUREMENT.2018.10.072 View PDFView articleView in ScopusGoogle
    Scholar [37] T Wiangtong, P. Sirisuk IoT-based Versatile Platform for Precision
    Farming Isc 2018 - 18th Int Symp Commun Inf Technol (2018), pp. 438-441, 10.1109/ISCIT.2018.8587989
    View in ScopusGoogle Scholar [38] MA Zamora-Izquierdo, J Santa, JA Martínez, V
    Martínez, AF Skarmeta Smart farming IoT platform based on edge and cloud computing
    Biosyst Eng, 177 (2019), pp. 4-17, 10.1016/J.BIOSYSTEMSENG.2018.10.014 View PDFView
    articleView in ScopusGoogle Scholar [39] NK. Jacob IoT powered portable aquaponics
    system ACM Int Conf Proceeding Ser (2017), 10.1145/3018896.3018965 Google Scholar
    [40] M Mehra, S Saxena, S Sankaranarayanan, RJ Tom, M. Veeramanikandan IoT based
    hydroponics system using Deep Neural Networks Comput Electron Agric, 155 (2018),
    pp. 473-486, 10.1016/J.COMPAG.2018.10.015 View PDFView articleView in ScopusGoogle
    Scholar [41] Naser BAA-Z, Saleem AL, Ali A, Alabassi S, Al-Baghdadi M. Design
    and construction of smart IoT-based aquaponics powered by PV cells 2019. Google
    Scholar [42] M Odema, I Adly, A Wahba, H. Ragai Smart Aquaponics System for Industrial
    Internet of Things (IIoT) Adv Intell Syst Comput, 639 (2017), pp. 844-854, 10.1007/978-3-319-64861-3_79
    Google Scholar [43] W Vernandhes, NS Salahuddin, A Kowanda, SP. Sari Smart aquaponic
    with monitoring and control system based on IoT Proc 2nd Int Conf Informatics
    Comput ICIC 2017 2018 (2018), 10.1109/IAC.2017.8280590 Google Scholar [44] B Keswani,
    AG Mohapatra, A Mohanty, A Khanna, JJPC Rodrigues, D Gupta, et al. Adapting weather
    conditions based IoT enabled smart irrigation technique in precision agriculture
    mechanisms Neural Comput Appl, 31 (2018), pp. 277-292, 10.1007/S00521-018-3737-1
    2018 311 Google Scholar [45] NK Nawandar, VR. Satpute IoT based low cost and intelligent
    module for smart irrigation system Comput Electron Agric, 162 (2019), pp. 979-990,
    10.1016/J.COMPAG.2019.05.027 View PDFView articleView in ScopusGoogle Scholar
    [46] PM Gupta, M Salpekar, PK. Tejan Agricultural practices Improvement Using
    IoT Enabled SMART Sensors 2018 Int Conf Smart City Emerg Technol ICSCET, 2018
    (2018), 10.1109/ICSCET.2018.8537291 Google Scholar [47] M Dholu, KA. Ghodinde
    Internet of Things (IoT) for Precision Agriculture Application Proc 2nd Int Conf
    Trends Electron Informatics, ICOEI 2018 (2018), pp. 339-342, 10.1109/ICOEI.2018.8553720
    View in ScopusGoogle Scholar [48] TAA Ali, V Choksi, MB. Potdar Precision Agriculture
    Monitoring System Using Green Internet of Things (G-IoT) Proc 2nd Int Conf Trends
    Electron Informatics, ICOEI 2018 (2018), pp. 481-487, 10.1109/ICOEI.2018.8553866
    View in ScopusGoogle Scholar [49] AJ Rau, J Sankar, AR Mohan, D Das Krishna, J
    Mathew IoT based smart irrigation system and nutrient detection with disease analysis
    TENSYMP 2017 - IEEE Int Symp Technol Smart Cities (2017), 10.1109/TENCONSPRING.2017.8070100
    Google Scholar [50] Thorat A, Kumari S, Valakunde ND. An IoT based smart solution
    for leaf disease detection. 2017 Int Conf Big Data, IoT Data Sci BID 2017 2018;2018-January:193–8.
    https://doi.org/10.1109/BID.2017.8336597. Google Scholar [51] K Foughali, K Fathallah,
    A. Frihida Using Cloud IOT for disease prevention in precision agriculture Procedia
    Comput Sci, 130 (2018), pp. 575-582, 10.1016/J.PROCS.2018.04.106 View PDFView
    articleView in ScopusGoogle Scholar [52] SS Koshy, VS Sunnam, P Rajgarhia, K Chinnusamy,
    DP Ravulapalli, S. Chunduri Application of the internet of things (IoT) for smart
    farming: a case study on groundnut and castor pest and disease forewarning CSI
    Trans ICT 2018 63, 6 (2018), pp. 311-318, 10.1007/S40012-018-0213-0 Google Scholar
    [53] SS Patil, SA. Thorat Early detection of grapes diseases using machine learning
    and IoT Proc - 2016 2nd Int Conf Cogn Comput Inf Process CCIP 2016 (2016), 10.1109/CCIP.2016.7802887
    Google Scholar [54] MI Pavel, SM Kamruzzaman, SS Hasan, SR. Sabuj An IoT based
    plant health monitoring system implementing image processing 2019 IEEE 4th Int
    Conf Comput Commun Syst ICCCS 2019 (2019), pp. 299-303, 10.1109/CCOMS.2019.8821783
    View in ScopusGoogle Scholar [55] MU Aftab, O Ashraf, M Irfan, M Majid, A Nisar,
    MA. Habib A Review Study of Wireless Sensor Networks and Its Security Commun Netw,
    7 (2015), pp. 172-179, 10.4236/cn.2015.74016 Google Scholar [56] X Yu, P Wu, W
    Han, Z. Zhang A survey on wireless sensor network infrastructure for agriculture
    Comput Stand Interfaces, 1 (2013), pp. 59-64, 10.1016/J.CSI.2012.05.001 View PDFView
    articleView in ScopusGoogle Scholar [57] J Gutierrez, JF Villa-Medina, A Nieto-Garibay,
    MA. Porta-Gandara Automated irrigation system using a wireless sensor network
    and GPRS module IEEE Trans Instrum Meas, 63 (2014), pp. 166-176, 10.1109/TIM.2013.2276487
    View in ScopusGoogle Scholar [58] H Navarro-Hellín, R Torres-Sánchez, F Soto-Valles,
    C Albaladejo-Pérez, JA López-Riquelme, R Domingo-Miguel A wireless sensors architecture
    for efficient irrigation water management Agric Water Manag, 151 (2015), pp. 64-74,
    10.1016/J.AGWAT.2014.10.022 View PDFView articleView in ScopusGoogle Scholar [59]
    SA Nikolidakis, D Kandris, DD Vergados, C. Douligeris Energy efficient automated
    control of irrigation in agriculture by using wireless sensor networks Comput
    Electron Agric, 113 (2015), pp. 154-163, 10.1016/J.COMPAG.2015.02.004 View PDFView
    articleView in ScopusGoogle Scholar [60] I Mat, MR Mohd Kassim, AN Harun Mat Yusoff
    I. IoT in Precision Agriculture applications using Wireless Moisture Sensor Network
    ICOS 2016 - 2016 IEEE Conf Open Syst (2017), pp. 24-29, 10.1109/ICOS.2016.7881983
    Google Scholar [61] KP Ferentinos, N Katsoulas, A Tzounis, T Bartzanas, C. Kittas
    Wireless sensor networks for greenhouse climate and plant condition assessment
    Biosyst Eng, 153 (2017), pp. 70-81, 10.1016/J.BIOSYSTEMSENG.2016.11.005 View PDFView
    articleView in ScopusGoogle Scholar [62] JA Jiang, MS Liao, TS Lin, CK Huang,
    CY Chou, SH Yeh, et al. Toward a higher yield: a wireless sensor network-based
    temperature monitoring and fan-circulating system for precision cultivation in
    plant factories Precis Agric, 19 (2018), pp. 929-956, 10.1007/S11119-018-9565-6
    View in ScopusGoogle Scholar [63] M Srbinovska, C Gavrovski, V Dimcev, A Krkoleva,
    V. Borozan Environmental parameters monitoring in precision agriculture using
    wireless sensor networks J Clean Prod, 88 (2015), pp. 297-307, 10.1016/J.JCLEPRO.2014.04.036
    View PDFView articleView in ScopusGoogle Scholar [64] PC. Menon IoT enabled Aquaponics
    with wireless sensor smart monitoring Proc 4th Int Conf IoT Soc Mobile, Anal Cloud,
    ISMAC 2020 (2020), pp. 171-176, 10.1109/I-SMAC49090.2020.9243368 View in ScopusGoogle
    Scholar [65] T Cao-Hoang, CN. Duy Environment monitoring system for agricultural
    application based on wireless sensor network 7th Int Conf Inf Sci Technol ICIST
    2017 - Proc (2017), pp. 99-102, 10.1109/ICIST.2017.7926499 View in ScopusGoogle
    Scholar [66] Samijayani ON, Darwis R, Rahmatia S, Mujadin A, Astharini D. Hybrid
    zigbee and wifi wireless sensor networks for hydroponic monitoring 2020. Google
    Scholar [67] Mell PM, Grance T. The NIST definition of cloud computing 2011. https://doi.org/10.6028/NIST.SP.800-145.
    Google Scholar [68] Alwada''n T. CLOUD COMPUTING AND MULTI-AGENT SYSTEM : MONITORING
    AND SERVICES 2018. Google Scholar [69] X Shi, X An, Q Zhao, H Liu, L Xia, X Sun,
    et al. State-of-the-art internet of things in protected agriculture Sensors (Switzerland),
    19 (2019), p. 1833, 10.3390/s19081833 View in ScopusGoogle Scholar [70] J Wang,
    H Yue, Z. Zhou An improved traceability system for food quality assurance and
    evaluation based on fuzzy classification and neural network Food Control, 79 (2017),
    pp. 363-370, 10.1016/J.FOODCONT.2017.04.013 View PDFView articleView in ScopusGoogle
    Scholar [71] A Kaloxylos, A Groumas, V Sarris, L Katsikas, P Magdalinos, E Antoniou,
    et al. A cloud-based farm management system: Architecture and implementation Comput
    Electron Agric, 100 (2014), pp. 168-179, 10.1016/J.COMPAG.2013.11.014 View PDFView
    articleView in ScopusGoogle Scholar [72] F Yang, K Wang, Y Han, Z. Qiao A Cloud-Based
    Digital Farm Management System for Vegetable Production Process Management and
    Quality Traceability Sustain, 10 (2018), p. 4007, 10.3390/SU10114007 Page2018;10:4007
    View in ScopusGoogle Scholar [73] DS Paraforos, V Vassiliadis, D Kortenbruck,
    K Stamkopoulos, V Ziogas, AA Sapounas, et al. A Farm Management Information System
    Using Future Internet Technologies IFAC-PapersOnLine, 49 (2016), pp. 324-329,
    10.1016/J.IFACOL.2016.10.060 View PDFView articleView in ScopusGoogle Scholar
    [74] Y Ampatzidis, L Tan, R Haley, MD. Whiting Cloud-based harvest management
    information system for hand-harvested specialty crops Comput Electron Agric, 122
    (2016), pp. 161-167, 10.1016/J.COMPAG.2016.01.032 View PDFView articleView in
    ScopusGoogle Scholar [75] S Fountas, G Carli, CG Sørensen, Z Tsiropoulos, C Cavalaris,
    A Vatsanidou, et al. Farm management information systems: Current situation and
    future perspectives Comput Electron Agric, 115 (2015), pp. 40-50, 10.1016/J.COMPAG.2015.05.011
    View PDFView articleView in ScopusGoogle Scholar [76] HY Chang, JJ Wang, CY Lin,
    CH. Chen An agricultural data gathering platform based on internet of things and
    big data Proc - 2018 Int Symp Comput Consum Control IS3C 2018 (2019), pp. 302-305
    https://doi.org/10.1109/IS3C.2018.00083 CrossRefGoogle Scholar [77] FJ Ferrández-Pastor,
    JM García-Chamizo, M Nieto-Hidalgo, J Mora-Pascual, J. Mora-Martínez Developing
    Ubiquitous Sensor Network Platform Using Internet of Things: Application in Precision
    Agriculture Sensors (Basel), 16 (2016), 10.3390/S16071141 Google Scholar [78]
    R M, T A, JA L-R, J M, L P, N P-P, et al. mySense: A comprehensive data management
    environment to improve precision agriculture practices Comput Electron Agric,
    162 (2019), pp. 882-894, 10.1016/J.COMPAG.2019.05.028 Google Scholar [79] ST Oliver,
    A González-Pérez, JH. Guijarro An IoT proposal for monitoring vineyards called
    senviro for agriculture ACM Int Conf Proceeding Ser (2018), 10.1145/3277593.3277625
    Google Scholar [80] Fan DH, Gao S. IOP Conference Series: Earth and Environmental
    Science The application of mobile edge computing in agricultural water monitoring
    system The application of mobile edge computing in agricultural water monitoring
    system 2018;191:12015. https://doi.org/10.1088/1755-1315/191/1/012015. Google
    Scholar [81] M Asmi Romli, S Daud, RA Aliana Raof, Z Awang Ahmad, N Mahrom Aquaponic
    Growbed Water Level Control Using Fog Architecture Related content Aquaponic Growbed
    Water Level Control Using Fog Architecture J Phys (2018), p. 12014, 10.1088/1742-6596/1018/1/012014
    Google Scholar [82] G L, C R, P G An automated low cost IoT based Fertilizer Intimation
    System for smart agriculture Sustain Comput Informatics Syst, 28 (2020), Article
    100300, 10.1016/J.SUSCOM.2019.01.002 Google Scholar [83] R Rahmadian, M. Widyartono
    Autonomous Robotic in Agriculture: A Review Proceeding - 2020 3rd Int Conf Vocat
    Educ Electr Eng Strength Framew Soc 50 through Innov Educ Electr Eng Informatics
    Eng ICVEE 2020 (2020), 10.1109/ICVEE50212.2020.9243253 Google Scholar [84] A Bechar,
    C. Vigneault Agricultural robots for field operations: Concepts and components
    Biosyst Eng, 149 (2016), pp. 94-111, 10.1016/J.BIOSYSTEMSENG.2016.06.014 View
    PDFView articleView in ScopusGoogle Scholar [85] Gonzalez-De-Santos P, Fernández
    R, Sepúlveda D, Navas E, Armada M. Unmanned Ground Vehicles for Smart Farms. Agron
    - Clim Chang Food Secur 2020. https://doi.org/10.5772/INTECHOPEN.90683. Google
    Scholar [86] O Bawden, J Kulk, R Russell, C McCool, A English, F Dayoub, et al.
    Robot for weed species plant-specific management J F Robot, 34 (2017), pp. 1179-1199,
    10.1002/ROB.21727 View in ScopusGoogle Scholar [87] J Gai, L Tang, BL. Steward
    Automated crop plant detection based on the fusion of color and depth images for
    robotic weed control J F Robot, 37 (2020), pp. 35-52, 10.1002/ROB.21897 View in
    ScopusGoogle Scholar [88] G Adamides, C Katsanos, I Constantinou, G Christou,
    M Xenos, T Hadzilacos, et al. Design and development of a semi-autonomous agricultural
    vineyard sprayer: Human–robot interaction aspects J F Robot, 34 (2017), pp. 1407-1426,
    10.1002/ROB.21721 View in ScopusGoogle Scholar [89] R Berenstein, Y. Edan Automatic
    Adjustable Spraying Device for Site-Specific Agricultural Application IEEE Trans
    Autom Sci Eng, 15 (2018), pp. 641-650, 10.1109/TASE.2017.2656143 View in ScopusGoogle
    Scholar [90] Underwood J, Calleija M, Taylor Z, Hung C, Nieto J, Fitch R, et al.
    Real-time target detection and steerable spray for vegetable crops 2015. Google
    Scholar [91] N Srinivasan, P Prabhu, SS Smruthi, NV Sivaraman, SJ Gladwin, R Rajavel,
    et al. Design of an autonomous seed planting robot IEEE Reg 10 Humanit Technol
    Conf 2016, R10-HTC 2016 - Proc (2017), 10.1109/R10-HTC.2016.7906789 Google Scholar
    [92] MU Hassan, M Ullah, J. Iqbal Towards autonomy in agriculture: Design and
    prototyping of a robotic vehicle with seed selector 2016 2nd Int Conf Robot Artif
    Intell ICRAI 2016 (2016), pp. 37-44, 10.1109/ICRAI.2016.7791225 View in ScopusGoogle
    Scholar [93] M Nejati, HS Ahn, B. MacDonald Design of a sensing module for a kiwifruit
    flower pollinator robot Australas Conf Robot Autom ACRA, 2020 (2019-December)
    Google Scholar [94] Y Ge, Y Xiong, PJ. From Symmetry-based 3D shape completion
    for fruit localisation for harvesting robots Biosyst Eng, 197 (2020), pp. 188-202,
    10.1016/J.BIOSYSTEMSENG.2020.07.003 View PDFView articleView in ScopusGoogle Scholar
    [95] S Birrell, J Hughes, JY Cai, F. Iida A field-tested robotic harvesting system
    for iceberg lettuce J F Robot, 37 (2020), pp. 225-245, 10.1002/ROB.21888 View
    in ScopusGoogle Scholar [96] J del Cerro, CC Ulloa, A Barrientos, L. Rivas J de
    Unmanned Aerial Vehicles in Agriculture: A Survey Agron, 11 (2021), p. 203, 10.3390/AGRONOMY11020203
    Page2021;11:203 View in ScopusGoogle Scholar [97] Patel PN, Patel M, Faldu RM,
    Dave YR. Quadcopter for Agricultural Surveillance 2013. Google Scholar [98] Sylvester
    G, Food and Agriculture Organization of the United Nations., International Telecommunication
    Union. E-agriculture in action : drones for agriculture n.d.:112. Google Scholar
    [99] H Aasen, A Burkart, A Bolten, G. Bareth Generating 3D hyperspectral information
    with lightweight UAV snapshot cameras for vegetation monitoring: From camera calibration
    to quality assurance ISPRS J Photogramm Remote Sens, 108 (2015), pp. 245-259,
    10.1016/J.ISPRSJPRS.2015.08.002 View PDFView articleView in ScopusGoogle Scholar
    [100] J Bendig, K Yu, H Aasen, A Bolten, S Bennertz, J Broscheit, et al. Combining
    UAV-based plant height from crop surface models, visible, and near infrared vegetation
    indices for biomass monitoring in barley Int J Appl Earth Obs Geoinf, 39 (2015),
    pp. 79-87, 10.1016/J.JAG.2015.02.012 View PDFView articleView in ScopusGoogle
    Scholar [101] M Du, N. Noguchi Monitoring of wheat growth status and mapping of
    wheat yield''s within-field spatial variations using color images acquired from
    UAV-camera System Remote Sens, 9 (2017), 10.3390/RS9030289 Google Scholar [102]
    ML Guillen-Climent, PJ Zarco-Tejada, JAJ Berni, PRJ North, FJ. Villalobos Mapping
    radiation interception in row-structured orchards using 3D simulation and high-resolution
    airborne imagery acquired from a UAV Precis Agric, 13 (2012), pp. 473-500, 10.1007/S11119-012-9263-8
    2012 134 View in ScopusGoogle Scholar [103] H Xiang, L. Tian Development of a
    low-cost agricultural remote sensing system based on an autonomous unmanned aerial
    vehicle (UAV) Biosyst Eng, 108 (2011), pp. 174-190, 10.1016/J.BIOSYSTEMSENG.2010.11.010
    View PDFView articleView in ScopusGoogle Scholar [104] CA. Rokhmana The Potential
    of UAV-based Remote Sensing for Supporting Precision Agriculture in Indonesia
    Procedia Environ Sci, 24 (2015), pp. 245-253, 10.1016/J.PROENV.2015.03.032 View
    PDFView articleView in ScopusGoogle Scholar [105] Z Pan, D Lie, L Qiang, H Shaolan,
    Y Shilai, L Yande, et al. Effects of citrus tree-shape and spraying height of
    small unmanned aerial vehicle on droplet distribution Int J Agric Biol Eng, 9
    (2016), pp. 45-52, 10.25165/IJABE.V9I4.2178 Google Scholar [106] S Meivel, K Dinakaran,
    N Gandhiraj, M. Srinivasan Remote sensing for UREA Spraying Agricultural (UAV)
    system ICACCS 2016 - 3rd Int Conf Adv Comput Commun Syst Bringing to Table, Futur
    Technol from Arround Globe (2016), 10.1109/ICACCS.2016.7586367 Google Scholar
    [107] BS Faiçal, FG Costa, G Pessin, J Ueyama, H Freitas, A Colombo, et al. The
    use of unmanned aerial vehicles and wireless sensor networks for spraying pesticides
    J Syst Archit, 60 (2014), pp. 393-404, 10.1016/J.SYSARC.2014.01.004 View PDFView
    articleView in ScopusGoogle Scholar [108] DK Giles, RC. Billing Deployment and
    performance of a uav for crop spraying Chem Eng Trans, 44 (2015), pp. 307-312,
    10.3303/CET1544052 View in ScopusGoogle Scholar [109] X Xue, Y Lan, Z Sun, C Chang,
    WC. Hoffmann Develop an unmanned aerial vehicle based automatic aerial spraying
    system Comput Electron Agric, 128 (2016), pp. 58-66, 10.1016/J.COMPAG.2016.07.022
    View PDFView articleView in ScopusGoogle Scholar [110] J Torres-Sánchez, JM Peña,
    AI de Castro, F. López-Granados Multi-temporal mapping of the vegetation fraction
    in early-season wheat fields using images from UAV Comput Electron Agric, 103
    (2014), pp. 104-113, 10.1016/J.COMPAG.2014.02.009 View PDFView articleView in
    ScopusGoogle Scholar [111] JM Peña, J Torres-Sánchez, AI de Castro, M Kelly, F.
    López-Granados Weed Mapping in Early-Season Maize Fields Using Object-Based Analysis
    of Unmanned Aerial Vehicle (UAV) Images PLoS One, 8 (2013), p. e77151, 10.1371/JOURNAL.PONE.0077151
    View in ScopusGoogle Scholar [112] J Baluja, MP Diago, P Balda, R Zorer, F Meggio,
    F Morales, et al. Assessment of vineyard water status variability by thermal and
    multispectral imagery using an unmanned aerial vehicle (UAV) Irrig Sci, 30 (2012),
    pp. 511-522, 10.1007/S00271-012-0382-9 View in ScopusGoogle Scholar [113] PJ Zarco-Tejada,
    V González-Dugo, Berni JAJ. Fluorescence temperature and narrow-band indices acquired
    from a UAV platform for water stress detection using a micro-hyperspectral imager
    and a thermal camera Remote Sens Environ, 117 (2012), pp. 322-337, 10.1016/J.RSE.2011.10.007
    View PDFView articleView in ScopusGoogle Scholar [114] H Hoffmann, R Jensen, A
    Thomsen, H Nieto, J Rasmussen, T. Friborg Crop water stress maps for an entire
    growing season from visible and thermal UAV imagery Biogeosciences, 13 (2016),
    pp. 6545-6563, 10.5194/BG-13-6545-2016 View in ScopusGoogle Scholar [115] C Romero-Trigueros,
    PA Nortes, JJ Alarcón, JE Hunink, M Parra, S Contreras, et al. Effects of saline
    reclaimed waters and deficit irrigation on Citrus physiology assessed by UAV remote
    sensing Agric Water Manag, 183 (2017), pp. 60-69, 10.1016/J.AGWAT.2016.09.014
    View PDFView articleView in ScopusGoogle Scholar [116] M Romero, Y Luo, B Su,
    S. Fuentes Vineyard water status estimation using multispectral imagery from an
    UAV platform and machine learning algorithms for irrigation scheduling management
    Comput Electron Agric, 147 (2018), pp. 109-117, 10.1016/J.COMPAG.2018.02.013 View
    PDFView articleView in ScopusGoogle Scholar [117] F Vanegas, D Bratanov, K Powell,
    J Weiss, F. Gonzalez A Novel Methodology for Improving Plant Pest Surveillance
    in Vineyards and Crops Using UAV-Based Hyperspectral and Spatial Data Sensors,
    18 (2018), p. 260, 10.3390/S18010260 Page2018;18:260 View in ScopusGoogle Scholar
    [118] F Garcia-Ruiz, S Sankaran, JM Maja, WS Lee, J Rasmussen, R. Ehsani Comparison
    of two aerial imaging platforms for identification of Huanglongbing-infected citrus
    trees Comput Electron Agric, 91 (2013), pp. 106-115, 10.1016/J.COMPAG.2012.12.002
    View PDFView articleView in ScopusGoogle Scholar [119] U Sivarajah, MM Kamal,
    Z Irani, V. Weerakkody Critical analysis of Big Data challenges and analytical
    methods J Bus Res, 70 (2017), pp. 263-286, 10.1016/J.JBUSRES.2016.08.001 View
    PDFView articleView in ScopusGoogle Scholar [120] M Chi, A Plaza, JA Benediktsson,
    Z Sun, J Shen, Y. Zhu Big Data for Remote Sensing: Challenges and Opportunities
    Proc IEEE, 104 (2016), pp. 2207-2219, 10.1109/JPROC.2016.2598228 View in ScopusGoogle
    Scholar [121] K Tesfaye, K Sonder, J Caims, C Magorokosho, A Tarekegn, GT Kassie,
    et al. Targeting drought-tolerant maize varieties in southern Africa: a geospatial
    crop modeling approach using big data Int Food Agribus Manag Rev, 19 (2016) Google
    Scholar [122] B Vandana, SS. Kumar A novel approach using big data analytics to
    improve the crop yield in precision agriculture 2018 3rd IEEE Int Conf Recent
    Trends Electron Inf Commun Technol RTEICT 2018 - Proc (2018), pp. 824-827, 10.1109/RTEICT42901.2018.9012549
    View in ScopusGoogle Scholar [123] S Sharma, G Rathee, H. Saini Big data analytics
    for crop prediction mode using optimization technique PDGC 2018 - 2018 5th Int
    Conf Parallel, Distrib Grid Comput (2018), pp. 760-764, 10.1109/PDGC.2018.8746001
    View in ScopusGoogle Scholar [124] A Ani, P. Gopalakirishnan Automated Hydroponic
    Drip Irrigation Using Big Data Proc 2nd Int Conf Inven Res Comput Appl ICIRCA
    2020 (2020), pp. 370-375, 10.1109/ICIRCA48905.2020.9182908 View in ScopusGoogle
    Scholar [125] P Zhang, Q Zhang, F Liu, J Li, N Cao, C. Song The Construction of
    the Integration of Water and Fertilizer Smart Water Saving Irrigation System Based
    on Big Data Proc - 2017 IEEE Int Conf Comput Sci Eng IEEE/IFIP Int Conf Embed
    Ubiquitous Comput CSE EUC 2017, 2 (2017), pp. 392-397, 10.1109/CSE-EUC.2017.258
    View in ScopusGoogle Scholar [126] R Sharma, SS Kamble, A Gunasekaran, V Kumar,
    A. Kumar A systematic literature review on machine learning applications for sustainable
    agriculture supply chain performance Comput Oper Res, 119 (2020), Article 104926,
    10.1016/J.COR.2020.104926 View PDFView articleView in ScopusGoogle Scholar [127]
    T Talaviya, D Shah, N Patel, H Yagnik, M. Shah Implementation of artificial intelligence
    in agriculture for optimisation of irrigation and application of pesticides and
    herbicides Artif Intell Agric, 4 (2020), pp. 58-73, 10.1016/J.AIIA.2020.04.002
    View PDFView articleView in ScopusGoogle Scholar [128] M Mohri, A Rostamizadeh,
    A. Talwalkar Foundations in Machine learning SpringerBriefs Comput Sci, 0 (2014),
    pp. 39-44 Google Scholar [129] KG Liakos, P Busato, D Moshou, S Pearson, D. Bochtis
    Machine Learning in Agriculture: A Review Sensors, 18 (2018), p. 2674, 10.3390/S18082674
    Page2018;18:2674 View in ScopusGoogle Scholar [130] G Xu, H Li, S Liu, K Yang,
    X. Lin VerifyNet: Secure and Verifiable Federated Learning IEEE Trans Inf Forensics
    Secur, 15 (2020), pp. 911-926, 10.1109/TIFS.2019.2929409 View in ScopusGoogle
    Scholar [131] E Kamir, F Waldner, Z Hochman, E Kamir, F Waldner, Z. Hochman Estimating
    wheat yields in Australia using climate records, satellite image time series and
    machine learning methods JPRS, 160 (2020), pp. 124-135, 10.1016/J.ISPRSJPRS.2019.11.008
    View PDFView articleView in ScopusGoogle Scholar [132] H Aghighi, M Azadbakht,
    D Ashourloo, HS Shahrabi, S. Radiom Machine Learning Regression Techniques for
    the Silage Maize Yield Prediction Using Time-Series Images of Landsat 8 OLI IEEE
    J Sel Top Appl Earth Obs Remote Sens, 11 (2018), pp. 4563-4577, 10.1109/JSTARS.2018.2823361
    View in ScopusGoogle Scholar [133] S Kulkarni, SN Mandal, GS Sharma, MR Mundada,
    Meeradevi Predictive Analysis to Improve Crop Yield using a Neural Network Model
    2018 Int Conf Adv Comput Commun Informatics, ICACCI 2018 (2018), pp. 74-79, 10.1109/ICACCI.2018.8554851
    View in ScopusGoogle Scholar [134] P Feng, B Wang, DL Liu, C Waters, D Xiao, L
    Shi, et al. Dynamic wheat yield forecasts are improved by a hybrid approach using
    a biophysical model and machine learning technique Agric For Meteorol, 285–286
    (2020), Article 107922, 10.1016/J.AGRFORMET.2020.107922 View PDFView articleView
    in ScopusGoogle Scholar [135] Y Cakir, M Kirci, EO. Gunes Yield prediction of
    wheat in south-east region of Turkey by using artificial neural networks 2014
    3rd Int Conf Agro-Geoinformatics, Agro-Geoinformatics 2014 (2014), 10.1109/AGRO-GEOINFORMATICS.2014.6910609
    Google Scholar [136] XE Pantazi, D Moshou, T Alexandridis, RL Whetton, AM. Mouazen
    Wheat yield prediction using machine learning and advanced sensing techniques
    Comput Electron Agric, 121 (2016), pp. 57-65, 10.1016/J.COMPAG.2015.11.018 View
    PDFView articleView in ScopusGoogle Scholar [137] Y Everingham, J Sexton, D Skocaj,
    G. Inman-Bamber Accurate prediction of sugarcane yield using a random forest algorithm
    Agron Sustain Dev, 36 (2016), pp. 1-9, 10.1007/S13593-016-0364-Z 2016 362 Google
    Scholar [138] I Ahmad, U Saeed, M Fahad, A Ullah, M Habib ur Rahman, A Ahmad,
    et al. Yield Forecasting of Spring Maize Using Remote Sensing and Crop Modeling
    in Faisalabad-Punjab Pakistan J Indian Soc Remote Sens, 46 (2018), pp. 1701-1711,
    10.1007/S12524-018-0825-8 2018 4610 View in ScopusGoogle Scholar [139] MS Verma,
    SD. Gawade A machine learning approach for prediction system and analysis of nutrients
    uptake for better crop growth in the Hydroponics system Proc - Int Conf Artif
    Intell Smart Syst ICAIS 2021 (2021), pp. 150-156, 10.1109/ICAIS50930.2021.9395956
    View in ScopusGoogle Scholar [140] MA Ebrahimi, MH Khoshtaghaza, S Minaei, B.
    Jamshidi Vision-based pest detection based on SVM classification method Comput
    Electron Agric, 137 (2017), pp. 52-58, 10.1016/J.COMPAG.2017.03.016 View PDFView
    articleView in ScopusGoogle Scholar [141] D Moshou, XE Pantazi, D Kateris, I.
    Gravalos Water stress detection based on optical multisensor fusion with a least
    squares support vector machine classifier Biosyst Eng, 117 (2014), pp. 15-22,
    10.1016/J.BIOSYSTEMSENG.2013.07.008 View PDFView articleView in ScopusGoogle Scholar
    [142] R Barosa, SIS Hassen, L. Nagowah Smart Aquaponics with Disease Detection
    2nd Int Conf Next Gener Comput Appl 2019, NextComp 2019 - Proc (2019), 10.1109/NEXTCOMP.2019.8883437
    Google Scholar [143] A Etienne, D. Saraswat Machine learning approaches to automate
    weed detection by UAV based sensors SPIE, 11008 (2019), Article 110080R, 10.1117/12.2520536
    View in ScopusGoogle Scholar [144] A Bakhshipour, A. Jafari Evaluation of support
    vector machine and artificial neural networks in weed detection using shape features
    Comput Electron Agric, 145 (2018), pp. 153-160, 10.1016/J.COMPAG.2017.12.032 View
    PDFView articleView in ScopusGoogle Scholar [145] A Morellos, XE Pantazi, D Moshou,
    T Alexandridis, R Whetton, G Tziotzios, et al. Machine learning based prediction
    of soil total nitrogen, organic carbon and moisture content by using VIS-NIR spectroscopy
    Biosyst Eng, 152 (2016), pp. 104-116, 10.1016/J.BIOSYSTEMSENG.2016.04.018 View
    PDFView articleView in ScopusGoogle Scholar [146] E Acar, MS Ozerdem, BB. Ustundag
    Machine learning based regression model for prediction of soil surface humidity
    over moderately vegetated fields 2019 8th Int Conf Agro-Geoinformatics, Agro-Geoinformatics
    2019 (2019), 10.1109/AGRO-GEOINFORMATICS.2019.8820461 Google Scholar [147] WM
    Ridwan, M Sapitang, A Aziz, KF Kushiar, AN Ahmed, A. El-Shafie Rainfall forecasting
    model using machine learning methods: Case study Terengganu Malaysia. Ain Shams
    Eng J, 12 (2021), pp. 1651-1663, 10.1016/J.ASEJ.2020.09.011 View PDFView articleView
    in ScopusGoogle Scholar [148] M Taki, S Abdanan Mehdizadeh, A Rohani, M Rahnama,
    M Rahmati-Joneidabad Applied machine learning in greenhouse simulation; new application
    and analysis Inf Process Agric, 5 (2018), pp. 253-268, 10.1016/J.INPA.2018.01.003
    View PDFView articleView in ScopusGoogle Scholar [149] J. Schmidhuber Deep Learning
    in Neural Networks: An Overview Neural Networks, 61 (2014), pp. 85-117, 10.1016/j.neunet.2014.09.003
    Google Scholar [150] Canziani A, Paszke A, Culurciello E. An Analysis of Deep
    Neural Network Models for Practical Applications 2016. Google Scholar [151] S
    Albawi, TA Mohammed, S Al-Zawi Understanding of a convolutional neural network
    Proc 2017 Int Conf Eng Technol ICET 2017 (2018), 10.1109/ICENGTECHNOL.2017.8308186
    2018-January:1–6 Google Scholar [152] A Kamilaris, FX. Prenafeta-Boldu Deep learning
    in agriculture: A survey Comput Electron Agric, 147 (2018), pp. 70-90, 10.1016/j.compag.2018.02.016
    View PDFView articleView in ScopusGoogle Scholar [153] V Kakani, VH Nguyen, BP
    Kumar, H Kim, VR. Pasupuleti A critical review on computer vision and artificial
    intelligence in food industry J Agric Food Res, 2 (2020), 10.1016/J.JAFR.2020.100033
    Google Scholar [154] Schwalbert RA, Amado T, Corassa G, Pierre Pott L, Prasad
    Pvv, Ciampitti IA. Satellite-based soybean yield forecast: Integrating machine
    learning and weather data for improving crop yield prediction in southern Brazil
    2019. https://doi.org/10.1016/j.agrformet.2019.107886. Google Scholar [155] Z
    Chu, J. Yu An end-to-end model for rice yield prediction using deep learning fusion
    Comput Electron Agric, 174 (2020), 10.1016/J.COMPAG.2020.105471 Google Scholar
    [156] D Tedesco-Oliveira, R Pereira da Silva, W Maldonado, C Zerbato Convolutional
    neural networks in predicting cotton yield from images of commercial fields Comput
    Electron Agric, 171 (2020), Article 105307, 10.1016/J.COMPAG.2020.105307 View
    PDFView articleView in ScopusGoogle Scholar [157] Y Chen, WS Lee, H Gan, N Peres,
    C Fraisse, Y Zhang, et al. Strawberry Yield Prediction Based on a Deep Neural
    Network Using High-Resolution Aerial Orthoimages Remote Sens, 11 (2019), p. 1584,
    10.3390/RS11131584 Page2019;11:1584 View in ScopusGoogle Scholar [158] L Gong,
    M Yu, S Jiang, V Cutsuridis, S. Pearson Deep Learning Based Prediction on Greenhouse
    Crop Yield Combined TCN and RNN Sensors, 21 (2021), p. 4537, 10.3390/S21134537
    Page2021;21:4537 View in ScopusGoogle Scholar [159] L Zhang, Z Xu, D Xu, J Ma,
    Y Chen, Z. Fu Growth monitoring of greenhouse lettuce based on a convolutional
    neural network Hortic Res, 7 (2020), 10.1038/S41438-020-00345-6 Google Scholar
    [160] X Song, G Zhang, F Liu, D Li, Y Zhao, J. Yang Modeling spatio-temporal distribution
    of soil moisture by deep learning-based cellular automata model J Arid Land, 8
    (2016), pp. 734-748, 10.1007/S40333-016-0049-0 View in ScopusGoogle Scholar [161]
    A Reyes-Yanes, P Martinez, R. Ahmad Real-time growth rate and fresh weight estimation
    for little gem romaine lettuce in aquaponic grow beds Comput Electron Agric, 179
    (2020), Article 105827, 10.1016/j.compag.2020.105827 View PDFView articleView
    in ScopusGoogle Scholar [162] M Dyrmann, H Karstoft, HS. Midtiby Plant species
    classification using deep convolutional neural network Biosyst Eng, 151 (2016),
    pp. 72-80, 10.1016/J.BIOSYSTEMSENG.2016.08.024 View PDFView articleView in ScopusGoogle
    Scholar [163] S Sladojevic, M Arsenovic, A Anderla, D Culibrk, D. Stefanovic Deep
    Neural Networks Based Recognition of Plant Diseases by Leaf Image Classification
    Comput Intell Neurosci (2016), p. 2016, 10.1155/2016/3289801 Google Scholar [164]
    SP Mohanty, DP Hughes, M. Salathé Using Deep Learning for Image-Based Plant Disease
    Detection Front Plant Sci, 0 (2016), p. 1419, 10.3389/FPLS.2016.01419 View in
    ScopusGoogle Scholar [165] A Fuentes, S Yoon, SC Kim, DS. Park A Robust Deep-Learning-Based
    Detector for Real-Time Tomato Plant Diseases and Pests Recognition Sensors, 17
    (2017), p. 2022, 10.3390/S17092022 Page2017;17:2022 View in ScopusGoogle Scholar
    [166] A Anagnostis, G Asiminari, E Papageorgiou, D. Bochtis A Convolutional Neural
    Networks Based Method for Anthracnose Infected Walnut Tree Leaves Identification
    Appl Sci, 10 (2020), p. 469, 10.3390/APP10020469 Page2020;10:469 View in ScopusGoogle
    Scholar [167] I Sa, Z Ge, F Dayoub, B Upcroft, T Perez, C. McCool DeepFruits:
    A Fruit Detection System Using Deep Neural Networks Sensors, 16 (2016), p. 1222,
    10.3390/S16081222 Page2016;16:1222 View in ScopusGoogle Scholar [168] SW Chen,
    SS Shivakumar, S Dcunha, J Das, E Okon, C Qu, et al. Counting Apples and Oranges
    with Deep Learning: A Data-Driven Approach IEEE Robot Autom Lett, 2 (2017), pp.
    781-788, 10.1109/LRA.2017.2651944 View in ScopusGoogle Scholar [169] Y Tian, G
    Yang, Z Wang, H Wang, E Li, Z. Liang Apple detection during different growth stages
    in orchards using the improved YOLO-V3 model Comput Electron Agric, 157 (2019),
    pp. 417-426, 10.1016/J.COMPAG.2019.01.012 View PDFView articleView in ScopusGoogle
    Scholar [170] F Terribile, A Agrillo, A Bonfante, G Buscemi, M Colandrea, A D''Antonio,
    et al. A Web-based spatial decision supporting system for land management and
    soil conservation Solid Earth, 6 (2015), pp. 903-928, 10.5194/SE-6-903-2015 View
    in ScopusGoogle Scholar [171] A Felsberger, B Oberegger, G. Reiner A Review of
    Decision Support Systems for Manufacturing Systems Undefined (2016) Google Scholar
    [172] P Taechatanasat, L. Armstrong Decision Support System Data for Farmer Decision
    Making ECU Publ Post (2013), p. 2014 Google Scholar [173] H Navarro-Hellín, J
    Martínez-del-Rincon, R Domingo-Miguel, F Soto-Valles, R. Torres-Sánchez A decision
    support system for managing irrigation in agriculture Comput Electron Agric, 124
    (2016), pp. 121-131, 10.1016/J.COMPAG.2016.04.003 View PDFView articleView in
    ScopusGoogle Scholar [174] E Giusti, S. Marsili-Libelli A Fuzzy Decision Support
    System for irrigation and water conservation in agriculture Environ Model Softw,
    63 (2015), pp. 73-86, 10.1016/J.ENVSOFT.2014.09.020 View PDFView articleView in
    ScopusGoogle Scholar [175] MDM Kadiyala, S Nedumaran, P, S.C Singh, MA Irshad,
    MCS Bantilan An integrated crop model and GIS decision support system for assisting
    agronomic decision making under climate change Sci Total Environ, 521–522 (2015),
    pp. 123-134, 10.1016/J.SCITOTENV.2015.03.097 View PDFView articleView in ScopusGoogle
    Scholar [176] KO Wenkel, M Berg, W Mirschel, R Wieland, C Nendel, B. Köstner LandCaRe
    DSS - An interactive decision support system for climate change impact assessment
    and the analysis of potential agricultural land use adaptation strategies J Environ
    Manage, 127 (2013), 10.1016/J.JENVMAN.2013.02.051 Google Scholar [177] DD Bochtis,
    CG Sørensen, O. Green A DSS for planning of soil-sensitive field operations Decis
    Support Syst, 53 (2012), pp. 66-75, 10.1016/J.DSS.2011.12.005 View PDFView articleView
    in ScopusGoogle Scholar [178] A Ghandar, A Ahmed, S Zulfiqar, Z Hua, M Hanai,
    G. Theodoropoulos A decision support system for urban agriculture using digital
    twin: A case study with aquaponics IEEE Access, 9 (2021), pp. 35691-35708, 10.1109/ACCESS.2021.3061722
    View in ScopusGoogle Scholar [179] JA Sánchez-Molina, N Pérez, F Rodríguez, JL
    Guzmán, JC. López Support system for decision making in the management of the
    greenhouse environmental based on growth model for sweet pepper Agric Syst, 139
    (2015), pp. 144-152, 10.1016/J.AGSY.2015.06.009 View PDFView articleView in ScopusGoogle
    Scholar [180] D Nestel, Y Cohen, B Shaked, V Alchanatis, E Nemny-Lavy, MA Miranda,
    et al. An Integrated Decision Support System for Environmentally-Friendly Management
    of the Ethiopian Fruit Fly in Greenhouse Crops Agron, 9 (2019), p. 459, 10.3390/AGRONOMY9080459
    Page2019;9:459 View in ScopusGoogle Scholar [181] G Aiello, I Giovino, M Vallone,
    P Catania, A. Argento A decision support system based on multisensor data fusion
    for sustainable greenhouse management J Clean Prod, 172 (2018), pp. 4057-4065,
    10.1016/J.JCLEPRO.2017.02.197 View PDFView articleView in ScopusGoogle Scholar
    [182] J Cañadas, JA Sánchez-Molina, F Rodríguez, IM. del Águila Improving automatic
    climate control with decision support techniques to minimize disease effects in
    greenhouse tomatoes Inf Process Agric, 4 (2017), pp. 50-63, 10.1016/J.INPA.2016.12.002
    View PDFView articleView in ScopusGoogle Scholar [183] RM Sampurno, KB Seminar,
    Y. Suharnoto Weed control decision support system based on precision agriculture
    approach Telkomnika (Telecommunication Comput Electron Control, 12 (2014), pp.
    475-484, 10.12928/TELKOMNIKA.V12I2.1982 View in ScopusGoogle Scholar [184] L Wang,
    M Törngren, M. Onori Current status and advancement of cyber-physical systems
    in manufacturing J Manuf Syst, 37 (2015), pp. 517-527, 10.1016/J.JMSY.2015.04.008
    View PDFView articleView in ScopusGoogle Scholar [185] DGS Pivoto, LFF de Almeida,
    R da Rosa Righi, JJPC Rodrigues, AB Lugli, AM. Alberti Cyber-physical systems
    architectures for industrial internet of things applications in Industry 4.0:
    A literature review J Manuf Syst, 58 (2021), pp. 176-192, 10.1016/J.JMSY.2020.11.017
    View PDFView articleView in ScopusGoogle Scholar [186] AF Jimenez, PF Cardenas,
    F Jimenez, A Canales, A. López A cyber-physical intelligent agent for irrigation
    scheduling in horticultural crops Comput Electron Agric, 178 (2020), Article 105777,
    10.1016/J.COMPAG.2020.105777 View PDFView articleView in ScopusGoogle Scholar
    [187] B Bagheri, S Yang, HA Kao, J. Lee Cyber-physical systems architecture for
    self-aware machines in industry 4.0 environment IFAC-PapersOnLine, 28 (2015),
    pp. 1622-1627, 10.1016/J.IFACOL.2015.06.318 View PDFView articleView in ScopusGoogle
    Scholar [188] A Selmani, H Oubehar, M Outanoute, A Ed-Dahhak, M Guerbaoui, A Lachhab,
    et al. Agricultural cyber-physical system enabled for remote management of solar-powered
    precision irrigation Biosyst Eng, 177 (2019), pp. 18-30, 10.1016/J.BIOSYSTEMSENG.2018.06.007
    View PDFView articleView in ScopusGoogle Scholar [189] A Nayak, RR Levalle, S
    Lee, SY. Nof Resource sharing in cyber-physical systems: modelling framework and
    case studies Http://DxDoiOrg/101080/0020754320161146419, 54 (2016), pp. 6969-6983,
    10.1080/00207543.2016.1146419 View in ScopusGoogle Scholar [190] N Chen, X Zhang,
    C. Wang Integrated open geospatial web service enabled cyber-physical information
    infrastructure for precision agriculture monitoring Comput Electron Agric, 111
    (2015), pp. 78-91, 10.1016/J.COMPAG.2014.12.009 View PDFView articleView in ScopusGoogle
    Scholar [191] DVS Srikar, KC Sairam, T Srikanth, G Narayanan, K Vrinda, DG. Kurup
    Implementation and Testing of Cyber Physical System in Laboratory for Precision
    Agriculture 2018 Int Conf Adv Comput Commun Informatics, ICACCI 2018 (2018), pp.
    1906-1908, 10.1109/ICACCI.2018.8554601 View in ScopusGoogle Scholar [192] I Ahmad,
    K. Pothuganti Smart Field Monitoring using ToxTrac: A Cyber-Physical System Approach
    in Agriculture Proc - Int Conf Smart Electron Commun ICOSEC 2020 (2020), pp. 723-727,
    10.1109/ICOSEC49089.2020.9215282 Google Scholar [193] P Guo, PO Dusadeerungsikul,
    SY. Nof Agricultural cyber physical system collaboration for greenhouse stress
    management Comput Electron Agric, 150 (2018), pp. 439-454, 10.1016/J.COMPAG.2018.05.022
    View PDFView articleView in ScopusGoogle Scholar [194] B Stark, S Rider, YQ. Chen
    Optimal pest management by networked unmanned cropdusters in precision agriculture:
    A cyber-physical system approach IFAC Proc Vol, 46 (2013), pp. 296-302, 10.3182/20131120-3-FR-4045.00019
    View PDFView articleView in ScopusGoogle Scholar [195] C-R Rad, O Hancu, I-A Takacs,
    G. Olteanu Smart Monitoring of Potato Crop: A Cyber-Physical System Architecture
    Model in the Field of Precision Agriculture Agric Agric Sci Procedia, 6 (2015),
    pp. 73-79, 10.1016/J.AASPRO.2015.08.041 View PDFView articleGoogle Scholar [196]
    K Antonopoulos, C Panagiotou, CP Antonopoulos, NS. Voros A-FARM Precision Farming
    CPS Platform. 10th Int Conf Information Intell Syst Appl IISA, 2019 (2019), 10.1109/IISA.2019.8900717
    Google Scholar [197] D Cimino, A Ferrero, L Queirolo, F Bellotti, R Berta, A.
    De Gloria A low-cost, open-source cyber physical system for automated, remotely
    controlled precision agriculture Lect Notes Electr Eng, 409 (2017), pp. 191-203,
    10.1007/978-3-319-47913-2_23 View in ScopusGoogle Scholar [198] C Verdouw, B Tekinerdogan,
    A Beulens, S. Wolfert Digital twins in smart farming Agric Syst, 189 (2021), Article
    103046, 10.1016/J.AGSY.2020.103046 View PDFView articleView in ScopusGoogle Scholar
    [199] D Jones, C Snider, A Nassehi, J Yon, B Hicks Characterising the Digital
    Twin: A systematic literature review CIRP J Manuf Sci Technol, 29 (2020), pp.
    36-52, 10.1016/J.CIRPJ.2020.02.002 View PDFView articleView in ScopusGoogle Scholar
    [200] A Ahmed, S Zulfiqar, A Ghandar, Y Chen, M Hanai, G. Theodoropoulos Digital
    Twin Technology for Aquaponics: Towards Optimizing Food Production with Dynamic
    Data Driven Application Systems Commun Comput Inf Sci, 1094 (2019), pp. 3-14,
    10.1007/978-981-15-1078-6_1 View in ScopusGoogle Scholar [201] A Kampker, V Stich,
    P Jussen, B Moser, J. Kuntz Business models for industrial smart services - the
    example of a digital twin for a product-service-system for potato harvesting Procedia
    CIRP, 83 (2019), pp. 534-540, 10.1016/J.PROCIR.2019.04.114 View PDFView articleView
    in ScopusGoogle Scholar [202] N Tsolakis, D Bechtsis, D. Bochtis AgROS: A Robot
    Operating System Based Emulation Tool for Agricultural Robotics Agron, 9 (2019),
    p. 403, 10.3390/AGRONOMY9070403 Page2019;9:403 Google Scholar [203] T Machl, A
    Donaubauer, TH. Kolbe Planning agricultural core road networks based on a digital
    twin of the cultivated landscape J Digit Landsc Archit, 2019 (2019), pp. 316-327,
    10.14627/537663034 View in ScopusGoogle Scholar [204] RG Alves, G Souza, RF Maia,
    ALH Tran, C Kamienski, JP Soininen, et al. A digital twin for smart farming 2019
    IEEE Glob Humanit Technol Conf GHTC 2019 (2019), 10.1109/GHTC46095.2019.9033075
    Google Scholar [205] J Monteiro, J Barata, M Veloso, L Veloso, J. Nunes Towards
    sustainable digital twins for vertical farming 2018 13th Int Conf Digit Inf Manag
    ICDIM 2018 (2018), pp. 234-239, 10.1109/ICDIM.2018.8847169 View in ScopusGoogle
    Scholar [206] Verdouw C, Kruize J. Digital twins in farm management : illustrations
    from the FIWARE accelerators SmartAgriFood and Fractals. Undefined 2017. Google
    Scholar [207] P Moghadam, T Lowe, EJ. Edwards Digital Twin for the Future of Orchard
    Production Systems Proc, 36 (2019), p. 92, 10.3390/PROCEEDINGS2019036092 Page2020;36:92
    Google Scholar [208] S Aydin, MN. Aydin Semantic and syntactic interoperability
    for agricultural open-data platforms in the context of IoT using crop-specific
    trait ontologies Appl Sci, 10 (2020), 10.3390/app10134460 Google Scholar [209]
    Y He, J Guo, X. Zheng From Surveillance to Digital Twin: Challenges and Recent
    Advances of Signal Processing for Industrial Internet of Things IEEE Signal Process
    Mag, 35 (2018), pp. 120-129, 10.1109/MSP.2018.2842228 View in ScopusGoogle Scholar
    [210] MS Farooq, S Riaz, A Abid, K Abid, MA. Naeem A Survey on the Role of IoT
    in Agriculture for the Implementation of Smart Farming IEEE Access, 7 (2019),
    pp. 156237-156271, 10.1109/ACCESS.2019.2949703 View in ScopusGoogle Scholar [211]
    A Villa-Henriksen, GTC Edwards, LA Pesonen, O Green, CAG. Sørensen Internet of
    Things in arable farming: Implementation, applications, challenges and potential
    Biosyst Eng, 191 (2020), pp. 60-84, 10.1016/J.BIOSYSTEMSENG.2019.12.013 View PDFView
    articleView in ScopusGoogle Scholar [212] HM Jawad, R Nordin, SK Gharghan, AM
    Jawad, M. Ismail Energy-efficient wireless sensor networks for precision agriculture:
    A review Sensors (Switzerland), 17 (2017), p. 1781, 10.3390/s17081781 View in
    ScopusGoogle Scholar [213] L Sigrist, N Stricker, D Bernath, J Beutel, L. Thiele
    Thermoelectric Energy Harvesting from Gradients in the Earth Surface IEEE Trans
    Ind Electron, 67 (2020), pp. 9460-9470, 10.1109/TIE.2019.2952796 View in ScopusGoogle
    Scholar [214] AR Yanes, P Martinez, R. Ahmad Towards automated aquaponics: A review
    on monitoring, IoT, and smart systems J Clean Prod (2020), 10.1016/j.jclepro.2020.121571
    Google Scholar [215] N Brinis, LA. Saidane Context Aware Wireless Sensor Network
    Suitable for Precision Agriculture Wirel Sens Netw (2016), 10.4236/wsn.2016.81001
    Google Scholar [216] M Zimmerling, L Mottola, S. Santini Synchronous Transmissions
    in Low-Power Wireless: A Survey of Communication Protocols and Network Services
    ACM Comput Surv, 53 (2021), 10.1145/3410159 Google Scholar [217] F Tonolini, F.
    Adib Networking across boundaries: Enabling wireless communication through the
    water-air interface SIGCOMM 2018 - Proc 2018 Conf ACM Spec Interes Gr Data Commun
    (2018), pp. 117-131, 10.1145/3230543.3230580 View in ScopusGoogle Scholar [218]
    L Chen, S Thombre, K Jarvinen, ES Lohan, A Alen-Savikko, H Leppakoski, et al.
    Robustness, Security and Privacy in Location-Based Services for Future IoT: A
    Survey IEEE Access, 5 (2017), pp. 8956-8977, 10.1109/ACCESS.2017.2695525 View
    in ScopusGoogle Scholar [219] Y Njah, M. Cheriet Parallel Route Optimization and
    Service Assurance in Energy-Efficient Software-Defined Industrial IoT Networks
    IEEE Access, 9 (2021), pp. 24682-24696, 10.1109/ACCESS.2021.3056931 View in ScopusGoogle
    Scholar [220] A Rajput, VB. Kumaravelu Scalable and sustainable wireless sensor
    networks for agricultural application of Internet of things using fuzzy c-means
    algorithm Sustain Comput Informatics Syst, 22 (2019), pp. 62-74, 10.1016/J.SUSCOM.2019.02.003
    View PDFView articleView in ScopusGoogle Scholar [221] BB Sinha, R. Dhanalakshmi
    Recent advancements and challenges of Internet of Things in smart agriculture:
    A survey Futur Gener Comput Syst, 126 (2022), pp. 169-184, 10.1016/J.FUTURE.2021.08.006
    View PDFView articleView in ScopusGoogle Scholar [222] F Caffaro, E. Cavallo The
    effects of individual variables, farming system characteristics and perceived
    barriers on actual use of smart farming technologies: Evidence from the piedmont
    region, northwestern Italy Agric, 9 (2019), 10.3390/AGRICULTURE9050111 Google
    Scholar [223] KumarPratyush JainMohit, Vera L BhansaliIshita, PatelShwetak.FarmChat
    TruongKhai Proc ACM Interactive, Mobile, Wearable Ubiquitous Technol, 2 (2018),
    pp. 1-22, 10.1145/3287048 Google Scholar [224] Mclaughlan B, Brandli J, Smith
    F. Toward Sustainable High-Yield Agriculture via Intelligent Control Systems 2015.
    Google Scholar [225] RK Kodali, S Soratkal, L. Boppana IOT based control of appliances
    Proceeding - IEEE Int Conf Comput Commun Autom ICCCA 2016 (2017), pp. 1293-1297,
    10.1109/CCAA.2016.7813918 Google Scholar [226] Abbasi R, Reyes A, Martinez E,
    Ahmad R. Real-time implementation of digital twin for robot based production line
    n.d.:4–6. Google Scholar [227] O Bermeo-Almeida, M Cardenas-Rodriguez, T Samaniego-Cobo,
    E Ferruzola-Gómez, R Cabezas-Cabezas, W. Bazán-Vera Blockchain in Agriculture:
    A Systematic Literature Review Commun Comput Inf Sci, 883 (2018), pp. 44-56, 10.1007/978-3-030-00940-3_4
    View in ScopusGoogle Scholar [228] V Saiz-Rubio, F. Rovira-Más From Smart Farming
    towards Agriculture 5.0: A Review on Crop Data Management Agron, 10 (2020), p.
    207, 10.3390/AGRONOMY10020207 Page2020;10:207 View in ScopusGoogle Scholar [229]
    X Xu, Y Lu, B Vogel-Heuser, L. Wang Industry 4.0 and Industry 5.0—Inception, conception
    and perception J Manuf Syst, 61 (2021), pp. 530-535, 10.1016/J.JMSY.2021.10.006
    View PDFView articleView in ScopusGoogle Scholar [230] PKR Maddikunta, Q-V Pham,
    P B, N Deepa, K Dev, TR Gadekallu, et al. Industry 5.0: A survey on enabling technologies
    and potential applications J Ind Inf Integr (2021), Article 100257, 10.1016/J.JII.2021.100257
    Google Scholar Cited by (119) Design and implementation of a cost-aware and smart
    oyster mushroom cultivation system 2024, Smart Agricultural Technology Show abstract
    Recent advances in environmental and agricultural applications of hydrochars:
    A review 2024, Environmental Research Show abstract A quality-based sustainable
    supply chain architecture for perishable products using image processing in the
    era of industry 4.0 2024, Journal of Cleaner Production Show abstract Design and
    development of intelligent control strategies and algorithms for automated control
    of biotechnical objects under uncertainty 2024, Decision Analytics Journal Show
    abstract Assessing the influence of artificial intelligence on agri-food supply
    chain performance: the mediating effect of distribution network efficiency 2024,
    Technological Forecasting and Social Change Show abstract Occlusion-aware fruit
    segmentation in complex natural environments under shape prior 2024, Computers
    and Electronics in Agriculture Show abstract View all citing articles on Scopus
    1 www.sciencedirect.com 2 www.scopus.com 3 ieeexplore.ieee.org © 2022 The Author(s).
    Published by Elsevier B.V. Recommended articles A lightweight network for mummy
    berry disease recognition Smart Agricultural Technology, Volume 2, 2022, Article
    100044 Hongchun Qu, Min Sun View PDF What really impedes the scaling out of digital
    services for agriculture? A Kenyan users’ perspective Smart Agricultural Technology,
    Volume 2, 2022, Article 100034 John Kieti, …, Tonny Kerage Omwansa View PDF Exploring
    the susceptibility of smart farming: Identified opportunities and challenges Smart
    Agricultural Technology, Volume 2, 2022, Article 100026 Elsa Jerhamre, …, Vera
    van Zoest View PDF Show 3 more articles Article Metrics Citations Citation Indexes:
    83 Captures Readers: 562 Social Media Shares, Likes & Comments: 8 View details
    About ScienceDirect Remote access Shopping cart Advertise Contact and support
    Terms and conditions Privacy policy Cookies are used by this site. Cookie settings
    | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V.,
    its licensors, and contributors. All rights are reserved, including those for
    text and data mining, AI training, and similar technologies. For all open access
    content, the Creative Commons licensing terms apply.'
  inline_citation: '>'
  journal: Smart agricultural technology
  limitations: '>'
  pdf_link: null
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: The digitization of agricultural industry – a systematic literature review
    on agriculture 4.0
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1155/2021/5584754
  analysis: '>'
  authors:
  - Rayda Ben Ayed
  - Mohsen Hanana
  citation_count: 69
  full_citation: '>'
  full_text: ">\nReview Article\nArtificial Intelligence to Improve the Food and Agriculture\
    \ Sector\nRayda Ben Ayed\n1 and Mohsen Hanana\n2\n1Laboratory of Molecular and\
    \ Cellular Screening Processes, Centre of Biotechnology of Sfax, P. B. 1177, Sfax\
    \ 3018, Tunisia\n2Laboratory of Extremophile Plants, Biotechnology Center of Borj-C´edria,\
    \ B. P. 901, Hammam Lif 2050, Tunisia\nCorrespondence should be addressed to Rayda\
    \ Ben Ayed; raydabenayed@yahoo.fr\nReceived 19 February 2021; Revised 6 April\
    \ 2021; Accepted 12 April 2021; Published 22 April 2021\nAcademic Editor: Rijwan\
    \ Khan\nCopyright © 2021 Rayda Ben Ayed and Mohsen Hanana. Tis is an open access\
    \ article distributed under the Creative Commons\nAttribution License, which permits\
    \ unrestricted use, distribution, and reproduction in any medium, provided the\
    \ original work is\nproperly cited.\nTe world population is expected to reach\
    \ over 9 billion by 2050, which will require an increase in agricultural and food\n\
    production by 70% to ﬁt the need, a serious challenge for the agri-food industry.\
    \ Such requirement, in a context of resources\nscarcity, climate change, COVID-19\
    \ pandemic, and very harsh socioeconomic conjecture, is diﬃcult to fulﬁll without\
    \ the in-\ntervention of computational tools and forecasting strategy. Hereby,\
    \ we report the importance of artiﬁcial intelligence and machine\nlearning as\
    \ a predictive multidisciplinary approach integration to improve the food and\
    \ agriculture sector, yet with some\nlimitations that should be considered by\
    \ stakeholders.\n1. Introduction\nTe estimation of the global food production\
    \ must be in-\ncreased by 60–110% to feed 9-10 billion of the population by\n\
    2050 [1, 2]. Tus, the sustainability of agriculture ﬁeld is the\nkey to guarantee\
    \ food security and hunger eradication for\nthe ever-growing population. In addition,\
    \ due to the ap-\npearance of several food safety scandals and incidents in the\n\
    food sector such as bovine spongiform encephalopathy and\ndioxin in poultry [3],\
    \ a well-documented traceability system\nhas become a requirement for quality\
    \ control in the food\nchain. Moreover, weather and climate change conditions,\n\
    together with the sustainable water management due to\nwater scarcity, are crucial\
    \ challenges in the next years. For\nthese reasons, urgently, the establishment\
    \ of a strategic shift\nfrom the current paradigm of enhanced agricultural pro-\n\
    ductivity to agricultural sustainability is needed. To antici-\npate eﬃcient solutions,\
    \ helping farmers and stakeholders to\nenhance their decision by adopting sustainable\
    \ agriculture\npractices is a crucial choice, especially the use of digital\n\
    technologies including Internet of things (Iot), Artiﬁcial\nIntelligence (AI),\
    \ and cloud computing. Additionally, the\nsubsets of AI (machine and deep learning\
    \ algorithms)\ncombined with location intelligence technologies are ex-\ntensively\
    \ used. Te goal of our review is to present the main\napplications of artiﬁcial\
    \ intelligence and machine learning\ntechniques in the agri-food sector.\n2. Artificial\
    \ Intelligence and Machine\nLearning Approach\nTe artiﬁcial intelligence (AI)\
    \ is a creative tool that simulates\nthe human intelligence and ability processes\
    \ by machines,\nprincipally computer systems, robotics, and digital equip-\nment\
    \ [4]. Several applications of the AI include natural\nlanguage processing (NLP)\
    \ to comprehend human verbal\ncommunication as it is spoken, computer vision to\
    \ see an\nanalog-to-digital conversion such as video, and speech\nrecognition\
    \ and expert systems to simulate the judgment.\nTe AI encoding is based on learning\
    \ (acquire data and then\ncreate algorithms to turn them into actionable information),\n\
    reasoning (choose the right algorithm to reach a preferred\nresult), and self-correction\
    \ (continually adjust designed\nalgorithms and ensure that they provide the most\
    \ accurate\nresults) as three cognitive skills [5]. Te AI technique is being\n\
    used in several sectors which are seeing the fastest growth in\nthe recent years\
    \ such as ﬁnance, healthcare, retail, phar-\nmaceutical research, intelligent\
    \ process automation, and\nmarketing. Machine learning (ML) is one of the central\n\
    themes of AI and helps people to work more creatively and\nHindawi\nJournal of\
    \ Food Quality\nVolume 2021, Article ID 5584754, 7 pages\nhttps://doi.org/10.1155/2021/5584754\n\
    eﬃciently. In ML, statistical and mathematical methods are\nused to learn from\
    \ datasets to make data-driven predictions/\ndecisions. Several diﬀerent methods\
    \ exist for this. General\ndistinction can be made by two systems; the ﬁrst one\
    \ is the\nsymbolic approaches (the induced rules and the examples\nare explicitly\
    \ represented) and the second one is the sub-\nsymbolic approaches (artiﬁcial\
    \ neuronal networks: ANN).\nTe ML approach is classiﬁed into three major tasks:\
    \ su-\npervised,\nunsupervised,\nand\nreinforcement\nlearning.\nAccording to the\
    \ supervised learning, the aim of this ap-\nproach is to map the variables to\
    \ the preferred output\nvariable [6]. Te predictive model is created using the\
    \ labeled\ndata with the prior knowledge of the input and the desired\noutput\
    \ variables. Algorithms used under supervised learning\ntechniques are numerous,\
    \ particularly, decision trees,\nBayesian networks, and regression analysis. Concerning\
    \ the\nunsupervised learning, it includes algorithms such as Ar-\ntiﬁcial Neural\
    \ Networks (ANNs), clustering, genetic algo-\nrithm, and deep learning and uses\
    \ unlabeled datasets\nwithout prior knowledge of the input and output variables.\n\
    In fact and as mentioned by Jordan and Mitchell [7], this\ncase of unsupervised\
    \ machine learning method establishes\nthe hidden patterns by using the unlabeled\
    \ dataset and is\nprimarily used for dimensionality reduction and exploratory\n\
    data analysis. According to the third category of ML task\nnamed the reinforcement\
    \ learning, numerous algorithms are\nused for machine skill acquisition, robot\
    \ navigation, and\nreal-time decision making such as Q-learning and deep\nQ-learning.\
    \ In this case of ML task, the learner interacts with\nthe environment to collect\
    \ information and the two steps of\ntraining and testing datasets are combined.\
    \ Te learner gets\nawarded for his actions with the environment leading to an\n\
    exploration versus exploitation dilemma. Te learner must\nexplore new unknown\
    \ actions to gain more information as\ncompared to exploiting the information\
    \ already collected\n[8]. Recently, AI technology has opened the doors of its\n\
    implementation in the agri-food sector. In fact, AI ap-\nproaches oﬀer signiﬁcant\
    \ contributions and assistances to\nunderstanding a model’s identiﬁcation, service\
    \ creation, and\nthe decision-making processes as support to the diﬀerent\nagri-food’s\
    \ applications and supply chain stages. Te prin-\ncipal goal of AI in agriculture\
    \ is to provide precision and\nforecasting decision in order to improve the productivity\n\
    with resource preservation [4]; through this, AI tools pro-\npose algorithms to\
    \ evaluate performance, classify patterns,\nand to predict unexpected problems\
    \ or phenomena in order\nto solve comprehension problems in the agricultural ﬁeld\n\
    and for the identiﬁcation of pests and its suitable method of\ntreatment, as well\
    \ as the management of the irrigation\nprocess and water consumption by setting\
    \ up smart irri-\ngation systems. Abiotic and biotic factors are being assessed\n\
    through remote sensing and sensors in order to optimize\ncrop and livestock management\
    \ [4, 9]. In addition, the AI\nimplementation and applications have enormous advan-\n\
    tages which could revolutionize the agri-food sector and its\nrelated business.\
    \ Firstly, AI provides more eﬃcient ways to\nproduce, harvest, and sell crops\
    \ products as well as emphasis\non checking defective crops and improving the\
    \ potential for\nhealthy crop production and also AI is being used in\napplications\
    \ such as automated machine adjustments for\nweather forecasting and disease or\
    \ pest identiﬁcation with\n98% accuracy. In fact, recently, Sujatha et al. [10]\
    \ compared\nthe performance of machine learning (ML) and deep\nlearning (DL) methods\
    \ to detect and identify the citrus plant\nleaf disease. Tey showed that the VGG-16\
    \ deep learning\nmethod gave the best result in terms of disease classiﬁcation\n\
    accuracy. Secondly, the progression in the AI technique has\nreinforced agro-based\
    \ businesses to run more proﬁciently by\nimproving crop management practices,\
    \ thus helping many\ntech businesses invest in algorithms that are becoming useful\n\
    in agriculture as well as by solving the contrasts farmers face\nsuch as climate\
    \ variation and an infestation of pests and\nweeds that decreases yields. Indeed,\
    \ Crane-Droesch [11]\ndeveloped a novel modeling approach for augmenting\nparametric\
    \ statistical models with deep neural networks,\nwhich we term semiparametric\
    \ neural networks (SNNs), and\nby using data on corn yield from the US Midwest,\
    \ they\nshowed the outperformance of this approach in predicting\nyields of years\
    \ withheld during model training compared to\nclassical statistical methods and\
    \ fully nonparametric neural\nnetworks. Tirdly, by using AI tools, farmers could\
    \ be able to\nremain updated with the data related to weather forecasting\nand,\
    \ therefore, predicted weather data help farmers to in-\ncrease yields and proﬁts\
    \ without risking the crop, and as a\nresult, after analyzing the generated data,\
    \ AI allows the\nfarmers to better understand and learn and then to take the\n\
    precaution by implementing practices in order to make a\npunctual smart decision.\
    \ In fact, Fente and Singh [12]\ncollected diﬀerent weather parameters (temperature,\
    \ pre-\ncipitation, wind speed, pressure, dew point visibility, and\nhumidity)\
    \ from the Indian climate data center and imple-\nmented a weather forecasting\
    \ model by using a recurrent\nneural network (RNN) with the long-short-term memory\n\
    (LSTM) technique. Tey concluded that the used technique\ngave high-accuracy results\
    \ compared to other weather\nforecasting approaches. Fourthly, AI approaches are\
    \ capable\nof monitoring soil health and management by conducting\nand identifying\
    \ the possible defects and nutrient deﬁciencies\nin the soil either by image captured\
    \ with the camera rec-\nognition tool or by deep learning based tool to analyse\
    \ ﬂora\npatterns in farms and to simultaneously understand soil\ndefects, plant\
    \ pests, and diseases. In fact, Suchithra and Pai\n[13] classiﬁed and predicted\
    \ the soil fertility indices and pH\nlevels of Kerala north central laterite Indian\
    \ region soil by\nusing the Extreme Learning Machine (ELM) technique with\ndiﬀerent\
    \ activation functions such as hard limit, sine-\nsquared, triangular basis, hyperbolic\
    \ tangent, and gaussian\nradial basis. Tey revealed that the maximum performance\n\
    (80% of the accuracy rate calculations in every problem) for\nfour out of ﬁve\
    \ problems was obtained with the Gaussian\nradical basis function followed by\
    \ hyperbolic tangent.\nHowever, the best performance (90%) of the pH classiﬁ-\n\
    cation problem was given by the hyperbolic tangent, whereas\nthe moderate values\
    \ were given by the gaussian radial basis.\nFifthly, an important functional beneﬁt\
    \ of the AI technology\nemployment is the environmental protection by decreasing\n\
    pesticide usage. For example and in order to manage weeds\nfaster\nand\nwith\n\
    greater\naccuracy,\nAI\ntechniques\nby\n2\nJournal of Food Quality\nimplementing\
    \ robotics, computer vision, and machine\nlearning could help farmers to spray\
    \ chemicals only where\nthe weeds are; thus, this directly reduced the use of\
    \ the\nchemical substance spraying on the whole ﬁeld. Conse-\nquently, AI tools\
    \ are helping farmers ﬁnd more eﬃcient\nactions to protect their crops from weeds.\
    \ Finally, the\npractice of the advanced AI-based technologies has other\nadvantages\
    \ on the agri-food supply chain such as reducing\nemployee training costs, reducing\
    \ the time needed to solve\nproblems, reducing the amount of human errors, reducing\n\
    human intervention, and oﬀering an automated good, ac-\ncurate, and robust decision-making\
    \ on the right time with\nlow cost [14].\n3. Artificial Intelligence Technology\
    \ and\nApplication to Improve Agriculture and\nFood Industries\nCurrently, the\
    \ use of ML algorithms in the main four clusters\n(preproduction, production,\
    \ processing, and distribution) of\nthe agriculture supply chain is becoming more\
    \ and more\nimportant [15]. In fact, in the preproduction step, the ML\ntechnologies\
    \ are used, especially for the prediction of crop\nyield, soil properties, and\
    \ irrigation requirements. In the\nnext stage of the production phase, the ML\
    \ could be used for\ndisease detection and weather prediction. Concerning the\n\
    third cluster of the processing phase, utilization of ML\napproaches is applied,\
    \ especially to estimate of the pro-\nduction planning to reach a high and safe\
    \ quality of the\nproduct. ML algorithms could be used also to the distri-\nbution\
    \ cluster, especially in storage, transportation, and\nconsumer analysis. Te preproduction\
    \ cluster is the initial\nstep in the agriculture supply chain. It mainly concerns\
    \ the\nprediction of crop yield, soil properties, and irrigation re-\nquirement.\
    \ Many researchers report the importance of the\ncrop yield production in order\
    \ to better support plant\nmanagement. In fact, by using as an input data (equipment\n\
    requirements, nutrients, and fertilizers) in predicting eﬃ-\ncient models based\
    \ on ML algorithms, these precision ag-\nriculture tools aim to make stakeholders\
    \ and farmers\nsupport ideal decision in crop yield forecasting and improve\n\
    the smart farming practices. Recently, diﬀerent ML algo-\nrithms are used for\
    \ crop yield prediction such as the\nBayesian network, regression, decision tree,\
    \ clustering, deep\nlearning, and ANN [16–18]. According to the prediction of\n\
    soil management properties, several ML algorithms are used\nin learning soil properties.\
    \ Among them, the LS-SVM (least-\nsquares support vector machine) method was used\
    \ by\nMorellos et al. [19] to study 140 soil samples. Nahvi et al. [20]\nused\
    \ the SaE (self-adpative evolutionary) ML algorithm to\nboost the performance\
    \ of the extreme learning machine\n(ELM) architecture to estimate daily soil temperature.\
    \ Ad-\nditionally, Kumar et al. [21] proposed a novel method named\nthe CSM (Crop\
    \ Selection Method) to resolve crop selection\nproblems and help improve net yield\
    \ rate of crops over the\nseason. In addition, Ben Ayed et al. [16] analyzed 18\n\
    worldwide table olive cultivars by using morphological,\nbiological,\nand\nphysicochemical\n\
    parameters\nand\nthe\nBayesian network to study the inﬂuence of these parameters\n\
    in tolerance, productivity, and oil content. Tey revealed that\noil content was\
    \ highly inﬂuenced by the tolerance of the\ncrop. Another important parameter\
    \ in the preproduction\ncluster is the irrigation management that plays a crucial\
    \ role\nin aﬀecting the quality and quantity of the crops. In fact, to\nachieve\
    \ an eﬀective irrigation system (better decision in\nwhen, where, and how much\
    \ to irrigate), researchers used\nsoil moisture data, precipitation data, evaporation\
    \ data, and\nweather forecasts as input data for simulation and optimi-\nzation\
    \ of predicted models based on ML adequate algo-\nrithms [22]. In fact, Arvind\
    \ et al. [23] demonstrated that\nusing ML algorithm associated with other technologies\
    \ such\nas sensors, Zigbee, and Arduino microcontroller was eﬃ-\ncient for prediction\
    \ and tackles drought situations. In ad-\ndition, Cruz et al. [24] exploited the\
    \ ANN feed-forward and\nback-propagation technologies to optimize the water re-\n\
    sources in a smart farm. More recently, Choudhary et al. [25]\nused PLSR and other\
    \ regression algorithms as an artiﬁcial\nintelligence tool combined with sensors\
    \ for data collection\nand Internet of things hardware implementation to increase\n\
    eﬃciency and economic feasibility.\nTe production cluster is the second phase\
    \ in the ag-\nriculture supply chain. Tere are numerous parameters that\naﬀect\
    \ and play a key role in the crop production step. Among\nthem are the weather\
    \ forecasts (sunlight, rainfall, humidity,\netc.), crop protection against biotic\
    \ stress factors (weeds and\npathogens) and abiotic stress factors (nutrient and\
    \ water\ndeﬁciency), crop quality management, and harvesting. Many\ndiﬀerent ML\
    \ algorithms are used to simulate eﬀective\nmodels for weather prediction (ANN,\
    \ deep learning, deci-\nsion tree, ensemble learning, and instance-based learning)\n\
    [26], for crop protection (clustering and regression) [27],\nANN, deep learning\
    \ [14], weed detection (ANN, decision\ntree, deep learning, and instance-based\
    \ learning) [28], crop\nquality management (clustering and regression) [29], and\n\
    harvesting (deep neural networks, data mining techniques\nsuch as k mean clustering,\
    \ k nearest neighbor, ANN, and\nSVM) [30]. During the harvest stage which is the\
    \ ﬁnal\nhorticultural stage after the ripening of the crops, ML al-\ngorithms\
    \ are also used to predict the transformation of the\nfruit or crop color. In\
    \ fact, many research teams used ML\nalgorithms to predict the fruit ripening\
    \ stages and fruit\nmaturity such as Gao et al. [31] who achieved 98.6% clas-\n\
    siﬁcation accuracy when they used hyperspectral datasets\nand the AlexNet CNN\
    \ deep learning model to classify the\nstrawberry fruits into early-ripe and ripe\
    \ stages. Te pro-\ncessing cluster is the third stage in the agriculture supply\n\
    chain. Tere are many types of processing techniques of\nagriculture products such\
    \ as heating, cooling, milling,\nsmoking, cooking, and drying. Te choice of eﬀective\n\
    combined parameters in the processing stage results in a\nhigh quality and quantity\
    \ of food product and, at the same\ntime, avoiding overutilization of resources.\
    \ To achieve this\ngoal, several food industries use modern food processing\n\
    technologies by installing software algorithms based on ML.\nAmong the used ML\
    \ algorithms, there are genetic algorithm,\nANN, clustering, and Bayesian network\
    \ [32]. In fact, Arora\nand Mangipudi [33] proposed support vector machine\nJournal\
    \ of Food Quality\n3\n(SVM) classiﬁer and artiﬁcial neural network (ANN) models\n\
    to detect the presence of nitrosamine in the red meat food\nsamples, and the obtained\
    \ predictive modeling results\nrevealed that the highest testing accuracy was\
    \ obtained using\nthe deep learning model. Additionally, Farah et al. [34] used\n\
    diﬀerential scanning calorimetry combined with ML tools\n(such as gradient boosting\
    \ machine, random forest, RF,\nmultilayer perceptron, MLP, and GBM) to determine\
    \ the\nmilk characteristics and authenticity and to detect fraud. Te\nmost eﬃcient\
    \ results were obtained with GBM and MLP\nmachine learning tools which were able\
    \ to classify 100% of\nadulterated samples. Te distribution cluster is the ﬁnal\
    \ step\nin the agriculture supply chain. Tis stage is the connection\nbetween\
    \ food production and processing and the ﬁnal use or\nﬁnal consumer. ML algorithms\
    \ could be used in storage,\ntransportation, consumer analytics, and inventory\
    \ man-\nagement. In transportation and storage steps, the mainly\nused algorithms\
    \ are genetic algorithm, clustering, and re-\ngression. Tese predictive techniques\
    \ aim to better preserve\nthe food product quality, to ensure safe food products\
    \ and to\nminimize the product damage by tracing the product [16].\nFor the consumer\
    \ analytics, ML techniques such as deep\nlearning and ANN are used in the food\
    \ retailing phase for\npredicting consumer demand, perception, and buying be-\n\
    havior. For the inventory management, the use of ML ge-\nnetic algorithms helps\
    \ in predicting daily demand and to\nensure that there are no inventory-related\
    \ problems [35].\nExamples of AI-applied technology are numerous in the\nagri-food\
    \ sector, i.e., robotics and mechatronics [2], drones\n[2, 36], geographic information\
    \ systems (GISs) [37],\nblockchain (BC) [38], and satellite guidance [2]. Miranda\n\
    et al. [39] have reported and described these items as sensing,\nsmart, and sustainable\
    \ technologies, providing systematic\nprocess where connectivity, automation,\
    \ precision, moni-\ntoring, and digitization are prevalent [40–43]. Smart\nmechanization,\
    \ robotics, and mechatronics in agriculture\naim to reduce drudgery and minimize\
    \ inputs using highly\nautonomous and intelligent machines [2]. From horse to\n\
    tractor, robots, and intelligent vehicles, a revolutionary era\nhas come for agriculture\
    \ and food industry, from rudi-\nmentary to high eﬃciency of agriculture with\
    \ the intro-\nduction\nof\nmechanization,\ninnovative\ntechnologies,\ncomputerized\
    \ analysis, and decision, improving farming\nactivities and crop productivity\
    \ [2]. Revolutionizing ma-\nchines, often called “agribots,” are now used in agriculture\n\
    for all kinds of activities, namely, soil preparation, seed\nsowing, weed and\
    \ pest treatment, irrigation, fertilization,\nand ultimately, grain and fruit\
    \ harvesting, minimizing eﬀort\nand energy cost [2, 44–47]. As a whole crop management,\n\
    agricultural drones can be used starting from soil treatment\n(herbicide), going\
    \ to sowing step, plant treatment (pesti-\ncide), and physiological control and\
    \ observation, and ending\nwith harvest time determination [2, 36, 48–51]. Agricultural\n\
    drones are now able to supply water, fertilizers, herbicides,\nand pesticides\
    \ and even ﬁlm, capture images, and generate\nmaps in real time of plants and\
    \ ﬁeld in order to help farmers\ntake management decision [2, 48, 52–56]. Today,\
    \ farmers use\ndrones for livestock surveillance for monitoring illnesses,\ninjuries,\
    \ and even pregnancies [57]. In 2019, the worldwide\nagriculture drone market\
    \ value was about USD one million\nand is expected to reach USD 3.7 million by\
    \ 2027 [58],\nwhereas the robot and agriculture drone market is projected\nto\
    \ reach USD 23 billion by 2028 [59, 60]. Based on geospatial\ntechnology that\
    \ relies on satellite, GIS is applied on several\nﬁelds of agriculture: crop management,\
    \ irrigation control,\nyield estimation, disease and weed control, farming auto-\n\
    mation, livestock monitoring, vegetation mapping, erosion,\nand land degradation\
    \ forecast [37, 61–68]. Application of\nGIS is, therefore, suitable in precision\
    \ agriculture, real-time\ncontrol, and raising awareness and signiﬁcantly contributes\n\
    to meet the needs of continuous rise in food demand.\nBlockchain is another technology\
    \ that answers to con-\nsumer’s awareness about food origin, quality, and mainly,\n\
    safety. BC aﬀords transparency, trust, certiﬁcation, and\ntraceability of food\
    \ product supply chain from farm to fork,\nwhere every single operation and data\
    \ are timely registered,\nsaved, encrypted, and secured, not in a single central\
    \ server\nnor under a single control, but in a common platform\ndatabase where\
    \ every user could access and take part in\ntransactions [38, 69–79]. Such digital\
    \ and computerized\ntraceability of the whole food supply chain would allow\n\
    detection of deﬁciency, contamination, and adulteration of\nthe product, thus\
    \ optimizing its quality and safety; therefore,\na multitude of agencies, consortia,\
    \ and platforms were born\nin this context [79]. In 2020, the worldwide market\
    \ of BC in\nagri-food market size was about USD 133 million; it is es-\ntimated\
    \ to grow and reach around USD 950 million by 2025\n[69]. Satellite-guided technology\
    \ applied to agriculture\nimproved farm monitoring and aided mapping agricultural\n\
    zones, soil management, crop husbandry, irrigation disease\nand\nweed\ncontrol,\n\
    yield\nestimation,\nand\nharvesting\n[2, 80–88]. Hence, in the late 1900s, one\
    \ single farmer was\nable to produce food grains for 128, actually, and in the\n\
    future, through smart agriculture, this ratio will greatly\nincrease [2].\n4.\
    \ Limits and Drawbacks of AI and ML\nHowever, despite all these advantages, the\
    \ AI technology has\nalso some drawbacks representing challenges. Firstly, the\n\
    most important social challenge is the unemployment that\ncould be a threat; in\
    \ fact, smart machines and robots could\nreplace the majority of the repetitive\
    \ works and tasks; thus,\nhuman interference is becoming less, which will cause\
    \ a\nmajor problem in the employment standards. Other tech-\nnological challenges,\
    \ for instance, machines can do only\nthose tasks which they are programmed or\
    \ developed to do,\nand anything out of that they tend to crash or give irrelevant\n\
    outputs could be a major backdrop. In addition, the high\ncosts of creation and\
    \ maintenance of the smart machines as\nwell as the cleaver computers could be\
    \ considered as\ntechnological limits of the AI technologies, especially that\
    \ AI\nis updating every day which is why the hardware and\nsoftware need to get\
    \ updated with time to meet the latest\nrequirements. Machines need repairing\
    \ and maintenance\nwhich is expensive. Te creation requires huge costs as they\n\
    are very complex machines. Other issues related to these\napplications are their\
    \ high cost that could increase the price\n4\nJournal of Food Quality\nof the\
    \ products. Moreover, beyond the opportunities\naﬀorded by smart and computerized\
    \ technologies, some\nrisks and apprehensions could be posed for sustainability,\n\
    particularly the massive energy consumption, e-waste\nproblem, market concentration,\
    \ job displacement, and even\nthe ethical framework [79, 89].\n5. Conclusions\n\
    Te agriculture and food industries are one of the most vital\nﬁelds for humanity.\
    \ Te ﬁrst products of agriculture are used\nas inputs in several multiactor distributed\
    \ supply chains,\nincluding four clusters or stages of the agriculture supply\n\
    chain (preproduction, production, processing, and distri-\nbution) in order to\
    \ reach the end user or consumer. Due to\nseveral challenges in the future for\
    \ the agriculture and food\nsector and various factors such as climate change,\
    \ pop-\nulation growth, technological progress, and the state of\nnatural resources\
    \ (water, etc.), it is urgent to use the digital\ntechnologies at diﬀerent stages\
    \ of agriculture supply chain\nsuch as automation of farm machinery, use of sensors\
    \ and\nremote satellite data, artiﬁcial intelligence, machine learning\nfor improved\
    \ monitoring of crops, and water, for agriculture\nfood product traceability.\
    \ In the present study, we dem-\nonstrate the main applications of the AI and\
    \ ML algorithms\nin diﬀerent clusters of the agriculture supply chain and the\n\
    unquestionable growing tendency in the adoption of these\nalgorithms to improve\
    \ food industries.\nData Availability\nTe data used to support the ﬁndings of\
    \ this study are\navailable from the corresponding author upon request.\nConflicts\
    \ of Interest\nTe authors declare no conﬂicts of interest.\nReferences\n[1] J.\
    \ Rockstr¨om, J. Williams, G. Daily et al., “Sustainable in-\ntensiﬁcation of\
    \ agriculture for human prosperity and global\nsustainability,” Ambio, vol. 46,\
    \ no. 1, pp. 4–17, 2017.\n[2] K. R. Krishna, Push Button Agriculture: Robotics,\
    \ Drones,\nSatellite-Guided Soil and Crop Management, Apple Academic\nPress, Waretown,\
    \ NJ, USA, 2016.\n[3] R. Ben-Ayed, N. Kamoun-Grati, and A. Rebai, “An overview\n\
    of the authentication of olive tree and oil,” Comprehensive\nReviews in Food Science\
    \ and Food Safety, vol. 12, pp. 218–227,\n2013.\n[4] G. S. Patel, A. Rai, N. N.\
    \ Das, and R. P. Singh, Eds., Smart\nAgriculture: Emerging Pedagogies of Deep\
    \ Learning, Machine\nLearning and Internet of Tings, CRC Press, Boca Raton, FL,\n\
    USA, 1st edition, 2021.\n[5] A. Gharaei, M. Karimi, and S. A. Hoseini Shekarabi,\
    \ “An\nintegrated multi-product, multi-buyer supply chain under\npenalty, green,\
    \ and quality control polices and a vendor\nmanaged inventory with consignment\
    \ stock agreement: the\nouter approximation with equality relaxation and augmented\n\
    penalty algorithm,” Applied Mathematical Modelling, vol. 69,\npp. 223–254, 2019.\n\
    [6] B. B. Traore, B. Kamsu-Foguem, and F. Tangara, “Data mining\ntechniques on\
    \ satellite images for discovery of risk areas,”\nExpert Systems with Applications,\
    \ vol. 72, pp. 443–456, 2017.\n[7] M. I. Jordan and T. M. Mitchell, “Machine learning:\
    \ trends,\nperspectives, and prospects,” Science, vol. 349, 2015.\n[8] M. Mohri,\
    \ A. Rostamizadeh, and A. Talwalkar, Foundations of\nMachine Learning, MIT Press,\
    \ Cambridge, MA, USA, 2018,\nhttps://cs.nyu.edu/∼mohri/mlbook/.\n[9] A. Suprem,\
    \ N. Mahalik, and K. Kim, “A review on application\nof technology systems, standards\
    \ and interfaces for agricul-\nture and food sector,” Computer Standards & Interfaces,\n\
    vol. 35, no. 4, pp. 355–364, 2013.\n[10] R. Sujatha, J. M. Chatterjee, N. Jhanjhi,\
    \ and S. N. Brohi,\n“Performance of deep learning vs machine learning in plant\n\
    leaf disease detection,” Microprocessors and Microsystems,\nvol. 80, p. 103615,\
    \ 2021.\n[11] A. Crane-Droesch, “Machine learning methods for crop yield\nprediction\
    \ and climate change impact assessment in agri-\nculture,” Environmental Research\
    \ Letters, vol. 13, no. 11,\np. 114003, 2018.\n[12] D. N. Fente and D. K. Singh,\
    \ “Weather forecasting using\nartiﬁcial neural network,” in Proceedingsof the\
    \ 2018 Second\nInternational Conference on Inventive Communication and\nComputational\
    \ Technologies (ICICCT), Coimbatore, India,\nApril 2018.\n[13] M. S. Suchithra\
    \ and M. L. Pai, “Improving the prediction\naccuracy of soil nutrient classiﬁcation\
    \ by optimizing extreme\nlearning machine parameters,” Information Processing\
    \ in\nAgriculture, vol. 7, no. 1, pp. 72–82, 2020.\n[14] A. Kamilaris and F. X.\
    \ Prenafeta-Bold´u, “Deep learning in\nagriculture: a survey,” Computers and Electronics\
    \ in Agri-\nculture, vol. 147, pp. 70–90, 2018.\n[15] O. Ahumada and J. R. Villalobos,\
    \ “Application of planning\nmodels in the agri-food supply chain: a review,” European\n\
    Journal of Operational Research, vol. 196, no. 1, pp. 1–20, 2009.\n[16] R. Ben\
    \ Ayed, K. Ennouri, F. Ben Amar, F. Moreau, M. A. Triki,\nand A. Rebai, “Bayesian\
    \ and phylogenic approaches for\nstudying relationships among table olive cultivars,”\
    \ Bio-\nchemical Genetics, vol. 55, no. 4, pp. 300–313, 2017.\n[17] D. Elavarasan,\
    \ D. R. Vincent, V. Sharma, A. Y. Zomaya, and\nK. Srinivasan, “Forecasting yield\
    \ by integrating agrarian\nfactors and machine learning models: a survey,” Computers\n\
    and Electronics in Agriculture, vol. 155, pp. 257–282, 2018.\n[18] C. Zhang, J.\
    \ Liu, J. Shang, and H. Cai, “Capability of crop\nwater content for revealing\
    \ variability of winter wheat grain\nyield and soil moisture under limited irrigation,”\
    \ Science of\nTe Total Environment, vol. 631-632, pp. 677–687, 2018.\n[19] A.\
    \ Morellos, X.-E. Pantazi, D. Moshou et al., “Machine\nlearning based prediction\
    \ of soil total nitrogen, organic\ncarbon and moisture content by using VIS-NIR\
    \ spectros-\ncopy,” Biosystems Engineering, vol. 152, pp. 104–116, 2016.\n[20]\
    \ B. Nahvi, J. Habibi, K. Mohammadi, S. Shamshirband, and\nO. S. Al Razgan, “Using\
    \ self-adaptive evolutionary algorithm\nto improve the performance of an extreme\
    \ learning machine\nfor estimating soil temperature,” Computers and Electronics\
    \ in\nAgriculture, vol. 124, pp. 150–160, 2016.\n[21] R. Kumar, M. P. Singh, P.\
    \ Kumar, and J. P. Singh, “Crop\nSelection Method to maximize crop yield rate\
    \ using machine\nlearning technique,” in Proceedings of the 2015 International\n\
    Conference on Smart Technologies and Management for\nComputing, Communication,\
    \ Controls, Energy and Materials\n(ICSTM), pp. 138–145, Avadi, India, May 2015.\n\
    [22] A. Goap, D. Sharma, A. K. Shukla, and C. Rama Krishna, “An\nIoT based smart\
    \ irrigation management system using\nJournal of Food Quality\n5\nMachine learning\
    \ and open source technologies,” Computers\nand Electronics in Agriculture, vol.\
    \ 155, pp. 41–49, 2018.\n[23] G. Arvind, V. G. Athira, H. Haripriya, R. A. Rani,\
    \ and\nS. Aravind, “Automated irrigation with advanced seed ger-\nmination and\
    \ pest control,” in Proceedings of the 2017 IEEE\nTechnological Innovations in\
    \ ICT for Agriculture and Rural\nDevelopment (TIAR), pp. 64–67, Chennai, India,\
    \ April 2017.\n[24] J. R. Dela Cruz, R. G. Baldovino, A. A. Bandala, and\nE. P.\
    \ Dadios, “Water usage optimization of smart farm au-\ntomated irrigation system\
    \ using artiﬁcial neural network,” in\nProceedings of the 2017 5th International\
    \ Conference on In-\nformation and Communication Technology (ICoIC7), pp. 1–5,\n\
    Melaka, Malaysia, May 2017.\n[25] V. Gaurav, S. Choudhary, A. Singh, and S. Agarwal,\
    \ “Au-\ntonomous crop irrigation system using artiﬁcial intelligence,”\nInternational\
    \ Journal of Engineering and Advanced Technology\n(IJEAT), vol. 8, 2019.\n[26]\
    \ M. K. Saggi and S. Jain, “Reference evapotranspiration esti-\nmation and modeling\
    \ of the Punjab Northern India using\ndeep learning,” Computers and Electronics\
    \ in Agriculture,\nvol. 156, pp. 387–398, 2019.\n[27] A. Singh, N. Shukla, and\
    \ N. Mishra, “Social media data an-\nalytics to improve supply chain management\
    \ in food in-\ndustries,” Transportation Research Part E: Logistics and\nTransportation\
    \ Review, vol. 114, pp. 398–415, 2018.\n[28] K. Liakos, P. Busato, D. Moshou,\
    \ S. Pearson, and D. Bochtis,\n“Machine learning in agriculture: a review,” Sensors,\
    \ vol. 18,\nno. 8, p. 2674, 2018.\n[29] A. Chlingaryan, S. Sukkarieh, and B. Whelan,\
    \ “Machine\nlearning approaches for crop yield prediction and nitrogen\nstatus\
    \ estimation in precision agriculture: a review,” Com-\nputers and Electronics\
    \ in Agriculture, vol. 151, pp. 61–69, 2018.\n[30] E. J. Sadgrove, G. Falzon,\
    \ D. Miron, and D. W. Lamb, “Real-\ntime object detection in agricultural/remote\
    \ environments\nusing the multiple-expert colour feature extreme learning\nmachine\
    \ (MEC-ELM),” Computers in Industry, vol. 98,\npp. 183–191, 2018.\n[31] Z. Gao,\
    \ Y. Shao, G. Xuan, Y. Wang, Y. Liu, and X. Han, “Real-\ntime hyperspectral imaging\
    \ for the in-ﬁeld estimation of\nstrawberry ripeness with deep learning,” Artiﬁcial\
    \ Intelligence\nin Agriculture, vol. 4, pp. 31–38, 2020.\n[32] X. Ma, S. Wang,\
    \ and Q. Bai, “Coordination of production\nscheduling and vehicle routing problems\
    \ for perishable food\nproducts,” International Journal of Internet Manufacturing\n\
    and Services, vol. 6, no. 1, p. 79, 2019.\n[33] M. Arora and P. Mangipudi, “A\
    \ computer vision-based\nmethod for classiﬁcation of red meat quality after nitrosamine\n\
    appendage,” International Journal of Computational Intelli-\ngence and Applications,\
    \ vol. 20, no. 1, p. 2150005, 2021.\n[34] J. S. Farah, R. N. Cavalcanti, J. T.\
    \ Guimarães et al., “Diﬀer-\nential scanning calorimetry coupled with machine\
    \ learning\ntechnique: an eﬀective approach to determine the milk au-\nthenticity,”\
    \ Food Control, vol. 121, p. 107585, 2021.\n[35] A. Dolgui, M. K. Tiwari, Y. Sinjana,\
    \ S. K. Kumar, and\nY.-J. Son, “Optimising integrated inventory policy for per-\n\
    ishable items in a multi-stage supply chain,” International\nJournal of Production\
    \ Research, vol. 56, no. 1-2, pp. 902–925,\n2018.\n[36] K. R. Krishna, Agricultural\
    \ Drones : A Peaceful Pursuit/K,\nApple Academic Press, Palm Bay, FL, USA, 2017.\n\
    [37] S. Ravensberg, “GIS in agriculture, integrate sustainability,”\n2018, https://www.integratesustainability.com.au/2018/11/23/\n\
    gis-in-agriculture/.\n[38] G. Zhao, S. Liu, C. Lopez et al., “Blockchain technology\
    \ in\nagri-food value chain management: a synthesis of applica-\ntions, challenges\
    \ and future research directions,” Computers\nin Industry, vol. 109, pp. 83–99,\
    \ 2019.\n[39] J. Miranda, P. Ponce, A. Molina, and P. Wright, “Sensing,\nsmart\
    \ and sustainable technologies for agri-food 4.0,” Com-\nputers in Industry, vol.\
    \ 108, pp. 21–36, 2019.\n[40] L. Trivelli, A. Apicella, F. Chiarello, R. Rana,\
    \ G. Fantoni, and\nA. Tarabella, “From precision agriculture to Industry 4.0,”\n\
    British Food Journal, vol. 121, no. 8, pp. 1730–1743, 2019.\n[41] M. Bacco, P.\
    \ Barsocchi, E. Ferro, A. Gotta, and M. Ruggeri,\n“Te digitisation of agriculture:\
    \ a survey of research activities\non smart farming,” Array, vol. 3-4, p. 100009,\
    \ 2019.\n[42] M. J. O’Grady, D. Langton, and G. M. P. O’Hare, “Edge\ncomputing:\
    \ a tractable model for smart agriculture?” Artiﬁcial\nIntelligence in Agriculture,\
    \ vol. 3, pp. 42–51, 2019.\n[43] K. Jha, A. Doshi, P. Patel, and M. Shah, “A comprehensive\n\
    review on automation in agriculture using artiﬁcial intelli-\ngence,” Artiﬁcial\
    \ Intelligence in Agriculture, vol. 2, pp. 1–12,\n2019.\n[44] G. Kootstra, X.\
    \ Wang, P. M. Blok, J. Hemming, and\nE. van Henten, “Selective harvesting robotics:\
    \ current re-\nsearch, trends, and future directions,” Current Robotics Re-\n\
    ports, vol. 2, no. 1, pp. 95–104, 2021.\n[45] K. Sennaar, “Agricultural robots-present\
    \ and future appli-\ncations,”\n2021,\nhttps://emerj.com/ai-sector-overviews/\n\
    agricultural-robots-present-future-applications/.\n[46] C. W. Bac, E. J. Van Henten,\
    \ J. Hemming, and Y. Edan,\n“Harvesting robots for high-value crops: state-of-the-art\
    \ re-\nview and challenges ahead,” Journal of Field Robotics, vol. 31,\n2014.\n\
    [47] A. Zujevs, V. Osadcuks, and P. Ahrendt, “Trends in robotic\nsensor technologies\
    \ for fruit harvesting: 2010–2015,” Procedia\nComputer Science, vol. 77, 2015.\n\
    [48] J. Huuskonen and T. Oksanen, “Soil sampling with drones\nand augmented reality\
    \ in precision agriculture,” Computers\nand Electronics in Agriculture, vol. 154,\
    \ pp. 25–35, 2018.\n[49] “Importance of drone technology in Indian agriculture,\
    \ farm-\ning,” 2021, https://www.equinoxsdrones.com/blog/importance-\nof-drone-technology-in-indian-agriculture-farming.\n\
    [50] “Drones and precision agriculture: the future of farming,”\n2021, https://www.microdrones.com/en/content/drones-and-\n\
    precision-agriculture-the-future-of-farming/.\n[51] How Drones Can Help Manage\
    \ the World’s Food Supply, World\nEconomic Forum, Cologny, Switzerland, 2021,\
    \ https://www.\nweforum.org/agenda/2018/09/how-drones-can-manage-the-fo\nod-supply-chain-and-tell-you-if-what-you-eat-is-sustainable/.\n\
    [52] Agricultural Drones: A Peaceful Pursuit, Routledge & CRC\nPress, Boca Raton,\
    \ FL, USA, 2021, https://www.routledge.com/\nAgricultural-Drones-A-Peaceful-Pursuit/Krishna/p/book/9781\n\
    774636428.\n[53] How Drones are Being Used in Australia to Make Farming More\n\
    Eﬃcient, ForestTECH, Rotorua, New Zealand, 2021, https://\nforesttech.events/how-drones-are-being-used-in-australia-to-ma\n\
    ke-farming-more-eﬃcient/.\n[54] Robots and Drones: Addressing Agriculture’s Long-Term\n\
    Challenges, IDTechEx, Cambridge, UK, 2018, https://www.\nidtechex.com/fr/research-article/robots-and-drones-addressi\n\
    ng-agricultures-long-term-challenges/14126.\n[55] Drones in Agriculture Industry\
    \ Helps with Demand for Food\nProduction, ITChronicles, Montreal, Canada, 2020,\
    \ https://\nitchronicles.com/artiﬁcial-intelligence/game-of-drones-in-big-\ndata-and-agriculture-industry/.\n\
    6\nJournal of Food Quality\n[56] Robots Agricoles, Drones et IA : 2020–2040 :\
    \ Technologies,\nMarch´es et Joueurs, https://www.idtechex.com/fr/research-\n\
    report/agricultural-robots-drones-and-ai-2020-2040-techn\nologies-markets-and-players/749,\n\
    Cambridge,\nUK,\nIDTechEx.\n[57] T. Jennings, Farming Drones: the Future of Agriculture?,\n\
    CropLife, Brussels, Belgium, 2017, https://www.croplife.com/\niron/farming-drones-the-future-of-agriculture/.\n\
    [58] Agriculture Drone Market Size, Share, Industry Analysis, 2027,\nFortune Business\
    \ Insights, Pune, Maharashtrahttps://www.\nfortunebusinessinsights.com/agriculture-drones-market-\n\
    102589.\n[59] BIS Research, Te Rising Demand for Agriculture Drones and\nRobots,\
    \ BIS Research, Fremont, CA, USA, 2021, https://blog.\nmarketresearch.com/the-rising-demand-for-agriculture-\n\
    drones-and-robots.\n[60] Global Agriculture Drones and Robots Market: Focus on\n\
    Drones, Robot Type (Milking Robot, Harvesting & Picking\nRobot, Autonomous Robot\
    \ Tractor), Farm Produce, Farming\nEnvironment, Business Model, Regulations, and\
    \ Patent-\ns–Analysis & Forecast, 2018–2028, BIS Research, Fremont,\nCA,\nUSA,\n\
    2021,\nhttps://www.marketresearch.com/BIS-\nResearch-v4011/Global-Agriculture-Drones-Robots-Focus-\n\
    12393359/?progid\x8891587.\n[61] GIS Applications in Agriculture, Routledge &\
    \ CRC Press, Boca\nRaton,\nFL,\nUSA,\n2021,\nhttps://www.routledge.com/GIS-\n\
    Applications-in-Agriculture/Pierce-Clay/p/book/\n9780849375262.\n[62] GIS Applications\
    \ in Agriculture, Routledge & CRC Press, Boca\nRaton,\nFL,\nUSA,\n2021,\nhttps://www.routledge.com/GIS-\n\
    Applications-in-Agriculture/book-series/GIS.\n[63] GIS Applications in Agriculture,\
    \ Volume 1, CRC Press, Boca\nRaton,\nFL,\nUSA,\n2021,\nhttps://www.nhbs.com/gis-\n\
    applications-in-agriculture-volume-1-book.\n[64] GIS Applications in Agriculture,\
    \ Volume 2: in Nutrient\nManagement for Energy Eﬃciency, Washington State Uni-\n\
    versity, Prosser, WA, USA, 2021, https://www.nhbs.com/gis-\napplications-in-agriculture-volume-2-book.\n\
    [65] GIS Applications in Agriculture, Volume 3: Invasive Species,\nCRC Press,\
    \ Boca Raton, FL, USA, 2021, https://www.nhbs.\ncom/gis-applications-in-agriculture-volume-3-book.\n\
    [66] GIS Applications in Agriculture, Volume 4: Conservation\nPlanning, CRC Press,\
    \ Boca Raton, FL, USA, 2021, https://\nwww.nhbs.com/gis-applications-in-agriculture-volume-4-\n\
    book.\n[67] Use of GIS in Agriculture, Cornell Small Farms, Ithaca, NY,\nUSA,\n\
    2017,\nhttps://smallfarms.cornell.edu/2017/04/use-of-\ngis/.\n[68] GIS in Agriculture\
    \ as the Key to Eﬀective Decision-Making,\nIntellias, Lviv, Ukraine, 2020, https://www.intellias.com/gis-\n\
    in-agriculture/.\n[69] Blockchain in Agriculture: Solving Agri-Food Supply Chain,\n\
    Farrelly Mitchell, Dubai, UAE, 2020, https://farrellymitchell.\ncom/blockchain-in-agriculture-solving-food-supply-chain/.\n\
    [70] F. Antonucci, S. Figorilli, C. Costa, F. Pallottino, L. Raso, and\nP. Menesatti,\
    \ “A Review on blockchain applications in the\nagri-food sector,” Journal of the\
    \ Science of Food and Agri-\nculture, vol. 99, 2019.\n[71] M. P. Caro, M. S. Ali,\
    \ M. Vecchio, and R. Giaﬀreda,\n“Blockchain-based traceability in agri-food supply\
    \ chain\nmanagement: a practical implementation,” in Proceedings of\nthe 2018\
    \ IoT Vertical and Topical Summit on Agriculture-\nTuscany (IOT Tuscany), pp.\
    \ 1–4, Tuscany, Italy, May 2018.\n[72] A. M. G. Lamparte, Use of Blockchain Technologies\
    \ in the Agri-\nFood Sector, EIP-AGRI-European Commission, Brussels,\nBelgium,\
    \ 2020, https://ec.europa.eu/eip/agriculture/en/event/\nuse-blockchain-technologies-agri-food-sector\
    \ (accessed April\n4, 2021).\n[73] G. A. Motta, B. Tekinerdogan, and I. N. Athanasiadis,\n\
    “Blockchain applications in the agri-food domain: the ﬁrst\nwave,” Frontiers in\
    \ Blockchain, vol. 3, 2020.\n[74] M. Tripoli and J. Schmidhuber, Emerging Opportunities\
    \ for the\nApplication of Blockchain in the Agri-Food Industry, FAO and\nICTSD,\
    \ Rome, Italy, 2018.\n[75] SmartAgriFood-Blockchain AgriOpenData, SmartAgriFood,\n\
    Brussels,\nBelgiumhttps://www.smartagrifood.it/index-en.\nhtml.\n[76] 2021 Blockchains\
    \ in agrifood project, TNO. /projects/\nagrifood.\n[77] “Blockchain in agriculture\
    \ and food supply chain market size,\nindustry statistics, trends and analysis.\
    \ COVID-19 impact\nanalysis,” 2021, https://www.marketsandmarkets.com/Market-\n\
    Reports/blockchain-agriculture-market-and-food-supply-chain-\n55264825.html?gclid\x88\
    CjwKCAjwx6WDBhBQEiwA_dP8rb1pY\nwZtfgPGY6Q7ITPmnCa5zDe7yJliCkiWjDEZtKbGWInzZh6p\n\
    UBoCAdEQAvD_BwE.\n[78] Blockchain in Agrifood: A Great Opportunity. . . Disguised\
    \ as a\nTrend?, AgFunderNews, San Francisco, CA, USA, 2021.\n[79] N. Patelli and\
    \ M. Mandrioli, “Blockchain technology and\ntraceability in the agrifood industry,”\
    \ Journal of Food Science,\nvol. 85, no. 11, pp. 3670–3678, 2020.\n[80] Satellite\
    \ Guidance, CropWatch, Beijing, China, 2015, https://\ncropwatch.unl.edu/ssm/guidance.\n\
    [81] Digital Cameras, Remote Satellites Measure Crop Water De-\nmand, EurekAlert\
    \ Science News, Washington, DC, USA,\n2021, https://www.eurekalert.org/pub_releases/2008-07/asfh-\n\
    dcr071708.php.\n[82] A. I. De Castro, F. L´opez-Granados, and M. Jurado-Exp´osito,\n\
    “Broad-scale cruciferous weed patch classiﬁcation in winter\nwheat using QuickBird\
    \ imagery for in-season site-speciﬁc\ncontrol,” Precision Agriculture, vol. 14,\
    \ no. 4, pp. 392–413,\n2013.\n[83] “Ground-based remote sensing system for irrigation\
    \ sched-\nuling-sciencedirect,”\n2021,\nhttps://www.sciencedirect.com/\nscience/article/abs/pii/S1537511012001523.\n\
    [84] “New satellite data will help farmers facing drought–climate\nchange: vital\
    \ signs of the planet,” 2021, https://climate.nasa.\ngov/news/1145/new-satellite-data-will-help-farmers-facing-\n\
    drought/.\n[85] N. C. Coops and T. R. Tooke, “Introduction to remote\nsensing,”\
    \ in Learning Landscape Ecology: A Practical Guide to\nConcepts and Techniques,\
    \ S. E. Gergel and M. G. Turner, Eds.,\nSpringer, New York, NY, USA, pp. 3–19,\
    \ 2017.\n[86] Precision Ag: Applying Agronomy Innovatively in Production\nCrop\
    \ Consulting, Crop Quest, Dodge City, KS, USA, 2021,\nhttps://www.cropquest.com/category/precision-ag/.\n\
    [87] NASA, NASA Uses Satellite to Unearth Innovation in Crop\nForecasting, NASA,\
    \ Washington, DC, USA, 2021, https://\nwww.nasa.gov/topics/earth/features/crop_forecast.html.\n\
    [88] 2021 Home GDA. https://www.gdacorp.com.\n[89] GAG, Digitising Agrifood, BCFN\
    \ Foundation, Parma, Italy,\n2021, https://www.barillacfn.com/en/publications/digitising-\n\
    agrifood/.\nJournal of Food Quality\n7\n"
  inline_citation: '>'
  journal: Journal of food quality
  limitations: '>'
  pdf_link: https://downloads.hindawi.com/journals/jfq/2021/5584754.pdf
  publication_year: 2021
  relevance_score1: 0
  relevance_score2: 0
  title: Artificial Intelligence to Improve the Food and Agriculture Sector
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/access.2019.2926642
  analysis: '>'
  authors:
  - Basheer Qolomany
  - Ala Al-Fuqaha
  - Ajay Gupta
  - Driss Benhaddou
  - Safaa Alwajidi
  - Junaid Qadir
  - A.C.M. Fong
  citation_count: 128
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Journals & Magazines >IEEE Access >Volume: 7 Leveraging
    Machine Learning and Big Data for Smart Buildings: A Comprehensive Survey Publisher:
    IEEE Cite This PDF Basheer Qolomany; Ala Al-Fuqaha; Ajay Gupta; Driss Benhaddou;
    Safaa Alwajidi; Junaid Qadir; Alvis C. Fong All Authors 116 Cites in Papers 8179
    Full Text Views Open Access Comment(s) Under a Creative Commons License Abstract
    Document Sections I. Introduction II. Smart Buildings: Concept and Architecture
    III. Smart Building Components IV. Ml Background for SBS: Models, Tasks, and Tools
    V. Applications of Ml-Based Context-Aware Systems for SBs Show Full Outline Authors
    Figures References Citations Keywords Metrics Abstract: Future buildings will
    offer new convenience, comfort, and efficiency possibilities to their residents.
    Changes will occur to the way people live as technology involves people''s lives
    and information processing is fully integrated into their daily living activities
    and objects. The future expectation of smart buildings includes making the residents''
    experience as easy and comfortable as possible. The massive streaming data generated
    and captured by smart building appliances and devices contain valuable information
    that needs to be mined to facilitate timely actions and better decision making.
    Machine learning and big data analytics will undoubtedly play a critical role
    to enable the delivery of such smart services. In this paper, we survey the area
    of smart building with a special focus on the role of techniques from machine
    learning and big data analytics. This survey also reviews the current trends and
    challenges faced in the development of smart building services. The major machine
    learning tasks that are relevant to smart buildings include: data collection and
    acquisition, data pre-processing, and dimensionality reduction. Published in:
    IEEE Access ( Volume: 7) Page(s): 90316 - 90356 Date of Publication: 03 July 2019
    Electronic ISSN: 2169-3536 DOI: 10.1109/ACCESS.2019.2926642 Publisher: IEEE CCBY
    - IEEE is not the copyright holder of this material. Please follow the instructions
    via https://creativecommons.org/licenses/by/4.0/ to obtain full-text articles
    and stipulations in the API documentation. SECTION I. Introduction Although the
    term “smart building” (SB) may bring a thought of a fictional smart space from
    science-fiction movies, but the reality is that SBs exist today, and their number
    is getting increased. With recent advances in machine learning (ML), big data
    analytics, sensor technologies and the Internet of Things (IoT), regular buildings
    can be cost-effectively transformed into SBs with bare minimum infrastructural
    modifications. There are smart office, smart library, smart home, smart health
    care facilities, smart hospital and many other types of SBs that can provide automated
    services that can provide many value-added services (such as reduction of wasted
    energy) and also help to ensure the comfort, health, and safety of the occupants.
    The hyperconnectivity that will be brought about by the emergence of IoT will
    increase the promise of SB since now all the basic building amenities and commodities
    ranging from your house electronics to your plant vases will be interconnected.
    But this hyperconnectivity will at the same time complicate the process of managing
    SBs. In particular, SBs and their inhabitants are expected to create large volumes
    of streaming data. ML, sampling, compression, learning, and filtering technologies
    are becoming more significant to manage the stream of big data of individuals.
    In 1981, the term Intelligent Buildings (IBs) was initially coined by United Technology
    Building Systems (UTBS) Corporation in the U.S. In July 1983, IBs became a reality
    with the opening of the City Place Building in Hartford, Connecticut [1]. Today,
    the number of SBs is growing at an unprecedented rate including smart office,
    smart hospitality, smart educational facilities etc. [2]. An SB is recognized
    as an integrated system that takes advantage of a range of computational and communications
    infrastructure and techniques [3]. Examples of SB services include smart thermostats
    that allow the temperature to be controlled based on the time of the day/year
    and the users’ preferences with minimal or no manual configuration. Using data
    analytics to “learn” the users’ preferences before taking the appropriate actions
    is probably the most important enabling technology for IBs [4]. Lately, smart
    coffee machines appeared in the market with the capability to make coffee automatically,
    according to users’ preferences and schedules. Fridges can offer allocated programming
    interfaces for their control [5]. IBs aim to provide their users with safe, energy
    efficient, environment-friendly, and convenient services. In order to maximize
    comfort, minimize cost, and adapt to the needs of their inhabitants, SBs must
    rely on sophisticated tools to learn, predict, and make intelligent decisions.
    SB algorithms cover a range of technologies, including prediction, decision-making,
    robotics, smart materials, wireless sensor networks, multimedia, mobile computing,
    and cloud computing. With these technologies, buildings can cognitively manage
    many SB services such as security, privacy, energy efficiency, lighting, maintenance,
    elderly care, and multimedia entertainment. The massive volume of sensory data
    collected from sensors and appliances must be analyzed by algorithms, transformed
    into information, and minted to extract knowledge so that machines can have a
    better understanding of humans than their environment. Furthermore, and most importantly,
    such knowledge can lead to new products and services that can dramatically transform
    our lives. For example, readings from smart meters can be used to better predict
    and balancing the usage of power. Monitoring and processing sensory data from
    wearable sensors attached to patients can produce new remote healthcare services.
    The main philosophy behind ML is to create the analytical models automatically
    in order to permit the algorithms to learn continuously from available data. The
    application of ML techniques increased over the last two decades due to the availability
    of massive amounts of complex data and the increased usability of current ML tools.
    Today, ML is already widely applied in different applications including recommendation
    systems offered by online services (e.g., Amazon, Netflix) and automatic credit
    rating services used by banks. Alphabet’s Nest thermostat utilizes ML to “learn”
    the temperature preferences of its users and adapt to their work schedule to minimize
    the energy use. Other widely publicized examples of ML applications include Google’s
    self-driving car, sentiment analysis of Amazon and Twitter data, fraud detection,
    and Facebook’s facial-recognition technology that is used to tag the suggested
    person on images uploaded by users. A. SB Trends and Market Impact In this section,
    we look at the statistics related to SBs, to allow us to understand the current
    trends and motivations in industry marketplaces and academic researches toward
    SBs. According to the report by MarketsandMarkets [6], The SB market is estimated
    to grow from 7.42 billion dollars in 2017 to 31.74 billion dollars by 2022, at
    a Compound Annual Growth Rate (CAGR) of 33.7% from 2017 to 2022. In yet another
    report Zion Market Research [7], 2016 and it is expected to reach 61,900 million
    dollars by 2024. It is expected to exhibit a CAGR of more than 34% between 2017
    and 2024. The market is primarily driven by government initiatives globally for
    SB projects and the increasing market for integrated security and safety systems
    as well as energy efficient building systems. Figure 1 shows the Statista [8]
    forecast market size of the global smart home market from 2016 to 2022 (in billion
    U.S. dollars). FIGURE 1. Forecast market size of the global smart home market
    from 2016 to 2022 [8]. Show All According to the Gartner report [9], it is expected
    that the number of smart connected homes grows to 700 million homes by 2020, supplied
    by mass consumer adoption and an increase in the number of devices and apps available.
    Figure 2 shows Gartner’s 2018 Hype Cycle expectation for deep learning, ML, connected
    homes, and smart workspace. FIGURE 2. Hype Cycle for the Connected Home, 2018
    [7]. Show All According to report by Research and Markets [10], [11], the global
    IoT SB market will reach approximately $51.44B USD globally by 2023. The report
    also forecast that 33% of IoT SB market will be supplied by artificial intelligent
    technologies by 2023, and automation systems of SB will grow at 48.3% CAGR from
    2018–2023. Frost & Sullivan also predict that by 2025, the growth of connected
    home living will reach 3.7 billion smartphones, 700 million tablets, 520 million
    wearable health-related devices and 410 million smart appliances in the connected
    person world. B. Related Survey Papers Although many of survey papers focused
    on SBs have been published, none of them is focused on the role of data analytics
    and ML in the context of SBs. We describe the relevant survey papers next and
    will compare these survey papers to our paper in Table 2. Chan et al. in 2008
    provided an overview of smart home research [12]. It also discusses assistive
    robots, and wearable devices. The article reviews smart home projects arranged
    by country and continent. Alam et al. [13] provided details about sensors, devices,
    algorithms, and communication protocols utilized in smart homes. The paper reviews
    smart home works according to their desired services and research goals; namely,
    security, comfort, and healthcare. Lobaccaro et al. [14] presented the concept
    of smart home and smart grid technologies and discuss some challenges, benefits
    and future trends of smart home technologies. Pan et al. [15] reviewed the works
    on efficient energy consumption in SBs using microgrids. The survey investigates
    research topics and the recent advancements in SBs and the vision of microgrids.
    A few survey papers have reviewed works on facilitating independent living of
    the elderly people in smart homes. Ni et al. [16] conducted a survey on the features
    of sensing infrastructure and activities that can assist the independent living
    of the elderly in smart homes. A survey on ambient assisted living technologies
    for elderly people has been presented Rashidi and Mihailidis [17]. Peetoom et
    al. [18] focused on monitoring technologies to recognize life activities in-home
    such as fall detection and changes in health status. Salih et al. [19] presented
    a review of ambient intelligence assisted healthcare monitoring services and described
    the various application, communication, and wireless sensor network technologies
    that have been employed in the existing research literature. A number of papers
    have focused IoT: (a) Perera et al. [20] discussed IoT applications from the perspective
    of context-awareness and self-learning; (b) Tsai et al. [21] surveyed the applications
    of data mining technologies in IoT; and (c) Mahdavinejad et al. [22] reviewed
    some ML methods that can be applied to IoT data analytics. TABLE 1 List of Important
    Acronyms Used TABLE 2 Comparison of Relevant Survey Papers C. Contributions and
    Organization of This Paper To the best of our knowledge, this is the first survey
    that covers SBs jointly from the perspectives of application, data analytics,
    and ML. The main contributions of our paper are: Exploration of the potential
    of ML-based context-aware systems to provide SB services; Identification of research
    challenges and directions for SBs and how ML models can help in resolving such
    challenges; Identification of SB applications including comfort, security, energy
    efficiency, and convenience and the role of ML in such applications. Our research
    can provide an impetus to ML researchers to investigate new exciting ML-based
    SB services. The rest of the paper is organized as follows: Section II introduces
    the concept of SBs and its underlying architecture. Section III introduces the
    various components of the SB ecosystem and its underlying architecture. Section
    V presents context recognition and activity modeling and the role of ML in SBs.
    Section VI highlights research and development challenges and provides a future
    perspective of SB projects. Finally, Section VII presents a summary of lessons
    learned and concludes the paper. For the convenience of the readers, we have enlisted
    the important acronyms used in Table 1. SECTION II. Smart Buildings: Concept and
    Architecture In 1984, The New York Times published an article that described that
    real estate developers are creating “a new generation of buildings that almost
    think for themselves called intelligent buildings.” Such an intelligent building
    (IB) was defined as “a marriage of two technologies - old-fashioned building management
    and telecommunications.” [23]. Since then, many definitions of SBs have been suggested.
    This is due to the fact that the life-cycle of building planning, design, implementation,
    and operation involves different industry players that have different roles. In
    addition, the rapid changes in technology are affecting this definition. For instance,
    the advent of IoT and smart city concepts is impacting the definition of SB. Therefore,
    it is hard to compose a unique view of IBs with a single definition that is accepted
    worldwide. However, it is vital to have a good understanding of the main standard
    bodies and companies involved in shaping the development of SBs [1]. The Institute
    for Building Efficiency [24] focuses on the operation of buildings to provide
    efficient healthy and comfortable environment [25]. IBM [26] focuses also on the
    operation of SBs to provide integrated physical and digital infrastructures that
    provide reliable, sustainable, and cost-effective occupancy services. According
    to the European Commission’s Information Society [27], SBs means buildings that
    are supplied by information and communication technologies in the context of the
    combining Ubiquitous Computing and the IoT: In general, the buildings that are
    supplied with sensors, actuators, microchips, micro- and nano-embedded systems
    in order to enable collecting, filtering and producing more information locally,
    to be further incorporated and managed globally according to business functions.”
    In SBs, a variety of AI and multi-agent system techniques are employed including
    [28]: Reasoning and knowledge representation including ontologies and rules to
    represent devices and building services. ML for human activity recognition. Multi-agent
    systems for distributed intelligence and semantic interoperability. Intelligent
    approaches such as planning, intelligent control, adaptive interfaces, and optimization
    for efficient management of resources and services. An SB is therefore the integration
    of a wide range of systems and services into a unified environment that involve
    energy management systems, temperature monitoring systems, access security systems,
    fire and life safety, lighting control and reduction, telecommunications services,
    office automation, computer systems, area locating systems, LANs, management information
    systems, cabling and records, maintenance systems, and expert systems [29]. Figure
    3 shows examples of SB appliances including air-conditioning systems, lighting
    systems, solar energy generators, power-supply systems, temperature sensors, humidity
    sensors, power usage sensors, and surveillance cameras. For example, centralized
    control of these elements can promote the efficient use of energy through the
    intelligent control of lights and air conditioning units and the intelligent management
    of multiple green and brown energy sources. In most cases, an SB uses an Ethernet
    backbone with bridges to a Controller Area Network (CAN) [26]. FIGURE 3. Example
    of SB appliances. Show All It is easier to introduce smart services in residential
    buildings compared to commercial buildings since residential buildings have less
    technical equipment and less stringent efficiency requirements. Because the commercial
    buildings usually have more public visitors and therefore building models for
    commercial buildings are usually more challenging than building models for residential
    buildings which usually have a limited number of the occupants most of the time.
    In addition, the costs associated with the purchase and installation of smart
    devices and infrastructure at commercial buildings is more than residential buildings.
    Figure 4 shows an integrated framework in a residential building that employs
    a network of intelligent sensors. These sensors control systems such as energy
    generation, metering, HVAC, lighting, and security. A building automation system
    manages a set of smart appliances, sensors, and actuators, which collectively
    deliver services for the well-being of the inhabitants. Examples of such smart
    appliances, sensors, and actuators include washers and dryers, refrigerators,
    heaters, thermostats, lighting systems, power outlets, energy meters, smoke detectors,
    televisions, game consoles, windows/door controllers and sensors, air conditioners,
    video cameras, and sound detectors. More advanced smart devices are constantly
    being developed like smart floors and smart furniture [28], [30]. FIGURE 4. Smart
    appliances, sensors, and actuators in a smart residential building. Show All The
    IoT will enable the integration and interoperability of heterogeneous devices
    in SBs as well as the real-time processing of the data generated by sensors in
    support of optimal control and operation of the building. In this paper, We propose
    a layered architecture for SBs based on the layered architecture of IoT. Figure
    5 shows the layered architecture of SBs. FIGURE 5. Layers of the base IoT architecture
    that serves as the foundation for SBs. Show All As can be seen from the sensing
    layer (the bottom layer in Figure 5), input data is obtained from different types
    of physical sensors that monitor environmental parameters, collect data about
    residents and detect anomalies (e.g., fire and water pipe bursts). This layer
    also includes actuators that can be controlled to save energy, minimize water
    consumption, etc. The network layer (the second layer in Figure 5), includes access
    and core networks that provide transparent data transmission capability. This
    layer serves as a bridge between the sensing layer and the upper layers which
    are mainly responsible for data processing. An intermediary software layer called
    the middleware layer is needed (the third layer in Figure 5) to provide seamless
    integration of heterogeneous devices and networks covered by the sensing layer
    of the architecture. That layer serves as a bridge between the embedded software
    that runs of smart sensors and back-end software services. This layer provides
    interoperability using standardized programming interfaces and protocols [31].
    Therefore, this layer performs the process of converting the collected data from
    various data formats into a common representation. SB middleware can be based
    on open standards or proprietary, in addition, application-specific or general-purpose.
    Most often, proprietary middleware is application-specific while general-purpose
    middleware is based on open standards [28]. The context and semantic discovery
    layer (the fourth layer in Figure 5) is responsible for managing context and semantic
    discoverers including context and semantics generating, configuring, and storing.
    The processing and reasoning layer (the fifth layer in Figure 5) is responsible
    for processing the extracted information from the middleware then according to
    the application’s type it will make decisions. In this layer, there are various
    techniques of information processing applied to fuse, extract, contextualize.
    massive data into useful actionable knowledge. In this layer, two phases should
    be identified: context consumer and context producer of the middleware. In the
    context consumer phase, the data processing techniques are applied on the data
    produced by the middleware; while in context producer phase the process of decision-making
    is implemented to supply the service layer with valuable knowledge. while in the
    second stage, further context information can be provided to the middleware for
    registration in the ontology context. Specific services and applications are abstracted
    in the application layer (the top-most layer in Figure 5). This layer presents
    a framework with direct access to the underlying functionalities to serve in the
    implementation of various types of applications. Moreover, control panels should
    be installed in the building to control the automated indoor spaces and to support
    a local human-machine interface. For instance, in a multi-story building, each
    floor could have a control panel to automate the operations, such as control opening
    the windows, control of air conditioning to achieve the desired temperature, control
    close/open the blinds according to the preferred light intensity before using
    artificial lighting [32], [33]. Summary: Still there is no single standard definition
    for SBs. In this section, we reviewed many definitions for SBs by many institutes,
    counties, regions and different disciplines; each has their own definition for
    SBs. We presented the layered architectural pattern for adapting services in an
    SB environment. We wanted to provide a general design for adapting actions according
    to the different versions of context in SBs. This architecture may be used in
    different smart environments such as intelligent transport systems, security,
    health assistance, and SBs among others. We layered the architecture into six
    layers starting from the sensing layer, which includes various types of sensors
    that are installed to collect environmental information in SBs. While network
    layer providing data stream support and data flow control and ensuring that messages
    arrive reliably by using data transport protocols such as Wi-Fi, Bluetooth, Ethernet
    etc. Data Acquisition layer to collect the data from the heterogeneous sources
    of data. Context and semantic discovery layer to generate, configure, and store
    context and semantic information. Context processing and reasoning layer to process
    the information and extract the knowledge that making the decisions according
    to the application context. And the last layer which is application layer such
    as health assistance and elderly home care, comfort and entertainment services,
    security, tele-management, smart watering, energy efficiency, etc. After discussing
    the main components of commercial and residential buildings, we have now set the
    stage for a detailed discussion on the components of SBs in the next section.
    SECTION III. Smart Building Components Advances in smart building technology have
    driven to the extensive development of SBs to generate economic and environmental
    benefits for building owners through the convergence of IT and building automation
    systems. Figure 6 shows the key components of SB systems, these include extensive
    sensors and actuators systems, networking and communication systems, software
    platform system, HVAC system, and smart control devices. FIGURE 6. Components
    of smart buildings. Show All Current systems utilize control devices and smart
    sensors that are connected to a central system. These control devices and smart
    sensors are placed throughout the environment. Each particular system has its
    own collection of networking and communication systems that enable it to communicate
    with the central system. SBs are performing connected networks that serve as a
    communication backbone for multiple systems. In many ways, HVAC equipment is the
    most complicated building system, with numerous components arranged to produce
    heating, cooling, and ventilation. The functionality of HVAC system not only makes
    the building healthy and comfortable for its inhabitants, but it also manages
    a big part of the energy consumed, as well as plays a significant role in life
    safety. SBs adopt technology to monitor and control facility systems and perform
    any required modifications. The objective of an SB is to utilize computers and
    software to control lighting, alarm systems, HVAC, and other systems through a
    single computer interface. A. Sensors and Actuators for SBs Sensors and actuators
    are mechanical components that measure and control the environmental values of
    their environment. Sensors collect information from the environment and make it
    ready for the system. For instance, IR sensors can be utilized for human presence
    detection in a room. While actuator is a device to convert an electrical control
    signal to a physical action, such that it takes decisions and then performs proper
    actions according to the environment, which enables automated and remote interaction
    with the environment.For example, a light actuator is capable of switching on/off,
    dimming one or more electric lights [34]. The rapid development of micromechanics,
    microelectronics, integrated optics, and other related technologies has facilitated
    the development of different types of smart sensors integrated into daily objects
    and infrastructure at smart building environment or worn by the users, and are
    connected by network technologies in order to collect contextual information about
    daily living activities more efficiently and faster, with lower energy consumption
    and less processing resources. Environmental sensors are utilized for detecting
    the human activity of a specific object that performed in specific locations in
    the building, while wearable sensors are utilized for controlling and observing
    mobile activities and physiological signals [35]. 1) Environmental Sensors It
    is found that data collected from environmental sensors can form important information
    to monitor human behaviors within an SB. These sensory data are then analyzed
    to identify and observe basic and instrumental daily living activities made by
    occupants such as bathing, dressing, preparing a meal, taking medication etc.
    The environmental sensing is generally based on several simple binary sensors
    in every part of the home, RFID technology, and video cameras. This variety of
    sensing may implement important insight into contexts and actual activities although
    it might come with possible costs such as complexity. Motion sensors are utilized
    for detecting the occupant’s presence and location everywhere in the house. There
    are different types of motion sensors. IR presence sensor is one of the most utilized
    kind of motion sensors in SBs to detect occupants’ presence. Pressure sensors
    can be attached to the objects such as beds, chairs, sofas, and floors in order
    to track the actions and locations of the occupants. While Contact switches are
    usually placed on the doors of fridge, rooms, or cabinets to detect the actions
    that the occupant makes with these objects [36]. Light sensors, humidity sensors,
    temperature sensors, or power sensors are other types of sensors that are deployed
    and utilized in SB to recognize the activities. Light sensors are utilized to
    measure the light intensity in a particular room in the building. Humidity sensors
    are utilized to detect the air humidity of a specific location in the building.
    Temperature sensors are utilized to measure the temperature of the specific environment.
    while the power sensors are utilized to identify the power usage of electric devices.
    2) Wearable Sensors and Biosensors These sensors are attached directly or indirectly
    to the user body. Their small size enables these sensors to be attached to clothes,
    wristwatches, glasses, belts, shoes etc. These sensors can be categorized into
    inertial sensors and vital sign sensors (or biosensors). Wearable inertial sensors
    are highly transportable and no stationary units that can give accurately detailed
    features of occupant’s action and body posture. Those sensors are composed of
    accelerometers, gyroscopes and magnetic sensors. There is a need for receivers
    and cameras in the process of data collection, therefore can be used outside laboratory
    circumstances [37]. Wearable biosensors such as blood pressure, skin temperature,
    and heart rate are significant for collecting vital signs to monitor the health.
    The most commonly utilized inertial sensors for mobile activity monitoring are
    accelerometers and gyroscopes. Accelerometers can be utilized to measure the rate
    of acceleration accompanying a sensitive axis, they are useful to monitor the
    motion’s activities such as doing exercise, standing, sitting, walking, or walking
    upstairs and downstairs. While the gyroscopes can be utilized to measure angular
    velocity and maintain orientation. Some examples of primary vital signs are Electrocardiogram
    (ECG), heart rate, blood pressure, blood glucose, oxygen saturation, and respiratory
    rate. There are various vital sign sensor utilized to measure different vital
    signals such as Electroencephalography sensors (EEG) for observing electrical
    brain activity, Electrooculography sensors (EOG) for observing eye movement in
    ocular activity, Electromyography sensors (EMG) for observing muscle activity.
    Electrocardiography sensors (ECG) for observing cardiac activity, pressure sensors
    for observing blood pressure, CO2 gas sensors for observing respiration, thermal
    sensors for observing body temperature and galvanic skin response for observing
    skin sweating [38], [39]. 3) Heating, Ventilation, and Air Conditioning (HVAC)
    HVAC system plays an essential role in SB services. HVAC system plays a remarkable
    role in efficient energy consumption in SBs, as well as it offers new operating
    options to increase the occupants’ comfort. In addition to meeting the desired
    temperature, HVAC control systems are produced in order to sustain comfort within
    an enclosed space by producing a specific level of humidity, pressure, air motion,
    and air quality in an SB [40]. CO2, humidity and temperature levels in a building
    can affect occupant’s health and comfort; consequently measuring CO2, humidity,
    and temperature in this context can improve personal wellbeing [41]. Heating and
    cooling systems consume a huge amount of energy in the buildings, so it is necessary
    to optimize it utilizing smart controllers and sensors in order to save operational
    costs. Smart HVAC systems can sense and control efficiently different air quality
    parameters inside the building by utilizing distributed sensors and VAV fans throughout
    the building to perform an optimal ventilation [42]. Most of the current HVAC
    actuation systems in smart buildings are based on the data collected about the
    occupants using sensors and cameras, which are utilized specifically for HVAC
    systems. Certainly, There is a specific cost for the design, maintenance, setup
    and hardware of the data collection network [43]. Table 3 shows a summary for
    different types of smart sensors in the SBs. TABLE 3 Various Smart Sensors Useful
    in the Context of SBs B. Smart Control Devices Smart control devices collect data
    from a variety of sensors, process this data, and activate actuators to react
    to the events detected by the sensors. A smart control device can operate independently,
    without control by a central server. But there might be a needed communication
    amongst various control devices or they can connect with each other using the
    smart gateway. WeMo [44] is a Wi-Fi enabled switch utilized to turn electronic
    devices on/off from anywhere. It can control LED motion sensors, light bulbs,
    mart wall switches and plugs, and lighting devices, all from the smartphone app
    or browser. There is no hub needed for WeMo devices, everything can be managed
    through the free cloud service provided by Belkin. You can use the specific channel
    to connect the device to e-services such as Gmail to trigger specific actions.
    WeMo devices also support context-aware feature, it turns on/off automatically
    according to the time of day, whether it is sunrise or sunset etc. The Nest thermostat
    [45], a smart device developed by Nest—which has been acquired by Google—adjusts
    to your life and seasons change automatically. Just use it for a week and it programs
    itself. It learns about the level of temperatures that the occupants prefer and
    creates a context-aware personalized schedule. The smart thermostat turns to an
    energy-efficient mode automatically when the residents leave the building. It
    could start warming up the area when it senses activity, such as an occupant’s
    returning back home from work. The Nest Thermostat is controllable via a smartphone
    and an installed app. If you are away for a while, this device has also a capability
    to sustain a particular temperature in your house. Lockitron [46] is a door lock
    that can control the door remotely over the Internet to open and close it by phone.
    Lockitron app can be installed and used by any iOS or Android smartphone. Homeowners
    can directly grant family and friends the access to open a given door by providing
    authorization over the Internet. Lockitron can also utilize Bluetooth low energy
    technology, which means that it will keep controlling even in the event of Internet
    or power outages. Lockitron can also connect to the Internet with Bridge, through
    which occupants can control the bolt anywhere in the world. The SmartThings [47]
    SB automation system comprised of a communications smart hub, that supports various
    smart appliances and devices; the smart hub supports various technologies and
    protocols such as ZigBee, Z-Wave, as well as IP-accessible devices and lets you
    control appliances using Wi-Fi and Bluetooth connectivity. SmartThings provides
    kits that include smart plugs, in addition, the basic sensors that can be utilized
    to measure temperature, as well as to detect presence, motion, orientation, and
    vibration. SmartThings also includes an open platform that enables smart device
    vendors and third-party software to provide hardware and software that can be
    utilized alongside the platform. Philips Hue [48] is a combination of LED lighting
    with mobile technology. An accompanying mobile app that allows you to control
    lighting systems and changing color sets depending on your mood utilizing Wi-Fi
    technology. The new Philips Hue bridge supports the required authentication to
    enable Apple HomeKit technology to control and enable your Philips Hue to connect
    to other HomeKit enabled accessories and take control of your home. Blufitbottle
    [49] this bottle records the drinking habits of the users and sends them notifications
    about the time and amount of the water that they are supposed to drink to keep
    them healthy and hydrated. The app collects data about users such as their weight
    and age, plus other factors such as the current levels of temperature and humidity
    to estimate the amount of the needed water to keep them hydrated. When the user
    falls behind with hydration, an alert sounds, as well as a simple glance from
    the LEDs, will indicate when it’s time for the next drink. Canary [50] is an all-in-one
    home security system that comprises a set of sensors such as temperature, air
    quality, sound, motion vibration, in addition, an HD video camera in one unit.
    The system utilizes ML algorithms to let the users know what is happening at home
    and take action by sending notifications to your phone if something happens. Those
    ML models learn over time and send the users smarter notifications as it detects
    motion. So that, the longer you have the system, the more effective it becomes.
    Canary is able to decrease the rate of false alarms by learning the user behavior
    and the ambient noise level and the home temperature patterns. Amazon Echo [51]
    is a small cylinder enable the users to control anything in the home via the voice.
    Amazon Echo has a powerful voice recognition capability, the user does not have
    to worry about the complexities of their voice. Amazon Echo is connectable via
    Wi-Fi or Bluetooth, the users can send voice commands to control the speakers
    as well as other compatible devices such as Belkin’s WeMo and Philips Hue. It
    can also use Amazon cloud Lambda service to send commands. To send any command
    It requires to include the name of the program, for instance, “Alexa, turn on
    TV”. It also includes a network to distant servers, which slows down the response
    time. Honeywell Total Connect Remote Services [52] this device merges personal
    smart home automation with security monitoring task. It enables the occupants
    to control and monitor everything in the home from lighting and window shades
    systems to security cameras and smoke alarms. the user can utilize a smartphone
    app or desktop-mounted hardware console for controlling and monitoring. It can
    provide real-time alerts, GPS vehicle and asset tracking, video viewing, and mobile
    control. The system only supports Z-Wave devices, it needs to be installed by
    an authorized Honeywell dealer. It does not work with Wi-Fi enabled smart thermostats.
    In addition, the Honeywell provides security cameras and sensors, it also supports
    other smart devices from third parties, such as Yale locks and Lutron lighting.
    Table 4 shows a comparison among various smart control devices in the SBs. TABLE
    4 Comparison Among Various Smart Control Devices in SB C. Networking and Home
    Gateway An SB combines a communication network in order to control smart devices
    and services within the building. The communication network of a smart building
    can be based on diverse communication media such as twisted pair cable, as the
    traditional computer networks. The networking in building automation system has
    a tendency to utilize a heterogeneous network that is made up of diverse communication
    media and network standards. The building automation network is identified by
    physical technology and communication protocols. There is an internal network
    that connects devices inside the building, as well as the external networks, can
    be integrated separately. Public Internet, ISDN, and mobile phone networks are
    some examples of external networks [28], [53]. A typical SB may comprise a number
    of different components, such as sensors, actuators, communication and processing
    devices. Because of their nature, these components have limited capabilities and
    computational capacity in term of battery capacity and capability of data processing.
    To deal with this issue, most of the SB systems have been utilized as a central
    gateway to collect, process, and analyze context data from different sensors and
    actuators in the building. Several protocols such as Bluetooth, ZigBee, Wi-Fi,
    and Z-wave can be utilized for communicating the gateway. The home gateway can
    also collect and store data for a specific time period. Typically, these gateways
    can connect to the cloud services and perform data processing and reasoning tasks.
    The centralized gateway usually does not have any interface. They can be controlled
    and managed utilizing smartphones, tablets, or computers [54], [55]. In general,
    depending on the communication media used, SB network technology can be classified
    by interconnection method into three main types: Powerline, Busline, and Wireless
    [15], [56], which we describe next. 1) Powerline Communication (PLC) PLC method
    reuses the building electrical network; such that devices, appliances, and services
    are directly connected to the main power supply utilizing the already available
    electrical outlets in a building. The data is sent through the normal cable system
    to activate or deactivate the devices in the building. PLC system is historically
    the oldest technology in SB and is generally cheap but less reliable and scalable
    [3]. Originally, the application of PLC was mainly to secure the typical operation
    of the electric power supply system in case of failures or breakdowns through
    the direct exchange of information between the distribution center, and power
    plant. Therefore, this approach has become a competitive choice for SB networking,
    benefiting from availability, robustness, and ready connectivity of this method.
    Some of the protocols of this method offer a single-way communication, which enables
    the device to only receive information but not to communicate. There are different
    mainstream protocols of PLC method such as X-10, INSTEON, HomePlug, BACnet, and
    Lonworks. 2) Busline Busline systems in SBs networks use a separate physical media,
    usually twisted-pair cabling similar to the physical cables utilized for network
    services for transporting electrical signals. This type of systems is pleasant
    the building’s occupants, albeit the configuration process is complex, and it
    requires some knowledge of networking. Although the configuring complexity and
    installation cost of this system, the use of a separate cable could present a
    positive note about this approach, as it allows this method of networking to provide
    higher bandwidth, and to make it the most reliable of the three approaches. In
    addition, this technology usually supports a completed two-way communication protocol
    that enables the appliances to easily communicate with each other [57]. Some of
    the protocols in Busline technology are Konnex (KNX), CAN (Controller Area Network),
    Modbus, Meter-Bus (M-Bus). 3) Wireless Interconnection Many of the new SB applications
    use wireless technologies such as infrared and radio frequency, which are more
    convenient for users due to their untethered nature and the elimination of cables.
    The devices within the smart building can communicate wirelessly as radio wave
    can penetrate through floors, cabinets, and walls [56]. Because of the complexity
    and cost of potential modifications and of the re-wiring process in a smart building,
    several different wireless technologies are rising to produce flexible networking
    patterns convenient to occupants without taking to consider the physical wiring
    and deployment of such wire in the building. Typically, there are various protocols
    for the wireless system such as Bluetooth, ZigBee, WLAN, Z-wave, RFID etc., which
    essentially work in the industrial scientific medical bands, particularly in the
    2.4GHz frequency range. These wireless technologies are usually related to some
    control network concept in an SB such as low power consumption, high cost-effectiveness,
    low speed, flexibility in networking, deployment as well as building coverage
    [3]. The gateway is the central server of an SB that is commonly used in IoT solutions.
    The services provided by the gateway essentially concern to system management
    functionalities such as monitoring, controlling, and configuring the systems and
    their devices. It also supports some processing and data storage capabilities
    required for complex applications. D. Software Platform For a building to be “smart,”
    it is important that all the appliances and systems in the building communicate
    and exchange data securely with each other as well as with smartphones, tablets,
    and servers in the cloud. Software platforms play a critical role in exchanging,
    archiving and disseminating information through different protocols. These platforms
    use push, pull, publish/subscribe, etc. The goal of the joint commercial enterprises
    is to develop an open source software platform in order to make the process of
    data exchanging easier between the devices of different manufacturers. Therefore,
    the users will not have to worry in the future about the compatibility issues
    when utilizing electric and electronic devices of different manufacturers at home.
    In addition, the new platform can also offer a variety of different building services
    such as entertainment, energy efficiency, and security technology. Hence, this
    will enable creating different apps for these areas of use [58]. ABB, Robert Bosch
    GmbH, and Cisco Systems Inc. established an open-software platform called Mozaiq
    Operations GmbH [59] to unify smart building technology and offer interoperability
    across for all devices and services in the building, to simplify the experience
    for residents. It will enable users to seamlessly and intuitively customize their
    appliances and devices, regardless of manufacturers and brands of these devices,
    in order to improve energy efficiency and achieve a unique level of control and
    comfort. For instance, the user can close the blinds in the home either by a click
    from a smartphone or through a pre-set instruction; and switch off automatically
    all screen devices for the children to go outside to play. In a smart building,
    many devices and appliances can simply and securely share information with one
    another and with smartphones and other smart devices; and the Internet in general.
    Indigo Domotics [60] is to implement the do-it-yourself smart building platform.
    Indigo home automation software controllers available for the Mac OS enables residents
    to combine an array of common INSTEON, Z-Wave and X10 devices for unparalleled
    control of your building lighting, sensors, thermostats, and appliances. With
    Indigo Touch (sold through iTunes app store, iOS only), users will easily achieve
    remote control of their appliances utilizing an iPhone, iPad, or iPod Touch. They
    also can use a web browser on any device to control their appliances virtually
    anywhere in the world. The users can receive texts or emails about specific events
    has been detected for doors opening/closing, power failures etc. Indigo, from
    Perceptive Automation, is the newest home automation software for the Mac. OpenHAB
    [61] is an open-source software platform that follows a middleware approach for
    integrating different technologies in smart building systems into a single solution.
    OpenHAB platform address a variety of network technologies and appliances in the
    area of a smart building. Currently, the dependency on a particular vendor becomes
    a problem due to the lack of a common language that bridges the different devices
    with building automation system. The main goal of the OpenHAB platform is to integrate
    the new devices and technologies in a smart building system through a community-based
    approach. OpenHAB utilizes an OSGi based modular system for communicating between
    different technologies and devices. Bindings can be developed and deployed as
    an OSGi bundle to bridge a particular technology and device. There are different
    supported technologies exist such as EnOcean, KNX, Z-Wave, and others are supported
    through special bindings [62]. SmartThings [47] this platform composed of hardware
    devices, sensors, and software applications. Context information is collected
    from the sensors, this context is contributed to the reasoning and action that
    are performed by the application. For instance, the sprinkler in the garden can
    detect the rain, and switch itself off accordingly to save water. SmartThings
    kit comprises sensors, smart devices, and hub. While the SmartThings application
    is configured to enable users to control and monitor their building environment
    through a smartphone device. The SmartThings Hub works to connect the sensors,
    devices and building’s internet router to one another and to the cloud. It is
    compatible with different communication protocols such as Zigbee, Z-Wave, and
    IP-accessible devices. In addition, the SmartThings is compatible with other sensors
    and devices such as thermostats, moisture sensors, motion sensors, presence sensors,
    locks and garage door openers [63]. HomeOS [64] is Microsoft’s home operating
    system platform, that can be installed on a personal computer. It is an open platform
    that is not limited to Windows-based devices [65], [66]. with HomeOS platform,
    applications can be installed to maintain various context-aware functionalities,
    for example, taking an image by a door camera and sending it to the occupant when
    someone rings the doorbell. HomeOS provides a PC-like abstraction that manages
    and extends the technology of network devices to the users and developers in the
    smart building environment. Its design enables the users to map their protocol-independent
    services to support the applications with simple APIs, a kernel, and protocols
    of specific devices. HomeOS usually runs on an allocated computer such as a home
    gateway, it does not need any adjustments to commodity devices. HomeOS usually
    utilizes (i) Datalog-based access control to facilitate the process of managing
    technology in the smart home (ii) a kernel to incorporate the devices and applications
    and (iii) protocol-independent services to allow the developers manageable access
    to the devices. Lab of Things (LoT) [67], [68] is an experimental research platform
    that utilizes connected devices in the buildings. LoT offers a framework that
    provides deployment capabilities such as remote monitoring and updating of system
    health, and logging data collected from different appliances in cloud storage.
    It enables data sharing and collecting, sharing codes, connect hardware sensors
    to the software platform, and participants using HomeOS. The platform is designed
    to make it simple to design solutions that can be deployed in IoT based smart
    services such as healthcare, energy management services as it works in combination
    with HomeOS. Eclipse Smarthome [69] is a framework that has a focus on heterogeneous
    environments such as smart building and ambient assisted living. This platform
    takes to consider a variety of existing communication mechanisms. Eclipse SmartHome
    works as an abstraction and translation framework that enables communications
    across system and protocol boundaries. It provides many relevant implemented extensions,
    protocols, and standards that are significant for smart building services. Those
    implementations can be of Java library or an OSGi bundle shapes so that they can
    be utilized independently from the rest of the project. The framework can work
    on different embedded devices such as a BeagleBone Black, an Intel Edison, or
    a Raspberry Pi. Extensions of Eclipse SmartHome are compatible with the solutions
    provided by different vendors. This means your code that is written for a specific
    purpose can be extended easily on commercial platforms. Eclipse SmartHome offers
    a variety of characteristics to allow you to design a special Smart Home solution
    for your expectations [70]. Apart from discussing various SB solutions, we will
    also highlight the popular simulator called Cooja is used widely by the research
    community to produce small simulations for relatively large wireless networks
    of embedding sensors and actuators; and connected devices, in order to develop,
    debug and evaluate systems based on the wireless sensor network technology. Cooja
    simulator is a Java-based wireless sensor network simulator. It is distributed
    with Contiki OS project. Cooja enables the emulation of the set of sensor nodes,
    in addition, it can simulate physical and application layers of the system [71].
    There are three basic properties for the simulated node in Cooja: Its hardware
    peripherals, node type, and data memory. The node type can be shared among multiple
    nodes and defines properties that are common to all these nodes [72]. Summary:
    The field of SBs contains a variety of technologies, across commercial, industrial,
    institutional and domestic buildings, including building controls and energy management
    systems. Several organizations and institutions are working to supply buildings
    with technology that enables the residents to adopt a single device to control
    all electronic devices and appliances. In this section, we discussed the various
    components for SBs including sensors and actuators, smart control devices, smart
    gateway, networking and software platforms. SECTION IV. Ml Background for SBS:
    Models, Tasks, and Tools Massive data generated from sensors, wearable devices,
    and other IoT technologies provide rich information about the context of users
    and building status and can be used to design SB management. This context information
    is needed to extract useful and interesting insights for various stakeholders.
    When the data volume is very high, developing predictive models using traditional
    approaches does not provide accurate insight and we require newly developed tools
    from big data. Big data is primed to make a big impact in SBs and is already playing
    a big role in the architecture, engineering, and construction (AEC) industries
    [73], notably for waste analytics [74] and waste minimization [75]. ML is a powerful
    tool that facilitates the process of mining a massive amount of data that have
    been collected from different sources around us and make sense of a complicated
    world. ML algorithms apply a model on new data by learning the model from a set
    of observed data examples called a training set. For example, after being trained
    on a set of sample accelerometer data marked as walking or jogging, an ML algorithm
    can classify the future data points into walking and jogging classes. ML makes
    it relatively easy to develop advanced software systems without much involvement
    from the human side. They are applicable to many real-life problems in SB environments.
    One can also design and develop self-learning and collaborative systems. ML does
    not remove the human element from data science—it draws on computers’ strengths
    in handling big data to complement our understanding of semantics and context.
    It only needs training data to extract better features or parameters required
    to improve a given system. ML algorithms can be used to make predictions based
    on data patterns. It enables the computer to learn from the fed input data without
    being explicitly programmed so that ML algorithms can learn from and make predictions
    on input data [76], [77]. Nest thermostat is an example of a device that applies
    a specific temperature in a specific room and at a certain time of day according
    to the occupants’ preference. There are devices such as Amazon’s Echo that can
    learn from voice patterns, and the others those learn from much more complex behavior
    and activity patterns. A. Ml Models ML techniques have been widely used to develop
    smart systems which can sense and react according to context modifications in
    SBs [78]. There are many different ML algorithms, according to the two well-known
    theorems No Free Lunch theorem and Ugly Duckling theorem. No Free Lunch theorem
    states “there are no algorithms that can be said to be better than any other”,
    without prior information about the problem, any two algorithms may perform equally
    well in solving a problem. While Ugly Duckling theorem states “we cannot say that
    any two different patterns would be more similar to each other than any other
    pairs.” [79]. Mainly, ML is categorized into four categories handling different
    types of learning tasks as follows: Supervised learning, unsupervised learning,
    semi-supervised learning and reinforcement learning (RL) algorithms Figure 7 shows
    ML styles. These categories are described next and a summarized comparison between
    these ML techniques is presented in Table 5. TABLE 5 Comparison of ML Techniques
    FIGURE 7. ML styles. Show All 1) Supervised Learning refers to developing algorithms
    based on a labeled training dataset, from which the learner should generalize
    a representation by building the system model that represents the relations between
    the input, output and system parameters. ML model is developed through a training
    process that continues on the input training data until the model reaches the
    desired level of accuracy [80], [81]. Some examples of common supervised ML algorithms
    are: naive Bayes model, decision tree, linear discriminant functions such as support
    vector machines (SVMs), artificial neural networks (ANNs), hidden Markov models
    (HMMs), instance-based learning (such as k-nearest-neighbor learning), ensembles
    (bagging, boosting, random forest), logistic regression, genetic algorithms, and
    logistic regression [82], [83]. Supervised learning approaches are extensively
    used to solve different problems in smart buildings. Application in SBs: Boger
    et al. [76] proposed a supervised learning system using Markov decision processes
    to help people with dementia the process of hand washing. Altun et al. [84] make
    a comparative study on the supervised human activity classification approaches
    using body-worn miniature inertial and magnetic sensors. Mozer [85] developed
    the occupant comfort control of the home environment system using neural networks
    and reinforcement learning to control air heating, lighting, ventilation, and
    water heating in the smart home environment. Bourobou et al. [86] presented a
    hybrid approach using ANN and K-pattern clustering to identify and predict user
    activities in the smart environments. Hsu et al. [87] proposed a TV recommendation
    system using a neural network model based on user personalized properties such
    as activities, interests, moods, experiences, and demographic information data.
    Fleury et al. [88] proposed a healthcare-focused smart home system using the SVM
    algorithm to classify daily living activities based on the data from the different
    sensors. Supervised learning problems can be further grouped into classification,
    regression, time series, and ensemble method problems. a: Classification The task
    of classification algorithms is to classify an instance into a specific discrete
    set of possible categories. Given two sets of data (labeled and unlabeled datasets),
    the labeled dataset is used for the training process, while the unlabeled dataset
    will be used to evaluate of the classification results. The normal process is
    to count the number of instances that are assigned to the right category, which
    is also known as the accuracy rate (AR) defined by [21]. The classification algorithm
    can mathematically be described as follows: AR= N c N t (1) View Source where
    N c denotes the number of test instances that are correctly assigned to their
    categories to which they belong; N t the number of test instances. The precision
    ( P ) and recall ( R ) are used to measure the details of the classification results.
    The four possible outcomes are true positive ( TP ), false negative ( FN ), false
    positive ( FP ), and true negative ( TN ), the precision ( P ) and recall ( R
    ) are generally defined as: P= TP TP+FP (2) View Source Given P and R , a simple
    method to describe the precision and recall of the overall classification results,
    called F-score or F-measure, is defined as: F= 2PR P+R (3) View Source Commonly
    used classification techniques include decision trees, SVM, rule-based induction,
    neural networks, deep learning, memory-based reasoning, and Bayesian networks
    [89]. b: Decision Tree Algorithms The decision tree method is an important predictive
    ML modeling approach, which constructs a model of decisions presented based on
    the actual values of features in the data. Decision trees can be utilized for
    both classification and regression problems. In tree structures, leaves represent
    class labels and branches represent conjunctions of attributes that drive to those
    labels [90]. The decision trees that the target variable takes continuous values
    called regression trees. Decision trees are often one of the favorites of ML algorithms
    because of its speed and accuracy. The most common algorithms for decision tree
    are [91]: classification and regression tree, ID3, C4.5 and C5.0, Chi-squared,
    M5, and conditional decision trees. Application in SBs: Delgado et al. [92] propose
    an ML technique based on decision trees to extract the most frequent activities
    of human behavior and the temporal relationship of those activities in order to
    produce the human behavior quickly in a smart environment. Viswanathan et al.
    [93] introduce a prototype distributed data mining system for healthcare environment
    using C4.5 classification algorithm that can provide the patient monitoring and
    health services. Decision trees algorithm is a non-parametric algorithm that is
    easy to interpret and explain. The main disadvantage of this algorithm is that
    it can easily overfit. c: Bayesian Algorithms Bayesian methods utilize Bayes’
    theorem for classification and regression problems. The most common Bayesian algorithms
    are [94]: Naive Bayes, Gaussian naive Bayes, Bayesian belief network, Bayesian
    network. Application in SBs: Parnandi et al. [95] propose an indoor localization
    approach based on Naive Bayes classification and dynamic time warping, they exploit
    the embedded sensors of smartphones to determine the building that the user entered
    and the activities that the user is performing inside the building. Verbert et
    al. [96] proposed an ML approach based on Bayesian network to diagnosis the fault
    in HVAC systems. The model has been constructed based expert knowledge concerning
    conservation laws, component interdependencies, and historical data using virtual
    sensors. Naive Bayes classifier approaches have been applied with potential results
    for human activity recognition in [97], [98]. Naive Bayes approach recognizes
    human activities that identify with the highest probability to the set of sensor
    readings that were observed. d: Support Vector Machine (SVM) is a supervised ML
    algorithm which can be applied for both classification and regression problems
    though mostly used in classification challenges [140]. SVM is one of the most
    popularly utilized for many statistical learning problems, such as face and object
    recognition, text classification, spam detections, handwriting analysis etc. [141].
    is maximizing the margin that separating between the hyperplane of two classes’
    closest points. Support vectors are the points lying on the boundaries, and the
    optimal separating hyperplane is the middle of the margin [142]. Application in
    SBs: Fu et al. [105] proposed an SVM method to predict the system level electricity
    loads of public buildings that have electricity sub-metering systems. A real-time
    human tracker system proposed Nguyen et al. [106] using SVM for predicting and
    recognizing human motion based on the input images from a network of four cameras
    in the ubiquitous smart homes. Petersen et al. [107] developed an SVM model to
    predict the times where visitors are present in the home using only the data provided
    by wireless motion sensors in each room. Fleury et al. [88] presented a study
    for automatic recognition of daily living activities in a smart home based on
    SVM. They collected the data from various sensors such as Infra-Red Presence Sensors,
    door contacts, temperature and hygrometry sensor, and microphones. Das et al.
    [108] proposed a one-class classification approach for a real-time activity error
    detection in smart homes using one-class SVM. Zhao et al. [143] proposed an ML
    approach based on SVM and RNN to detect the occupancy behavior of a building through
    the temperature and heating source information for the energy efficiency consumption
    purposes. e: Artificial Neural Network Algorithms (ANNs) ANN models are inspired
    by the process of biological neural networks. ANN models are commonly utilized
    for regression and classification problems. The common ANN algorithms are [94]:
    Perceptron, Back-Propagation, Hopfield Network, and Radial Basis Function Network
    (RBFN). ANNs provide a number of advantages including it requires less statistical
    training, it has the capacity to detect complex nonlinear relationships between
    the predictor and response variables, as well as the ability to detect all possible
    relationships between predictor variables [104]. On the other hand, disadvantages
    include its “black box” nature, heavy computational burden and proneness to overfitting.
    However, due to the inherent features of neural networks, it has the following
    main limitations: challenge in training with no local optima, its accommodation
    to modifications in the behavior, the validation process of the results, and the
    complexity of network performance interpretation. Application in SBs: Badlani
    and Bhanot [99] developed a smart home system for energy efficiency applying pattern
    recognition based on ANNs, the system incorporates an RNN to capture human behavior
    patterns and an ANN for security applications in smart homes. Other researchers
    have applied ANNs to present context-aware services. Campo et al. [100] developed
    a system that calculates the probability of occupation for each section of the
    building and compares the probability with the current situation systematically.
    See [101] for a survey paper focusing on the role of ANNs for smart home services.
    Ermes et al. [102] proposed a hybrid classifier approach using a tree structure
    comprising a priori knowledge and ANN to recognize the activities such as rowing,
    biking, playing football, walking, running, sitting, or hiking. Ciabattoni et
    al. [103] proposed a home energy management system design using the neural network
    algorithm to predict the power production of the photovoltaic plant and the home
    consumptions during the given time. f: Deep Learning Algorithms: Deep learning
    methods represent an evolved form of ANNs in which a deep architecture (many layers
    comprising multiple linear and non-linear transformations [144]) is used. One
    of the promises of DL is replacing the manually selected features with efficient
    unsupervised or semi-supervised feature learning and hierarchical feature extraction
    algorithms. The most common DL algorithms are [145]: Convolutional Neural Network
    (CNN), Recurrent Neural Network (RNN), Deep Boltzmann Machine (DBM), Deep Belief
    Network (DBN), and Stacked Auto-Encoders. Deep learning has been used successfully
    in varieties of big data analytics applications, particularly natural language
    processing (NLP) applications, medical diagnosis, stock market trading, network
    security, and image identification. Deep learning is now ubiquitously used in
    major businesses and companies. Microsoft research on a deep learning system presented
    real-time speech translation system between Mandarin Chinese and English languages
    [146]. Apple’s Siri uses a deep learning trained model, and the voice recognition
    in the Google Android phone also uses a deep learning trained model [147]. DL
    utilizes a number of techniques such as drop-out and convolutions that enables
    the models to learn efficiently from high-dimensional data. However, DL requires
    much more data to train compared to other algorithms because of the magnitudes
    of parameters for estimation required by the models. Application in SBs: Choi
    et al. [114] propose two prediction algorithms deep belief network and restricted
    Boltzmann machines based on the DL framework for predicting different human activities
    in a building. They also presented a hybrid model which combines for predicting
    human behavior. The paper [115] proposes a generic deep learning framework based
    on convolutional and RNNs for human activity recognition that is suitable for
    multimodal wearable sensors, such as accelerometers, gyroscopes or magnetic field
    sensors. Alsheikh et al. [116] proposed a hybrid approach of DL and hidden Markov
    model for human activity recognition using triaxial accelerometers. Baccouche
    et al. [117] propose a two-steps neural-based deep model to classify human activities,
    the first step of the model is automatically learned spatiotemporal features based
    on Convolutional Neural Networks. Then the second step of the model uses an RNN
    to classify the entire sequence of the learned features for each time-step. In
    [118], they propose an acceleration-based human activity recognition method using
    Convolution Neural Network. In [119] a deep convolutional neural network as the
    automatic feature extractor and classifier for recognizing human activities is
    proposed using the accelerometer and gyroscope on a smartphone. Hammerla et al.
    [148] explore the performance of deep, convolutional, and recurrent approaches
    of deep learning for human activity recognition using wearable sensors. For the
    sake of measuring the performance, the authors used three representative datasets
    that comprise motion data collected from wearable sensors. g: Hidden Markov Models
    (Hmm) An HMM is a doubly stochastic process with a hidden underlying stochastic
    process that can be observed through the sequence of observed symbols emitted
    by another stochastic process. Application in SBs: Wu et al. [113] proposed an
    improved HMM to predict user behaviors in order to provide services for people
    with disabilities. They developed a temporal state transition matrix to be utilized
    instead of the fixed state transition matrix. Lv and Nevatia [112] used hidden
    Markov models for both automatic recognition and segmentation of 3-D human activities
    to allow real-time evaluation and feedback for physical rehabilitation. Cheng
    et al. [110] proposed an inference engine based on the HMM that provides a comprehensive
    activity of daily living recognition capability. They integrated both Viterbi
    and Baum-Welch algorithms to enhance the accuracy and learning capability. Chahuara
    et al. [111] proposed sequence-based models for online recognition of daily living
    activities in an SB environment. They presented three of sequence-based models:
    HMM, conditional random fields, and a sequential Markov logic network. h: Time
    Series Analysis A time series is a collection of temporal instances; time series
    data set usually have the following characteristics include the high dimensionality,
    large number of instances, and updating continuously [149]. One of the important
    purposes for time series representation is to reduce the dimension, and it divides
    into three categories: model-based representation, non-data-adaptive representation,
    and data-adaptive representation [150], [151]. Application in SBs: Survadevara
    et al. [125] proposed a wellness model using seasonal autoregression integration
    moving average time series with sleeping activity scenario in a smart home environment
    to forecast the elderly sleeping tendency. Zhou et al. [126] proposed a time series
    analysis framework to explore relationships among non-stationary time series in
    the case of data sensors in SBs. Jakkula and Cook [127] propose a time series
    based framework to determine temporal rules from observed physical and instrumental
    activities of occupants in a smart home. i: Regression The aim in regression problems
    is to estimate a real-valued target function. It is related to representing the
    relationship between variables that are repeatedly processed utilizing a measure
    of error in the predictions made by the model [152]. The most common regression
    algorithms are [153]: linear regression, logistic regression, stepwise regression,
    and ordinary least squares regression. Application in SBs: Chen et al. [120] used
    the regression technique of orthogonal matching pursuit algorithm to identify
    the physical and environmental parameters that providing the energy efficiency
    in an SB. Bouchard et al. [121] presented a gesture recognition system using linear
    regression combined with the correlation coefficient to recognize the gesture
    direction and estimate the segmentation of continuing gestures of daily usage
    activities in a smart environment. j: Ensemble Methods A combination of multiple
    classifiers often referred to as a classifier ensemble, group of classification
    models that are trained separately and the predictions of those models are then
    combined in a way to produce the overall prediction [154]. The most popular ensemble
    learning based classification techniques are [155]: random forest, boosting, gradient
    boosting machines, AdaBoost, bagging, and blending. Application in SBs: Jurek
    et al. [122] proposed a cluster-based ensemble approach solution for activity
    recognition within the application domain of smart homes. With this approach,
    activities are modeled as cluster collections built on different subsets of features.
    Fatima et al. [123] proposed an ensemble classifier method for activity recognition
    in smart homes using genetic algorithm optimization to merge the prediction output
    of multiple classifiers that make up the ensemble. They used the ANN, HMM, conditional
    random field, and SVM [13] as base classifiers for activity recognition. Guan
    and Ploetz [124] proposed a deep LSTM ensemble method for activity recognition
    using wearables: more specifically, the authors developed modified training procedures
    for LSTM networks and proposed the combination of sets of diverse LSTM learners
    into classifier collectives. 2) Unsupervised Learning Unsupervised Learning refers
    to developing algorithms that use data with no labels to analyze the behavior
    or the system being investigated [156]. Thus, the algorithm does not know about
    the truth of the outcome. In other words, the unsupervised learning algorithm
    classifies the sample sets to different clusters by investigating the similarity
    between the input samples. Clustering is done using different parameters taken
    from the data which enable us to identify correlations which are not so obvious.
    The inferring structures existing within the input data is used to prepare the
    model to prepare and extract general rules of the model. A mathematical process
    might be used to systematically reduce redundancy, or organize data by similarity
    [129]. The unsupervised approach has been applied to recognize various activities
    in smart buildings when it is challenging to have labels for input data [130].
    Common unsupervised learning problems are clustering, dimensionality reduction,
    and association rule learning. There are a variety of commonly used unsupervised
    learning algorithms, some of those algorithms are based on supervised-learning
    algorithms: the Apriori algorithm and k-Means. In unsupervised learning, usually
    there is no a measure for the output; we recognize only the features and the target
    is to define the patterns and relationships among a set of input measures [80].
    The major disadvantage of unsupervised learning is the absence of direction for
    the learning algorithm, hence, there might not be any useful detected knowledge
    in the selected set of attributes for the training. Clustering is a method of
    unsupervised learning that involves detecting patterns in the data by placing
    each data element into a group of K-clusters, where each group holds data elements
    most similar to each other [157]. Unsupervised learning problems can be categorized
    into clustering and association problems, which are described next. a: Clustering
    A clustering problem explores the internal groupings in the input data, such as
    grouping customers by their purchasing habits. Clustering techniques are usually
    organized by modeling strategies such as centroid-based and hierarchical. All
    methods are concerned with handling the internal structures in the input data
    to properly organize the data into groups of maximum commonality [158]. The quality
    of the clustering result is evaluated depends on the type of application that
    utilizes a clustering algorithm. For example, the sum of squared errors is generally
    utilized for data clustering while the peak-signal-to-noise ratio is used for
    image clustering [21]. The most common clustering algorithms are [153]: k-Means,
    k-Medians, expectation maximization, and hierarchical clustering. Application
    in SBs: Fahad et al. [128] propose an activity recognition approach that combines
    the classification with the clustering, in their approach the activity instances
    are clustered using Lloyd’s clustering algorithm. Then, they apply evidence theoretic
    K-Nearest neighbors learning method that combines KNN with the Dampster Shafer
    theory of evidence. The paper [86] proposes a hybrid approach to recognize and
    predict user activities in a smart environment. They use the K-pattern clustering
    algorithm to classify so varied and complex user activities, and ANN to recognize
    and predict users’ activities inside their personal rooms. Lapalu et al. [82]
    used an unsupervised learning approach to address the issues of daily living activities’
    learning in smart home. They utilize the Flocking algorithm for clustering analysis
    of a use case in cognitive assistance service that assists the people suffering
    from some type of dementia such as Alzheimer’s disease. Aicha et al. [83] present
    an unsupervised learning approach for detecting abnormal visits of an elderly
    in a smart home environment based on a Markov modulated Poisson process model.
    The model combines multiple data streams, such as in the front-door sensor transitions
    and the general sensor transitions. The other cases of social communication services,
    Rashidi and Cook [129] applied an unsupervised learning approach to detect social
    interaction and monitor activity daily living in a smart space, their approach
    can adapt and update automatically to reflect the changes in discovered patterns
    from implicit and explicit identified feedbacks of the occupant. Rashidi et al.
    [130] introduce an unsupervised method that identifies and tracks the normal activities
    that commonly occur in an individual’s routine in a smart environment. The activity
    discovery method of the system is produced to cluster the sequences based on the
    simple k-means algorithm. Fiorini et al. [159] proposed an unsupervised ML approach
    to identify the behavioral patterns of the occupants using unannotated data collected
    from low-level sensors in an SB. Their approach involves processing and analyzing
    collected data related to the daily living activities of 17 older adults living
    in a community-based home supplied with a variety of sensors. They extract activity
    information from collected data at different times of the day. b: Association
    The association rule learning problem is utilized to identify the rules that define
    large portions of input data, such as people that buy X item also tend to buy
    Y item. Association analysis is performed on rules discovered by analyzing input
    data for frequent if/then statement and using the criteria of support and confidence
    to discover relationships between unrelated data in a relational database or another
    information repository. Here “support” indicates how frequently the items appear
    in the database while “confidence” indicates the number of times the if/then statements
    have been found to be true. Many algorithms for generating association rules have
    been proposed. Apriori algorithm is the most well-known association algorithm
    [160]. Application in SBs: Aztiria et al. [161] proposed system that learns the
    frequent patterns of human behavior using association, workflow mining, clustering,
    and classification techniques. The core part of the system is the learning layer
    which is made up of two modules: the language module, which provides a standard
    conceptualization of the patterns; and the algorithm module, which discovers the
    patterns. Kang et al. [162] proposed a service scenario generation scheme for
    interpreting association rules extracted from the states of all devices in SB
    environments. Typically, These states are collected periodically at a specific
    time interval from the devices. Nazerfard et al. [163] propose a framework to
    discover the temporal features of the activities, including the temporal sequencing
    of activities and their start time and duration using the temporal association
    rule techniques in a smart home. 3) Semi-Supervised Learning Semi-Supervised learning
    lies between supervised and unsupervised methods. Input data is a composite of
    labeled and unlabeled samples. These hybrid algorithms aim to inherit the strengths
    of the main categories while mitigating their weaknesses. The model learns the
    patterns present in the data and also make predictions. Example problems are classification
    and regression [164]. There are some common semi-supervised learning models, including
    generative models, heuristic approaches, semi-supervised SVM, graph-based methods,
    self-training, help-training, mixture models, co-training and multi-view learning
    [94]. Application in SBs: Cook [131] combined fully-supervised and semi-supervised
    learning to recognize and follow activities that support health monitoring and
    assistance context-aware services for people experiencing difficulties living
    individually at smart homes. Liu et al. [132] proposed a vision based semi-supervised
    learning approach for fall detection and recognizing other activity daily living
    in smart environments to overcome the labeling challenges of human activities
    by systematic interpreting the activities with the highest confidence. Fahmi et
    al. [133] proposed a semi-supervised fall detection approach in which a supervised
    algorithm utilizing decision trees in the training process and then profiles are
    used to implement a semi-supervised algorithm based on multiple thresholds. Radu
    et al. [134] present semi-supervised ML method using only the low power sensors
    on a smartphone to consider the problem of determining whether a user is indoors
    or outdoors. Guan et al. [135] propose a semi-supervised learning algorithm for
    activity recognition named En-Co-training to make use of the available unlabeled
    samples to enhance the performance of activity learning with a limited number
    of labeled samples. The proposed algorithm extends the co-training paradigm by
    using an ensemble method. 4) Reinforcement Learning Reinforcement learning is
    a learning approach to control a system in order to maximize performance measure
    that represents a long-term objective [165]. Reinforcement learning, an area of
    ML inspired by behaviorist psychology, is concerned with the way that software
    agents have to take actions in an environment in order to maximize the concept
    of cumulative reward. RL algorithms learn control policies, particularly when
    there is no a priori knowledge and there is a massive amount of training data.
    However, RL algorithms suffer from some drawback such as the high computational
    cost required to find the optimal solution, such that all states need to be visited
    to choose the optimal one. The well-known approaches of RL are Brute force, Monte
    Carlo methods, Temporal difference methods, and Value function [166]. Q-learning
    [167] is a model-free reinforcement learning approach based on learning the required
    utility given a state decision. Application in SBs: Mozer [136] applied Q-learning
    for lighting regulation to predict the time of turning the lights ON/OFF in a
    building. This prediction model can be utilized to schedule the lights’ activations
    in a building for efficient energy consumption proposes. Li and Jayaweera [137]
    proposed a Q-learning based approximate dynamic programming algorithm to provide
    a more efficient, flexible and adaptive method. This approach can enable customers
    to make an optimal on-line decision making in SB environment to maximize the profits
    based on both local fully observable and the estimated hidden information of the
    building. Khalili and Aghajan [138] proposed a temporal differential class of
    RL method for autonomous learning of a user’s preference of music and lighting
    service settings in presence of different states of the user in SB environment.
    The preferences are learned by the model by using the explicit or implicit feedback
    from users when they react to the provided service. Xu et al. [139] give a survey
    of developments in RL algorithms with function approximation. They evaluated and
    compared different RL algorithms using several benchmark learning, prediction,
    and learning control tasks. B. ML Tasks for SBS In this section, we will describe
    the major ML tasks that are relevant to SB. The reader is referred to Figure 8
    for a general depiction of ML tasks in SBs and the steps taken to implement ML
    in an SB environment. FIGURE 8. ML tasks in SB environment. Show All 1) Data Collection
    and Acquisition A variety of data collection approaches are used, each of which
    has different deals in terms of capabilities, energy efficiency, and connectivity.
    Sensors and similar objects in SBs produce raw data simultaneously in an automated
    way and such devices may store the data for a specific period of time or report
    it to controlled components [168]. Data can be collected at gateways; the collected
    data is then filtered and processed, fused into compact forms for efficient transmission.
    A variety of communication technologies such as Zigbee, Wi-Fi, and cellular are
    utilized to transfer data to collection points. Data collected from a global-scale
    deployment of smart things defines the basis for decision making and providing
    services. It is possible that the decisions are unreliable when the quality of
    utilized data is poor [169]. Zhao et al. [170] propose a data acquisition and
    transmission system which could be used for monitoring systems to collect energy
    consumption data (e.g., electricity, water, gas, heating, etc.) from terminal
    meters which are installed in buildings. The system stores the data periodically
    after analyzing and processing it and finally transmits the data to servers through
    the Ethernet. Rowley et al. [171] propose the data acquisition and modeling approaches
    that can support the delivery of building energy infrastructure in both new building
    and renovated real-world contexts. Such methods provide a means to achieve short,
    medium and long-term forecasting of possible scenario pathways to multi-objective
    sustainable outcomes. CLEEN MMEA [172] platform that collects, processes, and
    manages the data and initiates contextual knowledge extraction. The purpose is
    to establish an online marketplace to collect data and provide services for different
    companies. The interfaces are made public so that any company can easily join
    the network to buy or sell services. The analysis results can be given to an energy
    services company in order to allow offering the service to the owners. A typical
    example of open access data collection system is e3Portal [173] developed by VTT
    in collaboration with Finnish municipalities. e3Portal offers information and
    tools when planning savings measures and energy retrofitting in municipal buildings.
    It also involves frequently updated data regarding energy and water consumption
    in thousands of public buildings like schools, kindergartens, offices, hospitals,
    other health care facilities, etc. Decision makers, designers, operation and maintenance
    personnel, as well as buildings users, can utilize it. There are projects that
    provide publicly available SB datasets for researchers to conduct further studies;
    A list of “Home Datasets” [174] includes the datasets collected by projects from
    UC Berkeley, MIT, Washington State University, University of Amsterdam, University
    of Edinburgh, and the University of Tokyo. The WARD [175] project supported by
    NSF TRUST Center at UC Berkeley provides a benchmark dataset for human action
    recognition using a wearable motion sensor network. The dataset was collected
    from 13 repetitive actions by 13 male and 7 female participants between the ages
    of 19 and 75. An MIT project [176] collected daily live activities dataset from
    two single-person apartments within a period of two weeks. Eighty-four sensors
    to record opening-closing events were attached to different appliances and devices
    such as drawers, refrigerators, containers, etc. Banos et al. [177] introduced
    an open benchmark dataset collected from various inertial sensors attached to
    different parts of the body. They considered 33 fitness activities, recorded using
    9 inertial sensor units from 17 participants. The CASAS project [178] at Washington
    State University provides a publicly-available dataset for a three-bedroom apartment
    with one bathroom, a kitchen, and a living room. Different types of motion and
    digital sensors are installed to support temperature readings, in addition, the
    analog sensors are installed to support readings for hot water, cold water, and
    stove burner use [179]. The PlaceLab project [180] of MIT provides a dataset collected
    from a one-bedroom apartment with more than 900 sensors, including those coming
    from motion, switch and RFID sensors. That is being used to monitor activity in
    the environment in the context of a smart home [181]. A collection of smart meters
    data from five houses in the UK [182] That consists of 400 million instances.
    The active power is formed by different appliances and the whole-house power demand
    every 6 seconds. The major challenges that arise for data collection are scalability,
    privacy, security, and heterogeneity of resources [183]. Automated sensor data
    collection process collects a large amount of data that overwhelms the collection
    and analysis centers in comparison to the data collected from other sources such
    as IoT devices and social media. This leads to a huge number of small synchronous
    write operations to the database storage system, consequently, resulting in serious
    performance bottlenecks to the storage system design [184]. Because of the extensive
    use of RFID technology, privacy issues arise in data collection; for example,
    the RFID tags carried by a person may become a unique identifier for that person.
    Also, other security concerns appear, for example, the radio signals of RFID technology
    are easily jammed. Hence, that can disrupt the data collection process [185].
    The heterogeneity of data that is being collected from different resources is
    another major challenge, such that the data are usually very noisy, large-scale,
    and distributed. This makes it very difficult to use the collected data effectively
    without a clear description of existing data processing techniques [184]. 2) Data
    Preprocessing A large amount of data are generated by sensors in SBs; this data
    comes from various sources with diverse formats and structures. Usually, this
    data is not ready for analysis as it might be incomplete or redundant due to low
    battery power, poor calibration, exposure to various malicious elements and interference.
    Therefore, raw data typically needs to be preprocessed to deal with missing data,
    discard noisy and redundant data and integrate data from various sources into
    an integrated schema before being committed to storage. This preprocessing is
    called data cleaning. The quality of data can be improved substantially by applying
    some cleaning techniques to the data before it arrives its end user [168], [186].
    Data cleaning is one of the significant tasks in the data processing phase. Data
    cleaning is not a new process particular for the IoT data processing. It has already
    been applied as a process for database management systems. Presenting a data cleaning
    method would further aid the applications to focus on their core logic without
    worrying about data reliability post-processing overheads [184]. There are many
    different techniques that have been utilized to deal with the problem of cleaning
    noisy data streams such as Kalman filters [187], statistical models [186] and
    outlier detection models [184]. One of the major challenges with data cleaning
    techniques in the SBs is the heterogeneity of data collected from different sources
    particularly WSN- and RFID-enabled data streams. The utilized data cleaning techniques
    should be able to deal with several different variables of interest to satisfy
    IoT applications’ requirements, for example, setting home temperature based on
    observed outer temperature, user habits, energy management, etc. [169] Any type
    of failures such as a failed sensor, network issues, camera failure, or database
    crashes in the process of collecting data would invalidate the data. Consequently,
    this type of impediment will dramatically increase the time required to collect
    data [179]. 3) Dimensionality Reduction There are huge volumes of raw data that
    are captured from heterogeneous and ubiquitous of sensors used in SBs. Most of
    the data collected from those sensors are redundant and they need to be brought
    down to a smaller number of features by applying dimensionality reduction techniques
    without losing significant information [188]. The main idea from the dimensionality
    reduction strategy is to find a new coordinate system in which the input data
    can be represented with much fewer features without losing significant information.
    The dimensionality reduction can be made in two different ways: by extracting
    of the features that represent the significant data characteristics (this technique
    is called feature extraction), or by only selecting the most relevant features
    from the original dataset, this method is called feature selection [189], [190].
    Like clustering methods, the dimensionality reduction approach explores and exploits
    the internal structure of the data, but in this case in an unsupervised manner
    using less information. Most of these techniques can be utilized in classification
    and regression problems. Examples of some salient algorithms are [153]: Principal
    Component Analysis (PCA), Principal Component Regression (PCR), and Linear Discriminant
    Analysis (LDA). Chen et al. [191] propose a framework using the classification
    information of local geometry of data to reduce the dimensionality of a dataset
    on human activity recognition from wearable, object, and ambient sensors. a: Feature
    Extraction The main components of the original data are the features. After extracting
    the features from the raw dataset, such features contain important information
    that is used by the learning algorithms for the activities discrimination. The
    most common methods of feature extraction work in time, frequency, and discrete
    domains [192]. Among time domain method, mean and standard deviation are the key
    approaches for almost all sensor types. While the frequency domain method focuses
    on the periodic structure of the collected data. Wavelet Transformation and Fourier
    Transform are the most common approaches. And discrete domain methods such as
    Euclidean-based distances, dynamic time warping, and Levenshtein edit distance
    are key approaches implemented in several applications such to string similarity,
    classifying human activities and modeling human behavioral patterns [16], [193].
    b: Feature Selection The main role of feature selection is to discriminate the
    most related subset of features within a high dimensional vector of features,
    so that reduces the load of noise and computational expense on the learning models.
    In order to map the high dimensional vector of features into a lower dimensional
    vector, there are several common algorithms used such as Linear Discriminant Analysis
    (LDA), Principal Component Analysis (PCA), and Independent Component Analysis
    (ICA) [194]. Hausmann and Ziekow [195] proposed an approach for automatically
    adapting the feature selection for SBs application ML models from the time-series
    data based on wrapper methods and genetic optimization. Fahad et al. [196] propose
    an activity recognition approach for overlapping activities using K-Nearest neighbors
    approach that distinguishes the most important features from the collected information
    obtained from deployed sensors in multiple locations and objects. Fang et al.
    [197] determine that the different feature sets generate different levels of accuracy
    for recognizing human activities, and selecting inappropriate datasets increases
    the level of computational complexity and decreases the level of prediction accuracy
    in smart home environments. The wrapper and filtering are the two main statistical
    methods of feature selection problem. It is argued that although the wrapper approach
    may obtain better performances, filters are less resource intensive and faster
    [198]. In [199], different feature selection methods are utilized for the process
    of dimensionality reduction of the learning problem to recognize the human activities
    from observed sensors. The authors show that the performance of the learning models
    to recognize the human activity has a strong relationship with the utilized features.
    c: Feature Projection feature projection can be represented as a mapping from
    the original set of features to an appropriate set that optimizes the learning
    criterion, such that the feature projection approach allows the process of visualizing
    and mapping the high-dimensional feature vectors to low dimensional one, in addition,
    it enables analyzing the distribution of the reduced feature vectors [200]. Consequently,
    the feature projection approach reduces the pattern recognition’s processing time
    and enables selecting the best-performed classifier for the reduced feature vectors.
    Hence, it makes real-time implementation possible [198]. Chu et al. [201] proposed
    a linear supervised feature projection that utilizes the LDA algorithm for EMG
    pattern recognition that attempted to recognize nine kinds of hand motion. C.
    ML Tools & Platforms for SBs There are a variety of existing ML platforms and
    tools to support the learning process. With the current increasing number of those
    kinds of toolkits, the task of selecting the right tool for processing big data
    streaming from various sources can still be difficult. Typically, there is no
    single toolkit that truly fits and provides solutions for all different problems.
    Many of the available toolkits might have overlapping uses, and each has advantages
    and disadvantages. Most of those toolkits might require experiences in the domains
    of programming languages and system architecture. In addition, usually many people
    lack a full understanding of the capabilities and how to use those available platforms
    [202]. The important factors that must be considered when selecting a specific
    ML tool are scalability, speed, coverage, usability, extensibility, and programming
    languages support. With respect to the scalability factor, the size and complexity
    of the data should be considered to determine if a specific toolkit will be fit.
    The processing platform that the library is running on and the complexity of the
    algorithm affect the speed factor. Not all the projects prioritize the speed factor;
    if the models require frequent updates, the speed may be a crucial concern; but
    not otherwise. Coverage represents the number of ML algorithms implemented in
    the tool. With the massive amount of data capturing from heterogeneous sources,
    ML community faces the challenges of how the ML model can efficiently process
    and learn from the big data. In general, the available big data tools do not implement
    all varieties of different classes of ML algorithms, and typically their coverage
    ranges from a few algorithms to around two dozen. The usability factor includes
    elements such as initial setup processing; continuous maintenance; the available
    programming languages and user interface available; the amount of documentation,
    or availability of a knowledgeable user. The extensibility factor means that the
    implementations introduced in the tools can be utilized as building blocks towards
    new systems. It is necessary to evaluate tools in terms of how well they are able
    to meet this factor. There are a variety of ML libraries that are available in
    different programming languages. Depending on the task you are trying to accomplish,
    certain languages, libraries, and tools can be more effective than others. The
    following provides a detailed observation of the strengths and weaknesses of the
    top used deep learning and ML tools. The reader is also referred to Table 6 for
    a concise tabulated summary of the described deep learning and ML tools. TABLE
    6 Comparison Between Deep Learning and ML Tools 1) H2O H20 [203] is an open-source
    in-memory, distributed, and scalable ML framework for big-data analysis that supports
    ML libraries, along with tools for parallel processing, analytics, data preprocessing
    and evaluation tools. It is produced by the H2O.ai, which launched in 2011 in
    Silicon Valley. The most notable feature of this product is that it provides numerous
    tools for deep neural networks. The H2O software APIs can be called from Python,
    Java, R, and Scala. Users without programming expertise can still utilize this
    tool via the web-based User Interface. In addition to the processing engine provided
    by H2O framework, it also allows the users to integrate their models with other
    available frameworks such as Spark and Storm. Depending on what is suitable for
    the algorithm, The H2O’s engine uses multiple execution methods to process data
    completely in memory. The general technique used is distributed Fork/Join, which
    is reliable and suitable for massively parallel tasks. The H2O software can be
    run on different operating systems such as Microsoft Windows, Mac OS X, and Linux
    (e.g. Ubuntu 12.04; CentOS), It also runs on Apache Hadoop Distributed File System
    (HDFS) and Spark systems for big-data analysis. In addition, it can operate on
    various cloud computing environments such as Amazon EC2, Google Compute Engine,
    and Microsoft Azure. As of July 2016, the algorithms supported in H2O cover the
    tasks classification, clustering, generalized linear models, statistical analysis,
    ensembles, optimization tools, data preprocessing options and deep neural networks.
    2) MLlib (Spark) MLlib [204] is Apache Spark’s ML library. MLlib aims to provide
    scalable and easy to use ML methods. It includes common ML algorithms for classification,
    regression, clustering, dimensionality reduction, as well as lower-level optimization
    primitives and higher-level pipeline APIs. The classification techniques of SVM,
    random forest, logistic regression, Naïve Bayes, decision trees, and gradient-boosted
    trees are supported whereas for clustering, k-means, Gaussian mixture, and power
    iteration clustering are supported. MLLib supports implementations for linear
    regression and isotonic regression, and incorporates a collaborative filtering
    algorithm using alternating least squares. PCA is supported for dimensionality
    reduction. MLlib includes APIs for development in Scala, Java, Python, and SparkR.
    Generally, MLlib depends on Spark’s iterative batch and streaming approaches,
    as well as its use of in-memory computation. 3) Tensorflow Tensorflow [205] is
    an open source software library for numerical computation and deep ML in a variety
    of perceptual and language understanding tasks utilizing data flow graphs. TensorFlow
    was originally developed by the Google Brain team and was released in November
    2015 under an Apache 2.0 open source license. TensorFlow has tools that support
    deep learning, reinforcement learning, and other algorithms. TensorFlow implements
    data flow graphs, where “tensors” are batches of data that can be processed by
    a set of algorithms defined by a graph. The movements of the data through the
    system are called “flows”—hence, the name. TensorFlow can run on multiple CPUs
    and GPUs. It can run on Linux, Mac OS X desktop, and server systems, and Windows
    support on roadmap, as well as on Android and Apple’s iOS mobile computing platforms.
    TensorFlow is written with a Python API over a C/C++ engine that makes it run
    fast. TensorFlow utilizes a symbolic graph of vector operations method, in order
    to easily define a new network. However, TensorFlow has a weakness that is related
    to modeling flexibility. Such that each computational flow has to be constructed
    as a static graph. That makes some computations such as beam search difficult.
    4) Torch Torch [206] is an open source ML computing framework that supports a
    variety of ML algorithms. Torch was originally developed at NYU. It is efficient
    and easy to use, thanks to a script language based on the Lua programming language
    and a C/CUDA implementation, Torch was intended to be portable, fast, extensible,
    and easy to use in development. Some version of Torch is employed by large companies
    such as Google DeepMind, the Facebook AI Research Group, IBM, Yandex, and the
    Idiap Research Institute. In addition, it has been extended to run on Android
    and iOS platforms. A variety of community-contributed packages for Torch, giving
    it a versatile range of support and functionality. It provides various deep learning
    algorithms that support computer vision; signal, image, video, and audio processing;
    parallel processing and networking [207]. 5) Deeplearning4j Deeplearning4j [221]
    is an open source distributed DL library, primarily developed by Adam Gibson from
    an ML group in San Francisco. Deeplearning4j is written for Java and JVM as well
    as to support a variety of DL algorithms such as restricted Boltzmann machine,
    deep belief networks, convolutional networks, recurrent neural networks, deep
    autoencoder, stacked denoising autoencoder, and recursive neural tensor network.
    All these algorithms can be integrated with Hadoop and Spark for distributed parallel
    processing. Deeplearning4j relies on Java programming language, in addition, it
    is compatible with Clojure and includes a Scala API. Deeplearning4j is designed
    to be utilized in business environments, rather than as a research tool. It is
    applied in a variety of applications such as fraud detection, anomaly detection,
    recommender systems, and image recognition. 6) Massive Online Analysis (Moa) MOA
    [222] is one of the common open source frameworks for data stream mining and possessing.
    MOA is written in Java related to the WEKA project that developed at the University
    of Waikato, New Zealand. It includes a set of learners and stream generators that
    can be used from the GUI, the command-line, and the Java API. MOA supports a variety
    of ML algorithms for classification, regression, clustering, outlier detection,
    as well as some tools for evaluation [223]. 7) Caffe Caffe [224] is a DL framework,
    it is primarily developed with the consideration of expression, speed, and modularity.
    It utilizes the machine-vision library for fast convolutional networks from Matlab,
    which has been ported to C and C++. It is developed by the Berkeley vision and
    learning center and by the community contributors. In Caffe, multimedia scientists
    and practitioners have an organized and state-of-the-art toolkit for DL algorithms.
    Caffe was originally developed for machine-vision, it has been utilized and improved
    by users in other fields such as robotics, neuroscience, speech recognition, and
    astronomy. In addition, it supports Python and MATLAB code bindings. Caffe offers
    image classification with state of the art CNN algorithm. Caffe is mainly utilized
    as a source of pre-trained models hosted on its Model Zoo site. Caffe is useful
    for performing image analysis using CNNs and regional analysis within images using
    RCNNs. The performance and processing speed of Cafee make it as one of the most
    utilized platforms for research experiments and industry deployment. It has the
    capability to process over 60 million images per day with a single NVIDIA K40
    GPU. Caffe has already been applied in many research projects at UC Berkeley and
    other universities, performing very well in many tasks such as object classification,
    object detection, and Learning Semantic Features. It provides a complete and well-documented
    toolkit for training, testing, tuning, and deploying models. Caffe utilizes a
    large repository of pre-trained neural network models called the Model Zoo, which
    is suitable for a variety of common image classification tasks [225]. 8) Azure
    Ml Microsoft first launched Azure ML [226] as a preview in June 2014. Azure ML
    enables users to create and train models, then convert those models into APIs
    that can be applied to other services. Users can get up to 10GB of storage per
    account for model data, although they can also connect their own Azure storage
    to the service for larger models. programmers can use either the R or Python programming
    language for developing with Azure services. Users can purchase ML algorithms
    from Microsoft Azure Marketplace, they can also obtain free algorithms from the
    community gallery that has been created by Microsoft to share ML algorithms with
    each other. They share many of predictive analytics of personal assistant in Windows
    Phone called Cortana. Azure ML also utilizes solutions from Xbox and Bing. Azure
    currently supports different features and capabilities such as run Hadoop over
    Ubuntu Linux on Azure, it also supports hosting Storm for analyzing data streams.
    In addition, it allows developers to connect.NET and Java libraries to Storm.
    Azure ML studio supports a variety of modules for training, scoring, and validation
    processes. Azure ML comes with a large library of algorithms for predictive analytics.
    The popular families of algorithms are regression, anomaly detection, clustering,
    and classification. D. Real-Time Big Data Analytics Tools for SBS Several applications
    need to have real-time data analysis for stream data and waiting for the information
    to be archived and then analyzed is not practical for these type of applications.
    Generally, Stream processing is intended to analyze a massive amount of data and
    act on real-time streaming data utilizing continuous queries such as SQL-type
    queries to handle streaming data in real-time utilizing scalable, available and
    fault-tolerant architecture. Essential to stream processing is Streaming Analytics.
    More and more tools offer the possibility of real-time streaming data. The following
    presents some of the common and widely used options. 1) Apache Storm Storm [227]
    is an open source distributed real-time data processing framework that provides
    massively scalable event collection. The initial release was on 17 September 2011,
    it was created by Nathan Marz and the team at BackType, and is now owned by Twitter.
    Storm can easily process unlimited streams and with any programming language.
    It has the capability to process over one million tuples per second per node with
    a highly scalable, fault-tolerant, and reliable architecture. Storm is written
    in Java and Clojure. Trident is a high-level abstraction layer for Storm, can
    be utilized to accomplish state management persistence. Storm is a system of complex
    event processing. This type of solution allows companies to respond to the arrival
    of sudden and continuous data (information collected in real-time by sensors,
    millions of comments generated on social networks such as Twitter, WhatsApp and
    Facebook, bank transfers etc.). Some of the specific applications of Storm include
    customer service management in real-time, operational dashboards, data monetization,
    cybersecurity analytics, and threat detection. 2) Apache Kafka Kafka [228] is
    a fast, scalable, fault-tolerant and durable open-source message broker project
    that originally developed by LinkedIn, and subsequently open sourced in early
    2011 and released by Apache Software Foundation on 23 October 2012. Kafka is written
    in Scala. It supports a variety of use case scenarios with a focus on high throughput,
    reliability, and scalability characteristics. For example, it can message sensor
    data from heating and cooling equipment in office buildings. 3) Oracle In 2013,
    Oracle started utilizing Oracle Enterprise Manager that includes Oracle Big Data
    Appliance to manage all of its big-data technologies. Oracle has also produced
    multiple low-latency technologies for Oracle Fast Data components includes Oracle
    Event Processing, Coherence, NoSQL, Business Analytics, and Real-Time Decisions.
    Oracle Event Processing provides solutions for building applications to filter,
    correlate and process events in real-time. It supports IoT services by delivering
    actionable insight on data streaming from a variety of data sources in real-time
    [229]. Oracle Stream Explorer (OSX) and Oracle R Enterprise (ORE) aim to support
    equipment monitoring applications for the systems that made of a variety of components
    through sensors, anomaly detection and failure prediction of such systems. ORE
    [230] is utilized to handle low-frequency streams in batch mode, while OSX handles
    the high-frequency streams making real-time predictions and sends the results
    back to user applications that are communicating with the output channels. OSX
    [231] is a middleware platform has the capability to process large amounts of
    streaming data in real-time for a variety of streaming data applications, from
    a multitude of sources like sensors, social media, financial feeds, etc. It streamlines
    real-time data delivery into most popular big data solutions, including Apache
    Hadoop, Apache HBase, Apache Hive, Apache Flume, and Apache Kafka to facilitate
    improved insight and timely action. Oracle Real-Time Decisions [232] is a decision
    management platform with self-learning that determines optimized recommendations
    and actions with messaging, imagery, products, and services within business processes.
    4) Amazon Kinesis Streams Amazon Kinesis [233] is a platform for collecting and
    processing large streams of data on AWS in real-time, AWS launched Kinesis in
    November of 2013, offering powerful services for loading and analyzing streaming
    data, in addition, it provides custom streaming data applications for specialized
    needs. Sometimes Terabytes of data per hour can be generated - that need to be
    collected, stored, and processed continuously from various application services
    such as web applications, mobile devices, wearables, industrial sensors etc. Typically,
    Amazon Kinesis Streams application can use the Amazon Kinesis Client Library and
    reads data from an Amazon Kinesis stream as data records. These applications can
    run on Amazon EC2 instances. 5) Apache Spark Streaming Apache Spark [234] is an
    open-source platform for real-time data processing, it can implement using four
    different languages: Scala, the syntax in which the platform is written; Python;
    R; and Java. Spark Streaming is an extension of core Spark API. It allows building
    fault-tolerant processing of real-time data streams. Spark Streaming allows the
    processing of millions of data among the clusters, and Spark SQL which makes it
    easier to exploit the data through the SQL language. Spark Streaming divides the
    live data stream into a predefined interval of batches, then handles each batch
    of data as Resilient Distributed Datasets (RDDs). Then we can apply operations
    like map, reduce, join, window etc. to process these RDDs. The last results of
    these operations are then returned in batches. Spark Streaming can be utilized
    for a variety of application such as real-time monitoring and analyzing of application
    server logs. These logs messages are considered time series data. Examples of
    such type of data are sensor data, weather information, and clickstream data.
    This data can also be utilized for predicting future states based on historical
    data. Apache assures a computation speed that performs the operations quicker
    by 100 times than what is currently offered by Hadoop MapReduce in memory, and
    10 times better than in disc. Spark can be executed either in independent cluster
    mode or in the cloud on different frameworks such as Hadoop, Apache Mesos, and
    EC2. In addition, Spark can access numerous databases such as HDFS, Cassandra,
    HBase or S3, Amazon’s data warehouse. 6) Apache Flume Flume [242] is a distributed,
    reliable and open-source log data aggregation framework. Apache Flume is applied
    in many applications ranging from log data aggregation, to transport massive quantities
    of event data including network traffic data, social-media-generated data, email
    messages and pretty much any data source possible into the HDFS. The architecture
    of Flume is simple and flexible, it is also robust and fault tolerant with tunable
    reliability mechanisms for failover and recovery. log manufacturing operations
    is an example of Flume’s application. The a massive log file data can stream through
    Flume. The log file data can be stored in HDFS and analyzed by utilizing Apache
    Hive. 7) Apache Samoa SAMOA [243] is a distributed streaming ML framework that
    contains programming abstractions for distributed streaming ML algorithms. Its
    name stands for Scalable Advanced Massive Online Analysis and was originally developed
    at Yahoo! Labs in Barcelona in 2013 and has been part of the Apache incubator
    since late 2014. SAMOA is both a platform and a library. It enables the algorithm
    developer to reuse their code to run on different underlying execution engine.
    In addition, it supports plug-in modules to port SAMOA to different engines. By
    utilizing SAMOA, the ML algorithm developer does not need to worry about the complexity
    of underlying distributed stream processing engines. They can run it locally or
    utilizing one of stream processing engines, such as Storm, S4, or Samza. SAMOA
    provides the ML algorithms for a variety of tasks including classification, regression,
    clustering, along with boosting, and bagging for ensemble learning. Additionally,
    it offers a platform for the implementation of these ML algorithms, as well as
    a framework that enables the user to write their own distributed streaming algorithms.
    For example, there is CluStream for clustering, as well as Vertical Hoeffding
    Tree, which uses vertical parallelism on top of the decision tree, or Hoeffding
    tree for classification. There is also Adaptive Model Rules Regressor, which uses
    both vertical and horizontal parallelism implementations for regression [244].
    A summarized comparison between various real-time data analytics tools is provided
    in Table 7. TABLE 7 Comparison Between Real-Time Data Analytics Tools TABLE 8
    Categorized Applications of SB SECTION V. Applications of Ml-Based Context-Aware
    Systems for SBs The potential uses of ML in an SB environment can be divided into
    four categories: detection, recognition, prediction, and optimization [79]. We
    discuss these categories separately next. In general, detection is the extraction
    of particular information from a larger stream of information. Many detection
    applications in SBs such as fire detection, leak detection, and anomaly detection
    [245]. Many different applications have been studied by researchers in activity
    recognition in SBs; examples include fitness tracking, health monitoring, fall
    detection. [246]. The goal of recognition is to classify an object or an event
    to a predefined category. It focuses on how to make computer programs perform
    intelligent and human-like tasks, such as the recognition of an object from an
    image. The goal of prediction is to determine the temporal relations’ model between
    specific events to predict what will happen in the near future. Prediction can
    be either for classification or regression problems [247]. Event prediction when
    the goal is to predict the most probable event or subsequent activity is an example
    of classification problems, while latency prediction when the output takes on
    continuous values is an example of the regression problem. The general steps of
    applying ML processes to predict an event in an SB environment is shown in Figure
    9. FIGURE 9. Steps involved in applying ML models in an SB environment. Show All
    The goal of optimization, on the other hand, is to maximize the long-term profits
    by making proper decisions in different situations. reinforcement learning can
    be utilized with these problems. Some optimization problems can be managed as
    prediction problems such that the profits for different actions are predicted
    and the action with the highest profit would be selected. Decision making is the
    most common case of the optimization problem. It takes to consider a variety of
    variables and solving deals between the profits of different locations of the
    environment [248]. Smart buildings are becoming increasingly supplied with a variety
    of sensors that measure different parameters, and data from these sensors is analyzed
    by ML algorithms and used for a range of services and applications for the activities
    of the building occupants. SBs go far beyond saving energy and contributing to
    sustainability goals. The application and services provided by the SBs can be
    both residential and commercial ranging from e-health, e-marketing, intelligent
    car parking system, intelligent transportation system, automation, and logistics
    services. Figure 10 shows the taxonomy of basic domains of SB services. Lighting
    services are associated with the well-being of occupants depending on their activities
    in SBs that have sensors to conserve energy when lights are not needed. The power
    and electrical system may have onsite renewable energy sources to provide a percentage
    of power consumption in SBs. Waste management is related to the activities and
    actions required to collect, separate, transport, together with monitoring and
    regulation of waste management system in SBs. The security is related to managing
    automated locks, biometric devices as well as video surveillance systems in SBs.
    The communications center is related to connecting sensors and actuators in the
    building as well as the operations control center. The operations control center
    supports system analytics and decision making for the operations. Visual interfaces
    provide a dashboard that shows the status of SB services and human operators to
    better manage the building resources. These interfaces also allow the occupants
    to set up their optimal parameters for comfort and productivity improvement on
    daily activities. HVAC stands for the humidity, ventilation and air conditioning
    system, intended for the convenience of occupants that have effective interaction
    with the environment. Parking services aim to minimize the area and volume required
    for parking cars. It could support car sharing, electric vehicles and a place
    for bicycles as well. Finally, the water management services aim to increase savings
    and manage water reclamation for flushing, landscaping and air-cooling systems.
    FIGURE 10. SB services taxonomy. Show All Based on our literature survey, we have
    identified that the application areas of SBs can be elderly care, comfort/entertainment,
    security/safety, energy management, and other projects. In the rest of the section,
    we will briefly describe the major domains in providing the following SB services:
    (1) care of the elderly population; (2) enhancing energy efficiency; (3) enhancing
    comfort or providing entertainment; (4) enhancing safety and security; and (5)
    miscellaneous projects. a: Elderly Population’s Home Care SB technology such as
    sensors, voice activation, GPS, Bluetooth, cellular connectivity via mobile phones,
    smartphone monitoring apps and sophisticated computers can be especially useful
    for elderly or disabled individuals who live independently. Elderly persons can
    take the advantages of such technologies (e.g., monitoring system, emergency system,
    dangerous kitchen appliance detection, fall detection), to maintain a safe and
    healthy lifestyle while living independently [56], [249]. Smart technology in
    the SBs aims to collect real-time information on human daily activity and then
    learn of their personal patterns. ML techniques have the potential for a very
    wide array of new innovations in healthcare that will be transformative for both
    providers and their patients. Whenever a deviation from the norm patterns is detected,
    SB systems send the alerts to family members and the caregivers in order for them
    to take urgent response action. By using big data analytics and ML algorithms
    it is possible to analyze large-scale data contained in electronic medical records—e.g.,
    to learn automatically how physicians treat patients including the drugs they
    prescribe [250]. Some prominent projects in this space are described next. Chernbumroong
    et al. [56] proposed an activity recognition and classification approach for detecting
    daily living activities of the elderly people applying SVM. They used wrist-worn
    multi-sensors namely accelerometer, temperature sensor and altimeter for detection
    basic five activities namely feeding, grooming, dressing, mobility, and stairs.
    And other instrumental activities such as washing dishes, ironing, sweeping and
    watching TV. Taleb et al. [251] proposed a middleware-level solution that integrates
    both the sensing and the monitoring services for assisting elders at smart homes
    environment. The appliances used in the proposed framework include RFID readers
    that cover of the whole building, sound sensors, video cameras, smart door lock,
    microphone and speakers for interaction with the system. CAALYX [252] is a European
    Commission-funded project that supports older people’s autonomy and self-confidence.
    The service is formed of three distinct subsystems including elderly monitoring
    subsystem, home monitoring subsystem and the caretaker’s monitoring subsystem.
    The system delivers a high priority message to an emergency service including
    the geographic position and clinical condition of the elder user. EasyLine+ [253]
    project funded by the European Commission to support elderly people with or without
    disabilities in carrying out a longer independent life at home. The system uses
    a neural network, assistive software, and a variety of sensors such as illumination
    sensor, temperature sensor, door sensors, and RFID giving the capacity of controlling
    the white goods. Hossain et al. [254] proposed a cloud-based cyber-physical multi-sensory
    smart home framework for elderly people that supports gesture-based appliance
    control. Suryadevara et al. [255] proposed a model for generating sensor activity
    pattern and predicting the behavior of an elderly person using household appliances.
    b: Energy Efficiency When temperatures rise or fall in various zones of your home,
    heaters, air conditioners, fans, and other devices will turn on or off (or increase
    or decrease in speed or temperature). In order to perform an efficient energy
    consumption of the supply systems, a significant step that is necessary by analyzing
    the way that current energy consuming system is using in buildings [256]. In the
    last decade, analysis of the energy efficiency in the smart spaces has received
    increasing attention. Various approaches for energy efficiency have been proposed
    utilizing predictive modeling based on profile, climate data, and building characteristics
    [32], [257]. For instance, lights throughout your home might turn on and off depending
    on the time of day. In the past, various attempts have been made to improve energy
    efficiency in the SBs through the use of smart metering and sensor networks at
    the residential level facilities. It is a fact that these types of infrastructure
    are becoming more widespread but due to their variety and size, they cannot be
    directly utilized to make conclusions that help to improve the energy efficiency.
    ML approaches will be the key to the handling of energy efficiency problem in
    SBs. Learning about the occupants’ consumption habits is capable of generating
    collaborative consumption predictions that help the occupant to consume better
    [258]. Some prominent projects in this space are described next. Reinisch et al.
    [259] developed an optimized application of AI system for SB environment. The
    system focuses on some capabilities like ubiquity, context awareness, conflict
    resolution, and self-learning features. The system operates on a knowledge base
    that stores all the information needed to fulfill the goals of energy efficiency
    and user comfort. Jahn et al. [260] proposed an energy efficiency features system
    built on top of a Hydra middleware framework [261]. The system provides both,
    stationary and mobile user interfaces for monitoring and controlling a smart environment.
    Pan et al. [262] proposed an IoT framework that uses smartphone platform and cloud-computing
    technologies to improve the energy efficiency in SBs. They built an experimental
    testbed for energy consumption data analysis. Fensel et al. [263] proposed the
    SESAME-S project (SEmantic SmArt Metering - Services for energy efficient houses).
    The project focuses on designing and evaluating the energy efficiency services
    to enable the end-consumers in making the right decisions and controlling their
    energy consumption. The system combines a variety of smart building components,
    such as smart meters, a variety of sensors, actuators, and simulators that can
    integrate virtual appliances such as the washing machine. Vastardis et al. [264]
    proposed a user-centric smart-home gateway system architecture to support home-automation,
    energy usage management, and smart-grid operations. The gateway is supported by
    ML classification algorithms component such as C4.5 and RIPPER that is able to
    extract behavioral patterns of the users and feed them back to the gateway. Irrigation
    systems monitoring and smart watering system that keep track of rain and soil
    conditions and irrigate appropriately are a very cost-effective way to reduce
    outdoor water consumption. Investment in water management software and services,
    water-efficient plumbing, and irrigation management delivers economic and sustainability
    benefits. Water conservation and management is an example of such benefits [265].
    c: Comfort/Entertainment One of the main goals of SB research is to facilitate
    user daily life activities by increasing their satisfaction and comfort level.
    SBs supports automated appliance control and assistive services to offer a better
    quality of life. They utilize context awareness techniques to optimize the occupant’s
    comfort based on predefined constraints of conditions in a building environment.
    Typical examples of comfort services include lighting, background music, automation
    of routine activities, advanced user interfaces based on voice or gestures, etc.
    [30]. Other services related to comfort services in SB environments are Indoor
    Climate Control and Intelligent Thermostat [265]. Indoor Climate Control: Measurement
    and control of temperature, lighting, CO2 fresh air. In the SB environment, HVAC
    systems play an essential role in forming indoor environmental quality. Typically,
    HVAC systems are produced not only to heat and cool the air but also to draw in
    and circulate outdoor air in large buildings [266]. Kabir et al. [267] present
    a context-aware application that provides the service according to a predefined
    preference of a user. They use the KNN classifier to infer the predefined service
    that will maximize the user’s comfort and safety while requiring minimum explicit
    interaction of the user with the environment. Ahn et al. [268] proposed a deep
    learning model that estimates periodically the atmospheric changes and predict
    the indoor air quality of the near future. d: Safety/Security As the SB technology
    progresses, the role of ML and deep learning in security and connected devices
    will increase. Deep learning will continue to help gain insights using big data
    that were previously inaccessible, particularly in image and video. Advanced technologies
    such as behavioral analysis and ML to detect, categorize, and block new threats
    will be beneficial. In a traditional home system, as soon as a fire is detected
    the Fire/smoke detectors are activated and start sending a fire alarm. However,
    SB can perform much better than the traditional system. It not only sends an alarm
    but also turns on the light only in the safest route and guides the occupants
    of the building out, as well as it will unlock the doors and windows for smoke
    ventilation, turn off all the devices and call the nearest fire service station.
    Other than this, it can take video of the areas surrounding the building, provide
    the status of window breakage alarms, and automatically lock all the doors and
    the windows when the last person of the house leaves [30]. The main services for
    security and safety in SBs are: Perimeter Access Control, Liquid Presence, Intelligent
    Fire Alarm, Intrusion Detection, and Motion Detection Systems [265]. Perimeter
    Access Control service provides control to restricted areas and detects non-authorized
    users that access the areas. Access card provides a variety of solutions that
    allow staff members, vendors or contractors to access specific areas at specific
    times you designate. The same access card can also be utilized to check employee
    attendance. In addition, there is widespread use of biometric technology including
    fingerprint, facial recognition, and iris scans [269]. Additionally, liquid presence
    detection technique has been utilized in data centers, warehouses, and sensitive
    building grounds to prevent breakdowns and corrosion in such areas [270]. Intelligent
    Fire Alarm and its corresponding safety systems are crucial parts of an intelligent
    building. It is a system with multi-function sensors (i.e., chemical gas sensors,
    integrated sensor systems, and computer vision systems) These sensors enable measuring
    smoke and carbon monoxide (CO) levels in the building. They also can give warnings,
    howling alarms, and tell with a human voice about the place and level of smoke
    and CO. In addition, they can give a message on a smartphone if the smoke or the
    CO alarm goes off [271]. Examples of intrusion detection systems including window
    and door opening detection and intrusion prevention [265]. An infrared motion
    sensor is utilized to detect the motion in a specific area in the building. This
    sensor can reliably send alerts to the alarm panel, with the system implementing
    algorithms for adaption to environmental disturbances and reducing any false alarms
    [265]. Image recognition solution can be used in security software to identify
    people, places, objects, and more. It can also be used to detect unusual patterns
    and activities. Clarifai [272] specializes in a field of ML known as “computer
    vision” that teaches computers to “see” images and video. Clarifai’s technology
    can play a key role in security surveillance and at present, the company works
    only with home security. Each image is processed on a pixel by pixel basis through
    convoluted neural networks. Bangali and Shaligram [273] proposed a home security
    system that monitors the home when the user is away from the place. The system
    is composed of two methods: one uses a web camera to detect the intruder—whenever
    there is a motion detected in front of the camera, a security alert in terms of
    sound and an email is delivered to the occupant. And the other one is based on
    GSM technology that sends SMS. A home security system that sends alert messages
    to the house owner and police station in case of illegal invasion at home is proposed
    in [274]. The system consists of different sensor nodes as the input components
    while the output components respond to the signal received from the input components.
    The sensor nodes consist of a thief alarm, presence detecting circuit, and the
    break-in camera. Zhao and Ye [275] proposed a wireless home security system that
    utilizes low cost, low power consumption, and GSM/GPRS. The system has a user
    interface and it can respond to alarm incidents. e: Miscellaneous Projects CASAS
    [178] is a project by Washington State University that provides a noninvasive
    assistive environment for dementia patients at SBs. The project focuses on three
    main areas for SBs: medical monitoring, green living, and general comfort. CASAS
    project comprises of three layers: physical layer, middleware layer, and software
    applications layer. Aware Home Research Initiative (AHRI) [276] is a project that
    has constructed by a group at the Georgia Institute of Technology for SB services
    in the fields of health and well-being, digital media and entertainment, and sustainability.
    AHRI utilizes a variety of sensors such as smart floor sensors, it also utilizes
    assistive robots for monitoring and helping the elderly. House_n [277] is a multi-disciplinary
    project leads by a group of researchers at the MIT. The main objective of the
    project is to facilitate the design of the smart home and its associated technologies,
    products, and services. The home is supplied with hundreds of various sensors
    that are installed almost in every part of the home that and being utilized to
    develop user interface applications that enable the users to control and monitor
    their environment, save resources, remain mentally and physically active, and
    stay healthy. The EasyLiving project [278] at Microsoft Research is concerned
    with the development of a prototype architecture and technologies to aggregate
    diverse devices into a coherent user experience for intelligent environments.
    The EasyLiving project was designed to provide context-aware computing services.
    The project utilizes a variety of sensors and cameras to track and recognize the
    human activities in the room by using the geometric model of a room and taking
    readings from sensors installed in the room. The Gator Tech Smart House project
    [279] is a programmable space specifically designed for the elderly and disabled
    developed by The University of Florida’s mobile and pervasive computing laboratory.
    The project’s goal is to create SB environments that can sense themselves and
    their residents. The project provides special cognitive services for the residents
    such as mobility, health, and other age-related impairments. A generic middleware
    is utilized to integrate system components in order to maintain a service definition
    for every sensor and actuator in the building. The components of the middleware
    including separate physical, sensor platform, service, knowledge, context management,
    and application layers [280]. Other well-known smart home projects include DOMUS
    [281] which is a research project, by the University of Sherbrooke in Canada,
    that supports mobile computing and cognitive assistance in smart buildings. The
    project aims to assist people suffering from Alzheimer’s type dementia, schizophrenia,
    cranial trauma, or intellectual deficiencies. Adaptive House project [136] at
    The University of Colorado has constructed a prototype system that is equipped
    with a variety of sensors that provide different environmental information including
    sound, motion, temperature, light levels. In addition, actuators that control
    the space and water heaters; lighting units, and ceiling fans. In Asia, there
    are also some other smart building projects have been developed, such as “Welfare
    Techno House” project, which is equipped with different sensors such as ECG, body
    weight, and other temperature measured indicators [282]. Ubiquitous Home project
    [283] is another smart building project in Japan, which utilizes RFID, PIR, pressure
    sensors, as well as cameras and microphones for monitoring elderly adults. Summary:
    Recently, several different context-aware and ML techniques have been utilized
    to support SB services. ML-based approaches are capable to perform better prediction
    and adaptation than others. The philosophy behind ML is to automate the learning
    process that enables algorithms to create analytical models with the support of
    available data. ML can be applied in different learning styles including supervised
    learning, unsupervised learning, semi-supervised learning, as well as reinforcement
    learning when the learning is the result of the interaction between a model and
    the environment. The general uses of ML for SB services are detection, recognition,
    prediction, and optimization. In the section, we also talked about how to acquire
    the context from multiple distributed and heterogeneous sources and the techniques
    for modeling and processing such context to be used in the application services
    of SBs. We also talked about the most used tools and platforms ML and others for
    real-time data analytics by ML community to efficiently process and learn from
    big data. Without such ML tools, one would have to implement all of the techniques
    from scratch requiring expertise in the techniques and in efficient engineering
    practices. SECTION VI. Open Issues and Future Research Directions Research on
    SBs has made great strides in recent years, but a number of challenges remain.
    We present some major challenges related to SBs in this part of the work. These
    challenges will channelize the research directions for future SBs. A. Security
    and Privacy Wherever there is an interconnection of two systems or networks (wired
    or wireless), there are issues of security and privacy and the same is true in
    the case of SB. Security is an essential role in SB environments. Any SB application
    should ensure the confidentiality and integrity of data. Access control must be
    included in SB systems, for instance, the unauthorized users should not be able
    to disconnect the alarm system by connecting the pervasive system [284]. There
    is a massive amount of streaming that is collected from the various installed
    sensors and appliances, such data needs to be processed and stored. Hence, cloud
    computing services can be utilized for this purpose. However, with all of this
    data that is transmitted, the issue of losing the privacy increases. Therefore,
    different encryption techniques are needed to preserve personal privacy [285].
    There are specific challenges related to the user’s privacy including challenges
    related to the data privacy of personal information and the privacy of the individual’s
    physical location and tracking. That needs for privacy enhancement technologies
    and relevant protection laws and tools for identity management of users and objects
    [286]. The recent trend of ML research has focused on handling security and privacy
    issues in SB environments. There are different security-related services have
    utilized ML techniques, such as determining safe device behavior by detecting
    and blocking activities and potentially harmful behavior [287]. ML techniques
    have the potential to reduce security gap because of their capability to learn,
    identify and detect the users’ habits and behaviors. Consequently, it can detect
    the abnormal behaviors predicting risks and intrusions before they happen. For
    instance, ML models learn the routine of the users, such as the time they get
    home or go to sleep. These models can suggest rules based on those detected behaviors
    from all connected devices [288]. B. SBS and Context-Aware Computing In the SB
    environment, there exists a massive amount of raw data being continuously collected
    about the various human activities and behaviors. It is important to develop techniques
    that convert this raw data into valuable knowledge [289]. Context awareness and
    ML techniques are expected to provide great support to process and store big data
    and create important knowledge from all this data [290]. The process of data interpretation
    and knowledge extraction has the following challenges including addressing noisy
    real-world data and the ability to develop further inference techniques that do
    not have the limitations of traditional algorithms. Usually, It is very complex
    to formalize and model the contextual information related to human behaviors in
    a standard way due to the complex physiological, psychological and behavioral
    aspects of human beings [291]. The humans communicate through rich languages as
    well as gestures and expressions. Modern ubiquitous computer systems lack an automatic
    mechanism of inferring information as the humans do. New research is necessary
    to raise human activities and behaviors recognition to understand the complex
    dependencies between the apps and humans [292], [293]. The context-aware prompting
    systems have essential applications in SBs such as emergency notifications, medication
    prompting, heart rate monitoring, generation of agenda reminders, and weather
    alerts. However, issuing prompts for all detected errors can possibly be false
    positives, and consequently, lead to annoyance and sometimes prove to be unsafe
    for specific activities. ML methods can be used for an accurate and precise prediction
    when a person faces difficulty while doing daily life activities [294]. C. Personal
    Data Stream Management in SBS The data streaming management system is able to
    process and transfer raw data collected from a variety of sensors to information,
    it is also able to fuse this information to a feature and directly process features
    [295]. While the data processing for a single SB is simple, it is more complex
    when processing the data from multiple SBs, because there are different people
    that tend to share less common interests and have opposing interests concerning
    the processed data [296]. The simple sensors in an SB environment can detect different
    events related to temperature, motion, light, or weather. Moreover, other appliances
    like a television and a telephone can also send their status or other data as
    events. All this data from different sensors can be used by SB services to detect
    specific states and send a request to some actuators according to specific predefined
    rules, for instance, turn on the light if the television is used [297]. However,
    this approach is not generalizable in case of a group of people residing in the
    same building. Although it can work well for one certain person when personal
    preferences can be automatically learned for an individual person, therefore each
    of the residents has to define their own set of rules [298]. Because of the increasing
    number of sensors that produce data streams, the traditional analyzing and processing
    techniques of these data streams are mostly impractical now [299]. Despite the
    availability of new tools and systems for handling massive amounts of data continuously
    generating by a variety of sensors in SBs, however, the real promise of advanced
    data analytics to still lies beyond the realm of pure technology [296]. In [300]
    discuses research challenges for data streams of real-world applications. They
    analyze issues concerning privacy, timing, preprocessing, relational and event
    streams, model complexity and evaluation, availability of information, and problems
    related to legacy systems. D. Big Data Challenges in SBS Nowadays, a variety of
    sensing technology in the SBs can be utilized to collect a massive amount of heterogeneous
    data at a reasonable cost. Typically, hundreds of thousands of transactions can
    be generated by a single SB every day. The process of storing this data over the
    long-term is challenging [258]. We can imagine the challenges and opportunities
    that the companies or government will encounter in the future to manage incoming
    data from dozens of SBs. This new data could provide us with more contextual information
    that consequently leads to much better services to the occupants [301]. In the
    world of big data, despite the availability massive amount of data, however, it
    is not necessarily easy to obtain valuable information from this data utilizing
    the traditional approaches like trial and error to extract meaningful information
    from this data. Analyzing these massive amounts of data requires new technologies
    to store, organize, and process big data effectively, it needs high-performance
    processors that enable uncovering the insights in big data. It also requires flexible
    cloud computing services and virtualization techniques, as well as software such
    as Apache Hadoop and Spark [302]. It requires providing appropriate ML techniques
    which differ from the traditional approaches for effective and efficient solution
    of the above issues. For these reasons, researchers have recently started to think
    about the problems and opportunities resulting from the adoption of big data in
    SB environments [303], [304]. The information extracted from this big data has
    significant value and could greatly contribute in the future of SBs as assistive
    tools and for better services delivery. That is why it is necessary that the researchers
    start to analyze and think about the solutions for the current and future challenges
    of big data in SBs [305]. E. Interoperability Interoperability means that two
    (or more) systems work together unchanged even though they were not necessarily
    designed to work together. When equipment, devices or appliances having different
    communication and networking technologies can communicate effectively, interoperability
    is satisfied. It is a challenge to ensure that an SB that has various components
    will be intelligible. Typically, each of these components might have been produced
    by different vendors, each of which may have created under different design constraints
    and considerations [306]. Therefore it becomes essential to satisfy interoperability
    so that a number of heterogeneous communication and networking technologies could
    coexist in various parts of SBs. For example, an energy management system may
    use Wi-Fi and ZigBee for communication purposes. A lot of work can be done in
    this context [307]. F. Reliability We can expect that the reliability is one of
    the main concern of occupants and developers of SB systems. A variety of appliances
    and devices present in SB such as televisions, microwave, washing machines etc.
    are required exceedingly to be reliable. Achieving expected levels of reliability,
    especially when linked with communication technologies utilized with these devices
    that may be expected in SBs, is a great challenge. There are different reasons
    for these challenges differences in technological approaches, regulations, development
    culture, and the expectations of the market [306]. G. Integration The key to a
    successful SB implementation is integration: linking building systems such as
    lighting, power meters, water meters, pumps, heating, and chiller plants together
    using sensors and control systems, and then connecting the building automation
    system to enterprise systems. Integration allows executives to gain smart-building
    benefits, both in new construction and by gradually transforming existing buildings
    into SBs. What these SBs have in common is integration. Generally, the integration
    in SB systems brings a range of benefits from energy savings to productivity gains
    to sustainability. The SB systems can be attached to enterprise business systems
    to add another level of intelligence that enhances decision-making and improves
    building performance [2]. However, integrating multiple systems is very challenging
    as each individual system has its own assumptions, strategies to control the physical
    world, and semantics. As an example of integrating two systems in SB, assume a
    system that is responsible for energy management, and another system for health
    care are running concurrently. In this case, the integrated system should not
    turn off medical appliances to save energy while they are being used as suggested
    by the health care system [292]. As a future perspective for SBs, You will wake
    up to the sound of the alarm, at the same time the available sensors will be aware
    that you are waking up. The other sensors such as light sensors will automatically
    turn on the light in the building, while the thermostat will warm the area that
    you are about to use in the building. Your coffee will start to brew, you will
    also get a notification on your phone about the weather. The other sensors in
    the kitchen and refrigerator will remind you with a list of items that you will
    need to pick up on your way from your workplace to home to make dinner. When you
    leave your house, you can press a button from your phone to self-drive your car
    out of the garage. After that, the security system will start monitoring and controlling
    the home. Such the doors will automatically lock. Appliances will switch to an
    energy-saving mode. When the home sensors sense utilizing geofencing technology
    that you are way back home, it will get ready again for your arrival, the thermostat
    will warm things up, the garage door will open as you pull up, and your favorite
    music will start to play when you walk in [141]. Summary: Although the recent
    researches have been done in the SBs field, there is a need for a lot more efforts;
    however, we believe that SBs are possible for the mass market in the near future.
    The main challenges and future research directions of this eld can be summarized
    as follows: User context in term of behavior and intention should be studied and
    respected whenever possible; Further research is needed into context-aware prompting
    systems, personal data streaming and big data analysis of occupants in SB environment;
    Some of the other challenges like the interoperability, reliability, and integration
    still require more attention. SECTION VII. Conclusions The promise of smart buildings
    (SBs) is a world of appliances that anticipate your needs and do exactly what
    you want them to at the touch of a button. Since SBs and their inhabitants create
    voluminous amounts of streaming data, SB researchers are looking towards techniques
    from ML and big data analytics for managing, processing, and gaining insights
    from this big data. This paper reviewed the most important aspects of SBs with
    particular focus on what is being done and what are the issues that require further
    research in ML and data analytics domains. In this regards, we have presented
    a comprehensive survey of the research works that relate to the use of ML and
    big data particularly for building smart infrastructure and services. Although
    the recent advancements in technologies that make the concept of SBs feasible,
    there are still a variety of challenges that limit large-scale real-world systems
    in SBs field. Addressing these challenges soon will be a powerful driving force
    for advancements in both industrial and academic fields of SB research. ACKNOWLEDGMENT
    The statements made herein are solely the responsibility of the authors. Authors
    Figures References Citations Keywords Metrics More Like This MIS-IoT: Modular
    Intelligent Server Based Internet of Things Framework with Big Data and Machine
    Learning 2018 IEEE International Conference on Big Data (Big Data) Published:
    2018 Framework for Mobile Internet of Things Security Monitoring Based on Big
    Data Processing and Machine Learning IEEE Access Published: 2018 Show More IEEE
    Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW
    PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION
    AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE:
    +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help
    | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting
    | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s
    largest technical professional organization dedicated to advancing technology
    for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE Access
  limitations: '>'
  pdf_link: https://ieeexplore.ieee.org/ielx7/6287639/8600701/08754678.pdf
  publication_year: 2019
  relevance_score1: 0
  relevance_score2: 0
  title: 'Leveraging Machine Learning and Big Data for Smart Buildings: A Comprehensive
    Survey'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/rs13030531
  analysis: '>'
  authors:
  - Caiwang Zheng
  - Amr Abd-Elrahman
  - Vance M. Whitaker
  citation_count: 44
  full_citation: '>'
  full_text: '>

    This website uses cookies We use cookies to personalise content and ads, to provide
    social media features and to analyse our traffic. We also share information about
    your use of our site with our social media, advertising and analytics partners
    who may combine it with other information that you’ve provided to them or that
    they’ve collected from your use of their services. Consent Selection Necessary
    Preferences Statistics Marketing Show details                 Deny Allow selection
    Allow all     Journals Topics Information Author Services Initiatives About Sign
    In / Sign Up Submit   Search for Articles: Remote Sensing All Article Types Advanced   Journals
    Remote Sensing Volume 13 Issue 3 10.3390/rs13030531 Submit to this Journal Review
    for this Journal Propose a Special Issue Article Menu Academic Editor Alfredo
    Huete Subscribe SciFeed Recommended Articles Related Info Link More by Authors
    Links Article Views 10693 Citations 44 Table of Contents Abstract Introduction
    Remote Sensing Platforms and Sensors Machine and Deep Learning Analysis Methods
    Fruit Traits Leaf and Canopy Traits Abiotic/Biotic Stress Detection Discussion
    and Outlook Conclusions Author Contributions Funding Institutional Review Board
    Statement Informed Consent Statement Data Availability Statement Conflicts of
    Interest Appendix A Appendix B References Altmetric share Share announcement Help
    format_quote Cite question_answer Discuss in SciProfiles thumb_up Endorse textsms
    Comment first_page settings Order Article Reprints Open AccessEditor’s ChoiceReview
    Remote Sensing and Machine Learning in Crop Phenotyping and Management, with an
    Emphasis on Applications in Strawberry Farming by Caiwang Zheng 1,2,*, Amr Abd-Elrahman
    1,2 and Vance Whitaker 1,3 1 Gulf Coast Research and Education Center, University
    of Florida, Wimauma, FL 33598, USA 2 School of Forest Resources and Conservation,
    University of Florida, Gainesville, FL 32603, USA 3 Department of Horticultural
    Sciences, University of Florida, Gainesville, FL 32611, USA * Author to whom correspondence
    should be addressed. Remote Sens. 2021, 13(3), 531; https://doi.org/10.3390/rs13030531
    Submission received: 10 December 2020 / Revised: 18 January 2021 / Accepted: 27
    January 2021 / Published: 2 February 2021 (This article belongs to the Special
    Issue Digital Agriculture with Remote Sensing) Download keyboard_arrow_down     Browse
    Figures Versions Notes Abstract Measurement of plant characteristics is still
    the primary bottleneck in both plant breeding and crop management. Rapid and accurate
    acquisition of information about large plant populations is critical for monitoring
    plant health and dissecting the underlying genetic traits. In recent years, high-throughput
    phenotyping technology has benefitted immensely from both remote sensing and machine
    learning. Simultaneous use of multiple sensors (e.g., high-resolution RGB, multispectral,
    hyperspectral, chlorophyll fluorescence, and light detection and ranging (LiDAR))
    allows a range of spatial and spectral resolutions depending on the trait in question.
    Meanwhile, computer vision and machine learning methodology have emerged as powerful
    tools for extracting useful biological information from image data. Together,
    these tools allow the evaluation of various morphological, structural, biophysical,
    and biochemical traits. In this review, we focus on the recent development of
    phenomics approaches in strawberry farming, particularly those utilizing remote
    sensing and machine learning, with an eye toward future prospects for strawberries
    in precision agriculture. The research discussed is broadly categorized according
    to strawberry traits related to (1) fruit/flower detection, fruit maturity, fruit
    quality, internal fruit attributes, fruit shape, and yield prediction; (2) leaf
    and canopy attributes; (3) water stress; and (4) pest and disease detection. Finally,
    we present a synthesis of the potential research opportunities and directions
    that could further promote the use of remote sensing and machine learning in strawberry
    farming. Keywords: artificial intelligence; Fragaria; machine learning; phenomics;
    phenotyping; plant breeding; precision agriculture Graphical Abstract 1. Introduction
    According to the Food and Agriculture Organization (FAO)’s Future of Food and
    Agriculture: Alternative Pathways to 2050 report, the global population will reach
    almost 10 billion in 2050 [1], which mandates a continued increase in crop production.
    Meanwhile, agriculture is under increasing resource constraints within the context
    of climate change, with decreasing water and land resources. Precision agriculture
    is an important approach to help meet this goal of a continuous increase in crop
    production. Precision agriculture is an operation and management system supported
    by information technology that makes targeted measurements of plant growth, plant
    health, soil conditions, and other factors [2,3]. Through the integration of the
    Global Navigation Satellite System (GNSS), Geographic Information System (GIS),
    and remote sensing technologies, precision agriculture can help achieve a number
    of specific goals, such as (1) conduction of farmland surveys; (2) site-specific
    precision application of fertilizers, pesticides, and irrigation management schemes;
    and (3) fine-scale monitoring of crop status, soil moisture, diseases, and pests
    [2]. Implementing informed and science-based decision-making protocols can increase
    profits and productivity, environmental sustainability, crop quality, and ultimately
    food security [4]. Recently, applications of precision agriculture have gradually
    spread throughout the world as the adoption of auto-guidance systems, yield monitoring
    technology, and variable rate technology (VRT) in agriculture has increased in
    both developed and developing countries over the past 20 years [5]. Another important
    application of precision agriculture is in plant phenotyping, particularly within
    the context of breeding and genetic research. Phenotyping is broadly defined as
    the acquisition and evaluation of complex plant traits, such as geometric structure,
    abiotic stress tolerance, disease resistance, yield, and other physiological and
    biochemical characteristics. The measurement of economically important traits
    is essential to plant breeding [6]. With the combination of remote sensing, computer
    vision, and robotics, high-throughput plant phenotyping platforms have been developed.
    These systems usually use multiple sensors to measure various traits, such as
    color, texture, plant height, area, volume, degree of wilting, fresh weight, number
    of flowers/fruits, and quality of fruits [7]. This information enables scientists
    to establish a connection between genotype and phenotype, thus allowing them to
    select resilient varieties with high yield potential in the target environment.
    Of course, the same technologies and similar approaches are also valuable for
    crop management, specifically determination of nutrient needs, water, and pesticide
    requirements, as well as the detection of weeds, pathogens, and pests [8]. At
    present, plant phenotyping is the primary bottleneck in both plant breeding and
    crop management. Connecting phenotype to genotype in a set of target environments
    is the basic goal [9]. Next-generation advances in DNA sequencing technology and
    genome assembly methodology have dramatically increased the throughput and lowered
    the cost of genotyping. However, connecting this mountain of genomic information
    to the expression of traits is still a knotty problem [10]. The greatest challenge
    at present is to rapidly acquire large-scale plant phenotyping data with high
    dimensionality, density, and accuracy from single molecules to entire organisms.
    While new phenomics technology has significantly relieved some bottlenecks, many
    questions remain on how to efficiently define and extract complex traits as well
    as improve accuracy and throughput [11]. New advances in remote sensing and machine
    learning have the capacity to solve many of these problems. Strawberry (Fragaria
    × ananassa) is a very popular fruit among consumers by virtue of its appealing
    appearance, flavor, and health benefits [12]. The latest statistics from the FAO
    show that the world’s strawberry yield and cultivated area from 1961 to 2018 grew
    at annual rates of about 1.82% and 2.44%, respectively (Figure 1). A large portion
    of the research conducted during this period focused on the medical benefits of
    strawberries to human health [6]. The high-value market for strawberries has significantly
    promoted the breeding of new varieties worldwide, including in Europe, Asia, and
    North America [13], which is now driving the need for high-throughput phenotyping
    techniques. Accurate and rapid acquisition of heritable traits of interest is
    critical to improving the strawberry breeding selection accuracy. Remote sensing
    and machine learning can greatly relieve the heavy burden of manual work for strawberry
    phenotyping, such as plant height measurement and fruit quality evaluation. How
    to effectively improve accuracy and throughput is a hot research theme. On the
    other hand, strawberry is a highly perishable and labor-intensive crop that can
    benefit greatly from precision agriculture approaches. The fruits have many developmental
    stages and when ripe are very sensitive to environmental and management conditions.
    Plant development and fruit production can continually cycle and change over a
    6-month period, depending on the growing region. Therefore, real-time and intelligent
    monitoring of plant health and development as well as fruit quality assessment
    is essential for crop management and strategy formulation. The combination of
    remote sensing and machine learning is considered to have huge potential and a
    broad application space in these areas. Figure 1. Global trends in strawberry
    yield and harvested area from 1961 to 2018 [14]. In this manuscript, we reviewed
    the use of remote sensing and machine learning in agricultural applications, especially
    focusing on the latest advances in strawberry phenotyping and management. The
    manuscript also presented a synthesis of potential research opportunities and
    directions that could further support strawberry farming. A rigorous two-step
    approach was adopted to search and screen the literature related to remote sensing
    and machine learning applications, with an emphasis on strawberry. Details of
    the adopted approach and the number of articles on each topic are shown in Appendix
    A and Figure A1, respectively. 2. Remote Sensing Platforms and Sensors Remote
    sensing technology has developed rapidly in recent years, with sensors providing
    higher spatial, temporal, and spectral resolution images. Remotely sensed data
    are acquired by mounting sensors on multiple platforms, including satellites,
    unmanned aerial vehicles (drones), and ground-based vehicles. The unparalleled
    advantage of satellite observation lies in its large area of coverage, which allows
    for collecting various types of datasets, routinely on a global scale. A summary
    of agricultural data sources by Huang et al. [15] presented 28 optical and synthetic
    aperture radar (SAR) satellites for plant vegetation studies, with spatial resolutions
    varying from 0.3 m to 1 km. Research on the agriculture-related applications of
    satellite sensors focuses on several aspects, including crop type classification
    [16], soil property determination [17,18,19], crop mapping and spatial statistics
    [20], crop yield forecasting and canopy parameter estimation [21], and irrigation/drought
    evaluation [19,22]. For example, Sentinel-2 remote sensing imagery was used to
    retrieve various biophysical parameters of winter wheat, including the leaf area
    index, leaf chlorophyll content, and canopy chlorophyll content, utilizing vegetation
    indices and radiative transfer modeling [23]. A combination of two indices, enhanced
    vegetation index (EVI) and vegetation optical depth (VOD), derived from optical
    (MODIS) and microwave (Soil Moisture Active Passive Satellite, SMAP) remote sensors,
    respectively, was used to make a prediction of the corn, soybean, and wheat yield
    on the county scale, with an accuracy of over 76% [24]. In contrast to satellites,
    unmanned aerial vehicles (UAVs), or drones, can carry low-cost sensors and can
    operate on a flexible on-demand schedule. Due to higher spatial resolution, low
    cost, and high maneuverability, drones have become one of the most widely used
    remote sensing platforms in agriculture. Yang et al. [7] investigated the current
    progress and future prospects of UAVs as a remote sensing platform by reviewing
    96 articles. Radoglou-Grammatikis et al. [25] further made a comprehensive survey
    of UAV applications in precision agriculture. Currently, non-destructive crop
    monitoring and smart spraying are two of the primary UAV applications. Moreover,
    the integration of UAVs, wireless sensor networks (WSNs), and the Internet of
    Things (IoT) and the maturity of 5th-generation (5G) technology can make several
    applications such as pesticide application, irrigation, crop monitoring, and soil
    property analysis more precise, timely, and efficient [26,27,28,29]. Compared
    with satellites and drones, ground-based platforms enable close-range detection
    of plant characteristics and generally serve as ground truth information sources
    for sensor calibration and data quality control. Ground-based platforms can be
    categorized into sensors mounted on fixed platforms, such as towers or booms (fixed
    scanning systems); handheld field measuring instruments; and sensors mounted on
    mobile ground vehicles [30,31]. Currently, the main sensors used in remote sensing
    agricultural applications consist of passive multispectral, hyperspectral, visible
    RGB (VIS), and near-infrared (NIR) sensors, fluorescence spectroscopy and imaging
    sensors, light detection and ranging (LiDAR), and synthetic aperture radar (SAR)
    [32]. High-resolution RGB images are widely used in vegetation classification;
    identification of plant leaves, canopy, and fruits; and estimation of geometric
    attributes. Multispectral and hyperspectral imaging provides spectral information
    about various parameters related to physiological and biochemical attributes,
    such as the leaf area index (LAI), crop water content, leaf/canopy chlorophyll
    content, and nitrogen content [7,33]. These parameters are very useful for crop
    growth evaluation and yield prediction. Fluorescence remote sensing is efficient
    in retrieving the chlorophyll and nitrogen content, nitrogen-to-carbon ratio,
    and LAI [34]. LiDAR has the advantage of a high point-cloud density, which is
    useful for obtaining horizontal and vertical structural characteristics of plants
    [35]. A synthetic aperture radar can function in very low visibility weather conditions
    (e.g., cloud cover). It has been extensively explored in crop classification,
    crop growth monitoring, and soil moisture monitoring [36,37,38]. Specific uses
    of different sensor types in different agricultural applications are elaborated
    by Yang et al. [7]. Strawberry is different from most agronomic crops like corn,
    soybeans, and wheat in various aspects. It is clonally propagated, and a single
    plant is relatively small in size but has a complex growth habit that includes
    several parts such as the crown, leaves, runners, inflorescences, and fleshy fruits.
    Higher-spatial-resolution imagery is needed to reveal the canopy structure and
    identify the fruits. Handheld sensors as well as sensors mounted on UAVs and ground-based
    platforms have been used to study various strawberry phenotyping traits. Some
    commonly used UAV types for agriculture applications are elaborated by Radoglou-Grammatikis
    et al. [25]. Ground-based platforms (e.g., tractors) were used to collect high-quality
    images and generate a 3D point cloud for strawberry plants [39]. Handheld non-imaging
    spectrometers that cover a wide spectral range (350–2500 nm) and provide continuous
    spectral reflectance could be used to study strawberry physiological characteristics
    [40]. Additionally, many researchers designed various types of phenotyping platforms
    for strawberry disease detection and fruit quality evaluation. Multispectral or
    hyperspectral sensors mounted on various platforms have been used for specific
    purposes, such as powdery mildew disease detection, fruit grading, and fruit 3D
    construction [41]. Some platforms and topics discussed in this review are shown
    in Figure 2. Figure 2. Strawberry traits can be assessed using a variety of sensors
    mounted on multiple platforms. 3. Machine and Deep Learning Analysis Methods Machine
    learning (ML) is one of the most effective ways to process and analyze the vast
    amounts of data obtained by today’s remote sensing techniques. In general, machine
    learning used in the agricultural field can be grouped into four categories: (1)
    crop monitoring, including yield estimation, disease and weed detection, species
    recognition, and crop quality assessment; (2) livestock management, such as animal
    welfare and livestock production; (3) water regulation, for example, plant evapotranspiration
    estimation; and (4) soil management, including the identification and prediction
    of soil temperature and moisture content [42]. Traditional machine learning methods,
    such as support vector machines (SVMs), artificial neural networks (ANNs), and
    random forests (RFs), require the extraction of key features from image or LiDAR
    datasets that sufficiently represent the characteristics of the studied objects
    or phenomena [43,44]. The quality of selected features is critical to the classification
    or prediction performance [45]. However, finding the best feature subset can be
    a time-consuming and subjective process, especially for highly dimensional datasets
    and in problems with a complex domain (e.g., crop yield estimation) [46]. For
    example, Sabanci et al. [47] extracted 12 features of wheat grains from high-resolution
    RGB images, including grain dimension (length, width, perimeter, and area), spectral
    band (red, green, and blue), and texture (contrast, correlation, energy, homogeny,
    and entropy) information. These features were imported into an ANN model to classify
    the wheat into two types, bread and durum, with an accuracy higher than 97%. Deep
    learning (DL) has emerged as perhaps the most important branch of machine learning.
    Deep learning refers to the extension of ANNs to accommodate neural networks with
    a relatively large number of layers that enable hierarchical data representation
    [48,49]. Mainstream deep learning models at present include deep neural networks
    (DNNs) [50,51], recurrent/recursive neural networks (RNNs) for sequence or time
    data processing [52], convolutional neural networks (CNNs) for image analysis
    [53,54], deep generative models [55], and auto-encoder networks [56]. In contrast
    to conventional ML algorithms, DL models can achieve optimal discrimination features
    by determining a set of parameters during the training process; thus a specific
    step for feature extraction is not required [49,57]. The main disadvantages of
    DL methods are the need for massive training datasets, computing capacity, and
    training time [58]. Improving existing DL methods and creating novel algorithms
    have been the goals of numerous studies involving agricultural applications. Kamilaris
    et al. [59] reviewed the agricultural problems solved using DL, common DL models
    and frameworks, data sources and corresponding preprocessing procedures, and the
    overall performance of DL by summarizing 40 studies. They identified land cover
    classification, crop type estimation, crop phenology, fruit and weed detection,
    and fruit grading as the current main applications of DL in the agriculture field.
    DL may also have significant potential in seed identification, soil and leaf nitrogen
    content determination, and irrigation management. In addition, they identified
    the potential for long short-term memory (LSTM) or other RNN models in yield prediction,
    disease management, and water needs assessment based on consecutive observations.
    Overall, deep learning has experienced remarkable developmental progress and already
    has a number of operational applications in agriculture. 4. Fruit Traits 4.1.
    Fruit/Flower Detection Automated counting of fruits and flowers from images is
    a critical step in autonomous robotic harvesting and yield prediction [60]. In
    recent years, numerous studies have been conducted on this topic, mainly aimed
    at developing new image-based object detection and localization algorithms to
    improve recognition accuracy. Traditional image segmentation methods use morphological
    operations to generate binary images and separate fruits from the background according
    to the similarity of color, spatial texture, and geometric shape. For example,
    Feng et al. [61] introduced a strawberry stem detection and fruit classification
    workflow, which used the OHTA color space to segment the fruit from black-and-white
    plastic sheets, extracted the principal inertia axis feature to define the stem
    position, made a judgment of strawberry ripeness based on the hue intensity and
    saturation (HIS) color space, and then selectively harvested strawberry fruits
    according to fruit ripeness and shape. However, this segmentation method is not
    yet robust and stable enough for application in commercial settings that have
    variable lighting conditions, observation angles, object orientations, relative
    positions, and various clustering and occlusion situations. Recently, CNNs have
    evolved to be the most powerful approach for solving target identification and
    classification problems. The superiority of a CNN in image recognition lies in
    its ability to extract increasingly complex visual concepts and features through
    hierarchical structures. The first few layers can be used to learn simple local
    features, and the deeper hidden layers can capture more complicated semantic information,
    such as shape and texture. Koirala et al. [47] reviewed the use of deep learning
    in fruit detection and yield prediction. The author elaborated on the applications
    of current state-of-the-art DL frameworks in target recognition, including the
    faster regional convolutional neural network (Faster RCNN), single-shot multibox
    detector (SSD), and you only look once (YOLO), and in detectors, including the
    Oxford Visual Geometry Group network (VGGNet), the Residual Network (ResNet),
    and the Zeiler and Fergus network (ZFNet). Fruit weight and yield estimation were
    also discussed, which demonstrates the superiority of deep learning in analyzing
    multi-dimensional remote sensing data. With regard to strawberry flower/fruit
    counting, Lin et al. [62] applied RCNN, Fast RCNN, and Faster RCNN models for
    the identification of strawberry flowers from the image, with an accuracy of 63.4%,
    76.7%, and 86.1%, respectively. The Faster RCNN framework demonstrated good performance
    even if strawberry flowers were occluded by foliage, under shadow, and overlapped
    by other flowers. Another DL framework (SSD) was implemented by Lamb et al. [63]
    for strawberry detection. The authors modified the training images and network
    structure to optimize the detection precision and execution speed. This system
    with a sparse CNN can run quickly on mobile low-power hardware with an average
    precision of 84.2%. Yu et al. [64] further adapted a Mask-RCNN model for mature
    strawberry detection in the RGB image and achieved an accuracy of 95.78% even
    in a non-structural environment, particularly for overlapping and hidden fruits
    and those under varying illumination. Zhou et al. [65] proposed a robust deep
    learning architecture named improved Faster-RCNN, which adopted a transfer training
    technology based on Faster RCNN and greatly reduced the number of strawberry images
    required for training the network. The average fruit extraction accuracy was more
    than 86%. 4.2. Fruit Maturity/Ripeness During strawberry ripening, the fruit surface
    color typically goes through green, white, pink, and red stages, concurrent with
    the accelerated biosynthesis of pigments (e.g., carotenoids and anthocyanins)
    over a period of up to 30 days. Fruit ripening is a complicated process, with
    a variety of internal physical and chemical changes, which is mainly controlled
    by the synthesis and action of hormones [66]. Azodanlou et al. [67] found that
    as the fruit matures, there is an increase in volatile organic compounds (VOCs)
    and sugars, as well as a decrease in acidity. Meanwhile, structural changes in
    cell wall polysaccharides, especially the dissolution of pectin, contributes to
    fruit softening. The state of ripeness at harvest directly determines fruit quality
    and shelf life. Unripe fruits have lower nutrient values but are more resistant
    to physical injury. Overripe fruits are more susceptible to the external environment
    and fungal infection [68]. Rahman et al. [69] found that the shelf life of strawberry
    fruits picked at the 1/3rd maturity stage and the full maturity stage were about
    7.8 and 2.4 days, respectively, regardless of the genotype. Therefore, early evaluation
    of fruit ripeness and the determination of optimal harvest time are crucial to
    reducing waste in the supply chain and improving fruit quality [70]. Traditional
    strawberry ripeness assessment is implemented visually and subjectively based
    on the appearance, aroma, color distribution and intensity, as well as texture
    [71,72]. Standard maturity evaluation methods are quantitative, measuring the
    contents of internal quality attributes, such as firmness, soluble solids content
    (SSC), titratable acidity (TA), and total anthocyanins [73]. However, this technique
    is destructive, slow and requires expensive specialized devices and expertise
    [74]. Researchers have spent considerable efforts developing simple, non-invasive,
    and high-throughput ways to estimate the ripeness stage of strawberry fruits.
    Most of the studies have focused on extracting spatial and spectral information
    from representative wavelength bands (usually R, G, and NIR bands) to discriminate
    between strawberries at different growth stages. Raut et al. [75] proposed a direct
    color-mapping method to evaluate the redness of strawberries based on RGB images
    and sort them into pre-mature, mature, and over-mature classes. Jiang et al. [76]
    selected the wavelengths 535, 675, and 980 nm and introduced eight spectral indices
    to automatically identify immature, nearly mature, and mature strawberries using
    the Fisher linear discriminant (FLD) model, with a prediction accuracy over 95%.
    Guo et al. [77] combined spectral reflectance and textural indicators (correlation,
    contrast, entropy, and homogeneity) of 11 optimal wavelengths from hyperspectral
    images and used the SVM algorithm to classify ripe, mid-ripe, and unripe fruits,
    with an accuracy higher than 85%. Yue et al. [78] assessed strawberry maturity
    in the greenhouse using only a smart phone equipped with 535 and 670 nm optical
    filters, which were chosen to capture anthocyanin and chlorophyll contents, respectively.
    Absorptance data for the two wavelengths served as variables in three regression
    classification methods (multivariate linear, multivariate nonlinear, and SoftMax
    regression). The multivariate nonlinear model yielded an identification accuracy
    of over 94%. Gao et al. [79] further used the AlexNet CNN deep learning model
    to categorize the strawberry fruits into ripe and early-ripe stages using hyperspectral
    datasets, achieving 98.6% classification accuracy. Recently, data collection processes,
    feature extraction and classification algorithms have been integrated into a real-time
    strawberry ripeness evaluation and decision-making system developed for harvesting
    robots [80]. 4.3. Fruit Quality and Postharvest Monitoring Postharvest operations,
    including sorting, grading, and spoilage stage monitoring, are of great significance
    for price determination, fulfillment of orders with specific quality standards,
    and sales strategy formulation [81]. In terms of strawberry grading, manual selection
    is widely based on the shape, size, color, maturity, and imperfection of the fruits
    [82]. Compared with apples and citrus fruits, strawberries are more vulnerable
    to damage due to their high moisture content, lack of exocarp protection, and
    susceptibility to fungal infection [12]. From the moment of harvest, strawberry
    fruits begin to lose nutrition and generally spoil after three days without cold
    storage, potentially generating toxins harmful to human health [83]. Therefore,
    it is helpful to have a rapid and non-invasive inspection method for postharvest
    strawberry monitoring. As with ripeness evaluation, emerging computer vision and
    machine learning technologies have enabled the development of automatic, real-time,
    and non-destructive fruit-grading systems. Liming et al. [84] designed an intelligent
    strawberry-grading system by integrating conveyer belts, cameras, and other auxiliary
    devices and employing multi-attribute decision-making theory to grade the strawberry
    fruit into three or four classes based on color, shape (13 feature parameters),
    and size. The final accuracy was above 90%. Mahendra et al. [85] compared seven
    types of features and used the SVM classifier to categorize the fruits into two
    groups: good and damaged. They found that the speeded-up robust features (SURF)
    were most effective in classification, with an accuracy of 90.73%. Sustika et
    al. [81] evaluated the capability of six CNN architectures (the baseline CNN,
    AlexNet, GoogLeNet, VGGNet, Xception, and MobileNet) for the binary classification
    (good or bad) of strawberry fruit and its classification into four grading levels
    (1–4 ranking) using RGB images. The study indicated that VGGNet’s performance
    was the best, producing 96.49% and 89.12% accuracy for the binary and the four-grade-level
    classification, respectively. Péneau et al. [86] represented the consumer perception
    of freshness quantitatively by establishing the relationship between the fruit’s
    physiochemical parameters (appearance, odor, texture, and flavor) and consumer/expert
    ratings of freshness. Dong et al. [87] used long-path Fourier-transform infrared
    spectroscopy (FTIR) technology to capture the spectral characteristics of VOCs
    generated after different lengths of storage and then detect changes in VOC (esters,
    alcohols, ethylene, etc.) abundance. A principal component analysis (PCA) was
    implemented on the spectral data to distinguish fresh, slightly spoiled, and spoiled
    strawberries. As for storage time estimation, Weng et al. [12] collected the spectral
    data for strawberries from 0 to 60 h of storage with an interval of 6 h, using
    hyperspectral imaging technology. SVMs and RFs were then used to classify strawberry
    samples from different storage times with an accuracy of 100%. Partial least-squares
    regression (PLSR) [88] analysis has also been used to estimate the storage time
    with a prediction accuracy approaching 100%. 4.4. Internal Fruit Attributes As
    discussed in the previous section, fruit quality is broadly assessed by many parameters
    associated with the external attributes of the fruit, including appearance, texture,
    and flavor. However, the determination of internal fruit attributes (sugar content,
    juiciness, acidity, color, etc.) is also very important. NIR spectroscopy and
    multiple/hyperspectral imaging technology have been effective for evaluating internal
    fruit quality attributes in a non-contact manner. A difference between spectroscopy
    and imaging is that the former can only obtain single-point information, while
    the latter can provide spatial distribution. The VIS/NIR spectral range is usually
    selected for internal fruit attribute studies because it provides information
    about O–H, C–H, and N–H absorptions [89]. Spectroscopy and hyperspectral image
    data are highly redundant and require preprocessing and analysis. Most research
    on the retrieval of internal fruit attributes adopts the following steps: data
    pretreatment (spectral correction and noise reduction), optimal sensitive wavelength
    selection, feature extraction, and prediction model construction. ElMasry et al.
    [90] estimated the moisture content (MC), SSC, and pH of strawberry fruits using
    hyperspectral images. Optimal wavelengths were selected for the MC, SSC, and pH,
    using β-coefficients from partial least-squares models. Multiple linear regression
    (MLR) models were then applied to retrieve fruit quality attributes using the
    spectral data of optimal wavelengths, with prediction accuracies of 87%, 80%,
    and 92% for the MC, TSS, and pH, respectively. Unlike many researchers who only
    used the spectral information directly as input variables, Weng et al. [91] extracted
    the spectral information about optimal wavelengths, 9 color features obtained
    from color histograms and moments, and 36 textural features simultaneously from
    the hyperspectral images for the detection of soluble solid content (SSC), pH,
    and vitamin C. Spectral and color features achieved the best prediction for SSC,
    with an R2 coefficient of 0.94. In terms of pH, optimal prediction was obtained
    using spectral features only, with an R2 of 0.85. A combination of spectral and
    textural features helped improve the estimation of vitamin C, with an R2 of 0.88.
    At present, the main parameters retrieved for the internal fruit quality of strawberry
    include firmness; vitamin C (VC); phenolic compounds; TA; total water-soluble
    sugar (TWSS) content; concentrations of glucose, fructose, and sucrose; SSC; pH;
    MC; and VC. A detailed summary of the acquisition of these parameters using spectroscopy
    and imaging technology is shown in Table 1. Table 1. Summary of articles addressing
    the estimation of internal fruit quality attributes of strawberry based on remote
    sensing and machine learning. 4.5. Fruit Shape Fruit shape is a critical parameter
    affecting the esthetic appearance and marketability of strawberries. Basic shape
    descriptors, such as length, width, and aspect ratio, can be manually measured
    with, for example, a vernier caliper. However, this method is not only labor intensive
    and time consuming but also limited in capturing the complex and multi-dimensional
    aspects of shape and uniformity. Currently, most shape classification studies
    are based on 2D digital images. Ishikawa et al. [103] extracted four types of
    shape descriptors from RGB images taken by a digital camera: (1) measured values,
    including contour line length, fruit length and width, and fruit width/length
    ratio; (2) ellipse similarity (ES) index, including the optimum ellipse area ratio
    and the boundary length ratio, which indicate the ellipse similarity of fruits;
    (3) elliptic Fourier descriptors (EFDs); and (4) chain code subtraction (CCS).
    Random forest analysis was conducted to categorize strawberry fruit shape into
    nine types: reniform, conical, cordate, ovoid, cylindrical, rhomboid, obloid,
    globose, and wedged. The recall ratio was used for accuracy evaluation since Kappa
    coefficients were not able to classify more than three types. The recall ratio
    ranged from 0.52 to 1, depending on shape type. Oo and Aung [104] proposed a simpler
    but efficient method for strawberry size estimation and shape classification based
    on RGB images. Only three parameters (diameter, length, and apex angle) were imported
    into a three-layer neural network for four classes. The estimation accuracy of
    diameter and length was 94% and 93%, respectively, for strawberries without calyx
    occlusion and 94% and 89% for those with calyx occlusion. The classification was
    between 94% and 97%. Feldmann et al. [105] further extracted 68 strawberry fruit
    shape features of four types (linear and geometric descriptors, outline-based
    descriptors, landmark-based descriptors, and binary-image-pixel-based descriptors)
    from digital images and introduced a method called principal progression of k
    clusters (PPKC), which can automatically discover potential shape classes. Relationships
    between four shape categories and features were built and used for the classification.
    The accuracy varied from 68% to 99%. Zhou et al. [65] used the length-to-width
    ratio of the minimum external rectangle obtained from RGB images to assess the
    plumpness of strawberry fruits. Strawberries were classified into three types
    based on this ratio: plump (0–0.5), approximately plump (0.5–0.8), and fully plump
    (0.8–1). However, this approach applies only for strawberries of globose type.
    Although 2D images can only reflect one dimension or plane characteristics, they
    are sufficient to determine shape properties to some extent. Today, imaging technology
    can obtain three-dimensional information. A 3D-shape-measuring system equipped
    with cameras, a rotation table, and an operation system was designed by He et
    al. [106], which generated 3D point clouds of strawberry fruits using photos from
    various angles and heights using structure from motion (SfM) methods. The errors
    were less than 0.6 mm for 90% and 0.3 mm for 80% or more of the strawberry fruits
    [107]. Construction of 3D strawberry architecture can provide information beyond
    basic descriptors. For example, uniformity is a key shape factor that is directly
    tied to fruit quality and sales volume. Li et al. [108] defined eight uniformity
    variables calculated from the 3D architecture of the strawberry fruit and evaluated
    the importance of each variable for manual uniformity assessment. The results
    showed that circularity of the maximum circumference had the closest predictive
    relationship with the manual uniformity score. A regular shape genetic locus was
    detected and found to be related to three uniformity parameters. 4.6. Strawberry
    Yield Prediction Strawberry harvesting can extend for many months depending on
    the growing system and environment, with dramatic variation in weekly yields.
    Forecasting strawberry yield ahead of time can help growers formulate labor/equipment
    allocation strategies during the harvesting period. Since weather fluctuation
    is a key factor, many studies have been conducted on how weather parameters (e.g.,
    solar radiation, wind, temperature) influence strawberry yield [109]. These significant
    influential factors were combined with other yield-associated traits as input
    for statistical models and machine learning methods to predict strawberry yield.
    For example, Misaghi et al. [110] applied three neural network models (multilayer
    perception (MLP), generalized feedforward neural network (GFNN), and modular neural
    network) for strawberry yield prediction using vegetation indices (normalized
    difference vegetation index (NDVI) and Soil Adjusted Vegetation Index (SAVI))
    and soil characteristic parameters, with up to 94% final accuracy. MacKenzie and
    Chandler [111] built a relational expression between flower counts, temperature
    data, and strawberry total weight, with a coefficient of determination of 0.84.
    Various meteorological parameters (e.g., net radiation, vapor pressure, relative
    humidity) were examined by Pathak et al. [109] for strawberry yield forecast using
    a principal component regression model, achieving 70% yield prediction accuracy.
    Hassan et al. [112] used hyperspectral remote sensing imagery to obtain LAI parameters
    and six vegetation indices (VIs) to explore the relationship between these parameters
    and yield under different growing conditions (organic and conventional). The prediction
    accuracy (R2) was higher than 0.7 except in the treatment using the black plastic
    mulch conventional system (<0.6). The result also showed that six VIs worked better
    than LAI as yield estimators. Maskey et al. [113] utilized predictive principal
    component regression (PPCR), neural network (NN), and random forest (RF) models
    to forecast strawberry yield using 26 parameters related to leaf and canopy properties,
    soil characteristics, and weather conditions. Each of the selected weather parameters
    was highly correlated with strawberry yield, and the neural network (NN) analysis
    provided the best prediction accuracy (95%). Nevertheless, these prediction models
    were generally spatially confined and need to be validated in field experiments.
    Another method for strawberry yield forecasting is to count fruit numbers and
    determine size and maturity using remote sensing images. Deep learning can play
    a crucial role in accomplishing this task. Using the Faster RCNN model, Chen et
    al. [114] predicted strawberry yield by identifying and counting strawberry flowers
    and immature and mature fruits from UAV high-resolution images obtained at two
    heights (2 m and 3 m). The results showed that the mean average precision was
    higher at 2 m (83%) than at 3 m (72%). 5. Leaf and Canopy Traits Leaf and canopy
    traits are generally divided into two types: architectural and biophysical/biochemical
    characteristics. Architectural traits refer to external geometric morphology,
    such as leaf length and width; leaf area; leaf inclination angle; leaf azimuth;
    and canopy height, width, size, and shape. These parameters affect the penetration
    of light through the canopy, light utility efficiency (LUE), and, ultimately,
    photosynthesis efficiency. Biophysical/biochemical parameters describe internal
    physiological characteristics of leaves and are highly associated with crop growth
    dynamics, nutritional status, and photosynthetic capacity. These parameters include
    the green area index (GAI), green fraction (GF), above-ground biomass (AGBM),
    LAI, leaf/canopy water content, leaf/canopy chlorophyll content, leaf/canopy nitrogen
    content, and leaf/canopy temperature, etc. At present, SfM analysis and LiDAR
    are two methods used to generate 3D point-cloud data and obtain 3D structural
    properties of leaves and canopies with desirable accuracy. SfM is a computer vision
    technique that aims to recover the three-dimensional geometry of objects by analyzing
    overlapping images taken from different perspectives [115]. The workflow involves
    several steps: (1) Image feature extraction and matching is performed, where matching
    algorithms are used to detect conjugate features or tie points between overlapped
    images. (2) Camera location and orientation estimation is done using the conjugate
    features in the images. A bundle-block adjustment process is then implemented
    to estimate the position and orientation of each camera at the exposure moment.
    (3) Orthoimage and 3D point-cloud production [116] is then conducted using more
    dense conjugate points detected through image matching. The point cloud can be
    rasterized to produce a digital surface model, which is used to generate ortho-rectified
    image mosaics. Light detection and ranging (LiDAR) is an active remote sensing
    method that utilizes laser to generate 3D point-cloud datasets [35]. Most LiDAR
    systems send laser pulses and compute the distance between the LiDAR source and
    the point where the LiDAR pulse hits an object (e.g., plant leaf) using the laser
    pulse travel time. Other navigation sensors are then used with the measured distance
    to compute the 3D location of the point. Dense 3D points can be created this way
    to accurately depict the surveyed objects. One of the major differences between
    LiDAR- and SfM-based datasets is the significantly higher cost associated with
    LiDAR measurements. LiDAR, however, is capable of producing 3D points along the
    LiDAR laser path, which can reveal some under-canopy information. Both methods
    have been widely used to extract height, size, and shape of various crop plants,
    such as blueberry, maize, and soybean [117,118,119]. Two main approaches have
    been commonly used to retrieve biophysical characteristics and related parameters:
    statistical modeling and radiative transfer modeling (RTM). The former aims to
    establish the relationship between features obtained from remote sensing and field
    measurements using traditional statistical modeling (e.g., regression analysis)
    and machine learning methods. Commonly used image features include spectral (e.g.,
    band values and vegetation indices) and textural information. More than a hundred
    VIs could be calculated using different light spectra combinations extracted from
    UAV hyperspectral imagery, supplying abundant information about vegetation vigor
    and health [120]. It is worth noting that the red edge region, which is defined
    as the wavelength position of the inflection point on the red-NIR reflectance
    slope, has raised wide interest among researchers for LAI and chlorophyll content
    estimation [121]. As an alternative to statistical modeling, RTM considers the
    physical process of interactions between the vegetation canopy and solar radiation.
    Through the simulation of canopy reflectance, canopy parameters can be retrieved
    by RTM as long as other input parameters (radiation intensity, observation angle,
    soil conditions, etc.) are known [122,123]. Kattenborn et al. [124] revealed how
    canopy reflectance is linked with functional traits using the PROSAIL radiative
    transfer model (combination of PROSPECT leaf optical properties model and SAIL
    canopy bidirectional reflectance model). Recently, several scholars have compared
    and combined these two approaches to implement leaf/canopy property retrieval
    [81,124,125]. Studies on phenotyping of strawberry leaves and canopies using remote
    sensing techniques are relatively rare. Luisa et al. [126] investigated the relationship
    between 11 spectral response indices and nitrogen (N) content of young, mature,
    and old leaves. The results showed that only green reflectance (550 nm) was responsive
    to N fertilization for individual leaves. At the canopy level, green reflectance
    (550 nm), red reflectance (680 nm), VI, and NDVI were highly correlated with N
    content, with an R2 of 0.5, 0.6, 0.56, and 0.56, respectively. Sandino et al.
    [127] adopted a basic computer vision method to estimate strawberry leaf coverage
    from RGB images with an accuracy of 90%. Procedures such as smoothing, dilatation,
    contour detection, threshold segmentation, and edge detection operations were
    used. Similarly, a more complex algorithm was introduced by Jianlun et al. [128]
    to segment the greenhouse strawberry leaf edge from the background noise in the
    images, which integrated the scale space wavelet transformation, canny edge detection,
    Otsu threshold segmentation, and morphological analysis approaches. Guan et al.
    [129] extracted planimetric canopy area, canopy surface area, canopy average height,
    standard deviation of canopy height, canopy volume, and canopy smoothness parameters
    from high-spatial-resolution RGB images (~0.5 mm) through SfM, object-based image
    analysis (OBIA), and GIS analysis. Three of the variables were used to predict
    the leaf area (R2 = 0.79) and dry biomass (R2 = 0.84) throughout the strawberry-growing
    season using multiple linear regression analysis. Abd-Elrahman et al. [130] built
    on this study by developing automated canopy delineation and canopy size metric
    extraction models to predict strawberry biomass at greater throughput. Takahashi
    et al. [131] applied Kinect (the depth sensor used in the Microsoft XBOX console)
    to detect plant height and leaf area receiving direct sunlight at different leaf
    layers over time under different environments. These parameters were compared
    to the yield, dry weight, and nitrogen content inside the leaf. Kokin et al. [132]
    used a thermal camera to examine the difference between the strawberry leaf surface
    temperature and ambient air temperature under night frost conditions, which reached
    a maximum of ~8 °C. 6. Abiotic/Biotic Stress Detection 6.1. Water Stress Water
    deficit stress refers to the inhibition effect on plant growth caused by soil
    water deficiency or high evaporation requirement in a low-humidity atmosphere.
    The detection of the plant response to water stress is critical to irrigation
    management. Current irrigation practices are generally based on indirect estimation
    of plant water demand or evaporation calculated from soil moisture content and
    meteorological data [133,134]. Gutiérrez et al. [135] developed an automated irrigation
    system equipped with a distributed wireless network of soil moisture and temperature
    sensors placed in the root zone of the plants. Through irrigation control based
    on soil moisture and temperature threshold values, 90% saving was achieved in
    water consumption compared to traditional irrigation practices. Morillo et al.
    [136] implemented precision drip irrigation for strawberries using crop water
    requirement estimates and optimum irrigation pulse design. The method incorporated
    soil water content and crop evapotranspiration data obtained from a local meteorological
    station. In contrast, monitoring physiological changes in plants due to water
    stress provides a more direct and intuitive way to assess water demand. Under
    water stress, a plant’s temperature increases due to stomatal closure and reduced
    transpiration. Severe water scarcity can lead to wilting and loss of key pigments
    such as chlorophyll, which cause irreversible damage to the photosynthesis process.
    Multiple remote sensors have been used to detect pre-symptom changes. Commonly
    used sensors for this approach include the thermal imager (TIR; 8–14 µm), VIS,
    NIR, shortwave infrared reflectance (400–2500 nm), and sun-induced fluorescence
    (SIF; 685 and 740 nm). Thermal infrared imaging has demonstrated advantages compared
    to other remote sensing spectral domains in crop water stress detection. Through
    the analysis of information in different spectral ranges, numerous indices sensitive
    to water stress were proposed, such as temperature-based indices (stress degree
    day (SDD), crop water stress index (CWSI), and water deficit index (WDI)) and
    leaf-water-content-related indices (water index (WI), leaf water index (LWI),
    moisture stress index (MSI), and normalized difference water index (NDWI)) [137].
    These indicators can quantitatively reflect the water deficit of leaves or canopy
    to some extent. As for strawberries, drought severely limits plant growth and
    reduces yield and fruit quality. Extensive research has been done to investigate
    responses of strawberries to water stress, including changes in yield and morphological,
    physiological, and biochemical properties. Drought-tolerant cultivars have been
    selected according to their adaptability to limited water supply [138]. Numerous
    parameters related to strawberry growth status, such as leaf area, leaf size,
    leaf longevity, dry mass, number of leaves per plant, leaf expansion rates, leaf
    chlorophyll content, chlorophyll stability index, leaf moisture content, stomatal
    conductance, photosynthetic rate, transpiration rate, root development, and plant
    height, exhibit a decreasing tendency under water stress [139,140,141]. Adak et
    al. [142] found that water deficit increased some biochemical features of fruits,
    such as total phenolics, total anthocyanins, antioxidant activity, and sugar content.
    Strawberry fruit weight and yield per unit declined by 59.72% and 63.62%, respectively,
    under water stress as compared to control conditions. It is helpful in crop management
    to provide a real-time, accurate assessment of water demand inside the strawberry
    plant. Peñuelas et al. [143] found that strawberry leaf temperature and the CWSI
    obtained by a handheld infrared thermometer were very useful in evaluating even
    mild water stress. Razavi et al. [144] used chlorophyll fluorescence to identify
    drought stress in strawberries. Delalieux et al. [145] compared plant height,
    NDVI, red edge inflection point (REIP), and pigment-specific simple ratio for
    chlorophyll b (PSSRb) differences between strawberries under two irrigation scenarios
    (20% and 100%) using the COmpact hyperSpectral Imaging (COSI) system. The study
    indicated that the growth inhibition caused by water shortage could be detected
    using these spectral characteristics. Li et al. [146] measured strawberry plant
    temperature, dry surface temperature (Tdry), wet surface temperature (Twet) for
    a single point, and the whole plant area using a TIR sensor. They found the CWSI
    to be significant in detecting strawberry water stress. More indicators were examined
    by Gerhards et al. [147], including surface temperature (TS), CWSI, sun-induced
    fluorescence (F687, F780), and TIR indices, as well as the visible and near infrared
    (VNIR)/short-wave infrared (SWIR), photochemical reflectance index (PRI), normalized
    difference vegetation index (NDVI), and moisture stress index (MSI). These results
    illustrate the great potential of remote sensing in water stress detection. 6.2.
    Pest and Disease Detection Strawberries are susceptible to many insects, mites,
    pests, and microorganisms (bacteria, fungi, and viruses) that regularly cause
    reductions in total and marketable yield [148,149]. Early diagnosis and control
    of strawberry pests and diseases is critical to avoiding yield losses. The occurrence
    of plant diseases is a process of pathological and physiological changes. Internal
    symptoms of diseased crops are eventually reflected as abnormal changes in external
    morphological characters, such as necrosis, rot, and deformity of strawberry roots,
    stems, leaves, flowers, and fruits. Visual identification of pathogen signs and
    plant disease symptoms performed by trained experts is the common practice. Nevertheless,
    this process is post-symptom, and its accuracy depends on the individual’s experience.
    Microscopic methods are not feasible for large-scale commercial detection of pest
    and disease problems [150]. Numerous studies have utilized remote sensing to recognize
    various strawberry diseases, such as powdery mildew, anthracnose crown rot, verticillium
    wilt, and gray mold (Figure 3). Reflectance at various spectral bands contains
    significant information about plant biophysical and biochemical properties, such
    as leaf pigment content (VIS: 400–700 nm), leaf internal structure and water content
    (NIR: 700–1100 nm), and the composition of leaf chemicals and water content (SWIR:
    1100–2500 nm) [139]. Consequently, remote-sensing-based plant disease detection
    methods focus on the optical characteristics of infected and healthy strawberry
    plants in the images acquired by one or more sensors. The majority of the current
    research in this area focuses on differentiating between healthy strawberries
    and those affected by a single disease. Machine learning (particularly deep learning)
    plays an important role in analyzing images for disease detection. For example,
    Park et al. [151] applied a CNN to classify healthy and diseased strawberry using
    RGB images taken by a smart phone, with 89.7% accuracy. Chang et al. [149] extracted
    40 textural indices from high-resolution RGB images and compared the performance
    of three supervised learning classifiers, ANNs, SVMs, and K-nearest neighbors
    (KNNs), in detecting the strawberry powdery mildew disease. The overall classification
    accuracy was 93.8% and 78.80% for the ANN and KNN classifiers, respectively. More
    studies addressing strawberry disease detection are detailed in Table 2. Figure
    3. Several common strawberry diseases. Used with permission from N. Peres [148].
    Table 2. Summary of recent articles investigating strawberry diseases using remote
    sensing and machine learning. 7. Discussion and Outlook The primary aim of this
    manuscript was to present an overview of how remote sensing and machine learning
    have been used in strawberry phenotyping and management. We reviewed studies that
    have applied state-of-art technological breakthroughs in machine and deep learning
    techniques to detect strawberry fruits and flowers from images with high accuracy.
    This work contributed greatly to autonomous robotic harvesting and yield prediction
    applications. Statistical models and machine learning methods were explored to
    evaluate strawberry fruit ripeness, estimate internal fruit attribute parameters,
    and monitor postharvest fruit quality based on RGB, multispectral, and hyperspectral
    image datasets. Various image-based fruit shape descriptors were suggested, such
    as fruit contour line length, uniformity, and ellipse similarity indexes. Structures
    from motion algorithms were used to generate 3D point clouds of strawberry fruits.
    Canopy and leaf images were analyzed to build models relating the biochemical
    content of leaves and spectral indexes as well as predict biophysical parameters,
    such as dry biomass and leaf area. Additionally, studies related to the detection
    of abiotic and biotic stressors were developed. Table A1 lists a categorized summary
    of the studies reviewed in this manuscript that were not presented in tabular
    form. Although remote sensing data acquisition and machine learning data analysis
    are already advancing the prospects of strawberry precision agriculture and phenomics
    applications, there is still an urgent need for further exploration. For example,
    questions related to how to expand the robustness and transferability of the statistical
    and machine learning models connecting fruit quality to image-based spectral and
    geometrical information are still active research topics. Deep learning is also
    very promising for further advances in fruit quality assessment. A deep learning
    method may enable obtaining multiple fruit quality parameters, such as shape,
    size, color, and internal attributes, simultaneously, which can help build a comprehensive
    evaluation system for strawberries and promote the automation of postharvest grading
    processes. Strawberry yield forecasting can be improved by integrating multiple
    variables such as weather condition, soil parameters, fruit/flower counts, canopy
    metrics, and various spectral indices from hyperspectral images as input. Many
    of these parameters, such as fruit and flower count and canopy size, can be extracted
    directly from the images using deep learning networks, which may effectively increase
    prediction accuracy and reduce manual work of feature extraction. Continuous,
    real-time observations of leaf and canopy phenotyping traits are critical to monitoring
    the growth and nutritional status of the plants. With the advancement of remote
    sensing technology, UAVs and updated ground-based platforms are being used extensively
    in agriculture. Sensors that are expensive and hard to access, like LiDAR and
    hyperspectral cameras, are gradually becoming more affordable. Thus, an increasing
    number of studies are being conducted on using remote sensing and machine learning
    to obtain structural (e.g., leaf width/length, leaf inclination angle, and canopy
    height and width), biophysical (e.g., LAI and biomass), and biochemical (e.g.,
    chlorophyll and nitrogen content) traits of agronomic crops, fruit trees, and
    vegetables. Strawberry fruit shape is mostly depicted and evaluated by features
    extracted from 2D and 3D information facilitated by SfM and LiDAR technologies.
    As those technologies become more ubiquitous, more fruit descriptors and novel
    assessment systems can be developed based on the 3D architecture of strawberries.
    Although SfM methods were applied to high-spatial-resolution RGB images [129,130]
    to calculate several strawberry canopy parameters (e.g., canopy area, average
    height, volume, and smoothness), LiDAR could be used to obtain detailed information
    about a strawberry plant’s structural properties. For example, Jiang et al. [166]
    analyzed LiDAR data and proposed various quantification factors for the bush architecture
    of blueberries, including bush morphology (height, width, and volume), crown size,
    and shape descriptors (path curve λ and five shape indices). This type of research
    can be readily transferred to the strawberry domain. Besides, there is a great
    deal of progress to be made in predicting strawberry biophysical parameters and
    the photosynthesis process, and there is much to learn from other crops. Paul
    et al. [167] applied Gaussian process regression and the SVM model to estimate
    the canopy-averaged chlorophyll content of pear trees based on convolutional auto-encoder
    features of hyperspectral data. Li et al. [168] summarized the development of
    remote sensing imaging technologies for retrieval and analysis of information
    about various nutrition parameters, such as nitrogen, phosphorus, potassium, calcium,
    iron, and magnesium. The study showed that a leaf or canopy nutritional distribution
    map can be generated, and the coefficient of determination (R2) of nitrogen even
    reached 0.91. Lu et al. [169] found that the total emitted solar-induced chlorophyll
    fluorescence (SIF) is more effective than top-of-canopy (TOC) SIF in the prediction
    of forest photosynthesis. Dechant et al. [170] further revealed the canopy structure
    is dominant in the relationship between SIF and gross primary production (GPP)
    for rice, wheat, and corn. Studies like these in strawberry are few. Multispectral
    and hyperspectral datasets, radiative transfer modeling, and machine learning
    analysis may be comprehensively applied to study strawberry’s biophysical properties
    and photosynthesis processes. Furthermore, in a general sense, there is still
    room for model and algorithm development and the fusion and application of multiple
    types of remote sensing images. At present, several studies have assessed the
    feasibility of different methods or parameters in the detection of biotic and
    abiotic strawberry stresses, focusing on single stressors at discrete time points.
    These works have tried to distinguish between healthy plants and those with a
    single disease, improving discrimination accuracies where possible, as shown in
    Table 2. For future high-throughput disease detection, there is a need to integrate
    multiple sensors and multiple time points to identify field areas and plants under
    stress automatically and rapidly, diagnose the stressor type and evaluate its
    severity, comprehensively assess plant health through time, and model and predict
    plant responses to management strategies. 8. Conclusions Strawberry is different
    from most agronomic crops like corn, soybean, and wheat in various aspects. It
    is generally grown on raised-bed structures instead of flat ground and is also
    grown in hydroponic systems and under greenhouse and plastic tunnel structures.
    Strawberry is clonally propagated and has a complex growth habit that includes
    several plant parts, such as the crown, leaves, runners, inflorescences, and fleshy
    fruits. The fruits have many developmental stages and when ripe are very sensitive
    to environmental and management conditions. Plant development and fruit production
    can continually cycle and change over a six-month period, depending on the growing
    region. These characteristics make phenotyping considerations complex for strawberry.
    Therefore, the methods developed in major row crops must be creatively adapted
    to strawberry. The development of ground-based devices, UAVs, and emerging field
    robotics is advancing the potential for monitoring strawberry growth throughout
    the entire growing cycle, from planting to final harvest. Remote sensing can provide
    massive amounts of data about crop condition and health via plant and fruit characteristics.
    This deepens our knowledge about the crop itself and allows more advanced management
    practices. Remote sensing may also be useful for postharvest evaluation of strawberry
    fruits. Spectral and textual information obtained from multiple sensors can capture
    both external and internal fruit traits. Further, available artificial intelligence
    options include an expanding array of deep learning techniques and computer vision
    analysis methods. This combination of advances in sensors and data extraction
    and analysis will continue to accelerate the use of precision agriculture in strawberry
    production and phenomics technology in strawberry breeding and genetics. Author
    Contributions Conceptualization, A.A.-E. and C.Z.; methodology, C.Z.; writing—original
    draft preparation, C.Z.; writing—review and editing, A.A.-E., V.W. and C.Z.; visualization,
    C.Z.; supervision, A.A.-E. and V.W.; project administration, A.A.-E. and V.W.;
    and funding acquisition, A.A.-E. and V.W. All authors have read and agreed to
    the published version of the manuscript. Funding This research received no external
    funding. Institutional Review Board Statement Not applicable. Informed Consent
    Statement Not applicable. Data Availability Statement No data used in this work.
    Conflicts of Interest The authors declare that they have no conflict of interest.
    Appendix A A two-step approach was adopted to search and screen the literature
    related to remote sensing and machine learning applications, with an emphasis
    on strawberry. In the first step, refereed articles about remote sensing, machine
    learning, phenotyping, and strawberries were collected from the IEEE Xplore, ScienceDirect,
    Web of Science, and Google Scholar scientific database portals. The following
    query was used, which included the keywords implemented in the search: [“machine
    learning” OR “deep learning” OR “computer vision” OR “remote sensing” OR “phenotyping”
    OR “phenomics”] AND [“strawberry”]. In the second step, we screened a total of
    79 papers resulting from the search, of which 60 dealt with strawberry phenotyping
    and 19 were related to strawberry management during growth and development. The
    number of articles on each topic is shown in Figure A1. Figure A1. Number of articles
    included in this review by topic. Appendix B Table A1. Summary of research articles
    on strawberry phenotyping and management using remote sensing and machine learning.    References
    FAO. The Future of Food and Agriculture—Alternative Pathways to 2050; Food and
    Agriculture Organization of the United Nations: Rome, Italy, 2018. [Google Scholar]
    Bongiovanni, R.; Lowenberg-DeBoer, J. Precision agriculture and sustainability.
    Precis. Agric. 2004, 5, 359–387. [Google Scholar] [CrossRef] Zhang, N.; Wang,
    M.; Wang, N. Precision agriculture—A worldwide overview. Comput. Electron. Agric.
    2002, 36, 113–132. [Google Scholar] [CrossRef] Liaghat, S.; Balasundram, S.K.
    A review: The role of remote sensing in precision agriculture. Am. J. Agric. Biol.
    Sci. 2010, 5, 50–55. [Google Scholar] [CrossRef] [Green Version] Say, S.M.; Keskin,
    M.; Sehri, M.; Sekerli, Y.E. Adoption of precision agriculture technologies in
    developed and developing countries. Online J. Sci. Technol. 2018, 8, 7–15. [Google
    Scholar] Costa, C.; Schurr, U.; Loreto, F.; Menesatti, P.; Carpentier, S. Plant
    phenotyping research trends, a science mapping approach. Front. Plant Sci. 2019,
    9, 1933. [Google Scholar] [CrossRef] [PubMed] [Green Version] Yang, G.; Liu, J.;
    Zhao, C.; Li, Z.; Huang, Y.; Yu, H.; Xu, B.; Yang, X.; Zhu, D.; Zhang, X.; et
    al. Unmanned aerial vehicle remote sensing for field-based crop phenotyping: Current
    status and perspectives. Front. Plant Sci. 2017, 8, 1111. [Google Scholar] [CrossRef]
    Chawade, A.; van Ham, J.; Blomquist, H.; Bagge, O.; Alexandersson, E.; Ortiz,
    R. High-throughput field-phenotyping tools for plant breeding and precision agriculture.
    Agronomy 2019, 9, 258. [Google Scholar] [CrossRef] [Green Version] Pasala, R.;
    Pandey, B.B. Plant phenomics: High-throughput technology for accelerating genomics.
    J. Biosci. 2020, 45, 1–6. [Google Scholar] [CrossRef] Pauli, D.; Chapman, S.C.;
    Bart, R.; Topp, C.N.; Lawrence-Dill, C.J.; Poland, J.; Gore, M.A. The quest for
    understanding phenotypic variation via integrated approaches in the field environment.
    Plant Physiol. 2016, 172, 622–634. [Google Scholar] [CrossRef] [Green Version]
    Yang, W.; Feng, H.; Zhang, X.; Zhang, J.; Doonan, J.H.; Batchelor, W.D.; Xiong,
    L.; Yan, J. Crop phenomics and high-throughput phenotyping: Past decades, current
    challenges, and future perspectives. Mol. Plant 2020, 13, 187–214. [Google Scholar]
    [CrossRef] [Green Version] Weng, S.; Yu, S.; Dong, R.; Pan, F.; Liang, D. Nondestructive
    detection of storage time of strawberries using visible/near-infrared hyperspectral
    imaging. Int. J. Food Prop. 2020, 23, 269–281. [Google Scholar] [CrossRef] [Green
    Version] Mezzetti, B.; Giampieri, F.; Zhang, Y.-T.; Zhong, C.-F. Status of strawberry
    breeding programs and cultivation systems in Europe and the rest of the world.
    J. Berry Res. 2018, 8, 205–221. [Google Scholar] [CrossRef] Food and Agriculture
    Organization of the United Nations. FAOSTAT Database; 2018. Available online:
    http://www.fao.org/faostat/en/?#data/QC (accessed on 20 November 2020). Huang,
    Y.; Chen, Z.-X.; Tao, Y.; Huang, X.-Z.; Gu, X.-F. Agricultural remote sensing
    big data: Management and applications. J. Integr. Agric. 2018, 17, 1915–1931.
    [Google Scholar] [CrossRef] Sicre, C.M.; Fieuzal, R.; Baup, F. Contribution of
    multispectral (optical and radar) satellite images to the classification of agricultural
    surfaces. Int. J. Appl. Earth Obs. Geoinf. 2020, 84, 101972. [Google Scholar]
    [CrossRef] Xu, Y.; Smith, S.E.; Grunwald, S.; Abd-Elrahman, A.; Wani, S.P. Incorporation
    of satellite remote sensing pan-sharpened imagery into digital soil prediction
    and mapping models to characterize soil property variability in small agricultural
    fields. ISPRS J. Photogramm. Remote. Sens. 2017, 123, 1–19. [Google Scholar] [CrossRef]
    [Green Version] Zhu, Q.; Luo, Y.; Xu, Y.-P.; Tian, Y.; Yang, T. Satellite soil
    moisture for agricultural drought monitoring: Assessment of SMAP-derived soil
    water deficit index in Xiang River Basin, China. Remote. Sens. 2019, 11, 362.
    [Google Scholar] [CrossRef] [Green Version] Du, T.L.T.; Bui, D.D.; Nguyen, M.D.;
    Lee, H. Satellite-based, multi-indices for evaluation of agricultural droughts
    in a highly dynamic tropical catchment, Central Vietnam. Water 2018, 10, 659.
    [Google Scholar] [CrossRef] [Green Version] Estel, S.; Mader, S.; Levers, C.;
    Verburg, P.H.; Baumann, M.; Kuemmerle, T. Combining satellite data and agricultural
    statistics to map grassland management intensity in Europe. Environ. Res. Lett.
    2018, 13, 074020. [Google Scholar] [CrossRef] Fieuzal, R.; Baup, F. Forecast of
    wheat yield throughout the agricultural season using optical and radar satellite
    images. Int. J. Appl. Earth Obs. Geoinf. 2017, 59, 147–156. [Google Scholar] [CrossRef]
    Sharma, A.K.; Hubert-Moy, L.; Buvaneshwari, S.; Sekhar, M.; Ruiz, L.; Bandyopadhyay,
    S.; Corgne, S. Irrigation history estimation using multitemporal landsat satellite
    images: Application to an intensive groundwater irrigated agricultural watershed
    in India. Remote. Sens. 2018, 10, 893. [Google Scholar] [CrossRef] [Green Version]
    Xie, Q.; Dash, J.; Huete, A.; Jiang, A.; Yin, G.; Ding, Y.; Peng, D.; Hall, C.C.;
    Brown, L.; Shi, Y. Retrieval of crop biophysical parameters from Sentinel-2 remote
    sensing imagery. Int. J. Appl. Earth Obs. Geoinf. 2019, 80, 187–195. [Google Scholar]
    [CrossRef] Mateo-Sanchis, A.; Piles, M.; Muñoz-Marí, J.; Adsuara, J.E.; Pérez-Suay,
    A.; Camps-Valls, G. Synergistic integration of optical and microwave satellite
    data for crop yield estimation. Remote. Sens. Environ. 2019, 234, 111460. [Google
    Scholar] [CrossRef] [PubMed] Radoglou-Grammatikis, P.; Sarigiannidis, P.; Lagkas,
    T.; Moscholios, I. A compilation of UAV applications for precision agriculture.
    Comput. Netw. 2020, 172, 107148. [Google Scholar] [CrossRef] Giles, D.; Billing,
    R. Deployment and Performance of a UAV for Crop Spraying. Chem. Eng. Trans. 2015,
    44, 307–312. [Google Scholar] Faiçal, B.S.; Freitas, H.; Gomes, P.H.; Mano, L.Y.;
    Pessin, G.; de Carvalho, A.C.; Krishnamachari, B.; Ueyama, J. An adaptive approach
    for UAV-based pesticide spraying in dynamic environments. Comput. Electron. Agric.
    2017, 138, 210–223. [Google Scholar] [CrossRef] Di Gennaro, S.F.; Matese, A.;
    Gioli, B.; Toscano, P.; Zaldei, A.; Palliotti, A.; Genesio, L. Multisensor approach
    to assess vineyard thermal dynamics combining high-resolution unmanned aerial
    vehicle (UAV) remote sensing and wireless sensor network (WSN) proximal sensing.
    Sci. Hortic. 2017, 221, 83–87. [Google Scholar] [CrossRef] Popescu, D.; Stoican,
    F.; Stamatescu, G.; Ichim, L.; Dragana, C. Advanced UAV–WSN System for Intelligent
    Monitoring in Precision Agriculture. Sensors 2020, 20, 817. [Google Scholar] [CrossRef]
    [Green Version] Abd-Elrahman, A.; Pande-Chhetri, R.; Vallad, G. Design and development
    of a multi-purpose low-cost hyperspectral imaging system. Remote. Sens. 2011,
    3, 570–586. [Google Scholar] [CrossRef] [Green Version] Jin, X.; Li, Z.; Atzberger,
    C. Editorial for the Special Issue “Estimation of Crop Phenotyping Traits using
    Unmanned Ground Vehicle and Unmanned Aerial Vehicle Imagery. Remote Sens. 2020,
    12, 940. [Google Scholar] [CrossRef] [Green Version] Weiss, M.; Jacob, F.; Duveiller,
    G. Remote sensing for agricultural applications: A meta-review. Remote. Sens.
    Environ. 2020, 236, 111402. [Google Scholar] [CrossRef] Mishra, P.; Asaari, M.S.M.;
    Herrero-Langreo, A.; Lohumi, S.; Diezma, B.; Scheunders, P. Close range hyperspectral
    imaging of plants: A review. Biosyst. Eng. 2017, 164, 49–67. [Google Scholar]
    [CrossRef] Corp, L.A.; McMurtrey, J.E.; Middleton, E.M.; Mulchi, C.L.; Chappelle,
    E.W.; Daughtry, C.S. Fluorescence sensing systems: In vivo detection of biophysical
    variations in field corn due to nitrogen supply. Remote. Sens. Environ. 2003,
    86, 470–479. [Google Scholar] [CrossRef] Wallace, L.; Lucieer, A.; Watson, C.;
    Turner, D. Development of a UAV-LiDAR system with application to forest inventory.
    Remote Sens. 2012, 4, 1519–1543. [Google Scholar] [CrossRef] [Green Version] Steele-Dunne,
    S.C.; McNairn, H.; Monsivais-Huertero, A.; Judge, J.; Liu, P.-W.; Papathanassiou,
    K. Radar remote sensing of agricultural canopies: A review. IEEE J. Sel. Top.
    Appl. Earth Obs. Remote. Sens. 2017, 10, 2249–2273. [Google Scholar] [CrossRef]
    [Green Version] McNairn, H.; Shang, J. A review of multitemporal synthetic aperture
    radar (SAR) for crop monitoring. In Multitemporal Remote Sensing. Remote Sensing
    and Digital Image Processing; Ban, Y., Ed.; Springer: Cham, Switzerland, 2016;
    Volume 20. [Google Scholar] [CrossRef] Liu, C.-A.; Chen, Z.-X.; Yun, S.; Chen,
    J.-S.; Hasi, T.; Pan, H.-Z. Research advances of SAR remote sensing for agriculture
    applications: A review. J. Integr. Agric. 2019, 18, 506–525. [Google Scholar]
    [CrossRef] [Green Version] Kuester, M.; Thome, K.; Krause, K.; Canham, K.; Whittington,
    E. Comparison of surface reflectance measurements from three ASD FieldSpec FR
    spectroradiometers and one ASD FieldSpec VNIR spectroradiometer. In Proceedings
    of the IGARSS 2001. Scanning the Present and Resolving the Future. Proceedings.
    IEEE 2001 International Geoscience and Remote Sensing Symposium (Cat. No.01CH37217),
    Sydney, NSW, Australia, 9–13 July 2001; pp. 72–74. [Google Scholar] Danner, M.;
    Locherer, M.; Hank, T.; Richter, K. Spectral Sampling with the ASD FieldSpec 4—Theory,
    Measurement, Problems, Interpretation; EnMAP Field Guides Technical Report; GFZ
    Data Services: Potsdam, Germany, 2015. [Google Scholar] [CrossRef] Mahmud, M.S.;
    Zaman, Q.U.; Esau, T.J.; Chang, Y.K.; Price, G.W.; Prithiviraj, B. Real-Time Detection
    of Strawberry Powdery Mildew Disease Using a Mobile Machine Vision System. Agronomy
    2020, 10, 1027. [Google Scholar] [CrossRef] Liakos, K.G.; Busato, P.; Moshou,
    D.; Pearson, S.; Bochtis, D. Machine learning in agriculture: A review. Sensors
    2018, 18, 2674. [Google Scholar] [CrossRef] [Green Version] Mochida, K.; Koda,
    S.; Inoue, K.; Hirayama, T.; Tanaka, S.; Nishii, R.; Melgani, F. Computer vision-based
    phenotyping for improvement of plant productivity: A machine learning perspective.
    GigaScience 2019, 8, giy153. [Google Scholar] [CrossRef] [Green Version] Cai,
    J.; Luo, J.; Wang, S.; Yang, S. Feature selection in machine learning: A new perspective.
    Neurocomputing 2018, 300, 70–79. [Google Scholar] [CrossRef] Miao, J.; Niu, L.
    A survey on feature selection. Procedia Comput. Sci. 2016, 91, 919–926. [Google
    Scholar] [CrossRef] [Green Version] Chlingaryan, A.; Sukkarieh, S.; Whelan, B.
    Machine learning approaches for crop yield prediction and nitrogen status estimation
    in precision agriculture: A review. Comput. Electron. Agric. 2018, 151, 61–69.
    [Google Scholar] [CrossRef] Sabanci, K.; Kayabasi, A.; Toktas, A. Computer vision-based
    method for classification of wheat grains using artificial neural network. J.
    Sci. Food Agric. 2017, 97, 2588–2593. [Google Scholar] [CrossRef] [PubMed] Koirala,
    A.; Walsh, K.B.; Wang, Z.; McCarthy, C. Deep learning–Method overview and review
    of use for fruit detection and yield estimation. Comput. Electron. Agric. 2019,
    162, 219–234. [Google Scholar] [CrossRef] Jakhar, D.; Kaur, I. Artificial intelligence,
    machine learning and deep learning: Definitions and differences. Clin. Exp. Dermatol.
    2020, 45, 131–132. [Google Scholar] [CrossRef] Miikkulainen, R.; Liang, J.; Meyerson,
    E.; Rawal, A.; Fink, D.; Francon, O.; Raju, B.; Shahrzad, H.; Navruzyan, A.; Duffy,
    N. Evolving deep neural networks. arXiv 2016, arXiv:1703.00548. [Google Scholar]
    Seifert, C.; Aamir, A.; Balagopalan, A.; Jain, D.; Sharma, A.; Grottel, S.; Gumhold,
    S. Visualizations of deep neural networks in computer vision: A survey. In Transparent
    Data Mining for Big and Small Data; Springer: Berlin/Heidelberg, Germany, 2017;
    pp. 123–144. [Google Scholar] Zhang, J.; Man, K.F. Time series prediction using
    RNN in multi-dimension embedding phase space. In Proceedings of the SMC’98 Conference
    Proceedings. 1998 IEEE International Conference on Systems, Man, and Cybernetics
    (Cat. No. 98CH36218), San Diego, CA, USA, 14 October 1998; pp. 1868–1873. [Google
    Scholar] Yu, S.; Jia, S.; Xu, C. Convolutional neural networks for hyperspectral
    image classification. Neurocomputing 2017, 219, 88–98. [Google Scholar] [CrossRef]
    Liu, T.; Abd-Elrahman, A. An object-based image analysis method for enhancing
    classification of land covers using fully convolutional networks and multi-view
    images of small unmanned aerial system. Remote. Sens. 2018, 10, 457. [Google Scholar]
    [CrossRef] [Green Version] Salakhutdinov, R. Learning deep generative models.
    Ann. Rev. Stat. Appl. 2015, 2, 361–385. [Google Scholar] [CrossRef] [Green Version]
    Pu, Y.; Gan, Z.; Henao, R.; Yuan, X.; Li, C.; Stevens, A.; Carin, L. Variational
    autoencoder for deep learning of images, labels and captions. arXiv 2016, arXiv:1609.08976.
    [Google Scholar] Bauer, A.; Bostrom, A.G.; Ball, J.; Applegate, C.; Cheng, T.;
    Laycock, S.; Rojas, S.M.; Kirwan, J.; Zhou, J. Combining computer vision and deep
    learning to enable ultra-scale aerial phenotyping and precision agriculture: A
    case study of lettuce production. Hortic. Res. 2019, 6, 1–12. [Google Scholar]
    [CrossRef] [Green Version] Zhang, L.; Zhang, L.; Du, B. Deep learning for remote
    sensing data: A technical tutorial on the state of the art. IEEE Geosci. Remote.
    Sens. Mag. 2016, 4, 22–40. [Google Scholar] [CrossRef] Kamilaris, A.; Prenafeta-Boldú,
    F.X. Deep learning in agriculture: A survey. Comput. Electron. Agric. 2018, 147,
    70–90. [Google Scholar] [CrossRef] [Green Version] Puttemans, S.; Vanbrabant,
    Y.; Tits, L.; Goedemé, T. Automated visual fruit detection for harvest estimation
    and robotic harvesting. In Proceedings of the 2016 sixth international conference
    on image processing theory, tools and applications (IPTA), Oulu, Finland, 12–15
    December 2016; pp. 1–6. [Google Scholar] [CrossRef] Feng, G.; Qixin, C.; Masateru,
    N. Fruit detachment and classification method for strawberry harvesting robot.
    Int. J. Adv. Robot. Syst. 2008, 5, 4. [Google Scholar] [CrossRef] Lin, P.; Chen,
    Y. Detection of Strawberry Flowers in Outdoor Field by Deep Neural Network. In
    Proceedings of the 2018 IEEE 3rd International Conference on Image, Vision and
    Computing (ICIVC), Chongqing, China, 27–29 June 2018; pp. 482–486. [Google Scholar]
    [CrossRef] Lamb, N.; Chuah, M.C. A strawberry detection system using convolutional
    neural networks. In Proceedings of the 2018 IEEE International Conference on Big
    Data (Big Data), Seattle, WA, USA, 10–13 December 2018; pp. 2515–2520. [Google
    Scholar] [CrossRef] Yu, Y.; Zhang, K.; Yang, L.; Zhang, D. Fruit detection for
    strawberry harvesting robot in non-structural environment based on Mask-RCNN.
    Comput. Electron. Agric. 2019, 163, 104846. [Google Scholar] [CrossRef] Zhou,
    C.; Hu, J.; Xu, Z.; Yue, J.; Ye, H.; Yang, G. A novel greenhouse-based system
    for the detection and plumpness assessment of strawberry using an improved deep
    learning technique. Front. Plant Sci. 2020, 11, 559. [Google Scholar] [CrossRef]
    Kafkas, E.; Koşar, M.; Paydaş, S.; Kafkas, S.; Başer, K. Quality characteristics
    of strawberry genotypes at different maturation stages. Food Chem. 2007, 100,
    1229–1236. [Google Scholar] [CrossRef] Azodanlou, R.; Darbellay, C.; Luisier,
    J.-L.; Villettaz, J.-C.; Amadò, R. Changes in flavour and texture during the ripening
    of strawberries. Eur. Food Res. Technol. 2004, 218, 167–172. [Google Scholar]
    Kader, A.A. Quality and its maintenance in relation to the postharvest physiology
    of strawberry. In The Strawberry into the 21st Century; Timber Press: Portland,
    OR, USA, 1991; pp. 145–152. [Google Scholar] Rahman, M.M.; Moniruzzaman, M.; Ahmad,
    M.R.; Sarker, B.; Alam, M.K. Maturity stages affect the postharvest quality and
    shelf-life of fruits of strawberry genotypes growing in subtropical regions. J.
    Saudi Soc. Agric. Sci. 2016, 15, 28–37. [Google Scholar] [CrossRef] [Green Version]
    Li, B.; Lecourt, J.; Bishop, G. Advances in non-destructive early assessment of
    fruit ripeness towards defining optimal time of harvest and yield prediction—A
    review. Plants 2018, 7, 3. [Google Scholar] Rico, D.; Martin-Diana, A.B.; Barat,
    J.; Barry-Ryan, C. Extending and measuring the quality of fresh-cut fruit and
    vegetables: A review. Trends Food Sci. Technol. 2007, 18, 373–386. [Google Scholar]
    [CrossRef] [Green Version] Kader, A.A. Quality parameters of fresh-cut fruit and
    vegetable products. In Fresh-Cut Fruits and Vegetables; CRC Press: Boca Raton,
    FL, USA, 2002; pp. 20–29. [Google Scholar] Liu, C.; Liu, W.; Lu, X.; Ma, F.; Chen,
    W.; Yang, J.; Zheng, L. Application of multispectral imaging to determine quality
    attributes and ripeness stage in strawberry fruit. PLoS ONE 2014, 9, e87818. [Google
    Scholar] [CrossRef] [PubMed] Bai, J.; Plotto, A.; Baldwin, E.; Whitaker, V.; Rouseff,
    R. Electronic nose for detecting strawberry fruit maturity. In Proceedings of
    the Florida State Horticultural Society, Crystal River, FL, USA, 6–8 June 2010;
    Volume 123, pp. 259–263. [Google Scholar] Raut, K.D.; Bora, V. Assessment of Fruit
    Maturity using Direct Color Mapping. Int. Res. J. Eng. Technol. 2016, 3, 1540–1543.
    [Google Scholar] Jiang, H.; Zhang, C.; Liu, F.; Zhu, H.; He, Y. Identification
    of strawberry ripeness based on multispectral indexes extracted from hyperspectral
    images. Guang Pu Xue Yu Guang Pu Fen Xi = Guang Pu 2016, 36, 1423–1427. [Google
    Scholar] [PubMed] Guo, C.; Liu, F.; Kong, W.; He, Y.; Lou, B. Hyperspectral imaging
    analysis for ripeness evaluation of strawberry with support vector machine. J.
    Food Eng. 2016, 179, 11–18. [Google Scholar] Yue, X.-Q.; Shang, Z.-Y.; Yang, J.-Y.;
    Huang, L.; Wang, Y.-Q. A smart data-driven rapid method to recognize the strawberry
    maturity. Inf. Proc. Agric. 2019. [Google Scholar] [CrossRef] Gao, Z.; Shao, Y.;
    Xuan, G.; Wang, Y.; Liu, Y.; Han, X. Real-time hyperspectral imaging for the in-field
    estimation of strawberry ripeness with deep learning. Artif. Intell. Agric. 2020,
    4, 31–38. [Google Scholar] [CrossRef] Xiong, Y.; Peng, C.; Grimstad, L.; From,
    P.J.; Isler, V. Development and field evaluation of a strawberry harvesting robot
    with a cable-driven gripper. Comput. Electron. Agric. 2019, 157, 392–402. [Google
    Scholar] [CrossRef] Sustika, R.; Subekti, A.; Pardede, H.F.; Suryawati, E.; Mahendra,
    O.; Yuwana, S. Evaluation of deep convolutional neural network architectures for
    strawberry quality inspection. Int. J. Eng. Technol. 2018, 7, 75–80. [Google Scholar]
    Usha, S.; Karthik, M.; Jenifer, R.; Scholar, P. Automated Sorting and Grading
    of Vegetables Using Image Processing. Int. J. Eng. Res. Gen. Sci. 2017, 5, 53–61.
    [Google Scholar] Shen, J.; Qi, H.-F.; Li, C.; Zeng, S.-M.; Deng, C. Experimental
    on storage and preservation of strawberry. Food Sci. Tech 2011, 36, 48–51. [Google
    Scholar] Liming, X.; Yanchao, Z. Automated strawberry grading system based on
    image processing. Comput. Electron. Agric. 2010, 71, S32–S39. [Google Scholar]
    [CrossRef] Mahendra, O.; Pardede, H.F.; Sustika, R.; Kusumo, R.B.S. Comparison
    of Features for Strawberry Grading Classification with Novel Dataset. In Proceedings
    of the 2018 International Conference on Computer, Control, Informatics and Its
    Applications (IC3INA), Tangerang, Indonesia, 1–2 November 2018; pp. 7–12. [Google
    Scholar] [CrossRef] Péneau, S.; Brockhoff, P.B.; Escher, F.; Nuessli, J. A comprehensive
    approach to evaluate the freshness of strawberries and carrots. Postharvest Biol.
    Technol. 2007, 45, 20–29. [Google Scholar] [CrossRef] Dong, D.; Zhao, C.; Zheng,
    W.; Wang, W.; Zhao, X.; Jiao, L. Analyzing strawberry spoilage via its volatile
    compounds using longpath fourier transform infrared spectroscopy. Sci. Rep. 2013,
    3, 2585. [Google Scholar] [CrossRef] [PubMed] [Green Version] Geladi, P.; Kowalski,
    B.R. Partial least-squares regression: A tutorial. Anal. Chim. Acta 1986, 185,
    1–17. [Google Scholar] [CrossRef] Wang, H.; Peng, J.; Xie, C.; Bao, Y.; He, Y.
    Fruit quality evaluation using spectroscopy technology: A review. Sensors 2015,
    15, 11889–11927. [Google Scholar] [CrossRef] [PubMed] [Green Version] ElMasry,
    G.; Wang, N.; ElSayed, A.; Ngadi, M. Hyperspectral imaging for nondestructive
    determination of some quality attributes for strawberry. J. Food Eng. 2007, 81,
    98–107. [Google Scholar] [CrossRef] Weng, S.; Yu, S.; Guo, B.; Tang, P.; Liang,
    D. Non-Destructive Detection of Strawberry Quality Using Multi-Features of Hyperspectral
    Imaging and Multivariate Methods. Sensors 2020, 20, 3074. [Google Scholar] [CrossRef]
    Liu, Q.; Wei, K.; Xiao, H.; Tu, S.; Sun, K.; Sun, Y.; Pan, L.; Tu, K. Near-infrared
    hyperspectral imaging rapidly detects the decay of postharvest strawberry based
    on water-soluble sugar analysis. Food Anal. Methods 2019, 12, 936–946. [Google
    Scholar] [CrossRef] Liu, S.; Xu, H.; Wen, J.; Zhong, W.; Zhou, J. Prediction and
    analysis of strawberry sugar content based on partial least squares prediction
    model. J. Anim. Plant Sci. 2019, 29, 1390–1395. [Google Scholar] Amodio, M.L.;
    Ceglie, F.; Chaudhry, M.M.A.; Piazzolla, F.; Colelli, G. Potential of NIR spectroscopy
    for predicting internal quality and discriminating among strawberry fruits from
    different production systems. Postharvest Biol. Technol. 2017, 125, 112–121. [Google
    Scholar] [CrossRef] LI, J.-B.; GUO, Z.-M.; HUANG, W.-Q.; ZHANG, B.-H.; ZHAO, C.-J.
    Near-infrared spectra combining with CARS and SPA algorithms to screen the variables
    and samples for quantitatively determining the soluble solids content in strawberry.
    Spectrosc. Spectr. Anal. 2015, 35, 372–378. [Google Scholar] Ding, X.; Zhang,
    C.; Liu, F.; Song, X.; Kong, W.; He, Y. Determination of soluble solid content
    in strawberry using hyperspectral imaging combined with feature extraction methods.
    Guang Pu Xue Yu Guang Pu Fen Xi = Guang Pu 2015, 35, 1020–1024. [Google Scholar]
    [PubMed] Sánchez, M.-T.; De la Haba, M.J.; Benítez-López, M.; Fernández-Novales,
    J.; Garrido-Varo, A.; Pérez-Marín, D. Non-destructive characterization and quality
    control of intact strawberries based on NIR spectral data. J. Food Eng. 2012,
    110, 102–108. [Google Scholar] [CrossRef] Nishizawa, T.; Mori, Y.; Fukushima,
    S.; Natsuga, M.; Maruyama, Y. Non-destructive analysis of soluble sugar components
    in strawberry fruits using near-infrared spectroscopy. Nippon Shokuhin Kagaku
    Kogaku Kaishi = J. Jpn. Soc. Food Sci. Technol. 2009, 56, 229–235. [Google Scholar]
    [CrossRef] [Green Version] Wulf, J.; Rühmann, S.; Rego, I.; Puhl, I.; Treutter,
    D.; Zude, M. Nondestructive application of laser-induced fluorescence spectroscopy
    for quantitative analyses of phenolic compounds in strawberry fruits (Fragaria
    × ananassa). J. Agric. Food Chem. 2008, 56, 2875–2882. [Google Scholar] [CrossRef]
    Tallada, J.G.; Nagata, M.; Kobayashi, T. Non-destructive estimation of firmness
    of strawberries (Fragaria × ananassa Duch.) using NIR hyperspectral imaging. Environ.
    Control. Biol. 2006, 44, 245–255. [Google Scholar] [CrossRef] [Green Version]
    Nagata, M.; Tallada, J.G.; Kobayashi, T.; Toyoda, H. NIR hyperspectral imaging
    for measurement of internal quality in strawberries. In Proceedings of the 2005
    ASAE Annual Meeting, Tampa, FL, USA, 17–20 July 2005. ASAE Paper No. 053131. [Google
    Scholar] Nagata, M.; Tallada, J.G.; Kobayashi, T.; Cui, Y.; Gejima, Y. Predicting
    maturity quality parameters of strawberries using hyperspectral imaging. In Proceedings
    of the ASAE/CSAE Annual International Meeting, Ottawa, ON, Canada, 1–4 August
    2004. Paper No. 043033. [Google Scholar] Ishikawa, T.; Hayashi, A.; Nagamatsu,
    S.; Kyutoku, Y.; Dan, I.; Wada, T.; Oku, K.; Saeki, Y.; Uto, T.; Tanabata, T.;
    et al. Classification of strawberry fruit shape by machine learning. Int. Arch.
    Photogramm. Remote. Sens. Spat. Inf. Sci. 2018, 42. [Google Scholar] [CrossRef]
    [Green Version] Oo, L.M.; Aung, N.Z. A simple and efficient method for automatic
    strawberry shape and size estimation and classification. Biosyst. Eng. 2018, 170,
    96–107. [Google Scholar] [CrossRef] Feldmann, M.J.; Hardigan, M.A.; Famula, R.A.;
    López, C.M.; Tabb, A.; Cole, G.S.; Knapp, S.J. Multi-dimensional machine learning
    approaches for fruit shape phenotyping in strawberry. GigaScience 2020, 9, giaa030.
    [Google Scholar] [CrossRef] He, J.Q.; Harrison, R.J.; Li, B. A novel 3D imaging
    system for strawberry phenotyping. Plant Methods 2017, 13, 1–8. [Google Scholar]
    [CrossRef] Kochi, N.; Tanabata, T.; Hayashi, A.; Isobe, S. A 3D shape-measuring
    system for assessing strawberry fruits. Int. J. Autom. Technol. 2018, 12, 395–404.
    [Google Scholar] [CrossRef] Li, B.; Cockerton, H.M.; Johnson, A.W.; Karlström,
    A.; Stavridou, E.; Deakin, G.; Harrison, R.J. Defining Strawberry Uniformity using
    3D Imaging and Genetic Mapping. bioRxiv 2020. [Google Scholar] [CrossRef] [PubMed]
    Pathak, T.B.; Dara, S.K.; Biscaro, A. Evaluating correlations and development
    of meteorology based yield forecasting model for strawberry. Adv. Meteorol. 2016,
    2016, 1–7. [Google Scholar] [CrossRef] [Green Version] Misaghi, F.; Dayyanidardashti,
    S.; Mohammadi, K.; Ehsani, M. Application of Artificial Neural Network and Geostatistical
    Methods in Analyzing Strawberry Yield Data; American Society of Agricultural and
    Biological Engineers: Minneapolis, MN, USA, 2004; p. 1. [Google Scholar] MacKenzie,
    S.J.; Chandler, C.K. A method to predict weekly strawberry fruit yields from extended
    season production systems. Agron. J. 2009, 101, 278–287. [Google Scholar] [CrossRef]
    Hassan, H.A.; Taha, S.S.; Aboelghar, M.A.; Morsy, N.A. Comparative the impact
    of organic and conventional strawberry cultivation on growth and productivity
    using remote sensing techniques under Egypt climate conditions. Asian J. Agric.
    Biol. 2018, 6, 228–244. [Google Scholar] Maskey, M.L.; Pathak, T.B.; Dara, S.K.
    Weather Based Strawberry Yield Forecasts at Field Scale Using Statistical and
    Machine Learning Models. Atmosphere 2019, 10, 378. [Google Scholar] [CrossRef]
    [Green Version] Chen, Y.; Lee, W.S.; Gan, H.; Peres, N.; Fraisse, C.; Zhang, Y.;
    He, Y. Strawberry yield prediction based on a deep neural network using high-resolution
    aerial orthoimages. Remote. Sens. 2019, 11, 1584. [Google Scholar] [CrossRef]
    [Green Version] Fonstad, M.A.; Dietrich, J.T.; Courville, B.C.; Jensen, J.L.;
    Carbonneau, P.E. Topographic structure from motion: A new development in photogrammetric
    measurement. Earth Surf. Proc. Landf. 2013, 38, 421–430. [Google Scholar] [CrossRef]
    [Green Version] Ozyesil, O.; Voroninski, V.; Basri, R.; Singer, A. A survey of
    structure from motion. arXiv 2017, arXiv:1701.08493. [Google Scholar] Patrick,
    A.; Li, C. High throughput phenotyping of blueberry bush morphological traits
    using unmanned aerial systems. Remote. Sens. 2017, 9, 1250. [Google Scholar] [CrossRef]
    [Green Version] Makanza, R.; Zaman-Allah, M.; Cairns, J.E.; Magorokosho, C.; Tarekegne,
    A.; Olsen, M.; Prasanna, B.M. High-throughput phenotyping of canopy cover and
    senescence in maize field trials using aerial digital canopy imaging. Remote.
    Sens. 2018, 10, 330. [Google Scholar] [CrossRef] [PubMed] [Green Version] Han,
    L.; Yang, G.; Dai, H.; Yang, H.; Xu, B.; Feng, H.; Li, Z.; Yang, X. Fuzzy Clustering
    of Maize Plant-Height Patterns Using Time Series of UAV Remote-Sensing Images
    and Variety Traits. Front. Plant Sci. 2019, 10, 926. [Google Scholar] [CrossRef]
    [PubMed] [Green Version] Xue, J.; Su, B. Significant remote sensing vegetation
    indices: A review of developments and applications. J. Sens. 2017, 2017, 1–17.
    [Google Scholar] [CrossRef] [Green Version] Hunt, E.R., Jr.; Doraiswamy, P.C.;
    McMurtrey, J.E.; Daughtry, C.S.; Perry, E.M.; Akhmedov, B. A visible band index
    for remote sensing leaf chlorophyll content at the canopy scale. Int. J. Appl.
    Earth Obs. Geoinf. 2013, 21, 103–112. [Google Scholar] [CrossRef] [Green Version]
    Clevers, J.G.; Kooistra, L. Using hyperspectral remote sensing data for retrieving
    canopy chlorophyll and nitrogen content. IEEE J. Sel. Top. Appl. Earth Obs. Remote.
    Sens. 2011, 5, 574–583. [Google Scholar] [CrossRef] Kattenborn, T.; Schmidtlein,
    S. Radiative transfer modelling reveals why canopy reflectance follows function.
    Sci. Rep. 2019, 9, 1–10. [Google Scholar] [CrossRef] [Green Version] Yuan, H.;
    Yang, G.; Li, C.; Wang, Y.; Liu, J.; Yu, H.; Feng, H.; Xu, B.; Zhao, X.; Yang,
    X. Retrieving soybean leaf area index from unmanned aerial vehicle hyperspectral
    remote sensing: Analysis of RF, ANN, and SVM regression models. Remote. Sens.
    2017, 9, 309. [Google Scholar] [CrossRef] [Green Version] Wolanin, A.; Camps-Valls,
    G.; Gómez-Chova, L.; Mateo-García, G.; van der Tol, C.; Zhang, Y.; Guanter, L.
    Estimating crop primary productivity with Sentinel-2 and Landsat 8 using machine
    learning methods trained with radiative transfer simulations. Remote. Sens. Environ.
    2019, 225, 441–457. [Google Scholar] [CrossRef] Luisa España-Boquera, M.; Cárdenas-Navarro,
    R.; López-Pérez, L.; Castellanos-Morales, V.; Lobit, P. Estimating the nitrogen
    concentration of strawberry plants from its spectral response. Commun. Soil Sci.
    Plant Anal. 2006, 37, 2447–2459. [Google Scholar] [CrossRef] Sandino, J.D.; Ramos-Sandoval,
    O.L.; Amaya-Hurtado, D. Method for estimating leaf coverage in strawberry plants
    using digital image processing. Rev. Bras. Eng. Agrícola Ambient. 2016, 20, 716–721.
    [Google Scholar] [CrossRef] [Green Version] Jianlun, W.; Yu, H.; Shuangshuang,
    Z.; Hongxu, Z.; Can, H.; Xiaoying, C.; Yun, X.; Jianshu, C.; Shuting, W. A new
    multi-scale analytic algorithm for edge extraction of strawberry leaf images in
    natural light. Int. J. Agric. Biol. Eng. 2016, 9, 99–108. [Google Scholar] Guan,
    Z.; Abd-Elrahman, A.; Fan, Z.; Whitaker, V.M.; Wilkinson, B. Modeling strawberry
    biomass and leaf area using object-based analysis of high-resolution images. J.
    Photogramm. Remote. Sens. 2020, 163, 171–186. [Google Scholar] [CrossRef] Abd-Elrahman,
    A.; Guan, Z.; Dalid, C.; Whitaker, V.; Britt, K.; Wilkinson, B.; Gonzalez, A.
    Automated Canopy Delineation and Size Metrics Extraction for Strawberry Dry Weight
    Modeling Using Raster Analysis of High-Resolution Imagery. Remote. Sens. 2020,
    12, 3632. [Google Scholar] [CrossRef] Takahashi, M.; Takayama, S.; Umeda, H.;
    Yoshida, C.; Koike, O.; Iwasaki, Y.; Sugeno, W. Quantification of Strawberry Plant
    Growth and Amount of Light Received Using a Depth Sensor. Environ. Control. Biol.
    2020, 58, 31–36. [Google Scholar] [CrossRef] [Green Version] Kokin, E.; Palge,
    V.; Pennar, M.; Jürjenson, K. Strawberry leaf surface temperature dynamics measured
    by thermal camera in night frost conditions. Agron. Res. 2018, 16. [Google Scholar]
    [CrossRef] Touati, F.; Al-Hitmi, M.; Benhmed, K.; Tabish, R. A fuzzy logic based
    irrigation system enhanced with wireless data logging applied to the state of
    Qatar. Comput. Electron. Agric. 2013, 98, 233–241. [Google Scholar] [CrossRef]
    Avşar, E.; Buluş, K.; Saridaş, M.A.; Kapur, B. Development of a cloud-based automatic
    irrigation system: A case study on strawberry cultivation. In Proceedings of the
    2018 7th International Conference on Modern Circuits and Systems Technologies
    (MOCAST), Thessaloniki, Greece, 7–9 May 2018; pp. 1–4. [Google Scholar] Gutiérrez,
    J.; Villa-Medina, J.F.; Nieto-Garibay, A.; Porta-Gándara, M.Á. Automated irrigation
    system using a wireless sensor network and GPRS module. IEEE Trans. Instrum. Meas.
    2013, 63, 166–176. [Google Scholar] [CrossRef] Morillo, J.G.; Martín, M.; Camacho,
    E.; Díaz, J.R.; Montesinos, P. Toward precision irrigation for intensive strawberry
    cultivation. Agric. Water Manag. 2015, 151, 43–51. [Google Scholar] [CrossRef]
    Gerhards, M.; Schlerf, M.; Mallick, K.; Udelhoven, T. Challenges and future perspectives
    of multi-/Hyperspectral thermal infrared remote sensing for crop water-stress
    detection: A review. Remote. Sens. 2019, 11, 1240. [Google Scholar] [CrossRef]
    [Green Version] Grant, O.M.; Davies, M.J.; Johnson, A.W.; Simpson, D.W. Physiological
    and growth responses to water deficits in cultivated strawberry (Fragaria× ananassa)
    and in one of its progenitors, Fragaria chiloensis. Environ. Exp. Bot. 2012, 83,
    23–32. [Google Scholar] [CrossRef] Nezhadahmadi, A.; Faruq, G.; Rashid, K. The
    impact of drought stress on morphological and physiological parameters of three
    strawberry varieties in different growing conditions. Pak. J. Agric. Sci. 2015,
    52, 79–92. [Google Scholar] Grant, O.M.; Johnson, A.W.; Davies, M.J.; James, C.M.;
    Simpson, D.W. Physiological and morphological diversity of cultivated strawberry
    (Fragaria× ananassa) in response to water deficit. Environ. Exp. Bot. 2010, 68,
    264–272. [Google Scholar] [CrossRef] Klamkowski, K.; Treder, W. Response to drought
    stress of three strawberry cultivars grown under greenhouse conditions. J. Fruit
    Ornam. Plant Res. 2008, 16, 179–188. [Google Scholar] Adak, N.; Gubbuk, H.; Tetik,
    N. Yield, quality and biochemical properties of various strawberry cultivars under
    water stress. J. Sci. Food Agric. 2018, 98, 304–311. [Google Scholar] [CrossRef]
    [PubMed] Peñuelas, J.; Savé, R.; Marfà, O.; Serrano, L. Remotely measured canopy
    temperature of greenhouse strawberries as indicator of water status and yield
    under mild and very mild water stress conditions. Agric. For. Meteorol. 1992,
    58, 63–77. [Google Scholar] [CrossRef] Razavi, F.; Pollet, B.; Steppe, K.; Van
    Labeke, M.-C. Chlorophyll fluorescence as a tool for evaluation of drought stress
    in strawberry. Photosynthetica 2008, 46, 631–633. [Google Scholar] [CrossRef]
    Delalieux, S.; Delauré, B.; Tits, L.; Boonen, M.; Sima, A.; Baeck, P. High resolution
    strawberry field monitoring using the compact hyperspectral imaging solution COSI.
    Adv. Anim. Biosci. 2017, 8, 156. [Google Scholar] [CrossRef] Li, H.; Yin, J.;
    Zhang, M.; Sigrimis, N.; Gao, Y.; Zheng, W. Automatic diagnosis of strawberry
    water stress status based on machine vision. Int. J. Agric. Biol. Eng. 2019, 12,
    159–164. [Google Scholar] [CrossRef] Gerhards, M.; Schlerf, M.; Rascher, U.; Udelhoven,
    T.; Juszczak, R.; Alberti, G.; Miglietta, F.; Inoue, Y. Analysis of airborne optical
    and thermal imagery for detection of water stress symptoms. Remote. Sens. 2018,
    10, 1139. [Google Scholar] [CrossRef] [Green Version] Oliveira, M.S.; Peres, N.A.
    Common Strawberry Diseases in Florida. EDIS 2020, 2020. [Google Scholar] [CrossRef]
    Chang, Y.K.; Mahmud, M.; Shin, J.; Nguyen-Quang, T.; Price, G.W.; Prithiviraj,
    B. Comparison of Image Texture Based Supervised Learning Classifiers for Strawberry
    Powdery Mildew Detection. AgriEngineering 2019, 1, 434–452. [Google Scholar] [CrossRef]
    [Green Version] Mahlein, A.-K. Plant Disease detection by imaging sensors–parallels
    and specific demands for precision agriculture and plant phenotyping. Plant Dis.
    2016, 100, 241–251. [Google Scholar] [CrossRef] [PubMed] [Green Version] Park,
    H.; Eun, J.-S.; Kim, S.-H. Image-based disease diagnosing and predicting of the
    crops through the deep learning mechanism. In Proceedings of the 2017 International
    Conference on Information and Communication Technology Convergence (ICTC), Jeju,
    Korea, 18–20 October 2017; pp. 129–131. [Google Scholar] [CrossRef] Shin, J.;
    Chang, Y.K.; Heung, B.; Nguyen-Quang, T.; Price, G.W.; Al-Mallahi, A. Effect of
    directional augmentation using supervised machine learning technologies: A case
    study of strawberry powdery mildew detection. Biosyst. Eng. 2020, 194, 49–60.
    [Google Scholar] [CrossRef] De Lange, E.S.; Nansen, C. Early detection of arthropod-induced
    stress in strawberry using innovative remote sensing technology. In Proceedings
    of the GeoVet 2019. Novel Spatio-Temporal Approaches in the Era of Big Data, Davis,
    CA, USA, 8–10 October 2019. [Google Scholar] [CrossRef] Liu, Q.; Sun, K.; Zhao,
    N.; Yang, J.; Zhang, Y.; Ma, C.; Pan, L.; Tu, K. Information fusion of hyperspectral
    imaging and electronic nose for evaluation of fungal contamination in strawberries
    during decay. Postharvest Biol. Technol. 2019, 153, 152–160. [Google Scholar]
    [CrossRef] Cockerton, H.M.; Li, B.; Vickerstaff, R.; Eyre, C.A.; Sargent, D.J.;
    Armitage, A.D.; Marina-Montes, C.; Garcia, A.; Passey, A.J.; Simpson, D.W. Image-based
    Phenotyping and Disease Screening of Multiple Populations for resistance to Verticillium
    dahliae in cultivated strawberry Fragaria x ananassa. bioRxiv 2018, 497107. [Google
    Scholar] [CrossRef] [Green Version] Altıparmak, H.; Al Shahadat, M.; Kiani, E.;
    Dimililer, K. Fuzzy classification for strawberry diseases-infection using machine
    vision and soft-computing techniques. In Proceedings of the Tenth International
    Conference on Machine Vision (ICMV 2017), Vienna, Austria, 13–15 November 2017;
    p. 106961N. [Google Scholar] [CrossRef] Hecht-Nielsen, R. Theory of the backpropagation
    neural network. In Proceedings of the International 1989 Joint Conference on Neural
    Networks, Washington, DC, USA, 1989; Volume 1, pp. 593–605. [Google Scholar] [CrossRef]
    Siedliska, A.; Baranowski, P.; Zubik, M.; Mazurek, W.; Sosnowska, B. Detection
    of fungal infections in strawberry fruit by VNIR/SWIR hyperspectral imaging. Postharvest
    Biol. Technol. 2018, 139, 115–126. [Google Scholar] [CrossRef] Thompson, B. Stepwise
    Regression and Stepwise Discriminant Analysis Need Not Apply Here: A Guidelines;
    Sage Publications: Thousand Oaks, CA, USA, 1995. [Google Scholar] Lu, J.; Ehsani,
    R.; Shi, Y.; Abdulridha, J.; de Castro, A.I.; Xu, Y. Field detection of anthracnose
    crown rot in strawberry using spectroscopy technology. Comput. Electron. Agric.
    2017, 135, 289–299. [Google Scholar] [CrossRef] Abdel Wahab, H.; Aboelghar, M.;
    Ali, A.; Yones, M. Spectral and molecular studies on gray mold in strawberry.
    Asian J. Plant Pathol. 2017, 11, 167–173. [Google Scholar] [CrossRef] Yuhas, R.H.;
    Goetz, A.F.H.; Boardman, J.W. Discrimination among semi-arid landscape endmembers
    using the Spectral AngleMapper (SAM) algorithm. In Summaries of the Third Annual
    JPL Airborne Geoscience Workshop; AVIRIS Workshop: Pasadena, CA, USA, 1992; pp.
    147–149. [Google Scholar] Levine, M.F. Self-developed QWL measures. J. Occup.
    Behav. 1983, 4, 35–46. [Google Scholar] Yeh, Y.-H.; Chung, W.-C.; Liao, J.-Y.;
    Chung, C.-L.; Kuo, Y.-F.; Lin, T.-T. Strawberry foliar anthracnose assessment
    by hyperspectral imaging. Comput. Electron. Agric. 2016, 122, 1–9. [Google Scholar]
    [CrossRef] Yeh, Y.-H.F.; Chung, W.-C.; Liao, J.-Y.; Chung, C.-L.; Kuo, Y.-F.;
    Lin, T.-T. A comparison of machine learning methods on hyperspectral plant disease
    assessments. IFAC Proc. Vol. 2013, 46, 361–365. [Google Scholar] [CrossRef] [Green
    Version] Jiang, Y.; Li, C.; Takeda, F.; Kramer, E.A.; Ashrafi, H.; Hunter, J.
    3D point cloud data to quantitatively characterize size and shape of shrub crops.
    Hortic. Res. 2019, 6, 1–17. [Google Scholar] [CrossRef] [PubMed] [Green Version]
    Paul, S.; Poliyapram, V.; İmamoğlu, N.; Uto, K.; Nakamura, R.; Kumar, D.N. Canopy
    Averaged Chlorophyll Content Prediction of Pear Trees Using Convolutional Autoencoder
    on Hyperspectral Data. IEEE J. Sel. Top. Appl. Earth Obs. Remote. Sens. 2020,
    13, 1426–1437. [Google Scholar] [CrossRef] Li, D.; Li, C.; Yao, Y.; Li, M.; Liu,
    L. Modern imaging techniques in plant nutrition analysis: A review. Comput. Electron.
    Agric. 2020, 174, 105459. [Google Scholar] [CrossRef] Lu, X.; Liu, Z.; Zhao, F.;
    Tang, J. Comparison of total emitted solar-induced chlorophyll fluorescence (SIF)
    and top-of-canopy (TOC) SIF in estimating photosynthesis. Remote. Sens. Environ.
    2020, 251, 112083. [Google Scholar] [CrossRef] Dechant, B.; Ryu, Y.; Badgley,
    G.; Zeng, Y.; Berry, J.A.; Zhang, Y.; Goulas, Y.; Li, Z.; Zhang, Q.; Kang, M.;
    et al. Canopy structure explains the relationship between photosynthesis and sun-induced
    chlorophyll fluorescence in crops. Remote. Sens. Environ. 2020, 241, 111733. [Google
    Scholar] [CrossRef] [Green Version] Publisher’s Note: MDPI stays neutral with
    regard to jurisdictional claims in published maps and institutional affiliations.  ©
    2021 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open
    access article distributed under the terms and conditions of the Creative Commons
    Attribution (CC BY) license (http://creativecommons.org/licenses/by/4.0/). Share
    and Cite MDPI and ACS Style Zheng, C.; Abd-Elrahman, A.; Whitaker, V. Remote Sensing
    and Machine Learning in Crop Phenotyping and Management, with an Emphasis on Applications
    in Strawberry Farming. Remote Sens. 2021, 13, 531. https://doi.org/10.3390/rs13030531
    AMA Style Zheng C, Abd-Elrahman A, Whitaker V. Remote Sensing and Machine Learning
    in Crop Phenotyping and Management, with an Emphasis on Applications in Strawberry
    Farming. Remote Sensing. 2021; 13(3):531. https://doi.org/10.3390/rs13030531 Chicago/Turabian
    Style Zheng, Caiwang, Amr Abd-Elrahman, and Vance Whitaker. 2021. "Remote Sensing
    and Machine Learning in Crop Phenotyping and Management, with an Emphasis on Applications
    in Strawberry Farming" Remote Sensing 13, no. 3: 531. https://doi.org/10.3390/rs13030531
    Note that from the first issue of 2016, this journal uses article numbers instead
    of page numbers. See further details here. Article Metrics Citations Crossref   36
    ads   10 Web of Science   31 Scopus   44 Google Scholar   [click to view] Article
    Access Statistics Article access statistics Article Views 8. Jan 18. Jan 28. Jan
    7. Feb 17. Feb 27. Feb 8. Mar 18. Mar 28. Mar 0k 2.5k 5k 7.5k 10k 12.5k For more
    information on the journal statistics, click here. Multiple requests from the
    same IP address are counted as one view.   Remote Sens., EISSN 2072-4292, Published
    by MDPI RSS Content Alert Further Information Article Processing Charges Pay an
    Invoice Open Access Policy Contact MDPI Jobs at MDPI Guidelines For Authors For
    Reviewers For Editors For Librarians For Publishers For Societies For Conference
    Organizers MDPI Initiatives Sciforum MDPI Books Preprints.org Scilit SciProfiles
    Encyclopedia JAMS Proceedings Series Follow MDPI LinkedIn Facebook Twitter Subscribe
    to receive issue release notifications and newsletters from MDPI journals Select
    options Subscribe © 1996-2024 MDPI (Basel, Switzerland) unless otherwise stated
    Disclaimer Terms and Conditions Privacy Policy'
  inline_citation: '>'
  journal: Remote sensing (Basel)
  limitations: '>'
  pdf_link: null
  publication_year: 2021
  relevance_score1: 0
  relevance_score2: 0
  title: Remote Sensing and Machine Learning in Crop Phenotyping and Management, with
    an Emphasis on Applications in Strawberry Farming
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.55730/1300-011x.3033
  analysis: '>'
  authors:
  - Jing Nie
  - Yi Wang
  - Li Yang
  - Xuewei Chao
  citation_count: 27
  full_citation: '>'
  full_text: '>

    We use cookies to help provide and enhance our service and tailor content. By
    closing this message, you agree to the use of cookies. Close Home About FAQ My
    Account     Home > Turkish Journal of Agriculture and Forestry > Vol. 46 (2022)
    > No. 5 Turkish Journal of Agriculture and Forestry Artificial intelligence and
    digital twins in sustainable agriculture and forestry: a survey Authors JING NIE
    YI WANG YANG LI XUEWEI CHAO DOI 10.55730/1300-011X.3033 Abstract Affected by global
    economic pressure and epidemics, sustainable agriculture has received widespread
    attention from farmers and agricultural engineers. Throughout history, agricultural
    technology has closely followed the pace of scientific and technological development
    and has followed the footsteps of mechanization, automation, and intelligence
    to progress continuously. At this stage, artificial intelligence (AI) is dominating
    the field of agriculture and advancing the progress of sustainable agriculture.
    However, the large amount of data required by AI technology and the high cost
    of data have ensued, while the rapid development of virtualization technology
    has made people gradually begin to consider the application of digital twins (DT)
    in agriculture. This paper examines the application of artificial intelligence
    technology and digital twin technology in smart agriculture in recent years and
    discusses and analyzes the challenges they face and the future directions of development.
    We find that digital twins have great potential for success in sustainable agriculture,
    which is of great significance to advancing smart agricultural solutions that
    achieve low cost and high precision to meet the growing demand for high-yield
    production from farmers around the world. Keywords Smart agriculture, artificial
    intelligence, digital twins, sustainable agriculture First Page 642 Last Page
    661 Recommended Citation NIE, JING; WANG, YI; LI, YANG; and CHAO, XUEWEI (2022)
    "Artificial intelligence and digital twins in sustainable agriculture and forestry:
    a survey," Turkish Journal of Agriculture and Forestry: Vol. 46: No. 5, Article
    5. https://doi.org/10.55730/1300-011X.3033 Available at: https://journals.tubitak.gov.tr/agriculture/vol46/iss5/5
    Download 1,427 DOWNLOADS Since October 03, 2022 PLUMX METRICS INCLUDED IN Agriculture
    Commons, Forest Sciences Commons SHARE Facebook LinkedIn WhatsApp Email Share   Journal
    Home About This Journal Aims & Scope Open Access Statement Peer Review Editorial
    Board Information For Authors Abstracting and Indexing Publishing Policy & Ethics
    Contact Submit Article Manuscript Template Most Popular Papers Receive Email Notices
    or RSS Select an issue:         All Issues            Vol. 48, No. 1            Vol.
    47, No. 6            Vol. 47, No. 5            Vol. 47, No. 4            Vol.
    47, No. 3            Vol. 47, No. 2            Vol. 47, No. 1            Vol.
    46, No. 6            Vol. 46, No. 5            Vol. 46, No. 4            Vol.
    46, No. 3            Vol. 46, No. 2            Vol. 46, No. 1            Vol.
    45, No. 6            Vol. 45, No. 5            Vol. 45, No. 4            Vol.
    45, No. 3            Vol. 45, No. 2            Vol. 45, No. 1            Vol.
    44, No. 6            Vol. 44, No. 5            Vol. 44, No. 4            Vol.
    44, No. 3            Vol. 44, No. 2            Vol. 44, No. 1            Vol.
    43, No. 6            Vol. 43, No. 5            Vol. 43, No. 4            Vol.
    43, No. 3            Vol. 43, No. 2            Vol. 43, No. 1            Vol.
    42, No. 6            Vol. 42, No. 5            Vol. 42, No. 4            Vol.
    42, No. 3            Vol. 42, No. 2            Vol. 42, No. 1            Vol.
    41, No. 6            Vol. 41, No. 5            Vol. 41, No. 4            Vol.
    41, No. 3            Vol. 41, No. 2            Vol. 41, No. 1            Vol.
    40, No. 6            Vol. 40, No. 5            Vol. 40, No. 4            Vol.
    40, No. 3            Vol. 40, No. 2            Vol. 40, No. 1            Vol.
    39, No. 6            Vol. 39, No. 5            Vol. 39, No. 4            Vol.
    39, No. 3            Vol. 39, No. 2            Vol. 39, No. 1            Vol.
    38, No. 6            Vol. 38, No. 5            Vol. 38, No. 4            Vol.
    38, No. 3            Vol. 38, No. 2            Vol. 38, No. 1            Vol.
    37, No. 6            Vol. 37, No. 5            Vol. 37, No. 4            Vol.
    37, No. 3            Vol. 37, No. 2            Vol. 37, No. 1            Vol.
    36, No. 6            Vol. 36, No. 5            Vol. 36, No. 4            Vol.
    36, No. 3            Vol. 36, No. 2            Vol. 36, No. 1            Vol.
    35, No. 6            Vol. 35, No. 5            Vol. 35, No. 4            Vol.
    35, No. 3            Vol. 35, No. 2            Vol. 35, No. 1            Vol.
    34, No. 6            Vol. 34, No. 5            Vol. 34, No. 4            Vol.
    34, No. 3            Vol. 34, No. 2            Vol. 34, No. 1            Vol.
    33, No. 6            Vol. 33, No. 5            Vol. 33, No. 4            Vol.
    33, No. 3            Vol. 33, No. 2            Vol. 33, No. 1            Vol.
    32, No. 6            Vol. 32, No. 5            Vol. 32, No. 4            Vol.
    32, No. 3            Vol. 32, No. 2            Vol. 32, No. 1            Vol.
    31, No. 6            Vol. 31, No. 5            Vol. 31, No. 4            Vol.
    31, No. 3            Vol. 31, No. 2            Vol. 31, No. 1            Vol.
    30, No. 6            Vol. 30, No. 5            Vol. 30, No. 4            Vol.
    30, No. 3            Vol. 30, No. 2            Vol. 30, No. 1            Vol.
    29, No. 6            Vol. 29, No. 5            Vol. 29, No. 4            Vol.
    29, No. 3            Vol. 29, No. 2            Vol. 29, No. 1            Vol.
    28, No. 6            Vol. 28, No. 5            Vol. 28, No. 4            Vol.
    28, No. 3            Vol. 28, No. 2            Vol. 28, No. 1            Vol.
    27, No. 6            Vol. 27, No. 5            Vol. 27, No. 4            Vol.
    27, No. 3            Vol. 27, No. 2            Vol. 27, No. 1            Vol.
    26, No. 6            Vol. 26, No. 5            Vol. 26, No. 4            Vol.
    26, No. 3            Vol. 26, No. 2            Vol. 26, No. 1            Vol.
    25, No. 6            Vol. 25, No. 5            Vol. 25, No. 4            Vol.
    25, No. 3            Vol. 25, No. 2            Vol. 25, No. 1            Vol.
    24, No. 6            Vol. 24, No. 5            Vol. 24, No. 4            Vol.
    24, No. 3            Vol. 24, No. 2            Vol. 24, No. 1            Vol.
    23, No. EK5            Vol. 23, No. EK4            Vol. 23, No. EK3            Vol.
    23, No. EK2            Vol. 23, No. EK1            Vol. 23, No. 6            Vol.
    23, No. 5            Vol. 23, No. 4            Vol. 23, No. 3            Vol.
    23, No. 2            Vol. 23, No. 1            Vol. 22, No. 6            Vol.
    22, No. 5            Vol. 22, No. 4            Vol. 22, No. 3            Vol.
    22, No. 2            Vol. 22, No. 1            Vol. 21, No. 6            Vol.
    21, No. 5            Vol. 21, No. 4            Vol. 21, No. 3            Vol.
    21, No. 2            Vol. 21, No. 1            Vol. 20, No. 6            Vol.
    20, No. 5            Vol. 20, No. 4            Vol. 20, No. 3            Vol.
    20, No. 2            Vol. 20, No. 1          Issues by Year Search Enter search
    terms:       in this journal      in this repository      across all repositories      Advanced
    Search ISSN: 1300-011X EISSN: 1303-6173   Home | About | FAQ | My Account | Accessibility
    Statement Privacy Copyright'
  inline_citation: '>'
  journal: 'Turkish journal of agriculture and forestry : (Ankara)'
  limitations: '>'
  pdf_link: https://journals.tubitak.gov.tr/cgi/viewcontent.cgi?article=3033&context=agriculture
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: 'Artificial intelligence and digital twins in sustainable agriculture and
    forestry: a survey'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1007/s11831-022-09746-3
  analysis: '>'
  authors:
  - Mandeep Kaur Saggi
  - Sushma Jain
  citation_count: 16
  full_citation: '>'
  full_text: '>

    Your privacy, your choice We use essential cookies to make sure the site can function.
    We also use optional cookies for advertising, personalisation of content, usage
    analysis, and social media. By accepting optional cookies, you consent to the
    processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Log in Find a journal
    Publish with us Track your research Search Cart Home Archives of Computational
    Methods in Engineering Article A Survey Towards Decision Support System on Smart
    Irrigation Scheduling Using Machine Learning approaches Survey article Published:
    09 May 2022 Volume 29, pages 4455–4478, (2022) Cite this article Download PDF
    Archives of Computational Methods in Engineering Aims and scope Submit manuscript
    Mandeep Kaur Saggi & Sushma Jain  5779 Accesses 16 Citations Explore all metrics
    Abstract From last decade, Big data analytics and machine learning is a hotspot
    research area in the domain of agriculture. Agriculture analytics is a data intensive
    multidisciplinary problem. Big data analytics becomes a key technology to perform
    analysis of voluminous data. Irrigation water management is a challenging task
    for sustainable agriculture. It depends on various parameters related to climate,
    soil and weather conditions. For accurate estimation of requirement of water for
    a crop a strong modeling is required. This paper aims to review the application
    of big data based decision support system framework for sustainable water irrigation
    management using intelligent learning approaches. We examined how such developments
    can be leveraged to design and implement the next generation of data, models,
    analytics and decision support tools for agriculture irrigation water system.
    Moreover, water irrigation management need to rapidly adapt state-of-the-art using
    big data technologies and ICT information technologies with the focus of developing
    application based on analytical modeling approach. This study introduces the area
    of research, including a irrigation water management in smart agriculture, the
    crop water model requirement, and the methods of irrigation scheduling, decision
    support system, and research motivation. Similar content being viewed by others
    Water quality prediction using machine learning models based on grid search method
    Article Open access 29 September 2023 Can machine learning models provide accurate
    fertilizer recommendations? Article Open access 25 March 2024 Enhancing crop recommendation
    systems with explainable artificial intelligence: a study on agricultural decision-making
    Article Open access 11 January 2024 1 Introduction WATER-Every drop is precious,
    save it. Water is the main limiting factor of agricultural development in semi-arid
    and arid climates. It is a critical input for enhancing agricultural productivity.
    Arthur Keith said that the advancement of agriculture is the first major step
    for civilized life [1]. Even after six decades of planned development, agriculture
    has played an important role in the Indian economy. However, the agriculture sector
    of India has been transformed via the effective deployment of Information and
    Communication Technologies (ICTs) in traditional to modern practices which provide
    various services (such as- IoT agriculture, smart water management, soil management,
    plant diseases, crop management, geo-spatial image and livestock monitoring).
    In India, the demand of water for the agriculture and industry sectors is continuously
    increasing to fulfill the needs of 1.366 billion people. Central Indian Punjab
    is well-known for its agricultural activities and has occupied a high percentage
    of the land area all over India, and its agricultural production mainly depends
    on irrigation. Punjab has 97.95% highest gross irrigation of the total cropped
    area [2]. Recently, the achievement of the Green Revolution is endangered by a
    significant decline in water resources. As a result, water conservation and precision
    agriculture are becoming vital issues in tropical climate areas. Wheat and Maize
    are the most commonly cultivated crops and have high water consumption in Punjab,
    India. The major challenge in agriculture sustainability and dawdling is due to
    climate change; therefore, every drop of freshwater needs to be utilize effectively
    and efficiently. To overcome these challenges, the multivariate, complex, and
    unpredictable agricultural ecosystems must be well understood by continuously
    analyzing, measuring, and monitoring several physical aspects and phenomena [3].
    New technologies and knowledge can help in this complex decision-making. The fundamental
    idea is that the DSS should serve as a farm management tool, supporting farm managers
    in making decisions on irrigation, whether to irrigate and, if so, which field
    with how much water. Wani et al. [4] presented a thorough investigation to evaluate
    the possibility of using Machine Learning models to identify plant diseases. In
    the early twentieth century, irrigation is the most crucial practice no doubt
    and needs effective utilization. Farmers required to predict the need of water
    for the crops, to confirm the data provided by agricultural weather stations or
    to get insight the free water surface evaporation in lakes or dams. Agricultural
    irrigation scheduling is becoming a very important managerial activity whose ultimate
    purpose is to achieve effective and efficient utilization of water. The primary
    objective of good irrigation scheduling is to apply the right amount of water
    at right time. Irrigation scheduling improves the water use efficiency and focus
    on evapotranspiration (ET) estimation methods for understanding of spatial variations
    of ET. It determine irrigation applications such as identifying the water balance
    component, integrated various sensing technologies into irrigation scheduling
    models and control, new improved sensor technology and integrated water quality
    constraints into irrigation scheduling and control [5]. Figure 1 presents the
    six identified relevant works, indicating the smart water management related research
    work such as crop water modeling, soil monitoring, water quality, drones field
    monitoring, weather forecasting, and irrigation scheduling. Fig. 1 Smart water
    management in smart agriculture Full size image The ultimate irrigation potential
    of India has been estimated to be 139.5 million ha, comprising 58.5 million ha
    from major and medium schemes, 15 million ha from minor irrigation schemes, 66
    million ha from groundwater exploitation, and an estimated 77 million ha beyond
    2025 from freshwater use for irrigation [6]. It is approximated that after gaining
    the full potential of the irrigation, nearly 50% of the total cultivated area
    will hold out rain-fed. Irrigation is the most important factor for escalating
    the agricultural production of plants. It is essential to determine the quantity
    of water to get the optimal benefits from the irrigation, which depends on some
    factors such as the environment, type of crop, subsurface geo-hydrological condition,
    and the stage of its growth. The questions arise in the irrigation scheduling
    are as follows: (i) How to apply irrigation water?, (ii) How much to irrigate?,
    (iii) When to irrigate. Currently, irrigation decision-making systems are enforced
    to the agricultural field aiming for specific crop at a given area [7]. It is
    difficult to be practiced to different crops and areas. Under the growing environment,
    the amount of irrigation is defined as the depth of water required to meet the
    crop water loss through evapotranspiration. It can be obtained via prediction
    using indirect channels or field measurement techniques. However, the amount and
    timing of water have major impact on quality of crop and its yield. Several methods
    are applied for the irrigation scheduling such as pan evaporation, soil moisture
    basis, leaf water potential, and based on growth-stages. The demand of water can
    be fulfill by full or partial irrigation in all methods. 1.1 Motivation As technology
    rapidly spread in a few decades, precision agriculture is the key to fostering
    a new revolution in Irrigation scheduling. The United Nations statistical data
    indicate that agriculture consumes 70% of the overall use of water worldwide,
    compared with 20% for industry and 10% for domestic use [8]. To ensure the proper
    use of water supplies in irrigation we need more effective technologies. Automatic
    irrigation scheduling techniques replaced manual irrigation which was based upon
    crop water estimation. The crop evapotranspiration can be determined by weather
    parameters such as max–min temperature, humidity, wind speed, solar radiations,
    and even the crop factors such as the stage of growth, crop height, and the soil
    properties for the development of irrigation scheduling. The machine learning
    and deep learning advanced technologies provide direction and motivation to propose
    a novel application on crop water modeling. The influence of several factors on
    crop yields and temperature, precipitation have been found to have maximum influence
    on the yields of different crops [9]. 2 Reference Evapotranspiration ET “Evapotranspiration
    contains two processes, evaporation in which water is lost from the soil and plant
    surface, and transpiration from plant surfaces to the atmosphere” [10]. The water
    irrigation is enforced to match the needs of evapotranspiration of crop. Therefore,
    the irrigation scheduling needs to estimate the daily crop evapotranspiration
    accurately. Evapotranspiration of crops differs significantly over the growing
    season mainly due to alterations in climatic conditions and crop cover. It also
    varies among the crops. The information about crop water demand (i.e., ET) is
    a crucial practical consideration in the planning, developing, and working of
    water and irrigation management systems. Figure 2 presented the concept of ET
    . Table 1 presented the ET that affecting by weather element. The reference evapotranspiration
    is approximated from meteorological data (humidity, temperature, wind run/wind
    speed, sunshine hours/solar radiation) by using the Penman-Monteith equation.
    However, the adjusted pan evaporation measurements are also used. Fig. 2 Reference
    evapotranspiration (ET ) process Full size image 2.1 Factors Affecting ET Climate
    and weather play crucial role in determining long-term and day-to-day activities
    in the agriculture. The demand of crop water is determined largely by weather
    variables. Rainfall is the foremost weather variable that affects the water resources
    development planning, irrigation planning and agricultural cropping. The main
    climatic/weather components crucial for agriculture are rainfall, maximum/minimum
    temperature, solar radiation, sunshine duration, humidity, photo-period or sunshine
    hour, wind speed, and night temperature [11] as depicted in Fig. 3. Table 2 shows
    the different empirical methods with weather parameters for estimation of ET .
    Weather elements controls the crop water demand and crop ET. The ET depends upon
    the different weather elements such as humidity, temperature, sunshine hour, solar
    radiation, wind speed, etc. It is also affected by rainfall. The weather elements
    affect ET as follows: Table 1 Weather affecting parameters Full size table Fig.
    3 Factors affecting evapotranspiration Full size image 2.2 FAO ET Estimation Method
    There are various mathematical models used to calculate the reference evapotranspiration
    (ET ). The updated procedures for calculating the ET were introduced by FAO. The
    Food and Agriculture Organization (FAO) recommends the method for calculating
    the ET are as follows: Although, the method FAO-56 Penman–Monteith (Allen et al.
    1998) [10] is the most dominant as compared to others empirical methods [20, 21].
    But, it requires several climatic data factors [22]. The FAO-56 Penman-Monteith
    (FAO-PM56) [10] has been broadly used to analyze ET from meteorological factors
    and it is suggested as the standard technique by the Food and Agriculture Organization
    of the United Nations (FAO) [23] and calculated by Eq. (1). (1) where, ET is the
    reference evapotranspiration ;  = slope of saturation vapor pressure function
    (kPa °C ); R = net radiation (MJ ); = psychometric constant (kPa °C−1); G = soil
    heat flux density (MJ ); W = average 24-h wind speed at 2 m height ; T = mean
    air temperature (°C); e = actual vapour pressure(kPa); e = saturation vapour pressure(kPa);
    and (e ) = vapour pressure deficit (kPa). However, ET can be determined accurately
    by this method, large scale meteorological data requirement at specific spatio-temporal
    scales (vapor pressure deficit, wind speed, minimum and maximum air temperatures,
    and solar radiation) are quite often not available in many developing countries
    [24]. Thus, the alternate models are needed to estimate ET when the available
    data are either insufficient or limited. So, it is important to explore a simpler
    model to calculate ET using fewer weather properties and a reasonable precision.
    The need of crop water depends on some factors: crop growth/stages, crop type
    and the climate are given in detail [25]: Table 2 ET estimation empirical methods
    Full size table 3 Crop Evapotranspiration ET “The crop evapotranspiration denoted
    as ET ,is the crop water requirements or crop water need.” Fig. 4 Various crop-growth
    developement stages Full size image The need for crop water is the depth (or quantify
    of water required to cope with the loss of water through evapotranspiration. In
    other words, water needs to be cultivated optimally by different crops. Crop-growth
    models were developed to improve the understanding of crop dynamics and to predict
    crop growth and production under various agronomic conditions [35]. The continuous
    monitoring of the soil status water, the conditions of crop growth, and its spatial
    and temporal patterns will help in irrigation and precision water planning. Evaporation
    and transpiration variations in the field and grass crops can be integrated into
    dual crop coefficient or single crop coefficient (K ): a soil evaporation coefficient
    (K ) and a basal crop (K ) and calculated by Eq. (2). (2) 3.1 Climate Based ET
    The combination of two different processes by which water evaporates from the
    soil surface and transpiration from the plant is referred as evapotranspiration.
    It is determined by climatic factors including solar radiation, temperature, wind,
    and humidity as well as environmental factors. The evaporation account for approximately
    10% of the overall evapotranspiration and the transpiration of crops constitutes
    the remaining 90%. Hence, there is a need for crop water in hot, dry, windy, and
    sunny areas. For the lowest values when the wind is cold, humid, and cloudy, with
    little to no wind. Climate impact on crop water requirements is determined by
    reference crop evapotranspiration ET and generally expressed per unit of time
    in millimeters., e.g. mm/day, mm/month, or mm/season. 3.1.1 Crop Type The effect
    of the crop type in daily crop water requirements is often referred to as a fully
    grown crop; Plant height has reached maximum; Plants cover the ground optimally;
    probably they began to flowering or developing to set grain; The water demand
    is greatest when the crop is fully cultivated. Their water needs are called the
    “peak period”. The type of crop that has also affected the total growing duration
    of crop development is known by seasonal crop water need and can be obtained.
    The best possible local data can be obtained on the duration of the total seasons
    of the various plants cultivated in a region. Such data can be collected from,
    for example, the seed supplier, the Extension Service, the Irrigation Department,
    or the Ministry of Agriculture. Fig. 5 Irrigation methods Full size image 3.1.2
    Growth Stages of the Crop While planting and in the initial stage, evaporation
    is more essential than transpiration. When the crop is fully developed, the need
    for crop water is estimated to be 50% during the mid-season phase. At the stage
    of development, the crop demand moderately increases from 50% of the maximum crop
    water requirement to the maximum crop water. Thus, the maximum amount of crop
    water is extended to the end of crop development stage, which is the starting
    of mid-season stage. The value of K depends on different factors such as canopy
    cover density, agriculture operations, weather variable, type of crop, soil moisture,
    and growth stage [10]. The idea of crop coefficient K is proposed by Jensen [36]
    and has been improved by many researchers [37, 38]. However, K method has the
    capability to determine the actual crop evapotranspiration ET precisely. According
    to the FAO methodology, the four growing stages of a crop are the initial stage,
    crop development stage, mid-season stage, and end-season stage (Allen et al. 1998)
    [10]. The crop coefficient method can be expressed as follows: The two-step crop
    coefficient K reference evapotranspiration has been a successful method to predict
    the evapotranspiration (ET) and crop water requirements. The total growing period
    is divided into 4 growth stages shown in Fig. 4 [39]: The initial stage the period
    ranges from transplanting or sowing till crop covers the 10% of ground. The crop
    development stage the period begins at the completion of the initial stage and
    remains until the full ground has been covered (ground cover 70–80%). It does
    not certainly mean that the crop is at its maximum height. The mid-season stage
    the period begins at the completion of the crop development stage and remains
    till maturity; it consists grain-setting and flowering. The late-season stage
    the period starts at the completion of mid-season stage and remains until the
    last day of the harvest; it consists ripening. (3) where ET represents the requirement
    of crop water (mm d ), ET the reference crop water requirement (mm d ), and K
    the crop coefficient and calculated by Eq. (3). Besides, Kingra et al. (2004)
    computed crop water requirement for Wheat and transplanted Rice at Ludhiana, reported
    that the Wheat crop used about 315 mm water whereas the rice crop used about 780
    mm water during its growing season [40]. Saggi et al. [41] collected the K values
    as case study from Punjab agricultural University (PAU), Ludhiana and estimated
    the ET for two crops. The K values of Wheat crop were 0.4, 1.15 & 0.4 while for
    Wheat were 0.5, 1.36, 1.42, and 0.42 for the initial, mid and last stage of growth
    respectively. The length of time (days) for four seasons of Wheat were 29, 55,
    14 32 days while for Wheat 24, 46, 35, 42 days. The K values of Maize crop were
    0.7, 0.85, 1.15 & 1.05 for the initial, mid, and end-stage of growth respectively.
    The length of time (days) for four seasons of Maize were 35, 18, 17, and 15 days
    used in different stages. Detail of selected crops and period of data for the
    study. 4 Irrigation Scheduling In 1996, Howell explored the effects on water use
    and irrigation scheduling [42]. It is an application mechanism that can lead to
    the effective and efficient use of water. This efficiency can be enhanced by using
    advanced methods of irrigation. However, even in advanced irrigation methods,
    irrigation scheduling at the farm level is required. It is necessary when rainfall
    is deficient to remunerate for the water lost by evapotranspiration. The irrigation
    water need is described as the crop water requirement minus the fruitful rainfall.
    It is defined in mm/month or mm/day. The main goal of good irrigation scheduling
    is to apply the correct amount of water at the right time, and make sure that
    water is accessible when the crop requires it. According to predetermined schedules,
    the irrigation water is supplied to the cultivation by keep track of the following
    [43]: The status of soil water; The need of crop water. Fig. 6 Types of irrigation
    scheduling Full size image The purpose of our research work is to present, analyze,
    and optimize some measure of performance of the crop production under a set of
    specified conditions, such as the limited or unlimited total volume of water for
    the growing season. The main factors that influence the solution and implementation
    of the irrigation scheduling problem are the characteristics of climate soil,
    crop, irrigation water, and irrigation technology. Judicious usage of water for
    crop production needs knowledge of water quality, soil, weather, crop, and drainage
    situation. The increase in efficiency of pumping systems and conveyance need to
    review. The soil types and climatic conditions have a considerable effect on the
    major practical aspects of irrigation such as how much amount of water should
    be supplied and when to a selected crop. A time-consuming and complex process
    is a precise estimation of the irrigation schedule [25]. However, the advent of
    advanced technology has made it simpler and the water supply can be scheduled
    precisely to meet the water requirements of cultivation. The timing for irrigation
    applications can be fixed dates or on flexible dates. The quantity should not
    exceed the crop requirements per application, including the leaching of salts;
    otherwise, any excess water would not only reduce the efficiency of its usage
    but can hinder the crop development. Standard irrigation schedule performance
    metrics are crop yields and net benefits per unit area. The optimal irrigation
    schedule is any schedule that optimizes the adopted output measurement while meeting
    several defined constraints. Any schedule that optimizes the adopted measure of
    performance while satisfying some specified constraints is the optimal irrigation
    schedule. 4.1 Methods of Irrigation Scheduling Different techniques can be apply
    to the plants with irrigation water and each approach has its benefits and limitations.
    In this context, the best approach to accommodate local conditions should be taken
    into account. Earlier, the primary irrigation method is applied via the source
    of supply such as a bucket watering or a well. Although, it is a time-consuming
    method. More advanced water application methods are used in larger areas where
    irrigation is needed. The suitability of several irrigation methods, i.e. sprinkler,
    surface, or drip irrigation, depends on the following aspects: Natural conditions,
    type of crop, type of technology, previous experience with irrigation, required
    labor inputs and costs and benefits. Surface irrigation may be categorized based
    on mode of water application as depicted in Fig. 5. [44] and Fig. 6 shown the
    different types of irrigation methods. Table 3 presented the different types of
    irrigation methods, advantages and their applications. 4.1.1 Border Irrigation
    Surface irrigation is where the water is applied to the surface of field by gravity
    flow. The water is applied into small channels (furrows) or complete surface is
    flooded with water (basin irrigation) or strips of land (borders). Border irrigation
    is a modern method of surface irrigation. Borders are uniformly graded strips
    of land and long, set apart by earth bunds. They are also known as border strips.
    There are several ways to fed the irrigation water to the border such as by using
    small gates, launching the channel bank, using spiles or siphons. A sheet of water
    is guided by the earth bunds and flows down the slope of the border. It is mostly
    suited to generate long uninterrupted field lengths for facility of machine operations
    in the huge mechanized farms. Borders can be up to 3-30m wide and at least 800m
    in length depend on several factors. It is less applicable to farms on small-scale
    consisting animal-powered cultivation techniques or hand labor. 4.1.2 Sprinkler
    Irrigation It is equivalent to natural rainfall, where water is pumped using a
    pipe system and then rotating sprinkler heads used to spray onto the crops. Further,
    the spray is applied into the air via sprinklers to breaks it into small drops
    of water that fall on the ground. The sprinklers, pump supply system, and operating
    conditions must be developed to apply the water uniformly. It is well suited for
    the most field, row, and tree crops. Water can be sprayed under or over the crop
    canopy. Although, large sprinklers are not suggested for delicate crops such as
    lettuce due to the large size water drops generated by the sprinklers can harm
    the crops. Table 3 Different types of irrigation systems Full size table 4.1.3
    Drip Irrigation It involves application of dripping water to the soil from a small
    diameter plastic pipe systems attached with outlets called emitters or drippers
    at very low rates (2–20 l/h). It is also called as trickle irrigation. Water is
    applied very close to plants so that only part of the soil in which the roots
    grow is wetted, instead of sprinkler and surface irrigation, which consists wetting
    the complete soil profile [25]. It is well suited for trees, vine crops and row
    crops (vegetables, soft fruit), where one or more emitters can be given for each
    plant. It is considered for high-value crops only due to high capital costs required
    for installation of a drip system. 4.1.4 Need of Irrigation Scheduling Hydrological,
    climatologist, and agronomical processes play an significant part in the development
    of irrigation agriculture production. These studies were mainly developed to estimate
    daily, weekly, or monthly evapotranspiration. The precise approximation of evapotranspiration
    is an important process that plays a key role in crop planning, deployment and
    production of irrigation systems. In recent years, several approaches have been
    developed to overcome the problems and obstacles that occur with smart farming,
    such as species recognition, yield prediction, disease detection, drought, crop
    productivity problems and irrigation management. So, there is a great need to
    explore more research studies to enhance the scalability of irrigation scheduling
    based on advanced data analytic and machine learning. Some research has been done
    in the decision support system to improve the right decision on agriculture data.
    5 Decision Support System The idea of a decision support system (DSS) for irrigation
    water management is introduced in the 1970’s to assist users in complex decision-
    making processes and efficient use of irrigation water at the farm level [53].
    Decision support system (DSS) has great potential in agriculture era, if the water
    irrigation management research is combined with the modeling approach using machine
    learning analytics and agriculture statistical, the research level will be achieved
    in different levels of the agricultural development sector. The decision support
    system for crop water irrigation scheduling based on crop water model by estimation
    of evapotranspiration as weather parameter, historical dataset, and using of different
    Irrigation water management methods. The decision support system is an integrated
    approach to solve complex problems, combining the computer calculation and data
    storage capacities with human language and perception, support of mathematical
    model statistics, providing decision-maker. It is known as a primary tool in management
    for better decision making and environmental resources. In 1985, Guariso et al.
    firstly introduced the concept of DSS. Various researchers surveyed the advanced
    use of the management of DSS for water resources [54]. Today, it is required for
    the on-farm irrigation water management due to its use of the computer to relate
    soil, crop, and water quality conditions. It can be used for analyzing and determining
    how much water is needed and when it should give next time. 5.1 Statistics The
    statistical approach leads to the process of collection, presentation, analyze,
    and apply the data to make decisions, problems solving, design products, and processes.
    It is very useful for us to explore the description and understand the variability.
    Statistical methods contributed for making scientific judgments in the face of
    variation uncertainty. Russo et al. (2015) Bayesian method is used to estimate
    the hydrological properties and irrigation needs for an under-constrained mass
    balance model. They presented an approach Markov chain Montecarlo algorithm to
    solve for spreading of values for each unknown parameter in a conceptual mass
    balance model [55]. 5.2 Machine Learning From the last decade, machine learning
    and data analytics is a hot-spot research area in the domain of agriculture. Among
    the other definitions, machine learning is described as the scientific are that
    allows the machines to learn without being strictly programmed [56]. Machine learning
    models have demonstrated excellent results for crop-based modeling in recent days.
    There is a variety of machine learning models based on prediction for reference
    crop evapotranspiration. The main contribution of our research prediction, by
    applying machine-learning and data analytics based modeling to predict crop evapotranspiration.
    Fig. 7 Big data based machine learning framework for agriculture application Full
    size image Yamaç and Todorovic [57], revealed the satisfactory outputs of ML with
    R2 ranged from 0.81 to 0.97 [58] by applying several ML models on the climatic
    data. A comparative analysis was performed by Shiri et al. [59] to estimate the
    ET using various intelligent models, namely ANN, ANFIS, support vector machine
    (SVM), and GEP. In the domain of agriculture, big data analytic technologies have
    offered newly predictive models for ET estimation, e.g. generalized neuro-fuzzy
    models [60], artificial neural network (ANN), [61], adaptive neuro-fuzzy inference
    system [62], multi-layer Perceptrons neural network (MLPNN), Zaji and Bonakdari
    [63], extreme learning machine (ELM) Abdullah et al. [64], multivariate adaptive
    regression splines (MARS) and least square support vector regression (LSSVM) [65],
    GRNN (2016), ELM, WNN and GANN [66]. Moreover, the Auto-ML technique is found
    to show excellence in application of irrigation scheduling where border irrigation
    and sprinkler irrigation methods are deployed. 5.3 Deep Learning The deep learning
    technique is now practical to address millions or even billions of weights among
    neurons for better understanding of behaviors due to current advances in computational
    power, in terms of software, hardware and parallel processing. It is accepted
    to have established a revolutionary era since it can address the issues that have
    countered AI for a long time. Deep feed-forward neural networks are based on multi-layer
    Perceptrons (MLPs) published by Alexey Ivakhnenko and Lapa in 1965 [67]. It can
    be used to model the complicated relationship between input and output due of
    its high hierarchical structure model training, construction and feature learning
    [68]. It has been used in the hydrological and agricultural fields because of
    the difficulty of software data availability, costs, and complexity, e.g., approximation
    and modeling of crop evapotranspiration [42], Wang et al. (2018) determined that
    traditional ML and DL models are equivalent as a data-driven artificial intelligence
    method that can be used to model the complicated relationship between input and
    output [68]. However, DL has a benefit over traditional ML, due to wits high hierarchical
    structure model. 5.4 Big Data Analytics Big Data is a fascinating new field at
    the joint of advanced analytics, data science, statistics, and machine learning.
    Big data and analytics have tremendous development benefits in the agriculture
    economy. Advanced big data analytics have improved the tools and technologies
    that changed the way of real-time applications to make better decision processing,
    high-performance platform to efficiently analyze, capturing, storing and managing
    large scale of big data. In addition, agriculture practices are becoming increasingly
    data-derived and data-enabled with the recent development of 5G, artificial intelligence,
    Internet of Things and big data technologies [69]. To obtain insights from these
    data Saggi et al. [70] investigated the state-of-the-art framework for decision-making
    and different methods of integrating big data analytical methods with smart applications
    such as smart agriculture, healthcare, and cyber security. Figure 7 presented
    the framework of big data analytics and machine learning analytics for agriculture
    application as follows: Data sources The domain of data is expressed by variety
    of descriptive terms such as:-structured, unstructured, machine and sensor generated
    data, batch, and real-time processing data, biometric data, human-generated data,
    and business-generated data. Data storage and processing Database technology,
    Storage infrastructure, Distributed storage, Programming model and Data staging,
    collection, pre-processing and many tools for batch and streaming process. Data
    analytics and visualization It includes the machine learning, data mining, statistics,
    artificial neural network, natural language processing, and deep learning models
    for agriculture based applications such as DSS, forecasting weather, crop-soil
    and water monitoring and pesticides detection. Fig. 8 Number of publications,
    article types and publication title Full size image The objective of this study
    is to introduced the several advanced analytic techniques to develop a flexible
    system that would lead to better irrigation decisions (allocation, application,
    and optimization). This study is expected to provide a decision tool that will
    assist irrigators and water managers in determining reference evapotranspiration
    (ET ), crop water requirement (CWR), irrigation water requirement (IWR), and irrigation
    scheduling for more effective water allocation and application. 6 Literature of
    Irrigation Scheduling Agriculture is the world’s biggest water user, that consume
    70% of fresh water in average. However, these percentages will go as high as 95
    percent in few developed nations and Punjab is one of India’s largest contributors
    to the central grain pool. In India, ground-water (GW) is an essential source
    of water supply in agriculture and Rice-Wheat cropping system has resulted in
    significant increase in irrigation water need approximately 73% with GW in Punjab.
    India is a seventh largest subcontinent country by geographical area in South
    Asia, nowadays India ranks 2nd worldwide in farm production and 1st largest country
    in irrigated land area. Water conservation and precision agriculture is becoming
    a vital issue in the tropical climate areas. Central Indian Punjab is a well-known
    for its agriculture activities and occupied high percentage of land area in all
    over India. 6.1 A Bibliometric Perspective of Irrigation Scheduling In this section,
    the articles from Science direct digital database is considered. Figure 8 shows
    the number of papers published from 1995 to 2021 in field of irrigation scheduling,
    reference evapotranspiration and crop evapotranspiration. We have selected only
    elsevier science direct library to find out research articles, where we found
    34,083 results in area of irrigation scheduling, 32,775 papers in reference evapotranspiration
    and 14,261 results articles in crop evapotranspiration (crop water need). Irrigation
    scheduling, ET and ET trends are represented by Green, Blue, and Yellow colored
    lines respectively. Figure 8 shows the article type in which review reports, case
    reports, data articles, mini review, and many more articles. Figure 8 shows the
    number of top-journal publications. Several computer simulation techniques and
    decision support systems have been developed to estimate ET , ET and Crop Water
    Requirement (CWR). It is important to identify changes in the hydrological cycle
    when we want to predict the impacts of climate change. However, current studies
    on climate change must be expanded to cover the entire globe. The two main components
    of the global water cycle are evaporation and precipitation. Methods for measuring
    evapotranspiration from meteorological data include a number of climatology, and
    the physical inputs which is directly estimated in weather stations. Other parameters
    are associated with measured data and can be obtained by directly or empirical
    methods. Meteorological data can be expressed in several units. 6.2 Estimation
    and Forecasting of Evapotranspiration ET The application of Evapotranspiration
    (ET ) in irrigation scheduling is divided into different categories for literature
    section such as statistical, machine learning, evolutionary models, and decision
    support system [42, 71, 72]. We have presented a comprehensive review literature
    for reference evapotranspiration as follows: Fig. 9 Process of DSS for crop water
    irrigation scheduling Full size image Figure 9 presented the process of DSS for
    crop water irrigation scheduling. ET is an imperative aspect of the hydrological
    cycle that is stirring water availability on the earth surface. It is one of the
    significant criteria of accurate quantification of crop water requirement that
    influence various hydrological processes, planing of water management and resources
    [62], and requirement of irrigation [73]. Traditionally, the ET is estimated at
    the field scale, but it consumes lot of time and is difficult to process by complex
    mathematical calculations with various climatic variables. Methods for measuring
    evapotranspiration from meteorological data include a number of climatology, and
    the field inputs which is directly estimated in weather stations. Some parameters
    are associated with measured data, where as others can be obtained directly or
    through empirical methods. 6.2.1 Existing Methods Based on Empirical Since many
    years, various researchers have established reference evapotranspiration ET estimation
    with empirical methods. There are few categories of ET estimation methods: Temperature-based,
    Radiation-based, Empirical, Pan, and many more. Commonly, FAO-56 Penman-Monteith
    method is applied as the scientific, standard and temperature based method to
    estimate the ET [10, 74]. FAO-PM has been extensively adopted because to its positive
    outcomes in a variety of climates across the world. However, it needs a significant
    amount of meteorological data obtained from regular meteorological observation
    stations [75]. To overcome the existing limitation of the FAO-PM model, various
    attempts aiming to estimate ET with limited observed data have been made. A large
    number of studies have focused on estimating ET using empirical methods with limited
    ground-level data such as the Hargreaves and Samani equation, Priestley-Taylor
    equation, and Thornthwaite equation have been used for estimating (ET ) by Tomas-Burguera
    et al. [76]. ET is estimated with simplified or empirical methods (e.g. Lysimetric
    measurements) and it is highly difficult to achieve more precise and robust approaches
    [77, 78]. HS equation is the most simple and accurate approach based on temperature
    [10, 31]. There are many empirical approaches to predict the ET using five mass
    transfer-based models (Ivanov, WMO, Penman, Trabert, and Mahringer), five radiation-based
    approach (Tu, PT, Ab, JH, and Mk), and five temperature-based approach (HS, modified
    Hargreaves-Samani ) (Th, BC, MHS , and MHS ) [79]. Table 4 shows the literature
    of empirical methods for estimation of ET . Table 4 Estimation of evapotranspiration
    ET with empirical methods Full size table Malamos et al. [80] investigated the
    monthly Geo-spatial ET with FAO Penman–Monteith using line, polygon, and point
    through a geometry independent algorithm. They selected various climate parameters
    such as T , u , R , latitude , altitude (m), I . Tegos et al. [81] applied the
    radiation based model to calculate the daily potential evapotranspiration ET with
    FAO-56 Penman–Monteith using T , u , R ,and I parameters. The Potential ET is
    estimated for current and future drought condition using PDSI tool, Spatial, and
    Temperature based models such as Penman–Monteith, Thornthwaite, and Hamon methods.
    They have selected T , u , R , I input variable, and analyzed on MATLAB GUI [82].
    Yang et al. [83] analyses the daily reference evapotranspiration (ET ) using short-term
    forecasting with FAO-56 Penman–Monteith equation, Hargreaves–Samani equation,
    and Reduced-set Penman–Monteith (RPM). The R language is used to simulate with
    various climate parameters including T , T , T , u , RH , I , and Vapor pressure
    (ea). 6.2.2 Existing Methods Based on Machine Learning There have been many studies
    on hybrid models with machine learning, and evolutionary algorithms to estimation
    of ET with few climate parameters around the world. Patil and Deka [85] investigated
    the performance of extreme machine learning (ELM) to quantify the weekly ET in
    the Thar Desert of India. Also, they have showed the comparison of Artificial
    Neural Network (ANN) with three input variable. The ELM model gives slightly higher
    accuracy than empirical, and ANN models. Wu et al. [86] proposed hybrid model
    using machine learning and soft-computing to estimate the monthly ET in south
    China with 26 data stations. The proposed (Kmeans-FFA-KELM) approach developed
    with the three approaches (K-means clustering, Firefly Algorithms, and Kernel
    Extreme Learning Machine model) found higher accuracy using three input variables
    (Temperature , Temperature , and R ). Another study showed performance of six
    remote-sensing based ML models to predict the daily ET in the Andalusian. The
    two ELM and MLP models found higher accuracy than RF, SVM, GRNN, and XGBoost models
    [87]. Stacking and blending ensemble based ML models are used to calculate the
    daily ET with limited input variables. Two-layer ensemble model is build with
    RF, SVR, MLP, LR and KNN models and found higher accuracy in terms of R ranged
    from (0.66 to 0.99) as compared to empirical models [88]. Another, ensemble based
    model is build with ANN, SVM and RF to estimate the ET with geno-types and optimize
    the ET with time series data, and found the correct results [89]. Bai et al. [90]
    proposed ensemble-based four ML models with RF, BMA, KNN, SVM and MLP to calculate
    the ET . The MLP-based ensemble model provides the efficient results. However,
    the ML and DL based models are proposed to estimate a urban ET with Flux Footprint,
    Remote Sensing and Geographic Information System (GIS) data. The RF model provides
    slightly better result in terms of R of (0.840) and RMSE of (0.0239 mm) than CNN
    model [91]. Adnan et al. [92] demonstrated the capability of different Neuro-Fuzzy
    methods to estimate the pan evaporation monthly using climatic inputs of different
    parameters obtained from Uttarakhand, (India). Recently, Adnan et al. [93] demonstrated
    the capability of dynamic evolving Neural-Fuzzy Inference System (DENFIS) and
    Least-Square Support Vector Regression with a Gravitational Search Algorithm (LSSVR-GSA)
    for estimating ET . It has been shown that the extraterrestrial radiation or temperature-based
    LSSVR-GSA models are superior to DENFIS model for estimating monthly ET . They
    [94] forecasted the monthly and daily stream flows of poorly gauged mountainous
    watershed with Fuzzy Genetic Algorithm (FGA), Least Square Support Vector Machine
    (LSSVM), and M5 model tree (M5T) models. Heddam et al. [95] estimated and compared
    daily reference evapotranspiration (ET ) using the Online Sequential Extreme Learning
    Machine (OSELM) and Optimally Pruned Extreme Learning Machine (OPELM) in the Mediterranean
    region of Algeria. The OPELM models showed good performances as compared to OSELM
    models. Recently, Tikhamarine et al. [96] combined the Support Vector Regression
    and Grey Wolf Optimizer (SVR-GWO) to predict the monthly ET at Annaba, Algiers,
    and Tlemcen stations in North Algeria. Moreover, the proposed model is compared
    with the existing variants of SVR and showed that the performance of the SVR-GWO
    gives occasionally competitive and very promising results. Maroufpoorb et al.
    [34] proposed the concept of hybrid Artificial Neural Network-Gray Wolf Optimization
    (ANN-GWO) model and predicted the ET for Iran. Further, the proposed model showed
    more efficient and accurate results as compared to ANN and LS-SVR. Mohammadi and
    Mehdizadeh [97] proposed a hybrid of two models Support Vector Regression and
    Whale Optimization Algorithm to predict the daily reference evapotranspiration
    at three stations in Iran. It has been shown that hybrid models outperformed the
    support vector regressions models. Kisi [65] obtained weather dataset from Turkish
    Meteorological Organization (TMO) for 2 stations from 1982 to 2006 and applied
    MARS, LSSVR, and M5-Tree to estimate ET . Valipour et al. [79] collected data
    for the period of (1961–2010) with 50 climate parameters from 18 regions of Iran
    to estimate monthly ET using five models namely (mass transfer, radiation and
    temperature based). Mattar [98] obtained 32 weather stations of data from United
    Nations Food & Agriculture Organization (UN-FAO) known as CLIMWAT for (2013 to
    2015) and presented gene expression programming (GEP) and empirical models to
    estimate ET . Table 5 Estimation of evapotranspiration ET based on ML and EA Full
    size table Tao [99] presented the hybrid intelligent ET model using data of three
    meteorological stations during 1998 to 2012. They used the Adaptive Neuron Fuzzy
    Inference System (ANFIS), Firefly Optimization Algorithm with ANFIS (ANFIS-FA)
    and Penman–Monteith models. Co-active Neuro Fuzzy Inference System (CANFIS) model
    is proposed for modeling the monthly evaporation of Lake Nasser, Egypt [110].
    The Gene Expression Programming (GEP), Support Vector Machine (SVM), Classification
    and Regression Tree (CART), the Cascade Correlation Neural Network (CCNNs), and
    are proposed for estimating evaporation by Yaseen et al. [100]. Falamarzi et al.
    [101] estimated the daily ET for water resources with ANN and WNN models from
    the period of 2009 to 2012. They have applied RMSE, APE, N.S., R metrics to check
    the model accuracy with three input parameters such as T , T , and u . Models
    LS-SVM, MARS, and M5 models have been applied to estimate the Pan evaporation
    for Reservoir and water resources management. They have applied four input variable,
    T , R , u , and R with dataset of period 1986 to 2006 [102]. Another, ANN model
    is applied to forecast the ET for application of real-time irrigation scheduling
    with T , R , u , and R input parameters using dataset of (2011 to 2012) [103].
    Yassin et al. [73] analyzed the performance of ANN, and GEP models to quantify
    the ET with various climate parameters using dataset from 1980 to 2010. The GeneXpro
    Tools 5.0, and Propagation version 2.2.4 were used to developed the model and
    also provide the accuracy on the basis of these metrics MAE, RMSE, R , and OI.
    Gocic et al. [71] forecasted the ET using SVM, FFA, DWT, ANN, and GEP models with
    climate parameters for the period of 1980 to 2010. Goyal et al. [104] explored
    the four ML models namely ANN, LS-SVR, FL, ANFIS, and Gamma Test to estimate the
    pan evaporation for the duration of 2000 to 2010. They have found the efficient
    results with the FG and LS-SVR models using various climate parameters on MATLAB
    platform. However, Chen et al. [105] found the best performance of Bayesian Model
    Averaging Model to estimate the terrestrial ET using KGE and Cubist software.
    Mehdizadeh et al. [106] proposed the hybrid model to estimate the monthly ET with
    GEP, SVM-Poly, SVM-RBF, and MARS models for duration of 1951 to 2010. The performance
    of the applied models is compared with the empirical methods, where the MARS and
    SVM-RBF models give the most accurate results. The hybrid ELM model revealed a
    superior performance to estimate the daily ET at the four major countries of (US,
    Germany, Belgium, and Sweden) using 9 years of dataset [72]. Mohammadi et al.
    [97] proposed an approach that couples Support Vector Regression with Whale Optimization
    (SVM-WO) to estimate the daily ET .The T , T , RH , u , R , and SSD parameters
    are used to build the model and found accurate result with SVM-WO model. The recent
    estimation of reference evapotranspiration based on machine learning modeling,
    e.g. H2O-Deep Learning,Distributed Random Forest,Gradient Boosting Machine and
    Generalized Linear Model [107], Ensemble Extreme Machine Learning, Multi-layer
    Perceptrons-Neural Network, Support Vector Machine [108], Quantum Matrix Product
    State [111], CNN-LSTM and Conv-LSTM used for combine the features and modeling
    of ET [109], Deep learning versus gradient boosting used for predicting the pan
    evaporation [112], In the domain of agriculture, ML offered new predictive models
    for ET estimation, e.g. Generalized Neuro-Fuzzy Models (GNFM) [60], ANN model
    [61], ANFIS model [62], MLP-NN [63] [113], ELM algorithm [64] [90], M5 Model Tree
    [113], LS-SVR , MARS, ELM, WNN and GANN [66]. The DL model and ML model are applied
    in various domains such the COVID-19 analysis [114], proposed a novel method based
    on artificial intelligence (AI) to identify COVID-19 disease [115], developed
    genetically optimized Deep Neural Network [116], Tripathy et al. [117] investigated
    the performance of MARPUF approach and it is found to be better resistant to such
    modelling attacks, image classification using deep learning [118], Artificial
    Intelligence approaches used to classifying various types of cancer [119], enhanced
    the grip functionality of myoelectric hands based on deep learning [120], and
    classifiers for on-line handwriting recognition based on SVM and KNN algorithms
    [121], and a survey for software fault prediction [122]. Singh et al. [123] presented
    the efficient results and reliable algorithm for optimal design of water distribution
    networks.The literature summary of ML and EA are given in Table 5. 7 Estimation
    of Crop Evapotranspiration (ET ) Crop evapotranspiration (ET ) one the most essential
    element of the hydrological system for irrigation scheduling. The crop coefficient
    K method multiplied with (ET ) is most widely-used to determine the (ET ) Eq.
    (3). Different estimations and methods having their own advantages and disadvantages
    are available. For the estimation of ET using Machine Learning, Deep Learning
    and Evolutionary Algorithms, some potential literature work are presented in this
    section. The literature analysis of crop evapotranspiration methods is presented
    in Table 6. 7.1 Existing Methods Based on Statistics The need of precise estimation
    of crop water is an crucial aspect of agricultural planning and there exists several
    methods for determining ET in crop land [124]. The significant field based estimations
    are required, appropriate for monitoring the crop-water status at the land-scale
    level [125, 126]. The FAO-Penman, PM, and 1963 Penman applied to forecasting the
    ET for rice crop using meteorological data by Shah and Edling (2000). They have
    found the crop coefficients for initial, middle and late stage as 1.39, 1.51,
    and 1.43 [127]. The derivation and development of crop K were identified for Castor
    and Maize crops of Rajendranganagar by Reddy et al. [128]. Ko et al. [129] conducted
    study to estimate the crop water requirement for Cotton and Wheat crops at Uvalde,
    TX, USA. Fang and Ping (2013) presented an optimal the uncertainty approaches
    of interval regression analysis and crop water production function for irrigation
    and Penman-Monteith method used to obtain ET . LINGO software introduced to solve
    above model [57]. 7.2 Machine Learning and Evolutionary Models The Back-propagation
    Neural Network (BP-NN) model is proposed to evaluate the crop evapotranspiration
    ET with combination of various climate parameters (T , T , RH , S , RF and crop
    coefficient K ). It is observed that the combination of Eddy Covariance method
    and BP model achieved the best accuracy in terms of R (0.87) and accuracy (91.44%)
    than MLR model [130]. Mehta et al. [131] estimated the ET , ET and K of Wheat
    and Maize crops of Gujarat using climate data. They applied the various temperature
    and radiation based empirical methods to calculate and estimate the crop water
    requirement. It is observed that the accurate value of K for Wheat crop is more
    efficient as compared to FAO-56 Penman–Monteith method results. Whereas in case
    of maize crop the outcomes were found less accurate at Surat and higher outcomes
    as compared to FAO method at Bharuch station. Saggi et al. [41] proposed a novel
    multi-layer ensemble model based on fuzzy-genetic and regularization random forest
    (FG-RRF) for predicting the K and ET of Ludhiana station. They found that the
    models had high performance for modeling K and ET . Table 6 Estimation of ET based
    on empirical, ML and EA Full size table Elbeltagi et al. [132] presented the deep
    learning model to estimate the Wheat ET from 1970-2017 and forecasting the future
    changes from 2022-2035 of Nile Delta in Egypt using Visual Gene Developer technology.
    For calibration R of 0.95, 0.96, 0.97 and for testing R of 0.94, 0.95, 0.95 have
    been found efficient result respectively. Russo et al. [55] presented the MCMC
    and Bayesian algorithms to analysis the irrigation requirements for ground water
    mass balance with soil tensiometer of Rice crop. They have optimized the management
    decisions on crop replacement and increased the irrigation efficiency. The NN
    model and regression model are explored to estimate a greenhouse tomato crop yield,
    its growth, and efficiency in use of water with CropAssist and NeuralWare platforms
    [133]. Maurya et al. [134] developed a novel fuzzy-based energy-efficient routing
    protocol based on automated irrigation system for Maize crop on MATLAB platform.
    The FIS-DSS (Flexible Irrigation Scheduling Decision Support System) is proposed
    to analyze the optimal allocation of water resources of irrigation system. Fuzzy-inference
    and knowledge based user-friendly optimization tool is developed for Wheat and
    corn crops [135]. Chauhan et al. [136] proposed a web-based DSS to enhance irrigation
    water management for peanut crop on APSIM platform. Gavilán et al. [137] measured
    the daily greenhouse crop evapotranspiration for strawberry and found more accuracy
    using empirical methods and sensors based on soil moisture. Tabari et al. [138]
    explored a ANFIS and SVM model performance for Potato crop evapotranspiration
    ET using meteorological data. Yamaç et al. [139] applied the four scenarios based
    on features subset to accurately estimate the ET of Potato crop using ANN, ABM
    and KNN models. Further, ANN and SVM models are also applied to estimate the garlic
    ET by Abyaneh et al. [140] and the outcomes are found accurate as compared to
    lysimeter performance. The need of precise estimation of crop water is an crucial
    aspect of agricultural planning and there exists several methods for determining
    ET in crop land [124]. The field based estimations are required and appropriate
    for monitoring the crop-water status at the land-scale level [125] [126]. The
    FAO-Penman and Penman methods are applied to forecast the ET for rice crop using
    meteorological data [127]. They have found the crop coefficients for initial,
    middle and late stage as 1.39, 1.51, and 1.43. The derivation and development
    of crop K are identified for Castor and Maize crops of Rajendranganagar by Reddy
    et al. [128]. Ko et al. [129] conducted a analyses report to evaluate the crop
    water requirement for Cotton, and Wheat crops at Uvalde, TX, USA. Fang and Ping
    [57] presented an optimal solution to estimate the ET using interval regression
    analysis, crop water production function and Penman-Monteith method with LINGO
    software. Numerous experiments have been conducted in recent decades to investigate
    the possible effect of climate change on evapotranspiration ET . For efficient
    crop evapotranspiration ET modeling using VIP (Vegetation Interface Processes)
    for Wheat and Maize [141], durum Wheat in Tunisia [142], APSIM-Maize model [143],
    SEBAL model for yield, WUE, IWUE and HUE for Wheat crop [144], weighing lysimeter
    for K and ET [145], farm-level operational services in smart agriculture [146],
    crop water model based on Crop2ML framework [147] have been used. The ET estimation
    results proved that the ML and EA approaches performed better than existing classical
    methods. However, several studies have investigated the estimation of ET with
    empirical methods. But limited studies have reported the estimation of ET using
    ML, and EA models as shown in Table 6. 8 Decision Support System for Irrigation
    Scheduling This section considers the Decision support system (DSS) based on research
    that have included ET , ET , and irrigation requirement. An irrigation management
    system can offer farmers with appropriate decision-making tools in order to regulate
    the amount of water supplied to crops. A decision support system PETP V2.0.0 is
    developed to analysis and estimate the potential evapotranspiration ET using various
    empirical approaches namely Hargreaves, Jensen-Haise, Penman-Monteith, Priestley-Taylor,
    etc. Visual Studio 2010 software is used to build the computational tool to estimate
    the accurate results for water requirement of crop [148]. Navarro et al. [149]
    developed smart irrigation DSS for managing the irrigation scheduling. They purposed
    2 ML techniques i.e. PLSR and ANFIS. Maximum and minimum relative humidity, temperature,
    and direction of wind, global radiation, vapour pressure deficit, rainfall, dew
    point are the variables used to predict the daily ET with FAO Penman–Monteith
    method. Zizhong and Zenghui [150] presented a single irrigation system that enhanced
    higher corn production and also provided efficiency in use of water in Northeast
    China. They include climate parameters namely average, max and min of air temperatures,
    max and min of relative humidity, wind speed, and sunshine hours from 1980 to
    2012. Penman–Monteith approach is used to determine the soil evaporation and ET
    . Table 7 Estimation of evapotranspiration ET , ET , and Irrigation with DSS systems
    Full size table The knowledge of the irrigation management has an impact on crop
    water requirements, maintaining water balance and is the practical considerations
    to enhance productivity of crop [157]. Various research work in Punjab have demonstrated
    the requirements of crop water irrigation, irrigation water based on ET and pan
    evaporation, [158], but few studies have focused on Soil Water Deficit (SWD) [159].
    Paraskevopoulos and Singels [151] investigated the integrated content of soil
    water recordings of real-time field into the MyCanesim system to estimate its
    use in 15 sugarcane fields of South Africa for supporting irrigation system. It
    is used to determine the decision making for irrigation scheduling based on the
    status of forecasts of crop, soil water, and the next irrigation date. Ying et
    al. [152] represented the evaluation for summer Wheat and winter Maize cropping
    system for optimal irrigation scheduling. Further, they described topical versions
    of the SWAP and Wofost models for crop growing simulation and obtaining efficiency
    in use of water. Afzal et al. [160] improved water resources management using
    different irrigation strategies and water qualities by field, and modeling study.
    To deficit irrigation PRD and RDI methods are used to estimate the effects of
    waste and fresh water on salinity distribution, soil moisture, and crop yield
    of Potato, Maize in Italy, Bologna through field experiments. The fuzzy, evolutionary,
    and machine learning models are used to develop a DSS model for irrigation scheduling.
    Gaiqiang et al. [135] developed a FIS-DSS software based on knowledge, interface
    for user, and an inference engine for wheat, corn and cotton crops. It is a fuzzy
    interval programming model having multiple objectives and constraints, flexibility
    of model, data processing, and an alternative solving algorithm. The main objective
    is to maximize the economic-based benefits for crop-land in China. The NN model
    is used to train the model with precipitation and historical climate parameters.
    Giusti and Marsili-Libelli [153] developed a fuzzy-DSS to schedule the daily irrigation
    need of crop based on soil moisture as a predictive model and an inference model
    as irrigation decision maker. This model determines the actual need of water for
    kiwi, corn, and potato crops with past irrigation soil moisture, climatic parameters,
    and ET . They used meteorological data including temperature, solar radiation,
    wind, rain, etc. The objective of FDSS model is to reduce the water usage and
    provide the efficient result in terms of saving water up-to 13.55, 18.3, and 72.95
    water units for irrigating three crops respectively. Sahoo et al. [161] proposed
    fuzzy multi objective linear programming approach for planing of land-water-crop
    system. The meteorological data like daily rainfall, evaporation, temperature,
    solar radiation, daily sunshine hours, humidity, wind velocity, and albedo are
    collected from the Central Rice Research Institute, Cuttack. The objective function
    is to optimize, maximized crop production, net return, and to minimize the labor
    requirement for various vegetables and pulses. Reddy and Kumar [162] demonstrated
    a multi-objective method for the optimal crop pattern and multi-crop irrigation
    reservoir scheme by several procedures. Adeyemo and Otieno [163] explored a method
    to solve the multi objective crop planning model by an evolutionary algorithm.
    They have found excellent results in minimizing total water irrigation, maximizing
    the yield productivity, and net income from farming. Irrigation water management
    is numerically intensive for computations and provides model interpretation and
    discretization. Neural networks and evolutionary algorithms demonstrated to estimate
    the irrigation volume and also determined the effectiveness to diminish irrigation
    application and maximize production [164]. Ortega Álvarez et al. [154] proposed
    a non-linear model to recognize yield schemes and water irrigation management
    plannings using the genetic algorithms. Further, they estimated crop yield, gross
    margin and production as a function of irrigation depth. Schmitz et al. [165]
    simulated 92 percent greater production for corn using evolutionary algorithm
    as compared to dynamic programming. Application and web based DSS models are developed
    for the irrigation water scheduling by various researchers. Recently, a web-based
    DSS is proposed to estimate the soil-water balance for irrigation system with
    limited input parameters such as (dual crop-coefficient and meteorological). The
    irrigation parameters are computed through soil moisture and requirement of water.
    A web-based irrigation decision support system is introduced with limited inputs
    (WIDSSLI) for summer corn and winter Wheat irrigation management in North China
    Plain (NCP) [155]. Table 7 presents the estimation of ET , ET , and irrigation
    with DSS systems. Antonopoulou et al. [166] presented an appropriate decision
    support system for crops which is implemented on web-based software. They introduced
    this approach by using the Java and PHP technologies for specific irrigation technique
    and soil improvement instructions. Dutta et al. [167] developed a mobile application
    based on sustainable irrigation DSS. They proposed cloud sensors based approach
    to evaluate the ground water usage and availability of water. This approach includes
    the CSIRO sensor based cloud computing organization and integrated big data that
    includes machine learning technologies. Bonfante et al. [168] proposed an irrigation
    water supply management tool to obtain the maximum yield of Maize with W-tens,
    IRRISAT, and W-Mod approaches. W-Mod and IRRISAT models found more accurate results
    as compared to W-Tens in terms of irrigation water use efficiency. A Climate-Smart
    Decision-Support System (CSDSS) tool is proposed to evaluate the requirement of
    rice crop in Malaysia. They determine a daily crop-water balance based on input
    data (2010 to 2099) and (1976 to 2005) from Global climate models (GCM) and integrate
    with evapotranspiration using MATLAB simulator [156]. Ragab et al. [169] proposed
    a SALTMED model which includes the to partial root drying or deficit irrigation,
    subsurface irrigation, soil nitrogen fertilizer application, fertigation, dry
    matter production, plant nitrogen uptake, and nitrate leaching. For the model
    calibration and endorsement the statistical measurements are used such as R2 coefficient,
    RMSE, and percentage error. The DIDAS software package for irrigation system decision-making
    strategies of drip irrigation systems is developed [46]. A DSS framework have
    been introduced which includes 22 ET estimation approaches using user-friendly
    GUI (Microsoft Visual Basic 6.0) of 133 selected stations of India [170]. Potential-ET
    and FAO56-PM ET are used to estimate the ET in the Geisenheim Irrigation Scheduling
    (GS) for vegetable crops using sprinkler irrigation [171]. Ballesteros et al.
    [103] estimated the ET using FORETO software with Hargreaves Samani (HS) equation
    or the Penman Monteith (PM) and Artificial neural networks (ANNs) models. Modern
    platforms (.NET and Java) software applied to calculate the daily/monthly ET using
    meteorological parameters [172]. There are various crop simulation based models
    exists such as CropSyst [173], STICS (Brisson et al. 1998) [174], EPIC [175],
    DSSAT [176], VegSyst simulation model [177], and CERES [178]. A single approach,
    that can address all operational circumstances (weather information, crop growth
    monitoring, field data, agricultural expertise and infrastructure etc.), as well
    as the associated expenses for farmers which may limit the usage of these systems.
    Therefore, DSS’s for irrigation scheduling have been developed to integrating
    various approaches in terms of (data collection from meteorological), pre-processing
    techniques and modeling based on empirical or artificial intelligence. 9 Conclusion
    Overall agricultural systems modeling needs to rapidly adopt and absorb state-of-the-art
    data and ICT technologies with a focus on the needs of beneficiaries and on facilitating
    those who develop applications of their models. In spite of the vast literature
    available, the subject of irrigation water management and crop water modeling
    for machine learning techniques are yet in its emerging phase. Although there
    is wide literature available on statistics, machine learning, decision support
    system for general manifolds. To estimate crop water modeling on general manifolds,
    we have different approaches available in literature. Moreover, the water balance
    is well-entrenched approach for estimating irrigation amount and time (i.e. irrigation
    frequency) in irrigation scheduling. This approach is simple to use, typically
    inexpensive and very effective approach to estimates the ET , and ET . The major
    objective is to adopt the several approaches to develop a flexible system that
    supports irrigation water requirement system, which may fit into diverse fields
    of operational activities (weather information, field data collection, crop coefficients
    etc.). This study provides an overview of the irrigation water scheduling. It
    also presented the concept of reference evapotranspiration and crop evapotranspiration
    for crop water modeling. It also presents the various methods of irrigation scheduling.
    It also address the need of decision support system and its various approaches
    that lead to irrigation water management. References Keith SA (1948) A new theory
    of human evolution. Watts, London Google Scholar   Singh J, Dhaliwal T, Grover
    D (2012) State agricultural profile-Punjab. AERC Study 30:12–27 Google Scholar   Kamilaris
    A, Prenafeta-Boldú FX (2018) Deep learning in agriculture: a survey. Comput Electron
    Agric 147:70–90 Article   Google Scholar   Wani JA, Sharma S, Muzamil M, Ahmed
    S, Sharma S, Singh S (2021) Machine learning and deep learning based computational
    techniques in automatic agricultural diseases detection: Methodologies, applications,
    and challenges. Arch Comput Methods Eng 29:1–37 Google Scholar   Howell T (1996)Irrigation
    scheduling research and its impact on water use. Evapotranspiration and irrigation
    scheduling. In: Proceedings of the international conference. American Society
    of Agricultural Engineer St Joseph, pp 21–33 Das B (2003) The use of irrigation
    systems for sustainable fish production in India. Fisheries in irrigation systems
    of arid Asia. FAO fisheries Technical Paper (430), pp 47–58 Thompson R, Gallardo
    M, Valdez L, Fernández M (2007) Using plant water status to define threshold values
    for irrigation management of vegetable crops using soil moisture sensors. Agric
    Water Manag 88(1–3):147–158 Article   Google Scholar   Boretti A, Rosa L (2019)
    Reassessing the projections of the world water development report. NPJ Clean Water
    2(1):1–6 Article   Google Scholar   Bali N, Singla A (2021) Emerging trends in
    machine learning to predict crop yield and study its influential factors: a survey.
    Arch Comput Methods Eng 29:1–18 Google Scholar   Allen RG, Pereira LS, Raes D,
    Smith M et al (1998) Crop evapotranspiration-guidelines for computing crop water
    requirements-fao irrigation and drainage paper 56, FAO. Rome 300(9):D05109 Google
    Scholar   Ali M (2010) Weather: a driving force in determining irrigation demand.
    Fundamentals of irrigation and on-farm water management, vol 1. Springer, New
    York, pp 31–105 Chapter   Google Scholar   Richardson C (1985) Weather simulation
    for crop management models. Trans ASAE 28(5):1602–1606 Article   Google Scholar   Hinrichsen
    K (1994) The ångström formula with coefficients having a physical meaning. Sol
    Energy 52(6):491–495 Article   Google Scholar   Ali M, Adham A, Talukder M (2005)
    Estimation of solar radiation from climatic parameters. Bangladesh J Agril Sci
    32(1):99–104 Google Scholar   Allen R, Smith M, Perrier A, Pereira LS (1994) An
    update for the definition of reference evapotranspiration. ICID Bull 43(2):1–34
    Google Scholar   Ali MH (2010) Fundamentals of irrigation and on-farm water management,
    vol 1. Springer, New York Book   Google Scholar   Linsley Jr RK, Kohler MA, Paulhus
    JL (1975) Hydrology for engineers Sutton OG (1953) Micrometeorology, vol 79. McGraw-Hill,
    New York Google Scholar   Duffie JA, Beckman WA, Blair N (2020) Solar engineering
    of thermal processes, photovoltaics and wind. Wiley, Hoboken Book   Google Scholar   Blaney
    HF, Criddle WD (1962) Determining consumptive use and irrigation water requirements,
    no. 1275, US Department of Agriculture, Allen RG, Pruitt WO (1986) Rational use
    of the fao Blaney–Criddle formula. J Irrig Drain Eng 112(2):139–155 Article   Google
    Scholar   Hargreaves GH, Samani ZA (1985) Reference crop evapotranspiration from
    temperature. Appl Eng Agric 1(2):96–99 Article   Google Scholar   Ladlani I, Houichi
    L, Djemili L, Heddam S, Belouz K (2012) Modeling daily reference evapotranspiration
    (et0) in the north of Algeria using generalized regression neural networks (grnn)
    and radial basis function neural networks (rbfnn): a comparative study. Meteorol
    Atmos Phys 118(3–4):163–178 Article   Google Scholar   Almorox J, Quej VH, Martí
    P (2015) Global performance ranking of temperature-based approaches for evapotranspiration
    estimation considering köppen climate classes. J Hydrol 528:514–522 Article   Google
    Scholar   Brouwer C, Heibloem M (1986) Irrigation water management: irrigation
    water needs, Training manual 3 Droogers P, Allen RG (2002) Estimating reference
    evapotranspiration under inaccurate data conditions. Irrig Drain Syst 16(1):33–45
    Article   Google Scholar   Thornthwaite CW (1948) An approach toward a rational
    classification of climate. Geogr Rev 38(1):55–94 Article   Google Scholar   Kohler
    MA (1952) Lake and pan evaporation, Water-Lossa Investigations: Lake Hefner Studies.
    Technical Report. Geological Survey Professional Paper 269:127–148 Doorenbos J,
    Pruitt W (1997) Crop water requirements. FAO Irrigation and Drainage Paper 24:124
    Priestley CHB, Taylor R (1972) On the assessment of surface heat flux and evaporation
    using large-scale parameters. Mon Weather Rev 100(2):81–92 Article   Google Scholar   Jensen
    ME, Burman RD, Allen RG (1990) Evapotranspiration and irrigation water requirements,
    ASCE Gavilan P, Berengena J, Allen RG (2007) Measuring versus estimating net radiation
    and soil heat flux: Impact on Penman–Monteith reference et estimates in semiarid
    regions. Agric Water Manag 89(3):275–286 Article   Google Scholar   Tabari H,
    Grismer ME, Trajkovic S (2013) Comparative analysis of 31 reference evapotranspiration
    methods under humid conditions. Irrig Sci 31(2):107–117 Article   Google Scholar   Maroufpoor
    S, Bozorg-Haddad O, Maroufpoor E (2020) Reference evapotranspiration estimating
    based on optimal input combination and hybrid artificial intelligent model: Hybridization
    of artificial neural network with grey wolf optimizer algorithm. J Hydrol 588:125060
    Article   Google Scholar   Bouman B, van Keulen H, van Laar H, Rabbinge R (1996)
    The ‘school of de wit’crop growth simulation models: a pedigree and historical
    overview. Agric Syst 52(2–3):171–198 Article   Google Scholar   Jensen ME (1968)
    Water consumption by agricultural plants (chapter 1) Doorenbos J (1975) Guidelines
    for predicting crop water requirements, irrigation and drainage. Irrig Drainage
    24:1–154 Google Scholar   Urman R, Wright J, Nixon P, Hill R (1980) Irrigation
    management—water requirements and water balance Allen RG, Pereira LS (2009) Estimating
    crop coefficients from fraction of ground cover and height. Irrig Sci 28(1):17–34
    Article   Google Scholar   Kingra P, Hundal S, Sharma P (2004) Characterization
    of crop coefficients for wheat and rice crops in Punjab. J Agrometeorol 6:58–60
    Google Scholar   Saggi MK, Jain S (2020) Application of fuzzy-genetic and regularization
    random forest (fg-rrf): estimation of crop evapotranspiration (etc) for maize
    and wheat crops. Agric Water Manag 229:105907 Article   Google Scholar   Ferreira
    LB, da Cunha FF (2020) New approach to estimate daily reference evapotranspiration
    based on hourly temperature and relative humidity using machine learning and deep
    learning. Agric Water Manag 234:106113 Article   Google Scholar   Phocaides A
    (2007) Handbook on pressurized irrigation techniques. Food & Agriculture Org,
    Rome Google Scholar   Ali H (2011) Practices of irrigation & on-farm water management,
    vol 2. Springer, New York Book   Google Scholar   Ren W, Xiang Q, Yang Y, Cui
    H, Dai L (2010) Implement of fuzzy control for greenhouse irrigation. In: International
    conference on computer and computing technologies in agriculture, Springer, pp
    267–274 Friedman SP, Communar G, Gamliel A (2016) Didas-user-friendly software
    package for assisting drip irrigation design and scheduling. Comput Electron Agric
    120:36–52 Article   Google Scholar   Isern D, Abelló S, Moreno A (2012) Development
    of a multi-agent system simulation platform for irrigation scheduling with case
    studies for garden irrigation. Comput Electron Agric 87:1–13 Article   Google
    Scholar   García-Vila M, Fereres E (2012) Combining the simulation crop model
    aquacrop with an economic model for the optimization of irrigation management
    at farm level. Eur J Agron 36(1):21–31 Article   Google Scholar   Jackson T, Hanjra
    MA, Khan S, Hafeez M (2011) Building a climate resilient farm: A risk based approach
    for understanding water, energy and emissions in irrigated agriculture. Agric
    Syst 104(9):729–745 Article   Google Scholar   Morris MR, Hussain A, Gillies MH,
    O’Halloran NJ (2015) Inflow rate and border irrigation performance. Agric Water
    Manag 155:76–86 Article   Google Scholar   Burguete J, Lacasta A, García-Navarro
    P (2014) Surcos: a software tool to simulate irrigation and fertigation in isolated
    furrows and furrow networks. Comput Electron Agric 103:91–103 Article   Google
    Scholar   Pereira LS, Gonçalves J, Dong B, Mao Z, Fang S (2007) Assessing basin
    irrigation and scheduling strategies for saving irrigation water and controlling
    salinity in the upper yellow river basin, china. Agric Water Manag 93(3):109–122
    Article   Google Scholar   Rinaldi M, He Z (2014) Decision support systems to
    manage irrigation in agriculture. Advances in agronomy, vol 123. Elsevier, Amsterdam,
    pp 229–279 Google Scholar   Guariso G, Rinaldi S, Soncini-Sessa R (1985) Decision
    support systems for water management: the lake como case study. Eur J Oper Res
    21(3):295–306 Article   MATH   Google Scholar   Russo TA, Devineni N, Lall U (2015)
    Assessment of agricultural water management in Punjab, India, using Bayesian methods.
    Sustainability of integrated water resources management. Springer, New York, pp
    147–162 Chapter   Google Scholar   Liakos KG, Busato P, Moshou D, Pearson S, Bochtis
    D (2018) Machine learning in agriculture: a review. Sensors 18(8):2674 Article   Google
    Scholar   Tong F, Guo P (2013) Simulation and optimization for crop water allocation
    based on crop water production functions and climate factor under uncertainty.
    Appl Math Model 37(14–15):7708–7716 Article   Google Scholar   Yan S, Wu L, Fan
    J, Zhang F, Zou Y, Wu Y (2021) A novel hybrid woaxgb model for estimating daily
    reference evapotranspiration using local and external meteorological data. Applications
    in arid and humid regions of China. Agric Water Manag 244:594 Article   Google
    Scholar   Shiri J, Nazemi AH, Sadraddini AA, Landeras G, Kisi O, Fard AF, Marti
    P (2014) Comparison of heuristic and empirical approaches for estimating reference
    evapotranspiration from limited inputs in Iran. Comput Electron Agric 108:230–241
    Article   Google Scholar   Kişi O, Ali Baba AP, Shiri J (2012) Generalized neurofuzzy
    models for estimating daily pan evaporation values from weather data. J Irrig
    Drain Eng 138(4):349–362 Article   Google Scholar   Kumar M, Raghuwanshi N, Singh
    R (2011) Artificial neural networks approach in evapotranspiration modeling: a
    review. Irrig Sci 29(1):11–25 Article   Google Scholar   Tabari H, Kisi O, Ezani
    A, Talaee PH (2012) Svm, anfis, regression and climate based models for reference
    evapotranspiration modeling using limited climatic data in a semi-arid highland
    environment. J Hydrol 444:78–89 Article   Google Scholar   Zaji AH, Bonakdari
    H (2014) Performance evaluation of two different neural network and particle swarm
    optimization methods for prediction of discharge capacity of modified triangular
    side weirs. Flow Meas Instrum 40:149–156 Article   Google Scholar   Abdullah SS,
    Malek MA, Abdullah NS, Kisi O, Yap KS (2015) Extreme learning machines: a new
    approach for prediction of reference evapotranspiration. J Hydrol 527:184–195
    Article   Google Scholar   Kisi O (2016) Modeling reference evapotranspiration
    using three different heuristic regression approaches. Agric Water Manag 169:162–172
    Article   Google Scholar   Feng Y, Cui N, Zhao L, Hu X, Gong D (2016) Comparison
    of elm, gann, wnn and empirical models for estimating reference evapotranspiration
    in humid region of southwest China. J Hydrol 536:376–383 Article   Google Scholar   Ivakhnenko
    A Cybernetic predicting devices. Tech. rep Wang J, Ma Y, Zhang L, Gao RX, Wu D
    (2018) Deep learning for smart manufacturing: methods and applications. J Manuf
    Syst 48:144–156 Article   Google Scholar   Yang G, Huang Y, Zhao C (2020) Agri-bigdata:
    a smart pathway for crop nitrogen inputs. Artif Intell Agric 4:150–152 Google
    Scholar   Saggi MK, Jain S (2018) A survey towards an integration of big data
    analytics to big insights for value-creation. Inf Process Manag 54(5):758–790
    Article   Google Scholar   Gocić M, Motamedi S, Shamshirband S, Petković D, Ch
    S, Hashim R, Arif M (2015) Soft computing approaches for forecasting reference
    evapotranspiration. Comput Electron Agric 113:164–173 Article   Google Scholar   Dou
    X, Yang Y (2018) Evapotranspiration estimation using four different machine learning
    approaches in different terrestrial ecosystems. Comput Electron Agric 148:95–106
    Article   Google Scholar   Yassin MA, Alazba A, Mattar MA (2016) Artificial neural
    networks versus gene expression programming for estimating reference evapotranspiration
    in arid climate. Agric Water Manag 163:110–124 Article   Google Scholar   Wable
    P, Jha M, Gorantiwar S (2019) Assessing suitability of temperature-based reference
    evapotranspiration methods for semi-arid basin of Maharashtra. J Agrometeorol
    21(3):351–356 Article   Google Scholar   Hobbins MT, Wood A, McEvoy DJ, Huntington
    JL, Morton C, Anderson M, Hain C (2016) The evaporative demand drought index.
    Part I: linking drought evolution to variations in evaporative demand. J Hydrometeorol
    17(6):1745–1761 Article   Google Scholar   Vicente-Serrano SM, Tomas-Burguera
    M, Beguería S, Reig F, Latorre B, Peña-Gallardo M, Luna MY, Morata A, González-Hidalgo
    JC (2017) A high resolution dataset of drought indices for Spain. Data 2(3):22
    Article   Google Scholar   Martí P, González-Altozano P, López-Urrea R, Mancha
    LA, Shiri J (2015) Modeling reference evapotranspiration with calculated targets.
    Assessment and implications. Agric Water Manag 149:81–90 Article   Google Scholar   Perera
    KC, Western AW, Robertson DE, George B, Nawarathna B (2016) Ensemble forecasting
    of short-term system scale irrigation demands using real-time flow data and numerical
    weather predictions. Water Resour Res 52(6):4801–4822 Article   Google Scholar   Valipour
    M, Sefidkouhi MAG, Raeini M et al (2017) Selecting the best model to estimate
    potential evapotranspiration with respect to climate change and magnitudes of
    extreme events. Agric Water Manag 180:50–60 Article   Google Scholar   Malamos
    N, Barouchas P, Tsirogiannis I, Liopa-Tsakalidi A, Koromilas T (2015) Estimation
    of monthly FAO Penman–Monteith evapotranspiration in GIS environment, through
    a geometry independent algorithm. Agric Agric Sci Proc 4:290–299 Google Scholar   Tegos
    A, Malamos N, Efstratiadis A, Tsoukalas I, Karanasios A, Koutsoyiannis D (2017)
    Parametric modelling of potential evapotranspiration: a global survey. Water 9(10):795
    Article   Google Scholar   Ficklin DL, Letsinger SL, Gholizadeh H, Maxwell JT
    (2015) Incorporation of the Penman–Monteith potential evapotranspiration method
    into a palmer drought severity index tool. Comput Geosci 85:136–141 Article   Google
    Scholar   Yang Y, Cui Y, Bai K, Luo T, Dai J, Wang W, Luo Y (2019) Short-term
    forecasting of daily reference evapotranspiration using the reduced-set Penman–Monteith
    model and public weather forecasts. Agric Water Manag 211:70–80 Article   Google
    Scholar   Heydari MM, Tajamoli A, Ghoreishi SH, Darbe-Esfahani MK, Gilasi H (2015)
    Evaluation and calibration of Blaney–Criddle equation for estimating reference
    evapotranspiration in semiarid and arid regions. Environ Earth Sci 74(5):4053–4063
    Article   Google Scholar   Patil AP, Deka PC (2016) An extreme learning machine
    approach for modeling evapotranspiration using extrinsic inputs. Comput Electron
    Agric 121:385–392 Article   Google Scholar   Wu L, Peng Y, Fan J, Wang Y, Huang
    G (2021) A novel kernel extreme learning machine model coupled with k-means clustering
    and firefly algorithm for estimating monthly reference evapotranspiration in parallel
    computation. Agric Water Manag 245:106624 Article   Google Scholar   Bellido-Jiménez
    JA, Estévez J, García-Marín AP (2021) New machine learning approaches to improve
    reference evapotranspiration estimates using intra-daily temperature-based variables
    in a semi-arid region of spain. Agric Water Manag 245:106558 Article   Google
    Scholar   Wu T, Zhang W, Jiao X, Guo W, Hamoud YA (2021) Evaluation of stacking
    and blending ensemble learning methods for estimating daily reference evapotranspiration.
    Comput Electron Agric 184:106039 Article   Google Scholar   Kar S, Purbey VK,
    Suradhaniwar S, Korbu LB, Kholová J, Durbha SS, Adinarayana J, Vadez V (2021)
    An ensemble machine learning approach for determination of the optimum sampling
    time for evapotranspiration assessment from high-throughput phenotyping data.
    Comput Electron Agric 182:105992 Article   Google Scholar   Bai Y, Zhang S, Bhattarai
    N, Mallick K, Liu Q, Tang L, Im J, Guo L, Zhang J (2021) On the use of machine
    learning based ensemble approaches to improve evapotranspiration estimates from
    croplands across a wide environmental gradient. Agric For Meteorol 298:108308
    Article   Google Scholar   Vulova S, Meier F, Rocha AD, Quanz J, Nouri H, Kleinschmit
    B (2021) Modeling urban evapotranspiration using remote sensing, flux footprints,
    and artificial intelligence. Sci Total Environ 786:147293 Article   Google Scholar   Adnan
    RM, Malik A, Kumar A, Parmar KS, Kisi O (2019) Pan evaporation modeling by three
    different neuro-fuzzy intelligent systems using climatic inputs. Arab J Geosci
    12(20):606 Article   Google Scholar   Adnan RM, Chen Z, Yuan X, Kisi O, El-Shafie
    A, Kuriqi A, Ikram M (2020) Reference evapotranspiration modeling using new heuristic
    methods. Entropy 22(5):547 Article   Google Scholar   Adnan RM, Liang Z, Heddam
    S, Zounemat-Kermani M, Kisi O, Li B (2020) Least square support vector machine
    and multivariate adaptive regression splines for streamflow prediction in mountainous
    basin using hydro-meteorological data as inputs. J Hydrol 586:124371 Article   Google
    Scholar   Heddam S, Kisi O, Sebbar A, Houichi L, Djemili L (2020) New formulation
    for predicting daily reference evapotranspiration (et 0) in the mediterranean
    region of Algeria country: optimally pruned extreme learning machine (opelm) versus
    online sequential extreme learning machine (oselm), Water Resources in Algeria-Part
    I: Assessment of Surface and Groundwater Resources. Springer, Cham, pp 181–199
    Tikhamarine Y, Malik A, Souag-Gamane D, Kisi O (2020) Artificial intelligence
    models versus empirical equations for modeling monthly reference evapotranspiration.
    Environ Sci Pollut Res 27:30001–30019 Article   Google Scholar   Mohammadi B,
    Mehdizadeh S (2020) Modeling daily reference evapotranspiration via a novel approach
    based on support vector regression coupled with whale optimization algorithm.
    Agric Water Manag 237:106145 Article   Google Scholar   Mattar MA (2018) Using
    gene expression programming in monthly reference evapotranspiration modeling:
    a case study in Egypt. Agric Water Manag 198:28–38 Article   Google Scholar   Tao
    H, Diop L, Bodian A, Djaman K, Ndiaye PM, Yaseen ZM (2018) Reference evapotranspiration
    prediction using hybridized fuzzy model with firefly algorithm: regional case
    study in burkina faso. Agric Water Manag 208:140–151 Article   Google Scholar   Yaseen
    ZM, Al-Juboori AM, Beyaztas U, Al-Ansari N, Chau K-W, Qi C, Ali M, Salih SQ, Shahid
    S (2020) Prediction of evaporation in arid and semi-arid regions: a comparative
    study using different machine learning models. Eng Appl Comput Fluid Mech 14(1):70–89
    Google Scholar   Falamarzi Y, Palizdan N, Huang YF, Lee TS (2014) Estimating evapotranspiration
    from temperature and wind speed data using artificial and wavelet neural networks
    (wnns). Agric Water Manag 140:26–36 Article   Google Scholar   Kisi O (2015) Pan
    evaporation modeling using least square support vector machine, multivariate adaptive
    regression splines and m5 model tree. J Hydrol 528:312–320 Article   Google Scholar   Ballesteros
    R, Ortega JF, Moreno MÁ (2016) Foreto: new software for reference evapotranspiration
    forecasting. J Arid Environ 124:128–141 Article   Google Scholar   Goyal MK, Bharti
    B, Quilty J, Adamowski J, Pandey A (2014) Modeling of daily pan evaporation in
    sub tropical climates using ann, ls-svr, fuzzy logic, and anfis. Expert Syst Appl
    41(11):5267–5276 Article   Google Scholar   Chen Y, Yuan W, Xia J, Fisher JB,
    Dong W, Zhang X, Liang S, Ye A, Cai W, Feng J (2015) Using Bayesian model averaging
    to estimate terrestrial evapotranspiration in China. J Hydrol 528:537–549 Article   Google
    Scholar   Mehdizadeh S, Behmanesh J, Khalili K (2017) Using mars, svm, gep and
    empirical equations for estimation of monthly mean reference evapotranspiration.
    Comput Electron Agric 139:103–114 Article   Google Scholar   Saggi MK, Jain S
    (2019) Reference evapotranspiration estimation and modeling of the Punjab northern
    India using deep learning. Comput Electron Agric 156:387–398 Article   Google
    Scholar   Saggi MK, Jain S, Bhatia AS, Sharda R (2022) Proposition of new ensemble
    data-intelligence model for evapotranspiration process simulation. J Ambient Intell
    Hum Comput 1:1–17 Google Scholar   Sharma G, Singh A, Jain S (2021) A hybrid deep
    neural network approach to estimate reference evapotranspiration using limited
    climate data. Neural Comput Appl 19:1–20 Google Scholar   Salih SQ, Allawi MF,
    Yousif AA, Armanuos AM, Saggi MK, Ali M, Shahid S, Al-Ansari N, Yaseen ZM, Chau
    K-W (2019) Viability of the advanced adaptive neuro-fuzzy inference system model
    on reservoir evaporation process simulation: case study of nasser lake in egypt.
    Eng Appl Comput Fluid Mech 13(1):878–891 Google Scholar   Bhatia AS, Saggi MK,
    Kumar A, Jain S (2019) Matrix product state-based quantum classifier. Neural Comput
    31(7):1499–1517 Article   MathSciNet   MATH   Google Scholar   Malik SMKRSSHISBASFAAOAY,
    Anurag ZM (2022) Deep learning versus gradient boosting machine for pan evaporation
    prediction. Eng Appl Comput Fluid Mech 16:570–587 Google Scholar   Malik A, Kumar
    A, Kisi O (2017) Monthly pan-evaporation estimation in Indian central Himalayas
    using different heuristic approaches and climate based models. Comput Electron
    Agric 143:302–313 Article   Google Scholar   Punn NS, Sonbhadra SK, Agarwal S
    (2020) Covid-19 epidemic analysis using machine learning and deep learning algorithms.
    MedRxiv Gupta RK, Gupta AR, Pathik N, Pateriya R, Chaurasiya PK, Rakjak U, Verma
    TN, Alosaimi AM, Hussein MA (2021) Novel deep neural network technique for detecting
    environmental effect of covid-19. Energy Sources Part A. https://doi.org/10.1080/15567036.2021.1941435
    Article   Google Scholar   Agrawal S, Tiwari A, Goel I (2020) Genetically optimized
    deep neural learning for breast cancer prediction. Soft computing for problem
    solving, 2019. Springer, Cham, pp 127–139 Book   Google Scholar   Tripathy S,
    Rai VK, Mathew J (2021) Marpuf: physical unclonable function with improved machine
    learning attack resistance. Devices Syst IET Circ 15(5):465–74 Article   Google
    Scholar   Li X, Chang D, Ma Z, Tan Z-H, Xue J-H, Cao J, Guo J (2020) Deep interboost
    networks for small-sample image classification. Neurocomputing 456:492–503 Article   Google
    Scholar   Khalifa NEM, Taha MHN, Ali DE, Slowik A, Hassanien AE (2020) Artificial
    intelligence technique for gene expression by tumor rna-seq data: a novel optimized
    deep learning approach. IEEE Access 8:22874–22883 Article   Google Scholar   Ghazaei
    G, Alameer A, Degenaar P, Morgan G, Nazarpour K (2017) Deep learning-based artificial
    vision for grasp classification in myoelectric hands. J Neural Eng 14(3):036025
    Article   Google Scholar   Bothe S, Gärtner T, Wrobel S (2010) On-line handwriting
    recognition with parallelized machine learning algorithms. In: Annual conference
    on artificial intelligence, Springer, pp 82–90 Pandey SK, Mishra RB, Tripathi
    AK (2021) Machine learning based methods for software fault prediction: a survey.
    Expert Syst Appl 172:114595 Article   Google Scholar   Singh KP, Kansal M, Deep
    K (2014) Ga-nr for optimal design of water distribution networks. Int J Oper Res
    20(3):241–261 Article   MATH   Google Scholar   Rana G, Katerji N (2000) Measurement
    and estimation of actual evapotranspiration in the field under Mediterranean climate:
    a review. Eur J Agron 13(2–3):125–153 Article   Google Scholar   Liu C, Zhang
    X, Zhang Y (2002) Determination of daily evaporation and evapotranspiration of
    winter wheat and maize by large-scale weighing lysimeter and micro-lysimeter.
    Agric For Meteorol 111(2):109–120 Article   Google Scholar   López-Urrea R, Montoro
    A, González-Piqueras J, López-Fuster P, Fereres E (2009) Water use of spring wheat
    to raise water productivity. Agric Water Manag 96(9):1305–1310 Article   Google
    Scholar   Shah S, Edling R (2000) Daily evapotranspiration prediction from Louisiana
    flooded rice field. J Irrig Drain Eng 126(1):8–13 Article   Google Scholar   Reddy
    KC (2015) Development of crop coefficient models of castor and maize crops. Eur
    J Agron 69:59–62 Article   Google Scholar   Ko J, Piccinni G, Marek T, Howell
    T (2009) Determination of growth-stage-specific crop coefficients (kc) of cotton
    and wheat. Agric Water Manag 96(12):1691–1697 Article   Google Scholar   Han X,
    Wei Z, Zhang B, Li Y, Du T, Chen H (2021) Crop evapotranspiration prediction by
    considering dynamic change of crop coefficient and the precipitation effect in
    back-propagation neural network model. J Hydrol 596:126104 Article   Google Scholar   Mehta
    R, Pandey V (2015) Reference evapotranspiration (eto) and crop water requirement
    (etc) of wheat and maize in Gujarat. J Agrometeorol 17(1):107 Article   Google
    Scholar   Elbeltagi A, Deng J, Wang K, Malik A, Maroufpoor S (2020) Modeling long-term
    dynamics of crop evapotranspiration using deep learning in a semi-arid environment.
    Agric Water Manag 241:106334 Article   Google Scholar   Ehret DL, Hill BD, Helmer
    T, Edwards DR (2011) Neural network modeling of greenhouse tomato yield, growth
    and water use from automated crop monitoring data. Comput Electron Agric 79(1):82–89
    Article   Google Scholar   Maurya S, Jain VK (2016) Fuzzy based energy efficient
    sensor network protocol for precision agriculture. Comput Electron Agric 130:20–37
    Article   Google Scholar   Yang G, Liu L, Guo P, Li M (2017) A flexible decision
    support system for irrigation scheduling in an irrigation district in China. Agric
    Water Manag 179:378–389 Article   Google Scholar   Chauhan YS, Wright GC, Holzworth
    D, Rachaputi RC, Payero JO (2013) Aquaman: a web-based decision support system
    for irrigation scheduling in peanuts. Irrig Sci 31(3):271–283 Article   Google
    Scholar   Gavilán P, Ruiz N, Lozano D (2015) Daily forecasting of reference and
    strawberry crop evapotranspiration in greenhouses in a Mediterranean climate based
    on solar radiation estimates. Agric Water Manag 159:307–317 Article   Google Scholar   Tabari
    H, Martinez C, Ezani A, Talaee PH (2013) Applicability of support vector machines
    and adaptive neurofuzzy inference system for modeling potato crop evapotranspiration.
    Irrig Sci 31(4):575–588 Article   Google Scholar   Yamaç SS, Todorovic M (2020)
    Estimation of daily potato crop evapotranspiration using three different machine
    learning algorithms and four scenarios of available meteorological data. Agric
    Water Manag 228:105875 Article   Google Scholar   Abyaneh HZ, Nia AM, Varkeshi
    MB, Marofi S, Kisi O (2011) Performance evaluation of ann and anfis models for
    estimating garlic crop evapotranspiration. J Irrig Drain Eng 137(5):280–286 Article   Google
    Scholar   Mo X, Guo R, Liu S, Lin Z, Hu S (2013) Impacts of climate change on
    crop evapotranspiration with ensemble gcm projections in the North China plain.
    Clim Change 120(1–2):299–312 Article   Google Scholar   Lhomme J-P, Mougou R,
    Mansour M (2009) Potential impact of climate change on durum wheat cropping in
    Tunisia. Clim Change 96(4):549–564 Article   Google Scholar   Liu Z, Yang X, Lin
    X, Gowda P, Lv S, Wang J (2018) Climate zones determine where substantial increases
    of maize yields can be attained in northeast China. Clim Change 149(3–4):473–487
    Article   Google Scholar   Salama M, Yousef KM, Mostafa A (2015) Simple equation
    for estimating actual evapotranspiration using heat units for wheat in arid regions.
    J Radiat Res Appl Sci 8(3):418–427 Article   Google Scholar   Anapalli SS, Ahuja
    LR, Gowda PH, Ma L, Marek G, Evett SR, Howell TA (2016) Simulation of crop evapotranspiration
    and crop coefficients with data in weighing lysimeters. Agric Water Manag 177:274–283
    Article   Google Scholar   O’Grady M, Langton D, Salinari F, Daly P, O’Hare G
    (2020) Service design for climate-smart agriculture. Inf Process Agric 8(2):328–40
    Google Scholar   Midingoyi CA, Pradal C, Enders A, Fumagalli D, Raynal H, Donatelli
    M, Athanasiadis IN, Porter C, Hoogenboom G, Holzworth D et al (2021) Crop2ml:
    An open-source multi-language modeling framework for the exchange and reuse of
    crop model components. Environ Model Softw 142:105055 Article   Google Scholar   Gutierrez-Ninahuaman
    C, Gonzalez-Herrera R (2021) Software to analyze eto compilation of indirect methods.
    Environ Model Softw 142:105056 Article   Google Scholar   Navarro-Hellín H, Martínez-del
    Rincon J, Domingo-Miguel R, Soto-Valles F, Torres-Sánchez R (2016) A decision
    support system for managing irrigation in agriculture. Comput Electron Agric 124:121–131
    Article   Google Scholar   Li Z, Sun Z (2016) Optimized single irrigation can
    achieve high corn yield and water use efficiency in the corn belt of northeast
    China. Eur J Agron 75:12–24 Article   Google Scholar   Paraskevopoulos A, Singels
    A (2014) Integrating soil water monitoring technology and weather based crop modelling
    to provide improved decision support for sugarcane irrigation management. Comput
    Electron Agric 105:44–53 Article   Google Scholar   Ma Y, Feng S, Song X (2015)
    Evaluation of optimal irrigation scheduling and groundwater recharge at representative
    sites in the north China plain with swap model and field experiments. Comput Electron
    Agric 116:125–136 Article   Google Scholar   Giusti E, Marsili-Libelli S (2015)
    A fuzzy decision support system for irrigation and water conservation in agriculture.
    Environ Model Softw 63:73–86 Article   Google Scholar   Ortega Alvarez JF, de
    Juan Valero JA (2004) Mopeco: an economic optimization model for irrigation water
    management. Irrig Sci 23(2):61–75 Article   Google Scholar   Li H, Li J, Shen
    Y, Zhang X, Lei Y (2018) Web-based irrigation decision support system with limited
    inputs for farmers. Agric Water Manag 210:279–285 Article   Google Scholar   Rowshon
    MK, Dlamini NS, Mojid MA, Adib M, Amin MSM, Lai SH (2019) Modeling climate-smart
    decision support system (CSDSS) for analyzing water demand of a large-scale rice
    irrigation scheme. Agric Water Manag 216:138–152 Article   Google Scholar   Brar
    S, Mahal S, Brar A, Vashist K, Sharma N, Buttar G (2012) Transplanting time and
    seedling age affect water productivity, rice yield and quality in north-west India.
    Agric Water Manag 115:217–222 Article   Google Scholar   Prihar S, Khera K, Sandhu
    K, Sandhu B (1976) Comparison of irrigation schedules based on pan evaporation
    and growth stages in winter wheat 1. Agron J 68(4):650–653 Article   Google Scholar   Timsina
    J, Godwin D, Humphreys E, Kukal S, Smith D et al (2008) Evaluation of options
    for increasing yield and water productivity of wheat in Punjab, India using the
    dssat-csm-ceres-wheat model. Agric Water Manag 95(9):1099–1110 Article   Google
    Scholar   Afzal M, Battilani A, Solimando D, Ragab R (2016) Improving water resources
    management using different irrigation strategies and water qualities: field and
    modelling study. Agric Water Manag 176:40–54 Article   Google Scholar   Asahoo
    B, Lohani AK, Sahu RK (2006) Fuzzy multiobjective and linear programming based
    management models for optimal land-water-crop system planning. Water Resour Manag
    20:931–948 Article   Google Scholar   Reddy MJ, Kumar DN (2008) Evolving strategies
    for crop planning and operation of irrigation reservoir system using multi-objective
    differential evolution. Irrig Sci 26(2):177–190 Article   Google Scholar   Adeyemo
    J, Otieno F (2010) Differential evolution algorithm for solving multi-objective
    crop planning model. Agric Water Manag 97(6):848–856 Article   Google Scholar   Schmitz
    GH, Schütze N, Petersohn U (2002) New strategy for optimizing water application
    under trickle irrigation. J Irrig Drain Eng 128(5):287–297 Article   Google Scholar   de
    Paly M, Schutze N, Zell A (2010) Determining crop-production functions using multi-objective
    evolutionary algorithms. In: IEEE congress on evolutionary computation. IEEE,
    pp 1–8 Antonopoulou E, Karetsos S, Maliappis M, Sideridis A (2010) Web and mobile
    technologies in a prototype DSS for major field crops. Comput Electron Agric 70(2):292–301
    Article   Google Scholar   Li C, Dutta R, Kloppers C, D’Este C, Morshed A, Almeida
    A, Das A, Aryal J (2013) Mobile application based sustainable irrigation water
    usage decision support system: an intelligent sensor cloud approach. In: SENSORS,
    2013 IEEE, IEEE, 2013, pp 1–4 Bonfante A, Monaco E, Manna P, De Mascellis R, Basile
    A, Buonanno M, Cantilena G, Esposito A, Tedeschi A, De Michele C et al (2019)
    Lcis dss-an irrigation supporting system for water use efficiency improvement
    in precision agriculture: a maize case study. Agric Syst 176:102646 Article   Google
    Scholar   Ragab R (2015) Integrated management tool for water, crop, soil and
    n-fertilizers: the saltmed model. Irrig Drain 64(1):1–12 Article   MathSciNet   Google
    Scholar   Bandyopadhyay A, Bhadra A, Swarnakar R, Raghuwanshi N, Singh R (2012)
    Estimation of reference evapotranspiration using a user-friendly decision support
    system: Dss_et. Agric For Meteorol 154:19–29 Article   Google Scholar   Olberz
    M, Kahlen K, Zinkernagel J (2018) Assessing the impact of reference evapotranspiration
    models on decision support systems for irrigation. Horticulturae 4(4):49 Article   Google
    Scholar   Gocic M, Trajkovic S (2010) Software for estimating reference evapotranspiration
    using limited weather data. Comput Electron Agric 71(2):158–162 Article   Google
    Scholar   Stöckle CO, Donatelli M, Nelson R (2003) Cropsyst, a cropping systems
    simulation model. Eur J Agron 18(3–4):289–307 Article   Google Scholar   Brisson
    N, Mary B, Ripoche D, Jeuffroy MH, Ruget F, Nicoullaud B, Gate P, Devienne-Barret
    F, Antonioletti R, Durr C et al (1998) Stics: a generic model for the simulation
    of crops and their water and nitrogen balances. I. Theory and parameterization
    applied to wheat and corn. Agronomie 18(5–6):311–46 Article   Google Scholar   Williams
    J, Jones C, Dyke PT (1984) A modeling approach to determining the relationship
    between erosion and soil productivity. Trans ASAE 27(1):129–0144 Article   Google
    Scholar   Jones J, Tsuji G, Hoogenboom G, Hunt L, Thornton P, Wilkens P, Imamura
    D, Bowen W, Singh U (1998) Decision support system for agrotechnology transfer:
    Dssat v3. Understanding options for agricultural production. Springer, New York,
    pp 157–177 Chapter   Google Scholar   Giménez C, Gallardo M, Martínez-Gaitán C,
    Stöckle C, Thompson R, Granados M (2013) Vegsyst, a simulation model of daily
    crop growth, nitrogen uptake and evapotranspiration for pepper crops for use in
    an on-farm decision support system. Irrig Sci 31(3):465–477 Article   Google Scholar   Ritchie
    J, Singh U, Godwin D, Bowen W (1998) Cereal growth, development and yield. Understanding
    options for agricultural production. Springer, Cham, pp 79–98 Chapter   Google
    Scholar   Download references Acknowledgements Mandeep Kaur Saggi was supported
    by CSIR, funded by Ministry of Minority Affairs, Government of India. The authors
    wish to express their gratitude to Dr. Rakesh Sharda, Senior Extension Specialist,
    Department of Soil and Water Engineering in Punjab Agriculture University, Ludhiana
    (PAU) for his helpful suggestions. We acknowledge help rendered by Food Security
    at Thapar University. Funding Funding was provided by Council of Scientific and
    Industrial Research, India (Grant No. 09/677(0040)/2019-EMR-I). Author information
    Authors and Affiliations Department of Computer Science, Thapar Institute of Engineering
    & Technology, Patiala, India Mandeep Kaur Saggi & Sushma Jain Corresponding author
    Correspondence to Mandeep Kaur Saggi. Ethics declarations Conflict of interest
    The authors declare that they have no conflict of interest. Additional information
    Publisher''s Note Springer Nature remains neutral with regard to jurisdictional
    claims in published maps and institutional affiliations. Rights and permissions
    Reprints and permissions About this article Cite this article Saggi, M.K., Jain,
    S. A Survey Towards Decision Support System on Smart Irrigation Scheduling Using
    Machine Learning approaches. Arch Computat Methods Eng 29, 4455–4478 (2022). https://doi.org/10.1007/s11831-022-09746-3
    Download citation Received 08 May 2021 Accepted 11 April 2022 Published 09 May
    2022 Issue Date October 2022 DOI https://doi.org/10.1007/s11831-022-09746-3 Share
    this article Anyone you share the following link with will be able to read this
    content: Get shareable link Provided by the Springer Nature SharedIt content-sharing
    initiative Use our pre-submission checklist Avoid common mistakes on your manuscript.
    Sections Figures References Abstract Introduction Reference Evapotranspiration
    ET Crop Evapotranspiration ET Irrigation Scheduling Decision Support System Literature
    of Irrigation Scheduling Estimation of Crop Evapotranspiration (ET ) Decision
    Support System for Irrigation Scheduling Conclusion References Acknowledgements
    Funding Author information Ethics declarations Additional information Rights and
    permissions About this article Advertisement Discover content Journals A-Z Books
    A-Z Publish with us Publish your research Open access publishing Products and
    services Our products Librarians Societies Partners and advertisers Our imprints
    Springer Nature Portfolio BMC Palgrave Macmillan Apress Your privacy choices/Manage
    cookies Your US state privacy rights Accessibility statement Terms and conditions
    Privacy policy Help and support 129.93.161.219 Big Ten Academic Alliance (BTAA)
    (3000133814) - University of Nebraska-Lincoln (3000134173) © 2024 Springer Nature'
  inline_citation: '>'
  journal: Archives of Computational Methods in Engineering
  limitations: '>'
  pdf_link: https://link.springer.com/content/pdf/10.1007/s11831-022-09746-3.pdf
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: A Survey Towards Decision Support System on Smart Irrigation Scheduling Using
    Machine Learning approaches
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/w14223672
  analysis: '>'
  authors:
  - Fatemeh Ghobadi
  - Doosun Kang
  citation_count: 13
  full_citation: '>'
  full_text: ">\nCitation: Ghobadi, F.; Kang, D.\nMulti-Step Ahead Probabilistic\n\
    Forecasting of Daily Streamﬂow\nUsing Bayesian Deep Learning: A\nMultiple Case\
    \ Study. Water 2022, 14,\n3672. https://doi.org/10.3390/\nw14223672\nAcademic\
    \ Editors: Fi-John Chang,\nLi-Chiu Chang and Jui-Fa Chen\nReceived: 17 October\
    \ 2022\nAccepted: 11 November 2022\nPublished: 14 November 2022\nPublisher’s Note:\
    \ MDPI stays neutral\nwith regard to jurisdictional claims in\npublished maps\
    \ and institutional afﬁl-\niations.\nCopyright:\n© 2022 by the authors.\nLicensee\
    \ MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed\n\
    under\nthe\nterms\nand\nconditions of the Creative Commons\nAttribution (CC BY)\
    \ license (https://\ncreativecommons.org/licenses/by/\n4.0/).\nwater\nArticle\n\
    Multi-Step Ahead Probabilistic Forecasting of Daily Streamﬂow\nUsing Bayesian\
    \ Deep Learning: A Multiple Case Study\nFatemeh Ghobadi\nand Doosun Kang *\nDepartment\
    \ of Civil Engineering, Kyung Hee University, 1732 Deogyeong-daero, Giheung-gu,\n\
    Yongin-si 17104, Korea\n* Correspondence: doosunkang@khu.ac.kr; Tel.: +82-31-201-2513\n\
    Abstract: In recent decades, natural calamities such as drought and ﬂood have\
    \ caused widespread\neconomic and social damage. Climate change and rapid urbanization\
    \ contribute to the occurrence of\nnatural disasters. In addition, their destructive\
    \ impact has been altered, posing signiﬁcant challenges\nto the efﬁciency, equity,\
    \ and sustainability of water resources allocation and management. Uncertainty\n\
    estimation in hydrology is essential for water resources management. By quantifying\
    \ the associated\nuncertainty of reliable hydrological forecasting, an efﬁcient\
    \ water resources management plan is\nobtained. Moreover, reliable forecasting\
    \ provides signiﬁcant future information to assist risk assess-\nment. Currently,\
    \ the majority of hydrological forecasts utilize deterministic approaches. Nevertheless,\n\
    deterministic forecasting models cannot account for the intrinsic uncertainty\
    \ of forecasted values.\nUsing the Bayesian deep learning approach, this study\
    \ developed a probabilistic forecasting model\nthat covers the pertinent subproblem\
    \ of univariate time series models for multi-step ahead daily\nstreamﬂow forecasting\
    \ to quantify epistemic and aleatory uncertainty. The new model implements\nBayesian\
    \ sampling in the Long short-term memory (LSTM) neural network by using variational\n\
    inference to approximate the posterior distribution. The proposed method is veriﬁed\
    \ with three case\nstudies in the USA and three forecasting horizons. LSTM as\
    \ a point forecasting neural network model\nand three probabilistic forecasting\
    \ models, such as LSTM-BNN, BNN, and LSTM with Monte Carlo\n(MC) dropout (LSTM-MC),\
    \ were applied for comparison with the proposed model. The results show\nthat\
    \ the proposed Bayesian long short-term memory (BLSTM) outperforms the other models\
    \ in terms\nof forecasting reliability, sharpness, and overall performance. The\
    \ results reveal that all probabilistic\nforecasting models outperformed the deterministic\
    \ model with a lower RMSE value. Furthermore,\nthe uncertainty estimation results\
    \ show that BLSTM can handle data with higher variation and peak,\nparticularly\
    \ for long-term multi-step ahead streamﬂow forecasting, compared to other models.\n\
    Keywords: Bayesian neural network; forecasting uncertainty; multi-step ahead forecasting;\
    \ probabilistic\nstreamﬂow forecasting; variational inference\n1. Introduction\n\
    Sustainable water resource management is an essential requirement worldwide, and\n\
    streamﬂow forecasting is an essential component of an effective water resource\
    \ manage-\nment plan [1]. Accurate streamﬂow forecasting plays a critical role\
    \ in many decision-\nmaking scenarios related to water resource management such\
    \ as ﬂood/drought control\nand mitigation, reservoir management, hydropower generation,\
    \ sediment transport, and\nirrigation management [2]. Owing to the complex and\
    \ nonlinear characteristics associated\nwith streamﬂow [3], forecasting is challenging.\
    \ Sustainable water resource management\nplans are used to meet the requirements\
    \ of people today and in the future. To support\nrisk-aware decision-making in\
    \ water resource management, current streamﬂow forecasting\napproaches should\
    \ be improved to estimate forecasting uncertainties and leverage large\nvolumes\
    \ of data with complex dependencies [4].\nWater 2022, 14, 3672. https://doi.org/10.3390/w14223672\n\
    https://www.mdpi.com/journal/water\nWater 2022, 14, 3672\n2 of 22\nDeep learning\
    \ (DL), a sophisticated and mathematically complex evolution of machine\nlearning\
    \ (ML) algorithms, has recently received huge attention from researchers and has\n\
    gradually become the most widely used forecasting approach in hydrology [5–9].\
    \ The\nadvantage of DL is its ﬂexibility to learn massive data and the ease of\
    \ incorporating\nexogenous covariates [10]. The advantages of DL techniques over\
    \ traditional ML algorithms\nfor streamﬂow forecasting have been discussed in\
    \ many studies [1,11]. However, DL has\nnot been extensively explored in forecasting\
    \ uncertainty.\nOnly a few studies have been conducted on probabilistic approaches\
    \ to streamﬂow\nforecasting. Thus, the existing uncertainty was not addressed\
    \ by most DL approaches.\nHowever, deterministic approaches may not be as efﬁcient\
    \ as probabilistic methods and\nexhibit suboptimal performance. In general, deterministic\
    \ forecasting is widely used\nin hydrology as an input for various water resource\
    \ management plans. The transition\nfrom deterministic to probabilistic forecasting\
    \ methods with uncertainty quantiﬁcation is\nstrongly favored in academia and\
    \ industry. The primary issue in streamﬂow forecasting\nis the complex uncertainty\
    \ rooted in the stochastic characteristics of streamﬂow time\nseries. Furthermore,\
    \ probabilistic forecasting has emerged to overcome the shortcomings\nof conventional\
    \ deterministic methods and to deal with uncertainty more effectively. The\nprobabilistic\
    \ approach has recently gained importance because it can extract more valuable\n\
    information from historical data and quantify the uncertainty of the future by\
    \ forming a\nprobability distribution over possible outcomes. The probabilistic\
    \ approach extends beyond\nsingle-point forecasting for each time step and can\
    \ provide a band of likely forecasting\nintervals above and below the mean forecasted\
    \ value. Existing deterministic methods report\nthe mean of possible outcomes,\
    \ and they are unable to reﬂect the inherent uncertainty that\nexists in the real\
    \ world.\nDespite the fact that hydrological prediction can be most helpful when\
    \ given in proba-\nbilistic form [12], the use of probabilistic modeling is still\
    \ a relatively new concept in the\nﬁeld of hydrology [13]. Moreover, the probabilistic\
    \ approach is crucial to optimal decision-\nmaking that reveals the upper and\
    \ lower bounds between which the uncertain actual\nfuture values may exist. Occasionally,\
    \ decision-making requires more than single-point\nforecasting; this is where\
    \ distribution would be beneﬁcial. To make reliable forecasts and\nto conduct\
    \ a comprehensive performance evaluation, a probabilistic approach should be\n\
    considered in streamﬂow forecasting. Most existing streamﬂow forecasting methods\
    \ focus\non deterministic forecasting. The application of various machine learning\
    \ algorithms in\ndeterministic prediction has been investigated in many studies\
    \ [14–19]. Limited research\nhas been conducted on multistep-ahead streamﬂow predictions\
    \ [1,20–23]. Even though\nconsiderable efforts have been made to improve the performance\
    \ of streamﬂow forecasting\nmodels from short- to long-term [24,25] and from single-\
    \ to multi-step ahead [9,26,27], they\nare still limited by uncertainties [28–31].\n\
    An effective way to perform probability forecasting in the ﬁeld of hydrology is\
    \ to apply\nthe Bayesian approach due to the beneﬁts of uncertainty representation,\
    \ understanding\ngeneralization, and reliable prediction through the lens of probability\
    \ theory. The Bayesian\napproach can be classiﬁed into four primary groups: Bayesian\
    \ model averaging (BMA),\nBayesian model updating (BMU), Bayesian networks (BN),\
    \ and Bayesian neural networks\n(BNN) [32]. A BNN is a type of stochastic artiﬁcial\
    \ neural network that uses a BMU for\ntraining and updating the probabilistic\
    \ distributions of network parameters. Furthermore,\nBMU and BN have become prevalent,\
    \ and they have been implemented in various ﬁelds\nsuch as computer vision, natural\
    \ language processing, medical diagnostics, autonomous\ndriving, and ﬂood hazard\
    \ analysis [32]. Han and Coulibaly [33] presented a comprehensive\nreview of Bayesian\
    \ approaches applied to ﬂood forecasting from 1999 to 2015. The results\nreveal\
    \ that probabilistic ﬂood forecasting can reduce uncertainty and provide more\
    \ accurate\nand reliable forecasting. Moreover, they mentioned that only a limited\
    \ number of river\nbasins have been studied from the Bayesian perspective to date.\
    \ Furthermore, we should\ndetermine if the Bayesian approaches are suitable for\
    \ different watersheds with different\nsizes and physical and climatic characteristics.\
    \ Costa and Fernandes [34] developed a\nWater 2022, 14, 3672\n3 of 22\nBayesian\
    \ framework to estimate the extreme ﬂood quantile from a rainfall-runoff model\
    \ of a\ndam in California. Xu et al. [35] developed a real-time probabilistic\
    \ channel ﬂood forecasting\nmodel by combining a hydraulic model with the Bayesian\
    \ approach in the upstream\nreaches of the Three Gorges Dam on the Yangtze River,\
    \ China. A state-of-the-art review\nwas provided by Huang et al. [36] to summarize\
    \ the application of Bayesian inference in\nsystem identiﬁcation and damage assessment\
    \ for civil infrastructure. Goodarzi et al. [37]\nproposed a decision-making model\
    \ using BN to predict heavy precipitation in the Kan Basin.\nBayesian neural networks\
    \ are yet to be applied to probabilistic streamﬂow forecasting,\nas aforementioned.\n\
    Recent studies on probabilistic prediction in the ﬁeld of hydrology are summarized\n\
    in Table 1. As shown in Table 1, a few researchers trained a deterministic model\
    \ and used\nthe obtained deterministic result to obtain a probabilistic forecasting\
    \ result to estimate the\nuncertainty [38]. However, in a few studies, a deterministic\
    \ layer has been coupled with a\nprobabilistic layer to achieve forecasting uncertainty\
    \ [39]. Conversely, a few studies have\nfocused on developing a probabilistic\
    \ model by introducing stochastic components into the\nnetwork by giving the network\
    \ either stochastic activation or weights [40–42].\nTable 1. Overview of recent\
    \ probabilistic prediction studies in the ﬁeld of hydrology.\nField\nProbabilistic\
    \ Method\nBase Models\nPosterior Approximation *\nEvaluation Metrics\nRef.\nVI\n\
    MCM\nDeterministic\nProbabilistic\nStreamﬂow\nLSTM-HetGP\nANN, HetGP, GLM,\nLSTM\n\
    -\n-\nNSE, RMSE,\nMRE, MSLE\npercentage of\ncoverage (POC) and\nthe average interval\n\
    width (AIW)\n[39]\nFlood\nLSTM\nARIMA\n-\n-\nRMSE, MAE\n[40]\nStreamﬂow\nLSTM\
    \ with\nmultiparameter\nensemble and dropout\nensemble\n_\n-\n \nwatersheds with\
    \ different sizes and physical and climatic characteristics. Costa and \nFernandes\
    \ [34] developed a Bayesian framework to estimate the extreme flood quantile \n\
    from a rainfall-runoff model of a dam in California. Xu et al. [35] developed\
    \ a real-time \nprobabilistic channel flood forecasting model by combining a hydraulic\
    \ model with the \nBayesian approach in the upstream reaches of the Three Gorges\
    \ Dam on the Yangtze \nRiver, China. A state-of-the-art review was provided by\
    \ Huang et al. [36] to summarize \nthe application of Bayesian inference in system\
    \ identification and damage assessment for \ncivil infrastructure. Goodarzi et\
    \ al. [37] proposed a decision-making model using BN to \npredict heavy precipitation\
    \ in the Kan Basin. Bayesian neural networks are yet to be ap-\nplied to probabilistic\
    \ streamflow forecasting, as aforementioned. \nRecent studies on probabilistic\
    \ prediction in the field of hydrology are summarized \nin Table 1. As shown in\
    \ Table 1, a few researchers trained a deterministic model and used \nthe obtained\
    \ deterministic result to obtain a probabilistic forecasting result to estimate\
    \ the \nuncertainty [38]. However, in a few studies, a deterministic layer has\
    \ been coupled with \na probabilistic layer to achieve forecasting uncertainty\
    \ [39]. Conversely, a few studies have \nfocused on developing a probabilistic\
    \ model by introducing stochastic components into \nthe network by giving the\
    \ network either stochastic activation or weights [40–42]. \nTable 1. Overview\
    \ of recent probabilistic prediction studies in the field of hydrology. \nField\
    \ \nProbabilistic Method \nBase Models \nPosterior Approxima-\ntion * \nEvaluation\
    \ Metrics \nRef. \nVI \nMCM \nDeterministic \nProbabilistic \nStreamflow \nLSTM-HetGP\
    \ \nANN, HetGP, \nGLM, LSTM \n- \n- \nNSE, RMSE, MRE, \nMSLE \npercentage of cov-\n\
    erage (POC) and \nthe average inter-\nval \nwidth (AIW) \n [39] \nFlood \nLSTM\
    \ \nARIMA \n- \n- \nRMSE, MAE \n[40] \nStreamflow \nLSTM with multiparame-\nter\
    \ \nensemble and dropout \nensemble \n_ \n- \n \nPBIAS, MARE, \nRMSE, NSE, KGE\
    \ \nPOC, average \nwidth (AW), aver-\nage \ninterval score \n(AIS) \n[41] \nStream-\n\
    flow \nVariational Bayesian Long \nShort-Term Memory net-\nwork (VB-LSTM) \nBayesian\
    \ model \nAveraging (BMA) \n \n- \nMAE \nCRPS \n[42] \nRunoff \nXGBoost (XGB)\
    \ \nand Gaussian process re-\ngression (GPR) with \nBayesian optimization al-\n\
    gorithm (BOA) \nGBR, LGB, CNN, \nLSTM, ANN, SVR, \nQR, GPR—com-\nbined with GPR\
    \ \n- \n- \nRMSE, MAPE, R2 \nCoverage proba-\nbility, Mean width \npercentage,\
    \ Suita-\nbility metric, CRPS \n[38] \nRunoff \nB-spline quantile regres-\nsion\
    \ model combined \nwith kernel density esti-\nmation \nQR, QRNN \n- \n- \nRMSE,\
    \ R2, Qr \nPICP, PINAW, \nCRPS \n[43] \nPBIAS, MARE,\nRMSE, NSE,\nKGE\nPOC, average\n\
    width (AW), average\ninterval score (AIS)\n[41]\nStreamﬂow\nVariational Bayesian\
    \ Long\nShort-Term Memory\nnetwork (VB-LSTM)\nBayesian model\nAveraging (BMA)\n\
    \ \na limited number of river basins have been studied from the Bayesian perspective\
    \ to date. \nFurthermore, we should determine if the Bayesian approaches are suitable\
    \ for different \nwatersheds with different sizes and physical and climatic characteristics.\
    \ Costa and \nFernandes [34] developed a Bayesian framework to estimate the extreme\
    \ flood quantile \nfrom a rainfall-runoff model of a dam in California. Xu et\
    \ al. [35] developed a real-time \nprobabilistic channel flood forecasting model\
    \ by combining a hydraulic model with the \nBayesian approach in the upstream\
    \ reaches of the Three Gorges Dam on the Yangtze \nRiver, China. A state-of-the-art\
    \ review was provided by Huang et al. [36] to summarize \nthe application of Bayesian\
    \ inference in system identification and damage assessment for \ncivil infrastructure.\
    \ Goodarzi et al. [37] proposed a decision-making model using BN to \npredict\
    \ heavy precipitation in the Kan Basin. Bayesian neural networks are yet to be\
    \ ap-\nplied to probabilistic streamflow forecasting, as aforementioned. \nRecent\
    \ studies on probabilistic prediction in the field of hydrology are summarized\
    \ \nin Table 1. As shown in Table 1, a few researchers trained a deterministic\
    \ model and used \nthe obtained deterministic result to obtain a probabilistic\
    \ forecasting result to estimate the \nuncertainty [38]. However, in a few studies,\
    \ a deterministic layer has been coupled with \na probabilistic layer to achieve\
    \ forecasting uncertainty [39]. Conversely, a few studies have \nfocused on developing\
    \ a probabilistic model by introducing stochastic components into \nthe network\
    \ by giving the network either stochastic activation or weights [40–42]. \nTable\
    \ 1. Overview of recent probabilistic prediction studies in the field of hydrology.\
    \ \nField \nProbabilistic Method \nBase Models \nPosterior Approxima-\ntion *\
    \ \nEvaluation Metrics \nRef. \nVI \nMCM \nDeterministic \nProbabilistic \nStreamflow\
    \ \nLSTM-HetGP \nANN, HetGP, \nGLM, LSTM \n- \n- \nNSE, RMSE, MRE, \nMSLE \npercentage\
    \ of cov-\nerage (POC) and \nthe average inter-\nval \nwidth (AIW) \n [39] \n\
    Flood \nLSTM \nARIMA \n- \n- \nRMSE, MAE \n[40] \nStreamflow \nLSTM with multiparame-\n\
    ter \nensemble and dropout \nensemble \n_ \n- \n \nPBIAS, MARE, \nRMSE, NSE,\
    \ KGE \nPOC, average \nwidth (AW), aver-\nage \ninterval score \n(AIS) \n[41]\
    \ \nStream-\nflow \nVariational Bayesian Long \nShort-Term Memory net-\nwork (VB-LSTM)\
    \ \nBayesian model \nAveraging (BMA) \n \n- \nMAE \nCRPS \n[42] \nRunoff \nXGBoost\
    \ (XGB) \nand Gaussian process re-\ngression (GPR) with \nBayesian optimization\
    \ al-\ngorithm (BOA) \nGBR, LGB, CNN, \nLSTM, ANN, SVR, \nQR, GPR—com-\nbined\
    \ with GPR \n- \n- \nRMSE, MAPE, R2 \nCoverage proba-\nbility, Mean width \npercentage,\
    \ Suita-\nbility metric, CRPS \n[38] \nRunoff \nB-spline quantile regres-\nsion\
    \ model combined \nwith kernel density esti-\nmation \nQR, QRNN \n- \n- \nRMSE,\
    \ R2, Qr \nPICP, PINAW, \nCRPS \n[43] \n-\nMAE\nCRPS\n[42]\nRunoff\nXGBoost (XGB)\n\
    and Gaussian process\nregression (GPR) with\nBayesian optimization\nalgorithm\
    \ (BOA)\nGBR, LGB, CNN, LSTM,\nANN, SVR, QR,\nGPR—combined\nwith GPR\n-\n-\nRMSE,\
    \ MAPE,\nR2\nCoverage probability,\nMean width\npercentage,\nSuitability metric,\n\
    CRPS\n[38]\nRunoff\nB-spline quantile\nregression model\ncombined with kernel\n\
    density estimation\nQR, QRNN\n-\n-\nRMSE, R2, Qr\nPICP, PINAW, CRPS\n[43]\nStreamﬂow\n\
    Bayesian LSTM model\nphysics-based\nhydrologic model\n(Precipitation-Runoff\n\
    Modeling System)\n-\nWater 2022, 14, x FOR PEER REVIEW \n3 of 23 \n \na limited\
    \ number of river basins have been studied from the Bayesian perspective to date.\
    \ \nFurthermore, we should determine if the Bayesian approaches are suitable for\
    \ different \nwatersheds with different sizes and physical and climatic characteristics.\
    \ Costa and \nFernandes [34] developed a Bayesian framework to estimate the extreme\
    \ flood quantile \nfrom a rainfall-runoff model of a dam in California. Xu et\
    \ al. [35] developed a real-time \nprobabilistic channel flood forecasting model\
    \ by combining a hydraulic model with the \nBayesian approach in the upstream\
    \ reaches of the Three Gorges Dam on the Yangtze \nRiver, China. A state-of-the-art\
    \ review was provided by Huang et al. [36] to summarize \nthe application of Bayesian\
    \ inference in system identification and damage assessment for \ncivil infrastructure.\
    \ Goodarzi et al. [37] proposed a decision-making model using BN to \npredict\
    \ heavy precipitation in the Kan Basin. Bayesian neural networks are yet to be\
    \ ap-\nplied to probabilistic streamflow forecasting, as aforementioned. \nRecent\
    \ studies on probabilistic prediction in the field of hydrology are summarized\
    \ \nin Table 1. As shown in Table 1, a few researchers trained a deterministic\
    \ model and used \nthe obtained deterministic result to obtain a probabilistic\
    \ forecasting result to estimate the \nuncertainty [38]. However, in a few studies,\
    \ a deterministic layer has been coupled with \na probabilistic layer to achieve\
    \ forecasting uncertainty [39]. Conversely, a few studies have \nfocused on developing\
    \ a probabilistic model by introducing stochastic components into \nthe network\
    \ by giving the network either stochastic activation or weights [40–42]. \nTable\
    \ 1. Overview of recent probabilistic prediction studies in the field of hydrology.\
    \ \nField \nProbabilistic Method \nBase Models \nPosterior Approxima-\ntion *\
    \ \nEvaluation Metrics \nRef. \nVI \nMCM \nDeterministic \nProbabilistic \nStreamflow\
    \ \nLSTM-HetGP \nANN, HetGP, \nGLM, LSTM \n- \n- \nNSE, RMSE, MRE, \nMSLE \npercentage\
    \ of cov-\nerage (POC) and \nthe average inter-\nval \nwidth (AIW) \n [39] \n\
    Flood \nLSTM \nARIMA \n- \n- \nRMSE, MAE \n[40] \nStreamflow \nLSTM with multiparame-\n\
    ter \nensemble and dropout \nensemble \n_ \n- \n \nPBIAS, MARE, \nRMSE, NSE,\
    \ KGE \nPOC, average \nwidth (AW), aver-\nage \ninterval score \n(AIS) \n[41]\
    \ \nStream-\nflow \nVariational Bayesian Long \nShort-Term Memory net-\nwork (VB-LSTM)\
    \ \nBayesian model \nAveraging (BMA) \n \n- \nMAE \nCRPS \n[42] \nRunoff \nXGBoost\
    \ (XGB) \nand Gaussian process re-\ngression (GPR) with \nBayesian optimization\
    \ al-\ngorithm (BOA) \nGBR, LGB, CNN, \nLSTM, ANN, SVR, \nQR, GPR—com-\nbined\
    \ with GPR \n- \n- \nRMSE, MAPE, R2 \nCoverage proba-\nbility, Mean width \npercentage,\
    \ Suita-\nbility metric, CRPS \n[38] \nRunoff \nB-spline quantile regres-\nsion\
    \ model combined \nwith kernel density esti-\nmation \nQR, QRNN \n- \n- \nRMSE,\
    \ R2, Qr \nPICP, PINAW, \nCRPS \n[43] \nNSE, RMSE-observations standard\ndeviation\
    \ ratio (RSR)\n[44]\n* The tick mark (\nFOR PEER REVIEW \n3 of 23 \na limited\
    \ number of river basins have been studied from the Bayesian perspective to date.\
    \ \nFurthermore, we should determine if the Bayesian approaches are suitable for\
    \ different \nwatersheds with different sizes and physical and climatic characteristics.\
    \ Costa and \nFernandes [34] developed a Bayesian framework to estimate the extreme\
    \ flood quantile \nfrom a rainfall-runoff model of a dam in California. Xu et\
    \ al. [35] developed a real-time \nprobabilistic channel flood forecasting model\
    \ by combining a hydraulic model with the \nBayesian approach in the upstream\
    \ reaches of the Three Gorges Dam on the Yangtze \nRiver, China. A state-of-the-art\
    \ review was provided by Huang et al. [36] to summarize \nthe application of Bayesian\
    \ inference in system identification and damage assessment for \ncivil infrastructure.\
    \ Goodarzi et al. [37] proposed a decision-making model using BN to \npredict\
    \ heavy precipitation in the Kan Basin. Bayesian neural networks are yet to be\
    \ ap-\nplied to probabilistic streamflow forecasting, as aforementioned. \nRecent\
    \ studies on probabilistic prediction in the field of hydrology are summarized\
    \ \nin Table 1. As shown in Table 1, a few researchers trained a deterministic\
    \ model and used \nthe obtained deterministic result to obtain a probabilistic\
    \ forecasting result to estimate the \nuncertainty [38]. However, in a few studies,\
    \ a deterministic layer has been coupled with \na probabilistic layer to achieve\
    \ forecasting uncertainty [39]. Conversely, a few studies have \nfocused on developing\
    \ a probabilistic model by introducing stochastic components into \nthe network\
    \ by giving the network either stochastic activation or weights [40–42]. \nTable\
    \ 1. Overview of recent probabilistic prediction studies in the field of hydrology.\
    \ \nobabilistic Method \nBase Models \nPosterior Approxima-\ntion * \nEvaluation\
    \ Metrics \nRef. \nVI \nMCM \nDeterministic \nProbabilistic \nLSTM-HetGP \nANN,\
    \ HetGP, \nGLM, LSTM \n- \n- \nNSE, RMSE, MRE, \nMSLE \npercentage of cov-\nerage\
    \ (POC) and \nthe average inter-\nval \nwidth (AIW) \n [39] \nLSTM \nARIMA \n\
    - \n- \nRMSE, MAE \n[40] \nM with multiparame-\nter \nemble and dropout \nensemble\
    \ \n_ \n- \n \nPBIAS, MARE, \nRMSE, NSE, KGE \nPOC, average \nwidth (AW), aver-\n\
    age \ninterval score \n(AIS) \n[41] \national Bayesian Long \nt-Term Memory net-\n\
    work (VB-LSTM) \nBayesian model \nAveraging (BMA) \n \n- \nMAE \nCRPS \n[42]\
    \ \nXGBoost (XGB) \nGaussian process re-\nession (GPR) with \nsian optimization\
    \ al-\ngorithm (BOA) \nGBR, LGB, CNN, \nLSTM, ANN, SVR, \nQR, GPR—com-\nbined\
    \ with GPR \n- \n- \nRMSE, MAPE, R2 \nCoverage proba-\nbility, Mean width \npercentage,\
    \ Suita-\nbility metric, CRPS \n[38] \npline quantile regres-\nn model combined\
    \ \nh kernel density esti-\nmation \nQR, QRNN \n- \n- \nRMSE, R2, Qr \nPICP, PINAW,\
    \ \nCRPS \n[43] \n) denotes the application of Posterior Approximation.\nThe application\
    \ of probabilistic DL showed superior performance in various ﬁelds,\nincluding\
    \ residential net load forecasting [45,46], short-term scheduling in power mar-\n\
    kets [47], photovoltaic power [48], load forecasting for buildings [49], and electricity\n\
    consumption [50]. This indicates the wide range of the potential applicability\
    \ of the\nprobabilistic DL approaches. Univariate streamﬂow forecasting using\
    \ conventional data-\ndriven models has been investigated in the previous studies\
    \ [51–54]. To the best of the\nauthors’ knowledge, the application of BLSTM in\
    \ multi-step ahead probabilistic prediction\nusing a retrospective univariate\
    \ time series has not been applied to streamﬂow prediction\nyet. To address the\
    \ aforementioned research gaps, this study proposed a framework for\ntransforming\
    \ a deterministic model into a probabilistic model with improved performance.\n\
    Water 2022, 14, 3672\n4 of 22\nThis study developed a Bayesian deep neural network\
    \ framework to characterize the\nprognostic uncertainties for probabilistic streamﬂow\
    \ forecasting, which investigated both\nepistemic and aleatoric uncertainties.\
    \ The motivation of the framework was to transform\nexisting deterministic prediction\
    \ models into their probabilistic counterparts for better\nperformance in water\
    \ resources management and decision-making, and to cover newly\nemerged challenges\
    \ that humankind encountered primarily due to climate change.\nThe primary contributions\
    \ of the study are as follows: For the ﬁrst time, in stream-\nﬂow prediction,\
    \ we introduced the Bayesian LSTM network’s application for multi-step\nahead\
    \ probabilistic forecasting in water resource management. Bayesian theory and\
    \ LSTM\nnetworks were combined to generate probabilistic streamﬂow forecasts to\
    \ capture both\nepistemic and aleatoric uncertainties. This is the ﬁrst study\
    \ to exploit Bayesian deep learn-\ning for streamﬂow prediction. Moreover, a comprehensive\
    \ comparison with a series of\nstate-of-the-art probabilistic prediction methods\
    \ is conducted. The superior performance\nof the proposed scheme was demonstrated\
    \ with respect to both the deterministic and\nprobabilistic forecasting results.\
    \ Moreover, to demonstrate the superiority of probabilis-\ntic forecasting, particularly\
    \ for water resource management, a comparative analysis was\nconducted for three\
    \ case studies with different forecasting horizons and timescales.\nThe paper\
    \ is organized as follows: In Section 2, the materials and methods are pre-\n\
    sented in subsections on Bayesian long-short-term memory (BLSTM) (2.1), experimental\n\
    setup (2.2), and performance evaluation (2.3). In Section 3, the case study, study\
    \ area (3.1),\nand experimental setup (3.2) are detailed. The results are presented\
    \ in Section 4, with two\nsubsections focusing on the probabilistic forecasting\
    \ performance assessment (4.1) and the\nimpact of the forecast horizon on probabilistic\
    \ forecasting performance (4.2). Furthermore,\nthe concluding remarks of this\
    \ study with directions for future research are discussed in\nSection 5.\n2. Materials\
    \ and Methods\nThe proposed Bayesian deep-learning approach for probabilistic\
    \ streamﬂow forecast-\ning is presented in detail in the following sections.\n\
    2.1. Bayesian Long Short-Term Memory (BLSTM)\nIn this study, the Bayesian approach\
    \ is employed, which is a well-established and\nthorough approach to ﬁt probabilistic\
    \ models that capture and distinguish different sources\nof uncertainties [55].\
    \ The BNN is a stochastic artiﬁcial neural network (ANN) trained using\nthe Bayesian\
    \ approach. Probability is deﬁned in terms of the degree of belief in the Bayesian\n\
    approach; the more likely an outcome is, the higher its degree of belief. The\
    \ primary idea of\nthe Bayesian approach in deep learning is to replace each weight\
    \ with a distribution [56]. An\nLSTM network overcomes the long-term dependency\
    \ issue of conventional RNNs through\nadditional interactions in its various unit\
    \ cells. Additionally, LSTM cells (memory cells)\nare composed of three gates\
    \ (input, forget, and output) for short-term memory selection\nand a state vector\
    \ transmission responsible for long-term memory. Information can be\nselectively\
    \ passed during the learning procedure by manipulating the gate settings. The\n\
    LSTM network is mathematically represented as follows [57]:\nit = σ(Wi.[ht−1,\
    \ xt] + bi) ft = σ(Wf .[ht−1, xt] + bf ),\n(1)\not = σ(Wo.[ht−1, xt] + bo),\n\
    (2)\nht = ot × tanh(Ct),\n(3)\neC = tanh(Wc.[ht−1, xt] + bc),\n(4)\nCt = ft ◦\
    \ Ct−1 + it ◦ eC,\n(5)\nσ(x) = sigmoid(x) =\n1\n1 + e−x ,\n(6)\nWater 2022, 14,\
    \ 3672\n5 of 22\ntanh(x) = ex − e−x\nex + e−x ,\n(7)\nwhere at time step t, xt\
    \ is the input vector, ht is the LSTM output and hidden state (short-\nterm memory),\
    \ and it, ft, and ot are the input, forget, and output gates, respectively. W\n\
    and b are the weight matrix and bias, respectively. Ct is the current cell state\
    \ (long-term\nmemory), and eC is the candidate cell state value. σ is a sigmoid\
    \ activation function that\nuses ht−1 and xt to make decisions regarding the input,\
    \ forget, and output gates [57].\nGiven the input data, Xtrain = [x1, . . . ,\
    \ xTrain] and their corresponding output labels\nYtrain = [y1, . . . , yTrain].\
    \ The primary goal of the Bayesian approach is to identify the\nparameter W of\
    \ a function y = fW(x) that probably generates the desired output [58,59]. In\n\
    this approach, a prior distribution that represents the prior belief about the\
    \ neural network\nparameter distribution before observing the inputs is employed\
    \ over W to capture epistemic\nuncertainty. The Bayesian neural network structure\
    \ is illustrated in Figure 1. Rather than a\nsingle network, this method trains\
    \ a set of networks in which the weight of each network is\nderived from a shared\
    \ learning probability distribution [59].\nFigure 1. Structure of the Bayesian\
    \ neural network.\nSetting a standard normal distribution as a prior with zero\
    \ mean, which can bring\nthe beneﬁt of regularization, has been demonstrated as\
    \ one of the most effective solutions\nwhen the prior distribution is difﬁcult\
    \ to identify. After training the Bayesian deep neural\nnetwork and observing\
    \ data, the model likelihood distribution p\n\0YTrain\n\f\f f W\x01\nshould be\n\
    deﬁned as a normal distribution N\n\0f W(XTrain\n\x01\n, σ2) and observation noise\
    \ σ to capture\nroughly suitable parameters. Based on the Bayesian rule, the posterior\
    \ p(W|XTrain, YTrain)\nis employed over the weights to generate samples of predictions\
    \ rather than the prior\ndistribution. The posterior is calculated as follows\
    \ [59]:\np(W|XTrain, YTrain) = p(YTrain|XTrain, W).p(W)\np(YTrain|XTrain)\n(8)\n\
    where p(YTrain|XTrain) is the marginal likelihood probability that cannot be estimated,\n\
    thereby, the posterior is not tractable without a variational inference to approximate\
    \ it.\nWith this distribution, suitable parameters given by the input data can\
    \ be captured, and the\noutput y can be predicted for a new input x by integration\
    \ [58]:\np(y|x, XTrain, YTrain) =\nZ\np(y|x, W)p(W|XTrain, YTrain)dW.\n(9)\nWater\
    \ 2022, 14, 3672\n6 of 22\nTo evaluate the true posterior p(W|XTrain, YTrain),\
    \ an approximation variational dis-\ntribution qθ(W), which is parameterized by\
    \ θ, is required to ensure that the optimal dis-\ntribution eqθ(W) can represent\
    \ the posterior by minimizing the Kullback–Leibler (KL)\ndivergence [60] between\
    \ the approximation variational and posterior distributions [61]:\nKL(qθ(W) ∥\
    \ p(W|XTrain, YTrain)) =\nZ\nqθ(W) log\nqθ(W)\np(W|XTrain, YTrain)dW.\n(10)\n\
    Generally, two methods are available to approximate the posterior distribution:\
    \ vari-\national inference (VI) and Monte Carlo (MC) dropout [56,61,62]. The study\
    \ employed\nthe VI to solve the optimization issue analytically. Interested readers\
    \ can refer to [62] for\ndetailed information on the approximation method. The\
    \ predictive distribution can be\napproximated by:\np(y|x, XTrain, YTrain) =\n\
    Z\np(y|x, W)eqθ(W)dW = eqθ(y|x).\n(11)\n2.1.1. Epistemic Uncertainty\nMathematically,\
    \ by simulating the model based on input x, the predictive mean can be\nestimated\
    \ with an unbiased estimator, as follows [63]:\neE[y] := 1\nT\nT\n∑\nt=1\nf ˆWt(x),\n\
    (12)\nwhere eE[y] is the predictive mean, f ˆWt is the stochastic output of the\
    \ prediction model,\nˆWt represents the sample weights, and T denotes the number\
    \ of samples at time t. Simi-\nlar to the estimation of the predictive mean, given\
    \ that\nˆWt ∼ eqθ(W) and p\n\0y\n\f\f f W(x)\n\x01 =\nN\n\0y; f w(x), σ2\x01\n\
    for σ > 0, the predictive variance can be estimated by an unbiased estima-\ntor\
    \ as follows [63]:\neE\nh\nyTy\ni\n:= 1\nT\nT\n∑\nt=1\nf ˆWt(x)T f ˆWt(x) + σ2.\n\
    (13)\nThe term σ2 corresponds to inherent noise in the input data. Afterward,\
    \ the epistemic\nuncertainty, which represents the uncertainty of the model about\
    \ its prediction outputs, is\ncaptured by the predictive variance that can be\
    \ approximated as [63]:\ng\nVar[y] = eE\nh\nyTy\ni\n− eE[y]TeE[y].\n(14)\n2.1.2.\
    \ Aleatoric Uncertainty\nAleatoric uncertainty can be divided into homoscedastic\
    \ and heteroscedastic uncer-\ntainties. To capture the aleatoric uncertainty,\
    \ parameter σ should be tuned. For each input\nx, in the homoscedastic uncertainty,\
    \ the observation noise σ is assumed to be constant. In\ncontrast, heteroscedastic\
    \ uncertainty assumes that observation noise varies with the input.\nHeteroscedastic\
    \ models are data-dependent and can be expressed as:\nL(θ) =\n1\nTtrain ∑\nTtrain\n\
    i=1\n1\n2σ(xi)2 ∥ yi − f (xi)2 ∥ +1\n2log(xi)2.\n(15)\nBecause the maximum posterior\
    \ is performed to ﬁnd a single value for parameter θ,\nthis approach does not\
    \ capture the epistemic uncertainty since it is a property of the model,\nnot\
    \ the input data.\n2.1.3. Combining Aleatoric and Epistemic Uncertainty\nAbdar\
    \ et al. [64] explained that an effective way to combine both uncertainties in\
    \ a\nsingle model is to transform the heteroscedastic model into a Bayesian model\
    \ by placing\nWater 2022, 14, 3672\n7 of 22\na distribution over its weight and\
    \ bias parameters. Thus, both the predictive mean and\nvariance were derived from\
    \ the developed prediction model.\nh\nˆy, ˆσ2i\n= f W\nM (X),\n(16)\nwhere f W\n\
    M is the prediction model (BLSTM) used in this study, parameterized by the model\n\
    weight ˆW [55,56]. The Gaussian likelihood is used to model the aleatoric uncertainty,\
    \ and\nthe ﬁnal loss function of the prediction model can be expressed as [58]:\n\
    LM(θ) =\n1\nTtrain ∑\nTtrain\ni=1\n1\n2σ(xi)2 ∥ yi − ˆyi ∥2 +1\n2logˆσi\n2.\n\
    (17)\nFinally, the predictive uncertainty of the prediction model, consisting\
    \ of both aleatoric\nand epistemic uncertainties, can be approximated as\ng\n\
    Var[y] =\n1\nTsample ∑\nTsample\nt=1\nˆyt2 −\n \n1\nTsample ∑\nTsample\nt=1\n\
    ˆyt\n!2\n+\n1\nTsample ∑\nTsample\nt=1\nˆσt2,\n(18)\nwhere Tsample denotes the\
    \ number of training samples. An example of the Bayesian LSTM\ncell of the proposed\
    \ BLSTM network is shown in Figure 2, with a zoomed-in plot of the\nforget gate\
    \ at time step t in the ﬁrst layer.\nFigure 2. Example of the proposed BLSTM network\
    \ with a zoomed-in plot of the forget gate at time\nstep t in the ﬁrst layer.\n\
    2.2. Performance Evaluation Metrics\nTo assess the performance of the prediction\
    \ models, this study adopted the root mean\nsquare error (RMSE) metric for deterministic\
    \ prediction and three metrics for probabilistic\nprediction: continuous ranked\
    \ probability score (CRPS), prediction interval coverage\nprobability (PICP),\
    \ and mean prediction interval width (MPIW), which are formulated\nas follows.\n\
    Water 2022, 14, 3672\n8 of 22\n1.\nMetric for Deterministic Forecasting\nTo evaluate\
    \ the accuracy of the deterministic forecasting results, the root-mean-square\n\
    error (RMSE) was selected as a commonly used hydrological evaluation indicator.\
    \ The\nRMSE is deﬁned as follows:\nRMSE\nr\n1\nn ∑\nn\ni=1 (Yi − ˆYi)\n2,\n(19)\n\
    where ˆYi is the predicted variable, Yi is the observed value, and n is the number\
    \ of samples.\n2.\nMetrics for Probabilistic Forecasting\nA useful metric to assess\
    \ the accuracy of probabilistic prediction models is the CRPS.\nThe CRPS expresses\
    \ the distance between the probabilistic forecast p and the observed\nvalue Yi\
    \ and is deﬁned as\nCRPS =\nZ +∞\n−∞\n\x02\nP\n\0 ˆYi\n\x01 − H\n\0 ˆYi − Yi\n\
    \x01\x032d ˆYi,\n(20)\nP\n\0 ˆYi\n\x01 =\nZ ˆYi\n−∞ p(x)dx,\n(21)\nH\n\0 ˆYi −\
    \ Yi\n\x01 =\n\x1A0 for ˆYi < Yi\n1 for ˆYi ≥ Yi\n,\n(22)\nwhere p(x) is the probability\
    \ density function (PDF), P\n\0 ˆYi\n\x01\nis the prediction cumulative dis-\n\
    tribution function (CDF), and H is the Heaviside step function, which equals 0\
    \ if ˆYi < Yi and\nequals 1 otherwise.\nThe mean prediction interval width (MPIW)\
    \ is an effective representation of sharpness\nin probabilistic predictions. This\
    \ metric is deﬁned as\nMPIW = 1\nn ∑\nn\ni=1( ˆYi\nu − ˆYi\nl),\n(23)\nwhere n\
    \ is the size of the test set, and ˆYiu and ˆYil denote the upper and lower bounds\
    \ of the\n95% prediction interval, respectively.\nPrediction interval coverage\
    \ probability (PICP) or (PI) is the probability that the target\nlies within the\
    \ interval provided by the prediction model. PICP is deﬁned as:\nPICP = 1\nn ∑\n\
    n\ni=1 ci, ci =\n\n\n\n1, i f Yi ∈\nh\nˆYil, ˆYiui\n0, i f Yi /∈\nh\nˆYil,\
    \ ˆYiui .\n(24)\nThus, PICP indicates the frequency with which the prediction\
    \ interval (PI) captures\nthe observed value, ranging from 0 if all predicted\
    \ values lie outside the PI and 1 if all\npredicted values lie inside the PI.\n\
    3. Case Study\nTo evaluate the performance of the probabilistic data-driven models\
    \ under different\nconditions, three basins in the United States with different\
    \ hydroclimatic conditions and\ndrainage areas were selected as study areas, as\
    \ described in the following section.\n3.1. Study Area\nThe study basins were\
    \ located in different climate regions of three states across the\nUnited States,\
    \ i.e., IN (Indiana), MN (Minnesota), and CA (California). Figure 3 shows the\n\
    locations of the three basins. The ﬁrst case study was conducted in Bartholomew\
    \ County,\nIN, the second was conducted in Koochiching County, MN, and third was\
    \ conducted in Shasta\nCounty, CA. The drainage area of the river basins was approximately\
    \ 1560–4420 km2.\nWater 2022, 14, 3672\n9 of 22\nFigure 3. Location of 3 study\
    \ basins in different climate regions across the United States.\nBased on the\
    \ USGS statewide streamﬂow–water year 2021 report, the annual mean\nstreamﬂow\
    \ was ranked by state from 1 to 92, indicating the maximum and minimum\nannual\
    \ ﬂow for all years analyzed. Streamﬂow rankings were grouped into categories\n\
    of much below normal, below normal, normal, above normal, and much above normal\n\
    based on percentiles of ﬂow (<10%, 10–24%, 25–75%, 76–90%, and >90%, respectively)\
    \ [65].\nMuch-below-normal streamﬂow with a rank 84–91 is reported in CA and below-normal\n\
    streamﬂow with a rank 70–83 is reported in MN. The annual mean streamﬂow rank\
    \ for\nIN was reported to be normal, with a rank 24–50. Daily historical streamﬂow\
    \ data for the\nthree selected case studies were obtained from the United States\
    \ Geological Survey (USGS)\nwebsite, (https://waterdata.usgs.gov/nwis) (accessed\
    \ on 1 February 2022).\nThe descriptive information of the daily streamﬂow in\
    \ the three case studies is pre-\nsented in Table 2. Details of the case studies,\
    \ including gauge ID, gauge name, and drainage\narea, are presented in Table 3.\
    \ For all catchments, streamﬂow with a 30-day lag was\nconsidered owing to the\
    \ cross-correlation results.\nTable 2. Descriptive information of daily historical\
    \ streamﬂow data for three case studies.\nCriteria\nCase Study 1\nCase Study 2\n\
    Case Study 3\nNo. Samples\n27,146\n34,205\n22,645\nMean (m3/s)\n58\n30\n31\nStd\
    \ (m3/s)\n90\n51\n42\nMin (m3/s)\n2.5\n0.6\n3\n25% (m3/s)\n13\n4\n9\n50% (m3/s)\n\
    31\n11\n20\n75% (m3/s)\n64\n32\n36\nMax (m3/s)\n1654\n702\n1274\nTable 3. Details\
    \ of the selected case studies.\nCase Study. No.\nStation ID\nG-Name\nElev. (m)\n\
    Drainage Area (km2)\nLon. (◦)\nLat. (◦)\nPeriod\n1\n03364000\nEAST FORK WHITE\
    \ RIVER AT\nCOLUMBUS, IN\n183.8\n4421\n85◦55′32”\n39◦12′00”\n1948–2022\n2\n05131500\n\
    LITTLE FORK RIVER AT\nLITTLEFORK, MN\n330.3\n4403\n93◦32′57”\n48◦23′45”\n1928–2022\n\
    3\n11368000\nMCCLOUD R AB SHASTA LK CA\n335.3\n1564\n122◦13′07”\n40◦57′30”\n1945–2007\n\
    3.2. Experiment Setup\nBefore using the data to train the model, data preprocessing\
    \ began with min-max\nnormalization and log transfer as the initial phase of model\
    \ development. The input time\nWater 2022, 14, 3672\n10 of 22\nstep was then derived\
    \ from an autocorrelation analysis of the transformed-streamﬂow\ntime series.\
    \ Using a threshold of more than 0.5, which represents a moderate relationship,\n\
    the past 30 days were selected as input. The autocorrelation analysis results\
    \ for three\ncase studies are given in the Supplementary File. The datasets for\
    \ the three case studies\nwere split into three sets: the ﬁrst set accounted for\
    \ 60% of the data, and it was used for\nmodel training; the second set was used\
    \ for model validation (20%), and the remaining 20%\nwas used for test purposes.\
    \ Subsequently, the sliding window technique with a window\nsize of 30 days was\
    \ used. To demonstrate the superior performance of the Bayesian\nforecasting approach,\
    \ probabilistic methods that have been widely used in the literature\nwere employed\
    \ for comparison. More speciﬁcally, LSTM-BNN [66], LSTM Monte-Carlo\nDropout (LSTM-MC)\
    \ [62,67], BNN [68], and deterministic LSTM were implemented in this\nstudy. Monte\
    \ Carlo dropout is a straightforward epistemic uncertainty extension to the\n\
    neural network. In general, dropout is a technique used to avoid overﬁtting by\
    \ randomly\ndropping units during training. This can be considered the application\
    \ of random noise in\ntraining. When this dropout was performed multiple times,\
    \ multiple results were obtained.\nThe distribution of the samples represents\
    \ the uncertainty of the prediction model. The\nstructure of the prediction models\
    \ along with their graphical scheme are given in the\nSupplementary File.\nThe\
    \ prediction models were developed in Python 3.6.9 with the Keras [69], Tensor-\n\
    Flow [70], and PyTorch [71] libraries. The prediction model was implemented by\
    \ an\nNVIDIA® GeForce® RTX 2070 SUPER and an Intel® Core i9-10920X central processing\n\
    unit at 3.5 GHz utilizing 128 GB random access memory. For a fair comparison among\n\
    the prediction models, a grid search for hyperparameter tuning was used to ensure\
    \ identi-\ncal evaluation.\n4. Result and Discussion\nTo better clarify the forecasting\
    \ performance of BLSTM method, the study compares\nthe BLSTM to the LSTM-BNN,\
    \ BNN, and LSTM-MC in terms of prediction interval un-\ncertainty, sharpness,\
    \ prediction reliability, and multi-step ahead probabilistic prediction\nperformance.\
    \ Moreover, LSTM is used as a deterministic model to evaluate the performance\n\
    of all probabilistic prediction models against the deterministic model. In this\
    \ section, the\npredictive ability of the four probabilistic models for 1 day\
    \ (Scenario I), 7 days (Scenario II),\nand 30 days (Scenario III) ahead of streamﬂow\
    \ prediction is investigated.\n4.1. Probabilistic Prediction Performance Assessment\n\
    The PICP, MPIW, and CRPS values for the four models in the three case studies\
    \ during\nthe test period are listed in Table 4. The length of the bar represents\
    \ the value of the\nevaluation metrics. In terms of PICP, the higher the value,\
    \ the better and longer the bar,\nand vice versa for the other measures. Three\
    \ major aspects must be considered simultane-\nously to evaluate probabilistic\
    \ forecasting performance. PICP refers to the reliability of a\nmodel, MPIW refers\
    \ to the model’s sharpness, and CRPS indicates overall performance.\nIn Scenario\
    \ I, case study I was considered as an example because the models used the\nsame\
    \ mechanism to quantify the forecast uncertainty, and the PICP values of the four\n\
    models were relatively close. Note that the larger the PICP and the smaller the\
    \ MPIW\nand CRPS, the better the model performance. We observed that BLSTM showed\
    \ better\nperformance in handling datasets with high Std and peak streamﬂow. Case\
    \ study III had\n22,645 samples, which was ~17% and ~34% less than that of case\
    \ studies I and II, with\n27,146 and 34,205 samples, respectively. This difference\
    \ did not lead to a particular change\nin the prediction performance of all the\
    \ models for the ﬁrst scenario. In this case study,\nfrom Scenarios I to III in\
    \ BLSTM models, PICP decreased ~2% and 4%, respectively. While\nfor case study\
    \ I, PICP decreased ~25% and 50%, respectively, and for case study II, PICP\n\
    decreased ~1% and 2%, respectively. Therefore, from the obtained results, we inferred\
    \ that\nfor single-step ahead prediction, the results were promising for all case\
    \ studies, and the\nnumber of samples and peak streamﬂow did not affect the prediction\
    \ performance. This\nWater 2022, 14, 3672\n11 of 22\nmade BNNs extremely data-efﬁcient\
    \ because they could learn from even a small dataset\nwithout overﬁtting. Furthermore,\
    \ we predict that more uncertainty is associated with the\nresults, particularly\
    \ for the case study with a higher peak of streamﬂow, leading to wider\nprediction\
    \ intervals and lower coverage. As expected, all models exhibited better predictive\n\
    performance during shorter lead times (1–7 days) than during the longer horizon\
    \ (30 days).\nTherefore, from the obtained results, we can infer that the probabilistic\
    \ forecasting model\ncan lead to higher uncertainty and lower accuracy over a\
    \ longer forecasting horizon.\nTable 4. Summary of prediction performance results\
    \ for three case studies and three scenarios.\nForecast Horizon = 1\nForecast\
    \ Horizon = 7\nForecast Horizon = 30\nModel\nMetric Case I\nCase II\nCase III\n\
    Case I\nCase II\nCase III\nCase I\nCase II\nCase III\nBLSTM\nPICP\n0.950\n0.964\n\
    0.956\n0.709\n0.958\n0.941\n0.477\n0.943\n0.921\nMPIW\n0.021\n0.006\n0.016\n0.023\n\
    0.024\n0.023\n0.032\n0.042\n0.028\nCRPS\n0.087\n0.035\n0.066\n0.375\n0.212\n0.214\n\
    0.576\n0.437\n0.337\nLSTM-BNN\nPICP\n0.957\n0.967\n0.971\n0.591\n0.962\n0.956\n\
    0.371\n0.953\n0.942\nMPIW\n0.023\n0.008\n0.018\n0.035\n0.037\n0.032\n0.039\n0.076\n\
    0.040\nCRPS\n0.086\n0.034\n0.070\n0.400\n0.226\n0.237\n0.615\n0.457\n0.367\nBNN\n\
    PICP\n0.955\n0.953\n0.961\n0.496\n0.779\n0.870\n0.281\n0.630\n0.865\nMPIW\n0.027\n\
    0.009\n0.022\n0.045\n0.050\n0.040\n0.053\n0.141\n0.047\nCRPS\n0.101\n0.041\n0.083\n\
    0.412\n0.240\n0.262\n0.634\n0.461\n0.371\nLSTM-MC\nPICP\n0.973\n0.994\n0.981\n\
    0.454\n0.948\n0.913\n0.268\n0.945\n0.909\nMPIW\n0.046\n0.040\n0.027\n0.049\n0.050\n\
    0.032\n0.057\n0.076\n0.039\nCRPS\n0.109\n0.071\n0.106\n0.414\n0.251\n0.248\n0.636\n\
    0.545\n0.376\nTo further evaluate the results of the four probabilistic models\
    \ for all scenarios in\nthe three case studies, LSTM as a well-known deterministic\
    \ model was used to make\na comparison in terms of RMSE, as shown in Figure 4.\
    \ All probabilistic models in all\nhorizons performed well and provided more accurate\
    \ prediction performance in terms of\nRMSE than the deterministic LSTM, indicating\
    \ the superiority of all probabilistic models in\ncomparison with the conventional\
    \ deterministic model. The range of RMSE indicated that\nall models were fairly\
    \ trained, and they showed promising predictability performance in\nterms of RMSE.\n\
    Figure 4. Comparison among prediction models in terms of RMSE.\nWater 2022, 14,\
    \ 3672\n12 of 22\nAs shown in Figure 5, the probability that the prediction lies\
    \ within the prediction\ninterval by the LSTM-MC model is higher, followed by\
    \ the LSTM-BNN, BNN, and BLSTM\nin the ﬁrst scenario. The values of PICP indicate\
    \ the percentage of the observed streamﬂow\ndata lies within their 95% predictive\
    \ intervals. In Scenario I, LSTM-MC outperformed BNN\nin terms of PICP. Moreover,\
    \ for a longer horizon (7 days and 30 days ahead), due to the\ngradient vanishing\
    \ of LSTM and BNNs as non-sequential models, both showed the lowest\ncoverage\
    \ and the points falling within the interval decreased by increasing the uncertainty\n\
    in comparison with BLSTM and LSTM-BNN.\nFigure 5. Comparison among prediction\
    \ models in terms of PICP.\nThe MPIW values of the four models during the test\
    \ period are shown in Figure 6a. The\nMPIW was considered an effective representation\
    \ of sharpness in probabilistic predictions,\nand referred to the concentration\
    \ of the predictive distributions. The more concentrated the\npredictive distributions,\
    \ the lower the MPIW, the sharper the prediction, and consequently\nthe better\
    \ the predictive performance. As shown in Figure 6a, BLSTM has the lowest\nMPIW,\
    \ which indicates that it is the sharpest predictive model among the other models\n\
    in all scenarios. The stand-alone BNN and LSTM-MC were slightly different, whereas\n\
    the LSTM-MC obtained the highest MPIW value among the other models, particularly\n\
    by increasing the horizon. Compared with the BLSTM model with the narrowest MPIW,\n\
    LSTM-MC had the worst prediction sharpness over all horizons. The fact that BLSTM\n\
    presents the best predictive capability indicates the signiﬁcance of capturing\
    \ both epistemic\nand aleatoric uncertainties.\nTo comprehensively evaluate the\
    \ probability prediction accuracy and reliability, a com-\nparison among all prediction\
    \ models in terms of the CRPS is shown in Figure 6b. Overall,\nBLSTM and LSTM-BNN\
    \ competed with each other in all case studies and scenarios. How-\never, in the\
    \ longer horizon, BLSTM outperformed other models and proved its superiority\n\
    by keeping more points falling within its forecasting interval while keeping the\
    \ interval as\nnarrow as possible while also increasing the uncertainty for a\
    \ longer horizon. Therefore,\nthe proposed BLSTM model outperformed the other\
    \ models in terms of RMSE, MPIW,\nand CRPS, demonstrating the forecasting accuracy,\
    \ sharpness, and overall performance of\nthe model.\nWater 2022, 14, 3672\n13\
    \ of 22\nFigure 6. Comparison among prediction models in terms of (a) MPIW and\
    \ (b) CRPS.\n4.2. Impact of Forecast Horizon in Probabilistic Prediction Performance\n\
    The prediction results of all models are compared graphically in Figures 7–10\
    \ in the\nform of time series for the entire test set for case study II for all\
    \ scenarios (forecasting hori-\nzon). Considering space limitations, we have avoided\
    \ adding the results of all case studies\nand scenarios in the main text, and\
    \ only the results of case study II are presented. The actual\nstreamﬂow and forecast\
    \ value for the test period are represented by black and red curves,\nrespectively.\
    \ The red band represents the prediction interval, with a 95% conﬁdence level.\n\
    The probabilistic forecasts generated with the BLSTM model presented the beneﬁts\
    \ of high\nprediction coverage of observed streamﬂow data (PICP) with a tighter\
    \ prediction width\n(MPIW) and better overall performance (CRPS), corresponding\
    \ to reliability, sharpness,\nand resolution. Furthermore, accurate peak prediction,\
    \ which is a crucial factor for disaster\nprevention and water resources management,\
    \ can be predicted with reasonable magnitudes\nwith the proposed BLSTM. Additionally,\
    \ with increasing the forecast horizon, BLSTM still\nshowed reliable performance,\
    \ while other models were incapable of handling such a situa-\ntion. In forecast\
    \ horizon 30, massive ﬂuctuations in the prediction results occurred for all\n\
    the models and case studies. However, most of the prediction results were covered\
    \ by the\n95% interval in Scenario I, followed by Scenario II.\nWater 2022, 14,\
    \ 3672\n14 of 22\nFigure 7. Probabilistic streamﬂow forecasting results obtained\
    \ by BLSTM for case study II for\n(a) forecast horizon 1, (b) forecast horizon\
    \ 7, and (c) forecast horizon 30.\nFigure 8. Probabilistic streamﬂow forecasting\
    \ results obtained by LSTM-BNN for case study II for\n(a) forecast horizon 1,\
    \ (b) forecast horizon 7, and (c) forecast horizon 30.\nWater 2022, 14, 3672\n\
    15 of 22\nFigure 9. Probabilistic streamﬂow forecasting results obtained by BNN\
    \ for case study II for (a) forecast\nhorizon 1, (b) forecast horizon 7, and (c)\
    \ forecast horizon 30.\nFigure 10. Probabilistic streamﬂow forecasting results\
    \ obtained by LSTM-MC for case study II\n(a) forecast horizon 1, (b) forecast\
    \ horizon 7, and (c) forecast horizon 30.\nWater 2022, 14, 3672\n16 of 22\nAs\
    \ shown in Figure 11, with an increase in the forecasting horizon from 1 to 30\
    \ days,\nthe MPIW and CRPS values increase, and the PICP decreases. This indicates\
    \ that the\naccuracy of the prediction models decreases with an increase in the\
    \ forecasting horizon. The\nprediction accuracy over longer horizons decreased\
    \ mainly as a result of the accumulative\nerror issue in multi-step ahead recursive\
    \ models and the gradient vanishing issue in long\nsequence time-series forecasting.\
    \ Nevertheless, the predictive mean values of probabilistic\nstreamﬂow from the\
    \ BLSTM model matched the observations better than the other three\nmodels. The\
    \ performance of all models gradually worsened with increasing lead times for\n\
    the three case studies. As shown in Figure 11, when the overall prediction accuracy\
    \ was low,\nMPIW was smaller. The interval width of the forecasting with LSTM-MC\
    \ increased rapidly\nwith the prediction horizon. The average interval width of\
    \ the proposed BLSTM was much\nsmaller than that of the other models. Simultaneously,\
    \ the overall performance in terms\nof CRPS was higher, proving the superiority\
    \ of the proposed method for the probability\nforecasting of daily streamﬂow,\
    \ particularly for longer prediction horizons.\nFigure 11. Change in probabilistic\
    \ streamﬂow forecasting results by increasing horizon for (a) case\nstudy I, (b)\
    \ case study II, and (c) case study III.\nFor a better and more vivid comparison\
    \ of all model performances, the time series of\nall models for all case studies\
    \ in the three scenarios are shown in Figure 12a–c for the ﬁrst\nyear of the test\
    \ period (365 days). We observed that BNN and LSTM-MC underestimated\nthe peak\
    \ ﬂows with a misleading trend in the ﬁrst 365 days. In the ﬁrst scenario, a 95%\n\
    PI was relatively narrow and constant for all models, indicating that models captured\n\
    both low and high ﬂow values appropriately with low uncertainty. However, longer\n\
    horizons in Scenarios II and III were associated with a wider 95% PI, indicating\
    \ greater\nmodel uncertainty.\nWater 2022, 14, 3672\n17 of 22\nFigure 12. Prediction\
    \ results of all models with 1, 7, and 30 days ahead forecasting for (a) case\
    \ study\nI, (b) case study II, and (c) case study III.\nFurthermore, we observed\
    \ that all case studies can be effectively covered by the PI.\nFurthermore, for\
    \ case study II, which had the lowest peak, BLSTM achieved the best results\n\
    in all three scenarios. In contrast, case study I, with the highest peak at 1654\
    \ m3/s and\nStd. of 90 m3/s, achieved the worst prediction results for all scenarios.\
    \ From Scenarios\nI to II in case study I for BLSTM, LSTM-BNN, BNN, and LSTM-MC,\
    \ PICP decreased by\napproximately 25, 38, 48, and 53%, respectively, indicating\
    \ the best performance of BLSTM\nWater 2022, 14, 3672\n18 of 22\nin maintaining\
    \ its predictability in case study I, with the highest peak and Std in the\nextended\
    \ horizon prediction. Moreover, by increasing the horizon, prediction performance\n\
    for case study I dramatically decreased, whereas, in terms of PICP for BLSTM,\
    \ case studies\nII and III from Scenarios I to III decreased by approximately\
    \ 1–2% and 2–4%, respectively.\nFurthermore, LSTM-MC and BNN achieved the worst\
    \ overall prediction performance for\nall the scenarios. The catchment area of\
    \ case study I was relatively large, and heavy rain\nwas the primary source of\
    \ streamﬂow. These two characteristics cause the seasonal and\nannual variations\
    \ in streamﬂow to be greater than those in the other two case studies. In\nthis\
    \ case study, the streamﬂow was very stable and small during the dry season, whereas\n\
    in the rainy season, the streamﬂow increased steeply and then decreased. This\
    \ made\nforecasting challenging and resulted in a higher uncertainty than that\
    \ in the other case\nstudies. Therefore, for this type of catchment, using more\
    \ in-situ meteorological predictors,\nsuch as precipitation and temperature, along\
    \ with available high-resolution large-scale\nhydroclimate data, can improve forecasting\
    \ accuracy.\nThe kernel density estimation plots of the daily streamﬂow prediction\
    \ of all models for\ncase study II are displayed in Figure 13a–c. As depicted,\
    \ the kernel density estimation plots\nare on the top with boxplots, and the data\
    \ points of the prediction are underneath. The\nboxes represent the inner quartiles,\
    \ the vertical lines within the box indicate the median, and\nthe diamonds represent\
    \ the outliers in each model. As shown in Figure 13, the prediction\nvariance\
    \ of BLSTM is lower in comparison with the other models, in particular for the\n\
    Scenario III which is forecasting horizon 30. Moreover, the inter-quartile range\
    \ of BLSTM\nis smaller which indicates that the BLSTM prediction results has less\
    \ dispersion while\nLSTM-MC has the highest dispersion. The results of this study\
    \ indicate that BLSTM shows\nthe best overall probabilistic prediction performance.\n\
    Figure 13. Kernel density estimation plots of daily streamﬂow prediction of all\
    \ models in case study\nII for (a) forecast horizon 1, (b) forecast horizon 7,\
    \ and (c) forecast horizon 30.\n5. Conclusions\nThis study proposes BLSTM as a\
    \ probabilistic prediction model to estimate streamﬂow\nuncertainty. For comparison,\
    \ three probabilistic models and one deterministic model,\nincluding LSTM-BNN,\
    \ BNN, LSTM-MC, and LSTM, are developed under three scenarios:\n1 day, 7 days,\
    \ and 30 days ahead daily streamﬂow forecasting. The results are compared\nin\
    \ terms of reliability, sharpness, and overall performance for three different\
    \ case studies\nin the USA. Reliability is measured by computing the PICP, sharpness\
    \ is measured by\ncomputing the MPIW, and overall performance is measured by CRPS.\
    \ The results show\nthat all probabilistic models outperformed the deterministic\
    \ model (LSTM). Moreover,\namong the probabilistic models, BLSTM is superior.\
    \ The Bayesian LSTM achieves better\nresults with less computing time and is easier\
    \ to train than those of LSTM-BNN and\nBNN. The results reveal that the BLSTM\
    \ network with variational inference achieves the\nhighest accuracy. The fact\
    \ that BLSTM shows the best predictive performance indicates\nthe signiﬁcance\
    \ of capturing temporal dependencies by considering both uncertainties.\nMoreover,\
    \ taking advantage of the long- and short-term dependencies and capturing the\n\
    inherent uncertainty that is inevitable in hydrology provides better prediction\
    \ results. For\nWater 2022, 14, 3672\n19 of 22\nlonger forecast horizons, models\
    \ such as the BNN and LSTM-MC perform poorly due\nto the fact that the former\
    \ is not an autoregressive model, and both have the gradient-\nvanishing problem\
    \ in the long sequence time series. In addition, the issue of cumulative\nerror\
    \ in multi-step ahead recursive model is inevitable. Future research will investigate\n\
    an enhanced network structure with a large prediction capacity, such as attention-based\n\
    and parallel-feed architectures, to handle the long sequence time-series forecasting.\
    \ In\naddition to the recursive models, other multi-step ahead prediction strategies,\
    \ such as direct\nand hybrid, can be studied to minimize the accumulated error\
    \ issue for longer horizons\nforecasting. Moreover, in the relevant future work,\
    \ meteorological parameters such as\nprecipitation, temperature, and humidity\
    \ will be included as input to allow the model to\ndetect the complexity necessary\
    \ to enhance the accuracy of prediction, particularly for the\nlonger horizon,\
    \ and to evaluate the effect of multivariate input on model uncertainty.\nSupplementary\
    \ Materials: The following supporting information can be downloaded at: https:\n\
    //www.mdpi.com/article/10.3390/w14223672/s1, Figure S1: Autocorrelation function\
    \ plots of\ntransformed-streamﬂow timeseries; Figure S2: The visualizations of\
    \ network execution graphs and\ntraces for BLSTM models’ outputs; Figure S3: The\
    \ visualizations of network execution graphs and\ntraces for LSTM-BNN models’\
    \ outputs; Figure S4: The visualizations of network execution graphs\nand traces\
    \ for BNN models’ outputs; Figure S5: The visualizations of network execution\
    \ graphs and\ntraces for LSTM-MC models’ outputs; Figure S6: Prediction results\
    \ of all models for case study II;\nTable S1: General structures of deep neural\
    \ networks.\nAuthor Contributions: F.G.: conceptualization, methodology, investigation,\
    \ software, validation,\nformal analysis, data curation, writing—original draft,\
    \ writing—review and editing, visualization.\nD.K.: supervision, validation, writing—review\
    \ and editing, resources, and funding acquisition. All\nauthors have read and\
    \ agreed to the published version of the manuscript.\nFunding: This research was\
    \ funded by (1) the Korea Ministry of Environment (MOE) as “Graduate\nSchool specialized\
    \ in Climate Change” and (2) the Korea Institute of Energy Technology Evalua-\n\
    tion and Planning (KETEP) and the Korea Ministry of Trade, Industry & Energy (MOTIE)\
    \ grant\nnumber [20224000000260].\nData Availability Statement: Data will be made\
    \ available on request. Daily historical streamﬂow\ndata for the three selected\
    \ case studies were obtained from the United States Geological Survey\n(USGS)\
    \ website, accessed on 1 February 2022 (https://waterdata.usgs.gov/nwis).\nConﬂicts\
    \ of Interest: The authors declare no conﬂict of interest.\nReferences\n1.\nGhobadi,\
    \ F.; Kang, D. Improving Long-Term Streamﬂow Prediction in a Poorly Gauged Basin\
    \ Using Geo-Spatiotemporal\nMesoscale Data and Attention-Based Deep Learning:\
    \ A Comparative Study. J. Hydrol. 2022, 615, 128608. [CrossRef]\n2.\nWang, Y.;\
    \ Liu, J.; Li, R.; Suo, X.; Lu, E.H. Medium and Long-Term Precipitation Prediction\
    \ Using Wavelet Decomposition-\nPrediction-Reconstruction Model. Water Resour.\
    \ Manag. 2022, 36, 971–987. [CrossRef]\n3.\nDikshit, A.; Pradhan, B.; Santosh,\
    \ M. Artiﬁcial Neural Networks in Drought Prediction in the 21st Century–A Scientometric\n\
    Analysis. Appl. Soft Comput. 2022, 114, 108080. [CrossRef]\n4.\nVan den Hurk,\
    \ B.J.J.M.; Bouwer, L.M.; Buontempo, C.; Döscher, R.; Ercin, E.; Hananel, C.;\
    \ Hunink, J.E.; Kjellström, E.; Klein, B.;\nManez, M.; et al. Improving Predictions\
    \ and Management of Hydrological Extremes through Climate Services: Www.Imprex.Eu.\n\
    Clim. Serv. 2016, 1, 6–11. [CrossRef]\n5.\nLange, H.; Sippel, S. Machine Learning\
    \ Applications in Hydrology BT—Forest-Water Interactions; Levia, D.F., Carlyle-Moses,\
    \ D.E.,\nIida, S., Michalzik, B., Nanko, K., Tischer, A., Eds.; Springer International\
    \ Publishing: Cham, Switzerland, 2020; pp. 233–257.\nISBN 978-3-030-26086-6.\n\
    6.\nLin, Y.; Wang, D.; Wang, G.; Qiu, J.; Long, K.; Du, Y.; Xie, H.; Wei, Z.;\
    \ Shangguan, W.; Dai, Y. A Hybrid Deep Learning Algorithm\nand Its Application\
    \ to Streamﬂow Prediction. J. Hydrol. 2021, 601, 126636. [CrossRef]\n7.\nHagen,\
    \ J.S.; Leblois, E.; Lawrence, D.; Solomatine, D.; Sorteberg, A. Identifying Major\
    \ Drivers of Daily Streamﬂow from\nLarge-Scale Atmospheric Circulation with Machine\
    \ Learning. J. Hydrol. 2021, 596, 126086. [CrossRef]\n8.\nRen, K.; Wang, X.; Shi,\
    \ X.; Qu, J.; Fang, W. Examination and Comparison of Binary Metaheuristic Wrapper-Based\
    \ Input Variable\nSelection for Local and Global Climate Information-Driven One-Step\
    \ Monthly Streamﬂow Forecasting. J. Hydrol. 2021, 597, 126152.\n[CrossRef]\nWater\
    \ 2022, 14, 3672\n20 of 22\n9.\nTayerani Charmchi, A.S.; Ifaei, P.; Yoo, C.K.\
    \ Smart Supply-Side Management of Optimal Hydro Reservoirs Using the Water/Energy\n\
    Nexus Concept: A Hydropower Pinch Analysis. Appl. Energy 2021, 281, 116136. [CrossRef]\n\
    10.\nPapacharalampous, G.; Tyralis, H. A Review of Machine Learning Concepts and\
    \ Methods for Addressing Challenges in\nProbabilistic Hydrological Post-Processing\
    \ and Forecasting. arXiv 2022. [CrossRef]\n11.\nGhimire, S.; Yaseen, Z.M.; Farooque,\
    \ A.A.; Deo, R.C.; Zhang, J.; Tao, X. Streamﬂow Prediction Using an Integrated\
    \ Methodology\nBased on Convolutional Neural Network and Long Short-Term Memory\
    \ Networks. Sci. Rep. 2021, 11, 17497. [CrossRef]\n12.\nKlotz, D.; Kratzert, F.;\
    \ Gauch, M.; Keefe Sampson, A.; Brandstetter, J.; Klambauer, G.; Hochreiter, S.;\
    \ Nearing, G. Uncertainty\nEstimation with Deep Learning for Rainfall-Runoff Modeling.\
    \ Hydrol. Earth Syst. Sci. 2022, 26, 1673–1693. [CrossRef]\n13.\nPapacharalampous,\
    \ G.; Tyralis, H.; Langousis, A.; Jayawardena, A.W.; Sivakumar, B.; Mamassis,\
    \ N.; Montanari, A.; Koutsoyian-\nnis, D. Probabilistic Hydrological Post-Processing\
    \ at Scale: Why and How to Apply Machine-Learning Quantile Regression\nAlgorithms.\
    \ Water 2019, 11, 2126. [CrossRef]\n14.\nAdnan, R.M.; Liang, Z.; Parmar, K.S.;\
    \ Soni, K.; Kisi, O. Modeling Monthly Streamﬂow in Mountainous Basin by MARS,\n\
    GMDH-NN and DENFIS Using Hydroclimatic Data. Neural Comput. Appl. 2021, 33, 2853–2871.\
    \ [CrossRef]\n15.\nApaydin, H.; Taghi Sattari, M.; Falsaﬁan, K.; Prasad, R. Artiﬁcial\
    \ Intelligence Modelling Integrated with Singular Spectral\nAnalysis and Seasonal-Trend\
    \ Decomposition Using Loess Approaches for Streamﬂow Predictions. J. Hydrol. 2021,\
    \ 600, 126506.\n[CrossRef]\n16.\nMehdizadeh, S.; Fathian, F.; Safari, M.J.S.;\
    \ Adamowski, J.F. Comparative Assessment of Time Series and Artiﬁcial Intelligence\n\
    Models to Estimate Monthly Streamﬂow: A Local and External Data Analysis Approach.\
    \ J. Hydrol. 2019, 579, 124225. [CrossRef]\n17.\nNanda, T.; Sahoo, B.; Chatterjee,\
    \ C. Enhancing Real-Time Streamﬂow Forecasts with Wavelet-Neural Network Based\
    \ Error-\nUpdating Schemes and ECMWF Meteorological Predictions in Variable Inﬁltration\
    \ Capacity Model. J. Hydrol. 2019, 575, 890–910.\n[CrossRef]\n18.\nKhosravi, K.;\
    \ Golkarian, A.; Tiefenbacher, J.P. Using Optimized Deep Learning to Predict Daily\
    \ Streamﬂow: A Comparison to\nCommon Machine Learning Algorithms. Water Resour.\
    \ Manag. 2022, 36, 699–716. [CrossRef]\n19.\nXu, W.; Chen, J.; Zhang, X.J. Scale\
    \ Effects of the Monthly Streamﬂow Prediction Using a State-of-the-Art Deep Learning\
    \ Model.\nWater Resour. Manag. 2022, 36, 3609–3625. [CrossRef]\n20.\nCheng, M.;\
    \ Fang, F.; Kinouchi, T.; Navon, I.M.; Pain, C.C. Long Lead-Time Daily and Monthly\
    \ Streamﬂow Forecasting Using\nMachine Learning Methods. J. Hydrol. 2020, 590,\
    \ 125376. [CrossRef]\n21.\nCui, Z.; Zhou, Y.; Guo, S.; Wang, J.; Xu, C.Y. Effective\
    \ Improvement of Multi-Step-Ahead Flood Forecasting Accuracy through\nEncoder-Decoder\
    \ with an Exogenous Input Structure. J. Hydrol. 2022, 609, 127764. [CrossRef]\n\
    22.\nYin, H.; Zhang, X.; Wang, F.; Zhang, Y.; Xia, R.; Jin, J. Rainfall-Runoff\
    \ Modeling Using LSTM-Based Multi-State-Vector Sequence-\nto-Sequence Model. J.\
    \ Hydrol. 2021, 598, 126378. [CrossRef]\n23.\nKao, I.F.; Zhou, Y.; Chang, L.C.;\
    \ Chang, F.J. Exploring a Long Short-Term Memory Based Encoder-Decoder Framework\
    \ for\nMulti-Step-Ahead Flood Forecasting. J. Hydrol. 2020, 583, 124631. [CrossRef]\n\
    24.\nBabaeian, E.; Paheding, S.; Siddique, N.; Devabhaktuni, V.K.; Tuller, M.\
    \ Short- and Mid-Term Forecasts of Actual Evapotranspira-\ntion with Deep Learning.\
    \ J. Hydrol. 2022, 612, 128078. [CrossRef]\n25.\nXiang, Z.; Yan, J.; Demir, I.\
    \ A Rainfall-Runoff Model With LSTM-Based Sequence-to-Sequence Learning. Water\
    \ Resour. Res. 2020,\n56, e2019WR025326. [CrossRef]\n26.\nFerreira, L.B.; da Cunha,\
    \ F.F. Multi-Step Ahead Forecasting of Daily Reference Evapotranspiration Using\
    \ Deep Learning. Comput.\nElectron. Agric. 2020, 178, 105728. [CrossRef]\n27.\n\
    Granata, F.; Di Nunno, F.; de Marinis, G. Stacked Machine Learning Algorithms\
    \ and Bidirectional Long Short-Term Memory\nNetworks for Multi-Step Ahead Streamﬂow\
    \ Forecasting: A Comparative Study. J. Hydrol. 2022, 613, 128431. [CrossRef]\n\
    28.\nMasrur Ahmed, A.A.; Deo, R.C.; Feng, Q.; Ghahramani, A.; Raj, N.; Yin, Z.;\
    \ Yang, L. Deep Learning Hybrid Model with\nBoruta-Random Forest Optimiser Algorithm\
    \ for Streamﬂow Forecasting with Climate Mode Indices, Rainfall, and Periodicity.\n\
    J. Hydrol. 2021, 599, 126350. [CrossRef]\n29.\nRahimzad, M.; Moghaddam Nia, A.;\
    \ Zolfonoon, H.; Soltani, J.; Danandeh Mehr, A.; Kwon, H.H. Performance Comparison\
    \ of an\nLSTM-Based Deep Learning Model versus Conventional Machine Learning Algorithms\
    \ for Streamﬂow Forecasting. Water Resour.\nManag. 2021, 35, 4167–4187. [CrossRef]\n\
    30.\nBarzegar, R.; Aalami, M.T.; Adamowski, J. Coupling a Hybrid CNN-LSTM Deep\
    \ Learning Model with a Boundary Corrected\nMaximal Overlap Discrete Wavelet Transform\
    \ for Multiscale Lake Water Level Forecasting. J. Hydrol. 2021, 598, 126196. [CrossRef]\n\
    31.\nGranata, F.; Di Nunno, F. Forecasting Evapotranspiration in Different Climates\
    \ Using Ensembles of Recurrent Neural Networks.\nAgric. Water Manag. 2021, 255,\
    \ 107040. [CrossRef]\n32.\nZheng, Y.; Xie, Y.; Long, X. A Comprehensive Review\
    \ of Bayesian Statistics in Natural Hazards Engineering. Nat. Hazards 2021,\n\
    108, 63–91. [CrossRef]\n33.\nHan, S.; Coulibaly, P. Bayesian Flood Forecasting\
    \ Methods: A Review. J. Hydrol. 2017, 551, 340–351. [CrossRef]\n34.\nCosta, V.;\
    \ Fernandes, W. Bayesian Estimation of Extreme Flood Quantiles Using a Rainfall-Runoff\
    \ Model and a Stochastic Daily\nRainfall Generator. J. Hydrol. 2017, 554, 137–154.\
    \ [CrossRef]\n35.\nXu, X.; Zhang, X.; Fang, H.; Lai, R.; Zhang, Y.; Huang, L.;\
    \ Liu, X. A Real-Time Probabilistic Channel Flood-Forecasting Model\nBased on\
    \ the Bayesian Particle Filter Approach. Environ. Model. Softw. 2017, 88, 151–167.\
    \ [CrossRef]\nWater 2022, 14, 3672\n21 of 22\n36.\nHuang, Y.; Shao, C.; Wu, B.;\
    \ Beck, J.L.; Li, H. State-of-the-Art Review on Bayesian Inference in Structural\
    \ System Identiﬁcation\nand Damage Assessment. Adv. Struct. Eng. 2019, 22, 1329–1351.\
    \ [CrossRef]\n37.\nGoodarzi, L.; Banihabib, M.E.; Roozbahani, A.; Dietrich, J.\
    \ Bayesian Network Model for Flood Forecasting Based on Atmospheric\nEnsemble\
    \ Forecasts. Nat. Hazards Earth Syst. Sci. 2019, 19, 2513–2524. [CrossRef]\n38.\n\
    Bai, H.; Li, G.; Liu, C.; Li, B.; Zhang, Z.; Qin, H. Hydrological Probabilistic\
    \ Forecasting Based on Deep Learning and Bayesian\nOptimization Algorithm. Hydrol.\
    \ Res. 2021, 52, 927–943. [CrossRef]\n39.\nZhu, S.; Luo, X.; Yuan, X.; Xu, Z.\
    \ An Improved Long Short-Term Memory Network for Streamﬂow Forecasting in the\
    \ Upper\nYangtze River. Stoch. Environ. Res. Risk Assess. 2020, 34, 1313–1329.\
    \ [CrossRef]\n40.\nGude, V.; Corns, S.; Long, S. Flood Prediction and Uncertainty\
    \ Estimation Using Deep Learning. Water 2020, 12, 884. [CrossRef]\n41.\nAlthoff,\
    \ D.; Rodrigues, L.N.; Bazame, H.C. Uncertainty Quantiﬁcation for Hydrological\
    \ Models Based on Neural Networks: The\nDropout Ensemble. Stoch. Environ. Res.\
    \ Risk Assess. 2021, 35, 1051–1067. [CrossRef]\n42.\nLi, D.; Marshall, L.; Liang,\
    \ Z.; Sharma, A. Hydrologic Multi-Model Ensemble Predictions Using Variational\
    \ Bayesian Deep\nLearning. J. Hydrol. 2022, 604, 127221. [CrossRef]\n43.\nHe,\
    \ Y.; Fan, H.; Lei, X.; Wan, J. A Runoff Probability Density Prediction Method\
    \ Based on B-Spline Quantile Regression and\nKernel Density Estimation. Appl.\
    \ Math. Model. 2021, 93, 852–867. [CrossRef]\n44.\nLu, D.; Konapala, G.; Painter,\
    \ S.L.; Kao, S.C.; Gangrade, S. Streamﬂow Simulation in Data-Scarce Basins Using\
    \ Bayesian and\nPhysics-Informed Machine Learning Models. J. Hydrometeorol. 2021,\
    \ 22, 1421–1438. [CrossRef]\n45.\nSun, M.; Zhang, T.; Wang, Y.; Strbac, G.; Kang,\
    \ C. Using Bayesian Deep Learning to Capture Uncertainty for Residential Net Load\n\
    Forecasting. IEEE Trans. Power Syst. 2020, 35, 188–201. [CrossRef]\n46.\nWang,\
    \ Y.; Gan, D.; Sun, M.; Zhang, N.; Lu, Z.; Kang, C. Probabilistic Individual Load\
    \ Forecasting Using Pinball Loss Guided\nLSTM. Appl. Energy 2019, 235, 10–20.\
    \ [CrossRef]\n47.\nToubeau, J.F.; Bottieau, J.; Vallee, F.; De Greve, Z. Deep\
    \ Learning-Based Multivariate Probabilistic Forecasting for Short-Term\nScheduling\
    \ in Power Markets. IEEE Trans. Power Syst. 2019, 34, 1203–1215. [CrossRef]\n\
    48.\nWang, H.; Yi, H.; Peng, J.; Wang, G.; Liu, Y.; Jiang, H.; Liu, W. Deterministic\
    \ and Probabilistic Forecasting of Photovoltaic Power\nBased on Deep Convolutional\
    \ Neural Network. Energy Convers. Manag. 2017, 153, 409–422. [CrossRef]\n49.\n\
    Xu, L.; Hu, M.; Fan, C. Probabilistic Electrical Load Forecasting for Buildings\
    \ Using Bayesian Deep Neural Networks. J. Build.\nEng. 2022, 46, 103853. [CrossRef]\n\
    50.\nVan der Meer, D.W.; Shepero, M.; Svensson, A.; Widén, J.; Munkhammar, J.\
    \ Probabilistic Forecasting of Electricity Consumption,\nPhotovoltaic Power Generation\
    \ and Net Demand of an Individual Building Using Gaussian Processes. Appl. Energy\
    \ 2018, 213,\n195–207. [CrossRef]\n51.\nZhang, Z.; Zhang, Q.; Singh, V.P. Univariate\
    \ Streamﬂow Forecasting Using Commonly Used Data-Driven Models: Literature\nReview\
    \ and Case Study. Hydrol. Sci. J. 2018, 63, 1091–1111. [CrossRef]\n52.\nLange,\
    \ H.; Sippel, S. Machine Learning Applications in Hydrology. In Forest-Water Interactions;\
    \ Ecological Studies, Volume 240;\nSpringer: Cham, Switzerland, 2020; pp. 233–257.\n\
    53.\nAbdul Kareem, B.; Zubaidi, S.L.; Ridha, H.M.; Al-Ansari, N.; Al-Bdairi, N.S.S.\
    \ Applicability of ANN Model and CPSOCGSA\nAlgorithm for Multi-Time Step Ahead\
    \ River Streamﬂow Forecasting. Hydrology 2022, 9, 171. [CrossRef]\n54.\nWegayehu,\
    \ E.B.; Muluneh, F.B. Short-Term Daily Univariate Streamﬂow Forecasting Using\
    \ Deep Learning Models. Adv. Meteorol.\n2022, 2022, 1860460. [CrossRef]\n55.\n\
    Kendall, A.; Gal, Y. What Uncertainties Do We Need in Bayesian Deep Learning for\
    \ Computer Vision? Adv. Neural Inf. Process.\nSyst. 2017, 2017, 5575–5585. [CrossRef]\n\
    56.\nBlundell, C.; Cornebise, J.; Kavukcuoglu, K.; Wierstra, D. Weight Uncertainty\
    \ in Neural Networks. arXiv 2015. [CrossRef]\n57.\nHochreiter, S.; Schmidhuber,\
    \ J. Long Short-Term Memory. Neural Comput. 1997, 9, 1735–1780. [CrossRef] [PubMed]\n\
    58.\nLi, G.; Yang, L.; Lee, C.G.; Wang, X.; Rong, M. A Bayesian Deep Learning\
    \ RUL Framework Integrating Epistemic and Aleatoric\nUncertainties. IEEE Trans.\
    \ Ind. Electron. 2021, 68, 8829–8841. [CrossRef]\n59.\nBernardo, J.M.; Smith,\
    \ A.F.M. Bayesian Theory; Wiley Blackwell: Hoboken, NJ, USA, 2008; ISBN 9780470316870.\n\
    60.\nRunnalls, A.R. Kullback-Leibler Approach to Gaussian Mixture Reduction. IEEE\
    \ Trans. Aerosp. Electron. Syst. 2007, 43, 989–999.\n[CrossRef]\n61.\nJospin,\
    \ L.V.; Buntine, W.; Boussaid, F.; Laga, H.; Bennamoun, M. Hands-on Bayesian Neural\
    \ Networks–A Tutorial for Deep\nLearning Users. IEEE Comput. Intell. Mag. 2020,\
    \ 17, 29–48. [CrossRef]\n62.\nGal, Y.; Ghahramani, Z. Dropout as a Bayesian Approximation:\
    \ Representing Model Uncertainty in Deep Learning. 33rd Int. Conf.\nMach. Learn.\
    \ ICML 2016, 3, 1651–1660. [CrossRef]\n63.\nGal, Y. Uncertainty in Deep Learning.\
    \ Ph.D. Thesis, University of Cambridge, Cambridge, UK, 2016.\n64.\nAbdar, M.;\
    \ Pourpanah, F.; Hussain, S.; Rezazadegan, D.; Liu, L.; Ghavamzadeh, M.; Fieguth,\
    \ P.; Cao, X.; Khosravi, A.;\nAcharya, U.R.; et al. A Review of Uncertainty Quantiﬁcation\
    \ in Deep Learning: Techniques, Applications and Challenges.\nInf. Fusion 2021,\
    \ 76, 243–297. [CrossRef]\n65.\nJian, X.; Wolock, D.M.; Lins, H.F.; Henderson,\
    \ R.J.; Brady, S.J. Streamﬂow—Water Year 2021: U.S. Geological Survey Fact Sheet\n\
    2022–3072; USGS: Reston, VA, USA, 2022.\nWater 2022, 14, 3672\n22 of 22\n66.\n\
    Chen, R.; Cao, J.; Zhang, D. Probabilistic Prediction of Photovoltaic Power Using\
    \ Bayesian Neural Network-LSTM Model. In\nProceedings of the 2021 IEEE 4th International\
    \ Conference on Renewable Energy and Power Engineering (REPE), Beijing, China,\n\
    9–11 October 2021; pp. 294–299. [CrossRef]\n67.\nSrivastava, N.; Hinton, G.; Krizhevsky,\
    \ A.; Salakhutdinov, R. Dropout: A Simple Way to Prevent Neural Networks from\n\
    Overﬁtting. J. Mach. Learn. Res. 2014, 15, 1929–1958.\n68.\nFortunato, M.; Blundell,\
    \ C.; Vinyals, O. Bayesian Recurrent Neural Networks. arXiv 2019. [CrossRef]\n\
    69.\nKetkar, N. Introduction to Keras. In Deep Learning with Python; Ketkar, N.,\
    \ Ed.; Apress: Berkeley, CA, USA, 2017; pp. 97–111.\nISBN 978-1-4842-2766-4.\n\
    70.\nAbadi, M.; Barham, P.; Chen, J.; Chen, Z.; Davis, A.; Dean, J.; Devin, M.;\
    \ Ghemawat, S.; Irving, G.; Isard, M.; et al. TensorFlow:\nA System for Large-Scale\
    \ Machine Learning. In Proceedings of the 12th USENIX Symposium on Operating Systems\
    \ Design and\nImplementation (OSDI 16), Savannah, GA, USA, 2–4 November 2016;\
    \ pp. 265–283.\n71.\nPyTorch Documentation—PyTorch 1.13 Documentation. Available\
    \ online: https://pytorch.org/docs/stable/index.html (accessed\non 7 November\
    \ 2022).\n"
  inline_citation: '>'
  journal: Water (Basel)
  limitations: '>'
  pdf_link: https://www.mdpi.com/2073-4441/14/22/3672/pdf?version=1669002216
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: 'Multi-Step Ahead Probabilistic Forecasting of Daily Streamflow Using Bayesian
    Deep Learning: A Multiple Case Study'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.2991/ahis.k.210913.003
  analysis: '>'
  authors:
  - Deep Kothadiya
  - Aayushi Chaudhari
  - Ruchita Macwan
  - Krishna Patel
  - Chintan Bhatt
  citation_count: 11
  full_citation: '>'
  full_text: ">\n \n \nThe Convergence of Deep Learning and Computer \nVision: Smart\
    \ City Applications and Research \nChallenges\n \nDeep Kothadiya1, Aayushi Chaudhari1,\
    \ Ruchita Macwan1, Krishna Patel2, Chintan \nBhatt1* \n1U & P U. Patel Department\
    \ of Computer Engineering, Chandubhai S. Patel Institute of Science and Technology,\
    \ \nCharotar University of Science and Technology (CHARUSAT), CHARUSAT campus,\
    \ Changa 388421, India. \n2 Department of Computer Science & Engineering, Devang\
    \ Patel Institute of Advance Technology and Research, \nCharotar University of\
    \ Science and Technology (CHARUSAT), CHARUSAT campus, Changa 388421, India.  \n\
    *Corresponding author. Email: chintanbhatt.ce@charusat.ac.in \n \nABSTRACT \n\
    In recent years, deep learning strategies started to outshine traditional machine\
    \ learning methods in a few fields, with \nComputer Vision being one of the most\
    \ noticeable ones. The Computer Vision is becoming more suitable nowadays at \n\
    identifying patterns from images than the human visual cognitive system. It ranges\
    \ from raw information recording to \nmethods and ideas that span digital image\
    \ processing, machine learning, and computer graphics. The wide utilization of\
    \ \nComputer Vision has attracted many researchers to incorporate their ideas\
    \ with different fields and disciplines. The era \nof smart cities has emerged\
    \ to meet the recent demands of citizens using information and communication technology.\
    \ \nThis paper reviews research efforts that utilize Deep Learning Frameworks\
    \ and Computer Vision Applications in \nsupport of smart city applications like\
    \ smart healthcare, smart transportation, smart agriculture, etc. Furthermore,\
    \ the \npaper identified key research challenges that emanate from the use of\
    \ deep learning and computer vision in support of \nsmart city services. \nKeywords:\
    \ Agriculture, Computer Vision, Deep Learning, Healthcare, Smart City, Transportation,\
    \ Video \nSurveillance.\n1. INTRODUCTION \nComputer Vision is one of the active\
    \ research fields, \nespecially in the era of AI and robotics science [1]. \n\
    Computer vision has a very important role to make \nremarkable improvements [2].\
    \ The availability of AI \nespecially deep learning makes revolution from Image\
    \ \nProcess to Computer vision, with very rich support from \nDeep learning model\
    \ like CNN, RNN, LSTM, and many \nmore make CV more applicable in different field\
    \ of \nautomation \nlike \nmanufacturing, \ndriverless \ncar, \nhealthcare, education,\
    \ agriculture, satellite images, visual \nQNA, etc. Name computer vision is very\
    \ vast in terms of \napplicability [3]. Computer vision is a combination of \n\
    object \ndetection, \nsegmentation, \nreorganization, \nlocalization, restoration,\
    \ etc. [4-6]. With covering such \nfeatures in computer vision, its applicability\
    \ became \nmore impactful in the field of face recognition as part of \nbiometrics\
    \ identification, automated car, AR/VR, disease \nidentification plays a major\
    \ role in medical science, smart \ncity [7]. Deep learning models can operate\
    \ complex data \nfrom different sources like video, audio, medical images, \n\
    social media, sensor data (IoT), satellite images [8-11]. \nComputer vision algorithms\
    \ are a key element to make \nsmart cities a reality. Smart transportation, energy-saving\
    \ \nautomatic visual sensor, looking at the infrastructure to \nalert anomalies\
    \ activities, counting number of users in \ninfrastructure, taking statistics\
    \ in peak hour, smart \nmonitoring of human resources as well as infrastructures\
    \ \n[12-14]. Computer vision plays a significant role in the \ndevelopment and\
    \ management of smart cities as they are \nthe “Eyes of the city.” In this paper\
    \ we are going to see \nbelow important aspects of smart city in detail like Smart\
    \ \nAtlantis Highlights in Computer Sciences, volume 4\nProceedings of the 3rd\
    \ International Conference on Integrated Intelligent Computing\nCommunication\
    \ & Security (ICIIC 2021)\nCopyright © 2021 The Authors. Published by Atlantis\
    \ Press International B.V.\nThis is an open access article distributed under the\
    \ CC BY-NC 4.0 license -http://creativecommons.org/licenses/by-nc/4.0/.\n14\n\
    \ \n \n \nTransportation, Smart Healthcare, Smart Agriculture, \nand Smart Security\
    \ [15].  \n2. COMPUTER VISION FOR SMART CITY \n2.1 Smart Transportation \nThe\
    \ transportation system is the lifeline of any \ndevelopment and routine of the\
    \ city [16]. The smooth \nfunctioning of the transport system is necessary for\
    \ any \nsmart city concept. Smart transport offers novel and \ninnovative \napproaches\
    \ \nin \ndifferent \nmodes \nof \ntransportation like advanced infrastructure,\
    \ mobility, \ntraffic control, safety. It provides an advanced, safer, \nfaster,\
    \ and smart way of travelling. Features of smart \ntransportation systems are\
    \ public transport management, \nsmart infrastructure management, advanced route\
    \ \nmanagement, advance vehicle control and safety, smart \npayment system, and\
    \ route information [17-19]. \nDifferent technologies in smart transportation\
    \ like GPS \nbased tracking [20], advance sensing technology, \nadvance video\
    \ surveillance. Smart transportation system \nset makeable improvement in smooth\
    \ transit in city, \nminimization of pollution, effective parking system, \nenhance\
    \ security, utilization of resources [21-25]. Smart \nTransportation mainly divide\
    \ in Safety, Efficiency, \nSecurity also known as safe secure and effective \n\
    transportation. \nSafety \nin \ntransportation \ninvolves \napplications like\
    \ Lane Detection, Pedestrian Detection \nand Driver Monitoring. Efficiency cover\
    \ application like \nTraffic flow control, adaptive driving & warning system,\
    \ \nwhile Security is covered by advance traffic surveillance \n[26-29]. Figure\
    \ 1 shows different computer vision \ntechnique which are used in different domain\
    \ of smart \ntransportation. Smart transportation is not limited to \nlisted domain,\
    \ there is also minor domains like \ngovernment rules for transportation [30],\
    \ vehicle support \nfacility, transportation payment facilities\n \n \nFigure\
    \ 1 Pictorial representation of Computer Vision Techniques for Smart Transportation\
    \ \n2.2 Smart Healthcare \nSmart \nhealthcare \nincludes \nvarious \nhealth \n\
    parameters [31]; one of them includes a health \nmonitoring system, which detects\
    \ the motion of the \nhuman body using various techniques like vision-based \n\
    and sensor-based detection for identifying abnormal \nactivities of a patient\
    \ to stop unexpected death of \nhumans because of various illness factors. Motion\
    \ \ndetection is one of the most important technologies in \nbuilding intelligent\
    \ healthcare [32]. There are various \ncharacteristics for patient monitoring\
    \ solutions in \nhealthcare which will be useful in upcoming 5-10 years \n[33].\
    \ This characteristic is based on various categories \nlike medium, sensor-based,\
    \ application based and type \nof camera required for monitoring [34]. Figure\
    \ 2 \ndepicts the characteristics in various categories. Motion \ndetection falls\
    \ mainly into two major categories, vision-\nbased, and sensor-based detection.\
    \ We can have the \nvision-based and sensor-based motion detection \nmethods to\
    \ recognize the fall detection and identify the \nmovements of the patient [35].\
    \ \n \n \n \n \nAtlantis Highlights in Computer Sciences, volume 4\n15\n \n \n\
    \ \n \nFigure 2 Pictorial representation of Key Characteristics for Patient Monitoring\
    \ in Span of Upcoming 5 Years \n2.3 Smart Video Surveillance \nImportance of the\
    \ video surveillance recognition of \nsuspected human activities is to avoid robbery\
    \ cases \n[36], objects which are abandoned by terrorists for \nexplosive attacks,\
    \ mischiefs [37], fights between \npeople and personal attack on someone in the\
    \ many \ndifferent places such as banks [38], hospitals, shopping \narea, parking\
    \ space, public transport stations, airports, \ncolleges, cities, etc. [39]. \n\
    \ \nTable 1. Approaches for Suspicious Activity Recognition and Detection \nWorks/\
    \ Author \nDatasets \nClassification methods \nResult discussion \nTian et al.\
    \ (2012) [39] \nVideo Sequences of \nPETS2006, i-LIDS \nRegion Growing and Edge\
    \ \nEnergy \nShows poor performance in \nlow contrast video sequences, \nfor instance\
    \ white bottles in \nwhite background. \nZin et al. (2012a) [40] \nPETS 2006 and\
    \ Own \ndataset \nRule Based Classifier \nAble to detect tiny objects \nfrom video\
    \ sequences \nFan and Pankanti (2012) [41] \n \ni-LIDS, AB-L1 and ABL2 \nStructure\
    \ Similarity and \nRegion Growing \nAB-L1 and AB-l2 shows that \nfalse positive\
    \ measure is \nreduced by 6% and 3% \nrespectively \nSanMiguel et al. (2012) [42]\
    \ \nASODds dataset (2011) \nBoundary spatial color \ncontrast \nProven that feasible\
    \ for real –\ntime video sequences. \nTripathi et al. (2013) [43] \nPETS 2006\
    \ and PETS \n2007 \nEdge based object \nrecognition \nAchieved very good accuracy\
    \ \nfor both the dataset \nrespectively 84.71% and 100 \n%. \nSajith and Nair\
    \ (2013) [44] \nPETS 2006 and PETS \n2007 \nNeural Network classifier \n(NN) and\
    \ HOG descriptor \nFrom PETS 2006, detected a \nstatic person as an \nabandoned\
    \ object \nFerryman et al. (2013) [45] \nPETS 2006 \nLogic based inference \n\
    engine \n- \nAtlantis Highlights in Computer Sciences, volume 4\n16\n \n \n \n\
    Chitra et al. (2013) [46] \nPETS 2006 \nSupport Vector Machine \n(SVM) \n- \n\
    Nam (2016) [47] \nPETS 2006, PETS 2007 \nand i-LIDS \nSpatio-Temporal \nAchieved\
    \ for i-LIDS-Precision-\n98.88%, Recall-82.28%, F-\nmeasure-82.64% \nVirender\
    \ Singh (2020) [48] \nUCF-Crime Dataset, \nAnnotation, \nPreprocessing Testing\
    \ \nSet \nCNN and RNN \nAchieved accuracy about 96% \nAmrutha (2020) [49] \nKTH\
    \ \nCNN, LSTM, ReLU \nGained accuracy about \n87.15% \nRohit (2020) [50] \nCohn-Kanade,\
    \ faces94, \nfaces95 \nSVM, CNN, RNN \nAchieved accuracy about 82% \nArvind (2020)\
    \ [51] \nOwn Dataset \nLocal binary pattern \nhistogram (LBPH) Classifier \nAchieved\
    \ accuracy about \n93.67% \n2.4 Smart Agriculture \nThere has been ever-increasing\
    \ demand for food \nsupplies due to exponential growth in the world \npopulation.\
    \ Conventional methods alone might not be \nable to keep up with this demand.\
    \ Smart agriculture \nwhich is considered as one of the few realistic ways, \n\
    smart agriculture integrates the use of different \ntechnologies to better monitor\
    \ growth crop yield \nprediction, plant disease detection, weed detection, \n\
    irrigation management, prediction of soil properties etc. \nSmart agriculture\
    \ happens to be one of the many \ndisciplines where use of deep learning and computer\
    \ \nvision are being realized to be of major impact. The use \nof technology in\
    \ relation to smart agriculture should \nenable transmission of correct and accurate\
    \ information \nto farmers at right time.  \nFigure 3 shows popular application\
    \ of Computer \nVision and Deep Learning in Agriculture like plant \ndisease detection\
    \ wherein accurate diagnosis of \nprobable plant disease can save the entire crop\
    \ from \ngetting infected, fruit counting and yield production can \nhelp farmers\
    \ make necessary packing and storage \nrequirements before sale, weather prediction\
    \ to \nminimize crop loss due to severe weather conditions \nand crop type classification\
    \ to identify variety of crops \nusing deep learning models. \n \nFigure 3 Popular\
    \ Applications of Computer Vision and \nDeep Learning in Agriculture \n \nTable\
    \ 2. Major application areas of Computer Vision and Deep Learning in Agriculture\
    \ \nCategory \nReference \nApplication \nDL Model Used \nDataset \nPlant disease\
    \ \ndetection \nShradha et al. [52] \n(2020) \nDetection of healthy \nleaves and\
    \ thirteen \ndifferent diseases \nAlexnet, VGG, \nInception (Modified) \nPlant\
    \ village \ndataset \nAtlantis Highlights in Computer Sciences, volume 4\n17\n\
    \ \n \n \nKonstantinos et al. \n[53] (2018) \nDetection of plant \ndisease for\
    \ 25 plants. \nAlexNet, \nAlexNetOWTBn, \nGoogleNet, \nOverfeat,VGG \nPlant village\
    \ \ndataset \nMohanty et al.[54] \n(2016) \nIdentification of 14 crop \nspecies\
    \ and 26 diseases \nDeep CNN \nPlant village \ndataset \nCrop Count \n \n \n \n\
    \ \n \n \n \nJoao Valente et al. \n[55] (2020) \nTo detect number of \nplants\
    \ on the field that \nemerged after sowing. \nAlexnet \nUAV-acquired \nspinach\
    \ images \nfrom field of \nNetherland \nBruno et al. [56] \n(2019) \nTo detect\
    \ number of \nplants on the field that \nemerged after sowing. \nCorn Plant Counting\
    \ \nU-Net \nUAV acquired \nimages \nSteven et al.[57] (2017) \nOrange and Apple\
    \ count \nNeural Network + \nLinear Regression \nUAV acquired \nimages \nWeather\
    \ Prediction \nAshesh et al.[58] \n(2020) \nprediction of heat waves \nand cold\
    \ spells \nConvNet and \nCapsNet \nLENS dataset \nSnehlata et al.[59] \n(2020)\
    \ \nCyclone Prediction \nXception, \nNasNetMobile, and \nMobile Net \nIMD, MOSDAC\
    \ \nand KALPANA-I \nsatellite images \nRenato et al.[60] \n(2019) \nCrop Yield\
    \ prediction \nbased on crop genotype, \nenvironment and their \ninteractions.\
    \ \nNeural network \n2018 Syngenta \nCrop Challenge \nCrop Yield Prediction \n\
    Peteri et al.[61] (2019) \nCrop yield prediction of \n5 crops: Corn, Cotton, \n\
    Rice, Soyabean, \nSugarcane \nDNN + LSTM \nProduo Agrcola \nMunicipal (PAM) \n\
    Anna et al.[62] (2019) \nPrediction of wheat and \nbarley yield \nCustomised CNN\
    \ \nmodel with \nAdadelta training \nalgorithm \nUAV-acquired \nmultispectral\
    \ \ndata from 9 \nfields. \nAtlantis Highlights in Computer Sciences, volume 4\n\
    18\n \n \n \nCrop Type \nClassification \nYang-yang et al. [63] \n(2020) \nClassifying\
    \ 31 classes of \nfruits and vegetables \nusing various DL models \nVGG16, VGG19,\
    \ \nSqueezeNet, \nInceptionV4, \nDenseNet121, \nResNet18, ResNet50 \nCropDeep\
    \ \ndataset \nLiheng et al.[64] \n(2019) \nClassification of 14 \nsummer crops\
    \ \nConv1D + LSTM \nLandsat Level-2 \ndataset \n3. CHALLENGES \nChallenges in\
    \ smart cities are elaborated here: (i) \naccuracy and robustness in computer\
    \ vision and sensor \nnetwork, enhancement in result with high accuracy \nover\
    \ object detection, object recognition, object \nclassification, segmentation,\
    \ transform learning etc. are \nrequired. Robustness is a major concern in smart\
    \ cities \nbecause \nof \ndifferent \ngeographical \nconditions. \nAtmosphere\
    \ and weather conditions are different for \nvarious geographical area, like areas\
    \ covered with \nmountains, harbour, dusty etc. so more accuracy and \nenhancement\
    \ in technique is required to utilize services \nin real time. (ii) Cybersecurity\
    \ and privacy are also \nchallenging tasks in smart cities. Internet connected\
    \ \ndevices generate and transmit huge chunks of data, \nprivacy for data which\
    \ may be relevant to CCTV, \nmedical diagnosis, fund transfer, gas station or\
    \ \ncharging station, electricity or power supply, food \nsupply, emergency services\
    \ and many more. If there is \na case, criminals easily gain access to data and\
    \ use for \nillegal activity. Hence the government and IT support \nsystem \n\
    should \nstrengthen \nenough \nto \nprevent \ncyberattack.  (iii) Infrastructure,\
    \ well equipped \nresources are required to install and utilize smart \ntechnology\
    \ like Artificial Intelligent, Computer vision, \nIoT. (iv) Engaging the community,\
    \ smart city truly \nexists, when citizens are engaged and actively involved \n\
    in new projects and practices.  \n4. CONCLUSION \nComputer Vision is used to provide\
    \ better \nquantitative \ninformation \nthat \nis \nunobtainable \nsubjectively,\
    \ leading to the eventual replacement of \nhuman effort. Computer Vision is a\
    \ necessary and \npromising one for analysing the qualities and \ninformation\
    \ using different convolution networks like \nAlexNet, ZFNet, VGG-19, ResNet etc.\
    \ These model \nlearning systems are an essential part of feature \nextraction.\
    \ Deep learning frameworks are a cornerstone \nfor Computer Vision and used in\
    \ variety of visual \nunderstanding tasks, such as object detection, face \nrecognition,\
    \ action and activity recognition, human \npose estimation, image retrieval, and\
    \ semantic \nsegmentation. The most applicability of Computer \nVision is in smart\
    \ cities involving new use cases related \nto smart healthcare, smart transportation,\
    \ video \nsurveillance and smart agriculture. These are among the \nmost important\
    \ open issues in Smart City that attract \nthe interest of the research community\
    \ in Computer \nVision. \nREFERENCES \n[1] Vinayakumar R SSQVPSKP Mamoun Alazab.\
    \ A \nVisualized Botnet Detection System based Deep \nLearning for the Internet\
    \ of Things Networks of \nSmart Cities. IEEE Transactions on Industry \nApplications\
    \ 2020. \n[2] N Doulamis AD, Protopapadakis E. Deep \nLearning for Computer Vision:\
    \ A Brief Review \n2018. [3] \nC. Baier, J-P. Katoen, Principles of \nModel Checking,\
    \ MIT Press, 2008.  \n[3]   Bhuvaneswary, N., S. Prabu, S. Karthikeyan, R. \n\
    Kathirvel, and T. Saraswathi. \"Low Power \nReversible \nParallel \nand \nSerial\
    \ \nBinary \nAdder/Subtractor.\" Further Advances in Internet \nof Things in Biomedical\
    \ and Cyber Physical \nSystems (2021): 151. \n[4] Prabu, S., Balamurugan Velan,\
    \ F. V. Jayasudha, P. \nVisu, and K. Janarthanan. \"Mobile technologies \nfor\
    \ contact tracing and prevention of COVID-19 \npositive \ncases: \na \ncross-sectional\
    \ \nstudy.\" International \nJournal \nof \nPervasive \nComputing and Communications\
    \ (2020).  \n[5] Y. Sun, J. Liu, K. Yu, M. Alazab, K. Lin, “PMRSS: \nPrivacy-preserving\
    \ Medical Record Searching \nScheme \nfor \nIntelligent \nDiagnosis \nin \nIoT\
    \ \nHealthcare”, IEEE Transactions on Industrial \nInformatics, doi: 10.1109/TII.2021.3070544.\
    \  \n[6]   Z. Guo, L. Tang, T. Guo, K. Yu, M. Alazab, A. \nShalaginov, “Deep Graph\
    \ Neural Network-based \nSpammer Detection Under the Perspective of \nHeterogeneous\
    \ Cyberspace”, Future Generation \nComputer Systems.  \n[7]  Rajendrakumar, Shiny,\
    \ and V. K. Parvati. \n\"Automation \nof \nirrigation \nsystem \nthrough \nAtlantis\
    \ Highlights in Computer Sciences, volume 4\n19\n \n \n \nembedded \ncomputing\
    \ \ntechnology.\" \nIn Proceedings \nof \nthe \n3rd \nInternational \nConference\
    \ on Cryptography, Security and \nPrivacy, pp. 289-293. 2019.  \n[8]   Kumar,\
    \ M. Keerthi, B. D. Parameshachari, S. \nPrabu, and Silvia liberata Ullo. \"Comparative\
    \ \nAnalysis to Identify Efficient Technique for \nInterfacing BCI System.\" In\
    \ IOP Conference \nSeries: Materials Science and Engineering, vol. \n925, no.\
    \ 1, p. 012062. IOP Publishing, 2020.  \n[9]  Subramani, Prabu, K. Srinivas, R.\
    \ Sujatha, and B. \nD. Parameshachari. \"Prediction of muscular \nparalysis disease\
    \ based on hybrid feature \nextraction with machine learning technique for \n\
    COVID-19 \nand \npost-COVID-19 \npatients.\" Personal \nand \nUbiquitous \nComputing\
    \ (2021): 1-14. \n[10] Naeem, Muhammad Ali, Tu N. Nguyen, Rashid \nAli, Korhan\
    \ Cengiz, Yahui Meng, and Tahir \nKhurshaid. \"Hybrid Cache Management in IoT-\n\
    based Named Data Networking.\" IEEE Internet of \nThings Journal (2021). \n[11]\
    \ Le, Ngoc Tuyen, Jing-Wein Wang, Duc Huy Le, \nChih-Chiang Wang, and Tu N. Nguyen.\
    \ \n\"Fingerprint enhancement based on tensor of \nwavelet \nsubbands \nfor \n\
    classification.\" IEEE \nAccess 8 (2020): 6602-6615.  \n[12] Do, Dinh-Thuan, Tu\
    \ Anh Le, Tu N. Nguyen, \nXingwang Li, and Khaled M. Rabie. \"Joint \nimpacts\
    \ of imperfect CSI and imperfect SIC in \ncognitive \nradio-assisted \nNOMA-V2X\
    \ \ncommunications.\" IEEE \nAccess 8 \n(2020): \n128629-128645. \n[13] Alazab\
    \ T M Tang. Deep Learning Applications for \nCyber \nSecurity \nsegmentation \n\
    and \nfeature \nselection. Advanced Sciences and Technologies \nfor Security Applications,\
    \ Springer International \n2019. \n[14] Farhan Ullah SJFATMA Junfeng Wang. Source\
    \ \nCode Authorship Attribution Using Hybrid \nApproach of Program Dependence\
    \ Graph and \nDeep Learning Model 2019.  \n[15] C Szegedy SIJSZW V Vanhoucke.\
    \ Rethinking the \ninception architecture for computer vision 2016.  \n[16] Anjali\
    \ Goel “Lane Detection Techniques - A \nReview”, International Journal of Computer\
    \ \nScience and Mobile Computing, International \nJournal of Computer Science\
    \ and Mobile \nComputing – 2014. \n[17] Yeongmin Ko et al.“Key Points Estimation\
    \ and \nPoint Instance Segmentation Approach for Lane \nDetection” Submitted to\
    \ \"IEEE Transactions on \nIntelligent Transportation Systems 2020.  \n[18] Y.\
    \ Hou, Z. Ma2, C. Liu2, C Change Loy \n“Learning Lightweight Lane Detection CNNs\
    \ by \nSelf Attention Distillation”. ICCV 2019. \n[19] A. Revelo, R. Álvarez and\
    \ F. Grijalva, \"Human \nDrowsiness Detection In Real Time, Using \nComputer Vision,\"\
    \ 2019 IEEE Fourth Ecuador \nTechnical Chapters Meeting (ETCM), Guayaquil, \n\
    Ecuador, \npp. \n1-6, \ndoi: \n10.1109/ETCM48019.2019.9014884, 2019. \n[20] Nataniel\
    \ Ruiz, Eunji Chong James, M. Rehg \n“Fine-Grained Head Pose EstimationWithout\
    \ \nKeypoints”, Accepted to Computer Vision and \nPattern Recognition Workshops\
    \ (CVPRW), IEEE \nConference, 2018. \n[21] Wang, Haofan & Chen, Zhenghua & Zhou,\
    \ Yi., \nHybrid coarse-fine classification for head pose \nestimation, 2019. \n\
    [22] Yang, Tsun-Yi, et al. \"Fsa-net: Learning fine-\ngrained structure aggregation\
    \ for head pose \nestimation from a single image.\" Proceedings of \nthe IEEE\
    \ Conference on Computer Vision and \nPattern Recognition, 2019.  \n[23] C. Tang\
    \ et al. “Improving Pedestrian Attribute \nRecognitionWith Weakly-Supervised Multi-Scale\
    \ \nAttribute-Specific Localization” Accepted by \nICCV 2019.  \n[24] Liu, Xihui\
    \ & Zhao, Haiyu & Tian, Maoqing & \nSheng, Lu & Shao, Jing & Yi, Shuai & Yan,\
    \ Junjie \n& Wang, Xiaogang. (2017). HydraPlus-Net: \nAttentive Deep Features\
    \ for Pedestrian Analysis. \n350-359. 10.1109/ICCV.2017.46, 2017.  \n[25] Tabernik,\
    \ Domen, and Danijel Skočaj. \"Deep \nlearning for large-scale traffic-sign detection\
    \ and \nrecognition.\" IEEE Transactions on Intelligent \nTransportation Systems\
    \ 21.4 (2019): 1427-1440, \n2019. \n[26] Dollár, Piotr & Wojek, Christian & Schiele,\
    \ Bernt \n& Perona, Pietro. (2011). Pedestrian Detection: \nAn Evaluation of the\
    \ State of the Art. IEEE \ntransactions on pattern analysis and machine \nintelligence.\
    \ \n34. \n743-61. \n10.1109/TPAMI.2011.155, 2011.  \n[27] Felzenszwalb, Pedro\
    \ & Girshick, Ross & \nMcallester, David & Ramanan, Deva. Object \nDetection with\
    \ Discriminatively Trained Part-\nBased Models. IEEE transactions on pattern \n\
    analysis and machine intelligence. 32. 1627-45. \n10.1109/TPAMI.2009.167, 2010.\
    \  \n[28] A. Arinaldi, et al. “Detection and classification of \nvehicles for\
    \ traffic video analytics” INNS \nConference on Big Data and Deep Learning, 2018.\
    \ \n[29] Lee, Seokju, et al. \"Vpgnet: Vanishing point \nguided network for lane\
    \ and road marking \ndetection and recognition.\" Proceedings of the \nAtlantis\
    \ Highlights in Computer Sciences, volume 4\n20\n \n \n \nIEEE international conference\
    \ on computer \nvision, 2017.  \n[30] Fan Zhang, et al. DetReco: Object-Text Detection\
    \ \nand Recognition Based on Deep Neural Network, \nMathematical Problems in Engineering\
    \ Volume \n2020, Article ID 2365076 -2020.  \n[31] O. Shobayo, et al. Development\
    \ of Smart Plate \nNumber Recognition System for Fast Cars with \nWeb \nApplication,\
    \ \nApplied \nComputational \nIntelligence and Soft Computing Volume 2020, \n\
    Article ID 8535861, 2020  \n[32] Barringer, R. Kuiper, A. Pnueli, Now you may\
    \ \ncompose temporal logic specifications, in: \nProceedings of the Sixteenth\
    \ Annual ACM \nSymposium on the Theory of Computing (STOC), \nACM, 1984, pp. 51–63.\
    \ DOI:  \n[33] Xinyue Yang, Xiaoyang Ren, Meng Chen, Luqi \nWang, Yuhao Ding.\
    \ \"Human Posture Recognition \nin Intelligent Healthcare\", Journal of Physics:\
    \ \nConference Series, 2020.  \n[34] Yilmaz A, Javed O, Shah M (2006) Object \n\
    tracking: a survey. ACM Comput Surv 38(4):13, \n2006. \n[35] L. Tan, K. Yu, F.\
    \ Ming, X. Cheng, G. Srivastava, \n“Secure and Resilient Artificial Intelligence\
    \ of \nThings: a HoneyNet Approach for Threat \nDetection and Situational Awareness”,\
    \ IEEE \nConsumer Electronics Magazine, 2021, doi: \n10.1109/MCE.2021.3081874.\
    \  \n[36] L. Tan, N. Shi, K. Yu, M. Aloqaily, Y. Jararweh, \n“A \nBlockchain-Empowered\
    \ \nAccess \nControl \nFramework for Smart Devices in Green Internet of \nThings”,\
    \ \nACM \nTransactions \non \nInternet \nTechnology, \nvol. \n21, \nno. \n3, \n\
    pp. \n1-20, \n2021,https://doi.org/10.1145/3433542. \n[37] Z. Guo, A. K. Bashir,\
    \ K. Yu, J. C. Lin, Y. Shen, \n“Graph Embedding-based Intelligent Industrial \n\
    Decision \nfor \nComplex \nSewage \nTreatment \nProcesses”, International Journal\
    \ of Intelligent \nSystems，2021, doi: 10.1002/int.22540.  \n[38] Z. Guo, K. Yu,\
    \ A. Jolfaei, A. K. Bashir, A. O. \nAlmagrabi, and N. Kumar, “A Fuzzy Detection\
    \ \nSystem for Rumors through Explainable Adaptive \nLearning”, IEEE Transactions\
    \ on Fuzzy Systems, \ndoi: 10.1109/TFUZZ.2021.3052109.  \n[39] Tian Y, Senior\
    \ A, Lu M (2012) Robust and \nefficient \nforeground \nanalysis \nin \ncomplex\
    \ \nsurveillance videos. Mach Vis Appl 23(5):967–\n983, 2012 .  \n[40] Zin TT,\
    \ Tin P, Toriu T, Hama H (2012a) A novel \nprobabilistic video analysis for stationary\
    \ object \ndetection in video surveillance systems. IAENG \nInt J Comput Sci 39(3):295–306,\
    \ 2012  \n[41] Fan Q, Pankanti S (2012) Robust foreground and \nabandonment analysis\
    \ for large-scale abandoned \nobject detection in complex surveillance videos.\
    \ \nIn: IEEE ninth international conference on \nadvanced video and signal- based\
    \ surveillance \n(AVSS), IEEE, pp 58–63, 2012.  \n[42] SanMiguel J, Caro L, Martinez\
    \ J, Pixel-based \ncolour contrast for abandoned and stolen object \ndiscrimination\
    \ in video surveillance. Electron Lett \n48(2):86–87, 2012.  \n[43] Tripathi RK,\
    \ Jalal AS, Bhatnagar C (2013) A \nframework for abandoned object detection from\
    \ \nvideo \nsurveil- \nlance. \nIn: \nFourth \nnational \nconference \non \ncomputer\
    \ \nvision, \npattern \nrecognition, image processing and graphics \n(NCVPRIPG),\
    \ IEEE, pp 1–4, 2013  \n[44] Sajith K, Nair KR (2013) Abandoned or removed \n\
    objects detection from surveillance video using \ncodebook. Int J Eng Res Technol\
    \ 2:401–406, \n2013.  \n[45] Ferryman J, Hogg D, Sochman J, Behera A, \nRodriguez-Serrano\
    \ JA, Worgan S, Li L, Leung V, \nEvans M, Cornic P et al (2013) Robust abandoned\
    \ \nobject detection integrating wide area visual \nsurveillance and social context.\
    \ Pattern Recogn \nLett 34(7):789–798, 2013. \n[46] Chitra M, Geetha MK, Menaka\
    \ L, et al (2013) \nOcclusion and abandoned object detection for \nsurveillance\
    \ applications. Int J Comput Appl \nTechnol Res 2(6):708– meta, 2013. \n[47] Nam\
    \ Y (2016) Real-time abandoned and stolen \nobject detection based on spatiotemporal\
    \ features \nin crowded scenes. Multimed Tools Appl \n75(12):7003–7028, 2016.\
    \  \n[48] Virender Singha, Swati Singha, Dr. Pooja Gupta, \nReal-Time Anomaly\
    \ Recognition Through CCTV \nUsing Neural Networks, International Conference \n\
    on Smart Sustainable Intelligent Computing and \nApplications under ICITETM2020,\
    \ 2020. \n[49] Amrutha C.V, C. Jyotsna, Amudha J., Deep \nLearning Approach for\
    \ Suspicious Activity \nDetection from Surveillance Video, Proceedings \nof the\
    \ Second International Conference on \nInnovative Mechanisms for Industry Applications\
    \ \n(ICIMIA 2020) IEEE Xplore Part Number: \nCFP20K58-ART; \nISBN: \n978-1-7281-4167-1,\
    \ \n2020.  \n[50] Rohit Rastogi, Rishabh Jain, Puru Jain, Parul \nSinghal, Priyanshi\
    \ Garg and Mukund Rastogi, \nInference-Based \nStatistical \nAnalysis \nfor \n\
    Suspicious Activity Detection Using Facial \nAnalysis, Computational Intelligence\
    \ in Pattern \nRecognition, Proceedings of CIPR, 2020 \n[51] Arvind Jaiswal, Sandhya\
    \ Tarar, Real-Time \nBiometric system for security and surveillance \nAtlantis\
    \ Highlights in Computer Sciences, volume 4\n21\n \n \n \nusing \nface \nrecognition,\
    \ \n4th \nInternational \nConference, ICACDS 2020 ,Valletta, Malta, April \n24–25,\
    \ 2020. \n[52] Shradha S. Pradhan and Rupali Patil, Comparison \nof Deep Learning\
    \ Approaches for Plant Disease \nDetection, H. Vasudevan et al. (eds.), Proceedings\
    \ \nof \nInternational \nConference \non \nWireless \nCommunication, \nLecture\
    \ \nNotes \non \nData \nEngineering and Communications Technologies, \nSpringer\
    \ Nature Singapore Pte Ltd, 2020. \n[53] Konstantinos P.Ferentinos, Deep learning\
    \ models \nfor plant disease detection and diagnosis, \nComputers and Electronics\
    \ in Agriculture Volume \n145, February 2018, Pages 311-318  \n[54] Mohanty, S.P.,\
    \ Hughes, D.P., Salathé, M., 2016. \nUsing deep learning for image-based plant\
    \ disease \ndetection. Front. Plant. Sci. 7.  \n[55] Joao Valente, Bilal Sari,\
    \ Lammert Kooistra, Henk \nKramer, Sander Mucher, Automated crop plant \ncounting\
    \ \nfrom \nvery \nhigh-resolution \naerial \nimagery, Precision Agriculture, 2020.\
    \ \n[56] Bruno T. Kitano, Caio C. T. Mendes , André R. \nGeus, Henrique C. Oliveira\
    \ , and Jefferson R. \nSouza, Corn Plant Counting Using Deep Learning \nand UAV\
    \ Images, IEEE GEOSCIENCE AND \nREMOTE SENSING LETTERS, 2019.  \n[57] Steven W\
    \ Chen, Shreyas S. Shivakumar , Sandeep \nDcunha, Jnaneshwar Das , Edidiong Okon\
    \ , Chao \nQu , Camillo J. Taylor , and Vijay Kumar, \nCounting Apples and Oranges\
    \ with Deep \nLearning: A Data Driven Approach, IEEE \nROBOTICS AND AUTOMATION\
    \ LETTERS, \n2017.  \n[58] Ashesh Chattopadhyay Ebrahim Nabizadeh \nPedram Hassanzadeh,\
    \ Analog Forecasting of \nExtreme‐Causing Weather Patterns Using Deep \nLearning,\
    \ Journal of Advances in Modeling Earth \nSystems, Feb, 2020  \n[59] Snehlata\
    \ Shakya , Sanjeev Kumar, and Mayank \nGoswami, Deep Learning Algorithm for Satellite\
    \ \nImaging \nBased \nCyclone \nDetection, \nIEEE \nJOURNAL \nOF \nSELECTED \n\
    TOPICS \nIN \nAPPLIED EARTH OBSERVATIONS AND \nREMOTE SENSING, VOL. 13, 2020 \
    \ \n[60] Renato Luiz de Freitas Cunha, Bruno Silva, \nESTIMATING CROP YIELDS WITH\
    \ REMOTE \nSENSING AND DEEP LEARNING, Latin \nAmerican GRSS & ISPRS Remote Sensing\
    \ \nConference, 2020 ( arXiv:2007.10882v1). \n[61] Petteri Nevavuori, Nathaniel\
    \ Narraa Tarmo \nLippinga, Crop yield prediction with deep \nconvolutional neural\
    \ networks, Computers and \nElectronics in Agriculture, Volume 163, 104859, \n\
    August 2019. \n[62] Anna X. Wang, Caelin Tran, Nikhil Desai, David \nLobell, Stefano\
    \ Ermon, Deep Transfer Learning \nfor Crop Yield Prediction with Remote Sensing\
    \ \nData, Proceedings of the 1st ACM SIGCAS \nConference on Computing and Sustainable\
    \ \nSocieties, June 2018.  \n[63] Yang-Yang Zheng, Jian-Lei Kong ,Xue-Bo Jin,\
    \ \nXiao-Yi Wang,Ting-Li Su and Min Zuo, \nCropDeep: The Crop Vision Dataset for\
    \ Deep-\nLearning-Based Classification and Detection in \nPrecision Agriculture,\
    \ Internet-of-Things for \nPrecision Agriculture (IoAT)), Feb 2020.  \n[64] Liheng\
    \ Zhonga, Lina Hub , Hang Zhouc, Deep \nlearning based multi-temporal crop classification,\
    \ \nRemote Sensing of Environment, 2019.\n \nAtlantis Highlights in Computer Sciences,\
    \ volume 4\n22\n"
  inline_citation: '>'
  journal: Atlantis highlights in computer sciences
  limitations: '>'
  pdf_link: https://www.atlantis-press.com/article/125960870.pdf
  publication_year: 2021
  relevance_score1: 0
  relevance_score2: 0
  title: 'The Convergence of Deep Learning and Computer Vision: Smart City Applications
    and Research Challenges'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/plants11233344
  analysis: '>'
  authors:
  - Narendra Singh Chandel
  - Yogesh Anand Rajwade
  - Kumkum Dubey
  - Abhilash K. Chandel
  - A. Subeesh
  - Mukesh Tiwari
  citation_count: 8
  full_citation: '>'
  full_text: ">\nCitation: Chandel, N.S.; Rajwade,\nY.A.; Dubey, K.; Chandel, A.K.;\n\
    Subeesh, A.; Tiwari, M.K. Water\nStress Identiﬁcation of Winter Wheat\nCrop with\
    \ State-of-the-Art AI\nTechniques and High-Resolution\nThermal-RGB Imagery. Plants\
    \ 2022,\n11, 3344. https://doi.org/10.3390/\nplants11233344\nAcademic Editors:\
    \ John T. Hancock\nand Mikihisa Umehara\nReceived: 8 October 2022\nAccepted: 27\
    \ November 2022\nPublished: 2 December 2022\nPublisher’s Note: MDPI stays neutral\n\
    with regard to jurisdictional claims in\npublished maps and institutional afﬁl-\n\
    iations.\nCopyright:\n© 2022 by the authors.\nLicensee MDPI, Basel, Switzerland.\n\
    This article is an open access article\ndistributed\nunder\nthe\nterms\nand\n\
    conditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n\
    4.0/).\nplants\nArticle\nWater Stress Identiﬁcation of Winter Wheat Crop with\n\
    State-of-the-Art AI Techniques and High-Resolution\nThermal-RGB Imagery\nNarendra\
    \ S. Chandel 1, Yogesh A. Rajwade 2,*\n, Kumkum Dubey 1, Abhilash K. Chandel 3,4,*\n\
    , A. Subeesh 1\nand Mukesh K. Tiwari 5\n1\nAgricultural Mechanization Division,\
    \ ICAR—Central Institute of Agricultural Engineering,\nBhopal 462038, MP, India\n\
    2\nIrrigation and Drainage Engineering Division, ICAR—Central Institute of Agricultural\
    \ Engineering,\nBhopal 462038, MP, India\n3\nDepartment of Biological Systems\
    \ Engineering, Virginia Tech Tidewater AREC, Suffolk, VA 23437, USA\n4\nCenter\
    \ for Advanced Innovation in Agriculture (CAIA), Virginia Tech, Blacksburg, VA\
    \ 24061, USA\n5\nCollege of Agricultural Engineering and Technology, Anand Agricultural\
    \ University, Godhra 389001, GJ, India\n*\nCorrespondence: yogesh.rajwade@icar.gov.in\
    \ (Y.A.R.); abhilashchandel@vt.edu (A.K.C.)\nAbstract: Timely crop water stress\
    \ detection can help precision irrigation management and minimize\nyield loss.\
    \ A two-year study was conducted on non-invasive winter wheat water stress monitoring\n\
    using state-of-the-art computer vision and thermal-RGB imagery inputs. Field treatment\
    \ plots were\nirrigated using two irrigation systems (ﬂood and sprinkler) at four\
    \ rates (100, 75, 50, and 25% of crop\nevapotranspiration [ETc]). A total of 3200\
    \ images under different treatments were captured at critical\ngrowth stages,\
    \ that is, 20, 35, 70, 95, and 108 days after sowing using a custom-developed\
    \ thermal-\nRGB imaging system. Crop and soil response measurements of canopy\
    \ temperature (Tc), relative\nwater content (RWC), soil moisture content (SMC),\
    \ and relative humidity (RH) were signiﬁcantly\naffected by the irrigation treatments\
    \ showing the lowest Tc (22.5 ± 2 ◦C), and highest RWC (90%)\nand SMC (25.7 ±\
    \ 2.2%) for 100% ETc, and highest Tc (28 ± 3 ◦C), and lowest RWC (74%) and SMC\n\
    (20.5 ± 3.1%) for 25% ETc. The RGB and thermal imagery were then used as inputs\
    \ to feature-\nextraction-based deep learning models (AlexNet, GoogLeNet, Inception\
    \ V3, MobileNet V2, ResNet50)\nwhile, RWC, SMC, Tc, and RH were the inputs to\
    \ function-approximation models (Artiﬁcial Neural\nNetwork (ANN), Kernel Nearest\
    \ Neighbor (KNN), Logistic Regression (LR), Support Vector Machine\n(SVM) and\
    \ Long Short-Term Memory (DL-LSTM)) to classify stressed/non-stressed crops. Among\n\
    the feature extraction-based models, ResNet50 outperformed other models showing\
    \ a discriminant\naccuracy of 96.9% with RGB and 98.4% with thermal imagery inputs.\
    \ Overall, classiﬁcation accuracy\nwas higher for thermal imagery compared to\
    \ RGB imagery inputs. The DL-LSTM had the highest\ndiscriminant accuracy of 96.7%\
    \ and less error among the function approximation-based models for\nclassifying\
    \ stress/non-stress. The study suggests that computer vision coupled with thermal-RGB\n\
    imagery can be instrumental in high-throughput mitigation and management of crop\
    \ water stress.\nKeywords: winter wheat; crop water stress; canopy temperature;\
    \ computer vision; irrigation\nmanagement\n1. Introduction\nWater stress forces\
    \ leaf stomata closure, which reduces transpiration and increases\ncanopy temperature\
    \ (Tc) [1]. Timely estimation of those stressors may not only help preci-\nsion\
    \ irrigation management but also minimize yield losses [2]. The penalty gap between\n\
    actual and potential yield will widen further as a result of climate change that\
    \ projects\na decline in rainfall frequency, and rising ambient temperatures [3].\
    \ Water stress is typ-\nically assessed using xylem water potentials [4], canopy\
    \ thermometry [5], and stomatal\nPlants 2022, 11, 3344. https://doi.org/10.3390/plants11233344\n\
    https://www.mdpi.com/journal/plants\nPlants 2022, 11, 3344\n2 of 21\nconductance\
    \ measurements [6]. However, these methods are often invasive and tend\nto have\
    \ limited sampling accuracy due to low throughput or point data acquisitions [7].\n\
    Non-invasive proximal or remote sensing techniques have emerged as high throughput\n\
    alternatives for monitoring crop water stress through color features, reﬂectance,\
    \ and ther-\nmal emissivity of the vegetable, fruit, and specialty crops [8–10].\
    \ However, monitoring\ncrop water content using visible-range RGB imaging not\
    \ only requires speciﬁc leaf ori-\nentation relative to the camera but also pre-deﬁned\
    \ illumination conditions. This limits\nthe applicability of RGB imaging to determine\
    \ water content in ﬁeld conditions. Using\nscanner-type imaging devices could\
    \ be a cost and time-effective alternative [11]. Unlike\nthermometry, Tc from\
    \ thermal infrared imagery reﬂects upon the entire canopy emissivity\nproﬁle,\
    \ which is directly proportional to the canopy water content [9]. Thermal imagery\n\
    (8000–14,000 nm) also outperforms color RGB imagery (400–700 nm), and reﬂectance\
    \ char-\nacteristics in terms of robustness to characterize crop water stress\
    \ [8,9]. Nonetheless, the\nadaptability of thermal imaging in agricultural production\
    \ management is still at a nascent\nstage and is consistently evolving to maintain\
    \ imaging quality against drastic variations\nin relative humidity and wind speeds.\
    \ Thermal imaging cameras are also relatively more\nexpensive than simple-to-operate\
    \ RGB cameras. It is for these reasons; thermal imaging\nis still limitedly adopted\
    \ as a golden standard for crop stress mapping. Above all, long-\nwave infrared\
    \ wavelengths (thermal imaging) have a higher penetrating capability over\nvisible-range\
    \ wavelengths, making them more reliable and sensitive to crop water content\n\
    variations. Thermal imaging is therefore a better alternative for precision irrigation\
    \ man-\nagement unlike RGB imaging or using standard crop coefﬁcients coupled\
    \ with reference\nevapotranspiration [8,9].\nRGB imagery has been used to assess\
    \ crop water stress using different deep learning\n(DL) and machine learning (ML)\
    \ techniques [10,12,13]. ML techniques derive unique\nfeatures from input and\
    \ output datasets, which could be used for discrimination between\ndifferent object\
    \ types or classes. ML techniques such as Naïve Bayes, artiﬁcial neural\nnetworks\
    \ (ANNs), support vector machine (SVM), and random forests (RFs) have been\nwidely\
    \ used with RGB images for weed detection, biotic and abiotic stress identiﬁcation\n\
    and/or classiﬁcation, yield predictions, and other crop phenotyping applications\
    \ [14,15].\nThermal imagery has also been used with RFs and decision trees for\
    \ crop water status\nmonitoring in the vineyard and automated irrigation scheduling\
    \ [16]. However, there are\nseveral limitations associated with ML techniques.\
    \ The output quality is highly dependent\non input data quality, the presence\
    \ of noise and outliers, and other unaccounted biases\nthat have been reported\
    \ to signiﬁcantly affect the model performance. Furthermore, ML\ntechniques also\
    \ require skilled operators [17] for deﬁning input features that may also often\n\
    affect the model performances through unintentional subjectivity and bias [10,12].\n\
    DL has emerged as an advanced vision-based learning technique that enables au-\n\
    tomated feature extraction without human dependencies unlike ML [18]. Pertinent\
    \ to\nagricultural applications, crop phenological stages have been detected using\
    \ a deep con-\nvolution neural network (DCNN) trained on RGB imagery [19,20].\
    \ Similarly, different DL\ntechniques (AlexNet, GoogLeNet, and Inception V3) have\
    \ also been used to classify non-\nstressed and water-stressed soybean, maize,\
    \ and okra crops with digital RGB images [10].\nLong Short Term Memory (LSTM)\
    \ is a novel DL approach (DL-LSTM) that has been used\nfor different ﬁeld applications\
    \ like time series forecasting of wheat yield and productiv-\nity [21], irrigation\
    \ requirement [22], predicting agricultural product sale volumes based\non seasonal\
    \ and historical data [23], and identiﬁcation and classiﬁcation of weeds [24].\n\
    Most of the image processing studies have used RGB images (or visible range imagery)\
    \ to\nclassify crop water stress [25,26]. Thermal imagery has been reported to\
    \ be more robust\nfor crop water stress characterization compared to RGB or multispectral\
    \ imagery [27,28].\nThis is majorly due to the fact that the canopy emissivity\
    \ can be highly sensitive to water\ncontent [8,9,29,30].\nSo far, crop water stress\
    \ characterization has been carried out through traditional\nand destructive methods\
    \ that often have restricted commercial applicability. Moreover,\nPlants 2022,\
    \ 11, 3344\n3 of 21\nthese techniques have been limitedly explored using robust\
    \ computer-vision techniques\n(ML or DL models) for thermal infrared imagery inputs.\
    \ Small unmanned aerial system\n(UAS)-based thermal and multispectral remote sensing\
    \ is also being explored for high\nthroughput crop water stress phenotyping. However,\
    \ the frequency of data acquisition\nis limited to once or a few times a day and\
    \ atmospheric interferences including weather\nconditions may severely impact\
    \ the quality of thermal imaging. Additionally, onboard\ndata processing potential\
    \ for complex and robust algorithms is still limited for small UASs.\nContrarily,\
    \ proximal thermal imaging is subjected to the least atmospheric interference\n\
    and imaging frequency constraints. These systems can continuously collect data\
    \ at critical\ngrowth stages and also offer ﬂexibility for custom modiﬁcation\
    \ to implement onboard edge\nprocessing algorithms for real-time decision support\
    \ and management actuation. On the\ncost side, thermal and RGB imaging sensors\
    \ and the UASs are still far more expensive than\nthe proximal imaging systems,\
    \ which can be custom-assembled using miniature sensing\nmodules. However, such\
    \ miniature sensing modules neither offer sufﬁcient resolution nor\ndesired image\
    \ quality when integrated with UASs.\nObtaining robust data handling and the analytical\
    \ pipeline is the major obstacle to\nderiving real-time decision support for crop\
    \ management but is achievable using custom-\nassembled edge devices. This study\
    \ is a step toward alleviating those obstacles and\nfocuses on the evaluation\
    \ of non-invasive and cost-effective thermal-RGB imaging with\nrobust ML and DL\
    \ models for stress characterization in winter wheat crops. This could\nbe critical\
    \ from a precision irrigation scheduling and management perspective and may\n\
    potentially have high grower adaptability. Speciﬁc objectives for this two-year\
    \ study were\nto (a) non-invasively assess the crop responses to two irrigation\
    \ systems and four deﬁcit\nirrigation treatments, and (b) identify the water-stressed\
    \ and non-stressed crops by feature\nextraction using thermal-RGB imagery and\
    \ function approximation approaches using crop\nphysiological parameters and ambient\
    \ weather inputs.\n2. Materials and Methods\n2.1. Experiment Design\nWinter wheat\
    \ (Triticum aestivum L., cv. HI 1544) was planted (November to April,\n2019–2020,\
    \ and 2020–2021) in the research farm (77.24◦ E, 23.18◦ N) of the Central Institute\n\
    of Agricultural Engineering (CIAE), ICAR Bhopal, India (Figure 1). The meteorological\n\
    data are being recorded at the institute observatory since 1985. According to\
    \ Koppen’s\nclassiﬁcation (1934), Bhopal is a Mediterranean climatic zone with\
    \ an average annual\nrainfall of about 1127 mm. The soil type is heavy clay (Vertisols)\
    \ with clay content over 50%\nand moderate fertility with negligible salinity.\
    \ Soil structure is sub-angular blocky with a\nﬁeld capacity of 29.5–32% (db)\
    \ and wilting point of 18-19.5% (db). The average inﬁltration\nand percolation\
    \ rates of the soil are 10–12 mm day−1 and 6.3–7.0%, respectively. The plots\n\
    were irrigated using ﬂood and sprinkler systems at four treatment rates: 100,\
    \ 75, 50, and\n25% of full crop evapotranspiration (ETc). Micro sprinklers of\
    \ 120 lph discharge capacity\n(Make: Netaﬁm) were installed at 3.5 m spacing.\
    \ The reference crop evapotranspiration was\ncalculated using weather data with\
    \ the FAO56 Penman–Montieth method and standard\nnon-stressed crop coefﬁcient\
    \ [31]. The seasonal ETc of wheat during the ﬁrst and second\nyears of growth\
    \ was 380 mm and 345 mm, respectively. The application efﬁciencies of\n0.65 for\
    \ ﬂood irrigation and 0.90 for sprinkler irrigation were used as determined from\n\
    the experiment trials on the same site using the measurements of water applied\
    \ and the\nwater retained in the crop root zone. A total of six irrigation cycles\
    \ were implemented for\n100% ETc treatment (non-stressed) at sowing, crown root\
    \ initiation (CRI), tillering, booting,\nﬂowering, and grain ﬁlling stages. One\
    \ to three irrigation cycles were implemented for\ndeﬁcit treatments (75, 50,\
    \ and 25% of ETc) at jointing, booting, and ﬂowering stages.\nPlants 2022, 11,\
    \ 3344\n4 of 21\nPlants 2022, 11, x FOR PEER REVIEW \n4 of 22 \n \n \ncrown root\
    \ initiation (CRI), tillering, booting, flowering, and grain filling stages. One\
    \ to \nthree irrigation cycles were implemented for deficit treatments (75, 50,\
    \ and 25% of ETc) at \njointing, booting, and flowering stages. \n \nFigure 1.\
    \ Experimental layout of the winter wheat crop irrigated at different rates using\
    \ sprinkler \nand flood irrigation systems [32]. R—Replicates. Layout is prepared\
    \ over google map. \n2.2. Data Collection \nRGB and thermal imagery were synchronously\
    \ captured using a multifunctional \ncustom integrated thermal-RGB imaging system.\
    \ The system has a single board com-\nputer (B+, Raspberry Pi foundation), a thermal\
    \ imaging module (8000–14,000 nm, HTPA, \nHeimann, Pixel resolution: 80 × 64,\
    \ Horizontal and vertical FOV: 120° × 90°), an RGB \nimaging module (400–700 nm,\
    \ Raspberry Pi V2, Sony IMX219, Raspberry Pi foundation, \nPixel resolution: 3280\
    \ × 2464, HFOV: 62.2°, VFOV: 48.8°), a GPS receiver module (NEO \n6M V2, Adafruit)\
    \ for image geotagging, a capacitive touchscreen (LCD 800 × 400 mm, \nRobokit),\
    \ a keypad (Robokits), and a power source (20,000 mAh, 5V/2A, MI power bank).\
    \ \nThe computer used the NOOBS operating system with module-pertinent libraries\
    \ for \ndifferent operations. Imagery data were collected at critical crop growth\
    \ stages in the \n2019 and 2020 growing seasons (five times in each season). Ground\
    \ truth plant biophys-\nical and soil parameters were also measured synchronously.\
    \ \n2.2.1. Imagery Data \nThe developed imaging system was placed 1 m from the\
    \ crop and titled at 45° from \nthe horizontal. A total of 3200 images (400 per\
    \ treatment) were acquired (1600 RGB and \n1600 thermal) in two seasons at Crown\
    \ root initiation (20 days after sowing (DAS)), till-\nering (35 DAS) (Figure\
    \ 2), jointing (70 DAS), flowering and milking (95 DAS), and dough \n(108 DAS)\
    \ stages, between 11 am to 1 pm on clear sky days. Sample masked thermal and \n\
    RGB canopy images for model training are shown in Figure 2.  \nFigure 1. Experimental\
    \ layout of the winter wheat crop irrigated at different rates using sprinkler\n\
    and ﬂood irrigation systems [32]. R—Replicates. Layout is prepared over google\
    \ map.\n2.2. Data Collection\nRGB and thermal imagery were synchronously captured\
    \ using a multifunctional cus-\ntom integrated thermal-RGB imaging system. The\
    \ system has a single board computer (B+,\nRaspberry Pi foundation), a thermal\
    \ imaging module (8000–14,000 nm, HTPA, Heimann,\nPixel resolution: 80 × 64, Horizontal\
    \ and vertical FOV: 120◦ × 90◦), an RGB imaging mod-\nule (400–700 nm, Raspberry\
    \ Pi V2, Sony IMX219, Raspberry Pi foundation, Pixel resolution:\n3280 × 2464,\
    \ HFOV: 62.2◦, VFOV: 48.8◦), a GPS receiver module (NEO 6M V2, Adafruit)\nfor\
    \ image geotagging, a capacitive touchscreen (LCD 800 × 400 mm, Robokit), a keypad\n\
    (Robokits), and a power source (20,000 mAh, 5V/2A, MI power bank). The computer\n\
    used the NOOBS operating system with module-pertinent libraries for different\
    \ operations.\nImagery data were collected at critical crop growth stages in the\
    \ 2019 and 2020 growing\nseasons (ﬁve times in each season). Ground truth plant\
    \ biophysical and soil parameters\nwere also measured synchronously.\n2.2.1. Imagery\
    \ Data\nThe developed imaging system was placed 1 m from the crop and titled at\
    \ 45◦ from\nthe horizontal. A total of 3200 images (400 per treatment) were acquired\
    \ (1600 RGB\nand 1600 thermal) in two seasons at Crown root initiation (20 days\
    \ after sowing (DAS)),\ntillering (35 DAS) (Figure 2), jointing (70 DAS), ﬂowering\
    \ and milking (95 DAS), and dough\n(108 DAS) stages, between 11 am to 1 pm on\
    \ clear sky days. Sample masked thermal and\nRGB canopy images for model training\
    \ are shown in Figure 2.\n2.2.2. Weather and Ground Truth Data\nWeather data were\
    \ acquired for the imaging days from a standard station (Indian\nMeteorological\
    \ Department, Pune, India) installed at 300 m from the study site. The\nparameters\
    \ included, pan evaporation (mm/day), rainfall (mm), maximum and minimum\nair\
    \ temperature (◦C), relative humidity (RH, %), and wind velocity (m/s). The ambient\n\
    and soil ground truth data of air temperature (Ta), RH, and soil moisture content\
    \ (SMC)\nwere collected for each treatment plot during the imaging campaigns each\
    \ year. The Ta\nand RH parameters were recorded using the DHT22 module (Adafruit,\
    \ New York, NY,\nPlants 2022, 11, 3344\n5 of 21\nUSA). SMC was monitored in the\
    \ root zone depth (0–150 mm typical to wheat crops\ngrown in the experimental\
    \ site, soil type: vertisols) using a soil moisture meter of 200 mm\nsensing probe\
    \ length (ICT, MPM-160-B, Armidale, Australia). The probe was inserted at\nﬁve\
    \ different locations in each replication for measurement of soil moisture, acquiring\
    \ 15\ndata points of soil moisture content per measurement. The relative water\
    \ content (RWC)\nof leaves was calculated as the crop ground truth data [33].\
    \ For this, 10 matured and fully\nexpanded leaves from each sample plot were collected\
    \ and fresh weight was recorded on\neach sampling date, immediately following\
    \ the imagery acquisition. Collected samples\nwere then oven-dried at 70 ◦C, dry\
    \ weight was recorded, and RWC was calculated. A\ntotal of 30 samples were collected\
    \ per treatment per campaign amounting to a total of\n150 samples per treatment\
    \ in each year for RWC calculations. End-season yield was also\nrecorded from\
    \ 2 × 2 m areas from three plots in each replication, making nine sample\npoints\
    \ (36 m2 area) per treatment to characterize the effects of crop water stress.\n\
    Plants 2022, 11, x FOR PEER REVIEW \n5 of 22 \n \n \nFigure 2. Sample raw and\
    \ canopy masked RGB images ((a) non-stressed; (b) stressed) and thermal \nimages\
    \ ((c) non-stressed, (d) stressed) captured 35 days after sowing. Pseudo-color\
    \ thermal images \nhere are only for presentation and were scaled between 10 °C\
    \ (RGB: [25, 25, 113]) and 80 °C (RGB: \n[235, 246, 255]). \n2.2.2. Weather and\
    \ Ground Truth Data \nWeather data were acquired for the imaging days from a standard\
    \ station (Indian \nMeteorological Department, Pune, India) installed at 300 m\
    \ from the study site. The pa-\nrameters included, pan evaporation (mm/day), rainfall\
    \ (mm), maximum and minimum \nair temperature (°C), relative humidity (RH, %),\
    \ and wind velocity (m/s). The ambient \nand soil ground truth data of air temperature\
    \ (Ta), RH, and soil moisture content (SMC) \nwere collected for each treatment\
    \ plot during the imaging campaigns each year. The Ta \nand RH parameters were\
    \ recorded using the DHT22 module (Adafruit, New York, NY, \nUSA). SMC was monitored\
    \ in the root zone depth (0–150 mm typical to wheat crops \ngrown in the experimental\
    \ site, soil type: vertisols) using a soil moisture meter of 200 mm \nsensing\
    \ probe length (ICT, MPM-160-B, Armidale, Australia). The probe was inserted at\
    \ \nfive different locations in each replication for measurement of soil moisture,\
    \ acquiring 15 \ndata points of soil moisture content per measurement. The relative\
    \ water content (RWC) \nof leaves was calculated as the crop ground truth data\
    \ [33]. For this, 10 matured and fully \nexpanded leaves from each sample plot\
    \ were collected and fresh weight was recorded on \neach sampling date, immediately\
    \ following the imagery acquisition. Collected samples \nwere then oven-dried\
    \ at 70 °C, dry weight was recorded, and RWC was calculated. A \ntotal of 30 samples\
    \ were collected per treatment per campaign amounting to a total of 150 \nsamples\
    \ per treatment in each year for RWC calculations. End-season yield was also \n\
    recorded from 2 × 2 m areas from three plots in each replication, making nine\
    \ sample \npoints (36 m2 area) per treatment to characterize the effects of crop\
    \ water stress. \nFigure 2. Sample raw and canopy masked RGB images ((a) non-stressed;\
    \ (b) stressed) and thermal\nimages ((c) non-stressed, (d) stressed) captured\
    \ 35 days after sowing. Pseudo-color thermal images\nhere are only for presentation\
    \ and were scaled between 10 ◦C (RGB: [25, 25, 113]) and 80 ◦C (RGB:\n[235, 246,\
    \ 255]).\n2.2.3. Statistical Analysis\nThe impact of irrigation type (ﬂood and\
    \ sprinkler), rate (100, 75, 50, and 25% ETc),\nand interaction of both on crop\
    \ biophysical parameters were statistically evaluated using a\none-way analysis\
    \ of variance at a 5% level of signiﬁcance [34].\n2.3. Crop Water Stress Classiﬁcation\n\
    Two different approaches (1) feature extraction-based (DL models: AlexNet, GoogLeNet,\n\
    Inception V3, MobileNet V2, and ResNet50) and (2) function approximation-based\
    \ ML\nmodels (Artiﬁcial neural network (ANN), K-nearest neighbors (KNN), Support\
    \ vector\nmachine (SVM), and Logistic regression (LR)); and a DL model (DL-LSTM)\
    \ were adopted\nfor crop water stress classiﬁcation. Feature extraction-based\
    \ models were trained on thermal\nas well as RGB imagery. Function approximation-based\
    \ models were trained on ambient\nweather and soil parameters, and Tc inputs from\
    \ thermal imagery.\nDeep CNNs typically have complex architecture and some may\
    \ require signiﬁcant\ncomputational resources. All CNN model training and validation\
    \ processes were performed\non a desktop computer (Intel Core I7 Processor with\
    \ base frequency 2.60 GHz, 16 GB RAM,\n6 GB NVIDIA GeForce GTX 1660 Ti GPU) with\
    \ Windows 10 operating system (64 bits).\nPlants 2022, 11, 3344\n6 of 21\nCNN\
    \ models were developed in MATLAB 2019b using the deep learning and machine\n\
    learning toolbox. All the models are detailed in the following sub-sections.\n\
    2.3.1. Feature Extraction-Based Approaches\nFive DL models were selected as the\
    \ feature extraction-based approaches (1) AlexNet;\n(2) GoogLeNet; (3) Inception\
    \ V3; (4) MobileNet V2; and (5) ResNet50. These models were se-\nlected for their\
    \ extraordinary capabilities of automated feature extraction, easy and efﬁcient\n\
    training of the raw images with optimum computation resources, and their transferability\n\
    to edge computation devices [10,17]. The selected models ranged from the simplest\
    \ architec-\nture (AlexNet and MobileNet V2) to the most complex architecture\
    \ (GoogLeNet, Inception\nV3, and ResNet50) in order to evaluate their robustness\
    \ and efﬁciencies for crop water stress\nprediction. Successful application of\
    \ these models has been reported with accuracies up to\n100% for crop abiotic\
    \ and biotic stress classiﬁcation in recent studies [35–37]. Standardized\narchitectures\
    \ were used in the models for performance comparisons (Table 1).\nTable 1. Architecture\
    \ parameters in the feature extraction-based models for crop water stress classification.\n\
    Architecture Parameters\nAlexNet\nGoogLeNet\nInception V3\nMobileNet V2\nResNet50\n\
    Input image size\n227 × 227 × 3\n224 × 224 × 3\n299 × 299 × 3\n224 × 224 × 3\n\
    224 × 224 × 3\nNo. of layers\n25\n141\n316\n154\n177\nRelu layer\n7\n57\n95\n\
    35\n49\nMax Pooling layer\n3\n13\n4\n-\n01\nConvolutional layers\n5\n57\n94\n\
    35\n53\nDropout layer\n2\n1\n-\n-\n-\nFully connected\n3\n1\n1\n1\n1\nFully connected\
    \ layer Function\nFC8\nLoss3 classiﬁer\nPredictions\nLogits\nFC1000\nDepth\n8\n\
    22\n48\n53\n50\nParameters\n61 × 106\n7 × 106\n23.9 × 106\n3.5 × 106\n25.6 × 106\n\
    The DL-based classification includes steps of pre-trained model selection, data\
    \ pre-\nprocessing using morphological operators, data splitting, setting the\
    \ training hyper-parameters,\nmodel training, model tuning, cross-validation,\
    \ evaluation, and model testing (Figure 3).\nDL models were developed in MATLAB\
    \ (version 2019a, Mathworks, Natick, Boston, MA,\nUSA) using libraries of AlexNet,\
    \ GoogLeNet, Inception V3, MobileNet V2, and ResNet50.\nThe convolutional kernels\
    \ in AlexNet were extracted using the cost function optimized by\na stochastic\
    \ gradient descent with momentum (Sgdm) algorithm. While GoogLeNet pro-\ncesses\
    \ and classiﬁes images by alternately factorizing the convolutions and regularization\n\
    layers. To train a GoogLeNet model, the model’s loss 3-classiﬁer, prob, and output\
    \ layers\nwere replaced by fully connected, softmax and output class layers which\
    \ connected with\nother traditional layers. The inception V3 extracted (a) local\
    \ features of the stressed crop by\nusing small convolutions and (b) high abstracted\
    \ features with large convolutions. The last\nthree prediction layers in inception\
    \ V3 were replaced by three new layers; fully connected,\nsoftmax, and classiﬁcation\
    \ output layer. These layers were interconnected with average\npooling and a fully\
    \ connected layer of the pre-trained DL. MobileNet V2 and ResNet50 are\nthe very\
    \ recently proposed DL models for classiﬁcation problems. MobileNet V2 requires\n\
    less computational power compared to conventional CNN. ResNet50 is a deep residual\n\
    network that uses the shortcut connections by reducing the convolutional layers\
    \ and by\nalso solving the vanishing gradient issue typical to CNN. The residual\
    \ modules in ResNet50\nwere used to connect different layers of CNN to improve\
    \ the model performance [38].\nGeneralization can be poor for feature extraction-based\
    \ models when the number of\nepochs and batch sizes are more than the optimum\
    \ [39]. This is because the model can\noverlearn when trained on a speciﬁc dataset\
    \ at large epochs and batch sizes, and may lose\nits performance and generalization\
    \ capability when trained on new datasets. Conversely,\nthe smaller epochs and\
    \ bath sizes may lead to insufﬁcient learning and underﬁtting of the\nmodel and\
    \ hence may not perform as expected with the new datasets [40]. Therefore, to\n\
    Plants 2022, 11, 3344\n7 of 21\nmaximize the model performance and minimize their\
    \ overﬁtting, optimum hyperparameter\ntuning is required. In this study, all the\
    \ selected feature extraction-based models were\nextensively tuned with learning\
    \ rates, solvers, epochs, and batch sizes as detailed in Table 2.\nPlants 2022,\
    \ 11, x FOR PEER REVIEW \n7 of 22 \n \n \nThese layers were interconnected with\
    \ average pooling and a fully connected layer of the \npre-trained DL. MobileNet\
    \ V2 and ResNet50 are the very recently proposed DL models \nfor classification\
    \ problems. MobileNet V2 requires less computational power compared \nto conventional\
    \ CNN. ResNet50 is a deep residual network that uses the shortcut con-\nnections\
    \ by reducing the convolutional layers and by also solving the vanishing gradient\
    \ \nissue typical to CNN. The residual modules in ResNet50 were used to connect\
    \ different \nlayers of CNN to improve the model performance [38].  \n \nFigure\
    \ 3. Data processing pipeline for stress prediction using selected deep learning\
    \ and machine \nlearning models. \nGeneralization can be poor for feature extraction-based\
    \ models when the number of \nepochs and batch sizes are more than the optimum\
    \ [39]. This is because the model can \noverlearn when trained on a specific dataset\
    \ at large epochs and batch sizes, and may \nlose its performance and generalization\
    \ capability when trained on new datasets. Con-\nversely, the smaller epochs and\
    \ bath sizes may lead to insufficient learning and under-\nfitting of the model\
    \ and hence may not perform as expected with the new datasets [40]. \nTherefore,\
    \ to maximize the model performance and minimize their overfitting, optimum \n\
    hyperparameter tuning is required. In this study, all the selected feature extraction-based\
    \ \nmodels were extensively tuned with learning rates, solvers, epochs, and batch\
    \ sizes as \ndetailed in Table 2. \nTable 2. Hyperparameter tuning considerations\
    \ to reduce overfitting and performance enhance-\nment of the feature extraction-based\
    \ models. \nFigure 3. Data processing pipeline for stress prediction using selected\
    \ deep learning and machine\nlearning models.\nCollected thermal and RGB images\
    \ (1600 each) were labeled into stressed and non-\nstressed classes by the domain\
    \ experts based on the values of crop water stress indicators of\nSMC, RWC, and\
    \ Tc (Table 3). After this, 80% of the labeled dataset (separately for thermal\n\
    and RGB images) was used for DL model training based on features of object dimensions,\n\
    pixel intensity, pixel values (Tc), edges, etc. The remaining 20% of the labeled\
    \ dataset was\nused for model validations and testing.\nTable 2. Hyperparameter\
    \ tuning considerations to reduce overﬁtting and performance enhancement\nof the\
    \ feature extraction-based models.\nParameters\nValue\nEpoch\n5, 10, and 20\n\
    Batchsize\n5, 10, 15, and 20\nIterations\n250 and 300\nSolver\nSgdm and Adam\n\
    Learning rate\n1 × 10−4, 2 × 10−4, and 3 × 10−4\nSgdm: stochastic gradient descent\
    \ with momentum; Adam: adaptive moment estimation.\nPlants 2022, 11, 3344\n8 of\
    \ 21\nTable 3. Crop and auxiliary data ranges for stressed and non-stressed labeling.\n\
    Crop Label\nParameter\nOutput\nReferences\nStressed\nCanopy temperature (Tc):\
    \ >23 ◦C &\nRelative water content (RWC): <90% &\nSoil moisture content (SMC):\
    \ <25%\n0\n[41–46]\nNon-Stressed\nneither of the “stressed” conditions\n1\n2.3.2.\
    \ Function Approximation-Based Approaches\nFour ML models; ANN, KNN, LR, and SVM\
    \ and a DL-based LSTM (DL-LSTM) were\nselected as the function approximation approaches\
    \ for crop water stress classiﬁcation. The\nML models were selected as those provide\
    \ an opportunity to analyze numerous features\nsimultaneously unlike traditional\
    \ methods. ANN is effective in learning complex nonlinear\nfunctions and segmenting\
    \ data based on the learned weights. The input layer had four\nvariables to extract\
    \ features from 1600 samples while the output layer had one neuron to\ncalculate\
    \ the probability of each class [47]. KNN classiﬁes a data point based on its\
    \ distance\nfrom the maximum number of training data points in the neighborhood.\
    \ Typically, KNN\nuses Euclidean, Minkowski, Manhattan, or Hamming distances out\
    \ of which Minkowski\ndistance has been reported to be more reliable [48] and\
    \ was therefore selected in the model.\nLR classiﬁes data points into discrete\
    \ classes based on probability using a sigmoid or logistic\nfunction [49]. SVM\
    \ shifts data points to a higher dimension using linear, non-linear, and\nradial\
    \ kernels to achieve linear separability [50] and then identiﬁes a hyperplane\
    \ for the\nhighest possible distance between data points of the two classes. DL-LSTM\
    \ uses a chain of\nrepeated modules comprising memory cells with a backpropagation\
    \ algorithm to solve the\nclassiﬁcation problems. This model solves premature\
    \ overﬁtting and vanishing gradient\nissues by using the previously stored information\
    \ in the memory cell. The information\nis then used to generate the features during\
    \ the training process to predict the output\nclass [51]. ML models automatically\
    \ tuned their hyperparameter values by using Bayesian\noptimization. The optimization\
    \ minimizes the model loss based on the hyperparameter\ncombination and yields\
    \ the best possible set of parameters. Further, the models were\ntrained and validated\
    \ on these tuned hyperparameters. All function-approximation models\nwere deployed\
    \ on crop environment (Ta, RH, and SMC) and temperature (Tc, from thermal\nimages)\
    \ inputs for classiﬁcation into stressed and non-stressed through binary outputs\
    \ (0\nor 1, Table 3). The models (operating parameters in Table 4) were developed\
    \ in Python 3.7\nwith Keras and TensorFlow libraries.\nTable 4. Training parameters\
    \ of function approximation-based classiﬁcation models.\nFunction Approximation\
    \ Model\nParameters\nArtiﬁcial Neural Network (ANN)\nHidden layers: 2\nNeurons:\
    \ 64, 32\nLearning rate (alpha): 0.01\nActivation functions: sigmoid\nBatch size:\
    \ 8\nNumber of epochs: 300\nOptimizer: Adam\nLoss function: binary cross entropy\n\
    Kernel Nearest Neighbour (KNN)\nNumber of Neighbors (K): 8\nDistance Metric: minkowski\n\
    Weights: uniform\nAlgorithm: ball-tree\nLogistic Regression (LR)\nPenalty parameter:\
    \ L1\nInverse of regularization parameter (C): 5\nMaximum iteration: 100\nTolerance:\
    \ 0.0001\nPlants 2022, 11, 3344\n9 of 21\nTable 4. Cont.\nFunction Approximation\
    \ Model\nParameters\nSupport Vector Machine (SVM)\nKernel Type (Kernel): RBF (Radial\
    \ basis Function)\nPenalty parameter (C): 100\nbandwidth parameter (gamma): 0.001\n\
    Degree of the polynomial kernel: 3\nDeep Learning-Long Short Term Memory (DL-LSTM)\n\
    Number of neurons: 180\nEpochs: 200\nBatch size: 10\nOptimizer: Adam\nNumber of\
    \ hidden layers: 2\nLoss activation function: MAE (Mean absolute error)\nAdam:\
    \ adaptive moment estimation.\n2.4. Model Performance Evaluation\nThe performance\
    \ of both feature extraction and function approximation-based models\nwas evaluated\
    \ through accuracy (A), sensitivity (Se), speciﬁcity (Sp), precision (P), and\
    \ F1\nscore parameters (Equations (1)–(5)). Accuracy is the correct prediction\
    \ rate of non-stressed\nand stressed crops, precision is the fraction of true\
    \ positive (TS) or correctly predicted\nstressed crop from an overall prediction\
    \ of the stressed crop (PS), speciﬁcity is the true\nnegative (TN) or correctly\
    \ predicted non-stressed crops from the actual non-stressed crops\n(AN). Sensitivity\
    \ represents a fraction of the correctly predicted stressed crops (TS) from the\n\
    actual stressed crops (AS) and the F1 score is the harmonic mean of precision\
    \ and sensitivity.\nThe F1 score evaluates the accuracy of a binary classiﬁcation\
    \ problem as in this study, which\naims to classify the crops into two classes\
    \ (stressed and non-stressed). Often, the accuracy\nestimate is affected by true\
    \ negatives and therefore F1 score is highly used over accuracy to\nseek a balance\
    \ between the precision and recall (sensitivity) parameters and when there is\n\
    an uneven class distribution (a large number of actual negatives).\nA = TS + TN\n\
    TT\n(1)\nSe = TS\nAS\n(2)\nSp = TN\nAN\n(3)\nP = TS\nPS\n(4)\nF1 =\n2 ∗ TS\nAS\
    \ + PS\n(5)\nwhere TT is the total number of predictions. Stress/non-stress misclassiﬁcation\
    \ was rep-\nresented by type1 (TE1) (false positive) and type2 errors (TE2) (false\
    \ negative). TE1 is the\nnumber of actual stressed crops misclassiﬁed as non-stressed\
    \ (row 1-column 2 of the confu-\nsion matrix) while TE2 is the number of actual\
    \ non-stressed crops misclassiﬁed as stressed\n(row 2-column 1 of the confusion\
    \ matrix).\n3. Results\n3.1. Plant Water Stress Indicators\nThe thermal imagery\
    \ derived canopy temperatures (Tc (◦C)) under sprinkler irrigation\nat 100, 75,\
    \ 50 and 25% of ETc irrigation levels were 22.1 (2.0) (Mean, standard deviation\n\
    (SD)), 25.6 (1.6), 26.4 (2.2), and 27.9 ◦C (3.0 ◦C), respectively (Figure 4).\
    \ While Tc for ﬂood\nirrigation at the above irrigation levels were 23.2 (2.0),\
    \ 25.9 (1.5), 26.8 (2.4), and 28.1 ◦C\n(3.1 ◦C), respectively. Similarly, mean\
    \ RWC (%) at selected sprinkler irrigation rates were\nPlants 2022, 11, 3344\n\
    10 of 21\n90.4 (2.7), 87.7 (4.2), 75.8 (9.4), and 74.2% (8.2%) while at corresponding\
    \ irrigation levels in\nﬂood irrigation were 89.8 (2.7), 87.2 (4.3), 75.0 (9.4)\
    \ and 73.9% (8.3%), respectively. The mean\nSMCs (%) for respective sprinkler\
    \ irrigation were 26.6 (2.3), 26.2 (2.7), 22.5 (3.3), and 21.1%\n(3.0%) while\
    \ those for respective ﬂood irrigation were 24.9 (2.0), 24.4 (2.5), 21.4 (3.0),\
    \ and\n20.4% (3.1%). When analyzed statistically, Tc, RWC, and SMC were signiﬁcantly\
    \ affected\nby the irrigation method (ﬂood and sprinkler), irrigation rate (100,\
    \ 75, 50, and 25% ETc), as\nwell as their interaction (One-way ANOVA, p < 0.001).\
    \ The RWC and SMC decreased with\nthe decrease in irrigation level, while the\
    \ Tc increased. Based on the categories detailed in\nTable 3, the mean Tc for\
    \ the stressed crop was 26.6 ◦C (±2.6), and that for the non-stressed\ncrop was\
    \ 21.2 ◦C (±1.4). The mean RWC for the non-stressed crop was 92.2% (±1.5) and\n\
    for the stressed crop was 78.9% (±9.2) while the mean SMC for the non-stressed\
    \ crop was\n27.1% (1.6) and for the stressed crop was 21.2% (±2.4).\n3.2. Water\
    \ Stress Prediction\n3.2.1. Feature Extraction-Based Approaches\nThe performances\
    \ of AlexNet, GoogLeNet, Inception V3, MobileNet V2, and ResNet50\nmodels for\
    \ RGB and thermal imagery were tested for different combinations of epochs\nand\
    \ batch sizes (Table 5). The model training accuracies increased with the increase\
    \ in\nthe number of epochs from 5 to 10 and over-ﬁtting was observed for all the\
    \ models when\nepochs increased to 20. Over different epochs, accuracy increased\
    \ with the increase in\nbatch size from 5 to 20. For the batch size of 20 and\
    \ 250 iterations, overﬁtting was observed\nin Inception and ResNet50 with RGB\
    \ imagery inputs and in AlexNet, GoogLeNet, and\nResNet50 with thermal imagery\
    \ inputs (Table 5). Extensive hyperparameter tuning was\nperformed with parameters\
    \ listed in Table 2 to minimize overﬁtting and maximize the\nmodel accuracies.\
    \ Post-tuning, the maximum training accuracies of 94.6%, 96.7%, and 95.6%\nwere\
    \ observed for AlexNet, GoogLeNet, and MobileNet V2, respectively with RGB imagery\n\
    inputs at 10 epochs and batch size of 20 (Figure 5). While the Inception V3 and\
    \ ResNet50\nfor RGB imagery inputs converged at 10 epochs, batch size of 15, and\
    \ 300 iterations with\nrespective accuracies of 92.7% and 97.1% (Figure 5c,e).\
    \ For the thermal imagery inputs, the\noptimum hyperparameters were 10 epochs\
    \ and a batch size of 15, which yielded maximum\naccuracies of 96.4%, 97.2%, and\
    \ 98.5% for AlexNet, GoogLeNet, and ResNet50, respectively.\nFurthermore, 10 epochs\
    \ and a batch size of 20 were found optimum for Inception V3\nand MobileNet V2\
    \ models, and pertinent maximum accuracies were 98.0% and 95.3%,\nrespectively\
    \ (Figure 6). During hyperparameter tuning, the model overﬁtting reduced\nsigniﬁcantly\
    \ at 10 epochs without sacriﬁcing accuracy. The training accuracies fell below\n\
    50% for learning rates of 1 × 10−4 and 4 × 10−4 and went over 50% for the learning\
    \ rate of\n3 × 10−4. Moreover, the model overﬁtting was reduced when the solver\
    \ was shifted from\nSgdm to Adam. All the models converged with training accuracies\
    \ > 90% at the learning\nrate of 3 × 10−4 and Adam as the solver (Figures 5 and\
    \ 6).\nTable 5. Training accuracies of feature extraction-based models to characterize\
    \ wheat water stress\nusing RGB and thermal imagery inputs under different epoch\
    \ and batch size combinations.\nAccuracy (%)\nEpochs\nBatch Size\nAlexNet\nGoogLeNet\n\
    Inception V3\nMobileNet V2\nResNet50\nFeature Extraction-Based Approaches with\
    \ RGB Imagery Inputs\n5\n5\n90.4\n95.2\n91.9\n95.1\n96.3\n5\n10\n89.4\n94.3\n\
    90.5\n93.0\n92.7\n5\n15\n92.3\n94.6\n90.4\n92.3\n93.5\n5\n20\n92.6\n95.0\n90.8\n\
    92.7\n94.6\n10\n5\n93.8\n95.5\n92.2\n93.1\n95.8\n10\n10\n92.7\n95.7\n92.4\n94.2\n\
    95.1\n10\n15\n93.4\n95.9\n92.7\n94.4\n97.1\n10\n20\n94.6\n96.7\n93.6\n95.6\n97.2\n\
    20\n5\n95.3\n97.2\n93.8\n94.4\n92.3\nPlants 2022, 11, 3344\n11 of 21\nTable 5.\
    \ Cont.\nAccuracy (%)\nEpochs\nBatch Size\nAlexNet\nGoogLeNet\nInception V3\n\
    MobileNet V2\nResNet50\nFeature Extraction-Based Approaches with RGB Imagery Inputs\n\
    20\n10\n95.6\n97.5\n94.2\n95.5\n97.2\n20\n15\n96.6 *\n98.0\n94.5\n96.7 *\n97.9\
    \ *\n20\n20\n96.2\n98.2 *\n95.0 *\n96.1\n95.8\nFeature extraction-based approaches\
    \ with thermal imagery inputs\n5\n5\n94.4\n96.2\n97.0\n94.8\n95.9\n5\n10\n95.9\n\
    95.8\n96.8\n94.7\n95.9\n5\n15\n96.4\n95.4\n95.9\n93.1\n98.4\n5\n20\n92.7\n96.0\n\
    96.2\n92.7\n97.6\n10\n5\n94.5\n96.5\n97.2\n93.5\n96.7\n10\n10\n96.0\n96.7\n97.4\n\
    94.2\n97.3\n10\n15\n96.4\n97.2\n97.5\n94.7\n98.5\n10\n20\n96.5\n97.2\n98.0\n95.3\n\
    98.7\n20\n5\n97.2\n97.6\n98.2\n97.2\n99.0\n20\n10\n97.4\n98.1\n98.5\n97.5\n99.2\n\
    20\n15\n98.2 *\n98.5 *\n98.7 *\n98.1 *\n99.5 *\n20\n20\n98.0\n98.0\n98.5\n97.9\n\
    99.0\n* Highest accuracy for the epoch and batch size combinations.\nPlants 2022,\
    \ 11, x FOR PEER REVIEW \n11 of 22 \n \n \nFigure 4. Variations in (a) canopy\
    \ temperature; (b) soil moisture content; (c) relative water content; \nand (d)\
    \ grain yield from wheat plots irrigated at different rates. S and F represent\
    \ sprinkler and \nflood irrigations, respectively and the numbers followed by\
    \ these letters denote irrigation rates \nlevels as % of full crop evapotranspiration\
    \ (ETc). \n3.2. Water Stress Prediction \n3.2.1. Feature Extraction-Based Approaches\
    \ \nThe performances of AlexNet, GoogLeNet, Inception V3, MobileNet V2, and Res-\n\
    Net50 models for RGB and thermal imagery were tested for different combinations\
    \ of \nepochs and batch sizes (Table 5) The model training accuracies increased\
    \ with the in\nFigure 4. Variations in (a) canopy temperature; (b) soil moisture\
    \ content; (c) relative water content;\nand (d) grain yield from wheat plots irrigated\
    \ at different rates. S and F represent sprinkler and ﬂood\nirrigations, respectively\
    \ and the numbers followed by these letters denote irrigation rates levels as\
    \ %\nof full crop evapotranspiration (ETc).\nPlants 2022, 11, 3344\n12 of 21\n\
    \ \n \nhigher for the models with thermal imagery inputs compared to those with\
    \ RGB imagery \ninputs. The individual accuracy and errors for all the feature\
    \ extraction-based models \nwith validation datasets are shown in Figure 7. The\
    \ mean errors were higher for the RGB \nimagery compared to the thermal imagery\
    \ irrespective of the selected models.  \n \nFigure 5. Accuracy and loss curves\
    \ for (a) AlexNet; (b) GoogLeNet; (c) Inception V3; (d) MobileNet \nV2; and (e)\
    \ ResNet50 models with RGB imagery inputs for crop water stress identification.\
    \ \nFigure 5. Accuracy and loss curves for (a) AlexNet; (b) GoogLeNet; (c) Inception\
    \ V3; (d) MobileNet\nV2; and (e) ResNet50 models with RGB imagery inputs for crop\
    \ water stress identiﬁcation.\nThe training time elapsed for AlexNet, GoogLeNet,\
    \ Inception V3, MobileNet V2, and\nResNet50 was 76, 92, 609, 149, and 217 min\
    \ with RGB imagery inputs, and 42, 88, 287,\n134, 168 min with thermal imagery\
    \ inputs, respectively. While the classiﬁcation of an\nindependent image using\
    \ trained models into stressed/non-stressed class consumed less\nthan 5 s. The\
    \ overall validation accuracies (combined for stressed and non-stressed classes)\n\
    for AlexNet, GoogLeNet, Inception V3, MobileNet V2, and ResNet50 models were 93.4%,\n\
    95.9%, 92.5%, 94.4%, and 96.9%, respectively with RGB imagery inputs (Figure 7).\
    \ The\nhighest precision (100%) and F1 score (96.6%) were observed for GoogLeNet\
    \ and ResNet50,\nrespectively while maximum sensitivity was achieved for MobileNet\
    \ V2 (Table 6). Pertinent\nto thermal imagery inputs, overall validation accuracies\
    \ (combined for stressed and non-\nstressed classes) with AlexNet, GoogLeNet,\
    \ Inception V3, MobileNet V2, and ResNet50\nmodels were 96.2%, 96.9%, 97.5%, 94.7%,\
    \ and 98.4%, respectively. Alike RGB imagery,\nResNet50 for thermal imagery had\
    \ the highest precision (96.7%), sensitivity (100%), and\nF1 score (98.3%) (Table\
    \ 6). Additionally, the accuracies were higher for the models with\nthermal imagery\
    \ inputs compared to those with RGB imagery inputs. The individual\naccuracy and\
    \ errors for all the feature extraction-based models with validation datasets\n\
    are shown in Figure 7. The mean errors were higher for the RGB imagery compared\
    \ to the\nthermal imagery irrespective of the selected models.\nPlants 2022, 11,\
    \ 3344\n13 of 21\nPlants 2022, 11, x FOR PEER REVIEW \n14 of 22 \n \n \n \nFigure\
    \ 6. Accuracy and loss curves for (a) AlexNet; (b) GoogLeNet; (c) Inception V3;\
    \ (d) MobileNet \nV2; and (e) ResNet50 models with thermal imagery inputs for\
    \ crop water stress identification. \nTable 6. Validation performance of feature\
    \ extraction and function approximation models to \ncharacterize wheat water stress.\
    \ \nModels \nAccuracy (%) \nPrecision (%) \nSensitivity (%) \nF1 Score (%) \n\
    Feature Extraction-Based Approaches with only RGB Imagery Inputs \nAlexNet \n\
    93.4 \n91.4 \n94.5 \n92.2 \nGoogLeNet \n95.9 \n100 \n91.1 \n95.3 \nInception V3\
    \ \n92.5 \n94.4 \n89.4 \n91.8 \nMobileNet V2 \n94.4 \n89.0 \n100.0 \n94.1 \nResNet50\
    \ \n96.9 \n95.9 \n97.3 \n96.6 \nFeature extraction-based approaches with only\
    \ thermal imagery inputs \nAlexNet \n96.2 \n95.9 \n95.9 \n95.9 \nGoogLeNet \n\
    96.9 \n96.6 \n96.6 \n96.6 \nInception V3 \n97.5 \n96.6 \n98.0 \n97.3 \nMobileNet\
    \ V2 \n94.7 \n94.0 \n94.7 \n94.3 \nResNet50 \n98.4 \n96.7 \n100.0 \n98.3 \nFunction\
    \ approximation-based approaches (with RWC, SMC, Tc, and RH inputs) \nANN \n93.5\
    \ \n92.7 \n92.7 \n93.0 \nKNN \n88.1 \n90.2 \n84.1 \n86.9 \nLR \n89.2 \n95.1 \n\
    82.9 \n88.6 \nSVM \n91.4 \n95.1 \n86.7 \n90.8 \nDL-LSTM \n96.7 \n96.0 \n97.9 \n\
    97.0 \nFigure 6. Accuracy and loss curves for (a) AlexNet; (b) GoogLeNet; (c)\
    \ Inception V3; (d) MobileNet\nV2; and (e) ResNet50 models with thermal imagery\
    \ inputs for crop water stress identiﬁcation.\nTable 6. Validation performance\
    \ of feature extraction and function approximation models to charac-\nterize wheat\
    \ water stress.\nModels\nAccuracy (%)\nPrecision (%)\nSensitivity (%)\nF1 Score\
    \ (%)\nFeature Extraction-Based Approaches with only RGB Imagery Inputs\nAlexNet\n\
    93.4\n91.4\n94.5\n92.2\nGoogLeNet\n95.9\n100\n91.1\n95.3\nInception V3\n92.5\n\
    94.4\n89.4\n91.8\nMobileNet V2\n94.4\n89.0\n100.0\n94.1\nResNet50\n96.9\n95.9\n\
    97.3\n96.6\nFeature extraction-based approaches with only thermal imagery inputs\n\
    AlexNet\n96.2\n95.9\n95.9\n95.9\nGoogLeNet\n96.9\n96.6\n96.6\n96.6\nInception\
    \ V3\n97.5\n96.6\n98.0\n97.3\nMobileNet V2\n94.7\n94.0\n94.7\n94.3\nResNet50\n\
    98.4\n96.7\n100.0\n98.3\nFunction approximation-based approaches (with RWC, SMC,\
    \ Tc, and RH inputs)\nANN\n93.5\n92.7\n92.7\n93.0\nKNN\n88.1\n90.2\n84.1\n86.9\n\
    LR\n89.2\n95.1\n82.9\n88.6\nSVM\n91.4\n95.1\n86.7\n90.8\nDL-LSTM\n96.7\n96.0\n\
    97.9\n97.0\nPlants 2022, 11, 3344\n14 of 21\nPlants 2022, 11, x FOR PEER REVIEW\
    \ \n15 of 22 \n \n \n \nFigure 7. Confusion matrices for AlexNet, GoogLeNet, Inception\
    \ V3, MobileNet V2, and ResNet50 \nmodels pertinent validation datasets of RGB\
    \ imagery (a–e) and thermal imagery (f–j). Cell values \n(%) in row 1 column 2\
    \ represent type 1 error (TE1) while those in row 2 column 1 represent type 2\
    \ \nerror (TE2) (details in Section 2.4). Numbers (% and actual counts) in green\
    \ color indicate prediction \naccuracy while those in red color are prediction\
    \ errors for stressed and non-stressed crop classes. \nNumbers in green box represent\
    \ correct prediction and those in red box represent misclassification \nof non-stressed/stressed\
    \ classes. \n3.2.2. Function Approximation-Based Approaches \nAmongst the function\
    \ approximation approaches, the highest prediction accuracy \nwas obtained with\
    \ the DL-LSTM model (96.7%) followed by ANN (93.5%), SVM (91.4%), \nLR (89.2%),\
    \ and KNN models (88.1%) (Table 6). Moreover, the precision, sensitivity, and\
    \ \nF1 score were also highest for the DL-LSTM (96.0, 97.9, and 97.0%, respectively)\
    \ com-\npared to other ML models. The training and validation accuracies with\
    \ DL-LSTM \nshowed early convergence for which the loss on the validation dataset\
    \ reached minima at \n40 epochs (Figure 8). The TE1 for ANN, KNN, LR, SVM, and\
    \ LSTM were 3.2, 4.3, 2.2, 2.2, \nand 2.1%, respectively and TE2 were 3.2, 7.5,\
    \ 8.6, 6.5, and 1.1%, respectively (Figure 9). The \nDL-LSTM outperformed ML models\
    \ with the lowest mean error (Figure 9). \n \nFigure 8. Accuracy and loss corves\
    \ for Long Short Term memory based deep learning model for \ncrop water stress\
    \ identification. \nFigure 7. Confusion matrices for AlexNet, GoogLeNet, Inception\
    \ V3, MobileNet V2, and ResNet50\nmodels pertinent validation datasets of RGB\
    \ imagery (a–e) and thermal imagery (f–j). Cell values (%)\nin row 1 column 2\
    \ represent type 1 error (TE1) while those in row 2 column 1 represent type 2\
    \ error\n(TE2) (details in Section 2.4). Numbers (% and actual counts) in green\
    \ color indicate prediction\naccuracy while those in red color are prediction\
    \ errors for stressed and non-stressed crop classes.\nNumbers in green box represent\
    \ correct prediction and those in red box represent misclassiﬁcation of\nnon-stressed/stressed\
    \ classes.\n3.2.2. Function Approximation-Based Approaches\nAmongst the function\
    \ approximation approaches, the highest prediction accuracy was\nobtained with\
    \ the DL-LSTM model (96.7%) followed by ANN (93.5%), SVM (91.4%), LR\n(89.2%),\
    \ and KNN models (88.1%) (Table 6). Moreover, the precision, sensitivity, and\
    \ F1\nscore were also highest for the DL-LSTM (96.0, 97.9, and 97.0%, respectively)\
    \ compared\nto other ML models. The training and validation accuracies with DL-LSTM\
    \ showed early\nconvergence for which the loss on the validation dataset reached\
    \ minima at 40 epochs\n(Figure 8). The TE1 for ANN, KNN, LR, SVM, and LSTM were\
    \ 3.2, 4.3, 2.2, 2.2, and 2.1%,\nrespectively and TE2 were 3.2, 7.5, 8.6, 6.5,\
    \ and 1.1%, respectively (Figure 9). The DL-LSTM\noutperformed ML models with\
    \ the lowest mean error (Figure 9).\nPlants 2022, 11, x FOR PEER REVIEW \n15 of\
    \ 22 \n \n \n \nFigure 7. Confusion matrices for AlexNet, GoogLeNet, Inception\
    \ V3, MobileNet V2, and ResNet50 \nmodels pertinent validation datasets of RGB\
    \ imagery (a–e) and thermal imagery (f–j). Cell values \n(%) in row 1 column 2\
    \ represent type 1 error (TE1) while those in row 2 column 1 represent type 2\
    \ \nerror (TE2) (details in Section 2.4). Numbers (% and actual counts) in green\
    \ color indicate prediction \naccuracy while those in red color are prediction\
    \ errors for stressed and non-stressed crop classes. \nNumbers in green box represent\
    \ correct prediction and those in red box represent misclassification \nof non-stressed/stressed\
    \ classes. \n3.2.2. Function Approximation-Based Approaches \nAmongst the function\
    \ approximation approaches, the highest prediction accuracy \nwas obtained with\
    \ the DL-LSTM model (96.7%) followed by ANN (93.5%), SVM (91.4%), \nLR (89.2%),\
    \ and KNN models (88.1%) (Table 6). Moreover, the precision, sensitivity, and\
    \ \nF1 score were also highest for the DL-LSTM (96.0, 97.9, and 97.0%, respectively)\
    \ com-\npared to other ML models. The training and validation accuracies with\
    \ DL-LSTM \nshowed early convergence for which the loss on the validation dataset\
    \ reached minima at \n40 epochs (Figure 8). The TE1 for ANN, KNN, LR, SVM, and\
    \ LSTM were 3.2, 4.3, 2.2, 2.2, \nand 2.1%, respectively and TE2 were 3.2, 7.5,\
    \ 8.6, 6.5, and 1.1%, respectively (Figure 9). The \nDL-LSTM outperformed ML models\
    \ with the lowest mean error (Figure 9). \n \nFigure 8. Accuracy and loss corves\
    \ for Long Short Term memory based deep learning model for \ncrop water stress\
    \ identification. \nFigure 8. Accuracy and loss corves for Long Short Term memory\
    \ based deep learning model for crop\nwater stress identiﬁcation.\nPlants 2022,\
    \ 11, 3344\n15 of 21\nPlants 2022, 11, x FOR PEER REVIEW \n16 of 22 \n \n \n \n\
    Figure 9. The confusion matrices for function approximation-based (a) ANN; (b)\
    \ KNN; (c) LR; (d) \nSVM; and (e) DL-LSTM models. Cell values (%) in row 1 column\
    \ 2 represent type 1 error (TE1) while \nthose in row 2 column 1 represent type\
    \ 2 error (TE2) (details in Section 2.4). Numbers (% and actual \ncounts) in green\
    \ color indicate prediction accuracy while those in red color are prediction errors\
    \ for \nstressed and non-stressed crop classes. Numbers in green box represent\
    \ correct prediction and \nthose in red box represent misclassification of non-stressed/stressed\
    \ classes. \n4. Discussion \nSprinkler irrigation applies a predetermined quantity\
    \ of water and wets the entire \ncanopy, unlike traditional flood irrigation.\
    \ This cools down the microclimate and in-\ncreases relative air humidity to reduce\
    \ the microclimate’s water demand [52]. This could \nbe the reason for lower Tc\
    \ in all the sprinkler irrigation treatments compared to the cor-\nresponding\
    \ flood irrigation treatments (Figure 4). Lowered microclimate water demand \n\
    could have also resulted in lower soil moisture depletion from the root zone and\
    \ there-\nfore higher SMC with sprinkler irrigation [53]. In addition to sufficient\
    \ SMC, sprinkler \nirrigation results in lower deep percolation and nutrient leaching\
    \ compared to conven-\ntional flood irrigation [54–56]. This could have resulted\
    \ in a higher average yield for \nsprinkler irrigation treatment plots (5719 kg/ha)\
    \ compared to the flood irrigation treat-\nment plots (4898 kg/ha). With the projected\
    \ future climate change impacts in the form of \nlow rainfall frequencies and\
    \ high ambient temperatures, crop water stresses are further \nexpected to multiply,\
    \ which will multiply the penalties in yield potentials [3]. Therefore, \nstress-tolerant\
    \ crop cultivars need to be developed and planted for uncompromised yield \ngoals.\
    \ As also reported in our prior work based on canopy reflectance [57], water stress\
    \ \nstarted to occur before the CRI stage in both methods of irrigation. RWCs\
    \ were lower at \nlate jointing and flowering stages in case of flood irrigation.\
    \ Water stress at the flowering \nstage can result in significant yield and biomass\
    \ reductions [58] suggesting that it is also \ninfluenced by the phenological\
    \ growth stage. For robust analysis of this aspect, large \ndatasets are being\
    \ collected at each phenological growth stage. Water stress lowers CO2 \navailability\
    \ due to stomatal closure, thereby affecting photosynthesis and ultimately \n\
    growth, yield, and biomass [59,60]. \nCNNs have been increasingly used for plant\
    \ phenotyping applications over the past \ndecade for their capability of modeling\
    \ complicated plant processes by distinguishing \nand extracting regularized data\
    \ patterns [61,62]. It is for this reason; CNN models were \nhighly accurate in\
    \ predicting stressed and non-stressed crops using thermal and RGB \nimagery.\
    \ Chlorophyll is vital for photosynthesis, while carotenoids are critical \nnon-enzymatic\
    \ antioxidants. Water stress reduces chlorophyll and carotenoid contents, \nas\
    \ well as the ratio of chlorophyll ‘a’ to ‘b’, leading to leaf coloration changes.\
    \ This is the \nreason for RGB images also yielding satisfactory accuracy of up\
    \ to 94.6% for tracing leaf \ncolor changes [63]. Compared to RGB imagery, thermal\
    \ imagery is a more detailed and \nbetter presenter of the crop stress that alters\
    \ the emissivity patterns proportionally \n[64,65]. The canopy temperature is\
    \ affected by the microclimate conditions and the \navailable soil moisture [53].\
    \ This is the reason for the relatively lower accuracy of water \nstress detection\
    \ with RGB images (94.6%) than with thermal images (96.7%) irrespective \nFigure\
    \ 9. The confusion matrices for function approximation-based (a) ANN; (b) KNN;\
    \ (c) LR;\n(d) SVM; and (e) DL-LSTM models. Cell values (%) in row 1 column 2\
    \ represent type 1 error (TE1)\nwhile those in row 2 column 1 represent type 2\
    \ error (TE2) (details in Section 2.4). Numbers (% and\nactual counts) in green\
    \ color indicate prediction accuracy while those in red color are prediction\n\
    errors for stressed and non-stressed crop classes. Numbers in green box represent\
    \ correct prediction\nand those in red box represent misclassiﬁcation of non-stressed/stressed\
    \ classes.\n4. Discussion\nSprinkler irrigation applies a predetermined quantity\
    \ of water and wets the entire\ncanopy, unlike traditional ﬂood irrigation. This\
    \ cools down the microclimate and increases\nrelative air humidity to reduce the\
    \ microclimate’s water demand [52]. This could be the\nreason for lower Tc in\
    \ all the sprinkler irrigation treatments compared to the corresponding\nﬂood\
    \ irrigation treatments (Figure 4). Lowered microclimate water demand could have\n\
    also resulted in lower soil moisture depletion from the root zone and therefore\
    \ higher\nSMC with sprinkler irrigation [53]. In addition to sufﬁcient SMC, sprinkler\
    \ irrigation\nresults in lower deep percolation and nutrient leaching compared\
    \ to conventional ﬂood\nirrigation [54–56]. This could have resulted in a higher\
    \ average yield for sprinkler irrigation\ntreatment plots (5719 kg/ha) compared\
    \ to the ﬂood irrigation treatment plots (4898 kg/ha).\nWith the projected future\
    \ climate change impacts in the form of low rainfall frequencies\nand high ambient\
    \ temperatures, crop water stresses are further expected to multiply, which\n\
    will multiply the penalties in yield potentials [3]. Therefore, stress-tolerant\
    \ crop cultivars\nneed to be developed and planted for uncompromised yield goals.\
    \ As also reported in\nour prior work based on canopy reﬂectance [57], water stress\
    \ started to occur before the\nCRI stage in both methods of irrigation. RWCs were\
    \ lower at late jointing and ﬂowering\nstages in case of ﬂood irrigation. Water\
    \ stress at the ﬂowering stage can result in signiﬁcant\nyield and biomass reductions\
    \ [58] suggesting that it is also inﬂuenced by the phenological\ngrowth stage.\
    \ For robust analysis of this aspect, large datasets are being collected at each\n\
    phenological growth stage. Water stress lowers CO2 availability due to stomatal\
    \ closure,\nthereby affecting photosynthesis and ultimately growth, yield, and\
    \ biomass [59,60].\nCNNs have been increasingly used for plant phenotyping applications\
    \ over the past\ndecade for their capability of modeling complicated plant processes\
    \ by distinguishing and\nextracting regularized data patterns [61,62]. It is for\
    \ this reason; CNN models were highly\naccurate in predicting stressed and non-stressed\
    \ crops using thermal and RGB imagery.\nChlorophyll is vital for photosynthesis,\
    \ while carotenoids are critical non-enzymatic an-\ntioxidants. Water stress reduces\
    \ chlorophyll and carotenoid contents, as well as the ratio\nof chlorophyll ‘a’\
    \ to ‘b’, leading to leaf coloration changes. This is the reason for RGB\nimages\
    \ also yielding satisfactory accuracy of up to 94.6% for tracing leaf color changes\
    \ [63].\nCompared to RGB imagery, thermal imagery is a more detailed and better\
    \ presenter of the\ncrop stress that alters the emissivity patterns proportionally\
    \ [64,65]. The canopy tempera-\nture is affected by the microclimate conditions\
    \ and the available soil moisture [53]. This\nis the reason for the relatively\
    \ lower accuracy of water stress detection with RGB images\n(94.6%) than with\
    \ thermal images (96.7%) irrespective of the selected DL models (Table 5).\nA\
    \ similar observation is reported in a prior study [64] where higher accuracy\
    \ was obtained\nPlants 2022, 11, 3344\n16 of 21\nwith thermal imagery (89%) compared\
    \ to RGB imagery (82%) for wheat ear counting using\nDCNN models. Since thermal\
    \ imaging is often affected by the wind or RH factors of the\nenvironment, the\
    \ quality of data will be critical for training the DL models, especially when\n\
    acquired using aerial platforms [30,64]. Therefore, to maintain thermal data quality,\
    \ imag-\ning campaigns were launched when wind velocities were below 5 kmph. The\
    \ ResNet50\nhad relatively the highest accuracy among the feature extraction models.\
    \ Although it\nis the basic version of GoogLeNet and Inception V3, the performance\
    \ would be highly\nimpacted by the quality of input imagery, size, and robustness\
    \ of the dataset, especially\nfor the agricultural environments. ResNet50 addresses\
    \ the neural network degradation\nproblem by introducing identity mapping, which\
    \ results in the disappearance of gradient\nparameters and the non-ideal convergence\
    \ effect on the deeper networks [66,67]. This fea-\nture contributed to the enhanced\
    \ performance of ResNet50 compared to the other models\nthereby suggesting the\
    \ suitability of ResNet50 for agricultural applications for various\ncrop biotic\
    \ and abiotic stress characterizations. CNN models were also applied to thermal\n\
    imagery for water stress classiﬁcation in maize under well-irrigated, moderately\
    \ irrigated,\nand water-stressed treatments, obtaining an overall accuracy of\
    \ 89% [68]. Color and grey\nimages of maize were also used as inputs to the DCNN\
    \ model for water stress identiﬁcation\nwhere stress identiﬁcation and classiﬁcation\
    \ accuracies were 98% and 95%, respectively [26].\nThe inception-ResNet V2 framework\
    \ utilized for water stress identiﬁcation in sugarcane\nyielded an accuracy of\
    \ 83% with available soil water capacity as input [65]. Thus far, most\nof the\
    \ computer vision models have utilized single-dimensional data inputs, unlike\
    \ this\nstudy which advances water-stress identiﬁcation in wheat crops using multidimensional\n\
    data inputs. Multidimensional data modeling enhances the robustness and applicability\
    \ of\ndeveloped approaches across various agroclimatic conditions.\nCrop growth\
    \ or its water stress response is not necessarily linear to the weather or\nsoil\
    \ conditions [69]. Therefore, the linear (LR) and non-linear function approximation\n\
    approaches (ANN, KNN, SVM, and DL-LSTM) were evaluated to predict the stress class\
    \ of\nthe crop. ANN and SVM had a better stress prediction accuracy (Table 6)\
    \ compared to KNN\nand LR possibly due to two reasons (1) KNN or LR either use\
    \ locally linear segments or a\ngeneralized linear approach for making predictions\
    \ [66,69] and (2) KNN and LR models\ntrain on an unsupervised learning approach,\
    \ unlike ANN and SVM, which train on a\nsupervised learning approach [18]. ANN\
    \ and SVM had comparable accuracies for crop\nstress prediction. However, SVM\
    \ suits small datasets; while ANN can process relatively\nlarger datasets. Therefore,\
    \ ANN would have more conﬁdence in prediction classes.\nCrop phenotyping with\
    \ traditional function approximation approaches (ML mod-\nels) is often subjective\
    \ compared to the advanced DL-LSTM approach as those require\nmanual feature selection\
    \ of Tc, Ta, RH, and SMC. This restricts the robustness and accu-\nracy of the\
    \ ML models. Therefore, DL-LSTM outperformed the traditional ML models\n(Figure\
    \ 9) due to its automated and stabilized feature selection advantage [12,70].\
    \ This\nwas supported by minimum model loss compared to other function approximation-based\n\
    ML models. DL-LSTM not only integrates the thermal imagery features employed in\n\
    DL models but also combines the auxiliary soil and weather data inputs, of function\
    \ ap-\nproximation models. This eventually led to its superior performance over\
    \ the other ML\nmodels evaluated in this study as well as in prior studies of\
    \ crop stress and yield phenotyp-\ning [51] or irrigation forecasting [22]. However,\
    \ GoogleNet, Inception V3, and ResNet50\nprovided comparable or higher stress\
    \ prediction accuracy compared to the DL-LSTM model\n(Table 6). Stress/non-stress\
    \ misclassiﬁcation could be minimized through improved data\nsampling, increasing\
    \ training data size, and optimizing hyper-parameters, or by merging\ndifferent\
    \ ML and DL models for crop’s thermal emissivity and environment data inputs.\n\
    Among the feature extraction and function approximation-based approaches, the\
    \ feature\nextraction-based models outperformed all the function approximation-based\
    \ models for\nwater stress classiﬁcation.\nThe CNN models evaluated in this study\
    \ can be adopted for water stress identiﬁ-\ncation in other wheat cultivars while\
    \ for other crops and their cultivars, sufﬁcient data\nPlants 2022, 11, 3344\n\
    17 of 21\nacquisition, model training, and validations would be required. Along\
    \ similar lines, gath-\nering sufﬁcient data at different crop phenological stages\
    \ will enable growth stage-wise\naccuracy evaluation of ML and DL models in future\
    \ studies. The developed algorithms\nrequired below 5 sec to be successfully implemented\
    \ on independent images for classiﬁca-\ntion into stressed/non-stressed classes.\
    \ This is critical from a real-time stress diagnosis and\nmanagement perspective.\
    \ Trained algorithms are therefore transferrable to handheld or\nedge devices\
    \ for real-time stress detection by breeders, researchers, farmers, and students,\n\
    among others. For commercial adoption of the developed and tested approaches,\
    \ capital\ninvestment would be initially required following which high returns\
    \ may be expected\nthrough improvements in crop stress mitigation and management\
    \ at reduced costs [11].\n5. Conclusions\nThe canopy temperatures, relative water\
    \ content, soil moisture content, and grain\nyield for the wheat crop were signiﬁcantly\
    \ affected by the irrigation type and rates. Lower\nTc and higher RWC, SMC, and\
    \ yield were observed for irrigation at 100% of ETc compared\nto deﬁcit irrigation\
    \ (75, 50, and 25% of ETc). Moreover, a comparable or higher yield was\nobserved\
    \ for sprinkler irrigation compared to conventional ﬂood irrigation and amounted\n\
    to 20% of the water savings.\nThermal images resulted in higher crop water stress\
    \ classification accuracy (94.7–98.4%)\ncompared to RGB imagery (92.5–96.9%).\
    \ Moreover, the DL models (including DL-LSTM)\nperformed better than the ML models\
    \ for stressed and non-stressed crop classiﬁcation.\nAmong the function approximation-based\
    \ approaches, DL-LSTM had the highest accuracy\n(96.7%). Among the feature extraction-based\
    \ methods, ResNet50 had the highest accuracy\nof 96.9% and 98.4% with RGB and\
    \ thermal imagery inputs, respectively.\nOverall, DL models with thermal imagery\
    \ inputs could be highly efﬁcient for crop\nwater stress phenotyping. As a future\
    \ scope, feature extraction-based DL models could\nbe implemented on edge-computing\
    \ devices for real-time water stress monitoring and\nactuation of irrigation systems\
    \ through the internet of things.\nAuthor Contributions: Conceptualization, Y.A.R.\
    \ and N.S.C.; methodology, N.S.C. and M.K.T.;\nsoftware, K.D. and A.S.; validation,\
    \ A.S., K.D., N.S.C. and A.K.C.; resources, Y.A.R.; data curation,\nK.D., M.K.T.\
    \ and A.K.C.; writing—original draft preparation, N.S.C., Y.A.R., and A.K.C.;\
    \ writing—\nreview and editing, A.K.C. and M.K.T. All authors have read and agreed\
    \ to the published version of\nthe manuscript.\nFunding: This research was supported\
    \ by the Indian Council of Agricultural Research-Central\nInstitute of Agricultural\
    \ Engineering Bhopal, India, project# 824.\nData Availability Statement: Data\
    \ will be made available on personalized requests due to restrictions\nfrom the\
    \ parent organization.\nAcknowledgments: The authors would like to thank C.R.\
    \ Mehta and P.S. Tiwari from ICAR-CIAE\nBhopal, for their technical support in\
    \ the conduct of this study.\nConﬂicts of Interest: The authors declare no conﬂict\
    \ of interest.\nAbbreviations\nAbbreviation\nExpanded Form\nAdam\nAdaptive Moment\
    \ Estimation\nAN\nActual Non-Stressed Crop\nANN\nArtiﬁcial Neural Network\nANOVA\n\
    Analysis of Variance\nCIAE\nCentral Institute of Agricultural Engineering\nCNN\n\
    Convolution Neural Network\nDAS\nDay After Sowing\nDCNN\nDeep Convolution Neural\
    \ Network\nDL\nDeep Learning\nPlants 2022, 11, 3344\n18 of 21\nAbbreviation\n\
    Expanded Form\nDL-LSTM\nDeep Learning-Long Short Term Memory\nETc\nEvapotranspiration\n\
    F1\nF1 Score\nICAR\nIndian Council of Agricultural Research\nKNN\nKernel Nearest\
    \ Neighbor\nLR\nLogistic Regression\nLSTM\nLong Short Term Memory\nMAE\nMean Absolute\
    \ Error\nML\nMachine Learning\nP\nPrecision\nPS\nCorrectly Predicted Stressed\
    \ Crop From all the predictions\nRBF\nRadial Basis Function\nRF\nRandom Forest\n\
    RGB\nRed Green Blue\nRH\nRelative Humidity\nRWC\nRelative Water Content\nSD\n\
    Standard Deviation\nSe\nSensitivity\nSgdm\nStochastic Gradient Descent with Momentum\n\
    SMC\nSoil Moisture Content\nS\nSpeciﬁcity\nVM\nSupport Vector Machine\nTa\nAir\
    \ Temperature\nTc\nCanopy Temperature\nTE1\nType 1 Error\nTE2\nType 2 Error\n\
    TN\nTrue Negative\nTS\nTrue Positive\nUAS\nUnmanned Aerial System\nReferences\n\
    1.\nMega, R.; Abe, F.; Kim, J.-S.; Tsuboi, Y.; Tanaka, K.; Kobayashi, H.; Sakata,\
    \ Y.; Hanada, K.; Tsujimoto, H.; Kikuchi, J. Tuning\nWater-Use Efﬁciency and Drought\
    \ Tolerance in Wheat Using Abscisic Acid Receptors. Nat. Plants 2019, 5, 153–159.\
    \ [CrossRef]\n2.\nIhuoma, S.O.; Madramootoo, C.A. Recent Advances in Crop Water\
    \ Stress Detection. Comput. Electron. Agric. 2017, 141, 267–275.\n[CrossRef]\n\
    3.\nSeiﬁkalhor, M.; Niknam, V.; Aliniaeifard, S.; Didaran, F.; Tsaniklidis, G.;\
    \ Fanourakis, D.; Teymoorzadeh, M.; Mousavi, S.H.;\nBosacchi, M.; Li, T. The Regulatory\
    \ Role of γ-Aminobutyric Acid in Chickpea Plants Depends on Drought Tolerance\
    \ and Water\nScarcity Level. Sci. Rep. 2022, 12, 7034. [CrossRef]\n4.\nOletic,\
    \ D.; Bilas, V. How Thirsty the Crops Are: Emerging Instrumentation for Plant-Based\
    \ Field Measurement of Water Stress.\nIEEE Instrum. Meas. Mag. 2020, 23, 37–46.\
    \ [CrossRef]\n5.\nZhang, L.; Niu, Y.; Zhang, H.; Han, W.; Li, G.; Tang, J.; Peng,\
    \ X. Maize Canopy Temperature Extracted from UAV Thermal and\nRGB Imagery and\
    \ Its Application in Water Stress Monitoring. Front. Plant Sci. 2019, 10, 1270.\
    \ [CrossRef]\n6.\nAgam, N.; Cohen, Y.; Berni, J.A.J.; Alchanatis, V.; Kool, D.;\
    \ Dag, A.; Yermiyahu, U.; Ben-Gal, A. An Insight to the Performance of\nCrop Water\
    \ Stress Index for Olive Trees. Agric. Water Manag. 2013, 118, 79–86. [CrossRef]\n\
    7.\nElsayed, S.; Elhoweity, M.; Ibrahim, H.H.; Dewir, Y.H.; Migdadi, H.M.; Schmidhalter,\
    \ U. Thermal Imaging and Passive Reﬂectance\nSensing to Estimate the Water Status\
    \ and Grain Yield of Wheat under Different Irrigation Regimes. Agric. Water Manag.\
    \ 2017, 189,\n98–110. [CrossRef]\n8.\nChandel, A.K.; Khot, L.R.; Osroosh, Y.;\
    \ Peters, T.R. Thermal-RGB Imager Derived in-Field Apple Surface Temperature Estimates\n\
    for Sunburn Management. Agric. For. Meteorol. 2018, 253, 132–140. [CrossRef]\n\
    9.\nChandel, A.K.; Khot, L.R.; Molaei, B.; Peters, R.T.; Stöckle, C.O.; Jacoby,\
    \ P.W. High-Resolution Spatiotemporal Water Use Mapping\nof Surface and Direct-Root-Zone\
    \ Drip-Irrigated Grapevines Using Uas-Based Thermal and Multispectral Remote Sensing.\
    \ Remote\nSens. 2021, 13, 954. [CrossRef]\n10.\nChandel, N.S.; Chakraborty, S.K.;\
    \ Rajwade, Y.A.; Dubey, K.; Tiwari, M.K.; Jat, D. Identifying Crop Water Stress\
    \ Using Deep\nLearning Models. Neural Comput. Appl. 2021, 33, 5353–5367. [CrossRef]\n\
    11.\nTaheri-Garavand, A.; Mumivand, H.; Fanourakis, D.; Fatahi, S.; Taghipour,\
    \ S. An Artiﬁcial Neural Network Approach for\nNon-Invasive Estimation of Essential\
    \ Oil Content and Composition through Considering Drying Processing Factors: A\
    \ Case\nStudy in Mentha Aquatica. Ind. Crops Prod. 2021, 171, 113985. [CrossRef]\n\
    Plants 2022, 11, 3344\n19 of 21\n12.\nSingh, A.K.; Ganapathysubramanian, B.; Sarkar,\
    \ S.; Singh, A. Deep Learning for Plant Stress Phenotyping: Trends and Future\n\
    Perspectives. Trends Plant Sci. 2018, 23, 883–898. [CrossRef]\n13.\nGoldstein,\
    \ A.; Fink, L.; Meitin, A.; Bohadana, S.; Lutenberg, O.; Ravid, G. Applying Machine\
    \ Learning on Sensor Data for\nIrrigation Recommendations: Revealing the Agronomist’s\
    \ Tacit Knowledge. Precis. Agric. 2018, 19, 421–444. [CrossRef]\n14.\nPetrie,\
    \ P.R.; Wang, Y.; Liu, S.; Lam, S.; Whitty, M.A.; Skewes, M.A. The Accuracy and\
    \ Utility of a Low Cost Thermal Camera and\nSmartphone-Based System to Assess\
    \ Grapevine Water Status. Biosyst. Eng. 2019, 179, 126–139. [CrossRef]\n15.\n\
    Subeesh, A.; Bhole, S.; Singh, K.; Chandel, N.S.; Rajwade, Y.A.; Rao, K.V.R.;\
    \ Kumar, S.P.; Jat, D. Deep Convolutional Neural\nNetwork Models for Weed Detection\
    \ in Polyhouse Grown Bell Peppers. Artif. Intell. Agric. 2022, 6, 47–54. [CrossRef]\n\
    16.\nGutiérrez, S.; Diago, M.P.; Fernández-Novales, J.; Tardaguila, J. Vineyard\
    \ Water Status Assessment Using On-the-Go Thermal\nImaging and Machine Learning.\
    \ PLoS ONE 2018, 13, e0192037. [CrossRef]\n17.\nGhosal, S.; Blystone, D.; Singh,\
    \ A.K.; Ganapathysubramanian, B.; Singh, A.; Sarkar, S. An Explainable Deep Machine\
    \ Vision\nFramework for Plant Stress Phenotyping. Proc. Natl. Acad. Sci. USA 2018,\
    \ 115, 4613–4618. [CrossRef]\n18.\nSchmidhuber, J. Deep Learning in Neural Networks:\
    \ An Overview. Neural Netw. 2015, 61, 85–117. [CrossRef]\n19.\nChakraborty, S.K.;\
    \ Chandel, N.S.; Jat, D.; Tiwari, M.K.; Rajwade, Y.A.; Subeesh, A. Deep Learning\
    \ Approaches and Interventions\nfor Futuristic Engineering in Agriculture. Neural\
    \ Comput. Appl. 2022. [CrossRef]\n20.\nYalcin, H. Plant Phenology Recognition\
    \ Using Deep Learning: Deep-Pheno. In Proceedings of the 2017 6th International\n\
    Conference on Agro-Geoinformatics, Fairfax VA, USA, 7–10 August 2017; pp. 1–5.\n\
    21.\nHaider, S.A.; Naqvi, S.R.; Akram, T.; Umar, G.A.; Shahzad, A.; Sial, M.R.;\
    \ Khaliq, S.; Kamran, M. LSTM Neural Network Based\nForecasting Model for Wheat\
    \ Production in Pakistan. Agronomy 2019, 9, 72. [CrossRef]\n22.\nMouatadid, S.;\
    \ Adamowski, J.F.; Tiwari, M.K.; Quilty, J.M. Coupling the Maximum Overlap Discrete\
    \ Wavelet Transform and\nLong Short-Term Memory Networks for Irrigation Flow Forecasting.\
    \ Agric. Water Manag. 2019, 219, 72–85. [CrossRef]\n23.\nYoo, T.-W.; Oh, I.-S.\
    \ Time Series Forecasting of Agricultural Products’ Sales Volumes Based on Seasonal\
    \ Long Short-Term Memory.\nAppl. Sci. 2020, 10, 8169. [CrossRef]\n24.\nArif, S.;\
    \ Kumar, R.; Abbasi, S.; Mohammadani, K.; Dev, K. Weeds Detection and Classiﬁcation\
    \ Using Convolutional Long-Short-Term\nMemory; Research Square: Durham, NC, USA,\
    \ 2021.\n25.\nZhuang, S.; Wang, P.; Jiang, B.; Li, M.; Gong, Z. Early Detection\
    \ of Water Stress in Maize Based on Digital Images. Comput. Electron.\nAgric.\
    \ 2017, 140, 461–468. [CrossRef]\n26.\nAn, J.; Li, W.; Li, M.; Cui, S.; Yue, H.\
    \ Identiﬁcation and Classiﬁcation of Maize Drought Stress Using Deep Convolutional\
    \ Neural\nNetwork. Symmetry 2019, 11, 256. [CrossRef]\n27.\nNiu, Y.; Zhang, H.;\
    \ Han, W.; Zhang, L.; Chen, H. A Fixed-Threshold Method for Estimating Fractional\
    \ Vegetation Cover of Maize\nunder Different Levels of Water Stress. Remote Sens.\
    \ 2021, 13, 1009. [CrossRef]\n28.\nBiju, S.; Fuentes, S.; Gupta, D. The Use of\
    \ Infrared Thermal Imaging as a Non-Destructive Screening Tool for Identifying\n\
    Drought-Tolerant Lentil Genotypes. Plant Physiol. Biochem. 2018, 127, 11–24. [CrossRef]\n\
    29.\nChandel, A.K.; Khot, L.R.; Yu, L.-X. Alfalfa (Medicago Sativa L.) Crop Vigor\
    \ and Yield Characterization Using High-Resolution\nAerial Multispectral and Thermal\
    \ Infrared Imaging Technique. Comput. Electron. Agric. 2021, 182, 105999. [CrossRef]\n\
    30.\nPrashar, A.; Jones, H.G. Infra-Red Thermography as a High-Throughput Tool\
    \ for Field Phenotyping. Agronomy 2014, 4, 397–417.\n[CrossRef]\n31.\nAllen, R.G.;\
    \ Pereira, L.S.; Raes, D.; Smith, M. Crop Evapotranspiration-Guidelines for Computing\
    \ Crop Water Requirements-FAO\nIrrigation and Drainage Paper 56. FAO: Rome, Italy,\
    \ 1998; Volume 300, p. D05109.\n32.\nGoogle Experimental Layout of Winter Wheat\
    \ Crop at Different Rates Using Sprinkler and Flood Irrigation. 2022. Available\n\
    online: https://www.google.com/maps/ (accessed on 8 October 2022).\n33.\nPanigrahi,\
    \ N.; Das, B.S. Canopy Spectral Reﬂectance as a Predictor of Soil Water Potential\
    \ in Rice. Water Resour. Res. 2018, 54,\n2544–2560. [CrossRef]\n34.\nGomez, K.A.;\
    \ Gomez, A.A. Statistical Procedures for Agricultural Research; John Wiley & Sons:\
    \ Hoboken, NJ, USA, 1984; ISBN\n978-0-471-87092-0.\n35.\nTürko˘glu, M.; Hanbay,\
    \ D. Plant Disease and Pest Detection Using Deep Learning-Based Features. Turk.\
    \ J. Electr. Eng. Comput. Sci.\n2019, 27, 1636–1651. [CrossRef]\n36.\nHendrawan,\
    \ Y.; Damayanti, R.; Al Riza, D.F.; Hermanto, M.B. Classiﬁcation of Water Stress\
    \ in Cultured Sunagoke Moss Using\nDeep Learning. TELKOMNIKA (Telecommun. Comput.\
    \ Electron. Control) 2021, 19, 1594–1604. [CrossRef]\n37.\nEsgario, J.G.; Krohling,\
    \ R.A.; Ventura, J.A. Deep Learning for Classiﬁcation and Severity Estimation\
    \ of Coffee Leaf Biotic Stress.\nComput. Electron. Agric. 2020, 169, 105162. [CrossRef]\n\
    38.\nFulton, L.V.; Dolezel, D.; Harrop, J.; Yan, Y.; Fulton, C.P. Classiﬁcation\
    \ of Alzheimer’s Disease with and without Imagery Using\nGradient Boosted Machines\
    \ and ResNet-50. Brain Sci. 2019, 9, 212. [CrossRef]\n39.\nTurkoglu, M.; Hanbay,\
    \ D.; Sengur, A. Multi-Model LSTM-Based Convolutional Neural Networks for Detection\
    \ of Apple Diseases\nand Pests. J Ambient Intell Hum. Comput 2022, 13, 3335–3345.\
    \ [CrossRef]\n40.\nKandel, I.; Castelli, M. The Effect of Batch Size on the Generalizability\
    \ of the Convolutional Neural Networks on a Histopathology\nDataset. ICT Express\
    \ 2020, 6, 312–315. [CrossRef]\n41.\nBlum, A.; Shpiler, L.; Golan, G.; Mayer,\
    \ J. Yield Stability and Canopy Temperature of Wheat Genotypes under Drought-Stress.\n\
    Field Crops Res. 1989, 22, 289–296. [CrossRef]\nPlants 2022, 11, 3344\n20 of 21\n\
    42.\nRashid, A.; Stark, J.C.; Tanveer, A.; Mustafa, T. Use of Canopy Temperature\
    \ Measurements as a Screening Tool for Drought\nTolerance in Spring Wheat. J.\
    \ Agron. Crop Sci. 1999, 182, 231–238. [CrossRef]\n43.\nDeJonge, K.C.; Taghvaeian,\
    \ S.; Trout, T.J.; Comas, L.H. Comparison of Canopy Temperature-Based Water Stress\
    \ Indices for Maize.\nAgric. Water Manag. 2015, 156, 51–62. [CrossRef]\n44.\n\
    Olsovska, K.; Kovar, M.; Brestic, M.; Zivcak, M.; Slamka, P.; Shao, H.B. Genotypically\
    \ Identifying Wheat Mesophyll Conductance\nRegulation under Progressive Drought\
    \ Stress. Front. Plant Sci. 2016, 7, 1111. [CrossRef]\n45.\nLaxa, M.; Liebthal,\
    \ M.; Telman, W.; Chibani, K.; Dietz, K.-J. The Role of the Plant Antioxidant\
    \ System in Drought Tolerance.\nAntioxidants 2019, 8, 94. [CrossRef]\n46.\nWang,\
    \ X.; Vignjevic, M.; Jiang, D.; Jacobsen, S.; Wollenweber, B. Improved Tolerance\
    \ to Drought Stress after Anthesis Due to\nPriming before Anthesis in Wheat (Triticum\
    \ Aestivum L.) Var. Vinjett. J. Exp. Bot. 2014, 65, 6441–6456. [CrossRef]\n47.\n\
    Kukanov, I.; Hautamäki, V.; Lee, K.A. Recurrent Neural Network and Maximal Figure\
    \ of Merit for Acoustic Event Detection.\nIn Proceedings of the Proceedings of\
    \ the Workshop on Detection and Classiﬁcation of Acoustic Scenes and Events, Munich,\n\
    Germany, 16–17 November 2017.\n48.\nCastro-Zunti, R.; Park, E.H.; Choi, Y.; Jin,\
    \ G.Y.; Ko, S. Early Detection of Ankylosing Spondylitis Using Texture Features\
    \ and\nStatistical Machine Learning, and Deep Learning, with Some Patient Age\
    \ Analysis. Comput. Med. Imaging Graph. 2020, 82, 101718.\n[CrossRef]\n49.\nFan,\
    \ Y.; Bai, J.; Lei, X.; Zhang, Y.; Zhang, B.; Li, K.-C.; Tan, G. Privacy Preserving\
    \ Based Logistic Regression on Big Data. J. Netw.\nComput. Appl. 2020, 171, 102769.\
    \ [CrossRef]\n50.\nRehman, T.U.; Mahmud, M.S.; Chang, Y.K.; Jin, J.; Shin, J.\
    \ Current and Future Applications of Statistical Machine Learning\nAlgorithms\
    \ for Agricultural Machine Vision Systems. Comput. Electron. Agric. 2019, 156,\
    \ 585–605. [CrossRef]\n51.\nZhang, J.; Zhu, Y.; Zhang, X.; Ye, M.; Yang, J. Developing\
    \ a Long Short-Term Memory (LSTM) Based Model for Predicting Water\nTable Depth\
    \ in Agricultural Areas. J. Hydrol. 2018, 561, 918–929. [CrossRef]\n52.\nFanourakis,\
    \ D.; Aliniaeifard, S.; Sellin, A.; Giday, H.; Körner, O.; Nejad, A.R.; Delis,\
    \ C.; Bouranis, D.; Koubouris, G.;\nKambourakis, E. Stomatal Behavior Following\
    \ Mid-or Long-Term Exposure to High Relative Air Humidity: A Review. Plant\nPhysiol.\
    \ Biochem. 2020, 153, 92–105. [CrossRef]\n53.\nZhang, W.-Z.; Han, Y.-D.; Du, H.-J.\
    \ Relationship between Canopy Temperature at Flowering Stage and Soil Water Content,\
    \ Yield\nComponents in Rice. Rice Sci. 2007, 14, 67–70. [CrossRef]\n54.\nCavero,\
    \ J.; Medina, E.T.; Puig, M.; Martínez-Cob, A. Sprinkler Irrigation Changes Maize\
    \ Canopy Microclimate and Crop Water\nStatus, Transpiration, and Temperature.\
    \ Agron. J. 2009, 101, 854–864. [CrossRef]\n55.\nHome, P.G.; Panda, R.K.; Kar,\
    \ S. Effect of Method and Scheduling of Irrigation on Water and Nitrogen Use Efﬁciencies\
    \ of Okra\n(Abelmoschus Esculentus). Agric. Water Manag. 2002, 55, 159–170. [CrossRef]\n\
    56.\nWang, P.; Song, X.; Han, D.; Zhang, Y.; Zhang, B. Determination of Evaporation,\
    \ Transpiration and Deep Percolation of Summer\nCorn and Winter Wheat after Irrigation.\
    \ Agric. Water Manag. 2012, 105, 32–37. [CrossRef]\n57.\nChandel, N.S.; Rajwade,\
    \ Y.A.; Golhani, K.; Tiwari, P.S.; Dubey, K.; Jat, D. Canopy Spectral Reﬂectance\
    \ for Crop Water Stress\nAssessment in Wheat (Triticum Aestivum, L.). Irrig. Drain.\
    \ 2021, 70, 321–331. [CrossRef]\n58.\nGupta, N.K.; Gupta, S.; Kumar, A. Effect\
    \ of Water Stress on Physiological Attributes and Their Relationship with Growth\
    \ and\nYield of Wheat Cultivars at Different Stages. J. Agron. Crop Sci. 2001,\
    \ 186, 55–62. [CrossRef]\n59.\nYousefzadeh, K.; Houshmand, S.; Shiran, B.; Mousavi-Fard,\
    \ S.; Zeinali, H.; Nikoloudakis, N.; Gheisari, M.M.; Fanourakis, D.\nJoint Effects\
    \ of Developmental Stage and Water Deﬁcit on Essential Oil Traits (Content, Yield,\
    \ Composition) and Related Gene\nExpression: A Case Study in Two Thymus Species.\
    \ Agronomy 2022, 12, 1008. [CrossRef]\n60.\nOsakabe, Y.; Osakabe, K.; Shinozaki,\
    \ K.; Tran, L.-S. Response of Plants to Water Stress. Front. Plant Sci. 2014,\
    \ 5, 86. [CrossRef]\n61.\nNasiri, A.; Taheri-Garavand, A.; Fanourakis, D.; Zhang,\
    \ Y.-D.; Nikoloudakis, N. Automated Grapevine Cultivar Identiﬁcation via\nLeaf\
    \ Imaging and Deep Convolutional Neural Networks: A Proof-of-Concept Study Employing\
    \ Primary Iranian Varieties. Plants\n2021, 10, 1628. [CrossRef]\n62.\nTaheri-Garavand,\
    \ A.; Rezaei Nejad, A.; Fanourakis, D.; Fatahi, S.; Ahmadi Majd, M. Employment\
    \ of Artiﬁcial Neural Networks\nfor Non-Invasive Estimation of Leaf Water Status\
    \ Using Color Features: A Case Study in Spathiphyllum Wallisii. Acta Physiol.\n\
    Plant. 2021, 43, 78. [CrossRef]\n63.\nZomorrodi, N.; Rezaei Nejad, A.; Mousavi-Fard,\
    \ S.; Feizi, H.; Tsaniklidis, G.; Fanourakis, D. Potency of Titanium Dioxide\n\
    Nanoparticles, Sodium Hydrogen Sulﬁde and Salicylic Acid in Ameliorating the Depressive\
    \ Effects of Water Deﬁcit on Periwinkle\nOrnamental Quality. Horticulturae 2022,\
    \ 8, 675. [CrossRef]\n64.\nGrbovic, Z.; Panic, M.; Marko, O.; Brdar, S.; Crnojevic,\
    \ V. Wheat Ear Detection in RGB and Thermal Images Using Deep Neural\nNetworks.\
    \ Environments 2019, 11, 13.\n65.\nde Melo, L.L.; de Melo, V.G.M.L.; Marques,\
    \ P.A.A.; Frizzone, J.A.; Coelho, R.D.; Romero, R.A.F.; Barros, T.H. da S. Deep\
    \ Learning\nfor Identiﬁcation of Water Deﬁcits in Sugarcane Based on Thermal Images.\
    \ Agric. Water Manag. 2022, 272, 107820. [CrossRef]\n66.\nMhapsekar, M.; Mhapsekar,\
    \ P.; Mhatre, A.; Sawant, V. Implementation of Residual Network (ResNet) for Devanagari\
    \ Handwritten\nCharacter Recognition. In Advanced Computing Technologies and Applications;\
    \ Springer: Berlin/Heidelberg, Germany, 2020;\npp. 137–148.\n67.\nWang, F.; Qiu,\
    \ J.; Wang, Z.; Li, W. Intelligent Recognition of Surface Defects of Parts by\
    \ Resnet. J. Phys. Conf. Ser. 2021, 1883, 012178.\n[CrossRef]\nPlants 2022, 11,\
    \ 3344\n21 of 21\n68.\nZhuang, S.; Wang, P.; Jiang, B.; Li, M. Learned Features\
    \ of Leaf Phenotype to Monitor Maize Water Status in the Fields. Comput.\nElectron.\
    \ Agric. 2020, 172, 105347. [CrossRef]\n69.\nArchontoulis, S.V.; Miguez, F.E.\
    \ Nonlinear Regression Models and Applications in Agricultural Research. Agron.\
    \ J. 2015, 107,\n786–798. [CrossRef]\n70.\nWijaya, D.R.; Sarno, R.; Zulaika, E.\
    \ DWTLSTM for Electronic Nose Signal Processing in Beef Quality Monitoring. Sens.\
    \ Actuators\nB Chem. 2021, 326, 128931. [CrossRef]\n"
  inline_citation: '>'
  journal: Plants
  limitations: '>'
  pdf_link: https://www.mdpi.com/2223-7747/11/23/3344/pdf?version=1669960246
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: Water Stress Identification of Winter Wheat Crop with State-of-the-Art AI
    Techniques and High-Resolution Thermal-RGB Imagery
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.12731/2658-6649-2022-14-6-423-454
  analysis: '>'
  authors:
  - Gurjeet Singh
  - Naresh Kalra
  - Neetu Yadav
  - Ashwani Sharma
  - Manoj Saini
  citation_count: 16
  full_citation: '>'
  full_text: ">\n423\nSiberian Journal of Life Sciences and Agriculture, Том 14, №6,\
    \ 2022\nНАУЧНЫЕ ОБЗОРЫ И СООБЩЕНИЯ\n  \nSCIENTIFIC REVIEWS AND REPORTS\nDOI: 10.12731/2658-6649-2022-14-6-423-454\
    \ \nUDC 004:63\nSMART AGRICULTURE: A REVIEW\nGurjeet Singh, Naresh Kalra, Neetu\
    \ Yadav,                                                    \nAshwani Sharma,\
    \ Manoj Saini\nAgriculture is regarded as one of the most crucial sectors in guaranteeing\
    \ food \nsecurity. However, as the world’s population grows, so do agri-food demands,\
    \ \nnecessitating a shift from traditional agricultural practices to smart agriculture\
    \ \npractices, often known as agriculture 4.0. It is critical to recognize and\
    \ handle the \nproblems and challenges related with agriculture 4.0 in order to\
    \ fully profit from \nits promise. As a result, the goal of this research is to\
    \ contribute to the development \nof agriculture 4.0 by looking into the growing\
    \ trends of digital technologies in the \nfield of agriculture. A literature review\
    \ is done to examine the scientific literature \npertaining to crop farming published\
    \ in the previous decade for this goal. This \nthorough examination yielded significant\
    \ information on the existing state of digital \ntechnology in agriculture, as\
    \ well as potential future opportunities.\nKeywords: Smart Agriculture; Artificial\
    \ Intelligence; Machine Learning; IOT; \nEdge Computing; Fog Computing\nFor citation.\
    \ Gurjeet Singh, Naresh Kalra, Neetu Yadav, Ashwani Sharma, Manoj. \nSmart Agriculture:\
    \ A Review. Siberian Journal of Life Sciences and Agriculture, 2022, \nvol. 14,\
    \ no. 6, pp. 423-454. DOI: 10.12731/2658-6649-2022-14-6-423-454 \n1. Introduction\
    \ \n1.1. A worldwide dilemma of food security\nFood security is a multifaceted\
    \ notion that aims to eliminate hunger by \nassuring a steady supply of nutritious\
    \ food. It is defined by a four-pillar para-\ndigm, each of which is necessary\
    \ to provide food security [1]. Food security \nis becoming a severe global concern\
    \ as a result of anthropogenic factors such \nas rapid population expansion, urbanization,\
    \ industrialization, farmland loss, \nfreshwater scarcity, and environmental degradation.\
    \ This is due to the fact that \n424\nSiberian Journal of Life Sciences and Agriculture,\
    \ Vol. 14, №6, 2022\nthese factors have a direct impact on the agricultural industry,\
    \ which is the \nworld’s principal source of agri-food production. By 2050, it\
    \ is expected that \nthe global population will rise from 7.7 billion to 9.2 billion,\
    \ urban population \nwill rise by 66 percent, arable land will decline by approximately\
    \ 50 million \nhectares, global GHG emissions (source of CO 2 – promote crop disease\
    \ and \npest growth) will rise by 50 percent, agri-food production will decline\
    \ by 20%, \nand food demand will rise by 59 to 98 percent, posing an imminent\
    \ threat. To \nmeet rising food demands, agricultural practitioners around the\
    \ world will need \nto increase crop and livestock production to maximize agricultural\
    \ output. The \nemphasis of this review paper is crop farming, which includes\
    \ the production \nof both food and cash crops. \nA typical agri-food value chain\
    \ displaying three key stages in the production \nof agricultural products: pre-field\
    \ (pre-plantation stage), in-field (plantation and \nharvesting stage), and post-field\
    \ (post-harvesting stage). All of the stages are \nimportant in the value chain,\
    \ but in this examination, we will focus on the sec-\nond stage, in-field, which\
    \ includes numerous crop-growing operations such as \nploughing, sowing, spraying,\
    \ and harvesting, among others. Traditional agricul-\ntural approaches are now\
    \ used in these procedures, which are labor-intensive, \nrequire arable land,\
    \ time, and a significant quantity of water (for irrigation), and \nmake it difficult\
    \ to produce enough food [5]. A part of the problem is also due \nto the improper\
    \ application of pesticides and herbicides, as well as the misuse \nof available\
    \ technologies, both of which hurt crops and ultimately result in \nagricultural\
    \ waste [6]. These problems can be solved by combining advanced \ntechnologies\
    \ and computer-based applications that ensure higher crop yields, \nless water\
    \ use, better pesticide/herbicide use, and improved crop quality. This \nis where\
    \ the concept of smart agriculture comes into play.\n1.2. Smart Agriculture\n\
    Every industry is being revolutionized and reshaped by Industry 4.0. It’s a \n\
    strategic initiative that combines emerging disruptive digital technologies like\
    \ \nthe Internet of Things (IoT), big data and analytics (BDA), system integration\
    \ \n(SI), cloud computing (CC), simulation, autonomous robotic systems (ARS),\
    \ \naugmented reality (AR), artificial intelligence (AI), wireless sensor networks\
    \ \n(WSN), cyber-physical systems (CPS), digital twin (DT), and additive manu-\n\
    facturing (AM) to enable the digitization of the industry [7]. \nAgriculture 4.0,\
    \ also known as smart agriculture, smart farming or digital \nfarming [7], is\
    \ the next phase of industrial agriculture, fueled by the integra-\ntion of these\
    \ technologies in agriculture. Farmers can use smart agriculture to \naddress\
    \ a variety of agricultural food production concerns such as farm pro-\n425\n\
    Siberian Journal of Life Sciences and Agriculture, Том 14, №6, 2022\nductivity,\
    \ environmental impact, food security, crop losses, and sustainability. \nFarmers,\
    \ for example, can connect to farms remotely, regardless of location \nor time,\
    \ using IoT-enabled equipment based on WSNs to monitor and control \nfarm operations.\
    \ Drones outfitted with hyper spectral cameras can collect data \nfrom a variety\
    \ of sources on farmlands, while autonomous robots can assist \nor complete repetitive\
    \ chores on farms. Data analytics techniques can be used \nto examine the obtained\
    \ data, and computer programs can be utilized to help \nfarmers make decisions.\n\
    Similarly, smart agriculture can monitor and analyze a wide range of pa-\nrameters\
    \ related to environmental factors, weed control, crop production status, \nwater\
    \ management, soil conditions, irrigation scheduling, herbicides and pes-\nticides,\
    \ and controlled environment agriculture to increase crop yields, reduce \ncosts,\
    \ improve product quality, and maintain process inputs through the use of \nmodern\
    \ systems [8].\n1.3. Research Motivation and Contribution \nThe reason for writing\
    \ this assessment is that digital technologies in agri-\ncultural systems provide\
    \ new strategic solutions for increasing farm output ef-\nficiency and effectiveness.\
    \ Furthermore, digital transformation paves the door \nfor modern farming technologies\
    \ like vertical farming (hydroponics, aquapon-\nics, and aeroponics) to be used,\
    \ which has the potential to solve food security \nissues. However, there are\
    \ a number of issues and restrictions connected with \nthis change from a technological,\
    \ socioeconomic, and management perspective \nthat must be overcome in order to\
    \ fully realise the potential of agricultural 4.0 \n[9].A number of publications\
    \ [9–18] have examined developing trends in the \ndevelopment of agriculture 4.0\
    \ by offering concise information on essential \nuses, benefits, and research\
    \ problems of smart farming. These studies’ research \nfocuses on either explaining\
    \ more general technical aspects while focusing on \nonly one or a few digital\
    \ technologies, or improving agricultural supply chain \nperformance, or developing\
    \ an agriculture 4.0 definition, or achieving sustain-\nable agronomy through\
    \ precision agriculture, or proposing a smart farming \nframework. Nonetheless,\
    \ these studies do not include an explicit discussion of \nthe tools and techniques\
    \ utilized to construct various systems, as well as their \nmaturity level. There\
    \ are also few studies that look at the consequences of dig-\nital technology\
    \ in modern soilless farms including hydroponics, aquaponics, \nand aeroponics\
    \ (indoor/outdoor). As a result, in order to promote conversation \nin this field,\
    \ it is necessary to examine the emergence of agriculture 4.0 from \nmany angles.\
    \ This research seeks to provide a comprehensive overview of dig-\nital technologies\
    \ used in the second stage of the agricultural production value \n426\nSiberian\
    \ Journal of Life Sciences and Agriculture, Vol. 14, №6, 2022\nchain (in-field)\
    \ for various farm types as described in section 1.1. The study’s \nkey theoretical\
    \ contribution is the analysis and dissemination of the tools and \ntechniques\
    \ used, as well as the farm type, maturity level of produced systems, \nand potential\
    \ obstacles or inhibiting factors in agriculture 4.0 development. Re-\nsearchers\
    \ and agricultural practitioners will benefit from the review’s insights \nin\
    \ future study on agriculture 4.0. \n1.4. Paper organization \nThe following is\
    \ the structure of the paper after the introduction: \nSection 2 discusses the\
    \ methodology used to collect relevant literature; Sec-\ntion 3 then presents\
    \ the statistical results obtained after a general analysis of the \nselected\
    \ research studies; Section 4 then provides a detailed overview of the \ncore\
    \ technologies used in agricultural digitization; Section 5 then highlights the\
    \ \ntechnical and socio-economic roadblocks to digital integration in agriculture;\
    \ \nand finally, Section 6 outlines a discussion of the research questions.\n\
    2. Research Methodology \nA systematic literature review (SLR) is a technique\
    \ for organizing and iden-\ntifying research related to a specific topic [19].\
    \ SLR is used in this study to look \ninto the state of Industry 4.0 technologies\
    \ in the agricultural industry. Cases \nwhere the phrase ‘agricultural’ occurred\
    \ in the title, abstract, or keywords of \nan article with any of the ‘Industry\
    \ 4.0 technologies’ described in section 1.2 \nare specifically sought. A review\
    \ procedure is established prior to conducting \nthe SLR to ensure a transparent\
    \ and high-quality research process, which are \nthe features that distinguish\
    \ a systematic literature review [20]. By conducting \nthorough literature searches,\
    \ the review methodology also helps to reduce bias. \nThe creation of the research\
    \ questions, the defining of the search method, and \nthe specification of inclusion\
    \ and exclusion criteria are all part of this process. \nTo conduct SLR, this\
    \ paper uses a recommended reporting item for system-\natic reviews and meta-analysis\
    \ (PRISMA) approach. PRISMA is a minimum \ncollection of items based on evidence\
    \ that is used to guide the construction of \nsystematic literature reviews and\
    \ other meta-analyses [19].\n2.1. Review Protocol \nBefore doing the bibliographic\
    \ analysis, a review methodology is estab-\nlished to identify, analyze, and interpret\
    \ data that are relevant to the research \nfocus. To begin, research questions\
    \ are developed in order to provide insight \ninto the study of published studies\
    \ in the research area of interest from many \nperspectives. These are the questions\
    \ that must be addressed in the research. The \nsearch strategy is then created,\
    \ which aids in the identification of appropriate \n427\nSiberian Journal of Life\
    \ Sciences and Agriculture, Том 14, №6, 2022\nkeywords later in the search equation,\
    \ as well as the identification of relevant \ninformation sources, such as academic\
    \ databases and search engines that allow \naccess to vast amounts of digital\
    \ documentation. Science Direct, Scopus, and \nIEEE Xplore are three online research\
    \ archives that are utilized to find relevant \nstudies. Finally, boundaries are\
    \ created by predefining inclusion and exclusion \ncriteria for further inquiry\
    \ and content assessments of selected articles in order \nto narrow the search\
    \ results of each database.\n2.2. Evaluation Process \nIdentification, screening,\
    \ eligibility, and inclusion are the four stages of the \nliterature search process\
    \ that are evaluated. Consolidation is done for the re-\nmoval of duplicate items\
    \ in the identification step after initial metadata filtering \nby the use of\
    \ search expressions. After this phase, the number of publications is \nreduced.\
    \ The titles and abstracts of the papers are reviewed during the screening \n\
    stage, and the most relevant publications are chosen for integral reading. In\
    \ the \nthird stage, full-text screening of these papers is done to ensure that\
    \ they are \neligible for this paper’s goal.\n2.3. Threats to Validity \n(i) SLR\
    \ replication: Because the current search is confined to only three on-\nline\
    \ repositories, the provided SLR is vulnerable to risks to validity. \nAdditional\
    \ sources could potentially lead to the discovery of more pub-\nlications. Validity\
    \ can be regarded satisfactorily addressed because the SLR \nprocess is clearly\
    \ defined in sub-sections 2.1 and 2.2. However, it is possible \nthat slightly\
    \ different publications will be found if this SLR is replicated. This \nvariation\
    \ could be due to various personal choices made throughout the PRIS-\nMA screening\
    \ and eligibility phases, but it’s highly improbable that the overall \nresults\
    \ would alter.\n(ii)The search string used to discover the relevant papers covers\
    \ the entire \nspectrum of SLR; however it’s possible that some important studies\
    \ were over-\nlooked. More research may be found if more keywords and synonyms\
    \ in the \nsearch are included.\n3. Digitization Trends in Agriculture \nAlthough\
    \ the agriculture business is making significant progress in terms \nof digital\
    \ technology adoption, it is still lagging behind other industries such \nas healthcare,\
    \ manufacturing, mining, automotive, energy, and others [15]. The \ncrop farming\
    \ method considered while designing an application or framework \nis referred\
    \ to as the farm type. The farming method, for example, can be soil-\nbased or\
    \ soilless. Open-air fields (conventional outdoor agricultural farms) and \n428\n\
    Siberian Journal of Life Sciences and Agriculture, Vol. 14, №6, 2022\ngreenhouse\
    \ farms are included in the soil-based farming category (indoor). The \nsoilless\
    \ farming category, on the other hand, includes modern farming tech-\nniques such\
    \ as aquaponics, aeroponics, and hydroponics (mostly indoor). In \nthe recent\
    \ decade, autonomous robotics systems (including unmanned guided \nvehicles and\
    \ unmanned aerial vehicles (drones)), the internet of things, and \nmachine learning\
    \ appear to be the most commonly used technology in agricul-\nture. Agriculture’s\
    \ growing sectors include big data, wireless sensor networks, \ncyber-physical\
    \ systems, and digital twins. Furthermore, in contrast to indoor \nfarms, open\
    \ air farms are the most usually examined in research investigations. \nFew publications\
    \ exist for soilless farming systems (aquaponics, aeroponics, \nand hydroponics),\
    \ implying that these modern farming practices are still in \ntheir infancy. Similarly,\
    \ each use case’s services are identified and classified \ninto nine service categories:\
    \ I crop management, CM (estimation/harvesting \nperiod and seed plantation/prediction\
    \ of crop yield/ growth rate/harvesting/ \npollination/ spraying (fertilizer/\
    \ pesticide)); ii) crop quality management, CQM \n(fresh weight, green biomass,\
    \ height, length, width, leaf density, piment content \n(chlorophyll), and phytochemical\
    \ composition); iii) water and environmental \nmanagement, WEM (monitoring and\
    \ control of flow rate, water level, water \nquality (nutrients), temperature,\
    \ humidity, CO2, and weather forecasts, among \nother things); iv) irrigation\
    \ management, IM (water stress detection and sched-\nuling); v) farm management,\
    \ FM (monitoring of farm operations, tracking and \ncounting products, determining\
    \ production efficiency, financial analysis, energy \nconsumption analysis, technology\
    \ integration, and decision-making);\nPDM (pest and disease management) is a term\
    \ used to describe the man-\nagement of pests and diseases (pest identification\
    \ and disease detection) SM \n(Soil Management) vii) (moisture content, soil nutrients,\
    \ fertilizer needs and \napplication) WUVM (weed/unknown vegetation mapping, classification,\
    \ and \npesticide application) viii) weed and unwanted vegetation management FDC\
    \ \n(fruit detection and counting), and ix) \nThe role of various digital technologies\
    \ in smart farming is depicted in \nthese categories. Crop management characteristics\
    \ such as crop yield prediction, \ngrowth rate estimation, and harvesting period\
    \ evaluation are the most 4.0 in the \nprevious decade, whereas soil management,\
    \ fruit identification and counting, \nand crop quality management receive very\
    \ less attention. The European Union’s \nTRL scale, which divides system maturity\
    \ into three generic categories [21], is \nused to assess the technology readiness\
    \ level (TRL) of all use cases. The first \nlevel is conceptual, which corresponds\
    \ to European TRL 1–2 (use case is in \nconcept phase), the second level is prototype,\
    \ which corresponds to Europe-\n429\nSiberian Journal of Life Sciences and Agriculture,\
    \ Том 14, №6, 2022\nan TRL 3–6 (use case is functional even without all planned\
    \ features), and the \nthird level is deployed, which corresponds to European\
    \ TRL 7–9. (Use case \nis mature with all the possible functions). Each use case’s\
    \ TRL was produced \nin a few experiments. It has been noticed that smart agricultural\
    \ systems have \nmade little progress from the concept and prototype stages to\
    \ the commercial \nstage. The majority of use cases, for example, are still in\
    \ the prototype stage.\n4. Agriculture 4.0 enabling technologies \n4.1. Internet\
    \ of Things driven agricultural systems \nThe Internet of Things (IoT) is a network\
    \ of interconnected computing de-\nvices, sensors, appliances, and machines that\
    \ are all connected to the internet \nand have their own unique identities and\
    \ capacities for remote sensing and \nmonitoring [21]. Network layer (communication),\
    \ perception layer (hardware \ndevices), , middleware layer (device management\
    \ and interoperability), service \nlayer (cloud computing), application layer\
    \ (data integration and analytics), and \nend-user layer are the six layers of\
    \ the IoT reference architecture (user-inter-\nface). IoT devices on the physical\
    \ layer in the agricultural domain collect data \non environmental and crop characteristics\
    \ such as temperature, humidity, pH \nvalue, water level, leaf colour, fresh leaf\
    \ weight, and so on. The network layer is \nresponsible for transmitting this\
    \ information, and its architecture is determined \nby the field size, farm location,\
    \ and type of farming method. ZigBee, LoRa, and \nSigfox, for example, are widely\
    \ utilized and employed in outdoor fields because \nthey are less expensive, have\
    \ low energy consumption, and have a long trans-\nmission range [22, 23]. Bluetooth,\
    \ despite being a secure technology, is only \nemployed in indoor farms due to\
    \ its limited transmission range [22]. Due to its \nhigh costs and high energy\
    \ consumption, Wi-Fi is not a promising technology \nfor agricultural applications\
    \ [22]. On the other hand, RFID (radio frequency \nidentification) and NFC (near\
    \ field communication) technologies are increas-\ningly being used in agricultural\
    \ systems for product tracking [24]. For periodic \nmonitoring of environmental\
    \ and soil characteristics, GPRS or mobile commu-\nnication technology (2G, 3G,\
    \ and 4G) is utilized. Furthermore, HTTP, WWW, \nand SMTP are the most commonly\
    \ utilized communication protocols in agri-\ncultural contexts. Similarly, middleware\
    \ HYDRA and SMEPP are commonly \nused in agricultural systems to enable interoperability\
    \ and system security for \ntheir context-aware functionalities [25]. \nCloud\
    \ computing approaches are used in the service layer to store data. \nThis information\
    \ is then used on the application layer to create smart apps that \nfarmers, agriculture\
    \ experts, and supply chain professionals can use to improve \n430\nSiberian Journal\
    \ of Life Sciences and Agriculture, Vol. 14, №6, 2022\nfarm monitoring and productivity.\
    \ The use of IoT in agriculture is intended to \nprovide farmers with decision-making\
    \ tools and automation technologies that \nallow them to seamlessly integrate\
    \ knowledge, products, and services in order to \nincrease production, quality,\
    \ and profit. A slew of research have been conduct-\ned and presented on the incubation\
    \ of IoT concepts in the agricultural industry. \nThe development of IoT-based\
    \ agricultural systems has addressed a variety of \ntechnological and architectural\
    \ concerns. However, most of these technologies \nare now in the conceptual stage\
    \ or in prototype form (not commercial). Farm \nmanagement, irrigation control,\
    \ crop development, health monitoring, and dis-\nease detection are all priorities.\
    \ \nSome of these studies also explained how IoT is being used in current ag-\n\
    ricultural systems like vertical farming (soilless farming - aquaponics, hydro-\n\
    ponics, and aeroponics) and greenhouse farming (soil-based). Furthermore, the\
    \ \nmajority of studies have been focused on a single issue.\n4.2. Wireless sensor\
    \ networks in agriculture \nA wireless sensor network (WSN) is a technology that\
    \ is utilized in an Inter-\nnet of Things (IoT) system. It is defined as a collection\
    \ of spatially distributed \nsensors for monitoring environmental physical conditions,\
    \ temporarily storing \nobtained data, and transferring the information to a central\
    \ point [22]. A wire-\nless sensor network (WSN) for smart farming is made up\
    \ of multiple sensor \nnodes connected by a wireless connection module. These\
    \ nodes have a variety \nof skills that allow them to self-organize, self-configure,\
    \ and self-diagnose (for \nexample, processing, trans- mission, and feeling).\
    \ There are various varieties of \nWSNs, which are classified based on the environment\
    \ in which they are used. \nTWSNs (terrestrial wireless sensor networks), WUSNs\
    \ (wireless underground \nsensor networks), UWSNs (underwater wireless sensor\
    \ networks), WMSNs \n(wireless multimedia sensor networks), and MWSNs (mobile\
    \ wireless sensor \nnetworks) are a few examples [26]. TWSN and UWSN are commonly\
    \ utilized \nin agricultural applications. TWSN nodes are sensors that collect\
    \ data from \nthe environment and are located above ground. The second type of\
    \ WSN is \nWUSNs, which are WSNs with sensor nodes embedded in the soil. Lower\
    \ fre-\nquencies easily enter the soil in this environment, whereas higher frequencies\
    \ \nare severely attenuated [27]. Because of the limited communication radius,\
    \ the \nnetwork requires a larger number of nodes to cover a big area. Many research\
    \ \npublications on the use of WSN for various outdoor and indoor farm applica-\n\
    tions, such as irrigation management, water quality testing, and environmental\
    \ \nmonitoring, are accessible in the literature. The goal of these experiments\
    \ was \nto create WSN architectures that were simple, low-cost, energy-efficient,\
    \ and \n431\nSiberian Journal of Life Sciences and Agriculture, Том 14, №6, 2022\n\
    scalable. However, several aspects of WSNs, such as minimum maintenance, \nrobust\
    \ and fault-tolerant architecture, and interoperability, require more study. \n\
    4.3. Cloud computing in agriculture \nCloud computing (CC) is defined as a model\
    \ for enabling convenient, ubiq-\nuitous, on-demand network access to a shared\
    \ pool of configurable computing \nresources (e.g., networks, servers, storage,\
    \ applications, and services) that can \nbe rapidly provisioned and released with\
    \ minimal management effort or ser-\nvice provider interaction, according to the\
    \ National Institute of Standards and \nTechnologies (NIST) [28]. The datacenter\
    \ (hardware), infrastructure, platform, \nand application layers make up the primary\
    \ architecture of CC [29]. Each of \nthese layers corresponds to one of three\
    \ cloud service models: SaaS (software \nas a service), PaaS (platform as a service),\
    \ and IaaS (infrastructure as a service) \n(IaaS). In the agriculture sector,\
    \ cloud computing has gotten a lot of attention in \nthe last decade because it\
    \ provides: 1) low-cost storage for data collected from \nvarious domains via\
    \ WSNs and other preconfigured IoT devices, 2) large-scale \ncomputer systems\
    \ to make intelligent decisions by converting raw data into \nusable knowledge,\
    \ and 3) a secure platform for developing agricultural based \nIoT applications\
    \ [30]. \nCC is used to develop various agricultural applications in conjunction\
    \ with \nIoT and WSN. CC technology is also utilized to develop operational farm\
    \ man-\nagement systems (FMSs) that help farmers and farm managers monitor farm\
    \ \nactivities more efficiently. The traceability of agri-product quality is another\
    \ \narea of interest that is being investigated in global research [31]. However,\
    \ only \npreliminary research has been done to see if traceability complies with\
    \ food \nsafety and quality criteria. The usage of cloud-based agricultural systems\
    \ has \nthe potential to address issues such as rising food demand, pollution\
    \ from pes-\nticides and fertilizers, and the safety of agricultural products.\
    \ These FMSs, on \nthe other hand, lack the flexibility to offer run-time customization\
    \ in response \nto specific farmer needs. Furthermore, because most farm data\
    \ is fragmented \nand distributed, recording farm operations accurately in existing\
    \ FMSs systems \nis problematic [32].\n4.4. Edge/fog computing in agriculture\
    \ \nThe rapid expansion of IoT has resulted in an explosion of sensors and smart\
    \ \ndevices, creating massive amounts of data. The processing and analysis of\
    \ such a \nlarge volume of data in real time is difficult since it puts a strain\
    \ on the cloud serv-\ner and slows response times. When dealing with such a massive\
    \ data set, a cloud \nserver alone will not be able to offer real-time responses.\
    \ Furthermore, because \nIoT applications require a constant exchange of information\
    \ between devices and \n432\nSiberian Journal of Life Sciences and Agriculture,\
    \ Vol. 14, №6, 2022\nthe cloud, they are susceptible to network latency, making\
    \ CC unsuitable for these \napplications [23]. The introduction of the edge computing\
    \ idea has the potential \nto overcome the CC issues. This novel computing architecture\
    \ places computa-\ntional and storage resources (such as cloudlets or fog nodes)\
    \ closer to data sources \nlike mobile devices and sensors at the network’s edge.\
    \ This allows for real-time \nanalytics while maintaining data security on the\
    \ device [23]. Although edge com-\nputing has exciting potential for smart agriculture,\
    \ its applications in agricultural \nsystems are still in their infancy. As a\
    \ result, there are limited research studies in \nthis field. The majority of\
    \ the edge computing-based agricultural systems covered \nin these papers are\
    \ prototypes that solve a small number of challenges across a \nvariety of agricultural\
    \ disciplines. Interoperability and scalability issues haven’t \ngotten enough\
    \ attention so yet. Agricultural robots combine emerging technolo-\ngies such\
    \ as computer vision; wireless sensor networks (WSNs), satellite navi-\ngation\
    \ systems (GPS), artificial intelligence (AI), cloud computing (CC), and the \n\
    Internet of Things (IoT) to help farmers improve productivity and quality of ag-\n\
    ricultural products. AARS in smart farming can be mobile or fixed [33]. Mobile\
    \ \nAARS can move around the working field. Unmanned ground vehicles (UGVs) \n\
    and unidentified aerial vehicles (UAVs) are the two types of mobile AARSs, as\
    \ \ndiscussed in the following sections. \n4.5.1. Unmanned ground vehicles in\
    \ agriculture\nUnmanned ground vehicles (UGVs) are agricultural robots that work\
    \ with-\nout the use of a human operator on the ground. A platform for locomotive\
    \ ap-\nparatus and manipulator, navigation sensors, a supervisory control system,\
    \ an \ninterface for the control system, communication links for information exchange\
    \ \nbetween devices, and system architecture for integration between hardware\
    \ and \nsoftware agents are the main components of UGVs [34]. The control architec-\n\
    ture of a UGV can be remote-operated (controlled via an interface by a human \n\
    operator) or totally autonomous (operated without the use of a human control-\n\
    ler using artificial intelligence technology) [34]. Locomotive systems, likewise,\
    \ \ncan be based on wheels, tracks, or legs [34]. Legged robots are uncommon in\
    \ \nagriculture, despite their great terrain flexibility, inherent Omni directionality,\
    \ \nand soil protection. These robots, however, offer a disruptive locomotion\
    \ mech-\nanism for smart farms when paired with wheels (wheel-legged robots).\
    \ UGVs \nshould meet specific requirements, such as small size, maneuverability,\
    \ resil-\nience, efficiency, human-friendly interface, and safety, in addition\
    \ to the nec-\nessary features for infield operations, in order to improve crop\
    \ yields and farm \nproductivity. A 4WD locomotive system is used in the majority\
    \ of agricultural \nrobotic systems due to its ease of manufacture and control.\
    \ \n433\nSiberian Journal of Life Sciences and Agriculture, Том 14, №6, 2022\n\
    The disadvantage of 4WD is that terrains with stone elements and/or voids \nhave\
    \ a significant impact on the wheels [34]. As a result, other mechanisms, \nsuch\
    \ as legged or wheel-legged locomotive systems, should be investigated. \nAlthough\
    \ some robots include computer vision systems, most of these robots \nare designed\
    \ with a low-cost computer vision system, such as traditional RGB \ncameras, due\
    \ to the difficulties of establishing an accurate and dependable sys-\ntem that\
    \ can replace manual labour. Furthermore, the majority of the systems \nmentioned\
    \ above are still in the research phase, with no large-scale commer-\ncial application.\n\
    4.5.2. Unmanned aerial vehicles in agriculture \nUnmanned aerial vehicles (UAVs),\
    \ sometimes known as aerial robots, are \nplanes that do not have a human pilot\
    \ on board. There are many different types \nof UAVs [35] depending on the technology\
    \ used to fly (wing structure) and the \nlevel of autonomy. Fixed-wing (planes),\
    \ single-rotor (helicopter), hybrid system \n(vertical takeoff and landing), and\
    \ multi-rotor UAVs are examples of wing types \n(drone). Drones (multi-rotor technology),\
    \ which are raised and driven by four \n(quad-rotor) or six (hex-rotor) rotors,\
    \ have grown in popularity in the agricul-\nture sector because to their mechanical\
    \ simplicity in comparison to helicopters, \nwhich rely on a much more complex\
    \ plate control mechanism [36]. Similarly, \nUAVs can be tele-operated or tele-commanded,\
    \ depending on their autonomy \nlevel, with the pilot providing references to\
    \ each actuator of the aircraft to con-\ntrol it in the same way that an onboard\
    \ pilot would, or tele-commanded with the \naircraft relying on an automatic controller\
    \ on board to maintain a stable flight \n[35]. Agricultural UAVs with the right\
    \ sensors (vision, infrared, multispectral, \nand hyper spectral cameras, for\
    \ example) can collect data (vegetation, leaf area, \nand reflectance indexes)\
    \ from their fields to monitor dynamic changes in crops \nthat aren’t visible\
    \ from the ground [37]. Farmers can deduce information about \ncrop illnesses,\
    \ nutrient deficits, water level, and other agricultural growth char-\nacteristics\
    \ using this data. Farmers might plan possible cures using this knowl-\nedge (irrigation,\
    \ fertilization, weed control, etc.). \nThe majority of the systems mentioned\
    \ above are still in the research stage, \nwith no large-scale commercial use.\
    \ Other issues with these UAVs include bat-\ntery life and flight time [35]. Lithium-ion\
    \ batteries are currently in use because \ntheir capacity exceeds that of conventional\
    \ batteries. \nHowever, increasing the battery capacity increases the weight of\
    \ the drone, \nand research is currently underway to overcome this issue. \nFurthermore,\
    \ existing UAVs have complicated user interfaces that can only \nbe used by experts\
    \ to accomplish agricultural chores. People who are elderly \n434\nSiberian Journal\
    \ of Life Sciences and Agriculture, Vol. 14, №6, 2022\nor unfamiliar with UAV\
    \ technology will be able to control it more readily if \nthe user interface is\
    \ improved and made more human-centered with multimod-\nal feedback. \n4.6. Big\
    \ data and analytics in agriculture \nRapid advancements in IoT and CC technologies\
    \ have massively expanded \nthe amount of data available. Textual content (structured,\
    \ semi-structured, and un-\nstructured) and multimedia content (e.g., videos,\
    \ photos, and audio) are included \nin this data, also known as Big Data (BD)\
    \ [38]. Big data analytics is the practice \nof analyzing large amounts of data\
    \ to find hidden patterns, unknown relationships, \nmarket trends, client preferences,\
    \ and other important information (BDA). Big \ndata is usually classified into\
    \ five dimensions, each of which is represented by a V. \nThe concept of BD-driven\
    \ smart agriculture is very new, but its trend is \ngood because it has the potential\
    \ to make a dramatic change in the food supply \nchain and boost food security\
    \ through higher productivity. Agricultural big data \nis typically generated\
    \ from a variety of sources in agriculture, including ground \nsensors, aerial\
    \ vehicles, and ground vehicles equipped with special cameras and \nsensors; governmental\
    \ bodies in the form of reports and regulations; private \norganizations through\
    \ online web services; farmers in the form of knowledge \ngained through surveys;\
    \ and social media [39]. Depending on the agricultural \ndomain, the data can\
    \ be environmental (weather, climate, moisture level, etc.), \nbiological (plant\
    \ disease), or geospatial, and it comes in a variety of volumes, \nspeeds, and\
    \ formats [40]. The information is acquired and stored in a computer \ndatabase,\
    \ where it is analyzed using computer algorithms for seed characteris-\ntics,\
    \ weather patterns, soil attributes (such as pH or nutrient content), marketing\
    \ \nand trade management, consumer behaviour, and inventory management. In \n\
    agriculture, a range of strategies and tools are used to examine large data. The\
    \ \nmost often employed techniques include machine learning, cloud-based plat-\n\
    forms, and modelling and simulation. Machine learning technologies are used \n\
    to solve problems like prediction, clustering, and classification, while cloud\
    \ \nplatforms are utilized for large-scale data storage, preprocessing, and visual-\n\
    ization. There are still numerous potential areas where BDA can be used to \n\
    address various agricultural concerns that are not well covered in existing lit-\n\
    erature. For example, data-intensive greenhouses and indoor vertical farming \n\
    systems, quality control and health monitoring of crops in outdoor and indoor\
    \ \nfarms, genetic engineering, decision support platforms to help farmers design\
    \ \nindoor vertical farms, and scientific models for policymakers to help them\
    \ make \ndecisions about the physical ecosystem’s sustainability. Finally, the\
    \ majority of \nsystems are still in the prototype stage.\n435\nSiberian Journal\
    \ of Life Sciences and Agriculture, Том 14, №6, 2022\n4.7. Artificial intelligence\
    \ in agriculture \nArtificial intelligence (AI) is the study of theories and computer\
    \ systems that \ncan perform activities that need human intelligence, such as\
    \ sensory percep-\ntion and decision-making [41]. AI, particularly in the areas\
    \ of machine learning \n(ML) and deep learning (DL), is seen as one of the primary\
    \ forces driving the \ndigitization of agriculture when combined with CC, IoT,\
    \ and big data. These \ntechnologies have the potential to increase crop production,\
    \ harvesting, pro-\ncessing, and marketing in real time [42]. ML and DL algorithms\
    \ are being used \nto determine various parameters such as weed detection, yield\
    \ prediction, and \ndisease identification in a number of intelligent agricultural\
    \ systems. The fol-\nlowing two sub-sections go through these systems.\n4.7.1.\
    \ Machine learning in agriculture \nsupervised learning (linear regression, regression\
    \ trees, non-linear regres-\nsion, Bayesian linear regression, polynomial regression,\
    \ and support vector \nregression), and unsupervised learning (hierarchal clustering,\
    \ k-means cluster-\ning, neural networks (NN) anomaly detection, principal component\
    \ analysis, \nindependent component analysis, a-priori algorithm, and singular\
    \ value decom-\nposition (SVD)). Weed detection, Crop yield prediction, disease\
    \ and weather \nprediction (rainfall), soil properties estimation ( moisture content,\
    \ type, pH, \ntemperature, etc.), water management, fertilizer amount determination,\
    \ and \nlivestock production and management all use machine learning techniques\
    \ and \nalgorithms [2, 43]. According to the study of these publications, “crop\
    \ yield \nprediction” is an extensively researched area, with the most widely\
    \ utilized ML \napproaches to allow smart farming being linear regression [4],\
    \ neural network \n(NN), random forest (RF), and support vector machine (SVM)\
    \ [2]. \nThe presented use cases are still in the research phase, and no commercial\
    \ \nuse has been recorded as of yet. Furthermore, AI and machine learning ap-\n\
    proaches are found to be underutilized in greenhouse and indoor vertical farm-\n\
    ing systems, particularly hydroponics, aquaponics, and aeroponics. There are \n\
    only a handful publications that use machine learning techniques. To enable \n\
    digital farming, new methodologies such as federated learning and privacy \npreserving\
    \ methods are being developed in light of the digital transformation’s \ncyber-security\
    \ and data privacy problems [44]. These methods create machine \nlearning models\
    \ from local parameters rather than sharing private data samples, \nreducing security\
    \ concerns.\n4.7.2. Deep learning in agriculture \nDeep learning (DL) is an extension\
    \ of classical machine learning (ML) \nbecause extra “depth” (complexity) is added\
    \ to the model, it can accomplish \n436\nSiberian Journal of Life Sciences and\
    \ Agriculture, Vol. 14, №6, 2022\ndifficult tasks (predictions and classification)\
    \ extraordinarily well and quick-\nly. DL’s main benefit is feature learning,\
    \ which includes extracting features \n(high-level information) from big datasets\
    \ automatically [45]. Long short term \nmemory (LSTM) networks, convolutional\
    \ neural networks (CNNs), recurrent \nneural (RNN) networks, generative adversarial\
    \ networks (GANs), radial basis \nfunction networks (RBFNs), multilayer perceptron\
    \ (MLPs), feed-forward ar-\ntificial neural network (ANN), self-organizing maps\
    \ (SOMs), deep belief net-\nworks (DBNs), restricted Boltzmann machines (RBMs),\
    \ and autoencoders are \nexamples of deep learning algorithms Various sites [46]\
    \ provide a full overview \nof these methods, popular architectures, and training\
    \ systems. DL algorithms \nare commonly used in agriculture to solve problems\
    \ related to computer vision \napplications that aim to predict key parameters\
    \ such as crop yields, soil mois-\nture content, weather conditions, and crop\
    \ growth conditions; detect diseases, \npests, and weeds; and identify leaf or\
    \ plant species [47]. Computer vision is an \ninterdisciplinary field that has\
    \ exploded in popularity in recent years thanks to \nthe rise of CNNs. It provides\
    \ methods and techniques for accurately process-\ning digital images and allowing\
    \ computers to analyze and comprehend the vi-\nsual world [48]. CNNs, generally\
    \ is known as Convet and its derivatives, are \nthe most widely used deep learning\
    \ algorithms in agricultural applications. \nRegion-based CNNs (RCNN), Fast-RCNN,\
    \ Faster-RCNN, YOLO, and Mask-\nRCNN are some of the CNN variants, with the first\
    \ four being the most typi-\ncally used to address object detection issues. On\
    \ the other side, Mask-RCNN \nis utilized to overcome instance segmentation issues.\
    \ The reader can find a \nthorough explanation of these algorithms and their applications\
    \ in the exist-\ning bibliography [47]. Other DL approaches have been employed\
    \ in a few re-\nsearch. When it comes to datasets, the majority of deep learning\
    \ models are \ntrained on photographs, with only a few trained on sensor data\
    \ collected in the \nfield. This demonstrates that DL can be used on a wide range\
    \ of datasets. It’s \nalso worth noting that the majority of the research is focused\
    \ on outdoor farms, \nwith next-generation farms (environment-controlled) receiving\
    \ less attention. \nThough digital farming has the potential to be enabled by\
    \ DL, most systems \nare still in the prototype stage. Furthermore, the additional\
    \ obstacles created \nby cyber-security and privacy concerns necessitate the improvement\
    \ of current \ndeep learning and computer vision technologies.\n4.8. Agricultural\
    \ decision support systems \nA decision support system (DSS) is a smart system\
    \ that assists stakehold-\ners and potential users in making decisions in response\
    \ to specific needs and \nchallenges by offering operational responses based on\
    \ meaningful informa-\n437\nSiberian Journal of Life Sciences and Agriculture,\
    \ Том 14, №6, 2022\ntion retrieved from raw data, documents, personal knowledge,\
    \ and/or models \n[49]. Data-driven, model-driven, communication-driven, document-driven,\
    \ and \nknowledge-driven DSS are all possibilities. The following source [50]\
    \ lists the \nkey features of these DSSs. The volume of farming data has exploded\
    \ as a re-\nsult of the advent of agriculture 4.0. Platforms like agricultural\
    \ decision support \nsystems (ADSS) are necessary to convert this heterogeneous\
    \ data into practical \nknowledge in order to make evidence-based and precise\
    \ judgments about farm \nmanagement and facility layout [51]. ADSSs have gotten\
    \ a lot of interest in the \nagriculture industry over the last few years. A variety\
    \ of agricultural concerns, \nsuch as farm management, water management, and environmental\
    \ management, \nhave been addressed by a number of ADSSs. Most ADSSs have been\
    \ found \nto ignore expert knowledge, which is extremely useful since it enables\
    \ for the \nconstruction of systems that are tailored to the demands of the users.\
    \ Complex \nGUIs, insufficient re-planning components, a lack of prediction and\
    \ forecasting \nabilities, and a lack of ability to adjust to unpredictable and\
    \ dynamic elements \nare some of the other identified faults with some of these\
    \ ADDSs. It’s also worth \nnoting that all of the ADSSs are for outside agriculture\
    \ systems and are still in \ndevelopment. In comparison, the use of ADSS in indoor\
    \ soilless agriculture is \ncurrently underutilized.\n4.9. Agricultural cyber-physical\
    \ systems \nA cyber-physical system (CPS) is an automated distributed system that\
    \ inte-\ngrates physical processes with communication networks and computing infra-\n\
    structures [52], and it is one of the key technologies of Industry 4.0. There\
    \ are \nthree standard CPS reference architecture models: 5C, RAMI 4.0, and IIRA,\
    \ \nwhich may be found in full at the following source [53]. Among these, the\
    \ 5C \nis a well-known and widely used reference model. CPS takes advantage of\
    \ a \nnumber of existing technologies, including agent systems, IoT, CC, augmented\
    \ \nreality, big data, and machine learning (ML) [54]. Scalability, flexibility,\
    \ au-\ntonomy, reliability, resilience, safety, and security are all improved\
    \ as a result \nof its adoption.\nOne of the most difficult domains that can benefit\
    \ from CPS technology is \nagriculture. Agricultural cyber-physical systems (ACPSs)\
    \ combine advanced \nelectronic technology with agricultural infrastructure to\
    \ create integrated farm \nmanagement systems that interact with the physical\
    \ environment to keep crops \ngrowing at their best [55]. ACPSs collect high-accuracy\
    \ data regarding climate, \nsoil, and crops and utilize it to manage watering,\
    \ humidity, and plant health, \namong other things. For the management of various\
    \ services, a range of ACPSs \nhave been created; however, most of these systems\
    \ are still in the prototype and \n438\nSiberian Journal of Life Sciences and\
    \ Agriculture, Vol. 14, №6, 2022\nconceptual stages. Furthermore, the majority\
    \ of studies are for outdoor farms, \nwith only a few publications published on\
    \ soil-based greenhouse systems. There \nhas been no research on indoor soilless\
    \ agricultural methods. Since of its pro-\nspective applications in a variety\
    \ of fields, ACPSs have sparked a lot of academ-\nic interest; nevertheless, deploying\
    \ CPS models in real-world applications is \nstill a difficulty because it requires\
    \ the right hardware and software [56]. When \ndesigning ACPSs, special emphasis\
    \ should be paid to autonomy, robustness, and \nresilience in order to deal with\
    \ the unpredictable nature of the environment and \nthe unknown characteristics\
    \ of agricultural facilities. ACPSs are influenced by \na variety of factors,\
    \ including humans, sensors, robots, crops, and data.. ACPSs \nmust be properly\
    \ and extensively developed to provide a seamless operation \nwhile avoiding conflicts,\
    \ errors, and disturbances.\n4.10. Digital twins in agriculture \nA digital twin\
    \ (DT) is a dynamic virtual replica of a real-life (physical) \nobject that mimics\
    \ its behaviours and states across multiple stages of the ob-\nject’s lifecycle\
    \ by combining real-world data, simulation, and machine learning \nmodels with\
    \ data analytics to enable understanding, learning, and reasoning \n[57]. The\
    \ physical and virtual entities, the physical and virtual environments, \nthe\
    \ metrology, and realization modules that perform the physical to virtual and\
    \ \nvirtual to physical connection or twinning, the twinning and twinning rate,\
    \ and \nthe physical and virtual processes are all required for a complete description\
    \ of \nthe DT concept for any physical system [58]. Because of advancements in\
    \ tech-\nnology such as the Internet of Things, big data, wireless sensor networks,\
    \ and \ncloud computing, the DT concept has gained traction. This is due to the\
    \ fact that \nthese technologies enable real-time monitoring of physical twins\
    \ at high spatial \nresolutions using both small devices and distant sensing,\
    \ which generate ev-\ner-increasing data streams [21]. In comparison to other\
    \ fields, the notion of DT \nin agricultural applications is relatively new, with\
    \ the first references appearing \nin 2017; as a result, its added value has not\
    \ yet been thoroughly studied [21]. \nBecause of its reliance on natural circumstances\
    \ (temperature, soil, humidity), \nas well as the presence of living and non-living\
    \ physical twins (plants and an-\nimals), framing is a very complex and dynamic\
    \ realm (indoor farm buildings, \ngrow beds, outdoor agricultural fields, agricultural\
    \ machinery). \nNon-living physical twins interact directly or indirectly with\
    \ plants and \nanimals (living physical twins), posing more obstacles for DT in\
    \ agriculture, \nwhereas non-living physical twins are the focus of DT in other\
    \ domains such \nas manufacturing. The majority of research has been on open-air\
    \ agricultur-\nal systems. There is just one study that proposes DT for a soil-based\
    \ vertical \n439\nSiberian Journal of Life Sciences and Agriculture, Том 14, №6,\
    \ 2022\nfarming system and one study that implements DT for a soilless vertical\
    \ farm-\ning system (aquaponics). This could be due to the difficulty of designing\
    \ and \nmanaging modern farming systems. Furthermore, the majority of DTs are\
    \ still \nin the research phase, with no commercial deployment planned. Cost savings,\
    \ \ndisaster prevention, clearer decision making, and efficient management oper-\n\
    ations are all reported benefits of DT applications in agriculture, which can\
    \ be \napplied to a variety of agricultural subfields such as plant and animal\
    \ breeding, \naquaponics, vertical farming, cropping systems, and livestock farming.\
    \ While \nDT technology offers a lot of promise, achieving synchronization between\
    \ the \nreal and digital worlds is difficult. Due to the quirks of living physical\
    \ twins, \nthe intricacy of this procedure is magnified in agricultural settings.\
    \ As a result, \nagricultural DT should begin with micro-farms, which can then\
    \ be gradually up-\ngraded to a more intelligent and autonomous form by adding\
    \ more components.\n4.11. Roadblocks in digitization of agriculture industry \n\
    This section outlines a series of interconnected hurdles to a wider adoption of\
    \ \ndigital technologies in agriculture. Following a review of the literature,\
    \ 21 barri-\ners were found, which were divided into technical and socioeconomic\
    \ categories.\n4.12. Technical roadblocks \n•Interoperability: Data is regarded\
    \ as a critical component in the success of \nsmart systems. Agricultural data\
    \ is typically gathered from a variety of sources, \nincluding thousands of individual\
    \ farmlands, animal industries, and business ap-\nplications. Data can be in a\
    \ variety of formats, making data integration difficult. \nAs a result, after\
    \ systematic data collection, storage, processing, and knowledge \nmining, data\
    \ interoperability is critical to increasing the value of this widely \ndistributed\
    \ data [59]. Interconnected and interoperable devices are also required \nfor\
    \ successful communication between heterogeneous devices. The system’s in-\nteroperability\
    \ can be improved through cross-technology communication [60].\n•Standardization:\
    \ Standardization of devices is required to fully use digital \ntechnologies for\
    \ smart farming applications. Differences in output can occur \nas a result of\
    \ misinterpretation and changes over time. Device, application, and \nsystem interoperability\
    \ concerns can also be overcome by standardization [25].\n•Data quality: Data\
    \ quality, as well as data security, storage, and openness, \nare essential for\
    \ producing meaningful outcomes. Another impediment to the \nadoption of smart\
    \ farming technologies is the lack of decentralized data man-\nagement systems\
    \ [9]. Multiple actors’ willingness to exchange farm data is be-\ning harmed as\
    \ a result of this problem.\n•Hardware implementation: It is incredibly difficult\
    \ to establish a smart agri-\ncultural setup in large-scale open areas. This is\
    \ due to the fact that all hardware, \n440\nSiberian Journal of Life Sciences\
    \ and Agriculture, Vol. 14, №6, 2022\nincluding IoT devices, wireless sensor networks,\
    \ sensor nodes, machinery, and \nequipment, is directly exposed to harsh environmental\
    \ conditions such as heavy \nrainfall, extreme temperatures, extreme humidity,\
    \ high wind speeds, and a vari-\nety of other dangers that can destroy electronic\
    \ circuits or disrupt their normal \nfunctionality [61]. A possible answer is\
    \ to construct a sturdy and lasting casing \nfor all of the expensive devices\
    \ that can withstand real-world conditions [62].\n•Adequate power sources: Typically,\
    \ wireless gadgets used on farms func-\ntion for an extended period of time and\
    \ have a limited battery life. \nBecause replacing a battery in the event of a\
    \ failure is difficult, especially in \nopen-air farms where devices are strategically\
    \ located with limited access [61], a \nproper energy-saving system is required.\
    \ Low-power sensors and proper commu-\nnication management are two viable strategies\
    \ for reducing energy consumption \n[24, 63]. Other intriguing technologies to\
    \ eliminate the need for battery renewal by \nrecharging batteries using electromagnetic\
    \ waves include wireless power transfer \nand self-supporting wireless systems.\
    \ In most agricultural applications, however, \nlong-distance wireless charging\
    \ is required [9]. Another potential alternative is to \ncapture ambient energy\
    \ from rivers, fluid flow, vehicle movement, and the ground \nsurface using sensor\
    \ nodes; however the converted electrical energy is current-\nly restricted, necessitating\
    \ the need to enhance power conversion efficiency [64].\n•Reliability: The dependability\
    \ of devices, as well as the software applica-\ntions that run on them, is critical.\
    \ This is due to the fact that IoT devices must \ncollect and transmit data from\
    \ which judgments are made utilizing a variety of \nsoftware packages. Unreliable\
    \ sensing, processing, and transmission can result \nin erroneous monitoring data\
    \ reports, significant delays, and even data loss, all \nof which can have a negative\
    \ impact on agricultural system performance [25].\n •Adaptability: Agriculture\
    \ is a complicated, dynamic, and continuously \nchanging environment. As a result,\
    \ when building a system, it is critical for de-\nvices and applications to react\
    \ proactively with other entities in the face of un-\nknown and dynamic elements\
    \ in order to provide the required performance [65].\n•Robust wireless architectures:\
    \ Low-cost, wide-area coverage, enough net-\nworking flexibility, and high scalability\
    \ are all advantages of wireless networks \nand communication technologies. However,\
    \ in a dynamic agriculture environ-\nment, such as temperature swings, the movement\
    \ of live objects, and the ex-\nistence of impediments, dependable wireless connection\
    \ is a major difficulty. \nFor example, multipath propagation effects cause signal\
    \ strength oscillations, \nresulting in unstable connectivity and insufficient\
    \ data transmission [66]. These \nelements have an impact on the agricultural\
    \ system’s performance. As a result, \nrobust and fault-tolerant wireless architectures\
    \ with proper sensor node place-\n441\nSiberian Journal of Life Sciences and Agriculture,\
    \ Том 14, №6, 2022\nment, antenna height, network topology, and communication\
    \ protocols are re-\nquired, as well as low-maintenance wireless systems [11].\n\
    •Interference: Because of the extensive deployment of IoT devices and wire-\n\
    less sensor networks, another difficulty is wireless interference and quality\
    \ of \nservice degradation. Effective channel scheduling between heterogeneous\
    \ sens-\ning devices, cognitive radio-assisted WSNs, and upcoming networking prim-\n\
    itives like concurrent transmission [67] can all help to solve these problems.\
    \ \nBecause agriculture equipment are dispersed in indoor greenhouses, outdoor\
    \ \nfarmlands, underground locations, and even aquatic areas, cross-media com-\n\
    munication between underground, underwater, and air is also necessary for full\
    \ \nintegration of smart technologies [68].\n•Security and privacy: Because smart\
    \ agricultural systems are dispersed, \nthey are vulnerable to cyber-attacks such\
    \ as eavesdropping, data integrity, de-\nnial-of-service assaults, and other sorts\
    \ of disruptions that could jeopardize the \nsystem’s privacy, integrity, and\
    \ availability [69]. With various privacy-preserv-\ning techniques and federated\
    \ learning approaches, cyber-security is a funda-\nmental concern that needs to\
    \ be addressed in the context of smart farming [44].\n•Compatibility: in order\
    \ to meet the fragmentation and scalability standards, \nthe models or software\
    \ applications developed must be adaptable and able to \nrun on any equipment\
    \ in the agricultural system [13]. \n•Resource optimization: To boost farm profitability,\
    \ farmers need a resource op-\ntimization procedure to determine the ideal number\
    \ of IoT devices and gateways, \ncloud storage size, and volume of transmitted\
    \ data. Resource optimization is diffi-\ncult since farms vary in size and require\
    \ different types of sensors to assess different \nvariables [70]. Second, most\
    \ farm management systems do not support run-time \nchanges to match the demands\
    \ of individual farmers. To estimate adequate resource \nallocation, complicated\
    \ mathematical models and algorithms are necessary [32].\n•Scalability: Due to\
    \ technological improvements, the number of gadgets, \ngear, and sensors put on\
    \ farms is continually expanding. \nGateways, network applications, and back-end\
    \ databases should all be de-\npendable and scalable in order to serve these entities\
    \ [71].\n•Human-centered user interfaces: Existing agricultural software and gadgets\
    \ \nhave complicated user interfaces, which are limiting smart farming methods.\
    \ \nThe majority of graphical user interfaces are constructed in such a way that\
    \ \nonly specialists can use them to accomplish agricultural activities. By making\
    \ \nthe user interface more human-centered and providing multimodal feedback,\
    \ a \nbigger group of individuals will be able to use it to complete various agricul-\n\
    tural tasks [35].\n442\nSiberian Journal of Life Sciences and Agriculture, Vol.\
    \ 14, №6, 2022\n4.13. Socio-economic roadblocks \n•Gap between farmers and researchers:\
    \ Farmers’ engagement is critical to \nthe success of the agriculture industry’s\
    \ digitization. Agricultural specialists are \nfrequently unaware of the concerns\
    \ that farmers encounter during the agri-food \nproduction process, which smart\
    \ technologies could solve [16]. Furthermore, it \nis critical to completely comprehend\
    \ the nature of problems in order to create \nan appropriate smart solution. \n\
    As a result, bridging the gap between farmers, agricultural professionals, \n\
    and AI researchers is critical.\n•Expenses connected with smart systems: the costs\
    \ associated with adopt-\ning smart technology and systems are a major impediment\
    \ to the agriculture \nsector’s digitization. These expenses typically include\
    \ deployment, operation, \nand maintenance. Smart system deployment costs are\
    \ typically significant since \nthey include: I hardware installation, such as\
    \ autonomous robots and drones, \nWSNs, gateways, and base station infrastructure,\
    \ and ii) paying trained labour \nto do particular agricultural tasks [72]. Similarly,\
    \ subscriptions to centralized \nnetworks and software packages are necessary\
    \ to support data processing, con-\ntrol of IoT devices and equipment, and knowledge\
    \ exchange, which eventually \nraises operating expenses [73]. Even if service\
    \ providers occasionally provide \nfree subscription packages with limited capabilities,\
    \ storage capacity is limited. \nPeriodic maintenance is essential to ensure the\
    \ proper operation of the smart \nsystem, which adds to the total costs.\nEnvironmental,\
    \ ethical, and societal costs may also be connected with the \nadoption of smart\
    \ devices. Initiatives focusing on cooperative farming are need-\ned to overcome\
    \ cost-related roadblocks by providing: I support services for \nbetter cost management\
    \ and needed investments, and ii) hardware solutions to \ntransform conventional\
    \ equipment into smart farm-ready machinery to reduce \nhigh initial costs [73].\n\
    •Digital division: a lack of awareness of digital technology and their appli-\n\
    cations is another problem limiting the digitalization of the agriculture sector.\
    \ \nThe majority of farmers have no understanding what digital technologies are,\
    \ \nhow to install and utilize them, or which technology is appropriate for their\
    \ farm \nand matches their needs [14]. As a result, farmers must be educated on\
    \ current \nfarming technologies and processes. \nFurthermore, various tactics\
    \ are required to develop tools that use natural \nlanguage and are easily understood\
    \ by farmers with low levels of education [74]. \n•Return on investment: In agriculture,\
    \ like in other industries, the profit \nmargin is critical. When it comes to\
    \ implementing modern technologies, farm-\n443\nSiberian Journal of Life Sciences\
    \ and Agriculture, Том 14, №6, 2022\ners are concerned about the time it will\
    \ take to recoup their investment and the \ndifficulty in assessing the benefits\
    \ [12].\n•Building faith in the effectiveness of smart technology in agriculture\
    \ is \ndifficult, unlike in other disciplines, because many decisions influence\
    \ systems \nthat involve both living and non-living elements, and the results\
    \ can be difficult \nto reverse [16]. In addition, the lack of verification of\
    \ the influence of digital \ntools on farm productivity exacerbates the current\
    \ difficulties.\n•Legal frameworks: different regions and nations have distinct\
    \ legal frame-\nworks that influence the deployment of digital technologies in\
    \ agriculture, par-\nticularly in monitoring and agri-food supply [31]. Similarly,\
    \ laws governing \nresource allocation (spectrum for wireless devices), data privacy,\
    \ and security \ndiffer from country to country [31].\n•Connectivity infrastructure:\
    \ In most developing nations, connectivity in-\nfrastructure is poor, limiting\
    \ access to advanced digital technologies that could \nhelp turn data from disparate\
    \ sources into useful and actionable insights [10].\n4.14. Discussion \nThe goal\
    \ of this study was to describe the new digital technologies that are \nbeing\
    \ used in the agricultural industry in order to predict the future trajectories\
    \ \nof agriculture 4.0. Big data and analytics, wireless sensor networks, cyber-phys-\n\
    ical systems, and digital twins are among the technologies that have yet to be\
    \ \nfully explored in agriculture. This disparity could be due to the fact that\
    \ install-\ning advanced technologies with more complex processes can be costly,\
    \ at least \nin the early stages of their acceptance. The agricultural industry’s\
    \ development \nof these technologies is expected to speed up in the next years.\
    \ The findings of \nSLR also reveal that IoT is widely used in farms. This is\
    \ owing to the IoT’s di-\nverse capabilities, which include monitoring, tracking,\
    \ and tracing, agricultural \nmachinery, and precision agriculture [21]. One of\
    \ the key research aims within \nthe farm 4.0 techniques can be regarded to be\
    \ IoT. Nonetheless, when building \nan intelligent agricultural system, only a\
    \ few researches have examined data \nsecurity and dependability, scalability,\
    \ and interoperability. The outcomes of \nthe study also revealed that the majority\
    \ of use cases are still in the prototype \nstage. The reason for this could be\
    \ that most agricultural activities involve live \nsubjects, such as animals and\
    \ plants, or perishable products, and establish-\ning systems for living subjects\
    \ is more difficult than developing systems for \nnon-living human-made systems.\
    \ Another explanation could be that, due to the \ntrans-disciplinary character\
    \ of agriculture, it is a late adopter of technology. As a \nresult, in order\
    \ to construct intelligent systems, the agricultural community must \nbecome conversant\
    \ with all digital technologies. Finally, differences in plant/\n444\nSiberian\
    \ Journal of Life Sciences and Agriculture, Vol. 14, №6, 2022\ncrop species and\
    \ growth conditions complicate agricultural system digitaliza-\ntion [55]. In\
    \ contrast to indoor farms, the majority of the technologies created \nby SLR\
    \ are for open-air soil-based farms (soilless and soil-based). This is owing \n\
    to the complicated design and maintenance of indoor farms, particularly soilless\
    \ \nfarms, where the parameters and elements to be maintained are numerous (pH,\
    \ \nair temperature, humidity, etc.) [5]. However, by incorporating digital technol-\n\
    ogy and data-driven computer applications into indoor farms, a more reliable \n\
    control of the process can be attained. Furthermore, SLR reveals that insufficient\
    \ \nresearch is undertaken in three of the nine service areas described in section\
    \ 3 \n(soil management, fruit detection and counting, and crop quality management).\
    \ \nThis supports the notion that significant research and development is required\
    \ \nin some areas to ensure the successful digitization of the agriculture business\
    \ \nin both developed and developing countries. The agriculture ecosystem’s com-\n\
    plexity creates a set of interrelated hurdles that prevent full integration of\
    \ digital \ntechnology for agriculture 4.0 implementation. As a result, identifying\
    \ possible \nbottlenecks is critical in order to devise strategic strategies to\
    \ overcome them. \nThis research aims to figure out what these stumbling barriers\
    \ are. Following \nthe investigation, 21 barriers were found and characterized\
    \ on both a technical \nand socioeconomic level. These impediments are addressed\
    \ in section 5, which \noutlines what needs to be done on a bigger scale to digitize\
    \ the agricultural \neconomy. However, it is still unknown how much removing or\
    \ mitigating these \nhurdles aids in the successful integration of digital technologies.\
    \ \n4.16. Added value of agricultural digitization \nSeveral benefits that can\
    \ inspire framers and other actors to assist agriculture \nindustry digitization\
    \ have been discovered and outlined based on analysis. The \nbenefits described\
    \ here have the potential to increase farm productivity and im-\nprove product\
    \ quality, but they should not be viewed as a cure for the problems \nthat come\
    \ with smart agriculture [73]. \n•Improved agility: Farm operations can now be\
    \ more agile thanks to digital \ntechnologies. Farmers and agricultural professionals\
    \ can quickly respond to \nany anticipated changes in environmental and water\
    \ conditions using real-time \nsurveillance and forecasting technologies to save\
    \ crops [72].\n•Green process: By lowering the use of in-field fuel, nitrogen\
    \ fertilizers, \npesticides, and herbicides, digital technologies make farming\
    \ more ecologically \nfriendly and climate-resilient [75].\n•Resource efficiency:\
    \ By increasing the quantity and quality of agricultural \noutput while reducing\
    \ the use of water, energy, fertilizers, and pesticides, digital \nplatforms can\
    \ improve resource efficiency [3]. \n445\nSiberian Journal of Life Sciences and\
    \ Agriculture, Том 14, №6, 2022\n•Time and cost savings: By automating various\
    \ tasks such as harvesting, sow-\ning, or irrigation, managing the application\
    \ of fertilizers or pesticides, and sched-\nuling irrigation, digital technologies\
    \ provide significant time and cost savings [76].\n•Asset management: digital\
    \ technologies enable real-time observation of \nfarm holdings and equipment,\
    \ allowing for theft prevention, component re-\nplacement, and routine maintenance\
    \ [10].\n•Product safety: By eliminating fraud [17, 18] linked to adulteration,\
    \ coun-\nterfeiting, and artificial enhancement, digital technologies maintain\
    \ appropriate \nfarm output and ensure a safe and nutritious supply of agri-food\
    \ products [69].\n4.17. Considerations and future prospects \nThe agricultural\
    \ industry would see major benefits as a result of the planned \nmeasures. However,\
    \ the impediments identified in section 5 must be solved first \nin order to make\
    \ things sustainable for small and medium-scale growers. Some \nof the above hurdles\
    \ can be mitigated by awareness campaigns emphasizing the \nimportance of smart\
    \ agriculture at every level of the agricultural value chain and \nencouraging\
    \ novel techniques (such as gamification) to encourage stakeholders \nto take\
    \ an active role in the digital transformation [9]. Initiatives at the federal\
    \ \nlevel, grants and endowments, public-private collaborations, data transparency,\
    \ \nand regional research efforts can all help overcome potential hurdles. Finally,\
    \ \nwhen constructing a smart agriculture system, a roadmap can be used, starting\
    \ \nwith a basic architecture with few components and simpler functionality and\
    \ \ngradually adding components and functionality to develop a sophisticated sys-\n\
    tem with full digitization potential [21]. These issues can pave the road for\
    \ ag-\nriculture 4.0’s successful adoption. The use of explainable artificial\
    \ intelligence \nto monitor crop development, estimate crop biomass, evaluate\
    \ crop health, and \ncontrol pests and diseases is one of the future prospects\
    \ of digital technologies \nin smart agriculture. Explainable AI eliminates the\
    \ old black-box approach of \nmachine learning and allows for a better understanding\
    \ of the reasoning behind \nany given decision [15]. The use of common semantics\
    \ and ontologies to de-\nscribe big data, as well as the adoption of open standards,\
    \ has the potential to \naccelerate research and development in the field of smart\
    \ farming. Similarly, \n5G technology must be thoroughly investigated in order\
    \ to enable improved \nconnectivity and live streaming of crop data [6]. By executing\
    \ precise crop in-\nspections remotely, 5G technology will reduce internet costs\
    \ and enhance the \nentire user experience of farm management and food safety\
    \ [77]. It would also \nhelp to close the gap between stakeholders by keeping\
    \ them informed about \ncrop availability. Finally, blockchain can be used in\
    \ conjunction with IoT and \nother technologies to address data privacy and security\
    \ concerns [78]. \n446\nSiberian Journal of Life Sciences and Agriculture, Vol.\
    \ 14, №6, 2022\n4.18. Transition to Agriculture 5.0 \nThe agriculture sector has\
    \ traditionally had a breakthrough during industri-\nal revolutions. Agriculture\
    \ 4.0 offers significant potential to offset rising food \ndemands and prepare\
    \ for the future by reinforcing agricultural systems with \nWSN, IoT, AI, and\
    \ other technologies, as formally mentioned in preceding \nsections. While agricultural\
    \ 4.0 is still being implemented, agriculture 5.0 is \nalready being discussed.\
    \ \nAgriculture 5.0 builds on agriculture 4.0 by incorporating industry 5.0 prin-\n\
    ciples to provide healthy, affordable food while also ensuring that the environ-\n\
    ments on which life depends are not degraded [79]. Industry 4.0 focuses less \n\
    on the original principles of social fairness and sustainability and more on dig-\n\
    italization and AI-driven technologies for increasing efficiency and flexibility,\
    \ \nthe European Commission formally called for the Fifth Industrial Revolution\
    \ \n(industry 5.0) in 2021 [80]. Industry 5.0 adds to and expands on the industry\
    \ 4.0 \nconcepts by emphasizing human-centricity, sustainability, and resiliency\
    \ [81]. \nIt entails improving human-machine collaboration, decreasing environmental\
    \ \neffect through the circular economy, and designing systems with a high degree\
    \ \nof robustness to reach an ideal balance of efficiency and productivity. Among\
    \ \nthe enabling technologies of industry are cobots (collaborative robots), smart\
    \ \nmaterials with embedded bio-inspired sensors, digital twins, AI, energy efficient\
    \ \nand secure data management, renewable energy sources, and others 5.0[80].\n\
    Farm production efficiency and crop quality can be improved in agriculture \n\
    5.0 settings by delegating repetitive and boring activities to machines and those\
    \ \nthat need critical thinking to humans. For this reason, agricultural cyber\
    \ physical \ncognitive systems (CPCS) that observe/study the environment and conduct\
    \ ap-\npropriate actions, comparable to those established for the manufacturing\
    \ sector, \nshould be developed. This might include collaborative farm robots\
    \ that work in \nthe fields to aid crop growers with time-consuming operations\
    \ like seed sowing \nand harvesting. Similarly, digital twins in agriculture 5.0\
    \ can add substantial value \nby recognizing technical difficulties in agricultural\
    \ systems and resolving them \nmore quickly, detecting crop illnesses, and producing\
    \ more accurate crop output \nestimates. This demonstrates that agriculture 5.0\
    \ has the potential to pave the way \nfor climate-smart, sustainable, and resilient\
    \ agriculture, but it is still in its infancy. \n5. Conclusions \nConcerns about\
    \ global food security have heightened the demand for \nnext-generation industrial\
    \ farms and agricultural intensive production systems. \nDigital technologies,\
    \ such as those given by the Industry 4.0 programme, are at \n447\nSiberian Journal\
    \ of Life Sciences and Agriculture, Том 14, №6, 2022\nthe vanguard of this modern\
    \ agricultural period, providing a wide range of in-\nnovative solutions. Disruptive\
    \ technologies are being integrated into traditional \nagriculture systems by\
    \ scientists and researchers in order to boost crop yields, \ncut costs, reduce\
    \ waste, and sustain process inputs. This report includes an SLR \nthat discusses\
    \ the current state of various technologies in the agriculture sector. \nSeveral\
    \ findings are drawn, including the fact that big data and analytics inte-\ngration,\
    \ wireless sensor networks, cyber-physical systems, and digital twins in \nagriculture\
    \ are still in their infancy, with the majority of use cases still in the \nprototype\
    \ stage. Similarly, 21 technological and socioeconomic impediments \nare found\
    \ and categorized. These impediments must be identified and addressed \nif the\
    \ agriculture industry is to be digitalized. The report also identifies and \n\
    presents the additional value of digital technology in the agriculture industry.\
    \ \nOverall, this research contributes to the ongoing research on agricultural\
    \ 4.0. \nThe review’s principal restriction is twofold: first, only three online\
    \ reposito-\nries (Scopus, IEEE, and Science Direct) are considered for literature\
    \ searches, \nand second, new keywords and synonyms may return more papers. The\
    \ main \nconclusions are highly unlikely to alter in either scenario. Additional\
    \ research \ndatabases and areas can be considered for future study in order to\
    \ provide a \ncomplete overview of the agriculture industry in terms of digitization.\
    \ In addi-\ntion, papers focusing on agriculture 5.0 in general will be featured.\n\
    References\n1. F Schierhorn, M. Elferink, Global Demand for Food Is Rising. Can\
    \ We Meet \nIt? Harv Bus Rev, 2016, 7 (2017). https://hbr.org/2016/04/global-demand-for-\n\
    food-is-rising-can-we-meet-it\n2. Singh, G. Machine Learning Models in Stock Market\
    \ Prediction. International \nJournal of Innovative Technology and Exploring Engineering,\
    \ 2022, vol. 11, \nno. 3, pp. 18-28. https://doi.org/10.35940/ijitee.C9733.0111322\n\
    3. WK Mok, YX Tan, WN. Chen, Technology innovations for food security in \nSingapore:\
    \ A case study of future food systems for an increasingly natural re-\nsource-scarce\
    \ world, Trends Food Sci Technol, 2020, vol. 102, pp. 155–168, \nhttps://doi.org/10.1016/j.tifs.2020.06.013\n\
    4. Nagar, P., & Issar, G. S. Detection of outliers in stock market using regression\
    \ \nanalysis. International Journal of Emerging Technologies in Computational\
    \ and \nApplied Science, 2013. https://doi.org/10.5281/zenodo.6047417\n5. R Abbasi,\
    \ P Martinez, R. Ahmad, An ontology model to represent aquapon-\nics 4.0 system’s\
    \ knowledge, Inf Process Agric, 2021. https://doi.org/10.1016/J.\nINPA.2021.12.001\n\
    448\nSiberian Journal of Life Sciences and Agriculture, Vol. 14, №6, 2022\n6.\
    \ R Abbasi, P Martinez, R. Ahmad, An ontology model to support the automat-\n\
    ed design of aquaponic grow beds, Procedia CIRP, 2021, vol. 100, pp. 55–60, \n\
    https://doi.org/10.1016/j.procir.2021.05.009\n7. G Aceto, V Persico, A. Pescapé,\
    \ A Survey on Information and Communication \nTech- nologies for Industry 4.0:\
    \ State-of-the-Art, Taxonomies, Perspectives, \nand Challenges, IEEE Commun Surv\
    \ Tutorials, 2019. https://doi.org/10.1109/\nCOMST.2019.2938259\n8. B. Ozdogan,\
    \ A. Gacar, H. Aktas. Digital agriculture practices in the context of \nagriculture\
    \ 4.0. Journal of Economics, Finance and Accounting (JEFA), 2017, \nvol. 4, iss.\
    \ 2, pp. 184-191. https://doi.org/10.17261/pressacademia.2017.448\n9. Y Liu, X\
    \ Ma, L Shu, GP Hancke, AM. Abu-Mahfouz, From Industry 4.0 to Ag-\nriculture 4.0:\
    \ Current Status, Enabling Technologies, and Research Challenges, \nIEEE Trans\
    \ Ind Informatics, 2021, vol. 17, no. 6, pp. 4322-4334. https://doi.\norg/10.1109/TII.2020.3003910\n\
    10. F da Silveira, FH Lermen, FG. Amaral, An overview of agriculture 4.0 devel-\n\
    opment: Systematic review of descriptions, technologies, barriers, advantag-\n\
    es, and disadvantages, Comput Electron Agric 189 (2021) 106405, https://doi.\n\
    org/10.1016/J.COMPAG.2021.106405\n11. G Idoje, T Dagiuklas, M. Iqbal, Survey for\
    \ smart farming technologies: Chal-\nlenges and issues, Comput Electr Eng, 2021,\
    \ vol. 92, 107104. https://doi.\norg/10.1016/J.COMPELECENG.2021.107104\n12. J\
    \ Miranda, P Ponce, A Molina, P. Wright, Sensing, smart and sustain- able tech-\n\
    nologies for Agri-Food 4.0, Comput Ind, 2019, vol. 108, pp. 21–36. https://doi.\n\
    org/10.1016/J.COMPIND.2019.02.002 \n13. M Lezoche, H Panetto, J Kacprzyk, JE Hernandez,\
    \ Alemany Díaz MME. \nAgri-food 4.0: A survey of the supply chains and technologies\
    \ for the future \nagriculture, Comput Ind, 2020, vol. 117, 103187. https://doi.org/10.1016/J.\n\
    COMPIND.2020.103187\n14. Bhakta I, Phadikar S, Majumder K. State-of-the-art technologies\
    \ in precision \nagriculture: a systematic review. Journal of the Science of Food\
    \ and Agriculture, \n2019, vol. 99, no. 11. pp. 4878-4888. https://doi.org/10.1002/jsfa.9693\n\
    15. SO Araújo, RS Peres, J Barata, F Lidon, JC. Ramalho, Characterising the \n\
    Agriculture 4.0 Landscape — Emerging Trends, Challenges and Opportu-\nnities,\
    \ Agron, 2021, vol. 11, no. 4, 667. https://doi.org/10.3390/AGRONO-\nMY11040667\n\
    16. M Bacco, P Barsocchi, E Ferro, A Gotta, M. Ruggeri, The Digitisation of Agri-\n\
    culture: a Survey of Research Activities on Smart Farming, Array, 2019, 3–4, \n\
    100009. https://doi.org/10.1016/j.array.2019.100009\n449\nSiberian Journal of\
    \ Life Sciences and Agriculture, Том 14, №6, 2022\n17. Singh, G., & Nager, P.\
    \ A case Study on Nutek India Limited Regarding Deep \nFalling in Share Price.\
    \ Researchers World - Journal of Arts, Science & Com-\nmerce, 2012, vol. 3(2),\
    \ 3.\n18. Nager, P., & Singh, G. An Analysis of Outliers For Fraud Detection in\
    \ Indian \nStock Market. Researchers World - Journal of Arts, Science & Commerce,\
    \ 2012, \nvol. 3(4), 4.\n19. MJ Page, JE McKenzie, PM Bossuyt, I Boutron, TC Hoffmann,\
    \ CD Mulrow, et \nal., The PRISMA 2020 statement: An updated guideline for reporting\
    \ systematic \nreviews, BMJ, 2021, 372. https://doi.org/10.1136/BMJ.N71\n20. Ahmed\
    \ MA, Ahsan I, Abbas M. Systematic Literature Review: Ingenious \nSoftware Project\
    \ Management while narrowing the impact aspect. RACS ‘16: \nProceedings of the\
    \ International Conference on Research in Adaptive and Con-\nvergent Systems,\
    \ 2016, pp. 165–168. https://doi.org/10.1145/2987386.2987422\n21. C Pylianidis,\
    \ S Osinga, IN. Athanasiadis, Introducing digital twins to agricul-\nture, Comput\
    \ Electron Agric 184 (2021) 105942, https://doi.org/10.1016/J.\nCOMPAG.2020.105942\
    \ \n22. Shaikh ZA Aqeel-ur-Rehman, NA Shaikh, N Islam, An integrated framework\
    \ \nto de- velop context aware sensor grid for agriculture, Aust J Basic Appl\
    \ Sci, \n2010. \n23. W Shi, J Cao, Q Zhang, Y Li, L. Xu, Edge Computing: Vision\
    \ and Chal-\nlenges, IEEE Internet Things J 3, 2016, 637–646, https://doi.org/10.1109/\n\
    JIOT.2016.2579198\n24. A Tzounis, N Katsoulas, T Bartzanas, C. Kittas, Internet\
    \ of Things in agricul- \nture, recent advances and future challenges, Biosyst\
    \ Eng, 164, 2017, 31–48, \nhttps://doi.org/10.1016/J.BIOSYSTEMSENG.2017.09.007\n\
    25. VP Kour, S. Arora, Recent Developments of the Internet of Things in Agri-\
    \ cul-\nture: A Survey, IEEE Access 8, 2020, 129924–129957, https://doi.org/10.1109/\n\
    AC- CESS.2020.3009298\n26. MU Aftab, O Ashraf, M Irfan, M Majid, A Nisar, MA.\
    \ Habib, A Review Study \nof Wireless Sensor Networks and Its Security, Commun\
    \ Netw, 7, 2015, 172–179, \nhttps://doi.org/10.4236/cn.2015.74016\n27. X Yu, P\
    \ Wu, W Han, Z. Zhang, A survey on wireless sensor network infra-\nstructure for\
    \ agriculture, Comput Stand Interfaces, 1, 2013, 59–64, https://doi.\norg/10.1016/J.CSI.2012.05.001\n\
    28. Mell PM, Grance T. The NIST definition of cloud computing, 2011. https://doi.\n\
    org/10.6028/NIST.SP.800-145\n29. Alwada’n T. Cloud computing and multi-agent system:\
    \ monitoring and services. \n2018. \n450\nSiberian Journal of Life Sciences and\
    \ Agriculture, Vol. 14, №6, 2022\n30. X Shi, X An, Q Zhao, H Liu, L Xia, X Sun,\
    \ et al., State-of-the-art inter- net of \nthings in protected agriculture, Sensors\
    \ (Switzerland), 19, 2019, 1833, https://\ndoi.org/10.3390/s19081833\n31. J Wang,\
    \ H Yue, Z. Zhou, An improved traceability system for food quality assur-\nance\
    \ and evaluation based on fuzzy classification and neural network, Food Con-\n\
    trol, 79, 2017, 363–370, https://doi.org/10.1016/J.FOODCONT.2017.04.013\n32. S\
    \ Fountas, G Carli, CG Sørensen, Z Tsiropoulos, C Cavalaris, A Vatsanidou, et\
    \ \nal., Farm management information systems: Current situation and future per-\n\
    spectives, Comput Electron Agric, 115, 2015, 40–50, https://doi.org/10.1016/J.\n\
    COMPAG.2015.05.011\n33. A Bechar, C. Vigneault, Agricultural robots for field\
    \ operations: Concepts and \ncomponents, Biosyst Eng, 149, 2016, 94–111, https://doi.org/10.1016/J.BIO-\n\
    SYSTEMSENG.2016.06.014\n34. Gonzalez-De-Santos P, Fernández R, Sepúlveda D, Navas\
    \ E, Armada M. Un- \nmanned Ground Vehicles for Smart Farms. Agron - Clim Chang\
    \ Food Secur, \n2020. https://doi.org/10.5772/INTECHOPEN.90683\n35. J del Cerro,\
    \ CC Ulloa, A Barrientos, L. Rivas J de, Unmanned Aerial Vehicles in \nAgri- culture:\
    \ A Survey, Agron, 11, 2021, 203, https://doi.org/10.3390/AGRON-\nOMY11020203\n\
    36. Patel PN, Patel M, Faldu RM, Dave YR. Quadcopter for Agricultural Surveil-\n\
    lance, 2013.\n37. Sylvester G, Food and Agriculture Organization of the United\
    \ Nations., International \nTelecommunication Union. E-agriculture in action:\
    \ drones for agriculture n.d.:112. \n38. U Sivarajah, MM Kamal, Z Irani, V. Weerakkody,\
    \ Critical analysis of Big Data \nchallenges and analytical methods, J Bus Res,\
    \ 70, 2017, 263–286, https://doi.\norg/10.1016/J.JBUSRES.2016.08.001\n39. M Chi,\
    \ A Plaza, JA Benediktsson, Z Sun, J Shen, Y. Zhu, Big Data for Re- \nmote Sensing:\
    \ Challenges and Opportunities, Proc IEEE, 104, 2016, 2207–2219, \nhttps://doi.org/10.1109/JPROC.2016.2598228\
    \ \n40. K Tesfaye, K Sonder, J Caims, C Magorokosho, A Tarekegn, GT Kassie, et\
    \ al. \nTarget- ing drought-tolerant maize varieties in southern Africa: a geospatial\
    \ crop \nmodeling approach using big data, Int Food Agribus Manag Rev, 19, 2016.\
    \ \n41. R Sharma, SS Kamble, A Gunasekaran, V Kumar, A. Kumar, A system- atic\
    \ \nliterature review on machine learning applications for sustainable agri- culture\
    \ \nsupply chain performance, Comput Oper Res, 119, 2020, 104926, https://doi.\n\
    org/10.1016/J.COR.2020.104926\n42. T Talaviya, D Shah, N Patel, H Yagnik, M. Shah,\
    \ Implementation of artifi-\ncial intelli- gence in agriculture for optimisation\
    \ of irrigation and application \n451\nSiberian Journal of Life Sciences and Agriculture,\
    \ Том 14, №6, 2022\nof pesticides and herbicides, Artif Intell Agric, 4, 2020,\
    \ 58–73, https://doi.\norg/10.1016/J.AIIA.2020.04.002\n43. KG Liakos, P Busato,\
    \ D Moshou, S Pearson, D. Bochtis, Machine Learn- ing in \nAgriculture: A Review,\
    \ Sensors, 18, 2018, 2674, https://doi.org/10.3390/S18082674\n44. G Xu, H Li,\
    \ S Liu, K Yang, X. Lin, VerifyNet: Secure and Verifiable Federat-\ned Learning,\
    \ IEEE Trans Inf Forensics Secur, 15, 2020, 911–926, https://doi.\norg/10.1109/TIFS.2019.2929409\n\
    45. J. Schmidhuber, Deep Learning in Neural Networks: An Overview, Neural Net-\n\
    works, 61, 2014, 85–117, https://doi.org/10.1016/j.neunet.2014.09.003 \n46. Canziani\
    \ A, Paszke A, Culurciello E. An Analysis of Deep Neural Network \nModels for\
    \ Practical Applications, 2016. \n47. A Kamilaris, FX. Prenafeta-Boldu, Deep learning\
    \ in agriculture: A survey, \nComput Electron Agric, 147, 2018, 70–90, https://doi.org/10.1016/j.com-\n\
    pag.2018.02.016\n48. V Kakani, VH Nguyen, BP Kumar, H Kim, VR. Pasupuleti, A critical\
    \ review on \ncomputer vision and artificial intelligence in food industry, J\
    \ Agric Food Res, 2, \n2020, https://doi.org/10.1016/J.JAFR.2020.100033\n49. F\
    \ Terribile, A Agrillo, A Bonfante, G Buscemi, M Colandrea, A D’Antonio, et al.,\
    \ A \nWeb-based spatial decision supporting system for land management and soil\
    \ con-\nservation, Solid Earth 6 (2015) 903–928, https://doi.org/10.5194/SE-6-903-2015\n\
    50. A Felsberger, B Oberegger, G. Reiner, A Review of Decision Support Systems\
    \ \nfor Manufacturing Systems, Undefined, 2016. \n51. P Taechatanasat, L. Armstrong,\
    \ Decision Support System Data for Farmer De-\ncision Making, ECU Publ Post (2013)\
    \ 2014 . \n52. L Wang, M Törngren, M. Onori, Current status and advancement of\
    \ cyber- phys-\nical systems in manufacturing, J Manuf Syst, 37, 2015), 517–527,\
    \ https://doi.\norg/10.1016/J.JMSY.2015.04.008\n53. DGS Pivoto, LFF de Almeida,\
    \ R da Rosa Righi, JJPC Rodrigues, AB Lugli, \nAM. Al- berti, Cyber-physical systems\
    \ architectures for industrial internet of \nthings appli- cations in Industry\
    \ 4.0: A literature review, J Manuf Syst, 58, 2021, \n176–192, https://doi.org/10.1016/J.JMSY.2020.11.017\n\
    54. AF Jimenez, PF Cardenas, F Jimenez, A Canales, A. López, A cyber-physical\
    \ in-\ntelli- gent agent for irrigation scheduling in horticultural crops, Comput\
    \ Electron \nAgric, 178, 2020, 105777, https://doi.org/10.1016/J.COMPAG.2020.105777\n\
    55. A Selmani, H Oubehar, M Outanoute, A Ed-Dahhak, M Guerbaoui, A Lach- hab,\
    \ \net al., Agricultural cyber-physical system enabled for remote management of\
    \ \nsolar-powered precision irrigation, Biosyst Eng, 177, 2019, 18–30, https://doi.\n\
    org/10.1016/J.BIOSYSTEMSENG.2018.06.007\n452\nSiberian Journal of Life Sciences\
    \ and Agriculture, Vol. 14, №6, 2022\n56. A Nayak, RR Levalle, S Lee, SY. Nof,\
    \ Resource sharing in cyber-physical sys-\ntems: modelling framework and case\
    \ studies, 54, 2016, 6969–6983, https://doi.\norg/10.1080/00207543.2016.1146419\n\
    57. C Verdouw, B Tekinerdogan, A Beulens, S. Wolfert, Digital twins in smart farming,\
    \ \nAgric Syst, 189, 2021, 103046, https://doi.org/10.1016/J.AGSY.2020.103046\n\
    58. D Jones, C Snider, A Nassehi, J Yon, B Hicks, Characterising the Digital Twin:\
    \ \nA systematic literature review, CIRP J Manuf Sci Technol, 29, 2020, 36–52,\
    \ \nhttps://doi.org/10.1016/J.CIRPJ.2020.02.002\n59. S Aydin, MN. Aydin, Semantic\
    \ and syntactic interoperability for agricultural \nopen- data platforms in the\
    \ context of IoT using crop-specific trait ontologies, \nAppl Sci, 10, 2020, https://doi.org/10.3390/app10134460\n\
    60. Y He, J Guo, X. Zheng, From Surveillance to Digital Twin: Challenges and Re-\n\
    cent Advances of Signal Processing for Industrial Internet of Things, IEEE Signal\
    \ \nProcess Mag, 35, 2018, 120–129, https://doi.org/10.1109/MSP.2018.2842228\n\
    61. MS Farooq, S Riaz, A Abid, K Abid, MA. Naeem, A Survey on the Role of IoT\
    \ \nin Agriculture for the Implementation of Smart Farming, IEEE Access, 7, 2019,\
    \ \n156237–156271, https://doi.org/10.1109/ACCESS.2019.2949703\n62. A Villa-Henriksen,\
    \ GTC Edwards, LA Pesonen, O Green, CAG. Sørensen, In-\nternet of Things in arable\
    \ farming: Implementation, applications, challenges and \npotential, Biosyst Eng,\
    \ 191, 2020, 60–84, https://doi.org/10.1016/J.BIOSYSTE-\nMSENG.2019.12.013\n63.\
    \ HM Jawad, R Nordin, SK Gharghan, AM Jawad, M. Ismail, Energy-efficient \nwire-\
    \ less sensor networks for precision agriculture: A review, Sensors (Swit-\nzerland),\
    \ 17, 2017, 1781, https://doi.org/10.3390/s17081781\n64. L Sigrist, N Stricker,\
    \ D Bernath, J Beutel, L. Thiele, Thermoelectric Energy \nHarvesting from Gradients\
    \ in the Earth Surface, IEEE Trans Ind Electron, 67, \n2020, 9460–9470, https://doi.org/10.1109/TIE.2019.2952796\n\
    65. AR Yanes, P Martinez, R. Ahmad, Towards automated aquaponics: A re-\nview\
    \ on monitoring, IoT, and smart systems, J Clean Prod, 2020, https://doi.\norg/10.1016/j.jclepro.2020.121571\n\
    66. N Brinis, LA. Saidane, Context Aware Wireless Sensor Network Suitable \nfor\
    \ Preci- sion Agriculture, Wirel Sens Netw, 2016, https://doi.org/10.4236/\nwsn.2016.81001\n\
    67. M Zimmerling, L Mottola, S. Santini, Synchronous Transmissions in Low-Pow-\n\
    er Wireless: A Survey of Communication Protocols and Network Services, ACM \n\
    Comput Surv, 53 2021, https://doi.org/10.1145/3410159\n68. F Tonolini, F. Adib,\
    \ Networking across boundaries: Enabling wireless com-\nmunica- tion through the\
    \ water-air interface, SIGCOMM 2018 - Proc 2018 \n453\nSiberian Journal of Life\
    \ Sciences and Agriculture, Том 14, №6, 2022\nConf ACM Spec Interes Gr Data Commun,\
    \ 2018, 117–131, https://doi.\norg/10.1145/3230543.3230580\n69. L Chen, S Thombre,\
    \ K Jarvinen, ES Lohan, A Alen-Savikko, H Leppakoski, et al., Ro- \nbustness,\
    \ Security and Privacy in Location-Based Services for Future IoT: A Survey, \n\
    IEEE Access, 5, 2017, 8956–8977, https://doi.org/10.1109/ACCESS.2017.2695525\n\
    70. Y Njah, M. Cheriet, Parallel Route Optimization and Service Assurance in Ener-\n\
    gy- Efficient Software-Defined Industrial IoT Networks, IEEE Access, 9, 2021,\
    \ \n24682–24696, https://doi.org/10.1109/ACCESS.2021.3056931\n71. A Rajput, VB.\
    \ Kumaravelu, Scalable and sustainable wireless sensor networks \nfor agricultural\
    \ application of Internet of things using fuzzy c-means algorithm, \nSustain Comput\
    \ Informatics Syst, 22, 2019, 62–74, https://doi.org/10.1016/J.\nSUSCOM.2019.02.003\n\
    72. BB Sinha, R. Dhanalakshmi, Recent advancements and challenges of Internet\
    \ \nof Things in smart agriculture: A survey, Futur Gener Comput Syst, 126, 2022,\
    \ \n169–184, https://doi.org/10.1016/J.FUTURE.2021.08.006\n73. F Caffaro, E. Cavallo,\
    \ The effects of individual variables, farming system char-\nacter- istics and\
    \ perceived barriers on actual use of smart farming technologies: \nEvidence from\
    \ the piedmont region, northwestern Italy, Agric, 9, 2019, https://\ndoi.org/10.3390/AGRI-\
    \ CULTURE9050111 \n74. Mohit Jain, Pratyush Kumar, Ishita Bhansali, Q. Vera Liao,\
    \ Khai Truong, \nShwetak Patel. FarmChat: A Conversational Agent to Answer Farmer\
    \ Que-\nries. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiq-\n\
    uitous Technologies, 2018, vol. 2, issue 4, article 170, pp 1–22. https://doi.\n\
    org/10.1145/3287048\n75. Mclaughlan B, Brandli J, Smith F. Toward Sustainable\
    \ High-Yield Agriculture \nvia Intelligent Control Systems, 2015. \n76. RK Kodali,\
    \ S Soratkal, L. Boppana, IOT based control of appliances, in: Pro-\nceeding -\
    \ IEEE Int Conf Comput Commun Autom ICCCA 2016, 2017, pp. \n1293–1297, https://doi.org/10.1109/CCAA.2016.7813918\n\
    77. Abbasi R, Reyes A, Martinez E, Ahmad R. Real-time implementation of digital\
    \ \ntwin for robot based production line n.d.:4–6. \n78. O Bermeo-Almeida, M Cardenas-Rodriguez,\
    \ T Samaniego-Cobo, E Ferruzo-\nla- Gómez, R Cabezas-Cabezas, W. Bazán-Vera, Blockchain\
    \ in Agriculture: A \nSystematic Literature Review, Commun Comput Inf Sci, 883,\
    \ 2018, 44–56, \nhttps://doi.org/10.1007/978-3-030-00940-3_4\n79. V Saiz-Rubio,\
    \ F. Rovira-Más, From Smart Farming towards Agriculture 5.0: \nA Review on Crop\
    \ Data Management, Agron, 10, 2020, 207, https://doi.\norg/10.3390/AGRONOMY10020207\n\
    454\nSiberian Journal of Life Sciences and Agriculture, Vol. 14, №6, 2022\n80.\
    \ X Xu, Y Lu, B Vogel-Heuser, L. Wang, Industry 4.0 and Industry 5.0 – Incep-\n\
    tion, conception and perception, J Manuf Syst, 61, 2021, 530–535, https://doi.\n\
    org/10.1016/J.JMSY.2021.10.006\n81. PKR Maddikunta, Q-V Pham, P B, N Deepa, K\
    \ Dev, TR Gadekallu, et al., In-\ndustry 5.0: A survey on enabling technologies\
    \ and potential applications, J Ind \nInf Integr, 2021, 100257, https://doi.org/10.1016/J.JII.2021.100257\n\
    DATA ABOUT THE AUTHORS\nGurjeet Singh, Associate Professor& Dean, Lords School\
    \ of Computer Ap-\nplications & IT\n \nLords University\n \nAlwar-Bhiwadi Highway,\
    \ Chikani, Alwar, 301028, Rajasthan\n \nresearch.gurjeet@gmail.com\nNaresh Kalra,\
    \ Deputy Registrar (Research), Faculty of Pharmacy\n \nLords University\n \nAlwar-Bhiwadi\
    \ Highway, Chikani, Alwar, 301028, Rajasthan\n \nnaresh.kalra@lordsuni.edu.in\n\
    Neetu Yadav, Associate Professor& Dean, Lords School of Social Sciences \n& Humanities\n\
    \ \nLords University\n \nAlwar-Bhiwadi Highway, Chikani, Alwar, 301028, Rajasthan\n\
    \ \nneetu.yadav@lordsuni.edu.in\nAshwani Sharma, Assistant Professor, Lords School\
    \ of Computer Applica-\ntions & IT\n \nLords University\n \nAlwar-Bhiwadi Highway,\
    \ Chikani, Alwar, 301028, Rajasthan\n \nashwani.sharma@lordsuni.edu.in\nAshwani\
    \ Sharma, Assistant Professor, Lords School of Computer Applica-\ntions & IT\n\
    \ \nLords University\n \nAlwar-Bhiwadi Highway, Chikani, Alwar, 301028, Rajasthan\n\
    \ \nmanoj.saini@lordsuni.edu.in \nПоступила 21.05.2022 \nReceived 21.05.2022\n\
    После рецензирования 21.06.2022 \nRevised 21.06.2022\nПринята 03.07.2022 \nAccepted\
    \ 03.07.2022\n"
  inline_citation: '>'
  journal: Siberian journal of life sciences and agriculture (Print)
  limitations: '>'
  pdf_link: http://discover-journal.ru/jour/index.php/sjlsa/article/download/657/260
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: 'SMART AGRICULTURE: A REVIEW'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/agriculture13030540
  analysis: '>'
  authors:
  - Marwan Ali Albahar
  citation_count: 9
  full_citation: '>'
  full_text: '>

    Citation: Albahar, M. A Survey on

    Deep Learning and Its Impact on

    Agriculture: Challenges and

    Opportunities. Agriculture 2023, 13,

    540. https://doi.org/10.3390/

    agriculture13030540

    Academic Editor: Jiangbo Li

    Received: 7 January 2023

    Revised: 6 February 2023

    Accepted: 11 February 2023

    Published: 23 February 2023

    Copyright:

    © 2023 by the author.

    Licensee MDPI, Basel, Switzerland.

    This article is an open access article

    distributed

    under

    the

    terms

    and

    conditions of the Creative Commons

    Attribution (CC BY) license (https://

    creativecommons.org/licenses/by/

    4.0/).

    agriculture

    Review

    A Survey on Deep Learning and Its Impact on Agriculture:

    Challenges and Opportunities

    Marwan Albahar

    College of Computer Science in Al-Leith, Umm Al Qura University, Mekkah 21955,
    Saudi Arabia;

    mabahar@uqu.edu.sa

    Abstract: The objective of this study was to provide a comprehensive overview
    of the recent ad-

    vancements in the use of deep learning (DL) in the agricultural sector. The author
    conducted a

    review of studies published between 2016 and 2022 to highlight the various applications
    of DL in

    agriculture, which include counting fruits, managing water, crop management, soil
    management,

    weed detection, seed classiﬁcation, yield prediction, disease detection, and harvesting.
    The author

    found that DL’s ability to learn from large datasets has great promise for the
    transformation of the

    agriculture industry, but there are challenges, such as the difﬁculty of compiling
    datasets, the cost of

    computational power, and the shortage of DL experts. The author aimed to address
    these challenges

    by presenting his survey as a resource for future research and development regarding
    the use of DL

    in agriculture.

    Keywords: agriculture; deep learning; crop management; weed detection

    1. Introduction

    In the contemporary era of globalization, the role and contributions of agriculture
    are

    crucially important. Over the years, agriculture has suffered from different challenges
    in

    fulﬁlling the ever-increasing needs of the world population, which has increased
    by twofold

    in the past ﬁve decades. There are different predictions for this unprecedented
    growth

    in the population, which is likely to reach approximately 9 billion people in
    the world

    by 2050 [1]. In addition, the estimates show an increase in the number of people
    living

    within urban areas, along with a signiﬁcant drop in the percentage of the population
    who

    are retired or working [1,2]. This means that agricultural productivity around
    the world

    must be increased considerably, and there is a need for a human labor force. To
    address

    this sort of problem, technologies such as tractors were introduced into agriculture
    over a

    century ago. At present, mechanical technology is showing an incredible evolution,
    and

    a signiﬁcant number of technologies are available. Existing technologies, such
    as remote

    sensing [3], robotic platforms [4], and the Internet of Things (IoT) [2], have
    recently become

    widespread in industry, particularly in the agricultural sector, leading to the
    phenomenon

    of smart and efﬁcient farming [5,6]. Schmidhuber (2015) states that deep learning
    (DL) is a

    modern approach that is successfully being utilized as part of various machine-learning

    techniques [7]. It is comparable to artiﬁcial neutral networks (ANNs) but with
    enhanced

    learning capabilities; therefore, it has higher accuracy [8]. In recent years,
    DL technologies,

    such as generative adversarial networks (GANs), recurrent neutral networks (RNNs),
    and

    convolutional neutral networks (CNNs), have been widely implemented and investigated

    in different ﬁelds of research, including farming and agriculture. Agriculturalists
    and

    researchers often use different software systems without assessing the mechanisms
    and

    ideas of the techniques, such as GANs, RNNs, and CNNs, that are usually applied
    in DL

    algorithms. There are various sub-categories of DL algorithms, including deep
    convo-

    lutional generative adversarial networks (DCGANs), very deep convolutional networks

    (VGGNets), and long short-term memory (LSTM) networks; therefore, understanding
    these

    Agriculture 2023, 13, 540. https://doi.org/10.3390/agriculture13030540

    https://www.mdpi.com/journal/agriculture

    Agriculture 2023, 13, 540

    2 of 22

    sub-categories of DL algorithms is important for understanding common DL algorithms
    [9].

    According to Kamilaris and Prenafeta [10], DL is a modern and recent technique
    and

    system for data analysis and image processing with signiﬁcant potential and promising

    results [10]. DL has been successfully used in different domains and has recently
    entered

    the agriculture ﬁeld. Additionally, it has the potential to address complex problems
    more

    efﬁciently and quickly due to the use of complex models that enable massive parallelization.

    These multifaceted models used in DL are likely to increase classiﬁcation accuracy
    and

    limit faults in regression problems, but only if there are sufﬁciently large databases
    that can

    be used to explain such problems.

    The authors of [11] argued that DL using drone technology is signiﬁcant for agriculture

    and farming as it provides a convenient way to monitor, assess, and scan crops
    through the

    use of high-quality and high-resolution images [11]. Such technology aids in recognizing

    advancements in ﬁelds and assessing quality. For example, with the help of images

    provided by drone technology, agriculturalists and farmers can determine whether
    crops

    are fully ready for harvesting. DL, along with machine-learning (ML) techniques,
    can help

    farmers understand the nature of the soil, thus aiding them in making timely decisions

    regarding farming. DL is also applied to assess how nutrients and water are to
    be managed

    and to make decisions about the suitable time for cropping and harvesting. Yields
    are

    higher and more efﬁcient and the return on investment (ROI) for crops can be projected,

    considering the margin and cost in the market [12]. In addition, the efﬁciency
    of DL is

    recognized because it has been observed to outclass conventional methods, such
    as support

    vector machines (SVMs), random forest (RF) algorithms, and ANNs. Several technologies

    are being used together with DL to enhance performance in prediction and classiﬁcation

    related to agricultural problems. The RNN and LSTM models have memory and time

    dimensions. As a result, they can be used to project animal and plant growth based
    on

    recorded data, evaluate water needs, and determine crop yield using the mining
    time

    dimensions and memory function [13,14]. They can also be utilized to estimate
    plant

    and animal growth based on previously recorded data to evaluate fruit yields or
    water

    requirements. Ren et al. [15], for example, used both models to forecast various
    phenomena

    and climate changes. Using hyperspectral images and infrared thermal imaging to
    provide

    data and information is the right direction for the prompt detection of diseases
    in crops.

    With the subsequent exponential growth in this ﬁeld, it is necessary to provide
    an up-to-date

    review of the recent literature focusing on innovative research techniques implementing

    DL for agriculture. Hence, this study focused on providing an overview of the
    recent

    advancements linked to DL in the agricultural sector. The study aimed to describe
    the

    use of DL in agriculture; in particular, with respect to counting fruits, managing
    water,

    crop management, soil management, weed detection, seed classiﬁcation, yield prediction,

    disease detection, and harvesting. The adoption of technology in the agriculture
    sector

    during the recent period has signiﬁcantly transformed and assisted farming and
    crop

    cultivation. However, DL has been noted to have added efﬁciency to agriculture,
    which

    has motivated researchers to investigate how it can be helpful in farming and
    harvesting

    and in yield predictions.

    This paper is categorized in the following way: Section 2 presents the research
    method-

    ology. Section 3 provides a literature review by highlighting a brief history
    of the topic.

    Section 4 highlights the importance of DL in the agriculture sector. Section 5
    discusses DL

    tools that can be used for model development. In addition, the same section describes
    the

    usage, purpose, signiﬁcance, and implementation of DL in the agriculture sector.
    Section 6

    provides the results and a discussion, drawing on previous studies that have discussed

    deep learning. Section 7 presents the overall conclusion of the study, together
    with some

    ideas for future research directions.

    2. Research Method

    The methodology of this study was based on secondary data and a comprehensive
    re-

    view of approaches linked to agricultural DL, including disease detection, yield
    prediction,

    Agriculture 2023, 13, 540

    3 of 22

    and weed prediction, using databases such as Research Gate, IEEE Explore, Springer,
    Else-

    vier, Google Scholar, Frontier, and Science Direct. For this study, research papers
    published

    between 2016 and early 2022 were considered due to the increasing advancements
    in DL

    and its increasing use in agriculture. Additionally, the emphasis for data collection
    was on

    journal articles and conference papers. The inclusion criteria for research papers
    were that

    they were available in English with full access and were relevant to the research
    objectives

    with themes including development and agriculture. Studies that were published
    before

    2016 were excluded from this study. The research method ﬂowchart for this study
    is shown

    in Figure 1.

    Figure 1. The research methodology.

    3. Literature Review

    3.1. Deep Learning

    Agriculture faces many challenges due to the increase in demand and the presence

    of fewer workers in the ﬁelds. In this context, smart farming can be used to address

    issues such as food security, sustainability, productivity, and environmental
    impact [16].

    As is known, agriculture plays a vital role in the global economy [17]. This is
    because

    it ensures food security for countries, and most companies rely on it for their
    external

    trade. In the world today, most home appliances, travel means, and other commonly

    used services are becoming automated through the adoption of artiﬁcial intelligence
    (AI);

    thus, farming practices should too, since they are the backbone of a country.
    Achieving

    understanding and making quick responses with the help of data provided by continuous

    monitoring, measuring, and analysis of different physical aspects and phenomena
    would be

    helpful to overcome the complex, multivariate, and unpredictable challenges of
    agricultural

    ecosystems [18]. This would require the analysis of huge amounts of agricultural
    data

    and the use of new information and communication technologies (ICTs) and would
    be

    necessary for both small-scale farms and large-scale ecosystem monitoring [19].
    It could

    be achieved using DL with a large network. DL is basically an aspect of machine
    learning

    that aims to build neural networks that can analytically learn by simulating the
    human

    brain. It acts like the human brain in that it works by reading data, such as
    pictures, videos,

    text, and sounds. With its continued development, DL has already been implemented
    in

    various complex tasks, such as image segmentation, image recognition, natural
    language

    processing, object detection, and image classiﬁcation [18]. However, DL requires
    a huge

    dataset since the quality of the DL results entirely depends on the size of the
    dataset, and

    the model tends to learn from that data and then respond accordingly. Some computer
    and

    industrial advancements, such as image processing, IoT technologies, robotics,
    machine

    learning, deep learning, and computer vision, are very useful in the agricultural
    industry

    and even for local farmers. High-quality image processing makes AI based on drone

    technology a very helpful asset for farmers, since they can identify the progress
    of the crops

    and determine whether they are ready to harvest or not while sitting in one place
    rather

    than having to move long distances. This has been achieved just AI and a drone
    system;

    one can only imagine how beneﬁcial it would be to implement DL in agriculture
    [18].

    Figure 2 lists numerous advantages of using DL in agriculture. With the current

    increase in the population, there has also been an increase in the demand for
    agricultural

    goods [18]. The implementation of DL and other automation components could greatly

    beneﬁt production outcomes, reduce the chances of ripening, reduce production
    costs,

    and increase income due to the increased production. Moreover, it would also make

    Agriculture 2023, 13, 540

    4 of 22

    it possible to forecast climatic changes—for instance, if there is an incoming
    rainstorm,

    cyclone, etc.—so that the farmers could be ready and prepare before a disaster.

    Figure 2. Deep learning applications in agriculture [18].

    3.2. Agriculture before Deep Learning

    Traditional agriculture was the main method of farming before the adoption of
    sci-

    entiﬁc advancements in agricultural industries. Traditional agriculture mainly
    involves

    the extensive use of traditional tools and organic fertilizers, indigenous knowledge
    of land

    use and natural resources, cultural beliefs, etc. [19]. Another way to describe
    it could be

    as the “primitive style” or “early style” of farming and food production. The
    traditional

    method of farming affects the environment in many ways, such as through the depletion
    of

    soil nutrients. For instance, slash and burn practices in traditional agriculture
    were one

    reason for decreased soil organic matter. Another problem caused by traditional
    farming

    was deforestation, as most deforestation has taken place in tropical rainforests
    to make

    space for other agricultural activities. Another signiﬁcant issue relating to
    soil erosion is

    the removal of topsoil by water or wind. This topsoil is the most fertile, and
    it may take

    decades to replenish it once it is removed [19].

    Agroforestry, crop rotation, intercropping, polycultures, and water harvesting
    are

    some of the most common types of traditional farming practices. The traditional
    farming

    method of constructing grain storage structures provided an incredible moisture-proof

    environment for grain storage. Compared to today’s colossal warehouses, these
    small

    structures were cheap to fabricate and maintain. However, many different pesticides
    were

    used to keep the grains safe during storage periods, which later resulted in very
    bad effects

    on the environment [20]. The implementation of technology and the investment of
    huge

    sums of money in agricultural industries have helped to control other diseases,
    thereby

    making the amount of money spent worthwhile.

    3.3. Deep Learning Architecture

    Several nonlinear transformations are used to model higher-level abstractions
    in

    data, and these are the foundations of DL [21]. One of the main beneﬁts of DL
    is the

    Agriculture 2023, 13, 540

    5 of 22

    automatic extraction of features from raw data or feature learning. Producing
    features

    from lower-level components yields features in higher-level components [22]. Recurrent

    neural networks (RNNs) and CNNs are two types of DL networks that are often used

    in agriculture.

    3.3.1. Convolutional Neural Networks (CNNs)

    The CNN is a type of DL algorithm [23] composed of multiple convolutional layers,

    pooling layers, and fully connected layers. Two of the most common applications
    for CNNs

    are the recognition of handwritten characters and image processing. In the domain
    of

    computer vision, CNNs have been used for a variety of tasks, including object
    detection,

    image classiﬁcation, voice recognition, image fragmentation, medical image analysis,
    and

    text and video processing. Convolutional, pooling, and fully connected layers
    are the

    typical architectural components of a CNN [24]. Figure 3 depicts the architecture
    of a CNN,

    and brief descriptions of each layer are provided below.

    Figure 3. Convolutional neural network architecture.

    In a CNN, the convolutional layer is the most fundamental and signiﬁcant. It stores
    all

    of the images’ distinguishing characteristics while making it possible to limit
    the amount of

    data that must be simultaneously processed. Then, pooling enables a CNN to aggregate
    all

    the different dimensions of an image and recognize the object, even if its form
    is distorted or

    it is positioned at an angle. Thus, the number of learnable features in the model
    is reduced,

    helping to address the overﬁtting issue. Pooling can be accomplished in a variety
    of ways,

    including average pooling, maximum pooling, and stochastic pooling. The fully
    connected

    layer is the ﬁnal layer, which is used to feed the neural network [24].

    3.3.2. Recurrent Neural Networks (RNNs)

    An RNN is a type of neural network model capable of performing exceptionally

    well in fundamental tasks such as machine translation, language modeling, and
    speech

    recognition [25]. Unlike traditional neural networks, RNNs use the network’s sequential

    information. This feature is essential in many applications because the data sequence’s

    inherent structure contains valuable information that can be extracted from it.
    Figure 4

    depicts the fundamental structure of a recurrent neural network [25].

    Figure 4. Recurrent neural network generic structure.

    Agriculture 2023, 13, 540

    6 of 22

    4. Signiﬁcance of Deep Learning in Agriculture

    4.1. Counting of Fruit

    Counting fruit is an essential task for growers because it makes it possible to
    estimate

    the yield, which can be helpful in the management of yards. According to [26],
    counting

    fruit using automated fruit detection and algorithms can optimize agriculture
    production

    and help in managing the harvest process effectively. For automated fruit counting
    and

    detection, the authors provided a method that uses a pipeline for the DL algorithms

    consisting of part 0, part 1, part 2, and part 3. In part 0, the algorithms learn
    ground

    truths. They use the Bob detection neural network in part 1 and count the fruit
    through the

    neural network in part 2. In part 3, the linear regression is run for the ﬁnal
    count [26]. The

    authors of [27] proposed automatic yield estimation using robotic agricultural
    techniques

    to improve the manual counting of fruit. The authors used Inception-ResNet to
    achieve a

    high accuracy ratio with a lower computational cost as a deep simulated learning
    technique.

    The signiﬁcance of the technique proposed in [27] is that it does not require
    thousands of

    images to train the neural networks. Instead, the network can be trained with
    synthetic

    images to test the authenticity of images, achieving an accuracy rate of 91%.
    This novel

    DL method can facilitate farmers’ abilities to efﬁciently count fruit and make
    decisions

    with great precision [27]. Similarly, the authors of [28] trained a Fast R-CNN
    DL model

    to detect, count, and predict the right size for citrus fruit. The authors also
    used the long

    short-term memory detection method to calculate the number of fruit on each tree,
    as

    shown in Figure 5. Hence, DL methods, such as automated yield detection, DL simulation,

    and Fast R-CNN, can be helpful in the counting of fruit. Table 1 presents the
    most recent

    methods for counting fruits.

    Figure 5. Flowchart for Faster R-CNN [28].

    Agriculture 2023, 13, 540

    7 of 22

    Table 1. Summary of different DL methods for counting fruit.

    Ref

    DL model

    Dataset

    Accuracy

    [29]

    Faster R-CNN

    TL + ﬁeld farm

    0.83 F1-score

    [30]

    Inception-ResNet-v4

    ILSVRC-2010&2012

    N/A

    [31]

    VGG-16

    Orchard

    95%

    [32]

    CNN

    Kiwifruit

    89.29%

    [33]

    YOLO V3

    PT + WGISD

    —

    [34]

    Faster R-CNN + Iv2

    Cherries

    85%

    [35]

    E-Net

    Fruit 360

    93.7%

    [36]

    8-layer CNN model

    Self collecting

    95.67%

    [37]

    M-Net

    Mango orchard

    73.6%

    [38]

    YOLO V3

    PT + WGISD

    97.3% for test

    4.2. Management of Water

    Water is an essential natural resource for agriculture that needs recycling for
    the

    continued and sustainable development of agriculture. The authors of [39] stated
    that

    water is essential for agriculture production but the chemicals from industries
    and the

    wastewater from daily usage increase water pollution. Therefore, the agriculture
    ﬁeld

    needs a DL technique to protect agriculture from water pollution. The authors
    of [39]

    proposed a near-infrared (NIR) spectroscopy method that can be used to assess
    water

    demand, protection, and recycling. The NIR system is used as one layer along with
    an

    improved convolutional neural network (CNN) layer that employs decision tree analysis

    to depict informative data helpful for making decisions relevant to water management.

    The authors of [40] posited that agriculture is the backbone of the economy in
    India and

    requires water as a signiﬁcant resource. Traditional irrigation methods waste
    water due to

    excessive water use and unplanned water management. Therefore, the authors provided

    an integrative approach that uses DL methods to improve the irrigation system
    in India’s

    agriculture (see Figure 6). The system consists of sensors that detect the soil’s
    humidity

    and predict the irrigation needs of the soil. The authors of [41] stated that
    water is a critical

    resource for which evapotranspiration assessment is very beneﬁcial. Evapotranspiration

    assessment uses DL techniques to predict upcoming water needs and to provide clues
    that

    can be helpful for real-time irrigation management. Thus, DL techniques can help
    farmers

    precisely manage their irrigation systems.

    Figure 6. Deep learning approach for water management [40].

    Agriculture 2023, 13, 540

    8 of 22

    4.3. Crop Management

    The signiﬁcance of DL frameworks is increasing in crop management, a subﬁeld of

    agriculture. The authors of [42] asserted that DL technology is beneﬁcial for
    crop planting.

    Crop planting is the ﬁrst step in crop production and needs to be managed efﬁciently
    to

    increase crop production. The authors discussed the various DL crop planting techniques,

    including ViSeed, which has been used for soybean production; Fast R-CNN, which
    has

    been used to count and measure the stalks of sorghum plants; CNN, which has been
    used

    for the identiﬁcation of localized features of roots and shoots; and VGG-16, which
    has

    been used for categorization of crops and weeds. According to the authors of [43],
    there

    are different types of deep learning networks that can be used for crop prediction.
    These

    different types include ANNs, for which the regression method and crop species
    and images

    and climatic and soil properties can be used to predict wheat, barley, sugarcane,
    sunﬂower,

    and potato crop production. Other DL techniques discussed in [43] include two-layered

    DNN LSTM, which has been used to predict tomato, soybean, and corn crop production

    using the regression method, a vegetative index, environmental characteristics,
    and soil.

    In addition, the authors of [44] stated that intelligence plays a crucial role
    in precisely

    managing crops. The authors introduced the CropDeep approach, which classiﬁes
    and

    detects different classes of crops. CropDeep provides crop management services
    through

    cameras and models; it classiﬁes crops and provides analysis that is helpful for
    decision

    making and includes real-world challenges; e.g., weather uncertainty (see Figure
    7). Table 2

    presents the most recent methods for crop management.

    Figure 7. CropDeep deep-learning detection and classiﬁcation models [44].

    Table 2. Summary of different DL methods for crop management.

    Ref

    DL Model

    Application

    Accuracy

    [45,46]

    FCN architecture/Stem-seg-S

    Joint stem detection and

    crop/weed classiﬁcation

    mAP, 85.4% (stem detection)

    69.7% (segmentation)

    [47]

    AgroAVNET

    Crop/weed classiﬁcation

    98.23%

    [48]

    AlexNet, VGG-19, GoogLeNet,

    ResNet-50, ResNet-101,

    Inception-v3

    Crop/weed classiﬁcation

    96% (VGG-19)

    [49]

    1D/2D/3D CNN

    Crop mapping

    94% (3D CNN)

    4.4. Soil Management

    Soil management refers to the practices, operations, and treatments that protect
    soil

    and increase an agricultural ﬁeld’s production. The authors of [50] stated that
    DL techniques

    can help manage soil moisture. According to the authors, developing a mathematical
    model

    Agriculture 2023, 13, 540

    9 of 22

    is difﬁcult for soil moisture, so the accuracy, predictions, and generalization
    of existing

    models could be improved. The authors improved the DL regression model by ﬁtting
    it

    with large datasets, making it possible to precisely determine soil moisture.

    The authors of [51] proposed that agriculture has been an essential aspect of
    the lives of

    human beings since even before civilization. Soil yield plays a key role in crop
    production

    and efﬁcient agriculture. Therefore, the authors discussed how implementing the
    Keras

    API in Python can help protect soil from herbicide toxicity while also retaining
    moisture.

    Moreover, using a ﬁrst-order agriculture simulator that employs discrete time,
    the Richard

    equation can help determine the precise moisture level in soil [52]. The authors
    explained

    that using an agriculture simulator can help in obtaining aerial images with a
    particular soil

    moisture information dataset. The dataset was analyzed using seven methods, including

    constant prediction baseline, SVM, and NN, which showed that using a CNN could
    reduce

    water consumption by 52% [52]. Thus, the authors showed that DL techniques can
    help

    maintain soil moisture.

    4.5. Weed Detection

    Weeds are undesirable plants that can reduce crop production. DL techniques can

    help detect weeds. According to [51], a “weed” is a plant that grows in an unfavorable

    environment. They have negative effects on crop production because they compete
    with

    plants for water, sunlight, and soil minerals. Weed detection can be undertaken
    by using

    DL techniques, such as ﬁrst-order agriculture simulation with Richard’s equation.
    This

    approach reduces the use of weedicides, thus protecting the soil from toxicity
    and ensuring

    the plants achieve suitable production yields. In addition, the authors of [53]
    raised the

    concern that the production and utilization of herbicides have made weeds resistant
    to

    these herbicides. Therefore, developing precision techniques to detect weeds is
    important

    to increase crop production. Researchers have discussed the revolution in computing

    technology and how it can help in better understanding weed biology and ecology.
    DL is

    the most helpful technique, as it aids in categorizing weeds in crop categories
    and getting

    rid of them. In a similar context, the authors of [54] found that DL techniques,
    such as

    classiﬁcation SVMs and CNNs, can reduce the burden on farmers. The techniques
    can help

    farmers detect weeds. The authors described various weed detection and categorization

    techniques. In such techniques, the camera ﬁrst takes images of weeds and then
    uses a gray-

    level occurrence matrix to identify homogeneity among the images. The color identiﬁed

    through the hue saturation value (HSV) describes the mellowness of the weeds,
    as shown

    in Figure 8. Hence, DL techniques are helpful for weed detection, reducing the
    burden on

    farmers and increasing crop yield.

    4.6. Seed Classiﬁcation

    In the agriculture sector, crop production strongly relies on seeds. According
    to [55],

    seeds are a signiﬁcant part of crop production, without which production and harvesting

    of crops are impossible. The increased level of population growth has put pressure
    on

    agriculture growth due to the precision needed when identifying and classifying
    seeds.

    The authors proposed a CNN to increase the efﬁciency of the classiﬁcation of seeds.
    In this

    technique, the methods used included decayed learning points.

    4.7. Classiﬁcation of Plant Diseases

    Plants can produce decreased crop yields due to the presence of fungi, microbes,
    and

    bacteria. If the disease is not diagnosed in time, it can cause signiﬁcant economic
    losses

    for farmers. The pathogen-killing pesticides that are used to restore crop functionality

    and remove pests come at a high cost. Excessive use of pesticides is detrimental
    to the

    environment and can disrupt the water and soil cycles [56]. As plant diseases
    stunt growth,

    identifying them in their early stages is essential. DL models have been applied
    in the

    process of recognizing and categorizing various plant diseases. Several DL architectures

    have been proposed to improve detection accuracy [57]. In [58], the authors proposed
    a

    Agriculture 2023, 13, 540

    10 of 22

    method for identifying and categorizing banana diseases based on a CNN. The proposed

    model processes pictures of leaves to help farmers detect two banana diseases
    (sigatoka

    and speckle) quickly. In addition, the authors of [59] used AlexNet to accurately
    classify

    plant diseases based on leaf images. The DL hybrid model described in [60] identiﬁed

    and categorized diseases that affect sunﬂowers, such as Verticillium wilt, Phoma
    rot,

    downy mildew, and Alternaria leaf rot. The authors of [61] developed a mobile
    app that

    utilizes machine learning to diagnose diseases that affect plant leaves. The app
    can classify

    38 different diseases. The authors amassed 96,206 images, including both healthy
    and

    diseased plant leaf specimens, for training, testing, and validation of the model.
    In [62], the

    authors proposed a pre-trained, transfer-learning deep neural network model that
    could

    predict crop disease by learning leaf characteristics from input data. They extensively

    investigated different DL and CNN topologies, such as ResNet, MobileNet, Wide
    ResNet,

    and DenseNet. The result showed that the proposed method was superior in terms
    of

    accuracy and memory to previous methods in the literature. Another CNN-based method

    for detecting, classifying, and identifying plant diseases was proposed in [63].
    The accuracy

    for the identiﬁcation of 13 different plant diseases ranged from 91 to 98%. Furthermore,
    the

    proposed model was able to distinguish between unhealthy and healthy leaves, as
    well as

    their backgrounds. Using 500 different leaf images, the authors of [64] proposed
    a model

    based on an SVM classiﬁer. The proposed model could accurately identify plant
    diseases,

    achieving an accuracy of 94%. Table 3 presents the most recent methods for classifying

    plant diseases.

    Figure 8. Flowchart for weed detection and classiﬁcation [54].

    Agriculture 2023, 13, 540

    11 of 22

    Table 3. Summary of different DL methods for classifying plant diseases.

    Ref.

    Leaf Type

    Method

    Accuracy

    [65]

    Rice

    VGGNet

    92.00

    [66]

    Tomato

    S-CNN and F-CNN

    98.30

    [67]

    Plant leaf

    EfﬁcientNet

    96.18

    [68]

    Grape

    Hy-CNN

    98.70

    [69]

    Grape

    United model

    98.20

    [70]

    Plant leaf

    Whale and DL

    95.10

    [71]

    Crop

    FCNN and SCNN

    92.01

    [72]

    Coffee

    Deep CNN

    98.00

    4.8. Yield Prediction

    It is essential to focus on and carefully manage yield predictions for each crop.
    Agri-

    cultural machine-learning and DL algorithms are primarily concerned with crop
    yield

    prediction. They inform the farmer about whether the crop is ready for cultivation
    and

    predict when it will be [73]. Manjula et al. [74] proposed a model based on an
    RF classiﬁer

    that could predict millet crop yield with an accuracy of 99.74%. The prediction
    of crop

    yield is notoriously difﬁcult due to the presence of numerous complex factors.
    For example,

    high-dimensional marker data are required to represent genotype information, consisting

    of the data for millions of markers for each individual plant. The ﬁnal effect
    of the genetic

    markers must be estimated because it is affected by numerous environmental conditions

    and ﬁeld management techniques. Recently, a variety of machine-learning models,
    includ-

    ing association rule mining, ANNs, decision trees, and multivariate regression,
    have been

    applied in the ﬁeld of crop yield prediction. The most notable characteristic
    of ML and DL

    may be that the output is treated as an implicit function of the input variables
    and may be

    a highly nonlinear and complex function [75].

    Extensive research has been conducted on crop yield prediction. Liu et al. [76]
    em-

    ployed a neural network with one hidden layer for the prediction of corn yield
    using input

    data on weather, soil, and management. In the same context, Drummond et al. [76]
    worked

    on predicting crop yield by using neural networks, projection pursuit regression,
    and

    stepwise multiple linear regression. As a result, they found that both regression
    methods

    were outperformed by the neural network method. In addition, Marko et al. [76]
    predicted

    the crop yields of different soybean varieties by using weighted histogram regression.
    They

    obtained better performance than the conventional regression algorithms.

    4.9. Disease Detection

    In the agricultural ﬁeld, one major threat to farmers is crop disease. With the
    devel-

    opments in the ﬁelds of AI and DL and their implementation in agricultural industries,

    crop disease detection has become one of the easiest processes. Before the adoption
    of

    advanced technology in agriculture, the detection of diseases in crops at an early
    stage was

    a time-consuming and tedious task that had to be performed manually [77]. Plant
    disease

    not only affects plant growth and the population but also seriously affects the
    economy

    of countries. Hence, it is essential to adopt automatic and accurate techniques
    for the

    prediction and detection of plant disease severity for disease management and
    food safety

    and to predict losses in returns. In most developing countries, farmers are usually
    required

    to travel huge distances to contact experts, which can consume huge amounts of
    money

    and time [76]. This could be handled by developing a robust and easy-to-use plant
    or crop

    disease detection system, which would require many sample images of crops that
    have

    diseases that could be uploaded to the cloud, and the system could run on IoT
    devices, such

    as smartphones and tablet PCs with appropriate computational capabilities. Some
    work

    has been done in order to tackle this issue of crop diseases. Nikhil Patil et
    al. [78] proposed

    Agriculture 2023, 13, 540

    12 of 22

    a crop disease detection system using a CNN. The system achieved an accuracy rate
    of 89%

    compared to the traditional crop disease detection system. Hence, when it comes
    to image

    processing, CNN systems can be relied upon due to the fact that they are widely
    used in

    agricultural research. Most DL applications in agriculture can be categorized
    as plant or

    crop classiﬁcation, which is important for disaster monitoring, robotic harvesting,
    pest

    control, and yield prediction. Plant and crop disease recognition models are mostly
    based

    on pattern recognition and leaf images [78]. Hence, DL and AI models could automatically

    determine which plants are diseased and send alerts to the farmer for early action.
    Figure 9

    shows an example of how DL and AI can detect plant diseases.

    Figure 9. Plant disease detection [79].

    5. Application of Deep-Learning Models in Agriculture

    According to [80], there are different points of view about the creation of DL
    tools

    for model development. Python tools are used to emphasize the concept of saliency
    in

    images. Saliency is typically deﬁned by unique features, including pixels, or
    the resolution

    of the image in visual processing. Another DL tool is the gradient explanation
    technique,

    which employs the gradient-based attribution method. In this method, each gradient

    quantiﬁes each of the input dimensions that can change the predictions around
    the input.

    The integrated gradient is a gradient-based attribution that allows predictions
    to be formed

    by a deep neural network. It is created via attributions related to the network’s
    input

    features [81]. Deep label-speciﬁc feature (DeepLIFT) is another tool designed
    to ensure

    the accuracy of deep neural network predictions. It is also known as the gradient
    + input

    method, and it is used to enhance the gradient with the input signal. It has quite
    a few

    advantages over gradient-based methods, especially when it is implemented into
    models

    that are usually trained with natural images and genomics data [82]. Typically,
    activation

    of each neuron takes place with reference to the contribution scores calculated
    by the

    system. These calculations are based on comparisons between various outputs and
    a

    certain benchmarked output and the differences in the inputs from their reference
    inputs.

    Another model is guided backpropagation, also known as guided saliency, which
    is a

    type of deconvolution approach. This tool and approach is often employed in a
    range of

    network structures, such as in max pooling in CNNs [83]. The purpose is to substitute
    the

    max-pooling layers with a convolutional layer. Similarly, the authors of [84]
    claim that

    deconvolution is a technique for visualizing CNNs that uses quite similar aspects,
    such as

    deconvolutional networks. Furthermore, the authors of [85] proposed class activation
    maps

    (CAMs) for the identiﬁcation of images. With this tool, analysts may inspect a
    particular

    image and then its speciﬁc parts or pixels are used to form the ﬁnal output. In
    other

    Agriculture 2023, 13, 540

    13 of 22

    words, CAMs are used to study the discriminative regions of an image, as with
    a CNN. A

    ﬁnal softmax-loss layer is formed after obtaining the weighted sum of the vector.
    Finally,

    layer-wise relevance propagation (LRP) is a tool for decomposing nonlinear classiﬁers
    that

    aims to improve DL interpretability [86]. It is based on deep neural networks
    formed by

    propagating predictions backward, fulﬁlling the requirement for the conservation
    property.

    All the abovementioned DL tools are currently available for model development.

    According to [87], the deep neural network (DNN) can be employed using a CNN for

    the assessment of the quality of seeds in agriculture. The model can be used to
    study the

    quality of seeds in soybean pods, along with the sorting of haploid seeds. Assessments

    of the shape, phenotypic expression, and embryonic pose are undertaken [88]. CNNs

    have also been used in the classiﬁcation plant seedlings into 12 species. Furthermore,
    the

    authors of [89] used an image analysis technique to create a principal component
    analysis

    (PCA) that can be used to place seeds in different clusters in a cost- and time-effective

    manner. The authors of [90] claimed that DL algorithms, such as Inspection-v3,
    VGG-16,

    and VGG-19, are more efﬁcient in citrus plant disease detection than other innovations.

    In [91], the authors claimed that DL methods aid in the identiﬁcation of plant
    diseases

    from individual lesions and spots. This makes it possible to focus on other aspects
    rather

    than only considering the entire leaf in disease detection. This DL application
    is good

    at detecting multiple diseases on the same leaf and provides 12% greater accuracy.
    DL

    methods can also be used to identify various plant diseases [92]. The authors
    of [93]

    claimed that apple leaf and fruit diseases can be detected using a CNN model,
    implying

    that the use of DL models for disease detection is quite effective. There are
    also harvesting

    techniques that use DL. The authors of [94] formed a shot-detector (YOLO) algorithm
    for

    on-tree fruit detection and used the BBox-Label-Tool to label images. Likewise,
    two deep

    learning models were utilized for images of pears and apples fruits, and it was
    found that

    the deep learning models were quite effective for harvesting purposes. The authors
    of [95]

    revealed that having a robust DL model can be helpful in the harvesting process,
    as it

    showed promising results due to its employment of bio-inspired features. As shown
    by

    these studies, DL is becoming one of the most useful techniques and models in
    harvesting

    since it employs mature features in comparison to other agricultural techniques.
    This recent

    survey also shows that CNNs have promising results in agriculture and increase
    efﬁciency.

    In other words, CNNs have increased accuracy and improved learning capacities
    when DL

    mechanisms are employed in agriculture.

    6. Results and Discussions

    The ﬁndings from the studies show that DL mechanisms have helped farmers in

    different areas of agricultural production. These include counting fruit, management

    of water, crop management, soil management, weed detection, seed classiﬁcation,
    yield

    prediction, disease detection, and even harvesting. A summary of the key ﬁndings
    is

    presented in Table 4.

    Table 4. Summary of different DL methods used in agriculture.

    Ref

    Method Used

    Purpose of Employing Method

    Key Insights

    [20]

    Automated fruit detection and

    algorithms using a DL algorithm

    pipeline consisting of part 0, part 1,

    part 2, and part 3

    Counting fruit

    Optimization of agriculture production

    Promising harvesting results

    [27]

    Inception-ResNet

    Counting fruit

    Provides high accuracy in the counting of fruit

    Uses synthetic images to test authentic images,

    achieving a 91% accuracy rate

    [26]

    Near-infrared (NIR) spectroscopy

    Management of water

    Increased water protection and recycling

    Provides information that helps make effective

    decisions in water management

    Agriculture 2023, 13, 540

    14 of 22

    Table 4. Cont.

    Ref

    Method Used

    Purpose of Employing Method

    Key Insights

    [41]

    Evapotranspiration

    Management of water

    Allows the prediction of water speciﬁcations

    for real-time irrigation management

    [42]

    R-CNN for counting and measuring

    crop plantings

    Crop management

    The CNN helps in identifying localized

    features of roots and shoots

    CGG-16 allows categorization of crops

    and weeds

    [43]

    Two-layered DNN LSTM

    Crop management

    Highlights soil and environmental

    characteristics

    Prominent vegetative index used to create

    estimations of crop production for tomato,

    soybean, and corn

    [51]

    Keras API through Python

    Soil management

    Helps in preventing the harmful effects of

    herbicides and toxicity in soil and

    in retaining moisture

    [52]

    First-order agriculture simulator using

    discrete time

    Soil management

    Improves aerial images and provides soil

    moisture information

    [51]

    First-order agriculture simulation

    with Richard equation

    Weed detection

    Increases protection of soil from toxicity and

    ensures plants achieve good production yields

    [54]

    SVM and CNN

    Weed detection

    The camera is used to take an image of a weed,

    and then the gray-level occurrence matrix is

    employed to determine the homogeneity

    among the images

    Reduces burden on farmers

    [55]

    CNN

    Seed classiﬁcation

    Increased efﬁciency in seed classiﬁcation

    [74]

    Random forest (RF)

    Yield prediction

    Provides the best yield prediction accuracy

    [76]

    Histogram regression

    Yield prediction

    Offers accuracy in the determination of

    soybean varieties

    [78]

    CNN

    Disease detection

    Achieved an 89% accuracy rate when

    compared to other traditional crop disease

    detection methods

    Improves pest control and makes robotic

    harvesting possible with increased yield

    prediction and disaster monitoring

    abilities for crops

    [95]

    Bio-inspired methods

    Harvesting

    Increases harvesting efﬁciency

    Improves accuracy for harvesting in

    agriculture

    [96]

    Canopy-attention-YOLOv4

    Fruit detection

    Precision = 94.89%

    Recall = 90.08%

    F1 = 92.52%

    [97]

    YOLOv5-CS (citrus sort)

    Fruit detection and

    counting

    Recall = 97.66%

    Precision = 86.97%

    mAP = 98.23%

    The key ﬁndings from the literature review show that there are various ways in
    which

    DL has beneﬁted the agriculture industry. Agriculture faces numerous barriers
    as a result of

    increased demand and fewer workers in the sector. However, the implementation
    of smart

    farming can help address issues such as productivity, environmental impact, food
    security,

    and sustainability and increase the efﬁciency of agricultural production [16].
    Agriculture,

    as is well-known, plays an important part in the global economy [17] as it ensures
    food

    security for regions and is used by the majority of businesses for external commerce.
    The

    implementation of deep-learning methods has helped the agricultural sector grow
    and

    develop, employing the latest prediction analyses and tools. There are various
    tools that

    have been used by scholars to prove the efﬁciency of deep-learning methods in
    agriculture.

    According to [18], the size of the dataset used for deep-learning methods may
    determine

    the quality of the results. The accuracy of the results obtained using deep learning
    in

    agricultural production and processes may lead to improved decisions. Traditional
    farming

    Agriculture 2023, 13, 540

    15 of 22

    practices result in a wide range of environmental consequences, including soil
    nutrient

    depletion. Deforestation is another issue produced by traditional farming, as
    most defor-

    estation has occurred in tropical rainforests to make room for other agricultural
    activities.

    Soil erosion, which occurs as a result of the erosion of topsoil by water or wind,
    is another

    issue associated with traditional farming. This topsoil is the most productive
    portion of the

    soil and, once removed, it can take decades to restore it [19]. This implies that
    traditional

    agricultural production methods are insufﬁcient to promote the efﬁciency of the
    sector.

    Agriculture must become more brilliant and progressive in order to meet future
    demands

    and utilize emerging technologies, such as deep learning, remote sensors, and
    distributed

    computing [98]. The current study’s key ﬁndings highlight that the use of various
    DL tools

    in agriculture has improved farming outcomes and production. According to [95],
    the

    real parameters for agriculture are now obtained through cutting-edge technology
    and DL

    mechanisms. DL methods have proven their ability to increase efﬁciency in agriculture,

    showing improved results and accuracy in all domains. Despite the employment of
    DL

    mechanisms in agriculture, it was identiﬁed that there are also certain challenges
    that

    accompany the use of this technology, such as dataset creation, the time required
    to train

    staff, and having skilled labor to increase production. Furthermore, system development

    and hardware maintenance, as well as the deployment of large models and software
    on

    small devices, such as mobile phones, may have an impact on system efﬁciency [99].
    More-

    over, developing awareness among staff members when DL methods are employed is

    also challenging in agriculture. According to [100], transfer learning is a technique
    that

    can be employed to minimize the emerging challenges that may arise when employing

    deep learning in agriculture. It is typically used to address problems when there
    is a

    small dataset and minimal time is required to test the accuracy of the model.
    As shown

    in [101,102], AI is useful to minimize the challenges affecting agricultural production
    when

    DL and robotics are used. In the same context, automated machine learning (AutoML)
    is

    another technique that helps increase agriculture production through innovation.
    When

    DL methods are employed in agricultural production mechanisms, AutoML can be use-

    ful to minimize the challenges. Thus, the literature shows that DL methods have
    been

    extremely useful in increasing production in the agricultural sector. However,
    in order

    to minimize the challenges that come with employing DL techniques, it is important
    to

    consider employing other emerging technologies, such as robotics, the Internet
    of Things,

    and distributed computing.

    It was found that most DL-based farming techniques use very simple algorithms
    and

    network structures. The primary cause of this is that the combination of deep
    learning and

    precision agriculture is still in its infancy. The lack of collaboration between
    the computer-

    science and agriculture communities is also a contributing factor. Table 1 shows
    that many

    of the deep-learning algorithms tested had an accuracy of 90% or more with some
    datasets,

    but it should be noted that these results are not generalizable. The accuracy
    and speed

    of these networks typically fall short of the benchmarks when they are employed
    with

    other datasets or a real farmland environment. This is mainly due to the fact
    that the

    complexity, quality, and quantities of agricultural datasets are still very different
    from

    actual farmland environments. Many novel approaches have been proposed to lessen

    the reliance of DL models on agricultural datasets, including transfer learning
    [103,104],

    few-shot learning [105,106], graph convolutional networks [107], and semi-supervised

    learning [108]. However, their entire performances are still unavailable. Only
    a few

    recent studies have focused on tailoring deep-learning algorithms and neural network

    architectures to the needs of agricultural applications. Some studies, for instance,
    have

    aimed to ﬁnd the most effective ways to optimize the parameters used in DL models.

    Enhancing DL algorithms and frameworks has been the focus of other research. With
    the

    aim of large-scale dense semantic segmentation of weeds using aerial images, the
    authors

    of [109,110] presented WeedMap and WeedNet. They made changes to the decoder that

    allowed them to use a modiﬁed version of the VGG16 architecture in place of the
    original

    encoder. Jiao et al. [111] created an anchor-free convolutional neural network
    (AF-RCNN)

    Agriculture 2023, 13, 540

    16 of 22

    to achieve a balance between speed and accuracy in deep-learning algorithms applied

    to the detection of multiclass agricultural pests. To improve recognition accuracy
    in leaf

    disease detection, the authors of [112] utilized convolutional neural networks
    (CNNs) and

    pre-trained models to identify plant diseases. The study focused on ﬁne-tuning
    popular

    pre-trained models, such as DenseNet-121, ResNet-50, VGG-16, and Inception V4,
    using

    the PlantVillage dataset, which contains 54,305 images of plant diseases in 38
    classes. The

    performance of the models was evaluated through various metrics. The results showed
    that

    DenseNet-121 achieved the highest classiﬁcation accuracy of 99.81%, outperforming
    other

    state-of-the-art models. In the same context, the authors of [113] proposed a
    new method for

    data augmentation utilizing generative adversarial networks (GANs) for tomato
    leaf disease

    recognition. By utilizing deep convolutional generative adversarial networks (DCGANs)
    to

    augment the original images and GoogLeNet as the input, the proposed model was
    able to

    achieve the top average identiﬁcation accuracy of 94.33%. The model was further
    improved

    by adjusting the hyper-parameters, modifying the architecture of the convolutional
    neural

    networks, and experimenting with different GANs. The use of DCGAN to augment

    the dataset not only increased its size but also improved its diversity, leading
    to better

    generalization of the recognition model. In addition, the authors of [114] proposed
    the use

    of a deep convolutional generative adversarial network (DCGAN) to augment an original

    dataset and trained a convolutional neural network (CNN) in the task of regression
    by

    utilizing the DCGAN to generate synthetic images that were realistic enough to
    be included

    in the training set. They employed a two-stage scheme where the baseline CNN,
    trained

    with the original dataset, was utilized to predict the regression vectors for
    each image

    generated by the DCGAN. These regression vectors served as the ground truth for
    the

    augmented dataset, enabling the CNN to make more accurate predictions.

    7. Future Challenges and Opportunities in the Agricultural Domain

    Deep learning has the potential to revolutionize the agricultural industry by
    enabling

    more efﬁcient crop production, precision agriculture, and improved crop monitoring
    and

    forecasting. However, there are several challenges that need to be addressed to
    fully

    realize the potential of deep learning in agriculture. One major challenge is
    the lack of

    high-quality labeled data in the ﬁeld of agriculture. This can be addressed by
    developing

    new data collection methods and creating large labeled datasets that can be used
    to train

    deep-learning models [114]. Another challenge is the high computational cost associated

    with deep learning, which can make it difﬁcult to implement these models in resource-

    constrained environments, such as rural areas [115].

    Additionally, there is a need for deep-learning models in agriculture to attain
    robust-

    ness and adaptability to different environments, crop types, imaging conditions,
    and sensor

    modalities. This requires the development of models that can be generalized well
    across

    different scenarios and are robust to variations in the data [116,117]. Furthermore,
    as the

    data in the agricultural domain is often incomplete, noisy, or corrupted, there
    is a need for

    methods that can handle missing or incomplete data [118]. In recent years, research
    on

    robust deep-learning techniques, such as robust optimization, adversarial training
    [118],

    and meta-learning [119,120], has been undertaken to address this challenge, but
    more

    research is still needed in this area.

    Another important challenge is the need for deep-learning models in agriculture

    to be interpretable and explainable, as this is essential for decision making
    and to gain

    trust from stakeholders. There is a growing interest in developing methods that
    can

    provide insight into the inner workings of deep-learning models, such as explainable
    AI

    techniques—for instance, Local Interpretable Model-Agnostic Explanations (LIME)
    [121]

    and Shapley Additive Explanations (SHAP) [122]—and interpretable deep learning—for

    instance, decision trees and rule-based systems [123]. Moreover, the integration
    of multiple

    modalities of data, such as image, sensor, and weather data, is crucial to improving
    the

    performance of deep-learning models in agriculture. There is a need for multistream
    neural

    Agriculture 2023, 13, 540

    17 of 22

    networks, such as those based on attention [124], that can handle multiple modalities
    of

    data and provide a more comprehensive understanding of the agricultural system.

    Few-shot learning is a form of machine learning that allows models to be generalized
    to

    previously unseen classes with a small number of examples. This is beneﬁcial in
    agriculture,

    as it allows such models to learn more quickly and accurately from a limited amount
    of

    data. Furthermore, it is more data-efﬁcient, meaning that fewer data points are
    required to

    train the model [125].

    In conclusion, deep learning has the potential to revolutionize the agricultural
    industry,

    but there are several areas that need to be addressed to fully realize its potential.
    These

    include the need for robustness, interpretability, integration of multiple modalities
    of data,

    and few-shot learning. Further research in these areas is crucial to overcoming
    these

    challenges and fully harnessing the power of deep learning in agriculture.

    8. Conclusions and Future Work

    The primary aim of the present study was to provide an overview of the recent
    ad-

    vancements linked to DL in the agricultural sector. This study employed a comprehensive

    review of approaches linked to agricultural DL, including disease detection, yield
    predic-

    tion, and weed prediction, in studies published between 2016 and early 2022. The
    key

    ﬁndings of this paper indicated that a range of DL tools, employed for counting
    fruit,

    managing water, crop management, soil management, weed detection, seed classiﬁcation,

    yield prediction, disease detection, and even harvesting, have been identiﬁed.
    It was also

    revealed that, despite the employment of DL processes in agriculture, there are
    certain

    obstacles that come with the use of this technology. It involves difﬁculties such
    as the

    compilation of datasets, the time necessary for staff training, and the presence
    of DL experts

    to ensure high production. Furthermore, system development and hardware requirements,

    as well as the deployment of large models and software on small devices, such
    as smart-

    phones, may have impacts on system efﬁciency. Thus, it can be concluded that,
    with the

    support of the most recent prediction analyses and tools, the application of DL
    methods

    has assisted the agriculture industry in growing and developing. It can be noted
    that DL

    has great potential in the ﬁeld of agriculture. However, the high cost of hardware
    and

    software makes its application very limited. Therefore, there is a need to work
    on research

    and development around cost-effective DL methods in the future to enhance large-scale

    applications. Furthermore, DL methods are limited in terms of accuracy and effectiveness.

    Thus, more research is needed in this direction to enhance the accuracy and effectiveness
    of

    DL methods.

    The availability of computational capacity is yet another barrier that inhibits
    the

    implementation of DL in agriculture. The training of models necessitates ever-increasing

    amounts of computing resources due to the growing number of datasets, as well
    as the

    increasing complexity of deep-learning neural networks. It is very important that
    the

    performance of graphics processing units (GPUs) and central processing units (CPUs)

    continues to improve, as this is a very important accelerator for the widespread
    popularity

    of deep learning. In addition, the development of DL has been sped up by the availability
    of

    cloud computing services, such as the Google Cloud Platform, offered by private
    businesses.

    However, because of stringent requirements regarding computation capacity, current
    uses

    of DL in agriculture are typically ofﬂine. This means that the collection and
    analysis of

    images of farmland is undertaken in an asynchronous manner. Consequently, companies

    have paid some attention to this issue.

    Funding: This research received no external funding.

    Data Availability Statement: The data used are included within the manuscript.

    Conﬂicts of Interest: The author declares no conﬂict of interest.

    Agriculture 2023, 13, 540

    18 of 22

    References

    1.

    Santos, L.; Santos, F.; Mendes, J.; Costa, P.; Lima, J.; Reis, R.; Shinde, P.
    Path planning aware of robot’s center of mass for steep

    slope vineyards. Robotica 2020, 38, 684–698. [CrossRef]

    2.

    Patil, K.A.; Kale, N.R. A model for smart agriculture using IoT. In Proceedings
    of the 2016 International Conference on Global

    Trends in Signal Processing, Information Computing and Communication (ICGTSPICC),
    Jalgaon, India, 22–24 December 2016;

    pp. 543–545.

    3.

    Atzberger, C. Advances in remote sensing of agriculture: Context description,
    existing operational monitoring systems and major

    information needs. Remote Sens. 2013, 5, 949–981. [CrossRef]

    4.

    Santos, L.; Ferraz, N.; dos Santos, F.N.; Mendes, J.; Morais, R.; Costa, P.; Reis,
    R. Path planning aware of soil compaction for steep

    slope vineyards. In Proceedings of the 2018 IEEE International Conference on Autonomous
    Robot Systems and Competitions

    (ICARSC), Torres Vedras, Portugal, 25–27 April 2018. [CrossRef]

    5.

    Dhanaraju, M.; Chenniappan, P.; Ramalingam, K.; Pazhanivelan, S.; Kaliaperumal,
    R. Smart Farming: Internet of Things

    (IoT)-Based Sustainable Agriculture. Agriculture 2022, 12, 1745. [CrossRef]

    6.

    Walter, A.; Finger, R.; Huber, R.; Buchmann, N. Opinion: Smart farming is key
    to developing sustainable agriculture. Proc. Natl.

    Acad. Sci. USA 2017, 114, 6148–6150. [CrossRef] [PubMed]

    7.

    Schmidhuber, J. Deep learning in neural networks: An overview. Neural Netw. 2015,
    61, 85–117. [CrossRef] [PubMed]

    8.

    Kamilaris, A.; Prenafeta-Boldú, F.X. A review of the use of convolutional neural
    networks in agriculture. J. Agric. Sci. 2018, 156,

    312–322. [CrossRef]

    9.

    Bouguettaya, A.; Zarzour, H.; Kechida, A.; Taberkit, A.M. A survey on deep learning-based
    identiﬁcation of plant and crop

    diseases from UAV-based aerial images. In Cluster Computing; Springer Science
    and Business Media LLC: Berlin/Heidelberg,

    Germany, 2022. [CrossRef]

    10.

    Khan, A.; Vibhute, A.D.; Mali, S.; Patil, C.H. A systematic review on hyperspectral
    imaging technology with a machine and deep

    learning methodology for agricultural applications. In Ecological Informatics;
    Elsevier BV: Amsterdam, The Netherlands, 2022;

    Volume 69, p. 101678.

    11.

    Kashyap, P. Machine Learning for Decision-Makers: Cognitive Computing Fundamentals
    for Better Decision Making; Apress: Bangalore,

    India, 2017; pp. 227–228.

    12.

    Magomadov, V.S. Deep Plearning and its role in smart agriculture. J. Phys. Conf.
    Ser. 2019, 1399, 044109. [CrossRef]

    13.

    Graves, A.; Schmidhuber, J. Framewise phoneme classiﬁcation with bidirectional
    LSTM and other neural network architectures.

    Neural Netw. 2005, 18, 602–610. [CrossRef]

    14.

    Jain, A.; Zamir, A.R.; Savarese, S.; Saxena, A. Structural-run: Deep learning
    on Spatio-temporal graphs. In Proceedings of the

    IEEE Conference on Computer Vision and Pattern Recognition, Las Vegas, NV, USA,
    27–30 June 2016; pp. 5308–5317.

    15.

    Ren, C.; Kim, D.K.; Jeong, D. A survey of deep learning in agriculture: Techniques
    and their applications. J. Inf. Process. Syst.

    2020, 16, 1015–1033.

    16.

    Santos, L.; Santos, F.N.; Oliveira, P.M.; Shinde, P. Deep learning applications
    in agriculture: A short review. In Proceedings of

    the Fourth Iberian Robotics Conference: Advances in Robotics, Robot 2019: Porto,
    Portugal, 20–22 November 2019; Silva, M.F.,

    Lima, J.L., Reis, L.P., Sanfeliu, A., Tardioli, D., Eds.; Springer: Cham, Switzerland;
    pp. 139–151. Available online: https:

    //doi.org/10.1007/978-3-030-35990-4_12 (accessed on 23 February 2022). [CrossRef]

    17.

    Kamilaris, A.; Prenafeta-Boldú, F.X. Deep learning in agriculture: A survey. Comput.
    Electron. Agric. 2018, 147, 70–90. Available

    online: https://doi.org/10.1016/j.compag.2018.02.016 (accessed on 23 February
    2022). [CrossRef]

    18.

    Thai-Nghe, N.; Tri, N.T.; Hoa, N.H. Deep Learning for Rice Leaf Disease Detection
    in Smart Agriculture. In Artiﬁcial Intelligence in

    Data and Big Data Processing; Springer International Publishing: Berlin/Heidelberg,
    Germany, 2022; pp. 659–670.

    19.

    Traditional Agriculture: An Efﬁcient and Sustainable Farming Method. Stories.pinduoduo-global.com.
    2021. Available online:

    https://stories.pinduoduo-global.com/agritech-hub/traditionalagriculture#:~:text=Traditional%20agriculture%20can%20be%

    20deﬁned,cultural%20beliefs%20of%20the%20farmers (accessed on 23 February 2022).

    20.

    Shaila, M.; Begum, N. Ancient farming methods of seed storage and pest management
    practices in India—A review. Plant Arch.

    2021, 21, 499–509.

    21.

    Dargan, S.; Kumar, M.; Ayyagari, M.R.; Kumar, G. A survey of deep learning and
    its applications: A new paradigm to machine

    learning. Arch. Comput. Methods Eng. 2020, 27, 1071–1092. [CrossRef]

    22.

    LeCun, Y.; Bengio, Y.; Hinton, G. Deep learning. Nature 2015, 521, 436–444. [CrossRef]
    [PubMed]

    23.

    Abdullahi, H.S.; Sheriff, R.; Mahieddine, F. Convolution neural network in precision
    agriculture for plant image recognition and

    classiﬁcation. In 2017 Seventh International Conference on Innovative Computing
    Technology (INTECH), Luton, UK, 16–18 August 2017;

    IEEE: Piscataway, NJ, USA, 2017; Volume 10, pp. 256–272.

    24.

    Ajit, A.; Acharya, K.; Samanta, A. A review of convolutional neural networks.
    In Proceedings of the 2020 International Conference

    on Emerging Trends in Information Technology and Engineering (ic-ETITE), Vellore,
    India, 24–25 February 2020.

    25.

    Zaremba, W.; Sutskever, I.; Vinyals, O. Recurrent neural network regularization.
    arXiv 2014, arXiv:1409.2329. in press.

    26.

    Chen, S.W.; Shivakumar, S.S.; Dcunha, S.; Das, J.; Okon, E.; Qu, C.; Taylor, C.J.;
    Kumar, V. Counting apples and oranges with deep

    learning: A data-driven approach. IEEE Robot. Autom. Lett. 2017, 2, 781–788. [CrossRef]

    27.

    Rahnemoonfar, M.; Sheppard, C. Deep count: Fruit counting based on deep simulated
    learning. Sensors 2017, 17, 905. [CrossRef]

    Agriculture 2023, 13, 540

    19 of 22

    28.

    Apolo-Apolo, O.E.; Martínez-Guanter, J.; Egea, G.; Raja, P.; Pérez-Ruiz, M. Deep
    learning techniques for estimation of the yield

    and size of citrus fruits using a UAV. Eur. J. Agron. 2020, 115, 126030. [CrossRef]

    29.

    Sa, I.; Ge, Z.; Dayoub, F.; Upcroft, B.; Perez, T.; McCool, C. Deepfruits: A fruit
    detection system using deep neural networks.

    Sensors 2016, 16, 1222. [CrossRef]

    30.

    Krizhevsky, A.; Sutskever, I.; Hinton, G.E. Imagenet classiﬁcation with deep convolutional
    neural networks. In Advances in Neural

    Information Processing Systems, Proceedings of the Neural Information Processing
    Systems Conference, Lake Tahoe, NV, USA, 3–6 December

    2012; Neural Information Processing Systems Foundation, Inc.: Ljubljana, Slovenia,
    2012; pp. 1097–1105.

    31.

    Bargoti, S.; Underwood, J. Deep fruit detection in orchards. In Proceedings of
    the 2017 IEEE International Conference on Robotics

    and Automation (ICRA), Singapore, 29 May–3 June 2017.

    32.

    Fu, L.; Feng, Y.; Elkamil, T.; Liu, Z.; Li, R.; Cui, Y. Image recognition method
    of multi-cluster kiwifruit in ﬁeld based on

    convolutional neural networks. Nongye Gongcheng Xuebao/Trans. Chin. Soc. Agric.
    Eng. 2018, 34, 205–211.

    33.

    Katarzyna, R.; Paweł, M. A vision-based method utilizing deep convolutional neural
    networks for fruit variety classiﬁcation in

    uncertainty conditions of retail sales. Appl. Sci. 2019, 9, 3971. [CrossRef]

    34.

    Villacrés, J.F.; Auat Cheein, F. Detection and characterization of cherries: A
    deep learning usability case study in Chile. Agronomy

    2020, 10, 835. [CrossRef]

    35.

    Chung, D.T.P.; Van Tai, D. A fruits recognition system based on a modern deep
    learning technique. J. Phys. Conf. Ser. 2019,

    1327, 012050. [CrossRef]

    36.

    Wang, S.H.; Chen, Y. Fruit category classiﬁcation via an eight-layer convolutional
    neural network with parametric rectiﬁed linear

    unit and dropout technique. Multim. Tools Appl. 2018, 79, 15117–15133. [CrossRef]

    37.

    Kestur, R.; Meduri, A.; Narasipura, O. MangoNet: A deep semantic segmentation
    architecture for a method to detect and count

    mangoes in an open orchard. Eng. Appl. Artif. Intell. 2019, 77, 59–69. [CrossRef]

    38.

    Santos, T.T.; de Souza, L.L.; dos Santos, A.A.; Avila, S. Grape detection, segmentation,
    and tracking using deep neural networks

    and three-dimensional association. Comput. Electron. Agric. 2020, 170, 105247.
    [CrossRef]

    39.

    Chen, H.; Chen, A.; Xu, L.; Xie, H.; Qiao, H.; Lin, Q.; Cai, K. A deep learning
    CNN architecture applied in smart near-infrared

    analysis of water pollution for agricultural irrigation resources. Agric. Water
    Manag. 2020, 240, 106303. [CrossRef]

    40.

    Garg, D.; Khan, S.; Alam, M. Integrative use of IoT and deep learning for agricultural
    applications. In Proceedings of ICETIT

    2019: Emerging Trends in Information Technology; Springer: Cham, Switzerland,
    2020; pp. 521–531.

    41.

    Mohan, P.; Patil, K.K. Deep learning based weighted SOM to forecast weather and
    crop prediction for agriculture application. Int.

    J. Intell. Eng. Syst. 2018, 11, 167–176. [CrossRef]

    42.

    Yang, X.; Sun, M. A survey on deep learning in crop planting. IOP Conf. Ser. Mater.
    Sci. Eng. 2019, 490, 062053. [CrossRef]

    43.

    Dharani, M.K.; Thamilselvan, R.; Natesan, P.; Kalaivaani, P.C.D.; Santhoshkumar,
    S. Review Pon crop prediction using deep

    learning techniques. J. Phys. Conf. Ser. 2021, 1767, 012026. [CrossRef]

    44.

    Zheng, Y.Y.; Kong, J.L.; Jin, X.B.; Wang, X.Y.; Su, T.L.; Zuo, M. CropDeep: The
    crop vision dataset for deep-learning-based

    classiﬁcation and detection in precision agriculture. Sensors 2019, 19, 1058.
    [CrossRef]

    45.

    Lottes, P.; Behley, J.; Chebrolu, N.; Milioto, A.; Stachniss, C. Robust joint
    stem detection and crop-weed classiﬁcation using image

    sequences for plant-speciﬁc treatment in precision farming. J. Field Robot. 2020,
    37, 20–34. [CrossRef]

    46.

    Lottes, P.; Behley, J.; Milioto, A.; Stachniss, C. Fully convolutional networks
    with sequential information for robust crop and weed

    detection in precision farming. IEEE Robot. Autom. Lett. 2018, 3, 2870–2877. [CrossRef]

    47.

    Chavan, T.R.; Nandedkar, A.V. AgroAVNET for crops and weeds classiﬁcation: A step
    forward in automatic farming. Comput.

    Electron. Agric. 2018, 154, 361–372. [CrossRef]

    48.

    Suh, H.K.; Ijsselmuiden, J.; Hofstee, J.W.; van Henten, E.J. Transfer learning
    for the classiﬁcation of sugar beet and volunteer

    potato under ﬁeld conditions. Biosyst. Eng. 2018, 174, 50–65. [CrossRef]

    49.

    Meng, S.; Wang, X.; Hu, X.; Luo, C.; Zhong, Y. Deep learning-based crop mapping
    in the cloudy season using one-shot

    hyperspectral satellite imagery. Comput. Electron. Agric. 2021, 186, 106188. [CrossRef]

    50.

    Cai, Y.; Zheng, W.; Zhang, X.; Zhangzhong, L.; Xue, X. Research on soil moisture
    prediction model based on deep learning.

    PLoS ONE 2019, 14, e0214508. [CrossRef]

    51.

    Yashwanth, M.; Chandra, M.L.; Pallavi, K.; Showkat, D.; Kumar, P.S. Agriculture
    automation using deep learning methods

    implemented using keras. In Proceedings of the 2020 IEEE International Conference
    for Innovation in Technology (INOCON),

    Bangalore, India, 6–8 November 2020.

    52.

    Tseng, D.; Wang, D.; Chen, C.; Miller, L.; Song, W.; Viers, J.; Vougioukas, S.;
    Carpin, S.; Ojea, J.A.; Goldberg, K. Towards

    automating precision irrigation: Deep learning to infer local soil moisture conditions
    from synthetic aerial agricultural images.

    In Proceedings of the 2018 IEEE 14th International Conference on Automation Science
    and Engineering (CASE), Munich, Germany,

    20–24 August 2018; pp. 284–291.

    53.

    Westwood, J.H.; Charudattan, R.; Duke, S.O.; Fennimore, S.A.; Marrone, P.; Slaughter,
    D.C.; Swanton, C.; Zollinger, R. Weed

    management in 2050: Perspectives on the future of weed science. Weed Sci. 2018,
    66, 275–285. [CrossRef]

    54.

    Mishra, A.M.; Gautam, V. Weed species identiﬁcation in different crops using precision
    weed management: A review. Proc. CEUR

    Workshop 2021, 180–194. Available online: https://www.semanticscholar.org/paper/Weed-Species-Identiﬁcation-in-Different-

    Crops-Weed-Mishra-Gautam/8710e1a04eada39809b159ea8650f4c639c9bf19 (accessed on
    3 July 2022).

    Agriculture 2023, 13, 540

    20 of 22

    55.

    Gulzar, Y.; Hamid, Y.; Soomro, A.B.; Alwan, A.A.; Journaux, L. A convolution neural
    network-based seed classiﬁcation system.

    Symmetry 2020, 12, 2018. [CrossRef]

    56.

    Sharma, A.; Jain, A.; Gupta, P.; Chowdary, V. Machine learning applications for
    precision agriculture: A comprehensive review.

    IEEE Access 2020, 9, 4843–4873. [CrossRef]

    57.

    Saleem, M.H.; Potgieter, J.; Arif, K.M. Plant disease detection and classiﬁcation
    by deep learning. Plants 2019, 8, 468. [CrossRef]

    58.

    Amara, J.; Bouaziz, B.; Algergawy, A. A deep learning-based approach for banana
    leaf diseases classiﬁcation. In Proceedings of

    the Datenbanksysteme für Business, Technologie und Web (BTW 2017)-Workshopband,
    Stuttgart, Germany, 6–7 March 2017;

    Gesellschaft für Informatik e.V.: Bonn, Germany, 2017; pp. 79–88.

    59.

    Dipali, M.; Deepa, D. Automation, and integration of growth monitoring in plants
    (with disease prediction) and crop prediction.

    Mater. Today Proc. 2021, 43, 3922–3927.

    60.

    Akash, S.; Malik, A. A hybrid model for the classiﬁcation of sunﬂower diseases
    using deep learning. In Proceedings of the 2021

    2nd International Conference on Intelligent Engineering and Management (ICIEM),
    London, UK, 28–30 April 2021; pp. 58–62.

    61.

    Ahmed, A.A.; Reddy, G.H. A mobile-based system for detecting plant leaf diseases
    using deep learning. AgriEngineering 2021, 3,

    478–493. [CrossRef]

    62.

    Pallagani, V.; Khandelwal, V.; Chandra, B.; Udutalapally, V.; Das, D.; Mohanty,
    S.P. DCrop: A deep-learning-based framework for

    accurate prediction of diseases of crops in smart agriculture. In Proceedings
    of the 2019 IEEE International Symposium on Smart

    Electronic Systems (iSES) (Formerly iNiS), Rourkela, India, 16–18 December 2019;
    pp. 29–33.

    63.

    Sladojevic, S.; Arsenovic, M.; Anderla, A.; Culibrk, D.; Stefanovic, D. Deep neural
    networks based recognition of plant diseases by

    leaf image classiﬁcation. Comput. Intell. Neurosci. 2016, 2016, 3289801. [CrossRef]
    [PubMed]

    64.

    Arivazhagan, S.; Shebiah, R.N.; Ananthi, S.; Varthini, S.V. Detection of unhealthy
    region of plant leaves and classiﬁcation of plant

    leaf diseases using texture features. Agric. Eng. Int. CIGR J. 2013, 15, 211–217.

    65.

    Chen, J.; Chen, J.; Zhang, D.; Sun, Y.; Nanehkaran, Y.A. Using deep transfer learning
    for image-based plant disease identiﬁcation.

    Comput. Electron. Agric. 2020, 173, 105393. [CrossRef]

    66.

    Sharma, P.; Berwal, Y.P.S.; Ghai, W. Performance analysis of deep learning CNN
    models for disease detection in plants using

    image segmentation. Inf. Process. Agric. 2020, 7, 566–574. [CrossRef]

    67.

    Atila, Ü.; Uçar, M.; Akyol, K.; Uçar, E. Plant leaf disease classiﬁcation using
    EfﬁcientNet deep learning model. Ecol. Inform. 2021,

    61, 101182. [CrossRef]

    68.

    Kaur, P.; Harnal, S.; Tiwari, R.; Upadhyay, S.; Bhatia, S.; Mashat, A.; Alabdali,
    A.M. Recognition of leaf disease using hybrid

    convolutional neural network by applying feature reduction. Sensors 2022, 22,
    575. [CrossRef]

    69.

    Ji, M.; Zhang, L.; Wu, Q. Automatic grape leaf diseases identiﬁcation via UnitedModel
    based on multiple convolutional neural

    networks. Inf. Process. Agric. 2020, 7, 418–426. [CrossRef]

    70.

    Gadekallu, T.R.; Rajput, D.S.; Reddy, M.P.K.; Lakshmanna, K.; Bhattacharya, S.;
    Singh, S.; Jolfaei, A.; Alazab, M. A novel

    PCA–whale optimization-based deep neural network model for classiﬁcation of tomato
    plant diseases using GPU. J. Real-Time

    Image Process. 2021, 18, 1383–1396. [CrossRef]

    71.

    Azimi, S.; Kaur, T.; Gandhi, T.K. A deep learning approach to measure stress level
    in plants due to nitrogen deﬁciency. Measurement

    2021, 173, 108650. [CrossRef]

    72.

    Joshi, R.C.; Kaushik, M.; Dutta, M.K.; Srivastava, A.; Choudhary, N. VirLeafNet:
    Automatic analysis and viral disease diagnosis

    using deep-learning in Vigna mungo plant. Ecol. Inform. 2021, 61, 101197. [CrossRef]

    73.

    Kavitha, A. Deep Learning for Smart Agriculture.

    Int.

    J. Eng.

    Res.

    Technol.

    2021, 9.

    Available online: https://www.

    semanticscholar.org/paper/Deep-Learning-for-Smart-Agriculture-Kavitha/0a272722fe4838cce5af0bb907310bf76927406d
    (ac-

    cessed on 3 July 2022).

    74.

    Josephine, B.; Ramya, K.; Rao, K.V.S.N.; Kuchibhotla, P.; Venkata, K.; Rahamathulla,
    S. Crop yield prediction using machine

    learning. Int. J. Sci. Technol. Res. 2020, 9. Available online: http://www.ijstr.org/paper-references.php?ref=IJSTR-0120-29576

    (accessed on 3 July 2022).

    75.

    Khaki, S.; Wang, L. Crop yield prediction using deep neural networks. Front. Plant
    Sci. 2019, 10, 621. Available online:

    https://doi.org/10.3389/fpls.2019.00621 (accessed on 23 February 2022). [CrossRef]

    76.

    Deepika, P.; Kaliraj, S. A survey on pest and disease monitoring of crops. In
    Proceedings of the 2021 3rd International Conference

    on Signal Processing and Communication (ICPSC), Coimbatore, India, 13–14 May 2021;
    Available online: https://doi.org/10.110

    9/icspc51351.2021.9451787 (accessed on 23 February 2022).

    77.

    Ale, L.; Sheta, A.; Li, L.; Wang, Y.; Zhang, N. Deep learning based plant disease
    detection for smart agriculture. In Proceedings

    of the 2019 IEEE Globecom Workshops (GC Wkshps), Waikoloa, HI, USA, 9–13 December
    2019; Available online: https:

    //doi.org/10.1109/gcwkshps45667.2019.9024439 (accessed on 23 February 2022).

    78.

    Zhu, N.; Liu, X.; Liu, Z.; Hu, K.; Wang, Y.; Tan, J.; Huang, M.; Zhu, Q.; Ji,
    X.; Jiang, Y.; et al. Deep learning for smart agriculture:

    Concepts, tools, applications, and opportunities. Int. J. Agric. Biol. Eng. 2018,
    11, 32–44. [CrossRef]

    79.

    Deep Learning for Image-Based Plant Disease Detection.

    Let’s Nurture—An IT Company Nurturing Ideas into Reality.

    2022. Available online: https://www.letsnurture.com/blog/using-deep-learning-for-image-based-plant-disease-detection.html

    (accessed on 23 February 2022).

    80.

    Zhao, Q.; Koch, C. Learning saliency-based visual attention: A Review. Signal
    Process. 2013, 93, 1401–1407. [CrossRef]

    Agriculture 2023, 13, 540

    21 of 22

    81.

    Kümmerer, M.; Theis, L.; Bethge, M. Deep Gaze I: Boosting saliency prediction
    with feature maps trained on ImageNet. In

    Proceedings of the 2015 International Conference on Learning Representations (ICLR),
    San Diego, CA, USA, 8 May 2014; Available

    online: https://pure.mpg.de/pubman/faces/ViewItemOverviewPage.jsp?itemId=item_2160776
    (accessed on 24 February 2022).

    82.

    Shrikumar, A.; Greenside, P.; Kundaje, A. Reverse-complement parameter sharing
    improves deep learning models for genomics.

    bioRxiv 2017, in press.

    83.

    Springenberg, J.T.; Dosovitskiy, A.; Brox, T.; Riedmiller, M. Striving for simplicity:
    The all convolutional net. arXiv. 2015. in press.

    Available online: https://arxiv.org/abs/1412.6806 (accessed on 24 February 2022).

    84.

    Zeiler, M.D.; Fergus, R. Visualizing and understanding Convolutional Networks.
    In Proceedings of Computer Vision–ECCV

    2014: 13th European Conference, Part I 13, Zurich, Switzerland, 6–12 September
    2014; Springer International Publishing: Cham,

    Switzerland, 2014; pp. 818–833.

    85.

    Zhou, B.; Khosla, A.; Lapedriza, A.; Oliva, A.; Torralba, A. Learning deep features
    for discriminative localization. In Proceedings

    of the 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR),
    Las Vegas, NV, USA, 26 June–1 July 2016.

    86.

    Bach, S.; Binder, A.; Montavon, G.; Klauschen, F.; Müller, K.-R.; Samek, W. On
    pixel-wise explanations for non-linear classiﬁer

    decisions by layer-wise relevance propagation. PLoS ONE 2015, 10, e0130140. [CrossRef]

    87.

    Uzal, L.C.; Grinblat, G.L.; Namías, R.; Larese, M.G.; Bianchi, J.S.; Morandi,
    E.N.; Granitto, P.M. Seed-per-pod estimation for plant

    breeding using deep learning. Comput. Electron. Agric. 2018, 150, 196–204. [CrossRef]

    88.

    Nkemelu, D.K.; Omeiza, D.; Lubalo, N. Deep convolutional neural network for plant
    seedlings classiﬁcation. arXiv. 2018. in press.

    Available online: https://arxiv.org/abs/1811.08404?source=post_page (accessed
    on 24 February 2022).

    89.

    Amiryouseﬁ, M.R.; Mohebbi, M.; Tehranifar, A. Pomegranate seed clustering by machine
    vision. Food Sci. Nutr. 2017, 6, 18–26.

    [CrossRef] [PubMed]

    90.

    Sujatha, R.; Chatterjee, J.M.; Jhanjhi, N.Z.; Brohi, S.N. Performance of deep
    learning vs machine learning in plant leaf disease

    detection. Microprocess. Microsyst. 2021, 80, 103615. [CrossRef]

    91.

    Arnal Barbedo, J.G. Plant disease identiﬁcation from individual lesions and spots
    using deep learning. Biosyst. Eng. 2019, 180,

    96–107. [CrossRef]

    92.

    Liu, P.; Mahmood, T.; Khan, Q. Multi-attribute decision-making based on prioritized
    aggregation operator under hesitant

    intuitionistic fuzzy linguistic environment. Symmetry 2017, 9, 270. [CrossRef]

    93.

    Bresilla, K.; Perulli, G.D.; Boini, A.; Morandi, B.; Grappadelli, L.; Manfrini,
    L. Single-shot convolution neural networks for

    real-time fruit detection within the tree. Front. Plant Sci. 2019, 10, 611. [CrossRef]
    [PubMed]

    94.

    Altaheri, H.; Alsulaiman, M.; Muhammad, G. Date fruit classiﬁcation for robotic
    harvesting in a natural environment using deep

    learning. IEEE Access 2019, 7, 117115–117133. [CrossRef]

    95.

    Meshram, V.; Patil, K.; Meshram, V.; Hanchate, D.; Ramkteke, S.D. Machine learning
    in agriculture domain: A state-of-art survey.

    Artif. Intell. Life Sci. 2021, 1, 100010. [CrossRef]

    96.

    Lu, S.; Chen, W.; Zhang, X.; Karkee, M. Canopy-attention-YOLOv4-based immature/mature
    apple fruit detection on dense-foliage

    tree architectures for early crop load estimation. Comput. Electron. Agric. 2022,
    193, 106696. [CrossRef]

    97.

    Lyu, S.; Li, R.; Zhao, Y.; Li, Z.; Fan, R.; Liu, S. Green citrus detection and
    counting in orchards based on YOLOv5-CS and AI edge

    system. Sensors 2022, 22, 576. [CrossRef]

    98.

    Khan, R.; Dhingra, N.; Bhati, N. Role of Artiﬁcial Intelligence in Agriculture:
    A Comparative Study. In Transforming Management

    with AI, Big-Data, and IoT; Springer International Publishing: Cham, Switzerland,
    2022; pp. 73–83.

    99.

    Wang, C.; Liu, B.; Liu, L.; Zhu, Y.; Hou, J.; Liu, P.; Li, X. A review of deep
    learning used in the hyperspectral image analysis for

    agriculture. Artif. Intell. Rev. 2021, 54, 5205–5253. [CrossRef]

    100. Coulibaly, S.; Kamsu-Foguem, B.; Kamissoko, D.; Traore, D. Deep neural networks
    with transfer learning in Millet crop images.

    Comput. Ind. 2019, 108, 115–120. [CrossRef]

    101. Sahni, V.; Srivastava, S.; Khan, R. Modelling techniques to improve the quality
    of food using artiﬁcial intelligence. J. Food Qual.

    2021, 2021, 2140010. [CrossRef]

    102. Khan, R.; Tyagi, N.; Chauhan, N. Safety of food and food warehouse using
    VIBHISHAN. J. Food Qual. 2021, 2021, 1328332.

    [CrossRef]

    103. Kaya, A.; Keceli, A.S.; Catal, C.; Yalic, H.Y.; Temucin, H.; Tekinerdogan,
    B. Analysis of transfer learning for deep neural network

    based plant classiﬁcation models. Comput. Electron. Agric. 2019, 158, 20–29. [CrossRef]

    104. Sharma, M.; Nath, K.; Sharma, R.K.; Kumar, C.J.; Chaudhary, A. Ensemble Averaging
    of Transfer Learning Models for Identiﬁca-

    tion of Nutritional Deﬁciency in Rice Plant. Electronics 2022, 11, 148. [CrossRef]

    105. Argüeso, D.; Picon, A.; Irusta, U.; Medela, A.; San-Emeterio, M.G.; Bereciartua,
    A.; Alvarez-Gila, A. Few-shot learning approach

    for plant disease classiﬁcation using images taken in the ﬁeld. Comput. Electron.
    Agric. 2020, 175, 105542. [CrossRef]

    106. Zhong, F.M.; Chen, Z.K.; Zhang, Y.C.; Xia, F. Zero-and few-shot learning
    for diseases recognition of Citrus aurantium L. using

    conditional adversarial autoencoders. Comput. Electron. Agric. 2020, 179, 105828.
    [CrossRef]

    107. Jiang, H.H.; Zhang, C.Y.; Qiao, Y.L.; Zhang, Z.; Zhang, W.J.; Song, C.Q.
    CNN feature-based graph convolutional network for

    weed and crop recognition in smart farming. Comput. Electron. Agric. 2020, 174,
    105450. [CrossRef]

    108. Khaki, S.; Pham, H.; Han, Y.; Kuhl, A.; Kent, W.; Wang, L. Deepcorn: A semi-supervised
    deep learning method for high-throughput

    image-based corn kernel counting and yield estimation. Knowl. Based Syst. 2021,
    218, 106874. [CrossRef]

    Agriculture 2023, 13, 540

    22 of 22

    109. Sa, I.; Chen, Z.; Popovi´c, M.; Khanna, R.; Liebisch, F.; Nieto, J.; Siegwart,
    R. WeedNet: Dense semantic weed classiﬁcation using

    multispectral images and MAV for smart farming. IEEE Robot. Autom. Lett. 2017,
    3, 588–595. [CrossRef]

    110. Sa, I.; Popovi´c, M.; Khanna, R.; Chen, Z.; Lottes, P.; Liebisch, F.; Nieto,
    J.; Stachniss, C.; Walter, A.; Siegwart, R. WeedMap: A

    large-scale semantic weed mapping framework using aerial multispectral imaging
    and deep neural network for precision farming.

    Remote Sens. 2018, 10, 1423. [CrossRef]

    111. Jiao, L.; Dong, S.; Zhang, S.; Xie, C.; Wang, H. AF-RCNN: An anchor-free
    convolutional neural network for multi-categories

    agricultural pest detection. Comput. Electron. Agric. 2020, 174, 105522. [CrossRef]

    112. Eunice, J.; Popescu, D.E.; Chowdary, M.K.; Hemanth, J. Deep learning-based
    leaf disease detection in crops using images for

    agricultural applications. Agronomy 2022, 12, 2395.

    113. Wu, Q.; Chen, Y.; Meng, J. DCGAN-based data augmentation for tomato leaf
    disease identiﬁcation. IEEE Access 2020, 8,

    98716–98728. [CrossRef]

    114. Hammouch, H.; El-Yacoubi, M.; Qin, H.; Berrahou, A.; Berbia, H.; Chikhaoui,
    M. A two-stage deep convolutional generative

    adversarial network-based data augmentation scheme for agriculture image regression
    tasks. In Proceedings of the 2021

    International Conference on Cyber-Physical Social Intelligence (ICCSI), Beijing,
    China, 18–20 December 2021.

    115. Sourav, A.I.; Emanuel, A.W.R. Recent Trends of Big Data in Precision Agriculture:
    A Review. In IOP Conference Series: Materials

    Science and Engineering; IOP Publishing: Bristol, UK, 2021; Volume 1096, p. 012081.

    116. Bharman, P.; Ahmad Saad, S.; Khan, S.; Jahan, I.; Ray, M.; Biswas, M. Deep
    Learning in Agriculture: A Review. Asian J. Res.

    Comput. Sci. 2022, 13, 28–47. [CrossRef]

    117. Goodfellow, I.; Bengio, Y.; Courville, A. Deep Learning; MIT Press: Cambridge,
    MA, USA, 2014.

    118. Liu, J.; Cheng, L.; Yan, S. Deep learning with noisy labels. In Proceedings
    of the IEEE Conference on Computer Vision and Pattern

    Recognition, Long Beach, CA, USA, 16–20 June 2019.

    119. Madry, A.; Makelov, A.; Schmidt, L.; Tsipras, D.; Vladu, A. Towards deep
    learning models resistant to adversarial attacks. arXiv

    2018, arXiv:1706.06083. in press.

    120. Finn, C.; Abbeel, P.; Levine, S. Model-agnostic meta-learning for fast adaptation
    of deep networks. In Proceedings of the 34th

    International Conference on Machine Learning, Sydney, Australia, 6–11 August 2017;
    Volume 70, pp. 1126–1135.

    121. Ribeiro, M.T.; Singh, S.; Guestrin, C. “Why should I trust you?”: Explaining
    the predictions of any classiﬁer. In Proceedings of the

    22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,
    San Francisco CA, USA, 13–17 August

    2016; Association for Computing Machinery: New York, NY, USA, 2016; pp. 1135–1144.

    122. Lundberg, S.M.; Lee, S.I. A uniﬁed approach to interpreting model predictions.
    Adv. Neural Inf. Process. Syst. 2017, 30, 4765–4774.

    123. Caruana, R. Intelligible models for healthcare: Predicting pneumonia risk
    and hospital 30-day readmission. In Proceedings of the

    21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,
    Sydney, Australia, 10–13 August 2015;

    pp. 1721–1730.

    124. Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.; Gomez, A.N.;
    Kaiser, Ł.; Polosukhin, I. Attention is all you need. Adv.

    Neural Inf. Process. Syst. 2017, 30, 5998–6008.

    125. Snell, J.; Swersky, K.; Zemel, R. Prototypical networks for few-shot learning.
    Adv. Neural Inf. Process. Syst. 2017, 30, 4077–4087.

    Disclaimer/Publisher’s Note: The statements, opinions and data contained in all
    publications are solely those of the individual

    author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or
    the editor(s) disclaim responsibility for any injury to

    people or property resulting from any ideas, methods, instructions or products
    referred to in the content.

    '
  inline_citation: '>'
  journal: Agriculture
  limitations: '>'
  pdf_link: https://www.mdpi.com/2077-0472/13/3/540/pdf?version=1677156618
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: 'A Survey on Deep Learning and Its Impact on Agriculture: Challenges and
    Opportunities'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1186/s40537-022-00668-2
  analysis: '>'
  authors:
  - Nabila Chergui
  - M-Tahar Kechadi
  citation_count: 11
  full_citation: '>'
  full_text: ">\nOpen Access\n© The Author(s) 2022. Open Access This article is licensed\
    \ under a Creative Commons Attribution 4.0 International License, which permits\
    \ \nuse, sharing, adaptation, distribution and reproduction in any medium or format,\
    \ as long as you give appropriate credit to the original \nauthor(s) and the source,\
    \ provide a link to the Creative Commons licence, and indicate if changes were\
    \ made. The images or other third \nparty material in this article are included\
    \ in the article’s Creative Commons licence, unless indicated otherwise in a credit\
    \ line to the mate-\nrial. If material is not included in the article’s Creative\
    \ Commons licence and your intended use is not permitted by statutory regulation\
    \ or \nexceeds the permitted use, you will need to obtain permission directly\
    \ from the copyright holder. To view a copy of this licence, visit http:// \n\
    creat iveco mmons. org/ licen ses/ by/4. 0/.\nSURVEY\nChergui and Kechadi  Journal\
    \ of Big Data           (2022) 9:123  \nhttps://doi.org/10.1186/s40537-022-00668-2\n\
    Journal of Big Data\nData analytics for crop management: a big \ndata view\nNabila\
    \ Chergui1 and Mohand Tahar Kechadi1,2* \nAbstract \nRecent advances in Information\
    \ and Communication Technologies have a signifi-\ncant impact on all sectors of\
    \ the economy worldwide. Digital Agriculture appeared \nas a consequence of the\
    \ democratisation of digital devices and advances in artificial \nintelligence\
    \ and data science. Digital agriculture created new processes for making \nfarming\
    \ more productive and efficient while respecting the environment. Recent and \n\
    sophisticated digital devices and data science allowed the collection and analysis\
    \ of \nvast amounts of agricultural datasets to help farmers, agronomists, and\
    \ professionals \nunderstand better farming tasks and make better decisions. In\
    \ this paper, we present \na systematic review of the application of data mining\
    \ techniques to digital agriculture. \nWe introduce the crop yield management\
    \ process and its components while limiting \nthis study to crop yield and monitoring.\
    \ After identifying the main categories of data \nmining techniques for crop yield\
    \ monitoring, we discuss a panoply of existing works \non the use of data analytics.\
    \ This is followed by a general analysis and discussion on the \nimpact of big\
    \ data on agriculture.\nKeywords: Digital agriculture, Data analytics, Crop management,\
    \ Big data, Data \nmining, Machine learning\nIntroduction\nDA, (also called digital\
    \ farming or smart farming)1 [78, 105, 130], is a modern approach \nthat uses\
    \ digital and smart devices [sensors, cameras, satellite, drones, the Global Posi-\n\
    tioning System (GPS)] in conjunction with Data Mining (or data analytics) to improve\
    \ \nproductivity and to optimise the use of resources. Digital Agriculture (DA)\
    \ comes as a \nresponse to the increasing demand for improving productivity while\
    \ reducing farming \noperational costs. Moreover, the improvement of productivity\
    \ should not be done at \nany cost, e.g., overuse of natural resources and chemical\
    \ products. DA can, for example, \nmanage crop growth by finding appropriate fertilisation\
    \ program for each farming field \nand can help farmers to reduce their operational\
    \ costs and respect the environment by \nrefining their farming operations based\
    \ on the needs of each part of the farming field.\nSince agriculture has a direct\
    \ and significant impact on the population and therefore \nits economic environment,\
    \ DA in its turn should be viewed as the next natural step to \n*Correspondence:\
    \   \ntahar.kechadi@ucd.ie\n1 Faculty of Technology, Ferhat \nAbbas University,\
    \ Sétif, Algeria\n2 School of Computer Science, \nUniversity College Dublin, \n\
    Dublin, Ireland\n1 European Commission. Brussels. Preparing for Future AKIS in\
    \ Europe, 2019.\nPage 2 of 37\nChergui and Kechadi  Journal of Big Data      \
    \     (2022) 9:123 \nrespond to the world population’s needs while protecting\
    \ the environment, by taking \nadvantage of the recent technological advances\
    \ in digital devices, communications sys-\ntems, and artificial intelligence.\
    \ These allow us to construct multidimensional domains, \nwhere the farms and\
    \ farmers are their central subjects. Figure 1 shows the agriculture \necosystem\
    \ and its direct impact on other sectors of the economy.\nBesides, since DA involves\
    \ the development, adoption and iteration with digital tech-\nnologies [39], and\
    \ Artificial Intelligence (data analytics, ...), these developments and \ninteractions\
    \ should be well-defined (laws, regulations and policies) to guarantee rights\
    \ \nand benefits of all the involved actors (farmers, farm holders’, data owners’,\
    \ developers \nand analysts, technology vendors’,...) [70, 77, 78, 92, 113, 146].\n\
    DA can be regarded as a data driven form of farming, in which decision-making\
    \ pro-\ncesses are based on explicit information derived from data collected through\
    \ various \nsources [148]. DA and Precision Agriculture (PA) seem to refer to\
    \ the same thing, how-\never, as stated in [148], DA involves the development\
    \ and adoption of modern technolo-\ngies in both collecting the data and its analysis\
    \ in various farming contexts, while PA \ntakes into account only the in-field\
    \ variability [147]. DA aims to exploit advanced digital \ndevices, ranging from\
    \ a simple sensor to complex robots, to offer the required farmland \ntreatment\
    \ with high accuracy. DA can be applied in almost all agricultural fields. For\
    \ \ninstance, in crop production: DA allows accurate management of crops, which\
    \ includes \nfields, wasteland, crop, pest, and irrigation management, soil classification,\
    \ etc. In Ani-\nmal production: DA allows monitoring the animal over its whole\
    \ life cycle, its food \nquantity, health control and protection from diseases,\
    \ and so on. Fishery, animal Hus-\nbandry, livestock and dairy farming are some\
    \ examples [14]. In Forestry: We can effi-\nciently manage forests by supporting\
    \ the environmental and sustainable decision [36]. \nDA can help in detecting\
    \ unhealthy trees, air pollution, discriminate different tree spe-\ncies, protect\
    \ the wildlife, etc. From the economy point of view, the application of DA for\
    \ \nforest management enhances the wood quality and its production, which can\
    \ augment \nprofits; reduce waste and maintain the environment [138].\nAddressing\
    \ DA from all the above mentioned views is a challenging task and cannot \nbe\
    \ achieved without the participation of specialists from all these sectors. In\
    \ this study, \nFig. 1 The interlocked sectors involved in DA\nPage 3 of 37\n\
    Chergui and Kechadi  Journal of Big Data           (2022) 9:123 \n \nwe focus\
    \ on the use of Big Data in crop management, it is, not only one of the pillars\
    \ in \nagriculture but also it can profoundly affect biodiversity. Moreover, crop\
    \ growth is a very \ncomplex process involving various endogenous and exogenous\
    \ factors. Recent advances \nin digital technologies allow us to collect data\
    \ about all these factors. DA has the ability \nto elucidate the correlations\
    \ and interactions of these factor to help farmers and agrono-\nmists optimise\
    \ the productivity while reducing the side effects on the environment. DA \nexhibits\
    \ several benefits to agriculture as shown in Figure  2. These benefits were dis-\n\
    cussed in [10, 13, 70, 98, 104, 112, 113, 130, 135, 148] and summarised in the\
    \ following:\n• DA provides a farmer with useful information to support their\
    \ decision-making pro-\ncesses, such as soil and weather monitoring and prediction,\
    \ weed and pest monitor-\ning, crop yield dynamic predictions, etc.\n• DA can\
    \ sustain the environment and improve the products’ quality, since it provides\
    \ \nhigh quality information and measurements for optimal farming operations on\
    \ each \nfield.\n• DA can provide farmers advanced management methods against\
    \ climate change and \nother environmental challenges. The farmer can continuously\
    \ monitor crop growth \nand protect them against diseases.\n• DA offers valuable\
    \ feedback to farmers and good assessment of risks, to minimise \nmicrobiological\
    \ or disaster-related risks.\n• DA can provide prediction and assistance to farmers\
    \ against adverse weather inci-\ndence, disasters and market instability by assessing\
    \ the loss at the farm level.\n• Farmers/agronomists can benefit from advanced\
    \ models to understand the market \nand forecast which products could be more\
    \ profitable.\nThe contributions of this study are in the investigation of big\
    \ data analytics applications \nto crop production. Crop farming is a complex\
    \ task, and it depends on many factors that \nshould be taken into account. To\
    \ optimise the operational cost and reduce the impact \non the environment, the\
    \ big data analytics emerges as one of the most cost effective \napproaches nowadays.\
    \ The contributions, therefore, include the following:\nFig. 2 Role of DA in crop\
    \ production process\nPage 4 of 37\nChergui and Kechadi  Journal of Big Data \
    \          (2022) 9:123 \n• A comprehensive overview of Digital Agriculture big-data\
    \ with a presentation of the \nconceptual-layered framework to show the effectiveness\
    \ of data analytics on Digital \nAgriculture, when some necessary steps have been\
    \ implemented. For instance, large-\nscale data analytics can only be effective\
    \ if the historical data is available, carefully \ncollected, and it is of high\
    \ quality.\n• A highlight of the different types of data used in the existing\
    \ studies, and a presenta-\ntion of the classification of different techniques\
    \ applied to crop yield monitoring and \ntheir effectiveness of the overall results.\n\
    • A review and analytical studies of the most widely used data mining techniques\
    \ to \ncrop farming, with a report of their advantages and shortcomings.\n• A\
    \ discussion on the advantages of big data in agriculture, and how this can be\
    \ used \nefficiently for crop farming and its extension to the agricultural field\
    \ in general.\n• A discussion on Digital Agriculture applications for crop management\
    \ in small and \nlarge scale holders.\n• A discussion on Digital Agriculture challenges\
    \ and potential paths for future \nresearch.\nMethodology\nTo study the impact\
    \ of data analytics and big data on DA based on previous works, we \nconducted\
    \ a systematic review approach that consists of three steps: (1) collection of\
    \ \nrelated work, (2) selection of relevant work, and (3) examination and analysis\
    \ of the fil-\ntered related work.\nIn the first step, we performed keyword-based\
    \ research and We gathered a large \nnumber of studies from well-known and popular\
    \ online sources (Web of Science, Sco-\npus, IEEEXplore, ACM, etc.). We used a\
    \ combination of keywords from the two sets \n(Big data, data mining, data analytics,\
    \ machine learning, Internet Of Things, sensors) \nand (Digital agriculture, smart\
    \ farming, precision agriculture, agriculture, farming). We \ngathered more than\
    \ 327 articles. In the next steps, We selected a small number of arti-\ncles,\
    \ which are considered relevant for further analysis, based on their ideas, methods,\
    \ \ndata types and sources, addressed problems, proposed solutions, tools used\
    \ and quality \nof the results.\nThrough the literature analysis, the study aims\
    \ to find responses to the following \nresearch questions and discuss findings\
    \ in the following sections.\n• What is the process of DA for crop management?\n\
    • What are the various data types generated by farms and used in DA applications\
    \ for \ncrop management?\n• What role does big data analytics play in DA?\n• How\
    \ are big data analytics used for crop management?\n• What are the influences\
    \ of the farm’s scale on the application of DA?\n• How big is the data used in\
    \ the proposed DA solutions’?\n• What are the challenges facing the DA?\nPage\
    \ 5 of 37\nChergui and Kechadi  Journal of Big Data           (2022) 9:123 \n\
    \ \nFigure 3 summarises the overall approach, adopted from the PRISMA2 flow diagram.\n\
    Related work\nDespite that DA and Big Data being relatively recent research fields,\
    \ their scientific lit-\nerature is rich and covers several concepts. As DA is\
    \ at the cross boundaries between \nagriculture and ICT, three major dimensions\
    \ have emerged as of a very high importance; \ntechnology, social economics and\
    \ ethics, and decision-making based on Machine Learn-\ning. The first dimension\
    \ focuses on the use of advanced technologies to improve prac-\ntices and productivity\
    \ [56, 124]. In Ref. [124], the authors studied the impact of sensor \nnetworks\
    \ in agriculture, including remote sensing technologies, wireless devices, and\
    \ \nother IoT devices. Ref. [56] reviewed some developments in remote sensing\
    \ within Big \nData processing and management in agriculture. The second dimension\
    \ concerns legal, \nethics, social and economic factors of DA, to provide insights\
    \ into the impact of digit-\nised information and its analysis on the farm management;\
    \ farmer identity, skills, pri-\nvacy, production, and value chains in food systems\
    \ [39, 70, 77, 78, 92, 113, 146, 148]. The \nthird dimension focuses on the application\
    \ of big data analysis and machine learning \n(ML), to optimise and forecast the\
    \ production and the use of resources. In this paper, we \nonly consider this\
    \ dimension.\nVarious studies have been conducted on the application of data analytics\
    \ to crop yield \nmanagement. For instance, [71] presented a systematic review\
    \ on crop yield prediction \nusing ML techniques, and extracted major ML algorithms,\
    \ features and evaluation met-\nrics used in those studies. Ref.[35] discussed\
    \ the yield estimation by integrating agrarian \nfactors in ML techniques. This\
    \ allowed them to show a strong relationship between crop \nyield and climatic\
    \ factors. Ref. [103] Provided a systematic review on the use of com-\nputer vision\
    \ and AI to enhance the grain quality of five crops (maize, rice, wheat, soy-\n\
    bean and barley), disease detection and phenotyping. Ref. [64] reviewed the application\
    \ \nFig. 3 The research methodology flowchart\n2 http:// www. prisma- state ment.\
    \ org/.\nPage 6 of 37\nChergui and Kechadi  Journal of Big Data           (2022)\
    \ 9:123 \nof big data analysis in some fields of agriculture. It highlighted solutions\
    \ to some key \nwell-known problems, used tools and algorithms, along with input\
    \ datasets. The authors \nconcluded that big data analytics in agriculture is\
    \ still at its early stage, and many bar-\nriers need to be overcome, despite\
    \ the availability of the data and tools to analyse it. To \nmeasure the level\
    \ of usage of big data in DA, the authors defined big data metrics (low, \nmedium,\
    \ high) for each of its dimensions (volume, velocity, and variety). However, while\
    \ \nit is a very simple model, it is not easy to specify thresholds, as some dimensions,\
    \ such \nas volume and velocity depend on technological advances. Ref. [12] presented\
    \ a review \non the use of ML methods to detect biotic stress in crop protection.\
    \ The authors ana-\nlysed the potential of these techniques and their suitability\
    \ to deal with crop protection \nfrom weeds, diseases and insects. In addition,\
    \ they provided very good instructive exam-\nples from different fields of DA.\
    \ An earlier similar study was presented in [89], where \nthe authors studied\
    \ four very popular learning approaches; Artificial Neural Network \n(ANN), Support\
    \ Vector Machine (SVM), K-means, and K-Nearest Neighbour (KNN). \nRef. [25] presented\
    \ a survey on data mining clustering methods applied to food and agri-\ncultural\
    \ domains. It first described major techniques of unsupervised classification,\
    \ then \nit examined some existing techniques applied to agriculture products;\
    \ like fruit clas-\nsification, wine classification, analysis of remote sensing\
    \ in forest images and machine \nvision.\nThis study is not just an update of\
    \ previous surveys. The main objective is to examine \nthe effectiveness of big\
    \ data analytics in crop yield monitoring and discuss the challenges \nof such\
    \ paradigm shift in the agriculture domain. Moreover, It is important to under-\n\
    stand the sources of datasets, their types, and which ML techniques are more suitable\
    \ to \nanalyse them.\nDA: it’s all about data\nDigital Agriculture (DA) relies\
    \ heavily on the data sources and techniques used to col-\nlect it. This data\
    \ is then organised in agricultural data warehouses and analysed [93]. The \n\
    results of this data analysis provide significant insights to farmers and agronomists\
    \ about \nhow to improve the production, minimise the farming operational costs,\
    \ manage risks, \nand protect the environment. The process of deploying DA is\
    \ derived from data science.\nDigital agriculture process\nFigure  4, adopted\
    \ from the knowledge pyramid DIKW, shows a data-driven process, \nwhich is at\
    \ the heart of DA. This usually shows how data from past experiences and \nmodels\
    \ serve as input to techniques of mining and analysis to help in future decisions\
    \ \nand acting accordingly. The newly collected data will be used to further refine\
    \ the pro-\ncess and adapt it to an ever-evolving agricultural world.\nThis is\
    \ a data-driven methodology derived from the overall knowledge discovery pro-\n\
    cess. The first phase, data collection, is crucial to the validity of the whole\
    \ analysis. One \nneeds to carefully identify the type of data that should be\
    \ collected and the approach \nof gathering it and maintain it through its whole\
    \ life cycle. This is even more complex \nin DA, as the data is issued from various\
    \ and heterogeneous sources, and contains a \nnumber of factors of uncertainties.\
    \ The second phase, data representation and analysis, \nis very sophisticated,\
    \ as there is no common standards in the way the data should be \nPage 7 of 37\n\
    Chergui and Kechadi  Journal of Big Data           (2022) 9:123 \n \nintegrated,\
    \ consolidated, to derive a unified representation that is suitable for its analy-\n\
    sis, and in the choice of the analysis techniques. Finally, the decision-making\
    \ is a labori-\nous task, where the extracted knowledge will be associated to\
    \ the expertise of farmers \nand agronomists, farming constraints and regulations\
    \ to derive new management pro-\ncesses with the view to improve productivity\
    \ and quality of products, reduce and their \nimpact on the environment. Figure\
    \  5 depicts a diagram presenting the DA process for \ncrop yield monitoring,\
    \ as explained below.\n• Data collection and preparation It is important to identify\
    \ the data types and attrib-\nutes based on the problem at hand (e.g., crop management),\
    \ and the level of granu-\nlarity of the data. The required data sources should\
    \ also be identified and assessed for \ntheir data quality. As mentioned above,\
    \ the data is then prepared for analysis. This \nincludes data integration, representation,\
    \ selection, transformation, etc.\nFig. 4 DA– a data-driven process\nFig. 5 Big\
    \ Data Analytics system architecture for crop yield monitoring\nPage 8 of 37\n\
    Chergui and Kechadi  Journal of Big Data           (2022) 9:123 \n• Data analysis\
    \ the complex nature of the agricultural data requires an elaborative \nanalysis\
    \ approach, ranging from methods of feature selection or extraction to various\
    \ \nlearning algorithms to discover models, patterns (or knowledge in general\
    \ term) for \ndata analysis. These will be evaluated against the expected quality\
    \ of results and their \nsuitability to a decision-making process.\n• Decision-making\
    \ The main goal of the DA process is the decision-making. Any deci-\nsion should\
    \ follow the state-of-the-art practice, be justifiable and scientifically sound.\n\
    Digital agriculture data\nIn agriculture, Very large amounts of data can be collected\
    \ from various sources. These \ninclude sensors, weather stations, satellite imagery,\
    \ drone imagery, and many other \ninstruments. The datasets include weather data,\
    \ farm records, environmental condi-\ntions, soil parameters (nutrients, texture,\
    \ moisture, and so on. The data is usually rich, \nlarge, very complex, and heterogeneous.\
    \ Therefore, its analysis is not straightforward.\nThe heterogeneity is not only\
    \ expressed by the data types and formats, but it can be \ncollected using different\
    \ equipment of different quality. In addition, historical data may \nbe described\
    \ with different sets of attributes compared to very recent data. This can pre-\n\
    sent inconsistencies in naming conventions and measures when the data is collected\
    \ \nfrom different locations and times. Moreover, the data can be static and historical,\
    \ which \nis considered as offline data, and can be online weather data collected\
    \ at regular intervals \n(streams of data values), such as weather data (e.g.,\
    \ every 15 minutes), satellite imagery, \nwhich is characterised of being spatio-temporal,\
    \ such as Geo-spatial data, Moderate-\nResolution Imaging Spectroradiometer (MODIS)\
    \ images, etc.\nAs mentioned earlier, the data collection is not well tackled\
    \ in the literature. Most \nof the studies assume that the data is known already,\
    \ and the experimental setup was \nalready in place. Therefore, more effort is\
    \ allocated to the data analysis and interpreta-\ntion rather than on the complete\
    \ environmental parameters and conditions. In the fol-\nlowing sections, we discuss\
    \ the data analysis process. This discussion is structured based \non the main\
    \ categories of the data analysis; classification, and clustering [24]. Note that,\
    \ \nfor high quality results, the data needs to be pre-processed, as discussed\
    \ in the previous \nsection. The pre-processing includes cleaning (dealing with\
    \ missing values, redundant \ndata, noise and outliers), data transformation,\
    \ dimensionality or data reduction, and so \non.\nClassification for crop monitoring\n\
    Big Data analytics system architecture is depicted in Fig.  5. While this system\
    \ is tar-\ngeted specifically to crop yield management, it can be adapted to any\
    \ data-driven appli-\ncation. This architecture implements faithfully what we\
    \ have highlighted in the previous \nsections. In this section, we will focus\
    \ on the data analysis layer of the architecture, \nmoreover, we will pay attention\
    \ to the data types and their sources, techniques of data \nacquisition, the learning\
    \ algorithms. The main objective of the crop management data \nanalysis is to\
    \ get some insights about the crop monitoring problems and show the poten-\ntial\
    \ of DA through big data analytics, also called data mining. Data mining and its\
    \ tech-\nniques are involved in several roles in crop production. Farmers may\
    \ want to know the \nPage 9 of 37\nChergui and Kechadi  Journal of Big Data  \
    \         (2022) 9:123 \n \nfuture yield of their crop, specific areas of their\
    \ farms suffer from the spread of weeds \nor under-nutrition. Researchers can\
    \ look for information such as plant growth patterns, \noptimum growing conditions,\
    \ best pest and disease control environment and so on. Data \nmining offers panoply\
    \ of sophisticated techniques required to meet all of these needs.\nThere are\
    \ two major categories of data analysis: Classification and Clustering. In the\
    \ \nwork of [24], authors studied applications of data mining techniques in crop\
    \ manage-\nment and proposed a classification of these applications. They found\
    \ that the classifi-\ncation and clustering are the main used categories, where\
    \ the classification includes \nprediction, detection, protection, and categorisation).\
    \ The choice between classification \nor clustering analysis is very simple. If\
    \ the models or classes we are looking for were \nknown in advance and we have\
    \ an annotated data to support the training of the learn-\ning algorithms, then\
    \ classification is the right choice. However, the annotated data is not \nalways\
    \ available and easy to generate, and in many cases we do not know even which\
    \ \nmodels or patterns we are looking for. In these situations, clustering analysis\
    \ is the right \nalternative.\nIn this section, we focus on the studies that use\
    \ classification methods for their data \nanalysis. Clustering analysis will be\
    \ covered in the next section. We structure these clas-\nsification studies based\
    \ on the application objectives or targets which arecategorisation, \nprediction,\
    \ detection, and protection.\nCategorisation\nWhile the classification main objective\
    \ is to assign a given object into one of the pre-\ndetermined classes, in the\
    \ agricultural world, the use of classification process may vary \ndepending on\
    \ the stakeholders interests. In this study, we report four different applica-\n\
    tions (or targets) which are widely used in agriculture categorisation, prediction,\
    \ detec-\ntion, and protection.\nCategorisation aims at defining the classes (or\
    \ class labels) based on the simple recog-\nnition of similarities that exist\
    \ across a set of entities. For example, categorisation can \nbe used to classify\
    \ small fruit from fruit with normal to big size, to make an estima-\ntion of\
    \ yields; which may have an economic impact if the farmer wants to make different\
    \ \npackages or prices for each type of fruit separately. It can also be used\
    \ to classify dam-\naged crops from good ones in order to estimate losses, or\
    \ to prepare for the harvest and \nmarketing. Categorisation can also be applied\
    \ for crop mapping (e.g., poor, average, high \nyield), which aims to provide\
    \ information on farmed fields given a specific type of crops, \nor to identify\
    \ a type of crops that are more suitable for a particular field. Based on the\
    \ \ninput data, categorisation can help improve the farming operations based on\
    \ the mean-\ningful categories (classes) predefined in advance.\nProducing accurate\
    \ crop maps is essential for effective agricultural monitoring [131]. \nCategorisation\
    \ approaches can be applied to study regional crop distribution within or \npost\
    \ growing season. For this purpose, it can offer:\n• A good understanding of how\
    \ crops are distributed at early stage of their develop-\nment; allowing for an\
    \ opportune decision making and management, as well as \nadjusting crop planting\
    \ structure, is crucial. Besides, the timely available of (spatial \nPage 10 of\
    \ 37\nChergui and Kechadi  Journal of Big Data           (2022) 9:123 \nor maps)\
    \ distribution of crop types is required for statistical and economic purposes\
    \ \n[131].\n• The availability of crops maps is critical for the diverse agricultural\
    \ monitoring activi-\nties, such as crop acreage estimation, yield modelling,\
    \ harvest operation schedules \n[131, 144], etc.\nMoreover, categorisation has\
    \ been applied for agricultural field mapping [31], to quan-\ntify the cropping\
    \ intensity for small-scale farms [58], to identify and map crops and to \nretrieve\
    \ the area of major cultivation [100] and to classify land-cover and crop [76].\
    \ \nTable  1 highlights the major fields, ideas and tools used for crops categorisation.\
    \ We can \nsee that data issued from satellites and remote sensing, and the features\
    \ with vegetation \nindices especially NDVI and EVI, the RGB colours, are the\
    \ most used.\nCrop yield prediction\nThe estimation of crop yield is crucial in\
    \ DA, as it enables efficient planning of resources. \nEconomically, an early\
    \ and accurate prediction of yields can help decision-makers to \nreact to the\
    \ crops market. Moreover, crop yield prediction permits the study of factors \n\
    that influence and affect the production, such as climate and weather, natural\
    \ soil fer-\ntility and its physical structure and topography, crop stress, the\
    \ incidence of pests and \ndiseases, etc.\nThe prediction of crop yields has been\
    \ the subject of many studies. Ref. [71] presented \na literature review on crop\
    \ forecasting, where the authors highlighted the most used \nmachine learning\
    \ algorithms along with the applied metrics and measures. In this sec-\ntion,\
    \ we examine the learning algorithms that have been used in crop yield prediction\
    \ \nfrom different views: data types, the pre-processing methods, and features\
    \ or the predic-\ntor variables used in each study. Tables  2 and  3 summarise\
    \ some relevant studies.\nThe crop yield forecasting approaches follow two major\
    \ types of sources of data. The \nfirst type is related to the sources that have\
    \ direct impact on the crops. These sources are \nsoil data, weather data, environmental\
    \ parameter data. These are usually used to predict \ncrop yield [27, 34, 42,\
    \ 46, 51, 73]. The second type of sources are the use of advanced \ntechnologies\
    \ and tools like satellite multi/hyper spectral images, remote sensing and \n\
    sensors to collect the data [62, 83, 102, 114, 152]. Some advanced studies use\
    \ both types \nof data sources [1, 40, 54, 59, 65, 67, 68, 97, 120, 121].\nThe\
    \ forecasting models based on the first type of data sources provides a pre-season\
    \ \nestimation of the yield, even before the beginning of the crop season. This\
    \ allows farmers \nto decide which strategy to both optimise the farming operations\
    \ and crop production. \nThese decisions include choosing seeds and crop type,\
    \ type of fertiliser and its applica-\ntions. Moreover, This data can also be\
    \ used for some crop monitoring during the grow-\ning season.\nThe monitoring\
    \ systems based on the second type of data analysis - data imagery \nobtained\
    \ from satellite, cameras, scanner, sensors - allow for on-season estimation \n\
    (emergence, detect stress conditions of crop, harvest dates, ...). These models\
    \ are com-\nplex since they have to analyse the data that consists of both spatio-temporal\
    \ and non-\nspacial. While the spatial data is of high resolution, some images\
    \ can be of very poor \nPage 11 of 37\nChergui and Kechadi  Journal of Big Data\
    \           (2022) 9:123 \n \nTable 1 An analytical study on examples of crop\
    \ categorisation approaches; demonstrates: the type of categorisation application,\
    \ the used learning algorithm, the data type, \ndata pre-processing and selected\
    \ features for each algorithm\nReferences\nApplication\nAlgo\nTarget\nData type\n\
    Data pre-processing\nExtracted features\n[31]\nCrop fieldsmapping\nRF\n/\nSatelliteDigitalGlobe\
    \ World-\nview-2\nHand digitisation\nRandomised Quasi-Exhaustive \nfeatures\n\
    [41]\nCrop mapping\nDecision tree\nSoybean\nSatellite\nMulti resolutionsegmentation\n\
    NDVI NIR (near infrared) SWIR \n(short wave infrared)\n[131]\nCrops  mapping\n\
    RF\n/\nGF-1 WFV sensorsatellite \nimages\nMulti-resolutionsegmentation\ntemporal,\
    \ spectral textural fea-\ntures vegetation indexes(NDVI, \nEVI...)\n[22]\nCrop\
    \ fieldsmapping\nRF\nPaddy rice\nSatellite images\nPolarisation for cloud contami-\n\
    nation by Google Earth Engine\nNDVI, EVIland surface water \nindex LSWI\n[115]\n\
    Crop mapping\nDeep learning: autoencoder \nCNN, Full CNN\nSoybean, maize cotton\n\
    Satellite images\nData were pre-processed\nTexturepixel’s features based on \n\
    the image patch\n[157]\nCrop classification\nLSTM\n/\nSatellite & opticalimagesfield\
    \ \nsurveys\nSegmentaionpan-sharpening \nand mosaic of optical imag-\nesthermal\
    \ noise removal and \nradiometric correction\nSpatial features\n[76]\nCrop classification\n\
    Deep learning CNN\nWheat, maize sunflower soy-\nbeans, sugar beet\nSatellite images\n\
    segmentation and data \nrestoration using unsupervised \nNN self-organising Kohonen\
    \ \nmaps)\nSpectral and  spatial features\n[33]\nPlant classification\nDeep learningCNN\n\
    22 plants\nCamera and  cell phone \nimages\nData are not pre-processed\nSelf-learned\
    \ features\n[26]\nCrop classification\nEnsemble learningANN, DT, \nSVM\nRice,\
    \ soybean, corn cotton\nRemote sensing images\nUSGS online system, used \na cubic\
    \ convolution 245 \nre-sampling and a standard \nterrain correction incorporat-\n\
    ing ground truth points\nNDVI, levels of greenmoisture\n[100]\nCrop classification\n\
    set of classifiers SVM(RBF ker-\nnel), RF, Spectral Angle Mapper\nTree crops,\
    \ sugar beet alfalfa, \ncereals\nSensor satellite Time series \nand images\nAtmospheric\
    \ correction and \nRadiometric calibration and \nPan-Sharpening\nNDVI\nPage 12\
    \ of 37\nChergui and Kechadi  Journal of Big Data           (2022) 9:123 \nTable\
    \ 2 Part 1: an analytical study on examples of crop prediction methods; highlights:\
    \ the applied learning algorithms, the crop type, data type and pre-processing,\
    \ the other \nstudied and considered parameters in each proposed approach and\
    \ the predictor variables for each used algorithm\nReferences\nAlgorithm\nPlant\n\
    Data type\nData pre-processing\nOther parameters\nPredictor variables\n[46]\n\
    KNN, MLP, SVR regression \ntrees\nPepper, bean chickpea, corn \npotato, tomatoMexican\
    \ husk \ntomato\nHistorical yield climateirriga-\ntion plans\n/\n/\nPlanting area\
    \ min, max and \navg temperature precipitation, \nirrigation solor radiation\n\
    [51]\nRF\nGroundnut millet\nHistoricalyield\nKNN for dataimputation\n/\nSunlight,\
    \ humidity precipita-\ntion min, max, avg tempera-\nture\n[54]\nSVM, RF Gaussian\
    \ process \nregression\nWinter wheat\nRemote sensing climate, soil \nyield,crop\
    \ map\nGoogle earth engine (GEE)\nRegional differences of yield-\nvariable importance\n\
    Min, max temperature NDVI, \nEVI palmer drought severity \nindex, precipitation\
    \ soil: mois-\nture, physical and chemical \nproperties\n[121]\nLSTM\nSoybean\n\
    Satellite imageswheather \nand historicalyield\nGEE\n/\nNDVI, EVI, land surface\
    \ and air \ntemperature precipitation\n[120]\nRF\nCorn, soybean\nHistorical yield\
    \ satellite \nremote sensors ancillary and \nenvironment\n/\n/\nDynamic ranged\
    \ vegetation \nindex (WDRVI), temperature \nprecipitation, soil moisture \nshortwave\
    \ radiation statistics \nrelated to county-level irri-\ngated harvested cropland\n\
    [83]\nDNN\nSoybean\nMulti remote sensing data\nPix4D mapper softwrare: UAl \n\
    RGB, multi spectral andTIR \nimagesconversion of radio-\nmetric value\n/\n25 features:\
    \ canopy spectral \nstructure, thermal and texture \nfeatures NIR, NDVI, WDRVI,\
    \ EVI\n[1]\nSVR\nPotato\nproximal sensing (soil and  \ncrop properties) yield\
    \ data\nEffects of data-set size on \naccuracy\n/\nSoil electrical conductivity\
    \ \nsoil moisture, soil slope, soil \nchemistryNDVI\n[65]\nSVR\nWheat\nSatellite\
    \ images climate and \nyield records and maps\nKNN\n/\nNDVI, precipitation max\
    \ \ntemperature\n[40]\nRF\nWheat, barley canola\nYield, soil, climate remote \n\
    sensing Geo-physical data\n/\nPre-sowing mid and late \nseason\nSoil maps, surveys\
    \ rainfull, \nNDVI\nPage 13 of 37\nChergui and Kechadi  Journal of Big Data  \
    \         (2022) 9:123 \n \nTable 2 (continued)\nReferences\nAlgorithm\nPlant\n\
    Data type\nData pre-processing\nOther parameters\nPredictor variables\n[42]\n\
    RF\nMango\nIrrigation, historical yield\n/\nDifferent irrigation regimes\n/\n\
    [34]\nANN\nTomato\nHistorical data\n/\nWater monitoring different \nradiations\
    \ values\nCO2, day, water radiation, \ntemperature\n[97]\nRNN\nSoybean maize\n\
    Multi sources: satellite, soil \nproperties\n/\nPre-season yield\nMin and max\
    \ temperature \nprecipitation soil, pH and \nother 10 features\n[59]\nRF\nWheat,\
    \ maize potato\nMulti sources: climate, soil \nphoto-period water, yields \nfertilisation\n\
    /\nClimate and biophysical vari-\nables at global and regional \nscales\nMany\
    \ features on climate and \nsoil and nitrogen fertiliser\n[73]\nELM\nRobusta coffee\n\
    Soil components\n/\nSoil fertility\nExchangeable calcium boron, \nmagnesium and\
    \ nitrogen, PH\nZinc potassium, sulphur \nphosphorus\n[102]\nANN supervised kohonen\
    \ \ncounter propagation XY-\nfusion\nWheat\nMulti-spectral satellite data\nOrthorectification\
    \ in-band \nreflectance calibration\nPhysico-chemical soil \nparameters\nNDVI\n\
    [114]\nnon-linear regression\nCabbage\nSensor data\n/\nNitrogen variation\nNDVI\n\
    Page 14 of 37\nChergui and Kechadi  Journal of Big Data           (2022) 9:123\
    \ \nTable 3 Part 2: an analytical study on examples of crop prediction methods;\
    \ highlights: the applied learning algorithms, the crop type, data type and pre-processing,\
    \ the other \nstudied and considered parameters in each proposed approach and\
    \ the predictor variables for each used algorithm\nReferences\nAlgorithm\nPlant\n\
    Data type\nData pre/processing\nOther parameters\nPredictor variables\n[152]\n\
    CNN, LSTM Gaussian\nSoybean\nSensor MODIS data\nTransform multi-spectral images\
    \ to \nindividual histograms\n/\nHistogramsgeographic location year\n[62]\nRegression\
    \ Rulequest Cubist\nCorn, soybean\nSatellite data\n8-days periods data-points\
    \ com-\nposed then averaged\nPre and within season\nNDVI, precipitation day and\
    \ night \nland surface temperature\n[67]\nDT  (Extremely randomised) \nSVM(RBF);DNN\n\
    Corn\nSatellite images climate, yield\n/\nSeasonal sensitivities\nNDVI and many\
    \ other features\n[27]\nDeep learning semi-parametric \nNN for training: bayesian\
    \ hyper-\nparameter optimisation and early \nstopping\nCorn\nHistorical yield\
    \ weather\n/\nClimate change impact and semi-\nparametric prediction model\nPrecipitation\
    \ temperature humidity, \nwind radiation Latitude and longi-\ntude Growing degree,\
    \ soil County, \nirrigation\n[68]\nDNN; ANN; RF; multivariate adaptive \nregression\
    \ splines SVM; extremely \nrandomised trees\nCorn  and soybean\nSatellite images\
    \ MODIS historical \nyield meteorological and crop \nlandhydrological\n/\nEffect\
    \ of phenology\nEVI Leaf Area Index Gross Primary \nProduction precipitation;\
    \ min, max air \ntemperature soil Moisture, NDVI\n[50]\nSVM\nRice\nClimate and\
    \ geographical data\n/\nEffect of phenology and climate \npre-season\nMean, max,\
    \ mintemperature Daily Sun-\nshine hours precipitation mean relative \nhumidity\
    \ min relative humidity mean \nwind speed maximum wind speed\n[60]\nLR\nCorn\n\
    MODIS remote sensing\nSavitzky-Golay filter for smoothing \nNDVI time series\n\
    Effect of phenology\nMax correlation NDVI crop growth \nrate crop growth days\n\
    [111]\nRF\nChickpea\nModis images weather data yield \nstatistics remote sensing\n\
    /\nDrylands sensitivity to data time\nEVI, NDVI, Leaf Area Index precipita-\n\
    tion and 5 other features\n[4]\nBidirectional LSTM\nTomato, Potato\nClimate datairrigation\
    \ scheduling \nsoil water content\nMoving average method for data \nimputation\
    \ multi-collinear param-\netersremoval\nEffect of irrigation scheduling\nMin,\
    \ max, mean temperature min, \nmax, average relative humidity aver-\nage solar\
    \ radiation min and average \nwind speed precipitation\n[91]\n3D-CNN\nWheat, Barley,\
    \ Oats\nWeather data UAV RGB image \nyield data\nImages resizing\nEffects of time:efficiency\
    \ of using \ntime series data vs point-in-time \ndata\nRGB Images, cumulative\
    \ temperature\n[19]\nLSTM\nWinter, wheat\nClimate satellite data soil surveys\n\
    /\n/\nMin and max temperatureprecipita-\ntion, EVI, soil depth and texture, pH\
    \ \ngeographic properties\nPage 15 of 37\nChergui and Kechadi  Journal of Big\
    \ Data           (2022) 9:123 \n \nquality, (e.g., images with lot of clouds).\
    \ Features or predictor variables used in this kind \nof applications depend on\
    \ the type of data sources, NDVI and EVI are the most used \nvegetation indices\
    \ for satellite and remote/approximate sensors’ data source, min/max \ntemperature\
    \ and precipitation for weather data source, soil moisture and nitrogen ferti-\n\
    liser for soil based data source.\nCrop protection\nCrop disease is considered\
    \ as a major menace for food security in many regions of the \nworld since it\
    \ causes serious crops losses. While the detection of crop diseases correctly\
    \ \nand timely when they first appear is crucial in crop monitoring, this remains\
    \ a difficult \ntask. One of the solutions to deal with this issue is to use data\
    \ analytics approach. This \nwill reduce yield losses and prevent farmers to take\
    \ effective reactive actions. Forewarn-\ning can be seen as the outputs of data\
    \ mining process. Usually, this consists of examining \nthe features of a newly\
    \ presented case and assigning it to a predefined class.\nSeveral interesting\
    \ efforts have been developed to prevent crops losses due to dis-\neases, Tables\
    \  4 and 5 summarise some major studies. Ref. [7] presented an overview of \n\
    ML techniques for crop disease classification. In addition, it presented to a\
    \ case study \nwhere a deep learning algorithm was successfully used. Ref. [45]\
    \ provided a review on \nadvanced ANN techniques to process hyper-spectral data\
    \ for plant disease detection. \nRecently, deep learning approaches have been\
    \ emerged and widely used for plant dis-\nease detection and classification, with\
    \ a variety of network architectures (CNN, AlexNet, \ngoogLeNet, CaffeNet, DenseNet,\
    \ Inception, LeNet, VGGNet,...) and training methods \n(shallow, deep, from scratch)\
    \ [9, 16, 21, 28, 38, 63, 79, 82, 125, 139, 143, 150, 155]. More-\nover, [127]\
    \ presented an interesting study on the potential of the use of deep learning\
    \ for \nplant stress phenotyping.\nCrop protection, that consists of disease,\
    \ stress, and weed detection, aims to offer tools \nthat detect plants disease\
    \ caused by various biotic (pathogen, insect, pest, and weed) \nor abiotic (temperature\
    \ stress, nutrient deficiency, toxicity, herbicide) variables [126]. \nThe earlier\
    \ the stress, disease or their symptoms are detected, the greater the chance of\
    \ \nreducing the disease spread within a field. This has gained significant advantage\
    \ from the \nadvances in image collection and processing and their analysis using\
    \ ML algorithm. The \nstate-of-the-art is very rich. The large majority of studies\
    \ carried out so far were using \nimage processing, consequently image-based data\
    \ and classification techniques. These \nare capable of detecting disease at the\
    \ scale of leaf, canopy or field [126].\nDisease detection at a leaf level uses\
    \ images collected using digital cameras, which are \nstored in data warehouses.\
    \ For instance, PlantVillage database [6, 9, 21, 28, 63, 79, 88, \n106, 125, 129,\
    \ 150] is created for this purpose. The objective of this repository is to build\
    \ \nclassifiers with high accuracy. The basic classifiers can simply assign to\
    \ an unseen image \na label healthy or infected, while more elaborated classifiers\
    \ can identify the disease - in \nother words, classify unseen images to disease\
    \ classes. However, this approach has some \nlimitations. First, it depends on\
    \ the quality of the images, as when taken in natural envi-\nronment, these images\
    \ are subject to different degrees of light, shadow, dust and leaves \noverlapping\
    \ and requires sophisticated image processing, which is not an easy task. Sec-\n\
    ond, usually the datasets sizes are small, which affect the learning phase of\
    \ the classifiers \nPage 16 of 37\nChergui and Kechadi  Journal of Big Data  \
    \         (2022) 9:123 \nTable 4 Part 1: an analytical study on examples of crop\
    \ diseases protection and weeds detection approaches; highlights the applied algorithm,\
    \ plant and data type, data pre-\nprocessing and the extracted features\nReferences\n\
    Application\nAlgorithm\nPlant\nData type\nData pre-processing\nExtracted features\n\
    [21]\nLeaf disease recognition\nCNN\nTea plant\nDigital images\nData augmentation\n\
    /\n[63]\nPlant disease detection\nCNN\nPlant leaves\nDigital images\nData augmentation\n\
    /\n[9]\nPlant disease detection\nDNN\nPlant leaves\nDigital images\nData augmentation\n\
    [143]\nLight leaf spotdetection\nSVM\nSoilseedrape\nMulti-spectralimages\nRemoval\
    \ of:background and \nredundant features\nCarter Index 1 light leaf spot \nindex\
    \ Spectral signature\n[82]\nDisease detection\nSVM\nWheat\nSensing data\n/\nNDVI,\
    \ Photochemical reflec-\ntion index Pigment-specific \nsimple ratio, water index\n\
    [155]\nDiseasedetection\nCNN\nWheat\nRemote sensingdata\nSegmentaion: sliding-\n\
    window\n3D blocks\n[125]\nLeaf disease recognition\nCNN\nMaize\nDigital images\n\
    /\nRGB\n[15]\nPlant disease detection\nGated recurrent unit CNN\nSoybean\nSatellite\
    \ images Crop rota-\ntion\nTime-series\nSpectral bands of: red, green, \nblue\
    \ NIR, NDVI\n[150]\nLeaf disease detection\nCNN\nTomato\nDigital images\nData\
    \ \naugmentation:resolution \nreducingbicubic method to \nenlarge images\nPatches\n\
    [136]\nPlant disease detection\nRF\nWheat\nAerial multi-spectralimages\n/\nRVI,\
    \ NDVI, OSAVI NIR, Red\n[49]\nPlant disease detection\nPartial leastsquares regres-\n\
    sion\nWheat\nAerial hyper-spectralimages\nImage fusion and mosaicking Disease\
    \ index many vegeta-\ntion indexes texture features\n[153]\nPlant detection\n\
    CNN\nMaize\nAerial RGBimages\nSegmentation by RF\nMorphological caracteristics\
    \ of \nmaize tassels\n[80]\nPlant disease detection\nANN\nWheat\nHyper-spectral\
    \ aerial images\nFusion and stitchingra-\ndiometric calibrationatmos-\npheric\
    \ correction\n11 Vegetation indexes spectral \nbands texture features\n[88]\n\
    Plant disease detection\ndeep learning CNN: AlexNet \nGoogLeNet\nPlant leaves\n\
    Digital images\nColoured, gray-scaled, \nsegmented\n/\nPage 17 of 37\nChergui and\
    \ Kechadi  Journal of Big Data           (2022) 9:123 \n \nTable 4 (continued)\n\
    References\nApplication\nAlgorithm\nPlant\nData type\nData pre-processing\nExtracted\
    \ features\n[2]\nCrop and weed classification\nSVM RBF kernel\nChilli, Pigweed\
    \ Marsh herb \nLamb’s quarters Cogongrass, \ncucumber\nDigital images\nSegmentation:\
    \ binarisation \ntechnique: -global threshold \nnoise removal morphological \n\
    opening and  morphological \nclosing\n14 features: RGB colours, shape \nfeatures\
    \ Moment invariant \nfeatures\n[44]\nWeeds detection\nRF\nMaize\nHyper-spectral\
    \ images\nSegmentation\n185 features Ratio Vegetation \nIndex,NDVI\n[3]\nWeeds\
    \ detection\nSVM Gaussian kernel\nCorn leaves and broad silver \nbeet leaves\n\
    Spectral reflectance images\n/\nNDVI\n[8]\nCrop and weed classification\nANN Generalised\
    \ Softmax \nPerceptron and the Posterior \nProbability Model Selection \nalgorithm\n\
    Sunflower\nDigital images\nSpecial process of segmen-\ntation\n13 morphological\
    \ features: \nNumber of boundary pix-\nelsCompactness, Perimeter, \nCentroid and\
    \ Elongation,The \ngeometric centre Area, Num-\nber of pixels of objects, Major\
    \ \nand minor axis of the best fit \nellipse\nPage 18 of 37\nChergui and Kechadi\
    \  Journal of Big Data           (2022) 9:123 \nTable 5 Part 2: an analytical\
    \ study on examples of crop diseases protection and weeds detection approaches;\
    \ highlights the applied algorithm, plant and data type, data pre-\nprocessing\
    \ and the extracted features\nReferences Application\nAlgorithm\nPlant\nData type\n\
    Data pre-processing\nExtracted features\n[129]\nLeaf disease detection\nDeep learning\
    \ CNN: CaffeNet\n13 plants leaves\nImages\naugmentation by: afine trans-\nformation\
    \ and perspective \ntransformation and rotation \nmanually pre-processing by \n\
    image cropping and labelling\n[119] [29]\nWeeds classification\nANN:PSO and bee\
    \ for opti-\nmisation\nPotatoes rice\nStereo video\nSegmentation\nColor features\
    \ & vegetation \nindices\n[128]\nMid-late season weed detec-\ntion\nCNN\nSoybean\n\
    Aerial images\nOverlapped images removal \ndimenssion reduction annota-\ntion\n\
    Patches\n[118]\nWeed detection\nDNN\nSugar beet and  weeds Multi-spectral UAV\n\
    Segmentation\nRGB Color-Infrared NDVI\n[106]\nLeaf disease detection\nRF, SVM,\
    \ KNN\nAlfalfa\nDigital images\nLesion: artificial cutting-\nsegmentation:12 lesion\
    \ \nsegmentation with K-median \nclustering  and linear discrimi-\nnant analysis\n\
    129 texture colour and shape\n[55]\nSeeds disease detection\nANN\nOrchids\nDigital\
    \ images\nSegmentation: an exponential \ntransform with an adjustable \nparameter\n\
    Texture and colours\n[109]\nPlant disease detection\nRF\nSoybean\nSatellite images\
    \ Crop rotation\nGeometric distortions removal \nradiometrically and sensor \n\
    correction image rotation\nSpectral bands of:red, green, \nblueNDVI, NIR\n[28]\n\
    Leaves disease detection\nTransfer learning CNN: \nabstraction level fusion\n\
    Olive\nDigital images\nsegmentation: automatic \ncropping: Otsu’s algorithm\n\
    Edge magnitudes: Gray-scaled-\nShape features: area, perimeter\n[6]\n10 leaves\
    \ disease detection\nTransfer learning CNN\nEggplant, hyacinth \nbeans ladies\
    \ finger, \nlime\nDigital images\nSegmentation data augmen-\ntation\n/\nPage 19\
    \ of 37\nChergui and Kechadi  Journal of Big Data           (2022) 9:123 \n \n\
    Table 5 (continued)\nReferences Application\nAlgorithm\nPlant\nData type\nData\
    \ pre-processing\nExtracted features\n[79]\nLeaves disease detection\nDeep learning:\
    \ Alex NetGoog-\nLeNet\nApple\nDigital images\nNo pre-processing AlexNet \nPrecursor\
    \ for features maps \nmax-pooling for GoogLeNet \nfor features extractiondata\
    \ \naugmentaion:light distur-\nbance &rotationnoise removal\n/\n[81]\nPlant disease\
    \ detection\nKNN\nWheat\nSatellite imagesfield survey\nRadiometric calibration\
    \ \natmospheric correction\nRed and green bands NIR, \nvegetation indices:disease\
    \ \nwater stress index optimised \nsoil adjusted vegetation index \nshortwave\
    \ infrared water stress \nindex triangular vegetation \nindex and others\n[156]\n\
    Plant disease detection\nRF\nWheat\nSatellite images field canopy \nhyperspectral\n\
    Noise removal image mosai-\ncking Atmospheric correction \nspatial resolution\
    \ re-sampling\nDisease indexNDVi, EVI and \nothers\nPage 20 of 37\nChergui and\
    \ Kechadi  Journal of Big Data           (2022) 9:123 \nand more importantly the\
    \ potential of some advanced learning algorithms such as deep \nlearning. Data\
    \ augmentation (rotation, light shade’s variation, colour inversion, transla-\n\
    tion and changes in intensity and so on) is one of the methods used to overcome\
    \ this \nproblem to artificially increase the number of images [6, 9, 21, 63,\
    \ 79, 129, 150], but it \ndoes not always work. Transfer learning is another solution\
    \ to scarce/small data-set, \nwhere the knowledge obtained from solving a task\
    \ in a given domain is transferred to \nthe target domain in which the dataset\
    \ is small [6, 11, 28]. The transfer learning can only \nbe efficient if the source\
    \ and target domains share some similarities in terms of diseases \nand their\
    \ symptoms, for example. Moreover, it is very challenging to transfer knowledge\
    \ \nfrom representations learned using RGB images to a target task using multi-spectral\
    \ \nimages from UAV or satellite [126].\nThird, this approach cannot detect more\
    \ than a single disease at a time, and the detec-\ntion of diseases if the symptoms\
    \ are manifested in another area than leaves. Plant can-\nopy based-image was\
    \ proposed as a solution to this problem. The idea is to collect data \nrelative\
    \ to disease in situations where single-leaf phenotypes alone would not provide\
    \ \nsufficient information. Such features include the size, the height, the structure,\
    \ and \nbranching of canopy [126]. The canopy-based detection uses UAV equipped\
    \ with (multi/ \nhyper) spectral cameras and sensors to collect the data [32,\
    \ 49, 80, 82, 136, 143, 153, \n155]. Then data needs to be processed to extract\
    \ features which are usually related to \nvegetation indices like NDVI and EVI\
    \ or colours like RGB and NIR. The benefit from \nUAV images comes with cost on\
    \ complexity of analysis since images taken by UAV are \nsusceptible to occlusion,\
    \ overlapping, and atmospheric effects. Also, UAV is not able \nto fly at higher\
    \ altitudes, which decreases the quality of the collected images. To cover \n\
    larger zones and fields, satellite-based remote sensing and images has been proposed\
    \ as \na very good alternative [15, 81, 109, 156]. However, the problem with satellite\
    \ remote \nsensing is the revisit time, which is 16 days on average, which makes\
    \ protection applica-\ntions difficult, and some diseases can spread rapidly in\
    \ fields before they are detected. \nMoreover, passive sensors cannot penetrate\
    \ clouds [149]. The integration of these data \nwith additional data sources like\
    \ field surveys, contextual information of field and crop \nrotation can improve\
    \ the accuracy [15, 81, 109].\nDetecting diseases only from one data source based\
    \ on digital images or sensor data is \nnot sufficient. Besides, variations in\
    \ symptoms may lead to false positives due to dynamic \nnature of plant changes\
    \ [126]. Consequently, the appearance-based identification of dis-\neases is not\
    \ reliable enough to accurately detect unhealthy plants, especially in the early\
    \ \ngrowth stages. The use of multi-data sources can improve the accuracy of the\
    \ detection. \nFor instance, the use of physiological features and morphological\
    \ characteristics (growth \nattributes, yield-related features, soil) [66], or\
    \ the employment of satellite-based images \nand canopy-based images [156], where\
    \ the disease can be identified at the plant canopy \nlevel and at the field level.\n\
    Crop maturity monitoring\nCrop maturity is a kind of crop yield prediction, but\
    \ it is based on image data. This tech-\nnique has been used in fruit detection,\
    \ like apples, tomatoes, oranges, etc, and provides \nan early estimation of yield.\
    \ It is also used for crop monitoring to provide information \nto farmers with\
    \ the view to plan their farming operations, adjust management practices \nPage\
    \ 21 of 37\nChergui and Kechadi  Journal of Big Data           (2022) 9:123 \n\
    \ \nbefore harvesting, etc. Such intelligent systems for monitoring crop implement\
    \ the data \nmining process incorporating machine vision and image processing\
    \ methods among \nwith advanced learning algorithms, such as CNN, SVM and ANN.\
    \ Unlike crop yield \nprediction process described above, this process is based\
    \ on a single-data source; digital \nimages [5, 23, 52, 75, 108, 122] or sensor\
    \ based-images [117, 123, 153]. Table  6 summa-\nrises such techniques. The challenges\
    \ of these systems are more or less the same as those \nof systems for crop disease\
    \ detection and protection. For instance, images with differ-\nent illumination\
    \ and lighting angles, complex surroundings and backgrounds, noise, the \npresence\
    \ of clouds, etc.\nClustering for crop monitoring\nClustering techniques are not\
    \ widely employed in DA, few efforts have been deployed to \ninvestigate the potential\
    \ of these techniques for zones’ delineation within a field. There \nare several\
    \ reasons for splitting an agricultural field into zones. Some traditional reasons\
    \ \ninclude crop diversification within a field, crop-rotation, facilitating the\
    \ management \ntasks, and more recently we defined the zones based on yield maps.\
    \ This usually helps \nto improve the overall crop yield of the field, by managing\
    \ the zones more effectively. \nTherefore, delineation of Management zones (DMZ)\
    \ is a very important task for farming \noperations since determining zones of\
    \ low-or-high yields, and understanding the rea-\nsons behind low yields, can\
    \ help come up with specific solution for each zone with the \nview to increase\
    \ the yields. In addition, it has other economic benefits, because we can \ntarget\
    \ each zone with the right amount of fertilisers, water, and other nutrients.\n\
    According to [69], delineation of management zones is an effective way to manage\
    \ the \nvariability of soil within a field, such that each zone will receive specific\
    \ management. In \n[145], a management zone is defined as a subregion of a field\
    \ that has a relatively homo-\ngeneous combination of yield-limiting factors,\
    \ for which a single rate of a specific crop \ninput is appropriate to reach maximum\
    \ efficiency of farm inputs. In [53], it is defined as \na subregion of a field\
    \ that is relatively homogeneous with regard to soil attributes.\nDMZ is a complex\
    \ spatial problem, which is addressed in the literature from several \nperspectives.\
    \ This has attracted interest from many researchers [61, 85, 87, 110, 140]. A\
    \ \nliterature review has been presented in [90], where the authors discussed\
    \ the delineation \nof soil management zones from the variable-rate fertilisation\
    \ point of view. many other \nstudies presented the delineation based on various\
    \ criteria. Some techniques that have \nbeen used include topographic maps, direct\
    \ soil sampling, non-invasive soil sampling by \nelectrical conductivity equipment,\
    \ soil organic matter or organic estimated by remote \nsensing, and yield maps\
    \ built using data collected over several seasons/years [99].\nFigure  6 depicts\
    \ the general process of delineation of management zones designed \naccording\
    \ to methodologies followed by the majority of the literature.\nThe majority of\
    \ problems that are related to crop management imply the management \nof fields\
    \ and zones. Therefore, the collected data is usually characterised by geographic\
    \ \ncoordinates and time associated with each sample, which leads to the use of\
    \ data min-\ning techniques that are more suitable for spatial and temporal datasets.\
    \ It is well rec-\nognised that agricultural datasets are typically spatio-temporal,\
    \ as the data is always \nassociated with location and time. However, these datasets\
    \ contain a significant amount \nof noise, outliers, and even missing values.\
    \ For instance, GPS capture devices introduce \nPage 22 of 37\nChergui and Kechadi\
    \  Journal of Big Data           (2022) 9:123 \nTable 6 An analytical study on\
    \ examples of crop maturity monitoring (fruits detection and \ncounting) approaches;\
    \ highlights the applied algorithm, plant and data type, data pre-processing \n\
    and the extracted features\nReferences\nApplication\nAlgorithm\nPlant\nData type\n\
    Data pre-\nprocessing\nExtracted \nfeatures\n[123]\nFruit detec-\ntion\nEM\nTomato\n\
    High spacial \nresolution sensor \nimages\nNoise and \nstalks remov-\ning spacial\
    \ \nsegmentation\nShape and size\n[23]\nFruit detec-\ntion\nANN\nApple fruit \n\
    and tree \ncanopy\nDigital images\nSegmentation\nArea of fruit-\nsarea of small\
    \ \nfruits cross-\nsectional area \nof foliage fruit \nnumber total \ncross-section\
    \ \ntotal cross-\nsectional\n[108]\nFruit detec-\ntion\nSVM\nCoffee\nDigital images\n\
    Segmenta-\ntion: homo-\ngeneous \ninformation\n42 colours \nfeatures\n[5]\nFruit\
    \ detec-\ntion\nBC Gaussian\nCherry\nDigital images\nSegmenta-\ntion: enhance-\n\
    ments  and \nspecular \nreflections \nremoving \nby inward \ninterpolation \n\
    method\nColours \nfeatures:RGB\n[52]\nFruit detec-\ntion &clas-\nsification\n\
    CNN\nStrawberries\nDigital images\nHand marking \nregions of \ninterests\n/\n\
    [75]\nImmature fruit \ndetection\nANN\nPeach\nDigital images\nHue-Satura-\ntion-Intensity\
    \ \nfor illumina-\ntion enhance-\nmentpixels’ \nnormalisation \nhistogram \nequalisation\
    \ \nreconstruc-\ntion of images \nbackgoud \nelimination\nTexture features\n[117]\n\
    Fruit counting\nCNN\nSweet pep-\nperrock melon \nstrawberry \napple, avo-\ncado\
    \ mango, \norange\nMulti-spectral \nimages(RGB,NIR)\nPixel-wise \nsegmentaion\
    \ \nbounding box \nannotation\nColour and tex-\nture features\n[122]\nImmature\
    \ \nfruitcounting\nSVM\nGreen citrus\nDigital images\nImages \nconversion \nfrom\
    \ RGB to \ngraycircular \nHough trans-\nform\n13 texture \nfeatures\nPage 23 of\
    \ 37\nChergui and Kechadi  Journal of Big Data           (2022) 9:123 \n \nsome\
    \ noise, imprecisions, and even outliers in the data. Satellite imagery also faces\
    \ huge \nimprecision and noise (such as clouds, ...).\nBecause of the type of\
    \ the datasets, which is spatio-temporal, it is not surprising \nto notice that\
    \ the majority of the clustering algorithms used are of type partitional. \nK-means\
    \ and Fuzzy C-Mean (FCM) are considered among the most popular clustering \ntechniques\
    \ and heavily used to cluster agricultural data [17, 18, 84, 134, 137, 142, 151,\
    \ \n154]. The FCM approach has an advantage over K-means, as it deals better with\
    \ impre-\ncision and noisy data. Moreover, other types of clustering algorithms\
    \ have also been \nproven to be efficient in DA, such as density-based and hierarchical-based\
    \ clustering \ntechniques applied to DMZ [48, 116].\nAs mentioned above, besides\
    \ its huge importance in crop management, delineation \nof management zone (DMZ)\
    \ has received much attention, as the data is now available \nnot only from traditional\
    \ sources but also from refined sources, including advanced data \npre-processing\
    \ techniques. In addition, the recently collected data integrates knowledge \n\
    of experts and farmers experiences on their fields, which improves significantly\
    \ the qual-\nity of the data [84, 141]. Advanced imaging enhancement techniques\
    \ improve further \nthe data quality, and they offer the ability to track the\
    \ development of crops and provide \na Geo-referenced data that can describe the\
    \ spatial and the temporal variability of soil \nand crops variables at high resolution,\
    \ covering large areas [17, 84, 101, 132, 133, 141, \n151].\nSystematic analysis\n\
    In the following we will explore the application of data analytics in DA and its\
    \ extension \nto big data, and illustrate the practical challenges that hinder\
    \ the full adoption of DA by \nfarmers.\nDA in (small /large) scale farming\n\
    Farming can be carried out on a small or large-scale fields depending on several\
    \ fac-\ntors like land size, capital, farmer skills, level of use of machinery\
    \ and technology, etc. \nAccording to FAO3 and Grain4, over 90% of all farms worldwide\
    \ are of small-scale hold-\ning on average 2.2 hectares (from 0.6 to 10 hectares),\
    \ except for Northern America \nwhere small farms have an average size of 67.7\
    \ hectares5. Small-scale farms represent \n25% of the world’s farmland today,\
    \ where 73.12% are located in developing countries.\nFig. 6 The delineation management\
    \ zones process\n3 http:// faost at3. fao. org/ faost at- gatew ay/ go/ to/ home/.\n\
    4 https:// grain. org.\n5 According to the criterion put forward by Lincoln University\
    \ in Nebraska, which defines a small farm in the US as one \nwith an annual turnover\
    \ of less than US$50,000)\nPage 24 of 37\nChergui and Kechadi  Journal of Big\
    \ Data           (2022) 9:123 \nIn [10] the authors described three categories\
    \ of smart farming technology, which are \ncomplementary:\n• Data acquisition\
    \ technologies: they are used to acquire the data that is related to the \nfarm.\
    \ These include remote sensing, weather data, etc.;\n• Data analysis and evaluation\
    \ technologies: these technologies usually take as input \nthe data that has been\
    \ collected so far and deliver insight to the farmer. These include \ncomputer-based\
    \ visualisation and decision models, farm management and informa-\ntion systems;\n\
    • Precision application technologies: these are focusing on variable-rate application\
    \ \nand guidance technologies.\nThe application of smart technologies and data\
    \ analytics for crop management are not \nrestricted to one kind of farm. Nowadays,\
    \ every farm should adopt smart technologies, \nas they are needed for variable\
    \ rates applications (irrigation, pesticides, fertilisers) [72, \n102, 154] while\
    \ protecting the environment.\nThe size of the farm determines how these technologies\
    \ will be used. Large farms tend \nto develop their smart technology to monitor\
    \ their farming land, or to afford some of the \nexisting sophisticated systems\
    \ like CropX as they hold the scale and margins. While small \nfarms tend to rent\
    \ sophisticated machinery and smart applications on demand, especially \nwith\
    \ the proliferation of cloud technologies that makes these smart applications\
    \ reason-\nable, the work of [30] is an example among others, of a smart irrigation\
    \ system designed \nfor smallholders. Besides, some technologies are more suitable\
    \ for large-scale farms like \ndrones and aerial vehicles used to monitor crops\
    \ which are not as profitable or efficient \nfor small scales because they have\
    \ less difficulty visualising their crops. On the other side, \nlarge-scale farms\
    \ are responsible for 70% of current deforestation6, the largest share of \nagriculture-related\
    \ greenhouse-gazes emissions, agricultural water use and habitat disrup-\ntion\
    \ resulting in biodiversity loss. Generally, small-scale farms require considerably\
    \ fewer \nexternal inputs and cause minor damage to the environment.\nTable  7\
    \ summarises the main differences between small and large-scale farming from \n\
    several perspectives. However, DA can be applied to any kind of farm without restric-\n\
    tion. Yet, we have found that the number of papers that addressed large-scale\
    \ farms is \nalmost the same as works on large-scale farms.\nTechnologies for\
    \ data acquisition Table  7 can be used to all types of farms, such as \nremote\
    \ sensing, imagery data systems, and so on. The acquired data, over the years,\
    \ can \nlead to the phenomenon of Big Data. If pre-processed and stored properly,\
    \ this will give \na significant competitive advantage to farms that collected\
    \ them, whether they are small \nor large. Some of the applications and data analyses\
    \ that can be performed of the col-\nlected are summarised in the Tables  1,  2,\
    \  3, 4 and  5,  6.\nDA and big data\nBig data is not just characterised by the\
    \ volume, but also by velocity, variety, and oth-\ners [86]. These are enough\
    \ to challenge the existing data mining techniques, as trying \n6 IPBES, 2019:\
    \ Global Assessment Report on Biodiversity and Ecosystem Services of the Intergovernmental\
    \ Science-\nPolicy Platform on Biodiversity and Ecosystem Services.\nPage 25 of\
    \ 37\nChergui and Kechadi  Journal of Big Data           (2022) 9:123 \n \nTable\
    \ 7 Comparison between small-scale and large-scale farming\nBasis for comparison\n\
    Small-scale farming\nLarge-scale farming\nBasis for comparison\nSmall-scale farming\n\
    Large-scale farming\n% of all farms\n92.3%\n25%\nApplication of modern smart \n\
    technologies\nYes\nYes\n% of world’s farmland\n7.7%\n75%\nMapping technologies\n\
    Yes\nYes\nBudget (investment)\nLow to medium\nHigh\nData acquisition (cameras\
    \ sur-\nveying, sensing and navigation)\nYes\nYes\nMachinery vs labour\nLabour-based\n\
    Machinery-based\nVariable rate application\nHighly used: Irrigation \npesticides\
    \ fertilisation \nseeding for some crops\nLow to medium use: Irrigation \nfertilisation\
    \ pesticides\nTarget crops and cropping \nsystem\nHumain Food Backyard Arable\
    \ \ncrops Forage crops Vineyards \nField vegetables Orchards\nCommercial crops\
    \ plants grown \nfor animal feed or biofuels wood \nproducts other non-food crops\n\
    Navigation systems usability \n(GPS, INS,..) Inertial Navigation \nsystem (INS)+\
    \ Unmanned vehi-\ncles and drones\nLow to medium (73.12% \nof farms situated on\
    \ \ndeveloping countries)\nHigh\nFarming method\nExtensive\nintensive\nApplications\n\
    All applications\nAll applications\nContributors to agricultural infor-\nmation\
    \ and knowledge\nLow\nMedium to high\nUsers of agricultural information \nand\
    \ knowledge\nLow\nMedium to high\nEffective climate change capacity \nmeasures\
    \ and adaptation\nEnvironmentally friendly\nEnvironmentally not friendly\nSustainability\n\
    yes\nNo\nScope\nProduction for local communities Corporate farms Factory farms:\
    \ \nprofit and business oriented plan \nexportation\nExamples of references\n\
    [114 , 123, 136,   132, 137] [ 26, 43, 62,  67,  100, 102,   154]\nPage 26 of\
    \ 37\nChergui and Kechadi  Journal of Big Data           (2022) 9:123 \nto develop\
    \ techniques to deal with large volumes of data (volume), various types of data\
    \ \nattributes (variety or heterogeneity), and be able to analyse the new data\
    \ as soon as it \nis collected (velocity) are extremely challenging tasks. Moreover,\
    \ many other character-\nistics can be found in some big data-driven applications,\
    \ these include veracity, value, \nviscosity, veracity, visualisation, etc. In\
    \ this study, we added veracity, as the data, col-\nlected by various instruments\
    \ and sensors, is of different quality, which creates a huge \nchallenge to the\
    \ data pre-processing task, and therefore its analysis. In the following, we \n\
    discuss the impact of Big Data challenges on DA.\n• Velocity: many studies that\
    \ have been examined do not consider the data velocity \nduring their data collection.\
    \ In DA, the frequency of collecting data depends on its \nsource and the problem\
    \ for which the data was collected. Some applications need \nreal-time data and\
    \ others do not. For instance, crop yield prediction does not need \nreal-time\
    \ data or data streams. It is performed at ad-hoc, while crop protection and \n\
    disease detection require high quality sensors and imagery data connected to effi-\n\
    cient methods of data analysis, which need continuous control.\n• Variety: this\
    \ is very common in agricultural datasets, as multiple sources were used \nto\
    \ collect all the necessary information about the farm and farming operations.\
    \ The \ndata values can be a simple number such as temperatures to more elaborated\
    \ such as \nimagery data, NDVI, soil texture, etc. This makes the definition of\
    \ distance measures \nand other parameters of the learning algorithms very difficult.\n\
    • Veracity: Agricultural data contains many missing values and collected from\
    \ various \nsources of varying quality. The data is very noisy, and more importantly\
    \ it contains \nmany missing values. Therefore, it is very challenging to clean\
    \ and prepare it for the \nanalysis. This was the case in the work conducted by\
    \ [37], and also in [93–96, 107] \nwhere data was collected from very large farming\
    \ areas.\nTable  8, summarises a set of representative papers reported in the\
    \ paper according to \ntheir usage of big data. For each paper, we identify the\
    \ type, the size, the heterogeneity \nof data used, and the frequency of its collection.\
    \ Also, we consider the number and type \nof ML algorithms used, the complexity\
    \ of the proposed analysis algorithms and devices \nused to collect data, data\
    \ analysis applied to a given crop and problem to solve. One \ncan notice while\
    \ the data analysis algorithms and techniques were heavily used and var-\nied,\
    \ the rigorous process of knowledge discovery was not followed, usually the data\
    \ is \nrelatively small either in size (small observations) or the data has few\
    \ dimensions (for \ninstance, considering only weather data, or fertiliser, without\
    \ taking into account other \nfactors).\nFrom Table  8, we can extract three classes\
    \ of applications according to their usage of \nbig data: Full usage (the data\
    \ contains all the characteristics of big data), light usage (the \ndata contains\
    \ some characteristics), non-usage (the data does not contain any character-\n\
    istic of big data).\nTo examine the degree of use of the big data concept and\
    \ to figure out which of its \ndimension is more present, we conducted a statistical\
    \ study where we classify works \naccording to their employment of the 4Vs of\
    \ big data.\nPage 27 of 37\nChergui and Kechadi  Journal of Big Data         \
    \  (2022) 9:123 \n \nTable 8 DA applications and their usage of big data concepts\n\
    References V1\nV2\nV3\nV4\nML\nComplexity\nDevice\nTask\n[2]\n224 images\n/\n\
    No\nImage Data digital images\nSVM\nO(n2 ∗ P + n3) + O(nsv ∗ P)\nDigital camera\n\
    Classification\n[18]\n3*2 years of data monitor-\ning\n1 year\n/\nSensor data:\
    \ soil properties\nFCM\ntime: O(n ∗ d ∗ c2 ∗ i) \nspace:O(n ∗ d + n ∗ c)\nPressure-based\
    \ \nAgLeader\nClustering\n[26]\n/\n/\nNo\nSatellite data: Images in \nGeoTiff\n\
    EnsembleLearn-\ning (DT+ SVM+ \nANN)\nO(n2 ∗ P) + O(P) + O(n2 ∗ P + n3) \n+O(nsv\
    \ ∗ P)+ \nO(ep ∗ n(nl1 ∗ nl2 + nl2 ∗ nl3 + ...)+ \nO(P ∗ nl1 + nl1 ∗ nl2 + nl2\
    \ ∗ nl3 + ...)\nSatellite\nClassification\n[38]\n87.8K\n/\nYes Image data: Open\
    \ database \nimages\nCNN\nO(T ∗ Q ∗ t ∗ q)\n/\nClassification\n[40]\n/\n/\nYes\
    \ All data types: yield climate \ninformationsoil Geo-physi-\ncal NDVI Remote\
    \ sensed\nRF\nO(n2 ∗ P ∗ ntrees) + O(P ∗ ntrees)\nYield monitor \nsoil-maps, EM\
    \ \ngamma survey \nMODIS\nPrediction\n[46]\n6217\n/\n/\nHistoricalsensor data:\
    \ Yield \nclimate\nSVR, KNN, ANN\nO(n2P + n3) + O(nsv ∗ P); O(n ∗ P); \nO(ep ∗\
    \ n(nl1 ∗ nl2 + nl2 ∗ nl3 + ...)+ \nO(P ∗ nl1 + nl1 ∗ nl2 + nl2 ∗ nl3 + ...)\n\
    Spriter-GIS \nsystem\nPrediction\n[57]\n229\n1 year\nYes Historical data: Crop\
    \ yield\nK-means\nO(n ∗ c ∗ d ∗ i)\n/\nClustering\n[59]\nPrecipitation: 47554\
    \ min/\nmax temperature:24542 \nmean temperature:14835\n/\nYes Sensor data: Crop\
    \ yield soil \nBiophysical climate water \nphoto-period, fertilisation\nRF\nO(n2\
    \ ∗ P ∗ ntrees) + O(P ∗ ntrees)\n/\nPrediction\n[33]\n10413\n/\n/\nImage data:\
    \ Digital images\nCNN\nO(T ∗ Q ∗ t ∗ q)\nCell phone\nClassifiation\n[73]\n/\n\
    1 year\nNo\nHistorical data: Crop yield \nsoil parameters\nELM\nO(L3 + L2 ∗ n)\n\
    /\nPrediction\n[75]\n96\n1year\nYes Image data: Digital images\nSVM, ANN, \nNBKNN\
    \ DT \nDiscriminant \nanalysis\nDiscriminant analysis: O(n ∗ P2) NB: \nO(n ∗ p)\
    \ + O(P)\nCamera Nikon \nCoolpixL22\nClassification\n[76]\n4 Landsat-8 scenes\
    \ 15 \nSentinel-1 scenes\n/\nYes Satellite data: Multi-tempo-\nral multi-source\
    \ images\nCNN\nO(T ∗ Q ∗ t ∗ q)\nLandsat-8, \nSentinel-1A satel-\nlites\nClassification\n\
    Page 28 of 37\nChergui and Kechadi  Journal of Big Data           (2022) 9:123\
    \ \nTable 8 (continued)\nReferences V1\nV2\nV3\nV4\nML\nComplexity\nDevice\nTask\n\
    [152]\n8945\nmulti-spectral image: 8 \ndays interval for 30 per year\nYes Satellite,\
    \ sensor data: \nsurface reflectance land \nsurface temperature land \ncover\n\
    Gaussian CNN\nO(T ∗ Q ∗ t ∗ 2)\nMODIS satellite\nPrediction\n[62]\n/\n2006-2011\
    \ 8 days period \n32 times\n/\nSatellite sensor data: NDVI \nPrecipitation land\
    \ surface \ntemperature\nRulequest cubist O(n2 ∗ P)\nMODIS satellite\nPrediction\n\
    No data was clear,Yes data was cleaned and filtered and some samples were not\
    \ considered because of abnormalities, inconsistencies or duplication and for\
    \ other reasons,n number of data points.nsv : number of support \nvectors,P number\
    \ of features,ntrees : number of trees,c number of cluster,d  number of dimension.i\
    \  number of iterations,L number of hidden layers,T ∗ Q size of input feature\
    \ map; spatial, two/three-dimensional kernels are \nof size (t ∗ q),nli :number\
    \ of neurons at layer i,ep: number of epochs\nPage 29 of 37\nChergui and Kechadi\
    \  Journal of Big Data           (2022) 9:123 \n \nFigures  7 and  8 show that\
    \ no work has a full employment of big data (4Vs). One can \nnotice that the agricultural\
    \ data is multidimensional and heterogeneous (variety). More-\nover, we have found\
    \ that the prediction applications display more use of big data, there \nexist\
    \ studies that have used three dimensions such as DMZ applications. It is worth\
    \ not-\ning that these applications, either prediction or delineation of zones,\
    \ have the potential \nto use big data to provide stable and accurate results.\n\
    If we put aside the volume dimension (V1) (see Figure  7, only 7% of the reviewed\
    \ \nstudies used (V2, V3 and V4), and 32% of studies just employed data mining\
    \ techniques \nfor agriculture problems. The most employed data mining techniques\
    \ are for prediction, \nincluding yield prediction, forecasting, prediction of\
    \ fertiliser applications, etc.\nDA practical challenges\nThere exist a number\
    \ of challenges and obstacles impeding the potential benefit of DA. \nIn [104],\
    \ the authors studied the barriers that prevent the adoption of smart farming\
    \ \nin their country, Brazil. Some of these barriers include lack of integration\
    \ and compat-\nibility between different agriculture systems, lack of advanced\
    \ data manipulation of data \nobtained from different equipment, poor telecommunications\
    \ infrastructure on rural \nareas, and finally, the lack of training in deploying\
    \ and using new technologies. These \nbarriers are common to the majority of countries\
    \ in the world.\nFig. 7 Distribution of works according to the used Big Data dimensions’\n\
    Fig. 8 Percent of employment of big data dimensions\nPage 30 of 37\nChergui and\
    \ Kechadi  Journal of Big Data           (2022) 9:123 \nFrom the Table  7, we\
    \ can see that over 73% of crop farms are located in developing \ncountries. So\
    \ that, the investment in high and sophisticated DA technologies is not \nthere.\
    \ Most of the main technologies used in DA systems (GPS, UAV, auto-steering and\
    \ \nvariable rate technology) are designed for relatively large-scale farms located\
    \ in devel-\noped countries [10] or designed by developed countries. Some of these\
    \ technologies are \nbecoming available recently. For instance, since 2018 African\
    \ scientists can have access \nto free and open-source satellite data as a result\
    \ of a deal signed by the African Union \nwith the European Commission’s Copernicus\
    \ programme.\nAs DA is relatively new technology, there is a lack of standards\
    \ and common solutions \nfor data collection, preparation and storage. In addition,\
    \ there is a lack of data for many \nreasons, farmers did not record their data\
    \ and it takes time to build significant historical \ndatasets [20, 39, 77, 78,\
    \ 92, 146]. Another major barrier is that many farmers are relying \nmore on their\
    \ expertise and refusing to adopt these new and complex technologies [10]. \n\
    Moreover, the transition from their traditional practices and farming habits to\
    \ these \ntechnologies comes with a cost and energy (training and learning new\
    \ skills).\n[20] States that the legal and regulatory frameworks around the collection,\
    \ sharing and \nuse of agricultural data contributes to a range of challenges.\
    \ Many laws potentially influ-\nence the ownership, control of and data access.\
    \ Ref. [74] presented a set of socio-ethical \nimperatives associated with the\
    \ use of data in agriculture, including dependency risks, \ndata concentration,\
    \ potential lock-in effects, and the peril of transformation of farmers \ninto\
    \ information tools, in addition to the sustainability challenges.\nFinally, according\
    \ to [47], the real economic value of the use of big data in farming is \nstill\
    \ unknown, especially for small-scale farming. Consequently, it will be hard to\
    \ con-\nvince them to switch from process-driven towards data and machine learning\
    \ driven. \nThis is reaffirmed in [20], where the authors stated that on one side,\
    \ farmers are enticed \nwith promises of increased profits and farming efficiency,\
    \ on the other hand the proofs \nare not there yet.\nConclusion\nDigital agriculture\
    \ (DA) is a data-driven approach that exploits the hidden information \nwithin\
    \ the collected data to gain new insights; transforming the farming practices\
    \ from \nintuitive-based decision-making to informed-based decision-making. DA\
    \ relies on effi-\ncient data collection practices, efficient data preparation\
    \ and storage techniques, effi-\ncient data analytics, and efficient deployment\
    \ and exploitation of the gained insights to \nmake optimal farming decisions.\n\
    In this study, we presented a systematic review of the potential use of the data\
    \ mining \nprocess in crop production and management and highlighted serious gaps\
    \ which can be \nconsidered in future studies. The majority of the current practices\
    \ were dominated by \nstatistical analyses and small machine learning systems.\
    \ However, these can only give \nsome ideas within a very limited view of the\
    \ overall system. Agricultural data-driven \napplications collect a significant\
    \ amount of data from various sources. This constitutes \nan excellent opportunity\
    \ to the field to answer numerous research and practical ques-\ntions that were\
    \ not possible before. Nevertheless, despite all the advantages that can \nbe\
    \ gained from DA, there are several other challenges and obstacles that need to\
    \ be \nPage 31 of 37\nChergui and Kechadi  Journal of Big Data           (2022)\
    \ 9:123 \n \naddressed, among them lack of data, lack of skills, and lack of maturity\
    \ and standards so \nthat it can be adopted and deployed quickly and easily.\n\
    In this study, we cover approaches that deal the entire process of data mining;\
    \ from \ndata collection to knowledge deployment. We cover this process from big\
    \ data view, \nwith more focus on crop monitoring and management in an attempt\
    \ to understand the \nchallenges that DA is currently facing. We defined the research\
    \ questions addressed by \nthe study and provided a classification of data mining\
    \ techniques used in the field. For \neach class, a set of representative existing\
    \ works have been reviewed, and an analytical \nstudy has been provided to highlight\
    \ the category of machine learning method applied \nand for which purpose. We\
    \ discussed the big data concepts and its current impact on \nDA, and showed that\
    \ from the data analyst’s view, the transition towards DA is ready \nto embrace\
    \ big data analytics concepts. This provides new opportunities of investment \n\
    into these challenges and allows for a efficient ways of managing crops. Besides,\
    \ it will \nprovide farmers with new insights into how they can grow crops more\
    \ efficiently, while \nminimising the impact on the environment. It also promises\
    \ new levels of scientific dis-\ncovery and innovative solutions to more complex\
    \ problems.\nAbbreviations\nANN \n Artificial Neural Network\nBC \n Bayesian classifier\n\
    CNN \n Convolution Neural Network\nDT \n Decision tree\nDMZ \n Delineation of\
    \ management zones\nDNN \n Deep Neural Network\nELM \n Extreme learning machine\n\
    EVI \n Enhanced Vegetation Index\nFCM \n Fuzzy C-means\nGIS \n Geographical information\
    \ system\nGPS \n Global positioning system\nINS \n Inertial navigation system\n\
    KNN \n K-Nearest Neighbour\nLSTM \n Long/Short Term Memory Network\nKNN \n K-Nearest\
    \ Neighbour\nMLP \n Multi-layer perceptron\nMODIS \n Moderate-resolution imaging\
    \ spectro-radiometer\nNDVI \n Normalised difference vegetation index\nOSAVI \n\
    \ Optimised soil adjusted vegetation index\nRF \n Random forest\nRBF \n Radial\
    \ basis function\nRGB \n RedGreenBlue\nRNN \n Recurrent neural network\nRVI \n\
    \ Ratio Vegetation Index\nSVM \n Support vector machine\nSVI \n Spectral vegetation\
    \ index\nSVR \n Support vector regression\nUAV \n Unmanned aerial vehicle\nUGV\
    \ \n Unmanned ground vehicles\nWDRVI \n Weighted dynamic ranged vegetation index\n\
    Acknowledgements\nThis work is supported by the SFI Strategic Partnerships Programme\
    \ (16/SPP/3296) and is co-funded by Origin Enter-\nprises Plc.\nAuthor contributions\n\
    NC and TK conceived of the presented idea. NC designed the paper and figures,\
    \ collected and analysed the results \nextracted from the reviewed papers. TK\
    \ verified the relevance of the bibliography and the consistency of the results.\
    \ \nAll authors participated at the writing of the manuscript and provided critical\
    \ feedback and helped shape the research, \nanalysis and manuscript. All authors\
    \ read and approved the final manuscript.\nFunding\nNot applicable.\nPage 32 of\
    \ 37\nChergui and Kechadi  Journal of Big Data           (2022) 9:123 \nAvailability\
    \ of data and materials\nNot applicable.\nDeclarations\nEthics approval and consent\
    \ to participate\nNot applicable.\nConsent for publication\nNot applicable.\n\
    Competing interests\nThe authors declare that they have no competing interests.\n\
    Received: 10 January 2022   Accepted: 29 November 2022\nReferences\n \n1. Abbas\
    \ F, Afzaal H, Farooque A, Tang S. Crop yield prediction through proximal sensing\
    \ and machine learning \nalgorithms. Agronomy. 2020. https:// doi. org/ 10. 3390/\
    \ agron omy10 071046.\n \n2. Ahmed F, Al-Mamun H, Bari H, Hossain E, Kwan P. Classification\
    \ of crops and weeds from digital images: a support \nvector machine approach.\
    \ Crop Prot. 2012;40:98–104. https:// doi. org/ 10. 1016/j. cropro. 2012. 04.\
    \ 024.\n \n3. Akbarzadeh S, Paap A, Ahderom S, Apopei B, Alameh K. Plant discrimination\
    \ by support vector machine classifier \nbased on spectral reflectance. Comput\
    \ Electron Agric. 2018;148:250–8. https:// doi. org/ 10. 1016/j. compag. 2018.\
    \ 03. \n026.\n \n4. Alibabaei K, Gaspar P, Lima T. Crop yield estimation using\
    \ deep learning based on climate big data and irrigation \nscheduling. Energies.\
    \ 2021;14:3004. https:// doi. org/ 10. 3390/ en141 13004.\n \n5. Amatya S, Karkee\
    \ M, Gongal A, Zhang Q, Whiting M. Detection of cherry tree branches with full\
    \ foliage in planar \narchitecture for automated sweet-cherry harvesting. Biosyst\
    \ Eng. 2015;146:3–15. https:// doi. org/ 10. 1016/j. biosy \nstems eng. 2015.\
    \ 10. 003.\n \n6. Aravind K, Raja P. Automated disease classification in (selected)\
    \ agricultural crops using transfer learning. Autom J \nControl Meas Electron\
    \ Comput Commun. 2020;62:260–72. https:// doi. org/ 10. 1080/ 00051 144. 2020.\
    \ 17289 11.\n \n7. Aravind K, Maheswari P, Raja P, Szczepanski C. Crop disease\
    \ classification using deep learning approach: an \noverview and a case study.\
    \ In: Das H, Pradhan C, Dey N, editors. Deep learning for data analytics foundations,\
    \ \nbiomedical applications, and challenges. Cambridge: Academic Press; 2020.\
    \ p. 173–95. https:// doi. org/ 10. 1016/ \nb978-0- 12- 819764- 6. 00010-7.\n\
    \ \n8. Arribas J, Sanches-Ferrero G, Ruiz-Ruiz G, Gomez-Gil J. Leaf classification\
    \ in sunflower crops by computer vision \nand neural networks. Comput Electron\
    \ Agric. 2011;78:9–18. https:// doi. org/ 10. 1016/j. compag. 2011. 05. 007.\n\
    \ \n9. Arsenovic M, Karanovic M, Sladojevic S, Anderla A, Stefanovic D. Solving\
    \ current limitations of deep learning based \napproaches for plant disease detection.\
    \ Symmetry. 2019. https:// doi. org/ 10. 3390/ sym11 070939.\n 10. Balafoutis\
    \ AT, Beck B, Fountas S, Tsiropoulos Z, Vangeyte J, van der Wal T, Soto-Embodas\
    \ I, Gomez-Barbero M, \nPedersen S,. Smart farming technologies–description taxonomy\
    \ and economic impact. In: Pedersen SM, Lind K, \neditors. Precision agriculture:\
    \ technology and economic perspectives, progress in precision agriculture, chapter\
    \ 2. \nCham: Springer; 2017. p. 21–78. https:// doi. org/ 10. 1007/ 978-3- 319-\
    \ 68715-5.\n 11. Barbedo JA. Impact of dataset size and variety on the effectiveness\
    \ of deep learning and transfer learning for plant \ndisease classification. Comput\
    \ Electron Agric. 2018;153:46–53. https:// doi. org/ 10. 1016/j. compag. 2018.\
    \ 08. 013.\n 12. Behmann J, Mahlein AK, Rumpf T, Romer C, Plumer L. A review of\
    \ advanced machine learning methods for the \ndetection of biotic stress in precision\
    \ crop protection. J Precis Agric. 2014;16:239–60. https:// doi. org/ 10. 1007/\
    \ \ns11119- 014- 9372-7.\n 13. Bendre M, Thool R, Thool V. Big data in precision\
    \ agriculture through ICT: rainfall prediction using neural network \napproach.\
    \ In: Satapathy S, Bhatt Y, Joshi A, Mishra D, editors. Proceedings of the International\
    \ congress on informa-\ntion and communication technology. Singapore: Springer;\
    \ 2016. p. 165–75.\n 14. Berckmans D. Precision livestock farming technologies\
    \ for welfare management in intensive livestock systems. Rev \nSci. 2014;33:189–96.\n\
    \ 15. Bi L, Hu G, Raza M, Kandel Y, Leandro L, Mueller D. A gated recurrent units\
    \ (gru)-based model for early detection \nof soybean sudden death syndrome through\
    \ time-series satellite imagery. Remote Sens. 2020. https:// doi. org/ 10. \n\
    3390/ rs122 13621.\n 16. Brahimi M, Arsenovic M, Laraba S, Sladojevic S, Boukhalfa\
    \ K, Moussaoui A. Deep learning for plant diseases: detec-\ntion and saliency\
    \ map visualisation. In: Zhou J, Chen F, editors. Human and machine learning.\
    \ Cham: Springer; \n2018. p. 93–117. https:// doi. org/ 10. 1007/ 978-3- 319-\
    \ 90403-0_6.\n 17. Breunig F, Galvao L, Dalagnol R, Dauve C, Parraga A, Santi\
    \ A, Flora DD, Chen S. Delineation of management zones \nin agricultural fields\
    \ using cover-crop biomass estimates from planetscope data. Int J Appl Earth Obs\
    \ Geoinf. 2020. \nhttps:// doi. org/ 10. 1016/j. jag. 2019. 102004.\n 18. Brock\
    \ A, Brouder S, Blumhoff G, Hofmann B. Defining yield-based management zones for\
    \ corn-soybean rotations. \nAgron J. 2005;97:1115–28. https:// doi. org/ 10. 2134/\
    \ agron j2004. 0220.\n 19. Cao J, Zhao Z, Luo Y, Zhang L, Zhang J. ZLi, Tao F,\
    \ Wheat yield predictions at a county and field scale with deep \nlearning, machine\
    \ learning, and google earth engine. Eur J Agron. 2021;123: 126204. https:// doi.\
    \ org/ 10. 1016/j. eja. \n2020. 126204.\nPage 33 of 37\nChergui and Kechadi  Journal\
    \ of Big Data           (2022) 9:123 \n \n 20. Carolan M. Acting like an algorithm:\
    \ digital farming platforms and the trajectories they (need not) lock-in. Agric\
    \ \nHum Values. 2020;37:1041–53. https:// doi. org/ 10. 1007/ s10460- 020- 10032-w.\n\
    \ 21. Chen J, Liu Q, Gao L. Visual tea leaf disease recognition using a convolutional\
    \ neural network model. Symmetry. \n2019. https:// doi. org/ 10. 3390/ sym11 030343.\n\
    \ 22. Chen N, Yu L, Zhang X, Shen Y, Zeng L, Hu Q, Niyogi D. Mapping paddy rice\
    \ fields by combining multi-temporal \nvegetation index and synthetic aperture\
    \ radar remote sensing data using google earth engine machine learning \nplatform.\
    \ Remote Sens. 2020;2020. https:// doi. org/ 10. 3390/ rs121 82992.\n 23. Cheng\
    \ H, Damerow L, Sun Y, Blanke M. Early yield prediction using image analysis of\
    \ apple fruit and tree \ncanopy features with neural networks. J Imaging. 2017.\
    \ https:// doi. org/ 10. 3390/ jimag ing30 10006.\n 24. Chergui N, Kechadi T,\
    \ McDonnell M, The impact of data analytics in digital agriculture: a review.\
    \ In: the 2020 \nIEEE International multi-conference on: organization of knowledge\
    \ and advanced technologies (OCTA). Isko-\nMaghreb: ’International society for\
    \ knowledge organization’. February 6-8, 2020 Tunis (Tunisia). 2020. https://\
    \ \ndoi. org/ 10. 1109/ OCTA4 9274. 2020. 91518 51\n 25. Chinchuluun R, Lee W,\
    \ Bhorania J, Pardalos P. Clustering and classification algorithms in food and\
    \ agricultural \napplications: a survey. In: Papajorgji PJ, Pardalos PM, editors.\
    \ Advances in modelling agricultural systems \nspringer optimisation and its applications.\
    \ Boston: Springer; 2008. p. 433–54.\n 26. Contiu S, Groza A. Improving remote\
    \ sensing crop classification by argumentation-based conflict resolution in \n\
    ensemble learning. Expert Syst Appl. 2016;64:269–86. https:// doi. org/ 10. 1016/j.\
    \ eswa. 2016. 07. 037.\n 27. Crane-Droesch A. Machine learning methods for crop\
    \ yield prediction and climate change impact assessment \nin agriculture. Environ\
    \ Res Lett. 2018. https:// doi. org/ 10. 1088/ 1748- 9326/ aae159.\n 28. Cruz\
    \ A, Luvisi A, Bellis LD, Ampatzidis Y. X-fido: an effective application for detecting\
    \ olive quick decline syn-\ndrome with deep learning and data fusion. Front Plant\
    \ Sci. 2017. https:// doi. org/ 10. 3389/ fpls. 2017. 01741.\n 29. Dadashzadeh\
    \ M, Abbaspour-Gilandeh Y, Mesri-Gundoshmian T, Sabzi S, Hernández-Hernández J,\
    \ Hernández-\nHernández M, Arribas J. Weed classification for site-specific weed\
    \ management using an automated stereo \ncomputer-vision machine-learning system\
    \ in rice fields. Plants. 2020;5:22–36. https:// doi. org/ 10. 3390/ plant \n\
    s9050 559.\n 30. Dahane A, Benameur R, Kechar B. An IoT low-cost smart farming\
    \ for enhancing irrigation efficiency of small-\nholders farmers. Wirel Pers Commun.\
    \ 2022. https:// doi. org/ 10. 1007/ s11277- 022- 09915-4.\n 31. Debats S, Luo\
    \ D, Estes L, Fuchs T, Caylor K. A generalized computer vision approach to mapping\
    \ crop fields in \nheterogeneous agricultural landscapes. Remote Sens Environ.\
    \ 2016;179:210–21. https:// doi. org/ 10. 1016/j. rse. \n2016. 03. 010.\n 32.\
    \ Du CJ, Kechadi M, Zhang YB, Huang BQ. A hybrid HMM-SVM method for online handwriting\
    \ symbolrecogni-\ntion. Intell Syst Des Appl. 2006;3:887–91. https:// doi. org/\
    \ 10. 1109/ ISDA. 2006. 61.\n 33. Dyrmann M, Karstoft H, Midtiby H. Plant species\
    \ classification using deep convolutional neural network. \nBiosyst Eng. 2016;151:72–80.\
    \ https:// doi. org/ 10. 1016/j. biosy stems eng. 2016. 08. 024.\n 34. Ehret D,\
    \ Hill B, Helmer T, Edwards D. Neural network modeling of greenhouse tomato yield,\
    \ growth and water \nuse from automated crop monitoring data. Comput Electron\
    \ Agric. 2011;79:82–9. https:// doi. org/ 10. 1016/j. \ncompag. 2011. 07. 013.\n\
    \ 35. Elavarasan D, Vincent D, Sharma V, Zomaya A, Srinivasan K. Forecasting yield\
    \ by integrating agrarian factors \nand machine learning models: A survey. Comput\
    \ Electron Agric. 2018;155:257–82. https:// doi. org/ 10. 1016/j. \ncompag. 2018.\
    \ 10. 024.\n 36. Fardusi MJ, Chianucci F, Barbati A. Concept to practice of geospatial-information\
    \ tools to assist forest manage-\nment and planning under precision forestry framework\
    \ a review. Ann Silvic Res. 2017;41:3–14. https:// doi. org/ \n10. 12899/ asr-\
    \ 1354.\n 37. Feldman B, Martin E, Skotnes T. Big data in healthcare hype and\
    \ hope, october 2012.dr. bonnie 2012;360, 2012. \nHttp://www.westinfo.eu/files/big-data-inhealthcare\n\
    \ 38. Ferentinos PK. Deep learning models for plant disease detection and diagnosis.\
    \ Comput Electron Agric. \n2018;145:311–8. https:// doi. org/ 10. 1016/j. compag.\
    \ 2018. 01. 009.\n 39. Fielke S, Taylor B, Jakku E. Digitalisation of agricultural\
    \ knowledge and advice networks: a state-of-the art. Agric \nSyst. 2020. https://\
    \ doi. org/ 10. 1016/j. agsy. 2019. 102763.\n 40. Filippi P, Jones E, Bishop T,\
    \ Acharige N, Dewage S, Johnson L, Ugbaje S, Jephcott T, Paterson S, Whelan B.\
    \ A big \ndata approach to predicting crop yield. In: Proceedings of the 7th Asian-Australasian\
    \ Conference on Precision \nAgriculture 16-18 October 2017. Hamilton; 2017.https://\
    \ doi. org/ 10. 5281/ zenodo. 893668\n 41. Formaggio A, Vieira M, Renno C. Object\
    \ based image analysis (obia) and data mining (dm) in landsat time \nseries for\
    \ mapping soybean in intensive agricultural regions. In: Proceedings of IEEE International\
    \ Geoscience \nand Remote Sensing Symposium. 22-27 July 2012. Munich; 2012. p.\
    \ 2257–2260. https:// doi. org/ 10. 1109/ \nIGARSS. 2012. 63510 47\n 42. Fukuda\
    \ S, Spreer W, Yasunaga E, Yuge K, Sardsud V, Muller J. Random forests modelling\
    \ for the estimation of \nmango (Mangifera indica l. cv.chok anan) fruit yields\
    \ under different irrigation regimes. J Agric Water Manag. \n2013;116:142–50.\
    \ https:// doi. org/ 10. 1016/j. agwat. 2012. 07. 003.\n 43. Galambosova J, Rataj\
    \ V, Prokeinova R, Presinska J. Determining the management zones with hierarchic\
    \ and \nnon-hierarchic clustering methods. Res Agric Eng. 2014;60:44–51. https://\
    \ doi. org/ 10. 17221/ 34/ 2013- RAE.\n 44. Gao J, Nuyttens D, Lootens P, He Y,\
    \ Pieters J. Recognising weeds in a maize crop using a random for-\nest machine-learning\
    \ algorithm and near-infrared snapshot mosaic hyperspectral imagery. Biosyst Eng.\
    \ \n2018;170:30–50. https:// doi. org/ 10. 1016/j. biosy stems eng. 2018. 03.\
    \ 006.\n 45. Golhani K. KBalasundram S, Vadamalai G, Pradhan B, A review of neural\
    \ networks in plant disease detection \nusing hyperspectral data. Inf Proc Agric.\
    \ 2018;5:354–71. https:// doi. org/ 10. 1016/j. inpa. 2018. 05. 002.\n 46. Gonzalez-Sanchez\
    \ A, Frausto-Solis J, Ojeda-Bustamante W. Predictive ability of machine learning\
    \ methods for \nmassive crop yield prediction. Spanish J Agric Res. 2014;12:313–28.\
    \ https:// doi. org/ 10. 5424/ sjar/ 20141 22- 4439.\n 47. Griffin T, Mark T,\
    \ Ferrell S, Janzen T, Ibendahl G, Bennett J, Maurer J, Shanoyan A. Big data considerations\
    \ for \nrural property professionals. Am Soc Farm Manage Rural Appraisers. 2016;79:167–80.\n\
    Page 34 of 37\nChergui and Kechadi  Journal of Big Data           (2022) 9:123\
    \ \n 48. Guastaferro F, Castrignano A, Benedetto DD, Sollitto D, Troccoli A, Cafarelli\
    \ B. A comparison of different \nalgorithms for the delineation of management\
    \ zones. Precis Agric. 2010;11:600–20. https:// doi. org/ 10. 1007/ \ns11119-\
    \ 010- 9183-4.\n 49. Guo A, Huang W, Dong Y, Ye H, Ma H, Liu B, Wu W, Ren Y, Ruan\
    \ C, Geng Y. Wheat yellow rust detection using \nUAV-based hyperspectral technology.\
    \ Remote Sensing. 2021. https:// doi. org/ 10. 3390/ rs130 10123.\n 50. Guo Y,\
    \ Fu Y, Hao F, Zhang X, Wu W, Jin X, Bryant C, Senthilnath J. Integrated phenology\
    \ and climate in rice yields \nprediction using machine learning methods. Ecol\
    \ Indic. 2021;120: 106935. https:// doi. org/ 10. 1016/j. ecoli nd. 2020. \n106935.\n\
    \ 51. Gyamerah S, Ngare P, Ikpe D. Probabilistic forecasting of crop yields via\
    \ quantile random forest and Epanechnikov \nKernel function. Agric For Meteorol.\
    \ 2020. https:// doi. org/ 10. 1016/j. agrfo rmet. 2019. 107808.\n 52. Habaragamuwa\
    \ H, Ogawa Y, Suzuki T, Masanori T, Kondo O. Detecting greenhouse strawberries\
    \ (mature and \nimmature), using deep convolutional neural network. Eng Agric\
    \ Environ Food. 2018;11:127–38. https:// doi. org/ 10. \n1016/j. eaef. 2018. 03.\
    \ 001.\n 53. Haghverdi A, Leib B, Washington-Allen R, Ayers P, Buschermohle M.\
    \ Perspectives on delineating management \nzones for variable rate irrigation.\
    \ Comput Electron Agric. 2015;117:154–67. https:// doi. org/ 10. 1016/j. compag.\
    \ 2015. \n06. 019.\n 54. Han J, Zhang Z, Cao J, Luo Y, Zhang L, Li Z, Zhang J.\
    \ Prediction of winter wheat yield based on multi-source data \nand machine learning\
    \ in china. Remote Sensing. 2020. https:// doi. org/ 10. 3390/ rs120 20236.\n\
    \ 55. Huang K. Application of artificial neural network for detecting phalaenopsis\
    \ seedling diseases using color and \ntexture features. Comput Electron Agric.\
    \ 2007;57:3–11. https:// doi. org/ 10. 1016/j. compag. 2007. 01. 015.\n 56. Huang\
    \ Y, Chen Z, Yu T, Huang X, Gu X. Agricultural remote sensing big data: Management\
    \ and applications. J \nIntegr Agric. 2018;17:1915–31. https:// doi. org/ 10.\
    \ 1016/ S2095- 3119(17) 61859-8.\n 57. Ingeli M, Galambosova J, Prokeinova R,\
    \ Rataj V. Application of clustering method to determine production zones \nof\
    \ field. Acta Technol Agric. 2015;18:42–5. https:// doi. org/ 10. 1515/ ata- 2015-\
    \ 0009.\n 58. Jain M, Mondal P, DeFries R, Small C, Galford G. Mapping cropping\
    \ intensity of smallholder farms: a comparison of \nmethods using multiple sensors.\
    \ Remote Sensing Environ. 2013;134:210–23. https:// doi. org/ 10. 1016/j. rse.\
    \ 2013. 02. \n029.\n 59. Jeong J, Resop J, Mueller N, Fleisher D, Yun K, Butler\
    \ E, Timlin D, Shim K, Gerber J, Reddy V, Kim S. Random forests \nfor global and\
    \ regional crop yield predictions. PLoS ONE. 2016. https:// doi. org/ 10. 1371/\
    \ journ al. pone. 01565 71.\n 60. Ji Z, Pan Y, Zhu X, Wang J, Li Q. Prediction\
    \ of crop yield using phenological information extracted from remote \nsensing\
    \ vegetation index. Sensors. 2021;4:1406. https:// doi. org/ 10. 3390/ s2104 1406.\n\
    \ 61. Jiang Q, Wang QFZ. Study on delineation of irrigation management zones based\
    \ on management zone analyst \nsoftware. In: Jiang Q, editor. Computer and computing\
    \ technologies in agriculture IV. CCTA 2010 IFIP advances in \ninformation and\
    \ communication technology, vol. 346. Berlin: Springer; 2011. p. 4559–66. https://\
    \ doi. org/ 10. 1007/ \n978-3- 642- 18354-6_ 50\n 62. Johnson D. An assessment\
    \ of pre-and within-season remotely sensed variables for forecasting corn and\
    \ soybean \nyields in the united states. Remote Sensing Environ. 2014;141:116–28.\
    \ https:// doi. org/ 10. 1016/j. rse. 2013. 10. 027.\n 63. Kamal K, Yin Z, Wu\
    \ M, Wu Z. Depthwise separable convolution architectures for plant disease classification.\
    \ Com-\nput Electron Agric. 2019. https:// doi. org/ 10. 1016/j. compag. 2019.\
    \ 104948.\n 64. Kamilaris A, Kartakoullis A, Prenafeta-Boldú F. A review on the\
    \ practice of big data analysis in agriculture. Comput \nElectron Agric. 2017;143:23–37.\
    \ https:// doi. org/ 10. 1016/j. compag. 2017. 09. 037.\n 65. Kamir E, Waldner\
    \ F, Hochman Z. Estimating wheat yields in Australia using climate records, satellite\
    \ image time \nseries and machine learning methods. ISPRS J Photogramm Remote\
    \ Sens. 2020;160:124–35. https:// doi. org/ 10. \n1016/j. isprs jprs. 2019. 11.\
    \ 008.\n 66. Khalili E, Kouchaki S, Ramazi S, Ghanati F. Machine learning techniques\
    \ for soybean charcoal rot disease prediction. \nFront Plant Sci. 2021. https://\
    \ doi. org/ 10. 3389/ fpls. 2020. 590529.\n 67. Kim N, Lee Y. Machine learning\
    \ approaches to corn yield estimation using satellite images and climate data:\
    \ a case \nof Lowa state. J Korean Soc Surv Geod Photogramm Cartogr. 2016;34:383–90.\
    \ https:// doi. org/ 10. 7848/ ksgpc. 2016. \n34.4. 383.\n 68. Kim N, Ha K, Park\
    \ N, Cho J, Hong S, Lee Y. A comparison between major artificial intelligence\
    \ models for crop yield \nprediction: case study of the midwestern united states,\
    \ 2006–2015. ISPRS Int J Geoinform. 2019. https:// doi. org/ \n10. 3390/ ijgi8\
    \ 050240.\n 69. Kitchen N, Sudduth K, Myers D, Drummond S, Hong S. Delineating\
    \ productivity zones on claypan soil fields using \napparent soil electrical conductivity.\
    \ Comput Electron Agric. 2005;46:285–308. https:// doi. org/ 10. 1016/j. compag.\
    \ \n2004. 11. 012.\n 70. Klerk L, Jakku E, Labarthe P. A review of social science\
    \ on digital agriculture, smart farming and agriculture 4.0: new \ncontributions\
    \ and a future research agenda. NJAS Wageningen J Life Sci. 2019. https:// doi.\
    \ org/ 10. 1016/j. njas. 2019. \n100315.\n 71. Klompenburg T, Kassahun A, Catal\
    \ C. Crop yield prediction using machine learning: a systematic literature review.\
    \ \nComput Electron Agric. 2020. https:// doi. org/ 10. 1016/j. compag. 2020.\
    \ 105709.\n 72. Koch B, Khosla R, Frasier W, Westfall D, Inman D. Economic feasibility\
    \ of variable-rate nitrogen application utilizing \nsite-specific management zones.\
    \ Agron J. 2004;96:1572–80. https:// doi. org/ 10. 2134/ agron j2004. 1572.\n\
    \ 73. Kouadio L, Deo R, Byrareddy V, Adamowski J, Mushtaq S, Nguyen VP. Artificial\
    \ intelligence approach for the predic-\ntion of robusta coffee yield using soil\
    \ fertility properties. Comput Electron Agric. 2018;155:324–38. https:// doi.\
    \ org/ \n10. 1016/j. compag. 2018. 10. 014.\n 74. Kritikos M. Precision agriculture\
    \ in europe: legal, social and ethical considerations. science and technology\
    \ options \nassessment. Scientific foresight unit (STOA) of the European parliament,\
    \ brussels pe 603.207. 2017.\n 75. Kurtulmus F, Lee W, Vardar A. Immature peach\
    \ detection in colour images acquired in natural illumination \nconditions using\
    \ statistical classifiers and neural network. Precis Agric. 2014;15:57–79. https://\
    \ doi. org/ 10. 1007/ \ns11119- 013- 9323-8.\nPage 35 of 37\nChergui and Kechadi\
    \  Journal of Big Data           (2022) 9:123 \n \n 76. Kussul N, Lavreniuk M,\
    \ Skakun S, Shelestov A. Deep learning classification of land cover and crop types\
    \ using \nremote sensing data. Geosci Remote Sens Lett. 2017;14:778–82. https://\
    \ doi. org/ 10. 1109/ LGRS. 2017. 26811 28.\n 77. Lioutas E, Charatsari C. Big\
    \ data in agriculture: does the new oil lead to sustainability? Geoforum. 2020;109:1–3.\
    \ \nhttps:// doi. org/ 10. 1016/j. geofo rum. 2019. 12. 019.\n 78. Lioutas ED,\
    \ Charatsari C, Rocca GL, Rosa MD. Key questions on the use of big data in farming:\
    \ an activity theory \napproach. NJAS Wageningen J Life Sci. 2019. https:// doi.\
    \ org/ 10. 1016/j. njas. 2019. 04. 003.\n 79. Liu B, Zhang Y, He D, Li Y. Identification\
    \ of apple leaf diseases based on deep convolutional neural networks. Sym-\nmetry.\
    \ 2017. https:// doi. org/ 10. 3390/ sym10 010011.\n 80. Liu L, Dong Y, Huang\
    \ W, Du X, Ma H. Monitoring wheat fusarium head blight using unmanned aerial vehicle\
    \ \nhyperspectral imagery. Remote Sens. 2020. https:// doi. org/ 10. 3390/ rs122\
    \ 23811.\n 81. Ma H, Jing Y, Huang W, Shi Y, Dong Y, Zhang J, Liu L. Integrating\
    \ early growth information to monitor winter wheat \npowdery mildew using multi-temporal\
    \ Landsat-8 imagery. Sensors. 2018. https:// doi. org/ 10. 3390/ s1810 3290.\n\
    \ 82. Mahlein A, Alisaac E, Masri AA, Behmann J, Dehne H, Oerke E. Comparison\
    \ and combination of thermal, fluores-\ncence, and hyperspectral imaging for monitoring\
    \ fusarium head blight of wheat on spikelet scale. Sensors. 2019. \nhttps:// doi.\
    \ org/ 10. 3390/ s1910 2281.\n 83. Maimaitijiang M, Sagan V, Sidike P, Hartling\
    \ S, Esposito F, Fritschi F. Soybean yield prediction from UAV using multi-\n\
    modal data fusion and deep learning. Remote Sens Environ. 2020. https:// doi.\
    \ org/ 10. 1016/j. rse. 2019. 111599.\n 84. Martinez-Casasnovas J, Escola A, Arno\
    \ J. Use of farmer knowledge in the delineation of potential management \nzones\
    \ in precision agriculture: a case study in maize (Zea mays L.). Agriculture.\
    \ 2018. https:// doi. org/ 10. 3390/ agric \nultur e8060 084.\n 85. Mathur SBR,\
    \ Shukla A, Suresh K, Prakash C. Spatial variability of soil properties and delineation\
    \ of soil management \nzones of oil palm plantations grown in a hot and humid\
    \ tropical region of southern India. Catena. 2018;165:251–9. \nhttps:// doi. org/\
    \ 10. 1016/j. catena. 2018. 02. 008.\n 86. Mauro AD, Greco M, Grimaldi M. A formal\
    \ definition of big data based on its essential features. Libr Rev. \n2016;65:122–35.\
    \ https:// doi. org/ 10. 1108/ LR- 06- 2015- 0061.\n 87. Metwally M, Shaddad S,\
    \ Liu M, Yao R, Abdo A, Li P, Jiao J, Chen X. Soil properties spatial variability\
    \ and delineation \nof site-specific management zones based on soil fertility\
    \ using fuzzy clustering in a hilly field in Jianyang, Sichuan, \nChina. Sustainability.\
    \ 2019;2019. https:// doi. org/ 10. 3390/ su112 47084.\n 88. Mohanty S, Hughes\
    \ D, Salathe M. Using deep learning for image-based plant disease detection. Front\
    \ Plant Sci. \n2016;7:1–10. https:// doi. org/ 10. 3389/ fpls. 2016. 01419.\n\
    \ 89. Mucherino A, Papajorgji P, Pardalos PM. A survey of data mining techniques\
    \ applied to agriculture. J Operational \nRes. 2009;9:121–40. https:// doi. org/\
    \ 10. 1007/ s12351- 009- 0054-6.\n 90. Nawar S, Corstanje R, Halcro G, Mulla D,\
    \ Mouazen A. Delineation of soil management zones for variable-rate fertili-\n\
    zation: a review. Adv Agron. 2017;143:175–245. https:// doi. org/ 10. 1016/ bs.\
    \ agron. 2017. 01. 003.\n 91. Nevavuori P, Narra N, Linna P, Lipping T. Crop yield\
    \ prediction using multitemporal UAV data and spatio-temporal \ndeep learning\
    \ models. Remote Sens. 2020;12:4000. https:// doi. org/ 10. 3390/ rs122 34000.\n\
    \ 92. Newton J, Nettle R, Pryce J. Farming smarter with big data: Insights from\
    \ the case of Australia’s national dairy herd \nmilk recording scheme. Agric Syst.\
    \ 2020. https:// doi. org/ 10. 1016/j. agsy. 2020. 102811.\n 93. Ngo M, Kechadi\
    \ T. Electronic farming records-a framework for normalising agronomic knowledge\
    \ discovery. \nComput Electron Agric. 2021. https:// doi. org/ 10. 1016/j. compag.\
    \ 2021. 106074.\n 94. Ngo QH, Le-Khac NA, Kechadi T. Predicting soil pH by using\
    \ nearest fields. In: Bramer M, Petridis M, editors. Artifi-\ncial Intelligence\
    \ XXXVI. SGAI 2019. Lecture notes in computer science, vol. 11927. Cham: Springer;\
    \ 2019. https:// \ndoi. org/ 10. 1007/ 978-3- 030- 34885-4_ 40.\n 95. Ngo VM,\
    \ Kechadi MT Crop knowledge discovery based on agricultural big data integration.\
    \ In: Proceedings of the \n4th International conference on machine learning and\
    \ soft computing, association for computing machinery. \nNew York; ICMLSC. 2020.\
    \ https:// doi. org/ 10. 1145/ 33806 88. 33807 05\n 96. Ngo VM, Le-Khac N, Kechadi\
    \ T. Data warehouse and decision support on integrated crop big data. Int J Bus\
    \ Pro-\ncess Integr Manag. 2020. https:// doi. org/ 10. 1504/ IJBPIM. 2020. 113115.\n\
    \ 97. Oliveira I, Cunha R, Silva B, Netto M. A scalable machine learning system\
    \ for pre-season agriculture yield forecast. \nIn: the 14th IEEE eScience Conference.\
    \ 2018. https:// doi. org/ 10. 1109/ eScie nce. 2018. 00131\n 98. Oliver D, Bartie\
    \ P, Heathwaite A, Pschetz L, Quilliam R. Design of a decision support tool for\
    \ visualising E. coli risk on \nagricultural land using a stakeholder-driven approach.\
    \ Land Use Policy. 2017;66:227–34. https:// doi. org/ 10. 1016/j. \nlandu sepol.\
    \ 2017. 05. 005.\n 99. Ortega R, Santibanez O. Determination of management zones\
    \ in corn (Zea mays L.) based on soil fertility. Comput \nElectron Agric. 2007;58:49–59.\
    \ https:// doi. org/ 10. 1016/j. compag. 2006. 12. 011.\n 100. Ouzemou J, Harti\
    \ AE, Lhissou R. AEl-Moujahid, Bouch N, El-Ouazzani R, Bachaoui E, El-Ghmari A,\
    \ Crop type map-\nping from pansharpened Landsat 8 NDVI data: a case of a highly\
    \ fragmented and intensive agricultural system. \nRemote Sens Appl Soc Environ.\
    \ 2018. https:// doi. org/ 10. 1016/j. rsase. 2018. 05. 002.\n 101. Pantazi X,\
    \ Moshou D, Mouazen A, Alexandridis T, Kuang B. Data fusion of proximal soil sensing\
    \ and remote crop \nsensing for the delineation of management zones in arable\
    \ crop precision farming. In: CEUR Workshop Proceed-\nings. CEUR-WS. 2015. p.\
    \ 765–776.\n 102. Pantazi X, Moshou D, Alexandridis T, Whetton R, Mouazen A. Wheat\
    \ yield prediction using machine learning and \nadvanced sensing techniques. J\
    \ Comput Electron Agric. 2016;121:57–65. https:// doi. org/ 10. 1016/j. compag.\
    \ 2015. \n11. 018.\n 103. Patricio D, Rieder R. Computer vision and artificial\
    \ intelligence in precision agriculture for grain crops: a systematic \nreview.\
    \ Comput Electron Agric. 2018;153:69–81. https:// doi. org/ 10. 1016/j. compag.\
    \ 2018. 08. 001.\n 104. Pivoto D, Waquil P, Talamini E, Finocchio C, Corte V,\
    \ Mores G. Scientific development of smart farming technologies \nand their application\
    \ in Brazil. Inform Process Agric. 2018;5:21–32. https:// doi. org/ 10. 1016/j.\
    \ inpa. 2017. 12. 002.\n 105. Poppe K, Wolfert S, Verdouw C, Verwaart T. Information\
    \ and communication technology as a driver for change in \nagri-food chains. Eurochoices.\
    \ 2013;12:60–5.\nPage 36 of 37\nChergui and Kechadi  Journal of Big Data     \
    \      (2022) 9:123 \n 106. Qin F, Liu D, Sun B, Ruan L, Ma Z, Wang H. Identification\
    \ of alfalfa leaf diseases using image recognition technol-\nogy. PLoS ONE. 2016.\
    \ https:// doi. org/ 10. 1371/ journ al. pone. 01682 74.\n 107. Rafii F, TKechadi.\
    \ Collection of historical weather data: Issues with missing values. In: Proceedings\
    \ of the 4th Inter-\nnational conference on smart city applications, association\
    \ for computing machinery. New York; 2019. https:// doi. \norg/ 10. 1145/ 33687\
    \ 56. 33689 74\n 108. Ramos P, Prieto F, Montoya E, Oliveros C. Automatic fruit\
    \ count on coffee branches using computer vision. Comput \nElectron Agric. 2017;137:9–22.\
    \ https:// doi. org/ 10. 1016/j. compag. 2017. 03. 010.\n 109. Raza M, Harding\
    \ C, Liebman M, Leandro L. Exploring the potential of high-resolution satellite\
    \ imagery for the \ndetection of soybean sudden death syndrome. Remote Sens. 2020.\
    \ https:// doi. org/ 10. 3390/ rs120 71213.\n 110. Reyes J, Wendroth O, Matocha\
    \ C, Zhu J. Delineating site-specific management zones and evaluating soil water\
    \ \ntemporal dynamics in a farmer’s field in Kentucky. Vadose Zone J. 2019;18:1–19.\
    \ https:// doi. org/ 10. 2136/ vzj20 18. \n07. 0143.\n 111. Rezapour S, Jooyandeh\
    \ E, Ramezanzade M, Mostafaeipour S, Jahangiri M, Issakhov A, Chowdhury S, Techato\
    \ K. \nForecasting rainfed agricultural production in arid and semi-arid lands\
    \ using learning machine methods: a case \nstudy. Sustainability. 2021;13:4607.\
    \ https:// doi. org/ 10. 3390/ su130 94607.\n 112. Reznik T, Lukas V, Krivanek\
    \ Z, Kepka M, Herman L, Reznikova H. Disaster risk reduction in agriculture through\
    \ geo-\nspatial (big) data processing. ISPRS Int J Geoinform. 2017. https:// doi.\
    \ org/ 10. 3390/ ijgi6 080238.\n 113. Rijswijk K, Klerk L, Turner J. Digitalisation\
    \ in the New Zealand agricultural knowledge and innovation system: Initial \n\
    understandings and emerging organisational responses to digital agriculture. NJAS\
    \ Wageningen J Life Sci. 2019. \nhttps:// doi. org/ 10. 1016/j. njas. 2019. 100313.\n\
    \ 114. Ji R, Min J, Wang Y, Cheng H, Zhang H, Shi W. In-season yield prediction\
    \ of cabbage with a hand-held active \ncanopy sensor. Sensors. 2017. https://\
    \ doi. org/ 10. 3390/ s1710 2287.\n 115. Rosa LCL, Feitosa R, Happ P, Sanches\
    \ ID, da Costa GOP. Combining deep learning and prior knowledge for crop \nmapping\
    \ in tropical regions from multi-temporal SAR image sequences. Remote Sens. 2019.\
    \ https:// doi. org/ 10. \n3390/ rs111 72029.\n 116. RuB G, Krus R. Exploratory\
    \ hierarchical clustering for management zone delineation in precision agriculture.\
    \ In: \nIndustrial conference on data mining ICDM 2011: advances in data mining.\
    \ Applications and theoretical aspects. \nLecture notes in computer science book\
    \ series (LNCS, volume 6870). 2011. p. 161–173. https:// doi. org/ 10. 1007/ \n\
    978-3- 642- 23184-1_ 13\n 117. Sa I, Ge Z, Upcroft FDB, Perez T, Mccool C. Deepfruits:\
    \ a fruit detection system using deep neural networks. Sen-\nsors. 2016. https://\
    \ doi. org/ 10. 3390/ s1608 1222.\n 118. Sa I, Popovic M, Khanna R, Chen Z, Lottes\
    \ P, Liebisch F, Nieto J, Stachniss C, Walter A, Siegwart R. Weedmap: a \nlarge-scale\
    \ semantic weed mapping framework using aerial multispectral imaging and deep\
    \ neural network for \nprecision farming. Remote Sens. 2018. https:// doi. org/\
    \ 10. 3390/ rs100 91423.\n 119. Sabzi S, Abbaspour-Gilandeh Y. Using video processing\
    \ to classify potato plant and three types of weed using \nhybrid of artificial\
    \ neural network and particle swarm algorithm. Measurement. 2018;126:22–36. https://\
    \ doi. org/ \n10. 1016/j. measu rement. 2018. 05. 037.\n 120. Sakamoto T. Incorporating\
    \ environmental variables into a modis-based crop yield estimation method for\
    \ United \nstates corn and soybeans through the use of a random forest regression\
    \ algorithm. ISPRS J Photogramm Remote \nSens. 2020;160:208–28. https:// doi.\
    \ org/ 10. 1016/j. isprs jprs. 2019. 12. 012.\n 121. Schwalbert R, Amado T, Corassa\
    \ G, Pott L, Prasad P, Ciampitti I. Satellite-based soybean yield forecast: integrating\
    \ \nmachine learning and weather data for improving crop yield prediction in southern\
    \ brazil. Agric For Meteorol. \n2020. https:// doi. org/ 10. 1016/j. agrfo rmet.\
    \ 2019. 107886.\n 122. Sengupta S, Lee W. Identification and determination of\
    \ the number of immature green citrus fruit in a canopy \nunder different ambient\
    \ light conditions. Biosyst Eng. 2014;117:51–61. https:// doi. org/ 10. 1016/j.\
    \ biosy stems eng. \n2013. 07. 007.\n 123. Senthilnath J, Dokania A, Kandukuri\
    \ M, Ramesh K, Anand G, Omkar S. Detection of tomatoes using spectral-spatial\
    \ \nmethods in remotely sensed RGB images captured by UAV. Biosyst Eng. 2016;146:16–32.\
    \ https:// doi. org/ 10. 1016/j. \nbiosy stems eng. 2015. 12. 003.\n 124. Shafi\
    \ U, Mumtaz R, Garcia-Nieto J, Hassan S, Zaidi S, Iqbal N. Precision agriculture\
    \ techniques and practices: from \nconsiderations to applications. Sensors. 2019.\
    \ https:// doi. org/ 10. 3390/ s1917 3796.\n 125. Sibiya M, Sumbwanyambe M. A\
    \ computational procedure for the recognition and classification of maize leaf\
    \ \ndiseases out of healthy leaves using convolutional neural networks. AgriEngineering.\
    \ 2019;1:119–31. https:// doi. \norg/ 10. 3390/ agrie ngine ering 10100 09.\n\
    \ 126. Singh A, Jones S, Ganapathysubramanian B, Sarkar S, Mueller D, Sandhu K,\
    \ Nagasubramanian K. Challenges and \nopportunities in machine-augmented plant\
    \ stress phenotyping. Trends Plant Sci. 2021;25:53–69. https:// doi. org/ \n10.\
    \ 1016/j. tplan ts. 2020. 07. 010.\n 127. Singh S, Ganapathysubramanian B, Sarkar\
    \ S, Singh A. Deep learning for plant stress phenotyping: trends and \nfuture\
    \ perspectives. Trends Plant Sci. 2018;23:883–98. https:// doi. org/ 10. 1016/j.\
    \ tplan ts. 2018. 07. 004.\n 128. Sivakumar ANV, Li J, Scott S, Psota E, Jhala\
    \ A, Luck J, Shi Y. Comparison of object detection and patch-based classi-\nfication\
    \ deep learning models on mid- to late-season weed detection in UAV imagery. Remote\
    \ Sens. 2020. https:// \ndoi. org/ 10. 3390/ rs121 32136.\n 129. Sladojevic S,\
    \ Arsenovic M, Culibrk AAD, Stefanovic D. Deep neural networks based recognition\
    \ of plant diseases by \nleaf image classification. Computl Intell Neurosci. 2016.\
    \ https:// doi. org/ 10. 1155/ 2016/ 32898 01.\n 130. Soma K, Bogaardt M, Poppe\
    \ K, Wolfert S, Beers G, Urdu D, Kirova MP, Thurston C, Belles CM. Research for\
    \ agri \ncommittee. impacts of the digital economy on the food chain and the cap.\
    \ Policy department for structural and \ncohesion policies. European parliament.\
    \ Brussels; 2019.\n 131. Song Q, Hu Q, Zhou Q, Hovis C, Xiang M, Tang H, Wu W.\
    \ In-season crop mapping with GF-1/WFV data by combin-\ning object-based image\
    \ analysis and random forest. Remote Sens. 2017. https:// doi. org/ 10. 3390/\
    \ rs911 1184.\n 132. Song X, Wang J, Huang W, Liu L, Yan G, Pu R. The delineation\
    \ of agricultural management zones with high resolu-\ntion remotely sensed data.\
    \ Precis Agric. 2009;10:471–87. https:// doi. org/ 10. 1007/ s11119- 009- 9108-2.\n\
    Page 37 of 37\nChergui and Kechadi  Journal of Big Data           (2022) 9:123\
    \ \n \n 133. Speranza E, Ciferri R, Grego C, Vicente L. A cluster-based approach\
    \ to support the delination of management \nzones in precision agriculture. In:\
    \ IEEE 10 th International Conference on eScience. 2014.https:// doi. org/ 10.\
    \ 1109/ \neScie nce. 2014. 42,\n 134. Speranza E, Ciferri R, Ciferri C. Clustering\
    \ approaches and ensembles applied in the delineation of management \nclasses\
    \ in precision agriculture. In: Proceedings of the XVII GEOINFO, November 2016.\
    \ Campos do Jordao; 2016. p. \n27-30.\n 135. Stombaugh T, Shearer S. Equipment\
    \ technologies for precision agriculture. J Soil Water Conserv. 2000;55:6–11.\n\
    \ 136. Su J, Liu C, Coombes M, Hu X, Wang C, Xu X, Li Q, Chen LGW. Wheat yellow\
    \ rust monitoring by learning from mul-\ntispectral UAV aerial imagery. Comput\
    \ Electron Agric. 2018;155:157–66. https:// doi. org/ 10. 1016/j. compag. 2018.\
    \ 10. \n017.\n 137. Tagarakis A, Liakos V, Fountas S, Koundouras S, Gemtos T.\
    \ Management zones delineation using fuzzy clustering \ntechniques in grapevines.\
    \ Prec Agric. 2013;14:18–39.\n 138. Taylor S, Veal M, Grift T, Mcdonald T, Corley\
    \ F. Precision forestry-operational tactics for today and tomorrow. In: In: \n\
    25th annual Meeting of the council of Forest Engineers. Auburn: Auburn University;\
    \ 2002.\n 139. Too E, Yujian L, Njuki S, Yingchun L. A comparative study of fine-tuning\
    \ deep learning models for plant disease \nidentification. Comput Electron Agric.\
    \ 2019;161:272–9. https:// doi. org/ 10. 1016/j. compag. 2018. 03. 032.\n 140.\
    \ Tripathi R, Shahid ANM, Lal B, Gautam P, Raja R, Mohanty S, Kumar A, Panda B,\
    \ Sahoo R. Delineation of soil manage-\nment zones for a rice cultivated area\
    \ in Eastern India using fuzzy clustering. Catena. 2015;133:128–36. https:// doi.\
    \ \norg/ 10. 1016/j. rse. 2016. 03. 010.\n 141. Vallentin C, Dobers E, Itzerott\
    \ S, Kleinschmit B, Spengler D. Delineation of management zones with spatial data\
    \ \nfusion and belief theory. Prec Agric. 2010;21:802–30. https:// doi. org/ 10.\
    \ 1007/ s11119- 019- 09696-0.\n 142. Vendrusculo L, Kaleita A. Modeling zone management\
    \ in precision agriculture through fuzzy c-means technique \nat spatial database.\
    \ In: Proceedings of the 2011 ASABE Annual International Meeting Sponsored by\
    \ ASABE. Gault \nHouse, Louisville, Kentucky. August 7-10. 2016. p. 350–359. https://\
    \ doi. org/ 10. 13031/ 2013. 38168\n 143. Veys C, Chatziavgerinos F, AlSuwaidi\
    \ A, Hibbert J, Hansen M, Bernotas G, Smith M, Yin H, Rolfe S, Grieve B. Multi-\n\
    spectral imaging for presymptomatic analysis of light leaf spot in oilseed rape.\
    \ Plant Methods. 2019. https:// doi. \norg/ 10. 1186/ s13007- 019- 0389-9.\n 144.\
    \ Villa P, Bresciani M, Pinardi RBM, Giardino C. A rule-based approach for mapping\
    \ macrophyte communities using \nmulti-temporal aquatic vegetation indices. Remote\
    \ Sens Environ. 2015;171:218–33. https:// doi. org/ 10. 1016/j. rse. \n2015. 10.\
    \ 020.\n 145. Vrindts E, Mouazen A, Reyniers M, Maertens K, Maleki M, Ramon H,\
    \ Baerdemaeker JD. Management zones based \non correlation between soil compaction,\
    \ yield and crop data. Biosyst Eng. 2005;92:419–28. https:// doi. org/ 10. \n\
    1016/j. biosy stems eng. 2005. 08. 010.\n 146. Wiseman L, Sanderson J, Zhang A,\
    \ Jakku E. Farmers and their data: an examination of farmers’ reluctance to share\
    \ \ntheir data through the lens of the laws impacting smart farming. NJAS Wageningen\
    \ J Life Sci. 2019. https:// doi. \norg/ 10. 1016/j. njas. 2019. 04. 007.\n 147.\
    \ Wolfert S, Sorensen C, Goense D. Precision forestry-operational tactics for\
    \ today and tomorrow. In: Global Confer-\nence (SRII). San Jose: Annual SRII.\
    \ IEEE; 2014. p. 266–73.\n 148. Wolfert S, Verdouw C, Bogaardt M. Big data in\
    \ smart farming: a review. Agric Syst. 2017;153:69–80. https:// doi. org/ \n10.\
    \ 1016/j. agsy. 2017. 01. 023.\n 149. Xue J, Su B. Significant remote sensing\
    \ vegetation indices: a review of developments and applications. J Sensors. \n\
    2017. https:// doi. org/ 10. 1155/ 2017/ 13536 91.\n 150. Yamamoto K, Togami T,\
    \ Yamaguch N. Super-resolution of plant disease images for the acceleration of\
    \ image-\nbased phenotyping and vigor diagnosis in agriculture. Sensors. 2017.\
    \ https:// doi. org/ 10. 3390/ s1711 2557.\n 151. Yan L, Zhou S, Cifang W, Hongyi\
    \ L, Feng L. Classification of management zones for precision farming in saline\
    \ \nsoil based on multi-data sources to characterize spatial variability of soil\
    \ properties. Trans Chin Soc Agric Eng. \n2007;23:84–9.\n 152. You J, Li X, Low\
    \ M, Lobell D, Ermon S. Deep gaussian process for crop yield prediction based\
    \ on remote sensing \ndata. In: the Thirty-First AAAI Conference on Artificial\
    \ Intelligence. AAAI Publications. 2017. p. 4559–4566.\n 153. Zan X, Zhang X,\
    \ Xing Z, Liu W, Zhang X, Su W, Liu Z, Zhao Y, Li S. Automatic detection of maize\
    \ tassels from UAV \nimages by combining random forest classifier and VGG16. Remote\
    \ Sens. 2020. https:// doi. org/ 10. 3390/ rs121 \n83049.\n 154. Zhang X, Shi\
    \ L, Jia X, Seielstad G, Helgason C. Zone mapping application for precision farming:\
    \ a decision support \ntool for variable rate application. Prec Agric. 2010;11:103–14.\
    \ https:// doi. org/ 10. 1007/ s11119- 009- 9130-4.\n 155. Zhang X, Han L, Dong\
    \ Y, Shi Y, Huang W, Han L, Gonzalez-Moreno P, Ma H, Ye H, Sobeih T. A deep learning-based\
    \ \napproach for automated yellow rust disease detection from high-resolution\
    \ hyperspectral UAV images. Remote \nSens. 2019. https:// doi. org/ 10. 3390/\
    \ rs111 31554.\n 156. Zheng Q, Huang W, Cui X, Shi Y, Liu L. New spectral index\
    \ for detecting wheat yellow rust using sentinel-2 multi-\nspectral imagery. Sensors.\
    \ 2018. https:// doi. org/ 10. 3390/ s1803 0868.\n 157. Zhou Y, Luo J, Feng L,\
    \ Zhou X. DCN-based spatial features for improving parcel-based crop classification\
    \ using \nhigh-resolution optical images and multi-temporal SAR data. Remote Sens.\
    \ 2019. https:// doi. org/ 10. 3390/ rs111 \n31619.\nPublisher’s Note\nSpringer\
    \ Nature remains neutral with regard to jurisdictional claims in published maps\
    \ and institutional affiliations.\n"
  inline_citation: '>'
  journal: Journal of big data
  limitations: '>'
  pdf_link: https://journalofbigdata.springeropen.com/counter/pdf/10.1186/s40537-022-00668-2
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: 'Data analytics for crop management: a big data view'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.18196/jrc.v3i3.13760
  analysis: '>'
  authors:
  - Mochammad Haldi Widianto
  - Mochamad Iqbal Ardimansyah
  - Husni Iskandar Pohan
  - Davy Ronald Hermanus
  citation_count: 7
  full_citation: '>'
  full_text: ">\nJournal of Robotics and Control (JRC) \nVolume 3, Issue 3, May 2022\
    \ \nISSN: 2715-5072, DOI: 10.18196/jrc.v3i3.13760 \n269 \n \n \nJournal Web site:\
    \ http://journal.umy.ac.id/index.php/jrc \nJournal Email: jrc@umy.ac.id \nA Systematic\
    \ Review of Current Trends in Artificial \nIntelligence for Smart Farming to Enhance\
    \ Crop \nYield  \n \nMochammad Haldi Widianto 1*, Mochamad Iqbal Ardimansyah 2,\
    \ Husni Iskandar Pohan 3, Davy Ronald Hermanus 4 \n1,3,4 Computer Science Department,\
    \ School of Computer Science, Bina Nusantara University, Bandung Campus, Jakarta,\
    \ \nIndonesia 11480 \n2 Department of Software Engineering, Universitas Pendidikan\
    \ Indonesia, 229 Dr. Setiabudi Street, Bandung 40514, West \nJava, Indonesia \n\
    Email: 1 mochamad.widianto@binus.ac.id, 2 iqbalardimansyah@upi.edu, 3 husni.pohan@binus.ac.id,\
    \ \n4 davy.hermanus@binus.ac.id \n*Corresponding Author \n \nAbstract—Current\
    \ technology has been widely applied for \ndevelopment, one of which has an Artificial\
    \ Intelligence (AI) \napplied to Smart Farming. AI can give special capabilities\
    \ to be \nprogrammed as needed. In cooperation with agricultural \nsystems, AI\
    \ is part of improving the quality of agriculture. This \ntechnology is no stranger\
    \ to being applied in basic fields such as \nagriculture. This smart technology\
    \ is needed to increase crop \nyields for various regions by utilizing the current\
    \ trends paper. \nThis is necessary because less land is available for agriculture,\
    \ \nand there is a greater need for food sources. Therefore, this \nsystematic\
    \ review aims to collect the current trends in AI studies \nfor Smart Farming\
    \ papers using the latest year features from \n2018-2022. This paper is handy\
    \ for researchers and industry in \nlooking for the latest papers on research\
    \ to enhance crop yields. \nThe authors utilized Preferred Reporting Items for\
    \ Systematic \nReviews and Meta-Analyses (PRISMA) of 534 articles from \nIEEE,\
    \ ACM, MDPI, IAES, and ScienceDirect. After going \nthrough a careful process,\
    \ 67 papers were found that were \njudged according to the criteria. After the\
    \ authors got some of \nthe current trends, the author has discussed several factors\
    \ \nregarding the results obtained to enhance crop yields, such as \nWeather,\
    \ Soil, Irrigation, Unmanned Aerial Vehicle (UAV), \nPest Control, Weed Control,\
    \ and Disease Control. \nKeywords— Artificial Intelligence (AI); Preferred Reporting\
    \ \nItems for Systematic Reviews and Meta-Analyses (PRISMA); \nSmart Farming.\
    \ \nI. \nINTRODUCTION \n It is no longer strange if the world population can reach\
    \ 9.1 \nbillion. It is conceivable that the need for food must have \nincreased\
    \ by 70 percent, and the culture of moving people \nfrom rural to urban areas\
    \ is also a topic of discussion. As the \npopulation increases, one can imagine\
    \ if the land used for \nagriculture will experience a very drastic decline in\
    \ the years \nto come. The most important reasons for reduced food \nproduction\
    \ are improper planning, inappropriate harvesting, \nunpredictable weather conditions,\
    \ irrigation techniques, and \nother matters such as livestock not being maintained\
    \ [1]. \nBut this can be helped by the development of technology. \nThis progress\
    \ will greatly impact if a common thread is drawn. \nStill, it cannot be equated\
    \ altogether because small farmers \nand companies are left behind if they do\
    \ not carry out digital \ntransformation. As a new era of the Internet of Things\
    \ (IoT) \nemerges, several companies have seen how to stay ahead of \nthe curve\
    \ by leveraging open source applications, low-cost \nsensors, and, more generally,\
    \ scale-up farmers and small \nbusinesses. One area also discussed is Artificial\
    \ Intelligence \n(AI), where an algorithm learns independently and contributes\
    \ \nto developing new insights [2]. \nIoT or Internet of Things [3]–[6] also has\
    \ many research \napplications because it can use in almost every technology.\
    \ \nThe current technology in intelligent systems called Smart \nFarming usually\
    \ utilizes the IoT. It also offers software and \nhardware technology solutions\
    \ to increase agricultural yields. \nIts implementation in agricultural land has\
    \ changed over the \npast decade, starting from using holes and scissors to cultivate\
    \ \nfields and machines to harvest crops. Therefore, Smart \nFarming was introduced\
    \ because this technique promises \nefficiency in which farmers take advantage\
    \ of IoT to be \napplied to all farming methods and implementation methods \n\
    [7]. \nSmart Farming [8]–[11] is widely used in agriculture \nbecause it is very\
    \ helpful. In intelligent surveys, each planted \narea had various criteria and\
    \ could be measured from both \nquantity and quality. Some critical Criteria for\
    \ Smart Farming, \nsuch as nutrients [12], soil [13], pests [14], irrigation [15]\
    \ etc., \ndetermine the ability and suitability of certain types of crops. \n\
    In most situations, different criteria usually exist in one crop \nfield, let\
    \ alone for the same crop growing on all available land \nfor agriculture; because\
    \ it requires a specific analysis of the \nlocation needed to map the production\
    \ of plant products \neffectively and efficiently [16].  \nAI or Artificial Intelligence\
    \ [17]–[21] is the one that is often \nused both academically and educationally.\
    \ AI can also be \ncalled something that is imitation based on the human mind\
    \ \nintelligence. It is implanted in machines to be designed so that \nmachines\
    \ can think like humans. It is expected to be able to do \nwhatever living things\
    \ do, so AI can be likened to learning to \nsolve problems. Machine Learning (ML)\
    \ and Deep Learning \n(DL) are part of the AI where ML is above DL. But it has\
    \ the \nsame family under AI. This study becomes the main focus of \ntheir research.\
    \ AI techniques can be applied in this field and \ncombined with IoT and Smart\
    \ Farming. These techniques can \nbe used to capture detailed and very complex\
    \ data, after which \nAI can provide good answers and suggestions for the \nJournal\
    \ of Robotics and Control (JRC) \nISSN: 2715-5072 \n270 \n \nMochammad Haldi Widianto,\
    \ A Systematic Review of Current Trends in Artificial Intelligence for Smart Farming\
    \ to Enhance Crop Yield \nproblems being carried out. Existing AI techniques include\
    \ \nFuzzy Logic and Expert System networks [22].  \nML or Machine Learning [23]–[26],\
    \ has been widely used \nto help facilitate and solve problems. Other things can\
    \ also \ntake advantage of DL or Deep Learning [27]–[30] in solving \nand facilitating\
    \ important issues. Because ML and DL are part \nof AI, the author focuses on\
    \ using them to solve systematic \nreview problems that the author will display.\
    \ \nSeveral examples of Smart Farming systems work on a \ncombination of software\
    \ and hardware to work optimally. \nHardware [31]–[34] is one of the components\
    \ that often exist \nin IoT. Hardware has grown a lot because of support from\
    \ IoT \ncomponents. It can be carried anywhere, low power with \nconnections utilizing\
    \ a wireless network to make connections \nbetween massive devices in large numbers.\
    \ But don't forget to \nuse the Graphics Processing Unit (GPU) to be assisted\
    \ by AI. \nTo collect AI, data can use sensors to get input from the \nenvironment.\
    \ This is mostly done with the use of IoT. Many \ninput can use for Big Data technology\
    \ assists this software, \nwhich supports collecting large amounts of data. The\
    \ IoT \nmodule can collect this information as input from various data \nprocessed\
    \ by sophisticated AI-based software. As a result, AI \ncan provide new decisions\
    \ for farmers. AI works very \neffectively and efficiently in analyzing the current\
    \ trends [35].  \nTherefore, a need for Smart Farming, IoT, and AI arise. \nFarmers\
    \ often monitor and understand crops, which should be \ndone for fieldwork. Therefore,\
    \ agriculture is always related to \nequipment and uses that utilize AI. This\
    \ technology can be \nused from sowing seeds to harvesting. This also helps in\
    \ \ntimely harvest reports to minimize operational costs. Given \nthat each country\
    \ focuses on its agricultural industry, we are \nwaiting for optimal solutions\
    \ on technology with the hope of \nsustainable agriculture that does not cause\
    \ environmental \nimpacts. The latest communication and sensing technologies \n\
    provide capabilities for on-the-ground monitoring that are \nhelpful for land\
    \ pickers and farmers. The wireless sensors do \nan excellent job of real-time\
    \ crop monitoring with features like \ngiving high accuracy, moreover most usefully,\
    \ doing early \ndetection of conditions on farmland [16].  \nApplying these methods\
    \ is not easy. Industry players, \nresearchers, and the government put new hopes\
    \ into \nincreasing agricultural production with this technology, but \nthis is\
    \ not easy if you don't know the current trends in AI for \nSmart Farming and\
    \ how to enhance crop yield. Therefore, it \nis necessary to have a systematic\
    \ review and look at current \ntrends to see AI and other AI methods that can\
    \ help in Smart \nFarming systems. Various ways have been done in \nagriculture,\
    \ such as monitoring, measuring, processing to \ndoing good marketing. Many studies\
    \ have reviewed Smart \nFarming. Terence and Purushothaman [36] focus on Smart\
    \ \nFarming techniques and categorize agricultural techniques in \nIoT-based agricultural\
    \ control and monitoring systems, plant \ndiseases, and automatic irrigation systems.\
    \  \nStudy [37] has taken several into account: plant \nclassification, disease\
    \ detection, precision breeding, land \ncover identification, object recognition\
    \ of pests, weed \ndetection, phenotype, and smart irrigation. Other studies [35],\
    \ \n[38] focus on research in agriculture by conducting systematic \nreviews on\
    \ future trends, challenges, etc. \nThe authors aim to conduct a systematic review\
    \ and \ncurrent trends using some of the AI previous studies suitable \nfor Smart\
    \ Farming to enhance crop yield. Researchers \nproposed using Preferred Reporting\
    \ Items for Systematic \nReviews and Meta-Analyses (PRISMA) [39]. The difference\
    \ \nwith previous studies is that the authors only concentrate on \nusing PRISMA.\
    \ The other aims of this study include the \npublisher of the current trends paper\
    \ focusing on AI for Smart \nFarming to enhance crop yields, the country's current\
    \ trends \npaper focuses on AI for Smart Farming to enhance crop \nyields. \n\
    The contributions of this review are; to make a systematic \nreview of AI for\
    \ Smart Farming to enhance Crop Yield, look \nfor methods/platforms for AI for\
    \ Smart Farming to enhance \nCrop yields, and conduct discussions on the results\
    \ that can \nbe applied to a specific scope. \nFinally, after understanding the\
    \ background of the Study \nin part 1, several sections will be made to organize\
    \ this study \nsystematically. Part 2 explains the methodology that will be \n\
    used in Smart Farming. Next step 3, the author explains the \ndetails of the results\
    \ of the systematic review search. In \nSection 4, the researcher will discuss\
    \ some of the methods \nused. Finally, the very last Part 5 is the conclusion.\
    \ \nII. METHODOLOGY \nMany of the best scientific works are being developed or\
    \ \nhave existed in recent years. The number of studies makes the \narticle. Many\
    \ authors must analyze from different \nperspectives to determine what models\
    \ are suitable. For \nexample, many uses of Smart Farming focus show the \nfundamental\
    \ openings and challenges of utilizing this \ninnovation. This work aims to analyze\
    \ Smart Farming using \nPRISMA by systematically reviewing Smart Farming. Then,\
    \ \nseveral steps were made to help this systematic review, where \nthere are\
    \ 3 phases used. Fig. 1 will display the Methodology \nFlowchart (inspired by\
    \ a previous study [40]). \n \nFig. 1. Methodology Flowchart. \nAfter seeing the\
    \ display in Fig. 1, the author will elaborate \non the criteria, strategies,\
    \ and assessments that will be used \n(Inspired by a previous study [40] ). \n\
    \ \nJournal of Robotics and Control (JRC) \nISSN: 2715-5072 \n271 \n \nMochammad\
    \ Haldi Widianto, A Systematic Review of Current Trends in Artificial Intelligence\
    \ for Smart Farming to Enhance Crop Yield \nA. Research Strategy \nThe author\
    \ makes a strategy. In 2021, research was \nconducted on a website focused on\
    \ Smart Farming. The \nauthor must be more careful in determining this database,\
    \ \nconsidering its scope and relevance. The databases used are \nseveral journals\
    \ and conferences, such as ACM, IEEE, \nMDPI, ScienceDirect, and IAES. In 2022,\
    \ a modern look was \ncarried out within the same database.  \nAt this time, it\
    \ is done by searching for details of terms, \nsuch as (\"Artificial Intelligence\"\
    \ OR \"AI\") and (\"Smart \nFarming Model\" OR \"Smart Agriculture Model\") and\
    \ \n(\"Smart \nFarming \nEnhance \nProduction\" \nOR \n\"Smart \nAgriculture Enhance\
    \ Production\")  and (\"Smart Agriculture\" \nOR \"Smart Farming\") and (\"Precision\
    \ Farming\" OR \n\"Precision Agriculture\")  related to (\"IoT\" OR \"Internet\
    \ of \nThings) and (\"Agriculture System\" OR \"Farming System\") \nand (\"Deep\
    \ Learning\") and (\"Machine Learning\") and some \nrelated research AI that can\
    \ enhance the quality of Smart \nFarming.  \nThe previously mentioned keyword\
    \ phrases fit have been \nexplained, so based on the search algorithm from the\
    \ \ndatabase, the Study needs to have Main keywords that are \nderived and match\
    \ the scope of the Study. In this Study, the \nsearch does not focus on one type\
    \ of agriculture but on \nheterogeneous agriculture. \nOn the other hand, the\
    \ author has limited publications, \nincluding review articles, conference papers\
    \ (considered), \nand research articles. Hence the scope. Furthermore, the \n\
    publications that are used only focus on using English. \nB. Selection Criteria\
    \ \nSearching for several papers from 2018 – 2022, a \nselection of papers was\
    \ also carried out, focusing on \ndiscussing Smart Farming. It does not mean that\
    \ other things \nare ignored. But the impact must show the benefits of Smart \n\
    Farming and not discuss other points. Several stages were \ncarried out on selecting\
    \ criteria such as Identification, \nScreening, Eligibility, and Included. Essential\
    \ steps that must \nbe taken, such as the focus, must be in the form of paper,\
    \ for \nsome manuscripts such as editorials, book chapters, and \ntechnical and\
    \ online blogs cannot be included.  \nC. Quality Assessment \nInformation obtained\
    \ from four databases resulted in 534 \nresearch papers. After that, identification\
    \ is made to see \nseveral factors. In this Study, identification excluded 207\
    \ \npapers and left 327 papers at screening. After that, it entered \nthe next\
    \ stage, and there were 155 exceptions, 172 papers \nwere left in the eligibility\
    \ phase, and the final results were \nanalyzed for 67 papers and excluded 105\
    \ papers. Thus, 67 \npapers have been the center of discussion in this Study.\
    \ \nAfter doing the steps, the author will focus on classifying \nexisting papers.\
    \ So that in the next section, the results of the \nreview selection will be discussed.\
    \ \nIII. \nRESULT \nFrom the results of the methodology in the previous \nsection,\
    \ in this section, the author will describe the results \nused to carry out a\
    \ PRISMA [39] (and inspired by previous \npattern Study [38]) concept used, as\
    \ shown in Fig. 2. \n \nFig. 2. PRISMA flowchart. \nFig. 2. shows the stages and\
    \ results of the author's \npreparation for this systematic review. The author\
    \ looks for \nresearch papers on the internet that are by the research \nobjectives,\
    \ namely the AI study of current trends in Smart \nFarming to enhance crop yields.\
    \ The author will look for what \nis contained in Smart Farming, focusing on increasing\
    \ crop \nyields in several methods, technologies, and algorithms for \nthe current\
    \ trends. \nThe author also makes several tables of results from the \nreview\
    \ based on publishers, making it easier for other \nresearchers to find credible\
    \ sources. These results are shown \nin Table I. \nTABLE I.  PAPERS BY PUBLISHER\
    \ \nDatabase \nResult \nIEEE \n26 \nMDPI \n15 \nScienceDirect \n10 \nACM \n8 \n\
    IAES \n8 \n \nTable I shows that most of the papers used in this review \nare\
    \ 26 IEEE and 15 MDPI, indicating that these two \npublishers widely use AI for\
    \ Smart Farming to enhance crop \nyields. Then the author makes some results that\
    \ show the \ndemographics of the database results in Table II. \nIn Table II,\
    \ this systematic review shows that many \ncountries that Study (focus on the\
    \ first author) AI for Smart \nFarming come from Asia, especially India with 18\
    \ articles \nand China with 13 papers. \nJournal of Robotics and Control (JRC)\
    \ \nISSN: 2715-5072 \n272 \n \nMochammad Haldi Widianto, A Systematic Review of\
    \ Current Trends in Artificial Intelligence for Smart Farming to Enhance Crop\
    \ Yield \nTABLE II.   PAPERS BY COUNTRY \nCountry \nResult \nIndia \n18 \nChina\
    \ \n13 \nUSA \n5 \nMorocco \n5 \nBangladesh \n3 \nMalaysia \n2 \nSouth Korea \n\
    2 \nPhilippines \n2 \nFrance \n2 \nTurkey \n2 \nPakistan \n2 \nPortugal \n2 \n\
    Croatia \n1 \nGreece \n1 \nFinland \n1 \nVietnam \n1 \nIran \n1 \nSerbia \n1 \n\
    Mexico \n1 \nCanada \n1 \nSouth Afrika \n1 \n \nNext, the author will do a mapping\
    \ based on the quality \nof the good paper based on the publisher. This is done\
    \ by \nseveral review papers so that the quality of the review paper \nis in Table\
    \ III. \nTABLE III.  PAPERS BASED ON CRITERIA \nDatabase \nResult \nJournal \n\
    36 \nConference \n31 \n \nIn Table III, the authors can see the comparison results\
    \ \nfrom journals and conferences. Many use conference papers \nas references\
    \ in this systematic review compared to journals. \nThis shows the current trends\
    \ for enhancing crop yields are \nmostly described using conferences. \nAfter\
    \ that, the author will present the results according to \nthe year the paper\
    \ was published, which became a reference \nin preparing this systematic review\
    \ paper, as shown in Table \nIV. \nTABLE IV.   PAPERS BASED ON PUBLICATION YEAR\
    \ \nPublication Year \nResult \n2018 \n7 \n2019 \n10 \n2020 \n13 \n2021 \n24 \n\
    2022 \n13 \n \nTable IV shows publications by year and systematic \nreview of\
    \ research papers published in 2020, 2021, and 2022. \nTherefore, research is\
    \ starting in 2020, 2021, and 2022. \nFurthermore, after knowing the criteria\
    \ of the review \npaper, the author presents the discussion in the next section.\
    \ \nThe discussion contains the author's views on current trends \nand how Smart\
    \ Farming works and functions in enhancing \nCrop Yield. \nIV. \nDISCUSSION \n\
    This section will discuss what AI applications can drive \nSmart Farming that\
    \ will affect crop yields in the current trend \npaper (2018-2022) derived from\
    \ a systematic review. This \nneeds to be discussed because any research or paper\
    \ can help \nimprove a particular topic, but in this discussion, we focus on \n\
    what AI can do in Smart Farming (not detailed AI methods \nand their derivatives).\
    \ Here are the issues that can be used for \nimprovement, as shown in Fig. 3.\
    \ \n \nFig. 3. Smart Farming Improvement Concept. \nAfter understanding several\
    \ concepts of AI (DL or ML) \nfor enhancing Smart Farming on crop yields (see\
    \ Fig. 3.), the \nauthor then tries to describe some discussions related to the\
    \ \nimage. \nA. Weather \nThe weather is an everyday thing that happens in \n\
    agriculture. Their influence in the world of agriculture affects \nthe performance\
    \ of crop yields, so several studies are needed \nto help AI understand the weather\
    \ in Smart Farming \napplications. \nShandilya and Khanduja [41]  said several\
    \ studies have \nfocused on climate, weather, and Smart Farming, but most \nresearch\
    \ requires a significant increase in the cost. This Study \nuses AI in weather.\
    \ But Focus AI in the study-specific used \nSARIMAX algorithm.  \nKamatchi and\
    \ Parvathi [42] Explained using predictive \nanalysis. One of the AI methods,\
    \ the Artificial Neural \nNetwork (ANN) technique, has successfully performed\
    \ the \nbest crop analysis based on weather conditions. The ANN \ntechnique is\
    \ used in suitable groupings for data mining and \nmachine learning categorization.\
    \ \nTarik and Jamil  [43]  take an approach that utilizes AI \napplied in agriculture.\
    \ Using Convolutional Neural Networks \n(CNN) to prevent the number of production\
    \ results. By taking \nadvantage of the many meteorological and weather. Then\
    \ \nproceed to the data processing phase, such as normalization, \nfiltering,\
    \ and segmentation.  \nTherefore, in this Study, the author will present the focus\
    \ \nof weather on AI for Smart Farming of the current trends \npaper on enhancing\
    \ crop yields, which can be done in Table \nV. \nTABLE V.   WEATHER STUDY TO ENHANCE\
    \ CROP YIELD \nReferences \nTopic \nSolution \n[41], [42], [44]–[46] \nWeather\
    \ \nForecast and Predictions \n[43] \nWeather \nWeather Data \nJournal of Robotics\
    \ and Control (JRC) \nISSN: 2715-5072 \n273 \n \nMochammad Haldi Widianto, A Systematic\
    \ Review of Current Trends in Artificial Intelligence for Smart Farming to Enhance\
    \ Crop Yield \nB. Soil  \nIn Smart Farming, it is unavoidable to utilize the land.\
    \ \nSmart Farming requires suitable and qualified soil to increase \ncrop yields.\
    \ This discussion discusses the role of AI in \nimproving soil quality which will\
    \ be applied to Smart \nFarming. \nSuhag et al. [47] Explained there is no denying\
    \ that \nfarmers and landowners face challenges due to the ever-\nincreasing population.\
    \ One effective solution is to use new \ntechnologies such as AI and IoT. Therefore,\
    \ AI-assisted \nmanufacturing has advanced a lot in farming methods, and all \n\
    the task conducted by farmers has been made easier with AI. \nDifferent work cases\
    \ will be mapped beforehand in the \nsystem, learning new things. Technologies\
    \ such as precision \nagriculture use AI technology for mapping diseases in crops,\
    \ \nSoil nutrition, and overcome by AI technology (especially \nRobotic to harvest\
    \ the crop). \nAnand et al. [48] explained that monitoring nutrients in \nthe\
    \ soil are very important because one of the impacts is \nincreasing agricultural\
    \ yields and productivity, efficiency, \nand effectiveness. Soil monitoring is\
    \ based on basic \nparameters such as water content and temperature so that \n\
    farmers can estimate the situation. one result of the right \ndecisions being\
    \ made: is the choice of areas to plant to help \ntillers or farmers. In this\
    \ case, ML (Hybrid algorithm) has an \nimportant role in detecting the type of\
    \ soil. \nRodić et al. [49] Explained the big role in IoT in terms of \ninputs\
    \ that make the system smart in various things like \ndigital and physical. As\
    \ previously explained, the intelligent \nsystem has not only provided a solution\
    \ but effectively \nassisted the task of sensing soil moisture to ensure optimal\
    \ \nwater usage. With the help of several other technologies, such \nas LoRa can\
    \ provide cost-effective and energy-efficient \ndevices that have unique advantages\
    \ over existing solutions. \nThis Study uses Long Short-Term Memory (LSTM). This\
    \ \nalgorithm is one of the DL.  \nReshma et al. [50] Another breakthrough in\
    \ agricultural \nland management, as previously described, can be improved \n\
    by measuring soil characteristics. This information and data \nneed to be withdrawn\
    \ and stored in the cloud and then re-\nanalyzed on the land using AI. so that\
    \ farmers and land \npickers can properly utilize resources and direct farming\
    \ \nmethods wisely to optimize results. This Study can use \nsupervised learning\
    \ like Support vector machines (SVM) and \nDecision Trees to convey his recommendations.\
    \ \nThe authors present some soil studies on AI for Smart \nFarming of the current\
    \ trend studies that can support \nenhanced crop yields and Smart Farming in soil-focused\
    \ \nagriculture, as shown in Table VI. \nC. Irrigation \nAn important component\
    \ in increasing crop quality is the \nneed for good water, one of which can be\
    \ made from a good \nirrigation system. In this section, we will focus on the\
    \ role of \nAI in improving irrigation quality that can be applied to \nagriculture.\
    \ \nGoap et al. [58] On Agriculture sector requires a lot of \nwater, but freshwater\
    \ supply is running low. This happens \nbecause the method used is conventional\
    \ with many \nchallenges such as lack of utilization of water use efficiency.\
    \ \nIn addition, there is a lot of global warming and climate \nchange that often\
    \ impact the amount of rain intensity required \nto meet the availability. Sustainable\
    \ irrigation is one step in \nachieving food security. Algorithms using ML (Support\
    \ \nVector Regression (SVR) + k-means) show fewer errors and \nimprove accuracy.\
    \ The approach used can be proposed to \nassist in making effective irrigation\
    \ decisions. \nTABLE VI.  SOIL STUDY TO ENHANCE CROP YIELD \nReferences \nTopic\
    \ \nSolution \n[47] \nSoil \nNutrition  \n[51] \nSoil \nClassification  \n[48]\
    \ \nSoil \nDetection System  \n[49] \nSoil \nHumidity Sensing \n[52], [53] \n\
    Soil \nMoisture Prediction and Forecast  \n[54] \nSoil \nMoisture Evaluation \
    \ \n[55], [56] \nSoil \nPrediction \n[57] \nSoil \nEstimate Soil Moisture  \n\
    [50] \nSoil \nAnalysis  \n \nKwok and Sun [59], On technology in ML can be used\
    \ \nfor learning and is very important in agriculture. In recent \nyears, many\
    \ studies have taken advantage of machine \nlearning as part of AI. The utilization\
    \ of DL in irrigation \nsystems today is highly developed and developed by research\
    \ \nand industry. On an irrigation system, leveraging deeper and \nmore specific\
    \ learning with DL can adjust the water intensity \non the kinds of plants. \n\
    Murthy et al. [60], On scheduling irrigation, is very \nimportant, especially\
    \ because traditional irrigation uses a lot \nof water, which causes fatal things\
    \ such as water pollution \nand water wastage. By utilizing (Weather-aware Runoff\
    \ \nPrevention Irrigation Control (WaRPIC)), the recording of \nthe data obtained\
    \ to form a machine learning model focused \non predicting the Maximum Allowable\
    \ Run Time (MAR). \nThere are many more Irrigation applications focused on \n\
    AI for Smart Farming applications in the current trends paper \non increasing\
    \ crop production that focus on its application in \nirrigation, as shown in Table\
    \ VII. \nTABLE VII.  IRRIGATION STUDY TO ENHANCE CROP YIELD \nReferences \nTopic\
    \ \nSolution \n[58] \nIrrigation \nManagement \n[59], [61]–[66] \nIrrigation \n\
    System  \n[60] \nIrrigation \nControl \n[67] \nIrrigation \nTiming Decision  \n\
    [68] \nIrrigation \nPredictive \n \nD. Unmanned Aerial Vehicle (UAV) \nRapid advances\
    \ in technology make Smart Farming take \nadvantage of it, one of which is UAVs,\
    \ because it is \nunmanned and can be controlled anywhere. This section will \n\
    discuss the application of AI-based UAVs that will help \nSmart Farming \nPsiroukis\
    \ et al. [69] Explained that broccoli is a plant that \nrequires handling and\
    \ is highly valued in agriculture and \nrequires special care in the post-harvest\
    \ and growing season. \nBroccoli heads are susceptible to damage because they\
    \ are \nharvested by hand. In addition, it is first necessary to identify \nJournal\
    \ of Robotics and Control (JRC) \nISSN: 2715-5072 \n274 \n \nMochammad Haldi Widianto,\
    \ A Systematic Review of Current Trends in Artificial Intelligence for Smart Farming\
    \ to Enhance Crop Yield \nthe land cultivation segment (Using Faster R-CNN and\
    \ \nCenterNet). So, UAV research aims to automate architectural \nprocessing utilizing\
    \ deep learning. \nLi et al. [70] conducted high-resolution result mapping \n\
    is needed to determine the pattern of spatial yield variability. \nIn determining\
    \ this, there are important factors because it \naffects new insights and variability\
    \ of management results in \nviewing agricultural products. In UAV, machine learning\
    \ \n(random forest regression (RFR) and SVR models) methods \ncan imp0rove the\
    \ prediction of the results. A machine \nlearning model can be used to perform\
    \ different vegetation \nindications. \nHoummaidi et al. [71] focus on sustainable\
    \ agriculture, \nwhich is the focus of food security. Some governments are \n\
    starting to rely on new technology. Agricultural applications \nalso depend on\
    \ efficient land monitoring. However, in the \ntraditional case, monitoring is\
    \ carried out on field surveys, \nand it is very expensive, slow, and rare. By\
    \ utilizing remote \nsensing using UAV drones to be efficient and not waste a\
    \ lot \nof time-insensitive agricultural mapping. Then research is \ncarried out\
    \ by utilizing the method Unmanned Aerial \nSystems (UAS) and DL as solutions\
    \ for good mart Farming \nand sustainable agriculture. \nBecause there are many\
    \ studies on UAV on AI for Smart \nFarming, the author is looking for a current\
    \ trend paper to \nincrease crop yields in Smart Farming. as shown in Table \n\
    VIII. \nTABLE VIII.   UAV STUDY TO ENHANCE CROP YIELD  \nReferences \nTopic \n\
    Component \n[69], [72] \nUAV \nClassification  \n[70], [73] \nUAV \nPrediction\
    \ \n[71] \nUAV \nMapping  \n \nE. Pest Control \nAll farmers understand that pests\
    \ are enemies of the \nworld of agriculture, especially in large numbers. AI can\
    \ \ntackle pests by understanding such patterns and early \ndetection. In this\
    \ section, we will discuss to focus on AI in \nreducing pests that will be applied\
    \ to Smart Farming \nAccording to his survey study in [74], agriculture is the\
    \ \nprimary food source. More than 90% of the population gets \ntheir food source\
    \ from agriculture in some countries. But \nthere are problems, one of which is\
    \ pests as a cause of \nreduced or lost crops in the agricultural world. Therefore,\
    \ \ntechnology is needed to classify pests that can help detect \npests, which\
    \ is very important to minimize pest movement. \nThe experiment utilizes this\
    \ proposed classification accuracy \nwith different combinations of the learning\
    \ rate, ResNeXt-50 \n(32 × 4d), data augmentation, and transfer learning. \nHu\
    \ et al. [75] discuss knowledge about accurate \nidentification of pests has an\
    \ important role in deciding to \ncontrol pests. According to him, it is necessary\
    \ to investigate \nthe identification of pests in the field with characteristics\
    \ such \nas their protective colour, methods for identifying pests based \non\
    \ YOLOv5 technology, and near-infrared imaging. \nNam and Hung [76] found that\
    \ highly toxic pests could \nnegatively affect crop yields in the final phase\
    \ and even \nproduct quality in the industry. Therefore, everyone agrees to \n\
    minimize pests and even needs to detect the task of \nmaximizing these crops to\
    \ make decisions on minimizing the \nrelevant pests. However, this has challenges,\
    \ such as \nclassifying insect species using the Deep Convolutional \nNeural Network\
    \ (CNN), part of machine learning. \nMique and Palaoag [77] focus on detecting\
    \ rice diseases \nand pes and controlling and managing agricultural land \nattacked\
    \ by pests so that the crop yields. By utilizing modern \ntechnology, diseases\
    \ and pests are found in agriculture, \nespecially in rice fields. This work uses\
    \ CNN to control pests \nare plonia; knowledge of farmers about various rice diseases\
    \ \nand pests and his work on how to control this pest needs to \nbe considered;\
    \ This work focuses on finding suitable \nsolutions mechanisms for smallholder\
    \ reporting. Utilizing \nimage management and CNN, it is necessary to develop\
    \ \napplications for detecting diseases and pests of rice. \nPests are bothersome\
    \ even for agriculture and the final \nproducts managed in industry, but to minimize\
    \ pests is not \nonly using pesticides. The next Table IX will explain some \n\
    of Pest Control on AI for Smart Farming, the current trends \npaper related to\
    \ overcoming, identifying, controlling, and \neven minimizing pest growth.  \n\
    TABLE IX.  PEST CONTROL STUDY TO ENHANCE CROP YIELD \nReferences \nTopic \nSolution\
    \ \n[74], [78]–[80] \nPest Control \nPest Classification  \n[75]–[77], [81]–[84]\
    \ \nPest Control \nPest Identification or Detection \n[85] \nPest Control \nPest\
    \ Prediction \n \nF. Weed Control \nWeeds are considered very important because\
    \ they affect \nthe nutrients present in the land. Other things can also affect\
    \ \nagricultural yields from agricultural harvests. In this section, \nthe author\
    \ will discuss how to control weeds. \nReedha et al. [86] explained that controlling\
    \ weeds and \nfood crops is the main crop production and agriculture. \nBecause\
    \ basically, weeds take the same nutrients as plants. \nTherefore, weeds harm\
    \ crop yields if they cannot be \ncontrolled. Mapping and detection of weeds is\
    \ an important \nstep. Utilizing the deep learning approach can provide good \n\
    performance in many sensing tasks. In its investigate visual \ntransformers (ViT)\
    \ and UAV technology can help. \nGaribaldi-Márquez et al. [87] explain that Weed\
    \ \ndiscrimination in the environment is challenging to overcome \nin Smart Farming\
    \ practices, for example, weed control. Many \nmethods are used. Developing a\
    \ good practice system \nrecognizes weeds and their crops. Its utilization is\
    \ based on \nCNN and compared with the shallow learning approach. \nRazfar et\
    \ al. [88] Explain if research focusing on Weed \ndetection is a part that is\
    \ often used to implement Smart \nFarming in implementing IoT. Species such as\
    \ Weeds are \nresponsible for 45% of crop losses due to the struggle for \nnutrients\
    \ from native plants. Therefore, the weed detection \nmethod was used to reduce\
    \ this percentage. This study \nfocuses on detection methods using deep learning\
    \ models to \nlook for weeds in soybean plantations. The study used \nResNet50,\
    \ three custom CNN Models, and MobileNetV2. \nJournal of Robotics and Control\
    \ (JRC) \nISSN: 2715-5072 \n275 \n \nMochammad Haldi Widianto, A Systematic Review\
    \ of Current Trends in Artificial Intelligence for Smart Farming to Enhance Crop\
    \ Yield \nHaichen et al. [89] is an effective way to increase crop \nyields. In\
    \ the application in smart agriculture, in identifying \neffective, accurate,\
    \ and reliable weeds in controlling the \nlocation of weeds, in proposing VGG16+SVM\
    \ weed \nclassification algorithms to optimize the algorithm. \nUkaegbu et al.\
    \ [90]. Explaining machine learning \napplications is very clear and gaining more\
    \ popularity. There \nare better algorithms, such as the DL algorithm for \nclassification,\
    \ signal identification, and crack detection. The \nDL algorithm has a wider application\
    \ than other machine \nlearning systems. Weed detection research CNN, using \n\
    transfer learning focus in the previously ResNet50 model, \nthen proceed to performance\
    \ evaluation using random forest \n(RF). \nMany more recent research trends focus\
    \ on Weed Control \non AI for Smart Farming of crop yields in agriculture, be\
    \ it \nprecision or Smart Farming. Table X shows some of the \ncurrent trends\
    \ papers focusing on information and systems \nmanagement. \nTABLE X.   WEED CONTROL\
    \ STUDY TO ENHANCE CROP YIELD \nReferences \nTopic \nSolution \n[86], [87], [89],\
    \ [91], \n[92] \nWeed \nControl \nWeed Classification \n[88], [90], [93]–[98]\
    \ \nWeed \nControl \nWeed \nIdentification \nand \nDetection \n \nG. Disease Control\
    \ \nPlant diseases are becoming new material in the increased \nlearning broadly\
    \ to be studied scientifically. Usually focuses \non the biological characteristics\
    \ of the disease. Identifying \nplant diseases has recently been proven to require\
    \ special \nattention. Early detection of disease can help maintain plant \nquality.\
    \  \nLuna et al. [99] used tomato plants. In the ancient method \nof knowing the\
    \ disease, an examination is carried out, and the \ntreatment of diseases in tomatoes\
    \ is still done manually by \npractice. System development is needed to perform\
    \ tasks \nsuch as detecting plant diseases for users so that they do not \nalways\
    \ do everything manually. There are general signs of \ndamage such as bacterial,\
    \ fungal disease, nematodes, and \nviruses originating, resulting in death on\
    \ the underside of the \nleaf or yellowing and black spots on the bottom of the\
    \ leaf. \nThe research used in this study is CNN. Anomalies were used \nby F-RCNN\
    \ trained to detect. \nAfzaal et al. [100] Other crops are also very susceptible\
    \ \nto various diseases, which has led to an increase in the world \nof agriculture\
    \ and industry. To improve the quality of plants, \nplants must protect plants\
    \ from all kinds of harmful diseases. \nThe available options include ancient\
    \ ways to identify plant \ndiseases to achieve this goal. This includes inspections\
    \ \ncarried out anciently or simply by prescribing disease. But \nthis ancient\
    \ method was time-consuming, and not just anyone \nthought a disease had to be\
    \ an expert. Other solutions such as \nusing pesticides in crop production, only\
    \ the use of chemical \npesticides can be detrimental and cause poor food quality.\
    \ On \nthe other hand, farmers also need to increase labor costs. So, \naccording\
    \ to the author, early detection of plant diseases \n(using Mask R-CNN architecture)\
    \ is necessary to increase \ncrop yields. \nThere are many more studies regarding\
    \ diseases in plants. \nBecause basically, this disease can reduce the harvest\
    \ quality \nand make the Smart Farming system not good. Table XI will \nshow some\
    \ of the AI current trends papers for Smart Farming \nthat addresses plant disease\
    \ problems. \nTABLE XI.  DISEASE CONTROL STUDY TO ENHANCE CROP \nYIELD \nReferences\
    \ \nTopic \nSolution \n[47], [77], [99]–[103] \nDisease \nControl \nDisease \n\
    Detection \nand \nIdentification \n[104]–[106] \nDisease \nControl \nDisease Classification\
    \ \n[107] \nDisease \nControl \nRecognition \n \nV. \nCONCLUSION \nThis Study\
    \ focuses on conducting a systematic review in \nAI for Smart Farming of current\
    \ trends papers to enhance \ncrop yields. This review helps find the current trends\
    \ paper \nrelated to enhancing crop yields in Smart Farming \ntechnology. In this\
    \ review, the authors utilize PRISMA, \nwhich has successfully retrieved 534 articles\
    \ in databases \nspread across IEEE, ScienceDirect, ACM, IAES, and MDPI. \nAt\
    \ the end of the process, the authors get 67 AI studies for \nSmart Farming of\
    \ current trends papers that can enhance crop \nyields. The author also discusses\
    \ several factors that can \nenhance crop yields in Weather, Soil, Irrigation,\
    \ Unmanned \nAerial Vehicle (UAV), Pest Control, Weed Control, and \nDisease Control.\
    \ On the other hand, these AI factors \nsignificantly affect the performance of\
    \ Smart Farming. \nFurther research can be reviewed using other methods such \n\
    as statistical models, system recommenders, and multi-\nagents.  \nREFERENCES\
    \ \n[1] \nA. Sharma, A. Jain, P. Gupta, and V. Chowdary, “Machine Learning \n\
    Applications for Precision Agriculture: A Comprehensive Review,” \nIEEE \nAccess,\
    \ \nvol. \n9, \npp. \n4843–4873, \n2021, \ndoi: \n10.1109/ACCESS.2020.3048415.\
    \ \n[2] \nR. Dolci, “IoT Solutions for Precision Farming and Food \nManufacturing:\
    \ Artificial Intelligence Applications in Digital Food,” \nin 2017 IEEE 41st Annual\
    \ Computer Software and Applications \nConference \n(COMPSAC), \nJul. \n2017,\
    \ \npp. \n384–385. \ndoi: \n10.1109/COMPSAC.2017.157. \n[3] \nM. H. Widianto,\
    \ T. E. Suherman, and J. Chiedi, “Pathfinding \nAugmented Reality for Fire Early\
    \ Warning IoT Escape Purpose,” \nInternational Journal of Engineering Trends and\
    \ Technology, vol. 69, \nno. 7, pp. 190–197, 2021, doi: 10.14445/22315381/IJETT-\n\
    V69I7P226. \n[4] \nM. H. Widianto, A. Ramadhan, A. Trisetyarso, and E. Abdurachman,\
    \ \n“Energy saving on IoT using LoRa: a systematic literature review,” \nInternational\
    \ Journal of Reconfigurable and Embedded Systems \n(IJRES), \nvol. \n11, \nno.\
    \ \n1, \npp. \n25–33, \nMar. \n2022, \ndoi: \n10.11591/ijres.v11.i1.pp25-33. \n\
    [5] \nR. Yu, X. Zhang, and M. Zhang, “Smart Home Security Analysis \nSystem Based\
    \ on The Internet of Things,” in 2021 IEEE 2nd \nInternational Conference on Big\
    \ Data, Artificial Intelligence and \nInternet of Things Engineering (ICBAIE),\
    \ Mar. 2021, pp. 596–599. \ndoi: 10.1109/ICBAIE52039.2021.9389849. \n[6] \nH.\
    \ Huang, “Architecture of Audio Broadcasting Coverage Monitoring \nSystem Based\
    \ on Internet of Things,” in 2019 IEEE International \nConference on Smart Internet\
    \ of Things (SmartIoT), Aug. 2019, pp. \n320–324. doi: 10.1109/SmartIoT.2019.00055.\
    \ \nJournal of Robotics and Control (JRC) \nISSN: 2715-5072 \n276 \n \nMochammad\
    \ Haldi Widianto, A Systematic Review of Current Trends in Artificial Intelligence\
    \ for Smart Farming to Enhance Crop Yield \n[7] \nG. Idoje, T. Dagiuklas, and\
    \ M. Iqbal, “Survey for smart farming \ntechnologies: Challenges and issues,”\
    \ Computers & Electrical \nEngineering, \nvol. \n92, \np. \n107104, \n2021, \n\
    doi: \n10.1016/j.compeleceng.2021.107104. \n[8] \nM. S. D. Abhiram, J. Kuppili,\
    \ and N. A. Manga, “Smart Farming \nSystem using IoT for Efficient Crop Growth,”\
    \ in 2020 IEEE \nInternational Students’ Conference on Electrical,Electronics\
    \ and \nComputer \nScience \n(SCEECS), \nFeb. \n2020, \npp. \n1–4. \ndoi: \n10.1109/SCEECS48394.2020.147.\
    \ \n[9] \nF. Nolack Fote, S. Mahmoudi, A. Roukh, and S. Ahmed Mahmoudi, \n“Big\
    \ Data Storage and Analysis for Smart Farming,” in 2020 5th \nInternational Conference\
    \ on Cloud Computing and Artificial \nIntelligence: Technologies and Applications\
    \ (CloudTech), Nov. 2020, \npp. 1–8. doi: 10.1109/CloudTech49835.2020.9365869.\
    \ \n[10] X. Jiang et al., “Wireless Sensor Network Utilizing Flexible Nitrate\
    \ \nSensors for Smart Farming,” in 2019 IEEE SENSORS, Oct. 2019, pp. \n1–4. doi:\
    \ 10.1109/SENSORS43011.2019.8956915. \n[11] R. Deepa, V. Moorthy, R. Venkataraman,\
    \ and S. S. Kundu, “Smart \nFarming Implementation using Phase based IOT System,”\
    \ in 2020 \nInternational Conference on Communication and Signal Processing \n\
    (ICCSP), \nJul. \n2020, \npp. \n930–934. \ndoi: \n10.1109/ICCSP48568.2020.9182078.\
    \ \n[12] B. Ban, J. Lee, D. Ryu, M. Lee, and T. D. Eom, “Nutrient Solution \n\
    Management System for Smart Farms and Plant Factory,” in 2020 \nInternational\
    \ Conference on Information and Communication \nTechnology Convergence (ICTC),\
    \ Oct. 2020, pp. 1537–1542. doi: \n10.1109/ICTC49870.2020.9289192. \n[13] L. Yu\
    \ et al., “Comprehensive Evaluation of Soil Moisture Sensing \nTechnology Applications\
    \ Based on Analytic Hierarchy Process and \nDelphi,” Agriculture, vol. 11, no.\
    \ 11, p. 1116, Nov. 2021, doi: \n10.3390/agriculture11111116. \n[14] H. Nasir,\
    \ A. N. Aris, A. Lajis, K. Kadir, and S. I. Safie, “Development \nof Android Application\
    \ for Pest Infestation Early Warning System,” \nin 2018 IEEE 5th International\
    \ Conference on Smart Instrumentation, \nMeasurement and Application (ICSIMA),\
    \ Nov. 2018, pp. 1–5. doi: \n10.1109/ICSIMA.2018.8688774. \n[15] A. Cabarcas,\
    \ C. Arrieta, D. Cermeño, H. Leal, R. Mendoza, and C. \nRosales, “Irrigation System\
    \ for Precision Agriculture Supported in the \nMeasurement of Environmental Variables,”\
    \ in 2019 7th International \nEngineering, Sciences and Technology Conference\
    \ (IESTEC), Oct. \n2019, pp. 671–676. doi: 10.1109/IESTEC46403.2019.00125. \n\
    [16] M. Ayaz, M. Ammad-Uddin, Z. Sharif, A. Mansour, and E.-H. M. \nAggoune, “Internet-of-Things\
    \ (IoT)-Based Smart Agriculture: \nToward Making the Fields Talk,” IEEE Access,\
    \ vol. 7, pp. 129551–\n129583, 2019, doi: 10.1109/ACCESS.2019.2932609. \n[17]\
    \ H. WANG, Y. LIU, Z. HAN, and J. WU, “Extension of media literacy \nfrom the\
    \ perspective of artificial intelligence and implementation \nstrategies of artificial\
    \ intelligence courses in junior high schools,” in \n2020 International Conference\
    \ on Artificial Intelligence and \nEducation \n(ICAIE), \nJun. \n2020, \npp. \n\
    63–66. \ndoi: \n10.1109/ICAIE50891.2020.00022. \n[18] Z. Li, “Analysis on the\
    \ Influence of Artificial Intelligence \nDevelopment on Accounting,” in 2020 International\
    \ Conference on \nBig Data, Artificial Intelligence and Internet of Things Engineering\
    \ \n(ICBAIE), \nJun. \n2020, \npp. \n260–262. \ndoi: \n10.1109/ICBAIE49996.2020.00061.\
    \ \n[19] X. Fu, “The Application of Artificial Intelligence Technology in \nCollege\
    \ Physical Education,” in 2020 International Conference on \nBig Data, Artificial\
    \ Intelligence and Internet of Things Engineering \n(ICBAIE), \nJun. \n2020, \n\
    pp. \n263–266. \ndoi: \n10.1109/ICBAIE49996.2020.00062. \n[20] N. Wang, Y. Liu,\
    \ Z. Liu, and X. Huang, “Application of Artificial \nIntelligence and Big Data\
    \ in Modern Financial Management,” in 2020 \nInternational Conference on Artificial\
    \ Intelligence and Education \n(ICAIE), \nJun. \n2020, \npp. \n85–87. \ndoi: \n\
    10.1109/ICAIE50891.2020.00027. \n[21] S. Zel and E. Kongar, “Transforming Digital\
    \ Employee Experience \nwith Artificial Intelligence,” in 2020 IEEE / ITU International\
    \ \nConference on Artificial Intelligence for Good (AI4G), Sep. 2020, pp. \n176–179.\
    \ doi: 10.1109/AI4G50087.2020.9311088. \n[22] R. Sharma, “Artificial Intelligence\
    \ in Agriculture: A Review,” in 2021 \n5th International Conference on Intelligent\
    \ Computing and Control \nSystems \n(ICICCS), \nMay \n2021, \npp. \n937–942. \n\
    doi: \n10.1109/ICICCS51141.2021.9432187. \n[23] K. Pahwa and N. Agarwal, “Stock\
    \ Market Analysis using Supervised \nMachine Learning,” in 2019 International\
    \ Conference on Machine \nLearning, Big Data, Cloud and Parallel Computing (COMITCon),\
    \ \nFeb. 2019, pp. 197–200. doi: 10.1109/COMITCon.2019.8862225. \n[24] Q. Zhao,\
    \ J. Sun, H. Ren, and G. Sun, “Machine-Learning Based TCP \nSecurity Action Prediction,”\
    \ in 2020 5th International Conference on \nMechanical, Control and Computer Engineering\
    \ (ICMCCE), Dec. \n2020, pp. 1329–1333. doi: 10.1109/ICMCCE51767.2020.00291. \n\
    [25] J. Ma, “Machine Learning in Predicting Diabetes in the Early Stage,” \nin\
    \ 2020 2nd International Conference on Machine Learning, Big Data \nand Business\
    \ Intelligence (MLBDBI), Oct. 2020, pp. 167–172. doi: \n10.1109/MLBDBI51377.2020.00037.\
    \ \n[26] N. Li, T. Zong, and Z. Zhang, “Prediction of the Electronic Work \nFunction\
    \ by Regression Algorithm in Machine Learning,” in 2021 \nIEEE 6th International\
    \ Conference on Big Data Analytics (ICBDA), \nMar. 2021, pp. 87–91. doi: 10.1109/ICBDA51983.2021.9403202.\
    \ \n[27] H. C. Kaskavalci and S. Gören, “A Deep Learning Based Distributed \n\
    Smart Surveillance Architecture using Edge and Cloud Computing,” \nin 2019 International\
    \ Conference on Deep Learning and Machine \nLearning in Emerging Applications\
    \ (Deep-ML), Aug. 2019, pp. 1–6. \ndoi: 10.1109/Deep-ML.2019.00009. \n[28] H.\
    \ S. DIKBAYIR and H. Ïbrahim BÜLBÜL, “Deep Learning Based \nVehicle Detection\
    \ From Aerial Images,” in 2020 19th IEEE \nInternational Conference on Machine\
    \ Learning and Applications \n(ICMLA), \nDec. \n2020, \npp. \n956–960. \ndoi:\
    \ \n10.1109/ICMLA51294.2020.00155. \n[29] N. Shen, “A Deep Learning Approach of\
    \ English Vocabulary for \nMobile Platform,” in 2021 13th International Conference\
    \ on \nMeasuring Technology and Mechatronics Automation (ICMTMA), \nJan. 2021,\
    \ pp. 463–466. doi: 10.1109/ICMTMA52658.2021.00106. \n[30] A. Karami, M. Crawford,\
    \ and E. J. Delp, “A Weakly Supervised Deep \nLearning Approach for Plant Center\
    \ Detection and Counting,” in \nIGARSS 2020 - 2020 IEEE International Geoscience\
    \ and Remote \nSensing \nSymposium, \nSep. \n2020, \npp. \n1584–1587. \ndoi: \n\
    10.1109/IGARSS39084.2020.9324354. \n[31] I. Tudosa, F. Picariello, E. Balestrieri,\
    \ L. de Vito, and F. Lamonaca, \n“Hardware Security in IoT era: the Role of Measurements\
    \ and \nInstrumentation,” in 2019 II Workshop on Metrology for Industry 4.0 \n\
    and IoT (MetroInd4.0 IoT), Jun. 2019, pp. 285–290. doi: \n10.1109/METROI4.2019.8792895.\
    \ \n[32] W. Shalannanda, I. Zakia, F. Fahmi, and E. Sutanto, “Implementation \n\
    of the Hardware Module of IoT-based Infant Incubator Monitoring \nSystem,” \n\
    in \n2020 \n14th \nInternational \nConference \non \nTelecommunication Systems,\
    \ Services, and Applications (TSSA, Nov. \n2020, pp. 1–5. doi: 10.1109/TSSA51342.2020.9310901.\
    \ \n[33] H. Tao, M. Z. A. Bhuiyan, A. N. Abdalla, M. M. Hassan, J. M. Zain, \n\
    and T. Hayajneh, “Secured Data Collection With Hardware-Based \nCiphers for IoT-Based\
    \ Healthcare,” IEEE Internet of Things Journal, \nvol. \n6, \nno. \n1, \npp. \n\
    410–420, \nFeb. \n2019, \ndoi: \n10.1109/JIOT.2018.2854714. \n[34] H. Q. T. Ngo,\
    \ T. P. Nguyen, and H. Nguyen, “Hardware Design for \nIntelligent IoT Approach\
    \ to Optimize Parking Slots,” in 2019 \nInternational Conference on Advanced Computing\
    \ and Applications \n(ACOMP), \nNov. \n2019, \npp. \n171–175. \ndoi: \n10.1109/ACOMP.2019.00034.\
    \ \n[35] S. Qazi, B. A. Khawaja, and Q. U. Farooq, “IoT-Equipped and AI-\nEnabled\
    \ Next Generation Smart Agriculture: A Critical Review, \nCurrent Challenges and\
    \ Future Trends,” IEEE Access, vol. 10, pp. \n21219–21235, 2022, doi: 10.1109/ACCESS.2022.3152544.\
    \ \n[36] S. Terence and G. Purushothaman, “Systematic Review of Internet of \n\
    Things in Smart Farming,” Trans. Emerg. Telecommun. Technol., vol. \n31, no. 6,\
    \ Jun. 2020, doi: 10.1002/ett.3958. \n[37] Z. Ünal, “Smart Farming Becomes even\
    \ Smarter with Deep Learning \n- A Bibliographical Analysis,” IEEE Access, vol.\
    \ 8, pp. 105587–\n105609, 2020, doi: 10.1109/ACCESS.2020.3000175. \n[38] E. Navarro,\
    \ N. Costa, and A. Pereira, “A Systematic Review of IoT \nSolutions for Smart\
    \ Farming,” Sensors, vol. 20, no. 15, p. 4231, Jul. \n2020, doi: 10.3390/s20154231.\
    \ \n[39] D. Moher, A. Liberati, J. Tetzlaff, and D. G. Altman, “Preferred \nreporting\
    \ items for systematic reviews and meta-analyses: the \nPRISMA statement,” J Clin\
    \ Epidemiol, vol. 62, no. 10, pp. 1006–\n1012, 2009, doi: 10.1016/j.jclinepi.2009.06.005.\
    \ \n[40] W. S. Alaloul, M. Altaf, M. A. Musarat, M. F. Javed, and A. Mosavi, \n\
    “Systematic Review of Life Cycle Assessment and Life Cycle Cost \nAnalysis for\
    \ Pavement and a Case Study,” Sustainability, vol. 13, no. \n8, p. 4377, Apr.\
    \ 2021, doi: 10.3390/su13084377. \n[41] U. Shandilya and V. Khanduja, “Intelligent\
    \ Farming System With \nWeather Forecast Support and Crop Prediction,” in 2020\
    \ 5th \nInternational Conference on Computing, Communication and \nJournal of\
    \ Robotics and Control (JRC) \nISSN: 2715-5072 \n277 \n \nMochammad Haldi Widianto,\
    \ A Systematic Review of Current Trends in Artificial Intelligence for Smart Farming\
    \ to Enhance Crop Yield \nSecurity \n(ICCCS), \nOct. \n2020, \npp. \n1–6. \ndoi:\
    \ \n10.1109/ICCCS49678.2020.9277437. \n[42] S. B. Kamatchi and R. Parvathi, “Improvement\
    \ of Crop Production \nUsing Recommender System by Weather Forecasts,” Procedia\
    \ \nComputer \nScience, \nvol. \n165, \npp. \n724–732, \n2019, \ndoi: \n10.1016/j.procs.2020.01.023.\
    \ \n[43] H. Tarik and O. M. Jamil, “Weather Data For The Prevention Of \nAgricultural\
    \ Production With Convolutional Neural Networks,” in \n2019 International Conference\
    \ on Wireless Technologies, Embedded \nand Intelligent Systems (WITS), Apr. 2019,\
    \ pp. 1–6. doi: \n10.1109/WITS.2019.8723765. \n[44] X. Peng et al., “EALSTM-QR:\
    \ Interval wind-power prediction model \nbased on numerical weather prediction\
    \ and deep learning,” Energy, \nvol. 220, p. 119692, 2021, doi: 10.1016/j.energy.2020.119692.\
    \ \n[45] Md. A. Rizvee, A. R. Arju, Md. Al-Hasan, S. M. Tareque, and Md. Z. \n\
    Hasan, “Weather Forecasting for the North-Western region of \nBangladesh: A Machine\
    \ Learning Approach,” in 2020 11th \nInternational Conference on Computing, Communication\
    \ and \nNetworking Technologies (ICCCNT), Jul. 2020, pp. 1–6. doi: \n10.1109/ICCCNT49239.2020.9225389.\
    \ \n[46] L. Naveen and H. S. Mohan, “A novel weather parameters prediction \n\
    scheme and their effects on crops,” International Journal of Electrical \nand\
    \ Computer Engineering, vol. 12, no. 1, pp. 639–648, Feb. 2022, \ndoi: 10.11591/ijece.v12i1.pp639-648.\
    \ \n[47] S. Suhag, N. Singh, S. Jadaun, P. Johri, A. Shukla, and N. Parashar,\
    \ \n“IoT based Soil Nutrition and Plant Disease Detection System for \nSmart Agriculture,”\
    \ in 2021 10th IEEE International Conference on \nCommunication Systems and Network\
    \ Technologies (CSNT), Jun. \n2021, pp. 478–483. doi: 10.1109/CSNT51715.2021.9509719.\
    \ \n[48] R. Anand, D. Sethi, K. Sharma, and P. Gambhir, “Soil Moisture and \n\
    Atmosphere Components Detection System Using IoT and Machine \nLearning,” in 2019\
    \ International Conference on Smart Systems and \nInventive Technology (ICSSIT),\
    \ Nov. 2019, pp. 842–847. doi: \n10.1109/ICSSIT46314.2019.8987754. \n[49] L. D.\
    \ Rodić, T. Županović, T. Perković, P. Šolić, and J. J. P. C. \nRodrigues, “Machine\
    \ Learning and Soil Humidity Sensing: Signal \nStrength Approach,” ACM Trans.\
    \ Internet Technol., vol. 22, no. 2, \nOct. 2021, doi: 10.1145/3418207. \n[50]\
    \ R. Reshma, V. Sathiyavathi, T. Sindhu, K. Selvakumar, and L. \nSaiRamesh, “IoT\
    \ based Classification Techniques for Soil Content \nAnalysis and Crop Yield Prediction,”\
    \ in 2020 Fourth International \nConference on I-SMAC (IoT in Social, Mobile,\
    \ Analytics and Cloud) \n(I-SMAC), \nOct. \n2020, \npp. \n156–160. \ndoi: \n10.1109/I-\n\
    SMAC49090.2020.9243600. \n[51] S. A. Z. Rahman, K. Chandra Mitra, and S. M. Mohidul\
    \ Islam, “Soil \nClassification Using Machine Learning Methods and Crop Suggestion\
    \ \nBased on Soil Series,” in 2018 21st International Conference of \nComputer\
    \ and Information Technology (ICCIT), Dec. 2018, pp. 1–4. \ndoi: 10.1109/ICCITECHN.2018.8631943.\
    \ \n[52] P. Gao et al., “Modeling for the Prediction of Soil Moisture in Litchi\
    \ \nOrchard with Deep Long Short-Term Memory,” Agriculture, vol. 12, \nno. 1,\
    \ p. 25, Dec. 2022, doi: 10.3390/agriculture12010025. \n[53] A. Dubois, F. Teytaud,\
    \ and S. Verel, “Short term soil moisture \nforecasts for potato crop farming:\
    \ A machine learning approach,” \nComputers and Electronics in Agriculture, vol.\
    \ 180, p. 105902, 2021, \ndoi: 10.1016/j.compag.2020.105902. \n[54] K. Dasgupta,\
    \ K. Das, and M. Padmanaban, “Soil Moisture Evaluation \nUsing Machine Learning\
    \ Techniques on Synthetic Aperture Radar \n(SAR) And Land Surface Model,” in IGARSS\
    \ 2019 - 2019 IEEE \nInternational Geoscience and Remote Sensing Symposium, Jul.\
    \ 2019, \npp. 5972–5975. doi: 10.1109/IGARSS.2019.8900220. \n[55] E. ACAR, M.\
    \ S. OZERDEM, and B. B. USTUNDAG, “Machine \nLearning based Regression Model for\
    \ Prediction of Soil Surface \nHumidity over Moderately Vegetated Fields,” in\
    \ 2019 8th \nInternational \nConference \non \nAgro-Geoinformatics \n(Agro-\n\
    Geoinformatics), \nJul. \n2019, \npp. \n1–4. \ndoi: \n10.1109/Agro-\nGeoinformatics.2019.8820461.\
    \ \n[56] M. H. X. Wai, A. Huong, and X. Ngu, “Soil moisture level prediction \n\
    using optical technique and artificial neural network,” International \nJournal\
    \ of Electrical and Computer Engineering, vol. 11, no. 2, pp. \n1752–1760, Apr.\
    \ 2021, doi: 10.11591/ijece.v11i2.pp1752-1760. \n[57] L. Chen et al., “Estimating\
    \ Soil Moisture Over Winter Wheat Fields \nDuring Growing Season Using Machine-Learning\
    \ Methods,” IEEE \nJournal of Selected Topics in Applied Earth Observations and\
    \ Remote \nSensing, \nvol. \n14, \npp. \n3706–3718, \n2021, \ndoi: \n10.1109/JSTARS.2021.3067890.\
    \ \n[58] A. Goap, D. Sharma, A. K. Shukla, and C. Rama Krishna, “An IoT \nbased\
    \ smart irrigation management system using Machine learning \nand open source\
    \ technologies,” Computers and Electronics in \nAgriculture, \nvol. \n155, \n\
    pp. \n41–49, \n2018, \ndoi: \n10.1016/j.compag.2018.09.040. \n[59] J. Kwok and\
    \ Y. Sun, “A Smart IoT-Based Irrigation System with \nAutomated Plant Recognition\
    \ Using Deep Learning,” in Proceedings \nof the 10th International Conference\
    \ on Computer Modeling and \nSimulation, 2018, pp. 87–91. doi: 10.1145/3177457.3177506.\
    \ \n[60] A. Murthy, C. Green, R. Stoleru, S. Bhunia, C. Swanson, and T. \nChaspari,\
    \ \n“Machine \nLearning-Based \nIrrigation \nControl \nOptimization,” in Proceedings\
    \ of the 6th ACM International \nConference on Systems for Energy-Efficient Buildings,\
    \ Cities, and \nTransportation, 2019, pp. 213–222. doi: 10.1145/3360322.3360854.\
    \ \n[61] P. P. V, S. S M, and S. S. C, “Robust Smart Irrigation System using \n\
    Hydroponic Farming based on Data Science and IoT,” in 2020 IEEE \nBangalore Humanitarian\
    \ Technology Conference (B-HTC), Oct. \n2020, pp. 1–4. doi: 10.1109/B-HTC50970.2020.9297842.\
    \ \n[62] M. Sami et al., “A Deep Learning-Based Sensor Modeling for Smart \nIrrigation\
    \ System,” Agronomy, vol. 12, no. 1, p. 212, Jan. 2022, doi: \n10.3390/agronomy12010212.\
    \ \n[63] A. Glória, J. Cardoso, and P. Sebastião, “Sustainable Irrigation \nSystem\
    \ for Farming Supported by Machine Learning and Real-Time \nSensor Data,” Sensors,\
    \ vol. 21, no. 9, p. 3076, Apr. 2021, doi: \n10.3390/s21093079. \n[64] K. Cagri\
    \ Serdaroglu, C. Onel, and S. Baydere, “IoT Based Smart Plant \nIrrigation System\
    \ with Enhanced learning,” in 2020 IEEE Computing, \nCommunications and IoT Applications\
    \ (ComComAp), Dec. 2020, pp. \n1–6. doi: 10.1109/ComComAp51192.2020.9398892. \n\
    [65] R. Kondaveti, A. Reddy, and S. Palabtla, “Smart Irrigation System \nUsing\
    \ Machine Learning and IOT,” in 2019 International Conference \non Vision Towards\
    \ Emerging Trends in Communication and \nNetworking \n(ViTECoN), \nMar. \n2019,\
    \ \npp. \n1–11. \ndoi: \n10.1109/ViTECoN.2019.8899433. \n[66] S. Akshay and T.\
    \ K. Ramesh, “Efficient Machine Learning Algorithm \nfor Smart Irrigation,” in\
    \ 2020 International Conference on \nCommunication and Signal Processing (ICCSP),\
    \ Jul. 2020, pp. 867–\n870. doi: 10.1109/ICCSP48568.2020.9182215. \n[67] J. Cardoso,\
    \ A. Glória, and P. Sebastião, “Improve Irrigation Timing \nDecision for Agriculture\
    \ using Real Time Data and Machine \nLearning,” in 2020 International Conference\
    \ on Data Analytics for \nBusiness and Industry: Way Towards a Sustainable Economy\
    \ \n(ICDABI), \nOct. \n2020, \npp. \n1–5. \ndoi: \n10.1109/ICDABI51230.2020.9325680.\
    \ \n[68] L. Rabhi, N. Falih, L. Afraites, and B. Bouikhalene, “Digital \nagriculture\
    \ based on big data analytics: A focus on predictive \nirrigation for smart farming\
    \ in Morocco,” Indonesian Journal of \nElectrical Engineering and Computer Science,\
    \ vol. 24, no. 1, pp. 581–\n589, Oct. 2021, doi: 10.11591/ijeecs.v24.i1.pp581-589.\
    \ \n[69] V. Psiroukis, B. Espejo-Garcia, A. Chitos, A. Dedousis, K. \nKarantzalos,\
    \ and S. Fountas, “Assessment of Different Object \nDetectors for the Maturity\
    \ Level Classification of Broccoli Crops \nUsing UAV Imagery,” Remote Sensing,\
    \ vol. 14, no. 3, p. 731, Feb. \n2022, doi: 10.3390/rs14030731. \n[70] D. Li et\
    \ al., “Improving Potato Yield Prediction by Combining \nCultivar Information\
    \ and UAV Remote Sensing Data Using Machine \nLearning,” Remote Sensing, vol.\
    \ 13, no. 16, p. 3322, Aug. 2021, doi: \n10.3390/rs13163322. \n[71] L. el Hoummaidi,\
    \ A. Larabi, and K. Alam, “Using unmanned aerial \nsystems and deep learning for\
    \ agriculture mapping in Dubai,” \nHeliyon, \nvol. \n7, \nno. \n10, \np. \ne08154,\
    \ \n2021, \ndoi: \n10.1016/j.heliyon.2021.e08154. \n[72] D.-H. Lee, H.-J. Kim,\
    \ and J.-H. Park, “UAV, a Farm Map, and \nMachine Learning Technology Convergence\
    \ Classification Method of \na Corn Cultivation Area,” Agronomy, vol. 11, no.\
    \ 8, p. 1554, Aug. \n2021, doi: 10.3390/agronomy11081554. \n[73] P. Nevavuori,\
    \ N. Narra, P. Linna, and T. Lipping, “Crop Yield \nPrediction Using Multitemporal\
    \ UAV Data and Spatio-Temporal \nDeep Learning Models,” Remote Sensing, vol. 12,\
    \ no. 23, p. 4000, \nDec. 2020, doi: 10.3390/rs12234000. \n[74] C. Li, T. Zhen,\
    \ and Z. Li, “Image Classification of Pests with Residual \nNeural Network Based\
    \ on Transfer Learning,” Applied Sciences, vol. \n12, no. 9, p. 4356, Apr. 2022,\
    \ doi: 10.3390/app12094356. \n[75] Z. Hu et al., “Research on Identification Technology\
    \ of Field Pests \nwith Protective Color Characteristics,” Applied Sciences, vol.\
    \ 12, no. \n8, p. 3810, Apr. 2022, doi: 10.3390/app12083810. \nJournal of Robotics\
    \ and Control (JRC) \nISSN: 2715-5072 \n278 \n \nMochammad Haldi Widianto, A Systematic\
    \ Review of Current Trends in Artificial Intelligence for Smart Farming to Enhance\
    \ Crop Yield \n[76] N. T. Nam and P. D. Hung, “Pest Detection on Traps Using Deep\
    \ \nConvolutional Neural Networks,” in Proceedings of the 2018 \nInternational\
    \ Conference on Control and Computer Vision, 2018, pp. \n33–38. doi: 10.1145/3232651.3232661.\
    \ \n[77] E. L. Mique and T. D. Palaoag, “Rice Pest and Disease Detection \nUsing\
    \ Convolutional Neural Network,” in Proceedings of the 2018 \nInternational Conference\
    \ on Information Science and System, 2018, \npp. 147–151. doi: 10.1145/3209914.3209945.\
    \ \n[78] M. Khanramaki, E. Askari Asli-Ardeh, and E. Kozegar, “Citrus pests \n\
    classification using an ensemble of deep learning models,” Computers \nand Electronics\
    \ in Agriculture, vol. 186, p. 106192, 2021, doi: \n10.1016/j.compag.2021.106192.\
    \ \n[79] K. Thenmozhi and U. Srinivasulu Reddy, “Crop pest classification \nbased\
    \ on deep convolutional neural network and transfer learning,” \nComputers and\
    \ Electronics in Agriculture, vol. 164, p. 104906, 2019, \ndoi: 10.1016/j.compag.2019.104906.\
    \ \n[80] G. Pattnaik and K. Parvathy, “Machine learning-based approaches for \n\
    tomato pest classification,” TELKOMNIKA (Telecommunication \nComputing Electronics\
    \ and Control), vol. 20, no. 2, pp. 321–328, Apr. \n2022, doi: 10.12928/telkomnika.v20i2.19740.\
    \ \n[81] Y. Song, X. Duan, Y. Ren, J. Xu, L. Luo, and D. Li, “Identification of\
    \ \nthe Agricultural Pests Based on Deep Learning Models,” in 2019 \nInternational\
    \ Conference on Machine Learning, Big Data and \nBusiness Intelligence (MLBDBI),\
    \ Nov. 2019, pp. 195–198. doi: \n10.1109/MLBDBI48998.2019.00044. \n[82] V. Panchbhaiyye\
    \ and T. Ogunfunmi, “Experimental Results on Using \nDeep Learning to Identify\
    \ Agricultural Pests,” in 2018 IEEE Global \nHumanitarian Technology Conference\
    \ (GHTC), Oct. 2018, pp. 1–2. \ndoi: 10.1109/GHTC.2018.8601896. \n[83] V. Agnihotri,\
    \ “Machine Learning based Pest Identification in Paddy \nPlants,” in 2019 3rd\
    \ International conference on Electronics, \nCommunication and Aerospace Technology\
    \ (ICECA), Jun. 2019, pp. \n246–250. doi: 10.1109/ICECA.2019.8822047. \n[84] S.\
    \ Zhang, J. Zhu, and N. Li, “Agricultural Pest Detection System \nBased on Machine\
    \ Learning,” in 2021 IEEE 4th International \nConference on Electronics Technology\
    \ (ICET), May 2021, pp. 1192–\n1196. doi: 10.1109/ICET51757.2021.9451034. \n[85]\
    \ D. Marković, D. Vujičić, S. Tanasković, B. Đorđević, S. Ranđić, and \nZ. Stamenković,\
    \ “Prediction of Pest Insect Appearance Using Sensors \nand Machine Learning,”\
    \ Sensors, vol. 21, no. 14, p. 4846, Jul. 2021, \ndoi: 10.3390/s21144846. \n[86]\
    \ R. Reedha, E. Dericquebourg, R. Canals, and A. Hafiane, \n“Transformer Neural\
    \ Network for Weed and Crop Classification of \nHigh Resolution UAV Images,” Remote\
    \ Sensing, vol. 14, no. 3, p. \n592, Jan. 2022, doi: 10.3390/rs14030592. \n[87]\
    \ F. Garibaldi-Márquez, G. Flores, D. A. Mercado-Ravell, A. Ramírez-\nPedraza,\
    \ and L. M. Valentín-Coronado, “Weed Classification from \nNatural Corn Field-Multi-Plant\
    \ Images Based on Shallow and Deep \nLearning,” Sensors, vol. 22, no. 8, p. 3021,\
    \ Apr. 2022, doi: \n10.3390/s22083021. \n[88] N. Razfar, J. True, R. Bassiouny,\
    \ V. Venkatesh, and R. Kashef, “Weed \ndetection in soybean crops using custom\
    \ lightweight deep learning \nmodels,” Journal of Agriculture and Food Research,\
    \ vol. 8, p. \n100308, 2022, doi: 10.1016/j.jafr.2022.100308. \n[89] J. Haichen,\
    \ C. Qingrui, and L. Zheng Guang, “Weeds and Crops \nClassification Using Deep\
    \ Convolutional Neural Network,” in 2020 \nthe 3rd International Conference on\
    \ Control and Computer Vision, \n2020, pp. 40–44. doi: 10.1145/3425577.3425585.\
    \ \n[90] U. F. Ukaegbu, L. K. Tartibu, M. O. Okwu, and I. O. Olayode, “Deep \n\
    Learning Application in Diverse Fields with Plant Weed Detection as \na Case Study,”\
    \ in Proceedings of the International Conference on \nArtificial Intelligence\
    \ and Its Applications, 2021, pp. 1–9. doi: \n10.1145/3487923.3487926. \n[91]\
    \ T. Luo et al., “Classification of weed seeds based on visual images \nand deep\
    \ learning,” Information Processing in Agriculture, 2021, doi: \n10.1016/j.inpa.2021.10.002.\
    \ \n[92] M. Alam, M. S. Alam, M. Roman, M. Tufail, M. U. Khan, and M. T. \nKhan,\
    \ “Real-Time Machine-Learning Based Crop/Weed Detection \nand Classification for\
    \ Variable-Rate Spraying in Precision \nAgriculture,” in 2020 7th International\
    \ Conference on Electrical and \nElectronics Engineering (ICEEE), Apr. 2020, pp.\
    \ 273–280. doi: \n10.1109/ICEEE49618.2020.9102505. \n[93] A. Etienne, A. Ahmad,\
    \ V. Aggarwal, and D. Saraswat, “Deep \nLearning-Based Object Detection System\
    \ for Identifying Weeds \nUsing UAS Imagery,” Remote Sensing, vol. 13, no. 24,\
    \ p. 5182, Dec. \n2021, doi: 10.3390/rs13245182. \n[94] C. T. Selvi, R. S. Sankara\
    \ Subramanian, and R. Ramachandran, \n“Weed Detection in Agricultural fields using\
    \ Deep Learning Process,” \nin 2021 7th International Conference on Advanced Computing\
    \ and \nCommunication Systems (ICACCS), Mar. 2021, pp. 1470–1473. doi: \n10.1109/ICACCS51430.2021.9441683.\
    \ \n[95] X. Jin, J. Che, and Y. Chen, “Weed Identification Using Deep \nLearning\
    \ and Image Processing in Vegetable Plantation,” IEEE \nAccess, \nvol. \n9, \n\
    pp. \n10940–10950, \n2021, \ndoi: \n10.1109/ACCESS.2021.3050296. \n[96] S. Badhan,\
    \ K. Desai, M. Dsilva, R. Sonkusare, and S. Weakey, “Real-\nTime Weed Detection\
    \ using Machine Learning and Stereo-Vision,” in \n2021 6th International Conference\
    \ for Convergence in Technology \n(I2CT), Apr. 2021, pp. 1–5. doi: 10.1109/I2CT51068.2021.9417989.\
    \ \n[97] B. Jabir and N. Falih, “Deep learning-based decision support system \n\
    for weeds detection in wheat fields,” International Journal of \nElectrical and\
    \ Computer Engineering, vol. 12, no. 1, pp. 816–825, \nFeb. 2022, doi: 10.11591/ijece.v12i1.pp816-825.\
    \ \n[98] A. Tannouche, A. Gaga, M. Boutalline, and S. Belhouideg, “Weeds \ndetection\
    \ efficiency through different convolutional neural networks \ntechnology,” International\
    \ Journal of Electrical and Computer \nEngineering, vol. 12, no. 1, pp. 1048–1055,\
    \ Feb. 2022, doi: \n10.11591/ijece.v12i1.pp1048-1055. \n[99] R. G. de Luna, E.\
    \ P. Dadios, and A. A. Bandala, “Automated Image \nCapturing System for Deep Learning-based\
    \ Tomato Plant Leaf \nDisease Detection and Recognition,” in TENCON 2018 - 2018\
    \ IEEE \nRegion \n10 \nConference, \nOct. \n2018, \npp. \n1414–1419. \ndoi: \n\
    10.1109/TENCON.2018.8650088. \n[100] U. Afzaal, B. Bhattarai, Y. R. Pandeya, and\
    \ J. Lee, “An Instance \nSegmentation Model for Strawberry Diseases Based on Mask\
    \ R-\nCNN,” Sensors, vol. 21, no. 19, p. 6565, Sep. 2021, doi: \n10.3390/s21196565.\
    \ \n[101] N. Radha and R. Swathika, “A Polyhouse: Plant Monitoring and \nDiseases\
    \ Detection using CNN,” in 2021 International Conference on \nArtificial Intelligence\
    \ and Smart Systems (ICAIS), Mar. 2021, pp. \n966–971. doi: 10.1109/ICAIS50930.2021.9395847.\
    \ \n[102] J. Zhu, T. Yu, S. Zheng, C. Niu, J. Gao, and J. Tang, “Hemp Disease\
    \ \nDetection and Classification Using Machine Learning,” in 2020 \nInternational\
    \ Conferences on Internet of Things (iThings) and IEEE \nGreen Computing and Communications\
    \ (GreenCom) and IEEE \nCyber, Physical and Social Computing (CPSCom) and IEEE\
    \ Smart \nData \n(SmartData) \nand \nIEEE \nCongress \non \nCybermatics \n(Cybermatics),\
    \ Nov. 2020, pp. 878–887. doi: 10.1109/iThings-\nGreenCom-CPSCom-SmartData-Cybermatics50389.2020.00151.\
    \ \n[103] U. Barman and R. D. Choudhury, “Smartphone Assist Deep Neural \nNetwork\
    \ to Detect the Citrus Diseases in Agri-Informatics,” Global \nTransitions Proceedings,\
    \ 2021, doi: 10.1016/j.gltp.2021.10.004. \n[104] K. Wei et al., “Explainable Deep\
    \ Learning Study for Leaf Disease \nClassification,” Agronomy, vol. 12, no. 5,\
    \ p. 1035, Apr. 2022, doi: \n10.3390/agronomy12051035. \n[105] H. Wan, Z. Lu,\
    \ W. Qi, and Y. Chen, “Plant Disease Classification \nUsing Deep Learning Methods,”\
    \ in Proceedings of the 4th \nInternational Conference on Machine Learning and\
    \ Soft Computing, \n2020, pp. 5–9. doi: 10.1145/3380688.3380697. \n[106] S. Z.\
    \ M. Zaki, M. A. Zulkifley, M. Mohd Stofa, N. A. M. Kamari, and \nN. A. Mohamed,\
    \ “Classification of tomato leaf diseases using \nmobilenet v2,” IAES International\
    \ Journal of Artificial Intelligence, \nvol. 9, no. 2, pp. 290–296, Jun. 2020,\
    \ doi: 10.11591/ijai.v9.i2.pp290-\n296. \n[107] M. J. Mia, S. K. Maria, S. S.\
    \ Taki, and A. A. Biswas, “Cucumber \ndisease recognition using machine learning\
    \ and transfer learning,” \nBulletin of Electrical Engineering and Informatics,\
    \ vol. 10, no. 6, pp. \n3432–3443, Dec. 2021, doi: 10.11591/eei.v10i6.3096. \n\
    \ \n"
  inline_citation: '>'
  journal: Journal of Robotics and Control
  limitations: '>'
  pdf_link: https://journal.umy.ac.id/index.php/jrc/article/download/13760/7357
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: A Systematic Review of Current Trends in Artificial Intelligence for Smart
    Farming to Enhance Crop Yield
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/access.2022.3187528
  analysis: '>'
  authors:
  - Zhiming Hu
  - Rab Nawaz Bashir
  - Atta Ur Rehman
  - Salman Iqbal Iqbal
  - Malik Muhammad Ali Shahid
  - Tengfei Xu
  citation_count: 12
  full_citation: '>'
  full_text: '>

    IEEE.org IEEE Xplore IEEE-SA IEEE Spectrum More Sites 404: Page Not Found The
    page you were looking for could not be found. Browse or search IEEE Xplore to
    continue. Email us at onlinesupport@ieee.org for further assistance. © Copyright
    2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE access
  limitations: '>'
  pdf_link: https://ieeexplore.ieee.org/ielx7/6287639/6514899/09810934.pdf
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: Machine Learning Based Prediction of Reference Evapotranspiration (ET<sub>0</sub>)
    Using IoT
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/app13148332
  analysis: '>'
  authors:
  - Ali Assaf
  - Habibollah Haron
  - Haza Nuzly Abdull Hamed
  - Fuad A. Ghaleb
  - Sultan Noman Qasem
  - Abdullah M. Albarrak
  citation_count: 5
  full_citation: '>'
  full_text: ">\nCitation: Assaf, A.M.; Haron, H.;\nAbdull Hamed, H.N.; Ghaleb, F.A.;\n\
    Qasem, S.N.; Albarrak, A.M. A\nReview on Neural Network Based\nModels for Short\
    \ Term Solar\nIrradiance Forecasting. Appl. Sci.\n2023, 13, 8332. https://doi.org/\n\
    10.3390/app13148332\nAcademic Editors: Ahmed F. Zobaa\nand Almoataz Youssef Abdelaziz\n\
    Received: 25 May 2023\nRevised: 1 July 2023\nAccepted: 5 July 2023\nPublished:\
    \ 19 July 2023\nCopyright:\n© 2023 by the authors.\nLicensee MDPI, Basel, Switzerland.\n\
    This article is an open access article\ndistributed\nunder\nthe\nterms\nand\n\
    conditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n\
    4.0/).\napplied  \nsciences\nReview\nA Review on Neural Network Based Models for\
    \ Short Term\nSolar Irradiance Forecasting\nAbbas Mohammed Assaf 1,*\n, Habibollah\
    \ Haron 1,*, Haza Nuzly Abdull Hamed 1, Fuad A. Ghaleb 1\n,\nSultan Noman Qasem\
    \ 2\nand Abdullah M. Albarrak 2\n1\nFaculty of Computing, Universiti Teknologi\
    \ Malaysia, Johor Bahru 81310, Malaysia;\nhaza@utm.my (H.N.A.H.); abdulgaleel@utm.my\
    \ (F.A.G.)\n2\nDepartment of Computer Science, College of Computer and Information\
    \ Sciences, Imam Mohammad Ibn\nSaud Islamic University (IMSIU), Riyadh 11432,\
    \ Saudi Arabia; snmohammed@imamu.edu.sa (S.N.Q.);\namsbarrak@imamu.edu.sa (A.M.A.)\n\
    *\nCorrespondence: assaf.abbas@graduate.utm.my (A.M.A.); habib@utm.my (H.H.)\n\
    Abstract: The accuracy of solar energy forecasting is critical for power system\
    \ planning, management,\nand operation in the global electric energy grid. Therefore,\
    \ it is crucial to ensure a constant and\nsustainable power supply to consumers.\
    \ However, existing statistical and machine learning algo-\nrithms are not reliable\
    \ for forecasting due to the sporadic nature of solar energy data. Several factors\n\
    inﬂuence the performance of solar irradiance, such as forecasting horizon, weather\
    \ classiﬁcation,\nand performance evaluation metrics. Therefore, we provide a\
    \ review paper on deep learning-based\nsolar irradiance forecasting models. These\
    \ models include Long Short-Term Memory (LTSM), Gated\nRecurrent Unit (GRU), Recurrent\
    \ Neural Network (RNN), Convolutional Neural Network (CNN),\nGenerative Adversarial\
    \ Networks (GAN), Attention Mechanism (AM), and other existing hybrid\nmodels.\
    \ Based on our analysis, deep learning models perform better than conventional\
    \ models in\nsolar forecasting applications, especially in combination with some\
    \ techniques that enhance the ex-\ntraction of features. Furthermore, the use\
    \ of data augmentation techniques to improve deep learning\nperformance is useful,\
    \ especially for deep networks. Thus, this paper is expected to provide a baseline\n\
    analysis for future researchers to select the most appropriate approaches for\
    \ photovoltaic power\nforecasting, wind power forecasting, and electricity consumption\
    \ forecasting in the medium term\nand long term.\nKeywords: Attention Mechanism;\
    \ Convolutional Neural Network; deep learning; Generative Adversarial\nNetwork;\
    \ hybrid model; solar irradiance forecasting; Long Short-Term Memory\n1. Introduction\n\
    Recently, research on alternative energy resources has grown in popularity because\n\
    traditional energy sources are environmentally unfriendly and non-sustainable.\
    \ Moreover,\nthere is an ever-growing global energy crisis, since economic and\
    \ technological advance-\nments are highly dependent on the availability of energy\
    \ that is essential to industrialization\nand urbanization worldwide. Conversely,\
    \ the progressive growth of global inhabitancy has\nexacerbated the severity of\
    \ the global energy shortages. According to [1], electricity demand\nis anticipated\
    \ to grow by up to 70%. In the 20th century, fossil fuels were acknowledged as\n\
    the main sources of electrical energy generation, and they continue to play an\
    \ important\nrole today. Despite this fact, the prolonged consumption of fossil\
    \ fuel supplies, which are\nalready in short supply, adversely affects global\
    \ climate change (greenhouse effect or global\nwarming) [2,3] and is hazardous\
    \ to global health [4].\nMore recently, solar energy has been widely utilized\
    \ in photovoltaic (PV) power\ngeneration. The global PV power capacity may exceed\
    \ 1700 GW by 2030 [5]. Thus, the\ngeneration of PV power is known as another promising\
    \ renewable energy source because\nit offers more beneﬁts, including reducing\
    \ the use of fossil fuels and helping power system\nAppl. Sci. 2023, 13, 8332.\
    \ https://doi.org/10.3390/app13148332\nhttps://www.mdpi.com/journal/applsci\n\
    Appl. Sci. 2023, 13, 8332\n2 of 43\noperators to achieve their peak load demand\
    \ [6]. However, the forecastability of solar PV\noutput is heavily inﬂuenced by\
    \ weather conditions, such as rainy, cloudy, and sunny days;\nsudden weather changes;\
    \ snowy days; and other weather types, which present challenges\nfor system administrators.\
    \ Henceforth, PV power generation must be reliable in terms of\naccuracy for effective\
    \ grid function [7,8]. Thus, commercial electric power companies are\nhaving difﬁculties\
    \ in delivering reliable and safe electricity to their clients because electric\n\
    power systems require accurate forecasting models to plan their operations. The\
    \ demand\npatterns for electricity also include time, the economy, and social\
    \ and environmental\nfactors [9,10]. Solar irradiance forecasting assists in the\
    \ incorporation of solar PV plants\ninto the electricity grid, the scheduling\
    \ of energy storage systems, and energy transmission\noptimization, which reduces\
    \ energy loss [11]. It also reduces reserve capacity and cost\ngeneration, thus\
    \ preventing electrical energy system disruption [12], making it easier to\npredict\
    \ PV power generation. Over the years, solar irradiance forecasting has gained\n\
    a lot of interest from both academics and businesses due to the abundant and limitless\n\
    nature of solar energy that allows it to provide sustainable power globally. On\
    \ average,\nthe Earth receives 1367 W/m2 of solar radiation per day, which can\
    \ yield 1.74 × 1017 W in\na year. Figure 1 illustrates the potential distribution\
    \ of solar energy globally, inferencing\nthe limitless solar energy supply on\
    \ Earth. Thus, solar energy is shown to be the best\nalternative option to ensure\
    \ the availability of energy sources for industrial, commercial,\nand residential\
    \ use [13].\nAppl. Sci. 2023, 13, x FOR PEER REVIEW \n2 of 43 \n \noffers more\
    \ benefits, including reducing the use of fossil fuels and helping power system\
    \ \noperators to achieve their peak load demand [6]. However, the forecastability\
    \ of solar PV \noutput is heavily influenced by weather conditions, such as rainy,\
    \ cloudy, and sunny \ndays; sudden weather changes; snowy days; and other weather\
    \ types, which present chal-\nlenges for system administrators. Henceforth, PV\
    \ power generation must be reliable in \nterms of accuracy for effective grid\
    \ function [7,8]. Thus, commercial electric power com-\npanies are having difficulties\
    \ in delivering reliable and safe electricity to their clients be-\ncause electric\
    \ power systems require accurate forecasting models to plan their operations.\
    \ \nThe demand patterns for electricity also include time, the economy, and social\
    \ and envi-\nronmental factors [9,10]. Solar irradiance forecasting assists in\
    \ the incorporation of solar \nPV plants into the electricity grid, the scheduling\
    \ of energy storage systems, and energy \ntransmission optimization, which reduces\
    \ energy loss [11]. It also reduces reserve capacity \nand cost generation, thus\
    \ preventing electrical energy system disruption [12], making it \neasier to predict\
    \ PV power generation. Over the years, solar irradiance forecasting has \ngained\
    \ a lot of interest from both academics and businesses due to the abundant and\
    \ lim-\nitless nature of solar energy that allows it to provide sustainable power\
    \ globally. On aver-\nage, the Earth receives 1367 W/m2 of solar radiation per\
    \ day, which can yield 1.74 × 1017 W \nin a year. Figure 1 illustrates the potential\
    \ distribution of solar energy globally, inferencing \nthe limitless solar energy\
    \ supply on Earth. Thus, solar energy is shown to be the best al-\nternative option\
    \ to ensure the availability of energy sources for industrial, commercial, \n\
    and residential use [13]. \n \nFigure 1. Global distribution of solar resources\
    \ across the map [14]. \nThe main types of power forecasting models are (1) short-term\
    \ models, which fore-\ncast up to 1 day/week in advance; (2) medium-term models,\
    \ which forecast up to 1 year \nin advance; and (3) long-term models, which forecast\
    \ more than 1 year in advance and are \nmainly utilized to develop electricity\
    \ power distribution and power supply systems [15–\n17]. Sudden changes in solar\
    \ irradiance, known as ramp events, are relevant for extremely \nshort-term and\
    \ very short-term forecast horizons. Furthermore, if changes in solar irradi-\n\
    ance happen too quickly and strongly, PV power could become less reliable and\
    \ reduce \nin quality. Therefore, the results of short-term forecasting may be\
    \ utilized to determine \nthe most effective PV power ramp rates [18]. Moreover,\
    \ forecasting for the long term and \nmedium term enables operational enhancement\
    \ and market engagement [19]. Day-ahead \nsolar irradiance estimates have been\
    \ shown to enhance yearly energy consumption for \ncommercial operations in building\
    \ micro grids. Therefore, solar energy forecasts need to \nbe tailored based on\
    \ specific applications and adjusted using a suitable forecasting ap-\nproach.\
    \ \nFigure 1. Global distribution of solar resources across the map [14].\nThe\
    \ main types of power forecasting models are (1) short-term models, which forecast\n\
    up to 1 day/week in advance; (2) medium-term models, which forecast up to 1 year\
    \ in\nadvance; and (3) long-term models, which forecast more than 1 year in advance\
    \ and are\nmainly utilized to develop electricity power distribution and power\
    \ supply systems [15–17].\nSudden changes in solar irradiance, known as ramp events,\
    \ are relevant for extremely short-\nterm and very short-term forecast horizons.\
    \ Furthermore, if changes in solar irradiance\nhappen too quickly and strongly,\
    \ PV power could become less reliable and reduce in\nquality. Therefore, the results\
    \ of short-term forecasting may be utilized to determine the\nmost effective PV\
    \ power ramp rates [18]. Moreover, forecasting for the long term and\nmedium term\
    \ enables operational enhancement and market engagement [19]. Day-ahead\nsolar\
    \ irradiance estimates have been shown to enhance yearly energy consumption for\n\
    commercial operations in building micro grids. Therefore, solar energy forecasts\
    \ need to be\ntailored based on speciﬁc applications and adjusted using a suitable\
    \ forecasting approach.\nThe available literature discusses the solar irradiance\
    \ forecasting of photovoltaic\nsystems (PV), which uses image-based models for\
    \ GHI forecasting. According to [20],\nAppl. Sci. 2023, 13, 8332\n3 of 43\nthis\
    \ method performs admirably when it is used for solar irradiance forecasting in\
    \ a\ntargeted region. The high temporal and geographical resolutions of sky images\
    \ enable the\ncapture of cloud motion. In contrast to empirical methods, image-based\
    \ models extract\ncloud information from the sky image dataset to ensure the accuracy\
    \ of GHI forecasting.\nHowever, the drawbacks of image-based models include limited\
    \ access to image datasets,\nexpensive image capture equipment, and expensive\
    \ image processing [21]. There are\nfour ways to conduct PV power and solar irradiance\
    \ forecasting: physical approaches,\nstatistical models, artiﬁcial intelligence-based\
    \ techniques, and hybrid approaches. The\nphysical approaches use satellite images\
    \ and the Numerical Weather prediction (NWP)\nmodel to forecast solar irradiance\
    \ [22]. The NWP model determines the physical state\nand solar irradiance using\
    \ a dynamic atmospheric model. Moreover, the NWP model\nincorporates both geospatial\
    \ information and meteorological data [23]. Even though\nphysical models are commonly\
    \ utilized to forecast atmospheric dynamics, their complexity\nis a major setback.\
    \ This problem occurs due to the fact that physical models require higher\ncomputational\
    \ resources and more time to handle massive datasets. Consequently, the use\n\
    of physical models for estimating short-term solar irradiation is considered ineffective\
    \ [24].\nAccording to the literature, several other statistical models have been\
    \ utilized, including\nautoregressive moving averages [25] and dynamic systems\
    \ with coupled autoregressive\nfeatures [26]. Moreover, statistical models are\
    \ effective when using continuous time-series\ndata, even though these data are\
    \ not constant because of the effects of season and weather\nchanges. Although\
    \ the use of statistical models is an excellent option for forecasting solar\n\
    irradiation over time series, they are unable to incorporate non-linearity into\
    \ the data, hence\nthe minimal accuracy of forecasts [27]. Moreover, it is challenging\
    \ to forecast solar energy\nusing physical and statistical methods due to the\
    \ massive amount of weather data involved.\nThere has been a signiﬁcant increase\
    \ in interest in solar radiation forecasting research.\nBy examining the data\
    \ presented in Figure 2 from the Web of Knowledge website (WoS), it is\nevident\
    \ that the number of published papers in this ﬁeld has experienced seven-fold\
    \ growth\nover the past decade (2010–2023) compared to the previous decade (2000–2010).\
    \ Notably,\nwithin the last three years alone (2020–2023), there have been 1300\
    \ papers published,\ncompared to the 2159 papers published between 2010 and 2019.\n\
    tems (PV), which uses image-based models for GHI forecasting. According to [20],\
    \ this \nmethod performs admirably when it is used for solar irradiance forecasting\
    \ in a targeted \nregion. The high temporal and geographical resolutions of sky\
    \ images enable the capture \nof cloud motion. In contrast to empirical methods,\
    \ image-based models extract cloud in-\nformation from the sky image dataset to\
    \ ensure the accuracy of GHI forecasting. However, \nthe drawbacks of image-based\
    \ models include limited access to image datasets, expensive \nimage capture equipment,\
    \ and expensive image processing [21]. There are four ways to \nconduct PV power\
    \ and solar irradiance forecasting: physical approaches, statistical mod-\nels,\
    \ artificial intelligence-based techniques, and hybrid approaches. The physical\
    \ ap-\nproaches use satellite images and the Numerical Weather prediction (NWP)\
    \ model to fore-\ncast solar irradiance [22]. The NWP model determines the physical\
    \ state and solar irradi-\nance using a dynamic atmospheric model. Moreover, the\
    \ NWP model incorporates both \ngeospatial information and meteorological data\
    \ [23]. Even though physical models are \ncommonly utilized to forecast atmospheric\
    \ dynamics, their complexity is a major setback. \nThis problem occurs due to\
    \ the fact that physical models require higher computational \nresources and more\
    \ time to handle massive datasets. Consequently, the use of physical \nmodels\
    \ for estimating short-term solar irradiation is considered ineffective [24].\
    \ Accord-\ning to the literature, several other statistical models have been utilized,\
    \ including auto-\nregressive moving averages [25] and dynamic systems with coupled\
    \ autoregressive fea-\ntures [26]. Moreover, statistical models are effective\
    \ when using continuous time-series \ndata, even though these data are not constant\
    \ because of the effects of season and weather \nchanges. Although the use of\
    \ statistical models is an excellent option for forecasting solar \nirradiation\
    \ over time series, they are unable to incorporate non-linearity into the data,\
    \ \nhence the minimal accuracy of forecasts [27]. Moreover, it is challenging\
    \ to forecast solar \nenergy using physical and statistical methods due to the\
    \ massive amount of weather data \ninvolved. \nThere has been a significant increase\
    \ in interest in solar radiation forecasting research. \nBy examining the data\
    \ presented in Figure 2 from the Web of Knowledge website (WoS), \nit is evident\
    \ that the number of published papers in this field has experienced seven-fold\
    \ \ngrowth over the past decade (2010–2023) compared to the previous decade (2000–2010).\
    \ \nNotably, within the last three years alone (2020–2023), there have been 1300\
    \ papers pub-\nlished, compared to the 2159 papers published between 2010 and\
    \ 2019.  \n \nFigure 2. Publication frequency and citations report according to\
    \ WoS website. \nRecently, the problem of forecasting solar irradiance was addressed\
    \ using machine \nlearning algorithms, which have shown superior outcomes compared\
    \ to the statistical and \nFigure 2. Publication frequency and citations report\
    \ according to WoS website.\nRecently, the problem of forecasting solar irradiance\
    \ was addressed using machine\nlearning algorithms, which have shown superior\
    \ outcomes compared to the statistical\nand physical approaches related to quality\
    \ and dependability. One of the superior aspects\nAppl. Sci. 2023, 13, 8332\n\
    4 of 43\nof the machine learning method is the fact that it can extract non-complex\
    \ features from\nlarge amounts of high-dimensional data [28], as well as be utilized\
    \ to extract non-complex\nfeatures. In [29], the time-dependent characteristics\
    \ of solar irradiance are identiﬁed, and\nan ensemble-learning-based solar radiation\
    \ forecasting model is provided. Moreover, types\nof artiﬁcial intelligence techniques\
    \ used include the extreme learning machine (ELM) [30],\nthe support vector machine\
    \ (SVM) [31], the wavelet transform [32], deep learning [33],\nthe artiﬁcial neural\
    \ network (ANN) [34], and ensemble learning [35]. Ref. [36] utilized\nANN and\
    \ SVM to forecast solar radiation at two different locations in Saudi Arabia on\
    \ a\ntilted surface.\nThe advancements in data acquisition and storage technologies\
    \ have made it possible\nfor meteorological stations and photovoltaic power plants\
    \ to collect massive amounts of\ndata samples. Nonetheless, establishing a research\
    \ question is still the best way to use these\nsamples. While some machine learning\
    \ models are unable to handle high-dimensional\ninputs or large datasets effectively,\
    \ others even deal with them at all. However, the theory\nof deep learning is\
    \ rapidly developing, especially in unsupervised feature extraction [37].\nMoreover,\
    \ deep learning models represent the most suitable approach for solar irradiance\n\
    forecasting, especially when it involves a complex and substantial amount of data.\
    \ In con-\ntrast, machine learning models’ efﬁciency decreases as the quantity\
    \ of input data increases.\nRef. [38] investigated the impact of altering the\
    \ input size on deep learning and ML models.\nThe ﬁndings demonstrated that the\
    \ performance of traditional machine learning models\nwas stagnant after a speciﬁed\
    \ quantity of data, whereas deep learning models continued\nto be enhanced when\
    \ they received more training data. Deep learning models thrive in a\nvariety\
    \ of areas, including image processing, pattern extraction, classiﬁcation, and\
    \ forecast-\ning, since they are efﬁcient in learning complex patterns data without\
    \ human expertise. For\nexample, building thermal load forecasting using deep\
    \ learning models was utilized in [39].\nBefore that study, the deep learning\
    \ model was introduced by [40] for short-term wave\nenergy forecasting. Likewise,\
    \ deep learning models have been extensively used for various\nforecasting applications,\
    \ such as wind speed [41], PV power [42], solar irradiance [43],\nand others.\
    \ The known problems associated with Conventional Neural Networks (CNN),\nsuch\
    \ as gradient vanishing and training complexity, can be simply resolved using\
    \ deep\nlearning networks. To forecast time series, [44] developed a sophisticated\
    \ neural network,\nwhile [45] utilized deep learning to forecast solar radiation\
    \ at 30 locations in Turkey. Thus,\ndeep learning models are better than machine\
    \ learning and empirical models in terms\nof accuracy. This fact is due the structure\
    \ of the hidden layers; however, training takes\nmore time to complete because\
    \ there are more parameters to adjust as the architecture\nbecomes more complex.\
    \ Although deep learning may yield positive outcomes, the training\nprocess is\
    \ typically challenging; therefore, researchers often merge deep learning with\n\
    feature extraction methods, like Attention Mechanism, to enhance the efﬁciency\
    \ of feature\nextraction. Subsequently, the neural network that was paired with\
    \ Attention Mechanism\nwas able to perform most effectively, improving neural\
    \ network interpretability by elimi-\nnating irrelevant data and only selecting\
    \ more important information, as well as differently\nweighting each feature of\
    \ the meteorological data.\nRef. [33] proposed Convolutional Neural Networks and\
    \ Generative Adversarial Net-\nworks that categorize the weather into 10 categories.\
    \ Enervative adversarial networks\nincrease the training dataset for every weather\
    \ category. The simulation outcomes demon-\nstrate that Generative Adversarial\
    \ Networks have the potential to build high ﬁneness\nquality specimens that capture\
    \ the underlying properties of the original data. A data\naugment based on Generative\
    \ Adversarial Networks optimizes all categorization models.\nThus, GAN is ideal\
    \ for data creation to augment and rebalance the training dataset. On the\nother\
    \ hand, researchers have rarely used GAN to create time-series data (i.e., hourly\
    \ GHI\nand meteorological data). Indeed, there is a signiﬁcant need for sufﬁcient\
    \ training data for\nPV power models, which might come from either an actual dataset\
    \ or augmentations.\nDespite solar energy being the most prominent renewable energy\
    \ resource, few review\npapers have been published on this topic. Thus, ref. [46]\
    \ presented a review analysis of an\nAppl. Sci. 2023, 13, 8332\n5 of 43\nANN-based\
    \ model used for solar radiation forecasting. Similarly, ref. [47] analyzed a\
    \ total\nof 87 journals that implement ANN for solar power forecasting. Before\
    \ that study, a review\nanalysis of machine learning-based solar radiation forecasting\
    \ models was conducted [48].\nRecent work by [49] investigated solar irradiance\
    \ forecasting using the SVM application. In\n2019, ref. [50] examined the application\
    \ of 70 sky solar irradiance models. Following that\nstudy, ref. [49] provided\
    \ a review paper on physical models used to predict solar irradiation.\nNext,\
    \ ref. [13] presented deep learning-based solar radiation forecasting models.\n\
    According to statistics, deep learning-based models has been extensively explored\n\
    for forecasting model, but there is still no available publication that concentrated\
    \ on\ninvestigating the generation of meteorological data and its effect on the\
    \ forecasting accuracy\nof PV power. Most previous studies focused on developing\
    \ forecasting models, which\nsuffer from inaccuracy, particularly for extreme\
    \ weather types, for which models use\nsmall datasets that do not give enough\
    \ representative training specimens for Deep Neural\nNetworks. As this review\
    \ study focuses on generating and balancing meteorological\ndata to improve forecasting\
    \ performance, it also paves the way for future research in\na variety of areas,\
    \ including photovoltaic power forecasting, wind power forecasting,\nelectricity\
    \ consumption forecasting in the medium term and long term, etc., by expanding\n\
    and embracing the modern technique suggested in this work through data generation.\n\
    In contrast, most studies of photovoltaic power, wind power, and energy consumption\n\
    concentrate on the short-term forecast, disregarding medium- and long-term forecasts\n\
    because of a lack of training data for models.\nIn sum, neural networks and deep\
    \ learning-based models have been extensively ex-\nplored for solar irradiance\
    \ forecasting. Although there have been many review papers\npublished recently\
    \ on solar irradiance forecasting, such as [1–6], there is a lack of a com-\n\
    prehensive review paper that studies the signiﬁcance of deep learning models for\
    \ solar\nirradiance forecasting. A deep analysis of the effects of deep feature\
    \ extraction on forecast-\ning performance has been conducted, as many past studies\
    \ on solar irradiance forecasting\ntended to overlook how to successfully extract\
    \ features from meteorological data. This\nreview paper focuses on reviewing recent\
    \ and effective deep learning models that have\nachieved notable performance.\
    \ Additionally, this study has covered forecasting impacts\nthat are often neglected\
    \ by existing reviews. It provides a comprehensive review that\ncovers various\
    \ aspects of solar energy forecasting related to deep learning models. It can\n\
    also serve as a valuable reference point for researchers developing deep-learning\
    \ solar\nenergy solutions.\nThe main aim of this paper is to address the limitations\
    \ of existing reviews in terms of\ncovering aspects such as the main variables\
    \ inﬂuencing solar irradiance forecast, including\nthe forecasting horizon, input\
    \ parameter optimization, weather classiﬁcation, and others.\nFurthermore, this\
    \ paper outlines the application of CNN, RNN, GRU, AM, LSTM, DBN,\nAttention Mechanism,\
    \ and GAN for solar irradiance forecasting. It presents factors that\ninﬂuence\
    \ the accuracy of the solar irradiance forecasting models, in addition to providing\n\
    a background introduction and discussing prominent deep learning techniques. The\n\
    review emphasizes the limitations of existing solutions and provides recommendations\
    \ for\nfuture work.\n2. The Impact Factor of Solar Power Forecasting\nSeveral\
    \ factors can inﬂuence the effectiveness of solar irradiance forecasting, including\n\
    forecasting horizon, weather classiﬁcation, performance evaluation metrics, and\
    \ input\nfeature optimization. The related factors are further elaborated in the\
    \ following subsections.\n2.1. Forecasting Horizon\nForecasting models for solar\
    \ energy can be classiﬁed based on their forecasting horizon.\nA power generation\
    \ operator must be aware of future power generation and consumption\ndemands.\
    \ The use of solar irradiance forecasting relies heavily on the types of forecasting\n\
    horizon to ensure its efﬁcient installation of various applications, including\
    \ the execution\nAppl. Sci. 2023, 13, 8332\n6 of 43\nof PV power plants. Speciﬁcally,\
    \ the operation of the grid requires varied time horizons to\nachieve grid stability,\
    \ spinning reserve scheduling, and unit commitment [51]. There are\nthree main\
    \ types of forecasting horizons: (1) short-term, (2) medium-term, and (3) long-\n\
    term horizons. In addition, limited studies included a fourth type, which is referred\
    \ to as\n“extremely short-term forecasting”. Currently, there is no general taxonomy\
    \ available for\nforecasting horizon; therefore, the list is presented as follows.\n\
    •\nIntra-hour forecasting, also known as nowcasting, is a very short-term forecasting\n\
    horizon that ranges from 1 min to many minutes in advance and is often used in\n\
    electricity pricing, bidding, real-time power system dispatch monitoring, and\
    \ peak load\nmatching [52].\n•\nShort-term forecasting horizons range from 1 or\
    \ several hours to 1 day or week in\nadvance [2] and are critical for optimal\
    \ unit commitment, rotating reserve control,\nand analyzing sales/purchase contracts\
    \ between multiple enterprises. Therefore, they\nfacilitate the development of\
    \ a PV-integrated energy management system and increase\ngrid security.\n•\nMedium-term\
    \ forecasting horizons range from 1 month to 1 year in advance [53] and\nare efﬁcient\
    \ for modeling the maintenance schedule of solar power plants developed\nusing\
    \ transformers and other facilities that incur the least amount of loss [54].\n\
    •\nLong-term forecasting horizons range from 1 year to 10 years in advance. This\
    \ distance\nis ideal for designing long-term plans that allow the creation of\
    \ effective solar power\nfacilities and global management, such as site selection,\
    \ required to develop a PV\npower plant and ensure transmission, operation, and\
    \ distribution of solar energy [55].\nHowever, it is not perfect for long-term\
    \ forecasting due to its inability to predict long-\nterm weather changes. However,\
    \ it is still deemed to be the most suitable model for\ndesigning schedule plans,\
    \ setting prices, and selecting site strategies [56,57].\nThe forecasting horizon\
    \ is one of the most inﬂuential factors for forecasting models in\nterms of accuracy,\
    \ even when its input features remain constant [58]. In such a case, ref. [59]\n\
    utilized SVM to generate a very short-term forecasting model. Their ﬁndings included\
    \ a\ndecrease in forecasting accuracy for a forecasting horizon ranging from 5\
    \ to 30 min from\n96 to 64.6%, respectively, for similar datasets. The growth\
    \ of statistical data at shorter time\nscales complicates the training process\
    \ rather than improving accuracy. Several interrelated\nvariables affect the accuracy\
    \ of solar irradiance forecasting, such as very short time scales\n(including\
    \ one sec or one min period), cloud conditions, and intensity of solar radiation\n\
    towards the Earth. It is critical to focus on types of cloud classiﬁcation and\
    \ forecasts to\nachieve effective solar irradiation forecasting. However, existing\
    \ researchers often do not\nconsider cloud conditions when developing their models,\
    \ which eventually leads to poor\nforecast accuracy [60–62].\n2.2. Weather Classiﬁcation\n\
    Solar radiation is known as the key feature used in the determination of PV power\n\
    potential. Various meteorological input features inﬂuence the availability of\
    \ solar irradiance,\nsuch as cloud types, temperature, relative humidity, wind\
    \ speed, pressure, and aerosol\nindex. Based on this fact, weather changes can\
    \ be considered as the main factor that\ninﬂuences solar irradiance forecasting\
    \ models in terms of accuracy. This result demonstrates\nthat weather classiﬁcation\
    \ is critical for forecasting algorithm performance and durability.\nAccording\
    \ to multiple studies, weather classiﬁcation is the main factor involved at the\n\
    short-term solar irradiance forecasting pre-processing stage [63–65]. The lack\
    \ of data\navailable for model training is considered to be a major roadblock\
    \ in weather classiﬁcation.\nA study reported using 33 weather types that were\
    \ classiﬁed into 10 weather classiﬁcations\nby combining several types of weather\
    \ into a single type [66]. This limitation can be\naddressed by classifying weather\
    \ into three or four types [67,68]. Accordingly, ref. [34] fed\nsurface weather\
    \ and irradiance data into K-means clustering to analyze variations in cloud\n\
    conditions. In addition, regime-dependent ANN models were utilized for solar irradiance\n\
    forecasting and demonstrated better accuracy. Following that study, gew researchers\n\
    Appl. Sci. 2023, 13, 8332\n7 of 43\nhave concentrated on using Self-Organizing\
    \ Maps (SOM) to classify meteorological input\nfeatures into different categories\
    \ for forecasting models [61,69]. However, before that study,\nref. [66] presented\
    \ four major weather categories based on solar irradiation features for\neach\
    \ weather type [66]. In addition, ref. [70] predicted solar irradiance in northeastern\n\
    Brazil based on an Artiﬁcial Neural Network (ANN). The data were divided into\
    \ two\nclimates—dry and rainy—and the clustering method was used to identify the\
    \ homogenous\nclimatic zones present.\nThe comparisons between the GAN-based approach\
    \ and the other ﬁve established\nforecasting models were presented in [33]. The\
    \ study adopted 10 weather classes as the\ninput data, and a confusion matrix\
    \ was utilized for objectivity [71]. The literature makes\nseveral comparisons\
    \ between weather categorization and photovoltaic power forecasting\n(PVPF) models,\
    \ making it difﬁcult for PVPF researchers to select the best option. This statis-\n\
    tical tool analyses the effectiveness of classiﬁer algorithms using a table layout\
    \ to determine\nhow frequently a classiﬁer becomes confused and mislabels two\
    \ weather classes that are\nclose together. These classiﬁers include CNN with\
    \ a 1-D convolution layer (CNN1D), CNN\nwith a 2-D convolution layer (CNN2D),\
    \ multilayer perceptron (MLP), and SVM with a\nk-nearest neighbor (KNN). The ﬁndings\
    \ showed better accuracy in weather classiﬁcation\nand data augmentation, as well\
    \ as improved data imbalance weather categories using\nGAN, especially for short-term\
    \ sample size. The authors suggested GAN-CNN2D for PVPF\nmodeling, although CNN2D\
    \ achieved the highest scores due to its ability to eliminate\nnon-linear input–output\
    \ correlations. Correspondingly, the previous literature emphasized\nthe importance\
    \ of using weather categorization to ensure the effectiveness and accuracy of\n\
    solar irradiance forecasting models, as weather conditions should always be prioritized\
    \ for\nforecasting [52,72,73].\n2.3. Model Performance Metrics\nThe performance\
    \ evaluation metrics are useful throughout the model development\nprocess because\
    \ it is impossible to analyze how effectively deep learning models would\nperform\
    \ without the use of metrics for comparison [6]. However, performance can be\n\
    affected by many factors, such as the forecasting horizon, model parameters, and\
    \ site-\nspeciﬁc meteorological circumstances. Speciﬁcally, the overall performance\
    \ is assessed\nbased on a comparison between actual and forecasted solar irradiance.\
    \ The metrics used\nwill provide feedback in terms of forecasting accuracy, allowing\
    \ models to be ﬁne-tuned\nto achieve a target degree of precision; a lower score\
    \ indicates more precise forecasting.\nCommonly used statistical evolution metrics\
    \ for evaluation purposes include the following:\n•\nMean Absolute Error (MAE):\
    \ this metric demonstrates the mean of the absolute errors\namong the actual GHI\
    \ values and the anticipated values, and it provides equal weight\ndistribution\
    \ to all data inconsistencies, which can be shown in Equation (1) [74]:\nMAE=\
    \ 1\nN∑\nn\ni=1|Gai − Gpi|\n(1)\nwhere Gai and Gpi denote the actual and predicted\
    \ GHI values, respectively, while the\ntotal number of data points is represented\
    \ by n.\n•\nMean bias error (MBE): This metric evaluates the established mean\
    \ bias of the fore-\ncasting model. The MBE adjusts the deviation by subtracting\
    \ the positive from the\nnegative, as shown in Equation (2). It is considered\
    \ an unreliable method for perfor-\nmance evaluation; however, it does provide\
    \ an adequate indication of whether a model\nis over- or under-estimated [74].\n\
    MBE= 1\nN∑\nN\ni=1(Gpi − Gai)\n(2)\nAppl. Sci. 2023, 13, 8332\n8 of 43\n•\nMean\
    \ square error (MSE): This metric is the mean calculation of square differences\n\
    between the actual and forecasted solar irradiance levels, as shown in Equation\
    \ (3).\nTherefore, larger disparities occur [75].\nMSE =\n1\nN∑\nn\ni (Gp i− Gai)2\n\
    (3)\n•\nRoot mean square error (RMSE): This metric is the calculation of the square\
    \ root of\nthe average squared variances between actual and forecasted solar irradiance\
    \ values.\nRMSE is recognized as being one of the most trusted ways to measure\
    \ performance\nbecause it helps to identify and eliminate data outliers. The metric\
    \ is expressed via\nEquation (4) [76]:\nR =\ns\n1\nN\nn\n∑\ni\n(Gp i− Gai)2\n\
    (4)\n•\nMean absolute percentage error (MAPE): this metric is the relative average\
    \ value\nbetween MAPE and MAE, which is obtained by dividing the differences between\n\
    each actual and forecasted observed value by the actual observed value, as shown\
    \ in\nEquation (5) [77].\nMAPE = 1\nN ∑\nN\ni=1 / Gpi − Gai\nGai\n/\n(5)\n•\n\
    Normalized RMSE (nRMSE): in general, nRMSE is used to identify overall deviance\
    \ in\nlarger datasets, as shown in Equation (6) [77].\nnRMSE=\nq\n1\nN ∑n\ni (Gp\
    \ i− Gai)2\nGai\n(6)\n•\nCorrelation coefﬁcient (R): this metric measures the\
    \ linear correlation between actual\nand forecasted solar irradiance [78], and\
    \ it is calculated as shown in Equation:\nR=\n∑n\ni (Ga i − Gai\n\x01(Gp i − Gpi\n\
    \x01\nq\n∑n\ni (Ga i − Gai\n\x01\n∑n\ni (Gp i− Gpi\n\x012\n(7)\nGpi and Gai represent\
    \ the average of forecasted and actual GHI, respectively.\n•\nForecast skill score\
    \ (FS): the FS score compares the performance of the forecasting model\nand the\
    \ benchmark or persistence model, as shown in Equation (8):\nFS= 1 −\nRMSEmodel\n\
    RMSEsimple model\n(8)\nIn terms of accuracy, an optimal forecast model will achieve\
    \ an FS score of 1, whereas\na model that exhibits the same forecast error as\
    \ the benchmark model has a value of 0. The\nFS score will produce negative results\
    \ with a larger forecast error [79].\nThe forecast skill score is represented\
    \ by FS, while RMSEmodel and RMSEsimple model\nrepresent the RMSE values of the\
    \ recommended forecasting model and benchmark or\npersistence model, respectively.\n\
    2.4. Optimization of Input Feattures\nThe forecasting can be improved using the\
    \ appropriate input selection, both in terms\nof quantity and type. The presence\
    \ of large parameters can signiﬁcantly imbalance the\nforecasting, whereas redundant\
    \ or weakly correlated inputs will further complicate the\nAppl. Sci. 2023, 13,\
    \ 8332\n9 of 43\ncomputation. Hence, optimization techniques are critical to the\
    \ selection of suitable in-\nput features.\nMany input optimization strategies\
    \ for PV output models are described in the litera-\nture, including PSO [80],\
    \ grid-search [81], fruit ﬂy optimization algorithm (FOA) [82], ﬁreﬂy\n(FF) [8],\
    \ ant colony optimization (ACO) [83], chaotic ant swarm optimization (CAS) [84],\n\
    chaotic artiﬁcial bee colony algorithm [85], and immune algorithm (IA) [86]. While\
    \ each\nalgorithm has beneﬁts and drawbacks, the most prominent and efﬁcient technique\
    \ for\nimproving weights and inputs during forecasting is genetic algorithm (GA)-based\
    \ opti-\nmization. Moreover, it is practical for pairing with ANN. Tao and Chen\
    \ [87] improved the\nforecast accuracy of the back propagation neural network\
    \ (BPNN) model by altering the in-\nput weights. Similarly, ref. [88] claimed\
    \ that GA optimization improved their ANN for the\nPV power forecasting model.\
    \ According to [89], PSO is a method of iterative optimization\nthat is comparable\
    \ to GA. The PSO method starts with a collection of random solutions\nand discovers\
    \ the best values iteratively. Compared to GA, it has more convergence and\ndoes\
    \ not require the modiﬁcation of as many features [90,91]. PSO is used as an alterna-\n\
    tive for GA in applications such as function optimization, feature selection and\
    \ neural\nnetwork training, fuzzy system control, and others; however, it tends\
    \ to be dismissed in\nlocal extrema.\n3. The Architecture of Deep Learning Algorithms\n\
    We discuss the architecture of prominent deep learning models for solar irradiance\n\
    forecasting, which include Artiﬁcial Neural Networks (ANN), Gated Recurrent Units\n\
    (GRU), Recurrent Neural Networks (RNN), Deep Belief Networks (DBN), Convolutional\n\
    Neural Networks (CNN), and Long Short-Term Memory (LSTM), as well as the hybrid\n\
    models that were discussed in the literature. In this section, detailed information\
    \ on the\narchitecture and training techniques of related models is provided.\n\
    3.1. Artiﬁcial Neural Network (ANN)\nThe structure of the neural network is modeled\
    \ on the human brain, and it has made\nsigniﬁcant contributions to the evolution\
    \ of machine learning technologies. It is considered\na simple mathematical model\
    \ that can be used to address a variety of non-linear issues.\nPrevious researchers\
    \ reviewed ANN models in forecasting solar energy, such as Ref. [46]\nfor solar\
    \ radiation forecasting, Ref. [92] for PV applications, and Ref. [93] for solar\
    \ energy\nforecasting. They concluded that the ANN model can offer higher accuracy\
    \ for solar\nirradiation forecasting than other conventional models. Figure 3\
    \ shows the neural network\narchitecture that consists of a multi-layer perceptron\
    \ [94]. This multi-layer perceptron\nhas aspects known as the input, hidden, and\
    \ output layers. There are also auxiliary\ncomponents that are labeled as neurons,\
    \ weight, bias, and activation functions. These\nlayers communicate with each\
    \ other such that the input layer receives input values, which\nare then analyzed\
    \ via the hidden layer. Next, the output layer gathers data from the hidden\n\
    layer and decides how to use it. The training process of the neural network is\
    \ iterative, and\nit modiﬁes the structure during the learning process to achieve\
    \ the exact reference or set\npoint as the supervisor [95]. The network’s multiple\
    \ hidden layers allow it to forecast exact\nfeature extraction and the non-linear\
    \ structure of a model [96]. The ﬁndings of the ANN\nmodel are compared to those\
    \ of the ARMA model (Auto Regressive Moving Average) and\ndemonstrate how an ANN\
    \ model can estimate global solar irradiation.\nEquation (9) is a basic mathematical\
    \ function for ANN:\nAn = ∑\nn\ni=1 (wi ∗ Ii) + b\n(9)\nwhere wi represents the\
    \ weight, Ii represents the input, An represents the result, b represents\nthe\
    \ bias, and n represents the number of inputs.\nAppl. Sci. 2023, 13, 8332\n10\
    \ of 43\nAppl. Sci. 2023, 13, x FOR PEER REVIEW \n10 of 43 \n \n \nFigure 3. The\
    \ architecture of a neural network [94]. \nEquation (9) is a basic mathematical\
    \ function for ANN: \nAn=∑\n(\U0001D464\U0001D456 ∗ \U0001D43C\U0001D456)\nn\n\
    i=1\n + b \n(9) \nwhere \U0001D464\U0001D456 represents the weight, \U0001D43C\
    \U0001D456 represents the input, \U0001D434\U0001D45B represents the result, b\
    \ rep-\nresents the bias, and n represents the number of inputs.  \nThe activation\
    \ function is a mathematical equation that governs how neurons pro-\nduce information,\
    \ and it is interchangeably known as the transfer function. Hypotheti-\ncally,\
    \ it can influence the output value. The activation function types are linear\
    \ and non-\nlinear. For both input and output layers, a linear activation function\
    \ produces the exact \nlinear results. However, such a linear connection is insufficient\
    \ for actual implementa-\ntions, since problems involving complex information\
    \ and several elements, which include \nimage, video text, and sound, require\
    \ more processing. The limits of the linear activation \nfunctions can be circumvented\
    \ using a neural network with a non-linear activation func-\ntion. Table 1 lists\
    \ the most used activation functions of neural networks. The leaky ReLU \nand\
    \ Rectified Linear Unit (ReLU) are non-linear activation functions, since their\
    \ slope is \nnot constant for all values. Positive values have a slope of 1, whereas\
    \ negative values have \na slope of 0 [94]. \nTable 1. The activation function\
    \ of the neural network [94]. \nActivation Function \nEquation \nPlot \nLinear\
    \ \nf(x) = x \n \nRelu \nf(x) = max (0, x) \n \nLeaky Relu \nf(x) = max(0.1⋯x,\
    \ x) \n \nFigure 3. The architecture of a neural network [94].\nThe activation\
    \ function is a mathematical equation that governs how neurons produce\ninformation,\
    \ and it is interchangeably known as the transfer function. Hypothetically, it\n\
    can inﬂuence the output value. The activation function types are linear and non-linear.\n\
    For both input and output layers, a linear activation function produces the exact\
    \ linear\nresults. However, such a linear connection is insufﬁcient for actual\
    \ implementations, since\nproblems involving complex information and several elements,\
    \ which include image, video\ntext, and sound, require more processing. The limits\
    \ of the linear activation functions can\nbe circumvented using a neural network\
    \ with a non-linear activation function. Table 1\nlists the most used activation\
    \ functions of neural networks. The leaky ReLU and Rectiﬁed\nLinear Unit (ReLU)\
    \ are non-linear activation functions, since their slope is not constant for\n\
    all values. Positive values have a slope of 1, whereas negative values have a\
    \ slope of 0 [94].\nTable 1. The activation function of the neural network [94].\n\
    Activation Function\nEquation\nPlot\nLinear\nf(x) = x\n \nFigure 3. The architecture\
    \ of a neural network [94]. \nEquation (9) is a basic mathematical function for\
    \ ANN: \nAn=∑\n(\U0001D464\U0001D456 ∗ \U0001D43C\U0001D456)\nn\ni=1\n + b \n\
    (9) \nwhere \U0001D464\U0001D456 represents the weight, \U0001D43C\U0001D456 represents\
    \ the input, \U0001D434\U0001D45B represents the result, b rep-\nresents the bias,\
    \ and n represents the number of inputs.  \nThe activation function is a mathematical\
    \ equation that governs how neurons pro-\nduce information, and it is interchangeably\
    \ known as the transfer function. Hypotheti-\ncally, it can influence the output\
    \ value. The activation function types are linear and non-\nlinear. For both input\
    \ and output layers, a linear activation function produces the exact \nlinear\
    \ results. However, such a linear connection is insufficient for actual implementa-\n\
    tions, since problems involving complex information and several elements, which\
    \ include \nimage, video text, and sound, require more processing. The limits\
    \ of the linear activation \nfunctions can be circumvented using a neural network\
    \ with a non-linear activation func-\ntion. Table 1 lists the most used activation\
    \ functions of neural networks. The leaky ReLU \nand Rectified Linear Unit (ReLU)\
    \ are non-linear activation functions, since their slope is \nnot constant for\
    \ all values. Positive values have a slope of 1, whereas negative values have\
    \ \na slope of 0 [94]. \nTable 1. The activation function of the neural network\
    \ [94]. \nActivation Function \nEquation \nPlot \nLinear \nf(x) = x \n \nRelu\
    \ \nf(x) = max (0, x) \n \nLeaky Relu \nf(x) = max(0.1⋯x, x) \n \nRelu\nf(x) =\
    \ max (0, x)\n \nFigure 3. The architecture of a neural network [94]. \nEquation\
    \ (9) is a basic mathematical function for ANN: \nAn=∑\n(\U0001D464\U0001D456\
    \ ∗ \U0001D43C\U0001D456)\nn\ni=1\n + b \n(9) \nwhere \U0001D464\U0001D456 represents\
    \ the weight, \U0001D43C\U0001D456 represents the input, \U0001D434\U0001D45B\
    \ represents the result, b rep-\nresents the bias, and n represents the number\
    \ of inputs.  \nThe activation function is a mathematical equation that governs\
    \ how neurons pro-\nduce information, and it is interchangeably known as the transfer\
    \ function. Hypotheti-\ncally, it can influence the output value. The activation\
    \ function types are linear and non-\nlinear. For both input and output layers,\
    \ a linear activation function produces the exact \nlinear results. However, such\
    \ a linear connection is insufficient for actual implementa-\ntions, since problems\
    \ involving complex information and several elements, which include \nimage, video\
    \ text, and sound, require more processing. The limits of the linear activation\
    \ \nfunctions can be circumvented using a neural network with a non-linear activation\
    \ func-\ntion. Table 1 lists the most used activation functions of neural networks.\
    \ The leaky ReLU \nand Rectified Linear Unit (ReLU) are non-linear activation\
    \ functions, since their slope is \nnot constant for all values. Positive values\
    \ have a slope of 1, whereas negative values have \na slope of 0 [94]. \nTable\
    \ 1. The activation function of the neural network [94]. \nActivation Function\
    \ \nEquation \nPlot \nLinear \nf(x) = x \n \nRelu \nf(x) = max (0, x) \n \nLeaky\
    \ Relu \nf(x) = max(0.1⋯x, x) \n \nLeaky Relu\nf(x) = max(0.1· · · x, x)\n \n\
    Figure 3. The architecture of a neural network [94]. \nEquation (9) is a basic\
    \ mathematical function for ANN: \nAn=∑\n(\U0001D464\U0001D456 ∗ \U0001D43C\U0001D456\
    )\nn\ni=1\n + b \n(9) \nwhere \U0001D464\U0001D456 represents the weight, \U0001D43C\
    \U0001D456 represents the input, \U0001D434\U0001D45B represents the result, b\
    \ rep-\nresents the bias, and n represents the number of inputs.  \nThe activation\
    \ function is a mathematical equation that governs how neurons pro-\nduce information,\
    \ and it is interchangeably known as the transfer function. Hypotheti-\ncally,\
    \ it can influence the output value. The activation function types are linear\
    \ and non-\nlinear. For both input and output layers, a linear activation function\
    \ produces the exact \nlinear results. However, such a linear connection is insufficient\
    \ for actual implementa-\ntions, since problems involving complex information\
    \ and several elements, which include \nimage, video text, and sound, require\
    \ more processing. The limits of the linear activation \nfunctions can be circumvented\
    \ using a neural network with a non-linear activation func-\ntion. Table 1 lists\
    \ the most used activation functions of neural networks. The leaky ReLU \nand\
    \ Rectified Linear Unit (ReLU) are non-linear activation functions, since their\
    \ slope is \nnot constant for all values. Positive values have a slope of 1, whereas\
    \ negative values have \na slope of 0 [94]. \nTable 1. The activation function\
    \ of the neural network [94]. \nActivation Function \nEquation \nPlot \nLinear\
    \ \nf(x) = x \n \nRelu \nf(x) = max (0, x) \n \nLeaky Relu \nf(x) = max(0.1⋯x,\
    \ x) \n \nTanh\nf(x) = tanh(x)\nAppl. Sci. 2023, 13, x FOR PEER REVIEW \n11 of\
    \ 43 \n \nTanh \nf(x) = tanh(x) \n \nSigmoid \nf(x) = \n1\n1 +\U0001D452−\U0001D465\
    \ \n \n3.2. Convolutional Neural Network (CNN) \nAppl. Sci. 2023, 13, 8332\n11\
    \ of 43\nTable 1. Cont.\nActivation Function\nEquation\nPlot\nSigmoid\nf(x) =\n\
    1\n1+e−x\nAppl. Sci. 2023, 13, x FOR PEER REVIEW \n11 of 43 \n \nTanh \nf(x) =\
    \ tanh(x) \n \nSigmoid \nf(x) = \n1\n1 +\U0001D452−\U0001D465 \n \n3.2. Convolutional\
    \ Neural Network (CNN) \nCNN is considered to be robust for various applications,\
    \ since it can learn high-level \nfeatures from sequences without any human intervention\
    \ [97]. The CNN algorithm is \nwidely utilized in deep learning. The most notable\
    \ advantage of CNN is its remarkable \nability to capture non-linear information.\
    \ CNN comprises three layers: the convolutional, \npooling, and fully connected\
    \ layers [98,99]. The most significant component of CNN is the \nconvolution layer,\
    \ which consists of many convolution kernels used to construct new fea-\nture\
    \ maps. Figure 4 depicts the architecture of CNN, which consists of convolutional,\
    \ \npooling, and fully linked layers [49]. The following tasks are assigned to\
    \ each layer: The \nconvolution layer is involved in local feature extraction,\
    \ which is effective when the kernel \nweights are equally distributed across\
    \ all input maps. The convolutional layers are uti-\nlized to extract spatial\
    \ patterns from the underlying training sample and its related input \nvariables.\
    \ The mathematical formula for the convolutional layer is expressed via Equation\
    \ \n(10).  \n\U0001D466\U0001D458 \U0001D456\U0001D458 = f ((\U0001D464\U0001D458\
    \ * h) \U0001D456\U0001D457 + \U0001D44F\U0001D458) \n(10) \nwhere f represents\
    \ an activation function, * represents a convolutional process operator, \nand\
    \ \U0001D464\U0001D458 represents the weight of the kernel. \n \nFigure 4. The\
    \ architecture of CNN [49]. \nA pooling layer is commonly utilized to minimize\
    \ the in-plane dimensionality of in-\nput maps, hence minimizing the number of\
    \ learnable parameters and preventing overfit-\nting. Typically, pooling layers\
    \ can be divided into two types: maximal pooling and aver-\nage pooling. Both\
    \ types are used in the procedures outlined, as shown in Equation (11): \n\U0001D453\
    \ (\U0001D465) = max (0, \U0001D465) \n(11) \nThe fully connected layer is utilized\
    \ extensively for high-level inference, since it is \nresponsible for transferring\
    \ the features filtered by the convolutional and pooling layers \nto the output\
    \ layer. Next, linear activation and non-linear activation functions are em-\n\
    ployed for both layers. Finally, a full connection layer is added to the CNN structure\
    \ to \n3.2. Convolutional Neural Network (CNN)\nCNN is considered to be robust\
    \ for various applications, since it can learn high-level\nfeatures from sequences\
    \ without any human intervention [97]. The CNN algorithm is\nwidely utilized in\
    \ deep learning. The most notable advantage of CNN is its remarkable\nability\
    \ to capture non-linear information. CNN comprises three layers: the convolutional,\n\
    pooling, and fully connected layers [98,99]. The most signiﬁcant component of\
    \ CNN is\nthe convolution layer, which consists of many convolution kernels used\
    \ to construct new\nfeature maps. Figure 4 depicts the architecture of CNN, which\
    \ consists of convolutional,\npooling, and fully linked layers [49]. The following\
    \ tasks are assigned to each layer:\nThe convolution layer is involved in local\
    \ feature extraction, which is effective when the\nkernel weights are equally\
    \ distributed across all input maps. The convolutional layers\nare utilized to\
    \ extract spatial patterns from the underlying training sample and its related\n\
    input variables. The mathematical formula for the convolutional layer is expressed\
    \ via\nEquation (10).\nyk ik = f ((wk∗ h)ij+bk)\n(10)\nwhere f represents an activation\
    \ function, * represents a convolutional process operator,\nand wk represents\
    \ the weight of the kernel.\nAppl. Sci. 2023, 13, x FOR PEER REVIEW \n11 of 43\
    \ \n \nTanh \nf(x) = tanh(x) \n \nSigmoid \nf(x) = \n1\n1 +\U0001D452−\U0001D465\
    \ \n \n3.2. Convolutional Neural Network (CNN) \nCNN is considered to be robust\
    \ for various applications, since it can learn high-level \nfeatures from sequences\
    \ without any human intervention [97]. The CNN algorithm is \nwidely utilized\
    \ in deep learning. The most notable advantage of CNN is its remarkable \nability\
    \ to capture non-linear information. CNN comprises three layers: the convolutional,\
    \ \npooling, and fully connected layers [98,99]. The most significant component\
    \ of CNN is the \nconvolution layer, which consists of many convolution kernels\
    \ used to construct new fea-\nture maps. Figure 4 depicts the architecture of\
    \ CNN, which consists of convolutional, \npooling, and fully linked layers [49].\
    \ The following tasks are assigned to each layer: The \nconvolution layer is involved\
    \ in local feature extraction, which is effective when the kernel \nweights are\
    \ equally distributed across all input maps. The convolutional layers are uti-\n\
    lized to extract spatial patterns from the underlying training sample and its\
    \ related input \nvariables. The mathematical formula for the convolutional layer\
    \ is expressed via Equation \n(10).  \n\U0001D466\U0001D458 \U0001D456\U0001D458\
    \ = f ((\U0001D464\U0001D458 * h) \U0001D456\U0001D457 + \U0001D44F\U0001D458\
    ) \n(10) \nwhere f represents an activation function, * represents a convolutional\
    \ process operator, \nand \U0001D464\U0001D458 represents the weight of the kernel.\
    \ \n \nFigure 4. The architecture of CNN [49]. \nA pooling layer is commonly utilized\
    \ to minimize the in-plane dimensionality of in-\nput maps, hence minimizing the\
    \ number of learnable parameters and preventing overfit-\nting. Typically, pooling\
    \ layers can be divided into two types: maximal pooling and aver-\nage pooling.\
    \ Both types are used in the procedures outlined, as shown in Equation (11): \n\
    \U0001D453 (\U0001D465) = max (0, \U0001D465) \n(11) \nThe fully connected layer\
    \ is utilized extensively for high-level inference, since it is \nresponsible\
    \ for transferring the features filtered by the convolutional and pooling layers\
    \ \nto the output layer. Next, linear activation and non-linear activation functions\
    \ are em-\nployed for both layers. Finally, a full connection layer is added to\
    \ the CNN structure to \nFigure 4. The architecture of CNN [49].\nA pooling layer\
    \ is commonly utilized to minimize the in-plane dimensionality of input\nmaps,\
    \ hence minimizing the number of learnable parameters and preventing overﬁtting.\n\
    Typically, pooling layers can be divided into two types: maximal pooling and average\n\
    pooling. Both types are used in the procedures outlined, as shown in Equation\
    \ (11):\nf (x) = max (0, x)\n(11)\nThe fully connected layer is utilized extensively\
    \ for high-level inference, since it is\nresponsible for transferring the features\
    \ ﬁltered by the convolutional and pooling layers to\nthe output layer. Next,\
    \ linear activation and non-linear activation functions are employed\nfor both\
    \ layers. Finally, a full connection layer is added to the CNN structure to forecast\
    \ the\noutput using the extracted features [100]. CNN is commonly used in the\
    \ development of\ndata pattern-based ﬁlters and the extraction of hidden features.\
    \ More importantly, the key\nAppl. Sci. 2023, 13, 8332\n12 of 43\ncharacteristics\
    \ of Convolutional Neural Networks include local connections and weight\nsharing\
    \ [101,102].\n3.3. Recurrent Neural Network (RNN)\nRNN lies under the classiﬁcation\
    \ of Artiﬁcial Neural Network and functions substan-\ntially effectively for training\
    \ sequential or time-series data. Time-series data consist of\nintrinsic temporal\
    \ information that a Simple Neural Network cannot capture [103]. RNN\ndecomposes\
    \ sequence data into components and maintains a state to represent the data at\n\
    different time intervals [104]. Figure 5 highlights the structure of RNN, which\
    \ is composed\nof inputs, hidden neurons, and an activation function.\n \nforecast\
    \ the output using the extracted features [100]. CNN is commonly used in the de-\n\
    velopment of data pattern-based filters and the extraction of hidden features.\
    \ More im-\nportantly, the key characteristics of Convolutional Neural Networks\
    \ include local connec-\ntions and weight sharing [101,102].  \n3.3. Recurrent\
    \ Neural Network (RNN) \nRNN lies under the classification of Artificial Neural\
    \ Network and functions substan-\ntially effectively for training sequential or\
    \ time-series data. Time-series data consist of in-\ntrinsic temporal information\
    \ that a Simple Neural Network cannot capture [103]. RNN \ndecomposes sequence\
    \ data into components and maintains a state to represent the data at \ndifferent\
    \ time intervals [104]. Figure 5 highlights the structure of RNN, which is composed\
    \ \nof inputs, hidden neurons, and an activation function. \nThe previously hidden\
    \ layer (ℎ\U0001D461) is presented as shown in Equation (12): \nℎ\U0001D461 =\
    \ tanh(U·\U0001D465\U0001D461 + W·ℎ\U0001D461 −1) \n(12) \n \nFigure 5. The architecture\
    \ of RNN [94]. \nwhere \U0001D465\U0001D461 denotes the input at time t, ℎ\U0001D461\
    \ denotes the hidden neuron at time t, U de-\nnotes the weight of the hidden layer\
    \ at time t, and W denotes the transition weights of the \nhidden layer. The input\
    \ and prior hidden states are merged, as the current and past inputs \nflow uses\
    \ the tanh function to provide information. The output is a new hidden state that\
    \ \nfunctions as a Neural Network Memory by storing knowledge from past efforts.\
    \ \nDuring the training phase, RNN is frequently troubled with gradient vanishing\
    \ and \ngradient explosion difficulties. Once backpropagation has been closed\
    \ at a specific point, \nthe gradient explosion problem can be solved. However,\
    \ the outcome is suboptimal, since \nnot all the weights are updated. The initialization\
    \ of weights can help to modify the van-\nishing gradient to decrease its chances\
    \ of affecting the model. Moreover, there is another \nsolution to the problem,\
    \ which uses the LTSM and will be explained in the next section. \n3.4. Long Short-Term\
    \ Memory (LSTM) \nThe LSTM network is considered to be an extended and improved\
    \ structure of RNN \nthat can effectively solve its time-series forecasting issues\
    \ and inability to deal with long-\nterm data dependencies because of vanishing\
    \ gradient and gradient explosion issues \n[105]. Therefore, LSTMs are frequently\
    \ utilized in power systems for time-series forecast-\ning, including load forecasting,\
    \ demand response, and renewable power generation fore-\ncasting [106]. The LTSM\
    \ network concept was introduced by [43] to resolve the limitation \nof a vanishing\
    \ gradient. This approach can be seen in Figure 6, where the LTSM network \nconsists\
    \ of inputs, outputs, memory cells, and forget gates that work together to regulate\
    \ \ninformation flow. The forget gate separates information into two categories:\
    \ data that \nshould be deleted and data that should be retained. The input gate\
    \ is responsible for up-\ndating the cells, whereas the output gate determines\
    \ their next concealed state. The gates \nuse the sigmoid function as their activation\
    \ function, and they will generate a value be-\ntween 0 and 1 to selectively enable\
    \ information to pass through them. The gates can be \nused to indicate how much\
    \ data from the current input is allowed to pass through the \nstructure. As previously\
    \ stated, the whole structure serves as a gate; when it is open, all \nFigure\
    \ 5. The architecture of RNN [94].\nThe previously hidden layer (ht) is presented\
    \ as shown in Equation (12):\nht= tan h (U·xt+W·ht − 1)\n(12)\nwhere xt denotes\
    \ the input at time t, ht denotes the hidden neuron at time t, U denotes the\n\
    weight of the hidden layer at time t, and W denotes the transition weights of\
    \ the hidden\nlayer. The input and prior hidden states are merged, as the current\
    \ and past inputs ﬂow\nuses the tanh function to provide information. The output\
    \ is a new hidden state that\nfunctions as a Neural Network Memory by storing\
    \ knowledge from past efforts.\nDuring the training phase, RNN is frequently troubled\
    \ with gradient vanishing and\ngradient explosion difﬁculties. Once backpropagation\
    \ has been closed at a speciﬁc point, the\ngradient explosion problem can be solved.\
    \ However, the outcome is suboptimal, since not\nall the weights are updated.\
    \ The initialization of weights can help to modify the vanishing\ngradient to\
    \ decrease its chances of affecting the model. Moreover, there is another solution\n\
    to the problem, which uses the LTSM and will be explained in the next section.\n\
    3.4. Long Short-Term Memory (LSTM)\nThe LSTM network is considered to be an extended\
    \ and improved structure of RNN\nthat can effectively solve its time-series forecasting\
    \ issues and inability to deal with long-\nterm data dependencies because of vanishing\
    \ gradient and gradient explosion issues [105].\nTherefore, LSTMs are frequently\
    \ utilized in power systems for time-series forecasting,\nincluding load forecasting,\
    \ demand response, and renewable power generation forecast-\ning [106]. The LTSM\
    \ network concept was introduced by [43] to resolve the limitation of\na vanishing\
    \ gradient. This approach can be seen in Figure 6, where the LTSM network\nconsists\
    \ of inputs, outputs, memory cells, and forget gates that work together to regulate\
    \ in-\nformation ﬂow. The forget gate separates information into two categories:\
    \ data that should\nbe deleted and data that should be retained. The input gate\
    \ is responsible for updating\nthe cells, whereas the output gate determines their\
    \ next concealed state. The gates use the\nsigmoid function as their activation\
    \ function, and they will generate a value between 0\nand 1 to selectively enable\
    \ information to pass through them. The gates can be used to\nindicate how much\
    \ data from the current input is allowed to pass through the structure.\nAs previously\
    \ stated, the whole structure serves as a gate; when it is open, all information\n\
    is permitted to pass through it (sigmoid output is one). On the other hand, when\
    \ the\nAppl. Sci. 2023, 13, 8332\n13 of 43\ngate is closed (having a sigmoid output\
    \ of zero), no information can pass through it. The\nmathematical description\
    \ and information distribution are described in Equation (13):\n•\nThe forget\
    \ gate, ft, helps the LSTM to determine which information should be elimi-\nnated\
    \ from the cell state by applying a sigmoid function to the output of the prior\
    \ ht−1\nand input data xt:\nft= (w f .ht−1, w f .xt+ bf )\n(13)\nwhere (.) signiﬁes\
    \ the sigmoid activation function, wt signiﬁes the weight matrix, ht−1\nsigniﬁes\
    \ the prior state, xt signiﬁes the memory cell of the input vector at time t,\
    \ and bf\nsigniﬁes the bias vector.\nAppl. Sci. 2023, 13, x FOR PEER REVIEW \n\
    13 of 43 \n \ninformation is permitted to pass through it (sigmoid output is one).\
    \ On the other hand, \nwhen the gate is closed (having a sigmoid output of zero),\
    \ no information can pass \nthrough it. The mathematical description and information\
    \ distribution are described in \nEquation (13): \n• \nThe forget gate, \U0001D453\
    \U0001D461, helps the LSTM to determine which information should be elim-\ninated\
    \ from the cell state by applying a sigmoid function to the output of the prior\
    \ \nℎ\U0001D461−1 and input data \U0001D465\U0001D461: \n\U0001D453\U0001D461\
    \ = (\U0001D464\U0001D453. ℎ\U0001D461−1, \U0001D464\U0001D453. \U0001D465\U0001D461\
    \ +\U0001D44F\U0001D453) \n(13) \nwhere (.) signifies the sigmoid activation function,\
    \ \U0001D464\U0001D461 signifies the weight matrix, \nℎ\U0001D461−1 signifies\
    \ the prior state, \U0001D465\U0001D461 signifies the memory cell of the input\
    \ vector at time \nt, and \U0001D44F\U0001D453 signifies the bias vector.  \n\
    \ \nFigure 6. The architecture of the LSTM network [107]. \nThe input gate, \U0001D456\
    \U0001D461, determines which data are stored in the new candidate cell state \n\
    \U0001D436̃\n\U0001D461. The hyperbolic tangent function is symbolized as tanh\
    \ () in Equation (14). \nC̃t = tanh (wc. ht−1, wc. xt+ bc) \n(14) \n\U0001D43C\
    \U0001D461 = (\U0001D464\U0001D456. ℎ\U0001D461−1, \U0001D464\U0001D456. \U0001D465\
    \U0001D461 +\U0001D44F\U0001D456) \n(15) \nThe input gate applies the sigmoid\
    \ function, (\U0001D70E), to determine which values to write, \nand it updates\
    \ the gate using the tanh activation function to generate new cell values. \n\
    The new candidate’s cell state \U0001D436̃\n\U0001D461 and the prior cell state\
    \ \U0001D436\U0001D461−1 are incorporated to \nupdate the latest cell state, \U0001D436\
    \U0001D461, which is expressed as shown in Equation (16): \n\U0001D436\U0001D461\
    \ = \U0001D43C\U0001D461 ∗ \U0001D436 \U0001D461 + \U0001D453\U0001D461 ∗ \U0001D436\
    \U0001D461−1 \n(16) \nFinally, the output gate regulates the output of a cell\
    \ and merges it with a cell state \nthat is activated via the tanh function to\
    \ determine the final output, h\U0001D461, which is expressed \nin the Equations\
    \ (17) and (18):  \n\U0001D442\U0001D461 = \U0001D70E ( \U0001D464\U0001D45C.\
    \ ℎ\U0001D461−1, \U0001D464\U0001D45C. \U0001D465\U0001D461 +\U0001D44F\U0001D45C\
    ) \n(17) \nℎ\U0001D461 = tanh (\U0001D436\U0001D461). \U0001D442\U0001D461 \n\
    (18) \n3.5. Gated Recurrent Unit (GRU) \nFigure 6. The architecture of the LSTM\
    \ network [107].\nThe input gate, it, determines which data are stored in the\
    \ new candidate cell state\n∼\nCt.\nThe hyperbolic tangent function is symbolized\
    \ as tanh () in Equation (14).\n∼\nCt= tan h (wc.ht−1, wc.xt+bc)\n(14)\nIt= (wi.ht−1,\
    \ wi.xt+bi)\n(15)\nThe input gate applies the sigmoid function, (σ), to determine\
    \ which values to write,\nand it updates the gate using the tanh activation function\
    \ to generate new cell values.\nThe new candidate’s cell state\n∼\nCt and the\
    \ prior cell state Ct−1 are incorporated to\nupdate the latest cell state, Ct,\
    \ which is expressed as shown in Equation (16):\nCt= It ∗\n∼\nCt+ ft ∗ Ct−1\n\
    (16)\nFinally, the output gate regulates the output of a cell and merges it with\
    \ a cell state\nthat is activated via the tanh function to determine the ﬁnal\
    \ output, ht, which is expressed\nin the Equations (17) and (18):\nOt = σ (wo.ht−1,\
    \ wo.xt+bo)\n(17)\nht= tan h (Ct ). Ot\n(18)\nAppl. Sci. 2023, 13, 8332\n14 of\
    \ 43\n3.5. Gated Recurrent Unit (GRU)\nThe GRU is considered to be a less sophisticated\
    \ RNN [108] than LSTM, which can\nbe more simply applied and computed. GRU and\
    \ LSTM are equivalent in terms of their\ncapacity to recall and capture long-term\
    \ dependencies. The computational time is faster\nand the complexity is lower\
    \ in GRU compared to LSTM, since there are fewer features [67].\nMoreover, GRU\
    \ can effectively learn long-term dependencies data, which resolves the\nissue\
    \ of vanishing gradient that arises when using simple RNN. Furthermore, GRU is\n\
    deemed as a variant of LSTM due to the similarities between its function mechanism\
    \ and\ndesign. This observation can be seen when both GRU and LSTM use the gate\
    \ mechanism to\ncontrol the ﬂow of information by combining the input and forget\
    \ gates into a single update\ngate. However, unlike LSTM, GRU has only two gates,\
    \ which are the update gate (zt)\nand the reset gate (rt). These two gates determine\
    \ what information from the past should\nbe preserved for the future and what\
    \ past information should be deleted, respectively.\nFurthermore, GRU models suffer\
    \ from delayed convergence and low learning efﬁciency,\nresulting in extensive\
    \ training and even under-ﬁtting. Figure 7 depicts the structure of GRU,\nand\
    \ the relationship between its inpute and outpute is presented in Equations (19)–(21):\n\
    Rt= σ (Ur·ht−1+br+Wr·Xt)\n(19)\nzt= σ (bz+Wz·Xt+Uz·ht−1)\n(20)\nAt= tan h (Wh·Xt+Uh·bh+(rt\
    \ ∗ ht−1))\n(21)\nht= (1 − Zt) ∗ ht−1+Zt ∗ At\n(22)\nAppl. Sci. 2023, 13, x FOR\
    \ PEER REVIEW \n14 of 43 \n \nThe GRU is considered to be a less sophisticated\
    \ RNN [108] than LSTM, which can \nbe more simply applied and computed. GRU and\
    \ LSTM are equivalent in terms of their \ncapacity to recall and capture long-term\
    \ dependencies. The computational time is faster \nand the complexity is lower\
    \ in GRU compared to LSTM, since there are fewer features \n[67]. Moreover, GRU\
    \ can effectively learn long-term dependencies data, which resolves \nthe issue\
    \ of vanishing gradient that arises when using simple RNN. Furthermore, GRU is\
    \ \ndeemed as a variant of LSTM due to the similarities between its function mechanism\
    \ and \ndesign. This observation can be seen when both GRU and LSTM use the gate\
    \ mechanism \nto control the flow of information by combining the input and forget\
    \ gates into a single \nupdate gate. However, unlike LSTM, GRU has only two gates,\
    \ which are the update gate \n(\U0001D467\U0001D461) and the reset gate (\U0001D45F\
    \U0001D461). These two gates determine what information from the past \nshould\
    \ be preserved for the future and what past information should be deleted, respec-\n\
    tively. Furthermore, GRU models suffer from delayed convergence and low learning\
    \ effi-\nciency, resulting in extensive training and even under-fitting. Figure\
    \ 7 depicts the struc-\nture of GRU, and the relationship between its inpute and\
    \ outpute is presented in Equa-\ntions (19)–(21): \n\U0001D445\U0001D461 = σ (\U0001D448\
    \U0001D45F·ℎ\U0001D461−1 + \U0001D44F\U0001D45F + \U0001D44A\U0001D45F·\U0001D44B\
    \U0001D461) \n(19) \n\U0001D467\U0001D461 = σ(\U0001D44F\U0001D467 + \U0001D44A\
    \U0001D467·\U0001D44B\U0001D461 + \U0001D448\U0001D467·ℎ\U0001D461−1) \n(20) \n\
    \U0001D434\U0001D461 = tanh (\U0001D44Aℎ·\U0001D44B\U0001D461 +\U0001D448ℎ·\U0001D44F\
    ℎ + (\U0001D45F\U0001D461 ∗ ℎ\U0001D461 −1)) \n(21) \nℎ\U0001D461= (1−\U0001D44D\
    \U0001D461) ∗ ℎ\U0001D461−1 +\U0001D44D\U0001D461 ∗ \U0001D434\U0001D461 \n(22)\
    \ \n \nFigure 7. The architecture of the GRU network [94]. \nAt the current time\
    \ step (t), the reset gate is denoted as \U0001D445\U0001D461, the update gate\
    \ is denoted \nas \U0001D467\U0001D461, the memory component is denoted as \U0001D434\
    \U0001D461, the activation function is denoted as tanh, \nand the final memory\
    \ is denoted as ℎ\U0001D461. \n3.6. Bidirectional RNN (BRNN) \nIn general, Normal\
    \ Recurrent Neural Networks (RNN) are limited in terms of their \ninput data flexibility,\
    \ since future input data are omitted from the current state. Ref. [109] \ndeveloped\
    \ the Bidirectional Recurrent Neural Network (BRNN) to address the limitations\
    \ \nof RNNs. BRNNs can be trained using data from both the past and the future\
    \ at any given \ntime step, since they can receive input from both directions.\
    \ Figure 8 illustrates the basic \nstructure of the BRNN. The mathematical expression\
    \ is presented in Equations (23)–(25) \n[110]: \nℎ⃗ \U0001D461 = \U0001D453(\U0001D44A\
    \U0001D465,ℎ⃗⃗ \U0001D44B\U0001D461 + \U0001D44Aℎ⃗⃗ ,ℎ⃗⃗ ℎ⃗ \U0001D461−1 + \U0001D44F\
    ℎ⃗⃗ ) \n(23) \nℎ⃖⃗\U0001D461 = \U0001D453(\U0001D44A\U0001D465,ℎ⃖⃗⃗\U0001D44B\U0001D461\
    \ + \U0001D44Aℎ⃖⃗⃗,ℎ⃖⃗⃗ℎ⃖⃗\U0001D461−1 + \U0001D44Fℎ⃖⃗⃗) \n(24) \nFigure 7. The\
    \ architecture of the GRU network [94].\nAt the current time step (t), the reset\
    \ gate is denoted as Rt, the update gate is denoted\nas zt, the memory component\
    \ is denoted as At, the activation function is denoted as tanh,\nand the ﬁnal\
    \ memory is denoted as ht.\n3.6. Bidirectional RNN (BRNN)\nIn general, Normal\
    \ Recurrent Neural Networks (RNN) are limited in terms of their\ninput data ﬂexibility,\
    \ since future input data are omitted from the current state. Ref. [109]\ndeveloped\
    \ the Bidirectional Recurrent Neural Network (BRNN) to address the limitations\
    \ of\nRNNs. BRNNs can be trained using data from both the past and the future\
    \ at any given time\nstep, since they can receive input from both directions.\
    \ Figure 8 illustrates the basic structure\nof the BRNN. The mathematical expression\
    \ is presented in Equations (23)–(25) [110]:\n→\nh t = f\n\x12\nW\nx,\n→\nh Xt\
    \ + W→\nh ,\n→\nh\n→\nh t−1 + b→\nh\n\x11\n(23)\nAppl. Sci. 2023, 13, 8332\n15\
    \ of 43\n←\nh t = f\n\x12\nW\nx,\n←\nh Xt + W←\nh ,\n←\nh\n←\nh t−1 + b←\nh\n\x11\
    \n(24)\nyt = g\n\x12\nw→\nh ,y\n→\nh t + W←\nh ,y\n←\nh t + by\n\x13\n(25)\nAppl.\
    \ Sci. 2023, 13, x FOR PEER REVIEW \n15 of 43 \n \n \U0001D466\U0001D461 = \U0001D454\
    (\U0001D464ℎ⃗⃗ ,\U0001D466 ℎ⃗ \U0001D461 + \U0001D44Aℎ⃖⃗⃗,\U0001D466ℎ⃖⃗\U0001D461\
    \ + \U0001D44F\U0001D466) \n(25) \nThe input vector at time step t is signified\
    \ by \U0001D465\U0001D461, the forward hidden layer activation \nvector at time\
    \ t is signified by ℎ⃗ , the backward hidden layer activation vector at time t\
    \ is \nsignified by ℎ⃖⃗, the weight matrix is signified by w, the bias is signified\
    \ by b, and the output \nprobability is signified by \U0001D466\U0001D461. The\
    \ probability of the output at time t is signified by \U0001D466\U0001D461. The\
    \ \nactivation function of each node in the hidden layer is signified by f, while\
    \ the SoftMax \nfunction is signified by g. \n \nFigure 8. The architecture of\
    \ BRNN [110]. \n3.7. Bi-LSTM Network \nThe LSTM was modified into the Bi-LSTM,\
    \ which was presented by [109], to enhance \nforecasting accuracy by combining\
    \ forward and backward information from the input se-\nquence. The forward hidden\
    \ sequence was calculated first, and the reverse hidden se-\nquence was then merged\
    \ to find the result. The architecture of Bi-LSTM was enhanced by \nintegrating\
    \ the best features of BRNN and LSTM to improve the accuracy of the state. \n\
    Furthermore, double processing was beneficial for learning complex temporal correlations.\
    \ \n3.8. Deep Belief Network (DBN) \nGeoffrey Hinton invented a Deep Belief Network\
    \ (DBN) in 2006, and it has since been \nemployed in a variety of applications\
    \ [111]. DBN represents probabilistic generative \ngraphical models that are developed\
    \ using probability and unsupervised learning. They \nsolve various typical neural\
    \ network problems, such as slow convergence and learning \nrate for local minima\
    \ due to insufficient input selection. It is also a deep learning network \nthat\
    \ is built based on the stacking mechanisms of multiple Restricted Boltzmann Machines\
    \ \n(RBM). Figure 9 illustrates that each of the stacked RBMs are made up of two\
    \ layers: (1) \nthe visible layer (\U0001D463) and (2) the hidden layer (hi).\
    \ The hidden layer of each RBM acts as the \nvisible layer for the next RBM in\
    \ the DBN network. The structural diagram of DBN con-\nsists of bidirectional\
    \ and symmetrical layer connections. A greedy learning algorithm is \napplied\
    \ to train the DBN model; this technique involves repetitive training of one layer\
    \ at \na time until reaching a global optimum, which then serves as an input for\
    \ the RBM. The \napplication of the greedy algorithm is advantageous to the DBN\
    \ network because it assists \nin weight distribution at each layer and supports\
    \ proper network initialization, hence \neliminating the issue of local minima\
    \ t vanishing, as well as speeding up and optimizing \nthe training process [112].\
    \ However, DBN has an expensive computational rate, since it \nrequires the training\
    \ of multiple RBMs [113]. \nFigure 8. The architecture of BRNN [110].\nThe input\
    \ vector at time step t is signiﬁed by xt, the forward hidden layer activation\n\
    vector at time t is signiﬁed by\n→\nh , the backward hidden layer activation vector\
    \ at time t is\nsigniﬁed by\n←\nh , the weight matrix is signiﬁed by w, the bias\
    \ is signiﬁed by b, and the output\nprobability is signiﬁed by yt. The probability\
    \ of the output at time t is signiﬁed by yt. The\nactivation function of each\
    \ node in the hidden layer is signiﬁed by f, while the SoftMax\nfunction is signiﬁed\
    \ by g.\n3.7. Bi-LSTM Network\nThe LSTM was modiﬁed into the Bi-LSTM, which was\
    \ presented by [109], to enhance\nforecasting accuracy by combining forward and\
    \ backward information from the input\nsequence. The forward hidden sequence was\
    \ calculated ﬁrst, and the reverse hidden\nsequence was then merged to ﬁnd the\
    \ result. The architecture of Bi-LSTM was enhanced\nby integrating the best features\
    \ of BRNN and LSTM to improve the accuracy of the state.\nFurthermore, double\
    \ processing was beneﬁcial for learning complex temporal correlations.\n3.8. Deep\
    \ Belief Network (DBN)\nGeoffrey Hinton invented a Deep Belief Network (DBN) in\
    \ 2006, and it has since\nbeen employed in a variety of applications [111]. DBN\
    \ represents probabilistic generative\ngraphical models that are developed using\
    \ probability and unsupervised learning. They\nsolve various typical neural network\
    \ problems, such as slow convergence and learning rate\nfor local minima due to\
    \ insufﬁcient input selection. It is also a deep learning network that is\nbuilt\
    \ based on the stacking mechanisms of multiple Restricted Boltzmann Machines (RBM).\n\
    Figure 9 illustrates that each of the stacked RBMs are made up of two layers:\
    \ (1) the visible\nlayer (ν) and (2) the hidden layer (hi). The hidden layer of\
    \ each RBM acts as the visible\nlayer for the next RBM in the DBN network. The\
    \ structural diagram of DBN consists of\nbidirectional and symmetrical layer connections.\
    \ A greedy learning algorithm is applied to\ntrain the DBN model; this technique\
    \ involves repetitive training of one layer at a time until\nreaching a global\
    \ optimum, which then serves as an input for the RBM. The application\nof the\
    \ greedy algorithm is advantageous to the DBN network because it assists in weight\n\
    distribution at each layer and supports proper network initialization, hence eliminating\n\
    Appl. Sci. 2023, 13, 8332\n16 of 43\nthe issue of local minima t vanishing, as\
    \ well as speeding up and optimizing the training\nprocess [112]. However, DBN\
    \ has an expensive computational rate, since it requires the\ntraining of multiple\
    \ RBMs [113].\nAppl. Sci. 2023, 13, x FOR PEER REVIEW \n16 of 43 \n \n \nFigure\
    \ 9. The architecture of DBN [114]. \n3.9. Attention Mechanism \nThe Attention\
    \ Mechanism is an encoder–decoder technique designed specifically for \nneural\
    \ machine translation. This technology was developed to facilitate the translation\
    \ of \nneural information into machine information using an encoder and a decoder.\
    \ The input \nis transformed through the encoder into a fixed-length vector and\
    \ then translated via the \ndecoder [115]. In 2014, ref. [116] developed the first\
    \ Attention Mechanism, which was \nmodeled on the human visual Attention Mechanism.\
    \ The Attention Mechanism acts sim-\nilarly to the brain in terms of prioritizing\
    \ specific elements and is beneficial for many do-\nmains, including image analysis\
    \ [117], video analysis [118], machine translation [119], and \nothers. Moreover,\
    \ it is effective for time-series forecasting, and its diversified range of ap-\n\
    plications has been acknowledged by academics. \nThe Attention Mechanism might\
    \ prioritize more significant input features while \noverlooking other features.\
    \ This approach influences the way in which we pay attention \nto information\
    \ from the outside world in a wise and sensible way, ignoring irrelevant in-\n\
    formation and emphasizing relevant information. Hence, the application of the\
    \ Attention \nMechanism allows us to process information more rapidly and accurately.\
    \ The mathemat-\nical description and information distribution are expressed as\
    \ shown in Equations (26) \nand (27): \n\U0001D452\U0001D456 = tanh (\U0001D464\
    ℎ ℎ\U0001D456 +\U0001D44F\U0001D45B ℎ\U0001D45B), \U0001D452\U0001D456 ∈ [−1,\
    \ 1] \n(26) \n\U0001D44E\U0001D456=\n\U0001D452\U0001D465\U0001D45D (\U0001D452\
    \U0001D456)\n∑\n\U0001D452\U0001D465\U0001D45D (\U0001D452\U0001D456)\n\U0001D461\
    \n\U0001D456=1\n, ∑\n\U0001D44E\U0001D456\n\U0001D461\n\U0001D456=1\n= 1 \n(27)\
    \ \nFigure 9. The architecture of DBN [114].\n3.9. Attention Mechanism\nThe Attention\
    \ Mechanism is an encoder–decoder technique designed speciﬁcally for\nneural machine\
    \ translation. This technology was developed to facilitate the translation\nof\
    \ neural information into machine information using an encoder and a decoder.\
    \ The\ninput is transformed through the encoder into a ﬁxed-length vector and\
    \ then translated\nvia the decoder [115]. In 2014, ref. [116] developed the ﬁrst\
    \ Attention Mechanism, which\nwas modeled on the human visual Attention Mechanism.\
    \ The Attention Mechanism acts\nsimilarly to the brain in terms of prioritizing\
    \ speciﬁc elements and is beneﬁcial for many\ndomains, including image analysis\
    \ [117], video analysis [118], machine translation [119],\nand others. Moreover,\
    \ it is effective for time-series forecasting, and its diversiﬁed range of\napplications\
    \ has been acknowledged by academics.\nThe Attention Mechanism might prioritize\
    \ more signiﬁcant input features while over-\nlooking other features. This approach\
    \ inﬂuences the way in which we pay attention to infor-\nmation from the outside\
    \ world in a wise and sensible way, ignoring irrelevant information\nand emphasizing\
    \ relevant information. Hence, the application of the Attention Mechanism\nallows\
    \ us to process information more rapidly and accurately. The mathematical description\n\
    and information distribution are expressed as shown in Equations (26) and (27):\n\
    ei= tan h (wh hi+bnhn), ei ∈ [−1, 1]\n(26)\nAppl. Sci. 2023, 13, 8332\n17 of 43\n\
    ai=\nexp(e i)\n∑t\ni=1 exp(e i), ∑\nt\ni=1 ai = 1\n(27)\nSelf-attention picks\
    \ up both long- and short-term dependencies and focuses on various\naspects of\
    \ temporal patterns. It is an excellent candidate for time-series forecasting\
    \ because\nof these beneﬁts. It is utilized to personalize an attention layer,\
    \ the parameters of which are\nspeciﬁed via an optimization method [119].\nThe\
    \ Self-Attention Mechanism comprises a key matrix (K), a value matrix (V), and\
    \ a\nquery matrix (Q), as shown in Equation (28):\nT = K = V = Q\n(28)\nThe basic\
    \ principle in the self-attention process is the scaled dot-product of atten-\n\
    tion (SDA). Two stages are involved in the process of determining similarity,\
    \ which are\n(1) ﬁnding the dot product between Q and matching matrix K and (2)\
    \ dividing it by the\nmatrix K dimension. To acquire the attention expression,\
    \ we utilized the SoftMax function\nto normalize the output before multiplying\
    \ it by the matrix V. Equation (29) shows how\nSDA operates.\nSDA(K, V, Q) = SoftMax(\
    \ QKT\n√dk\n) v\n(29)\n3.10. Generative Adversarial Networks (GAN)\nThe GAN, which\
    \ was invented by the authors of [120], and its versions, including con-\nvolutional\
    \ GAN (Conv-GAN), which was developed by the authors of [121], demonstrate\nsigniﬁcant\
    \ potential in producing pictures that are incredibly similar to a given collection\
    \ of\ntraining images. GANs are a robust category of generative models that perform\
    \ their tasks\nby implicitly modeling high-dimensional data distributions [122].\
    \ In image processing,\nGAN has shown superiority relative to other generating\
    \ approaches in terms of its capacity\nto create realistic synthetic pictures\
    \ [121,123,124]. In terms of applicability to our study,\nGAN can be utilized\
    \ to understand the distribution of meteorological data and augment\nit. This\
    \ work has the possibility of supplementing training specimens with a wide range\n\
    of samples to increase the generalization of deep learning algorithms. The training\
    \ tech-\nnique in GAN involves building two antagonistic networks that compete\
    \ with each other,\nincluding the two main neural networks, which are typically\
    \ the generator (G) and the\ndiscriminator (D), that may be trained using a traditional\
    \ backpropagation approach.\nThe two networks collaborate to enhance each other,\
    \ albeit in an aggressive manner.\nDuring the training phase, G attempts to learn\
    \ and make “fake” specimens of input noise\nZ to trick D, while D endeavors to\
    \ identify “fake” or “genuine” inputs accurately. The\nmodel converges until the\
    \ discriminator no longer distinguishes between the specimens.\nIt is worth noting\
    \ that the input noise Z typically keeps track of a Gaussian distribution\nacross\
    \ G to provide the sample I = G (z), where Z = N (µ, σ2), and D is a fundamental\
    \ neural\nnetwork ﬁlter for bilateral categorization. This process provides an\
    \ excellent opportunity\nto supplement training specimens with a broad range of\
    \ data to increase the generalization\nof deep learning algorithms.\n4. Solar\
    \ Irradiance Forecasting Based on Deep Learning Techniques\nIn general, this section\
    \ elaborates the prerequisite for the effective implementation of\nsolar energy\
    \ systems, which is forecasting horizons. Therefore, it is important to focus\
    \ on\nthis fact to further achieve accurate solar irradiance forecasting.\n4.1.\
    \ Solar Irradiance Forecasting Model Based on the LSTM Algorithm\nThe application\
    \ of the LSTM algorithm in recent research into the development of solar\nirradiance\
    \ forecasting models is justiﬁed according to its ability to address time series-based\n\
    forecasting problems. Subsequently, the LSTM model was utilized by [65] to forecast\
    \ solar\nAppl. Sci. 2023, 13, 8332\n18 of 43\nirradiation 1 h in advance at three\
    \ location sites in the USA, which were located in Hawaii,\nAtlanta, and New York.\
    \ The input features that were used to generate the model were\ntemperature, relative\
    \ humidity, sun zenith angle, cloud type, perceptible water, dew point,\nwind\
    \ direction, and clear sky index. According to their analysis, the suggested LSTM\
    \ model\nexhibits an RMSE for the sites under consideration in the range of 45.84\
    \ and 41.37 W/m2.\nIn Seoul, South Korea, ref. [125] utilized LSTM to estimate\
    \ hourly, daily, and annual\nsolar irradiation. They used the Korea Meteorological\
    \ Administration (KMA) database\nto obtain solar data from 2001 to 2017. The model\
    \ data training was performed using the\nprevious solar irradiance dataset. Following\
    \ that approach, ref. [43] utilized an LSTM model\nfor hourly solar irradiation\
    \ forecasting of the following day. Input features considered\nincluded the month,\
    \ hour, and days of the month; wind speed; relative humidity; visibility;\ndew\
    \ point; weather conditions; and temperature. To validate the model, the dataset\
    \ from\nthe Measurement and Instrumentation Data Center (MIDC) was used. Table\
    \ 2 shows that\nthe proposed model performs better in terms of accuracy than other\
    \ established models\nwith an RMSE value of 76.245 W/m2. Figure 10 emphasizes\
    \ the comparison between real\nand LSTM forecasted solar irradiance.\nTable 2.\
    \ Comparison results for the proposed models using the MIDC dataset [43].\nAlgorithm\n\
    Testing RMSE\nPersistence\n209.2509\nLR\n230.9867\nBPNN\n133.5313\nLSTM\n76.245\n\
    Appl. Sci. 2023, 13, x FOR PEER REVIEW \n18 of 43 \n \nlocated in Hawaii, Atlanta,\
    \ and New York. The input features that were used to generate \nthe model were\
    \ temperature, relative humidity, sun zenith angle, cloud type, perceptible \n\
    water, dew point, wind direction, and clear sky index. According to their analysis,\
    \ the \nsuggested LSTM model exhibits an RMSE for the sites under consideration\
    \ in the range \nof 45.84 and 41.37 W/m2. \nIn Seoul, South Korea, ref. [125]\
    \ utilized LSTM to estimate hourly, daily, and annual \nsolar irradiation. They\
    \ used the Korea Meteorological Administration (KMA) database to \nobtain solar\
    \ data from 2001 to 2017. The model data training was performed using the \nprevious\
    \ solar irradiance dataset. Following that approach, ref. [43] utilized an LSTM\
    \ \nmodel for hourly solar irradiation forecasting of the following day. Input\
    \ features consid-\nered included the month, hour, and days of the month; wind\
    \ speed; relative humidity; \nvisibility; dew point; weather conditions; and temperature.\
    \ To validate the model, the da-\ntaset from the Measurement and Instrumentation\
    \ Data Center (MIDC) was used. Table 2 \nshows that the proposed model performs\
    \ better in terms of accuracy than other estab-\nlished models with an RMSE value\
    \ of 76.245 W/m2. Figure 10 emphasizes the comparison \nbetween real and LSTM\
    \ forecasted solar irradiance. \nTable 2. Comparison results for the proposed\
    \ models using the MIDC dataset [43]. \nAlgorithm \nTesting RMSE \nPersistence\
    \ \n209.2509 \nLR \n230.9867 \nBPNN \n133.5313 \nLSTM \n76.245 \n \nFigure 10.\
    \ The comparison between actual irradiance and forecasted irradiance [43]. \n\
    Recently, ref. [126] built a deep LSTM network for solar irradiance forecasting\
    \ based \non various horizons (3/6/24 h ahead) in the dry regions of India. Among\
    \ the feature inputs \nconsidered were dew point, diffuse horizontal irradiance\
    \ (DHI), global horizontal irradi-\nance (GHI), direct normal irradiance (DNI),\
    \ wind speed, pressure, temperature, wind di-\nrection, and relative humidity.\
    \ A five-year dataset (2010–2014) from the NSRB in the Thar \nDesert was used\
    \ to validate the model. The generated model had MAPE values ranging \nfrom 6.79\
    \ to 10.47%, which indicate excellent performance. Ref. [107] utilized satellite\
    \ data \nto estimate solar irradiance 1 day in advance using an LSTM model. The\
    \ model was tested \nFigure 10. The comparison between actual irradiance and forecasted\
    \ irradiance [43].\nRecently, ref. [126] built a deep LSTM network for solar irradiance\
    \ forecasting based\non various horizons (3/6/24 h ahead) in the dry regions of\
    \ India. Among the feature\ninputs considered were dew point, diffuse horizontal\
    \ irradiance (DHI), global horizontal\nirradiance (GHI), direct normal irradiance\
    \ (DNI), wind speed, pressure, temperature, wind\ndirection, and relative humidity.\
    \ A ﬁve-year dataset (2010–2014) from the NSRB in the Thar\nDesert was used to\
    \ validate the model. The generated model had MAPE values ranging\nfrom 6.79 to\
    \ 10.47%, which indicate excellent performance. Ref. [107] utilized satellite\
    \ data\nto estimate solar irradiance 1 day in advance using an LSTM model. The\
    \ model was tested\nAppl. Sci. 2023, 13, 8332\n19 of 43\nusing data from 21 remote\
    \ sensing sites, 16 of which were in mainland Europe, while 5 were\nin the United\
    \ States. The input features considered were maximum temperature, minimum\ntemperature,\
    \ air pressure, cloud cover, speciﬁc humidity, and other meteorological data.\n\
    According to the empirical results, the generated LSTM outperformed other persistent\n\
    models tested with a forecast skill score of 52.2%.\nRecent work by [127] used\
    \ LSTM for hourly solar irradiance forecasting for 1 day in\nadvance. The input\
    \ features considered were temperature, wind speed, sky cover, humidity,\nand\
    \ precipitation. The dataset for training was retrieved from the Korea Meteorological\n\
    Administration, which consists of weather variations recorded at different targeted\
    \ site\nlocations. It was shown that the model used can generate substantial forecasting\
    \ with\nan RMSE of 30 W/m2. Ref. [128] forecasted solar irradiance 1 h in advance\
    \ using GRU\nand LSTM. They used a mono-variate technique, which forecasts solar\
    \ irradiance using\nhistorical time series. Their proposed GRU and LSTM models\
    \ were superior to other\nconventional machine learning models for solar irradiation\
    \ forecasting. Another study\nby [129] forecasted hourly solar radiation utilizing\
    \ a deep LSTM network. They trained and\ntested the proposed model using data\
    \ from a Canadian solar farm. Figure 11 depicts the\nforecast results for a variety\
    \ of weather conditions, including cloudy sky, scattered clouds,\nclear sky, and\
    \ few clouds, using the suggested model. In addition, it outperformed the SVR\n\
    and FFNN.\nAppl. Sci. 2023, 13, x FOR PEER REVIEW \n19 of 43 \n \nusing data from\
    \ 21 remote sensing sites, 16 of which were in mainland Europe, while 5 \nwere\
    \ in the United States. The input features considered were maximum temperature,\
    \ \nminimum temperature, air pressure, cloud cover, specific humidity, and other\
    \ meteoro-\nlogical data. According to the empirical results, the generated LSTM\
    \ outperformed other \npersistent models tested with a forecast skill score of\
    \ 52.2%. \nRecent work by [127] used LSTM for hourly solar irradiance forecasting\
    \ for 1 day in \nadvance. The input features considered were temperature, wind\
    \ speed, sky cover, humid-\nity, and precipitation. The dataset for training was\
    \ retrieved from the Korea Meteorologi-\ncal Administration, which consists of\
    \ weather variations recorded at different targeted site \nlocations. It was shown\
    \ that the model used can generate substantial forecasting with an \nRMSE of 30\
    \ W/m2. Ref. [128] forecasted solar irradiance 1 h in advance using GRU and \n\
    LSTM. They used a mono-variate technique, which forecasts solar irradiance using\
    \ histor-\nical time series. Their proposed GRU and LSTM models were superior\
    \ to other conven-\ntional machine learning models for solar irradiation forecasting.\
    \ Another study by [129] \nforecasted hourly solar radiation utilizing a deep\
    \ LSTM network. They trained and tested \nthe proposed model using data from a\
    \ Canadian solar farm. Figure 11 depicts the forecast \nresults for a variety\
    \ of weather conditions, including cloudy sky, scattered clouds, clear \nsky,\
    \ and few clouds, using the suggested model. In addition, it outperformed the\
    \ SVR and \nFFNN. \n \nFigure 11. (a) Solar irradiation forecasting in various\
    \ weather situations. (b) Daily solar irradiation \nforecasting [130]. \nThe LTSM\
    \ model was employed by [131] for hourly solar irradiance forecasting in \nJohannesburg,\
    \ South Africa. The LSTM network was trained based on solar radiation, \nsunlight\
    \ duration, relative humidity, and temperature. The dataset available from the\
    \ Na-\ntional Oceanic and Atmospheric Administration (NOAA) consists of a ten-year\
    \ duration \nof weather data from 2009–2019. Simulation findings demonstrated\
    \ that the proposed \nLSTM network performed satisfactorily compared to the SVR\
    \ model with an nRMSE of \n3.2%. Subsequently, ref. [132] suggested the implementation\
    \ of two methods based on \nLSTM for novel solar irradiance forecasting model\
    \ on an image-based dataset. In this \nstudy, different input features were assigned\
    \ to achieve variations of 5 to 60 min in ad-\nvance of solar irradiance forecasting.\
    \ The first method focused on input features, such as \nsolar irradiance 5 min\
    \ before, current solar irradiance, and center value. In contrast, the \nsecond\
    \ method focused on solar irradiance 5 min earlier, most recent solar irradiance,\
    \ \ncenter value, variance value, the red–blue comparison method, and the three-step\
    \ search \nmethod. Findings indicated that the LSTM model trained using the second\
    \ method \nshowed superior forecasting.  \nFigure 11. (a) Solar irradiation forecasting\
    \ in various weather situations. (b) Daily solar irradiation\nforecasting [130].\n\
    The LTSM model was employed by [131] for hourly solar irradiance forecasting in\n\
    Johannesburg, South Africa. The LSTM network was trained based on solar radiation,\n\
    sunlight duration, relative humidity, and temperature. The dataset available from\
    \ the\nNational Oceanic and Atmospheric Administration (NOAA) consists of a ten-year\
    \ duration\nof weather data from 2009–2019. Simulation ﬁndings demonstrated that\
    \ the proposed\nLSTM network performed satisfactorily compared to the SVR model\
    \ with an nRMSE\nof 3.2%. Subsequently, ref. [132] suggested the implementation\
    \ of two methods based\non LSTM for novel solar irradiance forecasting model on\
    \ an image-based dataset. In\nthis study, different input features were assigned\
    \ to achieve variations of 5 to 60 min in\nadvance of solar irradiance forecasting.\
    \ The ﬁrst method focused on input features, such\nas solar irradiance 5 min before,\
    \ current solar irradiance, and center value. In contrast,\nthe second method\
    \ focused on solar irradiance 5 min earlier, most recent solar irradiance,\ncenter\
    \ value, variance value, the red–blue comparison method, and the three-step search\n\
    method. Findings indicated that the LSTM model trained using the second method\
    \ showed\nsuperior forecasting.\nBefore that study, ref. [133] employed LTSM for\
    \ hourly solar irradiation forecasting us-\ning historical and meteorological\
    \ data from Kharagpur, India. Further, they intended to use\nAppl. Sci. 2023,\
    \ 13, 8332\n20 of 43\nthese data for solar PV power output forecasting. For validation\
    \ purposes, the forecasting\nmodels used 15-year data available from 2000–2014\
    \ provided by NSRDB. The suggested\nmodel demonstrated superior performance compared\
    \ to the ANN model, achieving an\nRMSE value of 57.249 W/m2. Subsequently, ref.\
    \ [134] utilized the LSTM network to forecast\nhourly GHI in Islamabad, Pakistan.\
    \ The data were provided by the meteorological station\nat NUST Islamabad over\
    \ 55 months from 2015–2020. The model training was performed\non historical GHI\
    \ data while considering all meteorological feature inputs, such as relative\n\
    humidity, wind speed and direction, ambient temperature, DNI, and DHI.\nA recent\
    \ study by [135] utilized a new variant of LSTM known as stacked LTSM\nintegrated\
    \ with principal component analysis (PCA) for solar irradiance forecasting on\n\
    a 6-month dataset retrieved from a weather station at Morong, the Philippines.\
    \ Among\nthe input features considered were humidity, station height, wind speed,\
    \ station temper-\nature, absolute pressure, illuminance, sea level pressure,\
    \ and ambient temperature. The\nproposed stacked LSTM model was compared to CNN,\
    \ Bidirectional-LSTM, and other\ndeep learning models and managed to achieve a\
    \ performance of R2 value 0.953 and MAE\nvalue 41.738 W/m2. Previous work by [136]\
    \ used a deep learning-based univariate LSTM\nmodel to conduct short-term solar\
    \ irradiance forecasting. The model was trained using\ndata on solar radiation\
    \ collected over two years, starting on 1 January 2014, and originating\nfrom\
    \ a solar monitoring station based at the University of Jaffna’s Faculty of Engineering.\n\
    The outcomes showed that the suggested model outperformed the ARIMA model.\nRef.\
    \ [137] utilized an LSTM for solar irradiance forecasting based on the range of\n\
    forecasting horizons (intra-hour and intra-day). The dataset used to validate\
    \ the model was\nretrieved from SURFRAD, which consists of data from seven stations\
    \ located across the\nUnited States. The suggested approach outperformed typical\
    \ machine learning models by\n71.5%. For short-term forecasting, ref. [138] utilized\
    \ the LSTM Neural Network model for\nsolar irradiation forecasting. The experiments\
    \ were conducted at half-hourly and hourly\ndata intervals, as well as during\
    \ all four seasons. The model accuracy can be seen to\nvary from season to season\
    \ in Table 3. The suggested model demonstrates that the lowest\ninaccuracy happened\
    \ in the winter for the half-hourly forecast horizon, since Florida has\nsubstantially\
    \ more rain from May to October, resulting in less predictable PV generation.\n\
    Regardless, the model frequently showed a gradual increase in inaccuracy for hourly\
    \ solar\nirradiance forecasting.\nTable 3. Performance of Single Step Ahead of\
    \ PV Power Forecasting [138].\nSeason\nHourly Data\nHalf Hourly Data\nMAE\nRMSE\n\
    MBE\nMAE\nRMSE\nMBE\nSpring\n0.75\n1.51\n0.02\n0.69\n1.43\n−0.02\nSummer\n0.98\n\
    2.04\n0.31\n0.87\n1.84\n−0.05\nAutumn\n0.70\n1.48\n0.39\n0.55\n1.27\n0.21\nWinter\n\
    0.61\n1.39\n−0.24\n0.50\n1.23\n−0.07\n4.2. Solar Irradiance Forecasting Model\
    \ Based on CNN\nRef. [139] used a 3D-CNN model to forecast direct normal irradiance\
    \ 10 min ahead of\ntime. The proposed approach derived spatial and temporal features\
    \ from cloud character-\nistics by integrating multiple consecutive ground-based\
    \ cloud pictures. They developed\nthe forecasting algorithm using GBC pictures\
    \ and DNI data from a two-year period (2013\nto 2014) obtained from NREL, and\
    \ the model was able to achieve a forecasting accuracy\nof 17.06%. Ref. [33] presented\
    \ a CNN-based forecasting method based on weather classiﬁ-\ncation, as well as\
    \ Generative Adversarial Networks (GAN). Initially, 33 different types of\nweather\
    \ were integrated and classiﬁed into 10 new weather categories for data training.\
    \ A\ndata augmentation model using GAN was then applied to improve each weather\
    \ category.\nSubsequently, the extended dataset that consisted of both original\
    \ and generated solar\nirradiance data were used for CNN model training. The authors\
    \ also used a weather\nAppl. Sci. 2023, 13, 8332\n21 of 43\nclassiﬁer to evaluate\
    \ solar brightness and investigated how GAN can increase forecast\naccuracy. Based\
    \ on their observation, GAN could generate high-quality samples that\nprecisely\
    \ matched the unique features of the original data, as opposed to memorization\n\
    of the training data. Next, ref. [140] developed a Solar Net using 20 layers of\
    \ deep CNN\nto calculate the intra-hour global horizontal irradiance (GHI) (i.e.,\
    \ 10-min to one hour\nahead with a 10-min pause). Solar Net used a single total\
    \ sky image (TSI) with no feature\nengineering or numerical measurements as its\
    \ input. According to numerical studies based\non six years of public data, Solar\
    \ Net produced multi-step forecasts, resulting in an nRMSE\nof 8.85% and an accuracy\
    \ forecasting score of 25.14%, which were greater than those of\nother compared\
    \ models.\n4.3. Solar Irradiance Forecasting Model Based on GRU\nRef. [141] employed\
    \ LSTM and GRU up to an hour ahead of solar irradiance fore-\ncasting. Both univariate\
    \ and multivariate forecasting models were developed to utilize\nexogenous meteorological\
    \ factors and historical solar irradiance data. These solar data were\nbased on\
    \ an international airport in Phoenix, Arizona, USA (1 January 2004–31 December\n\
    2014). The ﬁndings showed that multivariate LSTM and GRU are more accurate than\n\
    their univariate equivalents. Further, ref. [142] suggested a short-term forecasting\
    \ horizons\nsolar irradiance forecasting model integrated with GRU and Attention\
    \ Mechanism, such\nas 5/10/20/30 min, for use in four climates in the Nevada desert,\
    \ USA. The dataset used\nwas obtained by the University of Nevada, Las Vegas,\
    \ USA, from the year 2014 onwards,\nand it consists of peak wind speed and averaged\
    \ historical solar irradiation data. A hybrid\ndeep learning model presented by\
    \ [143] was based on encoder–decoder networks of LSTM,\nBidirectional LSTM, RNN,\
    \ and GRU models for short-term solar irradiance forecasting.\nThe model training\
    \ was performed on NREL’s ﬁfteen-year dataset for Kharagpur, India,\nwhich spanned\
    \ the years 2000 to 2014. A 10-kilo meter grid of meteorological and solar\nirradiance\
    \ data were gathered. In addition, the suggested model was evaluated against\n\
    other previously used machine learning models, such as Feed-Forward Neural Networks\n\
    (FFNN) and Gradient-Boosted Regression Trees (GBRT), and showed superior performance.\n\
    4.4. Solar Irradiance Forecasting Model Based on Other Deep Learning\nRef. [144]\
    \ introduced a Multi-Reservoir Echo State Network (MR-ESN) and deep Echo\nState\
    \ Network architecture-based solar irradiance forecasting model (ESN). The model\
    \ was\ndesigned to forecast a wide range of periods (1 and multiple hours ahead).\
    \ The California\nIrrigation Management Information System collects solar irradiance\
    \ data from Seeley\nOwens Lake South, Davis, Salinas North, and Blythe NE Markleeville.\
    \ The suggested\nMR-ESN model achieved a lower forecasting error than the benchmark\
    \ models evaluated,\nsuch as Elman Neural Networks, BP, and ESN, according to\
    \ quantitative simulation results\n(ENN). Furthermore, as illustrated in Figure\
    \ 12, MR-ESN has a far greater RMSE forecasting\naccuracy than ESN. Table 4 further\
    \ illustrates that as the forecasting horizon lengthens,\nmodel forecasting accuracy\
    \ declines.\nTable 4. Ratio comparison of ANN and RNN models using a 10-minute\
    \ data sampling frequency in\nterms of forecasting accuracy [144].\nForecasting\
    \ Step\nEvaluation\nPeriod\nRMSE (ESN)\nRMSE\n(MR-ESN)\nReduction (%)\n1-step\n\
    1\n147.258\n121.671\n17.38\n2\n132.787\n63.014\n52.55\n3\n196.057\n168.158\n14.23\n\
    4\n119.763\n98.987\n17.35\n2-step\n1\n222.684\n169.543\n23.86\n2\n171.536\n70.068\n\
    59.15\n3\n273.373\n224.234\n17.98\n4\n154.126\n113.687\n26.24\nAppl. Sci. 2023,\
    \ 13, 8332\n22 of 43\nTable 4. Cont.\nForecasting Step\nEvaluation\nPeriod\nRMSE\
    \ (ESN)\nRMSE\n(MR-ESN)\nReduction (%)\n3-step\n1\n235.349\n189.584\n19.45\n2\n\
    156.275\n72.064\n53.89\n3\n286.015\n246.643\n13.77\n4\n158.033\n126.020\n20.26\n\
    Appl. Sci. 2023, 13, x FOR PEER REVIEW \n22 of 43 \n \n \nFigure 12. Two-Hour-Ahead\
    \ MR-ESN and ESN estimates for (a) Owens Lake South station and (b) \nBlythe NE\
    \ station [144]. \nTable 4. Ratio comparison of ANN and RNN models using a 10-minute\
    \ data sampling frequency in \nterms of forecasting accuracy [144]. \nForecasting\
    \ Step \nEvaluation \nPeriod \nRMSE (ESN) RMSE (MR-ESN) Reduction (%) \n1-step\
    \ \n1 \n147.258 \n121.671 \n17.38 \n \n2 \n132.787 \n63.014 \n52.55 \n \n3 \n\
    196.057 \n168.158 \n14.23 \n \n4 \n119.763 \n98.987 \n17.35 \n2-step \n1 \n222.684\
    \ \n169.543 \n23.86 \n \n2 \n171.536 \n70.068 \n59.15 \n \n3 \n273.373 \n224.234\
    \ \n17.98 \n \n4 \n154.126 \n113.687 \n26.24 \n3-step \n1 \n235.349 \n189.584\
    \ \n19.45 \n \n2 \n156.275 \n72.064 \n53.89 \n \n3 \n286.015 \n246.643 \n13.77\
    \ \n \n4 \n158.033 \n126.020 \n20.26 \nFurthermore, ref. [145] developed RNN using\
    \ the sliding window technique for \nshort-term solar irradiation forecasting\
    \ of meteorological data from an Alabama weather \nstation. The forecasting was\
    \ generated for variations in sampling intervals, such as 1 h, 30 \nmin, and 10\
    \ min, based on two factors: outside dry-bulb temperature and time. The model\
    \ \nwas trained using data from 7 days (22–28 May 2016) and validated on a single\
    \ day (29\nFigure 12. Two-Hour-Ahead MR-ESN and ESN estimates for (a) Owens Lake\
    \ South station and\n(b) Blythe NE station [144].\nFurthermore, ref. [145] developed\
    \ RNN using the sliding window technique for short-\nterm solar irradiation forecasting\
    \ of meteorological data from an Alabama weather station.\nThe forecasting was\
    \ generated for variations in sampling intervals, such as 1 h, 30 min,\nand 10\
    \ min, based on two factors: outside dry-bulb temperature and time. The model\
    \ was\ntrained using data from 7 days (22–28 May 2016) and validated on a single\
    \ day (29 May\n2016). According to the results in Table 5, both ANN and RNN have\
    \ respectable accuracy\nlevels, with RNN signiﬁcantly exceeding ANN. Further,\
    \ Figure 13 illustrates the forecasting\naccuracy of both ANN and RNN models with\
    \ and without the sliding window techniques.\nTable 5. Forecasting accuracy of\
    \ ANN and models on a 10-minute data sampling frequency [145].\nModels\nANN\n\
    RNN\nImprovement (%)\nR2\n0.974\n0.983\n1%\nRMSE\n55.7\n41.2\n26%\nCV (RMSE) (%)\n\
    9.41\n7.64\n19%\nNMBE (%)\n1.73\n0.92\n47%\nAppl. Sci. 2023, 13, 8332\n23 of 43\n\
    Table 5. Forecasting accuracy of ANN and models on a 10-minute data sampling frequency\
    \ [145]. \nModels \nANN \nRNN \nImprovement (%) \nR2 \n0.974 \n0.983 \n1% \nRMSE\
    \ \n55.7 \n41.2 \n26% \nCV (RMSE) (%) \n9.41 \n7.64 \n19% \nNMBE (%) \n1.73 \n\
    0.92 \n47% \n \nFigure 13. Comparison between findings of (a) ANN and (b) RNN\
    \ forecasting [145]. \nPrevious work by [45] used a Deep Neural Network (DNN)\
    \ for solar irradiance fore-\ncasting in Turkey. Meteorological input data used\
    \ included maximum temperature, sun-\nshine duration, cloud type, and lowest temperature,\
    \ as well as an astronomical feature \nknown as extra-terrestrial rotation. The\
    \ model training and testing were performed on a \n7-year dataset gathered from\
    \ 34 stations between 2001 and 2007. The results showed \nhighly accurate forecasting\
    \ results of 0.98 for the coefficient of determination. Further, ref. \n[146]\
    \ suggested a new deep learning model integrated with Embedding Clustering (EC)\
    \ \nand Deep Belief Networks (DBN) for daily solar irradiance forecasting. The\
    \ dataset was \ngathered from 30 meteorological stations located across China\
    \ and validated based on \ndaily input features (for mean) for wind speed, maximum\
    \ and minimum dry-bulb tem-\nperature, relative humidity, sunshine duration, and\
    \ global solar radiation. A dataset from \nthe preceding 22 years was used to\
    \ train the model (1994 to 2015). The suggested hybrid \nmodel generated an excellent\
    \ forecasting score, with an RMSE of 0.282 W/m2 and an MAE \nof 0.137 W/m2. Figure\
    \ 14 shows the comparative probabilistic density error curves for the \nmodels.\
    \ The improved performance of the developed model emphasizes its global accept-\n\
    ability for solar irradiance forecasting. \nFigure 13. Comparison between ﬁndings\
    \ of (a) ANN and (b) RNN forecasting [145].\nPrevious work by [45] used a Deep\
    \ Neural Network (DNN) for solar irradiance\nforecasting in Turkey. Meteorological\
    \ input data used included maximum temperature,\nsunshine duration, cloud type,\
    \ and lowest temperature, as well as an astronomical feature\nknown as extra-terrestrial\
    \ rotation. The model training and testing were performed on\na 7-year dataset\
    \ gathered from 34 stations between 2001 and 2007. The results showed\nhighly\
    \ accurate forecasting results of 0.98 for the coefﬁcient of determination. Further,\n\
    ref. [146] suggested a new deep learning model integrated with Embedding Clustering\n\
    (EC) and Deep Belief Networks (DBN) for daily solar irradiance forecasting. The\
    \ dataset\nwas gathered from 30 meteorological stations located across China and\
    \ validated based\non daily input features (for mean) for wind speed, maximum\
    \ and minimum dry-bulb\ntemperature, relative humidity, sunshine duration, and\
    \ global solar radiation. A dataset\nfrom the preceding 22 years was used to train\
    \ the model (1994 to 2015). The suggested\nhybrid model generated an excellent\
    \ forecasting score, with an RMSE of 0.282 W/m2 and\nan MAE of 0.137 W/m2. Figure\
    \ 14 shows the comparative probabilistic density error curves\nfor the models.\
    \ The improved performance of the developed model emphasizes its global\nacceptability\
    \ for solar irradiance forecasting.\nAppl. Sci. 2023, 13, x FOR PEER REVIEW \n\
    24 of 43 \n \n \nFigure 14. The probability density curves of hourly errors in\
    \ four Chinese stations [146]. \nThe Hierarchical Multi-Modal (H-MDL) and the\
    \ Wavelet Decomposition Multi-\nModal were introduced as two deep learning-based\
    \ multi-modal solar irradiance forecast-\ning models [147]. The proposed models\
    \ were trained on a 12-year dataset gathered via \nNREL. The dataset included\
    \ hourly images from all-sky web cameras, as well as data on \ntemperature, turbidity,\
    \ precipitation, wind speed, zenith angle, DHI, GHI, and DNI.\nFigure 14. The\
    \ probability density curves of hourly errors in four Chinese stations [146].\n\
    Appl. Sci. 2023, 13, 8332\n24 of 43\nThe Hierarchical Multi-Modal (H-MDL) and\
    \ the Wavelet Decomposition Multi-Modal\nwere introduced as two deep learning-based\
    \ multi-modal solar irradiance forecasting mod-\nels [147]. The proposed models\
    \ were trained on a 12-year dataset gathered via NREL. The\ndataset included hourly\
    \ images from all-sky web cameras, as well as data on tempera-\nture, turbidity,\
    \ precipitation, wind speed, zenith angle, DHI, GHI, and DNI. Based on the\nﬁndings,\
    \ the novel model outperformed well-known forecasting models, such as ANN\nand\
    \ ARIMA. Prior research conducted by [148] forecasted short-term solar irradiance\
    \ in\nthe Netherlands based on a DNN model. Satellite photographs of previous\
    \ irradiance\nvalues, historical and prospective temperatures, NWP projections,\
    \ clear-sky irradiance, and\nrelative humidity data for the next 6 h, as well\
    \ as historical and prospective temperature,\nNWP projections, clear-sky irradiance,\
    \ and relative humidity data for the next 6 h, were\nused to train the model.\
    \ In the Netherlands, 30 locations were chosen, with 5 serving as\nmodel training\
    \ sites and the remaining 25 serving as model evaluation sites. The results\n\
    showed superior performance compared to other techniques.\nSubsequent work in\
    \ 2021 by [149] introduced a Comprehensive Ensemble Empirical\nMode Decomposition\
    \ with Adaptive Noise (CEEMDAN), Bi-LSTM, and the Sine Cosine\nAlgorithm (SCA)\
    \ for solar irradiance forecasting. The time-series data were split into a\nfew\
    \ periodic intrinsic mode functions (IMFs) using CEEMDAN. Next, the trends of\
    \ solar\nirradiation were identiﬁed using an auto-correlation function (ACF) and\
    \ a partial auto-\ncorrelation function (PACF). The SCA algorithm was then used\
    \ to optimize the forecasting\nof Bi-LSTM. The model was trained using solar radiation\
    \ data from Dauphin Island,\nAlabama, USA. The suggested CEN-SCA-Bi-LSTM model\
    \ outperformed other considered\nmodels. As shown in Figure 15, the comparison\
    \ analyses of all considered models were\nbased on the season ranking, i.e., autumn,\
    \ winter, summer, or spring.\nAppl. Sci. 2023, 13, x FOR PEER REVIEW \n25 of 43\
    \ \n \n \nFigure 15. Comparison analysis of all considered models based on four\
    \ seasons [149]. \nPrior work conducted in 2020 by [150] utilized two unique variants\
    \ of LSTM, which \nwere attention LSTM and GRU, for daily solar irradiance forecasting\
    \ in India. The sug-\ngested model was introduced as a Bidirectional LSTM (Bi-LSTM)\
    \ and was trained using a \n36-year dataset (1983–2019) available from the National\
    \ Aeronautics and Space Admin-\nistration (NASA). The observed findings indicated\
    \ superior accuracy performance for Bi-\nLSTM than other deep learning models.\
    \ Ref. [151] introduced a sophisticated RNN model \nintegrated with a Chain-Structure\
    \ Echo State Network (CESN) for hour-ahead solar radi-\nFigure 15. Comparison\
    \ analysis of all considered models based on four seasons [149].\nPrior work conducted\
    \ in 2020 by [150] utilized two unique variants of LSTM, which\nwere attention\
    \ LSTM and GRU, for daily solar irradiance forecasting in India. The sug-\nAppl.\
    \ Sci. 2023, 13, 8332\n25 of 43\ngested model was introduced as a Bidirectional\
    \ LSTM (Bi-LSTM) and was trained using\na 36-year dataset (1983–2019) available\
    \ from the National Aeronautics and Space Admin-\nistration (NASA). The observed\
    \ ﬁndings indicated superior accuracy performance for\nBi-LSTM than other deep\
    \ learning models. Ref. [151] introduced a sophisticated RNN\nmodel integrated\
    \ with a Chain-Structure Echo State Network (CESN) for hour-ahead solar\nradiation\
    \ forecasting. The model was trained with spatial–temporal behavior data and\n\
    demonstrated rapid learning, as well as a cheaper computational cost than RNN.\
    \ Based on\nthe ﬁndings, the suggested CESN model outperforms backpropagation\
    \ (BP), ENN, and\nclassical ESN. Further, ref. [152] adopted GAN integrated with\
    \ CNN for model training\nto produce realistic future cloud images that were retrieved\
    \ from the University of Patras,\nGreece, and consisted of 1.5 million images\
    \ taken between August 2014 and April 2017.\nBased on observation, the images\
    \ produced by the model without the adversarial loss are\nrather blurry.\n4.5.\
    \ Solar Irradiance Forecasting Model Based on Deep Hybrid Model\nRecently, Ref.\
    \ [153] suggested an integration of CNN and LSTM to establish a frame-\nwork for\
    \ forecasting solar irradiance based on Clear-Sky Index that was 1-h ahead. The\n\
    suggested model was trained on historical solar radiation data and does not consider\
    \ any\noutside inﬂuences. The model was trained on the NREL solar dataset from\
    \ Oahu, which\nconsisted of 20 months of data (March 2010 to October 2011). The\
    \ developed model outper-\nformed the considered baseline models, as evidenced\
    \ by variations in forecast skill scores\nof 7.4 to 41%. Before that study, ref.\
    \ [154] also integrated the CNN and LSTM network\n(ConvLSTM) for hourly solar\
    \ irradiation forecasting in the Korean Peninsula. The dataset\nconsisted of 1100\
    \ photos taken in a row from 1 April 2011 to 31 December 2015. The\nsimulations\
    \ observed that the ConvLSTM model generated a higher forecasting accuracy\nthan\
    \ ANN and RF, with an R2 value of 0.895 and an RMSE value of 71.334 W/m2.\nAn\
    \ innovative hybrid deep architecture based on (ResNet) and LSTM was developed\n\
    by [155] for short-time solar irradiance forecasting. The model was trained on\
    \ an eight-year\ndataset (from 2000 to 2017) available from the NSRDB. The ResNet-LSTM\
    \ hybrid model\nlowered forecasting errors by 52.44 and 17.07%, respectively,\
    \ more than standalone ResNet\nand LSTM. Furthermore, [102] integrated the use\
    \ of LSTM and CNN algorithms to extract\nspatial and temporal information in sequence.\
    \ The meteorological data from 23 different\nsites in California were used for\
    \ model training, such as DHI, GHI, temperature, relative\nhumidity, cloud cover,\
    \ and precipitation. The model was tested over a whole year, through\nall four\
    \ seasons, and under three various types of meteorological conditions. The forecasts\n\
    made using the developed LSTM-CNN model are more accurate than individual models,\n\
    like SP, CNN, LSTM, ANN, SVM, and others. In Alice Springs, Australia, [156] proposed\
    \ an\nintegration of CNN and LSTM (CLSTM) for both short- and long-term forecasting\
    \ horizons\nof the half-hourly solar irradiation forecasting model. The model\
    \ was evaluated for daily,\nweekly, and n-month (n = 1 to 8) solar irradiance\
    \ forecasting horizons using data from a\n12-year and and eight-month period (from\
    \ 1 January 2006 to 31 August 2018). The recom-\nmended model obtained a higher\
    \ percentage, which denoted satisfactory performance. As\nseen in Figure 16, the\
    \ CLSTM hybrid model in 1-day forecasting for RMSE, MAE, MAPE,\nand RMSE obtained\
    \ a higher percentage, which denoted satisfactory performance.\nRef. [67] used\
    \ historical time series solar irradiance data to create a new hybrid deep\nlearning\
    \ model of LSTM, CNN, and wavelet decomposition for day-ahead forecasting of\n\
    solar irradiance in North Carolina, USA. The model was validated using the partitioned\n\
    data (into four different weather categories) obtained from NREL and the NOAA\
    \ Earth\nSystem Research Laboratory at two different locations: Desert Rock Station\
    \ and Elizabeth\nCity State University. Recent work by [157] suggested a new hybrid\
    \ model using both\nMLP networks and LSTM that uses two-branch inputs for hour-ahead\
    \ solar irradiance\nforecasting. The dataset used is a time series of historical\
    \ solar irradiation and auxiliary\ninputs. Findings showed superior performance\
    \ compared to other machine learning\nAppl. Sci. 2023, 13, 8332\n26 of 43\nmodels,\
    \ with performances of SVM, BPNN, Random Forest, RNN, and LSTM improved by\n19.31,\
    \ 19.19, 11.68, 20.15, and 13.48%, respectively.\nforecasts made using the developed\
    \ LSTM-CNN model are more accurate than individual \nmodels, like SP, CNN, LSTM,\
    \ ANN, SVM, and others. In Alice Springs, Australia, [156] \nproposed an integration\
    \ of CNN and LSTM (CLSTM) for both short- and long-term fore-\ncasting horizons\
    \ of the half-hourly solar irradiation forecasting model. The model was \nevaluated\
    \ for daily, weekly, and n-month (n = 1 to 8) solar irradiance forecasting horizons\
    \ \nusing data from a 12-year and and eight-month period (from 1 January 2006\
    \ to 31 August \n2018). The recommended model obtained a higher percentage, which\
    \ denoted satisfactory \nperformance. As seen in Figure 16, the CLSTM hybrid model\
    \ in 1-day forecasting for \nRMSE, MAE, MAPE, and RMSE obtained a higher percentage,\
    \ which denoted satisfactory \nperformance. \n \nFigure 16. The performance of\
    \ the CLSTM model for 1-day GSR forecasting (a) RMSE (%) and (b) \nMAPE (%) [156].\
    \ \nFigure 16. The performance of the CLSTM model for 1-day GSR forecasting (a)\
    \ RMSE (%) and\n(b) MAPE (%) [156].\nFor hourly GHI forecasting, Kumari [102]\
    \ developed a hybrid deep learning model\nthat made use of both the LSTM algorithm\
    \ and the CNN algorithm to extract spatial and\ntemporal information in sequence.\
    \ The model was trained using the GHI data, in addition\nto meteorological data\
    \ from 23 different sites across the state of California, including GHI,\ntemperature,\
    \ relative humidity, cloud cover, and precipitation data. The model was tested\n\
    over a whole year, through all four seasons, and under the three types of meteorological\n\
    conditions. The forecasts made using the developed LSTM-CNN model are more accurate,\n\
    having a range of about 37–45%, than standalone models, like SP, CNN, LSTM, ANN,\
    \ SVM,\nand others.\nRef. [158] suggested an evolutionary attention-based LSTM-based\
    \ time-series forecast-\ning model to address the problem of attention dispersion\
    \ that plagues the typical LSTM\nalgorithm. Varying in terms of time steps, the\
    \ Attention Mechanism can give characteristics\nto time-series weights. The LSTM-based\
    \ approach of forecasting has difﬁculty interpreting\ncomplex relationships between\
    \ features that only use weights. A Self-Attention Mecha-\nnism is an Attention\
    \ Mechanism that extracts deeper information from a row of data. The\nsuggested\
    \ method aimed to maximize the beneﬁts of the features of the extended input\n\
    sequences. The Attention Mechanism performed better than the standard LSTM.\n\
    Following that approach, ref. [159] proposed a probabilistic forecasting model\
    \ that\nintegrated residual modeling and an RNN. An LSTM-based point forecasting\
    \ method was\nutilized for deterministic forecasting and calculating the residual\
    \ distributions. The input\nfeatures considered include temperature, cloud cover,\
    \ dew point, east sea-level pressure,\nAppl. Sci. 2023, 13, 8332\n27 of 43\nrelative\
    \ humidity, wind speed, hour of the day, and month of the year. The model was\n\
    based on data from the MIDC ofﬁcial website dating back ten years. The suggested\
    \ model\noutperformed ELM, RF, SVR, and LSTM in terms of accuracy. Subsequently,\
    \ ref. [160]\nutilized six variants of RNN techniques, which are RNN, GRU, Content-Based\
    \ Attention,\nLuong Attention, Self-Attention-Based RNN, and LSTM for solar radiation\
    \ forecasting. A\ncomparative analysis was conducted, using a 37-year dataset,\
    \ between the two independent\nsites. The models were trained on historical time-series\
    \ data of solar radiation with no\nexogenous characteristics, and forecasts were\
    \ produced on several forecasting horizons.\nBased on the ﬁndings, it was revealed\
    \ that the Attention Mechanism signiﬁcantly improved\nmemory-based RNN.\nAnother\
    \ work by [161] suggested a two-stage deep solar radiation forecasting model\n\
    based on the CNN model to encode a frame from a sky-video to restore a full-sky\
    \ image, and\na two-tier LSTM model was used for monitoring. The model training\
    \ was performed on a\nfree dataset from two sites in Tucson, Arizona, and Golden,\
    \ Colorado. Results showed that\nthe suggested model can forecast a range of time\
    \ ranges of 1–4 h in advance. An ensemble\nmodel of (XGBF-DNN) [162] was employed\
    \ for hourly solar radiation forecasting by\nintegrating Deep Neural Networks\
    \ and Extreme Gradient Boosting Forest. The suggested\nhybrid model was evaluated\
    \ at three sites in India, which were Gangtok, Jaipur, and Delhi,\nin terms of\
    \ temperature, pressure, relative humidity, wind speed, clear sky index, wind\n\
    direction, time of day, and month number. Figure 17 depicts the comparison analysis\
    \ of\nthe proposed model against benchmarks, such as smart persistence, SVR, RF,\
    \ DNN, and\nXGBoost which resulted in superior performance at each site location\
    \ during the winter,\nsummer, monsoon, and autumn seasons.\nAppl. Sci. 2023, 13,\
    \ x FOR PEER REVIEW \n28 of 43 \n \nDNN, and XGBoost which resulted in superior\
    \ performance at each site location during \nthe winter, summer, monsoon, and\
    \ autumn seasons.  \n \nFigure 17. The comparison between performances of actual\
    \ and predicted GHI in Gangtok for \ndifferent seasons (a) Winter, (b) Summer,\
    \ (c) Monsoon and (d) Autumn [162]. \nRecent work by [163] suggested a hybrid\
    \ deep learning model that utilized both CNN \nand Bi-LSTM for excellent mid-term\
    \ solar radiation forecasting. The CNN architecture \ncaptured available solar\
    \ irradiance features, and Bi-LSTM manipulated the time-series \ndata dependencies.\
    \ The evaluation and comparison of the suggested model were per-\nformed against\
    \ other established DL models at three different geographical areas within \n\
    similar latitudes that received similar amounts of solar radiation. It was demonstrated\
    \ that \nthe hybrid DL model was durable and outperformed existing DL models for\
    \ forecasting \nmid-term solar radiation in terms of accuracy. A hybrid model\
    \ of four distinguished deep \nlearning-based techniques was designed by [164]\
    \ using LTSM and CNN based on Bayes-\nian Optimization (BO) for short-term PV\
    \ power generation forecasting. The study ana-\nlyzed feature selection for both\
    \ benchmark models and selected five predictive features to \nbe used to directly\
    \ forecast results (1 to 24 h ahead). The data originated from a PV facility \n\
    in Shandong, China. While Bi-LSTM and CNN-Bi-LSTM models were more practical for\
    \ \n1-hour forecasting, while LSTM-CNN and CNN-Bi-LSTM models were more suitable\
    \ for \n24-hour forecasting This work demonstrated that the integration of Bayesian\
    \ optimized\nFigure 17. The comparison between performances of actual and predicted\
    \ GHI in Gangtok for\ndifferent seasons (a) Winter, (b) Summer, (c) Monsoon and\
    \ (d) Autumn [162].\nRecent work by [163] suggested a hybrid deep learning model\
    \ that utilized both CNN\nand Bi-LSTM for excellent mid-term solar radiation forecasting.\
    \ The CNN architecture\ncaptured available solar irradiance features, and Bi-LSTM\
    \ manipulated the time-series data\ndependencies. The evaluation and comparison\
    \ of the suggested model were performed\nagainst other established DL models at\
    \ three different geographical areas within similar\nlatitudes that received similar\
    \ amounts of solar radiation. It was demonstrated that the\nhybrid DL model was\
    \ durable and outperformed existing DL models for forecasting mid-\nterm solar\
    \ radiation in terms of accuracy. A hybrid model of four distinguished deep\n\
    learning-based techniques was designed by [164] using LTSM and CNN based on Bayesian\n\
    Appl. Sci. 2023, 13, 8332\n28 of 43\nOptimization (BO) for short-term PV power\
    \ generation forecasting. The study analyzed\nfeature selection for both benchmark\
    \ models and selected ﬁve predictive features to be\nused to directly forecast\
    \ results (1 to 24 h ahead). The data originated from a PV facility\nin Shandong,\
    \ China. While Bi-LSTM and CNN-Bi-LSTM models were more practical for\n1-hour\
    \ forecasting, while LSTM-CNN and CNN-Bi-LSTM models were more suitable for\n\
    24-hour forecasting. This work demonstrated that the integration of Bayesian optimized\n\
    optimal weights offered a satisfactory forecasting performance for commercial\
    \ PV plants\nand could minimize error rates by up to 32.80% more than the benchmark\
    \ model.\nRecently, ref. [165] described a multivariate technique for forecasting\
    \ solar power\ngeneration of PV systems in the very short term using the LSTM\
    \ algorithm. The model\nis validated using the standard parameter and the Mean\
    \ Absolute Error (MAE), which\nwas 0.0565. The implementation of LSTM for multivariate\
    \ extremely short-term solar PV\npower forecasting was supported by potential\
    \ results, which outperformed the univariate\ntechnique. LTSM and fully connected\
    \ (FC) layers were introduced into an LSTM-FC\ndeep learning system to optimize\
    \ forecasting accuracy [166]. Due to the dual-branch\ninput, the model considered\
    \ was not limited to analysis of how meteorological data affects\npower generation,\
    \ but also considered time continuity and periodic dependencies in terms\nof accuracy\
    \ performance. The studies used meteorological data, as well as historical\ncontinuous\
    \ and periodic data, which were then combined into different input forms for\n\
    comparative evaluation of LSTM-FC relative to other benchmark models, like SVM,\
    \ GBDT,\nGRNN, FFNN, and LSTM. Meanwhile, the LSTM-FC model outperformed the others\
    \ in\nterms of forecasting accuracy, with a RMSE that was 11.79% greater than\
    \ that of SVM.\nAccordingly, ref. [167] investigated the implementation of a hybrid\
    \ Deep Learning\napproach by applying RNN, LTSM, and GRU for solar energy forecasting.\
    \ Real meteorolog-\nical data (year 2016–2018) from the Errachidia region were\
    \ used to validate the model. Six\nmetrics, including MAE, MSE, RMSE, ME, R2,\
    \ and NRMSE, were used in the analysis of the\nresults to measure forecast precision\
    \ and error margin for real-time photovoltaic forecasts\nto improve grid management\
    \ and safety. In terms of cost efﬁciency, it was found that\nRNN and LSTM performed\
    \ much better than GRU because they could preserve long-term\ndependencies in\
    \ time-series data. Subsequent work by [168] concentrated on a new deep\nlearning-based\
    \ multi-step ahead approach using LTSM for feature extraction to enhance\nthe\
    \ accuracy forecasting of the GHI. The sine–cosine algorithm based on the swarm\
    \ evolu-\ntionary optimization approach was employed to automate the neural network\
    \ architecture.\nA three-phase modiﬁcation model was developed using three datasets\
    \ gathered from three\nsolar stations in the Eastern USA. This approach was expected\
    \ to encourage a diversiﬁed\nand reduce premature convergence in the optimization\
    \ method. The experimental ﬁnd-\nings demonstrated excellent performance using\
    \ the MAE, RMSE, and Pearson metrics in\ncomparison to alternative forecasting\
    \ models.\nRef. [67] used LSTM and GRU for forecasting techniques to estimate\
    \ the efﬁciency of\nlearning data in the best, worst, and average circumstances.\
    \ Table 6 compares the training\ntime of LSTM and GRU in the three scenarios.\
    \ This table yields the superiority of GRU\ncompared to LSTM because the longest\
    \ training time for GRU was shorter than the best\ntraining time for LTSM.\nTable\
    \ 6. The training time of LSTM vs. GRU [94].\nModel\nThe Best Case (s)\nThe Worst\
    \ Case (s)\nThe Average Case (s)\nLSTM\n393.01\n400.57\n396.27\nGRU\n354.92\n\
    379.57\n365.40\nFurther, Table 7 compares the training times of both LSTM and\
    \ CNN–LSTM. The\nhybrid model must extract both temporal and spatial aspects of\
    \ the data [169], which\nresults in longer training times than the LSTM, which\
    \ takes 983.71 s.\nAppl. Sci. 2023, 13, 8332\n29 of 43\nTable 7. Performance of\
    \ LSTM vs. CNN–LSTM [94].\nModel\nLSTM (s)\nCNN–LSTM (s)\nTraining time\n70.490\n\
    983.701\nThe authors of [170] examined several Deep Neural Network (DNN) models\
    \ for\nthe one-day forecast of Global Horizontal Irradiance (GHI). The considered\
    \ DNN models\ninclude Gated Recurrent Unit (GRU), Long Short-Term Memory (LSTM),\
    \ Bidirectional-GRU\n(Bi-GRU), Bidirectional-LSTM (BiLSTM), one-dimensional Convolutional\
    \ Neural Network\n(CNN1D), and various hybrid conﬁgurations, like CNN-BiLSTM and\
    \ CNN-LSTM. For\nthe development and evaluation of the DNN-based models, the authors\
    \ utilized a dataset\nprovided by NASA, which consisted of daily GHI recordings\
    \ from 1 January 2000 to 30 June\n2020 at a dry site (Hail, Saudi Arabia). The\
    \ analysis also focused on identifying the features\nthat inﬂuenced the accuracy\
    \ of the models. However, this work did not take into account\nother weather features,\
    \ such as air temperature, wind direction, wind speed, pressure, and\nrelative\
    \ humidity. Only historical values of daily GHI were used to develop the DNN-based\n\
    models. The outcomes of the study indicated that the DNN models exhibited generally\n\
    good performance, with a maximum correlation coefﬁcient of 96% achieved for the\
    \ daily\nGHI forecasts.\nIn the Saudi Arabian province, the authors of [171] investigated\
    \ several models for\nforecasting solar energy yield. The models considered in\
    \ the study were Neural Networks\n(NN), Non-Linear Autoregressive (NAR), Gaussian\
    \ Process Regression (GPR), Support\nVector Machine (SVM), Simple Moving Average\
    \ (SMA), Simple Average (SA), and Naive\n(N). The ﬁndings demonstrated that all\
    \ of the models generated accurate estimates for the\nthree years from 2019 to\
    \ 2021, with the Naive and Simple Moving Average models slightly\noutperforming\
    \ the other models.\nGhimire, et al. [172] developed a hybrid forecasting model\
    \ that combined a Slime-\nMould algorithm-based feature selection technique, a\
    \ Convolutional Neural Network\n(CNN), a Long-Short-Term Memory Neural Network\
    \ (LSTM), and a ﬁnal CNN with a\nMultilayer Perceptron output (referred to as\
    \ the SCLC algorithm later). The proposed\napproach was applied to six solar farms\
    \ in Queensland, Australia, considering daily\ntemporal horizons in six different\
    \ time increments. The forecasting model proposed in the\nstudy outperformed two\
    \ Deep Learning models (CNN-LSTM and Deep Neural Network)\nand three Machine Learning\
    \ models (Artiﬁcial Neural Network, Random Forest, and Self-\nAdaptive Differential\
    \ Evolutionary Extreme Learning Machines) across all six selected\nsolar farms.\
    \ The results demonstrated strong performance metrics (r > 0.9 in all cases) and\n\
    improvements of more than 10% for daily, monthly, and seasonal periods.\nPeng\
    \ et al. [173] present a PV power forecasting approach for long- and short-term\n\
    memory networks based on Pearson feature selection. The method analyzed the inﬂuence\n\
    of input features on the variance in PV power using Pearson coefﬁcients, and the\
    \ model was\nconﬁrmed using case tests. The results revealed that the intensity\
    \ of insolation radiation,\ntemperature, and humidity were important effect features\
    \ in the change in PV power. When\nLSTM was compared to the BP, RB, and TS algorithms,\
    \ it was discovered that the proposed\napproach reduced the forecasting error\
    \ rate by 1.48, 11.4, and 6.45%, respectively, compared\nto the LSTM, CNN, and\
    \ BP.\nGhimire, Deo, Casillas-Pérez, Salcedo-Sanz, Sharma, and Ali [172] developed\
    \ a hy-\nbrid forecasting model that combined a Slime-Mould algorithm-based feature\
    \ selection\ntechnique, a Convolutional Neural Network (CNN), a Long Short-Term\
    \ Memory Neural\nNetwork (LSTM), and a ﬁnal CNN with a Multilayer Perceptron output\
    \ (SCLC algorithm\nlater). The suggested approach was applied to six solar farms\
    \ in Queensland, Australia,\nat daily temporal horizons in six different time\
    \ increments. The proposed forecasting\nmodel outperformed two Deep Learning (Deep\
    \ Neural Network, CNN-LSTM) and three\nMachine Learning (Artiﬁcial Neural Network,\
    \ Random Forest, Self-Adaptive Differential-\nEvolutionary Extreme Learning Machines)\
    \ models in all six selected solar farms. The results\nAppl. Sci. 2023, 13, 8332\n\
    30 of 43\nshowed good performance metrics (r > 0.9 in all cases) and improvements\
    \ of more than\n10% over daily, monthly, and seasonal periods.\nGhimire, et al.\
    \ [174] suggested a hybrid approach that combines a Convolutional\nNeural Network\
    \ (CNN), Long Short-Term Memory (LSTM), and Multi-Layer Perceptron\n(MLP) to predict\
    \ Global Sun Radiation (GSR). The proposed method involved utilizing a\nCNN-LSTM\
    \ model to extract optimal topological and structural characteristics from the\
    \ pre-\ndictive features, followed by an MLP-based predictive model for generating\
    \ GSR forecasts.\nMeteorological features were used to predict GSR in six solar\
    \ farms located in Queensland,\nAustralia. To enhance the efﬁciency of the proposed\
    \ CMLP model, a Hybrid–Wrapper fea-\nture selection technique based on a Random\
    \ Forest-Recursive Feature Elimination (RF-RFE)\nscheme was employed to eliminate\
    \ redundant predictor features. The performance of the\nCMLP model was compared\
    \ to those of seven temperature-based deterministic models\nbased on artiﬁcial\
    \ intelligence. The evaluation demonstrated the excellent performance of\nthe\
    \ CMLP model across all tested solar energy study sites, spanning daily, monthly,\
    \ and\nseasonal scales.\n5. Discussion and Analysis of Performance\nThe performances\
    \ of existing deep learning-based solar irradiance forecasting models\nare analyzed\
    \ and discussed in this section. Currently, the LTSM is deemed to be the\nmost\
    \ used model for solar irradiance forecasting due to it being one type of Recurrent\n\
    Neural Network that preserves data for future use, as well as providing extra\
    \ storage\ncapacity to the network. It is extensively utilized to forecast solar\
    \ irradiance because it can\nspeed up the convergence of non-linear forecasts\
    \ and reveal the long-term relationships\nbetween time series. In one of the studies,\
    \ ref. [107] proposed an LSTM model for 1-day\nahead solar irradiance forecasting\
    \ at 21 locations across the USA and Europe based on\nremote-sensing data. The\
    \ suggested model demonstrated over 52.2% more accuracy than\nthe smart persistence\
    \ model. Following that approach, ref. [65] used LTSM for 1-hour\nahead solar\
    \ irradiance forecasting at three locations in the USA. The ﬁndings presented\n\
    the lowest RMSE forecasting of 41.37 W/m2. Subsequently, different mechanisms\
    \ and\nnew variants were introduced to enhance the model’s performance. Therefore,\
    \ ref. [150]\npresented two different variants of LSTM, known as Bi-LSTM and attention-based\
    \ LSTM,\nfor daily solar irradiance forecasting at two locations in India. The\
    \ LTSM architecture\nwas composed of a gating mechanism and memory cells, which\
    \ assisted in learning long-\nterm data dependencies. Thus, it could be asserted\
    \ that LTSM and its variants performed\nadequately for solar irradiance time-series\
    \ data and forecasting accuracy. Before that\nstudy, GRU was also extensively\
    \ applied in the literature [141]. The beneﬁts of GRU\nis that it is computationally\
    \ cheaper because it requires less parameters training and\nmemory; hence, faster\
    \ execution. On the contrary, LTSM is computationally expensive, as\nit requires\
    \ multiple training stages, though it generates effective accuracy forecasting.\
    \ In\naddition, ref. [49] presented a CNN model for 10-minute ahead direct normal\
    \ irradiance\nforecasting. In this study, ground-based cloud images were utilized\
    \ to extract temporal\nand spatial features for model training and demonstrated\
    \ an increase of 17.06% in accuracy\nforecasting over a smart persistent model.\
    \ This result occurred due to the structure of CNN,\nwhich was made up of convolutional\
    \ and pooling layers that were particularly efﬁcient in\nfeatures extraction.\
    \ Therefore, it worked extremely effectively for image feature extraction\n(including\
    \ converting it to two-dimensional data) for solar irradiance data. The connections\n\
    of CNN and feature-sharing properties minimize the model parameter training and\
    \ time,\nand it has a strong ability to extract spatial correlations from weather\
    \ data, such as cloud\ncover, and other factors.\nFurthermore, the DBN was also\
    \ widely used for solar irradiance forecasting [146]. The\nstructure of DBN was\
    \ inherited from the restricted Boltzmann machine, in which a layer-by-\nlayer\
    \ unsupervised training method was employed. Therefore, it was suitable for extracting\n\
    input features that were explicitly detectable in renewable energy forecasts.\
    \ Moreover, another\nused deep learning model for solar irradiance forecasting\
    \ was RNN. For example, ref. [175]\nAppl. Sci. 2023, 13, 8332\n31 of 43\nintroduced\
    \ a multi-horizon GHI forecasting model using RNN that resulted in an average\n\
    RMSE of 18.57 W/m2 for variations in forecasting horizons. The main structure\
    \ of RNN were\nthe internal feedback and feedforward connections between the neurons.\
    \ These connections\nacted as memory functions for the RNN, allowing efficient\
    \ processing of time-series solar\ndata.\nThe performance of standalone models\
    \ is limited in cases where a hybrid model\nfocuses on combining different methods\
    \ while exploiting the beneﬁts of individual fore-\ncasting models to enhance\
    \ the accuracy of deep learning networks. This observation is\ntrue because a\
    \ single model sometimes may not be able to fully extract necessary features\n\
    and satisfactorily perform all tasks. Furthermore, a hybrid model is expected\
    \ to provide\nbetter accuracy than single deep learning models. However, it takes\
    \ longer to train than\nother models because it needs to extract both spatial\
    \ and temporal features from the data;\ntherefore, the use of hybrid models was\
    \ introduced. Several researchers have presented\ntheir work, including [49],\
    \ whose author used a hybrid of model CNN and LSTM. Addition-\nally, they integrated\
    \ the use of LSTM and CNN algorithms to extract spatial and temporal\ninformation\
    \ in sequences. The model training utilized meteorological data from 23 different\n\
    sites in California, including DHI, GHI, temperature, relative humidity, cloud\
    \ cover, and\nprecipitation. The developed LSTM-CNN model was tested throughout\
    \ a whole year,\ncovering all four seasons and under three types of meteorological\
    \ conditions. Similarly, [19]\npresented the use of both LSTM and RNN, [176] developed\
    \ an integrated GA with the DNN\nfor model optimization (GRU, LSTM, and RNN) of\
    \ solar irradiance forecasting, and [102]\ndeveloped an LSTM-CNN model to extract\
    \ spatial and temporal features. The forecasts\nproduced via the LSTM-CNN model\
    \ demonstrated higher accuracy than individual mod-\nels, such as SP, CNN, LSTM,\
    \ ANN, SVM, and others. In another study, Ghimire, Deo,\nCasillas-Pérez, Salcedo-Sanz,\
    \ Sharma, and Ali [172] developed a hybrid forecasting model\nthat combined a\
    \ Slime-Mould algorithm-based feature selection technique, a Convolutional\nNeural\
    \ Network (CNN), a Long Short-Term Memory Neural Network (LSTM), and a ﬁnal\n\
    CNN with a Multilayer Perceptron output (referred to as the SCLC algorithm later).\n\
    The Attention Mechanism allows deep learning models to engage in enhanced feature\n\
    extraction for a sequence of inputs. Although deep learning may yield positive\
    \ outcomes,\nthe training process is typically challenging; therefore, researchers\
    \ often combine an At-\ntention Mechanism to enhance the efﬁciency of feature\
    \ extraction. Such an example can\nbe seen in [177], whose authors used the Attention\
    \ Mechanism with two LSTM for short-\nterm PV power forecasting. Firstly, the\
    \ output of both networks was integrated with the\nAttention Mechanism. Secondly,\
    \ the integrated output was merged into a fully connected\nlayer for forecasting\
    \ output. The suggested model was then validated using the dataset of\nfour seasons\
    \ with variations in forecasting horizons against four other considered models.\n\
    Based on our observations, the proposed model outperformed other conventional\
    \ LSTMs,\nas well as all considered models for more than 15-min solar irradiance\
    \ forecasting; the\nneural network that was paired with the Attention Mechanism\
    \ performed most effec-\ntively, improving neural network interpretability by\
    \ eliminating irrelevant data and only\nselecting more important information,\
    \ as well as differently weighting each feature of the\nmeteorological data. In\
    \ addition, the correlation between features and irradiation in the\nfeature set\
    \ was analyzed to reduce model complexity and improve forecasting. Ghimire,\n\
    Nguyen-Huy, Prasad, Deo, Casillas-Perez, Salcedo-Sanz, and Bhandari [174] suggested\
    \ a\nhybrid approach that combined a Convolutional Neural Network (CNN), Long\
    \ Short-Term\nMemory (LSTM), and Multi-Layer Perceptron (MLP) to predict global\
    \ sun radiation (GSR).\nFirstly, a CNN-LSTM extracted optimal topological and\
    \ structural characteristics inherent\nin predictive features; an MLP-based predictive\
    \ model then generated GSR forecasts. Mete-\norological features were used to\
    \ predict GSR in six solar farms in Queensland, Australia. To\nimprove the efﬁciency\
    \ of the proposed CMLP model, a Hybrid–Wrapper feature selection\ntechnique based\
    \ on a Random Forest–Recursive Feature Elimination (RF-RFE) scheme was\nemployed\
    \ to eliminate redundant predictor features. Table 8 presents a summary of the\n\
    related studies.\nAppl. Sci. 2023, 13, 8332\n32 of 43\nTable 8. Summary of the\
    \ main studies related to solar irradiance forecasting using deep learning techniques,\
    \ including and advantages and disadvantages.\nAuthor\nYear\nModel\nResult\nAdvantage\n\
    Limitation\nMishra and Palanisamy [175]\n2018\nRNN\nIntroduced a multi-horizon\
    \ GHI\nforecasting model using RNN that\nresults in an average RMSE of\n18.57\
    \ W/m2 for variations in\nforecasting horizons.\nThe main structure of RNN is\
    \ the\ninternal feedback and feedforward\nconnections between the neurons.\nThese\
    \ connections act as memory\nfunctions for the RNN, allowing the\nefﬁcient processing\
    \ of time-series\nsolar data.\nInability to deal with long-term data\ndependencies\
    \ because of vanishing\ngradient and gradient\nexplosion issues.\nJeon and Kim\
    \ [127]\n2020\nGRU\nThe model generated substantial\nforecasting with an RMSE\
    \ of\n30 W/m2.\nIt is computationally cheaper\nbecause it requires lesser parameter\n\
    training and memory, hence\nfaster execution.\nIt is a struggle to capture long-term\n\
    dependencies in sequences.\nSrivastava and\nLessmann [107]\n2018\nLSTM\nThe LSTM\
    \ model demonstrated\n52.2% greater accuracy than the\nsmart persistence model.\n\
    It provides extra storage capacity to\nthe network and handles temporal\ndependencies\
    \ in data.\nIt has the capacity to handle\ntemporal dependencies in data, but\
    \ it\nmay face challenges in capturing and\nunderstanding intricate relationships\n\
    or patterns that span\nextended periods.\nBrahma and Wadhvani [150]\n2020\nBi-LSTM,\n\
    Attention\nMechanism.\nBi-LSTM outperforms other deep\nlearning models.\nIt uses\
    \ double processing, which is\nbeneﬁcial for learning complex\ntemporal correlations.\n\
    Its computational time is more than\nthat of LSTM because the forward\nhidden\
    \ sequence is calculated ﬁrst,\nand the reverse hidden sequence is\nthen merged\
    \ to ﬁnd the result.\nZang, Liu, Sun, Cheng, Wei\nand Sun [49]\n2020\nCNN\nCNN\
    \ demonstrated an increase of\n17.06% in accuracy forecasting\ncompared to the\
    \ smart\npersistent model.\nIt is superior at extracting spatial\ncorrelations\
    \ from weather data, such\nas cloud cover and other features;\nCNN has a strong\
    \ ability to extract\nnon-linear features.\nThough it effectively captures and\n\
    understands intricate relationships\nor patterns that span over extended\nperiods,\
    \ it may face challenges in\nhandling temporal dependencies\nin data.\nZang, Cheng,\
    \ Ding, Cheung,\nWang, Wei and Sun [146]\n2020\nDBN\nDBN illustrated an excellent\n\
    forecasting score with an RMSE of\n0.282 W/m2 and an MAE of\n0.137 W/m2.\nIt is\
    \ suitable for extracting input\nfeatures for renewable energy\nforecasts because\
    \ it employs\nlayer-by-layer unsupervised training.\nDBN is primarily designed\
    \ for\nmodeling static data distributions\nand does not naturally handle\nsequential\
    \ or temporal data.\nAppl. Sci. 2023, 13, 8332\n33 of 43\nTable 8. Cont.\nAuthor\n\
    Year\nModel\nResult\nAdvantage\nLimitation\nKumari and Toshniwal [102]\n2021\n\
    CNN and LSTM\nLSTM-CNN model is more accurate\nin a range of about 37–45%\ncompared\
    \ to the benchmark models.\nIt handles temporal and spatial\ndependencies in time-series\
    \ data and\nextracts non-linear features in data.\nIt takes longer to train than\
    \ a single\nmodel because it needs to extract\nboth spatial and temporal features\n\
    from the data.\nBrahma and Wadhvani [150]\n2020\nAttention\nMechanism\nThe neural\
    \ network that was paired\nwith the Attention Mechanism was\nable to perform most\
    \ effectively.\nThe Attention Mechanism supports\ndeep learning models to engage\
    \ in\nenhanced feature extraction for a\nsequence of inputs.\nThe pairwise calculations\
    \ required\nby Attention Mechanisms can result\nin increased computational\ncomplexity,\
    \ leading to longer\ntraining and inference times.\nGhimire, Deo, Casillas-Pérez,\n\
    Salcedo-Sanz, Sharma and\nAli [172]\n2022\nHybrid\nforecasting model\n(CNN, LSTM,\
    \ and\nMultilayer-\nPerceptron).\nThe results demonstrated strong\nperformance\
    \ metrics (r > 0.9 in all\ncases) and improvements of more\nthan 10% for daily,\
    \ monthly, and\nseasonal periods.\nThe hybrid model focuses on\ncombining different\
    \ methods while\nexploiting the beneﬁts of individual\nforecasting models to enhance\
    \ the\naccuracy of deep learning networks.\nIt takes longer to train than other\n\
    models because it needs to extract\nboth spatial and temporal features\nfrom the\
    \ data.\nWang, Zhang, Liu, Yu, Pang,\nDui´c, Shaﬁe-Khah and\nCatalão [33]\n2019\n\
    Generative\nalgorithm (GAN)\nThe simulation outcomes\ndemonstrated that Generative\n\
    Adversarial Networks have the\npotential to build high ﬁneness\nquality specimens\
    \ that catch the\nunderlying properties of the\noriginal data.\nIt makes more\
    \ training data available\nby adding new data devised from\ntraining data.\nTraining\
    \ GAN can be\ncomputationally expensive and\nresource-intensive, particularly\
    \ for\nlarger and more complex models.\nAppl. Sci. 2023, 13, 8332\n34 of 43\n\
    Deep learning techniques have robust performance, especially when dealing with\n\
    spatial and temporal features. However, small datasets may not offer appropriate\
    \ or\nadequate representative training data, which may result in model overﬁtting.\
    \ They are not\nsufﬁcient when dealing with extreme weather types because they\
    \ do not have sufﬁcient\ndata for training. Data augmentation is a way to make\
    \ deep learning, and especially deep\nnetworks, work better. This process makes\
    \ more training data available by adding new\ndata made of either old data or\
    \ new copies of old data that have been changed. Such an\nexample can be seen\
    \ in [33], whose authors used Convolutional Neural Networks and\nGenerative Adversarial\
    \ Networks to categorize the weather into ten categories. Based\non observation,\
    \ the Generative Adversarial Networks have the potential to build high\nﬁneness-quality\
    \ samples that catch the underlying properties of the original data and better\n\
    classiﬁcation performance than benchmark models. Thus, GAN is ideal for data creation\
    \ to\naugment and rebalance the training dataset.\nTable 8 presents a summary\
    \ of the main related studies, including their advantages\nand disadvantages.\
    \ This study elaborated several popular deep learning models, such as\nLSTM, CNN,\
    \ GAN, and an Attention Mechanism, focusing on their application in solar\nirradiance\
    \ forecasting. The study also highlighted improvements in model training by\n\
    increasing the training data and addressing the issue of overﬁtting. Additionally,\
    \ the table\nincludes information about the architecture, strengths, and limitations\
    \ associated with\nthese models.\n6. The Challenge and Future Direction of Solar\
    \ Energy Forecasting Using\nDeep Learning\nDeep learning has already been used\
    \ to make solar energy projections, and there has\nbeen a lot of research into\
    \ this topic. Deep learning-based forecasting models, on the other\nhand, confront\
    \ the two below real-world issues. Solving these issues will further increase\n\
    the accuracy of the deep learning forecasting model [178].\nTheoretical issues:\
    \ Theoretical concerns related to deep learning are generally ex-\nhibited in\
    \ two areas: statistics and calculating abilities. Any non-linear function can\
    \ be\nrepresented by a shallow or deep network. The deep learning model outperforms\
    \ the\nshallow model in non-linear representation. When it comes to solar and\
    \ renewable energy\nforecasts, it is necessary to understand how difﬁcult predicting\
    \ samples can be, as well as\nhow many training samples and how much processing\
    \ power are required to build the\ndeep learning network required to train these\
    \ forecasting samples.\nModeling problems: These problems are related to dealing\
    \ with large volumes of data.\nAccordingly, the extracted feature data from large-scale\
    \ forecasting samples will become\nmore relevant in parallel to the evolution\
    \ of deep learning. The main objective of deep\nlearning is to improve forecasting\
    \ accuracy by learning more relevant information directly\nand spontaneously.\
    \ The mechanism of deep learning models consists of hidden neurons\nwith up to\
    \ 6, 7, or even 10 layers, which allow more efﬁcient feature learning than other\n\
    shallow learning models. Moreover, deep learning makes it easier to learn data\
    \ from solar\nenergy time series through layer-by-layer feature learning. Despite\
    \ this fact, developing\nan efﬁcient hierarchical model with strong feature learning\
    \ is challenging. Thus, the key\nfuture directions for deep learning-based solar\
    \ energy forecasting models are highlighted\nas follows:\n1.\nData augmentation:\
    \ The use of data augmentation techniques make deep learning, and\nespecially\
    \ deep networks, work more effectively; therefore, it is always recommended\n\
    to develop novel methods for generating data that will better serve this purpose.\n\
    This work also paves the way for future research in a variety of areas, including\n\
    photovoltaic power forecasting, wind power forecasting, and electricity consumption\n\
    forecasting in the medium- and long-term, etc., by expanding and embracing the\n\
    modern technique suggested in this work through data generation; in contrast,\
    \ most\nstudies of photovoltaic power, wind power, and energy consumption concentrate\
    \ on\nAppl. Sci. 2023, 13, 8332\n35 of 43\nthe short-term forecast, disregarding\
    \ medium- and long-term forecasts due to a lack of\ntraining data for models.\n\
    2.\nProbability forecasting: Many studies on deterministic renewable energy forecast-\n\
    ing have been published. However, there is still limited work performed on deep\n\
    learning-based probabilistic forecasting models. For solar energy time series\
    \ data,\nthe probabilistic forecasting model can be used to objectively quantify\
    \ the level of\nuncertainty. Hence, it is essential to the operation and administration\
    \ of electric power\nand energy systems daily [178].\n3.\nUniﬁed Predictive Model:\
    \ Solar and renewable energy data have a variety of deep\nfeatures in different\
    \ seasons and meteorological and topographic situations. Accord-\ningly, the forecasting\
    \ model varies based on the situation. However, it is difﬁcult to\ndetermine whether\
    \ a forecasting model could work effectively with different types of\ndata because\
    \ of the unique solar energy datasets used in existing research.\n4.\nFeatures\
    \ Extraction Method: The use of feature extraction is important for effective\n\
    solar energy data forecasting; therefore, it is always recommended to develop\
    \ a novel\nfuture extraction method for deep forecasting data that will better\
    \ serve this purpose.\nCurrently, there is only one deep learning strategy that\
    \ is used for feature extraction\nin the current deep learning forecasting model.\
    \ Thus, it is recommended to develop\nfeature extraction for deep forecasting\
    \ features by combining different deep learning\nalgorithms for future work.\n\
    5.\nHybrid physical forecasting models: In general, it is normal to include numerical\n\
    weather forecasting data in short-term forecasting models to improve solar energy\n\
    forecasting performance. However, it is challenging to determine an effective\
    \ way to\ninclude the relationships between many ground measures in a deep learning-based\n\
    forecasting model. Thus, this topic is considered one of the most important future\n\
    directions of study.\n7. Conclusions\nA comprehensive review of numerous deep\
    \ learning-based models used to forecast\nsolar irradiance and accessible in the\
    \ literature is provided in this paper. These models’\nsophisticated architectures\
    \ make it easier to extract high-level, non-linear features from the\nsolar data.\
    \ This study elaborates on several popular deep learning models, such as LTSM,\n\
    DBN, CNN, RNN, RGU, GAN, and an Attention Mechanism based on solar irradiance\n\
    forecasting, and improves the training of models by increasing the training data\
    \ and avoid-\ning overﬁtting models. These models also include their associated\
    \ architecture, strengths,\nand limitations. In addition, the inﬂuential factors\
    \ of forecasting model accuracy, such as\nforecasting horizons, weather classiﬁcations,\
    \ input feature optimization, and assessment\nmeasures, are presented. Based on\
    \ the literature review, the existing research demon-\nstrates the superiority\
    \ of deep learning-based solar irradiance forecasting models compared\nto conventional\
    \ machine learning approaches. In most cases, the forecasting accuracy\nperformance\
    \ is further enhanced by incorporating the hybrid of deep learning models.\nThus,\
    \ the hybrid model, which extracts both temporal and spatial data features,\n\
    enhances accuracy even further and should be preferred. Additionally, extending\
    \ the\ndata are an approach that improves the performance of deep learning, particularly\
    \ deep\nnetworks. It involves augmenting the training data by adding new data\
    \ generated from\nexisting data or creating modiﬁed copies of old data. Furthermore,\
    \ conducting correlation\nanalysis between features and irradiation and removing\
    \ redundant information in the\nfeature set leads to reduced model complexity\
    \ and improved forecasting. Based on the\nliterature provided, hybrid LSTM and\
    \ CNN models demonstrated superior performances\ncompared to those of other models\
    \ considered. The main ﬁndings of this study can be\nsummarized as follows:\n\
    1.\nThe forecasting horizon is considered the key factor for improving accuracy\
    \ in fore-\ncasting models. The performance of a solar irradiance forecasting\
    \ model typically\nAppl. Sci. 2023, 13, 8332\n36 of 43\ndegrades as the forecasting\
    \ horizon lengthens. Therefore, forecasting models should\nbe considered based\
    \ on the selected forecasting horizon.\n2.\nThe use of a single deep learning\
    \ model is limited. Our ﬁndings show that the imple-\nmentation of hybrid models\
    \ and using different models can improve accuracy and are\npreferred over basic\
    \ deep learning models. The training duration should be considered\nduring performance\
    \ evaluation, since the hybrid model requires the extraction of both\ntemporal\
    \ and spatial features of data; therefore, this model has a longer training time\n\
    compared to other models.\n3.\nModel complexity is also a key factor. While hybrid\
    \ models perform better than individ-\nual models, their computational time is\
    \ generally higher. There is a trade-off between\nthe accuracy of the model and\
    \ its computational complexity and time. Therefore, using\nhigh-performance processors\
    \ and large data frameworks may be difﬁcult.\n4.\nChanges in the weather inﬂuence\
    \ how effectively a forecasting model performs. For\nexample, some forecasting\
    \ models generate lower accuracy for sky circumstances,\nwhile others have substantially\
    \ better performance. Therefore, it is important to\nprioritize weather classiﬁcation\
    \ to ensure accuracy in forecasting.\n5.\nThe implementation of deep learning\
    \ algorithms in solar irradiance forecasting has\nbeen widely explored. Some of\
    \ the most used algorithms include LSTM, CNN, and\nDBN, while rarely used algorithms\
    \ include GRU, ESN, and RNN. These models,\nhowever, have trade-offs because they\
    \ can be highly precise while also being computa-\ntionally expensive. In conclusion,\
    \ deep learning techniques are still in their infancy,\nand their potential to\
    \ resolve challenging time-series forecasting challenges should be\nfurther investigated.\n\
    The recently discussed comparative analysis based on existing deep learning models\n\
    introduced in this study will further serve as a reference for future academics,\
    \ planners,\nand forecasting experts who use solar energy systems to determine\
    \ the most appropriate\ndeep learning model required to achieve an excellent forecasting\
    \ model.\nAuthor Contributions: Conceptualization, A.M.A. (Abbas Mohammed Assaf)\
    \ and H.H.; data cura-\ntion, H.N.A.H. and A.M.A. (Abdullah M. Albarrak); formal\
    \ analysis, A.M.A. (Abbas Mohammed\nAssaf), H.H., A.M.A. (Abdullah M. Albarrak)\
    \ and S.N.Q.; funding acquisition, A.M.A. (Abdul-\nlah M. Albarrak) and S.N.Q.;\
    \ investigation, A.M.A. (Abbas Mohammed Assaf) and S.N.Q.; methodol-\nogy, A.M.A.\
    \ (Abbas Mohammed Assaf) and H.H.; resources, F.A.G. and S.N.Q.; software, H.N.A.H.,\n\
    A.M.A. (Abdullah M. Albarrak), F.A.G. and S.N.Q.; supervision, H.H. and H.N.A.H.;\
    \ validation,\nH.H., H.N.A.H., F.A.G. and S.N.Q.; writing—original draft, A.M.A.\
    \ (Abbas Mohammed Assaf);\nwriting—review and editing, A.M.A. (Abbas Mohammed\
    \ Assaf), F.A.G. and H.H. All authors have\nread and agreed to the published version\
    \ of the manuscript.\nFunding: This work was supported and funded by the Deanship\
    \ of Scientiﬁc Research at Imam\nMohammad Ibn Saud Islamic University (IMSIU)\
    \ (grant number IMSIU-RG23077).\nInstitutional Review Board Statement: Not applicable.\n\
    Informed Consent Statement: Not applicable.\nAcknowledgments: The authors extend\
    \ their gratitude to the Deanship of Scientiﬁc Research at\nImam Mohammad Ibn\
    \ Saud Islamic University for funding this work through Grant Number IMSIU-\n\
    RG23077, and the ﬁrst author would like to thank the Iraqi Ministry of Electricity,\
    \ General Company\nfor North Electricity Distribution, for allowing him to continue\
    \ with his Ph.D studies.\nConﬂicts of Interest: The authors declare no conﬂict\
    \ of interest.\nReferences\n1.\nDuffy, A.; Rogers, M.; Ayompe, L. Renewable Energy\
    \ and Energy Efﬁciency: Assessment of Projects and Policies; John Wiley & Sons:\n\
    Hoboken, NJ, USA, 2015.\n2.\nDas, U.K.; Tey, K.S.; Seyedmahmoudian, M.; Mekhilef,\
    \ S.; Idris, M.Y.I.; Van Deventer, W.; Horan, B.; Stojcevski, A. Forecasting of\n\
    photovoltaic power generation and model optimization: A review. Renew. Sustain.\
    \ Energy Rev. 2018, 81, 912–928. [CrossRef]\n3.\nDincer, I. Energy and environmental\
    \ impacts: Present and future perspectives. Energy Sour. 1998, 20, 427–453. [CrossRef]\n\
    Appl. Sci. 2023, 13, 8332\n37 of 43\n4.\nCampbell-Lendrum, D.; Prüss-Ustün, A.\
    \ Climate change, air pollution and noncommunicable diseases. Bull. World Health\
    \ Organ.\n2019, 97, 160. [CrossRef]\n5.\nvan der Hoeven, M. Technology Roadmap-Solar\
    \ Photovoltaic Energy; International Energy Agency: Paris, France, 2014.\n6.\n\
    Zhang, Y.; Beaudin, M.; Taheri, R.; Zareipour, H.; Wood, D. Day-ahead power output\
    \ forecasting for small-scale solar photovoltaic\nelectricity generators. IEEE\
    \ Trans. Smart Grid 2015, 6, 2253–2262. [CrossRef]\n7.\nYang, C.; Thatte, A.A.;\
    \ Xie, L. Multitime-scale data-driven spatio-temporal forecast of photovoltaic\
    \ generation. IEEE Trans. Sustain.\nEnergy 2014, 6, 104–112. [CrossRef]\n8.\n\
    Haque, A.U.; Nehrir, M.H.; Mandal, P. Solar PV power generation forecast using\
    \ a hybrid intelligent approach. In Proceedings of\nthe 2013 IEEE Power & Energy\
    \ Society General Meeting, Vancouver, BC, Canada, 21–25 July 2013; pp. 1–5.\n\
    9.\nRG Al-Shakarchi, M.; Ghulaim, M.M. Short-term load forecasting for baghdad\
    \ electricity region. Electr. Mach. Power Syst. 2000,\n28, 355–371. [CrossRef]\n\
    10.\nKeyno, H.S.; Ghaderi, F.; Azade, A.; Razmi, J. Forecasting electricity consumption\
    \ by clustering data in order to decline the\nperiodic variable’s affects and\
    \ simpliﬁcation the pattern. Energy Convers. Manag. 2009, 50, 829–836. [CrossRef]\n\
    11.\nDoorga, J.R.S.; Dhurmea, K.R.; Rughooputh, S.; Boojhawon, R. Forecasting\
    \ mesoscale distribution of surface solar irradiation\nusing a proposed hybrid\
    \ approach combining satellite remote sensing and time series models. Renew. Sustain.\
    \ Energy Rev. 2019,\n104, 69–85. [CrossRef]\n12.\nZhang, X.; Li, Y.; Lu, S.; Hamann,\
    \ H.F.; Hodge, B.-M.; Lehman, B. A solar time based analog ensemble method for\
    \ regional solar\npower forecasting. IEEE Trans. Sustain. Energy 2018, 10, 268–279.\
    \ [CrossRef]\n13.\nKumari, P.; Toshniwal, D. Deep learning models for solar irradiance\
    \ forecasting: A comprehensive review. J. Clean. Prod. 2021,\n318, 128566. [CrossRef]\n\
    14.\nDuvenhage, D.F. Sustainable Future CSP Fleet Deployment in South Africa:\
    \ A Hydrological Approach to Strategic Management.\nPh.D. Thesis, Stellenbosch\
    \ University, Stellenbosch, South Africa, 2019.\n15.\nAlfares, H.K.; Nazeeruddin,\
    \ M. Electric load forecasting: Literature survey and classiﬁcation of methods.\
    \ Int. J. Syst. Sci. 2002, 33,\n23–34. [CrossRef]\n16.\nPedregal, D.J.; Trapero,\
    \ J.R. Mid-term hourly electricity forecasting based on a multi-rate approach.\
    \ Energy Convers. Manag. 2010,\n51, 105–111. [CrossRef]\n17.\nWeron, R. Modeling\
    \ and Forecasting Electricity Loads and Prices: A Statistical Approach; John Wiley\
    \ & Sons: Hoboken, NJ, USA, 2007.\n18.\nLappalainen, K.; Wang, G.C.; Kleissl,\
    \ J. Estimation of the largest expected photovoltaic power ramp rates. Appl. Energy\
    \ 2020,\n278, 115636. [CrossRef]\n19.\nHusein, M.; Chung, I.-Y. Day-ahead solar\
    \ irradiance forecasting for microgrids using a long short-term memory recurrent\
    \ neural\nnetwork: A deep learning approach. Energies 2019, 12, 1856. [CrossRef]\n\
    20.\nHammer, A.; Heinemann, D.; Lorenz, E.; Lückehe, B. Short-term forecasting\
    \ of solar radiation: A statistical approach using\nsatellite data. Sol. Energy\
    \ 1999, 67, 139–150. [CrossRef]\n21.\nNonnenmacher, L.; Coimbra, C.F. Streamline-based\
    \ method for intra-day solar forecasting through remote sensing. Sol. Energy\n\
    2014, 108, 447–459. [CrossRef]\n22.\nMurata, A.; Ohtake, H.; Oozeki, T. Modeling\
    \ of uncertainty of solar irradiance forecasts on numerical weather predictions\
    \ with\nthe estimation of multiple conﬁdence intervals. Renew. Energy 2018, 117,\
    \ 193–201. [CrossRef]\n23.\nPerez, R.; Lorenz, E.; Pelland, S.; Beauharnois, M.;\
    \ Van Knowe, G.; Hemker, K., Jr.; Heinemann, D.; Remund, J.; Müller, S.C.;\nTraunmüller,\
    \ W. Comparison of numerical weather prediction solar irradiance forecasts in\
    \ the US, Canada and Europe. Sol.\nEnergy 2013, 94, 305–326. [CrossRef]\n24.\n\
    Hao, Y.; Tian, C. A novel two-stage forecasting model based on error factor and\
    \ ensemble method for multi-step wind power\nforecasting. Appl. Energy 2019, 238,\
    \ 368–383. [CrossRef]\n25.\nSingh, S.; Mohapatra, A. Repeated wavelet transform\
    \ based ARIMA model for very short-term wind speed forecasting. Renew.\nEnergy\
    \ 2019, 136, 758–768.\n26.\nHuang, J.; Korolkiewicz, M.; Agrawal, M.; Boland,\
    \ J. Forecasting solar radiation on an hourly time scale using a Coupled\nAutoRegressive\
    \ and Dynamical System (CARDS) model. Sol. Energy 2013, 87, 136–149. [CrossRef]\n\
    27.\nReikard, G. Predicting solar radiation at high resolutions: A comparison\
    \ of time series forecasts. Sol. Energy 2009, 83, 342–349.\n[CrossRef]\n28.\n\
    Kumari, P.; Toshniwal, D. Real-time estimation of COVID-19 cases using machine\
    \ learning and mathematical models—The case\nof India. In Proceedings of the 2020\
    \ IEEE 15th International Conference on Industrial and Information Systems (ICIIS),\
    \ Rupnagar,\nIndia, 26–28 November 2020; pp. 369–374.\n29.\nLee, J.; Wang, W.;\
    \ Harrou, F.; Sun, Y. Reliable solar irradiance prediction using ensemble learning-based\
    \ models: A comparative\nstudy. Energy Convers. Manag. 2020, 208, 112582. [CrossRef]\n\
    30.\nBouzgou, H.; Gueymard, C.A. Minimum redundancy–maximum relevance with extreme\
    \ learning machines for global solar\nradiation forecasting: Toward an optimized\
    \ dimensionality reduction for solar time series. Sol. Energy 2017, 158, 595–609.\n\
    [CrossRef]\n31.\nHou, K.; Shao, G.; Wang, H.; Zheng, L.; Zhang, Q.; Wu, S.; Hu,\
    \ W. Research on practical power system stability analysis algorithm\nbased on\
    \ modiﬁed SVM. Prot. Control Mod. Power Syst. 2018, 3, 11. [CrossRef]\nAppl. Sci.\
    \ 2023, 13, 8332\n38 of 43\n32.\nZhang, T.; Lv, C.; Ma, F.; Zhao, K.; Wang, H.;\
    \ O’Hare, G.M. A photovoltaic power forecasting model based on dendritic neuron\n\
    networks with the aid of wavelet transform. Neurocomputing 2020, 397, 438–446.\
    \ [CrossRef]\n33.\nWang, F.; Zhang, Z.; Liu, C.; Yu, Y.; Pang, S.; Dui´c, N.;\
    \ Shaﬁe-Khah, M.; Catalão, J.P. Generative adversarial networks and\nconvolutional\
    \ neural networks based weather classiﬁcation model for day ahead short-term photovoltaic\
    \ power forecasting.\nEnergy Convers. Manag. 2019, 181, 443–462. [CrossRef]\n\
    34.\nMcCandless, T.; Haupt, S.; Young, G. A regime-dependent artiﬁcial neural\
    \ network technique for short-range solar irradiance\nforecasting. Renew. Energy\
    \ 2016, 89, 351–359. [CrossRef]\n35.\nAlKandari, M.; Ahmad, I. Solar power generation\
    \ forecasting using ensemble approach based on deep learning and statistical\n\
    methods. Appl. Comput. Inform. 2020, 2020, 1–20. [CrossRef]\n36.\nRamli, M.A.;\
    \ Twaha, S.; Al-Turki, Y.A. Investigating the performance of support vector machine\
    \ and artiﬁcial neural networks in\npredicting solar radiation on a tilted surface:\
    \ Saudi Arabia case study. Energy Convers. Manag. 2015, 105, 442–452. [CrossRef]\n\
    37.\nZang, H.; Cheng, L.; Ding, T.; Cheung, K.W.; Wei, Z.; Sun, G. Day-ahead photovoltaic\
    \ power forecasting approach based on deep\nconvolutional neural networks and\
    \ meta learning. Int. J. Electr. Power Energy Syst. 2020, 118, 105790. [CrossRef]\n\
    38.\nSingh, P.; Singh, N.K.; Singh, A.K. Solar Photovoltaic Energy Forecasting\
    \ Using Machine Learning and Deep Learning Technique.\nIn Proceedings of the 2022\
    \ IEEE 9th Uttar Pradesh Section International Conference on Electrical, Electronics\
    \ and Computer\nEngineering (UPCON), Prayagraj, India, 2–4 December 2022; pp.\
    \ 1–6.\n39.\nWang, Z.; Hong, T.; Piette, M.A. Building thermal load prediction\
    \ through shallow machine learning and deep learning. Appl.\nEnergy 2020, 263,\
    \ 114683. [CrossRef]\n40.\nLi, L.; Yuan, Z.; Gao, Y. Maximization of energy absorption\
    \ for a wave energy converter using the deep machine learning. Energy\n2018, 165,\
    \ 340–349. [CrossRef]\n41.\nHu, Q.; Zhang, R.; Zhou, Y. Transfer learning for\
    \ short-term wind speed prediction with deep neural networks. Renew. Energy\n\
    2016, 85, 83–95. [CrossRef]\n42.\nMishra, M.; Dash, P.B.; Nayak, J.; Naik, B.;\
    \ Swain, S.K. Deep learning and wavelet transform integrated approach for short-term\n\
    solar PV power prediction. Measurement 2020, 166, 108250. [CrossRef]\n43.\nQing,\
    \ X.; Niu, Y. Hourly day-ahead solar irradiance prediction using weather forecasts\
    \ by LSTM. Energy 2018, 148, 461–468.\n[CrossRef]\n44.\nKuremoto, T.; Kimura,\
    \ S.; Kobayashi, K.; Obayashi, M. Time series forecasting using a deep belief\
    \ network with restricted\nBoltzmann machines. Neurocomputing 2014, 137, 47–56.\
    \ [CrossRef]\n45.\nKaba, K.; Sarıgül, M.; Avcı, M.; Kandırmaz, H.M. Estimation\
    \ of daily global solar radiation using deep learning model. Energy\n2018, 162,\
    \ 126–135. [CrossRef]\n46.\nYadav, A.K.; Chandel, S. Solar radiation prediction\
    \ using Artiﬁcial Neural Network techniques: A review. Renew. Sustain. Energy\n\
    Rev. 2014, 33, 772–781. [CrossRef]\n47.\nPazikadin, A.R.; Rifai, D.; Ali, K.;\
    \ Malik, M.Z.; Abdalla, A.N.; Faraj, M.A. Solar irradiance measurement instrumentation\
    \ and\npower solar generation forecasting based on Artiﬁcial Neural Networks (ANN):\
    \ A review of ﬁve years research trend. Sci. Total\nEnviron. 2020, 715, 136848.\
    \ [CrossRef]\n48.\nVoyant, C.; Notton, G.; Kalogirou, S.; Nivet, M.-L.; Paoli,\
    \ C.; Motte, F.; Fouilloy, A. Machine learning methods for solar radiation\nforecasting:\
    \ A review. Renew. Energy 2017, 105, 569–582. [CrossRef]\n49.\nZang, H.; Liu,\
    \ L.; Sun, L.; Cheng, L.; Wei, Z.; Sun, G. Short-term global horizontal irradiance\
    \ forecasting based on a hybrid\nCNN-LSTM model with spatiotemporal correlations.\
    \ Renew. Energy 2020, 160, 26–41. [CrossRef]\n50.\nAntonanzas-Torres, F.; Urraca,\
    \ R.; Polo, J.; Perpiñán-Lamigueiro, O.; Escobar, R. Clear sky solar irradiance\
    \ models: A review of\nseventy models. Renew. Sustain. Energy Rev. 2019, 107,\
    \ 374–387. [CrossRef]\n51.\nAntonanzas, J.; Osorio, N.; Escobar, R.; Urraca, R.;\
    \ Martinez-de-Pison, F.J.; Antonanzas-Torres, F. Review of photovoltaic power\n\
    forecasting. Sol. Energy 2016, 136, 78–111. [CrossRef]\n52.\nEngerer, N. Minute\
    \ resolution estimates of the diffuse fraction of global irradiance for southeastern\
    \ Australia. Sol. Energy 2015,\n116, 215–237. [CrossRef]\n53.\nOlatomiwa, L.;\
    \ Mekhilef, S.; Shamshirband, S.; Mohammadi, K.; Petkovi´c, D.; Sudheer, C. A\
    \ support vector machine–ﬁreﬂy\nalgorithm-based model for global solar radiation\
    \ prediction. Sol. Energy 2015, 115, 632–644. [CrossRef]\n54.\nHeng, J.; Wang,\
    \ J.; Xiao, L.; Lu, H. Research and application of a combined model based on frequent\
    \ pattern growth algorithm\nand multi-objective optimization for solar radiation\
    \ forecasting. Appl. Energy 2017, 208, 845–866. [CrossRef]\n55.\nKaushika, N.;\
    \ Tomar, R.; Kaushik, S. Artiﬁcial neural network model based on interrelationship\
    \ of direct, diffuse and global solar\nradiations. Sol. Energy 2014, 103, 327–342.\
    \ [CrossRef]\n56.\nJiang, Y. Prediction of monthly mean daily diffuse solar radiation\
    \ using artiﬁcial neural networks and comparison with other\nempirical models.\
    \ Energy Policy 2008, 36, 3833–3837. [CrossRef]\n57.\nHong, T.; Wilson, J.; Xie,\
    \ J. Long term probabilistic load forecasting and normalization with hourly information.\
    \ IEEE Trans. Smart\nGrid 2013, 5, 456–462. [CrossRef]\n58.\nPerez, R.; Kivalov,\
    \ S.; Schlemmer, J.; Hemker, K., Jr.; Renné, D.; Hoff, T.E. Validation of short\
    \ and medium term operational solar\nradiation forecasts in the US. Sol. Energy\
    \ 2010, 84, 2161–2172. [CrossRef]\n59.\nLi, J.; Ward, J.K.; Tong, J.; Collins,\
    \ L.; Platt, G. Machine learning for solar irradiance forecasting of photovoltaic\
    \ system. Renew.\nEnergy 2016, 90, 542–553. [CrossRef]\nAppl. Sci. 2023, 13, 8332\n\
    39 of 43\n60.\nWang, Z.; Tian, C.; Zhu, Q.; Huang, M. Hourly solar radiation forecasting\
    \ using a volterra-least squares support vector machine\nmodel combined with signal\
    \ decomposition. Energies 2018, 11, 68. [CrossRef]\n61.\nDong, Z.; Yang, D.; Reindl,\
    \ T.; Walsh, W.M. A novel hybrid approach based on self-organizing maps, support\
    \ vector regression\nand particle swarm optimization to forecast solar irradiance.\
    \ Energy 2015, 82, 570–577. [CrossRef]\n62.\nRoyer, J.C.; Wilhelm, V.E.; Junior,\
    \ L.A.T.; Franco, E.M.C. Short-term solar radiation forecasting by using an iterative\
    \ combination\nof wavelet artiﬁcial neural networks. Indep. J. Manag. Prod. 2016,\
    \ 7, 271–288. [CrossRef]\n63.\nBae, K.Y.; Jang, H.S.; Sung, D.K. Hourly solar\
    \ irradiance prediction based on support vector machine and its error analysis.\
    \ IEEE\nTrans. Power Syst. 2016, 32, 935–945. [CrossRef]\n64.\nKwon, Y.; Kwasinski,\
    \ A.; Kwasinski, A. Solar irradiance forecast using naïve Bayes classiﬁer based\
    \ on publicly available weather\nforecasting variables. Energies 2019, 12, 1529.\
    \ [CrossRef]\n65.\nYu, Y.; Cao, J.; Zhu, J. An LSTM short-term solar irradiance\
    \ forecasting under complicated weather conditions. IEEE Access 2019,\n7, 145651–145666.\
    \ [CrossRef]\n66.\nWang, F.; Zhen, Z.; Mi, Z.; Sun, H.; Su, S.; Yang, G. Solar\
    \ irradiance feature extraction and support vector machines based weather\nstatus\
    \ pattern recognition model for short-term photovoltaic power forecasting. Energy\
    \ Build. 2015, 86, 427–438. [CrossRef]\n67.\nWang, F.; Yu, Y.; Zhang, Z.; Li,\
    \ J.; Zhen, Z.; Li, K. Wavelet decomposition and convolutional LSTM networks based\
    \ improved deep\nlearning model for solar irradiance forecasting. Appl. Sci. 2018,\
    \ 8, 1286. [CrossRef]\n68.\nAkarslan, E.; Hocaoglu, F.O.; Edizkan, R. Novel short\
    \ term solar irradiance forecasting models. Renew. Energy 2018, 123, 58–66.\n\
    [CrossRef]\n69.\nWang, W.; Zhen, Z.; Li, K.; Lv, K.; Wang, F. An ultra-short-term\
    \ forecasting model for high-resolution solar irradiance based on\nSOM and deep\
    \ learning algorithm. In Proceedings of the 2019 IEEE Sustainable Power and Energy\
    \ Conference (iSPEC), Beijing,\nChina, 21–23 November 2019; pp. 1090–1095.\n70.\n\
    Lima, F.J.; Martins, F.R.; Pereira, E.B.; Lorenz, E.; Heinemann, D. Forecast for\
    \ surface solar irradiance at the Brazilian Northeastern\nregion using NWP model\
    \ and artiﬁcial neural networks. Renew. Energy 2016, 87, 807–818. [CrossRef]\n\
    71.\nStehman, S.V. Selecting and interpreting measures of thematic classiﬁcation\
    \ accuracy. Remote Sens. Environ. 1997, 62, 77–89.\n[CrossRef]\n72.\nWang, F.;\
    \ Zhen, Z.; Liu, C.; Mi, Z.; Shaﬁe-khah, M.; Catalão, J.P. Time-section fusion\
    \ pattern classiﬁcation based day-ahead solar\nirradiance ensemble forecasting\
    \ model using mutual iterative optimization. Energies 2018, 11, 184. [CrossRef]\n\
    73.\nNann, S.; Riordan, C. Solar spectral irradiance under clear and cloudy skies:\
    \ Measurements and a semiempirical model. J. Appl.\nMeteorol. Climatol. 1991,\
    \ 30, 447–462. [CrossRef]\n74.\nAguiar, L.M.; Pereira, B.; Lauret, P.; Díaz, F.;\
    \ David, M. Combining solar irradiance measurements, satellite-derived data and\
    \ a\nnumerical weather prediction model to improve intra-day solar forecasting.\
    \ Renew. Energy 2016, 97, 599–610. [CrossRef]\n75.\nKumari, P.; Wadhvani, R. Wind\
    \ power prediction using klms algorithm. In Proceedings of the 2018 International\
    \ Conference on\nInventive Research in Computing Applications (ICIRCA), Coimbatore,\
    \ India, 11–12 July 2018; pp. 154–161.\n76.\nGutierrez-Corea, F.-V.; Manso-Callejo,\
    \ M.-A.; Moreno-Regidor, M.-P.; Manrique-Sancho, M.-T. Forecasting short-term\
    \ solar\nirradiance based on artiﬁcial neural networks and data from neighboring\
    \ meteorological stations. Sol. Energy 2016, 134, 119–131.\n[CrossRef]\n77.\n\
    Ozgoren, M.; Bilgili, M.; Sahin, B. Estimation of global solar radiation using\
    \ ANN over Turkey. Expert Syst. Appl. 2012, 39,\n5043–5051. [CrossRef]\n78.\n\
    Shaddel, M.; Javan, D.S.; Baghernia, P. Estimation of hourly global solar irradiation\
    \ on tilted absorbers from horizontal one using\nArtiﬁcial Neural Network for\
    \ case study of Mashhad. Renew. Sustain. Energy Rev. 2016, 53, 59–67. [CrossRef]\n\
    79.\nYagli, G.M.; Yang, D.; Srinivasan, D. Automatic hourly solar forecasting\
    \ using machine learning models. Renew. Sustain. Energy\nRev. 2019, 105, 487–498.\
    \ [CrossRef]\n80.\nBashir, Z.; El-Hawary, M. Applying wavelets to short-term load\
    \ forecasting using PSO-based neural networks. IEEE Trans. Power\nSyst. 2009,\
    \ 24, 20–27. [CrossRef]\n81.\nBao, Y.; Liu, Z. A fast grid search method in support\
    \ vector regression forecasting time series. In Proceedings of the International\n\
    Conference on Intelligent Data Engineering and Automated Learning, Burgos, Spain,\
    \ 20–23 September 2006; pp. 504–511.\n82.\nLi, H.; Guo, S.; Zhao, H.; Su, C.;\
    \ Wang, B. Annual electric load forecasting by a least squares support vector\
    \ machine with a fruit\nﬂy optimization algorithm. Energies 2012, 5, 4430–4445.\
    \ [CrossRef]\n83.\nNiu, D.; Wang, Y.; Wu, D.D. Power load forecasting using support\
    \ vector machine and ant colony optimization. Expert Syst. Appl.\n2010, 37, 2531–2539.\
    \ [CrossRef]\n84.\nHong, W.-C. Application of chaotic ant swarm optimization in\
    \ electric load forecasting. Energy Policy 2010, 38, 5830–5839.\n[CrossRef]\n\
    85.\nHong, W.-C. Electric load forecasting by seasonal recurrent SVR (support\
    \ vector regression) with chaotic artiﬁcial bee colony\nalgorithm. Energy 2011,\
    \ 36, 5568–5578. [CrossRef]\n86.\nHong, W.-C. Electric load forecasting by support\
    \ vector model. Appl. Math. Model. 2009, 33, 2444–2454. [CrossRef]\n87.\nTao,\
    \ Y.; Chen, Y. Distributed PV power forecasting using genetic algorithm based\
    \ neural network approach. In Proceedings of the\n2014 International Conference\
    \ on Advanced Mechatronic Systems, Kumamoto, Japan, 10–12 August 2014; pp. 557–560.\n\
    88.\nPedro, H.T.; Coimbra, C.F. Assessment of forecasting techniques for solar\
    \ power production with no exogenous inputs. Sol.\nEnergy 2012, 86, 2017–2028.\
    \ [CrossRef]\nAppl. Sci. 2023, 13, 8332\n40 of 43\n89.\nZhen, Z.; Pang, S.; Wang,\
    \ F.; Li, K.; Li, Z.; Ren, H.; Shaﬁe-khah, M.; Catalão, J.P. Pattern classiﬁcation\
    \ and PSO optimal weights\nbased sky images cloud motion speed calculation method\
    \ for solar PV power forecasting. IEEE Trans. Ind. Appl. 2019, 55,\n3331–3342.\
    \ [CrossRef]\n90.\nWang, F.; Zhou, L.; Ren, H.; Liu, X. Search improvement process-chaotic\
    \ optimization-particle swarm optimization-elite retention\nstrategy and improved\
    \ combined cooling-heating-power strategy based two-time scale multi-objective\
    \ optimization model for\nstand-alone microgrid operation. Energies 2017, 10,\
    \ 1936. [CrossRef]\n91.\nWang, F.; Zhou, L.; Wang, B.; Wang, Z.; Shaﬁe-Khah, M.;\
    \ Catalão, J.P. Modiﬁed chaos particle swarm optimization-based\noptimized operation\
    \ model for stand-alone CCHP microgrid. Appl. Sci. 2017, 7, 754. [CrossRef]\n\
    92.\nMellit, A.; Kalogirou, S.A. Artiﬁcial intelligence techniques for photovoltaic\
    \ applications: A review. Prog. Energy Combust. Sci.\n2008, 34, 574–632. [CrossRef]\n\
    93.\nLee, J.-T.; Kim, H.-G.; Kang, Y.-H.; Yun, C.-Y.; Kim, C.K.; Kim, B.-Y.; Kim,\
    \ J.-Y.; Park, Y.Y.; Kim, T.H.; Jo, H.N. Trend Review of\nSolar Energy Forecasting\
    \ Technique. J. Korean Sol. Energy Soc. 2019, 39, 41–54.\n94.\nRajagukguk, R.A.;\
    \ Ramadhan, R.A.; Lee, H.-J. A review on deep learning models for forecasting\
    \ time series data of solar irradiance\nand photovoltaic power. Energies 2020,\
    \ 13, 6623. [CrossRef]\n95.\nHameed, W.I.; Sawadi, B.A.; Al-Kamil, S.J.; Al-Radhi,\
    \ M.S.; Al-Yasir, Y.I.; Saleh, A.L.; Abd-Alhameed, R.A. Prediction of solar\n\
    irradiance based on artiﬁcial neural networks. Inventions 2019, 4, 45. [CrossRef]\n\
    96.\nPaoli, C.; Voyant, C.; Muselli, M.; Nivet, M.-L. Forecasting of preprocessed\
    \ daily solar radiation time series using neural networks.\nSol. Energy 2010,\
    \ 84, 2146–2160. [CrossRef]\n97.\nKehl, C.; Varbanescu, A.L. Towards Distributed,\
    \ Semi-Automatic Content-Based Visual Information Retrieval (CBVIR) of Massive\n\
    Media Archives. Adv. Neural Inf. Process. Syst. 2012, 2012, 1097–1105.\n98.\n\
    Yamashita, R.; Nishio, M.; Do, R.K.G.; Togashi, K. Convolutional neural networks:\
    \ An overview and application in radiology.\nInsights Into Imaging 2018, 9, 611–629.\
    \ [CrossRef]\n99.\nLi, G.; Wu, S.X.; Zhang, S.; Li, Q. Detect insider attacks\
    \ using CNN in decentralized optimization. In Proceedings of the ICASSP\n2020—2020\
    \ IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP),\
    \ Barcelona, Spain, 4–8 May 2020;\npp. 8758–8762.\n100. Gu, J.; Wang, Z.; Kuen,\
    \ J.; Ma, L.; Shahroudy, A.; Shuai, B.; Liu, T.; Wang, X.; Wang, G.; Cai, J. Recent\
    \ advances in convolutional\nneural networks. Pattern Recognit. 2018, 77, 354–377.\
    \ [CrossRef]\n101. Zhou, D.-X. Universality of deep convolutional neural networks.\
    \ Appl. Comput. Harmon. Anal. 2020, 48, 787–794. [CrossRef]\n102. Kumari, P.;\
    \ Toshniwal, D. Long short term memory–convolutional neural network based deep\
    \ hybrid approach for solar\nirradiance forecasting. Appl. Energy 2021, 295, 117061.\
    \ [CrossRef]\n103. Hüsken, M.; Stagge, P. Recurrent neural networks for time series\
    \ classiﬁcation. Neurocomputing 2003, 50, 223–235. [CrossRef]\n104. Hochreiter,\
    \ S.; Schmidhuber, J. Long short-term memory. Neural Comput. 1997, 9, 1735–1780.\
    \ [CrossRef] [PubMed]\n105. Bandara, K.; Bergmeir, C.; Smyl, S. Forecasting across\
    \ time series databases using recurrent neural networks on groups of similar\n\
    series: A clustering approach. Expert Syst. Appl. 2020, 140, 112896. [CrossRef]\n\
    106. Liu, Y.; Guan, L.; Hou, C.; Han, H.; Liu, Z.; Sun, Y.; Zheng, M. Wind power\
    \ short-term prediction based on LSTM and discrete\nwavelet transform. Appl. Sci.\
    \ 2019, 9, 1108. [CrossRef]\n107. Srivastava, S.; Lessmann, S. A comparative study\
    \ of LSTM neural networks in forecasting day-ahead global horizontal irradiance\n\
    with satellite data. Sol. Energy 2018, 162, 232–247. [CrossRef]\n108. Cho, K.;\
    \ Van Merriënboer, B.; Gulcehre, C.; Bahdanau, D.; Bougares, F.; Schwenk, H.;\
    \ Bengio, Y. Learning phrase representations\nusing RNN encoder-decoder for statistical\
    \ machine translation. arXiv 2014, arXiv:1406.1078.\n109. Schuster, M.; Paliwal,\
    \ K.K. Bidirectional recurrent neural networks. IEEE Trans. Signal Process. 1997,\
    \ 45, 2673–2681. [CrossRef]\n110. Ogawa, A.; Hori, T. Error detection and accuracy\
    \ estimation in automatic speech recognition using deep bidirectional recurrent\n\
    neural networks. Speech Commun. 2017, 89, 70–83. [CrossRef]\n111. Hinton, G.E.;\
    \ Osindero, S.; Teh, Y.-W. A fast learning algorithm for deep belief nets. Neural\
    \ Comput. 2006, 18, 1527–1554. [CrossRef]\n112. Chen, Y.; Zhao, X.; Jia, X. Spectral–spatial\
    \ classiﬁcation of hyperspectral data based on deep belief network. IEEE J. Sel.\
    \ Top. Appl.\nEarth Obs. Remote Sens. 2015, 8, 2381–2392. [CrossRef]\n113. Lee,\
    \ H.; Ekanadham, C.; Ng, A. Sparse deep belief net model for visual area V2. Adv.\
    \ Neural Inf. Process. Syst. 2007, 20, 1–8.\n114. Qiao, J.; Wang, G.; Li, W.;\
    \ Li, X. A deep belief network with PLSR for nonlinear system modeling. Neural\
    \ Netw. 2018, 104, 68–79.\n[CrossRef] [PubMed]\n115. Bahdanau, D.; Cho, K.; Bengio,\
    \ Y. Neural machine translation by jointly learning to align and translate. arXiv\
    \ 2014, arXiv:1409.0473.\n116. Sutskever, I.; Vinyals, O.; Le, Q.V. Sequence to\
    \ sequence learning with neural networks. Adv. Neural Inf. Process. Syst. 2014,\
    \ 27,\n777–780.\n117. Choi, H.; Cho, K.; Bengio, Y. Fine-grained attention mechanism\
    \ for neural machine translation. Neurocomputing 2018, 284, 171–176.\n[CrossRef]\n\
    118. Song, K.; Yao, T.; Ling, Q.; Mei, T. Boosting image sentiment analysis with\
    \ visual attention. Neurocomputing 2018, 312, 218–228.\n[CrossRef]\n119. Li, W.;\
    \ Guo, D.; Fang, X. Multimodal architecture for video captioning with memory networks\
    \ and an attention mechanism.\nPattern Recognit. Lett. 2018, 105, 23–29. [CrossRef]\n\
    Appl. Sci. 2023, 13, 8332\n41 of 43\n120. Goodfellow, I.; Pouget-Abadie, J.; Mirza,\
    \ M.; Xu, B.; Warde-Farley, D.; Ozair, S.; Courville, A.; Bengio, Y. Generative\
    \ adversarial\nnetworks. Commun. ACM 2020, 63, 139–144. [CrossRef]\n121. Radford,\
    \ A.; Metz, L.; Chintala, S. Unsupervised representation learning with deep convolutional\
    \ generative adversarial networks.\narXiv 2015, arXiv:1511.06434.\n122. Wang,\
    \ Y.; Li, H. A novel intelligent modeling framework integrating convolutional\
    \ neural network with an adaptive time-series\nwindow and its application to industrial\
    \ process operational optimization. Chemom. Intell. Lab. Syst. 2018, 179, 64–72.\
    \ [CrossRef]\n123. Creswell, A.; White, T.; Dumoulin, V.; Arulkumaran, K.; Sengupta,\
    \ B.; Bharath, A.A. Generative adversarial networks: An\noverview. IEEE Signal\
    \ Process. Mag. 2018, 35, 53–65. [CrossRef]\n124. Mirza, M.; Osindero, S. Conditional\
    \ generative adversarial nets. arXiv 2014, arXiv:1411.1784.\n125. Muhammad, A.;\
    \ Lee, J.M.; Hong, S.W.; Lee, S.J.; Lee, E.H. Deep learning application in power\
    \ system with a case study on\nsolar irradiation forecasting. In Proceedings of\
    \ the 2019 International Conference on Artiﬁcial Intelligence in Information and\n\
    Communication (ICAIIC), Okinawa, Japan, 11–13 February 2019; pp. 275–279.\n126.\
    \ Chandola, D.; Gupta, H.; Tikkiwal, V.A.; Bohra, M.K. Multi-step ahead forecasting\
    \ of global solar radiation for arid zones using\ndeep learning. Procedia Comput.\
    \ Sci. 2020, 167, 626–635. [CrossRef]\n127. Jeon, B.-k.; Kim, E.-J. Next-day prediction\
    \ of hourly solar irradiance using local weather forecasts and LSTM trained with\n\
    non-local data. Energies 2020, 13, 5258. [CrossRef]\n128. Sorkun, M.C.; Paoli,\
    \ C.; Incel, Ö.D. Time series forecasting on solar irradiation using deep learning.\
    \ In Proceedings of the 2017\n10th International Conference on Electrical and\
    \ Electronics Engineering (ELECO), Bursa, Turkey, 30 November–2 December 2017;\n\
    pp. 151–155.\n129. Alzahrani, A.; Shamsi, P.; Dagli, C.; Ferdowsi, M. Solar irradiance\
    \ forecasting using deep neural networks. Procedia Comput. Sci.\n2017, 114, 304–313.\
    \ [CrossRef]\n130. Alzahrani, A.; Shamsi, P.; Ferdowsi, M.; Dagli, C. Solar irradiance\
    \ forecasting using deep recurrent neural networks. In\nProceedings of the 2017\
    \ IEEE 6th International Conference on Renewable Energy Research and Applications\
    \ (ICRERA), San\nDiego, CA, USA, 5–8 November 2017; pp. 988–994.\n131. Obiora,\
    \ C.N.; Ali, A.; Hasan, A.N. Forecasting Hourly Solar Irradiance Using Long Short-Term\
    \ Memory (LSTM) Network. In\nProceedings of the 2020 11th International Renewable\
    \ Energy Congress (IREC), Hammamet, Tunisia, 29–31 October 2020; pp. 1–6.\n132.\
    \ Chu, T.-P.; Jhou, J.-H.; Leu, Y.-G. Image-based Solar Irradiance Forecasting\
    \ Using Recurrent Neural Networks. In Proceedings of\nthe 2020 International Conference\
    \ on System Science and Engineering (ICSSE), Kagawa, Japan, 31 August–3 September\
    \ 2020;\npp. 1–4.\n133. Mukherjee, A.; Ain, A.; Dasgupta, P. Solar irradiance\
    \ prediction from historical trends using deep neural networks. In Proceedings\n\
    of the 2018 IEEE International Conference on Smart Energy Grid Engineering (SEGE),\
    \ Ottawa, ON, Canada, 12–15 August 2018;\npp. 356–361.\n134. Ashfaq, Q.; Ulasyar,\
    \ A.; Zad, H.S.; Khattak, A.; Imran, K. Hour-ahead global horizontal irradiance\
    \ forecasting using long short\nterm memory network. In Proceedings of the 2020\
    \ IEEE 23rd International Multitopic Conference (INMIC), Bahawalpur, Pakistan,\n\
    5–7 November 2020; pp. 1–6.\n135. Justin, D.; Concepcion, R.S.; Calinao, H.A.;\
    \ Alejandrino, J.; Dadios, E.P.; Sybingco, E. Using stacked long short term memory\
    \ with\nprincipal component analysis for short term prediction of solar irradiance\
    \ based on weather patterns. In Proceedings of the 2020\nIEEE Region 10 Conference\
    \ (TENCON), Osaka, Japan, 16–19 November 2020; pp. 946–951.\n136. Fernando, W.;\
    \ Jayalath, W.; Kanagasundaram, A.; Valluvan, R. Solar Irradiance Forecasting\
    \ Using Deep Learning Approaches; Research\nRepository; University of Jaffna:\
    \ Kokuvil East, Sri Lanka, 2019.\n137. Mishra, S.; Palanisamy, P. An integrated\
    \ multi-time-scale modeling for solar irradiance forecasting using deep learning.\
    \ arXiv\n2019, arXiv:1905.02616.\n138. Hossain, M.S.; Mahmood, H. Short-term photovoltaic\
    \ power forecasting using an LSTM neural network and synthetic weather\nforecast.\
    \ IEEE Access 2020, 8, 172524–172533. [CrossRef]\n139. Zhao, X.; Wei, H.; Wang,\
    \ H.; Zhu, T.; Zhang, K. 3D-CNN-based feature extraction of ground-based cloud\
    \ images for direct normal\nirradiance prediction. Sol. Energy 2019, 181, 510–518.\
    \ [CrossRef]\n140. Feng, C.; Zhang, J. SolarNet: A sky image-based deep convolutional\
    \ neural network for intra-hour solar forecasting. Sol. Energy\n2020, 204, 71–78.\
    \ [CrossRef]\n141. Wojtkiewicz, J.; Hosseini, M.; Gottumukkala, R.; Chambers,\
    \ T.L. Hour-ahead solar irradiance forecasting using multivariate gated\nrecurrent\
    \ units. Energies 2019, 12, 4055. [CrossRef]\n142. Yan, K.; Shen, H.; Wang, L.;\
    \ Zhou, H.; Xu, M.; Mo, Y. Short-term solar irradiance forecasting based on a\
    \ hybrid deep learning\nmethodology. Information 2020, 11, 32. [CrossRef]\n143.\
    \ Mukhoty, B.P.; Maurya, V.; Shukla, S.K. Sequence to sequence deep learning models\
    \ for solar irradiation forecasting. In\nProceedings of the 2019 IEEE Milan PowerTech,\
    \ Milano, Italy, 23–27 June 2019; pp. 1–6.\n144. Li, Q.; Wu, Z.; Ling, R.; Feng,\
    \ L.; Liu, K. Multi-reservoir echo state computing for solar irradiance prediction:\
    \ A fast yet efﬁcient\ndeep learning approach. Appl. Soft Comput. 2020, 95, 106481.\
    \ [CrossRef]\n145. Pang, Z.; Niu, F.; O’Neill, Z. Solar radiation prediction using\
    \ recurrent neural network and artiﬁcial neural network: A case study\nwith comparisons.\
    \ Renew. Energy 2020, 156, 279–289. [CrossRef]\nAppl. Sci. 2023, 13, 8332\n42\
    \ of 43\n146. Zang, H.; Cheng, L.; Ding, T.; Cheung, K.W.; Wang, M.; Wei, Z.;\
    \ Sun, G. Application of functional deep belief network for\nestimating daily\
    \ global solar radiation: A case study in China. Energy 2020, 191, 116502. [CrossRef]\n\
    147. Li, Z.; Wang, K.; Li, C.; Zhao, M.; Cao, J. Multimodal deep learning for\
    \ solar irradiance prediction. In Proceedings of the 2019\nInternational Conference\
    \ on Internet of Things (iThings) and IEEE Green Computing and Communications\
    \ (GreenCom) and\nIEEE Cyber, Physical and Social Computing (CPSCom) and IEEE\
    \ Smart Data (SmartData), Atlanta, GA, USA, 14–17 July 2019;\npp. 784–792.\n148.\
    \ Lago, J.; De Brabandere, K.; De Ridder, F.; De Schutter, B. Short-term forecasting\
    \ of solar irradiance without local telemetry: A\ngeneralized model using satellite\
    \ data. Sol. Energy 2018, 173, 566–577. [CrossRef]\n149. Peng, T.; Zhang, C.;\
    \ Zhou, J.; Nazir, M.S. An integrated framework of Bi-directional long-short term\
    \ memory (BiLSTM) based on\nsine cosine algorithm for hourly solar radiation forecasting.\
    \ Energy 2021, 221, 119887. [CrossRef]\n150. Brahma, B.; Wadhvani, R. Solar irradiance\
    \ forecasting based on deep learning methodologies and multi-site data. Symmetry\
    \ 2020,\n12, 1830. [CrossRef]\n151. Li, Q.; Wu, Z.; Zhang, H. Spatio-temporal\
    \ modeling with enhanced ﬂexibility and robustness of solar irradiance prediction:\
    \ A\nchain-structure echo state network approach. J. Clean. Prod. 2020, 261, 121151.\
    \ [CrossRef]\n152. Andrianakos, G.; Tsourounis, D.; Oikonomou, S.; Kastaniotis,\
    \ D.; Economou, G.; Kazantzidis, A. Sky Image forecasting with\nGenerative Adversarial\
    \ Networks for cloud coverage prediction. In Proceedings of the 2019 10th International\
    \ Conference on\nInformation, Intelligence, Systems and Applications (IISA), Patras,\
    \ Greece, 15–17 July 2019; pp. 1–7.\n153. Prado-Rujas, I.-I.; García-Dopico, A.;\
    \ Serrano, E.; Pérez, M.S. A ﬂexible and robust deep learning-based system for\
    \ solar irradiance\nforecasting. IEEE Access 2021, 9, 12348–12361. [CrossRef]\n\
    154. Yeom, J.-M.; Deo, R.C.; Adamowski, J.F.; Park, S.; Lee, C.-S. Spatial mapping\
    \ of short-term solar radiation prediction incorporating\ngeostationary satellite\
    \ images coupled with deep convolutional LSTM networks for South Korea. Environ.\
    \ Res. Lett. 2020, 15, 094025.\n[CrossRef]\n155. Ziyabari, S.; Du, L.; Biswas,\
    \ S. A spatio-temporal hybrid deep learning architecture for short-term solar\
    \ irradiance forecasting. In\nProceedings of the 2020 47th IEEE Photovoltaic Specialists\
    \ Conference (PVSC), Calgary, AB, Canada, 15 June–21 August 2020;\npp. 0833–0838.\n\
    156. Ghimire, S.; Deo, R.C.; Raj, N.; Mi, J. Deep solar radiation forecasting\
    \ with convolutional neural network and long short-term\nmemory network algorithms.\
    \ Appl. Energy 2019, 253, 113541. [CrossRef]\n157. Huang, X.; Zhang, C.; Li, Q.;\
    \ Tai, Y.; Gao, B.; Shi, J. A comparison of hour-ahead solar irradiance forecasting\
    \ models based on\nLSTM network. Math. Probl. Eng. 2020, 2020, 4251517. [CrossRef]\n\
    158. Luong, M.-T.; Pham, H.; Manning, C.D. Effective approaches to attention-based\
    \ neural machine translation. arXiv 2015,\narXiv:1508.04025.\n159. He, H.; Lu,\
    \ N.; Jie, Y.; Chen, B.; Jiao, R. Probabilistic solar irradiance forecasting via\
    \ a deep learning-based hybrid approach. IEEJ\nTrans. Electr. Electron. Eng. 2020,\
    \ 15, 1604–1612. [CrossRef]\n160. Brahma, B.; Wadhvani, R.; Shukla, S. Attention\
    \ mechanism for developing wind speed and solar irradiance forecasting models.\n\
    Wind Eng. 2021, 45, 1422–1432. [CrossRef]\n161. Siddiqui, T.A.; Bharadwaj, S.;\
    \ Kalyanaraman, S. A deep learning approach to solar-irradiance forecasting in\
    \ sky-videos. In\nProceedings of the 2019 IEEE Winter Conference on Applications\
    \ of Computer Vision (WACV), Waikoloa Village, HI, USA, 7–11\nJanuary 2019; pp.\
    \ 2166–2174.\n162. Kumari, P.; Toshniwal, D. Extreme gradient boosting and deep\
    \ neural network based ensemble learning approach to forecast\nhourly solar irradiance.\
    \ J. Clean. Prod. 2021, 279, 123285. [CrossRef]\n163. Rai, A.; Shrivastava, A.;\
    \ Jana, K.C. A CNN-BiLSTM based deep learning model for mid-term solar radiation\
    \ prediction. Int. Trans.\nElectr. Energy Syst. 2021, 31, e12664. [CrossRef]\n\
    164. Chen, Y.; Shi, J.; Cheng, X.; Ma, X. Hybrid Models Based on LSTM and CNN\
    \ Architecture with Bayesian Optimization for\nShortTerm Photovoltaic Power Forecasting.\
    \ In Proceedings of the 2021 IEEE/IAS Industrial and Commercial Power System Asia\n\
    (I&CPS Asia), Chengdu, China, 18–21 July 2021; pp. 1415–1422.\n165. Ahmad, R.;\
    \ Kumar, R. Very Short-Term Photovoltaic (PV) Power Forecasting Using Deep Learning\
    \ (LSTMs). In Proceedings of\nthe 2021 International Conference on Intelligent\
    \ Technologies (CONIT), Grimstad, Norway, 25–27 June 2021; pp. 1–6.\n166. Li,\
    \ Y.; Ye, F.; Liu, Z.; Wang, Z.; Mao, Y. A Short-Term Photovoltaic Power Generation\
    \ Forecast Method Based on LSTM. Math.\nProbl. Eng. 2021, 2021, 6613123. [CrossRef]\n\
    167. Jebli, I.; Belouadha, F.-Z.; Kabbaj, M.I.; Tilioua, A. Deep learning based\
    \ models for solar energy prediction. Adv. Sci 2021, 6,\n349–355. [CrossRef]\n\
    168. Jalali, S.M.J.; Ahmadian, S.; Kavousi-Fard, A.; Khosravi, A.; Nahavandi,\
    \ S. Automated deep CNN-LSTM architecture design for\nsolar irradiance forecasting.\
    \ IEEE Trans. Syst. Man Cybern. Syst. 2021, 52, 54–65. [CrossRef]\n169. Wang,\
    \ K.; Qi, X.; Liu, H. Photovoltaic power forecasting based LSTM-Convolutional\
    \ Network. Energy 2019, 189, 116225.\n[CrossRef]\n170. Boubaker, S.; Benghanem,\
    \ M.; Mellit, A.; Lefza, A.; Kahouli, O.; Kolsi, L. Deep neural networks for predicting\
    \ solar radiation at\nHail Region, Saudi Arabia. IEEE Access 2021, 9, 36719–36729.\
    \ [CrossRef]\n171. Kolsi, L.; Al-Dahidi, S.; Kamel, S.; Aich, W.; Boubaker, S.;\
    \ Ben Khedher, N. Prediction of Solar Energy Yield Based on Artiﬁcial\nIntelligence\
    \ Techniques for the Ha’il Region, Saudi Arabia. Sustainability 2022, 15, 774.\
    \ [CrossRef]\nAppl. Sci. 2023, 13, 8332\n43 of 43\n172. Ghimire, S.; Deo, R.C.;\
    \ Casillas-Pérez, D.; Salcedo-Sanz, S.; Sharma, E.; Ali, M. Deep learning CNN-LSTM-MLP\
    \ hybrid fusion\nmodel for feature optimizations and daily solar radiation prediction.\
    \ Measurement 2022, 202, 111759. [CrossRef]\n173. Peng, Y.; Wang, S.; Chen, W.;\
    \ Ma, J.; Wang, C.; Chen, J. LightGBM-Integrated PV Power Prediction Based on\
    \ Multi-Resolution\nSimilarity. Processes 2023, 11, 1141. [CrossRef]\n174. Ghimire,\
    \ S.; Nguyen-Huy, T.; Prasad, R.; Deo, R.C.; Casillas-Perez, D.; Salcedo-Sanz,\
    \ S.; Bhandari, B. Hybrid convolutional neural\nnetwork-multilayer perceptron\
    \ model for solar radiation prediction. Cogn. Comput. 2023, 15, 645–671. [CrossRef]\n\
    175. Mishra, S.; Palanisamy, P. Multi-time-horizon solar forecasting using recurrent\
    \ neural network. In Proceedings of the 2018 IEEE\nEnergy Conversion Congress\
    \ and Exposition (ECCE), Portland, OR, USA, 23–27 September 2018; pp. 18–24.\n\
    176. Bendali, W.; Saber, I.; Bourachdi, B.; Boussetta, M.; Mourad, Y. Deep learning\
    \ using genetic algorithm optimization for short\nterm solar irradiance forecasting.\
    \ In Proceedings of the 2020 Fourth International Conference on Intelligent Computing\
    \ in Data\nSciences (ICDS), Fez, Morocco, 21–23 October 2020; pp. 1–8.\n177. Zhou,\
    \ H.; Zhang, Y.; Yang, L.; Liu, Q.; Yan, K.; Du, Y. Short-term photovoltaic power\
    \ forecasting based on long short term memory\nneural network and attention mechanism.\
    \ IEEE Access 2019, 7, 78063–78074. [CrossRef]\n178. Wang, H.; Lei, Z.; Zhang,\
    \ X.; Zhou, B.; Peng, J. A review of deep learning for renewable energy forecasting.\
    \ Energy Convers.\nManag. 2019, 198, 111799. [CrossRef]\nDisclaimer/Publisher’s\
    \ Note: The statements, opinions and data contained in all publications are solely\
    \ those of the individual\nauthor(s) and contributor(s) and not of MDPI and/or\
    \ the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury\
    \ to\npeople or property resulting from any ideas, methods, instructions or products\
    \ referred to in the content.\n"
  inline_citation: '>'
  journal: Applied sciences (Basel)
  limitations: '>'
  pdf_link: https://www.mdpi.com/2076-3417/13/14/8332/pdf?version=1689760331
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: A Review on Neural Network Based Models for Short Term Solar Irradiance Forecasting
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/access.2023.3251655
  analysis: '>'
  authors:
  - Yomna Gamal
  - Ahmed Soltan
  - Lobna A. Said
  - Ahmed H. Madian
  - Ahmed G. Radwan
  citation_count: 7
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Journals & Magazines >IEEE Access >Early Access Smart
    Irrigation Systems: Overview Publisher: IEEE Cite This PDF Yomna Gamal; Ahmed
    Soltan; Lobna A. Said; Ahmed H. Madian; Ahmed G. Radwan All Authors 10 Cites in
    Papers 2054 Full Text Views Open Access Comment(s) Under a Creative Commons License
    Abstract Authors Citations Keywords Metrics Abstract: Countries are collaborating
    to make agriculture more efficient by combining new technologies to improve its
    procedure. Improving irrigation efficiency in agriculture is thus critical for
    the survival of sustainable agricultural production. Smart irrigation methods
    can enhance irrigation efficiency, specially with the introduction of wireless
    communication systems, monitoring devices, and enhanced control techniques for
    efficient irrigation scheduling. The study compared on a wide range of study subjects
    to investigate scientific approaches for smart irrigation. As a result, this project
    included a wide range of topics related to irrigation methods, decision-making,
    and technology used. Information was gathered from a variety of scientific papers.
    So, our research relied on several published documents, the majority of which
    were published during the last four years, and authors from all over the world.
    In the meantime, various irrigation initiatives were given special attention.
    Following that, the evaluation focuses on the key components of smart irrigation,
    such as real-time irrigation scheduling, IoT, the importance of an internet connection,
    smart sensing, and energy harvesting. Published in: IEEE Access ( Early Access
    ) Page(s): 1 - 1 Date of Publication: 02 March 2023 Electronic ISSN: 2169-3536
    DOI: 10.1109/ACCESS.2023.3251655 Publisher: IEEE Funding Agency: Authors Citations
    Keywords Metrics More Like This Predictive Classification Model of Crop Yield
    Data Using Artificial Neural Network 2023 5th International Conference on Inventive
    Research in Computing Applications (ICIRCA) Published: 2023 Artificial Neural
    Networks and Computer Vision’s-Based Phytoindication Systems for Variable Rate
    Irrigation Improving IEEE Access Published: 2022 Show More IEEE Personal Account
    CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS
    Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL
    INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT
    & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms
    of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy
    Policy A not-for-profit organization, IEEE is the world''s largest technical professional
    organization dedicated to advancing technology for the benefit of humanity. ©
    Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE access
  limitations: '>'
  pdf_link: https://ieeexplore.ieee.org/ielx7/6287639/6514899/10057388.pdf
  publication_year: 2024
  relevance_score1: 0
  relevance_score2: 0
  title: 'Smart Irrigation Systems: Overview'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/access.2022.3206009
  analysis: '>'
  authors:
  - Arfat Ahmad Khan
  - Muhammad Asif Nauman
  - Rab Nawaz Bashir
  - Rashid Jahangir
  - Roobaea Alroobaea
  - Ahmed Binmahfoudh
  - Majed Alsafyani
  - Chitapong Wechtaisong
  citation_count: 4
  full_citation: '>'
  full_text: '>

    IEEE.org IEEE Xplore IEEE-SA IEEE Spectrum More Sites 404: Page Not Found The
    page you were looking for could not be found. Browse or search IEEE Xplore to
    continue. Email us at onlinesupport@ieee.org for further assistance. © Copyright
    2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE Access
  limitations: '>'
  pdf_link: https://ieeexplore.ieee.org/ielx7/6287639/6514899/09887960.pdf
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: Context Aware Evapotranspiration (ETs) for Saline Soils Reclamation
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.21203/rs.3.rs-830669/v1
  analysis: '>'
  authors:
  - Akanksha Gupta
  - Priyank Nahar
  citation_count: 3
  full_citation: '>'
  full_text: ">\nClassi¦cation and Yield Prediction in Smart\nAgriculture System Using\
    \ IoT\nAkanksha Gupta  (  agupta.du@yahoo.com )\nUniversity of Delhi https://orcid.org/0000-0001-7253-3648\n\
    Priyank Nahar \nVenkateshwara Institute of Management\nResearch Article\nKeywords:\
    \ IoT, Sensors, Agriculture, Machine learning, Classi¦cation, Crop yield prediction.\n\
    Posted Date: February 21st, 2022\nDOI: https://doi.org/10.21203/rs.3.rs-830669/v1\n\
    License:   This work is licensed under a Creative Commons Attribution 4.0 International\
    \ License.  \nRead Full License\nVersion of Record: A version of this preprint\
    \ was published at Journal of Ambient Intelligence and\nHumanized Computing on\
    \ January 5th, 2022. See the published version at\nhttps://doi.org/10.1007/s12652-021-03685-w.\n\
    Classification and Yield Prediction in Smart Agriculture System Using IoT \nMs.\
    \ Akanksha Gupta*, Department of computer science, University of Delhi \nEmail:\
    \ akankshagupta@ss.du.ac.in  \nDr. Priyank Nahar, Shri Venkateshwara University,\
    \ Gajraula, India. \nEmail : priyank.nahar@gmail.com\nAbstract \nThe Modern agriculture\
    \ industry is data-\ncentred, precise and smarter than ever. \nAdvanced development\
    \ of Internet-of-\nThings (IoT) based systems redesigned \n“smart agriculture”.\
    \ This emergence in \ninnovative farming systems is gradually \nenhancing \nthe\
    \ \ncrop \nyield, \nreduces \nirrigation wastages and making it more \nprofitable.\
    \ \nMachine \nlearning \n(ML) \nmethods achieve the requirement of \nscaling the\
    \ learning performance of the \nmodel. This paper introduces a hybrid ML \nmodel\
    \ with IoT for yield prediction. This \nwork \ninvolves \nthree \nphases \n: \n\
    pre-\nprocessing, \nfeature \nselection(FS) \nand \nclassification. Initially,\
    \ the dataset is pre-\nprocessed and FS is done on the basis of \nCorrelation\
    \ based FS (CBFS) and the \nVariance Inflation Factor algorithm (VIF). \nFinally,\
    \ a two-tier ML model is proposed \nfor IoT based smart agriculture system. In\
    \ \nthe first tier, the Adaptive k-Nearest \nCentroid Neighbour Classifier (aKNCN)\
    \ \nmodel is proposed to estimate the soil \nquality and classify the soil samples\
    \ into \ndifferent classes based on the input soil \nproperties. In the second\
    \ tier, the crop \nyield is predicted using the Extreme \nLearning Machine algorithm\
    \ (ELM). In the \noptimized \nstrategy, \nthe \nweights \nare \nupdated \nusing\
    \ \nmodified \nButterfly \nOptimization \nalgorithm \n(mBOA) \nto \nimprove the\
    \ performance accuracy of \nELM \nwith \nminimum \nerror \nvalues. \nPYTHON is\
    \ the implementation tool for \nevaluating the proposed system. Soil \ndataset\
    \ \nis \nutilized \nfor \nperformance \nevaluation of the proposed prediction\
    \ \nmodel. Various metrics are considered for \nthe \nperformance \nevaluation\
    \ \nsuch \nas \naccuracy, RMSE, R2, MSE, MedAE, \nMAE, MSLE, MAPE and Explained\
    \ \nVariance Score (EVS).  \nKeywords: IoT, Sensors, \nAgriculture, \nMachine\
    \ learning, Classification, Crop \nyield prediction. \nDeclarations: \nFunding\
    \ - Not applicable.\nConflicts of interest/Competing \ninterests (include appropriate\
    \ \ndisclosures) - Not applicable \nAvailability of data and material - \nAvailable\
    \ at soilhealth.dac.gov.in \nCode availability - Custom code \nEthics approval\
    \ - Not applicable \nConsent to participate - The \nparticipant has consented\
    \ to the \nsubmission of the case report to the \njournal \nConsent for publication\
    \ - \nI give my consent for the publication \nof identifiable details, which can\
    \ \ninclude photograph(s) \nand/or videos and/or case history \nand/or details\
    \ within the text to be \npublished in the Journal. \n1. Introduction \nIoT is\
    \ an advanced technology for \nmonitoring \nand \ncontrolling \ndevices \nanywhere\
    \ in the world. In many fields, it \ncreates a remarkable mark due to its easy\
    \ \naccessibility [1]. Few IoT developed \ntechnologies such as remote sensors,\
    \ \ndrones and robots made human’s life \nsimpler and beneficial. Moreover, these\
    \ \ntechnologies \nhave \nexperimented \non \nfundamental needs such as food that\
    \ is \nobtained from the agricultural field [2, 3]. \nFrom the recent survey of\
    \ World Bank, it \nis approximated that more than 50% food \nis required to cultivate\
    \ before 2050 based \non present population rate [4]. However, \nsuch huge production\
    \ of the crop is a \nchallenging task because of the current \nclimatic changes.\
    \ In such cases, Smart \nagriculture system plays a vital role to \nincrease the\
    \ yield by monitoring and \npredicting the production of the crops [5]. \nIoT\
    \ based crop yield prediction enables the \nfarmers \nto \nenhance \nproductivity.\
    \ \nIn \ngeneral, IoT based smart farming system is \ndeployed in an agriculture\
    \ field for \nmonitoring the crop field with the help of \nsensors namely DHT11\
    \ (temperature and \nhumidity sensor), TOC (Total Organic \nCarbon) and nitrogen,\
    \ phosphorus, and \npotassium (NPK) sensors [6]. Using this \nsetup, farmers can\
    \ monitor the field \nconditions from anywhere. Gateways are \nresponsible for\
    \ receiving data from the \ncrop area and forward them to the storage \nunit.\
    \ The prediction engine is used to \npredict the results and sends information\
    \ to \nthe notification server [7]. Therefore, \nvarious IoT based techniques\
    \ can assist the \nfarmers to produce huge crops and the \ntechniques used are\
    \ sensors, hydroponic \nfarming, advanced tractors and drones [8]. \nThese devices\
    \ assist agriculturists and \nresearchers in analyzing and processing \nthe data\
    \ remotely for decision making. The \nmain advantage is that these techniques\
    \ are \nlow cost; hence it is affordable for all \nfarmers [9].  \nAgricultural\
    \ supervision, particularly crop \nyield \nobservation \nis \nessential \nfor\
    \ \nexamining the food security in a region. \nDue to several difficult aspects,\
    \ predicting \nthe crop yield manually is a challenging \ntask [10]. Based on\
    \ the water quality as \nwell as availability, pest infestations, \ngenotype,\
    \ landscape, soil quality, climatic \ncondition, etc., the yield of the crop may\
    \ \nvary. The strategies and the processes are \nnon-linear in nature, intricate\
    \ and varied \nwith time because of external aspects and \ncorrelated factors\
    \ [11]. Recently, several \nstudies illustrate that ML approaches such \nas support\
    \ vector regression, multilayer \nperceptron (MLP), etc. have comparatively \n\
    more \nenhanced \npotential \nthan \nthe \ntraditional techniques. These approaches\
    \ \nhave the ability to predict linear and non-\nlinear agricultural architecture.\
    \ From the \nlearning process, these methods were \nobtained in ML agricultural\
    \ framework \n[12-14]. \nOn \nobserving \nthe \nmost \noutstanding \nframeworks\
    \ in agriculture, artificial and \ndeep neural networks are the commonly \nutilized\
    \ models [15]. Artificial neural \nnetwork (ANN) is a network model that \ngenerates\
    \ approximation by bias as well as \nweight optimization for a node-link \nstructure\
    \ including input, hidden and \noutput layers [16]. Deep learning (DL) is a \n\
    subgroup of ML used to predict the crop \nyield based on the varying arrangement\
    \ of \nraw data via the intensive learning process \nin a deep network [17]. Moreover,\
    \ these \nDL algorithms have the capability to \ndesign a probability model using\
    \ field \ndata. Along with this benefit, the data \nabout the crop performance\
    \ under different \nclimatic changes are provided by DL \napproaches \n[18]. \n\
    For \nexample, \nReinforcement learning is one of the major \nareas of artificial\
    \ intelligence. It is the \npreparation of ML models for decision-\nmaking sequences\
    \ and is the significant \nclass of algorithm that is used to \nstreamline logic\
    \ for dynamic programming \n[19]. Besides, extreme learning machine \n(ELM) is\
    \ also a ML approach that has the \ncapability to empower neural network \ntraining\
    \ for predicting the crop yield. It \naccelerates the learning process and \n\
    provided better outcomes. However, these \napproaches have several disadvantages\
    \ like \nless \nsustainability, \ncomputationally \nexpensive, high complexity\
    \ and false \nprediction \n[20]. \nTo \novercome \nthese \nchallenges, a more\
    \ efficient ML based \ncrop yield prediction model is proposed in \nthis work.\
    \  \nMotivation: \nAgriculture \nis \nthe \nmajor \neconomic \nresource of India.\
    \ To overcome the issues \nof high cost and complex management of \nconventional\
    \ agricultural planting, IoT is \napplied for realizing real time detection, \n\
    crop growth intelligent management and \nchanging the conventional agricultural\
    \ \nplanting mode. Various mathematical and \nempirical yield approaches have\
    \ been \nevaluated for several crops.  These models \nneed huge knowledge about\
    \ soil and crops \nwhich make it hard for implementing for \nvarious localities.\
    \ Many satellite based \nremote \nsensing \nmethods \nwere \nalso \ndeveloped\
    \ in yield modelling. But these \napproaches are not able to provide enough \n\
    spatial \ndetails \nof \nsmall \nfarms \nfor \noptimizing crops. Recent developments\
    \ in \nmachine learning models have become \npopular that enable researchers for\
    \ solving \nand understanding complex predictions. \nMany ML approaches have been\
    \ employed \nfor crop prediction like decision trees, \nANN and Support vector\
    \ machine (SVM) \nand in this research work ELM and \naKNCN are used for crop\
    \ yield prediction \nthereby achieving better results. \nContributions: \nThe\
    \ proposed work’s major contributions \nare: \n The proposed work provides an\
    \ \nIoT based farming system that \nensures the deployment of effective \ncrop\
    \ yield prediction model. This \nwork involves pre-processing, FS \nand classification.\
    \ The data is pre-\nprocessed and features are selected \nby FS algorithms. \n\
     Then IoT based smart agriculture \nsystem using two-tier ML model is \nproposed\
    \ for the better prediction \nof crop yield. \n ML \nbased \nclassification \n\
    is \nperformed to classify the soil \nsamples for different classes by \nconsidering\
    \ the properties of soil \ndataset.  \n ELM \nmodel \nis \nproposed \nfor \n\
    predicting the crop yield and the \nweights of the model are updated \nusing mBOA\
    \ algorithm for the \nperformance improvement of the \nprediction system with\
    \ less error \nvalues. \n The systematic evaluation of the \nproposed crop yield\
    \ prediction \nsystem is implemented based on \nmachine \nlearning \nperformances\
    \ \nthrough \nvarious \nexperiment \nconsequences. \nPaper outline: Section 1\
    \ presents the \nintroduction \nand \nhighlights \nsmart \nagriculture in brief.\
    \ Recent related works \nduring (2019-2021) are discussed in \nsection 2. Section\
    \ 3 focuses on the \nproblems in the IoT based crop yield \nprediction. Section\
    \ 4 provides the detailed \ndescription about IoT devices used in a \nsmart \n\
    agriculture \nsystem. \nSection \n5 \npresents the proposed framework along \n\
    with important measurables. Section 6 \ndiscusses the experimental analysis and\
    \ \nresults. Section 7 concludes the presented \nwork. \n2. Related works \nAbbas,\
    \ et al. [21] predicted the crop yield \nvia \nproximal \nsensing \nand \nthe\
    \ \nML \nalgorithms. The objective was to extract \nsignificant data that are\
    \ responsible for \ncontrolling \nthe \nyield \nof \ncrop. \nThe \nproperties\
    \ of potato tuber crop and the data \nof soil have been gathered by proximal \n\
    sensing. A large dataset was utilized for \nthe prediction performance. Support\
    \ vector \nregression (SVR), k-nearest neighbour (K-\nNN), linear regression and\
    \ elastic net ML \nalgorithms \nwere \nutilized \nfor \nthe \nclassification and\
    \ prediction of crop yield. \nR2, MAE and RMSE were determined for \nthe \nperformance\
    \ \nevaluation. \nThe \nperformance achieved for KNN was poor \nin crop yield\
    \ prediction because of higher \nnumber of features. \nRezk, et al. [22] presented\
    \ an IoT based \nsmart \nagriculture \nsystem \nusing \nML \nalgorithm. The drought\
    \ and the crop \nproductivity were predicted by WPART \nand it was a combination\
    \ of wrapper and \nPART techniques. Feature selection and \nclassification were\
    \ the two important \nphases in the prediction process. Wrapper \nfeature selection\
    \ technique selected the \noptimal features for further classification. \nPART\
    \ was a partial decision tree approach \nused for classification and prediction.\
    \ \nAccuracy, precision, sensitivity and F1 \nscore were considered for the experiment\
    \ \nof \nWPART. \nThe \ncrops \ntaken \nfor \nexperiment were Sugarcane, Jowar,\
    \ Bajra \nand Soybean. Some samples in the dataset \nwere misleadingly labelled,\
    \ thus the false \nprediction rate was high. In future, some \nparameters like\
    \ soil nutrients, agricultural \ninputs, irrigated area and soil quality will\
    \ \nbe considered for forecasting the crop \nyield. \nBu, \net \nal. \n[23] \n\
    developed \ndeep \nreinforcement \nlearning \nbased \nML \ntechnique for smart\
    \ farming IoT system. \nCloud computing and artificial intelligence \nwere combined\
    \ for the classification and \nprediction of crop yield. The key goal of \nthis\
    \ research was to minimize resource \nconsumption and maximize the food \nproduction.\
    \ A hierarchical Bayesian based \nmulti-task reinforcement learning method \n\
    has been utilized for modelling the Markov \ndecision process. Then, the Q-value\
    \ \nregression function was examined using \npolicy \ndistillation. \nHowever,\
    \ \ncomputational complexity was considered \nas one of the major drawback of\
    \ this \napproach. Also, human-level performance \nwas not achieved in complex\
    \ task solution \nand \nin \nadaptation \nto \ndynamic \nenvironments. In future,\
    \ this research aims \nto design an incremental model and \ntransfer learning\
    \ approaches for the \nenhancement of performance efficiency.  \nNevavuori, et\
    \ al. [24] proposed a deep \nlearning \ntechnique \nfor \ncrop \nyield \nprediction.\
    \ The key objectives of this \nresearch were crop yield prediction, \nbiomass\
    \ \nevaluation, \ncrop \nand \nweed \ndetection. Convolutional Neural Network\
    \ \n(CNN) was modelled for extracting the \nfeatures, training, hyperparameter\
    \ tuning \nand regularization to predict the yield of \nwheat and barley crops.\
    \ MAE and MAPE \nare the evaluation metrics used for \nsimulation analysis. But,\
    \ the presented \nCNN does not perform well for the large \ndataset. Also, the\
    \ performance efficiency \nof this method was not good. The future \nscope of\
    \ this research is to train the \ndeveloped model for a large set of features\
    \ \nlike soil and climate with time series \nimage data.  \nDos Santos, et al.\
    \ [25] introduced \nAgriPrediction model for IoT based smart \nagriculture system.\
    \ It was an end-to-end \nmodel that predicted agricultural crops. It \nwas the\
    \ integration of prediction as well as \nshort and medium wireless network range\
    \ \nsystem. The components of AgriPrediction \nmodel have been designed according\
    \ to the \nARIMA prediction model and LoRa IoT \ntechnology. \nInitially, \nthe\
    \ \ndata \nwere \ngathered using sensors, then the discrete \nmoving average-based\
    \ prediction has been \nperformed. If the predicted crop goes \nwrong, then the\
    \ notification was given to \nthe farmer’s mobile phone. This model \nwas computationally\
    \ expensive and less \nsustainable. Moreover, the accuracy of this \nAgriPrediction\
    \ model was not evaluated in \nthis research. The future scope of this \nresearch\
    \ is to generate a mobile application \nfor crop’s real-time monitoring. \nSaranya,\
    \ C. P., and N. Nagarajan [26] \npresented \na \nneural \nnetwork \nwith \npopulation\
    \ based incremental learning \n(NN-PBIL) method for the prediction \nperformance\
    \ enhancement. The neural \nnetwork was used to classify and predict \nthe crop\
    \ yield. The weight of the neural \nnetwork was updated by the PBIL \napproach.\
    \ Hadoop framework has been \nutilized for the prediction performance. \nNeural\
    \ network along with ANN and \nmultiple linear regressions (MLR) were \nimplemented\
    \ for the crop yield prediction. \nLow convergence and getting stuck within \n\
    local minimum were the major drawbacks \nin this presented model. The future scope\
    \ \nof this research is to use the optimization \napproaches for the crop yield\
    \ forecasting.  \nFilippi, et al. [27] proposed the empirical \nmodelling scheme\
    \ for forecasting the yield \nof barley, wheat and canola crops. In this \nresearch,\
    \ several fields are considered for \nthe prediction performance instead of \n\
    single field in isolation. Random forest \nmodels and publically available data\
    \ with \ntemporal and spatial data collected on-\nfarm were combined for the \n\
    yield \nprediction of canola, barley and wheat. \nThe experimental results showed\
    \ that the \naccuracy obtained by this predictive model \nwas low. In future,\
    \ this research will be \nextended by exploring enhanced feature \nextraction\
    \ calibration and more publically \navailable data sources for forecasting the\
    \ \nyield of the crop. \nSun, Jie, et al. [28] predicted the yield of \nboth in-season\
    \ and end-of-season soybean \nusing deep CNN-LSTM based on remote \nsensing data.\
    \ The training data such as \nMODIS surface Reflectance (SR) data, \nMODIS land\
    \ surface temperature (LST) \ndata and weather data were correlated and \ntransformed\
    \ to histogram based tensors \naccording to the Google earth engine \n(GEE). The\
    \ performance of crop yield \nprediction at large scale was not evaluated \nin\
    \ this research. Time and computational \ncomplexity was high and fed the raw\
    \ \nremote sensing data into DL mode was a \ncomplex task. The future scope of\
    \ this \nresearch is to include more features for the \nyield prediction and the\
    \ performance will \nbe performed at large scale. \nSinwar, et al. [29] discussed\
    \ about \ndifferent methods of Artificial Intelligence \n(AI)for smart irrigation\
    \ and crop yield \nprediction system. From the research it \nwas proved that AI\
    \ based system offered \nadequate data regarding the crop yields at \nan early\
    \ stage. Several ML techniques \nsuch as Support vector machine (SVM), \nLinear\
    \ Discriminant Analysis (LDA), \nANN, Generative Adversarial network \n(GAN),\
    \ Deep Boltzmann machine (DBN), \nK \nnearest \nneighbour \n(KNN), \nBackpropagation\
    \ \nneural \nnetwork \n(BNN)and Deep neural network (DNN) \nperformed better in\
    \ crop yield prediction. \nHowever, some limitations are there in \nthese \napproaches\
    \ \nlike \ncomputational \ncomplexity, \nhigh \ncost, \ndependencies \nbetween\
    \ target and input variables, proper \nmodel \nrepresentation \nand \naccuracy\
    \ \naffected by data quality. \n3. Problem Statement \nThe method in [21] attained\
    \ better \nperformance but in some cases it achieves \npoor result due to the\
    \ small datasets. The \nmethod [22] outperformed conventional \nmodel for 5 datasets\
    \ for classification of \ndrought and productivity of crop but it did \nnot focus\
    \ on time series analysis. Deep \nreinforcement [23] showed better growth \nin\
    \ model design but it takes more time for \ntraining. \nCNN \n[24] \nachieves\
    \ \nbetter \naccuracy on yield prediction but does not \nsupport large features\
    \ like soil and climate. \nThe method [25] achieves better result in \nonline\
    \ prediction model in agri prediction \nbut it has high computational complexity.\
    \ \nANN [26] achieves good prediction in \ncrop yield but handling noise in the\
    \ images \nhas to be investigated. The method [27] \nachieved higher accuracy\
    \ but it has to be \nfocussed on time series prediction. Deep \nCNN-LSTM [28]\
    \ model is highly efficient \nin error performance at any time node but \nthe\
    \ processing time is large due to its \ncomplex structure. AI [29] minimizes the\
    \ \neffort of human and improves agricultural \npractices but the system cost\
    \ is too high. \nDue to these drawbacks the proposed \nmodel introduces 2 classification\
    \ models \nwith optimal weight selection for crop \nyield prediction. \n4. IoT\
    \ Devices \nThe IoT based smart agriculture model is \ndesigned to construct the\
    \ whole crop \nprediction system. The key goal of this \nmodel is to predict the\
    \ crop yield based on \nthe gathered data using IoT devices. It \nassists the\
    \ crop yield prediction system for \nbetter decision making on the yield of crop\
    \ \naccording to the gathered data from \nmonitoring camera analysis. The data\
    \ \nobtained from camera is integrated with \nenvironment data from IoT devices.\
    \ \nAvailability of environment data as well as \nits timely delivery is significant\
    \ for \npreserving the crops and property at the \ntime \nof \ndisasters. \nThe\
    \ \nimportant \ninformation considered for an effective \npredictive model are\
    \ Statistical agriculture \ndata and contemporary IoT sensing data. \nThe parameters\
    \ available in statistical and \ncontemporary IoT sensing data are rainfall, \n\
    temperature, pH level, soil nutrients and \nfertilizers. Figure 1 represents the\
    \ structure \nof IoT services for agriculture. \nInternet\nSoil \nsensor\nController\n\
    Transmi\ntter\nTemp. \nsensor\nReceiver Environment \ndata handling \nserver\n\
    Environment \ndatabase\nPrediction \nserver\nStreaming \nserver\nMonitoring and\
    \ \nPrediction\nIoT sensor \nWeb\nLaptop\nPDA\nData Acquisition and \nHandling\
    \ \nData management \nCamera\nFigure 1: Service of IoT for Agriculture\nThe major\
    \ components in IoT based \nagriculture \nmodel \nare \nsensors, \ndata \nacquisition,\
    \ data management devices, \nmonitoring and prediction devices. These \ndevices\
    \ enhanced the performance of the \ncrop \nyield \nprediction. \nSmart \nfarm\
    \ \nembedded with IoT system can improve \nthe production of crop by predicting\
    \ the \nsoil type, climatic changes, soil quality and \nseveral other factors.\
    \ Figure 2 illustrates \nthe example picture representation of IoT \nbased smart\
    \ agriculture system. \nFigure 2: Example pictorial representation of IoT based\
    \ smart agriculture system:\n (a) plant (b) moisture sensor (c) temperature and\
    \ humidity sensor and (d) USP \nSensors: \nSensors in IoT are used to track the\
    \ \nparticular soil and water pH value, \ntemperature and humidity value and \n\
    fertilizer control for the growth of crop \n[32].The \nmoisture, \ntemperature\
    \ \nand \nhumidity and pH sensors are discussed in \nthe following subsections.\
    \ \n(i) Soil moisture sensor: \nIt is a sensor that determines the water \ncontent\
    \ available in soil. Several sensors \nare there in a probe, which save the water\
    \ \nand \nmanage \nirrigation \nsystem \neconomically and successfully. Also,\
    \ the \nquality and yield of the crop is improved \nusing these sensors. It provides\
    \ the \naccurate outcomes immediately and is less \nexpensive. Figure 3 shows\
    \ the pictorial \nrepresentation of a soil moisture sensor. \nFigure 3:Soil moisture\
    \ sensor \nUsing this sensor, the soil’s water content \ncan be examined and it\
    \ averages the water \ncontent over the complete span of the \nsensor. The main\
    \ purpose of this sensor is \nto monitor the moisture of the soil for \nirrigation\
    \ management, examine the loss of \nhumidity over time because of plant uptake\
    \ \nand evaporation and to find the optimum \nsoil moisture stuffing. The sensor\
    \ readings \nare then transferred to the transmitter and \nthe threshold value\
    \ is set in the application. \nThe water motor in the field is operated \nbased\
    \ on the threshold value, i.e., if the \nthreshold value is greater than the water\
    \ \nlevel, then the needed water is supplied. \nOnce the water level is attained,\
    \ the sensor \nreading provides the indication and the \nirrigation is stopped.\
    \ \n(ii) Temperature and Humidity sensor: \nThis is used to measure pending rain,\
    \ \ntemperature changes, rain fallen at a \nparticular period and water consumption.\
    \ It \nis comprised of sense of wet NTC \ntemperature \nmeasuring \ndevices \n\
    and \nresistive element. This sensor provides fast \nresponse, \nhigh \ncost \n\
    performance, \nincredible quality and anti-interference \ncapability. Figure 4\
    \ illustrates the pictorial \nrepresentation of \na temperature and \nhumidity\
    \ sensor.   \nFigure 4: Temperature and humidity \nsensor \n(iii) pH sensor: \n\
    pH is an indicator of a solution’s acidity \nand alkalinity. Normally, the range\
    \ of pH \nlevel is considered between 0 and 14. \nMoreover, it represents the\
    \ concentration \nin certain hydrogen +ions solutions. Figure \n5 depicts the\
    \ pictorial representation of a \npH sensor. \nThe \npotential difference \nbetween\
    \ two electrodes such as hydrogen-\nsensitive glass electrode and reference \n\
    electrode is detected by this sensor. It can \nbe used with the microcontroller\
    \ like \nArduino. \nFigure 5: pH sensor \nController: \nArduino controller is\
    \ used to monitor and \ncontrol \nthe \nfarm’s \nenvironmental \nconditions. The\
    \ inputs provided to the \ncontroller are location from the farm and \nthe pH\
    \ value. Besides that, the percentage \nof nutrients such as Calcium, Zinc, \n\
    Manganese, \nOrganic \nmatters, \nBoron, \nMagnesium, \nIron, \nSulphur, \nNitrogen,\
    \ \nPotassium and Phosphorous. Based on the \npretrained network or real time\
    \ values or \nboth, the decisions regarding the prediction \nare made by the controller.\
    \ Figure 6 \nindicates the arduino controller. \nFigure 6: Arduino controller\
    \ \nData acquisition: \nThe initial process in data acquisition is to \nregister\
    \ each device deployed in the farm \ninto Mobius.  The registration is done \n\
    using &cube device and it acts as an \ninterface between the deployed devices\
    \ \nand the Mobius. \nThen, the virtual \nrepresentation is generated for each\
    \ device \nbased \non \nthe \nresource \ntype. \nThe \nenvironmental data gathered\
    \ by sensors are \ntransmitted to &cube and the &cube \nforwards the data to Mobius\
    \ [33]. Finally, \nthe available virtual representations of the \ndevices are\
    \ accessed by the farmers or \nend-users to monitor and manage their \nconnected\
    \ farm with the help of IoT \napplications such as tablets, laptops, \nsmartphone,\
    \ etc. \n(i) Mobius:\nIt is an open IoT service platform that \nperforms \noperations\
    \ \nbased \non \none \nmachine-to-machine \n(M2M) \nstandard \nrules. The generation\
    \ of physical IoT \ndevices’ virtual representations is assisted \nby this Mobius.\
    \ It is designed to conform \nwith one M2M specifications and helps \ngeneral\
    \ M2M/IoT service functions like \nsecurity, device registration, subscription\
    \ \nas well as notification and data repository \nand management. Moreover, the\
    \ data \nresources \npreserved \nin \nMobius \nare \naccessed \nand \nthe \nIoT\
    \ \ndevices \nare \ncontrolled by REST APIs. \n(ii) &cube \nThe &cube is a device\
    \ software platform \nthat is installed into IoT gateways. \nThrough the standard\
    \ REST APIs, the \ngathered data from physical devices is \ntransmitted to Mobius.\
    \ Several protocols \nare assisted by &cube such as CoAP, \nMQTT and HTTP. Raspberry-Pi\
    \ is utilized \nin this work for the connected farm. It is a \nsingle-board Linux\
    \ installed computer.  \nFigure 7: Raspberry-Pi \nData Management: \nIn data management\
    \ service, the required \nexternal data are gathered from the sensors \nand the\
    \ servers preserve the collected data \nfor further process. Also, the data gathered\
    \ \nfrom camera is stored to predict the yield \nof the crop. Storage, maintenance\
    \ and \nmanagement of data for maintenance of \ncorresponding services are provided\
    \ in this \ndata management system.  \n5. Proposed Framework \nThe ingredients\
    \ of soil like Phosphorous, \nPotassium and Nitrogen, crop rotation and \natmospheric\
    \ temperature etc. play a vital \nrole in cultivation. ML methods are an \nessential\
    \ decision support device for the \nprediction of crop yield like supporting \n\
    decision on what crops to grow. Many ML \nalgorithms are employed to support the\
    \ \nprediction of crop yield. In the proposed \nsmart \nagricultural \nframework,\
    \ \npre-\nprocessing, FS and a two-tier model is \nimplemented for crop yield\
    \ prediction. \nHere, akNCN is proposed to be deployed \nwhich is an improved\
    \ version of KNCN. \nGenerally ELM is an influential model \nwith more fast learning\
    \ methods, higher \nperformance and less training error when \ncompared with other\
    \ algorithms. Therefore \nthese two classification algorithms are \nproposed in\
    \ this work to improve the \naccuracy of the system and provide better \nresults\
    \ than the existing models. \nData \nSource\nData\nPreparator\nPrediction \nResult\n\
    Evaluation \nResult\nNotification Server\nGateway\nPrediction Engine\nUser\nCrop\
    \ Area\nClassification\nPrediction\nTwo tier machine \nlearning model\nCrop \n\
    parameters \nDatabase\nPre-\nprocessing\nFeature \nselection\nFigure 8: Architecture\
    \ of the proposed methodology \nFigure 8 illustrates the architecture of the \n\
    proposed crop yield prediction model. \nInitially, Pre-processing is done to remove\
    \ \nthe noise in data and the features are \nselected on the basis of features\
    \ selection \nmethods like CBFA and VIF. Finally, the \nclassification uses two\
    \ tier systems. In the \nfirst tier, the proposed aKNCN model is \nused to classify\
    \ the soil quality based on \nIoT system collected soil nutrients. Then \nin the\
    \ second tier, ELM-mBOA is utilized \nfor crop yield prediction and the accuracy\
    \ \nis improved by optimal weight selection \nusing mBOA. This model improves\
    \ the \naccuracy of the system with minimum \nerror values. \n5.1 Pre-processing\
    \ \nThe data is gathered from various sources \nand pre-processing is done. Pre-processing\
    \ \nis a necessary phase in ML since it can’t \nhandle noisy data. Noisy data\
    \ means it has \nerrors and outliers. Before applying the \ndata to classification\
    \ it has to be pre-\nprocessed for inserting missing values, \neliminate unwanted\
    \ data, functionality \nextraction and maintain the appropriate \ndata range.\
    \ In this work isnull() approach \nis used to check the null values then the \n\
    label \nencoder() \nis \nused \nto \nconvert \ncategorical data (string format)\
    \ into \nnumerical data (numeric format). Since \nPython does not handle categorical\
    \ data it \nmust be converted into numeric format. \nOnce the data is converted\
    \ to numeric \nformat, it is applied for feature selection. \n5.2 Feature selection(FS)\
    \ \nML is a computational learning model that \nworks on prediction from statistical\
    \ value. \nFS model is applied to identify necessary \nfeatures which are powerful\
    \ in correlation \nwith crop production. The main reason to \nemploy FS is that\
    \ it enables the ML \nalgorithm to train faster, minimizes the \nmodel complexity\
    \ and makes it easy to \ninterpret. It also increases the system \naccuracy when\
    \ the proper subset is \nselected and reduces overfitting. The \ncomputation time\
    \ of the algorithm is less \nnecessary than its classification for normal \nsize\
    \ feature sets. But the feature selection \nis necessary for large datasets. Various\
    \ \nstatistical approaches can be employed in \nFS like filter, embedded and wrapper\
    \ \nmethods. Filter methods choose the \nintrinsic characteristics of the features\
    \ \ncomputed by univariate statistics instead of \nperformance of cross-validation.\
    \ These \nmethods \nare \nfaster \nand \nless \ncomputationally expensive than\
    \ wrapper \nmethods. \nWhen \ndealing \nwith \nhigh-\ndimensional data, it is\
    \ computationally \ncheaper to use filter methods. Hence, in \nthis work filter\
    \ based FS methods like \nCBFA algorithm and VIF algorithm are \nused. CBFA chooses\
    \ the best feature set \nwhich is mainly correlated with yield. VIF \nverifies\
    \ \nthe \nmulticollinearity \namong \nindependent \nfeatures. \nTherefore, \n\
    it \neliminates all multicollinear features.  \n5.2.1 \nCorrelation \nbased \n\
    Feature \nselection Algorithm (CBFA)\nCBFS orders feature subset based on the\
    \ \ncorrelation heuristic evaluation function. \nThis function is towards a subset\
    \ that has \nfeatures which have high correlation \namongst class and uncorrelated\
    \ with each \nother. The features which are not relevant \nmust be removed since\
    \ they have less \ncorrelation \namongst \nclass \nand \nhigh \ncorrelation with\
    \ other features. Feature \nacceptance is based on the extent to which \nit identifies\
    \ classes in areas which are \nalready not identified by other features. \nThe\
    \ CBFS is computed as: \nfr\nN N\nN\nNrc\nM\n)1\n(\n\n\n\n(1) \nWhere N  is\
    \ the total number of features, \nc\nr is the average correlation, fr is average\
    \ \nfeature to pair wise correlation. \n5.2.2 \nVariance \nInflation \nFactor\
    \ \nalgorithm (VIF) \nVIF computes the strength of the multi \ncolinearity in\
    \ the analysis of least squares \nregression. It gives an index that computes\
    \ \nhow much the variance of an evaluated \nregression coefficient is enhanced\
    \ due to \ncolinearity. VIF model is employed for \nremoving correlated independent\
    \ features. \nThis method is fast and it exploits one pass \nsearch to the predictor.\
    \ In addition, this \nmethod is computationally efficient in \ntesting every predictor\
    \ to the model and it \navoids the overfitting issue. It is achieved \nby regressing\
    \ each independent variable, \nlet Y on the remaining independent \nvariables\
    \ (W and Z) and checking how \nmuch of it (of Y) is explained by these \nvariables.VIF\
    \ is measured by  \n2\n1\n1\nR\nV\n\n\n(2) \nFrom the expression it is shown\
    \ that the \nhigher the VIF, higher the R2 which means \nthe variable X is collinear\
    \ with Y and Z \nvariables. \nIf \nall \nthe \nvariables \nare \ncompletely orthogonal,\
    \ R2 will be 0 \nresulting in VIF of 1. \n5.3Tier 1-Classification  \nIn this\
    \ work, aKNCN [34] is used to \nclassify the soil classes from the different \n\
    parameters. \nThe \nproposed \naKNCN \novercomes the challenges of conventional\
    \ \nKNCN and enhanced the performance of \nKNCN classification. KNCN is a non-\n\
    parametric classifier that depends on the \ncentroid distance. This states the\
    \ nearest \nneighbours of the test samples should \nsatisfy the following criteria\
    \ - it should be \nclose to test samples and the nearest \nneighbour \ndistribution\
    \ \nshould \nbe \nsymmetrical in test samples. But it is \ncomplex to determine\
    \ neighbours in a \nfeature that satisfy these properties. \nThough KNCN achieves\
    \ good accuracy it \nlags in classification time. Hence aKNCN \nis \ndeveloped\
    \ \nfor \nimproving \nthe \nclassification time by adaptively adjusting \nthe\
    \ nearest centroid neighbour for every \ninput sample to enhance the classification\
    \ \naccuracy. Two properties of aKNCN are \ngiven as follows: \nProperty 1: \n\
    \ The aKNCN method satisfies a stable \nsearching phase only when \nth\nj  distance\
    \ of \nnearest centroid is more than pre-defined \nlimit which is multiplier product\
    \ of \nlk  and \nthe first nearest centroid \nzncn 1,\n to the test \nsample \n\
    )\n,\n(\nd y zncn 1,\n. \nThe \nsize \nof \nneighbourhood is represented as  \n\
    )\n( ,\n)\n,\n(\n1,\n1\nncn\nis\nd y z\nk\nd y z\n\n\n(3) \nWhere \n)\n,\n(\n\
    izs\nd y\n is the nearest centroid \ndistance among test samples, \ns\niz  and\
    \ y . \nThe multiplier product is higher or equal to \n1 and the 1st centroid\
    \ distance is \n)\n,\n(\nd y zncn 1,\n. \nProperty 2: \nThe aKNCN method satisfies\
    \ searching \nphase only when the entire sample class, \ni\nM , is found amongst\
    \ j nearest neighbour \nand the whole samples per class to \ncompete class is\
    \ lesser than\nMi 1\n . Then \nthe property is defined as  \n)'\n(\n)\n(\n(\n\
    wi\nwi\ni\nV\nV\nMCM\n \n\n\n(4)\nj\ny\ny\nx\ny\nx\ni\nV\nmcm\nmcm\nx\nMCM\n\
    } 1\n|\n{\n( )\n(\n\n\n\n\n is j\nnearest neighbour of \nMi\ny\ni\ny\ni\n\
    y\nwi\nV\ny\ny\nV\n} 1\n|\n{\n\n\n\nis a subset of  V from wi with training\
    \ \nsamples, \ni\nM and \n'\n} 1\n|\n{\n'\nMi\ny\ni\ny\ni\ny\nwi\nV\ny\ny\nV\n\
    \n\n\n is \na subset of  \n'\nV from wi with training \nsamples, \ni\nM . Finally,\
    \ the soil quality is \nclassified and the crop yield is predicted \nbased on\
    \ the classified properties for \ndifferent classes. The yield prediction is \n\
    performed using ELM, which is discussed \nin the next subsection. \n5.4 Tier 2-Prediction\
    \  \nIn this phase, ELM [36] is proposed to \npredict the crop yield based on\
    \ the \nclassified soil properties of different \nclasses along with different\
    \ parameters \nsuch as rainfall and temperature. In ELM, \na new metaheuristic\
    \ algorithm called \nmBOA is hybridized to tune the optimal \nset of ELM parameters\
    \ such as thresholds \nand weights that enhance the performance \naccuracy with\
    \ fast convergence. mBOA is \na novel approach, which solves the \nconvergence\
    \ \nproblems \nand \nprovides \nrobustness ELM has learning speed and \nhas a\
    \ better generalization because there is \nno need to tune the initial parameters\
    \ of \nthe hidden layer. The hidden layer Feed \nForward Network (FFN) is converted\
    \ into \nthe linear equation by minimum norm least \nsquares. The aim of the ELM\
    \ is to reduce \nthe output norm weight and training error \nat the same time.\
    \ For the samples\n}\n2,1 ,...\n,\n,\n|)\n,\n{(\nN\ni\nS\nT\nS\nX\nT\nZ\nn\ni\n\
    m\ni\ni\ni\n\n\n\n, \nthe P neurons hidden layer with the output \nfunction\
    \ is:                                                                       \n\
    \n\n( )\n( )\n)\n(\n1\nr Z\nr Z\nZ\nf\nP\ni\ni\nP\n\n \n\n     (5) \nWhere\
    \ \n]\n..........\n,\n[\n2\n1\nP\n   \n is the output \nweight vector between\
    \ output neuron and\nP . The hidden layer output vector to the \ninput X  is given\
    \ by  \n( )............ ( )]\n[ ( ),\n)\n(\n2\n1\nZ\nr\nr Z r Z\nr Z\nP\n\n(6)\
    \ \nFor enhancing the generalization and to \nreduce the training error of neural\
    \ \nnetworks, at the same time both output \nweight and the training error must\
    \ be \nminimized. \n||\n||,||\nmin :||\n\n\nT\nh\n\n                      \
    \       (7) \nAccording to (Karush–Kuhn–Tucker) the \nequation (19) can be written\
    \ as  \nT\nhh\nR\nh\nT\nT\n1\n1\n\n\n\n\n\n\n\n\n\n\n(8) \nWhere h \
    \ is the output matrix of the \nhidden layer, R is the coefficient of the \nreflection\
    \ and T is the expected samples \nand the ELM algorithm output function is  \n\
    T\nhh\nR\ng Z h\nZ\nf\nT\nT\n1\n1\n( )\n)\n(\n\n\n\n\n\n\n\n\n\n(9) \n\
    When the feature mapping function \nr(Z)\nis \nunknown, ELM kernel matrix on the\
    \ basis \nof Mercer’s condition is given by \n)\n,\n(\n)\n) (\n(\n, :\nj\ni\n\
    j\ni\nij\nT\nL Z Z\nr Z r Z\nm\nhh\nM\n\n\n\n(10) \nThe output function \n\
    g(Z)\n on the basis of \nKOELM is given by \nT\nM\nR\nL Z Z\nL Z Z\nZ\nf\nn\n\
    1\n1\n1\n)]\n)...... ( ,\n( ,\n)\n(\n\n\n\n\n\n\n\n\n\n(11) \nWhere \n\
    )\n,\n(\nL Z Z1\n and \nM  hhT\nare the \nhidden neurons kernel function of single\
    \ \nhidden layer FFN networks. The functions \nlike polynomial kernel, exponential\
    \ kernel, \nlinear kernel and Gaussian kernel will \nsatisfy the Mercer condition.\n\
    BOA [35] is a nature based metaheuristic \napproach which influences the behaviour\
    \ \nof mating and foraging of butterfly. One of \nthe major properties of BOA\
    \ varies from \nother optimization approaches that are \nevery butterfly has its\
    \ separate scent. The \nfragrance is expressed as: \nb\nr\nf  sI\n(12) \nWhere\n\
    rf  represents the identified \nmagnitude of fragrance, s  is modality of \nsensor\
    \ and \nbI  represents stimulus intensity \nwith absorption of fragrance.  \n\
    The value of s ranges from \n]\n[ ,0\n  but the \nvalue is identified by a particularity\
    \ of the \noptimization issues in the BOA iterative \nprocedure. The s  in the\
    \ optimal solution \nof the method is expressed as \n\n\n\n \n\n\nmax\n\
    1\n.\n.0 025\nc T\ns\ns\nt\nt\nt\n(13) \nWhere \nTmax\n is the maximum iteration\
    \ and \ninitial value of s  is 0.01.\nFurther, there are two stages in the \n\
    process, global search and local search \nspace. The mathematical calculation\
    \ of \nglobal search is calculated as \nr\nt\nj\nb\ni\nt\nj\nt\nj\nf\nx\ng\nr\n\
    x\nx\n)\n(\n2\n1\n\n\n\n \n(14) \nHere \nt\njx  is the solution vector \n\
    jx  of the \nth\nj  butterfly in iteration t  and ir  is a \nrandom number and\
    \ rages from [0,1]. Then \nb\ng is the present best solution identified \namong\
    \ every stage in the present stage.  \nThen the local search space is expressed\
    \ as\nr\nt\nj\nm\ni\ni\nt\nj\nt\nj\nf\nx\nx\nr\nx\nx\n)\n(\n2\n1\n\n\n\n \n\
    (15) \nHere \nm\nix  and \nt\njx  are the\nth\nm  and \nth\nj\nbutterflies selected\
    \ randomly and when \nm\nix\nand \nt\njx  is considered under same iteration,\
    \ \nthat means butterflies becomes a local \nrandom walk. When \nm\nix  and \n\
    t\njx  is not \nconsidered under same iteration random \nwalk may diversify the\
    \ solution. \nBoth local search and global search for \nmating and food partner\
    \ via the butterflies \nin nature can happen. Hence a switch \nprobability is\
    \ considered to transform the \nintensive local search and normal global \nsearch.\
    \ \nIt is seen from Equation (14) and (15) that \nchoosing randomly local and\
    \ global search \nwill affect BOA is trapped by local optima. \nFurther the parameter\
    \ \nir  capacity for \nadjusting local and global is limited. \nTherefore some\
    \ modification is needed. \nHence the new optimal solution is \nobtained by the\
    \ following equations. \n Therefore the new equation for global \nsearch is calculated\
    \ as \nr\nt\nj\nb\ni\nt\nj\nt\nj\nf\nx\ng\nr\nw x\nx\n)\n(\n.\n2\n1\n\n\n\n\
     \n(16) \nThe new equation for local search space is \nexpressed as\nr\nt\n\
    j\nm\ni\ni\nt\nj\nt\nj\nf\nx\nx\nr\nx\nw\nx\n)\n(\n)1\n(\n2\n1\n\n\n\n\n\
    \ \n(17) \nWhere w is a weighting coefficient. \nComparing with Equation (14)\
    \ and (15), \nthe updated equation (16) and (17) has the \nfeatures like the weighting\
    \ coefficient is \nable to adjust among local and global \nsearch when compared\
    \ to the original \nBOA. The best solution is updated either \nby equation (16)\
    \ or equation (17). These \ntwo equation provides better convergence \nspeed because\
    \ of the weighting coefficient. \nFurther this model has better convergence \n\
    speed and avoid local optima. Therefore \nthis mBOA provides better results due\
    \ to \nthe optimal value. The Pseudo-code \nmodified BOA is algorithm 1. \nAlgorithm\
    \ 1: Pseudo-code of mBOA \nInitialize butterflies population \nInitialize stimulus\
    \ intensity \nbI\nInitialize switch probability and  modality \nof sensor s\n\
    While termination criteria not met do \n \nCompute fragrance by Equation (12)\
    \ \nEnd for \nFind the best fragrance  \nFor every search agent \n \nInitialize\
    \ the random number \nIf ir <p then \nMove towards best position using \nEquation\
    \ (16) \n   Else \nMove randomly by Equation (17) \nEnd if \n   End for \n   Update\
    \ the power exponent b\nEnd while  \nReturn the best fitness solution \n6. Experimental\
    \ results and discussion \nThis \nsection \ngives \nthe \nperformance \nanalysis\
    \ \nand \ndiscussion \nabout \nthe \ndeveloped \nscheme. \nThe \nentire \nimplementation\
    \ has been processed on a \nsystem with 8 GB RAM and Intel Core i5 \nCPU with\
    \ 3.0 GHz speed. To implement \nthe proposed scheme, PYTHON 3.8 is \nutilized.\
    \ The dataset taken in this paper for \nthe experimentation is soil dataset. The\
    \ \ndeveloped \napproach \nperformance \nis \nimplemented with metrics like RMSE,\
    \ R2, \nMSE, MedAE, MAE, MSLE, MAPE and \nEVS, error measures and accuracy are\
    \ \nutilized for the performance evaluation. \n6.1 Evaluation metrics \nThe error\
    \ measures are estimated at every \niteration and the mean of each metric is \n\
    evaluated after the imputation of all the \nvalues to obtain their overall performance.\
    \ \nThe mathematical expression for each \nmetric is defined as: \nMSE computes\
    \ the mean of the squares of \nthe errors. That means mean squared \nvariation\
    \ among actual and estimated \nvalues. MSE is represented as \n\n\n\n\n\n\
    \nn\ni\npi\nip\nn\nMSE\n1\n2\nˆ\n1\n(18) \nMSLE is a ratio among the actual and\
    \ \npredicted \nvalues. \nMean \nsquared \nlogarithmic error is as the name suggests,\
    \ \nit is a variation of the MSE. \n\n\n\n\n\n\n2\n1\nˆ\nln1\n1  ln1\n\
    \n\n\n\n\nn\ni\nip\nip\nn\nMSLE\n(19) \nRMSE is the differences between values\
    \ \npredicted using an estimator and the \nobserved values and it is represented\
    \ as \n\n\n\n\n\n\nn\ni\nip\nip\nn\nRMSE\n1\n2\nˆ\n1\n (20) \nEVS is the\
    \ name suggested, it is metric \nused to calculate the ratio among error \nvariance\
    \ and true values variance and it is \nrepresented as \n\n\n\n\nn\ni\ni\n\
    i\ni\np\np\np\nn\nEVS\n1\nˆ\n1\n(21) \nMedAE is a robust computation of the \n\
    variability of a univariate sample of \nquantitative data and it is expressed\
    \ as \n\n\n\n\n\n\n\npn\npn\nip\nip\nmedian\nMedAE\nˆ\n,....,\nˆ\n(22)\
    \ \nMAPE also known as mean absolute \npercentage deviation (MAPD), it is a \n\
    calculation of prediction accuracy of a \nforecasting approach in statistics and\
    \ it is \ncomputed as\n \n\nn\ni\npi\nn\nMAPE\n1\n1\n (23) \nMAE is the absolute\
    \ difference between an \nobserved value of a quantity and the true \nvalue. That\
    \ is the difference between true \nand measured length and it is expressed as:\
    \ \n\n\n\n\nn\ni\npi\npi\nn\nMAE\n1\nˆ\n1\n                (24)\nR2 is a statistical\
    \ measure of fit that \nrepresents how much difference of a \ndependent variable\
    \ is expressed by the \nindependent variable in a regression model \nand it is\
    \ expressed as \n\n\n2\n1\n1\n1\n2\nˆ\n1\n2\n\n\n\n\n\n\n\n\n\n\n\
    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\
    \n\n\ni\nip\ni\nip\nip\nR\n(25) \nAccuracy is defined as the corrected \nprediction\
    \ to the total number of prediction \nand it is calculated by the below \nexpression\
    \ \nTotal number of prediction\nCorrect prediction\nAccuracy \n(26)\nWhere the\
    \ expected outcome is denoted as\nip , the predicted outcome for data is \nrepresented\
    \ as\nipˆ , where\nn\ni\n2,1 ,....\n\n. \n6.2 Comparative analysis of aKNCN -\n\
    ELM-mBOA and Existing approaches\nThe performance of proposed aKNCN-\nELM-mBOA\
    \ is compared with the state of \nthe art techniques like ELM, artificial \nneural\
    \ network (ANN), support vector \nmachine (SVM), gradient boost (GB) and \nrandom\
    \ forest (RF).  The simulation is \nperformed on aKNCN -ELM-mBOA with \nthese\
    \ existing methods using the error \nmetrics \nto \ndetermine \nthe \nprediction\
    \ \nefficiency of each method. \nTable 1: Error measures of various approaches\
    \ \nApproaches \nError measures \nMAE\nMSE\nRMSE \nMSLE\nR2 \nEVS \nMedAE\nMAPE\
    \ \naKNCN -ELM-mBOA \n0.064 0.091\n0.301 \n0.011 \n0.817 0.818 \n0.0504 \n3.932\
    \ \naKNCN- ELM-BOA \n0.067 0.095\n0.309 \n0.011 \n0.806 0.808 \n0.0529 \n3.871\
    \ \naKNCN -ELM \n0.097 0.134\n0.366 \n0.016 \n0.730 0.731 \n0.078 \n5.565 \naKNC\
    \ _ANN \n0.130 0.181\n0.426 \n0.022 \n0.636 0.636 \n0.105 \n7.809 \naKNC-SVM \n\
    0.165 0.230\n0.480 \n0.028 \n0.538 0.538 \n0.132 \n9.685 \naKNC-GB \n0.231 0.320\n\
    0.566 \n0.039 \n0.359 0.359 \n0.187 \n13.71 \naKNC-RF \n0.293 0.413\n0.642 \n\
    0.050 \n0.174 0.17 \n0.233 \n17.4 \nTable 1 provides the analysis of error \n\
    values attained by various approaches in \nterms of RMSE, MAE, MSLE, MAPE, \n\
    MedAE, EVS and MSE. MSE is the mean \nof sum of the squared errors. MSLE is the\
    \ \nsquared logarithmic error’s predicted  \nvalue. From the table, the MAE, MSE,\
    \ \nRMSE, MSLE, MedAE and MAPE value \nobtained by the proposed aKNCN -ELM-\n\
    mBOA is lower than the existing methods. \nWhile the R2 and EVS values attained\
    \ by \nthe proposed aKNCN -ELM-mBOA are \nhigher than other strategies.  \nFigure\
    \ 9: Comparative analysis on MAE, MSLE and MedAE \nFigure 9 illustrates the resultant\
    \ graph of \nMAE, MSLE and MedAE for various \napproaches. \nFrom \nthe \ngraphical\
    \ \nrepresentation, the error values for MAE, \nMSLE and MedAE obtained by the\
    \ \nproposed method is lower than the existing \nmethods. The MAE of the aKNCN-ELM-\n\
    mBOA is 0.064 and the MAE of the \naKNCN -ELM-BOA, aKNCN –ELM, \naKNC _ANN, aKNC-SVM,\
    \ aKNC-GB \nand aKNC-RF are0.067, 0.097, 0.130, \n0.165, 0.231 and 0.293 respectively.\
    \ \nSimilarly the proposed model achieves the \nbetter value of MSLE and MedAE.\
    \ In \ngeneral, if the error occurred is less in the \nprediction system then\
    \ it is considered as \nan \neffective \nmodel. \nTherefore, \nthe \nproposed\
    \ model is efficient for crop yield \nprediction. \nFigure 10: Comparative analysis\
    \ on RMSE, MSE and R2\nFigure 10 shows the resultant graph of \nRMSE, MSE and\
    \ R2 for the proposed and \nthe existing techniques. From the graphical \nrepresentation,\
    \ \nthe \nproposed \nmodel \nobtained less error values for MSE as well \nas RMSE\
    \ than other methods. However, \nR2 value attained by the proposed \napproach\
    \ is higher than the existing \ntechniques. The R2 value of the proposed \nmodel\
    \ is 0.817, where the R2 value of \naKNCN-ELM-BOA, \naKNCN \n–ELM, \naKNC-ANN,\
    \ aKNC-SVM, aKNC-GB and \naKNC-RF are 0.806, 0.730, 0.636, 0.538, \n0.359 and\
    \ 0.174. In addition the RMSE \nvalue of the proposed model is 0.301 \nwhich is\
    \ less error rate than the other \nclassification methods. Thus the proposed \n\
    model proved its performance in all the \ncases. \nFigure 11: Comparative analysis\
    \ on EVS and MAPE \nFigure 11 represents the resultant graph of \nEVS and MAPE\
    \ for the proposed and the \nexisting techniques. From the graphical \nrepresentation,\
    \ the MAPE value obtained \nby the proposed method is lesser than any \nother\
    \ methods. However, EVS value \nattained by the proposed approach is \nhigher\
    \ than the existing techniques. That \nis, MAPE value of aKNCN -ELM-mBOA \nand\
    \ aKNCN -ELM-mBOAare 3.932 and \n3.871 where the MAPE value of aKNCN–\nELM, aKNCN\
    \ -ANN, aKNCN-SVM, \naKNCN-GB and aKNCN-RF are 5.565, \n7.809, 9.685, 13.71 and\
    \ 17.1 respectively. \nIn all the metrics comparison, the proposed \nmodel has\
    \ generated better outcomes and \nother methods achieve less accuracy due to \n\
    the \ncomputational \ncomplexity \nand \noverfitting problem. Our proposed model\
    \ \nattains higher outcomes due to the optimal \nselection by mBOA.  \nFigure\
    \ 12: Accuracy measure of proposed aKNCN -ELM-mBOA and existing methods \nFigure\
    \ 12 represents the accuracy measure \nfor the proposed aKNCN-ELM-mBOA \nand \n\
    the \nexisting \napproaches. \nWhile \nconsidering the accuracy measure, the \n\
    actual and the predicted data are nearly \nsame then the system is said to be\
    \ efficient \nfor the crop yield prediction. It depicts the \nactual data and\
    \ the predicted data of \ndifferent techniques. From the graph, the \nproposed\
    \ aKNCN-ELM-mBOA predicted \nthe result more accurately than the existing \nmethods.\
    \ The proposed aKNCN-ELM-\nmBOA reached near to the actual data \nwhereas the\
    \ other techniques did not attain \na better accuracy. AKNCN-GB achieved \nvery\
    \ low accuracy that other strategies. \nTherefore, the proposed aKNCN-ELM-\nmBOA\
    \ is effective than the existing \ntechniques. \n7. Conclusion\nThis work focuses\
    \ on predicting the yield \nof the crop based on two-tier ML approach \nnamed\
    \ aKNCN and ELM-mBOA. In the \nfirst tier, the proposed aKNCN model is \nused\
    \ to estimate the soil quality based on \nIoT system collected soil nutrients.\
    \ In the \nsecond tier, the soil quality score along \nwith other crop yield related\
    \ parameters \nlike temperature and rainfall are taken as \nthe input of ELM model\
    \ to predict the crop \nyield. The hyper parameter tuning of ELM \nprediction\
    \ model is achieved by mBOA to \nenhance the prediction performance of \nELM.\
    \ PYTHON tool is used for the \nimplementation of proposed system. Soil \ndataset\
    \ \nis \nutilized \nfor \nperformance \nevaluation of the proposed prediction\
    \ \nmodel. The proposed scheme attains better \nresults than the other classification\
    \ models \non the basis of accuracy, RMSE, R2, MSE, \nMedAE, MAE, MSLE, MAPE and\
    \ EVS. \nThe RMSE and MAE of the aKNCN-\nELM-mBOA is found to be 0.301 and \n\
    0.064 respectively. In future, analysis \nbased on time-series will be done to\
    \ \npredict the future values. The use of \ndifferent parameters like soil nutrients,\
    \ soil \nquality, irrigated area and agricultural \npoints can be used to extend\
    \ the scope of \nthe research as well as improve the \naccuracy of the system.\
    \ In addition, deep \nlearning based smart agriculture can be \nused with the\
    \ IoT system in order to \nenhance the production quality. \nReferences \n[1]\
    \ Muangprathub, Jirapond, Nathaphon \nBoonnam, \nSiriwan \nKajornkasirat, \nNarongsak\
    \ \nLekbangpong, \nApirat \nWanichsombat, and Pichetwut Nillaor. \n\"IoT and agriculture\
    \ data analysis for \nsmart farm.\" Computers and electronics in \nagriculture\
    \ 156 (2019): 467-474. \n[2] Mekala, Mahammad Shareef, and P. \nViswanathan. \"\
    (t, n): Sensor Stipulation \nwith THAM index for smart agriculture \ndecision-making\
    \ \nIoT \nsystem.\" Wireless \nPersonal \nCommunications 111, \nno. \n3 \n(2020):\
    \ 1909-1940. \n[3] \nAyaz, \nMuhammad, \nMohammad \nAmmad-Uddin, \nZubair \nSharif,\
    \ \nAli \nMansour, and El-Hadi M. Aggoune. \n\"Internet-of-Things \n(IoT)-based\
    \ \nsmart \nagriculture: Toward making the fields \ntalk.\" IEEE Access 7 (2019):\
    \ 129551-\n129583. \n[4] Savchenko, Olesya M., Maik Kecinski, \nTongzhe Li, and\
    \ Kent D. Messer. \n\"Reclaimed water and food production: \nCautionary \ntales\
    \ \nfrom \nconsumer \nresearch.\" Environmental \nresearch 170 \n(2019): 320-331.\
    \  \n[5] Terence, Sebastian, and Geethanjali \nPurushothaman. \"Systematic review\
    \ of \nInternet \nof \nThings \nin \nsmart \nfarming.\" Transactions \non \nEmerging\
    \ \nTelecommunications Technologies 31, no. \n6 (2020): e3958. \n[6] Kalimuthu,\
    \ M., P. Vaishnavi, and M. \nKishore. \"Crop Prediction using Machine \nLearning.\"\
    \ In 2020 Third International \nConference \non \nSmart \nSystems \nand \nInventive\
    \ Technology (ICSSIT), pp. 926-\n932. IEEE, 2020. \n[7] Farooq, Muhammad Shoaib,\
    \ Shamyla \nRiaz, Adnan Abid, Kamran Abid, and \nMuhammad Azhar Naeem. \"A Survey\
    \ on \nthe Role of IoT in Agriculture for the \nImplementation of Smart Farming.\"\
    \ IEEE \nAccess 7 (2019): 156237-156271.  \n[8] Reddy, Kasara Sai Pratyush, Y.\
    \ \nMohana Roopa, and Narra Sai Nandan. \n\"IoT based Smart Agriculture using\
    \ \nMachine \nLearning.\" \nIn 2020 \nSecond \nInternational Conference on Inventive\
    \ \nResearch \nin \nComputing \nApplications \n(ICIRCA), pp. 130-134. IEEE, 2020.\
    \ \n[9] Miranda, Jhonattan, Pedro Ponce, \nArturo Molina, and Paul Wright. \"\
    Sensing, \nsmart and sustainable technologies for \nAgri-Food \n4.0.\" Computers\
    \ \nin \nIndustry 108 (2019): 21-36.  \n[10] Shastry, K. Aditya, and H. A. Sanjay.\
    \ \n\"Hybrid prediction strategy to predict \nagricultural \ninformation.\" Applied\
    \ \nSoft \nComputing 98 (2021): 106811. \n[11] Elavarasan, Dhivya, and PM Durairaj\
    \ \nVincent. \"Crop yield prediction using deep \nreinforcement \nlearning \n\
    model \nfor \nsustainable agrarian applications.\" IEEE \nAccess 8 (2020): 86886-86901.\
    \  \n[12] Dang, Chaoya, Ying Liu, Hui Yue, \nJiaXin Qian, and Rong Zhu. \"Autumn\
    \ \nCrop Yield Prediction using Data-Driven \nApproaches:-Support Vector Machines,\
    \ \nRandom Forest, and Deep Neural Network \nMethods.\" Canadian Journal of Remote\
    \ \nSensing (2020): 1-20.  \n[13] van Klompenburg, Thomas, Ayalew \nKassahun,\
    \ and Cagatay Catal. \"Crop yield \nprediction using machine learning: A \nsystematic\
    \ literature review.\" Computers \nand Electronics in Agriculture 177 (2020):\
    \ \n105709. \n[14] Bhojani, Shital H., and Nirav Bhatt. \n\"Wheat crop yield prediction\
    \ using new \nactivation \nfunctions \nin \nneural \nnetwork.\" Neural \nComputing\
    \ \nand \nApplications (2020): 1-11. \n[15] Gopal, PS Maya, and R. Bhargavi. \"\
    A \nnovel approach for efficient crop yield \nprediction.\" Computers and Electronics\
    \ in \nAgriculture 165 (2019): 104968. \n[16] PS, Maya Gopal. \"Performance \n\
    evaluation of best feature subsets for crop \nyield prediction using machine learning\
    \ \nalgorithms.\" Applied \nArtificial \nIntelligence 33, no. 7 (2019): 621-642.\
    \ \n[17] \nShook, \nJohnathon, \nTryambak \nGangopadhyay, \nLinjiang \nWu, \n\
    Baskar \nGanapathysubramanian, Soumik Sarkar, \nand Asheesh K. Singh. \"Crop yield\
    \ \nprediction \nintegrating \ngenotype \nand \nweather \nvariables \nusing \n\
    deep \nlearning.\" arXiv \npreprint \narXiv:2006.13847 (2020). \n[18] Nevavuori,\
    \ Petteri, Nathaniel Narra, \nPetri Linna, and Tarmo Lipping. \"Crop \nYield Prediction\
    \ Using Multitemporal \nUAV Data and Spatio-Temporal Deep \nLearning Models.\"\
    \ Remote Sensing 12, no. \n23 (2020): 4000. \n[19] Elavarasan, Dhivya, and PM\
    \ Durai \nRaj Vincent. \"A reinforced random forest \nmodel for enhanced crop\
    \ yield prediction \nby \nintegrating \nagrarian \nparameters.\" Journal \nof\
    \ \nAmbient \nIntelligence \nand \nHumanized \nComputing (2021): 1-14. \n[20]\
    \ Suchithra, M. S., and Maya L. Pai. \n\"Improving the prediction accuracy of\
    \ soil \nnutrient \nclassification \nby \noptimizing \nextreme \nlearning \nmachine\
    \ \nparameters.\" Information \nprocessing \nin \nAgriculture 7, no. 1 (2020):\
    \ 72-82. \n[21] \nAbbas, \nFarhat, \nHassan \nAfzaal, \nAitazaz A. Farooque, and\
    \ Skylar Tang. \n\"Crop yield prediction through proximal \nsensing \nand \nML\
    \ \nalgorithms.\" Agronomy 10, no. 7 (2020): \n1046. \n[22] Rezk, Nermeen Gamal,\
    \ Ezz El-Din \nHemdan, Abdel-Fattah Attia, Ayman El-\nSayed, and Mohamed A. El-Rashidy.\
    \ \"An \nefficient IoT based smart farming system \nusing ML algorithms.\" Multimedia\
    \ Tools \nand Applications 80, no. 1 (2021): 773-\n797. \n[23] Bu, Fanyu, and\
    \ Xin Wang. \"A smart \nagriculture IoT system based on deep \nreinforcement \n\
    learning.\" Future \nGeneration Computer Systems 99 (2019): \n500-507. \n[24]\
    \ Nevavuori, Petteri, Nathaniel Narra, \nand Tarmo Lipping. \"Crop yield prediction\
    \ \nwith \ndeep \nconvolutional \nneural \nnetworks.\" Computers and electronics\
    \ in \nagriculture 163 (2019): 104859. \n[25] dos Santos, U.J.L., Pessin, G.,\
    \ da \nCosta, C.A. and da Rosa Righi, R., 2019. \nAgriPrediction: A proactive\
    \ internet of \nthings model to anticipate problems and \nimprove \nproduction\
    \ \nin \nagricultural \ncrops. Computers \nand \nelectronics \nin \nagriculture,\
    \ 161, pp.202-213. \n[26] Saranya, C. P., and N. Nagarajan. \n\"Efficient agricultural\
    \ yield prediction \nusing metaheuristic optimized artificial \nneural \nnetwork\
    \ \nusing \nHadoop \nframework.\" Soft Computing 24, no. 16 \n(2020): 12659-12669.\
    \ \n[27] Filippi, Patrick, Edward J. Jones, \nNiranjan S. Wimalathunge, Pallegedara\
    \ \nDSN \nSomarathna, \nLiana \nE. \nPozza, \nSabastine U. Ugbaje, Thomas G. Jephcott,\
    \ \nStacey E. Paterson, Brett M. Whelan, and \nThomas FA Bishop. \"An approach\
    \ to \nforecast grain crop yield using multi-\nlayered, multi-farm data sets and\
    \ machine \nlearning.\" Precision Agriculture 20, no. 5 \n(2019): 1015-1029. \n\
    [28] Sun, Jie, Liping Di, Ziheng Sun, \nYonglin Shen, and Zulong Lai. \"County-\n\
    level soybean yield prediction using deep \nCNN-LSTM model.\" Sensors 19, no.\
    \ 20 \n(2019): 4363. \n[29] Sinwar, Deepak, Vijaypal Singh \nDhaka, Manoj Kumar\
    \ Sharma, and Geeta \nRani. \"AI-based yield prediction and smart \nirrigation.\"\
    \ In Internet of Things and \nAnalytics for Agriculture, Volume 2, pp. \n155-180.\
    \ Springer, Singapore, 2020. \n[30] Cao, Juan, Zhao Zhang, Fulu Tao, \nLiangliang\
    \ Zhang, Yuchuan Luo, Jing \nZhang, Jichong Han, and Jun Xie. \n\"Integrating\
    \ Multi-Source Data for Rice \nYield Prediction across China using \nMachine Learning\
    \ and Deep Learning \nApproaches.\" Agricultural \nand \nForest \nMeteorology\
    \ 297 (2021): 108275.  \n[31] Guo, Yahui, Yongshuo Fu, Fanghua \nHao, \nXuan \n\
    Zhang, \nWenxiang \nWu, \nXiuliang Jin, Christopher Robin Bryant, \nand J. Senthilnath.\
    \ \"Integrated phenology \nand climate in rice yields prediction using \nmachine\
    \ learning methods.\" Ecological \nIndicators 120 (2021): 106935. \n[32] \nWakhare,\
    \ \nPrashant \nB., \nS. \nNeduncheliyan, and Gaurav S. Sonawane. \n\"Automatic\
    \ Irrigation System Based on \nInternet of Things \nfor Crop Yield \nPrediction.\"\
    \ \nIn 2020 \nInternational \nConference \non \nEmerging \nSmart \nComputing and\
    \ Informatics (ESCI), pp. \n129-132. IEEE, 2020. \n[33] Patil, Suhas M., and R.\
    \ Sakkaravarthi. \n\"Internet of things based smart agriculture \nsystem using\
    \ predictive analytics.\" Asian \nJ. Pharm. Clin. Res 10 (2017): 148-152. \n[34]\
    \ Rosdi, B.A., Mukahar, N. and Han, \nN.T., 2021. Finger Vein Recognition \nUsing\
    \ Principle Component Analysis and \nAdaptive k-Nearest Centroid Neighbor \nClassifier.\
    \ \nInternational \nJournal \nof \nIntegrated Engineering, 13(1), pp.177-\n187..\"\
    \ \n[35] Arora, Sankalap, and Satvir Singh. \n\"Butterfly optimization algorithm:\
    \ a novel \napproach for global optimization.\" Soft \nComputing 23, no. 3 (2019):\
    \ 715-734. \n[36] Li, B., Rong, X. and Li, Y., 2014. An \nimproved kernel based\
    \ extreme learning \nmachine for robot execution failures. The \nScientific World\
    \ Journal, 2014. \nAUTHORS PROFILE \nMs. \nAkanksha \nGupta \nis \nworking as\
    \ an assistant professor in the \ndepartment \nof \nComputer \nScience, \nUniversity\
    \ of Delhi and currently pursuing \nPh.D in the area of Internet of Things, from\
    \ \nShri \nVenkateshwara \nUniversity. \nShe \ncompleted B.Sc honors in Computer\
    \ \nscience from University of Delhi in 2009 \nand MCA from Bharatiya Vidyapeeth\
    \ \ncollege, Indraprastha University, Delhi in \n2012. She has also qualified\
    \ UGC NET in \ncomputer science in 2013. She has a \nteaching experience of over\
    \ 7 years and \nhas earlier published 2 research papers in \nreputed international\
    \ journals and 2 \nchapters \nin \nedited \nbooks \nand \nalso \nparticipated\
    \ in many conferences. \nDr. Priyank Nahar pursued his \nUG \ndegree \nin \nComputer\
    \ \nApplications(BCA). He followed it with \nMCA, M.Phil(CS), Ph.D(CS). He has\
    \ over \n14 years of teaching experience. He \nworked as a corporate trainer in\
    \ companies \nlike Hewlett Packard and Integer software, \nBangalore. He has attended\
    \ more than 5 \nFDPs/seminars and conferences. He has \nwritten 5 research papers\
    \ in international \nand national journals. He has also authored \n13 books on\
    \ paper solution series along \nwith a book on VB.Net for BCA students. \nCurrently,\
    \ he is associated with MCA \ndepartment as an Associate Professor. \n"
  inline_citation: '>'
  journal: Research Square (Research Square)
  limitations: '>'
  pdf_link: https://www.researchsquare.com/article/rs-830669/latest.pdf
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: Classification and Yield Prediction in Smart Agriculture System Using IoT
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1186/s13007-023-01044-8
  analysis: '>'
  authors:
  - Xiang Dong
  - Yulin Wang
  - Peng Sun
  - Hui Huang
  - E. K. Lin
  citation_count: 1
  full_citation: '>'
  full_text: ">\nXing et al. Plant Methods           (2023) 19:66  \nhttps://doi.org/10.1186/s13007-023-01044-8\n\
    RESEARCH\nOpen Access\n© The Author(s) 2023. Open Access  This article is licensed\
    \ under a Creative Commons Attribution 4.0 International License, which \npermits\
    \ use, sharing, adaptation, distribution and reproduction in any medium or format,\
    \ as long as you give appropriate credit to the \noriginal author(s) and the source,\
    \ provide a link to the Creative Commons licence, and indicate if changes were\
    \ made. The images or \nother third party material in this article are included\
    \ in the article’s Creative Commons licence, unless indicated otherwise in a credit\
    \ line \nto the material. If material is not included in the article’s Creative\
    \ Commons licence and your intended use is not permitted by statutory \nregulation\
    \ or exceeds the permitted use, you will need to obtain permission directly from\
    \ the copyright holder. To view a copy of this \nlicence, visit http:// creat\
    \ iveco mmons. org/ licen ses/ by/4. 0/. The Creative Commons Public Domain Dedication\
    \ waiver (http:// creat iveco \nmmons. org/ publi cdoma in/ zero/1. 0/) applies\
    \ to the data made available in this article, unless otherwise stated in a credit\
    \ line to the data.\nPlant Methods\nA CNN-LSTM-att hybrid model \nfor classification\
    \ and evaluation of growth \nstatus under drought and heat stress in chinese \n\
    fir (Cunninghamia lanceolata)\nDong Xing1, Yulin Wang1, Penghui Sun1, Huahong\
    \ Huang1 and Erpei Lin1* \nAbstract \nBackground Cunninghamia lanceolata (Chinese\
    \ fir), is one of the most important timber trees in China. With the \nglobal\
    \ warming, to develop new resistant varieties to drought or heat stress has become\
    \ an essential task for breeders \nof Chinese fir. However, classification and\
    \ evaluation of growth status of Chinese fir under drought or heat stress are\
    \ \nstill labor-intensive and time-consuming.\nResults In this study, we proposed\
    \ a CNN-LSTM-att hybrid model for classification of growth status of Chinese fir\
    \ \nseedlings under drought and heat stress, respectively. Two RGB image datasets\
    \ of Chinese fir seedling under drought \nand heat stress were generated for the\
    \ first time, and utilized in this study. By comparing four base CNN models with\
    \ \nLSTM, the Resnet50-LSTM was identified as the best model in classification\
    \ of growth status, and LSTM would dra-\nmatically improve the classification\
    \ performance. Moreover, attention mechanism further enhanced performance of \n\
    Resnet50-LSTM, which was verified by Grad-CAM. By applying the established Resnet50-LSTM-att\
    \ model, the accuracy \nrate and recall rate of classification was up to 96.91%\
    \ and 96.79% for dataset of heat stress, and 96.05% and 95.88% for \ndataset of\
    \ drought, respectively. Accordingly, the  R2 value and RMSE value for evaluation\
    \ on growth status under heat \nstress were 0.957 and 0.067, respectively. And,\
    \ the  R2 value and RMSE value for evaluation on growth status under \ndrought\
    \ were 0.944 and 0.076, respectively.\nConclusion In summary, our proposed model\
    \ provides an important tool for stress phenotyping in Chinese fir, which \nwill\
    \ be a great help for selection and breeding new resistant varieties in future.\n\
    Keywords Cunninghamia lanceolata, CNN-LSTM, Attention mechanism, Drought stress,\
    \ Heat stress\nIntroduction\nBackground\n With global warming, drought and extremely\
    \ high tem-\nperature events have become more and more frequent \nin southern\
    \ China. Higher temperatures and less rainfall \ncaused by global warming will\
    \ lead to extreme weather \nevents (e.g., droughts and high temperatures) in the\
    \ \nfuture [1]. Many studies have indicated that drought \nand high temperature\
    \ were important environmental \nstresses affecting tree growth, development and\
    \ distri-\nbution, and even forest ecosystems and biogeographic \nprocesses [2–4].\
    \ Cunninghamia lanceolata (Chinese fir), \nan evergreen coniferous tree mainly\
    \ distributed in south-\nern China [5], is one of the most important timber trees\
    \ \nwith great commercial value due to its fast growth rate, \n*Correspondence:\n\
    Erpei Lin\nzjulep@hotmail.com\n1 State Key Laboratory of Subtropical Silviculture,\
    \ Zhejiang A&F University, \nHangzhou 311300, Zhejiang, China\nPage 2 of 13\n\
    Xing et al. Plant Methods           (2023) 19:66 \nhigh yield, high quality and\
    \ pest resistance [6, 7]. How-\never, frequent occurrences of extreme drought\
    \ and high \ntemperature events are becoming great risks for growth \nand biomass\
    \ production of Chinese fir [8–10]. Therefore, \nit is an important subject to\
    \ select or breed drought and \nhigh temperature resistant varieties for breeders\
    \ of Chi-\nnese fir. Although there was a long breeding history, arti-\nficial\
    \ selection on stress-resistant varieties of Chinese fir \nstill relies on expert\
    \ visual observation and physiological \nmeasurements [8, 11], which are time-consuming,\
    \ labor-\nintensive, costly and prone to human error. To develop an \nefficient,\
    \ automated and accurate method for evaluation \nand classification on growth\
    \ status is of great significance \nto stress-resistant varieties selection and\
    \ breeding in Chi-\nnese fir.\nComputer vision-based phenotyping provides a sim-\n\
    ple, rapid, and highly automated method for evaluation \nand classification on\
    \ plant physiological and growth sta-\ntus [12–14]. Especially the emergence of\
    \ convolutional \nneural networks (CNN) makes plant phenotyping under \ndifferent\
    \ stresses more and more efficient and automated. \nCNN and CNN-based methods\
    \ have been widely applied \nin related works. For instance, Lin et al. [15] proposed\
    \ a \nsemantic segmentation model based on CNN to detect \nthe powdery mildew\
    \ on cucumber leaf images at pixel \nlevel, achieving an average pixel accuracy\
    \ of 96.08%. Sel-\nvam and Kavitha classified leaf image into three catego-\n\
    ries namely healthy, disease and leaf burn in lady finger \n(Abelmoschus esculentus)\
    \ with a custom CNN architec-\nture, which achieved 96% classification accuracy\
    \ [16]. \nAnd, deep neural network was applied to detect wheat \nhead in real\
    \ time with average precision of 94.5% [17].\nAlthough single CNNs have great\
    \ performance in \nclassification and segmentation of images, they are not \n\
    appropriate for images from dynamic systems, such as \ntime-series image datasets\
    \ acquired from the whole \ngrowth period. For plant growth, temporal informa-\n\
    tion, such as growth patterns, is one of the key fac-\ntors in understanding plant\
    \ resistant capacity to stress \nand should be taken into account. This problem\
    \ can be \nsolved by using recurrent neural networks (RNN). In \nparticular, long\
    \ short-term memory (LSTM) has a very \ngood performance in analyzing dynamic\
    \ information \n[18–20]. Conjunction of CNN and LSTM could inte-\ngrate spatial\
    \ and temporal information from process-\ning signals to help predict plant growth\
    \ status more \nprecise. CNN-LSTM predictive methods have been \nwidely applied\
    \ in the field of botany research and agri-\nculture. Namin et  al. [21] combined\
    \ CNN and LSTM \nfor the classification of various Arabidopsis genotype, \nAbdalla\
    \ et  al. [22] applied Inceptionv3-LSTM frame-\nwork to diagnose the nutritional\
    \ status of oilseeds in \nthe field. Turkoglu et  al. [23] proposed Multi-model\
    \ \nLSTM-based Pre-trained Convolutional Neural Net-\nworks (MLP-CNNs) as an ensemble\
    \ majority voting \nclassifier for the detection of plant diseases and pests.\
    \ \nChang et al. [24] successfully constructed and trained \ndeep-learning models\
    \ based on the deep convolution \nneural network (DCNN) and LSTM for the nitrogen\
    \ \nnutrition diagnosis of muskmelon.\nOn the other hand, traditional deep neural\
    \ networks \noften failed to accurately locate and extract the dis-\ncriminative\
    \ regions of interest when processing images, \nespecially for the plant images,\
    \ which greatly affects the \nclassification and detection accuracy of images\
    \ [25] [26]. \nThe attention mechanism (AM) in deep learning, which \nis similar\
    \ to visual attention of human, could selectively \nfocus on the target area of\
    \ interest and ignoring the irrel-\nevant regions of the image [26–28], and then\
    \ invests \nmore attention resources in the target area to improve \nthe accuracy\
    \ image processing. Thus, the attention mech-\nanism has been used to improve\
    \ and optimize the deep \nneural network architecture. Zhang et  al. [29] used\
    \ the \nattention mechanism in natural language processing, \nwhich greatly improved\
    \ the translation accuracy. Zhang \net al. [26] successfully classified flower\
    \ images by embed-\nding spatial attention module and channel attention \nmodel\
    \ in Xception structure. Zeng et al. [30] proposed a \nSelf-Attention Convolutional\
    \ Neural Network (SACNN), \nwhich effectively extracts features of disease spots\
    \ to rec-\nognize crop diseases.\nMany deep neural models have been proposed to\
    \ clas-\nsify and evaluate the growth status of diverse broad-\nleaved plants\
    \ [31–33]. As a conifer tree, Chinese fir has \nthin, needle-like and waxy leaves,\
    \ which are completely \ndifferent from broad leaves. The phenotypic changes \n\
    of Chinese fir plants under stresses, such as changes in \nneedle color and degrees\
    \ of leaf wilting, are distinctly \ndifferent to those broad-leaved plants. Those\
    \ deep neu-\nral models fitting for broad-leaved plants are not suitable \nfor\
    \ needle-leaved tree, such as Chinese fir. It is still a big \nchallenge to classify\
    \ and evaluate the growth status of \nChinese fir under different stresses through\
    \ deep neural \nnetworks. In addition, the model should overcome the \ninterference\
    \ caused by the appearance similarity of differ-\nent status. Considering the\
    \ great importance of Chinese \nfir in timber industry of China, and the potential\
    \ negative \nimpact of climate change and global warming on produc-\ntion of Chinese\
    \ fir, it is urgent and meaningful to develop \nimage-based methods for classification\
    \ of growth status \nunder drought and heat stress to facilitate breeding pro-\n\
    grams. To address the above issues, a hybrid deep learn-\ning network CNN-LSTM-att\
    \ was designed to classify and \nevaluate the growth status of Chinese fir seedlings\
    \ under \ndrought and heat stress. The detailed contributions are \nstated as\
    \ follows:\nPage 3 of 13\nXing et al. Plant Methods           (2023) 19:66 \n\
    \ \nA) Since there was no publicly available image data-\nset of Chinese fir seedlings\
    \ under drought stress or \nheat stress, we created two image datasets based on\
    \ \ndrought and heat treatment of Chinese fir seedlings, \nrespectively. And,\
    \ the growth status of Chinese fir \nseedling in each image was also manual scored\
    \ with a \nvalue between 0 and 1.0.\nB) We combined CNN and LSTM to learn and\
    \ clas-\nsify the temporal and spatial information of growth \nand damage degree\
    \ of Chinese fir seedlings under \ndrought and heat stress, respectively. Compared\
    \ with \nbase CNN network, the classification accuracy has \nbeen greatly improved.\n\
    C) We embedded the attention mechanism into the \nbackbone network of the CNN-LSTM\
    \ to enhance \nthe feature extraction ability of the network.\nD) We proposed\
    \ a CNN-LSTM-att model to classify \nand evaluate the growth status of seedlings\
    \ under \ndrought and heat stress, which provides a useful tool \nfor stress phenotyping\
    \ on a large number of germ-\nplasms in Chinese fir.\nMaterials and methods\n\
    Plant materials and stress treatment\nTo create the image datasets of Chinese\
    \ fir under drought \nand heat stress, the seedlings were treated by artificial\
    \ \ndrought and heat stress, and images were then taken at \ndifferent time point.\
    \ The seeds of Chinese fir, obtained \nfrom an orchard in Kaihua forest farm of\
    \ Zhejiang Prov-\nince, China, were used to cultivate the seedlings in a \ngreen\
    \ house. The seedlings with about 20  cm in plant \nheight were subjected to heat\
    \ and drought stress, respec-\ntively. For the heat stress, 55 seedlings were\
    \ selected and \nplaced in a growth chamber, and the environment was \nset as\
    \ follows: temperature 43 ℃, relative humidity 80% \nand Photosynthetic Photon\
    \ Flux Density (PPFD) 200 \nµmol.  m− 2.  s− 1. And, the treatment was performed\
    \ in \nthe growth chamber for 30 h. For the drought treatment, \n45 seedlings\
    \ were used, and the drought condition was \nsimulated by irrigation with 20%\
    \ PEG6000. 30 ml of 20% \nPEG6000 solution was irrigated to each seedling every\
    \ 7 \ndays, and the treatment was performed in a greenhouse \nfor 35 days.\nImage\
    \ acquisition and annotation\nThe images were captured by Canon camera (PowerShot\
    \ \nSX720 HS, Canon Inc., Tokyo, Japan) in a small photo \nstudio. Images of seedlings\
    \ under heat stress were pho-\ntographed at regular intervals of 6 hours, and\
    \ images of \nseedlings under drought stress were taken every seven \ndays. For\
    \ each seedling, images were taken from eight \nangles at every  45◦. In order\
    \ to ensure the robustness \nof the classification, we take pictures at a fixed\
    \ position, \nso that all images of a dataset were taken from the same \nangle.\
    \ The parameters for taking photographs including \nlighting condition, the camera\
    \ distance, image size in pix-\nels, and other information were listed in Table 1.\
    \ Finally, \n2424 images (404 images of each session) were captured \nfor the\
    \ seedlings under drought stress, and 1776 images \n(296 images of each session)\
    \ were captured for the seed-\nlings under heat stress. Based on the growth status\
    \ of \nseedlings, each image was manually scored with a value \nfrom 0 to 1.0\
    \ as a label, which was used in loss function. \nAccordingly, the growth status\
    \ of seedlings from drought \nand heat stress was classified into 6 sessions,\
    \ respectively \n(Fig. 1). A stratified 5-fold cross-validation approach was \n\
    utilized to evaluate models. For that, 80% of images were \nprepared for training,\
    \ and 20% were taken for the testing. \nAnd, 20% of training data was used as\
    \ a validation set to \nprevent overfitting problems.\nDeep learning‑based feature\
    \ extraction\nAlthough several pre-trained CNN architectures have \nbeen proposed\
    \ for plant phenotyping [21], selecting the \nmost appropriate CNN architectures\
    \ for depth feature \n(DF) extraction is a challenging task. In this study, we\
    \ \nused VGG16 [34], AlexNet [35], ResNet18 and ResNet50 \n[36] for training.\
    \ All these networks were pre-trained \non the ImageNet public dataset to classify\
    \ the images \ninto 1000 classes. These networks differed in the input \nsize,\
    \ number of layers, and the number of the learnable \nparameters. In our study,\
    \ the last layers of these networks \nwere replaced by a classification layer\
    \ with 6 neurons to \nclassify images into six sessions. Before training, the\
    \ RGB \nimage size is adjusted to (448,448,3) to fit different net-\nworks. We\
    \ used transfer learning to fine-tune pre-trained \nCNNs models on the ImageNet\
    \ [37] dataset, and then \nused these models to classify Chinese fir seedlings\
    \ under \nheat stress and drought stress, and subsequently used \nTable 1 Parameters\
    \ used for image acquisition\nTreatment\nImage size in pixels\nImage Type\nTotal\
    \ Images\nLight used\nDistance \nof \ncamera\nHeat\n3072 × 3072\nRGB(JPEG)\n2424\n\
    Fluorescent tubes\n0.2 m\nDrought\n3072 × 3072\nRGB(JPEG)\n1776\nFluorescent tubes\n\
    0.2 m\nPage 4 of 13\nXing et al. Plant Methods           (2023) 19:66 \nthese\
    \ models as feature extractors for the CNN-LSTM \nmodel. Stochastic gradient descent\
    \ algorithm was applied \nto optimize the model performance.\nCNN‑LSTM architecture\n\
    The growth and development of plants are a dynamic \nprocess not only related\
    \ to spatial, but also associated \nwith temporal information, which are not considered\
    \ \nin conventional CNN model. As a specialized form of \nRecurrent Neural Network\
    \ (RNN) architecture, the \nLSTM network can learn long-term dependencies and\
    \ \npreserve useful temporal information for an extended \nperiod [38]. Compared\
    \ with simple RNN, the LSTM is \nmore suitable for sequential data such as time-series.\
    \ To \ndate, the LSTM has been widely used in jump shot per-\nformance in youth\
    \ basketball, language modeling, speech \nrecognition and stock price prediction\
    \ [39–42]. Also, \nthe LSTM was exhibited excellent capabilities in plant \ngrowth\
    \ and development prediction, prediction of dis-\neased rice plant and nutrient\
    \ status diagnosis of infield \noilseed rape [22, 43, 44]. In our study, as presented\
    \ in \nFig.  2, the LSTM was mainly composed of forget gate, \ninput gate, output\
    \ gate which were used to control the \ncell state. All these gates connect the\
    \ input of the cur-\nrent time step(xt) to the hidden state of the previous time\
    \ \nstep(ht − 1). The forget gate is responsible for deciding \nFig. 1 Representative\
    \ images of the two datasets. a Drought stress b heat stress\nFig. 2 The main\
    \ components of the LSTM unit\nPage 5 of 13\nXing et al. Plant Methods       \
    \    (2023) 19:66 \n \nwhich cell states from the previous time step should be\
    \ \npreserved. The input gate controls how much of the new \ninput data should\
    \ be recorded into the cell state. The out-\nput gate completes the selective\
    \ memory, update of the \ninformation and outputs the piece of the information\
    \ \nusing the sigmoid and the tanh.\nCNN-LSTM hybrid model has been successfully\
    \ used \nin tasks requiring sequence learning of visual features \n[45], like\
    \ video classification and activity recognition \nin videos [18, 46]. Our task\
    \ was similar to activity clas-\nsification in videos that predict which activity\
    \ is being \nperformed by analyzing visual changes over time. Thus, \nwe proposed\
    \ a modified CNN-LSTM model to clas-\nsify growth status of Chinese fir seedlings\
    \ under heat \nand drought stress. Our CNN-LSTM architecture for \nheat and drought\
    \ stress is shown in Fig. 3. The workflow \nwas briefly described here. At first,\
    \ the time series data-\nset and the manual scored value were fed into the CNN\
    \ \nmodel for feature extraction. Then, deep features were \nextracted from the\
    \ last fully-connected (FC) layers of the \nCNN models and fed to the LSTM model.\
    \ The number \nof sequentially connected cells is equal to the number of \nsession\
    \ data used for prediction. The LSTM network out-\nput is fed into a fully connected\
    \ layer of size 512-D, which \nis connected to the fully connected Layer of size\
    \ 6, equal \nto k heat and drought stress. The cross-entropy loss and \nL2 loss\
    \ were employed as a loss function, and hyperpa-\nrameters of the LSTM are presented\
    \ in Table 2.\nImprove CNN‑LSTM with attention mechanism\nAttention‑based modules\n\
    The attention mechanism in deep learning is similar to \nvisual attention of humans,\
    \ which selectively focuses on \nthe information that is beneficial to the final\
    \ result. In our \nstudy, attention mechanism was introduced into CNN-\nLSTM to\
    \ improve the classification accuracy.\nThe proposed approach is illustrated in\
    \ Fig.  4. Block \n1/2/3 is the local feature, which is the intermediate fea-\n\
    ture output at different scales in the ResNet50 network. \nBlock4 is treated as\
    \ a global feature, which has the entire \ninput image as support and outputs\
    \ by the network’s \nseries of convolutional and nonlinear layers. Local and \n\
    global features were fed into the attention mechanism, \nand the estimator can\
    \ generate new feature maps instead \nof local features of the image. Concatenating\
    \ the output \nof different local feature maps and Resnet50 last layer as \nthe\
    \ new output, and the final output is fed into the fully \nconnected layer classifier\
    \ (FC-2, 1024).\nThe modified backbone of network replaces the origi-\nnal backbone\
    \ of network and sends the output result \nof the fully connected layer into the\
    \ LSTM cell. A task-\ndriven attention estimator was designed (Fig. 4). Take \n\
    intermediate features and global features as input, \nthe dimension local information\
    \ is compressed to 1 \nby a 1 × 1 convolution kernel and then normalized by \n\
    softmax operation. The normalized features are then \nFig. 3 The proposed CNN-LSTM\
    \ framework for time-series image dataset in our study\nTable 2 Description of\
    \ the LSTM architecture hyperparameters\nParameters\nSpecification\nInput gate\n\
    Sigmoid\nForget gate\nSigmoid\nOutput gate\nSigmoid and tanh\nHidden layer\nTanh\n\
    Number of layers\n1\nPage 6 of 13\nXing et al. Plant Methods           (2023)\
    \ 19:66 \nmultiplied by the Block4, by element-wise multiplica-\ntion. By defining\
    \ a compatibility measure between local \nand global features, we redesign the\
    \ standard architec-\nture to classify input images using a weighted combi-\n\
    nation of local and global features, so the network is \nforced to learn attention\
    \ patterns relevant to solving \nthe task at hand.\nLoss function\nhe loss function\
    \ denotes the differences between the \nprediction and the ground truth, which\
    \ is essential for \nnetwork training. In this study, cross-entropy loss and \n\
    L2 loss function were used to train the network. The \nloss of the network is\
    \ computed using Eqs. (1)–(3).\n(1)\nL = Lcls + Lpro\n(2)\nLcls = −\nn\n\x1F\n\
    i=0\ncilog\n\x1E\nˆci\n\x1D\nwhere  Lcls is the loss of classification,  Lpro\
    \ is the loss \nof manual scored value regression. ci and \x1Fci denote the \n\
    predicted and truth classification. yi and \x1Fyi denote the \npredicted scores\
    \ and manual scored value.\nThis study is multi-task learning with regression\
    \ and \nclassification objectives. Multi-task learning aims to \nimprove learning\
    \ efficiency. However, the performance \nof multi-task learning strongly depends\
    \ on the relative \nweight between losses of each task. Manually adjust-\ning\
    \ these weights is a difficult and expensive process \n[47]. In this study, a\
    \ principled multi-task deep learn-\ning method is adopted to measure multiple\
    \ loss func-\ntions by considering the homoscedasticity uncertainty \nof each\
    \ task [48] The homoscedasticity uncertainty is \nindependent of the input and\
    \ depends on the inher-\nent uncertainty of the task. By transforming the homo-\n\
    scedasticity uncertainty into the weight of the loss, \nthe model can have the\
    \ ability to dynamically adjust \nthe loss [49]. This allows tasks to simultaneously\
    \ learn \n(3)\nLpro = 1\nn\nn\n\x1F\ni=0\n(yi − ˆyi)2\nFig. 4 Attention introduced\
    \ at 3 distinct layers of ResNet50 and the structure of designed task-driven attention\
    \ estimator\nPage 7 of 13\nXing et al. Plant Methods           (2023) 19:66 \n\
    \ \nvarious quantities with different units or scales in both \nclassification\
    \ and regression settings. Multi-task loss \nfunction is defined as follows:\n\
    Parameters σ 2\ncla , σ 2\npro correspond to the loss and the \ndata-based adaptive\
    \ weights ofLcla and Lpro.\nClassification and evaluation criteria\nThis study\
    \ intends to use a confusion matrix to classify \nand evaluate the plant growth\
    \ status under stresses. The \nperformance of the model was evaluated at the pixel\
    \ level \nand target level (plant part). In both cases, the assess-\nment is based\
    \ on accuracy (Acc), precision (Pr), recall \n(Re) and F1 scores. The four parameters\
    \ can be calcu-\nlated by Eqs. (5)–(8). TP, TN, FP and FN represent true \npositive,\
    \ true negative, false positive and false negative \nrespectively; The total number\
    \ of all states is N.\nThe performances of regression models were assessed \n\
    using the determination coefficient  (R2) and root \nmean square error (RMSE),\
    \ which were calculated by \nEqs. (9)–(10).\n(4)\nLOSS\n\x1F\nW, σ 2\ncla, σ 2\n\
    pro\n\x1E\n=\n1\n2σ 2\ncla\nLcla(W) +\n1\n2σ 2\npro\nLpro(W)\n+ log\n\x1F\nσ 2\n\
    cla\n\x1E\n+ log\n\x1F\nσ 2\npro\n\x1E\n(5)\nAccuracy = TP + TN\nN\n× 100%\n(6)\n\
    precision =\nTP\nTP + FP × 100%\n(7)\nrecall =\nTP\nTP + FN × 100%\n(8)\nF1score\
    \ = 2 × precision · recall\nprecision + recall\n(9)\nR2 = 1 −\n\x1Fn\ni (yi −\
    \ \x1Eyi)2\n\x1Fn\ni (yi−\n−y i)\n2\nwhere yi and \x1Fyi are the manual scored\
    \ and predicted \nvalues, respectively. \n−y i is the mean of the measured val-\n\
    ues, and n is the total number of samples in the testing \ndataset.\nExperimental\
    \ setting\nThe training and testing of the model were performed \non an Ubuntu\
    \ Linux workstation equipped with one \nIntel Xeon Processor CPU (96 GB RAM) and\
    \ two Nvidia \nGeForce RTX 3060Ti graphics cards for acceleration, \neach with\
    \ 12 GB of video memory. The model is imple-\nmented in the Pytorch 1.12.1 and\
    \ CUDA 11.3 deep learn-\ning open-source framework using Python 3.7. Neural \n\
    network weights are optimized using Adam optimizer. \nThe initial learning rate,\
    \ momentum factor and batch size \nwere set to 0.001, 0.9 and 30, respectively,\
    \ and 300 epochs \nwere trained.\nResults\nComparison of AlxNet, VGG16, resnet18\
    \ and resnet50\nAt the beginning, we trained and evaluated four CNN \nmodels including\
    \ AlxNet, VGG16, Resnet18 and \nResnet50, which were frequently used as feature\
    \ extrac-\ntors in plant phenotyping. The results showed that \nResnet50 network\
    \ had the best classification effect on \nplant images from drought and heat stress\
    \ (Table  3). \nWhen training with Resnet50, for images from heat \nstress, the\
    \ Acc, Pr, Re and F1 scores were 77.05%, 76.74%, \n76.94% and 76.84%, respectively\
    \ (Table  3), while for \nimages of drought stress, the Acc, Pr, Re and F1 scores\
    \ \nwere 75.20%, 75.33%, 75.19% and 75.26%, respectively, \n(Table  3). It indicated\
    \ the outperformance of Resnet50 \nin these CNN models. Resnet50 has more parameters\
    \ \nthan Alxnet, VGG16 and Resnet18, and the larger the \nmodel, the higher the\
    \ fitting degree, and the better the \n(10)\nRMSE =\n\x1F\x1En\ni=1(yi − \x1D\
    yi)2\nn\nTable 3 Performance of the four CNN models in classification of \nChinese\
    \ fir seedlings under drought and heat stress\nStress\nCNN Model\nAcc (%)\nPr\
    \ (%)\nRe(%)\nF1‑score (%)\nHeat\nAlxnet\n69.94\n69.80\n69.90\n69.84\nVGG16\n\
    69.47\n68.87\n69.44\n69.15\nResnet18\n71.91\n71.88\n71.77\n71.82\nResnet50\n77.05\n\
    76.74\n76.94\n76.84\nDrought\nAlxnet\n70.29\n70.44\n70.26\n70.34\nVGG16\n69.06\n\
    70.21\n69.03\n69.61\nResnet18\n71.72\n72.11\n71.70\n71.90\nResnet50\n75.20\n75.33\n\
    75.19\n75.26\nPage 8 of 13\nXing et al. Plant Methods           (2023) 19:66 \n\
    classification performance for heat and drought stress. \nOn the other hand, better\
    \ performance of Resnet50 was \nshown on heat stress images than drought stress\
    \ images, \nwhich was possibly caused by more obvious change in the \nneedle color\
    \ of Chinese fir seedlings after heat stress. In \nother words, visual changes\
    \ brought about by heat stress \nare more pronounced than drought stress, so it\
    \ is easier \nto classify Chinese fir seedlings images after heat stress.\nConstruction\
    \ of CNN‑LSTM hybrid models\nTo take the temporal information into consideration,\
    \ \nfour hybrid models based on above CNN models and \nLSTM were constructed,\
    \ and their performances of \nclassification on growth status of Chinese fir seedlings\
    \ \nunder heat and drought stress were then compared, \nrespectively. As a result,\
    \ the performances of all four \nCNN models were improved after conjunction with\
    \ \nLSTM (Table  4). Still, Resnet50-LSTM had the best \nperformance. The Acc,\
    \ Pr, Re and F1-score for images \nof drought stress reached up to 91.80%, 91.83%,\
    \ 91.65% \nand 91.74%, respectively. And, the Acc, Pr, Re and \nF1-score for images\
    \ of heat stress reached up to 92.18%, \n92.14%, 92.06% and 92.10%, respectively\
    \ (Table  4). \nMeanwhile, the confusion matrices also showed that \nResnet50-LSTM\
    \ hybrid model possessed the most \npowerful ability in classification of growth\
    \ status for \nseedlings under drought and heat stress (Fig. 5).\nResnet50‑LSTM\
    \ versus resnet50‑LSTM‑att\nTo further improve the CNN-LSTM architecture, \nattention\
    \ mechanism (AM) was introduced into \nTable 4 Performance of the CNN-LSTM models\
    \ on classification \nof Chinese fir seedlings under drought and heat stress\n\
    Stress\nCNN‑LSTM Model\nAcc (%)\nPr (%) Re (%) F1‑score (%)\nHeat\nAlxNet-LSTM\n\
    82.72\n83.33\n82.61\n82.95\nVGG16-LSTM\n83.74\n84.16\n83.64\n83.90\nResnet18-LSTM\n\
    85.80\n86.17\n85.69\n85.93\nResnet50-LSTM\n92.18\n92.14\n92.06\n92.10\nDrought\n\
    AlxNet-LSTM\n81.92\n82.60\n81.78\n82.19\nVGG16-LSTM\n83.61\n84.31\n83.47\n83.89\n\
    Resnet18-LSTM\n87.28\n87.62\n87.14\n87.38\nResnet50-LSTM\n91.80\n91.83\n91.65\n\
    91.74\nFig. 5 Confusion matrix of classification effects of the four CNN-LSTM\
    \ models. Heat stress:a AlxNet-LSTM, bVGG16-LSTM, c ResNet18-LSTM and (d) \nResNet50-LSTM.\
    \ Drought stress:e AlxNet-LSTM, f VGG16-LSTM, g ResNet18-LSTM and hResNet50-LSTM.\n\
    Table 5 Performance of Resnet-LSTM model before and after \nintroducing attention\
    \ mechanism\nStress\nModel\nAcc (%)\nPr(%)\nRe(%)\nF1‑score (%)\nHeat\nResnet50-LSTM\n\
    92.18\n92.14\n92.06\n92.10\nResnet50-LSTM-att\n96.91\n96.81\n96.79\n96.80\nDrought\n\
    Resnet50-LSTM\n91.52\n91.52\n91.37\n91.44\nResnet50-LSTM-att\n96.05\n95.92\n95.88\n\
    95.90\nPage 9 of 13\nXing et al. Plant Methods           (2023) 19:66 \n \nResnet50-LSTM.\
    \ As shown in Table 5, the introduction \nof attention mechanism leads to a significant\
    \ improve-\nment over Resnet50-LSTM in the classification task. \nCompared with\
    \ the Resnet50-LSTM model, the per-\nformance of Resnet50-LSTM-att in the classification\
    \ of \nheat and drought datasets was significantly improved. \nThe Acc, Pr, Re\
    \ and F1-score of heat stress were 96.91%, \n96.81%, 96.79%, and 96.80%, respectively.\
    \ And, the Acc, \nPr, Re and F1-score of drought stress reached 96.05%, \n95.92%,\
    \ 95.88%, and 95.90%, respectively (Table 5). And, \nthe confusion matrix also\
    \ showed better classification \nresults by Resnet50-LSTM-att (Fig.  6). Obviously,\
    \ the \nclassification accuracy of the network model is signifi-\ncantly improved\
    \ after the fusion attention module.\nVerification of CNN_attention feature extractor\
    \ using \nGrad‑CAM\nAttention mechanism gives more weight to important \nareas,\
    \ and pays attention to more differentiated infor-\nmation regions in images,\
    \ which improves the feature \nextraction ability for images, thus improving the\
    \ classi-\nfication accuracy in our study. Through Grad-CAM, the \nclass activation\
    \ graph of network layer was visualized \nbefore and after attention mechanism\
    \ introduced into the \nResnet50-LSTM model. As shown in Fig.  7, compared \n\
    with Resnet50-LSTM, Resnet50-LSTM-att network pays \nmore accurate attention to\
    \ the areas where seedlings \nlocated, which means the Resnet50-LSTM-att network\
    \ \ngives more weight to the important areas and less weight \nto the unimportant\
    \ areas. More specifically, before intro-\nducing of AM, the area of the Resnet50-LSTM\
    \ network \nattention to in the image included both the seedling and \nsome background\
    \ regions, which would result in a nega-\ntive impact on the final classification.\
    \ After the introduc-\ntion of the AM, the attention region of the network is\
    \ \nmore concentrated to the region of Chinese fir seedling \ninside the image.\
    \ This explains why AM could improves \nthe accuracy of the final classification\
    \ in our study.\nEvaluation of growth status by using Resnet50‑LSTM‑att \nmodel\n\
    Based on Resnet50-LSTM-att hybrid model, the \ngrowth status of seedling from\
    \ image of test set was \nevaluated by giving a predict score. As shown in Fig. 8,\
    \ \nthe growth status of seedlings was successfully evalu-\nated with a prediction\
    \ score, and classified into six \nsessions. Correlation analysis showed that\
    \ the  R2 and \nRMSE were 0.957and 0.067 for the dataset of heat \nstress, respectively,\
    \ and,  R2 and RMSE were 0.944and \n0.076 for the dataset of drought stress, respectively\
    \ \n(Fig.  9). This means that the predicted results were \nin good agreement\
    \ with the manual scoring results. \nAccording to the predicted score, it is easier\
    \ to deter-\nmine the growth status of seedlings. All these results \nindicated\
    \ that Resnet50-LSTM-att was the best model \nfor this study. Our framework provides\
    \ a faster, more \nconvenient and accurate method for classification and \nevaluation\
    \ on growth status of Chinese fir seedlings \nFig. 6 Confusion matrix of the classification\
    \ effects of Resnet50-LSTM-att on image datasets of a heat stress and b drought\
    \ stress\nPage 10 of 13\nXing et al. Plant Methods           (2023) 19:66 \nunder\
    \ heat and drought stress. Due to the flexibility \nof the proposed framework,\
    \ it also could be utilized in \ndetection and classification of images from different\
    \ \nstress conditions in needle-leaved plants.\nDiscussion\nIn past decades, the\
    \ development of deep learning and \nimage processing provides a great opportunity\
    \ for their \napplications in plant phenotyping. Many methods based \nFig. 7 Visualization\
    \ results of class activation maps before and after adding the attention mechanism.\
    \ The highlighted part of the class activation \nmap represents the attention\
    \ of the network on to the image, and the red intensity is proportional to the\
    \ strength of the neural activation with \nrespect to the predicted class. a The\
    \ original image b The region of attention before adding the attention mechanism\
    \ c The region of attention after \nadding the attention mechanism\nFig. 8 Prediction\
    \ of the growth status of Chinese fir seedlings from test dataset. a Heat stress\
    \ b drought stress\nPage 11 of 13\nXing et al. Plant Methods           (2023)\
    \ 19:66 \n \non different deep learning models have been proposed \nand applied\
    \ in yield prediction, disease detection, growth \nmonitoring, nutrient status\
    \ diagnosis and other tasks \nin crops and horticultural plants [50–52]. For example,\
    \ \nAbdalla et al. [22] proposed an Inceptionv3-LSTM model \nfor automatic nutrient\
    \ status diagnosis during the whole \nlife cycle of the Oilseed rape. Fan et \
    \ al. [53] proposed \na deep learning framework for segmentation and leaf \ncounting\
    \ in plant, which achieved good results in Arabi-\ndopsis and tobacoo plants.\
    \ Besides, in order to detect and \ncount rice panicle, Wang et  al. [54] built\
    \ a PanicleDe-\ntect model based on YOLOv5x, which was proved to be \nrobust and\
    \ accurate for counting panicles in field images \nof rice. Similarly, Yu et al.\
    \ [55] proposed a fast method \nfor soybean disease recognition based on residual\
    \ atten-\ntion network (RANet) model. And, Zhou et al. [56] suc-\ncessfully utilized\
    \ Mask R-CNN to detect bruising on \nstrawberry images captured by color cameras\
    \ under \nincandescent light and ultraviolet (UV) light. These stud-\nies showed\
    \ broad applications of deep learning models in \nrecognition, classification\
    \ and evaluation of phenotypic \ncharacteristics in diverse plants.\nChinese fir\
    \ distributed widely in southern China is one \nof the main timber trees of plantation\
    \ in China. In the \ncontext of global warming, it has been an important task\
    \ \nto select and develop new stress-resistant varieties for \nbreeders of Chinese\
    \ fir. The main object of this work is \nto provide a fast, automated and noninvasive\
    \ method for \nclassification and evaluation on growth status of Chinese \nfir\
    \ seedlings under drought and heat stress, which could \nreduce labor and costs,\
    \ and raise efficiency and accu-\nracy of breeding works. In previous studies,\
    \ a prediction \nmodel, which based on spatiotemporal long short-term \nmemory\
    \ (ST-LSTM) and memory network memory \n(MIM), was proposed to predict the image\
    \ sequences \nof future growth and development in wheat [43]. Azimi \net al. [57]\
    \ proposed a deep learning pipeline for the tem-\nporal analysis of stress-induced\
    \ visual changes in plants \nand applied it to the identification of specific\
    \ water stress \nsituations in plant shoot images of chickpea. In our study, \n\
    a hybrid Resnet-LSTM model with AM was designed \nand constructed for the stress\
    \ phenotyping of Chinese fir \nseedlings. Our proposed model could classify the\
    \ growth \nstatus of Chinese fir seedlings based on their images from \ndrought\
    \ and heat stress, and the model could also accu-\nrately evaluate the growth\
    \ status of the seedling with a \nprediction value (Fig. 9). Similarly, if sufficient\
    \ data could \nbe provided, we believe that the proposed model would \nbe feasible\
    \ for larger seedlings of Chinese fir, other coni-\nfers with needle-like leaves,\
    \ and those stress conditions \nthat can induce similar phenotypic changes. Of\
    \ course, \nmore data should be collected from seedlings of differ-\nent sizes\
    \ and stress conditions to verify the feasibility. In \nsummary, this model would\
    \ potentially become a power-\nful tool for breeders to select and develop stress\
    \ resistant \nvarieties. Meanwhile, by utilizing this model in future, \nirrigation\
    \ management in the cultivation of Chinese fir \nFig. 9 Correlation analysis between\
    \ manual and prediction scores. a Heat stress b drought stress\nPage 12 of 13\n\
    Xing et al. Plant Methods           (2023) 19:66 \nseedlings would probably be\
    \ more efficient so that more \nwater resources and manpower could be saved.\n\
    Advances in phenomics and genomics have brought \nunprecedented amounts of new\
    \ data, which requires \nmore intelligent and more efficient tools to deal with.\
    \ \nAs an important aspect of artificial intelligent (AI), deep \nlearning has\
    \ merged as a versatile tool in phenotypic \nanalysis and breeding practice. However,\
    \ in contrast to \ncrops or several important fruit plants, much less appli-\n\
    cations of deep learning principles have been reported in \ntimber trees. In this\
    \ study, for the first time, we proposed \na CNN-LSTM-att model as a tool for\
    \ stress phenotyping \nof Chinese fir seedlings. To ensure the accuracy, robust-\n\
    ness and predictive power, two datasets consisting of \n2424 and 1776 images were\
    \ generated to train the model. \nInterestingly, we found that a sample size of\
    \ at least 1000 \nimages is required to effectively train the model (data not\
    \ \nshown). This means that relatively large amounts of data \nare still necessary\
    \ to build a useful deep learning model. \nOn the other hand, it is actually difficult\
    \ to characterize \nthe phenotypic changes of seedlings under stress condi-\n\
    tions with only one or a few indicators. More morpho-\nlogical and physiological\
    \ indicators should be collected to \ntrain such a deep learning model, so that\
    \ the classification \nand evaluation by the model would have more biologi-\n\
    cal meaning. Our study is an interesting and meaningful \nattempt for application\
    \ of deep learning method in stress \nphenotyping of Chinese fir. It provides\
    \ a good reference \nfor similar timber tree, and would help to promote their\
    \ \nbreeding programs.\nConclusion\nIn this study, a hybrid deep learning model\
    \ Resnet50-\nLSTM-att was proposed to classify and evaluate the \ngrowth status\
    \ of Chinese fir seedlings under drought and \nheat stress. Our study showed the\
    \ importance of intro-\nducing time series information to detect the growth sta-\n\
    tus of Chinese fir seedlings. By comparing four base CNN \nmodels, Rensnet50 was\
    \ selected as the backbone net-\nwork. Conjunction of Resnet50 with LSTM dramatically\
    \ \nimproves classification accuracy for both image data-\nsets of the Chinese\
    \ fir seedlings under drought and heat \nstress. Furthermore, introduction of\
    \ the attention mech-\nanism, which would drive the Resnet50-LSTM model \npay\
    \ more attention to the region where seedling located \ninside the image, could\
    \ greatly improve the performance \nof the model. By utilizing the Resnet50-LSTM-att\
    \ model, \nthe accuracy rate, precision rate, recall rate and F1-score \nof classification\
    \ on the dataset of heat stress were 96.91%, \n96.81%, 96.79%, and 96.80%, respectively.\
    \ And, the accu-\nracy rate, precision rate, recall rate and F1-score of clas-\n\
    sification on the dataset of drought stress were 96.05%, \n95.92%, 95.88%, and\
    \ 95.90%, respectively. Accordingly, \nR2 value and RSME value for evaluation\
    \ on growth status \nunder heat stress were 0.957 and 0.067, respectively. And,\
    \ \nR2 value and RSME value for evaluation on growth status \nunder drought were\
    \ 0.944 and 0.076, respectively. In con-\nclusion, a Resnet50-LSTM hybrid model\
    \ with attention \nmechanism was designed and constructed in our study. \nThis\
    \ hybrid model is robust and accurate in classification \nand evaluation of growth\
    \ status of Chinese fir seedlings \nunder drought and heat stress.\nAcknowledgements\n\
    Not applicable.\nAuthor contributions\nDX. and EL. conceived the idea for the\
    \ paper. DX, YW. and PS. contributed to \nthe data collection. DX, YW, and EL.\
    \ contributed to the data curation; DX. and \nPS. wrote the code, designed, and\
    \ conducted the experiments. DX, HH, and \nEL. contributed to the writing of original\
    \ draft.\nFunding\nThis research was supported by Key research and development\
    \ project of \nZhejiang Province (2021C02054), and Zhejiang Science and Technology\
    \ Major \nProgram on Agricultural New Variety Breeding (2021C02070-8).\nAvailability\
    \ of data and materials\nThe datasets used analyzed during the current study are\
    \ available from the \ncorresponding author on reasonable request.\nDeclarations\n\
    Ethics approval and consent to participate\nNot applicable.\nConsent for publication\n\
    Not applicable.\nCompeting interests\nThe authors declare that there is no conflict\
    \ of interest regarding the publica-\ntion of this article.\nReceived: 6 April\
    \ 2023   Accepted: 22 June 2023\nReferences\n 1. \nAllan RP, et al. IPCC, 2021:\
    \ Summary for policymakers in climate change \n2021: the physical science basis\
    \ 2021. In: Masson-Delmotte V, editor., \net al., Contribution of working group\
    \ i to the sixth assessment report of \nthe intergovernmental panel on climate\
    \ change. Cambridge: Cambridge \nUniversity Press; 2021.\n 2. \nAllen CD, et al.\
    \ A global overview of drought and heat-induced tree mor-\ntality reveals emerging\
    \ climate change risks for forests. For Ecol Manag. \n2010;259(4):660–84.\n 3.\
    \ \nJing MD et al. Warming-induced drought leads to tree growth decline \nin subtropics:\
    \ evidence from tree rings in central China. Front Plant Sci, \n2022. 13.\n 4.\
    \ \nChoat B, et al. Global convergence in the vulnerability of forests to \ndrought.\
    \ Nature. 2012;491(7426):752–5.\n 5. \nWang B, et al. Biomass carbon pools of\
    \ Cunninghamia lanceolata (Lamb.) \nHook. Forests in subtropical China: characteristics\
    \ and potential. Scand J \nFor Res. 2012;27(6):545–60.\n 6. \nZhou T, et al. Effects\
    \ of elevated mean and extremely high temperatures \non the physio-ecological\
    \ characteristics of geographically distinctive \npopulations of Cunninghamia\
    \ lanceolata. Sci Rep. 2016;6(1):1–11.\nPage 13 of 13\nXing et al. Plant Methods\
    \           (2023) 19:66 \n \n 7. \nLiu L, et al. Impact of initial planting density\
    \ on the optimal economic \nrotation of chinese fir (Cunninghamia lanceolata (Lamb.)\
    \ Hook) in an \nexperimental forest plantation. Forests. 2019;10(9):713.\n 8.\
    \ \nBian F, et al. Drought stress introduces growth, physiological traits and\
    \ \necological stoichiometry changes in two contrasting Cunninghamia \nlanceolata\
    \ cultivars planted in continuous-plantation soils. BMC Plant \nBiol. 2021;21(1):1–13.\n\
    \ 9. \nLi M et al. Mitigation effects of exogenous acetic acid on drought stress\
    \ in \nCunninghamia lanceolata. Plant and Soil. 2022; 1–16.\n 10. Dong TF, et\
    \ al. Growth, biomass allocation and photosynthetic responses \nare related to\
    \ intensity of root severance and soil moisture condi-\ntions in the plantation\
    \ tree Cunninghamia lanceolata. Tree Physiol. \n2016;36(7):807–17.\n 11. Kershaw\
    \ JA Jr, Larsen DR. A rapid technique for recording and measuring \nthe leaf area\
    \ of conifer needle samples. Tree Physiol. 1992;11(4):411–7.\n 12. Patrício DI,\
    \ Rieder R. Computer vision and artificial intelligence in preci-\nsion agriculture\
    \ for grain crops: a systematic review. Comput Electron \nAgric. 2018;153:69–81.\n\
    \ 13. Singh A, et al. Challenges and Opportunities in machine-augmented \nplant\
    \ stress phenotyping. Trends Plant Sci. 2021;26(1):53–69.\n 14. Jiang Y, Li C.\
    \ Convolutional neural networks for image-based high-\nthroughput Plant Phenotyping:\
    \ a review. Plant Phenom. 2020;4152816.\n 15. Lin K, et al. Deep learning-based\
    \ segmentation and quantification of \nCucumber Powdery Mildew using convolutional\
    \ neural network. Front \nPlant Sci. 2019;10:155.\n 16. Selvam L, Kavitha P. Classification\
    \ of ladies finger plant leaf using deep \nlearning. J Ambient Intell Humaniz\
    \ Comput, 2020; p. 1–9.\n 17. Gong B, et al. Real-time detection for wheat head\
    \ applying deep neural \nnetwork. Sens  2020;21(1):191.\n 18. Rong J, Chen Y,\
    \ Yang J. CNN-LSTM Hybrid model for kinematic feature \nanalysis and parabolic\
    \ radian prediction in basketball videos. Comput \nIntell Neurosci. 2021;2021:7844472.\n\
    \ 19. Quan R, et al. Holistic LSTM for Pedestrian Trajectory Prediction. IEEE\
    \ Trans \nImage Process. 2021;30:3229–39.\n 20. Guo H, Sung YJS. Movement estimation\
    \ using soft sensors based \non Bi-LSTM and two-layer LSTM for human motion capture.\
    \ Sens  \n2020;20(6):1801.\n 21. Taghavi Namin S, et al. Deep phenotyping: deep\
    \ learning for tem-\nporal phenotype/genotype classification. J Amb Intel Hum\
    \ Comp. \n2018;14(1):1–14.\n 22. Abdalla A, et al. Nutrient status diagnosis of\
    \ Infield Oilseed rape \nvia Deep Learning-Enabled dynamic model. IEEE Trans Industr\
    \ Inf. \n2021;17(6):4379–89.\n 23. Turkoglu M, Hanbay D, Sengur A. Multi-model\
    \ LSTM-based convolutional \nneural networks for detection of apple diseases and\
    \ pests. J Ambient \nIntell Humaniz Comput. 2019;13:3335–45.\n 24. Chang L, et\
    \ al. Using a hybrid neural network Model DCNN–LSTM for \nImage-Based Nitrogen\
    \ Nutrition diagnosis in Muskmelon. Horticulturae. \n2021;7(11):489.\n 25. Yang\
    \ L, et al. Real-time classification of invasive plant seeds based on \nimproved\
    \ YOLOv5 with attention mechanism. Diversity. 2022;14(4):254.\n 26. Zhang M, Su\
    \ H, Wen J. Classification of flower image based on atten-\ntion mechanism and\
    \ multi-loss attention network. Comput Commun. \n2021;179:307–17.\n 27. Jetley\
    \ S, et al. Learn to pay attention. arXiv:1804.02391. 2018.\n 28. Vaswani A, et\
    \ al. Attention is all you need. arXiv:1706:03762. 2017.\n 29. Zhang B, et al.\
    \ Neural machine translation with GRU-Gated attention \nmodel. IEEE Trans Neural\
    \ Netw Learn Syst. 2020;31(11):4688–98.\n 30. Zeng W, Li MJC, Agriculture Ei.\
    \ Crop leaf disease recognition based on \nself-attention convolutional neural\
    \ network. Comput Electron Agric. \n2020;172:105341.\n 31. Zheng CW, et al. Deep\
    \ learning for strawberry canopy delineation and \nbiomass prediction from high-resolution\
    \ images. Plant Phenomics. 2022. \nhttps:// doi. org/ 10. 34133/ 2022/ 98504 86.\n\
    \ 32. Shoaib M, et al. Deep learning-based segmentation and classification \n\
    of leaf images for detection of tomato plant disease. Front Plant Sci. \n2022;13:1031748.\n\
    \ 33. Minowa Y, Kubota Y. Identification of broad-leaf trees using deep \nlearning\
    \ based on field photographs of multiple leaves. J For Res. \n2022;27(4):246–54.\n\
    \ 34. Karen S, Andrew Z. Very deep convolutional networks for large-scale \nimage\
    \ recognition. Computer Science. 2014;1409:1556.\n 35. Krizhevsky A, Sutskever\
    \ I. E.J.C.o.t.A. Hinton, Imagenet classification with \ndeep convolutional neural\
    \ networks. Commun ACM. 2017;60(6):84–90.\n 36. He K et al. Deep residual learning\
    \ for image recognition 2016 ieee confer-\nence on computer vision and pattern\
    \ recognition (CVPR), 2015: 770–778.\n 37. Guillaumin M, Kuttel D, Ferrari V.\
    \ ImageNet Auto-Annotation with Seg-\nmentation Propagation. Int J Comput Vision.\
    \ 2014;110(3):328–48.\n 38. Hochreiter S, Schmidhuber J. Long short-term memory.\
    \ Neural Comput. \n1997;9(8):1735–80.\n 39. França C, et al. The jump shot performance\
    \ in youth basketball: a system-\natic review. Int J Environ Res Public Health.\
    \ 2021;18(6):3283.\n 40. Greff K, et al. LSTM: a search space odyssey. IEEE Trans\
    \ Neural Netw Learn \nSyst. 2017;28(10):2222–32.\n 41. Banik S, et al. LSTM based\
    \ decision support system for swing trading in \nstock market. Knowl Based Syst.\
    \ 2022;239:107994.\n 42. Kim J, El-Khamy M, Lee J. Residual LSTM: design of a\
    \ deep recurrent archi-\ntecture for distant speech recognition. arXiv.https://\
    \ doi. org/ 10. 48550/ \narXiv. 1701. 03360.\n 43. Wang CY, et al. Predicting\
    \ plant growth and development using time-\nseries images. Agronomy. 2022;12(9):2745–58.\n\
    \ 44. Verma T, Dubey S. Prediction of diseased rice plant using video process-\n\
    ing and LSTM-simple recurrent neural network with comparative study. \nMultimed\
    \ Tools Appl. 2021;80(19):29267–98.\n 45. Bao T, et al. A CNN-LSTM hybrid model\
    \ for wrist kinematics estimation \nusing surface electromyography. IEEE Trans\
    \ Industr Inf. 2020;70:1–9.\n 46. Ullah A, et al. Action Recognition in Video\
    \ sequences using deep bi-\ndirectional LSTM with CNN features. Ieee Access. 2018;6:1155–66.\n\
    \ 47. Kokkinos I. Ubernet: Training a universal convolutional neural network \n\
    for low-, mid-, and high-level vision using diverse datasets and limited \nmemory.\
    \ 30th IEEE/CVF Conference on Computer Vision and Pattern \nRecognition (CVPR),\
    \ 2017: 6129–6138.\n 48. Kendall A, Gal Y, Cipolla R. Multi-task learning using\
    \ uncertainty to weigh \nlosses for scene geometry and semantics. 2018 IEEE/CVF\
    \ Conference on \nComputer Vision and Pattern Recognition (CVPR), 2018: 7482–7491.\n\
    \ 49. Kendall A. and Y.J.A.i.n.i.p.s. gal, what uncertainties do we need in bayes-\n\
    ian deep learning for computer vision. NIPS. 2017; 30.\n 50. Singh AK, et al.\
    \ Deep learning for plant stress phenotyping: trends and \nfuture perspectives.\
    \ Trends Plant Sci. 2018;23(10):883–98.\n 51. Araus JL, et al. Crop phenotyping\
    \ in a context of global change: what to \nmeasure and how to do it. J Integr\
    \ Plant Biol. 2022;64(2):592–618.\n 52. Yang B, Xu YJHR. Applications of deep-learning\
    \ approaches in horticul-\ntural research: a review. Hortic Res. 2021;8(1):123.\n\
    \ 53. Fan X, et al. A segmentation-guided Deep Learning Framework for Leaf \n\
    counting. Front Plant Sci. 2022;13:844522.\n 54. Wang X, et al. Field rice panicle\
    \ detection and counting based on deep \nlearning. Front Plant Sci. 2022;13:966495.\n\
    \ 55. Yu M, et al. A recognition method of soybean Leaf Diseases based on an \n\
    Improved Deep Learning Model. Front Plant Sci. 2022;13:878834.\n 56. Zhou X, et\
    \ al. Deep learning-based postharvest strawberry bruise \ndetection under UV and\
    \ incandescent light. Comput Electron Agric. \n2022;202:107389.\n 57. Azimi S,\
    \ Wadhawan R, Gandhi TK. Intelligent monitoring of stress Induced \nby Water Deficiency\
    \ in plants using deep learning. Ieee Trans Instrum \nMeas Ieee T Instrum Meas.\
    \ 2021;70:1–13.\nPublisher’s Note\nSpringer Nature remains neutral with regard\
    \ to jurisdictional claims in pub-\nlished maps and institutional affiliations.\n"
  inline_citation: '>'
  journal: Plant methods
  limitations: '>'
  pdf_link: https://plantmethods.biomedcentral.com/counter/pdf/10.1186/s13007-023-01044-8
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: A CNN-LSTM-att hybrid model for classification and evaluation of growth status
    under drought and heat stress in chinese fir (Cunninghamia lanceolata)
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.11591/ijai.v11.i2.pp753-763
  analysis: '>'
  authors:
  - Kavita Jhajharia
  - Pratistha Mathur
  citation_count: 1
  full_citation: '>'
  full_text: ">\nIAES International Journal of Artificial Intelligence (IJ-AI) \n\
    Vol. 11, No. 2, June 2022, pp. 753~763 \nISSN: 2252-8938, DOI: 10.11591/ijai.v11.i2.pp753-763\
    \ \n     753 \n \nJournal homepage: http://ijai.iaescore.com \nA comprehensive\
    \ review on machine learning in agriculture \ndomain \n \n \nKavita Jhajharia,\
    \ Pratistha Mathur \nDepartment of Information Technology, Faculty of Engineering,\
    \ Manipal University Jaipur, Jaipur, India \n \n \nArticle Info \n \nABSTRACT\
    \ \nArticle history: \nReceived Sep 6, 2021 \nRevised Feb 14, 2022 \nAccepted\
    \ Mar 3, 2022 \n \n \nAgriculture is an essential part of sustaining human life.\
    \ Population growth, \nclimate change, resource competition are the key issues\
    \ that increase food \nsecurity and to handle such complex problems in agriculture\
    \ production, \nintelligent or smart farming extends the incorporation of technology\
    \ into \ntraditional agriculture notion. Machine learning is a vitally used technology\
    \ \nin agriculture to protect food security and sustainability. Crop yield \n\
    production, water preservation, soil health and plant diseases can be \naddressed\
    \ by machine learning. This paper has presented a compendious \nreview of research\
    \ papers that deployed machine learning in the agriculture \ndomain. The observed\
    \ sub-categories of the agriculture domain are crop \nyield prediction, soil management,\
    \ pest management, weed management, \nand crop disease. The outcomes represent\
    \ that machine learning provides \nbetter accuracy concerning classification or\
    \ regression. Machine learning \nemerged with the internet of things, drones,\
    \ robots, automated machinery, \nand satellite imagery motivates researchers for\
    \ smart farming and food \nsecurity. \nKeywords: \nAgriculture  \nArtificial neural\
    \ network  \nFood security \nMachine learning  \nSupport vector machine  \nThis\
    \ is an open access article under the CC BY-SA license. \n \nCorresponding Author:\
    \ \nKavita Jhajharia \nDepartment of Information Technology, Faculty of Engineering,\
    \ Manipal University Jaipur \nDehmi Kalan, Near GVK Toll Plaza, Jaipur-Ajmer Expressway,\
    \ Jaipur, Rajasthan 303007, India \nEmail: Kavita.chaudhary@outlook.com \n \n\
    \ \n1. \nINTRODUCTION \nAgriculture is a basic need for humankind to subsist.\
    \ Continuous increment in population strains to \nfeed the ever-growing population.\
    \ Resources and food production management is required to cater for the \naugmented\
    \ population. Agriculture production relies on many factors, such as soil type\
    \ and quality, irrigation \nmanagement, weather, and water. Agriculture is a basic\
    \ need for humankind to subsist. Continuous increment \nin population strains\
    \ to feed the ever-growing population. Resources and food production management\
    \ is \nrequired to cater for the augmented population. Farming has become more\
    \ intensified to maximize crop \nyields. To produce the sufficient amount of food,\
    \ smart agriculture is required. Satellite data makes \nagriculture more accurate\
    \ and predictive. Smart farming has evolved widely in the last few years to fulfil\
    \ the \nfood need. \nMachine learning (ML) in consort with data analysis generates\
    \ possibilities to understand and \nreconnoitre the field of agriculture more\
    \ effectually. According to Tom Michael, ML is a set of computer \ninstructions\
    \ that learns from previous experience, concerning the task, and on the basis\
    \ of previous \nexperience and task, performance is measured and which improves\
    \ with experience and task [1]. Samuel \ndefines ML as a scientific domain of\
    \ study which provides machines with the ability to learn without being \nspecifically\
    \ programmed [2]. With time, machine learning is being widely applied in many\
    \ fields, including \nbioinformatics [3], anatomy [4], cheminformatics [5], economics\
    \ [6], robot locomotion [7], speech \n      \n  \n \n       ISSN: 2252-8938 \n\
    Int J Artif Intell, Vol. 11, No. 2, June 2022: 753-763 \n754 \nrecognition [8],\
    \ information retrieval [9], and neuroscience [10]. In this research paper, machine\
    \ learning \nalgorithm in agriculture domain is deliberated [11]. \nThe organization\
    \ of the paper is: machine approach section has the description of machine learning\
    \ \nmethods, techniques, and algorithms, the literature review section contains\
    \ the review of the identified areas \nof agriculture that have used machine learning,\
    \ and discussion and conclusion section encloses the final \nfindings, conclusion\
    \ and discussion of the paper along with the advantages of application of machine\
    \ learning \nin agriculture domain. ML is a process where the system or machine\
    \ learns from experience and can improve \nperformance. Statistical and mathematical\
    \ models can measure improved performance. Set of examples can \nalso be dictated\
    \ as ML model or algorithms are trained using data sets. After the accomplishment\
    \ of training, \nthe trained model is used to identify, predict or classify new\
    \ input data. Figure 1 illustrates the ML approach. \nML algorithms explained\
    \ below are not limited to the methods applied in papers used for this review\
    \ process. \n \n \n \n \nFigure 1. Machine learning approach \n \n \n2. \nLITERATURE\
    \ REVIEW  \n2.1.  Research method \nA systematic review methodology has been followed\
    \ for the review conduction used in this research \npaper. The review process\
    \ includes review planning, search string, and search criteria for Machine learning\
    \ in \nagriculture. After completing the search, the paper selection is made based\
    \ on inclusion and exclusion \ncriteria. This section contains information about\
    \ how the review is accomplished. \n \n2.2.  Planning of review \nMachine learning\
    \ has evolved in agriculture rapidly in past years. However, despite numerous\
    \ \nresearch studies, the potential results for every field have not been identified\
    \ yet. This review aims to provide \nan outline of the machine learning technology\
    \ in the agriculture domain and in-depth investigation. The work \nanalyses various\
    \ sub-categories of the agriculture domain, techniques applied, observed features,\
    \ and dataset \nresources used in the research. \n \n2.3.  Search string \nTo\
    \ conduct the search string, some keywords are identified as agriculture machine\
    \ learning, ML \ntechniques agriculture, crop yield prediction machine learning,\
    \ pest machine learning, crop disease machine \nlearning, soil machine learning,\
    \ and weed machine learning, with the main emphasis on keywords machine \nlearning\
    \ and agriculture. The authors performed an in-depth search to ensure the comprehensiveness\
    \ of the \nstudy. A few known papers may not have been considered because of title\
    \ mismatch with the identified \nkeywords. Figure 2 represents the chosen search\
    \ strings. \nInt J Artif Intell  \nISSN: 2252-8938 \n \n \nA comprehensive review\
    \ machine learning in agriculture domain (Kavita Jhajharia) \n755 \n2.4.  Selection\
    \ criteria \nThe literature review follows pre-specified selection criteria for\
    \ including and excluding the papers \nin the study. The inclusion criteria include\
    \ the paper which matches the search string, and exclusion criteria \nexcluded\
    \ the papers by title and domain mismatch, abstract and text irrelevance. Figure\
    \ 3 illustrates the paper \ninclusion and exclusion. \n \n \n \n \nFigure 2. Search\
    \ string \n \n \n \n \nFigure 3. Inclusion and exclusion criteria \n \n \n2.5.\
    \  Review conduction \nMachine learning is a game-changing technology and widely\
    \ used in diversified fields. Machine \nlearning has been applied in the agricultural\
    \ domain throughout the crop cycle. It starts with soil management \nand ends\
    \ with taking decisions about the crop's ripeness by the robot. In this review,\
    \ articles have been \nclassified into the following categories: crop yield prediction,\
    \ soil management, pest management, weed \nmanagement, and crop disease. The papers\
    \ were searched using particular keywords for every selected \ndomain of agriculture.\
    \ Agriculture has many sub-areas, and all cannot be included in the review; considering\
    \ \nthis constraint, some areas are excluded. General abbreviations used in the\
    \ paper are compiled in Table 1. \n \n2.6.  Categorical literature review \n2.6.1.\
    \ Crop yield prediction \nIn agriculture, crop yield, also known as agriculture\
    \ output, is an essential component to complete \nthe growing population's need.\
    \ Agriculture crop yield or productivity depends on many factors, such as \nweather\
    \ conditions, soil conditions, water, temperature, and rainfall. Therefore, ML\
    \ can match the demand \nand supply of food without affecting the environment\
    \ or natural resources. \n \n2.6.2. Soil management \nMachine learning implementation\
    \ has been used to predict and identify based on soil characteristics \nsuch as\
    \ valuation of soil moisture, condition, and temperature. A better prediction\
    \ of soil condition can help \nto improve soil management. ML technologies can\
    \ achieve a more accurate estimation of soil with less time \nand cost. \n \n\
    \      \n  \n \n       ISSN: 2252-8938 \nInt J Artif Intell, Vol. 11, No. 2,\
    \ June 2022: 753-763 \n756 \nTable 1. General abbreviations \nAbbreviation \n\
    Definition \nAbbreviation \nDefinition \nAMSR-E \nAdvanced Microwave Scanning\
    \ Radiometer on the Earth \nObserving System \nMODIS \nModerate Resolution Imaging\
    \ \nSpectroradiometer \nANN \nArtificial Neural Network \nMPE \nMean percent error\
    \ \nAI \nArtificial Intelligence \nNB \nNaïve Bayes \nCNN \nConvolutional Neural\
    \ Network \nNDVI \nNormalized difference vegetation index \nCP-ANN \nCounter Propagation\
    \ Artificial Neural Network \nNN \nNeural Network \nDL \nDeep Learning \nPCA \n\
    Principal Component Analysis \nDT \nDecision Tree \nPLSDA \nPartial Least Squares\
    \ Discriminant \nAnalysis \nEL \nEnsemble Learning \nPMNN \nPerceptron Multilayer\
    \ neural network \nELM \nExtreme Learning Machine \nRBF-NN \nRadial Basis Function\
    \ Neural Network \nEM \nExpectation Maximisation \nRE \nRelative Error \nERT \n\
    Extremely randomized tree \nRF \nRandom Forest \nLR \nLogistic Regression \nRMSE\
    \ \nRoot mean square error \nLS-SVM \nLeast Squares Support Vector Machines \n\
    SOM \nSelf-Organizing Map \nLSTM \nLong short-term memory \nSVM \nSupport Vector\
    \ Machine \nML \nMachine Learning \nSVR \nSupport Vector Regression \nMLR \nMultiple\
    \ Linear Regression \n \n \n \n \n2.6.3. Pest management \nPest damages the crops\
    \ and reduces production, which can rigorously affect the food supply and \ndemand\
    \ chain. Reduction of the crop damage and increment of the crop production compels\
    \ the farmers to \nuse chemicals to control and protect the field from pests.\
    \ Even though utilization of chemicals is harmful to \nthe environment, animals\
    \ and human's health, ML algorithms can provide an efficient solution for pest\
    \ \nmanagement. \n \n2.6.4. Weed management \nWeed in farming is the most undesirable\
    \ plant that rivals the yield. It makes harvesting difficult and \nincludes impurity\
    \ and moisture to crop. The negative eﬀects of weeds on yields incorporate challenge\
    \ to \nsunlight, water, space, complex harvesting, and devaluation of crop quality.\
    \ ML can detect weed on the crop. \nMany articles have been presented here to\
    \ detect and discriminate weed from the crop. \n \n2.6.5. Crop disease \nThe rapidly\
    \ increasing world population puts much pressure on agriculture resources. Crop\
    \ \nProduction is the essential component to maintain the population need as well\
    \ as the economic system. Crop \ndiseases are the primary source of plant damage,\
    \ which affects crop production. Due to distressed climate and \nenvironmental\
    \ situations, a manifestation of plant illnesses is at the upward thrust. There\
    \ are numerous crop \ndiseases and various symptoms containing spots/smudge appearing\
    \ on plant leaves [12]. ML techniques \naccommodated to detect the disease in\
    \ the plant at an early stage. The Table 2 shown in appendix represents \nthe\
    \ comparison of above-mentioned categories.  \n \n \n3. \nDISCUSSION \nThe review's\
    \ primary focus is to brief the significant benefits of ML in the agriculture\
    \ domain and \npossible research areas. The review analyses the existing machine\
    \ learning tools and techniques deployed in \nthe agriculture domain, including\
    \ crop prediction, soil management, pest management, weed management \nand crop\
    \ disease. Many international journals cover the advances in the development and\
    \ applications of \nhardware, software, and related technologies for solving issues\
    \ in the agriculture domain. The total number of \nresearch articles reviewed\
    \ is 38. The review includes 3 conference and 35 journal articles, as shown in\
    \  \nFigure 4. The presented articles here are from 2005 to till present, shown\
    \ in Figure 5. The year-wise \ndistribution of reviewed papers is demonstrated\
    \ in Figure 5. The result clearly shows that there is significant \nwork done\
    \ in the last 3 to 4 years in agriculture using machine learning. \nAnalysis of\
    \ the articles indicates that mainly nine ML algorithms are examined/adopted in\
    \ the \nsurvey, shown in Figure 6. In crop prediction, Nine ML algorithms are\
    \ deployed; further analysis of the \nsurveyed articles indicates that ANN is\
    \ the most popular algorithm applied in the field of crop prediction. In \nsoil\
    \ management, five ML algorithms are deployed where SVM and regression are mainly\
    \ used. In the pest \nmanagement category, five ML algorithms are deployed where\
    \ SVM is majorly used. In Weed management, \nfive ML algorithms are implemented\
    \ and, SVM is most often used. In last, crop disease, four ML algorithms \nare\
    \ implemented and, SVM is majorly used. Thus, the majority of work is done using\
    \ ANN and SVM can be \nconcluded from the reviewed literature. \nInt J Artif Intell\
    \  \nISSN: 2252-8938 \n \n \nA comprehensive review machine learning in agriculture\
    \ domain (Kavita Jhajharia) \n757 \n \nFigure 4. Categorization of papers \n \n\
    \ \n \n \nFigure 5. Number of papers published per years \n \n \n \n \nFigure\
    \ 6. Utilization of ML algorithms in different categories \n \n \nThe analysis\
    \ of figures indicates that SVM is majorly implemented because of its sequential\
    \ \napproach, which incorporates several features to make a decision/ features\
    \ into classes. SVM uses a kernel \nfunction to differentiate the nonlinear and\
    \ separable data and generates a mapping relationship between the \ninput vector\
    \ and high-dimensional space vector through a hyperplane. SVM is preferred because\
    \ of its sparse \nrepresentation and absence of local minima. Machine learning\
    \ has a significant impact on application areas of \n92%\n8%\nJournal Papers\n\
    Conference Papers\n1\n1\n1\n1\n1\n4\n1\n5\n1\n8\n6\n3\n5\n0\n2\n4\n6\n8\n10\n\
    2005 2006 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019\nNumber of Papers\n\
    Publication year\n0\n1\n2\n3\n4\n5\n6\nCrop Prediction\nSoil\nManagement\nPest\n\
    Management\nWeed\nManagement\nCrop Disease\nNumber of Papers\nAgriculture Categories\
    \ \nRegression\nDecision Tree\nClustering\nBayesian Algorithm\nANN\nDL\nEnsemble\
    \ Algorithm\nSVM\nInstance Based Algorithm\n      \n  \n \n       ISSN: 2252-8938\
    \ \nInt J Artif Intell, Vol. 11, No. 2, June 2022: 753-763 \n758 \nthe agriculture\
    \ domain. Results produced by ML are promising. Particularly DL is getting more\
    \ acceptance \nbecause of its automatic feature extraction method in the agriculture\
    \ sector, which can ease the process and \nsupport the stakeholders of the agriculture\
    \ domain. DL architectures/algorithms are also vastly implemented \nin crop disease,\
    \ weed management and crop prediction domains. \n \n \n4. \nCONCLUSION \nML-based\
    \ techniques have attracted much attention from researchers to improve the productivity\
    \ in \nagriculture domain. This review summarises the implementation of the ML\
    \ algorithm in the agriculture \ndomain in the past few years. Though many algorithms\
    \ are deployed, SVM and neural networks are the key \ntechniques to be better\
    \ and precise. However, the researcher can explore new techniques, new domain,\
    \ and \nthe inclusion of raw data to get more accurate results in the future.\
    \ Deep learning is getting attention in the \npast 3-4 years. The review covers\
    \ five major domains; however, further study is required to explore the other\
    \ \nresearch areas of agriculture: rain management, weather Management, climate\
    \ management, livestock \nproduction, and animal welfare. \n \n \nAPPENDIX \n\
    \ \n \nTable 2. Comparison among multiple agriculture domains (continue) \nReference\
    \ \nNo. \nAgriculture \nDomain \nObserved \nFeatures \nFunctionality \nApplied\
    \ \nAlgorithms \nData Sources \nResults \n[13] \nCrop \nprediction \nSeven-band\
    \ \nreflectance \nimagery \nRemote sensing \ndata used to train \nthe model to\
    \ \npredict the crop \nyield of one \nregion. Then, \nanother region \nprediction\
    \ was \nperformed using \ntransfer learning \nLSTM, \nregression \nModerate resolution\
    \ \nimaging spectroradiometer \nsatellite imagery \nTrained and tested \nthe model\
    \ on \nsoybean data of \nArgentina and \npredicts fine for \nbrazil. \nPre-trained\
    \ model \n[14] \nCrop \nprediction \nSoil \nmoisture \nEstimates crop \nyield\
    \ and present \ncomparison among \nmany machine \nlearning \ntechniques \nSVM,\
    \ ERT, \nRF, DL \nNational Agricultural \nStatistical Service and \nUnited States\
    \ of \nDepartment of Agriculture, \nNational Aeronautics and \nSpace Administration,\
    \ \nEuropean Space Agency, \nClimate Change Initiative \nand PRISM Climate Group\
    \ \nDL produced the \nhighest accuracy \namong all \n[15] \nCrop \nprediction\
    \ \nMultiple \nfeatures \ncolor, shape, \ntexture and \nsize \nDetects each \n\
    integral tomato \nfruit which \nincorporates \nmature, immature, \nand young fruits\
    \ \non a tomato plant \nX-Means, \nDT \n154 images were collected \nby conventional\
    \ RGB \ndigital camera at Tsukuba \nPlant Factory of the \nInstitute of Vegetable\
    \ and \nTea Science, Ibaraki, Japan \nRecall value: 0.80 \nPrecision: 0.88 \n\
    Recall of young \nfruit: 0.78 \n[16] \nCrop \nprediction \nMultilayer \nsoil \n\
    parameters \nPredicts wheat \nyield for three \nisofrequency \nclasses, namely\
    \ \nhigh, medium and \nlow \nCP-ANN, \nXY-Fusion, \nSupervised \nKohonen \nNetwork\
    \ \nDuck End Farm Field, \nWilstead, Bedfordshire, U. \nK. \nAccuracy: \nSupervised\
    \ kohonen \nnetwork: 81.65% \nCP-ANN: 78.3% \nXY-Fusion: 80.92% \n[17] \nCrop\
    \ \nprediction \nGeometrical \nfeatures \nDetects tomatoes \nfrom RGB images \n\
    K-Means, \nSOM, EM \nRGB images of Spatial \nresolution acquired from \nunmanned\
    \ aerial vehicles \nK-means \nPrecision: 0.723 \nRecall: 0.593 \nF-Measure: 0.652\
    \ \nSOM \nPrecision: 0.730 \nRecall: 0.686 \nF-Measure: 0.707 \nEM \nPrecision:\
    \ 0.919 \nRecall: 0.606 \nF-Measure: 0.730 \n \nInt J Artif Intell  \nISSN: 2252-8938\
    \ \n \n \nA comprehensive review machine learning in agriculture domain (Kavita\
    \ Jhajharia) \n759 \nTable 2. Comparison among multiple agriculture domains (continue)\
    \ \nReference \nNo. \nAgriculture \nDomain \nObserved \nFeatures \nFunctionality\
    \ \nApplied \nAlgorithms \nData Sources \nResults \n[18] \nCrop \nprediction \n\
    Soil \nproperties \nSBOCM used to \npredict different \nstages and yield of \n\
    rice \nSVM \nChinese \nAcademy of \nSciences \nMiddle-season rice \nTillering\
    \ stage: \nRE(%)=22.1 \nHeading stage: \nRE(%)=17.1 \nMilk stage: \nRE(%)=19.2\
    \ \n \nEarly rice Tillering stage: \nRE(%)=20.5 Heading stage: \nRE(%)=15.8 \n\
    Milk stage: \nRE(%)=8.5 \n \nLate rice: Tillering stage: \nRE(%)=21.0 \nHeading\
    \ stage: \nRE(%)=16.5 \nMilk stage: \nRE(%)=11.1 \n[19] \nCrop \nprediction \n\
    Irrigation \nwater, \nrainfall, \ntemperature \nCrop yield \nprediction \nperformed\
    \ for two \nconsecutive years \nMLR, M5- \nPrime \nRegression \nTrees, \nPMNN,\
    \ \nSVR, K-NN \nIrrigation \nmodule of \nSanta Rosa \n[Agricultural \nProduction\
    \ \nData and \nWeather \ninformation \nData] \nM5-Prime predicted with the \n\
    best accuracy, followed by \nKNN, SVR and MLR. \n[20] \nCrop \nprediction \nVegetation\
    \ \nindices \nDetermines the \npotential of \nhyperspectral data \nand ANNs \n\
    ANN \nEmile A. Lods \nAgronomy \nResearch \nCentre data \nobtained by \nCompact\
    \ \nAirborne \nSpectrographic \nImage \nRMSE (kg/ha)= 19.7 \n[21] \nSoil \nmanagement\
    \ \nN/A \nPredict soil texture \nand stoniness \nbased on γ-\nspectroscopy \n\
    SVM, ANN \nTuscany, \nCentral Italy \nRMSE: \nSVM \nSand: 7.0 \nClay: 5.9 \nStoniness:0.10\
    \ \nANN \nSand:7.9 \nClay:6.3 \nStoniness:0.11 \n[22] \nSoil \nmanagement \nN/A\
    \ \nCrop yield \nprediction based \non soil salinity \nStepwise \nlinear \nregression\
    \ \nLower seyhan \nplane, berdan, \nseyhan, and \nceyhan rivers \nMPE: \nWheat:\
    \ 7.9% \nCorn: 8.8% \nCotton:6.3% \nCrop Yield loss: \nCorn: 55% \nwheat: 28%\
    \ \nCotton: 15% \n[23] \nSoil \nmanagement \nN/A \nAMSR-E data is \nconsistently\
    \ used \nto observe patterns \nof Global soil \nmoisture \nRF \nGlobal change\
    \ \nmaster \ndirectory and \nrural \ndevelopment \nadministration \nCoefficient\
    \ correlation (r) \nSouth korea:0.71 \nAustralis: 0.84 \nRMSE: \nSouth Korea:0.049\
    \ \nAustralia: 0.05 \n[24] \nSoil \nmanagement \nN/A \nUses near-infrared \nand\
    \ visible bands \nto predict soil \nnitrogen, organic \ncarbon, and \nmoisture\
    \ \nLS-SVM, \nCubist \nTop soil layer \nfrom Premslin, \nGermany. \nRMSE of prediction\
    \ \nLS-SVM: \nMoisture content: 0.457% \nOrganic carbon: 0.062% \n[25] \nSoil\
    \ \nmanagement \nN/A \nPredicts soil \nliquefaction \nsusceptibility \nSVM \n\
    Chi-Chi, \nTaiwan \nearthquake. \nPerformance: 77.65% \n \n      \n  \n \n  \
    \     ISSN: 2252-8938 \nInt J Artif Intell, Vol. 11, No. 2, June 2022: 753-763\
    \ \n760 \nTable 2. Comparison among multiple agriculture domains (continue) \n\
    Reference \nNo. \nAgriculture \nDomain \nObserved \nFeatures \nFunctionality \n\
    Applied \nAlgorithms \nData Sources \nResults \n[26] \nSoil \nmanagement \nN/A\
    \ \nImplemented digital \nsoil mapping \ntechniques to estimate \nthe spatial\
    \ distribution \nof numerous soil \nproperties \nCubist, RF \nBorujen region,\
    \ \nChaharmahal-Va-\nBakhtiari Province, \ncentral Iran \nsoil organic carbon:\
    \ \nRMSE: 0.33(RF) \ncalcium carbonate \nequivalent \nRMSE: 9.52(Cubist) \nClay:\
    \ \nRMSE: 7.86(RF) \n[27] \nSoil \nmanagement \nN/A \nDefines and assesses \n\
    the efficiency of \ntransfer learning to \nlocalize \nCNN \nLUCAS Soil \ndatabase\
    \ \nRMSE \nOrganic carbon: 10.5% \nCation exchange \ncapacity: 11.8% \nClay content:\
    \ 12.0% \npH: 11.5% \n[28] \nPest \nmanagement \nColor, \nShape, \nTexture \n\
    Automated rice pest \nidentification system \nSVM \nLive images with \ncameras\
    \ \nAccuracy 97.5% \n[29] \nPest \nmanagement \nArea, \nPerimeter, \nsphericity,\
    \ \nEccentricity \nDetect individual pest \namong other species \nANN \nSugar\
    \ beet field in \nShiraz, Iran \nR=0.89 \n[30] \nPest \nmanagement \nCurve \n\
    response \nand slope \nDiagnosis of plant pest \nusing Electronic nose. \nSVM\
    \ \nLancaster \nUniversity, UK \nTomato (mildew) \nLinear: 95% \nPolynomial: 94%\
    \ \nRBF: 96% \nCucumber (wounded) \nLinear: 77% \nPolynomial: 82% \nRBF: 87% \n\
    Cucumber (spider mite) \nLinear: 94% \nPolynomial: 88% \nRBF: 91% \nPepper (wounded)\
    \ \nLinear: 67% \nPolynomial:71% \nRBF: 92% \n[31] \nPest \nmanagement \n58 attributes\
    \ \nDevelop a method to \nforecast the result of \npest monitoring. \nAdaBoost,\
    \ \nNB \nZespri International \nLtd \nPrecision: \nAdaBoost: 98% \nNaïve Bayes:\
    \ 95% \n[32] \nPest \nmanagement \nN/A \nDetects and classifies \nmulti-class\
    \ pests. \nDL \n88,670 images \nMean average Precision: \n75.46% \n[33] \nPest\
    \ \nmanagement \ncolor \nindexes \nwere: Hue, \nSaturation \nand \nIntensify \n\
    Automatically detects \nthrips and their \nposition. \nSVM \nTarbiat Modares \n\
    University, \nIslamic Republic of \nIran, Tehran \nMPE of less than 2.25% \n[34]\
    \ \nWeed \nmanagement \nColor, \nshape, \ntexture and \nimage \norientation \n\
    Pynovisao software \ndeveloped and used to \ndetect weed in crop \nimage and classified\
    \ \nusing CNN. \nCNN \nImages captured by \nunmanned aerial \nvehicle. \nCNN:\
    \ \nPrecision 0.991 \nSensitivity 0.991 \n[35] \nWeed \nmanagement \nNitrogen\
    \ \napplication \nrate: 60,120 \nand 250 kg \nN/ha \nWeed classification \nperformed\
    \ w.r.t. \nnitrogen application \nrate \nSVM \n72-waveband \ncompact airborne\
    \ \nspectrographic \nimager (CASI), \nrange: 408.73 to \n947.07 nm \nEffect of\
    \ nitrogen and \nweed combined: 69.2% \nEffect of nitrogen:80.8 \nEffect of weed:\
    \ 85.8 \n[36] \nWeed \nmanagement \nColor and \ntexture \nWeed discrimination\
    \ \nfor different growing \nstates of rice \nDT \nRice and weed \nimages from\
    \ the \ninternet of \n1125*1500 \nPrecision: 0.982 \nRecall: 0.977 \n[37] \nWeed\
    \ \nmanagement \nSpectral \nRecognizes weed \nspecies based on \nhyperspectral\
    \ sensing. \nSOM, \nMixture of \nGaussian \nHyperspectral \nimages using HSI.\
    \ \nMixture of Gaussian- \n31%-98% \nSOM- 53%-94% \n[38] \nWeed \nmanagemen \n\
    Color, \nmoment \ninvariant, \nsize \nWeed and crop were \nclassified using digital\
    \ \nimages. \nSVM \nOLYMPUS FE4000 \npoint-and-shoot \ndigital camera \nAccuracy-\
    \ 97% \n \nInt J Artif Intell  \nISSN: 2252-8938 \n \n \nA comprehensive review\
    \ machine learning in agriculture domain (Kavita Jhajharia) \n761 \nTable 2. Comparison\
    \ among multiple agriculture domains \nReference \nNo. \nAgriculture \nDomain\
    \ \nObserved \nFeatures \nFunctionality \nApplied \nAlgorithms \nData Sources\
    \ \nResults \n[39] \nWeed \nmanagement \nShape, Fourier \ndescriptor, \nmoment\
    \ \ninvariant \nWeed detection \nusing shape features \nSVM, ANN \n960×1280 pixels,\
    \ \nShiraz university. \nAccuracy: \nANN: 92.92% \nSVM: 95.00% \n[40] \nWeed \n\
    management \nRGB-NIR \nimagery \nDetect sugar beet \nplant and weed-\nbased on\
    \ vision \nclassification \nCNN \nUAVs equipped \nwith vision \nsensors \nAccuracy\
    \ 95% \n[41] \nWeed \nmanagement \nSize, length, and \nfourier \nClassification\
    \ for \nsmall-grain weed \nspecies concerning \ncirsium arvense and \ngalium aparine\
    \ \nSVM \nRed (580 nm) and \ninfrared (>720 \nnm) spectrum \nOverall accuracy:\
    \ 97.7% \n[42] \nCrop disease \nHyperspectral \nimaging with 2.8 \nmm spectral\
    \ \nresolution, pixel \nsize is 6.45×6.45 \nµm \nDetecting sclerotinia \nsclerotiorum\
    \ on \noilseed rape stems \nPLSDA, \nRBF-NN, \nSVM, and \nELM \nfarm of Zhejiang\
    \ \nUniversity \nSample set 1: \nAverage spectra: \nPLSDA: 100 \nRBFNN: 97.50\
    \ \nELM: 100 \nSVM: 92.50 \nPixel-wise Spectra: \nPLSDA: 94.80 \nRBFNN: 98.80\
    \ \nELM: 99.40 \nSVM: 99.00 \n \nSample set 2: \nAverage spectra: \nPLSDA: 92.50\
    \ \nRBFNN: 87.50 \nELM: 97.50 \nSVM: 90.00 \nPixel-wise Spectra: \nPLSDA: 96.60\
    \ \nRBFNN: 98.70 \nELM: 99.50 \nSVM: 99.30 \n[43] \nCrop disease \nLeaf, stem,\
    \ and \nfruits \nDetect real-time \ndisease along with \nthe class and \nlocation\
    \ of the plant \nDL \nImages using a \ndigital camera \nfrom farms of the \nKorean\
    \ peninsula \nMean average precision \n83.06% \n[44] \nCrop disease \nSpectral\
    \ \nvegetation \nindices \nDetects and \nclassifies plant \ndiseases in sugar\
    \ \nbeet \nSVM \nCercospora leaf \nspot, leaf rust and \npowdery mildew \nCercospora\
    \ Leaf spot: \n89.69 \nSugar beet rust: 83.60 \nPowdery mildew: 92.46 \n[45] \n\
    Crop disease \nColoured, \ngreyscale and \nsegmented \nDetects plant disease \n\
    using images \nCNN \nPlantVillage \nPublic dataset \nOverall accuracy- \n99.35%\
    \ \n[46] \nCrop disease \n75 features by \nwavelet \ndecomposition \nHealthy and\
    \ \nfusarium diseased \npepper leaves were \ndetected \nKNN \nGAP Agricultural\
    \ \nresearch \n(GAPTEAM), \nşanlıurfa, Turkey \nKNN: \nStatistics of wavelet \n\
    coefficient: 99% \nWavelet Coefficient: \n100% \n[47] \nCrop disease \nGrayscale\
    \ \nDetect and classify \npotato disease by \nvisible symptoms \nCNN \nImages\
    \ captured \nby cameras \nDataset split: \n90%-train and 10%-test \nprovides accuracy\
    \ -\n0.9585 \n[48] \nCrop disease \nShape, texture, \nand grey level \nIdentification\
    \ of \nplant disease by \nvisual symptoms \nSVM \nThe University of \nGeorgia,\
    \ USA \nAccuracy 93.1% \n[49] \nCrop disease \nLeaf properties \nClassifies the\
    \ \ndisease based on \nsymptoms visible \nCNN \nPlant village \nAccuracy 99.18%\
    \ \n[50] \nCrop disease \nColor, texture, \ngray level co-\noccurrence \nmatrix,\
    \ and \nwavelet \ntransform \nDetects disease in \napple fruit \nANN, \nSVR-rbf,\
    \ \nand SVR-\nPoly \nANN, SVR-RBF, \nand SVR-Poly \nRMSE: \nANN: 0.53 \nSVR-Poly:\
    \ 0.42 \nSVR-RBF: 0.2 \n \n \n      \n  \n \n       ISSN: 2252-8938 \nInt J Artif\
    \ Intell, Vol. 11, No. 2, June 2022: 753-763 \n762 \nREFERENCES \n[1] \nT. M.\
    \ Mitchell, Machine Learning. New York: McGraw-Hill, 1997. \n[2] \nA. L. Samuel,\
    \ “Some studies in machine learning using the game of checkers. I,” in Computer\
    \ Games I, vol. 3, no. 3, C. G. I and \nD. N. L. Levy, Eds. New York, NY: Springer\
    \ New York, 1988, pp. 335–365. \n[3] \nI. Inza, B. Calvo, R. Armañanzas, E. Bengoetxea,\
    \ P. Larrañaga, and J. A. Lozano, “Machine learning: an indispensable tool in\
    \ \nbioinformatics,” Methods in Molecular Biologyiology, vol. 593, pp. 25–48,\
    \ 2010, doi: 10.1007/978-1-60327-194-3_2. \n[4] \nX. Zhu, Y. Ge, T. Li, D. Thongphiew,\
    \ F.-F. Yin, and Q. J. Wu, “A planning quality evaluation tool for prostate adaptive\
    \ IMRT \nbased on machine learning,” Medical Physics, vol. 38, no. 2, pp. 719–726,\
    \ Jan. 2011, doi: 10.1118/1.3539749. \n[5] \nY.-C. Lo, S. E. Rensi, W. Torng,\
    \ and R. B. Altman, “Machine learning in chemoinformatics and drug discovery,”\
    \ Drug Discovery \nToday, vol. 23, no. 8, pp. 1538–1546, Aug. 2018, doi: 10.1016/j.drudis.2018.05.010.\
    \ \n[6] \nH. Park, N. Kim, and J. Lee, “Parametric models and non-parametric machine\
    \ learning models for predicting option prices: \nempirical comparison study over\
    \ KOSPI 200 Index options,” Expert Systems with Applications, vol. 41, no. 11,\
    \ pp. 5227–5237, \nSep. 2014, doi: 10.1016/j.eswa.2014.01.032. \n[7] \nN. Kohl\
    \ and P. Stone, “Policy gradient reinforcement learning for fast quadrupedal locomotion,”\
    \ in IEEE International \nConference on Robotics and Automation, 2004., 2004,\
    \ no. 3, pp. 2619–2624, doi: 10.1109/ROBOT.2004.1307456. \n[8] \nX. Xu, J. Deng,\
    \ E. Coutinho, C. Wu, L. Zhao, and B. W. Schuller, “Connecting subspace learning\
    \ and extreme learning machine \nin speech emotion recognition,” IEEE Transactions\
    \ on Multimedia, vol. 21, no. 3, pp. 795–808, Mar. 2019, doi: \n10.1109/TMM.2018.2865834.\
    \ \n[9] \nF. Sebastiani, “Machine learning in automated text categorization,”\
    \ ACM Computing Surveys, vol. 34, no. 1, pp. 1–47, Mar. 2002, \ndoi: 10.1145/505282.505283.\
    \ \n[10] J. Richiardi, S. Achard, H. Bunke, and D. Van De Ville, “Machine learning\
    \ with brain graphs: predictive modeling approaches for \nfunctional imaging in\
    \ systems neuroscience,” IEEE Signal Processing Magazine, vol. 30, no. 3, pp.\
    \ 58–70, May 2013, doi: \n10.1109/MSP.2012.2233865. \n[11] K. Liakos, P. Busato,\
    \ D. Moshou, S. Pearson, and D. Bochtis, “Machine learning in agriculture: a review,”\
    \ Sensors, vol. 18, no. 8, \nAug. 2018, doi: 10.3390/s18082674. \n[12] P. Chandana\
    \ et al., “An effective identification of crop diseases using faster region based\
    \ convolutional neural network and expert \nsystems,” International Journal of\
    \ Electrical and Computer Engineering (IJECE), vol. 10, no. 6, pp. 6531–6540,\
    \ Dec. 2020, doi: \n10.11591/ijece.v10i6.pp6531-6540. \n[13] A. X. Wang, C. Tran,\
    \ N. Desai, D. Lobell, and S. Ermon, “Deep transfer learning for crop yield prediction\
    \ with remote sensing \ndata,” in Proceedings of the 1st ACM SIGCAS Conference\
    \ on Computing and Sustainable Societies, Jun. 2018, pp. 1–5, doi: \n10.1145/3209811.3212707.\
    \ \n[14] N. Kim and Y.-W. Lee, “Machine learning approaches to corn yield estimation\
    \ using satellite images and climate data: a case of \niowa state,” Journal of\
    \ the Korean Society of Surveying, Geodesy, Photogrammetry and Cartography, vol.\
    \ 34, no. 4, pp. 383–390, \nAug. 2016, doi: 10.7848/ksgpc.2016.34.4.383. \n[15]\
    \ K. Yamamoto, W. Guo, Y. Yoshioka, and S. Ninomiya, “On plant detection of intact\
    \ tomato fruits using image analysis and \nmachine learning methods,” Sensors,\
    \ vol. 14, no. 7, pp. 12191–12206, Jul. 2014, doi: 10.3390/s140712191. \n[16]\
    \ X. E. Pantazi, D. Moshou, T. Alexandridis, R. L. Whetton, and A. M. Mouazen,\
    \ “Wheat yield prediction using machine learning \nand advanced sensing techniques,”\
    \ Computers and Electronics in Agriculture, vol. 121, pp. 57–65, Feb. 2016, doi:\
    \ \n10.1016/j.compag.2015.11.018. \n[17] J. Senthilnath, A. Dokania, M. Kandukuri,\
    \ R. K.N., G. Anand, and S. N. Omkar, “Detection of tomatoes using spectral-spatial\
    \ \nmethods in remotely sensed RGB images captured by UAV,” Biosystems Engineering,\
    \ vol. 146, pp. 16–32, Jun. 2016, doi: \n10.1016/j.biosystemseng.2015.12.003.\
    \ \n[18] Y. Su, H. Xu, and L. Yan, “Support vector machine-based open crop model\
    \ (SBOCM): case of rice production in China,” Saudi \nJournal of Biological Sciences,\
    \ vol. 24, no. 3, pp. 537–547, Mar. 2017, doi: 10.1016/j.sjbs.2017.01.024. \n\
    [19] A. Gonzalez-Sanchez, J. Frausto-Solis, and W. Ojeda-Bustamante, “Predictive\
    \ ability of machine learning methods for massive \ncrop yield prediction,” Spanish\
    \ Journal of Agricultural Research, vol. 12, no. 2, pp. 313–328, Apr. 2014, doi:\
    \ \n10.5424/sjar/2014122-4439. \n[20] Y. Uno et al., “Artificial neural networks\
    \ to predict corn yield from compact airborne spectrographic imager data,” Computers\
    \ \nand Electronics in Agriculture, vol. 47, no. 2, pp. 149–161, May 2005, doi:\
    \ 10.1016/j.compag.2004.11.014. \n[21] S. Priori, N. Bianconi, and E. A. C. Costantini,\
    \ “Can γ-radiometrics predict soil textural data and stoniness in different parent\
    \ \nmaterials? a comparison of two machine-learning methods,” Geoderma, vol. 226–227,\
    \ no. 1, pp. 354–364, Aug. 2014, doi: \n10.1016/j.geoderma.2014.03.012. \n[22]\
    \ O. Satir and S. Berberoglu, “Crop yield prediction under soil salinity using\
    \ satellite derived vegetation indices,” Field Crops \nResearch, vol. 192, pp.\
    \ 134–143, Jun. 2016, doi: 10.1016/j.fcr.2016.04.028. \n[23] J. Im, S. Park, J.\
    \ Rhee, J. Baik, and M. Choi, “Downscaling of AMSR-E soil moisture with MODIS\
    \ products using machine \nlearning approaches,” Environmental Earth Sciences,\
    \ vol. 75, no. 15, Aug. 2016, doi: 10.1007/s12665-016-5917-6. \n[24] A. Morellos\
    \ et al., “Machine learning based prediction of soil total nitrogen, organic carbon\
    \ and moisture content by using VIS-\nNIR spectroscopy,” Biosystems Engineering,\
    \ vol. 152, pp. 104–116, Dec. 2016, doi: 10.1016/j.biosystemseng.2016.04.018.\
    \ \n[25] P. Samui and T. G. Sitharam, “Machine learning modelling for predicting\
    \ soil liquefaction susceptibility,” Natural Hazards and \nEarth System Sciences,\
    \ vol. 11, no. 1, pp. 1–9, Jan. 2011, doi: 10.5194/nhess-11-1-2011. \n[26] M.\
    \ Zeraatpisheh, S. Ayoubi, A. Jafari, S. Tajik, and P. Finke, “Digital mapping\
    \ of soil properties using multiple machine learning \nin a semi-arid region,\
    \ central Iran,” Geoderma, vol. 338, pp. 445–452, Mar. 2019, doi: 10.1016/j.geoderma.2018.09.006.\
    \ \n[27] J. Padarian, B. Minasny, and A. B. McBratney, “Transfer learning to localise\
    \ a continental soil vis-NIR calibration model,” \nGeoderma, vol. 340, pp. 279–288,\
    \ Apr. 2019, doi: 10.1016/j.geoderma.2019.01.009. \n[28] Q. Yao et al., “An insect\
    \ imaging system to automate rice light-trap pest identification,” Journal of\
    \ Integrative Agriculture, vol. \n11, no. 6, pp. 978–985, Jun. 2012, doi: 10.1016/S2095-3119(12)60089-6.\
    \ \n[29] K. A. Vakilian and J. Massah, “Performance evaluation of a machine vision\
    \ system for insect pests identification of field crops \nusing artificial neural\
    \ networks,” Archives Of Phytopathology And Plant Protection, vol. 46, no. 11,\
    \ pp. 1262–1269, Jul. 2013, \ndoi: 10.1080/03235408.2013.763620. \n[30] R. Ghaffari\
    \ et al., “Plant pest and disease diagnosis using electronic nose and support\
    \ vector machine approach,” Journal of Plant \nDiseases and Protection, vol. 119,\
    \ no. 5–6, pp. 200–207, 2012, doi: 10.1007/BF03356442. \n[31] M. G. Hill, P. G.\
    \ Connolly, P. Reutemann, and D. Fletcher, “The use of data mining to assist crop\
    \ protection decisions on \nkiwifruit in New Zealand,” Computers and Electronics\
    \ in Agriculture, vol. 108, pp. 250–257, Oct. 2014, doi: \nInt J Artif Intell\
    \  \nISSN: 2252-8938 \n \n \nA comprehensive review machine learning in agriculture\
    \ domain (Kavita Jhajharia) \n763 \n10.1016/j.compag.2014.08.011. \n[32] L. Liu\
    \ et al., “PestNet: an end-to-end deep learning approach for large-scale multi-class\
    \ pest detection and classification,” IEEE \nAccess, vol. 7, pp. 45301–45312,\
    \ 2019, doi: 10.1109/ACCESS.2019.2909522. \n[33] M. A. Ebrahimi, M. H. Khoshtaghaza,\
    \ S. Minaei, and B. Jamshidi, “Vision-based pest detection based on SVM classification\
    \ \nmethod,” Computers and Electronics in Agriculture, vol. 137, pp. 52–58, May\
    \ 2017, doi: 10.1016/j.compag.2017.03.016. \n[34] A. dos S. Ferreira, D. M. Freitas,\
    \ G. G. da Silva, H. Pistori, and M. T. Folhes, “Weed detection in soybean crops\
    \ using \nConvNets,” Computers and Electronics in Agriculture, vol. 143, pp. 314–324,\
    \ Dec. 2017, doi: 10.1016/j.compag.2017.10.027. \n[35] Y. Karimi, S. O. Prasher,\
    \ R. M. Patel, and S. H. Kim, “Application of support vector machine technology\
    \ for weed and nitrogen \nstress detection in corn,” Computers and Electronics\
    \ in Agriculture, vol. 51, no. 1–2, pp. 99–109, Apr. 2006, doi: \n10.1016/j.compag.2005.12.001.\
    \ \n[36] B. Cheng and E. T. Matson, “A feature-based machine learning agent for\
    \ automatic rice and weed discrimination,” in Lecture \nNotes in Artificial Intelligence\
    \ (Subseries of Lecture Notes in Computer Science), vol. 9119, L. Rutkowski, M.\
    \ Korytkowski, R. \nScherer, R. Tadeusiewicz, L. A. Zadeh, and J. M. Zurada, Eds.\
    \ Cham: Springer International Publishing, 2015, pp. 517–527. \n[37] X.-E. Pantazi,\
    \ D. Moshou, and C. Bravo, “Active learning system for weed species recognition\
    \ based on hyperspectral sensing,” \nBiosystems Engineering, vol. 146, pp. 193–202,\
    \ Jun. 2016, doi: 10.1016/j.biosystemseng.2016.01.014. \n[38] F. Ahmed, H. A.\
    \ Al-Mamun, A. S. M. H. Bari, E. Hossain, and P. Kwan, “Classification of crops\
    \ and weeds from digital images: \na support vector machine approach,” Crop Protection,\
    \ vol. 40, pp. 98–104, Oct. 2012, doi: 10.1016/j.cropro.2012.04.024. \n[39] A.\
    \ Bakhshipour and A. Jafari, “Evaluation of support vector machine and artificial\
    \ neural networks in weed detection using shape \nfeatures,” Computers and Electronics\
    \ in Agriculture, vol. 145, pp. 153–160, Feb. 2018, doi: 10.1016/j.compag.2017.12.032.\
    \ \n[40] A. Milioto, P. Lottes, and C. Stachniss, “Real-time blob-wise sugar beets\
    \ vs weeds classification for monitoring fields using \nconvolutional neural networks,”\
    \ ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences,\
    \ vol. \nIV-2/W3, no. 2W3, pp. 41–48, Aug. 2017, doi: 10.5194/isprs-annals-IV-2-W3-41-2017.\
    \ \n[41] T. Rumpf, C. Römer, M. Weis, M. Sökefeld, R. Gerhards, and L. Plümer,\
    \ “Sequential support vector machine classification for \nsmall-grain weed species\
    \ discrimination with special regard to cirsium arvense and galium aparine,” Computers\
    \ and Electronics \nin Agriculture, vol. 80, pp. 89–96, Jan. 2012, doi: 10.1016/j.compag.2011.10.018.\
    \ \n[42] W. Kong, C. Zhang, W. Huang, F. Liu, and Y. He, “Application of hyperspectral\
    \ imaging to detect sclerotinia sclerotiorum on \noilseed rape stems,” Sensors,\
    \ vol. 18, no. 2, Jan. 2018, doi: 10.3390/s18010123. \n[43] A. Fuentes, S. Yoon,\
    \ S. Kim, and D. Park, “A robust deep-learning-based detector for real-time tomato\
    \ plant diseases and pests \nrecognition,” Sensors, vol. 17, no. 9, Sep. 2017,\
    \ doi: 10.3390/s17092022. \n[44] T. Rumpf, A.-K. Mahlein, U. Steiner, E.-C. Oerke,\
    \ H.-W. Dehne, and L. Plümer, “Early detection and classification of plant \n\
    diseases with support vector machines based on hyperspectral reflectance,” Computers\
    \ and Electronics in Agriculture, vol. 74, no. \n1, pp. 91–99, Oct. 2010, doi:\
    \ 10.1016/j.compag.2010.06.009. \n[45] S. P. Mohanty, D. P. Hughes, and M. Salathé,\
    \ “Using deep learning for image-based plant disease detection,” Frontiers in\
    \ Plant \nScience, vol. 7, no. 6, pp. 1083–1087, Sep. 2016, doi: 10.3389/fpls.2016.01419.\
    \ \n[46] K. Karadağ, M. E. Tenekeci, R. Taşaltın, and A. Bilgili, “Detection of\
    \ pepper fusarium disease using machine learning algorithms \nbased on spectral\
    \ reflectance,” \nSustainable Computing: Informatics and Systems, vol. 28, Dec.\
    \ 2020, doi: \n10.1016/j.suscom.2019.01.001. \n[47] D. Oppenheim, G. Shani, O.\
    \ Erlich, and L. Tsror, “Using deep learning for image-based potato tuber disease\
    \ detection,” \nPhytopathology, vol. 109, no. 6, pp. 1083–1087, Jun. 2019, doi:\
    \ 10.1094/PHYTO-08-18-0288-R. \n[48] A. Camargo and J. S. Smith, “Image pattern\
    \ classification for the identification of disease causing agents in plants,”\
    \ Computers \nand Electronics in Agriculture, vol. 66, no. 2, pp. 121–125, May\
    \ 2009, doi: 10.1016/j.compag.2009.01.003. \n[49] M. Brahimi, K. Boukhalfa, and\
    \ A. Moussaoui, “Deep learning for tomato diseases: classification and symptoms\
    \ visualization,” \nApplied Artificial Intelligence, vol. 31, no. 4, pp. 299–315,\
    \ Apr. 2017, doi: 10.1080/08839514.2017.1315516. \n[50] E. Omrani, B. Khoshnevisan,\
    \ S. Shamshirband, H. Saboohi, N. B. Anuar, and M. H. N. M. Nasir, “Potential\
    \ of radial basis \nfunction-based support vector regression for apple disease\
    \ detection,” Measurement, vol. 55, pp. 512–519, Sep. 2014, doi: \n10.1016/j.measurement.2014.05.033.\
    \ \n \n \nBIOGRAPHIES OF AUTHORS \n \n \nKavita Jhajharia \n \n \n \n was Born\
    \ in Jhunjhunu, Rajasthan, India, in 1992. She Received \nher B.Tech. Degree from\
    \ Rajasthan Technical University, India, in 2013 in Information \nTechnology,\
    \ and the M.Tech Degree from SRM University, Sonepat, India, in 2016. She is \n\
    Assistant Professor in Manipal University Jaipur since 2016. She is member of\
    \ ACM. Her \nResearch interest is VANET, Wireless networking, Machine Learning,\
    \ Software Engineering \nand IOT. She can be contacted at email: Kavita.chaudhary@outlook.com.\
    \ \n \n \n \nPratistha Mathur \n \n \n \n is a Professor in the Department of\
    \ Information Technology at \nManipal University Jaipur. She had an experience\
    \ of more than 20 years. She has done her Ph.D. \nin computer Science from Banasthali\
    \ Vidyapith in 2012. She has done M.Tech. in computer \nscience in 1998 and secure\
    \ the gold medal. Her Research areas are Digital Image Processing, \nSoft Computing\
    \ and Machine Learning. She is currently guiding many scholars at Ph.D. and \n\
    M.Tech. level. She has also been worked in the area of Indian language computing\
    \ and \nassociated with many funded projects of MCIT, DOE Rajasthan, DST Rajasthan.\
    \ She has \npublished more than 40 paper in international and national journals\
    \ and conferences. She has \nalso attended more than 25 workshops and trainings.\
    \ She can be contacted at email: \nPratistha.mathur@jaipur.manipal.edu. \n \n"
  inline_citation: '>'
  journal: IAES International Journal of Artificial Intelligence
  limitations: '>'
  pdf_link: https://ijai.iaescore.com/index.php/IJAI/article/download/21357/13391
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: A comprehensive review on machine learning in agriculture domain
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.22266/ijies2023.0630.46
  analysis: '>'
  authors: []
  citation_count: 1
  full_citation: '>'
  full_text: '>'
  inline_citation: '>'
  journal: International journal of intelligent engineering and systems
  limitations: '>'
  pdf_link: null
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: 'Optimized Farming: Crop Recommendation System Using Predictive Analytics'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3389/fpls.2023.1214006
  analysis: '>'
  authors:
  - Yongxin Lin
  - Shuang Li
  - Shaoguang Duan
  - Y. L. Ye
  - Bo Li
  - Guangcun Li
  - Dianqiu Lyv
  - Liping Jin
  - Chunsong Bian
  - Jiangang Liu
  citation_count: 3
  full_citation: '>'
  full_text: ">\nMethodological evolution of\npotato yield prediction:\na comprehensive\
    \ review\nYongxin Lin 1,2, Shuang Li 1, Shaoguang Duan 1, Yanran Ye 1,\nBo Li\
    \ 3, Guangcun Li 1, Dianqiu Lyv 2, Liping Jin 1,\nChunsong Bian 1* and Jiangang\
    \ Liu 1*\n1State Key Laboratory of Vegetable Biobreeding, Institute of Vegetables\
    \ and Flowers, Chinese\nAcademy of Agricultural Sciences, Beijing, China, 2College\
    \ of Agronomy and Biotechnology,\nSouthwest University, Chongqing, China, 3Seeds\
    \ Development, Syngenta Jealott’s Hill International\nResearch Centre, Bracknell,\
    \ United Kingdom\nTimely and accurate prediction of crop yield is essential for\
    \ increasing crop\nproduction, estimating planting insurance, and improving trade\
    \ beneﬁts. Potato\n(Solanum tuberosum L.) is a staple food in many parts of the\
    \ world and improving\nits yield is necessary to ensure food security and promote\
    \ related industries. We\nconducted a comprehensive literature survey to demonstrate\
    \ methodological\nevolution of predicting potato yield. Publications on predicting\
    \ potato yield\nbased on methods of remote sensing (RS), crop growth model (CGM),\
    \ and\nyield limiting factor (LF) were reviewed. RS, especially satellite-based\
    \ RS, is crucial\nin potato yield prediction and decision support over large farm\
    \ areas. In contrast,\nCGM are often utilized to optimize management measures\
    \ and address climate\nchange. Currently, combined with the advantages of low\
    \ cost and easy\noperation, unmanned aerial vehicle (UAV) RS combined with artiﬁcial\n\
    intelligence (AI) show superior potential for predicting potato yield in precision\n\
    management of large-scale farms. However, studies on potato yield prediction\n\
    are still limited in the number of varieties and ﬁeld sample size. In the future,\
    \ it is\ncritical to employ time-series data from multiple sources for a wider\
    \ range of\nvarieties and large ﬁeld sample sizes. This study aims to provide\
    \ a comprehensive\nreview of the progress in potato yield prediction studies and\
    \ to provide a\ntheoretical reference for related research on potato.\nKEYWORDS\n\
    yield prediction, potato, precision agriculture, remote sensing, crop growth model\n\
    1 Introduction\nGlobal food security is encountering signiﬁcant challenges from\
    \ climate change and\nincreasing resource competition (Godfray et al., 2010).\
    \ Potato (Solanum tuberosum L.), a\ntuberous crop, is cultivated worldwide due\
    \ to its stable and high yield, wide adaptability,\nand complete nutritional composition.\
    \ Furthermore, it is a pivotal crop for realizing the\nUnited Nations (UN) Sustainable\
    \ Development Goals (SDGs). Yield of potato and other\nFrontiers in Plant Science\n\
    frontiersin.org\n01\nOPEN ACCESS\nEDITED BY\nHuiling Chen,\nWenzhou University,\
    \ China\nREVIEWED BY\nQingquan Chu,\nChina Agricultural University, China\nYanbo\
    \ Huang,\nUnited States Department of Agriculture\n(USDA), United States\n*CORRESPONDENCE\n\
    Chunsong Bian\nbianchunsong@caas.cn\nJiangang Liu\nliujiangang@caas.cn\nRECEIVED\
    \ 28 April 2023\nACCEPTED 06 July 2023\nPUBLISHED 26 July 2023\nCITATION\nLin\
    \ Y, Li S, Duan S, Ye Y, Li B, Li G, Lyv D,\nJin L, Bian C and Liu J (2023)\n\
    Methodological evolution of potato yield\nprediction: a comprehensive review.\n\
    Front. Plant Sci. 14:1214006.\ndoi: 10.3389/fpls.2023.1214006\nCOPYRIGHT\n© 2023\
    \ Lin, Li, Duan, Ye, Li, Li, Lyv, Jin, Bian\nand Liu. This is an open-access article\n\
    distributed under the terms of the Creative\nCommons Attribution License (CC BY).\
    \ The\nuse, distribution or reproduction in other\nforums is permitted, provided\
    \ the original\nauthor(s) and the copyright owner(s) are\ncredited and that the\
    \ original publication in\nthis journal is cited, in accordance with\naccepted\
    \ academic practice. No use,\ndistribution or reproduction is permitted\nwhich\
    \ does not comply with these terms.\nTYPE Review\nPUBLISHED 26 July 2023\nDOI\
    \ 10.3389/fpls.2023.1214006\ncrops is determined interactively by genotype (G),\
    \ environment (E),\nand management practices (M) (Cooper et al., 2021). Analysis\
    \ and\nmodeling of key parameters can effectively predict crop yield,\nproviding\
    \ crucial guidance and decision support for various\nstakeholders, such as farmers,\
    \ policy makers, and agribusinesses.\nIn addition, these predictions substantially\
    \ impact optimizing\nplanting structure, optimizing trading policies, allocating\n\
    resources efﬁciently, and conducting precision management.\nThere have been signiﬁcant\
    \ strides in both theoretical and\npractical aspects of predicting potato yield.\
    \ Early on, such\nprediction relied on ﬁeld sampling, whereby the number and\n\
    weight of potatoes per unit area were measured to calculate the\nyield (Dyke and\
    \ Avis, 1953). Other agronomic traits in subsequent\nstudies, including petiole\
    \ potassium content (Holm and Nylund,\n1978), also served as useful indicators\
    \ for potato yield. Nevertheless,\nthese destructive methods require substantial\
    \ labor for ﬁeld\nsampling and do not provide complete spatial or temporal coverage.\n\
    Remote sensing (RS) has emerged as a popular tool in crop\nphenotyping (Araus\
    \ and Cairns, 2014), growth monitoring (Liu\net al., 2021), and yield prediction\
    \ (Ma et al., 2021), attributed to it\nbeing non-destructive, high-throughput,\
    \ and having large spatial\ncoverage. In 1974, the Large Area Crop Inventory Experiment\n\
    (LACIE) program, which showed the possibility of RS for yield\nprediction for\
    \ the ﬁrst time, was used to assess wheat acreage in the\nUnited States, Canada,\
    \ and the former Soviet Union combined with\nLandsat (MacDonald et al., 1975).\
    \ In 1977, the LACIE accurately\npredicted a declining trend in spring wheat production\
    \ in the Soviet\nUnion with precision of 90% leading to a positive impact on the\n\
    United States economy (Hill et al., 1980). From 1980 to 1986,\nmultiple departments\
    \ involved in the LACIE program collaborated\nin the Agriculture and Resources\
    \ Inventory Surveys Through\nAerospace Remote Sensing (AgRISTARS) initiative (Doraiswamy\n\
    et al., 1979). This effort aimed to predict yield for eight crops (not\nincluding\
    \ potato) within the United States and other countries\nworldwide. Satellite-based\
    \ potato yield prediction commenced later\nin the 1980s. Potato acreage was estimated\
    \ to predict production in\nCanada by Landsat (Ryerson et al., 1985). In 1987,\
    \ the European\nUnion proposed the Monitoring Agricultural Resources (MARS)\n\
    project, which utilized satellite and aerial imagery to continuously\nmonitor\
    \ the planting area and growth status of several staple crops\nincluding potatoes\
    \ (Van der Velde and Nisini, 2019). It also\nprovided timely prediction results\
    \ of crop yields for the\nEuropean Union.\nAlthough satellites have the advantage\
    \ of covering large areas of\nfarmland, they are greatly affected by the revisit\
    \ interval and low\nresolution. To address the growing demand for site-speciﬁc\
    \ crop\nmonitoring and yield prediction among farmers, research into\nproximal\
    \ RS technologies such as unmanned aerial vehicle (UAV)\nand ground-based RS has\
    \ increased rapidly. In contrast to satellites,\nUAVs possess tremendous potential\
    \ for site-speciﬁc phenotype\nacquisition, yield prediction, and precision management,\
    \ which is\nattributed to their low cost, convenience, and high spatial resolution\n\
    (Yang G. et al., 2017). Additionally, ground-based methods are\nincreasingly being\
    \ utilized for more detailed phenotypic analyses in\na variety of speciﬁc scenarios.\
    \ In general, RS is capable of rapidly\nmonitoring ﬁelds without damaging them.\
    \ However, it employs\nempirical modeling methods most of which lack a\nrobust\
    \ mechanism.\nCrop growth model (CGM) aim to describe the process of\npotato development\
    \ before harvest. POTATO (Ng and Loomis,\n1984) is the ﬁrst CGM for potato with\
    \ a complete mechanism.\nBetween the 1990s and early 2000s, potato CGM became\
    \ more\ncomprehensive with the incorporation of additional parameters,\nsuch as\
    \ water and nitrogen modules (Tang et al., 2021). During this\nperiod, various\
    \ models were developed, including DSSAT-\nSUBSTOR (Ritchie et al., 1995) and\
    \ LINTUL-NPOTATO (Van\nDelden et al., 2003). Although these models are mechanistic\
    \ and\nhave high precision, they require a substantial number of input\nparameters.\
    \ Furthermore, the calibration and validation of these\nmodels rely on ground-truth\
    \ data, which can be laborious\nto acquire.\nDuring the 2010s, sensor technology,\
    \ machine learning (ML),\ndigital image analysis, and data mining techniques developed\n\
    rapidly. Additionally, mechanisms underlying potato growth and\ndevelopment, yield\
    \ quality formation principles, and interactions\nbetween crop-environment-management\
    \ measures were better\nunderstood, encouraging improvement in theories of potato\n\
    yield prediction.\nYield prediction requires multidisciplinary knowledge at the\n\
    intersection of agronomy, meteorology, statistics, economics, and\ncomputer science.\
    \ Several studies have reviewed the advancements\nmade in yield prediction for\
    \ diverse crops such as rice (dela Torre\net al., 2021) and maize (Tandzi and\
    \ Mutengwa, 2020). In contrast,\nyield prediction for potato differs from other\
    \ major crops because\nits edible part is located belowground. Currently, there\
    \ is no\ncomprehensive literature survey of potato yield prediction due to\ncomplex\
    \ model types and application scenarios. To tackle these\nissues, this paper provides\
    \ an overview of the advancements in and\nprospects for potato yield prediction.\
    \ First, we present a summary of\nthe commonly used methodologies and compare\
    \ them. Second,\nafter thoroughly evaluating the existing methods, we envision\
    \ the\nfuture development of potato yield prediction. This review\ncomprehensively\
    \ evaluates the progress made in potato yield\nprediction and provides the corresponding\
    \ theoretical references.\n2 Literature survey\nA total of 276 articles including\
    \ the keywords “potato”, “yield or\nproduction or output”, and “estimat* or forecast*\
    \ or predict* or\nsimulat*” were identiﬁed in the Web of Science™ database\n(Clarivate\
    \ Analytics) through January 11, 2023. To encompass a\nbroader scope of relevant\
    \ studies, we also conducted a literature\nsurvey with the abovementioned keywords\
    \ on the Scopus database\nand retrieved 152 publications. After eliminating duplicates\
    \ and\nirrelevant studies, 160 publications were included in this study. As\n\
    depicted in Figure 1A, the number of pertinent studies has\nprogressively increased\
    \ since the 2010s. Furthermore, Figure 1B\ndemonstrates a growing number of annual\
    \ citations for these\npublications, indicating increased interest in this research\
    \ domain.\nThrough literature review, we classiﬁed studies on potato yield\nprediction\
    \ into three categories including methods based on RS,\nLin et al.\n10.3389/fpls.2023.1214006\n\
    Frontiers in Plant Science\nfrontiersin.org\n02\nCGM, and yield limiting factor\
    \ (LF). Methods with LF include those\nbased on agronomic and environmental parameters.\
    \ Figure 2\ndisplays the numbers of the three approaches in potato yield\nprediction\
    \ studies over the past 50 years. Initially, RS and CGM\nwere less used for potato\
    \ yield prediction. CGM-based methods\nhave a long history with the key period\
    \ of research and development\noccurring in the 1980s and 1990s. Since the 21st\
    \ century, CGM have\nbeen widely applied, with research efforts focused on the\n\
    parameterization of models under various conditions. The CO2\nresponse module\
    \ is integrated with climate models to assess the\nimpact of climate change on\
    \ future yields. With the development of\nadvanced information technology, RS-based\
    \ methods have emerged\nin the study of crop yield prediction, utilizing next-generation\n\
    sensors, UAVs, and ML algorithms. For instance, in 2020, there\nwere 17 publications\
    \ relating to potato yield prediction, of which\nten were dedicated to RS-based\
    \ methods. These publications\ncontain RS-based yield prediction at multiple carrying\
    \ platforms\nfor sensors, ranging from satellites and aerial, to ground-based\n\
    methods (Figure 3), achieving site-speciﬁc yield prediction across\nmultiple spatial\
    \ scales. Finally, to facilitate comprehension of\nreaders, we have produced a\
    \ nomenclature (Table 1).\n3 Remote sensing for potato\nyield prediction\nAgricultural\
    \ RS was primarily applied in the resource survey,\nand in crop growth monitoring,\
    \ yield prediction, disaster\nFIGURE 2\nDistribution of strategies for potato\
    \ yield prediction using CGM, RS, and LF-based methods since 1970s to 2020s.\n\
    A\nB\nFIGURE 1\nLiterature counts (A) and citations (B) for potato yield production\
    \ since 2003 to 2023.\nLin et al.\n10.3389/fpls.2023.1214006\nFrontiers in Plant\
    \ Science\nfrontiersin.org\n03\nestimation, and loss assessment (Weiss et al.,\
    \ 2020). The LACIE\nprogram in the 1970s was representative of RS-based yield\n\
    prediction in other crops; related applications in potatoes have\nbeen relatively\
    \ delayed. In the 1980s, researchers employed satellite\nimagery to estimate potato\
    \ acreage and combined it with yield data\nto estimate production (Ryerson et\
    \ al., 1985). Nonetheless, during\nthis period, yield data were still obtained\
    \ through interviewing\nfarmers, rather than direct evaluation of RS imagery.\
    \ In 1992, potato\nyield was estimated by combining process-based crop models\
    \ with\nleaf area index (LAI) data collected by handheld multispectral\nsensors\
    \ (Finke, 1992). However, the spatial coverage of the\nhandheld instruments was\
    \ incomplete, which made it challenging\nto capture the yield variability of the\
    \ entire ﬁeld. In the early 21st\ncentury, several studies were conducted using\
    \ non-destructive and\nconvenient UAVs and satellites, which provided more\ncomprehensive\
    \ spatial coverage, for potato yield estimation\n(Yokobori et al., 2004; Bala\
    \ and Islam, 2009). Currently, the\ntechnology for RS-based potato yield prediction\
    \ has signiﬁcantly\nadvanced with the emergence of new-generation platforms, sensors,\n\
    and advanced algorithms.\nIn this section RS-based yield prediction methods were\n\
    reviewed from three perspectives: the acquisition of RS\ninformation, the selection\
    \ of modeling parameters and the\nevolution of yield prediction models.\n3.1 Acquisition\
    \ of RS information\nThe RS system is comprised of a platform and integrated\n\
    sensors. Different types of RS platforms offer unique beneﬁts for\nspeciﬁc application\
    \ scenarios. According to the type of platform, we\ndivided the potato yield prediction\
    \ method based on RS into\nsatellite-based, aerial-based, and ground-based methods\n\
    for evaluation.\n3.1.1 Satellite-based RS\nPrimarily, satellites equipped with\
    \ spectral sensors can obtain\nground vegetation spectral information over large\
    \ areas for the\npurposes of land resource surveying, crop growth monitoring,\
    \ and\nyield prediction (Nakalembe et al., 2021). Since 1972, satellites such\n\
    as the Landsat-1, which is equipped with a Multispectral Scanner\n(MSS) containing\
    \ four spectral bands, have been successfully\nlaunched. As a result, humanity\
    \ began monitoring global\nresources and environmental factors on a large scale.\
    \ Landsat\nimagery was used to estimate potato acreage by Statistics Canada\n\
    in New Brunswick from 1980 to1982. They found that potato\nacreage could be estimated\
    \ accurately using Landsat images, with\na coefﬁcient of variation of around 5.5%\
    \ (Ryerson et al., 1985). A\nseries of weather observation satellites, such as\
    \ NOAA-6 with the\nAdvanced Very-High-Resolution Radiometer (AVHRR), has been\n\
    operated by the National Oceanic and Atmospheric Administration\n(NOAA) since\
    \ 1979. These satellites have provided an ample\namount of RS imagery for accurate\
    \ potato yield prediction\n(Akhand et al., 2016).\nEven the revisit time of NOAA\
    \ satellites equipped with AVHRR\nsensors is 12 hours, the spatial resolution\
    \ is only 1.1 km. In 1999, the\nEarth Observing System (EOS) program launched\
    \ Terra, which\ncarries ﬁve specially designed sensors for monitoring environmental\n\
    and climate change. Terra carries a Moderate Resolution Imaging\nSpectroradiometer\
    \ (MODIS) capable of receiving spectral\ninformation of 36 bands between 0.4 and\
    \ 14.4 mm with a spatial\nresolution of 250-1000 m. The potato yield was estimated\
    \ using\nFIGURE 3\nDistribution of RS Platforms adopted for potato yield prediction.\n\
    Lin et al.\n10.3389/fpls.2023.1214006\nFrontiers in Plant Science\nfrontiersin.org\n\
    04\nTABLE 1 Nomenclature: abbreviations and corresponding full names.\nAbbreviations\n\
    Full Name\nAbbreviations\nFull Name\nABA\nAbscisic Acid\nMCARI\nModiﬁed Chlorophyll\
    \ Absorption Ratio Index\nAEZ\nAgro-Ecological Zone\nMCYFS\nMars Crop Yield Forecasting\
    \ System\nAgRISTARS\nAgriculture and Resources Inventory Surveys Through Aerospace\
    \ Remote\nSensing\nML\nMachine Learning\nAI\nArtiﬁcial Intelligence\nMLR\nMultiple\
    \ Linear Regression\nANFIS\nAdaptive Neuro-Fuzzy Inference System\nMME\nMulti-Model\
    \ Ensembles\nANN\nArtiﬁcial Neural Network\nMODIS\nModerate Resolution Imaging\n\
    Spectroradiometer\nAPE\nAgro-Pastoral Ecotone\nMRE\nMean Relative Error\nAPSIM\n\
    Agricultural Production System Simulator Next Generation\nMS\nMultispectral\n\
    AVHRR\nAdvanced Very-High-Resolution Radiometer\nMSE\nMean Squared Error\nCC\n\
    Canopy Cover\nMSS\nMultispectral Scanner\nCGM\nCrop Growth Model\nMTY\nMarketable\
    \ Tuber Yield\nCGMS\nCrop Growth Monitoring System\nNDVI\nNormalized Difference\
    \ Vegetation Index\nCI\nChlorophyll Index\nNOAA\nNational Oceanic and Atmospheric\n\
    Administration\nCI1\nRed-Edge Chlorophyll Index 1\nNRCT\nNormalized Relative Canopy\
    \ Temperature\nCI2\nRed-Edge Chlorophyll Index 2\nOLI\nThematic Mapper Plus\n\
    CIP\nInternational Potato Center\nPAR\nPhotosynthetically Active Radiation\nCT\n\
    Computed Tomography\nPPI\nPotato Productivity Index\nCV\nComputer Vision\nPROSPECT\n\
    Leaf Optical Properties Spectra Model\nDL\nDeep Learning\nRF\nRandom Forest\n\
    EnKF\nEnsemble Kalman Filter\nRS\nRemote Sensing\nEOS\nEarth Observing System\n\
    RVI\nRatio Vegetation Index\nETM+\nEnhanced Thematic Mapper Plus\nSAIL\nScattering\
    \ By Arbitrarily Inclined Leaves\nModel\nEVI\nEnhanced Vegetation Index\nSAR\n\
    Synthetic Aperture Radar\nFAO\nFood And Agriculture Organization\nSAVI\nSoil-Adjusted\
    \ Vegetation Index\nFPAR\nFraction Of Absorbed Photosynthetically Active Radiation\n\
    SDGs\nSustainable Development Goals\nGA\nGenetic Algorithm\nSLR\nSimple Linear\
    \ Regression\nGF-1\nGaofen-1\nSVM\nSupport Vector Machine\nGLUE\nGeneralized Likelihood\
    \ Uncertainty Estimation\nTCI\nTemperature Condition Index\nHI\nHarvest Index\n\
    TIR\nThermal Infrared\nHS\nHyperspectral\nTM\nThematic Mapper\nIIASA\nInternational\
    \ Institute for Applied Systems Analysis\nUAV\nUnmanned Aerial Vehicle\nLACIE\n\
    Large Area Crop Inventory Experiment\nUN\nUnited Nations\nLAI\nLeaf Area Index\n\
    VCI\nVegetation Condition Index\nLF\nLimiting Factor\nVI\nVegetation Index\nLiDAR\n\
    Light Detection and Ranging\nWDVI\nWeighted Difference Vegetation Index\nLSTM\n\
    Long Short-Term Memory Networks\nWOFOST\nWorld Food Studies\n(Continued)\nLin\
    \ et al.\n10.3389/fpls.2023.1214006\nFrontiers in Plant Science\nfrontiersin.org\n\
    05\nNormalized Difference Vegetation Index (NDVI), LAI, and\nFraction of Absorbed\
    \ Photosynthetically Active Radiation (FPAR)\nextracted from Terra-MODIS with\
    \ an average error rate at 15%\ncompared with actual yield by Bala and Islam (2009).\n\
    Despite signiﬁcant enhancements in the resolution of MODIS\nimaging sensor compared\
    \ with the NOAA satellites, the mixed\nimage components comprising of different\
    \ objects such as soil and\npotato canopy remain challenging to be discriminated.\
    \ Low-\nresolution satellite imaging encounters the obstacle in estimating\npotato\
    \ yields in relatively smaller regions. Landsat 4 and subsequent\nsatellites equipped\
    \ with Thematic Mapper (TM), Enhanced\nThematic Mapper Plus (ETM+), or Operational\
    \ Land Imager\n(OLI), featuring a spatial resolution from 30 to 120 meters. The\n\
    ongoing Landsat 8 and Landsat 9 observation missions each offer a\nrevisit cycle\
    \ of around 16 days. The joint utilization of both satellites\nhas the potential\
    \ to halve the revisit period to 8 days. Similarly, the\nSentinel-2 of Copernicus\
    \ Programme captures images of the same\nregion every 10 days with a high spatial\
    \ resolution ranging from 10\nto 60 meters. Furthermore, the successful integration\
    \ of Sentinel-2A\nand Sentinel-2B has the capability to reduce the revisit interval\
    \ to a\nmere 5 days.\nSatellites with greater spatial resolution and shorter revisit\n\
    cycles showed better potential in predicting potato yield. Al-Gaadi\net al. (2016)\
    \ compared the accuracy of yield estimation for potato\nusing Landsat-8 and Sentinel-2.\
    \ Landsat-8 exhibited a range of\nprediction errors, ranging from 7.9% to 13.5%,\
    \ along with R2 values\nranging from 0.39 to 0.65 at different sites. In contrast,\
    \ Sentinel-2\ndemonstrated a lower prediction error, falling between 3.8% and\n\
    10.2%, though there was no signiﬁcant improvement in R2, which\nwas between 0.47\
    \ and 0.65.\nUltra-high-resolution satellites with meter and sub-meter\nspatial\
    \ resolution have emerged in recent years providing high-\nquality RS imaging\
    \ data for monitoring crop development. RS\nemployed in satellites has recently\
    \ undergone substantial\ndevelopment, resulting in signiﬁcant advancements in\
    \ spatial,\nspectral, and temporal resolution. Nevertheless, the current cost\n\
    of high-precision images acquired by commercial satellites remains\nhigh, and\
    \ it is challenging for free satellite imagery at low spatial\nresolution to provide\
    \ high-accuracy yield prediction. Moreover,\napart from resolution and cost, weather\
    \ conditions like cloud cover\ncan also limit the data quality of obtained vegetation\
    \ spectra. Site-\nspeciﬁc potato dry matter yield was estimated using GeoEye-1\
    \ with\nan R2 value of 0.60 (Elmetwalli et al., 2014). Due to the cost\nreduction\
    \ in satellite launch, a number of commercial companies\nhave launched small satellites\
    \ that can be leveraged for Earth\nobservation. PlanetScope, launched by Planet\
    \ comprising 130\nsmall satellites that can capture daily multispectral images\
    \ at 3-\nmeter resolution. PlanetScope images were utilized to develop\npotato\
    \ yield prediction models in Idaho and applied them to\nassess yield differences\
    \ between Norkotah and Russet varieties in\nLebanon (Abou Ali et al., 2020). Table\
    \ 2 displays several satellites\nand sensors that have been utilized for potato\
    \ yield prediction in\nrecent times. Meanwhile, we present some cases of potato\
    \ yield\nprediction with satellites in Table 3.\nFor the past decades, RS employed\
    \ in satellites has undergone\nsubstantial development, resulting in signiﬁcant\
    \ advancements in\nspatial, spectral and temporal resolution. Nevertheless, the\
    \ current\ncost of high-precision images acquired by commercial satellites remains\n\
    high, and it is challenging for the free satellite imagery at low spatial\nresolution\
    \ to provide high-accuracy yield prediction. Moreover, apart\nfrom resolution\
    \ and cost, weather conditions like cloud cover can also\nlimit the data quality\
    \ of obtained vegetation spectra.\n3.1.2 Aerial-based RS\nAerial-based RS platforms\
    \ include aerial vehicles at high\naltitudes and UAVs at low altitudes. A ﬁxed-wing\
    \ aerial plane\nPiper Seneca equipped with multispectral cameras was used to\n\
    capture images of southern Idaho to estimate irrigated potato yield,\nwhich can\
    \ be performed as a ﬂexible and effective tool for yield\nprediction (Sivarajan,\
    \ 2011). However, the cost for fuel and\nprofessional pilot is high. Recently,\
    \ UAVs has become an\nimportant tool for RS-based yield prediction owing to its\n\
    advantages of high resolution, high throughput, and low cost\n(Yang G. et al.,\
    \ 2017). Compared with satellites and manned\naircraft, UAVs equipped with high-resolution\
    \ sensors are able to\nacquire more detailed vegetation phenotypic information\
    \ to predict\nyield. Most of the UAVs for ﬁeld phenotyping ﬂy at an altitude of\n\
    below 150 m (Stöcker et al., 2017), and the image resolution can\nreach the centimeter\
    \ level. There are several kinds of UAVs used in\nagriculture, such as multi-rotor\
    \ UAVs, ﬁxed-wing UAVs and\nunmanned helicopters. Multi-rotor UAVs are able to\
    \ hover and\nturn ﬂexibly in the air (Fu et al., 2020) but with high power usage,\n\
    which lead to short battery life mostly within 30 minutes. In\naddition, multi-rotor\
    \ UAV can carry limited number and types of\nsensors due to the small payload.\
    \ Fixed-wing UAVs can ﬂy at high\nspeed with longer battery life, allowing them\
    \ to cover a large area of\nfarmland in a short period of time. In addition, ﬁxed-wing\
    \ UAVs\nwith large wings typically have larger payloads which can offer a\nwider\
    \ sensor option. However, it is impossible for ﬁxed-wing UAV\nto capture data\
    \ in small-scale farms because of the long runways\nrequired for takeoff and landing,\
    \ and the inability to hover and turn\nﬂexibly in the air. Multi-rotor UAV is\
    \ mostly used for potato yield\nforecasting, which is also for current mapping\
    \ operations. Although\nwe have not yet found the application ofﬁxed-wing drones\
    \ in potato\nyield prediction, they have great potential for large-scale potato\
    \ ﬁeld\nmonitoring due to their high speed, long endurance, and large loads.\n\
    TABLE 1 Continued\nAbbreviations\nFull Name\nAbbreviations\nFull Name\nLUE\nLight\
    \ Use Efﬁciency\nWP\nWater Productivity\nMARS\nMonitoring Agricultural Resources\n\
    4DVAR\nFour-Dimensional Variational Data\nAssimilation\nLin et al.\n10.3389/fpls.2023.1214006\n\
    Frontiers in Plant Science\nfrontiersin.org\n06\nCompared to satellites that carry\
    \ a ﬁxed number and type of\nsensors, UAVs can readily change to appropriate sensors\
    \ to meet\nspeciﬁc needs. For example, it is feasible to extract information such\n\
    as vegetation structure and reﬂectance from high-resolution RGB\nimages for growth\
    \ monitoring and biomass estimation. In contrast\nto digital RGB cameras that\
    \ can function in the visible range,\nmultispectral (MS) cameras obtain images\
    \ at multiple spectral\nbands, including near infrared, which provides supplemented\n\
    spectral information to estimate yield by calculating vegetation\nindexes (VIs).\
    \ With the relatively low price of RGB and MS\ncameras, researchers often choose\
    \ affordable small or medium-\nsized UAVs to conduct ﬁeld trials. Most MS can\
    \ only acquire a\nsmall amount of spectral information with low spectral resolution\n\
    in the visible and near-infrared bands. In contrast, hyperspectral\n(HS) cameras\
    \ provide higher spectral resolution with more\ncontinuous spectral information\
    \ than MS. The above-mentioned\nspectral sensors have speciﬁc requirements for\
    \ weather conditions\nwhen performing their tasks; in particular MS and HS need\
    \ to\nacquire images in clear and cloud-free conditions.\nRelative to passive\
    \ sensors, active sensors can obtain highly\naccurate phenotypic information,\
    \ such as plant height and biomass,\nindependent of sunlight (ten Harkel et al.,\
    \ 2020). Light Detection\nand Ranging (LiDAR) and Synthetic Aperture Radar (SAR)\
    \ are\ntypical active sensors available on the market today. LiDAR obtains\n3D\
    \ and echo intensity information of vegetation to monitor crop\ngrowth based on\
    \ the backward scattering characteristics of the light\nfeature (Raj et al., 2020).\
    \ SAR is a high-resolution active microwave\nimaging detection sensor that can\
    \ penetrate clouds to obtain crop\nphenotypic information independent of atmospheric\
    \ conditions\nand solar radiation (Lyalin et al., 2018). Active sensors such as\n\
    LiDAR and SAR have not been applied in potato yield prediction.\nDue to the high\
    \ cost of HS imaging sensor, reliable UAVs, such as\nthe DJI Matrice 600 Pro (DJI\
    \ Technology Co., Shenzhen, China) is\npreferred. Despite the advantages of UAVs\
    \ for yield estimation at a\nlarge scale, there are still fewer studies on the\
    \ application of UAV\nfor potato yield prediction comparing to other staple crops.\
    \ For\nreference, we summarize some previous studies of potato yield\nprediction\
    \ combined with UAVs in Table 4.\n3.1.3 Ground-based RS\nGround-based methods\
    \ provide higher resolution and more\nangular image data for crop ﬁeld phenotype.\
    \ Many ground-based\nplatforms have been developed, such as handheld or bracketed\n\
    devices, ground carriers, tracks, ropeways, and ﬁxed towers. They\nhave their\
    \ own unique advantages for different applications.\nHandheld or bracketed devices\
    \ are simple and ﬂexible in\nacquiring data. Tracks, ropeways, and ﬁxed towers\
    \ provide\ncontinuous observation of the same plot with high-precision\nsensors.\
    \ However, they can only acquire data of speciﬁc plant\nsamples. In contrast,\
    \ ground carriers can perform data acquisition\ntasks over relatively larger areas.\n\
    According to our literature review, handheld or bracketed\ndevices are still the\
    \ most applied ground-based platforms for\npotato yield prediction. Different\
    \ sensors have been used to\npredict potato yield by correlating various factors\
    \ with yield.\nZaeen et al. (2020) combined chlorophyll index (CI) and multiple\n\
    VIs obtained by active sensors (Crop Circle™ and GreenSeeker™)\nto improve the\
    \ performance of potato yield prediction. Their results\nindicated that the 18th\
    \ and 20th leaf growth stages were the optimal\nperiod for data collection. No\
    \ signiﬁcant difference in accuracy\nbetween active spectral sensor and passive\
    \ sensor was found for\nyield prediction in the early season by comparing handheld\
    \ active\nsensors (Crop Circle™ and GreenSeeker™) with the portable MS\nAltum\
    \ (MicaSense, Seattle, WA, USA) equipped on UAVs (Jasim\net al., 2020). To the\
    \ best of our knowledge, active sensors such as\nSAR and LiDAR have not been applied\
    \ in potato yield prediction.\nTABLE 2 Satellites that have previously been used\
    \ to predict potato yields.\nPlatform\nSensors\nBands\nNumber\nBands range*\n\
    Revisit interval\n(days)\nSpatial Resolution (m/\npixel)\nCost\nRunning state\
    \ on\norbit\nNOAA\nAVHRR\n5-6\nVIS, NIR, MIR, TIR\n0.5\n1100\nFree\nIn progress\n\
    Landsat 5\nTM\n7\nVIS, NIR, SWIR, TIR\n16\n30, 120\nFree\nDecommissioned in\n\
    2013\nLandsat 7\nETM+\n7\nVIS, NIR, SWIR, TIR,\nPAN\n16\n15, 30, 60\nFree\nDecommissioned\
    \ in\n2021\nTerra\nMODIS\n36\nVIS, NIR, SWIR,\nMIR, TIR\n1-2\n250, 500, 1000\n\
    Free\nIn progress\nIRS P6\nLISS-3\n4\nVIS, NIR\n24\n23.5\nPaid\nIn progress\n\
    GeoEye-1\n–\n4\nVIS, NIR\n3-5\n0.41-1.65\nPaid\nIn progress\nLandsat 8, 9\nOLI/TIRS\n\
    11\nVIS, NIR, SWIR, TIR,\nPAN\n16\n15, 30, 100\nFree\nIn progress\nPlanetScope\n\
    PS2, PS2-\nSD\n4-5\nVIS, RE, NIR\n1-2\n3-4\nPaid\nIn progress\nSentinel-\n2A/2B\n\
    MSI\n13\nVIS, RE, NIR, SWIR\n10\n10, 20, 60\nFree\nIn progress\n*Meaning of the\
    \ abbreviations. MIR, Mid-Infrared; MW, Microwave; NIR, Near Infrared; PAN, Panchromatic;\
    \ RE, Red edge; SWIR, Shortwave Infrared; TIR, Thermal Infrared; VIS, Visible\
    \ Spectrum.\nLin et al.\n10.3389/fpls.2023.1214006\nFrontiers in Plant Science\n\
    frontiersin.org\n07\nTABLE 3 Summary of satellite-based potato yield prediction.\n\
    Testing\nyear\nCountry\nSatellite\nSensor\nType\nSensor\nModel\nCultivars\nParameters\n\
    Modelling\nMethod\nAccuracy\nSample\nsize\nReferences\n2005/06-\n2006/07\nBangladesh\n\
    Terra\nMS1\nMODIS\n–\nRegional level:\nNDVI2,\nLAI3,\nFPAR4,\nField level:\nmean\
    \ NDVI\nSLR23\nRegional\nlevel:\nR2 (NDVI)\n= 0.79;\nR2 (LAI) =\n0.87;\nR2 (FPAR)\n\
    = 0.83;\nField level:\nR2 (mean\nNDVI) =\n0.66\n6\n(Regional)\n50 (Field)\nBala\
    \ and\nIslam, 2009\n2004-2005\nUnited\nStates\nLandsat 5\nMS\nTM\n–\nISAVI5,\n\
    cumulative\nET6\nMLR24\nR2 (2004) =\n0.97;\nR2 (2005) =\n0.75\n9 (2004)\n13 (2005)\n\
    Sivarajan,\n2011\n2011\nLibya\nGeoEye-1\nMS\n–\n–\nNDVI\nSLR\nR2 = 0.60\n24\n\
    Elmetwalli\net al., 2014\n1980-2014\nBangladesh\nNOAA\nMS\nAVHRR\n–\nVCI7, TCI8\n\
    ANN25\nerror % <\n10%\n24\nAkhand et al.,\n2016\n2016\nSaudi\nArabia\nLandsat\
    \ 8,\nSentinel-2A\nMS\nOLI/\nTIRS,\nMSI\n–\nNDVI, SAVI,\ncumulative\nNDVI,\ncumulative\n\
    SAVI\nSLR\nR2 (Landsat\n8) = 0.39-\n0.65\nR2\n(Sentinel-\n2A) = 0.47-\n0.65\n\
    60\nAl-Gaadi\net al., 2016\n2010/11-\n2015/16\nBangladesh\nLandsat 5,\n7, 8\n\
    MS\nTM,\nETM+,\nOLI/TIRS\n–\nMean NDVI\nSLR\nR2 = 0.81\n6\nNewton et al.,\n2018\n\
    2016-2018\nSpain\nSentinel-\n2A, 2B\nMS\nMSI\n–\nARI29, CRI210,\nIRECI211,\nLCC12,\
    \ NDVI,\nPSRI13,\nWDVI14, S2\nbands15\nGLM26,\nrqlasso27,\nLeapBack28,\nsvmL29,\n\
    svmR30,\nMARS31,\nkknn32, RF33,\navNNet34\nThe best\nthree\nalgrithoms:\nR2 (rqlasso)\n\
    = 0.90;\nR2\n(LeapBack)\n= 0.89;\nR2 (svmR)\n= 0.93\n33\nGómez et al.,\n2019\n\
    2012/13-\n2017/18\nIndia\nIRS P6\nMS\nLISS-3\n–\nVCI, climate\ndata\nStep wise\n\
    regression\nRMSE =\n9.8-21.8%\n–\nKumar et al.,\n2019\n2017\nUnited\nStates,\n\
    Lebanon\nPlanetScope\nMS\nPS2, PS2-\nSD\nRusset\nBurbank,\nNorkotah\nSAVI\nOLS35\n\
    R2 (Russet\nBurbank) =\n0.44;\nR2\n(Norkotah)\n= 0.57\n–\nAbou Ali\net al., 2020\n\
    2004-2018\nMexico\nTerra\nMS\nMODIS\n–\nNDVI,\nHarvested last\nyear, climate,\n\
    irrigation\nRF, svmP,\nsvmL, svmR,\nGLM\nR2 (RF) =\n0.757-0.839;\nR2 (svmR)\n\
    = 0.733-\n0.837;\nR2 (svmL)\n= 0.692-\n0.863;\nR2 (svmP)\n= 0.717-\n0.858;\nR2\
    \ (GLM)\n838\nSalvador\net al., 2020\n(Continued)\nLin et al.\n10.3389/fpls.2023.1214006\n\
    Frontiers in Plant Science\nfrontiersin.org\n08\nProximal handled thermal infrared\
    \ (TIR) imaging sensors could\nobtain canopy temperature at higher accuracy, but\
    \ the accuracy\ndecreased to ±5°C when integrating with UAV due to the impact\
    \ of\nenvironmental conditions for potato yield prediction (Kelly et al.,\n2019).\
    \ By capturing imaging data with combining a handheld\ninfrared camera (Ti-32,\
    \ Fluke Thermography, Glottertal,\nGermany) and a digital RGB camera (D5100 reﬂex,\
    \ Kodak,\nTokyo, Japan), an integrated adaptive neuro-fuzzy inference\nsystem\
    \ with a genetic algorithm (ANFIS-GA) was used to predict\nyield of two potato\
    \ varieties in a dry crop trial in Egypt (Elsayed\net al., 2021). Similarly, we\
    \ list some studies for potato yield\nprediction by ground-based RS in the Table\
    \ 5. Other platforms\nwere not identiﬁed for potato yield prediction.\n3.2 Selection\
    \ of RS-based\nmodeling parameters\nThe spectral, structural, thermal, and textural\
    \ information of\ncrop canopies are important indicators to explain yield variability\n\
    (Maimaitijiang et al., 2020). Reﬂected light from the canopy allows\nus to estimate\
    \ the photosynthetic capacity and other crop growth\nconditions of plants to predict\
    \ yield. VIs highlight image spectral\nfeatures to analyze crop phenotypic traits\
    \ by fusing reﬂectance\ninformation from two or more bands; the normalized difference\n\
    vegetation index (NDVI) is the most used VI in agriculture RS\n(Huang et al.,\
    \ 2021). In addition to NDVI, other VIs such as Soil-\nAdjusted Vegetation Index\
    \ (SAVI), Ratio Vegetation Index (RVI)\nand Enhanced Vegetation Index (EVI) are\
    \ also used in the ﬁeld of\npotato yield prediction. Recently, Potato Productivity\
    \ Index (PPI),\ncalculated based on the two bands at 490 to 945 nm bands\nconsidering\
    \ the key role of water stress on potato tuber\ndevelopment and yield formation,\
    \ was designed for potato\nproduction practices by Gómez et al. (2021). All bands\
    \ of\nSentinel-2, NDVI, PPI, coupled with a random forest (RF) model\nwere adopted\
    \ to predict potato yield, with the R2 of 0.77. In addition\nto moisture, temperature\
    \ is also an important environmental factor\naffecting potato tuber development.\
    \ TIR cameras can generate\nthermal indices such as normalized relative canopy\
    \ temperature\n(NRCT) to monitor temperature change on canopy to monitor\ndrought\
    \ tolerance (Elsayed et al., 2021). The difference between\ncanopy temperature\
    \ and air temperature can also reveal the water\nstress status of potato. The\
    \ full spectral bands obtained by HS\ncameras provide more spectral information\
    \ in visible and near\ninfrared region for potato yield prediction than the spectral\
    \ index\nabove. Potato yield was predicted by using full-band spectra\nTABLE 3\
    \ Continued\nTesting\nyear\nCountry\nSatellite\nSensor\nType\nSensor\nModel\n\
    Cultivars\nParameters\nModelling\nMethod\nAccuracy\nSample\nsize\nReferences\n\
    = 0.612-\n0.834\n2016-2019\nSpain\nSentinel-2\nMS\nMSI\nMonalisa,\nSpunta,\nRudolf\n\
    NDVI,\nPPI16, S2\nbands\nRF, SVM\nS2 & PPI:\nR2 (RF) =\n0.77;\nR2 (SVM)\n= 0.63\n\
    S2 &\nNDVI:\nR2 (RF) =\n0.66;\nR2 (SVM)\n= 0.64\n40\nGómez et al.,\n2021\n2019-2020\n\
    United\nKingdom\nSentinel-2\nMS\nMSI\nMaris\nPiper,\nAmora,\nPentland\nDell\n\
    NDVI,\nSLAVI17,\nNDMI18,\nCIG19\nSLR\nR2 = 0.65,\nNRMSE =\n0.16\n94\nMhango et\
    \ al.,\n2021\n2020\nIndia\nSentinel-2\nMS\nMSI\n–\nNDVI\nSLR\nR2 = 0.692\n50\n\
    Singha and\nSwain, 2022\n2016-2018\nBelgium\nSentinel-2\nMS\nMSI\n–\nNDVI\nintegral,\n\
    Tmax20, P21,\nSDrz22\nRF\nR2 (Late\npotato) =\n0.57;\nR2 (Early\npotato) =\n0.68\n\
    723\nVannoppen\nand Gobin,\n2022\n1 MS, Multispectral; 2 NDVI, Normalized Difference\
    \ Vegetation Index; 3 LAI, Leaf Area Index; 4 FPAR, Fraction of Absorbed Photosynthetically\
    \ Active Radiation; 5 ISAVI, three-date Integrated\nSoil Adjusted Vegetation Index;\
    \ 6 ET, Evapotranspiration; 7 VCI, Vegetation Condition Index; 8 TCI, Temperature\
    \ Condition Index; 9 ARI2, Anthocyanin Reﬂectance Index; 10 CRI2, Carotenoid\n\
    Reﬂectance Index; 11 IRECI2, Inverted Red-Edge Chlorophyll Index; 12 LCC, Leaf\
    \ Chlorophyll Content; 13 PSRI, Plant Senescence Reﬂectance Index; 14 WDVI, Weighted\
    \ Difference Vegetation\nIndex; 15 S2 bands, Sentinel-2 bands; 16 PPI, Potato\
    \ Productivity Index; 17 SLAVI, Speciﬁc Leaf Area Vegetation Index; 18 NDMI, Normalized\
    \ Difference Moisture Index; 19 CIG, Chlorophyll\nIndex Green; 20 Tmax, monthly\
    \ maximum temperature; 21 P, monthly precipitation; 22 SDrz, daily root-zone soil\
    \ water depletion; 23 SLR, Single Linear Regression; 24 MLR, Multiple Linear\n\
    Regression; 25 ANN, Artiﬁcial Neural Network; 26 GLM, Generalised Linear Model;\
    \ 27 rqlasso, Quantile Regression with LASSO penalty; 28 LeapBack, Linear Regression\
    \ with Backwards Selection;\n29 svmL, Support Vector Machine Linear; 30 svmR,\
    \ Support Vector Machine Radial; 31 svmP, Support Vector Machine Polynomial; 32\
    \ MARS, Multivariate adaptive regression splines; 33 RF,\nRandom Forest; 34 kknn,\
    \ k-Nearest Neighbours; 35 avNNet, Averaged Neural Network.\nLin et al.\n10.3389/fpls.2023.1214006\n\
    Frontiers in Plant Science\nfrontiersin.org\n09\nTABLE 4\nSummary of aerial-based\
    \ potato yield prediction.\nCountry\nPlatform\nType\nPlatform\nModel\nSensor\n\
    Type\nSensor Model\nCultivars\nBands\nnumber\nBands\nrange\nParameters\nModelling\n\
    Method\nAccuracy\nSample\nsize\nReferences\nUnited\nStates\nPlane\nPiper Seneca\n\
    MS1\nthree Kodak Megaplus 4.2i\ndigital cameras\n–\n3\nG, R,\nNIR\nIntegrated\
    \ SAVI\nSLR11\nR2 = 0.89\n18\nSivarajan,\n2011\nJapan\nUAV\nYH300\n(Yammer\nLtd.)\n\
    MS\nMSIS, MS2100, DuncanTech,\nLtd.\nToyoshiro\n4\nVIS,\nNIR\nSPAD, stem length\n\
    MLR12\nR2 = 0.75\n10\nYokobori\net al., 2004\nJapan\nUAV\nDJI\nSpreading\nWings\
    \ S900\nMS\nMicro MCA RGB+3, Tetracam\nToyoshiro\n6\n425-950\nnm\nNDVI, height\n\
    Alex Net,\nSLR, MLR\nR2 (NDVI) =\n0.18-0.67;\nR2 (NDVI &\nheight) =\n0.12-1.00;\n\
    Alex Net:\nInsufﬁcient\nprecision\n23\nTanabe et al.,\n2019\nChina\nUAV\nDJI Matrice\n\
    600 Pro\nHS2\nHeadwall Nano-Hyperspec\n(Headwall Photonics Inc.,\nBolton, MA,\
    \ USA)\nFavorita;\nShepody;\nZhongshu 5/10/\n18/19\n272\n400-\n1000 nm\nMCARI3,\
    \ CI14, CI25,\nMCARI/OSAVI6, full\nspectrum, height\nPLSR13, RF14\nR2 (PLSR) =\n\
    0.81;\nR2 (RF) =\n0.63\n144\nLi et al., 2020\nUnited\nStates\nUAV\nDJI Matrice\n\
    600 Pro\nHS\nHeadwall Nano-Hyperspec\n(Headwall Photonics Inc.,\nBolton, MA, USA)\n\
    6 unknown\nvarieties\n273\n400-\n1000 nm\nfull spectrum\nRidge15;\nOLS16;\nPLSR;\
    \ SVM17;\nRF; AdaBoost\nR2 (ridge) =\n0.63;\nR2 (OLS) =\n0.13;\nR2 (PLSR) =\n\
    0.53;\nR2 (SVR) =\n0.57;\nR2 (RF) =\n0.51;\nR2\n(AdaBoost) =\n0.45;\n96\nSun et\
    \ al.,\n2020\nUnited\nStates\nUAV\nDJI\nPhantom 4,\nDJI Inspire\n2\nMS\nNIR +\
    \ regular camera/senser;\nAltum multispectral\nsensor (MicaSense, Seattle, WA,\n\
    USA)\nRusset Burbank;\nShepody;\nSuperior\n4, 6\nVIS, RE,\nNIR,\nLWIR\nANTHO7,\
    \ GNDVI8,\nBNDVI9; CHLGR10,\nNDVI\nGLM18\nR2 = 0.34-\n0.63\n288\nJasim et al.,\n\
    2020\nChina\nUAV\nDJI Matrice\n600\nHS\nregular camera, Cubert UHD-\n185\nZhongshu\
    \ 3/5\n125\n450-950\nnm\n–\nPLSR\nR2 = 0.74,\nNRMSE =\n22.37%\n42\nWu et al.,\n\
    2020\n(Continued)\nLin et al.\n10.3389/fpls.2023.1214006\nFrontiers in Plant Science\n\
    frontiersin.org\n10\nbetween 400 and 1000 nm (R2 = 0.81), which had better\nperformance\
    \ than using plant height and several VIs including\nRed-edge Chlorophyll Index\
    \ 1 (CI1), Modiﬁed Chlorophyll\nAbsorption Ratio Index (MCARI), Ratio2, and Red-edge\n\
    Chlorophyll Index 2 (CI2) (R2 = 0.69) (Li et al., 2020).\nIt is essential to select\
    \ the best period to estimate yield because\nof the great variation in the predicted\
    \ performance of different\ngrowth periods. The weight of values at different\
    \ growing periods\nwere determined for estimating yield of potato using a handheld\n\
    hyperspectral camera (Luo et al., 2020). They believed that the tuber\nexpansion\
    \ period (about 70 days after planting in this study) was\nthe best period for\
    \ potato yield prediction with an adjusted\nR2 = 0.83. In addition, it has also\
    \ been noted that 90 days after\nplanting is satisfactory for potato yield prediction\
    \ (Li et al., 2020).\nThis may be caused by the great variation in species and\n\
    environmental conditions selected for different studies.\nMeanwhile, many studies\
    \ have used time series data rather than\nsingle period data to predict yields\
    \ (Fernandes et al., 2017; Aghighi\net al., 2018). This could be due to the more\
    \ comprehensive\ninformation on crop growth and development contained within\n\
    the time-series data. For potato yield prediction, three-date\nIntegrated SAVI\
    \ (ISAVI) is a better predictor of yield than single-\nperiod SAVI (Sivarajan,\
    \ 2011). Time-series data can also be applied\nto advanced algorithms such as\
    \ Long Short-Term Memory\nnetworks (LSTM) and three-dimensional Convolutional\
    \ Neural\nNetwork (3D-CNN).\nCompared with spectral features, canopy traits such\
    \ as LAI,\nplant height, and canopy cover (CC) can reﬂect the light use\nefﬁciency\
    \ on the canopy. VIs combined with structural\nparameters such as plant height\
    \ and LAI provides a better\nprediction of potato yield (Sharma et al., 2017;\
    \ Tanabe et al.,\n2019). In contrast to passive RS, active RS comes with its own\n\
    radiation source and reﬂects the characteristics of the ground by\ntransmitting\
    \ and receiving electromagnetic waves. Their\napplications are less affected by\
    \ ambient light and the\nelectromagnetic wave wavelength and emission mode can\
    \ be set\naccording to different land features, allowing them to obtain the\n\
    vegetation spatial structure parameters more accurately. In addition\nto spectral\
    \ and structural parameters, adding texture features can\npotentially impact the\
    \ performance of yield prediction (Ma et al.,\n2022). However, there are no publications\
    \ investigating potato yield\nprediction with texture features extracted from\
    \ image analysis.\nIt is also difﬁcult to fully represent the crop growth status\
    \ by RS\ndata alone. Integrating RS parameters with other indicators of\nagronomy\
    \ and meteorology is an effective way to improve yield\nprediction capability.\
    \ NDVI combined with plant height provides\nimproved estimation accuracy of potato\
    \ yield compared with using\nNDVI alone (Tanabe et al., 2019). Combining soil\
    \ parameters, such\nas moisture, conductivity, and nutritional parameters, with\
    \ NDVI\nobtained from handheld instruments, potato yield was predicted by\nSupport\
    \ Vector Machine (SVM) and the determination coefﬁcient\nof different datasets\
    \ ranged from 0.54 to 0.72 (Abbas et al., 2020).\nLikewise, RS information combined\
    \ with meteorological\nparameters provides a good prediction of yield with the\n\
    determination of coefﬁcients ranging from 0.76 to 0.86 in winter\nand summer growing\
    \ seasons (Salvador et al., 2020).\nTABLE 4\nContinued\nCountry\nPlatform\nType\n\
    Platform\nModel\nSensor\nType\nSensor Model\nCultivars\nBands\nnumber\nBands\n\
    range\nParameters\nModelling\nMethod\nAccuracy\nSample\nsize\nReferences\nUnited\n\
    States\nUAV\nDJI Inspire\n2\nMS\nGEMS multispectral camera\n(Sentek Systems LLC,\n\
    Minneapolis, MN, USA)\n–\n4\nR, G, B,\nNIR\ncultivar information\nRF, SVM\nR2\
    \ = 0.75-\n0.79\n–\nLi et al., 2021\n1 MS, Multispectral; 2 HS, Hyperspectral;\
    \ 3 MCARI, Modiﬁed Chlorophyll Absorption Reﬂectance Index; 4 CI1, Red-edge Chlorophyll\
    \ Index 1; 5 CI2, Red-edge Chlorophyll Index 2; 6 OSAVI, Optimised Soil Adjusted\
    \ Vegetation Index; 7 ANTHO, Anthocyanin; 8 GNDVI,\nGreen Normalized Difference\
    \ Vegetation Index; 9 BNDVI, Blue Normalized Difference Vegetation Index; 10 CHLGR,\
    \ Chlorophyll Green; 11 SLR, Single Linear Regression; 12 MLR, Multiple Linear\
    \ Regression; 13 PLSR, Parcial Least Squares Regression; 14 RF, Random\nForest;\
    \ 15 Ridge, Ridge Regression; 16 OLS, Ordinary Least Squares; 17 SVM, Support\
    \ Vector Machine; 18 GLM, Generalised Linear Model.\nLin et al.\n10.3389/fpls.2023.1214006\n\
    Frontiers in Plant Science\nfrontiersin.org\n11\nTABLE 5 Summary of ground-based\
    \ potato yield prediction.\nCountry\nPlatform\nType\nSensor\nType\nSensor Model\n\
    Cultivars\nBands\nnumber\nBands\nrange\n(nm)\nParameters\nModelling\nMethod\n\
    Accuracy\nSample\nsize\nReferences\nGermany\nHandheld\nMS1\nhand-held multi-spectral\
    \ radiometer\n(CROPSCAN, Inc.)\n–\n2\n670, 870\nLAI4, model\ninput\nparameters\n\
    assimilation of\nLAI and\nLEACHN model\nr = 0.63\n36\nFinke, 1992\nCanada\nHandheld\n\
    HS2\nFieldSpec HandHeld spectroradiometer\n(Analytical Spectral Devices [ASD]\
    \ Inc., Boulder,\nCO)\nRusset\nBurbank\n200\n325-1075\nCI15\nSLR13\nr = 0.64\n\
    40\nMorier et al.,\n2015\nUnited\nStates\nHandheld\nMS\nGreenSeeker™ (Trimble\
    \ Navigation Limited,\nSunnyvale, CA, USA);\nHolland Scientiﬁc Crop Circle™ ACS\
    \ 430\n(Holland Scientiﬁc, Inc., Lincoln, NE, USA)\nRusset\nBurbank\nGreenSeeker:\n\
    2;\nCrop Circle:\n3\nGreenSeeker:\n660, 770;\nCrop Circle:\n650, 730, 760\nNDVI6,\n\
    proprietor-\nproxy LAI\nnonlinear\nregression\nR2\n(GreenSeeker)\n= 0.60;\nR2\
    \ (Crop\nCircle) = 0.64\n144\nSharma et al.,\n2017\nUnited\nStates\nHandheld\n\
    MS\nGreenSeeker™;Holland Scientiﬁc Crop Circle™\nACS 430\nRusset\nBurbank,\nShepody,\n\
    Superior\nGreenSeeker:\n2;\nCrop Circle:\n3\nGreenSeeker:\n660, 770;\nCrop Circle:\n\
    650, 730, 760\nNDVI;\nNDVI, NDRE7,\nCHLRE8, LAI\nnonlinear\nregression\nR2\nadj\n\
    (GreenSeeker)\n= 0.57;\nR2\nadj\n(GreenSeeker)\n= 0.36\n288\nJasim et al.,\n2020\n\
    China\nHandheld\nHS\nUSB 2000 spectrometer (Ocean Optics, Inc.,\nDunedin, Florida,\
    \ United States)\nShepody\n1630\n350-1100\nOCW-based CI\nSLR\nR2 = 0.8225;\nRMSE\
    \ =\n0.2257\n27\nLuo et al.,\n2020\nCanada\nHandheld\nMS\nFieldScout CM 1000 NDVI\n\
    Meter (Spectrum Technologies, Aurora, USA)\nRusset\nBurbank\n2\n660, 840\nNDVI,\
    \ soil data\nSLR; EN14; k-\nNN15; SVM16\nR2 (SVR) =\n0.54-0.72;\nR2 (SLR) =\n\
    0.53-0.70;\nR2 (EN) =\n0.49-0.64;\nR2 (k-NN) =\n0.53-0.64\n479\nAbbas et al.,\n\
    2020\nEgypt\nHandheld\nThermal,\nRGB3\nhandheld infrared thermal camera (Ti-32;\
    \ Fluke\nThermography, Glottertal, Germany);\n14-megapixel digital camera (Kodak\
    \ D5100\nreﬂex; Tokyo, Japan)\nBellini,\nArizona\n–\n7500-14000,\n400-700\ncolor\
    \ Indices,\nNRTC10\nSMLR17;\nANFIS18-GA19\nR2 (SMLR) =\n0.73;\nR2 (ANFIS-\nGA)\
    \ = 0.80\n48\nElsayed et al.,\n2021\nPeru\nHandheld\nThermal,\nRGB\nFLIR thermal\
    \ camera (Model E60, FLIR Systems\nInc., Täby, Sweden); digital camera D5300\n\
    (Nikon, Thailand)\nUnica\n–\n7500-13000,\n400-700\nCC11, dT12,\nmodel input\n\
    parameters\nassimilation of dT\nand SOLANUM\nmodel\nR2 = 0.91-0.99\n8\nNinanya\n\
    et al., 2021\n1 MS, Multispectral; 2 HS, Hyperspectral; 3 RGB, red-green-blue;\
    \ 4 LAI, Leaf Area Index; 5 CI1, Red-edge Chlorophyll Index 1; 6 NDVI, Normalized\
    \ Difference Vegetation Index; 7 NDRE, Normalized Difference Red-edge; 8 CHLRE,\
    \ Chlorophyll Red-edge; 9 OCW, Optimal\nCombination Weighting Method; 10 NRTC,\
    \ Normalized Relative Canopy Temperature; 11 CC, Canopy Cover; 12 dT, Canopy temperature\
    \ minus air temperature; 13 SLR, Single Linear Regression; 14 EN, Elastic Net;\
    \ 15 k-NN, k-nearest neighbor; 16 SVM, Support Vector\nMachine; 17 SMLR, Stepwise\
    \ Multiple Linear Regression; 17 ANFIS, Adaptive Neuro-fuzzy Inference System;\
    \ 19 GA, Genetic Algorithm.\nLin et al.\n10.3389/fpls.2023.1214006\nFrontiers\
    \ in Plant Science\nfrontiersin.org\n12\n3.3 Evolution of RS-based yield\nprediction\
    \ methods\nEmpirical modeling methods, such as Simple Linear Regression\n(SLR),\
    \ Multiple Linear Regression (MLR), and Artiﬁcial Neural\nNetwork (ANN), are mostly\
    \ used for current RS-based potato yield\nprediction. LR clearly shows the relationship\
    \ between one or more\nexplanatory variables and yield. SLR can build a linear\
    \ relationship\nbetween a single parameter and the yield. Introducing more\nvariables\
    \ including VIs, agronomic parameters, and meteorology\nby MLR can improve model\
    \ performance. However, since the\nrelationship between the variables of the dataset\
    \ is not linear in\nmost real-life scenarios, a non-linear approach is necessary.\n\
    With the development of artiﬁcial intelligence (AI), ML models\nhave been increasingly\
    \ applied to RS-based potato yield prediction.\nAn ANN model was constructed with\
    \ variables including\nVegetation Condition Index (VCI) and Temperature Condition\n\
    Index (TCI) captured by NOAA-AVHRR between 1980-2014\n(Akhand et al., 2016). Percentage\
    \ error was calculated as lower\nthan 10% to quantify the difference between actual\
    \ and predicted\nyield. In addition, there are signiﬁcant differences in prediction\n\
    accuracy between various ML algorithms. Six ML algorithms\n(PLSR, Parcial Least\
    \ Squares Regression; RF, Random Forest;\nRidge, Ridge Regression; OLS, Ordinary\
    \ Least Squares; SVM,\nSupport Vector Machine; GLM: Generalised Linear Model)\
    \ were\ncompared for potato yield prediction at different irrigation levels\n\
    using a Headwall nano-hyperspec imager, and ridge regression\nshowed the highest\
    \ accuracy with R2 of 0.63 (Sun et al., 2020).\nYield prediction performance of\
    \ several ML algorithms were\ncompared using Sentinel-2 images and svmRadial got\
    \ the highest\naccuracy (R2 = 0.93) (Gómez et al., 2019). It is also worth noting\n\
    that varietal differences can signiﬁcantly impact predicted results.\nML combined\
    \ with cultivar information and UAV-based images\nwas used to improve potato yield\
    \ prediction (Li et al., 2021). The\nresults showed that RF and SVM models using\
    \ only RS data yield\npoor estimation (R2 = 0.48-0.51) but had signiﬁcantly improved\n\
    performance (R2 = 0.75-0.79) when variety information was\nincluded. The use of\
    \ ML algorithms combined with high spatial\nresolution images and cultivar information\
    \ can signiﬁcantly\nimprove yield prediction for different potato varieties than\n\
    approaches without variety information.\nThe AlexNet algorithm, proposed in 2012\
    \ as the ﬁrst deep\nlearning (DL) model, generates both low- and high-level features\
    \ of\ndata through a multilayer neural network as the input of fully\nconnected\
    \ layers before a classiﬁcation task (Krizhevsky et al.,\n2017). Compared to conventional\
    \ ML with handcrafted features,\nwhich reaches a bottleneck in model performance\
    \ with increasing\nthe size of training dataset, DL can further improve model\n\
    performance by enlarging the training dataset due to the huge\namount of generated\
    \ features. The performance of MLR and\nAlexNet to assess potato yield was compared\
    \ and concluded that\nthe DL algorithm was superior (Tanabe et al., 2019). However,\
    \ the\naccuracy of the proposed model was still not high enough to meet\nthe requirement\
    \ in practice, which encouraged the investigation of\nmore complex DL networks.\
    \ With the rapid development of DL,\nother networks including LSTM have been widely\
    \ applied in yield\nprediction in recent years (Muruganantham et al., 2022). Many\
    \ DL-\nbased studies have been conducted in other crops (Tian et al., 2021;\n\
    Liu et al., 2022). However, there is still a lack of application of such\nDL methods\
    \ applied to potato yield prediction.\nDifferent from the empirical models that\
    \ do not have a complete\nmechanism of crop development, the physical model of\
    \ RS\nconsidering spectra, radiation, and scattering, are deterministic\nbased\
    \ on the laws of physics. The PROSAIL, a combination of\nPROSPECT (leaf optical\
    \ PROperties SPECTra model) and SAIL\n(Scattering by Arbitrarily Inclined Leaves\
    \ model), considering leaf\nangle, canopy structure and biochemical properties\
    \ of vegetation is\nwidely used for to estimate chlorophyll content, LAI and biomass\n\
    (Berger et al., 2018). A mechanistic physical model, such as the\nradiative transfer\
    \ model, requires a thorough understanding of\nvegetation structure characteristics\
    \ and radiative transfer theory.\nProbably due to high complexity of the models,\
    \ physical models\nhave not yet been applied to potato yield prediction.\nCompared\
    \ with the mechanistic models based on RS, the semi-\nempirical models allow a\
    \ compromise by estimating intermediate\nvariables or simplifying the model. The\
    \ commonly used semi-\nempirical approach is the light use efﬁciency (LUE) model,\
    \ which\ncalculates dry matter yield by estimating total primary productivity\n\
    and combining it with harvest index (Monteith, 1972). According to\nthe principle\
    \ of assimilates accumulation and distribution, yield\ncould be calculated as\
    \ the product of photosynthetically active\nradiation (PAR), fraction of absorbed\
    \ PAR (FPAR), LUE, and\nharvest index (HI). Calculation formula is shown below:\n\
    Yield = PAR \x01 FPAR \x01 LUE \x01 HI\n4 Crop growth model for potato\nyield\
    \ prediction\nCGM delineate crop growth and development as a function of\nenvironmental\
    \ factors, such as climatic, soil, and management\nparameters, predicated upon\
    \ the physiological and ecological\ntenets of crops (Raymundo et al., 2014). The\
    \ mechanistic\nsimulation of potato development is an efﬁcacious tool for\npredicting\
    \ potato yield.\n4.1 Evolution of potato CGM\nThe potato growth model has evolved\
    \ from establishing\nfundamental principles to widespread application and continuous\n\
    optimization. The original CGM was established by de Wit at\nWageningen University\
    \ during the 1960s (Bouman et al., 1996).\nDevelopment of potato CGM began in\
    \ the late 1970s when\nresearchers designed a model based on physiological\ncharacteristics\
    \ and ﬁeld experiments. During this stage, the model\nsimulated the accumulation\
    \ and distribution of assimilates through\npotential light and thermal conditions,\
    \ thereby simulating the\nprocess of potato yield formation. A simulation of potato\
    \ growth\nLin et al.\n10.3389/fpls.2023.1214006\nFrontiers in Plant Science\n\
    frontiersin.org\n13\nwas conducted by utilizing temperature, photoperiod, and\
    \ soil\nmoisture during speciﬁc time intervals (Sands et al., 1979). Light\ninterception\
    \ calculated from canopy cover was used to estimate\npotential potato yield (Van\
    \ der Zaag, 1984). Similarly, it was posited\nthat fundamental data such as the\
    \ time of sowing and harvest, soil\nand air temperature, and solar radiation can\
    \ be used to estimate the\nmaximum dry matter yield of potatoes (Marshall et al.,\
    \ 1984). The\nPOTATO model, crafted by Ng and Loomis (1984), is the pioneer\n\
    mechanistic model for comprehensively delineating the\nmorphology and physiology\
    \ of potato. During this period, models\nprimarily focused on productivity simulations\
    \ without considering\nthe effects of environmental stress on actual yield.\n\
    In the 1990s, soil water and nitrogen dynamic modules were\nsuccessively incorporated\
    \ into potato CGM. For instance,\nSUBSTOR-potato (Grifﬁn et al., 1993), a sub-module\
    \ of DSSAT,\nis utilized to simulate potato growth, with its water and nitrogen\n\
    dynamics module derived from CERES (Crop Environment\nResearch Synthesis). During\
    \ the same period, numerous studies\nexplored the optimization of potato irrigation\
    \ and fertilization\nmanagement schemes using CGM. Additionally, some research\n\
    employed models to assess the impact of climate change on\npotato production.\n\
    Currently, models are being widely calibrated and validated\nacross different\
    \ regions to suit the needs of potato growth\nsimulation. Additionally, CO2 response\
    \ modules have been added\nto the CGM (Wolf, 2002), which have been extensively\
    \ used for\ndecision support and climate change response studies (Raymundo\net\
    \ al., 2018; Tang et al., 2021). The uncertainty in potato models\ncaused by model\
    \ structure, model input, and model parameters has\nalready attracted the attention\
    \ of researchers (Ojeda et al., 2020).\nThis has been extensively studied in other\
    \ crops (Bert et al., 2007;\nWang et al., 2020). In addition, CGM utilize data\
    \ of speciﬁc\nsamples, which cannot reﬂect the spatial heterogeneity of large-\n\
    scale farmland. Combination of the high-throughput and full-\ncoverage advantages\
    \ of RS with the complete mechanism of CGM\nmakes the assimilation of RS and CGM\
    \ an effective way to achieve\ncontinuous spatiotemporal monitoring of potato\
    \ growth dynamics.\nFor instance, in recent years, AquaCrop has emerged to simulate\n\
    crop yield using CC as an intermediate variable, which is closely\nrelated to\
    \ RS. However, there is still limited research on predicting\npotato yield using\
    \ assimilation techniques. Table 6 illustrates the\napplication of CGM for predicting\
    \ potato yield in recent years.\n4.2 Representative CGM\nAfter more than 40 years\
    \ of evolution, dozens of potato growth\nmodels have been built. The principles\
    \ of CGM have certain\ncommonalities. Most models include basic crop growth,\n\
    meteorology, soil, and management modules. The models also\nhave their own focuses\
    \ and have formed their own schools in\nvarious parts of the world and in different\
    \ application ﬁelds. In this\nsubsection, we will introduce some common potato\
    \ CGM and\nsystematically evaluate their applications over decades.\nThe potential\
    \ productivity of a crop can be derived by\nsimulating the net photosynthesis\
    \ and the percentage of\nassimilates apportioned to the tubers (Weir et al., 1984).\
    \ Multiple\nCGM employ this underlying principle while integrating\nenvironmental\
    \ modules such as soil and climate to simulate yield.\nAmong the early potato\
    \ models, POTATO stands out as a light-\ndriven model, which completely simulates\
    \ the growth and\ndevelopment of the crop. Nonetheless, this model is still an\n\
    oversimpliﬁed representation of the crop’s growth. Potato yield\nwas effectively\
    \ modeled by modifying the POTATO model through\nadjusting the photosynthetic\
    \ capacity of potatoes on cloudy days\n(Ewing et al., 1990). In contrast to POTATO,\
    \ which results in\noverestimated yields, NPOTATO offers more accurate yield\n\
    simulation (Wolf, 2002).\nSUBSTOR-Potato, a light-driven model derived from CERES,\
    \ is\na more comprehensive and widely used model. For improved\naccuracy, SUBSTOR-Potato\
    \ 2.0 added water and nitrogen\nsimulation modules (Grifﬁn et al., 1993). Over\
    \ decades of\nresearch and experimentation, researchers have identiﬁed some\n\
    shortcomings in the model. As the number of studies increases,\nthe model is constantly\
    \ being reﬁned. In a Canadian study,\nSUBSTOR-Potato was applied to simulate yield,\
    \ but an\nunderestimation of 15% occurred due to incorrectly simulated\nsoil moisture\
    \ content (Mahdian and Gallichand, 1997). Similarly,\nthe model predictions may\
    \ still underestimate yields under extreme\nweather conditions. Data from 87 ﬁeld\
    \ experiments was synthesized\nand it was proposed that it is necessary to improve\
    \ SUBSTOR-\nPotato to capture the effects of increased atmospheric CO2\nconcentration\
    \ and temperature rise on crop growth (Raymundo\net al., 2017). In DSSAT version\
    \ 4.7, this problem was solved by\nmodifying the response function (Raymundo et\
    \ al., 2018). However,\nthis version of DSSAT still neglects the impacts of pests\
    \ and diseases\non yield loss caused by quality degradation (Tooley et al., 2021).\n\
    LINTUL-Potato, which is based on the light interception and\nutilization model,\
    \ carefully considers the inﬂuence of temperature\nand daylength on potato yield\
    \ formation (Kooman and Haverkort,\n1995). Temperature is signiﬁcant in seedling\
    \ emergence, light\nenergy utilization, canopy morphogenesis, tuber bulking, and\n\
    yield formation, while photoperiod has a considerable effect on\nlight energy\
    \ utilization and potato tuberization (Snyder and Ewing,\n1989). By assessing\
    \ the effect of freezing on yield, the simulated\nresult of LINTUL-Potato showed\
    \ that an increase in the cold\ntolerance of potatoes from -1°C to -2°C and -3°C\
    \ led to respective\nincreases in average yield of 26% and 40% (Hijmans et al.,\
    \ 2003). In\naddition, numerous models have been derived from LINTUL-\nPotato\
    \ that are tailored to various scenarios. Van Delden et al.\n(2003) simulated\
    \ nitrogen dynamics and potato yield under\ndifferent organic nitrogen management\
    \ strategies in the\nNetherlands using LINTUL-NPOTATO. Similarly, the LINTUL-\n\
    Potato model was optimized for simulating yield of potatoes with\ndifferent genotypes\
    \ in the Andes Mountains by the International\nPotato Center (CIP). The revised\
    \ model known as SOLANUM\n(Condori et al., 2010) showed acceptable results (R2>0.88).\n\
    LINTUL-POTATO-DSS is an enhanced version of LINTUL-\nPotato that reduces the potential\
    \ for errors during computation\nby utilizing fewer parameters (Haverkort et al.,\
    \ 2015).\nSimulating the formation and distribution of photosynthetic\nassimilation\
    \ products is essential in the CGM. Moreover, moisture\nLin et al.\n10.3389/fpls.2023.1214006\n\
    Frontiers in Plant Science\nfrontiersin.org\n14\nTABLE 6\nSummary of CGM-based\
    \ potato yield prediction.\nModel\nCountry\nTesting\ntime\nVarieties\nSites\n\
    Accuracy\nSample\nsize\nReferences\nAPSIM-Potato\nAustralia\n2012/13\nRusset Burbank,\n\
    Moonlight\n2\nNRMSE = 15.4%\n–\nBorus et al., 2018\nAPSIM-Potato\nChina\n1986-2020\n\
    –\n1\nR2 = 0.92,\nNRMSE =\n14.48%\n10\nLuo et al., 2022\nAquacrop\nArgentina\n\
    2009-2010\nSpunta\n1\nR2 = 0.56\n25\nCasa et al., 2013\nAquaCrop\nDenmark\n2013-2015\n\
    Folva\n1\nR2 = 0.63-0.98,\nNRMSE = 7.3-\n21%\n–\nRazzaghi et al.,\n2017\nAquaCrop\n\
    Ethiopia\n2012\nJalene\n2\nE = 0.84-0.96,\nNRMSE=3.49-8%\n–\nYibrah et al.,\n\
    2015\nAquaCrop\nIran\n2010\nKuzima\n1\nR2 = 0.9, NRMSE\n= 9.21%\n–\nAfshar et\
    \ al.,\n2014\nCropSystVB-CSPotato\nUnited States\n2001-2002\nRanger Russet\n1\n\
    –\n–\nAlva, 2010\nDaisy\nPoland\n2000-2006\nTriada\n1\nRRMSE = 15.4%\n–\nMazurczyk\
    \ et al.,\n2007\nHamer-model\nUnited Kingdom\n3-15 years\n–\n5\naverage error\
    \ %\n= 15.8\n115\nEjieji and\nGowing, 2000\nInfocrop-potato\nIndia\n8-18 years\n\
    –\n2\nNRMSE = 8-10%\n–\nGovindakrishnan\net al., 2007\nLINTUL-NPOTATO\nNetherlands\n\
    1996-1999\nEersteling, Bintje,\nJunior, Agria\n2\nR2 = 0.865,\nRMSE = 1.08 Mg\n\
    ha-1\n18\nVan Delden\net al., 2003\nLINTUL-POTATO-DSS\nSouth Africa\n2013-2014\n\
    Innovator\n10\nR2 = 0.939, 0.635\n6, 9\nMachakaire et al.,\n2016\nLPOTCO\nIreland,\
    \ Germany,\nSweden, Finland, UK,\nBelgium, Italy\n1998-1999\nBintje\n20\nR2 =\
    \ 0.65\n–\nWolf, 2002\nMacKerron and Waister (1985)\nmodel, Versteeg and Van Keulen\n\
    (1986) model\nIndia\n1992/1993\nKufri\nChandermukhi\n1\nerror % = 4.1-\n25.7%\n\
    2\nPrihar et al., 1995\nMoDrY\nPoland\n1971-1996\n(excluding\n1984)\n–\n1\nR2\
    \ = 0.64, MRE\n= 12.40%\n25\nZyromski et al.,\n2013\nSands-model\nAustralia\n\
    –\nExton, Sebago,\nKennebec,\nDelaware, Sequoia\n9\n–\n–\nHackett et al.,\n1979\n\
    SSM-iCrop2\nIran\n2017-2018\nSante, Arinda,\nAgria, Marfona\n4\nr = 0.80, RMSE\
    \ =\n543 g m−2\n20\nDadrasi et al.,\n2020\nSUBSTOR-Potato\nArgentina\n1979-1983,\n\
    1987-1991\nHuinkul,\nKennebec, Mailen\nand Spunta\n4\nR2 = 0.915\n24\nTravasso\
    \ et al.,\n1996\nSUBSTOR-Potato\nCanada\n1992-1993\nKennebec\n8, 12\nerror % =\
    \ 4-15%\n–\nMahdian and\nGallichand, 1997\nSUBSTOR-Potato\nCzech\n1994-2002\n\
    Rosara\n1\nR2 = 0.97 (4\nyears)\n4\nŠťastná et al.,\n2010\nSUBSTOR-Potato\n\
    Uganda, Burundi, Peru,\nIndia, USA\n1980, 2002-\n2010\nAsante, Amarilis,\nKufri\
    \ Bahar,\nKathadin\n5\nRRMSE = 28.1%\n26\nKleinwechter\net al., 2016\nSUBSTOR-Potato,\
    \ AquaCrop\nChina\n2018-2019\nZihuabai\n1\nDM: R2 = 0.37-\n0.68; FM:\nR2 = 0.37-0.72\n\
    12\nWang et al., 2023\nLin et al.\n10.3389/fpls.2023.1214006\nFrontiers in Plant\
    \ Science\nfrontiersin.org\n15\ndynamics are critical in determining potato yield.\
    \ Some models\nutilize the transpiration or evapotranspiration of the crop or\
    \ soil as\na driver to simulate crop growth and yield formation processes.\nThese\
    \ water-driven models can assist in the development of rational\nirrigation practices\
    \ for efﬁcient utilization of limited water\nresources. The AquaCrop model (Steduto\
    \ et al., 2009), developed\nby the Food and Agriculture Organization (FAO) of\
    \ the UN, is an\nexample of a water-driven model that calculates biomass as the\n\
    product of water productivity (WP) and cumulative\nevapotranspiration, multiplied\
    \ by a harvest index to determine\nyield:\nYield = B \x01 HI = WP \x01oTr \x01\
    \ HI\nwhere Y is ﬁnal crop yield (kg·m-2), B is biomass (kg·m-2), HI is\nharvest\
    \ index (%), Tr is transpiration (mm), and WP is water\nproduction efﬁciency (kg·m-2·mm-1).\n\
    Compared to other models that require numerous input\nparameters, the AquaCrop\
    \ model is relatively simple and\ndemands fewer input parameters. Furthermore,\
    \ AquaCrop\nemploys CC rather than LAI to depict the canopy structure,\nwhich\
    \ allows for direct use of RS data with this model (Steduto\net al., 2009; Sun\
    \ et al., 2017). AquaCrop was employed to achieve\nbetter simulation results for\
    \ potato tuber yield under varying\nirrigation conditions (R2 = 0.98, NRMSE=0.046)\
    \ (Razzaghi et al.,\n2017). However, it should be noted that AquaCrop demonstrated\n\
    limited efﬁcacy in simulating each indicator at higher or lower\nirrigation levels\
    \ (Jin et al., 2019).\nAnother class of water-driven model integrates a CGM with\
    \ a\nhydrological model to describe the impacts of alterations in crop\nwater\
    \ management on potato respiration and yield. A combined\nSWAP-WOFOST model was\
    \ employed to evaluate productivity\nand recommended the inclusion of capillary\
    \ rise and recirculation\nin the model to enhance the precision of potato yield\
    \ prediction\n(Kroes et al., 2018).\nThe improvement of crop yields is heavily\
    \ reliant on the use of\nfertilizers, particularly nitrogen fertilizers. Nonetheless,\
    \ excessive\nnitrogen application can inﬂate production costs, harm the\nenvironment,\
    \ and pose risks to human health (Zhang et al.,\n2015). Precise management of\
    \ nitrogen fertilizer can diminish\npollution while also reducing expenses. Researchers\
    \ recognized\nthe signiﬁcance of accurate nitrogen management several decades\n\
    ago and integrated a nitrogen simulation module into the potato\nmodel. DAISY,\
    \ a one-dimensional soil-plant-atmosphere system\nmodel, can simulate crop production,\
    \ soil water balance, carbon\nand nitrogen cycles, and so on (Plauborg et al.,\
    \ 2022). DAISY was\nemployed to simulate root abscisic acid (ABA) synthesis, stomatal\n\
    conductance, transpiration and yield under water-saving irrigation\nconditions\
    \ in potato crops (Plauborg et al., 2010). Potato yield\nunder different split-N\
    \ fertigation regimes was simulated and it was\nobserved that prolonged N fertigation\
    \ consistently increased yield\n(Zhou et al., 2018).\nThe APSIM-Potato model is\
    \ part of the Agricultural Production\nSystem Simulator Next Generation (APSIM)\
    \ family. APSIM\nsimulates potato development and yield formation based on\nradiation,\
    \ temperature, photoperiod, soil water, and nitrogen\nbalance in daily increments\
    \ (Keating et al., 2003). Many studies\nconducted in Australia and China have\
    \ focused on water, nitrogen,\nsowing management, and strategies for coping with\
    \ climate change\n(Tang et al., 2021; Li et al., 2022). APSIM-Potato, however,\
    \ requires\nadditional parameters to improve model performance (Borus\net al.,\
    \ 2018).\nThe World Food Studies (WOFOST) model, developed based\non the SUCROS\
    \ model from Wageningen University, incorporates\nwater and soil simulation modules\
    \ to primarily simulate regional-\nscale crop growth and yield changes (Van Diepen\
    \ et al., 1989). A\nstudy that simulated the yield of early potatoes under water-limited\n\
    conditions indicated that simulation results of WOFOST are\nsensitive to water\
    \ deﬁcits (Kulig et al., 2020). Subsequent versions\nof WOFOST have included a\
    \ CO2 response module to better\nsimulate the effects of climate change on potato\
    \ yields.\n4.3 Assimilation methods\nThe utilization of RS technology enables\
    \ high-throughput and\nnon-destructive acquisition of crop phenotype data in the\
    \ ﬁeld.\nHowever, it falls short in simulating the crop yield formation\nprocess\
    \ and lacks a strong mechanistic foundation. Mechanistic\nCGM simulate crop growth\
    \ and development as well as yield\nformation processes, but they use speciﬁc\
    \ samples, an aspect that\nis lacking in spatial expansion. The assimilation of\
    \ RS and CGM can\nleverage the advantages of both to enhance the prediction accuracy\n\
    of various crop canopy state variables and yields at regional and\nnational scales.\
    \ Despite several studies being conducted on RS and\nCGM assimilation for other\
    \ crops, limited research has been\nconducted in potato. LAI acquired by Gaofen-1\
    \ (GF-1) satellite\ndata was employed as the assimilated variable coupled with\
    \ DSSAT-\nSUBSTOR with the SCE-UA optimization algorithm for regional\npotato\
    \ yield prediction (Duan, 2019). The mean relative error\n(MRE) was only 6.17%,\
    \ 9.45% lower than that of unassimilated\nRS data. Quiroz et al. (2017) estimated\
    \ single-point potato yield\nusing CC and the weighted difference vegetation index\
    \ (WDVI)\ncorrected crop growth model SOLANUM. Current data\nassimilation algorithms\
    \ such as Ensemble Kalman Filter (EnKF)\nand Four-Dimensional Variational Data\
    \ Assimilation (4DVAR),\nhave emerged, which could lead to further research progress\
    \ in\nassimilation studies of RS and CGM. Due to the lack of application\nof assimilation\
    \ methods, the technical gaps might increase between\nyield prediction of potato\
    \ and other crops.\n5 Methods based on yield\nlimiting factor\nIn the past, agronomists\
    \ predicted potato yields by the “visual\nmethod” using basic conditions of local\
    \ agricultural production and\nthe growth of potatoes. Considering the impact\
    \ of yield-enhancing\ntechnical measures and the yearly climate on yields, they\
    \ assessed\npotato yields per unit area visually and by experience. However, this\n\
    method relies on the investigators’ experience with crop growth and\nLin et al.\n\
    10.3389/fpls.2023.1214006\nFrontiers in Plant Science\nfrontiersin.org\n16\ndevelopment\
    \ patterns and yield formation rules, which is highly\nsubjective. When new situations\
    \ arise, such as the adoption of new\ntechnologies, the promotion of superior\
    \ varieties, or when crops\nsuffer severe losses due to abnormal disasters, the\
    \ judgment of crop\ngrowth status often exceeds the investigators’ experience.\
    \ This\nmethod thus often results in large errors in yield estimates and is\n\
    rarely used in current agricultural production. Instead, quantitative\nyield estimation\
    \ models based on LFs have become an important\nmethod for predicting potato yields.\n\
    5.1 Agronomic parameters-based methods\nMethods employing traditional agronomic\
    \ parameters were\napplied in potato yield prediction before the advent of RS\
    \ and\nCGM. Earlier studies destructively sampled tubers to record potato\nweight\
    \ and number of potatoes to estimate yield directly (Dyke and\nAvis, 1953). In\
    \ addition, canopy parameters could be linked to yield\nby reﬂecting the growth\
    \ status. The ﬁrst category is structure\nindicators that can directly reﬂect\
    \ photosynthetic capacity, such\nas LAI and leaf number. At the canopy structure\
    \ level, planting\ndensity and number of leaves were used as yield indicators\
    \ and\nachieved a reduction of mean squared error (MSE) of 9% (Singh\net al.,\
    \ 2020). In addition, some physiological and biochemical\nindicators have been\
    \ adopted. The highest correlation between\nyield and chlorophyll content (expressed\
    \ as SPAD) has been\nrevealed with an R2 value of 0.663 (Meng et al., 2021). The\n\
    nutritional status of the 4th leaf, as measured by the Mg DRIS\nindex (Mgi) and\
    \ N DRIS index (Ni) during the onset of\ntuberization, have demonstrated potential\
    \ as yield predictors.\nMoreover, N content in stems has shown a strong correlation\n\
    with marketable tuber yield (MTY), while the Ca:N ratio in stems\nhas displayed\
    \ the highest correlation with MTY.\nTraditional regression methods often have\
    \ inadequate\nsimulation performance, while some innovative methods provide\n\
    better prediction results. For instance, a Canadian study\ndemonstrated that using\
    \ a three-input multiple-layer perceptron\n(MLP) network with cumulative LAI,\
    \ maximum LAI, and\ncumulative rainfall achieved a higher accuracy in yield estimation\n\
    than MLR and SUBSTOR (Fortin et al., 2011).\nMethods based on agronomic parameters\
    \ often require tedious\nﬁeld sampling. In addition to the plant itself, environmental\
    \ and\nmanagement factors, among others, can affect yield. Therefore, the\nability\
    \ of a method to simulate different cultivation and\nmanagement conditions varies.\n\
    5.2 Environmental parameters-\nbased methods\nEnvironmental factors affecting\
    \ crop growth, such as\nmeteorology, soil, pests, and diseases, could be considered\
    \ yield\nindicators. The concept of using meteorological data to replace\ndestructive\
    \ sampling for predicting potato yield was proposed in a\nreport in 1929 by an\
    \ unknown author in the American Potato\nJournal. In addition, the agro-ecological\
    \ zone (AEZ) model, jointly\ndeveloped by the FAO of the UN and the International\
    \ Institute for\nApplied Systems Analysis (IIASA), predicted the yield potential\
    \ of\ndifferent potato farming areas based on statistical data in China\nfrom\
    \ 1961 to 1997 (Cai et al., 2006). In a study examining the\nrelationship between\
    \ meteorology and yield variability over\nmultiple years, models were constructed\
    \ with 35 years of data\nbased on MLR, stepwise regression, and BP neural networks,\
    \ with\nMREs of 6.715%, 7.811%, and 4.479% (Yang S. et al., 2017).\nPiekutowska\
    \ et al. (2021) constructed MLR and ANN models\nusing yield data and meteorological\
    \ and management data from\n2010 to 2017, with the ANN model estimating potato\
    \ yield more\naccurately (R2 = 0.86).\nFurthermore, soil indicators have been\
    \ utilized as predictors of\npotato yield in some studies. For instance, ANN and\
    \ MLR models\nwere constructed that incorporated soil inﬁltration resistance,\n\
    organic matter, microbial load, and tillage system, resulting in\nsuperior prediction\
    \ of potato yield, with R2 values of 0.951 and\n0.894, respectively (Abrougui\
    \ et al., 2019). Yield was simulated\nbased on soil apparent conductivity and\
    \ achieved an R2 between\n0.57 and 0.66 (Frąckowiak et al., 2020). However, yield\
    \ loss due to\npests and diseases also constitutes an essential component of yield\n\
    prediction theory. It was reported that the rate of yield loss caused\nby 64 potato\
    \ cyst nematode eggs per gram of soil ranged from 8.5%\nto 56% and 9% to 58%,\
    \ for two experimental sites (Hajihassani\net al., 2013).\nSeveral environmental\
    \ indicators can be used as yield indicators\nbecause their variability greatly\
    \ affects potato yield. However, as\nwith methods based on agronomic parameters,\
    \ these methods do\nnot reﬂect the full range of potato yield formation.\n5.3\
    \ Input-output model\nThe approach based on input-output theory considers various\n\
    agricultural inputs, including human labor, energy, fertilizer,\nirrigation, pesticides,\
    \ and so on (Chen and Wang, 2010). Some of\nthe input-output model for yield prediction\
    \ were developed by\nquantifying the effects of different energy inputs on yield\
    \ by\ncombining economic mathematical models such as the Cobb-\nDouglas function.\
    \ Potato production was estimated in Iran using\ninput-output theory combined\
    \ with ANN and ANFIS, with\ncorrelation coefﬁcients of 0.925 and 0.987, respectively\n\
    (Khoshnevisan et al., 2014). Farm potato production was\ncompared in Iran combined\
    \ with various inputs, such as\nmanpower, machinery, diesel, fertilizer, farmyard\
    \ manure,\npesticides, electricity, irrigation water, and seeds (Hamedani et al.,\n\
    2015). In addition, empirical statistical models consider the yield of\nprevious\
    \ years as a crucial indicator for yield estimation.\nThis type of model generally\
    \ employs a questionnaire to acquire\nthe different forms of energy inputs. However,\
    \ the most signiﬁcant\naspect of questionnaire approach might be the representativeness\
    \ of\nthe respondents and the authenticity of the survey data.\nAdditionally,\
    \ there are some differences in total energy\nconsumption and potato yield among\
    \ various production models\n(Al-Hamed and Wahby, 2016). For instance, the energy\
    \ ratio,\nenergy productivity, and net energy of large-scale farms (>3 ha)\nLin\
    \ et al.\n10.3389/fpls.2023.1214006\nFrontiers in Plant Science\nfrontiersin.org\n\
    17\nwere considerably higher than those of smaller farms\n(Khoshnevisan et al.,\
    \ 2014). These factors constrain the\napplicability of prediction methods at different\
    \ scales.\n6 Discussion\nThis study revealed the research progress of estimating\
    \ potato\nyield since 1953. A systematic review of different methods provides\n\
    an important reference for understanding potato yield prediction\napplications.\
    \ In this section, application scenarios, and advantages\nand disadvantages of\
    \ various methods are systematically discussed.\nAdditionally, the trend of potato\
    \ yield prediction is prospected.\n6.1 Application scenarios for\nyield prediction\n\
    Different application scenarios necessitate the use of matching\nyield prediction\
    \ methods. Yield prediction could be used to create\nmaps of potato yield layout\
    \ in various regions and to identify the\nmost suitable planting areas within\
    \ the planting structure layout.\nPrecise pre-harvest yield prediction at the\
    \ international trade level is\nbeneﬁcial for early adjustment of trade policies\
    \ to manage evolving\ninternational trade dynamics. Furthermore, in large-scale\
    \ potato\nproduction, pre-harvest yield estimation enables development of\ntimely\
    \ marketing and storage plans to ensure economic beneﬁts.\nWe present several\
    \ application scenarios and discuss the applicable\nyield prediction methods below.\n\
    6.1.1 Optimal allocation of resources\nPotato yield forecasts at the regional\
    \ and national level can\nsupport decision-making in planning growing areas and\n\
    international trade. Satellite RS is the most intuitive and effective\nmethod\
    \ to meet these demands because it can monitor the extent of\npotato cultivation\
    \ over large areas while obtaining various\nparameters for assessing vegetation\
    \ growth and predicting ﬁnal\nyields. In contrast to traditional statistical survey\
    \ methods, satellite\nRS can provide accurate and real-time maps of potato yield\n\
    distribution. Combining yield mapping for other crops and yield\nprojections for\
    \ different geographic spaces under future climate\nchange conditions can identify\
    \ more suitable planting areas for each\ncrop. The integration of satellite RS\
    \ technology and CGM can\nfacilitate the prediction of crop yields over large\
    \ areas with greater\naccuracy and precision. Satellite-based RS could predict\
    \ yield about\ntwo months before harvest to allow earlier development of trade\n\
    strategies and ensure economic development and food security.\nFrom a farm perspective,\
    \ potato yield prediction provides\ndecision support for marketing and storage\
    \ strategies. High-\nresolution satellites could be used to predict potato yield\
    \ for large\nplantings. However, it is preferable to use UAVs to acquire high-\n\
    resolution image data for slightly smaller farmlands. Companies in\nsmart agriculture\
    \ could provide these special services. In addition,\nlong-term yield forecasting\
    \ services, such as MARS Crop Yield\nForecasting System (MCYFS), are necessary\
    \ for all stakeholders.\n6.1.2 Precision management\nEstimating potential yield\
    \ through crop models and simulating\npotato productivity under different environmental\
    \ conditions can\noffer suggestions to potato farmers to reduce yield differentials,\
    \ such\nas implementing better management strategies for irrigation,\nfertilization,\
    \ and sowing period (Deguchi et al., 2016; Li et al.,\n2022). UAV RS provides\
    \ a fast and non-destructive way to access\nﬁeld phenotypes and is an important\
    \ tool for decision support in\nﬁeld management. Various yield estimation models\
    \ can also be\nintegrated with intelligent management systems to achieve accurate\n\
    ﬁeld management.\nThe image processing and model building for UAV remote\nsensing\
    \ and CGM can be challenging and require specialized skills.\nHowever, many growers\
    \ may not have the necessary professional\nbackground to conduct yield prediction\
    \ using these methods. To\naddress this issue, smart agriculture companies with\
    \ expertise can\nprovide data collection, analysis, and integrated delivery services.\n\
    For instance, a user interface based on the input-output model was\ndeveloped\
    \ using C-sharp that enables direct potato yield prediction\n(Al-Hamed and Wahby,\
    \ 2016). In addition, the CGM could provide\ndecision support for precision management\
    \ by simulating the\npotato growth process under different management and climate\n\
    conditions. However, it is still necessary to use different varieties to\ncalibrate\
    \ CGM in different regions. Due to the complexity of CGM,\nsome simpliﬁed models,\
    \ such as AquaCrop, might be suitable.\nAs smartphones become more prevalent,\
    \ one approach to site-\nspeciﬁc yield forecasting is to deliver dependable yield\
    \ projections\nand decision-making support by incorporating multiple sources of\n\
    big data into mobile devices and designing an intuitive user\ninterface for potato\
    \ farmers. It is critical that the yield estimation\ntechnique is practical and\
    \ comprehensible. It should provide\nunambiguous information as accurately as\
    \ possible while\nremaining applicable to commercial farming practices. Dispelling\n\
    user misunderstandings is crucial in facilitating replication.\nConducting pilot\
    \ studies and demonstrating the effects of yield\nestimation in speciﬁc regions\
    \ is an effective means of promotion.\n6.1.3 Responding to climate change\nAssessing\
    \ the impact of climate change on potato growth and\nyield is beneﬁcial for selecting\
    \ the most suitable varieties and\nmanagement strategies under climate change\
    \ conditions.\nHowever, the impact of climate change on potato production\nvaries\
    \ due to differences in cultivation areas, growing seasons, and\ncultivation management\
    \ practices (Bender and Sentelhas, 2020;\nYagiz et al., 2020).\nThere are many\
    \ studies pointing to a possible decline in potato\nyields under future climate\
    \ change conditions. Applying future\nclimate change scenarios to current potato\
    \ cropping systems using\nan improved SUBSTOR-potato, it was pointed to a small\
    \ decline in\nglobal tuber production by 2055 (-2% to -6%) and a large decline\
    \ by\n2085 (-2% to -26%)(Raymundo et al., 2018). DSSAT was used to\nsimulate the\
    \ yields of barley and potato under future climate change\nconditions (Holden\
    \ et al., 2003). Non-irrigated potato tuber\nproduction in Ireland is projected\
    \ to decline in 2055 and 2075\ndue to water shortages. A study of yield changes\
    \ under future\nLin et al.\n10.3389/fpls.2023.1214006\nFrontiers in Plant Science\n\
    frontiersin.org\n18\nclimate change scenarios for a variety of crops in Mexico\
    \ using\nAquaCrop suggests that Mexican potato yields will decline (Arce\nRomero\
    \ et al., 2020).\nInterestingly, other studies have produced the opposite result.\n\
    The possible negative effects of increased temperatures and reduced\nwater availability\
    \ for potato are offset by the positive effects of\nincreased CO2 levels on water\
    \ use efﬁciency and crop productivity\n(Haverkort et al., 2013). By mid-century,\
    \ potato yield variability and\nproductivity will increase in Belgium with greater\
    \ variability\nbetween climate change models than spatial variability\n(Vanuytrecht\
    \ et al., 2016). The differences in prediction results\ncould be attributed to\
    \ the different CGM and study areas used in\nthese investigations. In addition,\
    \ different climate change scenarios\nalso produce different simulation results\
    \ (Pushpalatha et al., 2021).\nDespite extensive research on the impact of climate\
    \ change on\npotato yields, validation of previous climate change impact\nassessment\
    \ results on yields is still lacking.\nAccording to the prediction results, it\
    \ is possible to implement\ncorresponding countermeasures, such as changing the\
    \ planting area\nor management practices. For example, optimizing sowing and\n\
    irrigation strategies can improve agro-pastoral ecotone (APE)\npotato yield and\
    \ water productivity (Tang et al., 2018). Delayed\nsowing and selection of medium-maturing\
    \ potato varieties are\nimportant ways to cope with warm and dry climates in the\
    \ APE\nof northern China (Li et al., 2019). WOFOST has been integrated\ninto the\
    \ Crop Growth Monitoring System (CGMS) to assess the\nimpacts of climate change.\
    \ The impact of climate change on\npotential productivity of potato was studied\
    \ in West Bengal using\nthe WOFOST crop growth simulation model (Dua and Sharma,\n\
    2017). They minimized the impact of climate change by selecting\nappropriate varieties\
    \ and changing planting dates to design\nmanagement strategies.\n6.2 Comparison\
    \ of different prediction\nstrategies for predicting potato yield\nVarious prediction\
    \ methods have their own characteristics. In\nthis section, yield prediction strategies\
    \ are compared and the\nknowledge gaps between potato and other crops are presented.\n\
    6.2.1 RS-based methods\nRS-based methods could replace other destructive sampling\n\
    methods by obtaining crop phenotype through non-destructive\nmethods to build\
    \ yield prediction models. Morier et al. (2015)\ninferred nitrogen stress and\
    \ estimated potato yield combined with a\nhandheld hyperspectral sensor (FieldSpec\
    \ handheld\nspectroradiometer), which obtained similar results to destructive\n\
    methods. In addition, there are signiﬁcant variations between\ndifferent platforms\
    \ and sensors for predicting potato yield.\nSatellite RS can be used to monitor\
    \ large areas of ﬁeld with its\nwide coverage. However, the constraints of cloud\
    \ cover and revisit\ncycles might limit the availability of images. Additionally,\
    \ the low\nspatial resolution of satellite results in a blended image element\n\
    composed of soil and vegetation is challenging to process. Yield\nprediction using\
    \ satellites faces signiﬁcant challenges in many\nregions due to small plot sizes,\
    \ mixed cropping, and\nintercropping. Advanced satellites and image processing\
    \ methods\nmight solve these problems. Satellites used for potato yield\nestimation\
    \ are detailed in Table 2. Currently, satellites equipped\nwith spectral sensors\
    \ are still prevalent, and there is a lack of active\nRS satellites, such as the\
    \ C-SAR-equipped GF-3 with high\nresolution of 1 m, applied to related research.\
    \ In addition,\nhyperspectral satellites have not been applied to predict\npotato\
    \ yield.\nCompared to satellites, proximal RS is more suitable for site-\nspeciﬁc\
    \ rather than regional yield prediction. UAVs are a promising\nsolution for precision\
    \ agriculture management, given their high\nresolution, low cost, and ﬂexibility.\
    \ According to our literature\nsurvey, studies on potato estimation with UAV RS\
    \ have employed a\nvariety of sensors, but there are few applications of UAV-based\n\
    active sensors. Fixed-wing drones are also applied less in potato\nyield prediction,\
    \ although their applications in more rapid\nmonitoring of large areas of farms\
    \ cannot be ignored. Ground-\nbased RS can capture phenotypes with higher resolution.\
    \ However,\nhandheld instruments have incomplete spatial coverage and are\ntime-consuming\
    \ for sampling. Additionally, ﬁxed ground-based\nphenotyping devices have limited\
    \ coverage and come with\nhigh costs.\nPotato yield formation can be described\
    \ as the production of\nphotosynthetic assimilates multiply by the harvest index\
    \ (Khan,\n2012). The growth dynamics of the aboveground canopy can\ndirectly reﬂect\
    \ canopy light energy interception and thus affect\nthe formation of photosynthetic\
    \ assimilation products. Therefore,\nmany practical applications in the studies\
    \ we investigated have been\nconducted to predict potato yield by directly obtaining\n\
    aboveground phenotypes from passive optical sensors. However,\nthey can only obtain\
    \ information from the top of the canopy and are\nsusceptible to clouds and light.\
    \ Active sensors that used controlled\nsources of radiation, such as SAR and LiDAR,\
    \ are not affected by\nweather and clouds. Another method is to detect the underground\n\
    tubers directly by sensors with penetrating ability. Longer\nwavelengths are more\
    \ penetrating because the object absorbs less\nof the wave. There has been a study\
    \ conducted on the use of sound\nwaves for detecting sweet potatoes in sandy soil\
    \ (Iwase et al., 2015).\nHowever, the research is still in its preliminary stages.\
    \ Computed\ntomography (CT) can be used to obtain potato tuber phenotypes\nnon-destructively\
    \ using X-ray to penetrate the soil for precise yield\nprediction. Nevertheless,\
    \ CT is mostly used in indoor pot\nexperiments (Ferreira et al., 2010), and it\
    \ is difﬁcult to apply it in\nopen conditions due to the associated radiation\
    \ dangers and the\nrequirements of a receiver after penetrating the tuber. Ground\n\
    penetrating radar (GPR) is an effective means of non-destructive\ndetection of\
    \ underground targets. Although GPR is still at the\nresearch phase in the detection\
    \ of underground tubers in potato\nwith limited throughput, this type of tool\
    \ has great potential for\nfuture potato yield prediction (Cheng et al., 2022).\
    \ Currently, there\nare few studies comparing active and passive sensors for potato\n\
    yield prediction, and more research is needed to evaluate the\npredictive performance\
    \ of both.\nThere are some differences in potato RS-based yield estimation\ncompared\
    \ to other crops. For example, computer vision (CV) is\nLin et al.\n10.3389/fpls.2023.1214006\n\
    Frontiers in Plant Science\nfrontiersin.org\n19\nwidely used in intelligent yield\
    \ prediction to identify and count\nfruits for further harvesting and marketing\
    \ decisions (Ramu and\nPriyadarsini, 2021), but potato tubers located underground\
    \ are\ndifﬁcult to observe directly by conventional optical sensors.\nSound waves\
    \ and CT could obtain tuber phenotype without the\neffect of soil, but most studies\
    \ are limited to potted plants. In\ncomplex ﬁeld conditions, there is a lack of\
    \ research on obtaining\npotato tuber phenotype directly for predicting yield.\
    \ Furthermore,\nthe leaves of potatoes are compound, and the propagation path\
    \ of\nlight between the leaves is different from that of rice and other ﬁeld\n\
    crops. It is necessary to improve or establish a dedicated RS-based\nyield prediction\
    \ methods for potatoes, taking into account the\ninherent characteristics of potato.\n\
    Compared to the mechanistic model, most RS-based methods\nbuild empirical models\
    \ by observing aboveground phenotype\ndirectly. In addition, these complex relationships\
    \ between crop\ngrowth and external environmental factors, including\nmeteorological\
    \ conditions, soil nutrients, and ﬁeld management,\nremain difﬁcult to accurately\
    \ capture through RS.\nDespite signiﬁcant progress in the development of theoretical\n\
    models and operational systems for RS yield estimation, the\nlimitations of current\
    \ RS technology prevent accurate and\nquantitative reﬂection of the underlying\
    \ mechanisms of crop\ndevelopment and yield formation.\n6.2.2 CGM-based methods\n\
    CGM simulate yield with comprehensive information of\nvariety, management, meteorological\
    \ parameters, and soil. CGM\nthus have a complete mechanism to simulate the crop\
    \ growth\nprocess, which is their most signiﬁcant property. In addition,\nalong\
    \ with yield prediction, CGM can simulate other elements\nsuch as water and nitrogen\
    \ dynamics of crops to provide support for\nprecision management. Finally, combining\
    \ CGM with climate\nchange models could predict the yield potential under different\n\
    regions, cultivars, and cultivation strategies under future climate\nchange conditions\
    \ to make optimal decisions.\nHowever, most CGM make accurate simulations based\
    \ on\nnumerous input parameters, which is often difﬁcult to achieve in\npotato\
    \ production. In addition, CGM require laborious ﬁeld trials to\ncalibrate and\
    \ validate the models for different varieties in different\nregions. Somewhat\
    \ simpliﬁed CGM, such as AquaCrop and\nLINTUL-POTATO-DSS, which signiﬁcantly reduce\
    \ the number\nof input parameters, have also been developed in recent years.\n\
    Additionally, the establishment of a database platform of shared\nvariety parameters\
    \ helps to enhance the applicability of the models.\nCompared to large scale RS\
    \ methods, CGM cannot reﬂect the\nvariation of yield in different spaces by collecting\
    \ data from speciﬁc\nsamples. Assimilation of RS with CGM could extend the model\n\
    application to a regional scale. In addition, although some models\nuse a constant\
    \ HI, the effectiveness of such an approach is not\nalways satisfactory. Techniques\
    \ for assimilating external\nobservations into the model to continually adjust\
    \ certain state\nvariables and attributes can be used to enhance model\nperformance.\
    \ RS data can offer prompt updates on crop or\nenvironmental conditions, allowing\
    \ for periodic updates of model\nsimulations during the simulation process (Hao\
    \ et al., 2021).\nCurrently, DSSAT-SUBSTOR is still the most widely used\nmodel\
    \ for predicting potato yield. However, due to differences in\nthe modeling principles\
    \ of individual models, these models often\nexhibit different simulation results.\
    \ Uncertainty due to differences\nin model structure could be reduced by multi-model\
    \ ensembles\n(MME), which could improve the prediction performance\ncompared to\
    \ a single model (Martre et al., 2015).\nIn addition to yield, commercial attributes\
    \ of potato are also\nvery important. Tuber yield and tuber size (expressed as\
    \ number of\ntubers per 10 kg) were simulated using LINTUL-POTATO-DSS\n(Machakaire\
    \ et al., 2016). However, there were few studies that\nsimulated commercial indicators\
    \ such as potato tuber size.\nAdditionally, unpredictable extreme weather events\
    \ remain a\nconcern, and even with the ability to anticipate and forecast\npotential\
    \ risks, current capacity to cope with them is limited.\n6.2.3 Methods based on\
    \ yield limiting factor\nYield prediction based on physiological and biochemical\n\
    agronomic indicators, require frequent manual sampling, but\nachieving full spatial\
    \ coverage is often challenging. In addition,\nmany agronomic parameter-based\
    \ approaches employ one or a few\nparameters for empirical modeling, which might\
    \ lead to\nweaker generalizability.\nMeteorological parameter-based methods predict\
    \ potato yields\nunder speciﬁc climatic conditions, without laborious ﬁeld sampling.\n\
    However, multi-year historical yield and climate data is difﬁcult to\nobtain in\
    \ reality. As with the agronomic parameter-based approach,\nwhich employs an empirical\
    \ approach to modeling, this method\nalso oversimpliﬁes. Simulation results are\
    \ not reliable with drastic\nchanges in weather conditions. Providing farmers\
    \ with suitable\nagricultural insurance may be a way to mitigate the adverse effects\n\
    of unexpected weather conditions. With the growing scope of\nagricultural informatization,\
    \ developing a precise and\ncomprehensive agricultural information data platform\
    \ containing\na range of meteorological and yield data is crucial to achieve multi-\n\
    year yield prediction.\nYield prediction methods based on input-output theory\n\
    necessitate multiple input parameters, which are frequently\nderived from interviews\
    \ with growers. Meanwhile, farmer surveys\nare also labor-intensive. Ensuring\
    \ the accuracy of the data collected\ncan be challenging (Fermont and Benson,\
    \ 2011).\n6.3 Uncertainties of yield prediction\nUncertainty is a range centered\
    \ on the true value, and the larger\nthe range the greater the uncertainty (Lu,\
    \ 2004). Model uncertainty\nemerges due to necessary simpliﬁcation of the real\
    \ physical process.\nDifferences between the theoretical and real values due to\
    \ various\nfactors such as assumptions made during model construction,\nboundary\
    \ conditions, and the difﬁculty of reﬂecting them in\ncalculations at the current\
    \ state of technology are considered\nmodel uncertainty (Xing and Guo, 2006).\
    \ Potato yield formation\nis a complex system determined by a combination of cultivation\n\
    management practices, climatic conditions, soil conditions, and\nvarieties. The\
    \ yield simulation process could be inﬂuenced by any\nLin et al.\n10.3389/fpls.2023.1214006\n\
    Frontiers in Plant Science\nfrontiersin.org\n20\nchanges in the above conditions.\
    \ At the same time, different\nparameter selections, model inputs, and model structures\
    \ can lead\nto uncertainty when constructing potato yield prediction models. It\n\
    is important to address sources of uncertainty and improve the\nadaptability of\
    \ model prediction accuracy and prediction\nconﬁdence for accurate and reliable\
    \ potato yield prediction (Ma\net al., 2021).\nThe causes of uncertainty include\
    \ inherent limitations in\npredictability (e.g., future greenhouse gas emissions)\
    \ and\ndeﬁciencies in forecasting skills (e.g., ﬂaws in model design)\n(Challinor\
    \ et al., 2013). Model structure, inputs, and parameters\nare the three main sources\
    \ of uncertainty (Wallach et al., 2016).\nAlthough the empirical statistical model\
    \ is computationally simple,\nthere is uncertainty in the functional form and\
    \ coefﬁcients of\ndifferent modeling approaches (Wu et al., 2014). Any simple\n\
    model-based or empirical regression-based inversion is unlikely to\nproduce stable\
    \ inversion results, and accounting for errors in ground\ntruth and sensor data\
    \ can improve the estimation accuracy of the\nparameters in the model (Fermont\
    \ and Benson, 2011). The\nmechanistic model simpliﬁes the real growth state of\
    \ the crop due\nto assumptions made in the construction process, boundary\nconditions,\
    \ and the difﬁculty of responding in the calculations at\nthe current level of\
    \ technology. Therefore, the uncertainty caused by\nthe model structure needs\
    \ to be considered in yield prediction.\nMoreover, the accuracy and representativeness\
    \ of the yield\nprediction model largely depends on the accuracy of the input\n\
    data, including weather, soil, and management information. The\nuncertainty of\
    \ these input data, especially in large-scale\napplications, can lead to signiﬁcant\
    \ errors in the prediction\nresults. Therefore, it is necessary to further improve\
    \ the accuracy\nof input data acquisition and data processing methods to improve\n\
    the accuracy of yield prediction methods. In terms of RS, its\nintegration with\
    \ other methods, such as ground-based sensors\nand machine learning algorithms,\
    \ can also improve the accuracy\nand practicality of yield prediction models.\
    \ For example, RS data\nnoise and environmental stress can increase the prediction\n\
    uncertainty (Ma et al., 2021).\nUncertainty in model parameters, on the other\
    \ hand, is a bias in\nsimulation results due to deviations in the selection of\
    \ parameters.\nFor example, the impact of parameter value uncertainty on spring\n\
    wheat phenology prediction uncertainty was quantiﬁed, and the\nrelative contribution\
    \ of model structure-driven and parameter\nvalue-driven uncertainty to overall\
    \ prediction uncertainty were\nassessed (Alderman and Stanﬁll, 2017).\nFew studies\
    \ address all three sources of uncertainty\nsimultaneously. For CGM, most studies\
    \ have been devoted to the\nresolution of model input uncertainty. Sensitivity\
    \ analysis is the\nmost used uncertainty analysis method to determine which model\n\
    inputs are more important for simulation results (Matott et al.,\n2009). In addition,\
    \ other methods such as Monte Carlo analysis,\nBayesian methods, and Generalized\
    \ Likelihood Uncertainty\nEstimation (GLUE) can be used for model uncertainty\
    \ analysis.\nCurrently, most uncertainty assessments focus on the three staple\n\
    crops wheat, maize, and rice, with less research on potato. Yield\nforecasting\
    \ is the most concentrated area of uncertainty research\nbecause of its importance\
    \ and because the results are inﬂuenced by\nmany factors (Chapagain et al., 2022).\n\
    6.4 Fusing multi-source information\nThe yield estimation performance of models\
    \ with a single\nsource of estimation information are often inferior to estimation\n\
    models that combine data from multiple sources. Previous studies\nhave shown that\
    \ combining multiple image feature parameters can\nimprove yield prediction accuracy.\
    \ Incorporating various\nparameters in RS yield estimation models can improve\
    \ model\nperformance. The crop model AquaCrop was combined with an\neconomic model\
    \ for optimizing irrigation management at the farm\nlevel (Garcia-Vila and Fereres,\
    \ 2012). It is signiﬁcant to use ﬁeld\ntrials, simulations, and deep learning\
    \ models to study changing\nsowing dates to mitigate the effects of climate change\
    \ (Dewedar\net al., 2021). By combining deep learning algorithms with multi-\n\
    source imagery including LiDAR and optical sensors, crop\ndetection can be signiﬁcantly\
    \ improved (Prins and Van Niekerk,\n2020). Coupling crop models with RS data is\
    \ now a common\nmethod for yield estimation. RS images can be used to invert the\n\
    LAI and applied to the crop model. However, the inconsistent\nrelationship of\
    \ LAI with most VIs and saturation problems lead to\nuncertainty in yield estimation.\
    \ Other canopy variables, such as CC\ncan be used in the AquaCrop model (Steduto\
    \ et al., 2009) for yield\nprediction instead of LAI.\n7 Conclusion\nIn this paper,\
    \ methodologies for potato yield prediction and its\nevolution were comprehensively\
    \ reviewed. The advantages and\ndisadvantages of various strategies for potato\
    \ yield prediction\nwere compared. Moreover, the uncertainties of models and multi-\n\
    source data fusion for yield prediction were discussed, providing a\nfoundation\
    \ for future studies.\nCurrently, potato yield prediction on large farmlands\n\
    commonly employs RS and CGM. RS-based methods obtain\nfarmland image information\
    \ quickly and comprehensively by\nmaking full use of the unique advantages of\
    \ RS platforms and\nsensors, however it is difﬁcult to reﬂect the intrinsic mechanism\
    \ of\ncrop growth. CGM-based methods simulate the yield formation\nprocess of\
    \ the crop, but their operation is challenging due to the lack\nof spatial expansion.\
    \ In addition, methods based on agronomic\nparameters, meteorological parameters,\
    \ and input-output theory\nare also widely used in the ﬁeld of potato yield prediction.\n\
    With the progress in RS platforms, sensor technologies, and AI\nalgorithms, UAVs\
    \ and satellites equipped with advanced sensors\nhave become mainstream tools\
    \ for ﬁeld monitoring and yield\nprediction at regional scales, which can be used\
    \ for resource\nallocation and trade decisions. In addition, with the incorporation\n\
    of modules, including water, nitrogen, meteorology, and economics,\nmechanisms\
    \ of CGM have been more comprehensive. Combined\nwith the comparison and improvement\
    \ of multi-model ensembles,\nLin et al.\n10.3389/fpls.2023.1214006\nFrontiers\
    \ in Plant Science\nfrontiersin.org\n21\npotato models are continuously improved\
    \ in terms of\nprecision management.\nMulti-source and time-series data have great\
    \ potential for future\nyield prediction, despite the current study using a limited\
    \ number of\nvarieties and sample sizes for potato yield prediction. In the future,\n\
    it is necessary to pay attention to large time-series data studies with\nmultiple\
    \ varieties and large sample sizes.\nAuthor contributions\nYL, JL and BL conducted\
    \ the literature survey and drafted the\narticle; CB, GL, SD, YY, SL, DL and LJ\
    \ gave valuable comments to\nthe manuscript and carried out critical revisions.\
    \ JL and CB\nobtained the funding to support this study. All authors\ncontributed\
    \ to the article and approved the submitted version.\nFunding\nThis research was\
    \ supported by National Natural Science\nFoundation of China (32001485), Breeding\
    \ new varieties for\nadvantageous agricultural industries in Ningxia - Digital\
    \ breeding\nsystem for potato in China (2019NYYZ01-4) and Key scientiﬁc and\n\
    technological projects of Heilongjiang province in China\n(2021ZXJ05A05-03) awarded\
    \ to Jiangang Liu, and China\nAgriculture Research System (CARS-09-P12) awarded\
    \ to CB.\nAcknowledgments\nWe are grateful to the reviewers for their valuable\
    \ comments\nand recommendations.\nConﬂict of interest\nThe authors declare that\
    \ the research was conducted in the\nabsence of any commercial or ﬁnancial relationships\
    \ that could be\nconstrued as a potential conﬂict of interest.\nPublisher’s note\n\
    All claims expressed in this article are solely those of the authors\nand do not\
    \ necessarily represent those of their afﬁliated organizations,\nor those of the\
    \ publisher, the editors and the reviewers. Any product\nthat may be evaluated\
    \ in this article, or claim that may be made by its\nmanufacturer, is not guaranteed\
    \ or endorsed by the publisher.\nReferences\nAbbas, F., Afzaal, H., Farooque,\
    \ A. A., and Tang, S. (2020). Crop yield prediction\nthrough proximal sensing\
    \ and machine learning algorithms. Agronomy 10 (7), 1046.\ndoi: 10.3390/agronomy10071046\n\
    Abou Ali, H., Delparte, D., and Griffel, L. (2020). “From pixel to yield: Forecasting\n\
    potato productivity in Lebanon and Idaho,” in The International Archives of\n\
    Photogrammetry, Remote Sensing and Spatial Information Sciences. Eds. T. R. Jordan\n\
    and K. Schuckman (Switzerland: ISPRS), 1–7.\nAbrougui, K., Gabsi, K., Mercatoris,\
    \ B., Khemis, C., Amami, R., and Chehaibi, S.\n(2019). Prediction of organic potato\
    \ yield using tillage systems and soil properties by\nartiﬁcial neural network\
    \ (ANN) and multiple linear regressions (MLR). Soil Tillage Res.\n190, 202–208.\
    \ doi: 10.1016/j.still.2019.01.011\nAfshar, A., Afsharmanesh, G. R., Adeli, M.,\
    \ and Malekian, A. (2014). Assessment of\nAquaCrop model in the simulation of\
    \ potato yield and water use efﬁciency under\ndifferent water regimes. J. Biol.\
    \ Environ. Sci. 8 (23), 79–86.\nAghighi, H., Azadbakht, M., Ashourloo, D., Shahrabi,\
    \ H. S., and Radiom, S. (2018).\nMachine learning regression techniques for the\
    \ silage maize yield prediction using\ntime-series images of Landsat 8 OLI. IEEE\
    \ J. Sel. Top. Appl. Earth Obs. Remote Sens. 11\n(12), 4563–4577. doi: 10.1109/JSTARS.2018.2823361\n\
    Akhand, K., Nizamuddin, M., Roytman, L., and Kogan, F. (2016). “Using remote\n\
    sensing satellite data and artiﬁcial neural network for prediction of potato yield\
    \ in\nBangladesh,” in Remote Sensing and Modeling of Ecosystems for Sustainability\
    \ XIII. Eds.\nW. W. Gao and N. B. Chang (California: SPIE), 52–66.\nAlderman,\
    \ P. D., and Stanﬁll, B. (2017). Quantifying model-structure- and\nparameter-driven\
    \ uncertainties in spring wheat phenology prediction with Bayesian\nanalysis.\
    \ Eur. J. Agron. 88, 1–9. doi: 10.1016/j.eja.2016.09.016\nAl-Gaadi, K. A., Hassaballa,\
    \ A. A., Tola, E., Kayad, A. G., Madugundu, R., Alblewi,\nB., et al. (2016). Prediction\
    \ of potato crop yield using precision agriculture techniques.\nPloS One 11 (9),\
    \ e0162219. doi: 10.1371/journal.pone.0162219\nAl-Hamed, S. A., and Wahby, M.\
    \ F. (2016). Prediction of potato yield based\non energy inputs using artiﬁcial\
    \ neural networks and C-sharp under Saudi\nArabia conditions. Biosci. Biotechnol.\
    \ Res. Asia 13 (2), 631–644. doi: 10.13005/\nbbra/2079\nAlva, A. K. (2010). Enhancing\
    \ sustainable nutrient and irrigation management for\npotatoes. J. Crop Improv.\
    \ 24 (3), 281–297. doi: 10.1080/15427528.2010.487742\nAraus, J. L., and Cairns,\
    \ J. E. (2014). Field high-throughput phenotyping: the new\ncrop breeding frontier.\
    \ Trends Plant Sci. 19 (1), 52–61. doi: 10.1016/\nj.tplants.2013.09.008\nArce\
    \ Romero, A., Monterroso Rivas, A. I., Gómez Dı́az, J. D., Palacios Mendoza,\
    \ M.\nA., Navarro Salas, E. N., López Blanco, J., et al. (2020). Crop yield simulations\
    \ in\nMexican agriculture for climate change adaptation. Atmósfera 33 (3), 215–231.\n\
    doi: 10.20937/ATM.52430\nBala, S. K., and Islam, A. S. (2009). Correlation between\
    \ potato yield and MODIS-\nderived vegetation indices. Int. J. Remote Sens. 30\
    \ (10), 2491–2507. doi: 10.1080/\n01431160802552744\nBender, F. D., and Sentelhas,\
    \ P. C. (2020). Assessment of regional climate change\nimpacts on Brazilian potato\
    \ tuber yield. Int. J. Plant Prod. 14 (4), 647–661. doi: 10.1007/\ns42106-020-00111-7\n\
    Berger, K., Atzberger, C., Danner, M., D’Urso, G., Mauser, W., Vuolo, F., et al.\n\
    (2018). Evaluation of the PROSAIL model capabilities for future hyperspectral\
    \ model\nenvironments: A review study. Remote Sens. 10 (1), 85. doi: 10.3390/rs10010085\n\
    Bert, F. E., Laciana, C. E., Podestá, G. P., Satorre, E. H., and Menéndez, A.\
    \ N. (2007).\nSensitivity of CERES-Maize simulated yields to uncertainty in soil\
    \ properties and daily\nsolar radiation. Agric. Syst. 94 (2), 141–150. doi: 10.1016/j.agsy.2006.08.003\n\
    Borus, D., Parsons, D., Boersma, M., Brown, H., and Mohammed, C. (2018).\nImproving\
    \ the prediction of potato productivity: APSIM-Potato model\nparameterization\
    \ and evaluation in Tasmania, Australia. Aust. J. Crop Sci. 12 (1),\n32–43. doi:\
    \ 10.21475/ajcs.18.12.01.pne570\nBouman, B., Van Keulen, H., Van Laar, H., and\
    \ Rabbinge, R. (1996). The ‘School of\nde Wit’crop growth simulation models: a\
    \ pedigree and historical overview. Agric. Syst.\n52 (2-3), 171–198. doi: 10.1016/0308-521X(96)00011-X\n\
    Cai, C., van Velthuizen, H., Fischer, G., and Prieler, S. (2006). Analyses of\
    \ potato\nyield potential by chinese farming system zoning based on AEZ model.\
    \ Chin. Potato J.\n20 (4), 207–211. doi: 10.3969/j.issn.1672-3635.2006.04.005\n\
    Casa, A., Ovando, G., Bressanini, L., and Martinez, J. (2013). Aquacrop model\n\
    calibration in potato and its use to estimate yield variability under ﬁeld conditions.\n\
    Atmos. Clim. Sci. 3 (3), 397–407. doi: 10.4236/acs.2013.33041\nChallinor, A. J.,\
    \ Smith, M. S., and Thornton, P. (2013). Use of agro-climate\nensembles for quantifying\
    \ uncertainty and informing adaptation. Agric. For.\nMeteorol. 170, 2–7. doi:\
    \ 10.1016/j.agrformet.2012.09.007\nChapagain, R., Remenyi, T. A., Harris, R. M.\
    \ B., Mohammed, C. L., Huth, N.,\nWallach, D., et al. (2022). Decomposing crop\
    \ model uncertainty: A systematic review.\nField Crops Res. 279, 108448. doi:\
    \ 10.1016/j.fcr.2022.108448\nChen, X., and Wang, H. (2010). Some important applications\
    \ of input-occupancy-\noutput technique. Chin. J. Manage. 7 (12), 1737–1740+1748.\
    \ doi: 10.3969/j.issn.1672-\n884X.2010.12.001\nLin et al.\n10.3389/fpls.2023.1214006\n\
    Frontiers in Plant Science\nfrontiersin.org\n22\nCheng, Q., van Verre, W., Podd,\
    \ F. J., Daniels, D. J., and Peyton, A. J. (2022).\n“Ground penetrating radar\
    \ antenna alignment for potato detection,” in 2022 23rd\nInternational Radar Symposium\
    \ (IRS) (Gdansk: IEEE), 54–56.\nCondori, B., Hijmans, R. J., Quiroz, R., and Ledent,\
    \ J.-F. (2010). Quantifying the\nexpression of potato genetic diversity in the\
    \ high Andes through growth analysis and\nmodeling. Field Crops Res. 119 (1),\
    \ 135–144. doi: 10.1016/j.fcr.2010.07.003\nCooper, M., Voss-Fels, K. P., Messina,\
    \ C. D., Tang, T., and Hammer, G. L. (2021).\nTackling G× E× M interactions to\
    \ close on-farm yield-gaps: creating novel pathways\nfor crop improvement by predicting\
    \ contributions of genetics and management to crop\nproductivity. Theor. Appl.\
    \ Genet. 134, 1625–1644. doi: 10.1007/s00122-021-03812-3\nDadrasi, A., Torabi,\
    \ B., Rahimi, A., Soltani, A., and Zeinali, E. (2020).\nParameterization and evaluation\
    \ of a simple simulation model (SSM-iCrop2) for\npotato (Solanum tuberosum L.)\
    \ growth and yield in Iran. Potato Res. 63 (4), 545–\n563. doi: 10.1007/s11540-020-09456-y\n\
    Deguchi, T., Iwama, K., and Haverkort, A. J. (2016). Actual and potential yield\
    \ levels\nof potato in different production systems of Japan. Potato Res. 59 (3),\
    \ 207–225.\ndoi: 10.1007/s11540-016-9322-z\ndela Torre, D. M. G., Gao, J., and\
    \ Macinnis-Ng, C. (2021). Remote sensing-based\nestimation of rice yields using\
    \ various models: A critical review. Geo Spatial Inf. Sci. 24\n(4), 580–603. doi:\
    \ 10.1080/10095020.2021.1936656\nDewedar, O., Plauborg, F., El-Shaﬁe, A., and\
    \ Marwa, A. (2021). Response of potato\nbiomass and tuber yield under future climate\
    \ change scenarios in Egypt. J. Water Land\nDev. 49 (IV-VI), 139–150. doi: 10.24425/jwld.2021.137106\n\
    Doraiswamy, P. C., Hodges, T., and Phinney, D. E. (1979) Crop yield literature\
    \ review\nfor agristars cropscorn, soybeans, wheat, barley, sorghumrice, cotton,\
    \ and sunﬂowers.\nAvailable at: https://ntrs.nasa.gov/api/citations/19800015257/downloads/\n\
    19800015257.pdf.\nDua, V. K., and Sharma, J. (2017). Forecasting impact of climate\
    \ change on potato\nproductivity in west Bengal and adaptation strategies. Indian\
    \ J. Hortic. 74 (4), 533–540.\ndoi: 10.5958/0974-0112.2017.00103.7\nDuan, D. (2019).\
    \ Regional potato production estimation based on data assimilation of\nremote\
    \ sensing information and DSSAT-SUBSTOR model. (Beijing: Chinese Academy\nof Agricultural\
    \ Sciences).\nDyke, G. V., and Avis, P. R. D. (1953). A survey of maincrop potatoes\
    \ I. Estimates of\nyield 1948-50. J. Agric. Sci. 43 (4), 450–455. doi: 10.1017/S0021859600057920\n\
    Ejieji, C. J., and Gowing, J. W. (2000). A dynamic model for responsive scheduling\
    \ of\npotato irrigation based on simulated water-use and yield. J. Agric. Sci.\
    \ 135, 161–171.\ndoi: 10.1017/S0021859699008102\nElmetwalli, A. H., Fouda, T.\
    \ Z., and Ali, E. Y. (2014). High resolution satellite\nimagery to detect stress\
    \ in potato. Acta Hortic. 1038, 97–104. doi: 10.17660/\nActaHortic.2014.1038.10\n\
    Elsayed, S., El-Hendawy, S., Khadr, M., Elsherbiny, O., Al-Suhaibani, N., Alotaibi,\n\
    M., et al. (2021). Combining thermal and RGB imaging indices with multivariate\
    \ and\ndata-driven modeling to estimate the growth, water status, and yield of\
    \ potato under\ndifferent drip irrigation regimes. Remote Sens. 13 (9), 1679.\
    \ doi: 10.3390/rs13091679\nEwing, E. E., Heym, W. D., Batutis, E. J., Snyder,\
    \ R. G., Ben Khedher, M., Sandlan, K.\nP., et al. (1990). Modiﬁcations to the\
    \ simulation model POTATO for use in New York.\nAgric. Syst. 33 (2), 173–192.\
    \ doi: 10.1016/0308-521X(90)90079-6\nFermont, A., and Benson, T. (2011). Estimating\
    \ yield of food crops grown by\nsmallholder farmers: a review in the Uganda context.\
    \ IFPRI Discussion Papers (1097).\nFernandes, J. L., Ebecken, N. F. F., and Esquerdo,\
    \ J. C. D. M. (2017). Sugarcane yield\nprediction in Brazil using NDVI time series\
    \ and neural networks ensemble. Int. J.\nRemote Sens. 38 (16), 4631–4644. doi:\
    \ 10.1080/01431161.2017.1325531\nFerreira, S. J., Senning, M., Sonnewald, S.,\
    \ Keßling, P.-M., Goldstein, R., and\nSonnewald, U. (2010). Comparative transcriptome\
    \ analysis coupled to X-ray CT\nreveals sucrose supply and growth velocity as\
    \ major determinants of potato tuber\nstarch biosynthesis. BMC Genomics 11 (1),\
    \ 1–17. doi: 10.1186/1471-2164-11-93\nFinke, P. A. (1992). Integration of remote\
    \ sensing data in the simulation of spatially\nvariable yield of potatoes. Soil\
    \ Technol. 5 (3), 257–270. doi: 10.1016/0933-3630(92)\n90026-W\nFortin, J. G.,\
    \ Anctil, F., Parent, L.-E., and Bolinder, M. A. (2011). Site-speciﬁc early\n\
    season potato yield forecast by neural network in Eastern Canada. Precis. Agric.\
    \ 12 (6),\n905–923. doi: 10.1007/s11119-011-9233-6\nFrąckowiak, K., Potarzycki,\
    \ J., Grzebisz, W., and Szczepaniak, W. (2020). Potato\nnutritional status at\
    \ the onset of tuberisation – a yield prediction tool. Plant Soil\nEnviron. 66\
    \ (2), 86–92. doi: 10.17221/533/2019-PSE\nFu, Z., Jiang, J., Gao, Y., Krienke,\
    \ B., Wang, M., Zhong, K., et al. (2020). Wheat\ngrowth monitoring and yield estimation\
    \ based on multi-rotor unmanned aerial vehicle.\nRemote Sens. 12 (3), 508. doi:\
    \ 10.3390/rs12030508\nGarcia-Vila, M., and Fereres, E. (2012). Combining the simulation\
    \ crop model\nAquaCrop with an economic model for the optimization of irrigation\
    \ management at\nfarm level. Eur. J. Agron. 36 (1), 21–31. doi: 10.1016/j.eja.2011.08.003\n\
    Godfray, H. C. J., Beddington, J. R., Crute, I. R., Haddad, L., Lawrence, D.,\
    \ Muir, J. F.,\net al. (2010). Food security: the challenge of feeding 9 billion\
    \ people. Science 327 (5967),\n812–818. doi: 10.1126/science.1185383\nGómez,\
    \ D., Salvador, P., Sanz, J., and Casanova, J. L. (2019). Potato yield prediction\n\
    using machine learning techniques and Sentinel 2 data. Remote Sens. 11 (15), 1745.\n\
    doi: 10.3390/rs11151745\nGómez, D., Salvador, P., Sanz, J., and Casanova, J.\
    \ L. (2021). New spectral indicator\nPotato Productivity Index based on Sentinel-2\
    \ data to improve potato yield prediction:\na machine learning approach. Int.\
    \ J. Remote Sens. 42 (9), 3430–3448. doi: 10.1080/\n01431161.2020.1871102\nGovindakrishnan,\
    \ P. M., Singh, J. P., Lal, S. S., and Sushma, P. (2007). A\nmethodology for pre-harvest\
    \ prediction of mean potato yield at regional scale using\ninfocrop-potato model.\
    \ Potato J. 34 (1/2), 125–126.\nGrifﬁn, T. S., Johnson, B. S., and Ritchie, J.\
    \ T. (1993). A simulation model for potato\ngrowth and development: Substor-potato\
    \ Version 2.0. (Michigan: IBSNAT Project).\nHackett, C., Sands, P. J., and Nix,\
    \ H. A. (1979). A model of the development and\nbulking of potatoes (Solanum tuberosum\
    \ L.) II. Prediction of district commercial yields.\nField Crops Res. 2 (C), 333–347.\
    \ doi: 10.1016/0378-4290(79)90032-7\nHajihassani, A., Ebrahimian, E., and Hajihasani,\
    \ M. (2013). Estimation of yield\ndamage in potato caused by iranian population\
    \ of Globodera Rostochiensis with and\nwithout aldicarb under greenhouse conditions.\
    \ Int. J. Agric. Biol. 15 (2), 352–356.\nHamedani, S. R., Liaqat, M., Shamshirband,\
    \ S., Al-Razgan, O. S., Al-Shammari, E. T.,\nand Petkovic, D. (2015). Comparative\
    \ study of soft computing methodologies for\nenergy input-output analysis to predict\
    \ potato production. Am. J. Potato Res. 92 (3),\n426–434. doi: 10.1007/s12230-015-9453-9\n\
    Hao, S., Ryu, D., Western, A., Perry, E., Bogena, H., and Franssen, H. J. H. (2021).\n\
    Performance of a wheat yield prediction model and factors inﬂuencing the\nperformance:\
    \ A review and meta-analysis. Agric. Syst. 194, 103278. doi: 10.1016/\nj.agsy.2021.103278\n\
    Haverkort, A. J., Franke, A. C., Engelbrecht, F. A., and Steyn, J. M. (2013).\
    \ Climate\nchange and potato production in contrasting south african agro-ecosystems\
    \ 1. Effects\non land and water use efﬁciencies. Potato Res. 56 (1), 31–50. doi:\
    \ 10.1007/s11540-013-\n9230-4\nHaverkort, A., Franke, A., Steyn, J. M., Pronk,\
    \ A., Caldiz, D., and Kooman, P. (2015).\nA robust potato model: LINTUL-Potato-DSS.\
    \ Potato Res. 58 (4), 313–327. doi: 10.1007/\ns11540-015-9303-7\nHijmans, R. J.,\
    \ Condori, B., Carrillo, R., and Kropff, M. J. (2003). A quantitative and\nconstraint-speciﬁc\
    \ method to assess the potential impact of new agricultural\ntechnology: the case\
    \ of frost resistant potato for the Altiplano (Peru and Bolivia).\nAgric. Syst.\
    \ 76 (3), 895–911. doi: 10.1016/s0308-521x(02)00081-1\nHill, J. D., Strommen,\
    \ N. D., Sakamoto, C. M., and Leduc, S. K. (1980). LACIE -\napplication of meteorology\
    \ for united-states and foreign wheat assessment. J. Appl.\nMeteorol. 19 (1),\
    \ 22–34. doi: 10.1175/1520-0450(1980)019<0022:Laomfu>2.0.Co;2\nHolden, N. M.,\
    \ Brereton, A. J., Fealy, R., and Sweeney, J. (2003). Possible change in\nIrish\
    \ climate and its impact on barley and potato yields. Agric. For. Meteorol. 116\
    \ (3-4),\n181–196. doi: 10.1016/S0168-1923(03)00002-9\nHolm, D. G., and Nylund,\
    \ R. E. (1978). Use of mineral element content of potato\npetioles for predicting\
    \ yield potential. Am. Potato J. 55 (6), 291–305. doi: 10.1007/\nBF02852071\n\
    Huang, S., Tang, L., Hupy, J. P., Wang, Y., and Shao, G. (2021). A commentary\n\
    review on the use of normalized difference vegetation index (NDVI) in the era\
    \ of\npopular remote sensing. J. For. Res. 32 (1), 1–6. doi: 10.1007/s11676-020-01155-1\n\
    Iwase, J., Sato, Y., Comparini, D., Masi, E., Mancuso, S., and Kawano, T. (2015).\n\
    Non-invasive acoustic sensing of tuberous roots of sweet potato (Ipomoea batatas)\n\
    growing belowground. Adv. Hortic. Sci. 29 (4), 176–180.\nJasim, A., Zaeen, A.,\
    \ Sharma, L. K., Bali, S. K., Wang, C., Buzza, A., et al. (2020).\nPredicting\
    \ phosphorus and potato yield using active and passive sensors. Agriculture 10\n\
    (11), 564. doi: 10.3390/agriculture10110564\nJin, J., Huang, J., and Gui, L. (2019).\
    \ Optimization of potato irrigation system based\non AquaCrop model. Acta Agric.\
    \ Boreali-occident. Sin. 28 (08), 1250–1258.\ndoi: 10.7606/j.issn.1004-1389.2019.08.006\n\
    Keating, B. A., Carberry, P. S., Hammer, G. L., Probert, M. E., Robertson, M.\
    \ J.,\nHolzworth, D., et al. (2003). An overview of APSIM, a model designed for\
    \ farming\nsystems simulation. Eur. J. Agron. 18 (3-4), 267–288. doi: 10.1016/S1161-0301(02)\n\
    00108-9\nKelly, J., Kljun, N., Olsson, P.-O., Mihai, L., Liljeblad, B., Weslien,\
    \ P., et al. (2019).\nChallenges and best practices for deriving temperature data\
    \ from an uncalibrated UAV\nthermal infrared camera. Remote Sens. 11 (5), 567.\
    \ doi: 10.3390/rs11050567\nKhan, M. S. (2012). Assessing genetic variation in\
    \ growth and development of potato.\n(Wageningen: Wageningen University).\nKhoshnevisan,\
    \ B., Raﬁee, S., Omid, M., and Mousazadeh, H. (2014). Prediction of\npotato yield\
    \ based on energy inputs using multi-layer adaptive neuro-fuzzy inference\nsystem.\
    \ Measurement 47, 521–530. doi: 10.1016/j.measurement.2013.09.020\nKleinwechter,\
    \ U., Gastelo, M., Ritchie, J., Nelson, G., and Asseng, S. (2016).\nSimulating\
    \ cultivar variations in potato yields for contrasting environments. Agric.\n\
    Syst. 145, 51–63. doi: 10.1016/j.agsy.2016.02.011\nKooman, P., and Haverkort,\
    \ A. (1995). “Modelling development and growth of the potato\ncrop inﬂuenced by\
    \ temperature and daylength: LINTUL-POTATO,” in Potato ecology and\nmodelling\
    \ of crops under conditions limiting growth (Wageningen: Springer), 41–59.\nKrizhevsky,\
    \ A., Sutskever, I., and Hinton, G. E. (2017). Imagenet classiﬁcation with\ndeep\
    \ convolutional neural networks. Commun. ACM 60 (6), 84–90. doi: 10.1145/\n3065386\n\
    Kroes, J., Supit, I., Van Dam, J., Van Walsum, P., and Mulder, M. (2018). Impact\
    \ of\ncapillary rise and recirculation on simulated crop yields. Hydrol. Earth\
    \ Syst. Sci. 22 (5),\n2937–2952. doi: 10.5194/hess-22-2937-2018\nLin et al.\n\
    10.3389/fpls.2023.1214006\nFrontiers in Plant Science\nfrontiersin.org\n23\nKulig,\
    \ B., Skowera, B., Klimek-Kopyra, A., Kołodziej, S., and Grygierzec, W. (2020).\n\
    The use of the WOFOST model to simulate water-limited yield of early potato cultivars.\n\
    Agronomy 10 (1), 81. doi: 10.3390/agronomy10010081\nKumar, P., Dubey, S., Kimothi,\
    \ M. M., Neetu,, Mamatha, S., and Ray, S. S. (2019).\n“Analysis of remote sensing-based\
    \ assessment of potato statistics and its comparison\nwith government estimates,”\
    \ in International Archives of the Photogrammetry, Remote\nSensing and Spatial\
    \ Information Sciences (New Delhi: ISPRS Archives) XLII-3/W6,\n299–305.\nLi, D.,\
    \ Miao, Y., Gupta, S. K., Rosen, C. J., Yuan, F., Wang, C., et al. (2021).\nImproving\
    \ potato yield prediction by combining cultivar information and UAV remote\nsensing\
    \ data using machine learning. Remote Sens. 13 (16), 3322. doi: 10.3390/\nrs13163322\n\
    Li, Y., Wang, J., Fang, Q., Hu, Q., Zhang, J., Pan, Z., et al. (2022). Optimal\
    \ planting\ndates for diverse crops in Inner Mongolia. Field Crops Res. 275, 108365.\
    \ doi: 10.1016/\nj.fcr.2021.108365\nLi, Y., Wang, J., Tang, J., Huang, M., Bai,\
    \ H., Wang, N., et al. (2019). Coupling\nimpacts of planting date and cultivar\
    \ on potato yield. Chin. J. Eco-Agric. 27 (2), 296–\n304. doi: 10.13930/j.cnki.cjea.180707\n\
    Li, B., Xu, X., Zhang, L., Han, J., Bian, C., Li, G., et al. (2020). Above-ground\
    \ biomass\nestimation and yield prediction in potato by using UAV-based RGB and\
    \ hyperspectral\nimaging. ISPRS J. Photogramm. Remote Sens. 162, 161–172. doi:\
    \ 10.1016/\nj.isprsjprs.2020.02.013\nLiu, N., Townsend, P. A., Naber, M. R., Bethke,\
    \ P. C., Hills, W. B., and Wang, Y.\n(2021). Hyperspectral imagery to monitor\
    \ crop nutrient status within and across\ngrowing seasons. Remote Sens. Environ.\
    \ 255, 112303. doi: 10.1016/j.rse.2021.112303\nLiu, Y., Wang, S., Chen, J., Chen,\
    \ B., Wang, X., Hao, D., et al. (2022). Rice yield\nprediction and model interpretation\
    \ based on satellite and climatic indicators using a\ntransformer method. Remote\
    \ Sens. 14 (19), 5045. doi: 10.3390/rs14195045\nLu, S. (2004). Geographic information\
    \ system (Beijing: Higher Education Press).\nLuo, S., He, Y., Li, Q., Jiao, W.,\
    \ Zhu, Y., and Zhao, X. (2020). Nondestructive\nestimation of potato yield using\
    \ relative variables derived from multi-period LAI and\nhyperspectral data based\
    \ on weighted growth stage. Plant Methods 16 (1), 150.\ndoi: 10.1186/s13007-020-00693-3\n\
    Luo, X., Sun, Y., Liu, L., Wang, L., Yang, L., and Gao, X. (2022). Simulation\
    \ of\nresponse of potato growth and yield to drought stress in the singlecropping\
    \ region in\nnorthern China: A case of Wuchuan County. Arid Land Geogr. 45 (3),\
    \ 867–878.\ndoi: 10.12118/j.issn.1000-6060.2021.350\nLyalin, K. S., Biryuk, A.\
    \ A., Sheremet, A. Y., Tsvetkov, V. K., and Prikhodko, D. V.\n(2018). “UAV synthetic\
    \ aperture radar system for control of vegetation and soil\nmoisture,” in 2018\
    \ IEEE Conference of Russian Young Researchers in Electrical and\nElectronic Engineering,\
    \ ElConRus 2018. Ed. S. Shaposhnikov (Moscow and St.\nPetersburg: IEEE), 1673–1675.\n\
    Ma, Y., Ma, L., Zhang, Q., Huang, C., Yi, X., Chen, X., et al. (2022). Cotton\
    \ yield\nestimation based on vegetation indices and texture features derived from\
    \ RGB image.\nFront. Plant Sci. 13. doi: 10.3389/fpls.2022.925986\nMa, Y., Zhang,\
    \ Z., Kang, Y., and Özdoğan, M. (2021). Corn yield prediction and\nuncertainty\
    \ analysis based on remotely sensed variables using a Bayesian neural\nnetwork\
    \ approach. Remote Sens. Environ. 259, 112408. doi: 10.1016/j.rse.2021.112408\n\
    MacDonald, R., Hall, F., and Erb, R. (1975). “The use of Landsat data in a large\
    \ area\ncrop inventory experiment (LACIE),” in LARS Symposia (Indiana: IEEE),\
    \ Paper 46.\nMachakaire, A. T. B., Steyn, J. M., Caldiz, D. O., and Haverkort,\
    \ A. J. (2016).\nForecasting yield and tuber size of processing potatoes in south\
    \ africa using the\nLINTUL-Potato-DSS model. Potato Res. 59 (3), 195–206. doi:\
    \ 10.1007/s11540-016-\n9321-0\nMahdian, M. H., and Gallichand, J. (1997). Estimating\
    \ potato yield with the\nSUBSTOR model in Quebec. Can. Agric. Eng. 39 (3), 157–164.\n\
    Maimaitijiang, M., Sagan, V., Sidike, P., Hartling, S., Esposito, F., and Fritschi,\
    \ F. B.\n(2020). Soybean yield prediction from UAV using multimodal data fusion\
    \ and deep\nlearning. Remote Sens. Environ. 237, 111599. doi: 10.1016/j.rse.2019.111599\n\
    Marshall, B., Heilbron, T., MacKerron, D., and Waister, P. (1984). “Modelling\n\
    potential dry-matter production,” in Proceedings of the 9th Triennial Conference\
    \ of the\nEuropean Association for Potato Research. 340–341.\nMartre, P., Wallach,\
    \ D., Asseng, S., Ewert, F., Jones, J. W., Rötter, R. P., et al. (2015).\nMultimodel\
    \ ensembles of wheat growth: many models are better than one. Global\nChange Biol.\
    \ 21 (2), 911–925. doi: 10.1111/gcb.12768\nMatott, L. S., Babendreier, J. E.,\
    \ and Purucker, S. T. (2009). Evaluating uncertainty in\nintegrated environmental\
    \ models: A review of concepts and tools. Water Resour. Res.\n45, W06421. doi:\
    \ 10.1029/2008WR007301\nMazurczyk, W., Nowacki, W., and Takac, J. (2007). Comparison\
    \ of the production\nand environmental effects of different potato cultivation\
    \ systems based on the\nsimulation experiment: the Daisy model. Acta Scientiarum\
    \ Polonorum Agricultura 6\n(3), 27–34.\nMeng, X., Han, Z., Zhang, S., Sun, J.,\
    \ Xv, F., Xv, S., et al. (2021). Dynamic changes of\nchlorophyll in potato leaves\
    \ and their correlation with yield. J. Jilin Agric. Sci. 46 (03),\n79–81.\nMhango,\
    \ J. K., Harris, E. W., Green, R., and Monaghan, J. M. (2021). Mapping\npotato\
    \ plant density variation using aerial imagery and deep learning techniques for\n\
    precision agriculture. Remote Sens. 13 (14), 2705. doi: 10.3390/rs13142705\nMonteith,\
    \ J. L. (1972). Solar radiation and productivity in tropical ecosystems. J.\n\
    Appl. Ecol. 9 (3), 747–766. doi: 10.2307/2401901\nMorier, T., Cambouris, A. N.,\
    \ and Chokmani, K. (2015). In-Season nitrogen status\nassessment and yield estimation\
    \ using hyperspectral vegetation indices in a potato crop.\nAgron. J. 107 (4),\
    \ 1295–1309. doi: 10.2134/agronj14.0402\nMuruganantham, P., Wibowo, S., Grandhi,\
    \ S., Samrat, N. H., and Islam, N. (2022). A\nsystematic literature review on\
    \ crop yield prediction with deep learning and remote\nsensing. Remote Sens. 14\
    \ (9), 1990. doi: 10.3390/rs14091990\nNakalembe, C., Becker-Reshef, I., Bonifacio,\
    \ R., Hu, G., Humber, M. L., Justice, C. J.,\net al. (2021). A review of satellite-based\
    \ global agricultural monitoring systems available\nfor Africa. Global Food Secur.\
    \ 29, 100543. doi: 10.1016/j.gfs.2021.100543\nNewton, I. H., Islam, A. M. T.,\
    \ Islam, A. S., Islam, G. T., Tahsin, A., and Razzaque, S.\n(2018). Yield prediction\
    \ model for potato using landsat time series images driven\nvegetation indices.\
    \ Remote Sens. Earth Sys. Sci. 1 (1), 29–38. doi: 10.1007/s41976-018-\n0006-0\n\
    Ng, N., and Loomis, R. S. (1984). Simulation of growth and yield of the potato\
    \ crop\nVol. 4 (Wageningen: Centre for Agricultural Publishing and Documentation,\
    \ P.O.\nBox), 6700 AA.\nNinanya, J., Ramirez, D. A., Rinza, J., Silva-Diaz, C.,\
    \ Cervantes, M., Garcia, J., et al.\n(2021). Canopy temperature as a key physiological\
    \ trait to improve yield prediction\nunder water restrictions in potato. Agronomy\
    \ 11 (7), 1436. doi: 10.3390/\nagronomy11071436\nOjeda, J. J., Rezaei, E. E.,\
    \ Remenyi, T. A., Webb, M. A., Webber, H. A., Kamali, B.,\net al. (2020). Effects\
    \ of soil- and climate data aggregation on simulated potato yield and\nirrigation\
    \ water requirement. Sci. Total Environ. 710, 135589. doi: 10.1016/\nj.scitotenv.2019.135589\n\
    Piekutowska, M., Niedbala, G., Piskier, T., Lenartowicz, T., Pilarski, K.,\nWojciechowski,\
    \ T., et al. (2021). The application of multiple linear regression and\nartiﬁcial\
    \ neural network models for yield prediction of very early potato cultivars before\n\
    harvest. Agronomy 11 (5), 885. doi: 10.3390/agronomy11050885\nPlauborg, F., Abrahamsen,\
    \ P., Gjettermann, B., Mollerup, M., Iversen, B. V., Liu, F.,\net al. (2010).\
    \ Modelling of root ABA synthesis, stomatal conductance, transpiration and\npotato\
    \ production under water saving irrigation regimes. Agric. Water Manage. 98 (3),\n\
    425–439. doi: 10.1016/j.agwat.2010.10.006\nPlauborg, F., Motarjemi, S. K., Nagy,\
    \ D., and Zhou, Z. (2022). Analysing potato\nresponse to subsurface drip irrigation\
    \ and nitrogen fertigation regimes in a temperate\nenvironment using the Daisy\
    \ model. Field Crops Res. 276, 108367. doi: 10.1016/\nj.fcr.2021.108367\nPrihar,\
    \ S. S., Arora, V. K., Singh, G., and Singh, R. (1995). Estimating potato-tuber\n\
    yield in a subtropical environment with simple radiation-based models. Exp. Agric.\
    \ 31\n(1), 65–73. doi: 10.1017/S0014479700025023\nPrins, A. J., and Van Niekerk,\
    \ A. (2020). Regional mapping of vineyards using\nmachine learning and LiDAR data.\
    \ Int. J. Appl. Geospat. Res. 11 (4), 1–22. doi: 10.4018/\nIJAGR.2020100101\n\
    Pushpalatha, R., Santhosh Mithra, V., Sunitha, S., Goerge, J., Nedunchezhiyan,\
    \ M.,\nMamatha, K., et al. (2021). Impact of climate change on the yield of tropical\
    \ root and\ntuber crops vs. rice and potato in India. Food Secur 14 (2), 495-508.\
    \ doi: 10.1007/\ns12571-021-01226-z\nQuiroz, R., Loayza, H., Barreda, C., Gavilan,\
    \ C., Posadas, A., and Ramirez, D. A.\n(2017). Linking process-based potato models\
    \ with light reﬂectance data: Does model\ncomplexity enhance yield prediction\
    \ accuracy? Eur. J. Agron. 82, 104–112. doi: 10.1016/\nj.eja.2016.10.008\nRaj,\
    \ T., Hanim Hashim, F., Baseri Huddin, A., Ibrahim, M. F., and Hussain, A.\n(2020).\
    \ A survey on LiDAR scanning mechanisms. Electronics 9 (5), 741. doi: 10.3390/\n\
    electronics9050741\nRamu, K., and Priyadarsini, K. (2021). “A review on crop yield\
    \ prediction using\nmachine learning methods,” in Proceedings - 2nd International\
    \ Conference on Smart\nElectronics and Communication, ICOSEC 2021 (Trichy: IEEE).\
    \ 1239–1245.\ndoi: 10.1109/ICOSEC51865.2021.9591764\nRaymundo, R., Asseng, S.,\
    \ Cammarano, D., and Quiroz, R. (2014). Potato, sweet\npotato, and yam models\
    \ for climate change: A review. Field Crops Res. 166, 173–185.\ndoi: 10.1016/j.fcr.2014.06.017\n\
    Raymundo, R., Asseng, S., Prassad, R., Kleinwechter, U., Concha, J., Condori,\
    \ B.,\net al. (2017). Performance of the SUBSTOR-potato model across contrasting\
    \ growing\nconditions. Field Crops Res. 202, 57–76. doi: 10.1016/j.fcr.2016.04.012\n\
    Raymundo, R., Asseng, S., Robertson, R., Petsakos, A., Hoogenboom, G., Quiroz,\
    \ R.,\net al. (2018). Climate change impact on global potato production. Eur.\
    \ J. Agron. 100,\n87–98. doi: 10.1016/j.eja.2017.11.008\nRazzaghi, F., Zhou, Z.,\
    \ Andersen, M. N., and Plauborg, F. (2017). Simulation of\npotato yield in temperate\
    \ condition by the AquaCrop model. Agric. Water Manage.\n191, 113–123. doi: 10.1016/j.agwat.2017.06.008\n\
    Ritchie, J. T., Grifﬁn, T. S., and Johnson, B. S. (1995). SUBSTOR: functional\
    \ model of\npotato growth, development and yield (Wageningen: Wageningen Pers),\
    \ 401–435.\nRyerson, R. A., Dobbins, R. N., and Thibault, C. (1985). Timely crop\
    \ area estimates\nfrom landsat. Photogramm. Eng. Remote Sens. 51 (11), 1735–1743.\n\
    Salvador, P., Gómez, D., Sanz, J., and Casanova, J. L. (2020). Estimation of\
    \ potato\nyield using satellite data at a municipal level: A machine learning\
    \ approach. ISPRS Int. J.\nGeo- nf. 9 (6), ijgi9060343. doi: 10.3390/ijgi9060343\n\
    Lin et al.\n10.3389/fpls.2023.1214006\nFrontiers in Plant Science\nfrontiersin.org\n\
    24\nSands, P. J., Hackett, C., and Nix, H. A. (1979). A model of the development\
    \ and\nbulking of potatoes (Solanum Tuberosum L.) I. Derivation from well-managed\
    \ ﬁeld\ncrops. Field Crops Res. 2 (C), 309–331. doi: 10.1016/0378-4290(79)90031-5\n\
    Sharma, L. K., Bali, S. K., Dwyer, J. D., Plant, A. B., and Bhowmik, A. (2017).\
    \ A case\nstudy of improving yield prediction and sulfur deﬁciency detection using\
    \ optical\nsensors and relationship of historical potato yield with weather data\
    \ in Maine. Sensors\n17 (5), 1095. doi: 10.3390/s17051095\nSingh, N. O., Singh,\
    \ N. G., Singh, L. N., Kumar, S., and Paull, A. K. (2020).\nForecasting model\
    \ of potato yield from farmers’ ﬁelds in Manipur. Int. J. Agric. Stat. Sci.\n\
    16 (1), 401–405.\nSingha, C., and Swain, K. C. (2022). “Evaluating the NDVI based\
    \ Rice and Potato\nYield Prediction map Using GIS Geostatistical Environment,”\
    \ in 2nd International\nConference on Advances in Electrical, Computing, Communication\
    \ and Sustainable\nTechnologies, ICAECT 2022 (Bhilai: IEEE). doi: 10.1109/ICAECT54875.2022.9807981\n\
    Sivarajan, S. (2011). Estimating yield of irrigated potatoes using aerial and\
    \ satellite\nremote sensing. (Utah: Utah State University).\nSnyder, R. G., and\
    \ Ewing, E. E. (1989). Interactive effects of temperature,\nphotoperiod, and cultivar\
    \ on tuberization of potato cuttings. HortScience 24 (2),\n336–338. doi: 10.21273/HORTSCI.24.2.336\n\
    Šťastná, M., Toman, F., and Dufková, J. (2010). Usage of SUBSTOR model in\
    \ potato\nyield prediction. Agric. Water Manage. 97 (2), 286–290. doi: 10.1016/\n\
    j.agwat.2009.09.015\nSteduto, P., Hsiao, T. C., Raes, D., and Fereres, E. (2009).\
    \ Aquacrop-the FAO crop\nmodel to simulate yield response to water: I. concepts\
    \ and underlying principles. Agron.\nJ. 101 (3), 426–437. doi: 10.2134/agronj2008.0139s\n\
    Stöcker, C., Bennett, R., Nex, F., Gerke, M., and Zevenbergen, J. (2017). Review\
    \ of the\ncurrent state of UAV regulations. Remote Sens. 9 (5), 459. doi: 10.3390/rs9050459\n\
    Sun, C., Feng, L., Zhang, Z., Ma, Y., Crosby, T., Naber, M., et al. (2020). Prediction\
    \ of\nend-of-season tuber yield and tuber set in potatoes using in-season UAV-based\n\
    hyperspectral imagery and machine learning. Sensors 20 (18), 5293. doi: 10.3390/\n\
    s20185293\nSun, S., Zhang, L., Chen, Z., and Sun, J. (2017). Advances in AquaCrop\
    \ model\nresearch and application. Sci. Agric. Sin. 50 (17), 3286–3299. doi: 10.3864/j.issn.0578-\n\
    1752.2017.17.004\nTanabe, D., Ichiura, S., Nakatsubo, A., Kobayashi, T., and Katahira,\
    \ M. (2019). “Yield\nprediction of potato by unmanned aerial vehicle,” in TAE\
    \ 2019 - Proceeding of 7th\nInternational Conference on Trends in Agricultural\
    \ Engineering 2019 (Prague: TAE).\n540–546.\nTandzi, L. N., and Mutengwa, C. S.\
    \ (2020). Estimation of Maize (Zea mays L.) Yield\nPer Harvest Area: Appropriate\
    \ methods. Agronomy 10 (1), 29. doi: 10.3390/\nagronomy10010029\nTang, J., Wang,\
    \ J., Fang, Q., Wang, E., Yin, H., and Pan, X. (2018). Optimizing\nplanting date\
    \ and supplemental irrigation for potato across the agro-pastoral ecotone in\n\
    North China. Eur. J. Agron. 98, 82–94. doi: 10.1016/j.eja.2018.05.008\nTang, J.,\
    \ Xiao, D., Wang, J., Fang, Q., Zhang, J., and Bai, H. (2021). Optimizing water\n\
    and nitrogen managements for potato production in the agro-pastoral ecotone in\n\
    North China. Agric. Water Manage. 253, 106945. doi: 10.1016/j.agwat.2021.106945\n\
    ten Harkel, J., Bartholomeus, H., and Kooistra, L. (2020). Biomass and crop height\n\
    estimation of different crops using UAV-based lidar. Remote Sens. 12 (1), 17.\n\
    doi: 10.3390/rs12010017\nTian, H., Wang, P., Tansey, K., Zhang, J., Zhang, S.,\
    \ and Li, H. (2021). An LSTM\nneural network for improving wheat yield estimates\
    \ by integrating remote sensing data\nand meteorological data in the Guanzhong\
    \ Plain, PR China. Agric. For. Meteorol. 310,\n108629. doi: 10.1016/j.agrformet.2021.108629\n\
    Tooley, B. E., Mallory, E. B., Porter, G. A., and Hoogenboom, G. (2021). Predicting\n\
    the response of a potato-grain production system to climate change for a humid\n\
    continental climate using DSSAT. Agric. For. Meteorol. 307, 108452. doi: 10.1016/\n\
    j.agrformet.2021.108452\nTravasso, M. I., Caldiz, D. O., and Saluzzo, J. A. (1996).\
    \ Yield prediction using the\nSUBSTOR-potato model under Argentinian conditions.\
    \ Potato Res. 39 (3), 305–312.\ndoi: 10.1007/BF02360922\nVan Delden, A., Schröder,\
    \ J. J., Kropff, M. J., Grashoff, C., and Booij, R. (2003).\nSimulated potato\
    \ yield, and crop and soil nitrogen dynamics under different organic\nnitrogen\
    \ management strategies in The Netherlands. Agric. Ecosyst. Environ. 96 (1-3),\n\
    77–95. doi: 10.1016/S0167-8809(03)00012-4\nVan der Velde, M., and Nisini, L. (2019).\
    \ Performance of the MARS-crop yield forecasting\nsystem for the European Union:\
    \ Assessing accuracy, in-season, and year-to-year\nimprovements from 1993 to 2015.\
    \ Agric. Syst. 168, 203–212. doi: 10.1016/j.agsy.2018.06.009\nVan der Zaag, D.\
    \ (1984). Reliability and signiﬁcance of a simple method of estimating the\npotential\
    \ yield of the potato crop. Potato Res. 27, 51–73. doi: 10.1007/BF02356197\nVan\
    \ Diepen, C. A., Wolf, J., van Keulen, H., and Rappoldt, C. (1989). WOFOST: a\n\
    simulation model of crop production. Soil Use Manage. 5 (1), 16–24. doi: 10.1111/\n\
    j.1475-2743.1989.tb00755.x\nVannoppen, A., and Gobin, A. (2022). Estimating yield\
    \ from NDVI, weather data,\nand soil water depletion for sugar beet and potato\
    \ in Northern Belgium. Water 14 (8),\n1188. doi: 10.3390/w14081188\nVanuytrecht,\
    \ E., Raes, D., and Willems, P. (2016). Regional and global climate\nprojections\
    \ increase mid-century yield variability and crop productivity in Belgium.\nReg.\
    \ Environ. Change 16 (3), 659–672. doi: 10.1007/s10113-015-0773-6\nWallach, D.,\
    \ Thorburn, P., Asseng, S., Challinor, A. J., Ewert, F., Jones, J. W., et al.\n\
    (2016). Estimating model prediction error: Should you treat predictions as ﬁxed\
    \ or\nrandom? Environ. Modell. Softw. 84, 529–539. doi: 10.1016/j.envsoft.2016.07.010\n\
    Wang, H., Cheng, M., Liao, Z., Guo, J., Zhang, F., Fan, J., et al. (2023). Performance\n\
    evaluation of AquaCrop and DSSAT-SUBSTOR-Potato models in simulating potato\n\
    growth, yield and water productivity under various drip fertigation regimes. Agric.\n\
    Water Manage. 276, 108076. doi: 10.1016/j.agwat.2022.108076\nWang, B., Feng, P.,\
    \ Liu, D. L., O’Leary, G. J., Macadam, I., Waters, C., et al. (2020).\nSources\
    \ of uncertainty for wheat yield projections under future climate are site-speciﬁc.\n\
    Nat. Food 1 (11), 720–72+. doi: 10.1038/s43016-020-00181-w\nWeir, A., Bragg, P.,\
    \ Porter, J., and Rayner, J. (1984). A winter wheat crop simulation\nmodel without\
    \ water or nutrient limitations. J. Agric. Sci. 102 (2), 371–382.\ndoi: 10.1017/S0021859600042702\n\
    Weiss, M., Jacob, F., and Duveiller, G. (2020). Remote sensing for agricultural\n\
    applications: A meta-review. Remote Sens. Environ. 236, 111402. doi: 10.1016/\n\
    j.rse.2019.111402\nWolf, J. (2002). Comparison of two potato simulation models\
    \ under climate change.\nI. Model calibration and sensitivity analyses. Clim.\
    \ Res. 21 (2), 173–186. doi: 10.3354/\ncr021173\nWu, X., Washaya, P., Liu, L.,\
    \ Li, K., Shao, Y., Meng, L., et al. (2020). Rice yield\nestimation based on spaceborne\
    \ SAR: A review from 1988 to 2018. IEEE Access 8,\n157462–157469, 9179784. doi:\
    \ 10.1109/ACCESS.2020.3020182\nWu, X., Xiao, Q., Wen, J., Liu, Q., Peng, J., and\
    \ Li, X. (2014). Advances in uncertainty\nanalysis for the validation of remote\
    \ sensing products: Take leaf area index for example.\nNatl. Remote Sens. Bull.\
    \ 18 (05), 1011–1023. doi: 10.11834/jrs.20143332\nXing, K., and Guo, H. (2006).\
    \ Review on uncertainty analysis methods in\nenvironment model. Environ. Sci.\
    \ Technol. 05), 112–115+121. doi: 10.19672/\nj.cnki.1003-6504.2006.05.045\nYagiz,\
    \ A. K., Cakici, M., Aydogan, N., Omezli, S., Yerlikaya, B. A., Ayten, S., et\
    \ al.\n(2020). Exploration of climate change effects on shifting potato seasons,\
    \ yields and\nwater use employing NASA and national long-term weather data. Potato\
    \ Res. 63 (4),\n565–577. doi: 10.1007/s11540-020-09457-x\nYang, S., Liu, J., Liang,\
    \ J., Yang, C., QIN, Y., Xv, X., et al. (2017). Potato climate yield\nprediction\
    \ model based on BP neural network. J. Agric. 7 (04), 29–33. doi: 10.11923/\n\
    j.issn.2095-4050.cjas16080007\nYang, G., Liu, J., Zhao, C., Li, Z., Huang, Y.,\
    \ Yu, H., et al. (2017). Unmanned aerial\nvehicle remote sensing for ﬁeld-based\
    \ crop phenotyping: current status and\nperspectives. Front. Plant Sci. 8. doi:\
    \ 10.3389/fpls.2017.01111\nYibrah, G., Araya, B., and Amsalu, N. (2015). Performance\
    \ of aquacrop model in\nsimulating tuber yield of potato (Solanum tuberosum L.)\
    \ under various water\navailability conditions in Mekelle Area, Northern Ethiopia.\
    \ J. Nat. Sci. Res. 5 (5),\n123–130.\nYokobori, J., Niwa, K., Sugiura, R., Noguchi,\
    \ N., and Chiba, Y. (2004). “Variable\nmanagement for uniform potato yield using\
    \ remote sensing images with unmanned\nhelicopter,” in Proceedings of the International\
    \ Conference on Automation Technology\nfor Off-road Equipment, ATOE 2004 (Kyoto:\
    \ MSABE). 447–454.\nZaeen, A. A., Sharma, L., Jasim, A., Bali, S., Buzza, A.,\
    \ and Alyokhin, A. (2020). In-\nseason potato yield prediction with active optical\
    \ sensors. Agrosyst. Geosci. Environ. 3\n(1), e20024. doi: 10.1002/agg2.20024\n\
    Zhang, X., Davidson, E. A., Mauzerall, D. L., Searchinger, T. D., Dumas, P., and\n\
    Shen, Y. (2015). Managing nitrogen for sustainable development. Nature 528 (7580),\n\
    51–59. doi: 10.1038/nature15743\nZhou, Z., Plauborg, F., Liu, F., Kristensen,\
    \ K., and Andersen, M. N. (2018). Yield and\ncrop growth of table potato affected\
    \ by different split-N fertigation regimes in sandy\nsoil. Eur. J. Agron. 92,\
    \ 41–50. doi: 10.1016/j.eja.2017.10.001\nZyromski, A., Szulczewski, W., Biniak-Pierog,\
    \ M., and Zmuda, R. (2013).\nApplication of the MoDrY model for the estimation\
    \ of potato yielding. Int. J. Plant\nProd. 7 (3), 505–516. doi: 10.22069/IJPP.2013.1116\n\
    Lin et al.\n10.3389/fpls.2023.1214006\nFrontiers in Plant Science\nfrontiersin.org\n\
    25\n"
  inline_citation: '>'
  journal: Frontiers in Plant Science
  limitations: '>'
  pdf_link: https://www.frontiersin.org/articles/10.3389/fpls.2023.1214006/pdf
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: 'Methodological evolution of potato yield prediction: a comprehensive review'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.32469/10355/85772
  analysis: '>'
  authors:
  - Aijing Feng
  citation_count: 1
  full_citation: '>'
  full_text: ">\n \n \n \n \n \n \n \nQUANTIFYING THE EFFECT OF ENVIRONMENTS ON \n\
    CROP EMERGENCE, DEVELOPMENT AND YIELD USING \nSENSING AND DEEP LEARNING TECHNIQUES\
    \ \n_______________________________________ \nA Dissertation \npresented to \n\
    the Faculty of the Graduate School \nat the University of Missouri-Columbia \n\
    __________________________________________________ \nIn Partial Fulfillment \n\
    of the Requirements for the Degree \nDoctor of Philosophy \n_____________________________________________________\
    \ \n \nby AIJING FENG \nDr. Jianfeng Zhou, Dissertation Supervisor \nMAY 2021\
    \ \n \n \n \n \nThe undersigned, appointed by the dean of the Graduate School,\
    \ have examined the \ndissertation entitled \n \nQUANTIFYING THE EFFECT OF ENVIRONMENTS\
    \ ON CROP EMERGENCE, \nDEVELOPMENT AND YIELD USING SENSING AND DEEP LEARNING \n\
    TECHNIQUES \n \npresented by Aijing Feng, \na candidate for the degree of doctor\
    \ of philosophy, \nand hereby certify that, in their opinion, it is worthy of\
    \ acceptance. \n \n \n ______________________________ \nDr. Jianfeng Zhou \n \n\
    ______________________________ \nDr. Gang Yao \n \n______________________________\
    \ \nDr. Kenneth A. Sudduth \n \n______________________________ \nDr. Toni Kazic\
    \ \n \n______________________________ \nDr. Earl D. Vories \n \n \n \nii \n \n\
    ACKNOWLEDGEMENTS \nI would like to express my sincere appreciation to my advisor\
    \ and committee chair \nDr. Jianfeng Zhou. Dr. Zhou constantly offers me great\
    \ support and excellent suggestions \nduring the period of my Ph.D. study. Without\
    \ his mentoring, I could not have completed \nthis dissertation. I not only regard\
    \ him as my academic advisor but also as a respected elder. \nHe taught me how\
    \ to think critically, how to do things meticulously, and how to deal with \n\
    the trivial things in life wisely. \nI would like to thank my committee members\
    \ Dr. Kenneth A. Sudduth and Dr. Earl \nD. Vories for the help with my experiments\
    \ as well as all the wonderful suggestions and \nthe review of my publications.\
    \ They help me improve my writing skills a lot and I learn \nhow to think deeper\
    \ on a research topic. I would also like to thank my committee members \nDr. Gang\
    \ Yao and Dr. Toni Kazic for all their guidance and suggestions through this long-\n\
    term process. \nI appreciate the great support from my colleagues Jing Zhou and\
    \ Chin Nee Vong \nfrom the Precision and Automated Agriculture Lab at the University\
    \ of Missouri. They \ncreated an excellent environment for research in our lab.\
    \ I enjoy working with them. They \nalways try their best to help me with the\
    \ data collection and gave me useful suggestions in \nmy research. We are best\
    \ friends in life and no matter in life or study, they have helped me \na lot.\
    \ \nIn the end, I would like to thank the China Scholarships Council fellowship\
    \ support. \n \n \niii \n \nTABLE OF CONTENTS \nACKNOWLEDGEMENTS ................................................................................................\
    \ ii \nLIST OF FIGURES ...........................................................................................................\
    \ vi \nLIST OF TABLES ...........................................................................................................\
    \ xiii \nLIST OF ABBREVIATIONS ..........................................................................................\
    \ xiv \nABSTRACT .....................................................................................................................\
    \ xvi \nChapter 1. INTRODUCTION .............................................................................................\
    \ 1 \n1.1 Problem Statement ...................................................................................................\
    \ 1 \n1.2 Literature review ......................................................................................................\
    \ 4 \nSoil and weather affect crop emergence, development and yield .......................\
    \ 4 \nSensor networks for crop monitoring ..................................................................\
    \ 5 \n1.3 Problems not been solved.........................................................................................\
    \ 8 \nThe need for rapid and accurate emergence assessment in early stage ...............\
    \ 8 \nThe need of quantifying the effects of soil, water and weather on plant\
    \ growth \nand yield ............................................................................................................\
    \ 10 \nEvaluation of high-resolution spatiotemporal crop, soil and weather ...............\
    \ 10 \nIntegration of emerging data analysis techniques: machine learning and\
    \ deep \nlearning ..............................................................................................................\
    \ 11 \n1.4 Goals of the study ..................................................................................................\
    \ 11 \n1.5 Literature cited .......................................................................................................\
    \ 12 \nChapter 2. GROUND DATA COLLECTION AND EXPERIMENT DESIGN ..............\
    \ 20 \n2.1 Experimental field ..................................................................................................\
    \ 20 \n2.2 Soil, field elevation and weather data ....................................................................\
    \ 21 \n2.3 Crop management and cotton yield data ................................................................\
    \ 23 \n2.5 Literature cited .......................................................................................................\
    \ 24 \nChapter 3. COTTON EMERGENCE EVALUATION AND THE SOIL EFFECTS ON \nEMERGENCE\
    \ .............................................................................................................\
    \ 26 \n3.1 Abstract ..................................................................................................................\
    \ 26 \n3.2 Introduction ............................................................................................................\
    \ 27 \n3.3 UAV system and experimental design ...................................................................\
    \ 31 \n3.4 UAV image pre-processing ....................................................................................\
    \ 33 \nDistortion calibration .........................................................................................\
    \ 33 \nQuantification of cotton row spacing ................................................................\
    \ 34 \nGeo-referencing cotton rows .............................................................................\
    \ 37 \nEvaluation of distortion correction and estimated row spacing ........................\
    \ 39 \n3.5 Evaluation of cotton stand count and canopy size .................................................\
    \ 40 \nIntroduction to convolutional neural networks .................................................\
    \ 40 \nDeployment of transform learning model using resnet18 .................................\
    \ 41 \nData set preparation ...........................................................................................\
    \ 44 \nPerformance of deep learning model resnet18 ..................................................\
    \ 46 \nComparison of resnet18 and other deep learning models .................................\
    \ 50 \n3.6 Development of a framework for evaluation of cotton emergence ........................\
    \ 51 \nStand count and canopy size mapping ..............................................................\
    \ 53 \nThe use of the data processing framework ........................................................\
    \ 56 \n3.7 Conclusion .............................................................................................................\
    \ 59 \niv \n \n3.8 Future work ............................................................................................................\
    \ 60 \n3.9 Literature cited .......................................................................................................\
    \ 61 \nChapter 4. SOIL AND ELEVATION EFFECTS ON COTTON EMERGENCE............ 69\
    \ \n4.1 Abstract ..................................................................................................................\
    \ 69 \n4.2 Introduction ............................................................................................................\
    \ 70 \n4.3 Emergence row register from individual RGB frame ............................................\
    \ 73 \nFeature detection and matching .........................................................................\
    \ 73 \nRemoval of false matches .................................................................................\
    \ 73 \nCalculation of the geometric transformation matrix .........................................\
    \ 75 \nCrop rows alignment based on the geometric transformation matrix ...............\
    \ 76 \nImage frame positions within each entire crop row ..........................................\
    \ 77 \nEmergence mapping based on the image alignment .........................................\
    \ 78 \n4.4 Limitation of the crop row alignment algorithm ....................................................\
    \ 79 \nLow overlapping of the image frames ...............................................................\
    \ 79 \nIncorrect image alignment when changing UAV batteries ...............................\
    \ 81 \n4.5 GPS accuracy .........................................................................................................\
    \ 82 \n4.6 Factors affected the stand count and canopy size ..................................................\
    \ 83 \nThe emergence maps .........................................................................................\
    \ 83 \nSoil and elevation effects on the stand count and canopy size ..........................\
    \ 84 \nEmergence and the crops’ subsequent development .........................................\
    \ 89 \n4.7 Conclusion .............................................................................................................\
    \ 90 \n4.8 Future work ............................................................................................................\
    \ 90 \n4.9 Literature cited .......................................................................................................\
    \ 91 \nChapter 5. COTTON DEVELOPMENT VARIATION AFFECTS BY SOIL AND \nWEATHER ..................................................................................................................\
    \ 95 \n5.1 Abstract ..................................................................................................................\
    \ 95 \n5.2 Introduction ............................................................................................................\
    \ 96 \n5.3 Multi-sensors UAV system and experimental design ..........................................\
    \ 100 \n5.4 UAV-based multispectral and thermal images processing ..................................\
    \ 104 \n5.5 Soil and weather data processing .........................................................................\
    \ 108 \n5.5.1 Soil texture data ...........................................................................................\
    \ 108 \n5.5.2 Evapotranspiration and water stress coefficient ..........................................\
    \ 110 \n5.6 Soil and weather effects on crop development ....................................................\
    \ 113 \n5.6.1 Data analysis methods .................................................................................\
    \ 113 \n5.6.2 Correlation between soil features and image features .................................\
    \ 115 \n5.6.3 Water stress coefficients ..............................................................................\
    \ 120 \n5.6.4 Difference in NDVI under various soil and weather conditions .................\
    \ 127 \n5.6.5 The effects of soil and weather features on crop growth ............................\
    \ 135 \n5.7 Conclusion ...........................................................................................................\
    \ 140 \n5.8 Literature cited .....................................................................................................\
    \ 141 \nChapter 6. CROP YIELD ESTIMATION BASED ON SOIL, WEATHER AND UAV \nIMAGES\
    \ ....................................................................................................................\
    \ 153 \n6.1 Abstract ................................................................................................................\
    \ 153 \n6.2 Introduction ..........................................................................................................\
    \ 154 \n6.3 UAV image processing ........................................................................................\
    \ 156 \n6.4 Soil and weather features processing ...................................................................\
    \ 157 \nv \n \n6.5 Yield estimation model ........................................................................................\
    \ 161 \n6.6 Yield prediction accuracy ....................................................................................\
    \ 167 \n6.6.1 Correlation between yield with soil features and image features\
    \ ................ 167 \n6.6.2 Yield prediction based on soil, weather and UAV\
    \ images.......................... 171 \n6.6.3 The crop growth and yield maps\
    \ ................................................................. 176 \n6.7\
    \ Conclusion ...........................................................................................................\
    \ 178 \n6.8 Future work ..........................................................................................................\
    \ 179 \n6.9 Literature cited .....................................................................................................\
    \ 181 \nChapter 7. CONCLUSIONS AND FUTURE STUDY ..................................................\
    \ 187 \n7.1 Conclusions ..........................................................................................................\
    \ 187 \n7.2 Future study ..........................................................................................................\
    \ 188 \nVITA ...............................................................................................................................\
    \ 190 \n \n \n \nvi \n \nLIST OF FIGURES \nFigure 1.1: Spectral reflection of\
    \ healthy plants, unhealthy plants and soil (Chang et \nal., 2013) ..............................................................................................................\
    \ 4 \n \nFigure 2.1: The research site includes two experimental fields (west\
    \ and east) of \nsimilar sizes, shown in a Google Earth satellite image captured\
    \ on Aug. 14, \n2019. Higher sand content soil regions (i.e. brighter soil color)\
    \ and variations \nin crop growth (i.e., degree of canopy closure) can be seen.\
    \ ............................. 20 \nFigure 2.2: Field elevation. ...............................................................................................\
    \ 21 \nFigure 2.3: Cumulative precipitation and the daily average temperature\
    \ of the \nexperimental field from May 1 to October 31 in 2017, 2018 and 2019.\
    \ The \ndata were obtained from a 400 m nearby weather station. The red and purple\
    \ \ndashed lines show the irrigation dates. Irrigations were on parts of the field\
    \ \nas described in Vories et al. (2020)....................................................................\
    \ 22 \nFigure 2.4: Monthly accumulative GDD (a) and monthly accumulative precipitation\
    \ \n(b) in 2017-2019 with the 10-year (2009-2019) averages .................................\
    \ 23 \n \nFigure 3.1: Illustration of the field experiment setup. (a) and (b)\
    \ show one of the 28 \nground reference points (GRPs) that include two 6-m crop\
    \ rows, a fence post \nand red flags marking 1-m intervals. The ground videos\
    \ were taken using a \ncell phone camera. (c) UAV image showing a PVC pipe square\
    \ with one \nground stake inside. ...........................................................................................\
    \ 33 \nFigure 3.2: Illustration of cotton row detection. (a) Image after decorrelation\
    \ stretch \nprocedure showing the substantial difference between pixel values\
    \ of crops \nand soil. (b) The corresponding binary image after soil removal using\
    \ a \nthreshold. (c) Cotton rows were detected using a standard Hough transform\
    \ \n(SHT). (d) Row spacing is denoted by ris. Cotton row spacings in an image\
    \ \nwere classified as left edges (two left row spacings, r1 and r2), middle (r3-r7),\
    \ \nor right edges (two right row spacings, r8 and r9) to test perspective distortion.\n\
    \ ...........................................................................................................................\
    \ 37 \nFigure 3.3: Illustration showing the location of a ground stake away from\
    \ the center of \nan image and the location calculation for each cotton row. (a)\
    \ Calculation of \nthe ground stake coordinates from the UAV GPS system. (b) Calculation\
    \ of \nGPS coordinates of 1-m seedling segments in each cotton row. The blue ‘x’\
    \ \nis the image geometric center. ...........................................................................\
    \ 38 \nFigure 3.4: Illustration of the principle of convolution layers and full\
    \ connection layers \nof the deep learning model. (a) Convolution layers include\
    \ a 3 × 3 filter with \nthe parameters wi. The input image size is assumed 9 ×\
    \ 9 and the moving \nstride is 2, resulting in the output of a 4 × 4 feature map.\
    \ xi is one of the pixel \nvalues of each 3 × 3 region that is used to calculate\
    \ outputs while moving. \nEach value in the output feature map is calculated by\
    \ \U0001D48A\U0001D48A = \U0001D7CF\U0001D7CF\U0001D7CF\U0001D7CF\U0001D498\U0001D498\
    \U0001D48A\U0001D48A × \U0001D499\U0001D499\U0001D48A\U0001D48A . (b) In \nthe\
    \ full connection layers, wi,j are the parameters, and xi are the input values.\
    \ \nThis is a four input and one output full connection layer that is calculated\
    \ by \nthe formula inside the purple box. .....................................................................\
    \ 41 \nvii \n \nFigure 3.5: The architecture of resnet18, as applied to the estimation\
    \ of stand count \nand seedling size. ...............................................................................................\
    \ 42 \nFigure 3.6: Illustration showing the approach used for the preparation\
    \ of the training \ndata and data augmentation. The red boxes mark the RoIs that\
    \ contained a \nsingle cotton seedling or a cluster of several cotton seedlings.\
    \ The yellow \ntext gives the ID of each RoI and the black text gives the number\
    \ of seedlings \nin each RoI. The different color boxes are the cropping images\
    \ used as the \ninput images of resnet18 model, where image size varied from 0.7\
    \ to 1.3 m, \nequaling 375 to 697 pixels. ................................................................................\
    \ 45 \nFigure 3.7: Predicted results of (a) cotton stand count and (b) canopy\
    \ size in the test \nset .......................................................................................................................\
    \ 47 \nFigure 3.8: Feature maps of stages 1 and 2 of the resnet18 model and the\
    \ Grad-\nregression activation map (Grad-RAM) of stage 5. (a), (e) and (i) are\
    \ three \ninput images; (b), (f) and (j) are the corresponding feature maps of\
    \ average \noutputs of 64 filters in stage 1 of the resnet18 model. The higher\
    \ values in \nthe feature maps mean that these regions were highlighted by the\
    \ model and \nthat information would be passed to the next layers. The color scale\
    \ legends \nof (f) and (j) are the same as that of (b). (c), (g) and (k) are the\
    \ corresponding \nfeature maps of average outputs of 64 filters in stage 2. The\
    \ color scale \nlegends of (g) and (k) are the same as that of (c). (d), (h) and\
    \ (l) are the Grad-\nRAM extracted from stage 5 of resnet18. The color scale legend\
    \ of (h) and \n(l) are the same as that of (d). ............................................................................\
    \ 48 \nFigure 3.9: Illustration of the complexity of image background removal\
    \ for \nsegmentation of seedlings due to soil color resulting from variations\
    \ in \ntexture and/or moisture content over a field. (a) A portion of an RGB image\
    \ \nincluding four crop rows; (b) A binary image showing the segmented \nseedlings\
    \ using the ExG and Otsu’s method. Some seedlings in the third and \nthe fourth\
    \ rows were not identified. (c) The pertinent image after using \ndecorrelation\
    \ stretch procedure and (d) its results of seedling segmentation. ... 50 \nFigure\
    \ 3.10: Overall processing flowchart. (a) Training procedure; (b) Cotton \nemergence\
    \ mapping procedure; (c) Legend used in both (a) and (b). ............... 53 \n\
    Figure 3.11: Histogram of (a) stand count per meter; and (b) canopy size of the\
    \ input \nimages that were manually labelled in the GRPs. Predicted results of\
    \ (c) \ncotton stand count and (d) canopy size in the whole field. ................................\
    \ 54 \nFigure 3.12: (a) Cotton stand count mapping and (b) canopy size mapping;\
    \ (c) yield \nmap; (d) soil ECa map. The red circles show the 28 GRPs. ..............................\
    \ 56 \nFigure 3.13: The process for training a customized model using the users’\
    \ own data \nset. Different color of the mouse icons showed the different processing\
    \ \noptions as described in the text. .........................................................................\
    \ 58 \nFigure 3.14: The process for mapping the cotton emergence of the whole\
    \ field. \nDifferent color of the mouse icons showed the different process options\
    \ as \ndescribed in the text. ..........................................................................................\
    \ 59 \n \nFigure 4.1: Feature detection and matching in two example frames. The\
    \ blue numbers \nin each frame are the detected image features and the same number\
    \ IDs with \na color line connect two matched image features. .............................................\
    \ 75 \nviii \n \nFigure 4.2: Crop rows alignment. There were 10 cotton rows identified\
    \ manually in \nthe first image frame. The numbers of 9 cotton rows identified\
    \ by the SHL \nin the second image frame were aligned with the first image frame\
    \ based on \nthe geometric transformation matrix M. ............................................................\
    \ 77 \nFigure 4.3: Two examples of the image frame alignment: (a) successfully\
    \ aligned with \nabout 30% overlapping in the forward direction between those\
    \ two \nsuccessive frames; (b) less than 5% overlap in the forward direction between\
    \ \nthese two successive frames and cannot be aligned successfully with the \n\
    algorithm. The alignment result in (b) was the result of manual alignment. .....\
    \ 80 \nFigure 4.4: Image frames aligned successfully using sideward overlapping\
    \ images. \nThis is one of the solutions for the 11 image frames that cannot be\
    \ \nsuccessfully aligned due to the low forward overlapping. The color numbers\
    \ \nin each image were the crop row numbers assigned to each image. .................\
    \ 80 \nFigure 4.5: Crop row alignment of image frames collected in the UAV batteries\
    \ \nchanged based on the feature detection and matching results. The color \n\
    numbers in each image were the crop row numbers assigned to each image. ... 82\
    \ \nFigure 4.6: GPS error measurement between two different kinds of systems:\
    \ ground \nRTK measurement and image measurement. ....................................................\
    \ 83 \nFigure 4.7: Emergence maps of (a) stand count (seedlings meter-1) and (b)\
    \ canopy size \n(cm2 seedling-1) with a dimension of 152 crop row × 315 m length\
    \ of each \ncrop row. (c) and (d) are the stand count (seedlings meter-1) and\
    \ (b) canopy \nsize (cm2 seedling-1) that downsampled from (a) and (b). Their\
    \ dimension \nwas 38 × 63, and each data point equates to a 4 m × 5 m area. .........................\
    \ 84 \nFigure 4.8: Relationships between emergence (stand count and seedling size)\
    \ and ECa-\nbased soil clay%. Low clay%: (0, 5.95], medium_low clay%: (5.95, 8.69],\
    \ \nmedium clay%: (8.69, 10.58], medium_high clay%: (10.58, 12.72], and high \n\
    clay%: (12.72, 28.39]. Each clay% group had the same numbers of clay% \ndata points.\
    \ (a) Mean stand count and (b) seedling size difference of five clay% \ncontent\
    \ groups. Different lower-case letters indicate a significant difference \nat\
    \ the 5% level of Tukey’s honest significant difference test. The KDE of the \n\
    (c) stand count and (d) seedling size in the five clay% content groups. ............\
    \ 85 \nFigure 4.9: Shapley value of the soil features in (a) stand count and (b)\
    \ canopy size \nprediction. ..........................................................................................................\
    \ 87 \nFigure 4.10: Shapley value changes corresponding to the top six important\
    \ soil feature \nvalues changes for stand count prediction. ........................................................\
    \ 89 \nFigure 4.11: Shapley value changes corresponding to the top six important\
    \ soil feature \nvalues changes for canopy size prediction. ........................................................\
    \ 89 \n \nFigure 5.1: Five poster boards painted with different colors. .........................................\
    \ 103 \nFigure 5.2: Dry-wet artificial reference surfaces. ...........................................................\
    \ 103 \nFigure 5.3: Image processing and image feature extraction. (a) Part of\
    \ an orthomosaic \nimage with corresponding row separation by the red lines and\
    \ background \nremoval (b). (c) Illustration of unit area (1 m2) used to extract\
    \ image features \nto generate (d) 152 (or 148) × 315 data points of the UAV image\
    \ features. \nThen the data points were downsampled to 38 (or 37) × 63 data points.\
    \ Each \ndata point corresponded to a 4 m × 5 m area of the field. ...............................\
    \ 104 \nix \n \nFigure 5.4: Temperature of the ground reference boards measured\
    \ by the UAV-based \nthermal camera and handheld thermometer. The numbers above\
    \ the columns \nshow the means of the measurements. .............................................................\
    \ 107 \nFigure 5.5: The Ks maps and the connection method of soil, image features\
    \ and Ks \nmaps. Ks was calculated for each position in the 38 (or 37 in 2018)\
    \ × 63 \nspatial raster with each Ks map representing a day ..........................................\
    \ 113 \nFigure 5.6: Pearson correlation coefficients between soil features. Clay%\
    \ and sand% \nare the average ECa-based clay and sand content in the top two soil\
    \ horizons.\n .........................................................................................................................\
    \ 116 \nFigure 5.7: Kriged maps of clay content in different depth layers. (a)\
    \ to (g) are the soil \nclay% distribution in the field at the seven different\
    \ depths (clay10 – clay70)\n .........................................................................................................................\
    \ 116 \nFigure 5.8: Pearson correlation coefficients between soil features and\
    \ image features. \nNRRE were not available before August of 2018. Thermal data\
    \ were not \navailable in August 2018 and July 2019 ..........................................................\
    \ 118 \nFigure 5.9: Cumulative precipitation and the lowest water stress coefficients\
    \ in each \nday of (a) 2019 and (b) 2018. The black vertical lines mark the starting\
    \ dates \nfor Ks <1. The green lines mark the dates of imaging. Irrigation was\
    \ site-\nspecific and did not show in the figures ..........................................................\
    \ 121 \nFigure 5.10: Ks maps on (a) Aug 8, (b) Aug 10 and (c) Aug 13. The legend\
    \ in (c) is \nalso used in (a)-(b). The white circle in (c) marks a plot that\
    \ had about 22 \nmm irrigation applied on Aug 6. (d) NDVI map collected on Aug\
    \ 14. (e) \nrelationship between NDVI and the Aug 13 Ks map. Different lower-case\
    \ \nletters indicate a significant difference at the 5% level of Tukey’s honest\
    \ \nsignificant difference test. The mean NDVI in Ks levels from 0-0.25 is 0.77,\
    \ \nfrom 0.25-0.5 is 0.86, from 0.5-0.75 is 0.85, from 0.75-1 is 0.89. ..................\
    \ 122 \nFigure 5.11: Temperature of the five color poster boards on each day of\
    \ image \ncollection. .........................................................................................................\
    \ 123 \nFigure 5.12: CWSI maps of Aug. 14 (a) and Sep. 6 (b) in 2019; and Ks maps\
    \ of Aug. \n13 (c) and Sep. 5 (d) in 2019. There was a problem with the camera\
    \ on Sep \n6, 2019 and the images in (d) were lost of the east edge part of the\
    \ field. The \nlegend in (a) is also used in (b), and the legend in (c) is also\
    \ used in (d). The \nblack and white circles mark the regions discussed in the\
    \ text. ...................... 125 \nFigure 5.13: CWSI maps of Jun. 29 (a), Jul.\
    \ 18 (b) and Sep. 15 (c) in 2018; and Ks \nmaps of Jun. 29 (d), Jul. 18 (e) and\
    \ Sep. 15 (f) in 2018. CWSI map of Aug. \n22 in 2018 was not available due to\
    \ a thermal camera problem. The legend \nin (a) is also used in (b) and (c), and\
    \ the legend in (d) is also used in (e) and \n(f). ....................................................................................................................\
    \ 127 \nFigure 5.14: NDVI maps collected on east field in 2019. (a)-(c) NDVI of\
    \ Jul., Aug. \nand Sep in 2019. There was a problem with the camera on Sep 5,\
    \ 2019 and \nthe images in (c) were lost of the east edge part of the field. The\
    \ legend in (c) \nis also used in (a) and (b). (d)-(e) show the NDVI changes from\
    \ Jul. to Aug. \nand Aug. to Sep. in 2019. (f) ECa-based sand% map of the east\
    \ field. ........... 129 \nFigure 5.15: (a)-(c) Histogram of NDVI maps of Jul.,\
    \ Aug. and Sep in 2019. (d)-(e) \nHistogram of NDVI changes from Jul. to Aug.\
    \ and Aug. to Sep. in 2019. ..... 130 \nx \n \nFigure 5.16: (a) Mean NDVI and\
    \ (b) NDVI difference of four sand% content groups \nin 2019. ANOVA test was conducted\
    \ to compare the mean NDVI and its \ndifference in four sand% levels. Different\
    \ lower-case letters indicate a \nsignificant difference at the 5% level of Tukey’s\
    \ honest significant difference \ntest. The results of Sep. 2019 may be misleading\
    \ due to missing NDVI values \non the right side of the field. The sand% groups\
    \ were split based on quartiles \nof the soil data of each side of the field.\
    \ .......................................................... 130 \nFigure 5.17:\
    \ NDVI maps collected on the west field in 2018. (a)-(d) NDVI of Jun., \nJul.,\
    \ Aug. and Sep in 2018. (e)-(g) NDVI changes from Jun. to Jul., July to \nAug.\
    \ and Aug. to Sep. in 2018. (h) ECa-based sand% map of the west field. . 132 \n\
    Figure 5.18: (a)-(d) Histogram of NDVI maps of Jun., Jul., Aug. and Sep in 2018.\
    \ (e)-\n(g) Histogram of NDVI changes from Jun. to Jul., July to Aug. and Aug.\
    \ to \nSep. in 2018. ....................................................................................................\
    \ 133 \nFigure 5.19: (a) Mean NDVI and NDVI difference of four sand% content groups\
    \ in \nthe year 2018. ANOVA test was conducted to compare the mean NDVI in \n\
    different sand% levels. Different lower-case letters indicate a significant \n\
    difference at the 5% level of Tukey’s honest significant difference test. The\
    \ \nsand% groups were split based on quartiles of the soil data of each side of\
    \ \nthe field ............................................................................................................\
    \ 133 \nFigure 5.20: Histogram compares two NDVI images collected by two cameras\
    \ at the \nsame time with (a) full canopy cover and no soil background visible\
    \ and (b) \nnon-full canopy cover and soil background visible. ........................................\
    \ 134 \nFigure 5.21: Soil moisture content (%) in different sand% groups at 4\
    \ different depth \n(0.15, 0.30, 0.45 and 0.60 m) in (a) Jul., (b) Aug. and (c)\
    \ Sep. in 2018 .......... 134 \nFigure 5.22: Heat map for the feature importance\
    \ (%) of soil features and Ks features \nfor each image feature and yield. I_\
    \ Ks: the Ks in the imaging date; T_1: total \ndays having Ks <1; T_0.9_1: total\
    \ days having Ks in [0.9,1]; L_1: the largest \nnumber of continuous days having\
    \ Ks <1; B_1: number of days after planting \nto first instance of Ks <1. Yield_2019_08_2019:\
    \ the Ks features for the 2019 \nyield estimation were calculated from the date\
    \ of planting to the imaging date \nin Aug. The pink and blue boxes mark the values\
    \ described in the text ......... 137 \nFigure 5.23: Feature contribution (%)\
    \ of the five highest and remainder (as ‘others’) \nsoil features and Ks features\
    \ for each image feature and yield in (a) 2019 and \n(b) 2018. XNiteCanonElph130\
    \ camera did not have a red-edge spectral band \nand NDRE was not available in\
    \ July 2018 ....................................................... 139 \n \n\
    Figure 6.1: S_CNN. Soil clay content percentage from different depth were processed\
    \ \nusing a network with two convolution layers. Each color dot was a \nmathematical\
    \ operation result of \U0001D48A\U0001D48A = \U0001D7CF\U0001D7CF\U0001D7CF\U0001D7CF\
    \U0001D498\U0001D498\U0001D48A\U0001D48A × \U0001D499\U0001D499\U0001D48A\U0001D48A\
    \ where xi were the clay \ncontent percentage of each layer and the wi were the\
    \ weights obtained by \ntraining from the data set provided. .................................................................\
    \ 159 \nFigure 6.2: The illustration of the developed W_CNN. Weekly weather data\
    \ from May \n1 to Oct. 29 were used. The first 13 weeks related to date from May\
    \ 1 to Jul. \n30, week14-week18 related to date from Jul. 31 to Sep. 3, week19-week22\
    \ \nrelated to date from Sep. 4 to Oct. 1 and week 23 to week 26 related to date\
    \ \nfrom Oct. 2 to Oct. 29. The meanings of the abbreviations of the weather \n\
    xi \n \nfeatures are: P- total precipitation (irrigation data was included), Tmax-\
    \ max \nair temperature, Tmin- min air temperature, SR- total solar radiation,\
    \ VP- \nvapor pressure, and ETo- evapotranspiration for reference crop. W1-W26\
    \ \nmean week1-week26 after planting. ................................................................\
    \ 160 \nFigure 6.3: The explanation of GRU. (a) GRU continuously accepts inputs\
    \ from a \nsequence. To easily understand the loop operation in the GUR, the GRU\
    \ was \ndrawn with the unfolded way in this paper. The ‘t’ represented each time\
    \ step. \n(b) The architecture of GRU related to Eq. 5.1-5.44. ......................................\
    \ 162 \nFigure 6.4: The architecture of the GRU network. SL means sequence length,\
    \ which \nwas set as 1 in this study. BZ is the batch size for the training procedure.\
    \ FCL \nmeans fully connected layer, which conducted another mathematical \noperation\
    \ of \U0001D48A\U0001D48A = \U0001D7CF\U0001D7CF\U0001D48F\U0001D48F\U0001D498\
    \U0001D498\U0001D48A\U0001D48A × \U0001D499\U0001D499\U0001D48A\U0001D48A . The\
    \ yellow GRU was the same loop \nprocessing unit in the network and has the same\
    \ parameters, as well as all the \ngreen FCL_1 unit. ............................................................................................\
    \ 164 \nFigure 6.5: Yield data distributions in 2017E, 2018W, 2019E and 2019W.\
    \ KDE: kernel \ndensity estimation. ...........................................................................................\
    \ 169 \nFigure 6.6: Yield comparison of different years in the same positions\
    \ as well as the \naverage yield in different sand% groups of these three years.\
    \ (a) Comparing \nthe yield in 2017 and 2019 in the east side of the field; (b)\
    \ comparing the \nyield in 2018 and 2019 in the west side of the field; (c) yield\
    \ difference \nbetween 2017E and 2019E in different sand% groups; (d) yield difference\
    \ \nbetween 2018W and 2019W in different sand% groups. Different lower-case \n\
    letters indicate a significant difference at the 5% level of Tukey’s Honest \n\
    significant difference test with ‘a’ the largest mean yield and ‘d’ the smallest\
    \ \nmean yield. .......................................................................................................\
    \ 169 \nFigure 6.7: Relationships between NDVI and yield in different years: (a)\
    \ quadratic \nrelationship between NDVI collected in Aug. 2019 and yield in 2019;\
    \ (b) \nrelationship between NDVI collected in Aug. 2017 with yield was more \n\
    likely be a linear relationship. To avoid the effects of different multispectral\
    \ \nsensors, all the NDVI and yield were normalized as (x-mean)/std. ................\
    \ 171 \nFigure 6.8: Yield prediction results. (a) The data set of 2019E and 2018W\
    \ were used \nfor training to predict the yield in 2017E; (b) The data set of\
    \ 2019E, 2019W \nand 2017E were used for training to predict the yield in 2018W;\
    \ (c) The data \nset of 2019W, 2018W and 2017E were used for training to predict\
    \ the yield \nin 2019E; (d) The data set of 2019E, 2018W and 2017E were used for\
    \ \ntraining to predict the yield in 2019W. Note, no image NDVI was available\
    \ \nin 2019W and the result in (d) is equal to the result of WO_TF_test. .............\
    \ 173 \nFigure 6.9: Yield prediction performance of models that excluded each\
    \ of the \ncomponents of  S_CNN, W_CNN, GRU unit, image NDVI and TF described\
    \ \nin Table 7. (a) The MAE and R2 of WO_S_CNN, WO_W_CNN, \nWO_TF_Test and WO_TF_Train;\
    \ (b) MAE and R2 of  WO_S2Y, WO \n_GRU, WO_GRU_NDVI and WO_GRU_NDVI_W. Note, no\
    \ image NDVI \nwas available in 2019W. ..................................................................................\
    \ 174 \nFigure 6.10: Yield prediction performance of models with different kernel\
    \ numbers in \nS_CNN and W_CNN. ......................................................................................\
    \ 175 \nxii \n \nFigure 6.11:  The NDVI and yield of (a) 2017E and (b) 2019E.\
    \ The multispectral \ncamera in Sep. 2019 had some problems and the data of the\
    \ right side of the \nfield were lost (the NDVI in the right of the white line\
    \ was the predicted \nNDVI from the GRU network). The black circles make the regions\
    \ that had \nmore yield in 2019 while the pink circles mark the regions that had\
    \ more \nyield in 2017. The white circles mark the regions of how NDVI changed\
    \ \nfrom July to Sep. of the yield difference regions between 2017 and 2019. All\
    \ \nthe NDVI were normalized and the absolute values did not have physical \n\
    meanings. The legend of NDVI was the same in all the NDVI maps. The \nlegend of\
    \ yield was the same in all the yield maps. I: irrigation applied......... 177\
    \ \nFigure 6.12: The NDVI and yield of (a)2018W and (b) 2019W. The black circles\
    \ make \nthe regions that having more yield in 2019 than in 2018. All the NDVI\
    \ were \nnormalized and the absolute values did not have physical meanings. The\
    \ \nlegend of NDVI was the same in all the NDVI maps. The legend of yield was\
    \ \nthe same in all the yield maps. S: regions with 55%-75% sand content. ........\
    \ 178 \n \n \nxiii \n \nLIST OF TABLES \nTable 3. 1: Weather conditions during\
    \ imaging measured by the nearby weather station\n ...........................................................................................................................\
    \ 32 \nTable 3.2: Mean and standard deviation of row spacing of edge and middle\
    \ rows in \nimages. The resampling t-test indicates that there was no significant\
    \ \ndifference (p-value < 0.05) in row spacing among the rows at different \n\
    locations of images. ...........................................................................................\
    \ 40 \nTable 3.3: Accuracy and computation resources comparison ..........................................\
    \ 51 \n  \nTable 4.1: Pearson correlation coefficients between emergence (stand\
    \ count and \nseedling size) and image features collected on July 12, 2019 and\
    \ the final \nyield in 2019. .....................................................................................................\
    \ 90 \n \nTable 5.1: Specifications of the cameras used in the study ............................................\
    \ 101 \nTable 5.2: Weather conditions during imaging. The values are the means\
    \ and standard \ndeviations from 11 am to 2 pm of the imaging days .......................................\
    \ 101 \nTable 5.3: Image features from the three cameras used in this study .............................\
    \ 106 \nTable 5.4: Mean and standard deviation of the moisture content of 28 soil\
    \ samples in \nthe top 0-0.075 and 0.075-0.15 m ....................................................................\
    \ 117 \nTable 5.5: R2 for each image features predicted by soil features and Ks\
    \ features on the \ntest set ..............................................................................................................\
    \ 135 \n \nTable 6.1: Yield prediction models with the removal of the five important\
    \ components\n .........................................................................................................................\
    \ 166 \nTable 6.2: Pearson correlation coefficients (r) between yield and soil\
    \ features. ............ 168 \nTable 6.3: Pearson correlation coefficients (r)\
    \ between yield and image NDVI \nrespectively ......................................................................................................\
    \ 170 \n \n \n \nxiv \n \nLIST OF ABBREVIATIONS \nAGL \nAbove Ground Level \n\
    ANOVA \nAnalysis of Variance \nAPI \nApplication Programming Interface \nCDT \n\
    Central Daylight Time \nCNN \nConvolutional Neural Network \nCWSI \nCrop Water\
    \ Stress Index \nDAP \nDay After Planting \nDL \nDeep Learning \nDSM \nDigital\
    \ Surface Model \nET \nEvapotranspiration \nExG \nExcess Green Index \nGDD \n\
    Growing Degree Days \nGNDVI \nGreen NDVI \nGNSS \nGlobal Navigation Satellite\
    \ System \nGRP \nGround Reference Point \nGRU \nGated Recurrent Units \nGSD \n\
    Ground Sampling Distance \nKNN \nK-Nearest Neighbors \nLSTM \nLong Short-Term\
    \ Memory network \nMAE \nMean Absolute Error \nMAPE \nMean Absolute Percentage\
    \ Error \nxv \n \nNDVI \nNormalized Difference Vegetation Index \nNIR \nNear-Infrared\
    \ \nPVC \nPolyvinyl Chloride \nR2 \nCorrelation of Determination \nReLU \nRectified\
    \ Linear Unit \nRGB \nRed-Green-Blue \nRNN \nRecurrent Neural Network \nROI \n\
    Region of Interest \nRTK \nReal Time Kinematics \nSfM \nStructure from Motion\
    \ \nSHT \nStandard Hough transform \nSSD \nSolid-State Drive \nSURF \nSpeeded-Up\
    \ Robust Features \nUAV \nUnmanned Aerial Vehicle \nVI \nVegetation Index \nVRI\
    \ \nVariable Rate Irrigation \nWAAS \nWide Area Augmentation System \n \n \nxvi\
    \ \n \nQUANTIFYING THE EFFECT OF ENVIRONMENTS ON CROP \nEMERGENCE, DEVELOPMENT\
    \ AND YIELD USING SENSING AND \nDEEP LEARNING TECHNIQUES \nAijing Feng \nDr. Jianfeng\
    \ Zhou, Dissertation Supervisor \nABSTRACT \nThe world population is estimated\
    \ to increase by 2 billion in the next 30 years, and \nglobal crop production\
    \ needs to double by 2050 to meet the projected demands from rising \npopulation,\
    \ diet shifts, and increasing biofuels consumption. Improving the production of\
    \ \nthe major crops has become an increasing concern for the global research community.\
    \ \nHowever, crop development and yield are complex and determined by many factors,\
    \ such \nas crop genotypes (varieties), growing environments (e.g., weather, soil,\
    \ microclimate and \nlocation), and agronomic management strategies (e.g., seed\
    \ treatment and placement, \nplanting, fertilizer and pest management). To develop\
    \ next-generation and high-efficiency \nagriculture production systems, we will\
    \ have to solve the complex equation consisting of \nthe interactions of genotype,\
    \ environment and management (G×E×M) using emerging \ntechnologies. Precision\
    \ agriculture is a promising agriculture practice to increase \nprofitability\
    \ and reduce environmental impact using site-specific and accurate \nmeasurement\
    \ of crop, soil and environment. The success of precision agriculture \ntechnology\
    \ heavily relies on access to accurate and high-resolution spatiotemporal data\
    \ and \nreliable prediction models of crop development and yield. \nSoil texture\
    \ and weather conditions are important factors related to crop growth and \nyield.\
    \ The percentages of sand, clay and silt in the soil affect the movement of air\
    \ and \nwater, as well as the water holding capacity. Weather conditions, including\
    \ temperature, \nxvii \n \nwind, humidity and solar irradiance, are determining\
    \ factors for crop evapotranspiration \nand water requirements. Compared to crop\
    \ yield, which is easy to measure and quantify, \ncrop development effects due\
    \ to the soil texture and weather conditions within a season \ncan be challenging\
    \ to measure and quantify. Evaluation of crop development by visual \nobservation\
    \ at field scale is time-consuming and subjective. In recent years, sensor-based\
    \ \nmethods have provided a promising way to measure and quantify crop development.\
    \ \nUnmanned aerial vehicles (UAVs) equipped with visual sensors, multispectral\
    \ sensors \nand/or hyperspectral sensors have been used as a high-throughput data\
    \ collection tool by \nmany researchers to monitor crop development efficiently\
    \ at the desired time and at field-\nscale. \nIn this study, UAV-based remote\
    \ sensing technologies combining with soil texture \nand weather conditions were\
    \ used to study the crop emergence, crop development and yield \nunder the effects\
    \ of varying soil texture and weather conditions in a cotton research field. \n\
    Soil texture, i.e., sand and clay content, calculated using apparent soil electrical\
    \ \nconductivity (ECa) based on a model from a previous study, was used to estimate\
    \ soil \ncharacteristics, including field capacity, wilting point and total available\
    \ water. Weather \ndata were obtained from a weather station 400 m from the field.\
    \ UAV imagery data were \ncollected using a high-resolution RGB camera, a multispectral\
    \ camera and a thermal \ncamera from the crop emergence to before harvesting on\
    \ a monthly basis. An automatic \nmethod to count emerged crop seedlings based\
    \ on image technologies and a deep learning \nmodel was developed for near real-time\
    \ cotton emergence evaluation. The soil and \nelevation effects on the stand count\
    \ and seedling size were explored. The effects of soil \ntexture and weather conditions\
    \ on cotton growth variation were examined using \nxviii \n \nmultispectral images\
    \ and thermal images during the crop development growth stages. The \ncotton yield\
    \ variations due to soil texture and weather conditions were estimated using \n\
    multiple-year UAV imagery data, soil texture, weather conditions and deep learning\
    \ \ntechniques. \nThe results showed that field elevation had a high impact on\
    \ cotton emergence \n(stand count and seedling size) and clay content had a negative\
    \ impact on cotton emergence \nin this study. Monthly growth variations of cotton\
    \ under different soil textures during crop \ndevelopment growth stages were significant\
    \ in both 2018 and 2019. Soil clay content in \nshallow layers (0-40 cm) affected\
    \ crop development in early growth stages (June and July) \nwhile clay content\
    \ in deep layers (40-70 cm) affected the mid-season growth stages \n(August and\
    \ September). Thermal images were more efficient in identifying regions of \n\
    water stress compared to the water stress coefficient Ks calculated using data\
    \ of soil texture \nand weather conditions. Results showed that cotton yield for\
    \ each one of the three years \n(2017-2019) could be predicted using the model\
    \ trained with data of the other two years \nwith prediction errors of MAE = 247\
    \ (8.9%) to 384 kg ha-1 (13.7%), which showed that \nquantifying yield variability\
    \ for a future year based on soil texture, weather conditions and \nUAV imagery\
    \ was feasible. Results from this research indicated that the integration of soil\
    \ \nand weather information and UAV-based image data is a promising way to understand\
    \ the \neffects of soil and weather on crop emergence, crop development and yield.\
    \ \n \n \n1 \n \nChapter 1. INTRODUCTION \n1.1 Problem Statement \nCrop production\
    \ is the function of genotype, environment and management \n(Hatfield and Walthall,\
    \ 2015). With the development of urbanization, the available \ncultivated land\
    \ is reducing in recent decades. Moreover, long-term cultivation leads to a \n\
    decline in soil quality (e.g. soil erosion, salinization, nutrient reduction),\
    \ which affects \nfuture cultivation (Pennock et al., 2015). Because of the worsening\
    \ environmental \nproblems, freshwater resources are becoming more and more precious.\
    \ Faced with the \nrapid growth of population, increasing crop yield using less\
    \ freshwater resources, less input \nunder the current situation of soil resources\
    \ and cultivated land is an important topic. \nTimely monitoring of crop development\
    \ and accurate estimation of yield are \nimportant to help improving field management\
    \ and crop production. The information \nobtained from different crop growth stages\
    \ can be used to explore environmental impacts \nand nutrient deficiencies. For\
    \ example, Holman et al. (2016) monitored the wheat plant \nheight in five days\
    \ and found out that the growth rates range from -13 mm /day to 17 mm \n/day subject\
    \ to four different nitrogen fertilizer treatments. Farmers could understand the\
    \ \ngrowth status of crops and make management adjustments through monitoring\
    \ crop growth \nin critical multi-temporal growth stages.  \nWeather, soil texture\
    \ and irrigation treatment affect crop development and yield. \nSoil texture type\
    \ is an important soil property related to crop growth (Scherer et al., 2017).\
    \ \nThe size of solid particles can be used to classify soil texture as clay (less\
    \ than 0.002 mm), \nsilt (from 0.002 mm to 0.05 mm) and sand (from 0.05 mm to\
    \ 2 mm). The percentage of \n2 \n \nsand, clay and silt content in the soil would\
    \ affect the movement of air and water, as well \nas the water holding capacity.\
    \ \nCompared to the crop yield, which is easy to measure and quantify, crop \n\
    development effects due to the soil texture and weather conditions within a growing\
    \ season \ncould be challenging to measure and quantify. Evaluation of crop development\
    \ by visual \nobservation in field-scale is time-consuming and subjective. In\
    \ recent years, sensor-based \nmethods have provided a promising way to measure\
    \ and quantify crop development \n(Bendig et al., 2015; Hunt et al., 2013). Vegetation\
    \ indices (VIs) such as normalized \ndifference vegetation index (NDVI), chlorophyll\
    \ vegetation index, triangular greenness \nindex, and green red vegetation index\
    \ can be used to quantify the crop growth status \nobjectively. In remote sensing\
    \ applications, VIs have been widely used for qualitative and \nquantitative evaluation\
    \ of vegetation cover and its growth. In the visible range of light \n(spectral),\
    \ the reflectance of green light (as shown in Figure 1.1) of plants is higher\
    \ than \nthat of blue and red (R). Red-edge and near-infrared (NIR) were 2 kinds\
    \ of invisible light \n(as shown in Figure 1.1), which are in 700-800nm and 800-1000nm.\
    \ Plants have higher \nreflectance near the infrared, which is obviously different\
    \ from the reflection of soil \n(similar reflectance from 400 nm to 1000 nm).\
    \ Moreover, different plants or those in \ndifferent growth conditions reflect\
    \ different values at red-edge. The slope of the reflection \ncurve of crops in\
    \ the red-edge range can reflect the growth states of crops. Thus, the red-\n\
    edge and near-infrared spectral region are of critical importance to describe\
    \ crop traits \ncomparing to visual wavelengths. The difference between NIR and\
    \ R reflection of healthy \ngreen vegetation is relatively large because R is\
    \ strongly absorbed by green plants, while \nNIR is the high reflection and high\
    \ transmittance, which means that the healthier plants \n3 \n \nhave larger NDVI\
    \ values (the equation is listed in Table 5.3). NIR and R of rock or bare \nsoil\
    \ are close to each other, so their NDVI was close to 0. Negative NDVI values\
    \ indicated \nthe effects of light and clouds. As for GNDVI (the equation is listed\
    \ in Table 5.3), the green \nchannel is more linked to the chlorophyll and nitrogen\
    \ content of plants, so it can use to \nestimate vegetation biomass and leaf area\
    \ index (Hunt et al., 2011). A study found that \nboth NDVI and GNDVI were reliable\
    \ predictors for forage biomass, forage N uptake, grain \nyield, grain N uptake\
    \ in winter wheat (Moges et al., 2005). As for NDRE (the equation is \nlisted\
    \ in Table 5.3), a study used it as a Canopy Chlorophyll Content Index (CCCI)\
    \ to \nestimate water and nitrogen stress (Barnes et al., 2000). Unmanned aerial\
    \ vehicles (UAVs) \nequipped with visual sensors, multispectral sensors and/or\
    \ hyperspectral sensors have been \nused as a high-throughput data collection\
    \ tool by many researchers to monitor crop \ndevelopment at the desired time efficiently\
    \ at field-scale (Turner, Lucieer, Malenovský, \nKing, & Robinson, 2014).  \n\
    \ \n \n \n4 \n \nFigure 1.1: Spectral reflection of healthy plants, unhealthy\
    \ plants and soil (Chang et al., \n2013) \n1.2 Literature review \nSoil and weather\
    \ affect crop emergence, development and yield \nSince soil texture affects soil\
    \ water holding capacity, it is one of the more important \nfactors that affecting\
    \ crop development and yield. Forcella et al. (2000) reported that soil \ntexture\
    \ and soil water content affected seedling emergence date and emergence rate.\
    \ Soil \ntexture and soil water content also affected root development (Oosterhuis,\
    \ 1990). Allen et \nal. (1998) pointed out that during the growing season, weather\
    \ conditions (i.e. daily \ntemperature, wind speed, relative humidity and solar\
    \ irradiance) at different crop growth \nstages affected the crop evapotranspiration\
    \ (ET) and water requirements. Models \ncalculating the ET (FAO-56) provided in\
    \ Allen et al. (1998) based on the soil, weather and \ncrop growth are widely\
    \ used for irrigation design and schedule, which calculate from ETo, \ncrop coefficient\
    \ Kc and water stress coefficient Ks. Once the water content in the soil cannot\
    \ \nsatisfy the crop water requirements, crop development would be influenced\
    \ and those \ninfluences would eventually be reflected in yield. Many studies\
    \ found that soil texture (or \nsoil ECa) was related to the yield of cotton (Vories\
    \ et al., 2020), corn (Kitchen et al., 2003; \nKitchen et al., 2005) and soybean\
    \ (Jiang and Thelen, 2004; Kitchen et al., 2005).  \nDaily weather data determine\
    \ the water loss due to soil evaporation (E) and crop \ntransportation (T) (Allen\
    \ et al., 1998). Weather parameters of radiation and air temperature \nprovide\
    \ energy for ET, air humidity affects the water stored capability in the air,\
    \ and wind \nspeed that affects the capability of water removal (Allen et al.,\
    \ 1998). Models such as \nPenman-Monteith (PM) model, Hargreaves–Samani (HS) model\
    \ and Priestly–Taylor (PT) \n5 \n \nmodel were widely used for calculating ET\
    \ based on daily weather parameters (Chia et al., \n2020). Weather conditions\
    \ of temperature, precipitation and solar radiation had been shown \nto be important\
    \ effects for yield variability of maize and winter wheat between years \n(Ceglar\
    \ et al., 2016). Addy et al. (2020) showed that the functional response of crop\
    \ yield \nto nitrogen application rate varied under different weather conditions\
    \ between years. Addy \net al. (2020) showed that the cereal grain yield had different\
    \ responses to nitrogen \napplication under various weather conditions during\
    \ 1968-2016. Tremblay et al. (2012) \nshowed that weather conditions could influence\
    \ the corn response to nitrogen. Battisti et \nal. (2018) showed that weather\
    \ condition was an important component for soybean yield \nestimation. Van Bussel\
    \ et al. (2016) used weather data for long-term (30 years) wheat yield \nestimation.\
    \ \nSensor networks for crop monitoring \nTo explore the soil and weather effects\
    \ on crop development and yield, data related \nto soil texture, weather and crop\
    \ development states are required. Sensor-based in-field \nmeasurement networks\
    \ were used for data collection and analysis for crop development \nmonitoring\
    \ due to different environmental conditions.  \nSoil texture usually is determined\
    \ by laboratory analysis, which analyzes the sand, \nclay and silt content. Sensor-based\
    \ in-field measurements to determine the soil texture have \nbeen used by some\
    \ researchers. For example, Sudduth et al. (2005), Stępień et al. (2015) \nand\
    \ James et al. (2003) reported that the apparent electrical conductivity (ECa)\
    \ measured \nby mobile sensors was related to clay, sand and silt content. Compared\
    \ to the traditional \nlaboratory methods, sensor-based methods had the advantage\
    \ of providing dense datasets \nat a lower cost and high efficiency (Sudduth et\
    \ al., 2005).  \n6 \n \nCrop growth can be monitored with remotely sensed data\
    \ acquired at various \nplatforms (Cheng et al., 2016). Some researchers monitored\
    \ crop in a large-scale area \nthrough vegetation indices of satellite images\
    \ (e.g. NDVI, GNDVI) using vegetation \nindices (Fermont and Benson, 2011). Satellite\
    \ images are limited by low resolution, the \ninfluence of the cloud, and predetermined\
    \ data collection times. The resolution of satellite \nimages is generally not\
    \ high enough for accurate yield estimation. For example, the \nresolution of\
    \ free or affordable multispectral satellite images such as Sentinel-2 is around\
    \ \n10 m (Liu, Wang, Skidmore, & Liu, 2018; Singhal, Bansod, Mathew, & Taneja,\
    \ 2018). \nCommercial sources such as WorldView-3 provide panchromatic imagery\
    \ with a 0.31 m \nresolution and multispectral imagery with a 1.24 m resolution\
    \ (Rahman, Robson, & \nBristow, 2018). However, it is a challenge to acquire images\
    \ at the desired time of day, \nsuch as noon when plants may show more symptoms\
    \ of stresses. For thermal images, the \nresolution is about 60 m -100 m from\
    \ Landsat (Amazirh et al., 2018) and ASTER (Zhang \net al., 2017) which is not\
    \ sufficient for precision decision making in sub-field management \nzones. Meanwhile,\
    \ atmospheric factors, such as clouds and humidity, make it challenging \nto utilize\
    \ satellite images for the collection of dynamic and high-resolution crop \ninformation\
    \ for field management.  \nGround-based platforms were also used to monitor crop\
    \ growth by some studies. \nFor example, Ni et al. (2018) used a handhold system\
    \ equipped with a multispectral sensor \nto monitor wheat canopy spectral reflectance.\
    \ The advantage of the extremely high \nresolution of the ground-based platforms\
    \ makes them good tools to assess crop emergence. \nFor example, Jin et al. (2017)\
    \ and Liu et al. (2017) used ground vehicle-based imaging \nsystems to assess\
    \ wheat stand count in field conditions. However, ground vehicle-based \n7 \n\
    \ \nsystems have many limitations when they are used in full-scale crop production,\
    \ such as \nbeing slow and affected by ground conditions (e.g., wet soil or narrow-row\
    \ cropping \nsystems). \nField monitoring with UAV integrated with remote sensors\
    \ are increasingly used \nin agriculture recently due to the ultra-high spatial\
    \ frequencies and efficiency of the UAV \nsensing systems (Yang et al., 2017).\
    \ Some examples include the assessment of wheat \ndensity (Jin et al., 2017; Sankaran\
    \ et al., 2015a), cotton uniformity (Feng et al., 2020), and \nstand count in\
    \ cotton (Chen et al., 2018; Feng et al., 2020), corn (Varela et al., 2018), potato\
    \ \n(Sankaran et al., 2017) and rapeseed (Zhao et al., 2018). Equipped with proper\
    \ sensors, \nUAV-based remote sensing systems are able to provide low-cost and\
    \ high-resolution \ndigital surface models (DSMs) and orthomosaic images for researchers\
    \ and farmers in a \ntimely manner (Yang et al., 2017). Du and Noguchi (2017)\
    \ used a UAV equipped with an \nRGB camera to monitor wheat growth status and\
    \ estimate yield. UAV can also be used to \nmonitor e.g. canopy cover (Chu et\
    \ al., 2016), crop height (Chang et al., 2017), germination \nrate (Chen et al.,\
    \ 2015). Studies have also used UAV-based remote sensing technologies \nto estimate\
    \ crop evaporation (Hoffmann et al., 2016b) and crop water status (Romero et al.,\
    \ \n2018) and have quantified water stress (Gago et al., 2017; Hoffmann et al.,\
    \ 2016a; Zhang \net al., 2019). These studies explored the relationships between\
    \ VIs and evapotranspiration \n(latent heat flux) calculated by energy balance\
    \ models, water status measured by pressure \nbomb, ground measured stomatal conductance\
    \ and sap flow under different irrigation \ntreatments. \nCrop monitoring using\
    \ multi-temporal UAV-based image data attracted a lot of \nattention recently.\
    \ Multi-temporal image data were mainly used to monitor the growth \n8 \n \nchanges\
    \ between different growth stages. The growth changes would be different based\
    \ on \nthe different treatment of the crops. For example, different nitrogen fertilizer\
    \ treatments \n(Yue et al., 2018), different varieties (Pádua et al., 2018), different\
    \ irrigation treatment \n(Dayananda et al., 2019), conventional tillage and no-tillage\
    \ system (Ashapure et al., 2019), \ndifferent field elevation and different planting\
    \ date (Yang et al., 2019). By comparing the \ngrowth changes, the effect of those\
    \ different treatments could be explored. The built multi-\ntemporal model could\
    \ also use to estimate yield (Yang et al., 2019), biomass (Dayananda \net al.,\
    \ 2019) and chlorophyll content (Aasen and Bolten, 2018).  \n1.3 Problems not\
    \ been solved \nThe need for rapid and accurate emergence assessment in early\
    \ stage \nMany UAV image studies used similar approaches to process UAV imagery\
    \ data, \ni.e., using commercial UAV image processing software, such as Agisoft\
    \ PhotoScan \n(Agisoft LLC, St. Petersburg, Russia) and Pix4D (Pix4D S.A., Lausanne,\
    \ Switzerland), to \ngenerate orthomosaic images before further processing. The\
    \ procedure of generating \northomosaic images includes image feature detection,\
    \ matching, alignment and blending \nbased on mosaic blending models as described\
    \ by Brown and Lowe (2003), which may \ntake a very long time (days or weeks)\
    \ and require extensive computational resources. For \nexample, it took more than\
    \ two weeks to develop an orthomosaic image using 2000 images \nof 4864 × 3648\
    \ pixels using Agisoft in one of our projects. The software was running in a \n\
    workstation desktop computer (Model Dell Precision Tower 5810, Dell, Round Rock,\
    \ TX, \nUSA) configured with an Intel Xeon E5 (1630 v3) 3.70 GHz central processing\
    \ unit (CPU), \n32GB random-access memory (RAM) and an NVIDIA Quadro K1200 4GB\
    \ graphics \nprocessing unit (GPU). Crop seedlings are usually small and require\
    \ high-resolution \n9 \n \nimages to capture sufficient information, which results\
    \ in a large number of images for \nmosaic processing and makes it challenging\
    \ to make timely decisions. The challenge in the \ntimely processing of imagery\
    \ data becomes one of the most critical barriers for adopting \nUAV imagery in\
    \ applications of crop emergence assessment (Forcella et al., 2000; Supak, \n\
    1990). Although leveraging high-performance computing or cloud computing resources\
    \ \nmay provide an alternative solution, it requires expensive and complicated\
    \ infrastructure \nthat may not be feasibly or economically accessible by most\
    \ users. Therefore, there is a \npressing need to develop a cost-effective solution\
    \ for timely image processing and real-\ntime decision making. \nCurrent studies\
    \ related to crop emergence using UAV imagery focus on stand count \nand uniformity\
    \ (Feng et al., 2020). Crop seedlings were usually segmented by their \nmorphological\
    \ features from the images to estimate the number of seedlings in a certain \n\
    row length or area. The image features include canopy area (total number of green\
    \ pixels) \n(Gnädinger and Schmidhalter, 2017), leaf polygons (Chen et al., 2018),\
    \ and major axis \nlength (Jin et al., 2017; Zhao et al., 2018). Developing seedling\
    \ templates based on the \nstatistical analysis of seedling geometric shape that\
    \ is then matched with every single plant \nin images is another way to count\
    \ seedlings (Koh et al., 2019). However, the shape, size \nand overlap of individual\
    \ seedlings may vary in a large range (Zhao et al., 2018) due to the \nvariation\
    \ in soil conditions (moisture, temperature, nutrients), cropping system, planting\
    \ \ndepth and seed quality (Egli and Rucker, 2012; Feng et al., 2020). Simple\
    \ image features \nor their combinations are not sufficient to identify seedlings\
    \ accurately, which will result \nin large errors in the evaluation of stand count.\
    \ In addition, most of the published studies \nused seedling clusters (overlapped\
    \ seedlings) as regions of interest (RoIs) and then \n10 \n \ndeveloped classification\
    \ models to estimate the number of seedlings in each RoI. However, \nFeng et al.\
    \ (2020) found that the number of plants in each RoI was unbalanced and most \n\
    of the RoIs contained one or two seedlings with only a few RoIs containing three\
    \ or four \nseedlings. Unbalanced data sets could affect the estimation accuracy\
    \ (Chawla, 2009); \nhowever, this effect can be potentially reduced by using regression\
    \ models (Ribera et al., \n2017). \nThe need of quantifying the effects of soil,\
    \ water and weather on plant growth and \nyield \nEven though studies had shown\
    \ that soil and weather affect crop development and \nyield, the combined effects\
    \ of soil and weather on crops are complicated. Crops showed a \ndifferent level\
    \ of weather-sensitive in different regions (Mathieu and Aires, 2018) and \ndifferent\
    \ growth stages (Addy et al., 2020; Ceglar et al., 2016). Crop development and\
    \ \nyield also showed different dependence on soil under different years’ weather\
    \ conditions \n(Feng et al., 2021). Studies had developed many crop models from\
    \ regions to the global to \nquantify crop development and yield based on weather\
    \ and soil (Van Bussel et al., 2016). \nThe development of those models required\
    \ more than 10 years of data and generally needed \na recalibration when used\
    \ in other regions (Ceglar et al., 2016). Khaki et al. (2020) and \nKhaki and\
    \ Wang (2019) developed yield prediction models based on weather and soil that\
    \ \ncan work for different states of the USA but needed data of 35 years and 9\
    \ years \nrespectively. \nEvaluation of high-resolution spatiotemporal crop, soil\
    \ and weather \nMost of the available literature focusing on a single sensor (RGB\
    \ or multispectral \ncameras). Some researchers have noticed the prospect of multi-sensors\
    \ for precision \n11 \n \nagriculture. Busemeyer et al. (2013) mentioned that\
    \ a single sensor showed constraints in \nthe determination accuracy of more complex\
    \ traits like biomass yield. No thermal multi-\ntemporal images or multi-sensors\
    \ were used in the above literature. The effect of soil \ntexture and weather\
    \ on crop development from emergence to harvest has not been \nsufficiently investigated.\
    \ \nIntegration of emerging data analysis techniques: machine learning and deep\
    \ learning \nAdvanced data processing technology, deep learning (DL), has been\
    \ increasingly \nused to process imagery data collected in agricultural applications\
    \ this decade (Kamilaris \nand Prenafeta-Boldú, 2018). Deep learning models have\
    \ been used to extract hidden \ninformation from imagery data collected by satellites,\
    \ UAVs and ground robotic systems \nto monitor crop development and predict yield\
    \ (Humphrey et al., 2012; Nanni et al., 2017). \nIn addition, the multilayer structure\
    \ of DL models works well for complex nonlinear \nproblems (Nielsen, 2015). However,\
    \ high accuracy prediction and explainable models are \nstill not exploring enough\
    \ under various agriculture application (Adão et al., 2017; \nKamilaris and Prenafeta-Boldú,\
    \ 2018). \n1.4 Goals of the study \nThe goal of this study is to quantify the\
    \ effects of soil and weather conditions on \ncrop emergence, crop development\
    \ and yield using sensing and data analytic technologies. \nThis study tried to\
    \ focus on the technologies and methods for extracting features of the \ncrop,\
    \ soil and weather from different sensing systems and tried to use the integrated\
    \ data \nof soil, weather and images to understand the soil and weather effects\
    \ on crop emergence, \ncrop development and yield.  \n12 \n \nThe specific objectives\
    \ included:  \n1) Methods to characterize crop development and yield using UAV-based\
    \ remote \nsensing and deep learning technologies; \n2) Fusion of different spatiotemporal\
    \ resolution soil, weather and images data; \n3) Quantification of soil and weather\
    \ effects on crop development and yield. \nThe study would organize the above\
    \ contents as four majority Chapters: emergence \nevaluation study as described\
    \ in Chapter 3, soil and elevation effects on crop emergence as \ndescribed in\
    \ Chapter 4, crop development monitoring study as described in Chapter 5, and\
    \ \nyield estimation study as described in Chapter 6. \n1.5 Literature cited \n\
    Aasen, H., Bolten, A., 2018. Multi-temporal high-resolution imaging spectroscopy\
    \ with \nhyperspectral 2D imagers–From theory to application. Remote sensing of\
    \ \nenvironment 205, 374-389. \nAdão, T., Hruška, J., Pádua, L., Bessa, J., Peres,\
    \ E., Morais, R., Sousa, J., 2017. \nHyperspectral imaging: a review on Uav-based\
    \ sensors, data processing and \napplications for agriculture and forestry. Remote\
    \ Sensing 9, 1110. \nAddy, J.W., Ellis, R.H., Macdonald, A.J., Semenov, M.A.,\
    \ Mead, A., 2020. Investigating \nthe effects of inter-annual weather variation\
    \ (1968–2016) on the functional \nresponse of cereal grain yield to applied nitrogen,\
    \ using data from the Rothamsted \nLong-Term Experiments. Agricultural and Forest\
    \ Meteorology 284, 107898. \nAllen, R., Pereira, L., Raes, D., Smith, M., 1998.\
    \ Crop evapotranspiration-Guidelines for \ncomputing crop water requirements-FAO\
    \ Irrigation and drainage paper 56. Fao, \nRome 300, D05109. \n13 \n \nAshapure,\
    \ A., Jung, J., Yeom, J., Chang, A., Maeda, M., Maeda, A., Landivar, J., 2019.\
    \ \nA novel framework to detect conventional tillage and no-tillage cropping system\
    \ \neffect on cotton growth and development using multi-temporal UAS data. ISPRS\
    \ \nJournal of Photogrammetry and Remote Sensing 152, 49-64. \nBarnes, E., Clarke,\
    \ T., Richards, S., Colaizzi, P., Haberland, J., Kostrzewski, M., Waller, \nP.,\
    \ Choi, C., Riley, E., Thompson, T., 2000. Coincident detection of crop water\
    \ \nstress, nitrogen status and canopy density using ground based multispectral\
    \ data, \nProceedings of the Fifth International Conference on Precision Agriculture,\
    \ \nBloomington, MN, USA. \nBattisti, R., Bender, F.D., Sentelhas, P.C., 2018.\
    \ Assessment of different gridded weather \ndata for soybean yield simulations\
    \ in Brazil. Theoretical and Applied \nClimatology. \nBendig, J., Yu, K., Aasen,\
    \ H., Bolten, A., Bennertz, S., Broscheit, J., Gnyp, M.L., Bareth, \nG., 2015.\
    \ Combining UAV-based plant height from crop surface models, visible, \nand near\
    \ infrared vegetation indices for biomass monitoring in barley. \nInternational\
    \ Journal of Applied Earth Observation and Geoinformation 39, 79-\n87. \nBusemeyer,\
    \ L., Mentrup, D., Möller, K., Wunder, E., Alheit, K., Hahn, V., Maurer, H.P.,\
    \ \nReif, J.C., Würschum, T., Müller, J., 2013. BreedVision—A multi-sensor \n\
    platform for non-destructive field-based phenotyping in plant breeding. Sensors\
    \ \n13, 2830-2847. \n14 \n \nCeglar, A., Toreti, A., Lecerf, R., Van der Velde,\
    \ M., Dentener, F., 2016. Impact of \nmeteorological drivers on regional inter-annual\
    \ crop yield variability in France. \nAgricultural and forest meteorology 216,\
    \ 58-67. \nChang, A., Jung, J., Maeda, M.M., Landivar, J., 2017. Crop height monitoring\
    \ with \ndigital imagery from Unmanned Aerial System (UAS). Computers and \nElectronics\
    \ in Agriculture 141, 232-237. \nChang, J., Clay, D.E., Clay, S.A., Reese, C.L.,\
    \ 2013. Using Field Scouting or Remote \nSensing Technique to Assess Soybean Yield\
    \ Limiting Factors. \nChen, Y., Mei, X., Liu, J., 2015. Cotton growth monitoring\
    \ and yield estimation based on \nassimilation of remote sensing data and crop\
    \ growth model, Geoinformatics, 2015 \n23rd International Conference on. IEEE,\
    \ pp. 1-4. \nCheng, T., Yang, Z., Inoue, Y., Zhu, Y., Cao, W., 2016. Preface:\
    \ Recent advances in \nremote sensing for crop growth monitoring. Multidisciplinary\
    \ Digital Publishing \nInstitute. \nChia, M.Y., Huang, Y.F., Koo, C.H., Fung,\
    \ K.F., 2020. Recent Advances in \nEvapotranspiration Estimation Using Artificial\
    \ Intelligence Approaches with a \nFocus on Hybridization Techniques—A Review.\
    \ Agronomy 10, 101. \nChu, T., Chen, R., Landivar, J.A., Maeda, M.M., Yang, C.,\
    \ Starek, M.J., 2016. Cotton \ngrowth modeling and assessment using unmanned aircraft\
    \ system visual-band \nimagery. Journal of Applied Remote Sensing 10, 036018.\
    \ \nDayananda, S., Astor, T., Wijesingha, J., Chickadibburahalli Thimappa, S.,\
    \ Dimba \nChowdappa, H., Nidamanuri, R.R., Nautiyal, S., Wachendorf, M., 2019.\
    \ Multi-\n15 \n \nTemporal Monsoon Crop Biomass Estimation Using Hyperspectral\
    \ Imaging. \nRemote Sensing 11, 1771. \nDu, M., Noguchi, N., 2017. Monitoring\
    \ of wheat growth status and mapping of wheat \nyield’s within-field spatial variations\
    \ using color images acquired from UAV-\ncamera system. Remote Sensing 9, 289.\
    \ \nFermont, A., Benson, T., 2011. Estimating yield of food crops grown by smallholder\
    \ \nfarmers. International Food Policy Research Institute, Washington DC, 1-68.\
    \ \nForcella, F., Arnold, R.L.B., Sanchez, R., Ghersa, C.M., 2000. Modeling seedling\
    \ \nemergence. Field Crops Research 67, 123-139. \nGago, J., Fernie, A.R., Nikoloski,\
    \ Z., Tohge, T., Martorell, S., Escalona, J.M., Ribas-\nCarbó, M., Flexas, J.,\
    \ Medrano, H., 2017. Integrative field scale phenotyping for \ninvestigating metabolic\
    \ components of water stress within a vineyard. Plant \nMethods 13, 90. \nHatfield,\
    \ J.L., Walthall, C.L., 2015. Meeting global food needs: realizing the potential\
    \ via \ngenetics× environment× management interactions. Agronomy Journal 107,\
    \ 1215-\n1226. \nHoffmann, H., Jensen, R., Thomsen, A., Nieto, H., Rasmussen,\
    \ J., Friborg, T., 2016a. \nCrop water stress maps for an entire growing season\
    \ from visible and thermal \nUAV imagery. Biogeosciences 13, 6545. \nHoffmann,\
    \ H., Nieto, H., Jensen, R., Guzinski, R., Zarco-Tejada, P., Friborg, T., 2016b.\
    \ \nEstimating evaporation with thermal UAV data and two-source energy balance\
    \ \nmodels. Hydrology and Earth System Sciences 20, 697-713. \n16 \n \nHolman,\
    \ F.H., Riche, A.B., Michalski, A., Castle, M., Wooster, M.J., Hawkesford, M.J.,\
    \ \n2016. High throughput field phenotyping of wheat plant height and growth rate\
    \ in \nfield plot trials using UAV based remote sensing. Remote Sensing 8, 1031.\
    \ \nHunt, E.R., Doraiswamy, P.C., McMurtrey, J.E., Daughtry, C.S.T., Perry, E.M.,\
    \ \nAkhmedov, B., 2013. A visible band index for remote sensing leaf chlorophyll\
    \ \ncontent at the canopy scale. International Journal of Applied Earth Observation\
    \ \nand Geoinformation 21, 103-112. \nHunt, E.R., Hively, W.D., McCarty, G.W.,\
    \ Daughtry, C.S.T., Forrestal, P.J., Kratochvil, \nR.J., Carr, J.L., Allen, N.F.,\
    \ Fox-Rabinovitz, J.R., Miller, C.D., 2011. NIR-green-\nblue high-resolution digital\
    \ images for assessment of winter cover crop biomass. \nGIScience & Remote Sensing\
    \ 48, 86-98. \nJames, I., Waine, T., Bradley, R., Taylor, J., Godwin, R., 2003.\
    \ Determination of soil \ntype boundaries using electromagnetic induction scanning\
    \ techniques. Biosystems \nEngineering 86, 421-430. \nJiang, P., Thelen, K., 2004.\
    \ Effect of soil and topographic properties on crop yield in a \nnorth-central\
    \ corn–soybean cropping system. Agronomy Journal 96, 252-258. \nKamilaris, A.,\
    \ Prenafeta-Boldú, F.X., 2018. Deep learning in agriculture: A survey. \nComputers\
    \ and electronics in agriculture 147, 70-90. \nKhaki, S., Wang, L., 2019. Crop\
    \ Yield Prediction Using Deep Neural Networks. \nFrontiers in Plant Science 10.\
    \ \nKhaki, S., Wang, L., Archontoulis, S.V., 2020. A cnn-rnn framework for crop\
    \ yield \nprediction. Frontiers in Plant Science 10, 1750. \n17 \n \nKitchen,\
    \ N., Drummond, S., Lund, E., Sudduth, K., Buchleiter, G., 2003. Soil electrical\
    \ \nconductivity and topography related to yield for three contrasting soil–crop\
    \ \nsystems. Agronomy Journal 95, 483-495. \nKitchen, N., Sudduth, K., Myers,\
    \ D., Drummond, S., Hong, S., 2005. Delineating \nproductivity zones on claypan\
    \ soil fields using apparent soil electrical \nconductivity. Computers and Electronics\
    \ in Agriculture 46, 285-308. \nMathieu, J.A., Aires, F., 2018. Assessment of\
    \ the agro-climatic indices to improve crop \nyield forecasting. Agricultural\
    \ And Forest Meteorology 253, 15-30. \nMoges, S., Raun, W., Mullen, R., Freeman,\
    \ K., Johnson, G., Solie, J., 2005. Evaluation of \ngreen, red, and near infrared\
    \ bands for predicting winter wheat biomass, nitrogen \nuptake, and final grain\
    \ yield. Journal of Plant Nutrition 27, 1431-1441. \nNi, J., Zhang, J., Wu, R.,\
    \ Pang, F., Zhu, Y., 2018. Development of an Apparatus for \nCrop-Growth Monitoring\
    \ and Diagnosis. Sensors 18, 3129. \nOosterhuis, D.M., 1990. Growth and development\
    \ of a cotton plant. Nitrogen Nutrition of \nCotton: Practical Issues, 1-24. \n\
    Pádua, L., Marques, P., Hruška, J., Adão, T., Peres, E., Morais, R., Sousa, J.,\
    \ 2018. \nMulti-Temporal Vineyard Monitoring through UAV-Based RGB Imagery. \n\
    Remote Sensing 10, 1907. \nPennock, D., McKenzie, N., Montanarella, L., 2015.\
    \ Status of the World's Soil \nResources. Technical Summary FAO, Rome, Italy.\
    \ \nRomero, M., Luo, Y., Su, B., Fuentes, S., 2018. Vineyard water status estimation\
    \ using \nmultispectral imagery from an UAV platform and machine learning algorithms\
    \ \n18 \n \nfor irrigation scheduling management. Computers and Electronics in\
    \ Agriculture \n147, 109-117. \nScherer, T.F., Franzen, D., Cihacek, L., 2017.\
    \ Soil, water and plant characteristics \nimportant to irrigation. North Dakota\
    \ State University, Fargo, North Dakota. \nStępień, M., Samborski, S., Gozdowski,\
    \ D., Dobers, E.S., Chormański, J., Szatyłowicz, \nJ., 2015. Assessment of soil\
    \ texture class on agricultural fields using ECa, Amber \nNDVI, and topographic\
    \ properties. Journal of Plant Nutrition and Soil Science \n178, 523-536. \nSudduth,\
    \ K.A., Kitchen, N.R., Wiebold, W., Batchelor, W., Bollero, G., Bullock, D., \n\
    Clay, D., Palm, H., Pierce, F., Schuler, R., 2005. Relating apparent electrical\
    \ \nconductivity to soil properties across the north-central USA. Computers and\
    \ \nElectronics in Agriculture 46, 263-283. \nTremblay, N., Bouroubi, Y.M., Bélec,\
    \ C., Mullen, R.W., Kitchen, N.R., Thomason, \nW.E., Ebelhar, S., Mengel, D.B.,\
    \ Raun, W.R., Francis, D.D., 2012. Corn response \nto nitrogen is influenced by\
    \ soil texture and weather. Agronomy Journal 104, \n1658-1671. \nVan Bussel, L.G.,\
    \ Ewert, F., Zhao, G., Hoffmann, H., Enders, A., Wallach, D., Asseng, \nS., Baigorria,\
    \ G.A., Basso, B., Biernath, C., 2016. Spatial sampling of weather \ndata for\
    \ regional crop yield simulations. Agricultural and Forest Meteorology 220, \n\
    101-115. \nVories, E., O’Shaughnessy, S., Sudduth, K.A., Evett, S., Andrade, M.,\
    \ Drummond, S., \n2020. Comparison of precision and conventional irrigation management\
    \ of cotton \nand impact of soil texture. Precision Agriculture, 1-18. \n19 \n\
    \ \nYang, G., Liu, J., Zhao, C., Li, Z., Huang, Y., Yu, H., Xu, B., Yang, X.,\
    \ Zhu, D., Zhang, \nX., 2017. Unmanned aerial vehicle remote sensing for field-based\
    \ crop \nphenotyping: current status and perspectives. Frontiers in Plant Science\
    \ 8, 1111. \nYang, Q., Shi, L., Han, J., Zha, Y., Zhu, P., 2019. Deep convolutional\
    \ neural networks \nfor rice grain yield estimation at the ripening stage using\
    \ UAV-based remotely \nsensed images. Field Crops Research 235, 142-153. \nYue,\
    \ J., Feng, H., Jin, X., Yuan, H., Li, Z., Zhou, C., Yang, G., Tian, Q., 2018.\
    \ A \ncomparison of crop parameters estimation using images from UAV-mounted \n\
    snapshot hyperspectral sensor and high-definition digital camera. Remote Sensing\
    \ \n10, 1138. \nZhang, L., Zhang, H., Niu, Y., Han, W., 2019. Mapping maize water\
    \ stress based on \nUAV multispectral remote sensing. Remote Sensing 11, 605.\
    \ \n \n20 \n \nChapter 2. GROUND DATA COLLECTION AND EXPERIMENT \nDESIGN \n2.1\
    \ Experimental field  \nThis study was conducted in a cotton research field at\
    \ the Fisher Delta Research \nCenter of the University of Missouri, located in\
    \ the upper portion of the Mississippi River \nDelta region near Portageville,\
    \ MO, USA as shown in Figure 2.1. The experimental site \nincludes two sub-fields,\
    \ i.e., west side and east side (East and West field hereafter). The \ntwo fields\
    \ have similar dimensions of approx. 320 m × 160 m with the long dimension in\
    \ \nthe south-north direction. \n \nFigure 2.1: The research site includes two\
    \ experimental fields (west and east) of similar \nsizes, shown in a Google Earth\
    \ satellite image captured on Aug. 14, 2019. Higher sand \ncontent soil regions\
    \ (i.e. brighter soil color) and variations in crop growth (i.e., degree of \n\
    canopy closure) can be seen. \n21 \n \n2.2 Soil, field elevation and weather data\
    \ \nThe spatial variability of soil texture in the field is quite large due to\
    \ both alluvial \nand seismic activities. As soil texture is strongly correlated\
    \ to ECa (Sudduth et al. 2003), \nsoil ECa data were collected on May 9, 2016\
    \ using a Veris 3100 instrument (Veris \nTechnologies, Salina, KS) following procedures\
    \ described by Sudduth et al. (2003). The \nelevation variation of the field was\
    \ measured using a Global Navigation Satellite System \n(GNSS) receiver (Geo 7X,\
    \ Trimble Navigation Ltd., Westminster, Colorado, USA) and a \nnetwork-based GNSS\
    \ correction service that provided 10 cm or better accuracy in 2018. \nThe field\
    \ elevation increases from 86.85 m on the north side to 88.37 m above mean sea\
    \ \nlevel on the south side, as shown in Figure 2.2.  \n \nFigure 2.2: Field elevation.\
    \ \nFigure 2.3 shows the cumulative precipitation and daily average temperature\
    \ from \nMay 1 to October 31 from 2017 to 2019, retrieved from an approximately\
    \ 400 m nearby \nweather station (http://agebb. missouri.edu/weather/). \n22 \n\
    \ \n \nFigure 2.3: Cumulative precipitation and the daily average temperature\
    \ of the \nexperimental field from May 1 to October 31 in 2017, 2018 and 2019.\
    \ The data were \nobtained from a 400 m nearby weather station. The red and purple\
    \ dashed lines show the \nirrigation dates. Irrigations were on parts of the field\
    \ as described in Vories et al. (2020) \nThe accumulated growing degree days (GDD)\
    \ were calculated by Eq. 2.1 (Main, \n2012; Thompson et al., 2019): \n\U0001D43A\
    \U0001D43A\U0001D43A\U0001D43A\U0001D43A\U0001D43A =\n\U0001D447\U0001D447\U0001D45A\
    \U0001D45A\U0001D45A\U0001D45A\U0001D45A\U0001D45A−\U0001D447\U0001D447\U0001D45A\
    \U0001D45A\U0001D45A\U0001D45A\U0001D45A\U0001D45A\n2\n− 15.6                \
    \              (2.1) \nwhere Tmax and Tmin are the highest and lowest temperature\
    \ (ºC) of each day.  The \naccumulated GDD and the accumulated precipitation in\
    \ each month from May to October \nare shown in Figure 2.4a-b. The accumulated\
    \ GDD during 2017 to 2019 were similar to \nthe 10-year (2009-2019) average accumulated\
    \ GDD with the exceptions of being slightly \nlower in Aug. in 2017, higher in\
    \ May and June 2018 and September 2019 (Figure 2.4a). \nHowever, the accumulated\
    \ precipitation in each month from 2017 to 2019 was quite \nvariable and different\
    \ from the 10-year average accumulated precipitation. In the early part \nof the\
    \ season, precipitation was lower than average in September in 2017 and from May\
    \ to \nJuly in 2018, but higher from May to July in 2019 (Figure 2.4b). The highest\
    \ monthly \nprecipitation was in August 2017, September in 2018 but May in 2019.\
    \ \n23 \n \n \nFigure 2.4: Monthly accumulative GDD (a) and monthly accumulative\
    \ precipitation (b) \nin 2017-2019 with the 10-year (2009-2019) averages \n2.3\
    \ Crop management and cotton yield data \nCotton cultivar PHY 333WRF for 2017E\
    \ (the east field), PHY 375 WRF for 2018W \n(the west field), PHY 320 WRF for\
    \ 2019E and PHY 390 WRF (Dow Agrosciences, \nIndianapolis, IN, USA) for 2019W\
    \ were planted on bedded soil using a commercial planter \n(John Deere 1700, Moline,\
    \ IL, USA) with a GPS system. The planting dates were May 15, \n2017, May 16,\
    \ 2018 and May 15, 2019. There were 152 cotton rows on the east side and \n148\
    \ cotton rows on the west side with a row spacing of 0.97 m.  \nA Valley 6000\
    \ center pivot irrigation system with zone control variable rate \nirrigation\
    \ (VRI; Valley Irrigation, Valley, NE, USA) was used to conduct site-specific\
    \ \nirrigation based on the needs of crops and different treatments, including\
    \ no irrigation, that \nwas described in Vories et al. (2020). The amount of irrigation\
    \ water applied to different \nareas of the fields was recorded. As the fields\
    \ were part of an irrigation study, all treatments \nother than irrigation (e.g.,\
    \ fertility, pest management) were applied uniformly to the entire \nfield. \n\
    24 \n \nCotton was harvested using a four-row cotton spindle picker (Case IH 2155,\
    \ Racine, \nWI, USA) on October 6 & 7, 2017, October 12, 2018 and October 10,\
    \ 2019. An Ag Leader \nInsight yield monitor system (Ag Leader Technology, Ames,\
    \ IA, USA) recorded geo-\nreferenced yield data separately for each row on a 1-s\
    \ interval at approximately 6.5 km h-\n1, or approximately 1.8 m of row per data\
    \ point. The location of each data point was \ndetermined with a GNSS receiver\
    \ (GPS 1500, Ag Leader Technology, Ames, IA, USA) \nusing wide area augmentation\
    \ system (WAAS) differential correction, which is expected \nto provide 150–200\
    \ mm pass-to-pass accuracy (Ag Leader Technology, 2011) in 2017 and \n2018. An\
    \ Ag Leader GPS 7500 receiver with TerraStar-C Pro differential correction, with\
    \ \npass-to-pass accuracy of 30 – 60 mm (Ag Leader Technology, 2019) was used\
    \ in 2019. \nThe spatially referenced yield data were managed using Ag Leader\
    \ SMS Basic version \n18.50 and ArcGIS 10.4 for Desktop (Esri, Redlands, CA, USA).\
    \ \n2.5 Literature cited \nAg Leader Technology, 2011. GPS differential sources\
    \ explained. \nAg Leader Technology, 2019. GPS 7500 and GPS 6500 correction signal\
    \ comparison. \nMain, C.L., 2012. W287 Cotton Growth and Development. Institute\
    \ of Agriculture, The \nUniversity of Tennessee. \nSudduth, K.A., Kitchen, N.,\
    \ Bollero, G., Bullock, D., Wiebold, W., 2003. Comparison of \nelectromagnetic\
    \ induction and direct sensing of soil electrical conductivity. \nAgronomy Journal\
    \ 95, 472-482. \nThompson, C.N., Guo, W., Sharma, B., Ritchie, G.L., 2019. Using\
    \ normalized difference \nred edge index to assess maturity in cotton. Crop Science\
    \ 59, 2167-2177. \n25 \n \nVories, E., O’Shaughnessy, S., Sudduth, K.A., Evett,\
    \ S., Andrade, M., Drummond, S., \n2020. Comparison of precision and conventional\
    \ irrigation management of cotton \nand impact of soil texture. Precision Agriculture,\
    \ 1-18. \n \n26 \n \nChapter 3. COTTON EMERGENCE EVALUATION AND THE SOIL \nEFFECTS\
    \ ON EMERGENCE \n3.1 Abstract \nCrop emergence is an important agronomic factor\
    \ for making field management \ndecisions, such as replanting, that are time-sensitive\
    \ and need to be made at very early \nstages. Crop emergence, evaluated using\
    \ plant population, stand count and uniformity, is \nconventionally quantified\
    \ manually, not accurate, and labor and time-intensive. Unmanned \naerial vehicle\
    \ (UAV)-based imaging systems are able to scout crop fields rapidly. However,\
    \ \ndata processing can be too slow to make timely decision making. The goal of\
    \ this study \nwas to develop a novel image processing method for processing UAV\
    \ images in nearly \nreal-time. In this study, a UAV imaging system was used to\
    \ capture RGB image frames of \ncotton seedlings to evaluate stand count and canopy\
    \ size. Images were pre-processed to \ncorrect distortions, calculate ground sample\
    \ distance and geo-reference cotton rows in the \nimages. A pre-trained deep learning\
    \ model, resnet18, was used to estimate the stand count \nand canopy size of cotton\
    \ seedlings in each image frame. Results showed that the \ndeveloped method could\
    \ estimate stand count accurately with R2 = 0.95 in the test dataset. \nSimilar\
    \ results were achieved for canopy size with an estimation accuracy of R2 = 0.93\
    \ in \nthe test dataset. The processing time for each image frame of 20 M pixels\
    \ with each crop \nrow geo-referenced was 2.22 s (including 1.80 s for pre-processing),\
    \ which was more \nefficient than traditional mosaic-based image processing methods.\
    \ An open-source \nautomated image-processing framework was developed for cotton\
    \ emergence evaluation \nand is available to the community for efficient data\
    \ processing and analytics.  \n27 \n \nKeywords. Emergence evaluation; stand count;\
    \ row geo-reference; real-time processing \n3.2 Introduction \nCrop emergence\
    \ is an important agronomic factor for field management in early \nstages, which\
    \ can be assessed using plant population, stand count, uniformity and seedling\
    \ \nsize (Sansone et al., 2002; Supak, 1990). Accurate and timely assessment of\
    \ crop stand \ncount and seedling size at the emergence stage may help farmers\
    \ make important field \nmanagement decisions (e.g., replanting) to reduce production\
    \ loss (Goodell et al., 2015). \nAcquisition of high-resolution site-specific\
    \ crop emergence information is the baseline for \nimplementing precision field\
    \ management. Meanwhile, accurate crop emergence \ninformation can be used to\
    \ understand the impact of soil and environment on crop \nemergence (Forcella\
    \ et al., 2000; Ghassemi-Golezani and Dalil, 2014). Conventionally, \ncrop stand\
    \ count is assessed through visual observation (manual counts) in a small number\
    \ \nof sampling sites (Wiles and Schweizer, 1999), which is time-consuming, labor-intensive,\
    \ \nand not suited to cover a large production field.  \nTo improve efficiency\
    \ and accuracy, advanced proximal and remote sensing \ntechnologies have been\
    \ developed to assess crop emergence. For example, Jin et al. (2017) \nand Liu\
    \ et al. (2017) used ground vehicle-based imaging systems to assess wheat stand\
    \ \ncount in field conditions. However, ground vehicle-based systems have many\
    \ limitations \nwhen they are used in full-scale crop production, such as being\
    \ slow and affected by ground \nconditions (e.g., wet soil or narrow-row cropping\
    \ systems). In recent years, unmanned \naerial vehicle (UAV)-based imaging technology\
    \ has been tested as a high-throughput tool \nfor crop emergence assessment in\
    \ various crops as summarized by Feng et al. (2020). Some \nexamples include the\
    \ assessment of wheat density (Jin et al., 2017; Sankaran et al., 2015), \n28\
    \ \n \ncotton uniformity (Feng et al., 2019a), and stand count in cotton (Chen\
    \ et al., 2018; Feng \net al., 2019a), corn (Varela et al., 2018), potato (Sankaran\
    \ et al., 2017) and rapeseed (Zhao \net al., 2018).  \nThe published studies used\
    \ similar approaches to process UAV imagery data, i.e., \nusing commercial UAV\
    \ image processing software, such as Agisoft PhotoScan (Agisoft \nLLC, St. Petersburg,\
    \ Russia) and Pix4D (Pix4D S.A., Lausanne, Switzerland), to generate \northomosaic\
    \ images before further processing. The procedure of generating orthomosaic \n\
    images includes image feature detection, matching, alignment and blending based\
    \ on \nmosaic blending models as described by Brown and Lowe (2003), which may\
    \ take a very \nlong time (days or weeks) and require extensive computational\
    \ resources. For example, it \ntook more than two weeks to develop an orthomosaic\
    \ image using 2000 images of 4864 × \n3648 pixels using Agisoft in one of our\
    \ projects. The software was running in a workstation \ndesktop computer (Model\
    \ Dell Precision Tower 5810, Dell, Round Rock, TX, USA) \nconfigured with an Intel\
    \ Xeon E5 (1630 v3) 3.70 GHz central processing unit (CPU), 32GB \nrandom-access\
    \ memory (RAM) and an NVIDIA Quadro K1200 4GB graphics processing \nunit (GPU).\
    \ Crop seedlings are usually small and require high-resolution images to capture\
    \ \nsufficient information, which results in a large number of images for mosaic\
    \ processing \nand makes it challenging to make timely decisions. The challenge\
    \ in the timely processing \nof imagery data becomes one of the most critical\
    \ barriers for adopting UAV imagery in \napplications of crop emergence assessment\
    \ (Forcella et al., 2000; Supak, 1990). Although \nleveraging high-performance\
    \ computing or cloud computing resources may provide an \nalternative solution,\
    \ it requires expensive and complicated infrastructure that may not be \nfeasibly\
    \ or economically accessible by most users. Therefore, there is a pressing need\
    \ to \n29 \n \ndevelop a cost-effective solution for timely image processing and\
    \ real-time decision \nmaking. \nCurrent studies related to crop emergence using\
    \ UAV imagery focus on stand count \nand uniformity (Feng et al., 2019a). Crop\
    \ seedlings were usually segmented by their \nmorphological features from the\
    \ images to estimate the number of seedlings in a certain \nrow length or area.\
    \ The image features include canopy area (total number of green pixels) \n(Gnädinger\
    \ and Schmidhalter, 2017), leaf polygons (Chen et al., 2018), and major axis \n\
    length (Jin et al., 2017; Zhao et al., 2018). Template matching with a single\
    \ plant was \nanother way to count seedlings (Koh et al., 2019). However, the\
    \ shape, size and overlap \n(Zhao et al., 2018) of individual seedlings may vary\
    \ in a large range due to the variation in \nsoil conditions (moisture, temperature,\
    \ nutrients), cropping system, planting depth and seed \nquality (Egli and Rucker,\
    \ 2012; Feng et al., 2019a). Using simple image features or their \ncombinations\
    \ may not identify seedlings accurately and result in errors in stand count. In\
    \ \naddition, most of the published studies defined the seedling clusters (overlapped\
    \ seedlings) \nas different regions of interest (ROI) and then used a classification\
    \ model to estimate the \nnumber of seedlings in each ROI. Classification methods\
    \ need to know the maximum \nexpected plant number in each ROI (Ribera et al.,\
    \ 2017). Feng et al. (2019a) pointed out \nthat there were unbalanced data sets\
    \ in their study when using the classification method as \nmost of the ROIs included\
    \ one or two seedlings and only a few ROIs included three or four \nseedlings.\
    \ Unbalanced data sets could affect the estimation accuracy (Chawla, 2009). \n\
    Using regression instead of classification may help to reduce the effect of the\
    \ above \nproblems (Ribera et al., 2017). \n30 \n \nAdvanced data processing technology,\
    \ deep learning (DL), has been increasingly \nused to process imagery data collected\
    \ in agricultural applications (Kamilaris and \nPrenafeta-Boldú, 2018) Deep learning\
    \ models have been used to extract hidden \ninformation from imagery data collected\
    \ by satellites, UAVs and ground robotic systems \nto monitor crop development\
    \ and predict yield (Humphrey et al., 2012; Nanni et al., 2017). \nIn addition,\
    \ the multilayer structure of DL models works well for complex nonlinear \nproblems\
    \ (Nielsen, 2015). There are two ways to develop a DL model: using the network\
    \ \narchitectures developed and tested by other research teams, or designing a\
    \ specific network \narchitecture (Kamilaris and Prenafeta-Boldú, 2018). Designing\
    \ a specific DL network for \na project requires a sufficiently large dataset\
    \ for training and validating the models (Erhan \net al., 2009), which is a challenge\
    \ in agricultural studies. On the other hand, a number of \nsuccessful and popular\
    \ DL models (pre-trained DL models) have been tested and validated \nto have high\
    \ efficiency and can be transferred to different tasks (transform learning model)\
    \ \n(Pan and Yang, 2009). Transform learning models have been used in many studies\
    \ and are \npotentially able to improve the efficiency and reduce the time to\
    \ train the models  \n(Ayyachamy et al., 2019; Kamilaris and Prenafeta-Boldú,\
    \ 2018), including in many \nagricultural studies (Fu et al., 2020; Gao et al.,\
    \ 2020; Li et al., 2019). Various successful \nand popular deep learning models,\
    \ such as AlexNet (Krizhevsky, 2014), VGG (Simonyan \nand Zisserman, 2014), GoogleNet\
    \ (Szegedy et al., 2015), and ResNet (He et al., 2016), \nhave been used to process\
    \ complex data from agriculture. The applications include weed \ndetection (Dyrmann\
    \ et al., 2017; Dyrmann et al., 2016), fruit detection and counting \n(Bargoti\
    \ and Underwood, 2017; Chen et al., 2017; Rahnemoonfar and Sheppard, 2017) and\
    \ \nplant disease detection (Ghosal et al., 2018; Mohanty et al., 2016). In addition,\
    \ transform \n31 \n \nlearning models have been used to evaluate plant stand count\
    \ and showed potential for \nimproved accuracy (Ribera et al., 2017). \nThis study\
    \ focused on developing an efficient imagery data processing and analysis \nframework\
    \ for timely evaluation of cotton emergence using UAV-based RGB imagery and \n\
    deep learning technology. This study was different from previously published studies\
    \ in \nthe approach of directly processing individual image frames rather than\
    \ developing \northomosaic images to reduce the processing time. The specific\
    \ objectives included (1) \ndeveloping a pre-processing pipeline to segment and\
    \ geo-reference crop rows in each \nindividual image frame; (2) implementing a\
    \ deep learning model to estimate the cotton \nstand count and canopy size; and\
    \ (3) developing a framework for automatically generating \ngeo-referenced emergence\
    \ maps in cotton. \n3.3 UAV system and experimental design \nTo imaging the small\
    \ size cotton seedlings, a high image resolution UAV system \nwas used for the\
    \ cotton emergence evaluation study. Imagery data were collected using a \nUAV\
    \ imaging system (DJI Phantom 4 Advanced, DJI, Shenzhen, Guangdong, China). The\
    \ \nonboard RGB camera has a focal length of 8.8 mm and the dimensions of the\
    \ imaging \nsensor were 12.8 mm × 7.2 mm with 20M effective pixels. The spatial\
    \ resolution of the \nimages was 2.7 mm pixel-1 at 10 m AGL with a frame size\
    \ of 3648×4864. A UAV control \napp (Autopilot, Hangar Technology, Austin, TX,\
    \ USA) was used to plan flight paths, set \nwaypoints, flight speed (7.5 km h-1),\
    \ and height (10 m above ground level, AGL) before \nflying. The camera collected\
    \ images at a snapshot rate of 2 s per image (i.e. 0.5 frames per \nsecond), with\
    \ a 60% image overlap in both sideward and forward directions. Imagery data \n\
    32 \n \nwere collected at near solar noon (around 1 pm Central Daylight Time,\
    \ CDT) 16 days after \nplanting (DAP) on May 31, 2019. The weather conditions\
    \ during imaging are shown in \nTable 3. 1, which indicates a mild wind speed\
    \ and negligible variation in the environment \n(air temperature, relative humidity\
    \ and solar irradiance). The onboard GPS system on the \nUAV continuously recorded\
    \ the coordinates and altitude of the imaging system and \nprovided geo-referencing\
    \ for each image frame as part of the image metadata. Geo-\nreferenced images\
    \ were downloaded after the flight for further processing.  \nTable 3. 1: Weather\
    \ conditions during imaging measured by the nearby weather station \nAir temperature\
    \ \n(ºC) \nRelative humidity \n(%) \nWind speed (m \ns-1) \nSolar irradiance \n\
    (W m-2) \n26.8±0.4 \n48.7±0.6 \n2±0 \n864±68.5 \n \nGround truth and reference\
    \ data including ground reference points (GRPs), stand \ncount and seedling size,\
    \ were collected on the day of the UAV flight. In this study, 28 \nGRPs (Figure\
    \ 3.1) were set in the field, including 16 fence posts (~ 1.1 m in height) with\
    \ \nwhite-black polytechnic boards (30 cm × 30 cm) and twelve 53 cm × 53 cm squares\
    \ \nconstructed with half-inch polyvinyl chloride (PVC) pipes. A ground stake\
    \ was placed at \neach GRP to mark its position in a way that could be recognized\
    \ during the growing season \n(Figure 3.1c). A real-time kinematic (RTK) survey\
    \ kit (REACH RS+, Emlid Ltd., Saint \nPetersburg, Russia) with a ReachView app\
    \ (Emlid Ltd.) was used to obtain the Global \nPositioning System (GPS) coordinates\
    \ of the 28 GRPs. At each GRP, six flags were used \nto mark six 1-m intervals\
    \ of crop seedlings in two cotton rows as shown in Figure 3.1a and \nFigure 3.1b.\
    \ The number of seedlings in each 1-m interval was counted manually to serve \n\
    as ground truth data for stand count estimation. Meanwhile, a tape measure with\
    \ a precision \n33 \n \nscale of 1 mm was placed along the cotton row to provide\
    \ a reference to calculate ground \nsampling distance (GSD), which is defined\
    \ as the number of pixels per meter. A digital \ncamera on a cell phone (iPhone\
    \ 6s, Apple Inc., Cupertino, CA, USA) was used to take \nvideos of the crop rows\
    \ while being held manually at a height of about 0.5 m AGL with \nthe camera facing\
    \ down. Cotton stands were counted by playing back the videos and \ncanopy size\
    \ (top view) was calculated using the GSD from the tape measure. \n \nFigure 3.1:\
    \ Illustration of the field experiment setup. (a) and (b) show one of the 28 \n\
    ground reference points (GRPs) that include two 6-m crop rows, a fence post and\
    \ red \nflags marking 1-m intervals. The ground videos were taken using a cell\
    \ phone camera. (c) \nUAV image showing a PVC pipe square with one ground stake\
    \ inside. \n3.4 UAV image pre-processing \nUAV images may have tilt/perspective\
    \ angles to the ground (crop canopy) and \ndifferent GSD due to variation in flight\
    \ attitude and altitude of the UAV. Therefore, pre-\nprocessing is required for\
    \ three main purposes: 1) image distortion correction; 2) \ncalibration of GSD\
    \ in each image; and 3) geo-referencing each crop row.  \nDistortion calibration\
    \ \nThere are two types of distortions in photography, i.e. optical distortion\
    \ due to the \ncamera lens and perspective distortion due to the position of the\
    \ camera relative to the \n34 \n \nscene. Both distortions will affect the accuracy\
    \ of geometric measurements using UAV \nphotogrammetry. In this study, each image\
    \ frame included about nine to fifteen cotton rows \ndepending on the flight altitude.\
    \ The GSD of cotton rows at the edge of each image is \naffected by both optical\
    \ distortion (including radial and decentering lens distortions) and \nperspective\
    \ distortion. The optical distortion of the onboard camera was corrected through\
    \ \nthe calibration procedure using the DJI Assistant 2 software (DJI, Shenzhen,\
    \ Guangdong, \nChina) before fights. To evaluate the calibration results of the\
    \ DJI Assistant 2 software, a \ncheckerboard with nine rows and 12 columns of\
    \ squares, each 60 mm × 60 mm, was used \nto calculate the level of distortion\
    \ following the procedure described by Zhang (2000). \nImages including different\
    \ views (orientations) of the checkerboard were taken and then \nthe corners of\
    \ the squares in the checkerboard were identified automatically. Since the \n\
    images of the checkerboard were taken outdoors, the uneven sunlight and the complex\
    \ \nbackground made corner detection challenging. A more robust method for checkerboard\
    \ \ncorner detection described by Geiger et al. (2012) was used for automatic\
    \ corner detection. \nThe corners of the squares were used as features to estimate\
    \ the camera intrinsic matrix \nand distortion parameters based on the maximum\
    \ likelihood criterion. The radial distortion \ncoefficient k1 of the lens was\
    \ used to describe the level of distortion (Zhang, 2000). There \nis no radial\
    \ distortion when k1=0. The images have pincushion distortion when k1 is \npositive,\
    \ and barrel distortion when k1 is negative. Perspective distortion of each image\
    \ \nwas explained using the differences in cotton row spacing in the edge and\
    \ in the middle of \nimages and is described in the following Chapter. \nQuantification\
    \ of cotton row spacing  \n35 \n \nTo calculate the GSD of each image, a dynamic\
    \ ground reference object with a \nknown dimension is needed. In field conditions,\
    \ it is challenging to set a sufficient number \nof artificial objects to be captured\
    \ by each frame. However, in production fields, row crops, \nincluding cotton,\
    \ are planted using commercial planters with fixed row spacing, which can \nbe\
    \ used as a ground reference object for calculating the GSD of each image frame.\
    \ The 12 \nPVC pipe squares with a side length of 0.53 m were randomly distributed\
    \ in the field to \nprovide secondary ground reference objects for validating\
    \ the GSD calculated using row \nspacing. \nTo calculate row spacing in the images,\
    \ the first step was to segment each row and \nidentify their central lines. Figure\
    \ 3.2 shows the procedures of crop row detection, \nincluding conducting decorrelation\
    \ stretch and standard Hough transform (SHT) (Duda and \nHart, 1972). Image decorrelation\
    \ stretch is designed to reduce the inter-channel correlation \nand enhance (stretch)\
    \ the color difference in a multiple-channel image for object \nsegmentation and\
    \ feature detection (Gnädinger and Schmidhalter, 2017). The decorrelation \nprocess\
    \ was conducted using the decorrstretch function in Matlab (version 2018a, \n\
    MathWorks, Natick, MA, USA). After decorrelation, the pixel values in the green\
    \ channel \nof images showed a large difference between crops and soil; therefore,\
    \ all pixels > 180 \nwere considered as cotton seedlings and set as “1” in a binary\
    \ image as shown in Figure \n3.2b. The SHT was applied to the binary images to\
    \ search long lines that were considered \nto be crop rows (Feng et al., 2020).\
    \ The SHT process was conducted using the hough \nfunction in Matlab that returned\
    \ two parameters for each detected line, i.e. the distance r \nfrom the origin\
    \ coordinates of the image to the detected cotton row, and the angle θ of the\
    \ \ndetected cotton row to the vertical axis of the image. Angles within an image\
    \ might be \n36 \n \nslightly different for each row and the median θ was used\
    \ for each image. The images then \nwere rotated -θ degrees to obtain cotton rows\
    \ aligned with the vertical axis of the images, \nas shown in Figure 3.2c. Row\
    \ spacing was calculated based on the r difference between \ntwo neighboring rows,\
    \ denoted by ri. As shown in Figure 3.2d, all cotton rows in an image \nwere split\
    \ into three groups automatically based on the r values, i.e. left two rows (two\
    \ \nsmallest r), right two rows (two largest r) and middle rows. This grouping\
    \ was selected to \nkeep more than 50% of an image as the middle rows and less\
    \ than 50% as the edge rows. \nThere were at least nine crop rows in each image\
    \ frame based on our statistical analysis in \nthis study (results not shown).\
    \ A t-test was conducted to test the difference in row spacing \nbetween the edge\
    \ rows (left and right two rows) and middle rows, and perspective \ndistortion\
    \ was detected by a significant difference. Since the paired t-test required an\
    \ equal \nsample size in each group, a random resampling process was conducted\
    \ before the t-test. \nThe standard deviation (δ) of row spacing across all images\
    \ was used to describe the \nvariation of the cotton row spacing. After the row\
    \ spacing was measured, the GSD of the \nimage was calculated as the ratio of\
    \ the number of pixels to the true row spacing, which \nwas 0.97 m in this case.\
    \  \n37 \n \n \nFigure 3.2: Illustration of cotton row detection. (a) Image after\
    \ decorrelation stretch \nprocedure showing the substantial difference between\
    \ pixel values of crops and soil. (b) \nThe corresponding binary image after soil\
    \ removal using a threshold. (c) Cotton rows \nwere detected using a standard\
    \ Hough transform (SHT). (d) Row spacing is denoted by \nris. Cotton row spacings\
    \ in an image were classified as left edges (two left row spacings, \nr1 and r2),\
    \ middle (r3-r7), or right edges (two right row spacings, r8 and r9) to test \n\
    perspective distortion.  \nGeo-referencing cotton rows \nThe accuracy of the UAV\
    \ GPS was evaluated by comparing the horizontal \ncoordinates of the ground stake\
    \ in each GRP with those measured using the RTK receiver. \nAs shown in Figure\
    \ 3.3a, the northing and easting distances in pixels between the image \ngeometric\
    \ center and the ground stake were measured first. Then, those distances in pixels\
    \ \nwere transformed to distances in meters using the GSD calculated based on\
    \ row spacing. \n38 \n \nThe GPS coordinates of the ground stake were calculated\
    \ based on the above calculated \ndistances in meters and the image GPS coordinates\
    \ using Eq. 3.1 and Eq. 3.2 (Bugayevskiy \nand Snyder, 2013; Snyder, 1987). \n\
    ∆\U0001D459\U0001D459\U0001D459\U0001D459\U0001D459\U0001D459\n1 = 111132.92 −\
    \ 559.82\U0001D450\U0001D450\U0001D450\U0001D450\U0001D450\U0001D4502\U0001D711\
    \U0001D711 + 1.175\U0001D450\U0001D450\U0001D450\U0001D450\U0001D450\U0001D450\
    4\U0001D711\U0001D711 − 0.0023\U0001D450\U0001D450\U0001D450\U0001D450\U0001D450\
    \U0001D4506\U0001D711\U0001D711           (3.1) \n∆\U0001D459\U0001D459\U0001D459\
    \U0001D459\U0001D459\U0001D459\U0001D459\U0001D459\n1\n= 111412.84 − 93.5\U0001D450\
    \U0001D450\U0001D450\U0001D450\U0001D450\U0001D4503\U0001D711\U0001D711 + 0.118\U0001D450\
    \U0001D450\U0001D450\U0001D450\U0001D450\U0001D4505\U0001D711\U0001D711      \
    \                                   (3.2) \nwhere ∆\U0001D459\U0001D459\U0001D459\
    \U0001D459\U0001D459\U0001D459\n1  and ∆\U0001D459\U0001D459\U0001D459\U0001D459\
    \U0001D459\U0001D459\U0001D459\U0001D459\n1\n are the lengths in meters of a 1-degree\
    \ change of latitude and \nlongitude, and \U0001D711\U0001D711 is the latitude\
    \ in radians. The constants 111132.92 and 111412.84 \nrepresent the average estimation\
    \ for ∆\U0001D459\U0001D459\U0001D459\U0001D459\U0001D459\U0001D459\n1  and ∆\U0001D459\
    \U0001D459\U0001D459\U0001D459\U0001D459\U0001D459\U0001D459\U0001D459\n1\n based\
    \ on earth’s radius and ellipsoid \nparameters. However, the earth is an irregular\
    \ ellipse and ∆\U0001D459\U0001D459\U0001D459\U0001D459\U0001D459\U0001D459\n\
    1  and ∆\U0001D459\U0001D459\U0001D459\U0001D459\U0001D459\U0001D459\U0001D459\
    \U0001D459\n1\n change with \nlatitude. The other parameters are the adjustment\
    \ of these changes in different latitudes. \nThe accuracy of image GPS coordinates\
    \ was calculated as the distance between the \ncoordinates of the ground stakes\
    \ measured using the two systems and was calculated using \nthe Haversine formula\
    \ as explained in Lipan and Groza (2010) and Monawar et al. (2017). \n \nFigure\
    \ 3.3: Illustration showing the location of a ground stake away from the center\
    \ of an \nimage and the location calculation for each cotton row. (a) Calculation\
    \ of the ground \nstake coordinates from the UAV GPS system. (b) Calculation of\
    \ GPS coordinates of 1-m \nseedling segments in each cotton row. The blue ‘x’\
    \ is the image geometric center. \n39 \n \nEq. 3.1 and Eq. 3.2 were also used\
    \ to calculate the GPS coordinates of each 1-m \nseedling segment (white dashed\
    \ boxes in Figure 3.3b) of each row in an image based on \nthe UAV GPS system.\
    \ GPS coordinates of the white boxes were assigned based on their \ndistances\
    \ from the geometric centers of the image frame. Since the images had > 60% \n\
    overlap in both the sideward and the forward directions, only middle rows were\
    \ used in the \nfollowing processing, i.e., seedlings within 2 m from the geometric\
    \ center in the north-\nsouth direction.  \nEvaluation of distortion correction\
    \ and estimated row spacing \nOne hundred and six (106) images of the checkerboard\
    \ were processed to validate \nthe calibration results of optical distortion using\
    \ the DJI Assistant 2 software. In this study, \nk1=0.0205 was obtained, indicating\
    \ the optical distortion was small enough to be negligible. \nThirty-eight images\
    \ that included PVC pipes were used to evaluate the variation of the row \nspacing\
    \ of 334 rows, resulting in a mean of 99.0 cm with a standard deviation of 3.8\
    \ cm. \nThis result showed that the variation of row spacing was small and usage\
    \ of cotton row \nspacing as the reference of GSD was reasonable. \nThe same thirty-eight\
    \ images that included 334 rows were also used to test the \nperspective distortion\
    \ of an image. Table 3.2 shows the means and standard deviations of \nrow spacing\
    \ of left, middle and right edge rows in the images (Figure 3.2). It can be seen\
    \ \nthat the mean row spacing at the middle of images was slightly larger than\
    \ that of left and \nright edge rows. A resampling t-test with a resampling size\
    \ of 1,000 showed that there was \nno significant difference among the three locations\
    \ at a 5% significance level, which also \nindicated that the perspective distortion\
    \ was small enough to be negligible. \n40 \n \nTable 3.2: Mean and standard deviation\
    \ of row spacing of edge and middle rows in \nimages. The resampling t-test indicates\
    \ that there was no significant difference (p-value < \n0.05) in row spacing among\
    \ the rows at different locations of images. \n \nLeft two rows \nMiddle rows\
    \ \nRight two rows \nMean ± std (cm) \n98.80 ± 3.64 \n99.28 ± 4.03 \n98.70 ± 3.30\
    \ \n \n3.5 Evaluation of cotton stand count and canopy size \nIntroduction to\
    \ convolutional neural networks \nThe convolutional neural network (CNN) is a\
    \ DL model designed in combinations \nof different numbers of convolution layers,\
    \ pooling layers, activation layers, and full \nconnection layers (Nielsen, 2015).\
    \ Convolution layers and pooling layers include filter \nboxes that scan the input\
    \ images using a sliding window to generate image feature maps, \nas shown in\
    \ Figure 3.4a. A filter box is a parameter matrix. It moves from the top to the\
    \ \nbottom and from left to right with a specific moving stride to calculate the\
    \ sum of \nmultiplication of the input image with the parameter matrix. This process\
    \ can extract the \ninput image features while keeping the spatial correlation\
    \ of image features. Pooling layers \nextract the mean or maximum pixel values\
    \ of the regions while they move. Full connection \nlayers calculate the sum of\
    \ multiplication of the input values with layer parameters, shown \nas Figure\
    \ 3.4b. Activation layers include nonlinear functions, such as the sigmoid function,\
    \ \nlogistic activation function, or rectified linear unit (ReLU) function (Nielsen,\
    \ 2015).  \n41 \n \n \nFigure 3.4: Illustration of the principle of convolution\
    \ layers and full connection layers of \nthe deep learning model. (a) Convolution\
    \ layers include a 3 × 3 filter with the parameters \nwi. The input image size\
    \ is assumed 9 × 9 and the moving stride is 2, resulting in the \noutput of a\
    \ 4 × 4 feature map. xi is one of the pixel values of each 3 × 3 region that is\
    \ \nused to calculate outputs while moving. Each value in the output feature map\
    \ is \ncalculated by ∑\n\U0001D498\U0001D498\U0001D48A\U0001D48A × \U0001D499\U0001D499\
    \U0001D48A\U0001D48A\n\U0001D7CF\U0001D7CF\n\U0001D48A\U0001D48A=\U0001D7CF\U0001D7CF\
    \n . (b) In the full connection layers, wi,j are the parameters, and \nxi are\
    \ the input values. This is a four input and one output full connection layer\
    \ that is \ncalculated by the formula inside the purple box. \nDeployment of transform\
    \ learning model using resnet18 \nThe CNN model used in this study was based on\
    \ a widely used pre-trained CNN \nmodel resnet developed by (He et al., 2015).\
    \ The architecture of the CNN model is shown \nin Figure 3.5. The resnet model\
    \ was chosen from many popular pre-trained models (such \nas VGG, DenseNet and\
    \ AlexNet) due to the high estimation accuracy and low computation \nresource\
    \ requirement. The resnet was trained and validated using the ImageNet dataset\
    \ \n(Russakovsky et al., 2015) with a classification capacity of 1000 classes.\
    \ The resnet model \ncan be optimized easily and could achieve higher accuracy\
    \ with deeper layers because of \nthe residual blocks (He et al., 2016). The resnet\
    \ model has different versions, including 18 \n42 \n \nlayers, 34 layers and 152\
    \ layers that are developed to process data of different complexity. \nThe smallest\
    \ model, resnet18 was chosen in this study due to the relatively less complex\
    \ \ndataset, preferred fast training speed and less computing time. The parameters\
    \ trained on \nthe ImageNet dataset were selected as the initial parameters as\
    \ they had strong image \nfeature extraction power (Pan and Yang, 2009) for low-level\
    \ features (such as dots, lines, \ncorners and textures) to avoid training models\
    \ from scratch and to reduce the required time. \nParameters in all layers of\
    \ the model were fine-tuned using the imagery dataset from this \nstudy. \n \n\
    Figure 3.5: The architecture of resnet18, as applied to the estimation of stand\
    \ count and \nseedling size. \nThe resnet18 model requires input images of 224\
    \ × 224 pixels in three channels \n(red, green and blue). Therefore, images collected\
    \ in this study were resized to the required \ndimensions. The pixel values in\
    \ the three channels ([R, G, B], pixel values ranged from 0-\n255) of the input\
    \ images were normalized to the range of [0, 1] by dividing by 255 (i.e., \nInput\
    \ image\n224 × 224 ×\n3 channel (RGB)\nNormalization\nConv1--Stage 1\nFilter:\
    \ 7×7\nStride: 2\nPadding: 3\nKernels: 64\nBatch normalization\nActivate function:\
    \ ReLU\nMax pool: 3×3\nStride: 2 \nPadding: 1\n……\nConv2_x--Stage 2\nOutput size:\
    \ 112 ×112\n64 feature maps\nFilter: 3×3\nStride: 1\nPadding: 1\nKernels: 64\n\
    Batch normalization\nActivate function: ReLU\nFilter: 3×3\nStride: 1\nPadding:\
    \ 1\nKernels: 64\nBatch normalization\n×2\n……\nOutput size: 56 ×56\n64 feature\
    \ maps\nConv3_x--Stage 3\nFilter: 3×3\nStride: 2\nPadding: 1\nKernels: 128\nBatch\
    \ normalization\nActivate function: ReLU\nFilter: 3×3\nStride: 1\nPadding: 1\n\
    Kernels: 128\nBatch normalization\n×2\n……\nOutput size: 28 ×28\n128 feature maps\n\
    ……\nOutput size: 14 ×14\n256 feature maps\nConv4_x--Stage 4\nFilter: 3×3\nStride:\
    \ 2\nPadding: 1\nKernels: 256\nBatch normalization\nActivate function: ReLU\n\
    Filter: 3×3\nStride: 1\nPadding: 1\nKernels: 256\nBatch normalization\n×2\nConv5_x--Stage\
    \ 5\nFilter: 3×3\nStride: 2\nPadding: 1\nKernels: 512\nBatch normalization\nActivate\
    \ function: ReLU\nFilter: 3×3\nStride: 1\nPadding: 1\nKernels: 512\nBatch normalization\n\
    ×2\n……\nOutput size: 7 ×7\n512 feature maps\nAvgPool--Stage 6\n1\n0.8\n0.6\n0.4\n\
    0.2\n0\nOutput size: 1 ×1\n512 features\nFC--Stage 7\nInput feature: 512\nOutput:\
    \ 2\nSeedling number: 7.9\nCanopy size: 122.8 cm2\n15.54 cm2 seedling-1\nShortcut\
    \ connection\nShortcut connection\nShortcut connection\nShortcut connection\n\
    43 \n \n[R/255, G/255, B/255]). The pre-trained resnet18 model requires the same\
    \ normalizing \nprocedure as the original ImageNet training set. Therefore, the\
    \ imagery data were \nsubtracted [0.485, 0.456, 0.406] and divided by [0.229,\
    \ 0.224, 0.225], i.e.,  [(R/255-\n0.485)/0.229, (G/255-0.456)/0.224, (B/255-0.406)/0.225],\
    \ which were the mean and \nstandard deviation of the three channels (red, green\
    \ and blue) of the ImageNet dataset \n(Russakovsky et al., 2015). The model used\
    \ five stages of different numbers of convolution \nlayer combinations, batch\
    \ normalization layers, ReLU activation layers and max pooling \nlayers for feature\
    \ extraction (He et al., 2016). Shortcut connections were added to this \nnetwork\
    \ to provide the residual learning (residual blocks) (He et al., 2016). The last\
    \ two \nstages (stages 6-7) were average pooling and full connection layers. The\
    \ outputs were stand \ncount and canopy size of each seedling based on a regression\
    \ model. The L1 loss function \n(|f(x)-y|) was used to minimize errors and search\
    \ for optimal model parameters \n(Goodfellow et al., 2016). The model calculated\
    \ canopy size and stand count \nsimultaneously using one loss function for the\
    \ parameter optimization. However, the \nabsolute values of canopy size (mean\
    \ was about 24 cm2 per seedling) were larger than the \nstand count (mean was\
    \ about 12 seedlings m-1), so the L1 loss was defined by Eq. 3.3 to \nbalance\
    \ the loss of canopy size and stand count. Mean absolute percentage error (MAPE)\
    \ \ndefined by Eq. 3.4 was used to evaluate the accuracy of the stand count and\
    \ canopy size \nestimations. \n\U0001D43F\U0001D43F1 \U0001D459\U0001D459\U0001D450\
    \U0001D450\U0001D450\U0001D450\U0001D450\U0001D450 = |\U0001D466\U0001D466ො\U0001D460\
    \U0001D460\U0001D460\U0001D460 − \U0001D466\U0001D466\U0001D460\U0001D460\U0001D460\
    \U0001D460| + \U0001D6FD\U0001D6FD × |\U0001D466\U0001D466ො\U0001D460\U0001D460\
    \U0001D460\U0001D460 − \U0001D466\U0001D466\U0001D460\U0001D460\U0001D460\U0001D460\
    |           (3.3) \n\U0001D440\U0001D440\U0001D440\U0001D440\U0001D440\U0001D440\
    \U0001D440\U0001D440 = 0.5 × (\n|\U0001D466\U0001D466ො\U0001D460\U0001D460\U0001D460\
    \U0001D460−\U0001D466\U0001D466\U0001D460\U0001D460\U0001D460\U0001D460|\n\U0001D466\
    \U0001D466\U0001D460\U0001D460\U0001D460\U0001D460\n+\n|\U0001D466\U0001D466ො\U0001D460\
    \U0001D460\U0001D460\U0001D460−\U0001D466\U0001D466\U0001D460\U0001D460\U0001D460\
    \U0001D460|\n\U0001D466\U0001D466\U0001D460\U0001D460\U0001D460\U0001D460\n) \
    \                (3.4) \n44 \n \nwhere \U0001D466\U0001D466ො\U0001D460\U0001D460\
    \U0001D460\U0001D460 is estimated stand count, \U0001D466\U0001D466\U0001D460\U0001D460\
    \U0001D460\U0001D460 is the true stand count, \U0001D466\U0001D466ො\U0001D460\U0001D460\
    \U0001D460\U0001D460 is estimated canopy size \nand \U0001D466\U0001D466\U0001D460\
    \U0001D460\U0001D460\U0001D460 is true canopy size, β is the ratio of the mean\
    \ of stand count to the mean of canopy \nsize in the training set.  \nDeep learning\
    \ models have provided promising results for agricultural applications \nin many\
    \ current studies but with limited potential for interpretation as a “black box”\
    \ system \n(Kamilaris and Prenafeta-Boldú, 2018). Several ways have been developed\
    \ in other studies \nto explain the mechanisms of DL models (Ghosal et al., 2018;\
    \ Mohanty et al., 2016). Those \nincluded visualization of the DL filters and\
    \ feature maps, deconvolutional networks (Zeiler \nand Fergus, 2014), calculation\
    \ of filters’ receptive field (Dumoulin and Visin, 2016), or \nthe Grad-class\
    \ activation map (Grad-CAM) (Selvaraju et al., 2017). In this study, feature \n\
    maps of the first two stages in the resnet18 and the Grad-regression activation\
    \ map (Grad-\nRAM) (Wang and Yang, 2017) were used to visually interpret the results.\
    \ The feature maps \nwere the outputs of each filter in each stage of the resnet18\
    \ model (Figure 3.5). All the \nfeature maps outputted from stage 5 (the 512 7\
    \ Х 7 features outputted from stage 5 in Figure \n3.5) were elementally summed\
    \ with weights that were connected between the outputs of \nAvgPool in stage 6\
    \ (the 512 1 Х 1 outputs from stage 6 in Figure 3.5) and the FC in stage \n7 (Figure\
    \ 3.5) to generate the Grad-RAM. This Grad-RAM can localize the discriminative\
    \ \nregions of seedlings in images that determined the final estimation of canopy\
    \ size and stand \ncount (Wang and Yang, 2017). \nData set preparation  \n A total\
    \ of 155 images were selected to train and test the DL model. A GRP included \n\
    two 6-m cotton rows as illustrated in Figure 3.1, resulting in 12×28=336 m of\
    \ cotton rows \nin total. Each selected image contained all or a portion of the\
    \ 6-m crop rows. All the \n45 \n \nindividual cotton seedlings and seedling clusters\
    \ in the images were segmented as RoIs \n(small red boxes in Figure 3.6) using\
    \ the method developed by (Feng et al., 2020). The \nnumber of seedlings in each\
    \ RoI was counted manually by playing back the recorded \nvideos, and each RoI\
    \ was labelled using the number of seedlings in the RoI. A few RoIs \nonly contained\
    \ part of a seedling (one seedling was identified as two separate RoIs) and \n\
    were labelled as 0.5. To improve the volume of the training dataset, a data augmentation\
    \ \nmethod was used as illustrated in Figure 3.6. Input images were cropped in\
    \ each image \nwith a length range from 0.7 m to 1.3 m of each cotton row and\
    \ including different numbers \nof consecutive RoIs, shown in Figure 3.6 as different\
    \ colored boxes.  \n \nFigure 3.6: Illustration showing the approach used for\
    \ the preparation of the training data \nand data augmentation. The red boxes\
    \ mark the RoIs that contained a single cotton \nseedling or a cluster of several\
    \ cotton seedlings. The yellow text gives the ID of each RoI \nand the black text\
    \ gives the number of seedlings in each RoI. The different color boxes \nare the\
    \ cropping images used as the input images of resnet18 model, where image size\
    \ \nvaried from 0.7 to 1.3 m, equaling 375 to 697 pixels.  \n46 \n \nThe augmented\
    \ input images were cropped as a square using the segmentation \nlength as side\
    \ length, which resulted in the dimensions of input images varying from \n375×375\
    \ to 697×697 pixels with the length from 0.7 m to 1.3 m (Figure 3.6). The positions\
    \ \nof the crop boxes from left to right in each image were random. The square\
    \ images provided \na constant ratio of height to width and minimized the distortion\
    \ of geometric features due \nto resizing (to 224 × 224 pixels as required by\
    \ resnet18). The number of seedlings in each \ninput image was the sum of the\
    \ seedlings of all RoIs. The canopy area (cm2) of seedlings \nof each input image\
    \ was calculated by Eq. 3.5.  \n\U0001D436\U0001D436\U0001D440\U0001D440 =\n\U0001D441\
    \U0001D441\U0001D45D\U0001D45D ×10000\n\U0001D43A\U0001D43A\U0001D43A\U0001D43A\
    \U0001D43A\U0001D43A2\n                                       (3.5) \nwhere, CA\
    \ is the canopy area of all seedlings from aerial images (cm2), Np is the total\
    \ \nnumber of pixels in a RoI of an input image. GSD is the ground sample distance\
    \ of each \ninput image (pixel m-1). In this study, a total of about 20000 input\
    \ images were generated, \nwhich were split 85% in the training set and 15% in\
    \ the test set. The model was trained and \nevaluated using the Pytorch package\
    \ (pytorch.org) (Paszke et al., 2017). \nPerformance of deep learning model resnet18\
    \ \nThe seedling data set that included more than 20000 input images was used\
    \ to train \nresnet18 with 40 epochs. An estimation error of an overall MAPE =\
    \ 3.3% was obtained in \ntraining and an overall MAPE = 4.4% was obtained in testing.\
    \ Figure 3.7 shows the true \nvalues and the predicted values of the test set\
    \ for cotton stand count and canopy size. For \nstand count estimation, R2 = 0.95\
    \ and MAPE = 4.3% were obtained, while for canopy size \nestimation R2 = 0.93\
    \ and MAPE = 4.5% were obtained. These results are promising when \ncompared to\
    \ similar published studies that reported MAPE from 9.8% to 5.1% (Chen et al.,\
    \ \n2018; Gnädinger and Schmidhalter, 2017; Jin et al., 2017; Ribera et al., 2017;\
    \ Sankaran et \n47 \n \nal., 2015; Sankaran et al., 2017; Zhao et al., 2018).\
    \ Only one of those papers used a deep \nlearning model and estimated stand count\
    \ with MAPE = 6.7% (Ribera et al., 2017), a value \nlarger than that obtained\
    \ in this study.  \n \nFigure 3.7: Predicted results of (a) cotton stand count\
    \ and (b) canopy size in the test set \nTo understand the reasons for such results\
    \ and potential approaches for improving \nthe accuracy, Figure 3.8 shows the\
    \ feature maps and the Grad-RAM. Figure 3.8a, e, and i \nshow three examples of\
    \ input images that had different numbers of seedlings and variations \nin soil\
    \ color. It can be seen from Figure 3.8b, f and j that their seedlings were identified\
    \ \nwith higher values in the feature maps of stage 1. Although the difference\
    \ between soil and \nseedlings decreased when the soil color was bright (Figure\
    \ 3.8i and j), they were segmented \ncorrectly in stage 2 (Figure 3.8c, g and\
    \ k), which not only highlighted the seedlings but \nalso the color differences\
    \ of the soil. Figure 3.8d, h and l show the seedlings identified in \nthe last\
    \ convolution layer (stage 5) of resnet18. When the number of seedlings in the\
    \ \nclusters and the canopy size of the seedlings decreased, the values of the\
    \ Grad-RAM map \ndecreased. Based on the algorithm of the Grad-RAM calculation,\
    \ it can be confirmed that \nthe model’s final estimation of stand count and canopy\
    \ size was decided by the regions of \nseedlings rather than other regions, which\
    \ was in line with our expectations of the model. \n48 \n \n \nFigure 3.8: Feature\
    \ maps of stages 1 and 2 of the resnet18 model and the Grad-regression \nactivation\
    \ map (Grad-RAM) of stage 5. (a), (e) and (i) are three input images; (b), (f)\
    \ and \n(j) are the corresponding feature maps of average outputs of 64 filters\
    \ in stage 1 of the \nresnet18 model. The higher values in the feature maps mean\
    \ that these regions were \nhighlighted by the model and that information would\
    \ be passed to the next layers. The \ncolor scale legends of (f) and (j) are the\
    \ same as that of (b). (c), (g) and (k) are the \ncorresponding feature maps of\
    \ average outputs of 64 filters in stage 2. The color scale \nlegends of (g) and\
    \ (k) are the same as that of (c). (d), (h) and (l) are the Grad-RAM \nextracted\
    \ from stage 5 of resnet18. The color scale legend of (h) and (l) are the same\
    \ as \nthat of (d). \nVegetation indices such as excess green index (ExG) combined\
    \ with a dynamic \nthreshold method, Otsu’s method, have been used to segment\
    \ seedlings from the \nbackground (Varela et al., 2018; Zhao et al., 2018). Otsu’s\
    \ method can automatically find \n49 \n \nan image threshold having the largest\
    \ difference between two classes and the smallest \ndifference within each class\
    \ (Otsu, 1979). However, the variability in soil texture and water \ncontent may\
    \ cause soil color differences, which makes it challenging to segment seedlings\
    \ \n(Feng et al., 2020). One example of using the ExG with Otsu’s method is shown\
    \ in Figure \n3.9a and b, from which we can see that some of the seedlings could\
    \ not be identified \nsuccessfully. Figure 3.9c shows an enhanced image of Figure\
    \ 3.9a using a decorrelation \nstretch procedure with a global threshold of 180\
    \ that improves the performance of \nsegmentation (Figure 3.9d). However, 180\
    \ was a global threshold instead of a dynamic \nthreshold (Gnädinger and Schmidhalter,\
    \ 2017), and needed to be determined by statistical \nanalysis of the crop pixel\
    \ values or by the image histograms (Feng et al., 2020) that aim to \nfind a global\
    \ threshold to largely separate the plants and soil. This global threshold is\
    \ a \nglobal optimal value in the whole data set, and there may be some misidentification\
    \ when \nusing this value. Variations in soil texture and/or moisture level resulted\
    \ in large \ndifferences in soil color and bright soil was detected as crop objects\
    \ when a global threshold \nwas used. When building the input image set for resnet18,\
    \ visual counting labelled the \ndetected objects that did not include cotton\
    \ seedlings with a 0 value (that is, misidentified \nby the global threshold).\
    \ This manually helped resnet18 learn to correct the global \nthreshold segmentation\
    \ error to provide more accurate stand count and canopy size results \nthan methods\
    \ based only on image segmentation. \n50 \n \n \nFigure 3.9: Illustration of the\
    \ complexity of image background removal for segmentation \nof seedlings due to\
    \ soil color resulting from variations in texture and/or moisture content \nover\
    \ a field. (a) A portion of an RGB image including four crop rows; (b) A binary\
    \ image \nshowing the segmented seedlings using the ExG and Otsu’s method. Some\
    \ seedlings in \nthe third and the fourth rows were not identified. (c) The pertinent\
    \ image after using \ndecorrelation stretch procedure and (d) its results of seedling\
    \ segmentation. \nComparison of resnet18 and other deep learning models \nThe\
    \ resnet18 model was running on a desktop configured as an Intel Core i9-9900K\
    \ \n3.60 GHz CPU, an NVIDIA GeForce RTX 2060 GPU with 6GB memory, 32GB RAM \n\
    and 256 GB solid-state drive (SSD). The performance of the resnet18 model in estimation\
    \ \naccuracy and computation resources for training models was compared with other\
    \ popular \nDL models, including resnet50 (He et al., 2016), AlexNet (Krizhevsky,\
    \ 2014), VGG11, \nVGG16 (Simonyan and Zisserman, 2014), SqueezeNet (Iandola et\
    \ al., 2016) and DenseNet \n51 \n \n(Huang et al., 2017). As shown in Table 3.3,\
    \ the resnet18 model had a lower use rate of \nGPU and GPU memory than other DL\
    \ models except for the SqueezeNet that used fewer \ncomputation resources but\
    \ had a higher MAPE. The size of the parameter file of resnet18 \nwas smaller\
    \ than other models except for DenseNet, which had a smaller Parameter file, \n\
    but used more computation resources and had a longer training time. Except for\
    \ the VGG16, \nresnet18 had a lower test MAPE than other models, however, VGG16\
    \ used the most GPU \nand GPU memory. Therefore, when considering both the low\
    \ MAPE and low computation \nresource usage, the resnet18 model showed more potential\
    \ to integrate into UAV systems \nto conduct real time emergence evaluation in\
    \ the future. AlexNet was the second most \npromising model based on Table 3.3\
    \ and could be considered as an alternative. \nTable 3.3: Accuracy and computation\
    \ resources comparison  \nModel \nTrain \nMAPE \n(%) \nTest \nMAPE \n(%) \nTraining\
    \ \ntime in s \n(40 epoch) \nCPU \n(%) \nGPU \n(%) \nGPU \nmemory \n(GB) \nRAM\
    \ \n(GB) \nParameter \nfile (MB) \nResnet18 \n3.3 \n4.4 \n5508 \n71 \n60 \n1.1\
    \ \n7.2 \n42.6 \nResnet50 \n4.9 \n5.0 \n11482 \n69 \n80 \n2.1 \n8.1 \n89.9 \n\
    AlexNet \n4.3 \n4.4 \n4294 \n71 \n58 \n2.1 \n7.9 \n217.0 \nVGG11 \n6.5 \n6.9 \n\
    11389 \n67 \n79 \n4.2 \n7.5 \n491.0 \nVGG16 \n2.9 \n3.9 \n15590 \n68 \n88 \n4.6\
    \ \n7.6 \n512.0 \nSqueezeNet \n7.0 \n7.9 \n4948 \n71 \n54 \n1.2 \n7.8 \n2.8 \n\
    DenseNet \n4.6 \n5.0 \n18951 \n71 \n77 \n2.3 \n9.0 \n27.0 \n \n3.6 Development\
    \ of a framework for evaluation of cotton emergence \nAn image processing and\
    \ analysis framework was developed in Python with the \nMATLAB engine application\
    \ programming interface (API) for Python. This framework \nincluded an easy to\
    \ use graphical user interface (GUI) to guide users 1) to train the deep \n52\
    \ \n \nlearning model using their own data set, and 2) map their crop emergence.\
    \ The framework \nwas implemented following the flowchart in Figure 3.10. The\
    \ process for training the \nmodel for specific applications is illustrated in\
    \ Figure 3.10a, which includes setting GRPs, \npre-processing training dataset\
    \ and training the model. After the model was trained for a \nspecific application,\
    \ individual images collected in the field could be processed using the \nprocedure\
    \ illustrated in Figure 3.10b. All the cotton rows in each image frame would be\
    \ \nautomatically split into geo-referenced 1-m segments based on the GPS information\
    \ in the \nmetadata of images. The output would be the geo-referenced stand count\
    \ and canopy area \nof seedlings in every meter of the row, which would be used\
    \ to map the emergence of the \nfield. \n \n53 \n \n \nFigure 3.10: Overall processing\
    \ flowchart. (a) Training procedure; (b) Cotton emergence \nmapping procedure;\
    \ (c) Legend used in both (a) and (b). \nThe data processing framework was developed\
    \ in a Windows 10 operating system \n(Microsoft, Redmond, WA, USA) environment\
    \ using Python software (v3.6), Matlab \nsoftware (v2018a), Matlab engine API\
    \ for Python, Opencv package (v3.4) (Bradski, 2000), \nScikit-learn package (v0.22)\
    \ (Pedregosa et al., 2011), NumPy package (v1.16) (Oliphant, \n2006), Pandas package\
    \ (v0.25) (McKinney, 2010) and Pytorch package (v1.2) (Paszke et \nal., 2017).\
    \ The framework has been uploaded to GitHub (https://github.com \n/AJFeng/Emergence-evaluation-Framework)\
    \ and is ready for testing by other research \ngroups. \nStand count and canopy\
    \ size mapping \nManually measured and estimated stand count and canopy area per\
    \ seedling from \nthe 20000 input images were summarized using histograms as shown\
    \ in Figure 3.11. The \nmean stand count of manual measurements was 12.5 seedlings\
    \ per meter with a standard \n54 \n \ndeviation of 2.2. The mean value of 12.5\
    \ was higher than the target seeding rate of 11.0 \nseed m-1. However, based on\
    \ field observation by the farm operator, it was found that there \nwas a planter-calibration\
    \ error and the actual rate was close to the mean value in this study. \nThe figure\
    \ also shows that the manually measured canopy size per seedling was 24.3 ± 7.0\
    \ \ncm2, indicating a big variation in the canopy size of the measured seedlings.\
    \ The estimated \nstand count and canopy area of the tested images for the whole\
    \ field were shown in Figure \n3.11c and d. This showed that the estimated values\
    \ of the whole field were consistent with \nour manual measurement with sampling.\
    \ \n \nFigure 3.11: Histogram of (a) stand count per meter; and (b) canopy size\
    \ of the input \nimages that were manually labelled in the GRPs. Predicted results\
    \ of (c) cotton stand \ncount and (d) canopy size in the whole field. \n55 \n\
    \ \nThe stand count and canopy size of the whole field were calculated using the\
    \ \ndeveloped model with all collected images. All data were geo-referenced using\
    \ the \nmetadata of the images and the GPS assignment method in this study. Time\
    \ spent on the \nmapping was 2.2 s for each 20 M pixel image frame, which was\
    \ nearly real-time image \nprocessing as the UAV took images every 2 s. When we\
    \ checked the procedures, it was \nfound that the majority of the processing time\
    \ (2.2 s) was spent on the process of GPS \nassignment (about 1.8 s per image).\
    \ The search of connected regions and SHT algorithm \nwas the most time-consuming\
    \ steps as this was the limitation of search-based methods.  \nGeo-referenced\
    \ stand count and canopy size were imported to the open-source \nsoftware QGIS\
    \ (version 3.6, www.qgis. org). Figure 3.12 shows the field maps of cotton \n\
    stand count and canopy size overlaid on a Google map (Google, Mountain View, CA,\
    \ \nUSA). Visual observation found that the distribution patterns of two maps\
    \ (Figure 3.12a \nand b) were similar to that of the yield map (Figure 3.12c)\
    \ and the soil ECa map (Figure \n3.12d), i.e., regions of the field with low seedling\
    \ canopy sizes had low ECa and low yield. \nRegions with lower ECa corresponded\
    \ to areas with a high-profile sand content (Sudduth \net al., 2003) and therefore\
    \ a low soil water holding capacity, which may affect the crop \nemergence and\
    \ growth (Feng et al., 2019b). The quantitative relationship among crop \nemergence,\
    \ soil condition and yield need further analysis. The framework developed in \n\
    this paper can be used to help farmers and researchers to explore the seedling\
    \ emergence \nstatus of their field efficiently and in real-time. Our GPS accuracy\
    \ test showed that the \naccuracy of image GPS coordinates based on the 27 ground\
    \ stakes was 1.72 m with a \nstandard deviation of 1.37 m (1.72 ±1.37 m). This\
    \ study aimed to enable real-time stand \ncount and canopy size mapping with meter\
    \ level spatial resolution using UAV-based RGB \n56 \n \nimages and the geo-location\
    \ of each image frame may be improved using an RTK GPS, \nfor example, DJI Phantom\
    \ 4 RTK Drone (DJI, Shenzhen, Guangdong, China) that has an \naccuracy of 1cm\
    \ + 1ppm RTK horizontal positioning. \n \nFigure 3.12: (a) Cotton stand count\
    \ mapping and (b) canopy size mapping; (c) yield map; \n(d) soil ECa map. The\
    \ red circles show the 28 GRPs. \nThe use of the data processing framework \n\
    The data processing framework consists of two major tasks, i.e. model training\
    \ and \nemergence evaluation. Users may directly use the model provided to map\
    \ cotton fields \nhaving similar data collection conditions to our experiment,\
    \ i.e., 0.97 m fixed crop row \nspacing, images collected in about 16 DAP, 2.7\
    \ mm pixel-1 and 60% image overlap. Since \nthe fixed row spacing is used for\
    \ canopy size GSD calibration, the developed method can \npotentially be used\
    \ in the conditions of different row spacing and image overlap (from 40% \nto\
    \ 80%) when the values of the canopy size map are modified accordingly based on\
    \ the \nratio of our row spacing to users’ specific row spacing. Users may have\
    \ images with \ndifferent image resolution and collected a few days earlier or\
    \ later than 16 DAP that have \ndifferent canopy shapes, sizes and overlapping.\
    \ It is expected that users would train a \nSeedlings/m\nCanopy size\ncm2/seedling\n\
    (a)\n(b)\n(d)\nECa-sh\n(mS m-1)\n(c)\nYield\n(kg ha-1)\n57 \n \nspecific model\
    \ using their own data by following the processing steps described in this \n\
    paper. The developed framework has not been tested in other crops such as soybean\
    \ and \ncorn but will be evaluated in future studies. A detailed introduction\
    \ file that explained the \nusage of the framework and every item appearing in\
    \ the GUI was attached with the \nframework in GitHub. \nFigure 3.13 illustrates\
    \ the major steps to train a customized model using UAV \nimagery data. All raw\
    \ image frames that include GCPs should be stored in one folder and \nwould be\
    \ read automatically by the program. The program would first conduct the seedling\
    \ \nsegmentation process following the orange mouse icon in Figure 3.13. This\
    \ would generate: \n1) a file that has the row spacing calculation results; 2)\
    \ a folder including images with \nsegmented crop seedlings; and 3) a file that\
    \ has the GPS coordinates of the segmented \nimages and waits for users to visually\
    \ label the cotton seedlings. After visual counting, the \nimage cropping process\
    \ following the green mouse icon in Figure 3.13 would ask the user \nto provide\
    \ the address of the rotated images folder, the labelling file, and the row spacing\
    \ \nfile (those were all generated from the above orange icon process of the seedling\
    \ \nsegmentation process) to crop the cotton seedlings into 1-m segmented images\
    \ to build the \ntraining data set. This would generate: 1) input images of the\
    \ model that were cropped from \neach individual image frame; 2) a file that included\
    \ image names of these cropped images \nand their labels. These would be used\
    \ to train the resnet18 model (the training process \nfollowing the blue mouse\
    \ icon in Figure 3.13). After this training process, the model trained \non the\
    \ users’ own data would be generated.  \n58 \n \n \nFigure 3.13: The process for\
    \ training a customized model using the users’ own data set. \nDifferent color\
    \ of the mouse icons showed the different processing options as described \nin\
    \ the text.  \nThe process of mapping crop emergence is illustrated in Figure\
    \ 3.14. The GPS \nassignment process (following the orange mouse icon in Figure\
    \ 3.14) would guide users to \nassign GPS coordinates to each 1-meter of crop\
    \ row. After geo-referencing all data of the \nwhole field, the process would\
    \ generate: 1) input images of resnet18 cropped by a meter \nof each cotton row;\
    \ 2) the related GPS file of each input image. Those input images and \nthe GPS\
    \ file would be used to map the cotton stand count and canopy size (the mapping\
    \ \nprocess following the blue mouse icon in Figure 3.14). \n59 \n \n \nFigure\
    \ 3.14: The process for mapping the cotton emergence of the whole field. Different\
    \ \ncolor of the mouse icons showed the different process options as described\
    \ in the text. \n3.7 Conclusion \nThis study developed a method and related framework\
    \ for real-time cotton stand \ncount and canopy size mapping. A UAV system with\
    \ a high-resolution RGB camera was \nused to take individual image frames. The\
    \ cotton rows in each image frame were detected \nand the row angle was used for\
    \ rotating each individual frame. The row spacing was used \nas a reference for\
    \ dynamic GSD calibration of each image frame. Seedlings in every \nindividual\
    \ frame were located based on their position in image coordinates and the GSD.\
    \ \nThe located seedlings were used as the input to the deep learning model resnet18\
    \ for stand \ncount and canopy size estimation. The results from the resnet18\
    \ model and the related \nlocation information were used to map cotton emergence.\
    \ Results showed that the method \nhad an overall error of MAPE = 4.4% and worked\
    \ better than current traditional image \nsegmentation methods. The framework\
    \ could be used as a powerful tool for farmers and \n60 \n \nresearchers to explore\
    \ the relationships between cotton emergence, soil conditions and \nweather conditions.\
    \ \n3.8 Future work \nComparing to image stitching and mosaic processing, this\
    \ study processed \nindividual image frames to map the emergence and had the problem\
    \ of some same seedling \nthat duplicate in two different image frames. For two\
    \ image frames that included the same \nseedlings, those data would be mapped\
    \ twice. Since this study mapped based on GPS of \neach meter of each crop row,\
    \ the data may be mapped twice at the same position (due to \nthe GPS error, they\
    \ would be mapped twice at the close position). Later, average processing \nwas\
    \ needed to group those mapped data points in each meter together. \nThis study\
    \ used MAE to evaluate the emergence prediction performance. It is worth \ntrying\
    \ other types of error measurement methods rather than MAE since the numbers of\
    \ \nseedlings were small in each frame and the performance of the seedling prediction\
    \ in each \ncluster of the frames needed to be evaluated. \nFor the current data\
    \ set, we had weeds control in the field and few weeds appeared \nin the image\
    \ data. This study did not use any methods to deal with weeds. However, for \n\
    some fields with weeds, the stand count and canopy size prediction may have errors\
    \ due to \nthe difficulty of identification between weeds and cotton seedlings.\
    \ Weed identification \nmethods are needed for this case. \n61 \n \n3.9 Literature\
    \ cited \nAbadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C.,\
    \ Corrado, G.S., \nDavis, A., Dean, J., Devin, M., 2016. Tensorflow: Large-scale\
    \ machine learning \non heterogeneous distributed systems. arXiv preprint arXiv:1603.04467.\
    \ \nAyyachamy, S., Alex, V., Khened, M., Krishnamurthi, G., 2019. Medical image\
    \ retrieval \nusing Resnet-18, Medical Imaging 2019: Imaging Informatics for Healthcare,\
    \ \nResearch, and Applications. International Society for Optics and Photonics,\
    \ p. \n1095410. \nBargoti, S., Underwood, J., 2017. Deep fruit detection in orchards,\
    \ 2017 IEEE \nInternational Conference on Robotics and Automation (ICRA). IEEE,\
    \ pp. 3626-\n3633. \nBradski, G., 2000. The opencv library. Dr Dobb's J. Software\
    \ Tools 25, 120-125. \nBrown, M., Lowe, D.G., 2003. Recognising panoramas, ICCV,\
    \ p. 1218. \nBugayevskiy, L.M., Snyder, J., 2013. Map projections: A reference\
    \ manual. CRC Press. \nChawla, N.V., 2009. Data mining for imbalanced datasets:\
    \ An overview, Data mining \nand knowledge discovery handbook. Springer, pp. 875-886.\
    \ \nChen, R., Chu, T., Landivar, J.A., Yang, C., Maeda, M.M., 2018. Monitoring\
    \ cotton \n(Gossypium hirsutum L.) germination using ultrahigh-resolution UAS\
    \ images. \nPrecision Agriculture 19, 161-177. \nChen, S.W., Shivakumar, S.S.,\
    \ Dcunha, S., Das, J., Okon, E., Qu, C., Taylor, C.J., \nKumar, V., 2017. Counting\
    \ apples and oranges with deep learning: A data-driven \napproach. IEEE Robotics\
    \ and Automation Letters 2, 781-788. \n62 \n \nDuda, R.O., Hart, P.E., 1972. Use\
    \ of the Hough transformation to detect lines and curves \nin pictures. Communications\
    \ of the ACM 15, 11-15. \nDumoulin, V., Visin, F., 2016. A guide to convolution\
    \ arithmetic for deep learning. arXiv \npreprint arXiv:1603.07285. \nDyrmann,\
    \ M., Jørgensen, R.N., Midtiby, H.S., 2017. RoboWeedSupport-Detection of \nweed\
    \ locations in leaf occluded cereal crops using a fully convolutional neural \n\
    network. Advances in Animal Biosciences 8, 842-847. \nDyrmann, M., Karstoft, H.,\
    \ Midtiby, H.S., 2016. Plant species classification using deep \nconvolutional\
    \ neural network. Biosystems Engineering 151, 72-80. \nEgli, D., Rucker, M., 2012.\
    \ Seed vigor and the uniformity of emergence of corn \nseedlings. Crop Science\
    \ 52, 2774-2782. \nErhan, D., Manzagol, P.-A., Bengio, Y., Bengio, S., Vincent,\
    \ P., 2009. The difficulty of \ntraining deep architectures and the effect of\
    \ unsupervised pre-training, Artificial \nIntelligence and Statistics, pp. 153-160.\
    \ \nFeng, A., Sudduth, K., Vories, E., Zhou, J., 2019a. Evaluation of cotton stand\
    \ count using \nUAV-based hyperspectral imagery, 2019 ASABE Annual International\
    \ Meeting. \nAmerican Society of Agricultural and Biological Engineers, p. 1.\
    \ \nFeng, A., Zhang, M., Sudduth, K.A., Vories, E.D., Zhou, J., 2019b. Cotton\
    \ yield \nestimation from UAV-based plant height. Transactions of the ASABE 62,\
    \ 393-\n404. \nFeng, A., Zhou, J., Vories, E., Sudduth, K.A., 2020. Evaluation\
    \ of cotton emergence \nusing UAV-based narrow-band spectral imagery with customized\
    \ image \nalignment and stitching algorithms. Remote Sensing 12, 1764. \n63 \n\
    \ \nForcella, F., Arnold, R.L.B., Sanchez, R., Ghersa, C.M., 2000. Modeling seedling\
    \ \nemergence. Field Crops Research 67, 123-139. \nFu, L., Majeed, Y., Zhang,\
    \ X., Karkee, M., Zhang, Q., 2020. Faster R–CNN–based apple \ndetection in dense-foliage\
    \ fruiting-wall trees using RGB and depth features for \nrobotic harvesting. Biosystems\
    \ Engineering 197, 245-256. \nGao, F., Fu, L., Zhang, X., Majeed, Y., Li, R.,\
    \ Karkee, M., Zhang, Q., 2020. Multi-class \nfruit-on-plant detection for apple\
    \ in SNAP system using Faster R-CNN. \nComputers and Electronics in Agriculture\
    \ 176, 105634. \nGeiger, A., Moosmann, F., Car, Ö., Schuster, B., 2012. Automatic\
    \ camera and range \nsensor calibration using a single shot, 2012 IEEE International\
    \ Conference on \nRobotics and Automation. IEEE, pp. 3936-3943. \nGhassemi-Golezani,\
    \ K., Dalil, B., 2014. Effects of seed vigor on growth and grain yield \nof maize.\
    \ Plant Breeding and Seed Science 70, 81-90. \nGhosal, S., Blystone, D., Singh,\
    \ A.K., Ganapathysubramanian, B., Singh, A., Sarkar, S., \n2018. An explainable\
    \ deep machine vision framework for plant stress \nphenotyping. Proceedings of\
    \ the National Academy of Sciences 115, 4613-4618. \nGnädinger, F., Schmidhalter,\
    \ U., 2017. Digital counts of maize plants by unmanned aerial \nvehicles (UAVs).\
    \ Remote Sensing 9, 544. \nGoodell, P.B., Davis, R.M., Godfrey, L.D., Hutmacher,\
    \ R.B., Roberts, P.A., Wright, \nS.D., M, B.V., Haviland, D.R., Munier, D.J.,\
    \ Natwick, E.T., 2015. UC IPM pest \nmanagement guidelines cotton, Oakland, CA.\
    \ \nGoodfellow, I., Bengio, Y., Courville, A., Bengio, Y., 2016. Deep learning.\
    \ MIT press \nCambridge. \n64 \n \nHe, K., Zhang, X., Ren, S., Sun, J., 2015.\
    \ Spatial pyramid pooling in deep convolutional \nnetworks for visual recognition.\
    \ IEEE transactions on pattern analysis and \nmachine intelligence 37, 1904-1916.\
    \ \nHe, K., Zhang, X., Ren, S., Sun, J., 2016. Deep residual learning for image\
    \ recognition, \nProceedings of the IEEE conference on computer vision and pattern\
    \ recognition, \npp. 770-778. \nHuang, G., Liu, Z., Van Der Maaten, L., Weinberger,\
    \ K.Q., 2017. Densely connected \nconvolutional networks, Proceedings of the IEEE\
    \ conference on computer vision \nand pattern recognition, pp. 4700-4708. \nHumphrey,\
    \ E.J., Bello, J.P., LeCun, Y., 2012. Moving beyond feature design: Deep \narchitectures\
    \ and automatic feature learning in music informatics, ISMIR. \nCiteseer, pp.\
    \ 403-408. \nIandola, F.N., Han, S., Moskewicz, M.W., Ashraf, K., Dally, W.J.,\
    \ Keutzer, K., 2016. \nSqueezeNet: AlexNet-level accuracy with 50x fewer parameters\
    \ and< 0.5 MB \nmodel size. arXiv preprint arXiv:1602.07360. \nJin, X., Liu, S.,\
    \ Baret, F., Hemerlé, M., Comar, A., 2017. Estimates of plant density of \nwheat\
    \ crops at emergence from very low altitude UAV imagery. Remote Sensing \nof Environment\
    \ 198, 105-114. \nKamilaris, A., Prenafeta-Boldú, F.X., 2018. Deep learning in\
    \ agriculture: A survey. \nComputers and electronics in agriculture 147, 70-90.\
    \ \nKoh, J.C., Hayden, M., Daetwyler, H., Kant, S., 2019. Estimation of crop plant\
    \ density at \nearly mixed growth stages using UAV imagery. Plant Methods 15,\
    \ 64. \n65 \n \nKrizhevsky, A., 2014. One weird trick for parallelizing convolutional\
    \ neural networks. \narXiv preprint arXiv:1404.5997. \nLi, B., Xu, X., Han, J.,\
    \ Zhang, L., Bian, C., Jin, L., Liu, J., 2019. The estimation of crop \nemergence\
    \ in potatoes by UAV RGB imagery. Plant methods 15, 15. \nLipan, F., Groza, A.,\
    \ 2010. Mining traffic patterns from public transportation GPS data, \nProceedings\
    \ of the 2010 IEEE 6th International Conference on Intelligent \nComputer Communication\
    \ and Processing. IEEE, pp. 123-126. \nLiu, S., Baret, F., Allard, D., Jin, X.,\
    \ Andrieu, B., Burger, P., Hemmerlé, M., Comar, A., \n2017. A method to estimate\
    \ plant density and plant spacing heterogeneity: \napplication to wheat crops.\
    \ Plant methods 13, 38. \nMcKinney, W., 2010. Data structures for statistical\
    \ computing in python, Proceedings of \nthe 9th Python in Science Conference.\
    \ Austin, TX, pp. 51-56. \nMohanty, S.P., Hughes, D.P., Salathé, M., 2016. Using\
    \ deep learning for image-based \nplant disease detection. Frontiers in plant\
    \ science 7, 1419. \nMonawar, T., Mahmud, S.B., Hira, A., 2017. Anti-theft vehicle\
    \ tracking and regaining \nsystem with automatic police notifying using Haversine\
    \ formula, 2017 4th \nInternational conference on Advances in Electrical Engineering\
    \ (ICAEE). IEEE, \npp. 775-779. \nNanni, L., Ghidoni, S., Brahnam, S., 2017. Handcrafted\
    \ vs. non-handcrafted features for \ncomputer vision classification. Pattern Recognition\
    \ 71, 158-172. \nNielsen, M.A., 2015. Neural networks and deep learning. Determination\
    \ press San \nFrancisco, CA, USA:. \nOliphant, T.E., 2006. A guide to NumPy. Trelgol\
    \ Publishing USA. \n66 \n \nOtsu, N., 1979. A threshold selection method from\
    \ gray-level histograms. IEEE \ntransactions on systems, man, and cybernetics\
    \ 9, 62-66. \nPan, S.J., Yang, Q., 2009. A survey on transfer learning. IEEE Transactions\
    \ on \nknowledge and data engineering 22, 1345-1359. \nPaszke, A., Gross, S.,\
    \ Chintala, S., Chanan, G., Yang, E., DeVito, Z., Lin, Z., Desmaison, \nA., Antiga,\
    \ L., Lerer, A., 2017. Automatic differentiation in pytorch. \nPedregosa, F.,\
    \ Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, \n\
    M., Prettenhofer, P., Weiss, R., Dubourg, V., 2011. Scikit-learn: Machine learning\
    \ \nin Python. Journal of Machine Learning Research 12, 2825-2830. \nRahnemoonfar,\
    \ M., Sheppard, C., 2017. Deep count: fruit counting based on deep \nsimulated\
    \ learning. Sensors 17, 905. \nRibera, J., Chen, Y., Boomsma, C., Delp, E., 2017.\
    \ Counting plants using deep learning, \n2017 IEEE Global Conference on Signal\
    \ and Information Processing (GlobalSIP). \nIEEE, Montreal, QC, Canada, pp. 1344-1348.\
    \ \nRussakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang,\
    \ Z., Karpathy, \nA., Khosla, A., Bernstein, M., 2015. Imagenet large scale visual\
    \ recognition \nchallenge. International Journal of Computer Vision 115, 211-252.\
    \ \nSankaran, S., Khot, L.R., Carter, A.H., 2015. Field-based crop phenotyping:\
    \ \nMultispectral aerial imaging for evaluation of winter wheat emergence and\
    \ spring \nstand. Computers and Electronics in Agriculture 118, 372-379. \nSankaran,\
    \ S., Quirós, J.J., Knowles, N.R., Knowles, L.O., 2017. High-resolution aerial\
    \ \nimaging based estimation of crop emergence in potatoes. American Journal of\
    \ \nPotato Research 94, 658-663. \n67 \n \nSansone, C., Isakeit, T., Lemon, R.,\
    \ Warrick, B., 2002. Texas cotton production: \nEmphasizing integrated pest management.\
    \ Texas Cooperative Extension Service, \nthe Texas A & M University System, Texas,\
    \ USA. \nSelvaraju, R.R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., Batra,\
    \ D., 2017. Grad-\ncam: Visual explanations from deep networks via gradient-based\
    \ localization, \nProceedings of the IEEE International Conference on Computer\
    \ Vision, pp. 618-\n626. \nSimonyan, K., Zisserman, A., 2014. Very deep convolutional\
    \ networks for large-scale \nimage recognition. arXiv preprint arXiv:1409.1556.\
    \ \nSnyder, J.P., 1987. Map projections--A working manual. US Government Printing\
    \ \nOffice. \nSudduth, K.A., Kitchen, N., Bollero, G., Bullock, D., Wiebold, W.,\
    \ 2003. Comparison of \nelectromagnetic induction and direct sensing of soil electrical\
    \ conductivity. \nAgronomy Journal 95, 472-482. \nSupak, J., 1990. Making replant\
    \ decisions, 1990 Beltwide cotton production conference. \nNational Cotton Council\
    \ of America, pp. 45-48. \nSzegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed,\
    \ S., Anguelov, D., Erhan, D., \nVanhoucke, V., Rabinovich, A., 2015. Going deeper\
    \ with convolutions, \nProceedings of the IEEE conference on computer vision and\
    \ pattern recognition, \npp. 1-9. \nVarela, S., Dhodda, P.R., Hsu, W.H., Prasad,\
    \ P., Assefa, Y., Peralta, N.R., Griffin, T., \nSharda, A., Ferguson, A., Ciampitti,\
    \ I.A., 2018. Early-season stand count \n68 \n \ndetermination in corn via integration\
    \ of imagery from unmanned aerial systems \n(UAS) and supervised learning techniques.\
    \ Remote Sensing 10, 343. \nWang, Z., Yang, J., 2017. Diabetic retinopathy detection\
    \ via deep convolutional networks \nfor discriminative localization and visual\
    \ explanation. arXiv preprint \narXiv:1703.10757. \nWiles, L.J., Schweizer, E.E.,\
    \ 1999. The cost of counting and identifying weed seeds and \nseedlings. Weed\
    \ Science 47, 667-673. \nZeiler, M.D., Fergus, R., 2014. Visualizing and understanding\
    \ convolutional networks, \nEuropean conference on computer vision. Springer,\
    \ pp. 818-833. \nZhang, Z., 2000. A flexible new technique for camera calibration.\
    \ IEEE Transactions on \npattern analysis and machine intelligence 22. \nZhao,\
    \ B., Zhang, J., Yang, C., Zhou, G., Ding, Y., Shi, Y., Zhang, D., Xie, J., Liao,\
    \ Q., \n2018. Rapeseed seedling stand counting and seeding performance evaluation\
    \ at \ntwo early growth stages based on unmanned aerial vehicle imagery. Frontiers\
    \ in \nPlant Science 9. \n \n69 \n \nChapter 4. SOIL AND ELEVATION EFFECTS ON\
    \ COTTON \nEMERGENCE \n4.1 Abstract \nCrop emergence is an important agronomic\
    \ factor for farmers and researchers to \nexplore crop development in the early\
    \ growth stage, as well as explore the relationship \nbetween emergence, subsequent\
    \ growth and environment (such as soil texture and field \nelevation). A method\
    \ and related framework were developed for near real-time emergence \nmapping\
    \ using Unmanned aerial vehicle (UAV)-based images in our previous study. \nHowever,\
    \ analysis of the emergence data, soil and field elevation, as well as the UAV\
    \ \nimage data collected in the later growth stages needed ways to align those\
    \ data from \ndifferent sensor systems together. The GPS error of the previous\
    \ study depended on the \nUAV GPS system, which was 1.72 ±1.37 m comparing with\
    \ the ground RTK measurement. \nTo improve the alignment accuracy, the goal of\
    \ this study is to improve the GPS accuracy \nof cotton emergence mapping and\
    \ then evaluate the feasibility of a UAV-based imaging \nsystem in quantifying\
    \ the relationship between emergence, subsequent growth and \nenvironment. A crop\
    \ row alignment method was developed based on feature detection and \nmatching,\
    \ and then the geo-referenced crop emergence data were registered with its \n\
    subsequent growth data (UAV-based vegetation indices) in July as well as soil\
    \ and field \nelevation data. Pearson correlation, ANOVA and machine learning\
    \ model XGBoost were \nused to analyze the relationships between stand count and\
    \ canopy size with field elevation, \nsoil, as well as with the UAV-based vegetation\
    \ indices in the next growth stages in July. \nResults showed that the GPS error\
    \ comparing with the ground RTK was 0.17 ± 0.13 m, \n70 \n \nwhich was higher\
    \ accuracy than our previous methods. Emergence, ECa-sh, ECa-dp and \nclay10-clay30\
    \ were ranked the first six important features to cotton emergence. The \nseedling\
    \ size had about 0.4-0.5 Pearson correlation coefficients with the image features\
    \ \ncollected in July but about 0.3 with the final yield, which showed the low\
    \ correlation \nbetween emergence and its later growth. \nKeyword: emergence evaluation,\
    \ soil texture, field elevation, row geo-reference; real-\ntime processing \n\
    4.2 Introduction \nCrop emergence is an important agronomic factor for crop development\
    \ assessment \nand field management in the early stages, which can be evaluated\
    \ using plant population, \nstand count, uniformity and seedling size (Sansone\
    \ et al., 2002; Supak, 1990). Accurate \nand timely assessment of crop stand count\
    \ and seedling size at the emergence stage may \nhelp farmers make important field\
    \ management decisions (e.g., replanting) to reduce \nproduction loss (Goodell\
    \ et al., 2015) as well as explore the environmental effects on the \ncrop emergence\
    \ and development (Anda and Pinter, 1994; Benvenuti, 2003; Domenech \nand Vila,\
    \ 2008; Forcella et al., 2000; Ghassemi-Golezani and Dalil, 2014; Valdés-\nRodríguez\
    \ et al., 2013). Acquisition of high-resolution site-specific crop emergence \n\
    information is the baseline for the above decisions and studies. Conventionally,\
    \ crop \nemergence is assessed through visual observation (manual stand counts\
    \ and seedling size \nevaluation) in a small number of sampling sites (Wiles and\
    \ Schweizer, 1999), which is \ntime-consuming, labor-intensive, and not suited\
    \ to cover a large production field.  \nIn recent years, unmanned aerial vehicle\
    \ (UAV)-based imaging technology has \nbeen tested as a high-throughput tool for\
    \ crop emergence assessment in various crops as \n71 \n \nsummarized by Feng et\
    \ al. (2020b). Some examples include the assessment of wheat \ndensity (Jin et\
    \ al., 2017; Sankaran et al., 2015), cotton uniformity (Feng et al., 2019), and\
    \ \nstand count in cotton (Chen et al., 2018; Feng et al., 2019), corn (Varela\
    \ et al., 2018), potato \n(Sankaran et al., 2017) and rapeseed (Zhao et al., 2018).\
    \ Those published studies used \nsimilar approaches to process UAV imagery data,\
    \ i.e., using commercial UAV image \nprocessing software, such as Agisoft PhotoScan\
    \ (Agisoft LLC, St. Petersburg, Russia) and \nPix4D (Pix4D S.A., Lausanne, Switzerland),\
    \ to generate orthomosaic images before \nfurther processing. The procedure of\
    \ generating orthomosaic images included image \nfeature detection, matching,\
    \ alignment and blending based on mosaic blending models as \ndescribed by Brown\
    \ and Lowe (2003), takes a very long time (days or weeks) and requires \nextensive\
    \ computational resources. However, emergence evaluation is a time-sensitive \n\
    analysis and the challenge in timely processing of imagery data becomes one of\
    \ the most \ncritical barriers for adopting UAV imagery in applications of crop\
    \ emergence assessment \n(Forcella et al., 2000; Supak, 1990). In our previous\
    \ study (Feng et al., 2020a), an efficient \nimagery data processing and analysis\
    \ framework for timely evaluation of cotton emergence \nusing UAV-based RGB imagery\
    \ and deep learning technology was developed. It was \ndifferent from previously\
    \ published studies in the approach of directly processing \nindividual image\
    \ frames rather than developing orthomosaic images to reduce the \nprocessing\
    \ time. \nWith the above methods and framework, timely emergence mapping and accurate\
    \ \nemergence data could be obtained. Exploring the relationship between crop\
    \ emergence, its \nsubsequent growth and the environment are the next important\
    \ topic (Feng et al., 2020a, \nb). Soil texture correlates with soil water holding\
    \ capacity and is one of the most important \n72 \n \nfactors that affect crop\
    \ emergence (Anda and Pinter, 1994; Benvenuti, 2003; Domenech \nand Vila, 2008;\
    \ Valdés-Rodríguez et al., 2013). The study of Stewart (2020) showed that \ntopography\
    \ and slope had the potential effects on soil erosion, water runoff and field\
    \ \nmicroclimate, which influenced corn emergence. Some studies (Carter and Nafziger,\
    \ 1990; \nNafziger et al., 1991) showed that uneven crop emergence resulting in\
    \ plant competition \nin the later growth stages decreased crop yield. Although\
    \ there have been studies on the \nrelationships between emergence, subsequent\
    \ growth, yield and environment many years \nago, the emerging sensing technologies\
    \ (i.e. soil EC sensors, field elevation sensors and \nUAV imaging sensors) in\
    \ recent years can provide more reliable and large amounts of data \nfor these\
    \ studies to draw more credible conclusions. Analysis of the emergence data, soil\
    \ \nand field elevation, as well as crop growth in the later growth stages, needed\
    \ ways to \nalignment those data from different sensor systems (i.e. different\
    \ UAV systems used in the \nemergence growing stage and in the later growth stages,\
    \ soil EC sensor systems, field \nelevation measurement system and yield monitor\
    \ system) together. The GPS error of the \nmapping methods used in our previous\
    \ study (Feng et al., 2020a) depended on the specific \nUAV GPS system used, which\
    \ was 1.72 ±1.37 m comparing with the ground RTK \nmeasurement. Therefore, to\
    \ improve the crop row alignment with the plants in later growth \nstages and\
    \ the ECa-based soil texture as well as the field elevation data, improving \n\
    alignment algorithm is needed to add to the previous study to conduct the environment\
    \ \neffects on emergence as well as explore the relationships between emergence\
    \ with the later \ngrow stages and yield. The goal of this study is to improve\
    \ the GPS accuracy of cotton \nemergence mapping and then evaluate the feasibility\
    \ of UAV-based imaging system in \nquantifying the relationship between emergence,\
    \ subsequent growth and environment. The \n73 \n \nspecific objectives are: 1)\
    \ increasing the accuracy of emergence maps to register with its \nsubsequent\
    \ growth data as well as soil and elevation data; and 2) using the developed \n\
    mapping methods to explore the soil and field elevation effects on emergence,\
    \ as well as \nthe relationships between the emergence with its subsequent growth\
    \ and yield. \n4.3 Emergence row register from individual RGB frame \nFeature\
    \ detection and matching \nThe crop row alignment algorithm was based on previous\
    \ customized image \nalignment and stitching algorithms described in Feng et al.\
    \ (2020b). Feature detection and \nmatching were conducted to the rotated images\
    \ based on the SHT crop row identification. \nImage features were detected using\
    \ the method of Speeded-Up Robust Features (SURF), a \n128-dimension (8 orientation\
    \ bins for each of the 4 × 4 location bins) local feature detector \nand descriptor\
    \ developed in (Bay et al., 2008). As a scale-invariant feature, SURF used \n\
    image pyramids and different sized box filters to find points of interest at different\
    \ scale-\nspaces (Lowe, 2004). The scale-space of SURF was divided into octaves\
    \ and each octave \nwas subdivided into a constant number of scale levels. The\
    \ number of pyramid octaves and \noctave layers were both set to 3 in this study.\
    \ After feature detection, the k-nearest \nneighbors (KNN) algorithm was used\
    \ to match the most similar feature pairs in two \nsuccessive raw images. The\
    \ KNN calculated all of the Euclidean distances of features with \neach other\
    \ to find the closest K matches. In this study, K was set to two (K = 2); therefore,\
    \ \nthe KNN algorithm returned the two closest key points for each key point to\
    \ be matched. \nRemoval of false matches \n74 \n \nFalse matches were those pixels\
    \ that had the shortest Euclidean distance but were \ndifferent objects in the\
    \ successive images. To detect and remove false matches, a distance \nratio test\
    \ was conducted to compare the Euclidean distance of the closest key point to\
    \ that \nof the second-closest key point identified by KNN (Lowe, 2004). It was\
    \ assumed that the \nfirst closest key point came from the same object as the\
    \ key point to be matched, while the \nsecond closest key point came from another\
    \ object. Distance ratio tests checked the \nsimilarity of the two nearest matches\
    \ to select the matches with high similarity in \nsuccessive images that were\
    \ not reliable and should be removed. All matches whose \ndistance ratio test\
    \ was greater than 0.65 were removed in this study. \nThe images were collected\
    \ on a calm day, and the UAV was parallel flying with \nthe ground with minimum\
    \ variations in roll and pitch, but small adjustments in yaw angle \ndue to navigation\
    \ error (flight heading, speed and height). Therefore, the geometric \ntransformations\
    \ for matching any two successive images only included the operations of \ntranslation,\
    \ scale and rotation. Considering the rotation and scale factor of two successive\
    \ \nimages were small in this study, in the case where scale and rotation were\
    \ small enough to \nbe negligible, the matching lines of the correct matches should\
    \ have similar slopes and \nlengths. The slope and length of the matching lines\
    \ were calculated using Eq 4.1 and 4.2:  \n\U0001D450\U0001D450\U0001D459\U0001D459\
    \U0001D450\U0001D450\U0001D460\U0001D460\U0001D460\U0001D460 =\n\U0001D466\U0001D466\
    2−\U0001D466\U0001D4661\n\U0001D465\U0001D4652−\U0001D465\U0001D4651         \
    \                                    (4.1) \n \n\U0001D459\U0001D459\U0001D460\
    \U0001D460\U0001D459\U0001D459\U0001D459\U0001D459\U0001D459\U0001D459ℎ = ඥ(\U0001D465\
    \U0001D4652 − \U0001D465\U0001D4651)2 + (\U0001D466\U0001D4662 − \U0001D466\U0001D466\
    1)2                                  (4.2) \n \nwhere, (x1, y1) and (x2, y2) are\
    \ the coordinates of a key point and its matching point in two \nsuccessive images.\
    \ The matches were considered to be false matches if the slopes and \nlengths\
    \ of the matching lines had a large difference from other matches. \n75 \n \n\
    Another way to determine false matches was to calculate the ratio of the slope\
    \ and \nthe length of one matching line to the mean value of all matching lines\
    \ in two successive \nimages. The ratios of the slope and length of the correct\
    \ matches would be close to 1. The \nthresholds for false matches were set as\
    \ lower than 0.9 and greater than 1.1. Both the \nmethods discussed above were\
    \ used in this study to remove false matches. Figure 4.1 shows \nan example of\
    \ feature detection and matching in two successive frames after all the false\
    \ \nmatches were removed. \n \nFigure 4.1: Feature detection and matching in two\
    \ example frames. The blue numbers in \neach frame are the detected image features\
    \ and the same number IDs with a color line \nconnect two matched image features.\
    \  \nCalculation of the geometric transformation matrix \nOnce the correct matches\
    \ were identified, transformation matrices of each pair of \ntwo successive images\
    \ were calculated. As mentioned earlier, the scale factor of two \nsuccessive\
    \ images was small in this study and the image frames were rotated to obtain \n\
    cotton rows aligned with the vertical axis of the images, therefore, only translation\
    \ was \nconsidered in this study. The transform matrix M is shown as Eq 4.3 (Szeliski,\
    \ 2007): \n76 \n \n\U0001D440\U0001D440 = ൤\U0001D459\U0001D459\U0001D465\U0001D465\
    \n\U0001D459\U0001D459\U0001D466\U0001D466൨                                  \
    \         (4.3) \n \nwhere, tx and ty are the distance in pixels of translation\
    \ in the horizontal and vertical \ndirections. Assuming a pixel value of an image\
    \ coordinate I(x, y) was to be transformed \ninto its previous image coordinate\
    \ I’(x',y'), Eq 4.4 shows the transformation of these two \nimages based on the\
    \ transform matrix M: \n൤\U0001D465\U0001D465′\n\U0001D466\U0001D466′൨ = \U0001D440\
    \U0001D440 ∙ ቈ\n\U0001D465\U0001D465\n\U0001D466\U0001D466\n1\n቉             \
    \                     (4.4) \n \nwhere, (x, y) and (x’, y’) are image coordinates\
    \ of image I(x, y) and I’(x',y').  \nCrop rows alignment based on the geometric\
    \ transformation matrix \nAfter conducting the SHL to the original image frames,\
    \ the images rotated and each \ncrop row positions in the rotated images could\
    \ be obtained. There were 152 crop rows in \ntotal and the crop row numbers of\
    \ the first image frame were identified manually. The tx in \nthe geometric transformation\
    \ matrix M controls the distance in pixels of translation in the \nhorizontal\
    \ directions. When each crop rows in the second image frame translated tx pixels,\
    \ \nthey would match with the positions of each crop rows in the first image and\
    \ would be \nassigned row numbers corresponding with the row numbers in the first\
    \ image. New crop \nrows that appeared on the right side of the second image frame\
    \ would be assigned a \nsuccessive number of the last crop row in the first image\
    \ frame. This process would \ncontinue in every two consecutive image frames until\
    \ all pictures have been assigned the \ncorresponding crop row numbers. Figure\
    \ 4.2 shows the crop rows alignment of the first \ntwo image frames. \n77 \n \n\
    \ \nFigure 4.2: Crop rows alignment. There were 10 cotton rows identified manually\
    \ in the \nfirst image frame. The numbers of 9 cotton rows identified by the SHL\
    \ in the second \nimage frame were aligned with the first image frame based on\
    \ the geometric \ntransformation matrix M. \nImage frame positions within each\
    \ entire crop row \nThe ty in the geometric transformation matrix M controls the\
    \ distance in pixels of \ntranslation in the vertical directions. When the UAV\
    \ flew through north to south then south \nto north, the regions included in each\
    \ image frame moved from the beginning to the end \nthen from the end to the beginning\
    \ of the entire crop rows. A specific image frame moved \nty pixels from its previous\
    \ image frame in the vertical directions. However, uncontrol \nfactors such as\
    \ wind and low batteries during the flight made the UAV flew unstably and \nresulted\
    \ in different GSD in each image frame and the pixels of translation in the vertical\
    \ \ndirections cannot represent the true translation in the meters of the entire\
    \ crop rows in the \n78 \n \nvertical directions. Since the GSD of each image\
    \ frame was calculated based on the fixed \nrow spacing in Chapter 3.1, translation\
    \ in meters in the vertical directions can be calculated \nby Eq 4.5. The first\
    \ image frame at the beginning of the data collection (the beginning of \nthe\
    \ first crop rows) was used as the reference of zero of the entire field, and\
    \ positions of \nother image frames were calculated as the meters of distance\
    \ between them and these zero \nreferences in the vertical directions. \n\U0001D459\
    \U0001D459\U0001D466\U0001D466_\U0001D45A\U0001D45A\U0001D45A\U0001D45A\U0001D459\
    \U0001D459\U0001D45A\U0001D45A\U0001D45A\U0001D45A =\n\U0001D459\U0001D459\U0001D466\
    \U0001D466\n\U0001D43A\U0001D43A\U0001D43A\U0001D43A\U0001D43A\U0001D43A     \
    \                       (4.5) \nwhere ty_meter is the translation in meters in\
    \ the vertical directions, ty is the pixels of \ntranslation in the vertical directions\
    \ and GSD is the ground sample distance. \nEmergence mapping based on the image\
    \ alignment \nFor each 1-m seedling segment in Figure 3.3b, the algorithm would\
    \ first recognize \nits crop row numbers based on the crop row assignment results\
    \ described above. The ty_meter \ndescribed the translation in meters in the vertical\
    \ directions for the geometric center of each \nimage frame. To calculate the\
    \ translation in meters of each 1-m seedling segment in Figure \n3.3b between\
    \ them and the zero reference in the vertical directions, the distance in meters\
    \ \nbetween the 1-m seedling segments and the geometric center of the image frames\
    \ were \nneeded to calculate. The translation in meters between each 1-m seedling\
    \ segment and the \nzero reference in the vertical directions was the result of\
    \ ty_meter added or subtracted the \ndistance in meters between the 1-m seedling\
    \ segments and the geometric center of the \nimage frames. If some 1-m seedling\
    \ segments from different image frames were \ngeometrically close (less than 1\
    \ meter distance), the average of their predicted stand count \nand their predicted\
    \ canopy size would be used when mapped the emergence of the whole \nfield.  \n\
    79 \n \n4.4 Limitation of the crop row alignment algorithm \nLow overlapping of\
    \ the image frames \nThe success of feature detection and matching relied on the\
    \ overlapping of every \ntwo successive frames. If the two successive frames had\
    \ a very small overlapping rate in \nthe forward direction, the feature detection\
    \ and matching would fail. Figure 4.3 shows two \nalignment examples with one\
    \ about 30% and the other one less than 5% overlapping in the \nforward direction.\
    \ Although a 60% overlapping in both forward and sideward directions \nwere set\
    \ for the UAV flight plan, uncontrol factors such as wind and low batteries during\
    \ \nthe flight made the UAV flew unstably and resulted in low overlapping images.\
    \ There are \n2200 images in total and 11 images were found out unsuccessful alignment\
    \ due to the low \noverlapping rate. There were two solutions for those 11 images\
    \ to align correctly: 1) used \nthe side overlapping images instead. The sideward\
    \ overlapping images could be found \nbased on the closest of the image GPS in\
    \ the nearby UAV flight path. Figure 4.4 shows an \nexample of the successfully\
    \ sideward overlapping images alignment; 2) if both the forward \nand sideward\
    \ overlapping rate were less than 5%, this image frame cannot be aligned \nsuccessfully\
    \ using the provided algorithm. Manually identified the crop row numbers of \n\
    this image frame with crop row numbers in its nearby image frames were needed\
    \ to assign \nthe correct crop row numbers. There were 3 images out of those 11\
    \ images needed to assign \nthe correct crop row numbers manually.    \n80 \n\
    \ \n \nFigure 4.3: Two examples of the image frame alignment: (a) successfully\
    \ aligned with \nabout 30% overlapping in the forward direction between those\
    \ two successive frames; (b) \nless than 5% overlap in the forward direction between\
    \ these two successive frames and \ncannot be aligned successfully with the algorithm.\
    \ The alignment result in (b) was the \nresult of manual alignment. \n \nFigure\
    \ 4.4: Image frames aligned successfully using sideward overlapping images. This\
    \ \nis one of the solutions for the 11 image frames that cannot be successfully\
    \ aligned due to \n81 \n \nthe low forward overlapping. The color numbers in each\
    \ image were the crop row \nnumbers assigned to each image. \nIncorrect image\
    \ alignment when changing UAV batteries \nWhen the UAV batteries were about to\
    \ use up, the UAV usually cannot have a well-\ncontrol of the stable flying, especially\
    \ for the flight height controlling, which resulted in a \nlow UAV flight height,\
    \ smaller numbers of crop rows including in one image and larger \nGSD of the\
    \ image frames.  We considered scale factor of two successive images were small\
    \ \nand only translation was considered in the geometric transformation matrix\
    \ M. When the \nUAV batteries were used up and changed to new batteries, the UAV\
    \ would become well-\ncontrol of the stable flying again and had a different flight\
    \ height with the last image frame \nthat using the previous about to use up batteries,\
    \ which resulted in a larger scale factor \nbetween these two image frames and\
    \ unsuccessful crop rows alignment. We used four sets \nof batteries in total\
    \ for the entire field data collection, and the crop row numbers of the first\
    \ \nimage frame in each set of batteries needed to be identified manually. For\
    \ crop row \nnumbers of the first image collected with the first set of the UAV\
    \ batteries were easy to \nassign the row numbers, as shown in Figure 4.2. For\
    \ the crop row numbers of the first \nimage collected with the second to the fourth\
    \ set of the UAV batteries, the crop row \nnumbers can be assigned based on the\
    \ feature detection and matching results, as shown in \nFigure 4.5. \n82 \n \n\
    \ \nFigure 4.5: Crop row alignment of image frames collected in the UAV batteries\
    \ changed \nbased on the feature detection and matching results. The color numbers\
    \ in each image \nwere the crop row numbers assigned to each image. \n4.5 GPS\
    \ accuracy \nGPS accuracy of the row alignment mapping method was measured between\
    \ \nground RTK measurement and image measurement, as shown in Figure 4.6. Ground\
    \ RTK \nmeasurement measured the distance in meter between each two GPS coordinates\
    \ of the 28 \nGRPs, while image measurement measured the distance in meter between\
    \ every two \nground stakes in the 28 GRPs in images. The row spacing determination\
    \ affected the \naccuracy of the ground distance calculation between two subsequent\
    \ image frames within \na UAV flight path based on the Eq. 4.5. The row spacing\
    \ was set as 0.97 m of the seed \nplanter, however, in Chapter 3, the row spacing\
    \ was 0.99 m based on image measurement \nin the GRPs. We tested the GPS accuracy\
    \ using 0.97, 0.975, 0.98, 0.985, 0.99 m as the row \nspacing of the Eq. 4.5 respectively,\
    \ and 0.98 m using as the row spacing had the lowest \nGPS accuracy, which was\
    \ 0.17 ± 0.13 m. This was higher accuracy than the methods used \nin Chapter 3,\
    \ which was 1.72 ±1.37 m. \n83 \n \n \nFigure 4.6: GPS error measurement between\
    \ two different kinds of systems: ground RTK \nmeasurement and image measurement.\
    \ \n4.6 Factors affected the stand count and canopy size \nThe emergence maps\
    \ \nThere were 152 crop rows in total and each crop row was about 315 m lengths,\
    \ \ntherefore a stand count map (seedlings meter-1) and a canopy size map (cm2\
    \ seedling-1) \nwith a dimension of 152 crop row × 315 m length of each crop row\
    \ could be generated, \nshown as Figure 4.7a-b. Then, those maps were downsampled\
    \ to a dimension of 38 × 63 \nmaps to match with the lower special dimension data\
    \ such as soil ECa, elevation, yield and \nvegetation indices maps in July.  Each\
    \ data point in the 38 × 63 maps equates to a 4 m × 5 \nm area. \n84 \n \n \n\
    Figure 4.7: Emergence maps of (a) stand count (seedlings meter-1) and (b) canopy\
    \ size \n(cm2 seedling-1) with a dimension of 152 crop row × 315 m length of each\
    \ crop row. (c) \nand (d) are the stand count (seedlings meter-1) and (b) canopy\
    \ size (cm2 seedling-1) that \ndownsampled from (a) and (b). Their dimension was\
    \ 38 × 63, and each data point equates \nto a 4 m × 5 m area. \nSoil and elevation\
    \ effects on the stand count and canopy size \nSome studies had shown that clay\
    \ content had a negative relationship while sand \ncontent had a positive relationship\
    \ with crop emergence rate (Anda and Pinter, 1994; \nBenvenuti, 2003; Domenech\
    \ and Vila, 2008; Valdés-Rodríguez et al., 2013). In this study, \nthe ECa-based\
    \ clay% were split into five groups evenly: low clay% (0, 5.95], medium_low \n\
    clay% (5.95, 8.69], medium clay% (8.69, 10.58], medium_high clay% (10.58, 12.72],\
    \ and \nhigh clay% (12.72, 28.39]. Analysis of variance (ANOVA) was conducted\
    \ to compare \ndifferences in the means of stand count and canopy size for different\
    \ clay% groups using \nTukey’s Honest method at a 0.05 level of significance,\
    \ as shown in Figure 4.8a-b. Kernel \ndensity estimation (KDE) was used to model\
    \ the probability distribution of stand count and \ncanopy size in the five clay%\
    \ groups using Gaussian kernels, as shown in Figure 4.8c-d. \nThe results show\
    \ that a majority of stand count of all the clay% groups were in the range \n\
    85 \n \nof 10 to 14, and the low and medium-low clay% groups had a slightly higher\
    \ stand count. \nThe planting rate was 11 seedlings meter-1 but with some planter-calibration\
    \ errors. For the \ncanopy size, the low clay% group had the lowest average canopy\
    \ size and there was higher \nprobability distribution of less than 20 cm2 seedling-1\
    \ than other clay% groups. Except for \nthe low clay% group, the average canopy\
    \ size decreases from the medium_low to the high \nclay% groups, which shows a\
    \ negative relationship between canopy size and clay%. \n \nFigure 4.8: Relationships\
    \ between emergence (stand count and seedling size) and ECa-\nbased soil clay%.\
    \ Low clay%: (0, 5.95], medium_low clay%: (5.95, 8.69], medium \nclay%: (8.69,\
    \ 10.58], medium_high clay%: (10.58, 12.72], and high clay%: (12.72, \n28.39].\
    \ Each clay% group had the same numbers of clay% data points. (a) Mean stand \n\
    count and (b) seedling size difference of five clay% content groups. Different\
    \ lower-case \nletters indicate a significant difference at the 5% level of Tukey’s\
    \ honest significant \ndifference test. The KDE of the (c) stand count and (d)\
    \ seedling size in the five clay% \ncontent groups. \n86 \n \nA scalable tree\
    \ boosting model XGBoost (Chen and Guestrin, 2016) was used to \nexplore how much\
    \ the soil features contributed to the stand count and canopy size variation.\
    \ \nThe XGBoost model included hundreds of decision trees trained by the inputs\
    \ of soil \nfeatures (included the ECa-sh, ECa-dp, clay10-clay70, WP, FC, TAW\
    \ and field elevation; soil \ndata processing details were written in Chapter\
    \ 5.4) and used the stand count and canopy \nsize as the prediction with an additive\
    \ strategy (build trees one following another, with the \ncurrent one trying to\
    \ predict what the previous trees did not predict well). Each decision \ntree\
    \ was trained using 70% of the training data and built its branches (decision\
    \ boundary) \nbased on the residual of the previously built trees. The procedure\
    \ of building tree branches \nof each decision tree was the procedure of choosing\
    \ features from inputs for prediction, \nand a certain proportion of features\
    \ instead of all the inputs would be used to build each \ntree to avoid overfitting.\
    \ Therefore, the XGBoost model itself has the ability for feature \nselection\
    \ and to address collinearity problems (Hayes et al., 2015). The overall dataset\
    \ was \nsplit into 85% training set and 15% test set, and the coefficient of determination\
    \ (R2) in the \ntest set was used to quantify how well the model explained the\
    \ data. The R2=0.43 and mean \nabsolute percentage error (MAPE)=5.97% were obtained\
    \ for the stand count prediction of \nthe test set, while R2=0.43 and MAPE=8.51%\
    \ were obtained for the canopy size prediction \nof the test set.  \nShapley values\
    \ (Shapley, 1953) were used to explain how much each of the soil \ninput feature\
    \ values contributed to the stand count and canopy size prediction. We \ncomputed\
    \ the predicted stand count and canopy size with a difference of each soil feature\
    \ \nvalue and take the predicted difference to get the marginal contribution.\
    \ The Shapley value \nis the (weighted) average of marginal contributions (Molnar,\
    \ 2020). When the Shapley \n87 \n \nvalue was zero for a specific soil feature,\
    \ it means that this feature does not have any \ncontribution to the stand count\
    \ and canopy size prediction, while if the Shapley value was \na negative (or\
    \ positive) value for a specific soil feature, it means this feature had a negative\
    \ \n(or positive) contribution to the prediction. Soil features with large absolute\
    \ Shapley values \nare important to the stand count and canopy size prediction\
    \ (Molnar, 2020). SHapley \nAdditive exPlanations (SHAP) tool (Lundberg et al.,\
    \ 2020) was used to calculate the \nShapley value in this study. Figure 4.9 shows\
    \ the Shapley value of the soil features in stand \ncount and canopy size prediction.\
    \ Elevation ranks at the first important to both the stand \ncount and canopy\
    \ size prediction, and the elevation shows a positive relationship with both \n\
    of them. The clay10 to clay70 show decrease important to the canopy size prediction,\
    \ while \nclay10 and clay30 show more important to the stand count than the clay\
    \ content in other \ndepth layers. WP, FC and TAW did not show too much important\
    \ to both the stand count \nand canopy size prediction. Elevation, ECa-sh, ECa-dp\
    \ and clay10-clay30 were ranked the \nfirst six important to both the stand count\
    \ and canopy size prediction. \n \nFigure 4.9: Shapley value of the soil features\
    \ in (a) stand count and (b) canopy size \nprediction. \nCanopy size\nStand count\n\
    (a)\n(b)\n88 \n \nThe SHAP tool (Lundberg et al., 2020) includes a function named\
    \ SHAP \ndependence plot, which can help to explore the details of how Shapley\
    \ values changes with \nspecific soil feature value changes, as shown in Figure\
    \ 4.10 and Figure 4.11. The overall \nelevation difference of the field is 1.5\
    \ m and increases from the north side to the south side. \nThe prediction of the\
    \ stand count decreases 1-2 seedlings and canopy size decreased 1-5 \ncm2 seedlings-1\
    \ compared to the overall average seedling numbers and canopy size if the \nelevation\
    \ is lower than 87.2 m. For clay10 and clay20, stand count and canopy size \n\
    prediction decreases largely when the clay content is less than 6%, and the highest\
    \ stand \ncount and canopy size prediction appear in the range of 6%-8%. When\
    \ the clay content is \nlarger than 8%, stand count and canopy size prediction\
    \ decrease slightly. The clay30 has a \nsimilar trend with the clay10 and clay20\
    \ for the canopy size prediction, but stand count had \na decreasing trend when\
    \ clay30 increases. ECa-sh had an increasing trend for the stand count \nprediction\
    \ in the range of 0-15, while ECa-dp had an increasing trend for the canopy size\
    \ \nprediction in the range of 0-15. \n \n89 \n \nFigure 4.10: Shapley value changes\
    \ corresponding to the top six important soil feature \nvalues changes for stand\
    \ count prediction. \n \nFigure 4.11: Shapley value changes corresponding to the\
    \ top six important soil feature \nvalues changes for canopy size prediction.\
    \ \nEmergence and the crops’ subsequent development \nThe stand count and seedling\
    \ size data in the emergence were conducted the \nPearson correlation with the\
    \ NDVI, canopy size, GNDVI, NDRE, a* in the image collected \non July 12, 2019\
    \ (image processing details were written in Chapter 5.3) and the final yield \n\
    in 2019, as shown in Table 4.1. Canopy size had higher correlation coefficients\
    \ with the \nimage features and yield than the stand count. The coefficients between\
    \ seedling size with \nNDVI, canopy size, GNDVI and NDRE were 0.4-0.5. The coefficients\
    \ between stand count \nwith image features and yield were less than 0.4. Both\
    \ the stand count and seedling size \nhad low correlation coefficients with the\
    \ final yield (0.3 and 0.35). \n90 \n \nTable 4.1: Pearson correlation coefficients\
    \ between emergence (stand count and seedling \nsize) and image features collected\
    \ on July 12, 2019 and the final yield in 2019.  \n \nNDVI \nCanopy size \nGNDVI\
    \ \nNDRE \na* \nYield \nStand count \n0.25 \n0.33 \n0.26 \n0.18 \n0.02 \n0.3 \n\
    Seedling size \n0.42 \n0.5 \n0.4 \n0.41 \n0.16 \n0.35 \n \n4.7 Conclusion \nThis\
    \ Chapter improved the mapping GPS accuracy for real-time cotton stand count \n\
    and canopy size mapping. A UAV system with a high-resolution RGB camera was used\
    \ to \ntake individual image frames. A crop row alignment method on each individual\
    \ frame was \ndeveloped. The results showed that the GPS accuracy of the improved\
    \ method of \nemergence mapping was 0.17 ± 0.13 m. Field elevation, ECa-sh, ECa-dp\
    \ and clay10-clay30 \nwere ranked the first six important features to both the\
    \ stand count and canopy size \nprediction. The seedling canopy had about 0.4-0.5\
    \ Pearson correlation coefficients with the \nimage features collected in July\
    \ but a low correlation coefficient with the final yield. The \nmethods developed\
    \ could be used as a powerful tool for farmers and researchers to explore \nthe\
    \ relationships between cotton emergence, soil conditions and weather conditions.\
    \ \n4.8 Future work \nCompared to the emergence mapping methods in Chapter 3,\
    \ the row alignment \nmapping method in this Chapter had higher GPS accuracy.\
    \ However, the image processing \ntime increased a lot (about 17 s / image) and\
    \ did not reach near real-time mapping as the \n91 \n \nmethods in Chapter 3.\
    \ Other low time cost image features rather than the SUFT for image \nalignment\
    \ could be tried to reduce the processing time in the future. \n4.9 Literature\
    \ cited \nAbadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C.,\
    \ Corrado, G.S., \nDavis, A., Dean, J., Devin, M., 2016. Tensorflow: Large-scale\
    \ machine learning \non heterogeneous distributed systems. arXiv preprint arXiv:1603.04467.\
    \ \nAnda, A., Pinter, L., 1994. Sorghum germination and development as influenced\
    \ by soil \ntemperature and water content. Agronomy Journal 86, 621-624. \nBay,\
    \ H., Ess, A., Tuytelaars, T., Van Gool, L., 2008. Speeded-up robust features\
    \ (SURF). \nComputer vision and image understanding 110, 346-359. \nBenvenuti,\
    \ S., 2003. Soil texture involvement in germination and emergence of buried \n\
    weed seeds. Agronomy Journal 95, 191-198. \nCarter, P.R., Nafziger, E.D., 1990.\
    \ Uneven emergence in corn. \nChen, R., Chu, T., Landivar, J.A., Yang, C., Maeda,\
    \ M.M., 2018. Monitoring cotton \n(Gossypium hirsutum L.) germination using ultrahigh-resolution\
    \ UAS images. \nPrecision Agriculture 19, 161-177. \nChen, T., Guestrin, C., 2016.\
    \ Xgboost: A scalable tree boosting system, Proceedings of \nthe 22nd acm sigkdd\
    \ international conference on knowledge discovery and data \nmining, pp. 785-794.\
    \ \nDomenech, R., Vila, M., 2008. Cortaderia selloana seed germination under different\
    \ \necological conditions. acta oecologica 33, 93-96. \n92 \n \nFeng, A., Sudduth,\
    \ K., Vories, E., Zhou, J., 2019. Evaluation of cotton stand count using \nUAV-based\
    \ hyperspectral imagery, 2019 ASABE Annual International Meeting. \nAmerican Society\
    \ of Agricultural and Biological Engineers, p. 1. \nFeng, A., Zhou, J., Vories,\
    \ E., Sudduth, K.A., 2020a. Evaluation of cotton emergence \nusing UAV-based imagery\
    \ and deep learning. Computers and Electronics in \nAgriculture 177, 105711. \n\
    Feng, A., Zhou, J., Vories, E., Sudduth, K.A., 2020b. Evaluation of cotton emergence\
    \ \nusing UAV-based narrow-band spectral imagery with customized image \nalignment\
    \ and stitching algorithms. Remote Sensing 12, 1764. \nForcella, F., Arnold, R.L.B.,\
    \ Sanchez, R., Ghersa, C.M., 2000. Modeling seedling \nemergence. Field Crops\
    \ Research 67, 123-139. \nGhassemi-Golezani, K., Dalil, B., 2014. Effects of seed\
    \ vigor on growth and grain yield \nof maize. Plant Breeding and Seed Science\
    \ 70, 81-90. \nGoodell, P.B., Davis, R.M., Godfrey, L.D., Hutmacher, R.B., Roberts,\
    \ P.A., Wright, \nS.D., M, B.V., Haviland, D.R., Munier, D.J., Natwick, E.T.,\
    \ 2015. UC IPM pest \nmanagement guidelines cotton, Oakland, CA. \nHayes, T.,\
    \ Usami, S., Jacobucci, R., McArdle, J.J., 2015. Using Classification and \nRegression\
    \ Trees (CART) and random forests to analyze attrition: Results from \ntwo simulations.\
    \ Psychology and Aging 30, 911. \nJin, X., Liu, S., Baret, F., Hemerlé, M., Comar,\
    \ A., 2017. Estimates of plant density of \nwheat crops at emergence from very\
    \ low altitude UAV imagery. Remote Sensing \nof Environment 198, 105-114. \n93\
    \ \n \nLowe, D.G., 2004. Distinctive image features from scale-invariant keypoints.\
    \ \nInternational Journal of Computer Vision 60, 91-110. \nLundberg, S.M., Erion,\
    \ G., Chen, H., DeGrave, A., Prutkin, J.M., Nair, B., Katz, R., \nHimmelfarb,\
    \ J., Bansal, N., Lee, S.-I., 2020. From local explanations to global \nunderstanding\
    \ with explainable AI for trees. Nature machine intelligence 2, 56-\n67. \nMolnar,\
    \ C., 2020. Interpretable machine learning. Lulu. com. \nNafziger, E.D., Carter,\
    \ P.R., Graham, E.E., 1991. Response of corn to uneven emergence. \nCrop Science\
    \ 31, 811-815. \nSankaran, S., Khot, L.R., Carter, A.H., 2015. Field-based crop\
    \ phenotyping: \nMultispectral aerial imaging for evaluation of winter wheat emergence\
    \ and spring \nstand. Computers and Electronics in Agriculture 118, 372-379. \n\
    Sankaran, S., Quirós, J.J., Knowles, N.R., Knowles, L.O., 2017. High-resolution\
    \ aerial \nimaging based estimation of crop emergence in potatoes. American Journal\
    \ of \nPotato Research 94, 658-663. \nSansone, C., Isakeit, T., Lemon, R., Warrick,\
    \ B., 2002. Texas cotton production: \nEmphasizing integrated pest management.\
    \ Texas Cooperative Extension Service, \nthe Texas A & M University System, Texas,\
    \ USA. \nShapley, L.S., 1953. A value for n-person games. Contributions to the\
    \ Theory of Games \n2, 307-317. \nStewart, S., 2020. Planting depth within-field\
    \ soil variability effects on corn stand \nestablishment and yield. University\
    \ of Missouri--Columbia. \n94 \n \nSupak, J., 1990. Making replant decisions,\
    \ 1990 Beltwide cotton production conference. \nNational Cotton Council of America,\
    \ pp. 45-48. \nSzeliski, R., 2007. Image alignment and stitching: A tutorial.\
    \ Foundations and Trends® \nin Computer Graphics and Vision 2, 1-104. \nValdés-Rodríguez,\
    \ O.A., Sánchez-Sánchez, O., Pérez-Vázquez, A., 2013. Effects of soil \ntexture\
    \ on germination and survival of non-toxic Jatropha curcas seeds. Biomass \nand\
    \ Bioenergy 48, 167-170. \nVarela, S., Dhodda, P.R., Hsu, W.H., Prasad, P., Assefa,\
    \ Y., Peralta, N.R., Griffin, T., \nSharda, A., Ferguson, A., Ciampitti, I.A.,\
    \ 2018. Early-season stand count \ndetermination in corn via integration of imagery\
    \ from unmanned aerial systems \n(UAS) and supervised learning techniques. Remote\
    \ Sensing 10, 343. \nZhao, B., Zhang, J., Yang, C., Zhou, G., Ding, Y., Shi, Y.,\
    \ Zhang, D., Xie, J., Liao, Q., \n2018. Rapeseed seedling stand counting and seeding\
    \ performance evaluation at \ntwo early growth stages based on unmanned aerial\
    \ vehicle imagery. Frontiers in \nPlant Science 9. \n \n95 \n \nChapter 5. COTTON\
    \ DEVELOPMENT VARIATION AFFECTS BY \nSOIL AND WEATHER \n5.1 Abstract \nCrop development\
    \ and production are partly determined by soil conditions, plant \navailable water,\
    \ and weather conditions. Quantification of their interactions is the key for\
    \ \noptimizing field management, such as precision irrigation and fertilization,\
    \ to achieve \noptimal production. The goal of this study was to quantify the\
    \ effects of soil and weather \nconditions on cotton development and production\
    \ using temporal areal imagery data and \nsoil apparent electrical conductivity\
    \ (ECa) of the field.  Soil texture, i.e., sand and clay \ncontent, calculated\
    \ using ECa based on a model from a previous study, was used to estimate \nthe\
    \ soil characteristics, including field capacity, wilting point and total available\
    \ water. \nWater stress coefficient Ks was calculated using soil texture and weather\
    \ data. Unmanned \naerial vehicle (UAV)-based multispectral imaging systems were\
    \ used to acquire imagery \ndata at three growth stages of cotton in 2018 and\
    \ 2019, respectively. Image features of \ncanopy size and several vegetation indices\
    \ (VIs) were extracted from the derived \northomosaic images. Pearson correlation,\
    \ analysis of variance (ANOVA) and a machine \nlearning method (XGBoost) were\
    \ used to quantify the relationships between crop response \n(variables extracted\
    \ from UAV images) and environments (soil texture and weather \nconditions). Results\
    \ show that the cotton NDVI was various monthly under different soil \ntextures\
    \ in both 2018 and 2019. Soil clay content in shallower layers (0-0.4 m) affected\
    \ \ncrop development in early growth stages (June and July) while clay content\
    \ in deeper layers \n(0.4-0.7 m) affected the mid-season growth stages (August\
    \ and September). It was also \n96 \n \nfound that soil clay content at 0.4-0.7\
    \ m had a higher impact on crop development when \nwater inputs were not sufficient,\
    \ while features related to crop water stress had a higher \ncontribution to the\
    \ prediction of crop growth when water stress was less. The study \nindicates\
    \ that the integration of soil and weather information was able to predict crop\
    \ \ngrowth and yield. \nKeywords Cotton; plant growth; soil texture; UAV; multispectral\
    \ imagery \n5.2 Introduction \nThe world population is estimated to increase by\
    \ 2 billion in the next 30 years, from \n7.7 billion currently to 9.7 billion\
    \ in 2050, although the growth speed is at a slower pace \n(United Nations, 2019).\
    \ It is estimated that global crop production needs to double by 2050 \nto meet\
    \ the projected demands from rising population, diet shifts, and increasing biofuels\
    \ \nconsumption (Alexandratos and Bruinsma, 2012; Hickey et al., 2019; Ray et\
    \ al., 2013). \nHowever, the current yearly increases of crop production for maize\
    \ (Zea mays L.) at 1.6%, \nrice (Oryza sativa L.) at 1.0%, wheat (Triticum aestivum\
    \ L.) at 0.9%, and soybean [Glycine \nmax (L.) Merr.] at 1.3% are insufficient\
    \ to meet the projected demands of ~2.4% in 2050 \n(Alexandratos and Bruinsma,\
    \ 2012; Ray et al., 2013). How to improve the production of \nthe major crops\
    \ has become an impressing pressure to the global research communities \n(Hatfield\
    \ and Walthall, 2015).  \nCrop development and yield are complex and determined\
    \ by many factors, such as \ncrop genotypes (varieties), growing environments\
    \ (e.g., weather, soil, microclimate and \nlocation), and agronomic management\
    \ strategies (e.g., seed treatment and placement, \nplanting, fertilizer and pest\
    \ management) (Cobb et al., 2013). To develop next-generation \nand high-efficiency\
    \ agriculture production systems, we will have to solve the complex \n97 \n \n\
    equation consisting of the interactions of genotype, environment and management\
    \ \n(G×E×M) using emerging technologies (Beres et al., 2020; Russell, 2017; Xin\
    \ and Tao, \n2019). Although crop yield potentials have been improved through\
    \ advanced crop breeding \ntechnologies, the yield gap, i.e., the difference between\
    \ farm yield (final yield) and \npotential yield, is still substantial (Beres\
    \ et al., 2020). Precision agriculture is a promising \nagriculture practice to\
    \ increase profitability and reduce the environmental impact using \nsite-specific\
    \ and accurate measurement of crop, soil and environment (Basso and Antle, \n\
    2020; Walter et al., 2017). However, the success of precision agriculture technology\
    \ \nheavily relies on the access of accurate and high-resolution spatiotemporal\
    \ data and reliable \nprediction models of crop development and yield (Feng et\
    \ al., 2020b). To-date, most \nresearch projects have been focused on development\
    \ of crop development and yield \npredication models using single factors, such\
    \ as crop response to irrigation (Bell et al., \n2018; Onder et al., 2005), fertilizer\
    \ (Cuong et al., 2017; Schut et al., 2018). There are few \nstudies that have\
    \ integrated effects of environment and management in their prediction due \n\
    to the lack of data and complex interactions (Beres et al., 2020). In this study,\
    \ we tested \nthe feasibility of modelling crop development using multiple factors\
    \ of soil, weather and \nmanagement practices.  \nSoil texture is an important\
    \ soil property related to crop growth (Scherer et al., \n2017). The size of solid\
    \ particles has been used to classify soil texture into different types, \nincluding\
    \ clay (less than 0.002 mm), silt (from 0.002 mm to 0.05 mm) and sand (from 0.05\
    \ \nmm to 2 mm) (Easton and Bock, 2016). The percentages of sand, clay and silt\
    \ in the soil \naffect the movement of air and water, as well as the water holding\
    \ capacity (Bittelli, 2011; \nDatta et al., 2017; Easton and Bock, 2016). Soil\
    \ texture is a determining factor for soil \n98 \n \nwater holding capacity that\
    \ is one of the important factors affecting crop development. Soil \ntexture can\
    \ affect seedling emergence date and emergence rate (Forcella et al. (2000)),\
    \ root \ndevelopment (Oosterhuis, 1990). Soil texture can be measured using a\
    \ laboratory-based \nwet chemistry method that is expensive and time-consuming\
    \ (Vos et al., 2016). An \nalternative method is to use a sensor-based method\
    \ that is efficient to acquire data with \nhigh spatial resolution and low cost.\
    \  The most acceptable method is to predict soil texture \nusing soil apparent\
    \ electrical conductivity (ECa) with a good calibration (James et al., 2003; \n\
    Stępień et al., 2015; Sudduth et al., 2005). Many studies have found that soil\
    \ texture (or \nsoil ECa) was related to the yield of cotton (Vories et al., 2020),\
    \ corn (Kitchen et al., 2003; \nKitchen et al., 2005) and soybean (Jiang and Thelen,\
    \ 2004; Kitchen et al., 2005). \nWeather conditions, including temperature, wind,\
    \ humidity and solar irradiance, \nthat are determining factor for crop evapotranspiration\
    \ and water requirements,  also have \na great impact on crop development and\
    \ yield (Allen et al., 1998). Addy et al. (2020) \nshowed that the cereal grain\
    \ yield had different responses to nitrogen application under \nvarious weather\
    \ conditions during 1968-2016. Tremblay et al. (2012) showed that weather \nconditions\
    \ could influence the corn response to nitrogen. Battisti et al. (2018) showed\
    \ that \nweather condition was an important component for soybean yield estimation.\
    \ Van Bussel \net al. (2016) used weather data for long-term (30 years) wheat\
    \ yield estimation. \nCompared to crop yield, which is easy to measure and quantify,\
    \ crop development \neffects due to the soil texture and weather conditions within\
    \ a season could be challenging \nto measure and quantify. Evaluation of crop\
    \ development by visual observation at field \nscale is time-consuming and subjective.\
    \ In recent years, sensor-based methods have \nprovided a promising way to measure\
    \ and quantify crop development (Bendig et al., 2015; \n99 \n \nHunt et al., 2013).\
    \ Vegetation indices (VIs) such as normalized difference vegetation index \n(NDVI),\
    \ chlorophyll vegetation index, triangular greenness index, and green red vegetation\
    \ \nindex, can be used to quantify the crop growth status (Xue and Su, 2017).\
    \ Unmanned aerial \nvehicles (UAVs) equipped with visual sensors, multispectral\
    \ sensors and/or hyperspectral \nsensors have been used as a high-throughput data\
    \ collection tool by many researchers to \nmonitor crop development at the desired\
    \ time efficiently at field-scale (Feng et al., 2019; \nFeng et al., 2020a; Feng\
    \ et al., 2020b; Turner et al., 2014). Studies have used UAV-based \nremote sensing\
    \ technologies to estimate crop evaporation (Hoffmann et al., 2016b), crop \n\
    water status (Romero et al., 2018) and water stress (Gago et al., 2017; Hoffmann\
    \ et al., \n2016a; Zhang et al., 2019). These studies explored the relationships\
    \ between VIs and \nevapotranspiration (latent heat flux) calculated by energy\
    \ balance models, water status \nmeasured by pressure bomb, ground measured stomatal\
    \ conductance and sap flow under \ndifferent irrigation treatments. \nUsing UAV-based\
    \ remote sensing technologies to study the relationships between \nsoil texture\
    \ (or ECa), weather conditions and crop development is an important and ongoing\
    \ \ntopic. For example, Santesteban et al. (2017) and Křížová et al. (2018) showed\
    \ that the \ncrop canopy temperature captured by a UAV-based thermal camera was\
    \ related to soil ECa.  \nThis study focused on examining the effects of soil\
    \ texture and weather conditions on \ncotton growth variation. The specific objectives\
    \ included: (1) extracting features of the \ncrop, soil and weather from different\
    \ sensing systems; and (2) quantifying soil texture and \nweather effects on cotton\
    \ growth variation. \n \n100 \n \n5.3 Multi-sensors UAV system and experimental\
    \ design \n \nTo monitor crop development during the whole growth season (from\
    \ July to \nSeptember), imagery data were collected using a UAV imaging system\
    \ integrating a UAV \nplatform (DJI Matrice 600 Pro, DJI, China) with multiple\
    \ cameras and thermal camera. \nThe multiple cameras used in 2017, June and July\
    \ of 2018 were an RGB camera (HERO \n5, GoPro, San Mateo, CA, USA) and a customized\
    \ multispectral camera \n(XNiteCanonElph130, LDP LLC, Carlstadt, NJ, USA). The\
    \ camera used in August and \nSeptember of 2018 and in 2019 was a multispectral\
    \ camera (RedEdge-M, MicaSense Inc., \nWA, USA). The thermal camera used in all\
    \ three years was an infrared thermal camera \n(ICI 8640P, Infrared Cameras Inc.,\
    \ Beaumont, TX, USA). Because the thermal camera had \nan uncooled detector, it\
    \ was warmed up by connecting to a power bank for more than half \nan hour before\
    \ data collection to produce stable temperature readings. The firmware \nprovided\
    \ by the thermal camera company was installed on a Raspberry Pi (model 3B, \n\
    Raspberry Pi Foundation, UK) to collect thermal images at a snapshot rate of 1\
    \ s image-1 \nand images were saved on the SD card of the Raspberry Pi.  Image\
    \ data were collected at \nthe east field in 2017 and 2019, and the west field\
    \ in 2018. The UAV imaging system flew \nat 30 m above the ground level (AGL)\
    \ when using the RedEdge-M, and at 50 m AGL when \nusing the HERO 5 and XNiteCanonElph130.\
    \ The specifications of the cameras, flight \nheight and ground sampling distance\
    \ (GSD) are listed in Table 5.1: Specifications of the \ncameras used in the study\
    \ Table 5.1. The cameras collected images with about 75% overlap \nin both sideward\
    \ and forward directions. A UAV control app (Autopilot, Hangar \nTechnology, Austin,\
    \ TX, USA) was used to plan flight paths and set waypoints, flight \nspeed (7.5\
    \ km h-1), and height (30 or 50 m AGL). Imagery data were collected near solar\
    \ \n101 \n \nnoon (around 1 pm Central Daylight Time). The specific conditions\
    \ during image \ncollection in two years are shown in Table 5.2: Weather conditions\
    \ during imaging. The \nvalues are the means and standard deviations from 11 am\
    \ to 2 pm of the imaging days, i.e., \nthe weather conditions from 11:00 pm to\
    \ 2:00 pm CDT. The on-board GPS system on the \nUAV system and on the cameras\
    \ continuously recorded the coordinates and altitude and \nprovided geo-referencing\
    \ for each image frame in the metadata of each image. Geo-\nreferenced images\
    \ were downloaded after the flight for further processing. \nTable 5.1: Specifications\
    \ of the cameras used in the study \nCamera type \nModel \nSpectrum range \n(nm)\
    \ \nFrame rate \n(s image-1) \nResolution \n(pixel) \nFlight \nheight (m) \nGSD\
    \ * \n(cm pixel-1) \nMultispectral XNiteCanon \nElph130 \nNIR (820 ± 80), R \n\
    (630 ± 80), \nG (550 ± 50) \n2.5 \n4608 × 3456 \n50 \n1.56 \nRGB \nGoPro \nHero5\
    \ \nR-G-B \n0.5 \n4000 × 3000 \n50 \n2.6 \nMultispectral \nMicasense \nRedEdge-M\
    \ \nB (475±10), G \n(560±10), R \n(668±5), red-edge \n(717±5) NIR \n(840±20) \n\
    1 \n1280 × 960 \n30 \n2 \nThermal \nICI 8640 P \n7,000 – 14,000 \n1 \n640 × 512\
    \ \n50 \n6.8 \n* GSD = ground sampling distance. \nTable 5.2: Weather conditions\
    \ during imaging. The values are the means and standard \ndeviations from 11 am\
    \ to 2 pm of the imaging days \nYear \nDate \nAir \ntemperature \n(ºC) \nRelative\
    \ \nhumidity (%) \nWind speed \n(m s-1) \nSolar \nirradiance \n(W m-2) \n2017\
    \ \nAug. 12 \n26.8 ± 0.2 \n63.0 ± 1.0 \n1.3 ± 0.2 \n989 ± 35 \n2018 \nJun. 29\
    \ \n29.3 ± 0.5 \n68.5 ± 1.3 \n2.3 ± 0.5 \n759 ± 71 \nJul. 18 \n30.7 ± 0.3 \n51.3\
    \ ± 1.5 \n2.8 ± 0.5 \n737 ± 96 \nAug. 22 \n25.4 ± 0.3 \n64.8 ± 2.6 \n2.0 ± 0.0\
    \ \n655 ± 38 \nSept. 15 \n30.0 ± 1.2 \n61.5 ± 4.7 \n2.5 ± 0.6 \n773 ± 38 \n102\
    \ \n \n2019 \nJul. 12 \n31.0 ± 0.9 \n48.7 ± 4.8 \n2.0 ± 0.0 \n914 ± 30 \nAug.\
    \ 14 \n31.3 ± 0.9 \n51.0 ± 5.2 \n1.5 ± 0.6 \n850 ± 71 \nSept. 6 \n27.4 ± 1.0 \n\
    53.0 ± 3.9 \n2.0 ± 0.0 \n828 ± 34 \n \nGround truth and reference data, including\
    \ ground reference points (GRPs) and soil \nmoisture content, were collected prior\
    \ to UAV flights on the same day as image data \ncollection. In this study, 28\
    \ GRPs were randomly set in the field and kept in the same \nlocations for all\
    \ flights in each growing season. The GRPs consisted of sixteen fence posts \n\
    (~ 1.1 m in height) with white-black polytechnic boards (0.3 m × 0.3 m) on the\
    \ top and \ntwelve 0.53 m × 0.53 m squares constructed with half-inch plastic\
    \ polyvinyl chloride (PVC) \npipes on the ground.  A ground stake was placed at\
    \ each GRP to be used as a permanent \nmark of GPS position in the growing season.\
    \ A real-time kinematic (RTK) GNSS survey \nkit (REACH RS+, Emlid Ltd., Saint\
    \ Petersburg, Russia) was used to obtain the coordinates \nof the 28 GRPs. Soil\
    \ samples were obtained at those 28 GRPs at two depths (0-0.075 m \nand 0.075-0.15\
    \ m) in 2019 during imagery data collection. The soil samples were put in \nsealed\
    \ plastic bags and weighted in the lab (wet weight). Then the soil samples were\
    \ put in \nan oven to dry 24 hours at 105 ºC. Soil samples were weighed again\
    \ after drying (dry \nweight). Gravimetric soil moisture content was obtained\
    \ by Eq. 2.2.  \n\U0001D446\U0001D446\U0001D450\U0001D450\U0001D446\U0001D446\U0001D459\
    \U0001D459 \U0001D45A\U0001D45A\U0001D450\U0001D450\U0001D446\U0001D446\U0001D459\
    \U0001D459\U0001D45A\U0001D45A\U0001D45A\U0001D45A\U0001D460\U0001D460 \U0001D450\
    \U0001D450\U0001D450\U0001D450\U0001D459\U0001D459\U0001D459\U0001D459\U0001D460\
    \U0001D460\U0001D459\U0001D459\U0001D459\U0001D459 % =\n\U0001D464\U0001D464\U0001D45A\
    \U0001D45A\U0001D459\U0001D459 \U0001D464\U0001D464\U0001D45A\U0001D45A\U0001D464\
    \U0001D464\U0001D459\U0001D459ℎ\U0001D459\U0001D459−\U0001D451\U0001D451\U0001D45A\
    \U0001D45A\U0001D466\U0001D466 \U0001D464\U0001D464\U0001D45A\U0001D45A\U0001D464\
    \U0001D464\U0001D459\U0001D459ℎ\U0001D459\U0001D459\n\U0001D451\U0001D451\U0001D45A\
    \U0001D45A\U0001D466\U0001D466 \U0001D464\U0001D464\U0001D45A\U0001D45A\U0001D464\
    \U0001D464\U0001D459\U0001D459ℎ\U0001D459\U0001D459\n                        \
    \      (2.2) \nSoil moisture sensors (TDR-315, Acclima, Meridian, ID, USA) were\
    \ installed at \nfive selected locations within the field at nominal 0.15, 0.30,\
    \ 0.45, and 0.60 m depths to \nmeasure soil water content. Data loggers (CR206X,\
    \ Campbell Scientific, Logan, UT, USA) \nwere set to record the data every 15\
    \ minutes and wirelessly transmit it to a central computer \nfrom July to October\
    \ each year. \n103 \n \nAs crop temperature affects by the daily air temperature,\
    \ five poster boards (1.0 m \n×1.5 m) painted with different colors (blue, black,\
    \ green, white, and yellow) were \ndistributed in the field and their temperature\
    \ was measured using the thermal camera and \na handheld IR thermometer (59 MAX+,\
    \ FLUKE Corporation, Everett, WA, USA) during \nthe flight each time, as shown\
    \ in Figure 5.1 . In 2019, not only the five color poster boards, \nwe also included\
    \ the dry-wet artificial reference surface (including a wet white cotton sheet\
    \ \nand a dry black cotton sheet) (Meron et al., 2010) as the reference to check\
    \ how canopy \ntemperature changes during different daily air temperature, as\
    \ shown in Figure 5.2. \n \nFigure 5.1: Five poster boards painted with different\
    \ colors. \n \nFigure 5.2: Dry-wet artificial reference surfaces. \n104 \n \n\
    5.4 UAV-based multispectral and thermal images processing \nImages were uploaded\
    \ to Agisoft PhotoScan Pro software (Version 1.2.2, Agisoft \nLLC., Russia) to\
    \ generate orthomosaic images, which is created out of many individual \nimage\
    \ frames that have been stitched together and geometrically corrected (Dukowitz,\
    \ \n2017) based on a mosaic blending model described by Brown and Lowe (2003),\
    \ as shown \nin Figure 5.3a. The GPS locations of the GRPs were used for GPS calibration\
    \ of the \northomosaic images. \n \nFigure 5.3: Image processing and image feature\
    \ extraction. (a) Part of an orthomosaic \nimage with corresponding row separation\
    \ by the red lines and background removal (b). \n(c) Illustration of unit area\
    \ (1 m2) used to extract image features to generate (d) 152 (or \n148) × 315 data\
    \ points of the UAV image features. Then the data points were \ndownsampled to\
    \ 38 (or 37) × 63 data points. Each data point corresponded to a 4 m × 5 m \n\
    area of the field. \n   \nEach cotton row was identified from the orthomosaic\
    \ images using the method \ndeveloped in previous studies (Feng et al., 2019;\
    \ Feng et al., 2020b) based on the \nidentification of image features along the\
    \ edge of the crop rows (such as low NDVI and v* \n105 \n \nvalues in hue, saturation,\
    \ lightness (HSV) color space that represented darker color due to \nshadows).\
    \ An example of separated crop rows is shown in Figure 5.3b. Then, the soil \n\
    background was removed using a threshold of NDVI<0.5 determined by the image \n\
    histogram (Feng et al., 2020a). Five image features were extracted from each ~1-m2\
    \ \nrectangle (0.97 m crop row spacing × 1 m length of row based on the GSD calculated\
    \ by \nthe image resolution, as shown in Figure 5.3c). These image features were\
    \ NDVI, green \nnormalized difference vegetation index (GNDVI), the normalized\
    \ difference red edge \nindex (NDRE), the values of a channel in the CIE-LAB color\
    \ space (a*) and canopy size. \nThese indices have shown to be useful to monitor\
    \ and evaluate crop growth status in other \nstudies (Table 5.3). For example,\
    \ canopy size had a strong relationship with crop biomass \n(Maimaitijiang et\
    \ al., 2019). Studies found that healthier plants had lower reflectance in \n\
    the red channel (about 600 nm to 660 nm wavelength) than unhealthy plants so that\
    \ NDVI \nvalues would be higher for the healthier plants (Ihuoma and Madramootoo,\
    \ 2019). The \nNDRE calculated by the red edge channel (about 680 nm to 760 nm\
    \ wavelength) was also \nuseful for nitrogen status evaluation and had a linear\
    \ relationship with leaf area index (LAI) \nand chlorophyll content (Hansen and\
    \ Schjoerring, 2003). GNDVI and a* were related to \ncrop leaf greenness and chlorophyll\
    \ content (Friedman et al., 2016; Reyes et al., 2017). \nThere were 152 (or 148\
    \ in 2018) cotton rows and the fields were about 320 m in the south-\nnorth direction,\
    \ so 152 (or 148) × 315 data points with related image features were obtained\
    \ \n(the north and south edges of the field were removed to avoid edge effects).\
    \  Then, the data \npoints were down sampled to 38 (or 37) × 63 data points by\
    \ spatial averaging, with each \ndata point equal to 4 cotton rows (matched with\
    \ the four-row harvested yield data) × 5 m \nlength (integer 315/5 rectangle instead\
    \ of non-integer 315/4 square). The GPS locations of \n106 \n \nthe center of\
    \ each 4 m × 5 m area were also extracted from the geo-referenced orthomosaic\
    \ \nimages.  \nTable 5.3: Image features from the three cameras used in this study\
    \ \nFeatures \nEquations \nRelated traits \nReferences \nNDVI \n\U0001D441\U0001D441\
    \U0001D43A\U0001D43A\U0001D441\U0001D441\U0001D441\U0001D441 = \U0001D441\U0001D441\
    \U0001D441\U0001D441\U0001D441\U0001D441 − \U0001D441\U0001D441\n\U0001D441\U0001D441\
    \U0001D441\U0001D441\U0001D441\U0001D441 + \U0001D441\U0001D441 \nwhere NIR and\
    \ R are pixel values in the near-\ninfrared and red channels, respectively \n\
    Yield, chlorophyll \ncontent, biomass \n(Dalezios et al., 2001; \nHunt et al.,\
    \ 2011; \nMoges et al., 2005; Ren \net al., 2008) \nGNDVI \n\U0001D43A\U0001D43A\
    \U0001D441\U0001D441\U0001D43A\U0001D43A\U0001D441\U0001D441\U0001D441\U0001D441\
    \ = \U0001D441\U0001D441\U0001D441\U0001D441\U0001D441\U0001D441 − \U0001D43A\U0001D43A\
    \n\U0001D441\U0001D441\U0001D441\U0001D441\U0001D441\U0001D441 + \U0001D43A\U0001D43A\
    \ \nwhere G are pixel values in the green channel \nYield, chlorophyll \ncontent,\
    \ biomass \n(Hunt et al., 2011; \nMoges et al., 2005)  \nNDRE \n\U0001D441\U0001D441\
    \U0001D43A\U0001D43A\U0001D441\U0001D441\U0001D441\U0001D441 = \U0001D441\U0001D441\
    \U0001D441\U0001D441\U0001D441\U0001D441 − \U0001D441\U0001D441\U0001D440\U0001D440\
    \n\U0001D441\U0001D441\U0001D441\U0001D441\U0001D441\U0001D441 + \U0001D441\U0001D441\
    \U0001D440\U0001D440 \nwhere RE are pixel values in the red edge \nchannel \n\
    Crop senescence, \nmaturity \n(Barnhart et al., 2019; \nThompson et al., 2019)\
    \ \nCanopy \nsize (CS) \n\U0001D436\U0001D436\U0001D446\U0001D446 \n= \U0001D459\
    \U0001D459\U0001D45A\U0001D45A\U0001D45A\U0001D45A\U0001D45B\U0001D45B\U0001D460\
    \U0001D460\U0001D45A\U0001D45A \U0001D450\U0001D450\U0001D45C\U0001D45C \U0001D460\
    \U0001D460\U0001D446\U0001D446\U0001D465\U0001D465\U0001D460\U0001D460\U0001D459\
    \U0001D459\U0001D450\U0001D450 \U0001D450\U0001D450\U0001D45C\U0001D45C \U0001D450\
    \U0001D450\U0001D45A\U0001D45A\U0001D450\U0001D450\U0001D460\U0001D460 \U0001D446\
    \U0001D446\U0001D459\U0001D459 \U0001D44E\U0001D44E \U0001D441\U0001D441\U0001D445\
    \U0001D445\U0001D441\U0001D441\n\U0001D450\U0001D450\U0001D45C\U0001D45C\U0001D460\
    \U0001D460\U0001D45A\U0001D45A\U0001D44E\U0001D44E\U0001D459\U0001D459\U0001D459\
    \U0001D459 \U0001D459\U0001D459\U0001D45A\U0001D45A\U0001D45A\U0001D45A\U0001D45B\
    \U0001D45B\U0001D460\U0001D460\U0001D45A\U0001D45A \U0001D450\U0001D450\U0001D45C\
    \U0001D45C \U0001D460\U0001D460\U0001D446\U0001D446\U0001D465\U0001D465\U0001D460\
    \U0001D460\U0001D459\U0001D459\U0001D450\U0001D450  \U0001D446\U0001D446\U0001D459\
    \U0001D459 \U0001D459\U0001D459ℎ\U0001D460\U0001D460 \U0001D441\U0001D441\U0001D445\
    \U0001D445\U0001D441\U0001D441 \nYield, biomass, \ncrop density \n(Hunt et al.,\
    \ 2011; Liu \net al., 2017; Steduto et \nal., 2012; Walton et al., \n2008) \n\U0001D44E\
    \U0001D44E∗ \n\U0001D44E\U0001D44E∗ channel in the CIE-LAB color space; a* \n\
    represents the green–red color components \nYield, water \ncontent, nitrogen,\
    \ \nchlorophyll \ncontent \n(Friedman et al., 2016; \nHunt et al., 2013; Reyes\
    \ \net al., 2017; Schwarz et \nal., 1987) \nCWSI  \n\U0001D436\U0001D436\U0001D436\
    \U0001D436\U0001D446\U0001D446\U0001D441\U0001D441 = \U0001D447\U0001D447\U0001D460\
    \U0001D460−\U0001D447\U0001D447\U0001D464\U0001D464\n\U0001D447\U0001D447\U0001D44F\
    \U0001D44F − \U0001D447\U0001D447\U0001D464\U0001D464\n \nwhere Tc is the crop\
    \ canopy temperature, Tb \nis the temperature of the black poster board \nand\
    \ Tw is the temperature of the white poster \nboard  \nYield, water stress (Ludovisi\
    \ et al., 2017; \nRischbeck et al., 2016) \n$ROI: region of interest. \nCanopy\
    \ temperature is also an important variable that has been found to be related\
    \ \nto leaf water content and respiration of crops (Baluja et al., 2012; Hoffmann\
    \ et al., 2016a; \nHoffmann et al., 2016b; Ludovisi et al., 2017), and has the\
    \ potential for yield prediction \n(Feng et al., 2020b; Rischbeck et al., 2016).\
    \ The canopy temperature in this study was \nextracted from the thermal images\
    \ collected in 2018-2019. The camera readings were \nfactory calibrated using\
    \ a calibration file provided by the camera supplier. \nTo validate the readings\
    \ of the thermal camera, the average temperature of each of \nthe five reference\
    \ color boards was extracted from the UAV thermal images, and measured \n107 \n\
    \ \nthree times using the handheld thermometer (Figure 5.4). The intent of the\
    \ comparison was \nnot to calibrate the camera, but to validate the sensor readings\
    \ using an additional device. \nA linear regression analysis was conducted between\
    \ the temperature from the thermal \ncamera and the handheld thermometer for the\
    \ five reference boards, and results show a \ngood fit (R2 = 0.99 and RMSE = 0.69\
    \ °С) between two sensors, indicating the readings of \nthe thermal camera were\
    \ valid. \n \nFigure 5.4: Temperature of the ground reference boards measured\
    \ by the UAV-based \nthermal camera and handheld thermometer. The numbers above\
    \ the columns show the \nmeans of the measurements. \nAs crop canopy temperature\
    \ affects by the daily air temperature, a crop water stress \nindex (CWSI) instead\
    \ of the original canopy temperature was used to quantify the crop \nwater stress\
    \ and crop growth variation in this study. The CWSI used the temperature of the\
    \ \nblack and white poster boards as the temperature reference. \n108 \n \n5.5\
    \ Soil and weather data processing \n5.5.1 Soil texture data  \nA soil ECa survey\
    \ was conducted in both fields on the same day using the Veris \n3100, which measured\
    \ the soil ECa at two depths, i.e. shallow (0.3 m, ECa-sh) and deep (1 \nm, ECa-dp).\
    \  There were about 5500 ECa readings (data points) in the research fields (around\
    \ \nhalf in each field). The Kriging method of spatial interpolation was used\
    \ to generate soil \nECa-sh and ECa-dp maps (2946×1716 raster for each field,\
    \ with each grid representing about \n0.1 m × 0.1 m area) based on the discrete\
    \ ECa points and their GPS coordinates. In this \nstudy, a python package pyKrige\
    \ (Revision db07202a, PyKrige developers adopted from \nan Open-Source Project.\
    \ http://pykrige.readthedocs.io) and its build-in variogram models \nwere used\
    \ to generate the block kriging soil ECa-sh and ECa-dp maps. A variogram plot\
    \ was \ncreated. Four variogram models (spherical, exponential, gaussian, cubic\
    \ models) were \nfitted to the variogram plot and the exponential model was chosen\
    \ as it had the lowest \nRMSE. Then the ordinary kriging estimator was used to\
    \ predict soil ECa-sh and ECa-dp of \nthose unknown points in the raster based\
    \ on the variogram model and the distance between \nthe unknown points and the\
    \ measured points (ArcGIS Pro 2.7, 2020; Oliver and Webster, \n1990). Once the\
    \ maps were generated, then soil ECa-sh and ECa-dp could be extracted for the\
    \ \ngrid where the image features were extracted to connect the soil data points\
    \ and image data. \nKriging spatial interpolation was also conducted for the yield\
    \ data, to allow it to be \nconnected to soil data and image features. \nTo develop\
    \ field-wide estimates of soil texture, linear regressions were calculated \n\
    for laboratory-measured sand and clay content as a function of ECa-sh (Sudduth\
    \ et al., 2017; \nVories et al., 2020). Calibration data came from profile soil\
    \ cores that were obtained at \n109 \n \neight locations selected across the field\
    \ to span differences in ECa and analyzed by the \npedogenic horizon. Combined\
    \ data from the top two soil horizons (mean depth 0.34 m) \nyielded the best results,\
    \ likely because approximately 90% of the ECa-sh response comes \nfrom the top\
    \ 0.3 m of the soil profile (Sudduth et al., 2003).  Results indicated a high\
    \ \ncorrelation between clay and ECa-sh (R2=0.85) and between sand and ECa-sh\
    \ (R2= 0.80). \nThese calibrations were then applied to the kriged ECa datasets\
    \ to estimate sand and clay \nfor the entire field (ECa-based sand% and ECa-based\
    \ clay%). \nField capacity (FC) and wilting point (WP) are two variables used\
    \ to describe the \nwater holding capacity. FC is defined as the level of soil\
    \ moisture content in the soil after \nwater drainage by gravity, and the wilting\
    \ point is defined as the level of soil moisture \ncontent where plants cannot\
    \ exert enough force to obtain the moisture from the soil (Easton \nand Bock,\
    \ 2016; Scherer et al., 2017). The amount of water between field capacity and\
    \ \nwilting point can be considered to be the total available water (TAW) for\
    \ plant use. Based \non the studies of Saxton et al. (1986) and Saxton and Rawls\
    \ (2006), the field capacity and \nwilting point were estimated based on the percentage\
    \ sand and clay content: \n\U0001D439\U0001D439\U0001D436\U0001D436 = (\n1\n3×\U0001D434\
    \U0001D434)\n1\n\U0001D435\U0001D435                                         \
    \   (5.1) \n\U0001D436\U0001D436\U0001D440\U0001D440 = (\n15\n\U0001D434\U0001D434\
    \ )\n1\n\U0001D435\U0001D435                                             (5.2)\
    \ \nwhere FC is field capacity (cm3 water / cm3 soil) and WP is wilting point\
    \ (cm3 water / cm3 \nsoil). A and B are coefficients that are calculated as: \n\
    \U0001D440\U0001D440 = \U0001D460\U0001D460(−4.396−0.0715×\U0001D436\U0001D436\
    −0.000488×\U0001D43A\U0001D43A2−0.00004285×\U0001D43A\U0001D43A2×\U0001D436\U0001D436\
    )                    (5.3) \n\U0001D435\U0001D435 = −3.14 − 0.00222 × \U0001D436\
    \U0001D4362 − 0.00003484 × \U0001D446\U0001D4462 × \U0001D436\U0001D436      \
    \         (5.4) \nwhere C is the percentage clay content, and S is the percentage\
    \ sand content (the ECa-\nbased sand% and clay% were used in this study). TAW\
    \ could be calculated by Eq. 5.5 \n(Allen et al., 1998). \n110 \n \n\U0001D447\
    \U0001D447\U0001D440\U0001D440\U0001D436\U0001D436 = 1000 × (\U0001D439\U0001D439\
    \U0001D436\U0001D436 − \U0001D436\U0001D436\U0001D440\U0001D440) × \U0001D44D\U0001D44D\
    \U0001D45A\U0001D45A                                (5.5) \nwhere TAW is the total\
    \ available water (mm), Zr is the rooting depth (m). Zr in the \nemergence stage\
    \ was set to 0.25 m (Allen et al., 1998; Oosterhuis, 1990; Savva and Frenken,\
    \ \n2002) and in the full development stage was set to 0.69 m based on prior research\
    \ in fields \nwith irrigation management in the Mid-South (Sui and Vories, 2020).\
    \ However, because it \nis difficult for plants to extract all the available water\
    \ in the soil, a fraction should be applied \nto the TAW based on a specific crop\
    \ to calculate the readily available water (RAW) as shown \nin Eq. 8 (Allen et\
    \ al., 1998): \n\U0001D441\U0001D441\U0001D440\U0001D440\U0001D436\U0001D436 =\
    \ \U0001D70C\U0001D70C \U0001D447\U0001D447\U0001D440\U0001D440\U0001D436\U0001D436\
    \                               (5.6) \nwhere ρ is the fraction, which was set\
    \ to 0.6 in this study based on Allen et al. (1998). \nIn addition, to explore\
    \ the effects of soil texture at different depths on crop \ndevelopment, clay\
    \ content in 10-cm layers from the surface to a 70 cm depth was estimated \nusing\
    \ ECa data obtained by Veris MSP3 system following the methods developed by \n\
    Sudduth et al. (2017) with the invVERIS software package (EMTOMO, Odivelas, \n\
    Portugal), which used a quasi-3D (Q3D) inversion method (Koganti et al., 2017).\
    \ \n5.5.2 Evapotranspiration and water stress coefficient \nCrop evapotranspiration\
    \ determines the crop water requirement and could be \nestimated by weather parameters\
    \ and soil conditions. Based on Allen et al. (1998) and \nSnyder and Eching (2002),\
    \ daily evapotranspiration of the reference crop (i.e. 20 cm height \ngrass),\
    \ defined as ETo, can be calculated using the Penman-Monteith model based on \n\
    latitude and elevation of the research field, solar radiation, wind speed, dew\
    \ point \ntemperature, and maximum and minimum air temperature. The American Society\
    \ of Civil \nEngineers (ASCE) standardized equation was recommended to simplify\
    \ the ETo \n111 \n \ncalculations (ASCE-EWRI, 2005; Walter et al., 2000). The\
    \ ETo of the research field was \ndirectly provided from a weather station 400\
    \ m from the field using the ASCE standardized \nequation. The evapotranspiration\
    \ of cotton was estimated based on the ETo and the crop \ncoefficient of cotton\
    \ (Kc) calculated using Eq. 5.7. The appropriate Kc has been found to \nvary in\
    \ different growth stages and different crop types (Allen et al., 1998; Hong et\
    \ al., \n2017). The Kc was set to 0.35 in the emergence growth stage and 1.2 in\
    \ mid-season in this \nstudy (Allen et al., 1998; Ko et al., 2009). The length\
    \ of the crop emergence, crop \ndevelopment and reproductive periods were set\
    \ to 20, 50 and 55 days respectively (Allen \net al., 1998; Ko et al., 2009).\
    \ \n\U0001D440\U0001D440\U0001D447\U0001D447\U0001D460\U0001D460 = \U0001D43E\U0001D43E\
    \U0001D460\U0001D460 × \U0001D440\U0001D440\U0001D447\U0001D447\U0001D459\U0001D459\
    \         \n  (5.7) \nwhere ETc is the evapotranspiration of crop and Kc is the\
    \ crop coefficient of cotton. \nRoot zone depletion (Dr) could be used to determine\
    \ the soil water storage relative \nto field capacity (Allen et al., 1998) with\
    \ Dr = 0 indicating no depletion of water (at the \nfield capacity level after\
    \ rain and/or irrigation). The Dr would increase when crops used \nsoil water\
    \ due to evapotranspiration. A value of Dr > RAW indicates that the readily \n\
    available water stores in the soil are less than the plant water required, and\
    \ therefore crops \nare under water stress. A water stress coefficient (Ks) ranging\
    \ from 0 to 1 was used to \ndescribe the level of crop water stress (Allen et\
    \ al., 1998). When Dr < RAW, Ks = 1, which \nmeans no water stress. When Dr >\
    \ RAW, Ks was calculated as: \n\U0001D43E\U0001D43E\U0001D460\U0001D460 =\n\U0001D447\
    \U0001D447\U0001D434\U0001D434\U0001D447\U0001D447−\U0001D43A\U0001D43A\U0001D45F\
    \U0001D45F,\U0001D45A\U0001D45A\n\U0001D447\U0001D447\U0001D434\U0001D434\U0001D447\
    \U0001D447−\U0001D445\U0001D445\U0001D434\U0001D434\U0001D447\U0001D447      \
    \                        (5.8) \nwhere TAW and RAW were calculated based on Eq.\
    \ 4.5 and Eq. 5.6, Dr,i was the Dr on a \nspecific day i and was determined by:\
    \ \n\U0001D43A\U0001D43A\U0001D45A\U0001D45A,\U0001D464\U0001D464 = \U0001D43A\
    \U0001D43A\U0001D45A\U0001D45A,\U0001D464\U0001D464−1 + \U0001D440\U0001D440\U0001D447\
    \U0001D447\U0001D460\U0001D460,\U0001D464\U0001D464 − \U0001D440\U0001D440\U0001D464\
    \U0001D464 − \U0001D441\U0001D441\U0001D464\U0001D464                        (5.9)\
    \ \n112 \n \nwhere Dr,i-1 was the Dr on the last day, ETc,i,,  Pi, and Ii were\
    \ the ETc, precipitation and the \nirrigation amounts for the specific day. Precipitation\
    \ and/or irrigation amounts greater \nthan Dr were assumed lost through runoff\
    \ and/or deep percolation below the root zone \nand were not available to the\
    \ crop. \nUsing 2019 data as an example, the daily Ks was calculated for each\
    \ of the 38 × 63 \n= 2,394 raster (each data point was the 4 m × 5 m area) using\
    \ the weather data and irrigation \ndata from May 15 (planting date in 2019) to\
    \ September 6 (the last date of image collection), \nor a total of 113 days as\
    \ shown in Figure 5.5. For each position (or data point) in the 38 × \n63 rasters\
    \ of the 113 days, 113 Ks maps were calculated based on the weather data, \nirrigation\
    \ data and soil data using Eq. 5.8 and Eq. 4.9. These two equations connected\
    \ each \nday’s weather (there were 113 days in Figure 5.5 so that 113 Ks maps\
    \ were generated) and \nthe spatially variable soil together. After all 113 Ks\
    \ maps were generated, the following \nfeatures were calculated (up to the imaging\
    \ date, i.e. Aug 14 in Figure 5.5) to match each \ndata point of the image features\
    \ (i.e. images collected on Aug 14 in Figure 5.5) with the \nsoil features raster\
    \ as shown in Figure 5.5, including Ks on the imaging date; the number \nof days\
    \ after planting when Ks < 1 first occurred; the total number of days with Ks\
    \ < 1 (as \nwell as 0.9 ≤ Ks <1, 0.8≤ Ks <0.9, 0.7≤ Ks <0.8, 0.6≤ Ks <0.7, 0.5≤\
    \ Ks <0.6, 0.4≤ Ks <0.5  \nand Ks <0.4; the Ks was classified as 8 different stress\
    \ levels); the largest number of \ncontinuous days with Ks < 1 (as well as Ks\
    \ <0.9, Ks <0.8, Ks <0.7, Ks <0.6, Ks <0.5, Ks <0.4 \nand Ks <0.3). The main reasons\
    \ for using this method to connect the soil and image feature \nmaps with the\
    \ Ks maps instead of directly connecting the 113 Ks maps with the image \nfeature\
    \ and soil raster were: 1) there were many instances of Ks = 1 in the overall\
    \ 63 × 38 \n× 113 matrix; and 2) the overall 63 × 38 × 113 matrix was a large\
    \ matrix and dimension \n113 \n \nreduction methods were needed. Similar processing\
    \ was conducted for the 2018 data from \nMay 16 to Sep 15 (122 Ks maps). \n \n\
    Figure 5.5: The Ks maps and the connection method of soil, image features and\
    \ Ks maps. \nKs was calculated for each position in the 38 (or 37 in 2018) × 63\
    \ spatial raster with each \nKs map representing a day \n5.6 Soil and weather\
    \ effects on crop development \n5.6.1 Data analysis methods \nThe goal of this\
    \ study was to evaluate variations in cotton development due to the \nvariation\
    \ of soil and weather. The soil condition of the field was quantified using the\
    \ \nfeatures extracted from ECa data, including the ECa-based sand% (the ECa-based\
    \ clay% \ndid not be included due to the high linear correlation with the ECa-based\
    \ sand% came from \nthe same ECa data source), ECa-based clay content percentage\
    \ in seven different depths of \nsoil (clay10 – clay70), FC, WP, TAW and RAW.\
    \ Soil water input included irrigation data \nand the watered plots recorded for\
    \ the center pivot irrigation system and precipitation from \nthe weather station.\
    \ The Ks feature was calculated based on water input, ETc (Eq. 4.7) and \nsoil\
    \ features. The image features extracted were used to represent the crop development.\
    \ \n114 \n \nPearson correlation coefficients between soil features and image\
    \ features were \ncalculated to evaluate their relationships. Analysis of variance\
    \ (ANOVA) was conducted \nto compare differences in the means of NDVI for different\
    \ Ks groups and sand% groups \nusing Tukey’s Honest method at a 0.05 level of\
    \ significance. A scalable tree boosting \nmodel XGBoost (Chen and Guestrin, 2016)\
    \ was used to explore how much the soil features \nand Ks features contributed\
    \ to the crop growth variation (as quantified by image features). \nXGBoost, standing\
    \ for eXtreme Gradient Boosting, is an implementation of gradient \nboosted decision\
    \ trees designed for efficiently processing structured or tabular data. The \n\
    XGBoost model, as one of the tree ensemble methods, included hundreds of decision\
    \ trees \nthat were trained using soil features and Ks features as inputs and\
    \ image features as the \nprediction (outputs) based on an additive strategy.\
    \ The overall dataset was split into 85% \ntraining set and 15% test set, and\
    \ the training process for each tree used 70% of the training \ndataset.  The\
    \ XGBoost model has the ability to automatically select features and to address\
    \ \ncollinearity problems (Hayes et al., 2015). Another benefit of using XGBoost\
    \ model is that \nthe model can retrieve importance scores for each input feature,\
    \ indicating how useful or \nvaluable each feature was in the construction of\
    \ the boosted decision trees within the model \n(Friedman et al., 2001; Lee, 2017).\
    \ The developed model was tested using the test dataset \nand the coefficient\
    \ of determination (R2) of a regression between the prediction and true \ndata\
    \ (imagery features) was used to quantify how well the model explained the true\
    \ data. \nAll data analysis was conducted in Matlab (version 2018a, MathWorks,\
    \ Natick, \nMA, USA), and in Python software with the packages NumPy (v1.16) (Oliphant,\
    \ 2006), \nPandas (v0.25) (McKinney, 2010) and SciPy (v1.5.2) (Virtanen et al.,\
    \ 2020). \n115 \n \n5.6.2 Correlation between soil features and image features\
    \ \nEven though there were nonlinear relationships between ECa -based sand%, FC,\
    \ \nWP and TAW based on Eqs. 4.1-4.6 and between clay contents through the soil\
    \ profile \n(clay10-clay70) based on inversion methods using the invVERIS software\
    \ package, \nPearson correlation coefficients (r) observed between them were high.\
    \ For example, \ncorrelations were over 0.9 between clay% in every adjacent depth\
    \ layer (clay10-clay70) as \nshown in Figure 5.6. This high similarity in clay%\
    \ distribution between adjacent depth \nlayers can also be seen in Figure 5.7.\
    \ The first three layers (i.e. 0 to 10 cm, 10 to 20 cm and \n20 to 30 cm) had\
    \ similar spatial clay% distribution patterns with r around 0.7-0.9. The last\
    \ \nthree layers (i.e. 40 to 50 cm, 50 to 60 cm and 60 to 70 cm) also had similar\
    \ spatial clay \ndistribution patterns with r over 0.95. However, the first three\
    \ layers and the last three \nlayers had different spatial clay distribution patterns\
    \ with the r around 0.2-0.8. Figure 5.7 \nshows the clay content was higher in\
    \ the deeper soil layers. \n116 \n \n \nFigure 5.6: Pearson correlation coefficients\
    \ between soil features. Clay% and sand% are \nthe average ECa-based clay and\
    \ sand content in the top two soil horizons. \n \nFigure 5.7: Kriged maps of clay\
    \ content in different depth layers. (a) to (g) are the soil \nclay% distribution\
    \ in the field at the seven different depths (clay10 – clay70) \nTable 5.4 shows\
    \ the mean and standard deviation of the 28 soil moisture samples \ncollected\
    \ in 2019. In July, August and September, the soil had a low average moisture\
    \ level \n117 \n \naround 6%-7% in the top ~15 cm, which was lower than the average\
    \ calculated WP around \nthe whole field (about 3000 data points in the east field;\
    \ average WP: 8.73%, FC: 21.48%) \nand indicated that crop could not obtain water\
    \ from the upper layers of the soil. The \nstandard deviation in moisture content\
    \ was around 2% between the 28 samples that had \nvarious ECa-estimated soil textures.\
    \ Pearson correlation coefficients (r) between soil \nclay10-clay20 and NDVI,\
    \ GNDVI, canopy size, and NDRE that represented the crop \ngrowth variation of\
    \ 2019 (Figure 5.8) were as low as 0.2-0.5, and most of them were lower \nthan\
    \ the r between image features and clay content at other deeper soil layers. The\
    \ above \nthree points indicated that the clay10-clay20 had low effects on crop\
    \ growth variation. \nTable 5.4: Mean and standard deviation of the moisture content\
    \ of 28 soil samples in the \ntop 0-0.075 and 0.075-0.15 m \nDate \nMean (%) \n\
    Std (%) \n \n0-0.075 m \n0.075-0.15 m \n0-0.075 m \n0.075-0.15 m \nMay 7 \n11.06\
    \ \n13.38 \n2.46 \n2.46 \nMay 31 \n14.52 \n16.64 \n3.27 \n3.04 \nJuly 12 \n6.11\
    \ \n6.86 \n1.70 \n1.50 \nAugust 14 \n6.38 \n- \n2.37 \n- \nSeptember 6 \n7.37\
    \ \n- \n1.94 \n- \n \n118 \n \n \n \nFigure 5.8: Pearson correlation coefficients\
    \ between soil features and image features. \nNRRE were not available before August\
    \ of 2018. Thermal data were not available in \nAugust 2018 and July 2019 \nClay\
    \ content in different depths had a different correlation with crop growth during\
    \ \ndifferent growth stages (Figure 5.8). The highest r values between the clay\
    \ content and the \nNDVI, GNDVI, canopy size, and NDRE in Jul. 2019 were around\
    \ 0.4-0.5 in the middle \n119 \n \nlayers (i.e., clay30 - clay40), while the highest\
    \ r values in Aug. and Sep. 2019 were around \n0.55-0.75 in deeper layers (i.e.,\
    \ clay50 - clay70). The study of Ritchie et al. (2007) showed \nthat the root\
    \ mass peaked at the flowering stage (Aug.), and the highest mass was at the 55\
    \ \ncm soil depth for a mature cotton plant (Aug. and Sep.). The cotton on July\
    \ 12, 2019 was \n58 days after planting, and the length of the roots may have\
    \ reached 70 cm depth \n(Oosterhuis, 1990). However, the mass of the roots may\
    \ have been small in July in 50-70 \ncm depth. Based on the crop water requirement\
    \ curve during the growing season (Allen et \nal., 1998; Scherer et al., 2017),\
    \ cotton required less water in the vegetation development \nstage and early reproductive\
    \ stage (July) than in the peak reproductive stage (Aug. and \nSep.), which may\
    \ be the reason that the soil clay content had 0.2-0.3 higher r with the crop\
    \ \ngrowth in Aug. and Sep. than in July.  \nThe r values between soil features\
    \ (i.e., WP and FC) and image features (NDVI, \nGNDVI, canopy size, and NDRE)\
    \ increased from July to September in 2019 (Figure 5.8). \nThere was 0.8 cm average\
    \ daily rainfall on 19-27 of June and 0.34 cm on 5-10 of July in \n2019 (Figure\
    \ 2.3), and there was no irrigation during the period. The r between soil water\
    \ \nholding capacity (WP and FC) and crop growth variation (NDVI, GNDVI, canopy\
    \ size, \nand NDRE) were around 0.4-0.5 on July 12. The r values between soil\
    \ water holding \ncapacity and crop growth variation were around 0.5-0.6 in Aug.\
    \ and around 0.6-0.7 in Sep., \nsuggesting that the effect of soil water holding\
    \ capacity on crop growth status may be a \ncumulative process. \nThe r values\
    \ between soil features (i.e., clay% in 0-70 cm) and image features \n(NDVI, GNDVI,\
    \ canopy size, and NDRE) were around -0.3-0 in Jun., 0.3-0.5 in July, 0-\n0.3\
    \ in Aug. and -0.3-0 in Sep. of 2018. Due to an equipment error, many of the 7\
    \ irrigation \n120 \n \napplications in 2018 were applied to the whole field,\
    \ rather than site-specific, resulting in \nover-irrigation in parts of the field\
    \ (see Figure 2.3), and this may be one of the reasons for \nthe low r values\
    \ between clay content and the image features in 2018, which will be \ndiscussed\
    \ with more details in the three following Chapters. Since the irrigation was\
    \ only \nconducted three times at a few plots in 2019 but having an over-irrigation\
    \ problem in 2018 \nand the crop growth variation had more correlation with soil\
    \ texture in 2019 than in 2018, \nwe will talk about the data in 2019 before that\
    \ in 2018 in all following Chapters. \n5.6.3 Water stress coefficients \nThe daily\
    \ Ks of the 38 × 63 (2019) or 37x63 (2018) positions (raster) of the field \n\
    were calculated using the Eq. 4.8, and the lowest Ks (min Ks) was checked to decide\
    \ if \nwater stress presented in the field. As shown in Figure 5.9a there were\
    \ three periods having \nmin Ks < 1 larger than 3 days, beginning on July 9, Aug\
    \ 1 and Sep. 2 of 2019 as marked by \nblack lines in Figure 5.9a. The Ks returned\
    \ to 1 again when rains > 1 cm per day occurred \non July 16, and Aug. 23. Figure\
    \ 5.9a shows that the crops imaged in July had experienced \nonly 3 days (from\
    \ July 9 to July 11) of min Ks = 0.84, while the crops imaged in Aug. had \na\
    \ lower min Ks around 0.31 after being subjected to water stress for several days,\
    \ which \nmatched with the conclusion in the previous Chapter that higher r values\
    \ between clay \ncontent and crop growth were found in Aug. 2019 than that in\
    \ July 2019. \nIn 2018, images were collected on dates where min Ks = 0.90 in\
    \ June (Figure 5.9b), \nmin Ks = 0.41 in July, and non-water stressed days with\
    \ min Ks = 1 in Aug. and Sep. Some \nregions were irrigated on July 14 and July\
    \ 17, which was just a few days before image \ncollection. These may be another\
    \ two reasons that NDVI, GNDVI, canopy size and NDRE \nhave lower r values with\
    \ clay content, WP and FC in 2018 than those in 2019. \n121 \n \n \n \nFigure\
    \ 5.9: Cumulative precipitation and the lowest water stress coefficients in each\
    \ day \nof (a) 2019 and (b) 2018. The black vertical lines mark the starting dates\
    \ for Ks <1. The \ngreen lines mark the dates of imaging. Irrigation was site-specific\
    \ and did not show in the \nfigures \nFigure 5.10 shows an example of the Ks maps\
    \ on Aug. 8, Aug. 10, and Aug. 13 in \n2019. Crops were affected by the lack of\
    \ water beginning on Aug. 1 (Figure 5.9a) and then \nrainfall on Aug. 7 helped\
    \ the crop recovered the most on Aug. 8. However, no rainfall and \nirrigation\
    \ was applied between Aug. 8- 13, and the lack of water effects accumulated until\
    \ \nAugust 13 resulting in a large variation of Ks due to different soil water\
    \ storage capacities \n122 \n \n(Figure 5.10b-c). The NDVI map collected on Aug\
    \ 14 (Figure 5.10d) had similar patterns \nwith the Ks map on Aug 13. Figure 5.10e\
    \ shows the different mean NDVI at different Ks \nlevels. When Ks < 0.44, the\
    \ mean NDVI was 0.77; while, when Ks > 0.67, the mean NDVI \nwas 0.89. In the\
    \ Ks intervals of 0.44-0.56 and 0.56-0.67, a similar mean NDVI of around \n0.85\
    \ was observed. The result indicated that the Ks has a good correlation with crop\
    \ growth \n(NDVI). \n \nFigure 5.10: Ks maps on (a) Aug 8, (b) Aug 10 and (c)\
    \ Aug 13. The legend in (c) is also \nused in (a)-(b). The white circle in (c)\
    \ marks a plot that had about 22 mm irrigation \napplied on Aug 6. (d) NDVI map\
    \ collected on Aug 14. (e) relationship between NDVI \nand the Aug 13 Ks map.\
    \ Different lower-case letters indicate a significant difference at \n123 \n \n\
    the 5% level of Tukey’s honest significant difference test. The mean NDVI in Ks\
    \ levels \nfrom 0-0.25 is 0.77, from 0.25-0.5 is 0.86, from 0.5-0.75 is 0.85,\
    \ from 0.75-1 is 0.89. \nThe Ks maps were compared to the thermal data to exam\
    \ their ability of water stress \nidentification. Firstly, the color poster boards’\
    \ temperature collection on each imaging date \nwere compared, shown as Figure\
    \ 5.11. The color poster board’s temperature difference can \nreflect the air\
    \ temperature difference on the imaging date. The temperature of the white \n\
    color poster boards did not have too much difference and the different range was\
    \ around \n2 °C. The temperature difference of the yellow, green and blue color\
    \ poster boards was \naround 10 °C. The temperature difference of the black poster\
    \ boards was 7 °C. The Sep. \n2018 and Aug. 2019 had the highest temperature of\
    \ the black poster boards. \n \nFigure 5.11: Temperature of the five color poster\
    \ boards on each day of image collection. \nFigure 5.12 shows the CWSI maps of\
    \ Aug. 14 and Sep. 6 in 2019; and Ks maps of \nAug. 13 and Sep. 5 in 2019 (since\
    \ images were collected at noon of the day and the CWSI \nmaps were compared with\
    \ the Ks maps in the previous days). As mentioned above, min Ks \nwas around 0.31\
    \ on Aug. 13 and around 0.37 on Sep. 5 in 2019. The Ks maps showed there \nwas\
    \ water stress identification on Aug. 13 shown as the marked black circle regions\
    \ in \n124 \n \nFigure 5.12c, which also be identified by the CWSI maps on Aug.\
    \ 14 shown as the marked \nblack circle regions in Figure 5.12a. The right upper\
    \ region of the field also was identified \nas a water stress region in CWSI on\
    \ Aug. 14 in Figure 5.12a but the Ks map on Aug. 13 in \nFigure 5.12c did not\
    \ show too much serious water stress as the other water stress regions \nin the\
    \ black circles. CWSI map of Sep. 6 in Figure 5.12b shows less water stress level\
    \ than \nthat on Aug. 14, and the Ks map of Sep. 5 in Figure 5.12d also shows\
    \ less water stress level \nthan that on Aug. 13. The Ks maps were estimated water\
    \ stress level maps based on soil \ntexture and weather condition, while the CWSI\
    \ maps were the images of the crop canopy. \nAlthough they are focus on different\
    \ objects, they almost gave the same water stress region \nidentification results,\
    \ which showed that the results of those maps were consistent and both \nof them\
    \ could be used as the tool for crop water stress identification.  \n125 \n \n\
    \ \nFigure 5.12: CWSI maps of Aug. 14 (a) and Sep. 6 (b) in 2019; and Ks maps\
    \ of Aug. 13 \n(c) and Sep. 5 (d) in 2019. There was a problem with the camera\
    \ on Sep 6, 2019 and the \nimages in (d) were lost of the east edge part of the\
    \ field. The legend in (a) is also used in \n(b), and the legend in (c) is also\
    \ used in (d). The black and white circles mark the regions \ndiscussed in the\
    \ text. \nFigure 5.13 shows Ks maps of Jun. 29, Jul. 18 and Sep. 15 in 2018; and\
    \ Ks maps of \nJun. 29, Jul. 18 and Sep. 15 in 2018. Unlike the thermal images\
    \ collection in 2019, two of \nthe three images were collected in the days that\
    \ did not have too much water stress \nidentification, with the highest CWSI values\
    \ of 0.06 on Jun. 29 in Figure 5.13a and of 0.01 \non Sep. 15 in Figure 5.13c.\
    \ Min Ks was around 0.90 on Jun. 29 in Figure 5.13d and 1.0 on \n126 \n \nSep.\
    \ 15 in Figure 5.13f. Unlike other vegetation indices maps (such as NDVI maps\
    \ \ndescribed in Chapter 4.4.4), if no water stress identification on that specific\
    \ day, CWSI \nwould not show value variation through the field even though the\
    \ daily air temperature was \nhigh (i.e. Sep. 15). If no water stress identification\
    \ on that specific day, Ks maps also would \nnot show value variation through\
    \ the field (Figure 5.13c). The min Ks was around 0.41, and \nit could be seen\
    \ in Figure 5.13b and Figure 5.13e that the Ks map and the CWSI map almost \n\
    mark the same regions that identifying water stress. However, the Ks map in Figure\
    \ 5.13e \nhas a very hard boundary of the irrigation regions, while the boundary\
    \ of the CWSI was \nmuch soft. This is because when calculated the Ks map, only\
    \ soil, weather and water input \nwere considered, and the irrigation plots were\
    \ considered as the exact same positions as \nour irrigation design. But in fact,\
    \ when irrigation was applied in the field with no physical \nseparation, winds\
    \ and water flow at the boundary of the irrigation regions could not be \naccurate\
    \ control, which resulted in the soft boundary of water stress variation in the\
    \ CWSI \nmaps. For this reason, the boundary of water stress in the Ks map may\
    \ not reflect real crop \ncondition, while CWSI captured by UAV thermal images\
    \ had better performance to \nindicate water stress than the Ks maps. \n127 \n\
    \ \n \nFigure 5.13: CWSI maps of Jun. 29 (a), Jul. 18 (b) and Sep. 15 (c) in 2018;\
    \ and Ks maps \nof Jun. 29 (d), Jul. 18 (e) and Sep. 15 (f) in 2018. CWSI map\
    \ of Aug. 22 in 2018 was not \navailable due to a thermal camera problem. The\
    \ legend in (a) is also used in (b) and (c), \nand the legend in (d) is also used\
    \ in (e) and (f). \n5.6.4 Difference in NDVI under various soil and weather conditions\
    \  \nThrough comparison of the image features collected through 2018-2019, different\
    \ \ncrop growth rates under varying soil and weather conditions were observed.\
    \ The NDVI \nmaps collected in the west field in 2018 and in the east field in\
    \ 2019 were used as examples \nhere to explain the different growth rates, as\
    \ shown in Figure 5.14 to Figure 5.19.  \nFigure 5.14a-c is the NDVI maps of 2019.\
    \ NDVI in July (Figure 5.14a) ranged from \n0.75-0.91 (mean=0.85, Figure 5.15a)\
    \ within the whole field and Figure 5.16a shows \n128 \n \nsignificant NDVI differences\
    \ associated with four different sand% groups of the field. \nHowever, Figure\
    \ 5.14b shows that NDVI values in regions with more sand (Figure 5.14d \nand Figure\
    \ 5.15d) decreased into the range of [0.6, 0.8] (0.6≤ NDVI≤ 0.8) and increased\
    \ \ninto [0.8, 0.95] in regions having lower sand content percentage (Figure 5.14d\
    \ and Figure \n5.15d) in Aug. This result was consistent with the results in Figure\
    \ 5.16 that NDVI dropped \nfrom Jul. to Aug. in the (67,89] sand% group (67< sand%≤\
    \ 89) while the other three groups \nshowed NDVI increased from Jul. to Aug. NDVI\
    \ increased more in the (0,42] sand% group \nthan in the (42,53] and (53,67] sand%\
    \ groups. Figure 5.14c shows that most of the NDVI \nvalues were in the range\
    \ of [0.85, 0.9] (Figure 5.15c), and only a few values were less than \n0.8 in\
    \ Sep. Some of the NDVI values increased from Aug. to Sep. and some decreased\
    \ (less \nthan 0.1) as shown in Figure 5.14e and Figure 5.15e. The decreasing\
    \ values were in the \nregions with lower sand content. NDVI of the regions that\
    \ had more sand content increased. \nFigure 5.16 also shows this trend. The crops\
    \ in high sand content regions were under water \nstress from Aug. 8 to Aug. 20\
    \ (Figure 5.9a) and the early stress causes the plants to develop \nmore slowly.\
    \ But the rainfall in 21-28 Aug. helped the stressed crops to recover and the\
    \ \nplant started growing more in September with the nitrogen that wasn’t used\
    \ earlier and \ngrows at the time of year that it should be senescing. \n129 \n\
    \ \n \nFigure 5.14: NDVI maps collected on east field in 2019. (a)-(c) NDVI of\
    \ Jul., Aug. and \nSep in 2019. There was a problem with the camera on Sep 5,\
    \ 2019 and the images in (c) \nwere lost of the east edge part of the field. The\
    \ legend in (c) is also used in (a) and (b). \n(d)-(e) show the NDVI changes from\
    \ Jul. to Aug. and Aug. to Sep. in 2019. (f) ECa-based \nsand% map of the east\
    \ field. \n130 \n \n \nFigure 5.15: (a)-(c) Histogram of NDVI maps of Jul., Aug.\
    \ and Sep in 2019. (d)-(e) \nHistogram of NDVI changes from Jul. to Aug. and Aug.\
    \ to Sep. in 2019. \n \nFigure 5.16: (a) Mean NDVI and (b) NDVI difference of\
    \ four sand% content groups in \n2019. ANOVA test was conducted to compare the\
    \ mean NDVI and its difference in four \nsand% levels. Different lower-case letters\
    \ indicate a significant difference at the 5% level \nof Tukey’s honest significant\
    \ difference test. The results of Sep. 2019 may be misleading \ndue to missing\
    \ NDVI values on the right side of the field. The sand% groups were split \nbased\
    \ on quartiles of the soil data of each side of the field. \nDifference in NDVI\
    \ were also observed in 2018 (Figure 5.17a-d and Figure 5.18a-\nd). No decrease\
    \ in NDVI was observed from Jun. to Jul. when the crop was in the vegetative \n\
    development stage, but a potentially different growth rate could be observed as\
    \ shown in \n131 \n \nFigure 5.17e and Figure 5.18e that crops in the regions\
    \ having higher clay content were \nassociated with a faster NDVI increase. A\
    \ faster NDVI increase was observed in the (0,50] \nsand% group and (50,65] sand%\
    \ group than the (65,72] sand% group and (72,85] sand% \ngroup from Jun. to Jul.\
    \ in Figure 5.19. The camera was changed from XNiteCanonElph130 \nto Micasense\
    \ RedEdge-M in Aug. 2018 and the XNiteCanonElph130 camera had a smaller \ndynamic\
    \ NDVI range due to the broad spectral bands (Feng et al., 2020b). In order to\
    \ \ncompare NDVI maps collected by these two cameras, two 40 m × 40 m regions\
    \ of the field \nwere imaged at the same time using these two cameras and Figure\
    \ 5.20 shows the NDVI \nhistograms of the collected frames. The region in Figure\
    \ 5.20a was with full canopy cover \nand no soil background was observed, while\
    \ the region in Figure 5.20b was with non-full \ncanopy cover and soil background\
    \ was observed. NDVI values less than 0.7 in the \nMicasense image and less than\
    \ 0.1 in the XNiteCanonElph130 image were soil background. \nTherefore, there\
    \ was a 0.60 NDVI shift between these two cameras when the soil \nbackground was\
    \ removed. Obviously, different growth rates were observed in Aug. 2018 \nin Figure\
    \ 5.17f and Figure 5.18f, with some of the NDVI decreasing and the other \nincreasing,\
    \ which was the same trend with the east field of Aug. 2019 in Figure 5.17d. \n\
    Mean NDVI increased in the (0,50] sand% group (a little bit), (50,65] sand% group\
    \ and \n(65,72] sand% group but dropped in the (72,85] sand% group from Jul. to\
    \ Aug. in Figure \n5.19. The mean NDVI in the (0,50] sand% group dropped the most\
    \ in Sep. 2018. The crop \nin the low sand content region may have first entered\
    \ the senescence stage. Higher NDVI \nvalues were found in the (50,65] sand% and\
    \ (65,72] sand% groups than the (0,50] sand% \ngroup during the whole 2018 growing\
    \ season (Figure 5.19). Soil moisture sensor data \nshowed that the (50,65] sand%\
    \ groups had the highest water content in July (Figure 5.21), \n132 \n \nand this\
    \ result was consistent with the NDVI data in July in Figure 5.19. Soil water\
    \ content \nin the (50,65] sand% was still higher than the (0,50] sand% group\
    \ in Aug. except for the \nfirst 0-15 cm depth. The last irrigation was applied\
    \ on Aug. 7, 2018, and then the soil water \ncontent in (0,50] sand% group became\
    \ the highest one in Sep., resulting from the higher-\nthan-average rainfall (Figure\
    \ 2.3). However, due to the sufficient soil moisture content in \nthe Jul. and\
    \ Aug., crop in (50,65] sand% and (65,72] sand% groups still showed high NDVI\
    \ \non Sep. 15. \n \nFigure 5.17: NDVI maps collected on the west field in 2018.\
    \ (a)-(d) NDVI of Jun., Jul., \nAug. and Sep in 2018. (e)-(g) NDVI changes from\
    \ Jun. to Jul., July to Aug. and Aug. to \nSep. in 2018. (h) ECa-based sand% map\
    \ of the west field. \n133 \n \n \nFigure 5.18: (a)-(d) Histogram of NDVI maps\
    \ of Jun., Jul., Aug. and Sep in 2018. (e)-(g) \nHistogram of NDVI changes from\
    \ Jun. to Jul., July to Aug. and Aug. to Sep. in 2018. \n \nFigure 5.19: (a) Mean\
    \ NDVI and NDVI difference of four sand% content groups in the year 2018. \nANOVA\
    \ test was conducted to compare the mean NDVI in different sand% levels. Different\
    \ lower-case \nletters indicate a significant difference at the 5% level of Tukey’s\
    \ honest significant difference test. The \nsand% groups were split based on quartiles\
    \ of the soil data of each side of the field \n134 \n \n \nFigure 5.20: Histogram\
    \ compares two NDVI images collected by two cameras at the \nsame time with (a)\
    \ full canopy cover and no soil background visible and (b) non-full \ncanopy cover\
    \ and soil background visible. \n \nFigure 5.21: Soil moisture content (%) in\
    \ different sand% groups at 4 different depth \n(0.15, 0.30, 0.45 and 0.60 m)\
    \ in (a) Jul., (b) Aug. and (c) Sep. in 2018 \n \n135 \n \n5.6.5 The effects of\
    \ soil and weather features on crop growth \nTo explore the contribution of soil\
    \ and weather features on crop growth, the soil \nfeatures and Ks features were\
    \ used as the inputs to train the XGBoost model to predict each \nimage feature\
    \ and yield. Table 5.3 shows the R2 obtained for the test set. The R2 in Aug.\
    \ \nand Sep. in 2019 were around 0.6-0.7 and Jul., Aug. and Sep. in 2018 were\
    \ around 0.5-0.6. \nSoil features and Ks features cannot fit the variance of the\
    \ crop growth accurately in the \nearly growth stages (i.e. Jul. 2019 and Jun.\
    \ 2018) with R2 around 0.2-0.4. The accuracy of \nyield prediction based on soil\
    \ and weather features increased from Jun. (R2 = 0.57) to Jul.-\nSep. (around\
    \ 0.62) in 2018 as well as from Jul. (0.65) to Aug.-Sep. (around 0.7) in 2019.\
    \  \nTable 5.5: R2 for each image features predicted by soil features and Ks features\
    \ on the test \nset \n \n2019 \n2018 \n \nJuly \nAug \nSep \nJune \nJuly \nAug\
    \ \nSep \nNDVI \n0.40 \n0.75 \n0.73 \n0.29 \n0.59 \n0.65 \n0.62 \nCanopy size\
    \ \n0.52 \n0.72 \n0.77 \n0.29 \n0.60 \n0.53 \n0.52 \nGNDVI \n0.46 \n0.73 \n0.65\
    \ \n0.26 \n0.56 \n0.54 \n0.53 \nNDRE \n0.39 \n0.70 \n0.54 \n-* \n- \n0.50 \n0.50\
    \ \nLab_a \n0.22 \n0.65 \n0.65 \n0.28 \n0.56 \n0.59 \n0.55 \nYield \n0.65 \n0.70\
    \ \n0.71 \n0.57 \n0.64 \n0.62 \n0.62 \n     *  XNiteCanonElph130 did not have\
    \ red-edge spectral band. \nThe XGBoost model could not fit the crop growth variation\
    \ accurately in June 2018 \nwhen all the plants were small (could not explain\
    \ the June 2018 data well), therefore they \nwere not used to analyze feature\
    \ contribution. Figure 5.22 shows the feature contribution \nof soil features\
    \ and Ks features for each image feature and yield in July, Aug. and Sep in \n\
    2018 and 2019 based on the analysis of the decision trees built into the XGBoost\
    \ model,  \n136 \n \nwith the percentage (%) represented the ratio of a specific\
    \ feature used in trees to the total \ntrees of the XGBoost (details of the first\
    \ five important features are shown in Fig. S4 in the \nSupplementary data). \n\
    Figure 5.22 shows that there are more grids with darker red color in the soil\
    \ features \nrather than Ks features with image features and yield in 2019, indicating\
    \ that soil features \nmight contribute more than the Ks features did to crop\
    \ development. The contribution of \nclay content at deeper layers (i.e., contribution\
    \ cumulated from all the clay40 to clay70) \naccounted for 34%-58% (Figure 5.23a)\
    \ to each of the prediction of NDVI, GNDVI, a* and \nNDRE in Aug 2019, while the\
    \ shallow layers (i.e. contribution cumulated from all the \nclay10 to clay30)\
    \ contributed less. However, the contribution of the clay content at deep \nlayers\
    \ (i.e., contribution cumulated from all the clay40 to clay70) dropped to 16-40%\
    \ \n(Figure 5.23a) in September. The longest period of days continuously having\
    \ Ks <0.3 \n(L_0.3 in Figure 5.22) was 7%-13% (Figure 5.23a) contribution to the\
    \ NDVI, GNDVI, a* \nand NDRE prediction in Aug. This may indicate that crops’\
    \ development might be \nseriously affected if they were under a long period of\
    \ Ks <0.3. Clay content percentage at \ndeep layers (i.e. clay40 to clay70) had\
    \ about 33%-69% (Figure 5.23a) contribution on the \nfinal yield prediction. In\
    \ summary, the result indicated the clay content in deeper layers \nplayed an\
    \ important role to crop development in 2019. It also showed that L_0.3 was a\
    \ \nmore important feature than other Ks features to the crop growth in Aug. \n\
    137 \n \n \nFigure 5.22: Heat map for the feature importance (%) of soil features\
    \ and Ks features for \neach image feature and yield. I_ Ks: the Ks in the imaging\
    \ date; T_1: total days having Ks \n<1; T_0.9_1: total days having Ks in [0.9,1];\
    \ L_1: the largest number of continuous days \nhaving Ks <1; B_1: number of days\
    \ after planting to first instance of Ks <1. \nYield_2019_08_2019: the Ks features\
    \ for the 2019 yield estimation were calculated from \nthe date of planting to\
    \ the imaging date in Aug. The pink and blue boxes mark the values \ndescribed\
    \ in the text \n138 \n \n \n \n139 \n \n \n \nFigure 5.23: Feature contribution\
    \ (%) of the five highest and remainder (as ‘others’) soil \nfeatures and Ks features\
    \ for each image feature and yield in (a) 2019 and (b) 2018. \nXNiteCanonElph130\
    \ camera did not have a red-edge spectral band and NDRE was not \navailable in\
    \ July 2018 \n \n140 \n \nIn addition, Figure 5.23b shows the feature contribution\
    \ (%) of soil and Ks features \nfor the prediction of each image feature and yield\
    \ in 2018. It can be seen from the figure \nthat the feature contribution of the\
    \ overall soil features was less than 20% in the prediction \nof all the image\
    \ features in Aug. and September. On the other hand, the Ks features had \nhigher\
    \ feature contribution values to the image feature prediction, especially L_1\
    \ and L_0.9 \nwhose contribution values were 25%-55% on the prediction of NDVI,\
    \ GNDVI, a* and \nNDRE. The different patterns showing in 2018 and 2019 might\
    \ be due to more irrigation \napplied in 2018 and crops being less affected by\
    \ the soil water capacity. The feature \ncontribution value of soil feature on\
    \ yield estimation in 2018 decreased to 18%-25%, which \nwas 15%-44% lower than\
    \ that in 2019. In summary, Ks is a good feature to explore crop \ngrowth variation\
    \ with fields having irrigation applied. \n5.7 Conclusion \nThis study investigated\
    \ the impact of soil texture, moisture and weather conditions \non cotton growth\
    \ variation that was quantified by crop growth image features from UAV-\nbased\
    \ multispectral images collected in 2018 and 2019. Soil features such as clay\
    \ content, \nfield capacity, wilting point and water holding capacity were calculated\
    \ and calibrated \nbased on soil ECa data. The water stress coefficient Ks was\
    \ calculated using weather, \nirrigation and soil data. Pearson correlation, ANOVA\
    \ and XGBoost models were \ndeveloped to explore the relationship of soil features\
    \ and Ks features with crop growth. \nResults showed that difference in NDVI were\
    \ found in both 2018 and 2019 under varying \nECa-based soil texture. Soil features\
    \ and Ks features did not fit the crop growth variation \nwell in the early growth\
    \ stages when crops do not require a large amount of water and soil \nwater storage\
    \ is sufficient.  Soil features and Ks features had a higher correlation with\
    \ image \n141 \n \nfeatures in middle growth stages. Soil features had a stronger\
    \ correlation with crop \ndevelopment when crops suffered from water stress. Clay\
    \ content in shallow layers affected \ncrop development in early growth stages\
    \ while clay content in the deeper layers affected \nthe middle growth stages.\
    \ The Ks features were important indicators of crop growth \nvariation if irrigations\
    \ were applied. The results showed that investigating the soil and \nweather data\
    \ corresponding with UAV image data is feasible to exam the effects of soil \n\
    and weather on crop growth variation. \n5.8 Literature cited \nAddy, J.W., Ellis,\
    \ R.H., Macdonald, A.J., Semenov, M.A., Mead, A., 2020. Investigating \nthe effects\
    \ of inter-annual weather variation (1968–2016) on the functional \nresponse of\
    \ cereal grain yield to applied nitrogen, using data from the Rothamsted \nLong-Term\
    \ Experiments. Agricultural and Forest Meteorology 284, 107898. \nAlexandratos,\
    \ N., Bruinsma, J., 2012. World agriculture towards 2030/2050: the 2012 \nrevision.\
    \ \nAllen, R., Pereira, L., Raes, D., Smith, M., 1998. Crop evapotranspiration-Guidelines\
    \ for \ncomputing crop water requirements-FAO Irrigation and drainage paper 56.\
    \ Fao, \nRome 300, D05109. \nArcGIS Pro 2.7, 2020. How kriging works. \nASCE-EWRI,\
    \ 2005. The ASCE standardized reference evapotranspiration equation. \nASCE Reston,\
    \ Va. \nBaluja, J., Diago, M.P., Balda, P., Zorer, R., Meggio, F., Morales, F.,\
    \ Tardaguila, J., \n2012. Assessment of vineyard water status variability by thermal\
    \ and \n142 \n \nmultispectral imagery using an unmanned aerial vehicle (UAV).\
    \ Irrigation \nScience 30, 511-522. \nBarnhart, I., Rosso, L.M., Secchi, M., Ciampitti,\
    \ I., 2019. Evaluating sorghum senescence \npatterns using small unmanned aerial\
    \ vehicles and multispectral iImaging. Kansas \nField Research 2019, 166. \nBasso,\
    \ B., Antle, J., 2020. Digital agriculture to design sustainable agricultural\
    \ systems. \nNature Sustainability 3, 254-256. \nBattisti, R., Bender, F.D., Sentelhas,\
    \ P.C., 2018. Assessment of different gridded weather \ndata for soybean yield\
    \ simulations in Brazil. Theoretical and Applied \nClimatology. \nBell, J.M.,\
    \ Schwartz, R., McInnes, K.J., Howell, T., Morgan, C.L., 2018. Deficit \nirrigation\
    \ effects on yield and yield components of grain sorghum. Agricultural \nWater\
    \ Management 203, 289-296. \nBendig, J., Yu, K., Aasen, H., Bolten, A., Bennertz,\
    \ S., Broscheit, J., Gnyp, M.L., Bareth, \nG., 2015. Combining UAV-based plant\
    \ height from crop surface models, visible, \nand near infrared vegetation indices\
    \ for biomass monitoring in barley. \nInternational Journal of Applied Earth Observation\
    \ and Geoinformation 39, 79-\n87. \nBeres, B.L., Hatfield, J.L., Kirkegaard, J.A.,\
    \ Eigenbrode, S.D., Pan, W.L., Lollato, R.P., \nHunt, J.R., Strydhorst, S., Porker,\
    \ K., Lyon, D., Ransom, J., Wiersma, J., 2020. \nToward a Better Understanding\
    \ of Genotype × Environment × Management \nInteractions—A Global Wheat Initiative\
    \ Agronomic Research Strategy. Frontiers \nin Plant Science 11. \n143 \n \nBittelli,\
    \ M., 2011. Measuring soil water content: A review. HortTechnology 21, 293-300.\
    \ \nChen, T., Guestrin, C., 2016. Xgboost: A scalable tree boosting system, Proceedings\
    \ of \nthe 22nd acm sigkdd international conference on knowledge discovery and\
    \ data \nmining, pp. 785-794. \nCobb, J.N., DeClerck, G., Greenberg, A., Clark,\
    \ R., McCouch, S., 2013. Next-generation \nphenotyping: requirements and strategies\
    \ for enhancing our understanding of \ngenotype–phenotype relationships and its\
    \ relevance to crop improvement. \nTheoretical and Applied Genetics 126, 867-887.\
    \ \nCuong, T.X., Ullah, H., Datta, A., Hanh, T.C., 2017. Effects of silicon-based\
    \ fertilizer on \ngrowth, yield and nutrient uptake of rice in tropical zone of\
    \ Vietnam. Rice \nScience 24, 283-290. \nDalezios, N., Domenikiotis, C., Loukas,\
    \ A., Tzortzios, S., Kalaitzidis, C., 2001. Cotton \nyield estimation based on\
    \ NOAA/AVHRR produced NDVI. Physics and \nChemistry of the Earth, Part B: Hydrology,\
    \ Oceans and Atmosphere 26, 247-251. \nDatta, S., Taghvaeian, S., Stivers, J.,\
    \ 2017. Understanding soil water content and \nthresholds for irrigation management.\
    \ \nDukowitz, Z., 2017. What is an orthomosaic map? How these maps are helping\
    \ catch bad \nguys, grow grops, and geep people safe. \nEaston, Z.M., Bock, E.,\
    \ 2016. Soil and soil water relationships. Virginia Cooperative \nExtension. \n\
    Feng, A., Zhang, M., Sudduth, K.A., Vories, E.D., Zhou, J., 2019. Cotton yield\
    \ \nestimation from UAV-based plant height. Transactions of the ASABE 62, 393-\n\
    404. \n144 \n \nFeng, A., Zhou, J., Vories, E., Sudduth, K.A., 2020a. Evaluation\
    \ of cotton emergence \nusing UAV-based narrow-band spectral imagery with customized\
    \ image \nalignment and stitching algorithms. Remote Sensing 12, 1764. \nFeng,\
    \ A., Zhou, J., Vories, E.D., Sudduth, K.A., Zhang, M., 2020b. Yield estimation\
    \ in \ncotton using UAV-based multi-sensor imagery. Biosystems Engineering 193,\
    \ \n101-114. \nForcella, F., Arnold, R.L.B., Sanchez, R., Ghersa, C.M., 2000.\
    \ Modeling seedling \nemergence. Field Crops Research 67, 123-139. \nFriedman,\
    \ J., Hastie, T., Tibshirani, R., 2001. The elements of statistical learning.\
    \ \nSpringer series in statistics, New York, NY, USA. \nFriedman, J.M., Hunt,\
    \ E.R., Mutters, R.G., 2016. Assessment of leaf color chart \nobservations for\
    \ estimating maize chlorophyll content by analysis of digital \nphotographs. Agronomy\
    \ Journal 108, 822-829. \nGago, J., Fernie, A.R., Nikoloski, Z., Tohge, T., Martorell,\
    \ S., Escalona, J.M., Ribas-\nCarbó, M., Flexas, J., Medrano, H., 2017. Integrative\
    \ field scale phenotyping for \ninvestigating metabolic components of water stress\
    \ within a vineyard. Plant \nMethods 13, 90. \nHansen, P., Schjoerring, J., 2003.\
    \ Reflectance measurement of canopy biomass and \nnitrogen status in wheat crops\
    \ using normalized difference vegetation indices and \npartial least squares regression.\
    \ Remote Sensing of Environment 86, 542-553. \nHatfield, J.L., Walthall, C.L.,\
    \ 2015. Meeting Global Food Needs: Realizing the Potential \nvia Genetics × Environment\
    \ × Management Interactions. Agronomy Journal 107. \n145 \n \nHayes, T., Usami,\
    \ S., Jacobucci, R., McArdle, J.J., 2015. Using Classification and \nRegression\
    \ Trees (CART) and random forests to analyze attrition: Results from \ntwo simulations.\
    \ Psychology and Aging 30, 911. \nHickey, L.T., A, N.H., Robinson, H., Jackson,\
    \ S.A., Leal-Bertioli, S.C.M., Tester, M., \nGao, C., Godwin, I.D., Hayes, B.J.,\
    \ Wulff, B.B.H., 2019. Breeding crops to feed \n10 billion. Nat Biotechnol 37,\
    \ 744-754. \nHoffmann, H., Jensen, R., Thomsen, A., Nieto, H., Rasmussen, J.,\
    \ Friborg, T., 2016a. \nCrop water stress maps for an entire growing season from\
    \ visible and thermal \nUAV imagery. Biogeosciences 13, 6545. \nHoffmann, H.,\
    \ Nieto, H., Jensen, R., Guzinski, R., Zarco-Tejada, P., Friborg, T., 2016b. \n\
    Estimating evaporation with thermal UAV data and two-source energy balance \n\
    models. Hydrology and Earth System Sciences 20, 697-713. \nHong, M., Zeng, W.,\
    \ Ma, T., Lei, G., Zha, Y., Fang, Y., Wu, J., Huang, J., 2017. \nDetermination\
    \ of growth stage-specific crop coefficients (Kc) of sunflowers \n(Helianthus\
    \ annuus L.) under salt stress. Water 9, 215. \nHunt, E.R., Doraiswamy, P.C.,\
    \ McMurtrey, J.E., Daughtry, C.S.T., Perry, E.M., \nAkhmedov, B., 2013. A visible\
    \ band index for remote sensing leaf chlorophyll \ncontent at the canopy scale.\
    \ International Journal of Applied Earth Observation \nand Geoinformation 21,\
    \ 103-112. \nHunt, E.R., Hively, W.D., McCarty, G.W., Daughtry, C.S.T., Forrestal,\
    \ P.J., Kratochvil, \nR.J., Carr, J.L., Allen, N.F., Fox-Rabinovitz, J.R., Miller,\
    \ C.D., 2011. NIR-green-\nblue high-resolution digital images for assessment of\
    \ winter cover crop biomass. \nGIScience & Remote Sensing 48, 86-98. \n146 \n\
    \ \nIhuoma, S.O., Madramootoo, C.A., 2019. Crop reflectance indices for mapping\
    \ water \nstress in greenhouse grown bell pepper. Agricultural Water Management\
    \ 219, 49-\n58. \nJames, I., Waine, T., Bradley, R., Taylor, J., Godwin, R., 2003.\
    \ Determination of soil \ntype boundaries using electromagnetic induction scanning\
    \ techniques. Biosystems \nEngineering 86, 421-430. \nJiang, P., Thelen, K., 2004.\
    \ Effect of soil and topographic properties on crop yield in a \nnorth-central\
    \ corn–soybean cropping system. Agronomy Journal 96, 252-258. \nKitchen, N., Drummond,\
    \ S., Lund, E., Sudduth, K., Buchleiter, G., 2003. Soil electrical \nconductivity\
    \ and topography related to yield for three contrasting soil–crop \nsystems. Agronomy\
    \ Journal 95, 483-495. \nKitchen, N., Sudduth, K., Myers, D., Drummond, S., Hong,\
    \ S., 2005. Delineating \nproductivity zones on claypan soil fields using apparent\
    \ soil electrical \nconductivity. Computers and Electronics in Agriculture 46,\
    \ 285-308. \nKo, J., Piccinni, G., Marek, T., Howell, T., 2009. Determination\
    \ of growth-stage-specific \ncrop coefficients (Kc) of cotton and wheat. Agricultural\
    \ Water Management 96, \n1691-1697. \nKoganti, T., Moral, F., Rebollo, F., Huang,\
    \ J., Triantafilis, J., 2017. Mapping cation \nexchange capacity using a Veris-3100\
    \ instrument and invVERIS modelling \nsoftware. Science of The Total Environment\
    \ 599, 2156-2165. \nKřížová, K., Kroulík, M., Haberle, J., Lukáš, J., Kumhálová,\
    \ J., 2018. Assessment of soil \nelectrical conductivity using remotely sensed\
    \ thermal data. Agronomy Research. \nLee, C., 2017. Feature importance measures\
    \ for tree models. \n147 \n \nLiu, S., Baret, F., Allard, D., Jin, X., Andrieu,\
    \ B., Burger, P., Hemmerlé, M., Comar, A., \n2017. A method to estimate plant\
    \ density and plant spacing heterogeneity: \napplication to wheat crops. Plant\
    \ methods 13, 38. \nLudovisi, R., Tauro, F., Salvati, R., Khoury, S., Mugnozza\
    \ Scarascia, G., Harfouche, A., \n2017. UAV-Based Thermal Imaging for High-Throughput\
    \ Field Phenotyping of \nBlack Poplar Response to Drought. Frontiers in Plant\
    \ Science 8, 1681. \nMaimaitijiang, M., Sagan, V., Sidike, P., Maimaitiyiming,\
    \ M., Hartling, S., Peterson, \nK.T., Maw, M.J., Shakoor, N., Mockler, T., Fritschi,\
    \ F.B., 2019. Vegetation index \nweighted canopy volume model (CVMVI) for soybean\
    \ biomass estimation from \nunmanned aerial system-based RGB imagery. ISPRS Journal\
    \ of Photogrammetry \nand Remote Sensing 151, 27-41. \nMcKinney, W., 2010. Data\
    \ structures for statistical computing in python, Proceedings of \nthe 9th Python\
    \ in Science Conference. Austin, TX, pp. 51-56. \nMeron, M., Tsipris, J., Orlov,\
    \ V., Alchanatis, V., Cohen, Y., 2010. Crop water stress \nmapping for site-specific\
    \ irrigation by thermal imagery and artificial reference \nsurfaces. Precision\
    \ agriculture 11, 148-162. \nMoges, S., Raun, W., Mullen, R., Freeman, K., Johnson,\
    \ G., Solie, J., 2005. Evaluation of \ngreen, red, and near infrared bands for\
    \ predicting winter wheat biomass, nitrogen \nuptake, and final grain yield. Journal\
    \ of Plant Nutrition 27, 1431-1441. \nOliphant, T.E., 2006. A guide to NumPy.\
    \ Trelgol Publishing USA. \nOliver, M.A., Webster, R., 1990. Kriging: a method\
    \ of interpolation for geographical \ninformation systems. International Journal\
    \ of Geographical Information System 4, \n313-332. \n148 \n \nOnder, S., Caliskan,\
    \ M.E., Onder, D., Caliskan, S., 2005. Different irrigation methods \nand water\
    \ stress effects on potato yield and yield components. Agricultural water \nmanagement\
    \ 73, 73-86. \nOosterhuis, D.M., 1990. Growth and development of a cotton plant.\
    \ Nitrogen Nutrition of \nCotton: Practical Issues, 1-24. \nRay, D.K., Mueller,\
    \ N.D., West, P.C., Foley, J.A., 2013. Yield Trends Are Insufficient to \nDouble\
    \ Global Crop Production by 2050. PLOS ONE 8, e66428. \nRen, J., Chen, Z., Zhou,\
    \ Q., Tang, H., 2008. Regional yield estimation for winter wheat \nwith MODIS-NDVI\
    \ data in Shandong, China. International Journal of Applied \nEarth Observation\
    \ and Geoinformation 10, 403-413. \nReyes, J.F., Correa, C., Zúñiga, J., 2017.\
    \ Reliability of different color spaces to estimate \nnitrogen SPAD values in\
    \ maize. Computers and Electronics in Agriculture 143, \n14-22. \nRischbeck, P.,\
    \ Elsayed, S., Mistele, B., Barmeier, G., Heil, K., Schmidhalter, U., 2016. \n\
    Data fusion of spectral, thermal and canopy height parameters for improved yield\
    \ \nprediction of drought stressed spring barley. European Journal of Agronomy\
    \ 78, \n44-59. \nRitchie, G.L., Bednarz, C.W., Jost, P.H., Brown, S.M., 2007.\
    \ Cotton growth and \ndevelopment. Cooperative Extension Service and the University\
    \ of Georgia \nCollege of Agricultural and Environmental Sciences, Athens, GA,\
    \ USA. \nRomero, M., Luo, Y., Su, B., Fuentes, S., 2018. Vineyard water status\
    \ estimation using \nmultispectral imagery from an UAV platform and machine learning\
    \ algorithms \n149 \n \nfor irrigation scheduling management. Computers and Electronics\
    \ in Agriculture \n147, 109-117. \nRussell, K., 2017. Genotype× Environment× Management:\
    \ Implications for selection to \nheat stress tolerance and nitrogen use efficiency\
    \ in Soft Red Winter Wheat. \nSantesteban, L., Di Gennaro, S., Herrero-Langreo,\
    \ A., Miranda, C., Royo, J., Matese, A., \n2017. High-resolution UAV-based thermal\
    \ imaging to estimate the instantaneous \nand seasonal variability of plant water\
    \ status within a vineyard. Agricultural \nWater Management 183, 49-59. \nSavva,\
    \ A.P., Frenken, K., 2002. Crop water requirements and irrigation scheduling.\
    \ FAO \nSub-Regional Office for East and Southern Africa Harare. \nSaxton, K.,\
    \ Rawls, W., 2006. Soil water characteristic estimates by texture and organic\
    \ \nmatter for hydrologic solutions. Soil Science Society of America Journal 70,\
    \ \n1569-1578. \nSaxton, K., RRawls, W., Romberger, J., Papendick, R., 1986. Estimating\
    \ generalized \nsoil-water characteristics from texture 1. Soil Science Society\
    \ of America Journal \n50, 1031-1036. \nScherer, T.F., Franzen, D., Cihacek, L.,\
    \ 2017. Soil, water and plant characteristics \nimportant to irrigation. North\
    \ Dakota State University, Fargo, North Dakota. \nSchut, A.G., Traore, P.C.S.,\
    \ Blaes, X., Rolf, A., 2018. Assessing yield and fertilizer \nresponse in heterogeneous\
    \ smallholder fields with UAVs and satellites. Field \nCrops Research 221, 98-107.\
    \ \n150 \n \nSchwarz, M.W., Cowan, W.B., Beatty, J.C., 1987. An experimental comparison\
    \ of RGB, \nYIQ, LAB, HSV, and opponent color models. ACM Transactions on Graphics\
    \ \n(TOG) 6, 123-158. \nSnyder, R., Eching, S., 2002. Penman-Monteith daily (24-hour)\
    \ reference \nevapotranspiration equations for estimating ETo, ETr and HS ETo\
    \ with daily \ndata. Regents of the University of California. \nSteduto, P., Hsiao,\
    \ T.C., Fereres, E., Raes, D., 2012. Crop yield response to water. FAO \nRome.\
    \ \nStępień, M., Samborski, S., Gozdowski, D., Dobers, E.S., Chormański, J., Szatyłowicz,\
    \ \nJ., 2015. Assessment of soil texture class on agricultural fields using ECa,\
    \ Amber \nNDVI, and topographic properties. Journal of Plant Nutrition and Soil\
    \ Science \n178, 523-536. \nSudduth, K.A., Kitchen, N., Bollero, G., Bullock,\
    \ D., Wiebold, W., 2003. Comparison of \nelectromagnetic induction and direct\
    \ sensing of soil electrical conductivity. \nAgronomy Journal 95, 472-482. \n\
    Sudduth, K.A., Kitchen, N., Drummond, S., 2017. Inversion of soil electrical \n\
    conductivity data to estimate layered soil properties. Advances in Animal \nBiosciences\
    \ 8, 433-438. \nSudduth, K.A., Kitchen, N.R., Wiebold, W., Batchelor, W., Bollero,\
    \ G., Bullock, D., \nClay, D., Palm, H., Pierce, F., Schuler, R., 2005. Relating\
    \ apparent electrical \nconductivity to soil properties across the north-central\
    \ USA. Computers and \nElectronics in Agriculture 46, 263-283. \n151 \n \nSui,\
    \ R., Vories, E., 2020. Comparison of sensor-based and weather-based irrigation\
    \ \nscheduling. Applied Engineering in Agriculture, 0. \nThompson, C.N., Guo,\
    \ W., Sharma, B., Ritchie, G.L., 2019. Using normalized difference \nred edge\
    \ index to assess maturity in cotton. Crop Science 59, 2167-2177. \nTremblay,\
    \ N., Bouroubi, Y.M., Bélec, C., Mullen, R.W., Kitchen, N.R., Thomason, \nW.E.,\
    \ Ebelhar, S., Mengel, D.B., Raun, W.R., Francis, D.D., 2012. Corn response \n\
    to nitrogen is influenced by soil texture and weather. Agronomy Journal 104, \n\
    1658-1671. \nTurner, D., Lucieer, A., Malenovský, Z., King, D.H., Robinson, S.A.,\
    \ 2014. Spatial co-\nregistration of ultra-high resolution visible, multispectral\
    \ and thermal images \nacquired with a micro-UAV over Antarctic moss beds. Remote\
    \ Sensing 6, 4003-\n4024. \nUnited Nations, U.N., 2019. World population prospects\
    \ 2019: highlights. Department of \nEconomic and Social Affairs, Population Division.\
    \ \nVan Bussel, L.G., Ewert, F., Zhao, G., Hoffmann, H., Enders, A., Wallach,\
    \ D., Asseng, \nS., Baigorria, G.A., Basso, B., Biernath, C., 2016. Spatial sampling\
    \ of weather \ndata for regional crop yield simulations. Agricultural and Forest\
    \ Meteorology 220, \n101-115. \nVirtanen, P., Gommers, R., Oliphant, T.E., Haberland,\
    \ M., Reddy, T., Cournapeau, D., \nBurovski, E., Peterson, P., Weckesser, W.,\
    \ Bright, J., 2020. SciPy 1.0: \nfundamental algorithms for scientific computing\
    \ in Python. Nature Methods 17, \n261-272. \n152 \n \nVories, E., O’Shaughnessy,\
    \ S., Sudduth, K.A., Evett, S., Andrade, M., Drummond, S., \n2020. Comparison\
    \ of precision and conventional irrigation management of cotton \nand impact of\
    \ soil texture. Precision Agriculture, 1-18. \nVos, C., Don, A., Prietz, R., Heidkamp,\
    \ A., Freibauer, A., 2016. Field-based soil-texture \nestimates could replace\
    \ laboratory analysis. Geoderma 267, 215-219. \nWalter, A., Finger, R., Huber,\
    \ R., Buchmann, N., 2017. Opinion: Smart farming is key to \ndeveloping sustainable\
    \ agriculture. Proceedings of the National Academy of \nSciences 114, 6148-6150.\
    \ \nWalter, I.A., Allen, R.G., Elliott, R., Jensen, M., Itenfisu, D., Mecham,\
    \ B., Howell, T., \nSnyder, R., Brown, P., Echings, S., 2000. ASCE's standardized\
    \ reference \nevapotranspiration equation, Watershed management and operations\
    \ management \n2000, pp. 1-11. \nWalton, J.T., Nowak, D.J., Greenfield, E.J.,\
    \ 2008. Assessing urban forest canopy cover \nusing airborne or satellite imagery.\
    \ Arboriculture & Urban Forestry 38, 334-340. \nXin, Y., Tao, F., 2019. Optimizing\
    \ genotype-environment-management interactions to \nenhance productivity and eco-efficiency\
    \ for wheat-maize rotation in the North \nChina Plain. Science of the Total Environment\
    \ 654, 480-492. \nXue, J., Su, B., 2017. Significant remote sensing vegetation\
    \ indices: A review of \ndevelopments and applications. Journal of sensors 2017.\
    \ \nZhang, L., Zhang, H., Niu, Y., Han, W., 2019. Mapping maize water stress based\
    \ on \nUAV multispectral remote sensing. Remote Sensing 11, 605. \n \n153 \n \n\
    Chapter 6. CROP YIELD ESTIMATION BASED ON SOIL, \nWEATHER AND UAV IMAGES \n6.1\
    \ Abstract \nCrop yield prediction is important for farmers to conduct proper\
    \ field management \nand marketing decisions. However current prediction models\
    \ are usually built on single \ntypes of data, e.g. imagery data, soil or weather\
    \ data, which may not reflect the holistic \neffect of environment and management\
    \ on crop development. The goal of this study was \nto quantify cotton yield variance\
    \ due to soil texture and weather conditions using the \nmultiple-year unmanned\
    \ aerial vehicle (UAV) imagery data and deep learning techniques. \nEleven soil\
    \ features were extracted using the collected apparent soil electrical conductivity\
    \ \n(ECa) to describe soil variation over the field. A soil convolutional neural\
    \ network (CNN) \nwas developed to process the soil features. In addition, six\
    \ weather parameters were also \nprocessed by a weather CNN. A gated recurrent\
    \ unit (GRU) network was used to quantify \ncotton yield variation due to soil\
    \ and weather features by integrating UAV-based image \nfeatures (e.g., NDVI)\
    \ variance in different months. Results show that each one of the three \nyears’\
    \ cotton yield could be predicted using the model trained with data of the other\
    \ two \nyears with prediction errors of MAE = 247 (8.9%) to 384 kg ha-1 (13.7%),\
    \ which showed \nthat quantified yield variance based on soil texture, weather\
    \ conditions and UAV imagery \nfor a future year was feasible. \nKeyword: Yield\
    \ prediction, soil CNN, weather CNN, multispectral imagery, gated \nrecurrent\
    \ unit network \n \n154 \n \n6.2 Introduction \nSoil and weather conditions are\
    \ important factors to quantify crop development and \nyield. Soil texture, defined\
    \ as different percentages of sand, clay and silt content in a soil \ngroup, affects\
    \ the water holding capacity and had effects on crop development and yield \n\
    (Scherer et al., 2017; Tremblay et al., 2012). Forcella et al. (2000) reported\
    \ that soil texture \nand soil water content affected seedling emergence date\
    \ and emergence rate. Soil texture \nand soil water content also had effects on\
    \ root development (Oosterhuis, 1990). Many \nstudies found out that soil texture\
    \ had relationships with the yield of cotton (Vories et al., \n2020), corn (Kitchen\
    \ et al., 2003; Kitchen et al., 2005) and soybean (Jiang and Thelen, \n2004; Kitchen\
    \ et al., 2005). Weather conditions of temperature, precipitation and solar \n\
    radiation had been shown to be important effects for yield variability of maize\
    \ and winter \nwheat between years (Ceglar et al., 2016). Addy et al. (2020) showed\
    \ that the functional \nresponse of crop yield to nitrogen application rate varied\
    \ under different weather conditions \nbetween years. \nHowever, the combined\
    \ effects of soil and weather on crops are complicated. Crops \nshowed different\
    \ levels of weather sensitivity in different regions (Mathieu and Aires, 2018)\
    \ \nand different growth stages (Addy et al., 2020; Ceglar et al., 2016). Crop\
    \ development and \nyield also showed different dependence on soil under different\
    \ years’ weather conditions \n(Feng et al., 2021). Studies have developed many\
    \ crop models from regional to global to \nquantify crop development and yield\
    \ based on weather and soil (Van Bussel et al., 2016). \nThe development of those\
    \ models required more than 10 years of data and generally needed \na recalibration\
    \ when used in other regions (Ceglar et al., 2016). Khaki et al. (2020) and \n\
    155 \n \nKhaki and Wang (2019) developed yield prediction models based on weather\
    \ and soil that \ncan work for different USA states but needed data from 35 years\
    \ and 9 years, respectively. \nRemote sensing technology has been used in recent\
    \ years to monitor crops to \nquantify crop development and yield. For example,\
    \ satellites images were used for yield \nprediction (Schut et al., 2018; You\
    \ et al., 2017) , evaluating metal-induced stress on crops \ndevelopment (Liu\
    \ et al., 2018), and quantifying chlorophyll concentration in vegetation \n(Singhal\
    \ et al., 2018). Site-specific monitoring instead of the region and state-level\
    \ \nmonitoring is more meaningful for farmers, and unmanned aerial vehicle (UAV)-based\
    \ \nimages were used to evaluate field-scale crop emergence (Chen et al., 2018;\
    \ Feng et al., \n2020a), crop water stress (Bian et al., 2019), crop growth status\
    \ (Du and Noguchi, 2017) \nand yield (Feng et al., 2019; Feng et al., 2020b).\
    \ Many studies that worked with UAV \nimages to quantify crop growth and yield\
    \ focused on images (including training and testing \nsets) collected within one\
    \ year (Maimaitijiang et al., 2020; Yang et al., 2019; Zhang et al., \n2020).\
    \ Models built using one year’s data were difficult to apply in a future year\
    \ to guide \nfield management. Evaluation of yield in a future year before harvest\
    \ is meaningful for \nfarmers, which required models that have good predictions\
    \ performance in an additional \nyear that included data not used in the model\
    \ training procedure. There were studies \nworking on this (Chu and Yu, 2020;\
    \ Khaki and Wang, 2019; Khaki et al., 2020; Schwalbert \net al., 2020) but none\
    \ of them works with UAV images. \nCombining soil texture, weather conditions\
    \ and UAV images together would be \npromising to quantify crop growth and yield\
    \ in a future year. This study aimed to establish \na method for yield estimation\
    \ based on soil texture, weather conditions and UAV imagery \ncollected in three\
    \ different years where soil texture did not change much (2017-2019). The \n156\
    \ \n \nspecific objectives were: 1) developing data fusion methods for spatiotemporal\
    \ soil data, \nweather data and UAV image data; 2) developing a deep learning\
    \ model to predict yield \nfor different years. \n6.3 UAV image processing \n\
    Images collected in all three years were processed using Agisoft PhotoScan Pro\
    \ \n(Version 1.2.2, Agisoft, Russia) to generate orthomosaic images. The GPS locations\
    \ of the \nGRPs were used for the GPS calibration of the orthomosaic images. Each\
    \ cotton row was \nidentified from the orthomosaic images using the method developed\
    \ in a previous study \n(Feng et al., 2019). NDVI was calculated in the orthomosaic\
    \ images and soil background \nwas removed based on a threshold of NDVI < 0.5.\
    \ There were 152 (or 148 in 2018) cotton \nrows and the field was about 320 m\
    \ in the south-north direction, therefore 152 (or 148) × \n315 rectangles with\
    \ ~1.0 m2 each were segmented (the north and south edges of the field \nwere removed\
    \ to avoid edge effects) and the mean NDVI in each rectangle were extracted \n\
    as image data points following by the procedure written in Feng et al. (2021).\
    \  Then, the \ndata points were downsampled to 38 (or 37) × 63 data points by\
    \ averaging the NDVI in a \nsample area of 4 m (match the four-row harvested yield\
    \ data) × 5 m (got the integer from \n315/5 instead of non-integer from 315/4).\
    \ The GPS of the center of each sample area was \nextracted from the geo-referenced\
    \ orthomosaic images. To register the data collected in \ndifferent years, data\
    \ points of soil ECa and yield and were firstly interpolated with Kriging, \n\
    and then the 4 m × 5 m sample areas were cropped from the Kriging maps of yield\
    \ and soil \nECa to align with those NDVI areas in different years. \n157 \n \n\
    6.4 Soil and weather features processing \nSand content percentage (sand%) and\
    \ clay content percentage (clay%) in the \naverage 34 cm and clay content percentage\
    \ in seven different depths from 10 cm to 70 cm \n(defined as clay10 - clay70)\
    \ were calibrated based on ECa and the soil sample lab analysis \nfollowing the\
    \ data processing procedure described in Chapter 4. Field capacity (FC), \nwilting\
    \ point (WP) and total available water (TAW) were calculated based on the sand%\
    \ \nand clay% (Saxton and Rawls, 2006; Saxton et al., 1986). Those soil features\
    \ could be used \ndirectly as inputs in machine learning models for crop development\
    \ and yield estimation \nas described in Chapter 4. However, Khaki et al. (2020)\
    \ and Chapter 4 pointed out that \nthere were dependencies (relationships) of\
    \ the soil features measured at different depths. \nFor example, the clay10 –\
    \ clay70 features showed high Pearson correlation coefficients \nbetween their\
    \ neighborhood layers (as described in Chapter 4). A soil convolutional neural\
    \ \nnetwork (S_CNN) was developed to capture the dependencies of soil data measured\
    \ at \ndifferent depths using two convolution layers (Figure 5.1). The convolutional\
    \ neural \nnetworks are able to scan the clay content in every two-neighbor layer\
    \ to extract the spatial \nfeatures. The first convolution layer consisted of\
    \ four kernels (Khaki et al., 2020) to extract \ninformation in each two neighborhood\
    \ depth layers.  Each kernel (marks as color dot in \nFigure 5.1) was designed\
    \ as ∑\n\U0001D498\U0001D498\U0001D48A\U0001D48A × \U0001D499\U0001D499\U0001D48A\
    \U0001D48A\n\U0001D459\U0001D459\n\U0001D48A\U0001D48A=\U0001D7CF\U0001D7CF\n\
    \ where xi were the inputs of clay1 - clay7 and the \nwi were the weights. Different\
    \ kernels with different wi defined different relationships or \ndata transforms\
    \ between the neighborhood depth layers. The numbers of kernels were \ndesigned\
    \ based on the numbers of soil features and the amount of soil data points. If\
    \ the \nnumber of kernels is too small, it would not have enough fitting ability\
    \ to extract the \ninformation between the soil features; however, if the number\
    \ of kernels is too large, it may \n158 \n \ncause over-fitting problems. In this\
    \ paper, there were seven input features (clay10 - clay70) \nand the number of\
    \ kernels in the first layer of the S_CNN were four, which was about the \nhalf\
    \ of the number of input features. Followed was an average pooling layer that\
    \ conducted \nan average process on the outputs of the first convolution layer.\
    \ The second convolution \nlayer conducted similar process as the first convolution\
    \ layer but with eight kernels, which \nwas the twice of the first convolution\
    \ layer, followed by an average pooling layer to \ngenerate features with 1 ×\
    \ 8 dimensions. The S_CNN extracted the most significant and \nindependent parameters\
    \ from the seven soil features (clay10 - clay70) that included the \nclay content\
    \ in different depth layers as well as their relationship between layers. In \n\
    addition, four soil features of sand% (clay% were removed since linear calibration\
    \ were \nused based on the same ECa data with the sand%), FC, WP and TAW were\
    \ transformed \nusing a fully connected layer to reduce collinearity since high\
    \ Pearson correlation \ncoefficients were found between these four soil features\
    \ (Chapter 4). The fully connected \nlayer conducted another mathematical operation\
    \ of ∑\n\U0001D498\U0001D498\U0001D48A\U0001D48A × \U0001D499\U0001D499\U0001D48A\
    \U0001D48A\n\U0001D459\U0001D459\n\U0001D48A\U0001D48A=\U0001D7CF\U0001D7CF\n\
    \ where xi were inputs of \nFC, WP, TAW and sand%. \n \n159 \n \nFigure 6.1: S_CNN.\
    \ Soil clay content percentage from different depth were processed \nusing a network\
    \ with two convolution layers. Each color dot was a mathematical \noperation result\
    \ of ∑\n\U0001D498\U0001D498\U0001D48A\U0001D48A × \U0001D499\U0001D499\U0001D48A\
    \U0001D48A\n\U0001D7CF\U0001D7CF\n\U0001D48A\U0001D48A=\U0001D7CF\U0001D7CF\n\
    \ where xi were the clay content percentage of each layer \nand the wi were the\
    \ weights obtained by training from the data set provided. \nWeekly weather data\
    \ was used in this study instead of daily weather (large amount \nof data and\
    \ was shown not necessary in (Khaki and Wang, 2019) and (Khaki et al., 2020))\
    \ \ndata and monthly weather data (less amount of data and may not enough to reflect\
    \ the \nweather effects on crop development), which included accumulative input\
    \ water \n(precipitation and irrigation), maximum and minimum air temperature,\
    \ total solar radiation, \nvapor pressure and evapotranspiration of reference\
    \ crop  (Allen et al., 1998) from May 1 \nto Oct. 29 in each year of 2017 to 2019.\
    \ In the experimental area, cotton is preferred to \nplant in late May or early\
    \ June, and they develop in the months of Jul., Aug. and Sep., and \nharvest in\
    \ Oct (Goodell et al., 2015). UAV images were collected in Jul., Aug. and Sep.\
    \ to \nmonitor cotton development. Weather data were divided into four periods\
    \ to match with \nthe imagery data periods, i.e., the first 13 weeks after planting\
    \ (May 1 to Jul. 30, Period 1) \nto match with the UAV image collected in Jul.,\
    \ week 14 to week 18 (Jul. 31 to Sep. 3, \nPeriod 2) to match with the UAV image\
    \ collected in Aug., week 19-week 22 (Sep. 4 to Oct. \n1, Period 3) to match with\
    \ the UAV image collected in Sep. and week 23 to week 26 (Oct. \n2 to Oct. 29,\
    \ Period 4) to represent the period that between the last image collection and\
    \ \nharvest.  \nWeather data have temporal dependencies. For example, some weather\
    \ prediction \nmodels such as the Markov chain (Khiatani and Ghose, 2017) assumed\
    \ that temperature \nwould reduce and vapor pressure would increase dependently\
    \ if rain, and if last week was \n160 \n \nin high temperature, this week may\
    \ have a low possibility of low temperature. A weather \nconvolutional neural\
    \ network (W_CNN) was designed to extract the relationships among \nthe six weekly\
    \ weather parameters and the temporal relationships (dependencies) of the \nweekly\
    \ weather parameters in the sequential weeks. Two convolution layers were designed\
    \ \nwith four filters in each layer (color boxes in Figure 5.2). Similar to the\
    \ S_CNN, a moving \nwindow scans every three weekly weather from the first week\
    \ to the 26th week after \nplanting using kernels that provided various relationships\
    \ (non-linear fit) between weekly \nweather parameters. The output features from\
    \ the W_CNN were 1×12 matrixes with fused \ninformation of both relationship information\
    \ between six weather parameters and \nsequential weeks. \n \nFigure 6.2: The\
    \ illustration of the developed W_CNN. Weekly weather data from May 1 \nto Oct.\
    \ 29 were used. The first 13 weeks related to date from May 1 to Jul. 30, week14-\n\
    week18 related to date from Jul. 31 to Sep. 3, week19-week22 related to date from\
    \ Sep. 4 \nto Oct. 1 and week 23 to week 26 related to date from Oct. 2 to Oct.\
    \ 29. The meanings of \nthe abbreviations of the weather features are: P- total\
    \ precipitation (irrigation data was \nincluded), Tmax- max air temperature, Tmin-\
    \ min air temperature, SR- total solar radiation, \n161 \n \nVP- vapor pressure,\
    \ and ETo- evapotranspiration for reference crop. W1-W26 mean \nweek1-week26 after\
    \ planting. \n \n6.5 Yield estimation model \nA recurrent neural network (RNN)\
    \ is a type of neural networks that are designed to \nprocess a sequence of variables\
    \ (e.g., a temporal sequence) by modelling the relationship \nbetween the current\
    \ state of a variable and the previous states (recurrent) in the sequence. \n\
    It has been used to handle sequential data such as weather data and time series\
    \ image data \n(Lipton et al., 2015). Improved RNN models, such as Long Short-Term\
    \ Memory networks \n(LSTMs) or Gated Recurrent Units (GRU), enable training on\
    \ long sequences, overcoming \nproblems like vanishing gradients (Lee et al.,\
    \ 2020). Chung et al. (2014) showed that the \nGRU and LSTM almost had similar\
    \ performance on serval sequence prediction tasks, \nhowever, GRU has fewer model\
    \ parameters and easier to optimize. \nIn this study, a GRU-based RNN (Chung et\
    \ al., 2014) was used to quantify cotton \nyield based on soil, weather condition\
    \ and imagery data. The GRU continuously accepts \ninputs from a sequence and\
    \ outputs the information that describes the data transform (or \nthe weighted\
    \ combination results) of the previous inputs and the current inputs. To easily\
    \ \nunderstand the loop operation in the GUR, the GRU was drawn with the unfolded\
    \ way \n(Chen et al., 2019) in this paper, as shown in Figure 5.3a. The GRU includes\
    \ a reset gate \n(Eq. 5.1) and an update gate (Eq. 5.2) to control how much information\
    \ through the \nsequence needed to be forgotten and memorized. Then a candidate\
    \ hidden layer ℎ෨\U0001D459\U0001D459 was \ncalculated based on the \U0001D45A\
    \U0001D45A\U0001D459\U0001D459, \U0001D465\U0001D465\U0001D459\U0001D459 and ℎ\U0001D459\
    \U0001D459−1 to carry the information remained after the process \nof the reset\
    \ gate (Eq. 5.3). If the reset gate \U0001D45A\U0001D45A\U0001D459\U0001D459 were\
    \ close to 0, all the information ℎ\U0001D459\U0001D459−1 from \n162 \n \nthe\
    \ previous sequence would not carry and passed (or memorized) to the later process\
    \ of \nthe sequence. The final hidden output calculates the ratio (the updated\
    \ gate \U0001D467\U0001D467\U0001D459\U0001D459) of previous \ninputs information\
    \ ℎ\U0001D459\U0001D459−1 updated to information after the reset process  ℎ෨\U0001D459\
    \U0001D459 to calculate the \ninformation that should be passed to the later process\
    \ of the sequence (Eq. 5.4). If \U0001D467\U0001D467\U0001D459\U0001D459 were\
    \ \nclose to 1, only the information from previous layers ℎ\U0001D459\U0001D459\
    −1 and none of the current input \U0001D465\U0001D465\U0001D459\U0001D459 \nwould\
    \ be used as the input to the later process of the sequence. \n\U0001D45A\U0001D45A\
    \U0001D459\U0001D459 = \U0001D70E\U0001D70E(\U0001D436\U0001D436\U0001D45A\U0001D45A\
    \U0001D465\U0001D465\U0001D459\U0001D459 + \U0001D448\U0001D448\U0001D45A\U0001D45A\
    ℎ\U0001D459\U0001D459−1)   \n \n \n \n(5.1) \n\U0001D467\U0001D467\U0001D459\U0001D459\
    \ = \U0001D70E\U0001D70E(\U0001D436\U0001D436\U0001D467\U0001D467\U0001D465\U0001D465\
    \U0001D459\U0001D459 + \U0001D448\U0001D448\U0001D467\U0001D467ℎ\U0001D459\U0001D459\
    −1) \n \n \n \n(5.2) \nℎ෨\U0001D459\U0001D459 = \U0001D459\U0001D459\U0001D44E\
    \U0001D44E\U0001D459\U0001D459ℎ(\U0001D436\U0001D436\U0001D465\U0001D465\U0001D459\
    \U0001D459 + \U0001D45A\U0001D45A\U0001D459\U0001D459 ∗ \U0001D448\U0001D448ℎ\U0001D459\
    \U0001D459−1) \n \n \n(5.3) \nℎ\U0001D459\U0001D459 = (1 − \U0001D467\U0001D467\
    \U0001D459\U0001D459) ∗ ℎ෨\U0001D459\U0001D459 + \U0001D467\U0001D467\U0001D459\
    \U0001D459 ∗ ℎ\U0001D459\U0001D459−1 \n \n \n(5.4) \nwhere, \U0001D45A\U0001D45A\
    \U0001D459\U0001D459, \U0001D467\U0001D467\U0001D459\U0001D459 and ℎ෨\U0001D459\
    \U0001D459 are the reset gate, update gate and candidate hidden layer; ℎ\U0001D459\
    \U0001D459 is the \nhidden layer with the information passed to the next layer;\
    \ \U0001D465\U0001D465\U0001D459\U0001D459 is the current input of a \nsequence\
    \ for the GRU and ℎ\U0001D459\U0001D459−1 is the information from the last layer;\
    \ \U0001D436\U0001D436\U0001D45A\U0001D45A,  \U0001D436\U0001D436\U0001D467\U0001D467\
    , \U0001D436\U0001D436, \U0001D448\U0001D448\U0001D45A\U0001D45A, \U0001D448\U0001D448\
    \U0001D467\U0001D467 \nand \U0001D448\U0001D448 are parameters to be trained from\
    \ the training data set; and \U0001D70E\U0001D70E  is the sigmoid function \n\
    and * is the Hadamard product.  \n \nFigure 6.3: The explanation of GRU. (a) GRU\
    \ continuously accepts inputs from a \nsequence. To easily understand the loop\
    \ operation in the GUR, the GRU was drawn with \n163 \n \nthe unfolded way in\
    \ this paper. The ‘t’ represented each time step. (b) The architecture of \nGRU\
    \ related to Eq. 5.1-5.44. \n \nThe architecture of the GRU-based RNN is shown\
    \ in Figure 5. 4 that included four \nlayers, i.e., S_CNN, W_CNN, GRU layers for\
    \ NDVI prediction (‘GRU’ in Figure 5. 4) and \nthe fully connected layers for\
    \ yield prediction (‘FCL2’ in Figure 5. 4). The input parameters \nof the GRU\
    \ network included the 11 soil features processed by the S_CNN and weather \n\
    data from May 1 to Jul. 30 processed by the W_CNN. The initially hidden input\
    \ vector \n(‘Init’ in Figure 5. 4) of the GRU was set as zeros and the corresponding\
    \ output was \nassumed to be the NDVI in July (the GRU output of its first loop).\
    \ The hidden outputs of \nthe July GRU would be passed to the next loop of the\
    \ GRU unit (i.e. the Aug. GRU). The \nprocessed weather data from Jul. 31 to Sep.\
    \ 3 would be passed to the Aug. GRU and its \noutput was assumed to be the NDVI\
    \ in Aug. The NDVI in Jul. would be used to replace \nthe ‘Init’ to input to the\
    \ Aug. GRU. Similar procedures were conducted to the GRU of Sep. \nand yield.\
    \ The GRU unit was a loop processing unit that continued to accept the three-\n\
    month weather data and the previous month’s NDVI images. The GRU can predict the\
    \ \nNDVI distribution of the current month based on the current month’s weather\
    \ and the \nprevious month’s NDVI. \n164 \n \n \nFigure 6.4: The architecture\
    \ of the GRU network. SL means sequence length, which was \nset as 1 in this study.\
    \ BZ is the batch size for the training procedure. FCL means fully \nconnected\
    \ layer, which conducted another mathematical operation of ∑\n\U0001D498\U0001D498\
    \U0001D48A\U0001D48A × \U0001D499\U0001D499\U0001D48A\U0001D48A\n\U0001D48F\U0001D48F\
    \n\U0001D48A\U0001D48A=\U0001D7CF\U0001D7CF\n. The \nyellow GRU was the same loop\
    \ processing unit in the network and has the same \nparameters, as well as all\
    \ the green FCL_1 unit. \nAlthough the GRU has the memory of short-term information\
    \ and can pass the \ncondensed information to the next timestamp, there is still\
    \ information loss and not all \ninformation that is able to be used after the\
    \ previous process of the GRU. Therefore, the \nprocessed soil features that were\
    \ important to the yield prediction were directly connected \nto the fully connected\
    \ yield prediction layer (‘FCL_2’ in Figure 5. 4) to avoid information \nloss\
    \ through the whole GRU process. These processed soil features would combine with\
    \ \nthe final output of the GRU and the NDVI in Jul., Aug. and Sep. together to\
    \ have the final \nyield prediction after the FCL_2 layer. The NDVI values from\
    \ images and yield were used \nas the true labels to train the overall network\
    \ and the loss function was defined in Eq. 5.5: \n165 \n \n\U0001D43F\U0001D43F\
    \ = |\U0001D466\U0001D466ො − \U0001D466\U0001D466| + ห\U0001D441\U0001D441\U0001D43D\
    \U0001D43D\n෢ − \U0001D441\U0001D441\U0001D43D\U0001D43Dห + ห\U0001D441\U0001D441\
    \U0001D434\U0001D434\n෢ − \U0001D441\U0001D441\U0001D434\U0001D434ห + ห\U0001D441\
    \U0001D441\U0001D43A\U0001D43A\n෢ − \U0001D441\U0001D441\U0001D43A\U0001D43Aห\
    \                          (5.5) \nwhere, L is the loss, \U0001D466\U0001D466\
    ො is the predicted yield (normalized values), y is the true yield \n(normalized\
    \ values),  \U0001D441\U0001D441\U0001D43D\U0001D43D\n෢, \U0001D441\U0001D441\U0001D434\
    \U0001D434\n෢ and \U0001D441\U0001D441\U0001D43A\U0001D43A\n෢ are the predicted\
    \ NDVI of the Jul., Aug. and Sep. \nrespectively, and \U0001D441\U0001D441\U0001D43D\
    \U0001D43D, \U0001D441\U0001D441\U0001D434\U0001D434 and \U0001D441\U0001D441\U0001D43A\
    \U0001D43A are the true NDVI of the Jul., Aug. and Sep.  \nHowever, the selected\
    \ deep learning network is a long training network and some \ninformation cannot\
    \ be passed to the subsequent layers, which makes it hard to train using \nthe\
    \ overall ground true corresponded with the global loss function. Therefore, a\
    \ Teacher \nForcing (TF) technology (Williams and Zipser, 1989) was conducted\
    \ to improve the \nparameter optimizing, which used the NDVI of Jul., Aug. and\
    \ Sep. from the imagery data \nto train the individual month’s GRU. To avoid yield\
    \ overfitting of the image NDVI, the TF \nconducts with a given possibility (for\
    \ example, 0.5-0.9; TF=1 means true NDVI will \nalways be used, while TF=0 means\
    \ the predicted NDVI will always be used) in the training \nprocedure, which means\
    \ the model had the possibility to learn yield variability from the \nsoil, weather\
    \ and the predicted NDVI (instead of relying the most on the collected image \n\
    data and ignoring the soil and weather features). Image NDVI (not predicted NDVI)\
    \ would \nalways be used in the testing procedure. \n  \nThe best hyperparameters\
    \ of the learning rate, training batch size, momentum of \nthe stochastic gradient\
    \ descent (SGD) optimizer and the TF possibility were obtained by \nthe Bayesian\
    \ optimization procedure with an open-source constrained global optimization \n\
    tool (Nogueira, 2014). All input data of the model were normalized using Eq. 5.6\
    \ before \nthey were used in the model. \n\U0001D441\U0001D441\U0001D465\U0001D465\
    \ =\n\U0001D465\U0001D465−\U0001D45A\U0001D45A\n\U0001D460\U0001D460\U0001D459\
    \U0001D459\U0001D451\U0001D451                                   (5.6) \n166 \n\
    \ \nwhere Nx is the normalized value, m and std are the mean and standard deviation\
    \ of the \ntraining set, and x is the original data. \nThere are five important\
    \ components in the GRU-based RNN network, including \nthe direct connection between\
    \ processed soil and the yield fully connected layer (FCL_2 \nin Figure 5. 4),\
    \ S_CNN, W_CNN, GRU and NDVI images. To test the importance of each \ncomponent\
    \ on the GRU-based RNN, different models without (WO_) one of each \ncomponent\
    \ were tested, as shown in Table 5.1. Firstly, the components of NDVI would be\
    \ \nremoved from the original model from the test procedure and then from the\
    \ training \nprocedure by setting the TF to 0 (WO_TF_Test and WO_TF_Train in Table\
    \ 5.1). S_CNN \nwould be removed and used a fully connected layer instead to process\
    \ the raw soil features \n(WO_S_CNN in Table 5.1). W_CNN would be removed and\
    \ used the average weekly \nweather as the inputs instead (WO_W_CNN in Table 5.1).\
    \ The direct connection between \nsoil and the FCL_2 would be removed in WO_S2Y\
    \ in Table 5.1. All the data used in the \noriginal GRU-based RNN network would\
    \ be used in the above five models. However, \nwhen GRU units were removed, an\
    \ ensemble module XGBoost (Chen and Guestrin, 2016) \nwas used to replace the\
    \ GRU for yield prediction and due to the requirement of fix \ndimension for the\
    \ inputs of XGBoost, only August NDVI, soil and weather would be used \nin the\
    \ WO _GRU as there were some missing image data in July and September in 2017\
    \ \nand 2019. WO_GRU_NDVI would remove the GRU and NDVI in the original model,\
    \ \nwhile WO_GRU_NDVI_W would only predict the yield by soil data and the XGBoost.\
    \ \nTable 6.1: Yield prediction models with the removal of the five important\
    \ components  \nModels \nDescription \n167 \n \nWO_TF_Test \nSet teacher forcing\
    \ as 0 in the test procedure, which meant that the true \nNDVI would not be used\
    \ as the input of the GRU. The overall model \nrelied on soil, weather and the\
    \ predicted NDVI. This aimed to test the \nimportance of the UAV NDVI images for\
    \ yield prediction. \nWO_TF_Train \nSet teacher forcing as 0 in both train and\
    \ test procedure. There was only \nyield data and no image data to guide the model\
    \ to optimize the GRU \nparameters in the training procedure. This aimed to test\
    \ the importance of \nthe UAV NDVI images in the training procedure for the parameter\
    \ \noptimization guide. \nWO_S_CNN \nRemove the S_CNN and use a fully connected\
    \ layer instead. This aimed to \ntest the importance of the S_CNN. \nWO_W_CNN\
    \ \nRemove the W_CNN and instead use the mean weather parameters as the \ninput.\
    \ This aimed to test the importance of the W_CNN. \nWO_S2Y \nRemove the connection\
    \ between the processed soil features and the FC_2 \nlayer. This aimed to test\
    \ if soil information would be lost through the \nwhole GRU procedure.  \nWO _GRU\
    \ \nUse an XGBoost model instead of a GRU model and the inputs of soil \nfeatures,\
    \ mean weather parameters and NDVI images for yield prediction. \nThis aimed to\
    \ test the importance of the GRU unit. Only soil, weather and \nAugust NDVI would\
    \ be used. \nWO_GRU_NDVI \nUse an XGBoost model and the inputs of soil features\
    \ and mean weather \nparameters for yield prediction. This aimed to test the importance\
    \ of the \nUAV NDVI images.  \nWO_GRU_NDVI_W \nUse an XGBoost model and only soil\
    \ features for yield prediction. This \naimed to test the importance of the UAV\
    \ NDVI images and the weather \ndata. \n \n6.6 Yield prediction accuracy \n6.6.1\
    \ Correlation between yield with soil features and image features \nPearson correlation\
    \ coefficients (r) between yield with soil features are shown in \nTable 5.2.\
    \ As can be seen in Table 5.2, the correlation between yield and soil features\
    \ in \neach year was about 0.5-0.7, except for the topsoil clay10 and clay20 that\
    \ had a lower \ncorrelation. Cotton yields in all three years had a higher correlation\
    \ with clay content in the \ndepth between 40 – 70 cm, i.e., clay40 – lay70 than\
    \ those in shallower layers, which may \nbe due to the less water content in the\
    \ shallow soil and higher water-use effeteness of deeper \nroots (Djaman and Irmak,\
    \ 2012). The r in clay40 -clay70 with yield is very close to each \nother as the\
    \ r between clay40 – clay 70 were over 0.92 (Chapter 5.6.2). Table 5.2 also \n\
    168 \n \nshows that the soil features derived from soil texture, including sand%\
    \ in the top 0-34 cm, \nWP, FC and TAW were about 0.5 and did not show strong\
    \ correlations with yield.  \nTable 6.2: Pearson correlation coefficients (r)\
    \ between yield and soil features. \nYield \nsand% \nclay10 \nclay20 \nclay30\
    \ \nclay40 \nclay50 \nclay60 \nclay70 \nWP \nFC \nTAW \n2017E§ \n-0.45 \n0.2 \n\
    0.37 \n0.5 \n0.52 \n0.51 \n0.51 \n0.51 \n0.49 \n0.49 \n0.48 \n2018W \n-0.51 \n\
    0.27 \n0.46 \n0.56 \n0.58 \n0.58 \n0.57 \n0.58 \n0.57 \n0.55 \n0.52 \n2019E \n\
    -0.55 \n0.23 \n0.46 \n0.64 \n0.67 \n0.69 \n0.69 \n0.69 \n0.58 \n0.57 \n0.55 \n\
    2019W \n-0.5 \n0.19 \n0.42 \n0.58 \n0.61 \n0.63 \n0.63 \n0.64 \n0.59 \n0.55 \n\
    0.53 \n§: ‘W’ represents the west side of the field, while ‘E’ represents the\
    \ east side of the field. \n \nSoil features did not explain all the variability\
    \ of the yield in the three years in this \nstudy. As shown in Figure 5.5, histograms\
    \ of the cotton yield of the same fields, whose soil \ntexture had not had substantial\
    \ changes in the three years, showed different distribution in \n2017-2019. In\
    \ addition, Figure 5.6 shows the fitness of the cotton yield in each same \nposition\
    \ at different years, i.e., data points in 2017E vs. 2019E, and 2018W vs. 2019W,\
    \ as \nwell as the average yield in different sand% groups of these three years.\
    \ The variance of \ncotton yield was MAE = 627 kg ha-1 (equivalent 27.0% to the\
    \ Yield2017E) between the \nyear 2017 and 2019 in the east field, and MAE = 662\
    \ kg ha-1 (equivalent 20.0% to the \nYield2018W) between the year 2018 and 2019\
    \ in the west field. Yield variation between \nyears in the same positions (assumed\
    \ same soil texture) may be due to the different weather \nconditions and field\
    \ management (irrigation in this case). \n169 \n \n \nFigure 6.5: Yield data distributions\
    \ in 2017E, 2018W, 2019E and 2019W. KDE: kernel \ndensity estimation. \n \n \n\
    Figure 6.6: Yield comparison of different years in the same positions as well\
    \ as the \naverage yield in different sand% groups of these three years. (a) Comparing\
    \ the yield in \n2017 and 2019 in the east side of the field; (b) comparing the\
    \ yield in 2018 and 2019 in \n170 \n \nthe west side of the field; (c) yield difference\
    \ between 2017E and 2019E in different \nsand% groups; (d) yield difference between\
    \ 2018W and 2019W in different sand% \ngroups. Different lower-case letters indicate\
    \ a significant difference at the 5% level of \nTukey’s Honest significant difference\
    \ test with ‘a’ the largest mean yield and ‘d’ the \nsmallest mean yield. \nNDVI\
    \ in August of 2017E and 2019E was highly correlated to yield, as shown in \n\
    Table 5.3. The correlation between NDVI and yield in Aug. and July of the 2018W\
    \ were \nclose (i.e., 0.65 and 0.69). Figure 5.7 shows the relationships between\
    \ NDVI and yield in \ndifferent years in the east side of the field, where the\
    \ soil texture was considered the same \nwithin two years. The relationship between\
    \ NDVI and yield was quadratic in 2019 but a \nlinear relationship in 2017. If\
    \ predicting the yield in 2019 only based on image NDVI \ncollected in 2019 and\
    \ the linear function fitted using NDVI and yield data collected in 2017, \nR2=0.31\
    \ was obtained. The NDVI collected in 2019 may face the saturation problem \n\
    though the 16-bit multispectral camera was used. Even though there was no difference\
    \ in \nquadratic and linear relationships, coefficients of the formula may still\
    \ be different in a \ndifferent year. The NDVI had a high correlation with yield\
    \ in 2017 and 2019, but predicting \nyield in different years only based on a\
    \ model build with the previous year’s image NDVI \nand yield may not be accurate.\
    \ \nTable 6.3: Pearson correlation coefficients (r) between yield and image NDVI\
    \ \nrespectively \nYield \nJul. NDVI \nAug. NDVI \nSep. NDVI \n2017E \n-- \n0.81\
    \ \n-- \n2018W \n0.69 \n0.65 \n0.12 \n2019E \n0.6 \n0.9 \n0.79 \n \n171 \n \n\
    \ \nFigure 6.7: Relationships between NDVI and yield in different years: (a) quadratic\
    \ \nrelationship between NDVI collected in Aug. 2019 and yield in 2019; (b) relationship\
    \ \nbetween NDVI collected in Aug. 2017 with yield was more likely be a linear\
    \ relationship. \nTo avoid the effects of different multispectral sensors, all\
    \ the NDVI and yield were \nnormalized as (x-mean)/std. \nIn summary, the low\
    \ correlation between soil features with yield (Table 5.3 and \nFigure 5.6) and\
    \ the unstable relationship between NDVI and yield in different yield (Figure\
    \ \n5.7) show that combining soil, weather and NDVI together for yield prediction\
    \ in a \ndifferent year is necessary. \n6.6.2 Yield prediction based on soil,\
    \ weather and UAV images \nFour tests were conducted with each selected one of\
    \ the years’ data as the testing \nset and the others as the training set to evaluate\
    \ the performance of the proposed model \nstructure for yield prediction in an\
    \ additional year.  Soil features, weather conditions and \nimage data of the\
    \ training set were used as the inputs and the true yield data of the training\
    \ \nset were used as the targets to train the GRU-based RNN network.  After model\
    \ training, \nsoil features, weather conditions and image data of the testing\
    \ set were used as the inputs \nfor the trained model to predict the yield of\
    \ the testing year and compared with the true \n172 \n \nyield in the testing\
    \ set. There were 38*63= 2394 data points per year. If used two years of \ndata\
    \ for training, there would be 2394*2=4788, and the other year for testing is\
    \ 2394. We \nhad 4788+2934=7722 in total for each one test in Figure 5.8. In Figure\
    \ 5.8a, the model was \ntrained using the soil, weather and NDVI images in Jul.\
    \ Aug. and Sep. of 2018W and 2019E, \nand predicted the yield of 2017E with the\
    \ inputs of soil, weather and the NDVI in Jul. 2017. \nFigure 5.8b shows the yield\
    \ prediction result of 2018W with the predictors of soil, weather \nand NDVI of\
    \ 2018W and the model trained with soil, weather and NDVI of 2019E and \n2017E.\
    \ MAE=345 kg ha-1 (12.3%) and R2=0.72 for 2017E as well as MAE=384 kg ha-1 \n\
    (13.7%) and R2=0.67 of 2018W were obtained. Figure 5.8c shows the result of 2019E\
    \ with \nthe predictors of soil, weather and NDVI of 2019E based on the model\
    \ that trained with \nsoil, weather and NDVI of 2018W and 2017E, while Figure\
    \ 5.8d shows the yield prediction \nresult of 2019W with the predictors of soil\
    \ and weather of 2019W but not have NDVI \nimages available in 2019W based on\
    \ the GRU network trained using the soil, weather and \nNDVI of 2018W and 2017E.\
    \ MAE=247 kg ha-1 (8.9%) and R2= for 2019E as well as \nMAE=355 kg ha-1 (10.8%)\
    \ and R2=0.60 of 2019W were obtained. Those MAE were lower \nthan the MAE shown\
    \ in Figure 5.6 (only relied on soil) and R2 were higher than that in \nFigure\
    \ 5.7 (only relied on image NDVI), which indicate that combining soil, weather\
    \ and \nimage NDVI as the predictors could potentially predict yield using model\
    \ that training with \nprevious years’ soil, weather and NDVI.  \n173 \n \n \n\
    Figure 6.8: Yield prediction results. (a) The data set of 2019E and 2018W were\
    \ used for \ntraining to predict the yield in 2017E; (b) The data set of 2019E,\
    \ 2019W and 2017E were \nused for training to predict the yield in 2018W; (c)\
    \ The data set of 2019W, 2018W and \n2017E were used for training to predict the\
    \ yield in 2019E; (d) The data set of 2019E, \n2018W and 2017E were used for training\
    \ to predict the yield in 2019W. Note, no image \nNDVI was available in 2019W\
    \ and the result in (d) is equal to the result of WO_TF_test. \nThe prediction\
    \ results in Figure 5.8 that obtained from the proposed model can be \nused as\
    \ a reference to compare with the models that excluded each of the components\
    \ of \nS_CNN, W_CNN, a direct connection between soil and FCL_2 layer, GRU unit\
    \ and image \nNDVI  (set by changing the TF) (Table 5.1), as shown in Figure 5.9.\
    \ Overall, models \nremoving those components had higher MAE and lower R2 compared\
    \ with the original \nmodel. It is worth noting that the removal of W_CNN obtained\
    \ the worst performance \n174 \n \n(about 150-250 kg ha-1 MAE increased compared\
    \ to the original model) in all the years’ \nyield prediction. There was about\
    \ 150-220 kg ha-1 MAE increased of the WO_TF_Test and \nWO_TF_Train models compared\
    \ to the original model, which indicated that NDVI played \nan important role\
    \ in the yield prediction. The models without S_CNN had about 20-120 kg \nha-1\
    \ MAE increased. The models without connection between the soil features and the\
    \ \nFCL_2 layer showed 20-130 kg ha-1 MAE increased, indicating that there was\
    \ some soil \ninformation loss through the GRU loop process. There was about 100\
    \ kg ha-1 MAE \nincreased for the models without GRU units. Removing the NDVI\
    \ from those XGBoost \nmodels showed more performance drop, as well as the weather\
    \ data. This indicates that \nNDVI and weather data were important even using\
    \ a non-time series model. \n \nFigure 6.9: Yield prediction performance of models\
    \ that excluded each of the components \nof  S_CNN, W_CNN, GRU unit, image NDVI\
    \ and TF described in Table 7. (a) The \nMAE and R2 of WO_S_CNN, WO_W_CNN, WO_TF_Test\
    \ and WO_TF_Train; (b) \n175 \n \nMAE and R2 of  WO_S2Y, WO _GRU, WO_GRU_NDVI\
    \ and WO_GRU_NDVI_W. \nNote, no image NDVI was available in 2019W. \nSince there\
    \ were 7 clay input features in the S_CNN, the yield prediction \nperformance\
    \ of kernel numbers of 2, 4, 8 in the first layer and of 2, 4, 8, 16 in the second\
    \ \nlayer were compared, as well as the kernel numbers of 4, 8, 16 in the first\
    \ layer and of 8, \n12, 16 in the second layer of the W_CNN. The numbers of kernels\
    \ changes did not affect \nthe yield prediction performance in 2017E and 2019E\
    \ too much (about 20-50 kg ha-1 MAE \nincreased and 0.01-0.03 R2 dropped). This\
    \ may due to the NDVI in 2017E and 2019E had \na high correlation with yield and\
    \ the yield prediction can get information from the NDVI. \nThere were about 30-80\
    \ kg ha-1 MAE increased and 0.12-0.2 R2 dropped for the 2018W \nwhen kernel numbers\
    \ changed, which was the one that had the largest effects. There was \nabout 20-60\
    \ kg ha-1 MAE increased and 0.1 R2 dropped for the 2019W. \n \nFigure 6.10: Yield\
    \ prediction performance of models with different kernel numbers in \nS_CNN and\
    \ W_CNN. \n176 \n \n6.6.3 The crop growth and yield maps \nThe monthly NDVI can\
    \ be used to trace the crop development through the growing \nseason. Figure 5.11\
    \ shows the NDVI and yield maps of the east field in 2017 and 2019. \nOnly NDVI\
    \ in Aug. of 2017 was available, and only 2/3 field’s NDVI in Sep. 2019 was \n\
    available due to a camera problem. The predicted NDVI from the GRU network in\
    \ Jul. and \nSep in 2017 and the other 1/3 field’s in Sep. 2019 were used as the\
    \ alternative in Figure \n5.11. Tough the soil texture was considered the same\
    \ between these two years, crop yield \ndistribution shows a difference in some\
    \ regions. The black circles in the yield maps mark \nthe regions that having\
    \ more yield in 2019, while the pink circles mark the regions that \nhaving more\
    \ yield in 2017. The predicted yield of 2017E and 2019E captured most of the \n\
    true yield variance, as well as those yield difference between these two years.\
    \ Irrigation \nwas applied in late July and in Aug. 2017 in the pink circle region,\
    \ while there was no \nirrigation in 2019. NDVI in the pink circle region in July\
    \ of 2019 was high.  The amount \nof rainfall was small from the middle of July\
    \ to the late of Aug. in 2019, and the temperature \nin 2019 in these days was\
    \ higher than that in 2017 (Figure 2.3). The soil in this pink circle \nregion\
    \ had about 40%-50% sand content. Those may be the reasons that NDVI were drop\
    \ \nin the pink circle region in Aug. and Sep. in 2019. However, the rainfall\
    \ amount in June \nand early July in 2019 were higher than that in 2017, and this\
    \ may be the reason for the \nhigh clay content region (the black circles) having\
    \ a higher yield than that in 2017. \n177 \n \n \nFigure 6.11:  The NDVI and yield\
    \ of (a) 2017E and (b) 2019E. The multispectral camera \nin Sep. 2019 had some\
    \ problems and the data of the right side of the field were lost (the \nNDVI in\
    \ the right of the white line was the predicted NDVI from the GRU network). The\
    \ \nblack circles make the regions that had more yield in 2019 while the pink\
    \ circles mark the \nregions that had more yield in 2017. The white circles mark\
    \ the regions of how NDVI \nchanged from July to Sep. of the yield difference\
    \ regions between 2017 and 2019. All the \nNDVI were normalized and the absolute\
    \ values did not have physical meanings. The \nlegend of NDVI was the same in\
    \ all the NDVI maps. The legend of yield was the same in \nall the yield maps.\
    \ I: irrigation applied \nThe rainfall amount before the middle of Aug. was low\
    \ in 2018, and this may be \nthe reason that most of the region in 2018 having\
    \ a lower yield than the same position in \n2019, especially in the black circle\
    \ regions in the yield maps that having 55%-75% sand \ncontent. For the year that\
    \ had higher rainfall amount (i.e., 2019 compared with 2018 and \n2017), yield\
    \ distribution patterns were more similar with the soil texture pattern and the\
    \ \n178 \n \ncorrelation between yield and soil features were higher (Yield2019E\
    \ and Yield2019W had \nthe highest Pearson correlation with clay30- clay70, FC,\
    \ WP and TAW in Table 5.2). There \nwas no NDVI available in 2019W, the predicted\
    \ NDVI were showing in Figure 5.12, which \nprovided an alternative way to observe\
    \ the crop growth changes during the season. \n \nFigure 6.12: The NDVI and yield\
    \ of (a)2018W and (b) 2019W. The black circles make \nthe regions that having\
    \ more yield in 2019 than in 2018. All the NDVI were normalized \nand the absolute\
    \ values did not have physical meanings. The legend of NDVI was the \nsame in\
    \ all the NDVI maps. The legend of yield was the same in all the yield maps. S:\
    \ \nregions with 55%-75% sand content. \n6.7 Conclusion \nThis paper quantified\
    \ yield variation based on soil texture, weather conditions and \nUAV imagery\
    \ collected in three different years of 2017-2019. Eleven soil features (sand\
    \ \ncontent percentage, wilting point, field capacity, total available water,\
    \ and clay content \npercentage in 7 different depth layers) and six weekly weather\
    \ data (total precipitation, \n179 \n \nmax air temperature, min air temperature,\
    \ total solar radiation, vapor pressure and \nevapotranspiration for reference\
    \ crop) were processed in an S_CNN and a W_CNN. A \nGRU-based RNN network was\
    \ trained using the processed soil features and weather \nfeatures, as well as\
    \ the UAV image NDVI and yield as ground true labels. Then the trained \nmodels\
    \ were used for yield prediction in an additional year. MAE = 247 (8.9%) to 384\
    \ kg \nha-1 (13.7%) were obtained for yield prediction of 2017-2019. The S_CNN,\
    \ W_CNN, \ndirect connection between soil with the final yield prediction layer,\
    \ UAV-based NDVI, \nweather data and the GRU unit were showed important for the\
    \ high accuracy yield \nprediction. Results showed that quantified yield variation\
    \ based on soil texture, weather \nconditions and UAV imagery for a future year\
    \ was feasible. \n6.8 Future work \nFor the crop growth quantification study in\
    \ Chapter 5.6.5, we tried to answer if the \nweather data more important to the\
    \ crop growth or the soil data more important in the year \n2018 and 2019 respectively.\
    \ In this Chapter of the yield prediction study, I haven’t figure \nout this question\
    \ of how a specific input feature (soil or weather features) affected the final\
    \ \nyield variation. One reason is that deep learning models though have high\
    \ prediction ability \nbut usually work like a ‘black box’ and have low explanation\
    \ ability. For my current \nprediction model, I haven’t found out a better way\
    \ to explain how the input features affect \nthe final yield prediction. Another\
    \ reason is that I had a limited data set. I only had three \nyears of data from\
    \ 2017-2019. The current model had the function for crop growth \nprediction monthly.\
    \ But the growth prediction currently did not have high accuracy. Even \nthough\
    \ we collected image data in the middle of each month, the crop growth stage at\
    \ the \nsame time of different yield was different due to the weather variation.\
    \ I did not have higher \n180 \n \ntemporal resolution image data now. I may need\
    \ more data especially more high temporal \nimage data to track the crop growth\
    \ to answer this question. Also, collecting the image data \nbefore or after irrigation\
    \ is a good way to understand the soil and water effects on crop \ndevelopment.\
    \ \nIn this Chapter, previous years’ data were used for model training. When predicted\
    \ \na future year, all the data for the future year such as soil, weather and\
    \ image data were used. \nThe cut-off date of the image data was the date we collected\
    \ images. The cut-off date of \nthe weather data was the end of October.  It may\
    \ be better to use part of the weather data \nsuch as weather data up to August\
    \ or September rather than using all the weather data in \nthe whole growth season\
    \ since farmers would like to know the yield earlier than waiting \nfor the whole\
    \ growth season at the harvest time. There are publications (Khaki and Wang, \n\
    2019; Khaki et al., 2020) that working for a future yield prediction, and they\
    \ added the \nweather prediction function in their models. Future weather prediction\
    \ or other methods \nare needed if not the whole growth season weather data are\
    \ included in the yield prediction \nmodel. \nI mixed the west field east field\
    \ and different years in the four tests because of the \nlimited amount of the\
    \ data set. For example, in the west field, I only had two years’ data, \n2018\
    \ and 2019, and therefore I cannot have more than one year’s data for training\
    \ as I need \nan additional year’s data for testing. The same situation happened\
    \ to the east field, I only \nhad two years’ data 2017 and 2019. If more data\
    \ will be collected in the future, separating \nthe field for different years’\
    \ tests (such as using the left half of the west field data of 2018-\n2019 for\
    \ training and using the right half of the west field data of 2020 for testing)\
    \ is a \ngood way to try. \n181 \n \nWeekly weather data was used instead of daily\
    \ weather (large amount of data and \nwas shown not necessary in (Khaki and Wang,\
    \ 2019) and (Khaki et al., 2020)) data and \nmonthly weather data (less amount\
    \ of data and may not enough to reflect the weather \neffects on crop development).\
    \ However, a test to tell is which is the best to use (daily \nweather data or\
    \ weekly weather data or monthly weather data) for yield prediction is worth \n\
    conducting. \nI tried to use the cotton boll as one of the image data for yield\
    \ prediction before. \nBut at that time, the UAV flew too high, and the cotton\
    \ bolls cannot be seen clearly. \nAnother difficulty for using the cotton bolls\
    \ is that the image collected before harvest is \nhard to stitch together due\
    \ to no plant leaves and fewer image features for stitching. the \ngrowing degree\
    \ days (GDD) as one of the weather data is worth trying in the yield \nprediction\
    \ model. \n6.9 Literature cited \nAddy, J.W., Ellis, R.H., Macdonald, A.J., Semenov,\
    \ M.A., Mead, A., 2020. Investigating \nthe effects of inter-annual weather variation\
    \ (1968–2016) on the functional \nresponse of cereal grain yield to applied nitrogen,\
    \ using data from the Rothamsted \nLong-Term Experiments. Agricultural and Forest\
    \ Meteorology 284, 107898. \nAllen, R., Pereira, L., Raes, D., Smith, M., 1998.\
    \ Crop evapotranspiration-Guidelines for \ncomputing crop water requirements-FAO\
    \ Irrigation and drainage paper 56. Fao, \nRome 300, D05109. \nBian, J., Zhang,\
    \ Z., Chen, J., Chen, H., Cui, C., Li, X., Chen, S., Fu, Q., 2019. Simplified\
    \ \nEvaluation of Cotton Water Stress Using High Resolution Unmanned Aerial \n\
    Vehicle Thermal Imagery. Remote Sensing 11, 267. \n182 \n \nCeglar, A., Toreti,\
    \ A., Lecerf, R., Van der Velde, M., Dentener, F., 2016. Impact of \nmeteorological\
    \ drivers on regional inter-annual crop yield variability in France. \nAgricultural\
    \ and forest meteorology 216, 58-67. \nChen, J., Jing, H., Chang, Y., Liu, Q.,\
    \ 2019. Gated recurrent unit based recurrent neural \nnetwork for remaining useful\
    \ life prediction of nonlinear deterioration process. \nReliability Engineering\
    \ & System Safety 185, 372-382. \nChen, R., Chu, T., Landivar, J.A., Yang, C.,\
    \ Maeda, M.M., 2018. Monitoring cotton \n(Gossypium hirsutum L.) germination using\
    \ ultrahigh-resolution UAS images. \nPrecision Agriculture 19, 161-177. \nChen,\
    \ T., Guestrin, C., 2016. Xgboost: A scalable tree boosting system, Proceedings\
    \ of \nthe 22nd acm sigkdd international conference on knowledge discovery and\
    \ data \nmining, pp. 785-794. \nChu, Z., Yu, J., 2020. An end-to-end model for\
    \ rice yield prediction using deep learning \nfusion. Computers and Electronics\
    \ in Agriculture 174, 105471. \nChung, J., Gulcehre, C., Cho, K., Bengio, Y.,\
    \ 2014. Empirical evaluation of gated \nrecurrent neural networks on sequence\
    \ modeling. arXiv preprint arXiv:1412.3555. \nDjaman, K., Irmak, S., 2012. Soil\
    \ water extraction patterns and crop, irrigation, and \nevapotranspiration water\
    \ use efficiency of maize under full and limited irrigation \nand rainfed settings.\
    \ Transactions of the ASABE 55, 1223-1238. \nDu, M., Noguchi, N., 2017. Monitoring\
    \ of wheat growth status and mapping of wheat \nyield’s within-field spatial variations\
    \ using color images acquired from UAV-\ncamera system. Remote Sensing 9, 289.\
    \ \n183 \n \nFeng, A., Zhang, M., Sudduth, K.A., Vories, E.D., Zhou, J., 2019.\
    \ Cotton yield \nestimation from UAV-based plant height. Transactions of the ASABE\
    \ 62, 393-\n404. \nFeng, A., Zhou, J., Vories, E., Sudduth, K.A., 2020a. Evaluation\
    \ of cotton emergence \nusing UAV-based narrow-band spectral imagery with customized\
    \ image \nalignment and stitching algorithms. Remote Sensing 12, 1764. \nFeng,\
    \ A., Zhou, J., Vories, E.D., Sudduth, K.A., Zhang, M., 2020b. Yield estimation\
    \ in \ncotton using UAV-based multi-sensor imagery. Biosystems Engineering 193,\
    \ \n101-114. \nForcella, F., Arnold, R.L.B., Sanchez, R., Ghersa, C.M., 2000.\
    \ Modeling seedling \nemergence. Field Crops Research 67, 123-139. \nGoodell,\
    \ P.B., Davis, R.M., Godfrey, L.D., Hutmacher, R.B., Roberts, P.A., Wright, \n\
    S.D., M, B.V., Haviland, D.R., Munier, D.J., Natwick, E.T., 2015. UC IPM pest\
    \ \nmanagement guidelines cotton, Oakland, CA. \nJiang, P., Thelen, K., 2004.\
    \ Effect of soil and topographic properties on crop yield in a \nnorth-central\
    \ corn–soybean cropping system. Agronomy Journal 96, 252-258. \nKhaki, S., Wang,\
    \ L., 2019. Crop Yield Prediction Using Deep Neural Networks. \nFrontiers in Plant\
    \ Science 10. \nKhaki, S., Wang, L., Archontoulis, S.V., 2020. A cnn-rnn framework\
    \ for crop yield \nprediction. Frontiers in Plant Science 10, 1750. \nKhiatani,\
    \ D., Ghose, U., 2017. Weather forecasting using hidden Markov model, 2017 \n\
    International Conference on Computing and Communication Technologies for \nSmart\
    \ Nation (IC3TSN). IEEE, pp. 220-225. \n184 \n \nKitchen, N., Drummond, S., Lund,\
    \ E., Sudduth, K., Buchleiter, G., 2003. Soil electrical \nconductivity and topography\
    \ related to yield for three contrasting soil–crop \nsystems. Agronomy Journal\
    \ 95, 483-495. \nKitchen, N., Sudduth, K., Myers, D., Drummond, S., Hong, S.,\
    \ 2005. Delineating \nproductivity zones on claypan soil fields using apparent\
    \ soil electrical \nconductivity. Computers and Electronics in Agriculture 46,\
    \ 285-308. \nLee, S.H., Goëau, H., Bonnet, P., Joly, A., 2020. Attention-Based\
    \ Recurrent Neural \nNetwork for Plant Disease Classification. Frontiers in Plant\
    \ Science 11. \nLipton, Z.C., Berkowitz, J., Elkan, C., 2015. A critical review\
    \ of recurrent neural \nnetworks for sequence learning. arXiv preprint arXiv:1506.00019.\
    \ \nLiu, M., Wang, T., Skidmore, A.K., Liu, X., 2018. Heavy metal-induced stress\
    \ in rice \ncrops detected using multi-temporal Sentinel-2 satellite images. Science\
    \ of the \ntotal environment 637, 18-29. \nMaimaitijiang, M., Sagan, V., Sidike,\
    \ P., Hartling, S., Esposito, F., Fritschi, F.B., 2020. \nSoybean yield prediction\
    \ from UAV using multimodal data fusion and deep \nlearning. Remote Sensing of\
    \ Environment 237, 111599. \nMathieu, J.A., Aires, F., 2018. Assessment of the\
    \ agro-climatic indices to improve crop \nyield forecasting. Agricultural And\
    \ Forest Meteorology 253, 15-30. \nNogueira, F., 2014. Bayesian Optimization:\
    \ Open source constrained global optimization \ntool for Python. \nOosterhuis,\
    \ D.M., 1990. Growth and development of a cotton plant. Nitrogen Nutrition of\
    \ \nCotton: Practical Issues, 1-24. \n185 \n \nSaxton, K., Rawls, W., 2006. Soil\
    \ water characteristic estimates by texture and organic \nmatter for hydrologic\
    \ solutions. Soil Science Society of America Journal 70, \n1569-1578. \nSaxton,\
    \ K., RRawls, W., Romberger, J., Papendick, R., 1986. Estimating generalized \n\
    soil-water characteristics from texture 1. Soil Science Society of America Journal\
    \ \n50, 1031-1036. \nScherer, T.F., Franzen, D., Cihacek, L., 2017. Soil, water\
    \ and plant characteristics \nimportant to irrigation. North Dakota State University,\
    \ Fargo, North Dakota. \nSchut, A.G., Traore, P.C.S., Blaes, X., Rolf, A., 2018.\
    \ Assessing yield and fertilizer \nresponse in heterogeneous smallholder fields\
    \ with UAVs and satellites. Field \nCrops Research 221, 98-107. \nSchwalbert,\
    \ R.A., Amado, T., Corassa, G., Pott, L.P., Prasad, P.V., Ciampitti, I.A., 2020.\
    \ \nSatellite-based soybean yield forecast: Integrating machine learning and weather\
    \ \ndata for improving crop yield prediction in southern Brazil. Agricultural\
    \ and \nForest Meteorology 284, 107886. \nSinghal, G., Bansod, B., Mathew, L.,\
    \ Taneja, S., 2018. A Preparatory Comparison of \nLandsat and Sentinel Satellite\
    \ Data for Estimation of Chlorophyll Concentration \nin Vegetation, 2018 2nd International\
    \ Conference on Micro-Electronics and \nTelecommunication Engineering (ICMETE).\
    \ IEEE, pp. 230-233. \nTremblay, N., Bouroubi, Y.M., Bélec, C., Mullen, R.W.,\
    \ Kitchen, N.R., Thomason, \nW.E., Ebelhar, S., Mengel, D.B., Raun, W.R., Francis,\
    \ D.D., 2012. Corn response \nto nitrogen is influenced by soil texture and weather.\
    \ Agronomy Journal 104, \n1658-1671. \n186 \n \nVan Bussel, L.G., Ewert, F., Zhao,\
    \ G., Hoffmann, H., Enders, A., Wallach, D., Asseng, \nS., Baigorria, G.A., Basso,\
    \ B., Biernath, C., 2016. Spatial sampling of weather \ndata for regional crop\
    \ yield simulations. Agricultural and Forest Meteorology 220, \n101-115. \nVories,\
    \ E., O’Shaughnessy, S., Sudduth, K.A., Evett, S., Andrade, M., Drummond, S.,\
    \ \n2020. Comparison of precision and conventional irrigation management of cotton\
    \ \nand impact of soil texture. Precision Agriculture, 1-18. \nWilliams, R.J.,\
    \ Zipser, D., 1989. A learning algorithm for continually running fully \nrecurrent\
    \ neural networks. Neural computation 1, 270-280. \nYang, Q., Shi, L., Han, J.,\
    \ Zha, Y., Zhu, P., 2019. Deep convolutional neural networks \nfor rice grain\
    \ yield estimation at the ripening stage using UAV-based remotely \nsensed images.\
    \ Field Crops Research 235, 142-153. \nYou, J., Li, X., Low, M., Lobell, D., Ermon,\
    \ S., 2017. Deep Gaussian Process for Crop \nYield Prediction Based on Remote\
    \ Sensing Data, AAAI, pp. 4559-4566. \nZhang, M., Zhou, J., Sudduth, K.A., Kitchen,\
    \ N.R., 2020. Estimation of maize yield and \neffects of variable-rate nitrogen\
    \ application using UAV-based RGB imagery. \nBiosystems Engineering 189, 24-35.\
    \ \n \n187 \n \nChapter 7. CONCLUSIONS AND FUTURE STUDY \n7.1 Conclusions \nThis\
    \ study tried to use emerging sensing technologies, such as soil EC sensors, and\
    \ \nUAV imaging sensors as well as data from the weather station to understand\
    \ the \nenvironmental effects on crop emergence, crop development and yield. This\
    \ study \nspecifically focused on methods to characterize crop development and\
    \ yield using UAV-\nbased remote sensing and deep learning technologies. This\
    \ study also developed methods \nfor the fusion of different spatiotemporal resolution\
    \ soil, weather and images data so that \nthose data can be used to quantification\
    \ of soil and weather effects on crop development \nand yield. Specifically, this\
    \ study developed the above characterize methods and the fusion \nmethods that\
    \ can be used in crop emergence, crop development and yield accordingly. The \n\
    whole study showed that the developed technologies and methods are feasible for\
    \ crop \nemergence evaluation, crop development monitoring and yield prediction.\
    \  \nFirst of all, this study developed methods and a framework for timely crop\
    \ \nemergence mapping. High accuracy of crop emergence stand count and canopy\
    \ size \nestimation was obtained in near real-time. With the improved crop row\
    \ alignment \nalgorithm, the mapping GPS accuracy was improved and provided the\
    \ feasibility of \nexploring the relationship between emergence, subsequent growth\
    \ and environment using \nUAV image data. Although there are only one-year data\
    \ collected due to weather and \nequipment issues for the other year (the year\
    \ 2018 and 2020), field elevation, ECa-sh, ECa-\ndp and soil clay content in the\
    \ shallow depth (i.e. clay10-clay30) still showed important \neffects on the crop\
    \ stand count and seedling canopy size. \n188 \n \nSecondly, crop development\
    \ variation and water stress level can be quantified by \nthe UAV multispectral\
    \ images and thermal images. Under different years (i.e. 2018 and \n2019) weather\
    \ conditions and field management (i.e. irrigation management), crop \nvegetation\
    \ indices increased and decreased differently in regions with different soil texture.\
    \ \nThe study showed that soil had more influence on crop development in the year\
    \ that when \nwater inputs were not enough and crop were under water stress. High\
    \ sand content regions \naffected the crop development due to water stress, but\
    \ the high sand content regions would \nnot affect the crop development too much\
    \ if irrigation were applied. If irrigation was \napplied and water inputs were\
    \ enough, the effects of soil on crop decreased. \nIn the end, this study showed\
    \ that the cotton yield could be estimated accurately \nand mapped based on the\
    \ integration of soil, weather and UAV image data. Integration of \nsoil, weather\
    \ and images data is a promising way to understand the soil and weather effects\
    \ \non crop development and yield. With the methods and models developed in this\
    \ study, \npredicting yield accurately in a future year before harvest based on\
    \ the model training on \nprevious years’ soil, weather and UAV image data is\
    \ feasible, which is meaningful for \nfarmers to prepare harvest and make marketing\
    \ decisions. \n7.2 Future study \nThe methods and models developed in this study\
    \ are promising for understanding \nsoil and weather effects on crop emergence,\
    \ crop development and yield. However, a larger \namount of data may be required\
    \ to give more convincing conclusions of the environmental \neffects on the crop.\
    \ Currently, the temporal resolution for image data (once per month) and \nthe\
    \ spatial resolution for ground data (like soil moisture data) in this study was\
    \ still not \nhigh. Future works may focus on higher temporal resolution image\
    \ data (twice or three \n189 \n \ntimes a week) to check more temporal details\
    \ of the crop development and higher spatial \nresolution ground data (like soil\
    \ moisture data) to understand more spatial distribution of \nthe environmental\
    \ characteristics of the field. Especially in the yield estimation study as \n\
    described in Chapter 6, predicting the crop growth as well as yield together may\
    \ also be \nmeaningful for researchers and farmers. For the current model, the\
    \ prediction of crop \ngrowth is still with low accuracy, and it requires more\
    \ data support for future study. \nMore accurate prediction models are needed\
    \ to have higher accuracy for yield \nestimation results and mapping. New models\
    \ with machine learning and deep learning \ntechnologies are waiting to be explored.\
    \ Especially, accurate models with higher \nexplainable ability are needed to\
    \ explain the relationships between crop, soil and weather \nas most of the machine\
    \ learning and deep learning models are with low explanation ability \ncurrently.\
    \  Explainable ability is important in agriculture science for understanding the\
    \ \nenvironmental effects on the crop. \n \n190 \n \nVITA \nAijing Feng was born\
    \ in Yangjiang city of Guangdong Province, China. She \nreceived her bachelor’s\
    \ degree in software engineering from South China Agricultural \nUniversity in\
    \ 2014, and master’s degree in computer application technology from South \nChina\
    \ Agricultural University in 2017. She started her Ph.D. studies in the Department\
    \ of \nBiomedical, Biological & Chemical Engineering at University of Missouri-Columbia\
    \ in \nthe fall of 2017. \nShe is interested in developing and applying computer\
    \ vision, machine learning, \ndata mining techniques to address precision agriculture\
    \ problems. Her research focuses on \nremote sensing, computer vision and machine\
    \ learning. Specifically, her primary research \nis to use UAV-based imaging and\
    \ machine learning methods in a cotton research field to \nautomatically mapping\
    \ cotton emergence, crop development variation under different soil \ntexture\
    \ and weather condition, as well as yield prediction. \n"
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: https://mospace.umsystem.edu/xmlui/bitstream/10355/85772/1/FengAijing.pdf
  publication_year: 2021
  relevance_score1: 0
  relevance_score2: 0
  title: Quantifying the effect of environments on crop emergence, development and
    yield using sensing and deep learning techniques
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.17762/itii.v7i3.809
  analysis: '>'
  authors:
  - Samiran Rana
  citation_count: 0
  full_citation: '>'
  full_text: ">\n \n31 \nIT in Industry, Vol. 7, No.3, 2019 \nPublished Online 30-Dec-2019\
    \ \nDOI: https://doi.org/10.17762/itii.v7i3.809 \nCopyright © Authors \nISSN (Print):\
    \ 2204-0595 \nISSN (Online): 2203-1731 \nAI Based Precision and Intelligent Farming\
    \ System \n \nSamir Rana \nDepartment of Comp. Sc. & Info. Tech., Graphic Era\
    \ Hill University, Dehradun, \nUttarakhand, India 248002 \n \nAbstract \nThe growing\
    \ global population and the \nincreasing demand for food have led to a \npressing\
    \ need for sustainable agricultural \npractices. To address this challenge, we\
    \ present \nan AI-Based Precision and Intelligent Farming \nSystem that leverages\
    \ state-of-the-art machine \nlearning techniques to optimize resource \nutilization\
    \ and crop yields. This study \ndemonstrates the integration of various data \n\
    sources such as satellite imagery, IoT sensors, \nand historical data to develop\
    \ a comprehensive \nand adaptive system for precision agriculture. \nOur approach\
    \ employs deep learning models, \nincluding Convolutional Neural Networks \n(CNNs)\
    \ and Long Short-Term Memory \n(LSTM) networks, to analyze and predict crop \n\
    health, \ngrowth, \nand \npotential \nyield. \nFurthermore, we propose a reinforcement\
    \ \nlearning-based decision-making module for \neffective irrigation, fertilization,\
    \ and pest \ncontrol management. The proposed system is \nextensively evaluated\
    \ on real-world datasets, \nshowing significant improvements in crop \nyield,\
    \ \nwater \nefficiency, \nand \noverall \nsustainability compared to traditional\
    \ farming \nmethods. Our findings suggest that the AI-\nBased Precision and Intelligent\
    \ Farming \nSystem has the potential to revolutionize \nagriculture and contribute\
    \ to global food \nsecurity while minimizing environmental \nimpacts. \n \n1.\
    \ Introduction \nThe global population continues to grow at an \nunprecedented\
    \ rate, placing immense pressure \non the agriculture sector to meet the increasing\
    \ \nfood demands. Traditional farming methods \nstruggle to keep pace with this\
    \ demand while \nmaintaining \nenvironmental \nsustainability. \nThus, it is crucial\
    \ to develop innovative and \nefficient farming systems that can optimize \nresource\
    \ utilization, enhance crop yields, and \nminimize environmental impacts. In this\
    \ \ncontext, we propose an AI-Based Precision and \nIntelligent Farming System\
    \ that harnesses the \npower of state-of-the-art machine learning \ntechniques\
    \ to transform agriculture. Our system \nintegrates a variety of data sources,\
    \ including \nsatellite imagery, IoT sensors, and historical \ndata, to create\
    \ a comprehensive and adaptive \nplatform \nfor \nprecision \nagriculture. \n\
    This \nmultidimensional approach enables the system \nto capture a wide range\
    \ of information, \nallowing for accurate assessment and prediction \nof crop\
    \ health, growth, and potential yield. We \nemploy deep learning models, such\
    \ as \nConvolutional Neural Networks (CNNs) and \nLong Short-Term Memory (LSTM)\
    \ networks, \nto analyze this vast amount of data and extract \nactionable insights.\
    \ \nIn addition to the predictive capabilities, \nour system incorporates a reinforcement\
    \ \nlearning-based decision-making module that \naids in effective irrigation,\
    \ fertilization, and \npest control management. This module allows \nthe system\
    \ to make data-driven decisions, \nresulting in optimized resource usage and \n\
    reduced \nenvironmental \nimpacts. \nTo \ndemonstrate the efficacy of our proposed\
    \ \nsystem, \nwe \nextensively \nevaluate \nits \nperformance on real-world datasets.\
    \ The results \nshow significant improvements in crop yield, \nwater efficiency,\
    \ and overall sustainability \ncompared to traditional farming methods. \nThese\
    \ findings underscore the potential of the \nAI-Based Precision and Intelligent\
    \ Farming \nSystem \nto \nrevolutionize \nagriculture, \ncontributing to global\
    \ food security while \nminimizing environmental degradation. \nOur AI-Based Precision\
    \ and Intelligent \nFarming System offers a promising solution to \n \n32 \nIT\
    \ in Industry, Vol. 7, No.3, 2019 \nPublished Online 30-Dec-2019 \nDOI: https://doi.org/10.17762/itii.v7i3.809\
    \ \nCopyright © Authors \nISSN (Print): 2204-0595 \nISSN (Online): 2203-1731 \n\
    address the challenges faced by the agriculture \nsector in meeting the growing\
    \ food demands. \nBy leveraging state-of-the-art machine learning \ntechniques\
    \ and integrating various data sources, \nour system has the potential to transform\
    \ \nagriculture and pave the way for a sustainable \nfuture. \n \n2. Literature\
    \ Review \nThe advent of wireless sensor networks has \ngreatly \nimpacted \n\
    the \nagriculture \nsector, \nproviding efficient and real-time monitoring of\
    \ \ncrop fields. Joshi (2017) presented an overview \nof the wireless sensor network's\
    \ application in \nagriculture, emphasizing the importance of \nmonitoring environmental\
    \ parameters such as \ntemperature, humidity, and soil moisture to \noptimize\
    \ crop growth and yield. The author also \ndiscussed the challenges and future\
    \ research \ndirections for wireless sensor networks in \nagriculture, including\
    \ energy management, data \naggregation, and security issues [1]. \nIn the context\
    \ of sensor data, Suchithra (2018) \ninvestigated the validation of sensor data\
    \ in \nvarious applications, including agriculture. The \nauthor proposed a methodology\
    \ for data \nvalidation and preprocessing, which helps \neliminate data inconsistencies,\
    \ improve data \nquality, and ensure accurate decision-making in \nvarious applications\
    \ [2]. \nMachine learning techniques have been widely \nused for crop yield prediction.\
    \ Ghadge (2018) \nexplored the application of various machine \nlearning \nalgorithms,\
    \ \nincluding \nLinear \nRegression, Support Vector Machines, and \nDecision Trees,\
    \ to predict crop yield using \nhistorical and environmental data. The study \n\
    demonstrated the potential of machine learning \ntechniques in accurately predicting\
    \ crop yields, \nproviding valuable insights for efficient crop \nmanagement [3].\
    \ \nDeep learning models have also shown promise \nin agriculture. Kshirsagar\
    \ and Akojwar (2016) \noptimized the parameters of a Backpropagation \nNeural\
    \ Network (BPNN) using Particle Swarm \nOptimization (PSO) for efficient processing\
    \ of \nEEG signals. This approach could be extended \nto \nagricultural \napplications,\
    \ \nwhere \nthe \noptimization of deep learning models can \ncontribute to improved\
    \ performance in tasks \nsuch as crop health monitoring and yield \nprediction\
    \ [4]. \nThe impact of agricultural field traffic on soil \ncompaction has been\
    \ modeled using SoilFlex \nby Keller et al. (2007). This model predicts soil \n\
    stress and compaction as a result of field traffic, \nproviding a useful tool\
    \ to minimize soil \ndegradation and improve crop growth. The \nauthors also synthesized\
    \ various analytical \napproaches \nto \nbetter \nunderstand \nsoil \ncompaction\
    \ dynamics [5]. \nGoap et al. (2018) proposed an IoT-based smart \nirrigation\
    \ management system that employs \nmachine learning techniques and open-source\
    \ \ntechnologies. This system allows for efficient \nwater management in agriculture,\
    \ resulting in \nreduced water usage and increased crop yield. \nThe integration\
    \ of IoT and machine learning in \nthis system exemplifies the potential of modern\
    \ \ntechnology in sustainable agriculture [6]. \n \nJayaraman et al. (2016) present\
    \ an IoT-based \nplatform designed to address various challenges \nin agriculture,\
    \ such as managing resources and \nmonitoring environmental parameters. The \n\
    authors \ndescribe \nthe \narchitecture \nand \ncomponents of their platform,\
    \ which include \nwireless sensor networks, data storage, data \nanalysis, and\
    \ data visualization modules. The \nplatform's \neffectiveness \nis \ndemonstrated\
    \ \nthrough real-world use cases, highlighting the \nbenefits of adopting IoT\
    \ technologies in \nagriculture [7]. \nPopović et al. (2017) discuss the development\
    \ \nof an IoT-enabled platform for precision \nagriculture (PA) and ecological\
    \ monitoring in \ntheir study \"Architecting an IoT-enabled \nplatform for PA\
    \ and ecological monitoring: A \ncase \nstudy\". \nThe \nauthors \npropose \n\
    an \narchitecture \nthat \nintegrates \nvarious \nIoT \ntechnologies, such as\
    \ wireless sensor networks, \ncloud computing, and machine learning \nalgorithms.\
    \ \nThe \npaper \nemphasizes \nthe \nimportance of addressing challenges related\
    \ to \ndata acquisition, processing, storage, and \ndecision-making in smart farming\
    \ systems [8]. \n \n33 \nIT in Industry, Vol. 7, No.3, 2019 \nPublished Online\
    \ 30-Dec-2019 \nDOI: https://doi.org/10.17762/itii.v7i3.809 \nCopyright © Authors\
    \ \nISSN (Print): 2204-0595 \nISSN (Online): 2203-1731 \nKatyara et al. (2017)\
    \ present a wireless sensor \nnetwork (WSN) based smart control and remote \n\
    field monitoring system for Pakistan's irrigation \ninfrastructure, using supervisory\
    \ control and \ndata acquisition (SCADA) applications. The \nauthors discuss the\
    \ potential benefits of their \nproposed system, including improved water \nmanagement,\
    \ reduced water wastage, and the \nability to remotely monitor and control \n\
    irrigation systems in real-time [9]. \nDespommier's (2009) article \"The rise\
    \ of \nvertical farms\" discusses the concept of vertical \nfarming as an innovative\
    \ solution to the \nchallenges of traditional agriculture. The author \nexplains\
    \ the advantages of vertical farming, \nsuch as reduced land and water usage,\
    \ \ncontrolled \nenvironment \nagriculture, \nand \nincreased crop yields. Despommier\
    \ emphasizes \nthe potential role of IoT technologies in the \nsuccessful implementation\
    \ of vertical farming \npractices [10]. \nBhola and Soni (2016) et al provide\
    \ an \noverview of the research challenges and issues \nin the field of wireless\
    \ sensor and actuator \nnetworks (WSANs). The authors discuss \nvarious aspects\
    \ of WSANs, such as network \narchitectures, protocols, security, and energy \n\
    efficiency. They highlight the importance of \naddressing these challenges to\
    \ ensure the \nsuccessful deployment of WSANs in smart \nfarming applications\
    \ [11]. \nGhosh and Koley's et al (2014) study \ndemonstrates the application\
    \ of machine \nlearning techniques in agriculture. The authors \npropose a method\
    \ to predict soil fertility and \nplant nutrient requirements based on historical\
    \ \ndata, using backpropagation neural networks. \nThis approach can help optimize\
    \ resource \nutilization and improve crop yields in smart \nfarming systems [12].\
    \ \nThe literature highlights the importance of \nwireless sensor networks, data\
    \ validation, and \nmachine learning techniques in agriculture. The \nintegration\
    \ of these technologies has led to \nimproved crop monitoring, yield prediction,\
    \ \nand resource management. The development of \nmodels such as SoilFlex has\
    \ further contributed \nto understanding soil compaction dynamics and \nmitigating\
    \ the negative impacts of agricultural \nfield traffic. The combination of IoT,\
    \ machine \nlearning, and open-source technologies has \nbeen shown to create\
    \ efficient and sustainable \nagriculture systems, as demonstrated by the \nsmart\
    \ irrigation management system proposed \nby Goap et al. (2018). These advancements\
    \ \npave the way for the development of AI-Based \nPrecision and Intelligent Farming\
    \ Systems that \nleverage state-of-the-art machine learning \ntechniques to optimize\
    \ resource utilization and \ncrop yields, ultimately contributing to global \n\
    food security and environmental sustainability. \n3. Proposed System \n \nA. System\
    \ Architecture \nIn the AI-Based Precision and Intelligent \nFarming System, we\
    \ employ a combination of \nalgorithms, including CNNs, LSTMs, and \nreinforcement\
    \ learning techniques. Here is a \nstep-by-step outline of the overall algorithm\
    \ \nused in our system: \n \nFigure 1. Proposed System Architecture \n \n34 \n\
    IT in Industry, Vol. 7, No.3, 2019 \nPublished Online 30-Dec-2019 \nDOI: https://doi.org/10.17762/itii.v7i3.809\
    \ \nCopyright © Authors \nISSN (Print): 2204-0595 \nISSN (Online): 2203-1731 \n\
    Step 1: Data Acquisition \n1.1. Collect data from various sources, such as \n\
    satellite imagery, IoT sensors (e.g., soil \nmoisture, temperature, humidity),\
    \ and historical \ndata (e.g., past yields, weather conditions). \n1.2. Pre-process\
    \ and clean the data to \nensure its quality and consistency. \nStep 2: Feature\
    \ Extraction using CNNs \n2.1. Train a CNN on satellite imagery to extract \n\
    relevant features related to crop health and \ngrowth. \n2.2. Use the trained\
    \ CNN to process the satellite \nimagery and obtain feature maps representing\
    \ \nthe spatial distribution of the detected features. \nStep 3: Time-Series Analysis\
    \ using LSTMs \n3.1. Train an LSTM network on the time-series \ndata obtained\
    \ from IoT sensors and historical \nrecords to learn temporal patterns and \n\
    dependencies. \n3.2. Use the trained LSTM to predict crop \nhealth, growth, and\
    \ potential yield based on the \ngiven time-series data. \nStep 4: Decision-Making\
    \ using Reinforcement \nLearning \n4.1. Formulate the irrigation, fertilization,\
    \ and \npest control management as a Markov Decision \nProcess (MDP). \n4.2. Train\
    \ a reinforcement learning agent (e.g., \nQ-Learning or Deep Q-Network) on the\
    \ MDP \nto \nlearn \noptimal \npolicies \nfor \nresource \nmanagement. \n4.3.\
    \ Apply the learned policies in real-time to \nmake \ndata-driven \ndecisions\
    \ \nregarding \nirrigation, fertilization, and pest control \nmanagement. \nStep\
    \ 5: System Integration \n5.1. \nIntegrate \nthe \nCNN, \nLSTM, \nand \nreinforcement\
    \ learning components into a \nsingle, unified system. \n5.2. Continuously update\
    \ the system with new \ndata to ensure that it remains adaptive and \nresponsive\
    \ to changing conditions. \nStep 6: System Evaluation \n6.1. Test the AI-Based\
    \ Precision and Intelligent \nFarming System on real-world datasets to \nevaluate\
    \ its performance in terms of crop yield, \nwater efficiency, and overall sustainability.\
    \ \n6.2. Compare the system's performance with \ntraditional farming methods to\
    \ demonstrate its \neffectiveness and potential for revolutionizing \nagriculture.\
    \ \nBy following these steps, the AI-Based \nPrecision and Intelligent Farming\
    \ System can \nleverage state-of-the-art machine learning \ntechniques to optimize\
    \ resource utilization and \ncrop yields, contributing to global food security\
    \ \nand environmental sustainability. \nB. Algorithms \nHere is a step-by-step\
    \ outline of the \nConvolutional Neural Networks (CNN) and \nLong Short-Term Memory\
    \ (LSTM) algorithms \nused in the AI-Based Precision and Intelligent \nFarming\
    \ System: \n1. Convolutional \nNeural \nNetworks \n(CNN) Algorithm: \nStep 1:\
    \ Initialize the CNN architecture with \nlayers \n1.1. Define the input layer\
    \ to accept the satellite \nimagery data. \n1.2. Add convolutional layers with\
    \ specific \nfilter sizes and activation functions. \n1.3. Add pooling layers\
    \ (e.g., max-pooling) to \nreduce spatial dimensions. \n1.4. \nAdd \nfully \n\
    connected \nlayers \nwith \nappropriate \nactivation \nfunctions \nfor \nclassification\
    \ or regression tasks. \n1.5. Define the output layer based on the \nspecific\
    \ problem (e.g., crop health assessment, \ngrowth prediction). \nStep 2: Preprocess\
    \ the satellite imagery data \n2.1. Resize the images to fit the input layer \n\
    dimensions. \n2.2. Normalize the pixel values for efficient \ntraining. \nStep\
    \ 3: Train the CNN \n3.1. Split the dataset into training and validation \nsets.\
    \ \n3.2. Train the CNN using the training set with a \nspecified loss function\
    \ and optimization \nalgorithm. \n3.3. Monitor the model's performance on the\
    \ \nvalidation set and adjust hyper-parameters as \nneeded. \nStep 4: Feature\
    \ extraction \n \n35 \nIT in Industry, Vol. 7, No.3, 2019 \nPublished Online 30-Dec-2019\
    \ \nDOI: https://doi.org/10.17762/itii.v7i3.809 \nCopyright © Authors \nISSN (Print):\
    \ 2204-0595 \nISSN (Online): 2203-1731 \n4.1. Pass the processed satellite images\
    \ through \nthe trained CNN. \n4.2. Extract the feature maps from the CNN's \n\
    last convolutional layer. \nStep 5: Post-processing \n5.1. Analyze the extracted\
    \ feature maps to \nidentify relevant patterns related to crop health \nand growth.\
    \ \n \n2. Long Short-Term Memory (LSTM) \nAlgorithm \nStep \n1: \nInitialize \n\
    the \nLSTM \nnetwork \narchitecture \n1.1. Define the input layer to accept the\
    \ time-\nseries data from IoT sensors and historical \nrecords. \n1.2. Add one\
    \ or more LSTM layers with a \nspecified number of hidden units and activation\
    \ \nfunctions. \n1.3. Define the output layer based on the \nspecific problem\
    \ (e.g., crop yield prediction). \nStep 2: Pre-process the time-series data \n\
    2.1. Normalize the data for efficient training. \n2.2. Transform the data into\
    \ suitable input \nformat (e.g., time steps and features). \nStep 3: Train the\
    \ LSTM network \n3.1. Split the dataset into training and \nvalidation sets. \n\
    3.2. Train the LSTM using the training \nset with a specified loss function and\
    \ \noptimization algorithm. \n3.3. Monitor the model's performance \non the validation\
    \ set and adjust hyper-\nparameters as needed. \nStep 4: Time-series prediction\
    \ \n4.1. Pass the processed time-series data through \nthe trained LSTM. \n4.2.\
    \ Obtain the predicted values (e.g., crop \nhealth, growth, potential yield).\
    \ \nBy following these steps, the AI-Based \nPrecision and Intelligent Farming\
    \ System can \nutilize the CNN and LSTM algorithms to \nanalyze satellite imagery\
    \ and time-series data, \nproviding accurate assessments and predictions \nof\
    \ crop health, growth, and potential yield. \n \n4. RESULT \n \nA. Comparative\
    \ Analysis \nTable 1 shows the comparative analysis of \nresearcher work with\
    \ their methodology used, \nadvantages and disadvantages \nTable 1. Comparative\
    \ Analysis of Researchers work \nAuthor(s) \nMethodology/Techniques \nUsed \n\
    Algorithms/  \nModels \nAdvantages \nDisadvantages \nP. \nJoshi \n(2017) \nWireless\
    \ sensor networks \nfor crop field monitoring \nN/A \nReal-time monitoring, \n\
    efficient data collection \nEnergy \nmanagement, data \naggregation, \nsecurity\
    \ \nM. Suchithra \n(2018) \nSensor data validation and \npreprocessing \nN/A \n\
    Improved data quality, \naccurate \ndecision-\nmaking \nN/A \nR. \nGhadge \n(2018)\
    \ \nMachine learning for crop \nyield prediction \nLinear \nRegression, \nSVM,\
    \ Decision \nTrees \nAccurate \nyield \nprediction, \nvaluable \ninsights \nfor\
    \ \ncrop \nmanagement \nLimited \nto \nhistorical \nand \nenvironmental data \n\
    Kshirsagar & \nAkojwar \n(2016) \nBPNN optimization using \nPSO for EEG signals\
    \ \nBPNN, PSO \nImproved \ndeep \nlearning \nmodel \nperformance \nFocused on\
    \ EEG \nsignals, not directly \napplicable \nto \nagriculture \nKeller et al.\
    \ \n(2007) \nSoil compaction modeling \ndue to agricultural field \ntraffic \n\
    SoilFlex \nBetter understanding of \nsoil \ncompaction \ndynamics \nLimited \n\
    to \nsoil \nstress \nand \n \n36 \nIT in Industry, Vol. 7, No.3, 2019 \nPublished\
    \ Online 30-Dec-2019 \nDOI: https://doi.org/10.17762/itii.v7i3.809 \nCopyright\
    \ © Authors \nISSN (Print): 2204-0595 \nISSN (Online): 2203-1731 \ncompaction\
    \ \nprediction \nGoap et al. \n(2018) \nIoT-based smart irrigation \nmanagement\
    \ system using \nmachine learning \nMachine \nlearning \ntechniques, \nopen-source\
    \ \ntechnologies \nEfficient \nwater \nmanagement, reduced \nwater usage, increased\
    \ \ncrop yield \nIntegration \ncomplexity, \ndependence on IoT \ninfrastructure\
    \ \nJayaraman et \nal., 2016 \nIoT platform \nN/A \nResource management, \nmonitoring,\
    \ \nand \noptimization \nLack of detailed \nalgorithms/models \nPopović \net \n\
    al., 2017 \nIoT-enabled platform \nCloud \ncomputing, \nmachine \nlearning \n\
    Data \nacquisition, \nprocessing, \nstorage, \ndecision-making \nRequires extensive\
    \ \ninfrastructure \nKatyara et al., \n2017 \nWSN, SCADA \nN/A \nImproved \nwater\
    \ \nmanagement, reduced \nwastage, \nremote \ncontrol \nLimited \nto \nirrigation\
    \ systems \nDespommier, \n2009 \nVertical farming \nN/A \nReduced \nland \nand\
    \ \nwater usage, increased \ncrop yields \nHigh \ninitial \ninvestment, energy\
    \ \nconsumption \nBhola \nand \nSoni, 2016 \nWSAN research overview \nN/A \nOutlines\
    \ \nchallenges \nand issues in WSAN \ndeployment \nDoes not provide \nsolutions\
    \ \nGhosh \nand \nKoley, 2014 \nMachine learning \nBackpropagation \nneural networks\
    \ \nPredicting soil fertility, \nplant \nnutrient \nrequirements \nLimited \n\
    to \nsoil \nfertility prediction \n \nB. Result Analysis \nFigure 2 shows the\
    \ accuracy and f1-score comparison graph of deep learning algorithm, CNN \noutperform\
    \ LSTM in terms of accuracy and F1-score. \n \nFigure 2. Performance Comparison\
    \ Graph \n \nCNN\nLSTM\nAccuracy\n95.2\n93.7\nF1-Score\n94.7\n91.4\n89\n90\n91\n\
    92\n93\n94\n95\n96\n%\nAlgorithms\nPERFORMACNE COMPARISON \nGRAPH\nAccuracy\n\
    F1-Score\n \n37 \nIT in Industry, Vol. 7, No.3, 2019 \nPublished Online 30-Dec-2019\
    \ \nDOI: https://doi.org/10.17762/itii.v7i3.809 \nCopyright © Authors \nISSN (Print):\
    \ 2204-0595 \nISSN (Online): 2203-1731 \nConclusion \nIn conclusion, the AI-Based\
    \ Precision and \nIntelligent Farming System effectively employs \nmachine learning\
    \ techniques, including CNNs, \nLSTMs, \nand reinforcement \nlearning, \nto \n\
    optimize resource utilization, improve crop \nyields, and reduce environmental\
    \ impacts. By \nintegrating satellite imagery, IoT sensors, and \nhistorical data,\
    \ our system has demonstrated \nsignificant improvements in crop yield, water\
    \ \nefficiency, and sustainability compared to \ntraditional \nfarming \nmethods.\
    \ \nThus, \nthe \nproposed system offers a promising solution to \nmeet the growing\
    \ food demands and pave the \nway for a sustainable and efficient future in \n\
    agriculture. \n \nReferences \n[1] P. Joshi, “Wireless sensor network and \nmonitoring\
    \ of crop field,” IOSR Journal of \nElectronics and Communication Engineering\
    \ \n(IOSR-JECE), vol. 12, no. 1, pp. 23–28, 2017. \n[2] M. Suchithra, “Sensor\
    \ data validation,” \nInternational Journal of Pure and Applied \nMathematics,\
    \ vol. 119, no. 12, pp. 14327–\n14335, 2018. \n[3] R. Ghadge, “Prediction of crop\
    \ yield using \nmachine learning,” International Research \nJournal of Engineering\
    \ and Technology, vol. 5, \nno. 2, pp. 2237–2239, 2018. \n[4] \nP. \nKshirsagar\
    \ \nand \nS. \nAkojwar, \n“Optimization of BPNN parameters using PSO \nfor EEG\
    \ signals,” in Proceedings of the \nInternational Conference on Communication\
    \ \nand Signal Processing, pp. 385–394, India, \n2016. \n[5] Keller, T., Défossez,\
    \ P., Weisskopf, P., \nArvidsson, J., and Richard, G. (2007). SoilFlex: \na model\
    \ for prediction of soil stresses and soil \ncompaction due to agricultural field\
    \ traffic \nincluding a synthesis of analytical approaches. \nSoil \nTillage \n\
    Res. \n93, \n391–411. \ndoi: \n10.1016/j.still.2006.05.012 \n[6] Goap, A., Sharma,\
    \ D., Shukla, A. K., and \nRama Krishna, C. (2018). An IoT based smart \nirrigation\
    \ management system using Machine \nlearning \nand \nopen \nsource \ntechnologies.\
    \ \nComput. Electron. Agric. 155, 41–49. doi: \n10.1016/j.compag.2018.09.040 \n\
    [7] P.  P.  Jayaraman,  A.  Yavari,  D.  \nGeorgakopoulos,  A.  Morshed,  and\
    \  A. \nZaslavsky, “Internet  of things  platform for  \nsmart farming:  Experiences\
    \  and lessons \nlearned,” Sensors, vol. 16, no. 11, p. 1884, \n2016.  \n[8] T.\
    \ Popović, N. Latinović, A. Pešić, Ž. \nZečević, B. Krstajić, and S. Djukanović,\
    \ \n“Architecting an IoT-enabled platform for PA \nand ecological monitoring:\
    \ A case study,” \nComput. Electron. Agric., vol. 140, pp. 255–65, \n2017. [12]\
    \ J. Tummers,  A. Kassahun, B.  \nTekinerdogan,  Obstacles &  features \n[9] Katyara,\
    \ S., Shah, M. A., Zardari, S., \nChowdhry, B. S., & Kumar, W. WSN based \nsmart\
    \ control &  remote field monitoring of \nPakistan’s irrigation system using SCADA\
    \ \napplications. Wireless Personal Comms, 95(2), \n491-504. 2017 \n[10] Despommier,\
    \ D. The rise of vertical farms. \nSci. Am. 2009, 301, 80–87 \n[11] J. Bhola and\
    \ S. Soni, “A study on research \nissues \nand \nchallenges \nin \nWSAN,” \nin\
    \ \nProceedings \nof \nthe \n2016 \nInternational \nConference on Wireless Communications,\
    \ \nSignal \nProcessing \nand \nNetworking \n(WiSPNET), pp. 1667–1671, Chennai,\
    \ India, \nMarch 2016. \n[12] S. Ghosh and S. Koley, “Machine learning \nfor soil\
    \ fertility and plant nutrient management \nusing back propagation neural networks,”\
    \ \nInternational Journal on Recent and Innovation \nTrends in Computing and Communication,\
    \ vol. \n2, no. 2, pp. 292–297, 2014. \n \n"
  inline_citation: '>'
  journal: Information Technology in Industry
  limitations: '>'
  pdf_link: http://it-in-industry.org/index.php/itii/article/download/809/654
  publication_year: 2019
  relevance_score1: 0
  relevance_score2: 0
  title: AI Based Precision and Intelligent Farming System
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'

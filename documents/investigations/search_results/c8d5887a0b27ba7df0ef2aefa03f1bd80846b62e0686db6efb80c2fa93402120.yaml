- DOI: https://doi.org/10.1109/icesc51422.2021.9532917
  analysis: '>'
  authors:
  - Sanjay Hardikar
  - Pradeep Ahirwar
  - Sameer Rajan
  citation_count: 7
  full_citation: '>'
  full_text: '>

    IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account
    Personal Sign In Browse My Settings Help Access provided by: University of Nebraska
    - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards
    Authors Citations ADVANCED SEARCH Conferences >2021 Second International Con...
    Containerization: Cloud Computing based Inspiration Technology for Adoption through
    Docker and Kubernetes Publisher: IEEE Cite This PDF Sanjay Hardikar; Pradeep Ahirwar;
    Sameer Rajan All Authors 7 Cites in Papers 1129 Full Text Views Abstract Document
    Sections I. Introduction II. Motivation and Objective III. Docker IV. Kubernetes
    (K8S) V. Rancher Show Full Outline Authors Figures References Citations Keywords
    Metrics Abstract: The field of cloud computing has been evolving rapidly since
    inception. Cloud is the virtual pool of resources which can be served to the user
    through SaaS, PaaS and IaaS flavours. No cloud can be existed without virtualization.
    With Virtual Machine, the bare metal is virtualized to run multiple Operating
    System instances. These VMs serve to the users for performing the tasks. All are
    independent units and user has complete ownership and control to install the required
    softwares and use as per the wish. The VM solves many problems by optimizing the
    resources. The developers concern that the code is working fine on the development
    environment, but fail to work on testing or production environment due to the
    environment differences, if any. So, the Containerization comes into the picture
    to address such challenges. In this paper, various aspects of Containerization
    are explored and highlighted. The Container runtime environment-Docker and Container
    orchestration tool-Kubernetes are focused and deployed for exploring the possibilities
    of Containerization adoption, which automate the Container deployment, scaling
    and load balancing. Published in: 2021 Second International Conference on Electronics
    and Sustainable Communication Systems (ICESC) Date of Conference: 04-06 August
    2021 Date Added to IEEE Xplore: 23 September 2021 ISBN Information: DOI: 10.1109/ICESC51422.2021.9532917
    Publisher: IEEE Conference Location: Coimbatore, India SECTION I. Introduction
    [1] Cloud Computing makes a virtual pool of resources which serves the user''s
    requirement at reasonable cost. It manages the pool of resources automatically
    and dynamically and provides Software as a Service (SaaS), Platform as a Service
    (PaaS) and Infrastructure as a Service (IaaS) through Public, Private and Hybrid
    Cloud models. It serves faster, simpler and cheaper services with high availability
    and scalability in elastic manner. In short, cloud serves ‘Everything as a Service’.
    [2] To harness the Cloud Computing benefits, Government of India already launched
    Meghraj Cloud. This not only makes certain the optimal infrastructure utilization
    but also expedite the deployment of e-governance applications. [3] Cloud environment
    uses virtualization technology to migrate physical environment into virtual environment
    which reduces the overheads to maintain the hardware. Virtualization can be achieved
    by creating Virtual Machines (VMs). VM is the heavy weight resource and run top
    of the virtualization software and this virtualization software run on host operating
    system which slowdowns the performance. Each VMs created on top of the virtualization
    software have guest OS. User wants to run the application but as VM is equipped
    with OS and system''s programs and files, these components consume space and computing
    power. One of the common problems is faced by the developers and operational team
    that the code is working successfully on a machine but doesn''t work on other
    one due to the differences in computing environment, if any. As per current technology
    trend, the Microservices are gaining the popularity among the developers. Microservices
    address the issues associated with monolithic applications. [4] Microservices
    are independent and self-sufficient components that isolate fine grained business
    capabilities. Microservices are based on Microservices Architecture which is an
    approach to design software applications as suites of independently deployable
    services. Many applications are easier to create and maintain if they are converted
    into smaller components which work in conjunction. Each component is developed
    independently, and the application is then just the integration of these individual
    components. The updations of application component are easy to handle. Also, the
    failure of one Microservice will not affect other Microservices of the system
    because of its loosely coupled nature. Microservice got a lot of popularity because
    of its advantages. The Virtual Machine or Virtualization is not the suitable option
    to handle these challenges. To address such issues, the need of Containerization
    arises. Containerization facilitates to deploy various applications utilizing
    the same OS on a single VM/ Server. A Container uses operating system level virtualization
    for deploying applications instead of creating an entire VM. [5] Containerization
    is a technology to virtualize the applications in a way that results the significant
    enhancement in cloud applications management. [6] The Containers enveloped an
    application and the associated dependencies inside its own environment. It permits
    them to execute in isolated way while utilizing the same resources including the
    Operating System. It enables a rapid, lightweight application deployment because
    the resources are utilized in feasible manner by not wasting on running separate
    operating system. [7] The applications are enveloped with all the required dependencies
    into a standardized format called as a Container. These Containers carry on running
    in an isolated manner on top of the host OS. Now several Microservices can run
    in the same VM by running various Containers for each Microservice. In this way,
    it supports the Microservices architecture as well as resolves the issue of differences
    in computing environment on VM/ Servers. The application will always work same
    way without any difference that on which Platform/ OS (Data Center, Cloud, Windows
    and Linux Distros) it runs. Containerization is in vogue with the rise of Microservices
    and Docker. There are various Containerization tools available to build, deploy
    and run the applications. Some Container runtime environments are Docker, Containerd,
    CRI-O etc. [8] The Docker is the leading Container platform that packages code
    and dependencies together and ships them as a Container Image. Docker is an open
    source tool which also provides online repository of Docker Images called as Docker
    Hub. Docker Containers are simply runtime instances of Docker Images. The complex
    requirements for a Microservice are written in easy to write DockerFile. The developer
    writes the codes that define the application requirement with its dependencies
    in a DockerFile. This DockerFile produces an Image. All the dependencies which
    are required for the application are present in the Image. This Image can be uploaded
    in Docker Hub. Docker hub is Git repository, which is distributed Version Control
    System, for Docker images. Anybody can pull the required Image and build a Container.
    There is no need to pre-allocate any RAM in the Containers. The Containers could
    not communicate with each other so it is needed to deploy and manage them appropriately.
    They cannot be auto scaled to handle the workloads and distribution of traffic
    is also challenging with Containers. So, to handle such issues, [9] Kubernetes
    comes into the picture. It is an open source Container orchestration engine which
    automates the Container deployment, Container scaling and Container load balancing.
    The basic deployment unit in Kubemetes is Pod. Pod is the basic unit in Kubemetesas
    Container is the basic unit in Docker. Each Pod contains mainly single Container.
    SECTION II. Motivation and Objective Containerization can replace the tradition
    of virtual machines and monolithic approaches. The virtual machine is not optimal
    platform for resource utilization. The VMs require separate OS and other resources
    to deploy and run the applications. The developers are also dependent on VM''s
    environment to test, run and deploy the application and waste their time to sort
    out the issues of environment differences. The microservices architecture enables
    the independent deployable services to take over and addresses the issues associated
    with the monolithic architecture. Microservices architecture makes the application
    loosely coupled by breaking a software application into independent deployable
    services. To address the issues and to take the advantages of microservices, the
    Containerization plays a vital role. The applications are enveloped with all related
    dependencies into a format named as a Container. The developers take its advantages
    as the application is now tested, run and deployed without worrying about environment
    differences. Each service is deployed in separate Container to make it loosely
    coupled and independent deployable units. There are many Container Runtimes but
    Docker is the most popular and open source tool, and as a Container Orchestration
    Platform Kubernetes is freely available and trending. Nowadays many IT giants
    adopting these latest trends and technologies, also many businesses are adopting
    this Containerization technology due to its easy deployment, scaling, and operations.
    Here, the objective is to discuss the aspects of Containerization using Docker
    and Kubernetes and the focus is to deploy, run and test the Docker and Kubernetes
    in order to explore them and gaining the experience by deploying the applications.
    SECTION III. Docker Docker [10] works as Client-Server based model. The Docker
    client sends the request to Docker server/daemon. The Docker client and server
    both can be run on same or separate machine. Docker makes it easier to create,
    deploy and run applications by using Containers. It simplifies the configuration,
    manage code pipeline, increase productivity, provide application isolation and
    mobility etc. A. Docker Images The Docker Image can be created using DockerFile.
    It contains a list of instructions. Simple Docker build command is sufficient
    to create an image file. All instructions written in the DockerFile are followed
    to build an Image. B. DockerRepository Docker images are placed in online repository
    of images. Images can be pushed and pulled through simple Docker push and Docker
    pull command respectively. Docker Hub is the repository where anybody can push
    or pull the images without building an Image afresh. C. DockerContainer A Docker
    Image is utilized to create a Docker Container. Containers contain all dependencies
    and instructions for an application to run in isolation. The Docker run command
    is available to execute the Docker Image to create a Container. SECTION IV. Kubernetes
    (K8S) It is an open source project to automate deployment, scale, and to manage
    the Containerized applications [11]. Without the Container orchestration the human
    cost of running services was high, increased complexity of running something new
    in production, scaling was difficult, manual service setup and manual node crash
    fixing was required. Kubernetes (K8S) provides various significant features which
    allow running immutable infrastructure. The key K8S features are as below- Horizontal
    scaling Automated rollouts and rollbacks Service discovery and load balancing
    Storage orchestration Secret and configuration management Self-healing Batch execution
    Automatic bin packing Fig. 1. Kubernetes features Show All A. Pods As the atomic
    unit of scheduling in Virtualization is VM and Container in Docker environment
    same way the atomic unit Pod is used in Kubernetes. Single VM can run multiple
    Pods and each Pod can contain one or more Container. Pod has unique IP address
    and each Container inside the Pod run on separate port numbers. There are two
    types of communication: intra Pod and inter Pod communication. The Container inside
    the Pod can communicate through the same network namespace which means all the
    Containers inside the same Pod share the same IP address but different port number
    while in the case of inter Pod communication, each Pod has separate IP address
    and this unique Pod IP establish the inter Pod communication. When a Pod fails/dies
    then Containers of that Pod are shifted to new Pod for uninterrupted execution.
    Pod is the basic scheduling unit and has unique IP address but Pods are ephemeral
    so if Pod fails, new Pod gets a fresh IP address so how to expose application
    to the outside world, how various components connect/communicate and how to resolve
    Pod IP changes. To address these situations, Service takes the charge. A service
    in Kubernetes is an abstraction that represents a logical set of pods and a policy
    through which they are accessed. The services correspond to a set of pods using
    labels and selectors. ClusterIP, NodePort and LoadBalancer are the main types
    of Services. ClusterIP exposes on an internal IP in the cluster. This is default
    Service and not accessible from outside the cluster. NodePort helps to expose
    the applications outside the world. It makes a Service accessible from outside
    the cluster. LoadBalancer provisions an external load balancer in current cloud
    and allocate a fixed, external IP to the Service. B. Kubernetes Components The
    cluster is composed of a master node, which helps in exposing the API, scheduling
    the deployment, and typically managing the cluster. Multiple worker nodes may
    be accountable for Container runtime (Docker, rkt etc.), plus an agent that talk
    to the master. C. Master Node Components Kube-apiserver responsible for exposing
    the API. Etcd. Key value stores all the cluster data. Kube-scheduler schedules
    new Pods on worker nodes. Kube-controller-manager runs the controllers. Cloud-controller-manager
    talks to cloud providers. D. Worker Node Components Kubelet agent ensures that
    Containers in a Pod are running. Kube-proxy keeps network rules and performs forwarding.
    Container runtime runs the Containers. E. Use Case of Kubernetes (Containerization)
    [12] Secure, Scalable and Sugamya Website as a Service (S3WaaS) is a GIGW based
    website generating framework which is based on SaaS model hosted on National Cloud
    of National Informatics Centre (NIC). It is built on Software Defind Infrastructure
    for smooth provisioning hosting, compute, storage and networking. It leverages
    technology for generating secure websites which are highly customizable and seamlessly
    deployed on a scalable and completely software defined infrastructure. All the
    district administration and many other governemnt bodies have launched the S3WaaS
    based websites, which are utilizing the benefits of cutting edge Containerization
    technologies like Docker, Kubernetes etc. and other latest trends. The infrastructure
    procurement/alocation and its management is not the matter of concern for user,
    the user focuses entirely on content quality. The website is developed on S3WaaS
    framework using CMS like WordPress provided through S3WaaS interface. User need
    to focus on website development instead of resource management. It is built on
    Containers using popular open source Container runtime-Docker and Container orchestration-Kubernetes
    tools. Some important points related to the Infrastructure are mentioned as- Built
    on Containers using open source tools (Docker, Container, WordPress etc.) Agile
    and Scalable with Auto Healing and Auto Scaling. Seamless deployment, scaling
    and monitoring of each generated website. Static content published on an software
    defined Object Storage with replication. Automatic configuring of each website
    on software defined Load Balancer. Automatic updates for security patches. Dashboard
    for real time log monitoring and website analytics for insights into website usage.
    SECTION V. Rancher Rancher [13] is a multi-cluster orchestration platform which
    sorts out the operational as well as security challenges to manage multiple Kubernetes
    clusters across any infrastructure, while making available DevOps teams with integrated
    tools for running Containerized workloads. It facilitates for delivering the Kubernetes-as-a-Service.
    Rancher quickly deploys Kubernetes clusters anywhere on any provider and also
    unites these deployed clusters under centralized authentication and also the access
    control. Because it is agnostic about where the resources run, you can easily
    bring a cluster to a different provider and transfer resources between them. Instead
    of having multiple independent Kubernetes deployments, Rancher integrates them
    as a single, managed Kubernetes cloud. Kubernetes is a powerful engine to orchestrate
    Containers. Rancher incorporates a full Kubernetes distribution, but adds value
    around Kubernetes in three crucial fields as Cluster Operations and Management,
    Intuitive Workload Management and Enterprise Support. Following are some features
    of the Rancher [14]. It supports the multi orchestration engines like Kubernetes,
    Cattle or Docker Swarm. It is useful to create a private SDN for each environment
    which enables secure communication. It distributes the traffic between Containers
    or services through Container load balancing. It supports orchestrating the persistent
    storage services for Docker. It is useful to implement distributed DNS based service
    discovery. It helps in monitoring the host resources and managing deployment of
    the Container. Rancher is designed for Multi-tenancy and user management support.
    It makes it easy to upgrade existing Container services, by allowing service cloning
    and redirection of service requests. Rancher supports Docker Machine, it monitors
    host resources and manages Container deployment which makes tasks more easier.
    SECTION VI. Steps During Deployment Setup A. Open Source Cutting Edge Technology
    Used Base OS-CentOS-8 Docker version: 19.03.13 Kubeadm /Kubectl Version: v1.19.2
    Rancher v2.5.3 B. Hands on to SetupKubernetes Cluster with Docker Runtime Environment
    The 04 nodes cluster with a master node has been set up as mentioned in Fig. 2.
    The master node works as manager node, while rest nodes work as worker node. The
    Workload is created on worker nodes only and the master node is responsible for
    managing the cluster. We follow the below mentioned steps to setup 04 Node Cluster
    Fig. 2. 04 nodes cluster with a master Show All Step 1. IP hostname mapping in
    /etc/hosts file on all (01+04) nodes. Step 2. systemctl stop/disable frrewalld
    Step 3. Disable Swap to avoid some performance issue. swapoff–a Step 4. Disable
    SELinux for subsequent reboots so that Kubernetes continues to run correctly setenforce
    0 (temporarily) vi /etc/selinux/config (permanent) SELINUX=Permissive Step 5.
    Reboot the node machine Step 6. Docker installation yum install docker–y Step
    7. If RHEL/CentOS7 then following need to be done (Optional) cat <<EOF > /etc/sysctl.d/k8s.conf
    net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1
    EOF sysctl net.bridge.bridge-nf-call-iptables=1 sysctl net.ipv4.ip_forward=1 sysctl‐‐system
    echo “1” > /proc/sys/net/ipv4/ip_forward systemctl daemon-reload systemctl restart
    kubelet Step 8. Add Kubernetes Repo as the kubeadm, kubelet, kubectl packages
    not available with default OS Repository. So, it needs to create a repo file inside
    repos directory. This repo file consists of location where related packages are
    available. Run following on linux terminal. cat <<EOF>/etc/yum.repos.d/Kubernetes.repo
    [Kubernetes] name=Kubernetes baseurl=https://packages.cloud.google.com/yum/repos/Kubernetes-e17-x86_64
    enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg
    https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg EOF Step 9. Kubernetes
    packages installation yum install -y kubeadm Step 10. Now start/enable and then
    see the status of Docker and kubelet service on nodes. systemctl start/enable/status
    docker systemctl start/enable/status kubelet Note-Steps 1 to 10 are common for
    all worker nodes and master node. Step 11. Run following command to initialize
    the control plane node, only on Master Node kubeadm init Step 12. Run following
    command only on Worker Nodes to add this worker node to the Kubernetes cluster
    kubeadm join (generated token in step 11) If the generated token is expired, obviously
    expired token will not work. Step 13. If token expired (24 hrs validity period)
    then run following command on Master Node to regenerate it and then do Step 12
    on Worker Node. kubeadm token create ‐‐print-join-command Step 14 Now Worker Node
    joined successfully, it can be verified from Master Node as kubectl get node.
    Fig. 3 highlights the basic details of all the worker nodes including master node.
    Fig. 3. The 04 node cluster with a master node Show All Later on, the same is
    verified through Kubemetes Dashboard utility. The dashboard screenshot of the
    created nodes is shown in the Fig. 4. The Kubernetes Dashboard is a web interface
    and the applications can also be deployed in the cluster, troubleshooting of the
    Containerized applications can be done and they can be easily managed. Dashboard
    provides an overview of the applications in the cluster. The Kubernetes resources
    can be easily created and modified with the help of the dashboard. It makes the
    task easier and quicker to manage the Kubernetes cluster. The Kubernetes Dashboard
    may be deployed by running following command on Master Node: kubectl apply -f
    https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0/aio/deploy/recommended.yaml
    Then access it through browser as <nodeIP>:<nodePort> Kubernetes Dashboard facilitates
    to create and deploy a Containerized application with a friendly wizard. The application
    details can be specified either manually or upload YAML or JSON file. [15] YAML
    (Ain''t Markup Language) is a human-readable data-serialization language which
    is popularly used for configuration files and in applications where data is being
    stored or transmitted while JSON stands for JavaScript Object Notation. JSON is
    a lightweight format and is used to store and transport data. The deployment is
    quicker through dashboard, user needs to just provide few details to launch the
    application and manage and troubleshoot it through the dashboard in a simpler
    way. After that, Rancher unified cluster manager can also be deployed in order
    to manage the clusters. The complete workload can be managed for DevOps and to
    maintain corporate level security. By running the following command, multi-cluster
    orchestration platform Rancher can be launched to handle the ground to manage
    our cluster. [16] docker run -d ‐‐restart=unless-stopped -p 80:80 -p 443:443 ‐‐privileged
    rancher/rancher:latest Fig. 4. Kubernetes dashboard showing all the created nodes
    Show All Then the cluster can be added/imported in Rancher orchestration manager.
    Fig. 5 shows the Rancher Dashboard of our added cluster which provides overview
    of the overall infrastructure and workloads etc. The figure shows the created
    resources like Namespaces, Deployments, Services, DaemonSets, Ingresses, Jobs
    and StatefulSet etc. of our cluster. Fig. 5. Rancher dashboard of the cluster
    Show All C. Hands on to Deploy NGINX on Kubernetes Cluster Step 1. A NGINX deployment
    is created with two replicas/Pods kubectl create deployment testwebapp ‐‐image=nginx‐‐replicas=2
    ‐‐port=80 Step 2. Check the deployment status kubectl get deploy -o wide Step
    3. Check the status of Pods kubectl get Pod -o wide Step 4. Ensure the Pods are
    accessible from other node curl <Pod IP address>:80 Step 5. Create a Service to
    expose the port to outside the cluster kubectl expose Pod testwebapp ‐‐port=8080
    ‐‐target-port=80 ‐‐type=LoadBalancer Step 6. Check the Service status kubectl
    get svc Step 7. It can also be checked by curl<nodeIP>:<nodePort> SECTION VI.
    Conclusion Virtualization technology is the fundamental technology for cloud environment.
    The limitations and problems associated with VMs and popularity of the Microservices
    give birth to utilize the leading-edge Container technology. Various Containerization
    tools are available to address the challenges towards the evolution in cloud environment.
    Docker is the leading Container runtime and Kubernetes is the Container orchestration
    tool, which are popular among the DevOps (Development and Operation) teams for
    adopting CI/CD (Continuous Integration and Continuous Deployment) in Software
    Development Life Cycle (SDLC). Kubernetes A lot of companies and government organizations
    are utilizing the benefits of Containerization by implementing a DevOps mindset
    to their workflow. Pods work like the VMs to deploy the applications but in dynamic
    way without pre-allocating the resources or installing the supporting softwares
    to run the application. So the applications are not dependent on computing environment.
    Such technologies are evolving day by day to ease the resource allocation and
    usage. This evolution is unstoppable and refinement is happening for transformation
    of the infrastructure allocation and utilization. Today, it is mandatory to adopt
    these technologies of inspiration to serve and use the ICT resources in effective
    and efficient manner by reducing the human intervention, for moving towards the
    Software Defined Infrastructure. Authors Figures References Citations Keywords
    Metrics More Like This Modularization of Software as a Service Products: A Case
    Study of the Configuration Management Tool Puppet 2015 International Conference
    on Enterprise Systems (ES) Published: 2015 SLA-Based Resource Provisioning for
    Hosted Software-as-a-Service Applications in Cloud Computing Environments IEEE
    Transactions on Services Computing Published: 2014 Show More IEEE Personal Account
    CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS
    Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL
    INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT
    & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms
    of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy
    Policy A not-for-profit organization, IEEE is the world''s largest technical professional
    organization dedicated to advancing technology for the benefit of humanity. ©
    Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: 2021 Second International Conference on Electronics and Sustainable Communication
    Systems (ICESC)
  limitations: '>'
  pdf_link: null
  publication_year: 2021
  relevance_score1: 0
  relevance_score2: 0
  title: 'Containerization: Cloud Computing based Inspiration Technology for Adoption
    through Docker and Kubernetes'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/mesoca.2016.9
  analysis: '>'
  authors:
  - Nitin Naik
  citation_count: 31
  full_citation: '>'
  full_text: '>

    IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account
    Personal Sign In Browse My Settings Help Access provided by: University of Nebraska
    - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards
    Authors Citations ADVANCED SEARCH Conferences >2016 IEEE 10th International ...
    Migrating from Virtualization to Dockerization in the Cloud: Simulation and Evaluation
    of Distributed Systems Publisher: IEEE Cite This PDF Nitin Naik All Authors 30
    Cites in Papers 1 Cites in Patent 8495 Full Text Views Abstract Document Sections
    I. Introduction II. Virtualization and Dockerization III. Dockerization on Non-Linux
    Machine (Mac OS X Machine) IV. Experimental Simulation: Development of a Distributed
    System Using Virtualization and Dockerization V. Experimental Results and Evaluation
    of Virtualization and Dockerization Technologies for the Development of a Distributed
    System Show Full Outline Authors Figures References Citations Keywords Metrics
    Abstract: Virtualization is the nucleus of the cloud computing for providing its
    services on-demand. Cloud-based distributed systems are predominantly developed
    using virtualization technology. However, the requirement of significant resources
    and issues of interoperability and deployment make it less adopt- able in the
    development of many types of distributed systems. Dockerization or Docker Container-based
    virtualization has been introduced in the last three years and gaining popularity
    in the software development community. Docker has recently introduced its distributed
    system development tool called Swarm, which extends the Docker Container-based
    system development process on multiple hosts in multiple clouds. Docker Swarm-based
    containerized distributed system is a brand new approach and needs to be compared
    with the virtualized distributed system. Therefore, this paper presents the simulation
    and evaluation of the development of a distributed system using virtualization
    and dockerization. This simulation is based on Docker Swarm, VirtualBox, Ubuntu,
    Mac OS X, nginx and redis. To simulate and evaluate the distributed system in
    the same environment, all Swarm Nodes and Virtual Machines are created using VirtualBox
    on the same Mac OS X host. For making this evaluation rational, almost similar
    system resources are allocated to both at the beginning. Subsequently, similar
    servers nginx and redis are installed on the Swarm Node and Virtual Machine. Finally,
    based on the experimental simulation results, it evaluates their required resources
    and operational overheads; thus, their performance and effectiveness for designing
    distributed systems. Published in: 2016 IEEE 10th International Symposium on the
    Maintenance and Evolution of Service-Oriented and Cloud-Based Environments (MESOCA)
    Date of Conference: 03-03 October 2016 Date Added to IEEE Xplore: 12 December
    2016 ISBN Information: Electronic ISSN: 2326-6937 DOI: 10.1109/MESOCA.2016.9 Publisher:
    IEEE Conference Location: Raleigh, NC, USA SECTION I. Introduction Virtualization
    is the most efficacious technology to simulate a distributed environment for the
    development of distributed systems similar to the real production site [1]. It
    embeds a preproduction site into each developer''s machine and offers them a real
    runtime environment for the system development [2], [3]. Thus, virtualization
    made system development more flexible and effective by allowing the dynamic allocation
    of hardware and software resources to support the build, integration, and test
    phases of complex system development projects [4]–[6]. However, the creation of
    virtualized environment requires lengthy and tedious installation and configuration
    process and highly skilled IT staff [7]. It also demands the good understanding
    of a wide range of technologies such as operating systems, databases, application
    servers and network services. This makes integration of virtualization technologies
    into the productive system development processes much harder [1]. Despite managing
    everything successfully, the biggest issues with the virtualization is its significant
    resource and operational overheads, which make it less adoptable in many types
    of distributed systems [8]. Dockerization or Docker Container-based virtualization
    has recently emerged as an alternate lightweight technology for the system development
    process and gaining popularity in the software development community [9], [10].
    Docker offers the ability to package applications and their dependencies into
    lightweight Containers that move easily between different distros, start up quickly
    and are isolated from each other [10], [11]. It aims to address the challenges
    of resource, speed and performance of virtualization in the system development
    process [12], [13]. In addition to all these facilities, its greatest advantage
    is that it provides developer''s workflow [14]. Thus, Docker Containers-as-a-Service
    (CaaS) platform empowers developers and sysadmins to build, ship and run distributed
    applications anywhere [15]. Docker recently launched its distributed system development
    tool called Swarm, which extends the Docker Container-based system development
    process on multiple hosts in multiple clouds. Virtualization is a well-established
    technology in the development of cloud-based distributed systems [1]–[3], [16],
    [17]. Whereas dockerization is an effective system development tool and now gaining
    popularity in the software development community [10]–[14]. Docker Swarm-based
    containerized distributed system is a brand new approach and needs to be compared
    with virtualized distributed system. The selection of one of the technology for
    building distributed system is a difficult task. Therefore, this paper presents
    the simulation and evaluation of the development of a distributed system using
    virtualization and dockerization. This simulation is based on Docker Swarm, VirtualBox,
    Ubuntu, Mac OS X, nginx and redis. To simulate and evaluate the distributed system
    in the same environment, all Swarm Nodes and Virtual Machines are created using
    VirtualBox on the same Mac OS X host rather than on multiple hosts in multiple
    clouds. For making this evaluation rational, almost similar system resources are
    allocated to both at the beginning. Subsequently, similar servers nginx and redis
    are installed on the Swarm Node and Virtual Machine. Finally, based on the experimental
    simulation results, it evaluates their required resources and operational overheads;
    thus, their performance and effectiveness for designing distributed systems. The
    remainder of this paper is organised as follows: Section II explains the theoretical
    background of Virtualization and Dockerization techniques; Section III exhibits
    the actual implementation of Dockerization on a non-Linux machine (e.g., Mac OS
    X machine in this implementation) and how it differs from the Linux-based implementation;
    Section IV presents a simulation of the distributed system using Docker Swarm
    Nodes and Virtual Machines; Section V evaluates Virtualization and Dockerization
    techniques for the development of distributed systems based on the experimental
    simulation results. Section VI concludes the paper and suggests some future areas
    of extension. SECTION II. Virtualization and Dockerization This section presents
    the theoretical background of virtualization and dockerization. A. Virtualization
    Virtualization technique allows a user to create a virtual version of a device
    or resource, such as a server, storage device, network or operating system. It
    is an abstraction of the computer hardware that facilitates a single machine to
    act as if it where many machines. Virtualization framework divides the resource
    into one or more execution environments [18]. It enables multiple operating systems
    to run on the same physical platform. Virtualization is a combination of software
    and hardware engineering that creates Virtual Machines (VMs) [19]. Generally,
    virtualization architecture has two main components: Virtual Machine Monitor (VMM)/Hypervisor
    and Virtual Machine (VM) as shown in Fig. 1. The VMM/Hypervisor is normally the
    software which runs the Virtual Machine (VM)/Guest Computer. The VMM is the control
    system within the virtualization technology [19], and translation system between
    VMs and hardware infrastructure. VMM/Hypervisor can be classified into two types:
    Type 1 or bare metal hypervisor and Type 2 hypervisor. Type 1 runs directly on
    the hardware of the host without the need of a host operating system. Whereas,
    Type 2 runs on top of a host operating system and then spawns higher level Virtual
    Machines. A Virtual Machine (VM) is a self-contained operating environment that
    behaves as if it is a separate computer. Generally, every Virtual Machine has
    its own operation system, binaries, libraries and applications as shown in Fig.
    1. Virtualization technique requires substantial bandwidth, storage and processing
    capacities. A large server or desktop is needed, if it is going to host multiple
    running Virtual Machines [20]. There are so many popular virtualization technologies
    available such as VMWare, VirtualBox, Parallels, QEMU, UML and Xen. In the rest
    of the paper, virtualization and Virtual Machine terminology represent the Type
    2 hypervisor category because this architecture is comparable to dockerization
    architecture. B. Dockerization Containers provide an isolated environment akin
    to virtualization but without virtual hardware emulation [9]. The concept of a
    Container is quite old in computing, however, they were never employed at large-scale.
    Containers run in user space on top of an operating system''s kernel; therefore,
    Container virtualization is known as OS-level virtualization [21]. Container technology
    allows multiple isolated user space instances to be run on a single host [21].
    Containers can also be classified into two categories System Containers and Application
    Containers. A System Container is similar to a full OS and runs all process such
    as init, inetd, sshd, syslogd, and cron. Whereas, Application Container only runs
    an application. Both types are useful in different circumstances [22]. There are
    many popular Container technologies available such as Open VZ, LXC, and Solaris
    Zones, systemd-nspawn, lmctfy, Warden [21], [22]. Docker technology is an example
    of Container virtualization, and its process is known dockerization. Fig. 1. Virtualization
    and virtual machine Show All Docker is an open-source engine that automates the
    deployment of applications into Containers [21]. It is developed by Docker, Inc.,
    which was previously known as dotCloud, Inc. that was one of the pioneering company
    in Platform-as-a-service market. Docker provides an isolated Container (see Fig.
    2) based on a major Linux kernel feature known as cgroups and namespace. Consequently,
    each Container can have strong isolation, own network stack, storage stack, file
    system and resource management capabilities to allow friendly co-existence of
    multiple Containers on a single host [21]. A Container does not have its own operating
    system as it shares the same kernel; however, it contains all binaries and libraries
    to run an application inside it as shown in Fig. 2. Docker Swarm Distributed applications
    need distributed system and compute resources on it. Docker Swarm is a clustering
    and scheduling tool, which offers functionalities to turn a group of Docker Nodes
    into a virtual Docker System [23]. It builds a cooperative group of systems that
    can provide redundancy if one or more nodes fail. Swarm provides workload balancing
    for Containers. It assigns Containers to underlying nodes and optimizes resources
    by automatically scheduling Container workloads to run on the most appropriate
    host with adequate resources while maintaining necessary performance levels [24].
    An IT administrator or developer controls Swarm using a swarm manager, which organises
    and schedules Containers. The swarm manager allows them to create a primary manager
    instance and multiple replica instances in case the primary instance fails [24].
    Fig. 2. Dockerization and docker container Show All SECTION III. Dockerization
    on Non-Linux Machine (Mac OS X Machine) The previous section has explained the
    Docker architecture, but that was mostly for Linux-based machines, where the host
    Linux OS also plays a part of Docker Host. This section reveals the actual implementation
    of Docker Containers on a non-Linux machine (e.g., Mac OS X machine) and how it
    differs from the Linux-based implementation. It is important to know about this
    implementation because this paper examines Docker on Mac OS X machine. In non-Linux
    OS-based systems, Docker needs an additional component called Docker Host as shown
    in Fig. 3. Essentially, Docker Host is a lightweight Virtual Machine, which requires
    very few resources and operational overheads. In a Mac OS X installation, the
    Docker Engine runs inside a Linux VM called “default”. The “default” is a lightweight
    Linux Virtual Machine made specifically to run the Docker engine on a non-Linux
    machine (e.g., Mac OS X machine). The great success of Docker is this small Virtual
    Machine, which runs completely in RAM and loads only in few seconds. This is largely
    due to its very small size (i.e., 35 MB in this implementation). Finally, the
    detailed architecture is shown in Fig. 3, which will be utilised in this experimental
    simulation. Fig. 3. Dockerization and docker container for non-linux machine (Mac
    OS X machine) Show All SECTION IV. Experimental Simulation: Development of a Distributed
    System Using Virtualization and Dockerization This simulation is based on Docker
    Swarm, VirtualBox, Ubuntu, Mac OS X, nginx and redis. To simulate and evaluate
    the distributed system in the same environment, all Swarm Nodes and Virtual Machines
    are created using VirtualBox on the same Mac OS X host rather than on multiple
    hosts in multiple clouds. A. Experimental Simulation: Development of a Distributed
    System Using Dockerization This simulation demonstrates the development of a distributed
    system using dockerization. In this simulation, a sample distributed system is
    developed using Docker Swarm, nginx and redis. This distributed system is implemented
    as a cluster of four Swarm Nodes (Virtual Machines) on the same host computer
    to measure the performance in the same environment. However, this simulation can
    be implemented and extended to develop the distributed system on Docker supported
    multiple clouds such as Amazon Web Services, Microsoft Azure, Digital Ocean, Exoscale,
    Google Compute Engine [25]. The complete system development process is carried
    out on Mac OS X, therefore, it uses the non-Linux architecture of dockerization
    technology. Fig. 4 shows the experimental architecture of the distributed system
    using Docker Swarm Nodes. Initially, Docker is running in the lightweight Virtual
    Machine called “default” as shown in Fig. 5. For creating a Swarm cluster of nodes,
    the first step is to create a Docker Swarm image as shown in Fig. 6, which can
    be used as a discovery token to connect all nodes within the Swarm cluster. This
    simulation uses the Docker Hub based token discovery service. Fig. 4. Docker swarm
    architecture implemented in the simulation Show All Fig. 5. Docker engine running
    in “default” virtual machine Show All Now use this Swarm image token to create
    all Swarm Nodes including Swarm Master in VirtualBox as shown in Fig. 7. In this
    simulation, Oracle VirtualBox driver is used, however, any other Docker supported
    driver can be used. Docker currently supports many virtual and cloud environments
    as a driver such as Amazon Web Services, Microsoft Azure, Digital Ocean, Exoscale,
    Google Compute Engine, Generic, Microsoft Hyper-V, OpenStack, Rackspace, IBM Softlayer,
    VMware vCloud Air, VMware Fusion, VMware vSphere [25]. In this distributed system,
    one Swarm master and three Swarm nodes are created as shown in Fig. 7. These Swarm
    nodes can be managed on different clouds by just changing the driver name to the
    desired cloud name from the above list in Fig. 7. Once all Swarm nodes are created
    and running, they can be seen in VirtualBox Manager as shown in Fig. 8. For this
    Swarm cluster up and running, next step is to set the environment variable as
    shown in Fig. 9. Now all the Swarm nodes and their details can be checked using
    the command shown in Fig. 9. Fig. 6. Creating docker swarm image for using as
    a service discovery token Show All Fig. 7. Creating docker swarm master and worker
    nodes Show All Fig. 8. Docker swarm master and worker nodes in virtualbox manager
    Show All Making this Swarm cluster as a working distributed system, it requires
    certain servers to be installed such as nginx and redis in this implementation.
    Here, two servers nginx and redis are started as two separate Containers on each
    Swarm nodes. This typical configuration is just to demonstrate the scheduling
    and scaling features of Swarm, however, in a real system, only one server can
    be used. Firstly,nginx servers are started on all the Swarm nodes as shown in
    Fig. 10. All these nginx Containers are automatically allocated by Swarm-agent
    to different Swarm nodes. Finally, redis servers are started on all the Swarm
    nodes as shown in Fig. 11. Again, all these redis Containers are automatically
    allocated by Swarm-agent to different Swarm nodes. Now the list of all the running
    Containers with nginx and redis servers on different Swarm nodes is given in Fig.
    12. This Docker Swarm-based distributed system can be used to develop distributed
    applications in the cloud environment. Fig. 9. Setting environment for swarm and
    listing details of all the nodes Show All Fig. 10. Running containers with nginx
    server on all the swarm nodes Show All Fig. 11. Running containers with redis
    server on all the swarm nodes Show All Fig. 12. All the running containers with
    redis and nginx servers on all the swarm nodes Show All B. Experimental Simulation:
    Development of a Distributed System Using Virtualization This simulation is similar
    to the dockerization-based simulation with an almost similar environment for making
    a rational comparison between the two technologies. Here, the similar distributed
    system is developed using VirtualBox, Ubuntu, nginx and redis. This distributed
    system is implemented as a cluster of four Virtual Machines on the same host computer
    to measure the performance in the same environment. However, this simulation can
    be implemented and extended to develop the distributed system on multiple clouds
    in the same way. The complete system development process is carried out on Mac
    OS X, and its experimental architecture using virtualization technology is shown
    in Fig. 13. The creation process of a Virtual Machine in VirtualBox is relatively
    very easy and well known, therefore, it is omitted here. Once it is created, it
    can be seen in VirtualBox Manager as shown in Fig. 14. All the Virtual Machines
    are configured with Ubuntu Operating System (OS) to create the similar environment
    for both technologies. Next step is to install nginx server on this Ubuntu-based
    Virtual Machine1 as shown in Fig. 15. Subsequently, another redis server is installed
    on this Ubuntu-based Virtual Machine1 as shown in Fig. 16. Similarly, all the
    Virtual Machines (2,3,4) can be easily created and required software can be installed.
    All the four Virtual Machines (1,2,3,4) are shown in Fig. 17. Within this Virtual
    Machine-based distributed system, cooperation and application development would
    be similar to a stand alone machine-based activity and one Virtual Machine can
    be promoted to the master or domain controller to coordinate all other machines.
    This process is well known and thoroughly explained in literature [26], [27].
    Fig. 13. Virtual machine architecture implemented in the simulation Show All Fig.
    14. Created virtual machine1 in virtualbox manager Show All Fig. 15. Installing
    nginx server on ubuntu-based virtual machine1 Show All SECTION V. Experimental
    Results and Evaluation of Virtualization and Dockerization Technologies for the
    Development of a Distributed System Designing distributed systems in the cloud
    using virtualization and dockerization is a wide topic and includes several QoS
    parameters such as resource and operational overheads, scalability, portability,
    interoperability, isolation, inter-communication and security [13], [22], [28].
    This paper mainly focuses on the system performance and operational overheads
    of Docker Swarm Node-based and Virtual Machine-based distributed systems. Therefore,
    only limited simulation is carried out for obtaining relevant results related
    to required resources and operational overheads. These parameters are recorded
    during the each simulation process. Table I shows system configurations for Swarm
    Nodes and Virtual Machines, which exhibits that the equal system resources are
    allocated for building the similar size of Swarm Node and Virtual Machine for
    making this comparative evaluation rational. Table II shows the average results
    obtained from both experimental simulations. Overall results in Table II illustrate
    that dockerization has consumed fewer resources and operational overheads as compared
    to virtualization. The dockerization-based distributed system utilised less memory,
    storage, CPU usage, CPU time, boot time and energy within the same Linux-based
    environment. Fig. 16. Installing redis server on ubuntu-based virtual machine1
    Show All Fig. 17. Four virtual machines in virtualbox manager Show All Memory
    is one of the most important metrics for the measurement of the performance of
    virtualization and dockerization. Docker Swarm Node has better memory usages as
    compared to Virtual Machine. The Docker Swarm Node is mostly used to run Application
    Container and a single process in it [22]. A standard Docker Container can only
    run a process CMD command and all processes that it spawns [29]. As an Application
    Container, unlike OS, it does not waste memory on redundant management processes
    [22]. However, an Application Container could not run several important system
    services automatically, and this gradually increases extra overheads to start
    these services and impediments in the system development at a later stage [29].
    Alternatively, a full Linux OS runs all kinds of important system services by
    default, which are required for the effective system development process in any
    application area. Storage is another crucial metric to determine the performance
    of virtualization and dockerization. A similar result is obtained for this metric,
    and the Docker Swarm Node is very compact requiring less storage. The main reason
    for higher storage overheads in the virtualization-based development process is
    due to the large size of the base image because it is a full OS image. Whereas,
    Docker Swarm Node needs a very small size of the base image as it comes with bare
    minimum features. This large image size in virtualization causes the problem of
    large system/application image which is difficult to implement or deploy [30].
    This is one of the reasons of the popularity of the compact Docker Swarm Node
    among the software community. Indeed, this issue is not a big issue and can be
    easily resolved in virtualization. While maintaining the full functionality of
    Linux OS, the base image size can be reduced in virtualization by using relatively
    smaller Linux distros such as TinyCore, Lubuntu, LXLE, MX Linux, Porteus, Slitaz,
    Vector Linux, Absolute Linux and Puppy Linux depending on the requirement of the
    distributed system [31]. Another decisive performance metric is CPU usage and
    time; again the Docker Swarm Node has achieved better performance results over
    the Virtual Machine. Therefore, Docker Container is beneficial for CPU intensive
    application. However, Docker Container is a locked down environment with no direct
    access to many kernel resources; and it contains multiple abstraction layers.
    Consequently, large I/O and network usage may consume more resources because of
    Docker-related abstraction layers demanding significant context switching between
    kernel and userspace [32]. Similarly, depending on the nature of an application,
    virtualization can be beneficial or expensive. Initial boot time of virtualization
    can also be reduced automatically if the lightweight version of Linux is used
    in the distributed system. While evaluating the other non-functional properties
    for both, Docker Swarm has inbuilt features of scheduling, load balancing, discovery,
    availability and networking that help it to act as a natural distributed system,
    which are demonstrated in the simulation. The token discovery services are shown
    in Fig. 6 [33]; scheduling, load balancing, and availability characteristics are
    shown in Figs. 10 to 12, where Docker Swarm managed eight Containers automatically.
    Whereas, Virtual Machines are completely independent from each other and, therefore,
    as a stand-alone machine, they require extra/external provision to coordinate
    and act as a distributed system similar to the Swarm-based distributed system.
    This would be an initial advantage of Docker Swarm over on Virtual Machine. However,
    when comparing security and privacy, Containers may be less secure than Virtual
    Machines as they share kernel resources and application libraries on the same
    virtual host, and the Virtual Machine has the advantage of having hardware isolation
    [34]–[36]. However, in the near future, Docker Container can be made more secure
    using the traditional OS security mechanism to lock down the environment inside
    a Container. This particular evaluation outlines the requirement of fewer resources
    and overheads for the Docker Swarm-based distributed system as compared to Virtual
    Machine-based distributed system. However, it can not be taken as a general guidance
    for all kinds of system. The main limitation of this simulation is that it is
    a very small system and may not reflect the requirements of a wide range of systems.
    Therefore, the use of virtualization and dockerization can be determined precisely
    depending on the need of a specific system. Despite Docker Swarm has demonstrated
    better performance, its Containers and images can be run only under dockerized
    GNU/Linux, and an application has to be Docker locked-in. Additionally, it is
    supported by a handful number of cloud computing corporations. Finally, dockerization
    technology is mainly focused on PaaS (Platform-as-a-Service), and its prime objective
    is the deployment of distributed systems (software/applications) with portability
    and interoperability while utilising operating systems (OS) virtualization principles
    [37], [38], [26]. Virtualization technology is mainly focused on IaaS (Infrastructure-as-a-Service),
    and its prime objective is the deployment of distributed systems (hardware provisioning/allocation
    and management) while utilising hardware virtualization principles [27], [37].
    Table I. System configurations for the virtual machine and docker swarm node of
    distributed system Table II. Resources and operational overheads for the virtual
    machine and docker swarm node of distributed system SECTION VI. Conclusion This
    paper presented the simulation and evaluation of the development of a distributed
    system using virtualization and dockerization. This simulation was based on Docker
    Swarm, VirtualBox, Ubuntu, Mac OS X, nginx and redis. To simulate and evaluate
    the distributed system in the same environment, all Swarm Nodes and Virtual Machines
    were created using VirtualBox on the same Mac OS X host. For making this evaluation
    rational, almost similar system resources are allocated to both at the beginning.
    Subsequently, similar OS environment, and servers nginx and redis are installed
    on Swarm Node and Virtual Machine. Finally, based on the experimental simulation
    results, it evaluated their required resources and operational overheads; thus,
    their performance and effectiveness for designing distributed systems. The overall
    result showed that the Docker Swarm-based distributed system consumed fewer resources
    and operational overheads as compared to the Virtual Machine-based distributed
    system. Additionally, Docker Swarm has inbuilt features of scheduling, load balancing,
    discovery, availability and networking that help it to act as a natural distributed
    system. Whereas, Virtual Machines are completely independent from each other and,
    therefore, as a stand-alone machine, they require extra/external provision to
    coordinate and act as a distributed system similar to Docker Swarm. However, this
    result is based on the simulation of a very small distributed system and may not
    cover the requirements of a wide range of distributed systems. Therefore, the
    use of virtualization and dockerization can be determined precisely depending
    on the need of a specific type of system. In the future, it may be interesting
    to simulate and evaluate dockerization and virtualization technologies in the
    cloud, while using some most lightweight Linux operating systems on the Virtual
    Machine. Authors Figures References Citations Keywords Metrics More Like This
    CloudDVMM: Distributed Virtual Machine Monitor for Cloud Computing 2013 IEEE International
    Conference on Green Computing and Communications and IEEE Internet of Things and
    IEEE Cyber, Physical and Social Computing Published: 2013 Lightweight Virtualization
    Approaches for Software-Defined Systems and Cloud Computing: An Evaluation of
    Unikernels and Containers 2019 Sixth International Conference on Software Defined
    Systems (SDS) Published: 2019 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved.'
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: null
  publication_year: 2016
  relevance_score1: 0
  relevance_score2: 0
  title: 'Migrating from Virtualization to Dockerization in the Cloud: Simulation
    and Evaluation of Distributed Systems'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1007/978-981-13-1501-5_12
  analysis: '>'
  authors:
  - Anuj Kumar Yadav
  - M. L. Garg
  - . Ritika
  citation_count: 25
  full_citation: '>'
  full_text: '>

    Your privacy, your choice We use essential cookies to make sure the site can function.
    We also use optional cookies for advertising, personalisation of content, usage
    analysis, and social media. By accepting optional cookies, you consent to the
    processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Log in Find a journal
    Publish with us Track your research Search Cart Emerging Technologies in Data
    Mining and Information Security pp 141–150Cite as Home Emerging Technologies in
    Data Mining and Information Security Conference paper Docker Containers Versus
    Virtual Machine-Based Virtualization Anuj Kumar Yadav, M. L. Garg & Ritika  Conference
    paper First Online: 02 September 2018 1714 Accesses 23 Citations Part of the book
    series: Advances in Intelligent Systems and Computing ((AISC,volume 814)) Abstract
    Cloud computing is a paradigm based on IT that enables ubiquitous access to large
    pools of configurable resources which can be shared (such as computer networks,
    servers, storage, applications, and services) and rapidly provisioned with least
    effort. Cloud computing implementation in traditional ways is done using virtual
    machines, but nowadays a new concept of Docker containers is also gaining popularity
    due to its features. Containerization in some cases is treated as lightweight
    virtualization technique. Virtualization is used by cloud computing environments
    and data centres to disassociate the tools and applications from the underlying
    hardware. To validate this, hardware virtualization and OS-level virtualization
    is used. Apart from virtualization, a new technique is, containers, gaining popularity
    and many cloud-based deployments are using this technique. In this paper, both
    of these technologies are compared such that end-user can use these according
    to the requirement to get benefitted. Keywords Container Docker engine Hypervisor
    VMs Access provided by University of Nebraska-Lincoln. Download conference paper
    PDF 1 Introduction Cloud computing provides many benefits to end-users on the
    basis of basic characteristics it poses. The characteristics include elasticity,
    availability, on-demand self-service, and scalability. Due to these, various users
    from different domains like industry, business, and other application hosting
    agencies are increasingly adopting cloud-based services. Cloud implementation
    is totally based on the virtualization that is used to obtain elasticity of large
    pool of shared resources. There are many benefits of using virtualization like
    it provides flexibility of allocating the physically available resources to visualized
    applications and the entire task is done dynamically. In addition to this, virtualization
    also helps in multi-tenancy that allows more than single resource instances of
    virtualized applications to share the same physical resource. Multi-tenancy also
    helps the data centres to integrate applications into small server that reduces
    the operating cost. Virtualization also provides scalability and replication of
    applications [1]. Virtual machines (VMs) have been the central part of the cloud
    computing that acts as infrastructure layer which is used to provide operating
    system virtualization. With the help of virtual machines, various cloud services
    can be provided to end-users such as infrastructure, platform, and software. VMs
    basically create illusion that user is working on a machine that is dedicated
    to him/her. All the peripheral devices are also emulated using the virtualization.
    Virtual machine provides user a complete operating system to work upon where user
    can use various application software. We can treat virtualization as an additional
    layer between the operating system and user [2]. A Docker container is a similar
    concept like virtual machines but it is lightweight in terms of time consumption
    and resource needs. They have been suggested as a solution for more interoperable
    application packaging in the cloud. Containers and host share the same kernel;
    that is why they are called lightweights as compared to virtual machines (VMs)
    that have an additional layer of isolation. In a container, almost all the components
    (software and hardware) are shared between the applications and host OS. Isolation
    among the application is provided by the host operating system itself [3]. Container
    generally is a package that includes multiple applications as well as dependencies
    associated with these applications, and the package can be made shareable to the
    users. Along with the shareable feature, containers can be used in variety of
    cloud deployment models whether it is public cloud or private cloud. In addition
    to this, it helps in reducing the management overhead as a single OS needs to
    be managed. A limitation in some cases arise in terms of OS compatibility due
    to availability of shared kernel; in other words, we can say no Linux container
    can be used on Windows-based host OS and vice versa [4]. Both cloud implementation
    techniques are based on virtualization but handle different kind of problems and
    provide solution to them. The little difference is that virtual machines are more
    suitable for hardware allocation and hardware management, and containers are more
    suitable tools for software delivery or we can say prime focus is on PaaS. So
    both of these are task-specific like for portable applications in the cloud computing
    we need a lightweight distribution of application package for development and
    deployment and virtual machines are preferred [1, 5]. 2 Paper Organization The
    rest of the paper is organized as follows. In Sect. 3, basics of virtual machines
    have been discussed. In Sect. 4, Docker containers’ working and basics have been
    discussed. In Sect. 5, these two virtualization techniques are compared, and finally,
    the paper concludes in Sect. 6. 3 Virtual Machines All the virtual machines are
    managed and controlled by virtual machine managers. These are generally termed
    as VMM or hypervisor, and their main focus is to provide abstraction to the underlying
    hardware. The system on which VMM is installed or run is termed as host machine,
    and all other virtual machines running inside the host machine are termed as guest.
    Both host and guest use almost same interface for using the different applications.
    Host machine and all the available guest machines running on host machine are
    independent of each other [6]. There are various hypervisors provided by different
    organizations. These hypervisors are capable of controlling the hardware and create
    a secure virtualized environment for users to work upon. These hypervisors can
    be divided into two categories: Type 1 and Type 2. Type 1 hypervisors basically
    run on the top of system hardware, and due to this, they are named as native virtual
    machine. In other way, we can say this Type 1 hypervisor takes the place of OS
    and they can directly access the available hardware for their use. Type 1 hypervisors
    have one favour that if any virtual machine fails or does not respond for any
    reason then other guest OS does not get affected. Type 1 runs in kernel mode and
    because of which has exclusive physical CPUs. Examples of Type 1 hypervisors are
    Microsoft Hyper-V, VMware ESXi Server, Citrix/Xen Server, etc. On the other side,
    Type 2 hypervisors run within the OS installed on top of hypervisor or in other
    words we can say they are just like any other application software which runs
    under OS. Type 2 hypervisors are also known as hosted virtual machines. Examples
    of Type 2 hypervisors are Microsoft Virtual PC, VMware Workstation, and Oracle
    Virtual Box, etc. [7]. 3.1 Virtual Machine Benefits There are several benefits
    of using virtual machines; some of the benefits are as follows: As there are many
    virtual machines running on a single host machine, they have their own basic security
    zones which cannot be accessible via other virtual machines. In addition to this,
    there is one security layer of hypervisor as well, so we can say there are many
    security zones available to provide the security [8]. In virtual machines, all
    the OS are isolated as well as their applications. This isolation provides better
    separation between the application and various activities of operating systems.
    Virtualization provides better resource utilization and improved performance as
    compared to traditional systems. All the underutilized resources can be used in
    much more efficient way by using virtualization. Virtualization provides better
    fault-tolerant environment as compared to traditional systems as if there is any
    server failure due to any reason, there are other servers that are available to
    work upon. Virtualization also reduces the many server requirements as it can
    be implemented using various virtual machines. Process migration is one of the
    major advantages provided by the virtual machines. Processes can be migrated at
    run-time from high-loaded virtual machines to less-loaded virtual machines. This
    process migration helps in saving of energy and balancing of loads. Another advantage
    is that due to this migration, no activity got disrupted. Traditional data centres
    generally have large pool of computing resources, and with the increasing demand,
    the capacity of various resources also needs to match. Due to this, large amount
    of energy is required to operate those systems as well as to keep them cool. With
    the use of virtual machines, the requirement can be minimized and resource utilization
    becomes efficient. And most importantly, this is also helpful for the environment.
    3.2 Limitation of Virtualization Apart from various benefits as discussed, there
    are several issues as well that needs to be taken into consideration while opting
    for virtual machine-based solution. Virtual machines generally share their data
    and interact with each other, so if the communication is not secure, then it can
    be exploited by the attacker and which in turn leads to security-based attack.
    Like other technologies, virtualization also has possibilities of attacks due
    to vulnerability like buffer overflow. There is a single point of failure in Type
    1 hypervisor as there exists a single hypervisor. If hypervisor stops working,
    then the entire system gets affected. While using virtualization in cloud computing,
    one data needs to be stored far away from the local machine, and also data generally
    moves time-to-time from one tenant to another tenant. This movement leads to concern
    of leakage of data, and it can be a risk from security point of view [9]. As Internet
    connection is the basic requirement of virtualization-based cloud computing, it
    can lead to various kinds of security risks. In cloud-based virtualization, user
    data always resides on cloud server, so user is always concerned about security
    of his/her data. 4 Docker Containers Docker is an open-source project that is
    used for automation in a systematic way for fast deployment of applications running
    under a container. Docker engine is required to run the Docker containers like
    VM runs inside hypervisor. Containers are a more lightweight virtualization concept,
    i.e. less resource- and time-consuming [10, 11]. They can be seen as more flexible
    tools for packaging, delivering, and orchestrating both software services and
    applications. Containers are built on recent advances in virtualization and therefore
    allows for better portability and interoperability while still utilizing operating
    systems’ virtualization techniques [12]. Docker container is just like a directory.
    It contains all the things that are required for an application. In containers,
    isolation is done at kernel level. Docker is a platform that is used to design,
    deploy, and run various applications. With the help of Dockers, applications can
    be isolated from the available infrastructure and user can view the infrastructure
    as a managed application [13]. In recent times, OS-based virtualization gained
    popularity in terms of software to run predictably and transferring from one environment
    to other. By using the containers, all these isolated systems can be run on a
    single host operating system. Containers lie on top layer over a server and its
    host operating system. Operating system can be Windows or Linux or any other operating
    systems. Every container not only shares the host OS but also the libraries and
    binary files as well that are required for application to run. All the shared
    components are generally read-only, and due to this, containers are lightweights,
    just some Mb in size. As the containers are less in size, they need few seconds
    to start up. By using the Dockers, jobs of application developers and system administrators
    become simple [14]. 4.1 Different Container Models There are different containers
    models or we can say delivery models according to the different operating systems.
    Few of them are listed as: Linux: Docker, LXC Linux containers, OpenVZ, Windows:
    Sandboxie, Cloud PaaS: Warden/Garden (in Cloud Foundry), LXC (in Openshift). 4.2
    Need for Containers By the invention of virtual machines, various issues related
    to cloud computing like scheduling, packaging, resource management have been resolved.
    As the applications can be made isolated with the help of virtual machines, due
    to this security can be improved [15]. Cloud needs to answer the requirements
    of application management and packaging. Containers can give solution to these
    requirements in efficient way. A container is a package that contains ready-to-deploy
    application parts, business logic, and middleware as shown in Fig. 1 [16]. Fig.
    1 Architecture comparison of virtual machines and hypervisors Full size image
    Containers are highly scalable and safe to use. These are easy to deploy when
    we compare it with the virtual machines. So we can say Docker is an open-source
    platform that helps users and programmers to isolate application dependencies.
    5 Containers Versus Virtual Machines Both of these technologies generally provide
    an illusion that a single host machine can be used to run multiple machines. All
    of these machines running under the host machine need to be isolated from one
    another and also from the host machine. The difference comes in that how both
    of these technologies are able to achieve isolation between the different machines.
    A brief difference is shown in Fig. 2[17], according to which we can say that
    containers generally are executed on host OS and virtual machines run on hypervisor.
    A container engine is generally combined with the kernel of the host OS. Fig.
    2 Virtual machines versus hypervisors Full size image Further, both of these can
    be compared based on certain factors like: Operating System Support: As per the
    architecture for both the virtual machine and Docker containers, the operating
    system support differs. A virtual machine contains a host OS which is able to
    run multiple guest OS inside different virtual machines, whereas containers need
    to be hosted on a single server that contains a shareable OS. The guest OS can
    be anything irrespective of the available host OS. On basis of this, we can say
    that both of these technologies can be used in different situations according
    to the requirement. If one wants to run many applications on a single OS kernel,
    then Dockers need to be preferred, and when user has many applications that need
    support of different operating systems, then virtual machines should be preferred.
    As the host OS is shared between the containers, it leads them to boot in very
    short span of time. So we can say maintenance overhead of containers is less than
    virtual machines [17]. Host/Guest Architecture: Virtual machine provides the facility
    to run the guest kernel that is different from the host kernel; that is not possible
    with containers as kernel needs to be shared. Booting: Booting started as it starts
    in normal operating system, and the speed depends on the applications. Containers
    can start up rapidly when we compare it with virtual machines as they are less
    resource-centric. Standardization: Virtual machines are generally like a complete
    standard operating system having all the features. On the other hand, containers
    are more application-specific [18]. Portability: Docker containers are the separate
    package which can run the needed application. As Dockers do not contain any separate
    operating system, so applications can be ported out easily across various platforms
    which is not possible in case of virtual machines. Containers can be switched
    on and off within seconds, much faster than that of virtual machines, because
    of their lightweight nature. Due to this feature, containers can be easily deployed
    on the servers. Virtual machines on the other side are separate server instance
    that is isolated with their operating system. It is not possible to port the virtual
    machines across various platforms due to compatibility issue. So we can say for
    the developers where application development is the primary focus, Docker containers
    need to be preferred. Need of Servers: Multiple server requirements in Dockers
    are not as much as compared to virtual machines. As Dockers are lightweight and
    contain only the applications, there is no need of multiple servers. These applications
    can run on a single physical server. But if user needs to run multiple applications
    on different server instance and these servers need specific operating system,
    then the user needs the virtual machines. Virtual machines contain all the necessary
    library files, supporting files, and most importantly the entire operating system
    to work upon which is required by the particular application. So we can say lesser
    number of virtual machines can be accommodated to the same server if we compare
    it with the Dockers. As the number of virtual machines hosted on a single server
    is less than Dockers, we can say that the server density is lesser with virtual
    machines. Due to this feature, one can say that Dockers are cost-effective application
    hosting solution when we compare it with virtual machines. Performance Evaluation:
    Both of the virtualization techniques have their specific purposes so comparison
    of performance evaluation is not fair. But we can say as the containers are lightweight
    virtual architecture, they are less resource-intensive when we compare them with
    virtual machines. Due to this, start-up time of containers is very much less than
    that of virtual machines. Resource allocation in containers is not permanent as
    resource usage can vary with the load. Replication and elasticity are also much
    easier in containers in comparison with virtual machines as containers do not
    require a separate operating system. Security: Security can be an overhead in
    the case of Dockers, as the host kernel is shareable among all the containers,
    so a single vulnerable point can lead to hacking of entire server. Due to this
    security concern, superuser access to the applications and also running them with
    root user privileges are not recommended. While in the case of virtual machines
    such applications are run, those need more security and privilege. Apart from
    this as we know that each virtual machine runs under separate or its own operating
    system, due to which they can use their own security features and kernel features.
    Low Redundancy: Containers just need the applications to run on host operating
    system unlike virtual machines where entire operating system needs to install
    before proceeding. This results in lots of duplicity of various components. Thus
    on the basis of this, we can say that containers result in low redundancy when
    we compare them with the standard virtual machines. Hardware Access: Applications
    that run under the containers have direct access to the hardware, which is not
    possible with virtual machines. Resource Distribution: Containers generally require
    very less resources, only those which are required at that particular time, unlike
    virtual machines which require permanent resource allocation before start-up of
    virtual machines. So we can say resource distribution is optimal in case of containers
    [19]. Memory Usage: Virtual machines need complete operating system for each of
    the guest, due to which it requires large memory when we compare it with containers.
    Containers use less memory as it shares the host operating system. Files and Library
    Sharing: Each virtual machine has its own OS, which contains large number of files
    and libraries. These files cannot be shared between different virtual machines.
    On the other side, containers run under host OS, no separate OS is needed by each
    application. So files and libraries can be shared using Linux commands. All these
    differences are summarized in Table 1. Table 1 Virtual machines versus hypervisors
    Full size table 6 Conclusion and Future Scope In this paper, virtual machines
    are compared with containers on the basis of various parameters. Both the techniques
    are based on virtualization and solve specific purpose; in some cases virtual
    machines can be used and in some cases containers can be preferred. If the requirement
    is to provide high availability and scalability, then containers are more suited.
    If the requirement is to create secure system, then virtual machines need to be
    preferred. While working in heterogeneous environment, Docker containers focus
    on applications and dependencies associated with them, whereas flexibility can
    be achieved using the virtual machines. So we can say both of these technologies
    are not to replace one another but these can be used simultaneously depending
    upon the requirement of the user. While adopting these two technologies, we can
    say VM provides better IaaS solution (machine portability, security and greater
    isolation) and Docker provides better SaaS solution (application/software portability)
    to end-users. If one can build hybrid architecture, then it will surely benefit
    variety of users. References Ranjan, R.: The cloud interoperability challenge.
    IEEE Cloud Comput. 1(2), 20–24 (2014) Article   Google Scholar   Goldberg, P.:
    Survey of virtual machine research. IEEE Comput. 7(6), 34–45 (1974) Article   Google
    Scholar   Soltesz et al.: Container-based operating system virtualization: A scalable,
    high-performance alternative to hypervisors. ACM, 41, 275–287(2007) Google Scholar   https://www.taksatech.com/containers-vs-vms/
    Di Martino, B.: Applications portability and services interoperability among multiple
    clouds. IEEE Cloud Comput. 1(1), 74–77 (2014) Article   Google Scholar   Silberschatz,
    P.B. Galvin, Gagne, G.: Operating System Concepts, 9th ed. ch. 8.5, 16, pp. 366–377,
    711–740. ISBN: 978-1-118-06333-0, (2013) Google Scholar   http://www.golinuxhub.com/2014/07/comparison-type-1-vs-type-2-hypervisor.html
    Sarna, D.E.Y.: Implementing and Developing Cloud Computing Applications. Taylor
    and Francis Group, LLC (2011) Google Scholar   Almond C.: A Practical Guide to
    Cloud Computing Security (2009) Google Scholar   Scheepers, M.J.: Virtualization
    and Containerization of Application Infrastructure: A Comparison. In: Presented
    at the 21st Twente Student Conference on IT, Twente The Netherlands June 23 (2014)
    Google Scholar   Pahl, C., Lee, B.: Containers and clusters for edge cloud architectures-a
    technology re View (2015) Google Scholar   Ranjan, R.: The cloud interoperability
    challenge. IEEE Cloud computer. 1, 20–24 (2014) Google Scholar   https://docs.docker.com/introduction/understanding
    docker/ Merkel, D.: Lightweight linux containers for consistent development and
    deployment. Linux J. 239, 2 (2014) Google Scholar   Mao, M., Humphrey, M.: A performance
    study on the VM startup time in the cloud. In: 5th International Conference on
    Cloud Computing (CLOUD), IEEE, pp. 423–430. (2012) Google Scholar   Soltesz, S.,
    Pötzl, H., Fiuczynski, M.E., Bavier, A., Peterson, L.: Container-based operating
    system virtualization: a scalable, highperformance alternative to hypervisors.
    ACM SIGOPS Operating Systems Rev. 41(3), 275–287 (2007) Google Scholar   https://bobcares.com/blog/docker-vs-virtual-machines/
    Bernstein, D.: Containers and cloud: from LXC to Docker to Kubernetes. IEEE Cloud
    Comput. 1(3), 81–84 (2014) Article   Google Scholar   http://www.channelfutures.com/technology/docker-vs-virtual-machines-understanding-performance-differences
    Download references Author information Authors and Affiliations DIT University,
    Dehradun, 248001, India Anuj Kumar Yadav, M. L. Garg &  Ritika Corresponding author
    Correspondence to Anuj Kumar Yadav . Editor information Editors and Affiliations
    Machine Intelligence Research Labs, Auburn, WA, USA Ajith Abraham Department of
    Computer and Systems Sciences, Visva-Bharati University, Santiniketan, West Bengal,
    India Paramartha Dutta Department of Computer Science and Engineering, University
    of Kalyani, Kalyani, India Jyotsna Kumar Mandal Institute of Engineering and Management,
    Kolkata, West Bengal, India Abhishek Bhattacharya Institute of Engineering and
    Management, Kolkata, West Bengal, India Soumi Dutta Rights and permissions Reprints
    and permissions Copyright information © 2019 Springer Nature Singapore Pte Ltd.
    About this paper Cite this paper Yadav, A.K., Garg, M.L., Ritika (2019). Docker
    Containers Versus Virtual Machine-Based Virtualization. In: Abraham, A., Dutta,
    P., Mandal, J., Bhattacharya, A., Dutta, S. (eds) Emerging Technologies in Data
    Mining and Information Security. Advances in Intelligent Systems and Computing,
    vol 814. Springer, Singapore. https://doi.org/10.1007/978-981-13-1501-5_12 Download
    citation .RIS.ENW.BIB DOI https://doi.org/10.1007/978-981-13-1501-5_12 Published
    02 September 2018 Publisher Name Springer, Singapore Print ISBN 978-981-13-1500-8
    Online ISBN 978-981-13-1501-5 eBook Packages Intelligent Technologies and Robotics
    Intelligent Technologies and Robotics (R0) Share this paper Anyone you share the
    following link with will be able to read this content: Get shareable link Provided
    by the Springer Nature SharedIt content-sharing initiative Publish with us Policies
    and ethics Download book PDF Download book EPUB Sections Figures References Abstract
    Introduction Paper Organization Virtual Machines Docker Containers Containers
    Versus Virtual Machines Conclusion and Future Scope References Author information
    Editor information Rights and permissions Copyright information About this paper
    Publish with us Discover content Journals A-Z Books A-Z Publish with us Publish
    your research Open access publishing Products and services Our products Librarians
    Societies Partners and advertisers Our imprints Springer Nature Portfolio BMC
    Palgrave Macmillan Apress Your privacy choices/Manage cookies Your US state privacy
    rights Accessibility statement Terms and conditions Privacy policy Help and support
    129.93.161.219 Big Ten Academic Alliance (BTAA) (3000133814) - University of Nebraska-Lincoln
    (3000134173) © 2024 Springer Nature'
  inline_citation: '>'
  journal: Advances in intelligent systems and computing
  limitations: '>'
  pdf_link: null
  publication_year: 2018
  relevance_score1: 0
  relevance_score2: 0
  title: Docker Containers Versus Virtual Machine-Based Virtualization
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1016/j.future.2018.12.035
  analysis: '>'
  authors:
  - Ilias Mavridis
  - Helen D. Karatza
  citation_count: 67
  full_citation: '>'
  full_text: '>

    Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords 1. Introduction 2. Related work 3. Virtualization
    isolation 4. Performance evaluation 5. Use cases - Further study 6. Power consumption
    analysis 7. Conclusions References Vitae Show full outline Figures (44) Show 38
    more figures Tables (8) Table 1 Table 2 Table 3 Table 4 Table 5 Table 6 Show all
    tables Future Generation Computer Systems Volume 94, May 2019, Pages 674-696 Combining
    containers and virtual machines to enhance isolation and extend functionality
    on cloud computing Author links open overlay panel Ilias Mavridis, Helen Karatza
    Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.future.2018.12.035
    Get rights and content Highlights • We study the combination of virtual machines
    and containers in the cloud. • The benefits and drawbacks of this approach are
    presented. • The performance and energy consumption overhead are empirically evaluated.
    • The results show how various virtualization techniques and configurations affect
    the system. Abstract Virtualization technology is the underlying element of cloud
    computing. Traditionally, cloud computing has employed virtual machines to distribute
    available resources and provide isolated environments among users. Multiple virtual
    machines, with their own operating system and services, can be deployed and run
    simultaneously on the same physical machine on the cloud infrastructure. Recently,
    a more lightweight virtualization technology is being rapidly adopted and it is
    based on containers. A key difference between virtual machines and containers,
    is that containers share the same underlying operating system. In this work, we
    studied the combination of these two virtualization technologies by running containers
    on top of virtual machines. This synergy aims to enhance containers’ main drawback,
    which is isolation and, among others, to simplify the system management and upgrade,
    and to introduce the new functionalities of containerized applications to virtual
    machines. The benefits of this method have been recognized by big cloud companies,
    which have been employing this approach for years. With this paper, we aimed to
    present the advantages of running containers on virtual machines and to explore
    how various virtualization techniques and configurations affect the performance
    of this method. Although, in bibliography there are a few papers that used this
    method partially to conduct experiments, there is not any research which considers
    this method from our integral aspect of view. In this study, we ran Docker containers
    and evaluated their performances, not only on KVM and XEN virtual machines, but
    also we ran Linux containers on Windows Server. We adopted an empirical approach,
    to quantify the performance overhead introduced by the additional virtualization
    layer of virtual machines, by executing various benchmarks and deploying real
    world applications as use cases. Furthermore, we presented for first time, how
    isolation is applied on virtual machines and containers, we evaluated different
    operating systems optimized to host containers, mechanisms of storing persistent
    data and, last but not least, we experimentally quantified the power and energy
    consumption overhead of containers running on virtual machines. Previous article
    in issue Next article in issue Keywords DockerVMsContainersKVMXENHyper-VPerformance
    evaluationEnergy consumption 1. Introduction Cloud computing is a popular and
    commonly used computing paradigm. The core of cloud computing is the virtualization
    technologies that allow different users to independently access and share the
    same computing infrastructure. Cloud offers virtually unlimited resources that
    allow various services, such as log analysis [1], to scale on-demand and fulfill
    the growing user needs. Cloud providers adopt virtualization to improve resource
    utilization and management, to enhance security and portability, as well as to
    reduce the energy consumption and total cost of data centers [2], [3]. However
    all these come with a performance penalty, due to the additional overhead of the
    virtualization layer and the rise of system complexity. In cloud environment,
    there are two main virtualization technologies, a hardware-based and an operating
    system-based. In hardware-based technology, multiple virtual machines (VMs) can
    be deployed and co-exist on the same physical machine. A VM runs its own operating
    system (OS) and is isolated from other VMs that may be hosted on the same physical
    machine. VMs are the key element of Infrastructure as a Service (IaaS) cloud services
    and can be created on-demand by users. In the operating system-based model, containers
    share a single host OS and its depending libraries, drivers or binaries. Services
    can run in containers, in a fraction of the overhead introduced by VMs, due to
    lack of hardware abstraction. Containers can be described as tools for packaging,
    delivering and orchestrating software services and applications [4]. VMs and containers
    are complementary and place virtualization at different layers; therefore containers’
    main advantage is low performance overhead, whereas VMs offer strong isolation
    [5], [6]. In order to enhance security, extend functionality and promote an effective
    development process, we propose to combine VMs and containers by running containers
    on top of VMs. In case there is an acceptable performance overhead, there are
    several additional reasons to encourage running containers on top of VMs. For
    instance, by maintaining containers on top of VMs, the management and upgrade
    of the system become easier, and hardware–software incompatibilities of the physical
    server are overcome by the hardware virtualization layer. In this way, one can
    handle the lack of suitable hardware of a private cloud infrastructure or the
    necessity to use already existing infrastructure. Additionally, with this method,
    the majority of public cloud providers that offer VMs as products can be used
    to host container-based services. Big cloud provider companies, like Amazon Web
    Services, Microsoft Azure and Google Container Engine, have deployed containers
    on VM instances already [7], [8]. Also virtualization companies, like VMware,
    embraced this approach and even submitted related patent applications [9]. In
    this work, we extended our previous study [2] in the following various directions.
    First, we presented how isolation is enforced in various virtualization technologies
    and methods. Second, in order to create and manage VMs, except for KVM on Linux,
    we studied XEN on Linux and we also explored how Windows Server attains to create
    and run Linux containers, by exploiting the Hyper-V hypervisor. Third, whereas
    in our previous work we ran containers on popular server-oriented Linux OSes,
    like Ubuntu Server and CentOS, this time we deployed five different container-optimized
    Linux OSes and also Windows Server on a more powerful infrastructure. Fourth,
    we used a new set of benchmarks with various parameters and configurations to
    stress the system in several ways. Fifth, we deployed SQL and NoSQL database services
    as use cases to measure how the performance overhead, which is introduced by the
    additional virtualization layer of the VM, is affected by the type of workload,
    type of storage mechanism, number of VMs, number of containers and users. And
    finally, we gathered power data to quantify the energy consumption overhead for
    the whole system and CPU separately, for system in idle state and under stress.
    Our goal is to study and provide an insight into the isolation, performance and
    energy consumption of containers running on top of VMs. The remainder of this
    paper is organized as follows. Section 2 provides an overview of the related research.
    Section 3 presents virtualization techniques and how virtualization provides isolation.
    In Section 4 the experimental results are demonstrated and in Section 5 one can
    find the performance overhead results of our use cases. Section 6 presents power
    consumption overhead results. Finally, concluding remarks are presented in Section
    7. 2. Related work By reviewing the literature, we noticed that virtualization
    technologies is an interesting topic and subject of study for many papers. We
    also identified that VMs and recently containers do play a vital role in cloud
    computing and in other emerging distributed computing paradigms [10]. Overall,
    we recognized three main categories. First, there are studies that analyzed and
    compared different hypervisors (also called virtual machine monitors — VMMs).
    Second, there are studies that compared container-based virtualization technologies
    and finally there are studies where both VMs and containers are compared and in
    some cases combined. A performance comparison of VMware, XEN and Hyper-V hypervisors
    is presented by Abdellatief et al. [11]. They conducted various experiments with
    SQL workloads for numerous VMs and system loads. Their measurements showed that
    for light load, VMware had the highest SQL database performance (lower CPU utilization
    and Higher Order Per Minutes), then followed XEN and last came Hyper-V. For heavy
    load and higher number of VMs per hypervisor, VMware still had the highest SQL
    database performance but, in this case, the second higher performance was achieved
    by Hyper-V and lastly XEN. Also, they measured the host server CPU utilization
    and memory consumed by the VM(s). They found that for light load, XEN was the
    most efficient, followed by Hyper-V and then VMware. On the contrary, for higher
    load, the most efficient was Hyper-V, followed by VMware and XEN. Specifically
    in the case of XEN, the system’s memory reached 98% consumption and made the server
    respond rather slowly. Hwang et al. in [12] compared Hyper-V, KVM, vSphere and
    XEN. They concluded that the performance of each hypervisor can vary significantly,
    depending on the type of application, the workload and the resources assigned
    to each VM. Naussbaum et al. [13] studied the I/O performance of KVM and XEN.
    They found that, in some areas, one outperforms the other. In [14] the authors,
    based on KVM’s near-native performance and feature-rich experience, claimed that
    KVM is a better choice compared to XEN and Virtual Box. In [15] the three most
    widespread virtualization frameworks, XEN, KVM, and VMware ESXi were analyzed
    from a HPC perspective. Based on these hypervisors, they concluded that their
    virtualization layer introduces a substantial performance cost in every case.
    The performances of the three open source hypervisors: OpenVZ, XEN and KVM was
    measured and analyzed by Che et al. [16]. The authors took measurements, both
    as a black box and as a white box, for their macro and micro performances on the
    virtualization of the operating system. The experimental results showed that,
    for their setup, OpenVZ achieved the best performance. The container-based virtualization
    has been studied by Xavier et al. [17] who compared the Linux VServer, OpenVZ
    and Linux Containers (LXC) as container-based systems, by running MapReduce workloads.
    They found that all three systems reached a near-native performance for these
    workloads and had many management capabilities, such as performance isolation,
    checkpoint and live migration. However, it is not recommended to use containers
    for security isolation [7]. In [18] Docker containers were used in workflows.
    This way the authors observed a great reduction in required resources and they
    highlighted that it is possible for non-computer science experts to integrate
    third-party applications into new or existing workflows. In more recent years,
    researchers analyzed and compared both hypervisors and containers. Estrada et
    al. [19] benchmarked the KVM and XEN hypervisors, as well as LXC, based on sequence
    alignment software that arranges sequences of DNA. They identified the differences
    and similarities of the runtime performance of each virtualized environment mentioned
    and they compared their runtime against a physical server. Kozhirbayev et al.
    [20] used the NeCTAR Research Cloud to deploy Docker and Flockport (LXC) containers.
    The authors compared the performance of CPU, memory, network bandwidth and latency
    and storage overheads of these two container technologies to the performance of
    native NeCTAR Research Cloud instance. Their various experiments showed that there
    were roughly no overheads on memory utilization or CPU for both container technologies.
    Whereas, I/O and operating system interactions incurred some overheads. KVM hypervisor
    was compared to Docker container manager in [21]. The authors ran several benchmarks
    and took performance measurements for CPU, memory, storage, and networking. Their
    benchmark results showed that containers achieved equal or better performance
    than VMs in almost all cases. In [22] the authors made a similar analysis with
    [21] but they also studied LXC as a container-based solution and OSv as a new
    type of lightweight Guest OS. They concluded that the containers’ overhead is
    almost negligible, whereas the other virtualization methods provide higher security.
    Xavier et al. [23] presented the container-based virtualization as an alternative
    to hypervisors in HPC. They conducted several experiments and found that XEN was
    outperformed by container-based virtualization implementations, such as Linux
    VServer, OpenVZ and LXC in HPC environments. They also experimentally evaluated
    the trade-off between performance and isolation. The authors of [24] provided
    a performance comparison of KVM, XEN hypervisors and Docker on ARM architecture.
    The experimental results showed a slightly better performance for containers,
    however it was mentioned that hypervisors provide high isolation given by hardware
    extensions. In [25] the authors evaluated bare metal, VMs and Docker containers,
    that can be provisioned in OpenStack, in terms of CPU, networking, memory, disk
    I/O and boot-up times. Their evaluation showed that Docker hosts are characterized
    by the fastest boot-time and overall performance, similarly to those of bare metal,
    with network bandwidth being the only exception. The authors of [26] used a HTTP
    proxy scenario to provide a performance analysis of KVM and Docker. They evaluated
    the total time needed to perform HTTP requests and responses, when the proxy was
    running on both virtualization technologies and the physical server was under
    heavy CPU load. They found that a Docker container can be up to twice as fast
    as a KVM-based VM. In [27] Docker containers and VMs were deployed on Amazon cloud
    environment and their performances were analyzed in terms of throughput, response
    time and CPU utilization. The authors surprisingly found that VM-based web services
    outperformed container-based web services. As they pointed out, this happened
    mainly because Amazon cloud ran containers on top of EC2 VMs and not directly
    on bare metal physical hosts. Plauth et al. [28] compared the performances of
    Docker and LXD containers, Rumprun, OSv and MirageOS unikernels, as well as XEN
    and KVM hypervisors. They recognized that running containers on VM is a common
    practice in order to run containers on top of IaaS cloud. They evaluated the performances
    of Nginx and Redis containers for both running on bare metal and on VM. Their
    results showed that unikernels performed equally or better than containers. Finally,
    the performances and performance isolation of containers and VMs were studied
    in [29]. The authors conducted experiments and measured the performances overhead
    of KVM hypervisor and LXC containers. LXC achieved higher performance in almost
    all cases. It is worth mentioning that, in a small part of their experiments,
    they ran a LXC container on a KVM VM and evaluated its performance. 3. Virtualization
    isolation 3.1. Virtualization and isolation of x86 architecture Although big cloud
    providers examine the adoption of low-power ARM processors, today the x86 architecture
    is the leading processor architecture used in cloud [30], [31]. In x86 architecture
    there are three modes, the real, the protected and the virtual 8086 mode [32].
    The protected mode is the predominant one because it offers some key advantages
    compared to the others, for example it supports multitasking. The x86 architecture’s
    protected mode uses four privileged levels or rings, as it can be seen in Fig.
    1. The ring 0 is the most privileged level to run instructions within the processor,
    it can communicate with the hardware and it is used for kernel space. Ring 3 is
    the least privileged and only used by the OSes for user space. The intermediate
    rings 1–2 are usually not used by the majority of the OSes. x86 virtualization
    was introduced for the first time in 1998, by VMware [33]. They managed to combine
    binary translation and direct execution techniques on the processor, to run multiple
    isolated Guest OSes on the same hardware. In this approach, the hypervisor runs
    in ring 0 and the Guest OS in ring 1 Fig. 2. The hypervisor provides each VM with
    a complete simulation of the existing hardware, including virtualized memory management
    and virtual devices. The Guest OS is unmodified and unaware that it is running
    on a VM. Any privileged and protected CPU operation of the Guest OS is intercepted
    by the hypervisor, modified and executed in the underlying hardware. This technique
    is called full virtualization, does not require Guest OS modification, hardware
    or OS assistance and offers the highest isolation. Download : Download high-res
    image (131KB) Download : Download full-size image Fig. 1. x86 architecture privilege
    rings. Another virtualization technique which, in contrast to full virtualization,
    requires Guest OS modification, is called paravirtualization. In this technique
    the Guest OS is aware that it is running on a VM and its privileged operations
    are replaced by calls to the hypervisor (hypercalls), Fig. 3. The Guest OS can
    also make hypercalls for memory management, interrupt handling and other crucial
    operations [33]. Paravirtualization has lower overhead compared to full virtualization,
    due to the lack of binary translations, while the modified Guest OS communicates
    through hypercalls with the hardware. On the other hand, the Guest OS modification
    might introduce maintenance and compatibility issues. Download : Download high-res
    image (151KB) Download : Download full-size image Fig. 2. Full virtualization
    privilege rings. Last but not least, there is the hardware assisted virtualization
    technique. Although hardware assisted virtualization is originated from 1972 (IBM
    System/370) [34], hardware assisted virtualization for x86 CPUs became available
    in 2006 with Intel VT and AMD-V technologies. Intel and AMD extended the instruction
    set of their processors to provide hardware-based virtualization support. Hardware
    assisted virtualization does not require a modified Guest OS or software emulation
    and it improves the system’s overall performance. Intel VT and AMD-V technologies
    have many similarities. However, as our system is equipped with Intel processor,
    we focus on Intel VT. Intel, with its extended instruction set, introduced two
    Virtual Machine Extensions (VMX) modes, the Root Mode and the Non Root Mode (Fig.
    4). The Non Root Mode is for the Guest OS and the Root Mode is for the hypervisor,
    in both modes there are 0–3 rings. The Guest OS is not aware that it is running
    on Non Root Mode and it does not need any modification. To execute Guest sensitive
    instructions, CPU stops running on Non Root Mode and switches to VMX Root Mode.
    This is called VMexit. Next, the hypervisor emulates the Guest’s instruction and
    afterwards the CPU switches again from Root Mode to Non Root Mode. This is called
    VMentry. Download : Download high-res image (147KB) Download : Download full-size
    image Fig. 3. Paravirtualization privilege rings. In our study we used KVM and
    XEN to deploy VMs on Linux Ubuntu Server and Hyper-V which is used by Windows
    Server. We chose KVM and XEN hypervisors because they are open-source, free and
    widely adopted. The Hyper-V was used by default from Docker for Windows, to run
    Linux containers on Windows. It is worth noting that these hypervisors are also
    used by some of the biggest cloud provider companies. Till the 6th of November
    2017 Amazon employed XEN to deploy VMs, then it presented a new EC2 instance based
    on KVM. Google Compute Engine also uses KVM, while Microsoft Azure uses a customized
    version of Hyper-V. Download : Download high-res image (123KB) Download : Download
    full-size image Fig. 4. Hardware assisted virtualization privilege rings. We exploited
    the hardware assisted virtualization capabilities of KVM and XEN, to deploy VMs
    in both cases. Although XEN and KVM have essential differences, they both support
    hardware emulation with QEMU and paravirtualization for I/O devices. XEN hypervisor
    is based on microkernel architecture and it consists of a privileged VM, which
    is called Domain-0 or Dom0, and other unprivileged VMs, which are called Domain-U
    or DomU [35]. Dom0 can directly access the hardware, it provides interfaces for
    DomU to use I/O devices, controls resource allocation policies, etc. Each DomU
    communicates with the XEN hypervisor, which is running on top of hardware and
    serves as an interface between the hardware and the VMs. CPU and main memory accesses
    are managed directly by the XEN hypervisor, whereas I/O is managed by Dom0 [36].
    In hardware assisted virtualization, the XEN hypervisor is running in VMX Root
    in ring 0, whereas Dom0 is running in Non VMX Root and its kernel is running in
    ring 0. Hyper-V comes as a role on Windows Server 2016 or as a stand-alone product.
    It is based on microkernel design and it requires CPU which supports hardware
    assisted virtualization [37]. Hyper-V isolates VMs in terms of a partition [38].
    A partition is a logical unit of isolation, in which operating systems are running
    [38]. The virtualization stack is running in a parent partition, which has direct
    access to the hardware devices. Moreover, there are child partitions which host
    the Guest OSes. Hyper-V is running in VMX Root in ring 0, whereas root and child
    partitions are running in Non VMX Root and their kernels are running in ring 0.
    Hyper-V is used by Windows Server, in order to assist Docker to run Linux containers
    on Windows OS. Hyper-V creates a VM, with a lightweight OS just enough to run
    containers, for each running container. With this technique, each container runs
    isolated from the others, as it is the only one that shares the VM’s kernel. Instead
    of creating a hypervisor and necessary components like scheduler, memory manager
    and device drivers, KVM just loads a kernel module into Linux kernel and transforms
    the host into a hypervisor [39]. Every VM is treated by the host OS as an ordinary
    process and any virtual CPU is treated by Linux scheduler as a normal thread.
    KVM uses a modified QEMU to emulate the I/O bus, network interface etc. At the
    same time, it supports paravirtualization with Virtio. Virtio allows the guest’s
    devices to be aware of the host’s hypervisor and to communicate directly with
    the hypervisor [40]. In hardware assisted virtualization, the hypervisor and driver
    are running in ring 0 of VMX Root mode, because KVM places the hypervisor and
    driver module in the Linux kernel. To further improve the isolation between VMs,
    the access control module SELinux can be used. XEN and Hyper-V provide a greater
    isolation between the hypervisor, the drivers and the guest VMs compared to KVM,
    as they follow a microkernel architecture. On the other hand, KVM follows a monolithic
    architecture and although KVM does not have as strong isolation between drivers
    and hypervisor, as XEN and Hyper-V do, still it provides a great degree of isolation
    between the hypervisor and Guest VMs. In addition, the more complex structure
    of a microkernel-based hypervisor may lead to significant performance overhead
    and may even negatively affect the system’s overall security, as more complicated
    systems have more lines of code and possibly more bugs. 3.1.1. Memory virtualization
    and isolation VMs that are deployed on the same physical system share its memory.
    Even if there is only an unvirtualized OS on a x86 system, its applications will
    still see a virtual address space. In modern x86 CPUs, hardware maps multiple
    virtual address spaces into a possibly smaller amount of physical memory [41].
    There is a memory management unit (MMU) which translates virtual to physical addresses
    and a translation lookaside buffer (TLB) which stores the most used parts of the
    page tables and accelerates the process [32]. In Linux systems there is memory
    isolation at the process level. To deploy VMs in x86 architecture, the MMU has
    to be virtualized. Modern CPUs support mapping guest physical memory to the host
    physical memory with hardware (AMD NPT and Intel EPT). If the processor does not
    support these technologies and, as a result, does not have the dedicated hardware
    for MMU virtualization, the Guest OS maps guest virtual addresses to guest physical
    addresses. As it is expected, because physical memory is virtualized, the guest
    physical address is not the actual host physical address and, consequently, the
    hypervisor is responsible for mapping guest virtual memory to host physical memory.
    The hypervisor creates guest physical addresses internally, to host physical addresses
    mapping and it creates shadow page tables which contain guest virtual memory to
    host physical memory mapping. With this technique, the hypervisor can map guest
    virtual addresses to physical host addresses and assure that every VM will access
    only the part of the host’s physical memory that it owns [41]. Although hardware
    TLB is used to cache guest virtual memory to host physical memory address translations
    and to accelerate the mapping process, extra overhead is introduced when the shadow
    page needs to be updated. A paravirtualization method can be used in order to
    improve the memory performance. Paravirtualization requires modification of the
    Guest OS, in order to be possible for Guest virtual memory to be mapped to host
    physical memory [42]. In our case, the system’s CPU supports Intel EPT technology
    and is equipped with special purpose hardware for MMU virtualization. In hardware-assisted
    MMU virtualization, a two level mapping is performed in hardware, as it can be
    seen in Fig. 5. The first one, from guest virtual memory to guest physical memory,
    is done by the Guest OS and the second, from guest physical memory to host physical
    memory addresses, is controlled by the hypervisor and is unseen by the Guest OS
    [41]. In this way there is no need for the hypervisor to keep shadow page tables,
    since these two sets of page tables are exposed to the hardware and can be used
    to find the host physical addresses from the guest virtual addresses. Furthermore,
    to speed up future guest virtual addresses to host physical address translations,
    TLB is used. Moreover, the nested page tables of hardware-assisted virtualization
    are mostly static and are not updated when the VM creates or modifies page tables.
    Hardware-assisted virtualization reduces memory consumption and has higher performance
    for most workloads [43]. On the other hand, this technique’s performance is heavily
    affected by workloads that stress the TLB, because the virtual to real physical
    address translation is a lot more complex, therefore each TLB miss is much more
    expensive [44]. However, the increased TLB miss cost can usually be overcome by
    using large pages. When a VM asks for memory access, the processor will perform
    a translation using the EPT. A hypervisor can define the memory, which the VM
    has the right to access, by setting bits in the EPT memory structures [45]. If
    a VM tries to compromise memory isolation and to access part of the memory that
    is not allowed to, then an EPT violation will occur and the hypervisor will intervene
    to handle the incident. By analyzing the EPT violations, one might recognize a
    potential attack or an isolation thread. Download : Download high-res image (129KB)
    Download : Download full-size image Fig. 5. Hardware assisted virtualization privilege
    rings. 3.1.2. I/O virtualization and isolation One of the key functions a hypervisor
    implements is sharing the system’s devices and providing isolated I/O to the deployed
    VMs. There are three ways to provide I/O virtualization, full virtualization with
    device emulation, paravirtualization and direct I/O [46]. In full virtualization,
    real hardware devices will be emulated and the hypervisor will expose their interfaces
    to the VM. This way the Guest OS will simply use its driver for the emulated device,
    but as all the device operations will be emulated in software, this will cause
    a performance degradation. QEMU emulates a set of different existing devices and
    can be used under XEN and KVM hypervisors. KVM was originally designed to use
    the full virtualized I/O method. KVM starts a QEMU process in user-mode for each
    VM and attaches to them specific emulated devices. Every I/O operation from a
    VM is redirected by the KVM to the corresponding QEMU process. The paravirtualization
    method has higher I/O performancecompared to full virtualization. In this method,
    there is a light-weight front-end driver that is running in the VM and managing
    its I/O requests. Also, there is a back-end driver which is running in the host
    and actually communicates with the I/O devices. Moreover, this method may require
    special drivers or tools to function properly, which however are already available
    in most Linux distributions. Although this method is commonly used in XEN, KVM
    also supports it by leveraging Virtio. In a common XEN configuration, the back-end
    driver and the actual device drivers, which manage the devices, are running in
    Dom0 and the front-end driver is running in DomU. The front-end and back-end driver
    transfer data to each other via a block of shared memory, called Grant Tables.
    Because every data transfer is related to a request or response between the front-end
    and back-end driver, a buffer ring is used to manage the requests or responses.
    These techniques ensure that each VM will exclusively have access to its devices.
    Finally, in direct I/O method, the VM can access the hardware device directly.
    As it would be expected, in this way we can achieve maximum performance, as the
    hypervisor does not intervene into the data-path. However, because the hypervisor
    is not involved in the data-path, useful functions such as exposure of file-image,
    virtual disk, network tunneling or live migration will no longer be possible.
    In all the above methods (Fig. 6) the isolation and the restricted access to devices
    is a very important factor. Intel and AMD, in order to support the isolation and
    restricted access to virtualized devices with hardware, introduced the VT-d and
    AMD-Vi virtualization technologies respectively. In this work we focus on Intel’s
    VT-d technology. The key capabilities of VT-d technology are I/O device assignment,
    direct memory access (DMA) remapping, interrupt remapping and reliability features
    [47]. Download : Download high-res image (160KB) Download : Download full-size
    image Fig. 6. I/O virtualization methods. The DMA remapping enhances isolation
    by restricting DMA of the devices to pre-assigned domains or physical memory regions
    [48]. When an I/O device asks for access to a certain memory location, DMA remapping
    hardware checks for its permissions to access that physical address. If the device
    has the corresponding right, it will access the memory, otherwise it will be blocked.
    To boost performances, frequently used remapping-structure entries are cached.
    In the direct assignment of I/O device, the hypervisor does not participate in
    every I/O request but only in requests for protected resources [48]. The DMA remapping
    hardware is used to convert the guest physical addresses, which the Guest OS provide,
    to host physical addresses. To further improve performance by reducing hypervisor
    overhead, interrupt remapping control can be directly assigned to VM. Intel VT-d
    can improve reliability and security of hypervisors by isolating different devices
    and also set access to specific memory ranges for each of them. 3.1.3. Containers
    and isolation Containers offer a logical packaging mechanism, which allows applications
    to be easily and consistently deployed in different environments, from personal
    computer to public cloud [49]. Containers do not run an instance of a complete
    OS, as VMs do, but they run multiple isolated processes in the same host [50].
    They access the same OS, including root file system, libraries and common files.
    Mainly because the virtual hardware layer is missing, containers can be created
    significantly faster than VMs and introduce less overhead compared to VMs [21].
    A container engine handles the container image, which maintains the necessary
    dependencies and binaries for a container to be executed. To control resource
    consumption and to organize processes, containers use Linux Control Groups (cgroups).
    With cgroups, it is possible to limit the CPU and memory consumption per container
    and resize or even terminate it. To isolate containers with no visibility or access
    to external objects, the namespace feature of the kernel is applied. In our study,
    we focus on Docker as an open source software container platform [51], which has
    recently grown very popular. The main feature of Docker, that is not present in
    most other container platforms, is that it uses layered file system images, such
    as AUFS (Advanced Multi Layered Unification Filesystem) [52], [53]. This feature
    allows different containers to use the same basis layer repeatedly, boosting performance,
    saving network bandwidth and space in host’s storage unit. Docker has great compatibility
    and maintainability, it is supported by many cloud platforms, like Amazon Web
    Services and Google Compute Platform and additionally, Docker dominates other
    container technologies in bibliography, [4], [6], [8], [21], [22], [24], [54],
    [55], [56], [57] and [58]. However, containers do not excel at providing isolation
    as VMs do [59]. The Docker Engine runs in user space (ring 3) as a root application,
    whereas namespaces and cgroups are applied by the Linux kernel in ring 0. Because
    all running containers share the same kernel, a compromised kernel leads to compromised
    containers. Moreover as containers run on the same level (ring 3) with other applications,
    any of them can disrupt their operation. To enhance security, a container can
    run on top of a VM. Thus, it can achieve multi-tenant isolation, having the VM
    as boundary of security, yet with the corresponding performance cost [60]. In
    addition, by running containers on VMs, supplementary security tools can be used
    by the host to monitor VMs and intercept malicious events [61], [62], [63]. 4.
    Performance evaluation In this section, we experimentally quantify the performance
    overhead that was introduced by running Docker containers on KVM, XEN and Hyper-V
    VMs. We deployed a series of benchmarks to measure how the additional layer of
    the VM affects the CPU, memory, disk and network performances. We performed each
    experiment twenty times and we calculated mean values and standard deviation.
    At first, we deployed containers on bare metal and used these measurements as
    a basis. Secondly, we executed the same benchmarks, but this time containers were
    running on top of VM (Fig. 7). All the experiments are executed on a 3.7 GHz Intel
    CORE I3-6100 processor with 8 GB of DDR4 DIMM RAM and 100 Mbps Ethernet. The OSes
    which are installed on physical node and VMs are Alpine 3.6.2, Atomic Host based
    on CentOS 7, CargOS 2016.08, CoreOS 1465.8.0 and RancherOs v1.1.0. In all cases
    where VMs were deployed, we used Ubuntu Server 16.04.3 LTS as host. In order to
    examine the overhead of Linux Docker containers on Windows, we used Windows Server
    2016 as host. Download : Download high-res image (158KB) Download : Download full-size
    image Fig. 7. Containers and containers on VM. Each VM that we created was configured
    to use all the available resources of the physical node. The Docker containers
    were created without any cgroups restrictions, in order for them to also use all
    available resources. 4.1. Container-centric operating systems As Docker’s popularity
    and adoption is growing rapidly, in the last years some new Linux distributions,
    optimized to run containers and mainly Docker, were released. As deploying a full-fledged
    Linux distribution on a host that will only run Docker appears to be exaggerated,
    these container-centric OSes are minimalistic. The idea of minimalistic OSes is
    not new, but it finds a new appliance in this field. Many of these OSes besides
    being characterized by small size, small overhead and small attack surface, have
    additional features that support the deployment of Docker containers. Some of
    these OSes run Docker daemon by default, have automatic updates to deal with inconsistencies
    and can update roll back in case of unsuccessful OS update. In our study, we deployed
    Docker containers on the free container-centric CoreOS [64], RancherOS [65], Atomic
    Host [66], CargOS [67] and the minimalistic Alpine OS [68]. CoreOS is an open
    source container-centric OS and it is also part of a commercial product called
    Tectonic [64]. CoreOS automatically configures the container’s runtime on each
    CoreOS machine, updates itself and detects every new Docker container which will
    be connected to the network. RancherOS is actually consisted of just the kernel
    and Docker and it runs all system services as Docker containers. Atomic Host is
    Red Hat’s container-centric minimalistic OS, it has built-in support for SELinux
    and it has replaced the yum package manager with the rpm-ostree package manager,
    something that allows software roll-back. CargOS [67] provides only the essentials
    to deploy Docker and it executes any other service as container. Alpine [68] was
    not originally designed to host Docker, but it is a secure and efficient OS which
    can be used to deploy Docker containers on it. 4.2. Benchmarks We employed four
    different benchmarks to individually measure the performances of the four main
    server components. We used LINPACK [69] for CPU performance overhead measurements,
    STREAM [70] to measure memory performance, IOZONE [71] for block devices and file
    systems and NETPERF [72] to measure network performance. LINPACK is a collection
    of Fortran subroutines which solve various systems of linear equations and measure
    the floating point operations per second (flops) [69]. The main LINPACK function
    solves a system of linear equations “Ax b” (random matrix A, vector b) by performing
    lower upper decomposition of numerical analysis with partial pivoting. STREAM
    is a simple synthetic benchmark which measures sustainable memory bandwidth by
    performing simple operations on vectors [70]. It executes four different operations,
    Copy, Scale, Add and Triad, which are presented in Table 1. Although STREAM recognizes
    a strong relation between the evaluated throughput and the size of the CPU cache,
    it measures the main memory bandwidth and not the cache bandwidth. According to
    STREAM’s general rule, each array has to be at least four times the accessible
    cache memory size. We used IOZONE [71] to measure the performances of various
    disk operations, such as Read, Write, Re-Read, Re-Write, Reverse Read, Stride
    Read, Random Read, Random Write, Fwrite and Fread. We executed this benchmark
    with 100 MB file size, originally on a container running on bare metal and then
    on a container running on top of a VM, for each of the six OSes. Table 1. STREAM
    operations. Name Kernel COPY a(i) b(i) SCALE a(i) q*b(i) SUM a(i) b(i) c(i) TRIAD
    a(i) b(i) q*c(i) Finally, we took unidirectional throughput and end-to-end latency
    measurements with NETPERF [72]. Because NETPERF is based on the client–server
    model, we hosted the NETPERF server in an additional node and the NETPERF client
    in our initial testing node. Both machines were connected with 100 Mb Ethernet
    Link through a ZTE H108NS router. 4.2.1. CPU First, we measured CPU performance.
    We ran LINPACK on Docker container on bare metal and LINPACK on Docker container
    on top of VMs. We executed a set of experiments on six different OSes with LINPACK
    array sizes of 200 × 200, 2000 × 2000 and 8000 × 8000. For this type of experiments
    we used three different hypervisors and we defined the number of vCPUs (virtual
    processors) same as the number of logical cores of the physical machine. In case
    of XEN, one of the four total vCPUs was occupied by Dom0. Fig. 8 shows the performance
    measurements of the LINPACK benchmark for various system configurations. In Fig.
    8 we observe that, on the one hand, CPU achieved the best performance for the
    smallest array (200 × 200). In this case (of the smallest array), we notice that
    our measurements show also the highest standard deviation. This probably happens
    because the results are affected by the existing high speed memory. On the other
    hand, for bigger arrays of 2000 × 2000 and 8000 × 8000, which are not affected
    so much by the cached data on the high speed memory, we took lower but more stable
    values. Download : Download high-res image (292KB) Download : Download full-size
    image Fig. 8. CPU performance. Download : Download high-res image (365KB) Download
    : Download full-size image Fig. 9. Memory performance. Download : Download high-res
    image (393KB) Download : Download full-size image Fig. 10. Disk write performance.
    Download : Download high-res image (453KB) Download : Download full-size image
    Fig. 11. Disk read performance. Download : Download high-res image (518KB) Download
    : Download full-size image Fig. 12. TCP_STREAM network performance. Download :
    Download high-res image (333KB) Download : Download full-size image Fig. 13. Request–Response
    network performance. In general, from Fig. 8 we can see that when containers ran
    on bare metal or on XEN VM, they performed almost the same. Windows Hyper-V and
    KVM VMs follow shortly after them. KVM appeared to have slightly worse CPU performance
    compared to the others. This probably happens because KVM is not Type-1 hypervisor
    like the other two, it runs at a different level and is treated by the host OS
    as an ordinary process. If we closely examine the case of 8000 × 8000 array, where
    we took the most stable measurements, the most significant difference is in KVM
    and bare metal CPU performance. For the biggest array, bare metal was 4,89% faster
    than KVM, and 11.12% in average for all different array sizes. Regarding OSes,
    Alpine achieved the best CPU performance in 77% of our cases, mostly with a relatively
    small difference of 3% from the others. It is worth noting that, whereas on bare
    metal CoreOS was the fastest, it was slower than Alpine, when running on a VM.
    This probably happens because the VM hides the nature of system information from
    the execution environment [5]. 4.2.2. Memory We evaluated the memory performance
    with STREAM benchmark. The available cache memory of our system (L3 cache) was
    3 MB. Following the STREAM’s rule, we set much larger arrays of about 2.3 GB and
    total memory required at 7 GB. As illustrated in Fig. 9 the Copy function, which
    is the simplest of the four different functions that STREAM uses (Table 1), achieved
    the highest performance for all different system configurations. By observing
    Fig. 9, we can also easily recognize that there is not a big difference in memory
    performance for Docker containers which run either on bare metal or on top of
    a VM. Our memory performance measurements, for all four functions on all OSes,
    show that, in average, bare metal achieved 3.74% higher memory performance compared
    to KVM, 1.63% compared to XEN and 1.95% higher memory performance compared to
    Hyper-V. The different type of KVM hypervisor seems to affect the memory performance
    and the memory management services of the host. The six OSes achieved almost the
    same memory performance. Nevertheless, Alpine was the one showing slightly higher
    memory performance on 66% of our cases. CoreOS, similarly to CPU measurements,
    is persistently faster on bare metal. 4.2.3. Disk We evaluated the disk performance
    with the IOzone benchmark and we configured it to generate files of 100 MB. We
    ran it first on containers on bare metal and secondly on containers on top of
    a VM. We measured various operations such as Read, Write, Re-Read, Re-Write, Reverse
    Read, Stride Read, Random Read, Random Write, Fwrite and Fread. For these series
    of experiments, although we deployed full virtualized VMs, we used paravirtualized
    drivers for disk and network devices to boost the performances of KVM and XEN
    VMs. The experimental results of write to disk functions can be seen in Fig. 10
    and read from disk functions in Fig. 11. As it was expected also in this case
    the bare metal achieved the highest overall performance. Fig. 10 shows a significant
    difference in the performances of write to disk operations between Windows Hyper-V
    and the other hypervisors. Generally, bare metal achieved the highest performance
    among all write operations, followed, with a short distance, by the KVM and XEN
    hypervisors. The performance gap between Windows Hyper-V and the other hypervisors
    is up to twice as bad as the lowest performance measurement. This probably happens
    because the files are stored on the Windows NTFS file-system and some translations
    may be needed [73]. According to Microsoft, incompatibilities for some applications
    may occur because some file-system operations are currently partially or even
    not at all implemented [73]. The performance measurements of read from disk functions
    are presented in Fig. 11. As well in this case, for almost all read operations,
    the performance of bare metal was the highest one, followed by KVM and XEN. Windows
    Hyper-V comes last with significantly lower performance. XEN disk performance
    measurements were slightly lower than KVM in almost all cases. This probably happens
    because only Dom0 has direct access to the disks when any other DomU can access
    the disks through Dom0. 4.2.4. Network With NETPERF, we measured the performances
    of TCP_Stream, TCP RR (request–response) and UDP RR. We recorded the throughput
    of transmitting TCP packets for packet sizes of 4, 16, 64, 256 and the default
    16 384 Bytes. In the cases of KVM and XEN hypervisors, network paravirtualized
    drivers were used. As illustrated in Fig. 12, our measurements for TCP_Stream
    on bare metal, XEN and KVM are almost the same for all different OSes. The only
    exception is the case of the 4 byte packet (which is the smallest one), where
    caching and the much higher number of transmitting packets probably heavily affected
    the results. As it can be seen in Fig. 12 and Fig. 13, containers which ran on
    Windows Hyper-V showed the lowest network performance in almost all cases. This
    probably happens because of the differences on network stack of Windows and Linux-based
    OSes. The TCP RR and UDP RR performance measurements are shown in Fig. 13. As
    we can see, for both TCP RR and UDP RR measurements, bare metal and KVM achieved
    almost the same performances, followed by XEN and finally by Hyper-V. XEN achieved
    lower performance compared to KVM, probably because every DomU must use the network
    driver that is located in Dom0 [12]. Also in this case, there was a significant
    difference of network performances of the Docker containers that ran on top of
    Windows Hyper-V and the Docker containers that ran on the other VMs. 4.3. Benchmarks
    results Containers that ran on KVM had the highest CPU performance overhead. In
    average, KVM introduced 13.02% higher CPU overhead compared to XEN and 7.4% higher
    CPU overhead compared to Hyper-V. Concerning container-centric OSes, almost all
    of them achieved the same CPU performance. Alpine achieved the highest one and
    Atomic Host the lowest one by 1,72% compared to Alpine. We recorded similar results
    for the memory overhead. All OSes achieved almost the same memory performance
    with less than 0.6% difference between them. Container on bare metal reached 1,63%
    higher memory performance compared to XEN, 1,95% higher performance compared to
    Hyper-V and 3,74% higher performance compared to KVM. In disk performance we observed
    high deviation in the recorded values. The highest GB/s achieved by Alpine and
    the lowest by CargOS, by 68.93% less compared to Alpine. Hyper-V on Windows had
    by far the lowest performance, which was 3.5 times lower compared to Alpine. KVM
    had in average 2,69% lower disk performance than bare metal and 16,73% higher
    disk performance compared to XEN. The network benchmark results for TCP_Stream
    show that Alpine was the most performant one and the least was CargOS, by 9.9%
    compared to Alpine. KVM and XEN performances were almost the same as bare metal’s
    network performance, whereas Hyper-V achieved 43.36% lower network performance
    compared to bare metal. From these measurements we can conclude that, for different
    kinds of applications there are different optimal solutions. For CPU intensive
    applications, the combination with the highest performance is Alpine and XEN.
    For memory intensive applications, the best choice would be CoreOS and XEN. Lastly,
    for disk and network intensive applications, Alpine and KVM can be combined, in
    order to achieve higher performance. 5. Use cases - Further study In the previous
    section, as in the first stage of our analysis, we ran containers on bare metal
    and containers on top of VMs. We separately evaluated how the performance of CPU,
    main memory, disk and network are affected by the type of hypervisor and OS. In
    the following section, we used a case study approach to further our research and
    enhance our understanding on how different parameters affect the overall performance
    of containers running on top of VMs. In this set of our analysis, we explored
    how the number of VMs, the number of containers per VM, the number of threads,
    the type of processing and the mechanism of storing data, affect the overall performance
    of containers. By combining the experimental results obtained so far, we observed
    that Alpine, CoreOS and RancherOS show the highest CPU performance. Although there
    is no big difference in CPU measurements, Alpine is the fastest one in seven of
    total nine Linux OS cases. Regarding the main memory, Alpine, CoreOS and RancherOS
    show the highest performance on bare metal, KVM and XEN. Alpine is the fastest
    one in six of nine cases. Finally, disk and network experiments revealed that
    Alpine, CoreOS and RancherOS also show the highest disk and network performance.
    By taking these findings into consideration and having as unique selection criterion
    the overall mean performance, we adopted Alpine OS in all use cases. It is important
    to note that containers were initially designed for stateless applications and
    ephemeral data. By default a container only has access to its own file-system
    and loses all of its data when it is terminated or crashed. For some applications
    this design may seem ideal, but for applications in which persistent storage is
    essential, like databases, it is totally unsuitable. Docker provides mechanisms
    to separate the data from containers and to store persistent data. Because databases
    are common cloud application and in order to examine if Docker successfully deals
    with persistent data, we deployed two database applications on containers and
    we studied them as use cases. We deployed MySQL as a relational database and MongoDB
    as a noSQL database example. Before proceeding to use cases, it will be helpful
    to present how Docker containers store data. 5.1. Docker data storage Docker uses
    union file-system architecture for images and containers. A union file-system
    represents a logical file-system by grouping directories and file-systems in branches.
    In Docker each branch is a layer and a Docker image is built up from different
    layers. Each layer, except for the very last one, is read-only. The last layer
    is initially empty but later it stores all the changes that are made to the file-system.
    Because each container has its own writable layer, different containers can share
    the same underlying image. In this way, Docker avoids duplication of data and
    optimizes disk space usage. When a container is removed, actually the top layer
    is deleted, leaving the underlying layers unaffected. The writable layer is designed
    to store a small amount of data and to promote building and sharing images. Although
    it is possible to store data in this layer, it is not recommended to store persistent
    or shared data, mainly, because of three reasons. First, data in the writable
    layer cannot be easily moved out of the container. Second, the data will be lost
    if the container stops running and third, it is not optimal concerning the container’s
    performance, because a storage driver is required to manage the file system. Storage
    drivers are based on copy-on-write technique which boosts the performances of
    read intensive applications, but it adversely affects the performances of heavy
    writing workloads. As a result, extra overhead is added in comparison to storing
    data directly in the host’s file-system. Docker provides a mechanism which is
    designed for persistent data, it bypasses the container’s union file system and
    is called “data volume”. Data volumes are not controlled by the storage driver
    and, as a result, operate at host speeds. A Docker data volume is a directory
    or file that is mounted into a container but stored in the Docker host’s file-system
    [74]. The data is stored outside of the container and will be still available
    if a container stops running or if it is removed. There are some different options
    for data volumes and persistent data storage techniques. The first one is to create
    a data volume along with the creation of a Docker container or at any time with
    the relevant command. Although the data volume is stored in Docker host directory,
    it is created and controlled by the Docker daemon, it is isolated from the host
    machine and it is only managed by Docker. Usually data volumes are created in
    the directory /var/lib/docker/volumes/, as illustrated in Fig. 14 for Container
    2 [75]. In order to be easily manageable, from Docker version 1.9, data volumes
    can have names and containers which are associated with specific data volume can
    be listed. The second option is to create a container whose only purpose will
    be to own data volume. Its data will be accessible by other containers even if
    this container stops running. This kind of containers can be used for backup purposes
    or with the purpose to provide other containers with simultaneous access to its
    data. The third option is to mount a local host file or directory into a container.
    The source directory or file may be any file of the host as shown in Fig. 13 for
    Container 1. In this case extra caution is needed because any modification of
    the host’s files might affect its operation. Last but not least, there are third-party
    volume plugins that allow containers to be integrated in external storage systems
    and extend its capabilities. For example there are plugins for Azure File Storage
    [76] and Google Cloud Engine [77]. Download : Download high-res image (149KB)
    Download : Download full-size image Fig. 14. Docker mounted volume and managed
    by Docker data volume. 5.2. Use case 1 MySQL MySQL is a widely used open-source
    relational database management system (RDBMS) [78]. With Docker Hub repositories,
    it is easy to create, share or download and run container images, such as MySQL,
    in a few seconds. We used the official MySQL repository to deploy our own MySQL
    Docker containers and we took various measurements for different configurations.
    We used the Sysbench [79] benchmark to measure the performance of MySQL 5.7.20
    database. The Sysbench can be used to separately evaluate different system components.
    Furthermore, it provides an OLTP (online transaction processing) component that
    is frequently used to measure the performances of databases. We created with Sysbench
    a database of twenty million rows, of about 5 GB total size of random data, to
    run our experiments. We stored the persistent data which Sysbench created in three
    different ways. First, we saved the data in data volumes by exploiting Docker’s
    internal volume management. Second, by mounting a host’s directory to a container.
    Finally, by creating a dedicated data volume container. We used InnoDB as storage
    engine and took performance measurements for various InnoDB buffer sizes. Moreover,
    we modified the number of threads from 1 to 150, the number of containers from
    1 to 6 and the number of VMs from 1 to 3. In the default mode, Sysbench executes
    read and write operations to the database. It selects queries from five SELECT
    queries, two UPDATE queries, a DELETE query and an INSERT query. As we noticed
    in our results, the ratio was about 65% reads, 25% writes and 10% other queries.
    5.2.1. MySQL Docker containers on bare metal Fig. 15 shows the operation throughput
    as a function of the number of threads for different buffer sizes. Initially,
    we ran this set of experiments with default buffer size of 125 MB. As Fig. 15
    presents, for the default buffer size, the throughput was increased up to 60 threads
    and then the system was saturated. Thus, the throughput was decreased. To explore
    how the buffer size affects the overall performance and in order to achieve better
    utilization of the available resources, we increased the buffer size by several
    GigaBytes. For sizes of 2, 4 and 6 GB the overall performance was almost identical.
    We observed that the available memory can successfully deal with the increasing
    number of threads and, as a result, the operation throughput was steadily increased.
    The bigger buffer led to a significantly higher overall performance by reducing
    the disk I/O. Table 2 presents the operation throughput for three different mechanisms
    which provide persistent storage. We configured our system to use 2 GB of InnoDB
    buffer and we used Sysbench to measure the operation throughput for 50 threads.
    First, we employed Docker’s internal volume management system to store data in
    data volumes. Second, we mounted a host’s directory to a container and finally,
    we created a dedicated data volume container. It is worth noting that the dedicated
    data volume container was not even running during the experiments, therefore we
    used an additional container to access and manage its data. After the system warm-up,
    we ran Sysbench experiments 40 times and the experimental results are presented
    in Table 2. Using host directory resulted to 0.54% more operations per second
    compared to using data volume container and 6.84% more operations per second compared
    to using Docker volume. Even though these tests did not show any significant difference
    among the different mechanisms of storing persistent data, host directory seems
    to be the most performant method to adopt. Download : Download high-res image
    (125KB) Download : Download full-size image Fig. 15. MySQL operations throughput
    on bare metal. Another factor which affects the operation throughput is the number
    of containers running parallelly on the same system. To investigate this factor,
    we simultaneously ran from 1 to 6 identical containers on our system and we observed
    how the overall performance was scaling. As illustrated in Fig. 16, the higher
    the number of running containers the more increased is the overall throughput
    and the more decreased is the individual container’s throughput. We can see that,
    in average, as a new container was added, the overall performance was increased
    by 13.81% while the individual performance was decreased by 19.54%. We can also
    observe that containers running in parallel achieved almost the same performances,
    which means that there is a high level of fairness and great resource management.
    However, we cannot increase our system performance endlessly by adding more containers,
    due to saturation and performance bottlenecks. Table 2. MySQL operations per second
    on bare metal for different mechanisms of persistent storage. Empty Cell Docker
    volume Host directory Data volume container Bare-metal (operations/s) 128.95 137.77
    137.03 Download : Download high-res image (102KB) Download : Download full-size
    image Fig. 16. MySQL operations throughput for 1–6 containers on bare metal. 5.2.2.
    MySQL Docker containers on VMs We performed a similar series of experiments to
    investigate how the same factors, which we previously examined on bare metal,
    affect the performances of containers running on top of VMs. We deployed Docker
    containers on KVM and XEN VMs and we configured VMs to utilize all the available
    resources. The results obtained from the Sysbench experiments for different buffer
    sizes and number of threads are presented in Fig. 17, Fig. 18. From these two
    figures, we can observe that the two hypervisors show similar performances. For
    the default buffer size of 125 MB, for both hypervisors, the throughput was increased
    up to 70 threads and then, due to saturation, the operation throughput was decreased.
    For buffer sizes of 2, 4 and 6 GB, we also observed an identical behavior as the
    significantly bigger buffer reduced the disk I/O and led to better performance.
    To determine how the additional layer of hardware virtualization affects the performances
    of different mechanisms that provide persistent storage, we replicated the experiments
    that we previously executed on bare metal, this time on KVM and XEN VMs. As well
    in this case, we configured our system to use 2 GB of InnoDB buffer and we used
    Sysbench to measure the operation throughput for 50 threads. Table 3 compares
    the mean operation throughput of containers which were running on top of KVM and
    XEN VMs and employed three different mechanisms to store persistent data. One
    can see on the table below that KVM achieved 4.83% better mean operation throughput,
    in all cases, compared to containers running on XEN. Host directory achieved in
    average, for both KVM and XEN 3.84% higher operation throughput compared to Docker
    volume and 0.08% higher operation throughput compared to data volume container.
    Download : Download high-res image (131KB) Download : Download full-size image
    Fig. 17. MySQL operations throughput on KVM VM. Download : Download high-res image
    (131KB) Download : Download full-size image Fig. 18. MySQL operations throughput
    on XEN VM. We also performed a number of MySQL tests to investigate the impact
    of the amount of VMs on total operation throughput. We progressively deployed
    from 1 to 6 containers on 1 to 3 VMs. We configured the VMs to use all available
    resources in every case and we deployed separately KVM and XEN VMs. We also set
    the InnoDB buffer of MySQL to 2 GB and Sysbench to measure the operation throughput
    for 50 threads. Table 3. MySQL operations per second on KVM and XEN VMs for different
    mechanisms of persistent storage. Empty Cell Docker volume Host directory Data
    volume container KVM (operations/s) 119.47 123.92 123.83 XEN (operations/s) 113.8
    118.3 118.2 In the case where there were two VMs deployed, when there was one
    container, this was running on one VM, while the second VM was running as well,
    without a container. In the case where two containers were running, each container
    was running on each VM. For three running containers, two containers were deployed
    on the first VM and the third container was running on the second VM. For four
    running containers, on each VM two containers were deployed. For five running
    containers, three containers were running on the first VM and two containers were
    running on the second VM. Last, for six running containers, on each VM three containers
    were deployed. We followed the same method to distribute the containers on three
    VMs. The results obtained from KVM experiments are presented in Fig. 19, Fig.
    20, Fig. 21. Fig. 19 shows how the overall system throughput was increased, as
    the number of running containers on a single KVM VM was increased as well. Fig.
    20, Fig. 21 present the results of the same experiments, but this time the containers
    were running on two and three similar VMs respectively. As it would be expected,
    for the various amount of VMs, the higher number of containers led to better overall
    performance. However, by observing Fig. 19, Fig. 20, Fig. 21, one can see that
    each additional VM added overhead to the system, especially when the number of
    containers was higher. The same containers which were running on one VM, achieved
    3.1% better operation throughput compared to those running on two VMs and 5% better
    operation throughput compared to those running on three VMs. By using Sysbench,
    we also investigated how additional XEN VMs affect the overall operation throughput
    of containers. In Fig. 22, Fig. 23, Fig. 24 we see the total system throughput
    and the individual container operation throughput for different numbers of containers
    and VMs. Also in this case, the increasing number of containers resulted to higher
    operation throughput. For XEN VMs, any additional VM led to higher overhead. The
    same containers that were running on one VM achieved 9.39% better operation throughput
    compared to those running on two VMs and 21.44% better operation throughput compared
    to those running on three VMs. Download : Download high-res image (98KB) Download
    : Download full-size image Fig. 19. MySQL operations throughput on 1 KVM VM for
    1–6 containers. Download : Download high-res image (98KB) Download : Download
    full-size image Fig. 20. MySQL operations throughput on 2 KVM VMs for 1–6 containers.
    Download : Download high-res image (98KB) Download : Download full-size image
    Fig. 21. MySQL operations throughput on 3 KVM VMs for 1–6 containers. Running
    containers on a higher number of VMs resulted to lower performance throughput
    for MySQL services on both KVM and XEN hypervisors. This happens because every
    additional VM consumes further resources in order to run its own operating system
    and services. For this type of service we found that KVM achieved overall 19.9%
    higher performance compared to XEN. Download : Download high-res image (94KB)
    Download : Download full-size image Fig. 22. MySQL operations throughput on 1
    XEN VM for 1–6 containers. Download : Download high-res image (97KB) Download
    : Download full-size image Fig. 23. MySQL operations throughput on 2 XEN VMs for
    1–6 containers. Download : Download high-res image (95KB) Download : Download
    full-size image Fig. 24. MySQL operations throughput on 3 XEN VMs for 1–6 containers.
    5.3. Use case 2 MongoDB A new set of extensive evaluation experiments was performed
    on one of the most commonly used NoSQL databases, MongoDB[80]. In order to provide
    a more comprehensive view of containers running on top of VMs, we deployed MongoDB
    services on containers which were running either on bare metal or on top of KVM
    and XEN VMs. We evaluated container performances for different types of workloads,
    mechanisms of persistent storage, number of VMs, containers and threads, by exploiting
    the Yahoo! Cloud Serving Benchmark (YCSB) [81]. MongoDB is document-oriented and
    stores data as binary-encoded JSON documents, called BSON. Contrary to SQL databases,
    where the table schema must be declared before inserting data, MongoDB uses an
    equivalent to SQL tables that is called “collections”, where the table schema
    does not have to be declared in advance. Documents within a collection might have
    different fields. In our evaluation, containers were running MongoDB v3.4.10 and
    WiredTiger storage engine. Firstly, we exploited YCSB to enrich the database with
    almost 5 GB of randomly generated records. Then we used four of the predefined
    types of workloads, which can emulate different application types, to test our
    system. The selected YCSB workloads are presented on Table 4. Table 4. YCSB workloads.
    Workload Operation ratio A Read/update: 50/50 B Read/update: 95/5 C Read/update:
    100/0 F Read/read–modify–write: 50/50 5.3.1. MongoDB Docker containers on bare
    metal To provide an insight on how the system performs, as the number of threads
    increases, we took measurements for all four workloads from 1 to 150 threads.
    The operation throughput of every workload is presented in Fig. 25. As it would
    be expected, regardless the number of threads, we see that workloads with higher
    read ratio achieved steadily higher operation throughput. Also in Fig. 25 we can
    observe that, when the number of threads was increased, the operation throughput
    was increased as well. The load of the system was not enough to lead to saturation
    and the system responded effectively to the increasing workload. We also experimentally
    evaluated the mechanisms of providing persistent storage with YCSB. Table 5 shows
    that there was no significant difference in operation throughput for persistent
    data stored in Docker volume, host directory or in data volume container. Nevertheless,
    host directory mechanism achieved 5.3% higher operation throughput compared to
    Docker volume and 3.48% higher operation throughput compared to data volume container.
    Download : Download high-res image (156KB) Download : Download full-size image
    Fig. 25. MongoDB operations throughput on bare metal. We selected workload A,
    whose operation ratio is 50/50 read/write, to investigate how the overall system
    operation throughput is affected by the number of simultaneously running containers.
    We deployed from 1 to 6 containers on bare-metal, which executed similar workloads
    and the results of these experiments are presented in Fig. 26. As we can see,
    there is high level of fairness among the parallelly running containers. Any additional
    container, which was running in parallel with others, led to 15.63% increment,
    in average, of the overall operation throughput. Table 5. MongoDB operations per
    second on bare metal for different mechanisms of persistent storage. Empty Cell
    Docker volume Host directory Data volume container Bare-metal (operations/s) 151.35
    159.38 154.01 Download : Download high-res image (111KB) Download : Download full-size
    image Fig. 26. MongoDB operations throughput for 1–6 containers on bare metal.
    5.3.2. MongoDB Docker containers on VMs Fig. 27, Fig. 28 present the YCSB results
    for MongoDB containers on KVM and XEN VMs, running Workloads A, B, C and F, for
    1 to 150 threads respectively. By observing Fig. 27, Fig. 28 we can see that the
    operations per second were gradually increasing as the number of threads was also
    increasing. Table 6 compares the mean operation throughput of MongoDB containers
    running on top of KVM and XEN VMs, as three different mechanisms to store persistent
    data were employed. We used YCSB benchmark with workload A and 50 threads. Our
    measurements show that KVM achieved 8.45% better mean operation throughput, in
    all cases, compared to containers running on XEN. Host directory achieved in average,
    for both KVM and XEN, 3.19% higher operation throughput compared to Docker volume
    and 0.08% higher operation throughput compared to data volume container. Download
    : Download high-res image (134KB) Download : Download full-size image Fig. 27.
    MongoDB operation throughput on KVM VM for different types of workload. Download
    : Download high-res image (138KB) Download : Download full-size image Fig. 28.
    MongoDB operation throughput on XEN VM for different types of workload. Considering
    the previous MySQL experiments, which demonstrated that there was an overhead
    introduced by additional VMs, we repeated this experimental scenario this time
    for MongoDB NoSQL database. In this set of experiments, we deployed from 1 to
    3 VMs and we progressively ran from 1 to 6 containers on top of them. We used
    YCSB benchmark with workload A and 50 threads to measure how MongoDB performs
    for different configurations. Table 6. MongoDB operations per second on KVM and
    XEN VMs for different mechanisms of persistent storage. Empty Cell Docker volume
    Host directory Data volume container KVM (operations/s) 141.88 144.51 143.68 XEN
    (operations/s) 128.79 134.63 133.16 Fig. 29, Fig. 30, Fig. 31 provide the experimental
    results for MongoDB containers which were running on 1 to 3 KVM VMs respectively.
    In all three cases, independently of the number of VMs, the additional containers
    led to higher overall system performance. On the contrary, as the same number
    of containers was deployed on more VMs, we observed a decrease on operation throughput.
    The MongoDB containers which were running on one VM achieved 3.75% better operation
    throughput compared to those running on two VMs and 9.09% better operation throughput
    compared to those running on three VMs. Corresponding to MongoDB containers on
    KVM experiments, we executed similar measurements for XEN VMs. In Fig. 32, Fig.
    33, Fig. 34 the results of those measurements are presented. As it would be expected,
    also in this case, the increasing number of containers resulted to higher operation
    throughput. On the contrary, the additional VMs led to a higher overhead. The
    same containers, which were running on one VM, achieved 9.93% better operation
    throughput compared to those running on two VMs and 20% better operation throughput
    compared to those running on three VMs. Download : Download high-res image (104KB)
    Download : Download full-size image Fig. 29. MongoDB operations throughput on
    1 KVM VM for 1–6 containers. Download : Download high-res image (107KB) Download
    : Download full-size image Fig. 30. MongoDB operations throughput on 2 KVM VMs
    for 1–6 containers. Download : Download high-res image (104KB) Download : Download
    full-size image Fig. 31. MongoDB operations throughput on 3 KVM VMs for 1–6 containers.
    Download : Download high-res image (112KB) Download : Download full-size image
    Fig. 32. MongoDB operations throughput on 1 XEN VM for 1–6 containers. Download
    : Download high-res image (99KB) Download : Download full-size image Fig. 33.
    MongoDB operations throughput on 2 XEN VMs for 1–6 containers. Download : Download
    high-res image (98KB) Download : Download full-size image Fig. 34. MongoDB operations
    throughput on 3 XEN VMs for 1–6 containers. 5.3.3. Experimental results Various
    experiments showed that Docker successfully stores persistent data. Regarding
    the methods of storing persistent data, host directory achieved the highest performance.
    Then data volumes follow and last comes host directory, by 1.06% and 4.37% lower
    performance respectively. The I/O benchmark experiments of the previous section,showed
    that containers, which ran on KVM, achieved 16,73% higher disk performance in
    average, compared to XEN. As it would be expected, because MySQL and MongoDB are
    I/O intensive applications, MySQL and MongoDB containers on KVM achieved higher
    performance compared to XEN. Experiments showed that, for both services, for all
    different configurations, KVM achieved 20% higher performance compared to XEN.
    Moreover, any additional KVM VM led to 3.81% performance degradation. Whereas,
    any additional to the system XEN VM led to 10.16% performance degradation. From
    the previous experiments we can claim that, for I/O intensive applications, the
    combination of KVM and Alpine OS seems to be the optimal solution. On the contrary,
    XEN and CargOS will introduce the highest performance overhead on the system.
    6. Power consumption analysis Another critical aspect of cloud computing, is energy
    efficiency. Due to data centers’ current sizes, software-based and hardware-based
    techniques and architectures are needed to moderate the high energy consumption,
    without heavily affecting the QoS requirements [82]. Virtualization in cloud computing,
    is a technique used to enhance resource consolidation, improve energy efficiency
    and promote green cloud computing [83]. Virtualization can increase CPU utilization
    by 40%–60% and combined with other Green House Data techniques, such as opportunistic
    free cooling and hot/cold aisle containment, can lead up to 64.5% energy savings
    compared to an average cloud data center [84]. Furthermore, VM migration techniques
    allow workloads to migrate on-site or on geo-dispersed sites in order to utilize
    available renewable energy sources [84]. To better understand and quantify the
    power consumption overhead introduced by containers running on VMs, we conducted
    a new series of experiments. In line with our previous experiments, we deployed
    Docker containers on XEN and KVM VMs, since these virtualization technologies
    are free and widely used in real-world production environments. The energy efficiency
    of containers and VMs has been separately evaluated and compared in the past.
    However, there is no study which investigated the power consumption overhead of
    the VM-container combination. In bibliography, there are several studies investigating
    power consumption of virtualization technologies. In [85] the authors compared
    KVM and Docker in terms of QoS and energy efficiency. They deployed a LAMP stack
    (Linux–Apache–MySQL–PHP) service and found that, for their configuration, Docker
    used 11.33% less energy than KVM. They concluded that Docker outperforms KVM in
    both QoS and energy efficiency. Jiang et al. [86] evaluated the energy consumption
    of different hypervisors and Docker containers on various platforms and workloads.
    They found that there is not a single hypervisor to outperform the others in terms
    of power, energy consumption, or performance in all cases. Moreover, they pointed
    out that, for computation-intensive workloads, containers had similar power efficiency
    to VMs, even though container virtualization is lighter than the one of VMs. In
    [87] OpenStack VM and Docker container were compared. Experiments showed that
    Docker container consumed less power while executing scientific workflow and while
    it was in idle state. Also, the container achieved better performance for CPU
    and memory intensive jobs compared to OpenStack VM. Morabito [88] compared the
    power usage of KVM and XEN hypervisors to container-based virtualization Docker
    and LXC. He also found that, in idle state and in CPU/Memory heavy workloads,
    containers used marginally less power than VMs. Nevertheless, for network intensive
    experiments, containers achieved noticeably less power consumption compared to
    VMs. As the author noted, this happened because network packets have to be processed
    by extra layers in a hypervisor environment, compared to a container environment.
    Finally, Shea et al. [89] compared the power consumption of network tasks on KVM,
    XEN and OpenVZ to bare metal. Their experiments revealed that the two hypervisors,
    KVM and XEN, consumed considerably more energy for this kind of tasks. On the
    other hand, OpenVZ consumed nearly the same amount of power as a non-virtualized
    system. The authors also proposed an adaptive packet buffering in KVM that could
    reduce the energy consumption caused by network transaction. 6.1. Power consumption
    experiments 6.1.1. System setup As mentioned, our test system is composed of a
    3.7 GHz Intel CORE I3-6100 processor, 8 GB of DDR4 DIMM RAM and 250 GB hard disk.
    The Intel’s x86 architecture, which is used in our system, is dominating in the
    CPU market and is used by major cloud service providers, such as Amazon [89].
    This kind of CPU has low power consumption and is equipped with Running Average
    Power Limit hardware counters (RAPL), to accurately record CPU power consumption.
    In our series of experiments, we recorded the overall power consumption of the
    system and CPU separately and we calculated the total energy consumption of different
    configurations and workloads. We also measured in real time the internal power
    consumption for core devices and dram, using the RAPL counters [90]. However,
    since RAPL counters do not measure the overall system power consumption, we used
    the Bearware 302 717 power meter to measure the total system power consumption
    (or “wall power”) per second. We also recorded utilization metrics and how Dynamic
    Voltage and Frequency Scaling adjusted the frequency/voltage of processors between
    16 distinct P-states 740–3700  to conserve power. 6.1.2. System in idle state
    The virtual resources of a data center may be idle during periods of low demand.
    Taking this into consideration, we measured and compared the idle power consumption
    of VMs and containers running on VMs. We deployed 1 and 6 containers on 1 and
    2 KVM and XEN VMs and we took power consumption measurements separately. The VMs
    were running Ubuntu Server and Alpine. Before recording any power measurement,
    the system was left for 5 min to be balanced and then we recorded the wall power
    consumption per second for 5 min. Table 7 shows the average power consumption
    results for every case. It can be seen from the data in Table 6 that the different
    virtualization technologies under evaluation have roughly the same power consumption
    in idle state. In average, an idle container on a KVM VM increased the system’s
    power consumption by 0.06% (0.03 W), 6 idle containers on a KVM VM increased the
    system’s power consumption by 0.28% (0.14 W) and 6 idle containers on 2 KVM VMs
    (3 containers per VM) increased the system’s power consumption by 0.34% (0.17
    W). Table 7. System power consumption in Watts for system in idle state. Empty
    Cell Bare-metal Ubuntu Bare-metal Alpine KVM XEN Empty Cell Empty Cell Empty Cell
    1 VM 2 VMs 1 VM 2 VMs Without docker 48,90 48,59 49,10 49,21 49,20 49,28 1 container
    48,96 48,67 49,13 – 49,24 – 6 containers 49,02 48,69 49,24 49,38 49,37 49,46 Table
    8. Power consumption experimental configurations. Empty Cell Empty Cell Configuration
    Number of VMs Number of containers DB total size MySQL InnoDB buffer size Empty
    Cell MySQL 1 – 1 5 GB 2 GB/container Bare metal 2 – 6 24 GB 1 GB/container Empty
    Cell MongoDB 3 – 1 5 GB – Empty Cell 4 1 1 5 GB 2 GB/container KVM MySQL 5 1 6
    24 GB 1 GB/container Empty Cell 6 2 6 24 GB 1 GB/container Empty Cell MongoDB
    7 1 1 5 GB – Empty Cell 8 1 1 5 GB 2 GB/container XEN MySQL 9 1 6 24 GB 1 GB/container
    Empty Cell 10 2 6 24 GB 1 GB/container Empty Cell MongoDB 11 1 1 5 GB – Similar
    experiments for XEN hypervisor showed that an idle container on a XEN VM increased
    the system’s power consumption by 0.08% (0.04 W), 6 containers on a XEN VM increased
    the system’s power consumption by 0.35% (0.17 W) and 6 containers on 2 XEN VMS
    increased the system’s power consumption by 0.36% (0.18 W). In average, for all
    different cases, the idle power consumption of XEN was 0.19% higher than KVM,
    0.71% higher than Ubuntu bare metal and 1.36% higher than Alpine bare metal. KVM
    idle power consumption was on average 0.52% higher than Ubuntu bare metal and
    1.16% higher than Alpine bare metal. Download : Download high-res image (673KB)
    Download : Download full-size image Fig. 35. System’s power consumption of running
    MySQL container with small dataset on bare metal and on a VM. Download : Download
    high-res image (821KB) Download : Download full-size image Fig. 36. System’s power
    consumption of running MySQL container with big dataset on bare metal and on a
    VM. Download : Download high-res image (871KB) Download : Download full-size image
    Fig. 37. System’s power consumption of running 6 MySQL containers with big dataset
    on bare metal and on 2 VMs. Download : Download high-res image (1MB) Download
    : Download full-size image Fig. 38. CPU frequency and power consumption of the
    whole system, dram and cores, for system running a MySQL container on KVM VM.
    Download : Download high-res image (1MB) Download : Download full-size image Fig.
    39. CPU frequency and power consumption of the whole system, dram and cores, for
    system running 6 MySQL containers on 2 KVM VMs. Download : Download high-res image
    (631KB) Download : Download full-size image Fig. 40. System power consumption
    and CPU, disk and memory utilization of system running a MySQL container on KVM
    VM. Download : Download high-res image (369KB) Download : Download full-size image
    Fig. 41. System’s power consumption of running MongoDB container on bare metal
    and on a VM. Our results on KVM and XEN idle power consumption are in alignment
    with earlier study [88], in which the authors had also found that, in idle state,
    XEN consumes a bit more power compared to KVM. Because both hypervisors take advantage
    of the standard Linux power saving system, they consume almost the same amount
    of power in idle state [88]. Although XEN, due to its architecture (Domain-0),
    was slightly more power-demanding in idle state compared to KVM. In our use cases,
    deploying idle containers on both XEN and KVM VM, led from 0.06% to only 0.36%
    increment of total power consumption. 6.1.3. System under stress We deployed 11
    different configurations to study the power consumption overhead of containers
    running on VMs compared to containers running on bare metal. As shown in Table
    8, we took power measurements for different workloads, number of containers and
    VMs. To ensure a fair analysis between all virtualization technologies, we deployed
    a similar setup in all cases, on the same server hardware. For MySQL experiments,
    for the smallest database size, we set the innodb buffer of MySQL to 2 GB and
    for the bigger one, we set the innodb buffer to 1 GB per container. We used the
    Sysbench benchmark to stress the system and we took power consumption measurements
    per second for the total system and the CPU. We ran 19 iterations of 1 min Sysbench
    tests, with 50 threads per container, for both the small and the big MySQL dataset.
    Sysbench executed about 65% reads, 25% writes and 10% other queries. For MongoDB
    experiments, we stressed the system with the YCSB benchmark and we also took power
    consumption measurements per second for the whole system and the CPU separately.
    We stressed the system by running 19 iterations with 10.000 operations for workload
    A (see Table 4), with 50 threads per container. In all cases where containers
    were running on VMs, we configured the virtualized nodes to exploit all the available
    resources of the server. 6.1.4. Experimental results Power data for the whole
    system was gathered over time. Fig. 35, Fig. 36, Fig. 37 provide the power measurements
    for the whole system, while 19 MySQL Sysbench tasks were executed consecutively
    for different system configurations (see Table 8). As it can be seen from Fig.
    35, Fig. 36, Fig. 37, in most cases, bare metal achieved the lowest power consumption.
    Also, we can observe that the power consumption of running containers on one VM
    is lower, compared to running the same containers on two VMs of the same technology
    (Fig. 36, Fig. 37). As the experiments progress over time, we can see that this
    difference is getting even higher. Moreover, we note that, especially for the
    biggest dataset, containers running on VMs consumed more time to perform the same
    tasks, compared to containers running on bare metal. To provide an aggregated
    view of the above empirical measurements, we calculated the mean power and the
    mean energy consumption for every experimental configuration; the calculated values
    are presented in Fig. 42, Fig. 43. As it can be seen in Fig. 42, a container running
    on a KVM VM has 1.48% power overhead compared to the same container running on
    bare metal. The same one running on a XEN VM, has 3.38% power overhead compared
    to bare metal. Regarding energy consumed by a container when running the same
    benchmark tasks, the container running on KVM VM consumed 2.25% more energy compared
    to bare metal and the container running on a XEN VM consumed 4.25% more energy
    compared to bare metal as well. Experiments with higher number of containers and
    VMs have a different power consumption impact on the system. We observe from figure
    Fig. 43 that running containers on VMs is marginally less power-demanding than
    running the same containers on bare metal. In case of containers running on a
    KVM VM and a XEN VM, this leads to 1.44% and 2.23% less power consumption compared
    to running the same containers on bare metal respectively. This case is also observed
    by Jin et al. [91] and may happen because of different processes simultaneously
    running on the CPU cores. In Fig. 36, Fig. 37, we can distinguish two very often
    observed values of about 50 and 65 W, nevertheless this pattern is not appeared
    in Fig. 35. Assuming that this is due to CPU’s DVFS mechanism, we focused on two
    representative cases and we recorded the values of RAPL counters to further investigate
    how the DVFS mechanism affects the CPU power consumption and, as a result, the
    overall system power consumption. In Fig. 38 we can see the total power consumption
    of the system, the CPU’s power consumption, the power consumption of CPU’s dram
    and cores, as well as the CPU frequency for the experimental configuration 4 (see
    Table 8). Similar measurements were taken for the experimental configuration 6.
    These results are presented in Fig. 39. Both Fig. 38, Fig. 39 reveal that there
    is a strong relation between CPU and the overall system’s power consumption. Higher
    CPU frequency led to higher CPU power consumption, which in turn led to higher
    overall system’s power consumption. For example in Fig. 38 from 265 to 309 s,
    CPU operated with 0.95 GHz average frequency and the average system power consumption
    was 51.78 W. On the other hand, we can see in Fig. 39 that, from 113 to 137 s,
    CPU operated at 3.38 GHz and the average system power consumption was 62.72 W.
    For the experimental configuration 4 the average CPU frequency was 1.38 GHz, whereas
    for experimental configuration 6 the system was under heavier load and the average
    CPU frequency was 2.32 GHz. For this reason we can see that, in cases where 6
    containers are running with larger databases, CPU was operated at higher frequency,
    consuming more power. This applies also in case of running containers without
    additional virtualization layer, as we can see for bare metal measurements in
    these figures. Our empirical analysis shows that CPU affects the power consumption
    behavior of the system rather heavily. The disk is recognized in bibliography
    [92] as the second highest energy consumption impact factor, especially for this
    kind of heavy I/O applications. Fig. 40 shows the correlation between the system’s
    total power consumption and CPU, disk and memory utilization in time, for the
    experimental configuration 4 (see Table 8). We can observe that, in periods with
    high CPU utilization, the disk was also highly utilized and the system was more
    power demanding. There is a strong correlation between CPU frequency and disk
    power consumption, which is also noted by Arjona et al. [92]. On the other hand,
    even though memory utilization was steadily increased from 20% to 90% during this
    experiment, we do not see any noticeable impact on the system’s power consumption.
    Power consumption measurements were also taken for the MongoDB service. To stress
    the system, we executed 50% read and 50% update operations by using the YCSB benchmark.
    Fig. 41 shows that also in this case, the system operated mainly in two power
    states, in a lower power state at about 50 W and in a higher power state at about
    80 W. This specific experimental configuration did not stress the system heavily
    and, as a result, for most of the time, the system’s power consumption was about
    50 W. Regarding energy consumption of the specific YCSB tasks, although power
    consumption of a container running on bare metal was higher than the one of a
    container running on VM, more execution time was consumed by the container running
    on VM while executing the same benchmark tasks. Fig. 44 provides the mean power
    and energy consumption for these MongoDB experiments. As it can be observed, the
    container running on KVM VM consumed 22.91% more energy, compared to the one running
    on bare metal and also the container running on a XEN VM consumed 26.36% more
    energy, compared to bare metal. In conclusion, power consumption measurements
    showed that, for the system in idle state, all configurations had almost the same
    power consumption. The power consumption of both KVM and XEN was almost the same
    for the system under stress. However, regarding the energy consumed by containers
    to complete the same tasks, containers running on KVM consumed 7,11% less energy
    compared to containers running on XEN. So, KVM not only achieved the highest performances
    for MySQL and MongoDB containers, but also consumed the least energy in comparison
    to XEN. Download : Download high-res image (158KB) Download : Download full-size
    image Fig. 42. Average power and energy consumption of MySQL small dataset containers.
    Download : Download high-res image (185KB) Download : Download full-size image
    Fig. 43. Average power and energy consumption of MySQL big dataset containers.
    Download : Download high-res image (155KB) Download : Download full-size image
    Fig. 44. Average power and energy consumption of MongoDB containers. 7. Conclusions
    In this study we combined the two most widely used virtualization technologies
    on cloud computing, VMs and containers. We highlighted that these two technologies
    are complementary and we proposed to run containers on VMs in order to improve
    containers’ isolation, resource utilization, system’s management and functionality.
    This approach offers some great benefits, however they come at a performance cost.
    In contrast to the majority of studies in bibliography, which separately compared
    VMs and containers, we evaluated their coexistence under various conditions. There
    are a few works that also conduct experiments by combining VMs and containers,
    but there is no research which used our approach to present the benefits of this
    method or which investigated how important factors, such as the number of VMs,
    the number of containers per VM and the Guest’s OS, affect the performance and
    also the energy consumption of the system. To quantify the performance overhead
    introduced by the additional layer of VMs, we conducted several experiments with
    various hypervisors, container-centric OSes and configurations. Our measurements
    showed a minor CPU and memory performance overhead of containers running on VMs,
    especially on XEN VMs. The disk and network performance is affected more heavily
    by the additional virtualization layer of VM. KVM hypervisor achieved the highest
    disk and network performance compared to other hypervisors. In addition, as far
    as OSes are concerned, Alpine, CoreOS and RancherOS achieved the highest performances.
    Additionally, we deployed two different types of DBMS services, MySQL and MongoDB,
    as use cases. Because database services are common in cloud and containers were
    initially designed for stateless applications, we considered DBMS as an interesting
    type of service to examine. After several experiments, we confirmed that Docker
    successfully manages persistent data in different ways. The experimental results
    showed that the overall performance of containers running on VMs is affected by
    the type of applications, the number of VMs, the number of containers, the guest’s
    OS, the storage mechanism and the different types of workloads. There is a noticeable
    overhead introduced by the VMs, especially as the number of VMs and parallelly
    running containers is getting higher. Furthermore, we studied the energy consumption
    impact of running containers on VMs. We took power consumption measurements for
    the whole system and for the CPU separately, for the system being in idle state
    and under stress, for various experimental configurations. For the system in idle
    state, as may expected, there was almost no overhead. But by stressing the system
    with running both MySQL and MongoDB services, we noticed that the XEN hypervisor
    is more energy demanding compared to KVM. Also we did not only measure the total
    system power consumption but we investigated how factors, such as CPU frequency
    and disk utilization, affect it. In this work we combined VMs and containers to
    enhance containers’ isolation and extend VMs’ functionality. As the main drawback
    of this approach we can consider the performance and energy overhead of the additional
    virtualization layer. We experimentally quantified these overheads and presented
    how various factors affect it. The factors presented above, can be modified and
    adapted in different situations, in order to further improve the overall performance
    or isolation. For example, for security sensitive applications, running one container
    per VM can be considered as a good approach while, for performance demanding applications,
    running a number of containers per VM could be a better solution. The findings
    of this study will serve as a base for future work. An interesting research topic
    is to investigate how the results of our analysis can be exploited by the currently
    available solutions for (multi-)cloud governance. Future directions may include
    the extension of the open reference architecture presented in [93], to support
    VM-container deployments. Also, we could integrate the findings of our study in
    cloud application automation standards like, TOSCA [94], which enables the creation,
    automated deployment and management of portable cloud applications. We could even
    extend tools, as in [95], to use TOSCA-based representation and VM-containers
    approach, to specify and orchestrate complex application in heterogeneous cloud
    platforms. References [1] Mavridis I., Karatza H. Performance evaluation of cloud-based
    log file analysis with apache hadoop and apache spark J. Syst. Softw., 125 (2017),
    pp. 133-151, 10.1016/j.jss.2016.11.037 View PDFView articleView in ScopusGoogle
    Scholar [2] Mavridis I., Karatza H. Performance and overhead study of containers
    running on top of virtual machines 2017 IEEE 19th Conference on Business Informatics
    (CBI), Vol. 2, IEEE (2017), pp. 32-38, 10.1109/CBI.2017.69 View in ScopusGoogle
    Scholar [3] Stavrinides G.L., Karatza H.D. A cost-effective and qos-aware approach
    to scheduling real-time workflow applications in paas and saas clouds 2015 3rd
    International Conference on Future Internet of Things and Cloud (FiCloud), IEEE
    (2015), pp. 231-239, 10.1109/FiCloud.2015.93 View in ScopusGoogle Scholar [4]
    Peinl R., Holzschuher F., Pfitzer F. Docker cluster management for the cloud-survey
    results and own solution J. Grid Comput., 14 (2) (2016), pp. 265-282, 10.1007/s10723-016-9366-y
    View in ScopusGoogle Scholar [5] Felter W., Ferreira A., Rajamony R., Rubio J.
    An updated performance comparison of virtual machines and linux containers 2015
    IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS),
    IEEE (2015), pp. 171-172, 10.1109/ISPASS.2015.7095802 View in ScopusGoogle Scholar
    [6] Barik R.K., Lenka R.K., Rao K.R., Ghose D. Performance analysis of virtual
    machines and containers in cloud computing 2016 International Conference on Computing,
    Communication and Automation (ICCCA), IEEE (2016), pp. 1204-1210, 10.1109/CCAA.2016.7813925
    View in ScopusGoogle Scholar [7] Higgins J., Holmes V., Venters C. Securing user
    defined containers for scientific computing 2016 International Conference on High
    Performance Computing & Simulation (HPCS), IEEE (2016), pp. 449-453, 10.1109/HPCSim.2016.7568369
    View in ScopusGoogle Scholar [8] Combe T., Martin A., Di Pietro R. To docker or
    not to docker: A security perspective IEEE Cloud Comput., 3 (5) (2016), pp. 54-62,
    10.1109/MCC.2016.100 View in ScopusGoogle Scholar [9] S.H. Davis, A. Sweemer,
    C. Greenwood, B.J. Corrie, G. Hicken, Z. Yang, Using virtual machine containers
    in a virtualized computing platform, uS Patent App. 14/505, 349 (Apr. 7 2016).
    Google Scholar [10] Tychalas D., Karatza H. High performance system based on cloud
    and beyond: Jungle computing J. Comput. Sci., 22 (2017), pp. 131-147, 10.1016/j.jocs.2017.03.027
    View PDFView articleView in ScopusGoogle Scholar [11] Elsayed A., Abdelbaki N.
    Performance evaluation and comparison of the top market virtualization hypervisors
    2013 8th International Conference on Computer Engineering & Systems (ICCES), IEEE
    (2013), pp. 45-50, 10.1109/ICCES.2013.6707169 View in ScopusGoogle Scholar [12]
    Hwang J., Zeng S., y Wu F., Wood T. A component-based performance comparison of
    four hypervisors 2013 IFIP/IEEE International Symposium on Integrated Network
    Management (IM 2013), IEEE (2013), pp. 269-276 Google Scholar [13] Nussbaum L.,
    Anhalt F., Mornard O., Gelas J.-P. Linux-based virtualization for hpc clusters
    Montreal Linux Symposium (2009) Google Scholar [14] Younge A.J., Henschel R.,
    Brown J.T., Von Laszewski G., Qiu J., Fox G.C. Analysis of virtualization technologies
    for high performance computing environments 2011 IEEE International Conference
    on Cloud Computing (CLOUD), IEEE (2011), pp. 9-16, 10.1109/CLOUD.2011.29 View
    in ScopusGoogle Scholar [15] Varrette S., Guzek M., Plugaru V., Besseron X., Bouvry
    P. Hpc performance and energy-efficiency of xen, kvm and vmware hypervisors 2013
    25th International Symposium on Computer Architecture and High Performance Computing
    (SBAC-PAD), IEEE (2013), pp. 89-96, 10.1109/SBAC-PAD.2013.18 View in ScopusGoogle
    Scholar [16] Che J., Shi C., Yu Y., Lin W. A synthetical performance evaluation
    of openvz, xen and kvm 2010 IEEE Asia-Pacific Services Computing Conference (APSCC),
    IEEE (2010), pp. 587-594, 10.1109/APSCC.2010.83 View in ScopusGoogle Scholar [17]
    Xavier M.G., Neves M.V., De Rose C.A.F. A performance comparison of container-based
    virtualization systems for mapreduce clusters 2014 22nd Euromicro International
    Conference on Parallel, Distributed and Network-Based Processing (PDP), IEEE (2014),
    pp. 299-306, 10.1109/PDP.2014.78 View in ScopusGoogle Scholar [18] Gerlach W.,
    Tang W., Keegan K., Harrison T., Wilke A., Bischof J., D’Souza M., Devoid S.,
    Murphy-Olson D., Desai N., et al. Skyport: container-based execution environment
    management for multi-cloud scientific workflows Proceedings of the 5th International
    Workshop on Data-Intensive Computing in the Clouds, IEEE Press (2014), pp. 25-32,
    10.1109/DataCloud.2014.6 View in ScopusGoogle Scholar [19] Estrada Z.J., Stephens
    Z., Pham C., Kalbarczyk Z., Iyer R.K. A performance evaluation of sequence alignment
    software in virtualized environments 2014 14th IEEE/ACM International Symposium
    on Cluster, Cloud and Grid Computing (CCGrid), IEEE (2014), pp. 730-737, 10.1109/CCGrid.2014.125
    View in ScopusGoogle Scholar [20] Kozhirbayev Z., Sinnott R.O. A performance comparison
    of container-based technologies for the cloud Future Gener. Comput. Syst., 68
    (2017), pp. 175-182, 10.1016/j.future.2016.08.025 View PDFView articleView in
    ScopusGoogle Scholar [21] Felter W., Ferreira A., Rajamony R., Rubio J. An updated
    performance comparison of virtual machines and linux containers 2015 IEEE International
    Symposium on Performance Analysis of Systems and Software (ISPASS), IEEE (2015),
    pp. 171-172, 10.1109/ISPASS.2015.7095802 View in ScopusGoogle Scholar [22] Morabito
    R., Kjällman J., Komu M., vs Hypervisors. Hypervisors vs. lightweight virtualization:
    a performance comparison 2015 IEEE International Conference on Cloud Engineering
    (IC2E), IEEE (2015), pp. 386-393, 10.1109/IC2E.2015.74 View in ScopusGoogle Scholar
    [23] Xavier M.G., Neves M.V., Rossi F.D., Ferreto T.C., Lange T., De Rose C.A.
    Performance evaluation of container-based virtualization for high performance
    computing environments 2013 21st Euromicro International Conference on Parallel,
    Distributed and Network-Based Processing (PDP), IEEE (2013), pp. 233-240, 10.1109/PDP.2013.41
    View in ScopusGoogle Scholar [24] Raho M., Spyridakis A., Paolino M., Raho D.,
    Kvm Kvm, xen and docker: A performance analysis for arm based nfv and cloud computing
    2015 IEEE 3rd Workshop on Advances in Information, Electronic and Electrical Engineering
    (AIEEE), IEEE (2015), pp. 1-8, 10.1109/AIEEE.2015.7367280 Google Scholar [25]
    Kominos C.G., Seyvet N., Vandikas K., Bare-metal Bare-metal, virtual machines
    and containers in openstack 2017 20th Conference on Innovations in Clouds, Internet
    and Networks (ICIN), IEEE (2017), pp. 36-43, 10.1109/ICIN.2017.7899247 View in
    ScopusGoogle Scholar [26] Eiras R.S., Couto R.S., Rubinstein M.G. Performance
    evaluation of a virtualized http proxy in kvm and docker 2016 7th International
    Conference on the Network of the Future (NOF), IEEE (2016), pp. 1-5, 10.1109/NOF.2016.7810144
    Google Scholar [27] Salah T., Zemerly M.J., Yeun C.Y., Al-Qutayri M., Al-Hammadi
    Y. Performance comparison between container-based and vm-based services 2017 20th
    Conference on Innovations in Clouds, Internet and Networks (ICIN), IEEE (2017),
    pp. 185-190, 10.1109/ICIN.2017.7899408 View in ScopusGoogle Scholar [28] Plauth
    M., Feinbube L., Polze A. A performance survey of lightweight virtualization techniques
    European Conference on Service-Oriented and Cloud Computing, Springer (2017),
    pp. 34-48, 10.1007/978-3-319-67262-5˙3 View in ScopusGoogle Scholar [29] Sharma
    P., Chaufournier L., Shenoy P., Tay Y. Containers and virtual machines at scale:
    A comparative study Proceedings of the 17th International Middleware Conference,
    ACM (2016), p. 1, 10.1145/2988336.2988337 View PDFView articleGoogle Scholar [30]
    https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html, [Online;
    accessed 29.09.18]. Google Scholar [31] https://cloud.google.com/compute/docs/cpu-platforms,
    [Online; accessed 29.09.18]. Google Scholar [32] Nagesh O.S., Kumar T., Vedula
    V.R. A survey on security aspects of server virtualization in cloud computing
    Int. J. Electr. Comput. Eng. (IJECE), 7 (3) (2017), pp. 1326-1336, 10.11591/ijece.v7i3.pp1326-1336
    View in ScopusGoogle Scholar [33] D. Marshall, Understanding full virtualization,
    paravirtualization, and hardware assist, VMWare White Paper (2007) 17. Google
    Scholar [34] Studnia I., Alata E., Deswarte Y., Kaâniche M., Nicomette V. Survey
    of security problems in cloud computing virtual machines Computer and Electronics
    Security Applications Rendez-vous (C & ESAR 2012). Cloud and Security: Threat
    or Opportunity (2012) p–61 Google Scholar [35] Petrovic D., Schiper A. Implementing
    virtual machine replication: A case study using xen and kvm 2012 IEEE 26th International
    Conference on Advanced Information Networking and Applications (AINA), IEEE (2012),
    pp. 73-80, 10.1109/AINA.2012.50 View in ScopusGoogle Scholar [36] Binu A., Kumar
    G.S. Virtualization techniques: a methodical review of xen and kvm Adv. Comput.
    Commun. (2011), pp. 399-410, 10.1007/978-3-642-22709-7_40 View in ScopusGoogle
    Scholar [37] https://docs.microsoft.com/en-us/windows-server/virtualization/hyper-v/get-started/install-the-hyper-v-role-on-windows-server,
    [Online; accessed 29.09.18]. Google Scholar [38] https://msdn.microsoft.com/en-us/library/cc768520(v=bts.10).aspx,
    [Online; accessed 29.09.18]. Google Scholar [39] Regola N., Ducom J.-C. Recommendations
    for virtualization technologies in high performance computing 2010 IEEE Second
    International Conference on Cloud Computing Technology and Science (CloudCom),
    IEEE (2010), pp. 409-416, 10.1109/CloudCom.2010.71 View in ScopusGoogle Scholar
    [40] Soriga S.G., Barbulescu M. A comparison of the performance and scalability
    of xen and kvm hypervisors 2013 RoEduNet International Conference 12th Edition
    Networking in Education and Research, IEEE (2013), pp. 1-6, 10.1109/RoEduNet.2013.6714189
    Google Scholar [41] O. Agesen, Software and hardware techniques for x86 virtualization,
    Palo Alto CA, 2009, VMware Inc. Google Scholar [42] Wang X., Zang J., Wang Z.,
    Luo Y., Li X. Selective hardware/software memory virtualization ACM SIGPLAN Not.,
    46 (7) (2011), pp. 217-226, 10.1145/2007477.1952710 Google Scholar [43] Chang
    X., Franke H., Ge Y., Liu T., Wang K., Xenidis J., Chen F., Zhang Y. Improving
    virtualization in the presence of software managed translation lookaside buffers
    ACM SIGARCH Computer Architecture News, Vol. 41, ACM (2013), pp. 120-129, 10.1145/2485922.2485933
    View in ScopusGoogle Scholar [44] N. Bhatia, Performance evaluation of intel ept
    hardware assist, 2009, VMware, Inc. Google Scholar [45] I. Korkin, Hypervisor-based
    active data protection for integrity and confidentiality of dynamically allocated
    memory in windows kernel, arXiv preprint arXiv:1805.11847. Google Scholar [46]
    Hwang K., Dongarra J., Fox G.C. Distributed and Cloud Computing: From Parallel
    Processing to the Internet of Things Morgan Kaufmann (2013) Google Scholar [47]
    Abramson D., Jackson J., Muthrasanallur S., Neiger G., Regnier G., Sankaran R.,
    Schoinas I., Uhlig R., Vembu B., Wiegert J. Intel virtualization technology for
    directed i/o Intel Technol. J., 10 (3) (2006) Google Scholar [48] https://software.intel.com/en-us/articles/intel-virtualization-technology-for-directed-io-vt-d-enhancing-intel-platforms-for-efficient-virtualization-of-io-devices,
    [Online; accessed 29.09.18]. Google Scholar [49] https://cloud.google.com/containers/,
    [Online; accessed 29.09.18]. Google Scholar [50] Xu X., Yu H., Pei X. A novel
    resource scheduling approach in container based clouds 2014 IEEE 17th International
    Conference on Computational Science and Engineering (CSE), IEEE (2014), pp. 257-264,
    10.1109/CSE.2014.77 View in ScopusGoogle Scholar [51] https://www.docker.com,
    [Online; accessed 29.09.18]. Google Scholar [52] http://aufs.sourceforge.net/aufs2/man.html,
    [Online; accessed 29.09.18]. Google Scholar [53] Tosatto A., Ruiu P., Attanasio
    A. Container-based orchestration in cloud: state of the art and challenges 2015
    Ninth International Conference on Complex, Intelligent, and Software Intensive
    Systems (CISIS), IEEE (2015), pp. 70-75, 10.1109/CISIS.2015.35 View in ScopusGoogle
    Scholar [54] Pahl C., Brogi A., Soldani J., Jamshidi P. Cloud container technologies:
    a state-of-the-art review IEEE Trans. Cloud Comput. (2017), 10.1109/TCC.2017.2702586
    Google Scholar [55] Chung M.T., Quang-Hung N., Nguyen M.-T., Thoai N. Using docker
    in high performance computing applications 2016 IEEE Sixth International Conference
    on Communications and Electronics (ICCE), IEEE (2016), pp. 52-57, 10.1109/CCE.2016.7562612
    View in ScopusGoogle Scholar [56] Gjerdrum A.T., Johansen H.D., Johansen D. Implementing
    informed consent as information-flow policies for secure analytics on ehealth
    data: Principles and practices 2016 IEEE First International Conference on Connected
    Health: Applications, Systems and Engineering Technologies (CHASE), IEEE (2016),
    pp. 107-112, 10.1109/CHASE.2016.39 View in ScopusGoogle Scholar [57] Naik N. Migrating
    from virtualization to dockerization in the cloud: Simulation and evaluation of
    distributed systems 2016 IEEE 10th International Symposium on the Maintenance
    and Evolution of Service-Oriented and Cloud-Based Environments (MESOCA), IEEE
    (2016), pp. 1-8, 10.1109/MESOCA.2016.9 View in ScopusGoogle Scholar [58] Mao C.-N.,
    Huang M.-H., Padhy S., Wang S.-T., Chung W.-C., Chung Y.-C., Hsu C.-H. Minimizing
    latency of real-time container cloud for software radio access networks 2015 IEEE
    7th International Conference on Cloud Computing Technology and Science (CloudCom),
    IEEE (2015), pp. 611-616, 10.1109/CloudCom.2015.67 View in ScopusGoogle Scholar
    [59] https://docs.docker.com/, [Online; accessed 29.09.18]. Google Scholar [60]
    de Alfonso C., Calatrava A., Moltó G. Container-based virtual elastic clusters
    J. Syst. Softw., 127 (2017), pp. 1-11, 10.1016/j.jss.2017.01.007 View PDFView
    articleView in ScopusGoogle Scholar [61] Baliga A., Iftode L., Chen X. Automated
    containment of rootkits attacks Comput. Secur., 27 (7–8) (2008), pp. 323-334,
    10.1016/j.cose.2008.06.003 View PDFView articleView in ScopusGoogle Scholar [62]
    Moon H., Lee H., Heo I., Kim K., Paek Y., Kang B.B. Detecting and preventing kernel
    rootkit attacks with bus snooping IEEE Trans. Dependable Secure Comput., 14 (2)
    (2017), pp. 145-157, 10.1109/TDSC.2015.2443803 View in ScopusGoogle Scholar [63]
    Xie X., Wang W. Rootkit detection on virtual machines through deep information
    extraction at hypervisor-level 2013 IEEE Conference on Communications and Network
    Security (CNS), IEEE (2013), pp. 498-503, 10.1109/CNS.2013.6682767 View in ScopusGoogle
    Scholar [64] https://coreos.com/, [Online; accessed 29.09.18]. Google Scholar
    [65] http://rancher.com/, [Online; accessed 29.09.18]. Google Scholar [66] https://www.projectatomic.io/,
    [Online; accessed 29.09.18]. Google Scholar [67] https://cargos.io/, [Online;
    accessed 29.09.18]. Google Scholar [68] https://www.alpinelinux.org/about/, [Online;
    accessed 29.09.18]. Google Scholar [69] Dongarra J.J., Luszczek P., Petitet A.
    The linpack benchmark: past, present and future Concurrency Comput.: Pract. Exp.,
    15 (9) (2003), pp. 803-820, 10.1002/cpe.728 View in ScopusGoogle Scholar [70]
    https://www.cs.virginia.edu/stream/ref.html, [Online; accessed 29.09.18]. Google
    Scholar [71] http://www.iozone.org/, [Online; accessed 29.09.18]. Google Scholar
    [72] http://www.netperf.org/, [Online; accessed 29.09.18]. Google Scholar [73]
    https://docs.microsoft.com/en-us/virtualization/windowscontainers/deploy-containers/linux-containers,
    [Online; accessed 29.09.18]. Google Scholar [74] https://docs.docker.com/engine/userguide/storagedriver/imagesandcontainers/#data-volumes-and-the-storage-driver,
    [Online; accessed 29.09.18]. Google Scholar [75] https://docs.docker.com/engine/admin/volumes/#more-details-about-mount-types,
    [Online; accessed 29.09.18]. Google Scholar [76] https://github.com/Azure/azurefile-dockervolumedriver,
    [Online; accessed 29.09.18]. Google Scholar [77] https://github.com/mcuadros/gce-docker,
    [Online; accessed 29.09.18]. Google Scholar [78] http://www.oracle.com/technetwork/database/mysql/index.html,
    [Online; accessed 29.09.18]. Google Scholar [79] https://github.com/akopytov/sysbench,
    [Online; accessed 29.09.18]. Google Scholar [80] https://www.mongodb.com/, [Online;
    accessed 29.09.18]. Google Scholar [81] Cooper B.F., Silberstein A., Tam E., Ramakrishnan
    R., Sears R. Benchmarking cloud serving systems with ycsb Proceedings of the 1st
    ACM symposium on Cloud computing, ACM (2010), pp. 143-154, 10.1145/1807128.1807152
    View in ScopusGoogle Scholar [82] Shuja J., Bilal K., Madani S.A., Othman M.,
    Ranjan R., Balaji P., Khan S.U. Survey of techniques and architectures for designing
    energy-efficient data centers IEEE Syst. J., 10 (2) (2016), pp. 507-519, 10.1109/JSYST.2014.2315823
    View in ScopusGoogle Scholar [83] Shuja J., Ahmad R.W., Gani A., Ahmed A.I.A.,
    Siddiqa A., Nisar K., Khan S.U., Zomaya A.Y. Greening emerging it technologies:
    techniques and practices J. Internet Serv. Appl., 8 (1) (2017), p. 9, 10.1186/s13174-017-0060-5
    View in ScopusGoogle Scholar [84] Shuja J., Gani A., Shamshirband S., Ahmad R.W.,
    Bilal K. Sustainable cloud data centers: a survey of enabling techniques and technologies
    Renew. Sustain. Energy Rev., 62 (2016), pp. 195-214, 10.1016/j.rser.2016.04.034
    View PDFView articleView in ScopusGoogle Scholar [85] Cuadrado-Cordero I., Orgerie
    A.-C., Menaud J.-M. Comparative experimental analysis of the quality-of-service
    and energy-efficiency of vms and containers’ consolidation for cloud applications
    2017 25th International Conference on Software, Telecommunications and Computer
    Networks (SoftCOM), IEEE (2017), pp. 1-6, 10.23919/SOFTCOM.2017.8115516 Google
    Scholar [86] Jiang C., Wang Y., Ou D., Li Y., Zhang J., Wan J., Luo B., Shi W.
    Energy efficiency comparison of hypervisors Sustain. Comput.: Inform. Syst. (2017),
    10.1016/j.suscom.2017.09.005 Google Scholar [87] A. Jaikar, S. Bae, H. Han, B.
    Kong, S.A.R. Shah, S.-Y. Noh, Openstack and docker comparison for scientific workflow
    wrt execution and energy. Google Scholar [88] Morabito R. Power consumption of
    virtualization technologies: An empirical investigation 2015 IEEE/ACM 8th International
    Conference on Utility and Cloud Computing (UCC), IEEE (2015), pp. 522-527, 10.1109/UCC.2015.93
    View in ScopusGoogle Scholar [89] Shea R., Wang H., Liu J. Power consumption of
    virtual machines with network transactions: Measurement and improvements 2014
    Proceedings IEEE INFOCOM, IEEE (2014), pp. 1051-1059, 10.1109/INFOCOM.2014.6848035
    View in ScopusGoogle Scholar [90] https://01.org/blogs/2014/running-average-power-limit-%E2%80%93-rapl,
    [Online; accessed 29.09.18]. Google Scholar [91] Jin Y., Wen Y., Chen Q. Energy
    efficiency and server virtualization in data centers: An empirical investigation
    2012 IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS), IEEE
    (2012), pp. 133-138, 10.1109/INFCOMW.2012.6193474 View in ScopusGoogle Scholar
    [92] Arjona Aroca J., Chatzipapas A., Fernández Anta A., Mancuso V. A measurement-based
    analysis of the energy consumption of data center servers Proceedings of the 5th
    International Conference on Future Energy Systems, ACM (2014), pp. 63-74, 10.1145/2602044.2602061
    View in ScopusGoogle Scholar [93] Brogi A., Carrasco J., Cubo J., D’Andria F.,
    Di Nitto E., Guerriero M., Pérez D., Pimentel E., Soldani J. Seaclouds: an open
    reference architecture for multi-cloud governance European Conference on Software
    Architecture, Springer (2016), pp. 334-338, 10.1007/978-3-319-48992-6˙25 View
    in ScopusGoogle Scholar [94] Brogi A., Soldani J., Wang P. Tosca in a nutshell:
    Promises and perspectives European Conference on Service-Oriented and Cloud Computing,
    Springer (2014), pp. 171-186, 10.1007/978-3-662-44879-3˙13 View in ScopusGoogle
    Scholar [95] Brogi A., Rinaldi L., Soldani J. Tosker: A synergy between tosca
    and docker for orchestrating multicomponent applications Softw. - Pract. Exp.,
    48 (11) (2018), pp. 2061-2079, 10.1002/spe.2625 View in ScopusGoogle Scholar Cited
    by (0) Ilias Mavridis received his B.Sc. in Computer Science from the Department
    of Computer Science and Biomedical Informatics from the University of Thessaly
    in 2012. He received his M.Sc. in Networks-Communications-Systems Architecture
    from the Department of Informatics at the Aristotle University of Thessaloniki
    in 2015. Currently he is a Ph.D. Student in the Department of Informatics at the
    Aristotle University of Thessaloniki, under the supervision of Professor Helen
    Karatza. He is also a member of the Parallel and Distributed Systems Group, under
    the coordination of Professor Helen Karatza. His research interests include cloud
    computing and distributed processing. Helen Karatza is a Professor Emeritus in
    the Department of Informatics at the Aristotle University of Thessaloniki, Greece.
    Dr.Karatza’s research interests include Computer Systems Modeling and Simulation,
    Performance Evaluation, Grid and Cloud Computing, Energy Efficiency in Large Scale
    Distributed Systems, Resource Allocation and Scheduling and Real-time Distributed
    Systems. Professor Karatza is the Editor-in-Chief of the Elsevier Journal “Simulation
    Modeling Practice and Theory”, Area Editor of the “Journal of Systems and Software”
    of Elsevier, and she has been Guest Editor of Special Issues in multiple International
    Journals. View Abstract © 2018 Elsevier B.V. All rights reserved. Recommended
    articles Plant steroidal hormone epibrassinolide regulate – Heavy metal stress
    tolerance in L. by modulating antioxidant defense expression Environmental and
    Experimental Botany, Volume 122, 2016, pp. 1-9 Priyanka Sharma, …, Renu Bhardwaj
    View PDF A study on container virtualization for guarantee quality of service
    in Cloud-of-Things Future Generation Computer Systems, Volume 99, 2019, pp. 356-364
    Antonio Celesti, …, Massimo Villari View PDF An adaptive scheduling approach based
    on integrated best-worst and VIKOR for cloud computing Computers & Industrial
    Engineering, Volume 140, 2020, Article 106272 Elham Rafieyan, …, Mohammadreza
    Ramezanpour View PDF Show 3 more articles Article Metrics Citations Citation Indexes:
    65 Captures Readers: 88 View details About ScienceDirect Remote access Shopping
    cart Advertise Contact and support Terms and conditions Privacy policy Cookies
    are used by this site. Cookie settings | Your Privacy Choices All content on this
    site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights
    are reserved, including those for text and data mining, AI training, and similar
    technologies. For all open access content, the Creative Commons licensing terms
    apply.'
  inline_citation: '>'
  journal: Future generation computer systems
  limitations: '>'
  pdf_link: null
  publication_year: 2019
  relevance_score1: 0
  relevance_score2: 0
  title: Combining containers and virtual machines to enhance isolation and extend
    functionality on cloud computing
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/ic2e.2019.00034
  analysis: '>'
  authors:
  - Joy Rahman
  - Palden Lama
  citation_count: 30
  full_citation: '>'
  full_text: '>

    IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Subscribe Donate Cart Create
    Account Personal Sign In Browse My Settings Help Institutional Sign In All Books
    Conferences Courses Journals & Magazines Standards Authors Citations ADVANCED
    SEARCH Conferences >2019 IEEE International Confe... Predicting the End-to-End
    Tail Latency of Containerized Microservices in the Cloud Publisher: IEEE Cite
    This PDF Joy Rahman; Palden Lama All Authors 26 Cites in Papers 1792 Full Text
    Views Abstract Document Sections I. Introduction II. Background on Microservice
    Architecture III. Related Work IV. Platform V. Performance Characterization Show
    Full Outline Authors Figures References Citations Keywords Metrics Abstract: Large-scale
    web services are increasingly adopting cloud-native principles of application
    design to better utilize the advantages of cloud computing. This involves building
    an application using many loosely coupled service-specific components (microservices)
    that communicate via lightweight APIs, and utilizing containerization technologies
    to deploy, update, and scale these microservices quickly and independently. However,
    managing the end-to-end tail latency of requests flowing through the microservices
    is challenging in the absence of accurate performance models that can capture
    the complex interplay of microservice workflows with cloudinduced performance
    variability and inter-service performance dependencies. In this paper, we present
    performance characterization and modeling of containerized microservices in the
    cloud. Our modeling approach aims at enabling cloud platforms to combine resource
    usage metrics collected from multiple layers of the cloud environment, and apply
    machine learning techniques to predict the end-to-end tail latency of microservice
    workflows. We implemented and evaluated our modeling approach on NSF Cloud''s
    Chameleon testbed using KVM for virtualization, Docker Engine for containerization
    and Kubernetes for container orchestration. Experimental results with an open-source
    microservices benchmark, Sock Shop, show that our modeling approach achieves high
    prediction accuracy even in the presence of multi-tenant performance interference.
    Published in: 2019 IEEE International Conference on Cloud Engineering (IC2E) Date
    of Conference: 24-27 June 2019 Date Added to IEEE Xplore: 08 August 2019 ISBN
    Information: DOI: 10.1109/IC2E.2019.00034 Publisher: IEEE Conference Location:
    Prague, Czech Republic I. Introduction Large-scale web services (e.g Netflix,
    Microsoft Bing, Uber, Spotify etc.) are increasingly adopting cloud-native principles
    and design patterns such as microservices and containers to better utilize the
    advantages of the cloud computing delivery model, which includes greater agility
    in software deployment, automated scalability, and portability across cloud environments
    [24], [30]. In a micro-services architecture, an application is built using a
    combination of loosely coupled and service-specific software containers that communicate
    using APIs, instead of using a single, tightly coupled monolith of code. This
    development methodology combined with recent advancements in containerization
    technologies makes an application easier to enhance, maintain, and scale. However,
    it is challenging to manage the end-to-end tail latency (e.g 95thpercentile latency)
    of requests flowing through the microservice architecture, which could result
    in poor user experiences and loss of revenue [32], [46]. Sign in to Continue Reading
    Authors Figures References Citations Keywords Metrics More Like This Application
    interference analysis: Towards energy-efficient workload management on heterogeneous
    micro-server architectures 2017 IEEE Conference on Computer Communications Workshops
    (INFOCOM WKSHPS) Published: 2017 A Resilient Agent-Based Architecture for Efficient
    Usage of Transient Servers in Cloud Computing 2018 IEEE International Conference
    on Cloud Computing Technology and Science (CloudCom) Published: 2018 Show More
    IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS
    VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION
    AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE:
    +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help
    | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting
    | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s
    largest technical professional organization dedicated to advancing technology
    for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: null
  publication_year: 2019
  relevance_score1: 0
  relevance_score2: 0
  title: Predicting the End-to-End Tail Latency of Containerized Microservices in
    the Cloud
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1016/j.ascom.2017.07.004
  analysis: '>'
  authors:
  - D. Morris
  - S. Voutsinas
  - N. C. Hambly
  - Robert Mann
  citation_count: 16
  full_citation: '>'
  full_text: '>

    Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Abstract Keywords 1. Introduction 2. Virtual machines and containers 3.
    Docker 4. IVOATeX in Docker 5. Docker in Firethorn 6. Issues found and lessons
    learned 7. Conclusion Acknowledgements References Show full outline Figures (33)
    Show 27 more figures Astronomy and Computing Volume 20, July 2017, Pages 105-119
    Full length article Use of Docker for deployment and testing of astronomy software☆
    Author links open overlay panel D. Morris, S. Voutsinas, N.C. Hambly, R.G. Mann
    Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.ascom.2017.07.004
    Get rights and content Abstract We describe preliminary investigations of using
    Docker for the deployment and testing of astronomy software. Docker is a relatively
    new containerization technology that is developing rapidly and being adopted across
    a range of domains. It is based upon virtualization at operating system level,
    which presents many advantages in comparison to the more traditional hardware
    virtualization that underpins most cloud computing infrastructure today. A particular
    strength of Docker is its simple format for describing and managing software containers,
    which has benefits for software developers, system administrators and end users.
    We report on our experiences from two projects – a simple activity to demonstrate
    how Docker works, and a more elaborate set of services that demonstrates more
    of its capabilities and what they can achieve within an astronomical context –
    and include an account of how we solved problems through interaction with Docker’s
    very active open source development community, which is currently the key to the
    most effective use of this rapidly-changing technology. Previous article in issue
    Next article in issue Keywords DockerSurvey astronomyDevOpsReproducible scienceContainerizationVirtualization
    1. Introduction In common with many sciences, survey astronomy has entered the
    era of “Big Data”, which changes the way that sky survey data centres must operate.
    For more than a decade, they have been following the mantra of ‘ship the results,
    not the data’ (e.g. Quinn et al., 2004, and other contributions within the same
    volume) and deploying “science archives” (e.g. Hambly et al., 2008, and references
    therein), which provide users with functionality for filtering sky survey data
    sets on the server side, to reduce the volume of data to be downloaded to the
    users’ workstations for further analysis. Typically these science archives have
    been implemented in relational database management systems, and astronomers have
    become adept in exploiting the power of their Structured Query Language (SQL)
    interfaces. However, as sky survey catalogue databases have grown in size – the
    UKIDSS (Hambly et al., 2008) databases were 1–10 terabytes, VISTA (Cross et al.,
    2012) catalogue data releases are several 10s of terabytes, as is the final data
    release from the Sloan Digital Sky Survey (DR12; Alam et al. 2015), Pan-STARRS1
    is producing a terabyte database (Flewelling, 2015) and LSST (Jurić et al. 2015;
    catalogue data volumes of up to 1 terabyte per night) will produce databases several
    petabytes in size – the minimally useful subset of data for users is growing to
    the point where simple filtering with an SQL query is not sufficient to generate
    a result set of modest enough size for a user to want to download to their workstation.
    This means that the data centre must provide the server-side computational infrastructure
    to allow users to conduct (at least the first steps in) their analysis in the
    data centre before downloading a small result set. The same requirement arises
    for data centres that wish to support survey teams in processing their imaging
    data (with data volumes typically 10–20 times larger than those quoted above for
    catalogue data sets). In both cases data centre staff face practical issues when
    supporting different sets of users running different sets of software on the same
    physical infrastructure (e.g. Gaudet et al. 2009). These requirements are not,
    of course, peculiar to astronomy, and similar considerations have motivated the
    development of Grid and Cloud Computing over the past two decades. A pioneering
    example of the deployment of cloud computing techniques for astronomy has been
    the CANFAR project Gaudet et al. (2009), Gaudet et al. (2011), Gaudet (2015) undertaken
    by the Canadian Astronomy Data Centre and collaborators in the Canadian research
    computing community. The current CANFAR system is based on hardware virtualization,
    where the data processing software and web services are run in virtual machines,
    isolated from the details of the underlying physical hardware. Following on from
    the development of systems based on hardware virtualization, the past few years
    have seen an explosion of interest within both the research computing and commercial
    IT sectors in operating system level virtualization, which provides an alternative
    method of creating and managing the virtualized systems. A lot of the most recent
    activity in this field has centred on Docker and this paper presents lessons learned
    from two projects we have conducted involving Docker: a simple test of its capabilities
    as a deployment system and as part of more complicated project connecting a range
    of Virtual Observatory (VO; Arviset et al. 2010) services running in separate
    Docker containers. Even by the standards of large open source projects, the rise
    of Docker has been rapid and its development continues apace. A journal paper
    cannot hope, therefore, to present an up-to-date summary of Docker, nor an authoritative
    tutorial in its use, so we attempt neither here. Rather, we aim to describe the
    basic principles underlying Docker and to contrast its capabilities with the virtual
    machine technologies with which astronomers may be more familiar, highlighting
    where operating system level virtualization provides benefit for astronomy. We
    illustrate these benefits through describing our two projects and the lessons
    we have learned from undertaking them. Many of the issues we encountered have
    since been solved as the Docker engine and toolset continue to evolve, but we
    believe there remains virtue in recounting them, both because they illustrate
    basic properties of Docker containers and because they show how the Docker community
    operates. For the sake of definiteness, we note the development of the systems
    described in this paper were based on Docker version 1.6 and that we discuss solutions
    to the issues we encountered that have appeared up to version 1.12. The plan of
    this paper is as follows. Section 2 describes hardware and operating system level
    virtualization, summarizing the differences between the two approaches. Section
    3 introduces Docker as a specific implementation of operating system level virtualization.
    Section 4 describes our first Docker project, in which it was used to create a
    deployment system for the IVOATeX Document Preparation System (Demleitner et al.,
    2016). Section 5 describes the use of Docker in the development and deployment
    of the Firethorn VO data access service (Morris, 2013). Section 6 describes a
    specific problem we encountered and how it was solved through interaction with
    the Docker development community. Section 7 summarizes some of the lessons we
    learned from these experiments and presents our conclusions as to the place that
    Docker (or similar technologies) may develop in astronomical data management.
    2. Virtual machines and containers The physical hardware of a large server may
    have multiple central processor units, each with multiple cores with support for
    multiple threads and access to several hundred gigabytes of system memory. The
    physical hardware may also include multiple hard disks in different configurations,
    including software and hardware RAID systems, and access to network attached storage.
    However, it is rare for a software application to require direct access to the
    hardware at this level of detail. In fact, it is more often the case that a software
    application’s hardware requirements can be described in much simpler terms. Some
    specific cases such as database services dealing with large data sets may have
    specific hardware requirements for disk access but in most cases this still would
    represent a subset of the hardware available to the physical machine. Virtualization
    allows a system administrator to create a virtual environment for a software application
    that provides a simplified abstract view of the system. If a software application
    is able to work within this abstract environment then the same application can
    be moved or redeployed on any platform that is capable of providing the same virtual
    environment, irrespective of what features or facilities the underlying physical
    hardware provides. This ability to create standardized virtual systems on top
    of a variety of different physical hardware platforms formed the basis of the
    Infrastructure as a Service (IaaS) cloud computing service model as exemplified
    by the large scale providers like Amazon Web Services (AWS).1 The interface between
    customer and service provider is based on provision of abstract virtual machines.
    The details of the underlying hardware platform and the infrastructure required
    to provide network, power and cooling are all the service provider’s problem.
    What happens inside the virtual machine is up to the customer, including the choice
    of operating system and software applications deployed in it. With hardware virtualization,
    each virtual machine includes a simulation of the whole computer, including the
    system BIOS, PCI bus, hard disks, network cards, etc. The aim is to create a detailed
    enough simulation such that the operating system running inside the virtual machine
    is not aware that it is running in a simulated environment. The key advantage
    of this approach is that because the guest system is isolated from the host, the
    guest virtual machine can run a completely different operating system to that
    running on the physical host. However, this isolation comes at a price. With hardware
    virtualization each virtual machine uses a non-trivial share of the physical system’s
    resources just implementing the simulated hardware, resources which are no longer
    available for running the intended application software and services. Most of
    the time this cost is hidden from the end user, but it is most visible when starting
    up a new virtual machine. With hardware virtualization the virtual machine has
    to run through the full startup sequence from the initial BIOS boot through to
    the guest operating system initialization process, starting the full set of daemons
    and services that run in the background. Comparing hardware virtualization with
    operating system level virtualization (Fig. 1) we find a number of key differences
    between them, to do with what they are capable of and how they are used. A key
    difference is determined by the different technologies used to implement the virtual
    machines. In hardware virtualization the host system creates a full simulation
    of the guest system, including the system hardware, firmware and operating system.
    With operating system level virtualization the physical host operating system
    and everything below it, including the hardware and system firmware, is shared
    between the host and guest systems. This imposes a key limitation on operating
    system level virtualization in that the host and guest system must use the same
    operating system. So, for example, if a Linux host system can use operating system
    level virtualization to support guests running different Linux distributions and
    versions, it cannot use operating system level virtualization to support a Berkeley
    Software Distribution (BSD) or Illumos guest. However, if this limitation is not
    a problem, then sharing the system hardware, firmware and operating system kernel
    with the host system means that supporting operating system level virtual machines,
    commonly referred to as containerization, represents a much lower cost in terms
    of system resources. This, in turn leaves more of the system resources available
    for running the intended application software and services. Download : Download
    high-res image (280KB) Download : Download full-size image Fig. 1. Comparison
    between hardware (left) and operating system level virtualization (right). 3.
    Docker Docker is emerging as the technology of choice for VM containers Yu and
    Huang (2015), Wang et al. (2015). Docker is an operating system level virtualization
    environment that uses software containers to provide isolation between applications.
    The rapid adoption and evolution of Docker from the initial open source project
    launched in 20132 by ‘platform-as-a-service’ (PaaS) provider dotCloud,3 to the
    formation of the Open Container Initiative (OCI)4 in 20155 suggests that Docker
    met a real need within the software development community which was not being
    addressed by the existing tools. (As an aside, it is interesting to note that
    the technologies behind OS virtualization have been available for a number of
    years. For example, Solaris containers have been available as part of the Solaris
    operating system since 2005, and cgroups and namespaces have been part of the
    Linux kernel since 2007.) Although both the speed and simplicity of Docker containers
    have been factors contributing to its rapid adoption, arguably it is the development
    of a standardized Dockerfile format for describing and managing software containers
    that has been the unique selling point, differentiating Docker from its competitors,6
    ,7 and has been the main driving force behind the rapid adoption of Docker across
    such a wide range of different applications: At the end user level, Docker enables
    users to describe, share and manage applications and services using a common interface
    by wrapping them in standardized containers. From a developer’s perspective, Docker
    makes it easy to create standard containers for their software applications or
    services. From a system administrator’s perspective, Docker makes it easy to automate
    the deployment and management of business level services as a collection of standard
    containers. 3.1. Docker, DevOps and MicroServices In a ‘DevOps’ (development and
    operations) environment, software developers and system administrators work together
    to develop, deploy and manage enterprise level services. Describing the deployment
    environment using Docker containers enables the development team to treat system
    infrastructure as code, applying the same tools they use for managing the software
    source code, e.g. source control, automated testing, etc. to the infrastructure
    configuration. 3.2. Reproducible science In the science and research community,
    Docker’s ability to describe a software deployment environment has the potential
    to improve the reproducibility and the sharing of data analysis methods and techniques:
    Boettiger (2014) describes how the ability to publish a detailed description of
    a software environment alongside a research paper enables other researchers to
    reproduce and build on the original work. Nagler et al. (2015) describes work
    to develop containerized versions of software tools used to analyse data from
    particle accelerators.8 The Nucletid project9 provides reproducible evaluation
    of genome assemblers using docker containers. The BioDocker10 project provides
    a curated set of bioinformatics software using Docker containers. 3.3. Compute
    resource services There are two roles in which Docker may be useful in implementing
    systems which enable end users to submit their own code to a compute resource
    for execution within a data centre. Docker can be used internally as part of the
    virtualization layer for deploying and managing the execution environments for
    the submitted code. This scenario is already being evaluated by a number of groups,
    in particular Docker is one of the technologies being used to deliver a PaaS infrastructure
    for the European Space Agency’s Gaia mission archive O’Mullane (2016), Ferreruela
    (2016). Alternatively, Docker can be used as part of the public service interface,
    providing the standard language for describing and packaging the software. In
    this scenario, the user would package their software in a container and then either
    submit the textual description or the binary container image to the service for
    execution. The advantage of this approach is that the wrapping of analysis software
    in a standard container enables the user to build and test their software on their
    own platform before submitting it to the remote service for execution. The common
    standard for the container runtime environment means that the user can be confident
    that their software will behave in the same manner when tested on a local platform
    or deployed on the remote service. For a service provider, using Docker to add
    containerization to the virtualization layer makes it easier to provide reliable,
    predictable execution environments for users to deploy their code into. This in
    turn reduces the number of support issues regarding software deployment and installation
    that the service provider needs to deal with. 3.4. Reproducible deployment It
    is often the case that a development team does not have direct control over the
    software environment where their service will be deployed. For example, the deployment
    platform may be configured with versions of operating system, Java runtime and
    Tomcat webserver which are determined by the requirements of other applications
    already running on the machine and by the system administrators running the system.
    This can present problems when attempting to update the version of these infrastructure
    components. Unless it is possible to isolate the different components from each
    other then a system component cannot be updated unless all of the other components
    that interact with it can be updated at the same time. With an operating system
    level virtualization technology like Docker, each application can be wrapped in
    a container configured with a specific version of operating system, language runtime
    or webserver. The common interface with the system is set at the container level,
    not at the operating system, language or application server level. In theory it
    is possible to do something similar using hardware virtualization. However, in
    practice the size and complexity of the virtual machine image makes this difficult.
    In a container based approach to service deployment, the development process includes
    a container specifically designed for the service. The same container is used
    during the development and testing of the software and becomes part of the final
    project deliverable. The final product is shipped and deployed as the container,
    with all of its dependencies already installed, rather than as an individual software
    component which requires a set of libraries and components that need to be installed
    along with it. This not only simplifies the deployment of the final product, it
    also makes it more reproducible. 4. IVOATeX in Docker As an early experiment in
    using containers to deploy applications, we used Docker to wrap the IVOATeX11
    document build system to make it easier to use. The IVOATeX system uses a combination
    of LaTeX tools and libraries, a compiled C program to handle LaTeX to HTML conversion,
    and a makefile to manage the build process. IVOATeX includes a fairly clear set
    of install instructions. However, the instructions are specific to the Debian
    Linux distribution and porting them to a different Linux distribution is not straightforward.
    In addition, it was found that, in some instances, configuring a system with the
    libraries required by the IVOATeX system conflicted with those required by other
    document styles. Installing the full IVOATeX software makes sense for someone
    who would be using it regularly. However, installing and configuring all of the
    required components is a complicated process for someone who just wants to make
    a small edit to an existing IVOA document. In order to address this we created
    a simple Docker container that incorporates all of the components needed to run
    the IVOATeX system configured and ready to run. The source code for our IVOATeX
    container is available on GitHub12 and a binary image is available from the Docker
    registry.13 The Docker Hub14 is a service provided by Docker Inc to enable users
    to publish binary images of their containers. The Docker Hub contains curated
    images for a wide range of different software including Linux distributions like
    Debian and Fedora, programming languages like Java and Python, and database services
    like MariaDB and PostgreSQL alongside user contributed images like our own IVOATeX
    container. In our experience, the wide range of free to use, open source software
    available in the Docker Hub made it extremely easy to get started, simply by running
    one of these pre-configured images or by using them as the starting point for
    developing our own images. The source code for our IVOATeX project consists of
    a text Dockerfile which lists the steps required to create the binary image. A
    Dockerfile specifies a list of commands needed to create an image, thus defining
    the ‘recipe’ of an image, which is machine-readable, but still simple enough to
    be human readable. Although the idea of an automated software deployment definition
    is not new, and similar ideas have been developed before, for example the kickstart
    format which is part of the Anaconda install tools for RedHat Linux.15 The Dockerfile
    is one of the few formats that is simple enough to be able to describe the configuration
    for a range of different Linux distributions using the same basic syntax. When
    a Dockerfile is built, the resulting binary image consists of a series of layers.
    Each layer in the image describes the files which have been added, changed or
    deleted by the corresponding Dockerfile command. By formatting the binary image
    as a series of layers, each of which has a unique identifier, the Docker system
    can share layers that are common between different containers. So, for example,
    if two containers are based on the same parent container, then the Docker host
    only has to download and store one copy of the layers needed to build the parent
    container, and then apply the specific changes needed to create each of the child
    images. The following section describes the Dockerfile commands used to create
    the IVOATeX container. (N.B. in this and subsequent listings we have added line
    numbers to aid explanation; they are not present in the Dockerfile itself.) Download
    : Download high-res image (253KB) Download : Download full-size image The first
    line of a Dockerfile uses the FROM command to declare the parent image this project
    is derived from: Download : Download high-res image (21KB) Download : Download
    full-size image At the start of the build process, Docker will download this base
    from the Docker registry and then apply our build instructions to it. Each new
    instruction adds another layer in the file system of the final image. In our example,
    the notroot-debian image is a container developed by one of our colleagues that
    includes tools for changing the user account when the container is started. This
    enables our LaTeX tools to run using our normal user account rather than root.
    The next section of the Dockerfile uses the ENV command to set an environment
    variable that prevents the apt-get install commands from requesting interactive
    user input: Download : Download high-res image (21KB) Download : Download full-size
    image A Dockerfile may contain multiple ENV commands to set environment variables
    which will be available both during the build process and in the runtime environment
    for a container. The next section uses RUN commands to call the Debian package
    manager, apt-get, to install the C compiler and build tools: Download : Download
    high-res image (36KB) Download : Download full-size image Followed by the HTML
    editing tools: Download : Download high-res image (45KB) Download : Download full-size
    image and the LaTeX tools: Download : Download high-res image (65KB) Download
    : Download full-size image The next two lines use ENV commands to set the default
    user name and the home directory which are used by the metagrid/notroot-debian
    base image to set the user account and home directory when a new container is
    created: Download : Download high-res image (31KB) Download : Download full-size
    image The final step in the build instructions declare the working directory as
    a data volume: Download : Download high-res image (20KB) Download : Download full-size
    image This marks the /texdata directory as a separate volume outside the layered
    file system of the Docker image. When we run an instance of this container, we
    can use the –volume option to mount a directory from the host system as the /texdata
    directory inside the container: Download : Download high-res image (17KB) Download
    : Download full-size image and once inside the container we can use the make commands
    to build our IVOATeX document: Download : Download high-res image (14KB) Download
    : Download full-size image The initial idea for this project was based on the
    work by Jessie Frazelle on wrapping desktop applications in containers.16 While
    exploring this technique we encountered a security issue that potentially allows
    privileged access to the host file system. When run from the command line, the
    Docker run command does not run the container directly, instead it uses a socket
    connection to send the command to the Docker service, which runs the container
    on your behalf. A side effect of the way that the Docker service works is that
    the root user inside the container also has root privileges when accessing the
    file system outside the container. This normally is not a problem, unless you
    use a –volume option to make a directory on the host platform accessible from
    inside the container, which is exactly what we need to do to enable the IVOATeX
    tools to access the source for our LaTeX document. In our case, this does not
    prevent our program from working, but it does mean that the resulting PDF and
    HTML documents end up being owned by root, which make it difficult for the normal
    user to manage them. This is where the user management tools provided by the notroot-debian
    base image can help. The source code for the notroot-debian 17 consists of a Dockerfile
    which describes how to build the image, plus a shell script that is run when a
    container instance starts up: Download : Download high-res image (112KB) Download
    : Download full-size image As with our ivoatex container, the first line of the
    Dockerfile uses the FROM command to declare the base image to use as the starting
    point to build the new image. In this case, it refers to one of the official Debian
    images registered in the Docker registry: Download : Download high-res image (7KB)
    Download : Download full-size image Followed by an ENV and RUN command to install
    the sudo program: Download : Download high-res image (44KB) Download : Download
    full-size image In this example we are installing a tool that most people would
    normally expect to be installed by default as part of a normal Debian system.
    Many of the base images provided in the Docker registry contain the minimum set
    of components necessary to run a basic shell and very little else. This is by
    design, both to keep the physical size of the image as small as possible (85 M
    bytes for the Debian Wheezy base image), and to minimize the potential attack
    surface of software that is not required. In general it is easier to start with
    a minimal configuration and add the components that you need, rather than starting
    from a larger base and removing the ones that you do not. The next section of
    the Dockerfile uses the COPY command to copy the shell script into the container
    image and then uses a RUN command to set the permissions to make it executable:
    Download : Download high-res image (28KB) Download : Download full-size image
    The last line of the Dockerfile adds the shell script as the container ENTRYPOINT.
    Which means that this script will be invoked whenever a new container instance
    is started: Download : Download high-res image (19KB) Download : Download full-size
    image The script itself checks to see if the target user account and group are
    already defined, and if not it will create a new user account or group. It then
    uses sudo to change from the root user to the target user before executing the
    original command for the container. If a new ivoatex container is run using the
    following command: Download : Download high-res image (24KB) Download : Download
    full-size image The –env option sets the useruid environment variable to the same
    uid as the current user. The ENTRYPOINT script from the notroot-debian image will
    use this to create a new user account inside the container with the same uid as
    the user outside the container. The –volume option mounts the current working
    directory, returned by the pwd command, as /texdata inside the container. The
    result is that the IVOATeX tools are run inside the container using the same uid
    as the external user, and can see the LaTeX document source in the /texdata directory
    inside the container. This workaround highlights a potentially serious problem
    with the way the Docker system operates. If we create a standard Debian container
    and mount the /etc directory from the host system as /albert inside the container:
    Download : Download high-res image (17KB) Download : Download full-size image
    Then, inside the container we run the vi text editor and edit the passwd file
    in the /albert directory: Download : Download high-res image (6KB) Download :
    Download full-size image The –volume mount means that vi running inside the container
    is able to edit the passwd file outside the container, using root privileges from
    inside the container. It is important to note that this issue is not caused by
    a security weakness in the container or in the Docker service. The problem occurs
    because the user that runs a container has direct control over what resources
    on the host system the container is allowed to access. Without the –volume mount,
    the container would not be able to access any files on the host system and there
    would be no problem. This is not normally an issue, because users would not normally
    have sufficient privileges to run Docker containers from the command line. Users
    on a production system would normally be given access to a container management
    program such as Kubernetes18 or OpenStack19 to manage their containers. In addition,
    most Linux distributions now have security constraints in place which prevent
    containers from accessing sensitive locations on the file system. For example,
    on RedHat based systems the SELinux security module prevents containers from accessing
    a location on the file system unless it has explicitly been granted permission
    to do so. Developing the IVOATeX container was an experimental project to learn
    how Docker works. The privileged escalation issue we encountered relates to a
    specific use case, where the end user is launching a user application container
    directly from the command line. Since we first worked on this, container technology
    has continued to evolve and there has been significant progress in a number of
    areas that addresses this issue. In particular the work within Docker on user
    namespaces,20 ,21 but also the work in the Open Containers project,22 , 23 ,24
    and new container hosting platforms such as Singularity25 which enable users to
    run Docker containers as non privileged users. If we were to develop a similar
    user application container in the future we would probably use a platform like
    Singularity to run the container as a non-privileged user, thus avoiding the issue
    of privileged access to the file system. 5. Docker in Firethorn 5.1. Firethorn
    overview The goal of the Firethorn project is to enable users to run queries and
    store results from local astronomy archive or remote IVOA relational databases
    and share these results with others by publishing them via a TAP service.26 The
    project has its origins in a prototype data resource federation service (Hume
    et al., 2012) and is built around the Open Grid Service Architecture Data Access
    Infrastructure (OGSA-DAI; Holliman et al. 2011 and references therein). The system
    architecture consists of two Java web services, one for handling the catalog metadata,
    and one for handling database queries and processing the results; two SQL Server
    databases,27 one for storing the catalog metadata and one for storing query results;
    a web.py28 based user interface, and a Python testing tool. A schematic representation
    of the architecture is shown in Fig. 2. Download : Download high-res image (369KB)
    Download : Download full-size image Fig. 2. Firethorn architecture illustrating
    the key components and web services. 5.2. Virtual machine allocation and containerization
    During the development of the Firethorn project we went through a number of stages
    in our use of virtualization and containerization. From the initial development
    where the services were manually deployed to an automated system using shell scripts
    to manage multiple deployments on the same platform: Manually configured virtual
    machines. Shell scripts to manage the virtual machines. Containerization for the
    core Tomcat web services. Ambassador pattern for database connections. Containerizing
    the Python GUI webapp and the Python test tools. Orchestration scripts to manage
    multiple deployments on the same platform. At the beginning of the project we
    assigned a full KVM29 virtual machine to each of our Java web services, connected
    to a Python webapp running on the physical host which provided the user interface
    web pages (see Fig. 3; each virtual machine was manually configured). Assigning
    a full virtual machine to each component represented a fairly heavy cost in terms
    of resources. However, at the time, this level of isolation was needed to support
    the different versions of Python, Java and Tomcat required by each of the components.
    Using virtual machines like this gave us an initial level of isolation from the
    physical host machine configuration. In theory it also allowed us to run more
    than one set of services on the same physical platform, while still being able
    to configure each set of services independently without impacting other services
    running on the same physical hardware. Download : Download high-res image (299KB)
    Download : Download full-size image Fig. 3. Manually configured virtual machine
    for each web application. However, in practice it was not until we moved from
    using manually configured virtual machines to using a set of shell scripts based
    on the ischnura-kvm30 project to automate the provisioning of new virtual machines
    that we were able to run multiple sets of services in parallel. Replacing the
    manually configured instances with template based instances gave us the reliable
    and consistent set of platforms we needed to develop our automated integration
    tests (see Fig. 4). The ischnura-kvm templates handle the basic virtual machine
    configuration such as cpu and memory allocation, network configuration, disk space
    and operating system. Download : Download high-res image (335KB) Download : Download
    full-size image Fig. 4. Multiple sets of scripted virtual machine configurations.
    Once the virtual machines were created, we used a set of shell scripts to automate
    the installation of the software packages needed to run each of our services.
    For our Java web services, this included installing and configuring specific versions
    of the Java runtime31 and Apache Tomcat.32 The final step in the process was to
    deploy our web service and configure them with the user accounts and passwords
    needed to access the local databases. The first stage of containerization was
    to create Docker containers for the two Tomcat web services, leaving the user
    interface web.py service running in the Apache web server on the physical host.
    The process of building the two Tomcat web service containers was automated using
    the Maven Docker plugin.33 Fig. 5 illustrates this first stage. Download : Download
    high-res image (306KB) Download : Download full-size image Fig. 5. First stage
    containerization (Tomcats but not Apache). 5.3. Using pre-packaged or in-house
    base images We ended up creating our own containers as the base images for our
    Tomcat web services, rather than using the official Java34 and Tomcat35 images
    available on the Docker registry. This was a result of our early experiments with
    Docker where we explored different methods of creating containers from simple
    Linux base images and learned that creating our own base images gave us much more
    control over the contents of our containers. The flexibility of the container
    build system means that we are able to swap between base containers by changing
    one line in a Docker buildfile and re-building. This enabled us to test our containers
    using a variety of different base images, and work towards standardizing on a
    common version of Python, Java and Tomcat for all of our components. Based on
    our experience, we would recommend that other projects follow a similar route
    and define their own set of base images to build their containers, rather than
    using the pre-packaged images available from the Docker registry. The latter are
    ideal for rapid prototyping, but there are some issues that mean they may not
    be suitable for use in a production environment. Although the Docker project is
    working to improve and to verify the official images,36 there is still a lot of
    work to be done in this area. The main issue with using a pre-packaged base image
    is that the contents of containers are directly dependent on how the third party
    image was built and what it contains. Unless full details of what the third party
    image contains are available it can be difficult to assess the impact of a security
    issue in a common component such as OpenSSL37 ,38 or glibc39 ,40 ,41 has on a
    system that is based on an opaque third party binary image. 5.4. Ambassador pattern
    At this point in the project we also began to use the Docker ambassador pattern42
    for managing the connections between our webapps and databases. The idea behind
    the ambassador pattern is to use a small lightweight container running a simple
    proxy service like socat43 to manage a connection between a Docker container and
    an external service. In our case, the two socat proxies in Docker containers makes
    the relational database appear to be running in another container on the same
    Docker host, rather than on a separate physical machine. This enables our service
    orchestration scripts to connect our web services to our database server using
    Docker container links. The arrangement is shown schematically in Fig. 6. At first
    glance, adding proxies like this may seem to be adding unnecessary complication
    and increasing network latency for little obvious gain. The benefit comes when
    we want to modify the system to support developers working remotely on platforms
    outside the Institute network firewall, who need to be able to run the set of
    services on their local system but still be able to connect to the relational
    database located inside the firewall. Download : Download high-res image (386KB)
    Download : Download full-size image Fig. 6. Socat ambassadors for database connections.
    In this scenario (illustrated schematically in Fig. 7) the sql-proxy containers
    are replaced by sql-tunnel containers that use a tunnelled ssh connection to link
    to the remote database located inside the Institute network firewall. The shell
    script for using the simple socat sql-proxy containers creates a named instance
    of the sql-proxy container for each of the database connections. In the following
    example, we create two database proxy containers, one for the metadata database
    and one for the userdata database. Each sql-proxy container runs an instance of
    socat that listens on port 1433 on the container and connects to port 1433 on
    the target database host: Download : Download high-res image (57KB) Download :
    Download full-size image Download : Download high-res image (458KB) Download :
    Download full-size image Fig. 7. SSH ambassadors for database connections. Within
    the virtual network created by Docker, containers are accessible using their names.
    So the configuration file for the Java web services can use the names of the sql-proxy
    containers in the JDBC connection url for the databases: Download : Download high-res
    image (12KB) Download : Download full-size image and Download : Download high-res
    image (12KB) Download : Download full-size image As far as the Java web services
    are concerned, they are making JDBC connections to two machines on the local network
    called metadata and userdata. To re-configure the system to use remote tunnelledconnections
    to access the databases, the deployment script can be modified to use instances
    of the sql-tunnel container, passing in environment variables for the ssh user
    name and host name used to create the ssh tunnel, and a volume mount of the SSH_AUTH_SOCK
    Unix socket to allow the ssh client to use agent forwarding44 for authentication:
    Download : Download high-res image (120KB) Download : Download full-size image
    Each sql-tunnel container runs an instance of the ssh client that listens on port
    1433 on the container and creates an encrypted tunnelled connection via the ssh
    gateway host to port 1433 on the target database host. Because the sql-tunnel
    containers function as drop-in replacements for the sql-proxy containers, as far
    as the rest of the system is concerned, nothing has changed. The configuration
    files use the same URLs for the JDBC database connections, and as far as the Java
    web services are concerned, they are still making JDBC connections to two machines
    on the local network called metadata and userdata. Obviously, using tunnelled
    ssh connections for database access adds significant latency to the system, and
    would not be appropriate for a production system. However, based on our experience,
    using tunnelled ssh connections for database access works well for development
    and testing. 5.5. Python GUI and Python testing The final stage in the migration
    to Docker containers was to wrap the web.py user interface service in a container
    and add that to our set of images (see Fig. 8). The web.py web user interface
    container is built starting with a basic Ubuntu image and building on that with
    a series of containers that add the Apache webserver, the Python language, a set
    of Python libraries and finally the web.py web application itself. Download :
    Download high-res image (315KB) Download : Download full-size image Fig. 8. Adding
    the web.py container. An additional web.py web interface was later developed for
    a separate project (Gaia European Network for Improved User Services; e.g. Hypki
    and Brown 2016), which used the distributed querying feature of Firethorn. Because
    of the separation of the interfaces, Firethorn web services and databases into
    containers and the modular design of Docker systems, attaching this new interface
    container to the existing set of Docker containers was seamless. Linking a configuration
    file and startup script when running the web application – a common technique
    when deploying web application containers which makes the interchange of components
    in the system chain easier – was also used in both. Another example of a top level
    container used in our system was the testing suite that we used to test our system
    for performance and accuracy, also written in Python. This consisted of a number
    of possible tests, which would each launch an instance of the core web service
    containers, as well as a number of other containers required for the tests, for
    databases to log results, or for loading and running the test suite code. By the
    end of the project we employed a set of bash scripts that allowed us to run a
    one line command to start the required test, which we would run on any virtual
    machine. These were long running tests, which helped us gauge how a system using
    Docker containers would behave and scale with large data volumes and long term
    up-time and whether Docker as a technology was production-readyor not. The full
    test deployment also included a local MySQL database deployed in a container alongside
    the Python test application for storing test results (see Fig. 9). The result
    is a set of plug-and-play containers for each component in our system that can
    be swapped and replaced with different versions or different implementations by
    modifying the scripts that manage the container orchestration. Download : Download
    high-res image (454KB) Download : Download full-size image Fig. 9. Python test
    suite configuration. A live deployment would include the web.py web application
    for the user interface, and use socat proxies to connect to the local relational
    databases. In the test and development scenarios we replace the web.py web application
    with a Python test client connected to a local MySQL database running in a container,
    and in some cases we also replaced the connection to the SQL Server metadata database
    for our Firethorn web service with a PostgreSQL database running in a container.
    5.6. Orchestrating build and deployment All of our containers are managed by a
    set of shell scripts which are included and maintained as part of the project
    source code. The Docker build scripts and the container orchestration scripts
    required to build and deploy a full set of services for each of the use cases
    are all stored in our source control repository alongside the source code for
    the rest of our project. Automating the service deployment, and treating the build
    and deployment scripts as part of the core project source code is a key step towards
    implementing what is referred to as Programmable Infrastructure or Infrastructure
    as code.45 ,46 The bash scripts described in previous sections are used to deploy
    and link Docker container instances to create the required configuration of containers
    and services. We have recently started to experiment with Docker Compose47 which
    makes this process much simpler and clearer. Compose allows you to define a set
    of container configurations in a YAML 48 file, where all the options that were
    defined in the shell scripts and passed as parameters to the Docker run command,
    are now defined in the YAML configuration file. Which means a complete set of
    inter-linked containers can be initialized with a single docker-compose command:
    Download : Download high-res image (9KB) Download : Download full-size image where
    <service> refers to one of the container instances defined in the YAML configuration
    file. Compose simplifies the process of configuring, initializing and linking
    containers, and overall the process of building development, testing, and staging
    environments as well as continuous integration workflows. However, at the time
    of writing we have only just started experimenting with Compose and we do not
    have enough experience with it to provide a more thorough description of its use.
    5.7. Cross platform deployment One of the key reasons for choosing Docker to deploy
    our systems was to be able to deploy the software reliably and repeatably on a
    range of different platforms. In our project the software has to be able to run
    on a number of different platforms, including the developer’s desktop computer,
    the integration test systems and at least two different live deployment environments.
    A key requirement of our project is that the software must be able to be deployed
    at a number of different third party data centres, each of which would have a
    slightly different operating system and runtime environment. If we relied on manual
    configuration for the target platform and runtime environment, then over time
    it is inevitable that they will end up being slightly different. Even something
    as simple as the version of Java or Tomcat used to run the web application can
    be difficult to control fully. We could, in theory, mandate a specific version
    and configuration of the software stack used to develop, test and deploy our software.
    In reality, unless the platform is created and managed by an automated process,
    then some level of discrepancy will creep in, often when it is least expected.
    There are a number of different ways of achieving this level of automation. A
    common method of managing a large set of systems is to use an automated configuration
    management tool, such as Puppet,49 or Chef50 to manage the system configuration
    based on information held in a centrally controlled template. Another common practice
    is to use a continuous integration platform such as Jenkins51 to automate the
    testing and deployment. These techniques are not mutually exclusive, and it is
    not unusual to use an automated configuration management tool such as Puppet to
    manage the (physical or virtual) hardware platform, in combination with a continuous
    integration platform such as Jenkins to manage the integration testing, and in
    some cases the live service deployment as well. However, these techniques are
    only really applicable when one has direct control over the deployment platform
    and the environment around it. In our case, we knew that although we had control
    over the environment for our own deployments, we would not have the same level
    of control over deployments at third party sites. 6. Issues found and lessons
    learned It is of course expected that issues and problems arise when using new
    technologies for the first time. These might be caused by mistakes made while
    climbing the learning curve or by software bugs in the technology itself, which
    may have not been uncovered yet while adoption of the technology is still growing,
    and all possible usages of it have not been visited yet. We document here an example
    of one of the issues we encountered, including how we solved it. 6.1. Memory issue
    As part of our Firethorn project we developed a testing suite written in Python
    as mentioned above. This suite included some long-runningtests, which iterated
    a list of user submitted SQL queries that had been run through our systems in
    the past, running the same query via a direct route to the database as well as
    through the new Firethorn system and comparing the results. This list scaled up
    to several thousand queries, which meant that a single test pass for a given catalogue
    could take several days to complete. The issue we encountered here was that the
    Docker process was being killed after a number of hours, with ‘Out of memory’
    error messages. An initial attempt at solving the problem was to set memory limits
    on all of our containers, which changed the symptoms and then caused our main
    Tomcat container to fail with memory error messages. After a few iterations of
    attempting to run the chain with different configurations, the solution was found
    through community forums, when we discovered that several other people were encountering
    the same symptoms with similar setups. Specifically, the problem was due to a
    memory leak, caused by the logging setup in the version of Docker that we were
    using (1.6). Output sent to the system stdout was being stored in memory causing
    a continuous buffer growth resulting in a memory leak.52 ,53 The solution that
    we adopted was to use the volume option to send the system output and logs from
    our container processes to a directory outside the container: Download : Download
    high-res image (31KB) Download : Download full-size image We learned several valuable
    lessons through the process of researching how other developers managed these
    problems, for example, the approach to logging where the logs of a container are
    stored separately from the container itself, making it easier to debug and follow
    the system logs. In addition, we benefited from learning how and why limiting
    memory for each container was an important step when building each of our containers.
    A fix for this issue was added to the Docker source code in November 201554 and
    released in Docker version 1.10. In addition, Docker added a pluggable driver
    based framework for handling logging55 ,56 which provides much more control over
    how logging output from processes running in the container is handled.57 6.2.
    Docker community More important than an analysis of the issues themselves is the
    understanding of the process undertaken to discover and solve them. An important
    point to make here, is in regard to the open source nature and culture of Docker
    and the Docker community. The main takeaway from this was finding how to go about
    solving issues related to containers and figuring out how the preferred method
    of implementing a certain feature is easy enough as doing a search of the keywords
    related to what you need. This can be done by either using a generic search engine
    or visiting the sources where the main Docker community interaction takes place.58
    ,59 ,60 Like many open source solutions, Docker has an active open source community
    behind it which enables users to find and fix issues more efficiently. An active
    open source community means it is more likely that any issue you might find has
    already been encountered by someone else, and just as likely that it has been
    solved officially (as part of a bug fix in Docker release) or unofficially (by
    some community member describing how they solved the problem). The memory issue
    described in the previous section is an example of how using community resources
    helped us to find how others who had encountered the same problem and how they
    had solved it. While Docker’s source code is open to the public, perhaps more
    importantly so is its issue tracking system. Apart from the fact that issues will
    get raised and solved quicker naturally with more eyes on them, another advantage
    for the users of such a platform is that they get the opportunity to contribute
    and help steer the direction it takes, by either raising issues or adding comments
    to the issue tracking system or the discussion forums. This leads to the targets
    for each new release being closely tied with what the majority of the community
    raises as important issues or requests for future enhancements. Another key point
    to note is how we benefited from Docker’s support team as well as the number of
    early adopters. We decided to take up Docker at an early stage, which can be considered
    its ‘bleeding-edge’ phase (version 1.6), at which point it was more likely to
    discover issues. However, with the large team and strong technological support
    of its developers, as well as the significant number of early adopters, new releases
    to solve bugs or enhance usability and performance were issued frequently. Consequently,
    after some research, we realized that many of the issues we found, whether they
    could be considered bugs or usability improvements needed, were often fixed in
    subsequent releases, meaning that by updating our Docker version they would be
    solved. Active participation in the community by the project developers and the
    fostering of an ‘inclusive’ atmosphere where users feel confident to submit bugs,
    request changes and post comments all contributes to the success of the project.
    This is true for many, but by no means all, open source projects, Linux itself
    being a prime example. Just making the source code accessible does not in itself
    guarantee the successful adoption of a project. In our experience, the more active
    and responsive the core project developers are to input from users, the more likely
    it is that a project will be successful and be widely adopted. This has certainly
    been the case so far with the Docker project. 6.3. Learning curve Getting started
    with creating basic containers was relatively easy, starting with the simple images
    available from Docker Hub, along with the extensive documentation and user guides,
    as well as the community forums. In the process of creating our containers we
    started with base images for the applications we wanted to create, for example
    using the official Tomcat image, looking at the source code for the Dockerfile,
    figuring out how they were put together and then developing our own version once
    we understood how they worked. Understanding concepts like the isolation of each
    process of an application, how to link containers and expose ports, as well as
    how best to handle logging and resource usage, develop later as a result of using
    Docker containers for different applications and exploring the comments and advice
    available on the Docker community sites and third party blogs. 7. Conclusion As
    mentioned throughout this paper, some of the main takeaways we noted from the
    use of Docker in development and production are the ease it provides in bundling
    components together, promoting re-usability, maintainability and faster continuous
    integration environments. We also noted how Docker improved collaboration between
    developers, specifically by providing a standard testing and deployment environment.
    Sharing code which is then compiled and executed on different environments has
    the potential to behave differently, while even the setup of such an environment
    can be cumbersome. By using Docker containers, developers need only share a Docker
    image or Dockerfile, which guarantees the environment will be the same. In addition,
    based on our own experience of working with Docker and from talking about Docker
    with colleagues on other projects the openness of Docker and its community has
    contributed to its popularity in both science and business systems. Based on our
    experience in development and production for the Firethorn and IVOATeX projects,
    we anticipate a rapid growth of interest and usage of Docker and container-based
    solutions in general. We expect that this will be the case for both developing
    and deploying systems as a replacement or complementary to existing hardware virtualization
    technologies, in enabling reproducible science and in systems that allow scientists
    to submit their own code to data centres. Docker can potentially help with this,
    as it provides the tools and simplicity that scientists need to recreate the environment
    that was used to generate a set of test results. In terms of the future of Docker
    in relation to the OCI, there is the potential for a common container standard
    to emerge, with the Docker project playing a leading role in the shaping of this
    standard. It should be noted that as explicitly stated by the OCI, given the broad
    adoption of Docker, the new standard will be as backward compatible as possible
    with the existing container format. Docker has already been pivotal in the OCI
    by donating draft specifications and code, so we expect any standard that emerges
    from this process will be closely tied with what exists now in Docker. Docker
    is not the perfect solution, and scientists or system engineers must decide when
    and if it is a suitable tool for their specific needs. It is most applicable in
    situations where reproducibility and cross-platform deployment are high on the
    list of requirements. When deciding on whether to adopt a container technology
    such as Docker our experience would suggest that the benefits in terms of re-usability,
    maintainability and portability represent a significant benefit to the project
    as a whole and in most cases we would expect the benefits to outweigh the costs
    in terms of learning and adopting a new technology. Acknowledgements The research
    leading to these results has received funding from: (i) The European Community’s
    Seventh Framework Programme (FP7-SPACE-2013-1) under grant agreement no. 606740;
    (ii) The European Commission Framework Programme Horizon 2020 Research and Innovation
    Action under grant agreement no. 653477; and (iii) The UK Science and Technology
    Facilities Council under grant numbers ST/M001989/1, ST/M007812/1, and ST/N005813/1.
    The authors would like to thank the reviewer for a comprehensive and detailed
    list of revision recommendations. The authors would like to thank Jenifer Tucker
    for her help in preparing this paper. References Alam et al. (2015) Alam S., Albareti
    F.D., Allende Prieto C., Anders F., Anderson S.F., Anderton T., Andrews B.H.,
    Armengaud E., Aubourg É., Bailey S., et al. The eleventh and twelfth data releases
    of the sloan digital sky survey: Final data from SDSS-III Astrophys. J. Suppl.,
    219 (2015), p. 12, 10.1088/0067-0049/219/1/12 arXiv:1501.00963 View in ScopusGoogle
    Scholar Arviset et al. (2010) Arviset, C., Gaudet, S., (2010) The IVOA Architecture,
    Version 1.0, IVOA Note, 23 November 2010. URL: http://www.ivoa.net/documents/Notes/IVOAArchitecture/index.html
    . Google Scholar Boettiger (2014) Boettiger, C., (2014) An introduction to Docker
    for reproducible research, with examples from the R environment. ArXiv e-prints
    arXiv:1410.0846. Google Scholar Cross et al. (2012) Cross N.J.G., Collins R.S.,
    Mann R.G., Read M.A., Sutorius E.T.W., Blake R.P., Holliman M., Hambly N.C., Emerson
    J.P., Lawrence A., Noddle K.T. The VISTA Science Archive Astron. Astrophys., 548
    (2012), p. A119, 10.1051/0004-6361/201219505 arXiv:1210.2980 View in ScopusGoogle
    Scholar Demleitner et al. (2016) Demleitner, M., Taylor, M., Harrison, P., Molinaro,
    M., The IVOATEX document preparation system, 2016, IVOA Note, 30 April 2016. URL:
    http://www.ivoa.net/documents/Notes/IVOATex/index.html. Google Scholar Ferreruela
    (2016) Ferreruela V. Gavip gaia avi portal, collaborative paas for data-intensive
    astronomical science Lorente N.P.F., Shortridge K. (Eds.), ADASS XXV, ASP Conf.
    Ser., TBD, ASP, San Francisco (2016), p. TBD Google Scholar Flewelling (2015)
    Flewelling H. Public release of Pan-STARRS data IAU General Assembly, 22 (2015),
    p. 2258174 Google Scholar Gaudet (2015) Gaudet, S., (2015) CADC and CANFAR: Extending
    the role of the data centre, in: Science Operations 2015: Science Data Management
    - an ESO/ESA Workshop, Held 24–27 November, 2015 at ESO Garching. Online at https://www.eso.org/sci/meetings/2015/SciOps2015.html,
    id.1, p. 1 doi:10.5281/zenodo.34641. Google Scholar Gaudet et al. (2011) Gaudet
    S., Armstrong P., Ball N., Chapin E., Dowler P., Gable I., Goliath S., Fabbro
    S., Ferrarese L., Gwyn S., Hill N., Jenkins D., Kavelaars J.J., Major B., Ouellette
    J., Paterson M., Peddle M., Pritchet C., Schade D., Sobie R., Woods D., Woodley
    K., Yeung A. Virtualization and grid utilization within the CANFAR Project Evans
    I.N., Accomazzi A., Mink D.J., Rots A.H. (Eds.), Astronomical Data Analysis Software
    and Systems XX, Astronomical Society of the Pacific Conference Series, vol. 442
    (2011), p. 61 Google Scholar Gaudet et al. (2009) Gaudet S., Dowler P., Goliath
    S., Hill N., Kavelaars J.J., Peddle M., Pritchet C., Schade D. The Canadian advanced
    network for astronomical research Bohlender D.A., Durand D., Dowler P. (Eds.),
    Astronomical Data Analysis Software and Systems XVIII, Astronomical Society of
    the Pacific Conference Series, vol. 411 (2009), p. 185 Google Scholar Hambly et
    al. (2008) Hambly N.C., Collins R.S., Cross N.J.G., Mann R.G., Read M.A., Sutorius
    E.T.W., Bond I., Bryant J., Emerson J.P., Lawrence A., Rimoldini L., Stewart J.M.,
    Williams P.M., Adamson A., Hirst P., Dye S., Warren S.J. The WFCAM science archive
    Mon. Not. R. Astron. Soc., 384 (2008), pp. 637-662, 10.1111/j.1365-2966.2007.12700.x
    arXiv:0711.3593 View in ScopusGoogle Scholar Holliman et al. (2011) Holliman M.,
    Alemu T., Hume A., van Hemert J., Mann R.G., Noddle K., Valkonen L. Service Infrastructure
    for Cross-Matching Distributed Datasets Using OGSA-DAI and TAP Evans I.N., Accomazzi
    A., Mink D.J., Rots A.H. (Eds.), Astronomical Data Analysis Software and Systems
    XX, Astronomical Society of the Pacific Conference Series, vol. 442 (2011), p.
    579 Google Scholar Hume et al. (2012) Hume A.C., Krause A., Holliman M., Mann
    R.G., Noddle K., Voutsinas S. TAP Service Federation Factory Ballester P., Egret
    D., Lorente N.P.F. (Eds.), Astronomical Data Analysis Software and Systems XXI,
    Astronomical Society of the Pacific Conference Series, vol. 461 (2012), p. 359
    Google Scholar Hypki and Brown (2016) Hypki, A., Brown, A.G.A., (2016) Gaia archive.
    ArXiv e-prints arXiv:1603.07347. Google Scholar Jurić et al. (2015) Jurić, M.,
    Kantor, J., Lim, K., Lupton, R.H., Dubois-Felsmann, G., Jenness, T., Axelrod,
    T.S., Aleksić, J., Allsman, R.A., AlSayyad, Y., Alt, J., Armstrong, R., Basney,
    J., Becker, A.C., Becla, J., Bickerton, S.J., Biswas, R., Bosch, J., Boutigny,
    D., Carrasco Kind, M., Ciardi, D.R., Connolly, A.J., Daniel, S.F., Daues, G.E.,
    Economou, F., Chiang, H.-F., Fausti, A., Fisher-Levine, M., Freemon, D.M., Gee,
    P., Gris, P., Hernandez, F., Hoblitt, J., Ivezić, Ž., Jammes, F., Jevremović,
    D., Jones, R.L., Bryce Kalmbach, J., Kasliwal, V.P., Krughoff, K.S., Lang, D.,
    Lurie, J., Lust, N.B., Mullally, F., MacArthur, L.A., Melchior, P., Moeyens, J.,
    Nidever, D.L., Owen, R., Parejko, J.K., Peterson, J.M., Petravick, D., Pietrowicz,
    S.R., Price, P.A., Reiss, D.J., Shaw, R.A., Sick, J., Slater, C.T., Strauss, M.A.,
    Sullivan, I.S., Swinbank, J.D., Van Dyk, S., Vujčić, V., Withers, A., Yoachim,
    P., (2015) The LSST data management system. ArXiv e-prints arXiv:1512.07914. Google
    Scholar Morris (2013) Morris, D., Wide field astronomy unit (WFAU) virtual observatory
    data access service, 2013, URL: http://wiki.ivoa.net/internal/ivoa/interopmay2013applications/20130508-firethorn-007.pdf
    . Google Scholar Nagler et al. (2015) Nagler, R., Bruhwiler, D., Moeller, P.,
    Webb, S., Sustainability and reproducibility via containerized computing, 2015.
    ArXiv e-prints arXiv:1509.08789. Google Scholar O’Mullane (2016) O’Mullane W.
    Bringing the computing to the data Lorente N.P.F., Shortridge K. (Eds.), ADASS
    XXV, ASP, San Francisco (2016), p. TBD Google Scholar Quinn et al. (2004) Quinn
    P.J., Barnes D.G., Csabai I., Cui C., Genova F., Hanisch B., Kembhavi A., Kim
    S.C., Lawrence A., Malkov O., Ohishi M., Pasian F., Schade D., Voges W. The international
    virtual observatory alliance: recent technical developments and the road ahead
    Quinn P.J., Bridger A. (Eds.), Optimizing Scientific Return for Astronomy Through
    Information Technologies, Society of Photo-Optical Instrumentation Engineers (SPIE)
    Conference Series, vol. 5493 (2004), pp. 137-145, 10.1117/12.551247 View in ScopusGoogle
    Scholar Wang et al. (2015) Wang X.Z., Zhang H.M., Zhao J.H., Lin Q.H., Zhou Y.C.,
    Li J.H. An interactive web-based analysis framework for remote sensing cloud computing
    ISPRS Ann. Photogramm. Remote Sens. Spat. Inform. Sci. (2015), pp. 43-50, 10.5194/isprsannals-II-4-W2-43-2015
    Google Scholar Yu and Huang (2015) Yu, H.-E., Huang, W., (2015) Building a virtual
    HPC cluster with auto scaling by the docker, ArXiv e-prints arXiv:1509.08231.
    Google Scholar Cited by (0) ☆ https://www.docker.com. 1 https://aws.amazon.com/
    2 http://www.infoq.com/news/2013/03/Docker 3 https://www.dotcloud.com/ 4 https://www.opencontainers.org/
    5 http://blog.docker.com/2015/06/open-container-project-foundation/ 6 http://www.zdnet.com/article/what-is-docker-and-why-is-it-so-darn-popular/
    7 http://www.americanbanker.com/news/bank-technology/why-tech-savvy-banks-are-gung-ho-about-container-software-1078145-1.html/
    8 https://github.com/radiasoft/containers 9 http://nucleotid.es/ 10 http://biodocker.org/docs/
    11 http://www.ivoa.net/documents/Notes/IVOATex 12 https://github.com/ivoa/ivoatex
    13 https://hub.docker.com/r/ivoa/ivoatex/ 14 https://hub.docker.com 15 http://fedoraproject.org/wiki/Anaconda/Kickstart
    16 https://blog.jessfraz.com/post/docker-containers-on-the-desktop/ 17 https://github.com/metagrid/notroot
    18 http://kubernetes.io/ 19 https://www.openstack.org/ 20 https://integratedcode.us/2015/10/13/user-namespaces-have-arrived-in-docker/
    21 https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-user-namespace-options
    22 https://runc.io/ 23 https://github.com/opencontainers/runc/issues/38 24 https://blog.jessfraz.com/post/getting-towards-real-sandbox-containers/
    25 http://singularity.lbl.gov/ 26 http://www.ivoa.net/documents/TAP/ 27 https://www.microsoft.com/en-us/sql-server/sql-server-2016
    28 http://webpy.org/ 29 http://www.linux-kvm.org/page/Main_Page 30 https://github.com/Zarquan/ischnura-kvm
    31 http://openjdk.java.net/ 32 http://tomcat.apache.org/ 33 https://github.com/alexec/docker-maven-plugin
    34 https://hub.docker.com/_/java/ 35 https://hub.docker.com/_/tomcat/ 36 https://docs.docker.com/docker-hub/official_repos/
    37 http://heartbleed.com/ 38 https://cve.mitre.org/cgi-bin/cvename.cgi?name=cve-2014-0160
    39 https://www.kb.cert.org/vuls/id/457759 40 https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-7547
    41 http://arstechnica.co.uk/security/2016/02/extremely-severe-bug-leaves-dizzying-number-of-apps-and-devices-vulnerable/
    42 http://docs.docker.com/engine/articles/ambassador_pattern_linking/ 43 http://www.dest-unreach.org/socat/
    44 http://www.unixwiz.net/techtips/ssh-agent-forwarding.html#fwd 45 http://devops.com/2014/05/05/meet-infrastructure-code/
    46 https://www.thoughtworks.com/insights/blog/infrastructure-code-reason-smile/
    47 https://docs.docker.com/compose/ 48 http://www.yaml.org/ 49 https://puppetlabs.com/
    50 https://www.chef.io/chef/ 51 https://wiki.jenkins-ci.org/ 52 https://github.com/docker/docker/issues/9139
    53 https://github.com/coreos/bugs/issues/908 54 https://github.com/docker/docker/pull/17877
    55 https://github.com/docker/docker/pull/10568 56 https://blog.logentries.com/2015/06/the-state-of-logging-on-docker-whats-new-with-1-7/
    57 https://docs.docker.com/engine/reference/logging/overview/ 58 https://forums.docker.com/c/general-discussions/general
    59 http://stackoverflow.com/questions/tagged/docker 60 https://github.com/docker/docker/issues
    View Abstract © 2017 Elsevier B.V. All rights reserved. Recommended articles Reliability-driven
    Automotive Software Deployment based on a Parametrizable Probabilistic Model Checking
    Expert Systems with Applications, Volume 174, 2021, Article 114572 Abdelhakim
    Baouya, …, Djamal Bennouar View PDF Deploying Docker Swarm cluster on hybrid clouds
    using Occopus Advances in Engineering Software, Volume 125, 2018, pp. 136-145
    József Kovács, …, Márk Emődi View PDF Container-based virtual elastic clusters
    Journal of Systems and Software, Volume 127, 2017, pp. 1-11 Carlos de Alfonso,
    …, Germán Moltó View PDF Show 3 more articles Article Metrics Citations Citation
    Indexes: 11 Captures Readers: 90 View details About ScienceDirect Remote access
    Shopping cart Advertise Contact and support Terms and conditions Privacy policy
    Cookies are used by this site. Cookie settings | Your Privacy Choices All content
    on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors.
    All rights are reserved, including those for text and data mining, AI training,
    and similar technologies. For all open access content, the Creative Commons licensing
    terms apply.'
  inline_citation: '>'
  journal: Astronomy and computing
  limitations: '>'
  pdf_link: null
  publication_year: 2017
  relevance_score1: 0
  relevance_score2: 0
  title: Use of Docker for deployment and testing of astronomy software
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1007/978-981-10-0557-2_126
  analysis: '>'
  authors:
  - Gemoh Maliva Tihfon
  - Jinsul Kim
  - Kuinam J. Kim
  citation_count: 7
  full_citation: '>'
  full_text: '>

    Your privacy, your choice We use essential cookies to make sure the site can function.
    We also use optional cookies for advertising, personalisation of content, usage
    analysis, and social media. By accepting optional cookies, you consent to the
    processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Log in Find a journal
    Publish with us Track your research Search Cart Home Information Science and Applications
    (ICISA) 2016 Conference paper A New Virtualized Environment for Application Deployment
    Based on Docker and AWS Conference paper First Online: 16 February 2016 pp 1339–1349
    Cite this conference paper Access provided by University of Nebraska-Lincoln Download
    book PDF Information Science and Applications (ICISA) 2016 Gemoh Maliva Tihfon,
    Jinsul Kim & Kuinam J. Kim  Part of the book series: Lecture Notes in Electrical
    Engineering ((LNEE,volume 376)) 4495 Accesses 6 Citations Abstract The setup environment
    and deployment of distributed applications is a human intensive and highly complex
    process that poses significant challenges. Nowadays many applications are developed
    in the cloud and existing applications are migrated to the cloud because of the
    promising advantages of cloud computing. The very core of cloud computing is virtualization.
    In this paper, we will look at application deployment with Docker. Docker is a
    lightweight containerization technology that has gained widespread popularity
    in recent years. It uses a host of the Linux kernel’s features such as namespaces
    and croup’s to sandbox processes into configurable virtual environments. Presenting
    two common serious challenging scenarios in the software development environment,
    we propose a multi-task PaaS cloud infrastructure using Docker and AWS services
    for application isolation/optimization and rapid deployment of distributed applications.
    Keywords Cloud Computing Virtual Machine Virtualized Environment Cloud Provider
    Specific Software Requirement These keywords were added by machine and not by
    the authors. This process is experimental and the keywords may be updated as the
    learning algorithm improves. Access provided by University of Nebraska-Lincoln.
    Download to read the full chapter text Chapter PDF Similar content being viewed
    by others An efficient multi-task PaaS cloud infrastructure based on docker and
    AWS ECS for application deployment Article 23 July 2016 About the Complexity to
    Transfer Cloud Applications at Runtime and How Container Platforms Can Contribute?
    Chapter © 2018 Docker Cluster Management for the Cloud - Survey Results and Own
    Solution Article 13 April 2016 Keywords Cloud Computing Virtual Machine Virtualized
    Environment Cloud Provider Specific Software Requirement These keywords were added
    by machine and not by the authors. This process is experimental and the keywords
    may be updated as the learning algorithm improves. References Zhang, Q., Cheng,
    L., Boutaba, R.: Cloud computing: state-of-the-art and research challenges. Journal
    of Internet Services and Application 1, 7–18 (2010) Article   Google Scholar   Yang,
    T.A., Joshy, N., Rojas, E., Anumula, S., Moola, J.: Virtualization and Data Center
    Design. Global Journal on Technology 9, 36–54 (2015) Google Scholar   Kratzke,
    N.: Lightweight Virtualization Cluster How to Overcome Cloud Vendor Lock-In. Journal
    of Computer and Communications 2, 1–7 (2014) Article   Google Scholar   Kratzke,
    N.: Cloud Computing Costs and Benefits—An IT Management Point of View (2012).
    In: Ivanov, I., van Sinderen, M., Shiskov, B. (eds.) Cloud Computing and Services
    Sciences, pp. 185–203. Springer, New York (2014) Google Scholar   Merkel, D.:
    Docker: Lightweight Linux Containers for Consistent Development and Deployment.
    Linux Journal 2 (2014) Google Scholar   Caballer, M., Blanquer, I., Molto, G.,
    de Alfonso, C.: Dynamic management of virtual infrastructures. Journal of Grid
    Computing 13(1), 53–70 (2014) Article   Google Scholar   Binz, T., Breitenbcher,
    U., Haupt, F., Kopp, O., Leymann, F., Nowak, A., Wagner, S.: OpenTOSCA - a runtime
    for TOSCAbased cloud applications. In: ICSOC. LNCS, vol. 8274, pp. 692–695. Springer
    (2013) Google Scholar   AmazonWebServices. AWSEC2. http://docs.aws.amazon.com/AmazonECS/latest/developerguide/
    Keahey, K., Freeman, T.: Contextualization: providing one-click virtual clusters.
    In: Fourth IEEE International Conference on eScience, Indianapolis, Indiana, USA,
    pp. 301–308 (2008) Google Scholar   Bresnahan, J., Freeman, T., LaBissoniere,
    D., Keahey, K.: Managing appliance launches in infrastructure clouds. In: Proceedings
    of the 2011 TeraGrid Conference: Extreme Digital Discovery, TG 2011, vol. 12,
    pp. 1–12:7. ACM, New York (2011) Google Scholar   Download references Author information
    Authors and Affiliations School of Electronics and Computer Engineering, Chonnam
    National University, Gwangju, 500-757, Korea Gemoh Maliva Tihfon & Jinsul Kim
    Convergence Security Department, Kyonggi University, Suwon, Gyonggi-Do, Korea
    Kuinam J. Kim Corresponding authors Correspondence to Jinsul Kim or Kuinam J.
    Kim . Editor information Editors and Affiliations Kyonggi University, iCatse Kyonggi
    University, Seongnam-si, Kyonggi-do, Korea (Republic of) Kuinam J. Kim Chair of
    IEEE CS STCOS, IBM T.J.Watson Research Center Chair of IEEE CS STCOS, Yorktown
    Heights, New York, USA Nikolai Joukov Rights and permissions Reprints and permissions
    Copyright information © 2016 Springer Science+Business Media Singapore About this
    paper Cite this paper Tihfon, G.M., Kim, J., Kim, K.J. (2016). A New Virtualized
    Environment for Application Deployment Based on Docker and AWS. In: Kim, K., Joukov,
    N. (eds) Information Science and Applications (ICISA) 2016. Lecture Notes in Electrical
    Engineering, vol 376. Springer, Singapore. https://doi.org/10.1007/978-981-10-0557-2_126
    Download citation .RIS.ENW.BIB DOI https://doi.org/10.1007/978-981-10-0557-2_126
    Published 16 February 2016 Publisher Name Springer, Singapore Print ISBN 978-981-10-0556-5
    Online ISBN 978-981-10-0557-2 eBook Packages Engineering Engineering (R0) Share
    this paper Anyone you share the following link with will be able to read this
    content: Get shareable link Provided by the Springer Nature SharedIt content-sharing
    initiative Publish with us Policies and ethics Sections References Abstract Chapter
    PDF References Author information Editor information Rights and permissions Copyright
    information About this paper Publish with us Discover content Journals A-Z Books
    A-Z Publish with us Publish your research Open access publishing Products and
    services Our products Librarians Societies Partners and advertisers Our imprints
    Springer Nature Portfolio BMC Palgrave Macmillan Apress Your privacy choices/Manage
    cookies Your US state privacy rights Accessibility statement Terms and conditions
    Privacy policy Help and support 129.93.161.219 Big Ten Academic Alliance (BTAA)
    (3000133814) - University of Nebraska-Lincoln (3000134173) © 2024 Springer Nature'
  inline_citation: '>'
  journal: Lecture notes in electrical engineering
  limitations: '>'
  pdf_link: null
  publication_year: 2016
  relevance_score1: 0
  relevance_score2: 0
  title: A New Virtualized Environment for Application Deployment Based on Docker
    and AWS
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1186/s13677-022-00358-7
  analysis: '>'
  authors:
  - Neelam Singh
  - Yasir Hamid
  - Sapna Juneja
  - Gautam Srivastava
  - Gaurav Dhiman
  - Thippa Reddy Gadekallu
  - Mohd Asif Shah
  citation_count: 7
  full_citation: '>'
  full_text: ">\nSingh et al. Journal of Cloud Computing            (2023) 12:4  \n\
    https://doi.org/10.1186/s13677-022-00358-7\nRESEARCH\n© The Author(s) 2023. Open\
    \ Access This article is licensed under a Creative Commons Attribution 4.0 International\
    \ License, which \npermits use, sharing, adaptation, distribution and reproduction\
    \ in any medium or format, as long as you give appropriate credit to the \noriginal\
    \ author(s) and the source, provide a link to the Creative Commons licence, and\
    \ indicate if changes were made. The images or \nother third party material in\
    \ this article are included in the article’s Creative Commons licence, unless\
    \ indicated otherwise in a credit line \nto the material. If material is not included\
    \ in the article’s Creative Commons licence and your intended use is not permitted\
    \ by statutory \nregulation or exceeds the permitted use, you will need to obtain\
    \ permission directly from the copyright holder. To view a copy of this \nlicence,\
    \ visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/.\nOpen Access\nJournal\
    \ of Cloud Computing:\nAdvances, Systems and Applications\nLoad balancing and service\
    \ discovery using \nDocker Swarm for microservice based big data \napplications\n\
    Neelam Singh1, Yasir Hamid2, Sapna Juneja3, Gautam Srivastava4,5,6, Gaurav Dhiman1,7,8,9,\
    \ \nThippa Reddy Gadekallu9,10 and Mohd Asif Shah11,12* \nAbstract \nBig Data\
    \ applications require extensive resources and environments to store, process\
    \ and analyze this colossal collec-\ntion of data in a distributed manner. Containerization\
    \ with cloud computing provides a pertinent remedy to accom-\nmodate big data\
    \ requirements, however requires a precise and appropriate load-balancing mechanism.\
    \ The load on \nservers increases exponentially with increased resource usage\
    \ thus making load balancing an essential requirement. \nMoreover, the adjustment\
    \ of containers accurately and rapidly according to load as per services is one\
    \ of the crucial \naspects in big data applications. This study provides a review\
    \ relating to containerized environments like Docker for \nbig data applications\
    \ with load balancing. A novel scheduling mechanism of containers for big data\
    \ applications \nestablished on Docker Swarm and Microservice architecture is\
    \ proposed. The concept of Docker Swarm is utilized \nto effectively handle big\
    \ data applications’ workload and service discovery. Results shows that increasing\
    \ workloads \nwith respect to big data applications can be effectively managed\
    \ by utilizing microservices in containerized environ-\nments and load balancing\
    \ is efficiently achieved using Docker Swarm. The implementation is done using\
    \ a case study \ndeployed on a single server and then scaled to four instances.\
    \ Applications developed using containerized microser-\nvices reduces average\
    \ deployment time and continuous integration.\nKeywords Big data, Containerization,\
    \ Docker, Microservice, Docker Swarm, Load-balancing\n*Correspondence:\nMohd Asif\
    \ Shah\nohaasif@kdu.edu.et\n1 Department of Computer Science and Engineering,\
    \ Graphic Era \nDeemed to be University, Dehradun 248002, India\n2 Abu Dhabi Polytechnic,\
    \ Abu Dhabi Polytechnic, Abu Dhabi, United Arab \nEmirates\n3 KIET Group of Institutions,\
    \ Delhi NCR, Ghaziabad, India\n4 Department of Mathematics and Computer Science,\
    \ Brandon University, \nBrandon, Canada\n5 Research Centre of Interneural Computing,\
    \ China Medical University, \n40402 Taichung, Taiwan\n6 Dept. of Computer Science\
    \ and Math, Lebanese American University, \n1102 Beirut, Lebanon\n7 Govt. Bikram\
    \ College of Commerce, Patiala, Punjab, India\n8 University Centre for Research\
    \ and Development, Department \nof Computer Science and Engineering, Chandigarh\
    \ University, Gharuan, \nMohali 140413, India\n9 Department of Electrical and\
    \ Computer Engineering, Lebanese \nAmerican University, Byblos, Lebanon\n10 School\
    \ of Information Technology and Engineering, Vellore Institute \nof Technology,\
    \ Vellore, India\n11 Department of Economics, Kebri Dehar University, Kebri Dehar,\
    \ Somali \n250, Ethiopia\n12 School of Business, Woxsen University, Hyderabad,\
    \ Telangana, 502345, \nIndia\nPage 2 of 9\nSingh et al. Journal of Cloud Computing\
    \            (2023) 12:4 \nIntroduction\nThe Big Data era led to the advent of\
    \ tools, technologies \nand architectures with improved efficiency, elasticity\
    \ and \nresiliency. Big data applications need sophisticated archi-\ntectures\
    \ with inherent capabilities to scale and optimize. \nTo enhance the scalability\
    \ and elasticity of big data appli-\ncation deployment, implemented environments\
    \ need \nto be continuously improved and updated. Organiza-\ntions are using cloud\
    \ based services to enhance the per-\nformance and to lessen overall cost. Containerization,\
    \ a \ncloud based technology, is attaining popularity since it \nis lightweight\
    \ in nature. Docker is one of the predomi-\nnant, extensively used container based\
    \ virtualizations, \nand since it is an open source project, it can be used to\
    \ \ndevelop, run and deploy an application efficiently.\nBig data applications\
    \ require extensive resources and \nenvironments to store, process and analyze\
    \ this colossal \ncollection of data in a distributed manner. Containeri-\nzation\
    \ with cloud computing provides a pertinent rem-\nedy to accommodate big data\
    \ requirements, however \nrequires a precise and appropriate load-balancing mech-\n\
    anism. The load on servers increases exponentially with \nincreased resource usage,\
    \ thus making load balancing an \nessential requirement. Moreover, the adjustment\
    \ of con-\ntainers accurately and rapidly according to load as per \nservices\
    \ is one of the crucial aspects in big data applica-\ntions. This study provides\
    \ a review relating to container-\nized environments like Docker for big data\
    \ applications \nwith load balancing. In this study, a scheduling mecha-\nnism\
    \ of containers for big data applications established \non Docker Swarm and Microservice\
    \ architecture is pro-\nposed. In this paper, we utilize the concept of Docker\
    \ \nSwarm to effectively handle big data applications work-\nload and service\
    \ discovery.\nImproving the performance of an application is an \nongoing struggle\
    \ with increased demands and usage. \nTechnical innovations are always aiming\
    \ towards achiev-\ning higher degree of efficiency and performance. Employ-\n\
    ing an environment that gives performance, reliability \nand fault tolerance is\
    \ required by all organizations. Cloud \nComputing has created a niche for itself\
    \ when perfor-\nmance, resiliency, availability, and a cost effective solution\
    \ \nis required. Modern technologies are employing Cloud \nComputing to gain benefits\
    \ as the  Cloud enables the \nubiquitous availability of resources in a cost effective\
    \ yet \ncompetent manner [1–6]. The Cloud has made resources \nlike infrastructure,\
    \ platform, and software available to \nthe end user without any management efforts.\
    \ The Cloud \noffers everything as a service including emerging tech-\nnologies\
    \ like the Internet of Things (IoT) or Big Data \n[3]. Various organizations are\
    \ offering cloud based solu-\ntions for handling Big Data as is shown in [7].\
    \ Elasticity \nin a cloud environment having multi-tier structure is \nachieved\
    \ by scaling the quantity of physical resources [8, \n9]. Resources can be scaled\
    \ in two ways, either by hori-\nzontal scaling i.e. by adding more (VMs) virtual\
    \ machines \n[10], or through vertical scaling by adding more resources \nto the\
    \ deployed VMs [11]. Both of the methods require \nadditional time, suffer from\
    \ latency issues, and may incur \nadditional cost. To expedite the processes and\
    \ optimizing \nthe cost of application development, different paradigms \nand\
    \ architectures have been studied and evaluated.\nContainerization is one of the\
    \ cloud based techniques \nwhich is gaining popularity because of features like\
    \ \nbeing lightweight, scalability, and availability when com-\npared to virtual\
    \ machines. Containers are best suited \nfor continuous integration and continuous\
    \ delivery (CI/\nCD) workflows. Docker [12], an open source project, is \na widely\
    \ used container-based virtualization tool assist-\ning in the development, execution,\
    \ and deployment of \napplications in  containerized environments. Docker can\
    \ \nmanage workloads dynamically in real time due to port-\nability and its lightweight\
    \ nature. Applications executed \nin a Docker container remain isolated from the\
    \ underly-\ning host environment.\nDocker can prove beneficial to deploy big data\
    \ appli-\ncations. Applications can be deployed in containers \nto serve massive\
    \ workloads. It is a challenging task to \nmanage numerous containers for a  single\
    \ application. \nDocker  thankfully comes with a cluster management \ntool called\
    \ Docker Swarm to handle multiple clusters. \nDocker Swarm provides clustering\
    \ and an  orchestra-\ntion mechanism and thus can deploy several containers \n\
    across different host machines. Docker Swarm also pro-\nvides a fault tolerance\
    \ mechanism not only by detecting  \nfailed containers on a host machine, but\
    \ also redeploy-\ning the same container on another host machine [13]. Big \n\
    data applications suffer from some of the major issues \nlike conventional data\
    \ analysis methods not adjusting \nto input data i.e. on-the-fly or real time\
    \ streaming data. \nMethods used may also pose computational and speed-\nup overhead.\
    \ Moreover, there is no theoretical derivation \nof parallelization speed-up factors.\
    \ Machine Learning \n(ML) programs may exhibit skewed distribution if the \nload\
    \ on each machine is not balanced, as they still lack \nmethods to synchronize\
    \ during waiting  times for  the \nexchange of parameter updates. As such, synchronization\
    \ \nis another open challenge to handle big data using ML \nalgorithms. Singh\
    \ et al. [14] proposed a container based \nmicroservice architecture to handle\
    \ monolithic design \nchallenges like scalability, integration, and throughput.\
    \ \nHowever,  the focus was not on handling big data based \napplications which\
    \ requires massive effort and deploy-\nment issues. Another issue which needs\
    \ to be addressed \nPage 3 of 9\nSingh et al. Journal of Cloud Computing     \
    \       (2023) 12:4 \n \nis how  to assign containers in real time accurately\
    \ to \nmanage service loads. In [15], a container scheduling \napproach employing\
    \ ML is proposed by the authors by \nanalyzing data sets using Random Forest (RF).\n\
    Most of the current  research fails to contribute the \ncause and effect of decrease\
    \ in service execution perfor-\nmance due to an increase in load on the nodes.\
    \ Another \narea of concern is how to assign service load dynamically \nat run\
    \ time in terms of big data applications.\nThis research aims to distribute big\
    \ data applica-\ntions implemented as a  microservice inside the  Docker \nSwarm\
    \ according to resource utilization for respective \nhost machines and service\
    \ discovery, both of which are \nimportant for microservice architectures. The\
    \ main focus \nof this research is on memory utilization according to \ngiven\
    \ memory limits. In this paper, we propose a Docker \nSwarm based mechanism to\
    \ observe consumption of \nmemory by each host machine and then look to assign\
    \ \nthe load to a given host machine based on memory usage \nusing microservices\
    \ for big data applications. Perfor-\nmance of the work is evaluated based on\
    \ the load assign-\nment according to memory utilization. Contributions \nof the\
    \ work focuses on improving performance during \nhigher workloads that may occur due\
    \ to big data process-\ning and scaling the services to improve the efficiency.\n\
    The paper is structured as follows: Section  Related \nWork will give a comprehensive\
    \ summary of the work \ndone in this area. Section Architectural design of Docker\
    \ \nbased load balancing and service discovery scheme \nfor microservice based\
    \ big data application will give an \naccount of the proposed work and methodology\
    \ and Sec-\ntion Result and Discussion will analyze the result of the \nproposed\
    \ work. In Section Conclusion, we conclude our \nwork.\nRelated work\nBig data\
    \ applications require extensive set of resources \nlike storage, processing power,\
    \ and communication \nchannels due to their inherent characteristics. To handle\
    \ \nthis gigantic pile of data, it is common that techniques, \nframeworks, environments,\
    \ and methodologies are con-\ntinuously reviewed, analyzed and developed. This\
    \ section \nexplores the work done for big data analytics using Cloud \ncomputing\
    \ and the use of Docker as well as Docker \nSwarm for the purpose of managing\
    \ and orchestrating \nclusters for load balancing.\nA Microservice based architecture\
    \ for big data \nknowledge discovery which aims to acknowledge scal-\nability\
    \ and efficiency issues in processing is proposed \nby Singh et al. [16]. Naik\
    \ et al. [17], have demonstrated \nthe  in workings of a model based on big data\
    \ process-\ning centered on Docker containers in multiple clouds by \nautomatic\
    \ assignment of big data clusters using Hadoop \nand Pachyderm. In the development\
    \ phase, the environ-\nment used ensures the accurate working of code but it \n\
    may fail during  the testing or production phase due to \nenvironmental changes\
    \ and/or differences. Containeriza-\ntion comes into play to handle this issue.\
    \ Hardikar et al. \n[18] explored several facets of Containerization like auto-\n\
    mation, deployment, scaling, and load balancing with a \nfocus on Docker as the runtime\
    \ environment and Kuber-\nnetes is deployed for orchestration. The focus is mainly\
    \ \non containerization, but handling the  big data micros-\nervice is not focused on\
    \ directly in the study. In micros-\nervices, based on neighbourhood divison,\
    \ a container \nscheduling approach called CSBND was proposed in [19] \nto optimize\
    \ the system performance using response time \nand load balancing. The research\
    \ did not handle big data \nand microservice based applications to be deployed\
    \ on \ncontainers.\nBig data analytics\nBig Data Analytics deals with discovering\
    \ knowledge \nfrom large datasets popularly known as big data for stra-\ntegic\
    \ planning, decision making, and prediction purposes \n[20]. To analyze these\
    \ colossal datasets, dynamic envi-\nronments are required which need to be scalable\
    \ enough \nto manage varying workloads as conventional methods \noften fail to\
    \ process these large sizes of data. Big Data \nAnalytics is an assortment of\
    \ tools, technologies, meth-\nodologies combined in a system/platform or framework\
    \ \nto perform knowledge discovery through processes like \ndata gathering, cleaning,\
    \ modelling, and visualization \n[21]. Techniques like machine learning and deep\
    \ neural \nnetworks are utilized to perform the analysis process.\nThe authors\
    \ in [20, 22] provide an insight into various \nmachine learning and deep learning\
    \ algorithms which \nprove to be beneficial in Big Data Analytics. These pro-\n\
    cesses require sophisticated architecture for storage, \nprocessing, and visualization.\
    \ Cloud computing is con-\nsidered to be an effective solution for it. The authors\
    \ \nillustrated the affinity of Big Data with cloud with respect \nto its characteristics\
    \ [23]. A web server load balanc-\ning mechanism focused on memory exploitation\
    \ using \nDocker Swarm was proposed by Bella et  al. [24]. This \nwork focused\
    \ on web server load balancing, however \nthe service discovery part is not considered\
    \ in the paper. \nBig data applications requires extensive use of resources \n\
    and resource utilization for big data is also not discussed.\nContainerization\
    \ using Docker\nTo increase the efficiency of methods and optimize devel-\nopment\
    \ as well as the deployment cost of applications \nover the cloud, there have\
    \ been numerous architectures, \nPage 4 of 9\nSingh et al. Journal of Cloud Computing\
    \            (2023) 12:4 \nframeworks, environments, and paradigms examined in\
    \ \nthe literature extensively. Docker, which is an open source \ncontainerization\
    \ tool, is fast emerging as an alternative \nfor application deployment over any cloud based\
    \ archi-\ntecture. Container centric virtualization is a substitute \nfor virtualization\
    \ done using hypervisor where contain-\ners share all resources like hardware,\
    \ operating system \nand supporting libraries while maintaining abstraction \n\
    and isolation [25]. Docker is a well-known  lightweight \ntool providing prompt\
    \ development and relocation with \nimproved efficiency and flexibility in resource\
    \ provision \n[26].\nA distinct host can be used to create numerous con-\ntainers\
    \ in multiple user spaces, which is unlike VMs [27]. \nContainer-based applications\
    \ fabricated using Micros-\nervice architecture require traffic management and\
    \ load \nbalancing at high workloads. This issue is handled through \ncontainer\
    \ load balancing. A load balancer for a  container \nresults in higher availability\
    \ and scalability of applications \nfor client requests. This ensures seamless\
    \ performance of \nMicroservice applications running in containers. Tools like\
    \ \nDocker Swarm as well as Kuberbnetes provide support to \nmanage and deploy\
    \ containers. Figure 1 gives an illustra-\ntion of a distributing application\
    \ client load to container-\nized microservices using a load balancer.\nDocker\
    \ Swarm\nManagement of containers is an important and crucial \naspect of containerization.\
    \ Load Balancing is required to \nhandle requests dynamically. To manage Docker\
    \ clusters, \nDocker Swarm, a cluster administration and orchestra-\ntion tool\
    \ is used that links and controls all Docker nodes \n[28]. Docker Swarm offers\
    \ features like reliability, secu-\nrity, availability, scalability, and maintainability.\
    \ It helps \nin the balanced distribution of any load and checks host \nmachines\
    \ for failed containers. If any failed contain-\ners are found, Docker Swarm redeploys\
    \ it [23]. It is an \nenhancement of Docker.\nDocker Swarm is made up of two types\
    \ of nodes, man-\nager and worker nodes. All  membership and alloca-\ntion processes\
    \ are handled by the  manager node while \nworker nodes execute swarm based services\
    \ in Docker \nSwarm. The Manager node uses its own IP address and \nport to expose\
    \ swarm services to all clients. Requests \nfrom clients are channelled to a chosen\
    \ worker node by \nthe swarm manager’s internal load balancing mechanism \nso\
    \ that requests are evenly distributed [29]. Although \nthe Docker Swarm load\
    \ balancing process distributes the \nload, the ability to monitor resource utilization\
    \ accord-\ning to available limits is not provided. This can lead to \nuneven\
    \ load distribution making any Big Data Micros-\nervice prone to collapse. In\
    \ this study, we will distribute \nMicroservice based loads in Docker Swarm by\
    \ checking \nresource consumption of host machines creating an even \nload distribution\
    \ mandated by available limits.\nMicroservice architecture\nMonolithic architectures\
    \ are the most common conven-\ntional architectures used to deploy applications.\
    \ These \narchitectures work on more or less three basic layers i.e. \npresentation,\
    \ business, and data logic in order to handle \nsimple to complex tasks. The architecture\
    \ is simple and \neasy  to use since everything is under one autonomous \ndeployment\
    \ unit. However, the architecture may limit \nthe application to scale and make updates\
    \  a difficult task \nwhen a complex task needs to be managed. Microser-\nvice\
    \ architectures aim to minimize the issues that exist \nin monolithic architectures\
    \ by dividing the entire appli-\ncation into lightweight and loosely coupled compo-\n\
    nents [30, 31]. Every component has its individual code \nrepository and can be\
    \ updated independently, making \nany complex application far more scalable, resilient\
    \ and \nefficient. Service Discovery and Load Balancing are two \ncritical as\
    \ well as fundamental aspects of Microservices. \nService Discovery can be defined\
    \ as a registry of run-\nning instances for one or many services. It is required\
    \ \nby Microservices to collaborate. Systems’ scalability, \nthroughput, execution\
    \ time, response time, and perfor-\nmance is largely influenced by load balancing\
    \ [32].\nContainer-based virtualization and Microservices \nmake a perfect association\
    \ as containers provide a decen-\ntralized environment and are lightweight in\
    \ nature. \nFig. 1 Container load balancing\nPage 5 of 9\nSingh et al. Journal\
    \ of Cloud Computing            (2023) 12:4 \n \nToday, Docker is used to build\
    \ modules called Micros-\nervices [33], to decentralize packages and distribute\
    \ jobs \ninto distinct, stand alone applications that collaborate \nwith each\
    \ other. Microservices can be considered as small \napplications that must be\
    \ deployed in their individual \nVM instances to have discrete environments. But\
    \ to dedi-\ncate an entire VM [34] instance to just a part of an appli-\ncation\
    \ is not an efficient approach. Docker containers \nrequire less computing resources\
    \ when compared to vir-\ntual machines, therefore deploying hundreds and thou-\n\
    sands of Microservices on Docker containers will reduce \nperformance overhead\
    \ and will increase the overall effi-\nciency of the applications [35]. In this\
    \ study, we will dis-\ntribute the load of Big Data applications inside a Docker\
    \ \nSwarm by utilizing resources of host machines. The main \nobjective is to\
    \ balance the load by checking memory con-\nsumption of all host machines based\
    \ on known memory \nlimits. This research aims at service discovery and server-\n\
    side load balancing for Big Data applications based on \nMicroservices using Docker\
    \ Swarm.\nArchitectural design of Docker based load \nbalancing and service discovery\
    \ scheme \nfor microservice based big data application\nA fault tolerant and decentralized\
    \ architecture is pro-\nvided by Docker Swarm. A set of Docker hosts can be \n\
    combined into a swarm using swarm mode. Services \ncan be created and scaled \
    \ with health checks along \nwith built in load balancing and service discovery\
    \ fea-\ntures. Big Data Applications require an extensive set of \nresources which\
    \ are required to be properly load bal-\nanced.  A  Docker based Load Balancing\
    \ and Service \nDiscovery system is used for Big Data applications. Fig-\nure 2 provides\
    \ a look at the Microservices stack in use \nfor a big data application.\nWe containerize\
    \ our application using Docker as \nMicroservices. We used Docker Swarm for orchestra-\n\
    tion, service discovery, and load balancing.\nThe Big Data application stack will\
    \ provide the given \nfunctionality in the form of Microservices:\n• Extraction\
    \ of links from the input URL using front \nend PHP application using Apache server.\n\
    • Interaction of the  Web application with API server \n(Python) to manage link\
    \ extraction and return JSON \nresponse.\n• An image of Redis cache (used by API\
    \ server) to \ncheck for already scraped pages and evading repeated \nfetch.\n\
    The experimental setup  is made up of four Swarm \nnodes – a master node and three\
    \ worker nodes as given \nin Table  1  and Fig.  3, respectively. The master node\
    \ is \nimplemented using NGINX service where the Swarm \ncommands are run. Swarm\
    \ itself is responsible for sched-\nuling, Domain Name Service (DNS) service discovery,\
    \ \nscaling, and container load balancing on all nodes. This \nDocker Swarm load\
    \ balancer will run on every node and \nwill balance load requests as required.\n\
    Four services are created within the Docker Swarm. \nA Master Load Balancer service\
    \ to enable load balanc-\ning and the  three  other services are Microservices\
    \ for \nthe implemented scenario for a  Big Data application. \nThese three worker\
    \ nodes are namely the PHP front \nend Microservice, python API Microservice,\
    \ and Redis \ncache Microservice, respectively. The port number \nFig. 2 Microservices\
    \ stack of a big data application\nTable 1 Docker Swarm services for big data\
    \ application\nType\nContainer\nPort\nLoad Balancer\nNGINX\n80\nFront End PHP\
    \ service\nApache\n8080\nAPI server (Python)\nPython\n5000\nAPI server (Redis)\n\
    Redis\n6379\nPage 6 of 9\nSingh et al. Journal of Cloud Computing            (2023)\
    \ 12:4 \nand respective containers of the services are listed in \nTable 1. For\
    \ example, to run the load balancer service, it \nis required to open port number\
    \ http:// 192. 168.0. 23: 80 \nand to access the  web server,  http:// 192. 168.0.\
    \ 24: 8080 \nis used to acquire the services of the Apache web server. \nDocker\
    \ Swarm is responsible to supervise and distribute \nthe containers running these\
    \ services routinely.\nThe proposed algorithm for the  entire process is dis-\n\
    cussed in Algorithm 1. Load balancing methodologies are \ncovered in Algorithm 2.\n\
    Algorithm 1: algorithmμBigLB (service orchestration)\nStep 1: Automate installation\
    \ of requirements using \nDocker file and build an isolated image (Container 1).\n\
    Step 2: Use Microservice for Big Data Application:\na. Creating full path URLs\
    \ of extracted path\nb. Extracting anchor and link texts\nc. Return object, move\
    \ main logic to function\nStep 3:\na. Run Server\nb. Map host and container ports\n\
    c. Expose link extraction (from step 2) as web service \nAPI in second python\
    \ file (Microservice).\nStep 4:\na. Create independent image of all the code\n\
    b. Create front end using PHP in different folder\nc. Services are integrated\
    \ using docker-compose.yml\nStep 5: Create second container for front end PHP\
    \ \napplication.\nStep 6: Create third container for Redis for caching \npurpose.\n\
    Algorithm 2: load balancing\nStep 1: Create NGINX service for load balancing.\n\
    Step 2: Run memory monitoring service in each worker \nnode.\nStep 3: Check for\
    \ load and service discovery and redirect \nload if a worker node fails, to active\
    \ worker node.\nService discovery is managed by applying Docker \nRemote API from\
    \ the services to extract service and \ninstance information. It  is a built in\
    \ service discovery \nmechanism of the orchestrator. In order to test the load\
    \ \nbalancing aspect of Docker Swarm,  our “linkextractor” \nMicroservice  is\
    \ scaled to run multiple instances using \nDocker API: docker service scale linkextractor\
    \ = 4.\nThis will create 4 replicas of our Microservice and if \nit is curled\
    \ a few times, it will get different IP addresses. \nThe calls were done using \
    \ round-robin over the four \ninstances. This load-balancing mechanism of container\
    \ \norchestrator implemented by Docker Swarm “service” \nabstraction removes the\
    \ complexity of client-side based \nload-balancing. The effect on latency and\
    \ CPU/memory \nusage is monitored using Docker API: docker stats, which \nprovides\
    \ container runtime metrics like CPU usage, \nMemory usage and limits, and network\
    \ I/O metrics.\nWe will consider the following parameters for each sce-\nnario\
    \ (container) implemented:\n• CPU usage\n• Memory usage and limits\n• Network\
    \ throughput\nResult and discussion\nUsing Remote Docker API, service discovery is\
    \ first per-\nformed as it is one of the crucial elements of any Micros-\nervice\
    \ architecture, so that Microservices can discover \nand collaborate with each\
    \ other as shown in Fig. 3. Ser-\nvice discovery helps to allocate and assign\
    \ nodes with \nlesser nodes and helps in automatic and continuous \nintegration.\
    \ Containers are assigned based on workloads \nonce service discovery is performed.\n\
    Once  all the container images  are discovered and \nloaded, our application \
    \ is executed to check its work-\ning in the containerized environment i.e. to\
    \ extract links \nfrom the given URL. Figure 4 shows the links extracted \nfrom\
    \ a test URL.\nFig. 3 Service Discovery for the Containers\nPage 7 of 9\nSingh et al.\
    \ Journal of Cloud Computing            (2023) 12:4 \n \nOnce our application is\
    \ tested, it is scaled from one to \nfour instances to check the effect on latencies\
    \ and CPU/\nmemory usage with respect to memory limits.\nResults achieved in Table \
    \ 2 and Fig.  5, respectively, \nshow that all four container instances are compara-\n\
    tively sharing similar workloads. Therefore, based on \nthese results, it is concluded\
    \ that containerized micros-\nervices for big data applications based on the proposed\
    \ \narchitecture can be effectively managed on Docker \nSwarm. More instances\
    \ can be added to scale  up and \nhandle the deployment and continuous integration\
    \ pro-\ncess in a much better way.\nMonolithic applications suffer from scalability\
    \ and \nintegration issues making it challenging to handle big \ndata applications\
    \ which can be easily managed by the \nproposed architecture.\nThe given case\
    \ study illustrates the requirement of \ncontainerization for applications working\
    \ on Big Data. \nThe  following section illustrates both  the merits and \ndemerits\
    \ of the strategy as proposed:\nMerits\n• Containers are well suited for complex\
    \ applications \ndeployed as microservices and thus can help the effi-\ncient\
    \ balancing of loads across servers as compared \nto VMs (Virtual Machines)\n\
    • According to the  requirements of a given applica-\ntion, functionality can\
    \ be scaled by deploying more \ncontainers which can be managed effectively using\
    \ \nDocker Swarm. This process is difficult to address \nusing virtualized environments\n\
    • Containers can be very easily duplicated or deleted \naccording to requirements\
    \  and the Swarm can han-\ndle this aspect in an efficient manner.\nDemerits\n\
    • Containers provide scalability, however portability can \nbe affected by placing\
    \ dependencies on containers.\n• Containers are susceptible to attacks as they\
    \ \nshare the OS kernel. This can affect service discovery \nand load balancing\
    \ across servers in case of an attack \nor any malicious activities.\n• Though\
    \ Containers can be duplicated at an amaz-\ning speed, they consume a huge amount\
    \ of resources \nmaking them a costlier strategy as compared to other \ntechniques\
    \ like virtualization.\nConclusion\nIt is often a  difficult and time consuming\
    \ process to \nmanage Big Data applications because of their predomi-\nnant characteristics.\
    \ Microservices are considered to be \na  better option to provide a  scalable\
    \ and fault tolerant \napproach to Big Data application  management. Service \n\
    discovery and load balancing are both important aspects \nof Microservices that\
    \ need to be addressed in modern \nsystems. In this study,  the benefits of containerization\
    \ \non Microservice based Big Data applications  was illus-\ntrated. The load\
    \ balancing and service discovery fac-\nets of Microservices are properly handled\
    \ by a  Docker \nFig. 4 Links extracted from a given URL\nTable 2 Resource utilization\
    \ by container instances (4)\nContainer\nCPU %\nMemory Usage (MB) / Limit (GB)\n\
    Net I/O\nlinkextractor.3.8j1ink3r57nfi1q6a2xf5gkc\n10.59%\n9.306 / 1.955\n1.209\
    \ KB/ 578 B\nlinkextractor.2.ap3adb28c79c8ax3age8ah1qp\n11.08%\n9.114 / 1.955\n\
    1.312 KB/ 630 B\ninkextractor.4.2kilgzglenbb0wew9hdme4z7t\n11.32%\n9.288 / 1.955\n\
    1.101 KB/ 528 B\nlinkextractor.1.y3yojmtxcvva3wa1q9nrh9asb\n10.17%\n21.26 / 1.955\n\
    1.266 KB/ 600 B\nPage 8 of 9\nSingh et al. Journal of Cloud Computing        \
    \    (2023) 12:4 \ncontainer and its attached  orchestration tool  called \nDocker\
    \ Swarm.\nThis proposed concept shows the usefulness of \nthe  Docker tools  suite\
    \ in orchestrating a multi-service \nstack like is needed for Big Data Applications.\
    \ This tech-\nnique can be utilized to avoid a single point of failure in \nBig\
    \ Data applications, as such making applications more \nscalable, resilient, and\
    \ portable. In the future, the com-\nputational complexity and cost efficiency\
    \ of the pro-\nposed work  needs to be examined and addressed. The \ngiven techniques\
    \ as presented can also be developed and \nimplemented for Big Data applications\
    \ in multi-cloud \nscenarios.\nAcknowledgments\nNot applicable.\nCode availability\n\
    Not Applicable.\nAuthors’ contributions\nConceptualization by Neelam Singh; Methodology\
    \ by Sapna Juneja; Software \nand formal analysis by Yasir Hamid; Investigation\
    \ and Writing by Gautam \nSrivastava; Resources and data collection by Writing\
    \ by: Gaurav Dhiman; \nValidation by: Thippa Reddy Gadekallu and Mohd Asif Shah.\
    \ The authors read \nand approved the final manuscript.\nFunding\nNot applicable.\n\
    Availability of data and materials\nNot Applicable.\nDeclarations\nCompeting interests\n\
    Not Applicable.\nReceived: 15 September 2022   Accepted: 2 November 2022\nReferences\n\
    \ 1. \nFox A, Griffith R, Joseph A, Katz R, Konwinski A, Lee G et al (2009) Above\
    \ \nthe clouds: a berkeley view of cloud computing. Rep UCBIEECS 28\n 2. \nArmbrust\
    \ M et al (2010) A view of cloud computing. Commun ACM \n53(4):50–58\n 3. \nRimal\
    \ BP, Jukan A, Katsaros an Goeleven D (2011) Architectural require-\nments for\
    \ cloud computing systems: an Enterprise cloud approach. J Grid \nComput 9(1):3–26\n\
    \ 4. \nBuyya R, Yeo CS, Venugopal S (2008) Marketoriented cloud computing: \n\
    vision, hype, and reality for delivering IT services as computing utilities. \n\
    In: Proceedings of the 10th IEEE international conference on high perfor-\nmance\
    \ computing and communications\n 5. \nVouk MA (2008) Cloud computing issues, research\
    \ and implementations. \nIn: 30th international conference on information technology\
    \ interfaces \n(ITI 2008), Cavtat/Dubrovnik, pp 31–40\n 6. \nP. Mell and T. Grance,\
    \ “Draft nist working definition of cloud comput-\ning”,2009. Available: http://\
    \ csrc. nist. gov/ groups/ SNS/ cloud- compu ting/ \nindex. html\n 7. \nWan J,\
    \ Cai H, Zhou K (2015) Industrie 4.0: enabling technologies. In: \nProceedings\
    \ of 2015 International Conference on Intelligent Computing \nand Internet of\
    \ Things, pp 135–140. https:// doi. org/ 10. 1109/ ICAIOT. 2015. \n71115 55\n\
    \ 8. \nLiu Z, Zhang Q, Zhani MF, Boutaba R, Liu Y, Gong Z (2015) DREAMS: \ndynamic\
    \ resource allocation for MapReduce with data skew. In: 2015 IFIP/\nIEEE International\
    \ Symposium on Integrated Network Management (IM), \npp 18–26. https:// doi. org/\
    \ 10. 1109/ INM. 2015. 71402 72\n 9. \nWei G, Vasilakos AV, Zheng Y, Xiong N (2010)\
    \ A game-theoretic method \nof fair resource allocation for cloud computing services.\
    \ J Supercomput \n54(2):252–269\n 10. Jiang J, Lu J, Zhang G, Long G (2013) Optimal\
    \ Cloud Resource Auto-\nScaling for Web Applications. In: 2013 13th IEEE/ACM international\
    \ \nsymposium on cluster, Cloud, and Grid Computing, pp 58–65. https:// doi. \n\
    org/ 10. 1109/ CCGrid. 2013. 73\n 11. Shi X, Dong J, Djouadi S, Feng Y, Ma X,\
    \ Wang Y (2016) PAPMSC: power-\naware performance management approach for virtualized\
    \ web servers \nvia stochastic control. J Grid Comput 14(1):171–191\nFig. 5 Memory\
    \ and CPU usage of four containers in Swarm\nPage 9 of 9\nSingh et al. Journal\
    \ of Cloud Computing            (2023) 12:4 \n \n 12. Preeth EN, Mulerickal FJ,\
    \ Mulerickal BP, Sastri Y (2015) Evaluation of Docker \ncontainers based on hardware\
    \ utilization. In: 2015 International Confer-\nence on Control Communication &\
    \ Computing India (ICCC), pp 697–700. \nhttps:// doi. org/ 10. 1109/ ICCC. 2015.\
    \ 74329 84\n 13. Ismail BI et al (2015) Evaluation of Docker as edge computing\
    \ platform. \nIn: 2015 IEEE Conference on Open Systems (ICOS), pp 130–135. https://\
    \ \ndoi. org/ 10. 1109/ ICOS. 2015. 73772 91\n 14. Singh V, Peddoju SK (2017)\
    \ Container-based microservice architecture \nfor cloud applications. In: 2017\
    \ International Conference on Computing, \nCommunication and Automation (ICCCA),\
    \ pp 847–852. https:// doi. org/ \n10. 1109/ CCAA. 2017. 82299 14\n 15. Lv J,\
    \ Wei M, Yu Y (2019) A container scheduling strategy based on \nmachine learning\
    \ in microservice architecture. In: 2019 IEEE International \nConference on Services\
    \ Computing (SCC), pp 65–71. https:// doi. org/ 10. \n1109/ SCC. 2019. 00023\n\
    \ 16. Singh N, Singh DP, Pant B, Tiwari UK (2021) μBIGMSA-microservice-based \n\
    model for big Data knowledge discovery: thinking beyond the mono-\nliths. Wirel\
    \ Pers Commun 116(4):2819–2833\n 17. Naik N, Jenkins P, Savage N, Katos V (2016)\
    \ Big data security analysis \napproach using computational intelligence techniques\
    \ in R for desktop \nusers. IEEE Symposium Series on Computational Intelligence\
    \ (SSCI) \n2016:1–8. https:// doi. org/ 10. 1109/ SSCI. 2016. 78499 07\n 18. Hardikar\
    \ S, Ahirwar P, Rajan S  Containerization: cloud computing based \ninspiration\
    \ Technology for Adoption through Docker and Kubernetes. In: \n2021 Second International\
    \ Conference on Electronics and Sustainable \nCommunication Systems (ICESC), vol\
    \ 2021, pp 1996–2003. https:// doi. \norg/ 10. 1109/ ICESC 51422. 2021. 95329\
    \ 17\n 19. Guo Y, Yao W (2018) A container scheduling strategy based on neighbor-\n\
    hood division in micro service. In: NOMS 2018–2018 IEEE/IFIP Network \nOperations\
    \ and Management Symposium, pp 1–6. https:// doi. org/ 10. \n1109/ NOMS. 2018.\
    \ 84062 85\n 20. Singh N, Singh DP, Pant B (2017) A comprehensive study of big\
    \ data \nmachine learning approaches and challenges. In: 2017 International \n\
    Conference on Next Generation Computing and Information Systems \n(ICNGCIS), pp\
    \ 80–85. https:// doi. org/ 10. 1109/ ICNGC IS. 2017. 14\n 21. Trnka A (2014)\
    \ Big data analysis. Eur J Sci Theol 10(1):143–148\n 22. Najafabadi MM, Villanustre\
    \ F, Khoshgoftaar TM, Seliya N, Wald R, \nMuharemagic E (2015) Deep learning applications\
    \ and challenges in big \ndata analytics. J Big Data 2(1):1–21\n 23. Hashem IAT,\
    \ Yaqoob I, Anuar NB, Mokhtar S, Gani A, Khan SU (2015) The \nrise of ‘big data’\
    \ on cloud computing: review and open research issues. Inf \nSyst 47:98–115\n\
    \ 24. Bella MRM, Data M, Yahya W (2018) Web server load balancing based \non memory\
    \ utilization using Docker swarm. In: 2018 International Confer-\nence on Sustainable\
    \ Information Engineering and Technology (SIET), pp \n220–223. https:// doi. org/\
    \ 10. 1109/ SIET. 2018. 86932 12\n 25. Soltesz S, Pötzl H, Fiuczynski ME, Bavier\
    \ A, Peterson L (2007) Container-\nbased operating system virtualization: a scalable,\
    \ high-performance alter-\nnative to hypervisors. SIGOPS Oper Syst Rev 41(3):275–287\
    \ (Pubitemid \n47281589)\n 26. Felter W, Ferreira A, Rajamony R, Rubio J (2015)\
    \ An updated performance \ncomparison of virtual machines and Linux containers.\
    \ In: 2015 IEEE Inter-\nnational Symposium on Performance Analysis of Systems\
    \ and Software \n(ISPASS), pp 171–172. https:// doi. org/ 10. 1109/ ISPASS. 2015.\
    \ 70958 02\n 27. J. Turnbull, The Docker Book, 2014, Available: www. docke rbook.\
    \ com\n 28. Docker.com./Docker Swarm. https:// docs. docker. com/ engine/ swarm/.\
    \ \nAccessed 24 Aug 2020]\n 29. Docker Swarm mode key concepts. Available: https://\
    \ docs. docker. com/ \nengine/ swarm/ key- conce pts/. Accessed 24 Aug 2020\n\
    \ 30. Al-Masri E (2018) Enhancing the microservices architecture for the \ninternet\
    \ of things. In: 2018 IEEE International Conference on Big Data (Big \nData),\
    \ pp 5119–5125. https:// doi. org/ 10. 1109/ BigDa ta. 2018. 86225 57\n 31. Imran\
    \ S (2021) Ahmad, and do Hyeun Kim, “a task orchestration approach \nfor Efficient\
    \ Mountain fire detection based on microservice and predic-\ntive analysis in\
    \ IoT environment”. J Intell Fuzzy Syst 40(3):5681–5696\n 32. Dhiman G et al (2022)\
    \ Federated learning approach to protect healthcare \ndata over big data scenario.\
    \ Sustainability 14(5):2500\n 33. Singh P et al (2022) A fog-cluster based load-balancing\
    \ technique. Sus-\ntainability 14(13):7961\n 34. Kanwal S et al (2022) Mitigating\
    \ the coexistence technique in wire-\nless body area networks by using superframe\
    \ interleaving. IETE J Res \n2022:1–15\n 35. Kour K et al (2022) Smart-hydroponic-based\
    \ framework for saffron culti-\nvation: a precision smart agriculture perspective.\
    \ Sustainability 14(3):1120\nPublisher’s Note\nSpringer Nature remains neutral\
    \ with regard to jurisdictional claims in pub-\nlished maps and institutional\
    \ affiliations.\n"
  inline_citation: '>'
  journal: Journal of cloud computing (Heidelberg)
  limitations: '>'
  pdf_link: https://journalofcloudcomputing.springeropen.com/counter/pdf/10.1186/s13677-022-00358-7
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: Load balancing and service discovery using Docker Swarm for microservice
    based big data applications
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1016/j.jisa.2021.102924
  analysis: '>'
  authors:
  - Hui Zhu
  - Christian Gehrmann
  citation_count: 11
  full_citation: '>'
  full_text: '>

    Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Abstract BetaPowered by GenAIQuestions answered in this article Keywords
    1. Introduction 2. Background and problem description 3. Experimental setup 4.
    Evaluation of Docker-sec and LiCShield 5. Lic-Sec — combining Docker-sec with
    LiCShield 6. Security and performance evaluations of Lic-Sec 7. Related work 8.
    Conclusion and future work CRediT authorship contribution statement Declaration
    of Competing Interest Acknowledgments References Show full outline Figures (10)
    Show 4 more figures Tables (6) Table 1 Table 2 Table 3 Table 4 Table 5 Table 6
    Journal of Information Security and Applications Volume 61, September 2021, 102924
    Lic-Sec: An enhanced AppArmor Docker security profile generator Author links open
    overlay panel Hui Zhu, Christian Gehrmann Show more Add to Mendeley Share Cite
    https://doi.org/10.1016/j.jisa.2021.102924 Get rights and content Under a Creative
    Commons license open access Abstract Along with the rapid development of cloud
    computing technology, containerization technology has drawn much attention from
    both industry and academia. In this paper, we perform a comparative measurement
    analysis of Docker-sec, which is a Linux Security Module proposed in 2018, and
    a new AppArmor profile generator called Lic-Sec, which combines Docker-sec with
    a modified version of LiCShield, which is also a Linux Security Module proposed
    in 2015. Docker-sec and LiCShield can be used to enhance Docker container security
    based on mandatory access control and allows protection of the container without
    manual configurations. Lic-Sec brings together their strengths and provides stronger
    protection. We evaluate the effectiveness and performance of Docker-sec and Lic-Sec
    by testing them with real-world attacks. We generate an exploit database with
    40 exploits effective on Docker containers selected from the latest 400 exploits
    on Exploit-DB. We launch these exploits on containers spawned with Docker-sec
    and Lic-Sec separately. Our evaluations show that for demanding images, Lic-Sec
    gives protection for all privilege escalation attacks for which Docker-sec and
    LiCShield failed to give protection. Previous article in issue Next article in
    issue Questions answered in this article BetaPowered by GenAI This is generative
    AI content and the quality may vary. Learn more. What types of exploits can be
    defended by Docker-sec? What was the main strength of Docker-sec and LiCShield?
    How is LiCShield different from Docker-sec? Why did Docker-sec fail to defend
    against attacks exploiting vulnerabilities of a specific user space program? What
    was the result of the test on vulnerable user space programs with Docker-sec and
    LiCShield? Keywords Docker-secLiCShieldLic-SecContainerSecurity evaluationDocker
    1. Introduction Cloud computing is currently the mainstream infrastructure technology
    and different cloud-based architectures are used for all kinds of applications
    and industries. Gartner predicts the cloud computing market to grow 18.4% in 2021
    to total $304.9 billion, up from $257.5 billion in 2020.1 A key cloud infrastructure
    technology is the container technology [1]. The most popular containerization
    ecosystems are Docker and Kubernetes which facilitate the management, scaling,
    and deployment of the containerized applications. In opposition to virtual machines,
    containers do not embed their kernel but run directly on the host kernel [2].
    The absence of kernel and kernel-sharing property make containers light-weight
    [3]. A problem is that the kernel-sharing property also makes containers not as
    secure as virtual machines. Virtual machines implement a layer called a hypervisor
    to add isolation between applications and the host. Containers implement a high-level
    interface between guest and host, which hides complexity to the user at the cost
    of becoming more complex itself [4]. The absence of a hypervisor in containers
    makes them more vulnerable to kernel exploits and attacks on the shared host resources.
    The authors in [5] present an overview of several relevant attacks. Thus, container
    security issues have become a major obstacle for wide adoption of the containerization
    technology. To address this issue, Docker implements several Linux kernel security
    mechanisms such as Capabilities, Seccomp, and Mandatory Access Control (MAC).
    However, even with these default security configurations in place, a Docker container
    is still vulnerable to many real-world exploits [6]. One of the most efficient
    ways to prevent such kinds of attacks is to apply a Linux Security Module (LSM),
    which is a kernel-level security framework initially targeting Linux [7]. In this
    paper, we study a recently proposed LSM called Docker-sec [8] and an earlier proposed
    LSM tool called LiCShield [9]. Docker-sec is a user-friendly security module based
    on AppArmor to protect Docker containers through their entire lifecycle by restricting
    capabilities and network accesses inside containers. It was shown by the authors
    behind Docker-sec that the proposed LSM is successful in protecting containers
    from zero-day vulnerabilities with limited performance overhead [8]. The LiCShield
    design principle is similar to Docker-sec. However, it does not generate rules
    for capabilities and network accesses but generates other important rules that
    Docker-sec cannot generate such as file access rules, mount rules, etc. So far
    no one has evaluated the Docker-sec and LiCShield strength concerning protection
    strength against real-world exploits. In this paper, such a measurement study
    is presented. Our evaluations are based on an exploit set extracted from Exploit-DB.2
    The exploit set was determined by selecting the exploits in the database which
    are effective against Docker containers only protected with the default security
    mechanisms. Then we evaluated the security of Docker-sec by manually executing
    the exploits on the container platform with Docker-sec enabled. Our results shows
    that Docker-sec is efficient against attacks exploiting extra network accesses
    or capabilities in addition to the ones actually required for proper function.
    In other conditions when the exploited capabilities and networks are truly required
    by the application running in the container, Docker-sec was not efficient. We
    also investigated the strength of LiCShield and concluded that it cannot either
    protect containers against all attacks in the exploit set. To address this issue,
    we then introduced the new AppArmor profile generator tool, Lic-Sec. The tool
    was designed by combining Docker-sec with LiCShield [9]. We have adapted and extended
    LicShield to fit the Docker-sec profile generation principles. Then we evaluated
    Lic-Sec by using the very same exploit set as we used for the Docker-sec and LiCShield
    evaluation. The measurement shows that Lic-Sec manages to give a much higher protection
    level. In particular, it prevents all privilege escalation attacks which Docker-sec
    and LiCShield failed to mitigate. In summary, we make the following contributions:
    We evaluate how Docker-sec and LiCShield perform against real-world attacks. We
    construct a new AppArmor profile generator tool that combined Docker-sec with
    a modified version of an older AppArmor profile generator, LiCShield, which we
    call Lic-Sec. We show that the new tool performs better than the pure Docker-sec
    and LiCShield tools. In particular, we show that it gives protection against all
    privilege escalation attacks which Docker-sec could not defend against. We present
    performance figures for the new combined profile generation tool. The rest of
    this paper is organized as follows. In Section 2, we give a background to the
    Docker Architecture, Mandatory Access Control, Docker-sec, and LiCShield. We also
    formulate the main research problem, i.e, the evaluation goal of Docker-sec and
    the design goal of the AppArmor profile generator. In Section 3, we introduce
    the methodology used in the evaluation and test setup and we describe how the
    exploit database was generated. In Section 4, the main Docker-sec and LiCShield
    security evaluation results are presented and a detailed analysis of the results
    is given. In Section 5, we describe the design details for Lic-Sec. In Section
    6, the results for security and performance evaluations for Lic-Sec are introduced
    as well as an analysis for the enhancements of Lic-Sec compared to pure Docker-sec.
    In Section 7, we present and discuss Docker security-related work. In Section
    8, we conclude the evaluation study and identify future work. 2. Background and
    problem description In this section, we give a brief background to Docker technology
    and architecture. In addition, we give an overview of key Linux and container
    security concepts with a focus on the security technologies behind Docker-sec
    and LiCShield. We also formulate the main research problem. 2.1. Background Here,
    we describe the Docker architecture, Mandatory Access Control, AppArmor as well
    as Docker-sec and LiCShield. 2.1.1. Docker architecture and components Docker
    uses a client–server architecture that consists of a server, a REST API, and a
    command-line interface (CLI) client as shown in Fig. 1. It can be further broken
    into four major components: the Docker server, the Containerd, the Containerd-shm,
    and the RunC.3 The Docker server is a long-running program which is also called
    the Docker daemon. It takes responsibility for the control, creation, and management
    of Docker objects such as containers, images, networks, and volumes. The Docker
    daemon implements the Containerd to manage the life-cycle of containers. The Containerd
    uses the RunC to run containers based on Open Container Initiative (OCI) specifications.
    The RunC is a command-line tool for spawning and running containers. It creates
    a container using Namespaces, cgroups, filesystem access controls, and Linux security
    capabilities. After the container runs, the RunC exits and hands the control over
    to the Containerd-shim, which sits between the Containerd and the RunC. The shields
    in Fig. 1 indicate the components in the architecture guarded by Docker-sec. Download
    : Download high-res image (414KB) Download : Download full-size image Fig. 1.
    Docker architecture and critical components. 2.1.2. Mandatory Access Control (MAC)
    In Mandatory Access Control (MAC) systems, mandatory policies govern access based
    on the classification of subjects and objects in the system. Each subject and
    object in the system are assigned a security level. The security level associated
    with an object reflects the sensitivity of the information contained in the object.
    The security level associated with a subject, also called clearance, reflects
    the subject’s trustworthiness not to disclose sensitive information to subjects
    not cleared to see it [10]. There are two kinds of tools for MAC in Linux: AppArmor
    and SELinux. SELinux is label-based and uses a type enforcement model. In SELinux,
    types are associated with applications and resources to enforce access rules [11].
    Since Docker-sec evaluated in this paper is based on AppArmor, we will not discuss
    SELinux further. Different from SELinux which is based on the label, AppArmor
    is based on paths. More details of AppArmor and its usage in Docker container
    are given in Section 2.1.3 below. 2.1.3. AppArmor AppArmor [12] is integrated
    into Ubuntu/Debian distributions and it is used by Docker. Users can define a
    specific AppArmor profile for a single application, restricting what it can do
    and cannot do based on paths. In this way, even if the attacker has succeeded
    in exploiting vulnerabilities in an application, the behavior of the compromised
    application is still restricted by AppArmor. When a container is started by Docker,
    a default AppArmor profile named ‘docker-default’ will be generated by Docker
    binary and loaded into the kernel for the container runtime. There is also an
    AppArmor profile for the Docker daemon but it is currently not installed with
    Docker.4 Generally, the default pre-defined AppArmor profile for the container
    is moderately protective to provide wide application compatibility. The default
    profile for instance forbids mount operations. It also denies access to important
    file systems on the host [13]. However, the default Docker AppArmor profile does
    not restrict the network and capability rules. This brings a high risk of the
    host suffered from privilege escalation attacks through a compromised container.
    Besides the predefined profile of Docker, administrators can also define and implement
    their own profiles which provide more strict restrictions. This requires advanced
    configuration skills by the person responsible for deploying the Docker application.
    2.1.4. Docker-sec The authors in [8] propose a novel security mechanism for Docker-based
    on AppArmor which is called Docker-sec. Docker-sec adds an additional security
    layer on top of Docker’s security defaults by automatically creating per-container
    AppArmor profiles. The AppArmor policy improved by Docker-sec has three major
    advantages compared to the default AppArmor policy loaded and enforced by Docker:
    (1) It protects the container through its whole life-cycle by generating secure
    profiles for all the critical Docker components as shown in Fig. 1. The default
    AppArmor profile only protects the container after the initialization by the RunC.
    (2) It generates per-container AppArmor profiles rather than the common secure
    profile compatible with all containers. (3) The AppArmor profile for each container
    is dynamic and can be adapted to any behavior change of the container by collecting
    the behavior of the container during the training period and then determining
    the privileges that are truly necessary for the container to run properly. 2.1.5.
    LiCShield LiCShield framework was presented in [9] for securing Docker containers
    and their workloads by automatically generating AppArmor rules for both the host
    and the Docker container. In brief, LiCShield traces all kernel operations by
    the trace tool called SystemTap5 while the Docker daemon is performing the build
    and run operations. LiCShield translates all the traces to AppArmor rules and
    constructs two different AppArmor profiles: one targeted to the operations performed
    inside the container, the other one to those performed on the host. LiCShield
    is similar to Docker-sec in design principles since both of them provide automatic
    AppArmor profile construction but with the following differences as listed in
    Table 1. First, we explain the differences that highlight the strengths of LiCShield:
    (1) LiCShield uses SystemTap as the tracing tool. This tool is more flexible than
    Auditd used by Docker-sec as it allows customizing the tracing script according
    to the user’s needs. Users can monitor and investigate a variety of kernel functions,
    system calls6 and process-related activities,7 etc. This feature enhances the
    extensibility of LiCShield; (2) LiCShield generates important rules which Docker-sec
    cannot generate, including pivot root rule, access rule, mount rule, link rule,
    and execution rule. These rules could be used as supplementary to the rules generated
    by Docker-sec. (3) LiCShield automatically constructs the profile for the Docker
    daemon based on its executions, which confines the privilege to the bare minimum
    needed for the proper function. While Docker-sec adopts a pre-defined AppArmor
    profile for the Docker daemon, which is moderately protective. Besides the strengths,
    LiCShield has several weaknesses compared to Docker-sec since LiCShield is incompatible
    with the latest Docker releases8: (1) LiCShield does not generate any profile
    for the RunC; (2) LiCShield does not give good runtime container protection. This
    is caused by the principles behind how LiCShield enforces the container protection
    profile. LiCShield exploits the pivot root rule in the host profile to enforce
    the container protection. In earlier Docker versions, the Docker daemon calls
    the pivot root right before starting the container processes. Hence, for older
    Docker versions, this is the right point to switch from the host profile to the
    container profile. But in current Docker versions, the RunC takes over this task
    from the Docker Daemon. Therefore, the pivot root rule cannot be used anymore
    for this purpose. Table 1. Comparison between Docker-sec and LiCShield. LSM Year
    MAC Tracing tool Generated rules Generated profiles Pre-defined profiles Effective
    protective range Docker-sec 2018 AppArmor Auditd Capability rule network rule
    Container runtime RunC Docker daemon Container RunC Docker daemon LiCShield 2015
    AppArmor SystemTap Pivot root rule access rule mount rule link rule execution
    rule Container runtime Docker daemon / Docker daemon 2.2. Problem description
    As has been shown in previous work [8], [9], AppArmor automatic profile generation
    has great potential in enhancing the security of containers. It is a major advantage
    if the profiles can be automatically generated to avoid forcing the end-user to
    make cumbersome manual configurations. However, previous work lacks an evaluation
    of the strength of the generated profiles. Hence, in this paper we address this
    issue, creating a new evaluation framework for judging the strength of an automatically
    generated AppArmor profile. Furthermore, by using such a new framework, we would
    like to find a stronger AppArmor profile generator than has been previously described.
    In summary, we address the following three sub-problems: (1) find a methodology
    and test framework for evaluating the strengths and weaknesses of existing AppArmor
    profile generators (Docker-sec and LiCShield) for Docker containers; (2) evaluate
    the strength of Docker-sec and LiCShield, and identify potential weaknesses; (3)
    find an enhanced profile generator offering higher security than Docker-sec or
    LiCShield. 3. Experimental setup Next, we describe the experimental setup we have
    used in our evaluation. First, we discuss how we classify attacks, then we describe
    how we have collected the exploit used in the tests and finally we explain how
    the actual tests were executed. 3.1. Attack classification We have chosen to use
    a similar two-dimensional method for classification as suggested by Lin et al.
    in [6] but with the following differences: (1) We choose the targeting objects
    of the attacks as the first dimension which is slightly different from the influence
    range used in [6]. We consider this way more intuitive and straight-forward since
    the targeting objects could be obtained directly from the official descriptions
    of vulnerabilities in the National Vulnerability Database (NVD). (2) We also choose
    the impacts of the attacks as the second dimension but with different approaches,
    i.e, we determine the impacts of the attacks based on the vulnerability type for
    each attack provided by NVD as shown in Table 2. First, we classify the exploits
    based on the targeting objects, i.e., Web Application, Server, Database, and Kernel.
    These are obtained from the “Known Affected Software Configurations” of vulnerability
    provided by NVD. Second, we classify the exploits into five categories based on
    the impacts of attacks. To summarize the impacts of all the attacks, we manually
    analyze the vulnerability type for each attack provided by NVD. The vulnerability
    type is defined by CWE (Common Weakness Enumeration).9 For each type, CWE defines
    its negative technical impact when the exploit is successfully used. We classify
    similar impacts into the same category. Then we obtain five categories: Bypass,
    Gain Privilege, Denial of Service (DoS), Gain Information, and Execute Code, which
    are listed in Table 2. Compared to Lin et al. work, we introduce one more category
    called “bypass”, which is explained in detail here. We here also further discuss
    privilege escalation attacks, which is the most important security class concerning
    container security. Table 2. Classification of different attack types. Impact
    Category Bypass protection mechanism Bypass Gain privileges or assume identity
    Gain privilege Modify application data Modify files or directories Modify memory
    DoS: CPU resource consumption Denial of Service (DoS) DoS: Memory resource consumption
    DoS: Resource consumption (Other) DoS: Crash, Exit, or Restart DoS: Instability
    Read application data Gain information Read memory Read files or directories Execute
    unauthorized code or commands Execute code • Bypass:By bypassing a protection
    mechanism, an attacker gains unauthorized access to a system. There are two general
    ways for attackers to bypass a protection mechanism; either gaining unauthorized
    access to a system by exploiting insecure interaction between components or compromising
    security functionality by risky resource management. The first way is commonly
    used in injection attacks and Cross-Site Request Forgery (CSRF) attacks. The second
    way is commonly used in DoS attacks. • Gain Privilege: Kernel vulnerabilities
    are used by attackers to gain unauthorized privileges of the container and the
    host. Depending on the effective range of the gained privilege, there are two
    kinds of privilege escalation attacks: – Inside container: Docker provides 14
    capabilities for the root user in containers instead of 38 capabilities for the
    real root user in the host. However, an attacker can bypass the CPU protection
    mechanisms and exploit kernel vulnerabilities to get the real root privilege,
    i.e., to obtain the full 38 capabilities. When using an exploit in this category,
    the attacker is still restricted inside the container and has no access to the
    underlying host and other containers running on the same host. – Container escape:
    In a successful container escape attack, the attacker not only gets the real root
    inside the container but also breaks the isolation between containers and the
    underlying host. After a successful attack, the attacker can modify the critical
    files or memory of the host and further influence or change other containers through
    the host. For example, CVE-2019-5736,10 a vulnerability of RunC, allows an attacker
    to overwrite the host RunC binary and consequently obtain host root access. Another
    example is a Namespaces switching attack which we describe in more detail in the
    analysis in Section 4.2. • Denial of Service (DoS): A DoS attack results in resource
    exhaustion or disability. An attacker can utilize a DoS attack to slow down or
    crash the software and deny service to legitimate users. • Gain Information:Attackers
    can read the critical application data, files, directories, and memory to gain
    sensitive information such as credentials, passwords, and keys. • Execute Code:A
    remote attacker can execute arbitrary codes on a victim’s computer, generally
    targeting Web Applications and servers. 3.2. Exploit database collection We generated
    our exploit database collection using a similar principle as presented in [6]
    but modified it to suit the Docker-sec evaluation target. In [6], the authors
    collected the latest 100 exploits of each category from Exploit-db11 and filtered
    out the exploits which would probably fail on the container platform such as the
    ones attacking the graphic user interface related program. Finally, they got 223
    exploits out of 400 exploits which might be effective on the container platform.
    In our evaluation, the purpose is to obtain the exploits which are actually effective
    on container platform with Docker default security mechanism. To achieve this,
    we processed the exploit database through three steps. First, we generated the
    universe set of exploits from Exploit-DB. Second, we did a first-round filter
    to filter out the exploits which are not commonly deployed in containers. Third,
    we applied a second-round filter to filter out the exploits which failed to launch
    the attacks on containers with just default security mechanisms enabled. • Generation
    of universe set of exploits:We used the same method as [6] to generate the original
    400 exploits collection from Exploit-DB. Exploit-DB is the oldest and most comprehensive
    database of real-world exploit code for several platforms such as Windows, Linux,
    etc. Exploit-DB divides the exploits into four categories: Web Application, remote,
    local & privilege escalation, and denial of service. Based on the four categories,
    we collected the latest 100 exploits of each category targeting on the Linux platform
    before December 31, 2019. Among the 400 exploits, 126 exploits were published
    in 2019. 190 exploits were published in 2018. 75 exploits were published in 2017
    and 2016. Only 9 exploits were published before 2016. • First-round filter:The
    purpose of this step was to obtain the exploits which might be effective on container
    platforms. We used theoretical investigations mainly focusing on the exploits
    of user space programs. We studied the text description of each exploits manually
    to confirm the affected user space program. Then we investigated the application
    based on the following criteria: (1) The exploits targeting graphic user interface
    (GUI) applications were filtered out since containers are generally used for deploying
    back-end services such as web servers and database servers; (2) The exploits targeting
    back-end applications, which are not generally used in containers, were filtered
    out since containers are designed for hosting single service in a single process.
    As recommended by Docker developers [14], it is not suitable to deploy an application
    running as a platform that integrating several applications. • Second-round filter:The
    purpose of the second step was to obtain the exploits that bypass all the default
    Docker protection mechanisms. These exploits are the most severe threats against
    the container and by testing them, we get a good view of the strengths and weaknesses
    of Docker-sec. First, we analyzed the exploit code and text description of CVE
    to figure out the attack principle and necessary conditions to carry out the attacks.
    Then we implemented the exploit code on a Docker container to see if the exploit
    was actually effective with the default Docker security configurations. We used
    the same method as in [6] for the exploits targeting userspace programs, i.e we
    deployed the vulnerable programs inside the container and ran the exploits outside
    the container. For the exploits which target the Linux kernel, we deployed the
    vulnerable kernel on the host and executed the exploits inside the container.
    After the two-round filter of the universe set of exploits, we obtained the final
    exploit database collection for our evaluation. For each exploit, we collected
    the EDB ID (Exploit Database IDentifier), CVE (Common Vulnerabilities and Exposures
    IDentifier) ID, publishing date, CVE type, exploit code to launch the attack,
    targeting object and text description of CVE. Then we utilized the classification
    method described in Section 3.1 to classify the exploit database. The number of
    exploits in the final database according to the classification is listed in Table
    3. Table 3. Exploit database collection. Categories Objects Empty Cell Web application
    Server Database Kernel Total Bypass 4 3 – – 4 Gain privilege (Inside Container)
    – – 2 4 6 Gain privilege (Container Escape) – – – 4 4 DoS – – 1 1 2 Gain information
    3 2 1 – 6 Execute code 13 9 2 – 24 Total 17 9 5 9 40a a The total number is less
    than the sum of all rows in the column. This is because some exploits cause more
    than one consequence. Table 4. Docker-sec security evaluation result overview.
    Exploits Userspace program targeted Kernel targeted Categories Objects Empty Cell
    Web application ( a) Server ( a) Database ( a) Other images ( a) Docker in Docker
    IBM DB2 ( a) Pihole/piholeb kylemanna/openvpn ( a) Bypass 4/4/4 3/3/3 – – – –
    Gain privilege (Inside Container) – – 2/2/2 4/0/4 4/4/4 4/1/4 Gain privilege (Container
    Escape) – – – 4/0/4 4/4/4 4/1/4 DoS – – 1/1/1 1/1/1 1/1/1 1/1/1 Gain information
    3/3/3 2/2/2 1/1/1 – – – Execute code 13/12/13 9/9/9 2/2/2 – – – Total 17/16/17
    9/9/9 5/5/5 9/1/9 9/9/9 9/3/9 a ‘Doc’ denotes the number of exploits executed
    successfully on containers launched with Docker, ‘Sec’ denotes the number of exploits
    executed successfully on containers launched with Docker-sec, ‘Lic’ denotes the
    number of exploits executed successfully on containers launched with LiCShield.
    b ‘pihole/pihole’ is vulnerable only when DHCP is used. 3.3. Test setup We used
    Docker 19.03.1-ce for the evaluations. This version was released on 25th July
    2019 and supports Linux kernel security mechanisms including Capability, Seccomp,
    and MAC. Furthermore, on the host, we ran the Linux distribution Ubuntu 14.04
    LTS with kernel version 4.4.0-51-generic. This kernel version was chosen to guarantee
    that the host kernel is vulnerable to all the kernel vulnerabilities in the selected
    exploit collection. This is obviously a requirement in order to do the security
    evaluation based on existing exploits. Docker-sec can generate the container profile
    through two mechanisms: static analysis and dynamic monitoring. In the static
    analysis mode, the profile is generated based on information about the container
    and the type of access rights it needs, which is either provided by the users
    as the command line arguments or generated by Docker. However, customizing these
    configurations is very time-consuming and if the user does not customize docker
    run, the resulting profile will be the same as the default AppArmor profile provided
    by Docker. Hence, in our tests, we directly enabled the dynamic monitoring for
    Docker-sec and we saved the runtime profile for each tested application for later
    usage. We generated the profiles in an isolated and trustworthy environment making
    sure this environment is not an infected one. Later, we evaluated the security
    strength of these profiles by testing them against a set of known exploits. We
    enabled dynamic monitoring by executing docker-sec train-start and docker-sec
    train-stop command. During these two commands, we performed all the required application
    functionalities. Then Docker-sec replaced capabilities and network accesses in
    the initial profile generated by static analysis, with the necessary capabilities
    and network accesses collected during the training period. Our profile evaluation
    methodology is using, in analogue with machine learning evaluation methodologies
    which distinguish between training and evaluation set, the principle of first
    generating a set of profiles without taking any known vulnerabilities into account.
    Then later, we tested the generated profiles against a set of know exploits we
    have collected. In this way, we get measurements of the overall robustness of
    the profiles including an indication of the profile strength against zero-day
    vulnerabilities. 4. Evaluation of Docker-sec and LiCShield Now, we present the
    exploit test results obtained in the study. We start by discussing the overall
    results and then we put special attention to the privilege escalation attacks,
    which we treat in a separate sub-section. 4.1. Test result analysis Based on the
    targeting objects, we divide the exploits into two categories: user space program
    targeted exploits and kernel targeted exploits. Userspace targets include web
    application, server, and database while the only kernel target considered is the
    Linux kernel. The results are displayed in Table 4. Detailed information regarding
    each exploit is listed in Table 5. In Table 5, exploit 1 to exploit 9 are kernel
    targeted exploits, the rest are userspace program targeted exploits. Columns from
    1 to 4 show the general information of each exploit. The fifth column shows the
    major impacts and targets of the attacks. 4.1.1. Docker-sec • User space program
    targeted exploits: We run the images of the vulnerable application, server, and
    database inside the container and launched the exploits outside the container.
    Some user space-targeted exploits, which require Linux capabilities and network
    accesses to launch, can be defended by Docker-sec. Since we ‘train’ the runtime
    profile by Docker-sec and discard the unnecessary capabilities and network accesses,
    not all required conditions to launch some of these attacks are fulfilled. For
    example, EDB-4096812 exploits CVE-2016-10033 to launch a remote code execution
    against PHPMailer. With the default runtime profile, the attack was successful.
    However, after training the container with Docker-sec, the capabilities were limited
    to ‘setuid’ and ‘setgid’ only, and the network accesses were constrained to ‘netlink
    raw’, ‘inet stream’, ‘inet dgram’, ‘inet6 stream’, and ‘inet6 dgram’. The attack
    failed under these restrictions due to the lack of network accesses: network unix
    dgram and network unix stream. The rest of the application-targeted attacks succeeded
    even with the Docker-sec generated AppArmor profile. The main reason is that these
    exploits do not directly depend on Linux capabilities or network accesses. Instead,
    these attacks generally exploit some common Web Application vulnerabilities such
    as injection, cross-site request forgery, and unrestricted upload of files with
    dangerous types. It is worth notice though, that even if this is the case, Docker-sec
    is still effective in the sense that the attack is isolated to the container and
    will not affect any program running outside of it. • Kernel targeted exploits:
    When it comes to kernel-targeted exploits, Docker-sec is much more effective as
    it restricts container capabilities. In particular, in the cases when the users
    run the Docker container on a host with kernel version 4.4.0. As Docker-sec reduces
    the capabilities to those really needed, several attacks can be prevented. However,
    clearly, if some rules are truly required during container runtime, then Docker-sec
    cannot discard these capabilities opening up for kernel-targeted exploits. In
    order to evaluate the defense performance in real-life application scenarios,
    we test 40 Docker images pulled from Docker hub13 with Docker-sec. We selected
    the top 20 images from two categories: non-community image and community image,
    ranked by popularity. Non-community images are either official images published
    by Docker or images having a verified publisher such as Microsoft, IBM, etc,.
    Community images are published by individual developers or by self-organized developer
    communities who have not been officially verified. We strongly believe that the
    test results of these 40 images are representative enough since they have been
    widely used and represent a large part of real-world Docker deployments. We found
    that only two images from the non-community images, ‘Docker in Docker’ and ‘IBM
    DB2’ are vulnerable to the majority of the attacks. For the remaining 18 images,
    the Docker-sec generated profile gives the expected protection as also can be
    seen in Table 4. Among the community images, there are two images, ‘kylemanna/openvpn’14
    and ‘pihole/pihole’,15 vulnerable to one kernel exploit which needs capability
    NET_ADMIN to launch. We analyze the failed cases in further detail in Section
    4.2 below. 4.1.2. LiCShield For the userspace program targeted attacks, the causes
    of the failed defense can be ascribed to two categories. (1) In most cases, the
    file access permissions needed by the exploits are also needed by the container.
    But in some cases, the performance highly depends on how the end-user uses the
    container. For example, the successful launch of EDB-47553 needs ‘write’ permission
    to directory ‘/tmp’ to create new files in this directory. If the user uploads
    files to the server, the ‘write’ permission is granted to ‘/tmp’. In this case,
    the containerized application is vulnerable to this attack. But if the user does
    not use the container in this way, then ‘write’ permission is not granted to ‘/tmp’
    and the exploit fails. (2) vulnerability is an innate flaw of the software. For
    example, CVE-2018-10933 is a logic vulnerability in libssh’s server-side state
    machine. The attacker can bypass the authentication by sending the MSG_USERAUTH_SUCCESS
    message before the authentication succeeds. LiCShield cannot defend against this
    attack by only restricting the rules. But it is worth noting that compared to
    Docker-sec, although LiCShield fails to avoid attacks from launching it can efficiently
    block their propagation. Since LiCShield could generate restrictions for all traced
    files. However, LiCShield also has such limitations that if the file is not accessed
    at all during the training period, no restrictions will be imposed on this file,
    which means all untraced files are out of the scope of LiCShield’s protection.
    For the kernel targeted attacks, LiCShield performs worse than Docker-sec. It
    is not able to defend all of them. There are two reasons for the failed defense
    against privilege escalation attacks and container escape attacks: (1) LiCShield
    does not restrict the capabilities. (2) LiCShield does not restrict the permission
    of ‘/bin/bash’, ‘/bin/dash’, ‘/bin/sh’ even though these commands do not need
    to be executed at all. So the shell with a new PID can still be launched to gain
    the root privilege. 4.2. Analysis of privilege escalation attacks Once a kernel-targeted
    exploit is launched successfully inside a container, the attacker will get root
    privilege and will be able to break the isolation by escaping from the container
    to the host. This is the far most severe type of attack and in this section, we
    dig deeper into the analysis and test results with respect to privilege escalation.
    Our focus is to analyze the efficiency of Docker-sec in restricting the attack
    ranges and minimizing the impacts. As we described in Section 4.1, there are two
    types of privilege escalation attacks. Below, we discuss the test results for
    these two types separately. • Inside container: We tested 4 exploits. Among these,
    3 of them (CVE-2017-7308,16 CVE-2017-607417 and CVE-2017-100011218 require capability
    SYS_ADMIN to launch and 1 (CVE-2016-979319) requires capability NET_ADMIN. If
    none of these capabilities are given to the container, all of these attacks fail.
    This is the reason Docker-sec protects the 36 tested images from the 4 exploits.
    During the images’ runtime, Docker-sec discards the NET_ADMIN and SYS_ADMIN since
    they are not necessary for the images to run properly. However, for the ‘Docker
    in Docker’ and ‘IBM DB2’ images, Docker-sec adds these two capabilities into the
    runtime profile after the training period and consequently the privilege escalation
    attacks succeed. To be more detailed, “Docker in Docker” and “IBM DB2” must both
    run in privileged mode, which gives the container the NET_ADMIN and SYS_ADMIN
    capabilities. ‘kylemanna/openvpn’ is an openVPN server in a Docker container completing
    with an EasyRSA PKI CA. While starting the server process, NET_ADMIN should be
    added inside the container. Pi-hole is a Linux network-level advertisement and
    Internet tracker blocking application, which can be run in a container. It is
    vulnerable only when DHCP is used since in this case the capability NET_ADMIN
    is added. Docker-sec is not any more effective after privilege escalation inside
    the container. In these attacks, once the real root privilege has been obtained
    inside the container, a root shell with a new PID is spawned. This process with
    real root privilege is not enforced by Docker-sec runtime profile and Docker-sec
    has no protective effect anymore. However, it should be noted that even if the
    capability restriction and MAC under these attack circumstances are not effective
    anymore, the Namespaces isolation and Docker Seccomp profile protections are still
    working. This means that the default read-only restriction for file access still
    applies despite the attacker root access. Therefore, the attack only affects resources
    inside the container and the host remains unaffected. • Container escape: Typically,
    the attacker switches the Namespaces to one of the host or hosts to launch the
    container escape attack. We tested 4 exploits based on this mechanism. As there
    is no ‘ready-made’ exploit code to launch these attacks, we used a well-proven
    technology20 to test this attack procedure which will be explained later. The
    root kernel exploits on which we based our tests were CVE-2017-1000112, CVE-2016-9793,
    CVE-2017-7308, and CVE-2017-6074. Among these exploits, three exploits need capability
    SYS_ADMIN to launch and one exploit needs capability NET_ADMIN to launch. The
    attack procedure we used is as follows. First, the attacker bypasses the Kernel
    Address-space Layout Randomization (KASLR) mechanism to get the kernel base address.
    Since the offsets of kernel symbols are constant to the kernel base address, it
    is easy to obtain the kernel symbol addresses through /proc/kallsyms which will
    be used in the container escape attack. Next, the attacker calls the kernel function
    find_task_by_vpid to obtain the task_struct of virtual process 1, which is the
    first process inside the container. Then the attacker further calls the switch_task_Namespaces()
    function to change attackers’ process’s Namespaces to those of the host’s. The
    input parameters for switch_task_namespaces() function are task_struct of process
    1, which is obtained in the previous step, and the address of init_nsproxy structure
    which contains the Namespaces of the initial process of the host. Finally, the
    attacker calls the setns syscall from the kernel exploit to perform the required
    Namespaces changes and then escape to the host. The defending principle of the
    container escape attacks is the same as the privilege escalation inside containers
    as we previously described. Docker-sec discards those two capabilities for the
    36 images runtime. The cause of failure for images ‘Docker in Docker’, ‘IBM DB2’,
    ‘pihole/pihole’ and ‘kylemanna/openvpn’ is also the same. Docker-sec considers
    these two capabilities as necessary and adds them into the runtime profile. Table
    5. Detailed information for exploit database. NO. EDB-ID CVE-ID CVSS Description
    Exploited Docker Exploited Docker-sec in dynamic mode Exploited LiCShield Exploited
    Lic-Sec Kernel targeted exploits 1 48 052 CVE-2019-18634 7.8 DoS on sudo process
    Yes Yes Yes Yes 2 43 418 CVE-2017-1000112 7.0 Privilege escalation Yes Yes only
    for images: Yes No Docker in Docker and IBM DB2 3 – CVE-2017-1000112 7.0 Container
    escape Yes Yes only for images: Yes No Docker in Docker and IBM DB2 4 41 994 CVE-2017-7308
    7.8 Privilege escalation Yes Yes only for images: Yes No Docker in Docker and
    IBM DB2 5 – CVE-2017-7308 7.8 Container escape Yes Yes only for images: Yes No
    Docker in Docker and IBM DB2 6 41 458 CVE-2017-6074 7.8 Privilege escalation Yes
    Yes only for images: Yes No Docker in Docker and IBM DB2 7 – CVE-2017-6074 7.8
    Container escape Yes Yes only for images: Yes No Docker in Docker and IBM DB2
    8 41 995 CVE-2016-9793 7.8 Privilege escalation Yes Yes only for images: Yes No
    Docker in Docker, IBM DB2, pihole/pihole and kylemanna/openvpn 9 – CVE-2016-9793
    7.8 Container escape Yes Yes only for images: Yes No Docker in Docker, IBM DB2,
    pihole/pihole and kylemanna/openvpn Userspace program targeted exploits 10 40
    678 CVE-2016-6663 7.0 Privilege escalation on MySQL Yes Yes Yes Yes 11 40 360
    CVE-2016-6662 9.8 Privilege escalation on MySQL Yes Yes Yes Yes 12 47 195 N/A
    N/A Execute Code on redis Yes Yes Yes Yes 13 39 867 CVE-2015-4870 N/A DoS on MySQL
    Yes Yes Yes Yes 14 43 271 CVE-2017-12636 7.2 Execute Code on CouchDB Yes Yes Yes
    Yes 15 40 968 CVE-2016-10033 9.8 Execute Code on PHPMailer Yes No Yes No 16 40
    185 CVE-2016-5734 9.8 Execute Code on phpMyAdmin Yes Yes Yes No 17 44 496 CVE-2018-10188
    8.8 Execute Code on phpMyAdmin Yes Yes Yes Yes 18 43 338 CVE-2018-11776 8.1 Execute
    Code on Apache Struts Yes Yes Yes Yes 19 42 984 CVE-2017-9805 8.1 Execute Code
    on Apache Struts Yes Yes Yes Yes 20 42 801 CVE-2017-5638 10.0 Execute Code on
    Apache Struts Yes Yes Yes Yes 21 42 279 CVE-2015-5531 N/A Gain Information on
    Elasticsearch Yes Yes Yes Yes 22 43 056 CVE-2017-5223 5.5 Gain Information on
    PHPMailer Yes Yes Yes Yes 23 45 272 CVE-2018-15685 8.1 Bypass on electron Yes
    Yes Yes Yes 24 42 084 CVE-2017-7494 9.8 Execute Code on Samba Yes Yes Yes Yes
    25 43 393 CVE-2018-10933 9.1 Bypass on libssh Yes Yes Yes Yes 26 42 938 CVE-2014-6271
    9.8 Execute Code on GNU bash Yes Yes Yes Yes 27 46 731 CVE-2019-3396 9.8 Execute
    Code on Confluence Yes Yes Yes Yes 28 46 242 CVE-2019-6116 7.8 Bypass on Ghostscript
    Yes Yes Yes Yes 29 45 369 CVE-2018-16509 7.8 Bypass on Ghostscript Yes Yes Yes
    Yes 30 46 585 CVE-2019-5418 7.5 Gain Information on RubyOnRails Yes Yes Yes Yes
    31 47 230 CVE-2019-15107 9.8 Execute Code on Webmin Yes Yes Yes Yes 32 45 914
    CVE-2018-19518 7.5 Execute Code on PHP Yes Yes Yes Yes 33 42 779 CVE-2017-11610
    8.8 Execute Code on Supervisor Yes Yes Yes Yes 34 47 553 CVE-2019-11043 9.8 Execute
    Code on PHP Yes Yes Yes Yes 35 48 182 CVE-2019-11043 9.8 Execute Code on PHP Yes
    Yes Yes Yes 36 41 965 CVE-2017-1000353 9.8 Execute Code on Jenkins Yes Yes Yes
    Yes 37 45 198 CVE-2017-1000028 7.5 Execute Code on GlassFish Yes Yes Yes Yes 38
    43 360 CVE-2017-17562 8.1 Execute Code on GoAhead Yes Yes Yes Yes 39 44 553 CVE-2018-2628
    9.8 Execute Code on WebLogic Yes Yes Yes Yes 40 43 458 CVE-2017-10271 7.5 Execute
    Code on WebLogic Yes Yes Yes Yes 5. Lic-Sec — combining Docker-sec with LiCShield
    Now we proceed with describing our enhancements to Docker-sec to get an overall
    stronger profile generator. We call our new tool, Lic-Sec, an AppArmor profile
    generator that combines Docker-sec and LiCShield. First, we discuss the Lic-Sec
    design motivations. Then, we show the modifications we have done to LiCShield
    as well as their purposes. Next, we describe how Lic-Sec works and the main differences
    compared to Docker-sec. In the end, we explain how to use the tool in different
    user scenarios. 5.1. The design of Lic-Sec The design of Lic-Sec is motivated
    by the evaluation results of Docker-sec and LiCShield. Based on the results, in
    some cases, their ability to defend against userspace program targeted attacks
    depends on how the user uses the container. Different rules are generated in different
    use cases. So the test results may be biased by the choice of specific exploit’s
    PoC, user’s behavior, and the containerized application functions. With these
    limitations in mind, we have shown though that both of the two tools limit the
    container’s behavior in the scope defined by an AppArmor profile even if some
    of the attacks still can be launched. As we have shown, they do not give a strong
    defense against userspace program targeted attacks, but they provide a solution
    for generating AppArmor rules tailored for each container. If we can combine them,
    we will be able to achieve a generator providing a higher level of protection
    with more rules to protect different parts. Based on the analysis of the differences
    between LiCShield and Docker-sec discussed in Section ??, we notice that LiCShield
    has the potential to collect more system information and generate additional protection
    rules (compare to Docker-sec) such as pivot root rules, file access rules, mount
    rules, link rules, and execution rules. If those rules can be generated for the
    container in addition to the capability and network rules generated by Docker-sec,
    we are able to construct a profile with more strict restrictions and broader container
    run-time analysis, giving an overall more flexible tool. For the kernel targeted
    attacks, according to the analysis in Section 4.2, the last step for an attacker
    to gain root privilege, whether inside or outside the container, is to launch
    a new shell with a new PID. The Docker-sec limitation with respect to only restricting
    capabilities or networks implies that we cannot defend against some of the attacks
    for some images. The LiCShield limitation with respect to not restricting the
    execution of shells also leads to the failure of defenses. If restrictions could
    be given to commands for launching shells, the attacks would be blocked. If no
    command such as ‘/bin/bash’, ‘/bin/sh’, and ‘/bin/dash’ is executed, one can deny
    running any shell inside the container, which could give a strong defense against
    privileged escalation attacks inside and outside the container. In summary, the
    design goals for the combined tool are: on top of Docker-sec and LiCShield, (1)
    providing more comprehensive protection for containerized userspace programs or
    applications; (2) enhancing the defense against privilege escalation attacks inside
    and outside the container. 5.2. The modifications of LiCShield and Docker-sec
    Based on the design goal of Lic-Sec, we made the following modifications to LiCShield.
    1. We modified LiCShield to generate more rules. We changed the way AppArmor profiles
    are enforced. Instead of using the LicShield approach where a profile is enforced
    with a pivot root rule on the host, we used the LicShield profile generator but
    applied them using the Docker sec enforcement principle. 2. We modified LiCShield’s
    SystemTap script to trace all processes triggered by different Docker components.
    First, we add one more field to the trace log structure called ‘executable process
    name’ to identify processes with an empty executable path such as ‘runc:[2:INIT]’.
    Second, we enable the trace for processes also for processes that are not in the
    target tree. 3. We modified LiCShield’s rules generator from two aspects: first,
    we generate deny rules for prompting shells inside the container in order to defend
    privilege escalation attacks. If no command such as ‘/bin/bash’, ‘/bin/sh’ and
    ‘/bin/dash’ is tracked during the tracing period, operations of ‘r’ (read), ‘w’
    (write), ‘m’ (memory map as executable), ‘k’ (file locking), ‘l’ (creation hard
    links) and ‘x’ (execute) to those commands are all denied by adding the deny rules
    to the container profile. Second, we change the way of classifying generated rules
    to container profiles and host profiles in order to identify profiles more accurately.
    4. We modified Docker-sec’s training process and rules generator in order to automate
    the generation of mount rules. We add auditing for mount operations when the training
    process starts in addition to the Docker-sec network and capabilities. We also
    add a function for generating mount rules in the container’s namespace based on
    the Auditd log. 5.3. The mechanisms of Lic-Sec Here we list the main mechanisms
    of Lic-Sec which include tracing and profile generation. The whole process is
    displayed in Fig. 2. (1) tracing: Tracing is the procedure of the new profile
    generator to collect necessary information as the basis to generate rules. SystemTap
    and Auditd are leveraged as the tracing tools. When the tracing starts, SystemTap
    and Auditd work in parallel: the former one collects kernel operations performed
    by all the Docker components based on a pre-defined trace script and the latter
    one collects mount operations, capability operations, and network operations performed
    by the running container. The structure of SystemTap trace can be customized and
    flexible while the structure of Auditd trace is defined by Auditd and fixed. We
    design the structure for SystemTap trace based on LiCShield. We add one more field
    called executable process name (marked with a star) in addition to LiCShield.
    The new structure has the following fields: Download : Download high-res image
    (282KB) Download : Download full-size image Fig. 2. Lic-Sec approach overview.
    probe point name control group path executable process name executable path resources
    path mount namespace root . • probe point name: the name of the kernel function
    probed, which identifies the required privileged operation. For example, when
    ‘security_sb_pivotroot’ function is probed, the pivot_root privilege is required.
    Lic-Sec identifies the type of rule depending on this field. • control group path:
    identifies the source of the request, either from the container or from the host.
    This is used to distinguish the operations inside the container and the host and
    classify the generated rules to container profile and host profile. • executable
    process name*: the name of the process which performs the operation. This field
    is introduced since we could not identify the process from the executable path
    for some processes such as the RunC:INIT. • executable path: the executable path
    of the process which performs the operation, acting as the subject of the privilege
    operation. • resources path: the resource involved in the operation, acting as
    the object of the privilege operation. • mount namespace root: identifies the
    involved resource’s mount point, which could also be used for identifying where
    the request comes from. Since if the operation is performed inside the container,
    the mount point locates in the Overlay2 filesystem. The Auditd trace has the following
    three structures, corresponding to capability rule, network access rule and mount
    rule, respectively: apparmor operation profile pid comm capability capname apparmor
    operation profile pid comm family sock_type protocol requested_mask addr apparmor
    operation profile name pid comm fstype srcname flags options • apparmor: the status
    of AppArmor. The value for this field could be ‘DENY’, ‘ALLOW’, ‘STATUS’ and ‘AUDIT’
    depending on AppArmor’s status. ‘AUDIT’ represents that this log could be used
    for generating rules. • operation: the performed operation, which is used for
    distinguishing logs related to capabilities (operation=‘capable’) from the ones
    related to network accesses. • profile: the enforced AppArmor profile reporting
    the privileged attempts. Lic-Sec uses this field to find out logs for the specified
    container which is confined by this profile. • capname: the name for the capability,
    which is added to the capability rules in the profile. • family: supported domains
    for the network such as inet, inet6, and unix, which are added to the network
    rules in the profile. • sock_type: supported types for the network such as stream,
    dgram, and raw, which are added to the network rules in the profile. • protocol:
    supported protocol numbers for the network which represent different protocols
    such as tcp, udp, and icmp. It is also added to the network rules in the profile.
    • name: the target mount point fileglob, should be a path, which is used for generating
    mount rules. • srcname: the source fileglob, which is used for generating mount
    rules. • fstype: the allowed filesystem type such as ‘ext4, debugfs, devfs’, which
    is used for generating mount rules. • flags: the allowed flags, such as ‘ro, rw,
    etc’, which are used for generating mount rules. (2) profile generation: the profiles
    are generated automatically through analyzing the trace files. Our rules generator
    engine grabs the key fields from the traces and combines them based on the different
    syntax of different rules. • trace file: The algorithm for translating the SystemTap
    trace to rules is shown as Algorithm 1. This is done by a Python script based
    on LiCShield’s implementation with our improvements. First, raw data of the trace
    file is collected line by line. For each line, we determine the applied rule (pivot
    root rule, link rule, file access rule, mount rule, or execution rule) according
    to the field ‘probe point name’. Second, the rules are classified into different
    profiles according to the fields ‘control group path’, ‘executable process name’,
    and ‘executable path’. Third, the fields ‘executable process name’, ‘executable
    path’, ‘resource path’, and ‘mount namespace root’ are input to the engine to
    generate rules. Lic-Sec introduces a new function: when generating the execution
    rules for the container, it checks if the execution is for prompting shells. If
    no such executions are traced, it adds the deny rules for all shell commands in
    the container profile. Fourth, the container rules are written into the AppArmor
    profile which has been enforced upon the container’s launch instead of a newly
    created profile, which gives real-time container protection enforcement. • auditd
    log: The translation from the Auditd trace to capability rules, network access
    rules, and mount rules are more straightforward using a bash script. For the capability
    rules and network access rules, we follow Docker-sec’s approach directly. Based
    on Auditd trace structures described before, first, we sort out capability traces
    generated by the running container by searching traces with ‘profile= profile_name
    ’, ‘apparmor=AUDIT’ and ‘operation=capable’. Here, the profile name is a known
    name of the enforced AppArmor profile for the container. Second, we get the capability
    used inside the container from the field ‘capname’ of these traces. We add them
    to the container profile as the capability rules using the following syntax: capability
    capname In a similar way, to generate the network accesses rules, first, we search
    out traces with ‘profile= profile_name ’ and ‘apparmor=AUDIT’, including the fields:
    ‘family’, ‘sock type’ and ‘protocol’. Second, we combine the values in these three
    fields to generate the network access rules using the following syntax: network
    family sock_type protocol To generate the mount rules, first, we grab the mount
    operation performed by the container through searching traces with ‘profile= profile_name
    ’, ‘apparmor=AUDIT’ and ‘operation=mount’. Second, we get the values in these
    key fields ‘fstype’, ‘srcname’, ‘name’ and ‘flags’ from those traces and combine
    them to a mount rule using the following syntax: mount fstype= fstype options=
    flags srcname - name Download : Download high-res image (503KB) Download : Download
    full-size image 5.4. Using Lic-Sec Lic-Sec is user-friendly to use. We provide
    docker-licsec commands as well as a bash script to run Lic-Sec. Lic-Sec can be
    run in three different modes depending on the usage scenario as displayed in Fig.
    3. Each mode has a different tracing period. Independent of the mode used, the
    tracing period can be terminated with the same command at any time after the container’s
    launch. Below, we describe the three different modes in more detail: • mode 1:
    Mode 1 is designed for the scenario where comprehensive profiles for both the
    host and the container are needed. This mode starts SystemTap tracing before the
    Docker daemon is launched and starts the Auditd auditing after the container is
    launched. Therefore, users can get all the kernel operations related to the Docker
    daemon, the containerd, the containerd-shim, and the RunC from the very beginning
    of the container’s life-cycle. The users need to run the bash script to enter
    this mode and use docker-licsec trace-stop to quit. • mode 2: Mode 2 is designed
    for the scenario where users only need to know the kernel operations done by the
    container from its initialization. This mode starts the SystemTap tracing right
    before the container launching and starts the Auditd auditing immediately once
    the container finishes initialization. Therefore, it traces the container build
    process by tracing the executions inside the Dockerfile specified by the image
    developer. Users can use the docker-licsec run command to enter this mode and
    use docker-licsec trace-stop to quit. • mode 3: Mode 3 is designed for the scenario
    where a flexible trace of the container is needed which allows users to start
    the tracing at any time during the container’s runtime. This mode is similar to
    the training period of Docker-sec. It only traces the container’s running process.
    The user specifies a tracing period for a specific container by running command
    docker-licsec trace-start and docker-licsec trace-stop, during which Lic-Sec collects
    information about the properties of the container. Users are supposed to perform
    all required executions and use all required application functionalities in order
    to feed necessary data to Lic-Sec and generate a profile with accurate restrictions.
    The tracing process is repeatable until users capture all the required functionality
    of the container. Download : Download high-res image (170KB) Download : Download
    full-size image Fig. 3. Lic-Sec modes and usage. 6. Security and performance evaluations
    of Lic-Sec Next, we investigate the security strength of Lic-Sec. We use the same
    exploit-based evaluation principles as we use for the Docker-sec testing (see
    Section 5). We also use the very same exploit database and the main focus of the
    evaluation is the most severe exploits and configurations that Docker-sec did
    not manage to defend, i.e. the privilege escalation attacks. 6.1. Evaluation result
    analysis In the evaluation with Docker-sec, we conclude that if the capabilities
    and networks exploited by the attacks are truly required during container runtime,
    then Docker-sec cannot discard these rules hence fails to defend those kernel-targeted
    exploits. In the evaluation of Lic-Sec, we launched the exploits from the exploit
    dataset again in the Docker containers protected by Lic-Sec. We found that, compared
    to Docker-sec, Lic-Sec successfully defended 8 more kernel-targeted exploits aiming
    to gain privilege inside containers and on the host, in the Docker container running
    image ‘Docker in Docker’, ‘IBM DB2’, ‘pihole/pihole’ and ‘kylemanna/openvpn’.
    Lic-Sec also defended 1 more userspace program targeted attack EDB-40185 which
    uses the function ‘system()’ to execute the command. This function needs the execution
    permission of ‘/bin/dash’ to prompt a terminal, which is denied by AppArmor rules
    generated from Lic-Sec. For other userspace program targeted attacks, Lic-Sec
    has the same performance as Docker-sec (see also Table 4, Table 5). We list the
    defense principles of Lic-Sec for both the privilege escalation attacks inside
    containers and the corresponding container escape attacks in Table 6. The EDB-ID
    is the ID of the privilege escalation exploits launched inside the container.
    For the container escape attacks, as explained in Section 5.2, since we used a
    well-proven technology and modified the original exploit, there is no official
    EDB-ID for those attacks. We have made a detailed analysis of the profile generation
    and protection mechanism with respect to the exploits mitigation: Since Lic-Sec
    does not identify any prompted shells during the tracing, it generates the corresponding
    deny rules for shell prompting, therefore, blocking the call of functions such
    as system() and execl(), which need to execute shell commands. The system() function
    uses fork() to create a child process that executes the shell command using execl(‘/bin/sh’,
    ‘sh’, ‘-c’, command, (char *) NULL). Since the execution of ‘/bin/sh’ is denied
    by Lic-Sec, the command cannot be executed anymore. For example, exploit 43418
    calls system(/sbin/ifconfig lo mtu 1500) to change MTU of interface ‘lo’ to 1500.
    Exploit 41 994 and 41 458 call system(‘/sbin/ifconfig lo up’) to activate interface
    ‘lo’. Similarly, exploit 41 995 calls execl(‘/bin/bash’, ‘bash’, NULL) after gaining
    root privilege to open a shell with new Namespaces, which is also be defended
    by Lic-Sec. The container escape attacks are based on the corresponding gain privilege
    attacks inside containers, so they have the same attack principles. Therefore,
    due to the failed call of those functions, these exploits could not be launched
    as well. Table 6. Lic-Sec security evaluation result overview. Image Exploit category
    Effective range EDB-ID CVE-ID Vulnerable kernel Lic-Sec defense principle Docker
    in Docker IBM Db2 pihole/pihole kylemanna/openvpn Gain privilege Inside container
    43 418 CVE-2017-1000112 Up to 4.13.9 AppArmor denies the call of function system()
    during exploiting. Container escape – Inside container 41 994 CVE-2017-7308 Up
    to 4.10.6 Container escape – Inside container 41 458 CVE-2017-6074 Up to 4.9.11
    Container escape – Inside container 41 995 CVE-2016-9793 Up to 4.8.13 AppArmor
    denies the execution of function execl(‘/bin/bash’, ‘bash’, NULL) after gaining
    root privilege. Container escape – 6.2. Performance We evaluated the performance
    for the three modes of Lic-Sec from two aspects: the profile generation time and
    the booting time. We collected the 10 most-used images from the Docker hub and
    used them for our performance measurements. When evaluating the performance for
    mode 1, we compared Lic-Sec with the pure LiShield since mode 1 corresponds to
    the LicShield tracing and profile generation principle. For mode 2 and mode 3,
    we compare Lic-Sec with the pure Docker-sec since these two modes are designed
    based on Docker-sec’s framework. We ran each image with Lic-Sec and LiCShield
    or Docker-sec respectively for 10 times and calculated the average time after
    10 rounds of test for each image. The results for Lic-Sec mode1 and pure LiCShield
    are shown in Fig. 4, Fig. 5. The overhead introduced by Lic-Sec regarding profile
    generation time is nearly ignorable. In terms of the bootstrap time, Lic-Sec introduces
    much more overhead due to the running of Docker-sec in parallel. The comparison
    of execution time for starting and terminating the trace between Lic-Sec’s mode2
    and Docker-sec are shown in Fig. 6, Fig. 7. Lic-Sec utilizes 2 more seconds on
    average than Docker-sec to start the trace, which is caused by the running of
    SystemTap trace. When SystemTap is set up, it first compiles the trace script
    into kernel modules and loads them into the kernel, which introduces some extra
    time. Considering the time for terminating the trace, Lic-Sec mode2 consumed more
    time than Docker-sec in general but showed different performances depending on
    images. For images such as Ubuntu, Redis, and Server JRE, Lic-Sec mode2 did not
    introduce obvious extra execution time. However, for images such as Weblogic server
    and Oracle DB, Lic-Sec mode2 consumed much more time to stop the trace. This increase
    in time is due to the fact that many more kernel operations were traced by Lic-Sec
    during the launch time for these images, which increased the workload of the profile
    generator engine. The comparison of execution time for starting and terminating
    the trace between Lic-Sec’s mode3 and Docker-sec are shown in Fig. 8, Fig. 9.
    Considering the trace termination time, in this case, we found that Lic-Sec performed
    basically the same as Docker-sec. The reason is that Lic-Sec mode3’s tracing starts
    after the container has been launched so kernel operations performed for launching
    the container are not traced. Since a large proportion of the trace is recorded
    during the launch time of the container, the workload is not increased significantly
    to the profile generator engine if the trace starts during the container’s runtime,
    which introduces nearly ignorable overhead to the trace termination time. Download
    : Download high-res image (241KB) Download : Download full-size image Fig. 4.
    Profile generation time for Lic-Sec and LiCShield. Download : Download high-res
    image (264KB) Download : Download full-size image Fig. 5. Booting time for Lic-Sec
    and LiCShield. Download : Download high-res image (259KB) Download : Download
    full-size image Fig. 6. Trace start time for Lic-Sec-mode2 and Docker-sec. Download
    : Download high-res image (213KB) Download : Download full-size image Fig. 7.
    Trace termination time for Lic-Sec-mode2 and Docker-sec. Download : Download high-res
    image (273KB) Download : Download full-size image Fig. 8. Trace start time for
    Lic-Sec-mode3 and Docker-sec. Download : Download high-res image (258KB) Download
    : Download full-size image Fig. 9. Trace termination time for Lic-Sec-mode3 and
    Docker-sec. 7. Related work 7.1. Container security solutions Several previous
    research work addresses LSMs for Docker containers. Some work focus on enhancing
    security by applying customized LSM modules’ policies such as AppArmor and SELinux.
    Docker-sec [8] and LiCShield [9] which are discussed in this paper are two of
    them. Bacis et al. proposed a solution based on SELinux hardening with an SELinux
    policy module added to the Dockerfile. In this way, containerized processes are
    run with SELinux types by binding SELinux policies with Docker container images,
    which specializes SELinux policy per-container or even per-process to increase
    Docker security [15]. This kind of approach relies on the host to define and enforce
    policies which infer that only the system administrator can use these approaches.
    Other than tailoring AppArmor and SELinux policies for each container to enhance
    security, researchers are exploring other ways to enable containers to use LSM
    modules to improve their own security. Y. Sun et al. proposed the design of a
    security namespace, which is a kernel abstraction that enables containers to utilize
    virtualization of the Linux kernel security framework to achieve autonomous per-container
    security control [16]. The main difference compared to our work is that, first,
    security namespace enables the container to autonomously control its security
    rather than relying on the system administrator to enforce the security control
    from the host. In our work, the policies are defined and enforced solely by the
    host. In [16], policies are pushed as string rules from the container directly
    to the kernel without the involvement of the host. Second, the whole kernel security
    framework could be used by containers rather than just limited security features
    since the security namespace virtualizes kernel security frameworks into virtual
    instances, each of which corresponds to one container. However, the security namespace
    requires intensive modifications of the kernel base and the LSM modules, and the
    policies are not automatically generated. The experimental results indicated that
    the security Namespaces can solve several container security problems with an
    acceptable performance overhead. DIVE (Docker Integrity Verification Engine) [17]
    is an architecture to support integrity verification and remote attestation of
    Docker containers. DIVE relies on a modified version of IMA (Integrity Measurement
    Architecture) which is also a widely used LSM module [18], and OpenAttestation
    which is a well-known tool for attestation of cloud services. With the help of
    DIVE, the infrastructure manager can be informed of the specific compromised container
    or hosting system and request to rebuild this single container. DIVE is practical
    to deploy due to a nearly negligible performance impact on the hosted services.
    Besides using LSM modules to improve Docker container security, kernel-based solutions
    are also proposed [19], [20]. These solutions aim to provide a secure framework
    or wrapper to run Docker containers. In the work of Reid and Tim [19], a secure
    framework based on the Linux user and mount namespaces called Charliecloud is
    proposed to run industry-standard Docker containers without privileged operations
    or daemons on center resources. Charliecloud is proved to avoid most security
    risks such as bypass of file and directory permissions and chroot escape. In the
    work of [20], a secure wrapper called Socker is described for running Docker containers
    on Slurm and a similar queuing system. The execution of containers within Slurm
    jobs is enforced by Socker as the submitting user instead of the root user to
    avoid privileged operations. Socker also bounds the resource usage of any container
    by the number of resources assigned by Slurm. There are some researches proposing
    security countermeasures or algorithms against a particular attack category of
    the container. This includes special investigations on DoS attacks [21], container
    escape attacks [22], attacks from the underlying compromised higher-privileged
    system software such as the OS kernel and the hypervisor [23], covert channels
    attacks [24] and the application level attacks [25]. In [21], Chelladhurai et
    al. apply three-tier protection mechanism including memory limit assignment, memory
    reservation assignment, and default memory value setting to defend against DoS
    attacks. The main principle behind their mechanism is to limit the resource consumption
    of the container. In [22], similar to our work, Jian et al. also investigated
    Docker escape attacks but particularly focusing on Namespace switching escapes.
    They proposed a defense based on Namespaces status inspection against this kind
    of attack. According to their solution, once a different Namespaces tag is detected,
    the corresponding process will be killed immediately and the malicious user will
    be tracked. The test results showed that this defense can effectively prevent
    some real-world attacks. In [23], SCONE is proposed, which is a secure container
    environment for Docker utilizing Intel Software Guard eXtension (SGX) [26] to
    run Linux applications in secure containers. The solutions provide confidentiality
    and integrity of application data within containers. Covert channel attacks against
    Docker containers are analyzed in [24]. In this paper, Luo et al. identify different
    types of covert channel attacks in Docker and propose solutions for using and
    configuring current security mechanisms provided by Docker to prevent those attacks.
    They also stress that the deployment of a full-fledged SELinux or AppArmor security
    policy is a key condition to protect the security perimeters of containers. A
    study about increase the application level isolation for containers is presented
    in the work of Hunger et al. [25]. The authors propose DATS which is a system
    to run web applications that heavily access data in shared folders and that are
    deployed with containers. The system enforces non-interference across containers
    and is effective to mitigate all data-disclosure vulnerabilities. Some researches
    address network security challenges for Docker containers. In the work of Ranjbar
    et al. [27], they propose SynAPTIC architecture to provide secure and persistent
    connectivity between containers based on the standard host identity protocol (HIP).
    Cilium21 is open-source software for transparently securing the network connectivity
    between application services deployed using Linux container management platforms
    such as Docker and Kubernetes. In the work of Secure Cloud [28], secure communication
    among containerized services is realized with the support of Intel’s Software
    Guard Extensions (SGX). 7.2. Container security testing and evaluation Besides
    proposing security solutions and enhancements, previous researches also present,
    similar to our work, an evaluation of container security. Most of them evaluate
    container security theoretically from the perspective of system architecture and
    design principle [29], [30], [31], [32], [33], [34]. In [6], Lin et al. described
    the first measurement study of Docker container’s security. We have used a similar
    methodology in our investigation but tailored it to the Docker-sec evaluation
    target. Some related researches are about early detection of Docker vulnerabilities
    such as performing penetration tests [35], implementing static code analyzer [36],
    implementing static and dynamic vulnerability detection schemes [37] and analyzing
    Docker image vulnerabilities [38], [39], [40]. In [35], Tao et al. clarified the
    importance of penetration testing technology in ensuring container security and
    studied some typical penetration test cases such as container escape and DoS in
    the container environment. Then they described the penetration testing process
    in the Docker container in detail. In [36], Ana et al. analyzed the applicability
    of static code analyzers in the Docker code base and concluded that these tools
    are very ineffective to detect Docker vulnerabilities. But they got the same conclusion
    as in [35], i.e. Docker vulnerabilities, especially bypass and privilege escalations,
    are easy to find using penetration testing. A study on the effectiveness of various
    vulnerability detection schemes for containers is conducted in [37] using 28 real-world
    vulnerability exploits. Their results showed that a dynamic detection scheme performs
    much better than a static detection scheme. Combining static and dynamic schemes
    can further increase the detection coverage. The authors in [38] analyze the Docker
    Hub images by using the framework DIVA (Docker Image Vulnerability Analysis).
    They studied 356,218 images and found that both official and community images
    contain more than 180 vulnerabilities on average. They recommend that automatic
    security updates could solve this problem. In [39], an empirical study about the
    impact of npm JavaScript package vulnerabilities in Docker images was conducted.
    The results showed that the outdated npm packages in Docker images pose a risk
    of security vulnerabilities so that the installed JavaScript packages should be
    up to date to avoid potential security risks from Docker images. In [40], Brady
    et al. described a continuous integration and continuous deployment (CI/CD) system
    to evaluate the security of Docker images under the scenario when the container
    is used as part of the software development. The results showed that the system
    is effective to prevent the publishing and reuse of images with known vulnerabilities.
    8. Conclusion and future work In this paper, we evaluated the security defense
    strength of Docker-sec and LiCShield by testing real-world attacks on containers.
    We manually collected 40 exploits out of 400 exploits from Exploit-DB. The selected
    exploits were all effective on container platforms with the default Docker security
    configurations. We categorized the exploits into two categories, kernel-targeted
    exploits, and userspace program targeted exploits. Using the selected exploits,
    we tested the top 40 community and non-community images from the Docker registry
    hub in containers spawned with Docker-sec and LiCShield. We ran the test on a
    host with a vulnerable kernel. Our investigation shows that for 36 out of 40 images,
    Docker-sec can defend against all attacks in the kernel target category, which
    aim at escalating privileges inside or outside the container. Only for four of
    the tested images, ‘Docker in Docker’, ‘IBM DB2’, ‘pihole/pihole’ and ‘kylemanna/openvpn’,
    Docker-sec was almost chance-less. LiCShiled was not able to defend all kernel
    attacks in the database since it does not restrict capabilities. But it can block
    the exploit’s propagation with file access restrictions. This result clearly shows
    the benefits and limitations of Docker-sec and LiCShield. The main strength of
    the approach is the capability to release the end-user burden in configuring strict
    container security policies as this is instead automated by Docker-sec and LiCSheild.
    The resulting strict LSM gives a reasonable level of security against kernel vulnerabilities
    and exploit’s propagation. Still, as clearly shown in our evaluation, for applications
    running on the container which require a broad set of privileges, the Docker-sec
    and LiCShield approaches do not give much additional security value. We also tested
    vulnerable user space programs inside containers spawned with Docker-sec and LiCShield.
    The result showed that Docker-sec failed to defend the attacks exploiting vulnerabilities
    of a specific user space program. This is mainly due to the fact that it can be
    launched independently of the Linux capabilities and network accesses. However,
    it is worth noticing, that even if Docker-sec was not directly effective against
    these types of vulnerabilities, the default read-only restriction for file access
    still blocks propagation to the host from the compromised container. LiCShield
    performs similar to Docker-sec, the exploits can still be launched even if restrictions
    have been generated. However, LiCShield provides more tailored restrictions for
    file access to block propagation. To address the issues which could not be solved
    by Docker-sec and LiCShield, we combined Docker-sec with a modified version of
    LiCShield to construct a new AppArmor profile generator called Lic-Sec. Besides
    auditing capabilities and network accesses, Lic-Sec was able to generate pivot_root_rules,
    link_rules, file_access_rules, mount_rules, and execution_rules. We evaluated
    the effectiveness of Lic-Sec against real-world exploits in the same way and made
    a comparative analysis of the evaluation results and performance of Docker-sec
    and Lic-Sec. The results showed that Lic-Sec was effective against defending privilege
    escalation attacks and could block the execution and propagation of all tested
    attacks with a reasonable performance overhead. Although the security evaluation
    of Lic-Sec is performed based on an old kernel in order to make all kernel exploits
    available, we consider the experimental evaluation results of Lic-Sec of protecting
    old kernels against privilege escalation attacks could indicate that Lic-Sec has
    the potential to defend against zero-day attacks in the future. Lic-Sec fits naturally
    into the verification phase prior to the deployment of microservices. This makes
    the tool and the approach well aligned with the modern software development principle
    using continuous development testing and integration. It is left to future work
    to compare Lic-Sec against other LSM based protection approaches such as the ones
    presented in [16][15]. Then we will get an even better understanding of the strength
    of Lic-Sec compared with alternative available tools. Also, in order to further
    assess the strength/weaknesses of Lic-Sec, it remains to test it using penetration
    testing tools and additional exploit datasets. Different tracing tools can be
    evaluated as well, for example, tools such as PLY and bpftrace which rely on eBPF
    can be used as a replacement for Audited and SystemTap used in this study. CRediT
    authorship contribution statement Hui Zhu: Conceptualization, Data curation, Formal
    analysis, Investigation, Software, Validation, Visualization, Writing - original
    draft, Writing - review & editing. Christian Gehrmann: Funding acquisition, Project
    administration, Resources, Supervision, Writing - review & editing. Declaration
    of Competing Interest The authors declare that they have no known competing financial
    interests or personal relationships that could have appeared to influence the
    work reported in this paper. Acknowledgments Work supported by framework grant
    RIT17-0032 from the Swedish Foundation for Strategic Research as well as the EU
    H2020 project CloudiFacturing under grant 768892. References [1] Bernstein D.
    Containers and cloud: From LXC to docker to kubernetes IEEE Cloud Comput, 1 (3)
    (2014), pp. 81-84, 10.1109/MCC.2014.51 View in ScopusGoogle Scholar [2] Martin
    A., Raponi S., Combe T., Di Pietro R. Docker ecosystem–vulnerability analysis
    Comput Commun, 122 (2018), pp. 30-43 View PDFView articleView in ScopusGoogle
    Scholar [3] Guru S.K., Patil M.V.T., Dhus A. Survey on docker Natl J Comput Appl
    Sci, 2 (3) (2019), pp. 5-9 Google Scholar [4] Williams D., Koller R., Lum B. Say
    goodbye to virtualization for a safer cloud 10th workshop on hot topics in cloud
    computing (HotCloud 18) (2018) Google Scholar [5] Caprolu M., Di Pietro R., Lombardi
    F., Raponi S. Edge computing perspectives: Architectures, technologies, and open
    security issues 2019 IEEE international conference on edge computing (EDGE), IEEE
    (2019), pp. 116-123 CrossRefView in ScopusGoogle Scholar [6] Lin X., Lei L., Wang
    Y., Jing J., Sun K., Zhou Q. A measurement study on linux container security:
    Attacks and countermeasures Proceedings of the 34th annual computer security applications
    conference, ACM (2018), pp. 418-429 CrossRefView in ScopusGoogle Scholar [7] Bélair
    M., Laniepce S., Menaud J.-M. Leveraging kernel security mechanisms to improve
    container security: a survey Proceedings of the 14th international conference
    on availability, reliability and security (2019), pp. 1-6 CrossRefGoogle Scholar
    [8] Loukidis-Andreou F., Giannakopoulos I., Doka K., Koziris N. Docker-sec: A
    fully automated container security enhancement mechanism 2018 IEEE 38th international
    conference on distributed computing systems (ICDCS), IEEE (2018), pp. 1561-1564
    View in ScopusGoogle Scholar [9] Mattetti M., Shulman-Peleg A., Allouche Y., Corradi
    A., Dolev S., Foschini L. Securing the infrastructure and the workloads of linux
    containers 2015 IEEE conference on communications and network security (CNS),
    IEEE (2015), pp. 559-567 CrossRefView in ScopusGoogle Scholar [10] Sandhu R.S.,
    Samarati P. Access control: principle and practice IEEE Commun Mag, 32 (9) (1994),
    pp. 40-48 View in ScopusGoogle Scholar [11] Mayer F., MacMillan K., Caplan D.
    SELinux by example: using security enhanced linux, (Prentice hall open source
    software development series), Prentice Hall PTR, Upper Saddle River, NJ, USA (2006)
    Google Scholar [12] Apparmor security profiles for docker (2019) https://docs.docker.com/engine/security/apparmor/
    Google Scholar [13] Bui T. Analysis of docker security (2015) arxiv preprint arxiv:1501.02967
    Google Scholar [14] Combe T., Martin A., Di Pietro R. To docker or not to docker:
    A security perspective IEEE Cloud Comput, 3 (5) (2016), pp. 54-62 View in ScopusGoogle
    Scholar [15] Bacis E., Mutti S., Capelli S., Paraboschi S. Dockerpolicymodules:
    mandatory access control for docker containers 2015 IEEE conference on communications
    and network security (CNS), IEEE (2015), pp. 749-750 CrossRefView in ScopusGoogle
    Scholar [16] Sun Y., Safford D., Zohar M., Pendarakis D., Gu Z., Jaeger T. Security
    namespace: making linux security frameworks available to containers 27th security
    symposium ( Security 18) (2018), pp. 1423-1439 View in ScopusGoogle Scholar [17]
    De Benedictis M., Lioy A. Integrity verification of docker containers for a lightweight
    cloud environment Future Gener Comput Syst, 97 (2019), pp. 236-246 View PDFView
    articleView in ScopusGoogle Scholar [18] Sailer R., Zhang X., Jaeger T., Van Doorn
    L. Design and implementation of a TCG-based integrity measurement architecture.
    USENIX security symposium, Vol. 13 (2004), pp. 223-238 Google Scholar [19] Priedhorsky
    R, Randles T. Charliecloud: Unprivileged containers for user-defined software
    stacks in hpc. In Proceedings of the international conference for high performance
    computing, networking, storage and analysis, 2017, pp. 1–10. Google Scholar [20]
    Azab A. Enabling docker containers for high-performance and many-task computing
    2017 Ieee international conference on cloud engineering (Ic2e), IEEE (2017), pp.
    279-285 CrossRefView in ScopusGoogle Scholar [21] Chelladhurai J., Chelliah P.R.,
    Kumar S.A. Securing docker containers from denial of service (dos) attacks 2016
    IEEE international conference on services computing (SCC), IEEE (2016), pp. 856-859
    CrossRefView in ScopusGoogle Scholar [22] Jian Z., Chen L. A defense method against
    docker escape attack Proceedings of the 2017 international conference on cryptography,
    security and privacy, ACM (2017), pp. 142-146 CrossRefView in ScopusGoogle Scholar
    [23] Arnautov S., Trach B., Gregor F., Knauth T., Martin A., Priebe C., Lind J.,
    Muthukumaran D., O’Keeffe D., Stillwell M.L., et al. : Secure linux containers
    with intel 12th symposium on operating systems design and implementation ( 16)
    (2016), pp. 689-703 View in ScopusGoogle Scholar [24] Luo Y., Luo W., Sun X.,
    Shen Q., Ruan A., Wu Z. Whispers between the containers: High-capacity covert
    channel attacks in docker 2016 IEEE trustcom/bigdatase/ispa, IEEE (2016), pp.
    630-637 CrossRefView in ScopusGoogle Scholar [25] Hunger C, Vilanova L, Papamanthou
    C, Etsion Y, Tiwari M. DATS-data containers for web applications. In Proceedings
    of the twenty-third international conference on architectural support for programming
    languages and operating systems, 2018, pp. 722–736. Google Scholar [26] Hoekstra
    M., Lal R., Pappachan P., Phegade V., Del Cuvillo J. Using innovative instructions
    to create trustworthy software solutions HASP@ ISCA, 11 (10.1145) (2013), pp.
    2487726-2488370 Google Scholar [27] Ranjbar A., Komu M., Salmela P., Aura T. Synaptic:
    Secure and persistent connectivity for containers 2017 17th IEEE/ACM international
    symposium on cluster, cloud and grid computing (CCGRID), IEEE (2017), pp. 262-267
    CrossRefView in ScopusGoogle Scholar [28] Kelbert F., Gregor F., Pires R., Köpsell
    S., Pasin M., Havet A., Schiavoni V., Felber P., Fetzer C., Pietzuch P. Securecloud:
    Secure big data processing in untrusted clouds Design, automation & test in europe
    conference & exhibition (DATE), 2017, IEEE (2017), pp. 282-285 CrossRefView in
    ScopusGoogle Scholar [29] Babar M.A., Ramsey B. Understanding container isolation
    mechanisms for building security-sensitive private cloud: Tech. rep., Technical
    report CREST, University of Adelaide, Adelaide, Australia (2017) Google Scholar
    [30] Casalicchio E., Iannucci S. The state-of-the-art in container technologies:
    Application, orchestration and security Concurr Comput: Pract Exper (2020), Article
    e5668 View in ScopusGoogle Scholar [31] Yasrab R. Mitigating docker security issues
    (2018) arxiv preprint arxiv:1804.05039 Google Scholar [32] MP A.R., Kumar A.,
    Pai S.J., Gopal A. Enhancing security of docker using linux hardening techniques
    2016 2nd international conference on applied and theoretical computing and communication
    technology (ICATccT), IEEE (2016), pp. 94-99 Google Scholar [33] Manu A., Patel
    J.K., Akhtar S., Agrawal V., Murthy K.B.S. A study, analysis and deep dive on
    cloud PAAS security in terms of docker container security 2016 international conference
    on circuit, power and computing technologies (ICCPCT), IEEE (2016), pp. 1-13 Google
    Scholar [34] Sultan S., Ahmad I., Dimitriou T. Container security: Issues, challenges,
    and the road ahead IEEE Access, 7 (2019), pp. 52976-52996 CrossRefView in ScopusGoogle
    Scholar [35] Lu T., Chen J. Research of penetration testing technology in docker
    environment 2017 5th international conference on mechatronics, materials, chemistry
    and computer engineering (ICMMCCE 2017), Atlantis Press (2017) Google Scholar
    [36] Duarte A., Antunes N. An empirical study of docker vulnerabilities and of
    static code analysis applicability 2018 eighth latin-american symposium on dependable
    computing (LADC), IEEE (2018), pp. 27-36 View in ScopusGoogle Scholar [37] Tunde-Onadele
    O., He J., Dai T., Gu X. A study on container vulnerability exploit detection
    2019 IEEE international conference on cloud engineering (IC2E), IEEE (2019), pp.
    121-127 CrossRefView in ScopusGoogle Scholar [38] Shu R, Gu X, Enck W. A study
    of security vulnerabilities on docker hub. In Proceedings of the seventh ACM on
    conference on data and application security and privacy, 2017, pp. 269–280. Google
    Scholar [39] Zerouali A., Cosentino V., Mens T., Robles G., Gonzalez-Barahona
    J.M. On the impact of outdated and vulnerable javascript packages in docker images
    2019 IEEE 26th international conference on software analysis, evolution and reengineering
    (SANER), IEEE (2019), pp. 619-623 CrossRefView in ScopusGoogle Scholar [40] Brady
    K., Moon S., Nguyen T., Coffman J. Docker container security in cloud computing
    2020 10th annual computing and communication workshop and conference (CCWC), IEEE
    (2020), pp. 0975-0980 CrossRefGoogle Scholar Cited by (0) 1 https://www.gartner.com/en/newsroom/press-releases/2020-11-17-gartner-forecasts-worldwide-public-cloud-end-user-spending-to-grow-18-percent-in-2021.
    2 https://www.exploit-db.com. 3 https://docs.docker.com/get-started/overview/.
    4 https://docs.docker.com/engine/security/apparmor/. 5 https://sourceware.org/systemtap/.
    6 https://sourceware.org/systemtap/SystemTap_Beginners_Guide/scripts.html. 7 https://sourceware.org/systemtap//man/tapset::kprocess.3stap.html.
    8 https://github.com/docker/docker-ce/releases/tag/v19.03.14. 9 https://cwe.mitre.org/data/index.html.
    10 https://nvd.nist.gov/vuln/detail/CVE-2019-5736. 11 https://www.exploit-db.com.
    12 https://www.exploit-db.com/exploits/40968. 13 https://hub.docker.com/search?q=&type=image.
    14 https://hub.docker.com/r/kylemanna/openvpn/. 15 https://hub.docker.com/r/pihole/pihole.
    16 https://www.exploit-db.com/exploits/41994. 17 https://www.exploit-db.com/exploits/41458.
    18 https://www.exploit-db.com/exploits/43418. 19 https://www.exploit-db.com/exploits/41995.
    20 https://www.cyberark.com/threat-research-blog/the-route-to-root-container-escape-using-kernel-exploitation/.
    21 https://github.com/cilium/cilium. © 2021 The Authors. Published by Elsevier
    Ltd. Recommended articles Bounded opacity for timed systems Journal of Information
    Security and Applications, Volume 61, 2021, Article 102926 Ikhlass Ammar, …, John
    Mullins View PDF PSCPAC: Post-quantum secure certificateless public auditing scheme
    in cloud storage Journal of Information Security and Applications, Volume 61,
    2021, Article 102927 Haifeng Li, …, He Guo View PDF Mechanisms and techniques
    to enhance the security of big data analytic framework with MongoDB and Linux
    Containers Array, Volume 15, 2022, Article 100236 Akalanka Mailewa, …, Hafiz Khan
    View PDF Show 3 more articles Article Metrics Citations Citation Indexes: 18 Captures
    Readers: 42 View details About ScienceDirect Remote access Shopping cart Advertise
    Contact and support Terms and conditions Privacy policy Cookies are used by this
    site. Cookie settings | Your Privacy Choices All content on this site: Copyright
    © 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved,
    including those for text and data mining, AI training, and similar technologies.
    For all open access content, the Creative Commons licensing terms apply.'
  inline_citation: '>'
  journal: Journal of information security and applications
  limitations: '>'
  pdf_link: null
  publication_year: 2021
  relevance_score1: 0
  relevance_score2: 0
  title: 'Lic-Sec: An enhanced AppArmor Docker security profile generator'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1177/1548512916662365
  analysis: '>'
  authors:
  - Tom Berg
  - Barry N. Siegel
  - A. Cramp
  citation_count: 8
  full_citation: '>'
  full_text: '>

    We value your privacy We and our partners store and/or access information on a
    device, such as cookies and process personal data, such as unique identifiers
    and standard information sent by a device for personalised advertising and content,
    advertising and content measurement, audience research and services development.
    With your permission we and our partners may use precise geolocation data and
    identification through device scanning. You may click to consent to our and our
    1438 partners’ processing as described above. Alternatively you may click to refuse
    to consent or access more detailed information and change your preferences before
    consenting. Please note that some processing of your personal data may not require
    your consent, but you have a right to object to such processing. Your preferences
    will apply to this website only. You can change your preferences or withdraw your
    consent at any time by returning to this site and clicking the "Privacy" button
    at the bottom of the webpage. MORE OPTIONS DECLINE ALL ACCEPT ALL Skip to main
    content Search this journal Enter search terms... Search Advanced search I have
    access via: UNIV NEBRASKA LIBRARIES Access/Profile Cart Browse by discipline Information
    for The Journal of Defense Modeling and Simulation: Applications, Methodology,
    Technology Impact Factor: 0.8 / 5-Year Impact Factor: 0.8 JOURNAL HOMEPAGE SUBMIT
    PAPER Available access Research article First published online September 20, 2016
    Containerization of high level architecture-based simulations: A case study Tom
    van den Berg tom.vandenberg@tno.nl, Barry Siegel, and Anthony CrampView all authors
    and affiliations Volume 14, Issue 2 https://doi.org/10.1177/1548512916662365 Contents
    PDF / ePub Cite article Share options Information, rights and permissions Metrics
    and citations Figures and tables Abstract NATO and the nations use distributed
    simulation environments for various purposes, such as training, mission rehearsal,
    and decision support in acquisition processes. Consequently, modeling and simulation
    (M&S) has become a critical technology for the coalition and its nations. Achieving
    interoperability between participating simulation systems and ensuring credibility
    of results currently often requires enormous effort with regards to time, personnel,
    and budget. Recent technical developments in the area of cloud computing technology
    and service oriented architecture (SOA) may offer opportunities to better utilize
    M&S capabilities in order to satisfy NATO critical needs. A new concept that includes
    service orientation and the provision of M&S applications via the as-a-service
    model of cloud computing may enable composable simulation environments that can
    be deployed rapidly and on-demand. This new concept is known as M&S as a Service
    (MSaaS). There has also been the recent emergence of containerization as an alternative
    to virtualization. Containerization is the process of creating, packaging, distributing,
    deploying, and executing applications in a lightweight and standardized process
    execution environment known as a container. Because containers are, in principle,
    lightweight, they are suitable to serve as the vehicle for the provision of packaged
    (micro)services. Service orientation is an approach to the design of heterogeneous,
    distributed systems in which solution logic is structured in the form of interoperating
    services. This paper investigates various aspects of service orientation and containerization
    including simulation composition, networking, discovery, scalability, and overall
    performance. This investigation provides background information on the topics
    of service orientation, containerization, and Docker – a technology ecosystem
    for working with containers. A case study is presented for the use of Docker in
    support of a training simulation based on the high level architecture (HLA). The
    HLA is an IEEE standard architecture for distributed simulation environments that
    was originally developed for defense applications. The case study introduces a
    number of training use cases, and shows how Docker can be used to assist in their
    implementation. The performance impact of running a simulation within container
    technology is also investigated. The application of container technology to HLA-based
    simulations as presented in this paper is novel. The motivation for looking at
    this topic stems from the activity being conducted within NATO MSG-136. 1. Introduction
    1.1 Background NATO and the nations use distributed simulation environments for
    various purposes, such as training, mission rehearsal, and decision support in
    acquisition processes. Consequently, modeling and simulation (M&S) has become
    a critical technology for the coalition and its nations. Achieving interoperability
    between participating simulation systems and ensuring credibility of results currently
    requires often enormous effort with regards to time, personnel, and budget. Recent
    technical developments in the area of cloud computing technology and service oriented
    architecture (SOA) may offer opportunities to better utilize M&S capabilities
    in order to satisfy NATO critical needs. A new concept that includes service orientation
    and the provision of M&S applications via the as-a-service model of cloud computing
    may enable composable simulation environments that can be deployed rapidly and
    on-demand. This new concept is known as M&S as a Service (MSaaS). The NATO Modelling
    and Simulation Group (NMSG) is one of the panels within the NATO Science and Technology
    Organisation (STO). The mission of the NMSG is to promote cooperation among Alliance
    bodies, NATO, and partner nations to maximize the effective utilization of M&S.
    Primary mission areas include: M&S standardization, education, and associated
    science and technology. The NMSG was officially named as the Delegated Tasking
    Authority for NATO M&S interoperability standards. NATO MSG-136 (“Modelling and
    Simulation as a Service – Rapid deployment of interoperable and credible simulation
    environments”1) is one of the working groups under the NMSG and investigates this
    new concept of MSaaS with the aim of providing the technical and organizational
    foundations for a future permanent service-based M&S ecosystem within NATO and
    partner nations. MSG-136 focuses on several areas: • operational concept of MSaaS:
    how it works from the user point of view; • technical concept of MSaaS: reference
    architecture, reference services, and reference engineering process; • governance
    concept and roadmap for MSaaS within NATO. Rather than providing a “one size fits
    all” solution architecture for MSaaS, MSG-136 is developing a reference architecture.
    This reference architecture provides a template solution for a more specific solution
    architecture. A solution architecture could comply with an established standard,
    such as the High Level Architecture (HLA), or may use an emerging services-based
    architecture, depending on requirements, policies, and standards. There can be
    several solution architectures arising from a single reference architecture. The
    case study that is presented in this paper represents a solution architecture.
    MSG-136 started its three-year term of work in November 2014. 1.2 HLA, service
    orientation, and containerization The HLA2–4 is an architecture for distributed
    simulation environments that was originally developed for defense applications.
    The HLA was ratified as a NATO Standardization Agreement (STANAG) in 2015.5 In
    the terminology of the HLA, an individual simulation application is known as a
    federate with a simulation environment being a collection of federates and known
    as a federation. Federates communicate via a Runtime Infrastructure (RTI), a software
    implementation of the HLA standard. Historically, within the military domain,
    federates have been implemented as large monolithic applications, executing on
    physical workstations, or executing on virtual machines (VMs) within a data center.
    Examples of large, monolithic, Distributed Interactive Simulation (DIS) or HLA-based
    applications used within the NATO community are Virtual Battle Space (VBS) and
    Joint Conflict and Tactical Simulation (JCATS), shown together in Figure 1 in
    a DIS-HLA simulation environment. Large monolithic applications are costly to
    develop and maintain, and are generally challenging to scale in a large distributed
    simulation environment. Figure 1. A DIS-HLA simulation environment with VBS, JCATS,
    and another simulator, connected via a gateway. The computer industry has experienced
    significant technology changes since the initial standardization of HLA and the
    adoption of SOA. The 2000s saw the emergence of cloud computing and the wide adoption
    of virtualization technology. Web-based visualization technologies circumvented
    the need for thick clients in most applications. Simulations were slow to migrate
    to the cloud for various reasons, including: cloud technology not being fully
    ripe for high performance distributed simulations; a large investment in existing
    simulation systems; and requirements for high powered graphics capabilities at
    client workstations. For these reasons, there was no substantial impetus to evolve
    distributed simulation standards such as the HLA to support cloud and service-based
    architectures. There has also been the recent emergence of containerization as
    an alternative to virtualization. Containerization is the process of creating,
    packaging, distributing, deploying, and executing applications in a lightweight
    and standardized process execution environment known as a container. A container
    provides a standard format and interface to its container runtime environment,
    and is portable across runtime environments. Because containers are, in principle,
    lightweight, they are suitable to serve as the vehicle for the provision of packaged
    (micro)services. Containers are analogous to lightweight VMs, with isolation similar
    to VMs but without the resource overhead. Support for containers is built into
    the core of various operating systems, including the Linux kernel, and containers
    maintain their own file system, network stack, and process space. Service orientation
    is an approach to the design of heterogeneous, distributed systems in which solution
    logic is structured in the form of interoperating services.6 Service orientation
    has the goal of creating intrinsic interoperability across a distributed system
    and, thereby, improving the ability to federate across a multitude of individual
    service implementations. The benefits of service orientation derive from core
    concepts of services, high interoperability, and loose coupling. The use of cloud
    computing, containerization, and service orientation present unique challenges
    to the execution of distributed simulations. DIS and HLA-RTI implementations generally
    assume seamless network connectivity between all participating applications, and
    assume no restrictions in data communication. These assumptions may not always
    be true. Examples of challenges include the dynamic nature of network addresses
    and physical machines in clouds, the lack of support for multicast protocols for
    data communication, the implementation of authentication, access control, firewalls
    and other security controls, and impacts on application performance. The purpose
    of this paper is to investigate various aspects of service orientation and containerization
    including simulation composition, networking, discovery, scalability, and overall
    performance. 1.3 Disclaimer The concepts that will be demonstrated in this paper
    are the result of development by participants of NATO MSG-136. The purpose of
    this paper is to explore innovative cloud and service-based simulation technologies,
    and the architecture and software presented do not necessarily represent an endorsement
    by NATO or the participant’s respective national organizations. The commercial
    and open-source products demonstrated were selected for prototyping purposes and
    do not necessarily represent an intent to use in the future by NATO or the participants
    of MSG-136. 1.4. Document overview The remaining sections of this paper are as
    follows. Section 2 provides an overview of the HLA, an international standard
    for the development of distributed simulation environments. The HLA is used in
    the case study presented in Section 5. Section 3 provides an overview of services
    and containerization. This section describes key concepts related to services
    and discusses different kinds of services. This section also introduces the concept
    of containerization. Section 4 discusses Docker, the key enabling technology endorsed
    by the Open Container Initiative (OCI) for containers and container runtime environment,
    and the containerization technology used in the case study. Section 5 presents
    a case study and a number of use cases related to containerization in general,
    and Docker specifically. Section 6 discusses performance implications resulting
    from the containerization of an HLA-based simulation environment. Finally, Sections
    7 and 8 present a summary, conclusions, and directions for further research and
    experimentation. 2. HLA overview The HLA is an international standard for the
    development of distributed simulation environments. In the terminology of the
    HLA, individual simulation applications are known as federates. Federates may
    be simulation models, data collectors, simulators, computer generated forces,
    or passive viewers. The collection of federates brought together to form a synthetic
    environment is known as a federation. It is the common interpretation of a shared
    data model, called the federation object model (FOM), which allows federates to
    interact within a single synthetic environment. A federation execution refers
    to the process of conducting a distributed simulation. Federates interact via
    an RTI. The RTI provides a number of Application Programming Interface (API) service
    groups that are used by a federate to interact with the underlying communication
    layer. Figure 2 is a typical example of an HLA federation, where simulators, support
    tools, viewer, and logger interact through a common RTI and API services, such
    as federation management. Figure 2. A graphical view of the HLA: federates operate
    together through a common RTI. The HLA is focused on interoperability between
    various types of simulations, and to promote reuse of simulations and their components.
    The HLA follows three general design principles. • Modularity: simulation components
    (federates) are composed into larger systems (federations) to obtain a specific
    functional behavior. • Separation of concerns: the functional behavior of the
    components (federates) are separated from the supporting communication infrastructure
    (RTI) via a well-defined interface. • Domain agnostic: the interface between the
    federate and the RTI is agnostic to the domain being simulated. Data communicated
    via the RTI is passed un-interpreted between federate endpoints. Instead, the
    data representing the domain to be simulated is captured externally (in a well-defined
    format) with that data only having meaning to the federates. This allows the HLA
    to be applicable to all domains that may need to be simulated. The HLA was originally
    developed for defense applications but there is a growing non-defense user base
    of the HLA in domains such as cyber physical simulation, aircraft flight simulation,
    railway simulation, offshore maritime simulation, engineering design analysis
    simulation, engine simulation, and lunar landing simulation. The HLA is an international
    standard, developed and maintained by the Simulation Interoperability Standards
    Organization (SISO) and published by the IEEE. The first complete version of the
    HLA was published in 1998 and was known as “HLA 1.3”. HLA became an IEEE standard
    in 2000 (IEEE Std 1516TM-2000) and was updated in 2010 (IEEE Std 1516TM-2010).
    This most recent version is colloquially known as HLA Evolved. Development of
    an updated version of the HLA has begun within SISO7. The HLA standard is composed
    of three parts: the HLA Framework and Rules, the HLA Interface Specification,
    and the HLA Object Model Template (OMT) Specification. • HLA Framework and Rules
    (IEEE Std 1516TM-2010): ten rules describing the responsibilities of federations
    and federates, and their relationship with the RTI2. • HLA Interface Specification
    (IEEE Std 1516.1TM-2010): identifies how federates interact within a federation.
    It specifies an API detailing how a federate interacts with an RTI3. • HLA Object
    Model Template (OMT) Specification (IEEE Std 1516.2TM-2010): defines a common
    format for describing the data that may be communicated between federates in a
    federation execution. This format is used for the creation of the FOM and each
    federate’s Simulation Object Model (SOM).4 The HLA Framework and Rules mandate
    a certain structure for federates and federations to ensure that the models are
    re-usable across applications. The HLA Interface Specification describes seven
    service groups to be used by a federate to interact with the underlying communication
    layer, the RTI. The services are divided into federate initiated calls (RTI Ambassador
    services) and RTI initiated callbacks (Federate Ambassador services). A service
    group refers to a collection of related RTI and Federate Ambassador services.
    All communication between federates in a federation execution is via the service
    implementation provided by the RTI. The RTI communicates with a federate synchronously
    or asynchronously by invoking a callback (Federate Ambassador service) on the
    federate when a certain event occurs. All possible data exchanged by federates
    in a federation is captured in an object model. The object model may contain HLA
    object classes to describe entities with persistent state, and HLA interaction
    classes to describe transient events. The OMT provides a format for this object
    model. There are three kinds of object models in the HLA framework: SOM, FOM,
    and MOM. A SOM describes the data that an individual federate can produce (outputs)
    and needs to receive (inputs). All data that is potentially exchanged in a collection
    of federates (i.e., the federation) is described by the FOM. The third object
    model is the Management Object Model (MOM), which provides a group of constructs
    that supports the monitoring and control of a federation execution. A new concept
    introduced in HLA Evolved is that of the FOM module. A FOM can consist of multiple
    FOM modules, each providing a part of the object model. The modularization of
    the FOM enables, for example, a service oriented approach where a federate can
    define its provided and required service interface in the form of a FOM module.
    3. Services and containerization Containerization has achieved its popularity
    today in part due to the adoption of SOA as a basis for constructing applications.
    A SOA-based architecture is one in which business functionality is provided via
    a number of collaborating services. Containerization allows these services to
    be packaged and deployed independently as a way of providing enhanced configuration
    management and deployment flexibility. This section provides an overview of services
    as the motivation for the use of containers. 3.1 Services There are many definitions
    of a service. The Organization for the Advancement of Structured Information Standards
    (OASIS) defines a service as “…a mechanism to enable access to one or more capabilities,
    where the access is provided using a prescribed interface and is exercised consistent
    with constraints and policies as specified by the service description”.8 The Open
    Group defines a service as “…a logical representation of a repeatable activity
    that has a specified outcome. It is self-contained and is a black box to its consumers”.9
    The Object Management Group (OMG) has a similar definition defining a service
    as “…value delivered to another through a well-defined interface and available
    to a community”.10 All of these definitions have similarities. The important point
    to note is that digital services have interfaces, communicate to the outside world
    using a particular communication style, and provide value to the digital consumer
    of the service. The following two subsections describe key concepts related to
    services and discuss different kinds of services. 3.1.1 Key concepts 3.1.1.1 Service
    elements Figure 3 illustrates some of the basic elements of services. The figure
    is based on the services meta-model described in the NATO Architecture Framework.11
    Figure 3. Service elements. As shown in Figure 3, a service has service attributes
    (such as “service availability”), is subjected to a service policy (putting constraints
    on the service, such as “the service must be provided within x days”), performs
    service functions (describing the functionality of the service), and provides/requires
    service interfaces (specifying the mechanism by which a service communicates).
    Furthermore, services may be placed in a hierarchy, where one service is a specialization
    of another service. 3.1.1.2 Service interface Services have well-defined interfaces
    or APIs. Interfaces are usually expressed in an interface description language,
    which is simply a specification language used to describe a service’s interface.
    For example, with web services in a SOA environment that use Simple Object Access
    Protocol (SOAP), interfaces are described using the W3C Web Services Description
    Language (WSDL). Other examples of interface description languages are Apache’s
    Thrift Protocol, the JavaScript Object Notation Web-Service Protocol (JSON-WSP),
    and the Swagger RESTful API specification. 3.1.1.3 Service composition and orchestration
    Service composition is defined as the aggregation of services to implement a particular
    application: in this paper, a simulation environment. Service orchestration is
    the process of automating the workflow of the arrangement, coordination, and management
    of services as a single aggregate simulation service. The concept of orchestration
    includes the scaling up and scaling down of services on an as-needed basis. Service
    orchestration can be performed through a workflow engine or centralized controller.
    Alternatively, orchestration can be performed using a service choreography approach
    without a centralized service controller, where each participating service controls
    their own workflow and execution. Both orchestration and choreography service
    automation techniques are utilized in the case study. 3.1.1.4 Service deployment
    Service deployment is the process of allocating services to compute nodes, and
    the packaging mechanism to deliver those services. A packaging mechanism for services
    is containers with orchestration software used to provision and deploy containers
    to the cloud. Load balancing is an important aspect of service deployment. Load
    balancing is the process of distributing workload and services across a number
    of compute nodes. Load balancing is used to increase capacity in order to, for
    example, support a larger number of concurrent users. Load balancing is also used
    to improve reliability by deploying redundant services. Load balancing thereby
    improves the performance of an application. 3.1.1.5 Service repository and service
    registry A service repository contains design-time information about services,
    such as service interface information. A service registry contains runtime information
    about services, such as the executable image that provides the service. A service
    repository is available during the engineering of a service, prior to the execution
    of the service. A service registry is available to register compute nodes, network
    addresses, and service ports during service execution, and is used for runtime
    service discovery. Runtime service registration is less common than design time
    service registration. The case study illustrates the use of a runtime service
    registry and repository. 3.1.1.6 Service discovery Service discovery may be design-time
    or runtime. Design-time service discovery, for example, may involve an enterprise-wide
    search for available service interfaces and their associated dependencies. Runtime
    discovery is enabled by protocols that support the automatic detection of services
    on a computer network. When service A invokes service B, service A needs to identify
    the location of the executing instance of service B. Service endpoints may not
    be static, and dynamic service discovery is needed so that services that depend
    on other services can locate and invoke the required service interfaces during
    runtime. Load balancers simplify runtime discovery by providing automated support
    for runtime discovery of service instances managed by the load balancer. Services
    that are not load-balanced must discover and internally manage the runtime addresses
    of dependent service instances. The case study illustrates the concepts of dynamic
    runtime service discovery without a load balancer. 3.1.2 Kinds of services 3.1.2.1
    Stateless and stateful services Services may be stateless or stateful. A stateless
    service is memoryless. Each invocation of the service is independent of the next,
    and each invocation of the service will produce identical outputs, given the same
    set of inputs. Conversely, a stateful service has memory. A stateful service is
    one where requests to that service depend on the inputs provided in the request
    as well as the current state of the service, which is the result of the processing
    of all previous requests. In a simulation environment, the concept of stateless
    and stateful models applies; a stateless service is simply an algorithm or model
    that does not require state maintenance. For example, in a Command and Control
    simulation, a route planning service might be stateless whereas a Common Operational
    Picture service might be stateful. Both stateless and stateful services are used
    in the case study. 3.1.2.2 Microservices A service is an architectural style and
    methodology to decompose complex systems into smaller processes that communicate
    through a well-defined, platform-independent, API. The concept of services in
    a SOA has been around for many years but the term microservice has gained popularity
    only in recent years. Microservices are generally small, single-purpose services
    that follow the “single responsibility” principle found in object-oriented design.
    This principle states that a microservice should provide only one function, and
    have only one reason to change over its development lifecycle. Each microservice
    should follow a separate software development lifecycle enabling a short turnaround
    on changes made by a small, autonomous development team. Traditional SOA services,
    however, have tended to support multiple domain-specific capabilities, are generally
    more tightly coupled with other services, and have larger source code bases. However,
    the difference between microservices and traditional SOA services is mostly one
    of degree. The case study uses mostly single-function, minimal sized microservices
    as the basis for experimentation. 3.1.3 Challenges of using services in a simulation
    environment There are a number of challenges that need to be addressed when designing
    a simulation environment based on services. Many challenges are the same when
    using the HLA, and some are more related to the application of services. A few
    of these challenges are discussed below. 3.1.3.1 Service composability and interoperability
    A key challenge with distributed simulations is service composability and interoperability.
    Composability is a design principle where a simulation environment is decomposed
    into a set of interoperable components that can be deployed independently and
    reused in other simulation environments. These components are called federates
    in the terminology of the HLA. The concept of service adds another dimension to
    decomposition. Components are a structural decomposition of the simulation environment,
    whereas services can be viewed as a more functional decomposition of the simulation
    environment. A service performs a function that can be implemented by a component.
    A service is a finer grained decomposition than structural component decomposition.
    A simulation environment can have just a few components, but there can be many
    services. If designed correctly, with a well-defined service interface, services
    can be combined with other services to form a simulation environment. The challenge
    here is to decompose a simulation environment into much smaller composable and
    interoperable services, and view the components as the pieces that implement the
    services. 3.1.3.2 Service time synchronization One of the most difficult aspects
    of distributed simulation is logical time synchronization. Stateful services may
    contain time-dependent information and, in order to minimize inconsistencies between
    states that may arise due to message latency, message reliability, and network
    drops, some mechanism to synchronize the changes in the states of these services
    is required. Stateless services do not have the same requirements since they operate
    purely on their inputs to produce an output. Therefore, if the inputs and outputs
    are time-dependent, then time must also be an input. However, the outputs generated
    by stateless services must be used in a manner consistent with any stateful services
    present in the simulation. 3.1.3.3 Inter-service communication The HLA defines
    an RTI for federates to communicate with each other. In principle a service can
    use the same RTI to communicate with other services or with service consumers
    in the simulation environment. The service interface could be defined by a HLA
    FOM module that is associated with the service. However, there are a number of
    other protocols and data formats that could be employed to support communication
    between services. For example, in relation to web services, there are techniques
    like Representational State Transfer (REST) and SOAP, and formats like JavaScript
    Object Notation (JSON) and Extensible Markup Language (XML). A web service can
    be described with WSDL. These inter-service protocols and formats provide additional
    choices in the construction of a distributed simulation environment. 3.2 Containerization
    Containerization is the process of creating, packaging, distributing, deploying,
    and executing applications as self-contained units in a lightweight and standardized
    process execution environment known as a container. A container provides a standard
    format and interface to its container runtime environment. A container may provide
    an application like a web or database server, provide a base platform of programming
    language dependencies from which a user can extend, or may provide a complete
    operating system user space such as Ubuntu or, more minimally, Alpine Linux distribution.
    The only thing not included in a container is the operating system (OS) kernel.
    This is provided by the host computing system, and is shared by all containers
    running on the host. As such, containers built to run on a particular OS kernel
    are not portable to hosts running other OS kernels, i.e., a container holding
    a Linux application is not deployable to a Windows host. However, presently, container
    technology is only production-ready on Linux operating systems. This is due to
    the Linux kernel containing specific technology supporting isolated execution
    of multiple containers on a single host. Support for containers is being added
    to other operating system platforms. A container declares, amongst other things,
    the network ports on which it exposes its services to other containers or to non-containerized
    applications. A container has its own file store, but can also share a file store
    that is imported from another container. Because containers are, in principle,
    lightweight, they are very suitable to serve as the vehicle for the provision
    of packaged (micro)services. The key element of containerization is isolation
    enforced by the operating system. File store, network, and process space are managed
    by the operating system in order to isolate these system resources from one container
    to another. This is similar in concept to a VM but with less resource requirements
    because the complete operating system is not required within each container. Therefore,
    containers can be viewed as lightweight VMs. The concept of sandboxing an application,
    prevalent on mobile devices, is also very similar to the concept of a container.
    Containers are also a better match than VMs for the concept of microservices,
    discussed in Section 3.1.2. Containers better support the microservice design
    philosophies of small stateless services, rapid and automated scalability, speed
    to change, and distributed deployment. Note that containers themselves are programming
    language-agnostic, and the use of containers does not dictate a particular software
    development methodology or internal software design paradigm. Containers are a
    packaging and deployment approach that is particularly suitable for cloud- and
    service-based system architectures. Historically, the idea of containers started
    with the chroot made available with Unix V7. This allowed a process to have a
    view of the file system that was isolated from other processes. The FreeBSD jail
    extended this concept of isolation to cover other system resources. The term “container”
    was introduced with Solaris 10 and its Solaris Containers feature. From 2007,
    the Linux kernel introduced cgroups and namespaces as features to better support
    the creation and execution of containerized processes. Linux Containers (LXC),
    introduced around 2008, provided a userspace interface to cgroups and namespaces
    to allow non-privileged users to create and run containerized applications. Initially
    making use of LXC, Docker became available in 2013 as a way of more easily building,
    managing, deploying, and sharing containers. Docker’s popularity has seen a large
    uptake in the use of containerization in recent years. In response to this popularity,
    the OCI was formed to develop standards in relation to containerization with Docker
    technology providing the reference implementation of these initial standards.12
    Docker will also be usable as the command line interface to managing Windows Containers
    introduced by Microsoft in their upcoming Windows Server 2016 release. The Docker
    technology stack is used for the case study presented in Section 5. In preparation
    for that discussion, Section 4 provides an overview of Docker. 4. Docker basics
    4.1 What is Docker and what is so special about it? Since its release as open
    source in 2013, interest in Docker13 has increased considerably with many articles
    and several books being published. A Google search for “Docker container” yields
    over 1,500,000 results. In a nutshell, Docker is an open-source platform to build,
    ship, and run distributed container-based applications. Docker enables the creation
    of lightweight VMs – called container images – that can run on, in principle,
    any Linux host. A container image contains everything that an application needs
    in order to run, using a so-called Docker Engine. Because container images are
    lightweight and have a standard package format, it is easy to ship and run them
    on the fly. This fact, along with its ease of use, makes Docker very popular.
    Figure 4 illustrates the difference between classic virtualization and lightweight
    virtualization with Docker. Figure 4. Docker and virtualization. (a) Classic virtualization
    with a VM; (b) lightweight virtualization with Docker. Figure 4(a) shows the classic
    virtualization with a VM. Each virtualized application includes not only the application
    and the necessary binaries and libraries, but also an entire guest operating system.
    Figure 4(b) shows the lightweight virtualization with Docker. Docker avoids the
    overhead that occurs when using multiple VMs, each requiring its own guest OS.
    This not only saves resources, but allows containers to start and run faster by
    not needing a hypervisor. A container comprises just the application and its dependencies.
    It runs as an isolated process in user space on the host operating system, sharing
    the kernel with other containers. This technology works locally on the user’s
    own PC, within a (virtual) data center environment, and generally in a cloud infrastructure.
    While Docker containers provide numerous benefits over virtual machines, there
    are some drawbacks. At present, applications to be run from within a container
    need to be Linux applications. Since containers running on the same host share
    the services of the one Linux kernel, there is a greater security risk present
    in comparison to running the same applications within their own dedicated virtual
    machines. Finally, Docker containers run in user space and interact with the kernel
    via system calls. Any application requiring lower level access to the kernel or
    to hardware cannot be containerized. These are important points to keep in mind
    alongside the benefits arising from Docker container technology. 4.2 Architecture
    Docker uses a client–server architecture. The main Docker components in this architecture
    are Docker Client, Docker Daemon, Docker Registry, Docker Container, and Docker
    Image, as shown in Figure 5. Figure 5. Docker components. The Docker Client provides
    the user interface for interacting with the Docker Daemon. Communication with
    the Docker Daemon is via Unix sockets or through a RESTful API. The Docker Client
    and Docker Daemon can run on the same host or on different hosts. Some examples
    of commands that may be issued from the Docker Client are: • build: build an image
    from a Dockerfile; • pull: pull an image from a Docker registry server; • push:
    push an image to a Docker registry server; • run: run a command in a new container;
    • start: start a stopped container; • stop: stop a running container; • tag: tag
    an image. The Docker Daemon runs on a host OS (called Docker Host) and handles
    the requests from Docker clients. It is responsible for managing all containers
    and images. A Docker Image is a read-only template from which Docker Containers
    are instantiated. An image is a collection of read-only layers plus some metadata
    that represent filesystem differences. An image can be created with the docker
    build command, by saving a manually modified container, or pulled from a Docker
    Registry. An image is composed of layers of other images, conceptually stacked
    on top of each other. Docker makes use of the Union File System (UnionFS) to combine
    these individual layers into a single image. Layers can be shared between images
    to optimize disk usage, transfer times, and memory use. This layering approach
    enables images to remain relatively small, preventing large amounts of data being
    sent over the network. Figure 6 illustrates the stacking of layers. Figure 6.
    Docker images. Using the image stacking feature, a tree of images can be built,
    all sharing common ancestor images. Figure 7 shows a tree of simulation images,
    some of which will be used and explained further in the case study in Section
    5. The root of the tree is called scratch, on which an Ubuntu and CentOS image
    are based. For the Ubuntu side of the tree, two child images are shown, called
    Pitch RTI Base (pi-rti-base) and Portico RTI Base (po-rti-base). The Pitch RTI
    Base is the parent for a whole set of other images, such as the Pitch Central
    RTI Component (CRC) (pi-crc), the Pitch Recorder (pi-rec-x11ssh and pi-rec-x11vnc),
    the Pitch Google Earth Adapter (pi-ge), and so on. For the CentOS side of the
    tree only one image is shown in the figure, called the VR Forces Simulation Engine
    using the Pitch RTI (pi-vrf-sim). More information about these products can be
    found on the vendor websites.14–16 Figure 7. Simulation image tree. By building
    simulation images in this way it is possible to share common code and libraries
    across images and, thereby, reduce image storage space and the time required to
    pull images from the Docker Registry. A Docker Container is based on a Docker
    Image. A container is the runtime instance of an image, and provides the environment
    in which the application that is held within the container runs. A Docker Container
    is created with the docker run command. Lastly, the Docker Registry is a server
    application for storing and retrieving images (using the docker push and pull
    commands). A registry can be self-hosted (e.g., behind a corporate firewall) or
    hosted by a third party. An example of hosted registry is the Docker Hub.17 The
    Docker Hub includes a free-to-use registry where users can exchange images through
    both public and private repositories. 4.3 Docker networking There are various
    configurations in which Docker containers can be networked together. Two common
    configurations are called bridge networking and overlay networking. Bridge networking
    is the default configuration for a Docker Host where containers are connected
    to a network bridge, and can communicate with every other container on the bridge.
    The default bridge is called docker0, and networking is limited to a single Docker
    Host. Overlay networking is basically a network that is built on top of another
    network. Overlay networking enables containers to run in a seamless network across
    a cluster of Docker Hosts. Where the overlay network also supports the Domain
    Name System (DNS), containers can reference each other by container name rather
    than just by IP address. The benefits of overlay networking are further described
    in the case study. 4.4 The Docker ecosystem The components listed in the previous
    subsections are a part of the so-called Docker Ecosystem. Although there is no
    established definition for what an IT-related ecosystem is, the term Docker Ecosystem
    can be defined as a complex system of interdependent components that work together
    to enable or provide services via the Docker platform. A number of other important
    components in the ecosystem include service discovery, service composition and
    orchestration, continuous integration and deployment, data volume management,
    and cross-host container networking. In addition, the Docker Hub provides a large
    and ever-increasing set of components that users can leverage to build (new) solutions.
    Some of these components will be demonstrated in the case study in the next section.
    5. Case study A case study is used to explore the concept of containerizing simulation
    components. The case study concerns a fictitious situation where a maritime task
    group is planned to be deployed in the Persian Gulf region for a maritime interdiction
    mission. Surface track managers need to rehearse coordination in the task group
    and use a simulation environment to prepare themselves for this mission. The track
    managers are located on different training sites, but in real life they may be
    on board a military vessel (Military Surface Unit). From each training site they
    connect to the simulation environment that is running somewhere in a cloud environment.
    A Simulation Controller is responsible for the creation of the simulation environment
    in the cloud environment. The Simulation Controller can rapidly compose the simulation
    environment from components that are published in a so-called NATO M&S Registry.
    In our case study this registry is actually the Docker Hub, and all of the components
    used in the case study are unclassified. The cloud environment is provided by
    Amazon Web Services (AWS), consisting of two Elastic Compute Cloud (EC2) instances
    running in a data center in Ireland and one EC2 instance running in a data center
    in Germany. In this fictitious mission rehearsal situation, the following simulation
    components are pulled on-demand from the NATO M&S Registry: • a Vessel Traffic
    Simulator to generate vessel traffic in the region of interest; • a Military Surface
    Unit Simulator to be used by each track manager; • several simulation infrastructure
    components. The number of Military Surface Unit Simulators can be scaled up or
    down depending on the number of track managers in the mission rehearsal. The simulation
    runs entirely in a cloud environment distributed across two data centers, where
    the interface to the simulation is provided by a web browser, and where Google
    Earth is used for visualization of all entities in the region of interest. This
    is illustrated in Figure 8. Figure 8. Cloud view of the simulation environment.
    The simulation in this case study is a small HLA federation with the following
    components: • a Vessel Traffic Simulator federate (TrafficSim); • one or more
    Military Surface Unit Simulator federates (ShipSim); • a Pitch Google Earth Adapter
    federate (see Pitch Technologies14), translating federation data to Keyhole Markup
    Language (KML) for visualization in Google Earth; • a Pitch Central RTI Component
    (CRC) (see Pitch Technologies14), providing the RTI for HLA federates to communicate;
    and • a Pitch Web graphical user interface (GUI) (see Pitch Technologies14), providing
    a web-based graphical user interface to monitor the federates in the HLA federation.
    There are also several other Docker Ecosystem components: • Docker Compose and
    Docker Swarm (see Docker, Inc.13) for service composition and orchestration; •
    Consul and Registrator for service discovery (see Docker, Inc.18); • Weave for
    providing the overlay network across the two data centers (see Weaveworks19).
    For technical reasons the native Docker overlay networking (available in Docker
    1.9 onwards) could not be used at the time of the case study, but this had no
    effect on the results. The HLA federation view of the simulation environment is
    provided in Figure 9. The components shown in the enclosed box are containerized
    components. All that is running on the desktop is Google Earth and a web browser.
    Figure 9. Federation view of the simulation environment. The case study is broken
    down into a number of use cases, each exploring some aspect of the concept. 5.1
    Use case 1: Search NATO M&S Registry In this first use case, the Simulation Controller
    searches the NATO M&S Registry to identify Docker Images that satisfy requirements.
    Activities that the Simulation Controller performs in this use case include: •
    search registry; • browse registry; • obtain services descriptions; • download
    images. In this use case we use the Docker Hub, a hosted registry that is run
    by Docker, Inc. Figure 10 provides an example of a list of Docker Images in the
    Docker Hub registry. More information about an image can be obtained by clicking
    the Details button. Figure 10. Docker Hub registry. The Simulation Controller
    can immediately download selected Docker Images with the docker pull command,
    or defer this until the simulation execution is started. For example, the following
    command will pull the Military Surface Unit Simulator image to the Docker Host:
    docker pull msaas/shipsim Obviously a graphical user interface for the Simulation
    Controller is preferred for getting images from the registry. However, in this
    case study we will just use the command line interface to illustrate the concept.
    5.2 Use case 2: Compose a simulation environment In the first use case the Simulation
    Controller pulled the required Docker Images from the NATO M&S Registry onto a
    Docker Host. In principle the Simulation Controller can now start a simulation
    execution by manually starting the containers. For example, to start the traffic
    simulation on a single Docker Host the Simulation Controller would run: docker
    run -d ––link crc:crc \ ––name trafficsim msaas/vesseltraffic \ -F TrainingSessionA
    -f TrafficSim -c crc and to start the ship simulation on the same Docker Host:
    docker run -d ––link crc:crc \ ––name shipsim msaas/shipsim \ -F TrainingSessionA
    -f ShipSim -c crc The specifics of the docker run command line options are explained
    at Docker, Inc.13 The command options specified after the image name (i.e., msaas/vesseltraffic
    and msaas/shipsim) are supplied to the service started within the launched container,
    for example the name of the federation to join. As one can see, starting a simulation
    execution this way is quite laborious and, potentially, error prone. Automated
    means of composing a simulation environment and starting a simulation execution
    are very much preferred. Docker Compose provides a way for the Simulation Controller
    to define the composition of a multi-container simulation environment. The next
    use case, described in Section 5.3, illustrates using such a composition to start
    the simulation execution with a single command. Activities that the Simulation
    Controller performs in this use case of composing a simulation environment include:
    • define the services that make up the simulation environment, amongst others:
    ◦ specify the Docker Image used for each service; ◦ specify the exposed service
    ports; ◦ specify data volumes; • define service dependencies, amongst others:
    ◦ specify constraints (e.g., service must run on a specific host); ◦ specify affinities
    (e.g., service must run together with another service). The Simulation Controller
    uses a Compose file to define the composition of the simulation environment. A
    Compose file is a YAML Ain’t Markup Language (YAML) formatted file that can be
    created with a plain text editor.20 This file is used by Docker Compose to start
    the simulation environment based on the definitions contained in the file. A fragment
    of a Compose file (vesselsim.yml) is provided below. shipsim: image: msaas/shipsim
    command: -F TheWorld -f ShipSim -c crc  –connection-attempts 20 ports: - “8088”
    environment: - adapter=ethwe trafficsim: image: msaas/vesseltraffic command: -F
    TheWorld -f TrafficSim -c crc  -k Tracks.kml -s 2 -d 5 environment: - adapter=ethwe
    crc: image: msaas/pi-crc:5.0.1.0L container_name: crc ports: - “8989:8989” web:
    image: msaas/pi-web:2.1.0 container_name: web ports: - “8080:8080” ge: image:
    msaas/pi-ge:1.4.1L container_name: ge command: -F TheWorld -f Google  -g 54.1.2.3
    -t 10 -c crc ports: - “8765:8765” environment: - adapter=ethwe - “constraint:node==ip-172-31-9-126”
    The top level keys in the Compose file represent services, and the values contained
    within each service form the service definition. In this case study Compose file
    there are five services defined, corresponding with the simulation components
    illustrated in Figure 9. For each service there are values for the container image,
    container name, container-specific command, exposed ports, constraints, and so
    on. In the above sample file, the Google Earth service, for example, uses the
    image “msaas/pi-ge” with the tag “1.4.1L”, has a list of command line options
    (such as the federation and federate name), exposes its service on port 8765,
    and constrains the execution of the service to the compute node with the name
    “ip-172-31-9-126”. For more information on the possible values that can be used
    per service, see Docker Compose at Docker, Inc.13 5.3 Use case 3: Start a simulation
    execution In this use case the Simulation Controller starts the simulation execution
    across a cluster of Docker Hosts. Two hosts are located in Ireland and one in
    Frankfurt, Germany. In order to execute the simulation in a cluster of Docker
    Hosts the Simulation Controller needs to establish an overlay network between
    the hosts and needs some other components to automatically distribute and monitor
    the simulation components in the cluster. The Simulation Controller uses the Compose
    file from the previous use case to start the execution with a single command.
    Activities that the Simulation Controller performs in this use case includes:
    • prepare infrastructure components; • start and stop simulation execution; •
    scale up or scale down specific services; • monitor and control services. 5.3.1
    Prepare infrastructure components To run the simulation in a cluster of Docker
    Hosts the Simulation Controller needs to prepare various “infrastructure” components.
    The Simulation Controller needs components for: • overlay networking (Weave Proxy
    and Weave Router); • services orchestration (Docker Compose and Docker Swarm);
    • services discovery (Consul and Registrator); • services monitoring and control
    (Weave Scope, Consul). Figure 11 provides a schematic view of our cluster of Docker
    Hosts and the components per host. Hosts A and B are located in the data center
    in Ireland, and host C in Germany. The infrastructure components are all Docker
    Containers and are described next. Figure 11. Docker Host cluster view. Overlay
    networking is used for inter-container communication across Docker Hosts. With
    overlay networking, containers all have a unique IP address within the scope of
    the overlay network. Overlay networking is currently the only out-of-the-box approach
    for creating a multi-host network that enables the distribution of Docker containers
    across different Docker Hosts. In addition, Weave overlay networking supports
    multicast network communication, which is disabled by many cloud providers. For
    other approaches – besides bridged networking – dedicated network drivers need
    to be developed. With overlay networking Docker Hosts may all be located in the
    same data center, may be distributed across data centers (of the same or different
    cloud providers), or may even be distributed between data centers and other computing
    environments (such as a private local area network (LAN)). In this use case, overlay
    networking is provided by Weave, and the Docker Hosts are located in two different
    data centers of the same cloud provider. Overlay networking with Weave is quite
    easy to set up, and the following two Weave components are used. • The Weave Proxy
    sits between the Docker client (in this case Swarm) and the Docker Daemon, so
    that it can automatically attach new containers to the Weave overlay network.
    The use of the proxy is transparent to the client. • The Weave Router establishes
    the overlay network and provides many features, including a DNS. With Weave DNS,
    containers can reference each other by name. Each host runs one Weave Router that
    communicates with the other Weave Routers to build up and maintain the overlay
    network. For a complete list of features see Weaveworks.19 Service orchestration
    generally refers to the automated arrangement, coordination, and management of
    services. In this use case the Simulation Controller uses Docker Compose and Docker
    Swarm for service orchestration. • Docker Compose uses the previously created
    Compose file to start our multi-container simulation environment. It can run from
    any host. In our setup, it communicates with Docker Swarm to load balance and
    start the containers in the Docker Host cluster. • Docker Swarm is a tool for
    clustering and turns a cluster of Docker Hosts into one virtual Docker Host. Docker
    Swarm provides the standard Docker Daemon API so that any Docker client can use
    Swarm to transparently scale to multiple Docker Hosts. Service discovery is concerned
    with (in the context of this use case) the runtime discovery of services in a
    cluster so that services can find and communicate with each other. Generally,
    service discovery involves a service directory, the registration of services in
    the directory, and the ability to look up and connect to services in that directory.
    DNS is a simple example of a discovery service. In this use case the following
    two components are used to establish service discovery: • Consul is a distributed
    system, consisting of Consul servers and Consul agents. The servers maintain a
    service directory amongst other features. Agents are responsible for health checking
    services on a node as well as the node itself. Clients can query any of the Consul
    servers or Consul agents about services using either the DNS or the HTTP API of
    Consul. • Registrator is a component used for registration and de-registration
    of services on a Docker Host with Consul. Service monitoring and control in this
    use case is defined as the real-time monitoring of the status, performance and
    resource utilization of a service, and the real-time control of the status of
    the service (i.e., start, stop, pause, resume). In this use case we use Weave
    Scope and Consul, although there are various other tools available that are equally
    suited. • Weave Scope automatically generates a map of containers, enabling us
    to monitor and control the individual containers and services. • Consul can be
    used to query the status of services. 5.3.2 Start and stop simulation execution
    Once the infrastructure components have been set up in the Docker Host cluster,
    the Simulation Controller can easily start the simulation execution with docker-compose
    -f vesselsim.yml up The Simulation Controller uses Google Earth to obtain an overview
    of the situation in the (simulated) mission area, shown in Figure 12. Since the
    Google Earth Adapter is constrained to a particular node in the cluster, the Simulation
    Controller knows how to configure Google Earth to fetch the KML data from that
    node. However, the other simulation components are running anywhere in the cluster
    and the Simulation Controller needs to consult Consul to find out where. Figure
    12. The mission area. For example, to find out where the CRC is running, the Simulation
    Controller navigates to the services list in Consul and selects “pi-crc-8989”.
    On the right of the screen in Figure 13, the node on which the service runs is
    displayed (node-2A, corresponding to one of the two EC2 instances in Ireland).
    In another simulation execution the CRC may be located on another node. Figure
    13. Consul service page. With a simple command, the Simulation Controller stops
    the simulation execution docker-compose -f vesselsim.yml stop and removes the
    services with docker-compose -f vesselsim.yml rm 5.3.3 Scale up or scale down
    specific services Once the simulation execution has started, the Simulation Controller
    can easily add additional services. These additional services are in principle
    all identical services. If the service requires state information then the initial
    state information (such as location of ship) should be provided via some scenario
    management interface. This is, however, outside the scope of the case study. For
    example, to add two additional Military Surface Unit Simulators the Simulation
    Controller does docker-compose -f vesselsim.yml scale shipsim=3 Similarly, the
    Simulation Controller can reduce the number of services by two with docker-compose
    -f vesselsim.yml scale shipsim=1 Docker Compose provides various other useful
    commands, such as viewing log files, obtaining the public port number of a service,
    and listing the status of services. 5.3.4 Monitor and control services With Weave
    Scope (using a web browser) the Simulation Controller can monitor and control
    the services as they start and run on the different hosts. An example of a container
    overview is shown in Figure 14. Figure 14. Weave Scope container network overview.
    By selecting a node, more information appears, such as memory and CPU usage. Figure
    15 shows information about the CRC. From the popup window the service may be stopped,
    paused/resumed, or restarted. Figure 15. Weave Scope container information. 5.4
    Lessons learned from the case study Several issues have been identified through
    the case study in containerizing both new and legacy applications. • User interfaces.
    Some applications require a command line interface at installation time, for example
    to run an installer program or to enter a license key. This obviously breaks automated
    container builds since manual steps are needed to install the application. Also,
    some applications use a GUI at runtime or just link with GUI libraries while not
    actually using a GUI. This requires the installation of an X Server inside the
    container or access to an X Server elsewhere in the network. Note that an X Server
    running inside the container makes the container image bigger. • Licenses. Since
    license dongles do not work in the cloud, node-locked licenses or a license server
    must be used. Media access control (MAC) addresses or a containerized license
    server have to be provisioned to run licensed applications within containers.
    A MAC address can be assigned to a container when it starts. • Application configuration
    data. Applications often have the assumption built in that the user can change
    certain application settings by editing configuration files. When the application
    is containerized this is obviously not possible anymore, and other measures are
    needed to pass in configuration settings, for example, via container command line
    options or via data containers that are mounted by the application container.
    • Weave overlay networking. The Weave overlay network creates a Weave-related
    network adapter inside the container. From the application point of view this
    means that there are two network adapters that can be used to communicate with
    other containers: the Weave (overlay) network adapter and the Docker bridge network
    adapter. The application must be forced to use the Weave network adapter. In the
    case of the federates used in the case study, this was accomplished by modifying
    the start script of each application to change the (Pitch) Local RTI Component
    (LRC) configuration files to point the host adapter setting to the Weave network
    adapter. This is, however, an RTI vendor-specific solution. • Services discovery.
    In the case study, KML files are generated by the Pitch Google Earth Adapter and
    icons are generated by a so-called Icon Server. Each icon in the KML file has
    to be addressed with the full URL of the icon, hence the Pitch Google Earth Adapter
    needs to know the URL of the Icon Server upon startup. The Icon Server is, in
    the case study, actually the same application as the Google Earth Adapter. In
    the case study this issue was resolved by: (1) providing the URL of the Icon Server
    as a command line option to the Pitch Google Earth Adapter; and (2) scheduling
    the Pitch Google Earth Adapter container on a specific compute node via the Docker
    Compose “constraint:node” element of the service. A more flexible and dynamic
    way to handle this kind of situation through services discovery should be possible.
    For example, the Pitch Google Earth Adapter should be able to discover the Icon
    Server and be able to query the address and port that the Icon Server exposes
    its service on (this approach is in fact supported by Consul). • LRC base image.
    Every HLA RTI has an LRC, and in the case study the vendor-specific LRC was built
    into each application container. A containerized LRC base image is missing, however.
    New applications can leverage such a standard base image, thereby decoupling application
    logic from a vendor-specific LRC. • Standardized container command line options.
    In the case study the containers can be started with various command line options.
    In the scope of the case study some of the command line options have been standardized
    across containers (such as -F federationName). However, new containers will most
    likely not comply with these agreements and will have their own command line options.
    Still, it is important to standardize on a set of common command line options
    that containers must support. Based on these issues and within the limited scope
    of the case study, several guidelines for application developers can be formulated
    (some of these guidelines are discussed further by Cramp et al.21 and van den
    Berg et al.22). • Decouple the GUI from an application that is intended to provide
    a service. A containerized application should generally provide a GUI via a web
    browser. • Handle application configuration via environment variables or via data
    containers. Do not assume that the user has access to the container content. •
    Use standard LRC base images for HLA applications. This decouples application
    logic from the specific HLA-RTI, and enables the configuration of the base image
    independent from the application. Obviously, RTI vendors should provide these
    LRC base images, and standard settings for LRC base images have to be agreed upon.
    • Use a standard set of command line options. This paper shows several command
    line options that can be standardized. 6. Performance The previous sections have
    argued that containerization provides real benefits in the development and operation
    of HLA federations. The question arises: what is the performance cost of running
    simulations thus containerized? Felter et al.23 showed that, on a single machine,
    containers result in equal or better performance than VMs in almost all cases,
    and the performance of the containers is comparable to native performance. However,
    the question of performance of containerized HLA federations is particularly pertinent
    in a networked computing environment. To illustrate the potential performance
    penalties, the following three figures provide different configurations for running
    a networked HLA federation: non-containerized, containerized using raw networking,
    and containerized using an overlay network. Each configuration has the same network
    environment between the hosts. Differences in performance of the configurations
    arise from how much extra work, including network management, is required from
    each host. Figure 16 illustrates a non-containerized HLA federation spread over
    five hosts connected via a local network. In this configuration, there is no custom
    network management required from a host. Figure 16. A non-containerized HLA federation.
    Figure 17 represents the same HLA federation but with the federates and RTI provided
    via containers. Docker provides a virtual Ethernet bridge, named docker0, to allow
    containers on a single host to communicate. However, by default, the IP range
    used by the Docker Daemon will be the same on each host. In order for containers
    to communicate between hosts, they need unique IP addresses. This can be done
    through custom Docker configuration, and this is illustrated in Figure 17. The
    host machines also require custom network routing table rules to allow a host
    to correctly forward IP packets to containers running on other hosts. Figure 17.
    Network configuration of the multi-host, raw networking, containerized test. This
    configuration introduces extra Layer 3 (OSI network model) routing steps in the
    network path from one federate to another. To be explicit, communication from
    a federate on Host 1 to a federate on Host 2 is: Federate (Host 1) → docker0 bridge
    (Host 1) → eth0 (Host 1) → eth0 (Host 2) → docker0 bridge (Host 2) → Federate
    (Host 2). Finally, Figure 18 illustrates the configuration where the networking
    between containers across hosts is delegated to a Weave overlay network. With
    this configuration, each host runs an additional container providing a Weave Router.
    These routers maintain knowledge of the overall network configuration allowing
    the HLA federation to more easily connect and communicate. In particular, the
    routing tables on the hosts do not require manipulation. However, all communication
    is via these routers. Figure 18. Network configuration of the multi-host, Weave
    overlay, containerized test. Now the network path from the federate on Host 1
    to the federate on Host 2 is: Federate (Host 1) → Weave bridge (Host 1) → Weave
    Router (Host 1) → eth0 (Host 1) → eth0 (Host 2) → Weave Router (Host 2) → Weave
    bridge (Host 2) → Federate (Host 2). The Weave overlay network adds two steps
    over the raw networking configuration. These additional steps are representative
    of Layer 5 to Layer 7 user space routing being conducted by the Weave Router.
    Routing at this level incurs extra overhead compared to the lower level Layer
    3 kernel space routing used by raw networking. Data sent between two federates
    on the same host would not follow the above network path through the Weave Router.
    Instead, they are able to communicate directly via the Weave bridge. Additionally,
    Weave supports the creation of a so-called fast data path between hosts that involves
    the Weave Router dynamically configuring a kernel module to provide direct routing
    of packets from one container to a destination container (rather than having the
    Weave Router perform the routing). The fast data path removes the Weave Router
    from the network path from one federate to another but does introduce a kernel
    space routing function similar to the raw networking option. In this case, the
    network path between two federates is: Federate (Host 1) → Weave bridge (Host
    1) → eth0 (Host 1) → eth0 (Host 2) → Weave bridge (Host 2) → Federate (Host 2),
    with kernel space routing between the weave bridge and eth0 on both hosts. Testing
    performed by the developers of Weave show that the fast data path is close in
    performance to direct host networking.24 Performance tests of these three network
    configurations were conducted to evaluate the costs of these networking options.
    Google Compute Engine (GCE) provided the Infrastructure as a Service (IaaS) platform
    in which the tests were run. GCE compute instances of machine type n1-standard-1
    were instantiated to act as the hosts. This machine type has one virtual CPU and
    3.75 GB of RAM. Ubuntu 15.10 was installed with Docker 1.9, Weave 1.3 (for the
    overlay network test) and Java 8. Routing information for the raw networking configuration
    was entered through the GCE console. The Weave overlay network did create a fast
    data path between the hosts. A custom HLA Performance Federation was configured
    to run a fixed number of simulation steps with 30 to 60 bytes of data sent between
    Performance Federates at each step. The wallclock time to complete the simulation
    was used as the measure of performance. The results showed that the raw networking,
    containerized configuration was, on average, 16% slower than the non-containerized
    federation, while the Weave overlay configuration was 26% slower than the non-containerized
    federation. In absolute terms, the wallclock time required to complete 20 simulation
    seconds were: 0.402 s for the non-containerized federation, 0.466 s for the containerized,
    raw networking configuration, and 0.508 s for the containerized, Weave overlay
    configuration. The relatively poorer performance of the Weave overlay configuration
    can’t be completely attributed to the overlay networking. The Weave configuration
    also included an additional process (the Weave Router) on each host when compared
    to the other networking configurations. This extra process may have competed with
    the Performance Federate for CPU time. Retesting with a different machine type
    (e.g., n1-standard-2 that has two virtual CPUs) would identify whether this resource
    constraint was a problem. 7. Summary and conclusions This paper presented and
    evaluated an alternative approach to current practices in developing HLA-based
    applications: using service orientation and containerization in combination with
    cloud computing. The emergence of container-based technologies and service-based
    approaches provide new opportunities and challenges for distributed simulation
    and standards such as the HLA. A fictitious case study was used to explore the
    concept of containerization. As learned from the case study, containerization
    is disruptive and impacts the way (HLA-based) simulation applications are designed,
    developed, and deployed. Containerization is ideally suited for small applications,
    whereas many existing simulation applications are large and monolithic; these
    need to be broken down in smaller building blocks to really benefit from containerization.
    Some challenges encountered in the case study are: how to deal with configuration
    data, how to deal with user interfaces in a cloud environment, and how to containerize
    existing applications in the first place. For example, once an application is
    containerized, its configuration data cannot be accessed in the usual way by editing
    a file and changing a setting. Configuration data is provided by mounting a data
    volume from another (data) container in which the new settings are provided. Lastly,
    standardized LRC base images should be made available to application developers
    so that application logic can be decoupled from a specific HLA-RTI implementation.
    Also, standard container command line options should be promoted. Containerization
    also has an impact on performance. This is especially true in a networked computing
    environment where container runtime components and assistive tools like overlay
    networking add steps to the network paths between pairs of federates. Performance
    measurements in a multi-host simulation environment for some configurations have
    shown that containerization degrades performance by 16% to 26%, depending on the
    network architecture. However, not all configurations have been tested, and performance
    gains are possible. Further tests are required to pinpoint the cause of the degraded
    performance and to identify possible solutions. Once the simulation applications
    were containerized, the case study demonstrated that it was straightforward to
    compose and run a geographically distributed simulation in the cloud across two
    data centers; no network engineering expertise was required to establish this
    network. In fact, the simulation could be deployed in any Docker-based computing
    environment, any time, any place. When the initial hurdle was taken (that of containerizing
    applications), two benefits became obvious almost immediately: zero deployment
    time and zero network engineering time to run a distributed simulation. A third
    benefit was the use of the Docker Hub to exchange container images during development;
    the use of the Docker Hub provided immediate access by the developers to images
    provided by individuals resulting in there being no need for collocated integration
    events during the case study. The developers who participated in the case study
    are located on three continents, and travel costs were zero. In the classic, non-cloud-based
    situation, there would have been travel costs to integrate, test, and execute
    the simulation, and there would have been costs to establish a virtual private
    network (VPN) between the three locations. In summary, containerization potentially:
    • Integrates with legacy and standards-based (e.g., HLA) simulation technologies.
    It is important to mention that containerization is orthogonal to the HLA and
    adds another dimension to architecting a simulation environment. The concepts
    of federate and container are independent in the architecture of the simulation
    environment. Containerization does not solve simulation interoperability challenges,
    but it does enable simulation engineers to address these challenges much earlier
    in the development phase of a simulation environment, as explained in the following
    items. • Simplifies the development process of simulation applications. Containerization
    enables the development of small applications (i.e., services), packaged as a
    container. Small applications are easier to develop and maintain. • Simplifies
    the deployment process of simulation applications. Once an application is packaged
    as a container, it can in principle be deployed anywhere seamlessly without much
    user involvement. Existing non-containerized applications require running an application-specific
    installer program (best case) or the installation of a complete development environment
    with all kinds of configuration files (worst case), often with dependencies on
    other software libraries or applications installed on the host. A container provides
    a self-contained and packaged solution with, in principle, no dependencies on
    the host on which it runs. • Reduces the need for large-scale integration events.
    When a simulation application is available as a container image in a registry
    such as the Docker Hub or a private registry, it can in principle be deployed
    anywhere within the network. Containerization enables a “self-service” model where
    components are available anywhere and anytime. There is less need for big get-together
    events where participants physically bring in their own PCs with the simulation
    applications running on them. Integration events are still needed, but these can
    become smaller in terms of people and shorter in terms of time because many things
    can be tested well ahead of such an event. • Promotes a model of continuous integration
    rather than “big-bang” integration. When applications are containerized it is
    relatively easy to deploy them, enabling early test and integration with other
    (containerized) applications. An application can be integrated and tested with
    another containerized application as soon as it is made available as a container
    image in a registry. This promotes a model of continuous integration, well known
    in software development practices. It enables simulation engineers to address
    interoperability issues much earlier in the development phase of a simulation
    environment, rather than at a big-bang integration event. • Scales up and down
    seamlessly. If designed well, containerized applications can be scaled up or down
    seamlessly by making use of lightweight virtualization. • Drops the cost of large-scale
    NATO simulation events for training and coalition exercises. All in all, the cost
    of large-scale NATO simulation events will drop when a simulation environment
    is more composable (i.e., consisting of smaller and containerized applications),
    and can be assembled and deployed more rapidly, and on-demand; possibly even in
    the cloud. In addition, there is: • A growing Docker ecosystem with strong support
    from the open-source community; • Ongoing commercial standardization. In conclusion,
    the authors believe that the advantages of containerization and service orientation
    outweigh the disadvantages. 8. Future research The Docker ecosystem will evolve
    further, and features will continually be added to the Docker products. Since
    the initial version of this paper was developed, several promising new features
    have been added to Docker, such as user-defined networks and storage drivers.
    These new features will be researched in the remaining time of MSG-136. Further
    work that will be undertaken in the context of MSG-136 includes the following.
    • Establishment of service repositories (with service design-time information)
    and Docker registries (with service images), and development of tools to automate
    simulation environment composition and execution using information from service
    repositories. • Establishment of guidelines for containerizing HLA federates,
    and experimentation with various service design patterns and stateless/stateful
    services with appropriate levels of aggregation in order to establish guidelines
    for using services within the HLA. For example, should non-HLA protocols and formats
    only be used for communication with stateless services in order not to violate
    the HLA rules? • Identification of required security services. A complete discussion
    of security in a service-based simulation is outside the scope of this paper.
    However, concepts such as single sign-on (SSO), role-based access control (RBAC),
    and attribute-based access control (ABAC), and commercial standards such as Security
    Assertion Markup Language 2.0 (SAML) and OAuth 2, are fundamental components of
    a service-based architecture. A service-based architecture must implement security
    services, especially in a defense simulation environment. • Experimentation with
    non-HLA cloud-based simulation environments, for example, persistent storage architectures
    where objects that must be maintained throughout the simulation are stored and
    distributed via persistent storage. • Additional performance tests that cover
    different kinds of Docker Host, network, storage, and container configurations.
    Questions include: what additional latencies are introduced due to containerization;
    what is the effect of scaling in a containerized environment, and why. • Experimentation
    with cross-cloud and cross-domain simulation environments. Commercial and private
    clouds have varying support for networking protocols, cryptologic protocols, and
    policies relating to the automated configuration of firewalls and virtual private
    networks. For example, most commercial clouds today do not support multicast protocols
    used by some HLA-RTIs. Acknowledgments This paper was created on the basis of
    the work conducted by Research Task Group (RTG) MSG-136 “Modelling and Simulation
    as a Service – Rapid deployment of interoperable and credible simulation environments”
    of the NATO STO. Declaration of conflicting interests The authors declare that
    there is no conflict of interest. Funding This research received no specific grant
    from any funding agency in the public, commercial, or not-for-profit sectors.
    References 1. NATO Science and Technology Organization CSO. Modelling and Simulation
    as a Service (MSaaS) Rapid deployment of interoperable and credible simulation
    environments (MSG-136), https://www.sto.nato.int/Pages/activitieslisting.aspx
    (2014, accessed 11 July 2016). GO TO REFERENCE Google Scholar 2. IEEE Std 1516TM-2010
    – IEEE Standard for Modeling and Simulation (M&S) High Level Architecture (HLA)
    – Framework and Rules, https://standards.ieee.org/findstds/standard/1516-2010.html
    (2010, accessed 13 September 2010) Google Scholar 3. IEEE Std 1516.1TM-2010 –
    IEEE Standard for Modeling and Simulation (M&S) High Level Architecture (HLA)
    – Federate Interface Specification, https://standards.ieee.org/findstds/standard/1516.1-2010.html
    (2010, accessed 25 March 2010). GO TO REFERENCE Google Scholar 4. IEEE Std 1516.2TM-2010
    – IEEE Standard for Modeling and Simulation (M&S) High Level Architecture (HLA)
    – Object Model Template (OMT) Specification, https://standards.ieee.org/findstds/standard/1516.2-2010.html.
    (2010, accessed 6 August 2010). Google Scholar 5. NATO. NATO Standardization Agreement
    (STANAG) 4603 Edition 2. Orlando, USA, 17 February 2015. Orlando, FL: SISO. GO
    TO REFERENCE Google Scholar 6. Cramp A, Van Den Berg T, Huiskamp W. Service orientation
    for the design of HLA federations. In: SISO Fall Simulation Interoperability Workshops
    Orlando, USA, 8–12 September 2014, pp. 329–339. Orlando, FL: SISO. GO TO REFERENCE
    Google Scholar 7. Simulation Interoperability Standards Organization. HLA PDG
    – High-Level Architecture, https://www.sisostds.org/StandardsActivities/DevelopmentGroups/HLAPDG-High-LevelArchitecture.aspx
    (2016, accessed 11 July 2016). GO TO REFERENCE Google Scholar 8. MacKenzieet al.
    Reference Model for Service Oriented Architecture 1.0. 12 October 2006. Burlington,
    MA: OASIS. GO TO REFERENCE Google Scholar 9. The Open Group. Service-Oriented
    Architecture Ontology Version 2.0. April 2014, Reading, UK: The Open Group. GO
    TO REFERENCE Google Scholar 10. Object Management Group. Service oriented architecture
    Modeling Language (SoaML) Specification Version 1.0.1. Needham, MA: Object Management
    Group, 2012. GO TO REFERENCE Google Scholar 11. NATO. NATO Architecture Framework
    Version 3. Brussels, Belgium: NATO C3 Board, 2007. GO TO REFERENCE Google Scholar
    12. Open Container Initiative. The Open Container Initiative, https://www.opencontainers.org
    (2016, accessed 11 July 2016). GO TO REFERENCE Google Scholar 13. Docker, Inc.
    Build, ship, and run any app, anywhere, https://www.docker.com (2016, accessed
    11 July 2016). Google Scholar 14. Pitch Technologies, http://www.pitchtechnologies.com
    (2016, accessed 11 July 2016). Google Scholar 15. VT MÄK, http://www.mak.com.
    (2015, accessed 11 July 2016). Google Scholar 16. Portico. The PoRTIco Project,
    http://www.porticoproject.org (2016, accessed 6 May 2016). GO TO REFERENCE Google
    Scholar 17. Docker, Inc. Docker Hub. 11 July 2016. https://hub.docker.com. GO
    TO REFERENCE Google Scholar 18. Docker, Inc. Progrium, https://hub.docker.com/u/progrium
    (2013, accessed 11 July 2016). GO TO REFERENCE Google Scholar 19. Weaveworks.
    Weave, http://weave.works (2014, accessed 11 July 2016). Google Scholar 20. Cramp
    A, Fletcher D, van den Berg T. An introduction to using Docker in support of HLA
    federations. In: SimTecT, Australasian Simulation Congress Melbourne, Australia,
    26–29 September 2016. Adelaide, Australia: Simulation Australasia. GO TO REFERENCE
    Google Scholar 21. van den Berg T, Cramp A, Siegel B. Guidelines and best practices
    for using Docker in support of HLA federations. In: SISO Simulation Innovation
    Workshop (Fall 2016). Orlando, USA, 11–16 September 2016. Orlando, FL: SISO. GO
    TO REFERENCE Google Scholar 22. Evans CC. YAML 1.2, http://yaml.org (2016, accessed
    3 March 2016). GO TO REFERENCE Google Scholar 23. Felter Wet al. An updated performance
    comparison of virtual machines and Linux containers. July 2014. IBM Research Division.
    GO TO REFERENCE Google Scholar 24. Weaveworks. Weave networking performance with
    the new fast data path, http://www.weave.works/weave-docker-networking-performance-fast-data-path
    (2015, accessed 16 January 2016). GO TO REFERENCE Google Scholar Biographies Tom
    van den Berg is a senior scientist in the Modeling, Simulation and Gaming department
    at TNO, The Netherlands. He holds an MSc degree in Mathematics and Computing Science
    from Delft Technical University, and has over 25 years of experience in distributed
    operating systems, micro kernels, database systems, and distributed simulation
    systems. His research area includes simulation systems engineering, distributed
    simulation architectures, systems of systems, and concept development and experimentation.
    Barry Siegel is a senior scientist at the Space and Naval Warfare Systems Center
    – Pacific in San Diego, California. He is currently a PhD candidate in Systems
    Engineering at Colorado State University, and holds Masters degrees in Economics
    and Computer Science. He has conducted R&D in the areas of Command and Control,
    software engineering and architectures, web technologies, predictive analytics
    using “big data”, gaming, and anomaly detection algorithms. His current focus
    is the application of cluster-based computing to M&S in the military domain. Anthony
    Cramp is a Simulation Specialist with the Defence Science and Technology Group
    (DST Group), Australia. He joined the DST Group in 1999 working on the Virtual
    Maritime System Architecture, a HLA-based simulation framework for maritime C2
    centric experimentation, and received his PhD from the University of Adelaide
    in 2009 based on research into the construction of HLA simulations containing
    multiple systems of systems. In 2014, Anthony undertook a DST Group International
    Fellowship within the Modeling, Simulation and Gaming department of TNO Defence,
    Security and Safety, The Netherlands on topics including M&S as a Service and
    HLA performance. His research interests include distributed systems and simulations,
    software architectures, and programming languages. Related content Articles In
    the Same Collection(s): Collection: Editor''s Collection Free access Estimating
    Ricochet Hazard Zones at Sea Show details  Free access Estimating Ricochet Hazard
    Zones at Sea Show details  Free access Transforming systems engineering through
    digital engineering Show details  Similar articles: Available access Standards
    for Simulation: As Simple As Possible But Not Simpler The High Level Architecture
    For Simulation Show details  Available access Peer-to-Peer-Based Resource Management
    in Support of HLA-Based Distributed Simulations Show details  Open Access Ad hoc
    HLA simulation model derived from a model-based traffic scenario Show details        View
    more Sage recommends: SAGE Knowledge Entry Distributed Computing Show details
    SAGE Knowledge Book chapter Storing in the Cloud Show details SAGE Knowledge Entry
    File Transfer Protocol Show details View more Also from Sage CQ Library Elevating
    debate Sage Data Uncovering insight Sage Business Cases Shaping futures Sage Campus
    Unleashing potential Sage Knowledge Multimedia learning resources Sage Research
    Methods Supercharging research Sage Video Streaming knowledge Technology from
    Sage Library digital services About About Sage Journals Accessibility guide Historical
    content Advertising disclaimer Permissions Terms of use Sage discipline hubs Sage
    microsites Information for Authors Editors Librarians Promoters / Advertisers
    Researchers Reviewers Societies Frequently asked questions The Journal of Defense
    Modeling and Simulation ISSN: 1548-5129 Online ISSN: 1557-380X About SageContact
    usCCPA - Do not sell my personal informationCCPA Privacy Policy Copyright © 2024
    by The Society for Modeling and Simulation International We value your privacy
    We and our partners store and/or access information on a device, such as cookies
    and process personal data, such as unique identifiers and standard information
    sent by a device for personalised advertising and content, advertising and content
    measurement, audience research and services development. With your permission
    we and our partners may use precise geolocation data and identification through
    device scanning. You may click to consent to our and our 1438 partners’ processing
    as described above. Alternatively you may click to refuse to consent or access
    more detailed information and change your preferences before consenting. Please
    note that some processing of your personal data may not require your consent,
    but you have a right to object to such processing. Your preferences will apply
    to this website only. You can change your preferences or withdraw your consent
    at any time by returning to this site and clicking the "Privacy" button at the
    bottom of the webpage.'
  inline_citation: '>'
  journal: Journal of defense modeling and simulation
  limitations: '>'
  pdf_link: https://journals.sagepub.com/doi/pdf/10.1177/1548512916662365
  publication_year: 2016
  relevance_score1: 0
  relevance_score2: 0
  title: 'Containerization of high level architecture-based simulations: A case study'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1093/nar/gky379
  analysis: '>'
  authors:
  - Enis Afgan
  - Dannon Baker
  - Bérénice Batut
  - Marius van den Beek
  - Dave Bouvier
  - Martin Čech
  - John Chilton
  - D. L. Clements
  - Nate Coraor
  - Björn Grüning
  - Aysam Guerler
  - Jennifer Hillman-Jackson
  - Saskia Hiltemann
  - Vahid Jalili
  - Helena Rasche
  - Nicola Soranzo
  - Jeremy Goecks
  - James Taylor
  - Anton Nekrutenko
  - Daniel Blankenberg
  citation_count: 2938
  full_citation: '>'
  full_text: '>

    Advertisement Journals Books Issues Section browse More Content Submit Purchase
    About Nucleic Acids Research This issue NAR Journals                      Science
    and Mathematics Books Journals Oxford Academic                                   Advanced
    Search Volume 46 Issue W1 2 July 2018 Article Contents Abstract INTRODUCTION NEW
    FEATURES COMMUNITY ACKNOWLEDGEMENTS FUNDING REFERENCES Author notes Comments (0)
    < Previous Next > JOURNAL ARTICLE The Galaxy platform for accessible, reproducible
    and collaborative biomedical analyses: 2018 update Enis Afgan, Dannon Baker, Bérénice
    Batut, Marius van den Beek, Dave Bouvier, Martin Čech, John Chilton, Dave Clements,
    Nate Coraor, Björn A Grüning ... Show more Author Notes Nucleic Acids Research,
    Volume 46, Issue W1, 2 July 2018, Pages W537–W544, https://doi.org/10.1093/nar/gky379
    Published: 22 May 2018 Article history PDF Split View Cite Permissions Share Abstract
    Galaxy (homepage: https://galaxyproject.org, main public server: https://usegalaxy.org)
    is a web-based scientific analysis platform used by tens of thousands of scientists
    across the world to analyze large biomedical datasets such as those found in genomics,
    proteomics, metabolomics and imaging. Started in 2005, Galaxy continues to focus
    on three key challenges of data-driven biomedical science: making analyses accessible
    to all researchers, ensuring analyses are completely reproducible, and making
    it simple to communicate analyses so that they can be reused and extended. During
    the last two years, the Galaxy team and the open-source community around Galaxy
    have made substantial improvements to Galaxy''s core framework, user interface,
    tools, and training materials. Framework and user interface improvements now enable
    Galaxy to be used for analyzing tens of thousands of datasets, and >5500 tools
    are now available from the Galaxy ToolShed. The Galaxy community has led an effort
    to create numerous high-quality tutorials focused on common types of genomic analyses.
    The Galaxy developer and user communities continue to grow and be integral to
    Galaxy''s development. The number of Galaxy public servers, developers contributing
    to the Galaxy framework and its tools, and users of the main Galaxy server have
    all increased substantially. Issue Section: Web Server issue INTRODUCTION Advances
    in biomedicine and biology increasingly rely on analysis of large datasets. Started
    in 2005, the Galaxy Project (https://galaxyproject.org) (1–3) maintains a focus
    on enabling data-driven biomedical science by pursuing three goals: (a) accessible
    data analysis serving all scientists regardless of their informatics expertise
    and tool developers seeking a wider audience and broad integration of their tools;
    (b) reproducible analyses regardless of the particular platform and (c) transparent
    communication of analyses, which in turn enables reuse and extension of analyses
    across communities of practice. The Galaxy Project consists of four complementary
    components: The main public Galaxy server (https://usegalaxy.org)—this server
    is the subject of this article and has been online since 2007. It features a rich
    toolset for large-scale genomics analyses, terabytes of public data for use, and
    hundreds of shared analysis histories, workflows, and interactive publication
    supplements. This server has more than 124,000 registered users whom run ∼245,000
    analysis jobs each month. The Galaxy framework and software ecosystem (https://github.com/galaxyproject)—an
    open-source software package that anyone can use to run a Galaxy server on any
    Unix-based operating system. The Galaxy ecosystem includes a software development
    kit (SDK) for Galaxy tool development, API language bindings for multiple programming
    languages, software for scripting Galaxy interactions, and tools for automating
    setup and deployment of Galaxy and its plugins such as tools and visualizations.
    The Galaxy ToolShed (https://toolshed.g2.bx.psu.edu/)—a community-driven resource
    for the dissemination of Galaxy tools, workflows, and visualizations. This server
    functions as an ‘AppStore’ for Galaxy servers where developers and Galaxy admins
    can host, share, and install Galaxy tools, workflows and visualizations. The Galaxy
    Community (https://galaxyproject.org/community/)—distinct and complementary subcommunities
    make key contributions to all aspects of the Project. These subcommunities address
    the needs and desires of every category of stakeholder including users, administrators,
    developers, resource providers and educators. Galaxy has served hundreds of thousands
    of users, been used in >5700 scientific publications, and provided 500+ developers
    with a framework provisioning accessible, transparent, and reproducible data analysis
    (https://galaxyproject.org/galaxy-project/statistics/). Many instances of the
    framework have been installed, including Galaxy Main (https://usegalaxy.org) and
    over 99 publicly accessible servers (https://galaxyproject.org/public-galaxy-servers/),
    serving biomedical and other domain-specific research. Significant growth has
    occurred across all sectors of the Galaxy Project within the past two years (Figure
    1). Figure 1. Open in new tabDownload slide Circular barplot illustrating recent
    growth of the Galaxy Project across several independent facets. In the past two
    years, usage of the main public Galaxy server has increased 60%, the number of
    tools and supported versions has increased 53%, and the amount of data analyzed
    on the main server has increased 72%. A growing number of public instances (18%
    increase) and cloud-based Galaxy instances (38% increase) provide researchers
    with a wider range of options for scalability and application domains. Additionally,
    more developers (45% increase with 63% more commits to the codebase) contributed
    to the Galaxy framework and software ecosystem. Question and answer activity on
    the Galaxy Biostars forum increased 68%. NEW FEATURES Scalability Scalability
    is amongst the most significant challenges that Galaxy faces as the size and number
    of biomedical and especially genomics datasets continues to grow. For instance,
    single-cell RNA-seq experiments routinely generate hundreds or thousands of primary
    datasets. As a web-based application, Galaxy must scale both in its web-based
    interface and on its backend server and do so in a multiuser environment. User
    interface scalability enables scientists to use the Galaxy web interface to analyze
    many datasets, apply (collective) operations on them, and design pipelines to
    analyze them. Galaxy implements a variety of features to facilitate analyzing
    large numbers of datasets, including workflows and collections. Our recent optimizations
    of the user interface (UI) yielded a significant improvement to frontend scalability.
    We benchmarked the optimizations by replicating an experiment conducted on single
    Hematopoietic stem cells and multipotent progenitors (4) to quantify the expression
    of 64 000 transcripts, which generates 11 872 history items. Galaxy ran this proof
    of concept experiment seamlessly using existing standard tools, whereas earlier
    versions of Galaxy would not have been able to support this analysis. Server scalability
    refers to the Galaxy''s ability to execute many data analysis/manipulation tasks
    for many users. This is achieved by advantageously utilizing a range of available
    computing resources. The Galaxy framework runs on various platforms, from a standard
    laptop to institutional clusters and cloud-based platforms. Galaxy is highly versatile
    in its ability to deploy jobs (atomic units of work), as it can leverage a multitude
    of workload managers including Slurm (5), HTCondor (6), Apache Mesos (7) and Kubernetes
    (https://kubernetes.io), among others, in addition to a built-in lightweight job
    running system. Recent enhancements to Galaxy''s job management include dynamic
    job destination assignment (which facilitate automatic job parameter-specific
    resource selection), delay in job queuing (e.g. for workflows), automatic job
    re-submission (e.g., on job failure due to a temporary cluster error), and means
    of implementing fair-share prioritization schemes. These features are being used
    on Galaxy Main (Figure 2) to leverage cloud computing resources for better job
    throughput. Specifically, Galaxy Main is now configured to take advantage of the
    XSEDE infrastructure (8) that includes Bridges and Stampede resources as well
    as the Jetstream cloud (9). The benefits of using these resources include the
    ability to run larger jobs, as shown in Figure 3. Additionally, use of these resources
    has enabled new types of analysis to be enabled on Main. Notably, this includes
    Galaxy Interactive Environments through the ability to use containerization technologies
    and provide sufficient isolation of individual jobs from other processes running
    on the same underlying compute infrastructure. Figure 2. Open in new tabDownload
    slide Schematic of servers and services in use at Galaxy Main. (A) A global overview
    of Galaxy Main resources. When users interact with usegalaxy.org, their browser
    connects to one of two frontends (shown as web-01/02) with file uploads being
    handled by web-03/04; each of these web servers connects to a database server
    and mounts a set of shared distributed file systems. Web-03/04 also prepares and
    schedules jobs using Slurm directly to manage compute tasks on fifteen dedicated
    compute nodes, which also directly mount the shared distributed file systems.
    A combination of Slurm and Pulsar (https://github.com/galaxyproject/pulsar) are
    used to manage tasks and for dataset file staging, respectively, on the Jetstream
    cloud at Indiana University (IU) and the Texas Advanced Computing Center (TACC).
    Communication between Galaxy and Pulsar is handled using the RabbitMQ (https://www.rabbitmq.com/)
    message broker. Additional jobs are sent to the supercomputer systems Bridges
    at Pittsburgh Supercomputing Center (PSC) and Stampede at TACC using Pulsar. These
    various compute resources are chosen based upon tool and job characteristics.
    See, e.g. https://github.com/galaxyproject/usegalaxy-playbook/wiki/Infrastructure
    for specific and up-to-date information. (B) Multiple frontend servers provide
    Galaxy content to users by utilizing round-robin load balancing. Nginx (https://nginx.org/)
    is used to serve HTTP content from the Galaxy uWSGI web application. Individual
    software processes are monitored and controlled using Supervisor (http://supervisord.org/).
    Each of these frontend servers connects to a PostgreSQL (https://www.postgresql.org/)
    database server. (C) Layout of data schemes used by Galaxy Main is optimized for
    application speed, concurrent access, and versioned content. Each Galaxy frontend
    server utilizes a combination of shared distributed file systems, CVMFS for versioned
    semi-static content and TACC’s Corral filesystem via NFS for mutable content,
    along with server-specific local file systems. (D) CernVM File System (CVMFS)
    infrastructure hosted by the Galaxy Project that is used at Main and available
    for access to any other Galaxy instance. Stratum 0 contains the single-source
    modifiable data repositories. File content is served using the Apache HTTP server
    (https://httpd.apache.org/). To enable redundancy and scaling to a large number
    of clients, Stratum 1 replica servers are hosted at multiple locations and utilize
    Squid (http://www.squid-cache.org/) for data caching. Additional replica servers
    can also be hosted by community members. Individual clients (Galaxy instances
    and compute nodes) access data content from Stratum 1 servers using a Filesystem
    in Userspace (FUSE) mount. Figure 3. Open in new tabDownload slide Enabling automated
    selection and use of specialized national cyberinfrastructure compute resources
    from Galaxy Main enhances user-experience. It is now possible to run jobs that
    are up to an order of magnitude larger than before by using Bridges and Stampede.
    New types of jobs, such as interactive environments (see Advances in tools section),
    that require execution isolation due to security concerns are enabled by utilizing
    virtualization facilitated by the Jetstream cloud. Consequently, it is possible
    to concurrently run more jobs due to the increase in processing capacity. A complete
    Galaxy server with a full repertoire of tools and reference data can be run on
    major cloud platforms. These servers are launched independently by users, and
    come pre-configured with hundreds of tools and reasonable default settings typical
    of a production server. Notably, launched instances do not have usage quotas and
    can be customized to install any desired tool. We have designed a cloud-agnostic
    approach for leveraging these resources by developing the abstraction library
    CloudBridge (10) and a new CloudLaunch application. These two solutions make it
    possible to launch Galaxy instances across a variety of cloud providers while
    reducing the requirement to build and maintain cloud-specific resources (e.g.
    machine images, file systems). There are now 10 different flavors of Galaxy available
    for launching on major clouds including Amazon Web Services, Jetstream and Microsoft
    Azure (https://launch.usegalaxy.org). Advances in tools The Galaxy ToolShed (11)
    assumes the role of an AppStore for Galaxy instances by hosting thousands of tools.
    The ToolShed improves tool availability, deployment, and portability across Galaxy
    servers and computing environments. Updated tool suite Over the last two years,
    we have expanded both the quantity and quality of the tools available on the Galaxy
    ToolShed. As of April 2018, the ToolShed hosts 5628 tools, which shows 53% growth
    since 2016, and ∼2000 repositories had at least one new update. Examples of new
    tools include: GEMINI for exploring genetic variation (12); mothur for analyzing
    rRNA gene sequences (13); QIIME for quantitative microbiome analysis from raw
    DNA sequencing data (14); deepTools for explorative analysis of deeply sequence
    data (15,16); HiCexplorer (17) for analysis and visualization of Hi-C data; ChemicalToolBox
    for comprehensive access to cheminformatics libraries and drug discovery tools
    (18); minimap2 (https://arxiv.org/abs/1708.01492) and poretools for long read
    sequencing analysis (19); MultiQC (20) to aggregate multiple results into a single
    report; a new RNA-seq analysis tool suite with modern analysis tools such as Kallisto
    (21), Salmon (22), Deseq2 (23) and STAR-Fusion (24), and GenomeSpace (25), a cloud-based
    interoperability tool. Tool environment and interface The portability and backward-compatibility
    of the Galaxy tools environment is improved significantly. Accordingly, a tool
    configuration now includes a tool profile version, which is used to ensure compatibility
    between a version of a tool and its targeted Galaxy version. In addition, tool
    profile versions allow for the evolution of new and better tool defaults and behaviors
    while maintaining backwards compatibility. We also improved the ToolShed API and
    its interface to facilitate installing tools missing from an imported workflow.
    We improved the installation process so that restarting Galaxy is not required
    to use a newly installed tool. Interactive analysis and visualization Galaxy''s
    UI makes it possible for anyone to run complex analyses. However, a complete analysis
    of genomic data often requires custom scripts or visualizations, especially at
    the beginning (data preparation) or end (data summarization) of analyses. To meet
    these customized needs, we recently introduced Galaxy Interactive Environments
    (26), an integration of Galaxy with Jupyter (RStudio is in development)—a commonly
    used interactive scripting platform. With Interactive Environments, Galaxy users
    benefit from existing computational infrastructure via both graphical UI and ad
    hoc scripting, or any combination of these. Galaxy''s visualization framework
    (27) makes it possible to integrate a wide variety of Web-based and server-side
    visualizations. Through this framework, many new visualizations have been added
    to Galaxy, including Cytoscape (28), and the WebGL enabled 3D Protein viewer NGL
    (29), molecular interaction networks and macromolecular structures visualizations,
    and the 100+ visualizations available through BioJS (30), a rich set of community-driven
    JavaScript components for agile and interactive visualization of biological data.
    User interface and experience enhancements There are two common modes of data
    analysis: exploratory and pipeline execution. Galaxy enables simultaneous access
    to both of these. Users are able to interactively analyze their data by making
    use of individual tools in a trial-and-error manner. They are then able to automatically
    generate reusable and generalizable workflows from an ad hoc analysis. An interactive
    workflow editor is also available to modify or generate workflows from scratch.
    At any point in time, a user can seamlessly switch modes between interactively
    analyzing datasets and executing a workflow on these datasets. There is no analysis
    lock-in, and users can exercise full control, or make use of pre-existing pipelines.
    Importantly, these analysis artefacts, such as datasets, analysis histories, workflows,
    and visualizations can all be shared and copied by collaborators at the discretion
    of the analyst. Client-side infrastructure The client-side of Galaxy, which is
    the user-interface most people associate with Galaxy, has seen significant changes
    under the hood. The usage of server-side mako templates, for example to create
    forms, has been further reduced and replaced by client-side only code that communicates
    via the RESTful Galaxy API with the backend. This minimizes the number of full-page
    refreshes and improves response time by enabling partial page updates. The interface
    has been further enhanced to allow for drag-and-drop of files and datasets, presents
    a fuzzy search on dataset and tool metadata, and implements a modal scratchbook
    for visualizations and comparison of multiple datasets. Furthermore, the community
    has selected the Vue.js framework (https://vuejs.org/) as the base for future
    improvements allowing all UI elements to converge into a more reactive and future-proof
    interface. With the integration of Vue.js, the entire client-side build system
    was updated to utilize the latest web-technologies, to make routing and loading
    times faster, and to encourage rapid future interface improvements. While mostly
    transparent to users, these changes are the fundamental groundwork of a much more
    flexible UI framework that will enable visual enhancements and an improved user
    experience for years to come. Tags Although tags have been supported in Galaxy
    for several years, they have only recently become advantageous for large many-sample
    analyses. We have enhanced tags to allow propagation through dataset analysis
    steps. This facilitates tracking individual datasets through the entire analysis
    life-cycle and becomes part of the provenance system and ease-of-use of Galaxy.
    To enable automatic tag propagation, a hash-sign (#) is placed at the beginning
    of the tag, which is colloquially referred to as a named-tag. While standard Galaxy
    output dataset naming is suitable for many interactive analyses, the connection
    between inputs and outputs through large workflows becomes increasingly less obvious;
    by utilizing named-tags, users can label datasets with an identifier that is maintained
    throughout the analysis. Webhooks Inspired by user feedback and the need to quickly
    modify and adapt Galaxy''s interface, we integrated a pluggable system to extend
    Galaxy''s frontend. Webhooks provide an entry-point into the Galaxy UI, in which
    it is possible to add buttons, menu entries, or entire iframes. At these entry-points
    a developer can dynamically add client-side code (JavaScript, HTML, CSS) and interact
    with the rest of the Galaxy user-interface. By integrating Webhooks with the Galaxy
    API, it is also possible to trigger server-side functions from within a Webhook.
    Webhooks can be thoroughly customized and are enabled at the discretion of the
    Galaxy administrator. Interactive tours We have developed self-paced, interactive
    tours that users can step through to learn about Galaxy. These tours guide users
    step by step through using the interface including tools, workflows, and other
    features available in Galaxy. To simplify tour creation, a Tour Builder (https://github.com/TailorDev/galaxy-tourbuilder)
    has been created for recording, replaying, updating and exporting tours. Improved
    workflows Galaxy workflows have been extended in several ways. Switching between
    tool versions and upgrading workflows with new tool versions is now supported.
    A workflow can now be embedded in another, making it easier to create and edit
    workflows that have many common steps repeated. Many of these features have existed
    in in standalone workflow systems, such as Taverna (31), for sometime, but have
    been widely requested by Galaxy users. Workflows are now scheduled by a Galaxy
    server more efficiently and in the background, making it possible to execute larger
    workflows, generating tens of thousands of jobs, while providing instant feedback
    and a snappier user-experience. We have also enhanced Galaxy with initial support
    for running workflows defined in the Common Workflow Language (32) format. Dataset
    collections Galaxy Dataset Collections combine datasets to enable simultaneous
    analysis. They organize sets of datasets as potentially nested lists of objects
    allowing easier data handling and batch execution of tools. In addition to the
    related frontend improvements, and support of nesting collections together, we
    recently introduced specialized tools to be executed on collections (e.g. Collapse,
    which combines a list of datasets into a single dataset, Flatten which takes nested
    collections and produces a flat list of datasets, and Merge which takes two lists
    and creates a single unified list), and enabled uploading and downloading dataset
    collections to and from both user''s local disk and Galaxy data libraries. Infrastructure
    enhancements In order to make Galaxy more robust in a production environment,
    we adopted technologies to enhance Galaxy''s portability, security, reliability,
    and scalability. Galaxy now utilizes uWSGI (http://projects.unbit.it/uwsgi) as
    its default web application server. This adoption has several advantages, namely
    the ability to negate Python''s limitations regarding concurrent tasks execution,
    built-in load balancing, scalability, improved fault tolerance and the possibility
    of restarting Galaxy uninterruptedly. Many tools available via Galaxy rely on
    the availability of reference and index data. To promote ease of use and efficient
    storage and compute resources, Galaxy is able to share a precomputed set of local
    reference data for tools to use. Previously, making this data available to the
    tools was a time intensive process where a Galaxy administrator had to install
    and properly configure the server, either manually or by using Data Managers (33).
    However, this resulted in much redundant effort required for each Galaxy server
    being configured. To streamline this process, we have made all the reference data
    we prepared for Galaxy Main available via a CernVM File System (CVMFS; (34)),
    a scalable and content-addressable file system. This repository currently hosts
    5TB of pre-build reference data, which are versioned and shared publicly with
    read-only access. With minimal configuration, any instance of Galaxy, including
    Galaxy-Docker images, can attach to this file system and gain access to the same
    reference data available on Galaxy Main. To improve accessibility and fault-tolerance,
    this data source is replicated on servers located in Europe and Australia. Galaxy
    is powered by various open-source projects which are installed automatically,
    and used when needed. Galaxy is using the Conda package manager (https://conda.io)
    as its default tool dependency resolver, and offers support for virtualization
    and containerization technologies (e.g. Docker (https://www.docker.com) and Singularity
    (35)) to ensure a higher level of portability, if needed. By leveraging the Bioconda
    (https://doi.org/10.1101/207092) and the BioContainer (36) projects, Galaxy is
    able to provision and use reproducible tool execution environments ((37); https://doi.org/10.1101/200683).
    Galaxy is a generic data analysis framework, which can be configured for various
    application scenarios using a wide range of configuration parameters. To facilitate
    configuring these parameters with optimal values for a number of predefined application
    scenarios, the Galaxy project leverages Ansible (https://www.ansible.com), software
    for automated configuration and management of other software packages. We have
    developed and shared Ansible configurations for Galaxy Main, the main public Galaxy
    server, (https://github.com/galaxyproject/usegalaxy-playbook) and also a configurable
    generic playbook for setting up production instances on cloud resources, virtual
    machines, and bare metal (https://github.com/ARTbio/GalaxyKickStart). This playbook
    can be used as a reference for configuring a Galaxy instance for a production
    environment. The Galaxy-Docker project (https://github.com/bgruening/docker-galaxy-stable),
    delivers a production ready Galaxy instance in minutes and can be used as the
    basis for personalized, self-contained, portable instances of Galaxy, known as
    Galaxy flavors. Preconfigured by the Galaxy community, a plenitude of flavors
    already exist covering application scenarios, from BLAST+ (38,39), metagenomics
    (https://doi.org/10.1101/183970), ChIP-exo analysis, or RNA research (40). In
    addition to the facilitated and out-of-box functionality, these images provision
    isolated environments well-suited for experimenting with tools and Galaxy configurations,
    and are ideal for training courses, as demonstrated by the Galaxy Training Network.
    Server monitoring and issue management is crucial in production Galaxy instances.
    Galaxy has integrated a plugin module to submit user bug-reports to configurable
    endpoints such as mailing lists or GitHub issues. With this, Galaxy can be configured
    to send error reports to a local ticket system. The recent integration of Sentry
    (https://sentry.io/) for automated error tracking and reporting makes it easier
    for administrators to track both client- and server-side errors without requiring
    manual user bug reports. COMMUNITY Galaxy serves several distinct communities:
    researchers, tool developers, resource providers, trainers, and trainees. To centralize
    resources for all communities, we have developed the Galaxy Community Hub (https://galaxyproject.org)
    for all things Galaxy. The Hub uses a modified wiki approach, with content written
    in Markdown, a simple formatting language, and then built into a static website.
    Anyone can update the Markdown documents using GitHub pull requests, a standard
    approach for collaborating on code and documentation on GitHub projects. Submitted
    pull requests are reviewed and merged, and the Hub site is automatically regenerated
    and updated, resulting in high-quality reviewed content that can be updated by
    any member of the Galaxy community. The Hub includes a full list of public Galaxy
    servers (https://galaxyproject.org/public-galaxy-servers), a large set of tutorials
    for learning to use Galaxy and perform genomic analyses, extensive documentation
    on deploying and administering a Galaxy server in the Cloud or on local hardware,
    and upcoming events. We also maintain an annotated listing of the >5000 publications
    referencing Galaxy via the free and open-source Zotero service (https://www.zotero.org/groups/1732893/galaxy).
    The Main Galaxy server has over 124 000 registered users and ∼2000 new users register
    each month. On average, 20 000 unique users execute over 245 000 analysis jobs
    by accessing 750 different tools every month. With such an active user-base, questions
    on platform and tool usage, as well as general research questions (41), are common.
    To efficiently assist users in performing research, we provide a Biostars (42)
    Question and Answers forum (https://biostar.usegalaxy.org/) that leverages the
    knowledge and strength of community members to provide support. This forum is
    monitored and moderated by core team members, but the Galaxy user community provides
    many answers. Help is also available through live chat with the team and community
    members via Gitter and IRC chat services, which are used most often by developers
    and administrators. In addition to the online help and documentation, the Galaxy
    Training Network has developed comprehensive tutorials and workflows for performing
    common data analysis tasks, providing topic-specific introduction slides, hands-on
    material, sample data, and even playable Galaxy tours (https://doi.org/10.1101/225680).
    Many in-person events that highlight and build the Galaxy community occur each
    year (https://galaxyproject.org/events/). These include free or low-cost hands-on
    workshops and training sessions that have been hosted by the community on six
    continents. The Galaxy Community Conference (GCC) is an annual conference that
    was first held in 2010. GCC alternates between Europe and the United States, includes
    two full days of training, two days of coding and data analysis hackathons, and
    two days of oral and poster presentations. Galaxy conferences have had over two
    hundred attendees each year since 2012, and over eleven hundred different researchers
    have attended since 2010. Our 2018 conference will be hosted jointly with the
    Bioinformatics Open Source Conference (BOSC) in an effort to promote and centralize
    discussion of open-source software for bioinformatics. Another core area of community
    focus is tool development and availability. The Intergalactic Utilities Commission
    (IUC; https://galaxyproject.org/iuc/) is a community-based organization that defines
    best-practices for tool development that help ensure the availability of high-quality
    tools in the ToolShed. It is a self-organizing and self-regulating group that
    has grown by six new members in the last two years and is primarily composed of
    individuals outside of the core Galaxy development team. The IUC is only one of
    many tool contributors, with the ToolShed allowing any member of the community
    to share tools that they have added to Galaxy. To assist community members with
    tool development and distribution, a command-line tool named Planemo (https://github.com/galaxyproject/planemo)
    has been developed. Planemo provides functionality for verifying best-practice
    adherence, testing, installation and uploading of tools to the ToolShed. Community
    contributions have helped the Galaxy framework and its tool suite to grow considerably.
    One hundred and seventy-four developers, who have collectively produced 13 135
    commits within just the past two years (63% increase since January 2016), have
    improved Galaxy''s scalability, functionality, and usability. The project utilizes
    the Travis and Jenkins continuous integration (CI) services to automatically execute
    comprehensive test suites on each set of proposed code changes. This strategy
    helps prevent the introduction of bugs to the codebase and improves review time.
    By harnessing the open-source community and modern software development practices,
    we are able to release a new stable version of the Galaxy framework every four
    months. Current future directions include enabling data and compute federation;
    tighter coupling of Interactive Environments with provenance and reuse; ToolShed
    installation and development enhancements; continued work on collections, workflows,
    analysis interfaces and history views; additional training material; improving
    statistical usage tracking and instrumentation; and much more. For anyone interested
    in getting involved with Galaxy development, we invite them to read the project''s
    Contributing and Code of Conduct documents, review open issues, and explore the
    current roadmap, all which are available from the Galaxy GitHub repository (https://github.com/galaxyproject/galaxy/).
    ACKNOWLEDGEMENTS The Galaxy Project has grown in large part thanks to the contributions
    of time and effort by numerous individuals over the years. Contributing individuals
    include members of the Galaxy user, developer and administrative communities and
    organizers of Galaxy Community Conferences. We are indebted to these helpful people.
    The Public Galaxy site is located at the Texas Advanced Computing Center (TACC
    at the University of Texas). We are extremely grateful to both TACC and CyVerse
    for enabling Galaxy to serve thousands of researchers worldwide. FUNDING National
    Human Genome Research Institute, National Institutes of Health [HG006620, HG005133,
    HG004909 and HG005542]; NSF [DBI 0543285, 0850103 and 1661497]; Huck Institutes
    for the Life Sciences at Penn State; and, in part, under a grant with the Pennsylvania
    Department of Health using Tobacco Settlement Funds, the Department specifically
    disclaims responsibility for any analyses, interpretations or conclusions. Funding
    for open access charge: Cleveland Clinic. Conflict of interest statement. None
    declared. REFERENCES 1. Giardine B., Riemer C., Hardison R.C., Burhans R., Elnitski
    L., Shah P., Zhang Y., Blankenberg D., Albert I., Taylor J.et al.  Galaxy: a platform
    for interactive large-scale genome analysis. Genome Res. 2005; 15:1451–1455. Google
    Scholar CrossrefPubMed WorldCat   2. Blankenberg D., Taylor J., Schenck I., He
    J., Zhang Y., Ghent M., Veeraraghavan N., Albert I., Miller W., Makova K.D.et
    al.  A framework for collaborative analysis of ENCODE data: making large-scale
    analyses biologist-friendly. Genome Res. 2007; 17:960–964. Google Scholar CrossrefPubMed
    WorldCat   3. Afgan E., Baker D., van den Beek M., Blankenberg D., Bouvier D.,
    Čech M., Chilton J., Clements D., Coraor N., Eberhard C.et al.  The Galaxy platform
    for accessible, reproducible and collaborative biomedical analyses: 2016 update.
    Nucleic Acids Res. 2016; 44:W3–W10. Google Scholar CrossrefPubMed WorldCat   4.
    Yang J., Tanaka Y., Seay M., Li Z., Jin J., Garmire L.X., Zhu X., Taylor A., Li
    W., Euskirchen G.et al.  Single cell transcriptomics reveals unanticipated features
    of early hematopoietic precursors. Nucleic Acids Res. 2017; 45:1281–1296. Google
    Scholar PubMed WorldCat   5. Yoo A.B., Jette M.A., Grondona M. SLURM: Simple Linux
    Utility for Resource Management. Job Scheduling Strategies for Parallel Processing,
    Lecture Notes in Computer Science. 2003; Berlin, HeidelbergSpringer44–60. Google
    Scholar Crossref Google Preview WorldCat COPAC  6. Thain D., Tannenbaum T., Livny
    M. Distributed computing in practice: the Condor experience. Concurr. Comput.
    2005; 17:323–356. Google Scholar Crossref WorldCat   7. Hindman B., Konwinski
    A., Zaharia M., Ghodsi A., Joseph A.D., Katz R., Shenker S., Stoica I. Mesos:
    A Platform for Fine-grained Resource Sharing in the Data Center. Proceedings of
    the 8th USENIX Conference on Networked Systems Design and Implementation. 2011;
    BerkeleyUSENIX Association295–308.NSDI’11. Google Scholar Google Preview WorldCat
    COPAC  8. Towns J., Cockerill T., Dahan M., Foster I., Gaither K., Grimshaw A.,
    Hazlewood V., Lathrop S., Lifka D., Peterson G.D.et al.  XSEDE: accelerating scientific
    discovery. Comput. Sci. Eng. 2014; 16:62–74. Google Scholar Crossref WorldCat   9.
    Stewart C.A., Cockerill T.M., Foster I., Hancock D., Merchant N., Skidmore E.,
    Stanzione D., Taylor J., Tuecke S., Turner G.et al.  Jetstream: a self-provisioned,
    scalable science and engineering cloud environment. Proceedings of the 2015 XSEDE
    Conference: Scientific Advancements Enabled by Enhanced Cyberinfrastructure. 2015;
    NYACM29XSEDE ’15. Google Scholar Google Preview WorldCat COPAC  10. Goonasekera
    N., Lonie A., Taylor J., Afgan E. CloudBridge: a Simple Cross-Cloud Python Library.
    Proceedings of the XSEDE16 Conference on Diversity, Big Data, and Science at Scale.
    2016; MiamiACM37. Google Scholar Google Preview WorldCat COPAC  11. Blankenberg
    D., Von Kuster G., Bouvier E., Baker D., Afgan E., Stoler N., Taylor J., Nekrutenko
    A.Galaxy Team Dissemination of scientific software with Galaxy ToolShed. Genome
    Biol. 2014; 15:403. Google Scholar CrossrefPubMed WorldCat   12. Paila U., Chapman
    B.A., Kirchner R., Quinlan A.R. GEMINI: integrative exploration of genetic variation
    and genome annotations. PLoS Comput. Biol. 2013; 9:e1003153. Google Scholar CrossrefPubMed
    WorldCat   13. Schloss P.D., Westcott S.L., Ryabin T., Hall J.R., Hartmann M.,
    Hollister E.B., Lesniewski R.A., Oakley B.B., Parks D.H., Robinson C.J.et al.  Introducing
    mothur: open-source, platform-independent, community-supported software for describing
    and comparing microbial communities. Appl. Environ. Microbiol. 2009; 75:7537–7541.
    Google Scholar CrossrefPubMed WorldCat   14. Caporaso J.G., Kuczynski J., Stombaugh
    J., Bittinger K., Bushman F.D., Costello E.K., Fierer N., Peña A.G., Goodrich
    J.K., Gordon J.I.et al.  QIIME allows analysis of high-throughput community sequencing
    data. Nat. Methods. 2010; 7:335–336. Google Scholar CrossrefPubMed WorldCat   15.
    Ramírez F., Dündar F., Diehl S., Grüning B.A., Manke T. deepTools: a flexible
    platform for exploring deep-sequencing data. Nucleic Acids Res. 2014; 42:W187–W191.
    Google Scholar CrossrefPubMed WorldCat   16. Ramírez F., Ryan D.P., Grüning B.,
    Bhardwaj V., Kilpert F., Richter A.S., Heyne S., Dündar F., Manke T. deepTools2:
    a next generation web server for deep-sequencing data analysis. Nucleic Acids
    Res. 2016; 44:W160–W165. Google Scholar CrossrefPubMed WorldCat   17. Ramírez
    F., Bhardwaj V., Arrigoni L., Lam K.C., Grüning B.A., Villaveces J., Habermann
    B., Akhtar A., Manke T. High-resolution TADs reveal DNA sequences underlying genome
    organization in flies. Nat. Commun. 2018; 9:189. Google Scholar CrossrefPubMed
    WorldCat   18. Lucas X., Grüning B.A., Günther S. ChemicalToolBoX and its application
    on the study of the drug like and purchasable space. J. Cheminform. 2014; 6:P51.
    Google Scholar Crossref WorldCat   19. Loman N.J., Quinlan A.R. Poretools: a toolkit
    for analyzing nanopore sequence data. Bioinformatics. 2014; 30:3399–3401. Google
    Scholar CrossrefPubMed WorldCat   20. Ewels P., Magnusson M., Lundin S., Käller
    M. MultiQC: summarize analysis results for multiple tools and samples in a single
    report. Bioinformatics. 2016; 32:3047–3048. Google Scholar CrossrefPubMed WorldCat   21.
    Bray N.L., Pimentel H., Melsted P., Pachter L. Near-optimal probabilistic RNA-seq
    quantification. Nat. Biotechnol. 2016; 34:525–527. Google Scholar CrossrefPubMed
    WorldCat   22. Patro R., Duggal G., Love M.I., Irizarry R.A., Kingsford C. Salmon
    provides fast and bias-aware quantification of transcript expression. Nat. Methods.
    2017; 14:417–419. Google Scholar CrossrefPubMed WorldCat   23. Love M.I., Huber
    W., Anders S. Moderated estimation of fold change and dispersion for RNA-seq data
    with DESeq2. Genome Biol. 2014; 15:550. Google Scholar CrossrefPubMed WorldCat   24.
    Dobin A., Davis C.A., Schlesinger F., Drenkow J., Zaleski C., Jha S., Batut P.,
    Chaisson M., Gingeras T.R. STAR: ultrafast universal RNA-seq aligner. Bioinformatics.
    2013; 29:15–21. Google Scholar CrossrefPubMed WorldCat   25. Qu K., Garamszegi
    S., Wu F., Thorvaldsdottir H., Liefeld T., Ocana M., Borges-Rivera D., Pochet
    N., Robinson J.T., Demchak B.et al.  Integrative genomic analysis by interoperation
    of bioinformatics tools in GenomeSpace. Nat. Methods. 2016; 13:245–247. Google
    Scholar CrossrefPubMed WorldCat   26. Grüning B.A., Rasche E., Rebolledo-Jaramillo
    B., Eberhard C., Houwaart T., Chilton J., Coraor N., Backofen R., Taylor J., Nekrutenko
    A. Jupyter and Galaxy: easing entry barriers into complex data analyses for biomedical
    researchers. PLoS Comput. Biol. 2017; 13:e1005425. Google Scholar CrossrefPubMed
    WorldCat   27. Goecks J., Eberhard C., Too T., Nekrutenko A., Taylor J.Galaxy
    Team Web-based visual analysis for high-throughput genomics. BMC Genomics. 2013;
    14:397. Google Scholar CrossrefPubMed WorldCat   28. Shannon P., Markiel A., Ozier
    O., Baliga N.S., Wang J.T., Ramage D., Amin N., Schwikowski B., Ideker T. Cytoscape:
    a software environment for integrated models of biomolecular interaction networks.
    Genome Res. 2003; 13:2498–2504. Google Scholar CrossrefPubMed WorldCat   29. Rose
    A.S., Hildebrand P.W. NGL Viewer: a web application for molecular visualization.
    Nucleic Acids Res. 2015; 43:W576–W579. Google Scholar CrossrefPubMed WorldCat   30.
    Gómez J., García L.J., Salazar G.A., Villaveces J., Gore S., García A., Martín
    M.J., Launay G., Alcántara R., Del-Toro N.et al.  BioJS: an open source JavaScript
    framework for biological data visualization. Bioinformatics. 2013; 29:1103–1104.
    Google Scholar CrossrefPubMed WorldCat   31. Wolstencroft K., Haines R., Fellows
    D., Williams A., Withers D., Owen S., Soiland-Reyes S., Dunlop I., Nenadic A.,
    Fisher P.et al.  The Taverna workflow suite: designing and executing workflows
    of Web Services on the desktop, web or in the cloud. Nucleic Acids Res. 2013;
    41:W557–W561. Google Scholar CrossrefPubMed WorldCat   32. Amstutz P., Crusoe
    M.R., Tijanić N., Chapman B., Chilton J., Heuer M., Kartashov A., Leehr D., Ménager
    H., Nedeljkovich M.et al.  Common Workflow Language, v1.0. figshare. 2016; https://doi.org/10.6084/m9.figshare.3115156.v2.
    Google Scholar WorldCat   33. Blankenberg D., Johnson J.E., Taylor J., Nekrutenko
    A.Galaxy Team Wrangling Galaxy''s reference data. Bioinformatics. 2014; 30:1917–1919.
    Google Scholar CrossrefPubMed WorldCat   34. Blomer J., Buncic P., Charalampidis
    I., Harutyunyan A., Larsen and D., Meusel R. Status and future perspectives of
    CernVM-FS. J. Phys. Conf. Ser. 2012; 396:052013. Google Scholar Crossref WorldCat   35.
    Kurtzer G.M., Sochat V., Bauer M.W. Singularity: Scientific containers for mobility
    of compute. PLoS One. 2017; 12:e0177459. Google Scholar CrossrefPubMed WorldCat   36.
    da Veiga Leprevost F., Grüning B.A., Alves Aflitos S., Röst H.L., Uszkoreit J.,
    Barsnes H., Vaudel M., Moreno P., Gatto L., Weber J.et al.  BioContainers: an
    open-source and community-driven framework for software standardization. Bioinformatics.
    2017; 33:2580–2582. Google Scholar CrossrefPubMed WorldCat   37. Nekrutenko A.,
    Goecks J., Taylor J., Blankenberg D.Galaxy Team Biology needs evolutionary software
    tools: Let''s build them right. Mol. Biol. Evol. 2018; https://doi.org/10.1093/molbev/msy084.
    Google Scholar WorldCat   38. Cock P.J.A., Chilton J.M., Grüning B., Johnson J.E.,
    Soranzo N. NCBI BLAST+ integrated into Galaxy. Gigascience. 2015; 4:39. Google
    Scholar CrossrefPubMed WorldCat   39. Camacho C., Coulouris G., Avagyan V., Ma
    N., Papadopoulos J., Bealer K., Madden T.L. BLAST+: architecture and applications.
    BMC Bioinformatics. 2009; 10:421. Google Scholar CrossrefPubMed WorldCat   40.
    Grüning B.A., Fallmann J., Yusuf D., Will S., Erxleben A., Eggenhofer F., Houwaart
    T., Batut B., Videm P., Bagnacani A.et al.  The RNA workbench: best practices
    for RNA and high-throughput sequencing bioinformatics in Galaxy. Nucleic Acids
    Res. 2017; 45:W560–W566. Google Scholar CrossrefPubMed WorldCat   41. Blankenberg
    D., Taylor J., Nekrutenko A. Online resources for genomic analysis using high-throughput
    sequencing. Cold Spring Harb. Protoc. 2015; 2015:324–335. Google Scholar CrossrefPubMed
    WorldCat   42. Parnell L.D., Lindenbaum P., Shameer K., Dall’Olio G.M., Swan D.C.,
    Jensen L.J., Cockell S.J., Pedersen B.S., Mangan M.E., Miller C.A.et al.  BioStar:
    an online question & answer resource for the bioinformatics community. PLoS Comput.
    Biol. 2011; 7:e1002216. Google Scholar CrossrefPubMed WorldCat   Author notes
    The authors wish it to be known that, in their opinion, all authors should be
    regarded as Joint First Authors. © The Author(s) 2018. Published by Oxford University
    Press on behalf of Nucleic Acids Research. This is an Open Access article distributed
    under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/4.0/),
    which permits unrestricted reuse, distribution, and reproduction in any medium,
    provided the original work is properly cited. Comments 0 Comments Add comment
    Advertisement CITATIONS 3k VIEWS 31,738 ALTMETRIC More metrics information Email
    alerts Article activity alert Advance article alerts New issue alert Subject alert
    Receive exclusive offers and updates from Oxford Academic Recommended The Galaxy
    platform for accessible, reproducible and collaborative biomedical analyses: 2020
    update Vahid Jalili et al., Nucleic Acids Research, 2020 Expanding the Galaxy’s
    reference data Nagampalli VijayKrishna et al., Bioinformatics Advances, 2022 The
    Galaxy platform for accessible, reproducible and collaborative biomedical analyses:
    2016 update Enis Afgan et al., Nucleic Acids Research, 2016 Applying FAIR Principles
    to Plant Phenotypic Data Management in GnpIS C. Pommier et al., Plant Phenomics,
    2019 SDCBench: A Benchmark Suite for Workload Colocation and Evaluation in Datacenters
    Yanan Yang et al., Intelligent Computing, 2022 Earth Map: A Novel Tool for Fast
    Performance of Advanced Land Monitoring and Climate Assessment Carmen Morales
    et al., Journal of Remote Sensing, 2023 Powered by Citing articles via Web of
    Science (2188) Google Scholar Latest Most Read Most Cited NetActivity enhances
    transcriptional signals by combining gene expression into robust gene set activity
    scores through interpretable autoencoders Definition of the binding specificity
    of the T7 bacteriophage primase by analysis of a protein binding microarray using
    a thermodynamic model KDM5-mediated transcriptional activation of ribosomal protein
    genes alters translation efficiency to regulate mitochondrial metabolism in neurons
    Ordered and disordered regions of the Origin Recognition Complex direct differential
    in vivo binding at distinct motif sequences The EMBL-EBI Job Dispatcher sequence
    analysis tools framework in 2024 More from Oxford Academic Science and Mathematics
    Books Journals About Nucleic Acids Research Editorial Board Policies Author Guidelines
    Facebook Twitter LinkedIn Advertising and Corporate Services Journals Career Network
    Online ISSN 1362-4962 Print ISSN 0305-1048 Copyright © 2024 Oxford University
    Press About Oxford Academic Publish journals with us University press partners
    What we publish New features  Authoring Open access Purchasing Institutional account
    management Rights and permissions Get help with access Accessibility Contact us
    Advertising Media enquiries Oxford University Press News Oxford Languages University
    of Oxford Oxford University Press is a department of the University of Oxford.
    It furthers the University''s objective of excellence in research, scholarship,
    and education by publishing worldwide Copyright © 2024 Oxford University Press
    Cookie settings Cookie policy Privacy policy Legal notice Oxford University Press
    uses cookies to enhance your experience on our website. By selecting ‘accept all’
    you are agreeing to our use of cookies. You can change your cookie settings at
    any time. More information can be found in our Cookie Policy. Cookie settings
    Accept all'
  inline_citation: '>'
  journal: Nucleic acids research
  limitations: '>'
  pdf_link: https://academic.oup.com/nar/article-pdf/46/W1/W537/25110642/gky379.pdf
  publication_year: 2018
  relevance_score1: 0
  relevance_score2: 0
  title: 'The Galaxy platform for accessible, reproducible and collaborative biomedical
    analyses: 2018 update'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.23919/indiacom54597.2022.9763171
  analysis: '>'
  authors:
  - Anshita Malviya
  - Rajendra Kumar Dwivedi
  citation_count: 9
  full_citation: '>'
  full_text: '>

    IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account
    Personal Sign In Browse My Settings Help Access provided by: University of Nebraska
    - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards
    Authors Citations ADVANCED SEARCH Conferences >2022 9th International Confer...
    A Comparative Analysis of Container Orchestration Tools in Cloud Computing Publisher:
    IEEE Cite This PDF Anshita Malviya; Rajendra Kumar Dwivedi All Authors 10 Cites
    in Papers 1306 Full Text Views Abstract Document Sections I. Introduction II.
    Cloud Computing III. Container Orchestration Tools in Cloud Computing IV. Comparative
    Analysis of Orchestration Tools V. Conclusion and Future Scope Authors Figures
    References Citations Keywords Metrics Abstract: Cloud Computing is an emerging
    technology that is used not only by developers but also by end-users. It has vital
    importance in the Information Technology (IT) industries as its future would create
    a great transition from conventional IT services. These days, containerization
    in cloud computing has become an important research area. The selection of container
    orchestration tools is one of the difficult tasks for the organizations involved
    in the management of the vast number of containers. These tools have their strengths,
    weaknesses, and functionalities which need to be considered. This paper presents
    a comparative analysis of the container orchestration tools. This analysis would
    help the professionals to decide whether they need an orchestrator bound to a
    single technology or an orchestrator which provides the independent solution.
    In this paper, four popular orchestration tools viz., Kubernetes, Docker Swarm,
    Mesos, and Redhat OpenShift are analyzed on various parameters viz., security,
    deployment, stability, scalability, cluster installation, and learning curve.
    We observed that Kubernetes has the best scheduling features whereas Docker Swarm
    is easy to use. We also found that Mesos has good scalability whereas OpenShift
    is a highly secure orchestration tool. Published in: 2022 9th International Conference
    on Computing for Sustainable Global Development (INDIACom) Date of Conference:
    23-25 March 2022 Date Added to IEEE Xplore: 02 May 2022 ISBN Information: DOI:
    10.23919/INDIACom54597.2022.9763171 Publisher: IEEE Conference Location: New Delhi,
    India SECTION I. Introduction The application software and the resources that
    run on the Internet in spite of running locally on our computers constitute the
    cloud. The evolution of cloud computing took place from bundled software to resources
    and from consistent uses to dynamic clients [1]. Cloud computing facilitates the
    handling, arranging, and retrieving the hardware and software resources over the
    Internet. Creating, arranging, and personalizing the applications online are also
    allowed by it [1]. There is no need to install the software locally on our computer
    which means platform independence is also offered by cloud computing. Deployment
    and service models make cloud computing viable and approachable. The type of access
    to the cloud is defined by the deployment models which are public, private, hybrid,
    and community. There are different service models on which cloud computing is
    based which are infrastructure-as-a-service (IaaS), Platform-as-a-service (PaaS),
    Software-as-a-Service (SaaS), Container-as-a-Service (CaaS) [1]. Online construction
    and deployment tools are offered by cloud computing. It is cost-effective and
    operates at high reliability, efficiency, and flexibility. If we want to use some
    external services, cloud computing acts as a trading subscription that is based
    on a pay-per-use model [2] [3]. These days, we have noticed that there is enormous
    use and popularity of cloud computing which is supported by container technology
    [4]. In cloud computing, containerization helps in the management of applications
    by virtualizing them in a lightweight manner. In this paper, four popular orchestration
    tools viz., Kubernetes, Docker Swarm, Mesos, and Redhat OpenShift are analyzed
    on various parameters like security, deployment, stability, scalability etc. The
    rest of the paper is organized as follows: The background of cloud computing is
    explained in Section II; Section III describes container orchestration and its
    platform; Section IV provides the analysis of orchestration tools; and Section
    V concludes the paper. SECTION II. Cloud Computing This section describes the
    background and importance of cloud computing and its different service models.
    At present time, cloud computing facilitates data accessing and storing in fast
    and efficient manner. Now, we can access our data online in comparison to accessing
    the data through local drives. Images, audios, documents, files, videos, etc constitute
    the term data. When people were unaware of the cloud computing technology, then
    the client-server architecture was used. At that time, if a user wanted to access
    their data, firstly that user had to connect to the server, and then only they
    could get their data. Then, the concept of distributed computing came which solved
    the above issue. This computing involves networking of all the computers and shared
    access of resources to the users when needed. But, distributed computing also
    involves some limitations. Then, cloud computing came into existence which solved
    all the problems and limitations making data access and backup easier. It helps
    us to quickly and easily store information at any time and any place. Data accessing
    via mobile also became possible because of it. Cloud computing helps in the reduction
    of software and hardware price. The basic types of service models of cloud computing
    are Infrastructure as a Service (IaaS), Platform as a Service (PaaS), and Software
    as a Service (SaaS) [5]. Managing infrastructure over the internet, reducing cost,
    and avoiding the complexity in buying physical services are provided by the IaaS
    service model. PaaS provides computing platforms to the developers so that they
    could develop, run, test, and manage their software. Applications are provided
    to the users on their demand by cloud service providers with the help of the SaaS
    model. Containers, Serverless, Microservices, Internet of Things, and Artificial
    Intelligence are the emerging technologies that can be associated with cloud computing.
    Transforming industries with these latest technologies is possible because of
    the revolution brought by cloud computing. The world of computing is changing
    with the help of these technologies. SECTION III. Container Orchestration Tools
    in Cloud Computing In cloud computing, virtualization of the operating system
    is done by an approach known as Container. The deployment and management of software
    can be achieved with the help of containers. It runs the software applications
    in a remote environment by packing all the application''s dependencies. The applications
    which are containerized can easily be drifted towards the cloud. The APIs given
    by the orchestration can be used to deploy, modify or clone the container easily
    and efficiently. Microservices, modernization of applications, DevOps, hybrid,
    and multi-cloud are some of the use cases favorable for accessing containers in
    the cloud [6], [7]. In this section, container orchestration and some of its tools
    are discussed on basis of their features, architecture, advantages, and disadvantages.
    Nowadays, several industries have adopted the concept of containers rather than
    virtual machines because of their lightweight, portability, and agility to handle
    virtualization [8]–[10]. Containers can be divided into four categories, that
    is, System container, Application container, Container manager, and Orchestrator
    [11]. Kubernetes, Docker Swarm, Marathon, and Cloudify are some of the orchestrators.
    LXC, OpenVZ, WHC are examples of System containers, and Docker, LXC, WSC are examples
    of the application container. Container manager is further divided into On-premise
    and managed. Docker, LXD, OpenVZ, rkt are applications of On-premise and ECS,
    GCE, ACS come under Managed container manager. Container orchestration refers
    to the accounting, deployment, and supervision of software applications that are
    containerized [12]. It is also used for the administration of the lifecycle of
    containers shown in Figure 1. Fig. 1. Lifecycle of container Show All Acquire,
    Build, Deliver, Run, and Maintain are the elements that constitute a container''s
    lifecycle. Kubernetes, Docker Swarm, Apache Mesos, RedHat, and OpenShift are some
    of the orchestration tools. Among these the most widely used orchestration platform
    in the IT industry is Kubernetes. Container orchestration is used by IT industries
    for container scaling, moving containers from one host to other in case of the
    dearth of resources in a particular host, allocating resources among containers,
    load balancing of services among containers, and many more. Deploying and managing
    hundreds of containers is a very tedious job, that is why container orchestration
    came into the picture. It reduces the complexity of the development of software
    applications. Simplified operations, resilience, and security are some of the
    major benefits of container orchestration. Fig. 2. Architecture of kubernetes
    Show All A. Kubernetes It is an open-source orchestration tool of containers developed
    by Google in 2008. In 2015, this tool was given by Google to Cloud Native Computing
    Foundation. Declarative automation and configuration are supported by Kubernetes.
    At present, it is the most widely used orchestration tool [13], [14]. The containers
    are orchestrated using YAML and JSON files in Kubernetes. The architecture of
    Kubernetes is depicted in Figure 2. Pods, nodes, and clusters are instigated in
    this tool. Containers are muffled into an edifice called pods where they can share
    their resources as well as local networks maintaining segregation among them.
    In this orchestration platform, pods are also known as replication units which
    scale up and down as a unit. Pod instances run on nodes that act as a single machine.
    Cluster refers to the master machine where various nodes captivate resources together.
    Amazon elastic container service, azure Kubernetes services, rancher, istio, cloudify,
    knative, VMware tanzu, Redhat Openshift container platform, and Google Kubernetes
    engines are Kubernetes-as-a-service providers constructed on top of the platform
    of Kubernetes [15]. Storage is a challenging issue for Kubernetes because of its
    extensive nature. Building of application services that reach several containers,
    scheduling, scaling, and managing health over time of those containers are all
    allowed by Kubernetes orchestration. This tool abolishes the manual deploying
    and scaling of containerized applications [16]. The main components of Kubernetes
    are cluster, control plane, pod, nodes, replication controllers, and labels. This
    platform offers extensive tools which give flexibility, ease of use, maximum productivity.
    It has the capability of managing microservices. There are more than 109 tools
    that have container managing capabilities but among them, 89% use different configurations
    of Kubernetes according to a survey report of CNCF''s Cloud Native Landscape.
    There are several features of Kubernetes such as load balancing, the discovery
    of service, orchestration storage, scaling, automatic rollouts and rollbacks,
    self-healing, management of secret and configuration, batch execution, IPv4/IPv6
    dual-stack, and automated bin packing. B. Docker Swarm The building of containers
    is done by a specific platform known as Docker which includes Docker engine container
    runtime. As we know automation of a container''s life cycle refers to container
    orchestration. In the Docker platform, the container orchestration tool which
    starts Docker containers automatically is the Docker swarm. Swarm refers to a
    group of physical and virtual machines that work together to run different Docker
    applications [17]. It is a fully assimilated and open-source orchestration tool.
    Docker Swarm''s architecture is shown in Figure 3. Docker swarm is used to package
    and run the applications as containers, deploy the containers and detect their
    images from other hosts. This tool came in 2003, years before Kubernetes. This
    leads to the popularization of the concept of container orchestration for organizations
    that wanted to use containers in place of virtual machines. Fig. 3. Architecture
    of docker swarm Show All Docker swarm is suitable for organizations that give
    preference to easy orchestration for smaller applications. Both the Kubernetes
    and Docker swarm could be integrated by the organization to use the best of both
    tools and this has been done by Docker Enterprise Edition. Because of that now
    Docker provides flexibility in the choice of orchestration engine. Dockers do
    not run on Linux platforms and they have an issue while linking containers to
    storage, highly portable and aerobatic applications are allowed by Docker Swarm.
    Docker swarm is also redundant to offer high availability to the applications.
    Proper load balancing of Docker applications is taken care of by Swarm managers.
    When the workload increases the swarm managers ensure high scalability by bringing
    up worker nodes. Decentralization of access and collaboration are allowed by Docker
    swarm''s distributed environment [18]. The interactions with the clusters are
    done by Docker commands. The joining of clusters is done by a machine called nodes
    and the activities of clusters are handled by the swarm manager. The two main
    components of the Docker swarm are the manager and worker node. Management of
    cluster integrated with Docker engine decentralized design scaling, declarative
    service model, multi-host networking, load balancing, state reconciliation are
    some of the main features of Docker swarm. C. Apache Mesos Mesos was instigated
    by some Ph.D. scholars at the University of California, Berkeley. Its original
    name was Nexus but was renamed later to Mesos. Apache software foundation declared
    its first version on 27 July 2016. Apache Mesos is an open-source cluster management
    tool that performs container orchestration efficiently [19]. The components of
    Mesos are presented in Figure 4. It is a lightweight cross-platform with high
    availability and, is easy to use. Linux, Windows, and Mac operating systems are
    suitable for Mesos and C++, Python, Java are the languages supported by its APIs.
    This platform provides allocation and sharing of resources in distributed frameworks.
    Crone''s schedulers are used by Mesos for starting and stopping services. For
    scaling services and balancing loads, this tool uses Marathon API. Several software
    projects are built on Mesos by Apache such as Avrora, Batch scheduling, solutions
    of data storage and big data processing, marathon, singularity, and much more
    [20], [21]. Linear scalability, GUI, various APIs for constructing applications,
    LXC segregation allying tasks, controlling consolidation for fault-tolerant replication
    of master are some of the main features of Apache Mesos. For running workloads
    such as Big data, etc clustering of virtual machines or physical machines can
    also be done by Mesos as it is not only a tool for containers. Fig. 4. Architecture
    of apache mesos Show All Marathon is a framework in this tool that is used for
    managing and deploying containers on a cluster efficiently. Kubernetes cluster
    can also run on the Mesos cluster. The main components in Mesos architecture are
    Master Mesos, Master Agents, Marathon API, and scheduler. Apache Mesos is used
    by various organizations like Apple, Netflix, eBay, and many more. Red Hat has
    developed many containerized software products and OpenShift is among them. Kubernetes
    services are extended by OpenShift which is a hybrid and business-class platform.
    OpenShift framework is constructed on business class Linux Operating Systems.
    The lifecycle of the containerized program is automatized by it [22]. Databases
    can be easily be created by OpenShift. D. Openshift The marketplace of Red Hat
    helps to purchase many guaranteed applications which in turn helps in billing,
    visibility, administration, and responsive support [23]. Platform-as-a-Service
    (PaaS) and Container-as-a-Service (Caas) both are offered by OpenShift. Faster
    production, Integrated Container embedded operator Hub, open-source and vendor-skeptic
    platform are some of the salient features of the Red Hat OpenShift platform. Figure
    5 and 6 show the layered and component architectures of Redhat OpenShift, respectively.
    Fig. 5. Layered architecture of openshift Show All Fig. 6. Component architecture
    of openshift Show All Table I. Comparison of kubernetes, docker swarm, mesos,
    and openshift It is built on the top of Kubernetes. Both, community and business
    version of OpenShift is available. The projects of OpenShift are maintained by
    Red Hat. For container management and orchestration it provides. Kubernetes features
    as well as out-of-the-box components. On AWS cloud, Openshift is found as a managed
    service. For deployment of applications OpenShift online project of OpenShift
    is used. Openshift online is a PaaS service. The other project of OpenShift is
    OpenShift Dedicated which is provided as a managed service. SECTION IV. Comparative
    Analysis of Orchestration Tools In this section, we summarized the differences
    among four container orchestration tools using various parameters. Table I depicts
    a comparative analysis of Kubernetes, Docker Swarm, Apache Mesos, and OpenShift
    platforms. It is seen that OpenShift is the oldest platform among them released
    on 4th May 2011 but it is still evolving and its latest version came on 18th of
    October, 2021. Kubernetes platform can run in almost every operating system but
    others are restricted to some operating systems. OpenShift offers more security
    than Kubernetes. Docker Swarm is the least popular orchestration tool among them.
    The Software development community as well as the practitioners and researchers
    use to decide their orchestration tools according to their needs and application
    complexity. The growth of orchestration platforms of containers will increase
    with the new technologies of cloud deployment. SECTION V. Conclusion and Future
    Scope We analysed four popular orchestration tools viz., Kubernetes, Docker Swarm,
    Mesos, and Redhat OpenShift on various parameters viz., security, deployment,
    stability, scalability, cluster installation, and learning curve. We observed
    that Kubernetes has the best scheduling features whereas Docker Swarm is easy
    to use. We also found that Mesos has good scalability whereas OpenShift is a highly
    secure orchestration tool. We also noticed that Kubernetes is the most popular
    and widely used platform among the tools discussed in this paper. We also found
    that the second most popular orchestration tool in the IT industries is OpenShift.
    A good technical skill and knowledge of these platforms are required to use these
    tools. Therefore, we can do research on their architecture to make them developer
    and user friendly. We can also work on deployment, management, and development
    of containerized applications. Some more container orchestration tools can be
    analysed in terms of the quality of the deployed applications Authors Figures
    References Citations Keywords Metrics More Like This Flexible Job-Shop Scheduling
    via Graph Neural Network and Deep Reinforcement Learning IEEE Transactions on
    Industrial Informatics Published: 2023 Multi-agent distributed collaborative method
    for flexible job shop scheduling problem 2022 37th Youth Academic Annual Conference
    of Chinese Association of Automation (YAC) Published: 2022 Show More IEEE Personal
    Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED
    DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION
    TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732
    981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility
    | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap |
    IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s largest
    technical professional organization dedicated to advancing technology for the
    benefit of humanity. © Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: 2022 9th International Conference on Computing for Sustainable Global Development
    (INDIACom)
  limitations: '>'
  pdf_link: null
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: A Comparative Analysis of Container Orchestration Tools in Cloud Computing
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/isca45697.2020.00049
  analysis: '>'
  authors:
  - Dimitrios Skarlatos
  - Umur Darbaz
  - Bhargava Gopireddy
  - Nam Sung Kim
  - Josep Torrellas
  citation_count: 9
  full_citation: '>'
  full_text: '>

    IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account
    Personal Sign In Browse My Settings Help Access provided by: University of Nebraska
    - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards
    Authors Citations ADVANCED SEARCH Conferences >2020 ACM/IEEE 47th Annual Int...
    BabelFish: Fusing Address Translations for Containers Publisher: IEEE Cite This
    PDF Dimitrios Skarlatos; Umur Darbaz; Bhargava Gopireddy; Nam Sung Kim; Josep
    Torrellas All Authors 9 Cites in Papers 828 Full Text Views Abstract Document
    Sections I. Introduction II. Background III. Babelfish Design IV. Implementation
    V. Security Considerations Show Full Outline Authors Figures References Citations
    Keywords Metrics Abstract: Cloud computing has begun a transformation from using
    virtual machines to containers. Containers are attractive because multiple of
    them can share a single kernel, and add minimal performance overhead. Cloud providers
    leverage the lean nature of containers to run hundreds of them on a few cores.
    Furthermore, containers enable the serverless paradigm, which leads to the creation
    of short-lived processes.In this work, we identify that containerized environments
    create page translations that are extensively replicated across containers in
    the TLB and in page tables. The result is high TLB pressure and redundant kernel
    work during page table management. To remedy this situation, this paper proposes
    BabelFish, a novel architecture to share page translations across containers in
    the TLB and in page tables. We evaluate BabelFish with simulations of an 8-core
    processor running a set of Docker containers in an environment with conservative
    container co-location. On average, under BabelFish, 53% of the translations in
    containerized workloads and 93% of the translations in serverless workloads are
    shared. As a result, BabelFish reduces the mean and tail latency of containerized
    data-serving workloads by 11% and 18%, respectively. It also lowers the execution
    time of containerized compute workloads by 11%. Finally, it reduces serverless
    function bring-up time by 8% and execution time by 10%-55%. Published in: 2020
    ACM/IEEE 47th Annual International Symposium on Computer Architecture (ISCA) Date
    of Conference: 30 May 2020 - 03 June 2020 Date Added to IEEE Xplore: 13 July 2020
    ISBN Information: DOI: 10.1109/ISCA45697.2020.00049 Publisher: IEEE Conference
    Location: Valencia, Spain SECTION I. Introduction Cloud computing is ubiquitous.
    Thanks to its ability to provide scalable, pay-as-you-go computing, many companies
    choose cloud services instead of using private infrastructure. In cloud computing,
    a fundamental technology is virtualization. Virtual Machines (VMs) allow users
    to share resources, while providing an isolated environment to each user. Recently,
    cloud computing has been undergoing a radical transformation with the emergence
    of Containers. Like a VM, a container packages an application and all of its dependencies,
    libraries, and configurations, and isolates it from the system it runs on. However,
    while each VM requires a guest Operating System (OS), multiple containers share
    a single kernel. As a result, containers require significantly fewer memory resources
    and have lower overheads than VMs. For these reasons, cloud providers such as
    Google’s Compute Engine [27], Amazon’s ECS [3], IBM’s Cloud [31], and Microsoft’s
    Azure [52] now provide container-based solutions. Container environments are typically
    oversubscribed, with many more containers running than cores [56]. Moreover, container
    technology has laid the foundation for Serverless computing [65], a new cloud
    computing paradigm provided by services like Amazon’s Lambda [2], Microsoft’s
    Azure Functions [53], Google’s Cloud Functions [26], and IBM’s Cloud Functions
    [32]. The most popular use of serverless computing is known as Function-as-a-Service
    (FaaS). In this environment, the user runs small code snippets called functions,
    which are triggered by specified events. The cloud provider automatically scales
    the number and type of functions executed based on demand, and users are charged
    only for the amount of time a function spends computing [39], [66]. Our detailed
    analysis of containerized environments reveals that, very often, the same Virtual
    Page Number (VPN) to Physical Page Number (PPN) translations, with the same permission
    bit values, are extensively replicated in the TLB and in page tables. One reason
    for this is that containerized applications are encouraged to create many containers,
    as doing so simplifies scale-out management, load balancing, and reliability [12],
    [33]. In such environments, applications scale with additional containers, which
    run the same application on different sections of a common data set. While each
    container serves different requests and accesses different data, a large number
    of the pages accessed is the same across containers. Another reason for the replication
    is that containers are created with forks, which replicate translations. Further,
    since containers are stateless, data is usually accessed through the mounting
    of directories and the memory mapping of files. The result is that container instances
    of the same application share most of the application code and data pages. Also,
    both within and across applications, containers often share middleware. Finally,
    the lightweight nature of containers encourages cloud providers to deploy many
    containers in a single host [30]. All this leads to numerous replicated page translations.
    Unfortunately, state-of-the-art TLB and page table hardware and software are designed
    for an environment with few and diverse application processes. This has resulted
    in per-process tagged TLB entries, separate per-process page tables, and lazy
    page table management — where, rather than updating the page translations at process
    creation time, they are updated later on demand. In containerized environments,
    this approach causes high TLB pressure, redundant kernel work during page table
    management and, generally, substantial overheads. To remedy this problem, we propose
    BabelFish, a novel architecture to share translations across containers in the
    TLB and page tables — without sacrificing the isolation provided by the virtual
    memory abstractions. BabelFish eliminates the replication of translations in two
    ways. First, it modifies the TLB to dynamically share identical {VPN, PPN} pairs
    and permission bits across containers. Second, it merges page table entries of
    different processes with the same {VPN, PPN} translations and permission bits.
    As a result, BabelFish reduces the pressure on the TLB, reduces the cache space
    taken by translations, and eliminates redundant minor page faults. In addition,
    it effectively prefetches shared translations into the TLB and caches. The end
    result is higher performance of containerized applications and functions, and
    faster container bring-up. We evaluate BabelFish with simulations of an 8-core
    processor running a set of Docker containers in an environment with conservative
    container co-location. On average, under BabelFish, 53% of the translations in
    containerized workloads and 93% of the translations in FaaS workloads are shared.
    As a result, BabelFish reduces the mean and tail latency of containerized data-serving
    workloads by 11% and 18%, respectively. It also lowers the execution time of containerized
    compute workloads by 11%. Finally, it reduces FaaS function bring-up time by 8%
    and execution time by 10%–55%. SECTION II. Background A. Containers Containers
    are a lightweight software virtualization solution that aims to ease the deployment
    of applications [44]. A container is defined by an image that specifies all of
    the requirements of an application, including the application binary, libraries,
    and kernel packages required for deployment. The container environment is more
    light-weight than a traditional VM, as it eliminates the guest operating system.
    All of the containers share the same kernel and, consequently, many pages can
    be automatically shared among containers. As a result, containers typically exhibit
    better performance and consume less memory than VMs [67]. Docker containers [21]
    is the most prominent container solution. In addition, there are management frameworks,
    such as Google’s Kubernetes [28] and Docker’s Swarm [20], which automate the deployment,
    scaling, and maintenance of containerized applications. The lightweight nature
    of containers has led to the Function-as-a-Service (FaaS) paradigm [32], [24],
    [26], [2], [53]. In FaaS, the user provides small code snippets, called Functions,
    and providers charge users only for the amount of time a function spends computing.
    In FaaS environments, many functions can be running concurrently, which leads
    to high consolidation rates. Containers rely on OS virtualization and, hence,
    use the process abstraction, rather than the thread one, to provide resource isolation
    and usage limits. Typically, a containerized application scales out by creating
    multiple replicated containers, as this simplifies load balancing and reliability
    [12], [33]. The resulting containers usually include one process each [22], and
    run the same application but use different sections of data. For example, a graph
    application exploits parallelism by creating multiple containers, each one with
    one process. Each process performs different traversals on the shared graph. As
    another example, a data-serving workload such as Apache HTTPD, creates many containers,
    each one with one process. Each process serves a different incoming request. In
    both examples, the containers share many pages. B. Address Translation in x86
    Linux Figure 1 shows a conventional TLB organization. Each entry includes a Valid
    bit (V), a Virtual Page Number (VPN), a Physical Page Number (PPN), flags, and
    a Process Context Identifier (PCID). The PCID identifies the process, and is shorter
    than the pid that the OS assigned to the process. For an access to hit in the
    TLB, both VPN and PCID have to match. In modern processors, a core typically has
    an L1 instruction TLB, an L1 data TLB, and a unified L2 TLB. Fig. 1: Conventional
    TLB organization. Show All When an access misses in both L1 and L2 TLBs, a page
    table walk begins. This is a multistep process performed in hardware. Figure 2
    shows the page walk for an address in the x86-64 architecture. The hardware reads
    the CR3 control register, which contains the physical address of the Page Global
    Directory (PGD) of the currently-running process. The hardware adds the 40-bit
    CR3 register to bits 47-39 of the virtual address. The result is the physical
    address of an entry in the PGD. The hardware reads such address from the memory
    hierarchy — accessing first the data caches and, if they declare a miss, the main
    memory. The data in that address contains the physical address of the Page Upper
    Directory (PUD), which is the next level of the translation. Such physical address
    is then added to bits 38-30 of the virtual address. The contents of the resulting
    address is the physical address of the next-level table, the Page Middle Directory
    (PMD). The process is repeated using bits 29-21 of the virtual address to reach
    the next table, the Page Table (PTE). In this table, using bits 20-12 of the virtual
    address, the hardware obtains the target physical table entry (pte t). The pte
    t provides the PPN and additional flags that the hardware uploads into the L1
    TLB to proceed with the translation of the virtual address. Fig. 2: Page table
    walk. Show All In theory, a page walk involves four cache hierarchy accesses.
    In practice, each core has a translation cache called the Page Walk Cache (PWC)
    that stores a few recently-accessed entries of the first three tables (PGD, PUD,
    and PMD). The hardware checks the PWC before going to the cache hierarchy. If
    it hits there, it avoids a cache hierarchy access. When this translation process
    fails, a page fault occurs and the OS is invoked. There are two relevant types
    of page faults: major and minor. A major one occurs when the page for one of these
    physical addresses requested during the walk is not in memory. In this case, the
    OS fetches the page from disk into memory and resumes the translation. A minor
    page fault occurs when the page is in memory, but the corresponding entry in the
    tables says that the page is not present in memory. In this case, the OS simply
    marks the entry as present, and resumes the translation. This happens, for example,
    when multiple processes share the same physical page. Even though the physical
    page is present in memory, a new process incurs a minor page fault on its first
    access to the page. C. Replicated Translations The Linux kernel avoids having
    multiple copies of the same physical page in memory. For example, when a library
    is shared among applications, only a single copy of the library is brought into
    physical memory. As a result, multiple processes may point to the same PPN. The
    VPNs of the different processes may be the same, and have identical permission
    bits. Furthermore, on a fork operation, pages are only copied lazily and, therefore,
    potentially many VPNs in the parent and child are the same and point to the same
    PPNs. Finally, file-backed mappings created through mmap lead to further sharing
    of physical pages. In all of these cases, there are multiple copies of the same
    {VPN, PPN} translation with the same permission bits, in the TLB (tagged with
    different PCIDs) and across the page tables of different processes. SECTION III.
    Babelfish Design BabelFish has two parts. One enables TLB entry sharing, and the
    other page table entry sharing. In the following, we describe each part in turn,
    and then present a simple example. A. Enabling TLB Entry Sharing Current TLBs
    may contain multiple entries with the same {VPN, PPN} pair, the same permission
    bits, and tagged with different PCIDs. Such replication is common in containerized
    environments, and can lead to TLB thrashing. To solve this problem, BabelFish
    combines these entries into a single one with the use of a new identifier called
    Container Context Identifier (CCID). All of the containers created by a user for
    the same application are given the same CCID. It is expected that the processes
    within the same CCID group will want to share many TLB entries and page table
    entries. BabelFish adds a CCID field to each entry in the TLB. Further, when the
    OS schedules a process, the OS loads the process’ CCID into a register — like
    it currently does for the process’ PCID. Later, when the TLB is accessed, the
    hardware will look for an entry with a matching VPN tag and a matching CCID. If
    such an entry is found, the translation succeeds, and the corresponding PPN is
    read. Figure 3 shows an example for a two-way set-associative TLB. This support
    allows all the processes in the same CCID group to share entries. Fig. 3: Two-way
    set-associative BabelFish TLB. Show All The processes of a CCID group may not
    want to share some pages. In this case, a given VPN should translate to different
    PPNs for different processes. To support this case, we retain the PCID in the
    TLB, and add an Ownership (O) bit in the TLB. If O is set, it indicates that this
    page is owned rather than shared, and a TLB hit also requires a PCID match. We
    also want to support the more advanced case where many of the processes of the
    CCID group want to share the same {VPN0, PPN0} translation, but a few other processes
    do not, and have made their own private copies. For example, one process created
    {VPN0, PPN1} and another one created {VPN0, PPN2}. This situation occurs when
    a few of the processes in the CCID group have written to a Copy-on-Write (CoW)
    page and have their own private copy of the page, while most of the other processes
    still share the original clean page. To support this case, we integrate the Ownership
    bit into a new TLB field called Ownership-PrivateCopy (O-PC) (Figure 3). Ownership-PrivateCopy
    Field. The O-PC field is expanded in Figure 4. It contains a 32-bit PrivateCopy
    (PC) bitmask, one bit that is the logic OR of all the bits in the PC bitmask (O
    R PC ) , and the Ownership (O) bit. The PC bitmask has a bit set for each process
    in the CCID group that has its own private copy of this page. The rest of the
    processes in the CCID group, which can be an unlimited number, still share the
    clean shared page. We limit the number of private copies to 32 to keep the storage
    modest. Before we describe how BabelFish assigns bits to processes, we describe
    how the complete TLB translation in BabelFish works. The BabelFish TLB is indexed
    as a regular TLB, using the VPN Tag. The hardware looks for a match in the VPN
    and in the CCID. All of the potentially-matching TLB entries will be in the same
    TLB set, and more than one match may occur. On a match, the O-PC and PCID fields
    are checked, and two cases are possible. First, if the O bit is set, this is a
    private entry. Hence, the entry can be used only if the process’ PCID matches
    the TLB entry’s PCID field. Fig. 4: Ownership-PrivateCopy (O-PC) field. The PrivateCopy
    (PC) bitmask has a bit set for each process in the CCID group that has its own
    private copy of the page. The ORPC bit is the logic OR of all the bits in the
    PC bitmask. Show All Alternately, if O is clear, this is a shared entry. In this
    case, before the process can use it, the process needs to check whether the process
    itself has its own private copy of the page. To do so, the process checks its
    own bit in the PC bitmask. If the bit is set, the process cannot use this translation
    because the process already has its own private copy of the page. An entry for
    such page may or may not exist in the TLB. Otherwise, since the process’ bit in
    the PC bitmask is clear, the process can use this translation. The O-PC information
    of a page is part of a TLB entry, but only the O and ORPC bits are stored in the
    page table entry. The PC bitmask is not stored in the page table entry to avoid
    changing the data layout of the page tables. Instead, it is stored in an OS software
    structure called the MaskPage that is described in the Appendix. Each MaskPage
    also includes an ordered list (pid_list) of up to 32 pids of processes from the
    CCID group. The order of the pids in this list encodes the mapping of PC bitmask
    bits to processes. For example, the second pid in the pid_list is the process
    that is assigned the second bit in the PC bitmask. In BabelFish, a MaskPage contains
    the PC bitmasks and pid_list for all the pages of a CCID group mapped by a set
    of PMD tables (details in the Appendix). Actions on a Write to a Copy-on-Write
    (CoW) Page. To understand the operation of the pid_list, consider what happens
    when a process writes to a CoW page. The OS checks whether the process is already
    in the pid_list in the MaskPage for this PMD table set. If it is not, this is
    the process’ first CoW event in this MaskPage. In this case, the OS performs a
    set of actions. Specifically, it adds the process’ pid to the end of the pid_list
    in the MaskPage, effectively assigning the next bit in the corresponding PC bitmask
    to the process. This assignment will be used by the process in the future, to
    know which bit in the PC bitmask to check when it accesses the TLB. In addition,
    the OS sets that PC bitmask bit in the MaskPage to 1. Then, the OS makes a copy
    of a page of 512 pte t translations for the process, sets the Ownership (O) bit
    for each translation, allocates a physical page for the single page updated by
    the process, and changes the translation for that single page to point to the
    allocated physical page. The other 511 pages will be allocated later on demand
    as needed. We choose to copy a page of 512 translations rather than only one translation
    to reduce the bookkeeping overhead. In addition, irrespective of whether this
    was the process’ first CoW event in this MaskPage, the OS has to ensure that the
    TLB is consistent. Hence, similar to a conventional CoW, the OS invalidates from
    the local and remote TLBs, the TLB entry for this VPN that has the O bit equal
    to zero. The reason is that this entry has a stale PC bitmask. Note that only
    this single entry needs to be invalidated, while the remaining (up to 511) translations
    in the same PTE table can still safely remain in the TLBs. Finally, when the OS
    gives control back to the writing process, the latter will re-issue the request,
    which will miss in the TLB and bring its new pte_t entry into the TLB, with the
    O bit set and the updated PC bitmask. Writable pages (e.g., data set) and read-only
    pages (e.g., library code) can have an unlimited number of sharers. However, CoW
    pages, which can be read-shared by an unlimited number of sharers, cannot have
    more than 32 unique writing processes — since the PC bitmask runs out of space.
    We discuss the case when the number of writers goes past 32 in the Appendix. Overall,
    with this support, BabelFish allows multiple processes in the same CCID group
    to share the TLB entry for a page — even after other processes in the group have
    created their own private copies of the page. This capability reduces TLB pressure.
    This mechanism works for both regular pages and huge pages. Role of the ORPC Bit
    in the O-PC Field. Checking the PC bitmask bits on a TLB hit adds overhead. The
    same is true for loading the PC bitmask bits into the TLB on a TLB miss. To reduce
    these overheads, BabelFish uses the ORPC bit (Figure 4), which is the logic OR
    of all the PC bitmask bits. This bit is present in the O-PC field of a TLB entry.
    It is also present, together with the O bit, in each pmdt entry of the PMD table.
    Specifically, bits O and ORPC use the currently-unused bits 10 and 9 of pmdt in
    the x86 Linux implementation [34], [45] (Figure 5(a)). Fig. 5: ORPC bit: position
    in the pm d t (a) and impact (b). Show All The ORPC bit is used to selectively
    avoid reading the PC bitmask on a TLB hit, and to avoid loading the PC bitmask
    to the TLB on a TLB miss. The logic is shown in Figure 5(b). Specifically, consider
    the case when the O bit is clear. Then, if the ORPC bit is clear, the two operations
    above can be safely skipped; if ORPC is set, they need to be performed. Consider
    now the case when the O bit is set. In this case, the two operations can also
    be skipped. The reason is that an access to a TLB entry with the O bit set relies
    only on the PCID field to decide on whether there is a match. In all cases, when
    the PC bitmask bits are not loaded into the TLB, the hardware clears the corresponding
    TLB storage. Overall, with ORPC, the two operations are skipped most of the time.
    Rationale for Supporting CoW Sharing Supporting CoW sharing within a CCID group,
    where a page is read-shared by a potentially unlimited number of processes, and
    a few other processes have private copies of the page adds complexity to the design.
    However, it is important to support this feature because it assists in accelerating
    container bring-up — and fast bring-up is a critical requirement for FaaS environments.
    Specifically, during bring-up, containers first read several pages shared by other
    containers. Then, they write to some of them. This process occurs gradually. At
    any point, there are some containers in the group that share the page read-only,
    and others that have created their own copy. Different containers may end-up writing
    different sets of pages. Hence, not all containers end-up with a private copy
    of the page. B. Enabling Page Table Entry Sharing In current systems, two processes
    that have the same {VPN, PPN} mapping and permission bits still need to keep separate
    page table entries. This situation is common in containerized environments, where
    the processes in a CCID group may share many pages (e.g., a large library) using
    the same {VPN, PPN} mappings. Keeping separate page table entries has two costs.
    First, the many pte_t requested from memory could thrash the cache hierarchy [50].
    Second, every single process in the group that accesses the page may suffer a
    minor page fault, rather than only one process suffering a fault. Page fault latency
    has been shown to add significant overhead [15]. To solve this problem, BabelFish
    changes the page table structures so that processes with the same CCID can share
    one or more levels of the page tables. In the most common case, multiple processes
    will share the table in the last level of the translation. This is shown in Figure
    6. The Figure shows the translation of an address for two processes in the same
    CCID group that map it to the same physical address. The two processes (one with
    CR 3 0 and the other with CR 3 1 ) use the same last level page (PTE). They place
    in the corresponding entries of their previous tables (PMD) the base address of
    the same PTE table. Now, both processes together suffer only one minor page fault
    (rather than two), and reuse the cache line that contains the target pte_t. Fig.
    6: Page table sharing in BabelFish. Show All The default sharing level in BabelFish
    is a PTE table, which maps 512 4KB pages in x86-64. Sharing can also occur at
    other levels. For example, it can occur at the PMD level— i.e., entries in multiple
    PUD tables point to the base of the same PMD table. In this case, multiple processes
    can share the mapping of 512×512 4KB pages or 512 2MB huge pages. Further, processes
    can share a PUD table, in which case they can share even more mappings. We always
    keep the first level of the tables (PGD) private to the process. Examples of large
    chunks of shared pages are libraries, and data accessed through mounting directories
    or memory mapping of files. Note that Figure 6 does not imply that all the pages
    in the shared region are present in memory at the time of sharing; some may be
    missing. However, it is not possible for two processes to share a table and want
    to keep private some of pages mapped by the table. C. Example of BabelFish Operation
    To understand the impact of BabelFish, we describe an example. Consider three
    containers (A, B, and C) that have the same {VP N 0 ,PP N 0 } translation. First,
    A runs on Core 0, then B runs on Core 1, and then C runs on Core 0. Figure 7 shows
    the timeline of the translation process, as each container, in order, accesses
    VPN0 for the first time. The top three rows of the Figure correspond to a conventional
    architecture, and the lower three to BabelFish. To save space, we show the timelines
    of the three containers on top of each other; in reality, they take place in sequence.
    We assume that VPN0 is in memory but not yet marked as present in memory in any
    of the A,B , or Cpt e ts . We also assume that none of these translations is currently
    cached in the page walk cache (PWC) of any core. Conventional Architecture. The
    top three rows of Figure 7 show the conventional process. As container A accesses
    VPNO, the translation misses in the L1 and L2 TLBs, and in the PWC. Then, the
    page walk requires a memory access for each level of the page table (we assume
    that, once the PWC has missed, it will not be accessed again in this page walk).
    First, as the entry in the PGD is accessed, the page walker issues a cache hierarchy
    request. The request misses in the L2 and L3 caches and hits in main memory. The
    location is read from memory. Then, the entry in the PUD is accessed. The process
    repeats for every level, until the entry in the PTE is accessed. Since we assume
    that VPN0 is in memory but not marked as present, A suffers a minor page fault
    as it completes the translation (Figure 7). Finally, A’s page table is updated
    and a {VPNO, PPNO} translation is loaded into the TLB. After that, container B
    running on another core accesses VPN0. The hardware and OS follow exactly the
    same process as for A. At the end, B’s page table is updated and a {VPN0, PPN0}
    translation is loaded into the TLB. Fig. 7: Timeline of the translation process
    in a conventional (top) and BabelFish (bottom) architecture. In the figure, container
    A runs on Core 0, then container B on Core 1, and then container C on Core 0.
    Show All Finally, container C running on the same core as A accesses VPN0. Again,
    the hardware and OS follow exactly the same process. C’s page table is updated,
    and another VPN0, PPN0 translation is loaded into the TLB. The system does not
    take advantage of the state that A loaded into the TLB, PWC, or caches because
    the state was for a different process. BabelFish Architecture. The lower three
    rows of Figure 7 show the behavior of BabelFish. Container A’s access follows
    the same translation steps as in the conventional architecture. After that, container
    B running on another core is able to perform the translation substantially faster.
    Specifically, its access still misses in the TLBs and in the PWC; this is because
    these are per-core structures. However, during the page walk, the multiple requests
    issued to the cache hierarchy miss in the local L2 but hit in the shared L3 (except
    for the PGD access). This is because BabelFish enables container B to reuse the
    page-table entries of container A — at any level except at the PGD level. Also,
    container B does not suffer any page fault. Finally, as C runs on the same core
    as A, it performs a very fast translation. It hits in the TLB because it can reuse
    the TLB translation that container A brought into the TLB. Recall that, in the
    x86 architecture, writes to CR3 do not flush the TLB. This example highlights
    the benefits in a scenario where multiple containers are co-scheduled on the same
    physical core, either in SMT mode, or due to an oversubscribed system. SECTION
    IV. Implementation We now discuss the implementation of BabelFish. A. Resolving
    a TLB Access Figure 8 shows the algorithm that the hardware uses in a TLB access.
    For simplicity, the figure shows the flowchart assuming a single TLB level; in
    practice, the checks are performed sequentially in the L1 and L2 TLBs. As the
    TLB is accessed, each way of the TLB checks for a VPN and CCID match (➀). If none
    of the ways matches, a page walk is initiated (11). Otherwise, for each of the
    matching ways, the following process occurs. The hardware first checks if the
    Ownership bit is set ( ◯2 ). If it is, the hardware checks for a PCID match (
    ◯9 ). If the PCID matches (and assuming that all the permissions checks pass)
    we declare a TLB hit ( ◯8 ) and provide the PPN ( ◯7 ). Otherwise, it is a TLB
    miss (◯10) . Fig. 8: Flowchart of a TLB access. Show All If the Ownership bit
    is clear, the hardware checks if the requesting process already has a private
    copy of the page. It does so by checking first the ORPC bit and, if it is set,
    checking the bit of the process in the PC bitmask ( ◯3 ). If both are set, it
    means that the process has a private copy, and a miss is declared ( ◯10 ). Otherwise,
    a hit is declared ( ◯4 ). In this case, the hardware checks whether this is a
    write to a CoW page ( ◯5 ). If it is, a CoW page fault is declared ( ◯6 ). Otherwise,
    assuming that all the permissions checks pass, the PPN is provided ( ◯7 ). After
    all the TLB ways terminate their checks, if no hit has been declared ( ◯10 ),
    a page walk is initiated ( ◯11 ). B. Implementing Shared Page Table Entries The
    page walker of current systems uses the contents of a control register to initiate
    the walk. In x86, it is the CR3 register. CR3 points to the beginning of the PGD
    table (Figure 6), and is unique per process. To minimize OS changes, BabelFish
    does not change CR3 and, therefore, does not support sharing PGD tables. This
    is not a practical limitation because processes rarely share the whole range of
    mapped pages. BabelFish adds counters to record the number of processes currently
    sharing pages. One counter is assigned to each table at the translation level
    where sharing occurs. For example, if sharing occurs at the PTE level like in
    Figure 6, then there is one counter logically associated with each PTE table.
    When the last sharer of the table terminates or removes its pointer to the table,
    the counter reaches zero, and the OS can unmap the table. Such counters do not
    take much space or overhead to update, and are part of the virtual memory metadata.
    C. Comparing BabelFish and Huge Pages Both BabelFish and huge pages attempt to
    reduce TLB pressure, and they use orthogonal means. Huge pages merge the translations
    of multiple pages belonging to the same process to create a huge page; BabelFish
    merges the translations of different processes to eliminate unnecessary replication.
    As a result, BabelFish and huge pages are complementary techniques that can be
    used together. If an application uses huge pages, BabelFish automatically tries
    to combine huge-page translations that have identical {VPN, PPN} pairs and permission
    bits. Specifically, if the application uses 2MB huge pages, BabelFish automatically
    tries to merge PMD tables; if the application uses 1GB huge pages, BabelFish automatically
    tries to merge PUD tables. D. Supporting ASLR in BabelFish Address Space Layout
    Randomization (ASLR) is a security mechanism that randomizes the positions of
    the segments of a process in virtual memory [47], [58], [48]. When a process is
    created, the kernel generates a random virtual address (VA) offset for each segment
    of the process, and adds it to the base address of the corresponding segment.
    Hence, the process obtains a unique segment layout, which remains fixed for the
    process lifetime. This strategy thwarts attackers that attempt to learn a program’s
    segment layout. In Linux, a process has 7 segments, including code, data, stack,
    heap, and libraries. BabelFish supports ASLR, even while sharing translations
    between processes. We envision two alternative configurations for ASLR, a software-only
    solution called ASLR-SW that requires minimal OS changes, and a hardware-software
    solution called ASLR-HW, that provides stronger security guarantees. In the ASLR-SW
    configuration, each CCID group has a private ASLR seed and, therefore, gets its
    own layout randomization. All processes in the same CCID group get the same layout
    and, therefore, can share TLB and page table entries among themselves. In all
    cases, different CCID groups have different ASLR seeds. This configuration is
    easy to support in Linux. Specifically, the first container in a CCID gets the
    offsets for its segments, and subsequent containers in the group reuse them. This
    configuration is likely sufficient for most deployments, especially in serverless
    environments where groups of containers are spawned and destroyed quickly. In
    the ASLR-HW configuration, each process has a private ASLR seed and, therefore,
    its own layout randomization. In this configuration, when a CCID group is created,
    the kernel generates a randomized VA offset for each of its segments, as indicated
    above. We call this set of offsets CCID_offset[]. Every time that a process i
    is spawned and joins the CCID group, in addition to getting its own set of random
    VA offsets for its segments (i_offset[]), it also stores the set of differences
    between the CCID group’s offsets and its own offsets (i.e., diff_i_offset [] =
    CCID_offset[] - i_offset[]). With this support, when a process is about to access
    the TLB, its VA goes through a logic module with comparators and one adder. This
    logic module determines which segment is being accessed, and then adds the corresponding
    entry in diff_i_offset[] to the VA being accessed. The result is the corresponding
    VA shared by the CCID group. The TLB is accessed with this address, enabling the
    sharing of translations between same-CCID processes while retaining per-process
    ASLR. Similarly, software page walks follow the same steps. The hardware required
    by this configuration may affect the critical path of an L1 TLB access. Consequently,
    BabelFish places the logic module in between the L1 TLB and L2 TLB. The result
    is that BabelFish’s translation sharing is only supported from the L2 TLB down;
    the L1 TLB does not support TLB entry sharing. In practice, eliminating translation
    sharing from the L1 TLB only has a minor performance impact. The reason is that
    the vast majority of the translations are cached in the L2 TLB and, therefore,
    page walks are still eliminated. The L1 TLB performs well as long are there is
    locality of accesses within a process, which ASLR-HW does not alter. To be conservative,
    in our evaluation of Section VII, we model BabelFish with ASLR-HW by default.
    SECTION V. Security Considerations To minimize vulnerabilities, cloud providers
    limit page sharing to occur only within a single user security domain. For example,
    VMware only allows page deduplication within a single guest VM [72]. In Kubernetes,
    the security domain is called a Pod [29], and only containers or processes within
    a Pod share pages by default. In the recently-proposed X-Containers [68], the
    security domain is the shared LibOS, within which all processes share pages. In
    this paper, we consider a more conservative container environment, where a security
    domain contains only the containers of a single user that are running the same
    application. It is on top of this baseline environment that BabelFish proposes
    that the containers in the security domain additionally share address translations.
    The baseline environment, where all the containers of a single user running the
    same application share pages is likely vulnerable to side channel attacks. Adding
    page translation sharing with BabelFish does not significantly change the security
    considerations over the baseline environment. This is because the attacker could
    leverage the sharing of pages to attack, without needing to leverage the sharing
    of translations. Addressing the issue of securing the baseline environment is
    beyond the scope of this paper. SECTION VI. Evaluation Methodology Modeled Architecture.
    We use cycle-level simulations to model a server architecture with 8 cores and
    32GB of main memory. The architecture parameters are shown in Table I. Each core
    is out-of-order and has private L1 I+D caches, a private unified L2 cache, and
    a shared L3 cache. Each core has L1 I+D TLBs, a unified L2 TLB, and a page walk
    cache with a page walker. The table shows that the TLBs can hold pages of different
    sizes at the same time. With BabelFish, the access times of the L1 TLBs do not
    change. However, on an L1 TLB miss, BabelFish performs a two-cycle address transformation
    for ASLR (Section IV-D). Moreover, the L2 TLB has two access times: 10 and 12
    cycles. The short one occurs when the O and O RPC bits preempt an access to the
    PC bitmask (Figure 5(b)); the long one occurs when the PC bitmask is accessed.
    Section VII-D provides details. We use Ubuntu Server 16.04 [13] and Docker 17.06
    [18]. Table I : Architectural Parameters. At Is Access Time. Modeling Infrastructure.
    We integrate the Simics [49] full-system simulator with the SST framework [62],
    [9] and the DRAMSim2 [63] memory simulator. Additionally, we utilize Intel SAE
    [14] on Simics for OS instrumentation. We use CACTI [10] for energy and access
    time evaluation. For the address translation, each hardware page walker is connected
    to the cache hierarchy and issues memory requests following the page walk semantics
    of x86-64 [34]. The Simics infrastructure provides the actual memory and control
    register contents for each memory access of the page walk. We use the page tables
    maintained by the Linux kernel during full-system simulation. To evaluate the
    hardware structures of BabelFish, we model them in detail in SST. To evaluate
    the software structures, we modify the Linux kernel and instrument the page fault
    handler. Workloads. We use three types of workloads: three Data Serving applications,
    two Compute applications, and three Functions representing Function-as-a-Service
    (FaaS). The Data Serving applications are the containerized ArangoDB [7], MongoDB
    [55], and HTTPd [5]. ArangoDB represents a key-value store NoSQL database with
    RocksDB as the storage engine. MongoDB is a scalable document-model NoSQL database
    with a memory mapped engine, useful as a backend for data analytics. HTTPd is
    an efficient open source HTTP server with multiprocess scaling, used for websites
    and online services. Each application is driven by the Yahoo Cloud Serving Benchmark
    [16] with a 500MB dataset. The Compute applications are the containerized GraphChi
    [42] and FIO [36]. GraphChi is a graph processing framework with memory caching.
    We use the PageRank algorithm which traverses a 500MB graph from SNAP [43]. FIO
    is a flexible I/O benchmarking application that performs in-memory operations
    on a randomly generated 500MB dataset. We developed three C/C++ containerized
    Functions: Parse, which parses an input string into tokens, a Hash function based
    on the djb2 algorithm [35], and a Marshal function that transforms an input string
    to an integer. All functions are based on OpenFaaS [24] and use the GCC image
    from Docker Hub [19]. Each function operates on an input dataset similar to [2].
    For these functions, we explore dense and sparse inputs. In both cases, a function
    performs the same work; we only change the distance between one accessed element
    and the next. In dense, we access all the data in a page before moving to the
    next page; in sparse, we access about 10% of a page before moving to the next
    one. Configurations Evaluated. We model widely-used container environments that
    exploit replication of the applications for better load balancing and fault tolerance.
    We conservatively keep the number of containers per core low. Specifically, in
    Data Serving and Compute workloads, each core is multiplexed between two containers,
    which run the same application on different input data. Each Data Serving container
    is driven by a distinct YCSB client and, therefore, serves different requests.
    Similarly, each Compute container accesses different random locations. As a result,
    in both types of workloads, each container accesses different data, but there
    is partial overlap in the data pages accessed by the two containers. In the Function
    workloads, each core is multiplexed between three containers, each running a different
    function. The three containers access different data, but there is partial overlap
    in the data pages accessed by the three containers. In each case, we compare two
    configurations: a conventional server (Baseline), and one augmented with the proposed
    hardware and software (BabelFish). We enable transparent huge pages (THP) for
    both the Baseline and BabelFish. Simulation Methodology. BabelFish proposes software
    and hardware changes. To model a realistic system, we need to warm-up both the
    OS and the architecture state. We use two phases. In the first phase, we warm-up
    the OS by running the containers for Data Serving and Compute for a minute, and
    all the functions to completion, as they are short. In the second phase, we bring
    the applications to steady state, warm-up the architectural state, and measure.
    Specifically, for Data Serving and Compute, we instrument the applications to
    track entry to steady state and then execute for 10 seconds. We then warm-up the
    architectural state by running 500 million instructions, and finally evaluate
    for four billion instructions. For Functions, there is no warm-up. We run all
    the three functions from the beginning to completion and measure their execution
    time. We also measure container bring-up, as the time to start a Function container
    from a pre-created image (docker start). We perform full system simulation of
    all the above steps. SECTION VII. Evaluation The BabelFish performance improvements
    come from two sources: page table entry sharing and L2 TLB entry sharing. In this
    section, we first characterize these two sources, and then discuss the overall
    performance improvements. Finally, we examine the resources that BabelFish needs.
    A. Characterizing Page Table Entry Sharing Figure 9 shows the shareability of
    PTE entries (pte_ts) when running two containers of the same Data Serving and
    Compute application, or three containers of the functions. The figure includes
    the steady-state mappings of all pages, including container infrastructure, and
    program code and data. The data is obtained by native measurements on a server
    using Linux Pagemap [46], while running each application for 5 minutes. Fig. 9:
    Page table sharing characterization. Show All For each application, there are
    three bars, which are normalized to the leftmost one. The leftmost one is the
    total number of pte_ts mapped by the containers. The central bar is the number
    of Active pte_ts, namely those that are placed by the kernel in the active LRU
    list. They are a proxy for the pages that are recently touched. The rightmost
    bar is the number of Active pte_ts after enabling BabelFish. Each bar is broken
    down into pte_ts that are shareable, pte_ts that are unshareable, and pte_ts that
    correspond to the huge pages created by THP. The latter are also unshareable.
    A shareable pte_ts has an identical {VPN, PPN} pair and permission bits as another.
    Unshareable pte_ts are either exclusive to a process or not shareable. Data Serving
    and Compute Applications. If we consider the average bars, we see that 53% of
    the total baseline pte_ts are shareable. Further, most of them are active. BabelFish
    reduces the number of shareable active pte_ts by about half. Since this plot corresponds
    to only two containers, the reduction in shareable active pte_ts is at most half.
    Sharing pte_ts across more containers would linearly increase savings, as only
    one copy is required for all the sharers. Overall, the average reduction in total
    active pte_ts attained by BabelFish is 30%. The variation of shareability across
    applications is primarily due to the differences in usage of shared data versus
    internal buffering. For example, GraphChi operates on shared vertices, but uses
    internal buffering for the edges. As a result, most of the active pte_ts are unshareable,
    and we see little gains. In contrast, MongoDB and FIO operate mostly on shared
    data and see substantial pte_ts savings. The other applications have a more balanced
    mixture of shareable and unshareable pte_ts. Impact of Huge Pages. As shown in
    Figure 9, THP pte_ts are on average 8% of the total pte_ts, and are in the unshareable
    portion. Moreover, only a negligible number of these entries are active during
    execution. To understand this data, note that MongoDB and ArangoDB recommend disabling
    huge pages [6], [54]. Further, THP supports only anonymous mappings, and not file-backed
    memory mapping. The anonymous mappings are commonly used for internal buffering,
    which are unshareable. Therefore, huge pages are rarely active. Functions. Functions
    have a very high percentage of shareable pte_ts. Combining them reduces the total
    active pte_ts by 57%. The unshareable pte_ts correspond to the function code and
    internal buffering, which are unique for each function. They account for only
    ≈ 6% of pte_ts. One can subdivide the shareable category in the bars into application
    shared data and infrastructure pages. The latter contain the common libraries
    that are required by all the functions. It can be shown that they are 90% of the
    total shareable pte_ts, and can be shared across functions. Data pte_ts are few,
    but also shareable across functions. B. Characterizing TLB Entry Sharing Figure
    10a shows the reduction in L2 TLB Misses Per Kilo Instructions (MPKI) attained
    by BabelFish. Note that in our evaluation, we conservatively do not share translations
    at the L1 TLB (Section IV-D). The figure is organized based on workload, and shows
    data and instruction entries separately. Fig. 10: (a) L2 TLB MPKI reduction attained
    by BabelFish. (b) Hits on L2 TLB entries that were brought into the TLB by processes
    other than the one issuing the accesses. We call them Shared Hits and show them
    as a fraction of all L2 TLB hits. Show All From the figure, we see that BabelFish
    reduces the MPKI across the board. For example, for Data Serving, the data MPKI
    reduces by 66%, and the instruction MPKI reduces even more, by 96%. These are
    substantial reductions. Good results are also seen for the Compute workloads.
    Functions see smaller MPKI reductions, as they are short lived and interfered
    by the docker engine/OS. The reductions come from various sources. First, a container
    may reuse the L2 TLB entries of another container and avoid misses. Second, sharing
    L2 TLB entries effectively increases TLB capacity, which reduces misses. Finally,
    as a result of these two effects, there is a lower chance that co-scheduled processes
    evict each other’s TLB entries. To gain more insight into L2 TLB entry sharing,
    Figure 10b shows the number of hits on L2 TLB entries that were brought into the
    L2 TLB by processes other than the one performing the accesses. We call them Shared
    Hits and show them as a fraction of all L2 TLB hits. The figure is organized as
    Figure 10a. As we can see, the percentage of shared hits is generally sizable,
    but varies across applications, as it is dependent on the applications’ access
    patterns. For example, GraphChi shows 48% shared hits for instructions and 12%
    for data. This is because PageRank’s code is regular, while its data accesses
    are fairly random, causing variation between the data pages accessed by the two
    containers. Overall, BabelFish’s TLB entry sharing bolsters TLB utilization and
    reduces page walks. C. Latency or Execution Time Reduction To assess the performance
    impact of BabelFish, we report different metrics for different applications: reduction
    in mean and 95 th percentile (Tail) latency in Data Serving applications; reduction
    in execution time in Compute applications; and reduction in bring-up time and
    function execution time in Functions. Figure 11 shows the results, all relative
    to Baseline. To gain further insight, Table II shows what fraction of the performance
    improvement in Figure 11 comes from TLB effects; the rest comes from page table
    effects. Recall that transparent huge pages are enabled in all applications but
    MongoDB and ArangoDB [6], [54]. Consider first the Data Serving applications.
    On average, BabelFish reduces their mean and tail latencies by a significant 11%
    and 18%, respectively. The reductions are higher in MongoDB and ArangoDB than
    in HTTPd. It can be shown that this is because, in Baseline, address translation
    induces more stress in the MongoDB and ArangoDB database applications than in
    the stream-based HTTPd application. Hence, BabelFish is more effective in the
    former. Table II shows that MongoDB gains more from L2 TLB entry sharing, while
    ArangoDB more from page table entry sharing. Therefore, both types of entry sharing
    are helpful. Fig. 11: Latency/time reduction attained by BabelFish. Show All Table
    II : Fraction of Time Reduction Due To L2 Tlb Effects. Compute applications also
    benefit from BabelFish. On average, their execution time reduces by 11%. GraphChi
    has lower gains because it performs low-locality accesses in the graph, which
    makes it hard for one container to bring shared translations that a second container
    can reuse. On the other hand, FIO has higher gains because its more regular access
    patterns enable higher shared translation reuse. Table II shows that these applications
    benefit more from page table effects. Recall that we run the Functions in groups
    of three at a time. The leading function behaves similarly in both BabelFish and
    Baseline due to cold start effects. Hence, Figure 11 shows the reduction in execution
    time for only the other two functions in the group. We see that the reductions
    are heavily dependent on the access patterns. Functions with dense access patterns
    access only a few pages, and spend little time in page faults. Hence, their execution
    time decreases by only 10% on average. In contrast, functions with sparse access
    patterns access more pages and spend more time servicing page faults. Hence, BabelFish
    reduces their execution time by 55% on average. In all cases, as shown in Table
    II, most gains come from page table entry sharing. Finally, although not shown
    in any figure, BabelFish speeds-up function bring-up by 8%. Most of the remaining
    overheads in bring-up are due to the runtime of the Docker engine and the interaction
    with the kernel. Overall BabelFish speeds-up applications across the board substantially,
    even in our conservative environment where we co-locate only 2-3 containers per
    core. BabelFish vs Larger TLB. BabelFish’s main hardware requirements are additional
    bits in the L2 TLB for the CCID and O-PC fields. It could be argued that this
    extra hardware could be used instead to make a conventional TLB larger. Hence,
    we have re-run the workloads with a conventional architecture with this larger
    L2 TLB. On average, the resulting architecture reduces the mean request latency
    of Data Serving applications by 2.1%, the execution time of Compute applications
    by 0.6%, and the execution time of Functions by 1.1% (dense) and 0.3% (sparse).
    These reductions are much smaller than those attained by BabelFish (Figure 11).
    One reason is that BabelFish benefits from both L2 TLB and page table effects.
    A second reason is that BabelFish also benefits from processes prefetching TLB
    entries for other processes into the L2 TLB and caches. Overall, this larger L2
    TLB is not a match for BabelFish. D. BabelFish Resource Analysis We analyze the
    hardware and software resources needed by BabelFish. We also analyze the resources
    of a design where, as soon as a write occurs on a CoW page, sharing for the corresponding
    PMD table set immediately stops, and all sharers get private page table entries.
    This design does not need a PC bitmask. Hardware Resources. BabelFish’s main hardware
    overhead is the CCID and O-PC fields in the TLB, and the associated comparison
    logic (Figure 3). We estimate that this extra hardware adds 0.4% to the area of
    a baseline core (without L2). If we eliminate the need for the PC bitmask bits,
    the area overhead falls to 0.07%. These are very small numbers. Table III shows
    several parameters of the L2 TLB, both for Baseline and BabelFish: area, access
    time, dynamic energy of a read access, and leakage power. The data corresponds
    to 22nm, and is obtained with CACTI [10]. The table shows that the difference
    in TLB access time between Baseline and BabelFish is a fraction of a cycle. To
    be conservative, we add two extra cycles to the access time of the BabelFish L2
    TLB when the PC bitmask has to be accessed. Table III : Parameters of the L2 Tlb
    At 22Nm. Memory Space. The memory space of BabelFish is minimal. It includes one
    MaskPage with PC bitmasks and pid-list (Figure 13) for each 512 pages of pte_ts.
    This is 0.19% space overhead. In addition, it includes one 16-bit counter per
    512 pte_ts to determine when to de-allocate a page of pte_ts (Section IV-B). This
    is 0.048% space overhead. Overall, BabelFish only adds 0.238% space overhead.
    If we eliminate the need for the PC bitmask bits, the first item goes away, and
    the total space overhead is 0.048%. Software Complexity. We implement BabelFish’s
    page table sharing mechanism in the Linux kernel and in the Simics shadow page
    tables. We require about 300 Lines of Code (LoC) in the MMU module, 200 LoC in
    the page fault handler, and 800 LoC for page table management operations. SECTION
    VIII. Related Work Huge Pages. BabelFish transparently supports huge pages, which
    are in fact a complementary way to reduce TLB and cache pressure. Recent work
    has tackled huge-page bloating and fragmentation issues [41], [57]. Translation
    Management and TLB Design. Recent work [4], [74], [40] aims to reduce the translation
    coherence overheads with software and hardware techniques. Other work provides
    very fine grain protection domains and enables sub-page sharing, but does not
    support translation sharing [73]. CoLT and its extension [60], [59] propose the
    orthogonal idea of coalesced and clustered TLB entries within the same process.
    MIX-TLB [17] supports both huge page and regular page translations in a single
    structure, increasing efficiency. In [8], self-invalidating TLB entries are proposed
    to avoid TLB shoot-downs. Shared last-level TLB [11] aims to reduce translation
    overhead in multi-threaded applications. Recent work [51] proposes to prefetch
    page table entries on TLB misses. Other work [61], [69] shows optimizations for
    CPU-GPU environments. These approaches tackle a set of different problems in the
    translation process and can co-exist with BabelFish. Elastic cuckoo page tables
    [71] propose a hashed page table design based on elastic cuckoo hashing. Such
    scheme can be augmented with an additional hashed page table where containers
    in a CCID group share page table entries. Auxiliary structures called Cuckoo Walk
    Tables could be enhanced to indicate whether a translation is shared. Since the
    TLB is not affected by elastic cuckoo page tables, BabelFish’s TLB design remains
    the same. Other work has focused on virtualized environments. POMTLB and CSALT
    [64], [50] propose large in-memory TLBs and cache partitioning for translations.
    DVMT [1] proposes to reduce 2D page walks in virtual machines by enabling application-managed
    translations. RMM [37] proposes redundant memory mappings and [25] aims to reduce
    the dimensionality of nested page walks. PageForge [70] proposes near-memory extensions
    for content-aware page merging. This deduplication process shares pages in virtualized
    environments, generating an opportunity to further share translations. These solutions
    are orthogonal to BabelFish in a scenario with containers inside VMs. Khalidi
    and Talluri [38] propose a scheme to share TLB entries between processes. The
    idea is to tag each TLB entry with a PCID or a bitvector. The bitvector uses one-hot
    encoding to identify one of 10-16 different collections of shared translations.
    A TLB is accessed twice: with the PCID and with the bitvector. If the bitvector
    matches, the shared translation is retrieved. The authors also suggest tagging
    global hashed page tables with PCIDs or bitvectors. While this scheme allows translation
    sharing, compared to BabelFish, it has several limitations. First, unlike BabelFish,
    the scheme is not scalable because the number of different collections of translations
    that can be shared is limited to the number of bits in the bitvector. Second,
    to find a shared translation, the TLB is accessed twice. Third, unlike BabelFish,
    the scheme does not support CoW or selective sharing of a translation. In addition,
    it does not support ASLR. Finally, BabelFish also proposes the sharing of multi-level
    page table entries. Native Execution Environment. A software-only approach that
    improves zygote fork and application performance in Android by sharing page translations
    across applications is presented in [23]. This scheme only shares code translations
    of 4KB pages in a 2-level page table design. This solution requires disabling
    TLB tagging and marking TLB entries as global, which leads to TLB flushes at context
    switches. Moreover, this solution does not support the sharing of data translations.
    In contrast, BabelFish shares both code and data translations in both TLB and
    page tables, for multiple page sizes, while supporting tagged TLBs and CoW. SECTION
    IX. Conclusion Container environments create replicated translations that cause
    high TLB pressure and redundant kernel work during page table management. To address
    this problem, we proposed BabelFish, a novel architecture to share address translations
    across containers in the L2 TLB and in the page tables. We evaluated BabelFish
    with simulations of an 8-core processor running a set of Docker containers. On
    average, BabelFish reduced the mean and tail latency of containerized data-serving
    workloads by 11% and 18%, respectively. It also lowered the execution time of
    containerized compute workloads by 11%. Finally, it reduced serverless function
    bring-up time by 8% and execution time by 10%-55%. Overall, BabelFish sped-up
    applications across the board substantially, even in our conservative environment
    where we co-located only 2-3 containers per core. ACKNOWLEDGMENT This research
    was funded in part by NSF under grants CNS 17-63658, CNS 17-05047, and CCF 16-29431.
    Appendix: Storing and Accessing the PC Bitmask To understand where the PC bitmask
    is stored and how it is accessed, consider Figure 12(a), which shows the page
    tables of three processes of a CCID group that share a PTE table. BabelFish adds
    a single MaskPage associated with the set of PMD tables of the processes. Fig.
    12: Operation of the MaskPage. Show All The OS populates the MaskPage with the
    PC bitmask and the pid_list information for all the pages mapped by the PMD table
    set. Figure 13 shows its contents. It contains up to 512 PC bitmasks for the 512
    pmd_t entries in the PMD table set. Further, it contains a single pid_list, which
    has the ordered pids of the processes in the CCID group that have performed a
    CoW on any of the pages mapped by the PMD table set. The pid_list has at most
    32 pids. Hence, there can be at most 32 distinct processes performing CoW on these
    pages. Fig. 13: MaskPage with 512 PC bitmasks and one pid_list. Show All As a
    process performs a CoW on a page in this PMD table set for the first time, the
    OS puts its pid in the next position in the ordered pid_list. If this is position
    i, it means that the process claims bit i in all of the 512 PC bitmasks. Of course,
    bit i is set in only the PC bitmasks of the pmd_t entries that reach pages that
    the process has performed a CoW on. With this design, on a TLB miss, as a pmd_t
    entry is accessed, the hardware checks the ORPC bit (Section III-A). If it is
    set, then the hardware accesses the MaskPage in parallel with the request for
    the pte_t entry. The hardware then reads the corresponding PC bitmask and loads
    it into the L1 TLB. If more than 32 processes in a CCID group perform CoWs on
    pages mapped by a PMD table set, this design runs out of space, and all the processes
    in the group need to revert to non-shared translations — even if many processes
    in the group share many {VPN, PPN} mappings. Specifically, when a 33rd process
    performs a CoW, the OS allocates a page of pte_t translations for each of the
    processes in the group that were using shared translations in the PMD page set.
    In these new translations, the OS sets the Ownership (O) bit. The only physical
    data page that is allocated is the one updated by the writing process. The result
    is the organization shown in Figure 12(b), for a single PTE table being shared.
    Consolidating CoW information from all the pages mapped by a PMD table set in
    a single MaskPage may sometimes be inefficient. However, we make this choice because
    selecting a finer granularity will increase space overhead. Furthermore, recall
    that writable pages (e.g., dataset) and read-only pages (e.g., code) can have
    an unlimited number of sharers. CoW pages can also be read-shared by an unlimited
    number of sharers; they just cannot have more than 32 writing processes. It can
    be shown that, with an extra indirection, one could support more writing processes.
    Authors Figures References Citations Keywords Metrics More Like This Unified-TP:
    A Unified TLB and Page Table Cache Structure for Efficient Address Translation
    2020 IEEE 38th International Conference on Computer Design (ICCD) Published: 2020
    Exploiting Page Table Locality for Agile TLB Prefetching 2021 ACM/IEEE 48th Annual
    International Symposium on Computer Architecture (ISCA) Published: 2021 Show More
    IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS
    VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION
    AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE:
    +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help
    | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting
    | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s
    largest technical professional organization dedicated to advancing technology
    for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: null
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: 'BabelFish: Fusing Address Translations for Containers'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.2478/amcs-2019-0017
  analysis: '>'
  authors:
  - Vladimir Podolskiy
  - Anshul Jindal
  - Michael Gerndt
  citation_count: 10
  full_citation: '>'
  full_text: ">\nInt. J. Appl. Math. Comput. Sci., 2019, Vol. 29, No. 2, 227–244\n\
    DOI: 10.2478/amcs-2019-0017\nMULTILAYERED AUTOSCALING PERFORMANCE EVALUATION:\n\
    CAN VIRTUAL MACHINES AND CONTAINERS CO–SCALE?\nVLADIMIR PODOLSKIY a,∗, ANSHUL\
    \ JINDAL a, MICHAEL GERNDT a\naChair of Computer Architecture and Parallel Systems\n\
    Technical University of Munich, Boltzmannstr. 3, 85748 Garching, Germany\ne-mail:\
    \ {v.podolskiy,anshul.jindal,gerndt}@in.tum.de\nThe wide adoption of cloud computing\
    \ by businesses is due to several reasons, among which the elasticity of the cloud\n\
    virtual infrastructure is the deﬁnite leader. Container technology allows increasing\
    \ the ﬂexibility of an application by\nadding another layer of virtualization.\
    \ The containers can be dynamically created and terminated, and also moved from\n\
    one host to another. A company can achieve a signiﬁcant cost reduction and increase\
    \ the manageability of its applications\nby allowing the running of containerized\
    \ microservice applications in the cloud. Scaling for such solutions is conducted\n\
    on both the virtual infrastructure layer and the container layer. Scaling on both\
    \ layers needs to be synchronized so that,\nfor example, the virtual machine is\
    \ not terminated with containers still running on it. The synchronization between\
    \ layers\nis enabled by multilayered cooperative scaling, implying that the autoscaling\
    \ solution of the virtual infrastructure layers\nis aware of the decisions of\
    \ the autoscaling solution on the container layer and vice versa. In this paper,\
    \ we introduce\nthe notion of cooperative multilayered scaling and the performance\
    \ of multilayered autoscaling solutions evaluated using\nthe approach implemented\
    \ in ScaleX (previously known as Autoscaling Performance Measurement Tool, APMT).\
    \ We\nprovide the results of the experimental evaluation of multilayered autoscaling\
    \ performance for the combination of virtual\ninfrastructure autoscaling of AWS,\
    \ Microsoft Azure and Google Compute Engine with pods horizontal autoscaling of\n\
    Kubernetes by using ScaleX with four distinct load patterns. We also discuss the\
    \ effect of the Docker container image size\nand its pulling policy on the scaling\
    \ performance.\nKeywords: cooperative scaling, multilayered autoscaling, autoscaling\
    \ performance, autoscaling evaluation, ScaleX.\n1.\nIntroduction\nCloud computing\
    \ is based on virtualization.\nThis\ntechnology represents the hardware as a pool\
    \ of resources\nto be sliced and provided to users in the form of virtual\nmachines\
    \ (VM): it also helps businesses to scale their\napplications.\nScalability of\
    \ cloud applications is one\nof the main reasons behind the wide adoption of cloud\n\
    computing.\nMost of IaaS cloud services providers\n(CSP) offer autoscaling services\
    \ to adapt the VMs to the\nchanging demand.\nA new type of virtual entity, the\
    \ container, allows\nthe user to design loosely coupled applications consisting\n\
    of multiple small building blocks.\nThese building\nblock (microservices) implement\
    \ a small set of functions\nand communicate with other microservices.\nThe\nruntime\
    \ environment is packed within the container\nallowing the execution of the microservice\
    \ anywhere,\n∗Corresponding author\nboth on bare metal or in a VM. Containerization\n\
    extends the cloud computing paradigm from several\nviewpoints:\nﬁner and more\
    \ accurate management of\nthe running application; decoupling of the application\n\
    from the underlying resources; self-containment of the\nmicroservices.\nHowever,\
    \ the management of several\nvirtualization layers can become very challenging.\n\
    Additional layers of virtualization introduce a higher\nlevel of ﬂexibility and\
    \ control. Aside from an obvious\nperformance loss when introducing additional\
    \ layers of\nvirtualization, the absence of the awareness of these\nvirtualization\
    \ layers about one another could become\na signiﬁcant concern.\nWith the lack\
    \ of coordination\nbetween the multiple layers, one can expect that, e.g., the\n\
    termination of the VM due to autoscaling may result in\nthe termination of the\
    \ running containers and, potentially,\nin unfulﬁlled requests. By increasing\
    \ the awareness of the\nvirtualization layers about their neighbours with multilay-\n\
    © 2019 V. Podolskiy et al.  \nThis is an open access article distributed under\
    \  \nthe Creative Commons Attribution-NonCommercial-NoDerivs license \n(http://creativecommons.org/licenses/by-nc-nd/3.0/).\n\
    228\nV. Podolskiy et al.\nered cooperative scaling, ﬂexible multilayered application\n\
    deployment may acquire predictable scaling behavior.\nWith the rich set of metrics\
    \ and approaches\nto evaluate existing autoscaling solutions1 and their\npolicies,2\
    \ it may become difﬁcult to select them for a\nparticular case. One should always\
    \ distinguish between\nthe assessment of the quality of the autoscaling policy\
    \ and\nthe evaluation of the autoscaling solution performance.\nIn this paper,\
    \ emphasis is put on the evaluation of the\nperformance of autoscaling solutions\
    \ with the autoscaling\npolicy being ﬁxed for all the cases.\nParticularly, the\n\
    performance of multilayered autoscaling is presented for\nthe combination of infrastructure\
    \ autoscaling by AWS,\nAzure, and GCE with container-level autoscaling based\n\
    on Kubernetes.\nThe\nkey\ncontributions\nof\nthis\npaper\nare\nthe\ntheoretical\
    \ framework for cooperative scaling involving\ndifferent types of virtual entities\
    \ (VMs, containers), a\nreﬁned approach to QoS-based multilayered autoscaling\n\
    performance evaluation based on scaling intervals, an\nextended description of\
    \ the performance evaluation tool\nScaleX and its use, results of cooperative\
    \ autoscaling\nperformance evaluation for the public IaaS clouds (AWS,\nAzure\
    \ and GCE), autoscaling solutions combined with\nthe autoscaling solution of Kubernetes,\
    \ and results of the\nexperiment highlighting the impact of the container image\n\
    size and pulling policy type on the scaling performance.\nThe following section\
    \ introduces the theoretical\nframework and the background.\nSection 3 covers\n\
    the multilayered autoscaling performance evaluation\napproach.\nSection 4 focuses\
    \ on the autoscaling\nperformance\nmeasurement\ntool\nScaleX.\nSection\n5\nprovides\n\
    experimental\nresults\nfor\nevaluating\nthe\nperformance\nof\nmultilayered\nautoscaling\n\
    and\nfor\nestimating the potential impact of the container image\nsize and pulling\
    \ policy on the autoscaling performance.\nSection 6 discusses the obtained experimental\
    \ results.\nThe related works and the position of the paper in the\nexisting research\
    \ are summarized in Section 7. Section 8\nconcludes the paper.\n2.\nTheoretical\
    \ framework and background\n2.1.\nScalability and elasticity.\n“The concept [of\
    \ scal-\nability] connotes the ability of a system to accommodate\nan increasing\
    \ number of elements or objects, to process\ngrowing volumes of work gracefully,\
    \ and/or to be suscep-\ntible to enlargement” (Bondi, 2000).\nThe scalability\n\
    of cloud applications and\nthe\nunderlying virtual infrastructure means that the\
    \ number\nor the capacity of the virtual entities forming the cloud\n1An autoscaling\
    \ solution is a piece of software that implements au-\ntoscaling.\n2An autoscaling\
    \ policy is a set of precise rules that determine how\nthe virtual infrastructure\
    \ is scaled based on its monitored parameters.\napplication (containers) and the\
    \ virtual infrastructure\n(virtual machines, VMs) can change dynamically in\n\
    response to the changing workload. Often, the scalability\nof a cloud is speciﬁed\
    \ by the term “elasticity” (Herbst\net al., 2013).\nElasticity differs from scalability\
    \ in\nthat the state of the virtual infrastructure and cloud\napplications, acquired\
    \ as a result of the increased demand\nfor the capacity, lasts only until the\
    \ amount of requests\nand resource utilization starts decreasing.\nThus, cloud\n\
    applications and the virtual infrastructure can return to the\noriginal state\
    \ in terms of resources consumed. Elasticity\ncould be viewed from two viewpoints—of\
    \ the cloud\nservices provider and of the cloud user.\nThe elasticity of the cloud\
    \ as viewed by the CSP\nrevolves around the hardware resources provided to the\n\
    cloud users. The pool of hardware resources allocated\nfor the particular user\
    \ in the form of VMs can arbitrarily\ngrow and shrink.\nThe CSP provides virtual\
    \ machines\nfor the customer.\nThis enables the dynamic change\nof the amount\
    \ of resources, e.g., elasticity on the\ninfrastructure level.\nThis requires\
    \ the provisioning of\nsufﬁcient hardware as well as the scheduling of VMs.\n\
    Cloud scalability on the CSP’s side resides on hardware\nvirtualization using\
    \ hypervisors (e.g., Xen, Hyper-V)\nand on the hardware resources allocation for\
    \ the virtual\nmachines scheduling (Sotomayor et al., 2009a; 2009b).\nThe society’s\
    \ concerns about the ecology and the CSPs\nconcerns about the cost of electricity\
    \ introduce power\nconsumption as another parameter to be considered when\nscaling\
    \ (Jakobik et al., 2017).\nThe elasticity of the cloud as viewed by the cloud\n\
    user puts the cloud application in the center.\nA cloud\napplication may consist\
    \ of multiple microservices in\ncontainers. The elasticity from the user’s prospect\
    \ is in\nthe opportunity to increase or decrease the number of\nmicroservice instances,\
    \ thus regulating the capacity of the\napplication in terms of the processed requests.\
    \ Elasticity\nin that sense might be supported by out-of-the-box CSPs\n(e.g.,\
    \ AWS Lambda). The scalability of the application\ncould be achieved within the\
    \ IaaS cloud by running the\ncontainers on top of VMs.\nWe assume this scenario\n\
    when discussing multilayered scaling spanning several\nvirtualization layers.\n\
    2.2. Changing the cloud capacity through scaling.\n2.2.1.\nTypes of scaling.\n\
    From the point of view of the\ncloud user, scaling can be conducted in two ways—either\n\
    by increasing the capacity of the existing virtual entities\nor by increasing\
    \ the number of virtual entities.\nVertical\nscaling\nallows\nchanging\nthe\n\
    resource\ncapacity of a virtual entity.\nIn the case of a virtual\nmachine, it\
    \ could be achieved, e.g., by increasing the\namount of allocated memory or the\
    \ number of virtual CPU\nMultilayered autoscaling performance evaluation ...\n\
    229\ncores assigned to the VM. Vertical scaling in such a case\ncould be represented\
    \ by substituting the VM of the type\nwith a smaller capacity for the VM of the\
    \ type with a\nlarger capacity (scale-up) or vice versa (scale-down). A\ncontainer\
    \ can also be vertically scaled by changing the\nmaximal amount of resources allocated\
    \ to it (e.g., the\nmaximal amount of processor time as millicore parameter\n\
    of Kubernetes pods3).\nHorizontal scaling allows changing the capacity of\nthe\
    \ pool of virtual entities by introducing new entities or\nremoving old ones.\
    \ Horizontal scaling requires load bal-\nancing. Horizontal scaling for large-scale\
    \ applications is\npreferable as it imposes a homogeneity requirement on the\n\
    groups of virtual entities and does not require stopping\nrunning the application\
    \ in order to change the underlying\nvirtual machine.\n2.2.2.\nScaling the virtual\
    \ infrastructure.\nThe virtual\ninfrastructure is a “software-based IT infrastructure\
    \ being\nhosted on another physical infrastructure and meant to be\ndistributed\
    \ as a service as in the cloud computing Infras-\ntructure as a Service (IaaS)\
    \ delivery model”.4\nIn\nthe\ncase\nof\nthe\nIaaS\nmodel,\nthe\nvirtual\ninfrastructure\
    \ could be represented as one or more VMs\nthat are allocated on the physical\
    \ servers in one of the\nCSP’s data centers. From the point of view of the CSP,\n\
    scaling the virtual infrastructure is always connected to\nallocating more or\
    \ less hardware resources.\nFrom the\npoint of view of the IaaS cloud services’\
    \ user, virtual\ninfrastructure scaling is represented either by a change in\n\
    the number of virtual machines (horizontal scaling) or by\na change in the type\
    \ of virtual machines (vertical scaling).\nThe IaaS model supports the automation\
    \ of VM scaling\nvia automatic scaling (or autoscaling).\nA detailed discussion\
    \ of autoscaling is provided in\nSection 2.3.\n2.2.3.\nScaling\ncontainerized\n\
    applications.\nAn\napplication container could be deﬁned as “a controlling\nelement\
    \ for an application instance that runs within a type\nof virtualization scheme\
    \ called container-based virtual-\nization. [. . . ] in container-based virtualization,\
    \ the in-\ndividual instances share an operating system.”5\nEach application container\
    \ can be an enclosed\nfunctional unit of the application that provides services\n\
    to other containers. This viewpoint allows considering\na container to be a lightweight\
    \ entity that includes a\nrelatively compact code base, though in general several\n\
    microservices could be packed in the same container.\n3https://kubernetes.io/docs/concepts/configura\n\
    tion/manage-compute-resources-container/.\n4https://www.techopedia.com/definition/30459/v\n\
    irtual-infrastructure.\n5https://www.techopedia.com/definition/31114/a\npplication-container.\n\
    Although containers support both types of scaling,\nthe most widely used is horizontal\
    \ scaling.\nContainer\nscaling can be automated by using container orchestration\n\
    tools (e.g., DockerSwarm or Kubernetes). Vertical scaling\nof a container is not\
    \ explicitly implemented, although it\ncould be simulated by increasing or decreasing\
    \ container\nresource limits.6 The automation of container on-the-ﬂy\nvertical\
    \ scaling is being researched (Al-Dhuraibi et al.,\n2017).\nKubernetes’ abstraction\
    \ of pods as a group of\ncontainers sharing the network and the storage7 leverages\n\
    the opportunity to decrease the degree of container\nisolation, allowing access\
    \ to the shared resources.\nIt\nallows scheduling and running application containers\
    \ on\nclusters of physical or virtual machines. The abstraction\nof a pod serves\
    \ as a basis to scale groups of containers.\nAutomatic horizontal scaling thereof\
    \ is supported by\nout-of-the-box Kubernetes by monitoring CPU utilization\nand\
    \ changing the number of pods in the replication\ncontroller. The vertical autoscaling\
    \ feature is also being\nactively developed.8\nBy leveraging the ability to scale\
    \ both the virtual\ninfrastructure and containers, we may introduce the\nnotions\
    \ of multilayered and cooperative scaling.\n2.2.4.\nMultilayered\nand\ncooperative\n\
    scaling.\nSimultaneous scaling on several layers of virtualization\nintroduces\
    \ additional issues that do not appear when\nscaling either the virtual infrastructure\
    \ or a containerized\napplication. When putting containers on virtual machines,\n\
    it is necessary to ensure that during the scale-out the\nnecessary amount of resources\
    \ is available in the form of\nVMs. It could also occur that a VM is terminated\
    \ with\ncontainers running on top of it. In the case of Kubernetes,\naccidental\
    \ termination of the master VM during the\nscale-down may yield a fault of the\
    \ whole deployment.\nTo avoid such problems, each virtualization layer should\n\
    be aware scaling actions happening on the other layer.\nMultilayered scaling with\
    \ enabled awareness of scaling\nactions on other layers can be called cooperative\
    \ scaling.\nCooperative scaling supposes the presence of several\nvirtualization\
    \ layers. By putting virtual entities of one\nlayer on top of virtual entities\
    \ of the other layer, a\ndependency is established.\nThough the multilayered\n\
    structure allows more ﬂexibility, the presence of a\ndependency yields scaling\
    \ challenges.\nTo reduce\ndamaging effects of scaling on multiple layers, each\
    \ layer\nshould receive updates about scaling actions taken on\nanother one.\n\
    Allowing scaling solutions on different\nlayers to communicate, the availability\
    \ of the application\n6https://docs.docker.com/config/containers/res\nource_constraints/.\n\
    7https://kubernetes.io/docs/concepts/workloads\n/pods/pod/.\n8https://github.com/kubernetes/autoscaler/tree\n\
    /master/vertical-pod-autoscaler.\n230\nV. Podolskiy et al.\nduring and after scaling\
    \ can be ensured.\nCooperative scaling exhibits (a) support for scaling\non multiple\
    \ layers induced by triggering the same rule of\nthe scaling policy, (b) coordinated\
    \ scheduling of scaling\nactivities on all virtualization layers, (c) the availability\
    \ of\ndata about the planned scaling to the scaling solution of\nthe neighbour\
    \ layer, (d) scaling ﬂexibility, e.g., the ability\nto use different scaling policies/thresholds\
    \ to conduct\nscaling on different virtualization layers.\nCurrently,\nproduction-level\n\
    cooperative\nscaling\nrequires an additional functionality to enable the selection\n\
    of scaling policies parameters for each layer.\n2.3. Autoscaling.\n2.3.1.\nReactive\
    \ autoscaling.\nAutoscaling (automatic\nscaling, auto scaling, auto-scaling) is\
    \ the technology that\nenables automatic provisioning and termination of virtual\n\
    entities to adapt the resource capacity to changes in the\ndemand. The key difference\
    \ from the previous discussion\nof scaling is in the automation of this process.\n\
    The\nautomation is achieved by using a monitoring service\nto retrieve relevant\
    \ resource utilization metrics on which\nalarms and triggers can be deﬁned.\n\
    State-of-the-art autoscaling solutions by public CSPs\nare of the reactive type.\n\
    Reactive autoscaling is the\ntype of autoscaling that either deploys or terminates\
    \ the\npredeﬁned amount of virtual entities as a response to the\nchange of some\
    \ metric. Hence, reactive autoscaling takes\ninto account only the given parameters,\
    \ which are either\nprovided by the cloud administrator or are measured by\nthe\
    \ monitoring solution. The amount of change, i.e., the\nnumber of virtual entities\
    \ to be allocated or terminated, is\nencoded as a set of rules. The most severe\
    \ limitation of\nreactive autoscaling is the small amount of time allocated\n\
    for the scaling action in the case of an increased workload.\nThe most recent\
    \ research tries to overcome it on the CSP’s\nside by employing continuous (online)\
    \ updates of the\noptimal autoscaling conﬁguration (Guo et al., 2018).\nEach IaaS/PaaS/FaaS\
    \ CSP provides its own native\nreactive autoscaling solution.\nFollowing,\nwe\
    \ will\nintroduce brief information on autoscaling solutions\nof AWS, Microsoft\
    \ and Google that were used for\nconducting the experiments in the paper.\nAWS\
    \ (Amazon Web Services) Auto Scaling9 is a part\nof the services offered by Amazon\
    \ in its IaaS public\ncloud.\nThe core concept of AWS Auto Scaling is an\nAuto\
    \ Scaling Group (ASG). An ASG is a set of different\nAmazon Elastic Compute Cloud\
    \ (EC2) instances (VMs)\nsharing similar characteristics and being subject to\
    \ the\nsame scaling policies. Therefore, every VM in the group\nhas the same Amazon\
    \ Machine Image (AMI) and the same\n9https://aws.amazon.com/autoscaling/.\nhardware\
    \ characteristics.\nThe load distribution among\nthe VMs is automated by Elastic\
    \ Load Balancer (ELB).\nAmazon CloudWatch provides the performance data used\n\
    in the scaling rules.\nMicrosoft Azure Autoscale10 comes in two modes:\nmetric-based\
    \ and scheduled. The metric-based autoscale\nservice of Microsoft represents the\
    \ common way of\nautoscaling as in the AWS case.\nThe scheduled mode\nallows the\
    \ user to write a scaling schedule to adjust the\ninfrastructure according to\
    \ time markers.\nSimilarly to\nAWS, Azure also groups VM instances into a group\
    \ that\nis managed by its autoscaling solution. These groups are\ncalled scaling\
    \ sets.\nDespite the fundamental similarity\nof scaling sets to auto scaling groups\
    \ of AWS, they are\nslightly different, e.g., the user is not allowed to attach\
    \ the\nshell script to the VM template—the necessary ﬁle should\nbe provided directly\
    \ in the VM image. Each scaling set\nis scaled based on the autoscale settings.\
    \ They determine\nthe capacity and the set of scaling rules identifying the\n\
    thresholds for different metrics.\nGoogle Compute Engine (GCE) autoscaling11 is\
    \ based\non a managed instance group.\nIt is a scalable group\nof the same virtual\
    \ machines that behaves as a uniform\nentity.\nEach group contains a load balancer.\n\
    GCE\nautoscaling is based on the metrics provided by Google\nStackdriver.12\n\
    Out-of-the-box it supports autoscaling\nbased solely on the average CPU utilization.\
    \ Moreover,\nStackdriver introduces additional metrics as well as the\nability\
    \ to create custom ones.\n2.3.2.\nScheduled autoscaling.\nReactive autoscaling\n\
    is appropriate for most practical cases, though the time\nbetween the decision\
    \ to scale-out and the new instances\nbeing able to serve the requests may impact\
    \ the quality\nof service (QoS). A particular example could be the\nChristmas\
    \ season for a web shop. With the rising number\nof customers, the virtual infrastructure\
    \ may not meet\nthe demand, and reactive autoscaling tries to adapt the\nvirtual\
    \ infrastructure to the growing demand. However,\nduring the autoscaling process,\
    \ the web site may not\nhave enough capacity to serve all the Christmas orders,\n\
    which will result in a revenue decrease.\nOn the other\nhand, loosening a reactive\
    \ autoscaling policies could\nresult in the overprovisioning and increase of the\
    \ costs.\nA partial solution to this problem is provided in the form\nof scheduled\
    \ autoscaling.\nThe concept of scheduled autoscaling is simple.\nBased on the\
    \ knowledge of load patterns, the cloud\nadministrator\ndevises\na\nscaling\n\
    schedule\nwhich\n10https://docs.microsoft.com/en-us/azure/archi\ntecture/best-practices/auto-scaling.\n\
    11https://cloud.google.com/compute/docs/autosca\nler/.\n12https://cloud.google.com/stackdriver/.\n\
    Multilayered autoscaling performance evaluation ...\n231\ncontains the information\
    \ on how many virtual entities\nshould be added to or removed from the virtual\n\
    infrastructure/containerized application at the speciﬁc\ntime.\nMost CSPs offer\
    \ scheduled autoscaling along\nwith reactive autoscaling. AWS, for example, started\
    \ to\nprovide the scheduled autoscaling service for applications\nin 2017.13 Kubernetes\
    \ also supports pods scheduling.14\nScheduled autoscaling could be combined with\
    \ reactive\nautoscaling, both to capture the expected load changes\nand to react\
    \ to spontaneous variations.\n2.3.3.\nPredictive autoscaling.\nCertain drawbacks\
    \ of\nthe widely used types of autoscaling could be avoided\nby incorporating\
    \ a smarter approach to autoscaling that\nis able to extract a value from the\
    \ monitoring data. Pre-\ndictive autoscaling (also known as proactive autoscaling)\n\
    leverages historical data about the application and the\nvirtual infrastructure\
    \ collected by the monitoring solution.\nThe collected historical data can be\
    \ in various forms:\napplication traces, logs, time series, etc. These data are\n\
    needed for the derivation of the models used to extrapolate\nthe future values\
    \ of the speciﬁc metrics. For example, the\ncollected requests per second time\
    \ series could be used\nto derive a model and forecast (predict, extrapolate)\
    \ the\nrequest per second value for a speciﬁc service at some\nmoment in the future.\n\
    In addition to the forecast, performancemodels of the\nsoftware and the virtual\
    \ entity as well as a management\ncomponent implementing autoscaling are required\
    \ (Bauer\net al., 2017).\nWith these components, the predictive\nautoscaling solution\
    \ (i) collects monitoring data for the\nforecasted parameter, (ii) derives forecasting\
    \ models, (iii)\nderives application and virtual infrastructure performance\n\
    models, (iv) derives the scaling policy that ensures the\nprovision of such an\
    \ amount of virtual entities that would\nbe able to serve the forecast workload,\
    \ (v) executes scaling\nactions.\nPredicitive\nautoscaling\nhas\nto\nbe\ndynamically\n\
    adapted to changes in the application and in user demand\npatterns. This includes\
    \ updating the prediction model, the\nperformance models and the derived scheduling\
    \ policy.\nThough predictive autoscaling is yet to be provided\nby CSPs, various\
    \ solutions are already widely represented\nin the research literature (Roy et\
    \ al., 2011; Nikravesh\net al., 2015; Moore et al., 2013).\nMoreover, some\norchestration\
    \ solutions contain predictive autoscaling as\nwork-in-progress.15\nAs unpredictable\
    \ changes in the load may also\n13https://aws.amazon.com/about-aws/whats-new/2\n\
    017/11/scheduled-scaling-now-available-for-appl\nication-auto-scaling/.\n14https://kubernetes.io/blog/2017/03/advanced-\n\
    scheduling-in-kubernetes/.\n15https://github.com/mattjmcnaughton/kubernetes\n\
    /tree/add-predictive-autoscaling.\nhappen in such a dynamic environment, predictive\
    \ and\nreactive autoscaling might be combined (Liu et al., 2015).\n2.4.\nEvaluation\
    \ of autoscaling.\nThe evaluation of\nautoscaling could be conducted from different\
    \ points of\nview. First of all, one needs to distinguish between the\nevaluation\
    \ of autoscaling policies and the evaluation of\nthe autoscaling solution.\nThe\
    \ autoscaling policy is a set of rules that governs\nthe autoscaling process,\n\
    be it reactive,\nscheduled,\nor\npredictive.\nAn\nautoscaling\npolicy\nevaluation\n\
    framework\nshould\nprovide\nthe\nset\nof\nautoscaling\nsolution\nimplementation-independent\n\
    metrics\nthat\nallow comprehensive evaluation of the quality of the\nspeciﬁc autoscaling\
    \ policy, e.g., the tendency to over- or\nunderprovision the resources, the frequency\
    \ of the scaling\nevents, and the cost of the scaled virtual infrastructure (?).\n\
    Although the evaluation of autoscaling policies with\nvarious\nmetrics\nprovides\n\
    a\nuseful\ndecision-making\nframework\nallowing\nselection\nof\nthe\nappropriate\n\
    autoscaling policy based on multiple criteria, it does\nnot capture the implementation-speciﬁc\
    \ characteristics of\nthe autoscaling solution, e.g., its performance.\nThe performance\
    \ could be measured by the time to\ntake a scaling decision and the time for starting\
    \ additional\nvirtual entities.\nAnother approach could be based on\nuser-level\
    \ performance metrics, e.g., the number of QoS\nviolations for the application\
    \ (Jindal et al., 2017). The\nevaluation of autoscaling solution performance using\
    \ both\ntechniques is discussed further in the paper.\n3.\nApproach to evaluate\
    \ autoscaling\nperformance\n3.1.\nSingle-layered autoscaling performance evalu-\n\
    ation.\nThe main purpose of reactive autoscaling is to\nreact to a change in the\
    \ application/virtual infrastructure\nload.\nThe reaction time or autoscaling\
    \ latency is the\ntime between the decision of the autoscaler and the ﬁnal\nadaptation\
    \ of the resources (Jindal et al., 2017).\nFor\napplication level metrics, the\
    \ fraction of the autoscaler\nlatency where QoS requirements were violated is\
    \ an\nimportant metric.\nThe autoscaling latency can be deﬁned based on\nCurrent\
    \ Amount of Instances (CAI) and Desired Amount\nof Instances (DAI). Each autoscaling\
    \ solution contains\nautoscaling rules that determine conditions triggering\n\
    autoscaling actions (scale-in or scale-out in the horizontal\nscaling case). As\
    \ the deployment of the virtual entity takes\ntime for resource allocation, booting\
    \ and conﬁguring,\nDAI will differ from CAI during some time.\nWhen\nautoscaling\
    \ is completed, CAI and DAI will be equal.\nThus, we consider the described time\
    \ interval to be the\nautoscaling latency. If tstart is the start time and tend\
    \ is\n232\nV. Podolskiy et al.\nthe end time of autoscaling then the autoscaling\
    \ inter-\nval Tautoscale = [tstart, tend] is an interval such that ∀t ∈\nTautoscale\
    \ : CAI(t) ̸= DAI(t).\nIf ∀t ∈ Tautoscale :\nCAI(t) < DAI(t), then Tautoscale\
    \ is a scale-out interval.\nIf ∀t ∈ Tautoscale : CAI(t) > DAI(t), then Tautoscale\
    \ is\na scale-in interval. The autoscaling latency is deﬁned as\ntend − tstart.\n\
    Other\nperformance\nmeasures\nfor\nautoscaling\nsolutions are based on the notion\
    \ of the quality of service\nfor the cloud application.\nFor autoscaling solution\n\
    performance evaluation, two user-level quality metrics\nwere chosen: the cloud\
    \ application response time and\nthe maximal failure rate.\nThey are directly\
    \ inﬂuenced\nby the quality of the corresponding autoscaling solution\nservices.\n\
    These metrics have the corresponding QoS\nlimitations which may be imposed by\
    \ cloud application\nusers:\n• required response time (RRT),\n• required maximal\
    \ failure rate (RMFR).\nTo measure the performance of the autoscaling\nsolution,\
    \ we now deﬁne the following two metrics:\nresponse time violation and maximal\
    \ failure rate violation.\nBoth are the fraction of the autoscaling interval where\
    \ the\ncorresponding QoS requirement was violated.\nAs the performance metric\
    \ for autoscaling is based\non the cloud application response time, we identify\
    \ such a\nmetric as the fraction of the autoscaling interval Tautoscale\nwith\
    \ the service response time (RT) above the threshold.\nSo, if Tautoscale = [ta,\
    \ tb] and Thigh RT = [tc, td], where\nta ≤ tc ≤ td\n≤ tb, then the autoscaling\
    \ solution\nperformance metric can be computed as (Jindal et al.,\n2017)\nRTV(Tautoscale)\
    \ = td − tc\ntb − ta\n,\n(1)\nwhere RTV(Tautoscale) is the fraction of the autoscaling\n\
    latency where the response time requirement is violated.\nIn more complex cases,\
    \ Thigh RT could be a set of intervals,\ne.g., Thigh RT = {T (1)\nhigh RT, T (2)\n\
    high RT, . . . , T (p)\nhigh RT}.\nSimilarly to RTV(Tautoscale), we compute the\
    \ fraction\nof the autoscaling interval with the maximal failure rate\n(MFR) higher\
    \ than a predeﬁned threshold. If Tautoscale =\n[ta, tb] and Thigh MFR = [te, tf],\
    \ where ta ≤ te ≤ tf ≤\ntb, then ∀t ∈ Thigh MFR and the performance metric is\n\
    computed as in (Jindal et al., 2017)\nMFRV(Tautoscale) = tf − te\ntb − ta\n.\n\
    (2)\nThe presented autoscaling performance metrics (1)\nand (2) allow us to evaluate\
    \ the performance of the\nautoscaling solution directly without considering the\n\
    particular autoscaling policy implemented by the solution.\n3.2.\nPerformance\n\
    evaluation\nof\nmultilayered\nautoscaling.\nThe general idea behind multilayered\n\
    autoscaling performance evaluation is to measure it\nas a fraction of autoscaling\
    \ time with violated QoS\nrequirements spanning multiple layers of virtualization.\n\
    Figure 1 illustrates the concept of a multilayered\nautoscaling interval and the\
    \ multilayered autoscaling\nperformance measurement.\n\x02\x03\x04\x05\x03\x06\
    \a\x06\b\t\x03\n\b\x06\x03\v\f\r\x0E\n\a\n\x0F\x10\x11\b\x11\a\x12\x13\x12\x14\
    \x15\a\x12\f\r\x16\b\x17\n\a\n\x18\n\x18\n\x19\x18\b\x17\n\x02\x03\x04\x05\x06\
    \x03\a\b\t\n\v\a\x04\n\f\a\r\x03\n\x0E\x0F\r\a\x06\x10\x0E\b\x05\x04\x06\n\x11\
    \x06\x10\x0E\b\x05\x12\a\x0F\r\x13\n\x1A\x05\e\x1C\x03\n\b\f\x1D\b\x1E\x1F\b\x12\
    \r\x06\a\x15\r\v\x03\x06\n\a\n\x19\n \n\x14\x05\x06\x15\x04\x05\t\n\x16\x17\a\x0F\
    \x18\r\n\a\v\n\x19\x18\x06\r\x0E\x18\x10\x05\x06\n\x11\x14\x16\x19\x13\n\x1A\x0F\
    \x04\x04\x05\x18\r\n\x16\x17\a\x0F\x18\r\n\a\v\n\x19\x18\x06\r\x0E\x18\x10\x05\
    \x06\n\x11\x1A\x16\x19\x13\n!\x18\x06\b\b\"\b\a#\n\x03\x06#\f\x13\x0E\n\b\b\b\b\
    \b\b\b\b\b\b$\x03\x03\t\x12\r%\n\b\b\b\b\b\b\b\b\b\b\x12\r\a\x03\n&\x15\x13\n\r\
    \n\b\b\n\x18\n\x1A\x05\e\x1C\x03\n\b\f\x1D\b'\x05\x1C\x03\n\r\x03\a\x03\x06\b\x10\
    \f\x0E\x06\n\a\n\x18\n\x19\n \n\x14\x05\x06\x15\x04\x05\t\n\x16\x17\a\x0F\x18\r\
    \n\a\v\n\x19\x18\x06\r\x0E\x18\x10\x05\x06\n\x11\x14\x16\x19\x13\n\x1A\x0F\x04\
    \x04\x05\x18\r\n\x16\x17\a\x0F\x18\r\n\a\v\n\x19\x18\x06\r\x0E\x18\x10\x05\x06\
    \n\x11\x1A\x16\x19\x13\n!\n(\n\x02\x03\x06\t\f\r\x06\x03\b\a\x12\e\x03\x16\b\x06\
    \b)*\f+\b\e\x03\a\n\x12\v,\n\a\n\x18\n\x19\n \n!\n\e\a\x1C\n\x1D\x05\x1E\x0F\x15\
    \x04\x05\x17\x05\x18\r\x1F\n\x1D\x02\n\x18\a\n\x17\a\x04\x05\n\r\x03\x0E\x18\n\
    \ \n\x06\n-\x10\b.\b\x18/01\n-\x05\a\f\x06\v\x15\x13\x12\r%\b2\r\a\x03\n&\x15\x13\
    \n\x10\x15\n\a\b\f\x1D\b2\r\a\x03\n&\x15\x13\b3\x12\a#\b*\f+\b\n\x03\x04\x05\x12\
    \n\x03\e\x03\r\a\x06\n\a#\x15\a\b3\x03\n\x03\b\r\f\a\b\e\x03\a\n\v\n\b\b\n\b\n\
    \x03\nFig. 1. Abstract example of a response time-based multilayered\nautoscaling\
    \ performance metric.\nThe multilayered autoscaling interval is a set of time\n\
    intervals on different layers of virtualization covering the\nwhole autoscaling\
    \ event. The ﬁrst two graphs in Fig. 1\nshow how CPU utilization changes in response\
    \ to change\nin the amount of requests.\nThe two following graphs\nhighlight change\
    \ in the number of VMs and pods in\nresponse to increased CPU utilization (the\
    \ rule was set\nto increase the number of pods and VMs by one after\nreaching\
    \ a 10% CPU utilization and sustaining it for 30\nseconds).\nIf we assume the\
    \ QoS requirement of the\nresponse time is 3 seconds as shown in the last graph,\n\
    then we can identify the fraction of the autoscaling time\ninterval during which\
    \ the requirement on the response\ntime was not met.\nThe approach for multilayered\n\
    autoscaling performance evaluation closely follows this\nMultilayered autoscaling\
    \ performance evaluation ...\n233\nexample.\nThe\nmain\nresearch\nproblem\nin\n\
    multilayered\nautoscaling performance evaluation is to identify a\nset of autoscaling\
    \ events on different virtualization layers\nto be considered as a single autoscaling\
    \ event spanning\nmultiple layers.\nIn the methodology deﬁned by Jindal\net al.\
    \ (2017), this challenge is resolved using the notion\nof time locality, i.e.,\
    \ the scaling events on multiple layers\nof virtualization are considered to be\
    \ part of the same\nmultilayered autoscaling event if autoscaling events on\n\
    the previous virtualization layer and on the next one\nhave the same direction\
    \ of scaling (scale-in or scale-out)\nand the event of the dependent virtualization\
    \ layer (e.g.,\ncontainerized application) follows the scaling event on\nthe lower\
    \ layer (e.g., virtual infrastructure).\nT (1)\nas\n= {T (1)\n1\n, T (2)\n1\n\
    , . . . , T (n)\n1\n} is a set of autoscaling\nintervals, with T (1)\ni\nbeing\
    \ an autoscaling interval on the\nvirtualization layer that is closest to the\
    \ hardware (e.g.,\nnative CSP’s autoscalers are on this level); superscripts\n\
    denote the layers, subscripts signify that an interval in\nthe set belongs to\
    \ the particular multilayered autoscaling\ninterval, i.e., T (1)\nas .\nIn turn,\
    \ each element of the set\ncould also be a set of intervals on the corresponding\n\
    layer of virtualization.\nThe intervals of time between\nthe autoscaling intervals\
    \ are not taken into account\nwhen computing multilayered autoscaling duration\
    \ in\norder to reduce the effect of the performance of the\nunderlying hardware,\
    \ though, depending on the goals\nof performance evaluation, one might attribute\
    \ these\nintervals to autoscaling duration.\nIn general, a single-layer autoscaling\
    \ interval T (i)\n1\nis\nconsidered an element of the set of autoscaling intervals\n\
    for a single case of multilayered autoscaling if and only if\n∀j : j > i and we\
    \ have the following conditions fulﬁlled:\nT (i)\n1\n≺ T (i)\n2 ,\n(3)\nT (i)\n\
    1\n⪯ T (j)\n1 ,\n(4)\nCAI(tj) − DAI(tj)\n|CAI(tj) − DAI(tj)|· CAI(ti) − DAI(ti)\n\
    |CAI(ti) − DAI(ti)| = 1, (5)\nwith ∀tj ∈ T (j)\n2\nand ∀ti ∈ T (i)\n1 .\nThus,\
    \ in order to\nbe considered a part of a single multilayered autoscaling\nevent,\
    \ autoscaling on level i should (i) occur when all\nprevious layers have entered\
    \ a stable state, i.e., CAI =\nDAI, after the corresponding previous j-th autoscaling\n\
    has already occurred, and (ii) be of the same direction\n(scale-in or scale-out)\
    \ as each of the autoscalings on\nprevious layers.\nExample\nCAI/DAI\nplots\n\
    for\nthe\ntwo-layered\nautoscaling case are presented in Fig. 2.\nIf A = {a1,\
    \ a2, . . . , am} is a set of indices that\nenumerates all the members of Tas,\
    \ then the duration\n\a\n\x18\n\a\n\x18\n\x10\f\x0E\x06\n\x1E\x1F\b\x12\r\x06\a\
    \x15\r\v\x03\x06\n\x19\n(\n\x19\n \n4\x19\n)\x19,\n4\x19\n) ,\n+\v\x15\x13\x03\
    5\f\x05\a\b\v\x15\x06\x03\b)\r\f\r5\x12\r\a\x03\n\x06\x03\v\a\x12\r%,\n+\v\x15\
    \x13\x035\x12\r\b\v\x15\x06\x03\b)3\x12\a#\b\x12\r\a\x03\n\x06\x03\v\a\x12\f\r\
    \b\x12\r\b%\n\x156,\n-\x05\a\f\x06\v\x15\x13\x12\r%\b\x12\r\a\x03\n&\x15\x13\x06\
    \b\f\r\b\a#\x03\b\x19\x06\a\b\x13\x156\x03\n-\x05\a\f\x06\v\x15\x13\x12\r%\b\x12\
    \r\a\x03\n&\x15\x13\x06\b\f\r\b\a#\x03\b \r\x0E\b\x13\x156\x03\n7-2\n\x0F-2\n\
    Fig. 2. Example of multilayered autoscaling event identiﬁcation\nfor two-layered\
    \ virtualization (virtual infrastructure and\ncontainerized application).\nof\
    \ multilayered autoscaling can be determined with the\nfollowing formula:\nΔTas\
    \ = |T (a1)\n1\n|+\nm\n\x02\ni=1\n(|T (ai+1)\n1\n|−|T (ai+1)\n1\n∩T (ai)\n1\n\
    |). (6)\nThe formula (6) takes into account a possible\nintersection of the autoscaling\
    \ intervals on different layers\nby adding a delta of the interval further in\
    \ time (if a pair\nof consecutive intervals overlaps) or the whole interval\n\
    (if a pair of consecutive intervals does not overlap, i.e.,\nT (ai+1)\n1\n∩ T\
    \ (ai)\n1\n= ∅). The formula (6) with respect to\nconstraints (3)–(5) gives us\
    \ an estimate for the duration\nof a single autoscaling event for an arbitrary\
    \ multilayered\ncloud application. In the simplest case of two layers, the\nformula\
    \ becomes\nΔTas = |T (1)\n1\n| + (|T (2)\n1\n| − |T (2)\n1\n∩ T (1)\n1\n|).\n\
    (7)\nWith respect to metrics, the previously introduced\nformulas (1) and (2)\
    \ are still in use, but the notion of\nthe autoscaling interval on which they\
    \ are computed is\nchanged:\nTautoscale =\nm\n\x03\ni=1\nT (ai)\n1\n.\n(8)\nThe\
    \ presented multilayered autoscaling performance\nmeasurement approach is implemented\
    \ in the autoscaling\nperformance\nmeasurement\ntool\nScaleX,\nwhich\nis\ndiscussed\
    \ in the following section.\nComparison with the existing evaluation schemes.\n\
    The\npresented\nuser-side\nautoscaling\nperformance\nevaluation approach and metrics\
    \ should be considered\ncomplimentary\nto\nthe\nexisting\napproaches\nand\nmetrics\
    \ (Ilyushkin et al., 2017; Evangelidis et al., 2017).\n234\nV. Podolskiy et al.\n\
    It is not designed to be the only one used when evaluating\nthe performance of\
    \ autoscaling solutions. Such metrics\nas the overprovisioning, underprovisioning,\
    \ instability,\nor cost of the overprovisioned virtual infrastructure\nshould\
    \ also be measured and calculated when evaluating\nan autoscaling solution.\n\
    The proposed metrics and\napproach are different from the existing in that (i)\
    \ several\nvirtualization levels are considered when evaluating\nthe performance,\
    \ and (ii) the metrics are designed to\ncapture the user-side performance, i.e.,\
    \ what the user\nwill encounter during the autoscaling process. Thus, the\napproach\
    \ and metrics are necessary for comprehensive\nevaluation of the autoscaling solution’s\
    \ performance.\n4.\nScaleX: An autoscaling performance\nmeasurement tool\n4.1.\n\
    ScaleX overview.\nScaleX is a user-friendly web\nservice-based horizontal single-layered\
    \ and multi-layered\nautoscaling performance measurement tool designed and\nimplemented\
    \ by the authors (Jindal et al., 2017). The tool\nis implemented in Node.js. The\
    \ architecture of ScaleX\nand the communications between its modules in a typical\n\
    use case are shown in Fig. 3.\nScaleX is composed of multiple modules, overall\n\
    matching the microservice architecture.\nEach module\nconsists of components for\
    \ handling a particular task.\nLoad Generator & \nMonitoring\nAutoscaler\nDeployment\
    \ \nin Cloud\nDB\nMetrics Visualization\nLoad Generation & \nMetrics collection\n\
    User \nSelection\nMetrics Store\nGCE\nSingle-Layered Autoscaler\nAWS\nAzure\n\
    GCE\nKubernetes\nAWS\nKubernetes\nAzure\nKubernetes\nCooperative Autoscaler\n\
    User Interface\nApplication \nType\nConfiguration \nParameters\nLoad Pattern\n\
    Autoscaler \nSelection\nVisualization\nSelected \nAutoscaler \ndeployment\nFig.\
    \ 3. High-level architecture of ScaleX.\nApart from measuring the performance\
    \ of the\ndeployed autoscaling solution,\nScaleX allows cloud\napplication\ndeployment\n\
    for\nmultiple\nCSP\nnative\nautoscalers with a single command.\nWith the same\n\
    command, the user may conﬁgure autoscaling parameters.\nThe following subsections\
    \ present the modules of ScaleX.\n4.2.\nUser interface.\nThe user interface (UI)\
    \ module\nof ScaleX interacts with the user and provides him or\nher with an opportunity\
    \ to select or conﬁgure different\ntool parameters. It comprises ﬁve components,\
    \ which are\ndiscussed in the following paragraphs.\nApplication Type Setting\
    \ Component enables the selection\nof an application to be deployed for testing\
    \ from a list of\npredeﬁned applications.16\nThe user can select an application\
    \ from any of\nthese categories to conduct the tests of the autoscaling\nsolution(s)\
    \ on it using a particular autoscaling decision\nmetric.\nAt the moment, ScaleX\
    \ supports only CPU\nutilization as an autoscaling metric.\nConﬁguration Parameters\
    \ Component provides the user\nwith the autoscaling solution conﬁguration functionality.\n\
    This\ncomponent conﬁgures the\nchosen\nautoscaling\nsolution using parameter values\
    \ speciﬁed by the user.\nEach autoscaling solution supported by ScaleX provides\n\
    all important autoscaling conﬁguration parameters.\nSingle-Layered Autoscaler\n\
    Conﬁguration Component\nallows conﬁguring horizontal scaling of the virtual\n\
    infrastructure based on a numbers of parameters: the type\nof instance, minimal\
    \ and maximal number of instances, a\nscaling decision metric and its threshold,\
    \ or an autoscaling\npolicy.\nMultilayered Autoscaler Conﬁguration Component allows\n\
    conﬁguring horizontal scaling for both the virtual\ninfrastructure and the containerized\
    \ application.17\nThe\nconﬁguration parameters for both virtualization layers\
    \ are\nconﬁgured by this component:\n1. CSPs IaaS Autoscaler: all the parameters\
    \ as listed for\nthe Single-Layered Autoscaler Component.\n2. Kubernetes Horizontal\
    \ Pod Autoscaler (HPA): the\nminimal and maximal numbers of pods and the pod\n\
    scaling decision metric with its threshold. As of now,\nonly CPU utilization is\
    \ supported as the autoscaling\ndecision metric in Kubernetes.\nLoad Pattern Conﬁguration\
    \ Component provides an\ninterface to the workload request generator integrated\
    \ in\nthe ScaleX. It allows the user to select a preconﬁgured\nload pattern in\
    \ order to test the performance of the\nautoscaling solution. At the moment, four\
    \ load patterns\nare supported by ScaleX:\n• Linear Increase Load Pattern corresponds\
    \ to the\nlinearly increasing number of requests per second\nduring the test time.\n\
    • Linear\nIncrease\nand\nConstant\nLoad\nPattern\ncorresponds to the number of\
    \ requests per second\npattern that linearly increases during the ﬁrst half of\n\
    16This component also supports arbitrary application.\n17The autoscaling of the\
    \ containerized application is enabled via the\nKubernetes orchestration tool.\n\
    Multilayered autoscaling performance evaluation ...\n235\nthe test time and then\
    \ stabilizes for the rest of the\ntest.\n• Random Load Pattern corresponds to\
    \ the randomly\nincreasing and decreasing number of requests per\nsecond during\
    \ the test time.\n• Triangle Load Pattern corresponds to the number of\nrequests\
    \ per second pattern that linearly increases\nduring the ﬁrst half of the test\
    \ time and then\ndecreases with the same slope during the rest of the\ntest.\n\
    The user can conﬁgure the following parameters\nof the load pattern selected:\
    \ the number of concurrent\nclients, the maximal number of requests, the maximal\n\
    duration of a test, the request timeout, the HTTP request\nmethod, the request\
    \ body, the content type, and the\nnumber of requests per second.\nAutoscaler\
    \ Selection Component allows the user to pick\na supported autoscaling solution\
    \ from the list.\nA\nsingle-click functionality to deploy and undeploy an\nautoscaling\
    \ solution is also provided.\nVisualization Component shows plots and tables for\
    \ all the\nperformance metrics. The user can use these plots and\ntables to compare\
    \ the autoscaling solutions.\n4.3.\nSingle-layered autoscaler interface.\nScaleX\n\
    comprises interfaces to single-layered CSP native IaaS\nautoscaling solutions.\n\
    This\nmodule supports the\ndeployment process for different CSP native autoscaling\n\
    solutions.\nThe purpose of this module is to combine\nconﬁguration parameters\
    \ with the selected application and\nto deploy it using the chosen autoscaler.\
    \ Currently, 3 CSP\nnative autoscaling solutions are supported by ScaleX:\nGCE,\
    \ AWS, and Azure.\nThe following highlights the\ndeployment procedure of these\
    \ CSPs native autoscaling\nsolutions.\nGCE Autoscaler. A common VM instance template\n\
    is created with a start script to deploy the application on\na VM start. This\
    \ template is used as a basis to form the\nmanaged instance group. The GCE autoscaling\
    \ solution\nis conﬁgured using the parameters provided by the user.\nFollowing,\
    \ a load balancer is created to direct the load\nto the managed instance group.\
    \ Stackdriver logging and\nGCE monitoring are used to collect the metrics data\
    \ for\nthis group.\nAWS Autoscaler. At the starting point, an instance\nlaunch\
    \ conﬁguration is created with the same start script\nthat is used with the GCE\
    \ autoscaler to deploy the\napplication on a VM start. The launch conﬁguration\
    \ is\nused to form an Auto Scaling Group (ASG) in AWS Cloud\nusing the user parameters.\
    \ The scaling parameters and\npolicies are added to the ASG in the next step.\
    \ To direct\nthe load to this ASG, an Elastic Load Balancer (ELB)\nis added.\n\
    It serves as a single endpoint for the load\ngeneration workload—internally the\
    \ load is distributed\namong the ASG instances. AWS Cloud Watch is used to\ncollect\
    \ the metrics data for the whole ASG as well as for\nthe individual EC2 instances.\n\
    Azure Autoscaler. At the beginning, a customized\nVM image is created with a start\
    \ script to deploy the\napplication when the VM ﬁnishes booting. This image is\n\
    then used in the VM scale set for replication along with the\nuser-deﬁned autoscaling\
    \ conﬁguration parameters. The\nVM scale set serves the same purpose as the managed\n\
    instance group in GCE or an ASG in the AWS virtual\ninfrastructure. The load balancer\
    \ is also added. Azure\nmonitoring APIs are used to collect the metrics for the\n\
    VM scale set.\nFigure\n4\nshows\nthe\ndeployment\nto\ntest\nthe\nsingle-layered\
    \ virtual infrastructure autoscaling solution\nprovided by IaaS CSP.\nLoad \n\
    Balancer\nInstance 1\nInstance 2\nInstance N\n.\n.\n.\nCSP’s Monitoring \nService\n\
    CSP’s Scaling Group\nFig. 4. Deployment to test single-layered virtual infrastructure\n\
    autoscaling.\n4.4.\nMultilayered autoscaler interface.\nIn the scope\nof this\
    \ module, ScaleX combines CSP native IaaS\nautoscaling solutions with the Kubernetes\
    \ horizontal pod\nautoscaler to form a two-layered autoscaling solution.\nAdditionally,\n\
    the\nmodule\ncombines\nconﬁguration\nparameters with the selected application\
    \ and deploys\nin the selected IaaS cloud as a Kubernetes cluster.\nA\nmonitoring\
    \ service is attached as part of the deployment\nto collect the performance metrics\
    \ and store these data in\na database.\nA\nmultilayered\nautoscaler\nneeds\nto\n\
    enable\nsynchronization\nbetween\nautoscaling\nsolutions\non\ndifferent virtualization\
    \ layers.\nA sequence of actions\nis undertaken by the module in order to enable\
    \ the\nsynchronization. A separate VM instance is created for\nthe Kubernetes\
    \ master before starting the nodes (formerly\n236\nV. Podolskiy et al.\nknown\
    \ as minions) as part of a managed instance group\nin GCE, an ASG in AWS or a\
    \ VM scale set in Azure.\nSuch a conﬁguration allows scaling the nodes based\n\
    on the observed workload. ScaleX employs kubeadm18\nto deploy the Kubernetes cluster.\n\
    Kubeadm is used to\ninitialize the master. Once the master becomes ready, the\n\
    nodes can join it by running a speciﬁc command. A start\nscript is added as part\
    \ of the each CSP IaaS autoscaling\nsolution.\nThis start script is modiﬁed to\
    \ include all\nthe conﬁgurations and commands required by the VM\ninstance to\
    \ join the Kubernetes cluster. Hence, when a\nnew instance is created in a managed\
    \ instance group in\nGCE, an ASG in AWS or a VM scale set in Azure, it\nautomatically\
    \ joins the Kubernetes cluster.\nDuring the\nscale-in, a VM instance to be terminated\
    \ is removed\nsafely by the master from the Kubernetes cluster so that\nno further\
    \ pods are scheduled to run there, whereas the\npods that already run there are\
    \ rescheduled to run on other\nnodes. This mechanism adds the awareness of the\
    \ virtual\ninfrastructure about containerized virtualization with\npods, therefore\
    \ synchronization between layers hinders\npremature termination of the VM with\
    \ running pods by\nthe native autoscaling solution of the IaaS CSP.\nThe user\
    \ parameters are used to conﬁgure the\nKubernetes cluster along with the scaling\
    \ parameters\nand policies in the CSPs IaaS autoscaler.\nThe master\nIP-address\
    \ is used as a single endpoint for the generated\nworkload and internally the\
    \ master distributes the load\namong Kubernetes cluster nodes.\nFor the collection\n\
    of the metrics from the Kubernetes cluster, ScaleX\nuses Heapster19 coupled with\
    \ the InﬂuxDB.20 Both are\ndeployed in the cluster with the chosen application.\n\
    Metrics data are continuously fetched by ScaleX from\nboth Heapster (data about\
    \ the Kubernetes cluster) and the\nnative CSPs monitoring service (data for CSPs\
    \ instances\nand the autoscaling group), and stored in the database for\nvisualization\
    \ and analysis. Figure 5 shows the deployment\nto test the multilayered autoscaling\
    \ solution.\n4.5.\nLoad generator and monitoring.\nThis module\ngenerates the\
    \ workload of the desired pattern and\ndirects it to the IP address of the deployed\
    \ application.\nScaleX employs the customized version of Node.js-based\nLoadtest21\
    \ for load generation.\nThe number of clients\nthat generate the load and the\
    \ load generation time\nare conﬁgured for the selected load pattern.\nTo\nprevent\
    \ a single load generation node from becoming\nthe bottleneck, the module implements\
    \ the master-slave\narchitecture—the generation of the requests is distributed\n\
    18https://kubernetes.io/docs/setup/independent/\ncreate-cluster-kubeadm/.\n19https://github.com/kubernetes/heapster.\n\
    20https://www.influxdata.com/time-series-platf\norm/influxdb/.\n21https://www.npmjs.com/package/loadtest.\n\
    Load \nBalancer\nCSP’s Scaling Group\nInstance 1\nPod 1\nPod 2\nInstance 2\nPod\
    \ 3\nHPA\nCSP’s Monitoring Service\nKube Cluster Monitoring \nHeapster\nFig. 5.\
    \ Deployment to test multilayered autoscaling.\nMaster Load \nGenerator\nSlave\
    \ Load \nGenerator\nSlave Load \nGenerator\nSlave Load \nGenerator\nAutoscaler\n\
    Deployment in \nCloud\nDB\nFig. 6. Load generator architecture.\namong the slave\
    \ nodes. After completion of each request,\nthe performance results are sent back\
    \ to the master node\nand stored in the database. The monitoring part of the\n\
    component periodically fetches the data from different\nmonitoring services deployed\
    \ as part of the autoscaling\nsolutions and stores them in the database for further\n\
    performance analysis. Figure 6 depicts the architecture\nof the ScaleX load generator\
    \ module.\n4.6.\nDatabase.\nScaleX uses MongoDB to store the\nperformance data.\n\
    The reason to choose MongoDB\nas the storage for the performance data and generated\n\
    workload parameters is the support for high insert\nrates. The drawback, however,\
    \ is the missing transaction\nsafety, which in principle is not relevant for ScaleX.\n\
    An additional advantage of this NoSQL database is\nthat it supports storing measurements\
    \ with varying data\nschema as the monitoring solutions used to collect the\n\
    performance and requests data employ different data\nschemes.\nMultilayered autoscaling\
    \ performance evaluation ...\n237\n5.\nMultilayered autoscaling performance\n\
    evaluation\n5.1.\nExperimental setting.\nIn our experiments, we\nused all workload\
    \ patterns supported by ScaleX. The\ntotal time for each test was 20 minutes;\
    \ the request\ntimeout was 6.5 seconds.\nThe number of simulated\nconcurrent clients\
    \ for each load generation was 50;\nthey were deployed on a single VM instance\
    \ not\nparticipating in the experiment. For each pattern except\nfor random, the\
    \ start value of the request rate was 1\nrequest per second, whereas the increase/decrease\
    \ was\nset to 3. The random load pattern starts at 50 requests\nper second and\
    \ increases/decreases randomly.\nLoad\ngeneration is distributed among the concurrent\
    \ clients.\nThe computer-intensive test application computes the\nsum of prime\
    \ numbers between 1 and 1000000 when\ncalled. Executing this computation from\
    \ multiple clients\nincreases CPU utilization.\nHence we can observe the\nautoscaling\
    \ solution effect on the deployment.\nThe VM conﬁguration for experiments on different\n\
    clouds is provided in Table 1. The image of the operating\nsystem used in every\
    \ conﬁguration was Ubuntu 16.04\nLTS.\nTable 2 highlights the conﬁguration of\
    \ Kubernetes\nautoscaling. The target number of pods in a deployment\nor replication\
    \ controller is automatically adjusted based\non the formula\nNtgt.pods =\n\x04\
    \x05\npods Ucur.CPU\nUtgt.CPU\n\x06\n,\n(9)\nwhere \x05\npods Ucur.CPU is the\
    \ overall current pod CPU\nutilization and Utgt.CPU is a target CPU utilization.\n\
    Table 3 contains the conﬁguration settings for CSP native\nautoscalers.\nThe experiment\
    \ was conducted several times for\neach combination of autoscaling solutions using\
    \ the\nMultiple Consecutive Trials (MCT) methodology.\nAs\nthe results demonstrated\
    \ relative stability in performance\nand in scaling patterns, and we wanted to\
    \ highlight\nautoscaling behavioral features that might be lost by\naveraging,\
    \ we chose to show in the paper the results\nof a single experiment.\nIn the future,\
    \ ScaleX will\nbe extended to support the more accurate Randomized\nMultiple Interleaved\
    \ Trials (RMITs) methodology (Abedi\nand Brecht, 2017).\n5.2. Experimental results.\n\
    5.2.1.\nEvaluating the performance of multilayered\nautoscaling.\nAWS Auto Scaling\
    \ + Kubernetes. The data collected in\nthe scope of AWS Auto Scaling/Kubernetes,\
    \ experiment\ndemonstrate that the scale-out action conducted by the\nTable 1.\
    \ Experimental VM conﬁguration.\nCSP\nInstance type\nMemory\nvCPUs\nGCE\n–\n2\
    \ GB\n1 vCPU\nAWS\nt2.small\n2 GB\n1 vCPU\nAzure\nA1 V2 Standard\n2 GB\n1 vCPU\n\
    Table 2. Experimental conﬁguration:\nKubernetes autoscaling\nsolution.\nInstances\n\
    Min.\nMax.\nScaling\nThreshold\npods\npods\nmetric\n1(master)\n1\n10\nCPU\n20\
    \ %\n3(nodes)\nUtilization\nTable 3. Experimental conﬁguration: CSP autoscaling\
    \ solution.\nMin.\nMax.\nScaling\nThreshold\ninstances\ninstances\nmetric\n1\n\
    3\nCPU\n20 %\nUtilization\nnative AWS autoscaling solution lags the scale-out\
    \ action\nby Kubernetes which results in the deployment of new\npods on a single\
    \ VM (see rows B and C in Fig. 7).\nThis behavior indicates coordination problems\
    \ between\nmultiple virtualization layers. The lack of coordination\nleads to\
    \ the deployment of new pods on the old VM\ninstances whereas the newly added\
    \ VM could only have\na single pod (in particular, rows B and C in Fig. 7\nshow\
    \ that all the pods were started when the number\nof running VMs was 1). Such\
    \ a disproportion leads to\nload balancing issues and results in a latency increase,\
    \ as\nshown in row D. The scale-in times for AWS Auto Scaling\nare larger than\
    \ the scale-out times which is indicated\nby row C. A possible explanation is\
    \ that AWS Auto\nScaling conducts more time-consuming actions during the\ntermination\
    \ of the VM. In B-1 and B-3 the current number\nof pods is reduced, although Kubernetes\
    \ did not request\nthis.\nThe reason is that infrastructure scaling decided\n\
    to decommission VMs although pods were still running\nthere.\nMicrosoft Azure\
    \ Autoscale + Kubernetes.\nMicrosoft\nAzure Autoscale demonstrates the slowest\
    \ autoscaling\nbehavior (see row C in Fig. 8). Both scale-out and scale-in\ntimes\
    \ are signiﬁcantly larger than for GCE and AWS.\nBased on plots in rows D and\
    \ E, we can conclude that\nthe overall performance of a single Azure VM instance\n\
    is better than that of the competitors since with the\nlater scale-out (compared\
    \ with AWS and GCE) Azure\nis still able to keep the performance on par with other\n\
    tested conﬁgurations. The most probable cause could be\nthe newer hardware used\
    \ to host the VMs at Microsoft\ndatacenters. It is possible to notice in the Azure\
    \ graphs\nin rows B–E for all tested patterns that the performance\n238\nV. Podolskiy\
    \ et al.\n0\n500\n1000\n1500\n23:40\n23:45\n23:50\n23:55\n00:00\n00:05\n00:10\n\
    00:15\n00:20\nRequests (sent)\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n23:40\n23:45\n\
    23:50\n23:55\n00:00\n00:05\n00:10\n00:15\n00:20\nNumber of Kubernetes Pod Replicas\n\
    Type of replicas count\nCurrent replicas\nDesired replicas\n0\n1\n2\n3\n23:40\n\
    23:45\n23:50\n23:55\n00:00\n00:05\n00:10\n00:15\n00:20\nNumber of VM instances\n\
    Type of nodes count\nCurrent instances\nDesired instances\n0\n2500\n5000\n7500\n\
    10000\n23:40\n23:45\n23:50\n23:55\n00:00\n00:05\n00:10\n00:15\n00:20\nLatency,\
    \ ms\nType of latency\nMaximal Latency\nMean Latency\nMinimal Latency\n0\n500\n\
    1000\n1500\n23:40\n23:45\n23:50\n23:55\n00:00\n00:05\n00:10\n00:15\n00:20\nErrors\n\
    A\nB\nC\nD\nE\n0\n500\n1000\n1500\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n0\n1\n2\n\
    3\n0\n2500\n5000\n7500\n10000\n0\n500\n1000\n1500\n15:20\n15:25\n15:30\n15:35\n\
    15:40\n15:45\n15:50\n15:55\n16:00\n16:05\n15:20\n15:25\n15:30\n15:35\n15:40\n\
    15:45\n15:50\n15:55\n16:00\n16:05\n15:20\n15:25\n15:30\n15:35\n15:40\n15:45\n\
    15:50\n15:55\n16:00\n16:05\n15:20\n15:25\n15:30\n15:35\n15:40\n15:45\n15:50\n\
    15:55\n16:00\n16:05\n15:20\n15:25\n15:30\n15:35\n15:40\n15:45\n15:50\n15:55\n\
    16:00\n16:05\nType of replicas count\nCurrent replicas\nDesired replicas\nType\
    \ of nodes count\nCurrent instances\nDesired instances\nType of latency\nMaximal\
    \ Latency\nMean Latency\nMinimal Latency\n0\n500\n1000\n1500\n0\n1\n2\n3\n4\n\
    5\n6\n7\n8\n9\n10\n0\n1\n2\n3\n0\n2500\n5000\n7500\n10000\n0\n500\n1000\n1500\n\
    14:15\n14:20\n14:25\n14:30\n14:35\n14:40\n14:45\n14:50\n14:55\n15:00\n14:15\n\
    14:20\n14:25\n14:30\n14:35\n14:40\n14:45\n14:50\n14:55\n15:00\n14:15\n14:20\n\
    14:25\n14:30\n14:35\n14:40\n14:45\n14:50\n14:55\n15:00\n14:15\n14:20\n14:25\n\
    14:30\n14:35\n14:40\n14:45\n14:50\n14:55\n15:00\n14:15\n14:20\n14:25\n14:30\n\
    14:35\n14:40\n14:45\n14:50\n14:55\n15:00\nType of replicas count\nCurrent replicas\n\
    Desired replicas\nType of nodes count\nCurrent instances\nDesired instances\n\
    Type of latency\nMaximal Latency\nMean Latency\nMinimal Latency\n0\n500\n1000\n\
    1500\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n0\n1\n2\n3\n0\n2500\n5000\n7500\n10000\n\
    0\n500\n1000\n1500\n05:15\n05:20\n05:25\n05:30\n05:35\n05:40\n05:45\n05:50\n05:55\n\
    05:15\n05:20\n05:25\n05:30\n05:35\n05:40\n05:45\n05:50\n05:55\n05:15\n05:20\n\
    05:25\n05:30\n05:35\n05:40\n05:45\n05:50\n05:55\n05:15\n05:20\n05:25\n05:30\n\
    05:35\n05:40\n05:45\n05:50\n05:55\n05:15\n05:20\n05:25\n05:30\n05:35\n05:40\n\
    05:45\n05:50\n05:55\nType of replicas count\nCurrent replicas\nDesired replicas\n\
    Type of nodes count\nCurrent instances\nDesired instances\nType of latency\nMaximal\
    \ Latency\nMean Latency\nMinimal Latency\nFig. 7. Graphical representation of\
    \ the AWS/Kubernetes multilayered autoscaling solution. Columns (load patterns):\
    \ (ﬁrst) linearly\nincreasing, (second) linearly increasing and constant, (third)\
    \ random, (fourth) triangle. Rows: (A) total number of requests\nsent, (B) DAI\
    \ and CAI of Kubernetes pods, (C) DAI and CAI of AWS VM instances, (D) response\
    \ time, (E) requests failure\nrate.\nmostly depends on the underlying hardware\
    \ and on the\nscaling of Kubernetes pods, and not on the actual number\nof VMs.\n\
    Google Compute Engine (GCE) autoscaling + Kuber-\nnetes. Based on rows D and E\
    \ in Fig. 9, we can conclude\nthat the GCE/Kubernetes deployment exhibits the\
    \ best\nperformance. Looking deeper at row C, we can see a\ncause for such behavior—most\
    \ part of the experiment\ninterval is covered by scaled-out VM instances. If pod\n\
    replicas are distributed over more VMs, they can take a\nhigher load. However,\
    \ there is always a tradeoff between\nthe size of VMs, their number and the number\
    \ of pod\nreplicas. For example, an early VM scale-out will result\nin a cost\
    \ increase.\nThe experiments also show that\nGCE autoscaling is faster at making\
    \ scaling decisions and\nproviding VM instances than AWS and Azure in the scope\n\
    of the evaluated case. Additional VMs are added early\nand thus the new pods are\
    \ better distributed, which is\nillustrated by rows B and C.\nDiscussion.\nThe\
    \ comparison of the AWS, Azure, and\nGCE deployments for the tested case is conducted\
    \ using\ntwo metrics:\n(i) the amount of QoS violations, (ii)\nthe fraction of\
    \ the autoscaling interval where the QoS\nrequirements were violated.\nIn Tables\
    \ 4 and 5 we\nsummarize the number of QoS violations by a load\npattern. A response\
    \ time QoS requirement violation is\nidentiﬁed by the mean response time being\
    \ higher than\n6.5 s. The maximal failure rate QoS violation is arbitrarily\n\
    indicated by the amount of errors higher than 10. Table 6\ngoes into more details\
    \ on the multilayered autoscaling\nperformance of the studied deployments.\nThe\
    \ results in Tables 4 and 5 show that the\nGCE/Kubernetes\ndeployment\nin\nthe\n\
    tested\ncase\noutperforms both AWS and Azure.\nThe initial cause\nfor this is\
    \ the fast decision-making process for VMs\ninstances scale-out that allows distributing\
    \ the new\npods more or less evenly. However, with respect to the\namount of requests\
    \ ending up in an error, the results\nshow no clear leader. For example, the GCE/Kubernetes\n\
    deployment shows problems handling the Linear Increase\nand Random Load patterns\
    \ in the tested case. If we refer\nto the error plot E-2 in Fig. 9, we might notice\
    \ really\nsmall intervals with a high amount of errors.\nThe\nconclusion\nof\n\
    the\ncomparison\nmight\nbe\nformulated in such a way that the GCE/Kubernetes\n\
    deployment provides the best autoscaling performance\nMultilayered autoscaling\
    \ performance evaluation ...\n239\n0\n500\n1000\n1500\n07:05\n07:10\n07:15\n07:20\n\
    07:25\n07:30\n07:35\n07:40\nRequests (sent)\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\
    07:05\n07:10\n07:15\n07:20\n07:25\n07:30\n07:35\n07:40\nNumber of Kubernetes Pod\
    \ Replicas\nType of replicas count\nCurrent replicas\nDesired replicas\n0\n1\n\
    2\n3\n07:05\n07:10\n07:15\n07:20\n07:25\n07:30\n07:35\n07:40\nNumber of VM instances\n\
    Type of nodes count\nCurrent instances\nDesired instances\n0\n2500\n5000\n7500\n\
    10000\n07:05\n07:10\n07:15\n07:20\n07:25\n07:30\n07:35\n07:40\nLatency, ms\nType\
    \ of latency\nMaximal Latency\nMean Latency\nMinimal Latency\n0\n500\n1000\n07:05\n\
    07:10\n07:15\n07:20\n07:25\n07:30\n07:35\n07:40\nErrors\nA\nB\nC\nD\nE\n0\n500\n\
    1000\n1500\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n0\n1\n2\n3\n0\n2500\n5000\n7500\n\
    10000\n0\n500\n1000\n06:15\n06:20\n06:25\n06:30\n06:35\n06:40\n06:45\n06:50\n\
    06:55\n06:15\n06:20\n06:25\n06:30\n06:35\n06:40\n06:45\n06:50\n06:55\n06:15\n\
    06:20\n06:25\n06:30\n06:35\n06:40\n06:45\n06:50\n06:55\n06:15\n06:20\n06:25\n\
    06:30\n06:35\n06:40\n06:45\n06:50\n06:55\n06:15\n06:20\n06:25\n06:30\n06:35\n\
    06:40\n06:45\n06:50\n06:55\nType of replicas count\nCurrent replicas\nDesired\
    \ replicas\nType of nodes count\nCurrent instances\nDesired instances\nType of\
    \ latency\nMaximal Latency\nMean Latency\nMinimal Latency\n0\n500\n1000\n1500\n\
    0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n0\n1\n2\n3\n0\n2500\n5000\n7500\n10000\n0\n\
    500\n1000\n05:30\n05:35\n05:40\n05:45\n05:50\n05:55\n06:00\n05:30\n05:35\n05:40\n\
    05:45\n05:50\n05:55\n06:00\n05:30\n05:35\n05:40\n05:45\n05:50\n05:55\n06:00\n\
    05:30\n05:35\n05:40\n05:45\n05:50\n05:55\n06:00\n05:30\n05:35\n05:40\n05:45\n\
    05:50\n05:55\n06:00\nType of replicas count\nCurrent replicas\nDesired replicas\n\
    Type of nodes count\nCurrent instances\nDesired instances\nType of latency\nMaximal\
    \ Latency\nMean Latency\nMinimal Latency\n0\n500\n1000\n1500\n0\n1\n2\n3\n4\n\
    5\n6\n7\n8\n9\n10\n0\n1\n2\n3\n0\n2500\n5000\n7500\n10000\n0\n500\n1000\n01:10\n\
    01:15\n01:20\n01:25\n01:30\n01:35\n01:40\n01:10\n01:15\n01:20\n01:25\n01:30\n\
    01:35\n01:40\n01:10\n01:15\n01:20\n01:25\n01:30\n01:35\n01:40\n01:10\n01:15\n\
    01:20\n01:25\n01:30\n01:35\n01:40\n01:10\n01:15\n01:20\n01:25\n01:30\n01:35\n\
    01:40\nType of replicas count\nCurrent replicas\nDesired replicas\nType of nodes\
    \ count\nCurrent instances\nDesired instances\nType of latency\nMaximal Latency\n\
    Mean Latency\nMinimal Latency\nFig. 8. Graphical representation of the Azure/Kubernetes\
    \ multilayered autoscaling solution. Columns (load patterns): (ﬁrst) linearly\n\
    increasing, (second) linearly increasing and constant, (third) random, (fourth)\
    \ triangle. Rows: (A) total number of requests\nsent, (B) DAI and CAI of Kubernetes\
    \ pods, (C) DAI and CAI of Azure VM instances, (D) response time, (E) requests\
    \ failure\nrate.\nTable 4. Performance comparison based on the amount of re-\n\
    sponse time requirement QoS violations.\nLoad\nAmount of RT requirement violations\n\
    Pattern\nAWS\nAzure\nGCE\nLinear\nIncrease\n0\n0\n0\nLinear\nand\nCon-\nstant\n\
    17962\n40934\n250\nRandom\n1545\n2570\n1127\nTriangle\n6418\n15222\n76\nfor the\
    \ experimental case without careful selection of\nthe parameters for autoscaling\
    \ policy (e.g., the CPU\nthreshold).\nTable 6 summarizes parameters of all CSP\
    \ layer\nscale-out intervals. The column RTV represents a fraction\nof the autoscaling\
    \ interval with the violated response time\nrequirement, whereas MFRV represents\
    \ the same for the\nrequirement on the maximal failure rate. Since not all\nthe\
    \ deployments have exposed the clear synchronized\nTable 5. Performance comparison\
    \ based on the amount of max-\nimal failure rate QoS violations.\nLoad\nAmount\
    \ of MFR requirement violations\nPattern\nAWS\nAzure\nGCE\nLinear\nIncrease\n\
    0\n0\n382\nLinear\nand\nCon-\nstant\n25707\n42725\n1251\nRandom\n1720\n2570\n\
    1835\nTriangle\n9954\n16368\n845\nmultilayered behavior, the autoscaling performance\
    \ was\nevaluated only during the scaling of VM instance groups.\nWe can observe\
    \ a clear autoscaling performance\nproblem for Azure. It is not only the slowest,\
    \ but also\nexhibits more performance problems during the scaling\ntime. Scale-out\
    \ times of other deployments for all the\npatterns are mostly in the 5—30 second\
    \ interval, which\ncould be considered appropriate, although even these\ntimes\
    \ can exhibit performance problems (refer to high\n240\nV. Podolskiy et al.\n\
    0\n500\n1000\n1500\n21:20\n21:25\n21:30\n21:35\n21:40\n21:45\n21:50\n21:55\n22:00\n\
    22:05\nRequests (sent)\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n21:20\n21:25\n21:30\n\
    21:35\n21:40\n21:45\n21:50\n21:55\n22:00\n22:05\nNumber of Kubernetes Pod Replicas\n\
    Type of replicas count\nCurrent replicas\nDesired replicas\n0\n1\n2\n3\n21:20\n\
    21:25\n21:30\n21:35\n21:40\n21:45\n21:50\n21:55\n22:00\n22:05\nNumber of VM instances\n\
    Type of nodes count\nCurrent instances\nDesired instances\n0\n2500\n5000\n7500\n\
    10000\n21:20\n21:25\n21:30\n21:35\n21:40\n21:45\n21:50\n21:55\n22:00\n22:05\n\
    Latency, ms\nType of latency\nMaximal Latency\nMean Latency\nMinimal Latency\n\
    0\n100\n200\n21:20\n21:25\n21:30\n21:35\n21:40\n21:45\n21:50\n21:55\n22:00\n22:05\n\
    Errors\nA\nB\nC\nD\nE\n0\n500\n1000\n1500\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\
    0\n1\n2\n3\n0\n2500\n5000\n7500\n10000\n0\n100\n200\n05:15\n05:20\n05:25\n05:30\n\
    05:35\n05:40\n05:45\n05:50\n05:55\n06:00\n05:15\n05:20\n05:25\n05:30\n05:35\n\
    05:40\n05:45\n05:50\n05:55\n06:00\n05:15\n05:20\n05:25\n05:30\n05:35\n05:40\n\
    05:45\n05:50\n05:55\n06:00\n05:15\n05:20\n05:25\n05:30\n05:35\n05:40\n05:45\n\
    05:50\n05:55\n06:00\n05:15\n05:20\n05:25\n05:30\n05:35\n05:40\n05:45\n05:50\n\
    05:55\n06:00\nType of replicas count\nCurrent replicas\nDesired replicas\nType\
    \ of nodes count\nCurrent instances\nDesired instances\nType of latency\nMaximal\
    \ Latency\nMean Latency\nMinimal Latency\n0\n500\n1000\n1500\n0\n1\n2\n3\n4\n\
    5\n6\n7\n8\n9\n10\n0\n1\n2\n3\n0\n2500\n5000\n7500\n10000\n0\n100\n200\n01:25\n\
    01:30\n01:35\n01:40\n01:45\n01:50\n01:55\n02:00\n02:05\n02:10\n01:25\n01:30\n\
    01:35\n01:40\n01:45\n01:50\n01:55\n02:00\n02:05\n02:10\n01:25\n01:30\n01:35\n\
    01:40\n01:45\n01:50\n01:55\n02:00\n02:05\n02:10\n01:25\n01:30\n01:35\n01:40\n\
    01:45\n01:50\n01:55\n02:00\n02:05\n02:10\n01:25\n01:30\n01:35\n01:40\n01:45\n\
    01:50\n01:55\n02:00\n02:05\n02:10\nType of replicas count\nCurrent replicas\n\
    Desired replicas\nType of nodes count\nCurrent instances\nDesired instances\n\
    Type of latency\nMaximal Latency\nMean Latency\nMinimal Latency\n0\n500\n1000\n\
    1500\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n0\n1\n2\n3\n0\n2500\n5000\n7500\n10000\n\
    0\n100\n200\n23:50\n23:55\n00:00\n00:05\n00:10\n00:15\n00:20\n00:25\n00:30\n00:35\n\
    23:50\n23:55\n00:00\n00:05\n00:10\n00:15\n00:20\n00:25\n00:30\n00:35\n23:50\n\
    23:55\n00:00\n00:05\n00:10\n00:15\n00:20\n00:25\n00:30\n00:35\n23:50\n23:55\n\
    00:00\n00:05\n00:10\n00:15\n00:20\n00:25\n00:30\n00:35\n23:50\n23:55\n00:00\n\
    00:05\n00:10\n00:15\n00:20\n00:25\n00:30\n00:35\nType of replicas count\nCurrent\
    \ replicas\nDesired replicas\nType of nodes count\nCurrent instances\nDesired\
    \ instances\nType of latency\nMaximal Latency\nMean Latency\nMinimal Latency\n\
    Fig. 9. Graphical representation of the GCE/Kubernetes multilayered autoscaling\
    \ solution. Columns (load patterns): (ﬁrst) linearly\nincreasing, (second) linearly\
    \ increasing and constant, (third) random, (fourth) triangle. Rows: (A) total\
    \ number of requests\nsent, (B) DAI and CAI of Kubernetes pods, (C) DAI and CAI\
    \ of GCE VM instances, (D) response time, (E) requests failure\nrate.\nvalues\
    \ of RTV and MFRV for the 2nd AWS scale-out\ninterval for Linear Increase and\
    \ Constant).\nThe results shown in Table 6 indicate that the\nperformance issues\
    \ in the autoscaling solutions can be the\nreason for QoS violations. Making autoscaling\
    \ intervals\nsmaller and loosening thresholds in the autoscaling rules\ndo not\
    \ necessarily help to increase the performance of\nthe solution during autoscaling\
    \ as the old infrastructure\nremains exposed to the arriving requests. Moreover,\
    \ the\ntime necessary for the application services to become\navailable for the\
    \ requests was not taken into account.\n5.2.2.\nEvaluating the effect of the container\
    \ image\nsize and pulling policy on the scaling performance.\nCreation and termination\
    \ of microservice replicas is a\nmechanism that enables scaling on the containerized\n\
    application virtualization layer. With the differences in\nthe types of software\
    \ used inside the containers, the actual\nscaling time in the multilayered autoscaling\
    \ case may\ndiffer as the additional time is required to receive the\nimage that\
    \ is used to create the container. This difference\ncould be attributed to the\
    \ size of the image as well as\nits actual location. For example, many users prefer\
    \ to\nuse the centralized DockerHub repository of images. It\ncontains a vast\
    \ number of container images with different\nsoftware combinations. Therefore,\
    \ one needs to take into\naccount the time that will be required to get the container\n\
    image over the network considering the latency.\nThis\nissue is usually resolved\
    \ by adding a local repository with\nthe Docker container images. In this subsection\
    \ of the\npaper we tried to make a point that the parameters of\ncontainer images\
    \ and pulling policies can be responsible\nfor the changes in the scaling time\
    \ of the containerized\napplications.\nIn order to prove the hypothesis that the\
    \ pulling\npolicy and the container image size should be considered\nwhen\nstudying\n\
    the\nscaling\nof\nthe\ncontainerized\napplication, a small-scale experiment was\
    \ conducted\non 11 container images taken from Docker Hub.\nDuring the experiment,\
    \ the time between scheduling the\ncontainer and its start was measured. The measurements\n\
    were conducted multiple times for the Always Pull and If\nNot Present policies\
    \ for container images supported by\nKubernetes. The averaged results are provided\
    \ in Table 7.\nThe pulling time in the conducted experiment does\nnot give a clear\
    \ indication of the connection between the\npulling time when the image resides\
    \ on Docker Hub and\nits size, though, for example, the average pulling time for\n\
    Multilayered autoscaling performance evaluation ...\n241\nTable 6. Performance\
    \ of the AWS, Azure, and GCE autoscaling\nsolutions for scale-out events.\nLoad\n\
    Pattern\nCSP\nScale\n-out\nScale\n-out\ntime [s]\nRTV\nMFRV\nLinear\nAWS\n1st\n\
    28.06\n0.00\n0.00\nIncrease\n2nd\n9.03\n0.00\n0.00\nAzure\n1st\n128.00\n0.00\n\
    0.00\n2nd\n126.00\n0.00\n0.00\nGCE\n1st\n8.01\n0.00\n0.00\n2nd\n12.01\n0.00\n\
    0.00\nLinear\nAWS\n1st\n17.03\n0.00\n0.00\nIncrease\n2nd\n28.08\n0.73\n0.88\n\
    and\nAzure\n1st\n128.00\n0.85\n0.92\nConstant\n2nd\n123.00\n0.92\n0.94\nGCE\n\
    1st\n26.02\n0.00\n0.00\n2nd\n11.95\n0.02\n0.02\nRandom\nAWS\n1st\n33.08\n0.00\n\
    0.00\n2nd\n15.01\n0.00\n0.00\nAzure\n1st\n131.00\n0.00\n0.00\n2nd\n117.00\n0.00\n\
    0.00\nGCE\n1st\n11.01\n0.00\n1.00\n2nd\n7.99\n0.00\n0.00\nTriangle\nAWS\n1st\n\
    6.01\n0.00\n0.00\n2nd\n18.02\n0.00\n0.00\nAzure\n1st\n155.00\n0.86\n0.91\n2nd\n\
    128.00\n0.00\n0.00\nGCE\n1st\n7.98\n0.00\n0.00\n2nd\n8.01\n0.00\n0.00\nsix smallest\
    \ images is more than twice larger than the\naverage pulling time for ﬁve largest\
    \ images. The outlier\npulling times for the hello-world, python-alpine and java\n\
    images may be caused by the popularity of these images\nand the limited capacity\
    \ of Docker Hub. Though such\na small experiment does not provide a clear support\
    \ for\nthe initial hypothesis, it highlights the ﬂuctuations in the\npulling time,\
    \ which could be a reason for the slowdown\non the containerized application virtualization\
    \ layer. As\nexpected, in case of the locally present image, the pulling\ntime\
    \ is signiﬁcantly lower, staying in the interval between\n12 and 14 seconds for\
    \ the tested cases. A local container\nimages repository may increase the performance\
    \ of the\nmultilayered scaling though the additional resources will\nbe required\
    \ to establish such a conﬁguration.\n6.\nRelated works\nFundamental principles\n\
    of\nthe\nautoscaling\npolicies\nperformance\nevaluation\nwere\nintroduced\nby\n\
    Papadopoulos et al. (2016).\nThe researchers describe\nan autoscaling policy performance\
    \ evaluation approach\nTable 7. Docker image pulling time for different pulling\
    \ poli-\ncies: image present and image on Docker Hub.\nImage\nSize [Mb]\nPulling\n\
    Pulling\ntime [s]\ntime [s]\n(present)\n(Docker Hub)\nhello-world\n0.00185\n13\n\
    101\nredis\n27.8\n12\n66\nnodejs-alpine\n69.7\n13\n78\npython-alpine\n89.9\n13\n\
    234\nmongodb\n368\n13\n98\nmysql\n445\n12\n55\njava\n584\n14\n300\nnodejs\n674\n\
    14\n181\nr\n701\n14\n191\ngolang\n715\n14\n272\npython\n912\n14\n183\nbased on\
    \ a chance constrained optimization problem\nsolved using scenario theory.\nThe\
    \ approach was\nimplemented in Performance Evaluation Framework\nfor Auto-Scaling\
    \ (PEAS) and tested on several existing\nautoscaling policies using 796 real workload\
    \ traces. The\npaper also introduced several distinct metrics to evaluate\nthe\
    \ autoscaling performance with the core metrics of the\naverage number of under-\
    \ and over-provisioned resources.\nThe major contribution of the study by Ilyushkin\n\
    et al. (2017) is a set of performance metrics to\nestimate an autoscaling policy.\
    \ The set includes under-\nand\nover-provisioning\naccuracy,\nwrong-provisioning\n\
    timeshare, instability, as well as other user-oriented\nmetrics, e.g., wait time,\
    \ response time, elastic slowdown,\naverage number of resources, or average task\
    \ throughput.\nUpon\nthe\nlisted\nmetrics,\nthe\nauthors\nhave\nbuilt\nan approach\
    \ to compare autoscalers using pairwise\ncomparison,\nfractional\ndifference\n\
    comparison,\nand\naggregated elasticity, as well as some user metrics. The\ndeveloped\
    \ approach and the metrics were applied to\nselected existing autoscaling policies.\n\
    Although the\npresented approach and metrics allow comparing different\nautoscaling\
    \ policies, even the authors admit that the type\nof performance considered also\
    \ heavily relies on the type\nof application under consideration.\nThe technical\
    \ report by Versluis (2017) highlights\nfundamental\nresearch\nquestions\nregarding\n\
    the\nperformance of different autoscaling policies.\nThis\npaper may be viewed\
    \ as a comprehensive extension\nof the one by Ilyushkin et al.\n(2017).\nUsing\
    \ four\ndifferent workloads from scientiﬁc,\nindustrial,\nand\nengineering domains,\
    \ the authors were able to prove that\nthe application domain actually heavily\
    \ inﬂuences the\nquality of the autoscaling results.\nThe performance estimation\
    \ approach presented\nby Evangelidis et al. (2017) is based on probabilistic\n\
    242\nV. Podolskiy et al.\ndiscrete-time Markov chain model checking.\nThe\nchecking\
    \ is conducted using the PRISM tool, which is\na probabilistic model checker for\
    \ the formal modeling\nand analysis of systems with random or probabilistic\n\
    behavior.\nEach policy is encoded in the PRISM tool\nwith a set of user-deﬁned\
    \ model parameters.\nBy\nspecifying the auto-scaling policy, the model parameters,\n\
    and running PRISM, the user would be able to obtain\nthe estimates of the probability\
    \ that various estimated\nperformance parameters are lying in speciﬁed intervals\
    \ for\ndifferent values of model parameters. The identiﬁed most\nappropriate values\
    \ of model parameters could be used to\nadjust the autoscaling policy. The authors\
    \ also conducted\nthe validation of the study by using the AWS public cloud\n\
    testbed and ROC analysis.\nHwang\net\nal.\n(2016)\noutlined\nthe\ngeneric\nperformance\
    \ model for clouds of\nany\ntype.\nIt\nencompasses a total of 19 metrics divided\
    \ into 3\nabstraction levels:\nbasic performance metrics, cloud\ncapabilities,\
    \ cloud productivity.\nMultiple metrics were\napplied to comprehensively estimate\
    \ the performance of\nscale-out, scale-up, and mixed scaling modes on some\nreal-world\
    \ benchmarks and on the public cloud providers.\nThe presented works concentrate\
    \ on the evaluation of\nautoscaling on the level of virtual machines. These works\n\
    also consider the evaluation of policies and not of the\nimplementation of autoscaling\
    \ in commercial clouds. Our\napproach extends the works towards multiple autoscaling\n\
    layers and investigates the important aspect of overheads\nof real implementations.\n\
    7.\nConclusion and future work\nIn this paper we tried to summarize our theoretical\n\
    understanding of the autoscaling area and shed the light\non performance evaluation\
    \ for multilayered autoscaling\nsolutions.\nThe paper incorporates the methodology\n\
    and tools originally presented by Jindal et al. (2017).\nThe multilayered autoscaling\
    \ performance evaluation\nmethodology and ScaleX were applied in the scope of\
    \ the\npaper to enable the comparison of several multilayered\nautoscaling solutions\
    \ based on the virtual infrastructure\nprovided by public CSPs.\nThe results of\
    \ the conducted comparison show that\nfor multilayered autoscaling the performance\
    \ is not only\ndetermined by the time taken for autoscaling but rather\nalso by\
    \ the time that the decision to scale takes, by the\nreal hardware underlying\
    \ VM instances, and by the degree\nof synchronization between autoscaling on different\n\
    virtualization layers.\nWith the unadjusted autoscaling\npolicies, the GCE/Kubernetes\
    \ solution showed the best\noverall performance on the tested case which could\n\
    mostly be attributed to the overprovisioning of VMs.\nAdditionally, with another\
    \ small experiment, the inﬂuence\nof the container image pulling time on the autoscaling\n\
    quality was highlighted in the paper.\nThe study indicated several future work\
    \ directions.\nThe addition of support for the Randomized Multiple\nInterleaved\
    \ Trials (RMITs) testing methodology (Abedi\nand Brecht, 2017) to ScaleX will\
    \ increase the accuracy\nof the evaluations made using the tool.\nThe support\n\
    for automated autoscaling policies testing with the\nspecialized metrics given\
    \ by ScaleX (?)\nwill extend\nthe evaluation capabilities of the tool allowing\
    \ evaluation\nof both autoscaling solutions and policies. By making\nload generation\
    \ in ScaleX more ﬂexible (generating\nthe load based on data from logs and traces),\
    \ the\nbehaviour of autoscaling solutions could be studied in\nconditions close\
    \ to industrial cases. Yet another necessary\nstep would be the extension of ScaleX’s\
    \ functionality\nto support the evaluation of vertical autoscaling and\nautoscaling\
    \ in hybrid cloud environments. With all these\npossible extensions, ScaleX may\
    \ ﬁnd use even in business\nenvironments willing to test scaling capabilities\
    \ of the\nvirtual infrastructure and the containerized application\nto ﬁnd out\
    \ the scaling bottlenecks and get rid of them.\nAddition of the recommending service\
    \ to the evaluation\ntool may allow the user to receive insights from ScaleX\n\
    on how autoscaling solutions should be set or which\nautoscaling policy should\
    \ be selected.\nBy implementing these extensions in ScaleX and\nfurther polishing\
    \ the evaluation methodology, we aim to\ncontinue testing autoscaling capabilities\
    \ of the existing\nsolutions in different settings.\nSuch tests will enable\n\
    us to better understand the complex area of elastic\ncloud applications. Nevertheless,\
    \ the provided approach\nmay become inappropriate for the serverless paradigm.\n\
    Function-as-a-Service (FaaS) tries to hide the elasticity\nof the virtual infrastructure\
    \ from the user highlighting\nonly scaling on the application level by changing\
    \ the\nnumber of function instances backed with the change in\nthe number of running\
    \ containers (Lloyd et al., 2018).\nAdapting the autoscaling solution performance\
    \ evaluation\nmethodology to this paradigm may become another\nchallenging research\
    \ direction.\nThe\nnext\nimportant\nstep\nis\nto\nidentify\nthe\ninfrastructure\
    \ and application parameters that inﬂuence\nthe quality of scaling. Yet another\
    \ barely covered research\nproblem is the inﬂuence of the application structure\
    \ on the\nactual scaling capabilities of the application. The research\nin this\
    \ area may uncover the particular microservice\napplication structures that have\
    \ a bigger scaling potential\nthan the other applications.\n8.\nAvailability\n\
    The source code of ScaleX and the video manual are\navailable in the Git repository\
    \ at https://github.c\nom/ansjin/ScaleX.\nMultilayered autoscaling performance\
    \ evaluation ...\n243\nAcknowledgment\nThe authors would like to express their\
    \ gratitude to the\nanonymous reviewers of the paper, who provided their\nvaluable\
    \ comments to improve the contribution.\nThis\nwork was supported by the German\
    \ Research Foundation\n(DFG) and the Technical University of Munich within the\n\
    funding programme Open Access Publishing.\nReferences\nAbedi, A. and Brecht, T.\
    \ (2017).\nConducting repeatable\nexperiments\nin\nhighly\nvariable\ncloud\ncomputing\n\
    environments, Proceedings of the 8th ACM/SPEC on\nInternational Conference on\
    \ Performance Engineering,\nICPE’17, L’Aquila, Italy, pp. 287–292.\nAl-Dhuraibi,\
    \ Y., Paraiso, F., Djarallah, N. and Merle, P. (2017).\nAutonomic vertical elasticity\
    \ of docker containers with\nelasticdocker, 2017 IEEE 10th International Conference\n\
    on Cloud Computing (CLOUD), Honolulu, HI, USA,\npp. 472–479.\nBauer, A., Herbst,\
    \ N. and Kounev, S. (2017).\nDesign and\nevaluation of a proactive, application-aware\
    \ auto-scaler:\nTutorial paper, Proceedings of the 8th ACM/SPEC on\nInternational\
    \ Conference on Performance Engineering,\nICPE’17, L’Aquila, Italy, pp. 425–428.\n\
    Bondi, A.B. (2000).\nCharacteristics of scalability and their\nimpact on performance,\
    \ Proceedings of the 2nd Interna-\ntional Workshop on Software and Performance,\
    \ WOSP’00,\nOttawa, Canada, pp. 195–203.\nEvangelidis,\nA.,\nParker,\nD.\nand\n\
    Bahsoon,\nR.\n(2017).\nPerformance modelling and veriﬁcation of cloud-based\n\
    auto-scaling policies, Proceedings of the 17th IEEE/ACM\nInternational Symposium\
    \ on Cluster, Cloud and Grid Com-\nputing, CCGrid’17, Madrid, Spain, pp. 355–364.\n\
    Guo, Y., Stolyar, A. and Walid, A. (2018).\nOnline VM\nauto-scaling algorithms\
    \ for application hosting in a cloud,\nIEEE Transactions on Cloud Computing, pp.\
    \ 1–1, (early\naccess), https://ieeexplore.ieee.org/docum\nent/8351912.\nHerbst,\
    \ N.R., Kounev, S. and Reussner, R. (2013). Elasticity in\ncloud computing: What\
    \ it is, and what it is not, Proceed-\nings of the 10th International Conference\
    \ on Autonomic\nComputing (ICAC 13), San Jose, CA, USA , pp. 23–27.\nHwang, K.,\
    \ Bai, X., Shi, Y., Li, M., Chen, W.G. and Wu,\nY. (2016). Cloud performance modeling\
    \ with benchmark\nevaluation of elastic scaling strategies, IEEE Transactions\n\
    on Parallel and Distributed Systems 27(1): 130–143.\nIlyushkin,\nA.,\nAli-Eldin,\n\
    A.,\nHerbst,\nN.,\nPapadopoulos,\nA.V.,\nGhit,\nB.,\nEpema,\nD. and Iosup,\nA.\
    \ (2017).\nAn experimental performance evaluation of autoscaling\npolicies for\
    \ complex workﬂows, Proceedings of the 8th\nACM/SPEC on International Conference\
    \ on Performance\nEngineering, ICPE’17, L’Aquila, Italy, pp. 75–86.\nJakobik,\
    \ A., Grzonka, D. and Kolodziej, J. (2017).\nSecurity\nsupportive energy aware\
    \ scheduling and scaling for cloud\nenvironments, European Conference on Modelling\
    \ and\nSimulation, ECMS 2017, Budapest, Hungary, pp. 583–590.\nJindal, A., Podolskiy,\
    \ V. and Gerndt, M. (2017). Multilayered\ncloud applications autoscaling performance\
    \ estimation,\n2017 IEEE 7th International Symposium on Cloud and\nService Computing\
    \ (SC2), Kanazawa, Japan, pp. 24–31.\nVersluis,\nL. and Neacsu,\nA.I. (2017).\n\
    A trace-based\nperformance study of autoscaling workloads of workﬂows\nin datacenters,\
    \ Technical Report 1711.08993v1, Vrije\nUniversiteit Amsterdam, Amsterdam.\nLiu,\
    \ Y., Rameshan, N., Monte, E., Vlassov, V. and Navarro, L.\n(2015). Prorenata:\
    \ Proactive and reactive tuning to scale a\ndistributed storage system, 2015 15th\
    \ IEEE/ACM Interna-\ntional Symposium on Cluster, Cloud and Grid Computing,\n\
    Shenzen, China, pp. 453–464.\nLloyd, W., Ramesh, S., Chinthalapati, S., Ly, L.\
    \ and Pallickara,\nS. (2018).\nServerless computing:\nAn investigation of\nfactors\
    \ inﬂuencing microservice performance, 2018 IEEE\nInternational Conference on\
    \ Cloud Engineering (IC2E),\nOrlando, FL, USA, pp. 159–169.\nMoore, L.R., Bean,\
    \ K. and Ellahi, T. (2013).\nTransforming\nreactive auto-scaling into proactive\
    \ auto-scaling, Proceed-\nings of the 3rd International Workshop on Cloud Data\n\
    and Platforms, CloudDP’13, Prague, Czech Republic,\npp. 7–12.\nNikravesh, A.Y.,\
    \ Ajila, S.A. and Lung, C.-H. (2015). Towards\nan autonomic auto-scaling prediction\
    \ system for cloud\nresource provisioning, Proceedings of the 10th Interna-\n\
    tional Symposium on Software Engineering for Adaptive\nand Self-Managing Systems,\
    \ SEAMS’15, Florence, Italy,\npp. 35–45.\nPapadopoulos, A.V., Ali-Eldin, A., Arzen,\
    \ K.-E., Tordsson,\nJ. and Elmroth, E. (2016).\nPEAS: A performance\nevaluation\
    \ framework for auto-scaling strategies in cloud\napplications, ACM Transactions\
    \ on Modeling and Perfor-\nmance Evaluation of Computing Systems 1(4): 15:1–15:31.\n\
    Roy, N., Dubey, A. and Gokhale, A. (2011).\nEfﬁcient\nautoscaling in the cloud\
    \ using predictive models for\nworkload forecasting, 2011 IEEE 4th International\
    \ Con-\nference on Cloud Computing, Washington, DC, USA,\npp. 500–507.\nSotomayor,\
    \ B., Montero, R.S., Llorente, I.M. and Foster, I.\n(2009a).\nResource leasing\
    \ and the art of suspending\nvirtual machines, Proceedings of the 2009 11th IEEE\n\
    International Conference on High Performance Comput-\ning and Communications,\
    \ HPCC’09, Seoul, South Korea,\npp. 59–68.\nSotomayor, B., Montero, R.S., Llorente,\
    \ I.M. and Foster, I.\n(2009b). Virtual infrastructure management in private and\n\
    hybrid clouds, IEEE Internet Computing 13(5): 14–22.\n244\nV. Podolskiy et al.\n\
    Vladimir Podolskiy is a PhD student at TUM\nand a DAAD scholar. His research interests\
    \ are\nin the area of predictive cloud applications, au-\ntoscaling, evaluation\
    \ of autoscaling solutions and\nscalable middleware for the Internet of things.\
    \ He\ngraduated in 2014 from Bauman Moscow State\nTechnical University (BMSTU),\
    \ Russia. Prior to\nstarting his PhD, he had worked for several years\nat IBS\
    \ Group as an analyst and a software archi-\ntect.\nAnshul Jindal is a PhD student\
    \ at TUM. His\nresearch interests include cloud computing, au-\ntoscaling and\
    \ performance predictions of mi-\ncroservices. He completed his MSc in informat-\n\
    ics in 2018 at TUM, Germany. Prior to starting\nhis studies, he had worked for\
    \ 2 years at Samsung\nResearch Institute in Bangalore, India, as a senior\nsoftware\
    \ engineer.\nMichael Gerndt received a PhD in computer sci-\nence in 1989 from\
    \ the University of Bonn. In\n1990 and 1991, he held a postdoc position at\nthe\
    \ University of Vienna, and joined Julich Re-\nsearch Centre in 1992. He habilitated\
    \ in 1998\nat the Technical University of Munich (TUM).\nSince 2000 he has been\
    \ a professor of archi-\ntecture of parallel and distributed systems there.\n\
    His research focuses on resources management in\ncloud environments and on programming\
    \ models\nand tools for scalable parallel architectures.\nReceived: 18 July 2018\n\
    Revised: 12 December 2018\nAccepted: 1 February 2019\n"
  inline_citation: '>'
  journal: International Journal of Applied Mathematics and Computer Science
  limitations: '>'
  pdf_link: https://content.sciendo.com/downloadpdf/journals/amcs/29/2/article-p227.pdf
  publication_year: 2019
  relevance_score1: 0
  relevance_score2: 0
  title: 'Multilayered Autoscaling Performance Evaluation: Can Virtual Machines and
    Containers Co–Scale?'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1016/j.future.2020.03.060
  analysis: '>'
  authors:
  - Gor Mack Diouf
  - Halima Elbiaze
  - Wael Jaafar
  citation_count: 10
  full_citation: '>'
  full_text: '>

    Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords 1. Introduction 2. Background 3. Kubernetes:
    An open-access orchestrator of docker containers 4. Fault tolerance in kubernetes
    5. Kmmr: A k8s multi-master robust platform 6. Experimental evaluation 7. Conclusion
    Declaration of Competing Interest Acknowledgment References Vitae Show full outline
    Cited by (15) Figures (13) Show 7 more figures Tables (2) Table 1 Table 2 Future
    Generation Computer Systems Volume 109, August 2020, Pages 407-419 On Byzantine
    fault tolerance in multi-master Kubernetes clusters Author links open overlay
    panel Gor Mack Diouf a, Halima Elbiaze a, Wael Jaafar b Show more Add to Mendeley
    Share Cite https://doi.org/10.1016/j.future.2020.03.060 Get rights and content
    Highlights • Docker, Kubernetes. • DDoS attack, Byzantine Faults. • Raft protocol,
    BFT-SMaRt. • State machine replication. Abstract Docker container virtualization
    technology is being widely adopted in cloud computing environments because of
    its lightweight and efficiency. However, it requires adequate control and management
    via an orchestrator. As a result, cloud providers are adopting the open-access
    Kubernetes platform as the standard orchestrator of containerized applications.
    To ensure applications’ availability in Kubernetes, the latter uses Raft protocol’s
    replication mechanism. Despite its simplicity, Raft assumes that machines fail
    only when shutdown. This failure event is rarely the only reason for a machine’s
    malfunction. Indeed, software errors or malicious attacks can cause machines to
    exhibit Byzantine (i.e. random) behavior and thereby corrupt the accuracy and
    availability of the replication protocol. In this paper, we propose a Kubernetes
    multi-Master Robust (KmMR) platform to overcome this limitation. KmMR is based
    on the adaptation and integration of the BFT-SMaRt fault-tolerant replication
    protocol into Kubernetes environment. Unlike Raft protocol, BFT-SMaRt is resistant
    to both Byzantine and non-Byzantine faults. Experimental results show that KmMR
    is able to guarantee the continuity of services, even when the total number of
    tolerated faults is exceeded. In addition, KmMR provides on average a consensus
    time 1000 times shorter than that achieved by the conventional platform (with
    Raft), in such condition. Finally, we show that KmMR generates a small additional
    cost in terms of resource consumption compared to the conventional platform. Previous
    article in issue Next article in issue Keywords Cloud computingDocker containersKubernetesByzantine
    and non-Byzantine faultsFault toleranceService continuity 1. Introduction Faced
    with the continuous increase in capital expenditure and operating expenditure
    costs of fully reliable and available Information Technology (IT) systems, companies
    tend towards outsourcing their IT services to specialized companies such as cloud
    service providers. The main advantage of this strategy is to claim an excellent
    service quality while paying only for the necessary and consumed resources. As
    for the service provider, its purpose is to meet the needs of clients by providing
    the required resources when demanded. A common approach is to pool (or slice)
    its resources to share them between several clients. In this context, many challenges
    emerge to provide a reliable cloud environment, e.g., quality-of-service guarantee,
    resources management, and service continuity. In order to exploit efficiently
    the service provider’s resources, the virtualization technology has been introduced
    [1], [2]. The latter allows the services to see the resources, e.g., servers,
    routers, communication links, and data storage, in a manner that is independent
    from the physical infrastructure/equipment, and to use these resources based on
    service requirements, rather than on physical granularity. In particular, servers
    virtualization using containers, called also containerization, has gained popularity
    among cloud service providers, since it addresses issues, such as the inefficient
    use of resources [3], [4]. Unlike full-hardware virtualization, such as VMware
    [1], containerization leverages virtualization at the operating system level,
    hence generating a lighter overhead. In such system, the resource allocation unit
    is the container. The latter is defined as the virtual runtime environment running
    atop a single operating system kernel and emulating an operating system. Several
    implementation platforms are available for containerization, such as LXC, OpenVZ
    and Docker [3], [4], [5]. Nevertheless, Docker stands out as the most interesting
    container-based virtualization platform as it provides the simplest lightweight
    and scalable way of creating and deploying containers, besides its large spectrum
    of use cases, including hybrid clouds [6], microservices [7], infrastructure optimization
    [8] and big data [9]. In a container-based server platform, containerized applications
    need to be managed, i.e., a container hosting an application is dynamically deployed,
    run, then removed. The management of these operations in a container-based virtualization
    platform is called Containers Orchestration. Containers Orchestration is a complex
    task that requires a very light but efficient mechanism for automated deployment,
    scaling, and management of containers. For instance, to efficiently manage Docker
    containers, cloud service providers such as Google, Docker, Mesosphere, Microsoft,
    VMware, IBM and Oracle adopted Kubernetes as their standard platform to orchestrate
    containerized applications [11], [12], [13]. Kubernetes is a Google open project
    advocating the vision of a modular, customizable and therefore scalable orchestration
    platform [3]. In order to guarantee the availability and continuity of hosted
    applications, Kubernetes uses the Raft protocol. The latter replicates the states
    between the machines hosting the containers, where each state is an image of the
    hosted containerized applications [14], [15]. In spite of its simplicity and rapidity
    in the replication process, Raft protocol has major limitations when it comes
    to machines’ failure. Indeed, Raft can only detect and correctly deal with shutdown
    events of machines. In other words, if a machine experiences a Byzantine (random)
    behavior, Raft is unable to guarantee service continuity [15], [16], [17]. Indeed,
    Byzantine behaviors, such as delayed, dropped, or corrupted messages, or abnormally
    executed processes have been widely observed in real systems, as summarized in
    [18]. Download : Download high-res image (621KB) Download : Download full-size
    image Fig. 1. From virtual machines to containers [10]. Being conscious of the
    risks of software errors and malicious attacks that can push a machine into a
    Byzantine behavior, we propose in this paper the adaptation and integration of
    the BFT-SMaRt fault-tolerant replication protocol into Kubernetes. By doing so,
    we expect our proposed platform to resist to any type of faults while guaranteeing
    service continuity. To the best of our knowledge, this is the first work that
    proposes a Kubernetes platform tolerant to Byzantine and non-Byzantine faults.
    The main contributions of this paper are summarized as follows: 1. We present
    an overview of Docker virtualization, Kubernetes platform, fault-tolerance within
    this platform and its limits. 2. We propose the Kubernetes multi-Master Robust
    (KmMR) platform, a platform tolerant to Byzantine and non-Byzantine faults. KmMR
    is based on the integration of BFT-SMaRt into Kubernetes environment. 3. We propose
    an efficient method to adapt and integrate the replication protocol BFT-SMaRt
    (written in Java) into Kubernetes (written in Golang). 4. We implement the proposed
    KmMR solution in an OpenStack-based cloud environment, evaluate its performances
    and compare it to the conventional platform, called Kubernetes multi-Master Conventional
    (KmMC). Comparison is realized through experiments in non-Byzantine and Byzatine
    environments, where both crash and Distributed Denial-of-Service (DDoS) attacks
    are performed to destabilize the machines and corrupt their replication process.
    The obtained results confirm the effectiveness and robustness of KmMR. The rest
    of the paper is organized as follows. Section 2 describes Docker containerization
    technology. In Section 3, the Docker containers orchestration platform Kubernetes
    is explained. Whereas, Section 4 discusses fault-tolerance in Kubernetes. Section
    5 presents our KmMR platform. Experimental evaluation and results are discussed
    in Section 6. Finally, Section 7 closes the paper. 2. Background In this section,
    we present an overview of Docker containers and its orchestration mechanism, supported
    by Kubernetes. 2.1. Docker containers Container virtualization, also known as
    containerization, relies directly on kernel functionalities to create isolated
    virtual environments, as illustrated in Fig. 1. These virtual environments are
    named containers, while the features provided by the operating system kernel are
    called namespaces and cgroups [19]. The namespaces control and limit the amount
    of resources used for a process, while the cgroups manage the resources of a process
    group. Hence, a container provides the resources needed to run applications as
    if they were the only processes running in the host machine’s operating system.
    Even though several containerization platforms have been proposed, such as LXC,
    OpenVZ and Docker [3], [4], [5], only Docker sparked interest and popularity among
    the research and professional communities thanks to its operational simplicity
    and flexibility. Indeed, traditional virtualization uses a Hypervisor to create
    virtual machines, deploy guest operating systems on them, and host the applications
    [20]. Whereas, Docker containerization requires only the installation of the Docker
    container engine on the operating system’s kernel of the host machine, allowing
    the creation of containers that host the applications. Nevertheless, both are
    autonomous systems that use a higher system, i.e., the one of the host machine,
    to perform their tasks. The difference is that virtual machines must contain a
    whole guest operating system, while the containers use directly the one of the
    host machine. Fig. 1 illustrates an architectural comparison of traditional virtualization
    and containerization. Docker is a complex but very intuitive ecosystem for container
    development. It is mainly composed of six elements, as shown in Fig. 2: Download
    : Download high-res image (345KB) Download : Download full-size image Fig. 2.
    Components of Docker [10]. 1. Docker Client: It is the command line interface
    tool used to configure and interact with Docker. For any Docker command instruction
    (e.g.,  ), the client sends the command to Docker daemon ( ) that carries it out.
    2. Docker Daemon: It is the Docker server that listens to the application programming
    interface requests and manages Docker objects, such as images, containers, networks,
    and volumes, etc. 3. Docker Images: An image is a read-only template/snapshot,
    pulled or pushed from a public or a private repository, in order to create a Docker
    container. This is the building block of Docker. It is lightweight, small, and
    fast compared to those of traditional virtual machines. 4. Docker file: It is
    used to build Docker images. 5. Docker Containers: Basically, a Docker container
    is a user space of the operating system. It is composed of a set of processes
    isolated from the rest of the system, and running from an image that provides
    necessary files to support the processes of the hosted application. 6. Docker
    registries: Registries are the central repository and distribution component of
    Docker images. 7. Docker Engine: It combines the Docker daemon, application programming
    interface and the command line interface tools. By its simplicity and small number
    of components, the Docker architecture provides interesting advantages [21], [22],
    [23]: 1. Deployment rapidity: Docker achieves fast operations, such as communication,
    and container building, testing and deployment. 2. Applications Portability: Containerized
    applications are easily portable, as they can be moved around as a single unit,
    without affecting their response performances or the containers. 3. Fast service
    delivery: Docker containers format is standardized, such that programmers and
    administrators tasks do not interfere when deploying them. Indeed, Docker provides
    a reliable, consistent, and enhanced environment that achieves predictable outputs
    when codes are moved between development, test and deployment platforms. 4. Density:
    Docker uses the available resources more efficiently compared to virtual machines,
    since it does not rely on a Hypervisor. It is able to run densely several containers
    on the same single host, hence optimally using the resources and increasing its
    performance, compared to virtual machines. 5. Scalability: Docker can be deployed
    in several physical servers, data servers, and cloud platforms without any restriction.
    Containers can be easily moved from a cloud environment to a local host and vice-versa,
    at a fast pace. Deployment adjustments can be easily realized according to needs.
    In Table 1, we summarize the characteristics of virtual machines and Docker containers.
    Accordingly, the Docker container can be created and removed almost in real time
    and thus introduces a negligible task overload with respect to the host machine’s
    resources use [22], [24], [25]. Compared to virtual machines, Docker containers
    are advantageous in terms of network management, boot speed, deployment/migration
    flexibility, and resources use, e.g. RAM, storage, etc. [22]. However, they suffer
    from the weak isolation of the host machine. Indeed, if a Docker container is
    compromised, then an attacker can get full access to the operating system of the
    host machine [26], [27]. Consequently, there is an urgent need for a robust and
    secured environment for Docker containers. Moreover, Docker is unable on its own
    to deploy containers on distributed machines and ensure their interaction [26].
    In this matter, an orchestration mechanism is needed to manage Docker containers
    in distributed systems. Table 1. Characteristics of virtualization technologies.
    Parameters Virtual machines Docker containers Operating System Every virtual machine
    virtualizes the host material and loads its own guest operating system No container
    emulates host material. Host operating system is used. Communication Through Ethernet
    peripherals Through Inter-Process Communication standard mechanisms, e.g., sockets,
    pipes, shared memory, etc. Resources Usage (CPU and RAM) High Quasi-native Startup
    time Few minutes Few seconds Storage High requirement for guest operating system
    and associated software installation and execution Low since host operating system
    is used Isolation Libraries and files’ sharing among virtual machines is impossible
    Libraries and files can be seamlessly mounted and shared Security Depends on the
    Hypervisor’s configuration Requires access control 2.2. Containers orchestration
    Handling a few Docker containers on one machine is an easy task. However, when
    it comes to moving these containers into production on a set of distributed hosts,
    many questions arise. Indeed, driven by providing availability, scaling, and networking,
    an integration and management tool is required not only to ensure initial containers
    deployment, but to also manage multiple and dynamic containers as one entity.
    Clearly, handling everything manually is not conceivable because it would be very
    difficult to ensure the viability, maintenance and sustainability of the system.
    Thus, the process of deploying multiple containers can be optimized through automation,
    especially in large scale systems. This type of automation is referred to as orchestration
    and includes features like work nodes’ location determination, load balancing,
    inter-container communication, service discovery, status updates, containers migrations,
    scaling up, and tolerance to malfunctions. Several orchestrators have been proposed
    and implemented to manage Docker container-based platforms. Examples include Fleet
    [28], Mesos [29], Swarm [30] and Kubernetes [31]. In the remainder of this paper,
    we are interested in Kubernetes only. The latter is a stable and free solution
    that can automate the deployment, migration, monitoring, networking, scalability,
    and availability of applications hosted in container-based server platforms [4],
    [12]. 3. Kubernetes: An open-access orchestrator of docker containers Kubernetes,
    abbreviated K8s, is a project initiated by Google in 2014 when it saw the advantages
    of Docker containers over traditional virtualization. The Kubernetes Orchestrator
    automates the deployment and management of large-scale containerized applications,
    such as applications’ microservices generation [7], cloud services to store, access,
    edit and share video content [32], and mission critical services as telecommunications
    and energy delivery services [33], [34]. Its platform runs and coordinates containers
    on sets of physical and/or virtual machines. Kubernetes is designed to fully manage
    the life cycle of containerized applications, using predictability, extensibility,
    and high availability methods, as detailed in [35], [36]. Download : Download
    high-res image (372KB) Download : Download full-size image Fig. 3. Architecture
    of Kubernetes (ex: one master node and one work node). 3.1. Kubernetes architecture
    Kubernetes architecture is based on the master/slave model [37]. It consists of
    a cluster of one master node and several work nodes, called , as shown in Fig.
    3. Their roles are given as follows: Kubernetes master: This node is responsible
    of the overall management and availability of the Kubernetes cluster. Its components,
    i.e. the Application Programming Interface (API) server, controller and scheduler,
    support the interaction, monitoring and scheduling tasks within the cluster. The
    API server provides the interface to the shared state of the cluster through which
    the other components, e.g. work nodes, interact. The controller monitors the shared
    state of the cluster through the API server and makes decisions to bring the cluster
    back from an unstable state to a stable one. The scheduler manages the cluster
    load. It takes into account individual and collective resource requirements, quality-of-service
    requirements, hardware/software constraints, policies, etc. The Kubernetes cluster
    data is stored in a database, e.g. etc. [38], whereas cluster administration is
    at the master level via the K8s command-line interface . The latter stores its
    configuration and authentication information to access the API server in the file.
    Kubernetes minions: Containerized applications run on these nodes. On one hand,
    the client nodes communicate with the work node via their through the master node.
    The receives commands from the master node and executes them through its Docker
    engine. It also reports the state of the work node to the API server. On the other
    hand, the kube-proxy runs on each work node to manage clients’ access to deployed
    services. Each service is compiled into one or many Pods. A Pod is a logical set
    of one or several containers. This is the smallest unit that can be programmed
    as a deployment in Kubernetes. Containers in the same Pod share resources such
    as storage capacity, IP address, etc. 3.2. Pods instantiation In Kubernetes, the
    placement of Pods is realized following a specific strategy. In fact, considering
    a Kubernetes cluster consisting of a master node and a finite set of minions ,
    a pod asking for CPU cycles, RAM, a specific communication port and a storage
    capacity, needs to be deployed within the cluster. To select the on which the
    pod will be instantiated, the K8s master node proceeds in two steps: (1) it filters
    the minions. Then, (2) it ranks the remaining minions to determine the best one
    suited for the pod. These two steps are detailed as follows: Filtering: In this
    operation, nodes without required resources are removed. Kubernetes uses multiple
    predicates to perform filtering, including: • PodFitsResources: does the node
    have enough resources (CPU and RAM) to accommodate the pod? • PodFitsHostPorts:
    is the node able to run the pod via the port without conflicts? • NoVolumeZoneConflict:
    does the node have the amount of storage that the pod requests? • MatchNodeSelector:
    does the node match the parameters of the selector query defined in the pod description?
    These predicates can be combined to set up sophisticated filters. Ranking: After
    filtering, Kubernetes uses priority functions to determine the best among the
    nodes able to host the pod. A priority function assigns a score between 0 and
    10 where 0 is the least preferred and 10 is the most preferred node. Each priority
    function is weighted by a positive number and the final score is the sum of the
    weighted scores. The main priority functions that can be activated in Kubernetes
    are: • BalancedResourceAllocation: it aims at balancing the charge. Indeed, it
    places the pod in a node in a way that the resource utilization rate (CPU and
    RAM) is balanced among the minions. • LeastRequestedPriority: it favors the node
    that has most resources available. • CalculateSpreadPriority: it minimizes the
    number of pods belonging to the same service on the same node. • CalculateAntiAffinityPriority:
    it minimizes the number of pods belonging to the same service on nodes sharing
    a particular attribute or label. • CalculateNodeLabelPriority: it favors nodes
    with a specific label. Once the final scores of all nodes are calculated, the
    having the highest score is selected to instantiate the pod. If there is more
    than one that has the highest score, the master node selects one of them randomly.
    4. Fault tolerance in kubernetes In this section, we explain the fault tolerance
    mechanism in Kubernetes. We start by a brief description of faults. Next, we present
    the associated consensus problem. Finally, the built-in fault tolerance protocol
    “Raft” is detailed. 4.1. Background The robustness of a system refers to its ability
    to continue functioning when part of the system fails [39]. A system fails when
    the outputs are no longer conform to the original specification. The occurrence
    of a failure can be: 1) transient, i.e. appears, disappears and never occur again,
    2) intermittent, i.e. reproducible in a given context and 3) persistent, i.e.
    appears until repair. A non-faulty (non-failing) node or process is called correct
    when it follows its specifications. Whereas, a faulty node/process may stop or
    exhibits a random behavior. In general, failures/faults may be caused by software
    defects, malicious attacks, or human–machine interaction errors. In distributed
    systems orchestrated by Kubernetes, faults may occur at the master node or minions.
    They can be classified into two categories: 1. Fail-stop faults: They are characterized
    by the complete activity’s stop (or crash) of a node. This state is perceived
    by others as the absence of expected messages until the eventual application’s
    termination. A system that is able to detect only these faults considers that
    a node/process can be in one of two states, either it works and gives the correct
    result, or it does nothing. 2. Byzantine faults: Byzantine faults are characterized
    by any behavior deviating from the node/process’s specifications and producing
    non-conform results [40]. We distinguish between natural Byzantine faults, such
    as undetected physical errors on messages’ transmissions, memory and instructions,
    and malicious Byzantine faults, designed to defeat the system, such as viruses,
    worms and sabotage instructions. In large and/or uncontrolled systems, the risk
    of faults is high and shall be mitigated to ensure service continuity. One way
    to realize it is to use the State Machine Replication (SMR) mechanism [41]. The
    latter consists of using multiple copies of a system, implemented as a state machine,
    to tolerate faults and keep the system’s availability. Each copy of the system,
    called a replica, is placed on a different node [42]. SMR allows a set of nodes
    to execute the same instruction sequences on each request sent by a client. There
    are two approaches to execute requests: 1) active replication, where all nodes
    execute requests, update their state machines, and respond to clients. And 2)
    passive replication, where only one node, called leader, executes the requests
    and forwards state machine changes to other nodes, then responds to clients. To
    avoid inconsistency in replication, nodes/replicas need to be sure that their
    state machines are identical before responding to clients. The following section
    describes this state machine replication problem, called the Consensus problem.
    4.2. Consensus problem The Consensus is a fundamental condition in fault-tolerant
    distributed systems. It consists of tuning replicas’ values to the same one, proposed
    by one of the nodes. The Consensus problem can be formulated as follows: We assume
    a system composed of a set of replicated nodes, and that at most only nodes can
    fail, where . Let be a subset of nodes. The consensus problem consists of finding
    a protocol that allows the following: 1. Any node can propose a replica’s value
    to the other nodes. 2. When all nodes agree on the same value, a consensus is
    achieved. Without loss of generality, protocols that satisfy these conditions,
    possess four properties [43]: 1. Termination: Each correct node eventually decides
    a value. 2. Validity: The decided value has been proposed by one or many other
    nodes. 3. Integrity: The decision is unique and final. 4. Agreement: Two correct
    nodes cannot decide different values. According to [42], any protocol that verifies
    the following safety and liveness conditions has the previous four properties:
    (1) Safety: All the correct replicas execute the requests they receive in the
    same order. (2) Liveness: Each request is correctly executed by correct nodes.
    Such a protocol is commonly referred as consensus/replication protocol. Its decisions
    are based on exchanged messages between all or a part of the nodes in the system.
    Indeed, a consensus is achieved if the quorom, defined as the minimum number of
    correct nodes required to build the consensus, participate in the consensus process.
    The quorum depends on the size of the system and the maximum number of tolerated
    faults. Two fault-tolerant classes of replication protocols exist. In the first,
    called Non-Byzantine, nodes fail only when they stop functioning. For nodes, at
    most crash faults can be tolerated. Examples of non-Byzantine protocols include
    Raft [15], Paxos [44], and Zab [45]. In the second class, called Byzantine, any
    type of failures can be tolerated. However, they typically tolerate only faults
    [46]. As Byzantine protocols examples, we can cite Practical Byzantine Fault-Tolerance
    (PBFT) [47], Efficient Byzantine Fault-Tolerance (EBFT) [48], UpRight [49], Prime
    [50], and Byzantine Fault-Tolerance State Machine Replication (BFT-SMaRt) [16],
    [51]. 4.3. Built-in fault tolerance in kubernetes: Raft protocol Raft is the replication
    protocol built into Kubernetes [15], [52]. Basically, it ensures that the replicas
    maintain identical state machines, while tolerating only crash faults. It is based
    on passive replication, where a node may be leader, follower or candidate, as
    illustrated in Fig. 4: • Leader: In a cluster, a single active node directs the
    communication, by receiving requests, processing them, forwarding state machine
    changes to other nodes, and responding to clients. • Follower: When a leader is
    active, all other nodes are set as followers. They wait for the changes sent by
    the leader to update their state machines. • Candidate: When the leader breaks
    down, the followers become candidates and trigger votes to elect a new leader.
    The mandate of a leader lasts from its election until its breakdown. In order
    to organize elections, Raft assigns an index to each mandate. These indexes are
    called terms. Any leader or candidate node includes the term index in its messages.
    Whereas, a follower needs to wait for a random time, typically between and , before
    transiting into candidate. An active leader periodically sends heartbeat messages
    ( ) to all nodes in the cluster. Any node receiving this message resets its wait
    time to a random value. Otherwise, at the expiration of its wait timer, the follower
    changes status to candidate and triggers a new election. The candidate proceeds
    as follows: 1) Increments its current term number, 2) votes for itself, and 3)
    sends vote request ( ) to all other nodes. The latter vote for the request containing
    a term index greater than theirs, update their term index and return to the follower
    status. Once a candidate receives the votes of the majority, defined as votes,
    it becomes the new leader. However, if no candidate obtains the majority of votes,
    e.g. in a tie situation, no leader is elected in this term, and a new term will
    be triggered by the node that sees its timer expiring first. The requirement for
    a majority of votes ensures that a single leader is elected in a term (Safety
    condition), while the wait time of followers guarantees that a leader will eventually
    be elected (Liveliness condition). Download : Download high-res image (140KB)
    Download : Download full-size image Fig. 4. Raft Protocol’s Election Process.
    To run in Kubernetes environment, some changes have been made to Raft protocol:
    1. Unlike the conventional Raft, where requests to followers are redirected to
    the leader, Raft is converted to active replication to be conform to the load
    balancing property of Kubernetes [52]. 2. Raft is re-implemented in Golang, the
    same programming language used to develop Kubernetes and Docker containers. Besides
    Raft, another non-Byzantine replication protocol, called was proposed for Kubernetes
    [53]. This protocol is similar to Raft, but requires sharing the master node’s
    memory to all instantiated containers in work nodes, in order to store their state
    machines. This approach allows to achieve shorter consensus times than Raft, but
    aggravates the containers’ isolation issue. Despite their simplicity, Raft and
    are particularly powerless against Byzantine behaviors [54]. Indeed, a failing
    node may not stop, and adopts continually a Byzantine (random) behavior, e.g.
    not following the protocol, corrupting its local state, or producing incorrect
    or inconsistent outputs [42]. To mitigate this problem, we propose in the next
    section a novel Kubernetes platform, where both non-Byzantine and Byzantine faults
    can be tolerated, while ensuring service continuity. Download : Download high-res
    image (551KB) Download : Download full-size image Fig. 5. System Model. 5. Kmmr:
    A k8s multi-master robust platform Kubernetes allows to deploy and orchestrate
    groups of containers with a single master node. The latter replicates the containers
    on different work nodes to provide service continuity. However, if the master
    node fails, containers are no longer available and all management data is lost.
    To avoid such case, the deployment of multi-master clusters, where several master
    nodes cooperate, becomes necessary. However, duplicating master nodes only does
    not provide complete fault tolerance [55]. In fact, this mechanism must be associated
    with a replication protocol to ensure consistency between the master nodes states,
    i.e., update operations to a replicated data item within the nodes should reach
    and be executed at some time, in all master nodes, and in the same chronological
    order [42], [56]. Such multi-master systems are important for critical applications,
    e.g., telecommunication and energy services, where the continuous availability
    of services is required 24 h a day, and 7 days a week. In this section, we propose
    to create a resistant Kubernetes multi-master platform to all kinds of faults,
    in order to guarantee service continuity. We consider a Kubernetes cluster consisting
    of replicated K8s master nodes and work nodes. Work nodes process clients’ service
    requests and send their reports (requests) to the master nodes, as shown in Fig.
    5. We assume that communications between nodes may experience important delays,
    thus causing communication failures. Download : Download high-res image (195KB)
    Download : Download full-size image Fig. 6. Consensus Process by BFT-SMaRt. Download
    : Download high-res image (167KB) Download : Download full-size image Fig. 7.
    Integration Methodology of BFT-SMaRt into Kubernetes. 5.1. BFT-Smart: Replication
    protocol for kmmr Among the known Byzantine protocols, only PBFT [47], UpRight
    [49] and BFT-SMaRt [16] implement a Byzantine fault-tolerant replication system.
    The choice of BFT-SMaRt is motivated by the following: • BFT-SMaRt is very well
    suited for modern hardware, e.g. multi-core systems, unlike other protocols such
    as PBFT [16]. • BFT-SMaRt outperforms other protocols, e.g. UpRight, in terms
    of consensus time, defined as the required time to process a client’s request
    [16]. • BFT-SMaRt guarantees a high accuracy in replicated data, when a Byzantine
    faulty behavior is exhibited within the system [16]. • BFT-SMaRt is a modular,
    extensible and robust library. It is able to provide an adaptable library that
    sets up reliable services [57]. • Unlike other Byzantine protocols, BFT-SMaRt
    supports reconfiguration of the replica sets, e.g., addition and removal of nodes
    [58]. • BFT-SMaRt provides efficient and transparent support for critical and
    sustainable services [59]. In BFT-SMaRt, a consensus is established according
    to the following steps, as illustrated in Fig. 6. First, a work node broadcasts
    its request to master nodes, who trigger the execution of the consensus protocol.
    Each instance of the consensus begins with the leader master node proposing to
    other nodes a batch of requests in the PROPOSE message. Master nodes validate
    the authenticity of the PROPOSE message and its content. If valid, they register
    the proposed batch and broadcast WRITE messages with cryptographic hashes of the
    proposed batch, to all other nodes. If a master node receives WRITE messages with
    the same hash, where is the ceiling function, it sends an ACCEPT message to all
    other nodes. This message contains its decision batch for the consensus instance.
    If the leader master node is not correct, a new election must be triggered, and
    all nodes need to converge to the same execution by consensus. The election procedure
    is described in detail in [60]. 5.2. Proposed integration methodology of BFT-smart
    into k8s The BFT-SMaRt protocol is implemented in Java, an object-oriented programming
    language, while Kubernetes and the Docker engine are written in Golang, a service-oriented
    programming language [61]. In order to integrate BFT-SMaRt into Kubernetes, two
    options can be considered: 1. Rewrite all BFT-SMaRt library’s source code in Golang.
    2. Wrap the BFT-SMaRt library in a Docker container. Unlike Raft, with a source
    code less than 3000 lines and easily rewrited in Golang, BFT-SMaRt source code
    is larger and more complex, with approximately 100 files and a total of 13500
    lines of Java code. Consequently, the second option is more likely to be realizable.
    This choice is supported by the advantages offered by Docker. Indeed, Docker containers
    run fast and their introduced overhead is negligible [22], [24]. The proposed
    procedure to integrate BFT-SMaRt into Kubernetes is illustrated in Fig. 7. First,
    we recover the library BFT-SMaRt and all its dependencies from Github [57]. Then,
    we customize it by setting the parameters of the master nodes. Next, we create
    our Docker file Dockerfile, as detailed in Fig. 8. Afterwards, we execute Dockerfile
    to produce the BFT-SMaRt containerized image. Finally, we instantiate in each
    K8s master node the Docker image with its information. Download : Download high-res
    image (301KB) Download : Download full-size image Fig. 8. Dockerfile to Create
    the BFT-SMaRt Container. 6. Experimental evaluation 6.1. Simulation settings We
    implemented the KmMR solution in an OpenStack cloud environment provided by Ericsson
    Canada [62]. The available resources are as follows: 50 GB of RAM and 20 virtual
    processors (VCPU), usable on a maximum of 10 machines. The experiment is carried
    out on clusters composed of several Kubernetes master nodes ( and ), connected
    to each other via the OpenStack GigabitEthernet network and accessible from the
    Internet. Each node is a virtual machine equipped with the Ubuntu server 18.04
    TLS 64-bit OS, a dual-core i7 CPUs (VCPU) clocked at 2.4 GHz, 4 GB of RAM and
    20 GB storage capacity. The Docker engine 18.05.0-ce is installed on Kubernetes
    nodes for container instantiation needs. We deployed Kubernetes 1.11.0 to orchestrate
    the Docker containers. The master Kubernetes role kubeadm has been enabled on
    all master nodes (multi-master configuration). The remaining machines are used
    to act as work nodes and DDoS attackers. BFT-SMaRt has been containerized and
    integrated into the master nodes to provide coordination and consensus. Work nodes
    send their requests in closed loop, i.e. they wait for the response of a request
    before sending a new one, as defined in [63]. In the cluster, we initialize the
    replication protocol on master nodes. Then, two work nodes broadcast their requests.
    Upon request reception, master nodes exchange messages to build the consensus.
    To measure the performance of KmMR, we used the micro-benchmark where both request
    and response messages are empty [47]. DDoS attacks are used to model Byzantine
    behaviors, using the Hping3 command [64], [65]. Indeed, we inject DDoS-based “CPU
    Load” and “Network Flooding” Byzantine faults as follows [66], [67]. “CPU Load”
    fault is triggered by increasing the number of users continuously sending requests
    to a master node, while “Network Flooding” can be initiated by some master nodes
    towards others. We assume that attacking machines target simultaneously a single
    master node. Each attacker sends successively and continuously requests of size
    65495 bytes in open loop, i.e. without waiting for responses, through the command
    Hping3 -f IP address of targeted master node -d 65495. We evaluate the performance
    of our solution and compare it to the Kubernetes multi-Master Conventional (KmMC)
    platform, where non-Byzantine replication protocol Raft is used. Two scenarios
    are considered for our experiments: • Scenario 1: In this scenario, we consider
    a Kubernetes platform where, initially, the number of (crash) faults in the cluster
    is lower than the maximum number of faults tolerated by the replication protocol
    in place. This corresponds to and for KmMC and KmMR respectively. Then, we perform
    a DDoS attack on one master node, and evaluate the consensus times for each platform.
    • Scenario 2: Unlike Scenario 1, the initial number of (crash) faults is set to
    be the maximum that can be tolerated by the used replication protocol. Then, DDoS
    attacks are performed on one master node. In this scenario, we evaluate established
    consensus times as well as resources consumption by the DDoS victim (CPU, RAM,
    and available communication Bandwidth). Resources are measured using commands
    IPerf3 for Bandwidth, and top for CPU and RAM [68], [69]. 6.2. Results and discussions
    Considering Scenario 1, we present in Table 2 the achieved consensus times versus
    DDoS attack rate of KmMC and KmMR, for a cluster of 5 and 7 master nodes respectively.
    For both platforms, consensus times increase slightly and proportionally to DDoS
    attack rates. Indeed, even with the additional Byzantine fault, and respect the
    maximum number of tolerated faults1 . Hence, platforms’ operation continue without
    significant degradation. However, KmMC realizes shorter consensus times than KmMR.
    This is expected, since the replication protocol Raft is designed with few consensus
    message exchanges between master nodes, compared to BFT-SMaRt. Finally, we conclude
    that it is recommended to select the KmMC platform if the risk of exceeding the
    maximum number of faults, dictated by Raft, is very low. Table 2. Consensus times
    ( sec) versus DDOS attack rate (Gbps) (Scenario 1). DDoS attack rate KmMC KmMR
    Empty Cell 5 K8s master nodes 7 K8s master nodes 5 K8s master nodes 7 K8s master
    nodes 0 1701.91 2048.25 2746.45 3161.83 2 2004.38 2132.93 2940.87 3179.45 4 2178.72
    2471.39 3362.42 4521.79 4.5 2201.37 2501.73 3525.17 4632.38 5 2287.65 2623.87
    3612.93 4729.98 5.5 2304.12 2702.99 3867.32 4970.93 6 2331.12 2732.25 4053.53
    4970.93 For Scenario 2, we present in Fig. 9 the consensus time versus DDoS attack
    rate, for a cluster of 5 master nodes. The results show that the consensus time
    increases with DDoS attack rate. When the attack rate is below 4.25 Gbps, KmMC
    provides a slightly better performance than KmMR. Indeed, in this case, the DDoS
    victim resists to the attack thanks to its sufficient resources. However, for
    an attack rate above 4.25 Gbps, KmMC deteriorates rapidly and significantly. This
    is mainly due to the vulnerability of Raft replication protocol in front of Byzantine
    faults. Indeed, the DDoS victim would behave improperly, e.g. not responding to
    other nodes in a timely manner. Thus, from this moment, Raft triggers changes
    in the cluster’s leadership since it is no longer able to reach a consensus with
    its current leader. This triggering considerably slows down consensus in the KmMC
    platform. Meanwhile, KmMR resists to all DDoS attacks, and is able to achieve
    consensus time 1000 times better than KmMC in average. Download : Download high-res
    image (470KB) Download : Download full-size image Fig. 9. Consensus time versus
    DDOS attack rate (Scenario 2, ). Fig. 10 illustrates the consensus time versus
    DDoS attack rate in the same environment as Fig. 9, but for a cluster of 7 master
    nodes. The same behavior is exhibited for and master nodes. However, for , consensus
    is established faster thanks to the smaller number of exchanged messages. As increases,
    KmMC becomes more susceptible to DDoS attacks. Indeed, the rapid degradation of
    KmMC’s performance starts at attack rate 4.1 Gbps for , compared to 4.25 Gbps
    for . Whereas, KmMR is able to establish consensus in a reasonable time, even
    for high attack rates. Download : Download high-res image (486KB) Download : Download
    full-size image Fig. 10. Consensus time versus DDOS attack rate (Scenario 2, ).
    Fig. 11, Fig. 12, Fig. 13 present the CPU, RAM and Bandwidth performances of the
    DDoS victim node, for Scenario 2 and . When the DDoS attack rate is below 4.5
    Gbps, KmMR uses as much or more resources than KmMC. This is expected since establishing
    a consensus in KmMR using BFT-SMaRt requires a larger number of messages exchange.
    However, for attack rates above 4.5 Gbps, KmMR and KmMC have almost the same level
    of resource utilization. Indeed, Raft starts to make changes in the cluster in
    order to regain its stability, resulting in higher resources consumption than
    usual. Download : Download high-res image (178KB) Download : Download full-size
    image Fig. 11. CPU consumption rate versus DDOS attack rate (Scenario 2, ). Download
    : Download high-res image (271KB) Download : Download full-size image Fig. 12.
    RAM consumption versus DDOS attack rate (Scenario 2, ). Download : Download high-res
    image (187KB) Download : Download full-size image Fig. 13. Available Bandwidth
    versus DDOS attack rate (Scenario 2, ). 6.3. Solution limitations and future insights
    When researchers proposed PBFT-like protocols, such as BFT-Smart, their main concern
    was to enhance the performance of BFT in fault-free cases, while maintaining properties
    of Liveness and Safety, when faults occur. BFT-SMaRt aims to be robust in terms
    of high performance in fault-free executions, and correctness when faults happen.
    According to our experiments, it is clear that BFT-Smart is capable of surviving
    in a small and partially uncontrolled environment, where Byzantine faults may
    occur. However, it would reach rapidly its limits in a larger network, mainly
    due to its heavy communication and limited scalability. To reinforce resistance
    to malicious Byzantine faults, the notion of robust BFT protocols has been introduced
    by Aardvark, i.e., maintaining a constant and stable performance in the presence
    of few Byzantine faults [70]. Indeed, several improvements have been proposed,
    such as Aardvark [70], Spinning [71], and RBFT [72], in order to efficiently handle
    some worst-case malicious Byzantine behaviors. For instance, Aardvark tolerates
    nodes/replicas to expect a minimum acceptable throughput from the leader [70],
    while Spinning changes the leader with every batch of requests [71]. Finally,
    RBFT [72] proposed to maintain a constant performance during a fault event. It
    is demonstrated in [72] that Aardvark and Spinning performances are reduced by
    at least 78% in presence of a fault, whereas RBFT degrades by only 3%. This is
    due to RBFT’s design, where protocol instances are ran, but only one executes
    the received request. Although interesting, the previous protocols would experience
    difficulties in managing inconsistency in large scale systems [73]. Indeed, this
    type of management is relegated to client nodes, although the reason to use a
    consistent BFT protocol is precisely to avoid this responsibility to clients.
    One of the promising solutions is to concurrently run independent processes aiming
    at achieving higher throughputs [74], which is the basic approach to implement
    scalable blockchain architectures. Blockchain, by itself, is a BFT replicated
    state machine, where each state-update is a Turing machine with bounded resources.
    Unlike conventional BFT protocols where fault tolerance is realized among a small/medium
    group of nodes through rounds of message exchanges (votes and safety-proofs messages),
    blockchain achieves BFT among a very large number of participants, where at each
    time period, only a single message (Proof-of-Work -PoW- message) is broadcast
    by a participant. Adopting known BFT mechanisms into blockchain has led to the
    proposal of hybrid solutions, such as Byzcoin [75], Bitcoin-NG [76], Casper [77]
    and Solida [78]. These approaches anchor off-chain BFT decisions inside a PoW
    chain or the other way around. For instance, Casper is a proof-of-stack (PoS)-based
    finality system, which overlays a PoW blockchain. By design, Casper allows to
    provide Safety and plausible Liveness, as well as protect the system against long
    range revisions and catastrophic crashes faults [77]. Moreover, innovative solutions
    in the age of blockchains, such as Honeybadger [79], Algorand [80], and LightChain
    [81], revisit the BFT setting with greater scalability and simplicity. Honeybadger
    is a demonstrative example of how BFT can build a blockchain cryptocurrency [79].
    It can reach consensus within 5 min using 104 nodes. By design, Honeybadger requires
    prior setting of a fixed number of consensus nodes, which may be problematic in
    terms of targeted attacks that may either compromise the nodes or exclude them
    from the system. In contrast, Algorand, a PoS approach, can achieve better performance
    without having to select a fixed set of nodes beforehand [80]. Also, it is robust
    against malicious attacks, even from a malicious leader, and scales better for
    a large number of clients. Finally, in order to overcome the low communication
    and storage efficiency, inconsistency and scalability problems encountered in
    existing blockchains, the authors in [81] proposed LightChain. The latter is a
    blockchain defined over a skip graph-based peer-to-peer distributed hash table
    overlay, which achieves consensus through Proof-of-Validation (PoV), i.e., a blockchain
    data is considered valid if its hash value is signed by a randomly selected number
    of validators [81]. It has been proven that LightChain is a fair, consistent,
    and communication/storage efficient blockchain. In spite of its limits, it is
    clear that the implementation of BFT-Smart into Kubernetes is the first step into
    providing robustness to this popular Docker containers orchestration platform.
    As future work, one could investigate the integration of more sophisticated protocols
    to Kubernetes, such as the aforementioned ones, and test their robustness to malicious
    Byzantine behaviors. Testing can be realized through the BFT-bench framework introduced
    in [66]. 7. Conclusion With the increased importance of virtualization in cloud
    computing, Docker containerization is favored for its lightweight and efficient
    virtualization. This implies the emergence of new forms of architectures organizing
    cloud services in containers, ready to be instantiated in virtual and/or physical
    machines. Since the main objective is to guarantee service continuity, orchestrating
    these containers may seem challenging. Recently, Kubernetes has been adopted as
    the orchestration platform of Docker containers. Although efficient in managing
    containers, Kubernetes guarantees service continuity only in presence of non-Byzantine
    (crash) faults occurring within the system. In fact, the current replication protocol
    within Kubernetes “Raft” cannot handle Byzantine faults. In this paper, we propose
    a new orchestration platform capable of overcoming this limitation in Kubernetes.
    The KmMR platform, based on Byzantine replication protocol BFT-SMaRt, is presented.
    We detailed our approach to integrate the BFT-SMaRt library (written in Java)
    into Docker and Kubernetes (written in Golang). Then, we implemented a Kubernetes
    multi-master platform in an OpenStack-based cloud environment. The system is evaluated
    for two different scenarios, where initially the maximum number of tolerated faults
    is either reached or not, and for two orchestration platforms, KmMC and KmMR.
    The results show that the conventional approach KmMC is efficient and robust in
    a non-Byzantine and controlled environment, i.e. number of maximum tolerated faults
    is not exceeded. However, in a Byzantine and not fully controlled environment,
    KmMR guarantees the continuity of services, while KmMC collapses in front of severe
    Byzantine faults. In a such environment, KmMR resources consumption is typically
    stable, compared to KmMC. In future works, we will investigate the integration
    of more robust BFT protocols into Kubernetes, in order to ensure a better protection
    against malicious Byzantine faults. Declaration of Competing Interest The authors
    declare that they have no known competing financial interests or personal relationships
    that could have appeared to influence the work reported in this paper. Acknowledgment
    This work was partially funded by NSERC-CRD program . References [1] Thiruvathukal
    G.K., Hinsen K., Läufer K., Kaylor J. Virtualization for computational scientists
    Comput. Sci. Eng., 12 (4) (2010), pp. 52-61 View in ScopusGoogle Scholar [2] Mijumbi
    R., Serrat J., Gorricho J., Bouten N., De Turck F., Boutaba R. Network function
    virtualization: State-of-the-art and research challenges IEEE Commun. Surveys
    Tuto., 18 (1) (2016), pp. 236-262 View in ScopusGoogle Scholar [3] Bernstein D.
    Containers and cloud: From LXC to docker to kubernetes IEEE Cloud Comput., 1 (3)
    (2014), pp. 81-84 View in ScopusGoogle Scholar [4] Peinl R., Holzschuher F., Pfitzer
    F. Docker cluster management for the cloud-survey results and own solution J.
    Grid Comput., 14 (2) (2016), pp. 265-282 CrossRefView in ScopusGoogle Scholar
    [5] R. Rizki, A. Rakhmatsyah, M.A. Nugroho, Performance analysis of container-based
    hadoop cluster: OpenVZ and LXC, in: Proc. 4th Int. Conf. on Information and Commun.
    Tech. (ICoICT), 2016, pp. 1–4. Google Scholar [6] Zhang H., Jiang G., Yoshihira
    K., Chen H. Proactive workload management in hybrid cloud computing IEEE Trans.
    Netw Serv. Manag., 11 (1) (2014), pp. 90-100, 10.1109/TNSM.2013.122313.130448
    View in ScopusGoogle Scholar [7] Jamshidi P., Pahl C., Mendonça N.C., Lewis J.,
    Tilkov S. Microservices: The journey so far and challenges ahead IEEE Softw.,
    35 (3) (2018), pp. 24-35 CrossRefView in ScopusGoogle Scholar [8] S. Garg, S.
    Garg, Automated cloud infrastructure, continuous integration and continuous delivery
    using docker with robust container security, in: Proc. IEEE Conf. Multimedia Info.
    Process. and Retrieval (MIPR), 2019, pp. 467–470. Google Scholar [9] R. Zhang,
    M. Li, D. Hildebrand, Finding the big data sweet spot: Towards automatically recommending
    configurations for hadoop clusters on docker containers, in: roc. IEEE Int. Conf.
    Cloud Eng., 2015, pp. 365–368. Google Scholar [10] Padhy R.P. Docker containers
    and kubernetes: An architectural perspective (2018) URL https://dzone.com/articles/docker-containers-and-kubernetes-an-architectural
    Google Scholar [11] Sill A. Emerging standards and organizational patterns in
    cloud computing IEEE Cloud Comput., 2 (4) (2015), pp. 72-76 View in ScopusGoogle
    Scholar [12] Burns B., Grant B., Oppenheimer D., Brewer E., Wilkes J. Borg, omega,
    and kubernetes Queue, 14 (1) (2016), p. 10 CrossRefGoogle Scholar [13] Google
    B. Kubernetes (2018) URL https://kubernetes.io/ Google Scholar [14] Oliveira C.,
    Lung L.C., Netto H., Rech L. Evaluating raft in docker on kubernetes Proc. Int.
    Conf. Syst. Science, Springer (2016), pp. 123-130 Google Scholar [15] D. Ongaro,
    J.K. Ousterhout, In search of an understandable consensus algorithm, in: Proc.
    USENIX Annual Technical Conf., 2014, pp. 305–319. Google Scholar [16] A. Bessani,
    J. Sousa, E.E.P. Alchieri, State machine replication for the masses with BFT-SMART,
    in: Proc. 44th Annual IEEE/IFIP Int. Conf. Dependable Syst. and Net., 2014, pp.
    355–362. Google Scholar [17] Copeland C.N., Zhong H. Tangaroa: A byzantine fault
    tolerant raft (2014) scs.stanford.edu Google Scholar [18] Correia M., Ferro D.G.,
    Junqueira F.P., Serafini M. Practical hardening of crash-tolerant systems Proc.
    of the USENIX Conf. on Annual Technical Conf. (USENIX ATC), USENIX Association,
    Berkeley, CA, USA (2012) pp. 41–41 Google Scholar [19] Moga A., Sivanthi T., Franke
    C. OS-Level virtualization for industrial automation systems: Are we there yet?
    Proc. 31st Annual ACM Symp. Applied Comput., ACM (2016), pp. 1838-1843 CrossRefView
    in ScopusGoogle Scholar [20] VMware vSphere Hypervisor (2019) URL http://www.vmware.com/products/vsphere-hypervisor.html
    Google Scholar [21] Rad B.B., Bhatti H.J., Ahmadi M. An introduction to docker
    and analysis of its performance Int. J. Comput. Sci. Netw. Secur., 17 (3) (2017),
    pp. 228-235 Google Scholar [22] Joy A.M. Performance comparison between linux
    containers and virtual machines Proc. Int. Conf. Advances in Comput. Eng. and
    Appl. (ICACEA), IEEE (2015), pp. 342-346 CrossRefView in ScopusGoogle Scholar
    [23] Vase T. Advantages of docker (2015) URL jyx.jyu.fi/bitstream/handle/123456789/48029/1/URN%3ANBN%3Afi%3Ajyu-201512093942.pdf
    Google Scholar [24] Felter W., Ferreira A., Rajamony R., Rubio J. An updated performance
    comparison of virtual machines and linux containers Proc. Int. Symp. Perf. Analysis
    of Syst. and Soft. (ISPASS), IEEE (2015), pp. 171-172 CrossRefView in ScopusGoogle
    Scholar [25] Sharma P., Chaufournier L., Shenoy P., Tay Y. Containers and virtual
    machines at scale: A comparative study Proc. 17th Int. Middleware Conf., ACM (2016),
    p. 1 View PDFView articleGoogle Scholar [26] W. Li, A. Kanso, Comparing containers
    versus virtual machines for achieving high availability, in: Proc. IEEE Int. Conf.
    Cloud Eng., 2015, pp. 353–358. Google Scholar [27] Manu A., Patel J.K., Akhtar
    S., Agrawal V., Murthy K.B.S. Docker container security via heuristics-based multilateral
    security-conceptual and pragmatic study Proc. Int. Conf. Circuit, Power and Comput.
    Tech. (ICCPCT), IEEE (2016), pp. 1-14 CrossRefGoogle Scholar [28] CoreOS A. Fleet
    project (2014) URL https://github.com/coreos/fleet Google Scholar [29] Apache
    A. Mesos project (2014) URL https://github.com/apache/mesos Google Scholar [30]
    Luzzardi A., Victor V. Swarm: A docker-native clustering system (2014) URL https://github.com/docker/swarm/
    Google Scholar [31] K8s A. Kubernetes source code (2014) URL https://github.com/kubernetes/kubernetes/
    Google Scholar [32] AWS A. Gopro reduces compute footprint by 70% using amazon
    ECS (2017) URL https://aws.amazon.com/solutions/case-studies/gopro-containers/
    Google Scholar [33] Mazzara M., Dragoni N., Bucchiarone A., Giaretta A., Larsen
    S.T., Dustdar S. Microservices: Migration of a mission critical system IEEE Trans.
    Serv. Comput. (2018) 1–1 Google Scholar [34] Banerjee A., Venkatasubramanian K.K.,
    Mukherjee T., Gupta S.K.S. Ensuring safety, security, and sustainability of mission-critical
    cyber–Physical systems Proc. IEEE, 100 (1) (2012), pp. 283-299 View in ScopusGoogle
    Scholar [35] Kratzke N., Quint P.-C. Understanding cloud-native applications after
    10 years of cloud computing: A systematic mapping study J. Syst. Softw., 126 (2017),
    pp. 1-16 View PDFView articleView in ScopusGoogle Scholar [36] Sayfan G. Mastering
    Kubernetes: Master the Art of Container Management by using the Power of Kubernetes
    (second ed.), Packt Publishing (2018) Google Scholar [37] Bila N., Dettori P.,
    Kanso A., Watanabe Y., Youssef A. Leveraging the serverless architecture for securing
    linux containers Proc. IEEE 37th Int. Conf. Dist. Comput. Syst. Wrkshps. (ICDCSW),
    IEEE (2017), pp. 401-404 View in ScopusGoogle Scholar [38] CoreOS N. Coreos ETCD
    (2018) URL https://coreos.com/etcd/ Google Scholar [39] Cristian F. Understanding
    fault-tolerant distributed systems Commun. ACM, 34 (2) (1991), pp. 56-78 View
    in ScopusGoogle Scholar [40] Lamport L., Shostak R., Pease M. The byzantine generals
    problem ACM Trans. Programm. Lang. Syst. (TOPLAS), 4 (3) (1982), pp. 382-401 View
    in ScopusGoogle Scholar [41] Aublin P.-L. Towards Efficient and Robust Fault-Tolerant
    Protocols (Ph.D. thesis) Université de Grenoble (2014) (in French) Google Scholar
    [42] Schneider F.B. Implementing fault-tolerant services using the state machine
    approach: A tutorial ACM Comput. Surveys (CSUR), 22 (4) (1990), pp. 299-319 View
    in ScopusGoogle Scholar [43] Pease M., Shostak R., Lamport L. Reaching agreement
    in the presence of faults J. ACM, 27 (2) (1980), pp. 228-234 View in ScopusGoogle
    Scholar [44] Lamport L., et al. Paxos made simple ACM SiGACT News, 32 (4) (2001),
    pp. 51-58 Google Scholar [45] Van Renesse R., Schiper N., Schneider F.B. Vive
    la différence: Paxos vs. Viewstamped Replication vs. Zab IEEE Trans. Depend. Secure
    Comput., 12 (4) (2015), pp. 472-484 View in ScopusGoogle Scholar [46] Bracha G.,
    Toueg S. Asynchronous consensus and broadcast protocols J. ACM (JACM), 32 (4)
    (1985), pp. 824-840 View in ScopusGoogle Scholar [47] Castro M., Liskov B. Practical
    byzantine fault tolerance and proactive recovery ACM Trans. Comput. Syst. (TOCS),
    20 (4) (2002), pp. 398-461 View in ScopusGoogle Scholar [48] Veronese G.S., Correia
    M., Bessani A.N., Lung L.C., Verissimo P. Efficient byzantine fault-tolerance
    IEEE Trans. Comput., 62 (1) (2013), pp. 16-30 View in ScopusGoogle Scholar [49]
    Clement A., Kapritsos M., Lee S., Wang Y., Alvisi L., Dahlin M., Riche T. Upright
    cluster services Proc. 22nd Symp. Operating Systems Principles (SIGOPS), ACM (2009),
    pp. 277-290 CrossRefView in ScopusGoogle Scholar [50] Amir Y., Coan B., Kirsch
    J., Lane J. Prime: Byzantine replication under attack IEEE Trans. Depend. Secure
    Comput., 8 (4) (2011), pp. 564-577 View in ScopusGoogle Scholar [51] Sousa J.,
    Bessani A., Vukolic M. A byzantine fault-tolerant ordering service for the hyperledger
    fabric blockchain platform Proc. 48th Annual Int. Conf. Dependable Syst. and Net.
    (DSN), IEEE (2018), pp. 51-58 View in ScopusGoogle Scholar [52] Blake Mizerany
    X.L., Qin Y. The raft consensus algorithm (2018) URL https://raft.github.io//#implementations
    Google Scholar [53] Netto H.V., Lung L.C., Correia M., Luiz A.F., de Souza L.M.S.
    State machine replication in containers managed by kubernetes J. Syst. Arch.,
    73 (2017), pp. 53-59 View PDFView articleView in ScopusGoogle Scholar [54] Lim
    J., Suh T., Gil J., Yu H. Scalable and leaderless byzantine consensus in cloud
    computing environments Inf. Syst. Frontiers, 16 (1) (2014), pp. 19-34 CrossRefView
    in ScopusGoogle Scholar [55] Perronne L. Towards Efficient and Robust BFT Protocols
    (Ph.D. thesis) Université Grenoble Alpes (2016) (in French) Google Scholar [56]
    Souri A., Pashazadeh S., Navin A. Consistency of data replication protocols in
    database systems: A review Int. J. Inf. Theory (IJIT), 3 (2014), pp. 19-32 CrossRefGoogle
    Scholar [57] GitHub A. BFT-Smart library (2018) URL https://github.com/bft-smart/library
    Google Scholar [58] Lamport L., Malkhi D., Zhou L. Reconfiguring a state machine
    ACM SIGACT News, 41 (1) (2010), pp. 63-73 CrossRefGoogle Scholar [59] A.N. Bessani,
    M. Santos, J. Felix, N.F. Neves, M. Correia, On the efficiency of durable state
    machine replication, in: Proc. USENIX Annual Tech. Conf., 2013, pp. 169–180. Google
    Scholar [60] Sousa J., Bessani A. From byzantine consensus to BFT state machine
    replication: A latency-optimal transformation Proc. 9th European Dependable Comput.
    Conf. (EDCC), IEEE (2012), pp. 37-48 CrossRefView in ScopusGoogle Scholar [61]
    Golang J. The go programming language (2018) URL https://golang.org/ Google Scholar
    [62] Sefraoui O., Aissaoui M., Eleuldj M. Openstack: Toward an open-source solution
    for cloud computing Int. J. Computer Appl., 55 (3) (2012), pp. 38-42 CrossRefGoogle
    Scholar [63] Schroeder B., et al. Open versus closed: A Cautionary tale NSDI,
    USENIX Association (2006), pp. 239-252 Google Scholar [64] Sanfilippo B. Hping3
    (2014) URL http://www.hping.org/hping3.html Google Scholar [65] Ops B. Denial-of-service
    attack–DOS using hping3 with spoofed IP in kali linux BlackMORE Ops. BlackMORE
    Ops, 17 (2016) Google Scholar [66] Gupta D. Towards Performance and Dependability
    Benchmarking of Distributed Fault Tolerance Protocols (Ph.D. thesis) Grenoble
    Alpes University (2016) URL https://tel.archives-ouvertes.fr/tel-01376741 Google
    Scholar [67] Gupta D., Perronne L., Bouchenak S. BFT-BEnch: A framework to evaluate
    BFT protocols Proc. 7th ACM/SPEC Int. Conf. Perform. Eng. (ICPE) (2016), pp. 109-112,
    10.1145/2851553.2858667 View in ScopusGoogle Scholar [68] iPerf D. IPerf (2018)
    URL https://iperf.fr/fr/iperf-doc.php Google Scholar [69] BISWAS S. A guide to
    the linux top command (2018) URL www.booleanworld.com/guide-linux-top-command/
    Google Scholar [70] Clement A., Wong E.L., Alvisi L., Dahlin M., Marchetti M.
    Making byzantine fault tolerant systems tolerate byzantine faults NSDI, vol. 9
    (2009), pp. 153-168 Google Scholar [71] Veronese G.S., Correia M., Bessani A.N.,
    Lung L.C. Spin one’s wheels? byzantine fault tolerance with a spinning primary
    Proc. 28th IEEE Int. Symp. Rel. Dist. Syst. (2009), pp. 135-144, 10.1109/SRDS.2009.36
    View in ScopusGoogle Scholar [72] Aublin P., Mokhtar S.B., Quéma V. RBFT: Redundant
    byzantine fault tolerance Proc. IEEE 33rd Int. Conf. Dist. Comp. Syst. (2013),
    pp. 297-306, 10.1109/ICDCS.2013.53 View in ScopusGoogle Scholar [73] Buchman E.
    Tendermint: Byzantine Fault Tolerance in the Age of Blockchains (Master’s thesis)
    University of Guelph (2016) URL https://atrium.lib.uoguelph.ca/xmlui/handle/10214/9769
    Google Scholar [74] Kotla R., Dahlin M. High throughput byzantine fault tolerance
    Proc. Int. Conf. Depend. Syst. and Net. (2004), pp. 575-584, 10.1109/DSN.2004.1311928
    View in ScopusGoogle Scholar [75] Kokoris-Kogias E., Jovanovic P., Gailly N.,
    Khoffi I., Gasser L., Ford B. Enhancing bitcoin security and performance with
    strong consistency via collective signing Proc. 25th USENIX Conf. Sec. Symp.,
    USENIX Association, USA (2016), pp. 279-296 Google Scholar [76] Eyal I., Gencer
    A.E., Sirer E.G., Renesse R.V. Bitcoin-NG: A scalable blockchain protocol 13th
    USENIX Symp. Network. Syst. Design and Implement. (NSDI 16), USENIX Association,
    Santa Clara, CA (2016), pp. 45-59 Google Scholar [77] Buterin V., Griffith V.
    Casper the friendly finality gadget (2017) arXiv:1710.09437 Google Scholar [78]
    Abraham I., Malkhi D., Nayak K., Ren L., Spiegelman A. Solida: A blockchain protocol
    based on reconfigurable byzantine consensus (2016) arXiv:1612.02916 Google Scholar
    [79] Miller A., Xia Y., Croman K., Shi E., Song D. The honey badger of BFT protocols
    Proc. ACM Conf. Comp. and Commun. Sec. (SIGSAC), Association for Computing Machinery,
    New York, NY, USA (2016), pp. 31-42, 10.1145/2976749.2978399 View in ScopusGoogle
    Scholar [80] Gilad Y., Hemo R., Micali S., Vlachos G., Zeldovich N. Algorand:
    Scaling byzantine agreements for cryptocurrencies Proc. 26th Symp. Op. Syst. Princ.
    (SOSP), Association for Computing Machinery, New York, NY, USA (2017), pp. 51-68,
    10.1145/3132747.3132757 Google Scholar [81] Hassanzadeh-Nazarabadi Y., Kupçu A.,
    Ozkasap O. LightChain: A DHT-based blockchain for resource constrained environments
    (2019) arXiv:1904.00375 Google Scholar Cited by (15) Towards Resilient Method:
    An exhaustive survey of fault tolerance methods in the cloud computing environment
    2021, Computer Science Review Show abstract Improving fault tolerance in LinuX
    container-based distributed systems using blockchain 2024, Cluster Computing CONTAINER-BASED
    VIRTUALIZATION FOR BLOCKCHAIN TECHNOLOGY: A SURVEY 2023, Jordanian Journal of
    Computers and Information Technology Primary node election based on probabilistic
    linguistic term set with confidence interval in the PBFT consensus mechanism for
    blockchain 2023, Complex and Intelligent Systems Engage-Envision-Enact: Self-Organised
    Governance for Self-Improving Socio-Technical Systems 2023, Proceedings - 2023
    IEEE International Conference on Automatic Computing and Self-Organizing Systems
    Companion, ACSOS-C 2023 Improvement of Raft Consensus Algorithm Based on Credit
    Values on Electronic Medical Record (EMR) Blockchain 2023, Proceedings of SPIE
    - The International Society for Optical Engineering View all citing articles on
    Scopus Gor Mack Diouf received his Bachelor degree in electrical and computer
    engineering from École polytechnique de Thiès (Sénégal), in 2016. He obtained
    his Master degree from Université du Québec à Montréal in May in 2019. His is
    presently a software architect at Prima Solutions Montreal. Halima Elbiaze holds
    a Ph.D. in computer science and a M.Sc in Telecommunication systems from Institut
    National des Télécommunications, Paris, France and Université de Versailles in
    2002 and 1998. Since 2003, she is with the Department of Computer Science, Université
    du uéeec Montréal, C, Canada, where she is currently an Associate Professor. In
    2005, Dr. Eleiaze received the Canada Foundation for Innovation Award to build
    her IP over the DWDM network Laboratory. Her research interests include performance
    evaluation, traffic engineering, cloud computing, wireless networks, and next
    generation IP networks. She had been awarded many research grants from both public
    agencies and industry. Wael Jaafar (S’14) received B.Eng. degree from SUP’COM,
    Tunisia, in 2007, and the M.A.Sc. and Ph.D. degrees in Electrical Engineering
    from Polytechnique Montreal, Canada, in 2009 and 2014, respectively. He was a
    Visiting Research Intern with U AM, Montreal, Canada, in 2007 and a Visiting Researcher
    within Keio University, Tokyo, Japan, in 2013. In 2018, he held Research Fellow
    and Lecturer positions within U AM, Montreal, Canada. Since December 2018, Dr.
    Jaafar joined the Systems and Computer Engineering Department of Carleton University
    as an NSERC Postdoctoral Fellow. His current research interests include wireless
    communications, resource allocation, edge caching and computing and machine learning.
    1 Notice that KmMC sees the DDoS attack as a crash event in this case. View Abstract
    © 2020 Published by Elsevier B.V. Recommended articles Cloud restriction solver:
    A refactoring-based approach to migrate applications to the cloud Information
    and Software Technology, Volume 95, 2018, pp. 346-365 Marcos Borges, …, Paulo
    Henrique Maia View PDF LXCloudFT: Towards high availability, fault tolerant Cloud
    system based Linux Containers Journal of Parallel and Distributed Computing, Volume
    122, 2018, pp. 51-69 Thouraya Louati, …, Christophe Cérin View PDF Programming
    framework and infrastructure for self-adaptation and optimized evolution method
    for microservice systems in cloud–edge environments Future Generation Computer
    Systems, Volume 118, 2021, pp. 263-281 Xiang He, …, Zhongjie Wang View PDF Show
    3 more articles Article Metrics Citations Patent Family Citations: 1 Citation
    Indexes: 14 Captures Readers: 54 View details About ScienceDirect Remote access
    Shopping cart Advertise Contact and support Terms and conditions Privacy policy
    Cookies are used by this site. Cookie settings | Your Privacy Choices All content
    on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors.
    All rights are reserved, including those for text and data mining, AI training,
    and similar technologies. For all open access content, the Creative Commons licensing
    terms apply.'
  inline_citation: '>'
  journal: Future generation computer systems
  limitations: '>'
  pdf_link: null
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: On Byzantine fault tolerance in multi-master Kubernetes clusters
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.30534/ijatcse/2020/220942020
  analysis: '>'
  authors:
  - Manish Kumar Abhishek
  citation_count: 4
  full_citation: '>'
  full_text: '>'
  inline_citation: '>'
  journal: International journal of advanced trends in computer science and engineering
  limitations: '>'
  pdf_link: null
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: High Performance Computing using Containers in Cloud
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/icc40277.2020.9148636
  analysis: '>'
  authors:
  - Francisco Carpio
  - Marta Caridad Naipe Delgado
  - Admela Jukan
  citation_count: 8
  full_citation: '>'
  full_text: '>

    IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account
    Personal Sign In Browse My Settings Help Access provided by: University of Nebraska
    - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards
    Authors Citations ADVANCED SEARCH Conferences >ICC 2020 - 2020 IEEE Internat...
    Engineering and Experimentally Benchmarking a Container-based Edge Computing System
    Publisher: IEEE Cite This PDF Francisco Carpio; Marta Delgado; Admela Jukan All
    Authors 7 Cites in Papers 462 Full Text Views Abstract Document Sections I. Introduction
    II. Related Work III. System Architecture IV. Performance Evaluation V. Conclusions
    Authors Figures References Citations Keywords Metrics Footnotes Abstract: While
    edge computing is envisioned to superbly serve latency sensitive applications,
    the implementation-based studies benchmarking its performance are few and far
    between. To address this gap, we engineer a modular edge cloud computing system
    architecture that is built on latest advances in containerization techniques,
    including Kafka, for data streaming, Docker, as application platform, and Firebase
    Cloud, as realtime database system. We benchmark the performance of the system
    in terms of scalability, resource utilization and latency by comparing three scenarios:
    cloud-only, edge-only and combined edge-cloud. The measurements show that edge-only
    solution outperforms other scenarios only when deployed with data located at one
    edge only, i.e., without edge computing wide data synchronization. In case of
    applications requiring data synchronization through the cloud, edge-cloud scales
    around a factor 10 times better than cloudonly, until certain number of concurrent
    users in the system, and above this point, cloud-only scales better. In terms
    of resource utilization, we observe that whereas the mean utilization increases
    linearly with the number of user requests, the maximum values for the memory and
    the network I/O heavily increase when with an increasing amount of data. Published
    in: ICC 2020 - 2020 IEEE International Conference on Communications (ICC) Date
    of Conference: 07-11 June 2020 Date Added to IEEE Xplore: 27 July 2020 ISBN Information:
    ISSN Information: DOI: 10.1109/ICC40277.2020.9148636 Publisher: IEEE Conference
    Location: Dublin, Ireland SECTION I. Introduction Edge computing systems are emerging
    today as the solution to bringing cloud capabilities closer to the users thus
    not only reducing the latency as perceived by users, but also the network traffic
    to remote cloud data centers. The latest advances on lightweight virtualization
    (LV) techniques in form of containers and serverless computing are especially
    gaining traction in edge computing. Unlike the Kernel-Based Virtual Machines (KVM)
    commonly used in the cloud, containers do not require manual server administration
    before launching the apps, and are used as standalone and self-contained software
    packages that include all the code and related dependencies necessary to run the
    app. In addition, container platform solutions, such as Docker, are platform independent,
    just like KVMs, allowing to execute apps independently from the operating system.
    As the name implies, lightweight virtualization techniques are also able to run
    on constrained devices, such as Raspberry Pis, making them a highly relevant IoT
    (Internet of Things) solution. When engineering an edge computing system, the
    issue about how to interconnect distributed localities of computing nodes comes
    into play, and the performance of the resulting system needs to be benchmarked
    in terms of latency, resource utilization and scalability. While it is widely
    assumed that edge computing outperforms the cloud in terms of latency, when engineering
    a real edge computing system, this performance advantage is not given, or obvious.
    In fact, many theoretical studies have pointed out that edge computing would show
    better latency as long as sufficient inter-edge bandwidth and computing edge capabilities
    are provisioned, which has not been tested real world systems yet. In regard to
    the basic performance metrics, including latency, resource utilization and scalability,
    there are still open questions regarding to the real advantages that edge computing
    solutions can bring. We engineer to this end an edge and cloud system architecture
    with open source software using Kafka at the edge for data streaming, Docker as
    application platform and Firebase as realtime cloud database system. We then experimentally
    benchmark the performance in terms of scalability, latency and resource utilization,
    in scenarios where large number of amount of concurrent jobs in the system are
    sending data concurrently. We compare three scenarios: cloud-only, edgeonly and
    combined edge-cloud. The results indicate that edgeonly case performs the best
    in terms of latency, as long as the application does not require data synchronization
    between edge nodes. Otherwise, edge-cloud solution is a better option until certain
    number of concurrent users in the system and a certain amount of data; above that
    point, there is a clear disadvantage as compared to cloud-only. The resource utilization
    measurements show that the mean utilization is not affected by the amount of data
    and only the maximum values for the memory and network I/O increase with the number
    of users when sending larger amounts of data. The rest of the paper is organized
    as follows. Section II presents related work. Section III describes the system
    architecture. The Section IV shows the performance evaluation of the proposed
    system and Section V concludes the paper. SECTION II. Related Work Edge computing
    is envisioned to computing, processing and storing data as close as possible to
    the source of the data, which is critical to IoT systems [1], [2]. Especially
    in the resource constrained edge computing, traditional KernelBased Virtual Machines
    (KVM) have already been replaced by lightweight virtualization solutions [3].
    Different lightweight virtualization technologies, most notably containers or
    unikernels, are used today as underlying tools to facilitating the fast adoption
    of edge computing [4]. Despite significant engineering challenges, including resource
    constraints, resilience and security [5], [6], the LV solutions have been shown
    to exhibit good scalability, resource and service management or fault tolerance,
    with a rather limited overhead introduced [7], [8]. Containerization is also the
    most widely adopted technique and orchestration engine in today’s cloud systems,
    including Kubernetes or Docker Swarm being the de-facto standard of the so-called
    serverless computing concept, as adopted by AWS Lambda, Azure Functions, Google
    Cloud Functions, etc, in form of various frameworks, such as OpenFaas, Kubeless
    or OpenWhisk [9]. Despite significant momentum, the implementation-based studies
    benchmarking its performance are few and far between. While lightweight virtualization
    on constrained devices have been shown in a myriad of works as a promising solution
    for edge computing, once engineered, the system needs to be benchmarked for the
    performance expected. For the first time, we focus on that engineering and benchmarking
    process precisely, and show how to experimentally evaluate the edge computing
    performance in three realworld scenarios: cloud-only, edge-only and edge-cloud.
    Fig. 1: System Architecture Show All SECTION III. System Architecture The reference
    architecture is shown in Fig. 1 and follows the modular microservice design principles.
    To this end, different architecture components and modules can be combined to
    follow different configurations. Starting from the bottom up, the architecture
    includes IoT devices (single-boards, such as Raspberry Pis), over to the so-called
    edge nodes (desktop computers, laptops, servers), the related end-devices (smartphones
    or tablets) up to the traditional cloud service (in our implementation, Firebase).
    IoT devices, having sensors attached directly to them, or receiving the data from
    external sensors connected to it, act as data producers. In our system, we have
    developed two docker ARM-based images: the bridge and the processor. The bridge
    implements an HTTP server to receive data from other containers, for instance,
    from the processor or from external sensors. By using a Kafka producer, the bridge
    also sends data to Kafka Broker located, in this case, in the edge node. The edge
    node runs the following containers: Kafka Broker, Zookeeper, the Aggregator and
    Data-Analysis. Zookeeper and Kafka Broker work together and are used as streaming
    messaging platforms. The Aggregator receives data from Kafka by subscribing to
    it using a consumer, and stores the data into Firebase through a Firebase Admin.
    Dataanalysis as well as Processor are not required for the main architecture to
    work but are the components designed to performing some kind of processing on
    the data (for instance, machine learning) to be later sent to the Aggregator.
    The cloud is implemented as a realtime database instance using Firebase platform
    which flexibly stores data using JSON tree structures. Finally, the client is
    a Web-based module with both Firebase and Kafka interfaces in order to receive
    data either using the cloud or the edge nodes. While the detailed functionality
    and implementation of each module is out of the scope of this paper, we here focus
    on the parts relevant to the communication between the modules which will be later
    used to benchmark the latency and other performance. A. Data Streaming In edge
    computing, efficient and reliable communication between different modules is critical
    to achieve scalability. While different communication protocols, following both
    client-server and publish-subscribe approaches, are being used at the application
    layer, HTTP is being the most predominant one [10] which is commonly used adopting
    the RESTful architectural design as application programming interface (API). HTTP
    protocol, which was designed as client-server based model for web browsers, is
    however not optimized for managing large amounts of data stream messages due to
    excessive overhead. Other publish-subscribe communication protocols, such as AMQP
    or MQTT can handle scalability much better than HTTP and have been traditionally
    used in the cloud. Despite this, we decided to use Apache Kafka, – a known distributed
    streaming platform based on the publish-subscribe model currently used by major
    industries (including Netflix, Airbnb, Microsoft, Linkdin). With Kafka, in comparison
    with traditional AMQP or MQTT, while the broker is not able to track the messages
    received that have been acknowledged by the consumers, it is possible to achieve
    high throughput by ingesting a large amount of data very quickly; for instance,
    Kafka is proven to manage more than 20 million of events per second in Netflix’s
    system 1. This tool together with processing tools like Apache Spark becomes a
    powerful data processing solution. B. The Aggregator Since Kafka keeps track of
    all sent messages by persistent storage, and is also built to run as a cluster,
    that can expand or contract, where data is replicated internally to provide high
    availability and fault-tolerance, it is often considered a database system. On
    the other hand, Kafka is usually not used as a replacement of traditional database
    systems, but as support acting as commit log. In this context, an interface is
    required between Kafka and the database system, which we engineer herewith as
    Aggregator. The Aggregator, developed in Java, consists of a Kafka consumer that
    is subscribed to all topics which data need to be stored in the database. Since
    all data exchange in our system follows the JSON specification where every message
    contains one JSON object, the Aggregator only requires an identification field
    for every exchanged object. These objects are then stored into the database through
    the Firebase Admin SDK that the Aggregator also incorporates. C. Data Storage
    and Synchronization As previously mentioned, our system relies on a Firebase real-time
    database system specifically designed to maintain data synchronization among multiple
    clients. This database is NoSQL, and instead uses JSON trees structures to store
    data, which provides more scalability and full flexibility when defining data
    structures as compared to traditional SQL-based databases. The selection of Firebase
    database system rather than other NoSQL available ones is basically because of
    the ability of maintaining all clients synchronized automatically removing the
    effort of developing periodic queries to the database. There is also another feature
    that makes Firebase a suitable option for our architecture, which is the ability
    of working in offline mode. Since the Aggregator uses the Admin SDK, it first
    stores the data locally and later synchronizes in best effort mode to the cloud
    and to other clients. These features provide high flexibility to the Aggregator
    which is now able to work not only on devices with reliable connectivity, but
    also on mobile devices with intermittent connectivity. SECTION IV. Performance
    Evaluation Let us now introduce the testbed and the parameters used to perform
    the tests and benchmark the performance. The testbed consists of two local desktop
    computers (both with i5-7600 CPU, 16GB of RAM and SSD SanDisk X400 up to 540 and
    520 MBps of reading and writing speeds, respectively), one desktop running as
    edge node and the other one as tester node. Each computer has two Gigabit Ethernet
    interfaces, where, in both cases, one is connected externally with 1 Gbps downlink
    and 500 Mbps uplink, and another one is used for the interconnection between the
    two machines. The computer running as edge node is running three Docker containers:
    the Aggregator, Kafka broker and Zookeeper. The computer used for the tests runs
    a Java application with a Firebase client and Kafka consumer to to receive data
    either from the cloud or from the Kafka Broker depending on the scenario, and
    also stores the results of the measurements. In the same machine, a Python script
    sends data with JSON format to either the edge node using a Kafka producer or
    to the cloud using HTTP requests. In the Cloud, we have a Firebase realtime database
    (located in Western Europe) that will store the data sent by the Aggregator and
    will notify to the connected clients, in our case the Java app running on the
    tester node. With these two machines and the cloud, we evaluate three different
    scenarios shown in Fig. 2. In cloud-only scenario (see Fig. 2a), the tester node
    performs the tests by sending HTTP requests to the cloud endpoint and uses the
    firebase client to receive the updates asynchronously a soon as they are stored
    in the database. In edge-only scenario (see Fig. 2b), the tester node sends and
    receives data to and from the edge node using one Kafka producer and one Kafka
    consumer. In a combined edge-cloud scenario (see Fig. 2c), the tester node sends
    data to the edge node using the Kafka producer and receive the updated data from
    the cloud using the Firebase client. To benchmark the system, we performed tests
    to measure the total latency of the system since the tester node sends data until
    the data is received in the same machine. The scalability is measured in terms
    of how many concurrent users (i.e., processes) the system support until the latency
    is too high that the system becomes unusable. We also benchmark the resource utilization,
    including CPU, memory and network utilization that are required by the containers
    running on the edge node when performing the tests. For the different tests, the
    tester node simulates different number of users (i.e., processes), from 100 to
    1000, by opening threats and sending different payload sizes depending on each
    case. Every user individually sends 1000 requests with inter-arrival time following
    a normal distribution with mean value 1 second. For each test, the database is
    deleted and the containers at the edge node restarted in order to delete any data
    from previous tests. A. Latency To show the latency results, we use violin plots
    (which represents the probability density of the data as well as makers for median
    and interquartile range when possible) and cumulative distribution function (CDF).
    We then compare the results for all three scenarios previously described. Fig.
    3 and Fig. 4 show the latency of the system for different number of users (i.e.,
    processes) when performing requests with 1 KB and 10 KB of payload data, respectively,
    in the scenarios described in Fig. 2. Fig. 2: Test scenarios Show All Starting
    with the cloud-only scenario, Fig. 3a and Fig. 4a show the violin plots when the
    payload data size is 1KB and 10KB, respectively. From these measurements, we can
    observe that the increment in the number of users in the system increases exponentially
    the average latency. This trend is more evident above 500 concurrent users when
    sending 1KB and 300 users when sending 10KB. The latency distribution, with 400
    users or less, when using 1KB, and with 200 users or less, when using 10KB, is
    similar in both cases. The main point to note here is the fact that above 500
    and 300 users, respectively, the points are less concentrated around the median,
    but spread between the maximum and minimum values. This behavior can be explained
    by the fact that the cloud-only scenario starts getting overloaded at the values
    of around 300 concurrent users, and the response times may vary for every request,
    independently. Since this behavior is more or less similar by either sending 1KB
    or 10KB, the reason behind is the way that Firebase manages concurrent HTTP requests
    and less so because of the amount of data sent. The difference between the amount
    of data sent can be, however, appreciated by comparing the average values between
    both cases of data size, being 10KB size clearly higher than with 1KB. The final
    point to consider from these results is the fact that the results for 10KB are
    highly polarized as compared to the case with 1KB. This shows how sending more
    data concurrently with every request impacts on the variation of the response
    time of a request. This behavior can be better observed by comparing Fig. 5a and
    Fig. 5b where the CDF shows how the latency for 10KB case is clearly affected
    above 300 users, which is not for the case of 1KB of data. Fig. 3b and Fig. 4b
    shows the latency results when considering the edge-only scenario described in
    Fig. 2b. In this case, the results for 1KB of payload data size do not exhibit
    large differences with varying number of users. For the case of data with 10 KB,
    there is clear increment of the median above 400 users. The latter case also affects
    the distribution of the latency measurements. Again, this behavior can be better
    observed by comparing Fig. 5c and Fig. 5d where for more than 400 users, the CDF
    is more affected as compared to the case when only 1KB of data is sent. In Fig.
    3c and Fig. 4c, we again show the latency, but in this case for the combined edge-cloud
    scenario described in Fig. 2c. Here, the behavior is quite different depending
    of the payload size and for different number of users. For 1KB size, the results
    between 100 and 600 users are similar, and above 600, the latency exponentially
    increases with the number of users (i.e., processes). For the case of sending
    10KB, the same behavior can be observed but for over 200 users. The latter case
    is interesting since the results are not concentrated around the median, but spread
    out between the minimum and maximum values. Again, in Fig. 5e and Fig. 5f we can
    observe better the difference in the the number of users affected in both cases.
    B. Scalability By comparing all three scenarios, we can observe that edgeonly
    case scales better than the other two cases for any number of users, with around
    1 second of latency in the worst case scenario. This is because, while in this
    case the data is also synchronized to the cloud, the tests are being measured
    just between the tester node and the edge node. Therefore here, we see a clear
    advantage of using fast data stream tools such as Kafka, which can heavily reduce
    the latency as perceived by the end user, with data synchronized with the cloud.
    This, however, does not show, for instance, the latency that two users located
    in different locations would perceive when the data has to travel over the network.
    This case can be only measured by using either cloud-only or edge-cloud scenarios
    where the latency is measured after cloud synchronization. Then, by comparing
    these two cases, we see how edge-cloud outperforms cloud-only when the system
    has 600 users or less for 1KB of data, and 200 or less when for 10KB of data.
    This behavior is quite interesting since it would be more natural to expect that
    edge-cloud is always slower than cloud-only by the sheer fact the data is forwarded
    using Kafka and the Aggregator, which intuitively adds extra latency. The reasoning
    behind this interesting behavior is that the Aggregator and Kafka act as a buffer
    for the data and are more optimally synchronized with the cloud, at least until
    certain amount of concurrent request and amount of data. Above that level (700
    users sending 1KB or 300 sending 10KB), edge-cloud does not scale anymore, getting
    latency values between 10 and 100 seconds for 1KB, and between 10 seconds and
    1000 seconds for 10KB. In the cloud-only case, the system scales well for 1KB
    case up to 600 users, and for 10KB case up to 300 users. Above these values, the
    latency can reach up to 10 seconds, which is the point where we can assume that
    the system does not scale anymore and becomes practically unusable. Fig. 3: Latency
    with 1KB versus num. of users and scenarios. Show All C. Resource Utilization
    Since the objective of our experimental study is also to show the feasibility
    of edge-cloud systems realized with commonpurpose hardware, we now provide measurements
    on resources utilized by the edge node when running the tests. Because the edge
    node is running three different containers, we use Docker stats command to retrieve
    the the status of all three containers which are combined and stored in an output
    file every second. Fig. 6a shows the mean, maximum and minimum CPU utilization
    for all number of users and both payload data sizes. It should be noted here that
    Docker considers 100% utilization when 1 core is fully utilized, so results above
    100% mean that more cores have been used. Here, we can see how the mean value
    slightly increases with the number of users, with the case of 10KB being larger
    than 1KB in all cases. The maximum values are in both cases similar, and are progressively
    increasing from 100 to 400 users, and later stabilized at around 600 users. The
    memory utilization is shown in Fig. 6b. Here we can observe that the mean value
    slightly increases with the number of users, but the maximum value for the case
    of 10KB increases heavily with the number of users. This is due to the excessive
    memory usage that the Aggregator requires from the moment of the broker receiving
    the data until the data is stored into the database and removed from the memory.
    Since these intervals are short in time, they affects the maximum values but not
    to the mean values. Fig. 6c shows the results for the network input/output (I/O),
    whereby in this case both input and output are the same. This is due to all three
    containers combined, and for all data received are sent out again. In this case,
    we can observe the pattern similar to the memory measurements, whereby the maximum
    value for the 10KB case heavily increases with the number of users, from around
    1GB of data transmitted to 6GB, which is in line to what we could also observe
    in memory measurements. Fig. 4: Latency with 10KB versus num. of users and scenarios.
    Show All Fig. 5: CDF for latency for different number of users, payload size and
    scenarios. Show All SECTION V. Conclusions While edge computing is expected to
    be the solution for latency sensitive applications that require high intensive
    processing tasks, it is always an open question of whether a real-world edge computing
    system implementation can achieve the performance forseen. We engineered a modular
    edge cloud computing system architecture using the latest advances on containerization
    platforms and open source tools and show the challenges and importance of benchmarking
    latency, scalability and resource utilization in edge computing. We compared experimentally
    three scenarios: cloud-only, edgeonly and edge-cloud. The measurements showed
    that while edge-only outperforms other cases in terms of latency and scalability,
    it also requires the app to work with data located at centralized edge nodes.
    Edge-cloud performs around 10 times better compared to only-cloud until certain
    number of concurrent processes where the system does not scale anymore, and only-cloud
    performs better. Finally, for resource utilization the maximum memory and network
    I/O increase heavily with increasing amounts of data and concurrent users. Fig.
    6: Resource utilization at the edge node. Show All Authors Figures References
    Citations Keywords Metrics Footnotes More Like This A Comparative Study of Mobile
    Cloud Computing, Mobile Edge Computing, and Mobile Edge Cloud Computing 2023 Congress
    in Computer Science, Computer Engineering, & Applied Computing (CSCE) Published:
    2023 Container Placement and Migration in Edge Computing: Concept and Scheduling
    Models IEEE Access Published: 2021 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved.'
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: null
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: Engineering and Experimentally Benchmarking a Container-based Edge Computing
    System
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1007/978-3-030-49432-2_8
  analysis: '>'
  authors:
  - Remo Scolati
  - Ilenia Fronza
  - Nabil El Ioini
  - Areeg Samir
  - Hamid Reza Barzegar
  - Claus Pahl
  citation_count: 6
  full_citation: '>'
  full_text: '>

    Your privacy, your choice We use essential cookies to make sure the site can function.
    We also use optional cookies for advertising, personalisation of content, usage
    analysis, and social media. By accepting optional cookies, you consent to the
    processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Log in Find a journal
    Publish with us Track your research Search Cart Home Cloud Computing and Services
    Science Conference paper A Containerized Edge Cloud Architecture for Data Stream
    Processing Conference paper First Online: 04 June 2020 pp 150–176 Cite this conference
    paper Access provided by University of Nebraska-Lincoln Download book PDF Download
    book EPUB Cloud Computing and Services Science (CLOSER 2019) Remo Scolati, Ilenia
    Fronza, Nabil El Ioini, Areeg Samir, Hamid Reza Barzegar & Claus Pahl  Part of
    the book series: Communications in Computer and Information Science ((CCIS,volume
    1218)) Included in the following conference series: International Conference on
    Cloud Computing and Services Science 548 Accesses 7 Citations Abstract Internet
    of Things (IoT) devices produce large volumes of data, which creates challenges
    for the supporting, often centralised cloud infrastructure that needs to process
    and store the data. We consider here an alternative, more centralised approach,
    based on the edge cloud computing model. Here, filtering and processing of data
    happens locally before transferring it to a central cloud infrastructure. In our
    work, we use a low-power and low-cost cluster of single board computers (SBC)
    to apply common models and technologies from the big data domain. The benefit
    is reducing the volume of data that is transferred. We implement the system using
    a cluster of Raspberry Pis and Docker to containerize and deploy an Apache Hadoop
    and Apache Spark data streaming processing cluster. We evaluate the performance,
    but of trust support of the system, showing that by using containerization increased
    fault tolerance and ease of maintenance can be achieved. The analysis of the performance
    takes into account the resource usage of the proposed solution with regards to
    the constraints imposed by the devices. Our trust management solution relies on
    blockchain technologies. Access provided by University of Nebraska-Lincoln. Download
    conference paper PDF Similar content being viewed by others A Blockchain-Based
    Decentralized Self-balancing Architecture for the Web of Things Chapter © 2019
    Artificial Intelligence at the Edge in the Blockchain of Things Chapter © 2020
    IoT Big Data provenance scheme using blockchain on Hadoop ecosystem Article Open
    access 30 August 2021 Keywords Edge cloud IoT Container Cluster architecture Raspberry
    Pi Docker Big data Data streaming Performance Trust 1 Introduction Devices that
    produce data are ubiquitous by now. Connected to the Internet of Things (IoT)
    a major part of this data is stored or processed in a cloud environment. This
    data volume is growing exponentially [44]. In order to reduce data volume in transfer,
    local (pre-)processing of data is a more resource-efficient alternative to the
    currently used centralised cloud processing model. We present here a lightweight
    infrastructure following the edge computing model. We specifically aim to provide
    affordable, low-energy local clusters at the outer edge of the cloud that are
    partly composed of IoT devices themselves. In more concrete terms, we have build
    a small low-power, low-cost cluster of single board computers in a local network,
    which alows us to process generated data at the outer edge closer to producers
    and often consumers of the data. This solution addresses critical performance,
    but also trust concerns. We also look at cost concerns, important for the industrial
    application. Single-board devices (SBD) such as Raspberry Pis have already been
    investigated for IoT and edge settings [25, 33, 43, 47], but performance and trust
    for an industry-relevant setting still need to be better investigated. We introduce
    here an edge cloud architecture on SBDs [32] that builds on technologies commonly
    used in big data processing like Apache Hadoop and Apache Spark, which are characterised
    by high speed, high variety, and high volume. The software platform builds on
    Docker as the containerization technology. Docker Swarm is used as the mechanism
    of orchestrating application services on a device cluster. We describe the implementation
    of the solution using a cluster of Raspberry Pis, a single board computer (SBC).
    We use Docker to deploy and orchestrate lightweight containers [35] in which we
    run an Apache Hadoop and Apache Spark cluster. In order to analyze the performance
    of the system [16] considering the resource constraints of the Raspberry Pi, system
    metrics are collected through a monitoring stack based on Prometheus, a monitoring
    and alerting tool, that we deployed on the cluster. Performance is evaluated experimentally,
    using a test application to process data. Furthermore, we demonstrate how the
    cluster can be used as test bed for such applications. We also look into trust,
    which we validate using a use case analysis. 2 State-of-the-Art Discussion Many
    IoT-cloud integrations monitor and collect data at the IoT edge, but send this
    data directly to a centralized cloud where sufficient storage space and computational
    power is available. However, as a consequence of increasing numbers of IoT device
    and volume of data that is being generated, such centralised cloud infrastructures
    are not ideal from a latency, cost and reliability perspective [13]. The IoT domain
    gives rise to a number of use cases, where large amounts of data are generated
    and have to be processed. The ability to process data locally with a low-cost
    and low-power system opens up use cases in environments without large amounts
    of processing power at disposal on premise, which would benefit from a decreased
    traffic, like systems in remote areas. Also autonomous monitoring and automation
    systems, like remote localised power grids are sample applications. Possible application
    scenarios include autonomous power generation and distribution plants, such as
    smaller local energy grids. In smart city contexts, mobility applications need
    to support vehicles moving around that themselves have limited computational power.
    Edge computing aims at migrating storage and computation to the remote layer close
    to the data producers and consumers [22]. Specifically low-cost and lightweight
    approaches based on the fog or edge cloud computing model are needed if the edge
    devices are somewhat resource-constrained or the need to use affordable devices
    exists. Functionally, the main requirement is to collect, process, and aggregate
    data locally. Quality-wise, the aim is reducing the overall amount of traffic
    and the need for a backing cloud infrastructure. The costs for acquisition, maintenance
    and operation of such a system and its suitability in an industrial setting will
    also need to be considered as well as the overall performance of the system with
    regards to the limited resource constraints. Another requirement is that a suitable
    platform needs to reflect a industry-relevant setting in terms of software deployment
    or big data processing. Yet another problem arises from the often cross-organisation
    setting. Often, no prior trust relationship exists between providers and consumers
    of devices, software and data. Constrained edge systems benefit from the use of
    single board computers like the Raspberry Pi [24] to address cost or other constraints.
    The possibility of connecting sensors to the device’s GPIO paired with the capability
    to perform more complex computations, thus creating a network of smart sensors
    capable of recording, filtering, and processing data is enabled here. The nodes
    can be joined together to a cluster to distribute the workload in the form of
    containers, having separate nodes responsible for different steps of the data
    pipeline from data generation and collection to evaluation for big data streaming
    and analytics. Lightweight cluster infrastructure (Raspberry Pis), lightweight
    container-based software deployment and orchestration platform (Docker swarm)
    that hosts a big data streaming application architecture are introduced in the
    next section. This would lead towards a microservices-style architecture [19,
    42] allowing for flexible software deployment and management to be enabled. In
    this paper, we built on [1] by adding trust to the previous performance concern
    for evaluation. Furthermore, we better demonstrate the utility of our results
    by developing an automated vehicle and mobility use case and show how the proposed
    architecture can be utilised in this context. 3 Literature Review Lightweight
    devices such as single-board devices and lightweight virtualization based on containers
    have continuously gained popularity. Lightweightness is a benefit for computing
    at the outer edge, where limited resources are available, but still data originating
    from the IoT layer needs to be processed. Lightweight devices result in lower
    costs and lower energy consumption. We review literature in terms of three criteria:
    overhead, edge applicability and big data feasibility. Firstly, overhead: in comparison
    to native processes, according to [26, 36] Docker container virtualization has
    been shown to not add significant overhead by leveraging kernel technologies like
    namespaces and control groups, allowing the isolation of processes from each other
    and an optimal allocation of resources such as CPU, memory and I/O device access.
    Secondly, IoT/Edge Applicability: according to [27, 30], Docker is highly suitable
    as a platform for both IoT and Edge Computing. Here as a consequence of constraints
    imposed by low-power devices, it allows lightweight virtualization and facilitates
    the creation of distributed architectures. Thirdly, Big Data: [29] shows that
    Docker is suitable for provisioning Big Data platforms, for instance Hadoop and
    Pachyderm, thus helping overcome difficulties in installation, management, and
    usage of large data processing systems. Systems like Hadoop have been demonstrated
    in [12] to be a suitable platform for pre-processing large amounts of data even
    on small clouds with limited networking and computing resources. In [46], it is
    pointed out that the recent development of low-cost SBDs allows the creation of
    low-power affordable IoT and edge clusters that offer the capability of pre-processing
    sensor data, while also reducing acquisition and maintenance costs [46]. SBDs
    such as the Raspberry Pi are particularly interesting for any system which gathers,
    processes, and reacts to environment data of some form. They allow technically
    to attach sensors and actuators to its GPIO pins. Their architecture enables smart
    infrastructures and smart sensor networks, see e.g.,[25, 43] that describe the
    University of Glasgow Smart Campus project. HypriotOS [37, 38] is a Linux-based
    operating system that makes the Docker platform available for ARM processor and
    thus for IoT networks. The Hypriot developers have demonstrated that container
    orchestration tools like Docker Swarm and Kubernetes can be run on Raspberry Pis
    to facilitate highly available and scalable clusters despite the given resource
    limits of SBDs. Trust is another open concern. While trust architectures exist
    [11] that address identity and integrity concerns for instance through distributed
    ledger technologies, their application to edge context is not sufficiently analysed.
    Despite some acknowledgement of the principle suitability, an exploration of the
    performance limits resulting from a containerised big data streaming application
    on a lightweight cluster architecture is still lacking. Furthermore, trust platforms
    exist, but need to be better investigated regarding their edge suitability. Thus,
    we have built such an architecture and evaluated it in terms of cost, configuration,
    performance and trust concerns in the context of an industry-relevant choice of
    technologies such as container management (Docker), monitoring (Prometheus), stream
    process (Spark) and blockchain (Hyperledger Fabric). Nowadays, the utilization
    of SBDs such as a Raspberry Pi with different techniques of lightweight virtualization
    attracts researchers from an industrial projects such as Carberry 1 and ODB-Pi
    2 to academical research. In [28], a Docker container-based platform has been
    proposed as a lightweight virtualization solution for enabling a customized smart
    car application. According to the result, container-based virtualization is not
    an only a viable approach, although is more flexible and effective in terms of
    management of several parallel processes running on On-Board-Unit (OBU). In [40],
    a scaled validation of Connected and Automated Vehicles (CAV) has been studied
    for vehicle-to-vehicle and vehicle-to-infrastructure communications. Furthermore,
    the development of robotic devices such as Pololu Zumo 3 that combined with an
    on-board Raspberry Pi 3 supports researchers to provide shorter gaps between theory
    and practical implementation scenarios to reduce the overall cost of the project.
    The possibility of cooperative automation through the cloud for distributed computing
    has been studied in [14, 41] in the project CARMA (Cloud-Assisted Real-Time Methods
    for Autonomy). CARMA combines a 3-tier architecture, includes of Vehicle, Edge,
    and Cloud to address on-board and off-board computation as important necessities
    of cooperative automated driving technology. All 3 tiers are logically divided
    into CARMA Core Cloud, CARMA Edge and CARMA Vehicle, which have a possibility
    to work independently, therefore, they could enable ultra-Reliability and Low-Latency
    Communication (uRLLC) for 5G. Low-cost connected devices for measuring acceleration
    and assessing road surface friction during vehicle braking performance-wise have
    been studied in [2]. As reported in the study the measurements which obtained
    from the proposed prototype during some tests are comparable to their benchmark
    regarding all measurement parameters including sample frequency, acceleration
    values and triggering thresholds, on the other hand with 10 to 15-times fewer
    values for the material cost. Another implementation of an inexpensive Raspberry
    Pi for a real-time traffic jam on the road has been studied in [7]. An innovative
    prototype for control and management of a connected car is modeled in [45] which
    can be a remotely controlled connected car based on YANG/RESTCONF and cloud computing.
    In this demonstration, a RESTCONF server was installed on a Raspberry Pi, responsible
    for the sensors and actuators of the car and allowing for its remote control using
    SDN/NFV technology from a user terminal and through the cloud. In terms of safe
    driving system, [15] proposes a new model based on the plural sensors inside a
    car and on a driver’s body which uses multiple edge computing nodes. This prototype
    consists of three edge computing nodes; first one is for monitoring the car and
    the driver. The second one acts as a controller and the last node is learning
    server for training a model for more sophisticated risk assessment. All these
    3 distributed cooperative edge nodes are implemented based on the Raspberry Pi.
    4 Platform Technologies We propose a layered architecture of three platform technologies,
    with Raspberry Pis as the device layer, Docker containers and the software platform
    and Apache Hadoop/Spark as the data processing layer. The Raspberry Pi (RPi) is
    a single-board computer, which was initially developed as an educational device,
    but soon attracted attention from developers due to the small size and relatively
    low price [39]. There have been multiple updates of the platform. The specifications
    are shown in Table 1. In this project, the Raspberry Pi 2 Model B, released in
    2015, is used. Table 1. Specification of the Raspberry Pi 2, Model B – see [1].
    Full size table Docker is an open source software project that allows to run containerized
    applications [9]. A container is a runnable instance of a Docker image, a layered
    template with instructions to create such a container. A container holds everything
    the application needs to run, like system tools, libraries and resources, while
    keeping it in isolation from the infrastructure on which the container is running,
    thus forming a kind of virtualisation layer. Figure 1 illustrates Docker’s architecture.
    Containers interact with their environment. Access to system resources can be
    configured for each container to access storage, or, in the case of the RPis,
    to the general-purpose input/output pins (GPIO) for interaction with its environment,
    e.g., for using sensors or actuators. Technically, containers compartmentalize
    the container process and its children using Linux containers (LXC) and libcontainer
    technology provided by the Linux kernel via kernel namespacing and control groups
    (cgroups), in fact isolating the process from all other processes on the system,
    while using the hosts kernel and resources. The major difference between containers
    and VMs is that containers, sharing the hosts kernel, do not necessitate a separate
    operating system, resulting in less overhead and minimizing the needed resources.
    Fig. 1. Docker container architecture – see [1]. Full size image Fig. 2. Docker
    swarm configuration sample – see [1]. Full size image A central component is the
    Docker Engine 4. The Docker daemon is the server that manages all Docker objects,
    i.e., images, containers, volumes and networks. The client, a command line interface
    (CLI), communicates with the daemon using a REST API. The Docker Swarm mode 5
    allows natively to manage a cluster/swarm of Docker engines. Docker Swarm allows
    to use the Docker CLI to create and manage a swarm, and to deploy application
    services to it, without having to resort to additional orchestration software.
    A Docker swarm (cluster) is made up of multiple Docker hosts that run in swarm
    mode and act as either manager or worker nodes. A host can run as manager, worker,
    or both. When a service is created, the number of replicas, available network
    and storage resources, exposed ports, and other configurations are defined. The
    state of a service is actively maintained by Docker. For example, if a worker
    node becomes unavailable, the tasks assigned to that node are scheduled on other
    nodes. This enables fault-tolerance. A task here refers to a running container
    that is run and managed by the swarm, as opposed to a standalone container. In
    Fig. 2, we illustrate a schematic Docker swarm configuration. At the core is MapReduce,
    which is a programming model allowing to process big data sets. It is build on
    a distributed, parallel algorithm on clustered devices [8]. The name indicates
    that a MapReduce program contains (1) a map method for performing filtering/sorting
    of data and (2) also a Reduce method, to execute some associative operation. While
    being inspired by map and reduce methods common in functional programming, the
    main aim of MapReduce is the optimization of the underlying engine, thus achieving
    scalability and fault tolerance. The MapReduce process can be illustrated as follows:
    Both the Map and Reduce operation are run on structured data in the form of (key,
    value) pairs. The Map function is applied to all pairs (k1, v1) of the input in
    parallel, producing a list of pairs (k2, v2). After this first step, all pairs
    with the same key k2 are collected by the framework, producing one group (k2,
    list(v2)) for each key. Then, the Reduce function is applied to each group in
    parallel, producing a list of values v3. Apache Hadoop is an open source software
    library based on the MapReduce programming model [3] to process large datasets
    in a distributed way. The aim is to scale from single nodes to clusters with multiple
    thousands of machines [6]. The following modules are part of the Apache Hadoop
    core: Hadoop Common – common libraries & utilities; Hadoop Distributed File System
    (HDFS) – distributed file system to store data on cluster nodes; Hadoop YARN –
    manage/schedule computing resources and applications; Hadoop MapReduce – large
    scale MapReduce data processing. Figure 3 illustrates a small cluster with a single
    master node and multiple worker nodes. The master node acts as a task and job
    tracker, NameNode (data index), and DataNode (data store). Worker nodes act as
    task tracker and DataNode. At the core of the Hadoop architecture is the Hadoop
    Distributed File System (HDFS) together with the MapReduce processing component.
    Since the nodes manipulate the data they have access to, Hadoop allows for faster
    and more efficient processing of the dataset than more traditional supercomputer
    architectures [48]. Files are split into blocks of data and distributed across
    the DataNodes. Transferring a packaged application on the same nodes, Hadoop takes
    advantage of the principle of data locality. Finally, Apache Spark is a distributed
    computing framework as an extension to the MapReduce paradigm that provides an
    interface for executing applications on clusters [4]. Based on resilient distributed
    datasets (RDD), a distributed and fault-tolerant set of read-only data items is
    processed. RDDs provide a limited form of Apache Spark generally reduces the latency,
    compared to an Apache Hadoop implementation by several orders of magnitude. Hadoop
    has a distributed shared memory for distributed programs, allowing a less forced
    dataflow compared to the MapReduce paradigm. Apache Spark requires a cluster manager
    – supported implementations are Spark native, Apache Hadoop YARN, and Apache Mesos
    clusters – and a distributed storage system. In extension to Apache Hadoop’s batch
    processing model, Apache Spark provides an interface to perform streaming analytics.
    Fig. 3. Small Hadoop cluster – see [1]. Full size image Fig. 4. Stream processing
    system architecture – see [1]. Full size image Spark supports distributed storage
    systems, TCP/IP sockets, and a variety of data feed providers such as Kafka and
    Twitter as streaming sources, thus making it interoperate well with common platforms.
    5 A Lightweight Platform for Edge Data Processing Our architecture builds on a
    Raspberry Pi cluster that hosts a Docker swarm to leverage the ease of container
    orchestration on multiple devices. Other applications, i.e., Apache Hadoop and
    Spark cluster, the Prometheus monitoring stack and the applications used to simulate
    data collection, are executed inside Docker containers. In order to have a data
    producer, data is provided by a Nodejs 6 application that writes files to the
    HDFS via its API. The Hadoop distributed file system (HDFS) serves as data source
    for an Apache Spark streaming application. This simplifies the deployment and
    management of these applications. For instance, even partial hardware failure
    can be managed by Docker. Our lightweight edge architecture is shown in Figs.
    4 and 5. Figure 4 shows the processing in the architecture and the data flow during
    the experiments, while Fig. 5 shows an overview of the distribution of the services
    on the Raspberry Pis in the configuration that reflects our experimental setting.
    Fig. 5. Overview of the distribution of the service containers on the nodes –
    see [1]. Full size image 5.1 Hardware Architecture The Raspberry Pi cluster is
    made up of eight RPi 2 Model B, fitted with an 8 GB micro SDcard for the installation
    of the OS. The Raspberry Pis are connected to a Veracity Camswitch 8 Mobile switch
    7. This serves also to power the devices through Power over Ethernet (POE). The
    switch features ten 10/100Mbit/s ports, eight of which are 802.3 POE outputs.
    POE has the advantage of the setup being cleaner, since a separate power supply
    is not needed for the Raspberry Pis and as such less cables run across the system,
    although this is neither necessary nor cost efficient. Since the Raspberry Pi
    does not provide the necessary connectivity for POE, the devices need to be outfitted
    with an additional POE module, connected to the Raspberry Pis through the GPIO
    pins. The RPis are connected to the switch using category 5E SFTP cables. 5.2
    Software Architecture Hypriot - Operating System. Hypriot OS 8 is a specialized
    Debian distribution suitable for RPis. The distribution comes with Docker pre-installed,
    and is a minimal operating system optimized to run Docker on ARM devices. Hypriot
    OS is available as an image which can be flashed onto a micro SD card. The OS
    comes with a pre-installed SSH service, accessible through the configured credentials.
    Since password authentication is not secure, all nodes are set up to use public
    key authentication. In order to automate the setup of the nodes, the configuration
    management tool Ansible 9, is used to define the hosts and automate configuration
    tasks via SSH. Docker Swarm - Container Setup and Management. In order to initialize
    and setup a Docker swarm, the Docker engine CLI is used, starting with a single
    node swarm created on one of the RPI nodes, which becomes the manager for the
    newly created swarm. The manager stores join tokens for manager and worker nodes,
    which can be used to join other machines to the swarm. In addition, different
    tags can be set through the Docker CLI on each node that can be used to constrain
    the deployment of services to specific nodes. For other swarm management tasks
    such as promotions, demotions and manage the membership of nodes, Docker engine
    commands can be issued to any define manager. Application Services - Deployment.
    Docker stack deployment is used to deploy services to the swarm. To describe the
    stack, Docker uses a stack description in form of a Compose file, where multiple
    services can be defined. For each service part of the stack, the origin registry,
    ports and networks, mounted volumes, service name and replicas as well as deployment
    constraints, for example Docker node tags, can be specified. When deployed on
    a manager node, Docker will deploy each service in the stack to the nodes of the
    swarm, according to the constraints and definition, balancing out the containers
    on the available nodes. To deploy the compose file to the swarm manager and to
    set up the nodes, e.g., for the preparation of configuration files and mounted
    directories, Ansible scripts can be used (or alternatively these actions can be
    performed manually). The table below describes the allocation of services to nodes
    10, see also Fig. 5. Node Container Node 0 Data collection, Prometheus exporters
    Node 1 Data collection, Prometheus exporters Node 2 Data collection, Prometheus
    exporters Node 3 Spark worker 2, Prometheus exporters Node 4 Spark worker 1, Prometheus
    exporters Node 5 Spark master, Prometheus exporters, Prometheus, Grafana Node
    6 Spark worker 3, Prometheus exporters Node 7 Spark worker 4, Prometheus exporters
    Hadoop and Apache Spark - Deployment. Hadoop and Apache Spark are deployed to
    the cluster, together with the data collection application used to evaluate the
    implementation, through a Docker Compose file. Hadoop can be natively used to
    create clusters of computers, but Hadoop and also Apache Spark can also be deployed
    inside Docker containers. We chose the latter option to streamline the deployment
    process and avoid a tedious per-device installation of the software and the management
    of required dependencies. We used a Docker image to install Hadoop and Apache
    Spark inside a container and also for the set-up of the environment. In the final
    set-up, one master node and four separate worker nodes are deployed. Since the
    worker nodes act as DataNodes for the cluster, each worker node container is provided
    with sufficient storage space, by means of a standard 3.5 inch. 1TB hard disk,
    mounted as a volume. Note that the three remaining cluster nodes act as data producers.
    6 Data Processing and Monitoring at the Edge The process of data production, collection
    and analysis is at the core and support by Hadoop/Spark. Additionally, monitoring
    is critical. 6.1 Edge Data Collection and Analysis For the experimental evaluation
    of the architecture, we use two applications, one for simulating data production
    and collection on three nodes and a second one is deployed to the Apache Spark
    cluster to process the collected data. The applications are also used to gather
    data related to the performance of the system. Here, we focus on the data processing
    time. Data Collection. In order to simulate data collection, a Nodejs application
    sends a HTTP PUT request with the data content to the HDFS API creating a file
    in a specified interval of time. The data collection application is deployed on
    three cluster nodes. The experiment data are sample files exposed to and read
    by the application over the network allowing to change the size and the contents
    without having to modify the application and re-deploy it. Data Analysis. For
    collected data analysis, a Python application polls for newly created files every
    second and performs a count of single occurrences of words in the files. The application
    is derived, with some minor changes, from a sample application provided with the
    Apache Spark engine 11 in order to use a common benchmark. Our implementation
    follows the MapReduce model, i.e., creating a list of (key, value) pairs of the
    form (word, 1) for each occurrence of a word. This list is then grouped by keys
    (here words) and the Reduce step is then applied on each group, generating the
    sum of occurrences of each word. These last two steps are performed by one function,
    reduceByKey. The listing below illustrates the algorithm in pseudocode with the
    sample MapReduce implementation used as the test application. Finally, the deployment
    of the application to the Spark cluster is done using the Spark CLI tool sparksubmit
    to send it to the master node, which then distributes the application to the workers.
    6.2 Edge Monitoring We deployed a Prometheus 12-based monitoring stack to the
    cluster. Prometheus is an open source monitoring and alerting system, which uses
    a time series database and supports the integration with other software such as
    HAProxy, the ELK stack (Elasticsearch, Logstash and Kibana) or Docker. Since the
    task of Prometheus is to pull data from services, the stack uses a number of so-called
    exporters to collect data for different metrics and expose them to be collected
    by Prometheus. The Docker-related exporters that we used are cAdvisor 13, a daemon
    which collects and exposes container resource usage, and Node exporter 14, which
    exports hardware and system metrics exposed by the Linux kernel. In order to visualize
    and analyse the collected data, we used Grafana 15. Grafana allows to monitor
    and analyze metrics by creating dashboards exposed via a web user interface (UI).
    Grafana could be integrated with little configuration for monitoring of Docker
    containers on multiple Linux machines. The stack is deployed to the Docker cluster
    using a custom Compose file. One instance each of the cAdvisor and Node exporter
    is deployed on every RPi. Prometheus and Grafana are both deployed on one of the
    node. 7 Trusted Orchestration Management for Edge Clouds Besides performance,
    trust management is another key concern of edge architectures where often devices
    and software from different providers and consumers meet. In order to provide
    trust management, we propose here in this section a trust management component,
    the so-called Trusted Orchestration Management TOM, that we integrate with the
    container cluster architecture. Blockchain technologies shall be utilised here.
    7.1 Blockchain Principles Blockchains are shared distributed databases where the
    users can add to or read transactions with no one having full control, thus avoiding
    fraudulent manipulation. Thus, they form a distributed ledger and are also referred
    to as Distributed Ledger Technology DLT. New transactions are signed digitally
    and timestamped, allowing operations to be traced, thus determining their provenance.
    Blockchains enhance security in untrusted environments. Often, security concerns
    can be remedied if autonomy and trust capabilities of decentralised blockchains
    are used to provide security functions that can operate without a central authority
    in unreliable networks. Blockchains operate as follows. Blocks that represent
    transactions are added to the blockchain. An added transaction is cryptographically
    hashed and signed to ensure integrity and support non-repudiation. Smart contracts
    such as orchestration actions can also be attached to a blockchain. A problem
    with blockchains in general is massive data replication, requiring scalability
    and performance concerns to be addressed, specifically in constrained environment.
    7.2 Blockchain-Based Trusted Orchestration Orchestration is the key activity in
    clustered edge clouds that looks after the lifecycle management (create, run,
    delete) of data, software and hardware. In Fig. 6, we show the principles of a
    TOM architecture. Fig. 6. Trusted orchestration management. Full size image the
    key entities to be looked after are data, service and device. Devices like RPis
    host software services. These software services are in our case containerised.
    The containers process the data from the IoT layer, e.g., sensors. All entities
    need to be processed, which here means that the orchestrator needs to identify,
    place and orchestrate them (manage their lifecycle). Data is continuously produced,
    but needs to be identified when it enter the system at least in terms of its source.
    In dynamic environments, also software and device can join (or leave) the system
    and need to be identified, possibly more strictly in security terms. All need
    to be placed, i.e., transfered/connected to suitable host. These are containers
    for data processing or network nodes for hosting containers. Their lifecycle is
    then subsequently managed. In order to formalise this, our reference architecture
    builds on the W3C Provenance standard PROV. This standard introduces entities
    (here data, services, devices), agents (the orchestrator) and actions (identify,
    place, orchestrate in our case). The PROV standard then defines relationships
    between them: uses, is generated by, is followed by. Trust management is a function
    added to the functional orchestration actions. We aim to improve the trustworthiness
    of edge systems by recording identity, provenance and the actually executed orchestration
    actions in a tamper-proof, trustworthy infrastructure – the blockchain. We reflect
    the PROV relationships such as ‘is generated by’ or ‘uses’ in the records we enter
    into the blockchain. The TOM Orchestrator is in our case placed in the Master
    node of the RPi cluster network as an additional function. Figure 7 shows the
    TOM reference architecture applied to the clustered edge cloud setting, with data,
    containers and devices as entities. The TOM orchestrator looks after the identification,
    placement and orchestration of these. Three types of information are entered in
    to the blockchain: 1) identity of the entity, 2) provenance data using the define
    relationships, and 3) orchestration action as a smart contract. Fig. 7. TOM-enabled
    edge cluster architecture. Full size image 8 Evaluation and Discussion We cover
    different aspects in our evaluation. We start with some operation concerns. Then,
    we look at performance in the following experimental performance evaluation. Subsequently,
    we discuss the trust management approach. Finally, we look at a use case to further
    demonstrate applicability. 8.1 Maintainability, Fault-Tolerance and Build Times
    We can make some observations on some operations-oriented evaluation criteria:
    Maintainability and Ease of Operation. Using containerized services on a Docker
    swarm contributes significantly to achieving maintainability and ease of operation
    of the implementation. Fault-Tolerance. Using Docker requires only minimal overhead,
    but increases the overall fault tolerance of the system, since containers that
    have failed due to hardware or software problems can be restarted on any other
    node. This is managed by the cluster itself. Thus, Docker achieves high availability
    and increased fault tolerance. Image Building and Build Times. IA general limitation
    can be the lack of RPi (SBD) specific Docker images (for ARM architectures) that
    include applications such as Apache Hadoop and Apache Spark. Continuous integration
    and continuous delivery (CI/CD) services such as provided by Gitlab 16 can be
    used to build necessary images. Since the containers used to build the images
    run on a different instruction set than the Raspberry Pis, we used a system emulator,
    QEMU 17 inside the Dockerfiles to cross-build images. Despite some problems due
    to the Java Virtual Machine (JVM) displaying bugs during the builds, requiring
    to run some preparatory commands manually on the already deployed services, we
    preferred this over building the images on one of the cluster nodes due to the
    longer build times. The table below shows the build times of one of the used images
    on a common notebook 18, compared to build times of the same image on a RPi used
    in the cluster, to which the time to distribute the image on the nodes has to
    be added. Target architecture Build architecture Build time armv7 x86\(\_\)64
    6 m 1 s armv7 armv7 14 m 33 s The pull of the image from the Gitlab registry took
    about 6 min. While these build times seem high, this is an activity that is not
    frequently needed and can generally be tolerated. 8.2 Experimental Performance
    Evaluation A critical factor for small devices is to deliver the required performance
    in a constrained environment. The performance evaluation focus shall be on experimentally
    evaluating data processing time and resource consumption. Running the test applications
    required some fine tuning of the resources allocated to the Spark executors, influenced
    by the constraints imposed by the Raspberry Pis. The only relevant results were
    achieved by allocating 500 MB of memory to each executor, since the Spark process
    would generate out-of-memory exceptions when using less, while on the other hand,
    if given more memory, the processes would starve one of the components necessary
    for the Hadoop/Spark cluster. This memory allocation can be set during the submission
    of a job. The main aspects are now file processing time and resource consumption,
    which we discuss separately before ending with a discussion of results. File Processing
    Times. We based this on input data file sizes that reflect common IoT scenarios
    with common small-to-midsize data producers. The delay between the submission
    of a new file and the end of the analysis process was measured using time stamps
    by comparing the submission time with the time the output was printed to the standard
    output stream (stdout) of the submission shell. In both cases, the data analysis
    application was polling for new files every second, and files were submitted at
    a rate of one per second. File size Polling time Delay 1.04 KB 1 s 236 s 532 B
    1 s 61 s The results in the table above shows the measurements for files with
    around 500 B and 1 KB, respectively, that were submitted once per second. This
    reflects, as already said, a common small-to-midsize data production volume. The
    test cases aimed at exploring the limits of the RPi-based container cluster architecture
    for certain IoT and edge computing settings. The delays shown above can be considered
    too high for some real-time processing requirements, e.g., for any application
    which relies on short times for immediate actuation, and are unexpectedly high
    considering the file size and the submission rates used during the test runs.
    However, if only storage and analysis without immediate reaction is required or
    the sensors produce a limited volume of data (such as temperature sensors), then
    the setting we outlines is adequate. Resource Consumption. In our implementation,
    we had various services were distributed among the nodes of the cluster, see Fig.
    5. The data recorded by the Prometheus monitoring stack deployed shows no increase
    of the used resources during file submission and analysis by the respective services.
    We detail this now for CPU and memory. Fig. 8. Container CPU time, by node – see
    [1]. Full size image Fig. 9. Container CPU time, by container – see [1]. Full
    size image CPU. In Fig. 8 we show the CPU time use (by node) during the execution
    of the test application, while Fig. 9 shows the same data, divided by container.
    The shown records are for the 532 Bytes test file. As expected, the graphs show
    an increase of CPU workload on all Apache Spark nodes, in particular on the worker
    nodes of the cluster. The analysis application was submitted from node 3 (Spark
    worker 2), which explains the higher CPU use compared to the other nodes at point
    0 in the graphs, while data collection was started two minutes in, at the 120
    s mark, as can be seen by an increased CPU utilization by the Spark master node.
    Data collection and data analysis were stopped at 420 and 480 s, resp. Memory.
    Figures 10 and 11 show, similar to CPU, the memory use of the containers in Spark
    and the monitoring stack during the experiment divided by node and by container,
    respectively. As expected, we observe that memory usage by the Spark node is higher
    than on the other nodes, as it is used to submit the application and therefore
    acts as controller for the execution and collects the results from all other nodes.
    Note that the resource usage by the remaining system is not shown (e.g., the Docker
    daemons and system processes), which were constant during the test, with CPU time
    below 2% and memory use around 120 MB on each node stable. Fig. 10. Container
    memory use, by node – see [1]. Full size image Fig. 11. Container memory use,
    by container – see [1]. Full size image Performance Analysis and Discussion. The
    experimental results demonstrate that the system resources are not used optimally,
    with capacities both at the CPU and in particular for the memory of the devices.
    The results suggest that the delay is due to how the distribution and replication
    of small files is performed by HDFS (a typical block size used to split files
    by HDFS is 64 MB), causing a non-optimal use of system resources as well as Spark
    streaming capabilities. Besides the rather high delays and suboptimal resource
    usage, the recorded data shows an uneven CPU utilization by the Spark master container,
    reaching 0% around the 250 s mark, which was consistently irregular throughout
    all the test runs. This might be due to the file system, or rather HDFS, starving
    the process due to high I/O times. Here, further experiments with alternative
    sources might be better able to confirm reasons. Raspberry Pi 2 has now been replaced
    by RPi 3, which would allow some performance improvements. While in comparison
    the CPU only gains 300 MHz, it also updates its architecture from a Cortex-A7
    set to a Cortex-A53, i.e., an architecture improvement from 32-bit to 64-bit.
    This should result in much better performance of a factor 2 to 3 19. In terms
    of RAM and tact rate, where the Raspberry Pi 2 has 450 MHz, the Pi 3 has 900 MHz
    RAM. In order to summarise, the objective here was to determine some of the limits
    of the proposed infrastructure. Depending on the concrete application in question,
    our configuration could however still be sufficient, or could otherwise be improved
    through better hardware or software configuration. In order to utilise resources
    better, a controller allowing self-adaptation [20] to address performance and
    resource utilisation anomalies of the platform configuration [17, 18] is a solution
    that could address suboptimal resource utilisation. 8.3 Trust Management Review
    As such, containers can provide a degree of security through the in-build process
    isolation. However, in an open and often cross-organisation setting, more is need
    to secure the infrastructure and provide an additional degree of trust, particularly
    between partners that need to cooperate. For this situation, we introduced and
    applied the TOM reference model earlier on. The application of the TOM principles
    in a blockchain-supported architecture demonstrates that a degree of trust can
    be achieved. In more concrete terms, we mapped the PROV-based TOM model to Hyperledger
    Fabric [11]. Hyperledger Fabric is an open-source implementation of a permissioned
    distributed, decentralized ledger. It relies on a modular architecture, which
    enables pluggable components and implementations of different functionality (e.g.,
    consensus and encryption mechanisms). Differently from many widely used blockchain
    platforms where all nodes of the network can carry all the operations, fabric
    distinguishes between two types of nodes: worker nodes and peer nodes. Peer nodes
    are responsible for coordinating the consensus mechanism, validating transactions
    and committing transactions to the blockchain. Each peer maintains a copy of the
    blockchain. In our architecture a Hyperledger fabric is used as the PROV chain
    storing all the three block types (identity, provenance, orchestration). Each
    block contains thus transactions specifying the identity, provenance records,
    smart orchestration contracts of the interactions taking place in the network.
    Identity: Hyperledger fabric relies on public key infrastructures (PKI), which
    provide verifiable identities through a chain of trust to identify each entity
    (i.e., device, container and data). Provenance: One of the main features of the
    proposed architecture is the implementation of the W3C-PROV standard. Being able
    to track the origin of every piece of data in the system is at the core of blockchain
    technology. In the proposed architecture each asset has an attribute (i.e., derivedFrom)
    that connects it with its origin. Once the system is in place, starting from a
    data object, a recursive call would provide the complete chain of provenance.
    Orchestration: To support the orchestration requirements of the reference scenario,
    a high degree of nodes management is required. The proposed architecture takes
    advantage of Docker Swarm to dispatch services on remote nodes as well as start
    containers to run different services. Fig. 12. CCAM scenario: 5G-enable MEC-to-vehicle
    coordination. Full size image 8.4 Cooperative, Connected and Automated Mobility
    Use Case In order to validate the usefulness of our architecture for concrete
    application settings, we discuss in this section its application to a use case.
    Cooperative, Connected and Automated Mobility (CCAM) is a context in which for
    instance vehicles are connected using a network. Often, compute and storage capabilities
    in this application area are limited and largely similar to the capabilities of
    RPis, see [26, 27]. These compute capabilities are often spread between in-vehicle
    and road-side computation and edge clouds. Often the term MEC is used here, standing
    for Mobile Edge Computing or Multi-Access Edge Computing (in 2017, the ETSI standardisation
    body officially changed the name from Mobile Edge Computing to Multi-Access Edge
    Computing). MEC often refers to communication using mobile phone networks. Lightweight
    MECs provide computational and storage services close to the vehicles. Figure
    12 shows a MEC architecture that supports direct vehicular coordination. Here,
    the cars are data producers (providing position or car status data) and the MEC
    nodes are data consumers that provide e.g. lane change support (or other coordinated,
    cooperative maneouvres). The orchestrator for this coordination between vehicles
    and road-side devices is a dedicated MEC node. Fig. 13. CCAM architecture: lightweight
    MEC cluster. Full size image In Fig. 13, we detail further how the orchestrator
    enables virtualised network functions or application services, e.g., for the lane
    change scenario. Other services for similar CCAM usage scenarios could be video
    streaming, where different MEC nodes will buffer video content close to the position
    of the vehicle. As a consequence of the dynamic nature here, vehicles move and
    might connect differently over time. The different services such as lane changing
    or video streaming have different quality requirements (lane changing is latency
    critical, but not high volume in data, whereas video streaming is more of the
    opposite). An important function here is the placement engine that assigns suitable
    nodes for virtual functions (in container format) to cluster nodes depending on
    their capabilities and capacities. Figure 14 shows a layered orchestration and
    management stack for this, which includes placement, lifecycle management (LCM)
    and quality management engines as central orchestration functions. We refer here
    to TOSCA as the service specification and orchestration format, but other semantic
    description notations [23, 34] for description and matching are possible. What
    this short use case discussion shows is that our containerised RPi cluster architecture
    is a typical architecture for common edge computing scenarios. Fig. 14. CCAM layered
    light management and orchestration stack for MEC. Full size image 9 Conclusions
    Leveraging the lightweight containerization and orchestration capabilities offered
    by Docker, allows for an edge computing architecture that is simple to manage
    and has high fault-tolerance. A lightweight containerised cluster platform can
    be suitable for a common range of IoT data processing applications at the edge.
    Due to the Docker swarm actively maintaining the state of the services, we gain
    high availability of services, making the cluster self-healing, while also making
    scaling simple. In practical terms, for our platform configuration, most of the
    images used were created from scratch, or at least heavily customized from similar
    implementations to meet the requirements. Nonetheless, the number of projects
    targeting ARM devices are growing in popularity. The monitoring stack, which we
    used in a performance test bed for the implementation and applications, was available
    as a ready-to-use Docker compose file. Further benefits apply. Low energy and
    cost are properties of single board devices, that are still able to run complex
    infrastructures by means of clustering, are promising with regards to the overall
    reduction of infrastructure costs even in the presence of high volumes of data.
    We have shown that it is possible to implement a data streaming processing system
    on device clusters with strict constraints on networking and computing resources
    like the Raspberry Pis to create a low-cost and low-power cluster capable of processing
    large amounts of data. Though, the actual performance of our prototype system
    has limits. For instance, a performance limitation of the prototype implementation
    was caused by the choice of the Hadoop distributed file system (HDFS) as source
    for data streams of small files, indicating that not all components are suitable
    for the constained environment. Trust [10, 31] has been an equally important aspect
    that we included in our discussion. The presented lightweight edge architectures
    are important for many new application areas. Autonomous driving is an example
    where mobile edge clouds are required. Vehicles need to coordinate their behaviour,
    often using modern telecommunications technologies such as 5G mobile networks.
    This requires onboard computing capability as well as local edge clouds in addition
    to centralised clouds in order to guarantee the low latency requirements. SBC
    clusters are an example of computational infrastructure close the outer edge that
    can support these scenarios as our use case analysis has shown. In the future,
    we will explore different configuration options of Apache Spark, e.g., using the
    network as a data source. This would allow the use of IoT data transmission protocols
    like MQTT, while Hadoop and HDFS might be used on pre-processed and aggregated
    data. Furthermore, the model used to evaluate the implementation could be extended
    in order to verify the actual performance of the system in more scenarios. Here,
    alternative data stream sources could also be considered as part of future work.
    In this work, we only looked at identifying performance problems. An opportunity
    is using machine learning [21] to implement autonomous configuration and resource
    management [5]. Notes 1. http://www.carberry.it. 2. http://www.instructables.com/id/OBD-Pi/.
    3. https://www.pololu.com/product/2506. 4. Docker Engine, https://docs.docker.com/engine.
    5. Docker Swarm, https://docs.docker.com/engine/swarm/. 6. Nodejs, https://nodejs.org.
    7. Veracity Global Camswitch 8, http://www.veracityglobal.com/products/networked-video-integration-devices/camswitch-mobile.aspx.
    8. Hypriot OS, https://blog.hypriot.com/about/. 9. Ansible, https://www.ansible.com/.
    10. Prometheus exporters: Armexporter, Node exporter, cAdvisor. 11. Spark sample
    applications, https://github.com/apache/spark/tree/master/examples. 12. Prometheus,
    https://prometheus.io/. 13. Google cAdvisor, https://github.com/google/cadvisor.
    14. Node exporter, https://github.com/prometheus/ node_exporter. 15. Grafana,
    https://grafana.com/. 16. Gitlab, https://about.gitlab.com/. 17. QEMU, https://www.qemu.org/.
    18. The model used is a HP 355 G2, with AMD A8-6410 2 GHz CPU and 12 GB memory.
    19. https://www.jeffgeerling.com/blog/2018/raspberry-pi-3-b-review-and-performance-comparison.
    References Scolati, R., Fronza, I., El Ioini, N., Samir, A., Pahl, C.: A containerized
    big data streaming architecture for edge cloud computing on clustered single-board
    devices. In: International Conference on Cloud Computing and Services Science
    (2019) Google Scholar   Ambroz, M., Hudomalj, U., Marinsek, A., Kamnik, R.: Raspberry
    pi-based low-cost connected device for assessing road surface friction. Electronics
    8(3), 341 (2019) Google Scholar   Apache: Hadoop (2019). https://hadoop.apache.org.
    Accessed June 2019 Apache: Spark (2019). https://spark.apache.org. Accessed June
    2019 Arabnejad, H., Pahl, C., Jamshidi, P., Estrada, G.: A comparison of reinforcement
    learning techniques for fuzzy cloud auto-scaling. In: 17th IEEE/ACM International
    Symposium on Cluster, Cloud and Grid Computing (2017) Google Scholar   Baldeschwieler,
    E.: Yahoo! launches world’s largest hadoop production application (2018). http://yahoohadoop.tumblr.com/post/98098649696/
    yahoo-launches-worlds-largest-hadoop-production. Accessed September 2018 Baumgartl,
    R., Muller, D.: Raspberry pi as an inexpensive platform for real-time traffic
    jam analysis on the road. In: Federated Conference on Computer Science and Information
    Systems (2018) Google Scholar   Dean, J., Ghemawat, S.: Mapreduce: simplified
    data processing on large clusters. In: OSDI 2004 Symposium on Operating System
    Design and Implementation (2004) Google Scholar   Docker (2018). https://docs.docker.com/.
    Accessed September 2018 El Ioini, N., Pahl, C.: A review of distributed ledger
    technologies. In: Panetto, H., Debruyne, C., Proper, H.A., Ardagna, C.A., Roman,
    D., Meersman, R. (eds.) OTM 2018. LNCS, vol. 11230, pp. 277–288. Springer, Cham
    (2018). https://doi.org/10.1007/978-3-030-02671-4_16 Chapter   Google Scholar   El
    Ioini, N., Pahl, C.: Trustworthy orchestration of container based edge computing
    using permissioned blockchain. In: Fifth International Conference on Internet
    of Things: Systems, Management and Security (IoTSMS) (2018) Google Scholar   Femminella,
    M., Pergolesi, M., Reali, G.: Performance evaluation of edge cloud computing system
    for big data applications. In: 5th IEEE International Conference on Cloud Networking
    (Cloudnet), pp. 170–175 (2016) Google Scholar   Fowley, F., Pahl, C., Jamshidi,
    P., Fang, D., Liu, X.: A classification and comparison framework for cloud service
    brokerage architectures. IEEE Trans. Cloud Comput. 6(2), 358–371 (2018) Article   Google
    Scholar   Gillam, L., Katsaros, K., Dianati, M., Mouzakitis, A.: Exploring edges
    for connected and autonomous driving. In: Conference on Computer Communications
    WS (2018) Google Scholar   Haramaki, T., Nishino, H.: A safe driving support system
    based on distributed cooperative edge computing. In: International Conference
    on Consumer Electronics (2018) Google Scholar   Heinrich, R., et al.: Performance
    engineering for microservices: research challenges and directions. In: Proceedings
    of the 8th ACM/SPEC on International Conference on Performance Engineering Companion
    (2017) Google Scholar   Jamshidi, P., Sharifloo, A., Pahl, C., Arabnejad, A.,
    Metzger, A., Estrada, G.: Fuzzy self-learning controllers for elasticity management
    in dynamic cloud architectures. In: 12th International ACM Conference on Quality
    of Software Architectures (2016) Google Scholar   Jamshidi, P., Sharifloo, A.,
    Pahl, C., Metzger, A., Estrada, G.: Self-learning cloud controllers: Fuzzy q-learning
    for knowledge evolution. arXiv preprint arXiv:1507.00567 (2015) Jamshidi, P.,
    Pahl, C., Mendonca, N.C., Lewis, J., Tilkov, S.: Microservices: the journey so
    far and challenges ahead. IEEE Softw. 35(3), 24–35 (2018) Article   Google Scholar   Jamshidi,
    P., Pahl, C., Mendonca, N.C.: Managing uncertainty in autonomic cloud elasticity
    controllers. IEEE Cloud Comput. 3, 50–60 (2016) Google Scholar   Jamshidi, P.,
    Pahl, C., Chinenyeze, S., Liu, X.: Cloud migration patterns: a multi-cloud service
    architecture perspective. In: Toumani, F., et al. (eds.) ICSOC 2014. LNCS, vol.
    8954, pp. 6–19. Springer, Cham (2015). https://doi.org/10.1007/978-3-319-22885-3_2
    Chapter   Google Scholar   Jamshidi, P., Pahl, C., Mendonca, N.C.: Pattern-based
    multi-cloud architecture migration. Softw.: Practice Experience 47(9), 1159–1184
    (2017) Google Scholar   Javed, M., Abgaz, Y.M., Pahl, C.: Ontology change management
    and identification of change patterns. J. Data Semant. 2(2–3), 119–143 (2013)
    Article   Google Scholar   Johnston, S.J., et al.: Commodity single board computer
    clusters and their applications. Future Gen. Comput. Syst. 89, 201–212 (2018)
    Article   Google Scholar   Hentschel, K., Jacob, D., Singer, J., Chalmers, M.:
    Supersensors: Raspberry pi devices for smart campus infrastructure. In: IEEE International
    Conference on Future Internet of Things and Cloud (FiCloud) (2016) Google Scholar   Morabito,
    R.: A performance evaluation of container technologies on internet of things devices.
    In: IEEE Conference on Computer Communications Workshops (2016) Google Scholar   Morabito,
    R., Farris, I., Iera, A., Taleb, T.: Evaluating performance of containerized iot
    services for clustered devices at the network edge. IEEE Internet Things J. 4(4),
    1019–1030 (2017) Article   Google Scholar   Morabito, R., Petrolo, R., Loscri,
    V., Mitton, N., Ruggeri, G., Molinaro, A.: Lightweight virtualization as enabling
    technology for future smart cars. In: Symposium on Integrated Network and Service
    Management, pp. 1238–1245. IEEE (2017) Google Scholar   Naik, N.: Docker container-based
    big data processing system in multiple clouds for everyone. In: International
    Systems Engineering Symposium (ISSE), pp. 1–7 (2017) Google Scholar   Pahl, C.,
    Lee, B.: Containers and clusters for edge cloud architectures - a technology review.
    In: IEEE International Conference on Future Internet of Things and Cloud (2015)
    Google Scholar   Pahl, C., El Ioini, N., Helmer, S., Lee, B.: An architecture
    pattern for trusted orchestration in IoT edge clouds. In: International Conference
    Fog and Mobile Edge Computing (2018) Google Scholar   Pahl, C., Jamshidi, P.,
    Zimmermann, O.: Architectural principles for cloud software. ACM Trans. Internet
    Technol. (TOIT) 18(2), 17 (2018) Article   Google Scholar   Pahl, C., Helmer,
    S., Miori, L., Sanin, J., Lee, B.: A container-based edge cloud PaaS architecture
    based on raspberry pi clusters. In: IEEE International Conference on Future Internet
    of Things and Cloud Workshops (2016) Google Scholar   Pahl, C.: An ontology for
    software component matching. In: Pezzè, M. (ed.) FASE 2003. LNCS, vol. 2621, pp.
    6–21. Springer, Heidelberg (2003). https://doi.org/10.1007/3-540-36578-8_2 Chapter   MATH   Google
    Scholar   Pahl, C., Brogi, A., Soldani, J., Jamshidi, P.: Cloud container technologies:
    a state-of-the-art review. IEEE Trans. Cloud Comput. 7, 677–692 (2017) Google
    Scholar   Renner, T., Meldau, M., Kliem, A.: Towards container-based resource
    management for the internet of things. In: International Conference on Software
    Networking (2016) Google Scholar   Renner, M.: Testing high availability of docker
    swarm on a raspberry pi cluster. https://blog.hypriot.com/post/high-availability-with-docker.
    Accessed 09 2018 Renner, M.: Evaluation of high availability performance of kubernetes
    and docker swarm on a raspberry pi cluster. In: Highload++ Conference (2016) Google
    Scholar   Raspberry Pi Foundation (2018). https://www.raspberrypi.org/products/raspberry-p
    i-2-model-b/. Accessed Sept 2018 Stager, A., Bhan, L., Malikopoulos, A., Zhao,
    L.: A scaled smart city for experimental validation of connected and automated
    vehicles. IFAC 51(9), 130–135 (2018) Google Scholar   Stevens, A., et al.: Cooperative
    automation through the cloud: the CARMA project. In: Proceedings of 12th ITS European
    Congress (2017) Google Scholar   Taibi, D., Lenarduzzi, V., Pahl, C.: Architectural
    patterns for microservices: a systematic mapping study. In: International Conference,
    Cloud Computing and Services Science (2018) Google Scholar   Tso, F.P., White,
    D.R., Jouet, S., Singer, J., Pezaros, D.P.: The glasgow raspberry pi cloud: a
    scale model for cloud computing infrastructures. In: IEEE 33rd International Conference
    on Distributed Computing Systems Workshops (2013) Google Scholar   Turner, V.:
    The digital universe of opportunities: rich data and the increasing value of the
    internet of things. IDC Report (2014) Google Scholar   Vilalta, R., et al.: Control
    and management of a connected car using YANG/RESTCONF and cloud computing. In:
    International Conference on the Network of the Future (2017) Google Scholar   von
    Leon, D., Miori, L., Sanin, J., El Ioini, N., Helmer, S., Pahl, C.: A performance
    exploration of architectural options for a middleware for decentralised lightweight
    edge cloud architectures. In: International Conference Internet of Things, Big
    Data & Security (2018) Google Scholar   von Leon, D., Miori, L., Sanin, J., El
    Ioini, N., Helmer, S., Pahl, C.: A lightweight container middleware for edge cloud
    architectures. In: Fog and Edge Computing: Principles and Paradigms, pp. 145–170.
    Wiley (2019) Google Scholar   Wang, Y., Goldstone, R., Yu, W., Wang, T.: Characterization
    and optimization of memory-resident mapreduce on HPC systems. In: IEEE 28th International
    Parallel and Distributed Processing Symposium (2014) Google Scholar   Download
    references Acknowledgements This work has received funding from the EU’s Horizon
    2020 research and innovation programme under grant agreement 825012 - Project
    5G-CARMEN. Author information Authors and Affiliations Free University of Bozen-Bolzano,
    Bolzano, Italy Remo Scolati, Ilenia Fronza, Nabil El Ioini, Areeg Samir, Hamid
    Reza Barzegar & Claus Pahl Corresponding author Correspondence to Claus Pahl .
    Editor information Editors and Affiliations Columbia University, New York, NY,
    USA Donald Ferguson Escola d’Enginyeria, Bellaterra, Barcelona, Spain Víctor Méndez
    Muñoz Free University of Bozen-Bolzano, Bolzano, Bolzano, Italy Claus Pahl Dublin
    City University, Dublin, Ireland Markus Helfert Rights and permissions Reprints
    and permissions Copyright information © 2020 Springer Nature Switzerland AG About
    this paper Cite this paper Scolati, R., Fronza, I., El Ioini, N., Samir, A., Barzegar,
    H.R., Pahl, C. (2020). A Containerized Edge Cloud Architecture for Data Stream
    Processing. In: Ferguson, D., Méndez Muñoz, V., Pahl, C., Helfert, M. (eds) Cloud
    Computing and Services Science. CLOSER 2019. Communications in Computer and Information
    Science, vol 1218. Springer, Cham. https://doi.org/10.1007/978-3-030-49432-2_8
    Download citation .RIS.ENW.BIB DOI https://doi.org/10.1007/978-3-030-49432-2_8
    Published 04 June 2020 Publisher Name Springer, Cham Print ISBN 978-3-030-49431-5
    Online ISBN 978-3-030-49432-2 eBook Packages Computer Science Computer Science
    (R0) Share this paper Anyone you share the following link with will be able to
    read this content: Get shareable link Provided by the Springer Nature SharedIt
    content-sharing initiative Publish with us Policies and ethics Sections Figures
    References Abstract Introduction State-of-the-Art Discussion Literature Review
    Platform Technologies A Lightweight Platform for Edge Data Processing Data Processing
    and Monitoring at the Edge Trusted Orchestration Management for Edge Clouds Evaluation
    and Discussion Conclusions Notes References Acknowledgements Author information
    Editor information Rights and permissions Copyright information About this paper
    Publish with us Discover content Journals A-Z Books A-Z Publish with us Publish
    your research Open access publishing Products and services Our products Librarians
    Societies Partners and advertisers Our imprints Springer Nature Portfolio BMC
    Palgrave Macmillan Apress Your privacy choices/Manage cookies Your US state privacy
    rights Accessibility statement Terms and conditions Privacy policy Help and support
    129.93.161.219 Big Ten Academic Alliance (BTAA) (3000133814) - University of Nebraska-Lincoln
    (3000134173) © 2024 Springer Nature'
  inline_citation: '>'
  journal: Communications in computer and information science
  limitations: '>'
  pdf_link: null
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: A Containerized Edge Cloud Architecture for Data Stream Processing
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1145/3311790.3396659
  analysis: '>'
  authors:
  - Peter Z. Vaillancourt
  - Bennett Wineholt
  - Brandon Barker
  - Plato Deliyannis
  - Jackie Zheng
  - Akshay Suresh
  - A. Brazier
  - Richard Knepper
  - Rich Wolski
  citation_count: 7
  full_citation: '>'
  full_text: '>

    This website uses cookies We occasionally run membership recruitment campaigns
    on social media channels and use cookies to track post-clicks. We also share information
    about your use of our site with our social media, advertising and analytics partners
    who may combine it with other information that you’ve provided to them or that
    they’ve collected from your use of their services. Use the check boxes below to
    choose the types of cookies you consent to have stored on your device. Use necessary
    cookies only Allow selected cookies Allow all cookies Necessary Preferences Statistics
    Marketing Show details       skip to main content University of Nebraska Lincoln
    Browse About Sign in Register Journals Magazines Proceedings Books SIGs Conferences
    People Search ACM Digital Library Advanced Search Conference Proceedings Upcoming
    Events Authors Affiliations Award Winners HomeConferencesPEARCProceedingsPEARC
    ''20Reproducible and Portable Workflows for Scientific Computing and HPC in the
    Cloud RESEARCH-ARTICLE SHARE ON Reproducible and Portable Workflows for Scientific
    Computing and HPC in the Cloud Authors: Peter Vaillancourt , Bennett Wineholt
    , Brandon Barker , + 6 Authors Info & Claims PEARC ''20: Practice and Experience
    in Advanced Research ComputingJuly 2020Pages 311–320https://doi.org/10.1145/3311790.3396659
    Published:26 July 2020Publication History 4 citation 164 Downloads View all FormatsPDF
    PEARC ''20: Practice and Experience in Advanced Research Computing Reproducible
    and Portable Workflows for Scientific Computing and HPC in the Cloud Pages 311–320
    Previous Next ABSTRACT Supplemental Material References Cited By Index Terms Recommendations
    Comments ABSTRACT The increasing availability of cloud computing services for
    science has changed the way scientific code can be developed, deployed, and run.
    Many modern scientific workflows are capable of running on cloud computing resources.
    Consequently, there is an increasing interest in the scientific computing community
    in methods, tools, and implementations that enable moving an application to the
    cloud and simplifying the process, and decreasing the time to meaningful scientific
    results. In this paper, we have applied the concepts of containerization for portability
    and multi-cloud automated deployment with industry-standard tools to three scientific
    workflows. We show how our implementations provide reduced complexity to portability
    of both the applications themselves, and their deployment across private and public
    clouds. Each application has been packaged in a Docker container with its dependencies
    and necessary environment setup for production runs. Terraform and Ansible have
    been used to automate the provisioning of compute resources and the deployment
    of each scientific application in a Multi-VM cluster. Each application has been
    deployed on the AWS and Aristotle Cloud Federation platforms. Variation in data
    management constraints, Multi-VM MPI communication, and embarrassingly parallel
    instance deployments were all explored and reported on. We thus present a sample
    of scientific workflows that can be simplified using the tools and our proposed
    implementation to deploy and run in a variety of cloud environments. Skip Supplemental
    Material Section Supplemental Material 3311790.3396659.mp4 Presentation video
    MP4 283.9 MB Play streamDownload References Devansh Agarwal, Kshitij Aggarwal,
    Sarah Burke-Spolaor, Duncan R. Lorimer, and Nathaniel Garver-Daniels. 2019. Towards
    Deeper Neural Networks for Fast Radio Burst Detection. arxiv:1902.06343 [astro-ph.IM]
    Amazon Web Services Inc.2020. Amazon Web Services (AWS). Amazon Web Services Inc.
    Retrieved October 23, 2019 from https://aws.amazon.com/ Amazon Web Services Inc.2020.
    Amazon Web Services (AWS) storage services. Amazon Web Services Inc. Retrieved
    October 23, 2019 from https://aws.amazon.com/products/storage/ Show All References
    Cited By View all Munhoz V and Castro M. (2023). Enabling the execution of HPC
    applications on public clouds with HPC@Cloud toolkit . Concurrency and Computation:
    Practice and Experience. 10.1002/cpe.7976. 36:8. Online publication date: 10-Apr-2024.
    https://onlinelibrary.wiley.com/doi/10.1002/cpe.7976 Nicolae B, Islam T, Ross
    R, Van Dam H, Assogba K, Shpilker P, Titov M, Turilli M, Wang T, Kilic O, Jha
    S and Pouchard L. (2023). Building the I (Interoperability) of FAIR for Performance
    Reproducibility of Large-Scale Composable Workflows in RECUP 2023 IEEE 19th International
    Conference on e-Science (e-Science). 10.1109/e-Science58273.2023.10254808. 979-8-3503-2223-1.
    (1-7). https://ieeexplore.ieee.org/document/10254808/ Lofton M, Howard D, Thomas
    R and Carey C. (2023). Progress and opportunities in advancing near‐term forecasting
    of freshwater quality. Global Change Biology. 10.1111/gcb.16590. 29:7. (1691-1714).
    Online publication date: 1-Apr-2023. https://onlinelibrary.wiley.com/doi/10.1111/gcb.16590
    Show All Cited By Index Terms Reproducible and Portable Workflows for Scientific
    Computing and HPC in the Cloud Applied computing Computer systems organization
    Architectures Distributed architectures Social and professional topics Software
    and its engineering Software creation and management Software notations and tools
    Software organization and properties Software system structures Distributed systems
    organizing principles Index terms have been assigned to the content through auto-classification.
    Recommendations Comparing FutureGrid, Amazon EC2, and Open Science Grid for Scientific
    Workflows Scientists have many computing infrastructures available to conduct
    their research, including grids and public or private clouds. This article explores
    the use of these cyberinfrastructures to execute scientific workflows, an important
    class of ... Read More Enhancing the Grid with Cloud Computing Scientific computing
    has evolved considerably in recent years. Scientific applications have become
    more complex and require an increasing number of computing resources to perform
    on a large scale. Grid computing has become widely used and is the chosen ...
    Read More Cloud Paradigms and Practices for Computational and Data-Enabled Science
    and Engineering Clouds are rapidly joining high-performance computing (HPC) systems,
    clusters, and grids as viable platforms for scientific exploration and discovery.
    As a result, understanding application formulations and usage modes that are meaningful
    in such a ... Read More Comments 47 References View Table Of Contents Footer Categories
    Journals Magazines Books Proceedings SIGs Conferences Collections People About
    About ACM Digital Library ACM Digital Library Board Subscription Information Author
    Guidelines Using ACM Digital Library All Holdings within the ACM Digital Library
    ACM Computing Classification System Digital Library Accessibility Join Join ACM
    Join SIGs Subscribe to Publications Institutions and Libraries Connect Contact
    Facebook Twitter Linkedin Feedback Bug Report The ACM Digital Library is published
    by the Association for Computing Machinery. Copyright © 2024 ACM, Inc. Terms of
    Usage Privacy Policy Code of Ethics'
  inline_citation: '>'
  journal: Practice and Experience in Advanced Research Computing
  limitations: '>'
  pdf_link: null
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: Reproducible and Portable Workflows for Scientific Computing and HPC in the
    Cloud
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.23919/icitst.2017.8356378
  analysis: '>'
  authors:
  - Walter Blair
  - Aspen Olmsted
  - Paul E. Anderson
  citation_count: 2
  full_citation: '>'
  full_text: '>

    IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Subscribe Donate Cart Create
    Account Personal Sign In Browse My Settings Help Institutional Sign In All Books
    Conferences Courses Journals & Magazines Standards Authors Citations ADVANCED
    SEARCH Conferences >2017 12th International Confe... Docker vs. KVM: Apache spark
    application performance and ease of use Publisher: IEEE Cite This PDF Walter Blair;
    Aspen Olmsted; Paul Anderson All Authors 2 Cites in Papers 725 Full Text Views
    Abstract Document Sections I. Introduction II. Related Work III. Hypothesis IV.
    Methods V. Expected Results Authors Figures References Citations Keywords Metrics
    Abstract: In this paper, we compare the performance and ease of use of an Apache
    Spark application deployed via Docker and alternatively via KVM. Docker containers
    have rapidly grown in popularity for dynamic cloud computing and for general-use
    application deployment and collaboration. Recent work comparing the performance
    of Docker versus VM deployments has found that Docker''s reduced overhead results
    in better performance. We compare Docker versus VM deployments of an Apache Spark
    application in regard to ease of use in a collaborative development environment.
    We expect that developing the application in a containerized environment will
    result in fewer post-deployment tests that fail compared to application versions
    that are developed in non-virtual or VM environments. Future work will closely
    examine the performance of these two implementations and more generally investigate
    potential trade-offs between performance and ease of use. Published in: 2017 12th
    International Conference for Internet Technology and Secured Transactions (ICITST)
    Date of Conference: 11-14 December 2017 Date Added to IEEE Xplore: 10 May 2018
    ISBN Information: DOI: 10.23919/ICITST.2017.8356378 Publisher: IEEE Conference
    Location: Cambridge, UK I. Introduction Computationally demanding processes and
    workflows, such as those involved in the fields of genomics and transcriptomics,
    rely decreasingly on dedicated HPC clusters and increasingly on dynamic cloud
    clusters. Driven largely by cost benefits, dynamic cloud infrastructures that
    spin up and pull down VMs or containers as needed promise to be the future of
    big data crunching in the life sciences [1]. A great deal of research is ongoing
    to compare cloud infrastructures based on VMs to those based on containers like
    Docker, and recent publications have used Docker to achieve dynamic cloud performance
    that is extremely fast and efficient [2], [3]. Sign in to Continue Reading Authors
    Figures References Citations Keywords Metrics More Like This A Comparative Analysis
    of Container Orchestration Tools in Cloud Computing 2022 9th International Conference
    on Computing for Sustainable Global Development (INDIACom) Published: 2022 Cloud
    computing service framework for bioinformatics tools 2015 IEEE International Conference
    on Bioinformatics and Biomedicine (BIBM) Published: 2015 Show More IEEE Personal
    Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED
    DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION
    TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732
    981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility
    | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap |
    IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s largest
    technical professional organization dedicated to advancing technology for the
    benefit of humanity. © Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: null
  publication_year: 2017
  relevance_score1: 0
  relevance_score2: 0
  title: 'Docker vs. KVM: Apache spark application performance and ease of use'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/pdp2018.2018.00087
  analysis: '>'
  authors:
  - Attila Csaba Marosi
  - Attila Farkas
  - Róbert Lovas
  citation_count: 4
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy IEEE.org IEEE Xplore IEEE
    SA IEEE Spectrum More Sites Donate Cart Create Account Personal Sign In Browse
    My Settings Help Access provided by: University of Nebraska - Lincoln Sign Out
    All Books Conferences Courses Journals & Magazines Standards Authors Citations
    ADVANCED SEARCH Conferences >2018 26th Euromicro Internati... An Adaptive Cloud-Based
    IoT Back-end Architecture and Its Applications Publisher: IEEE Cite This PDF Attila
    Csaba Marosi; Attila Farkas; Robert Lovas All Authors 3 Cites in Papers 417 Full
    Text Views Abstract Document Sections I. Introduction II. Related Work III. Proposed
    Architecture IV. Agrodat.hu: Precision Agriculture V. Evaluation Show Full Outline
    Authors Figures References Citations Keywords Metrics Abstract: Internet of Things
    (IoT) is playing increasingly more fundamental role in wide range of sectors,
    including industry, agriculture, health care, and other services. In many cases,
    cloud computing serves as an elastic and efficient paradigm for implementing IoT
    back-ends. With the emerging lightweight software container technologies, the
    feasible approaches and design options for such IoT back-ends have been significantly
    enriched. In our paper we present the evolution of an IoT back-end, which is responsible
    for collecting (among others) meteorological, image and soil data from cultivated
    fields in order to enable precision farming. The different versions, namely the
    cloud VM-based and the Docker containerized variants, provide highly scalable
    and vendor independent (cloud provider agnostic) solutions, therefore they can
    form a robust and adaptive framework for further pilot applications areas, e.g.
    Connected Cars and Industry 4.0, as the presented benchmarks illustrate the throughput
    and other parameters of the current implementation in the paper. Published in:
    2018 26th Euromicro International Conference on Parallel, Distributed and Network-based
    Processing (PDP) Date of Conference: 21-23 March 2018 Date Added to IEEE Xplore:
    07 June 2018 ISBN Information: Electronic ISSN: 2377-5750 DOI: 10.1109/PDP2018.2018.00087
    Publisher: IEEE Conference Location: Cambridge, UK SECTION I. Introduction Precision
    Farming in agriculture is a special method of crop management that allows farmers
    to decide on (among others) which areas of land/crop within a field can be managed
    with reduced levels of fertilizer, chemicals, and irrigation water depending on
    e.g. the yield potential of the crop in the given area. There are benefits of
    the method; the cost of producing the crop can be reduced and, on the other hand,
    the risk of environmental pollution can be also significantly smaller at the same
    time. In general, for implementing precision farming and related methods a vast
    amount of data have to be collected and analyzed from the fields [1]. Large scale
    projects including national level projects, such as Agrodat.hu from Hungary [2],
    require even more sophisticated IoT, cloud [3], Big Data [4] and other ICT solutions
    starting from the sensor level, through the applied communication network, and
    by ending with the data collector/processing/storage facilities, and knowledge
    center with decision support system. IoT back-end is needed for several other
    use case scenarios as well, including Connected Cars [5], [6] and Industry 4.0
    [7]. The paper is structured as follows. Section II discusses related work including
    related IoT solutions. Section III describes the different architecture variants
    and their reference implementations. Section IV details the applications built
    on top of the architecture. Section V evaluates our framework, while section VI
    presents future work and concludes the paper. SECTION II. Related Work Amazon
    Web Services (AWS), Microsoft Azure and Google Cloud may be considered the three
    dominant forces in public cloud computing, and all three provide their own IoT
    platform and services [8]–[10]. These are generic, hosted platforms and not available
    as an on premise private solution. There are several proposals available for big
    data processing that aim to provide a generic architecture rather than one that
    fits a single use-case [11]–[13]. The Lambda Architecture for Big Data [12] aims
    to decompose computing arbitrary functions on arbitrary dataset in real time into
    three layers: (i) speed layer; (ii) serving layer; and (iii) batch layer. The
    main goal of the batch layer is to provide high level accuracy with its processing
    capabilities on all available data when generating views, i.e. this layer is able
    to fix any errors using the complete data set (and later updating the already
    existing views). Outputs are mostly stored in a read-only database, with updates
    completely replacing existing precomputed views. Hadoop [14] is the de facto standard
    for batch-processing in most high-throughput systems. The speed layer intended
    to process data streams in real-time even without fix-ups or completeness of such
    streams. As a trade-off, the speed layer sacrifices throughput when it provides
    real-time views on the latest data in order to minimize latency. Stream-processing
    technologies are typically used here, e.g., Apache Storm [15], Apache Spark [16].
    Outputs from both layers are stored in the so-called serving layer. It is responsible
    for responding ad-hoc queries either by providing precomputed views or building
    views. Typically dedicated stores are used like Apache Cassandra [17], Apache
    HBase [18] for speed-layer output, and Cloudera Impala [19] for batch-layer output.
    The architecture emphasizes the problem of reprocessing data thus, processing
    input data over and over again. This allows re-evaluation of data in case of bugs
    or when the application simply evolves and new outputs are required from the same
    data. The lambda architecture (or a variant of it) is used by Yahoo for analytics
    on its advertising data warehouse and by Metamarkets [20]. The FIWARE Big Data
    Architecture [21] was created within the FIWARE (Core Platform of the Future Internet)
    project as one of many Generic Enablers (GEs). A GE represents a functional building
    unit. A GE implementation supports a given set of functions over a set of APIs
    and interoperable interfaces that conform to the open specifications given for
    that GE [22]. The Big Data GE architecture expands the basic Apache Hadoop one.
    The Master Node has all of the management softwares and acts as a frontend for
    the users. Infinity is the permanent storage cluster (based on HDFS). Computing
    clusters have a lifecycle: they are created, used for computation and finally,
    they are removed. All data must be uploaded to Infinity beforehand. Data can be
    uploaded to and retrieved from Infinity via WebHDFS [23] or Cosmos CLI (a command
    line interface to WebHDFS). The Big Data GE specifies the use of SQL-like analytics
    tools like Hive, Impala or Shark. Although the GE is based on Hadoop, it proposes
    several alternatives: (i) Cassandra File System can be used instead of HDFS; (ii)
    a distributed NoSQL database like HBase can be installed on top of HDFS; (iii)
    use e.g., Cascading [24] as an extension or replacement. Docker [25] is an open
    platform to build, ship and run container-based applications. Docker provides
    process separation at kernel level to run applications in isolated containers.
    This separation is allows to run many isolated containers on one physical or virtual
    host. These containers are lightweight because they only contain the application
    and the necessary libraries and they do not need the overhead of a hypervisor
    because they run exactly on the host''s kernel. Terraform [26] is an open source
    tool for building, managing and versioning virtual infrastructures on public or
    private cloud environment. Terraform provides to define a whole virtual infrastructure
    at a high level configuration file. These configurations can contain low-level
    information like machine types, storage or network configuration and high-level
    components like SaaS services or dns entries. Based on the configuration Terraform
    creates an execution plan and a resource graph to build the defined infrastructure.
    SECTION III. Proposed Architecture The goal of the framework is to reliably receive
    and store incoming sensor data (including images) from multiple array of configured
    sensors with the capability to scale as the number of sensors (and the incoming
    data) grows. This is augmented by different user facing and administrative applications
    and external analytical tools. A. Variant 1: Infrastructure (VM) Level Architecture
    Sensor data is usually generated by small microcontroller-based devices where
    usually raw data is from arbitrary number of different instruments. Measurements
    are taken periodically and thus, it generates a large number of small packets
    that usually consist of instrument, sensor ID, node ID, timestamp, and actually
    measured data. Storing large volume of this kind of data requires a tailored infrastructure
    with the capability to scale out (horizontally) as the volume of data grows. The
    architecture follows a three-tier layout as depicted in Fig 1. Each component
    of each tier is typically deployed on a separate node. This allows easy scaling
    of appropriate tiers for example when the volume of incoming sensor data increases
    or decreases. The Availability Tier (shown in Fig. 1) accepts incoming sensor
    (including image) data and forwards it to one of the data collector application
    instances in the Application Tier. The forwarding decision is made in two steps.
    First, based on a round-robin algorithm a high-availability proxy and load-balancer
    (based on HAProxy [27]) is selected. The proxy in turn will select an application
    server with the lowest load and forward the request to that one. A Data Collector
    instance in the Application Tier (shown in Fig. 1) will decode the received data
    and store them in the Database Tier (shown in Fig. 1). Besides the Data Collector,
    other functionalities (see section IV for more details) are also available and
    work in similar fashion. The Database Tier typically consists of a Cassandra or
    Mon-goDB [28] database cluster, besides a RDBMS like MySQL. Cassandra is a decentralized
    structured storage system that is well suited for storing time-series data like
    sensor data. As the volume of incoming data changes Cassandra allows dynamically
    adding or removing new nodes to the database cluster to either scale up or down.
    Metadata submission is initiated by resolving the DNS endpoint. The DNS endpoint
    may contain one or more load-balancer addresses, they distribute the load between
    the available Receiver instances in turn. Using round-robin DNS techniques, it
    is possible to scale the number of load-balancer nodes. Round-robin DNS is a well-known
    simple method for load sharing, fault tolerance and load distribution for making
    multiple redundant service hosts available. In the simplest implementation round-robin
    DNS returns a list of IP addresses. For each such request the returned list is
    permuted and the client will connect to the first address in the list. If the
    connection fails the second address should be tried and so on. This may result
    in longer service handling times, but ensures that the requests are served by
    one of the working servers. Sequential requests can and usually will be served
    by different servers thus, if the application in the Application Tier is not stateless
    (e.g., has user sessions) then either all requests belonging to the same session
    must be handled by the same server (not possible when round-robin DNS is used)
    or the Application Tier must be prepared to share session data between all application
    servers. The receiver is stateless so no such measures are required and round-robin
    DNS is well suited. HAProxy servers are responsible for balancing the load across
    multiple application servers (e.g., Data Collectors) after through the round-robin
    DNS the client contacts one. HAProxy is a lightweight high-performance TCP/HTTP
    load balancer. It monitors continuously the health and performance of the application
    servers connected to it, and proxies the submission request to the least loaded
    one. The Application Server Tier is depicted in Fig. 2 and presented via the Data
    Collector application. It consists of the following: Chef is used as a deployment
    orchestrator for bootstrapping new nodes for the different tiers. The Data Processing
    component and Cassandra Connector are implemented using the Flask Web Framework
    and Python. The Sensor Metadata Decoder is responsible for interpreting the incoming
    data and passing it to the Cassandra Connector. The Cassandra Connector is used
    to store the decoded metadata in the database cluster. uWSGI [29] is used as a
    WSGI [30] application server, and finally NGINX [31] is connected to the wire-protocol
    of uWSGI to achieve a high performance WSGI-based web frontend. Other applications
    have (e.g., Backoffice) similar architecture. Fig. 1: General architecture of
    the framework Show All Fig. 2: Architecture of a web-based data collector application
    for sensor image data in agrodat.hu Show All There are two methods available for
    communication between sensors and the framework: periodic and event driven upload.
    These two methods can be combined: it is possible to set some parameters to be
    collected periodically while other parameters are sent in an event driven fashion.
    It is sensible to use periodic mode for telemetry type parameters and to use event
    driven mode for special features such as reporting extreme events or conditions.
    There are two archetypes available for Applications. First, is web applications
    available via HTTP(S) protocol. Second is the TCP applications and communication
    via TCP protocol. The latter is typically utilized by Data Collectors. An example
    web application is depicted in Fig. 2 (see more details in section IV). B. Variant
    2: Container-Based Architecture The original data collector framework is based
    on virtual machines and the components are run on separate nodes. This architecture
    is ideal to scale out or scale in the components based on the application utilization.
    On the other hand, this separation might have negative effect on the resource
    utilization. To achieve better resource utilization we have created the Docker
    version of the data collector infrastructure with smaller granularity. With the
    Docker container technology [25] the components of the architecture can be separated
    into containers therefore we can run more than one collector component on one
    particular virtual machine. The Docker version of the collector provides more
    efficient resource utilization than virtual machine based solution. To create
    the Docker-based version we built container images from the given software components
    of Variant 1, starting with the data collector. Since it is an OS-independent,
    Python application, an Ubuntu image was served as a baseline for this Docker image.
    We extended the application with a new configuration file which can be customized
    through the environment variables on the container start. This configuration is
    performed by the docker entrypoint script at the start (this is the main configuration
    method in the Docker ecosystem). For the Cassandra Docker version, the official
    Cassandra image was selected from the Docker Hub but we applied some modifications;
    the official entrypoint script was extended to support the automatic Cassandra
    cluster creation on the start time on a Docker Swarm cluster. With these images
    we created a Docker compose file to provide a simply container orchestration method.
    With the compose file the main part of the collector infrastructure can be deployed
    by the service operator on one machine or on a Swarm cluster as a Docker stack,
    and the containers can be easily configured through the compose file with various
    environment variables. We used the Docker Swarm technology to create a virtual
    machine based infrastructure to the Docker containers that enables the management
    of the whole cluster from the Swarm manager. The service operator can deploy the
    data collector framework as Docker stack from the described Docker compose file.
    This docker stack consists of Docker services which is started from compose file,
    and such Docker services include Docker tasks as the atomic units of the services.
    The task can invoke exactly one container. Inside one service the number of the
    tasks can be described during start time and they can be scaled up or down during
    the service lifetime. In this way, the service operator can scale the components
    of the data collector manually within these Docker services. Another important
    feature of Docker Swarm is the provided overlay network between the Swarm nodes
    for the containers. In this network the containers can access each other like
    they are on one virtual machine. Furthermore, Swarm provides an ingress routing
    mesh on this network. With the routing mesh the Swarm services can expose their
    ports on the virtual machines, so they can be reached on every Swarm node from
    outside of the cluster. With that feature, Swarm can provide an external load
    balancer between the application containers within a Docker service. Therefore,
    we decided to replace the HAproxy (from Variant 1) in the data collector infrastructure
    of Variant 2 with the above described routing mesh facility of Swarm. This Docker
    Swarm-based architecture is demonstrated in Fig. 3. The whole infrastructure is
    built and managed by the Occopus [32], [33] cloud orchestrating tool (developed
    by the Institute for Computer Science and Control, Hungarian Academy of Sciences).
    It is an open source software providing features to orchestrate, configure, and
    manage virtual infrastructures based on single or multi-cloud environments. Occopus
    operates leveraging on descriptors which describe a whole virtual infrastructure
    in a cloud-agnostic way. Therefore, we created the necessary descriptor files
    to build and maintain the data collector framework, and the Swarm worker nodes
    can be automatically scaled by Occopus-depending on the CPU usage of the nodes.
    C. Variant 3: Extended Architecture In the next iteration of the data collector
    we improved the data storing layer and separated the functions of the data collector
    layer to improve the disadvantages of the framework. In the first version, all
    metadata about the sensors and the measured data are stored in the Cassandra database.
    This is not an optimal database schema to store related data in a NoSQL database,
    therefore, we separated the stored data into two database. The information and
    the corresponding metadata of the sensors are stored in an SQL database, and the
    measured data will stay in the NoSQL database. To reach this state we had to add
    a SQL connector to the receiver and a SQL database to the framework. Fig. 3: Container-based
    architecture Show All Fig. 4: Extended collector used in architecture variant
    3 Show All In the first version, the data collector has three separated task:
    collect, transform, and store the data in the database. In this variant these
    functions have been separated into new components, than we completed the framework
    with a data streaming module. This streaming component receives the raw data from
    the sensor and provide it to the collector to process it and store into the database.
    With this component we could avoid to overload the data collector and the spikes
    can be managed in the input data stream. The extended collector architecture is
    demonstrated in Fig. 4. SECTION IV. Agrodat.hu: Precision Agriculture In this
    section we detail the application of our platform through the AgroDat.hu project.
    The ultimate aim of AgroDat.hu project [2] is to create a knowledge centre for
    precision agriculture based on the local sensor data and also integrating semi-or
    unstructured data from international repositories. Concerning the sensors, more
    than 1000 newly developed complex sensor pillars have been deployment at various
    selected locations covering more than 8000 hectares of 58 farmers in Hungary.
    The sensor pillars have modular structure [34] with facilities to measure environmental
    factors (weather, soil moisture, etc.), phenotypes (sensor image data) and other
    parameters continuously at least for 3 years, see Fig. 5 for the administrative
    interface. The IoT communication network is based on 4G GSM network and M2M communication
    enabled SIM cards. For processing and storing data and also for providing services
    for researchers, farmers, decision makers, etc. a new big data center is in operation
    with hierarchical storage with noSQL database, GPGPU cluster for processing the
    raw data (images), Hadoop servers [35], etc. OpenStack [36] cloud is responsible
    for providing an elastic and flexible framework for the higher level software
    services; (among others) IoT back-end for data collection, processing and decision
    support systems. The aggregation of related scientific and other semi-or non-structured
    data from international repositories relies on the integrated workflow-oriented
    services [37] of the agINFRA project [38]. The back-end architecture of AgroDat.hu
    contains two main functionalities: (i) data collectors for processing incoming
    sensor and sensor image data; and (ii) a backoffice system for additional functionalities
    and administrative functions. The obtained raw data is then made available for
    processing and analytics in the big data center. First, the data collectors are
    responsible for gathering and storing sensor messages in the cloud for further
    processing. They perform a basic extract, transform, load (ETL) functionality
    by pre-processing the data and storing it in a structured format for the other
    cloud-based functions. Additionally, it is also stored directly in the input format
    to have backup for security reasons and to be available for future implemented
    functions and statistics. The Backoffice provides administrative interface for
    plots and sensors (see Fig. 5). There, sensor pillar configurations can be created,
    and sensor types assigned to different heights on the pillars. Pillars can be
    configured as below or above surface. Based on the pillar configurations, pillar
    instances can be created and sensor instances can be assigned to the configured
    heights on them. Finally, plots can be registered and sensor pillar instances
    can be deployed to different GPS locations within the plots. Once the instances
    are deployed, the collector framework will allow incoming data through the appropriate
    collector type (e.g., TCP or HTTP, raw values or image data, etc.). The collected
    data can be visualised within the Backoffice and is also available for further
    processing by analytical tools. Moreover, the Backoffice also provides sensor
    (pillar) health checks, monitoring and alerting functionalities. SECTION V. Evaluation
    For evaluation, we deployed Variant 1 of our framework (see Section III) on an
    Infrastructure-as-a-Service (IaaS) cloud analogous to the Agrodat.hu infrastructure
    with the following configuration: (i) a Cassandra cluster with up to 5 nodes,
    each with 4 vCPUs, 4GB RAM and iSCSI storage from a storage area network (SAN)
    (ii) single HAProxy node with 4 vCPUs and 2GB RAM; (iii) up to 5 Data Collector
    nodes with 4 VCPUs and 2GB RAM each. We used the following additional components:
    (i) a node as Chef server; (ii) a local Amazon S3 compatible service (via Ceph
    RadosGW); and (iii) a MySQL instance. All nodes ran as virtual machines on AMD
    Opteron 6376 CPUs with all VCPUs mapped to actual physical cores, and connected
    via 10Gbit/s network. For evaluation purposes and benchmarking, we performed load
    testing with two scenarios: (i) Cassandra database cluster; and (ii) the whole
    data collector framework via the camera sensor image data collector. For the first
    case, we used the stress-testing tool (cassandra-stress [39]) provided by Cassandra.
    Cassandra-stress uses a warmup phase to load data in to the cluster before the
    actual measurement. In the second case load tests were carried out with the Tsung
    load-testing framework [40] using the Zabbix [41] monitoring tool for observing
    the infrastructure during tests. The load testing framework includes 8 additional
    Tsung nodes with 4VCPUs and 2GB RAM each. Tsung nodes were also deployed in the
    same IaaS cloud, thus, any measurement that involves network speed was always
    using the internal 10Gbit/s network. A. Database First we used the Cassandra stress
    tool to determine the theoretical limit of number of inserts (row/s) for the database
    cluster using given payload size. The ‘SimpleStrategy’ was configured for replica
    placement with replication factor of 1. The payload was set to 90KBytes data per
    query, representing an image from a sensor image data collector. The Cassandra
    stress tool increases the number of threads writing to the database as long as
    there are no large drops in write speed. This is denoted by “thread count”. Table
    II shows our results. In this table total ops represent the rows written in this
    case, while row/s is the actual insert speed. Mean, median, 0.95 and max are latency
    related (we omitted 0.99 and 0.999 percentiles, time and stderr from the table).
    The tests were run always against an empty database, however the stress tool performs
    a warm up phase for the cluster before the actual stress testing by default. We
    also randomized the partition key to avoid hot spots. Our results show that the
    deployed system was able to sustain a median write speed of 2492.0 rows/s with
    x ¯ =2320.7, σ 2 =431.80 for thread count> 8 using the conditions detailed above.
    B. Data Collector Framework A 8-node Tsung cluster was set up for distributed
    load testing. Our goal was twofold: i.) to see which defined scenarios the framework/architecture
    is able to complete; and ii.) how the performance compares to the performance
    measured in the raw Cassandra load testing. Table I: Evaluation results for the
    image sensor data collector framework Table II: Results for load testing the cassandra
    cluster via cassandra-stress We defined 12 test cases as a matrix for inter-arrival
    times (0.1s, 0.05s and 0.01s) and images sizes (16KByte, 64KByte, 128KByte, 256KByte)
    representing an increasing load both in frequency and payload size. At the beginning
    5-minute tests were executed via Tsung and monitored via the HAProxy administrative
    interface to see if any requests were denied and how many requests were queued
    up on the application servers. If the application servers were able to handle
    the load, we repeated the test with 60-minute long tests. The 60-minute tests
    were repeated 5 times. For the tests a 5-node Cassandra cluster was used, up to
    5 Data Collectors and a single HAProxy. Table I details our results. The sample
    deployment is able to handle up to 256KByte of payload with 0.05s inter-arrival
    time, or up to 128KByte of payload with 0.05s inter-arrival time. As the inter-arrival
    time decreases the deployment starts to fail with timeout. We confirmed this using
    the administrative interface of HAProxy. The results can be seen as much lower
    compared to the native speed of the database layer (see section V-A), however
    the sensor data collector does some transformation of the payload, it converts
    and normalizes the received image which is CPU bound. First, this problem is mitigated
    in the architecture Variant 3 (see section III-C) by splitting the data collector
    framework explicitly into a data receiver, a streaming and a processor component.
    Concerning Variant 2, this can be mitigated by introducing additional Data Collector
    instances. SECTION VI. Conclusion and Future Work In this paper we presented different
    variants (based on orchestrated VMs and containers) and also the major implementation
    steps of a scalable IoT back-end architecture that can be adapted with low-entry
    barriers to other use case scenarios as well. The adaptation of this IoT architecture
    is already in progress in two sectors, namely Connected Cars and Industry 4.0,
    with some positive preliminary results based on the following sectoral demands.
    A. Connected Cars Connected car technologies have been rapidly advancing with
    several new digital solutions and autonomous driving features. Connected cars
    collect and make interpretable massive amounts of data-mostly from digital sensors
    of IoT systems by exchanging useful data (e.g. alerts) between other vehicles,
    stoplights, and back-end services [6] [5]. Even though automobiles today are equipped
    significant amount of processing and storage capacities, the rapidly growing amount
    of raw data and the higher and higher level functionalities require robust and
    scalable back-end technologies that can handle the underlying sophisticated processing
    and analytical functions. Relying on the presented IoT back-end architecture our
    current research focuses on CAN data collection, remote device flashing, Eco-driving,
    weather report and forecast with some promising initial achievements. B. Industry
    4.0 One of the main driving forces in the era of Industry 4.0 [7] is the introduction
    of massive sensor networks and state-of-the-art IoT solutions into manufacturing
    processes, services of logistics, etc. Large amount of sensor data has to be ingested
    by the IoT back-end in order to generate and make usable the so-called ‘twin digital
    model’ or Virtual Factory of the existing physical production processes for (among
    others) simulation and scheduling purposes [42]. We recently started the related
    research and development activities in the ‘Cloudification of Production Engineering
    for Predictive Digital Manufacturing’ (CloudiFacturing) consortium [43] in order
    to adapt the presented IoT back-end architecture by the help of digital innovation
    hubs across Europe. Fig. 5: Agrodat backoffice: Plot and sensor pillar administration;
    and example temperature sensor data graph for sensor “t1” Show All ACKNOWLEDGMENT
    This work was partially funded by the European “COLA-Cloud Orchestration at the
    Level of Application” project, Grant Agreement No. 731574 (H2020-ICT-2016-1),
    by the National Research, Development and Innovation Fund of Hungary under grant
    No. VKSZ_12-1-2013-0024 (Agrodat.hu), and by the International Science & Technology
    Cooperation Program of China under grant No. 2015DFE12860. On behalf of the Project
    Occopus we thank for the usage of MTA Cloud [44] that significantly helped us
    achieving the results published in this paper. Authors Figures References Citations
    Keywords Metrics More Like This Structuring cloud computing using big data analytics
    solution: A survey 2016 International Conference on Communication and Electronics
    Systems (ICCES) Published: 2016 Integration of Cloud Computing, IoT, and Big Data
    for the Development of a Novel Smart Agriculture Model 2023 3rd International
    Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE)
    Published: 2023 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase
    Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS
    PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA:
    +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE
    Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved.'
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: null
  publication_year: 2018
  relevance_score1: 0
  relevance_score2: 0
  title: An Adaptive Cloud-Based IoT Back-end Architecture and Its Applications
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.23919/date51398.2021.9474167
  analysis: '>'
  authors:
  - Stefano Aldegheri
  - Nicola Bombieri
  - Samuele Germiniani
  - Federico Moschin
  - Graziano Pravadelli
  citation_count: 5
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy IEEE.org IEEE Xplore IEEE
    SA IEEE Spectrum More Sites Donate Cart Create Account Personal Sign In Browse
    My Settings Help Access provided by: University of Nebraska - Lincoln Sign Out
    All Books Conferences Courses Journals & Magazines Standards Authors Citations
    ADVANCED SEARCH Conferences >2021 Design, Automation & Tes... A containerized
    ROS-compliant verification environment for robotic systems Publisher: IEEE Cite
    This PDF Stefano Aldegheri; Nicola Bombieri; Samuele Germiniani; Federico Moschin;
    Graziano Pravadelli All Authors 4 Cites in Papers 213 Full Text Views Abstract
    Document Sections I. Introduction II. Problem Statement III. Verification Architecture
    IV. Monitor Synthesis V. Monitor Orchestration Show Full Outline Authors Figures
    References Citations Keywords Metrics Abstract: This paper proposes an architecture
    and a related automatic flow to generate, orchestrate and deploy a ROS-compliant
    verification environment for robotic systems. The architecture enables assertion-based
    verification by exploiting monitors automatically synthesized from LTL assertions.
    The monitors are encapsulated in plug-and-play ROS nodes that do not require any
    modification to the system under verification (SUV). To guarantee both verification
    accuracy and real-time constraints of the system in a resource-constrained environment
    even after the monitor integration, we define a novel approach to move the monitor
    evaluation across the different layers of an edge-to-cloud computing platform.
    The verification environment is containerized for both cloud and edge computing
    using Docker to enable system portability and to handle, at run-time, the resources
    allocated for verification. The effectiveness and efficiency of the proposed architecture
    have been evaluated on a complex distributed system implementing a mobile robot
    path planner based on 3D simultaneous localization and mapping. Published in:
    2021 Design, Automation & Test in Europe Conference & Exhibition (DATE) Date of
    Conference: 01-05 February 2021 Date Added to IEEE Xplore: 16 July 2021 ISBN Information:
    ISSN Information: DOI: 10.23919/DATE51398.2021.9474167 Publisher: IEEE Conference
    Location: Grenoble, France SECTION I. Introduction One of the main impediments
    of efficiently developing large-scale and reliable robotic infrastructures with
    high-level autonomy is the lack of support for runtime system verification [1].
    What is missing is a modular approach to verify, during the whole HW/SW design
    flow, the complex and heterogeneous software applications implementing the robot
    behaviors and tasks. A reliable design practice requires the use of monitors,
    which are chunks of code that can check key properties of the system behavior
    in real-time, report violations, and possibly enforce fail-safe behaviors. Basic
    monitors to check resources and detect local faults for robotic applications are
    at the state-of-the art [2]. On the other hand, with an increased level of perception,
    interaction and control, current autonomous robotic systems need more advanced
    monitors to check their tasks. These include monitors for security and real-time
    safety constraints in addition to pattern matching over sensor readings to help
    perception. Various works have been proposed to generate these complex monitors
    automatically from their high-level specifications and integrate them into Robot
    Operating System (ROS)-based designs, for both single robots [3], [4] and robot
    swarms [5]. All these solutions are effective in generating verification environments
    where monitors are added to the System Under Verification (SUV) by assuming no
    limit concerning the computational resources available for its real-time execution.
    However, verification procedures introduce an overhead that, with the same amount
    of resources, could negatively impact the execution of the SUV tasks; i.e., SUV
    tasks can miss their real-time deadline since, now, part of the computational
    resources must be dedicated to verification. As a consequence, assertions monitoring
    real-time constraints can fail as well. To address this problem, this paper proposes
    an assertion-based verification (ABV) architecture and a related automatic flow
    to generate, orchestrate and deploy monitors into a dynamic verification environment.
    The rest of the paper is organized as follows. Section II details the problem
    statement. Section III describes the proposed verification architecture. Section
    IV is devoted to the monitor synthesis. Section V presents the orchestration approach.
    Section VI describes the experimental results. Finally, Section VII concludes
    the paper with final remarks. SECTION II. Problem Statement We assume that the
    SUV is a real-time system composed of several software tasks running inside ROS-based
    nodes. ROS is the de facto standard middleware for developing robotic software
    applications. It implements messages passing among the system nodes by providing
    a publish-subscribe communication model. Every message sent by any node has a
    topic, which is a unique string known to all the communicating nodes. A node can
    create a topic to publish messages that will be received by all subscribed nodes.
    The nodes execute on computational platforms distributed among different layers.
    The goal is to add a monitor-based architecture for semi-formal runtime verification
    of the SUV. The problem is how and where integrating monitors in the ROS-based
    system to achieve accurate verification without violating the real-time constraints
    of the SUV. More in detail, depending on how close each machine is to the source
    of the data, each ROS node is logically placed at a certain computational layer.
    The bottom layer is called “the edge”. Here we can find computing platforms such
    as microcontrollers and off-the-shelf devices. These devices guarantee low latency
    for monitor verification because data is elaborated on the spot. However, they
    provide low computation resources. Adding run-time verification at the edge may
    lead to violations of real-time constraints; indeed, the execution of monitors
    steals computational resources from software tasks, often preventing them from
    meeting their deadlines. The upper layer is called “the Cloud”. Here we have high-performance
    computing platforms, such as computer clusters and servers. Although the cost
    of monitor execution is negligible when carried out on these machines, the verification
    latency could become unpredictable and sometimes exceptionally high. This is due
    to the delay induced by moving data through the network from lower layers (where
    data is generated) to the cloud (where verification occurs), and vice-versa. As
    a result, notifications of failures may arrive too late. Fig. 1: Verification
    architecture. Show All SECTION III. Verification Architecture To solve the issues
    described in the previous section, we propose the verification architecture depicted
    in Fig. 1. Our approach enables assertion-based verification of real-time robotic
    systems, by orchestrating the execution of runtime monitors among different layers,
    from the edge to the cloud. The verification workload is shared among the layers
    by considering constraints of latency, accuracy, and available computational resources.
    Monitors are automatically synthesized from linear temporal logic (LTL) assertions,
    usually following the template “always (antecedent → consequent)”. Furthermore,
    they exploit the ROS publisher-subscriber paradigm to capture the events required
    by their evaluation function. Each event represents the value generated by the
    SUV for a variable at a specific time instant. For each variable used inside an
    assertion, a subscriber to the corresponding topic is created to receive the events
    in the synthesized monitor. Monitor verification is enabled in a plug-and-play
    fashion that does not require any modification of the SUV. Monitors execution
    is under the control of dedicated monitor handlers, one per each computing device
    in the system. Each handler is a ROS-compliant node containing both the orchestrator
    and the entire set of monitors. The verification environment is finally containerized
    into a Docker image to simplify the deployment of monitors across different hardware
    architectures and operating systems, and to handle the resources allocated for
    verification. We implemented a runtime system that dynamically migrates the execution
    of one or more monitors across the computing devices. It is worth noting that
    each machine contains a copy of the whole verification environment, yet only one
    instance of each monitor is executing in the system at any time. We report the
    details concerning monitor synthesis, containerization and orchestration in the
    next sections. SECTION IV. Monitor Synthesis This section describes how ROS-compliant
    monitors are automatically synthesized from LTL assertions. The input is a LTL
    assertion formalized by using the Property Specification Language (PSL). The output
    is a monitor composed of a C++ evaluation function to check the assertion dynamically,
    and a ROS-compliant infrastructure to capture the events to perform the evaluation.
    To better understand the process, let us refer to the running example of Fig.
    2. In the first step of the process, each proposition is substituted with a boolean
    variable acting as a placeholder. This is done because boolean values can be easily
    represented in a compressed format by using only one bit for each value. It becomes
    exceptionally convenient when implementing the monitor orchestration described
    in section V. In Fig. 2, the assertion G(running→speed<100 U stop) is substituted
    by G( p 0 → p 1  U  p 2 ) , where p 0 is the placeholder for running, p 1 for
    speed < 100 and p 1 for stop. Once the above substitution is completed, we generate
    a corresponding Büchi automaton. In Fig. 2, the generated automaton contains the
    states 0, 1 and 2. Finally, the automaton is visited to generate the monitor,
    which is mainly composed of a C++ evaluation function that checks the assertion
    at each simulation instant. In the last step of the synthesis process, we create
    the ROS-compliant infrastructure to capture and handle the input for the evaluation
    function of the monitor. For each variable included in the evaluation function,
    we generate a callback to capture the related events from the corresponding topic.
    A callback function is attached to an independent thread executing each time a
    message is processed from the subscriber queue. An event is a couple (new_value,
    timestamp) where new_value is the next value assumed by the variable and timestamp
    is the instant at which the event was generated in the SUV. Each time a callback
    is called, the captured event is added to a buffer, i.e., it is not immediately
    processed by the evaluation function. As described later in Section V, the buffer
    allows the orchestrator to move the evaluation of the monitor across the edge-to-cloud
    layers, independently from the location of the machine where the events were observed.
    In addition, the buffer allows us to sort the events according to the order defined
    by their timestamps, thus minimizing evaluation errors due to synchronization
    issues and/or communication delays. The buffer is sorted each time its size reaches
    a certain threshold. A higher threshold ensures a better verification accuracy,
    as the events are more likely to be evaluated in the correct order. Once the buffer
    is sorted, the events are used to generate the values for the boolean placeholders.
    These values are stored in a compressed format in a new buffer. The compression
    process drops the timestamps (as the events are already ordered) and converts
    the boolean value to a single bit (1 for true, 0 for false). Each time the evaluation
    function is called, an event is consumed from the compressed buffer and used to
    advance the verification. Fig. 2: Monitor synthesis and event subscription. Show
    All In Fig. 2, the ROS node is subscribed to three topics: running, speed, and
    stop. These topics correspond to the variables used in the assertion. In the example,
    three events are captured and added to the event buffer by the callback functions:
    〈17.3,10022〉 for the numeric variable speed, and 〈false,10021〉 (true, 10023) for
    the boolean variables stop and running, respectively. Assuming that the sorting-threshold
    is set to 3, as soon as the third event arrives, the content of the event buffer
    is sorted according to the timestamps and moved to the sorted buffer. Then, each
    event is compressed and added to the compressed boolean buffer. Event (17.3, 10022)
    is compressed to 1, as the corresponding proposition p 1: speed < 100 is true
    for speed equal to 17.3, while 〈false,10021〉 and 〈true,10023〉 are directly translated
    to 0 and 1, respectively. Once the monitors are synthesized, they are containerized
    to enable portability of the verification environment across different HW /SW
    architectures. We extended the containerization procedure based on Docker for
    edge computing. State-of-the-art solutions to containerized cloud-native applications
    associate each container to a private (isolated) subnet IP [6]. As a consequence,
    since ROS nodes cannot communicate if mapped to different subnet IPs, existing
    solutions allow communication of containerized ROS nodes only if all nodes are
    mapped to the same subnet IP. To solve this issue, which severely limits the applicability
    of such a container-based solution, the proposed architecture automatically maps
    the IP address of each container to the IP address of the host device (i. . e,
    the device architecture in which the ROS node executes), while the port numbers
    are assigned randomly. The proposed solution is modular, as it supports the easy
    generation and integration of containers for different HW /SW target architectures,
    from Cloud data centers to edge servers, off-the-shelf edge devices (e.g., NVIDIA
    Jetson), and embedded edge devices (e.g., robot native boards). SECTION V. Monitor
    Orchestration The purpose of the orchestration is to adjust, at run-time, the
    trade-off between verification responsiveness and resource consumption during
    the SUV execution. Our orchestrating system consists in moving the monitor execution
    from a machine to another, possibly belonging to a higher computational layer,
    in the edge-to-cloud computing paradigm. This way we ensure that the receiving
    machine can provide the additional resources needed to handle the new monitor,
    at the expense of a reduction in responsiveness, as the evaluation of the monitor
    is located farther from the generation of the observed events. Fig. 3: Example
    of buffer migration. Show All Since each machine has a copy of all monitors, moving
    a monitor aifrom machine m 1 to machine m2 can be achieved by (i) turning off
    a 1 on m 1, (ii) sending the state and event buffer of a 1 to m2 and (iii) activating
    a 1 on m2. This procedure requires moving data through the network. However, the
    proposed migration approach is extremely efficient, as the data to be transferred
    are compressed, making the procedure exceptionally lightweight even for slow connections.
    Moreover, transferring the monitor''s state is exceptionally efficient as well
    because it consists in just an integer value identifying the current state of
    the automaton implemented in the evaluation function. We describe in detail the
    migration protocol between two machines hereafter. To simplify the exposition,
    let us consider the example shown in Fig. 3. The figure shows the movement of
    monitor 1 between hondler1 executing at level liof the edge-to-cloud hierarchy
    and handler2 executing at level li+1. Before the migration is initiated, hondler1
    is executing monitors 1 and 4, while hondler2 is executing monitors 2 and 5. Let
    us consider that, at a certain point, monitor1 detects its event buffer is becoming
    full, as the machine cannot provide enough resources to consume the events. As
    a consequence, it asks handle r 1 to be migrated (step 1). handle r 1 removes
    monitor1 from the scheduler (step 2 a ), but it does not stop the process of adding
    events to its buffer. At the same time, it notifies the beginning of the migration
    to handle r 2 (step 2 b ) ). handle r 2 attaches the correct callbacks to start
    adding events to the buffer of monito r 2 (step 3). However, monito r 2 is not
    yet put on the scheduler. Once monito r 2 receives enough events to perform the
    first sorting, handle r 2 returns the timestamp of the oldest event in monito
    r 1 to handle r 1 (step 4). This way, once monitor1 receives the timestamp, it
    understands what events of the buffer must be sent, that is, all evaluated events
    with timestamp lower than the received timestamp. When this happens, handle r
    1 detaches the callbacks from monito r 1 to stop the process of adding events
    to its buffer (step 5 a ) and sends the correct events to handle r 2 together
    with the state of monito r 1 (step 5 b ). Now, monito r 1 is inactive on handle
    r 1 and handle r 2 finishes the migration by filling the buffer of monitor1 with
    the received events and by putting it on the scheduler to start its evaluation
    (step 6). SECTION VI. Experimental Results A. Case Study We applied the proposed
    methodology to a software application for an autonomous navigation mobile robot
    (Robotnik Kairos). The software implements an ORB-SLAM [7] application for localization
    and mapping through RGB cameras combined to an inference-based image recognition
    system [8] that controls a move base system based on a global and a local planner
    with obstacle avoidance. Our goal was to verify the functional correctness of
    the application by considering the real-time constraints of the software system.
    In particular, we mapped the global planner to the cloud as a non-critical task.
    We considered the ORB-SLAM and local planner executing in real time at the edge
    on an NVIDIA Jetson TX2 and by setting a constraint of 8 FPS as the minimum supported
    rate for the RGB camera-input stream (i.e., 125 ms application makespan). Communication
    and synchronization between cloud and edge devices rely on the ROS software stack
    through Ethernet. B. Results In this subsection, we show that the proposed verification
    architecture can make the system endure computational loads that would be unfeasible
    with traditional assertion-based verification approaches. To accomplish that,
    we describe the results of simulating the case study with an increasing number
    of monitors, showing the improvements in applying our orchestration approach.
    We considered the scenario where the robot has to reach a statically planned location
    ⟨ x 2 , y 2 ⟩ from a starting point ⟨ x 1 , y 1 ⟩ . At first, the global planner
    finds a path to reach the arrival point. After that, during the movement of the
    robot, the local planner reschedules the path trajectory (waypoints) according
    to the changes in the environment to avoid unwanted collisions with moving obstacles.
    We considered the 200 monitors initially allocated by the static orchestration
    to be executed on the Jetson TX2. During execution, we noticed that the monitor
    corresponding to the assertion always((robo t − x 1 = x 1  && robo t − y 1 = y
    1  && newGoal) → (currentTime <timeout U robo t − x 2 fails. The purpose of this
    monitor is to check if that robot arrives at ⟨ x 2 , y 2 ⟩ before a certain timeout.
    The monitor failed because the overhead introduced by the verification environment
    caused an increase in the execution time. As a consequence, the controller of
    the robot could not support the minimum updating frequency of the motor velocities,
    making the robot move on the wrong trajectory. In particular, the controller needs
    at least an update of the motor velocities every 125 ms (8 Hz) to execute correctly.
    Without the verification environment, the system guarantees a makespan of 115
    ms (8.7Hz). Such a value is increased to 140 ms (7.1 Hz) when including the verification
    overhead. By applying the buffer migration approach, the evaluation of 150 monitors
    was automatically moved from the Jetson to the Cloud during execution, freeing
    the edge device from some of the verification overhead. Because of this, the controller
    of the robot started working properly once again with a makespan of 125 ms (8
    Hz), preventing the above assertion from failing. This result shows that the approach
    is effective in freeing computational resources by moving the evaluation of monitors
    from congested computational devices. SECTION VII. Conclusions This paper proposed
    an architecture and a related automatic flow to generate, orchestrate and deploy
    a ROS-compliant verification environment for robotic systems. We provided several
    contributions regarding the synthesis, containerization and orchestrations of
    monitors. Execution of the architecture on a complex case study showed promising
    results toward a new comprehensive solution to apply assertion-based verification
    on real-time robotic systems. Authors Figures References Citations Keywords Metrics
    More Like This Simultaneous Localization and Mapping with Application to Monitoring
    of Underground Transportation Infrastructure 2019 International Symposium on Advanced
    Electrical and Communication Technologies (ISAECT) Published: 2019 Simultaneous
    localization and mapping for mobile robot based on an improved particle filter
    algorithm 2009 International Conference on Mechatronics and Automation Published:
    2009 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details
    PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES
    PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678
    4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact
    Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics
    Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE
    is the world''s largest technical professional organization dedicated to advancing
    technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: null
  publication_year: 2021
  relevance_score1: 0
  relevance_score2: 0
  title: A containerized ROS-compliant verification environment for robotic systems
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1016/j.jpdc.2019.08.002
  analysis: '>'
  authors:
  - Ivan Merelli
  - F. Fornari
  - Fabio Tordini
  - Daniele D’Agostino
  - Marco Aldinucci
  - Daniele Cesini
  citation_count: 4
  full_citation: '>'
  full_text: '>

    Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords 1. Introduction 2. Related works 3. Bioinformatic
    background 4. Computational background 5. Experiment description 6. Results and
    discussion 7. Conclusions and future directions Declaration of Competing Interest
    Acknowledgements References Vitae Show full outline Cited by (5) Figures (6) Tables
    (4) Table 1 Table 2 Table 3 Table 4 Journal of Parallel and Distributed Computing
    Volume 134, December 2019, Pages 116-127 Exploiting Docker containers over Grid
    computing for a comprehensive study of chromatin conformation in different cell
    types Author links open overlay panel Ivan Merelli a, Federico Fornari d, Fabio
    Tordini b, Daniele D’Agostino c, Marco Aldinucci b, Daniele Cesini d Show more
    Add to Mendeley Share Cite https://doi.org/10.1016/j.jpdc.2019.08.002 Get rights
    and content Highlights • With more flexibility, grid can be a cloud competitor,
    since it is free. • Docker-based solutions can help in customizing the grid environment.
    • Udocker can extend the grid utility, since work without root permissions. •
    We model the spatial DNA conformation in the nucleus, using a graph-based approach.
    • Preselecting grid resource can improve the computation efficiency and scalability.
    Abstract Many bioinformatic applications require to exploit the capabilities of
    several computational resources to effectively access and process large and distributed
    datasets. In this context, Grid computing has been largely used to face unprecedented
    challenges in Computational Biology, at the cost of complex workarounds needed
    to make applications successfully running. The Grid computing paradigm, in fact,
    has always suffered from a lack of flexibility. Although this has been partially
    solved by Cloud computing, the on-demand approach is way distant from the original
    idea of volunteering computing that boosted the Grid paradigm. A solution to outpace
    the impossibility of creating custom environments for running applications in
    Grid is represented by the containerization technology. In this paper, we describe
    our experience in exploiting a Docker-based approach to run in a Grid environment
    a novel, computationally intensive, bioinformatic application, which models the
    DNA spatial conformation inside the nucleus of eukaryotic cells. Results assess
    the feasibility of this approach in terms of performance and efforts to run large
    experiments. Previous article in issue Next article in issue Keywords Grid computingDocker
    containersData modellingChromatin conformationComputational Biology 1. Introduction
    In the last decade, Grid infrastructures had an important role in supporting the
    biomedical scientific community to perform its compute-intensive analysis, finding
    innovative solutions for reducing computational times [66]. Nowadays, due to the
    exponential availability of new biological data and considering the increasing
    complexity of bioinformatic applications, Big Data-like situations and computational
    demanding problems are becoming more and more urgent in Computational Biology
    [57]. Distributed infrastructures, such as those based on the Grid and Cloud paradigms,
    represent one of the possible solutions to achieve the required amount of computational
    power in a cost-effective way [9]. Grid computing can be defined as a hardware
    and software infrastructure that provides dependable, consistent, pervasive, and
    inexpensive access to high-end computational capabilities. Many years after the
    spreading of this technology, we can say that Grid is a wrapper to freely access
    remote multi-institutional resources, e.g. with the EGI Foundation, formerly named
    the European Grid Infrastructure [21], for research activities. On the other hand,
    Cloud computing has been defined as a model for enabling convenient, on-demand
    network access to a shared pool of configurable computing resources (e.g., networks,
    servers, storage, applications, and services) that can be rapidly provisioned
    and released with minimal management effort or service provider interaction. In
    contrast with the definition of Grid, we can define Cloud computing as a way to
    deliver on-demand, scalable, pay-per-use services, which rely on virtualized computational
    facilities hosted by single institution, over Internet. Above all, Cloud infrastructures
    can be used for business, commercial and research purposes, but the idea is always
    to have on-demand resources, working on a pay-per-use basis. On the other hand,
    Grid platforms are mainly used for research by Virtual Organizations, that are
    a dynamic sets of individuals and/or institutions that share a goal to be pursued
    using the Grid resources, but for free. While the users of a Cloud infrastructure
    are customers, the users of a Grid are members of one or more virtual organizations.
    Working for public bodies, we believe that the Grid computing paradigm is still
    important for sharing resources, in particular in the context of large consortia
    oriented to specific research purposes. However, Grid-based solutions are not
    completely satisfactory to create reliable computing environments for complex
    tasks [25], [43]. A key issue is that a Grid offers poor chances to customize
    the computational environment. For example, it is quite common in Computational
    Biology to make use of relational databases and/or web-oriented tools to perform
    analyses, store output files and visualize results, which are difficult tasks
    to exploit without having administration rights on the used resources. Another
    problem concerns the huge amount of bioinformatic packages available in different
    programming languages and frameworks (such as R, Perl and Python) that typically
    require many dependencies and fine-tuned customizations of the settings. These
    are the reasons why Docker [47] represents a very appealing solution to create
    a custom environment over Grid [62]. In this paper, we describe our experience
    in exploiting a Docker-based approach for a bioinformatic application, which basically
    consists in modelling the DNA spatial organization, i.e. the chromatin conformation,
    in the nucleus of different cell types [72]. Although many experiments to study
    the chromatin conformation are daily performed in molecular biology laboratories
    all around the world [22], [29], [59], the interpretation and modelling of this
    data is still a complex and challenging task [26], [60]. In particular we exploited
    a novel experimental technique, called chromosome conformation capture (3C) [19],
    which allows to measure the proximity of DNA strands in the nucleus. Among novel
    3C-based methods, Hi-C uses Next-Generation Sequencing (NGS) techniques to interrogate
    3C experiments more comprehensively and with an increased throughput [40]. The
    “Hi” thus stands for “high-throughput”, and sometimes it is written as HT-3C.
    The data produced by a Hi-C experiments are coupled reads that describe the frequency
    by which two strands of DNA are close each other inside the nucleus. The output
    of a Hi-C analysis is a list of coupled locations along chromosomes, which can
    be represented as a contact map, i.e. a square matrix where stands for the sum
    of read pairs matching, respectively, in position and position . Contact maps
    are reliable while looking at the intensity of the interactions inside a chromosome
    or between two chromosomes, but become unsuitable to depict the neighbourhood
    of genes, as they lack the possibility to define metrics for computing distances
    between two or more genes. On the other hand, graph-based models of Hi-C data
    can be very useful for creating representations where other omics data can be
    mapped, in order to characterize different spatially associated domains [44],
    [68]. By exploiting their higher level of expressiveness, graphs permit the integration
    of multi-omic data and facilitate their statistical analysis [69], [70]. Therefore
    our goal is to exploit a Grid computing infrastructure for creating a collection
    of graph-based models relying on a set of publicly available Hi-C experiments
    performed in different laboratories worldwide, in order to produce a catalogue
    on which new results from different multi-omic experiments can be modelled, analysed
    and interpreted. To accomplish this task a huge computational power is needed,
    and Grid computing perfectly suites our requirements, if a proper execution environment
    can be created. This paper is organized as follows: Section 2 discusses Related
    Works and Section 3 provides a background on the biology-related topics of the
    application we considered. Section 4 gives an overview of the computational infrastructure
    we exploited, Section 5 describes how the computation was performed, while Section
    6 discusses the achieved results. Section 7 concludes this work. 2. Related works
    The design and effective deployment of reliable, scalable and portable complex
    computational systems is a major issue in many research and industrial fields
    [38], [53]. This is the reason why there have been significant progresses in building
    virtualization layers for operating systems and, more recently, software applications
    [20], [33]. A first approach for providing such results is represented by the
    full virtualization technology [41], in which each virtualized system gets its
    own subset of physical resources, with a minimal sharing and an high level of
    isolation with respect to other systems running on them. Examples of platforms
    supporting it are Xen [10], KVM [37] and VMware [56]. A second approach is represented
    by the use of containers [64], which provide a lower level of isolation, but the
    resulting lightweight overhead allows easily to run thousands of instances on
    a host, result that is almost impossible with the full virtualization [24], [74].
    The most popular example of the container technology is the Docker platform [47],
    which allows for the creation and configuration of software containers for deployment
    on a range of systems [7]. However, other solutions are available, such as rkt
    [61] from the Linux distributor CoreOS, LXD [64] from Canonical Ltd. - which is
    the company behind Ubuntu, or OpenVZ [75], which is an extension of the Linux
    kernel. Behind these core architectures, a number of orchestrator tools are available.
    Among the most popular solution is worth citing Kubernetes [30], a project released
    as open source by Google, or Apache Mesos [31]. Due to the large interest in the
    container technology, the most popular Cloud providers have released solutions
    for dealing with systems relying on it, which are often defined Container applications
    as a Service - CaaS [52]. An example is Amazon AWS ECS [6], a manager of Docker
    images, which can store images in the accompanying ECS Registry, run Docker containers
    (ECS Runtime) and schedule/orchestrate/monitor these container instances (AWS
    CloudWatch). Microsoft Azure Container Service (ACS) works together with Docker
    and Apache Mesos as container orchestration engine [48]. Rancher also supports
    Docker Swarm, Kubernetes and Apache Mesos [54]. Obviously there are pros and cons
    for both using the full virtualization or containers. The most important aspects
    are represented by security and performance. As said before, if a system needs
    a full isolation and a set of guaranteed resources, the full virtualization is
    the proper solution. On the contrary if it is sufficient to isolate just processes
    and the purpose is to serve a large number of them at a time, then containers
    have to be adopted. Moreover, a full virtualized system usually takes minutes
    to start, whereas containers take seconds. Download : Download high-res image
    (316KB) Download : Download full-size image Fig. 1. The workflow of a typical
    Hi-C experiment. DNA strands close to each other in the 3D space of the nucleus
    are fragmented and cross-linked using molecular biology techniques. Then, using
    paired-end sequencing, couples of fragments are identified as co-localized in
    the nucleus of cells and the corresponding bin count in the contact matrix is
    updates consequently. The contact matrix is converted into a graph-based representation
    to enable more complex analysis. While the use of full virtualization represents
    a consolidated approach in Bioinformatics [2], [8], in the last few years several
    studies have begun to focus on the use of Docker [1], [11], [34], [49] and a repository
    of Docker images for Biomedical applications, called BioShaDock, has also been
    developed [49]. Considering the use of Docker in distributed computing environments
    for Biomedicine, some attempts have been done to combine Docker Swarm with OpenStack
    [36] and to develop containerized Bioinformatic services on Cloud [5]. Although
    just a few attempts have been done to run container on Grid, the resources available
    on Cloud infrastructures for researchers (such as the EGI Federated Cloud) are
    still not comparable with the resources available on the Grid. Moreover, several
    communities still have computing models based on the Grid platform and hence exploiting
    user-level containerization techniques can increase the flexibility without re-creating
    from scratch their computing models. Considering the Desktop/Edge Grid approach,
    some implementations based on Docker in combination with BIONC, the most popular
    middleware for volunteer computing, are available  [15], [63]. Because of the
    small footprint of Docker, the general outcome of these experiments is that using
    container over Desktop/Edge Grid provide good performance giving the applications
    much more agility [35]. Considering more traditional service based Grids, IBM
    has also worked to get Docker containers running on the top of its Platform LSF
    scheduler and Adaptive Computing has just updated its Moab scheduler with Docker
    support [50]. Moreover, Docker images are available for Selenium Grid [27], and
    a Docker compliant version of HTCondor has been released by CERN [42]. However,
    to the best of our knowledge, no extensive experiments have been done or at least
    reported using these infrastructures. The only published application that actually
    combines Docker, more precisely the Udocker version, and Grid has been developed
    in the field of biomedical image processing [13]. This work presents a sort of
    parameter sweep application to identify the best parameters for the analysis of
    computer tomography data. From the technological point of view, the tests compare
    two approaches for managing the software dependencies of the code, i.e. the use
    of a Storage Element for the software libraries and the use of containers for
    executing the jobs. Considering the similarities of this work with our approach,
    we will compare our results with their ones at the end of Section 6.1. 3. Bioinformatic
    background Recent advances in high throughput molecular biology techniques and
    Bioinformatics have provided insights into chromatin interactions on a genome
    scale [40]. These techniques allow the description of the nucleus organization
    at unprecedented resolution, offering the possibility to study the structural
    properties and spatial organization of chromosomes. This is of critical importance
    for understanding and evaluating the regulation of gene expression, DNA replication,
    repair and recombination [12]. In particular, Hi-C experiments, which are the
    combination of high-throughput sequencing with 3C techniques, allows the characterization
    of long-range chromosomal interactions. They give in fact information about DNA
    fragments that are cross-linked together due to spatial proximity. This is achieved
    by reading their blunting ends through a special protocol called paired-end sequencing
    (see Fig. 1), which provides a map containing the contact probability data that
    describe the chromosomal organization in the 3D space of the nucleus. The resulting
    contact map reports the contact frequencies between a group (or groups) of genomic
    bins. The contact frequency between two bins relies on their spatial proximity,
    and it is expected to reflect their actual physical distance. Despite contact
    maps are reliable while looking at the intensity of the interactions inside a
    chromosome or between two chromosomes, they becomes unsuitable to depict the neighbourhood
    of a gene, as they lack the possibility to define a metric for computing the distance
    between two or more genes. Graphs have a higher level of expressiveness, since
    nodes represent the actors of a process while edges identify relationships among
    the actors, and graph-based model of Hi-C data can be very useful for creating
    a representation where other omic data can be mapped. Structural properties of
    a graph can reveal significant information on how the actors of the represented
    process interact, while parallel algorithms can be employed to operate over a
    graph. Some tools have been proposed to analyse Hi-C data using a graph-based
    representation, among which the most popular is probably NuChart [46], [67]. Inspired
    by web applications such as Google Maps, NuChart is an R package that elaborates
    Hi-C information to provide a Systems Biology oriented, gene-centric view of the
    three-dimensional organization of the DNA in the nucleus. NuChart can be used
    to describe the DNA conformation in the neighbourhood of selected genes by mapping
    on the achieved graph genomic features that are important for controlling gene
    expression at epigenetic level and of multi-omic data on the nodes, thus facilitating
    statistical analysis [69], [70]. 3.1. Algorithm for chromatin conformation analysis
    We recall that a graph is a formal mathematical representation of a collection
    of vertices ( ), connected by edges ( ) that model a relationship among vertices.
    In this context, vertices represent genes (e.g. an ordered set of an organism’s
    genes) labelled with gene names. Here we define paired-ends Hi-C reads as a connection
    meaning a spatial relationship between two genes (see Fig. 1). It follows that
    two genes are connected if there exists a connection encompassing both of them.
    Connections correspond to the edges of the graph, i.e.  . The neighbourhood graph
    , , can be defined as an undirected weighted graph where: • is a set of genes;
    • is a set of existing edges; • is a function that assigns a probability of actual
    physical proximity for each pair of adjacent genes connected by means of a paired-ends
    Hi-C read. The neighbourhood graph is obtained by starting from a given root vertex
    , which includes all vertices adjacent to and all edges connecting such vertices,
    including the root vertex. With these premises, our neighbourhood graph represents
    a topological map of the specific nucleus region to which a gene belongs. 3.1.1.
    Graph construction The construction of such graphs is based on the exploration
    of static datasets: raw data resulting from Hi-C experiments are processed through
    the HiCUP pipeline [71], which produces millions of paired-end reads (i.e., short
    DNA sequences with start/end coordinates) written into Sequence Alignment Map
    (SAM) files. These reads represent the main input of NuChart, because they expose
    the spatial information exploited by the process to infer a topological structure
    of the DNA. NuChart evaluates reads against a reference genome that contains the
    coordinated chromosome fragments, and a list of genes with their positions (again,
    coordinates) along the DNA. The basic mechanism in the exploration stage loops
    over the set of desired initial genes: for each gene, it looks for all connections
    (i.e. edges) (paired-ends Hi-C reads) whose first end encompasses the current
    gene — basically comparing chromosome name and coordinates. Among the found connections,
    it searches for neighbouring genes that might be located within ’s second end.
    The reason for searching adjacent genes in a read’s second end come from the way
    in which Hi-C (and 3C-based) experiments are conducted: Hi-C identifies spatially
    adjacent DNA segments in terms of three-dimensional space. If a gene is found
    on a read’s first end, a possible gene found in the second end is likely to be
    spatially adjacent, unless there are sequencing errors and biases. If we define
    the root of our neighbourhood graph to be at level , a search at level yields
    all the genes directly adjacent to the root. It follows that a search at level
    returns all genes directly adjacent to any gene discovered at level , starting
    from the root. The final graph is returned in form of a list of edges linking
    couples of nodes. The graph exploration proceeds according to a Breadth First
    Search (BFS) strategy: starting from one or more root genes (the starting node(s)
    of the graph), it expands the discovered graph one level at a time, until either
    all the reachable nodes have been found, or up to a chosen distance from the root.
    The BFS-like graph exploration results in a data-parallel procedure, in which
    any arbitrary subset of reads can be processed independently from each other,
    provided that no data dependency is involved in their manipulation. Ideally, it
    can be parallelized in a seamless way by just taking the kernel of the procedure
    and putting it into a parallel loop pattern [32]. The graph exploration has been
    organized in a level-synchronized way, and concurrent write accesses to data structures
    shared between worker threads have been managed. For example, each iteration of
    the loop builds a local graph, and a mechanism of graph merging from local graphs
    to a global output graph (actually one for each level) has been provided. Globally,
    this approach amounts at providing a reduce phase after each loop step, in which
    per-thread local data structures are merged into per-level global ones. 3.1.2.
    Normalization Hi-C readouts generally suffer from data biases that may lead to
    false-positives or false-negatives during data analysis. These biases might result
    from a number of sources, including sequencing machines’ precision and read alignment
    slips, while some might be specific to the Hi-C experiment protocol. In NuChart,
    particular attention is given to the detection and normalization of systematic
    biases, in order to correct them and avoid wrong data interpretation [73]. In
    our vision, an edge identifies the existence of an Hi-C read that encompasses
    two connected genes: normalizing each edge using genomic features — which may
    include the DNA sequence, genes and gene order, regulatory sequences and other
    genomic structural landmarks — yields a significance estimate of fragment interactions.
    Such an estimate is then used as the weight of the edge, which assumes the role
    of likelihood of physical proximity for the involved genes. For each edge, a contact
    map ( ) is constructed that directly models the read count data at the defined
    resolution. A Hi-C data matrix is symmetrical, and thus we consider only its upper
    triangular part, where each point of denotes the intensity of the interaction
    between positions and . Using the local genomic features that describe the chromosome,
    we can set up a Generalized Linear Model (GLM) with Poisson regression, with which
    we estimate the maximum likelihood of the model parameters. The model is given
    by the formula: . Here is the dependent variable, or rather the contact map that
    contains the measured contact frequencies: the assumption of this GLM is that
    the measured interaction frequencies are generated from a particular distribution
    in the exponential family, the Poisson distribution in our case, which is used
    to count the occurrences in a fixed amount of space. is the independent variable,
    which is built from chromosome length and Guanine Cytosine content, measured for
    each locus of the contact map. denotes the parameter vector to be estimated: is
    thus the linear predictor, that is the quantity which incorporates the information
    about the independent variables into the model. It is related to the expected
    value of the data through the link function . The maximum likelihood estimate
    for each edge is computed using the Iteratively Weighted Least Squares algorithm
    (IWLS) [51]. The best-fit coefficients returned by the linear regression are used
    to compute the final score of an edge, so that the edge contains an estimate of
    the physical proximity between the two genes it links, plus the genomic information
    for both linked genes. The regression is run until a convergence criterion is
    met: in our case, we check that the absolute value of the (chi-squared) difference
    at each iteration is less than a certain threshold . The edges weighing phase
    is again a data parallel application, where any arbitrary subset of the edges
    can be processed independently from the others by means of a parallel loop pattern.
    In order to fully exploit thread-level parallelism in multi-core computers, NuChart
    uses a skeletal approach [3] such as the FastFlow library [4], [17]. Download
    : Download high-res image (497KB) Download : Download full-size image Fig. 2.
    Schema of the proposed application. Due to the specific environment of the Working
    Nodes, the User is not able to run the bioinformatic application directly on Grid.
    On the other hand, using Docker and preparing a suitable Linux image for the application,
    the user is able to exploit the computational power of the Grid. 4. Computational
    background The Grid paradigm represents a suitable solution to achieve the computational
    power required by many bioinformatic tools in a cost-effective way. However, most
    of the Grid environments present some challenges, i.e. to create a customized
    computing environment and its management, that can discourage some users in favour
    of Cloud solutions [9], [16]. But some technological solution can reduce the gap
    between the two paradigms, as the Cloud-over-Grid approach [43], [55] and, more
    recently, the use of Docker in the Grid environment. In this work, we considered
    this last approach. In Fig. 2 the solution we designed is depicted, and details
    are presented in the following. 4.1. EGI Grid infrastructure EGI is a federation
    of computing and storage resourceproviders with the main goal to support research
    and development efforts. In particular EGI federates publicly funded data centres
    and Cloud providers, mostly in Europe, and give scientists access to more than
    850,000 cores and 300 PetaBytes of disk storage. Its access is free for EGI members.
    As regards the Grid component, it relies basically on a geographically distributed
    model exploiting the Unified Middleware Distribution (UMD) [23], which offers
    to end-users a set of services that allow them to access and orchestrate all the
    available computing and storage resources. The underlying architecture is composed
    by User Interfaces (UI), from which it is possible to submit jobs, described using
    the Job Description Language (JDL), to a Resource Broker (RB), a Grid Service
    able to find the most suitable computational resources for each job using different
    matching criteria [14]. Through the JDL file it is possible to specify a small
    file to be sent to the Grid resource, through the mechanism of the InputSandBox,
    a small file to retrieve, the so called OutputSandBox, and a number of global
    identifiers that refer to large files, previously allocated on the Grid distributed
    file system, that must be accessed during the computation. Moreover, the JDL file
    specifies the first command to launch on the grid, once the job is started. Each
    computational site is accessed through a specific Grid services, the Computing
    Element (CE), which is an abstraction layer for the batch queue system installed
    on the site to handle the Worker Nodes (WNs), which are the actual resources where
    the computations are run. Concerning a Grid site, we can see the front-end CE
    as the master node of a cluster, and the WNs as the computing farm. On the other
    hand, each Grid site is completed by a Storage Element (SE), which stores the
    large files that are required for/produced by the computations. The network of
    the SEs, integrated by a File Metadata Service (FMS), implements a full distributed
    file systems, able to manage multiple replicas of each file. Relying on this distributed
    infrastructure, the main steps performed by each job on the Grid sites are: •
    download the executables from the InputSandBox and the input files from the closest
    available SE; • run the simulation according to what is specified in the JDL file;
    • send the output data back to the UI through the OutputSandBox. On the UI, a
    job control facility monitors the status of the production, querying the proper
    Grid tools and orchestrating the productions triggering re-submission when needed.
    It also takes care of the data management of the final result. Security is demanded
    to the Grid Security Infrastructure (GSI), which relies on X.509 certificates
    for authentication on the computational and storage resources. 4.2. Udocker Udocker
    is a python2-based tool that can execute Docker containers in user-space, without
    requiring root privileges [28]. It enables basic download and execution of Docker
    containers by non-privileged users in Linux systems were the Docker server is
    not available. It can be used to access and execute the content of Docker containers
    in Linux batch and interactive clusters that are managed by other entities, such
    as Grid infrastructures. Udocker is an open source tool developed within the INDIGO-DataCloud
    European H2020 project [58] and has python2 as only prerequisite. Udocker is a
    wrapper around several tools that mimic a subset of the Docker capabilities, including
    pulling images and running them with minimal functionality. The current implementation
    uses PRoot to emulate chroot without requiring privileges. This feature permits
    to use some tools that do not require root privileges, but still check the actual
    user id. For instance, software installation using rpm, yum or dnf inside the
    container is possible. The containers data are unpacked and stored in the user
    home directory or other location of choice. Therefore, the containers data will
    be subject to the same filesystem protections as other files owned by the user.
    If containers have sensitive information, files and directories should be adequately
    protected by the user. 5. Experiment description The analysis process performed
    by NuChart takes SAM files as input, which contain the sequences aligned against
    the reference genome. In the present tests we used anonymized human data from
    a public experiment [40], which do not present security issues. These files normally
    reach considerable sizes (order of GigaBytes), which are prohibitive for data
    movement across WNs through the InputSandBox. Therefore we exploited remote SEs
    to dispose a number of replicas for each file, as described in the following Section.
    To perform a statistical analysis of the Grid performance in terms of input data
    size, we defined six classes, according to the sizes of the experiments we considered:
    1. 2. 3. 4. 5. 6. Output results are relatively small files that describe the
    chromosome conformation of the cell, basically a network in which nodes are genes
    and connections describe their proximity in the nucleus, and are sent back to
    the UI by using the OutputSandBox. The application has been run on the Grid resources
    in a parallel fashion, using 4 cores and 16 GB of RAM, the same number of cores
    and RAM of our reference computer, which is equipped with a modern off-the-shelf
    Intel i5-7400 processor. 5.1. Set up of storage elements Considering that we used
    files having a size up to 16 GB we had to make use of the SE, because it is not
    possible for these files to travel with the job through the InputSandBox of the
    dispatching service. In order to avoid the overloading of remote SEs and to increase
    the availability of data files, we distributed them across multiple locations
    using the FMS functionalities. Through simple experiments (i.e hundreds of downloads
    of the same file) we evaluated the download efficiency and decided to set the
    replica multiplicity to a factor of . In fact, increasing the number of replicas
    above had no significant effect on data management efficiency (greater than ),
    in terms of failed downloads (and hence failed jobs). About of failures can be
    solved through multiple trials using different locations. For what concerns the
    execution times, our experiment reported that, using replicas, of the downloads
    for 1 GB files took about 3 min, and we considered this number acceptable if compared
    with the scheduling and execution time of the application on the computational
    infrastructure, as discussed in Section 6. A time-out of 8 min was set on the
    job to consider the download failed and trigger a new trial using a different
    location. For the purposes of the work reported in this paper, we considered hundreds
    of concurrent downloads at reasonable scale. The jobs where instrumented to try
    as default SE the closest one to the site where they have been scheduled, and
    to randomly choose another replica in case of failure. Replicas are discovered
    dynamically by querying the Grid Logical File Catalogue (gLite-LFC). 5.2. Jobs
    set up The computation launched through the UI is actually executed on the WN
    and it is composed by the following sequence of steps: 1. Sanity checks of the
    environment, in particular the presence of the /tmp directory with proper permissions.
    2. Download of the corresponding SAM file from the closest SE if available, otherwise
    choose another replica and download from there. Repeat until download completion
    – a fixed number of trials (10, to have a higher probability to try all 6 replicas)
    was set before labelling the download as failed. The SAM file is automatically
    mounted and available to the Docker image. Indeed, using Udocker, users can mount
    any host directory inside the container, although this is not a real mount but
    a chroot, and the directories will be visible inside the container. 3. Download
    the NuChart Docker image from Docker Hub. No multiple trials enabled. This is
    done, as usually for Docker, using different layers (in our case starting from
    a CentOS distribution). 4. Start the NuChart computation within the Udocker image
    and create the graph using all cores requested by the Grid job (set to 4 in our
    case). 5. Pack the output to reduce bandwidth usage during the upload. 6. Send
    back the output, report successful execution and exit. In each step, entire job
    re-submission was triggered via standard Grid directives (JDL Retry and ShallowRetry
    options), in case of unrecoverable failures. Download : Download high-res image
    (374KB) Download : Download full-size image Fig. 3. Jobs flowchart: job life cycle
    management framework running on the User Interface (on the left); once submitted
    jobs are routed to a suitable CE and eventually executed on a WN (centre); main
    steps performed by the job on the WN (on the right). 5.3. The NuChart container
    and experiment management We created a custom Docker image with an ad hoc installation
    of R equipped with all the add-on packages required to run NuChart, beside some
    mandatory system libraries such as the latest boost library, the GNU Scientific
    Library gsl and FastFlow. The necessity of using a custom R environment and some
    specific system libraries is the main reason why Grid cannot be exploited in a
    straightforward way for this application. Indeed, the installation of a custom
    R environment takes a lot of time, while the installation of system libraries
    requires root privileges. The image is available at https://hub.docker.com/r/imerelli/nuchart/
    and, since it has been tagged as latest, it can be simply launched in Docker using
    the command docker pull imerelli/nuchart. Since Udocker is a very small application,
    it can be sent using the InputSandBox. On the other hand, the Udocker image is
    downloaded every time from the Docker repository. The only requirement is that
    the temporary directory(i.e. /tmp) of the server should be accessible and mounted
    without the noexec and nosuid flags, in order to make Udocker able to start. As
    for any Grid computation, it is necessary to automate the creation of the JDL
    files that describe each job of the computational challenge. Then, the framework
    used to manage the computation launches each job, monitors their status, and finally
    works to collect the results. Due to the high number of jobs required, it is essential
    to develop the tools that perform all this process automatically, since it is
    not feasible to do it manually. This has been managed using a Python-based framework
    developed by us. Fig. 3 shows the flowchart of the jobs’ life cycle management,
    whose steps consist in the creation of the JDL files, which results from the combination
    of all the input parameters, followed by the instructions for triggering all the
    jobs, monitoring their status and the retrieval of the results, when jobs are
    completed. For what concerns jobs distribution and monitoring, our submission
    framework exploits the gLite Workload Management System (WMS), while data management
    on the client side is based on the lcg-utils [65]. The framework needs to be executed
    on a standard gLite UI, while the initial data management (i.e., replica distribution
    of SAM files and Docker image uploads) have been completed before launching all
    the jobs. Download : Download high-res image (356KB) Download : Download full-size
    image Fig. 4. Average jobs lifetime, considering waiting time, input file download
    time, Docker setting time and running time. On the top panel the average job lifetime
    on the selected resource, on the bottom panel the average job lifetime on the
    whole Grid. 6. Results and discussion Results achieved in this work are twofold.
    From one side, we tested the possibility of using Udocker to run on the EGI Grid
    infrastructure a bioinformatic application, describing the achievable performance
    and scalability figures. On the other hand, we analysed the bioinformatic results,
    i.e. the contact maps describing the organization of the DNA in the nucleus for
    many different Hi-C experiments. 6.1. Udocker over Grid performance Each experiment
    we performed consists in the submission of 100 jobs for each of the 6 input types,
    for a total of 600 jobs. Submitting 100 jobs to the WMS using a single thread
    on the UI took a negligible time (in the order of 2 min) with respect to the time
    needed to complete the full analysis, so as reference time for the performance
    evaluation we considered the time when all the jobs where dispatched to the WMS
    (i.e., job_state Submitted). Other possible state for the jobs are: Ready (the
    job can be sent to the site batch system), Scheduled (the job is waiting on the
    batch system queue), Running (the job is executing), Done (the job completed)
    and Aborted (the job failed after all the re-submission trials). The Udocker version
    1.1.1 has been used. In order to compare the efficiency of Grid resources, in
    this work we performed two complete set of experiments, for a total of 1200 jobs.
    In the first simulation we restricted the number of sites eligible to run our
    jobs to a very limited set of trusted resources, named selected resources. They
    correspond to 2 CA, one in Padua1 and the other in Naples.2 They have been selected
    according to high job successful execution rate and low queue occupancy (in order
    to shorten waiting time as much as possible), and they have been very well tested
    before launching the jobs of the experiment. In the second simulation we used
    all the EGI sites accessible by our Virtual Organization gridit,3 named free resources.
    They correspond to 20 sites with 32 Computing Elements (i.e., different batch
    system queues) and 15 Storage Elements. Moreover, we repeated the two complete
    set of experiments 5 times, in different days and time in order to increase the
    statistical power of our analysis, for a total of 6000 jobs. In fact, using a
    production infrastructure, high variations can be observed due to the different
    level of usage of the communities having access to it. Fig. 4 shows the average
    queue time on the remote resources, the average input file download time, the
    average Docker setting time, and the average execution times of all the jobs for
    varying input size, considering both the selected resources and the free resources.
    Numerical data about lifetime cycle (average times and relative standard deviations)
    are reported Table 1, Table 2.4 It can be observed that for small SAM files, the
    time that the jobs remain in the Scheduled state, and the time required to perform
    the data download is greater than the time required for the execution of the NuChart
    application. However, when increasing the size of the problem, the application
    requires more time, reaching the maximum for the largest SAM files. Considering
    only jobs that come to a successful completion, we have quite similar lifetime
    cycles. High standard deviations are explained by the fact that our tests were
    run in a production environment, where the incidental infrastructure load, due
    to community usage, is out of our control and heavily influences the progression
    of jobs execution. Regarding the data download time, we notice that the average
    time remains quite similar for all input data, regardless of the size of the files
    to be downloaded. This seems to indicate that the influence of the number of jobs
    that download the same file is greater than the size of the file. The pull time
    of the Docker image from Docker Hub and the creation of the required container
    is relatively small in comparison with the application running time, becoming
    progressively negligible as the analysed datasets increase in size. Table 1. Lifetime
    for selected resources, in minutes, waiting to be executed (WT), for downloading
    the data (DT), for the set up of the Docker execution environment (ST) and for
    the execution (ET). Class Dimension WT DT ST ET 1 SAM 500 MB 24.7 ± 28.5  3.9
    ± 1.0 5.0 ± 1.0 10.0  1.0 2 750 MB SAM 1 GB 24.2 ± 30.0  5.0 ± 1.0 5.0 ± 1.0 17.0  1.0
    3 1.5 GB SAM 2.0 GB 27.5 ± 32.1  5.1 ± 1.0 4.0 ± 1.1 24.9  2.0 4 3.0 GB SAM 4.0
    GB 23.5 ± 32.5  5.0 ± 1.0 5.0 ± 1.0 31.9  2.0 5 6.0 GB SAM 8.0 GB 23.1 ± 34.9  8.0
    ± 1.1 4.0 ± 1.0 32.7 ±  9.5 6 12.0 GB SAM 16.0 GB 22.9 ± 34.7 10.0 ± 1.0 4.0 ±
    1.0 40.5 ± 10.6 Table 2. Lifetime for free resources, in minutes, waiting to be
    executed (WT), for downloading the data (DT), for the set up of the Docker execution
    environment (ST) and for the execution (ET). Class Dimension WT DT ST ET 1 SAM
    500 MB 41.5 ± 43.7  3.9 ± 1.0 5.1 ± 1.0 10.0  1.0 2 750 MB SAM 1 GB 39.1 ± 45.6  4.9
    ± 1.0 5.0 ± 1.0 17.0  1.0 3 1.5 GB SAM 2 GB 40.5 ± 47.4  5.0 ± 1.1 4.0 ± 1.0 25.0  2.0
    4 3.0 GB SAM 4 GB 40.8 ± 44.0  5.0 ± 1.0 4.0 ± 1.0 31.9  2.1 5 6.0 GB SAM 8.0
    GB 44.5 ± 44.8  8.0 ± 1.0 5.0 ± 1.0 32.2 ±  9.6 6 12.0 GB SAM 16.0 GB 44.2 ± 44.6
    10.1 ± 1.0 5.0 ± 1.0 40.3 ± 10.7 Moreover, the running time of the algorithm depends
    on the number of connections identified in the SAM file. Although for larger files
    it is possible to forecast more connections, this is not always true. Therefore,
    it is difficult to estimate the execution time in each possible case. For instance,
    when the graph has few edges, the waiting time and download time can be greater
    than the execution time. However, observing the time statistics we can conclude
    that the execution times corresponding to the application are generally much longer
    than the download time. Fig. 5 shows the number of completed jobs after the first
    job is completed, in the run that achieved median performances for each class
    of files. Even if relevant differences can be observed in runs on the same dataset
    executed in different times due to the infrastructure load, the time needed to
    analyse a single class of files (100 jobs for each class) varies from 100 ± 20
    to 165 ± 20 min in the selected resources case, while is about 2.0/2.4 times greater
    in the free resources simulation, depending on the datasets. For this kind of
    application, and given the Grid resources load at the time of the test, the strategy
    that tries to maximize the job efficiency is also the one that minimizes the total
    duration of the production, and hence should be preferred. Efficiency (overall
    percentage of jobs reported as successfully finished) and re-submissions (number
    of tries to achieve a successful job outcome) are two key parameters from a Grid
    computation and these are reported in Table 3, both for the selected resources
    and the free resources. In the free resources case we maximize the concurrency
    of the jobs (more jobs run in parallel) penalizing the job efficiency (i.e., more
    job re-submission after a failure are needed before having the job Done), while
    using the selected resources we maximize the job efficiency, but we have less
    concurrency, as reported in Table 3. In particular, we can see that we have a
    large number of failed jobs, due to the mis-configuration of some Grid sites,
    both in relation to the computational and storage resources, which causes errors
    in job submission and in data transfer respectively. The re-submissions number
    is particularly high in the case of the largest dataset (16GB) due to download
    timeout effects on the slower sites. This is in line with what has been reported
    so far [18], [39], [45]. On the other hand, basically all the computations are
    successful when jobs are dispatched to suitable CEs. Download : Download high-res
    image (448KB) Download : Download full-size image Fig. 5. Progression of the challenge
    after the end of the first job for one of the performed run for each dataset.
    On the top panel the progression on the selected resources, on the bottom panel
    the progression on the whole Grid. This is shown for all input datasets considered
    in this work. We performed the same simulation five times for each dataset. High
    variations on the progression can be experienced depending on the infrastructure
    load. Details on average times and standard deviations for the job lifetime cycle
    are reported in the text and tables. The crunching factor, which is defined (similarly
    to the speed up for parallel computations) as the expected single-CPU time required
    for the computations divided by the real computational time achieved on the distributed
    platform, is presented inTable 4, both for selected resources and free resource.
    Moreover, we reported the peak number of concurrent jobs (see Table 4), which
    is higher in the free resources because of its larger dimension compared to the
    selected resources, which nonetheless achieved a better scalability. Therefore
    these numbers show that the best result in terms of the execution time of the
    full experiment is likely to be achieved using a well tested — even if smaller
    infrastructure, due to the minimization of re-submissions. Table 3. Efficiency
    and Re-submissions. Class Dimension Efficiency (%) Re-submissions (#) Empty Cell
    Empty Cell Selected Free Selected Free 1 SAM 500 MB 100 90 ± 5 0  25  3 2 750
    MB SAM 1 GB 100 78 ± 5 0  50 ± 15 3 1.5 GB SAM 2 GB 100 86 ± 7 0  44 ± 10 4 3.0
    GB SAM 4 GB 100 92 ± 6 0  32 ± 10 5 6.0 GB SAM 8.0 GB 100 75 ± 6 0  53  7 6 12.0
    GB SAM 16.0 GB 100 60 ± 8 0 120 ± 15 The comparison with the results achieved
    by the previously published work [13], although relying on a different application,
    highlights three major points. First, in both the experiments, the pull time of
    the Docker image from Docker Hub and the creation of the required container is
    relatively small and basically negligible in comparison with the computational
    time. Second, it can be determined that, despite the generation of a delay due
    to the necessary data download and queuing time, this overhead is not exceedingly
    large, in particular while using selected resources, so it is still profitable
    to carry out the study in the Grid platform instead of being carried out on a
    local machine. In particular, considering our experiments, this claim is supported
    by the evaluation of the crunching factor, that shows a good scalability even
    for this small/medium data challenge. Third, in contrast with what has been previously
    reported, we did not experience an increase in the execution time. This was justified
    assuming that a Docker container is slower than the bare CE, but our data do not
    support this hypothesis. Table 4. Crunching factor (CF) and peak number of concurrent
    jobs (PNJ). Average on multiple simulation performed in different times. Class
    Dimension Average CF Average PNJ Empty Cell Empty Cell Selected Free Selected
    Free 1 SAM 500 MB  7.6 ± 1.4  6.5 ± 1.3 35 ± 10 75 ± 5 2 750 MB SAM 1 GB 17.2
    ± 2.6 10.2 ± 2.0 30 ± 12 76 ± 6 3 1.5 GB SAM 2 GB 24.3 ± 3.5 14.0 ± 2.7 31  7
    73 ± 4 4 3.0 GB SAM 4 GB 26.2 ± 3.5 15.8 ± 2.7 32  8 74 ± 5 5 6.0 GB SAM 8.0 GB
    19.2 ± 3.0 16.5 ± 3.0 40 ± 11 88 ± 8 6 12.0 GB SAM 16.0 GB 18.4 ± 2.9  7.5 ± 2.6
    35  7 86 ± 6 6.2. Chromatin conformation By using this Grid environment, we computed
    the graph-based representation for many public available Hi-C experiments. As
    an example, we show the results achieved analysing data from the experiments of
    Lieberman-Aiden [40], which consist in four lines of karyotypically normal human
    lymphoblastoid cell line (GM06990) sequenced with Illumina Genome Analyzer, compared
    with two lines of K562 cells, an erythroleukemia human cell line with an aberrant
    karyotype. The idea was to study the Philadelphia translocation, which is a specific
    chromosomal abnormality associated with chronic myelogenous leukaemia (CML). The
    presence of this translocation is a highly sensitive test for CML, since 95% of
    people with CML have this abnormality, although occasionally it may occur in acute
    myelogenous leukaemia (AML). The result of this translocation is that a fusion
    gene created from the juxtaposition of the ABL1 gene on chromosome 9 (region )
    to part of the BCR (breakpoint cluster region) gene on chromosome 22 (region ).
    This is a reciprocal translocation, creating an elongated chromosome 9 (called
    ), and a truncated chromosome 22 (called the Philadelphia chromosome). In this
    experiments, by using our graph-based approach, we compared the distance of some
    couples of genes that are known to create DNA translocations in CML/AML. The very
    interesting result is that ABL1 and BCR are likely to be distant 1 or 2 contacts
    ( ) in sequencing runs concerning GM06990, while they are directly in contact
    ( ) in sequencing runs related to K-562. Therefore, there is a perfect agreement
    between the positive and the negative presence of Hi-C interactions and cytogenetic
    data (see Fig. 6). Download : Download high-res image (1MB) Download : Download
    full-size image Fig. 6. Example of graph computed during this analysis. 7. Conclusions
    and future directions This work presents the performance achieved by a compute-intensive
    bioinformatic study exploiting a new modelling approach for representing the chromosome
    conformation inside the nucleus using the Grid infrastructure provided by EGI
    and the container technology. Containers in fact extend the usability of Grid
    environments, since this technology allows users to make use of software that
    would not be executed without root permissions. The key contribution is represented
    by the assessment of the feasibility of the use of Docker relying on an image
    which includes a previous installation of the used application and libraries in
    the Grid in terms of execution time and efforts to develop the container. The
    code of the application in fact has been adapted for its execution in this environment
    and the necessary tools have been developed for launching and monitoring the required
    jobs. The achieved results show that the use of containers on the Grid, enabled
    by tools such as Udocker, can represent a fundamental advantage to make this paradigm
    accessible and suitable for many more users, that otherwise will rely on smaller,
    local clusters or possibly expensive Cloud infrastructures. After assessing the
    feasibility of the Grid platforms with containers, the future directions of our
    work is represented by the development of an optimized version of the application
    using specific libraries that make a more efficient use of matrices. In this way,
    we would not have to perform a static compilation of the program to make it work
    in any CE: we could just compile it inside the Docker container, which is an even
    easier and powerful approach. Beside this, we plan to implement new containers
    for other bioinformatic applications and confirm the general validity of our findings.
    Declaration of Competing Interest No author associated with this paper has disclosed
    any potential or pertinent conflicts which may be perceived to have impending
    conflict with this work. For full disclosure statements refer to https://doi.org/10.1016/j.jpdc.2019.08.002.
    Acknowledgements This work has been supported by the Italian Flagship Project
    InterOmics, Italy (grant number PB05), founded by the Italian Ministry of Education
    and Research, and the European MIMOMICS (grant number 305280) project, funded
    by the European Commission’s 7th Framework Programme, The authors want to acknowledge
    the support of the INDIGO-DataCloud (grant number 653549) project, funded by the
    European Commission’s Horizon 2020 Framework Programme . This work benefited from
    services provided to the GRIDIT Virtual Organisation by the national resource
    providers of the EGI Federation. References [1] Afgan E., Baker D., Batut B.,
    Van Den Beek M., Bouvier D., Čech M., Chilton J., Clements D., Coraor N., Grüning
    B.A., et al. The galaxy platform for accessible, reproducible and collaborative
    biomedical analyses: 2018 update Nucleic Acids Res., 46 (W1) (2018), pp. W537-W544
    CrossRefView in ScopusGoogle Scholar [2] Afgan E., Chapman B., Jadan M., Franke
    V., Taylor J. Using cloud computing infrastructure with cloudbiolinux, cloudman,
    and galaxy Current Protoc. Bioinform., 38 (1) (2012), pp. 11-19 Google Scholar
    [3] Aldinucci M., Campa S., Danelutto M., Dazzi P., Laforenza D., Tonellotto N.,
    Kilpatrick P. Behavioural skeletons for component autonomic management on grids
    Making Grids Work, Springer (2008), pp. 3-15 CrossRefGoogle Scholar [4] Aldinucci
    M., Danelutto M., Kilpatrick P., Torquati M. Fastflow: high-level and efficient
    streaming on multi-core Pllana S., Xhafa F. (Eds.), Programming Multi-Core and
    Many-Core Computing Systems, Parallel and Distributed Computing, Wiley (2017),
    pp. 261-280 CrossRefView in ScopusGoogle Scholar [5] Ali A.A., El-Kalioby M.,
    Abouelhoda M. The case for docker in multicloud enabled bioinformatics applications
    International Conference on Bioinformatics and Biomedical Engineering, Springer
    (2016), pp. 587-601 CrossRefView in ScopusGoogle Scholar [6] Amazon, AWS Documentation,
    URL https://docs.aws.amazon.com/ecs/index.html#lang/en_us. Google Scholar [7]
    Anderson C. Docker [software engineering] IEEE Softw., 32 (3) (2015), pp. 102-c3,
    10.1109/MS.2015.62 URL https://doi.ieeecomputersociety.org/10.1109/MS.2015.62
    View in ScopusGoogle Scholar [8] Angiuoli S.V., Matalka M., Gussman A., Galens
    K., Vangala M., Riley D.R., Arze C., White J.R., White O., Fricke W.F. Clovr:
    a virtual machine for automated and portable sequence analysis from the desktop
    using cloud computing BMC Bioinform., 12 (1) (2011), p. 356 View in ScopusGoogle
    Scholar [9] Banegas-Luna A.J., Imbernón B., Llanes Castro A., Perez-Garrido A.,
    Ceron-Carrasco J.P., Gesing S., Merelli I., D’Agostino D., Perez-Sanchez H. Advances
    in distributed computing with modern drug discovery Expert Opin. Drug Discov.,
    14 (1) (2019), pp. 9-22 CrossRefView in ScopusGoogle Scholar [10] Barham P., Dragovic
    B., Fraser K., Hand S., Harris T., Ho A., Neugebauer R., Pratt I., Warfield A.
    Xen and the art of virtualization ACM SIGOPS Operating Systems Review, Vol. 37,
    ACM (2003), pp. 164-177 5 View in ScopusGoogle Scholar [11] Boettiger C. An introduction
    to docker for reproducible research Oper. Syst. Rev., 49 (1) (2015), pp. 71-79
    CrossRefView in ScopusGoogle Scholar [12] Chepelev I., Wei G., Wangsa D., Tang
    Q., Zhao K. Characterization of genome-wide enhancer-promoter interactions reveals
    co-expression of interacting genes and modes of higher order chromatin organization
    Cell Res., 22 (3) (2012), pp. 490-503 CrossRefView in ScopusGoogle Scholar [13]
    Chillarón M., Vidal V., Segrelles D., Blanquer I., Verdú G. Combining grid computing
    and docker containers for the study and parametrization of ct image reconstruction
    methods Procedia Comput. Sci., 108 (2017), pp. 1195-1204 View PDFView articleView
    in ScopusGoogle Scholar [14] Clematis A., Corana A., D’Agostino D., Galizia A.,
    Quarati A. Job–resource matchmaking on grid through two-level benchmarking Future
    Gener. Comput. Syst., 26 (8) (2010), pp. 1165-1179 View PDFView articleView in
    ScopusGoogle Scholar [15] Concas M., Berzano D., Bagnasco S., Lusso S., Masera
    M., Puccio M., Vallero S. Plancton: an opportunistic distributed computing project
    based on docker containers Journal of Physics: Conference Series, Vol. 898, IOP
    Publishing (2017), p. 092049 CrossRefView in ScopusGoogle Scholar [16] D’Agostino
    D., Clematis A., Quarati A., Cesini D., Chiappori F., Milanesi L., Merelli I.
    Cloud infrastructures for in silico drug discovery: Economic and practical aspects
    BioMed Res. Int., 2013 (2013) Google Scholar [17] Danelutto M., Torquati M. Loop
    parallelism: a new skeleton perspective on data parallel patterns Parallel, Distributed
    and Network-Based Processing (PDP), 2014 22nd Euromicro International Conference
    on, IEEE (2014), pp. 52-59 View in ScopusGoogle Scholar [18] Degliesposti G.,
    Kasam V., Da Costa A., Kang H.-K., Kim N., Kim D.-W., Breton V., Kim D., Rastelli
    G. Design and discovery of plasmepsin ii inhibitors using an automated workflow
    on large-scale grids ChemMedChem: Chem. Enabling Drug Discov., 4 (7) (2009), pp.
    1164-1173 CrossRefView in ScopusGoogle Scholar [19] Dekker J., Rippe K., Dekker
    M., Kleckner N. Capturing chromosome conformation Science, 295 (5558) (2002),
    pp. 1306-1311 View in ScopusGoogle Scholar [20] Dudley J.T., Butte A.J. In silico
    research in the era of cloud computing Nature Biotechnol., 28 (11) (2010), p.
    1181 CrossRefView in ScopusGoogle Scholar [21] E. Foundation, Egi use cases. URL
    https://zenodo.org/record/159455#.W8MIeC9aZvU, (2017). Google Scholar [22] Eagen
    K.P. Principles of chromosome architecture revealed by hi-c Trends Biochem. Sci.
    (2018) Google Scholar [23] EGI Software Repository, URL http://repository.egi.eu.
    Google Scholar [24] Felter W., Ferreira A., Rajamony R., Rubio J. An updated performance
    comparison of virtual machines and linux containers Performance Analysis of Systems
    and Software (ISPASS), 2015 IEEE International Symposium on, IEEE (2015), pp.
    171-172 CrossRefView in ScopusGoogle Scholar [25] Foster I., Kesselman C. The
    history of the grid Adv. Parallel Comput., 20 (2011), pp. 3-30, 10.3233/978-1-60750-803-8-3
    View in ScopusGoogle Scholar [26] Fraser J., Williamson I., Bickmore W.A., Dostie
    J. An overview of genome organization and how we got there: from fish to hi-c
    Microbiol. Mol. Biol. Rev., 79 (3) (2015), pp. 347-372 View in ScopusGoogle Scholar
    [27] M. Gholap, Deploying Selenium Grid Using Docker, URL https://dzone.com/articles/deploying-selenium-grid-using-docker,
    2018. Google Scholar [28] Gomes J., Bagnaschi E., Campos I., David M., Alves L.,
    Martins J., Pina J., Lopez-Garcia A., Orviz P. Enabling rootless linux containers
    in multi-user environments: the udocker tool Comput. Phys. Comm., 232 (2018),
    pp. 84-97 View PDFView articleView in ScopusGoogle Scholar [29] Harewood L., Kishore
    K., Eldridge M.D., Wingett S., Pearson D., Schoenfelder S., Collins V.P., Fraser
    P. Hi-c as a tool for precise detection and characterisation of chromosomal rearrangements
    and copy number variation in human tumours Genome Biol., 18 (1) (2017), p. 125
    View in ScopusGoogle Scholar [30] Hightower K., Burns B., Beda J. Kubernetes:
    Up and Running: Dive Into the Future of Infrastructure O’Reilly Media, Inc. (2017)
    Google Scholar [31] Hindman B., Konwinski A., Zaharia M., Ghodsi A., Joseph A.D.,
    Katz R.H., Shenker S., Stoica I. Mesos: A platform for fine-grained resource sharing
    in the data center. NSDI, Vol. 11 (2011), p. 22 Google Scholar [32] Hong S., Oguntebi
    T., Olukotun K. Efficient parallel graph exploration on multi-core CPU and GPU
    Proceedings of the 2011 International Conference on Parallel Architectures and
    Compilation Techniques, PACT ’11, IEEE Computer Society, Washington, DC, USA (2011),
    pp. 78-88 CrossRefView in ScopusGoogle Scholar [33] Howe B. Virtual appliances,
    cloud computing, and reproducible research Comput. Sci. Eng., 14 (4) (2012), pp.
    36-41 View in ScopusGoogle Scholar [34] Hung L.-H., Kristiyanto D., Lee S.B.,
    Yeung K.Y. Guidock: using docker containers with a common graphics user interface
    to address the reproducibility of research PLoS One, 11 (4) (2016), Article e0152686
    CrossRefView in ScopusGoogle Scholar [35] Ismail B.I., Goortani E.M., Ab Karim
    M.B., Tat W.M., Setapa S., Luke J.Y., Hoe O.H. Evaluation of docker as edge computing
    platform Open Systems (ICOS), 2015 IEEE Confernece on, IEEE (2015), pp. 130-135
    View in ScopusGoogle Scholar [36] Jansen C., Witt M., Krefting D. Employing docker
    swarm on openstack for biomedical analysis International Conference on Computational
    Science and Its Applications, Springer (2016), pp. 303-318 CrossRefView in ScopusGoogle
    Scholar [37] Kivity A., Kamay Y., Laor D., Lublin U., Liguori A. Kvm: the linux
    virtual machine monitor Proceedings of the Linux Symposium, vol. 1 (2007), pp.
    225-230 Google Scholar [38] Kratzke N. Lightweight virtualization cluster how
    to overcome cloud vendor lock-in J. Comput. Commun., 2 (12) (2014), p. 1 CrossRefGoogle
    Scholar [39] Lee H.-C., Salzemann J., Jacq N., Chen H.-Y., Ho L.-Y., Merelli I.,
    Milanesi L., Breton V., Lin S.C., Wu Y.-T. Grid-enabled high-throughput in silico
    screening against influenza a neuraminidase IEEE Trans. Nanobiosci., 5 (4) (2006),
    pp. 288-295 Google Scholar [40] Lieberman-Aiden E., van Berkum N.L., Williams
    L., Imakaev M., Ragoczy T., Telling A., Amit I., Lajoie B.R., Sabo P.J., Dorschner
    M.O., Sandstrom R., Bernstein B., Bender M.A., Groudine M., Gnirke A., Stamatoyannopoulos
    J., Mirny L.A., Lander E.S., Dekker J. Comprehensive mapping of long-range interactions
    reveals folding principles of the human genome Science, 326 (5950) (2009), pp.
    289-293 CrossRefView in ScopusGoogle Scholar [41] D. Marshall, Understanding full
    virtualization, paravirtualization, and hardware assist, VMWare White Paper, (2007)
    17. Google Scholar [42] N. Medjkoune, Integrating Docker containers into the CERN
    batch system, URL https://zenodo.org/record/159455#.W8MIeC9aZvU, 2016. Google
    Scholar [43] Merelli I., Cozzi P., Ronchieri E., Cesini D., D’Agostino D. Porting
    bioinformatics applications from grid to cloud: A macromolecular surface analysis
    application case study Int. J. High Perform. Comput. Appl., 31 (3) (2017), pp.
    182-195 CrossRefView in ScopusGoogle Scholar [44] Merelli I., Liò P., Milanesi
    L. Nuchart: An r package to study gene spatial neighbourhoods with multi-omics
    annotations PLoS ONE, 8 (9) (2013), Article e75146 CrossRefView in ScopusGoogle
    Scholar [45] Merelli I., Pescini D., Mosca E., Cazzaniga P., Maj C., Mauri G.,
    Milanesi L. Grid computing for sensitivity analysis of stochastic biological models
    International Conference on Parallel Computing Technologies, Springer (2011),
    pp. 62-73 CrossRefView in ScopusGoogle Scholar [46] Merelli I., Tordini F., Drocco
    M., Aldinucci M., Liò P., Milanesi L. Integrating multi-omic features exploiting
    chromosome conformation capture data Front. Geneti., 6 (40) (2015) Google Scholar
    [47] Merkel D. Docker: Lightweight Linux containers for consistent development
    and deployment Linux J., 2014 (239) (2014) Google Scholar [48] Microsoft, Azure
    Container Service Documentation, URL https://docs.microsoft.com/en-us/azure/container-service/.
    Google Scholar [49] F. Moreews, O. Sallou, H. Ménager, et al. Bioshadock: a community
    driven bioinformatics shared Docker-based tools registry, F1000Research 4. Google
    Scholar [50] T.P. Morgan, Bridging The Gap Between Grid And Containers, URL https://www.nextplatform.com/2015/12/04/bridging-the-gap-between-grid-and-containers/,
    2015. Google Scholar [51] Nelder J.A., Wedderburn R.W.M. Generalized linear models
    J. R. Stat. Soc. Ser. A Gen., 135 (1972), pp. 370-384 CrossRefGoogle Scholar [52]
    Peinl R., Holzschuher F., Pfitzer F. Docker cluster management for the cloud-survey
    results and own solution J. Grid Comput., 14 (2) (2016), pp. 265-282 CrossRefView
    in ScopusGoogle Scholar [53] Quint P.-C., Kratzke N. Overcome vendor lock-in by
    integrating already available container technologies towards transferability in
    cloud computing for smes Cloud Comput., 2016 (2016), p. 50 Google Scholar [54]
    Rancher Documentation, URL https://rancher.com/docs/rancher/v1.6/en/. Google Scholar
    [55] Ronchieri E., Cesini D., D’Agostino D., Ciaschini V., Dalla Torre G., Cozzi
    P., Salomoni D., Clematis A., Milanesi L., Merelli I. The wnodes cloud virtualization
    framework: a macromolecular surface analysis application case study Parallel,
    Distributed and Network-Based Processing (PDP), 2014 22nd Euromicro International
    Conference on, IEEE (2014), pp. 218-222 CrossRefView in ScopusGoogle Scholar [56]
    Rosenblum M. Vmwares virtual platform Proceedings of Hot Chips, Vol. 1999 (1999),
    pp. 185-196 Google Scholar [57] Rossi R.L., Grifantini R.M. Big data: challenge
    and opportunity for translational and industrial research Front. Digit. Humanit.,
    5 (2018), p. 13 CrossRefGoogle Scholar [58] D. Salomoni, I. Campos, L. Gaido,
    G. Donvito, M. Antonacci, P. Fuhrman, J. Marco, A. Lopez-Garcia, P. Orviz, I.
    Blanquer, et al. INDIGO-Datacloud: foundations and architectural description of
    a Platform as a Service oriented to scientific computing, CoRR abs/1711.01981,
    arXiv:1711.01981, URL http://arxiv.org/abs/1711.01981. Google Scholar [59] Sati
    S., Cavalli G. Chromosome conformation capture technologies and their impact in
    understanding genome function Chromosoma, 126 (1) (2017), pp. 33-44, 10.1007/s00412-016-0593-6
    View in ScopusGoogle Scholar [60] Shavit Y., Merelli I., Milanesi L., Lio’ P.
    How computer science can help in understanding the 3d genome architecture Brief.
    Bioinform., 17 (5) (2015), pp. 733-744 Google Scholar [61] da Silva V.G., Kirikova
    M., Alksnis G. Containers for virtualization: An overview Appl. Comput. Syst.,
    23 (1) (2018), pp. 21-27 Google Scholar [62] Silver A. Software simplified Nat.
    News, 546 (7656) (2017), p. 173 CrossRefView in ScopusGoogle Scholar [63] S. Smith,
    Containerizing The Grid - BOINC on Docker, URL https://rsmitty.github.io/Containerizing-The-Grid/,
    2015. Google Scholar [64] Soltesz S., Pötzl H., Fiuczynski M.E., Bavier A., Peterson
    L. Container-based operating system virtualization: a scalable, high-performance
    alternative to hypervisors ACM SIGOPS Operating Systems Review, Vol. 41, ACM (2007),
    pp. 275-287 3 View in ScopusGoogle Scholar [65] B. Stephen, C. Simone, L. Elisa,
    L. Maarten, M.L. Patricia, M. Vincenzo, N. Christopher, S. Roberto, S. Andrea,
    gLite 3.2 user guide, https://edms.cern.ch/file/722398/1.4/gLite-3-UserGuide.pdf,
    version 1.4.2, 2012. Google Scholar [66] Talbi E.-G., Zomaya A.Y. Grid Computing
    for Bioinformatics and Computational Biology, Vol. 1 John Wiley & Sons (2007)
    Google Scholar [67] Tordini F., Aldinucci M., Milanesi L., Liò P., Merelli I.
    The genome conformation as an integrator of multi-omic data: The example of damage
    spreading in cancer Front. Genet., 7 (194) (2016), pp. 1-17 Google Scholar [68]
    Tordini F., Drocco M., Merelli I., Milanesi L., Liò P., Aldinucci M. Nuchart-II:
    a graph-based approach for the analysis and interpretation of hi-c data Post-Conference
    Proceedings of the 11th Intl. Meeting on Computational Intelligence Methods for
    Bioinformatics and Biostatistics (CIBB 2014), LNBI, vol. 8623, Springer, Cambridge,
    UK (2015), 10.1007/978-3-319-24462-4˙25 Google Scholar [69] Tordini F., Drocco
    M., Misale C., Milanesi L., Liò P., Merelli I., Aldinucci M. Parallel exploration
    of the nuclear chromosome conformation with NuChart-II Proc. of Intl. Euromicro
    PDP 2015: Parallel Distributed and Network-Based Processing, IEEE (2015) Google
    Scholar [70] Tordini F., Merelli I., Liò P., Milanesi L., Aldinucci M. Nuchart:
    embedding high-level parallel computing in R for augmented Hi-C data analysis
    Publishing S.I. (Ed.), Computational Intelligence Methods for Bioinformatics and
    Biostatistics, Lecture Notes in Computer Science, vol. 9874, Springer International
    Publishing, Cham (ZG) (2016), pp. 259-272 CrossRefView in ScopusGoogle Scholar
    [71] S. Wingett, P. Ewels, M. Furlan-Magaril, T. Nagano, S. Schoenfelder, P. Fraser,
    S. Andrews, HiCUP: pipeline for mapping and processing Hi-C data [version 1; referees:
    2 approved, 1 approved with reservations], F1000Research 4 (1310). Google Scholar
    [72] de Wit E., de Laat W. A decade of 3C technologies: insights into nuclear
    organization Genes Dev., 26 (1) (2012), pp. 11-24 CrossRefView in ScopusGoogle
    Scholar [73] Yaffe E., Tanay A. Probabilistic modeling of hi-c contact maps eliminates
    systematic biases to characterize global chromosomal architecture Nature Genet.,
    43 (11) (2011), pp. 1059-1065 CrossRefView in ScopusGoogle Scholar [74] Q. Zhang,
    L. Liu, C. Pu, Q. Dou, L. Wu, W. Zhou, A Comparative Study of Containers and Virtual
    Machines in Big Data Environment, arXiv preprint arXiv:1807.01842. Google Scholar
    [75] Zheng Y., Nicol D.M. A virtual time system for openvz-based network emulations
    Proceedings of the 2011 IEEE Workshop on Principles of Advanced and Distributed
    Simulation, IEEE Computer Society (2011), pp. 1-10 CrossRefGoogle Scholar Cited
    by (5) Hound: A Parallel Image Distribution System for Cluster Based on Docker
    2023, Journal of Systems Engineering and Electronics Using Singularity for Geant4-Based
    Simulations on HPC Infrastructures 2022, 2022 IEEE NSS/MIC RTSD - IEEE Nuclear
    Science Symposium, Medical Imaging Conference and Room Temperature Semiconductor
    Detector Conference Advantages of using graph databases to explore chromatin conformation
    capture experiments 2021, BMC Bioinformatics NeoHiC: A web application for the
    analysis of Hi-C data 2020, Lecture Notes in Computer Science (including subseries
    Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
    DL-HAR: Deep learning-based human activity recognition framework for edge computing
    2020, Computers, Materials and Continua Ivan Merelli is staff scientist at the
    Institute for Biomedical Technologies (ITB) of the Italian National Research Council
    (CNR) in the Bioinformatic Unit. He earned a PhD in computer science from the
    University of Milano-Bicocca in 2009 and was visiting scientist at Harvard University
    in 2014 and at Cambridge University in 2015. He got the Italian associate professor
    habilitation in 2017. He coauthored more than forty papers published in international
    peer-reviewed journals and more than forty contributions in International Conference
    Proceedings. His research activities concern statistical data analysis, software
    development and data management in the field of Genomics and Proteomics, in particular
    for the management of Biological Databases and High Performance Computing facilities.
    He participated to the Italian Projects Grid.it, LITBIO and ITALBIONET and to
    the European Projects BioinfoGRID and EGEE for the development of high performance
    solutions in the field of Systems and Computational Biology. He is associated
    editor of “BMC Genomics”, BioMed Central Ltd and “Frontiers in Bioinformatics
    and Computational Biology”, Frontiers Media S.A. He was Guest Editor of the special
    issue on “Latest advances in distributed, parallel, and graphic processing unit
    accelerated approaches to computational biology” in “Concurrency and Computation:
    Practice and Experience” and of the special issue “High- Performance Computing
    and Big Data in Omics-Based Medicine” in “Biomed Research International”. Federico
    Fornari graduated in physics in 2014 at Bologna University with a thesis on the
    research of electronic neutrino interactions in the OPERA experiment, at INFN
    Gran Sasso Laboratories. Then he took his PhD in physics in 2018 at Bologna University
    with a thesis on the software development and detector characterization of the
    Near-Infrared Spectro- Photometer aboard the ESA Euclid mission. Currently he
    is a member of CNAF user support team for INFN astro-particle physics experiments.
    Fabio Tordini is currently a postdoc researcher at the University of Torino, Italy,
    and at the Fondazione Edo ed Elvo Tempia, Biella, Italy. He received his Ph.D.
    in Computer Science from the University of Torino in April 2016, with the thesis
    “The road towards a cloud-based High-Performance solution for genomic data analysis”.
    He is a research associate at the University of Torino since 2012. Before, he
    has been a visiting scholar at the State University of New York at Stony Brook,
    in 2011, and received is Ms.C. in Computer Science in 2010 from the University
    of Camerino, Italy. He has co-authored papers in international journals and conference
    proceedings. He has been participating in the European STREP FP7 ParaPhraseproject,
    and the H2020 RePhrase project, working on techniques and methodologies for developing
    data-intensive applications in C++, targeting heterogeneous systems that combine
    CPUs and GPUs into a coherent parallel platform. He has been participating in
    the cHiPSet ICT Cost action on High-Performance Modelling and Simulation for Big
    data Applications. His research activity began with high-level parallel programming
    patterns for multi-core and many-cores systems and memory optimization. His research
    is now focused on high-performance computing and Bioinformatics. In particular,
    his work at the University of Torino focuses on HPC solutions for scientific workflows,
    cloud deployment, job scheduling and resource provisioning. At the Fondazione
    Tempia, his work focuses on tools and methods for the optimization of Bioinformatics
    workflows and NGS data analysis. Daniele D’Agostino, Ph.D., is a researcher at
    the Institute of Applied Mathematics and Information Technologies of National
    Research Council. His research activities concern the design of science gateways
    in different research fields, the resource allocation in Grid/Cloud environments
    and the development of parallel software. He co-organized the 22th Euromicro International
    Conference on Parallel, Distributed, and Network-Based Processing, several special
    issues on ISI journals and co-authored more than 100 scientific papers, published
    in journals, book chapters and conference proceedings. Marco Aldinucci is an associate
    professor at Computer Science Department of the University of Torino (UNITO) since
    2014. He got the Italian full professor habilitation in 2017. Previously, he has
    been compiler designer at Quadrics (Alenia Spazio), postdoc at University of Pisa,
    researcher at Italian National Research Agency (ISTI-CNR), and University of Torino.
    He is the author of over 120 papers in international journals and conference proceeding.
    He has been participating in over 20 national and international research projects
    concerning parallel and autonomic computing. He is the recipient of the HPC Advisory
    Council University Award 2011, the NVidia Research award 2013, the IBM Faculty
    Award 2015. He is the P.I. of the parallel computing group alpha@UNITO, the director
    of the “HPC and smart data” laboratory at ICxT@UNITO innovation centre, and vice-president
    of the C3S@UNITO competency centre. He co-designed a number of frameworks for
    parallel computing, including FastFlow, which has been the background technology
    for the EU FP7/H2020 projects Paraphrase, Repara, Rephrase (total cost over 10M)
    and used for the development of production software in several industrial settings,
    including Siemens. As director of the CINI consortium at University of Torino,
    he participates to the EU H2020 Toreador BigData Analytics projects (total cost
    6.2 M). His research is focused on parallel and distributed computing. Daniele
    Cesini is working as a Researcher in Technology (Tecnologo) at the Italian Institute
    for Nuclear Physics (INFN). He is currently a member of the Data Handling group
    at INFN- CNAF, a WLCG Tier1 datacenter. Within this group, he is responsible for
    the operations of the data management services exposed to users. He is the coordinator
    of the User Support Team of the same datacenter. Since 2004, he acquired experience
    working within national and international initiatives dealing with distributed
    and parallel computing. During the EGEE projects series he worked for the Italian
    Grid Infrastructure fulfilling managerial roles in Operations and User Support
    activities. For the EGI-Inspire project, he coordinated the Work Package dealing
    with the development of the EGI Operational tools. He focused his research in
    the field of efficient tasks scheduling in distributed environments for mixed
    High Performance/High Throughput Computing workflows. He is expert in the application
    porting to different computing platforms: distributed architectures, low power
    processors and HPC hybrid systems. He is contributing to various tasks in the
    ExaNeST project to build the storage system of an Exascale prototype machine.
    1 http://operations-portal.egi.eu/vapor/resources/GL2ResSummaryServicesDetail?site=INFN-PADOVA&country=italy.
    2 http://operations-portal.egi.eu/vapor/resources/GL2ResSummaryServicesDetail?site=GRISU-UNINA&country=italy.
    3 https://operations-portal.egi.eu/vo/view/voname/gridit. 4 Full results are available
    at https://github.com/imerelli/GridDocker. View Abstract © 2019 Elsevier Inc.
    All rights reserved. Part of special issue Parallel Computing in Modelling and
    Simulation Edited by William Spataro, Giuseppe A. Trunfio, Georgios Ch. Sirakoulis
    View special issue Recommended articles Intracellular acidosis via activation
    of Akt-Girdin signaling promotes post ischemic angiogenesis during hyperglycemia
    International Journal of Cardiology, Volume 277, 2019, pp. 205-211 Hong-Ming Zhang,
    …, Xiao-Yan Li View PDF Simple, efficient allocation of modelling runs on heterogeneous
    clusters with MPI Environmental Modelling & Software, Volume 88, 2017, pp. 48-57
    David I. Donato View PDF Distributed computing by leveraging and rewarding idling
    user resources from P2P networks Journal of Parallel and Distributed Computing,
    Volume 122, 2018, pp. 81-94 Nunziato Cassavia, …, Chiara Pulice View PDF Show
    3 more articles Article Metrics Citations Citation Indexes: 4 Captures Readers:
    29 View details About ScienceDirect Remote access Shopping cart Advertise Contact
    and support Terms and conditions Privacy policy Cookies are used by this site.
    Cookie settings | Your Privacy Choices All content on this site: Copyright © 2024
    Elsevier B.V., its licensors, and contributors. All rights are reserved, including
    those for text and data mining, AI training, and similar technologies. For all
    open access content, the Creative Commons licensing terms apply.'
  inline_citation: '>'
  journal: Journal of parallel and distributed computing
  limitations: '>'
  pdf_link: null
  publication_year: 2019
  relevance_score1: 0
  relevance_score2: 0
  title: Exploiting Docker containers over Grid computing for a comprehensive study
    of chromatin conformation in different cell types
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1145/3487923.3487934
  analysis: '>'
  authors:
  - Kennedy Chengeta
  citation_count: 2
  full_citation: '>'
  full_text: '>

    Comparing the performance between Virtual

    Machines and Containers using deep learning credit

    models

    Kennedy Chengeta

    kennedy.chengeta@kaributechs.com

    University of Cape Town

    Cape Town, South Africa

    Abstract

    The cloud computing paradigm utilizes neutralization to iso-

    late data, workloads and network bandwidth in an elastic

    mode. The providers hence have historically used Virtual

    Machines (VM) to perform this workload isolation . How-

    ever these virtual machines require huge resources and are

    costly to set-up and deploy. Containerization has of late

    been used as a different approach for neutralization albeit

    as a Software as a service approach. Docker containeriza-

    tion has been one of the most popular approaches and its a

    solution where containers all share the same resources and

    operating system as opposed to virtual machines which use

    hyper-visor technology to abstract hardware and operating

    systems. The study uses different cloud vendors to compare

    docker containers for response time, download time, CPU

    processing time as well as memory usage against virtual ma-

    chines. The study did a performance comparison for Virtual

    Machines and Docker Containers in various cloud providers

    namely AWS, Google Cloud as well as Microsoft Azure cloud

    platforms. The dataset used included deep learning big data

    downloaded from Kaggle website and classified for loan de-

    faulting with Keras and tensorflow python implementation

    frameworks. The comparisons do prove that docker contain-

    ers are faster than KVMs and Xen virtual machines. The

    study also proves that by using Kubernetes framework for

    scaling the containers, the performance of the docker con-

    tainers improves compared to the docker and bare metal as

    well as cloud frameworks.

    CCS Concepts: • Containerization → Docker Contain-

    ers; • Clustering → Kubernetes; • Hosting → Virtual Ma-

    chines; • Cloud → Microsoft Azure.

    Permission to make digital or hard copies of all or part of this work for

    personal or classroom use is granted without fee provided that copies are not

    made or distributed for profit or commercial advantage and that copies bear

    this notice and the full citation on the first page. Copyrights for components

    of this work owned by others than ACM must be honored. Abstracting with

    credit is permitted. To copy otherwise, or republish, to post on servers or to

    redistribute to lists, requires prior specific permission and/or a fee. Request

    permissions from permissions@acm.org.

    icARTi ’21, December 9–10, 2021, Virtual Event, Mauritius

    © 2021 Association for Computing Machinery.

    ACM ISBN 978-1-4503-8575-6/21/12...$15.00

    https://doi.org/10.1145/3487923.3487934

    Keywords: containers, deep learning, kubernetes, perfor-

    mance, open stack, VM (Virtual Machines)

    ACM Reference Format:

    Kennedy Chengeta. 2021. Comparing the performance between

    Virtual Machines and Containers using deep learning credit models.

    In International Conference on Artificial Intelligence and its Appli-

    cations (icARTi ’21), December 9–10, 2021, Virtual Event, Mauritius.

    ACM, New York, NY, USA, 8 pages. https://doi.org/10.1145/3487923.

    3487934

    1

    Introduction

    Virtual machines provide computing resources and allow

    for hardware abstraction and consolidation of resources.

    They are also popular for hosting Virtual Defined Functions

    or VNFs, reduce vendor lock-in and improved security. In

    cloud computing, services like Amazon Web Services, Google

    Cloud and Microsoft Azure the importance of virtualiza-

    tion in provision of infrastructure as a service, abstraction

    and resource allocation has been witnessed due to rapid

    growth[2, 11]. The virtualization technologies however, add

    extra layers of virtualization at the costs of performance

    and costs for customers. Containers have been introduced as

    alternatives to virtual machines due to their low utilization

    of computational resources. These technologies bring near

    native performance in cloud and on premise environments.

    Key container services include docker containers, Amazon

    EC2 Containers, Google Container Engine and container

    orchestrations like Kubernetes. Virtual machines include

    Amazon EC2 virtual machines, OpenStack virtual machines,

    VMware ESXi, Vsphere and Vcenter [2, 3, 10, 17]. Primary

    motivations for containers have been largely to encapsulate

    and easier deploying of systems, run micro-service architec-

    ture components, efficiency as well as flexibility.

    The study aims to study the performance of traditional vir-

    tual machines and the container technologies. Critical areas

    of assessment include performance metrics, CPU utilization,

    booting time, throughput and scaling, evaluation of overhead

    the two technologies on bare metal directly. The study will

    also look at performance by combining the two technologies

    where containers are executed in virtual machines to see if

    they give better throughput both for on premise and cloud

    icARTi ’21, December 9–10, 2021, Virtual Event, Mauritius

    Kennedy Chengeta

    environments.

    The study will compare the output of executing big data

    based on deep learning resource intensive classification on

    both containers and virtual machines. The output will be col-

    lected and results compared for disk, CPU, memory, network

    and application performance using the resource intensive

    machine learning application running deep learning classifi-

    cation of big data loan lending dataset. The study details the

    objectives, literature study, methodology, implementation,

    results analysis and conclusion.

    2

    Literature Review

    Virtualization which built the foundations of cloud com-

    puting enabled resource provisioning, multi-tenancy, sys-

    tem constitution in IAAS or infrastructure as a service and

    was mostly based on hypervisor virtual platforms to be a

    middle-ware between the CPU and operating system. Differ-

    ent studies analysed the use of virtual machines in abstract-

    ing hardware and exposing as infrastructure as a service

    components. With emergency of cloud computing, hyper-

    visor based virtual machines like OpenStack, KVM (Kernel

    Virtual Machine), VirtualBox and Vmware.Virtual machines

    are known to degrade over time through slow performance

    because of disk fragmentation, virtual machine sprawling,

    memory and CPU bottlenecks as well non frequent patch

    updates [3, 10, 11, 22]. Key considerations for performance

    in virtual machines include memory, CPU and storage disk

    sizes. as well as network access to external systems as well

    as high traffic peak periods scalability. In virtualization, a

    hypervisor runs on the underlying hardware and guests will

    use the underlying hardware features.

    Containers are a major enabler in operating system virtu-

    alization which are alternate to virtual machines and have

    been found to be demanding low computational resources

    and are mostly classified as application containers, docker

    or system containers [3]. They eliminate need of an extra

    guest operating system.

    Various studies have looked at container based and virtual

    machines comparisons with focus on performance, cloud

    computing, WebRTC servers and resource allocation [23].

    The study notes however lack of comparisons of systems of

    big data machine learning applications on virtual machines

    and containers focusing on resource usage, scaling, set-up

    costs, memory and CPU utilizations. Big data applications

    include the use of frameworks like deep learning, Spark and

    Hadoop for big data classification using large datasets.

    Hypervisors are grouped into Type 1 and Type 2 hyper-

    visors with the former directly linked to the infrastructure

    hardware and the later runs as an application on the host ap-

    plication namely HyperKit or OSX and Hyper-V and Virtual

    Box and VMWare. For docker containers the docker daemon

    replaces the hypervisors and have docker images as binaries

    and the images are managed independently by the docker

    daemon. The daemon rationalises resources and isolates host

    OS from containers and it requires less memory and storage.

    3

    Virtual Machines

    Popular virtual machines include KVM, VMware ESXi, Hyper-

    V and XEN and are both hypervisor based virtual machines

    as opposed to LXC and Docker which are container based

    platforms [1, 11, 23]. The following section discusses Xen

    and KVM virtual machines. The two were selected based

    on their widespread use and popularity in the virtual ma-

    chine community as well as their widespread documentation

    availability.

    3.1

    Xen

    The Xen hypervisor supports x86, itanium and x86-64 as well

    as ARM architectures and runs on linux as well as windows

    and is primarily used by Citrix and Oracle Virtual Machines.

    With Xen, full virtualization is enabled and it runs directly

    on the hardware and allocates memory and CPU as well as

    hardware resources [1, 12]. The running instance will have

    drivers of all system software it needs. The guest domains

    run their own software and handle all the access for input

    and output as Type 1 hypervisors [11]. The Virtual Machines

    provide abstraction and operational efficiency and reduce

    costs to data centers and Xen also uses para-virtualization

    where the operating system is aware of the virtualization and

    works with the hypervisor to improve operational efficiency.

    The Xen and KVM machines are compared in the following

    figure 1.

    Figure 1. Comparison of the Xen and KVM virtual machines

    [21]

    3.2

    Kernel Virtual Machines

    KVM (for Kernel-based Virtual Machine) enable complete

    virtualization solutions on x86 architecture with Intel VT or

    AMD-V hardware and is open source based. The kernel is

    Comparing the performance between Virtual Machines and Containers using deep learning
    credit models

    icARTi ’21, December 9–10, 2021, Virtual Event, Mauritius

    based on Linux and acts as a Type 2 Hypervisor and enables

    improved performance by coordinating calls for processor

    memory and hard disks as well as network resources through

    the host operating system [1, 12]. The KVM can be loaded

    and run on multiple virtual machines on solitary servers

    running unchanged Linux as well as Windows. Multiple vir-

    tual machines can be run unchanged on Linux or Windows

    images with every VM or virtual machine having dedicated

    hardware, network and graphics drivers. The KVM architec-

    ture is shown in figure 2 showing the user and guest modes.

    Figure 2. Architecture of the Kernel Virtual Machines [6]

    Both Xen and KVM are both open source modifications

    of the Linux kernel and KVM runs as a kernel module. Xen

    supports both paravirtualization as well as hypervisor.

    4

    Containerization

    As alternative to virtualization is containerization with tech-

    nologies like LXC or Linux containers and docker being

    prominent [20, 21]. They are less memory intensive and en-

    able of micro-services and require less storage. To enable self

    automation, deployment and scaling containers have also

    been scaled using technologies like Kubernetes or K8s. Pop-

    ular container technologies are explained in the following

    section.

    4.1

    LXC (Linux Containers)

    LXC (Linux Containers) enables operation system virtual-

    ization to execute several solitary Linux system containers

    positioned on controller hosts supported on a singular Linux

    kernel [25]. The kernel enables cgroups to allow limitation

    and priority of CPU, memory and network resources without

    starting up virtual machines . It enables namespace isolation

    and has mounted file systems as well as networking and

    process trees. Early versions of the Docker containers were

    based on LXC.

    4.2

    Docker

    Docker improves on LXC with kernel as well as APIs to

    enable processes execute in isolation with CPU processing

    unit, memory,input and output, network and other resources

    [13, 19, 26]. The Docker namespaces are used to isolate ap-

    plication views of base operating environment as well as

    file systems, user ids and process trees. The containers are

    created with images and an action happens when the image

    is being built. For docker images, each action command is

    above the prior action and execution of commands is maunal

    or systematically based on docker files with scripts of list

    of commands and arguments. Docker images can also be

    executed in virtual machines as well.

    4.3

    Differences between Containerization and

    Virtualization

    Some of the differences between containerization and virtu-

    alization include the fact containers run on host operating

    system and are normally combined with the kernel of the

    host OS and virtual machines run on hypervisor [10, 22, 23].

    For virtual machines like KVM there is full virtualization

    from hardware to the OS and docker is implemented on the

    cloud without guest OS and economic resources. and is ideal

    for micro-hosting services. Both technologies are used in

    cloud computing in IaaS cloud models and easier bundling of

    applications is achieved with docker containers and images

    [20, 21].

    Virtualization virtual machines are more preferred if its

    needed to create a secure system and for high availability

    and scalable system containers are used. Docker contain-

    ers focus on applications and dependencies whereas virtual

    machines introduce flexibility. and VMs provide better porta-

    bility, security and isolation and docker provide better SaaS

    for application and software portability to given users. The

    hypervisor and containers are compared in the following

    figure 3.

    Figure 3. Hypervisor compared to the container based vir-

    tual services [13]

    Hybrid options where both virtual machines and docker

    containers are used can give both benefits. Other difference

    icARTi ’21, December 9–10, 2021, Virtual Event, Mauritius

    Kennedy Chengeta

    include the following summary. The performance and vari-

    ances of the two approaches are summarized in the following

    table 1.

    Table 1. Comparisons of virtual machines and container

    systems

    Variance

    Virtual Machines

    Containers

    Operating System

    Need a guest

    Shared

    Booting Speed

    Slower than traditional machine

    Faster than VMs

    Standardization

    OS standards specific in nature

    Application specific in nature

    Portability

    Not very portable

    Faster and easily ported

    Servers needed

    Needs more

    Few servers

    Security

    Hypervisor defines security

    Security is shared

    Redundancy Level

    VM owns resources

    Shared OS so less redundancy

    Hardware Abstraction

    Hardware Abstracted

    Hardware access can be achieved

    Resources Sharing

    Huge resources needed

    Less resources needed and shared

    Memory

    Huge memory footprint

    Less memory footprint and shared

    Files sharing

    File sharing not possible

    File sharing possible

    5

    Performance of Docker Containers and

    Virtual Machines

    Various studies have been done to compare docker and vir-

    tual machines including the use of Cassandra dataset by

    Shrinibab. Key conclusions from the study include that con-

    tainers had lower overheads than VMWare virtualized ver-

    sion and the performance was as good as non virtualized

    versions. In [6, 17], the authors measured various central

    processing unit CPU power, disk storage intensive docker

    processes and the latter the found correlation of performance

    of cgroup file and the /proc file systems when workloads

    were increased on the CPU.

    Raho et al [26] compared KVM to Xen hypervisors using

    ARM architecture based docker containers andmade con-

    clusions that much improvments on performances on the

    loads resulted and networking for containers whilst hy-

    pervisors shows better disk I/O and TCP streaming per-

    formances.Zhang et al [26] compared performance of hy-

    pervisor based virtualization and container based in high

    performance computing. and the latter gave better perfor-

    mance results. Walters et al [25] used VMWare ESXi , KVM

    as well as Xen to open source LXC containers and achieved

    98 percent accuracy on base performance and virtual ma-

    chines ranging only 2 percentage points only. Kozhirbayev

    and Sinnott [13] compared the container based technologies

    in the cloud environment and the Ferreira [8] study com-

    pared Docker, Flockport (LXC) and VMs. Few studies have

    used machine learning to compare docker containers and vir-

    tual machines as big data analysis to see their performance

    and accuracy. Few studies have also compared bare metal

    against cloud environments to see the performance of the

    the two virtualization approaches

    5.1

    Kurbenetes and OpenShift

    Kubernetes is a popular open source deployment and scal-

    ing engine for management of container based deployments

    which in this cases are docker containers [5, 8, 9, 16]. The de-

    sign includes a pod as a unit of application. The pod houses

    at least one docker container which are grouped together

    using identical IP as well as physical or virtual storage. The

    cluster also has a master node and group of the worker nodes

    [7, 9, 16].

    The master node also called the control plane manages the

    issues in the cluser and also has the stcd, kube-apiserver,

    kube controller as well as kube scheduling component. The

    etcd is a storage repository for all configuration and cluster

    state data as shown in in the next figure with two worker

    nodes 4 pods and exposed using the API server in the master

    node. The frontend is the kubernetes API server to expose

    the kubernetes control plane. It is through which a client

    can communicate with the kubernetes system as shown in

    figure 4.

    Figure 4. Diagram showing Kubernetes architecture com-

    ponents [9]

    The unscheduled pods are assigned by the scheduler based

    on resource avaialability, session affinity configurations and

    the controller manages the cluster state machine for instance

    the replica quantities. Comparisons have been done in edge

    servers [7, 24], on managed services with containers [9] and

    for resource management in kubernetes [16]. The interaction

    with a cloud enviroment is shown in figure 5.

    Figure 5. Kubernetes cluser connected to a cloud provider

    like Azure or Amazon Web Services [5]

    Comparing the performance between Virtual Machines and Containers using deep learning
    credit models

    icARTi ’21, December 9–10, 2021, Virtual Event, Mauritius

    The docker swarm and open shift are other options [15] .

    The docker swarm hosts the containers virtually and uses the

    docker daemon for communication to scale to more hosts.

    Figure 6. Redhat openshift [15, 18]

    5.1.1

    Red Hat OpenShift infrastructure architecture.

    Redhat open shift uses infrastructure nodes based on kuber-

    netes architecture [14, 18] as shown in figure 6. The nodes

    will house the cluster services, log aggregation as well as

    metric and reporting information in some form of registry

    as well as network routing data [15].

    6

    Motivation of the Study

    Various studies have compared virtual machines and contain-

    ers for performance but the study offers a different approach

    of analysing deep learning machine big data algorithms on

    virtual machines and docker containers on Google Cloud

    Platform, Microsoft Azure and Amazon Web Services using

    EC2 instances as well as bare metal on premise hardware.

    The deep learning implementation uses the keras and ten-

    sorflow python implementation using credit data set. The

    approach was to classify the credit lending dataset for loan

    defaulting with two class attributes namely defaulting or not

    defaulting. The study also enhances the container technol-

    ogy by using a Kubernetes cluster to boost its performances

    based on the docker containers. The virtual machines used

    include KVM and Xen based hypervisors all with Ubuntu

    linux.

    7

    Methodology

    The study uses deep learning credit scoring data to predict de-

    faulting of Kaggle sourced data of home credit lending loans

    based on Convolution Neural Networks and CNN-RNN or

    recurrent neural networks. The classification experiments

    using deep learning are executed on the virtualized AWS,

    Azure, Google Cloud and OpenStack environments both on

    and off the cloud as well using different docker contain-

    ers like Amazon EC2 Container Service and Google Cloud

    Container. A java front-end to execute the deep learning

    classification is developed using Java and react web technol-

    ogy frameworks. Open source tools and cloud monitoring

    tools like Cloudwatch and cloud trail are used to monitor and

    measure the performance disk utilization, network latency,

    degradation, CPU usage and boot up times as well when

    there is an application which is resource intensive like deep

    learning is executing.

    The classification results are stored in an elastic search envi-

    ronment and a dashboard comparing the results using Kibana

    is created and compared. Because OpenStack supports both

    bare metal and virtual machines as well as container based

    The study will compare results from the three stack layers.

    OpenStack supports bare metal provisioning, virtual ma-

    chines and container based servers. Load testing and stress

    testing will also be applied using the home loans lending

    dataset on both virtual and container technologies. The Con-

    volutional Neural Networks algorithms were based on the

    Deep learning convolutional neural networks (CNN) imple-

    mented using keras and tensorflow . The date went through

    various training and testing and a series of convolution of

    layers with filters and kernels. With CNN, more than one

    convolution layers with different pooling and fully connected

    layers are used and is represented by the following equation

    𝑆(𝑖, 𝑗) = (𝐾 ∗ 𝐼)(𝑖, 𝑗) =

    Õ

    𝑚

    Õ

    𝑛

    𝐼 (𝑖 − 𝑚, 𝑗 − 𝑛)𝐾(𝑚,𝑛)

    (1)

    Convolutional networks are a breed of neural network based

    on convolution in the middle layers. and also represented in

    the following form for the input kernel.

    𝑖𝑛𝑝𝑢𝑡⊗𝑘𝑒𝑟𝑛𝑒𝑙 =

    𝑐𝑜𝑙𝑢𝑚𝑛𝑠

    Õ

    𝑣=0

    (

    𝑟𝑜𝑤𝑠

    Õ

    𝑤=0

    𝑖𝑛𝑝𝑢𝑡(𝑤−𝑎, 𝑣−𝑏)𝑘𝑒𝑟𝑛𝑒𝑙(𝑤, 𝑣))))

    (2)

    Thee deep learning approach used followed a Keras and

    TensorFlow architecture as follows where Keras is the high

    level language in python.

    Figure 7. Deep Learning with Keras and TensorFlow archi-

    tecture

    8

    Approach

    The comparison approach of the Virtual Machine and con-

    tainer based on the cloud solutions like Amazon Web Ser-

    vices, Microsoft Azure and Google Cloud and bare metal ap-

    proach. For monitoring tools like AppDynamics based agent,

    Jmeter and Elastic Search Kibana were used to monitor the

    icARTi ’21, December 9–10, 2021, Virtual Event, Mauritius

    Kennedy Chengeta

    performance of the study. The study used deep learning clas-

    sification approach by analysing credit data to predict loan

    defaulting for the performance assessment of the containers

    and virtual machine approaches and then based time and

    response times.

    Data: Preprocess Prosper and lending club deep data

    downloaded from Kaggle

    Result: Default/no default loan class attributes

    while For each virtual machine/container do

    1. Classify the training and test sets for Prosper

    and Lending Club;

    2. For each dataset in AWS, Microsoft Azure and

    Google cloud as well as bare metal

    3. Apply download the dataset and pre-process

    and classify;

    6. Measure the CPU usage, network bandwidth as

    well download speed for Docker and VMs

    End While’

    end

    Algorithm 1: Preprocess credit lending data for VM and

    Container comparisons

    8.1

    Deep Learning Dataset used for performance

    comparisons

    For the deep learning classification, the peer to peer credit

    lending dataset was used and included a mix of Prosper

    Lending and Lending Club datasets. The number of of ob-

    servations included around 40 000 observations for Lending

    club and 100 000 for Prosper Loan dataset. The implementa-

    tion was done in python and downloaded from the Kaggle

    dataset with the downloading of the Kaggle dataset also mea-

    sured for performance with the docker and virtual machines

    configured. Epochs of 500-1000 were used and the learning

    rate was base lined at 0.0001. A sample of the Lending Club

    dataset is shown below where the loan status was shown

    against different statuses and total payment done as shown

    in figure 8 For the Prosper Lending dataset the results are

    shown as follows and the data shows the loan borrowers and

    their prosper ratings as in figure 8.

    Figure 8. Prosper rates versus income range

    9

    Results Analysis

    Different results were measured including the following mea-

    sured on an Azure Cloud infrastructure based on running the

    peer to peer lending dataset on different containers as well

    as virtual machines showing the following response times.

    The confusion matrix for various classifiers are shown in the

    following two graphs in the following figure.

    Xen

    Kvm

    Docker

    LXC

    0

    10 000

    20 000

    30 000

    27 835

    27 387

    26 619

    27 388

    24 012

    24 699

    24 021

    24 376

    No Defaulting

    Defaulting

    Xen

    Kvm

    Docker

    LXC

    0

    10 000

    20 000

    30 000

    28 255

    29 318

    26 161

    25 250

    24 312

    25 649

    23 268

    22 238

    No Defaulting

    Defaulting

    Figure 9. Prosper and Lending Club on the first and subse-

    quent graph

    The previous graph in figure 9 show that bulk of results

    had no defaulting and both graphs used deep learning ap-

    proaches with same datasets hence the results were almost

    similar. The dataset used including use of 90 percent for train-

    ing at random and 10 percent classification which explains

    for the slight differences. The deep learning classification

    results given include the following showing the accuracy

    rate of 0.988 and 0.99 percent on the two credit peer to peer

    datasets.

    Figure 10. Keras and tensorflow

    The virtual machines used in the study include KVM and

    Xen and Docker containers were used for the comparisons

    with also configured in a kubernetes cluster. Microsoft Azure

    Cloud environment classification using the VMs and con-

    tainer results are shown below.

    Comparing the performance between Virtual Machines and Containers using deep learning
    credit models

    icARTi ’21, December 9–10, 2021, Virtual Event, Mauritius

    0

    100

    200

    300

    400

    500

    600

    700

    800

    900

    1,000

    Xen

    Docker

    LXC

    KVM

    BM

    Prosper Credit Data

    Small sample size

    0

    100

    200

    300

    400

    500

    600

    700

    800

    900

    1,000

    XenDocker

    LXC

    KVM

    BM

    Time Taken

    Lending Credit Data

    Small sample size

    Figure 11. Various datasets using Lending as well as Prosper

    Credit Dataset.

    AWS Cloud environment classification using the VMs

    and container results are shown below

    0

    100

    200

    300

    400

    500

    600

    700

    800

    900

    1,000

    Xen

    Docker

    LXC

    KVM

    BM

    Prosper Credit Data

    Large sample size

    0

    100

    200

    300

    400

    500

    600

    700

    800

    900

    1,000

    Xen

    Docker

    LXC

    KVM

    BM

    Time Taken

    Lending Credit Data

    Large sample size

    Figure 12. Various datasets using Lending as well as Prosper

    Credit Dataset.

    Google Cloud Platform classification using the VMs

    and container results are shown below

    0

    100

    200

    300

    400

    500

    600

    700

    800

    900

    1,000

    Xen

    Docker

    LXC

    KVM

    BM

    Prosper Credit Data

    Large sample size

    0

    100

    200

    300

    400

    500

    600

    700

    800

    900

    1,000

    Xen

    Docker

    LXC

    KVM

    BM

    Time Taken

    Lending Credit Data

    Large sample size

    Figure 13. Various datasets using Lending as well as Prosper

    Credit Dataset.

    9.1

    Comparing CPU, Disk Utilization and other

    factors for Virtual Machines and Docker

    Containers

    The following tables compared the booting time, network

    delay as well as data download and network delay for the 4

    different virtualization approaches based on the deep learn-

    ing dataset of Prosper Lending and Lending Club datasets

    for classifications.

    Table 2. lr=0.001 and Lending Club Dataset

    Function

    KVM

    Xen

    Docker

    Docker(Kuber)

    Booting Time sec

    x

    +0.040

    -0.400

    -0.350

    Network Delay ms

    x

    +0.623

    -0.412

    -0.611

    New VM Creation Time ms

    x

    +2.321

    -0.882

    -1.343

    CPU Ave Usage %

    x

    +0.070

    -0.060

    -0.110

    Dataset Download time(s)

    x

    +3.230

    -5.110

    -6.310

    Disk Utilization(%)

    x

    +0.050

    -0.080

    -0.090

    Memory Utilization(%)

    x

    +0.060

    -0.080

    -0.120

    For Prosper dataset, the following results show different

    comparison metrics the study used to do the comparisons

    showing booting time, network time and dataset download

    relative time where 𝑥 is the baseline value of the KVM rela-

    tive to the others.

    Table 3. lr=0.0001 and Prosper Dataset

    Function

    KVM

    Xen

    Docker

    Docker(Kuber)

    Booting Time sec

    x

    +0.020

    -0.500

    -0.650

    Network Delay ms

    x

    +0.345

    -0.234

    -0.465

    New VM Creation Time ms

    x

    +2.654

    -0.994

    -1.245

    CPU Ave Usage %

    x

    +0.060

    -0.050

    -0.090

    Dataset Download time(s)

    x

    +2.450

    -4.560

    -5.670

    Disk Utilization(%)

    x

    +0.040

    -0.030

    -0.050

    The results show better performance of the two datasets

    in the AWS and Google Cloud compared to the Azure cloud

    environments. The docker container technologies fared bet-

    ter than the two virtualized technologies KVM and Xen in

    all the three cloud environments used in the study. The boot-

    ing time for the AWS EC2, Google cloud virtual machines

    and Azure environments were averaged and the Xen took

    the longest to start-up with worst network delay of 0.345

    relative to the KVM and almost half a second less than the

    docker and docker on kubernetes cluster. The docker con-

    tainer showed better download times than KVM and Xen for

    both the Lending Club and Prosper credit datasets.

    10

    Conclusion

    Docker container was compared virtual machine (VM) and

    the results show that docker images take less memory and are

    faster compared to the virtual machines used in the study

    namely KVM and Xen. Different cloud platforms namely

    Google Cloud Platform, Amazon Web Services AWS plat-

    form as well as the Microsoft Azure platform were used in

    the performance comparisons. The best performance was

    witnessed in the Amazon AWS cloud environment. The study

    also concludes that enhancing the docker containers with

    Kubernetes increases the performance by few percentage

    points and reduces the delay as well as quickens deploy-

    ment time as well and reduced Quality of Service transaction

    speed. The study could have used GPU units or quantum

    computing hardware but this was discovered as prohibitive

    in terms of access and cost.

    icARTi ’21, December 9–10, 2021, Virtual Event, Mauritius

    Kennedy Chengeta

    References

    [1] Luca Abeni and Dario Faggioli. 2019. An experimental analysis of the

    xen and kvm latencies. In 2019 IEEE 22nd International Symposium on

    Real-Time Distributed Computing (ISORC). IEEE, 18–26.

    [2] Rabindra K Barik, Rakesh K Lenka, K Rahul Rao, and Devam Ghose.

    2016. Performance analysis of virtual machines and containers in

    cloud computing. In 2016 international conference on computing, com-

    munication and automation (iccca). 1204–1210. https://doi.org/10.1109/

    CCAA.2016.7813925

    [3] Rabindra K. Barik, Rakesh K. Lenka, K. Rahul Rao, and Devam Ghose.

    2016. Performance analysis of virtual machines and containers in

    cloud computing. In 2016 International Conference on Computing, Com-

    munication and Automation (ICCCA). 1204–1210. https://doi.org/10.

    1109/CCAA.2016.7813925

    [4] Rabindra K Barik, Rakesh K Lenka, K Rahul Rao, and Devam Ghose.

    2016. Performance analysis of virtual machines and containers in

    cloud computing. In 2016 international conference on computing, com-

    munication and automation (iccca). IEEE, 1204–1210.

    [5] Brendan Burns, Joe Beda, and Kelsey Hightower. 2019. Kubernetes: up

    and running: dive into the future of infrastructure. O’Reilly Media.

    [6] Emiliano Casalicchio and Vanessa Perciballi. 2017. Auto-scaling of

    containers: The impact of relative and absolute metrics. In 2017 IEEE

    2nd International Workshops on Foundations and Applications of Self*

    Systems (FAS* W). IEEE, 207–214.

    [7] Halim Fathoni, Chao-Tung Yang, Chih-Hung Chang, and Chin-Yin

    Huang. 2019. Performance comparison of lightweight kubernetes

    in edge devices. In International Symposium on Pervasive Systems,

    Algorithms and Networks. Springer, 304–309.

    [8] Wes Felter, Alexandre Ferreira, Ram Rajamony, and Juan Rubio. 2015.

    An updated performance comparison of virtual machines and linux

    containers. In 2015 IEEE international symposium on performance anal-

    ysis of systems and software (ISPASS). IEEE, 171–172.

    [9] Arnaldo Pereira Ferreira and Richard Sinnott. 2019. A performance

    evaluation of containers running on managed kubernetes services. In

    2019 IEEE International Conference on Cloud Computing Technology

    and Science (CloudCom). IEEE, 199–208.

    [10] Khasa Gillani and Jong-Hyouk Lee. 2020. Comparison of linux virtual

    machines and containers for a service migration in 5g multi-access

    edge computing. ICT Express 6, 1 (2020), 1–2.

    [11] Mohd Badrulhisham Ismail, Habibah Hashim, and Yusnani Mohd Yu-

    soff. 2017. Dynamics resource allocation via virtual machine for cloud

    computing: Statistical approach. In 2017 7th IEEE International Con-

    ference on System Engineering and Technopreneurship (ICE2T). 1–5.

    https://doi.org/10.1109/ICE2T.2017.8215984

    [12] Prashanth Jakkula. [n.d.]. Container Runtime Performance Evaluation

    of Kubernetes and OpenShift. ([n. d.]).

    [13] Zhanibek Kozhirbayev and Richard O Sinnott. 2017. A performance

    comparison of container-based technologies for the cloud. Future

    Generation Computer Systems 68 (2017), 175–182.

    [14] Endah Kristiani, Chao-Tung Yang, Yuan Ting Wang, and Chin-Yin

    Huang. 2018. Implementation of an edge computing architecture using

    openstack and kubernetes. In International Conference on Information

    Science and Applications. Springer, 675–685.

    [15] Nikhil Marathe, Ankita Gandhi, and Jaimeel M Shah. 2019. Docker

    swarm and kubernetes in cloud computing environment. In 2019 3rd In-

    ternational Conference on Trends in Electronics and Informatics (ICOEI).

    IEEE, 179–184.

    [16] Víctor Medel, Rafael Tolosana-Calasanz, José Ángel Bañares, Unai

    Arronategui, and Omer F Rana. 2018. Characterising resource manage-

    ment performance in Kubernetes. Computers & Electrical Engineering

    68 (2018), 286–297.

    [17] Roberto Morabito, Jimmy Kjällman, and Miika Komu. 2015. Hypervi-

    sors vs. lightweight virtualization: a performance comparison. In 2015

    IEEE International Conference on Cloud Engineering. IEEE, 386–393.

    [18] Stefano Picozzi, Mike Hepburn, and Noel O’Connor. 2017. DevOps

    with Openshift: Cloud deployments made easy. " O’Reilly Media, Inc.".

    [19] Moritz Raho, Alexander Spyridakis, Michele Paolino, and Daniel Raho.

    2015. KVM, Xen and Docker: A performance analysis for ARM based

    NFV and cloud computing. In 2015 IEEE 3rd Workshop on Advances in

    Information, Electronic and Electrical Engineering (AIEEE). IEEE, 1–8.

    [20] Tasneem Salah, M Jamal Zemerly, Chan Yeob Yeun, Mahmoud Al-

    Qutayri, and Yousof Al-Hammadi. 2017. Performance comparison

    between container-based and VM-based services. In 2017 20th Con-

    ference on Innovations in Clouds, Internet and Networks (ICIN). IEEE,

    185–190.

    [21] Kyoung-Taek Seo, Hyun-Seo Hwang, Il-Young Moon, Oh-Young Kwon,

    and Byeong-Jun Kim. 2014. Performance comparison analysis of linux

    container and virtual machine for building cloud. Advanced Science

    and Technology Letters 66, 105-111 (2014), 2.

    [22] Prateek Sharma, Lucas Chaufournier, Prashant Shenoy, and YC Tay.

    2016. Containers and virtual machines at scale: A comparative study.

    In Proceedings of the 17th International Middleware Conference. 1–13.

    [23] Cristian Constantin Spoiala, Alin Calinciuc, Corneliu Octavian Turcu,

    and Constantin Filote. 2016.

    Performance comparison of a We-

    bRTC server on Docker versus virtual machine. In 2016 International

    Conference on Development and Application Systems (DAS). 295–298.

    https://doi.org/10.1109/DAAS.2016.7492590

    [24] Salman Taherizadeh and Marko Grobelnik. 2020.

    Key influenc-

    ing factors of the Kubernetes auto-scaler for computing-intensive

    microservice-native cloud-based applications. Advances in Engineer-

    ing Software 140 (2020), 102734.

    [25] John Paul Walters, Andrew J Younge, Dong In Kang, Ke Thia Yao,

    Mikyung Kang, Stephen P Crago, and Geoffrey C Fox. 2014. GPU

    passthrough performance: A comparison of KVM, Xen, VMWare ESXi,

    and LXC for CUDA and OpenCL applications. In 2014 IEEE 7th inter-

    national conference on cloud computing. IEEE, 636–643.

    [26] Jie Zhang, Xiaoyi Lu, and Dhabaleswar K Panda. 2016. Performance

    characterization of hypervisor-and container-based virtualization for

    HPC on SR-IOV enabled InfiniBand clusters. In 2016 IEEE International

    Parallel and Distributed Processing Symposium Workshops (IPDPSW).

    IEEE, 1777–1784.

    '
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: https://dl.acm.org/doi/pdf/10.1145/3487923.3487934
  publication_year: 2021
  relevance_score1: 0
  relevance_score2: 0
  title: Comparing the performance between Virtual Machines and Containers using deep
    learning credit models
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.30534/ijatcse/2020/166942020
  analysis: '>'
  authors:
  - Manish Kumar Abhishek
  citation_count: 2
  full_citation: '>'
  full_text: '>'
  inline_citation: '>'
  journal: International journal of advanced trends in computer science and engineering
  limitations: '>'
  pdf_link: null
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: Containerization for shipping Scientific Workloads in Cloud
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'

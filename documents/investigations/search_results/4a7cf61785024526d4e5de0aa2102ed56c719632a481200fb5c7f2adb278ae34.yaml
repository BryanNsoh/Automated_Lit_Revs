- analysis: '>'
  authors:
  - Kethineni K.
  - Pradeepini G.
  citation_count: '3'
  description: Smart agriculture is a popular domain due to its intensified growth
    in recent times. This domain aggregates the advantages of several computing technologies,
    where the IoT is the most popular and beneficial. In this work, a novel and effective
    deep learning-based framework is developed to detect intrusions in smart farming
    systems. The architecture is three-tier, with the first tier being the sensor
    layer, which involves the placement of sensors in agricultural areas. The second
    tier is the Fog Computing Layer (FCL), which consists of Fog nodes, and the proposed
    IDS is implemented in each Fog node. The gathered information is transferred to
    this fog layer for further data analysis. The third tier is the cloud computing
    layer, which provides data storage and end-to-end services. The proposed model
    includes a fused CNN model with the bidirectional gated recurrent unit (Bi-GRU)
    model to detect and classify intruders. An attention mechanism is included within
    the BiGRU model to find the key features responsible for identifying the DDoS
    attack. In addition, the accuracy of the classification model is improved by using
    a nature-inspired meta-heuristic optimization algorithm called the Wild Horse
    Optimization (WHO) algorithm. The last layer is the cloud layer, which collects
    data from fog nodes and offers storage services. The proposed system will be implemented
    in the Python platform, using ToN-IoT and APA-DDoS attack datasets for assessment.
    The proposed system outperforms the existing methods in accuracy (99.35%), detection
    rate (98.99%), precision (99.9%) and F-Score (99.08%) for the APA DDoS attack
    dataset and the achieved accuracy of the ToN-IoT dataset (99.71%), detection rate
    (99.02%), precision (99.89%) and F-score (99.05%).
  doi: 10.1007/s10586-023-04052-4
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Log in Find a journal Publish
    with us Track your research Search Cart Home Cluster Computing Article Intrusion
    detection in internet of things-based smart farming using hybrid deep learning
    framework Published: 03 June 2023 Volume 27, pages 1719–1732, (2024) Cite this
    article Download PDF Access provided by University of Nebraska-Lincoln Cluster
    Computing Aims and scope Submit manuscript Keerthi Kethineni & G. Pradeepini  339
    Accesses 3 Citations Explore all metrics Abstract Smart agriculture is a popular
    domain due to its intensified growth in recent times. This domain aggregates the
    advantages of several computing technologies, where the IoT is the most popular
    and beneficial. In this work, a novel and effective deep learning-based framework
    is developed to detect intrusions in smart farming systems. The architecture is
    three-tier, with the first tier being the sensor layer, which involves the placement
    of sensors in agricultural areas. The second tier is the Fog Computing Layer (FCL),
    which consists of Fog nodes, and the proposed IDS is implemented in each Fog node.
    The gathered information is transferred to this fog layer for further data analysis.
    The third tier is the cloud computing layer, which provides data storage and end-to-end
    services. The proposed model includes a fused CNN model with the bidirectional
    gated recurrent unit (Bi-GRU) model to detect and classify intruders. An attention
    mechanism is included within the BiGRU model to find the key features responsible
    for identifying the DDoS attack. In addition, the accuracy of the classification
    model is improved by using a nature-inspired meta-heuristic optimization algorithm
    called the Wild Horse Optimization (WHO) algorithm. The last layer is the cloud
    layer, which collects data from fog nodes and offers storage services. The proposed
    system will be implemented in the Python platform, using ToN-IoT and APA-DDoS
    attack datasets for assessment. The proposed system outperforms the existing methods
    in accuracy (99.35%), detection rate (98.99%), precision (99.9%) and F-Score (99.08%)
    for the APA DDoS attack dataset and the achieved accuracy of the ToN-IoT dataset
    (99.71%), detection rate (99.02%), precision (99.89%) and F-score (99.05%). Similar
    content being viewed by others Deep Learning: A Comprehensive Overview on Techniques,
    Taxonomy, Applications and Research Directions Article 18 August 2021 An improved
    fire detection approach based on YOLO-v8 for smart cities Article Open access
    28 July 2023 AI-big data analytics for building automation and management systems:
    a survey, actual challenges and future perspectives Article Open access 15 October
    2022 1 Introduction The agricultural region plays a dynamic role in the country’s
    financial growth and is one of the most crucial food providers. To meet the demands,
    the Food and Agriculture Organization (FAO) of the United Nations states that
    worldwide food productivity must reach 70% by 2050 [1]. Even though the current
    productivity rate is capable of meeting the demands, a report claimed that about
    500 million people across the globe suffer from malnutrition. In comparison, around
    821 million people go hungry [2]. It is also estimated that the global population
    has increased to 2 billion. The most of the population growth is seen in countries
    like India, Nigeria, Ethiopia, Pakistan, Egypt, the Democratic Republic of Congo,
    the United States, Indonesia and the United Republic of Tanzania [3]. It might
    also be problematic to meet the water demands of 40% by 2030, and arable land
    destruction impacts the overall food supply. Therefore, many sustainable systems
    and resources must obtain higher productivity levels to meet increasing demands
    worldwide [4, 5]. Increasing productivity requires advancements in cultivation
    practices and the adaptability of several technologies to provide crucial knowledge
    about the farm fields to take appropriate actions. Integrating novel and innovative
    technologies to optimize irrigation is termed smart farming or precision farming
    [6, 7]. The technological integration provides more information regarding the
    fields and plants to enhance the irrigation procedure and to obtain optimal outcomes
    [8]. This information includes the presence of pests in the crops, the water requirement
    for the plants, the area needed to achieve higher production, resources required
    to control pests, the number of fertilizers needed, etc. All these can be achieved
    by adapting prediction technologies, measurements of the environment and tools
    of automation [9, 10]. This combination can escalate agricultural production to
    several extents without requiring huge amounts of natural resources. Smart farming
    integrates several technologies, protocols, computing paradigms and devices to
    empower the farmers to gather and understand most details regarding the farm fields
    [11, 12]. Since integrating technologies in smart farming offers undeniable benefits
    to farmers, this integration comes with many difficulties and complexities [13].
    Among those challenges, the most terrifying is intrusions intentionally introduced
    into embedded technologies to gain access to the accumulated data. Most security
    challenges are due to the systems’ vulnerability in smart farming and their contained
    power [14, 15]. Technologies like artificial intelligence (AI), machine learning
    (ML), deep learning (DL), etc., were used for the effective removal of challenges
    like resource wastage and shortage of food [16]. Data features are very important
    for the accurate classification of IoT attacks. In existing works, different statistical
    features are extracted for the IoT attack prediction using machine learning techniques
    [17]. Furthermore, an essential features such as correlation based feature metrics
    [18], and wrapper based feature selection [19] are selected in the existing works.
    The main advantages of IoT-based smart agriculture are labour cost reduction,
    water and electricity conservation, and the farmers can keep a record of their
    yield [20]. The devices included in the fields collect crucial data regarding
    the farm fields and transmit them to the servers for storage. During data transfer
    to a destination, there is a higher possibility of security attacks requiring
    quick fixes [21]. The most common attack in smart farming is the distributed denial
    of service (DDoS) attack, which can generate fake traffic on the network. This
    attack intensifies by compromising multiple devices in the network to generate
    fake traffic to overwhelm the network [22, 23]. Therefore, this paper focuses
    on developing an effective intrusion detection system (IDS) that can accurately
    detect and classify the DDoS attack on the network. Smart agriculture is a popular
    domain due to its intensified growth in recent times. This domain aggregates the
    advantages of several computing technologies, where the IoT is the most popular
    and beneficial. The IoT system places sensors on agricultural fields to collect
    important data regarding crops and fields to improve the overall productivity
    rate. While transmitting the sensed data from fields to the destination, there
    is a possibility of occurrence of cyber-attacks that intruders design to gain
    access to the contents being transmitted. If the equipment installed in the field
    increases the production loss, it will be a serious issue. The main objectives
    of the proposal are as follows: Designing a new and effective deep hybrid learning-based
    IDS framework for smart farming applications. The work considers a 3-tier architecture,
    where the sensing layer contributes to the agricultural fields on which the sensors
    are located, the fog computing layer (FCL), where the IDS framework is deployed
    and the cloud computing layer for storage. A hybridization of deep learning named
    Fused and Optimized CNN-BiGRU (FOCB) with the metaheuristic optimization algorithm
    called Wild Horse Optimization (WHO) is explored to gain significant improvements
    in classification accuracy. The significance of features representing DDoS attacks
    is further enhanced by adding an attention mechanism at the end of a BiGRU model.
    The following sections are structured as follows: Sect. 2 explains the related
    works on IDSs. Section 3 underlines the proposed IDS procedure. Section 4 evaluates
    the results and discussion. The conclusion of the work is explained in Sect. 5.
    2 Related work Some of the recent and effective IDS frameworks contributing to
    security in smart farming are discussed below: Smart farming embeds advanced computing
    technologies with general farming operations to enhance performance and improve
    the overall production rate. With the convergence of the IoT with the smart farming
    scenario, farming operations have achieved considerable improvement. Since IoT
    devices are placed directly on the fields, many threats are encountered that require
    prompt solutions to be protected from cyber-attacks. One methodology has been
    declared by Ferrag et al. [24] to depend on the integration of IoT with smart
    farming, where the IDS was developed to protect the data from DDoS attacks. The
    system model included a sensing layer, FCL and the cloud layer. The sensors in
    the sensing layer captured the data from fields and forwarded it to fog nodes
    where the IDS framework detected the DDoS attacks. The IDS framework was developed
    using three DL models: Deep Neural Network (DNN), CNN and Recurrent Neural Network
    (RNN), each trained on the data sets for classification. The results proved the
    performance of the model compared to previous work. Another methodology for IDS
    to secure the data from agricultural fields was introduced by Raghuvanshi et al.
    [25]. The IoT sensors were placed on the fields in the methodology to collect
    agricultural data. The NSL-KDD dataset was utilized as the input to the framework,
    where initially, pre-processing was carried out by converting all the symbolic
    features into numeric features. Following this step, feature extraction was performed
    using the principal component analysis (PCA) technique. The classification was
    performed using machine learning methods such as Random Forest (RF), Support Vector
    Machine (SVM) and Linear Regression (LR). The methodology was compared to other
    ML methods to demonstrate the increased performance. The technologies used in
    smart agriculture are effective instruments capable of generating temporal, spatial
    and time-series data streams collected from fields. These generated data must
    be protected from adversarial attacks to enhance agricultural productivity. Moso
    et al. [26] introduced an ensemble anomaly detector called Enhanced Local Selective
    Combination in Parallel Outlier Ensembles (ELSCP) to accomplish the task. A data-driven
    unsupervised methodology was presented and applied to two case studies. One dealt
    with a global positioning system (GPS) traces; the other dealt with crop data.
    While dealing with the crop data, the ELSCP framework predicted the crop’s state
    and detected anomalies present in the data. The experimental outcomes of the model
    proved that the model was capable of accurately identifying the anomalies related
    to crop damage. Establishing a smart farm includes several types of equipment
    operated to achieve certain functionality. Anomalies in such equipment decrease
    the reliability of smart farms and cause various troubles. A method to solve the
    above issue was introduced by Park et al. [27], integrating the deep learning
    technique. The technique was established to secure pig house equipment and enhance
    livestock management. The data accumulated in the equipment, such as the environmental
    factors, were used for training. The RNN model was utilized in the method for
    training and classification purposes. Environmental factors such as temperature,
    ventilation, CO2, humidity, external and radiator temperatures are used for training.
    The method provided better and correct outcomes related to other current mechanisms.
    The main intention of developing the precision farming system is to reduce the
    burden on farmers and increase the overall net productivity. To achieve this,
    the agricultural sector embeds multiple devices labeled with specific objectives.
    One such piece of equipment only provides water to the agricultural field when
    needed. Thakur et al. [28] introduced a methodology for intrusion identification,
    where several sensors were utilized to obtain the data. The method also focused
    on detecting field intrusions before the captured data was forwarded to cloud
    servers. The methodology utilized and monitored soil data, detecting different
    forms of intrusions in the fields. The effectiveness of the approach was proved
    through experiments. Several IDS methodologies are proposed in the literature
    to accurately detect and classify the attacks to transmit the data securely. Deep
    learning-based techniques flourished among the introduced methodologies due to
    their excellent learning capacity. However, the existing techniques suffer from
    various issues, such as poor data quality, overfitting, training data underfitting,
    non-representative and insufficient training data. All these problems must be
    resolved efficiently to improve the overall growth of agriculture. 3 Proposed
    methodology The proposed smart farming architecture is comprised of 3 layers are
    sensor layer, fog layer and cloud computing layer. In agricultural layer, drones
    and other IoT devices are used to track data about the agricultural environment.
    When the data fulfil certain criteria, actuators in the agricultural sensors layer
    are turned on. In order to provide energy for IoT devices, new energy technologies
    and smart grid design are integrated into the layer of agricultural sensors. In
    fog computing layer, a deep learning-based intrusion detection system is installed
    in each fog node. Agricultural sensors feed IoT data straight to the fog computing
    layer for analysis and ML algorithms, while in cloud computing layer, cloud computing
    nodes handle the storage and end-to-end services. The fog nodes are where the
    calculations for intrusion detection systems based on deep learning are done.
    The efficiency of the agri-food supply chain, food safety, and agricultural production
    may all be impacted by a gang of attackers who perform DDoS assaults in an effort
    to disrupt network operations. The proposed model includes label encoding and
    data normalization for pre-processing and a fused model of bidirectional gated
    recurrent unit (Bi-GRU) with a CNN model to detect and classify the intrusions.
    An attention mechanism is included within the BiGRU model to find the key features
    responsible for identifying the DDoS attack. Further, the model classification
    accuracy is improved using a nature-inspired meta-heuristic optimization algorithm
    called the WHO algorithm. The last layer is the cloud layer, which collects data
    from fog nodes and offers storage services. Figure 1 shows the proposed methodology.
    Fig. 1 Suggested methodology Full size image 3.1 The BiGRU-CNN-based IDS The ToN-IoT
    dataset and the APA-DDoS-Attack dataset are used as input data to detect DDoS
    attacks in the IDS. Several attacks are included in the dataset used, and the
    proposed IDS is used to identify the DDoS attack from the dataset. The BiGRU-CNN
    IDS contains 5 layers: input layer, BiGRU layer, attention layer, convolution
    layer and output layer. 3.1.1 Input layer Data from the ToN-IoT dataset and APA-DDoS-Attack
    dataset are first pre-processed. The pre-processing section contains label encoding
    and data normalization. In label encoding, non-numerical data are converted to
    numerical values. The categorical features were converted to numerical values
    using the label encoder. The label encoding technique converted every definite
    value in the dataset to a number. The min–max method is the next data normalization
    process that allows the values to fall within the same range. To normalize data
    in the range 0 and 1, the expression used is, $$\\overline{Z} = \\frac{Z - \\min
    }{{\\max - \\min }}$$ (1) where \\(Z\\) and \\(\\overline{Z}\\) are real and normalized
    data, respectively, \\(\\min\\) is the minimum and \\(\\max\\) is maximum values.
    3.1.2 BiGRU layer A sequence-processing model called BiGRU consists of two GRUs.
    One GRU receives input in the forward direction, the other in the reverse direction.
    The GRU is a modified version of the RNN. Reduced computational cost, training
    efficiency and simpler structure are the main advantages of GRU. The design of
    the BiGRU model is depicted in Fig. 2. Fig. 2 Structure of BiGRU Full size image
    Equation (2) defines the GRU’s underlying computation method, $$\\left\\{ \\begin{gathered}
    r_{t} = \\sigma \\left( {X_{r} y_{t} + V_{r} k_{t - 1} } \\right) \\hfill \\\\
    z_{t} = \\sigma \\left( {X_{z} y_{t} + V_{z} k_{t - 1} } \\right) \\hfill \\\\
    \\overset{\\lower0.5em\\hbox{$\\smash{\\scriptscriptstyle\\smile}$}}{k}_{t} =
    \\tanh (X_{{\\overset{\\lower0.5em\\hbox{$\\smash{\\scriptscriptstyle\\smile}$}}{h}
    }} y_{t} + V_{{\\overset{\\lower0.5em\\hbox{$\\smash{\\scriptscriptstyle\\smile}$}}{h}
    }} (r_{t} \\Theta k_{t - 1} )) \\hfill \\\\ k_{t} = (1 - z_{t} )\\Theta k_{t -
    1} + z_{t} \\Theta k_{t} \\hfill \\\\ \\end{gathered} \\right.$$ (2) The sigmoid
    activation function \\(\\sigma\\) converts intermediate states to the range [0,1],
    \\(k_{t - 1}\\) and \\(k_{t}\\) are the outputs at the time \\(t - 1\\) and \\(t\\),
    respectively. \\(y_{t}\\) is the input arrangement value at the time \\(t\\).
    The output state is \\(\\overset{\\lower0.5em\\hbox{$\\smash{\\scriptscriptstyle\\smile}$}}{k}_{t}\\);
    \\(r_{t}\\) and \\(z_{t}\\) are the reset and update gates; \\(X_{r} ,\\,\\,X_{z}
    ,\\,X_{{\\overset{\\lower0.5em\\hbox{$\\smash{\\scriptscriptstyle\\smile}$}}{h}
    }} ,\\,\\,V_{r} ,\\,V_{Z}\\) and \\(\\,V_{{\\overset{\\lower0.5em\\hbox{$\\smash{\\scriptscriptstyle\\smile}$}}{h}
    }}\\) are the coefficient matrices of the weight in every part; tanh is a hyperbolic
    tangent function and \\(\\Theta\\) is the element-wise multiplication. The output
    \\(k_{t}\\) of each time step \\(t\\) contains two vectors from forward propagation
    \\(\\vec{k}_{t}\\) and backward propagation \\(\\mathop{k}\\limits^{\\leftharpoonup}
    _{t}\\), \\(H_{t} = [\\vec{k}_{t} \\,,\\,\\mathop{k}\\limits^{\\leftarrow} _{t}
    ]\\). 3.1.3 Attention layer To strengthen the performance of the IDS, an attention
    mechanism is added to the output of a BiGRU layer. The most crucial features responsible
    for IDS are selected using the attention mechanism to identify the DDoS attack.
    The attention mechanism introduces a weight coefficient according to the importance
    of identifying the important features for selecting a DDoS attack. The calculation
    process is shown in Eq. (3), $$\\alpha_{1} = soft\\max (w_{3} \\tanh (W_{3} H^{T}
    + b_{3} ))$$ (3) $$f_{t} = \\sum\\limits_{i = 1}^{T} {\\alpha_{1}^{t} .H_{t} }$$
    (4) The output from the BiGRU model after the attention mechanism is given to
    the convolution layer. 3.1.4 Convolution layer Multiple convolution kernels are
    used in the convolution layer to extract deeper features in the intrusion detection
    system. This layer includes convolution and pooling layers different from other
    neural networks. For the BiGRU-CNN-based IDS, 3 different convolution kernels
    are used, using maximum pooling to extract the important features. The convolution
    kernel is related to weight and bias vectors. The nth kernel at position (i,j)
    in the mth layer calculates the feature value \\(x_{i,j,n}^{m}\\). $$x_{i,j,n}^{m}
    = f\\left( {W_{n}^{{m^{T} }} x_{i,j}^{m - 1} + b_{n}^{m} } \\right)$$ (5) where,
    \\(x_{i,j}^{m - 1}\\) is the input patch for the \\((m - 1)^{th}\\) layer, centred
    at the position \\((i,j)\\). The nth kernel filter’s weight (\\(W\\)) and bias
    (\\(b\\)) terms, respectively in \\(m^{th}\\) layer. The pooling layer is used
    to minimize the dimensions and increase robustness. The pooling method that determines
    the maximum value in the pooling windows uses Max Pooling in the pooling layer.
    3.1.5 Output layer The output of the convolution layer is sent to the fully linked
    layer of the output layer. The outcome of the convolution layer is given to the
    softmax classifier, where the softmax function is used for identifying the DDoS
    attack. The mathematical expression for the softmax function is, $$z_{l} = soft\\max
    (vZ + c)$$ (6) where \\(c\\) is the bias, \\(v\\) is the weight coefficient matrix,
    and \\(z_{l}\\) is the attained output that is the DDoS attack. 3.1.6 Parameter
    tuning using wild horse optimization To optimally tune the bias and weight parameter
    and thereby reduce the classification error rate, the WHO algorithm is aimed,
    which improves the accuracy of detecting DDoS attacks. In WHO, the social behaviour
    of wild horses is considered for an optimal selection of parameters, which improves
    detection accuracy. Initially, the population is divided into groups, which \\(H\\)
    symbolizes the number of different attacks and \\(M\\) represents the total number
    of system attacks. The number of stallions equals \\(H\\), since each group has
    a leader, and \\(MH\\) represents the population of foals and mares scattered
    in this group. $$Y_{j,H}^{i} = 2X\\cos (2\\pi SX) \\times (stlan^{i} - Y_{j,H}^{i}
    ) + stlan^{i}$$ (7) \\(Y_{j,H}^{i}\\) denotes the current position of the mare
    or foal group member, \\(stlan\\) gives the location of the stallion, \\(S\\)
    has a stochastic value in the interval -2 to 2 and \\(X\\) denotes the adaptive
    model projected as, $$\\begin{gathered} R = \\vec{T}_{1} \\, < TDR;\\,\\,\\,\\,IDX
    = (p = = 0) \\hfill \\\\ X = T_{2} \\Theta IDX + \\vec{T}_{3} \\Theta ( \\approx
    IDX) \\hfill \\\\ \\end{gathered}$$ (8) where,\\(R,\\vec{T}_{1} \\,,\\vec{T}_{3}
    \\,and\\,T_{2}\\) has an arbitrary value in the range of [0, 1]. The value of
    TDR reduces to 0 at the end of iteration starting from 1 given as, $$TDR = 1 -
    it \\times \\left( {\\frac{1}{\\max it}} \\right)$$ (9) The maximal iteration
    is represented as \\(\\max it\\). The crossover operator is used to simulate horse
    mating behaviour: $$\\begin{gathered} Y_{H,K}^{R} = Crossover\\left( {Y_{{H,j^{\\prime}}}^{q}
    ,\\,Y_{H,i}^{X} } \\right)\\,\\,\\,\\,j \\ne i \\ne k,q = p = end, \\hfill \\\\
    \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,Crossover = Mean \\hfill \\\\
    \\end{gathered}$$ (10) The group leader struggles a lot for the water hole, and
    the others should wait till the dominant group leaves the water hole: $$\\overline{{Stlan_{{H_{j}
    }} }} = \\,\\,T\\left\\{ \\begin{gathered} 2X\\cos \\left( {2\\pi SX} \\right)
    \\times (WH - Stlan_{{H_{j} }} ) \\hfill \\\\ \\,\\, + WH\\,\\,if\\,\\,T_{3} >
    0.5 \\hfill \\\\ 2X\\cos (2\\pi SX) \\times (WH - stlan_{{H_{j} }} ) \\hfill \\\\
    \\,\\,\\, - WH\\,\\,if\\,\\,T_{3} \\le 0.5 \\hfill \\\\ \\end{gathered} \\right.$$
    (11) \\(WH\\) is the location of water hole, and the leader who finds the location
    is represented as \\(\\overline{{Stlan_{{H_{j} }} }}\\). Based on the fitness
    value, the leader is selected in the next phases, and the leader’s position and
    the selected member are indicated as follows: $$\\overline{{Stlan{}_{{H_{j} }}}}
    = \\left\\{ \\begin{gathered} Y_{H,j} \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,if\\,\\,\\,\\,\\,\\,\\cos
    \\,\\,t(Y_{H,j} )\\,\\, < \\,\\,\\cos \\,\\,t(Stlan_{{H_{j} }} ) \\hfill \\\\
    Stlan_{{H_{j} }} \\,\\,\\,\\,if\\,\\,\\,\\,\\,\\,\\cos \\,\\,t(Y_{H,j} )\\,\\,
    > \\,\\,\\cos \\,\\,t(Stlan_{{H_{j} }} ) \\hfill \\\\ \\end{gathered} \\right.$$
    (12) The fitness function used in WHO is the classification error rate, and the
    goal of WHO algorithm is to minimize the classification error rate. The flow chart
    of the proposed WHO is shown in Fig. 3, $$\\begin{gathered} fitness(y_{i} ) =
    classificationerrorrate(y{}_{i}) \\hfill \\\\ \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,
    = \\frac{count\\,\\,of\\,\\,misidentified\\,\\,attacks}{{total\\,\\,number\\,\\,of\\,\\,attacks}}*100
    \\hfill \\\\ \\end{gathered}$$ (13) Fig. 3 Flowchart of WHO Full size image The
    suggested system helps to detect intrusions in smart farming systems with better
    performance. It mainly detects DDoS and DoS attacks. 4 Results and discussion
    This section analyses the effectiveness of suggested IDS using different performance
    metrics. The evaluation metrics used for the analysis are accuracy, precision,
    detection rate, F-measure, ROC and confusion matrix. The experimental analysis
    of the proposed methodology is performed in the working platform of PYTHON, Anaconda,
    spyder (Tensorflow packages), Intel i5 processor, 64-bit operating system (OS)
    and 8 GB RAM CPU. The proposed methodology is analyzed with two datasets: APA-DDoS
    attack and ToN-IoT. The experimental setup of hyperparameters in deep learning
    is given in Table 1. Table 1 Simulation details of hyperparameters Full size table
    4.1 APA-DDoS attack dataset The APA-DDoS Attack dataset comprised three different
    types of data: DDos-PSH-ACK type, Benign type and DDos-ACK type. The total number
    of data samples in the dataset is 151,201 data samples. The total data samples
    are split into 70 and 30% for training and testing, respectively. As the connection
    between devices increased, the major challenge was detecting attacks, for an intrusion
    detection system (IDS) was developed. Machine learning techniques have been developed
    to find the attacks which need access to attack patterns. The APA-DDoS attack
    contains different types of DDoS attacks. The dataset holds mainly ACK and PUSH-ACK
    DDoS attacks [29]. To improve the detection rate, the APA-DDoS attack dataset
    was used. 70% of the dataset is used for training, while 30% is used for testing.
    4.2 ToN-IoT dataset The RoN-IoT dataset consists of six types of data samples
    such as DoS, Normal, DDoS, Injection, Mitm and password types. The total number
    of data samples in the dataset is 140,113 samples. Moreover, the total data is
    categorized into 70% and 30% for training and testing processes. Telemetry datasets
    of Internet of things (IoT) and Industrial IoT (IIoT) sensors are included in
    the ToN-IoT dataset and split into 70% and 30% for training and testing sets.
    The dataset is allocated in the ratio of 70:30 for training and testing. The dataset
    contains 43 features with 9 types of attacks and a normal vector. Attacks in IoT
    environments like Backdoor, MITM, DDoS, DoS, Injection, Password, Scanning, XSS
    and Ransomware are included in the dataset. The ToN-IoT Dataset is the newest
    testbed for an IoT system that comprises 3 categories: operating systems data,
    network data and telemetry data. 4.3 Evaluation metrics In estimating the suggested
    IDS, the chosen performance metrics play a vital role. The evaluation metrics
    selected for the estimation are Accuracy, Precision, Detection rate, F-score,
    and Area under the curve (AUC). 4.3.1 Accuracy It is the ratio of accurately categorized
    instances to the total number of considered instances in the test set. It considers
    both true positive and true negative instances for the calculation. The accuracy
    performance evaluation is performed by the subsequent Eq. (14). $$Accuracy = \\frac{TP
    + TN}{{TN + TP + FP + FN}}$$ (14) where, \\(TP\\) represents the true positive,
    \\(TN\\) represents the true negative, \\(FP\\) represents the false positive,
    and \\(FN\\) represents the false negative. 4.3.2 Detection rate The detection
    rate is the ratio of the number of attacks predicted by the proposed framework
    to the total number of attacks in the testing data. It is calculated by the following
    condition (15). $$Detection\\,\\,Rate/\\,{\\text{Re}} call = \\frac{TP}{{TP +
    FN}}$$ (15) 4.3.3 Precision The precision measure is defined as the ratio of the
    total number of predicted attacks to the total number of instances classified
    as an attack. The precision measure is computed through the subsequent Eq. (16).
    $$\\Pr ecision = \\frac{TP}{{FP + TP}}$$ (16) 4.3.4 F-measure The weighted mean
    of precision and recall calculates the F-measure. The F-measure performance validation
    is more important and computed based on the false positive and false negative.
    It is generally utilized when the class distribution is imbalanced. The F-measure
    computation is expressed in the subsequent Eq. (17). $$F - measure = 2*\\frac{{{\\text{Re}}
    call*\\Pr ecision}}{{\\Pr ecision + {\\text{Re}} call}}$$ (17) 4.3.5 AUC The AUC
    performance metric estimates the probability of selecting positive over negative
    instances. The AUC calculation is expressed in the subsequent Eq. (18). $$auc
    = \\frac{1}{2}\\left( {\\frac{TP}{{TP + FP}} + \\frac{TN}{{TP + FP}}} \\right)$$
    (18) Here, \\(auc\\) represents the AUC measure. 4.4 Performance analysis based
    on APA-DDoS attack This section compares the performance of the proposed IDS to
    other current approaches [30] in terms of recall, accuracy, F-measure and precision.
    For the analysis, the APA-DDoS Attack dataset is utilized. The comparison analysis
    of different performance metrics is given in Table 2. Table 2 Comparison analysis
    of Accuracy, Precision, F-measure and Detection rate for APA-DDoS Attack dataset
    Full size table Table 2 gives a comparative analysis of the proposed system with
    current methods. The proposed system’s detection rate, precision, accuracy, and
    F-measure are compared with the existing methods for the APA-DDoS attack dataset.
    The confusion matrix (CM) of the APA-DDoS attack dataset is shown in Fig. 4. The
    CM compares the values predicted by the suggested system with the original target
    values. Fig. 4 Confusion matrix of APA-DDoS attack dataset Full size image The
    suggested system achieved a good performance in terms of accuracy with 99.35%.
    Figure 5 gives an accurate performance analysis of the suggested and existing
    methods. Fig. 5 Performance Analysis of Accuracy Full size image Figure 6 gives
    the performance evaluation in terms of the detection rate of the suggested system
    with numerous present methods. The suggested system attained a 98.99% detection
    rate, while the existing methods achieved only 77.85% for DT, 63.8% for NB, 94.12%
    for SLSTM and 76.62% for RF. So the suggested system outperformed in terms of
    the detection rate. Fig. 6 Performance Analysis Detection Rate Full size image
    Figure 7 gives the performance evaluation in terms of the F-measure of the suggested
    system with various existing methods. The suggested system attained 99.08% F-measure,
    while the existing methods have achieved only 77.99% for DT, 63.47% for NB, and
    94.14% for SLSTM and RF, with 77.45%. So the suggested system outperformed in
    terms of F-measure. Fig. 7 Performance Analysis of F-measure Full size image Figure
    8 gives the performance evaluation based on the precision of the suggested system
    with numerous existing methods. The suggested system attained 99.90% precision,
    while the existing methods have achieved only 78.4% for RF, 78.31% for DT, 94.11%
    for SLSTM and 69.19% for NB. So the suggested system outperformed in terms of
    precision. Fig. 8 Performance Analysis of Precision Full size image Figure 9 depicts
    the receiver operating characteristic (ROC) curve, which represents the rate of
    true positives vs the rate of false positives. The ROC curve examines the performance
    of the classifier. Then, the analysis of training accuracy is shown in Fig. 10.
    Fig. 9 ROC curve for APA-DDoS-Attack dataset Full size image Fig. 10 Training
    accuracy vs testing accuracy for the suggested system with APA-DDoS Attack dataset
    Full size image Figure 10 shows the training accuracy when tested for the suggested
    APA-DDoS attack dataset system. The suggested system achieved a better accuracy
    with 99.35%. The suggested system got low loss in testing and training. The training
    loss vs a testing loss of the suggested system for the APA-DDoS Attack dataset
    is plotted in Fig. 11. Fig. 11 Training loss vs testing loss for the suggested
    system with the APA-DDoS Attack dataset Full size image 4.5 Performance analysis
    based on ToN-IoT dataset This section compares the suggested IDS’s performance
    to other current approaches regarding a recall, accuracy, F-measure and precision.
    For the analysis, the ToN-IoT dataset is utilized. Table 3 compares the suggested
    system with various existing methods like NB, DT, RF and SLSTM. Table 3 Comparison
    analysis of Accuracy, Precision, F-measure and Detection rate for APA-DDoS Attack
    dataset Full size table The confusion matrix (CM) of the ToN-IoT dataset, which
    indicates the performance of the classification, is shown in Fig. 12. The rows
    in CM symbolize the true label, and the columns symbolize the predicted labels.
    Fig. 12 Confusion matrix of ToN-IoT Dataset Full size image Figure 13 gives a
    performance evaluation in terms of accuracy of the suggested system with numerous
    existing methods. The suggested system attained 99.71% accuracy, while the existing
    methods achieved only 95.34% for DT, 90.62% for NB, 98.64% for SLSTM and RF 97.81%.
    So the suggested system outperformed in terms of accuracy. Fig. 13 Analysis of
    Accuracy Performance Full size image The suggested system achieved good performance
    with a detection rate of 99.02%. Figure 14 gives the detection rate performance
    analysis of the suggested and present methods. Fig. 14 Analysis of Detection rate
    Performance Full size image Figure 15 gives the performance evaluation of an F-measure
    suggested system with numerous present methods. The suggested system attained
    99.85% F-measure, while the existing methods have achieved only 76.33% for DT,
    72.43% for NB, and 98% for SLSTM and RF, with 86.41%. So the proposed system outperformed
    in terms of F-measure. Fig. 15 Analysis of F-measure Performance Full size image
    Figure 16 shows the performance evaluation in terms of precision. The various
    existing methods used are DT, RF, NB and SLSTM, with precisions of 74.42%, 87.5%,
    77.68% and 98.94%, respectively. The proposed system attained 99.89% precision.
    Fig. 16 Analysis of Precision Performance Full size image The classifier outcomes
    were evaluated using the receiver operating characteristic (ROC), which gives
    the performance assessment of multiclass vectors in a dataset. To represent the
    ROC, the TP and the FP rates are considered. The ROC curve of the proposed system
    is shown in Fig. 17. Fig. 17 Graph of ROC curve for ToN-IoT dataset Full size
    image The accuracy of training and testing of the suggested system for the ToN-IoT
    dataset is plotted in Fig. 18. The suggested system with BiGRU-CNN achieved 99.71%
    accuracy. Fig. 18 Accuracy of Training vs testing for the suggested system with
    APA-DDoS Attack dataset Full size image The proposed system got low loss in testing
    and training. The training loss vs a testing loss of the proposed system for the
    ToN-IoT dataset is plotted in Fig. 19. The comparison analysis of the proposed
    methodology with different existing approaches is given in Table 4. Fig. 19 Training
    loss vs testing loss for the proposed system with APA-DDoS Attack dataset Full
    size image Table 4 Comparison analysis on F-measure with ToN-IoT dataset Full
    size table Table 4 compares the proposed methodology with different existing approaches
    such as LSTM, NN, GBM, KNN, TP2SF, CART, RF, CART, and XGBoost approaches [31]
    in terms of F-measure performance. The proposed scheme attains better performance
    than the compared existing schemes. The comparison table on accuracy with different
    datasets is given in Table 5. Table 5 Comparison table on accuracy with various
    datasets Full size table According to Table 5, the proposed model with the TON-IoT
    dataset attains higher accuracy than other models such as VGG16, Xception, Inception
    [32], RNN, stacked LSTM, extreme gradient boosting algorithm, DNN, RF, Generative
    adversarial network [24] with different datasets. The proposed scheme attains
    better performance, and the existing Xception with NSL-KDD dataset attained the
    lowest accuracy. Table 6 compares AUC, training time and predicted time for other
    existing models. Table 6 Comparison of AUC and time Full size table Table 6 compares
    performance metrics such as AUC, training time and predicting time taken by ConvNeXt,
    ConvNeXt-DenseNet, ConvNeXt-Sf [33] and the proposed model. The AUC of the proposed
    model outperforms other existing schemes with a value of 0.99981. ConvNeXt, ConvNeXt-DenseNet,
    ConvNeXt-Sf and the proposed model have taken 148,833.81, 62,879.73, 25,857.367
    and 15,795 s of training time, respectively, on TON-IoT dataset. The ConvNeXt-Sf
    and the suggested model had faster training times than ConvNeXt. The prediction
    times for ConvNeXt, ConvNeXt-DenseNet, ConvNeXt-Sf and the suggested model were
    18.493 s, 18.637 s, 10.671 s, and 7.45 s, respectively. This proved that the proposed
    scheme takes less time than the existing approaches. 5 Conclusion In this research,
    an effective intrusion detection system for DDoS attack detection for smart agriculture
    was developed. The data collected are pre-processed using data normalization and
    label encoding. A fused model of CNN with the bidirectional gated recurrent unit
    (Bi-GRU) is used to detect and classify the intrusions. The BiGRU model includes
    an attention mechanism to find the most crucial features responsible for identifying
    the DDoS attack. Further, the model’s classification accuracy is enhanced using
    a nature-inspired metaheuristic optimization algorithm called the Wild Horse Optimization
    (WHO) algorithm. Standard performance metrics calculate the intrusion detection
    system (IDS) performance. The developed IDS model can detect the DDoS attack in
    smart agriculture and attained an accuracy of 99.35% for APA-DDoS-Attack and ToN-IoT
    datasets with 99.71% accuracy. The attained results proved that the proposed scheme
    outperforms the different existing approaches. In future, more advanced technology
    can be used to improve the performance to detect IoT attacks. Furthermore, more
    performance validations can be performed with different performance metrics. Data
    availability The entire implementation of the work will be carried out in the
    Python platform. The major performance metrics such as accuracy, precision, recall,
    f-measure and ROC will be computed and compared with the recent techniques relevant
    to intrusion detection in IoT-enabled smart farming. The data that support this
    finding of this study are openly available at the following URL/https://www.unb.ca/cic/datasets/ddos-2019.html
    , https://cloudstor.aarnet.edu.au/plus/s/ds5zW91vdgjEj9i. Code availability The
    code that supports this finding of this study is openly available at the following
    URL/https://github.com/keerthikethineni/IDin-IOT-based-Smart-Farming-using-HDLF.git
    References Yang, X., Shu, L., Chen, J., Ferrag, M.A., Wu, J., Nurellari, E., Huang,
    K.: A survey on smart agriculture: development modes, technologies, and security
    and privacy challenges. IEEE/CAA J. Automatica Sinica. 8(2), 273–302 (2021) Article   Google
    Scholar   de Araujo Zanella, A.R., da Silva, E., Albini, L.C.P.: Security challenges
    to smart agriculture: current state, key issues, and future directions. Array
    8, 100048 (2020) Article   Google Scholar   Kumar, P., Gupta, G.P., Tripathi,
    R.: PEFL: deep privacy-encoding-based federated learning framework for smart agriculture.
    IEEE Micro 42(1), 33–40 (2021) Article   Google Scholar   Suhaimi, A.F., Yaakob,
    N., Saad, S.A., Sidek, K.A., Elshaikh, M.E., Dafhalla, A.K., Lynn, O.B., Almashor,
    M.: IoT based smart agriculture monitoring, automation and intrusion detection
    system. J. Phys.: Conf. Series, IOP Publish. 1962(1), 012016 (2021) Google Scholar   Fróna,
    D., Szenderák, J., Harangi-Rákos, M.: The challenge of feeding the world. Sustainability.
    11(20), 5816 (2019) Article   Google Scholar   Alsoufi, M.A., Razak, S., Siraj,
    M.M., Nafea, I., Ghaleb, F.A., Saeed, F., Nasser, M.: Anomaly-based intrusion
    detection systems in iot using deep learning: a systematic literature review.
    Appl. Sci. 11(18), 8383 (2021) Article   Google Scholar   Cicioğlu, M., Çalhan,
    A.: Smart agriculture with Internet of things in cornfields. Comput. Electr. Eng.
    90, 106982 (2021) Article   Google Scholar   Ferrag, M.A., Shu, L., Friha, O.,
    Yang, X.: Cyber security intrusion detection for agriculture 4.0: machine learning-based
    solutions, datasets, and future directions. IEEE/CAA J. Automatica Sinica. 9(3),
    407–436 (2021) Article   Google Scholar   Kumar, R., Mishra, R., Gupta, H.P.,
    Dutta, T.: Smart sensing for agriculture: applications, advancements, and challenges.
    IEEE Consum. Electron. Magazine 10(4), 51–56 (2021) Article   Google Scholar   Kumar,
    M., Vikas Reddy, S.: Intrusion detection and prevention system for Iot. Eur. J.
    Mol. Clin. Med. 7(8), 2983–2991 (2020) Google Scholar   Bhatt, H., Bhushan, B.,
    Kumar, N.: IOT: The current scenario and role of sensors involved in smart agriculture.
    Int. J. Recent Technol. Eng. 8(4), 12011–12023 (2019) Google Scholar   Riaz, A.R.,
    Gilani, S.M.M., Naseer, S., Alshmrany, S., Shafiq, M., Choi, J.G.: Applying adaptive
    security techniques for risk analysis of internet of things (IoT)-based smart
    agriculture. Sustainability 14(17), 10964 (2022) Article   Google Scholar   Bhatnagar,
    V., Singh, G., Kumar, G., Gupta, R.: Internet of thingsin smart agriculture: applications
    and open challenges. Int. J. Stud. Res. Technol. Manage. 8(1), 11–17 (2020) Google
    Scholar   Yadahalli, S., Parmar, A. and Deshpande, A.: Smart intrusion detection
    system for crop protection by using Arduino. In 2020 Second International Conference
    on Inventive Research in Computing Applications (ICIRCA), IEEE. 405–408 (2020).
    Murugesan, M.: Smart agriculture monitoring system. Turkish J. Comput. Math. Educ.
    10(3), 1001–1005 (2019) Google Scholar   Tao, W., Zhao, L., Wang, G., Liang, R.:
    Review of the Internet of things communication technologies in smart agriculture
    and challenges. Comput. Electron. Agric. 189, 106352 (2021) Article   Google Scholar   Shafiq,
    M., Tian, Z., Bashir, A.K., Jolfaei, A., Yu, X.: Data mining and machine learning
    methods for sustainable smart cities traffic classification: a survey. Sustain.
    Cities Soc. 60, 102177 (2020) Article   Google Scholar   Shafiq, M., Tian, Z.,
    Bashir, A.K., Du, X., Guizani, M.: CorrAUC: a malicious bot-IoT traffic detection
    method in IoT network using machine-learning techniques. IEEE Internet Things
    J. 8(5), 3242–3254 (2020) Article   Google Scholar   Shafiq, M., Tian, Z., Bashir,
    A.K., Du, X., Guizani, M.: IoT malicious traffic identification using wrapper-based
    feature selection mechanisms. Comput. Secur. 94, 101863 (2020) Article   Google
    Scholar   Kumar, K.N., Pillai, A.V. and Narayanan, M.B.: Smart agriculture using
    IoT. Materials Today: Proceedings. (2021). Eskandari, M., Janjua, Z.H., Vecchio,
    M., Antonelli, F.: Passban IDS: An intelligent anomaly-based intrusion detection
    system for IoT edge devices. IEEE Int. Things J. 7(8), 6882–6897 (2020) Article   Google
    Scholar   Salim, C. and Mitton, N. 2021 Image similarity based data reduction
    technique in wireless video sensor networks for smart agriculture. In International
    Conference on Advanced Information Networking and Applications, Springer, Cham.
    Abraham, G., Raksha, R. and Nithya, M.: Smart Agriculture Based on IoT and Machine
    Learning. In 2021 5th International Conference on Computing Methodologies and
    Communication (ICCMC), IEEE. 414–419 (2021). Ferrag, M.A., Shu, L., Djallel, H.,
    Choo, K.K.R.: Deep learning-based intrusion detection for distributed denial of
    service attack in agriculture 4.0. Electronics 10(11), 1257 (2021) Article   Google
    Scholar   Raghuvanshi, A., Singh, U.K., Sajja, G.S., Pallathadka, H., Asenso,
    E., Kamal, M., Singh, A., Phasinam, K.: Intrusion detection using machine learning
    for risk mitigation in IoT-enabled smart irrigation in smart farming. J. Food
    Quality. 2022, 1–8 (2022) Article   Google Scholar   Moso, J.C., Cormier, S.,
    de Runz, C., Fouchal, H., Wandeto, J.M.: Anomaly detection on data streams for
    smart agriculture. Agriculture 11(11), 1083 (2021) Article   Google Scholar   Park,
    H., Park, V., Kim, S.: Anomaly detection of operating equipment in livestock farms
    using deep learning techniques. Electronics 10(16), 1958 (2021) Article   Google
    Scholar   Thakur, D., Kumar, Y., Vijendra, S.: Smart irrigation and intrusions
    detection in agricultural fields using IoT. Procedia Computer Science. 167, 154–162
    (2020) Article   Google Scholar   https://www.kaggle.com/datasets/yashwanthkumbam/apaddos-dataset
    Kumar, R., Kumar, P., Tripathi, R., Gupta, G.P., Gadekallu, T.R., Srivastava,
    G.: SP2F: A secured privacy-preserving framework for smart agricultural Unmanned
    Aerial Vehicles. Comput. Netw. 187, 107819 (2021) Article   Google Scholar   Le,
    T.T.H., Oktian, Y.E., Kim, H.: XGBoost for imbalanced multiclass classification-based
    industrial Internet of things intrusion detection systems. Sustainability 14(14),
    8707 (2022) Article   Google Scholar   El-Ghamry, A., Darwish, A., Hassanien,
    A.E.: An optimized CNN-based Intrusion Detection system for reducing risks in
    smart farming. Int Things 22, 100709 (2023) Article   Google Scholar   Zhao, Guosheng,
    Yang Wang, and Jian Wang. 2023 “Lightweight Intrusion Detection Model of the Internet
    of Things with Hybid Cloud-Fog Computing.” Security and Communication Networks
    2023: 1–16. Download references Acknowledgements We declare that this manuscript
    is original, has not been published before and is not currently being considered
    for publication elsewhere. Funding The authors have not disclosed any funding.
    Author information Authors and Affiliations Research Scholar, Koneru Lakshmaiah
    Education Foundation, Guntur, India Keerthi Kethineni Department of Computer Science
    and Engineering, V.R. Siddhartha Engineering College, Vijayawada, India Keerthi
    Kethineni Department of Computer Science and Engineering, Koneru Lakshmaiah Education
    Foundation, Guntur, India G. Pradeepini Contributions K: conceptualization, Data
    Curation, Formal Analysis, Investigation, Resources, Software, Writing an original
    draft. P: Methodology, Project administration, Supervision, Validation, Visualization,
    Writing-Review & editing, Funding acquisition. Corresponding author Correspondence
    to G. Pradeepini. Ethics declarations Conflict of interest There is no conflict
    of interest in the present research work. Informed consent Author and Co-author
    are well aware of the publication. Additional information Publisher''s Note Springer
    Nature remains neutral with regard to jurisdictional claims in published maps
    and institutional affiliations. Rights and permissions Springer Nature or its
    licensor (e.g. a society or other partner) holds exclusive rights to this article
    under a publishing agreement with the author(s) or other rightsholder(s); author
    self-archiving of the accepted manuscript version of this article is solely governed
    by the terms of such publishing agreement and applicable law. Reprints and permissions
    About this article Cite this article Kethineni, K., Pradeepini, G. Intrusion detection
    in internet of things-based smart farming using hybrid deep learning framework.
    Cluster Comput 27, 1719–1732 (2024). https://doi.org/10.1007/s10586-023-04052-4
    Download citation Received 20 January 2023 Revised 07 March 2023 Accepted 22 May
    2023 Published 03 June 2023 Issue Date April 2024 DOI https://doi.org/10.1007/s10586-023-04052-4
    Share this article Anyone you share the following link with will be able to read
    this content: Get shareable link Provided by the Springer Nature SharedIt content-sharing
    initiative Keywords Intrusion detection Label encoding Smart agriculture Detection
    Attention mechanism Normalization Deep learning Weight optimization Use our pre-submission
    checklist Avoid common mistakes on your manuscript. Sections Figures References
    Abstract Introduction Related work Proposed methodology Results and discussion
    Conclusion Data availability Code availability References Acknowledgements Funding
    Author information Ethics declarations Additional information Rights and permissions
    About this article Advertisement Discover content Journals A-Z Books A-Z Publish
    with us Publish your research Open access publishing Products and services Our
    products Librarians Societies Partners and advertisers Our imprints Springer Nature
    Portfolio BMC Palgrave Macmillan Apress Your privacy choices/Manage cookies Your
    US state privacy rights Accessibility statement Terms and conditions Privacy policy
    Help and support 129.93.161.219 Big Ten Academic Alliance (BTAA) (3000133814)
    - University of Nebraska-Lincoln (3000134173) © 2024 Springer Nature"'
  inline_citation: '>'
  journal: Cluster Computing
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Intrusion detection in internet of things-based smart farming using hybrid
    deep learning framework
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Rezaee M.R.
  - Abdul Hamid N.A.W.
  - Hussin M.
  - Zukarnain Z.A.
  citation_count: '0'
  description: The proliferation of Internet of Things (IoT) devices and other IT
    forms in almost every area of human existence has resulted in an enormous influx
    of data that must be managed and stored. One viable solution to this issue is
    to store and handle massive amounts of data in cloud environments. Real-time data
    analysis has always been critical. However, it becomes even more crucial as technology
    and the IoT develop, and new applications emerge, such as autonomous cars, smart
    cities, and IoT devices for healthcare, agriculture, and other industries. Given
    the massive volume of data, moving to a remote cloud is time-consuming and produces
    severe network congestion, rendering cloud administration and rapid data processing
    difficult. Fog computing provides close-to-device processing at the network's
    periphery, and fog computing can analyze data in near real-time. However, the
    increased amount of IoT gadgets and data they produce is a formidable challenge
    for fog nodes. Task offloading may enhance fog computing by offloading the excess
    data to other nodes for processing due to the restricted resources in the fog.
    Management of tasks and resources must be optimized in fog devices. This review
    article overviews related works on task offloading in IoT-Fog-Cloud Environment.
    In addition, we discuss about fog networks and Software-defined network (SDN)
    applications and challenges in fog offloading.
  doi: 10.1109/ACCESS.2024.3375368
  full_citation: '>'
  full_text: '>

    "IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account
    Personal Sign In Browse My Settings Help Access provided by: University of Nebraska
    - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards
    Authors Citations ADVANCED SEARCH Journals & Magazines >IEEE Access >Volume: 12
    Fog Offloading and Task Management in IoT-Fog-Cloud Environment: Review of Algorithms,
    Networks, and SDN Application Publisher: IEEE Cite This PDF Mohammad Reza Rezaee;
    Nor Asilah Wati Abdul Hamid; Masnida Hussin; Zuriati Ahmad Zukarnain All Authors
    168 Full Text Views Open Access Comment(s) Under a Creative Commons License Abstract
    Document Sections I. Introduction II. Overview of Fundamental Concepts III. Related
    Surveys IV. Fog Offloading Related Approaches V. Evaluation and Comparative Analysis
    Show Full Outline Authors Figures References Keywords Metrics Abstract: The proliferation
    of Internet of Things (IoT) devices and other IT forms in almost every area of
    human existence has resulted in an enormous influx of data that must be managed
    and stored. One viable solution to this issue is to store and handle massive amounts
    of data in cloud environments. Real-time data analysis has always been critical.
    However, it becomes even more crucial as technology and the IoT develop, and new
    applications emerge, such as autonomous cars, smart cities, and IoT devices for
    healthcare, agriculture, and other industries. Given the massive volume of data,
    moving to a remote cloud is time-consuming and produces severe network congestion,
    rendering cloud administration and rapid data processing difficult. Fog computing
    provides close-to-device processing at the network’s periphery, and fog computing
    can analyze data in near real-time. However, the increased amount of IoT gadgets
    and data they produce is a formidable challenge for fog nodes. Task offloading
    may enhance fog computing by offloading the excess data to other nodes for processing
    due to the restricted resources in the fog. Management of tasks and resources
    must be optimized in fog devices. This review article overviews related works
    on task offloading in IoT-Fog-Cloud Environment. In addition, we discuss about
    fog networks and Software-defined network (SDN) applications and challenges in
    fog offloading. A Deep Dive into IoT-Fog-Cloud Environments, Exploring Strategies
    for Offloading and Task Management, Including Algorithmic Approaches, Network
    ,and SDN Applications. Published in: IEEE Access ( Volume: 12) Page(s): 39058
    - 39080 Date of Publication: 13 March 2024 Electronic ISSN: 2169-3536 DOI: 10.1109/ACCESS.2024.3375368
    Publisher: IEEE Funding Agency: CCBY - IEEE is not the copyright holder of this
    material. Please follow the instructions via https://creativecommons.org/licenses/by/4.0/
    to obtain full-text articles and stipulations in the API documentation. SECTION
    I. Introduction The vast development of intelligent devices and the rise of cloud
    computing have led to exponential growth in the quantity of data generated by
    IoT gadgets. Furthermore, cutting-edge IoT applications need ultra-low latency
    for data transmission and processing. These include augmented reality (AR), virtual
    reality (VR), autonomous driving, and intelligent manufacturing. A new computer
    paradigm, “fog computing,” is designed to fulfil these needs. Rather than transmitting
    large amounts of data to a centralized cloud server, delay-sensitive apps like
    augmented reality (AR), virtual reality (VR), and online games may do the necessary
    processing at fog nodes. It would significantly lessen the latency of information
    processing and reduce the quantity of data sent inside the primary networks. In
    fog computing, fog nodes are located close to the IoT devices so that they may
    act as a bridge between them and the public cloud. Depending on the structure,
    a fog node might be a cloudlet, a micro-data center, or an IoT gateway. The benefits
    of fog computing have yet to be realized entirely despite many practical and educational
    efforts [1], [2]. Since the IoT generates copious amounts of data, cloud computing
    may be used to manage and analyze this deluge of information. However, real-time
    processing is essential for many IoT devices. Fog computing provides a great answer
    to this problem. Offloading tasks from one fog to another node is crucial for
    continuing processing operations without interruption due to the limited resources
    in fogs for heavy-duty processing, particularly for procedures that need to be
    handled in real-time or quickly. Fog offloading and SDN have been widely used
    across several industries, showcasing their capacity to improve operational efficiency
    and decision-making. Fog computing is employed in smart cities to decrease latency
    and power usage, which is essential for IoT applications such as traffic management
    and public safety systems. Additionally, wireless fog networks enabled by SDN
    offer reduced latency and effective load balancing [3], [4], [5]. Within the healthcare
    sector, it facilitates expedited processing of data at the periphery, hence enhancing
    the promptness and dependability of patient treatment [6], [7] Fog computing and
    SDN are advantageous for industrial automation since they provide predictive maintenance
    and process optimization, particularly in industrial Internet of Things (IIoT)
    systems, ensuring real-time performance and high reliability [8], [9]. Vehicular
    ad-hoc networks (VANET) [10] and vehicular networks [11] integrate SDN and fog
    computing, while [12] employs a fusion of fog computing, SDN, and blockchain to
    enhance IoT sensors in agriculture. Additionally, within the domain of Intelligent
    Transportation Systems (ITS), [13] highlights further innovative deployments and
    [14] focus on prediction of forest fires via distributed machine learning on a
    fog network. These examples highlight the extensive influence of the technology
    across several industries. An evaluation of existing research shows that several
    frameworks and methods have been used to offload computation from the fog onto
    other nodes in the computing infrastructure. While algorithms provide many options
    for dealing with this problem, including offloading to the cloud, the most practical
    approach is to upload work to another fog due to the high expense of cloud offloading.
    The challenge now is picking the right node from all the available ones on the
    network—one that has enough computing power, a fast enough connection, enough
    bandwidth, and is not too far from the original place. Literature evaluation and
    research of various methods and methodologies show that centralized and distributed
    architectures have benefits and drawbacks. The fogs assemble their data and the
    rest of the network’s nodes and linkages. In addition to placing a heavy computational
    burden on the fog and communication lines, this effort also needs to improve the
    efficiency of the underlying network and computing fog. The Centralized architecture
    has performance concerns since it relies on a single device, making it vulnerable
    to outages in case of a communication breakdown between the nodes. In light of
    the numerous complexities surrounding offloading in fog computing, with particular
    emphasis on the intricate nature of network structures, this review paper delves
    into a comprehensive analysis of the prevailing challenges and their corresponding
    solutions. Our objective is to scrutinize the diverse aspects of network utilization
    in fog offloading and explore the applications, benefits, and obstacles associated
    with SDN technology within this domain. The following are the primary contributions
    of this survey: A thorough analysis of the fog offloading issue classifies the
    most recent solutions and identifies the various aspects impacting the offloading
    decision. We discuss and explore diverse types of offloading networks by focusing
    on SDN applications in this field. We present a classification for the optimization
    methodologies to tackle the service placement issue for IoT applications deployed
    across fog nodes. Finally, we explore future research directions in fog-based
    systems and identify great difficulties. We will go deeply into each issue in
    the following parts of this review article. In the second part, we will review
    the significant components, ideas, and aspects of fog computing. In the third
    section, the related surveys are discussed. We will then perform a detailed assessment
    and evaluation of fog offloading related approaches and analyzing recent studies
    in the fourth part. In the fifth part, we will assess and evaluate the approaches
    and categorization of fog computing architectures and SDN. In the sixth part,
    we will discuss the results, emphasizing both the advantages and problems connected
    with SDN in fog computing. Finally, in the last part, we will make conclusions
    that will pave the way for future research areas in fog computing. SECTION II.
    Overview of Fundamental Concepts A. IoT The term “Internet of Things” (IoT) refers
    to a network of physical things, such as buildings, cars, and other objects, that
    collect and distribute data using software, sensors, electronics, and network
    connections. IoT devices have confronted storage, communication, energy, and computing
    limits. Due to these inefficiencies, IoT and cloud computing technologies are
    combined [15]. Many IoT systems and information science addresses associated with
    IoT devices are connected to the internet to provide end users and businesses
    with regular services and tasks. Applications for the IoT have exploded in recent
    years, and predictions indicate that this trend will continue. More than seven
    billion IoT devices were linked to the internet in 2018; fourteen billion were
    anticipated to do so in 2019. Among the IoT applications with the highest number
    of deployed devices is the home sector, with 663 million devices in use in 2017.
    Some of the purposes for intelligent homes include locks, freezers, stoves, refrigerators,
    and lighting. Expanded IoT usage, or the “smart city,” has been proposed for many
    European nations. Automation, pricing potency, and exactness have contributed
    most to the present trend in industrial, agricultural, and health applications.
    Patient monitoring, energy-saving, and imaging-related technologies are a few
    examples of healthcare gadgets (X-ray machines) [16]. B. Cloud Computing “IoT”
    and “cloud computing” are the foundation of a swift and autonomous transformation.
    IoT technology’s processing, storage, and communications constraints may initially
    be made up for by the almost limitless cloud computing resources and capabilities.
    Additionally, cloud computing may be advantageous in many real-world situations
    by allowing new services. IoT technology has extended its reach to solve real-world
    issues in a more distributed and dynamic fashion [17]. Connecting self-aware,
    intelligent nodes, or “things,” in a dynamic, worldwide network architecture is
    the core concept of the IoT. It supports ubiquitous and pervasive computing potential
    and is one of the most problematic technologies. Some define the IoT as a phrase
    for small, universal, global, and responsible items with limited processing and
    storage power and privacy, security, and accountability concerns. On the other
    hand, cloud computing is a highly developed technology that offers almost endless
    processing and storage capacity and has addressed or substantially resolved most
    IoT issues. As such, it is anticipated that a single IT paradigm—in which Cloud
    and IoT are complementary technologies—will disrupt the current and future internet
    [18]. The necessity for an interface between cloud and fog infrastructures was
    seen from the beginning of the fog concept [19]. Additionally, [18] addresses
    the interaction between such entities; the standardization of this interface is
    highlighted as one of the crucial challenges [20]. C. Edge Computing In order
    to improve reaction times and save bandwidth, edge computing and fog computing—two
    essential elements of distributed computing—seek to move processing and data storage
    closer to the point of need. Even if their goals are identical, their distinct
    qualities may either support or contradict one another. Whereas fog computing
    makes use of an intermediate layer, such as routers or gateway devices, edge computing
    processes data on devices at the edge of the network, such as smartphones and
    IoT sensors. Through a layered computing architecture, the synergy of these two
    enables a more effective allocation of computational activities, boosting efficiency,
    performance, scalability, and system dependability. Edge computing requires the
    construction of tiny, virtualized infrastructures between base stations, radio
    network controllers, and other aggregation sites at the network edge. Although
    edge computing uses an architecture and an operating system distinct from fog
    computing (one operator maintains the infrastructure, excluding consumer devices),
    it targets applications comparable to fog computing. Edge computing also leverages
    telecom infrastructures to provide mobile edge services, including location, information
    measure management, and radio network information [21]. To prolong the battery
    life of edge devices, the applications running on edge devices may be efficiently
    migrated to fog devices that possess sufficient resources and battery capacity.
    This approach has been demonstrated in research [22]. Nevertheless there are additional
    difficulties in combining edge and fog computing. It is difficult to manage resources
    between fog nodes and edge devices, and the increasing data processing at the
    edge raises security and privacy issues. Interoperability problems may arise from
    a lack of standardisation, and in certain situations, the interdependency on network
    connection presents difficulties. Furthermore, the deployment and maintenance
    of these integrated systems are very complicated, and the energy consumption and
    sustainability of such a dispersed network need cautious management. All things
    considered, edge computing enhances fog computing by improving processing power,
    but it also brings new challenges that must be resolved in order to maximise dispersed
    computing systems. D. Fog Computing Fog computing has emerged as a feasible supplement
    to cloud computing with the advent of real-time IoT devices, bringing cloud computing
    to the edge of the network to fulfill the stringent latency constraints and intense
    processing needs of these applications [22], [23]. A typical fog compute node
    comprises several geographically distributed fog nodes positioned at the network’s
    edge with different resource provisioning, such as storage, processing power,
    and communication bandwidth [24]. Fog computing bridges edge devices and the cloud,
    offering low-latency connections and a dynamic environment. It is similar to the
    edge in architecture and closer to the cloud regarding resources, capable of performing
    computations and storing data fields [25]. A cloud extension known as fog computing
    occasionally reduces latency and supports time-sensitive applications, including
    online gaming, healthcare, and autonomous driving. Local devices execute simple
    activities, whereas large cloud installations handle sophisticated procedures.
    Fog computing collects virtual resources from several devices scattered around
    the environment, each managed by a different entity [21]. The IoT enables connections
    between objects and networks. Fog computing, an innovative concept, provides computer,
    storage, and networking services to IoT devices (such as sensors or embedded devices)
    at the network’s edge. Fog computing benefits mobile computing swiftly analyses
    massive amounts of data and manages billions of internet-connected devices. Fog
    property, quality of service, interface and programming model, machine offloading,
    scheduling, accounting and tracking, resource and repair management, and information
    privacy are among the fundamental problems in fog computing. Fog computing eliminates
    interruptions with an economical cloud architecture. Positioning fog nodes adjacent
    to the information source provides cloud support options. Instead of transferring
    IoT data to the cloud, fog evaluates and stores it locally at IoT devices, enabling
    fog to offer higher-quality services with quicker response times. Fog is the ideal
    choice for allowing the IoT to provide a range of IoT applications in an IoT system
    with practical and dependable services [26]. The closeness of end users, regionally
    targeted allocation, and quality allowance will distinguish fog from the cloud.
    Fog substantially minimizes network information measure utilization when compared
    to the cloud. In cloud based IoT data processing, each unique piece of IoT data
    must be sent to the cloud data center. Transferring data becomes increasingly
    costly if the number of data to be reviewed rises fast as is the situation with
    today’s IoT. Because of the fog, information is kept and processed locally, reducing
    the utility of sending such information. If processed data is required to be retained
    for different analytical and historical reasons, it is uploaded to the cloud.
    Consumers would benefit from cheaper operational expenses as a consequence. Furthermore,
    since the data is handled so close to the source, the end-user application becomes
    very fast, which is crucial for maintaining the quality of service for period
    and Mobile to Mobile operations. As a result, fog management services improve
    customer satisfaction while IoT information services become more reliable, efficient,
    and consistent [26]. Even though fog networking seems to be a realistic solution
    for overcoming the drawbacks of cloud computing and current networks, some concerns
    must be addressed in the future. The most critical need is a distributed intelligent
    platform for managing computing, networking, and storage resources at the edge.
    Given the wide variety of processing power capabilities of nodes, the uncertainty
    surrounding task demands, resources available at fog nodes, and distribution choices,
    it is challenging to make an acceptable distribution decision in fog networks
    [27]. Furthermore, communication delays between nodes should be considered when
    selecting a distribution, since this may lead to more extended processing times
    [28]. Consequently, the Fog computing paradigm confronts several challenges [29].
    A fog node’s response period is used to evaluate whether it should handle the
    whole of a service request that has been received, process just a part of it,
    or offload it to another fog. Each fog’s reaction time will be determined regularly
    utilizing the fog’s available capacity (i.e., waiting line volume) and the service’s
    demand travel time (lower latency is always desirable) [30]. Each fog in the network
    tries to gather data about other fogs and nodes nearby. Whenever a fog has to
    offload its responsibilities to other nodes, it stays connected to the surrounding
    nodes, changes the value of the computational function and the state of its connection
    connections, and decides about which fog to offload based on an algorithm that
    analyses the different fogs. In contrast, the centralized architecture relies
    on a server or other centralized device to gather data from distributed fogs,
    analyze computing resources, and map out connections between distributed fogs
    throughout a network. Send the communication connections from the nodes constantly
    to the device in the center. A node will communicate with this centralized machine
    when it wants to submit its duties. Central devices pick the target fog for offloading
    and introduce the source node based on nodes and network connections following
    the decision process for which the choice is made. A three-layer fog computing
    architecture is shown in Figure 1. FIGURE 1. A three-layer fog computing architecture
    [22]. Show All E. Task Offloading IoT and mobile devices are not suited for running
    programs needing significant resources since they have limited memory, computing
    power, battery life, and measurement of communication data. Mobile cloud computing
    was developed to solve the current problem and eliminate such challenges. It is
    a paradigm for shifting heavy-lifting mobile device tasks to the cloud or compute
    offloading, which frees up mobile devices’ resource constraints. Several constraints,
    including a sizeable average access latency between users and remote clouds, high
    battery consumption, and a deficiency of local user data, make offloading activities
    to the cloud possible only for specific mobile applications. Novel approaches
    are being presented to address these problems, including offloading mobile network
    traffic to complementary networks like Wi-Fi and satellite-terrestrial networks
    and edge cloud computing [31]. Consider the case when a fog node first receives
    and processes a request for data processing from a thing before responding. When
    a fog node is overloaded with other requests, it may only process a portion of
    the payload before sending it to other fog nodes. There are two ways to simulate
    fog node interactions: With the first approach, a central node keeps up the fog
    node offload contact. Every fog node follows a protocol to provide its most current
    status information to its neighbors. Second, every fog node maintains a frequently
    updated list of the best nodes to manage the offloaded workloads [30]. Offloading
    must handle many challenges in fog computing, including: How to construct the
    best offloading scheme, how to partition an application for offloading, and what
    sort of data is needed for offloading decisions are the first three questions
    [24]. Offloading must handle many challenges in fog computing, including: How
    to construct the best offloading scheme, how to partition an application for offloading,
    and what sort of data is needed for offloading decisions are the first three questions
    [13], [32], [33]. According to [23], resource allocation and dynamic offloading
    in fog computing present many vital challenges. These challenges include the following:
    The Power-Latency Tradeoff and System Dynamics: A fog system often consists of
    several layers, intricate dynamic interactions between fog tiers and the cloud,
    and dynamic internal dynamics that are always changing. Effective Decision-Making
    Process: Because of overheads, decision-making processes should be computationally
    effective. The challenges are often brought on by the unpredictable nature of
    the traffic data, the ongoing nature of task delivery, and the intrinsic complexity
    of the issue. Understanding the Benefits of Predictive Offloading: A crucial aspect
    of online decision-making is using predictive offloading to reduce delays and
    improve the quality of service. Although fog computing prediction offloading has
    various applications, its primary constraints remain a mystery. The key topic
    that will be explored is resource management in terms of computing resources and
    data storage amongst different fogs in the network. IoT devices may offload tasks
    to fog nodes fog nodes to other fog nodes, and fog nodes to clouds. The tasks
    are re-offloaded to the surrounding fog nodes or cloud due to the fog node’s low
    processing resources [34], [35], [36], [37], that resulted in more transmission
    and processing costs [37], [38]. Figure 2 depicts the scopes of task offloading
    in fog computing. FIGURE 2. Task offloading scopes related to fog computing. Show
    All Here, we will present and discuss related fog processing and offloading efforts.
    Due to its relevance and significance, the fog processing debate has garnered
    the attention of several scholars. F. Software Defined Network (SDN) SDN is an
    advanced networking concept that divides the control plane from the data plane
    [39]. This leads to increased flexibility and agility as well as more straightforward
    network design and management. SDN’s main idea is to let a logically centralized
    software-based controller, or control plane, take care of network intelligence
    and decision-making, with the data plane handling tasks like traffic forwarding.
    SDN has many advantages, including network programmability, which promotes network
    automation, and network management, which lowers operating costs by streamlining
    administration activities. And virtualization of networks [40]. Most device power
    consumption in IoT applications happens during packet forwarding on the network
    side [13], [41]. Device life and offloading quality will suffer from poor-quality
    offloading brought on by limited bandwidth and excessive latency. SDN has evolved
    as an auxiliary technology on the network side in offloading operations to alleviate
    this issue [13], [42]. Centralized control, programmability, load balancing, and
    management are just some of the problems that plague traditional Fog networks
    [43], [44], [45]. Fog nodes can efficiently operate together using SDN [2], [45],
    [46]. By enhancing the rules in its centralized SDN controller with a network-wide
    perspective [47], SDN allows for more wiggle room in the network’s programming.
    By gathering information from each network device, adjusting the load-balancing
    plan, and keeping an eye on network traffic, an SDN controller dynamically manages
    the network [45], [48], [49]. Gathering network data, such as utilization of resources,
    device positioning and mobility, load metrics, and network information, is the
    primary duty of the SDN controller in order to ensure the field of SDN-enabled
    networks provides a high level of service [13], [50], [51], [52], [53]. The offloading
    service with SDN can detect changes in the network since it uses the SDN controller
    according to the compute demands and network conditions, it may select the best
    offloading node for an overloaded fog node. SECTION III. Related Surveys As pointed
    out earlier, merely transferring and offloading data across Fogs won’t provide
    the perfect setup without considering task management and resource availability.
    Nevertheless, the majority of prior review papers have addressed algorithms from
    a broad perspective, failing to take into account the specifics of the algorithm’s
    capacity for task and resource management. This work makes a substantial addition
    to the area of fog computing by analyzing fog analysis algorithms based on the
    three primary capabilities of task management, resource management, and task offloading.
    This study diverges from recent surveys focused on fog and Edge computing, mobile
    Edge computing, or machine learning applications. Instead, it offers an in-depth
    analysis of network concerns and SDN applications, specifically within the framework
    of fog offloading. This extensive examination of network and SDN issues fills
    a gap in previous research, which either ignored or briefly addressed these aspects.
    As a result, it makes a substantial addition to the subject. This approach fills
    an essential need in existing literature, establishing our study as a crucial
    asset in comprehending and progressing network management tactics in these developing
    computing paradigms. Surveys [39], [40], and [44] mainly examined Edge computing,
    mobile Edge computing, and general SDN usage. However, they either neglected or
    just briefly addressed network concerns. On the other hand, this study provides
    a detailed analysis of these topics, addressing a significant deficiency in the
    existing body of knowledge and offering valuable perspectives for enhancing network
    management tactics in Fog computing. In [54], task offloading in edge computing
    and the IoT is investigated. The study considers the benefits, factors that impact
    the decision of offloading, and different offloading techniques and algorithms.
    The algorithms are classified into two categories, machine learning and non-machine
    learning, and offloading strategies, such as total and partial offloading, are
    discussed. Authors of [55] analyzed the role and challenges of Artificial Intelligence
    and Machine Learning algorithms for resource management in fog/edge computing
    environments. References [56] examined significant journal publications on mobile
    computing and how the research route, challenges, and methodologies have evolved.
    Also, the architecture and essential components of edge computing are described.
    Reference [57] overviews offloading strategies in a fog environment. The contributions
    they cover are articles published on or before November 2020 and do not contain
    the most recent research in fog computing. A general overview of the goals, optimization
    methods, algorithms relevant to task offloading in fog computing, and formulation
    of its mathematical issue is covered in [58]. The article [35] examines the factors
    influencing whether to utilize the cloud or the fog for offloading while discussing
    various offloading techniques in the cloud-IoT ecosystem. The authors also discuss
    other offloading-supporting technologies, such as wireless connection, virtualization,
    and AI. Reference [59] reviews how Reinforcement Learning (RL) and Deep Reinforcement
    Learning (DRL) algorithms deal with offloading problems in fog computing. Value-based,
    policy-based, and hybrid-based algorithms are the three classes into which it
    divides the fog computing offloading methods. In contrast to prior review studies,
    we focused on task management from different perspectives in this study, including
    network problems and SDN technologies. Table 1 compares this study with other
    relevant studies in this field. TABLE 1 Related Works This review article focuses
    on the importance of networks and SDN in fog computing, emphasizing how they improve
    resource management, scalability, and compute efficiency in centralized and distributed
    computing environments. As a cloud computing extension, fog computing moves storage
    and processing closer to the network’s edge, requiring reliable and adaptable
    network management systems. In this context, SDN’s function is essential since
    it offers dynamic network design and optimization, which can adjust to fog computing
    environments’ different and sometimes erratic requirements. The detailed examination
    of these issues by this study not only offers a complete knowledge of the problems
    and solutions in this field today but also opens the door for future advancements
    in SDN application and network management, both essential for developing fog computing
    technologies. SECTION IV. Fog Offloading Related Approaches The paradigm for fog
    computing has extremely low latency. Due to fog computing scalability and improved
    reactivity, it has caught the interest of numerous academics [14], [35], [46],
    [55], [59], [60]. Several publications in the fog computing sector were investigated
    in the literature review. These articles are classified and compared into the
    following areas of fog offloading based on the kind of algorithms and system architectures.
    Resource management Task management Task Offloading The interconnected components
    comprising the fog computing architecture are shown in Figure 3, and relevant
    articles will be discussed in the following sections. FIGURE 3. The system of
    interconnected components that constitutes fog offloading. Show All Before proceeding
    to the articles connected to the debate, we evaluate the available surveys on
    this issue and emphasize the significance of this study in this part. A. Resource
    Management The fog network consists of various heterogeneous devices that may
    perform computations, store data, and exchange messages. Due to the ever-changing
    nature of fog networks and the mobility of their constituent devices, resource
    management is a significant challenge. Considering the importance of effectively
    managing resources, this might enhance fog network performance and make the most
    of fog’s processing capability. Since then, various attempts to improve fog networks’
    resource management have been assessed. In [30], a fog-to-fog cooperation paradigm
    encourages fog nodes to offload incoming requests based on their load and processing
    capacity. The mathematical model of fog-to-fog collaboration that achieves near-optimal
    task distribution across cooperating fog nodes. The Fog Resource Management Scheme
    (FRAMES) encourages load balancing to address the latency issue with service requests
    received from objects. It is built on the fog as a service concept, which implies
    that each fog node is self-contained in processing, networking, and storage. The
    study uses a formal mathematical model that underlies fog node load balancing.
    The DLAEC algorithm, introduced in reference [61] aims to enhance service quality
    through the utilization of deep learning, taking into account the availability
    of human resources and network capacity for each edge system. The DLAEC method
    maximizes resource utilization at the edge while guaranteeing the concurrent execution
    of the maximum number of deep learning tasks via a three-step decision procedure.
    DLAEC independently evaluates edge access and calculates the correct number of
    deep learning layers for identification at both the edge and cloud nodes, in contrast
    to previous models that allocate a set number of deep learning layers to edge
    systems. By assigning the majority of deep learning tasks to edge nodes, this
    method lessens the requirement for cloud transfers in an Edge Computing-based
    intelligent city environment, reducing network congestion and the load on the
    cloud. Nevertheless, instead of minimizing processing time delays, its primary
    objective is to maximize the capacity of the edge nodes. Consequently, the maximization
    may result in delays, and additional tasks may be accumulated on a single node
    before being redistributed to other nodes. Blaster is a federated structure for
    routing packets within a dispersed edge network to improve application performance
    and data-intensive application scalability [62]. It also includes a revolutionary
    path selection algorithm that predicts the best route using Long Short-Term Memory
    (LSTM). This method employs a Federated Learning (FL) model to increase communication
    across SDN controllers while retaining data flow capacity. Choose the optimal
    route during system construction by using the results of an LSTM model, which
    is a kind of recurrent neural network that uses regression as a tunable technique.
    It is common practice to use the LSTM approach to deep learning-based time series
    forecasting problems. It provides a traffic matrix and a network graph to the
    LSTM. In a peak load prediction, the SDN controller or application may modify
    route selection based on the output, which is the estimated future load on the
    input connections. As a consequence, the state of the network influences route
    selection. Reference [63] deal with implementing SDN to fog networks, namely P4/P4Runtime.
    According to the industry, P4 as a data plan programming language and P4Runtime
    as a control-to-data plan interface may assist address the demands of next-generation
    networks. It presents a unique technique for deploying SDN control plans capable
    of handling fog network SDN data plans and SDN data plans integrated near the
    main network. In this manner, SDN controllers may handle cross-layer SDN data
    plans, enabling certain operations to be offloaded to the Edge. Reference [64]
    creates Android applications that serve as intermediaries between IoT devices
    and Edge/Fog/Cloud Computing ecosystems is made more. These modules facilitate
    connectivity with numerous devices functioning as data sources, and they can seamlessly
    integrate with various Fog/Cloud frameworks, making them readily adaptable for
    diverse applications. This concept is confined to one Android application and
    face limitation to be implemented in any system. A mechanism for data allocation
    in IoT systems was proposed in [65] using the Blockchain. A data controller based
    on fuzzy logic aids in data allocation decisions. FogBus used blockchain-based
    cloud and fog technologies to improve a healthcare case study. The latency of
    data transfers, network utilization, energy consumption, and blockchain storage
    have all decreased, but security mechanism delays persist. In [66], a paradigm
    based on Edge Affinity was proposed and developed to manage applications in processioning
    fog infrastructures. This paradigm organizes applications so that its resource-aware
    approach employs a larger number of fog processes to run applications with heavy
    data loads and rigorous resource needs. It addresses difficulties with application
    data flow and bandwidth. The drawback of this strategy is that it is dependent
    on a static fog management server to perform. In [67], a fog computing model be
    utilized to produce mobility assistance advice for visually impaired people. This
    device combines a mobile phone with a low-cost, low-power embedded board and a
    neural computing stick, giving rise to the acronym PEN (Phone + Embedded Board
    + Neural Computing Stick). These three devices work together to provide numerous
    distributed capabilities by combining fog computing with cloud computing. The
    model’s shortcoming is that varied hardware devices impact the system’s mobility
    and adaptability. Reference [68] present SOSW in Mobile Edge Computing (MEC) by
    leveraging the network traffic matrix. To determine the ideal placements for fog
    nodes, the SOSW model combines column-pivoting linear algebra techniques with
    singular-value decomposition (SVD) and QR factoring. With the aid of ant colony
    optimization (ACO), SOSW provides the constraint-based shortest path algorithm
    (CSPA), a heuristic-based traffic engineering solution that optimizes route calculation
    for task offload. The architecture of fog and its grid to its location within
    the network are the main topics of this research. The placement of fog to IoT
    devices in offloading data to fog in less time is also useful in decreasing energy
    consumption. Selects the route by which the IoT device may upload its data to
    the fog by collecting data through SDN and the recommended method for transmission.
    Research [69] measuring connection quality over time as the average failure, downtime,
    or repair time. To evaluate the reliability of connections, use a k-nearest (k-NNR)
    ML approach based on regression trained on a 5-month real-life network data set.
    The k-NNR considers connection parameters such as the rate of link utilization,
    link failure, and the frequency of data set failures. Furthermore, calculate the
    connection delay as the sum of the transfer delay package size. Research [70]
    discusses the internet of vehicular in MEC by utilizing SDN to propose a resource
    allocation and communication enhancement technique. It leverages q-learning to
    enhance the allocation of communication and computation resources by anticipating
    offload choices. This design’s shortcoming is that it ignores a number of environmental
    factors that are necessary for the proper functioning of the Internet of Vehicles
    system. In order to determine the best offloading choice, communication, computing
    resource allocation, and privacy protection design, it applies a deep reinforcement
    learning method in SDN networks with an emphasis on edge computing-based computing
    offloading and resource allocation. Real-time business from terminal vehicles
    is sent straight into MEC’s processing equipment, and MEC and SDN are integrated
    to provide centralized resource management and flexible network control. Study
    [9] has proposed an adaptive computing optimization for resource management in
    industrial IoT using SDN and edge computing. It describes a strategy for effectively
    calculating the resources of neighboring devices and edge nodes for task processing:
    priority-based transmission with the least energy. In [71] a user revocation system
    with an efficient architecture for a multi-user cloud environment that maintains
    data integrity is provided. It is efficient at reducing overhead when compared
    to current models in the cloud environment, but as user numbers rise, it increases
    the duration it takes to create signatures and proofs. Using CCTV cameras for
    surveillance and event monitoring or on-board cameras for traffic monitoring,
    an application may produce enormous volumes of data, especially when video stream
    processing is involved field [72]. The primary contribution of [20] is the development
    of dynamic workload placement methods for latency-constrained stream processing
    requests. The primary concentration is on the arrangement of operators and the
    allocation of resources in a distributed environment that utilizes cloud and fog
    computing. When there is a network capacity shortage, provisioning of computing
    infrastructure uses the interaction between fog and cloud. The algorithms’ goal
    is to optimize the proportion of successfully handled requests while adhering
    to application delay requirements by efficiently using the resources at hand.
    To balance quality of service and energy consumption in large-scale networks,
    [73] introduces the Set-based Differential Evolutionary algorithm for energy-efficient
    resource management in IoT-based smart cities, employing SDN and fog computing.
    In [74], each fog node in the resource allocation approach for fog computing based
    on SDN is defined by its processing capability and bandwidth (communication capacity).
    The method begins with picking an admin node and then mapping the nodes in the
    task graph to the fog node depending on the capacity of the fog node. Following
    this mapping, the allotted resources are taken from the fog node’s capacity, which
    is maintained by a management module. However, this approach begins by virtualizing
    all of the nodes and scheduling them to one fog node. It then optimizes the schedule
    by relocating the nodes to other fog nodes. B. Task Management By leveraging fog
    in processing information related to IoT devices in many sectors, such as health,
    agriculture, transportation, media, and other sections of intelligent cities,
    various tasks are assigned to the fog for analysis and processing. Several tasks
    are available, ranging from little data gathered by sensors to extensive data
    and films taken by cameras, as well as location and navigation for analysis and
    processing. Most of these data and devices need immediate reactions and real-time
    data processing via fog. Consequently, effectively managing diverse tasks is crucial
    for tasks that must be completed before a deadline. Several studies have developed
    approaches and algorithms for task management in fog networks, some of which are
    addressed here. In order to improve quality in hybrid cloud settings for data-intensive
    applications running in a centralized shared file system, Tuli et al. suggested
    making use of dynamic resources and task scheduling. For data-intensive applications,
    it assesses data file type, data transfer time, network speed, and data proximity
    while planning and dynamically supplying public cloud resources. By lowering the
    quantity of shared file transfers across nodes, this technique may improve service
    quality and decrease task placement in a hybrid cloud environment. This approach
    was designed for cloud computing and is currently incompatible with edge and fog
    computing [75]. A lightweight distributed solution to self-organizing surveillance
    and monitoring fog networks is offered by [76]. FogMon analyses the hardware resources
    (CPU, RAM, HDD) of the access nodes, the end-to-end network quality of service
    (latency and bandwidth) and detects available IoT devices. It does not take storage
    or bandwidth into account when selecting leader nodes. Reference [77] propose
    a privacy-aware task scheduling approach for a Blockchain-based fog network. The
    Ant Colony Optimization (ACO) approach optimizes work scheduling. It keeps end-user
    devices anonymous and reduces work processing time on the cloud’s VRs. To reduce
    application latency, consider demands from edge scheduling [78]. Network latency
    and service time for live video streaming services are significantly decreased
    by a score-based edge service scheduling approach that examines the network, computing,
    and reliability aspects of edge nodes. The flaw is that it restricts the centralized
    optimization process. A fuzzy evolutionary organizer is provided for the multi-target
    resource allocation in a fog environment [79]. Since task processing time, information
    about inter-task communication, and task deadlines are all represented as fuzzy
    values; the technique achieves both the agreement index and robustness aims. The
    proposed approach has a significant temporal complexity. Machine learning is employed
    in the mobile edge processing environment by [80] or distributed task scheduling
    algorithms and distributed device coordination. This model uses the Stackelberg
    game theory and the distributed ADMM optimization approach. This approach can
    achieve quick and ideal convergence regarding intelligent edge processing. The
    design has a significant issue in that it only impacts one MEC server, and the
    scheduling strategy may change when there are several MEC servers. In [81], a
    paradigm for safe data storage and processing at the edge and in the cloud was
    presented. For privacy, this approach encrypts data during transit. In this architecture,
    tasks are broken into tiny portions and transmitted between edge nodes for execution;
    if a node does not have adequate processing capacity, the task migrates to its
    side nodes, and so on, until a suitable node is identified and wholly performed.
    In this system, the node is only dispatched for processing based on its proximity,
    independent of its resources or capacity. It may fail and be compelled to move
    to other nodes. This data transfer and undefined movement might cause substantial
    data latency issues when system demands increase. C. Task Offloading Since there
    is a variety of fog in the network, it is vital to identify the destination fog
    for offloading when fog is overloaded, or IoT devices demand an external processor.
    So, the destination selection choice influences the amount of processing time,
    data delay, and deadline. Conversely, the destination fog’s reliability in completing
    the requisite processing with no errors is another priority offloading operation.
    Factors like having adequate processing power in the destination fog, enough memory,
    and a sufficient and acceptable connection to send data may all be utilized to
    establish the fog’s competence. The right strategy for gathering fog information
    in the network and selecting the optimal fog is vital at this stage. Several approaches
    have been developed to acquire fog information in the network, which may be categorized
    into two categories: centralized and distributed. Most centralized algorithms
    have incorporated SDN technology because of the advantages of SDN networks. 1)
    Decentralize Task Offloading As discussed in last section, some fog offloading
    methods are based on distributed architecture or created without SDN technologies.
    The matching theory-based distributed computing offloading framework MATO, utilized
    for heterogeneous fog nodes to minimize task execution latency, was introduced
    in the research field [82]. Reference [14] enhanced the framework for distributed
    processing on a fog network based on Akka. The Akka toolkit is one of the most
    comprehensive and well-liked actor modeling solutions for Java Virtual Machine
    (JVM). In the Fog IoV network, [37] provide a task offloading strategy employing
    the roadside parked cars as a computing offload location. The struggle between
    IoT devices for fog nodes is treated as a game in Field [83]. The Weighted Potential
    Game’s finite improvement characteristic demonstrates the Nash equilibrium. DecChain
    is a secure edge computing solution based on blockchain that removes the requirement
    for a trusted third party on the network [84]. Concerns such as eliminating a
    trusted network failure point when losing access to a third party have been addressed.
    It faces challenges, such as integrating blockchain into the processing environment
    at the edge. Edge servers or service providers manage tasks in the network. As
    can be seen, service providers handle tasks based on a predefined structure, and
    the capacity of edge nodes to split tasks is not considered. Reference [85] concentrate
    on multi-hop vehicular systems to have optimum options for performing activities
    locally or remotely. For compute offloading, efficient route selection and fog
    node assignment may reduce average service latency and energy consumption. Its
    performance is inferior to other frameworks when there are less than 50 automobiles,
    but by increasing the numbers, performance is more outstanding than others. In
    5G network technologies based on edge computing, research [86] combines optimization
    techniques for task offloading and resource allocation by controlling the energy
    consumption of the system. The plan may provide even better latency performance,
    which boosts the functionality of 5G mobile communication networks and enhances
    end-user satisfaction. The suggested approach ignores the order in which computing
    tasks are completed and only considers the overall processing time delay of all
    tasks inside the system. An Optimal Stopping Theory (OST) inspired paradigm for
    data quality-aware task offloading in mobile edge computing is presented in [87].
    The OST-based method is acceptable when mobile nodes make small, independent choices
    inside the MEC environment and do not need many resources. Each offloading mobile
    node will run the models in a single configuration without considering the context
    of other mobile nodes. The structure and task offloading based on neural network
    service are illustrated using a GPU-based embedded edge server [88]. An offloading
    mechanism is presented based on the computing gap between the edge and the central
    cloud. It is particularly costly to build since it depends on GPU resources at
    the network’s edge. In [22], when one node on the network becomes overburdened,
    it may upload all or part of its responsibilities to other fogs through a cooperative
    mechanism. This algorithm improves fog dispersal based on multipliers distributed
    alternating direction approach. This model focuses on optimizing the Quality of
    Experience (QoE) and increasing the power efficiency of fog nodes and the tradeoff
    between these two measures. Reference [23] provides a multi-layered fog computing
    system for dynamic resource allocation and offloading utilizing traffic prediction.
    It defined the problem as a stochastic network optimization problem and offered
    a solution that reduces power consumption while maintaining queue stability. The
    shortcoming of the concept is that power usage and overall queue backlog sizes
    would become inefficient if forecast mistakes happened. For the concurrent task
    data offloading, [36] suggests collaborating horizontally with several fog nodes
    and vertically with a faraway cloud. It took into account the latency in communication
    between end users and the fog, as well as the time it took to send data and provide
    services. It also factored in local computation time and waiting times at the
    fog node linked to queuing. The authors [89] put their attention on offloading
    duties from a device to fog and fog-to-fog. The ideal scheduling approach for
    the two queues, such as low and high priority in a fog node, is examined in this
    model. The stability of both queues is concurrently maintained while more offloaded
    tasks that are aware of deadlines may be finished. Two techniques comprise the
    recommended approach: The Lyapunov drift-plus-penalty method and fog computing
    collaboration are used to construct a priority-aware scheduling approach based
    on the fog nodes’ queue status. According to the simulation findings, with the
    same resource setup, this strategy may ensure that more tasks are finished within
    the allotted time limit. 2) Centralized Task Offloading Centralized task offloading
    is split into two groups: those that use a SDN and those that don’t. a: SDN-Based
    Task Offloading In this part, we investigate and evaluate fog offloading strategies
    based on SDN technology. Most of these techniques are developed for data offloading
    from IoT or mobile devices to fog. For an SDN-based fog computing system, a dynamic
    offloading service between fog nodes is suggested by [2]. Selecting the suitable
    offloading node and enabling the offloading path by providing an end-to-end bandwidth
    guarantee are the goals of using SDN technology. To choose an appropriate offloading
    node, the proposed method makes use of fog node information and real-time network
    status. Furthermore, a few network parameters may be used to ensure bandwidth
    throughout the offloading path and create an optimal end-to-end path selection
    route. Q-learning offloading choice allows the controller to choose appropriate
    actions depending on the reward function [29]. In this strategy, the controller
    may customize their incentive function based on the desired performance. Consequently,
    the suggested Q-learning-based offloading choice can estimate how good the current
    offloading will be in the future, resulting in remarkable overall system performance.
    Furthermore, the suggested solution is compatible with SDN architecture as the
    reinforcement learning-based decision-making process is on-demand, which allows
    the controller to construct a reward function depending on the required performance.
    By using an integer linear programing (ILP), [90] resolves the multi-hop task
    offloading issue. To solve the problem effectively, use a greedy heuristic-based
    approach since the viable set is non-convex. Latency, energy costs, multi-hop
    routes, and fluctuating network factors like link utilization and SDN rule capacity
    are all part of the greedy approach. The contribution 1) the best decision is
    to compute a work locally or remotely; 2) the best fog node selection; 3) the
    best offloading route selection. With fewer fog devices, the recommended technique
    can attain excellent performance. In [31], SDN approaches are used to optimize
    resource management and load balance across a network of Cloudlets. To balance
    the distribution of different tasks offloaded from mobile devices while optimizing
    resource utilization, it is handled as a mixed-integer linear programming (MILP)
    optimization model. Taking into account both communications and computation delay,
    available resources, and a task with a restricted deadline, the issue of a balanced
    distribution of incoming requests throughout the Cloudlet network is outlined.
    To emulate the recommended architecture, experiment with utilizing Mininet-WIFI
    and Floodlight as the SDN controller. The limitations of this method are the available
    resources and the demands of the consumers. Reference [11] created a blend offloading
    structure to improve the offloading choice selection process by selecting the
    optimal offload node and assuring the infeasible request’s needed deadline and
    the average processing cost of the fog node. It employs a mathematical approach
    known as Binary Linear Programming (BLP) to determine to offload destination fog.
    The fog node’s SDN controller will choose the optimal offload target fog by comparing
    the needed deadline of the infeasible request with the response time of each available
    parked and moving car. Reference [91] suggests a four-layer network paradigm based
    on SDN for the Industrial Internet of Things (IIoT). Depending on the requirements
    of different controllers, all possible computation offloading locations indirectly
    manage the production equipment to tasks at the closest power steering device.
    SDN controllers oversee data transmission routing, while lightweight containers
    such as Docker and Micro are utilized to offer computing. Reference [92] provide
    algorithm in fog system resource management to ensure each task’s specific service
    quality and optimize resource consumption by collaborating amongst fog computing
    nodes. Develop a common heterogeneous task download and resource method with Deep
    Recurrent Reinforcement Learning to optimize tasks within time restrictions. Depending
    on their buffer and resource state, the proposed method may offload their tasks
    into nearby nodes. Prevent unfairness in resource allocation slices with varied
    priorities, resulting in a higher average success rate. Which cloudlet should
    be utilized to offload a particular task from mobile devices is determined by
    [93] based on the load assessment of cloudlets in multi-cloudlet networks. Furthermore,
    SDN is used by this system to load balance between cloudlets in wireless mobile
    networks. Additionally, it suggests an admission control mechanism to limit the
    acceptance of task assignment requests made if there are more requests than the
    network can handle. Authors in [94] considered the multi-hop route and the impact
    of vehicle mobility while proposing a software-defined vehicle network offloading
    technique. It provided an ILP-based optimization problem for determining the ideal
    number of fog nodes for a given network in order to lower operating and capital
    costs. The dynamic offloading for soft real-time workloads in an SDN-based fog
    architecture is investigated in research [95]. Preliminary results have emphasized
    the impact of intra- and inter-fog cluster analysis on the expense of missing
    the deadline. Study [50] explores the offloading problem in IoV systems based
    on SDN and fog computing. It proposes an energy-aware dynamic offloading technique
    to extend the battery life of the IoV system and run more apps. The system model
    calculation and application transfer incur cost, and the heuristic searching optimization
    technique sometimes need assistance in order to find the best answer. However,
    testing on a real IoV edge network was not done in the experiment scenario. The
    Programming Protocol-independent Packet Processors(P4) framework allows for the
    direct execution of resource and system functions on the programmable data plane,
    including in the newly introduced P4. This functionality enables the shifting
    of specific tasks from the controller to specialized hardware, such as P4 switches.
    With P4, programmers can specify packet behavior in the data plane [13]. To optimize
    the efficiency of task-offloading solutions and reduce computational overhead
    and latency in IoT networks, [13] propose a P4-assisted task-offloading scheme
    for fog-based IoT networks. However, if the fog server has the necessary resources,
    the offloaded task from IoT device will be executed immediately; otherwise, the
    task will wait in the queue until those resources become available in the fog.
    As a result, the system becomes less effective, and task processing experiences
    slight delays. b: Centralized Task Offloading (Without SDN) Some research provides
    centralized architectures without using SDN. Authors in [96] provide Fogbus, a
    blockchain-based platform that integrates IoT, fog, edge, and cloud communications
    via user identification and data encryption. Duties are controlled by a fog called
    master fog, who distributes tasks to other fog nodes called workers. The mechanism
    chooses master fog and worker fog nodes at random. When confronted with enormous
    volumes of data and activities, system flexibility is reduced, and modifying and
    transmitting data from multiple nodes to identify the final processing node delays
    and system performance. This complex technique employs a rudimentary blockchain
    algorithm that the system administrator may activate or stop. As the blockchain
    is activated, the system latency rises immediately compared to the inactive state.
    Reference [97] provides a cost-effective compute offloading architecture for use
    in industrial networks. It works based on a fog federation in which a master fog
    controller manages the flow of traffic and data from IIoT sensors to the various
    fog nodes. Furthermore, it hired a policy-based reinforcement learning approach
    using a Q-learning algorithm and a controller-based device adaption strategy to
    regulate emergency-based service requests effectively and route them toward the
    fog devices along the shortest path. Reference [98] introduces a hierarchical
    paradigm for the IoT, fog, and the cloud. Distributed task execution may control
    global energy usage and enable highly scalable IoT applications. As a proof of
    concept, analyze the efficacy of a three-tier design by considering the processing
    needs of several IoT applications in medicine, multimedia, geolocation, and text.
    It evaluates three use cases employing real-world datasets: fog-only, cloud-only,
    and fog-cloud cooperative. SECTION V. Evaluation and Comparative Analysis The
    research about the offloading fog given in the offloading section were examined
    and compared in this part. Table 2 provides an overview of the studied algorithms,
    including the technique employed, the usage of SDN and the kind of protocol utilized,
    the metrics employed the type of simulator used, area of algorithm, and their
    notable features and constraints. As shown in the examination of the articles,
    the majority of the papers and algorithms are concerned with IoT to fog offloading,
    and a few methods have been described in the offloading section from one fog to
    another fog. TABLE 2 Summary of Task Offloading Algorithms Several things could
    be improved when looking at fog-to-fog algorithms utilizing SDN. Fog selection
    is a decision-making method with a high real-time processing requirement and is
    one of the main obstacles in the decision-making process and destination. On the
    other hand, reducing system efficiency by increasing the amount of fog and network
    traffic is a significant difficulty that most of these algorithm’s face. In addition,
    the network data plan could be more helpful in choosing the connection for offloading
    to the destination. Additionally, connection traffic and data plans must be appropriately
    considered when choosing a fog, which might increase the latency in data transmission
    to the target fog and cause the offloading process to halt and fail if the link
    fails. The following is a summary of the comparative evaluation and notable shortcomings
    in current approaches: A. Fog Offloading Algorithm Types Based on the reviewed
    research, we can categorize task offloading techniques as indicated in Figure
    4 fog computing employs a variety of task-offloading strategies. Machine learning
    uses data-driven judgements to adapt to changing situations, but it may need much
    training data and computing power. When well-modelled, mathematical optimization
    gives near-optimal solutions but is challenging and less adaptable. Heuristic
    approaches are simple and efficient, but they are not ideal. Blockchain-based
    offloading improves trust and decentralization while potentially adding overhead.
    The technique of choosing is determined by application requirements and resource
    availability while balancing flexibility, complexity, and trust factors. To summarize,
    fog computing task offloading strategies each have their own benefits and drawbacks
    that suit different application needs. To achieve a balance between flexibility
    and cost, the decision should take into account the unique demands of the application
    as well as the available resources. FIGURE 4. Task offloading algorithm types.
    Show All The combination of mathematical algorithms, AI algorithms, and blockchain
    technology with fog computing has resulted in varied and complex solutions for
    data and resource management. Each of these approaches has distinct advantages
    and constraints, making them crucial in the realm of fog computing. Mathematical
    techniques are often used in fog offloading for various purposes, such as task
    offloading, load balancing, energy optimization, and delay reduction. Their focused
    and precise approach offers practical answers for optimization difficulties, such
    as minimizing energy consumption and distributing computing workloads evenly.
    Nevertheless, they only sometimes provide the most favorable outcomes and may
    need significant processing resources since their effectiveness relies greatly
    on the particularities of the situation and the design of the algorithm. Although
    optimization and game theory based solutions are effective in some constrained
    contexts, matching-based techniques provide potential benefits due to their distributed
    nature and low computing cost methodology [82]. However, AI algorithms in fog
    computing are used for predictive analytics [97], dynamic decision-making [29],
    and adaptive resource management [92]. They possess exceptional flexibility and
    aptitude for learning, making them well-suited for dynamic and unexpected circumstances.
    The primary advantage of AI is its capacity to automate intricate decision-making
    procedures and predict forthcoming requirements. However, it also presents problems
    such as the need for extensive datasets, intricacy in training and implementing
    models, and sometimes, the opaqueness of decision-making processes. Blockchain
    technology [30], a recent addition to the field of fog computing, provides a clear
    benefit in terms of security and the preservation of data integrity. Blockchain
    guarantees a high degree of security by facilitating transparent and distributed
    transactions and communications inside fog networks, according to its distributed
    and tamper-evident characteristics. This capability is essential in remote computing
    systems, where maintaining the accuracy and reliability of data is of utmost importance.
    Nevertheless, blockchain faces a lot of constraints. Scalability problems arise,
    especially when dealing with higher transaction volumes, and the maintenance of
    a blockchain network needs significant resources. Furthermore, the process of
    incorporating blockchain into current systems has its own distinct set of difficulties.
    Ultimately, the selection of mathematical algorithms, AI, and blockchain in fog
    computing is determined by specific criteria such as security, flexibility, utilization
    of resources, and intricacy of the environment. Mathematical algorithms give precise
    and efficient solutions in certain situations, while AI brings flexibility and
    predictive capabilities. Additionally, blockchain ensures unmatched security and
    integrity in distributed systems. Frequently, using a hybrid strategy that capitalizes
    on the advantages of these varied technologies provides the most efficient answer
    in the complex realm of fog computing. Fog-to-fog offloading difficulties and
    challenges need a study and enhancement of route selection and decision selection
    algorithms and the successful use of SDN-based network characteristics. Due to
    the advancement of artificial intelligence and machine learning in multiple sectors,
    many of the approaches that have been seen have turned to employ machine learning,
    deep learning, or AI algorithms in fog computing algorithms. Although these algorithms
    have significantly improved predictions for fog offloading, employing them presents
    several difficulties owing to their high computational cost and the limited processing
    power in the network’s fog. Challenges like: Computing resources are plentiful
    for artificial intelligence, machine learning, and deep learning algorithms, while
    computing resources are scarce in fog. On the other hand, the amount of communication
    load and bandwidth required to transmit data between devices for fog calculations
    adds to the difficulty of fog calculations. B. Fog Computing Architecture The
    effects of centralized, distributed, and SDN techniques on fog computing algorithms
    differ. Algorithms can optimize task offloading in a centralized system with a
    global view of resources and network circumstances, resulting in theoretically
    optimum solutions but presenting a single point of failure and scalability difficulties.
    Distributed techniques disperse decision-making across fog nodes, depending on
    local data and cooperation, making them more robust but less globally optimum.
    SDN-based designs provide dynamic network management, improving algorithm flexibility
    and responsiveness to real-time network changes, but their efficacy depends on
    algorithm integration and network programming. Task offloading centralized and
    distributed schemes features comparison are shown in Table 3. As can be seen,
    centralized networks, particularly SDN, provide several benefits despite their
    limitations and low flexibility. Centralized management using controllers in the
    SDN network allows for more simple controlling and managing of the computing resources
    of various fogs in the network with high capabilities and low loads on fog nodes.
    TABLE 3 Task Offloading Networking Schemes Comparision In dynamic fog environments,
    where node availability, network circumstances, and workload vary, many of the
    current techniques may not be able to adapt properly. Inflexible strategies may
    not function as well as they could under changing circumstances, which might affect
    the system’s overall performance. Mitigating the negative impacts of a highly
    dynamic nature, such as the lack of fog device availability and end device mobility
    support, is an essential concern. SDN is a potential network architecture for
    fog computing because of its centralized, intelligent view and control of the
    network [95]. The following is an overview of the benefits and limitations of
    SDN architecture for fog offloading, including SDN protocols discussion: 1) SDN
    Advantages SDN enables the immediate acquisition of network state, allowing for
    real-time centralized network management based on current network status and user-defined
    rules. Furthermore, this results in advantages in optimizing network setups and
    enhancing network performance [99], which is crucial for fog networks to offload
    tasks immediately without delay. Configuration is crucial in network administration,
    particularly when incorporating new equipment into an established network. The
    difficulty stems from the diversity among network device manufacturers and their
    configuration interfaces, resulting in laborious and error-prone manual setup
    procedures. These errors need extensive troubleshooting efforts. SDN solves this
    problem by consolidating the control plane across different network devices, enabling
    centralized and automated setup via software control. This not only streamlines
    network administration but also allows for adaptive optimization depending on
    current network circumstances. The use of SDN in network configuration greatly
    affects fog computing networks by improving their capacity to quickly and easily
    manage and adjust fog devices to enable new applications and services. In light
    of the present network condition and demand, flow rules may be simply adjusted
    dynamically and optimally using SDN [100]. SDN significantly impacts mathematical
    algorithms [2], [11], [13], [20], [31], [50], [68], [90], [91], [95] by streamlining
    network resource management in fog computing, enhancing load balancing, task offloading,
    and latency optimization. The dynamic allocation of resources empowers these algorithms
    to optimize distribution based on real-time data and preset criteria. Additionally,
    SDN’s adaptability allows swift adjustments, bolstering algorithmic agility amidst
    network changes. In the realm of AI algorithms [20], [29], [69], [70], [92], SDN
    facilitates efficient data handling and routing crucial for decision-making processes.
    Its adaptability enables real-time resource optimization, augmenting AI system
    performance and scalability across diverse networks. Moreover, in blockchain integration
    [30], SDN aligns with the secure, distributed nature of transactions, enhancing
    network security and optimizing resource allocation. It also fosters improved
    interoperability among fog computing nodes, facilitating seamless integration
    of blockchain systems. 2) SDN Challenges Previous research has encountered many
    obstacles with conventional SDN-based handover, which leads to increased latency
    and packet losses because of centralized control. The increase in mobility cars
    puts a load on the main SDN controller, making it difficult to fulfill quality
    of service requirements and causing frequent handover problems. Further limiting
    their efficacy in high-mobility circumstances requires comprehensive simulation
    evaluations. In order to close this gap, article [10] presents a Vehicular ad-hoc
    networks (VANET) architecture that places changeover procedures at the edge of
    the network by merging SDN and fog computing technologies. This adaptable solution
    eases the load on core networks by decentralizing changeover management using
    zone SDN controllers and fog computing vehicles while meeting the needs of highly
    mobile and data-intensive services. Incorporating SDN into fog computing poses
    significant obstacles that need resolution. These tasks include guaranteeing the
    capacity to handle many fog devices and adaptability, improving security and privacy
    within a centralized control system, establishing compatibility across different
    technologies, and optimizing resource management to distribute the workload efficiently.
    Additionally, addressing the critical challenges of optimizing traffic flows while
    minimizing latency, enhancing the energy efficiency of SDN controllers and fog
    nodes, ensuring consistent Quality of Service and reliability in dynamic fog environments,
    and seamlessly integrating SDN into current network infrastructures is essential.
    The number of SDN controllers used in reviewed research is limited, so multi-controller
    scenario challenges need to be considered and discussed in massive networks. It
    is crucial to address these shortcomings to ensure the effective adoption of SDN
    in fog computing. This will need ongoing innovation and cooperation in the industry.
    3) SDN Protocols The OpenFlow [29], [50] protocol, which is well recognized in
    the field of Software-Defined Networking (SDN), provides extensive support and
    compatibility. However, it is limited in terms of flexibility because of its rigid
    architecture. Also it also has some security and scalability concerns. P4 [13],
    a more recent and adaptable protocol, enables the customization of packet processing.
    However, it is more complex and lacks widespread compatibility. In addition to
    these, other protocols such as NetConf and YANG provide network configuration
    management by providing structured data models and transactions. However, they
    may not possess the extensive programmability of P4 or the broad acceptance of
    OpenFlow. Each protocol fulfils distinct network needs, with OpenFlow being characterized
    by a higher level of standardization, P4 providing enhanced control capabilities,
    and NetConf or YANG concentrating on configuration management. The selection of
    either OpenFlow or P4 for fog offloading relies on the particular demands of the
    network. OpenFlow’s standardization and compatibility render it well-suited for
    contexts that priorities interoperability and stability. On the other hand, the
    ability of P4 to define packet processing behaviors is beneficial in situations
    that need customized and specialized data handling. Hence, if the task of offloading
    fog requires packet processing and flexibility that are highly specialized, P4
    would be the more suitable choice. However, for broader and standardized implementations,
    OpenFlow may be the preferred option. The particular needs and attributes of the
    fog computing environment will determine which SDN protocol is best for fog offloading.
    While Netconf is well-known for its simplicity and ease of use, making it a suitable
    match for easy network administration, OpenFlow is recognized for its fine-grained
    control and flexibility, making it excellent for dynamic and complicated network
    management. A network’s complexity, scalability, required functionality and accessible
    knowledge are among the variables that determine which SDN protocol is best. Other
    protocols, including BGP-SDN, ONOS, and Faucet each offer advantages and disadvantages.
    Depending on their particular requirements, certain fog computing architectures
    may even combine these protocols to handle different aspects of task offloading
    and network management. 4) SDN With Machine Learning The integration of SDN with
    Machine Learning may provide several advantages for Fog offloading. SDN offers
    a centralized perspective of the network, enabling the optimization of the decision-making
    process for selecting the most suitable Fog node for offloading. Machine learning
    may be used to create compute offloading strategies that enhance the efficiency
    and dependability of Fog computing. The advantages of integrating Software-Defined
    Networking (SDN) with Machine Learning (ML) for Fog offloading include enhanced
    utilization of storage and computing resources, improved performance metrics like
    latency, energy consumption, and Quality of Service, and the ability to dynamically
    allocate services based on objectives such as power consumption, security, and
    QoS constraints. Nevertheless, it is essential to take into account the drawbacks
    as well. The system’s complexity may result in elevated maintenance expenses.
    Acquiring substantial data to train machine learning models may be a significant
    obstacle. The confidentiality and integrity of the data being processed by the
    Fog nodes may be compromised. To address these challenges, employing lightweight
    methodologies such as federated learning might be effective in fog offloading.
    C. Metrics for Validation During fog offloading, route selection, latency, and
    energy metrics are crucial, yet not all research studies encompass these elements
    based on Table 2. Factors like problem complexity, limited resources, or research
    focus contribute to this omission. Some studies prioritize energy efficiency [50],
    [73], [83], [98], overlooking metrics like latency or route selection, while majority
    concentrate solely on delay optimization, disregarding energy concerns or routes.
    Some researchers highlighted path selection like [2], [69], [74], [85], [97].
    Due to experimental constraints or study scope, researchers sometimes explore
    only a subset of these metrics. However, disregarding any of these measures can
    significantly impact system performance. Neglecting energy efficiency may deplete
    IoT and Fog device battery life while overlooking latency can degrade user experience
    and system performance. Ignoring route selection may lead to poor data transfer
    and heightened network congestion. Therefore, considering all criteria remains
    paramount for optimal system performance in constructing an efficient fog offloading
    system. In prior frameworks, time issues are only partially explored, and the
    computing power of resources needs to be better used. The computational strain
    increases the overall delay time, deployment cost, and energy consumption of IoT
    devices or resource-enriched fog nodes, requiring an efficient task management
    strategy to address this issue. Real-time processing is hampered by the high latency
    and system overload caused by the AI techniques utilized in these systems. D.
    Simulation Limitation Most current articles have undergone testing and evaluation
    in simulated contexts, with only methods [13], [14], [50] applied in actual or
    near-real situations. Furthermore, various kinds of simulators have been employed,
    each with its own merits and drawbacks. The wide range of simulators and the intricate
    nature of different network topologies, particularly SDN, will significantly challenge
    the effectiveness of the suggested algorithms in the real world. While simulations
    carried out using simulators such as iFogSim and Mininet and Matlab, provide insightful
    results, real-world validation is essential. From simulation to real-world application,
    there might be unanticipated difficulties or new factors to take into account.
    Although there are many theoretical ideas, there may not be as much opportunity
    for these techniques’ practical application or real-world assessment. Real-world
    implementation and thorough testing under various conditions are essential to
    verify its efficacy and functionality of proposed algorithms. E. Dataset A primary
    obstacle is the need for uniformity in the datasets used for modelling and executing
    fog-offloading studies and publications. This makes it challenging to generalize
    the data and compare the outcomes of various investigations [101]. More real-world
    data is needed to support the simulation conclusions. This may result in exaggerated
    expectations and erroneous forecasts [101]. Additionally, the particular use case
    and the surrounding environment significantly impact fog computing systems’ performance.
    As a result, it’s critical to carefully choose the simulation tools and datasets
    suitable for the particular use case [102]. The majority of studies use randomized
    data or fail to identify the application as data and tasks that are delegated
    to other fog nodes. Nevertheless, a limited number of researches, such as [14],
    have used real datasets. Consequently, the outcomes of most of experiments may
    not be applicable to addressing real-world applications that need low latency
    or real-time execution. The absence of appropriate datasets and a simulation environment
    that accurately reflects the intricate nature of the fog space is a significant
    challenge. F. Scalability and Throughput As the number of nodes in the network
    increases, the system’s efficiency is significantly diminished. The issue of managing
    massive networks of fog will provide a significant obstacle to the system. In
    the technique described in reference [2], the maximum number of fogs is limited
    to 16, and only a single SDN controller is used. Just 5 fogs used in [29], [90]
    and in real testbed fog node limited to 2 fog in [50], 6 fogs in [13]. Other algorithms
    have also been presented with more fogs, but only a limited number of fogs have
    been tried in small spaces and networks. It has been observed that as the number
    of fogs increases, there is a considerable loss in efficiency. The use of more
    fog nodes in the experiments resulted in a reduction in the overall waiting time
    for tasks [13]. Delay or waiting time is one of the main metrics of related researches
    that is in front of the efficiency of systems, so should be considered. Scalability
    is a significant challenge, particularly in systems with many devices and fogs.
    High overhead approaches may need help scaling efficiently, affecting their viability
    in real-world applications. This can be true of communication overhead, compute
    overhead, or resource allocation. It is crucial to thoroughly evaluate the scalability
    of the suggested algorithms, particularly in practical smart city implementations,
    where the quantity of devices and fog resources may be much greater. G. Security
    and Privacy Maintaining data security and privacy throughout offloading procedures
    is an important yet difficult component. Many current techniques may disregard
    strong security safeguards, putting sensitive data at risk. The [12] merges fog
    computing, SDN, and blockchain to create a security framework for IoT in agriculture.
    By combining blockchain technology with SDN controllers, this design emphasizes
    safe IoT communication. This increases security and dependability, particularly
    for devices with limited resources. If the fog nodes in smart healthcare systems
    lack robust security protocols, there is a risk that malevolent users may be able
    to steal users’ private data. In addition, fog computing must address emerging
    issues, like resource limited IoT devices and insider assaults. In order to address
    these difficulties, [7] suggests implementing a secure authentication system for
    fog nodes in intelligent healthcare based on SDN. The system involves the implementation
    of an authentication algorithm in the SDN gateway to verify the credibility of
    the fog node. The IoT devices only need to transmit their privacy and functional
    properties to the SDN gateway to reduce the computational burden on the IoT devices.
    In the context of fog offloading, where the network environment is constantly
    changing, it is crucial to prioritize secure communication, authentication, and
    authorization. Nonetheless, these aspects have been overlooked in the majority
    of previous research and have not been taken into account. Software-Defined Networking
    (SDN) enables more effective management of these issues via its centralized control
    structure. The centralized method enables the application of security rules and
    network settings in a dynamic and flexible manner, capable of adjusting to evolving
    network circumstances and threats. SDN facilitates enhanced network visibility,
    a critical factor in detecting and addressing security breaches and anomalies.
    SDN facilitates the implementation of encryption, firewalls, and intrusion detection
    systems by unifying control. Conversely, in the absence of SDN, maintaining security
    in fog offloading settings necessitates the use of decentralized methods. This
    involves the implementation of distributed firewalls and intrusion detection systems
    at several network nodes. Effective communication in such situations depends significantly
    on effective peer-to-peer authentication techniques and resilient encryption mechanisms.
    Periodic updates and manual adjustments are essential to align security rules
    with the changing network environment. This technique requires more coordination
    among various network components and may exhibit less adaptability in rapidly
    evolving circumstances as compared to SDN-enabled systems. However, it enables
    a decentralized approach to security, which might be advantageous in situations
    where centralized control is impractical. A complete security architecture that
    includes secure communication, dynamic authentication, strong authorization, network
    segmentation, monitoring, blockchain integration, frequent updates, and user education
    is required due to the changing fog offloading scenario. Every aspect plays a
    vital role in strengthening the fog environment while adjusting to its constantly
    changing circumstance. H. Other Chalenges As indicated in Table 2, most current
    studies do not incorporate cloud offloading in their simulations and implementations.
    This omission can lead to delays in many scenarios due to the absence of a comprehensive
    and accurate integration of cloud services. If the cost and delay associated with
    cloud offloading are less than those of using other fog nodes, the efficiency
    of such algorithms in evaluating cloud offloading remains unaddressed. Consequently,
    when tasks are only offloaded to other fog nodes instead of the cloud, this may
    result in increased delays and costs, leading to reduced system efficiency. Due
    to the dynamic nature of the fog environment, it comprises many fogs with distinct
    memory capacities and processing capabilities. Conversely, the ongoing tasks vary
    in size and have varying deadlines. The intelligent organization of these tasks
    is a challenge faced by the majority of systems and algorithms since it aims to
    maximize the efficiency and capacity used by the fog computing infrastructure.
    For instance, in a scenario where there are three distinct fogs with varying available
    capacities and three different sizes of tasks (small, medium, and large), the
    optimal approach would involve transferring larger tasks to a fog with higher
    capacity and medium tasks to a fog with a proper capacity, smaller tasks to a
    fog with a sufficient capacity. Suppose a fog with more computational capacity
    is allocated to a minor task for any reason like it first come. In that case,
    the computational capacity of other fogs may not be sufficient for the enormous
    task, resulting in a potential delay in completing the task owing to the absence
    of a suitable fog with enough capacity. While several algorithms for resource
    and task management merely include these factors, managing resources and tasks
    concurrently to optimize task offloading efficiency and load balancing is still
    a significant and unavoidable difficulty in large-scale systems and real-time
    tasks that are ignored in most researches. One potential option to address this
    difficulty and enhance fog systems load balancing is integrating SDN with machine
    learning techniques. SDN may get the latest information on forthcoming tasks and
    fog resources. Machine learning can then use the knowledge stored in SDN to forecast
    future events and tasks and choose the most appropriate fog resource for offloading.
    Most previous studies assumed that the task size and fog capacity were the same.
    However, instead of using actual tasks, they have used randomly generated data,
    which fails to accurately depict the present state of the fog network in terms
    of task transmission, task processing, and real-time response. Addressing these
    gaps highlights the need for more flexible and comprehensive offloading approaches
    in the fog computing realm. Fog offloading solutions must improve with strategies
    that balance energy efficiency, scalability, security, flexibility, and latency
    in dynamic settings in a way that considers real-world implementation circumstances.
    SECTION VI. Discussion When a fog is overwhelmed, tasks should be transferred
    to another fog since it cannot process them (known as fog-to-fog offloading).
    In real-time computing, the process of determining and choosing the optimal destination
    node with adequate processing capacity in the quickest possible time is critical.
    Furthermore, most models disregard heterogeneity in computer infrastructure. In
    most present algorithms, when a fog gets overloaded, it asks that the central
    server introduce the destination node for offloading. Before determining which
    node to deploy, the central server evaluates and compares the available nodes.
    It takes a long time to request the central server, perform the decision algorithm,
    respond to the initial node, and ultimately upload data to the destination node.
    Also, choosing the optimum method to convey data from the main fog to the target
    fog is difficult since the selected path may be delayed due to traffic congestion.
    Because of traffic congestion on a particular route, another fog node with an
    acceptable and sufficient bandwidth for data transmission may be used. The issues
    in fog-to-fog offloading include making a judgment about picking fog with adequate
    resources in the shortest period and choosing a suitable way to transmit data.
    In older frameworks, time issues are explored from a limited perspective, and
    computing resources could be used more effectively. Implementing an efficient
    task management strategy is required to address this issue since computational
    strain increases the overall delay time, deployment costs, and energy consumption
    of IoT devices or resource-enriched fog nodes. Real-time processing is hampered
    by the AI algorithms utilized in these techniques, which also introduce significant
    delay and overload into the system. When looking into fog-to-fog algorithms utilizing
    SDN, many things could be improved. Fog selection is one of the main obstacles
    in the decision-making process and destination because it requires a decision-making
    algorithm that is time consuming and high cost in real-time processing. On the
    other hand, increasing the amount of network traffic and fog reduces system efficiency,
    which is a significant difficulty faced by the majority of these algorithms. The
    network data plan is not believed to successfully choose the connection for offloading
    to the destination. Additionally, connection traffic and data plans should be
    adequately taken into account when choosing a fog, which might cause data transmission
    to the target fog to be delayed. If the link fails, the offloading process will
    also halt and fail. A summary of the methods used in task offloading schemes is
    provided in TABLE 4. Fog-to-fog offloading concerns and difficulties need a study
    and enhancement of decision selection and route selection algorithms with appropriate
    use of SDN-based networks’ capabilities. To expedite and enhance the fog offloading
    algorithms, it effectively employs the characteristics and capabilities of SDN
    networks, and artificial intelligence is crucial. Due to the advancement of artificial
    intelligence and machine learning in multiple sectors, many of the diverse fog
    offloading techniques that have been seen have turned to employing AI. These algorithms
    present several difficulties owing to their high computational cost and the limited
    computing resources available in the network for fog, even though they have been
    highly successful in improving estimates for fog and clouds. Challenges like:
    While computational resources are scarce in fog, they are ample for computing
    machine learning, deep learning, and artificial intelligence algorithms. Contrastingly,
    the amount of bandwidth and communication burden required to transmit data between
    devices for offloading decisions makes fog offloading more challenging. TABLE
    4 Summary of Methodology Used in Task Offloading Schemes The term “link prediction-based”
    refers to a technique for maximizing traffic offloading that is based on link
    prediction. The link prediction-based strategy prioritizes traffic offloading
    by selecting relevant seed nodes for efficient data transmission while keeping
    quality of service (QoS) in mind. To optimize overall performance, it is vital
    to establish a balance between traffic dumping and minimizing time delay [103].
    Link prediction methods can assist in determining the optimum link and node to
    offload. In prior studies of resource management that can be addressed as future
    research, heterogeneity or homogeneity of fog nodes is an essential factor that
    keeps the same for different fogs. Another issue for future task management studies
    is partial or whole task offloading. The algorithms should divide and distribute
    tasks efficiently based on task size and priority. Depending on the fog processing
    constraints and task size, each task may offload partially or fully. Aside from
    time and delay, energy consumption and algorithm computation cost are essential
    metrics for fog offloading techniques that are often overlooked in many suggested
    algorithms and should be considered in future studies. While SDN has many benefits,
    it also has certain drawbacks. Latency remains an issue since faraway fog nodes
    or data centers introduce inevitable delays. The complexity of SDN deployment,
    possible security issues from centralized management, and increased network overhead
    may impede adoption. Interoperability concerns might develop, especially in heterogeneous
    fog computing environments, and the initial expense of specialized hardware and
    software may dissuade some organizations from using SDN for fog offloading. SDN’s
    applicability must be determined by carefully examining individual use cases and
    needs. Fog computing simulation has a number of drawbacks, such as issues with
    model accuracy, scalability, the lack of real-time elements, overhead, abstraction,
    and dependence on behavioral assumptions. It may be difficult to effectively simulate
    the dynamic nature of fog computing with constantly changing workloads and network
    circumstances. Further impediments include incomplete network models, problems
    with validation and verification, and low predictive power. Large-scale and resource-intensive
    simulations may also be difficult to execute due to resource limitations. Although
    simulations provide insightful information, they should be utilized with caution,
    and the findings should be interpreted considering these limitations. Real-world
    testing and simulation combined may lead to a more comprehensive knowledge of
    fog computing systems. SECTION VII. Conclusion and Future Work Most of the examined
    related fog offloading algorithms do not take a holistic approach to resource
    management, task management, and task offloading in the same system, instead focusing
    on one or two of these three critical components. Lake of this viewpoint will
    encounter several obstacles in implementing these algorithms in real-world complicated
    settings with various types of tasks and diverse fogs hardware and software with
    changing resources simultaneously. As a result, fog offloading systems need further
    development to be highly adaptable to IoT’s diverse and extensive real-time task
    response. SDN provides various advantages for fog offloading in computer systems.
    It enables network flexibility by enabling dynamic and programmable configurations
    to react to changing workloads. Centralized control streamlines decision-making
    for task offloading, optimizing routing, and enhancing service quality. SDN is
    a crucial tool for practical fog computing since it improves traffic optimization
    and scales to handle the rising number of IoT devices and fog nodes. SDN can manage
    the fog network effectively. However, its centralized and unique architecture
    does increase the possibility of initial implementation expenses. Machine learning
    may be helpful for fog processing if it transfers little data across the network
    while using far fewer computing resources. Machine learning may determine the
    decision-making process in choosing the connection link for data transmission
    and the fog destinations for offload. Selecting an efficient machine learning
    algorithm that decreases the computational burden on the network with its few
    connections and computation resource will be a problem solver. Therefore, future
    studies aim to speed up and enhance the fog-to-fog algorithm by efficiently using
    the capabilities and characteristics of SDN networks and artificial intelligence.
    Furthermore, the implementation of additional SDN controllers and Fog networks
    on a wider scale, together with conducting rigorous testing in real-world scenarios
    and networks, is viable. likewise, exploring the integration of SDN networks with
    both centralized and decentralized networks outside the realm of SDN may serve
    as a viable approach to accommodate and merge novel and more expansive networks
    and smart city challenges. ACKNOWLEDGMENT Any options, finding, and conclusion
    or recommendation expressed in this material are those of the author(s) and do
    not necessarily reflect the views of the United States Air Force. Authors Figures
    References Keywords Metrics More Like This Software-Defined Networking for Internet
    of Things: A Survey IEEE Internet of Things Journal Published: 2017 A Software-Defined-Networking-Enabled
    Approach for Edge-Cloud Computing in the Internet of Things IEEE Network Published:
    2021 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details
    PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES
    PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678
    4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact
    Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics
    Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE
    is the world''s largest technical professional organization dedicated to advancing
    technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: IEEE Access
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Fog Offloading and Task Management in IoT-Fog-Cloud Environment: Review
    of Algorithms, Networks, and SDN Application'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Bera S.
  - Dey T.
  - Ghosh S.
  - Mukherjee A.
  citation_count: '1'
  description: Internet of Things has revolutionised our daily life by providing varied
    smart applications. Smart healthcare, smart home monitoring, smart city, smart
    retail, etc., are various sectors where Internet of Things serves as the principal
    element. Agriculture is one of the significant sectors of a country that also
    seeks smart solutions. The use of Internet of Things in agriculture has become
    popular in the last few years. In this chapter, we discuss the use of Internet
    of Things in smart agriculture along with the use of dew computing. The dew computing
    paradigm is able to provide access to the data even offline. The architecture
    of dew computing-based smart agriculture has been demonstrated. Various machine
    learning algorithms used for data analysis have been discussed. The advantage
    of using dew computing over the conventional cloud-only system, edge/fog computing-based
    system, are also highlighted in this chapter. From the simulation results, we
    observe that the dew computing-based paradigm has approximately 40% and 55% lower
    latency than the edge-based and cloud-only paradigms, respectively.
  doi: 10.1007/978-981-99-4590-0_14
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Log in Find a journal
    Publish with us Track your research Search Cart Home Dew Computing Chapter Internet
    of Things and Dew Computing-Based System for Smart Agriculture Chapter First Online:
    03 September 2023 pp 289–316 Cite this chapter Access provided by University of
    Nebraska-Lincoln Download book PDF Download book EPUB Dew Computing Somnath Bera,
    Tanushree Dey, Shreya Ghosh & Anwesha Mukherjee  Part of the book series: Internet
    of Things ((ITTCC)) 140 Accesses 1 Citations Abstract Internet of Things has revolutionised
    our daily life by providing varied smart applications. Smart healthcare, smart
    home monitoring, smart city, smart retail, etc., are various sectors where Internet
    of Things serves as the principal element. Agriculture is one of the significant
    sectors of a country that also seeks smart solutions. The use of Internet of Things
    in agriculture has become popular in the last few years. In this chapter, we discuss
    the use of Internet of Things in smart agriculture along with the use of dew computing.
    The dew computing paradigm is able to provide access to the data even offline.
    The architecture of dew computing-based smart agriculture has been demonstrated.
    Various machine learning algorithms used for data analysis have been discussed.
    The advantage of using dew computing over the conventional cloud-only system,
    edge/fog computing-based system, are also highlighted in this chapter. From the
    simulation results, we observe that the dew computing-based paradigm has approximately
    40% and 55% lower latency than the edge-based and cloud-only paradigms, respectively.
    Access provided by University of Nebraska-Lincoln. Download chapter PDF Similar
    content being viewed by others Effective Contribution of Internet of Things (IoT)
    in Smart Agriculture: State of Art Chapter © 2022 Smart Agriculture Management
    System Using Internet of Things (IoT) Chapter © 2021 Smart Farming: Application
    of Internet of Things (IoT) Systems Chapter © 2021 Keywords Internet of things
    Dew computing Machine learning Agriculture Latency 1 Introduction The “Internet
    of Things (IoT)” facilitates data collection, processing, and exchange by connecting
    devices and communication paths. The goal of the IoT is to create a smart environment
    by using intelligent things, items, and devices with communication and sensing
    capabilities, which can generate data on their own and communicate the data over
    the Internet [1]. IoT is defined as a network of numerous “things” or “objects”
    around us, such as sensors, mobile phones, and Radio Frequency Identification
    (RFID) tags, which enable them to communicate with one another and successfully
    carry out their responsibilities. These choices are made in order to deal with
    challenges relevant to human living, such as energy conservation, climate change,
    mobility, healthcare, business logistics, building automation, etc. IoT is a technology
    that naturally supports the establishment of autonomous federated services and
    applications. It is distinguished by a high level of autonomy in data collection,
    event transmission, network connectivity, and interoperability. Things concentrate
    on combining generic objects into a framework that is easy to use, whereas the
    Internet works on creating an integrated network. IoT uses the Internet as a communication
    and information-exchange medium with the goal of fusing the real world with the
    virtual one. IoT is described as a network of interconnected computing devices,
    objects, animals, mechanical and digital machines, or people, with unique identifiers
    [1], and can transmit data over a network. The tremendous influence the IoT idea
    will have on a number of facets of daily life and potential consumers’ behaviour
    is without a doubt its greatest strength. IoT is a technological innovation, and
    according to the idea of innovation diffusion, consumer acceptance of new technology
    is highly influenced by how it is introduced and how beneficial the user perceives
    it to be. Users will more readily embrace technologies in their daily lives if
    they believe that they are simple to use and allow them to contribute more. The
    most evident effects of the implementation of IoT will be visible from the perspective
    of individual users in the working place as well as at home. It is also widely
    utilised to access multimedia information and services as well as other diverse
    tasks via social network applications, with statistics showing that about two
    billion people use the Internet daily [2, 3]. In addition to being successfully
    used in various fields, IoT is successfully implemented in the agriculture field
    also. IoT-based solutions are being created to autonomously monitor and maintain
    agricultural crops with the least amount of human participation. IoT has significantly
    changed the environment for agriculture by examining many difficulties the farmers
    face. In the field of agriculture, technological applications are employed to
    lower costs and increase agricultural yields or quality. The use of WSN in satellite
    agriculture provides farmers with statistical support, enabling them to make more
    informed decisions. With the development of technology today, it has been predicted
    that agriculturalists and technologists will use IoT to solve difficulties the
    farmers face, such as water shortages, concerns with cost control, and productivity
    problems. By continuously monitoring the field, IoT-based smart farming enhances
    the overall agricultural system [4]. Modern IoT technologies have identified all
    these problems and fixed them to raise productivity while decreasing costs. The
    IoT in agriculture has reduced the lavish use of resources like water and electricity
    and saved farmers’ time by utilising sensors and connections [1, 5]. The IoT is
    producing an unprecedented volume of data, which in turn strains the Internet’s
    infrastructure severely. Large corporations are therefore trying to figure out
    how to lower that pressure and address the data problem. In particular, by enabling
    all of the connected devices to collaborate, cloud computing will play a significant
    role in that. Aggregating data and gaining insights from it require the use of
    the cloud. Data comparison over larger areas is substantially more challenging
    without the cloud. Additionally, high scalability is another benefit of using
    the cloud [6, 7]. Sharing resources is a major component of cloud computing, which
    is essential for IoT platforms. In addition to sharing resources, cloud computing
    also makes the most of them. Additionally, cloud services are accessed by users
    from any area and on any device with an Internet connection. When discussing the
    IoT platform, it should be accessible 24/7 from any location [8]. The mission
    of passing down human knowledge to future generations can be accomplished very
    effectively with cloud computing. Farmers all over the world use IT tools to manage
    and distribute their crop-related data quickly and easily. The farming sector
    is also deploying additional hardware and software resources for measuring luminance
    as well as temperature, humidity, and soil moisture. Agriculture’s modernisation
    lessens its reliance on the climate, improves the use of already-available resources,
    and quickly disseminates information about new methods and resources. Additionally,
    it offers contemporary agricultural machinery, planting and breeding techniques,
    weather observation and forecasts, and production management and organisation
    techniques [9]. Building a network of interconnected smart devices is made possible
    by cloud computing and IoT. The computing problems cannot yet be solved using
    these two approaches. Inextricably linked to IoT, the new paradigm of fog computing
    expands the cloud by extending some services to the network edge near the end
    users in an effort to lessen the computational load on the network. Additionally,
    fog computing is mainly introduced for applications that require low latency real-time
    processing. Large-scale, geographically dispersed fog nodes placed at the edge
    of networks make up the fog layer [10]. Fog is dependent on the availability of
    computing, storage, and networking resources, just like the cloud. Servers or
    networking hardware with more processing power may be used as fog nodes. Fog computing
    seeks to bring processing power closer to the customers while preventing the overuse
    of cloud resources and further reducing computational burdens. The most crucial
    pieces of information are transmitted while any extraneous data is filtered out
    and deleted according to the fog computing paradigm. Utilising end-device resources
    to give the network a better intelligence distribution and improve performance
    is one of the key objectives of fog computing. Servers or networking hardware
    with additional processing power can act as fog nodes. Even wireless access points
    could include them. The majority of the time, fog nodes will be placed near end
    users at the network’s edge [11]. Additionally, by providing storage, processing,
    networking, and data management on network nodes close to IoT devices, fog computing
    serves as a bridge between the cloud and the edge. For farmers and other agricultural
    stakeholders, agriculture is made simple by these distinctive qualities. For instance,
    it may be necessary to swiftly and locally process sensitive data collected by
    all devices [12]. There is another emerging area called edge computing. Edge computing
    has been proposed to increase efficiency and address cloud-related problems by
    providing local data processing and storage at the end devices. In order to meet
    the high computation and low-latency needs of deep learning on edge devices, edge
    computing is a viable option. It also offers additional advantages in terms of
    privacy, bandwidth efficiency, and scalability. Edge computing allows data to
    be examined near the source, sometimes by a local trustworthy edge server, avoiding
    the public Internet and minimising vulnerability to privacy and security assaults.
    This helps to address privacy challenges [13, 14]. In the agricultural sector,
    edge computing is mainly used for pest identification, product safety tracking,
    autonomous agricultural equipment, agricultural technology promotion, intelligent
    management, etc. Furthermore, by delivering cloud capabilities close to end users,
    edge computing supports the transition to fifth generation (5G). To maximise the
    benefits in agriculture, edge must be combined with other computing technologies
    like cloud and fog [15, 16]. For edge, fog, and cloud computing, Internet connectivity
    is required. However, if the network connectivity is interrupted, then the quality
    of service is reduced. Here, dew computing is one of the feasible options. Dew
    computing enhances the offering of human-aware customised services at the network’s
    edge. Dew computing is an innovative form of computer organisation and architecture
    that builds on the practical cloud and conventional client–server architecture.
    In order to complete a task, cloud computing offers service models, fog computing
    permits “on-the-spot” on-network processing, and edge computing makes use of computation
    of tasks that were started at network edges. All the mentioned generic model is
    expanded upon by dew computing to a sub-platform paradigm [17, 18]. In this chapter,
    we specifically focus on the utility of dew computing in agriculture. In Sects.
    2 and 3, we discuss the use of machine learning and deep learning in agriculture,
    respectively. In Sect. 4, we demonstrate the use of IoT in agriculture. Section
    5 briefly discusses cloud, fog, edge, and dew computing. Section 6 illustrates
    the use of dew computing in agriculture. Finally, Sect. 7 concludes the chapter.
    2 Machine Learning in Agriculture In recent years, machine learning (ML) techniques
    are largely used in the agriculture domain for improving the productivity and
    quality of the crops [19, 20]. ML algorithms are used for a particular crop to
    determine the condition in which the best yield would be produced. ML models have
    the ability of decision-making and can take actions in a real-world framework
    with minimal human interaction. ML, a subset of artificial intelligence (AI) that
    focuses on learning, can estimate yields more accurately utilising a variety of
    features. ML may extract information from datasets by finding patterns and correlations.
    The models must be trained using datasets depicting the outcomes based on prior
    knowledge. Multiple features are used to build the predictive model, and as a
    result, the model parameters are selected using the historical data during the
    training phase. A part of the previous dataset is used in the testing phase for
    evaluating the performance. Depending on the research issue, the ML model can
    be categorised as descriptive or predictive. For gaining and explaining knowledge
    from collected real-time data, we use a descriptive model, whereas for predicting
    the data for the future, we use a predictive model. Hence, there is a challenge
    for ML studies to choose the appropriate algorithm for solving the problem at
    hand. Single sample spaces can be predicted using traditional statistical methods.
    Additionally, using ML techniques, many predictions can be made. Unlike ML approaches,
    where we must take the structure of data models into consideration, traditional
    methods do not require this [19, 20]. In precision agriculture, crop production
    prediction is a challenging issue, and various models have been proposed. Since
    agricultural production varies on a wide range of variables, including soil, weather,
    climate, seed variety, and fertilizer use, this problem makes the use of several
    datasets essential. This shows that predicting agricultural yields involves a
    number of challenging processes and is not a simple operation [21]. The three
    most important parameters to consider when estimating the amount of water needed
    in each agricultural crop are moisture, temperature, and humidity. The sensors
    for measuring temperature, humidity, and moisture are placed in an agricultural
    field, and the collected data is analysed inside the cloud. ML techniques such
    as decision tree are applied to the collected data [22]. Machine learning (ML)
    facilitates extracting useful insights from huge volume of data by analyzing,
    correlating with contexts, and finding interesting but previously unknown patterns.
    According to the learning type (supervised or unsupervised), models are used to
    accomplish the chosen goal. ML tasks are often divided into a variety of broad
    categories discussed as follows: Categorized tasks of ML: ML techniques are usually
    categorised as supervised and unsupervised learning. In supervised learning, the
    software is trained using training examples before being used to draw an accurate
    conclusion from the incoming data. Supervised learning techniques include artificial
    neural networks, decision trees, Bayesian networks, support vector machines, Interactive
    Dichotomizer3 (ID3), and k-nearest neighbour algorithms, among others. Unsupervised
    ML involves feeding software with huge data, and the programmes will uncover patterns
    and connections between them. Therefore, to find hidden patterns in the data,
    unsupervised learning can be used. K-means clustering, self-organising maps, partial-based
    clustering, and k-nearest neighbour are a few examples of unsupervised learning
    algorithms. Supervised learning algorithms employ labelled training data for inference
    (classification, regression). Unsupervised learning algorithms use unlabelled
    data to find hidden patterns in the existing data (clustering) [23]. Interpretation
    of learning: In order to reserve information as much as possible from the original
    data, dimensionality reduction (DR), an approach that is used in both supervised
    and unsupervised learning, aims to provide a more condensed, lower-dimensional
    representation of a dataset. In order to mitigate the effects of dimensionality,
    it is typically carried out before using a classification or regression model.
    Principal component analysis [24] and linear discriminant analysis [25] are the
    popular DR algorithms. ML models: ML techniques can be utilised for agricultural
    purposes to forecast crop production, soil monitoring, crop growth monitoring,
    etc., because the data amount is vast and growing daily. The process of classifying
    is the transformation of an input set of instances into a specific set of attributes,
    also referred to as target attributes or labels. Numerous applications employ
    categorization methods such as bayesian classifiers, decision tree classifiers,
    artificial neural networks, nearest neighbour classifiers, random forests, and
    support vector machines [26]. Various ML models are described as follows: (i)
    Decision Tree: Decision tree is a very popular and simple classifier for handling
    classification issues. Decision tree models incorporate nodes, branches, terminal
    values, strategy, payout distribution, specific equivalents, and the rollback
    procedure. In a decision tree, objects are arranged in a graph according to the
    values of their features in order to be classified. This algorithm is built in
    two steps: first, a massive decision tree grows, then its size is reduced and
    it is pruned in the second phase if it is overfitting the data. The depicted classification
    tree is the trimmed decision tree that is employed for categorization. The prediction
    is influenced by a number of things. To construct the yield mapping and anticipate
    the production, agronomic data, nitrogen treatment, and weed management utilise
    ML algorithms like artificial neural network (ANN) and decision tree [27]. They
    come to the conclusion that ANNs can produce high prediction accuracies. Decision
    tree was used for detailed modelling of soybean productivity [28]. They took into
    account environmental elements like evaporation, the highest possible temperature,
    the highest possible relative humidity, rainfall, and crop yield for soybean.
    They used the ID3 algorithm, an information-based technique that is predicated
    on two presumptions. The soybean crop production is significantly influenced by
    the relative humidity. There are certain criteria developed that aid in the low
    and high soybean production prediction since relative humidity has a significant
    impact on soybean yield. (ii) Bayesian classifier: Sometimes prediction of class
    labels for a given set of input attributes can be challenging. Even when matching
    some of the attributes from the training data set with values from the input attribute
    set, class variables are nondeterministic. This is plausible given the existence
    of certain noisy data and perplexing elements, which are ignored during processing.
    In such applications, it is necessary to describe the probabilistic correlations
    between the attribute set and the class label; the bayesian classifier focuses
    on explaining such tasks. This kind of model falls under the field of supervised
    learning and can be used to address classification or regression issues. Some
    of the most well-known algorithms in the literature are Naive Bayes [29], Gaussian
    Naive Bayes, and a mixture of Gaussians [30]. (iii) ANN: ANN, a supervised learning
    method is based on the biological process of our brain. Once trained, a neural
    network may predict patterns in future data that are comparable, for example,
    producing meaningful solutions to issues even when the input data is inaccurate
    or incomplete. ANN is a connectionist system; given a weight, each connection
    is in charge of sending a signal from one node to another. Before sending a signal
    to another node, a node examines the signal it has just received. In ordinary
    ANN implementations, the signal at each artificial neuron''s connection is essentially
    a real number, and each neuron''s output is obtained by a nonlinear function of
    the sum of all of its inputs. ANNs can absorb complexity without being aware of
    the underlying concepts. Any process can use ANN to determine the relationship
    between input and output [31]. ANN was used to forecast potato production in Iran
    based on input energy and to design output energy and greenhouse gas emissions
    (GHG) [32]. In terms of energy usage, power, chemical fertilizer, and seed were
    the three main factors. To confirm the symptoms of the tomato crop, artificial
    intelligence and ML algorithms (particularly ID3) were used to create a web-based
    expert system with Java at the front end and SQL at the back end [33]. The professional
    arrangement had two key components: a tomato knowledge system and an expert system,
    where the applicant may acquire all the reliable information on various topics
    such as varieties, symptoms of pests and illnesses, cultural practises, and a
    mosaic of tomato fruits and plants via message. ANN was used to present the intelligent
    control system for efficient irrigation scheduling [34]. Models were created using
    input variables including air temperature, soil moisture, radiation levels, and
    humidity. The amount of water required for irrigation was then assessed using
    the proper method, ecological conditions, evapotranspiration, and crop type, after
    which associated effects were simulated. The suggested system was contrasted to
    an ON/OFF controller, and it was demonstrated that due to these constraints, the
    ON/OFF controller-based system failed. However, ANN-based approaches have made
    it possible to adopt stronger and more effective control. Convolutional neural
    networks and generative adversarial networks (GAN) were combined in the suggested
    ANN-based approach [35]. Due to its capacity for knowledge accumulation and forgetting
    reduction, the suggested method was able to recognise all categories from both
    new and old tasks with good performance. In [36], the artificial neural network
    was used to estimate the crop utilising soil characteristics including soil type,
    nitrogen, pH, phosphate, potassium, calcium, organic carbon, magnesium, manganese,
    sulphur, copper, and iron as well as climate parameters like temperature, rainfall,
    and humidity. Crops like sugarcane, cotton, bajara, jawar, soybeans, corn, rice,
    wheat, and groundnut were used in the experiment. (iv) Regression analysis: Regression
    is a type of supervised learning model that seeks to produce an output variable
    based on known input variables. The most popular algorithms are stepwise regression,
    logistic regression, and linear regression. Additionally, more sophisticated regression
    methods have been created, including multiple linear regression and multivariate
    adaptive regression splines. For agriculture-related organisations, consultants,
    producers, etc., crop output is crucial. Crop forecasting can be done using a
    variety of data types, including soil, remote sensing, agro-metrological, and
    agricultural statistics. Marketing, storage, and transportation decisions depend
    on accurate and timely forecasting. The construction of a crop prediction model
    was examined in [37], and it was shown that planting methods, particularly the
    application of the proper quantity of fertilizer, had a significant impact on
    corn production rather than climate-related variables as the key predictors of
    yield. For the purpose of predicting the yield, a model was built by employing
    the fortnightly weather variables, such as average daily maximum and lowest temperatures,
    morning and evening relative humidity, total fortnightly rainfall, and the yield
    data of the sugarcane [38]. Their forecast model was able to account for 87% of
    the fluctuation in the sugarcane output. They also concluded that two months prior
    to harvest, the sugarcane production might be successfully forecasted using the
    regression technique. Although there are several statistical methods for agricultural
    production, regression analysis is one of the mostly used methods [39]. (v) Clustering:
    The practise of finding things that are similar to one another but distinct from
    individuals in other groups is known as cluster analysis or clustering. As the
    similarities between things in one group and the differences between objects in
    various groups increased, the clustering would get better. The fundamental technique
    of data mining is clustering, which has numerous applications in areas including
    agriculture, image analysing, pattern recognition, data compression, machine learning,
    etc. In addition to classification, segmentation, and partitioning, clustering
    can also be used to categorise items. Cluster analysis and classification are
    comparable; thus we can define clustering as unsupervised learning. Classification
    and cluster analysis are distinct from one another since clustering does not preserve
    class information whereas classification does. Additionally, cluster analysis
    suggests categories based on data patterns as opposed to classification, which
    classifies fresh samples into known classifications [40]. There are many clustering
    algorithms, including k-means, the expectation maximisation technique, k-medoid,
    hierarchical clustering, and others, but k-means is the most popular and significant
    one [26]. Numerous factors contribute to the popularity of hierarchical clustering,
    including the following: Unlike k-means clustering, which demands a particular
    value, it does not. The tree that was constructed has useful taxonomy. Only the
    distance matrix is needed to calculate the hierarchical clustering. To evaluate
    the prediction of crop properly, k-means clustering algorithm was demonstrated
    in [41]. The modified k-means clustering technique is given the determined number
    of clusters and starting cluster centres. The same determined value of the number
    of clusters is provided and initial cluster centres are uniformly picked because
    the number of clusters (k value) is required at the beginning for standard k-means
    and k-means++. By contrasting k-means and k-means++ methods, the modified k-means
    clustering algorithm is evaluated and found to produce the greatest number of
    high-quality clusters, accurate crop predictions, and the highest accuracy count.
    (vi) Support Vector Machine (SVM): The general discriminant classifier or SVM
    is frequently employed in the field of pattern recognition. The SVM model uses
    the concept of a surface called a hyperplane to represent a number of classes,
    with the border between the data examples being drawn and shown in multidimensional
    space. By employing the “kernel trick”, it is possible to significantly improve
    the classification skills of conventional SVMs by converting the original feature
    space to a feature space with a larger dimension [42]. Non-separable problems
    are converted into separable problems [43]. SVMs are based on global optimization
    and handle overfitting issues raised in high-dimensional spaces, which makes them
    appealing in a variety of applications [44]. The support vector regression algorithm
    [45], least squares support vector machine [46], and successive projection algorithm
    [47] are three popular SVM algorithms. (vii) k-Nearest Neighbour (k-NN): The k-nearest
    neighbour (k-NN) method is a supervised learning classifier, which applies proximity
    for generating classifications or predictions regarding the grouping of a single
    data point. Though, for classification or regression it can be used, it is generally
    used for classification as it is based on the concept that comparable points close
    to one another are discoverable. It is computed how far away every data point
    in the training collection is from the specified test example. The k points which
    are closest to the data point are known as the k-Nearest Neighbour. The classification
    of the data point then depends on the class labels of its neighbours [48]. If
    a data point has more than one neighbour with a class label, the class label that
    contains the most class labels is applied to the data point. The exact value of
    k''s closest neighbours must be established. The noise that is present in the
    training data may cause misclassification if the value of the k is too low. However,
    if the value of k is too high, there is a risk of misclassification since the
    collection of nearest neighbours can include data points, which were already located
    distant from the area surrounding the test characteristic [49]. In [50], real-time
    environmental measurements were taken in Mangalore, Kodagu, Kasaragod, and other
    districts of the state of Karnataka. These measurements included soil type, rainfall,
    humidity, etc. The values of the closest known neighbours can be used to predict
    the crop yield, which is an unknown value. Calculating the Euclidian distance
    between those places makes this achievable. Thus, for the specified input parameters,
    crop yield may be predicted. Different distance functions, including the most
    often used one, the Euclidean distance function, could be used to calculate the
    distance between points in a feature space. Let''s assume that \\(p\\) and \\(q\\)
    are shown as feature vectors. The Euclidean metric is typically used to calculate
    the distance between \\(p\\) and \\(q\\). If \\(a = ({a}_{1},{a}_{2})\\) and \\(b
    = ({b}_{1},{b}_{2})\\), the distance is given by Eq. (1). $$\\mathrm{d}(\\mathrm{a},\\mathrm{b})
    = \\sqrt{{({b}_{1}-{a}_{1})}^{2}+ {({b}_{2}-{a}_{2})}^{2}}$$ (1) (viii) Random
    Forest: The supervised machine learning technique known as “random forest” consists
    of many decision trees created using random vectors, each of which makes a decision.
    Regression techniques and classification problems can be addressed using this
    strategy. It is based on ensemble learning (EL), a method of integrating various
    classifiers to deal with critical issues. EL models create a linear combination
    of simpler base learners in order to enhance the prediction performance of a specific
    statistical learning or model-fitting method. The probability of receiving a more
    accurate result grows as the number of trees in the forest increases since the
    random forest''s output is inversely proportional to the number of trees it integrates
    into the forest [51]. It is crucial to understand that building a forest differs
    from building decision trees. In case of random forest (RF) classification, the
    process of locating the root node and dividing the feature nodes will be random
    [52]. RF classification is common because of its advantages; enough trees are
    available so that the overfitting issue will be avoided. Again, in this classifier,
    missing values are also handled suitably. RF classifier is used in various sectors
    such as the stock market, banking, e-commerce, medicine, agriculture, etc. [53].
    In banking, it is used to distinguish between legitimate and dishonest consumers.
    In the stock market, an RF classifier is used to watch a stock''s activity and
    then to determine its gain and loss. It can also be applied in e-commerce to predict
    product recommendations [54]. 3 Deep Learning in Agriculture The term “smart agriculture”
    refers to the extensive use of AI in agriculture, which includes big data, IoT,
    deep learning, and many other smart systems. For analysing a huge amount of data,
    deep learning [55,56,57] comes into the picture. It has immense potential, has
    shown promising outcomes, and has been successfully applied in a variety of industries,
    including agriculture [55]. The foundation of deep learning is a set of machine
    learning algorithms, which model high-level abstractions in data through a variety
    of nonlinear transformations. Deep learning (DL) has a number of benefits, including
    feature learning, which refers to the autonomous extraction of features from the
    raw data. There are different common deep learning networks used in agriculture,
    such as recurrent neural networks and convolutional neural networks, briefly described
    as follows: Recurrent Neural Network (RNN): In contrast to standard neural networks,
    RNNs are neural sequence models, which make use of the sequential information
    in the network. RNN is an adaptation of ANN, which indicates that the network''s
    current input and output are connected. The unique expression is that the network
    will remember the previously learned information and utilise it to calculate the
    output of the current network; in other words, RNN may be thought of as a Backpropagation
    (BP) neural network whose output is used as the input to the next network. Even
    though RNN theoretically solves time series problems, it is challenging to do
    so in practise since the amount of information fluctuates, which can lead to gradients
    disappearing or exploding. Input layer X, hidden layer S, and output layer Y of
    an RNN can be thought of as a short-term memory unit [56]. A development of the
    recurrent neural network, the long short-term memory (LSTM) network is primarily
    intended to address time series problems with long intervals and large delays.
    To selectively alter the present state of the RNN, LSTM relies on the structure
    of a few “doors” [58, 59]. Convolutional Neural Network (CNN): A deep learning
    method called CNN, which contains numerous convolutional layers, pooling layers,
    and fully connected layers, has made significant advancements in speech recognition,
    face identification, natural language processing, etc. [60]. As long as there
    are sufficient large data sets available for defining the problem, classifications
    will have a higher possibility of being accurate in CNN. Convolutional layers
    and pooling layers make up the structure for feature extraction, while fully linked
    layers serve as a classifier [61]. While convolutional networks first transform
    signals into features and subsequently map the features to a specified target
    value, Backpropagation neural networks primarily map features via the network
    to specific values [61]. The fully linked layers often take advantage of the high-level
    features learned at the final layer to classify the input images into predetermined
    groups. CNN models perform classification and predictions particularly effectively
    due to their highly hierarchical structure and great learning capacity. They are
    also flexible and adaptive in a broad variety of situations [62, 63]. Fully Convolutional
    Network (FCN): FCN is a CNN-based architecture that generates a semantic mask
    as output by down-sampling (convolution), followed by up-sampling (deconvolution).
    A predicted label for the input image is often produced by downscaling the input
    image and passing it through numerous convolution layers. FCN networks do not
    downscale the image, therefore, the output is not a single label, allowing for
    an upsampling of the output and the prediction of the class''s pixel-by-pixel
    characteristics [64]. CNN indicates that classification accuracy is 1–8% higher
    than SVM [65, 66], 41% advancement compared with ANN [67], and 3–11% higher than
    unsupervised learning [68]. Additionally, CNN performed better than SVM regression
    [69], Large Margin Classifier (LMC), and Naïve Bayes Classifier [70, 71]. In case
    of RNN, LSTM achieved comparatively 1% better performance than SVM and RF [72],
    and 44% advancement than SVM [73]. 4 IoT in Agriculture The traditional approach
    to agriculture is to advance modernised farming while researching relevant IoT
    areas in the agricultural sector. Systematic evaluation provides current and future
    trends in the agriculture sector. IoT has several uses in the field of digital
    agriculture, including crop growth monitoring, fertiliser selection, irrigation
    decision support systems, etc. With a wide variety of sensors being utilised for
    diverse smart agricultural goals, the IoT has also recently made a major influence
    on the agriculture sector. Utilising the Internet to connect numerous networked
    devices, such as numerous sensors, drivers, and smart objects, to mobile devices,
    provided efficient production to the smart agriculture industry. The IoT sensors
    interact with actuators and need wireless connectivity. Microprocessor, memory,
    input/output interfaces, and communication components make up the embedded system.
    There are various types of sensors including airflow sensors, mechanical sensors,
    optical sensors, location sensors, and mechanical sensors used to track and measure
    various parameters (for instance, soil nutrients and weather information) and
    temperatures of the atmosphere, different depths of the soil, precipitation, relative
    humidity, atmospheric pressure that affect production [74]. The development of
    mobile technology, wireless communication networks, and the ubiquity of services
    has made it possible for a vast amount of people to be connected to the Internet.
    The core network layer, or Internet, provides pathways for the transmission and
    exchange of data and network information between various subnetworks. Data is
    accessible anywhere and at any time due to IoT devices’ connection to the network.
    Therefore, adequate security, real-time data support, and accessibility are required
    for data transfer over the Internet [75]. Managing user interfaces, services,
    network node organisation and coordination, computing, and data processing are
    all part of cloud computing, which collects massive amounts of data for archival
    and analysis. IoT middleware and networking protocols are being created to enable
    the Internet-based connectivity of heterogeneous systems and devices. IoT middleware,
    like actor-based and cloud-based, is basically used for supporting the IoT [76].
    A crucial component of the effective implementation of IoT systems is communication
    technology. Standards, spectrum, and application scenarios can be used to categorise
    the current communication technology. Standard: Long-range and short-range communication
    standards are two categories of the communication standard. Short-range standards
    like Bluetooth, ZigBee, and Z-Wave can span a range of 100 m or less, whereas
    long-range communication protocols like LoRa, and NB-IoT can transmit data over
    a distance of up to 10 km. Long-range communication standards are within the low
    power wide area category (LPWA) that takes low power but gives a large area coverage
    [77]. Spectrum: One can divide the communication spectrum into licenced and unlicensed
    spectrum. The industrial, scientific, and medical (ISM) band, a radio frequency
    spectrum, is used in the unlicensed spectrum. On the other side, the licenced
    spectrum that has been assigned to the cellular network provides consumers with
    improved traffic management, less interference, higher reliability, increased
    quality of service (QoS), a high level of security, more coverage, and lower infrastructure
    costs. The cost of membership for data transmission as well as the transmit power
    consumption on IoT devices are disadvantages of using licenced spectrum. On the
    other side, the downsides of using unlicensed spectrum include interference, infrastructure
    costs, and security concerns. Application Scenario: Application requirements for
    the IoT device influence the choice of communication technology. A backhaul network
    or an IoT device that serves as a node can employ communication technology. Low-data-transmission
    nodes use less power and travel a very little distance. The backhaul network can
    be used over very long distances and supports high data speeds. Additionally,
    the kind of topology that will be deployed will also influence the communication
    technology that is selected for the IoT device. An IoT device performs various
    roles and tasks in each of these topologies. The function ((full function device
    (FFD) or a reduced function device (RFD)) can either be an end device or a personal
    area coordinator (PAN). Every aspect of conventional farming processes can be
    drastically altered by integrating the most recent IoT technologies. The IoT may
    now be seamlessly integrated into smart agriculture. IoT can help to deal with
    many traditional farming problems, such as drought response, yield optimization,
    land appropriateness, irrigation, pest management, etc. 4.1 Soil Sampling and
    Mapping The major goal of soil analysis is to ascertain a field''s nutritional
    status so that appropriate action can be taken when nutrient deficits are discovered.
    The cropping history, soil type, application of fertilisers, irrigation level,
    topography, etc., are important variables to consider when analysing the levels
    of soil nutrients. These variables provide information on the soil''s chemical,
    physical, and biological conditions, allowing for the identification of the constraints
    on the crops and the subsequent management of those constraints. In order to better
    match soil qualities, such as seed compatibility, sowing time, and even planting
    depth, as certain crop types are deep-rooted while others are not, soil mapping
    makes it possible to sow various crop kinds in a given area. Manufacturers are
    offering a variety of sensors and toolkits to help farmers to monitor the quality
    of the soil. These devices make it possible to keep track of soil characteristics
    including texture and water-holding capacity. Moderate resolution imaging spectroradiometer
    (MODIS) sensor was used in [78] for mapping different soil characteristics, and
    calculating the probability of land degradation in sub-Saharan Africa. Technology
    based on sensors and vision is useful in determining the distance and depth for
    effective seeding. In [79], the authors described the development of the autonomous
    Agribot seeding robot, which is sensor and vision-based. 4.2 Irrigation Since,
    fresh water must be retained in lakes, rivers, and similar reservoirs to sustain
    it, humanity depends on 0.5% water to meet all of its needs and to maintain the
    ecosystem [80, 81]. It is important to note that the agricultural sector alone
    uses over 70% of the available freshwater [82]. Due to the shortage of water worldwide
    and the rising demand for water in various sectors of the economy, water should
    be delivered only when required and in the required amount. To address the water
    wastage issues, several controlled irrigation techniques, such as drip irrigation
    and spray irrigation, are being encouraged. When there is a water deficit, both
    the quality and quantity of the crops suffer because irregular irrigation, even
    excessive irrigation, reduces the nutrients in the soil. Building a precise soil
    and air moisture control system by employing wireless sensors not only makes the
    best use of water, but also improves crop health because it is not always simple
    to take crop yield metrics into account. By using developing IoT technologies,
    it is anticipated that the current state of irrigation methods would change [83].
    With the adoption of IoT-based solutions, such as irrigation management based
    on the crop water stress index (CWSI), a sharp rise in agricultural efficiency
    is anticipated. A wireless sensor network is utilised to collect the aforementioned
    measures, followed by transmission to a processing hub, in which the related intelligent
    programmes are used to analyse the farm data. Water consumption efficiency is
    finally increased through CropMetrics’ Variable Rate Irrigation (VRI) optimization,
    which takes topography or soil variations into account [84]. 4.3 Fertiliser In
    order to reduce the adverse effects of nutrients on the environment, fertilisation
    is a key component of intelligent agriculture. Based on a variety of variables,
    including soil type, crop type, soil absorption capacity, fertility type and utilisation
    rate, product yield, meteorological condition, etc., fertilisation requires site-specific
    measurements of soil nutrient levels. The issue is that measuring soil nutrients
    is time- and money-consuming because it normally necessitates the analysis of
    soil samples from each location. With greater accuracy and with less labour input,
    new IoT-based fertilization techniques enable the assessment of spatial patterns
    of nutrient requirements [85]. The NDVI is a tool for estimating crop health,
    vegetation vigour, and density, and it also helps to determine the level of soil
    nutrients. The IoT-based smart fertilisation is being greatly aided by a number
    of current enabling technologies, including Global Positioning System (GPS) accuracy
    [86], Variable Rate Technology (VRT) [87], and autonomous robots [88]. 4.4 Crop
    Disease and Pest Management By precisely identifying agricultural pests, modern
    IoT-based intelligent equipment like wireless sensors and drones are enabling
    growers to significantly reduce pesticide usage. Pest management based on IoT
    is more successful since it offers real-time monitoring, modelling, and disease
    predictions. Modern IoT-based pest management is more successful since it offers
    real-time monitoring, modelling, and disease predictions [89]. Sensing, evaluating,
    and treating are often the three factors to determine how effectively crop diseases
    and pests are managed. Advanced disease and pest recognition methods are built
    on image processing, whereby field sensors, unmanned aerial vehicles, or satellites
    are used to collect raw images from all over the crop area. Remote sensing imagery
    typically covers broad areas and provides better efficiency at a reduced cost.
    On the other side, field sensors have a greater capacity to support data collection
    tasks including environmental sampling, plant health, and pest situations across
    the entire crop cycle. Automated traps powered by the IoT can collect, count,
    and even classify different insect species; they can then upload data to the cloud
    for in-depth research [90]. The same methods which are frequently employed for
    smart fertilisation, such as vehicle precision spray and automatic VRT chemigation,
    can also be applied for the treatment of diseases and other pesticide applications
    [91]. The IoT-based pest control technology offers various benefits, including
    the ability to lower total costs while also assisting in the climate''s restoration.
    4.5 Yield Supervision, Crop Forecasting, and Harvest The technique known as “yield
    supervising” is used to examine several factors related to agricultural production,
    such as moisture content, grain mass flow, and harvested grain quantity. When
    it comes to precision farming, yield monitoring is regarded as being significant,
    not just during harvest, but also before that because yield quality monitoring
    is important. Crop forecasting is the technique of foreseeing the yield and production
    prior to the harvest. The farmer can plan and make decisions based on this prediction
    for the near future. For this monitoring, which spans many stages of development
    fruit characteristics such as colour, size, etc., are used. Predicting the ideal
    harvesting window not only maximises the crop quality and output, but also gives
    managers the chance to modify their management approach. Different mobile applications
    are developed for displaying harvest data that will be uploaded to the web platform
    of the manufacturer. In this context, many researches have been carried out over
    the years, with sensors and IoT-based technologies assisting in the improvement
    of traditional agricultural processes to increase the crop output without or with
    minimal impact on its originality. To address the aforementioned problems, new
    advanced settings, which are more tightly controlled, are anticipated. With the
    help of IoT, the advance level of agricultural aspects like vertical farming,
    greenhouse farming, phenotyping, etc., are used to build the super smart agricultural
    system. 5 Cloud-Fog-Edge-Dew Computing in Agriculture Along with IoT, cloud computing
    is utilised in the agricultural industry. Cloud storage is required because IoT
    devices produce more data than the classic database paradigm can store. Nowadays,
    along with cloud computing for better service provisioning fog, edge, and dew
    computing also become popular. 5.1 Cloud Computing Cloud computing combines significant
    IT resources using the Internet on the backend and makes them accessible to the
    user community through clearly defined interfaces. Processors, storage, networks,
    specialised hardware resources, and other services are examples of cloud resources.
    These resources are made available to users in the cloud on a pay-per-use basis
    as needed. Today, cloud computing has applications in practically every field,
    including science, engineering, business, and social sectors. The IoT and cloud-based
    big data analytics play a significant role in the feasibility study of smart agriculture.
    Smart farming maximises resource efficiency while minimising environmental effects.
    At the moment, sensors can provide incredibly precise measures of crop status.
    Actuators can control agricultural activities involving livestock, crops, greenhouses,
    irrigation, soil, and weather based on those values. This can lead to advancements
    in harvest forecasting, weather prediction, increase in productivity, water conservation,
    real-time data collecting, and production, as well as decreased operating costs,
    precise farm and field evaluation, equipment monitoring, and remote monitoring
    [92]. The area of agriculture is being benefited significantly from cloud computing
    over the past few decades. The major characteristics of cloud computing in agriculture
    include data collection and remote storage, low-cost access to information and
    communication technology (ICT) resources, online access to agricultural experts,
    automation of land records, and weather forecasting. Similar issues apply to the
    usage of cloud computing in the agriculture sector, including constant and fast
    network access, security, and privacy. There are some major applications of cloud
    computing in the agriculture field: Enormous amounts of information: Individual
    farmers can easily store and access information from the cloud, including information
    about crops, weather, markets, farmers’ experiences with agricultural procedures,
    and information about pesticides. Inexpensive use of IT resources: It is the more
    affordable and dependable way to get access to resources. The use of cloud computing
    allows farmers to access resources and services as needed. Simple answer to farming
    problems: Cloud computing has made it possible for farmers to easily solve issues,
    which may arise at many phases of their agricultural activities, from tilling
    to marketing and selling of their crops. Tools for gathering data: There are numerous
    efficient and trustworthy data collection methods available today. These methods
    are simple to combine with cloud computing applications. Applications for sensors
    include monitoring soil and water quality, forestry, and forecasting changing
    environmental conditions. The sensors may detect water in the soil, or they can
    measure humidity, liquid pH, or pressure. Predicting the weather: Farmers can
    choose their crops based on weather forecasting for a specified period of time.
    When the climate is unsuitable for a seasonal crop, a farmer can choose a different
    seasonal crop. 5.2 Fog Computing Fog computing is a growing computing technique
    to enhance and support cloud computing. Fog computing platforms include a number
    of features to deliver services to users more quickly and improve the QoS. As
    a result, it is becoming a crucial strategy for IoT-based applications focusing
    on users and entails real-time operations [93, 94]. High processing power and
    extensive data storage are features of cloud and fog computing. The core concept
    of fog computing is a geographically dispersed architecture that connects several
    smart devices in an IoT environment similar to the cloud, but it is situated close
    to the end users. Hence, it may support latency-sensitive applications and services
    [3, 92]. The use of intermediate devices, between the end node and cloud, serves
    as fog devices. Precision agriculture, which is a developing field, is applied
    to the suggested fog computing approach. Additionally, using this framework, they
    were able to replicate and demonstrate how the two-tier fog computing technique
    may considerably minimise the quantity of data that is sent to the cloud [95].
    Its purpose is to facilitate communication, computation, and storage between the
    user and the cloud. Instead of using cloud servers, computations, and data processing
    can be partially done by the intermediate nodes, which will lighten the overhead
    of the cloud servers. The services and applications of fog computing are dispersed,
    which has several benefits including speed, fault tolerance, and security. Fog
    is excellent for real-time processing since it is close to the edge, enabling
    real-time interactions between IoT devices [92, 95]. The development of creative
    farming methods is gradually increasing crop yield, increasing profitability,
    and lowering irrigation waste. 5.3 Edge Computing Edge computing and related paradigms
    are at an early stage of developmental. Despite its advantages (cost savings,
    efficiency, scalability, and reliability), cloud computing faces significant difficulties
    when dealing with large amount of data. The challenges of cloud computing, such
    as low latency, real-time analytics, high network bandwidth, data management,
    energy usage, security, load balancing, and privacy, can be resolved using edge
    computing [96]. Edge computing is suggested as a way to enhance speed and solve
    cloud-related issues by enabling local data processing and storage at endpoints.
    Hence, edge computing is a computational approach that locates computing power
    and storage closer to the end user, at the edge of the network. It offers intelligent
    services with cloud computing [97,98,99]. Edge computing offers various advantages
    such as: Data streams from various sources are processed by the nodes before being
    sent to the cloud to conserve bandwidth and storage space and to filter out noise.
    Processing data close to its source of origin results in proximity and reduced
    latency. Decentralised processing and storage allow greater scalability. Each
    node of the network has privacy. Edge computing is a strong component for enabling
    global smart environments in agriculture [100]. Edge-enabled services can be categorised
    as node-centric services and cloud-centric services. The node-centric services
    operate independently of the cloud. The cloud-centric services rely on at least
    one cloud service to function. The majority of the systems analysed in the preceding
    section might be categorised as cloud-centric. Reduced latency, better bandwidth
    usage, and work offloading are the three key advantages of edge computing [101,102,103,104,105],
    which were used to varied degrees. Local edge devices were employed for initial
    data processing, and core cloud services were used for second-level offloading,
    storage, and alert generating. Rural broadband connection is still a major issue
    everywhere in the world. The consequences of intermittent Internet access can
    be partially mitigated by edge computing, but comprehensive analytics-driven service
    provision needs access to the cloud. A third model based on delay tolerance should
    be taken into consideration for the agricultural domain, according to the intractability
    of this problem. Delay-tolerant edge services may be used as a design template
    for services, which need a connection to the cloud, but only in circumstances
    where sporadic network access is the norm. The idea of delay/disruption tolerance
    is well-established in the networking field, where it is regarded as a workable
    solution to problems like excessive latency and uncertain network availability.
    However, from the standpoint of service, delay tolerance must be taken into account
    from the very beginning of the service''s design. When accustomed to immediate
    Internet access, services that do not respond in near real-time may initially
    appear out of the ordinary. However, many agricultural services can wait; the
    IoT’s requirement for constant Internet access is frequently superfluous because
    many environmental parameters change rather slowly. Other wireless technologies
    may be used to cover the farm and link to the edge node there in situations where
    an urgent alert needs to be brought to the farmer''s notice. In this scenario,
    the service''s underlying logic must reside on the node. Global food security,
    the present state of smart agriculture, and the prevalent problem of internet
    connectivity are considered in [106]. In [106], the use of the edge computing
    model in agriculture has been illustrated. The use of cloud, fog, and edge computing
    in the existing literature on agriculture are summarised in Table 1. Table 1 Existing
    literature on the use of cloud, fog, and edge computing in agriculture Full size
    table 5.4 Dew Computing The “micro-service(s)” concept is anticipated to be used
    by dew computing in a very diverse, extremely vertical, and highly distributed
    hierarchy. Data dispersal into low-end devices like smartphones, tablets, laptops,
    e-book readers, etc. becomes viable in this new area of centralised-virtualisation-free
    computing paradigm. As a result, it opens up a brand-new possibility for data
    accessibility without constant Internet access. As a result, dew computing encompasses
    all current network technologies as well as a wide range of essential traits like
    independent, mobile data aggregation, cooperative applications, and hybrid network
    behaviour [113]. Dew computing has the following advantages: It is lightweight.
    It maintains the information that is used frequently in its databases. The cloud
    server allows the regeneration of this data. All tasks, such as DBMS control,
    identity mapping, raw data synchronisation, rule-based data collecting, dew script
    analysis, etc., will fall under its purview. It will eventually become apparent
    to the user as a Personal Information Centre. The user will always have access
    to its services, whether or not they have an Internet connection. Independence
    and collaboration are two pillars of dew computing architecture [114]. Independence
    refers to a computer''s ability to function without cloud services or a network
    connection. In other words, it indicates that this application is not a cloud
    service or an entirely online application. Collaboration requires that, while
    in use, the dew computing automatically communicates data with cloud services.
    Synchronisation, correlation, or other forms of interoperation are examples of
    this collaboration [17]. In order to continue storing data when a connection is
    sporadic, dew computing seeks to replicate data close to sensors or users. In
    case of connection failure, it enables access to a local copy of the data. It
    enhances false tolerance and reliability [115]. The use of dew computing in agriculture
    will be demonstrated in Sect. 6. 6 Dew Computing in Agriculture In the dew computing-based
    model, the sensor data is accumulated at the dew layer. When internet connectivity
    is available the data is transmitted to the cloud through the edge/fog nodes.
    Figure 1 presents the dew computing-based architecture for smart agriculture.
    The proposed paradigm contains: Fig. 1 Dew computing-based architecture for smart
    agriculture Full size image Sensors Microcontrollers Edge/fog nodes Cloud servers.
    The four-layer architecture is described as follows: Layer 1: Layer 1 contains
    the sensor nodes. A sensor node (\\(S\\)) is mathematically defined as $$S\\;
    = \\;\\left\\langle {{\\text{ID}}_{s} ,O_{s} } \\right\\rangle$$ where \\({\\mathrm{ID}}_{s}\\)
    denotes the ID of the sensor node, and \\({O}_{s}\\) denotes the type of the object.
    The sensors are used to collect the object data such as soil temperature, soil
    moisture, nitrogen, phosphorous, potassium level, pH level, environmental temperature,
    humidity, etc. The sensors are connected to the microcontroller present at layer
    2. Relay nodes can be used in layer 1 if required. The sensors at layer 1 transmit
    the collected data to the microcontroller at layer 2. Layer 2: Layer 2 contains
    microcontrollers. A microcontroller (\\(M\\)) is mathematically defined as $$M
    = {\\text{ }}\\left\\langle {{\\text{ID}}_{m} ,C_{m} } \\right\\rangle$$ where
    \\({\\mathrm{ID}}_{m}\\) denotes the ID of the microcontroller, and \\({C}_{m}\\)
    denotes the configuration of the microcontroller. The microcontroller receives
    the data from the sensor and stores the data. The microcontroller can pre-process
    the data. The microcontroller here serves the purpose of a dew layer. If Internet
    connectivity is not available, it holds and pre-processes the data. The microcontroller
    sends the data to the edge/fog node at layer 3 when Internet connectivity is available.
    Layer 3: Layer 3 contains the edge/fog nodes. An edge/fog node (\\(N\\)) is mathematically
    defined as $$N = \\left\\langle {{\\text{ID}}_{n} ,C_{n} } \\right\\rangle$$ where
    \\({ID}_{n}\\) denotes the ID of the edge/fog node, and \\({C}_{n}\\) denotes
    the configuration of the edge/fog node. The edge/fog node performs further processing
    on the data and forwards it to the cloud at layer 4. Layer 4: Layer 4 contains
    the cloud servers. A cloud computing instance (\\(I\\)) is mathematically defined
    as $$I\\,=\\,\\left\\langle{\\mathrm{ID}}_{i},{C}_{i}\\right\\rangle$$ where \\({\\mathrm{ID}}_{i}\\)
    denotes the ID of the cloud component and \\({P}_{i}\\) denotes the set containing
    the processing unit IDs. The cloud servers after receiving the data store it if
    required for further analysis. The total latency of the dew computing-based paradigm
    is computed as the sum of the data collection latency (\\({L}_{1}\\)), data processing
    latency (\\({L}_{2}\\)), and data transmission latency (\\({L}_{3}\\)), given
    as $$L = {L}_{1}+{L}_{2}+{L}_{3}$$ (2) Using MATLAB 2021, we have simulated the
    dew computing-based, edge computing-based, and only cloud computing-based architecture.
    Figure 2 presents the latency using the proposed dew computing-based paradigm,
    existing edge-based paradigm, and cloud-only paradigm. We observe that the use
    of dew computing reduces the latency by approximately 40 and 55% than the edge-based
    and cloud-only paradigms respectively. Fig. 2 Comparison of latency between dew
    computing-based, edge computing-based, and cloud-only paradigms Full size image
    As the dew layer holds the collected data and pre-processes the data before forwarding
    it to the next layer, the data transmission latency is reduced. Consequently,
    the overheads on the next layer as well as on the cloud are reduced. The use of
    dew computing moreover provides the advantage of accessing the data even when
    not connected to the Internet. 7 Conclusions The use of the Internet of Things
    in smart agriculture has gained significant research interest in the last few
    years. The sensors are used to collect soil-related data, crop-related data, and
    the analysis of the collected data takes place inside the cloud. Based on the
    data analysis, the farmers can be guided for better crop production. However,
    the use of cloud-only paradigm has several shortcomings such as increase in latency,
    network bandwidth, network connectivity, huge overheads on the cloud, etc. To
    deal with these problems, fog and edge computing have come. The use of intermediate
    devices in data processing and brining the resources to the network edge solves
    various issues related to latency, bandwidth, etc. Nevertheless, the edge and
    fog computing scenarios require good Internet connectivity. But in the remote
    location, the Internet connectivity may not be always good. To resolve this issue,
    dew computing has come. The use of dew computing provides the facility of accessing
    the data even when Internet connectivity is unavailable. When the network connectivity
    resumes, the data transmission to the upper layer takes place, and finally the
    data is sent to the cloud if further analysis is required. In this chapter, we
    have discussed the architecture of dew computing-based smart agriculture, along
    with a brief discussion on the use of cloud, fog, and edge computing in smart
    agriculture. Various machine learning algorithms used for data analysis are also
    discussed. The simulation results present that the use of dew computing reduces
    the latency by approximately 40% and 55% than the edge-based and cloud-only paradigms,
    respectively. There are varied future research avenues. With the advancement of
    deep learning-based models, an efficient quality monitoring framework of agricultural
    products, greenhouse automation, and crop management system can be developed.
    Leveraging the dew-edge-cloud paradigm, we can develop a latency-aware smart farm
    management system to enhance the overall quality of life. References Elijah, O.,
    Rahman, T.A., Orikumhi, I., Leow, C.Y., Hindia, M.N.: An overview of internet
    of things (IoT) and data analytics in agriculture: benefits and challenges. IEEE
    Internet Things J. 5(5), 3758–3773 (2018) Article   Google Scholar   Marjumin,
    N.H., Sidek, S., Hassan, M.A., Rajikon, M., Kamalrudin, M.: The challenges and
    contribution of internet of things (Iot) for smart living. Int. J. Recent Technol.
    Eng. 8, 162–166 (2019) Google Scholar   Atzori, L., Iera, A., Morabito, G.: The
    internet of things: a survey. Comput. Netw. 54(15), 2787–2805 (2010) Article   MATH   Google
    Scholar   Fang, S., Da Xu, L., Zhu, Y., Ahati, J., Pei, H., Yan, J., Liu, Z.:
    An integrated system for regional environmental monitoring and management based
    on internet of things. IEEE Trans. Ind. Inf. 10(2), 1596–1605 (2014) Article   Google
    Scholar   Ray, P.P.: Internet of things for smart agriculture: technologies, practices
    and future direction. J. Ambient Intell. Smart Environ. 9(4), 395–420 (2017) Article   Google
    Scholar   Sadeeq, M.M., Abdulkareem, N.M., Zeebaree, S.R., Ahmed, D.M., Sami,
    A.S., Zebari, R.R.: IoT and Cloud computing issues, challenges and opportunities:
    a review. Qubahan Acad. J. 1(2), 1–7 (2021) Article   Google Scholar   Kaur, C.:
    The cloud computing and internet of things (IoT). Int. J. Sci. Res. Sci. Eng.
    Technol. 7(1), 19–22 (2020) Google Scholar   Biswas, A.R., Giaffreda, R.: IoT
    and cloud convergence: opportunities and challenges. In: 2014 IEEE World Forum
    on Internet of Things (WF-IoT), pp. 375–376. IEEE (2014) Google Scholar   Goraya,
    M.S., Kaur, H.: Cloud computing in agriculture. HCTL Open Int. J. Technol. Innov.
    Res. (IJTIR) 16, 2321–1814 (2015) Google Scholar   Deng, R., Lu, R., Lai, C.,
    Luan, T.H., Liang, H.: Optimal workload allocation in fog-cloud computing toward
    balanced delay and power consumption. IEEE Internet Things J. 3(6), 1171–1181
    (2016) Google Scholar   Guardo, E., Di Stefano, A., La Corte, A., Sapienza, M.,
    Scatà, M.: A fog computing-based iot framework for precision agriculture. J. Internet
    Technol. 19(5), 1401–1411 (2018) Google Scholar   Yousefpour, A., Fung, C., Nguyen,
    T., Kadiyala, K., Jalali, F., Niakanlahiji, A., et al.: All one needs to know
    about fog computing and related edge computing paradigms. J. Syst. Archit. (2019)
    Google Scholar   Chen, J., Ran, X.: Deep learning with edge computing: a review.
    Proc. IEEE 107(8), 1655–1674 (2019) Article   Google Scholar   Sittón-Candanedo,
    I., Alonso, R.S., Corchado, J.M., Rodríguez-González, S., Casado-Vara, R.: A review
    of edge computing reference architectures and a new global edge proposal. Fut.
    Gener. Comput. Syst. 99, 278–294 (2019) Article   Google Scholar   Zhang, X.,
    Cao, Z., Dong, W.: Overview of edge computing in the agricultural internet of
    things: key technologies, applications, challenges. IEEE Access 8, 141748–141761
    (2020) Article   Google Scholar   Xu, L., Collier, R., O’Hare, G.M.: A survey
    of clustering techniques in WSNs and consideration of the challenges of applying
    such to 5G IoT scenarios. IEEE Internet Things J. 4(5), 1229–1249 (2017) Article   Google
    Scholar   Rindos, A., Wang, Y.: Dew computing: the complementary piece of cloud
    computing. In: 2016 IEEE International Conferences on Big Data and Cloud Computing
    (BDCloud), Social Computing and Networking (SocialCom), Sustainable Computing
    and Communications (SustainCom) (BDCloud-SocialCom-SustainCom), pp. 15–20. IEEE
    Google Scholar   Wang, Y.: Definition and categorization of dew computing. Open
    J. Cloud Comput. (OJCC) 3(1), 1–7 (2016) Google Scholar   Van Klompenburg, T.,
    Kassahun, A., Catal, C.: Crop yield prediction using machine learning: a systematic
    literature review. Comput. Electron. Agric. 177, 105709 (2020) Article   Google
    Scholar   Chlingaryan, A., Sukkarieh, S., Whelan, B.: Machine learning approaches
    for crop yield prediction and nitrogen status estimation in precision agriculture:
    a review. Comput. Electron. Agric. 151, 61–69 (2018) Article   Google Scholar   Xu,
    X., Gao, P., Zhu, X., Guo, W., Ding, J., Li, C., et al.: Design of an integrated
    climatic assessment indicator (ICAI) for wheat production: a case study in Jiangsu
    Province, China. Ecol. Indicat. 101, 943–953 (2019) Google Scholar   Reddy, K.S.P.,
    Roopa, Y.M., LN, K.R., Nandan, N.S.: IoT based smart agriculture using machine
    learning. In: 2020 Second International Conference on Inventive Research in Computing
    Applications (ICIRCA), pp. 130–134. IEEE (2020) Google Scholar   Jagtap, S.T.,
    Phasinam, K., Kassanuk, T., Jha, S.S., Ghosh, T., Thakar, C.M.: Towards application
    of various machine learning techniques in agriculture. Mater. Today: Proc. 51,
    793–797 (2022) Article   Google Scholar   Pearson, K.: LIII. On lines and planes
    of closest fit to systems of points in space. London Edinburgh Dublin Philos.
    Mag. J. Sci. 2(11), 559–572 Google Scholar   Fisher, R.A.: The use of multiple
    measurements in taxonomic problems. Ann. Eugen. 7(2), 179–188 (1936) Article   Google
    Scholar   Mishra, S., Mishra, D., Santra, G.H.: Applications of machine learning
    techniques in agricultural crop production: a review paper. Indian J. Sci. Technol.
    9(38), 1–14 (2016) Article   Google Scholar   Uno, Y., Prasher, S.O., Lacroix,
    R., Goel, P.K., Karimi, Y., Viau, A., Patel, R.M.: Artificial neural networks
    to predict corn yield from compact airborne spectrographic imager data. Comput.
    Electron. Agric. 47(2), 149–161 (2005) Article   Google Scholar   Veenadhari,
    S., Mishra, B., Singh, C.D.: Soybean productivity modelling using decision tree
    algorithms. Int. J. Comput. Appl. 27(7), 11–15 (2011) Google Scholar   Bhargavi,
    P., Jyothi, S.: Applying Naive Bayes data mining technique for classification
    of agricultural land soils. Int. J. Comput. Sci. Netw. Secur. 9(8), 117–122 (2009)
    Google Scholar   Rainville, D., Durand, A., Fortin, F.A., Tanguy, K., Maldague,
    X., Panneton, B., Simard, M.J.: Bayesian classification and unsupervised learning
    for isolating weeds in row crops. Pattern Anal. Appl. 17(2), 401–414 (2014) Article   MathSciNet   Google
    Scholar   Sharma, B., Yadav, J.K.P.S., Yadav, S.: Predict crop production in India
    using machine learning technique: a survey. In: 2020 8th International Conference
    on Reliability, Infocom Technologies and Optimization (Trends and Future Directions)
    (ICRITO), pp. 993–997. IEEE (2020) Google Scholar   Khoshnevisan, B., Rafiee,
    S., Omid, M., Mousazadeh, H., Rajaeifar, M.A.: Application of artificial neural
    networks for prediction of output energy and GHG emissions in potato production
    in Iran. Agric. Syst. 123, 120–127 (2014) Article   Google Scholar   Babu, M.P.:
    A web based tomato crop expert information system based on artificial intelligence
    and machine learning algorithms (2010) Google Scholar   Umair, S.M., Usman, R.:
    Automation of irrigation system using ANN based controller. Int. J. Electr. Comput.
    Sci. IJECS-IJENS 10(02), 41–47 (2010) Google Scholar   Li, Y., Chao, X.: ANN-based
    continual classification in agriculture. Agriculture 10(5), 178 (2020) Article   Google
    Scholar   Dahikar, S.S., Rode, S.V.: Agricultural crop yield prediction using
    artificial neural network approach. Int. J. Innov. Res. Electr. Electron. Instrum.
    Control Eng. 2(1), 683–686 (2014) Google Scholar   Kantanantha, N.: Crop decision
    planning under yield and price uncertainties. Georgia Institute of Technology
    (2007) Google Scholar   Suresh, K.K., Krishna Priya, S.R.: A study on pre-harvest
    forecast of sugarcane yield using climatic variables. Stat. Appl. 7&8(1&2), 1–8
    (New Series) (2009) Google Scholar   Horie, T., Yajima, M., Nakagawa, H.: Yield
    forecasting. Agric. Syst. 40(1–3), 211–236 (1992) Article   Google Scholar   Liakos,
    K.G., Busato, P., Moshou, D., Pearson, S., Bochtis, D.: Machine learning in agriculture:
    a review. Sensors 18(8), 2674 (2018) Article   Google Scholar   Narkhede, U.P.,
    Adhiya, K.P.: Evaluation of modified K-means clustering algorithm in crop prediction.
    Int. J. Adv. Comput. Res. 4(3), 799 (2014) Google Scholar   Mahesh, B.: Machine
    learning algorithms-a review. Int. J. Sci. Res. (IJSR) 9, 381–386 (2020); Noble,
    W.S.: What is a support vector machine?. Nat. Biotechnol. 24(12), 1565–1567 (2006)
    Google Scholar   Pradhan, A.: Support vector machine-a survey. Int. J. Emerg.
    Technol. Adv. Eng. 2(8), 82–85 (2012) Google Scholar   Chandra, M.A., Bedi, S.S.:
    Survey on SVM and their application in image classification. Int. J. Inf. Technol.
    13(5), 1–11 (2021) Google Scholar   Mierswa, I.: Controlling overfitting with
    multi-objective support vector machines. In: Proceedings of the 9th Annual Conference
    on Genetic and Evolutionary Computation, pp. 1830–1837 (2007) Google Scholar   Mohamed,
    A.E.: Comparative study of four supervised machine learning techniques for classification.
    Int. J. Appl. 7(2), 1–15 (2017) Google Scholar   Gupta, A., Katarya, R.: Social
    media based surveillance systems for healthcare using machine learning: a systematic
    review. J. Biomed. Inform. 108, 103500 (2020) Article   Google Scholar   Shakoor,
    M.T., Rahman, K., Rayta, S.N., Chakrabarty, A.: Agricultural production output
    prediction using supervised machine learning techniques. In: 2017 1st International
    Conference on Next Generation Computing Applications (NextComp), pp. 182–187.
    IEEE (2006) Google Scholar   Kataria, A., Singh, M.D.: A review of data classification
    using k-nearest neighbour algorithm. Int. J. Emerg. Technol. Adv. Eng. 3(6), 354–360
    (2013) Google Scholar   Karthikeya, H.K., Sudarshan, K., Shetty, D.S.: Prediction
    of agricultural crops using KNN algorithm. Int. J. Innov. Sci. Res. Technol 5,
    1422–1424 (2020) Google Scholar   Cutler, A., Cutler, D.R., Stevens, J.R.: Random
    forests. In: Ensemble Machine Learning, pp. 157–175. Springer, Boston, MA (2012)
    Google Scholar   Ali, J., Khan, R., Ahmad, N., Maqsood, I.: Random forests and
    decision trees. Int. J. Comput. Sci. Issues (IJCSI) 9(5), 272 (2012) Google Scholar   Tan,
    K., Ma, W., Wu, F., Du, Q.: Random forest–based estimation of heavy metal concentration
    in agricultural soils with hyperspectral sensor data. Environ. Monit. Assess.
    191(7), 1–14 (2019) Article   Google Scholar   Sharma, N., Juneja, A.: Combining
    of random forest estimates using LSboost for stock market index prediction. In:
    2017 2nd International Conference for Convergence in Technology (I2CT), pp. 1199–1202.
    IEEE (2017) Google Scholar   Dargan, S., Kumar, M., Ayyagari, M.R., Kumar, G.:
    A survey of deep learning and its applications: a new paradigm to machine learning.
    Arch. Comput. Methods Eng. 27, 1071–1092 (2020) Article   MathSciNet   Google
    Scholar   LeCun, Y., Bengio, Y., Hinton, G.: Deep learning. Nature 521(7553),
    436–444 (2015) Google Scholar   Bengio, Y., Lecun, Y., Hinton, G.: Deep learning
    for AI. Commun. ACM 64(7), 58–65 (2021) Article   Google Scholar   Sak, H., Senior,
    A.W., Beaufays, F.: Long short-term memory recurrent neural network architectures
    for large scale acoustic modeling. Interspeech (2014) Google Scholar   Zhu, N.,
    Liu, X., Liu, Z., Hu, K., Wang, Y., Tan, J., et al.: Deep learning for smart agriculture:
    Concepts, tools, applications, and opportunities. Int. J. Agric. Biol. Eng. 11(4),
    32–44 (2018) Google Scholar   Gu, J., Wang, Z., Kuen, J., Ma, L., Shahroudy, A.,
    Shuai, B., et al.: Recent advances in convolutional neural networks. Pattern Recogn.
    77, 354–377 (2018) Google Scholar   Kamilaris, A., Prenafeta-Boldú, F.X.: A review
    of the use of convolutional neural networks in agriculture. J. Agric. Sci. 156(3),
    312–322 (2018) Article   Google Scholar   Schmidhuber, J.: Deep learning in neural
    networks: an overview. Neural Netw. 61, 85–117 (2015) Article   Google Scholar   Oquab,
    M., Bottou, L., Laptev, I., Sivic, J.: Learning and transferring mid-level image
    representations using convolutional neural networks. In: Proceedings of the IEEE
    Conference on Computer Vision and Pattern Recognition, pp. 1717–1724 (2014) Google
    Scholar   Long, J., Shelhamer, E., Darrell, T.: Fully convolutional networks for
    semantic segmentation. In: Proceedings of the IEEE Conference on Computer Vision
    and Pattern Recognition, pp. 3431–3440 (2015) Google Scholar   Chen, Y., Lin,
    Z., Zhao, X., Wang, G., Gu, Y.: Deep learning-based classification of hyperspectral
    data. IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens. 7(6), 2094–2107 (2014)
    Article   Google Scholar   Grinblat, G.L., Uzal, L.C., Larese, M.G., Granitto,
    P.M.: Deep learning for plant identification using vein morphological patterns.
    Comput. Electron. Agric. 127, 418–424 (2016) Article   Google Scholar   Lee, S.H.,
    Chan, C.S., Wilkin, P., Remagnino, P.: Deep-plant: plant identification with convolutional
    neural networks. In 2015 IEEE International Conference on Image Processing (ICIP),
    pp. 452–456. IEEE (2015) Google Scholar   Luus, F.P., Salmon, B.P., Bergh, F.V.,
    Maharaj, B.T.: Multiview deep learning for land-use classification. IEEE Geosci.
    Remote Sens. Lett. 12, 2448–2452 (2015) Article   Google Scholar   Kuwata, K.,
    Shibasaki, R.: Estimating crop yields with deep learning and remotely sensed data.
    In: 2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS),
    pp. 858–861. IEEE (2015) Google Scholar   Xinshao, W., Cheng, C.: Weed seeds classification
    based on PCANet deep learning baseline. In: 2015 Asia-Pacific Signal and Information
    Processing Association Annual Summit and Conference (APSIPA), pp. 408–415. IEEE
    (2015) Google Scholar   Yalcin, H.: Plant phenology recognition using deep learning:
    deep-pheno. In: 2017 6th International Conference on Agro-Geoinformatics, pp.
    1–5. IEEE (2017) Google Scholar   Ienco, D., Gaetano, R., Dupaquier, C., Maurel,
    P.: Land cover classification via multitemporal spatial data by deep recurrent
    neural networks. IEEE Geosci. Remote Sens. Lett. 14(10), 1685–1689 (2017) Article   Google
    Scholar   Rußwurm, M., Körner, M.: Multi-temporal land cover classification with
    long short-term memory neural networks. Int. Arch. Photogramm. Remote Sens. Spatial
    Inf. Sci. 42 (2017) Google Scholar   Abbasi, A.Z., Islam, N., Shaikh, Z.A.: A
    review of wireless sensors and networks’ applications in agriculture. Comput.
    Stand. Interfaces 36(2), 263–270 (2014) Article   Google Scholar   TongKe, F.:
    Smart agriculture based on cloud computing and IOT. J. Converg. Inf. Technol.
    8(2), 210–216 (2013) Google Scholar   Ngu, A.H., Gutierrez, M., Metsis, V., Nepal,
    S., Sheng, Q.Z.: IoT middleware: a survey on issues and enabling technologies.
    IEEE Internet Things J. 4(1), 1–20 (2016) Article   Google Scholar   Raza, U.,
    Kulkarni, P., Sooriyabandara, M.: Low power wide area networks: an overview. IEEE
    Commun. Surv. Tutor. 19(2), 855–873 (2017) Google Scholar   Vågen, T.G., Winowiecki,
    L.A., Tondoh, J.E., Desta, L.T., Gumbricht, T.: Mapping of soil properties and
    land degradation risk in Africa using MODIS reflectance. Geoderma 263, 216–225
    (2016) Article   Google Scholar   Santhi, P.V., Kapileswar, N., Chenchela, V.K.,
    Prasad, C.V.S.: Sensor and vision based autonomous AGRIBOT for sowing seeds. In:
    2017 International Conference on Energy, Communication, Data Analytics and Soft
    Computing (ICECDS), pp. 242–245. IEEE (2017) Google Scholar   Williams, M.: What
    Percent of Earth is water. Universe Today 2016 (2014) Google Scholar   Water Facts_Worldwide
    Water Supply.: https://www.usbr.gov/mp/arwec/water-facts-ww-water-sup.html. Accessed
    15 Apr. 2019 Water for Sustainable Food and Agriculture by FAO.: https://www.fao.org/3/a-i7959e.pdf.
    Accessed 15 Apr. 2019 Hassan, Q.F.: (Ed.). (2018). Internet of things A to Z:
    technologies and applications. John Wiley & Sons. Google Scholar   LaRue, J.,
    Fredrick, C.: Decision process for the application of variable rate irrigation.
    Am. Soc. Agric. Biol. Eng. (Dallas, TX, USA, Tech. Rep.) (2012) Google Scholar   Lavanya,
    G., Rani, C., GaneshKumar, P.: An automated low cost IoT based fertilizer intimation
    system for smart agriculture. Sustain. Comput.: Inform. Syst. 28, 100300 (2020)
    Google Scholar   Shi, J., Yuan, X., Cai, Y., Wang, G.: GPS real-time precise point
    positioning for aerial triangulation. GPS Solut. 21(2), 405–414 (2017) Article   Google
    Scholar   Colaço, A.F., Molin, J.P.: Variable rate fertilization in citrus: a
    long term study. Precision Agric. 18(2), 169–191 (2017) Article   Google Scholar   Khan,
    N., Medlock, G., Graves, S., Anwar, S.: GPS guided autonomous navigation of a
    small agricultural robot with automated fertilizing system (No. 2018-01-0031).
    SAE Technical Paper (2018) Google Scholar   Venkatesan, R., Kathrine, G.J.W.,
    Ramalakshmi, K.: Internet of things based pest management using natural pesticides
    for small scale organic gardens. J. Comput. Theor. Nanosci. 15(9–10), 2742–2747
    (2018) Article   Google Scholar   Suma, V.: Internet-of-things (IoT) based smart
    agriculture in India-an overview. J. ISMAC 3(01), 1–15 (2021) Article   Google
    Scholar   Oberti, R., Marchi, M., Tirelli, P., Calcante, A., Iriti, M., Tona,
    E., et al.: Selective spraying of grapevines for disease control using a modular
    agricultural robot. Biosyst. Eng. 146, 203–215 (2016) Google Scholar   Kalyani,
    Y., Collier, R.: A systematic survey on the role of cloud, fog, and edge computing
    combination in smart agriculture. Sensors 21(17), 5922 (2021) Article   Google
    Scholar   Abbas, N., Zhang, Y., Taherkordi, A., Skeie, T.: Mobile edge computing:
    a survey. IEEE Internet Things J. 5(1), 450–465 (2018). https://doi.org/10.1109/JIOT.2017.2750180
    Article   Google Scholar   Shi, W., Cao, J., Zhang, Q., Li, Y., Xu, L.: Edge computing:
    vision and challenges. IEEE Internet Things J. 3(5), 637–646 (2016) Article   Google
    Scholar   Sarhan, A.: Fog computing as solution for IoT-based agricultural applications.
    In: Smart Agricultural Services Using Deep Learning, Big Data, and IoT, pp. 46–68.
    IGI Global (2021) Google Scholar   Mukherjee, A., De, D., Ghosh, S.K., Buyya,
    R.: Introduction to mobile edge computing. In: Mobile Edge Computing, pp. 3–19.
    Springer, Cham (2021) Google Scholar   Zhang, J., Chen, B., Zhao, Y., Cheng, X.,
    Hu, F.: Data security and privacy-preserving in edge computing paradigm: survey
    and open issues. IEEE Access 6, 18209–18237 (2018) Article   Google Scholar   Satyanarayanan,
    M.: The emergence of edge computing. Computer 50(1), 30–39 (2017) Article   Google
    Scholar   Zamora-Izquierdo, M.A., Santa, J., Martínez, J.A., Martínez, V., Skarmeta,
    A.F.: Smart farming IoT platform based on edge and cloud computing. Biosyst. Eng.
    177, 4–17 (2019) Article   Google Scholar   Sengupta, A., Gill, S.S., Das, A.,
    De, D.: Mobile edge computing based internet of agricultural things: a systematic
    review and future directions. Mob. Edge Comput. 415–441 (2021) Google Scholar   Ghosh,
    S., Mukherjee, A., Ghosh, S.K., Buyya, R.: Mobi-iost: mobility-aware cloud-fog-edge-IoT
    collaborative framework for time-critical applications. IEEE Trans. Netw. Sci.
    Eng. 7(4), 2271–2285 (2019) Article   Google Scholar   Mukherjee, A., Ghosh, S.,
    De, D., Ghosh, S.K.:. MCG: mobility-aware computation offloading in edge using
    weighted majority game. IEEE Trans. Netw. Sci. Eng. (2022) Google Scholar   Ghosh,
    S., Mukherjee, A.: STROVE: spatial data infrastructure enabled cloud–fog–edge
    computing framework for combating COVID-19 pandemic. Innov. Syst. Softw. Eng.
    1–17 (2022) Google Scholar   Das, J., Ghosh, S., Mukherjee, A., Ghosh, S.K., Buyya,
    R.: Rescue: enabling green healthcare services using integrated IoT‐edge‐fog‐cloud
    computing environments. Softw.: Pract. Exp. (2022) Google Scholar   Ghosh, S.,
    Ghosh, S.K.: Mobility driven cloud-fog-edge framework for location-aware services:
    a comprehensive review. Mob. Edge Comput. 229–249 (2021) Google Scholar   O’Grady,
    M.J., Langton, D., O’Hare, G.M.P.: Edge computing: a tractable model for smart
    agriculture? Artif. Intell. Agric. 3, 42–51 (2019) Google Scholar   Kakamoukas,
    G., Sarigiannidis, P., Maropoulos, A., Lagkas, T., Zaralis, K., Karaiskou, C.:
    Towards climate smart farming—A reference architecture for integrated farming
    systems. In: Telecom, vol. 2, no. 1, pp. 52–74. MDPI Google Scholar   Almalki,
    F.A., Soufiene, B.O., Alsamhi, S.H., Sakli, H.: A low-cost platform for environmental
    smart farming monitoring system based on IoT and UAVs. Sustainability 13(11),
    5908 (2021) Article   Google Scholar   Chew, K.T., Jo, R.S., Lu, M., Raman, V.,
    Then, P.H.H.: Organic black soldier flies (BSF) farming in rural area using Libelium
    Waspmote smart agriculture and internet-of-things technologies. In: 2021 IEEE
    11th IEEE Symposium on Computer Applications & Industrial Electronics (ISCAIE),
    pp. 228–232. IEEE (2021) Google Scholar   Li, X., Ma, Z., Zheng, J., Liu, Y.,
    Zhu, L., Zhou, N.: An effective edge-assisted data collection approach for critical
    events in the SDWSN-based agricultural internet of things. Electronics 9(6), 907
    (2020) Article   Google Scholar   Roopaei, M., Rad, P., Choo, K.-K.R.: Cloud of
    things in smart agriculture: intelligent irrigation monitoring by thermal imaging.
    IEEE Cloud Comput. 4(1), 10–15 (2017). https://doi.org/10.1109/MCC.2017.5 Puri,
    B.: IoT and AI-based Plant Monitoring System. International J. Mach. Learn. Netw.
    Collab. Eng. 4(3), 135–142 (2021) Google Scholar   Ray, P.P.: An introduction
    to dew computing: definition, concept and implications. IEEE Access 6, 723–737
    (2017) Article   Google Scholar   Roy, S., Sarkar, D., De, D.: DewMusic: crowdsourcing-based
    internet of music things in dew computing paradigm. J. Ambient. Intell. Humaniz.
    Comput. 12(2), 2103–2119 (2021) Article   Google Scholar   Skala, K., Davidovic,
    D., Afgan, E., Sovic, I., Sojat, Z.: Scalable distributed computing hierarchy:
    cloud, fog and dew computing. Open J. Cloud Comput. (OJCC) 2(1), 16–24 (2015)
    Google Scholar   Download references Author information Authors and Affiliations
    Department of Computer Science, Mahishadal Raj College, Mahishadal, West Bengal,
    India Somnath Bera, Tanushree Dey & Anwesha Mukherjee College of Information Sciences
    and Technology, The Pennsylvania State University, University Park, USA Shreya
    Ghosh Corresponding author Correspondence to Anwesha Mukherjee . Editor information
    Editors and Affiliations Department of Computer Science and Engineering, Maulana
    Abul Kalam Azad University of Technology, West Bengal, Kolkata, India Debashis
    De Department of Computer Science and Engineering, D Y Patil International University,
    Pune, India Samarjit Roy Rights and permissions Reprints and permissions Copyright
    information © 2024 The Author(s), under exclusive license to Springer Nature Singapore
    Pte Ltd. About this chapter Cite this chapter Bera, S., Dey, T., Ghosh, S., Mukherjee,
    A. (2024). Internet of Things and Dew Computing-Based System for Smart Agriculture.
    In: De, D., Roy, S. (eds) Dew Computing. Internet of Things. Springer, Singapore.
    https://doi.org/10.1007/978-981-99-4590-0_14 Download citation .RIS.ENW.BIB DOI
    https://doi.org/10.1007/978-981-99-4590-0_14 Published 03 September 2023 Publisher
    Name Springer, Singapore Print ISBN 978-981-99-4589-4 Online ISBN 978-981-99-4590-0
    eBook Packages Engineering Engineering (R0) Share this chapter Anyone you share
    the following link with will be able to read this content: Get shareable link
    Provided by the Springer Nature SharedIt content-sharing initiative Publish with
    us Policies and ethics Sections Figures References Abstract Introduction Machine
    Learning in Agriculture Deep Learning in Agriculture IoT in Agriculture Cloud-Fog-Edge-Dew
    Computing in Agriculture Dew Computing in Agriculture Conclusions References Author
    information Editor information Rights and permissions Copyright information About
    this chapter Publish with us Discover content Journals A-Z Books A-Z Publish with
    us Publish your research Open access publishing Products and services Our products
    Librarians Societies Partners and advertisers Our imprints Springer Nature Portfolio
    BMC Palgrave Macmillan Apress Your privacy choices/Manage cookies Your US state
    privacy rights Accessibility statement Terms and conditions Privacy policy Help
    and support 129.93.161.219 Big Ten Academic Alliance (BTAA) (3000133814) - University
    of Nebraska-Lincoln (3000134173) © 2024 Springer Nature"'
  inline_citation: '>'
  journal: Internet of Things
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Internet of Things and Dew Computing-Based System for Smart Agriculture
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Tarek Z.
  - Elhoseny M.
  - Alghamdi M.I.
  - EL-Hasnony I.M.
  citation_count: '0'
  description: The world's population is expected to exceed 9 billion people by 2050,
    necessitating a 70% increase in agricultural output and food production to meet
    the demand. Due to resource shortages, climate change, the COVID-19 pandemic,
    and highly harsh socioeconomic predictions, such a demand is challenging to complete
    without using computation and forecasting methods. Machine learning has grown
    with big data and high-performance computers technologies to open up new data-intensive
    scientific opportunities in the multidisciplinary agri-technology area. Throughout
    the plant's developmental period, diseases and pests are natural disasters, from
    seed production to seedling growth. This paper introduces an early diagnosis framework
    for plant diseases based on fog computing and edge environment by IoT sensors
    measurements and communication technologies. The effectiveness of employing pre-trained
    CNN architectures as feature extractors in identifying plant illnesses has been
    studied. As feature extractors, standard pre-trained CNN models, AlexNet are employed.
    The obtained in-depth features are eliminated by proposing a revised version of
    the grey wolf optimization (GWO) algorithm that approved its efficiency through
    experiments. The features subset selected were used to train the SVM classifier.
    Ten datasets for different plants are utilized to assess the proposed model. According
    to the findings, the proposed model achieved better outcomes for all used datasets.
    As an average for all datasets, the accuracy of the proposed model is 93.84 compared
    to 85.49, 87.89, 87.04 for AlexNet, GoogleNet, and the SVM, respectively.
  doi: 10.1038/s41598-023-43465-4
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement View all journals
    Search Log in Explore content About the journal Publish with us Sign up for alerts
    RSS feed nature scientific reports articles article Article Open access Published:
    09 November 2023 Leveraging three-tier deep learning model for environmental cleaner
    plants production Zahraa Tarek, Mohamed Elhoseny, Mohamemd I. Alghamdi & Ibrahim
    M. EL-Hasnony  Scientific Reports  13, Article number: 19499 (2023) Cite this
    article 568 Accesses 1 Citations Metrics Abstract The world''s population is expected
    to exceed 9 billion people by 2050, necessitating a 70% increase in agricultural
    output and food production to meet the demand. Due to resource shortages, climate
    change, the COVID-19 pandemic, and highly harsh socioeconomic predictions, such
    a demand is challenging to complete without using computation and forecasting
    methods. Machine learning has grown with big data and high-performance computers
    technologies to open up new data-intensive scientific opportunities in the multidisciplinary
    agri-technology area. Throughout the plant''s developmental period, diseases and
    pests are natural disasters, from seed production to seedling growth. This paper
    introduces an early diagnosis framework for plant diseases based on fog computing
    and edge environment by IoT sensors measurements and communication technologies.
    The effectiveness of employing pre-trained CNN architectures as feature extractors
    in identifying plant illnesses has been studied. As feature extractors, standard
    pre-trained CNN models, AlexNet are employed. The obtained in-depth features are
    eliminated by proposing a revised version of the grey wolf optimization (GWO)
    algorithm that approved its efficiency through experiments. The features subset
    selected were used to train the SVM classifier. Ten datasets for different plants
    are utilized to assess the proposed model. According to the findings, the proposed
    model achieved better outcomes for all used datasets. As an average for all datasets,
    the accuracy of the proposed model is 93.84 compared to 85.49, 87.89, 87.04 for
    AlexNet, GoogleNet, and the SVM, respectively. Similar content being viewed by
    others Advanced deep learning techniques for early disease prediction in cauliflower
    plants Article Open access 27 October 2023 A novel smartphone application for
    early detection of habanero disease Article Open access 16 January 2024 Image-based
    crop disease detection with federated learning Article Open access 06 November
    2023 Introduction In the global economy, agriculture is crucial. The agriculture
    system will face more strain as the human population grows and the COVID-19 pandemic
    takes hold. Agri-technology has developed as a novel scientific area that employs
    data-intensive techniques to boost agricultural output while reducing the environmental
    impact. In contemporary agricultural activities, data is created by a variety
    of sensors that give a better understanding of the operational surroundings (weather
    conditions, dynamic crop, and soil) as well as the operation itself (data from
    machines), resulting in more precise and quicker decision-making1. Conservation
    agriculture has long been regarded as an effective and ecologically beneficial
    management strategy to boost agricultural yields. In addition, measuring the total
    impact of conservation agriculture on crop output amelioration by taking the average
    of the entire dataset is not unfamiliar. Nevertheless, the influence of conservation
    agriculture on yielding cleaner output should be examined2. Plant disease and
    pest identification are critical research areas in the realm of machine learning.
    To determine whether or not a plant image contains diseases or pests, machine
    vision equipment is used3. Are these types of detection systems needed? A vital
    food security hazard is plant disease. Agricultural and population growth are
    affected by plant diseases, as is the economy. Disease control, food safety, and
    anticipated loss of income need an automated and exact estimation of plant disease
    gravity. Plant diseases must thus be identified and treated at an early stage.
    Non-expert farmers, on the other hand, are frequently oblivious to non-native
    illnesses, necessitating consultation with experts to determine whether there
    are any strange symptoms or appearances on their crops. A farmer may have to travel
    vast distances to consult with an expert, which is costly and time-consuming.
    To automate the process of identifying plant illnesses, these difficulties motivate
    research and expansion in this area. The essential requirement for a plant disease
    diagnosis model that can operate in an Internet of Things (IoT) environment with
    minimal processing capabilities is very important4. Already, machine vision is
    being used in agriculture to detect plant diseases and pests. While artificial
    intelligence (AI) is still a long way from being widely deployed, the technology
    has tremendous development potential and application value5. Plant diseases have
    been classified and identified using machine learning (ML) models. Nonetheless,
    with improvements in deep learning (DL), this field of research looks to offer
    enormous promise for greater accuracy. When it comes to planting disease detection,
    multiple DL structures have been developed or modified, as have many visualization
    methodologies. Various performance measurements are also used to evaluate these
    architectures and techniques6. As a result, several researchers have sought to
    build robust plant disease detection systems that require a high number of disease-infected
    specimens to be successful. In the past, collecting such a vast number of samples
    was difficult. Thanks to the Internet of Things, we can now gather and diagnose
    diseases within the human body! As part of the Plantvillage datasets, there are
    a lot of photos of corpses with various diseases. Because it is well-labeled and
    extensively utilized, this dataset has been used in several plant disease detection
    studies. To maximize their harvests, the farmers also want an easy-to-use detection
    system that they can use on their phones to identify plant diseases and remove
    them early. Using image processing methods, Plant disease farmers and researchers
    may be able to diagnose plant ailments more precisely. Image processing techniques
    for detecting sickness can also yield satisfactory results, but they require human
    intervention for other detection and analysis7,8,9. According to these challenges,
    we aim to improve the quality of the product and arrive at cleaner production.
    For plant disease and pest identification using machine vision, the emphasis has
    switched from standard machine learning and image processing approaches to deep
    learning techniques in fog environments, which have handled complex previously
    unsolvable issues. The paper contribution handles four-folds. The first fold is
    using IoT sensors to generate data and images; there are many sensors used in
    this field, such as soil moisture, humidity, and temperature, light-dependent
    resistors, water level, relay module, analog extender, and buzzer ESP 8266. These
    images were preserved for ten economically and environmentally beneficial plants.
    Leaf pictures of these plants in ideal and dire circumstances have been collected
    and dispersed across two categories. In this paper, datasets that focus on plants
    with significant ecological and economic benefits to their ecosystems are examined.
    As a result, ten plants, popularly known as Arjun, Mango, Guava, Saptaparni, Jamun,
    Bael, Sukh Chain, Jatropha, Pomegranate, Basil, Chinar, and Lemon, have been picked.
    To name just a few, some of these plants have high medicinal value; others are
    popular for their fruits, and the vast majority are environmentally and economically
    significant. Algorithms and models based on deep learning must be successfully
    integrated with agricultural and plant protection experience to fully exploit
    AL and ML''s potential in the second fold. Three deep learning models applied
    for plant disease detection are AlexNet, one of the most widely used neural network
    designs nowadays, GoogleNet, one of the most significant advances in the domain
    of Neural Networks, notably for CNNs the support vector machine (SVM). These models
    are utilized to the deep extracted features generated by the pre-trained CNN layers,
    AexNet, and we extracted the (fc7) layer as our feature extracting layer. After
    feeding images into that layer, we can receive features of the images from it.
    After having all the features, we could use them for training the classifiers.
    Then, a comparative study among the three models is conducted to show the accuracy
    of the three models. The third fold is using a fog environment for computing all
    necessary tasks of image preprocessing, visualization, monitoring, and local decision
    support systems for detection and prediction tasks. As a new way of extending
    and assisting cloud computing, Fog Computing is a rapidly evolving technology.
    Its proximity to edge users, openness, and mobility, make fog computing platforms
    ideal for providing services to users quickly and improving the QoS (Quality of
    Service) of Internet of Things devices. A customer application based on IoT involving
    real-time activities in agriculture is increasingly reliant on this method10.
    Lastly, developing a novel version of the grey wolf optimization algorithm (GWO)
    for selecting the important features to feed to the classifiers. This process
    is very important to select the relevant features to accelerate the prediction
    models with fair accuracy. The selected features are fed to the SVM and compared
    to the standard model, which used all the features from AlexNet. The remainder
    of the paper is structured as follows: “Related work” provides some studies about
    the recent work. An overview of the basic concepts and methods utilized in this
    paper is presented in “Methods and overviews”. “Proposed methodology” provides
    the suggested methodology in detail. The experiment setting and results are shown
    in “Experimental results and discussion”. “Conclusion and future work” concludes
    with a look at what''s next. Related work Abbas et al.11, presented a technique
    based on deep learning for tomato disease diagnosis. To categorize tomato leaf
    pictures into ten disease categories, the DenseNet121 approach was trained on
    real and synthetic images using transfer learning. The suggested approach attained
    an accuracy of 97.11%, 98.65%, and 99.51% for the classification of leaf images
    into 10 classes, 7 classes, and 5 classes, respectively. Thenmozhi and Reddy12,
    proposed a powerful CNN approach, and transfer learning is being applied to achieve
    the best or a desired performance of the pre-training model. Three public insect
    datasets were used to classify insect species, with accuracy rates of 96.75 percent,
    97.47 percent, and 95.97 percent, respectively. Wiesner-Hanks et al.13, utilized
    community data for training a CNN, and nutrition the output into a conditional
    random field (CRF) to divide pictures into non-lesion and lesion areas with an
    accuracy of 0.9979 and F1 score of 0.7153. Too et al.14, utilized DenseNets, which
    have a propensity to always progress in accuracy as the number of iterations increases,
    with no evidence of performance decay or overfitting. For the classification of
    plant disease, an accuracy score of 99.75% was achieved. Chen et al.15, presented
    CNN architecture depended on a gliding window to construct a structure for location
    regression calculation and recognition of pests’ species and plant diseases, feature
    fusion, characteristics automatic learning, and the identification rate of 38
    frequent symptoms was 50–90%. Zhou et al.16, demonstrated a rapid approach for
    the detection of rice diseases founded on the combination of Faster R-CNN and
    FCM-KM. The sheath blight, bacterial blight, and detection accuracy, and rice
    blast time were 98.26 percent/0.53 s, 97.53 percent/0.82 s, and 96.71 percent/0.65
    s respectively, based on the application results of 3010 images. Sethy et al.17
    presented 5932 on-field pictures of 4 different kinds of rice leaf illnesses:
    brown spot, bacterial blight, tungro, and blast. Furthermore, the effectiveness
    of eleven CNN architectures in the deep feature with SVM and the transfer learning
    approach was assessed. According to the experimental findings, the deep feature
    of ResNet50 with SVM outperforms transfer learning equivalent in classification.
    Deep learning-based methods for identifying illnesses and pests in rice plant
    pictures have been developed by Rahman et al.18. A two-stage tiny CNN design was
    developed, and it was compared to SqueezeNet, NasNet Mobile, and MobileNet. The
    simulation findings demonstrated that the suggested framework could attain the
    necessary accuracy of 93.3%. Guo et al.19 presented a mathematical model based
    on deep learning for the recognition of plant disease and detection. The model
    was tested for illnesses such as rust diseases, black rot, and bacterial plaque.
    The results indicated that the accuracy of the model is 83.57%, which is greater
    than the previous technique, decreasing the impact of illness on agricultural
    productivity and being beneficial to agriculture''s long-term improvement. Atila
    et al.20, presented the EfficientNet model for the plant leaf disease classification,
    and the performance of the model was compared to existing previous deep learning
    techniques. The experimental findings revealed that the B4 and B5 approaches of
    the EfficientNet attained the greatest rates in the original and enhanced datasets,
    with the accuracy of 99.91% and 99.97%, and precision of 98.42% and 99.39% respectively.
    There are many studies for plan disease prediction as in Refs.7,8,9,21. Table
    1 summarizes the role of ML/DL in agriculture for plant diseases classification
    using accuracy measurement as mentioned by many authors. It is observable that
    most of the recent works use the PlantVillage dataset and deploying a set of pre-trained
    CNN models. In this paper, new datasets have been used for testing our proposed
    architecture for plant disease classification. Table 1 ML/DL for plant disease
    detection. Full size table The next section handles an overview of the problem
    statement and the used methods in this paper. Methods and overviews Overvies Climate
    change, population expansion, and food security concerns have pushed the sector
    to explore more creative ways to agricultural yield protection and improvement.
    As a result, artificial intelligence (AI) is progressively developing as a component
    of the industry''s technical growth31. Popular applications of traditional machine
    learning algorithms in agriculture are: Recognition/harvesting of vegetables and
    fruits. Plant disease classification/pest detection. Crop/weed discernment and
    classification. Plant/leaves recognition and classification. Land cover classification.
    In comparison to the defined segmentation, detection, and classification tasks
    in computer vision, the criteria for detecting pests and plant diseases are quite
    broad. Its needs may be classified into three categories: what, where, and how.
    Even though, the fact that the function needs and aims of the 3 phases of plant
    disease and pest detection are distinct, the three stages are mutually inclusive32.
    The classification job in computer vision is represented by \"what\" in the first
    step. Classification defines the image globally using feature expression and then
    decides if the image contains a certain type of object using the classification
    process. While structure learning is the primary research path in object detection,
    feature expression is the primary research path in classification tasks. Machine
    learning (ML) has developed alongside high-performance computation and big data
    technologies to open up new avenues for unraveling, quantifying, and comprehending
    data-intensive processes in agricultural operational contexts. ML offers machines
    the capacity to learn without being precisely programmed33. Convolutional neural
    networks (CNNs) are more complex to construct than traditional neural networks,
    but they are simpler to utilize. It is not required to extract picture characteristics
    independently in the case of this sort of neural network. In image classification
    problems, complex and pre-trained CNNs with millions of parameters are frequently
    utilized. Their complete training is difficult since it is a time-consuming and
    labor-intensive procedure34. With developments in machine learning (ML) principles,
    significant gains in agricultural activities have been noticed. The capacity to
    extract features automatically generates an adaptable nature in deep learning
    (DL), especially CNNs, which achieves human-level accuracy in a variety of agricultural
    applications, prominent among which are crop/plant recognition, fruit counting,
    land cover classification, weed/crop discrimination, and plant disease detection
    and classification35. Methods Transfer learning. Data Transfer Learning (DTL)
    is a strategy in which knowledge derived from the data is transferred to solve
    various but associated assignments to train the CNN, including new data that often
    comes from a lower population36. To initialize the models and pre-train two profound
    convolutionary neuro-network models, transfer learning was used: AlexNet and GoogleNet.
    AlexNet is expected to be the first recommended deep CNN technology due to its
    remarkable outcomes for the identification and classification functions on image
    data37. In an attempt to improve hardware constraints and obtain the total functionality
    of deep CNN, AlexNet was trained on two parallel GPUs. In AlexNet, the CNN depth
    was widened from only five layers in the LetNet CNN to eight layers in the way
    to produce CNN appropriate to different data sets of images. Dropout, ReLU, and
    pre-processing are major attributes to attain significant improvement in computer
    vision applications. The common 8 layers are five convolutional layers, two fully
    connected hidden layers, and one fully connected output layer, as shown in Fig.
    138. Figure 1 An illustration of AlexNet layers. Full size image In this study,
    we replaced the 1000 classes that the original AlexNet had, with only 2 classes
    which we evaluated in this paper, healthy images and diseased images of 10 different
    plants as illustrated in the dataset description. GoogleNet consists of 22 layers
    deep CNN that is a version of the inception network established by Google researchers.
    The design of the GoogleNet structure resolved many constraints that appeared
    for large networks, primarily out of the use of the Inception module. The structure
    diagram of the GoogleNet network is shown in Fig. 239. Figure 2 GoogleNet network
    structure diagram. Full size image GoogleNet consists of inception modules, so
    its architecture is complex. GoogleNet is looked like one of the initial CNN architectures
    to resist successively accumulating convolutions and pooling layers. In addition,
    GoogleNet plays a vital role in consideration of storage and power, since accumulating
    all tiers and combining different restrictions would take time for computation
    and will result in higher costs of memory40. Support vector machine The deep feature
    extraction technique necessitates the training of a classifier method with the
    extracted features. Vapnik''s SVM was utilized as a classifier in this study41.
    It has been found that the SVM classifier outperforms others in several agricultural
    image categorization tasks. The support vector machine is a classifier with a
    linear or non-linear relationships that is capable of distinguishing between two
    different types of objects. SVMs are machine learning approaches focused on cambered
    improvement that operate as stated by the concept of structural risk reduction.
    These approaches are separate of distribution, as it does not need any details
    on the common distribution functions42. SVM training can be illustrated with algorithm
    143. While a hyperplane classifier can distinguish between 2 classes, certain
    categories surpass the highest distance set as the most effective separation hyperplane.
    The objective of SVM is to construct an ideal hyperplane space by utilizing training
    sets40. The main idea behind using SVM to solve a classification issue is to find
    a hyperplane that best separates data from two groups. The formula for a linear
    SVM''s output is presented in Eq. (1), where \\(\\overrightarrow{w}\\) is the
    hyperplane''s normal vector and \\(\\overrightarrow{x}\\) is the input vector.
    Margin maximization may be thought of as an optimization issue: reduce Eq. (2)
    subject to Eq. (3) where yi and \\(\\overrightarrow{x}\\) are the SVM''s correct
    output and input vector for the ith training sample, respectively44. $$ u{ } =
    { }\\vec{w}.{ }\\vec{x} - {\\text{b}} $$ (1) $$ 1/2\\left\\| {\\vec{w}} \\right\\|2
    $$ (2) $$ yi{{(\\vec{w}}}{{.\\vec{x} - b)}} \\ge {1,}\\forall i $$ (3) SVM is
    a binary classifier that can only distinguish between two classes and does not
    handle multi-class classification issues. One approach to classification of multi-class
    using SVMs is to build a one-to-one group of classifiers and forecast the class
    picked by the majority of classifiers45. While this allows for the creation of
    K (K + 1)/2 classifier for the classification issue with K classes, the classifiers
    training time may be decreased because the training data set for every classifier
    is lower. In this article, SVM is used to analyze data in addition to CNN techniques
    such as AlexNet and GoogleNet. Grey wolf optimization (GWO) algorithm Mirjalili
    et al. proposed the grey wolf optimizer (GWO) as a novel swarm intelligence method46.
    The GWO method has been successfully utilized and applied in a variety of research.
    The primary inspiration for the GWO algorithm came from the social pursuit of
    grey wolves in nature. Figure 3 depicts the social hierarchy as well as an instance
    of the position update process47. Figure 3 GWO’s social structure and position
    update method. Full size image In the GWO algorithm, the first, second, and third
    best-recommended solutions are alpha (α), beta (β), and delta (δ). Omega is projected
    to be the outstanding solution. The wolves can be presented in a form that is
    representable mathematically in Eqs. (4–8) during the hunting process: $$\\overrightarrow{D}=\\left|\\overrightarrow{C}.
    {\\overrightarrow{X}}_{P}-{\\overrightarrow{X}}_{\\left(t\\right)}\\right|$$ (4)
    $${\\overrightarrow{X}}_{\\left(t+1\\right)}={\\overrightarrow{X}}_{P\\left(t\\right)}-\\overrightarrow{A}.\\overrightarrow{D}$$
    (5) $$\\overrightarrow{A}=2 \\overrightarrow{a}. \\overrightarrow{rand1}-\\overrightarrow{a}$$
    (6) $$a=2\\times (1-\\frac{t}{{t}_{max}})$$ (7) $$\\overrightarrow{C}=2. \\overrightarrow{rand2}$$
    (8) where x is the grey wolf''s vector position, xp is the prey''s vector position,
    D is the distance between x and xp, t is the current iteration number, and A and
    C correspond to component-wise multiplication. The \"A'' parameter is given in
    a [− a, a] random value according to the \"a\" value. Whether a gray wolf attacks
    or not, the value of A can be determined. As a result of the calculation, the
    gray wolf is exceptionally close to the hunt and can attack at any time if |A < 1|
    status is available. The gray wolf leaves a beast in the case of |A > 1|, hoping
    for a new beast. Another critical parameter of control, C, is recognized as the
    exploration component of the algorithm and may include random values within the
    range [0, 2]. This variable leads to a random behavior of the algorithm that prevents
    an optimization at optimum local values. This condition happens if the random
    conduct is minimized by |C < 1| or else |C > 1|47. To mimic grey wolf hunting
    behavior, Eqs. (9–14) show how grey wolves are positions updating of α, β, and
    δ wolves. It is accepted that the wolves of α, β, and δ are closest to the prey
    and attract the rest of the wolves to the prey area. The grey wolf population
    can use the following formulae to determine prey position: $${\\overrightarrow{D}}_{\\alpha
    }=\\left| {\\overrightarrow{C}}_{1} . {\\overrightarrow{X}}_{\\alpha }-\\overrightarrow{X}\\right|$$
    (9) $${\\overrightarrow{D}}_{\\beta }=\\left| {\\overrightarrow{C}}_{2} . {\\overrightarrow{X}}_{\\beta
    }-\\overrightarrow{X}\\right|$$ (10) $${\\overrightarrow{D}}_{\\delta }=\\left|
    {\\overrightarrow{C}}_{3} . {\\overrightarrow{X}}_{\\delta }-\\overrightarrow{X}\\right|$$
    (11) $${\\overrightarrow{X}}_{1}={\\overrightarrow{X}}_{\\alpha }(t)-{\\overrightarrow{A}}_{1}.({\\overrightarrow{D}}_{\\alpha
    })$$ (12) $${\\overrightarrow{X}}_{2}={\\overrightarrow{X}}_{\\beta }(t)-{\\overrightarrow{A}}_{2}.({\\overrightarrow{D}}_{\\beta
    })$$ (13) $${\\overrightarrow{X}}_{3}={\\overrightarrow{X}}_{\\delta }(t)-{\\overrightarrow{A}}_{3}.({\\overrightarrow{D}}_{\\delta
    })$$ (14) The locations are determined from Eqs. (12–14) is utilized to modify
    the next location of the wolves by Eq. (15): $${\\overrightarrow{X}}_{\\left(t+1\\right)}=\\frac{\\left({\\overrightarrow{X}}_{1}+{\\overrightarrow{X}}_{2}+{\\overrightarrow{X}}_{3}\\right)}{3}$$
    (15) where xt + 1 is the location of the next iteration. Using Eq. (15) to find
    a new location for the leading wolves drives the Omega wolves to change their
    locations to converge with prey. The GWO algorithm sequence consists of three
    steps: initialization, fitness calculation, swarm individual position updates,
    and the best result generation. The optimization process starts with the starting
    value for all control parameters, and all gray wolves are altered in regular intervals.
    The fitness function is then calculated based on the initial data, and the best
    solutions are identified as wolves of alpha, beta, and delta. The next step is
    to upgrade all gray wolves other than delta, beta, and alpha wolves. The next
    step is to renew all gray wolves'' positions and controller parameter values,
    followed by Alpha, Beta, and delta wolves. Finally, the alpha wolf returns its
    optimal position value. Fog computing and IOT The providers of cloud computing
    frequently utilize data centers that consider a variety of factors, including
    energy consumption and user proximity. Thus, the cloud layer, the top layer, often
    comprises a cloud infrastructure made up of data centers that provide resources
    and amenities that are dynamically assigned according to the demands of the users.
    These services could include networking, storage, and server (rendering tools,
    computational power, and so on) capabilities48. Fog Computing attempts to bring
    processing capabilities closer to end-users, preventing overuse of Cloud resources,
    further lowering computational burdens, enhancing load balancing, and shortening
    wait times49,50. The Internet of Things (IoT), which represents the future of
    communications and computers, is a breakthrough technology. IoT is now used in
    almost every sector, including intelligent cities, intelligent traffic control,
    and intelligent homes. The deployment of IoT is wide and may be applied in any
    field. IoT aids in better resource and crop management, crop monitoring, cost-effective
    agriculture, and increased quantity and quality. Air temperature sensors, soil
    moisture, soil pH, water volume, humidity, and other IoT sensors are employed47.
    Figure 4 shows IoT in agriculture using edge computing, fog computing, and cloud
    computing. Figure 4 Smart agriculture IoT with edge, fog, and cloud computing.
    Full size image The key benefits of IoT in agriculture are discovered in these
    points51: Community agriculture in rural and urban regions, utilizing software
    and hardware resources as well as vast amounts of data. Quality and logistical
    traceability of food security that allows reduced costs via real-time decision-making
    data. Business strategies established in the agricultural setting that enable
    direct consumer contact. Crop surveillance allows cost savings and machine robbery
    avoidance. Systems of automatic irrigation that operate based on soil moisture
    levels, and temperature measured by sensors. Environmental characteristics are
    automatically collected via sensor networks for subsequent analysis and processing.
    Large quantities of data are analyzed by decision support systems to increase
    production and operational efficiency. At the end of this section, we can summarize
    this paper in 3 folds; the first is applying DL models (AlexNet, GoogleNet) to
    extract features from plants. Secondly is using an optimization algorithm called
    the modified grey wolf optimization algorithm for eliminating the redundant features.
    The third is the classification of the output images using the support vector
    machine. The above techniques are divided to be used some processes in Fog and
    some processes in cloud computing. The next section introduces the architecture
    of the proposed solution using the deep learning techniques referred to above.
    Proposed methodology As technology advances, smart agricultural solutions are
    becoming more prevalent. Since then, technology has returned to agriculture with
    the latest trends and techniques it has produced. A significant advantage of smart
    agriculture is connecting to existing 3G and 4G networks using existing hardware
    and software. For smart agriculture solutions, it speeds up setting up hardware,
    resulting in the various successful implementation of IoT in agriculture that
    can run in a fog or cloud environment. There will be an evolution from the existing
    standard mobile computing scenario of smartphones and their apps to the connection
    of gadgets around us to help solve a real-world problem52. We’ll discuss in this
    section the proposed methodology based on the mentioned transfer learning, pretraining
    methods, and the optimization algorithm on fog and cloud computing using IoT sensors
    common in the problem statement of this paper. Figure 5 shows the block diagram
    of the proposed IoT smart agriculture network architecture which consists of three
    layers. The first layer contains the IOT devices that are used for different purposes
    in agriculture. Many technologies are being used in IoT agricultural solutions
    which have an important role in modernizing the services of IoT agriculture. Examples
    of these technologies are cloud and edge computing, machine learning and big data
    analytics, communication networks and protocols, and robotics. The second layer
    presents the sequence of work in this paper from collecting the images from IoT
    sensors then preprocessing these images if they need to resize, or normalize,
    or removing noise according to the recommended DL algorithms in this paper (CNN,
    SVM). All processes happened on the images from collecting it till detection of
    plant diseases are applied on fog environment to facilitate the function of scalability
    and stability that are advantages of fog computing. The third layer is connecting
    with cloud computing for henting resources for further and large processing. The
    other proposed models don’t suitable for cloud or fog computing, so we proposed
    a new model for plant disease detection using machine learning techniques by the
    Internet of Things (IoT) sensors that can run on fog or cloud environments. Figure
    5 Block diagram of the proposed IoT smart agriculture network architecture. Full
    size image The proposed model depends on deep learning, transfer learning, and
    shallow machine learning. In deep learning, multi-hidden layers are stacked for
    learning objects significantly. These layers require a training process including
    “fine-tuning” for adjusting the weights slightly of DNN discovered during the
    procedure of backpropagation. In turn, following an efficient training procedure,
    DL nets can categorize, extract characteristics, and give a decision effectively
    and accurately. In the proposed model, we use transfer learning to optimize different
    pre-innovated CNNs architectures to the datasets. As seen in Fig. 6, the proposed
    model starts by a data acquisition layer in which images are collected for different
    plants. This acquisition procedure was entirely wi-fi enabled, which means that
    the camera and the computer were linked with each other via the internet. In the
    preprocessing phase, the images are reconstructed and resized since the images
    are taken from various sources and their dimensions vary. In addition, the model
    layer of each of these products needs separate image dimensions to be managed.
    Therefore, the input image size is adjusted to fit the templates that are used
    in this analysis. Figure 6 Dataflow diagram of the proposed methodology. Full
    size image The feature extraction layer comes after image enhancements that represent
    the layer in which most of the calculations are carried out. The calculations
    include extracting image data set features and preserve the spatial relationship
    between image pixels. A pre-trained CNN, AlexNet, was used as feature extraction
    and we extracted the ’fc7’ layer as our feature extracting layer. After extracting
    the features, it is the role of feature subset selection to reduce the features
    and eliminate the irrelevant features. The proposed model makes use of a modified
    version of the grey wolf optimization algorithm. The details of the modified grey
    wolf optimization algorithm (MGWO) are explained in the next subsection. After
    that, the generated features set were utilized to train the SVM. Once we get the
    baseline SVM, we use a validated data set to adjust SVM parameters. Modified grey
    wolf optimization algorithm (MGWO) Mirjalili showed that The GWO algorithm tends
    to become stuck at optimal local values because of the small number of control
    parameters utilized in its simplest form. Because of this, researchers modified
    GWO by adding additional controls and changing control parameter values. According
    to their findings, the alpha-wolf was more powerful than the delta—and beta-wolf
    when searching for food. So, it''s possible to acquire better outcomes in tests
    in this manner. For this reason, there is much research in the literature that
    has adapted and developed the grey wolf algorithm in various sectors. As a result
    of this, it produces superior outcomes in tests47. The parameter adjusted equation
    for the \"a\" parameter was used in this study to improve the method50 significantly.
    However, instead of using the usual GWO Eq. (7), this study uses Eq. (16) to derive
    the parameter \"a\" instead. $$a=2\\times ({e }^{\\frac{-t\\times s}{tmax}})$$
    (16) \"s\" is only added in Eq. (16) to \"a\", and it reflects the total number
    of individuals in the swarm, as seen in Eq. (16). Standard GWO has a linearly
    decreasing \"a\" parameter, which prevents the algorithm from settling on local
    minimum values. Researchers found that as the \"a\" attribute approaches 0, it
    not only keeps the algorithm from reaching a locally minimal value but also considerably
    enhances its strength. Therefore, the method converges on the optimal values faster
    when this parameter is reduced from 2 to 0. So, the program has sped up and parabolically
    slowed down from 2 to 0. Moreover, it can be seen from the governing Eq. (15)
    that the dominants perform a similar function in the searching procedure; each
    of the grey wolves converges or flees away from the surroundings with an average
    weight of the beta, delta, and alpha. Even if the alpha is closest to the victim
    at first, it may be distant from the eventual result. Only the alpha position
    should be considered in Eq. (15) at the beginning of the search operation, or
    its weight should be substantially more significant than that of other dominants.
    Equation (15)''s average weight, on the other hand, contradicts the grey wolf
    social hierarchy idea. If the pack''s social hierarchy is strictly observed, the
    alpha is in charge, which could mean that he/she will always be the closest to
    the prey. This indicates that the alpha wolf''s weight in Eq. (15) should never
    be smaller than that of the delta and beta wolves. As a result, the beta''s weight
    should always be more than the delta''s. In light of these concerns, the authors53
    further hypothesize the following: (1) The dominants surround a supposed prey
    when it is being searched for, but they do not surround an actual prey when being
    hunted. As their social hierarchy dictates, the dominant grey wolves encircle
    the prey in order of their dominance. The alpha is the closest wolf in the pack,
    followed by the beta and the delta. Omega wolves play a role in this process,
    passing on their superior positions to the dominants. (2) Alpha controls the search
    and hunting process, while beta has a minor role, and delta has an even smaller
    one. A wolf''s position changes if an alpha wins out over his/her peers. Equation
    (15) should not use the same updating procedure for the positions as the previous
    hypotheses. Thus, the alpha weight should be near 1.0 at the beginning, whereas
    delta and beta weights could be close to 0. According to Eq. (15), the delta,
    beta, and alpha wolves should surround the victim at the final stage. During the
    entire process of searching, the alpha is always found by the beta, and the beta
    always finds the delta because he/she is always ranked third. As a result, the
    beta and delta weights are determined by the total number of iterations. Alpha''s
    weight should be reduced, and beta and delta''s weights should rise. In mathematics,
    the above ideas could be stated. When adding up the weights, ensure that they''re
    all varying and that the aggregate is capped at 1.0. As a result, Eq. (15) is
    altered to the following: $${\\overrightarrow{X}}_{\\left(t+1\\right)}={w}_{1}{\\overrightarrow{X}}_{1}+{w}_{2}{\\overrightarrow{X}}_{2}+{w}_{3}{\\overrightarrow{X}}_{3}$$
    (17) $${w}_{1}+{w}_{2}+{w}_{3}=1$$ As a second rule, when calculating the alpha
    w1, beta w2, and delta w3 weights, they should always satisfy w1 >  > w2 > w3.
    Along with the search technique, the weight of the alpha would be adjusted from
    1.0 to 1/3. While doing so, we''ll boost beta and delta''s weights, increasing
    them from 0.0 to 1/3 in the process. W1 can be described using a cosine function
    if we limit the angle range to be between [0, arccos (1/3)]. The weights should
    be adjusted based on the total iterations or \"it\" as a third point. And we recognize
    that w2⋯w3 ⟶ 0 if it = 0 and w1, w2, w3 ⟶ 1/3 when it ⟶ ∞. As a result, we present
    an arc-tangent function that changes from 0.0 to π/2. And then, somehow, cos (π/4) = sin
    (π/4) = − 2 √ /2, so different angular parameter φ was organized as seen below53:
    $$\\mathrm{\\varphi }=\\frac{1}{2}\\mathrm{ arctan}(it)$$ (18) Given that w2 would
    be maximized from 0.0 to 1/3 alongside it, we assume that it includes cos φ and
    sin θ and θ ⟶ arccos (1/3) when it ⟶ ∞; hence, $$\\uptheta =\\frac{2}{\\uppi }\\mathrm{arccos}\\frac{1}{3}.\\mathrm{arctan}(it)$$
    (19) when it ⟶ ∞, θ ⟶ arccos (1/3), w2 = 1/3, we can then formulate w2 in detail.
    The following is a new updating method for positions with variable weights that
    are based on these principles: $${w}_{1}=\\mathrm{cos\\theta },$$ (20) $${w}_{2}=\\frac{1}{2}\\mathrm{sin\\theta
    }.\\mathrm{ cos \\varphi },$$ (21) $${w}_{3}=1-{w}_{1}-{w}_{2}$$ (22) The flowchart
    of the Modified Gray Wolf Optimization (MGWO) algorithm is shown in Fig. 7. Figure
    7 Flowchart of the grey wolf optimization algorithm. Full size image The pseudocode
    of the MGWO is presented in algorithm 2. Experimental results and discussion Performance
    measures True positives, true negatives, false negatives, and false positives,
    and are displayed separately in the table, in two rows and two columns, accordingly
    (sometimes also referred to as a confusion matrix). In this way, the classification
    proportion can be studied in greater detail (accuracy). An unbalanced data collection
    (i.e., when the number of observations in different classes changes dramatically)
    will lead to inaccurate conclusions. Sensitivity and specificity are also valuable
    traits to have. As shown in Table 254, the most widely used measures are used
    to create the confusion matrix (Data science, 2019). Five measurements are utilized
    in this article to gauge our work performance, these measurements are shown in
    Table 3. Table 2 The confusion matrix. Full size table Table 3 Performance measures.
    Full size table Experiment 1 We provided the results as two experiments. For the
    first experiment, a modified grey wolf optimization method (MGWO) for feature
    selection is being evaluated. When developing a machine-learning model, feature
    selection is becoming increasingly important. The feature selection process involves
    deleting irrelevant or redundant characteristics and picking the ideal subset
    of features that better categorize patterns that belong to different plants. The
    evaluation is made by using fifteen standard feature selection datasets. The overall
    properties of these datasets are given in Table 455. Table 4 Datasets used for
    evaluating the MGWO. Full size table Using a random seeding strategy, a random
    population of n wolves or search agents is formed in the first part of the procedure.
    An ideal solution is found when the number of features \"d\" equals that of the
    original dataset features set. When selecting features for purity classification,
    make sure they enhance accuracy. Identify the appropriate characteristics (one
    value) and discard the rest (zero). Initially, the binary values (0 and 1) were
    set in each solution. A large part of GWO''s success depends on the development
    of initial populations. We use chaotic initialization of maps to increase the
    global convergence speed of the MGWO optimization process. Instead of a standard
    map, a chaotic map serves to improve the balance of search-and-exploitation skills.
    The logistics map is one of the most effective chaos-based approaches. It is represented
    as follows in Eq. (28) 56. $$ {\\text{X}}_{{{\\text{n}} + {1}}} = \\, \\phi \\left(
    {{\\text{X}}_{{\\text{n}}} , \\, \\mu } \\right) = \\, \\mu \\times {\\text{ X}}_{{\\text{n}}}
    \\left( {{1} - {\\text{ X}}_{{\\text{n}}} } \\right) $$ (28) where μ is set to
    4, the bifurcation coefficient is also defined. xn means the nth chaotic variable,
    in other words, xn ∈ (0, 1) in favor of limitations that the initial x0 ∈ (0,
    1) of severely static periods (0, 0.25, 0.5, 0.75,1). Figure 8 of the logistic
    map shows a consistently divided sequence, which prevents it from effectively
    immersing into minor regular cycles. Figure 8 Flowchart of logistic map for initialization.
    Full size image Because the problem has more than one objective, it is understood
    to be a multi-objective problem57. Following steps must be taken to solve the
    multi-objective issue of selecting optimal features. The first is to produce the
    highest accuracy rate, and the second is to eliminate the features to the lowest
    range. Taking this into consideration, the fitness function of the resulting solution
    evaluation is configured to balance the aims as follows: $$\\mathrm{fitness}=\\mathrm{\\alpha
    }{\\upgamma }_{\\mathrm{R}}\\left(\\mathrm{D}\\right)+\\upbeta \\frac{\\left|\\mathrm{S}\\right|}{\\left|\\mathrm{D}\\right|}$$
    (29) Given that \\(\\left|S\\right|\\) for the length of the selected subset feature
    cardinality, \\(\\alpha \\) and \\(\\beta \\) are generated as parameters for
    expressing a weight for the percentage of classification accuracy and the total
    number of selected features respectively, α ϵ [0,1] and β = 1 − α and have been
    selected concerning the evaluation function, \\({\\gamma }_{R}\\left(D\\right)\\)
    denotes the classification error rate. \\(\\left|D\\right|\\) represents dataset
    cardinality. So, to find the K neighbors for the KNN classifier, the Euclidean
    distance58 must be calculated as follows: $${\\mathrm{EUC}}_{\\mathrm{d}}\\left(\\mathrm{P},\\mathrm{Q}\\right)=\\sqrt{\\sum_{\\mathrm{i}=1}^{\\mathrm{d}}{\\left({\\mathrm{Q}}_{\\mathrm{i}}-{\\mathrm{P}}_{\\mathrm{i}}\\right)}^{2}}$$
    (30) Qi and Pi relate to a specific feature in the sample, \"i\" refer to the
    number of features in the sample, and d refers to the overall number of features
    used in the analysis. To reduce overfitting, cross-validation is a popular strategy.
    Cross-validation with K = 10 is utilized in this paper. In contrast to binary
    values, continuous values represent the positions of the search agents formed
    by the algorithm. A straight application to our situation would be impossible
    because it is incompatible with the standard binary format for feature selections.
    Features are selected depending on the problem of feature selection to increase
    the performance and accuracy of the classification system (0 or 1 in the case
    of binary features). A transformation function is used to convert a binary search
    space. The following equations can convert any continuous value into binary with
    the sigmoid function57: $$ {\\text{x}}_{{{\\text{s}}_{{\\text{i}}} }} = \\frac{1}{{1
    + {\\text{e}}^{{ - 10({\\text{x}}_{{\\text{i}}} - 0.5)}} }} $$ (31) $$ {\\text{x}}_{{{\\text{binary}}}}
    = \\left\\{ {\\begin{array}{*{20}c} 0 & {{\\text{if}}\\quad {\\text{R < x}}_{{{\\text{s}}_{{\\text{i}}}
    }} } \\\\ 1 & {{\\text{if}}\\quad {\\text{R}} \\ge {\\text{x}}_{{{\\text{s}}_{{\\text{i}}}
    }} } \\\\ \\end{array} } \\right. $$ (32) where i = 1, …, d, and \\({x}_{binary}\\)
    parameter identified as 0 or 1 by randomly selected value in range: R ϵ [0,1]
    value compared to \\({x}_{{s}_{i}}\\), the value of the parameter \\({x}_{{s}_{i}}\\)
    which defined in the S-shaped search agent is the value identified by the algorithm
    calculations (continuous), All trials were conducted on a Windows 10 Pro 64-bit
    operating system with a Core(TM) i7-8550U CPU running at 1.80 GHz and 1.99 GHz,
    respectively. To implement the algorithms, we use MATLAB (2018a). The selected
    values of the algorithms to be its parameters were collected from the literature
    to make sure that the algorithms are compared on an equal basis59. Although the
    KNN classification unit for feature selection is a frequent wrapper, it can also
    be thought of as a learning algorithm that is monitored and characterized by simple
    and quick learning. There are twenty different runs for each algorithm with a
    random seed. The maximum number of iterations for all subsequent experiments using
    the standard k-fold cross-validation is 20. Multiple observational experiments
    were conducted on a variety of datasets to determine the best literature values
    for α and β. Therefore, it has the value of 0.9 for α and has the value of 0.1
    for β. The parameters settings of our experiments are shown in Table 5. Table
    5 Parameters settings. Full size table Tables 6 and 7 show the resulted feature
    and the accuracy respectively. The experimental results are conducted for the
    standard grey wolf optimization (GWO), the Ant Colony Optimization (ACO), the
    Butterfly Optimization Algorithm (BOA), the Particle Swarm Optimization (PSO),
    and the Modified Grey Wolf Optimization (MGWO) algorithms. The experimental results
    show the superiority of the proposed MGWO in both achieving the least set of features
    in all the datasets while producing a fair accuracy in most of the utilized datasets.
    These results are graphically displayed in Figs. 9 and 10. Table 6 The features
    reduction for different algorithms. Full size table Table 7 The classification
    accuracy for different algorithms. Full size table Figure 9 The features reduction
    for different algorithms. Full size image Figure 10 The classification accuracy
    for different algorithm. Full size image According to the conclusion of these
    results, we can say that the MGWO can be used for our plant disease problem. Experiment
    2 According to the experimental result in the first experiment, the modified grey
    wolf optimization algorithm (MGWO) can be effective as a wrapper feature selection
    algorithm. In experiment 2, the core problem of the plant disease classification
    and prediction is introduced. As discussed in the previous section, the first
    stage of the proposed model is the feature extraction process where the pre-trained
    AlexNet CNN is used. This process is performed for ten datasets. The second stage
    is the feature selection process, in which the MGWO is used as the wrapper feature
    section method. Lastly, the generated reduced features set were used SVM training.
    The datasets’ details are discussed in the next subsection. Datasets description
    Plants play a crucial role in climate regulation and erosion reduction. To preserve
    the environment, ecosystem, and living beings, they are both equally necessary
    to consider. Deciduous and coniferous trees are the most common types. Compared
    to conifers, deciduous trees have broader and bigger leaves. During the fall,
    their leaves fall off. This is due to the giant leaf, which allows for more photosynthesis
    to occur. Trees of this type are famous for their high wood production. There
    is a coniferous tree or evergreen tree green throughout the year. Leaves have
    a triangular form and grow upwards in most cases. Even though they have softer
    wood, they are pretty durable and resistant to various weather conditions60. The
    data on https://data.mendeley.com/datasets/hb74ynkjcn/1 focuses on plants that
    contribute both ecologically and economically. As a result, ten different plants,
    such as Jamun, Lemon, Sukh Chain, Arjun, Pomegranate, Jatropha, Mango, Saptaparni,
    Guava, and Chinar, have been selected, as shown in Table 8. Images have been divided
    into two categories: healthy and diseased images. Table 9 shows the dataset description.
    Table 8 Sample of healthy and diseased leaf images of the plant’s disease dataset.
    Full size table Table 9 Plants diseases datasets description. Full size table
    Results The proposed model (AlexNet as feature extraction, MGWO as a feature selection,
    and the SVM as a classifier) has achieved better results compared to Alexnet,
    GoogleNet, and the SVM. The results showed in Table 10 give a comparison among
    the AlexNet, GoogleNet, SVM, and the proposed model through different metrics
    such as sensitivity, specificity, precision, F1-score, and accuracy. The proposed
    model achieved the highest accuracy in all datasets except the dataset named p2
    in which the GoogleNet achieved the best accuracy. Figure 11 display the comparison
    among the different model concerning the accuracy metric. A comparison between
    the SVM which trained for the extracted features directly without feature selection
    and the SVM which trained to the selected features by the MGWO that extracted
    by AlexNet showed in Fig. 12. The ROC curve on the test set for the proposed model
    SVM is introduced in Fig. 13. Table 10 Classification results for the four models.
    Full size table Figure 11 Classification accuracy for the four models. Full size
    image Figure 12 Classification accuracy of the standard SVM Vs the proposed model.
    Full size image Figure 13 The ROC curve on the test set for the proposed model
    SVM. Full size image Conclusion and future work We present in this paper a paradigm
    for the identification of plant diseases. Initially, a comparison is undertaken
    using the SVM, AlexNet, and Google Net-based transfer training method, which will
    be used on the edge servers with increased computational capability, to detect
    plant diseases. Then, with the AlexNet feature extraction and support vector machines
    for plant detection and classification diseases, we proposed a hybrid approach
    based on the modified gray wolf optimization algorithm for eliminating the resulted
    features from the AlexNet. The proposed model can operate on Internet of Things
    (IoT) devices that use a framework that integrates fog and cloud computing with
    limited resources. Experimental evidence shows that the suggested models can detect
    plant diseases accurately using the minimum computational resources from real-world
    datasets. The proposed model worked better on most data sets. In the future, using
    blockchain technology, we hope to improve the fog environment without impacting
    the efficiency of features map extraction. We will also develop apps to detect
    plant diseases to support smart agriculture with deep learning support. Data availability
    The datasets analyzed for this study available in “https://data.mendeley.com/datasets/hb74ynkjcn/1”
    focus on plants that contribute both ecologically and economically. All datasets
    used are open access data, and we didn’t use any private data. Our research complies
    with institutional, national, and international guidelines and legislation. We
    have permissions from our institutional committee for scientific research ethics
    to do this study and to collect plants data from the open access dataset. Throughout
    the entirety of the process of generating all the plots and statistics, Microsoft
    Excel 2016 and MATLAB were utilized. On the other hand, figures were generated
    using Microsoft PowerPoint and Adobe Photoshop. All plant samples used in the
    proposed model and tables are samples from the utilized dataset, which is open
    access data. Abbreviations AI: Artificial intelligence ML: Machine learning DL:
    Deep learning GWO: Grey wolf optimization IoT: Internet of things QoS: Quality
    of service MGWO: Modified grey wolf optimization DTL: Data transfer learning SSD:
    Single shot detector RCNN: Recurrent convolutional neural network MLP: Multi-layer
    perceptron FCN: Fully convolutional neural network KNN: K-nearest neighbor VGG:
    Visual geometry group RF: Random forest SVM: Support vector machines CNN: Convolutional
    neural network DCNN: Deep convolutional neural network DAML: Deep adversarial
    metric learning CAE: Convolutional autoencoder GLDD: Grape leaf disease dataset
    GPDCNN: Global pooling extended convolutional neural network EPA: Environmental
    Protection Agency TN: True negatives FN: False negatives FP: False positives TP:
    True positives ACO: Ant colony optimization PSO: Particle swarm optimization BOA:
    Butterfly optimization algorithm References Liakos, K. G., Busato, P., Moshou,
    D., Pearson, S. & Bochtis, D. Machine learning in agriculture: A review. Sensors
    18(8), 2674 (2018). Article   ADS   PubMed   PubMed Central   Google Scholar   Xiao,
    L., Zhao, R. & Zhang, X. Crop cleaner production improvement potential under conservation
    agriculture in China: A meta-analysis. J. Clean. Prod. 269, 122262 (2020). Article   Google
    Scholar   Lee, S. H., Chan, C. S., Mayo, S. J. & Remagnino, P. How deep learning
    extracts and learns leaf features for plant classification. Pattern Recognit.
    71, 1–13 (2017). Article   ADS   Google Scholar   Ale, L., Sheta, A., Li, L.,
    Wang, Y., Zhang, N. Deep learning based plant disease detection for smart agriculture.
    In 2019 IEEE Globecom Workshops (GC Wkshps), 1–6 (2019). Liu, J. & Wang, X. Plant
    diseases and pests detection based on deep learning: A review. Plant Methods 17(1),
    22 (2021). Article   PubMed   PubMed Central   Google Scholar   Saleem, M. H.,
    Potgieter, J. & Arif, K. M. Plant disease detection and classification by deep
    learning. Plants 8(11), 468 (2019). Article   PubMed   PubMed Central   Google
    Scholar   Singh, V. & Misra, A. K. Detection of plant leaf diseases using image
    segmentation and soft computing techniques. Inf. Process. Agric. 4(1), 41–49 (2017).
    Google Scholar   Mahum, R. et al. A novel framework for potato leaf disease detection
    using an efficient deep learning model. Hum. Ecol. Risk Assess. Int. J. 29(2),
    303–326 (2023). Article   CAS   Google Scholar   Gouse, S., Dulhare, U. N. Automation
    of Rice Leaf Diseases Prediction Using Deep Learning Hybrid Model VVIR. In Advancements
    in Smart Computing and Information Security: First International Conference, ASCIS
    2022, Rajkot, India, November 24–26, 2022, Revised Selected Papers, Part I, 133–143
    (2023). Sarhan, A. Fog computing as solution for IoT-based agricultural applications.
    In Smart Agricultural Services Using Deep Learning, Big Data, and IoT, 46–68 (IGI
    Global, 2021). Abbas, A., Jain, S., Gour, M. & Vankudothu, S. Tomato plant disease
    detection using transfer learning with C-GAN synthetic images. Comput. Electron.
    Agric. 187, 106279 (2021). Article   Google Scholar   Thenmozhi, K. & Reddy, U.
    S. Crop pest classification based on deep convolutional neural network and transfer
    learning. Comput. Electron. Agric. 164, 104906 (2019). Article   Google Scholar   Wiesner-Hanks,
    T. et al. Millimeter-level plant disease detection from aerial photographs via
    deep learning and crowdsourced data. Front. Plant Sci. 10, 1550 (2019). Article   PubMed   PubMed
    Central   Google Scholar   Too, E. C., Yujian, L., Njuki, S. & Yingchun, L. A
    comparative study of fine-tuning deep learning models for plant disease identification.
    Comput. Electron. Agric. 161, 272–279 (2019). Article   Google Scholar   Chen,
    T. et al. Intelligent identification system of disease and insect pests based
    on deep learning. China Plant Prot. 39(04), 26–34 (2019). Google Scholar   Zhou,
    G., Zhang, W., Chen, A., He, M. & Ma, X. Rapid detection of rice disease based
    on FCM-KM and faster R-CNN fusion. IEEE Access 7, 143190–143206 (2019). Article   Google
    Scholar   Sethy, P. K., Barpanda, N. K., Rath, A. K. & Behera, S. K. Deep feature
    based rice leaf disease identification using support vector machine. Comput. Electron.
    Agric. 175, 105527 (2020). Article   Google Scholar   Rahman, C. R. et al. Identification
    and recognition of rice diseases and pests using convolutional neural networks.
    Biosyst. Eng. 194, 112–120 (2020). Article   Google Scholar   Guo, Y. et al. Plant
    disease identification based on deep learning algorithm in smart farming. Discret.
    Dyn. Nat. Soc. 2020, 1–11 (2020). Google Scholar   Atila, Ü., Uçar, M., Akyol,
    K. & Uçar, E. Plant leaf disease classification using EfficientNet deep learning
    model. Ecol. Inform. 61, 101182 (2021). Article   Google Scholar   Gadekallu,
    T. R. et al. A novel PCA—whale optimization-based deep neural network model for
    classification of tomato plant diseases using GPU. J. Real-Time Image Process.
    18, 1383–1396 (2021). Article   Google Scholar   Sanga, S., Mero, V., Machuve,
    D., Mwanganda, D. Mobile-based deep learning models for banana diseases detection.
    arXiv Prepr. arXiv2004.03718 (2020). Chohan, M., Khan, A., Chohan, R., Hassan,
    S. & Mahar, M. Plant disease detection using deep learning. Int. J. Recent Technol.
    Eng. 9(1), 909–914 (2020). Google Scholar   Guo, X. Q., Fan, T. J. & Shu, X. Tomato
    leaf diseases recognition based on improved multi-scale AlexNet. Trans. Chin.
    Soc. Agric. Eng. 35(13), 162–169 (2019). Google Scholar   Tan, L., Lu, J. & Jiang,
    H. Tomato leaf diseases classification based on leaf images: A comparison between
    classical machine learning and deep learning methods. AgriEngineering 3(3), 542–558
    (2021). Article   Google Scholar   Agarwal, M., Singh, A., Arjaria, S., Sinha,
    A. & Gupta, S. ToLeD: Tomato leaf disease detection using convolution neural network.
    Proc. Comput. Sci. 167, 293–301 (2020). Article   Google Scholar   Kundu, N. et
    al. IoT and interpretable machine learning based framework for disease prediction
    in pearl millet. Sensors 21(16), 5386 (2021). Article   ADS   PubMed   PubMed
    Central   Google Scholar   Zhang, S., Zhang, S., Zhang, C., Wang, X. & Shi, Y.
    Cucumber leaf disease identification with global pooling dilated convolutional
    neural network. Comput. Electron. Agric. 162, 422–430 (2019). Article   Google
    Scholar   Khamparia, A. et al. Seasonal crops disease prediction and classification
    using deep convolutional encoder network. Circuits Syst. Signal Process. 39(2),
    818–836 (2020). Article   Google Scholar   Bedi, P. & Gole, P. Plant disease detection
    using hybrid model based on convolutional autoencoder and convolutional neural
    network. Artif. Intell. Agric. 5, 90–101 (2021). Google Scholar   Faggella, D.
    Ai in agriculture—present applications and impact. Emerj Artif. Intell. Res. Insight.
    18, 2020 (2020). Google Scholar   Boulent, J., Foucher, S., Théau, J. & St-Charles,
    P.-L. Convolutional neural networks for the automatic identification of plant
    diseases. Front. Plant Sci. 10, 941 (2019). Article   PubMed   PubMed Central   Google
    Scholar   Samuel, A. L. Some studies in machine learning using the game of checkers.
    IBM J. Res. Dev. 3(3), 210–229 (1959). Article   MathSciNet   Google Scholar   Kujawa,
    S., Mazurkiewicz, J. & Czekała, W. Using convolutional neural networks to classify
    the maturity of compost based on sewage sludge and rapeseed straw. J. Clean. Prod.
    258, 120814 (2020). Article   Google Scholar   Saleem, M. H., Potgieter, J. &
    Arif, K. M. Automation in agriculture by machine and deep learning techniques:
    A review of recent developments. Precis. Agric. 22, 1–39 (2021). Google Scholar   Weiss,
    K., Khoshgoftaar, T. M. & Wang, D. A survey of transfer learning. J. Big Data
    3(1), 1–40 (2016). Article   Google Scholar   Krizhevsky, A., Sutskever, I. &
    Hinton, G. E. Imagenet classification with deep convolutional neural networks.
    Adv. Neural Inf. Process. Syst. 25, 1097–1105 (2012). Google Scholar   Hemmer,
    M., Van Khang, H., Robbersmyr, K. G., Waag, T. I. & Meyer, T. J. J. Fault classification
    of axial and radial roller bearings using transfer learning through a pretrained
    convolutional neural network. Designs 2(4), 56 (2018). Article   Google Scholar   Dhillon,
    A. & Verma, G. K. Convolutional neural network: A review of models, methodologies
    and applications to object detection. Prog. Artif. Intell. 9(2), 85–112 (2020).
    Article   Google Scholar   Özyurt, F. Efficient deep feature selection for remote
    sensing image recognition with fused deep learning architectures. J. Supercomput.
    76, 1–19 (2019). Google Scholar   Vapnik, V. The Nature of Statistical Learning
    Theory (Springer Science & Business Media, 2013). MATH   Google Scholar   Soman,
    K. P., Loganathan, R. & Ajay, V. Machine Learning with SVM and Other Kernel Methods
    (PHI Learning Pvt. Ltd., 2009). Google Scholar   Pedersen, R., Schoeberl, M. An
    embedded support vector machine. In 2006 International Workshop on Intelligent
    Solutions in Embedded Systems, 1–11 (2006). Altuntacs, Y. & Kocamaz, F. Deep feature
    extraction for detection of tomato plant diseases and pests based on leaf images.
    Celal Bayar Univ. J. Sci. 17(2), 145–157 (2021). Google Scholar   Bishop, C. M.
    Pattern recognition. Mach. Learn. 128(9) (2006). Mirjalili, S., Mirjalili, S.
    M. & Lewis, A. Grey wolf optimizer. Adv. Eng. Softw. 69, 46–61 (2014). Article   Google
    Scholar   Dereli, S. A new modified grey wolf optimization algorithm proposal
    for a fundamental engineering problem in robotics. Neural Comput. Appl. 33, 1–13
    (2021). Article   Google Scholar   Tsipis, A. et al. An alertness-adjustable cloud/fog
    IoT solution for timely environmental monitoring based on wildfire risk forecasting.
    Energies 13(14), 3693 (2020). Article   Google Scholar   Guardo, E., Di Stefano,
    A., La Corte, A., Sapienza, M. & Scatà, M. A fog computing-based iot framework
    for precision agriculture. J. Internet Technol. 19(5), 1401–1411 (2018). Google
    Scholar   Goundar, S., Bhushan, S. B. & Rayani, P. K. Architecture and Security
    Issues in Fog Computing Applications (IGI Global, 2019). Google Scholar   Gómez-Chabla,
    R., Real-Avilés, K., Morán, C., Grijalva, P., Recalde, T. IoT applications in
    agriculture: A systematic literature review. In 2nd International Conference on
    ICTs in Agronomy and Environment, 68–76 (2019). Srinivasan, G., Vishnu Kumar,
    N., Shafeer Ahamed, Y. & Jagadeesan, S. Providing smart agricultural solution
    to farmers for better yielding using IoT. Int. J. Adv. Sci. Eng. Res 2(1), 2017
    (2017). Google Scholar   Gao, Z.-M. & Zhao, J. An improved grey wolf optimization
    algorithm with variable weights. Comput. Intell. Neurosci. 2019, 1–18 (2019).
    Article   CAS   Google Scholar   What is Confusion Matrix and Advanced Classification
    Metrics? Data Science and Machine Learning-blogger. manisha-sirsat.blogspot.com
    (2019). Dheeru, E. D., Taniskidou, K. {UCI} Machine Learning Repository. (2017).
    Dwivedi, S., Vardhan, M. & Tripathi, S. An effect of chaos grasshopper optimization
    algorithm for protection of network infrastructure. Comput. Netw. 176, 107251
    (2020). Article   Google Scholar   Abdel-Basset, M., El-Shahat, D., El-henawy,
    I., de Albuquerque, V. H. C. & Mirjalili, S. A new fusion of grey wolf optimizer
    algorithm with a two-phase mutation for feature selection. Expert Syst. Appl.
    139, 112824 (2020). Article   Google Scholar   Gou, J. et al. A generalized mean
    distance-based k-nearest neighbor classifier. Expert Syst. Appl. 115, 356–372
    (2019). Article   Google Scholar   El-Hasnony, I. M., Elhoseny, M. & Tarek, Z.
    A hybrid feature selection model based on butterfly optimization algorithm: COVID-19
    as a case study. Expert Syst. 39, e12786 (2022). Article   PubMed   Google Scholar   Chouhan,
    S. S., Singh, U. P., Kaul, A., Jain, S. A data repository of leaf images: Practice
    towards plant conservation with plant pathology. In 2019 4th International Conference
    on Information Systems and Computer Networks (ISCON), 700–707 (2019). Download
    references Author information Authors and Affiliations Faculty of Computers and
    Information Science, Mansoura University, Mansoura, Egypt Zahraa Tarek, Mohamed
    Elhoseny & Ibrahim M. EL-Hasnony College of Computing and Informatics, University
    of Sharjah, Sharjah, United Arab Emirates Mohamed Elhoseny Department of Computer
    Science, Al-Baha University, Al Bahah, Kingdom of Saudi Arabia Mohamemd I. Alghamdi
    Contributions All authors have equal contributions. Corresponding author Correspondence
    to Ibrahim M. EL-Hasnony. Ethics declarations Competing interests The authors
    declare no competing interests. Additional information Publisher''s note Springer
    Nature remains neutral with regard to jurisdictional claims in published maps
    and institutional affiliations. Rights and permissions Open Access This article
    is licensed under a Creative Commons Attribution 4.0 International License, which
    permits use, sharing, adaptation, distribution and reproduction in any medium
    or format, as long as you give appropriate credit to the original author(s) and
    the source, provide a link to the Creative Commons licence, and indicate if changes
    were made. The images or other third party material in this article are included
    in the article''s Creative Commons licence, unless indicated otherwise in a credit
    line to the material. If material is not included in the article''s Creative Commons
    licence and your intended use is not permitted by statutory regulation or exceeds
    the permitted use, you will need to obtain permission directly from the copyright
    holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.
    Reprints and permissions About this article Cite this article Tarek, Z., Elhoseny,
    M., Alghamdi, M.I. et al. Leveraging three-tier deep learning model for environmental
    cleaner plants production. Sci Rep 13, 19499 (2023). https://doi.org/10.1038/s41598-023-43465-4
    Download citation Received 20 March 2022 Accepted 24 September 2023 Published
    09 November 2023 DOI https://doi.org/10.1038/s41598-023-43465-4 Share this article
    Anyone you share the following link with will be able to read this content: Get
    shareable link Provided by the Springer Nature SharedIt content-sharing initiative
    Subjects Energy infrastructure Engineering Comments By submitting a comment you
    agree to abide by our Terms and Community Guidelines. If you find something abusive
    or that does not comply with our terms or guidelines please flag it as inappropriate.
    Download PDF Sections Figures References Abstract Introduction Related work Methods
    and overviews Proposed methodology Experimental results and discussion Conclusion
    and future work Data availability Abbreviations References Author information
    Ethics declarations Additional information Rights and permissions About this article
    Comments Advertisement Scientific Reports (Sci Rep) ISSN 2045-2322 (online) About
    Nature Portfolio About us Press releases Press office Contact us Discover content
    Journals A-Z Articles by subject protocols.io Nature Index Publishing policies
    Nature portfolio policies Open access Author & Researcher services Reprints &
    permissions Research data Language editing Scientific editing Nature Masterclasses
    Research Solutions Libraries & institutions Librarian service & tools Librarian
    portal Open research Recommend to library Advertising & partnerships Advertising
    Partnerships & Services Media kits Branded content Professional development Nature
    Careers Nature Conferences Regional websites Nature Africa Nature China Nature
    India Nature Italy Nature Japan Nature Middle East Privacy Policy Use of cookies
    Your privacy choices/Manage cookies Legal notice Accessibility statement Terms
    & Conditions Your US state privacy rights © 2024 Springer Nature Limited"'
  inline_citation: '>'
  journal: Scientific Reports
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Leveraging three-tier deep learning model for environmental cleaner plants
    production
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Lin Y.B.
  - Chen W.E.
  - Chang T.C.Y.
  citation_count: '3'
  description: Integrating cloud with fog/edge is a main trend in networking. Many
    cloud computing applications have been shifted to the edge/fog domain. Such paradigm
    shift offers new opportunities for pervasive computing. An example is AgriTalk,
    an Internet of Things (IoT) application development platform for smart agriculture.
    By integrating cloud with edge/fog, this article describes how AgriTalk addresses
    six issues for developing edge/fog agriculture applications. These issues include
    device domain development, application generation and bug detection, sensor failure
    detection and calibration, big data management, Artificial Intelligence (AI) provisioning,
    and data privacy. We show how AgriTalk integrates fog/edge applications and use
    rice blast detection and piglet crushing mitigation as two examples to demonstrate
    that fog/edge computing is a better solution than cloud computing. Compared with
    cloud computing, fog/edge computing reduces the delays by 50 percent in AgriTalk.
    Through the low-code no-code approach, AgriTalk allows the farmers to create and
    maintain fog/edge agriculture applications by themselves.
  doi: 10.1109/MCOM.001.2200633
  full_citation: '>'
  full_text: '>

    "IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account
    Personal Sign In Browse My Settings Help Access provided by: University of Nebraska
    - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards
    Authors Citations ADVANCED SEARCH Journals & Magazines >IEEE Communications Magazine
    >Volume: 61 Issue: 12 Moving from Cloud to Fog/Edge: The Smart Agriculture Experience
    Publisher: IEEE Cite This PDF Yi-Bing Lin; Whai-En Chen; Ted C.-Y. Chang All Authors
    3 Cites in Papers 251 Full Text Views Abstract Document Sections Introduction
    AgriTalk-FE: the AgriTalk Architecture for IoT-FE Special FE-Talks AgriTalk-C:
    Integration of Cloud and Fog/Edge Domains Integrated Operations Center (IOC):
    MapTalk Show Full Outline Authors Figures References Citations Keywords Metrics
    Abstract: Integrating cloud with fog/edge is a main trend in networking. Many
    cloud computing applications have been shifted to the edge/fog domain. Such paradigm
    shift offers new opportunities for pervasive computing. An example is AgriTalk,
    an Internet of Things (IoT) application development platform for smart agriculture.
    By integrating cloud with edge/fog, this article describes how AgriTalk addresses
    six issues for developing edge/fog agriculture applications. These issues include
    device domain development, application generation and bug detection, sensor failure
    detection and calibration, big data management, Artificial Intelligence (AI) provisioning,
    and data privacy. We show how AgriTalk integrates fog/edge applications and use
    rice blast detection and piglet crushing mitigation as two examples to demonstrate
    that fog/edge computing is a better solution than cloud computing. Compared with
    cloud computing, fog/edge computing reduces the delays by 50 percent in AgriTalk.
    Through the low-code no-code approach, AgriTalk allows the farmers to create and
    maintain fog/edge agriculture applications by themselves. Published in: IEEE Communications
    Magazine ( Volume: 61, Issue: 12, December 2023) Page(s): 86 - 92 Date of Publication:
    08 May 2023 ISSN Information: DOI: 10.1109/MCOM.001.2200633 Publisher: IEEE Funding
    Agency: Introduction In the advancement of the Internet of Things (IoT) technologies,
    one of the main trends in networking is the paradigm shift from cloud based IoT
    (IoT-C; that is, connecting the IoT device directly to a cloud server in Fig.
    1(1)) to fog/edge based IoT (IoT-FE; that is, connecting the IoT devices to the
    fog/edge nodes in Fig. 1 (2). We define three types of IoT-FE: monitoring-IoT,
    controlling-IoT, and automating-IoT. Monitoring-IoT allows the users to remotely
    read the sensor data ((3) → (2) in Fig. 1). Controlling-IoT allows the users to
    remotely control actuators ((2) → (4) in Fig. 1). Automating-IoT controls the
    actuators according to the sensor data without manual operation ((3) → (2) → (4)
    in Fig. 1). To deploy IoT-FE applications rapidly and reliably, an IoT development
    platform should provide functions to speed up application creation and management.
    Based on our experience with smart agriculture deployment in the past 8 years,
    this article describes the IoT-FE application development focusing on six issues.
    Issue 1–Device Domain Development Most commercial IoT applications use off-the-shelf
    sensors/actuators. To accommodate these devices in fog/edge computing, we need
    to integrate them with the microcontroller units (MCUs) with significant effort
    [1]. An MCU is an integrated circuit that consists of a processor unit, memory
    modules, communication interfaces (to connect the IoT servers) and peripheral
    pins (to connect sensors and actuators). To speed up the accommodation of an IoT
    device in fog/ edge computing, it is essential to provide a development environment
    in the IoT device domain. Examples of the MCU solutions include Ardublock, S4A,
    Webduino and ArduTalk [1]. Issue 2–Application Generation and Bug Detection IoT-FE
    application development consists of two phases [2]. In Phase 1, a proof-of-concept
    is built through simulation. In Phase 2, the real IoT application is implemented
    and experimented on a testbed. However, the code developed in Phase 2 may not
    be consistent with the code developed in Phase 1. In fog/edge computing, it is
    essential to automatically or semi-automatically generate the application codes
    and conduct automatic bug detection to speed up the development process [3]. Issue
    3–Sensor Failure Detection and Calibration Many IoT-FE applications fail due to
    inaccurate data produced by the sensors. Traditionally, sensor failure detection
    and calibration are conducted manually in an offline process. In fog/edge computing,
    there are many agricultural sensors spread across different locations. It is important
    to detect sensor failures and conduct calibration automatically to guarantee normal
    operations of the sensors [4], [5]. Issue 4–Big Data Management The data produced
    by the agricultural sensors from a large number of fog/edge nodes are typically
    handled by big data tools in an offline process. It is more beneficial to integrate
    the database system (Fig. 1 (5)) with the IoT-FEs and the IoT-C to support automatic
    real-time data analysis in fog/edge computing [6], [7]. Issue 5–Artificial Intelligence
    (AI) Provisioning Some data from the IoT-FE applications are manipulated by AI
    tools through an offline process [8]. Significant programming effort is required
    to integrate AI modeling into existing IoT-FE applications. Therefore, it is critical
    to provide transparent AI inferencing at IoT-FE (Fig. 1 (6)) and online AI training
    at IoT-C (Fig. 1 (7)) [6]. Issue 6–Data Privacy Since IoT-FE applications may
    support video monitoring, access rights must be enforced for data privacy [9].
    Also, the controlling-IoT and automating-IoT applications will trigger the actuators,
    and data security is required to protect these IoT-FE applications from illegal
    access. This article uses AgriTalk [10] as an example to address the above 6 issues
    for IoT-FE application development. A fog/edge node of AgriTalk is called an AgirTalk-FE.
    AgriTalk is an IoT-based smart agriculture platform for developing various AgriTalk-FEs,
    and the applications developed in an AgriTalk-FE are called FE-Talks. Examples
    are MapTalk for integrated operations center (IOC) and HouseTalk for greenhouse
    [10]. This article shows that fog/edge computing can be effectively achieved in
    these sustainable FE-Talk examples. We first describe how to organize the agriculture
    applications as FE-Talks hosted in the AgriTalk platform through a modular approach.
    Then we integrate every FE-Talk Graphical User Interface (GUI) with the MapTalk
    GUI to enhance the user experience. AgriTalk is an interesting fog/edge computing
    example, which conducts non-toxic organic farming at more than twenty soil farms
    and 4 greenhouses located in Taiwan, Japan, Philippe, Thailand and Armenia. AgriTalk
    eliminates the requirement of physical presence for some critical farming tasks
    through fog/edge computing to achieve distributed farm management. The article
    is organized as follows: The next section proposes the AgriTalk IoT-FE approach.
    Following that, we show several special FE-Talks, and then describe the AgriTalk
    mechanism on the cloud domain. We then elaborate on MapTalk, the IOC for AgriTalk,
    and illustrate PigTalk, a fog/ edge intelligent system for piglet crushing mitigation.
    The final section gives conclusions. AgriTalk-FE: the AgriTalk Architecture for
    IoT-FE Figure 2 illustrates the fog/edge AgriTalk architecture based on Fig. 1.
    The original AgriTalk was designed with a cloud-based server called AgriTalk-C
    in the network domain (Fig. 2 (3)), which directly connects the agricultural sensors/actuators
    in the device domain (Fig. 2 (1)) [10]. Figure 1. Fog/edge computing for IoT.
    Show All To offer fog/edge computing, the network domain is further partitioned
    into the fog/edge domain and the cloud domain, where the AgriTalk-FEs (individual
    farms) are deployed in the fog/edge domain (Fig. 2 (2)), and AgriTalk-C is located
    in the cloud domain. In this architecture, the low-layer communications among
    the three domains ((1) <-> (8), (1) <-> (5), (5) <-> (8) and (6) <-> (22)) can
    be Ethernet, Bluetooth, WiFi, 4G, and 5G. The high-layer APIs for these domains
    can be Restful or Message Queuing Telemetry Transport (MQTT), except that connections
    (5) <-> (8) and (6) <-> (22) use Restful API. The AgriTalk Database (DB) System
    (Fig. 2 (4)) is accessed through Object Relational Mapping (ORM). The AgriTalk-FEs
    interact with each other in two ways. They can exchange their data through the
    AgriTalk DB System or through AgriTalk-C. AgriTalk-C resides in the cloud as a
    docker container image. As an edge node in the current implementation, an AgriTalk-FE
    is installed in an industry version of Raspberry Pi 4. This section elaborates
    on AgriTalk-FE architecture for a fog/edge node. Multiple FE-Talks ((9), (10),
    (11), (13), (15), and (17) in Fig. 2) can be developed through the AgriTalk-FE
    GUI (Fig. 2 (6)), and be manipulated (e.g., parameter setups) through the FE-Talk
    GUIs (Fig. 2 (7)). Through connecting icons in the AgriTalk-FE GUI window, the
    program for an FE-Talk application is automatically created without any programming
    effort. This no-code approach allows the farmers to quickly deploy their farming
    applications. In Fig. 2, the system FE-Talks are marked green ((10), (11), (13),
    (15), and (17)) and the application FE-Talks are marked blue ((9)). Both the AgriTalk-FE
    and the FE-Talk GUIs are web based, which can be remotely accessed through any
    computing device with a browser (Fig. 3 (1)). In this GUI, a project window (Fig.
    3 (2)) allows the farmer to develop an FE-Talk. We use Figs. 2 and 3 to describe
    this development procedure. The IoT-FE device software binds an IoT device (Fig.
    2 (1)) to the AgriTalk-FE engine (Fig. 2 (8)) through several simple operations
    in the AgriTalk-FE GUI (Fig. 2 (6)), and an example of its layout is the “Project”
    window illustrated in Fig. 3 (2). AgriTalk defines a device model for real IoT
    devices with the same properties. For example, a smartphone model is mapped to
    real phones such as Apple iPhones, Samsung smart phones and so on. In the project
    window, an IoT device model is graphically represented by an icon, for example,
    “Sensors” (Fig. 3 (6)). This icon includes one or more smaller icons representing
    the “features” (individual sensors) of the device. For example, the features of
    a micro weather station (Fig. 3 (3)) include the sensors for temperature, humidity,
    electrical conductivity (EC), CO2 and so on. When we click the gear icon in the
    upper-left corner of a device icon, the physical device is bound to AgriTalk-FE
    (e.g., the (3) → (6) connection in Fig. 3). The binding mechanism is similar to
    the one for Bluetooth. We enable a sensor device to control an actuator device
    by dragging a “Join” link between them (see Joins 1–5 in Fig. 3). There is a circle
    in the middle of the link. When the circle is clicked, a function management window
    pops up (Fig. 3 (22)). We write functions in this window to manipulate the data
    passing through the link. For example, the soil EC values are collected in real
    time, and are used to train a fertilizer regulatory model for the farm. The model
    provides appropriate fertilizer solution, for example, the Nitrogen (N) to optimize
    the yield of the plant cultivation. The relationship between EC ( χ E ) and N
    ( f N ( χ E )) for a specific farm in the Bao Mountain is derived as [10] f N
    ( χ E )=63.2526 χ 2 E +14.2131 χ E +0.1797 (1) View Source Figure 2. The AgriTalk
    architecture for edge/fog computing. Show All Through this function, the values
    measured from the EC sensor are transformed into the amount of Nitrogen to drive
    the pump of the fertilizer solution through the path (3) → (6) → (8) → (7) in
    Fig. 3. This function is implemented as a Python program in the function management
    window; see Lines 3 and 4 in Fig. 3 (22). Note that AgriTalk-FE automatically
    integrates the Join functions to constitute the network program of the IoT-FE
    application, and this “Join” mechanism partially addresses Issue 2 in the fog/edge
    domain. FE-Talk is defined by the device models that can be accessed from the
    model pull-down list (Fig. 3 (5)). For example, the items in the AgriTalk model
    list include the micro weather station with the soil sensors (Fig. 3 (3)), the
    fertilizer and irrigation drippers (Fig. 3 (7)), the biopesticide sprayers and
    so on [10]. Besides the AgriTalk-FE GUI, we can design a specific GUI for FE-Talk,
    which is typically a browser that can be shown in a mobile device (Fig. 3 (4)).
    Based on the setups in this GUI, the AgriTalk-FE engine (Fig. 2 (8)) executes
    the FE-talk code (Fig. 2 (9)) to interact with the IoT devices (Fig. 2 (1)). The
    FE-Talk code is automatically created when the device connection configuration
    is complete in the Project window (Fig. 3 (2)), which addresses the automatic
    application generation part of Issue 2. Figure 3. AgriTalk-FE GUI. Show All In
    the device domain, many IoT devices are connected to the MCUs. Programming an
    MCU is a tedious task. The AgriTalk-FE engine automatically generates software
    module codes for the MCU boards including Arduino, Raspberry pi, MediaTek LinkIt,
    ROHM IoT kit and ESP8266 ESP-12F [1]. After we have deployed the standard IoT
    device software into an MCU board, a developer can easily create new applications
    with the AgriTalk-FE GUI (see the Project 1 window in Fig. 4) without the need
    of re-programming the MCU. Specifically, an MCU board (Fig. 4 (1)) can be represented
    by a device icon (Fig. 4 (3)), and its pins can be represented by the feature
    icons within the device icon (e.g., A0 in Fig. 4 (3)). If a device has both inputs
    (to send the data to the AgriTalk-FE engine; see Fig. 4 (6) in Arduino1) and outputs
    (to receive the data from the AgriTalk-FE engine; see Fig. 4 (7) and (8) in Arduino1),
    then the inputs are represented as the feature icons within an “input” device
    icon (Fig. 4 (3)), and the outputs are represented as the feature icons with-in
    an “output” device icon (Fig. 4 (4)). The input device icons are placed on the
    left side of the window, and the output device icons are placed on the right side
    of the window. In Project 1, we also use a second MCU board (Arduion2; see Fig.
    4 (2) and (5)). We build the Arduino network programs for the greenhouse fan control
    (Fig. 4 (7) → (11)) and the energy screen control (Fig. 4 (8) → (12)) as follows:
    We use drag-and-drop operations to draw lines between analog and digital pin icons
    in the AgriTalk-FE GUI, which allows quick agriculture application deployment.
    Furthermore, we can easily re-link sensors to actuators to modify Arduino applications
    without re-burning the MCU. Therefore, our solution has nicely addressed Issue
    1 in the device domain and the application generation part of Issue 2. In Project
    1, both the fan and the energy screen are automatically controlled by the heat
    sensor (Fig. 4 (6)). They are also manually controlled by the switches (Fig. 4
    (9) and (10)). With the pre-built agriculture functions, the low-code no-code
    approach of AgriTalk allows the farmers to create and maintain the fog/edge agriculture
    applications by themselves. Special FE-Talks We have developed several special
    FE-Talks to resolve Issues 2–6 for agriculture fog/edge computing. To address
    the bug detection part of Issue 2, we proposed BigraphTalk to detect any forbidden
    Join connections by using Bigraph, a universal mathematical model for representing
    the spatial configuration of physical or virtual entities and their interactions
    [11]. Our operation experience in commercial farms indicated that the farmers
    at a fog/edge site may inappropriately connect the IoT devices in the GUI. For
    example, the farmer may connect a motor to a temperature and a humidity sensors.
    The temperature and the humidity conditions may conflict with each other, which
    causes the motor to oscillate between “on” and “off” states, and eventually burn
    out. No existing solutions solved this problem automatically until we developed
    BigraphTalk. To check correctness of connections, we use bigraph to specify what
    an invalid configuration of entities looks like and check these against a given
    input model. Bigraph-Talk automates this verification process without requiring
    the developer to specify any bigraph. After static Join connection is proved correct,
    we may verify if the execution of the developed FE-Talk is correct by SimTalk
    [3] through the path (11)-(8)-(9) in Fig. 2. Specifically, after an FE-Talk is
    created, we click the “simulation” toggle button (Fig. 3 (11)). Then the SimTalk
    GUI (Fig. 2 (12)) pops up for specifying the traffic characteristics. Before physical
    sensors/controls are actually connected to the FE-Talk, SimTalk binds the feature
    icons to the simulated software modules corresponding to the real sensors/actuators,
    and set up specific traffic patterns to simulate or emulate the application. The
    simulated software modules are automatically created by SimTalk. The reader is
    referred to Fig. 5 in [3] for more details. We proposed SensorTalk (Fig. 2 (10))
    to address Issue 3 [4], [12]. The farmers often need to replace or calibrate failed/aged
    sensors. Such maintenance is labor-intensive, and the user experience is poor
    in the fog/edge environments. To address this issue, SensorTalk developed a Dash-Board
    output device model (Display-O; Fig. 3 (9)) that shows the real-time sensor values
    in a display (Fig. 3 (10)). DashBoard has a built-in calibration table to correct
    aging sensors [4]. Traditionally, aged sensors were calibrated in the laboratories
    manually or semi-automatically. Conversely, SensorTalk automatically calibrates
    the sensors under test by the standard sensors in fog/edge farming nodes directly.
    The reader is referred to Fig. 2 in [4] for more details. To address Issue 4,
    we developed DataTalk (Fig. 2 (13)) by creating the DataBank device model (with
    the features Data-O in (12) and Data-1 in (13) in Fig. 3). In this way, all AgriTalk-FEs
    can access the AgriTalk DB System (Fig. 2 (4)) and manage the database as an IoT
    device. Data-O of DataBank receives data from the sensors through (6) → (12) in
    Fig. 3. DataBank also receives data from open datasets stored in the AgriTalk
    DB system through (4) → (20) in Fig. 2. The received data may be pre-processed
    and then stored in a DataBank device for future usage. We use the rice blast detection
    [13] as an example to show how DataTalk works. The commercial farm operation indicated
    that image detection of rice blast is not practical (it is too late when you detect
    rice blast in an image). Therefore, we utilized non-image IoT devices to detect
    conditions leading to rice blast. The non-image data are the weather data (including
    the barometric pressure, the temperature and the relative humidity) obtained from
    the database of Central Weather Bureau in Taiwan and the real-time data of the
    AgriTalk sensors from the micro weather stations we established at 4 farm locations.
    We found that high spore germination rate for various fungi may cause rice blast
    disease. Therefore, it is also important to obtain information of spore germination
    rate that is affected by the temperature χ T and the relative humidity χ H . We
    designed a specific spore germination rate function for every farm field computed
    locally at its fog/edge node (an AgriTalk-FE). For example, in a Bao Mountain
    farm, the function is f T ( χ T , χ H )=0.1143×(0.27−0.0078 χ 3 T +0.28 χ 2 T
    + 1.67 χ T ) e 6.6 χ H (2) View Source Figure 4. Arduino MCU mapping for a greenhouse.
    Show All This function is derived from a bio regression model [13] and was implemented
    in a DataBank device through the DataTalk GUI (Fig. 2 (14)). In the rice blast
    AI model, three features – χ T ,  χ H , and f T ( χ T ,  χ H ) - are sent from
    DataBank (Fig. 3 (13)) to Almodule (Fig. 3 (15)). The subtle way we manipulate
    χ T , χ H and f T ( χ T ,  χ H ) significantly improves the accuracy of the rice
    blast prediction, which is 89.4 percent, the world record for non-image sensing
    [13]. Thanks to the “plug-in” module approach of AgriTalk-FE, any FE-Talk can
    be independently developed without any data preprocessing capability, and can
    easily connect to DataTalk for online database access and operation later. The
    rice blast detection was conducted at fourteen counties in Taiwan through fog/edge
    computing, where rice blast detection of a county is conducted by an AgriTalk-FE.
    To address Issue 5, we develop Altalk [6] (Fig. 2 (15)) by creating the Almodule
    device model (with the features Label-O in (14), Feature-O in (15) and Prediction-1
    in (16) in Fig. 3). Like the DataTalk approach, Almodule is manipulated as an
    IoT device. Therefore Altalk can rapidly extend existing IoT applications into
    AI-based smart applications [10]. Upon receiving the data from DataBank, Almodule
    performs feature extraction. The extraction method is selected through the Altalk
    GUI (Fig. 2 (16)), which extracts the data characteristics to form a feature vector.
    The feature vectors as well as the labels obtained from, for example, the remote
    control (Fig. 3 (17)) are used for training. We have ported scikit-learn, Tensor
    Flow, Flux, and other AI tools to Altalk, and the developer can select an appropriate
    tool for AI modeling. Through an appropriate ensemble method, the best prediction
    result is used to activate the actuators. The results are also used to improve
    the accuracy of prediction by conducting validation that provides better hyper-parameter
    setups for Almodule. Through the path (16) → (9) → (10) in Fig. 3, useful statistics
    are displayed for the developer to adjust the machine learning model. Like DataTalk,
    every FE-Talk can be independently developed without AI, and can easily connect
    to Altalk for online AI training and inference later. Figure 5. Maptalk and the
    fog/edge applications. Show All AgriTalk-C: Integration of Cloud and Fog/Edge
    Domains If fog/edge computing involves multiple countries, then Issue 6 (data
    privacy) is a major concern. For example, the current AgriTalk operation includes
    the sites (AgriTalk-FEs) in several countries. These AgriTalk-FEs are managed
    under AgriTalk-C in Chunghwa Telecom''s cloud in Taiwan. Our operation faces the
    problem that the General Data Protection Regulations (GDPRs) are not the same
    for every country. To fit an IoT-FE application to different GDPRs, existing approaches
    require significant efforts to modify the IoT-FE application. To address Issue
    6, the data privacy requirement of an FE-Talk in AgriTalk-FE is set in the Authentication,
    Authorization and Accounting (AAA) subsystem (Fig. 2 (17)) without changing the
    code of the FE-Talk application. Specifically, every IoT message delivered in
    a Join link has a privacy tag to indicate the privacy level of the delivered data.
    A smart application may need to set different privacy levels according to different
    users'' authorization for hiding information in IoT messages. In smart farming,
    a control message sent from a smartphone with a low privacy level cannot trigger
    the irrigation pump. According to the GDPRs of different countries, Personally
    Identifiable Information (PII) and user behavior history should be protected,
    which can be achieved by the AAA subsystem. The details of the tag mechanism are
    out of the scope of this article and the details can be found in [10]. The AgriTalk-C
    server has the same structure as an AgriTalk-FE. All farmer accounts can be managed
    in the AgriTalk-C AAA (Fig. 2 (18)) with single sign-on, where the farmer''s access
    right to a specific AgriTalk-FE is granted through the path (18) → (5) → (8) →
    (17) in Fig. 2. Therefore, the farms in different countries are supported by their
    AgriTalk-FEs with different GDPRs, and these AgriTalk-FEs are monitored by AgriTalk-C
    at the same time. The AgriTalk-C engine controls an AgriTalk-FE through the path
    (5) → (8) in real-time following the same protocol as that for the control path
    to an IoT device ((5) → (1) in Fig. 2). Before an edge/fog node (a new AgriTalk-FE)
    is allowed to join AgriTalk, SimTalk of AgriTalk-C conducts validation and performance
    tests on the AgriTalk-FE through the path (19) → (5) → (8) → (9) in Fig. 2. The
    DataTalk subsystems of individual AgriTalk-FEs (Fig. 2 (13)) and AgriTalk-C (Fig.
    2 (20)) interact with each other indirectly through the database operations on
    the AgriTalk DB System (Fig. 2 (4)). If an AI model is used in an FE-Talk, the
    AI model can be trained in the cloud (AgriTalk-C) and AI inference is performed
    in the edge/fog node (AgriTalk-FE). AgriTalk-C sends model parameters to an AI
    execution engine already installed on the AgriTalk-FEs. The training datasets
    may be generated by the FE-Talk and saved in the AgriTalk DB System. The data
    path for AI training is (4) → (20) → (5) → (21) in Fig. 2. The trained model is
    sent to the AgriTalk-FE through the path (21) → (5) → (8) → (15). Then AI inference
    is performed at the edge/fog node through the path (9) → (8) → (13) → (8) → (15)
    → (8) → (9). Integrated Operations Center (IOC): MapTalk The fog/edge nodes in
    a distributed farming system should be managed in an organized way so that the
    farm owners can conveniently access the applications. In AgriTalk-C, we have developed
    an IOC called MapTalk (Fig. 2 (22) and (23)) based on Google Maps. MapTalk is
    an application FE-Talk. Compared with a traditional IOC [14], the MapTalk user
    can transparently add the IoT devices to the IOC without any programming effort
    while a traditional IOC requires a professional system integrator to modify the
    IOC software. MapTalk shows the location and the status of every farming device
    and allows a farmer to interact with these devices through their cyber representations
    on the map. MapTalk can be displayed in a big screen like traditional IOCs. Furthermore,
    one can also access MapTalk from everywhere through any computing device with
    a browser. The GUIs of all AgriTalk-FEs are managed by MapTalk and can be accessed
    through the “App” pull-down list in the MapTalk GUI, where the layout is illustrated
    in Fig. 5 (1). When the user selects an application item, for example, “CO2” of
    the farms managed as fog/edge nodes (Fig. 5 (2)), the status of every CO2 sensor
    is shown on the map. The IoT devices in MapTalk can be stationary or movable.
    The icon of a stationary IoT device is placed at the map according to its GPS
    coordinates. The stationary examples are “PM2.5” (Fig. 5 (4)), “Germany Power
    Plants” (Fig. 5 (5)) and “Taiwan Farms” (Fig. 5 (6)). The icon of a movable IoT
    device is dynamically placed at its current position of the map. An example is
    the “Bus” application (Fig. 5 (7)) that shows the status of an individual bus
    or all buses. Fig. 5 (8) is “Bus 2” with a pink tail representing its one-hour
    trajectory. The “Bus” application can be transparently reused by AgriTalk to manage
    the cultivators and the tractors in the farms. There are two types of stationary
    applications: map-type and hybrid-type. “PM2.5” and “Germany Power Plants” are
    map-type applications. When we select “Germany Power Plants” from the App list,
    a map for this application pops up with a dedicated function bar to select various
    sensors, such as generated power, wind speed, temperature, and humidity of a power
    plant (Fig. 5 (5)). We are reusing “Germany Power Plants” to implement AgriTalk-FEs
    for agro-photovoltaics applications. “Taiwan Farms” is a hybrid-type application.
    When this application is selected from the App list, all farm icons are shown
    on the map. When we click a farm icon (Fig. 5 (9)), a dialog box (Fig. 5 (10))
    pops up. From this dialog box, we may select specific hyperlinks to see the sensor
    dashboard and the farm control board (including video; see Fig. 5 (11)). Examples
    of dashboard/control board are given in Fig. 3 (10), (18), (21) and Fig. 6. The
    name of the person who maintains this application is also listed (in Chinese;
    see Fig. 5 (12)). Adding an IoT-FE application to MapTalk is achieved through
    the MapTalk project created from the GUI of AgriTalk-C (Fig. 2 (24)), which shows
    the locations of the IoT devices in the digital map (through Display-O in Fig.
    3 (9)). To add a map-type application, we create a “Sensors” device (for example,
    “Germany power plants”; see Fig. 3 (6)) in the MapTalk project, and connect them
    through the path (23) → (22) → (5) → (8) → (9) in Fig. 2. We use the “Routing-with-obstacles”
    application to illustrate how multiple IoT-FE applications (path routing, PM2.5
    and CO2 applications) can interact with each other to create new functions through
    MapTalk. When we select the “Routing” application, MapTalk suggests a driving
    route from the starting point to the endpoint (Fig. 5 (3)). If we select “PM2.5”
    as obstacle, then MapTalk suggests another route to avoid passing through the
    PM2.5 pollution areas (Fig. 5 (4)). We are reusing this routing application to
    implement an AgriTalk-FE that guides automatic tractor movement in irregular-shaped
    farm fields with obstacles. MapTalk was originally designed for managing general
    smart applications. Some of these applications such as “Bus,” “Germany Power Plants”
    and “Routing-with-obstacles” are being reused in AgriTalk-FE without any code
    modification. MapTalk provides a low-code no-code approach to manage the fog/edge
    nodes in an IOC. Pigtalk as a Fog/Edge Computing Example Through the AgriTalk-FE
    platform, we have built more than 20 FE-Talks applications. As a controlling-IoT
    example of fog/edge computing, this section describes PigTalk, an intelligent
    system for piglet crushing mitigation. Figure 6. Pig talk control board accessed
    through maptalk. Show All Many piglets die on pig farms because they are crushed
    when sows roll sideways or lie down. PigTalk was proposed to resolve the piglet
    mortality issue [15], which uses a DataBank device to transform the voice data
    into audio clips. These audio clips serve as the input of the Convolutional Neural
    Network (CNN) model. Through real-time analysis of the voice data collected in
    a farrowing house from a directional microphone (Fig. 6 (1)), PigTalk detects
    if any piglet screaming occurs, and automatically activates sow-alert actuators
    such as heating light (Fig. 6 (2)) for emergency handling of the crushing event
    (light heating effectively forces the sow to stand up). The whole process is remotely
    monitored by the hog farmer through the camera in the farrowing house (Fig. 6
    (3)). The PigTalk configuration can reuse the “Project” configuration in Fig.
    3 where the micro weather station (Fig. 3 (3)) is replaced by the microphone,
    the irrigation system (Fig. 3 (7)) is replaced by the heating light, and the farm
    camera (Fig. 3 (20)) is replaced by the camera in the farrowing house. The raw
    voice data received from the microphone (Sensor-I in Fig. 3 (6)) are sent to DataBank
    (Fig. 3 (12)) to produce the audio clips. These audio clips are further modified
    by min-max scaling in feature extraction. Then the CNN model is used as the machine
    learning algorithm (Fig. 3 (15)). Finally, the k-fold cross validation is conducted
    to validate the model, and the predicted result is used to determine if the heating
    light (Fig. 3 (8)) should be activated. Through fog/edge computing, PigTalk can
    save piglets from being crushed within 0.05 seconds with a 99.93 percent success
    rate. The PigTalk system consists of several farrowing houses, each of which is
    an AgriTalk-FE (called PigTalk-FE). In a PigTalk-FE, the control path for piglet
    crushing avoidance is (6) → (12) → (13) → (15) → (16) → (8) in Fig. 3, where the
    control message is delivered locally through Asymmetric Digital Subscriber Line
    (ADSL) with the delay tA. A PigTalk-FE communicates with the PigTalk AgriTalk-C
    (called PigTalk-C) through the 4G technology. With the AgriTalk-FE GUIs accessed
    from MapTalk of PigTalk-C, we remotely observe pig activities of all farrowing
    houses within the delay tG. The delay tG in the cloud domain is about twice the
    delay t A in the fog/edge domain for other AgriTalk applications. In cloud computing,
    t A = t G . It is clear that t G is much larger than t A , and piglet crushing
    avoidance should be implemented locally as fog/edge computing instead of cloud
    computing. We enhanced the scream detection accuracy of the existing best solutions
    (up to 92.8 percent). With data pre-processing and subtle parameter setups of
    the CNN model, the piglet scream detection accuracy of PigTalk is up to 99.4 percent.
    Through fog/edge computing, PigTalk can save piglets from being crushed within
    0.05 seconds with a 99.93 percent success rate. Conclusion This article proposed
    the fog/edge approach for AgriTalk, an IoT application development platform for
    smart agriculture. By integrating cloud with edge/fog, we described how AgriTalk
    addresses six issues including device domain development, application generation
    and verification, sensor failure detection and calibration, big data management,
    AI provisioning, and data privacy. We showed how AgriTalk integrates its fog/edge
    applications called FE-Talks, and used rice blast detection and piglet crushing
    avoidance as two examples to indicate that fog/edge computing is a much better
    solution than cloud computing, where the delays can be reduced by 50 percent.
    In our solution, the non-agriculture applications in MapTalk can be transparently
    translated into smart agriculture applications. The examples include the cultivators
    and the tractors management, and agro-photovoltaics applications. Through the
    low-code no-code approach, AgriTalk and MapTalk allow the farmers to create and
    maintain FE-Talks by themselves in the fog/edge computing environment. ACKNOWLEDGMENT
    This work was supported in part by the National Science and Technology Council
    (NSTC) 112-2221-E-033-023, 112-2221-E-468 -005 -MY2, 111-2221-E-468 -012, 110-2622-8-A49-022,
    NSTC112-2221-E-A49-049, NCKU Miin Wu School of Computing, Research Center for
    Information Technology Innovation, Academia Sinica. Authors Figures References
    Citations Keywords Metrics More Like This Artificial Intelligence and Internet
    of Things for Sustainable Farming and Smart Agriculture IEEE Access Published:
    2023 Analysis of Internet of Things based Artificial Intelligence in Agriculture
    Fertilizer Process Management 2023 2nd International Conference on Automation,
    Computing and Renewable Systems (ICACRS) Published: 2023 Show More IEEE Personal
    Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED
    DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION
    TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732
    981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility
    | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap |
    IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s largest
    technical professional organization dedicated to advancing technology for the
    benefit of humanity. © Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: IEEE Communications Magazine
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Moving from Cloud to Fog/Edge: The Smart Agriculture Experience'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Mallick S.R.
  - Apat H.K.
  - Lenka R.K.
  - Ranjan Senapati M.
  - Sharma S.
  - Barik R.K.
  citation_count: '0'
  description: Blockchain and Internet of Spatial Things (IoST) integration in smart
    agricultural systems employing Geographical Information System (GIS) provides
    agricultural systems with decentralized, trustworthy, secure, dependable, scalable,
    traceable, and transparent services. Most previous research uses IoT to automate
    agricultural systems without addressing security, scalability, single-point failure,
    access control, trust, and transparency concerns. With an expanded marketplace,
    distributors, producers, buyers, sellers, and other agricultural users, the previously
    proposed cloud-based and centralized agricultural systems faced limits in data
    collection, sharing, management, processing, storing, availability, security,
    auditability, and stability. To address the challenges that exist in IoST agricultural
    systems, we propose BlockAgro, a Blockchain-assisted IoST framework for the agricultural
    sector, with a three-tier architecture, namely an IoST device layer, a fog layer,
    and a cloud layer, to address the issues in IoT agricultural systems. Additionally,
    it provides data analysis, visualization, processing, filtration, and temporary
    storage of gathered IoST data at the nearest fog nodes to reduce cloud infrastructure
    overhead. Moreover, the experimental findings of the proposed framework ensure
    the access control mechanism for IoST devices, efficiency measurement metrics,
    and data availability in a decentralized agricultural platform.
  doi: 10.1109/IC2E357697.2023.10262487
  full_citation: '>'
  full_text: '>

    "IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account
    Personal Sign In Browse My Settings Help Access provided by: University of Nebraska
    - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards
    Authors Citations ADVANCED SEARCH Conferences >2023 International Conference...
    BlockAgro: Towards Blockchain assisted IoST Framework for Agricultural Sector
    Publisher: IEEE Cite This PDF Soubhagya Ranjan Mallick; Hemant K. Apat; Rakesh
    Kumar Lenka; Manas Ranjan Senapati; Suraj Sharma; Rabindra K. Barik All Authors
    1 Cites in Paper 58 Full Text Views Abstract Document Sections I. Introduction
    II. Related Works III. Proposed Framework IV. Analytical modelling V. Conclusion
    and Future Work Authors Figures References Citations Keywords Metrics Abstract:
    Blockchain and Internet of Spatial Things (IoST) integration in smart agricultural
    systems employing Geographical Information System (GIS) provides agricultural
    systems with decentralized, trustworthy, secure, dependable, scalable, traceable,
    and transparent services. Most previous research uses IoT to automate agricultural
    systems without addressing security, scalability, single-point failure, access
    control, trust, and transparency concerns. With an expanded marketplace, distributors,
    producers, buyers, sellers, and other agricultural users, the previously proposed
    cloud-based and centralized agricultural systems faced limits in data collection,
    sharing, management, processing, storing, availability, security, auditability,
    and stability. To address the challenges that exist in IoST agricultural systems,
    we propose BlockAgro, a Blockchain-assisted IoST framework for the agricultural
    sector, with a three-tier architecture, namely an IoST device layer, a fog layer,
    and a cloud layer, to address the issues in IoT agricultural systems. Additionally,
    it provides data analysis, visualization, processing, filtration, and temporary
    storage of gathered IoST data at the nearest fog nodes to reduce cloud infrastructure
    overhead. Moreover, the experimental findings of the proposed framework ensure
    the access control mechanism for IoST devices, efficiency measurement metrics,
    and data availability in a decentralized agricultural platform. Published in:
    2023 International Conference on Computer, Electronics & Electrical Engineering
    & their Applications (IC2E3) Date of Conference: 08-09 June 2023 Date Added to
    IEEE Xplore: 29 September 2023 ISBN Information: DOI: 10.1109/IC2E357697.2023.10262487
    Publisher: IEEE Conference Location: Srinagar Garhwal, India SECTION I. Introduction
    Internet of Spatial Things (IoST) technology in agriculture is known as agricultural
    IoST or Ag-IoST. To increase the effectiveness, productivity, and sustainability
    of farming methods, it deploys the use of sensors, gadgets, and networking technologies
    to gather, process and analyze agricultural data [1][2][3]. The agricultural industry
    has transformed because of IoST technology, raising farm expectations, productivity,
    and efficiency while reducing prices, time, effort, and costs [4][5]. IoST is
    being used in agriculture in the following ways: Precision farming: IoST devices
    are used to monitor soil moisture, temperature, water content, and nutrient levels
    to better irrigate, fertilize, and manage pests, boosting productivity and reducing
    waste. They also track plant development and agricultural production. Soil and
    water monitoring: IoST sensors can continuously monitor soil moisture, humidity,
    temperature, water level, and nutrient content, notifying farmers to plan accordingly.
    This saves time, effort, and money while optimizing irrigation, fertilization,
    and soil health with minimal waste. Equipment monitoring: Sensors track location,
    monitor real-time visibility, utilization rates, and automate farming assets,
    allowing farmers to improve efficiency, productivity, Reduce costs of farming,
    lower downtime, monitor safety, and extend the asset’s lifespan. Crop surveillance:
    For a better agricultural environment, IoST sensors may help to collect information
    on weather conditions, temperature, moisture, water level, and soil contents,
    as well as track records of equipment utilized, crop growth, animal encroachment,
    and pest management. Logistics management: IoST sensors are used in the agricultural
    supply chain to track agricultural products, fertilizers, processing enterprises,
    wholesalers, distributors, producers, customers, transportation, stock, equipment,
    crop location, and crop condition to assist farmers and distributors in developing
    a logistics and market place for agricultural products. IoST has the potential
    to transform the agriculture sector by enhancing production, efficiency, lowering
    labour requirements, eliminating waste, and conserving resources[6][7]. We may
    expect IoT technology to play a significant part in establishing an intelligent
    agricultural environment as technology advances. Sensor devices are used in most
    of the previously proposed smart agricultural systems to enable the agricultural
    ecosystem to become more interconnected and share records among themselves for
    improved agricultural data management and processing without human intervention.
    However, several technological challenges need to be addressed in IoT agricultural
    systems. The rising number of IoT device connectivity generates a large volume
    of data, which can cause a data handling and management challenge [8]. Because
    IoST devices are prone to cyber attacks, protected and secure storage, processing,
    and transaction of sensitive farmer’s data in a centralized IoST platform addresses
    security concerns. As the number of connected devices in the smart agricultural
    field grows, a number of significant technological issues, such as risks of system
    failure and issues with scalability, availability, privacy, security, dependability,
    scalability, trust, decentralization, and malicious detection, become difficult
    to manage [9][10]. Blockchain, a digital ledger technology (DLT) that uses cryptographic
    hashes for block addressing, can improve IoST agriculture by providing a decentralized,
    secure, transparent, immutable, and distributed platform for managing data and
    transactions throughout its peer-to-peer network. Blockchain is used in supply
    chain management to track the location and movement of agricultural items from
    farms to distributors and customers on a decentralized trusted platform to increase
    efficiency [11][12][13][14]. To ensure traceability and transparency in the agricultural
    industry, Blockchain immutable ledger technology records the history of agricultural
    transactions, including the items sold, bought, distributors’ identities, transportation
    details, product availability, and growing and harvesting conditions. Smart contracts
    reduce transaction time and cost between partners by automating the agricultural
    system and establishing a trusted platform among farmers, processors [15][16],
    customers, retailers, government, distributors, and suppliers. Blockchain provides
    a safe and decentralized data-sharing platform across many stakeholders in the
    agricultural ecosystem enabling faster decision-making processes in the agricultural
    sector. Moreover, the application of Blockchain in IoST agriculture has the potential
    to improve the security, privacy, transparency, trust, and efficiency of the system
    while also addressing scalability, availability, regulatory and interoperability
    issues [17][18][19]. A. Motivations Although IoT-based smart agriculture is used
    in most previously proposed models, there are still several issues to be addressed.
    Still, a few research papers addressing fewer topics have been published with
    the integration of IoT and Blockchain. To address the limitations of IoT-based
    agricultural systems, such as scalability, security, centralized control, limited
    storage, efficiency, single point failures, and interoperability issues, researchers
    proposed a decentralized platform for an agricultural system incorporating Blockchain
    technology. The Internet of Spatial Things (IoST), Blockchain, fog computing,
    and cloud infrastructure are merged into a single platform to provide a secure,
    decentralized, transparent, efficient, traceable, irreversible, and trustworthy
    platform for agricultural data exchange. B. Contributions The following best sums
    up the contributions of this proposed work: It presents BlockAgro, a Blockchain-assisted
    IoST framework for the agricultural sector, with a three-tier architecture, namely
    an IoST device layer, a fog layer, and a cloud layer, to address the issues in
    IoT agricultural systems. It provides data analysis, visualization, processing,
    filtration, and temporary storage of gathered IoST data at the nearest fog nodes
    to reduce cloud infrastructure overhead. It also evaluates the mathematical results
    of the proposed framework to ensure access control for IoST devices, efficiency
    measurement metrics, and data availability in a decentralized agricultural platform.
    C. Organizations The rest of the article is arranged as follows. Section II covers
    background information and relevant studies. Section III describes the proposed
    model i.e. BlockAgro, Blockchain-assisted IoST framework for the agricultural
    sector. Section IV provides a description of the analytical model of each layers
    that investigates a technique based on the proposed system. Finally, Section V
    contains the concluding remarks and covers the future scope of the study endeavour.
    SECTION II. Related Works A Blockchain-based fine-grained, and adaptable terminal
    data access control strategy based on encryption techniques have been proposed
    by Zhang et al. [9]. to ensure access control, security, privacy, data confidentiality,
    and data availability in the agricultural IoT. Awan et al. [6] has presented a
    futuristic IoT with a blockchain architecture for agriculture and the food supply
    chain to reduce energy consumption and provide network stability. An Ethereum
    Blockchain-based smart contract platform has been proposed by Umamaheswari et
    al. [10]. to simplify purchasing and selling crops and lands as well as the storage
    of sensor data in the Blockchain network. Vyas et al. [7] studied the usage of
    Blockchain in the food, agricultural, and healthcare industry, with an emphasis
    on AI and IoT, and highlighted Blockchain solutions with AI integration for healthcare
    ecosystems and the food business. The IoT with Blockchain integration has been
    presented by Zeng et al. [15]. for communication, information security, trust,
    and monitoring agricultural fields among the members of the agricultural system.
    Torky et al. [16]. has presented a unique Blockchain framework to address fundamental
    security and privacy issues in IoT-based precision agriculture systems by integrating
    Blockchain and IoT. Vangala et al. [17]. have studied the advancement of information
    security through Blockchain technology in IoT agriculture and presented a Blockchain-based
    security model for the smart agricultural sector. Ferrag at al. [18]. employs
    a fourtier green IoT-based agricultural framework to present privacy and security
    issues that exist in past studies in the field of green IoT agriculture, as well
    as proposes a classification of threat models to address attacks on privacy, availability,
    authentication, integrity, and confidentiality. Jamil et al. [19]. contributed
    prediction, optimization, and eventually control of a three-step Blockchain-enabled
    optimization approach for greenhouse systems. Fig. 1. BlockAgro : Proposed Framework
    with Cloud, fog and IoST layers Show All A summary of past research work in smart
    agricultural systems is presented in Table I. SECTION III. Proposed Framework
    The architectural description of the proposed smart agriculture system is presented
    in this part. The proposed BlockAgro framework is used for IoST agricultural monitoring
    and controlling system, as illustrated in Fig. 1, is made up of three layers:
    IoST device layer, fog computing layer, and cloud processing. The layered approach
    is being integrated with a Blockchain-enabled geospatial environment to address
    scalability, security, availability, stability, transparency, single-point failure,
    and trust issues in IoST agricultural platforms. Based on the geographic mapping,
    the IoST device layer collects and monitors information about soil moisture, temperature,
    water content, nutrient levels, pesticides, soil health, illumination, and crop
    growth to better irrigate, fertilize, and manage pests, enhance productivity,
    and decrease waste. They also monitor plant development, livestock, air content,
    and agricultural output. An access management queueing mechanism has been introduced
    between the device layer and the fog computing layer of the proposed framework
    to provide adequate connectivity management, scalability, and IoST device control
    in the agricultural system. Data collected from nearby IoST devices is analyzed
    and temporarily stored briefly on the fog computing layer. This architecture introduces
    fog nodes to reduce cloud overhead, faster and decentralized processing, reduce
    energy consumption, quick response, complexity reduction in device connectivity,
    and increase efficiency in agricultural systems. Fog nodes evaluate, process,
    and filter the agricultural data before transmitting it to the cloud layer. Blockchain
    is a decentralized technology integrated into the agricultural system to allow
    distributors, consumers, sellers, producers, government agencies, and other stakeholders
    to keep a shared ledger transparent, immutable, and maintains the highest trust
    among the parties. Scalability, mutual authentication, decentralization, stability,
    availability, persistence, efficiency, auditability, security, and privacy are
    all significant features of Blockchain technology in IoST-based agriculture systems.
    This framework’s smart contract manages privacy policies, business rules, device
    authentication mechanisms, and the history of all transactions performed by different
    system users. Moreover, after the fog nodes have processed the data, it is sent
    to the cloud network for permanent storage and display by various system users.
    TABLE I Summary of related works in smart agricultural platforms SECTION IV. Analytical
    modelling A. BlockAgro Application Model A BlockAgro application is defined as
    a 7 tuple Finite State Machine(FSM) represents as A = (ψ, Σ, δ, ϕ, D, λd, η) where
    ψ represent the non empty set of finite tasks i.e, ψ= ⋃ α j=1 t j i , Σ is the
    set of all possible application generated through the available IoST devices i.e,
    if we have n IoST devices then number of applications possible is the power set
    i.e, 2n. δ is a transition functions defined as δ:ψ×Σ→ψ×Σv where δ( t j i , D
    1 i )=δ( t j i +1, D j+1 ) signifies the output of the input data item D 1 i using
    the function t j i producing a new data item Dataj+1 to be transferred and processed
    by the successor task t j+1 i ,ϕ denotes the period of occurrence of an application
    i.e; the time interval between the consecutive application request, D symbolises
    the data hold by an application, λd signifies the deadline assigned by the application
    developer, η represents the execution time of an application respectively. A simple
    Geoagro application workflow is depicted in Figure 2. A task is a single unit
    generated from various IoST devices deployed over the large agriculture land that
    has to be computed in the fog computing devices. In this work, it considers finite
    number of tasks which is defined as τ={ τ 1 , τ 2 , τ 3 … τ n } where each τk
    consists of Million Instructions (MI). A Directed Acyclic Graph (DAG) G = (V,
    E) where V is the set of tasks and E is the set of links represent BlockAgro application
    workflow which is depicted in 2. It constitutes of different dependent tasks.
    The root node is called the entry node and last node is called the exit node.
    The IoST data first goes to the entry node and after processing the output is
    forwarded to the next node and so on. The final output of the IoST application
    is given by the exit node of the DAG. In figure 3 different possible IoST application
    workflow is presented. The various performance metrics for IoST application workflow
    is given below. Speedup Speedup is defined as the sequential execution time divided
    by the parallel execution time. The formula in equation 1 was used to calculate
    the sequential execution time. speedup= min p j ∈P [ ∑ t i ∈T C comp ( t i , p
    j )] makespan (1) View Source Fig. 2. Sample of BlockAgro Application workflow
    Show All Fig. 3. Different possible workflow of BlockAgro applications Show All
    Efficiency Efficiency is calculated as the speedup value divided by the number
    of processors being used. Equations in equation 2 are used to calculate a DAG’s
    efficiency. efficiency= sppedup NumberofVM ∗100 (2) View Source Schedule length
    ratio(SLR) A normalized schedule length is calculated in order to comparing the
    performance of scheduling algorithm in DAG by using the equation 3. SLR= makespan
    ∑ t i ∈CP min p j ∈P [ C comp ( t i , p j )] (3) View Source where CP stands for
    the critical path, which is the longest route in the application graph between
    the entry and exit nodes. Ccomp(ti, pj) reflected the cost of the ith task’s computation
    on the jth host. B. Fog Computing Model In BlockAgro, the fog layer serves as
    an intermediary layer between the IoST and the cloud computing layer, processing
    and executing numerous heterogeneous IoST applications. In our system model, it
    assumes finite number of fog devices F = {F1, F2, F3…Fn} where 1 ≤ i ≤ and each
    Fi supports type-1 hypervisor to create finite number of virtual machine instance
    represented as F i ={V M 1 i ,V M 2 i ,V M 3 i …V M m i } . C. Cloud Computing
    Model A cloud layer consists of k number of heterogeneous cloud server or hosts
    represented by CS={C S 1 ,C S 2 ,C S 3 …C S k } , where each cloud hosts C S j
    ∈CS,1≤j≤k is assumed to have infinitely many resource to process and store the
    result for future use. A cloud host j is represented as R k =( R C k , R M k ,
    R S k , R B K ,) . Where R C k represent the the CPU capacity measured in MIPS,
    R M k represents the RAM capacity measured in MB, R S k represents the storage
    capacity measured GB respectively. SECTION V. Conclusion and Future Work The integration
    of Blockchain, IoST, fog computing, and cloud computing gives numerous advantages
    over the centralized IoT-based agriculture system by providing a secure, de-centralized,
    and trusted platform. A Blockchain-assisted IoST framework BlockAgro has been
    proposed for the agricultural sector, with a three-tier architecture that addresses
    challenges in IoT agricultural systems through an IoST device layer, a fog layer,
    and a cloud layer. IoST devices are used to monitor soil moisture, temperature,
    water content, and nutrient levels to better irrigate, fertilize, and manage pests,
    increasing productivity and decreasing waste. They also monitor plant development
    and agricultural output. We overcame challenges such as bandwidth requirement,
    traffic volume, communication distance, network overload, data filtration, latency,
    response time, efficiency, and performance by including a fog node in the IoST
    agriculture system. Furthermore, real-time monitoring and updation, vulnerability
    checks, security, decentralized platform, item and equipment tracking, trustless
    environment, avoidance of single point failure, scalability, large volume of data
    storage, and large scale of device connection are major features added to the
    smart agricultural system with the use of blockchain technology. In future, intelligent
    agricultural management and information systems will be based on blockchain technology
    with queueing approaches for more effective task management. It will also plan
    to investigate, compare, and implement different queuing models in conjunction
    with the proposed model for efficient device connectivity. Authors Figures References
    Citations Keywords Metrics More Like This Access control model with enhanced flexibility
    and scalability for cloud 2015 International Conference on Green Computing and
    Internet of Things (ICGCIoT) Published: 2015 HASBE: A Hierarchical Attribute-Based
    Solution for Flexible and Scalable Access Control in Cloud Computing IEEE Transactions
    on Information Forensics and Security Published: 2012 Show More IEEE Personal
    Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED
    DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION
    TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732
    981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility
    | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap |
    IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s largest
    technical professional organization dedicated to advancing technology for the
    benefit of humanity. © Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: 2023 International Conference on Computer, Electronics and Electrical Engineering
    and their Applications, IC2E3 2023
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'BlockAgro: Towards Blockchain assisted IoST Framework for Agricultural Sector'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Verma A.
  - Bodade R.
  citation_count: '0'
  description: Agriculture is an essential part of developing countries’ economies.
    Internet of Things (IoT) sensors can provide data about agricultural fields and
    then operate based on human input. The IoT is cloud-based technology that allows
    for scalable management, data management, data security, data analysis, and more.
    The present IoT solutions are not suitable for the Indian agriculture sector due
    to it being very complex and not being cost-effective, which means it is not applicable
    to the reality on the ground. The existing IoT solutions employ paid network GSM/NB-IoT/4G/5G
    for sensor networks. In this chapter, a holistic affordable IoT framework focused
    on the agriculture Indian scenario is proposed. The IoT end nodes are battery-operated,
    and power consumption should be low and adopt low-power wide-area network technology.
    Cloud services included the weather department, agriculture scientists of Indian
    Council of Agricultural Research, e-mandi, the Indian market, the nearest point
    for selling, and so on. It also includes the monitoring of temperature, humidity,
    soil moisture, irrigation and insect and pest detection, actuator intervention,
    message notification for disastrous weather warnings, and expert advice for farmers.
    Crop monitoring via by using machine learning and deep learning algorithms. In
    future work, this framework can adopt edge and fog computing to improve more secure
    data management.
  doi: 10.1201/9781003298335-16
  full_citation: '>'
  full_text: '>

    "Access Provided By:University of Nebraska-Lincoln T&F eBooks ‍ Advanced Search
    Login About Us Subjects Browse Products Request a trial Librarian Resources What''s
    New!! HomeComputer ScienceAlgorithms & ComplexityBig Data, Cloud Computing and
    IoTComplete Low-Cost IoT Framework for the Indian Agriculture Sector Chapter Complete
    Low-Cost IoT Framework for the Indian Agriculture Sector ByAshish Verma, Rajesh
    Bodade Book Big Data, Cloud Computing and IoT Edition 1st Edition First Published
    2023 Imprint Chapman and Hall/CRC Pages 14 eBook ISBN 9781003298335 Share ABSTRACT
    Agriculture is an essential part of developing countries’ economies. Internet
    of Things (IoT) sensors can provide data about agricultural fields and then operate
    based on human input. The IoT is cloud-based technology that allows for scalable
    management, data management, data security, data analysis, and more. The present
    IoT solutions are not suitable for the Indian agriculture sector due to it being
    very complex and not being cost-effective, which means it is not applicable to
    the reality on the ground. The existing IoT solutions employ paid network GSM/NB-IoT/4G/5G
    for sensor networks. In this chapter, a holistic affordable IoT framework focused
    on the agriculture Indian scenario is proposed. The IoT end nodes are battery-operated,
    and power consumption should be low and adopt low-power wide-area network technology.
    Cloud services included the weather department, agriculture scientists of Indian
    Council of Agricultural Research, e-mandi, the Indian market, the nearest point
    for selling, and so on. It also includes the monitoring of temperature, humidity,
    soil moisture, irrigation and insect and pest detection, actuator intervention,
    message notification for disastrous weather warnings, and expert advice for farmers.
    Crop monitoring via by using machine learning and deep learning algorithms. In
    future work, this framework can adopt edge and fog computing to improve more secure
    data management. Previous Chapter Your institution has not purchased this content.
    Please get in touch with your librarian to recommend this.  To purchase a print
    version of this book for personal use or request an inspection copy  GO TO ROUTLEDGE.COM  Policies
    Privacy Policy Terms & Conditions Cookie Policy Journals Taylor & Francis Online
    Corporate Taylor & Francis Group Help & Contact Students/Researchers Librarians/Institutions
    Connect with us Registered in England & Wales No. 3099067 5 Howick Place | London
    | SW1P 1WG © 2024 Informa UK Limited"'
  inline_citation: '>'
  journal: 'Big Data, Cloud Computing and IoT: Tools and Applications'
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Complete Low-Cost IoT Framework for the Indian Agriculture Sector
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Sakthi U.
  - Thangaraj K.
  - Poongothai T.
  - Kirubakaran M.K.
  citation_count: '1'
  description: With the development of the Internet of Things (IoT) and machine learning
    technology, a smart agriculture environment produces more agricultural land and
    crop-associated data for knowledge discovery systems. Machine learning decision-making
    algorithm is applied to discover hidden knowledge patterns from the agricultural
    data stored in the distributed database. Big data analytics extract useful information
    from the large, distributed, and complex datasets, which helps the farmer to increase
    crop yield and quality of the production. The edge computing node collects crop
    data and land environment data from the agricultural lands using a different kind
    of IoT sensors. The predicted smart agricultural knowledge pattern can provide
    needed information to the farmers and other users like an agent, agriculture officers,
    researchers, and producers to get more profit. Cloud and fog computing provides
    efficient distributed data storage for big data and execute dynamic operations
    to predict business intelligence facts to increase production and minimize natural
    resource utilization. We have compared traditional data mining techniques with
    the business analytical tool hybrid association rule-based decision tree (HDAT)
    MapReduce approach for implementing decision tree algorithm to predict and forecast
    the future needs of the farmer to increase the profit and reduce the resource
    wastage.
  doi: 10.1007/978-981-16-9967-2_63
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Log in Find a journal
    Publish with us Track your research Search Cart Smart Trends in Computing and
    Communications pp 675–682Cite as Home Smart Trends in Computing and Communications
    Conference paper Big Data Analytics and Machine Learning Approach for Smart Agriculture
    System Using Edge Computing U. Sakthi , K. Thangaraj , T. Poongothai & M. K. Kirubakaran   Conference
    paper First Online: 06 July 2022 694 Accesses 1 Citations Part of the book series:
    Lecture Notes in Networks and Systems ((LNNS,volume 396)) Abstract With the development
    of the Internet of Things (IoT) and machine learning technology, a smart agriculture
    environment produces more agricultural land and crop-associated data for knowledge
    discovery systems. Machine learning decision-making algorithm is applied to discover
    hidden knowledge patterns from the agricultural data stored in the distributed
    database. Big data analytics extract useful information from the large, distributed,
    and complex datasets, which helps the farmer to increase crop yield and quality
    of the production. The edge computing node collects crop data and land environment
    data from the agricultural lands using a different kind of IoT sensors. The predicted
    smart agricultural knowledge pattern can provide needed information to the farmers
    and other users like an agent, agriculture officers, researchers, and producers
    to get more profit. Cloud and fog computing provides efficient distributed data
    storage for big data and execute dynamic operations to predict business intelligence
    facts to increase production and minimize natural resource utilization. We have
    compared traditional data mining techniques with the business analytical tool
    hybrid association rule-based decision tree (HDAT) MapReduce approach for implementing
    decision tree algorithm to predict and forecast the future needs of the farmer
    to increase the profit and reduce the resource wastage. Access provided by University
    of Nebraska-Lincoln. Download conference paper PDF 1 Introduction A computer-based
    smart agriculture system collects data from the farmer device, IoT sensors, and
    embedded devices and applies pattern prediction algorithm and deliver required
    information to the farmers and users. The size of agriculture data collected by
    Open Government Data (OGD) Platform India, and India Agriculture and Climate Dataset
    is in the order of gigabytes. The datasets are captured and gathered continuously,
    so the database size is increased by approximately 92 KB/min in the OGD data repository.
    The Global Positioning System (GPS) and IoT sensors agriculture dataset consists
    of crop images, weather images, soil and productivity data, which are stored in
    a cloud data repository for data analysis. To perform data analysis on large datasets,
    there is a need for high storage and a powerful computing system to provide efficient
    and effective data patterns to the users [1]. Big data analytics and cloud computing
    have been applied to store huge data and perform data analysis in the smart agricultural
    system [2, 3]. Edge computing is integrated with cloud computing and IoT to provide
    decisions with low latency time and increase the cloud network bandwidth [4].
    Figure 1 shows the smart agricultural model based on IoT and cloud computing technology.
    Smart farming is the integration of IoT and machine learning process to reduce
    excessive use of natural resources and reduce the damage of crops. The proposed
    system provides user-friendly Web-based application to the farmers for acquiring
    knowledge about the farms and the + environment. Big data are applied everywhere
    to increase the profit in the business and to analyze the historical data with
    the following four parameters: volume, velocity, variety, and veracity. Fig. 1
    Smart agricultural decision-making model Full size image The rest of the paper
    is organized as follows. Section 2 presents related work in a smart agricultural
    system using machine learning and edge computing. The architecture and functionalities
    of the different layers are discussed in Sect. 3. In Sect. 3, the workflow of
    the proposed system is summarized. Section 4 presents the machine learning algorithm
    used for data classification. Section 5 describes the experimental setup, execution
    method, and analyzes the performance of the proposed system. Section 6 concludes
    the result of the precision agricultural system and future scope. 2 Related Works
    Big data analytics and machine learning approach play a significant role in large
    dataset analysis and efficient decision-making process, which makes the smart
    agricultural system more profitable, safer, and efficient [5]. Many applications
    use big data analytics for achieving better profit and make better decisions with
    less time and cost [6]. Many research works have focused on the knowledge intelligent
    system for monitoring and controlling the agricultural land using IoT and fog
    computing with the cloud environment. Edge computing performs data analysis locally
    without transforming data to the cloud environment, which makes the precision
    agricultural system provide dynamic knowledge to the farmers and reduce the network
    latency. The computational load and storage process of the cloud environment are
    reduced by introducing the edge node in the IoT environment [7]. For example,
    the farmer can get the knowledge about the humidity of the soil, and he can decide
    the level of water irrigation to the crops so that the natural resource water
    can be utilized properly without wastage [8]. Intelligent services are provided
    to the farmers by applying data classification and prediction algorithms on the
    large datasets stored in the data repository in the edge node and the decentralized
    database server [9]. Precision agriculture system includes big data analytics,
    machine learning classification algorithm, edge computing, and IoT to increase
    the profit and reduce the wastage. The need for an edge computing nodes in cloud-based
    environments is analyzed in many research works [10]. The intelligent system does
    not move all dataset to the cloud server, which transfers partial data to the
    cloud server, which reduces the network latency and increases the network bandwidth
    [11]. An effective and efficient smart system is developed to overcome the challenges
    in the traditional agricultural land management systems. Many researchers and
    business applications use big data analytics to accomplish great success [12].
    A smart agricultural system is a modern application technology to provide, compute,
    and analyze multisource agricultural data for different management as shown in
    Fig. 2. It supports water irrigation management, crop management, soil analysis,
    and fertilizer analysis. The Hadoop distributed file system (HDFS) is used to
    work with a large amount of data in distributed methods in the cloud network [13].
    Google proposed MapReduce programming model for parallel and distributed data
    analysis approach for large datasets in a cloud environment. The important classification
    algorithm called decision tree is implemented using the MapReduce processing model
    to perform data analysis in a distributed manner. Fig. 2 Functionalities of a
    smart agricultural system Full size image 3 Big Data Analytics in Smart Knowledge-Based
    Agricultural System A smart agricultural system includes electronic IoT sensors,
    edge computing transmission technology, big data analytics, and machine learning.
    The purpose of this proposed system is to provide required agricultural land data
    to the farmers and other users without any delay in a precision agricultural environment
    as shown in Fig. 3. A smart agricultural system consists of four layers, which
    are the agricultural environment data collection layer, edge computing layer,
    big data analytics layer, and application layer. All layers are interconnected
    by the information or data flow. The functionalities provided by each layer are
    given below. Fig. 3 Layered architecture of the smart agricultural system using
    big data Full size image 3.1 Agricultural Environment Data Collection Layer This
    layer is responsible for collecting data from sources like the sensors deployed
    in the agricultural land, Global Positioning System (GPS), and Roadside Unit (RSU)
    and transfers those data to the next level edge computing layer and cloud server.
    The data will be in the form of photos, text, images, videos, and pictures. 3.2
    Edge Computing Layer The cloud network connected with the edge computing node
    via edge gateway using the protocols like Zigbee, Bluetooth, Wi-Fi, NFC, and Ethernet
    protocol. The edge computing node performs data analysis on the data collected
    from the data source and sends useful required information to the users. 3.3 Big
    Data Analytics Layer The association rule-based decision tree algorithm is executed
    to generate knowledge patterns for the farmers. The large volume of data is collected
    from the data source and stored in the database server for data analysis. The
    high performance and distributed rule mining algorithm is executed and performs
    data management. 3.4 Application Layer The farmer, agent, researcher, scientist,
    producer, and agent can access the smart agricultural application software using
    mobile devices connected with the Internet. The user can send a query to the knowledge
    base server and can receive information about the crop yield, fertilizer availability,
    pest control, soil details, and water irrigation status. 4 Machine Learning Approach
    for the Precision Agriculture In the big data ecosystem, machine learning technology
    provides powerful agricultural knowledge prediction algorithm to execute on large
    datasets. In Fig. 4, we have explained the steps involved in the big data analysis.
    In this paper, we propose the parallel and distributed association rule mining
    algorithm and tested with large datasets. The hybrid association rule-based decision
    tree algorithm is designed to analyze the distributed datasets available in the
    fog node and cloud computing node. In the supervised machine learning approach,
    decision trees are widely used prediction algorithm for large datasets. The most
    widely used supervised algorithm is tree-based algorithm, which gives greater
    accuracy, easy implementation, and consistency. Fig. 4 System framework for big
    data analytics Full size image 5 Performance Analysis The performance of the proposed
    has been evaluated by recording the farmer query response time for 6 days. The
    query processing time is calculated as the sum of user query request time and
    query response time. Figure 5 shows the various mobile user query response time
    sent on different days to the cloud environment. QID number represents query identification
    number, and it is calculated as the time taken by the cloud application service
    to compute the query and send a response to the farmer user. Fig. 5 User query
    response time Full size image The response can vary based on the type and nature
    of the query sent by the end user. In Fig. 6, the performance of the various approaches
    for generating the knowledge from the large datasets is explained. The proposed
    hybrid association rule-based decision tree-based MapReduce approach gives more
    accuracy and less error than the other data classification approach. The query
    response time can vary based on the user request type and nature of the query.
    Fig. 6 Performance comparisons of various approaches Full size image 6 Conclusion
    and Future Work Integration of cloud computing technologies and machine learning
    approaches swiftly moves traditional agricultural systems to smart agricultural
    systems. Big data analytics system has been applied in a smart agricultural system
    to provide knowledge patterns to the farmers to make real-time decisions about
    farm management. The proposed precision agricultural system is used in the field
    of science, which leads to maximum crop yield by reducing the usage of resources.
    The farm management process is optimized with the use of big data and machine
    learning methods by increasing the crop yield and reducing the resources like
    fertilizer, water, and pesticide. This system provides the required information
    to the farmers at the right time and right place. In future, the system can be
    extended for finding particular crop disease analysis. References S. Wolfert,
    L. Ge, C. Verdouw, Big data in smart farming-a review. Agric. Syst. 153, 69–80
    (2017) Article   Google Scholar   G.B. Kumar, An encyclopedic overview of ‘“big
    data”’ analytics. Int. J. Appl. Eng. Res. 10(3), 5681–5705 (2015) Google Scholar   M.
    Carolan, Publicising food: big data, precision agriculture, and co-experimental
    techniques of addition. Sociol Ruralis 57(2), 135–154 (2017) Article   Google
    Scholar   H.R. Zhang, Z. Li, T. Zou, Overview of agriculture big data research.
    Comput. Sci. 41(S2), 387–392 (2014) Google Scholar   M. Chunqiao, P. Xiaoning,
    M. Yunlong, Research status and development trend of agriculture big data technology.
    J. Anhui Agric. Sci. 44(34), 235–237 (2016) Google Scholar   D. Waga, K. Rabah,
    Environmental conditions’ big data management and cloud computing analytics for
    sustainable agriculture. World J. Comput. Appl. Technol. 2(3), 73–81 (2014) Article   Google
    Scholar   Z.F. Sun, K.M. Du, F.X. Zheng, Perspectives of research and application
    of big data on smart agriculture. J. Agric. Sci. Technol. 15(6), 63–71 (2013)
    Google Scholar   C.S. Nandyala, H.K. Kim, Green IoT agriculture and healthcare
    application (GAHA). Int. J. Smart Home 10(4), 289–300 (2016) Article   Google
    Scholar   A. Kamilaris, A. Kartakoullis, F.X. Prenafeta-Boldu, A review on the
    practice of big data analysis in agriculture. Comput. Electron. Agric. 143, 23–37
    (2017) Article   Google Scholar   A.Z. Abbasi, N. Islam, Z.A. Shaikh, A review
    of wireless sensors and networks’ applications in agriculture. Comput. Stand Interface
    36(2), 263–270 (2014) Article   Google Scholar   J. Lee, S.H. Kim, S.B. Lee, A
    study on the necessity and construction plan of the Internet of things platform
    for smart agriculture. J. Phys. IV 17(11), 1313–1324 (2014) Google Scholar   H.
    Tian, W. Zheng, H. Li, Application status and developing trend of open field water-saving
    internet of things technology. Trans. Chin. Soc. Agric. Eng. 32(21), 1–12 (2016)
    Google Scholar   I. Protopop, A. Shanoyan, Big data and smallholder farmers: big
    data applications in the agri-food supply chain in developing countries. Int.
    Food Agribus. Manage. Rev. 19, 173–190 (2016) Google Scholar   Download references
    Author information Authors and Affiliations Department of Computer Science and
    Engineering, Saveetha School of Engineering, SIMATS, Chennai, Tamil Nadu, 602105,
    India U. Sakthi Department of Information Technology, Sona College of Technology,
    Junction Main Road, Salem, Tamil Nadu, 636005, India K. Thangaraj Department of
    Computer Science and Engineering, St. Martin’s Engineering College, Secunderabad,
    Telangana, 500100, India T. Poongothai Department of Information Technology, St.
    Joseph’s Institute of Technology, Chennai, Tamil Nadu, 600119, India M. K. Kirubakaran
    Corresponding author Correspondence to U. Sakthi . Editor information Editors
    and Affiliations University of Leicester, Leicester, UK Yu-Dong Zhang Faculty
    of Engineering, University of the Ryukyus, Nishihara, Okinawa, Japan Tomonobu
    Senjyu Department of Computer Science, Khon Kaen University, Khon Kaen, Thailand
    Chakchai So-In Global Knowledge Research Foundation, Ahmedabad, Gujarat, India
    Amit Joshi Rights and permissions Reprints and permissions Copyright information
    © 2023 The Author(s), under exclusive license to Springer Nature Singapore Pte
    Ltd. About this paper Cite this paper Sakthi, U., Thangaraj, K., Poongothai, T.,
    Kirubakaran, M.K. (2023). Big Data Analytics and Machine Learning Approach for
    Smart Agriculture System Using Edge Computing. In: Zhang, YD., Senjyu, T., So-In,
    C., Joshi, A. (eds) Smart Trends in Computing and Communications. Lecture Notes
    in Networks and Systems, vol 396. Springer, Singapore. https://doi.org/10.1007/978-981-16-9967-2_63
    Download citation .RIS.ENW.BIB DOI https://doi.org/10.1007/978-981-16-9967-2_63
    Published 06 July 2022 Publisher Name Springer, Singapore Print ISBN 978-981-16-9966-5
    Online ISBN 978-981-16-9967-2 eBook Packages Engineering Engineering (R0) Share
    this paper Anyone you share the following link with will be able to read this
    content: Get shareable link Provided by the Springer Nature SharedIt content-sharing
    initiative Publish with us Policies and ethics Download book PDF Download book
    EPUB Sections Figures References Abstract Introduction Related Works Big Data
    Analytics in Smart Knowledge-Based Agricultural System Machine Learning Approach
    for the Precision Agriculture Performance Analysis Conclusion and Future Work
    References Author information Editor information Rights and permissions Copyright
    information About this paper Publish with us Discover content Journals A-Z Books
    A-Z Publish with us Publish your research Open access publishing Products and
    services Our products Librarians Societies Partners and advertisers Our imprints
    Springer Nature Portfolio BMC Palgrave Macmillan Apress Your privacy choices/Manage
    cookies Your US state privacy rights Accessibility statement Terms and conditions
    Privacy policy Help and support 129.93.161.219 Big Ten Academic Alliance (BTAA)
    (3000133814) - University of Nebraska-Lincoln (3000134173) © 2024 Springer Nature"'
  inline_citation: '>'
  journal: Lecture Notes in Networks and Systems
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Big Data Analytics and Machine Learning Approach for Smart Agriculture System
    Using Edge Computing
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Bajaj K.
  - Sharma B.
  - Singh R.
  citation_count: '77'
  description: The Internet of Things (IoT) applications and services are increasingly
    becoming a part of daily life; from smart homes to smart cities, industry, agriculture,
    it is penetrating practically in every domain. Data collected over the IoT applications,
    mostly through the sensors connected over the devices, and with the increasing
    demand, it is not possible to process all the data on the devices itself. The
    data collected by the device sensors are in vast amount and require high-speed
    computation and processing, which demand advanced resources. Various applications
    and services that are crucial require meeting multiple performance parameters
    like time-sensitivity and energy efficiency, computation offloading framework
    comes into play to meet these performance parameters and extreme computation requirements.
    Computation or data offloading tasks to nearby devices or the fog or cloud structure
    can aid in achieving the resource requirements of IoT applications. In this paper,
    the role of context or situation to perform the offloading is studied and drawn
    to a conclusion, that to meet the performance requirements of IoT enabled services,
    context-based offloading can play a crucial role. Some of the existing frameworks
    EMCO, MobiCOP-IoT, Autonomic Management Framework, CSOS, Fog Computing Framework,
    based on their novelty and optimum performance are taken for implementation analysis
    and compared with the MAUI, AnyRun Computing (ARC), AutoScaler, Edge computing
    and Context-Sensitive Model for Offloading System (CoSMOS) frameworks. Based on
    the study of drawn results and limitations of the existing frameworks, future
    directions under offloading scenarios are discussed.
  doi: 10.1007/s40747-021-00434-6
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Log in Find a journal
    Publish with us Track your research Search Cart Home Complex & Intelligent Systems
    Article Implementation analysis of IoT-based offloading frameworks on cloud/edge
    computing for sensor generated big data Original Article Open access Published:
    19 June 2021 Volume 8, pages 3641–3658, (2022) Cite this article Download PDF
    You have full access to this open access article Complex & Intelligent Systems
    Aims and scope Submit manuscript Karan Bajaj, Bhisham Sharma & Raman Singh  4954
    Accesses 80 Citations Explore all metrics Abstract The Internet of Things (IoT)
    applications and services are increasingly becoming a part of daily life; from
    smart homes to smart cities, industry, agriculture, it is penetrating practically
    in every domain. Data collected over the IoT applications, mostly through the
    sensors connected over the devices, and with the increasing demand, it is not
    possible to process all the data on the devices itself. The data collected by
    the device sensors are in vast amount and require high-speed computation and processing,
    which demand advanced resources. Various applications and services that are crucial
    require meeting multiple performance parameters like time-sensitivity and energy
    efficiency, computation offloading framework comes into play to meet these performance
    parameters and extreme computation requirements. Computation or data offloading
    tasks to nearby devices or the fog or cloud structure can aid in achieving the
    resource requirements of IoT applications. In this paper, the role of context
    or situation to perform the offloading is studied and drawn to a conclusion, that
    to meet the performance requirements of IoT enabled services, context-based offloading
    can play a crucial role. Some of the existing frameworks EMCO, MobiCOP-IoT, Autonomic
    Management Framework, CSOS, Fog Computing Framework, based on their novelty and
    optimum performance are taken for implementation analysis and compared with the
    MAUI, AnyRun Computing (ARC), AutoScaler, Edge computing and Context-Sensitive
    Model for Offloading System (CoSMOS) frameworks. Based on the study of drawn results
    and limitations of the existing frameworks, future directions under offloading
    scenarios are discussed. Similar content being viewed by others RETRACTED ARTICLE:
    A Review and State of Art of Internet of Things (IoT) Article 14 July 2021 Internet
    of Things: Challenges and Opportunities Chapter © 2014 Smart home security: challenges,
    issues and solutions at different IoT layers Article 10 May 2021 Introduction
    Internet of Things (IoT) is termed as a connection of networks over the Internet.
    However, the purpose of this network is not merely the transfer of data or acting
    as a communication channel; instead, the objective of this network is for enabling
    the linked devices to communicate and collaborate among themselves to provide
    some particular service. The aim of IoT is to simplify tasks and enable it to
    perform smartly by gaining a high degree of intelligence in applications and services
    with the least human intervention using various sensors, actuators and processors
    [1]. Internet serves a significant role in IoT services to provide a communication
    channel and set up a smart interface between people and surrounding objects. Cloud
    and edge structures act as the critical component of IoT, to provide useful applications,
    specific services in multiple application domains [2]. IoT brings in automation
    in all sectors of life referred to as public domain and also makes all physical
    objects intelligent that can connect, communicate with each other and can make
    the smart decision by themselves. IoT provides several applications to the various
    streams of users, and for that, it implements different frameworks. IoT frameworks
    can be termed as a set of guiding policies, protocols, and principles which simplify
    the accomplishment of IoT applications [3]. Manyika et al. [4] had predicted the
    sharp rise of IoT impacting the overall economic sector by $2.7 trillion to $6.2
    trillion per year by 2025. Health services and manufacturing would be the most
    impacted area in the system. After these sectors, the next most influenced areas
    from IoT would be farming, energy processing, and security. It is calculated that
    the sole financial impact of IoT technology in health-related services would be
    range from $1.1 trillion to $2.5 trillion per year by 2025 [4]. The application
    of IoT spans in all the domains of society and daily life; it serves in all the
    fields from environmental information, activity information of living organism
    to the processing tasks in the industries. In all domains, IoT has no existence
    without a Wireless Sensor Network (WSN). Acting as a backbone of IoT, sensors
    collect the data and communicate them. Sensors are connected with the devices
    having different technologies and vide application areas, which make the incorporation
    of IoT with WSN challenging [5]. Some of the common issues that arise for the
    deployment of IoT applications are data management, communication issues, real-time
    computing and security, privacy and scalability of data [6]. There is also trustworthiness
    issue related to security and privacy of data in cloud storage scenarios, there
    may arise a security concern due to continuous connectivity of IoT-based sensors
    with the edge entities [7, 8], the vulnerabilities can arise specially in sectors
    like healthcare where a small change in values can be life threatening. Data aggregation
    is also termed as one big problem for smart grid IoT systems [9] which is somewhere
    related to data gathering and management issue. Some applications are delay sensitive
    due to challenges when processing a large amount of data at edge or the cloud
    level of devices, leading to latency, which is not acceptable in some critical
    applications like health scenarios, transport management, etc. Some solutions
    demand high energy, and it’s evident that computation-intensive applications require
    more power and drain the batteries of devices quickly; thus, demanding expensive
    options or solutions [10]. Figure 1 lists several critical issues faced by IoT,
    in the paper focus of the study is that using the computation and data offloading
    in middleware architecture design can aid in dealing with the huge data generation
    and its processing challenge, also context awareness and device management issues.
    Architectures serve as a building blocks to fulfil all the essential requirements
    to solve the fundamental problems faced in IoT [11]. Fig. 1 Key issues faced by
    IoT Full size image The architecture of internet of things Limited knowledge and
    work in the present scenario resist the researchers to get through the scope of
    the Internet of Things. Middleware plays a vital role in IoT services, and this
    paper study the role of middleware and its scope to deal some of the critical
    challenges like time delay, energy consumption, scalability and big data management,
    etc. using offloading frameworks. Offloading frameworks are part of architectures
    to improve the overall functionality of IoT applications by developing a better
    understanding of the associated tool, technologies, and methodology. Its primary
    purpose is to solve real-life problems using and developing IoT concepts for day-to-day
    tasks [12]. The architecture serves as the most basic and essential block structure
    for IoT, and it is vital in terms of design choices for functional and non-functional
    requirements in IoT environments to serve the increasing scale and complexity
    of IoT. Figure 2 shows the basic five-layer general IoT architecture where the
    bottom layer is perception and sensing layer, this is the physical layer and forms
    the connection between the real and the digital world. The role of the transport
    layer is transporting data among different devices and objects. Enormous sensors
    lead to a massive amount of data generation necessitating IoT system to be a flexible
    and high-performance network structure to support different protocols among these
    devices adequately. Processing layer also called as the middleware layer, analyses
    and process the data coming from the transport layer. This layer uses large numbers
    of technologies for analysing and processing work. Massive databases are used
    for maintaining the data and edge, femto, fog, and cloud computing schemes are
    used for processing tasks containing big data [1]. Temporary data storage functionalities,
    data duplication and distribution is provided by a storage layer. The top-most
    layer of the architecture is the application layer and provides application services
    of the IoT system to users. Fig. 2 Basic structural design of IoT Full size image
    Smart solutions Edge and fog computing and its integration with cloud computing
    are one of the promising solutions to address many challenges faced by IoT applications,
    service-related problems and the limitations of cloud computing [13], Middleware
    plays a significant role to deal with such challenges and support the delay-sensitive
    and context-aware services in IoT applications by creating the smart gateway for
    edge/fog server structures. Local computing and nearby devices can perform a large
    amount of processing instead of carrying out all storage of data and computing
    in clouds clusters and thus provide timely and intelligent services. Computation
    offloading is a scheme to achieve various performance parameters mainly to reduce
    the consumption of energy and latency of service among the IoT devices. With the
    help of offloading, resource-efficient edge/fog computing for IoT applications
    can be achieved, to provide smart services to the users. Offloading criteria Understanding
    the data and its context plays a vital role in offloading. Some criterion is listed
    in Fig. 3 that acts as a measure to take an offloading decision. Middleware by
    working as a smart gateway acts as a crucial mediator to monitor the nodes and
    decide the offloading of applications and services. Fig. 3 Essential offloading
    criteria’s Full size image During the extreme computation requirement or under
    constrained resources or when the processing requirement of applications is more
    than the potential of the native device, devices are not able to fulfil the requirement
    of processing, and computation. This leads to delay or latency, which is critical
    to specific delay-sensitive applications. Load balancing is another criterion
    when the server has reached its maximum limit of processing the tasks, and jobs
    can be dispersed among other servers using offloading. Offloading is beneficial
    in the above cases and also this may help in securing the privacy and security
    of data at edge, femto cloud, or at fog cloud [14,15,16,17]. Related work A systematic
    review of literature is carried out starting from the basic understanding of context,
    its role in IoT, how context awareness can help in offloading tasks, decision
    and role of machine learning and deep learning that can aid in recognition of
    context and taking an offloading decision based on it. A detailed review and comparative
    study are carried out of various models and offloading frameworks. Role of context
    in offloading Many researchers define context as understanding the situation of
    some events, Abowed et al. [18] defined context as the information that can be
    used to characterise the status of an entity. Context-aware or sensitive applications,
    look at the details of the data for understanding the behaviour of applications
    and requirement of services, to identify who’s, where’s, when’s and what’s of
    entities, to utilise the information to decide why the situation is occurring
    or taking place [19]. Context-aware computing requires both sensing and increasingly
    learning, as the data coming from the physical devices and sensor sources are
    large in amount and of continuous nature, making learning and gathering inferences
    tough. Big data and machine learning, aids by providing similar techniques for
    processing massive data sets [20]. Several big data techniques, learning algorithms
    like neural and deep learning, etc. are used to analyse data for IoT applications
    and services. To recognise and distinguish the affective context from data, Nalepa
    et al. [21] showed the integration of context-aware systems with the affective
    computing prototype. Based on this knowledge, models, which interpret effects,
    were identified. Activity patterns are important during understanding and learning
    from data, recognition of patterns inference the knowledge and help in the identification
    of the context and situation. Researchers are mostly focussing on the implementation
    of computationally pervasive frameworks to make high-level conceptual models [22].
    Under the current scenario, the middleware system architecture suffers by falling
    short in services and resources [23]. Middleware can provide essential services
    like collection of data from sensors, its processing and context recognition [22].
    As achieving energy efficiency is a major challenge in context-aware applications
    as there are a continuous extraction and inference learning of data from sensors,
    there is a need of middleware design that can support context-awareness among
    application development task. Offloading for IoT applications As of now, there
    are a large number of devices and applications as part of IoT. There is a shift
    in the requirement of services towards computation and power management. The purpose
    of computation offloading architectures is to deal with such challenges and process
    the vast amount of data generated by IoT devices. Ren et al. [24] proposed a Software
    Defined Network (SDN) to counter the challenge of generation of Big data across
    the different geographical locations, an adaptive recovery mechanism using support
    vector machine is given as solution. In [25], Mobile Edge Computing (MEC) devices
    are used, and to identify the offloading rate, current battery level of the devices
    is used. A reinforcement learning-based computation-offloading framework is presented
    for IoT device. Q-learning model with the combination of deep learning and hot-booting
    to increase the learning speed is shown. For many large computation-intensive
    applications, there is a requirement of other entities to execute the tasks in
    place of a client device and getting results after processing [26], such mechanism
    is referred as offloading, where jobs are outsourced. This kind of offloading
    can be done in between sensors (edge devices), fog or cloud devices, but it turns
    out to be challenging to perform the real-time or actual processing due to the
    considerable distance between the cloud and end-user devices. Middleware can address
    such issues by acting as a smart medium in the middle of end nodes and the cloud.
    Mobile edge computing, cloudlets are some of the middleware technologies proposed
    to handle such offloading scenarios. Aazam et al. [27] described the offloading
    procedure, where the nodes close in proximity of client node that is the receiving
    node must be involved in the task of offloading for meeting the delay-sensitive
    requirements of applications. Offloading of tasks needs an intelligent system
    that can make optimal decisions about whether to offload based on the energy trade-offs
    and which specific task to be offloaded to the cloud, or a local fog or femto-cloud.
    Authors in [28] proposed a partial flooding algorithm, and given an offloading
    methodology for Internet of Vehicles (IoV) to improve the overall utilization
    of system. For the reduction of time and energy consumption for mobile devices,
    a multi-objective optimisation technique is proposed in [29], here Computation
    Offloading Model (COM) is proposed for IoT-based cloud-edge computing. With the
    perspective of context-awareness, many learning solutions and systems have been
    developed in IoT. These solutions are mainly designed-based, logic-based, and
    ontology-based, and developed using supervised, unsupervised, and reinforcement
    algorithms. A hybrid or a mixed approach can be designed to improve them. Deep
    learning, neural networks can be merged as a novel technique [30]. In the next
    section, we will be discussing the several IoT offloading frameworks and their
    major objectives and working parameters. Offloading frameworks There are different
    methodologies vide which the research network has learned different ways to implementing
    offloading frameworks, the various categories under offloading are: partition
    of applications, where applications can partition category wise [31], migration
    of threads, where first threads of applications are created then offloaded [32],
    migration of the application to the server-side, and distributed offloading [33].
    Various internal and external factors like the requirement of applications, condition
    of network and device computing capabilities, etc. influence the decision of offloading
    of computation-intensive applications. These internal and external factors affect
    the offloading decision whether, where and when the offloading should be done.
    Edge and fog computing are becoming a promising solution to lessen a load of computation
    from the cloud. This aids in delay-sensitive and context-aware applications by
    providing timely services. Instead of using only a cluster of clouds for data
    storage and performing all the computation processing, edge and fog computing
    try to utilise the maximum benefit of local computing. MAUI [34] based on smartphones
    to make them work longer with code offloading, works on the principle of managed
    code, which reduces the load on the coder. Program partitioning is used to increase
    the energy benefits. ThinkAir [35], another model that works on the principle
    of smartphone virtualisation in the cloud, dynamic allocation of resource and
    parallel execution, is used for code offloading. Lin et al. [36] implemented a
    Context-Aware Decision Algorithm (CADA), a decision engine-based approach to decide
    whether to offload a given method to the cloud servers. CADA algorithm was integrated
    with ThinkAir. MobiByte, a context-based model, proposed, is a cloud-based progressive
    application model for mobile cloud computing. It uses multiple data offloading
    schemes to increase smartphones devices applications performance, energy efficiency,
    and execution support [37]. Eom et al. [38] presented a mobile offloading framework
    called Machine Learning-Based Mobile Offloading Scheduler (MALMOS), having a novel
    approach of using online machine learning algorithms. It makes the assumption
    of attributes as independent of each other and also has a drawback of biasing
    towards earlier observations. Majeed et al. [39] presented code offloading using
    Support Vector Machine (SVM), which is an adaptive and dynamic mobile system to
    take the offloading decision locally or remotely. AnyRun Computing (ARC) [40]
    uses a dynamic offloading model to choose the most capable nearby local computing
    infrastructure to support offloading structure. In ARC for offloading, not only
    the nearby devices are considered, but peer devices can also be taken to perform
    offloading as code can be run anywhere on any device structure. A round-robin
    scheduling based offloading approach is used in the Autoscaler [41] to allocate
    the load among the available servers. It consists of three parts, back-end consisting
    of servers that act as surrogates, front-end to receive the incoming requests,
    and load simulator to generate the multiple offloading requests. An edge-based
    computing framework was proposed in [42] to help smart city residents by providing
    situational awareness. The presented framework showed that delivering relevant
    and essential services to the city residents would be beneficial by processing
    the IoT data at the edges. This would aid the decision-makers to be situation-aware
    and deliver services to the people. It is helpful in terms of latency and provides
    inferential knowledge to city residents. Results showed that using the edge computing
    services, the requirement of data that needed to be shifted to the remote server
    decreased significantly. The only limitation of this model is task allocation
    on edge devices is done based on fixed window size. Another model named Evidence-Aware
    Mobile Computational Offloading (EMCO) [43] toolkit and platform is a cloud-based
    model designed as a new solution to solve the challenges faced during computational
    offloading. For the categorisation of the contextual parameters and other important
    factors on the offloading decisions, it makes use of the crowd sensed evidence
    traces. In this framework, models are constructed in the cloud and are sent to
    mobile devices; therefore, raw processing of data is not done. Nakahara et al.
    [44] proposed a Context-Sensitive Model for Offloading System (CoSMOS). It is
    a self-adaptive offloading system and works based on the context-aware mechanism
    for mobile cloud computing (MCC) systems. An Adaptive Job Allocation Scheduler
    (AJAS) [45] to reduce the job reallocation delay time is proposed, it uses user
    behaviour pattern to requests the allocation of jobs to other nodes when the user''s
    applications are being executed. Dynamic Energy-Efficient Data Offloading (DEED)
    framework given by Yan et al. [46] for IoT applications is based on an unstable
    channel state in the communication model and was proposed for task reliability,
    energy consumption, and device reliability model. The authors of Energy Efficient
    Offloading Strategy (EES) [47] developed a new bi-objective model based on firefly
    technique, which looks for the most advantageous computational device. MobiCOP-IoT
    [48] framework uses the concept of surrogates, and it deploys them on both far-end
    clouds and nearby nodes. These nodes are edge-based and offer several features
    like automated self-regulating offloading of arbitrary tasks based on the output
    of an integrated decision-making engine. Having rich features, but still, MobiCOP-IoT
    needs manual configuring to decide whether the structure should work in cloud
    or edge mode. A Mobile Edge Computing (MEC) [49], based on an adaptive framework
    that supports mobile applications with offloading is proposed. It enables the
    application to dynamically offload among the mobile devices, edges and the cloud.
    An estimation model and unique design pattern based on DPartner, is proposed to
    decide the offloading scheme. A content-based offloading mechanism for Mobile
    Edge Computing is proposed [50] in which the offloading is based on data transmission
    rate, built on which the contents are partitioned into separate categories. The
    transmission rate is considered to identify the priority; users having a low transmission
    rate are regarded as lesser priority work and offloaded first. It is considered
    that data having low priority will be having lower utilisation of Small Base Station
    (SBS). In case the SBS traffic exceeds the threshold, then the resources will
    be offloaded to the WiFi—app first. A code offloading edge/fog mobile-based Autonomic
    Management Framework is a computation-offloading model for mobile fog environment
    [51]. The main components of the framework are fog nodes to support parallelism,
    code analyser unit identify the basic blocks that are computation hungry and require
    resources. Resource availability and network status are considered for computing
    latency and resource demand. Junior et al. [52] proposed a Context-Sensitive Offloading
    System (CSOS), which is a machine learning-based framework using J48, JRIP, IBK
    and Naive Bayes reasoning techniques. The authors selected two techniques—J48
    and JRIP for the implementation as these provided the best accuracy to make offloading
    decisions. The Fog Computing (FC)-based analytical model is proposed for IoT-based
    healthcare applications [53]. These services are critical in terms of latency,
    and therefore, require fast processing. The overall latency in communication must
    be reduced, like computation and network latency for IoT data transmission. An
    edge-based structure is proposed as a solution for the problem, where edges are
    used for processing and analysis of data to reduce high latency. Table 1 lists
    the authors with the objectives of their models and frameworks, and it also lists
    the offloading architecture specifying the basis and techniques of offloading
    used by them. The main aim of a large number of frameworks is to reduce time and
    energy consumption. The offloading frameworks are classified into two broad categories
    [54], Virtual Machine (VM) cloning, and Client–Server communication frameworks.
    In VM clone, the whole application is made on the cloud server by transferring
    application completely with its operating system; is therefore termed as full
    image transfer. After finishing the task, the cloned VM state is merged with the
    client to resume the execution. Client–server frameworks, works using communication
    protocols to achieve offloading, where only logic imitation termed as replication
    of logic part is done by pre-installing application part on the server device.
    Offloading frameworks mainly differ in their techniques and basis of implementation.
    Table 1 Objectives and architecture model of frameworks Full size table Table
    2 presents a detailed study of different frameworks, including the data sets or
    real-time environment for their working, parameters used by them and their offloading
    and simulation environment. It also details the tools, technologies and the implementation
    used by the frameworks. Table 2 Parameters and simulation environment of frameworks
    Full size table In the present scenario for large-scale IoT applications and systems,
    the offloading architecture is understudied. Due to a lack of understanding of
    contexts and situations, offloading is not favoured for large offloading environments.
    Consequently, there is poor usage and allocation of resources on the cloud, and
    the study of offloading have mostly shown that instead of benefiting, offloading
    increases computational effort. From Tables 1 and 2, we can identify that Client–server
    model is a better choice over the VM model for the offloading purpose as it saves
    bandwidth consumption and more near to the real-world situations required for
    data offloading. Also, most of the frameworks are mobile-based, and therefore,
    mobile and gaming applications are mostly used for the implementation purpose
    with cloud-based offloading scenario. From the literature reviews, it has been
    identified that very less work has been done on edge structures and edge-based
    cloud scenarios, and the working models and frameworks based on them were not
    focussed on the smart requirements or understanding-based offloading approach.
    Instead, mostly fixed scheduling schemes were used. Materials and methods A total
    of five frameworks having different simulation, working environments, datasets,
    and working parameters, have been shortlisted for the implementation study. All
    these models are chosen based on their effective, accurate, and novel approach
    towards offloading. EMCO framework A novel computational offloading approach was
    given by Flores et al. [43], in which the solution in the form of a toolkit and
    platform was designed for offloading, for implementation resources are available
    as open-source on GitHub. Crowdsensed evidence traces were used to categorise
    the influence of different contextual factors and other parameters on offloading
    decisions. A simulation environment for the framework is Google Cloud Messaging,
    LAPSI cloud-based runtime, C4.5 Decision tree classifier with fivefold cross-validation
    environment based on the Dalvik virtual machine. Implementation is done on lightweight
    compiler for executing the code. The results obtained from the EMCO framework
    are in the context of the time taken from a range of 1–30 s to execute on different
    devices and cloud environment, including pre-caching techniques. The maximum energy
    consumption in the local scenario was approximately 10,000 J. In Fig. 4a, the
    average execution time is calculated for both the applications of chess and backtracking.
    The time represents both summations of processing time and communication latency.
    Similarly, Fig. 4b shows the average energy consumption. Only a single local mobile
    device is taken, which shows that the local device consumes more time and energy
    for the calculations. Fig. 4 a Execution time of Chess and Backtracking Applications
    of EMCO Framework. b Energy consumption of Chess and Backtracking Applications
    of EMCO Framework Full size image This model had considered only the cloud approach
    for offloading having smartphone implementation only. Approximate average execution
    time and energy consumption is 8.33 s and 391 J on surrogate’s cloud excluding
    requirements of the local execution of the devices. MobiCOP-IoT Frameworks given
    by Benedetto et al. [48] contain surrogates set up as distant clouds and proximate
    nodes at the edges to enhance the capabilities of resource-constrained devices.
    Various scenarios were used to examine MobiCOP-IoT; both with the centralised
    cloud and edge distribution, and performance measurements taken were based on
    time and energy to complete multiple tasks of the gaming applications. Figure
    5a and b show edge computing is having the benefit in terms of performance parameter
    mentioned as time consumption. Fig. 5 a Performance gain for MobiCOP-IoT in edge
    scenario. b Performance gain for MobiCOP-IoT in cloud scenario. c Energy gain
    for MobiCOP-IoT in edge scenario. d Energy gain for MobiCOP-IoT in cloud scenario
    Full size image On the similar lines, Fig. 5c and d show benefits of edge computing
    in total consumption of power. The framework is tested on three applications N-Queens,
    RenderScript and VideoProcessing. In Fig. 5, improvement can be noticed in edge
    scenarios, results show that deployments get better in edge-based systems. Both
    scenarios were taken when tasks were fully offloaded to the centralised cloud
    and to the edge servers, as shown in Fig. 5. These benchmarks are available online
    as open source. The average results of each task are taken after running five
    times. Autonomic management framework Alam et al. [51] proposed an edge/fog-based
    framework simulated through MATLAB. The N-Queen application is taken to carry
    out test, Fig. 6a shows the increase in the execution time when the number of
    queens increased from 1 to 8. Similarly, Fig. 6b shows the raise in energy consumption
    with the increase in number of queens. Fig. 6 a Execution time of Fog Nodes in
    Autonomic Framework. b Energy consumption of Fog Nodes in Autonomic Framework
    Full size image The results from the model tested on dataset with the maximum
    number of queens taken was 8, variation in time observed was between 25 to 225
    s, and energy consumption varied from 10 to 77 J. Figure 6a shows the approximate
    execution time mentioned as response time in fog nodes and Fig. 6b shows approximate
    energy consumption, here eight fog nodes deployed to represent the 8-Queen problem.
    However, the model was not suitable when the number of queens increased to more
    than eight. CSOS framework Junior et al. [52] proposed a context-sensitive machine
    learning-based offloading environment (CSOS). Based on the implementation of a
    classification algorithm, a middleware is designed to work on a robust profiling
    system. Mobiles are very dynamic in nature; there is a need for an adaptive environment
    for them. By implementing the classification and profiling, a highly accurate
    decision engine way designed for mobiles. 10-fold cross-validation was used for
    training and testing purpose, and it achieved the accuracy of around 95%. The
    source for the implementation automation program is openly available on the GitHub.
    Figure 7a shows the average execution time with an increasing interval of 5 tasks
    under the contexts data set. The graph shows the execution time as favourable,
    unfavourable, and unknown contexts of BenchFace & BenchImage application. J48,
    JRIP & Cloudlet simulations are taken into consideration, and the best time of
    the model at a particular task is taken into consideration for the calculation.
    Fig. 7 a Execution time of CSOS Mobile-Cloud Environment. b Energy Consumption
    of CSOS Mobile-Cloud Environment Full size image On similar lines, the average
    power utilisation is shown in Fig. 7b for BenchFace, BenchImage & CollisionBalls
    application, and its results show that in the favourable condition, JRIP is more
    efficient in terms of consumption of energy than the cloudlet and J48 strategy,
    and it has a smaller number of rules and needs less classification time. In an
    unfavourable context, J48 and JRIP show promising results by choosing to process
    locally. Unknown contexts show that for offloading of the computations, JRIP yields
    better outcome and results in lesser time for execution with lower consumption
    of energy. Under the results shown in Fig. 7, the local strategy is not considered
    as it does not make use of the CSOS framework of offloading, and all processing
    is done on the smartphone. Further, in this framework, only cloud structure was
    taken for implementation of offloading structure on a mobile cloud with J48 &
    JRIP classifier. Fog computing framework A fog-computing framework-based analytical
    model proposed by Shukla et al. [53], aims at boosting the cloud-based computations
    by bringing them near the edge devices. A framework was designed for a healthcare
    system to incorporate the analytical model and hybrid fuzzy-based reinforcement-learning
    algorithm. iFogSim simulator was used for implementation that includes fog devices,
    ECG sensors, and cloud servers. Five physical arrangements topologies were used,
    as shown in Fig. 8. Fig. 8 a Delay analysis of Fog Computing (FC) analytical framework.
    b Efficiency analysis of Fog Computing (FC) analytical framework Full size image
    Simulation setup was implemented on iFogSim (Net-Beans), Spyder (Python), skfuzzy
    API to model the fuzzy system & Java APIs. ECG data set available on the UCI machine
    learning repository was used, with parameters already specified in the paper mentioned
    in Table 2. Results in Fig. 8a and b show physical topology configurations, and
    this framework showed improved performance and efficiency by minimising latency.
    Very few parameters of the data set were selected, as in case of health scenarios
    the accuracy of the results is critical. There might be a rise in overall latency,
    with the increase in number of parameters or increasing the size of dataset. But
    this model needs to be tried out with more parameters and larger dataset to formulate
    for obtaining desired improvement regarding overall latency, consumption of memory
    and network. This section presents that EMCO framework; consider only cloud approach
    towards offloading with the average execution time of 10 s over six cloud surrogates
    and average energy consumption of 389 J over five cloud surrogates. MobiCOP-IoT
    working based on mobile applications showed that edge processing is beneficial
    over cloud processing. Still, there is a big rise in execution time and power
    consumption with the increase in the size of an application. For different applications
    on different devices, the range of average execution time is from 4 to 20 s, and
    the overall energy consumption is approximately from 10 to 195 J. In the Autonomic
    framework, the execution time extends beyond 200 s, which is comparatively higher
    than other frameworks. Here the size of application decreases the performance
    and energy consumption that goes around 80 J. Like MobiCOP-IoT, CSOS framework
    is also a smartphone-based framework. The average variation of execution time
    is 4 s in case of favourable context, 17 s in unknown context and 103 s in unfavourable
    context cases. Similarly, the variation in the energy consumption in three different
    contexts is 0.5, 1 and at max 1.5 J/s, respectively. Similar to EMCO framework,
    CSOS is a cloud-based model without considering edge processing. The increase
    in the number of tasks adversely affects its performance. Fog computing framework
    based on edge processing working structure, is same as in EMCO and Autonomic framework
    in terms of non-smartphone-based application and gives an average delay of 0.8
    s with more than 85% network and 25% memory consumption. This model gives a good
    performance in terms of time in general application scenario but required testing
    when data size increases as other frameworks have large data set over this. After
    analysis of the implementation of different frameworks, it can be stated that
    most of the devices do not have any built-in framework for offloading computation
    and switches for manual offloading. There is a need for smart middleware gateway
    design that can work as a solution with the smart-devices operating system to
    perform the efficient offloading. Designing the middleware which can learn from
    the sensory data, battery behaviour, context inferences through machine learning
    and processing of that data, are the major challenges faced, as most of the available
    solutions are rule-based or logic-based. There is a scope of further improvement
    using hybrid methods and learning algorithms in future. Comparative analysis and
    discussion Under this section, some frameworks are taken for comparative study
    with the frameworks analysed above, based on several performance parameters, models
    are compared. These frameworks have their working conditions and environment discussed
    in detail in Sect. “Related work” and Tables 1 and 2. MAUI is remotely executed
    on the server with WiFi with Round-trip time (RTT) of 10, 25, 50, 100 and 220
    ms as shown in Fig. 9a and b. Fig. 9 a Execution time of MAUI Model for smartphone
    code offload. b Energy consumption of MAUI Model for smartphone code offload Full
    size image In this, three applications are taken for performance and energy consumption
    parameters running standalone on the smartphone, which are video game for 400
    frames and 30 moves for chess game and face recognition application, are taken.
    MAUI is tested on smartphones with mobile applications and uses program partitioning
    methodology. Figure 10a shows the mean time execution and Fig. 10b shows the energy
    drain for ARC framework, here nexus smartphone is used to run all benchmarks to
    attain a baseline performance in three modes. The three modes are fixed network
    topology, full connectivity-based dynamic network topology, and emulated dynamic
    network topology. Fig. 10 a Mean time execution for AnyRun Computing (ARC). b
    Energy drain for AnyRun Computing (ARC) Full size image In AutoScaler, execution
    time is based on the minimax algorithm, and varies on different surrogates as
    that can be seen in the Fig. 11a. Fig. 11 a Execution time of AutoScaler. b Processing
    time of Edge Computing Framework Full size image In Fig. 11b, edge computing framework,
    edges are used for offloading data, storage, processing, and privacy protection.
    For the partitioning of data for offloading to the edge devices fixed window size
    approach is used to sample the sensor stream data. In Fig. 12a and b, the average
    of the total time taken for execution and their mini-max values are specified
    for both N-Queens and BenchImage applications. Fig. 12 a Average execution time
    of N Queens Application for CoSMOS. b Average execution time of BenchImage Application
    for CoSMOS Full size image In Fig. 13a, the average of total energy consumption
    for N-Queens application is taken and in Fig. 13b, the average for total consumption
    of energy for BenchImage application considered. Here min–max values are specified
    for both the applications. The three environment chosen for the analysis are cloudlet
    WiFi, cloud WiFi and cloud 3G. Fig. 13 a Average energy consumption of N- Queens
    Application for CoSMOS. b Average energy consumption of BenchImage Application
    for CoSMOS Full size image From the Figs. 12 and 13, it can be said that, application
    size and physical distance among the devices and remote servers have a significant
    influence over the system as the offloading time rises with the transfer time
    of the dataset. From Fig. 9, it is observed that the Round-trip time significantly
    affects the execution time and energy consumption of the applications. A sudden
    rise represents that this model is highly dependent on the size of the application
    similar to observed in frameworks like MobiCOP-IoT and Autonomic frameworks. ARC
    framework from Fig. 10 represents the mean execution time and energy drain using
    application datasets described in Table 2. The execution time varies from 11 to
    20 s with an exceptionally high-power consumption of around 300 Joules in two
    modes and about 600 J in ARC dynamic mode. This approach may waste resources during
    offloading done by the inference engine, which ignores the impact of remote devices
    for offloading. AutoScaler can be referred to as a predecessor model of EMCO considering
    cloud approach, and it takes approximately 16.02 s over 11 devices, which is relatively
    higher like ARC. If the local devices are not considered, then the average computation
    time is about 13.6 s, and this, including communication latency and processing
    time. The main consideration point here is that the cases used are not a realistic
    practice as a smartphone. Another framework based on edge computing structure
    is discussed to process the IoT data [42]. This model resembles the Fog Computing
    model [53] from the material and method section. This model takes 0.102 s (sec)
    in offline mode for CityPulse data set, 0.4 s for the Chicago park data set to
    calculate the results using edge processing. The total processing time in the
    real-time scenario is approximately 4.35 s, which includes sensor processing time
    of 0.352 s, edge to cloud network delay of 0.256 s, overall processing time in
    edge and cloud are 3.5 s and user delay is 0.243 s. Here the only disadvantage
    is that, fixed window size approach is used during data offloading, which is a
    rigid approach for all kinds of data whereas Fog Computing model uses the reinforcement
    learning approach but dataset size used is small and can’t be relied for real
    world applications. A Context-Sensitive Model for Offloading System (CoSMOS),
    which is a mobile-based cloud computing offloading decision support model, also
    termed as self-aware and self-expressive system was proposed [44]. Two mobile
    applications, N-Queen problem, and BenchImage for image-processing applications
    used, with the focus on the CPU processing time. Over these applications, N-Queens
    have a relatively small dataset and BenchImage have a large data set. In the case
    of N-Queens, the number of queens taken is between 4 and 13. However, when taken
    number of queens taken are 14 or more, then the processing time and energy consumption
    increases drastically. For BenchImage application, five different resolutions
    of three pictures are handled within a range from 0.3 to 0.8 MP. From the implementation,
    analysis, and comparison of different frameworks, it is observed that most of
    the structures are tested on gaming applications and are mobile-based. Their efficiency
    is affected by the bulkiness of the applications. Edge Computing paradigm and
    Fog computing frameworks discussed show some useful practical life data set implementations
    and shows promising results in terms of various parameters like time, energy,
    network, and system utilisation. However, some of the direct methods used for
    offloading create a scope for some hybrid, regression, and learning-based approaches
    for offloading. Scaling-up the requirement of services needs to be handled under
    offloading architectures, to manage the particular load of the devices. Proper
    planning for the capacities is required to identify the adequate number of back-end
    servers. Future research challenges There are several challenges in IoT from heterogeneity
    among the devices, their data to device management, context awareness and processing
    of information [5]. It has identified that, irrespective of application areas,
    there are some common key issues that keep on existing, like inherent distribution,
    data management and making human centric applications [74]. Today cloud services
    are required to give stable Quality of Service (QoS), as these can be reused.
    A cost-effective approach is required to provide cloud service composition [75].
    Offloading appears as solution for IoT applications and devices but it is not
    as straightforward as it seems to be, raising further, several challenges from
    this fusion of technologies. To overcome the problem of computing power limitation,
    storing capability, and limitations of built-in batteries, the offloading of computations
    are critically important [45]. Understanding the context, situation, or status
    of data and learning from them for computational and data offloading is among
    the major problems and can have a high impact on making systems and applications
    as a part of intelligent IoT services [51]. Most of the designed solutions are
    based on rules, logic and ontology using supervised and unsupervised learning,
    along with reinforcement algorithms. There is a scope of improvement using hybrid
    methods, such as neural methods and deep learning algorithms to achieve better
    performance [29]. There is a need for an intelligent system that can make optimal
    decisions about which specific tasks to be offloaded, to the cloud or Femto-cloud.
    Designing the middleware which can learn from the sensory data, battery behaviour,
    and context inferences through machine learning and processing of the data are
    quite challenging. Middleware devices encounter limitation during providing service
    due to resource constraints in terms of power, memory, and bandwidth [23, 24].
    Many IoT applications require separate entities to compute and process the tasks
    on behalf of user devices, like smart home, healthcare, intelligent transport
    management, Ambient Assisted Living (AAL), Virtual Reality (VR), etc. to produce
    the results. It becomes challenging to provide real-time computations and delivering
    fast responses due to significant distance among the cloud servers and end-users
    [26, 27]. During transmission and computing for offloading the IoT applications
    to the cloud, there is the consumption of a large amount of energy because the
    far-end network experiences a higher latency and network delay. Edge and Fog nodes
    provide solution and offer the cloud services at near end edges of the network,
    and this makes IoT applications to run locally with minimum energy utilization
    and reduce the delay. However, such a structure has a limitation in terms of resource
    capacity. Resource-intensive IoT applications suffer constrained resources issue
    under edge/fog nodes implementation [46, 50]. Current studies in the field of
    offloading are more focussed on centralisation and coordination of data. Edge
    computing and fog computing are new areas of research and need establishing frameworks
    to put these concepts into practice [51]. Identification of the situation is a
    crucial issue to take the offloading decision as all of them are not beneficial,
    and a primary challenge is to identify those situations. A large number of factors
    influence the efficiency of offloading for making practical and optimal offloading
    decisions [42]. The key research issues for offloading computation in fog or edge
    structures are choosing the approach to offload computation, the module or procedure
    of applications to offload, and where to offload for minimizing the latency of
    service computing [47]. There is need of a smart, intelligent and selective offloading
    scheme to formulate the decision of whether to offload computation, when to offload
    and where to offload the tasks, like across local devices at edge level, to the
    fog cloud, or the cloud structure in proximity. Most of the solutions designed
    are single reasoner, or mobile-based, and therefore, mobile and gaming applications
    are used for the implementation study and very less work has been done on IoT
    applications and their implementation on edge-based cloud scenarios, and the working
    models or frameworks based on offloading with such scenarios have not focussed
    on the smart requirements or understanding-based offloading approach. Instead,
    mostly fixed scheduling schemes were used. With the results obtained in figures
    and graphs it can be seen that for most of the applications, their efficiency
    is affected by the bulkiness of the applications, with the efficient deployment
    of fog/edge scenarios and smart offloading scheme we can deal with such issues.
    Direct methods used for offloading create a scope for implementation of some hybrid
    and learning-based approaches for offloading. Such methodologies can take advantage
    of the reasoning techniques to provide offloading decisions, as higher latency
    and delay makes the data meaningless and inadequate for end-users. Conclusion
    In this paper, a detailed implementation analysis and comparison of various data
    offloading frameworks has been carried out, with the aim of understanding and
    analysing the role of context or situation to perform the data offloading. Some
    of the existing frameworks based on their novel approach and optimum results are
    taken for implementation. Under the analysis of implemented frameworks and their
    comparison with some of the existing frameworks, it has been identified that to
    meet the performance requirements of IoT enabled services, offloading play a crucial
    role. From the work carried out it also has been identified the size of the applications
    play crucial role for achieving adequate performance as increase in time and energy
    consumption can be seen in the graphs under the implementation, some intelligent
    approach is required to deal with large data size of applications and then perform
    the offloading to perform computations. From the experiments done and results
    obtained, it has been deduced that offloading is not a straight way approach,
    rather before offloading some learning of context of data is required which will
    aid in taking correct decision like where and when to offload. Under the implementation
    scenarios, it has been seen that some learning methodologies were used in few
    implementations, but mostly was performed under mobile-based scenarios, there
    has been scope of improvement by implementing smart middleware design using hybrid
    learning mechanism to implement the computation offloading. It also has been identified
    that there is a future possibility of work in edge structures and edge-based cloud
    structures for offloading frameworks, as very little work has been done in such
    scenarios and also mostly fixed scheduling schemes were used which can be improved.
    References Sethi P, Sarangi SR (2017) Internet of things: architectures, protocols,
    and applications. J Electr Comput Eng 2017:9324035 Google Scholar   Ray PP (2016)
    A survey of IoT cloud platforms. Future Comput Inf J 1(1):35–46 Article   Google
    Scholar   Ammar M, Russello G, Crispo B (2018) Internet of Things: a survey on
    the security of IoT frameworks. J Inf Secur Appl 38:8–27 Google Scholar   Manyika
    J, Chui M, Bughin J, Dobbs R, Bisson P, Marrs A (2013) Disruptive technologies:
    advances that will transform life, business, and the global economy. McKinsey
    Glob Inst San Francisco CA 180:17–21 Google Scholar   Giri A, Dutta S, Neogy S,
    Dahal K, Pervez Z (2017) Internet of things (IoT): a survey on architecture, enabling
    technologies, applications and challenges. In: Proceedings of the 1st International
    Conference on Internet of Things and Machine Learning, Liverpool, UK, pp 1–12
    Al-Qaseemi SA, Almulhim HA, Almulhim MF, Chaudhry SR (2016) IoT architecture challenges
    and issues: lack of standardization. In; Future Technologies Conference (FTC),
    San Francisco, pp 731–738 Khan A, Din S, Jeon G, Piccialli F (2020) Lucy with
    agents in the sky: trustworthiness of cloud storage for industrial internet of
    things. IEEE Trans Industr Inf 17(2):953–960 Article   Google Scholar   Aujla
    GS, Jindal A (2021) A decoupled blockchain approach for edge-envisioned IoT-based
    healthcare monitoring. IEEE J Sel Areas Commun 39(2):491–499 Article   Google
    Scholar   Saleem A, Khan A, Malik SUR, Pervaiz H, Malik H, Alam M, Jindal A (2019)
    FESDA: fog-enabled secure data aggregation in smart grid IoT network. IEEE Internet
    Things J 7(7):6132–6142 Article   Google Scholar   Li Y, Björck F, Xue H (2016)
    IoT architecture enabling dynamic security policies. In: Proceedings of the 4th
    International Conference on Information and Network Security, Kuala Lumpur, Malaysia,
    pp 50–54 Cavalcante E, Alves MP, Batista T, Delicato FC, Pires PF (2015) An analysis
    of reference architectures for the internet of things. In: Proceedings of the
    1st International Workshop on Exploring Component-Based Techniques for Constructing
    Reference Architectures, Montreal, QC, Canada, pp 13–16 Ray PP (2018) A survey
    on Internet of Things architectures. J King Saud Univ Comput Inf Sci 30(3):291–319
    Google Scholar   Qureshi KN, Jeon G, Piccialli F (2021) Anomaly detection and
    trust authority in artificial intelligence and cloud computing. Comput Netw 184:107647
    Article   Google Scholar   Elgazar A, Harras K, Aazam M, Mtibaa A (2018) Towards
    intelligent edge storage management: determining and predicting mobile file popularity.
    In: 2018 6th IEEE International conference on mobile cloud computing, services,
    and engineering (MobileCloud), Bamberg, Germany, pp 23–28 Masip-Bruin X, Marín-Tordera
    E, Tashakor G, Jukan A, Ren G (2016) Foggy clouds and cloudy fogs: a real need
    for coordinated management of fog-to-cloud computing systems. IEEE Wirel Commun
    23(5):120–128 Article   Google Scholar   Huang C, Lu R, Choo KR (2017) Vehicular
    fog computing: architecture, use case, and security and forensic challenges. IEEE
    Commun Mag 55(11):105–111 Article   Google Scholar   Aazam M, Huh E-N, St-Hilaire
    M (2018) Towards media inter-cloud standardization—evaluating impact of cloud
    storage heterogeneity. Int J Grid Util Comput 16(3):425–443 Article   Google Scholar   Abowd
    GD, Dey AK, Brown PJ, Davies N, Smith M, Steggles P (1999) Towards a better understanding
    of context and context-awareness. In: Handheld and Ubiquitous Computing. Springer,
    Berlin, Heidelberg, pp 304–307 Sukode S, Gite S, Agrawal H (2015) Context aware
    framework in IoT: a survey. Aqua Microbial Ecol Int J 4(1):1–9 Google Scholar   Zaslavsky
    A, Perera C, Georgakopoulos D (2013) Sensing as a service and big data. In: International
    conference on advances in cloud computing, Bangalore, India, pp 21–29 Nalepa GJ,
    Kutt K, Bobek S (2019) Mobile platform for affective context-aware systems. Future
    Gener Comput Syst 92:490–503 Article   Google Scholar   Yürür Ö, Liu CH, Sheng
    Z, Leung VCM, Moreno W, Leung KK (2014) Context-awareness for mobile sensing:
    a survey and future directions. IEEE Commun Surv Tutor 18(1):68–93 Article   Google
    Scholar   Wood AD, Stankovic JA, Virone G, Selavo L, He Z, Cao Q, Doan T, Wu Y,
    Fang L, Stoleru R (2008) Context-aware wireless sensor networks for assisted living
    and residential monitoring. IEEE Netw 22(4):26–33 Article   Google Scholar   Ren
    X, Aujla GS, Jindal A, Batth RS, Zhang P (2021) Adaptive recovery mechanism for
    SDN controllers in Edge-Cloud supported FinTech applications. IEEE Internet Things
    J 2021:1–1 Google Scholar   Shukla RM, Munir A (2017) An efficient computation
    offloading architecture for the Internet of Things (IoT) devices. In: 2017 14th
    IEEE annual consumer communications networking conference (CCNC), Las Vegas, pp
    728–731 Jararweh Y, Doulat A, AlQudah O, Ahmed E, Al-Ayyoub M, Benkhelifa E (2016)
    The future of mobile cloud computing: Integrating cloudlets and Mobile Edge Computing.
    In: 2016 23rd international conference on telecommunications (ICT), Thessaloniki,
    pp 1–5 Aazam M, Zeadally S, Harras KA (2018) Offloading in fog computing for IoT:
    review, enabling technologies, and research opportunities. Futur Gener Comput
    Syst 87:278–289 Article   Google Scholar   Li B, Peng Z, Hou P, He M, Anisetti
    M, Jeon G (2019) Reliability and capability based computation offloading strategy
    for vehicular ad hoc clouds. J Cloud Comput 8(1):1–14 Article   Google Scholar   Xu
    X et al (2020) A computation offloading method over big data for IoT-enabled cloud-edge
    computing. Futur Gener Comput Syst 95:522–533 Article   Google Scholar   Sezer
    OB, Dogdu E, Ozbayoglu AM (2018) Context-aware computing, learning, and big data
    in internet of things: a survey. IEEE Internet Things J 5(1):1–27 Article   Google
    Scholar   Eom H (2014) Extending the capabilities of mobile platforms through
    remote offloading over social device networks. University of Florida Chun B-G,
    Ihm S, Maniatis P, Naik M, Patti A (2011) CloneCloud: elastic execution between
    mobile device and cloud. In: Proceedings of the sixth conference on computer systems,
    New York, pp 301–314 Hassan MA, Chen S (2012) Mobile MapReduce: minimizing response
    time of computing intensive mobile applications. In: Mobile computing, applications,
    and services, Los Angeles, pp 41–59 Cuervo E, Balasubramanian A, Cho D-K, Wolman
    A, Saroiu S, Chandra R, Bahl P (2010) MAUI: making smartphones last longer with
    code offload. In: Proceedings of the 8th International Conference on Mobile Systems,
    Applications, and Services, pp 49–62 Kosta S, Aucinas A, Pan H, Mortier R, Xinwen
    Z (2012) ThinkAir: dynamic resource allocation and parallel execution in the cloud
    for mobile code offloading. In: Proceedings IEEE INFOCOM, IEEE, pp 945–953 Ting-Yi
    L, Ting-An L, Cheng-Hsin H, Chung-Ta K (2013) Context-aware decision engine for
    mobile cloud offloading. In: IEEE wireless communications and networking conference
    workshops (WCNCW), Shanghai, pp 111–116 Khan A, Mur R, Othman M, Khan AN, Abid
    SA, Madani SA (2015) MobiByte: an application development model for mobile cloud
    computing. Int J Grid Util Comput 13(4):605–628 Article   Google Scholar   Eom
    H, Figueiredo R, Cai H, Zhang Y, Huang G (2015) MALMOS: machine learning-based
    mobile offloading scheduler with online training. In: 3rd IEEE international conference
    on mobile cloud computing, services, and engineering, San Francisco, pp 51–60
    Majeed AA, Khan AUR, Ul Amin R, Muhammad J, Ayub S (2016) Code offloading using
    support vector machine. Sixth Int Conf Innov Comput Technol (INTECH) 2016:98–103
    Google Scholar   Ferrari A, Giordano S, Puccinelli D (2016) Reducing your local
    footprint with anyrun computing. Comput Commun 81:1–11 Article   Google Scholar   Flores
    H, Xiang S, Kostakos V, Ding AY, Nurmi P, Tarkoma S, Hui P, Li Y (2017) Large-scale
    offloading in the Internet of Things. In: 2017 IEEE international conference on
    pervasive computing and communications workshops (PerCom Workshops), (Heidelberg,
    Germany),pp 479–484 Alamgir Hossain SK, Rahman A, Hossain MA (2018) Edge computing
    framework for enabling situation awareness in IoT based smart city. J Parall Distrib
    Comput 122:226–237 Article   Google Scholar   Flores H, Hui P, Nurmi P, Lagerspetz
    E, Tarkoma S, Manner J, Kostakos V, Li Y, Su X (2018) Evidence-aware mobile computational
    offloading. IEEE Trans Mob Comput 17(8):1834–1850 Article   Google Scholar   Nakahara
    FA, Beder DM (2018) A context-aware and self-adaptive offloading decision support
    model for mobile cloud computing system. J Ambient Intell Humaniz Comput 9(5):1561–1572
    Article   Google Scholar   Kim H-W, Park JH, Jeong Y-S (2019) Adaptive job allocation
    scheduler based on usage pattern for computing offloading of IoT. Futur Gener
    Comput Syst 98:18–24 Article   Google Scholar   Yan H, Zhang X, Chen H, Zhou Y,
    Bao W, Yang LT (2020) DEED: dynamic energy-Efficient Data offloading for IoT applications
    under unstable channel conditions. Futur Gener Comput Syst 96:425–437 Article   Google
    Scholar   Adhikari M, Gianey H (2019) Energy efficient offloading strategy in
    fog-cloud environment for IoT applications. Internet Things 6:100053 Article   Google
    Scholar   Benedetto JI, González LA, Sanabria P, Neyem A, Navón J (2019) Towards
    a practical framework for code offloading in the Internet of Things. Futur Gener
    Comput Syst 92:424–437 Article   Google Scholar   Chen X, Chen S, Ma Y, Liu B,
    Zhang Y, Huang G (2019) An adaptive offloading framework for Android applications
    in mobile edge computing. Sci China Inf Sci 62(8):82102 Article   Google Scholar   Zhao
    X et al (2019) Deep learning based mobile data offloading in mobile edge computing
    systems. Futur Gener Comput Syst 99:346–355 Article   Google Scholar   Alam MGR,
    Hassan MM, Uddin MZ, Almogren A, Fortino G (2019) Autonomic computation offloading
    in mobile edge for IoT applications. Futur Gener Comput Syst 90:149–157 Article   Google
    Scholar   Junior W, Oliveira E, Santos A, Dias K (2019) A context-sensitive offloading
    system using machine-learning classification algorithms for mobile cloud environment.
    Futur Gener Comput Syst 90:503–520 Article   Google Scholar   Shukla S, Hassan
    MF, Khan MK, Jung LT, Awang A (2019) An analytical model to minimize the latency
    in healthcare internet-of-things in fog computing environment. PLoS ONE 14(11):e0224934
    Article   Google Scholar   Fernando N, Loke SW, Rahayu W (2013) Mobile cloud computing:
    a survey. Futur generations computer systems 29(1):84–106 Article   Google Scholar   Conti
    M, Giordano S, May M, Passarella A (2010) From opportunistic networks to opportunistic
    computing. IEEE Commun Mag 48(9):126–139 Article   Google Scholar   Pitkänen M,
    Kärkkäinen T, Ott J, Conti M, Passarella A, Giordano S, Puccinelli D, Legendre
    F, Trifunovic S, Hummel K, May M, Hegde N, Spyropoulos T (2012) SCAMPI: service
    platform for social aware mobile and pervasive computing. SIGCOMM Comput Commun
    Rev 42(4):503–508 Article   Google Scholar   Costa PB, Rego PAL, Rocha LS, Trinta
    FAM, de Souza JN (2015) MpOS: a multiplatform offloading system. In: Proceedings
    of the 30th annual ACM symposium on applied computing, New York, pp 577–584 Mnih
    V, Kavukcuoglu K, Silver D, Rusu AA, Veness J, Bellemare MG, Graves A, Riedmiller
    M, Fidjeland AK, Ostrovski G, Petersen S, Beattie C, Sadik A, Antonoglou I, King
    H, Kumaran D, Wierstra D, Legg S, Hassabis D (2015) Human-level control through
    deep reinforcement learning. Nature 518(7540):529–533 Article   Google Scholar   Ehringer
    D (2010) The Dalvik Virtual Machine Architecture. Technical Report. http://show.docjava.com/posterous/file/2012/12/10222640-The_Dalvik_Virtual_Machine.pdf.
    http://show.docjava.com/posterous/file/2012/12/10222640-The_Dalvik_. Accessed
    1 Jul 2015 Java SE Hot Spot at a Glance (2014) http://www.oracle.com/technetwork/java/javase/tech/index-jsp-136373.html
    Puiu D, Barnaghi P, Tönjes R, Kümper D, Ali MI, Mileo A, Xavier Parreira J, Fischer
    M, Kolozali S, Farajidavar N, Gao F, Iggena T, Pham T, Nechifor C, Puschmann D,
    Fernandes J (2016) CityPulse: large scale data analytics framework for smart cities.
    IEEE Access 4:1086–1108 Article   Google Scholar   C. of Chicago, City of chicago
    open data (2018) Tech. rep. https://data.cityofchicago.org/. Accessed 26 Jun 2018
    Oliner AJ, Iyer AP, Stoica I, Lagerspetz E, Tarkoma S (2013) Carat. In: Proceedings
    of the 11th ACM conference on embedded networked sensor systems—SenSys ’13. https://doi.org/10.1145/2517351.2517354
    Sonntag S, Manner J, Schulte L (2013) Netradar—Measuring the wireless world. 2013
    11th international symposium and workshops on modeling and optimization in mobile.
    Ad Hoc Wirel Netw 13:29–34 Google Scholar   Gent IP, Jefferson C, Nightingale
    P (2017) Complexity of n-Queens Completion. J Artif Intell Res 59:815–848 Article   MathSciNet   MATH   Google
    Scholar   Qualcomm (2015) Trepn power profiler. https://developer.qualcomm.com/software/trepn-power-profiler
    Viola P, Jones M (2001) Rapid object detection using a boosted cascade of simple
    features. In; Proceedings of the 2001 IEEE computer society conference on computer
    vision and pattern recognition, CVPR, pp 1–1 Rego PAL, Costa PB, Coutinho EF,
    Rocha LS, Trinta FAM, de Souza JN (2017) Performing computation offloading on
    multiple platforms. Comput Commun 105:1–13 Article   Google Scholar   IPerf (2017)
    The ultimate speed test tool for TCP, UDP and SCT. https://iperf.fr/ CpuRun (2017)
    Tool to consume CPU resource by constant usage rate. https://play.google.com/store/apps/details?id=jp.gr.java_conf.toytech.cpurun&hl=pt_BR
    CpuBurn (2017) The ultimate stability testing tool for overclockers. https://patrickmn.com/projects/cpuburn/
    Andras Janosi WS, Matthias P, Robert D (2018) UCI Machine Learning Repository.
    https://archive.ics.uci.edu/ml/datasets/heart+Disease. Accessed 25 Feb 2018 Gupta
    H, Dastjerdi AV, Ghosh SK, Buyya R (2017) iFogSim: a toolkit for modeling and
    simulation of resource management techniques in the Internet of Things, Edge and
    Fog computing environments. Softw Pract Exp 47(9):1275–1296 Article   Google Scholar   Bajaj
    K, Sharma B, Singh R (2020) Integration of WSN with IoT applications: a vision,
    architecture, and future challenges. In: Integration of WSN and IoT for Smart
    Cities, Springer, Cham, pp 79–102 Anisetti M, Ardagna CA, Damiani E, Gaudenzi
    F, Jeon G (2020) Cost-effective deployment of certified cloud composite services.
    J Parall Distrib Comput 135:203–218 Article   Google Scholar   Download references
    Acknowledgements This work has been carried out in wireless sensor network research
    facility in Computer Science and Engineering department of Chitkara University,
    India. This research facility has been funded from the in-house grant of Chitkara
    University. Author information Authors and Affiliations Chitkara University School
    of Engineering and Technology, Chitkara University, Himachal Pradesh, India Karan
    Bajaj & Bhisham Sharma Department of Computer Science and Engineering, Thapar
    Institute of Engineering and Technology, Patiala, Punjab, India Raman Singh Corresponding
    author Correspondence to Bhisham Sharma. Ethics declarations Conflict of interest
    On behalf of all authors, the corresponding author states that there is no conflict
    of interest. Additional information Publisher''s Note Springer Nature remains
    neutral with regard to jurisdictional claims in published maps and institutional
    affiliations. Rights and permissions Open Access This article is licensed under
    a Creative Commons Attribution 4.0 International License, which permits use, sharing,
    adaptation, distribution and reproduction in any medium or format, as long as
    you give appropriate credit to the original author(s) and the source, provide
    a link to the Creative Commons licence, and indicate if changes were made. The
    images or other third party material in this article are included in the article''s
    Creative Commons licence, unless indicated otherwise in a credit line to the material.
    If material is not included in the article''s Creative Commons licence and your
    intended use is not permitted by statutory regulation or exceeds the permitted
    use, you will need to obtain permission directly from the copyright holder. To
    view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.
    Reprints and permissions About this article Cite this article Bajaj, K., Sharma,
    B. & Singh, R. Implementation analysis of IoT-based offloading frameworks on cloud/edge
    computing for sensor generated big data. Complex Intell. Syst. 8, 3641–3658 (2022).
    https://doi.org/10.1007/s40747-021-00434-6 Download citation Received 25 March
    2021 Accepted 09 June 2021 Published 19 June 2021 Issue Date October 2022 DOI
    https://doi.org/10.1007/s40747-021-00434-6 Share this article Anyone you share
    the following link with will be able to read this content: Get shareable link
    Provided by the Springer Nature SharedIt content-sharing initiative Keywords Context-awareness
    Frameworks Internet of Things Offloading IoT applications Edge/fog computing Use
    our pre-submission checklist Avoid common mistakes on your manuscript. Associated
    Content Part of a collection: Intelligent Mobile Edge Computing for IoT Big Data
    Sections Figures References Abstract Introduction Related work Materials and methods
    Comparative analysis and discussion Future research challenges Conclusion References
    Acknowledgements Author information Ethics declarations Additional information
    Rights and permissions About this article Advertisement Discover content Journals
    A-Z Books A-Z Publish with us Publish your research Open access publishing Products
    and services Our products Librarians Societies Partners and advertisers Our imprints
    Springer Nature Portfolio BMC Palgrave Macmillan Apress Your privacy choices/Manage
    cookies Your US state privacy rights Accessibility statement Terms and conditions
    Privacy policy Help and support 129.93.161.219 Big Ten Academic Alliance (BTAA)
    (3000133814) - University of Nebraska-Lincoln (3000134173) © 2024 Springer Nature"'
  inline_citation: '>'
  journal: Complex and Intelligent Systems
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Implementation analysis of IoT-based offloading frameworks on cloud/edge
    computing for sensor generated big data
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Jamil B.
  - Ijaz H.
  - Shojafar M.
  - Munir K.
  - Buyya R.
  citation_count: '54'
  description: The Internet of Everything paradigm is being rapidly adopted in developing
    applications for different domains like smart agriculture, smart city, big data
    streaming, and so on. These IoE applications are leveraging cloud computing resources
    for execution. Fog computing, which emerged as an extension of cloud computing,
    supports mobility, heterogeneity, geographical distribution, context awareness,
    and services such as storage, processing, networking, and analytics on nearby
    fog nodes. The resource-limited, heterogeneous, dynamic, and uncertain fog environment
    makes task scheduling a great challenge that needs to be investigated. The article
    is motivated by this consideration and presents a systematic, comprehensive, and
    detailed comparative study by discussing the merits and demerits of different
    scheduling algorithms, focused optimization metrics, and evaluation tools in the
    fog computing and IoE environment. The goal of this survey article is fivefold.
    First, we review the fog computing and IoE paradigms. Second, we delineate the
    optimization metric engaged with fog computing and IoE environment. Third, we
    review, classify, and compare existing scheduling algorithms dealing with fog
    computing and IoE environment paradigms by leveraging some examples. Fourth, we
    rationalize the scheduling algorithms and point out the lesson learned from the
    survey. Fifth, we discuss the open issues and future research directions to improve
    scheduling in fog computing and the IoE environment.
  doi: 10.1145/3513002
  full_citation: '>'
  full_text: '>

    "This website uses cookies We occasionally run membership recruitment campaigns
    on social media channels and use cookies to track post-clicks. We also share information
    about your use of our site with our social media, advertising and analytics partners
    who may combine it with other information that you’ve provided to them or that
    they’ve collected from your use of their services. Use the check boxes below to
    choose the types of cookies you consent to have stored on your device. Use necessary
    cookies only Allow selected cookies Allow all cookies Necessary Preferences Statistics
    Marketing Show details       skip to main content University of Nebraska Lincoln
    Browse About Sign in Register Journals Magazines Proceedings Books SIGs Conferences
    People Search ACM Digital Library Advanced Search Journal Home Just Accepted Latest
    Issue Archive Authors Editors Reviewers About Contact Us HomeACM JournalsACM Computing
    SurveysVol. 54, No. 11sResource Allocation and Task Scheduling in Fog Computing
    and Internet of Everything Environments: A Taxonomy, Review, and Future Directions
    SURVEY SHARE ON Resource Allocation and Task Scheduling in Fog Computing and Internet
    of Everything Environments: A Taxonomy, Review, and Future Directions Authors:
    Bushra Jamil , Humaira Ijaz , Mohammad Shojafar , + 2 Authors Info & Claims ACM
    Computing SurveysVolume 54Issue 11sArticle No.: 233pp 1–38https://doi.org/10.1145/3513002
    Published:09 September 2022Publication History 20 citation 2,523 Downloads View
    all FormatsPDF ACM Computing Surveys Volume 54, Issue 11s Previous Next Abstract
    1 INTRODUCTION 2 OPTIMIZATION METRICS 3 CLASSIFICATION OF SCHEDULING METHODS 4
    ANALYTICAL DISCUSSION 5 OPEN ISSUES AND FUTURE DIRECTIONS 6 CONCLUSIONS AND FINAL
    REMARK REFERENCES Cited By Index Terms Recommendations Comments Skip Abstract
    Section Abstract The Internet of Everything paradigm is being rapidly adopted
    in developing applications for different domains like smart agriculture, smart
    city, big data streaming, and so on. These IoE applications are leveraging cloud
    computing resources for execution. Fog computing, which emerged as an extension
    of cloud computing, supports mobility, heterogeneity, geographical distribution,
    context awareness, and services such as storage, processing, networking, and analytics
    on nearby fog nodes. The resource-limited, heterogeneous, dynamic, and uncertain
    fog environment makes task scheduling a great challenge that needs to be investigated.
    The article is motivated by this consideration and presents a systematic, comprehensive,
    and detailed comparative study by discussing the merits and demerits of different
    scheduling algorithms, focused optimization metrics, and evaluation tools in the
    fog computing and IoE environment. The goal of this survey article is fivefold.
    First, we review the fog computing and IoE paradigms. Second, we delineate the
    optimization metric engaged with fog computing and IoE environment. Third, we
    review, classify, and compare existing scheduling algorithms dealing with fog
    computing and IoE environment paradigms by leveraging some examples. Fourth, we
    rationalize the scheduling algorithms and point out the lesson learned from the
    survey. Fifth, we discuss the open issues and future research directions to improve
    scheduling in fog computing and the IoE environment. Skip 1INTRODUCTION Section
    1 INTRODUCTION The Internet of Everything (IoE) paradigm is based on the convergence
    of the digital and physical world to make this world smarter with intelligence,
    cognition, and connectivity. IoE is the system that interconnects billions of
    heterogeneous physical devices, computing elements, objects, animals, and humans
    that can set up, share, and self-organize their limited resources to achieve a
    system-wide goal [1]. The main objective of IoE networks is to enhance the performance
    of underlying Internet of Things (IoT) physical infrastructures by providing services
    to humans [2]. The IoT paradigm aims to make things smart without human intervention
    by incorporating in them the ability to capture, send data over the network, and
    respond according to given commands [3]. Any entity such as sensors, actuators,
    and Radio Frequency Identification (RFID) devices with an Internet Protocol (IP)
    address, along with the ability to capture and transmit data over the network,
    can be a thing [4]. These things are the only pillar of the IoT, so communication
    is always between these things and machines through various protocols. The terms
    IoT and IoE are interchangeably used. These IoE devices are resource- and energy-constrained
    and cannot efficiently process data generated by various IoE applications within
    a fixed time frame. Therefore, to host these IoE applications, cloud computing
    has been the most commonly used distributed computing paradigm in recent years
    due to its capabilities such as unlimited storage and processing power, service-oriented
    architecture, high performance, reliability, and on-demand access to the shared
    pool of configurable resources [5, 6]. Currently, a centralized Cloud-centric
    Internet of Things (CIoT) architecture is used to process the data generated by
    these IoE devices-based IoE applications [7]. The recent advancements in IoT and
    computing technologies, use of ubiquitous and pervasive computing for provision
    of computing services all the time and at any location, and other enabling communication
    technologies such as 4G, 5G, and Wireless Sensor Network (WSN), have resulted
    in a rapidly increasing number of IoE devices and applications. According to an
    estimate, active IoE devices will reach up to 1.2 trillion by 2030 [8]. These
    IoE devices generate an enormous amount of different-nature data used by different
    applications. The cloud data centers alone will be unable to efficiently process
    this vast amount of data generated by these devices. Furthermore, the cloud data
    centers are multi-hop away from the end-user. Therefore, transferring data from
    end-user to geographically distant cloud results in long latency and network congestion
    that are not acceptable for time-sensitive applications such as smart healthcare,
    connected vehicles, remote patient monitoring, and so on [9]. Therefore, in the
    near future, the traditional centralized CIoT architecture will not be able to
    address these challenges of bandwidth consumption, long delay, network congestion,
    and security. To handle these issues, several approaches such as mist computing,
    mobile cloud computing, multi-access edge computing, volunteer computing, cloudlet
    computing, and fog computing [10] are presented. Among these approaches, fog computing,
    introduced by Cisco, has gained the most attention due to its greater support
    for application processing, mobility, low-energy consumption, heterogeneity, geographical
    distribution, thus achieving significant improvement of Quality of Service (QoS)
    expectations [11]. 1.1 Fog Computing Paradigm and Benefits Fog computing is a
    novel decentralized computing paradigm that complements cloud computing by using
    an additional layer of fog devices between the cloud data centers and the end-users
    to provide computing, storage, network, analytics, and data management in a closer
    vicinity of the edge at various fog nodes and IoE devices [12]. This has led to
    the use of a decentralized Fog-IoT Framework (FIoT) for the IoT model that supports
    real-time services, mobility, geographic distribution, minimizes service latency,
    energy consumption, cost, and network traffic. In Figure 1, we present the multi-layer,
    bi-directional, and decentralized architecture of FIoT that consists of three
    tiers. Fig. 1. Fig. 1. Fog computing architecture. F = Fog Node; C = Cloud; IoE2F
    = IoE-to-Fog; IoE2IoE = IoE-to-IoE; F2F = Fog-to-Fog; F2C = Fog to Cloud. Cloud
    Layer: This layer is the topmost layer that includes a remote centralized cloud
    responsible for performing long-term analysis and decision-making. Fog Layer:
    This layer is the intermediate layer that consists of three sub-layers in which
    the fog nodes are deployed as given below: (1) Inner Edge: The inner edge layer
    consists of WAN and Metropolitan Area Network (MAN) data centers, Internet Service
    Providers (ISPs), and so on, that help in connecting local networks to global
    networks. (2) Middle Edge: The middle layer consists of Local Area Networks (LANS)
    and cellular network. (3) Outer Edge: The outer edge includes different types
    of devices, e.g., hubs, switches, Raspberry Pis, nano-servers, mobile phones,
    radio towers. [13]. These devices communicate with upper-level fog devices via
    Fog to Fog (F2F) link using ZigBee or Z-wave [14]. These outer edge devices are
    arranged in two sub-layers as mentioned below. – Integrated Devices: These devices
    have adequate memory, storage, and processing power, along with networking capabilities,
    for example, CPU-based smartphones and tablets. – IP Gateway Devices: IP Gateways
    are used as intermediate devices between the end and the middle edge layered devices,
    e.g., Hubs or IP gateway devices. End Devices Layer: This layer consists of heterogeneous
    and resource-constrained devices, such as sensors, actuators, and controllers
    that can communicate through IoE2IoE connection using short-range waves such as
    RFID, Bluetooth, and Radio Frequency [2]. Sensors receive data from the physical
    environment, convert it into signals, and then send those signals to nearby fog
    nodes for further processing. Once processed, feedback is sent back to actuators
    that take actions accordingly. In contrast to the cloud and inner edge-fog nodes,
    the devices in the outer edge and end device layer are resource and energy-constrained
    and heterogeneous (having various hardware specifications, communication protocols,
    and architectures) [15]. These heterogeneous resource-constrained fog nodes and
    highly unpredictable nature of the fog computing environment make resource management
    a challenging issue. The challenges includes service placement, resource discovery,
    service migration, load balancing, task scheduling, resource allocation, energy
    efficiency, and QoS [16]. Among these resource management issues, resource and
    task scheduling challenges are significant due to their effect on enhancing the
    overall system’s performance. 1.2 Scheduling in Fog Computing The IoE applications
    generate a large number of variable-length tasks that often require priority-based
    execution. But, end devices of the network are heterogeneous and resource-constrained.
    These tasks have to compete for constrained resources of these heterogeneous devices
    in a heterogeneous environment [17]. Therefore, to execute these jobs according
    to their resource demands, appropriate nodes having sufficient resources should
    be allocated. Furthermore, an efficient and convenient ordering of these tasks
    on heterogeneous fog nodes with available resources can enhance efficiency and
    accuracy of the task execution process and maximization of resource utilization
    such as processor, memory, bandwidth, and minimizing delay, cost, and energy consumption.
    In fog computing, three major scheduling issues are resource allocation, task
    scheduling, and workflow scheduling [18] as described below: Resource Allocation:
    Resource allocation aims at the optimal allocation of a set of tasks {T1, T2,
    ..., Tn} with different QoS requirements to a set of densely distributed heterogeneous
    fog nodes {F1, F2, ..., Fm} to yield faster response, improved resource utilization,
    decreased energy consumption, makespan, and cost [19]. Task scheduling: The fog
    devices receive a vast number of heterogeneous tasks for processing from different
    fog applications (latency-sensitive or delay-tolerant) that are dynamic, with
    varying lengths, and often require priority-based execution. These tasks wait
    in a ready queue for execution on resource-constrained fog nodes. Therefore, an
    efficient, fast, and convenient way of sequencing these tasks according to their
    criticality to maximize resource usage and minimize delay, cost, and energy is
    of great importance. Workflow scheduling: The IoE devices generate jobs that can
    be decomposed into a series of tasks. These tasks can be either independent or
    dependent [20]. The independent tasks do not affect the other tasks and they are
    not affected by them either. Therefore, they are independent of execution order.
    However, the dependent tasks can execute only after the completion of their parent
    tasks. Dependent task scheduling, also known as workflow scheduling, is described
    by the Directed Acyclic Graph (DAG) or workflows. The objective of workflow scheduling
    is to distribute tasks onto heterogeneous fog nodes and decide an execution sequence
    of all tasks in a workflow according to their dependencies along with minimization
    of their makespan. Workflow scheduling in a complex-distributed environment is
    an NP-complete problem and is extensively studied by researchers [21]. 1.3 Challenges
    in Resource Allocation, Task Scheduling, and Workflow Scheduling The challenges
    faced by resource allocation, task scheduling, and workflow techniques in fog
    computing environment are discussed below: Outer-edge Fog Nodes: In contrast to
    the cloud and inner-edge fog nodes, the devices in the outer edge and end-device
    layer have [15]: – Heterogeneity: various hardware specifications, communication
    protocols, and architectures – Resource-constraint: limited processing capability
    and storage – Energy-constraint: limited power – Distributed nature: dense geo-spatial
    distributions – Dynamic workloads: different workloads Optimal allocation of a
    set of tasks to a large number of geographically distributed fog nodes is a challenging
    issue. Heterogeneous Fog Applications: Fog applications vary in nature, as some
    applications are real-time while some others are delay-tolerant. The real-time
    applications have low latency requirements, therefore, they should be executed
    on a priority basis. Allocating a large number of heterogeneous tasks to an appropriate
    fog node, from a set of heterogeneous and resource-constrained fog nodes, makes
    resource allocation an NP-hard problem [22]. Stochastic Environment: The fog-cloud
    environment is stochastic in many ways. For example, a task’s arrival rate, duration,
    as well as computational requirements randomly vary and are not known in advance.
    Therefore, allocating the limited resources of fog nodes to these IoE-generated
    workloads according to their computational needs is another challenge. Mobility:
    Mobility is an essential part of many fog applications for improving user-experience.
    Mobility causes several challenges such as handling user’s preferences, time and
    distance constraints [23]. Therefore, allocation and scheduling in such a dynamic
    environment becomes even more challenging to accomplish user requests according
    to their preferences and QoS requirements for real-time applications [24]. The
    resource-constraint, the heterogeneity, unpredictable arrival rate, and vast number
    of tasks to be completed make resource and task scheduling a complex issue. To
    overcome this problem, many research efforts have been done to develop efficient
    scheduling techniques to optimize resource utilization and various performance
    metrics. However, there is need of a deep and up-to-date review of proposed research
    methods to find the recent advances in scheduling in fog environment. 1.4 Comparison
    with Existing Surveys Hosseinioun et al. [25] study the related task scheduling
    works in fog computing between 2015 to 2018. They classify the algorithms as static
    and dynamic. The static algorithms are further classified as heuristic and meta-heuristic
    algorithms, while real-time scheduling algorithms are discussed as dynamic algorithms.
    The scheduling algorithms are compared with one another based on certain QoS factors.
    They also stress the strengths, weaknesses, and simulation environment for each
    study. However, the survey does not include the recent studies and the information
    related to the application scheduling environment. Ghobaei-Arani et al. [16] discuss
    different resource management techniques in fog computing. They compare these
    approaches based on optimization metrics, case studies, used techniques, and evaluation
    tools, along with their merits and demerits. The survey partially reviews the
    scheduling approaches and does not include the recent studies as well. Naha et
    al. [26] present an overview of fog computing, various existing fog computing
    architectures, and their components. They also discuss fault tolerance, resource
    allocation, and scheduling techniques for fog computing. The paper only reviews
    a few resource scheduling papers in a subsection. Mukherjee et al. [27] present
    a comprehensive survey on fog computing architectures and applications along with
    several critical issues and future research directions. The survey does not discuss
    resource and task scheduling papers. In another survey, Yang and Rahmani [28]
    review the task scheduling mechanisms in fog computing. The authors categorize
    the scheduling algorithms as heuristic and meta-heuristic mechanisms. For each
    algorithm, they present the main features and the environment. The algorithms
    are compared with one another based on the performance and resource utilization
    metrics. The simulation environment used in different related studies is not discussed.
    The authors partially review the related literature and many recent studies are
    also not included. Alizadeh et al. [29] point out a comprehensive survey of different
    task scheduling algorithms and their strengths and weaknesses from 2015 to 2020.
    They classify the task scheduling algorithms as static, dynamic, heuristic, and
    hybrid algorithms. They also discuss the scheduling type, application environment,
    and the simulator used in each study. The selected literature lacks an appropriate
    categorization and review of many intelligent learning-based techniques. In a
    recent survey, Islam et al. [30] discuss the context-aware scheduling techniques
    in fog computing. They compare and analyze the scheduling approaches based on
    context-aware parameters, optimization metrics, case studies, and simulation tools,
    along with their merits and demerits. The survey only includes the scheduling
    papers addressing the task scheduling issue. Matrouk and Alatoun present a survey
    on scheduling algorithms in fog computing [31] in which they discuss the algorithms
    for resource allocation and scheduling issues. They classify the related literature
    according to a focused scheduling problem such as task scheduling, resource scheduling,
    resource allocation, job scheduling, and workflow scheduling. For every related
    study, the authors discuss its merits and demerits. They also compare the proposed
    algorithms according to specific metrics and evaluation tools. The work lacks
    in analysis and study of the fog computing and IoE application environment and
    comprehensive comparison of application metrics, which is addressed in this survey.
    Table 1 summarizes the advantages and limitations of existing surveys. Table 1.
    Reference Objectives Limitations [25] Review of task scheduling approaches in
    fog computing Literature survey from 2015–2018 [16] Review of resource management
    approaches in fog computing Partially reviews the scheduling approaches [26] Review
    of fog computing architectures along with fault tolerance, resource allocation,
    and scheduling techniques Reviews only a few resource scheduling papers Show More
    Table 1. Comparison of Surveys on Scheduling 1.5 Motivation and Goal of the Article
    Although the previous surveys provide the base for understanding fog computing
    architectures and some scheduling approaches, they only review the mono or bi-objective
    optimization-oriented scheduling techniques that need prior details. The resource-constrained
    devices, heterogeneity of devices-applications-data, and dynamic and real-time
    fog applications make resource management in the Fog environment an NP-complete
    problem. As explained in the previous subsections, efficient scheduling algorithms
    can significantly improve system performance by optimizing resource utilization
    and other performance metrics. Therefore, the researchers focus on designing dynamic,
    intelligent, efficient, and multi-objective task scheduling algorithms that can
    jointly optimize performance and resource utilization metrics along with task
    deadlines constraint. These techniques may become more successful because of their
    ability to handle the uncertain environment, self-learning ability, computational
    efficiency, and adaptive nature [32]. There is minimal discourse on how these
    intelligent, self-learning, and dynamic task scheduling techniques such as Reinforcement
    Learning (RL), Deep Reinforcement Learning (DRL), and machine learning-based techniques
    can be used to optimize resource management. There is a need to provide a systematic
    literature review of these advanced along with traditional scheduling techniques.
    Furthermore, there is a need to provide a basic understanding of Fog computing
    and IoE paradigms, their background, characteristics, architectures, and open
    challenges, especially various scheduling techniques used in fog computing. To
    bridge these gaps, we provide a comprehensive survey that explores all these avenues
    together. This survey provides a foundation of fog computing, IoE paradigms, various
    scheduling techniques, along with a thorough review of most of the methods presented
    so far for scheduling and resource allocation in fog computing with a focus on
    learning-based dynamic algorithms. 1.6 Contributions The contributions of our
    work are five-fold, as described below: Review of fog computing and IoE paradigms
    Detailed discussion on the basics of scheduling and types of scheduling, i.e.,
    task scheduling, workflow scheduling, resource allocation, and different optimization
    metrics used for evaluation of these algorithms Classification and comprehensive
    review of existing scheduling algorithms, particularly focusing on intelligent
    dynamic scheduling techniques based on machine learning, fuzzy logic, reinforcement
    learning, and deep reinforcement learning, describing their strengths and weaknesses
    Presentation of various simulation environments and tools used in different studies
    Identification of the research gaps and challenges for task scheduling and resource
    allocation in fog computing for future research work in this field. 1.7 Article
    Organization The rest of the article is organized as follows: In Section 2, we
    present the optimization metrics for scheduling in fog environment. Section 3
    discusses the classification of the task scheduling, resource allocation, and
    workflow scheduling algorithms. Section 4 presents the discussion about the surveyed
    techniques. In Section 5, we describe the issues and challenges; we conclude in
    Section 6. Figure 2 shows the organization of the article. Fig. 2. Fig. 2. Organization
    of the article. Skip 2OPTIMIZATION METRICS Section 2 OPTIMIZATION METRICS The
    objectives of resource allocation, task scheduling, and workflow scheduling is
    to optimize the job execution process for maximum resource usage of fog nodes.
    For this purpose, in scheduling different optimization functions such as mono,
    bi-objective, or multi-objective functions are defined to optimize resource-utilization
    and performance metrics such as waiting time, latency, makespan, throughput, and
    percentage of missing deadlines of tasks. The aim of multi-objective optimization
    is to provide an optimal solution for more than one objectives that can be contradictory.
    Figure 3 shows the optimization metrics discussed in the following subsections.
    Fig. 3. Fig. 3. Optimization metrics. In the following subsections, we present
    an overview of some metrics optimized in different task scheduling algorithms
    in cloud-fog settings. 2.1 Performance Metrics Performance metrics help in measuring
    the quality and efficiency of the task scheduling, workflow scheduling, and allocation
    process. In this subsection, we discuss the commonly used performance metrics
    optimized in different algorithms by different scheduling techniques. Latency:
    Latency is one of the most important metrics to measure the performance of any
    task scheduling algorithm. Latency is also known as delay or response time. The
    overall latency is the summation of transmission latency and computational latency
    [33]. The transmission latency is the communication delay to transfer data between
    resources, and the computational latency is the time taken for the task to be
    processed. The computational latency of any task is calculated using Equation
    (1) given below: Latenc y i =T L i +C L i , where Latenc y i is the latency, T
    L i is the transmission latency, and C L i is the computational latency of the
    task i. Execution Time: The time taken by a system to execute the task is known
    as execution time. The waiting time for I/O and other executing tasks is not included
    in CPU or execution time [34]. The execution time is computed using Equation (2)
    as follows: ExeTim e i =F T i +S T i , where ExeTim e i is overall execution time,
    F T i is finish time, and S T i is the start execution time of the task i. Makespan:
    Makespan is a significant objective of task scheduling that indicates the overall
    time required to finish a complete workflow [35]. The minimization of makespan
    results in a fast execution of the applications. Makespan can be computed using
    Equation (3) as follows: Makespan=C T l −S T f , where C T l denotes the time
    when last task is completed, and S T f denotes the starting time of the first
    task. Throughput: Throughput of a system is the number of tasks completed per
    unit time [36]. Equation (4) can be used to compute throughput as follows: Throughput=
    Number of tasks Makespan . Deadline: Deadline is the time duration from task submission
    to the time till it must be completed. In real-time applications, the completion
    of each tasks within specified deadline is important. Especially, for the hard
    real-time applications like air traffic control, missing a task deadline can result
    in a disaster. 2.2 Resource Usage One significant objective of task scheduling
    is to increase the resource usage of fog nodes including processor, memory, storage,
    and network bandwidth. As the end-devices and edge-devices, such as routers, gateways,
    Raspberry Pi, and so on, offer only limited computing, memory capacity, bandwidth,
    and battery life, a good resource utilization strategy is necessary. Poor resource
    utilization may result in poor performance that can lead to application failure.
    A task scheduling algorithm should efficiently allocate the following resources:
    Processor: is the most important resource and should be carefully allocated by
    a task scheduler. An overloaded CPU can result in long latency of tasks that are
    not acceptable in the case of latency-sensitive applications like healthcare.
    Memory: allocation is also critical, as over-booked memory can lead to application
    failure. Network Bandwidth: is another significant metric. As the number of IoE
    devices grows, so does network traffic, resulting in congestion. This congestion
    badly affects the performance of the fog applications. Fog computing decreases
    the network usage by offloading workload on nearby fog devices that can be computed
    through Equation (5) as follows: Network Usage= ∑ K k=1 L×T_Nw_Sz. Here, K denotes
    total number of tuples, L denotes the delay, and T_Nw_Sz denotes the network size
    of tuple. 2.3 Energy Consumption Energy is a necessary and scarce resource. Energy
    consumption is the amount of resource-energy utilized for producing output [37].
    All devices such as proxy, sensor, gateway, cloud, and so on, consume energy even
    in an idle state, and this consumption increases when the device is used. 2.4
    Financial Costs Financial costs include processing and communication costs like
    the cost of utilizing cloud or fog resources. The network usage for transferring
    data and energy consumption of devices also impacts the overall cost. 2.5 Quality
    of Service All the above attributes are quantifiable. However, some other metrics
    are non-quantifiable but they can affect the user experience; for example, reliability,
    security, user preferences, and Quality of Experience (QoE) [38]. Through optimal
    resource allocation, more users can be simultaneously served, resulting in a better
    QoS. Skip 3CLASSIFICATION OF SCHEDULING METHODS Section 3 CLASSIFICATION OF SCHEDULING
    METHODS In this section, we present a survey of scheduling algorithms considering
    the different optimization metrics in a fog computing environment. The majority
    of these algorithms focus on the allocation of tasks on geographically distributed
    fog devices. We categorize the resource allocation and task scheduling algorithms
    as traditional, linear integer programming, heuristic, hyper-heuristic, hybrid
    heuristic, meta-heuristic, fuzzy based, reinforcement learning, and deep reinforcement
    learning-based, as shown in Figure 4. Fig. 4. Fig. 4. A taxonomy of resource allocation,
    task scheduling, and workflow scheduling algorithms in fog computing environment.
    According to the taxonomy of scheduling algorithms presented in Figure 4, the
    first type of algorithms are traditional algorithms that are discussed in Section
    3.1. ILP and MILP-based scheduling approaches are also used to solve optimization
    problems that are discussed in Section 3.2. Heuristic algorithms are the third
    type of algorithms often used for solving optimization problems. Section 3.3 presents
    the survey of the existing heuristic algorithms. Hyper-heuristic algorithms have
    gained the attention of researchers to solve problems of different domains. Section
    3.4 describes the hyper-heuristic algorithms in detail. Section 3.5 explains the
    hybrid heuristic algorithms that are developed by combining different heuristic
    algorithms to yield a faster solution in a reasonable time. Meta-heuristic algorithms
    are found efficient for solving resource allocation in a distributed environment
    and they are discussed in Section 3.6. For handling the uncertain environment
    of fog computing, some researchers apply fuzzy methods that are presented in Section
    3.7. For dynamic and uncertain fog computing environment, some researchers have
    successfully applied Reinforcement Learning algorithms to solve scheduling problems.
    Section 3.8 discusses RL-based algorithms. To design adaptive resource allocation
    algorithms for complex and unpredictable fog environments, some researchers apply
    Deep Reinforcement Learning (DRL)-based algorithms. DRL algorithms can also be
    categorized as value-iteration and policy-iteration-based algorithms, explained
    in Section 3.9. The following subsections describe each of the scheduling categories
    in more detail, as shown in Figure 4. 3.1 Traditional In this subsection, we first
    explain the traditional scheduling algorithms, their merits and demerits. Then,
    we present a review and comparison of the well-known traditional algorithms for
    task scheduling in fog computing. Traditional algorithms are static algorithms
    in which all the information about tasks and fog resources is known in advance
    for a scheduling decision. These algorithms are simple and easy to understand
    and implement. First Come First Served (FCFS), Min-Max, Min-Min, Minimum Completion
    Time (MCT), and Min-Max are some well-known traditional task scheduling algorithms.
    FCFS and Round Robin algorithms are used for single machine, while Min-Max and
    Min-Min algorithms are used for multiple machines. First-Come-First-Served (FCFS):
    In FCFS, the task execution order depends upon their arrival time [39]. When a
    task is received, it is placed at the tail of the task queue and then the scheduler
    executes them according to their entry order. Round Robin (RR): In this scheduling,
    tasks are served in FCFS order but, each task is assigned a small time interval
    of processor that is called timeslot or time quantum [40]. If a task completes
    its CPU-burst before the quantum expires, then it is preempted and the processor
    is assigned to the succeeding task in the task queue. However, if a task does
    not complete its burst, then it is moved at the tail of the task queue. Min–Min
    algorithm: This algorithm selects and executes the smallest task on available
    machines. Therefore, it results in long delays for large tasks [41]. The algorithm
    then assigns a resource to the task that can give minimum completion time. Max–Min
    algorithm: This algorithm selects and executes large tasks on available machines
    first, so small jobs may suffer from starvation. Minimum Completion Time algorithm:
    Minimum Completion Time algorithm (MCT) algorithm selects and executes a task
    that has earliest completion time [42]. Priority Scheduling Algorithm: In priority
    scheduling, each task is assigned a priority and then executed according to its
    priority number [43]. All tasks with equal priority number are executed in an
    FCFS manner. For example, Shortest Job First (SJF) algorithm prioritizes the tasks
    according to their CPU burst. These static algorithms are simple and easy to implement.
    Below is survey of the well-known traditional algorithms of task scheduling on
    fog nodes. Task Scheduling: Harshit Gupta et al. use FCFS scheduling algorithm
    for task scheduling on two different types of applications using iFogSim [44].
    iFogSim is a simulator that executes at the top of CloudSim and helps in computing
    application latency, energy consumption, and network usage. The authors compute
    these evaluation metrics for both applications. In case of non-availability of
    processing power, a task is sent to the scheduling queue. The authors prove that
    the edge-word placement of modules yields better results as compared to the cloud
    placement in terms of network use, delays, and consumed energy. Tejaswini et al.
    [45] propose a Prioritized Efficient Resource Algorithm (PERA) to decrease response
    time and cost in fog-cloud architecture. Upon task submission, the task priority
    is computed according to its deadline. Once the task is prioritized, it is sent
    to the fog layer for execution. The fog layer is composed of many micro data centers
    and fog devices that can communicate with one another. If none of the fog layer
    data centers is available to handle a task due to resource unavailability, then
    it is sent to the cloud. The algorithm is implemented using the CloudAnalyst simulator.
    Their performance results show that prioritized scheduling can minimize response
    time and cost, because the tasks are prioritized according to their delay-tolerant
    requirements. The limitation of their work is that they do not dynamically compute
    task priority and ignore important metrics such as energy consumption and network
    usage. In a study, Mtshali et al. present an application scheduling technique
    to investigate the most efficient task scheduling algorithm to minimize energy
    consumption, network usage, and average task execution latency for real-time applications
    [46]. They implement four task scheduling algorithms, FCFS, SJF, Round-Robin,
    and Genetic Programming (GP), using the iFogSim simulator. According to their
    analysis, FCFS’s performance is the best in minimization of latency and energy
    consumption than the performances of other algorithms. Alsmadi et al. propose
    a weighted round-robin (WRR) task scheduling algorithm for a smart city [47].
    The algorithm selects the optimal fog node for executing a pre-emptive task based
    on available computing capacity and residual energy. If the task cannot be executed
    on a fog node, then it is moved to other fog nodes or cloud. The spanning-tree
    protocol is used to collect and route the data in a fog network. For simulation,
    the authors use iFogSim and NS3 simulators. The authors compare their proposed
    algorithm with the conventional task scheduling algorithm considering the optimization
    of throughput and latency. Resource Allocation: Bittencourt et al. [48] apply
    three different scheduling algorithms, namely: FCFS, concurrent, and delay-priority
    for mobility-aware scheduling in fog environment to analyze both real-time and
    delay-tolerant applications. They take two case studies: one of delay-tolerant
    application and the other of a near real-time application. They use iFogSim for
    simulation and compute loop delay as well as network usage for different configurations
    to show that scheduling policies should be designed for appropriate handling of
    the mobility and latency requirements of the application. A weakness of the research
    is the high computational cost. A comparison of traditional scheduling techniques
    considering different optimization metrics, simulation tools used along with simulation
    environment, are presented in Table 2, where the tick marks indicate the focused
    criteria of the researchers and the crosses show the ignored criteria. Table 2.
    Technique Name Scheduling Type Latency Makespan Execution Time Network Usage Energy
    Cons. Cost QoS Environment Evaluation Tool Reference Traditional FCFS TS ✓ × ×
    ✓ ✓ × × Fog-Cloud iFogSim [44] Priority PERA TS ✓ × × × × ✓ × Fog-Cloud CloudAnalyst
    [45] Traditional WRR TS ✓ × × × × × × Fog-Cloud iFogSim, NS3 [47] Show More Table
    2. Comparison of Traditional Scheduling Algorithms = metrics focused in proposed
    technique; × = metrics ignored; TS = Task Scheduling; RS = Resource Scheduling;
    WS = Workflow Scheduling; Energy Cons. = Energy Consumed. As the traditional algorithms
    are static, these algorithms are better when workloads do not frequently vary.
    These algorithms are not suitable for the unpredictable fog environments with
    varying workloads. 3.2 Integer Linear Programming In this subsection, we present
    the review and comparison of different scheduling approaches based on Integer
    Linear Programming (ILP) and Mixed Linear Integer Programming (MILP) along with
    their focused metrics. ILP is a widely used mathematical technique where one or
    more of the decision variables are further constrained to take integer or binary
    values [49]. The objective function as well as the constraints must be linear.
    MILP is often used for solving optimization problems including both continuous
    and discrete variables as well as nonlinear functions in the objective function
    and/or the constraints [50]. The scheduling techniques used by researchers in
    their studies related to resource scheduling are discussed below. Resource Allocation:
    In Reference [51], the authors investigate the Fog Service Placement Problem (FSPP),
    that allocates fog nodes to IoT services considering Quality of Service (QoS)
    constraints such as deadlines. The service placement problem is formulated as
    a linear integer programming (ILP) problem. The objective of the study is maximization
    of utilization of the resource of fog nodes. The authors only consider one objective
    function and the evaluation data is not realistic. Farooq et al. [52] design two
    scheduling algorithms, namely, Min-CCV and Min-V, to jointly minimize computation,
    communication and violation cast delay for fog-cloud environment. They formulate
    resource allocation problem as a Mixed-Integer Nonlinear Programming (MINLP).
    After formulation, Min-CCV algorithm is used to minimize computation, communication,
    and violation cast, while Min-V is used to minimize deadline violation cost. The
    experimental study is done by changing number of tasks, fog and cloud nodes. Their
    experimental results show better deadline satisfaction task rates and minimized
    total cost than those of a genetic-based algorithm. The algorithm’s fundamental
    flaw is that as the number of devices grows, so does the amount of energy consumed,
    influencing the overall system cost. Considering the dynamic nature of the fog
    computing environment, Aburukba et al. in Reference [53] present a model for scheduling
    IoE service requests from end devices. To minimize service latency, they present
    the task allocation problem as an integer linear programming problem. They implement
    a customized genetic algorithm as a heuristic approach to get optimal scheduling
    solution in a reasonable computational time. They initialize the problem size
    with the received IoE requests and available resources. Then, the population is
    generated through several candidate solutions. The fitness of every chromosome
    is defined using the inverse of overall delay. Crossover and mutation are used
    to select individuals producing new population. The performance is analyzed and
    compared with three other scheduling techniques. The algorithm is shown to be
    effective in minimizing latency and cost. To minimize the cost of fog computing
    infrastructure for latency-sensitive IoT applications, Martinez et al. [54] present
    an optimal design and dimensioning scheme using MINLP. They use the MINLP model
    to find optimal fog infrastructure by minimizing infrastructure deployment costs.
    The authors define the maximum number of resources for each candidate fog node.
    As the design and dimensions are extendable, current fog nodes can be added when
    IoT data traffic increases. Santos et al. [55] use MILP to formulate the IoT service
    allocation problem over Low Power Wide Area Networks. The IoT applications are
    decomposed into a set of different micro-services that users can access. The data
    is collected through sensors and sent to Fog-cloud infrastructure through gateways.
    Then the micro-service instances should be allocated to available fog nodes under
    multiple constraints. The model includes multiple optimization objectives and
    different objectives are considered in each iteration of the model. Every iteration
    refines the previous solution by improving another objective function. To evaluate
    the proposed MINLP formulation, the authors choose various smart city use cases.
    Workflow Scheduling: Guevara and Fonseca propose two schedulers, CASSIA-INT and
    CASSIA-RR, for task allocation on heterogeneous resources in the fog-cloud environment
    [56]. CASSIA-INT is formulated as integer linear programming, while CASSIA-RR
    scheduler implements Randomized Rounding. The authors use QoS requirements of
    the applications to classify them and then assign a label. The scheduler uses
    workflows, labels, and resource availability for scheduling decisions. The objective
    of their scheduling strategy is to decrease the makespan and task’s execution
    time. The algorithms are implemented using Java language and tested for two different
    types of applications. The algorithm’s performance is compared with two traditional
    algorithms, and the results show that the presented algorithm effectively minimizes
    the makespan and execution time of a task. Table 3 presents a comparison of integer
    linear programming-based scheduling techniques based on different optimization
    metrics, scheduling type, environment, and evaluation tools. The tick marks show
    the intended criteria of the researchers while the crosses show the ignored metrics.
    Table 3. Type Name Scheduling Type Latency Makespan Cost QoS Environment Evaluation
    Tool Reference ILP FSPP RS ✓ × ✓ ✓ Fog-Cloud iFogSim [51] MILP Min-CCV, Min-V
    RS × × ✓ ✓ Fog-Cloud Matlab [52] ILP - RS ✓ × ✓ × Fog-Cloud N/A [53] Show More
    Table 3. Comparison of Integer Linear Programming-based Scheduling Algorithms
    ✓ = metrics focused in proposed technique; × = metrics ignored; RS = Resource
    Scheduling; WS = Workflow Scheduling. The reviews show that both ILP and MILP
    approaches give an optimal solution close in a reasonable time. The main drawback
    is that these solutions cannot take into account non-linear effects. 3.3 Heuristics
    In this subsection, we present the review and comparison of different heuristic
    algorithms used by researchers to solve resource scheduling problems along with
    their focused metrics. Heuristic algorithms are flexible and well-suited methods
    for performance optimization of the scheduling problems [57] that aim to provide
    an optimal solution in a short time. These algorithms help in solving NP-complete
    problems. The scheduling techniques used by researchers in their studies related
    to resource scheduling are discussed below. Task Scheduling: In Reference [58],
    Jamil et al. design a heuristic-based fog node task scheduler for IoE-service
    provisioning. The authors present a Smart Healthcare case study to optimally schedule
    a variety of incoming tasks with different computational needs, such as latency-sensitive,
    delay-tolerant, and so on, on fog nodes. Their algorithm aims for the optimization
    of delay, energy consumption, and better resource utilization. They use iFogsim
    for simulating the fog environment. As compared to FCFS the proposed algorithm
    performs better in minimization latency and network usage. However, the long tasks
    can starve using their approach. Resource Allocation: Lina et al. [19] present
    Priced Timed Petri Nets (PTPN) algorithm based on task’s completion time along
    with the credibility of fog devices to optimize resource usage and enhance QoS
    requirements of a user. In their work, the user can select the appropriate resource
    from the allocated resource group and then using the credibility of both user
    and available resources, task allocation is done considering the cost of time.
    Their calculations deviate, because the credibility of both users and resources
    is dynamic, and the same credibility of different users is assigned to multiple
    groups. The authors do not consider the average completion time, network usage,
    and fairness. Another heuristic-based resource allocation algorithm, Fog-based
    Region and Cloud (FBRC), is designed by Thanh and Doan [59], which aims at decreasing
    latency in a fog-cloud environment. They present a fog-based region architecture
    for the allocation of tasks to fog regions and clouds. The scheduling problem
    is considered as an Integer problem to reduce completion time in which tasks are
    allocated based on their probability distribution. The authors do not consider
    the important metrics such as energy consumption and execution costs of tasks.
    To achieve energy-efficient resource allocation, Yang et al. [60] describe Maximal
    Energy-Efficient Task Scheduling (MEETS) algorithm, which utilizes efficient cooperation
    between neighborhood nodes through cognitive spectrum access techniques. They
    formulate the optimization problem as multi-nodes fractional programming. After
    formulation, MEETS algorithm is applied to offload tasks on homogeneous fog networks
    to enhance energy efficiency. Their simulation results indicate that MEETS is
    more energy-efficient than other algorithms. Also, the available spectrum bandwidth
    and the probability of spectrum access greatly affect the offloading decision.
    However, the work only focuses on overall energy optimization while ignoring energy
    conversions across the fog and IoE layers. For dynamic resource allocation to
    multiple real-time workflows in fog-cloud environment, Stavrinides in Reference
    [61] describes a heuristic algorithm (Hybrid-EDF). In the study, the tasks are
    allocated on resources according to their computational demands. Fog nodes are
    used for communication-intensive tasks with low computation demands, while cloud
    nodes are used for computation-intensive tasks with low communication demands.
    The scheduling strategy works in two steps. First, the tasks are prioritized according
    to their deadlines using Earliest Deadline First (EDF) rule. Second, VMs are allocated
    to each task based on the Earliest estimated Finish Time (EFT). The results indicate
    that the scheduling strategy reduces the deadline-miss ratio but increases monetary
    cost. For real-time resource allocation, Auluck et al. [62] present two heuristic
    algorithms generated by autonomous cars. The study is based on an embedded fog-cloud
    framework in which real-time tasks are categorized as hard, firm, or soft. The
    hard real-time tasks are the most latency-sensitive and, therefore, assigned to
    embedded fog processors. The firm real-time tasks are less sensitive and are scheduled
    at fog processor, while the soft ones are sent to cloud processor for scheduling.
    The EDF algorithm is used to schedule individual tasks on an assigned processor.
    In EDF, initially, all the tasks are ordered according to the increasing order
    of their deadlines. Then, a static LFC (Local, Fog, Cloud) algorithm is used for
    scheduling the tasks in queues according to their delay tolerances. The iFogSim
    simulator is used for simulation. Their results show the minimization of overall
    communication delay. An efficient IoT architecture along with mobility-aware scheduling
    algorithm is proposed by Abdelmoneem et al. [63] for latency-sensitive healthcare
    applications. The authors use adaptive Received Signal Strength (RSS)-based handoff
    technique for supporting a patient’s mobility. The approach works in two steps:
    the ranking step and the scheduling step. In the first step, the tasks are ranked
    according to the emergency-level using the Weighted Sum Method (WSM). In the second
    step, the heuristic-based algorithm Mobility Aware Modified Balance Reduced (MobMBAR)
    is used to schedule tasks on computing nodes based on the movement of patients.
    The authors minimize the scheduling and response time of tasks. iFogSim is used
    for evaluating MobMBAR, and the results are compared with three other algorithms.
    Their results indicate that their algorithm outperforms other algorithms in reducing
    makespan and consumed energy. Another resource allocation mechanism (TIPS) is
    presented by Zeng et al. [64] using task image placement for minimization of task
    completion time along with better user-experience. Initially, they stored task
    image on the storage server. The processing is performed on embedded client and
    fog devices. They use Mixed-Integer Nonlinear Programming (MINLP) to formulate
    their problem. The presented three-step heuristic algorithm minimizes overall
    completion time by dividing the problem into three subproblems: processing, I/O,
    and transmission time. Their results show that their algorithm performs better
    than greedy algorithms, but the authors ignore mobility of user and financial
    cost. Pooranian at el. [65] propose a scheduling algorithm for allocating resources
    in fog computing to reduce latency and consumed energy. They consider scheduling
    as a Bin Packing Penalty (BPP)-aware problem in which bins are fog servers and
    the Virtual Machines (VMs) are packs. The servers are penalized and rewarded based
    on wasted energy, time, and frequency. They use “penalty and reward policy” for
    the optimization of energy consumption. The algorithm computes the total number
    of VMs that could be allocated to a server for a certain time duration. The penalty
    and reward are awarded to reduce consumed energy. Zhang et al. in Reference [66]
    present Delay-Optimal Task Scheduling (DOTS) algorithm based on capabilities of
    the Voluntary Nodes (VNs). They develop a general analytical model for the problem
    and propose algorithm for minimizing overall task computational latency. Simulation
    is done to obtain numerical results that indicate that DOTS can effectively offload
    tasks on VMs to reduce processing delay as compared to command-mode offloading
    along with minimized energy consumption and high fairness level among fog nodes.
    To achieve balanced performance among delay and energy consumption, Yang et al.
    [67] present a new energy-aware framework for similar fog networks. The authors
    use a control parameter V for characterization between delay-energy tradeoff and
    present the DEBTS algorithm based on Lyapunov optimization techniques for minimizing
    overall energy consumption and average service latency. Lyapunov optimization
    aims to stabilize queues while optimizing performance objective like minimizing
    average energy [68]. Numerical simulations are performed to measure the performance
    of the DEBTS algorithm. The results suggest that the algorithm’s performance is
    better in minimizing delay and energy as compared to other algorithms. But the
    authors do not consider the metrics such as cost and computation time. Workflow
    Scheduling: Xuan-Qui and Eui-Nam [69] propose a task allocation policy (TSCF)
    to study the contrast between task’s execution times and the financial costs for
    the fog-cloud computing system. Their heuristic algorithm allocates fog nodes
    to dependent tasks. The algorithm works in two steps. First, the tasks are ranked
    by traversing DAG. Second, the prioritized tasks are allocated to fog nodes. If
    these nodes are not available, then the task is shifted to cloud. They use CloudSim
    for the evaluation of their algorithm. The results show that their presented algorithm
    performs better than the other algorithms in reducing cost and execution time.
    They did not consider the important metrics such as cost and deadline-constraint
    of workflows. In Table 4, we provide a comparison of heuristic scheduling techniques
    based on different optimization metrics, scheduling type, environment, and evaluation
    tools. The tick marks show the intended criteria of the researchers, while the
    crosses show the ignored metrics. Table 4. Type Name Scheduling Type Latency Makespan
    Network Usage Energy Cons. Cost QoS Environment Evaluation Tool Reference Heuristic
    SJF TS ✓ × × ✓ × × Fog-Cloud iFogSim [58] PTPN RASPTPN RS × × × ✓ × ✓ Fog N/A
    [19] Heuristic FBRC RS × ✓ × × × × Fog-Cloud iFogSim [59] Show More Table 4. Comparison
    of Heuristic Scheduling Algorithms ✓ = metrics focused in proposed technique;
    × = metrics ignored; TS = Task Scheduling; RS = Resource Scheduling; WS = Workflow
    Scheduling; Energy Cons. = Energy Consumed. As seen in Table 4, some researchers
    use heuristics algorithms to solve the task scheduling problem in fog computing.
    The heuristics do not guarantee accurate solutions but give a solution close to
    the best one in a short time. The main drawback is that these solutions are greedy.
    Therefore, they are usually trapped in local minima problem. Also, the objective
    function in the heuristics aims to optimize only one or two metrics. 3.4 Hyper-heuristic
    In this subsection, we briefly describe hyper-heuristic algorithms used in various
    studies, their merits and demerits, focused performance measures, and evaluation
    environment. Hyper-heuristic solutions are automated search procedures for improving
    the generalization of searching techniques to solve hard computational search
    problems [70]. A hyper-heuristic strategy chooses one of the heuristics at each
    iteration from a pool of candidate heuristics. Therefore, the search space of
    hyper-heuristics is always inside the heuristic’s search space. These strategies
    are applied to develop a system that can solve a class of problems instead of
    solving a particular problem domain. Task Scheduling & Resource Allocation: In
    Reference [71], Liu et al. use an improved classification mining approach to schedule
    IoT tasks. Their algorithm uses association rules. For mining association rules
    (TSFC), the authors present the I-Apriori algorithm. The generated rules and the
    least completion time of the task are combined for prioritizing and scheduling
    tasks and allocating fog nodes to these tasks. Their main focus is the minimization
    of task’s execution and waiting time. As the approach is purely time-based, it
    ignores optimization of network bandwidth, completion time, and QoS. Resource
    Allocation & Workflow Scheduling: Sabihe Kabirzadeh [72] devises a hyper-heuristic
    algorithm (HH) for workflow scheduling. For efficient resource allocation at each
    phase, the most suitable heuristic from Particle Swarm Optimization Algorithm
    (PSO), Genetic Algorithm (GA), Ant Colony Optimization Algorithm (ACO), and Simulated
    Annealing (SA) is selected. The scheduling objectives are classified on the basis
    of the user and the service provider’s perspective. The authors focus on the reduction
    of energy consumption, execution time, and cost. They use iFogSim simulator for
    simulations. The obtained results are compared with GA, SA, PSO, and ACO and proven
    to be better in terms of reduction in cost and energy in comparison with the stated
    approaches. Although they are difficult to implement, hyper-heuristic algorithms
    can solve complex real-world problems, because they offer greater levels of generalization
    and can solve single and multi-objective optimization problems. 3.5 Hybrid Heuristic
    In this subsection, we present the brief introduction of hybrid heuristic algorithms
    along with their merits and demerits. After that, a review of hybrid heuristic
    algorithms is provided. A hybrid-heuristic algorithm combines two or more heuristic
    algorithms, takes complementary advantages of specific algorithms, and compensates
    for their weaknesses at each step. Hence, it yields better results than a single
    heuristic [73]. Hybrid algorithms may combine a mono-objective algorithm and a
    population-based algorithm, or two heuristic/meta-heuristic algorithms. Task Scheduling:
    Juan Wang and Di Li [74] present a hybrid-heuristic algorithm for task scheduling.
    Their Hybrid-heuristic algorithm solves task scheduling problems using Improved
    Ant Colony optimization (IACO) and Improved Particle Swarm Optimization (IPSO)
    algorithm to decrease latency, energy consumed, and reliability. Recently, Yadav
    et al. [75] propose a hybrid task scheduling algorithm for the fog computing environment.
    The present algorithm BH-FWA combines Heterogeneous Earliest Finish Time First
    (HEFT) and fireworks algorithm (FWA) for bijective optimization. The main objective
    of the study is to minimize makespan and cost. For evaluation, they use the iFogSim
    toolkit. The hyper-heuristic and hybrid-heuristic algorithms work for the allocation
    of fog nodes to the tasks. Most of these algorithms use a single-objective function
    that optimizes only one of the metrics, ignoring the rest, while the hybrid-heuristic
    algorithms optimize two of them. Most of these algorithms are implemented using
    iFogSim, focusing on latency and energy consumption while ignoring QoS factors.
    In Table 5, we present the comparison of hyper-heuristic and hybrid-heuristic
    techniques along with simulation technique used and simulation environment. Table
    5. Technique Name Scheduling Type Latency Makespan Execution Time Network Usage
    Energy Cons. Cost QoS Environment Evaluation Tool Reference Hyper Heuristic TSFC
    TS,RS,WS ✓ × ✓ × × × × Fog SimGrid [71] Hyper Heuristic HH RS,WS × × ✓ × ✓ × ×
    Fog iFogSim [72] Hybrid Heuristic HH TS,RS,WS ✓ × × × ✓ × × Fog-Cloud Matlab [74]
    Show More Table 5. Comparison of Hyper-heuristic and Hybrid-heuristic Scheduling
    Algorithms ✓ = metrics focused in proposed technique; × = metrics ignored; TS
    = Task Scheduling; RS = Resource Scheduling; Energy Cons. = Energy Consumed. 3.6
    Meta-heuristic In this subsection, we discuss meta-heuristic algorithms and their
    further classification as: Bio-inspired (BI)-based and Swarm intelligence (SI)-based.
    Then, we present the survey of the meta-heuristic algorithms. In the past few
    years, meta-heuristic algorithms have gained popularity and are commonly used
    for solving complex computational problems [76]. Researchers use meta-heuristic
    algorithms to find optimal or near-optimal solutions for task allocation in distributed
    computing environment [77]. These algorithms are used because they provide near-optimal
    solutions within a reasonable duration of time. Meta-heuristics algorithms can
    be categorized as: Bio-inspired (BI)-based meta-heuristics: These algorithms mimic
    the evolution process observed in nature to solve optimization problems. GA is
    an example of bio-inspired algorithms [78]. In GA, a chromosome is used to represent
    every individual. A chromosome comprises a binary coded string of genes. The algorithm
    starts with a random selection of the initial population. An objective function
    is used for checking the fitness of the chromosome. For generating a new population,
    mutation and crossover operations are performed on selected chromosomes. These
    steps repeat till sufficient or best offspring is found [36]. Swarm intelligence
    (SI)-based meta-heuristics: Swarm intelligence is an evolutionary computation-based
    technique inspired by collective intelligence of swarms especially, from their
    biological systems and social-behavior models. PSO, Bee Life Algorithm (BLA),
    and ACO are some examples of SI-based algorithms [79]. Below is the survey of
    task scheduling and resource allocation algorithms using meta-heuristic algorithms.
    Task Scheduling: An adaptive double fitness Genetic Task Scheduling algorithm
    (ADGTS) is presented by Qianyu Liu [80] for IoT task scheduling in smart cities.
    The main objective of the algorithm is to reduce makespan and communication cost.
    The algorithm allocates fog nodes to tasks by considering their computing power,
    communication cost, and latency requirements. The chromosome encoding scheme represents
    the task allocation on fog nodes and roulette selection selects the new generation.
    They use a single-point crossover and mutation to generate a new generation. The
    results indicate that ADGTS algorithm efficiently reduces cost and makespan as
    compared to other algorithms. Wang et al. [81] present a task scheduling algorithm
    for a decentralized fog computing environment on the basis of the immune system
    of the human body having self-organizing, cooperative, and robustness characteristics.
    The fog network is considered a collection of geographically distributed computing
    devices having independent schedulers that can cooperate for synchronization to
    produce an optimal scheduling strategy. They implement local and meta-schedulers.
    The local scheduler aims to decrease the execution time, and the meta-scheduler
    in computing nodes collects the tasks from neighborhood nodes to get the information
    of their computing demands such as memory, processor, and bandwidth and shares
    this data to computing nodes. This framework helps to avoid conflicting scheduling
    decisions and single point of failure of schedulers in a decentralizing environment.
    The evaluation results show that the algorithm results in efficiently minimizing
    task finishing time as compared to the other algorithms. Another algorithm to
    solve the task allocation issue for Bag-of-Tasks applications in a fog-cloud environment
    is described by Binh Minh Nguyen et al. [82]. The main objective of an algorithm
    named Time-Cost aware Scheduling (TCaS) is to minimize the execution time of tasks
    and operating costs. Every chromosome shows the assignment of a task to a fog
    node. Mutation and two-point crossover are used for the generation of a new population.
    They use iFogSim for simulations. Their algorithm’s performance is compared with
    two other algorithms. Their obtained results indicate that the algorithm attains
    a better tradeoff between cost and makespan. The authors, however, ignore some
    important metrics such as network usage and energy consumption. Salim Bitam [83]
    presents a static task scheduling algorithm using BLA for allocation of tasks
    on fog devices. In this algorithm, the tasks are distributed on fog nodes for
    optimal utilization of fog computing resources along with the service-level agreements
    that can be fulfilled. The authors consider the scheduling problem as an Integer
    Linear Programming (ILP) problem to achieve a tradeoff between execution time
    and memory requirements of computing services. The algorithm is compared with
    PSO algorithm. Their results indicate that the presented algorithm is more effective
    than PSO for reducing execution time and memory usage. The main merit of the algorithm
    is that it is static. However, it ignores metrics such as cost and QoS. In 2019,
    Dadmehr Rahbari et al. implemented Greedy Knapsack-based Scheduling (GKS) algorithm
    and symbiotic organism search algorithm named KnapSOS for task scheduling using
    iFogSim simulator [84]. The objective of the algorithm is minimization of energy
    consumption, latency, and network usage. The CPU usage and virtual machine bandwidth
    are used to create Knapsack items. They apply the algorithm on two different applications.
    For both these applications, they compute execution cost and energy consumption.
    Then they compared the obtained results with three other scheduling algorithms.
    Their algorithm takes a longer simulation time. Jayasena and Thisarasinghe use
    Whale Optimization Algorithm (WOA) algorithm to schedule tasks in fog computing
    environment [85]. WOA is a bio-inspired algorithm that uses the idea of bubble-net
    attacking method of the humpback whales through which they determine the prey’s
    location and surround it [86]. Their objective function is to reduce consumed
    energy and execution cost. The authors use iFogSim for implementing the WOA algorithm.
    To analyze the presented algorithm, they compare its performance with PSO, RR,
    and SJF algorithms for three different case studies. The presented algorithm is
    proven to perform better in terms of consumed energy and execution cost. In Reference
    [87], XU et al. present the task scheduling problem as an optimization problem
    for fog-cloud environment. The task scheduling technique (LBP-ACS) uses a laxity
    and ant-colony system to minimize energy consumption along with satisfying the
    task deadlines. To meet the deadline constraint of delay-sensitive tasks, the
    authors apply a laxity-based algorithm for task prioritization and scheduling.
    After that, an ant-colony system algorithm is applied to get an optimal allocation
    plan. CloudSim is used to simulate a fog-cloud environment as well as to evaluate
    the algorithm. The algorithm performance is found better as compared to three
    other algorithms including HEFT. The HEFT [88] algorithm is a popular list scheduling
    algorithm that prioritizes and schedules the tasks according to the finish time
    of tasks and GfE is mainly concerned with minimization of energy consumption.
    Resource Allocation: In another study, Yan Sun, Fuhong, and Haito [89] propose
    a resource allocation scheme. The resources are allocated to different fog clusters.
    It is done among fog devices that reside in a cluster. For solving multi-objective
    optimization problems, the authors use the idea of improved NSGA II for allocating
    resources among heterogeneous fog devices in a cluster. They implement their algorithm
    in Matlab. The results are compared with the results of two other models that
    indicate that the algorithm achieves smaller delays and more solidity of the execution
    of tasks as compared to the other techniques. The major drawback of their proposed
    scheme is that it lacks an appropriate technique for scheduling between fog clusters.
    Also, some important metrics such as cost and energy are ignored in their approach.
    Ghobaei-Arani et al. [90] propose a resource allocation algorithm for Cyber-Physical
    System (CPS) applications in fog environment using Moth-Flame Optimization (MFO)
    algorithm. MFO algorithm is a bio-inspired population-based optimization algorithm
    where the main inspiration is the navigation of a moth’s behavior in the night
    around the flames [91]. The objective function of the algorithm is to decrease
    the execution and transfer time of tasks. Simulation is performed using iFogSim
    and the simulation results are compared with NSGA II, PSO, and BLA. The comparison
    proves that the algorithm is good for minimizing the task execution time along
    with better QoS for CPS applications. To fulfill the increasing needs of IoE applications,
    Wang et al. [92] propose a resource allocation algorithm I-FASC using (I-FA) improved
    genetic algorithm firework algorithm. I-FA is presented by introducing the explosion
    radius detection mechanism of fireworks. The algorithm is compared with three
    other algorithms. Their results show that the presented algorithm efficiently
    minimizes the computing time. Real-time applications are latency-sensitive, while
    some others are delay-tolerant. These different requirements increase the complexity
    of the fog computing environment. To find an optimal solution according to the
    needs of IoT application, Meng et al. propose an adaptive neighborhood multi-objective
    optimization algorithm FOG-AMOSM for fog computing [93]. The conflicting optimization
    objectives of the algorithm are to decrease the execution time of tasks along
    with minimized cost for service providers. The authors present a multi-objective
    evolutionary heuristic algorithm based on the method of adaptive neighborhood
    technique. The technique is used for better distribution of tasks on fog resources.
    CloudSim 5.0 is used for simulation. Their performance analysis shows that the
    algorithm effectively optimizes their chosen metrics in comparison with the classical
    Round Robin and simple GA. Hoseiny et al. present a priority-aware task allocation
    algorithm named Prioritized Genetic Algorithm (PGA) to jointly optimize computational
    time, consumed consumption, and percentage of tasks finished prior to their deadlines
    [94]. The prioritization of tasks is based on their deadlines. Their fog broker
    is constituent of three components, namely, task receiver, task scheduler, and
    resource monitor. The task receiver guesses the deadlines of tasks and resource
    monitor evaluates the available resources. The task scheduler first prioritizes
    the tasks according to their deadlines and then genetic algorithm is applied to
    select appropriate fog node for every task. Simulation is done using Matlab. Their
    results reveal that the performance of the algorithm is better than that of Power
    of 2 Choices (Po2C) and Ant-Mating Optimization (AMO) algorithms. Potu et al.
    present an Extended Particle Swarm Optimization (EPSO) algorithm for resource
    allocation in fog-cloud environment [95]. The objective of the algorithm is to
    minimize task completion time and cost using the proximal gradient method. iFogSim
    is used for simulation purposes, and the results are compared with PSO and its
    variant. According to their results, EPSO works well for reducing makespan and
    cost. Workflow Scheduling: A cost-effective workflow scheduling algorithm is proposed
    by Rongbin Xu [96] based on IPSO in a fog-cloud environment. The experiment is
    done in Matlab, with six cloud servers and four fog servers. The authors claim
    to reduce the task’s completion time as compared to PSO. A side-by-side comparison
    of surveyed meta-heuristic-based algorithms is presented in Table 6 where tick
    marks show the focus criteria and the crosses indicate the ignored metrics. The
    table also shows the focused scheduling type along with environment used for scheduling.
    Table 6. Technique Name Scheduling Type Latency Makespan Execution Time Network
    Usage Energy Con. Cost QoS Environment Evaluation Tool Reference Genetic ADGTS
    TS × ✓ × × × ✓ × Fog N/A [80] Bio Inspired - TS × × × ✓ × × × Fog Experimental
    [81] Genetic TCaS TS × × × ✓ × × ✓ Fog-Cloud Experimental [82] Show More Table
    6. Comparison of Meta-heuristic Scheduling Algorithms ✓ = metrics focused in proposed
    technique; × = metrics ignored; TS = Task Scheduling; RS = Resource Scheduling;
    WS = Workflow Scheduling. The surveyed meta-heuristic algorithms perform resource
    allocation to a set of tasks for mono- or bi-objective optimization of given metrics.
    Although, such algorithms give an optimal solution, they require a lot of computational
    time. Also, these algorithms ignore QoS criteria. 3.7 Fuzzy Logic-based Algorithms
    This subsection reviews fuzzy logic-based scheduling algorithms along with focused
    metrics. Fuzzy logic is a powerful tool to deal with uncertainty, vague, and non-numeric
    information in systems and is robust to changing environment. Fuzzy logic was
    proposed in 1965 by Lotfi Zadeh [97]. Fuzzy set theory and fuzzy quantifiers are
    the basic building blocks of fuzzy logic. In fuzzy sets, each element has a degree
    of membership, while a fuzzy quantifier is a fuzzy relationship between fuzzy
    sets. Fuzzy logic can effectively be used to efficiently solve dynamic real-time
    scheduling problems [98]. Resource Allocation: Most of the research work done
    for resource allocation focuses on delay, energy consumption, and network usage,
    but unlike cloud, fog nodes are resource-constrained. Therefore, Mohammed Anis
    et al. use fuzzy-quantified ranking method to Rank Fog Nodes (RFN) for task allocation
    [99]. The ranking is done based on features of fog nodes along with user preferences
    using linguistic quantifiers and fuzzy-quantified propositions. Least Satisfactory
    Proportion (LSP) and Greatest Satisfactory Proportion (GSP) parameters are defined
    to differentiate among similar fog devices. The authors focus on achieving user-satisfaction
    along with minimization of execution delay and consumed energy. In Reference [100],
    FCAP, a resource scheduling algorithm, is described that combines Fuzzy C-Mean
    Clustering (FCM) and PSO. The authors use FCM to search clusters of fog nodes
    and PSO for global optimization that reduces the resource search space. The algorithm
    works in two steps. In the first step, there is initialization of the particle
    population and random generation of the cluster centers. In the second step, a
    weighted matching method is applied to compute the fitness function. As the FCM
    algorithm can trap in a local optima, they combine PSO with it for global optimization
    and faster convergence. For the implementation of FCAP, the authors use Matlab.
    Their results indicate that the algorithm obtains better clustering accuracy and
    fast convergence than that of FCM. Also, the algorithm results in better user-satisfaction
    as compared to the Min-min algorithm. For the dynamic environment of fog computing
    in [101], Javanmardi presents a fog resource allocator FPFTS that jointly uses
    meta-heuristic algorithm and uses fuzzy logic. In the designed task allocation
    algorithm, fuzzy-logic is used as a fitness function in the PSO algorithm. The
    objective of the algorithm is the optimal resource utilization of fog nodes along
    with the minimization of network usage and application loop delay. The algorithm
    is implemented using iFogsim and evaluated for different fog node configurations.
    Wu et al. propose a multi-objective Estimation of Distribution Algorithm (EDA)
    resource allocation algorithm for workflows based on fuzzy logic for multi-objective
    optimization [102]. They consider a system in which the heterogeneous processors
    are located at three tiers. They use fuzzy numbers for modeling uncertain IoT
    environments and workload characteristics. After that, they use fuzzy clustering
    to classify the tasks in DAG according to their characteristics. Then, these grouped
    tasks are allocated to relative tiers using the cluster-tier allocation rule that
    is learned by fuzzy EDA. For simulations, the algorithm is developed in C++ and
    results are compared with three algorithms. The results show that EDA outperforms
    the heuristic algorithms. Ali et al. present a resource allocation algorithm to
    schedule real-time tasks in a fog-cloud computing environment using fuzzy logic
    [103]. The fuzzy-based algorithm schedules the tasks on cloud and fog nodes based
    on task attributes (mips, storage, bandwidth), time constraints of tasks (deadline),
    and resource availability in the fog layer. The aim of the presented algorithm
    is to reduce the makespan and average turnaround time of tasks. The algorithm
    is implemented in the iFogSim simulator and the comparison is done with SJF and
    FIFO. Table 7 lists the fuzzy-based resource allocation techniques, focused scheduling
    technique, environment. In the table, the tick marks show the intended criteria
    and the crosses indicate the metrics ignored by the researchers. Table 7. Technique
    Name Scheduling Type Latency Makespan Network Usage Energy Consumed Cost QoS Environment
    Evaluation Tool Reference Fuzzy Logic RFN RS ✓ × × ✓ × × Fog-Cloud Matlab [99]
    Fuzzy Clustering FCAP RS × × × × × ✓ Fog Matlab [100] Fuzzy Logic & PSO FPFTS
    RS ✓ × ✓ ✓ × × Fog iFogSim [101] Show More Table 7. Comparison of Fuzzy-based
    Scheduling Algorithms ✓ = metrics focused in proposed technique; × = metrics ignored;
    TS = Task Scheduling; RS = Resource Scheduling; WS = Workflow Scheduling. 3.8
    Reinforcement Learning In this subsection, we explain reinforcement learning,
    classification of RL-based algorithms, and an overview of different RL-based algorithms
    of task scheduling in fog computing. RL is a type of machine learning that has
    successfully been applied for solving the Job-Shop Scheduling Problem (JSSP) [104].
    Reinforcement Learning is a sequential decision-making process where agent is
    the decision-maker that is trained to optimize its behavior by learning from its
    experience while interacting with the environment. These algorithms are successful
    because of their ability to handle the uncertain environment, self-learning ability,
    computational efficiency, and adaptive nature and, hence, are well-suited to schedule
    diverse-nature tasks in a fog computing environment [32]. In RL, self-learning
    agents can take appropriate action in a particular situation to perform a task
    and try to maximize the received rewards [105]. By using reinforcement learning,
    a system can map a situation to actions. Agents, environment, states, actions,
    and rewards are the five basic concepts of reinforcement learning. (1) Agent:
    Agent is a decision-maker that takes action in a particular situation. The agents
    choose best actions either on the basis of their experience (exploitation) or
    by choosing entirely new actions (exploration). This tradeoff aids the agent to
    learn appropriate action to take. (2) Actions: Actions are the set of all possible
    moves. (3) Environment: The agent observes the environment. The input of the environment
    is the agent’s current state and action, while its output is a numeric reward
    and generated next state. (4) State: The state is the immediate situation in which
    the agent finds itself. (5) Reward: The reward is the response that describes
    how the agent behaved by the action taken. [106]. Figure 5 shows the agent and
    environment interaction in Reinforcement learning architecture. Fig. 5. Fig. 5.
    Reinforcement learning architecture. RL algorithms can be broadly classified as
    follows: (1) Model-Based: Model-based algorithms aim to learn the working of the
    environment using observations and plan a situation using model [107]. These algorithms
    may or may not have a policy or value function. Instead, a transition and reward
    function is used to search optimal policy; for example, dynamic programming. Model-based
    RL can further be classified as Learn Model and Model Given. (2) Model-free: Model-free
    algorithms do not learn from the dynamics of the environment. These are simpler
    and less expensive than their counterparts and can learn the optimal policy based
    on trial-and-error. The three main model-free methods to solve RL problems are
    value-based methods, policy-based methods, and actor-critic methods [108]. These
    techniques are explained in the following subsections. 3.8.1 Value-based Methods.
    Value-based methods aim to optimize the value function V(s) using Bellman equation
    [105] in a given state. The action-value function estimates the maximum expected
    future return the agent will get at each state. Q-Learning is an example of off-policy
    value-based methods [109]. An off-policy algorithm learns the value function being
    independent of the policy used during training. An on-policy algorithm selects
    a policy depending upon the one used in gathering data. State–Action–Reward–State–Action
    (SARSA) is an example of on-policy value-based methods. The details of the value-based
    algorithms used for scheduling are given below. Q Learning algorithm is a powerful
    value-based algorithm to select optimal action-selection policy using a Q function.
    The simple version of Q-learning sustains a lookup table of values Q(s,a) where
    s indicates the state and a indicates the set of actions. Each entry in the table
    is a state-action pair used to compute the maximum future reward against an action
    at each state. Q-Learning algorithm uses the Bellman equation to update the value
    function. In Q-Learning, Q ∗ (s,a) is the cumulative discounted reward of action
    a taken in any state s. Orhean et al. use reinforcement learning for allocating
    tasks in a heterogeneous distributed environment [110]. They assume different
    machine performance and cluster status. They propose Machine Learning Box (MLBox)
    for the implementation of the agent using the BURLAP library. Their main objective
    is to design a scheduler that can optimally schedule tasks on a given cluster
    of machines with each machine with an internal scheduler to reduce task’s execution
    time. In the described platform, they apply both SARSA and Q-Learning algorithms
    for task scheduling. The main drawback is that their approach is not suitable
    for a complex environment. In 2019, Liu et al. [111] consider resource allocation
    problem for the IoT networks. Every edge device is considered as an agent that
    decides which task should be allocated on edge devices. They propose resource
    allocation using ϵ -greedy Q-learning algorithm. Their objective is minimization
    of the cost of consumed energy as well as delay in task execution. Q-Learning
    algorithm is simple and easy to implement. It also yields better results [110].
    But this algorithm is difficult to generalize, and the agent may not select the
    best action in case of experiencing an unseen event. Therefore, this algorithm
    is not well-suited for a complex dynamic environment. 3.8.2 Policy-based Methods.
    A policy maps agent’s observed states of the environment to actions [105]. In
    policy-based methods, the objective is to learn optimal policy π with the highest
    expected future rewards without maintaining the value function. A policy can be:
    (1) Deterministic: A deterministic policy maps state to actions. For each given
    state, the function returns a defined action to take. Deterministic policies are
    used in deterministic environments when there is no uncertainty. Because for a
    given history and action, there is a single potential observation and reward.
    (2) Stochastic: The stochastic policy is useful when the environment is uncertain.
    Therefore, the agent selects actions using a policy that is explained as a probability
    distribution over actions π:π(s;a)⟶[0;1];π(s;a) the probability of performing
    action a under state s. For a given history and action, there are many potential
    observations and rewards. Policy-based methods usually use a function approximator
    with some adjustable parameters, θ ; π(s,aθ) . Policy gradient algorithms are
    a popular type of reinforcement learning algorithms. These algorithms optimize
    policy parameters using gradient descent on an objective function J . Their goal
    is to estimate the gradient by analyzing the trajectories generated by following
    the current policy. Qing Wu [112] propose a DAG scheduling algorithm using policy-gradient
    REINFORCE algorithm to execute security-sensitive tasks on trusted entities in
    a heterogeneous computing environment. The algorithm aims at minimization of the
    makespan of the tasks. They compare the obtained results of their scheduler with
    HEFT and CPOP for randomly generated DAGs. The limitation of their work is that
    they only focus on the static problem with predefined task priorities. 3.9 Deep
    Learning, Deep Reinforcement Learning In this subsection, we introduce deep learning
    and deep reinforcement learning, the categories of DRL-based algorithms, and a
    review of different DRL algorithms used by researchers. Deep Learning is a new
    area of machine learning research in which feature learning and pattern classification
    are done through multiple processing layers [113]. In past few years, deep learning
    [114] has successfully been applied for image processing, sequence prediction,
    natural language processing, and data analysis [115]. Due to the promising results
    of Deep Learning, it has recently been used in various other fields such as healthcare
    and agriculture. Convolutional Neural Network (CNN), Recurrent Neural Network
    (RNN), Multilayer Perceptrons (MLPs), Long-short Term Memory (LSTM), and Deep
    Belief Networks (DBNs) are some examples of widely used neural networks [115].
    CNN has successfully been applied for image processing as it deals with spatial
    distribution and RNN has been used for natural language processing because of
    its ability to learn long-term dependencies. Resource Allocation: Amudha and Murali
    present an intelligent and novel scheduling algorithm, Modified Wake-on Reconfigurable
    Networks, to optimize performance using distance energy adaptive rule sets (WORN-DEAR)
    for patient’s health monitoring [116]. They integrate deep learning algorithms
    in fog gateways for energy-efficient routing and scheduling without compromising
    latency and throughput. In their experimental setup, they implement reconfigurable
    software in fog gateways, and the communication between these gateways is via
    short-range waves. The data collected from various body sensors are moved towards
    the nearest fog gateways that take necessary decisions about where to process
    the received data. The energy-efficient path prediction for both normal and emergency
    data on the proposed network uses Long-Short Term Memory (LSTM). Cooja-Contiki
    network simulator is used for performance evaluation [117]. The work is also implemented
    on different testbeds and a comparison is made with logistic regression, naïve
    bias, Support Vector Machine (SVM), and K-Nearest Neighbours (KNN). The demerit
    of the proposed work is that it ignores mobility and security factor. Reinforcement
    learning refers to goal-oriented algorithms, so the agent aims to maximize numerical
    reward by taking appropriate actions. Simple RL algorithms are applied to solve
    few low-dimensional problems because they lack scalability. Also, RL algorithms
    suffer from the same complexity issues such as computational and memory complexities,
    as suffered by the other optimization algorithms [118]. The exponential explosion
    of states and actions is termed as “Curse of Dimensionality.” Deep learning makes
    RL able to solve such intractable optimization problems. The fusion of deep learning
    and reinforcement learning named DRL has emerged as an active area of research.
    DRL has recently proved its capability to solve decision-making problems where
    mapping magnitude is too large. In the DRL model, Deep Neural Network (DNN) helps
    in function approximation, as shown in Figure 6. Fig. 6. Fig. 6. Deep reinforcement
    learning architecture. If the state space is simple, then a table can be used
    to store mapping of states to actions, but the solution is not feasible if the
    mapping magnitude is too large. Therefore, in such cases, function approximators
    are usually used. A function approximator contains some adjustable parameters.
    If a DNN is used as a function approximator, then a DRL model can be created,
    as shown in Figure 6. DRL algorithms are also classified as Value-based and Policy-based
    methods, which are described in the following subsections. 3.9.1 Value-based DRL
    Methods. As explained in the previous section, the value-based algorithms learn
    a value function that is used for defining a policy. Deep Q-network (DOQN) and
    Double DQN are examples of Value-based DRL algorithms. DQN is a value function-based
    DRL algorithm in which a DNN helps estimating the Q-value function [118]. Mnih
    et al. introduce this algorithm. It outperforms in an online setting across a
    variety of ATARI video games [119]. In DQN, state features are given as input
    to a deep neural network that outputs the Q-value function in a high-dimensional
    and continuous state space. Q-Learning uses a single estimator for selection and
    evaluation of action, so it may select an overestimated value in case of noise.
    To overcome the problem of overestimation, DQN uses upward bias, while Double
    DQN (DDQN) [120] uses two separate Q-value estimators for each variable. Resource
    Scheduling: Task scheduling for fog-based IoT applications using DRL is proposed
    by Gazori et al. [121] to decrease service latency, energy consumption, and computational
    cost with resource and task’s deadline constraints. They apply a DDQ-Learning-based
    scheduling algorithm. They use gateways as schedulers that work as agents. Nodal
    collaboration is master-slave in which Gateways are master and fog nodes are slaves.
    Computing node resources are distributed among many VMs (CPU, Memory, Storage)
    that are allocated to incoming tasks. Their algorithm directly learns the scheduling
    policy from experience without having a prior knowledge of the environment. They
    claim to minimize energy consumption along with load-balancing on available resources.
    The above review shows that DQN and Double DQN algorithms perform better as compared
    to the simple Q-Learning algorithm in a large and dynamic environment. But, in
    case of high dimensional state-action space, the algorithm converges slowly. 3.9.2
    DRL-based Policy Gradient Methods. Policy-based methods aim to optimize a performance
    objective by finding an optimal policy, as explained in earlier sections. Policy
    Gradient Algorithms and Actor-critic Algorithms are [122] commonly used as policy-based
    methods. Policy gradient algorithms are also classified as Deterministic and Non-deterministic
    Policy Gradient (DPG) Algorithms. Gradient Ascent and Deep Deterministic Policy
    Gradient (DDPG) [123] are examples of these Methods. In 2016, Mao et al. [124]
    are the first ones who claim that a system itself can learn to manage resources.
    They assume dynamic arrival of jobs that remain non-preempted when allocated on
    a cluster of resources (CPU, memory, I/O). Their main objective of the resource
    scheduler is to decrease average slowdown and completion time of a task. They
    present policy as a neural network trained in an episodic setting. In each episode,
    the tasks are scheduled using the policy. The authors assume that jobs arrive
    in the job queue after discrete time intervals. In case the job queue is full,
    the tasks are placed in a backlog. They use convolutional neural network as a
    function approximator for state representation. They use the REINFORCE algorithm
    for training. However, they do not consider the jobs with dependent tasks. In
    Reference [125], Chen et al. also use a policy-gradient algorithm for resource
    allocation in multiple server clusters to reduce average job slowdown time. Their
    study proves that DRL outperforms conventional resource allocation algorithms
    in multi-resource and multi-machine environments. The authors consider m machines
    with d resources and a job queue in which jobs arrive after a discrete time step.
    In case the job queue is full, a job is saved in the backlog to allocate the processor
    in the future. They use convolutional neural network for state representation.
    Task Scheduling: In Reference [126], Ye et al. propose online task scheduling
    algorithm DeepRM2 and offline scheduling algorithm DeepRM-off. Their main aim
    is to decrease the average slowdown and completion time of the job. In the DeepRM2,
    job arrival is according to Poisson distribution, while in the DeepRM-off, jobs
    simultaneously reach a queue for a slot. They assume that there is no job preemption
    once it is selected. To speed up the learning process, the authors use imitation
    learning. For training purposes, they use the SJF scheduling algorithm. The trained
    neural network is then used as the initial policy for DRL. Then, the policy gradient
    algorithm is used in which CNN works as a function approximator. Resource Allocation:
    Bian et al. in Reference [127] purpose Dominant Resource Fairness (DRF) and DRL-based
    solution for multi-resource fairness for resource allocation. DRF is a newly presented
    multi-resource fairness policy, which is a generalized form of max-min fairness
    policy for various resources [128] in which allocation of a user is according
    to the user’s dominant share. Its main objective is maximization of the smallest
    dominant share across tasks. Their adaptive scheduling algorithm FairTS minimizes
    average task slowdown and schedules resources fairly among these tasks. In FairTS,
    scheduling is performed in two steps: In the first step, the tasks are generated
    as a Poisson process, while in the second step, the available resources are allocated
    to arrived tasks. After the allocation of the resources, no preemption is done
    till the task finishes. They consider three types of task delay: waiting delay,
    transmission delay, and execution delay. A DRL-based Policy-Gradient algorithm
    is used to minimize average task slowdown time. Their evaluation results compared
    with those of Random and Shortest Execution Time (SET) show that their algorithm
    performs better in terms of minimization of average task slowdown and resource
    fairness. The above review indicates that the policy-gradient methods are mostly
    used for scheduling and resource allocation by researchers, because these algorithms
    converge faster and are more effective and adaptive in high-dimensional space.
    Their main disadvantages is that they may converge to local optima, and the evaluation
    of a policy is typically inefficient and it suffers from high variance. The actor-critic
    algorithm is a hybrid method in which two non-linear neural network function approximators
    are used. A critic learns a value function for evaluating the goodness of the
    taken action, and an actor is policy-based that receives the state as input and
    outputs the best action. The critic provides a reinforcing signal to the actor.
    The training of two networks is separately performed, and it uses gradient ascent
    to update weights. As time passes, the actor learns to take better actions and
    the critic evaluates those actions. Weight updation happens at each step as opposed
    to a policy gradient. DDPG, Proximal Policy Optimization (PPO) [129], and Trust
    Region Policy Optimization (TRPO) [130] are some examples of variations of the
    actor-critic algorithm. Resource Allocation: Shreshth Tuli [131] use Asynchronous-Advantage-Actor-Critic
    (A3C) algorithm [132] for the stochastic dynamic scheduler in edge-cloud environment
    in which Residual Recurrent Neural Network (R2N2)-based framework is used to exploit
    temporal patterns in a hybrid environment [133]. They claim that the designed
    scheduler can quickly adapt to a dynamically changing environment. Their aim is
    to reduce consumed energy, response time, and cost. They use iFogsim and Cloudsim
    for simulations. The limitation of their purposed model is the lack of scalability.
    Actor-critic algorithms quickly converge and also solve the problem of variance
    issue suffered by the policy gradient algorithms. A side-by-side comparison of
    the dynamic RL and DRL-based scheduling techniques considering the different optimization
    metrics, environment, scheduling technique, and evaluation tools is shown in Table
    8. The tick marks indicate the intended criteria, while the crosses show the metrics
    ignored by the researchers. Table 8. Algorithm Learning Scheduling Type Service
    Delay Avg Slowdown ATT Energy Cons. Execution Time Environment Evaluation Tool
    Reference Modified WORN-DEAR - RS × × × ✓ × Edge-Fog-Cloud Cooja-Contiki [116]
    DDQL Off-Policy RS ✓ × × ✓ ✓ Fog-Cloud Keras, Simpy [121] Policy Gradient On &
    Off-Policy TS × ✓ ✓ × × Fog-Cloud Experimental [126] Show More Table 8. Comparison
    of RL- and DRL-based Scheduling Algorithms ✓ = metrics focused in technique; ×
    = metrics ignored; TS = Task Scheduling; RS = Resource Scheduling; Energy Cons.
    = Energy Consumed; ATT = Avg. Turnaround Time. The above survey shows the initial
    efforts made by different researchers for solving the task scheduling and allocation
    problem using RL and DRL-based algorithms. According to Table 8, most of the proposed
    algorithms aim to minimize energy consumption along with minimization in turnaround
    time. However, some other factors, such as cost, reliability, and security, have
    been ignored by most of the researchers. Skip 4ANALYTICAL DISCUSSION Section 4
    ANALYTICAL DISCUSSION In this section, we provide our analysis of the existing
    task scheduling techniques in fog computing. The analytical examination is done
    on the basis of the classification of these algorithms, evaluation environment,
    tools used, along with the metrics used in these studies. Figure 7 shows the percentage
    of scheduling techniques focused by different researchers. It shows that most
    of the researchers, i.e., 65%, focus on solving resource allocation problems in
    complex fog computing environments, while task scheduling on fog devices is addressed
    in 28% of studies. Only 7% of the studies address the workflow scheduling issue
    in fog computing. Fig. 7. Fig. 7. Focused techniques. Figure 8 shows the application
    environment used by researchers for solving scheduling problems. In 55% of studies,
    fog-cloud environment is considered, while fog environment is considered in 38%
    of the studies. Edge-fog-cloud is considered in 7% of studies. Fig. 8. Fig. 8.
    Application environments. Figure 9 shows the evaluation factors that are considered
    in different approaches. Latency is the most widely used metric, and it is used
    in 26% of the studies. Among the other metrics, energy consumption has been optimized
    by 20%, execution time by 8%, QoS by 12%, cost by 10%, network usage by 7%, makespan
    by 10%, and average slowdown time by 4% of the studies. Fig. 9. Fig. 9. Metrics
    used in schedulingalgorithms. The software tools used in different studies and
    their brief introduction are briefly described in Table 9, including CloudSim
    [134], iFogSim [44], CloudAnalyst [135], SimGrid [136], and Keras [137]. Table
    9. Software Tools Usage %age License Brief Introduction CloudSim [134] 12% Open-source
    CloudSim is the most commonly used generalized free framework modeling and simulating
    large-scale cloud infrastructure and its core services. It builds on GridSim.
    It facilitates the researchers to simulate data centers, virtual machines, cloud,
    and data center brokers. It allows users to define policies for the allocation
    of hosts, and host resources, such as memory and storage. iFogSim [44] 55% Open-source
    iFogSim is the most popular free simulation toolkit to model and simulate resource
    management techniques in the fog/cloud and IoT environments. It is based on CloudSim
    and allows the user to simulate fog infrastructure with millions of fog nodes,
    sensors, actuators, and IoT services [138] for evaluating resource-management
    and scheduling policies. It helps the researchers to evaluate various metrics
    such as delay, energy consumption, network usage, and cost [139] CloudAnalyst
    [135] 3% Open-source CloudAnalyst is an open-source simulator built on CloudSim
    for evaluating the performance of large-scale distributed applications on the
    cloud. It provides GUI for configuring a geographically distributed system. The
    evaluation results are presented through graphs and tables. Show More Table 9.
    Representation of Software Tools Table 9 shows that iFogSim is used in 55% of
    the simulation studies. CloudSim tool is used in 12% of the studies. Matlab tool
    is used in around 21% of the evaluation studies. For the rest of the studies,
    the researchers use WorkflowSim, CloudAnalyst simulators, and C++/Java languages.
    The percentage usage, merits and demerits of the techniques used for task scheduling
    in fog computing are listed in Table 10. The table suggests that Heuristic and
    Meta-heuristic algorithms have widely been used by researchers, i.e., 21% and
    27%, respectively. Policy-based DRL algorithms have also been applied by 6% researchers.
    Traditional algorithms are used by 10%, ILP and MILP by 12%, fuzzy Logic-based
    algorithms by 10%, Hybrid heuristic, Hyper-heuristic algorithms by 4% of researchers.
    Table 10. Tech. %age Merits Demerits Traditional [44, 45, 47, 48] 10% simple,
    easy to implement low overhead deterministic not suitable for uncertain and dynamic
    fog environments not adaptable ILP, MILP [51, 52, 53, 54, 55, 56] 12% flexible
    extensive widely used for scheduling not suitable for high-dimensional dynamic
    fog environments cannot handle non-linear effects Heuristic [19, 58, 59, 60, 61,
    62, 63, 64, 65, 66, 67, 69] 21% simple and cheap to implement solution in a reasonable
    time greedy, so it can easily trap in local optima less flexible and scalable
    Show More Table 10. Percentage Usage, Merits and Demerits of Task Scheduling Techniques
    4.1 Lessons Learned from the Survey/ Research Findings We reviewed literature
    related to three major scheduling issues in the fog computing and IoE environment:
    task scheduling, resource allocation, and workflow scheduling. The techniques
    used in the reviewed studies belong to different domains: traditional, ILP, heuristic,
    hyper-heuristic, hybrid-heuristic, meta-heuristic, and intelligent ones such as
    RL, DRL, and fuzzy-logic based. The survey reveals that most researchers target
    the resource allocation problem in fog computing, some address task scheduling
    on fog nodes, while only a few consider workflow scheduling. The survey indicates
    that the unpredictable workload, dynamic nature, and complex fog computing and
    IoE make optimal and self-adaptive resource allocation and scheduling challenges.
    Most of the approaches need prior information regarding scheduling tasks that
    are not suitable for a dynamic fog computing environment. Therefore, considering
    the discussed techniques, fuzzy-based and deep reinforcement learning techniques
    have great potential to solve these issues. In different studies, the resource
    allocation applies on either the fog-cloud layers or only the fog layer and fog
    computing and IoE. As the cloud and fog environments vary in resource availability
    and geographical location, this makes the allocation problem more complex. Therefore,
    the allocation algorithm should fairly, optimally, and efficiently allocate cloud
    and fog resources to competing IoE requests according to their QoS requirements.
    Most of the reviewed studies in the survey are simulation-based, while only a
    few studies are experimental. In simulation-based studies, we present a small-size
    simulations scale. Therefore, to assess the performance of these algorithms, extensive
    simulations are needed. Also, the simulators used in these studies lack the mobility
    factor as well as the network properties. Therefore, we need simulators that can
    support these features. Most studies try to optimize metrics such as energy consumption,
    delay, and network usage while ignoring the security, fault tolerance, and privacy
    issues. For resource allocation, the trusted node selection is of great importance.
    Therefore, new algorithms are required that can allocate resources to tasks according
    to privacy and security needs. Skip 5OPEN ISSUES AND FUTURE DIRECTIONS Section
    5 OPEN ISSUES AND FUTURE DIRECTIONS In this section, we discuss the open issues,
    future challenges, and future research directions for task scheduling in fog computing.
    Resource Utilization of Fog Node: The fog devices are resource-constrained in
    terms of storage, processing, and energy. They receive dynamic workloads from
    both latency-sensitive and delay-tolerant applications. Therefore, the challenging
    part is to schedule the unpredictable arrival of tasks on these fog nodes for
    optimal utilization of available resources. Optimal Resource Allocation: A big
    number of tasks are generated by IoE devices that should be optimally allocated
    to fog nodes to yield faster response time, especially for latency-sensitive applications.
    As fog computing supports the mobility of fog nodes and IoT devices, all the resources
    accessible at one time might be unreachable at any other time. Therefore, this
    makes resource allocation a challenging task. Long latency for real-time applications,
    lack of generalization, and quick adaptability of the existing algorithms are
    the issues that need attention. Parallel Scheduling: In parallel processing, a
    task is divided into multiple tasks, and then these sub-tasks are concurrently
    executed [140]. Dividing tasks into sub-tasks that can reduce delays via distributed
    computing is another open issue that needs attention. Privacy: Fog nodes receive
    a lot of personal data from various fog applications like smart healthcare. Therefore,
    the privacy of such data is most important for users [141]. Although some researchers
    apply privacy-preserving techniques on fog nodes, there is no acceptable authentication
    solution. The fog nodes are more vulnerable to potential threats that make authentication
    a challenging issue. Security: Security is one of the main challenges, as fog
    nodes lack resources and are deployed in unsafe environments, and hence they are
    easy to attack. Therefore, designing a lightweight, high-speed, and reliable safety
    algorithm is still a challenging task. Currently, only a few researchers focus
    on security issues in fog computing, and there are some open issues such as dynamic
    authentication, access controls, external attacks, and intrusion detection. Context-aware
    Service Provisioning: The context constitutes the runtime factors that can affect
    the applications [142]. The existing context-aware service provisioning techniques
    are less flexible, scalable, and are not able to handle a vast number of IoT applications
    [54, 55]. Therefore, more techniques should be investigated for context-aware
    service provisioning to overcome the above-said limitations. Energy Consumption:
    As fog devices are energy-constrained because of low-power batteries, energy-aware
    fog computing is still an open issue that needs to be addressed. Some researchers
    focus on energy optimization, while the appropriate usage of bandwidth in data
    transfer, energy wastage, and battery drainage issues are still some of the challenges
    that need attention. Self-adaptive Scheduling: Most of the scheduling algorithms
    lack the learning component that makes self-adaptive resource scheduling a challenge
    in task scheduling in fog computing. Although some research studies consider self-adaptive
    scheduling, all these efforts have only been made on the experimental level. Therefore,
    task scheduling algorithms are required to optimally schedule tasks generated
    as a result of unexpected events in a dynamic environment. Fog computing architecture
    is distributed as tasks are allocated to heterogeneous fog nodes. Multi-Agent
    Reinforcement Learning (MARL) is a kind of Reinforcement Learning that can be
    used for optimal self-adaptive scheduling. Several agents can dynamically learn
    in multi-agent reinforcement learning after interacting with the environment [143].
    In single-agent reinforcement, the learning state is changed due to the actions
    of the individual agent. In MARL, the state change is concerned with the actions
    of all agents. MARL for task scheduling has also not been studied by researchers
    yet. Skip 6CONCLUSIONS AND FINAL REMARK Section 6 CONCLUSIONS AND FINAL REMARK
    Efficient scheduling algorithms can significantly improve the performance of a
    fog computing and IoE. In this study, we have studied different task scheduling,
    resource allocation, and workflow scheduling approaches in fog computing and IoE
    paradigm. We have classified these approaches into eight main categories, namely,
    traditional, heuristic, hyper-heuristic, hybrid heuristic, meta-heuristic, fuzzy-based,
    reinforcement learning, and deep reinforcement learning-based. We have described
    the advantages, disadvantages, evaluation factors, and simulation environment
    of every approach. Our analysis indicates that most of the researchers have used
    heuristic, meta-heuristic, and ILP algorithms for solving the scheduling problem.
    Considering the evaluation environment, our analysis shows that 86% of the studies
    are simulation-based, while only 14% of studies are experimental. The review also
    revealed that iFogSim is the most commonly used simulator that has been used in
    55% of the studies. Moreover, 21% of studies use Matlab, and 14% of studies use
    the CloudSim for evaluations. Furthermore, the latency has been the most commonly
    chosen metric for evaluation considered in 26% research studies, energy consumption
    in 20%, and QoS in 12% studies. The work can be extended by considering the security-aware
    resource management mechanisms, reliability-based scheduling, privacy, and security
    architectures in fog computing and IoE. REFERENCES [1] Buyya Rajkumar and Dastjerdi
    Amir Vahid. 2016. Internet of Things: Principles and Paradigms. Elsevier. Reference
    [2] Baccarelli Enzo, Naranjo Paola G. Vinueza, Scarpiniti Michele, Shojafar Mohammad,
    and Abawajy Jemal H.. 2017. Fog of everything: Energy-efficient networked computing
    architectures, research challenges, and a case study. IEEE Access 5 (2017), 9882–9910.
    Reference 1Reference 2 [3] Gubbi Jayavardhana, Buyya Rajkumar, Marusic Slaven,
    and Palaniswami Marimuthu. 2013. Internet of Things (IoT): A vision, architectural
    elements, and future directions. Fut. Gen. Comput. Syst. 29, 7 (2013), 1645–1660.
    Reference [4] Al-Fuqaha Ala, Guizani Mohsen, Mohammadi Mehdi, Aledhari Mohammed,
    and Ayyash Moussa. 2015. Internet of things: A survey on enabling technologies,
    protocols, and applications. IEEE Commun. Surv. Tutor. 17, 4 (2015), 2347–2376.
    Reference [5] Buyya Rajkumar, Yeo Chee Shin, Venugopal Srikumar, Broberg James,
    and Brandic Ivona. 2009. Cloud computing and emerging IT platforms: Vision, hype,
    and reality for delivering computing as the 5th utility. Fut. Gen. Comput. Syst.
    25, 6 (2009), 599–616. Reference [6] Zhang Qi, Cheng Lu, and Boutaba Raouf. 2010.
    Cloud computing: State-of-the-art and research challenges. J. Internet Serv. Applic.
    1, 1 (2010), 7–18. Reference [7] Jo Dongsik and Kim Gerard Jounghyun. 2019. IoT+
    AR: Pervasive and augmented environments for “Digi-log” shopping experience. Hum.-centric
    Comput. Inf. Sci. 9, 1 (2019), 1–17. Reference [8] Chowdhury Abdullahi, Karmakar
    Gour, and Kamruzzaman Joarder. 2019. The co-evolution of cloud and IoT applications:
    Recent and future trends. In Handbook of Research on the IoT, Cloud Computing,
    and Wireless Network Optimization. IGI Global, 213–234. Reference [9] Mahmud Redowan,
    Koch Fernando Luiz, and Buyya Rajkumar. 2018. Cloud-fog interoperability in IoT-enabled
    healthcare solutions. In Proceedings of the 19th International Conference on Distributed
    Computing and Networking. 1–10. Reference [10] Malik Swati and Gupta Kamali. 2019.
    Resource scheduling in fog: Taxonomy and related aspects. J. Comput. Theoret.
    Nanosci. 16, 10 (2019), 4313–4319. Reference [11] Bonomi Flavio, Milito Rodolfo,
    Zhu Jiang, and Addepalli Sateesh. 2012. Fog computing and its role in the internet
    of things. In Proceedings of the 1st Edition of the MCC Workshop on Mobile Cloud
    Computing. ACM, 13–16. Reference [12] Yousefpour Ashkan, Fung Caleb, Nguyen Tam,
    Kadiyala Krishna, Jalali Fatemeh, Niakanlahiji Amirreza, Kong Jian, and Jue Jason
    P.. 2019. All one needs to know about fog computing and related edge computing
    paradigms: A complete survey. J. Syst. Archit. 98 (2019), 289–330. Reference [13]
    Mahmud Redowan, Ramamohanarao Kotagiri, and Buyya Rajkumar. 2020. Application
    management in fog computing environments: A taxonomy, review and future directions.
    Comput. Surv. 53, 4 (2020), 1–43. Reference [14] Naranjo Paola G. Vinueza, Pooranian
    Zahra, Shojafar Mohammad, Conti Mauro, and Buyya Rajkumar. 2019. FOCAN: A fog-supported
    smart city network architecture for management of applications in the Internet
    of Everything environments. J. Parallel Distrib. Comput. 132 (2019), 274–283.
    Reference [15] Chen Xu, Jiao Lei, Li Wenzhong, and Fu Xiaoming. 2015. Efficient
    multi-user computation offloading for mobile-edge cloud computing. IEEE/ACM Trans.
    Netw. 24, 5 (2015), 2795–2808. Reference 1Reference 2 [16] Ghobaei-Arani Mostafa,
    Souri Alireza, and Rahmanian Ali A.. 2020. Resource management approaches in fog
    computing: A comprehensive review. J. Grid Comput. 18, 1 (2020), 1–42. Reference
    1Reference 2Reference 3 [17] Hong Cheol-Ho and Varghese Blesson. 2019. Resource
    management in fog/edge computing: A survey on architectures, infrastructure, and
    algorithms. ACM Comput. Surv. 52, 5 (2019), 1–37. Reference [18] Mathew Teena,
    Sekaran K. Chandra, and Jose John. 2014. Study and analysis of various task scheduling
    algorithms in the cloud computing environment. In Proceedings of the International
    Conference on Advances in Computing, Communications and Informatics (ICACCI).
    IEEE, 658–664. Reference [19] Ni Lina, Zhang Jinquan, Jiang Changjun, Yan Chungang,
    and Yu Kan. 2017. Resource allocation strategy in fog computing based on priced
    timed petri nets. IEEE Internet Things J. 4, 5 (2017), 1216–1228. Navigate to
    [20] Chronaki Kallia, Rico Alejandro, Casas Marc, Moretó Miquel, Badia Rosa M.,
    Ayguadé Eduard, Labarta Jesus, and Valero Mateo. 2017. Task scheduling techniques
    for asymmetric multi-core systems. IEEE Trans. Parallel Distrib. Syst. 28, 7 (2017),
    2074–2087. Reference [21] Visheratin Alexander A., Melnik Mikhail, and Nasonov
    Denis. 2016. Workflow scheduling algorithms for hard-deadline constrained cloud
    environments. Procedia Comput. Sci. 80 (2016), 2098–2106. Reference [22] Al-Khafajiy
    Mohammed, Baker Thar, Al-Libawy Hilal, Waraich Atif, Chalmers Carl, and Alfandi
    Omar. 2018. Fog computing framework for internet of things applications. In Proceedings
    of the 11th International Conference on Developments in eSystems Engineering (DeSE).
    IEEE, 71–77. Reference [23] Waqas Muhammad, Niu Yong, Ahmed Manzoor, Li Yong,
    Jin Depeng, and Han Zhu. 2018. Mobility-aware fog computing in dynamic environments:
    Understandings and implementation. IEEE Access 7 (2018), 38867–38879. Reference
    [24] Ghosh Shreya, Mukherjee Anwesha, Ghosh Soumya K., and Buyya Rajkumar. 2019.
    Mobi-iost: Mobility-aware cloud-fog-edge-IoT collaborative framework for time-critical
    applications. IEEE Trans. Netw. Sci. Eng. 7, 4 (2019), 2271–2285. Reference [25]
    Hosseinioun Pejman, Kheirabadi Maryam, Tabbakh Seyed Reza Kamel, and Ghaemi Reza.
    2022. aTask scheduling approaches in fog computing: A survey. Trans. Emerg. Telecommun.
    Technol. 33, 3 (2022), e3792. Reference 1Reference 2 [26] Naha Ranesh Kumar, Garg
    Saurabh, Georgakopoulos Dimitrios, Jayaraman Prem Prakash, Gao Longxiang, Xiang
    Yong, and Ranjan Rajiv. 2018. Fog computing: Survey of trends, architectures,
    requirements, and research directions. IEEE Access 6 (2018), 47980–48009. Reference
    1Reference 2 [27] Mukherjee Mithun, Shu Lei, and Wang Di. 2018. Survey of fog
    computing: Fundamental, network applications, and research challenges. IEEE Commun.
    Surv. Tutor. 20, 3 (2018), 1826–1857. Reference 1Reference 2 [28] Yang Xin and
    Rahmani Nazanin. 2020. Task scheduling mechanisms in fog computing: Review, trends,
    and perspectives. 50, 1 (2020), 22–38. Reference 1Reference 2 [29] Alizadeh Mohammad
    Reza, Khajehvand Vahid, Rahmani Amir Masoud, and Akbari Ebrahim. 2020. Task scheduling
    approaches in fog computing: A systematic review. Int. J. Commun. Syst. 33, 16
    (2020), e4583. Reference 1Reference 2 [30] Islam Mir Salim Ul, Kumar Ashok, and
    Hu Yu-Chen. 2021. Context-aware scheduling in Fog computing: A survey, taxonomy,
    challenges and future directions. J. Netw. Comput. Applic. 180 (2021), 103008.
    Reference 1Reference 2 [31] Matrouk Khaled and Alatoun Kholoud. 2021. Scheduling
    algorithms in fog computing: A survey. Int. J. Netw. Distrib. Comput. 9, 1 (2021),
    59–74. Reference 1Reference 2 [32] Zhao Xinyi, Zong Qun, Tian Bailing, Zhang Boyuan,
    and You Ming. 2019. Fast task allocation for heterogeneous unmanned aerial vehicles
    through reinforcement learning. Aerosp. Sci. Technol. 92 (2019), 588–594. Reference
    1Reference 2 [33] Dastjerdi Amir Vahid, Gupta Harshit, Calheiros Rodrigo N., Ghosh
    Soumya K., and Buyya Rajkumar. 2016. Fog computing: Principles, architectures,
    and applications. In Internet of Things. Elsevier, 61–75. Reference [34] Tanenbaum
    Andrew S. and Steen Maarten Van. 2007. Distributed Systems: Principles and Paradigms.
    Prentice-Hall. Reference [35] Singh Poonam, Dutta Maitreyee, and Aggarwal Naveen.
    2017. A review of task scheduling based on meta-heuristics approach in cloud computing.
    Knowl. Inf. Syst. 52, 1 (2017), 1–51. Reference [36] Kalra Mala and Singh Sarbjeet.
    2015. A review of metaheuristic scheduling techniques in cloud computing. Egypt.
    Inform. J. 16, 3 (2015), 275–295. Reference 1Reference 2 [37] Ali Syed Arshad
    and Alam Mansaf. 2016. A relative study of task scheduling algorithms in cloud
    computing environment. In Proceedings of the 2nd International Conference on Contemporary
    Computing and Informatics (IC3I). IEEE, 105–111. Reference [38] Alodib Mohammed.
    2016. QoS-Aware approach to monitor violations of SLAs in the IoT. J. Innov. Dig.
    Ecosyst. 3, 2 (2016), 197–207. Reference [39] Ibrahim Elhossiny, El-Bahnasawy
    Nirmeen A., and Omara Fatma A.. 2016. Task scheduling algorithm in cloud computing
    environment based on cloud pricing models. In Proceedings of the World Symposium
    on Computer Applications & Research (WSCAR). IEEE, 65–71. Reference [40] Elmougy
    Samir, Sarhan Shahenda, and Joundy Manar. 2017. A novel hybrid of shortest job
    first and round robin with dynamic variable quantum time task scheduling technique.
    J. Cloud Comput. 6, 1 (2017), 1–12. Reference [41] Salot Pinal. 2013. A survey
    of various scheduling algorithm in cloud computing environment. Int. J. Res. Eng.
    Technol. 2, 2 (2013), 131–135. Reference [42] Madni Syed Hamid Hussain, Latiff
    Muhammad Shafie Abd, Abdullahi Mohammed, Abdulhamid Shafi’i Muhammad, and Usman
    Mohammed Joda. 2017. Performance comparison of heuristic algorithms for task scheduling
    in IaaS cloud computing environment. PloS One 12, 5 (2017), e0176321. Reference
    [43] Abraham Silberschatz, Peter B. Galvin, and Greg Gagne. 2003. Operating System
    Concepts. John Wiley & Sons. Reference [44] Gupta Harshit, Dastjerdi Amir Vahid,
    Ghosh Soumya K., and Buyya Rajkumar. 2017. iFogSim: A toolkit for modeling and
    simulation of resource management techniques in the Internet of Things, edge and
    fog computing environments. Softw.: Pract. Exper. 47, 9 (2017), 1275–1296. Navigate
    to [45] Choudhari Tejaswini, Moh Melody, and Moh Teng-Sheng. 2018. Prioritized
    task scheduling in fog computing. In Proceedings of the ACMSE’18. Reference 1Reference
    2Reference 3 [46] Mtshali Mxolisi, Kobo Hlabishi, Dlamini Sabelo, Adigun Matthew,
    and Mudali Pragasen. 2019. Multi-objective optimization approach for task scheduling
    in fog computing. In Proceedings of the International Conference on Advances in
    Big Data, Computing and Data Communication Systems (icABCD). IEEE, 1–6. Reference
    [47] Alsmadi Ahmad Mohammad, Aloglah Roba Mahmoud Ali, Abu-darwish Nisrein Jamal
    Sanad, Smadi Ahmad Al, Alshabanah Muneerah, Alrajhi Daniah, Alkhaldi Hanouf, and
    Alsmadi Mutasem K.. 2021. Fog computing scheduling algorithm for smart city. Int.
    J. Electric. Comput. Eng. 11, 3 (2021), 2219–2228. Reference 1Reference 2Reference
    3 [48] Bittencourt Luiz F., Diaz-Montes Javier, Buyya Rajkumar, Rana Omer F.,
    and Parashar Manish. 2017. Mobility-aware application scheduling in fog computing.
    IEEE Cloud Comput. 4, 2 (2017), 26–35. Reference 1Reference 2Reference 3 [49]
    Schrijver Alexander. 1998. Theory of Linear and Integer Programming. John Wiley
    & Sons. Reference [50] Floudas Christodoulos A. and Lin Xiaoxia. 2005. Mixed integer
    linear programming in process scheduling: Modeling, algorithms, and applications.
    Ann. Oper. Res. 139, 1 (2005), 131–162. Reference [51] Skarlat Olena, Nardelli
    Matteo, Schulte Stefan, and Dustdar Schahram. 2017. Towards QoS-aware fog service
    placement. In Proceedings of the IEEE 1st International Conference on Fog and
    Edge Computing (ICFEC). IEEE, 89–96. Reference 1Reference 2Reference 3 [52] Hoseiny
    Farooq, Azizi Sadoon, Shojafar Mohammad, and Tafazolli Rahim. 2021. Joint QoS-aware
    and cost-efficient task scheduling for fog-cloud resources in a volunteer computing
    system. ACM Trans. Internet Technol. 21, 4 (2021), 1–21. Navigate to [53] Aburukba
    Raafat O., AliKarrar Mazin, Landolsi Taha, and El-Fakih Khaled. 2020. Scheduling
    Internet of Things requests to minimize latency in hybrid Fog–Cloud computing.
    Fut. Gen. Comput. Syst. 111 (2020), 539–551. Navigate to [54] Martinez Ismael,
    Jarray Abdallah, and Hafid Abdelhakim Senhaji. 2020. Scalable design and dimensioning
    of fog-computing infrastructure to support latency-sensitive IoT applications.
    IEEE Internet Things J. 7, 6 (2020), 5504–5520. Navigate to [55] Santos José,
    Wauters Tim, Volckaert Bruno, and Turck Filip De. 2021. Towards end-to-end resource
    provisioning in fog computing over low power wide area networks. J. Netw. Comput.
    Applic. 175 (2021), 102915. Navigate to [56] Guevara Judy C. and Fonseca Nelson
    L. S. da. 2021. Task scheduling in cloud-fog computing systems. Peer-to-Peer Netw.
    Applic. 14, 2 (2021), 962–977. Reference 1Reference 2Reference 3 [57] Soltani
    Nasim, Soleimani Behzad, and Barekatain Behrang. 2017. Heuristic algorithms for
    task scheduling in cloud computing: A survey. Int. J. Comput. Netw. Inf. Secur.
    9, 8 (2017), 16. Reference [58] Jamil Bushra, Shojafar Mohammad, Ahmed Israr,
    Ullah Atta, Munir Kashif, and Ijaz Humaira. 2020. A job scheduling algorithm for
    delay and performance optimization in fog computing. Concurr. Comput.: Pract.
    Exper. 32, 7 (2020), e5581. Reference 1Reference 2Reference 3 [59] Hoang Doan
    and Dang Thanh Dat. 2017. FBRC: Optimization of task scheduling in fog-based region
    and cloud. In Proceedings of the Trustcom/BigDataSE/ICESS Conference. IEEE, 1109–1114.
    Reference 1Reference 2Reference 3 [60] Yang Yang, Wang Kunlun, Zhang Guowei, Chen
    Xu, Luo Xiliang, and Zhou Ming-Tuo. 2018. MEETS: Maximal energy efficient task
    scheduling in homogeneous fog networks. IEEE Internet Things J. 5, 5 (2018), 4076–4087.
    Reference 1Reference 2Reference 3 [61] Stavrinides Georgios L. and Karatza Helen
    D.. 2019. A hybrid approach to scheduling real-time IoT workflows in fog and cloud
    environments. Multimedia Tools Applic. 78, 17 (2019), 24639–24655. Reference 1Reference
    2Reference 3 [62] Auluck Nitin, Azim Akramul, and Fizza Kaneez. 2019. Improving
    the schedulability of real-time tasks using fog computing. IEEE Trans. Serv. Comput.
    15, 1 (2019), 372–385. Reference 1Reference 2Reference 3 [63] Abdelmoneem Randa
    M., Benslimane Abderrahim, and Shaaban Eman. 2020. Mobility-aware task scheduling
    in cloud-fog IoT-based healthcare architectures. Comput. Netw. 179 (2020), 107348.
    Reference 1Reference 2Reference 3 [64] Zeng Deze, Gu Lin, Guo Song, Cheng Zixue,
    and Yu Shui. 2016. Joint optimization of task scheduling and image placement in
    fog computing supported software-defined embedded system. IEEE Trans. Comput.
    65, 12 (2016), 3702–3712. Reference 1Reference 2Reference 3 [65] Pooranian Zahra,
    Shojafar Mohammad, Naranjo Paola G. Vinueza, Chiaraviglio Luca, and Conti Mauro.
    2017. A novel distributed fog-based networked architecture to preserve energy
    in fog data centers. In Proceedings of the IEEE 14th International Conference
    on Mobile Ad Hoc and Sensor Systems (MASS). IEEE, 604–609. Reference 1Reference
    2Reference 3 [66] Zhang Guowei, Shen Fei, Chen Nanxi, Zhu Pengcheng, Dai Xuewu,
    and Yang Yang. 2018. DOTS: Delay-optimal task scheduling among voluntary nodes
    in fog networks. IEEE Internet Things J. 6, 2 (2018), 3533–3544. Reference 1Reference
    2Reference 3 [67] Yang Yang, Zhao Shuang, Zhang Wuxiong, Chen Yu, Luo Xiliang,
    and Wang Jun. 2018. DEBTS: Delay energy balanced task scheduling in homogeneous
    fog networks. IEEE Internet Things J. 5, 3 (2018), 2094–2106. Reference 1Reference
    2Reference 3 [68] Neely Michael J.. 2010. Stochastic network optimization with
    application to communication and queueing systems. Synth. Lect. Commun. Netw.
    3, 1 (2010), 1–211. Reference [69] Pham Xuan-Qui and Huh Eui-Nam. 2016. Towards
    task scheduling in a cloud-fog computing system. In Proceedings of the 18th Asia-Pacific
    Network Operations and Management Symposium (APNOMS). IEEE, 1–4. Reference 1Reference
    2Reference 3 [70] Drake John H., Kheiri Ahmed, Özcan Ender, and Burke Edmund K..
    2020. Recent advances in selection hyper-heuristics. Eur. J. Oper. Res. 285, 2
    (2020), 405–428. Reference [71] Liu Lindong, Qi Deyu, Zhou Naqin, and Wu Yilin.
    2018. A task scheduling algorithm based on classification mining in fog computing
    environment. Wirel. Commun. Mob. Comput. 2018 (2018). Reference 1Reference 2Reference
    3 [72] Kabirzadeh Sabihe, Rahbari Dadmehr, and Nickray Mohsen. 2017. A hyper heuristic
    algorithm for scheduling of fog networks. In Proceedings of the 21st Conference
    of Open Innovations Association (FRUCT). IEEE, 148–155. Reference 1Reference 2Reference
    3 [73] Tsai Chun-Wei, Huang Wei-Cheng, Chiang Meng-Hsiu, Chiang Ming-Chao, and
    Yang Chu-Sing. 2014. A hyper-heuristic scheduling algorithm for cloud. IEEE Trans.
    Cloud Comput. 2, 2 (2014), 236–250. Reference [74] Wang Juan and Li Di. 2019.
    Task scheduling based on a hybrid heuristic algorithm for smart production line
    with fog computing. Sensors 19, 5 (2019), 1023. Navigate to [75] Yadav Ashish
    Mohan, Tripathi Kuldeep Narayan, and Sharma S. C.. 2022. A bi-objective task scheduling
    approach in fog computing using hybrid fireworks algorithm. Journal Supercomput.
    78, 3 (2022), 4236–4260. Reference 1Reference 2 [76] Houssein Essam H., Gad Ahmed
    G., Wazery Yaser M., and Suganthan Ponnuthurai Nagaratnam. 2021. Task scheduling
    in cloud computing based on meta-heuristics: Review, taxonomy, open challenges,
    and future trends. Swarm Evolut. Comput. 62 (2021), 100841. Reference [77] Abdel-Basset
    Mohamed, Abdel-Fatah Laila, and Sangaiah Arun Kumar. 2018. Metaheuristic algorithms:
    A comprehensive review. In Computational Intelligence for Multimedia Big Data
    on the Cloud with Engineering Applications. Elsevier, 185–231. Reference [78]
    Tsai Chun-Wei and Rodrigues Joel J. P. C.. 2013. Metaheuristic scheduling for
    cloud: A survey. IEEE Syst. J. 8, 1 (2013), 279–291. Reference [79] Yang Xin-She,
    Chien Su Fong, and Ting Tiew On. 2014. Computational intelligence and metaheuristic
    algorithms with applications. The Scientific World Journal 2014 (2014). Reference
    [80] Liu Qianyu, Wei Yunkai, Leng Supeng, and Chen Yijin. 2017. Task scheduling
    in fog enabled internet of things for smart cities. In Proceedings of the IEEE
    17th International Conference on Communication Technology (ICCT). IEEE, 975–980.
    Reference 1Reference 2Reference 3 [81] Wang Yabin, Guo Chenghao, and Yu Jin. 2018.
    Immune scheduling network based method for task scheduling in decentralized fog
    computing. Wirel. Commun. Mob. Comput. 2018 (2018). Reference 1Reference 2Reference
    3 [82] Nguyen Binh Minh, Binh Huynh Thi Thanh, and Son Bao Do2019. Evolutionary
    algorithms to optimize task scheduling problem for the IoT based bag-of-tasks
    application in cloud–fog computing environment. Appl. Sci. 9, 9 (2019), 1730.
    Reference 1Reference 2Reference 3 [83] Bitam Salim, Zeadally Sherali, and Mellouk
    Abdelhamid. 2018. Fog computing job scheduling optimization based on bees swarm.
    Enterp. Inf. Syst. 12, 4 (2018), 373–397. Reference 1Reference 2Reference 3 [84]
    Rahbari Dadmehr and Nickray Mohsen. 2019. Low-latency and energy-efficient scheduling
    in fog-based IoT applications. Turk. J. Electric. Eng. Comput. Sci. 27, 2 (2019),
    1406–1427. Reference 1Reference 2Reference 3 [85] Jayasena K. P. N. and Thisarasinghe
    B. S.. 2019. Optimized task scheduling on fog computing environment using meta
    heuristic algorithms. In Proceedings of the IEEE International Conference on Smart
    Cloud (SmartCloud). IEEE, 53–58. Reference 1Reference 2Reference 3 [86] Mirjalili
    Seyedali and Lewis Andrew. 2016. The whale optimization algorithm. Adv. Eng. Softw.
    95 (2016), 51–67. Reference [87] Xu Jiuyun, Hao Zhuangyuan, Zhang Ruru, and Sun
    Xiaoting. 2019. A method based on the combination of laxity and ant colony system
    for cloud-fog task scheduling. IEEE Access 7 (2019), 116218–116226. Reference
    1Reference 2Reference 3 [88] Topcuoglu Haluk, Hariri Salim, and Wu Min-you. 2002.
    Performance-effective and low-complexity task scheduling for heterogeneous computing.
    IEEE Trans. Parallel Distrib. Syst. 13, 3 (2002), 260–274. Reference [89] Sun
    Yan, Lin Fuhong, and Xu Haitao. 2018. Multi-objective optimization of resource
    scheduling in Fog computing using an improved NSGA-II. Wirel. Person. Commun.
    102, 2 (2018), 1369–1385. Reference 1Reference 2Reference 3 [90] Ghobaei-Arani
    Mostafa, Souri Alireza, Safara Fatemeh, and Norouzi Monire. 2020. An efficient
    task scheduling approach using moth-flame optimization algorithm for cyber-physical
    system applications in fog computing. Trans. Emerg. Telecommun. Technol. 31, 2
    (2020), e3770. Reference 1Reference 2Reference 3 [91] Mirjalili Seyedali. 2015.
    Moth-flame optimization algorithm: A novel nature-inspired heuristic paradigm.
    Knowle.-based Syst. 89 (2015), 228–249. Reference [92] Wang Shudong, Zhao Tianyu,
    and Pang Shanchen. 2020. Task scheduling algorithm based on improved firework
    algorithm in fog computing. IEEE Access 8 (2020), 32385–32394. Reference 1Reference
    2Reference 3 [93] Yang Ming, Ma Hao, Wei Shuang, Zeng You, Chen Yefeng, and Hu
    Yuemei. 2020. A multi-objective task scheduling method for fog computing in cyber-physical-social
    services. IEEE Access 8 (2020), 65085–65095. Reference 1Reference 2Reference 3
    [94] Hoseiny Farooq, Azizi Sadoon, Shojafar Mohammad, Ahmadizar Fardin, and Tafazolli
    Rahim. 2021. PGA: A priority-aware genetic algorithm for task scheduling in heterogeneous
    fog-cloud computing. In Proceedings of the IEEE IEEE Conference on Computer Communications
    Workshops. 1–6. Reference 1Reference 2Reference 3 [95] Potu Narayana, Jatoth Chandrashekar,
    and Parvataneni Premchand. 2021. Optimizing resource scheduling based on extended
    particle swarm optimization in fog computing environments. Concurr. Comput.: Pract.
    Exper. 33, 23 (2021), e6163. Reference 1Reference 2Reference 3 [96] Xu Rongbin,
    Wang Yeguo, Cheng Yongliang, Zhu Yuanwei, Xie Ying, Sani Abubakar Sadiq, and Yuan
    Dong. 2018. Improved particle swarm optimization based workflow scheduling in
    cloud-fog environment. In Proceedings of the International Conference on Business
    Process Management. Springer, 337–347. Reference 1Reference 2Reference 3 [97]
    Zadeh Lotfi A.. 1996. Soft computing and fuzzy logic. In Fuzzy Sets, Fuzzy Logic,
    and Fuzzy Systems: Selected Papers by Lotfi a Zadeh. World Scientific, 796–804.
    Reference [98] Tariq Muhammad Imran, Tayyaba Shahzadi, Ashraf Muhammad Waseem,
    Imran Muhammad, Pricop Emil, Cangea Otilia, Paraschiv Nicolae, and Mian Natash
    Ali. 2020. An analysis of the application of fuzzy logic in cloud computing. J.
    Intell. Fuzzy Syst.Preprint 38, 5 (2020), 5933–5947. Reference [99] Benblidia
    Mohammed Anis, Brik Bouziane, Merghem-Boulahia Leila, and Esseghir Moez. 2019.
    Ranking fog nodes for tasks scheduling in fog-cloud environments: A fuzzy logic
    approach. In Proceedings of the 15th International Wireless Communications & Mobile
    Computing Conference (IWCMC). IEEE, 1451–1457. Reference 1Reference 2Reference
    3 [100] Li Guangshun, Liu Yuncui, Wu Junhua, Lin Dandan, and Zhao Shuaishuai.
    2019. Methods of resource scheduling based on optimized fuzzy clustering in fog
    computing. Sensors 19, 9 (2019), 2122. Reference 1Reference 2Reference 3 [101]
    Javanmardi Saeed, Shojafar Mohammad, Persico Valerio, and Pescapè Antonio. 2021.
    FPFTS: A joint fuzzy particle swarm optimization mobility-aware approach to fog
    task scheduling algorithm for Internet of Things devices. Softw.: Pract. Exper.
    51, 12 (2021), 2519–2539. Reference 1Reference 2Reference 3 [102] Wu Chu-Ge, Li
    Wei, Wang Ling, and Zomaya Albert Y.. 2021. An evolutionary fuzzy scheduler for
    multi-objective resource allocation in fog computing. Fut. Gen. Comput. Syst.
    117 (2021), 498–509. Reference 1Reference 2Reference 3 [103] Ali Hala S., Rout
    Rashmi Ranjan, Parimi Priyanka, and Das Sajal K.. 2021. Real-time task scheduling
    in fog-cloud computing framework for IoT applications: A fuzzy logic based approach.
    In Proceedings of the International Conference on COMmunication Systems & NETworkS
    (COMSNETS). IEEE, 556–564. Reference 1Reference 2Reference 3 [104] Jiménez Yailen
    Martínez. 2012. A Generic Multi-agent Reinforcement Learning Approach for Scheduling
    Problems. PhD. Vrije Universiteit Brussel. Reference [105] Sutton Richard S. and
    Barto Andrew G.. 2018. Reinforcement Learning: An Introduction. The MIT Press.
    Reference 1Reference 2Reference 3 [106] Klaine Paulo Henrique Valente. 2019. Self-organization
    for 5G and Beyond Mobile Networks Using Reinforcement learning. Ph.D. Dissertation.
    University of Glasgow. Reference [107] Reyna Yunior César Fonseca, Jiménez Yailen
    Martínez, Cabrera Juan Manuel Bermúdez, and Hernández Beatriz M. Méndez. 2015.
    A reinforcement learning approach for scheduling problems. Investigac. Operac.
    36, 3 (2015), 225–231. Reference [108] Arulkumaran Kai, Deisenroth Marc Peter,
    Brundage Miles, and Bharath Anil Anthony. 2017. Deep reinforcement learning: A
    brief survey. IEEE Sig. Process. Mag. 34, 6 (2017), 26–38. Reference [109] Watkins
    Christopher J. C. H. and Dayan Peter. 1992. Q-learning. Mach. Learn. 8, 3–4 (1992),
    279–292. Reference [110] Orhean Alexandru Iulian, Pop Florin, and Raicu Ioan.
    2018. New scheduling approach using reinforcement learning for heterogeneous distributed
    systems. J. Parallel Distrib. Comput. 117 (2018), 292–302. Reference 1Reference
    2Reference 3 [111] Liu Xiaolan, Qin Zhijin, and Gao Yue. 2019. Resource allocation
    for edge computing in IoT networks via reinforcement learning. arXiv preprint
    arXiv:1903.01856 (2019). Reference 1Reference 2 [112] Wu Qing, Wu Zhiwei, Zhuang
    Yuehui, and Cheng Yuxia. 2018. Adaptive DAG tasks scheduling with deep reinforcement
    learning. In Proceedings of the International Conference on Algorithms and Architectures
    for Parallel Processing. Springer, 477–490. Reference [113] Goodfellow Ian, Bengio
    Yoshua, Courville Aaron, and Bengio Yoshua. 2016. Deep Learning. Vol. 1. The MIT
    Press, Cambridge. Reference [114] Faust Oliver, Hagiwara Yuki, Hong Tan Jen, Lih
    Oh Shu, and Acharya U. Rajendra. 2018. Deep learning for healthcare applications
    based on physiological signals: A review. Comput. Meth. Prog. Biomed. 161 (2018),
    1–13. Reference [115] LeCun Yann, Bengio Yoshua, and Hinton Geoffrey. 2015. Deep
    learning. Nature 521, 7553 (2015), 436–444. Reference 1Reference 2 [116] Amudha
    S. and Murali M.. 2020. Deep learning based energy efficient novel scheduling
    algorithms for body-fog-cloud in smart hospital. J. Amb. Intell. Human. Comput.
    (2020), 1–20. Reference 1Reference 2 [117] Osterlind Fredrik, Dunkels Adam, Eriksson
    Joakim, Finne Niclas, and Voigt Thiemo. 2006. Cross-level sensor network simulation
    with COOJA. In Proceedings of the 31st IEEE Conference on Local Computer Networks.
    IEEE, 641–648. Reference [118] Arulkumaran Kai, Deisenroth Marc Peter, Brundage
    Miles, and Bharath Anil Anthony. 2015. A brief survey of deep reinforcement learning.
    Nature 518, 7540 (2015), 529–533. Reference 1Reference 2 [119] Mnih Volodymyr,
    Kavukcuoglu Koray, Silver David, Rusu Andrei A., Veness Joel, Bellemare Marc G.,
    Graves Alex, Riedmiller Martin, Fidjeland Andreas K., Ostrovski Georg et al. 2015.
    Human-level control through deep reinforcement learning. Nature 518, 7540 (2015),
    529–533. Reference [120] Wang Ziyu, Schaul Tom, Hessel Matteo, Hasselt Hado, Lanctot
    Marc, and Freitas Nando. 2016. Dueling network architectures for deep reinforcement
    learning. In Proceedings of the International Conference on Machine Learning.
    PMLR, 1995–2003. Reference [121] Gazori Pegah, Rahbari Dadmehr, and Nickray Mohsen.
    2019. Saving time and cost on the scheduling of fog-based IoT applications using
    deep reinforcement learning approach. Fut. Gen. Comput. Syst. (2019). Reference
    1Reference 2Reference 3 [122] Konda Vijay R. and Tsitsiklis John N.. 2000. Actor-critic
    algorithms. In Proceedings of the Conference on Advances in Neural Information
    Processing Systems. 1008–1014. Reference [123] Lillicrap Timothy P., Hunt Jonathan
    J., Pritzel Alexander, Heess Nicolas, Erez Tom, Tassa Yuval, Silver David, and
    Wierstra Daan. 2015. Continuous control with deep reinforcement learning. arXiv
    preprint arXiv:1509.02971 (2015). Reference [124] Mao Hongzi, Alizadeh Mohammad,
    Menache Ishai, and Kandula Srikanth. 2016. Resource management with deep reinforcement
    learning. In Proceedings of the 15th ACM Workshop on Hot Topics in Networks. ACM,
    50–56. Reference [125] Chen Weijia, Xu Yuedong, and Wu Xiaofeng. 2017. Deep reinforcement
    learning for multi-resource multi-machine job scheduling. arXiv preprint arXiv:1711.07440
    (2017). Reference [126] Ye Yufei, Ren Xiaoqin, Wang Jin, Xu Lingxiao, Guo Wenxia,
    Huang Wenqiang, and Tian Wenhong. 2018. A new approach for resource scheduling
    with deep reinforcement learning. arXiv preprint arXiv:1806.08122 (2018). Reference
    1Reference 2Reference 3 [127] Bian Simeng, Huang Xi, and Shao Ziyu. 2019. Online
    task scheduling for fog computing with multi-resource fairness. In Proceedings
    of the IEEE 90th Vehicular Technology Conference (VTC’19-Fall). IEEE, 1–5. Reference
    1Reference 2Reference 3 [128] Ghodsi Ali, Zaharia Matei, Hindman Benjamin, Konwinski
    Andy, Shenker Scott, and Stoica Ion. 2011. Dominant resource fairness: Fair allocation
    of multiple resource types. In Proceedings of the Conference on Networked Systems
    Design & Implementation. 24–24. Reference [129] Schulman John, Wolski Filip, Dhariwal
    Prafulla, Radford Alec, and Klimov Oleg. 2017. Proximal policy optimization algorithms.
    arXiv preprint arXiv:1707.06347 (2017). Reference [130] Schulman John, Moritz
    Philipp, Levine Sergey, Jordan Michael, and Abbeel Pieter. 2015. High-dimensional
    continuous control using generalized advantage estimation. arXiv preprint arXiv:1506.02438
    (2015). Reference [131] Tuli Shreshth, Ilager Shashikant, Ramamohanarao Kotagiri,
    and Buyya Rajkumar. 2020. Dynamic scheduling for stochastic edge-cloud computing
    environments using A3C learning and residual recurrent neural networks. IEEE Trans.
    Mob. Comput. (2020). Reference 1Reference 2Reference 3 [132] Mnih Volodymyr, Badia
    Adria Puigdomenech, Mirza Mehdi, Graves Alex, Lillicrap Timothy, Harley Tim, Silver
    David, and Kavukcuoglu Koray. 2016. Asynchronous methods for deep reinforcement
    learning. In Proceedings of the International Conference on Machine Learning.
    1928–1937. Reference [133] Yue Boxuan, Fu Junwei, and Liang Jun. 2018. Residual
    recurrent neural networks for learning sequential representations. Information
    9, 3 (2018), 56. Reference [134] Calheiros Rodrigo N., Ranjan Rajiv, Beloglazov
    Anton, Rose César A. F. De, and Buyya Rajkumar. 2011. CloudSim: A toolkit for
    modeling and simulation of cloud computing environments and evaluation of resource
    provisioning algorithms. Softw.: Pract. Exper. 41, 1 (2011), 23–50. Reference
    1Reference 2 [135] Wickremasinghe Bhathiya, Calheiros Rodrigo N., and Buyya Rajkumar.
    2010. CloudAnalyst: A CloudSim-based visual modeller for analysing cloud computing
    environments and applications. In Proceedings of the 24th IEEE International Conference
    on Advanced Information Networking and Applications. IEEE, 446–452. Reference
    1Reference 2 [136] Casanova Henri, Legrand Arnaud, and Quinson Martin. 2008. SimGrid:
    A generic framework for large-scale distributed experiments. In Proceedings of
    the 10th International Conference on Computer Modeling and Simulation (UKSIM’08).
    IEEE, 126–131. Reference 1Reference 2 [137] Gulli Antonio and Pal Sujit. 2017.
    Deep Learning with Keras. Packt Publishing Ltd. Reference 1Reference 2 [138] Mahmud
    Redowan and Buyya Rajkumar. 2019. Modelling and simulation of fog and edge computing
    environments using iFogSim toolkit. Fog Edge Comput.: Princ. Parad. (2019), 1–35.
    Reference [139] Abreu David Perez, Velasquez Karima, Curado Marilia, and Monteiro
    Edmundo. 2020. A comparative analysis of simulators for the cloud to fog continuum.
    Simul. Model. Pract. Theor. 101 (2020), 102029. Reference [140] Barney B.. 2015.
    Introduction to Parallel Computing. Lawrence Livermore National Laboratory, USA.
    Reference [141] Laghari Asif Ali, Jumani Awais Khan, and Laghari Rashid Ali. 2021.
    Review and state of art of fog computing. Arch. Comput. Meth. Eng. (2021), 1–13.
    Reference [142] Abbas Assad, Khan Samee U., and Zomaya Albert Y.. 2020. Fog Computing:
    Theory and Practice. John Wiley & Sons. Reference [143] Kim Daewoo, Moon Sangwoo,
    Hostallero David, Kang Wan Ju, Lee Taeyoung, Son Kyunghwan, and Yi Yung. 2019.
    Learning to schedule communication in multi-agent reinforcement learning. arXiv
    preprint arXiv:1902.01554 (2019). Reference Cited By View all Barrios C and Kumar
    M. (2023). Service Caching and Computation Reuse Strategies at the Edge: A Survey.
    ACM Computing Surveys. 56:2. (1-38). Online publication date: 29-Feb-2024. https://doi.org/10.1145/3609504
    Kumar R, Sinwar D and Singh V. (2024). QoS aware resource allocation for coexistence
    mechanisms between eMBB and URLLC. Computer Communications. 213:C. (208-235).
    Online publication date: 1-Jan-2024. https://doi.org/10.1016/j.comcom.2023.10.024
    Khiat A, Haddadi M and Bahnes N. (2023). Genetic-Based Algorithm for Task Scheduling
    in Fog–Cloud Environment. Journal of Network and Systems Management. 32:1. Online
    publication date: 1-Jan-2024. https://doi.org/10.1007/s10922-023-09774-9 Show
    All Cited By Index Terms Resource Allocation and Task Scheduling in Fog Computing
    and Internet of Everything Environments: A Taxonomy, Review, and Future Directions
    Networks Network algorithms Control path algorithms Network resources allocation
    Network services Cloud computing Recommendations All one needs to know about fog
    computing and related edge computing paradigms: A complete survey Abstract With
    the Internet of Things (IoT) becoming part of our daily life and our environment,
    we expect rapid growth in the number of connected devices. IoT is expected to
    connect billions of devices and humans to bring promising advantages ... Read
    More From Cloud Computing to Fog Computing: Platforms for the Internet of Things
    (IoT) This article describes how in recent years, Cloud Computing has emerged
    as a fundamental computing paradigm that has significantly changed the approach
    of enterprises as well as end users towards implementation of Internet technology.
    The key ... Read More Resource scheduling methods in cloud and fog computing environments:
    a systematic literature review Abstract In recent years, cloud computing can be
    considered an emerging technology that can share resources with users. Because
    cloud computing is on-demand, efficient use of resources such as memory, processors,
    bandwidth, etc., is a big challenge. ... Read More Comments 143 References View
    Issue’s Table of Contents Footer Categories Journals Magazines Books Proceedings
    SIGs Conferences Collections People About About ACM Digital Library ACM Digital
    Library Board Subscription Information Author Guidelines Using ACM Digital Library
    All Holdings within the ACM Digital Library ACM Computing Classification System
    Digital Library Accessibility Join Join ACM Join SIGs Subscribe to Publications
    Institutions and Libraries Connect Contact Facebook Twitter Linkedin Feedback
    Bug Report The ACM Digital Library is published by the Association for Computing
    Machinery. Copyright © 2024 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics"'
  inline_citation: '>'
  journal: ACM Computing Surveys
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Resource Allocation and Task Scheduling in Fog Computing and Internet of
    Everything Environments: A Taxonomy, Review, and Future Directions'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Wójcicki K.
  - Biegańska M.
  - Paliwoda B.
  - Górna J.
  citation_count: '54'
  description: The fourth industrial revolution taking place in the industrial sector
    is related to the increasing digitization and linkage of goods, products, value
    chains and business models. Industry 4.0 is based on the global connection of
    people, things and machines. By connecting devices and sensors to the internet,
    we are entering a new era of data analysis, connectivity and automation. This
    gives great opportunities for innovation and progress, previously unattainable
    in such a dimension. The term Internet of Things (IoT) has spread along with the
    vision of a world instrumented with intelligent inputs and outputs able to communicate
    with each other through internet data and technologies. IoT is being implemented
    in various areas of the modern economy, for example, healthcare, quality control,
    logistics, energy, agriculture and production. The Industrial Internet of Things
    (IIoT) blazes the trail to a better understanding of the manufacturing process,
    thus enabling efficient and sustainable production. The paper explains the concepts
    of IoT, IIoT and Industry 4.0. It highlights the accompanying opportunities, threats
    and challenges related to their implementation. Additionally, it presents an outline
    of computing architecture in IoT and related energy consumption issues. Moreover,
    it provides examples of application and IIoT research profiling.
  doi: 10.3390/en15051806
  full_citation: '>'
  full_text: '>

    "This website uses cookies We use cookies to personalise content and ads, to provide
    social media features and to analyse our traffic. We also share information about
    your use of our site with our social media, advertising and analytics partners
    who may combine it with other information that you’ve provided to them or that
    they’ve collected from your use of their services. Consent Selection Necessary
    Preferences Statistics Marketing Show details                 Deny Allow selection
    Allow all   Journals Topics Information Author Services Initiatives About Sign
    In / Sign Up Submit   Search for Articles: Energies All Article Types Advanced   Journals
    Energies Volume 15 Issue 5 10.3390/en15051806 Submit to this Journal Review for
    this Journal Propose a Special Issue Article Menu Academic Editors Igor Kotenko
    Jaume Segura-Garcia Subscribe SciFeed Recommended Articles Related Info Link More
    by Authors Links Article Views 6980 Citations 54 Table of Contents Abstract Introduction
    Industry 4.0 Internet of Things (IoT) Industrial Internet of Things (IIoT) Conclusions
    Author Contributions Funding Institutional Review Board Statement Informed Consent
    Statement Data Availability Statement Conflicts of Interest Abbreviations References
    Altmetric share Share announcement Help format_quote Cite question_answer Discuss
    in SciProfiles thumb_up Endorse textsms Comment first_page settings Order Article
    Reprints Open AccessReview Internet of Things in Industry: Research Profiling,
    Application, Challenges and Opportunities—A Review by Krzysztof Wójcicki 1,*,
    Marta Biegańska 1, Beata Paliwoda 2 and Justyna Górna 2 1 Institute of Quality
    Science, Poznań University of Economics and Business, Al. Niepodległości 10, 61-875
    Poznań, Poland 2 Institute of Management, Poznań University of Economics and Business,
    Al. Niepodległości 10, 61-875 Poznań, Poland * Author to whom correspondence should
    be addressed. Energies 2022, 15(5), 1806; https://doi.org/10.3390/en15051806 Submission
    received: 15 December 2021 / Revised: 22 February 2022 / Accepted: 25 February
    2022 / Published: 28 February 2022 Download keyboard_arrow_down     Browse Figures
    Versions Notes Abstract The fourth industrial revolution taking place in the industrial
    sector is related to the increasing digitization and linkage of goods, products,
    value chains and business models. Industry 4.0 is based on the global connection
    of people, things and machines. By connecting devices and sensors to the internet,
    we are entering a new era of data analysis, connectivity and automation. This
    gives great opportunities for innovation and progress, previously unattainable
    in such a dimension. The term Internet of Things (IoT) has spread along with the
    vision of a world instrumented with intelligent inputs and outputs able to communicate
    with each other through internet data and technologies. IoT is being implemented
    in various areas of the modern economy, for example, healthcare, quality control,
    logistics, energy, agriculture and production. The Industrial Internet of Things
    (IIoT) blazes the trail to a better understanding of the manufacturing process,
    thus enabling efficient and sustainable production. The paper explains the concepts
    of IoT, IIoT and Industry 4.0. It highlights the accompanying opportunities, threats
    and challenges related to their implementation. Additionally, it presents an outline
    of computing architecture in IoT and related energy consumption issues. Moreover,
    it provides examples of application and IIoT research profiling. Keywords: Industry
    4.0; Internet of Things (IoT); IIoT; smart grid; Cloud computing; Fog computing;
    Edge computing; Blockchain 1. Introduction One of the fundamental elements facilitating
    societal development and economic growth is energy. In recent years, among other
    things, due to development and dissemination of the Internet of Things, increasing
    energy consumption can be observed [1]. Technology advancements and their growing
    abundance lead to unavoidable energy consumption. The increasing demand for energy
    from industry, commercial and individual customers impacts the energy security
    of countries on every continent. Additionally, the implementation of United Nations
    Sustainable Development Goals creates possibilities for wider IoT applications
    and environmentally friendly solutions in the energy sector. Deloitte Report [2]
    reveals that, “across the world, spending on software and hardware related to
    IoT is projected to grow rapidly, from USD 726 billion in 2019 to USD 1.1 trillion
    in 2023”. According to a recent IoT industry spending report, “Asia/Pacific accounted
    for most of the spending on IoT in 2019, with India spending USD 20.6 billion”
    [2]. Furthermore, Cisco [3] predicted that “there will be 500 billion devices
    connected with the Internet of Things (IoT) by 2030”. According to Microsoft Report
    [3], the growing application of IoT is being observed. In 2019, 85% of surveyed
    companies used IoT technology; in 2020, the rate increased to 91%, while in 2021,
    it was 90%. In total, 90% of these organizations lead one or more projects that
    have already reached the “use” stage. In 2020, it was 83%, while in 2019, it was
    only 74%. The highest percentage of IoT adopters was observed in Australia (96%),
    Italy (95%) and US (94%). The US is leading when it comes to the percentage of
    projects which are in the “use” phase. It was 27% last year. The Italians are
    next with 26% [4]. The applications of next-generation IoT were presented by Zikria
    et al. [5] in their work. Authors found that IoT technology could be applied in:
    smart healthcare, smart cities, smart transportation, smart grid, smart industries
    and smart households. Figure 1 presents the autocomplete data from search engines
    such as Google that contained all the useful phrases and questions people were
    looking for around the keyword “IoT”. Analysis was carried out using “Answer the
    Public” search engine. Figure 1 shows the 56 most frequently asked questions related
    to IoT in the United States. Analysis was carried out on 30 November 2021. Figure
    1. The 56 most frequently asked questions within the IoT in the United States,
    based on “Answer the Public” search engine. For businesses around the globe, IoT
    has already passed the stage of being seen only as an exploratory technology [2].
    The IoT provides industries with multiple opportunities, allowing initiation of
    unique strategies and projects to implement their concepts. Moreover, such industrial
    opportunities lead to “creative and effective examination possibilities for researchers
    and specialists in multi-disciplinary research areas, thus combining research
    studies, engineering abilities, sciences and humanities” [5]. The IoT transforms
    the world into a digital, modern and smart world where everything is readily available
    at hand. To catch up with the trend, industries will need to participate in ventures
    and invest in the IoT technologies [5]. “These new technological advancements
    are making it conceivable to embrace this technology worldwide, while the user’s
    Quality of Experience (QoE) and applications’ Quality of Service (QoS) prerequisites
    are expanding radically” [5]. The future of global manufacturing has permanently
    changed as a result of improvement of smart industries. The transformation has
    increased digitization and influenced manufacturing and distribution processes
    in companies. Adopting IoT appliances in factories not only influences productivity,
    but also has an impact on safety and quality and makes complex advancements more
    efficient and effective. IoT, Artificial Intelligence (AI), Cloud and Big Data
    Analytics (BDA) are known as “big four technologies”, enabling the following:
    connecting organizations, generating data, implementing automation and making
    intelligent decisions based on facts, figures and data. IoT provides tools enabling
    automated data accumulation and generating insights by using sensors, networks
    and analytics. It is the most significant element in the “digital stack”. 2. Industry
    4.0 The Industry 4.0 definition refers to the fourth industrial revolution, Figure
    2. Previous industrial revolutions led to increases in productivity and were driven
    by mechanization (first industrial revolution or industry 1.0), electricity (second
    industrial revolution or industry 2.0) and information technology (third industrial
    revolution or industry 3.0) [6,7]. Industry 4.0 refers to digital transformation
    [8]. It describes changes in manufacturing systems and transformation from “machine
    manufacturing” to “digital manufacturing”, driven mainly by information technology
    [9]. Figure 2. Four industrial revolutions. Simultaneously with the transformation
    of manufacturing models, there was a transformation of the society from “Hunting
    society, through Agricultural society, Industrial society, Information society
    to Super smart society” [10], Figure 3. Figure 3. Transformation of society. According
    to Lasi et al. [9], the transformation to Industry 4.0 is driven by an enormous
    emphasis on applications, resulting in a tremendous need for change due to changing
    operational conditions and huge technological impulses (application-pull and technology-push).
    According to Zheng [7] the transformation to Industry 4.0 is driven by the demand
    for faster delivery, more effective and automated processes, better quality and
    customized products. Key technologies of Industry 4.0 consist of cyber physical
    systems (CPS), IoT, smart factory, embedded systems, sensors, BDA, Cloud manufacturing
    and computing, radio frequency identification (RFID), automation, autonomous robots,
    additive manufacturing, virtual reality (VR), augmented reality, data mining,
    advanced/smart materials, AI, machine learning (ML) and cyber security [11,12].
    Industry 4.0 introduces those technology pillars into core manufacturing processes,
    taking a significant step forward from information technology, including computerization
    or automation of processes that were characteristic of the third industrial revolution
    [13]. Although digital transformation has changed both (the software and the hardware
    side of organizations), not all organizations are digitally mature enough to be
    able to take advantage of the Industry 4.0 technologies [14,15]. The task of the
    fourth industrial revolution is to transform the traditional machines and equipment
    into smart and self-learning devices to boost their efficiency and maintenance
    [16]. The main goal of Industry 4.0 is the creation of collaborative, smart manufacturing
    platforms enabling the implementation of networked information systems [17]. “Real
    time data monitoring, tracking the status and positions of product as well as
    to hold the instructions to control production processes” are the objectives of
    Industry 4.0 [18,19]. 3. Internet of Things (IoT) The concept of the IoT appeared
    at the end of the 20th century and is gaining more and more supporters. It originated
    from radiofrequency technology (Massachusetts Institute of Technology, Cambridge,
    MA, USA, 1999) [20]. By design, IoT is to be universal and easy to use on a massive
    scale. As a rule (simplified to a great extent), IoT is a variety of devices with
    embedded systems connected to the telecommunications network—the internet. They
    have the ability to generate and automatically send information without direct
    human intervention. Their potential is almost unlimited and they are used, among
    others, in economy, medicine and households. IoT mainly consists of Machine-To-Machine
    (M2M) networks, in which intelligent devices can communicate with each other and,
    on the basis of generated and transmitted information, are able to make independent
    decisions [21,22,23,24]. These include, for example, commonly used smartphones,
    intelligent household appliances and electronics, heating and lighting systems
    that can be operated remotely using appropriate applications, but also a machine
    park whose devices connected to the network allow it to be managed from anywhere
    in the plant and/or outside of it [25,26,27]. There are 5 billion IoT devices
    worldwide and forecasts show that this will reach 29 billion by 2022 [24] or 9.27
    billion according to Matsumoto et al. [28]. Different smart technologies such
    as sensors, actuators and intelligent systems can be integrated and enable digitalization
    of organizations and even industries, providing a novel paradigm in business operations.
    This is supported by development of information systems such as Cloud computing
    technologies that provide borderless sharing and access to information. The amount
    of data generated from IoT is enormous and allows organizations to conduct efficient
    analysis [23,29,30]. It plays a significant role not only in a digitalized and
    connected society, but also in industry, healthcare, transportation, etc., and
    the economy as a whole [31]. From small companies to enterprises, all seek huge
    data storage capacity with efficient scalability. This can be achieved by switching
    to Cloud, Fog and Edge paradigms [32]. Computing architecture of these paradigms
    is presented in Figure 4. Figure 4. Computing architecture. Internet of Things
    through the application of different sensors and actuators generates petabytes
    (PB) of data streamed to the Cloud service for maintaining and computing [33].
    As shown in the above figure, Cloud is a data center or server that can be accessed
    from anywhere in the world via the internet such as Microsoft Azure, Google Cloud
    Platform, Amazon Web Services, IBM Watson Cloud or ORACLE Cloud. The Cloud provides
    low-cost, scalable storage and processing capabilities. The term Cloud computing,
    defined by the National Institute of Standards and Technology (NIST), describes
    it as “a model for enabling ubiquitous, convenient, on-demand network access to
    a shared pool of configurable computing resources (e.g., networks, servers, storage,
    applications, and services) that can be rapidly provisioned and released with
    minimal management effort or service provider interaction.” [34]. However, this
    paradigm has its limitations as the data within the Cloud infrastructure needs
    to be provided to the servers for processing and then must be sent back to the
    device. This in turn drastically increases latency [35]. Moreover, Cloud computing
    offers a centralized architecture that results in bandwidth limitations [33,36,37].
    The second tier of computing architecture is the Fog computing. It is as an extension
    of a Cloud. It employs nodes (e.g., base stations, access points, switches, routers,
    gateways) located between the Cloud and Edge tiers [35,36,38]. Thus, it performs
    low-latency computation on the IoT data, routing it to the Cloud for extensive
    data aggregation [39]. The OpenFog defines Fog as a “horizontal, system-level
    architecture that distributes computing, storage, control, and networking functions
    closer to the users along a Cloud-to-thing continuum” [32,40]. The Fog typically
    is located close to the nodes on the local network and offers decentralized architecture
    in Cloud computing. It serves the same purposes as the Cloud, but allows for transferring
    to it only the data for permanent storage, thus reducing the bandwidth [33]. The
    third and bottom layer of the described architecture is Edge computing. Like Fog
    computing, it offers distributed architecture, low latency and bandwidth, but
    high scalability. It uses shared computing and processes information at the Edge
    gateway to the device level, in turn enabling the reduction of the amount of data
    required to be moved to the Cloud. In other words, Edge computing uses Edge devices
    as tools for moving the computing power and intelligence of an Edge gateway. Its
    aim is to offload computational capabilities from the Cloud to the Edge [35].
    Both Fog and Edge computing can operate together with the Cloud, providing better
    latency, data reliability and security and better response times. Stream data
    processing can successfully be performed by distributed Fog and Edge nodes. Whereas,
    big data (batch data) would typically be processed in the Cloud. Edge and Cloud
    systems can be integrated together as the IoT-to-cloud continuum. The communication
    within the described architecture should use standard communication protocols
    such as Open Platform Communications United Architecture (OPC UA). It is used
    for industrial automation in machine-to-machine (M2M) communication [41]. Other
    connectivity standards are, for example, Highway Addressable Remote Transducer
    Protocol (HART), WirelessHart and Data-Distribution Service (DSS) [37]. Cabrini
    et al. [42] investigated a Helix Multilayered platform offering an Industrial
    IoT service platform extending the horizontal digital continuum towards Fog and
    Edge layer based on open standards. They were able to route “context information
    through the near edge and the city’s cloud datacenter”. The vast amount of data
    generated in IoT and transferred to the Cloud requires data management solutions
    such as Big Data Analytics (BDA). BDA processing tools can support or in some
    cases enable real-time problem solving and enhance decision making, thus creating
    a competitive advantage for organizations in constantly changing business environments
    [23,29,30]. On the other hand, IoT solutions require specific databases to support
    data management; NoSQL is an example of such a database. For instance, Google
    has developed the Google IoT framework services, allowing for easy and secure
    data management from devices located globally in real time. Whereas a General
    Electric framework PREDIX aids in functioning (operation, deployment, development)
    of industrial applications in the Cloud and at the Edge [30]. One potential concern
    in wide implementation of IoT is security of information. Blockchain technology
    combined with IoT can overcome this issue. Such a combination of technologies
    can enable a wide range of applications that would increase value chain transparency
    and support Business-To-Business (B2B) trust. A Blockchain is a digital, decentralized
    and distributed data structure (also known as ledger) where data/transactions
    are logged and added chronologically, and shared in a Peer-To-Peer (P2P) network
    providing permanent and tamperproof records [24,30,43]. Blockchain allows for
    vast amounts of IoT-generated data to be aggregated in a centralized or decentralized
    manner. This influences the scalability of IoT solutions. Decentralized Blockchain
    consists of multiple users sharing decision making, whereas the centralized one
    has one central entity as the primary decision-maker. This technology was first
    introduced by Bitcoin cryptocurrency applications, but it can well be employed
    in different industries. Each transaction, file or data (block) has a cryptographic
    hash and is linked to a previous block. Once a block is verified by a certain
    number of network members (nodes), it is then added to previous blocks and forms
    a Blockchain. It usually comprises a shared ledger, permissioning, smart contracts
    and consensus [30]. This technology increases the transparency, security, authenticity
    and auditability of data shared [44,45]. Blockchain technology provides privacy
    protection by encrypting and verifying the data. To overcome block creation time
    shortfall of Blockchain, Ethereum became useful. It is slightly different from
    Bitcoin; however, it enables developers to write smart contracts for Blockchain
    platforms. Due to which, it is possible to customize Blockchain towards desired
    applications. In other words, Ethereum makes possible the configuration of IoT
    devices and authentication of operations management in public key infrastructure.
    Today, Blockchain technology is slowly entering non-currency domain usage [25].
    4. Industrial Internet of Things (IIoT) 4.1. Research Profiling The purpose of
    a systematic literature review is to gain an understanding of the existing research
    and share the results of other studies relevant to a particular topic or area
    of study. The most universal method for finding the relevant literature is keyword
    searches. A graphic visualization using VOSviewer software (Leiden University,
    Leiden, The Netherlands) showing co-occurrence networks is presented in Figure
    5. Figure 5. Network resulting from the Scopus bibliometric data analysis. Source:
    own work based on obtained Scopus metadata [46]. The research profiling was conducted
    in Scopus database (www.scopus.com; accessed on 16 October 2021) according to
    “Article title, Abstract, Keywords” in October 2021. No temporal restriction was
    chosen [47]. The choice of Scopus was based on the knowledge that it is more comprehensive
    than Web of Science, which encloses only International Scientific Indexing (ISI)
    journals [48]. The selected keyword, which was “IIoT” allowed us to find 3815
    papers from 2010 to 2021, as seen in Figure 5. The metadata of the papers were
    then exported in a CSV format to gather necessary data for further analysis. VOSviewer
    software was used for bibliometric analysis at the macro-level [49]. As shown
    in Figure 5, it enabled structuring and visualization of the co-occurrence networks
    based on the most important terms extracted from the metadata. In our analysis,
    we have set a threshold of minimum number of occurrences of the IIoT keyword to
    5. This allowed the retrieving of 1053 keywords meeting this threshold of the
    total 14,444 keywords. Then, for each of the 1053 keywords, the total strength
    of the co-occurrence links with other keywords was calculated. The keywords with
    the greatest total link strength were selected. The obtained results from the
    sample with the keyword Industrial Internet of Things (IIoT) had 1811 occurrences
    and IIoT had 295 and Industrial Internet of things had 277. Their total link strength
    was 15,350, 2586 and 2946, respectively. With the least occurrences equal to 5
    were such keywords as: public works, process industries, power plants, practical
    swarm optimization and diverse applications. These also had the lowest total link
    strength, amounting to 41. With the help of VOSviewer software, a two-dimensional
    map was created (Figure 5). In this co-occurrence network, keywords with high
    relevance are automatically grouped together into clusters with different colors
    and sizes of nodes for better data visualization. The relationships between each
    node are shown as curved lines [50]. Analysis of the terms in each of the eight
    obtained clusters allowed for subject area recognition as shown in Table 1. In
    some clusters, more than one subject area was referred to. Table 1. Cluster analysis
    based on Scopus bibliometric analysis [46]. The IIoT presented as the largest
    red node was linked to terms such as: Industry 4.0, network security, edge computing,
    cryptography, deep learning, reinforced learning, interoperability, resource allocation
    scheduling, IEEE standards or blockchain and many more. This shows how vast and
    broad are the correlations related to IIoT keyword. The year 2011 was the first
    time the “IIoT” keyword was used by Chen et al. [51]. After ten years, the number
    of publications with IIoT keyword has rapidly increased. In 2020, there were 1248
    documents while in 2021 (until October 2021), there were 1134. This suggests that
    the IIoT topic is gaining interest today, as seen in Figure 6. Figure 6. Publishing
    trend of the sample based on Scopus bibliometric analysis [46]. Keyword “IIoT”.
    The next step was to compare the document counts for five sources with the largest
    number of published articles. The results are presented in Figure 7. The largest
    number of published documents (with IIoT keyword) is in IEE Transactions on Industrial
    Informatics journal, with 255 papers. In 2018, they had 35 published documents
    while in 2021, it was 147. The IEEE Internet of Things Journal is also very popular,
    with 179 published documents. The first two documents were published in 2017.
    In 2021, they had 105 published documents. The first publication about IIoT was
    published in 2016 in Lecture Notes in Computer Science. Until October 2021, 124
    documents were published in that journal (41 documents in 2021). The IEEE Access
    has 119 published documents. In 2018, they had 17 documents, while in 2021, it
    was 39. The last journal is Sensors; until October 2021, they had 76 published
    documents. Figure 7. Top five sources based on Scopus bibliometric analysis [46].
    Keyword “IIoT”. Next, we compared authors and co-authors of IIoT-related publications,
    as seen in Figure 8. Gidlund M. (Sweden) published the largest number of documents
    with IIoT keyword. It was 21 documents in Scopus (first in 2018). Kumar N. (India)
    is in the second place with 18 documents in Scopus. The top 10 authors altogether
    published 155 documents in Scopus. Figure 8. Number of published documents sorted
    by authors based on Scopus bibliometric analysis [46]. Keyword “IIoT”. Conducting
    a comparison of the published documents by type of document enabled us to spot
    that nearly half (49.4%) of the published documents were conference papers. Articles
    and book chapters accounted for 45.7%. There were 1647 published articles (43.3%)
    and 86 book chapters (2.3%). Review (82 documents) and conference review (40 documents)
    consisted of a total of 122 publications (3.3%). List of all published documents
    sorted by type is presented in Figure 9. Figure 9. Documents type trend of the
    sample based on Scopus bibliometric analysis [46]. Keyword “IIoT”. The comparison
    of documents by country or territory is presented in Figure 10, which shows that
    825 published documents were from China. The United States are in second place
    with 526 documents. Germany has 365 published documents, while India has 341.
    Figure 10. Top 10 countries of the sample with the largest number of publications
    based on Scopus bibliometric analysis [46]. Keyword “IIoT”. 4.2. Application of
    IoT in Industry IoT application in industry leads to the creation of Smart Factories
    where almost all objects such as machinery, devices and products are equipped
    with sensors connecting each to each and to the Internet [52]. Industrial IoT
    is one of the most demanding applications [42]. This in turn provides advanced
    visibility into operations through real-time access to information. In this novel
    environment, manufacturing equipment and other devices can communicate their real-time
    performance and improve productivity, efficiency and quality by providing a high
    level of responsiveness and flexibility at the process level [23]. In 2017, the
    global IIoT market was valued at USD 312.79 billion with the prediction to reach
    USD 700.38 billion by 2023 [53]. Typically, unlicensed bands of 2.4 GHz are used
    in IoT where several technologies compete for spectrum access. However, there
    is no inter-technology coordination mechanism due to which there is mutual interference,
    which in turn discourages implementation of industrial monitoring and control.
    The above-mentioned 2.4 GHz unlicensed band offers a free 85 MHz wide spectrum
    worldwide. This has led to increased usage of wireless standards such as Bluetooth
    Low Energy (BLE), IEEE 802.11 and IEEE 802.15.1 on an enormous scale. Process
    automation domain in IIoT uses the IEEE 802.15.4 physical layer on which WirelessHART
    and ISA 100.11a leading wireless standards are based [54,55,56,57]. IoT at the
    industrial level leads to the creation of fully automated production systems,
    together with Cloud systems and BDA enabling improved analysis of market demand
    patterns, thus significantly improving planning and production control. This in
    turn contributes to the rapid customization of products at the individual or local
    level [23]. Selected industry sector categories with the potential for IIoT implementation
    are presented in Figure 11. Figure 11. Selected industry sector categories [21].
    As the manufacturing environment has changed over the past decades, along with
    it new business models have developed Industrial Product-Service Systems (IPSS).
    They shift business from simply selling products, thus generating profits, to
    selling functionalities. In the IPSS model, industrial products and services are
    delivered consistently, which in many cases requires BDA coming from different
    sources such as the IoT devices. The IIoT solutions take into account both technical
    details of product production and the stakeholders being part of the IPSS business
    model. In that sense, they allow for dynamic adoption to constantly changing consumer
    demand and manufacturing abilities [29]. Industrial internet concept originated
    in the United States and was first mentioned by General Electric, whereas the
    concept of Industry 4.0 itself originated in Germany. The two concepts are not
    identical, but indeed they overlap. “Industrial Internet of Things: A system comprising
    networked smart objects, cyber-physical assets, associated generic information
    technologies and optional cloud or edge computing platforms, which enable real-time,
    intelligent, and autonomous access, collection, analysis, communications, and
    exchange of process, product and/or service information, within the industrial
    environment, so as to optimize overall production value.” [21]. IIoT is an extension
    of IoT technology, providing industry with a set of tools used in creating its
    competitive advantage. It serves the industry and therefore has to meet much stricter
    requirements than in the case of consumer domain. Usually, an IIoT architecture
    model (Figure 12) consists of several layers with different sets of networks [58].
    IIoT through the use of sensors and actuators within an organization, through
    data collection, analysis and exchange, enables machines (embedded with sensors)
    to change their own mode of action or to indicate other devices to do so without
    the need for human action. Moreover, it can support human decision making based
    on collected data in real time, but also by the ability to store that data, to
    use them for periodic assessment and/or maintenance prediction. Figure 12. IIoT
    architecture model [58]. Despite many possibilities of use, the IIoT faces barriers
    (e.g., security issues, non-scalable systems and interoperability challenges)
    that can be addressed by IIoT reference architectures. We mention only three:
    Reference Architecture Model Industrie 4.0 (RAMI 4.0), Industrial Internet Reference
    Architecture (IIRA) and Internet of Things Architecture (IoT-A). Sensors and actuators
    (e.g., position, motion, biosensor, mass/volume measurement and environment) connected
    to different devices and to the internet are an essential source of ubiquitous
    production data in IIoT [29]. Such sensors, together with energy balance sheets
    and smart embedded devices, can support energy monitoring in order to aid manufacturing
    decision making using real-time online data [59]. One of IoT and IIoT technological
    solutions is RFID tags and sensors. RFID technology is based on data collection
    and automatic object identification via radio waves, where a tag transmits its
    identity to the tag reader. The tag can be either attached or embedded to a device
    or product and is equipped with a microcircuit with a unique code and/or a set
    of information. The tag reader has an antenna emitting radio waves and the tag
    sends back its data to the reader. Collected data are sent and grouped in an information
    management system including a server connected with a database and software that
    can be connected with Enterprise Resource Planning (ERP) programs [60,61]. The
    use of RFID tags can enhance transparency in the supply chain by providing tools
    and products for real-time tracking system. Those tags can also be used for real-time
    traceability of resources, thus improving inventory management, but also for the
    machines at production lines to detect variations in production or assembly performance
    [23,24]. Such innovations are already being implemented in industry where machines
    monitor and control assembly parts’ speed and status, and send information to
    the next operators with specific instructions on how and when to put elements
    together via digital displays [20,62]. Other RFID applications in manufacturing
    and supply chain management are presented in Figure 13. Examples of industry branches
    that already exploit RFID technology include automotive, car parts, machine, heavy
    industry, electronic, food industry, pharmaceutical industry and many others [60].
    Utilization of RFID also assists in anti-counterfeit approaches through product
    traceability, ensuring high supply chain visibility and product authentication.
    In addition, RFID tags become part of the product moving through the supply chain
    to the point of sale. However, although RFID technology is well known and low
    cost, it is not the only tool building up Industrial IoT. Other components with
    the ability to link real world with the digital one are Near Field Communications
    (NFC) and Wireless Sensor and Actuator Networks (WSAN) [61]. Figure 13. RFID applications
    in manufacturing and supply chain management [60]. RFID tags and ML algorithms
    were investigated by Sharif et al. [63] for food contamination detection. The
    study was conducted using sticker-type inkjet printing UHF RFID tags. The obtained
    backscattered power from food samples and contaminated food samples was compared
    and used as input data to the machine learning algorithm. At first, samples of
    water contaminated with known amounts of salt and sugar ranging from 2 to 10 g
    per 500 mL PET bottle were prepared and UHT RFID tags were attached. Received
    Signal Strength Indicator (RSSI) of samples was measured. The RSSI values (dBm)
    increased with increasing salt or sugar concentrations in the samples. The next
    step was to prepare spring water samples with added known amounts of sugar/salt.
    The contamination was sensed with 90% accuracy. The obtained RSSI data were used
    as input for ML XGBoost algorithm to improve sensing accuracy. The authors used
    a commercial handheld UHF RFID reader-based setup that was connected via BLE with
    a smartphone provided with a preinstalled Android application, for water contamination
    sensing. The implementation of IIoT reduces human errors, time and maintenance
    costs, among others, as it allows for collecting, analyzing and storing data consistently
    to avoid machinery faults, maintenance prediction and customization [24,29]. Moreover,
    Industrial IoT solutions reduce manufacturing costs through optimized assets and
    inventory management, also reducing machine downtime and contributing to the monitoring
    and controlling of workplace environment. In manufacturing, this is a shift from
    reactive to proactive maintenance of equipment that relies on collected and analyzed
    data allowing for prognostics rather than diagnostics after the device’s failure
    [26]. Additionally, use of IoT (e.g., RFID tags, barcodes, Quick Response (QR)
    codes, NFC) can facilitate warehouse inventory management. When a product or product
    packaging equipped with an RFID tag moves through an RFID reader installed on
    the warehouse gate and/or racks, etc., the data of the inbound and outbound item
    are collected and stored and the warehouse inventory database is updated. Whenever
    the item moves within or outside the warehouse, it is easy to track and trace
    it automatically [57]. Moreover, some warehouse operations, thanks to IIoT, can
    be performed without human intervention by means of Automated Guided Vehicles
    (AGVs) [22]. Thames Water (the largest provider of drinking water and wastewater
    service in the UK) installed over 100,000 sensors in London for real-time data
    gathering and analytics. The aim is to cover all customers in London by 2030 [27].
    This IIoT solution allows for anticipating equipment failures and enables fast
    response in crisis situations. IIoT devices have been installed as well at the
    Mitsubishi plant in Kashima (Japan), producing chemicals for real-time process
    management. This allowed for increase of production performance. Furthermore,
    mining industries also benefit from implementing IIoT solutions. Different sensor
    and real-time data collection and analysis make mining in difficult locations
    more economical and productive, but also support decrease of safety incidents
    [27]. IoT technology also has applications in the food sector, where it helps
    in improving process control and optimizing the decision-making process. The so-called
    Agriculture 3.0 implements IoT for precision agriculture that, among others, includes
    the utilization of sensors for nutrients control and monitoring, growth patterns
    and disease as well as pesticide or fertilizer application control. The development
    of novel information technologies has led to Agriculture 4.0 which uses satellite
    data to precisely control field operations, sensors and computers to optimize
    the production process in glasshouses, introduces robotic milking and improves
    traceability. Smart irrigation systems include the monitoring of soil moisture
    and humidity sensors connected with a microcontroller that obtain weather reports
    from the internet and are able to measure the probable time of the next irrigation.
    Modern, digitized farms are equipped with sensors monitoring various soil parameters
    (e.g., moisture content, pH, humidity), which support process control and decision
    making. Passive infrared (PIR) sensors are used in intruder detection systems,
    allowing for repelling of birds and rodents in the fields [63,64]. Wireless Sensor
    Networks (WSN) are cost efficient as they eliminate the necessity of using cables.
    To overcome the access to the internet infrastructure, power grid solar panels
    can be utilized [65,66]. Companies such as AT & T, Microsoft, Climate Corp. or
    Monsanto are promoting IoT in agriculture which provides additional support for
    the development of this technology [27]. Combining Industrial IoT with Blockchain
    gives additional benefits as it provides greater transaction transparency and
    supports product traceability in the case of recall or counterfeit products. This
    is extremely important, i.e., in counterfeiting of electronic parts that can cause
    potential safety risk and loss of company profits and also damages the reputation
    of manufacturers [45]. Maersk and IBM cooperated to implement Blockchain in solving
    cross-border supply chain problems. This increased information transparency and
    information sharing between partners was carried out [43]. Esmaeilian et al. [30]
    give examples of Blockchain application in the food sector, such as an IBM and
    Brooklyn Roasting Company project that enabled consumers to follow the product’s
    journey through the entire supply chain. Another one mentioned is the BeefChain
    platform simplifying the tracking of beef in Wyoming (USA) being raised in open
    range conditions [30]. Rising consumer demand forces manufacturers to provide
    more and more information, including information related to allergens, ingredients,
    provenance, traceability or processing method. The Blockchain technology supports
    access to relevant and authentic (tamperproof) data that can be coded in the form
    of a barcode or QR code placed on the primary packaging. Consumers can scan such
    a code with their smartphone to access information. It is also worth mentioning
    that these solutions are also implemented in containers for refrigerated biopharmaceuticals
    to monitor temperature, humidity and location [24]. Smart devices connected to
    the internet through smart equipment such as smartphones and tablets can communicate
    with the controller and send alarms each time a deviation from variables’ acceptable
    limits occurs. This allows for taking quick actions regarding process control
    and supports maintenance of the product quality. Perishable food products are
    usually transported in a specific temperature regime and when temperature monitoring
    sensors are used for such transport they have the ability to monitor and even
    regulate the temperature if it deviates from acceptable limits. They can also
    inform food suppliers in case of failure, thus preventing quality deterioration,
    spoilage and food and economic losses [60]. The possibilities of the IIoT are
    endless, and it is only a matter of time before they are implemented on a massive
    scale. 4.3. Challenges of Internet of Things in Industry During the global financial
    crisis caused by the pandemic situation (COVID-19), more and more industrial companies
    are transferring to the IIoT. These companies want to be able to remotely monitor
    their systems and prevent unplanned downtime. A survey by Microsoft [4] found
    that 44% of organizations will invest more in IoT while in 2020 it was 31%. Moreover
    “82% of surveyed companies have at least one IoT project in the use stage”. IoT
    is changing the future of manufacturing, but it does carry major challenges that
    companies will have to face in order to be able to implement the new solutions,
    which will accelerate their digital transformation. Below we listed some main
    challenges that companies have to face in their implementing phase of Internet
    of Things. Technical and technological challenges The complexity and technical
    challenges are the biggest barriers for companies that want to exploit the IoT.
    For these reasons, 30% of surveyed organizations decide against adopting IoT [4]
    in favor of using current solutions. Connecting together so many devices is a
    serious challenge of the IoT/IIoT. Today, we rely on the centralized, server/client
    paradigm to authorize, authenticate and connect different nodes in a network.
    For an interconnected system, devices should work together to function properly,
    even if these devices work in different fields. A lack of common connectivity,
    standard data formats and common software interfaces complicates implementation
    of IoT. Another challenge is costly retrofitting or replacement of the traditional
    devices to work with the latest technologies [67]. Most of the IoT devices are
    powered by batteries, so IoT must also deal with high energy consumption. Expenses
    related to servicing and/or replacement of such devices are a serious concern
    due to the fact that in the future a huge number of sensors will be used. Without
    appropriate maintenance and life cycle assessment consideration, sooner or later
    they may become electro-rubbish. Even today, the number of devices connected to
    the internet outnumbers the human population. Another challenge is to develop
    high-energy-efficient and long-life sensor batteries which will operate over the
    lifetime of a sensor [68,69], and define responsible methods of their reprocessing
    at the end of their life. The high amount of data produced via the IoT has a crucial
    role in the big data landscape. Millions of devices are equipped with sensors
    connected together, communicating, collecting and exchanging data. These devices
    collect a huge amount of data which is known as Big Data. The significant challenge
    will be ensuring appropriate handling of these various types of data, in particular
    in time, resources and processing capability shortages. According to Said and
    Masud [70], the biggest concern is related to the growing amount of information
    which is generated through RFID. Each object in the IoT produces information about
    itself. This information (in a massive quantity) must be collected and then processed,
    which can cause problems in transmission and storage of data that accelerate every
    day. As mentioned in [71], “80,000 petabytes of data were stored across the world
    in 2000, and this is predicted to rise to 35 zettabytes by 2020”. The different
    types of data such as structured data, semi-structured data and unstructured data
    which come from sensors are collected and analyzed by Big Data and stored in a
    data warehouse. Only 20% of that data is processed while 80% cannot be used by
    traditional methods. Most of these data are useless for decision-making processes
    [43]. Layers of intelligence are required to transform that tremendous amount
    of data collected by devices connected to the internet into wisdom [69]. Another
    challenge is to “adjust structures in semi-structured and unstructured data before
    integrating and analyzing these types of data” [72]. b. Lack of budget and knowledge
    When building the IIoT, it is necessary to bear in mind its future updates and
    maintenance. IIoT, which is a tangled network of interconnected devices, poses
    a considerable challenge to system operators. They will not only have to manage
    the original system, but also administer all new systems. Training engineers takes
    a long time, especially since most user interface management systems (UIMSs) are
    not dedicated to industrial automation. Management tasks are very different and
    require different tools. Manually configuring the network can add to human error
    and add hours of work. Moreover, it involves additional costs for the company
    through hiring digital transformation specialists and engineers and training them
    in the use of systems (to improve the speed of response to errors). According
    to Microsoft’s IoT Signals Report [4], 26% of organizations reported that a lack
    of budget and staff were at the top of the reasons for holding off on IoT adoption.
    Companies complain that it is hard to find the right skilled and experienced employees.
    In total, 26% of companies that have already adopted IoT said that they still
    do not have enough skilled workers, and 24% of organizations reported lack of
    technical knowledge. c. Information security and data protection challenges One
    of the IoT adoption barriers is corporate concerns about information security
    and privacy. Almost a third (29%) of organizations believe that security risks
    prevail over benefits of implementing the IoT [3]. Basically, billions of interconnections
    between devices and people and data exchange cause huge risk of data leakage.
    Due to the ubiquity and pervasiveness of IoT systems, inevitable problems with
    privacy and security in the network will arise. From the point of view of the
    development and expansion of the IoT, it is crucial to ensure data protection
    and information security in various activities, such as transport services, personal
    activities, processes or information protection. This is a significant matter;
    a lot of research has been done, but there are also services related to current
    trends in the IoT security system [61]. Various services have presented some of
    the challenges, as they are not designed with security in mind, and can potentially
    become attack vectors to various IoT devices and device guards [73]. According
    to Siby et al. [74], today it is hard to manage the security of IoT organization
    and businesses while various privacy threats emerge, which can penetrate IoT and
    its network. Organizations need to develop scanning and monitoring systems for
    all types of IoT devices that could be at risk of information privacy and security
    breach. Analyzers and traffic interceptors help identify and investigate various
    cyber threats. One of the major types of cyber-attacks is called the “False Data
    Injection” (FDI) attack. An FDI attack corrupts sensor measurements; as a result,
    the device mislead the industrial platform [75]. In order to prevent outside malicious
    attacks, the following security systems can be used: encryption to ensure data
    confidentiality and message authentication codes to ensure data integrity and
    authenticity [76]. However, the encryption does not protect against “insider attacks”.
    Such attacks pose a serious threat for wireless sensor networks. Different IoT
    wireless network attacks and detection possibilities were presented by Pamarthi
    and Narmadha [77] and Balogh et al. [78]. Security in the cloud is the next significant
    area of research which will need more consideration. This is due to the fact that
    businesses will use hybrid clouds which contain private as well as public clouds.
    For this reason, security and protection become very important to prevent cyber-attacks
    [79]. Abomhara and Koien [80] proposed a series of security components contributing
    to the improvement of IoT security. The authors mentioned also that there are
    many security and privacy challenges, such as the following: “user privacy and
    data protection, authentication and identity management, trust management and
    policy integration, authorization and access control, end-to-end security, attack
    resistant security solutions”. The above-mentioned issues are significant for
    IoT development. To overcome those challenges, several solutions have been developed,
    such as the anonymous orthogonal code-based privacy preserving scheme for cyber-physical
    systems. It uses, among others, orthogonal bit codes for user privacy, authentication
    and anonymity while at the same time it provides low communication and computation
    overheads [81]. Tawalbeh et al. [82] said that implementation of existing information
    security concepts in IIoT systems is not so easy. The authors proposed to implement
    security in multiple layers, starting from the device level to the system level.
    To ensure that real-time communication and control processes (10–100 ms cycle
    duration) are not disrupted, security countermeasures are required in IoT. However,
    solutions used in IT systems such as malware detection software are insufficient
    [28]. In typical IIoT, symmetric-key cryptography can provide a lightweight solution
    [83]. This, however, can be insufficient when low-capacity devices are used. Ali
    et al. [84] proposed a symmetric encryption scheme to tackle this problem. This
    solution allowed one to obtain user privacy and integrity while using lower computing
    resources and communication overhead. Another security solution is Elliptic-Curve
    Cryptography (ECC) which provides smaller key size, thus reducing storage and
    transmission requirements [27]. Another solution for securing data within IoT
    is steganography. According to Djebbar [85], such systems “manipulate the characteristics
    of digital media files to use them as carriers or covers” (e.g., images, audio,
    video, text, protocols or storage devices) in order to hide secret information
    (payload). The payload itself is hidden in any type of digital cover. It uses
    a key for securing data and produces a stego file (blind steganalysis). As different
    control systems used in IoT need to operate 24 h a day, all year round, and have
    a service life of 5–10 years, security updates become a challenge. They cannot
    cause system malfunctions, and unlike in IT systems, updates cannot result in
    the system being stopped and restarted [28]. d. Scalability As mentioned before,
    the IoT and IIoT are composed of an enormous number of devices. Those devices
    are usually connected one to another in hierarchical subdomains rather than in
    a mesh. This in turn results in the number of connected objects being significantly
    greater than the current internet. The complexity of such architecture is an obstacle
    for scalability. To overcome this challenge, retaining technologies very simply
    in the network and dealing with complexity at the end point should be implemented
    [56,86]. This could be achieved with a scheme that identifies, addresses and names
    a large number of devices and that will support and scale with them [58]. e. Interoperability
    of the IIoT environment Key to the IIoT interoperability is the standardization
    and adoption of protocols that define the details of communication between devices.
    Interoperability means that any device is able to connect to another device or
    system and exchange information. However, it is not always possible for all production
    aspects, required or wanted. In some cases, within the IIoT, it is necessary in
    order to achieve interchangeability between devices from different vendors. However,
    when interoperability is thought of as using the IP protocol, it does not ensure
    that devices from vendor A and vendor B can be interoperable [58]. f. Standardization
    issues Standardization issues play a key role in the development and dissemination
    of the IoT and IIoT. There are still overlapping activities and fragmented efforts
    of different providers around the world. Standardization would lower entry barriers
    and allow for better performance of products/services. Standardization of, e.g.,
    functionalities or requirements should be carried out at an international level
    in order to enable easier integration of various services [27,56,58]. The aforementioned
    fragmentation was brought about by the European Telecommunications Standards Institute
    (ETSI) technical report ETSI TR 103375. This report aimed at providing roadmaps
    of IoT standards. Moreover, International Electrotechnical Commission (IEC) set
    up study groups and technical committees on IoT standardization and also published
    several white papers on IIoT [27]. An IEC 62657-2:2017+AMD1:2019 standard specifies
    the fundamental assumptions, concepts, parameters and procedures for wireless
    communication coexistence, as well as its availability and performance in an industrial
    automation plant. It also provides a common point of reference [87]. g. Legal
    and regulatory security Legal and regulatory security is understood as compliance
    by IoT devices with legal standards regarding, for example, the admissibility
    of processing specific information and compliance with the regulations of the
    EU and other countries. For example, there are no separate and detailed regulations
    for IoT technology in the Polish legal system. IoT regulations are scattered throughout
    many legal acts (including General Data Protection Regulation (GDPR), telecommunications
    law and sector secrets, but also Network and Information Security directive (NIS
    directive)), which often grant administrative or supervisory authorities the power
    to impose severe financial penalties. Although an EU Regulation 2018/1807 of the
    European Parliament and of the Council of 14 November 2018 on a framework for
    the free flow of non-personal data in the European Union (text with EEA relevance)
    has been adopted, it does not respond to the challenges of using anonymous data
    in IoT [88]. 4.4. Opportunities of Internet of Things in Industry Quality assurance
    (43%) and cloud security (42%) are major motivators that cause companies to implement
    IoT [4]. Other factors for IoT adopters are issues related to device security
    (40%) and operations optimization (40%). Over one third of enterprises also adopt
    IoT to improve products and services for customers [4]. There are many benefits
    for organizations which adopt IoT. Based on the Microsoft [4] report, the most
    important are: “increased efficiency of operations (55%), improved safety conditions
    (51%) and increased employee productivity (50%)”. Enterprises also noticed that
    IoT implementation gave a return on investment through better productivity, increasing
    production capacity, reducing human mistakes and reducing expenses. IoT can also
    boost customer satisfaction and increase opportunities for organizations based
    on more informed and better decisions. Below, we list some main opportunities
    for implementing IoT in industry. Software development The proper software for
    the collection of data by IoT devices, and then their analysis, could improve
    efficiency and reliability [89]. b. Energy Consumption Industrial IoT can become
    a major player in controlling energy consumption. It can contribute to minimizing
    energy consumption and optimizing its production. A lot of energy is consumed
    to produce the final product and to ensure its good quality in traditional factories.
    Moreover, human resources are needed for controlling every single process and
    operation of production. For this reason, actions should be taken to avoid wasteful
    energy consumption in production processes [36]. Various technological solutions
    such as Green IoT are proposed by Xu et al. [90]. Cloud platforms, gateway devices,
    web servers and IoT hub networks, which are accessible with smart mobile devices,
    could be used as monitoring equipment. Wired and wireless communications (Bluetooth,
    WiFi, ZigBee, etc.) can be used to connect together different devices. Moreover,
    the smart sensors may be installed on each device in the smart factory, which
    will detect higher energy consumption of the components, exceeding set limits
    [36]. Another opportunity will be the development of low-power sensing units.
    The new compact and efficient batteries, energy-generation devices and fuel cells
    will be the key factor for the implementation of autonomous wireless smart systems.
    [91]. The concept of green Sensors On a Chip (SoC) could be used to reduce energy
    consumption of the entire infrastructure (traffic, e-waste, carbon footprint)
    [92,93]. Another example which enables the reduction of energy consumption by
    adjusting power transmission to minimum level and using more efficient communication
    protocols is green M2M [36]. In contrast to the Low Power Wide Area Networks (LPWANs),
    they are developed to be low cost, with low energy consumption and operating over
    a wide transmission range. They rely on limited energy sources that need to be
    either replaced or recharged. Peruzzi and Pozzebon described energy harvesting
    techniques for Wireless Sensor Networks (WSN) [94], whereas Elahi et al. [95]
    presented different energy harvesting methods (e.g., mechanical energy harvesting,
    aeroelastic energy harvesting and others). The application of blockchain in the
    energy sector will improve IoT efficiency by providing a decentralized platform
    for distributed power generation and storage system, which will enhance energy
    efficiency and security. Blockchain also enables energy distribution between devices
    and remotely controls energy flow to the particular area. People will have direct
    access to energy information with no involvement of third parties [96]. Smart
    Grid (SG), Electricity System Network (ESN), and IoT nodes may be potential solutions
    to the upcoming global energy crisis [97]. The SG framework, combined with IoT
    and Energy Internet, can be used in various applications related to energy. Smart
    grid is a bidirectional grid which allows for power and information flow. The
    recent era has brought growing energy consumption worldwide and, as a result,
    increased fossil fuel burning. Environment concerns led to introduction and development
    of Renewable Energy Sources (RES). Making these solutions more abundant and available
    to consumers has changed their role on the energy market to prosumers. Now, consumers
    not only consume energy, but are also producers of energy to the grid. In addition,
    individual consumers are not only consuming energy provided by the energy sector,
    but also contribute to the energy production which is made available commercially
    and for industrial purposes. Implementing IoT in the smart grid environment aids
    monitoring and control of the power system in real time. Tightiz and Yang [98]
    describe different communication protocols in the smart grid such as Common Object
    Request Broker Architecture (COBRA), Advanced Message Queuing Protocol (AMQP),
    Open Platform Communications United Architecture (OPC UA), Data Distribution Services
    (DDS), Message Queue Telemetry Transport (MQTT) and Constrained Application Protocol
    (CoAP). Energy harvesting is a major player when it comes to the increase of the
    efficiency and lifetime of IoT devices [95]. To minimize the power draining of
    the batteries, a crucial role is played by power management integrated circuits,
    which help increase the system’s life span. The concept of Internet Nano-Things
    (IoNT) discussed by Elahi et al. [95], shows that in the future IoT devices might
    be the self-powering sources which will make high-performance nanosystems. c.
    Connectivity Sensor technology will continue to become more efficient, cheaper
    and widely available, which will lead to the application of sensors on a large
    scale for monitoring and detection. Moreover, many wireless standards, which are
    used today, are optimized for human-to-human applications, so another opportunity
    will be making clusters of the machines [69]. 5. Conclusions The revolution of
    the IoT keeps going forward; this means that we are at the beginning of a new
    age of data. This revolution will have a significant impact on the day to day
    life and behaviors of users, both private and corporate. IoT applications will
    expand in various industries, improving them and bringing tangible benefits. The
    opportunities offered by IoT implementation will mean that all affected sectors
    can now access functionality that did not exist a few years earlier. IoT applications
    can affect, among others: automation of industrial production, logistics, management
    of individual processes and enterprise management, as well as transport through
    the development of an intelligent system for transporting people and goods. Industrial
    Internet of Things, as confirmed by the profiling research, enjoys constant interest.
    It is also important that these solutions enable unmanned work and limit human
    work, especially in places where manpower could be exposed to dangerous factors
    (work in a mine, at heights, underwater at great depths, etc.). IoT is in the
    early stage of development, and despite the many benefits and opportunities it
    brings, it faces challenges, barriers and risks. The concerns related to the implementation
    of IoT are not unfounded. Each organization must ask itself whether the benefits
    of implementing IoT outweigh the challenges associated with it. Moreover, as with
    most new technologies it is subject to certain rules; in particular, the technology
    adoption life cycle. As IoT is in the diffusion growth phase, innovators and early
    adopters have already paved the way for other organizations which need complete
    and reliable solutions to implement IoT. From our analysis, the image of IoT diffusion
    is shaped in a way in which the benefits and opportunities for companies resulting
    from the implementation of this technology are recognized. At the same time, participants
    of the so-called early market experienced problems with the implementation and
    operation of IoT. These limitations and barriers currently stand in the way of
    faster diffusion of IoT, but on the other hand, there are more and more research
    studies and solutions that tackle these issues. It will take time to overcome
    these problems, and mistakes and failures will occur along the way. However, all
    of us will benefit from IoT to a greater or lesser extent. It will have impacts
    on our everyday life and lifestyle and reduce human errors in many activities.
    Author Contributions K.W. was involved in project administration and supervision.
    K.W., M.B., B.P. and J.G. were involved in funding acquisition, conceptualization,
    writing the initial draft of the paper, and revisions. K.W., M.B. and B.P. contributed
    to data collection and revisions. K.W. and M.B. were involved in writing the paper,
    editing, designing the figures and the layout of the paper. B.P. and J.G. were
    involved in commenting on the content and its relevance to the scope of the journal.
    All authors have read and agreed to the published version of the manuscript. Funding
    This research was funded by the project Economics in the face of the New Economy
    financed within the Regional Initiative for Excellence programme of the Minister
    of Science and Higher Education of Poland, years 2019–2022, grant no. 004/RID/2018/19,
    financing 3,000,000 PLN. Institutional Review Board Statement Not applicable.
    Informed Consent Statement Not applicable. Data Availability Statement Not applicable.
    Conflicts of Interest The authors declare no conflict of interest. The funders
    had no role in the design of the study; in the collection, analyses, or interpretation
    of data; in the writing of the manuscript, or in the decision to publish the results.
    Abbreviations Alphabetical list of abbreviations used within the text: AGVs Automated
    Guided Vehicles AI Artificial Intelligence B2B Business-to-Business BDA Big Data
    Analytics BLE Bluetooth Low Energy CPS Cyber Physical Systems ECC Elliptic-Curve
    Cryptography ERP Enterprise Resource Planning FDI False Data Injection IEEE Institute
    of Electrical and Electronics Engineers IIoT Industrial Internet of Things IoT
    Internet of Things IoT-A Internet of Things Architecture IIRA Industrial Internet
    Reference Architecture IPSS Industrial Product-Service Systems M2M Machine-To-Machine
    ML Machine Learning NFC Near Field Communications P2P Peer-To-Peer PIR Passive
    infrared QoE Quality of Experience QoS Quality of Service QR Quick Response RAMI
    Reference Architecture Model Industrie RFID Radio Frequency Identification RSSI
    Received Signal Strength Indicator SG Smart Grid SVM Support Vector Machine WSAN
    Wireless Sensor and Actuator Networks WSN Wireless Sensor Networks References
    Fan, Y.V.; Pintarič, Z.N.; Klemeš, J.J. Emerging Tools for Energy System Design
    Increasing Economic and Environmental Sustainability. Energies 2020, 13, 4062.
    [Google Scholar] [CrossRef] Deloitte. Internet of Things (Iot)—The Rise of the
    Connected World. Available online: https://www2.deloitte.com/content/dam/Deloitte/in/Documents/technology-media-telecommunications/in-tmt-IoT_Theriseoftheconnectedworld-28aug-noexp.pdf
    (accessed on 12 January 2021). Cisco. Internet of Things. Available online: https://www.cisco.com/c/en/us/products/collateral/se/internet-of-things/at-a-glance-c45-731471.pdf
    (accessed on 12 January 2021). Microsoft. IoT Signals, 3rd ed.; Available online:
    www.azure.microsoft.com (accessed on 16 October 2021). Zikria, Y.B.; Ali, R.;
    Afzal, M.K.; Kim, S.W. Next-Generation Internet of Things (IoT): Opportunities,
    Challenges, and Solutions. Sensors 2021, 21, 1174. [Google Scholar] [CrossRef]
    [PubMed] Liao, Y.; Deschamps, F.; Loures, E.D.; Ramos, L.F. Past, present and
    future of Industry 4.0—A systematic literature review and research agenda proposal.
    Int. J. Prod. Res. 2017, 55, 3609–3629. [Google Scholar] [CrossRef] Zheng, T.;
    Ardolino, M.; Bacchetti, A.; Perona, M. The applications of Industry 4.0 technologies
    in manufacturing context: A systematic literature review. Int. J. Prod. Res. 2021,
    59, 1922–1954. [Google Scholar] [CrossRef] Oztemel, E.; Gursev, S. Literature
    review of Industry 4.0 and related technologies. J. Intell. Manuf. 2020, 31, 127–182.
    [Google Scholar] [CrossRef] Lasi, H.; Fettke, P.; Kemper, H.-G.; Feld, T.; Hoffmann,
    M. Industry 4.0. Bus. Inf. Syst. Eng. 2014, 6, 239–242. [Google Scholar] [CrossRef]
    Yikilmaz, İ. New era: The transformation from the information society to super
    smart society (society 5.0). In Data, Information and Knowledge Management; Nobel
    Bilimsel Eserler: Ankara, Turkey, 2020; pp. 85–112. [Google Scholar] Wichmann,
    R.; Eisenbart, B.; Gericke, K. The Direction of Industry: A Literature Review
    on Industry 4.0; Cambridge University Press: Cambridge, UK, 2019; Volume 1, pp.
    2129–2138. [Google Scholar] [CrossRef] [Green Version] Silvestri, L.; Forcina,
    A.; Introna, V.; Santolamazza, A.; Cesarotti, V. Maintenance transformation through
    Industry 4.0 technologies: A systematic literature review. Comput. Ind. 2020,
    123, 103335. [Google Scholar] [CrossRef] Alqahtani, A.Y.; Gupta, S.M.; Nakashima,
    K. Warranty and maintenance analysis of sensor embedded products using internet
    of things in industry 4.0. Int. J. Prod. Econ. 2019, 208, 483–499. [Google Scholar]
    [CrossRef] Hizam-Hanafiah, M.; Soomro, M.A.; Abdullah, N.L. Industry 4.0 Readiness
    Models: A Systematic Literature Review of Model Dimensions. Information 2020,
    11, 364. [Google Scholar] [CrossRef] Stentoft, J.; Adsbøll Wickstrøm, K.; Philipsen,
    K.; Haug, A. Drivers and barriers for Industry 4.0 readiness and practice: Empirical
    evidence from small and medium-sized manufacturers. Prod. Plan. Control 2021,
    32, 811–828. [Google Scholar] [CrossRef] Lee, J.; Kao, H.-A.; Yang, S. Service
    Innovation and Smart Analytics for Industry 4.0 and Big Data Environment. Procedia
    CIRP 2014, 16, 3–8. [Google Scholar] [CrossRef] [Green Version] Bahrin, M.; Othman,
    F.; Azli, N.; Talib, M. Industry 4.0: A review on industrial automation and robotic.
    J. Teknol. 2016, 78, 6–13. [Google Scholar] [CrossRef] [Green Version] Almada-Lobo,
    F. The Industry 4.0 revolution and the future of Manufacturing Execution Systems
    (MES). J. Innov. Manag. 2016, 3, 16–21. [Google Scholar] [CrossRef] Vaidya, S.;
    Ambad, P.; Bhosle, S. Industry 4.0—A Glimpse. Procedia Manuf. 2018, 20, 233–238.
    [Google Scholar] [CrossRef] Malik, P.K.; Sharma, R.; Singh, R.; Gehlot, A.; Satapathy,
    S.C.; Alnumay, W.S.; Pelusi, D.; Ghosh, U.; Nayak, J. Industrial Internet of Things
    and its Applications in Industry 4.0: State of the Art. Comput. Commun. 2021,
    166, 125–139. [Google Scholar] [CrossRef] Boyes, H.; Hallaq, B.; Cunningham, J.;
    Watson, T. The industrial internet of things (IIoT): An analysis framework. Comput.
    Ind. 2018, 101, 1–12. [Google Scholar] [CrossRef] Dlodlo, N.; Foko, T.; Mvelase,
    P.; Mathaba, S. The State of Affairs in Internet of Things Research. Electron.
    J. Inf. Syst. Eval. 2012, 3, 244–258. [Google Scholar] Fatorachian, H.; Kazemi,
    H. Impact of Industry 4.0 on supply chain performance. Prod. Plan. Control 2021,
    32, 63–81. [Google Scholar] [CrossRef] Rejeb, A.; Keogh, J.G.; Treiblmaier, H.
    Leveraging the Internet of Things and Blockchain Technology in Supply Chain Management.
    Future Internet 2019, 11, 161. [Google Scholar] [CrossRef] [Green Version] Alfa,
    A.A.; Alhassan, J.K.; Olaniyi, O.M.; Olalere, M. Blockchain technology in IoT
    systems: Current trends, methodology, problems, applications, and future directions.
    J. Reliab. Intell. Environ. 2021, 7, 115–143. [Google Scholar] [CrossRef] Garg,
    K.; Goswami, C.; Chhatrawat, R.S.; Kumar Dhakar, S.; Kumar, G. Internet of things
    in manufacturing: A review. Mater. Today Proc. 2022, 51, 286–288. [Google Scholar]
    [CrossRef] Sisinni, E.; Saifullah, A.; Han, S.; Jennehag, U.; Gidlund, M. Industrial
    Internet of Things: Challenges, Opportunities, and Directions. IEEE Trans. Ind.
    Inform. 2018, 14, 4724–4734. [Google Scholar] [CrossRef] Matsumoto, N.; Fujita,
    J.; Endoh, H.; Yamada, T.; Sawada, K.; Kaneko, O. Asset Management Method of Industrial
    IoT Systems for Cyber-Security Countermeasures. Information 2021, 12, 460. [Google
    Scholar] [CrossRef] Alexopoulos, K.; Koukas, S.; Boli, N.; Mourtzis, D. Architecture
    and development of an Industrial Internet of Things framework for realizing services
    in Industrial Product Service Systems. Procedia CIRP 2018, 72, 880–885. [Google
    Scholar] [CrossRef] Esmaeilian, B.; Sarkis, J.; Lewis, K.; Behdad, S. Blockchain
    for the future of sustainable supply chain management in Industry 4.0. Resour.
    Conserv. Recycl. 2020, 163, 105064. [Google Scholar] [CrossRef] Forsstrom, S.;
    Butun, I.; Eldefrawy, M.; Jennehag, U.; Gidlund, M. Challenges of Securing the
    Industrial Internet of Things Value Chain. In Proceedings of the 2018 Workshop
    on Metrology for Industry 4.0 and IoT, Brescia, Italy, 16–18 April 2018; pp. 218–223.
    [Google Scholar] [CrossRef] [Green Version] Ometov, A.; Molua, O.L.; Komarov,
    M.; Nurmi, J. A Survey of Security in Cloud, Edge, and Fog Computing. Sensors
    2022, 22, 927. [Google Scholar] [CrossRef] Karakaya, A.; Akleylek, S. A novel
    IoT-based health and tactical analysis model with fog computing. PeerJ Comput.
    Sci. 2021, 7, e342. [Google Scholar] [CrossRef] Mell, P.; Grance, T. The NIST
    Definition of Cloud Computing; National Institute of Standards & Technology: Gaithersburg,
    MA, USA, 2011; p. 2. Mijuskovic, A.; Chiumento, A.; Bemthuis, R.; Aldea, A.; Havinga,
    P. Resource Management Techniques for Cloud/Fog and Edge Computing: An Evaluation
    Framework and Classification. Sensors 2021, 21, 1832. [Google Scholar] [CrossRef]
    Motlagh, N.H.; Mohammadrezaei, M.; Hunt, J.; Zakeri, B. Internet of Things (IoT)
    and the Energy Sector. Energies 2020, 13, 494. [Google Scholar] [CrossRef] [Green
    Version] Wang, G.; Nixon, M.; Boudreaux, M. Toward Cloud-Assisted Industrial IoT
    Platform for Large-Scale Continuous Condition Monitoring. Proc. IEEE 2019, 107,
    1193–1205. [Google Scholar] [CrossRef] Pinto, D.; Dias, J.P.; Ferreira, H.S. Dynamic
    Allocation of Serverless Functions in IoT Environments. In Proceedings of the
    2018 IEEE 16th International Conference on Embedded and Ubiquitous Computing (EUC),
    Bucharest, Romania, 29–31 October 2018; pp. 1–8. [Google Scholar] Mohan, N.; Kangasharju,
    J. Edge-Fog cloud: A distributed cloud for Internet of Things computations. In
    Proceedings of the 2016 Cloudification of the Internet of Things (CIoT), Paris,
    France, 23–25 November 2016. [Google Scholar] [CrossRef] [Green Version] OpenFogConsortium.
    OpenFog Reference Architecture for Fog Computing; OPFRA001.020817; OpenFogConsortium:
    Fremont, CA, USA, 2017. [Google Scholar] Vaclavova, A.; Strelec, P.; Horak, T.;
    Kebisek, M.; Tanuska, P.; Huraj, L. Proposal for an IIoT Device Solution According
    to Industry 4.0 Concept. Sensors 2022, 22, 325. [Google Scholar] [CrossRef] Cabrini,
    F.H.; Filho, F.V.; Rito, P.; Filho, A.B.; Sargento, S.; Neto, A.V.; Kofuji, S.T.
    Enabling the Industrial Internet of Things to Cloud Continuum in a Real City Environment.
    Sensors 2021, 21, 7707. [Google Scholar] [CrossRef] Lim, M.K.; Li, Y.; Wang, C.;
    Tseng, M.-L. A literature review of blockchain technology applications in supply
    chains: A comprehensive analysis of themes, methodologies and industries. Comput.
    Ind. Eng. 2021, 154, 107133. [Google Scholar] [CrossRef] Benzidia, S.; Makaoui,
    N.; Subramanian, N. Impact of ambidexterity of blockchain technology and social
    factors on new product development: A supply chain and Industry 4.0 perspective.
    Technol. Forecast. Soc. Chang. 2021, 169, 120819. [Google Scholar] [CrossRef]
    Dietrich, F.; Ge, Y.; Turgut, A.; Louw, L.; Palm, D. Review and analysis of blockchain
    projects in supply chain management. Procedia Comput. Sci. 2021, 180, 724–733.
    [Google Scholar] [CrossRef] Scopus. Abstract and Citation Database. 2021. Available
    online: https://www.scopus.com (accessed on 16 October 2021). Katoch, R. IoT research
    in supply chain management and logistics: A bibliometric analysis using vosviewer
    software. Mater. Today Proc. 2021, in press. [Google Scholar] [CrossRef] Singh,
    V.K.; Singh, P.; Karmakar, M.; Leta, J.; Mayr, P. The journal coverage of Web
    of Science, Scopus and Dimensions: A comparative analysis. Scientometrics 2021,
    126, 5113–5142. [Google Scholar] [CrossRef] Donthu, N.; Kumar, S.; Mukherjee,
    D.; Pandey, N.; Lim, W.M. How to conduct a bibliometric analysis: An overview
    and guidelines. J. Bus. Res. 2021, 133, 285–296. [Google Scholar] [CrossRef] Xie,
    L.; Chen, Z.; Wang, H.; Zheng, C.; Jiang, J. Bibliometric and Visualized Analysis
    of Scientific Publications on Atlantoaxial Spine Surgery Based on Web of Science
    and VOSviewer. World Neurosurg. 2020, 137, 435–442.e434. [Google Scholar] [CrossRef]
    Chen, Y.; Guo, G.; Hu, Y.; Ning, B.; Wang, W. Spindle and workpiece information
    collecting for industrial internet of things. ICIC Express Lett. 2011, 5, 455–459.
    [Google Scholar] Gebremichael, T.; Ledwaba, L.P.I.; Eldefrawy, M.H.; Hancke, G.P.;
    Pereira, N.; Gidlund, M.; Akerberg, J. Security and Privacy in the Industrial
    Internet of Things: Current Standards and Future Challenges. IEEE Access 2020,
    8, 152351–152366. [Google Scholar] [CrossRef] Gidlund, M.; Han, S.; Sisinni, E.;
    Saifullah, A.; Jennehag, U. Guest Editorial From Industrial Wireless Sensor Networks
    to Industrial Internet of Things. IEEE Trans. Ind. Inform. 2018, 14, 2194–2198.
    [Google Scholar] [CrossRef] [Green Version] Grimaldi, S.; Mahmood, A.; Hassan,
    S.A.; Gidlund, M.; Hancke, G.P. Autonomous Interference Mapping for Industrial
    Internet of Things Networks Over Unlicensed Bands: Identifying Cross-Technology
    Interference. IEEE Ind. Electron. Mag. 2021, 15, 67–78. [Google Scholar] [CrossRef]
    Åkerberg, J.; Gidlund, M.; Lennvall, T.; Neander, J.; Björkman, M. Efficient integration
    of secure and safety critical industrial wireless sensor networks. EURASIP J.
    Wirel. Commun. Netw. 2011, 2011, 100. [Google Scholar] [CrossRef] [Green Version]
    Basir, R.; Qaisar, S.; Ali, M.; Aldwairi, M.; Ashraf, M.I.; Mahmood, A.; Gidlund,
    M. Fog Computing Enabling Industrial Internet of Things: State-of-the-Art and
    Research Challenges. Sensors 2019, 19, 4807. [Google Scholar] [CrossRef] [PubMed]
    [Green Version] Grimaldi, S.; Martenvormfelde, L.; Mahmood, A.; Gidlund, M. Onboard
    Spectral Analysis for Low-Complexity IoT Devices. IEEE Access 2020, 8, 43027–43045.
    [Google Scholar] [CrossRef] Lennvall, T.; Gidlund, M.; Akerberg, J. Challenges
    when bringing IoT into industrial automation. In Proceedings of the 2017 IEEE
    AFRICON, Cape Town, South Africa, 18–20 September 2017; pp. 905–910. [Google Scholar]
    [CrossRef] [Green Version] Peng, C.; Peng, T.; Liu, Y.; Geissdoerfer, M.; Evans,
    S.; Tang, R. Industrial Internet of Things enabled supply-side energy modelling
    for refined energy management in aluminium extrusions manufacturing. J. Clean.
    Prod. 2021, 301, 126882. [Google Scholar] [CrossRef] Liukkonen, M. RFID technology
    in manufacturing and supply chain. Int. J. Comput. Integr. Manuf. 2015, 28, 861–880.
    [Google Scholar] [CrossRef] Arulogun, O.T.; Falohun, A.S.; Akande, N.O. Radio
    Frequency Identification and Internet of Things: A Fruitful Synergy. Br. J. Appl.
    Sci. Technol. 2016, 18, 1–16. [Google Scholar] [CrossRef] [Green Version] Maśniak,
    L.; Marcisz, K.; Płodzich, J.; Świętochowska, E.; Tomala, A.; Zaboklicki, J. IOT
    W Polskiej Gospodarce; Ministerstwo Cyfryzacji: Warsaw, Poland, 2019. Sharif,
    A.; Abbasi, Q.H.; Arshad, K.; Ansari, S.; Ali, M.Z.; Kaur, J.; Abbas, H.T.; Imran,
    M.A. Machine Learning Enabled Food Contamination Detection Using RFID and Internet
    of Things System. J. Sens. Actuator Netw. 2021, 10, 63. [Google Scholar] [CrossRef]
    Kodan, R.; Parmar, P.; Pathania, S. Internet of Things for Food Sector: Status
    Quo and Projected Potential. Food Rev. Int. 2020, 36, 584–600. [Google Scholar]
    [CrossRef] Lloret, J.; Sendra, S.; Garcia, L.; Jimenez, J.M. A Wireless Sensor
    Network Deployment for Soil Moisture Monitoring in Precision Agriculture. Sensors
    2021, 21, 7243. [Google Scholar] [CrossRef] Abdollahi, A.; Rejeb, K.; Rejeb, A.;
    Mostafa, M.M.; Zailani, S. Wireless Sensor Networks in Agriculture: Insights from
    Bibliometric Analysis. Sustainability 2021, 13, 12011. [Google Scholar] [CrossRef]
    Petrut, I.; Otesteanu, M. The IoT Connectivity Challenges. In Proceedings of the
    12th International Symposium on Applied Computational Intelligence and Informatics
    (SACI), Timisoara, Romania, 17–19 May 2018; pp. 000385–000388. [Google Scholar]
    Farhan, L.; Shukur, S.T.; Alissa, A.E.; Alrweg, M.; Raza, U.; Kharel, R. A survey
    on the challenges and opportunities of the Internet of Things (IoT). In Proceedings
    of the 2017 Eleventh International Conference on Sensing Technology (ICST), Sydney,
    Australia, 4–6 December 2017; pp. 1–5. [Google Scholar] Chen, Y. Challenges and
    opportunities of internet of things. In Proceedings of the 17th Asia and South
    Pacific Design Automation Conference, Sydney, Australia, 30 January–2 February
    2012; pp. 383–388. [Google Scholar] Said, O.; Masud, M. Towards Internet of Things:
    Survey and Future Vision. Int. J. Comput. Netw. 2013, 5, 1–17. [Google Scholar]
    Thabet, N.; Soomro, T. Big Data Challenges. Comput. Eng. Inf. Technol. 2015, 4,
    31–40. [Google Scholar] [CrossRef] Baars, H.; Kemper, H.-G. Management Support
    with Structured and Unstructured Data—An Integrated Business Intelligence Framework.
    Inf. Syst. Manag. 2008, 25, 132–148. [Google Scholar] [CrossRef] Noor, M.B.M.;
    Hassan, W.H. Current research on Internet of Things (IoT) security: A survey.
    Comput. Netw. 2019, 148, 283–294. [Google Scholar] [CrossRef] Siby, S.; Maiti,
    R.R.; Tippenhauer, N.O. IoTScanner: Detecting Privacy Threats in IoT Neighborhoods.
    In Proceedings of the 3rd ACM International Workshop on IoT Privacy, Trust, and
    Security, Abu Dhabi, United Arab Emirates, 2 April 2017; pp. 23–30. [Google Scholar]
    Aboelwafa, M.M.N.; Seddik, K.G.; Eldefrawy, M.H.; Gadallah, Y.; Gidlund, M. A
    Machine-Learning-Based Technique for False Data Injection Attacks Detection in
    Industrial IoT. IEEE Internet Things J. 2020, 7, 8462–8471. [Google Scholar] [CrossRef]
    Neill, D.B. Fast Bayesian scan statistics for multivariate event detection and
    visualization. Stat. Med. 2011, 30, 455–469. [Google Scholar] [CrossRef] Pamarthi,
    S.; Narmadha, R. Literature review on network security in Wireless Mobile Ad-hoc
    Network for IoT applications: Network attacks and detection mechanisms. Int. J.
    Intell. Unmanned Syst. 2021. ahead-of-print. [Google Scholar] [CrossRef] Balogh,
    S.; Gallo, O.; Ploszek, R.; Špaček, P.; Zajac, P. IoT Security Challenges: Cloud
    and Blockchain, Postquantum Cryptography, and Evolutionary Techniques. Electronics
    2021, 10, 2647. [Google Scholar] [CrossRef] Kaufman, L.M. Data Security in the
    World of Cloud Computing. IEEE Secur. Priv. 2009, 7, 61–64. [Google Scholar] [CrossRef]
    Abomhara, M.; Køien, G.M. Security and privacy in the Internet of Things: Current
    status and open issues. In Proceedings of the 2014 International Conference on
    Privacy and Security in Mobile Systems (PRISMS), Aalborg, Denmark, 11–14 May 2014;
    pp. 1–8. [Google Scholar] Ali, W.; Din, I.U.; Almogren, A.; Kumar, N. ALPHA: An
    Anonymous Orthogonal Code-Based Privacy Preserving Scheme for Industrial Cyber–Physical
    Systems. IEEE Trans. Ind. Inform. 2021, 17, 7716–7724. [Google Scholar] [CrossRef]
    Tawalbeh, L.; Muheidat, F.; Tawalbeh, M.; Quwaider, M. IoT Privacy and Security:
    Challenges and Solutions. Appl. Sci. 2020, 10, 4102. [Google Scholar] [CrossRef]
    Vinoth, R.; Deborah, L.J.; Vijayakumar, P.; Kumar, N. Secure Multifactor Authenticated
    Key Agreement Scheme for Industrial IoT. IEEE Internet Things J. 2021, 8, 3801–3811.
    [Google Scholar] [CrossRef] Ali, W.; Din, I.U.; Almogren, A.; Guizani, M.; Zuair,
    M. A Lightweight Privacy-Aware IoT-Based Metering Scheme for Smart Industrial
    Ecosystems. IEEE Trans. Ind. Inform. 2021, 17, 6134–6143. [Google Scholar] [CrossRef]
    Djebbar, F. Securing IoT Data Using Steganography: A Practical Implementation
    Approach. Electronics 2021, 10, 2707. [Google Scholar] [CrossRef] Van Kranenburg,
    R.; Bassi, A. IoT Challenges. Commun. Mob. Comput. 2012, 1, 9. [Google Scholar]
    [CrossRef] [Green Version] IEC+AMD. Industrial communication networks—Wireless
    communication networks—Part 2: Coexistence management. In IEC 62657-2:2017+AMD1:2019
    CSV; IEC: Geneva, Switzerland, 2019. [Google Scholar] Iot and the Polish Economy,
    Report of the Working Group for the Internet of Things at the Ministry of Digital
    Affairs. Available online: https://www.gov.pl/attachment/f79e07cc-9f3e-491b-a205-30b4a67855a7
    (accessed on 12 January 2021). Nižetić, S.; Šolić, P.; González-De-Artaza, D.L.-D.;
    Patrono, L. Internet of Things (IoT): Opportunities, issues and challenges towards
    a smart and sustainable future. J. Clean. Prod. 2020, 274, 122877. [Google Scholar]
    [CrossRef] Xu, L.; He, W.; Li, S. Internet of Things in Industries: A Survey.
    IEEE Trans. Ind. Inform. 2014, 10, 2233–2243. [Google Scholar] [CrossRef] Chen,
    S.; Xu, H.; Liu, D.; Hu, B.; Wang, H. A Vision of IoT: Applications, Challenges,
    and Opportunities with China Perspective. IEEE Internet Things J. 2014, 1, 349–359.
    [Google Scholar] [CrossRef] Arshad, R.; Zahoor, S.; Shah, M.A.; Wahid, A.; Yu,
    H. Green IoT: An Investigation on Energy Saving Practices for 2020 and beyond.
    IEEE Access 2017, 5, 15667–15681. [Google Scholar] [CrossRef] Bol, D.; Vos, J.D.;
    Botman, F.; Streel, G.d.; Bernard, S.; Flandre, D.; Legat, J. Green SoCs for a
    sustainable Internet-of-Things. In Proceedings of the 2013 IEEE Faible Tension
    Faible Consommation, Paris, France, 20–21 June 2013; pp. 1–4. [Google Scholar]
    Peruzzi, G.; Pozzebon, A. A Review of Energy Harvesting Techniques for Low Power
    Wide Area Networks (LPWANs). Energies 2020, 13, 3433. [Google Scholar] [CrossRef]
    Elahi, H.; Munir, K.; Eugeni, M.; Atek, S.; Gaudenzi, P. Energy Harvesting towards
    Self-Powered IoT Devices. Energies 2020, 13, 5528. [Google Scholar] [CrossRef]
    Alladi, T.; Chamola, V.; Rodrigues, J.J.P.C.; Kozlov, S.A. Blockchain in Smart
    Grids: A Review on Different Use Cases. Sensors 2019, 19, 4862. [Google Scholar]
    [CrossRef] [PubMed] [Green Version] Kumar, N.M.; Chand, A.A.; Malvoni, M.; Prasad,
    K.A.; Mamun, K.A.; Islam, F.; Chopra, S.S. Distributed energy resources and the
    application of AI, IoT, and blockchain in smart grids. Energies 2020, 13, 5739.
    [Google Scholar] [CrossRef] Tightiz, L.; Yang, H. A Comprehensive Review on IoT
    Protocols’ Features in Smart Grid Communication. Energies 2020, 13, 2762. [Google
    Scholar] [CrossRef] Publisher’s Note: MDPI stays neutral with regard to jurisdictional
    claims in published maps and institutional affiliations.  © 2022 by the authors.
    Licensee MDPI, Basel, Switzerland. This article is an open access article distributed
    under the terms and conditions of the Creative Commons Attribution (CC BY) license
    (https://creativecommons.org/licenses/by/4.0/). Share and Cite MDPI and ACS Style
    Wójcicki, K.; Biegańska, M.; Paliwoda, B.; Górna, J. Internet of Things in Industry:
    Research Profiling, Application, Challenges and Opportunities—A Review. Energies
    2022, 15, 1806. https://doi.org/10.3390/en15051806 AMA Style Wójcicki K, Biegańska
    M, Paliwoda B, Górna J. Internet of Things in Industry: Research Profiling, Application,
    Challenges and Opportunities—A Review. Energies. 2022; 15(5):1806. https://doi.org/10.3390/en15051806
    Chicago/Turabian Style Wójcicki, Krzysztof, Marta Biegańska, Beata Paliwoda, and
    Justyna Górna. 2022. \"Internet of Things in Industry: Research Profiling, Application,
    Challenges and Opportunities—A Review\" Energies 15, no. 5: 1806. https://doi.org/10.3390/en15051806
    Note that from the first issue of 2016, this journal uses article numbers instead
    of page numbers. See further details here. Article Metrics Citations Crossref   44
    Web of Science   33 Scopus   54 Google Scholar   [click to view] Article Access
    Statistics Article access statistics Article Views 14. Jan 24. Jan 3. Feb 13.
    Feb 23. Feb 4. Mar 14. Mar 24. Mar 3. Apr 0k 2k 4k 6k 8k For more information
    on the journal statistics, click here. Multiple requests from the same IP address
    are counted as one view.   Energies, EISSN 1996-1073, Published by MDPI RSS Content
    Alert Further Information Article Processing Charges Pay an Invoice Open Access
    Policy Contact MDPI Jobs at MDPI Guidelines For Authors For Reviewers For Editors
    For Librarians For Publishers For Societies For Conference Organizers MDPI Initiatives
    Sciforum MDPI Books Preprints.org Scilit SciProfiles Encyclopedia JAMS Proceedings
    Series Follow MDPI LinkedIn Facebook Twitter Subscribe to receive issue release
    notifications and newsletters from MDPI journals Select options Subscribe © 1996-2024
    MDPI (Basel, Switzerland) unless otherwise stated Disclaimer Terms and Conditions
    Privacy Policy"'
  inline_citation: '>'
  journal: Energies
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Internet of Things in Industry: Research Profiling, Application, Challenges
    and Opportunities—A Review'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Dubey K.
  - Sharma S.C.
  - Kumar M.
  citation_count: '28'
  description: Applications of the Internet of Things (IoT) are used in several areas
    to create a smart environment such as healthcare, smart agriculture, smart cities,
    transportation, and water management, etc. Due to the high pace of IoT technology
    adoption, Big Data generation is increasing excessively, requiring an efficient
    platform like cloud computing to process a large amount of data. On the other
    hand, time/delay-sensitive and real-time applications cannot be processed in the
    cloud due to high latency and energy consumption. Hence, a new emerging computing
    model named fog has emerged to address the mentioned issues and provide a complementary
    solution. However, Fog nodes provide limited cloud services in minimum delay and
    energy at the local node, but they cannot process the highly computation-oriented
    IoT applications. Furthermore, an adaptive cloud-fog integrated framework is proposed
    to process entire IoT applications and significantly improve the latency, computation
    cost, load balancing, and energy consumption by accommodating the resources in
    the form of virtual machine instances. This article exploited the features of
    two metaheuristic-based techniques Cuckoo Search Optimization (CSO) and Partial
    Swarm Optimization (PSO). We have developed a secure framework to solve the allocation
    of the IoT services in the cloud-fog environment while minimizing the mentioned
    influential parameters. The performance of the proposed framework is rigorously
    evaluated at synthetic datasets and heterogeneity of resources in fog as well
    as cloud simulation environment. The simulation results proved that the proposed
    hybrid metaheuristic algorithm outperforms other baseline policies and improves
    the various influential parameters.
  doi: 10.1007/s10723-021-09591-x
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Log in Find a journal
    Publish with us Track your research Search Cart Home Journal of Grid Computing
    Article A Secure IoT Applications Allocation Framework for Integrated Fog-Cloud
    Environment Published: 15 February 2022 Volume 20, article number 5, (2022) Cite
    this article Download PDF Access provided by University of Nebraska-Lincoln Journal
    of Grid Computing Aims and scope Submit manuscript Kalka Dubey , S. C. Sharma
    & Mohit Kumar  322 Accesses 23 Citations 1 Altmetric Explore all metrics Abstract
    Applications of the Internet of Things (IoT) are used in several areas to create
    a smart environment such as healthcare, smart agriculture, smart cities, transportation,
    and water management, etc. Due to the high pace of IoT technology adoption, Big
    Data generation is increasing excessively, requiring an efficient platform like
    cloud computing to process a large amount of data. On the other hand, time/delay-sensitive
    and real-time applications cannot be processed in the cloud due to high latency
    and energy consumption. Hence, a new emerging computing model named fog has emerged
    to address the mentioned issues and provide a complementary solution. However,
    Fog nodes provide limited cloud services in minimum delay and energy at the local
    node, but they cannot process the highly computation-oriented IoT applications.
    Furthermore, an adaptive cloud-fog integrated framework is proposed to process
    entire IoT applications and significantly improve the latency, computation cost,
    load balancing, and energy consumption by accommodating the resources in the form
    of virtual machine instances. This article exploited the features of two metaheuristic-based
    techniques Cuckoo Search Optimization (CSO) and Partial Swarm Optimization (PSO).
    We have developed a secure framework to solve the allocation of the IoT services
    in the cloud-fog environment while minimizing the mentioned influential parameters.
    The performance of the proposed framework is rigorously evaluated at synthetic
    datasets and heterogeneity of resources in fog as well as cloud simulation environment.
    The simulation results proved that the proposed hybrid metaheuristic algorithm
    outperforms other baseline policies and improves the various influential parameters.
    Article PDF Similar content being viewed by others An Autonomous Evolutionary
    Approach to Planning the IoT Services Placement in the Cloud-Fog-IoT Ecosystem
    Article 14 September 2022 Solving the Multi-Objective Problem of IoT Service Placement
    in Fog Computing Using Cuckoo Search Algorithm Article 22 January 2022 Resource
    Provisioning in Fog-Based IoT Chapter © 2022 Data Availability Data sharing not
    applicable to this article as no datasets were generated or analyzed during the
    current study. References Mansouri, N., Zade, B.M.H., Javidi, M.M.: Hybrid task
    scheduling strategy for cloud computing by modified particle swarm optimization
    and fuzzy theory. Comput. Ind. Eng. 130, 597–633 (2019) Article   Google Scholar   Bansal,
    M., Malik, S.K.: A multi-faceted optimization scheduling framework based on the
    particle swarm optimization algorithm in cloud computing. Sustain. Comput. Inform.
    Syst. 28, 100429 (2020) Google Scholar   Souza, V.B., Masip-Bruin, X., Marín-Tordera,
    E., Ramírez, W., Sanchez, S.: \"Towards distributed service allocation in fog-to-cloud
    (f2c) scenarios.\" In: 2016 IEEE global communications conference (GLOBECOM),
    pp. 1–6. IEEE, (2016) Li, W., Santos, I., Delicato, F.C., Pires, P.F., Pirmez,
    L., Wei, W., Song, H., Zomaya, A., Khan, S.: System modelling and performance
    evaluation of a three-tier cloud of things. Futur. Gener. Comput. Syst. 70, 104–125
    (2017) Article   Google Scholar   Maddikunta, P.K.R., Gadekallu, T.R., Kaluri,
    R., Srivastava, G., Parizi, R.M., Khan, M.S.: Green communication in IoT networks
    using a hybrid optimization algorithm. Comput. Commun. 159, 97–107 (2020) Article   Google
    Scholar   Ahmed, U., Lin, J.C.-W., Srivastava, G., Aleem, M.: A load balance multi-scheduling
    model for OpenCL kernel tasks in an integrated cluster. Soft. Comput. 25(1), 407–420
    (2021) Article   Google Scholar   Khalid, M., Yousaf, M.M., Iftikhar, Y., Fatima,
    N.: \"Establishing the state of the art knowledge domain of cloud computing.\"
    In: Advanced Computer and Communication Engineering Technology, pp. 1001–1014.
    Springer, Cham, (2016) Mahmud, R., Srirama, S.N., Ramamohanarao, K., Buyya, R.:
    Profit-aware application placement for integrated fog–cloud computing environments.
    J. Parallel Distrib. Comput. 135, 177–190 (2020) Article   Google Scholar   Azimi,
    I., Anzanpour, A., Rahmani, A.M., Liljeberg, P., Salakoski, T.: \"Medical warning
    system based on Internet of Things using fog computing.\" In: 2016 International
    Workshop on Big Data and Information Security (IWBIS), pp. 19–24. IEEE, (2016)
    Seth, B., Dalal, S., Jaglan, V., Le, D.-N., Mohan, S., Srivastava, G.: Integrating
    encryption techniques for secure data storage in the cloud. Trans. Emerg. Telecommun.
    Technol. e4108 (2020) Vilela, P.H., Rodrigues, J.J.P.C., Solic, P., Saleem, K.,
    Furtado, V.: Performance evaluation of a fog-assisted IoT solution for e-health
    applications. Futur. Gener. Comput. Syst. 97, 379–386 (2019) Article   Google
    Scholar   Thirumalai, C., Mohan, S., Srivastava, G.: An efficient public key secure
    scheme for cloud and IoT security. Comput. Commun. 150, 634–643 (2020) Article   Google
    Scholar   Adhikari, M., Gianey, H.: Energy efficient offloading strategy in fog-cloud
    environment for IoT applications. Internet Things. 6, 100053 (2019) Article   Google
    Scholar   Aburukba, R.O., AliKarrar, M., Landolsi, T., El-Fakih, K.: Scheduling
    internet of things requests to minimize latency in hybrid fog–cloud computing.
    Futur. Gener. Comput. Syst. 111, 539–551 (2020) Article   Google Scholar   Yadav,
    V., Natesha, B.V., Guddeti, R.M.R.. \"GA-PSO: Service Allocation in Fog Computing
    Environment Using Hybrid Bio-Inspired Algorithm.\" In: TENCON 2019–2019 IEEE Region
    10 Conference (TENCON), pp. 1280–1285. IEEE (2019) Alli, A.A., Alam, M.M.: SecOFF-FCIoT:
    Machine learning based secure offloading in Fog-Cloud of things for smart city
    applications. Internet Things. 7, 100070 (2019) Article   Google Scholar   M.
    Abdelmoneem et al., \"A Cloud-Fog Based Architecture for IoT Applications Dedicated
    to Healthcare,\" In: IEEE International Conference on Communications (ICC), Pp.
    1–6 (2019) Yasmeen, A., Javaid, N., Rehman, O.U., Iftikhar, H., Malik, M.F., Muhammad,
    F.J. \"Efficient resource provisioning for smart buildings utilizing fog and cloud
    based environment.\" In: 2018 14th International Wireless Communications & Mobile
    Computing Conference (IWCMC), pp. 811-816. IEEE (2018) Naha, R., et al.: deadline-based
    dynamic resource allocation and provisioning algorithms in fog-cloud environment.
    Futur. Gener. Comput. Syst. 104, 131–141 (2020) Article   Google Scholar   Shah-Mansouri,
    H., Wong, V.W.S.: Hierarchical fog-cloud computing for IoT systems: A computation
    offloading game. IEEE Internet Things J. 5(4), 3246–3257 (2018) Article   Google
    Scholar   Siasi, N., Jasim, M., Aldalbahi, A., Ghani, N.: Delay-aware SFC provisioning
    in hybrid fog-cloud computing architectures. IEEE Access. 8, 167383–167396 (2020)
    Article   Google Scholar   Tang, Z., Srivastava, G., Liu, S.: Swarm intelligence
    and ant colony optimization in accounting model choices. J. Intell. Fuzzy Syst.
    38(3), 2415–2423 (2020) Article   Google Scholar   Deng, R., Lu, R., Lai, C.,
    Luan, T.H., Liang, H.: Optimal workload allocation in fog-cloud computing toward
    balanced delay and power consumption. IEEE Internet Things J. 3(6), 1171–1181
    (2016) Google Scholar   Chen, X., Zhou, Y., Yang, L., Lu, L.: Hybrid fog/cloud
    computing resource allocation: joint consideration of limited communication resources
    and user credibility. Comput. Commun. 169, 48–58 (2021) Article   Google Scholar   Fu,
    W., Liu, S., Srivastava, G.: Optimization of big data scheduling in social networks.
    Entropy. 21(9), 902 (2019) Article   MathSciNet   Google Scholar   Gad-Elrab,
    A.A.A., Noaman, A.Y.: A two-tier bipartite graph task allocation approach based
    on fuzzy clustering in cloud–fog environment. Futur. Gener. Comput. Syst. 103,
    79–90 (2020) Article   Google Scholar   Kennedy, J., Eberhart, R.: \"Particle
    swarm optimization,\" In: IEEE Proceedings of ICNN''95-International Conference
    on Neural Networks, vol. 4, pp. 1942–1948 (1995) Yang, X.-S., Deb, S.: Cuckoo
    search: recent advances and applications. Neural Comput. & Applic. 24(1), 169–174
    (2014) Article   Google Scholar   Bouyer, A., Hatamlou, A.: An efficient hybrid
    clustering method based on improved cuckoo optimization and modified particle
    swarm optimization algorithms. Appl. Soft Comput. 67, 172–182 (2018) Article   Google
    Scholar   Dash, J., Dam, B., Swain, R.: Optimal design of linear phase multi-band
    stop filters using improved cuckoo search particle swarm optimization. Appl. Soft
    Comput. 52, 435–445 (2017) Article   Google Scholar   Gupta, H., Vahid Dastjerdi,
    A., Ghosh, S.K., Buyya, R.: iFogSim: a toolkit formodeling and simulation of resource
    management techniques in the internet of things, edge and fog computing environments.
    Softw. Pract. Experience. 47(9), 1275–1296 (2017) Article   Google Scholar   Buyya,
    R., Ranjan, R., Calheiros, R.N.: \"Modeling and simulation of scalable Cloud computing
    environments and the CloudSim toolkit: Challenges and opportunities.\" In: 2009
    international conference on high performance computing & simulation, pp. 1–11.
    IEEE (2009) Rafique, H., Shah, M.A., Islam, S.U., Maqsood, T., Khan, S., Maple,
    C.: A novel bio-inspired hybrid algorithm (NBIHA) for efficient resource management
    in fog computing. IEEE Access. 7, 115760–115773 (2019) Article   Google Scholar   Mulani,
    K., Talukdar, P., Das, A., Alagirusamy, R.: Performance analysis and feasibility
    study of ant colony optimization, particle swarm optimization and cuckoo search
    algorithms for inverse heat transfer problems. Int. J. Heat Mass Transf. 89, 359–378
    (2015) Article   Google Scholar   Kumar, M., Sharma, S.C.. \"PSO-based novel resource
    scheduling technique to improve QoS parameters in cloud computing.\" Neural Comput.
    & Applic. 1–24 (2019) Download references Author information Authors and Affiliations
    Cloud Computing and Wireless Sensor Lab, Indian Institute of Technology Roorkee,
    Roorkee, India Kalka Dubey & S. C. Sharma Department of Information Technology,
    B R Ambedkar National Institute of Technology, Jalandhar, India Mohit Kumar Corresponding
    author Correspondence to Kalka Dubey. Additional information Publisher’s Note
    Springer Nature remains neutral with regard to jurisdictional claims in published
    maps and institutional affiliations. Rights and permissions Reprints and permissions
    About this article Cite this article Dubey, K., Sharma, S.C. & Kumar, M. A Secure
    IoT Applications Allocation Framework for Integrated Fog-Cloud Environment. J
    Grid Computing 20, 5 (2022). https://doi.org/10.1007/s10723-021-09591-x Download
    citation Received 08 June 2021 Accepted 29 September 2021 Published 15 February
    2022 DOI https://doi.org/10.1007/s10723-021-09591-x Share this article Anyone
    you share the following link with will be able to read this content: Get shareable
    link Provided by the Springer Nature SharedIt content-sharing initiative Keywords
    Cloud computing Fog computing Internet of things Particle swarm optimization Cuckoo
    search optimization Use our pre-submission checklist Avoid common mistakes on
    your manuscript. Associated Content Part of a collection: Math for SDG 7 - Affordable
    and Clean Energy Sections References Abstract Article PDF Data Availability References
    Author information Additional information Rights and permissions About this article
    Advertisement Discover content Journals A-Z Books A-Z Publish with us Publish
    your research Open access publishing Products and services Our products Librarians
    Societies Partners and advertisers Our imprints Springer Nature Portfolio BMC
    Palgrave Macmillan Apress Your privacy choices/Manage cookies Your US state privacy
    rights Accessibility statement Terms and conditions Privacy policy Help and support
    129.93.161.219 Big Ten Academic Alliance (BTAA) (3000133814) - University of Nebraska-Lincoln
    (3000134173) © 2024 Springer Nature"'
  inline_citation: '>'
  journal: Journal of Grid Computing
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: A Secure IoT Applications Allocation Framework for Integrated Fog-Cloud Environment
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Kummar S.
  - Bhushan B.
  citation_count: '0'
  description: The unprecedented growth of population in urban areas has been causing
    a challenge for the citizens in their day-to-day lives such as road congestion,
    public security, environmental pollution, electricity shortage and water shortage.
    To control and resolve all these issues, new technologies have been developed
    for smart cities. Intelligent services and better applications are deployed in
    smart cities, by combining the Internet of Things (IoT) with the technologies
    like data mining (DM) and deep learning (DL). Many sectors like healthcare, governance,
    agriculture and public safety can increase their efficiency with the help of these
    new technologies and can convert these into smart applications for smart cities.
    Different kinds of computing like edge computing, fog computing and cloud computing
    support to provide better insights into analytics with the help of big data in
    smart cities. All these technologies are transforming or raising healthcare ecosystems,
    leading them in the direction of smart healthcare. This permits surgeons to get
    real-time data of their patients distantly with the help of wireless communication.
    Smart healthcare is established on new technologies to convey enriched and valued
    healthcare facilities for patients. This chapter explores the current challenges
    that are faced during the indigenous development of the smart cities. Furthermore,
    the chapter discusses the theoretical background of smart cities with the explanation
    of their components. Moreover, the chapter describes the necessity of computational
    infrastructure for smart cities in a framework of big data and DM. The chapter
    highlights some mining methods for extracting important information from huge
    and mixed data. Additionally, the chapter examines the advancement of healthcare
    sector in smart cities in context of big data and DM.
  doi: null
  full_citation: '>'
  full_text: '>'
  inline_citation: '>'
  journal: 'The Internet of Medical Things: Enabling technologies and emerging applications'
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Big data analytics and data mining for healthcare and smart city applications
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Saini K.
  - Raj P.
  citation_count: '6'
  description: Edge computing, a rapidly growing technology, satisfies the business
    needs of most of the smart business cultures today. Smart agriculture, smart cities,
    smart manufacturing or any other smart business can be benefited from Edge computing.
    The chapter discuss how to about the cloud computing to edge computing. Various
    edge computing technologies and applications are also discussed in detail. 5G
    Communications, Remote Monitoring, Healthcare and other such applications require
    tremendous accuracy, high latency I less cost. Augmented and Virtual reality applications
    or gaming are just few applications. There are many more to discuss about. The
    chapter discuss how edge computing is helpful for all such applications. Unlike
    cloud computing, edge computing enables data analysis, its processing, and transfer
    at the edge of the network. Basically data is analyzed locally where it is stored.
    The analysis is done in real time without latency and allows for quicker data
    processing and content delivery.
  doi: 10.1016/bs.adcom.2022.02.005
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full volume
    Outline Abstract Keywords 1. Introduction to cloud computing 2. Cloud computing
    to edge computing 3. Edge computing: A brief overview 4. Essential of edge computing
    5. Advantages of edge computing 6. Significance of cloudlets 7. Conclusion References
    Vitae Show full outline Cited by (7) Figures (6) Advances in Computers Volume
    127, 2022, Pages 237-258 Chapter Eight - Edge platforms, frameworks and applications
    Author links open overlay panel Kavita Saini a, Pethuru Raj b c Show more Share
    Cite https://doi.org/10.1016/bs.adcom.2022.02.005 Get rights and content Abstract
    Edge computing, a rapidly growing technology, satisfies the business needs of
    most of the smart business cultures today. Smart agriculture, smart cities, smart
    manufacturing or any other smart business can be benefited from Edge computing.
    The chapter discuss how to about the cloud computing to edge computing. Various
    edge computing technologies and applications are also discussed in detail. 5G
    Communications, Remote Monitoring, Healthcare and other such applications require
    tremendous accuracy, high latency I less cost. Augmented and Virtual reality applications
    or gaming are just few applications. There are many more to discuss about. The
    chapter discuss how edge computing is helpful for all such applications. Unlike
    cloud computing, edge computing enables data analysis, its processing, and transfer
    at the edge of the network. Basically data is analyzed locally where it is stored.
    The analysis is done in real time without latency and allows for quicker data
    processing and content delivery. Previous chapter in volume Next chapter in volume
    Keywords Cloud computingFog computingEdge computingIoT devicesVideo StreamingRemote
    monitoringGaming-as-a-serviceSecurity MonitoringEdge computing enabled devicesEdgeOS
    1. Introduction to cloud computing Cloud computing by which remote servers hosted
    on the Internet store and process data, rather than local servers or personal
    computers [1]. It is ready to move to the next level, i.e., “Edge Computing.”
    Icloud, onedrive, Google are the few examples of cloud computing [2]. As cloud
    computing is the “On-Demand” availability of the computer system resources, especially
    data storage and computing power, without direct active management by the user
    [3]. To Leverage 5G wireless technology and artificial Intelligence to enable
    faster response times, lower latency (ability to process very high volumes of
    data with minimal delay), and simplified maintenance in computing. Cloud provider
    are responsible to manage, restore and backup. In short data centers are being
    managed by cloud service providers [4], [5]. They are also providing high-end
    computing power, software and so on. This is where Edge Computing comes in, which
    many see as an extension to the cloud computing, but which is in fact, different
    in several basic ways [6]. 2. Cloud computing to edge computing The basic difference
    between cloud computing and edge computing lies in the place where the data processing
    takes place. At the moment, the existing Internet of Things (IoT) system performs
    all of their computations in the cloud using data centers. Experts believe the
    true potential of edge computing will become apparent when 5G networking go mainstream
    in a year from now. Edge offers an extra added scalability which will be needed
    for locally applicable responsibilities in the environment with a huge quantity
    of data producers and customers [7], [8]. Multifaceted, extensive and data determined
    responsibilities which aren''t time threating would be benefited greatly from
    the richness of ascendable sources in clouds [9], [10]. Edge can make the communications
    more consistent, in the manner that it could provide an option if the network
    link to cloud breaks. It can be an interesting especially for crisis management
    scene where edge provides optional substructure to preserve critical responsibilities
    thriving. Edge sources could generally be accessible within one hop from the wireless
    gateways which operators are linked with. Preferably, edge system can identify
    and back handler flexibility, e.g., by moving its information and computing to
    the subsequent nearby positions. User will be able to enjoy consistent connectivity
    without even realizing it [7]. 3. Edge computing: A brief overview Edge Computing
    enables data to be analyzed, processed and transferred at the edge of a network.
    The idea is to analyze data locally, closer to where it is stored, in real-time
    without latency, rather that send it far away to a centralized data center [4],
    [10]. Time-sensitive data is processed using edge computing, while data that is
    not time-sensitive is processed using cloud computing which is the main advantage
    of edge computing over cloud computing. The prime aid edge offers consist lower
    latency, higher bandwidth [11], device processing and data unburden as well as
    reliable computations and storing. Concludingly, 5G requires edge to drive need
    for its facilities [5]. In edge computing some content will be offload before
    using which will help in accessing data without any delay. In short in Edge computing
    there is a use of 5G wireless technology and AI. Edge could be considers as an
    additional layer between the CC and users, applications and devices (such IoT
    devices). With the rapid advancement in IoT and Edge Computing, the traditional
    cloud computing was facing communication latency and network bandwidth as a biggest
    challenge. A new driving technology coming into role has now moved the functionality
    of centralized cloud computing to the network edge node for addressing the difficulties
    in traditional system. Several edge computing systems have emerged from various
    backgrounds in order to reduce latency, increase computational capabilities and
    handle huge machine connectivity [12]. This study provides an in-depth look at
    three common edge computing technologies: mobile edge computing (MEC), cloudlets,
    and fog computing [6]. 4. Essential of edge computing Pushes the intelligence,
    processing power, and Communication Capabilities of an edge gateway or applicant
    directly into devices [13]. The idea is to analyze data locally, closer to where
    it is stored, in real-time without latency, rather than send it far away to a
    centralized data center. So whether you are streaming a video on Netflix or accessing
    a library of video games in the cloud, edge computing allows for quicker data
    processing and content delivery [12]. As of now all the applications using IoT
    devices store and compute the data on cloud data center. With edge computing it
    is possible to perform all the analysis and computation at the edge on cloud and
    saves lots of time. Not just saving time edge helps in computation in real time.
    Playing online games, live video streaming are the examples where computation
    should be finished in fraction on second. This is possible with edge computing
    [14], [15]. This is how edge computing different from cloud computing. Only important
    data is sent over the network instead of whole data. In this way edge computing
    is reduces the amount of data traversal over the network. Transferring data from
    cloud to devices and vice versa take time, also known as Internet latency. It
    can be achieved using AI, 5G wireless tech and IoT devices. It will help in reducing
    amount of data stored over cloud as some data some data could be stored only on
    edge [8]. Edge Computing simplifier this Communication chain and reduces Potential
    Print of Failure. In edge Computing, physical assets like pumps, motor, and generators
    are again physically wired into a control system, but this system in controlled
    by an Edge Programmable Industrial Controller, or EPIC. Edge Computing saves time
    and money by Streamline IoT Communication, reducing system and Network Architecture
    Complexity and decreasing the number of potential failure in an IoT application
    Reducing system Architecture Complexity is key to the Success of IoT applications
    [7], [16]. 5. Advantages of edge computing Edge computing has many important features
    unnoticed in preceding network generations. These consist of huge data generation.
    Edge directs the computing information, application, and facilities aside from
    the Cloud server to the edge of networks [10]. Content suppliers and app creators
    can utilize an edge computational system by providing handlers the facilities
    nearer to themselves. Edge computation is categorized as employing higher bandwidths,
    lower latencies, and real time admittance to the system data which could be utilized
    by numerous appliances [13], [17], [18]. Edge is favored to supply the wireless
    communication needs of next-gen technologies, like virtual reality & augmented
    reality, that are collaborating in behavior [14]. Edge technology enables the
    computing to be executed at the networking edges. 5.1. Latency reduction Cloud
    computing can''t adequately support the volume of data being processed every second.
    Having spoken about latency within the cloud computing world, there is a lot that
    cloud computing does not provide to cloud-based applications [5]. Given the amount
    of stored data within the cloud, there are two problems that transpire during
    the processing stage—latency in processing and high number of wasted resources.
    These issues exist especially in decentralized data centers, mobile edge nodes,
    and cloudlets [17]. By reducing latency, edge computing enhances network performance.
    The information does not go travel as far as it would in a traditional cloud architecture
    rather devices process data natively or at a local edge center. It has been noticed
    earlier if source is sending any mail at destination at same workplace also, there
    could be some delay in standard network. This delay does not exist if the procedure
    occurs at the edge and the company''s router handling office emails [19]. 5.2.
    Safer data processing DDoS (Distributed Denial of Service) assaults and power
    outages are common in cloud environments. Systems are less prone to interruption
    and unavailability because edge computing spreads processing and storage. There
    is no single point of failure in the setup [15]. Furthermore, because many procedures
    take place locally, cyber attackers are unable to prevent data from being sent.
    Even if a data breach occurs on one machine, the attacker can only access location
    data [20]. 5.3. Inexpensive scalability Edge computing empowers a company to increase
    its capacity with a combination of IoT devices and peripheral servers. Adding
    additional resources does not require investing in a more expensive private data
    center to build, maintain, and expand [5]. Instead, the company can set up regional
    edge servers to expand the network quickly and inexpensively. Edge computing also
    reduces growth costs as each new device does not add additional bandwidth requirements
    across the network. 5.4. Simple expansions to new markets The company can partner
    with the local edge data center to quickly expand and explore new markets. The
    expansion does not require expensive new infrastructure. Instead, the company
    only sets up end-to-end devices and starts serving customers without delay. If
    the market seems unwanted, the extraction process is quick and inexpensive. This
    benefit is important for industries that need rapid expansion in areas with limited
    connectivity. 5.5. Consistent user experience As the edge servers work closer
    to end users, the problem of a remote network is less likely to affect customers.
    Even if the local facility is disconnected, the peripheral devices may continue
    to operate due to their ability to handle important traditional tasks. The system
    can also extract the data route in other ways to ensure that users retain access
    to the services [15]. 5.6. Speed Speed is absolutely vital to any company''s core
    business. Take the financial sector''s reliance upon high-frequency trading algorithms,
    for example. A slowdown of mere milliseconds in their trading algorithms can result
    in expensive consequences. In the healthcare industry, where the stakes are much
    higher, losing a fraction of a second can be a matter of life or death [1], [20].
    5.7. Edge computing technologies There has been a substantial growth in connected
    smart devices and IoT nodes, which resulted into increased data generation at
    these nodes. Handling this massive amount of raw data is a crucial challenge because
    of limited computational and energy resources [2], [4], [9], [19]. Due to the
    requirement of large processing and storage capacity, the existing cloud computing
    platform can easily handle the tremendous heaps of data generated by IoT devices.
    But this is not conceptual for dissipated IoT systems or the On-time operation
    of deliciated latency IoT applications as they require centralized manner of operation
    and are concerned with the associated delay also. Edge computing can minimize
    end-to-end latency, save bandwidth in backlog links, and mitigate the computational
    pressures on cloud-servers, by providing cloud-like computing environment, storage,
    and communication facilities at the network edge [21]. The presence of “Edge devices”
    reduces the compute burden at data centers by handling some of the requests directed
    to the cloud locally, without the need for cloud involvement. As a result, the
    delay in resolving requests is reduced, and a subset of requests can be handled
    in real time. Because of their widespread availability and geographical distribution,
    edge devices also aid mobility. There are various technologies that can be used
    to develop edge computing, which is based on the idea that it can expand the settings
    of IoT usage by complementing the cloud [22]. Let''s take a close look at some
    IoT based edge computing technologies, including cloudlets, mobile edge computing
    (MEC), fog computing, and a novel idea called the Cloud of Things [11]. These
    technologies are also predicted to be important in the development of edge computing
    platforms. 5.8. Cloudlets: An overview A cloudlet is basically a regional cloud
    that can bring far-flung cloud services nearer to the user. Cloudlets are small-scale,
    mobility-enhanced cloud data centers that sit at the network''s edge. The cloudlet''s
    primary goal is to support furious resource and interactive mobile applications
    by delivering strong computing resources to mobile devices with reduced latency.
    A wireless local area network with single hop at comparatively higher speed, allows
    User Equipments (UEs) to connect to the computing resources in the neighboring
    cloudlet [15]. To ensure crisp reaction time, cloudlets constitute the intermediate
    tier in a 3-tier hierarchical architecture containing Edge device layer, cloudlet
    layer, and cloud layer. For security reasons, cloudlet is bounded in a tamper
    resistant box for safeguarding safety in unregulated regions [9]. On the inside,
    cloudlets consist of a group of source rich multicore computer with high-speed
    internet connection and higher bandwidth wireless LAN for the use by closer mobile
    gadgets (Fig. 1). Download : Download high-res image (198KB) Download : Download
    full-size image Fig. 1. Three tier view of cloud data centers at edge network.
    The Cloudlet is an architecture model that enables cloud computing at the mobile
    network''s edge. Low latency and high bandwidth characterize this environment,
    forming a fresh ecosystem in which network service provider can open their network
    edge for third party user, allowing them to quickly and flexibly install creative
    and innovative services. 6. Significance of cloudlets The purpose of a cloudlet
    is to improve the response time of mobile apps by employing low-latency, high-bandwidth
    wireless communication and physically bringing cloud computing resources, such
    as virtual computers, closer to the mobile devices that access them [23]. Cloudlet
    vs Cloud: Cloudlets differ from Cloud in many cases: 1. Clouds are normally monitored
    by their service providers whereas cloudlet is self-managed. 2. Provider locate
    the cloud in purpose specific areas at his premises, on the other hand cloudlet
    are located in business premises in the form of a data center in a box. 3. Cloud
    uses internet bandwidth/latency whereas cloudlet uses the latency/ bandwidth of
    a local area network. 4. Since cloud has a centralized ownership, cloudlet is
    owned by the local business/organization. 5. Cloud can accommodate hundreds and
    thousands of users at a time but cloudlet can accommodate only few users. Benefits:
    Cloudlet resides as a middle layer in its three tier view, offering various benefits
    in the edge infrastructure 1. Simple to set up: The fact that cloudlet servers
    are exiled makes maintenance easier; adding or replacing of a cloudlet just takes
    few minutes for setup and simple steps of configuration. 2. Enhancement of security:
    The cloudlet''s proximity to mobile nodes makes the architecture more resistant
    to DoS attacks (secondary variants). It can also help to avoid data leakage from
    traffic analysis by limiting the range of end-to-end connection, which prohibits
    snoopers from accessing traffic data from afar. 3. Resilience: Even with shaky
    connectivity to a remote cloud provider, a cloudlet collection can provide dependable
    cloud computing services. Mobile Edge Computing (MEC): Multi-access Edge Computing,
    also known as Mobile Edge Computing (MEC), is a network design that allows computational
    and storage resources to be placed within the Radio Access Network (RAN). The
    MEC aids in improving network efficiency and content delivery to end-users. This
    device can do this by adapting over the load available on the radio link, resulting
    into increase in network efficiency and reducing the requirement for long-distance
    backlogs. MEC offers mobile and cloud computational abilities among the access
    system, and goals to unite the telco and IT at the mobile edge network [19]. As
    in near locations to users, MEC can provide a service environment with ultra-low
    latencies, high bandwidth, and direct entree to real time system data [23], [24].
    Mobile Edge Computing is the principal technology among the next gen system technologies.
    As per European Telecommunications Standards Institute (ETSI), mobile edge computing
    is defined as “Mobile Edge Computing offers an IT service environment and cloud
    computing capabilities at the mobile network''s edge, within the Radio Access
    Network (RAN), and close to mobile customers.” Listed below are few characteristics
    of MEC: Download : Download high-res image (571KB) Download : Download full-size
    image MEC is a layer that sits between mobile devices and the cloud. As a result,
    the infrastructure is organized into three layers: cloud layer, MEC layer, and
    mobile device layer. Mobile edge computing, for the most part, works in tandem
    with cloud computing for supporting and improving the performance of end devices
    (Fig. 2). Download : Download high-res image (324KB) Download : Download full-size
    image Fig. 2. General architecture: three tier view of MEC. 6.1. MEC benefits
    Listed below are some advantages of Mobile Edge Computing (MEC) that are proving
    to be beneficial to both Mobile Network Operators (MNOs) and application service
    providers. • Mobile network operators might provide third-party suppliers with
    real-time access, allowing them to deploy their applications and services in a
    more flexible and agile manner. These services could make money by charging for
    things like storage, bandwidth, and other IT resources. • MEC-enabled infrastructure-as-a-service
    (IaaS) platforms at the network edge node could benefit application service providers
    by allowing them to scale their services while maintaining higher bandwidth and
    reduced latency. ASPs may also gain real-time access to radio pursuit that is
    likely to develop. • End users may perform faster computation by offloading the
    MES servers. • Driving business model evolution—The capacity to collect or process
    data from any facility''s base leads to the development of a wide range of business
    models. Evolution of the Industry 4.0 is a best example for this. In this case,
    mobile edge computing can act as an enabler for developing a proactive maintenance
    business model to extend the life of any resources. • A new way to run your business
    more efficiently—Mobile edge computing will allow SMEs to grow their marketing
    efforts, reach more customers, and improve their services at considerably lower
    costs than the public cloud. 6.2. FOG computing Fog computing is a framework hierarchical
    architecture defined by the OpenFog Consortium as a horizontal architecture that
    divides processing, storage, control, and connectivity services and goods anywhere
    along the spectrum from the fog to things [5], [19]. Fog computing differs from
    edge computing in that it includes tools for across networks and between edge
    devices for spreading, coordinating, controlling, and protecting resources and
    services [1]. It is also known as Fog networking or fogging. It is a decentralized
    infrastructure where application resides between data stores and the cloud. It
    is an architecture which uses edge device for computation, storage and communication
    [19]. This edge device is the device that controls the data flow at the boundaries
    of any two networks, example: router, switch, IAD, gateways, hub, multiplexer
    or bridge. It is actually a mediator between hardware and remote server. Fog is
    a distributed network environment and is very close to cloud computing and IoT
    device. It has a high security network. Instead of sending selected data to the
    cloud for processing, fog actually process the data which saves the network bandwidth
    and reduces latency requirement which in turn helps in fast decision making capability
    (Fig. 3). Download : Download high-res image (228KB) Download : Download full-size
    image Fig. 3. Three tier view of Fog infrastructure. Definition: Some researchers
    have defined Fog computing as: “Fog computing is a highly virtualized platform
    that provides compute, storage, and networking services between IoT devices and
    traditional cloud computing data centers, typically, but not exclusively located
    at the edge of network.” “Fog computing is a scenario where a huge number of heterogeneous
    (wireless and sometimes autonomous) ubiquitous and decentralised devices communicate
    and potentially cooperate among them and with the network to perform storage and
    processing tasks without the intervention of third parties. These tasks can be
    for supporting basic network functions or new services and applications that run
    in a sandboxed environment. Users leasing part of their devices to host these
    services get incentives for doing so.” “The term Fog computing or Edge Computing
    means that rather than hosting and working from a centralized cloud, Fog systems
    operate on network ends. It is a term for placing some processes and resources
    at the edge of the cloud, instead of establishing channels for cloud storage and
    utilization.” Considering these definitions we can define Fog computing as: “A
    distributed computing platform in which end or edge devices perform the majority
    of the work. By existing in between users and the cloud, it is also associated
    with the cloud for non-latency-aware processing and long-term storage of important
    data.” 6.3. Benefits 6.3.1. Confidentiality Fog computing can be used to keep
    the quantity of data shared to a minimum. Instead of sending sensitive personal
    information to a centralized cloud platform, any confidential material can be
    reviewed regionally. In this way, the IT staff will be able to monitor and control
    the device. Any portion of data that has to be analyzed can also be sent to the
    cloud [6]. 6.3.2. Efficiency Clients can employ fog procedures to make the machine
    function effectively they want it to. Publishers may easily design these fog applications
    with the right combination of tools. They can use it whenever they want once the
    job gets completed [13]. 6.3.3. Safety and security Fog computing supports multiple
    devices to be connected to the same network. As a result, rather from being consolidated,
    processes in a complex decentralized system take place at multiple end terminals.
    This makes it easier to identify potential threats before they have a large-scale
    impact on the network [5]. 6.3.4. Bandwidth The cost of bandwidth required for
    data transmission depends on the availability of resources and it can be costly
    [7]. The throughput requirements are greatly decreased because the chosen processing
    is done locally instead of being transferred to the cloud. This bandwidth reduction
    will be particularly significant as the number of Internet—connected devices grows.
    When the number of IoT devices grows, this bandwidth savings will be especially
    useful. Fog computing allows multiple devices to share a common network. As a
    result, instead of being centralized, processes in a complex distributed system
    occur at multiple end points. This makes it easier to identify potential threats
    before they spread throughout the network. 6.3.5. Latency Another advantage of
    processing data locally is the reduction in latency. The data can be analyzed
    or processed at the data source that is expected to be geographically nearer to
    the user. This can result in instantaneous responses, which is highly valuable
    for services that require quick reactions [4]. Several edge computing systems
    have emerged from various backgrounds in order to reduce latency, increase computational
    capabilities and handle huge machine connectivity. This study provides an in-depth
    look at three common edge computing technologies: mobile edge computing (MEC),
    cloudlets, and fog computing. 6.4. Edge computing applications There are various
    applications of Edge computing, some are listed below (Fig. 4): Download : Download
    high-res image (209KB) Download : Download full-size image Fig. 4. Edge computing
    applications. 6.4.1. Smart systems It comprises of IoT devices used as home essentials
    like smart TVs, smart phones, smart lights, CCTV cameras etc. Smart systems also
    include devices used for monitoring air quality index, weather conditions, traffic
    management, smart gardening and others which will help in making smart city. All
    those systems used in healthcare like fitness tracker, apps for pandemic diseases
    (Arogya setu) are also a part of smart systems [25]. 6.4.2. Video streaming Various
    reports have highlighted the statistics that video streaming on internet will
    be capturing almost 83% of all internet traffic by 2022. This video streaming
    requires good bandwidth resources and cache requirement which directly affect
    the cost parameter and the video quality. Edge computing is undoubtedly providing
    a reasonable mechanism to cache the local video. These devices are embedded with
    filtering capability, to figure out useful data [16]. 6.4.3. Remote monitoring
    and predictive analysis With the help of edge computing enabled IoT devices manufactures
    are now able to remotely monitor their assets more carefully and at early stage
    before they create any disaster. Bringing the processing capabilities closer to
    the device, has helped in predicting the real-time health status of the machines
    [20]. This may beneficial in analyzing and detecting the changes required in production
    line before any failure occurs. 6.4.4. Gaming-as-a-service It is a kind of online
    video game that runs on a cloud server and directly stream on the player''s device
    [26]. Xbox, a Microsoft soft product is a cloud gaming service, where game itself
    is hosted and processed in cloud data centers but feed directly to the gamers
    device through real time streaming. Edge and 5G connectivity integrations provides
    the bandwidths required to aid high quality, multi-player gaming experiences.
    Edge is not only restricted to the gaming but it is also the future of mobile
    applications. It significantly contributes into the future of industries adopting
    hybrid multi-clouds & edge structures as it plays a crucial role in the digital
    structures. Mobile experience will be more real-time, more interactive, and rich
    in handling/operating just because it will be because of edge computing [23].
    6.4.5. 5G communications For lower latency and higher throughput 5G communication
    is required. 5G is considered as a next gen. Cellular network. With edge computing
    it is possible to bring the cloud computing capabilities closer to the end user
    or to the edge of network. Cloud computing where there is high latency, low throughput
    and less security, edge computing combat with all mentioned problem and improves
    the user experience. 5G and edge computing technologies are capable to improve
    the application''s performance significantly. Specially where data is to be processed
    in real time, 5G increases speeds 10 times in comparison to 4G and edge computing
    reduces the latency by bringing the computational capabilities to the edge of
    the network. This deadly combination of 5G and edge computing improves the users
    real time application''s experience. 6.4.6. 5G smart health care 5G smart health
    care, on the other hand, has far more grave safety and seclusion apprehension
    than traditional healthcare services. Traditional medical services are altered
    by 5G medical applications, which extend them from the healthcare center to an
    online examine mode that involves many users, data systems, and medical devices,
    is embedded by posing serious security, massive medical data transmission, and
    privacy challenges. The quality of medical services and the routine operations
    of medical facilities will be severely harmed by security weaknesses in terminals,
    networks, and systems. Science and technology in healthcare area is a considerable
    study part for countless scholars. Similar to various manufacturing, health care
    subdivision can also be assisted from edge, for example heart patients suffering
    from heart attack [14]. Health care application are generally regarded time sensitive
    applications in Internet of Things. At first, cloud computing was utilized for
    health care implementations but was not great success due to latencies problems.
    Introduction of edge solved these problems & made cloud accurate for health care
    IoT uses. Into the smart clinics edge is currently used in numerous ways, like
    in wireless health regulation the data received from the affected ones directed
    to the physicians which eases them to tackle the emergencies [1]. Meanwhile, there
    are no 5G security standards or 5G medical engineering safety standards in place,
    and it''s unclear to concern security protection for 5G health check appliances.
    6.4.7. Security monitoring Various IoT devices like Intrusion detection systems
    (IDS) are deployed on either ends of communicators for an efficient network monitoring.
    It helps in security and privacy related issues while transmitting data either
    from one network to another or from data centers to edge device [19]. 6.4.8. AR
    and VR Augmented Reality (AR) and Virtual Reality (VR) is one of the rapidly growing
    industry. Reason is both helps in reducing the cost and time to perform any task,
    for example remotely managed any operation [2]. By removing the geographical barriers
    any operation and be performed by the experts sitting on same or different places.
    But presently the biggest problem with deployment of such applications is comprehensive
    deployment of mobile AR is that current devices. Still there is a need to improve
    the computational power, data communication and graphical performance. With the
    edge computing all computational task could be taken care by the edge of network
    and will help in improved performance in all aspects. Challenges that can now
    be overcome by 5G and edge computing by performing computation at the network
    edge and not need to send and receive data frequently to/from cloud and will support
    more and more real-life applications [19] (Fig. 5). Download : Download high-res
    image (188KB) Download : Download full-size image Fig. 5. Applications of edge
    computing. 6.5. Edge computing and future Edge computing is currently in its early
    stages and has a great capability to pave the pathway for more effective dispersed
    computations [19]. The prime goals of edge computing are to give real time interactions,
    local processing, higher data rates, and higher availabilities. Edge advances
    network actions to assist and locations varied scenes, like distant surgeries
    [17]. The flaws and lacunas of cloud and fog are completed by the edge computing
    to a greater amount which has consequence in low response time, lower latency,
    lower bandwidth price, lesser energy usage and superior and higher data privacy.
    The significance and need of edge computing is acceptable with the assistance
    of few of the upcoming sectors and appliances that are extensively utilized in
    recent times like smart city, smart houses, online marketing, etc. So, to offer
    an advanced and well-organized facility to IoT smart applications, the idea of
    edge computing is able to execute all the functions by going beyond the cloud
    capabilities. Edge visions to get facilities and efficacies of Clouds near to
    the handler for safeguarding fast processing of data-concentrated apps. Video
    analytics, online shopping, smart cities, smart homes, digital health care, mutual
    edge and high privacy apps are few of the extensively utilized famous areas &
    applications that uses the idea of edge. Transferring data processes through the
    edge networks will be helpful to companies so that they can take benefit of the
    increasing quantities of IoT gadgets, advance network speeds, and increase customer
    experiences. Scalable behavior of the edge also makes it an appropriate option
    for the rapidly developing, sprightly industries, particularly to those who uses
    data centers and utilizes cloud substructures [1]. Edge gives an unprecedented
    benefit of flexibility and reliability which will increase of each product combined
    or integrated with it resulting into customer satisfaction. Edge computing provides
    varied benefits over conventional type of network structures and will definitely
    play a significant part in near future. With the advancement in internet associated
    gadgets coming in markets everyday advanced administrations have just scratched
    the uppermost part of what''s possible with Edge. 6.6. Shortcomings of edge computing
    So far the chapter talks about edge computing and benefits of its use over the
    cloud computing. Every technology be it cloud or edge computing have some drawbacks
    and give scope of improvements in the technologies. It also help in discovering
    the scope and hope for new technologies [4]. Like other technologies, Edge computing
    also has some Shortcomings. This section will elaborate the same. With Edge devices,
    (used for edge computing) open the door for the various attacks [10]. With different
    attacks, an attacker can inject malicious activity. Edge devices can be infect
    with these attacks which may lead to A software or even entire network may be
    infected. These attacks are difficult to manage adequately due to distributed
    environment. Another problem is cost. Though with the edge computing we can reduce
    the computing but at the same time its maintenance cost will increase. The main
    reason for higher maintenance cost is typically used of various edge devices,
    maintenance team should be knowledgeable enough to manage this technology. 7.
    Conclusion This chapter briefly introduced cloud computing and given a more comprehensive
    definition of edge computing. The chapter talk about various technologies around
    the edge computing. After a deep discussion about the technology various benefits
    out of use of the same explained widely. The chapter also discuss the journey
    from cloud computing and edge computing in detail. Various applications after
    detailed explanation also major part of the chapter. Though, there are noteworthy
    security threats within IoT gadgets, which means edge security is most vital than
    ever. Along with the threat resolvase techniques, edge also gives a chance to
    improve the security by researching the related areas. The chapter concludes that
    the edge computing has tremendous benefits over the cloud computing and helpful
    to overcome the limitations of traditional and cloud computing. With 5G and edge
    technology there is very bright future of many real time applications. References
    [1] K. Saini, V. Agarwal, A. Varshney, A. Gupta E2EE for data security for hybrid
    cloud services: a novel approach IEEE International Conference on Advances in
    Computing, Communication Control and Networking (IEEE ICACCCN 2018) Organized
    by Galgotias College of Engineering & Technology Greater Noida , 12–13 October,
    2018 (2018), 10.1109/ICACCCN.2018.8748782 Google Scholar [2] I. Goodfellow, et
    al. Generative adversarial nets Proc. Adv. Neural Inf. Process. Syst. (2014),
    pp. 2672-2680 Google Scholar [3] H.T. Dinh, C. Lee, D. Niyato, P. Wang A survey
    of mobile cloud computing: architecture, applications, and approaches Wirel. Commun.
    Mob. Comput. (2013) Google Scholar [4] P.J. Werbos Backpropagation through time:
    what it does and how to do it Proc. IEEE, 78 (10) (1990), pp. 1550-1560 View in
    ScopusGoogle Scholar [5] S.R. Jena, R. Shanmugam, R. Dhanaraj, K. Saini Recent
    advances and future research directions in edge cloud framework Int. J. Eng. Adv.
    Technol., 2249-8958, 9 (2) (2019), 10.35940/ijeat.B3090.129219 Google Scholar
    [6] V. Mnih, et al. Human-level control through deep reinforcement learning Nature,
    518 (7540) (2015), p. 529 CrossRefView in ScopusGoogle Scholar [7] S.R. Jena,
    R. Shanmugam, K. Saini, S. Kumar Cloud computing tools: inside views and analysis
    International Conference on Smart Sustainable Intelligent Computing and Applications
    under ICITETM2020, Elsevier (2020), pp. 382-391 View PDFView articleView in ScopusGoogle
    Scholar [8] F. Bonomi, R. Milito, J. Zhu, S. Addepalli Fog computing and its role
    in the internet of things Workshop on Mobile Cloud Computing, ACM (2012) Google
    Scholar [9] C. Szegedy, et al. Going deeper with convolutions Proceedings of the
    IEEE Conference on Computer Vision and Pattern Recognition (2015), pp. 1-9 CrossRefGoogle
    Scholar [10] K. Saini, P. Raj Handbook of Research on Smarter and Secure Industrial
    Applications Using AI, IoT, and Blockchain Technology IGI Global (2021) ISBN13:
    9781799883678, ISBN10: 1799883671, EISBN13: 9781799883685 Google Scholar [11]
    Z. Liu, Z. Dai, P. Yu, Q. Jin, H. Du, Z. Chu, D. Wu Intelligent station area recognition
    technology based on NB-IoT and SVM Proceedings of the IEEE 28th International
    Symposium on Industrial Electronics (2019), pp. 1827-1832 CrossRefView in ScopusGoogle
    Scholar [12] J. Marescaux, J. Leroy, M. Gagner, et al. Transatlantic robot-assisted
    telesurgery Nature, 413 (2001), pp. 379-380 View in ScopusGoogle Scholar [13]
    I. Stojmenovic, S. Wen The fog computing paradigm: scenarios and security issues
    Federated Conference on Computer Science and Information Systems (FedCSIS), IEEE
    (2014) Google Scholar [14] M. Satyanarayanan, P. Bahl, R. Caceres, N. Davies The
    case for VM-based cloudlets in mobile computing IEEE Pervasive Comput., 4 (2009),
    pp. 14-23 View in ScopusGoogle Scholar [15] C.-C. Hung, et al. VideoEdge: processing
    camera streams using hierarchical clusters Proceedings of the IEEE/ACM Symposium
    on Edge Computing (SEC) (2018), pp. 115-131 CrossRefView in ScopusGoogle Scholar
    [16] K. Hong, D. Lillethun, U. Ramachandran, B. Ottenwalder, B. Kold-ehofe Opportunistic
    spatio-temporal event processing for mobile situation awareness Proceedings of
    the ACM International Conference on Distributed Event-Based Systems (2013) Google
    Scholar [17] L.M. Vaquero, L. Rodero-Merino Finding your way in the fog: towards
    a comprehensive definition of fog computing ACM SIGCOMM CCR (2014) Google Scholar
    [18] I. Stojmenovic Fog computing: a cloud to the ground support for smart things
    and machine-to-machine networks Telecommunication Networks and Applications Conference
    (ATNAC), IEEE (2014) Google Scholar [19] S. Hochreiter, J. Schmidhuber Long short-term
    memory Neural Comput., 9 (8) (1997), pp. 1735-1780 CrossRefView in ScopusGoogle
    Scholar [20] J. Zhu, et al. Improving web sites performance using edge servers
    in fog computing architecture SOSE, IEEE (2013) [12] H. Madsen, G. Albeanu, B.
    Burtschy, and F. Popentiu-Vladicescu, “Reliability in the utility computing era:
    Towards reliable fog computing,” in IEEE International Conference on Systems,
    Signals and Image Processing (IWSSIP), 2013 Google Scholar [21] S. Yi, Z. Qin,
    Q. Li Security and privacy issues of fog computing: a survey International Conference
    on Wireless Algorithms, Systems and Applications (WASA) (2015) Google Scholar
    [22] D.N. Le, R. Kumar, B.K. Mishra, J.M. Chatterjee, M. Khari, (Eds.). Cyber
    Security in Parallel and Distributed Computing: Concepts, Techniques, Applications
    and Case Studies John Wiley & Sons (2019) Google Scholar [23] B. Chen, S. Qiao,
    J. Zhao, D. Liu, X. Shi, M. Lyu, H. Chen, H. Lu, Y. Zhai A security awareness
    and protection system for 5G smart healthcare based on zero-trust architecture
    IEEE Internet Things J. (2020), 10.1109/JIOT.2020.3041042 Google Scholar [24]
    B. Ottenwalder, B. Koldehofe, K. Rothermel, U. Ramachandran Migcep: operator migration
    for mobility driven distributed complex event processing Proceedings of the ACM
    International Conference on Distributed Event-Based Systems (2013) Google Scholar
    [25] K. Hong, D. Lillethun, U. Ramachandran, B. Ottenwalder, B. Kold-ehofe Mobile
    fog: a programming model for large-scale applications on the internet of things
    ACM SIGCOMM Workshop on Mobile Cloud Computing (2013) Google Scholar [26] S. Yi,
    C. Li, Q. Li A survey of fog computing: concepts, applications and issues Proceedings
    of the 2015 Workshop on Mobile Big Data, ACM (2015) Google Scholar Cited by (7)
    Applications of food packaging quick response codes in information transmission
    toward food supply chain integrity 2024, Trends in Food Science and Technology
    Show abstract Artificial intelligence and machine learning in healthcare 2024,
    Biomedical Research Developments for Improved Healthcare Fog Computing: The Secret
    Sauce for Immersive Tech Experiences 2024, Lecture Notes in Networks and Systems
    Role of Dew Computing in Smart Healthcare Applications 2024, Internet of Things
    The Foggy Frontier: Exploring the Fog and Edge Computing for Online Games 2024,
    Communications in Computer and Information Science Integration of Digital Twin
    and Federated Learning for Securing Vehicular Internet of Things 2023, 2023 Research
    in Adaptive and Convergent Systems RACS 2023 View all citing articles on Scopus
    Kavita Saini, is presently working as professor, School of Computing Science and
    Engineering, Galgotias University, Delhi NCR, India. She received her PhD degree
    from Banasthali Vidyapeeth, Banasthali. She has 18 years of teaching and research
    experience supervising Masters and PhD scholars in emerging technologies. She
    has published more than 40 research papers in national and international journals
    and conferences. She has published 17 authored books for UG and PG courses for
    a number of universities including MD University, Rothak, and Punjab Technical
    University, Jallandhar with National Publishers. Kavita Saini has edited many
    books with International Publishers including IGI Global, CRC Press, IET Publisher
    Elsevier and published 15 book chapters with International Publishers. Under her
    guidance many MTech and PhD scholars are carrying out research work. She has also
    published various patents. She has also delivered technical talks on Blockchain:
    An Emerging Technology, Web to Deep Web, and other emerging areas and handled
    many special sessions in International Conferences and Special Issues in International
    Journals. Her research interests include Web-Based Instructional Systems (WBIS),
    Blockchain Technology, Industry 4.O, and Cloud Computing. Pethuru Raj working
    as a chief architect at Reliance Jio Platforms Ltd. (JPL) Bangalore. Previously.
    worked in IBM global Cloud center of Excellence (CoE), Wipro consulting services
    (WCS), and Robert Bosch Corporate Research (CR). In total, I have gained more
    than 20 years of IT industry experience and 8 years of research experience. Finished
    the CSIR-sponsored Ph.D. degree at Anna University, Chennai and continued with
    the UGC-sponsored postdoctoral research in the Department of Computer Science
    and Automation, Indian Institute of Science (IISc), Bangalore. Thereafter, I was
    granted a couple of international research fellowships (JSPS and JST) to work
    as a research scientist for 3.5 years in two leading Japanese universities. Focuses
    on some of the emerging technologies such as the Internet of Things (IoT), Optimization
    of Artificial Intelligence (AI) Models, Big, fast and streaming Analytics, Blockchain,
    Digital Twins, Cloud-native computing, Edge and Serverless computing, Reliability
    engineering, Microservices architecture (MSA), Event-driven architecture (EDA),
    5G, etc. My personal web site is at https://sweetypeterdarren.wixsite.com/pethuru-raj-books/my-books
    https://scholar.google.co.in/citations?user=yaDflpYAAAAJ&hl=en. View Abstract
    Copyright © 2022 Elsevier Inc. All rights reserved. Part of volume Edge/Fog Computing
    Paradigm: The Concept Platforms and Applications Edited by Pethuru Raj, Kavita
    Saini, Chellammal Surianarayanan Download full volume Recommended articles Article
    Metrics Citations Citation Indexes: 3 Captures Readers: 14 View details About
    ScienceDirect Remote access Shopping cart Advertise Contact and support Terms
    and conditions Privacy policy Cookies are used by this site. Cookie settings |
    Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V.,
    its licensors, and contributors. All rights are reserved, including those for
    text and data mining, AI training, and similar technologies. For all open access
    content, the Creative Commons licensing terms apply."'
  inline_citation: '>'
  journal: Advances in Computers
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Edge platforms, frameworks and applications
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Roy C.
  - Das N.
  - Rautaray S.S.
  - Pandey M.
  citation_count: '2'
  description: Pests and crop diseases have remained a constant threat to overall
    crop production quality and quantity throughout the ages. Therefore, their timely
    and accurate predictions could significantly reduce worldwide economic losses
    while also reducing the harmful environmental impact of fertilizers and pesticides.
    Cloud computing and the IoT can build an interconnected network in this circumstance.
    These two frameworks are not yet able to solve the problems of computing. Fog
    computing aims to push processing capabilities closer to target consumers, prevent
    overuse of cloud resources, and further reduce operational loads. The proposed
    approach to fog computing is applicable to the evolving field of precision agriculture,
    along with all agricultural land management strategies. We now need a method of
    forecasting that can accurately predict crop disease from the symptoms that are
    monitored.
  doi: 10.1016/B978-0-12-823694-9.00006-2
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln Access through another institution
    University of Nebraska-Lincoln Libraries does not subscribe to this content on
    ScienceDirect. Article preview Abstract Cited by (2) AI, Edge and IoT-based Smart
    Agriculture Intelligent Data-Centric Systems 2022, Pages 287-300 Chapter 16 -
    A fog computing-based IoT framework for prediction of crop disease using big data
    analytics Author links open overlay panel Chandrima Roy, Nivedita Das, Siddharth
    Swarup Rautaray, Manjusha Pandey Show more Share Cite https://doi.org/10.1016/B978-0-12-823694-9.00006-2
    Get rights and content Abstract Pests and crop diseases have remained a constant
    threat to overall crop production quality and quantity throughout the ages. Therefore,
    their timely and accurate predictions could significantly reduce worldwide economic
    losses while also reducing the harmful environmental impact of fertilizers and
    pesticides. Cloud computing and the IoT can build an interconnected network in
    this circumstance. These two frameworks are not yet able to solve the problems
    of computing. Fog computing aims to push processing capabilities closer to target
    consumers, prevent overuse of cloud resources, and further reduce operational
    loads. The proposed approach to fog computing is applicable to the evolving field
    of precision agriculture, along with all agricultural land management strategies.
    We now need a method of forecasting that can accurately predict crop disease from
    the symptoms that are monitored. References (0) Cited by (2) Cooperative and distributed
    intelligent computation in fog computing: Concepts, architectures, and frameworks
    2023, Cooperative and Distributed Intelligent Computation in Fog Computing: Concepts,
    Architectures, and Frameworks IoT-Based Smart Ankle-Foot Orthosis for Patients
    with Gait Imbalance 2023, International Conference on Control, Automation and
    Systems View full text Copyright © 2022 Elsevier Inc. All rights reserved. Recommended
    articles Cyberespionage: Socioeconomic implications on sustainable food security
    AI, Edge and IoT-based Smart Agriculture, 2022, pp. 477-486 Charles Oluwaseun
    Adetunji, …, Kingsley Eghonghon Ukhurebor Decision-making system for crop selection
    based on soil AI, Edge and IoT-based Smart Agriculture, 2022, pp. 449-475 Jitendra
    Singh, …, P.K. Pandey Smart irrigation and crop security in agriculture using
    IoT AI, Edge and IoT-based Smart Agriculture, 2022, pp. 143-155 Sugamya Katta,
    …, Harika Sammeta Show 3 more articles Article Metrics Citations Citation Indexes:
    2 Captures Readers: 15 View details About ScienceDirect Remote access Shopping
    cart Advertise Contact and support Terms and conditions Privacy policy Cookies
    are used by this site. Cookie settings | Your Privacy Choices All content on this
    site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights
    are reserved, including those for text and data mining, AI training, and similar
    technologies. For all open access content, the Creative Commons licensing terms
    apply."'
  inline_citation: '>'
  journal: AI, Edge and IoT-based Smart Agriculture
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: A fog computing-based IoT framework for prediction of crop disease using
    big data analytics
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Barriga J.A.
  - Clemente P.J.
  - Sosa-Sanchez E.
  - Prieto A.E.
  citation_count: '19'
  description: Internet of Things (IoT) is being applied to areas as smart-cities,
    home environment, agriculture, industry, etc. Developing, deploying and testing
    IoT projects require high investments on devices, fog nodes, cloud nodes, analytic
    nodes, hardware and software. New projects require high investments on devices,
    fog nodes, cloud nodes, analytic nodes, hardware and software before each system
    can be developed. In addition, the systems should be developed to test them, which
    implies time, effort and development costs. However, in order to decrease the
    cost associated to develop and test the system the IoT system can be simulated.
    Thus, simulating environments help to model the system, reasoning about it, and
    take advantage of the knowledge obtained to optimize it. Designing IoT simulation
    environments has been tackled focusing on low level aspects such as networks,
    motes and so on more than focusing on the high level concepts related to IoT environments.
    Additionally, the simulation users require high IoT knowledge and usually programming
    capabilities in order to implement the IoT environment simulation. The concepts
    to manage in an IoT simulation includes the common layers of an IoT environment
    including Edge, Fog and Cloud computing and heterogeneous technology. Model-driven
    development is an emerging software engineering area which aims to develop the
    software systems from domain models which capture at high level the domain concepts
    and relationships, generating from them the software artefacts by using code-generators.
    In this paper, a model-driven development approach has been developed to define,
    generate code and deploy IoT systems simulation. This approach makes it possible
    to design complex IoT simulation environments and deploy them without writing
    code. To do this, a domain metamodel, a graphical concrete syntax and a model
    to text transformation have been developed. The IoT simulation environment generated
    from each model includes the sensors, actuators, fog nodes, cloud nodes and analytical
    characteristics, which are deployed as microservices and Docker containers and
    where elements are connected by using publish-subscribe communication protocol.
    Additionally, two case studies, focused on smart building and agriculture IoT
    environments, are presented to show the simulation expressiveness.
  doi: 10.1109/ACCESS.2021.3092528
  full_citation: '>'
  full_text: '>

    "IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account
    Personal Sign In Browse My Settings Help Access provided by: University of Nebraska
    - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards
    Authors Citations ADVANCED SEARCH Journals & Magazines >IEEE Access >Volume: 9
    SimulateIoT: Domain Specific Language to Design, Code Generation and Execute IoT
    Simulation Environments Publisher: IEEE Cite This PDF José A. Barriga; Pedro J.
    Clemente; Encarna Sosa-Sánchez; Álvaro E. Prieto All Authors 17 Cites in Papers
    2150 Full Text Views Open Access Comment(s) Under a Creative Commons License Abstract
    Document Sections I. Introduction II. Related Works III. SimulateIoT Methodology
    IV. SimulateIoT Tools V. Case Studies Show Full Outline Authors Figures References
    Citations Keywords Metrics Abstract: Internet of Things (IoT) is being applied
    to areas as smart-cities, home environment, agriculture, industry, etc. Developing,
    deploying and testing IoT projects require high investments on devices, fog nodes,
    cloud nodes, analytic nodes, hardware and software. New projects require high
    investments on devices, fog nodes, cloud nodes, analytic nodes, hardware and software
    before each system can be developed. In addition, the systems should be developed
    to test them, which implies time, effort and development costs. However, in order
    to decrease the cost associated to develop and test the system the IoT system
    can be simulated. Thus, simulating environments help to model the system, reasoning
    about it, and take advantage of the knowledge obtained to optimize it. Designing
    IoT simulation environments has been tackled focusing on low level aspects such
    as networks, motes and so on more than focusing on the high level concepts related
    to IoT environments. Additionally, the simulation users require high IoT knowledge
    and usually programming capabilities in order to implement the IoT environment
    simulation. The concepts to manage in an IoT simulation includes the common layers
    of an IoT environment including Edge, Fog and Cloud computing and heterogeneous
    technology. Model-driven development is an emerging software engineering area
    which aims to develop the software systems from domain models which capture at
    high level the domain concepts and relationships, generating from them the software
    artefacts by using code-generators. In this paper, a model-driven development
    approach has been developed to define, generate code and deploy IoT systems simulation.
    This approach makes it possible to design complex IoT simulation environments
    and deploy them without writing code. To do this, a domain metamodel, a graphical
    concrete syntax and a model to text transformation have been developed. The IoT
    simulation environment generated from each model includes the sensors, actuators,
    fog... (Show More) In this paper, a model-driven development approach has been
    developed to define, generate code and deploy IoT systems simulation. This approach
    makes it possible to desig...View more Published in: IEEE Access ( Volume: 9)
    Page(s): 92531 - 92552 Date of Publication: 25 June 2021 Electronic ISSN: 2169-3536
    DOI: 10.1109/ACCESS.2021.3092528 Publisher: IEEE Funding Agency: CCBY - IEEE is
    not the copyright holder of this material. Please follow the instructions via
    https://creativecommons.org/licenses/by/4.0/ to obtain full-text articles and
    stipulations in the API documentation. SECTION I. Introduction The Internet of
    Things (IoT) is widely applied in several areas such as smart-cities, home environments,
    agriculture, industry, intelligent buildings, etc. [46]. Usually, these IoT environments
    require using hundreds of sensors and actuators shared throughout these areas
    which are generating a vast amount of data. Data must be suitably stored, analysed
    and published using Big Data or Stream Processing techniques. Big Data or Stream
    Processing techniques must be applied to conveniently store and analyse published
    data. Taking into account where data are processed and stored, the IoT environment
    architecture can be defined by several computing layers (Edge, Fog and Cloud computing
    (see Figure 1) [30]). Edge layer is defined closer to data generators, Fog layer
    resides on top of the edge and act as intermediary layer with limited storing
    and processing capabilities and Cloud layer is defined with full storing and processing
    capabilities. Thus, the development of IoT systems requires the management and
    integration of conveniently heterogeneous technologies such as devices, actuators,
    databases, communication protocols, stream processing engines, etc. As a consequence,
    in order to implement, deploy and test the IoT systems a high investment must
    be made in time, money and effort. FIGURE 1. IoT architecture: Cloud, Fog and
    Edge computing. Show All Simulating IoT environments is one way to decrease this
    initial investment because the users can measure and dimension the artefacts needed
    to deploy and interconnect the systems. Thus, these artefacts can include several
    kinds of devices from sensors or actuators to NoSQL databases, messaging brokers
    or stream processor engines. However, although there are several simulation environments
    for wireless sensor networks (WSN), there is a lack of IoT simulator tools for
    designing IoT environments at a high level that enable modeling this kind of systems
    by using the domain concepts and relationships. In addition, there is a lack of
    IoT simulation tools that makes it possible to deploy the IoT system on multiple
    nodes in order to test the communications among the system’s elements and where
    complex IoT components such as databases, complex event processing or message
    brokers can be suitable deployed and tested. Currently, there is a lack of methodologies
    and tools to simulate IoT systems and allow users to properly describe the IoT
    environment. Currently, not only tools are needed but also methodologies to guide
    the simulation designing and simulation process of IoT environments. So, both
    methodologies and tools to simulate IoT systems are interesting research areas.
    should be developed. Thus, while methodologies would allow developers to describe
    the steps and the characteristics to simulate IoT systems, the tools would help
    to design and execute the IoT environment simulated in sandbox environments. These
    tools should take into account the main IoT characteristics including heterogeneous
    devices (sensors and actuators), heterogeneous communication mechanisms such as
    publish-subscribe communication protocol, analysis from information generated,
    storing of information, etc. However, an IoT environment is a broad and heterogeneous
    concept which involves heterogeneous technologies such as communication protocols
    such as publish-subscribe communication protocol, databases, analysis tools, etc.
    Not only should IoT methodologies and tools be designed and developed, but they
    should also be carried out using software engineering good practices. Model-Driven
    Development is an emerging software engineering research area that aims to develop
    software guided by models based on Metamodeling technique. Metamodeling is defined
    by four model layers (see Figure 2). Thus, a Model (M1) is conform to a MetaModel
    (M2). Moreover, a Metamodel conforms to a MetaMetaModel (M3) which is reflexive
    [2]. The MetaMetaModel level is represented by well-known standards and specifications
    such as Meta-Object Facilities (MOF) [29], ECore in EMF [48] and so on. A MetaModel
    defines the domain concepts and relationships in a specific domain in order to
    model partial reality. A Model (M1) defines a concrete system conform to a Metamodel.
    Then, from these models it is possible to generate totally or partially the application
    code (M0 - code) by model-to-text transformations [44]. Thus, high level definition
    (models) can be mapped by model-to-text transformations to specific technologies
    (target technology). Consequently, the software code can be generated for a specific
    technological platform, improving the technological independence and decreasing
    error proneness. FIGURE 2. Model-driven development. Four layers of metamodeling.
    Show All So, Model-Driven Development (MDD) is proposed to tackle this heterogeneous
    technology (devices, actuators, complex event processing engines, notification
    technology, publish-subscribe communication protocol, etc.). Model-Driven Development
    [16], [20], [40], [43] increases the abstraction level where the software is implemented,
    focusing on the domain concepts and their relationships. These domain concepts
    (sensors, actuators, fog nodes, cloud nodes, etc.) and their relationships are
    defined by a model (M1), conform to a metamodel (M2), which can be analysed and
    validated using MDD techniques. Besides, the IoT environment code, including all
    the artefacts needed, can be generated from a model (M1) using model-to-text transformations,
    decreasing error proneness and increasing the user’s productivity. The main contributions
    of this paper include: This work shows that using Model-Driven Development techniques
    are suitable to develop tools and languages to tackle successfully the complexity
    of heterogeneous technologies in the context of IoT simulation environments. A
    methodology called SimulateIoT to describe each step needed to define an IoT simulation
    environment and execute it. A Model-Driven solution that supports the methodology
    proposed. It facilitates the development of each methodology phase by defining
    a SimulateIoT metamodel (M2), a graphical concrete syntax (graphical editor) to
    define models (M1) and a model-to-text transformation towards the code generation
    for specific IoT simulation environment (M0 - code). It includes the code generation
    to execute the IoT simulation. Furthermore, the IoT system generated can be deployed.
    An IoT deployment process that makes it possible to deploy the simulation based
    on microservices which are deployed on Docker containers, including components
    such as databases, complex-event processing engines or message brokers. The application
    of SimulateIoT to two case studies focused on different kinds of IoT systems (Smart
    buildings and Agricultural environment). The rest of the paper is structured as
    follows. In Section 2, we give an overview of existing IoT simulation approaches
    centered on both low level and high level IoT simulation environments. In Section
    3, we present the SimulateIoT methodology. Section 4 describes SimulateIoT design
    and implementation phases including the SimulateIoT metamodel, the graphical editor
    and the model-to-text transformation developed. In Section 5 two case studies
    are presented. Finally, Section 6 elaborates on the limitations of the presented
    approach before Section 7 concludes the paper. SECTION II. Related Works IoT environments
    and IoT simulation environments have been developed using several strategies with
    different targets and distinct abstraction levels. The abstraction levels are
    not related to the different IoT Architecture levels (Edge, Fog or Cloud layers)
    but also the concepts and relationships used to design the simulation at the IoT
    architecture level. For instance, you could use concepts to low level such as
    memory, network capabilities and use tools to manage this kind of configuration
    or using high level concepts such as Fog Node, Cloud Node or Complex Event Processing,
    engines, NoSQL storage where low level concepts could be transparently managed.
    Additionally, using high level abstractions could be used to generate code for
    specific technological targets. In this sense, among other, the concepts analysed
    for each different related work include: the abstraction level used to define
    the IoT environment, Edge modeling capabilities, Fog modeling capabilities, Cloud
    modeling capabilities, Complex Event Processing, Big data support, and Code generation
    support. So, in the following subsections several IoT simulation approaches are
    reviewed that focus on the different abstraction levels used for their definitions.
    So, we are examining i) Low level IoT simulation environments; and ii) High level
    IoT simulations environments and IoT modeling based on model-driven development.
    The former are based on defining sensors and actuators close to hardware (Contiki-Cooja,
    OMNeT++, IoT-Lab), so these proposals foster the knowledge of hardware, networks
    or energy consumption characteristics. The latter (COMFIT, CupCarbon, IoTSim)
    focus on defining IoT context and environments at a level of high abstraction.
    A. Low Level IoT Simulation Environments Contiki-Cooja [42] is a network simulator
    tool based on the Contiki operating system. It is implemented in Java and allows
    users to define large and small Contiki motes (a node in a sensor network) which
    can be deployed throughout the network. Relevant information about the network
    such as mote output or time-lines could be obtained after the simulation execution.
    Note that a mote can be defined ad-hoc using the motes templates. Obviously, these
    simulations are defined at a low level focusing on hardware and network issues
    more than IoT contexts or communication patterns such as publish-subscribe. OMNeT++
    [51] is a general network simulator adapted to simulate IoT networks. It offers
    a Domain Specific Language for modelling the IoT context including aspects related
    to routers, switchers, routing protocols or network protocols (IPv4, IPv6, etc.).
    This is a powerful simulator focused on analysing low level aspects of network
    issues. It uses components and component-based compositions to define network
    simulations. This approach focuses on defining IoT environments at a low level
    of abstraction closed to hardware. So, it is not centered on describing the IoT
    environment and high-level component relationships. Therefore, simulating wide
    IoT environments could be tedious and error prone. IoT-Lab [35] is a platform
    which allows deploying compiled WSN (Wireless Sensor Network)/IoT applications
    on a large WSN infrastructure. The applications can be installed on different
    types of sensors and can be developed on the Contiki operating system, among others.
    Thus, the goal of the authors is showing how both local and global energy consumption
    can be precisely monitored. Tossim [24] is a Wireless Sensor Network (WSN) simulator
    tool used over TinyOS. It can simulate thousands of nodes while it is able to
    capture the network behaviour with accuracy. It emulates the underlying raw hardware
    behaviour. Thus, the aim of this approach is simulating low level motes without
    defining communication patterns such as publish-subscribe or without using pattern
    data generations. B. High Level IoT Model-Driven Development and Simulation Environments
    This section includes both IoT development environments and IoT simulation environments
    which are based on graphical or textual domain concept descriptions, or model-driven
    technologies. There are several IoT metamodels [8], [36], [47] to model IoT systems,
    and usually the application code is partially generated from these models. In
    [8] a Domain Specific Language has been defined to model IoT environments, taking
    into account several IoT concepts such as devices, and input and output properties.
    Its goal is modelling IoT environments and generating code for a specific platform
    such as KNX/EIB. Although it is not related to IoT simulation, it uses model-driven
    techniques in order to tackle designing IoT systems and it can be used for quick
    IoT system prototyping. Another approach based on Model Driven Development [9]
    makes it possible to model complex event processing for near real-time open data.
    This approach is interesting because they present a methodology and a domain specific
    language to define models in order to model open-data sources, the processing
    nodes and the notifications agents. However, this approach does not focus on modeling
    and simulating IoT environments. COMFIT [15] was a cloud environment to develop
    the Internet of Things system. It used model-driven techniques included in the
    Model-Driven Architecture (MDA) specification [18]. For instance, a model-to-text
    transformation towards code generation for specific operating system targets (for
    instance, Contiki or TinyOS operating systems) was implemented. It defined several
    UML Profiles such as PIM:UML Profile and PSM:UML Profile, a model to model transformation
    from PIM models to PSM models, and a model-to-text transformation. So, authors
    used well-known UML tools to model the IoT Systems, however they did not define
    an ad-hoc metamodel for IoT, but used UML diagrams such as detailed activity diagrams.
    On the other hand, IoTSuite [36], [47] defined a high level domain specific language
    in order to model IoT environments including concepts such as regions, sensors,
    actuator, storage, request, action, etc. Thus, it joined computational services
    with spatial information related to regions such as buildings or floors. Several
    modelling languages were defined to model these kinds of systems: Srijan Vocabulary
    Language (SVL), Srijan Architecture Language (SAL) and Srijan Deployment Language
    (SDL). Then, a code generation process allows generating the application code.
    Although IoTSuite makes it possible to define IoT environments, it isn’t an IoT
    simulator. In [39] a component-based approach for the Web of Things was presented.
    They defined a Model Driven Development process to model Web of Things (WoT) systems
    by using model-driven techniques such as meta-modelling and model transformations.
    Thus, they defined a metamodel for WoT which related Physical Entities such as
    Sensors or Actuators with Visual Entities such as components deployed on a system.
    These models can automatically turn into code skeletons. However, this metamodel
    does not allow defining specific domain concepts related to simulation or storage
    issues, among others. Other approaches focus on simulating IoT systems proposing
    specific tools [4], [27], [45]. Thus, CupCarbon [27] defined an IoT Simulator
    environment which allows users to describe IoT contexts using a graphical editor.
    For instance, a mote could be added on a map like Google Maps, taking into account
    parameters such as action radio. It implements an ad-hoc language to manage the
    sensor’s communication and the business logic. It can execute simulations including
    the reactions to random events. So, although this approach allows describing IoT
    simulation issues, it does not allow describing the storage information or the
    complex communication protocols such as publish/subscribe using messages brokers.
    IoTSim [53] is an extension of CloudSim [6] that focuses on simulating IoT applications
    in cloud environments. It supports and enables IoT big data processing using the
    MapReduce model in the cloud. However, in order to execute the IoT application
    to be simulated, users should implement the workflow that IoTsim proposes, including
    Datacenter configuration, IoTDataCenterBroker, JobTracker, etc. Obviously, this
    approach offers a framework to execute IoT applications on cloud, however it does
    not offer a designing tool to easily define the artefacts necessary to be deployed
    on the IoTSim. Additional extensions to CloudSim deal with the analysis and use
    of BigData. BigDataSDNSim [1] allows the simulation of the big data management
    system YARN, its related programming models MapReduce, and SDN-enabled networks
    in a cloud computing environment. On the other hand, IoTSim-Edge is another CloudSim
    extension specialised in EdgeComputing [22]. In this way, this simulator allows
    defining and simulating elements such as EdgeNodes (EdgeDevice, EdgeDataCenter,
    EdgeBroker), IoTDevices (sensors and actuators) and their characteristics such
    as battery consumption, mobility, communication protocol, etc. These simulators
    deal with relevant aspects of the IoT in detail, allowing the simulation of IoT
    environments or parts of these environments in a very realistic way. However,
    these works lack a high-level abstraction graphical interface to visualise and
    model the architecture of the environment. On the other hand, they lack a module
    capable of validating a configured environment before its simulation. Therefore,
    although these simulators are able to simulate an IoT environment with high detail
    they need to define the configuration simulation environment using JSON files
    and Java code, which raise the learning curve. For instance, each sensor type
    needs to be implemented before being used on a configuration file. Finally, they
    do not model high concepts related to Complex Event Processing or they facilitate
    code-generation. Another important aspect is related with Simulation deployment
    which is carried out in the same machine without deploying a service-oriented
    architecture (common architecture where an IoT system is deployed), that is, all
    IoT aspects are simulated so code cannot be re-used for real implementation proposes.
    Using the approach in [4] the developers can test their cloud and on premise MQTT
    (Message Queuing Telemetry Transport) [33] application for functional and load
    testing. So, it allows deploying IoT environments focused on using sensors, actuators
    and MQTT servers. This tool allows users to define sensors and actuators and publish/subscribe
    concepts to define the IoT environment. It defines a set of template sensors to
    be used in order to model the IoT environment. Besides, data generation can be
    defined by the users following several data patterns such as concrete value, range
    values, random set or based on time & client. However, the IoT environment does
    not make it possible to define stream rules to react to event patterns. In [45]
    an IoT simulator was defined. It was written in Java and it allowed defining IoT
    simulations including agents, places and the context therein. The main steps to
    define a simulation included: i) defining the environment, ii) developing the
    behaviour and iii) packing and deploying it all together. The IoT system behaviour
    should be implemented ad-hoc using Java. So, this simulator required high expertise
    implementing Java agents. Furthermore, this approach did not resolve how to manage
    or analyse the device data. Viptos [7] is an integrated graphical development
    and simulation environment for TinyOS-based [21] wireless sensor networks. Developers
    can model algorithms with the graphical framework included in Viptos and generate
    their code in nesC [17]. Besides, users can define environments to simulate the
    behaviour of these algorithms. These environments could have features such as
    communication channels, network topology (the nodes where the algorithms will
    be tested) and physical characteristics (low-level, such as OS interruptions)
    of the environment. In short, this framework allows application developers to
    easily transition between high-level simulation of algorithms to low-level implementation
    and simulation. However, due to the characteristics mentioned, this framework
    works with a low level of abstraction. For that reason, the application developers
    that use this framework need to know low level concepts about it and the domain
    which can simulate. In addition, modelling an extensive simulation could be complex
    and the use of simulators with a higher level of abstraction would be more suitable.
    VisualSense [3] is a modelling and simulation framework for wireless sensor networks
    that builds on and leverages Ptolemy II [12]. This framework supports the modelling
    of sensor nodes, wireless communication channels, physical media such as acoustic
    channels, and wired subsystems among others characteristics. Besides, this framework
    supports the modelling of dynamic networks where nodes can change their connectivity
    in run-time. It’s worth mentioning that the communication between nodes is via
    events with timestamps [5]. Finally, the models can be simulated and visualised
    at run time. However, this simulator is focused on modeling networks at a low
    level of abstraction, without including high level concepts based on Cloud/Fog
    computing, publish-subscribe communication protocols and so on. To sum up, although
    there is a wide literature focus on defining the IoT environment and IoT simulation
    environments at different abstraction levels, several issues should be additional
    treated including fog computing, cloud computing, storage data, communication
    protocols or data analysis (see Table 1. The following sections describe the SimulateIoT
    methodology and tools which are proposed to tackle the complexity of the description
    and execution of IoT simulation environments. TABLE 1 Key Elements of the Related
    Works Summarized (IoT Simulation and Model-Driven Development) SECTION III. SimulateIoT
    Methodology This section describes the Simulation Methodology which has two phases,
    simulation description and simulation execution, as shown in Figure 3. FIGURE
    3. SimulateIoT methodology overview. Show All First, simulation description includes
    the following steps: Data and WSAN specification: Users should define the wireless
    sensors and actuator network (WSAN) to identify the device characteristics (including
    their data inputs and outputs) The wireless sensors and actuator network (WSAN)
    should be defined to identify the device characteristics (including their data
    inputs and outputs). It allows defining the edge computing layer formed by sensors
    and actuators; Fog/Cloud computing spec includes defining devices with different
    process capacities. For instance, these nodes can define how and where data should
    be stored, including the database characteristics (SQL database, NoSQL database,
    etc.); Processing data specification defines the communication schemas, that is,
    the communication protocols to connect the devices and nodes previously identified.
    In addition, this phase should make it possible to describe how data should be
    processed using multiple technologies such as big data or stream processors. Next,
    Simulation execution phase includes aspects related to the hosts where the IoT
    devices and nodes should be deployed. So, it includes where databases, message
    brokers, stream processors, etc. should be deployed. As a consequence, these aspects
    allow the IoT to tailor the simulation, adapting it to real situations. SECTION
    IV. SimulateIoT Tools This section describes the tools designed to implement the
    SimulateIoT methodology (defined in Section III) which include a Domain-Specific
    Language (DSL) named SimulateIoT for defining and deploying IoT simulation environments.
    For this, SimulateIoT uses model-driven development techniques to manage the IoT
    simulation environment definition using models. So, the models guide the system
    description and the code generation. Later on, the code generated can be deployed
    through several hosts. In a Model-Driven Development approach like this the software
    development is guided through Models (M1) which conform to a MetaModel (M2). Moreover,
    a Metamodel conforms to a MetaMetaModel (M3) which is reflexive. The MetaMetaModel
    level is represented by well-known standards and specifications such as Meta-Object
    Facilities (MOF), ECore in EMF and so on. A MetaModel defines the concepts and
    relationships in a specific domain in order to model partial reality. Then these
    models are used to generate totally or partially the application code by model-to-text
    transformations. Thus, the software code can be generated for a specific technological
    platform, improving the technological independence and decreasing error proneness.
    Figure 4 shows a mapping among the phases defined in the SimulateIoT methodology
    and the SimulateIoT design and implementation which defines a model-driven development
    process and the SimulateIoT deployment and execution phase. Thus, it shows the
    main elements needed to build the SimulateIoT ToolsExecution Environment and includes:
    a Metamodel definition, a Graphical Concrete Syntax definition (Figure 4-1) and
    the model-to-text transformations (Figure 4-2) to generate the code artefacts
    needed to deploy, monitor and measure the IoT environment (Figure 4-3). FIGURE
    4. SimulateIoT methodology and SimulateIoT execution design & implementation phase
    and deployment & execution phase related. Show All Thus, the Design and Implementation
    phase makes it possible to design the IoT models and generate the code which will
    be deployed and executed during the Deployment and Execution phase. Both the Design
    and Implementation phase and the Deployment and Execution phase together address
    users to design and implement the SimulateIoT methodology focusing on using well-known
    model driven software engineering practices such as metamodeling, validating,
    model transformations, etc. Using it improves the system development productivity
    and decreases the error proneness [43]. The main elements of the Design and Implementation
    phase such as the SimulateIoT Metamodel or the model-to-text transformations are
    described below. A. SimulateIoT Design and Implementation Phase. Simulate IoT
    Metamodel A MetaModel defines the concepts and relationships in a specific domain
    in order to model partially reality [43]. Then these models could be used to generate
    total or partially the application code. Thus, the software code could be generated
    for a specific technological platform, improving its technological independence
    and decreasing the error proneness. Figure 5 defines the domain metamodel including
    concepts related to sensors, actuators, databases, fog and cloud nodes, data generation,
    communication protocols, stream processing, and deploying strategies, among others.
    The relevant elements are summarised below: The Environment element defines the
    global parameters of the IoT simulation environment, including simulationSpeed
    and the number of messages to be interchanged among the nodes (numberOfMessages).
    These attributes define global policies to manage simulation resources to be applied
    on all the Node elements defined. Node is an abstract concept to represent each
    node in the IoT simulation environment. It is extended by several concepts such
    as EdgeNode or ProcessNode in order to specialise each kind of node. A Node can
    publish and subscribe to a specific Topic. It defines publish or subscribe references
    towards a Topic element in which it is interested. Note that, later on, each concrete
    kind of Node could be defined with specific constraints. Thus, the device position
    (Coordinates element) can be defined using latitude and longitude attributes.
    latitude and longitude attributes define the device position (Coordinates element).
    Furthermore, with the RaspBerryPi attribute, the generation of the node will be
    carried out for this kind of device. The EdgeNode element makes it possible to
    define simple physical devices such as a sensor or an actuator without process
    capacities. Moreover, with the attribute quantity, it is possible to define how
    many EdgeNodes of a type must be generated. Each EdgeNode could be linked with
    ProcessNode elements by Topic elements. Topic elements allow link each EdgeNode
    with ProcessNode elements. Moreover, each EdgeNode can be mapped with a physical
    device such as a temperature sensor, a humidity sensor, a turn on/off light device
    or an irrigation water flow device at the IoT environment. A Sensor element extends
    the EdgeNode element. It is the device that publishes the data that the IoT environment
    works with. A Sensor element analyses a specific environment issue (temperature,
    humidity, people presence, people counter, etc.) and sends these data to be analysed
    later. A Sensor element is able to publish on Topic elements which propagate data
    throughout the simulation nodes. To perform this data propagation, Sensors could
    integrate the element dditionalConfiguration that, together with the element RedirectionConfiguration,
    can define a redirection route of ProcessNode through which their data can flow.
    Thus, Sensors are able to publish their data in Topics not accessible to them.
    n ctuator element is a device in the IoT environment which can execute an action
    from a set of inputs. For instance, the inputs could determine that an actuator
    turn on or turn off a light; other actuators could require data input to define
    the light’s luminosity. In order to receive data, an ctuator element should be
    subscribed to topics. Topic is a central element in this metamodel because it
    defines the information transmitted among any kind of Node elements. Thus, Topic
    elements are defined from CloudNode and FogNode elements, and help users to model
    a publish-subscribe communication model. Node elements should identify the target
    Topic for both publication or subscription. Consequently, the Topic element is
    a flexible concept to model how data should be interchanged. Data element defines
    the simple data type to be generated (Boolean, short, integer, real, string).
    It has a DataSource element to model either the DataGeneration element or LoadFromFile
    element. The former (DataGeneration element) models how synthetic data are generated,
    for instance, using an Aleatory strategy among two values defined in a GenerationRange
    element. The latter (LoadFromFile element) models the path-file that contains
    the historic data, for instance, it could be defined by a CSVload element. In
    addition, external tools such as [11], [19] can be linked to increase the capabilities
    to offer additional data generation patterns. The ProcessNode element defines
    an IoT node with process capability. For this, two subtype nodes could be defined:
    CloudNode and FogNode. Essentially, both have the same properties and only differ
    in their process capability. Thus, in order to classify the ProcessNode capacity
    (the size attribute) related to batteries, CPU, memories, etc. a set of granularity
    values have been defined (XS, S, L, XL and XXL). They make it possible to define
    different kinds of nodes and apply different kinds of policies. Thus, Model-Driven
    Development helps to deal with the complexity of IoT systems and policies management
    by model abstractions and constraints. Using labels (XS, S, L, XL and XXL) to
    define the node capacity simplifies the knowledge needed to model the IoT environment,
    overall in a changing environment such as IoT. Labels are used to simplify the
    reality taken into account the user’s knowledge and expertise. For instance, Scrum
    agile methodology [41] makes it possible to define the effort needed for a set
    of developers to develop a specific user history by using labels. Concretely they
    use the Planning Poker technique which uses Poker cards to estimate the effort
    needed to carry out a specific task summarising the developer’s knowledge and
    expertise, task complexity, context changing, and so on. In the same sense we
    estimate the node capacities using the labels defined. The resources that different
    users can associate to a specific label can change throughout the time or taking
    into account their knowledge and expertise. This strategy allows specifying the
    ProcessNode element capacity and associating specific constraints. For example,
    in an XS ProcessNode a ProcessesEngine such as Complex Event Processing (CEP)
    engine cannot be deployed. Hence, granularity labels are used as in a Scrum project
    development to define task complexity. As mentioned, ProcessNode can define Topic
    elements, which can be referenced by any kind of Node elements. Besides, the redirectionTime
    attribute defines the frequency that stored data are flushed towards the next
    ProcessNode element defined by redirect references (redirection route defined
    in Sensors). The attribute BrokerType defines the message-oriented broker that
    currently is established by Mosquitto [32]. In addition, the ProcessNode element
    hides the complexity about how data should be gathered and processed. For instance,
    it defines how data will be stored, published or offered to be analysed by stream
    processing engines (SP) or complex event processing engines (CEP) by defining
    Component elements. Note that either the stream processing or the complex event
    processing capabilities help to define when an Actuator element should carry out
    an action. FogNode allows users to describe fog computing instances [6] which
    could manage and coordinate several devices or actuators. Thus, this concept focuses
    on aggregating data for a limited time or connection conditions that are released
    later on. Furthermore, a FogNode element can include persistent data storing and
    data processing. CloudNode extends ProcessNode and allows describing a special
    node deployed on a public or private cloud computing environment. The ProcessEngine
    element should be linked to a ProcessNode, to allow real time data analysis defining
    coming from ProcessNode elements or EdgeNode elements. To do this, defining complex
    event patterns can be carried out by Rule elements. These patterns analyse Topic
    data in real time. Currently, the SimulateIoT environment works with WSO2 Stream
    Processor [37] and Esper CEP [13]. Usually, a CEP (Complex Event Processing) engine
    has a higher process capacity and lower latency than an ESP (Event Stream Processing)
    engine [25], [26]. Rule elements are linked with the ProcessEngine elements defined
    at the ProcessNode element. Rule elements can be defined using the Event Processing
    Language (EPL) [14] defined for a concrete ProcessEngine kind. Note that the eventType
    attribute is used to name a rule. Notification elements make it possible to throw
    alerts by using several notification kinds: TopicNotification or eMailNotification.
    Obviously, Notification hierarchy could be extended in further metamodel versions.
    Mention that the Notifications are carried out by messages. Mention that messages
    carry out the Notifications. In this manner, the attribute message could define
    the notification message which will be notified. FIGURE 5. SimulateIoT metamodel.
    Show All B. SimulateIoT Design and Implementation Phase. Graphical Concrete Syntax
    and Validator The Design phase includes creating models conforming to the SimulateIoT
    metamodel. So, in order to do this, a Graphical Concrete Syntax (Graphical editor)
    has been generated using the Eugenia tool [23]. —- So, in order to do this, the
    Eugenia tool [23] —- makes it possible to generate a Graphical Concrete Syntax
    (Graphical editor). The Graphical Concrete Syntax generated from SimulateIoT metamodel
    is based on Eclipse GMF (Graphical Modeling Framework) and EMF (Eclipse Modeling
    Tools). Consequently, models (EMF and OCL (Object Constraint Language) [34] based)
    can be validated against the defined metamodel (EMF and OCL based). Note that
    OCL is a standard to define model constraints. Figure 6 shows an excerpt from
    this graphical editor. It helps users to improve their productivity allowing not
    only defining models conforming to the SimulateIoT metamodel, but also their validation
    using OCL constraints [34]. OCL rules have been defined as part of the SimiulateIoT
    metamodel using OCLInEcore Tools (https://wiki.eclipse.org/OCL/OCLinEcore). Each
    OCL rule, defined as invariant, has its own context which is related to the class
    where it is established. Some of these OCL constraints are the following: An EdgeNode
    element can only send data to Topic elements defined in one FogNode: class EdgeNode
    { \\ldots invariant send_data_to_one_node: self. publish-> forall (topic1, topic2|
    topic1.oclContainer() = topic2. oclContainer()); \\ldots } Each EdgeNode element
    should be connected (to publish or to subscribe) with a Topic: class Sensor {
    \\ldots invariant sensor_publish: self.publish > 0 \\ldots class Actuator { \\ldots
    invariant actuator_subscribed: self. subscribed > 0 \\ldots TopicNotification
    generated by a Rule should be published on a Topic created by the FogNode which
    analyses data with this Rule: class ProcessNode { \\ldots invariant TopicNotificationPublication:
    self.create_topic→includesAll(self. component→selectByKind(ProcessEngine) .rule.generates_notification→
    selectByKind(TopicNotification). publish_on_topic); \\ldots } ProcessNode could
    be a FogNode or a CloudNode, the main difference between these two kinds of node
    are their computation power, a characteristic defined by the ProcessNode attribute
    size which should be greater than L in the CloudNode element and smaller than
    or equal to L in the FogNode element: class CloudNode { \\ldots invariant cloudSizeMajorThanL:
    self.size. toString() = ’XL’ or self.size. toString() = ’XXL’; \\ldots } class
    FogNode { \\ldots invariant fogSizeMinorThanXL: self.size. toString() <> ’XL’
    and self.size. toString() <> ’XXL’; \\ldots } The ProcessNode element has the
    ability to redirect data. To redirect data ProcessNode must have data persistence,
    be connected to another ProcessNode and its attribute redirectionTime must be
    greater than 0. If redirectionTime is equal to 0, ProcessNode won’t redirect the
    data and does not have to meet these requirements. class ProcessNode { \\ldots
    invariant redirectionRequeriments: self. redirectionTime = $ 0 $ ~orself. redirectionTime
    > $ 0 $ ~and self. component→selectByKind(DataBase) <> null and self.redirect→size
    () > 0; \\ldots } FIGURE 6. Graphical editor based on the Eclipse to model conforming
    to the SimulateIoT metamodel. Show All To sum up this subsection, the graphical
    concrete syntax (based on an Eclipse plugin) developed offers a suitable way to
    model the IoT environment by using the high-level concepts defined in the SimulateIoT
    metamodel. Later on, the graphical concrete syntax will be used to model and validate
    several case studies. C. SimulateIoT Design and Implementation Phase. Model-to-Text
    Transformation Once the models have been defined and validated conforming to the
    SimulateIoT metamodel, several artefacts can be generated using a model-to-text
    transformation defined using Acceleo. a model-to-text transformation defined using
    Acceleo [38] can generate several artefacts. The generated software includes,
    MQTT messaging broker (based on MQTT protocol [33]), device infrastructure, databases,
    a graphical analysis platform, a stream processor engine, docker container, etc.
    In this regard, Table 2 summarises each node type characteristic including the
    Docker container, NoSQL database, MQTT broker, Monitoring using graphical visualisation
    and analysing characteristics labelled as Complex Event Processing (CEP). TABLE
    2 Available Code Generation for Each Different Kind of Node D. SimulateIoT Deployment
    and Execution Phase The Execution phase involves deploying all the artefacts generated
    from the models. So, several software artefacts such as the MQTT messaging broker,
    device infrastructure, databases, graphical analysis platform, etc. can be configured
    and deployed. Code is generated to allow users to package code, deploy and monitor
    the simulation. Thus, the simulation can be deployed through several hosts where
    each node should be deployed. Figure 7 shows an example of the IoT simulation
    deployed. It shows the different elements that can be deployed including a CloudNode
    or FogNode, Sensors and Actuators. Thus, each CloudNode and FogNode is implemented
    as a micro-service based on Thorntail [49] and it is deployed on a Docker container
    [28]. Besides, each node can be deployed on hardware with different characteristics
    such as Rasberry Pi, Jaguarboard, Orange Pi or Pine64. Note that these micro-computers
    run under several versions of Linux and Docker containers can be deployed on them.
    FIGURE 7. Deploy diagram. Show All Furthermore, each CloudNode / FogNode can define
    a Complex Event Processing Engine (e.g. Esper) or Event Stream Processing Engine
    (e.g. WSO2). Besides, it includes an MQTT broker (e.g Mosquitto), a No-SQL database
    (e.g. MongoDB) and a REST API. Likewise, as can be observed, all of these elements
    are inter-connected and are deployed on Docker containers. Finally, all Docker
    containers are orchestrated using Docker Swarm. Moreover, each node deployed with
    storing characteristics includes a specific monitoring tool. Figure 8 shows an
    excerpt from the monitoring environment based on Compass [10]. So, users take
    over the monitoring tool including several kinds of graphical elements such as
    bar graphs, data lists and so on. The monitoring environment makes it possible
    to query the data stored. FIGURE 8. MongoDB compass to monitor the data stored
    in the MongoDB databases. Show All Finally, an overview dashboard is generated
    to monitor the simulation execution. So, each node defined can be queried. For
    instance, the data stored on a specific ProcessNode can be queried in real-time.
    For instance, the user can query the data stored on a specific ProcessNode in
    real-time. So, during simulation execution the console of each ProcessNode shows
    the simulation execution log. Later on, the simulation logs and data stored in
    the ProcessNode with storage capacity are available to be queried. The simulation
    execution process including the following steps: i) compiling and deploying the
    artefacts previously generated from a SimulateIoT model; ii) data generation to
    commence the simulation process, consequently the defined sensors start to generate
    data and send them towards the defined Topics; iii) data propagation, data analysis
    and actions are carried out taking into account the defined data flows; and iv)
    log simulation can be analysed both in real-time querying the databases or after
    simulation execution by querying the log simulation. For instance, the following
    characteristics can be analysed: the performance of each component (in real-time)
    including CPU or RAM usage, the total memory used for each component, the amount
    of data sent and received for each component over its network interface, etc.
    Algorithm 1 shows a simplified simulation execution process. It focuses on the
    actions carried out in the Docker containers deployed to execute the simulation
    process. Note that each Docker container has its own behaviour depending on the
    simulation component deployed (Sensor, Actuator, FogNode or CloudNode) as has
    been described previously. Algorithm 1: Deploying and Executing the IoT Simulation
    1 begin 2 3 //Step 1)~Connections and configuration of each component 4 5 Compile
    and deploy each IoT component by using Docker Swarm 6 Subscribe each Node (Fog-CloudNode,
    Sensors, Actuators) to the Topics offered by MQTT Brokers 7 Subscribe each ProcessNode
    (FogNode and CloudNode) to the Topics on other Fog-CloudNode 8 Configure~the CEP/SP
    Engine with their EPL rules 9 10 //Step 2)~Start the message flow, the~components
    start their processes 11 12 //Start Data Generation 13 foreach Sensor do 14 start
    to publish data from it sources (.csv, syntheticDataGeneration(), etc.) to Topic
    15 done 16 17 // Main process executed in parallel by each Node 18 while (data
    in Sensors is available) do 19 Nodes (FogNode, CloudNode, Actuator) subscribed
    to Topic receive the data 20 21 //each Node (FogNode, CludNode or Actuator) process
    the data received 22 switch (NodeType n) 23 24 ProcesNode: 25 26 //2.1 CEP/SP
    Analysis 27 if (n has CEP/SP engine) then 28 foreach rule to apply to data do
    29 ruleObserved=CEP-SP.applyRule(rule[i]) 30 if ruleObserved == True then 31 CEP-SEP.sendNotification(rule[i].notificationDestiny)
    32 endif 33 endforeach 34 endif 35 36 // 2.2. Data Store 37 if (n has Persistence)
    then 38 n.saveData(MongoDB) 39 endif 40 41 // 2.3. Data redirection 42 if (n has
    redirection data) then 43 redirectionData = n.checkredirectionableData(MongoDB)
    44 foreach redirectionData do 45 n.redirectData(redirectionData.Destiny) 46 endforeach
    47 endif 48 49 Actuator: 50 n.doSomeAction(data) 51 endswitch 52 done 53 end The
    number of interactions in Algorithm 1 grows to O(N∗M) that is O( N 2 ) , where
    N is the number of Node elements and where M the number of messages to be interchanged.
    Note that, each Node is deployed on a concrete Docker container where each Node
    should execute its behaviour ( O(N) ). The generated IoT system defines a mesh
    topology network where sensors, actuators, fog nodes and cloud nodes could be
    interconnected following the model defined. The system modeller can use the Graphical
    Concrete Syntax that has been developed to describe the Node elements interactions.
    SECTION V. Case Studies Next, two case studies have been defined using the SimulateIoT
    methodology and tools previously presented. The first one defines an IoT simulation
    on a smart building while the second one defines an IoT simulation in an agricultural
    environment. Below is a synthesis of the methodology required to use SimulateIoT
    and the processes carried out by this tool to simulate these use cases in order
    to illustrate them more effectively. Model definition: This step refers to the
    modelling of the IoT Environment that the user wants to deploy. This model corresponds
    to the DSL and therefore can contain all the elements defined in it. Two examples
    of IoT Environment models are shown in Figure 9 and in Figure 11. Code generation
    and deployment: Once the model has been defined, the source code of all the elements
    involved can be generated from it. Sensors, Actuators, FogNodes, CloudNodes and
    all their sub-components and configuration files will be ready for the deployment
    phase. The deployment performs many steps for the correct deployment of all previously
    generated components. FIGURE 9. Case 01. The school of technology model conforms
    to the SimulateIoT metamodel. Show All FIGURE 10. Case 01. The school of technology
    model deployed. Show All FIGURE 11. Case 02. AgroTech model conforming to the
    SimulateIoT metamodel. Show All A. Case 01. School of Technology Our first case
    study presents the simulation of a smart building, more specifically, we have
    modelled the School of Technology at the University of Extremadura. It has six
    buildings (Computer Science, Civil Works, Architecture, Telecommunications, Research
    and a Common Building). So, each building has its own environment with a set of
    sensors, actuators and analysis information processes. 1) Case 01. Model Definition
    Figure 9 shows an excerpt from the School of Technology model. Note that Figure
    9 also includes numerical references for each node which are then used to describe
    the use case. It is a design of an IoT system which includes several nodes shared
    throughout the different buildings. Each building takes over its own ProcessNode
    (Figure 9, references 1.1, 1.2, 2) which recovers all the information produced
    by the sensors (Figure 9, references 3.1, 3.2). Thus, these data are suitably
    stored on specific databases (Figure 9, references 6.1, 6.2, 6.3), analysed and
    monitored in ProcessNode elements. In this case study, a FogNode element is defined
    for each building (Figure 9, references 1.1, 1.2). For instance, Common_Building
    or Computer_Science are FogNode elements (Figure 9, references 1.2, 1.1). Furthermore,
    a CloudNode named SchoolTechnologyCloudNode (Figure 9, reference 2) is defined
    to store information gathered from the FogNode elements. Both FogNode and CloudNode
    elements define several Topic elements such as heating_temperature, presence,
    smoke-detection topics (Figure 9, references 5.1, 5.2, 5.3). These Topic elements
    communicate data among the Node elements defined in the IoT system (Figure 9,
    references 1.1, 1.2, 2, 3.1, 3.2, 3.3). In order to model the School of Technology
    case study, several sensors such as heating_temperature_meter, presence_detector,
    smoke_detector (Figure 9, reference 3.1) and so on have been defined in Figure
    9. Each of them publishes its own data on a specific Topic element (Figure 9,
    reference 5.1). As can be observed in Figure 9, the Sensor elements publish data
    to several FogNode through Topic elements. Note that Sensor elements are EdgeNode
    elements which generate data, so the data pattern generators should be defined
    (Figure 9, references 4.1, 4.2). For instance, in order to describe the synthetic
    data generated by a temperature sensor a.csv input file has been defined. It makes
    it possible to reuse historical data. Other sensors can define their synthetic
    data generators using a random pattern, incremental pattern, etc. So, the approach
    can consume synthetic data based on simple data, range data, a specific set of
    values, the values obtained from a.csv file, data obtained from a url source or
    data generated form the external tools such as [11], [19]. As mentioned, in Figure
    9 each FogNode has its own characteristics about how data should be managed including
    storing, analysing or addressing. For instance, the ComputerScience FogNode element
    (Figure 9, reference 1.1) addresses the information every thirty seconds, storing
    the data obtained in a specific NoSQL database (Figure 9, reference 6.1). Then
    all data are flushed to the next node FogNode or CloudNode defined in the architecture
    and named in the example SchoolofTechnology_CloudNode. On the other hand, the
    Common_Building FogNode element (Figure 9, reference 1.2) defines a different
    behaviour in order to analyse the data and take advantage of being close to the
    devices that should carry out some action. For instance, the Common_Building FogNode
    defines a CEP engine component (Esper_CEP) and several Rule elements (Figure 9,
    reference 7), for example, the rule_heating analyses the data obtained from a
    specific Topic named heating_temperature to notify a specific action to another
    Topic named turn_on_heating which is subscribed by specific Actuator named heating.
    Thus, the rule_heating rule analyses the temperature sent to the heating_temperature
    Topic element from the heating_temperature_meter Sensor. Consequently, it is gathered
    and analysed by the CEP engine by means of the rule_heating Rule. Consequently,
    the CEP engine can gather data and analyse them by means of the rule_heating Rule.
    As a consequence, when the pattern defined is matched (for instance, if (temperature
    < 20) then switch on heating), the CEP engine generates an event to turn_on_off_heating
    Topic. As a consequence, the CEP engine generates an event to turn_on_off_heating
    Topic when the pattern defined is matched (for instance, if (temperature < 20)
    then switch on heating). 2) Case 01. Code Generation and Deployment Once the model
    has been defined, the model-to-text transformation is applied with the following
    goals: i) to generate Java code which wraps each device behaviour; ii) to generate
    configuration code to deploy the message brokers necessary, including the topic
    configurations defined; iii) to generate the configuration files and scripts necessary
    to deploy the databases and stream processors defined; and finally, to generate
    the code necessary to query the databases where the data will be stored; iv) to
    generate for each ProcessNode and EdgeNode a Docker container which can be deployed
    throughout a network of nodes using Docker Swarm. Figure 10 shows an excerpt from
    the School of Technology IoT model deployed and it includes the following: Each
    Node has been deployed on a Docker container using Docker Swarm technology. Each
    Docker container instance deploys the characteristics defined on the IoT model,
    including: where the nodes are deployed, and what the components included in each
    ProcessNode are. Finally, executing the simulation modelled and later on deploying
    it, makes it possible to analyse the final IoT environment before it is implemented
    and deployed. Thus, each EdgeNode and ProcessNode element carries out its own
    functions such as sending messages, processing and storing messages, acting from
    messages, etc. Consequently, the code generated can be reused on the final system
    deployed. For instance, the EdgeNode elements can be replaced by physical devices
    (both sensors and actuators), and the Process Node can be deployed as Docker containers
    either on premise or on cloud. Not only is the simulation code generated, but
    also the final IoT system code is partially generated. B. Case 02. Agricultural
    Environment This case study focuses on designing an IoT system for managing irrigation
    and weather data in order to improve crop production. So, the case study has been
    designed to simulate the sensors and actuators distributed over the countryside
    which can be monitored in real time. Nowadays, the agricultural domain has several
    requirements [50], [52]: i) Collection of weather, crop and soil information;
    ii) Monitoring of distributed land; iii) Multiple crops on a single piece of land;
    iv) Different fertilizer and water requirements for different pieces of uneven
    land; v) Diverse requirements of crops for different weather and soil conditions;
    vi) Proactive solutions rather that reactive solutions. For instance, sensors
    such as temperature sensors, humidity sensors, irrigation sensors, PH sensors
    and actuators such as irrigation artefacts help to monitor and save water, optimising
    crop production. This agricultural IoT environment has been designed over ten
    hectares of soil where tomatoes are being cultivated. So, for each hectare a set
    of sensors and fog nodes has been shared. So, using fog nodes decreases the communication
    requirements among them. The sensor network is built by temperature, humidity,
    irrigation and water pressure sensors. These sensors send data to a specific Topic
    element linked to a FogNode element which is gathering data and re-sending it,
    if it is needed. In addition, the irrigation actuators have been defined for controlling
    irrigation water. The notification events from the FogNode elements are sent to
    Actuator elements using Topic elements. 1) Case 02. Model Definition In Figure
    11 an excerpt from an IoT model conforming to the SimulateIoT metamodel is defined.
    It shows different Sensor elements such as ph_H1, temperature_H1, Humidity_H1,
    etc. (Figure 11, reference 3.2) which generates data for simulation. Moreover,
    several fog computing nodes have been defined, although in Figure 11 (for the
    sake of simplicity) only two FogNode elements are shown (Figure 11, references
    1.1, 1.2). They define several Topics such as Humidity, Temperature, pH, Water_pressure,
    etc (Figure 11, references 5.1, 5.2). In addition, each FogNode element defines
    a MongoDB database (Figure 11, references 6.1, 6.2) and an ESP engine (Figure
    11, references 7.1, 7.2) by means of Component elements. Besides, several Rule
    elements (event pattern definitions) such as rule_Humidity or rule_pH have been
    defined to analyse the data gathered from Topic elements in real-time. Likewise,
    when an event pattern is matched, a Notification element such as Low_pH, High_pH,
    Low_Humidity, High_Humidity and so on is thrown. For instance, the Actuator element
    named Irrigator (Figure 11, references 3.1) activates when the Notification element
    named Low_Humidity is thrown. 2) Case 02. Code Generation and Deployment Once
    the model has been completed and validated, a model-to-text transformation is
    carried out obtaining the simulation code, which can be deployed on a specific
    platform. Thus, the code generated includes several modules defined using several
    frameworks or programming languages. Thus, in order to define a scalable IoT environment,
    each deployable element (EdgeNode, CloudNode, FogNode, Actuators and ProcessEngine)
    is defined as a microservice, wrapping each Node element in a Docker container.
    Figure 12 shows an excerpt from the case study deployment architecture including
    the Docker containers defined and deployed. In Figure 12 the main characteristics
    of each node can be observed. For instance, each ProcessNode (Figure 12, references
    1.1, 1.2, 2) defines a MongoDB database (Figure 12, references 8.1, 8.2, 8.3),
    a Mosquitto MQTT message broker (Figure 12, references 5.1, 5.2, 5.3), and a WSO2
    Stream Processor engine (Figure 12, references 6.1, 6.2). In addition, the Rule
    elements defined are processed through the WSO2 engine defined. FIGURE 12. Case
    02. AgroTech deployment architecture. Show All Each Docker container has its own
    characteristics: CloudNode (Figure 12, reference 2) is composed of a message-driven
    broker (Figure 12, reference 5.3) like Mosquitto [32] (that implements a MQTT
    communication protocol) and a NoSQL database like MongoDB [31] (Figure 12, reference
    7.3). Besides, the MongoDB instance exposes the data stored using a REST API (Figure
    12, reference 8.3). Moreover, the CloudNode deploys a Compass instance [10] to
    monitor the data gathered. Each FogNode (Figure 12, references 1.1, 1.2) is composed
    of a message-driven broker (Figure 12, references 5.1, 5.2) like Mosquitto [32]
    (that implements a MQTT communication protocol) and a NoSQL database like MongoDB
    [31] (Figure 12, references 7.1, 7.2). MongoDB stores the temporal data gathered
    by the FogNode instance. Currently, the main difference between a CloudNode and
    a FogNode is the process capability. Using the size attribute at FogNode element
    makes it possible to define the process capabilities of the node. Consequently,
    both CloudNode elements and FogNode elements are deployed as Docker containers
    on hardware nodes such as PC, VM or Raspberry Pi. The ESP characteristic defined
    at ProcessNode deploys an event stream processor to process high amounts of messages
    in real-time. As can be observed in Figure 12 a WSO2 engine (Figure 12, references
    6.1, 6.2 is deployed on each FogNode. The WSO2 engine processes the Rule elements
    associated with it. The EdgeNode elements including sensors (Figure 12, references
    4.1, 4.2) and actuators (Figure 12, references 9.1, 9.2) defined in the model
    are suitably deployed in Docker containers. Later on, the execution information
    can be audited by querying the MongoDB database or using the monitoring tool available
    on each ProcessNode. Moreover, each Docker is generating log information during
    the IoT execution. Finally, the nodes deployed are accessible from a dashboard
    tool which gathers the available endpoints of each element, for example, to query
    a MongoDB database or to show information about a Mosquitto broker. SECTION VI.
    Discussion Model-driven development can be used to model complex IoT environments
    using domain concepts. They could not be tied to specific technology, but rather
    a model-to-text transformation makes it possible to generate the code needed to
    deploy and simulate the systems. Besides, the system deployed is gathering continuous
    data which can be analysed later on. Simulate IoT makes it possible to define
    models which could include a large amount of Node elements. Then, the code generated
    from models allows to create an scalable deployment based on well-known software
    architecture patterns such as publish-subscribe and Docker containers among others.
    The technology used as a target, such as micro-services (Thorntail), containers
    (Dockers), message-oriented middleware and MQTT (Mosquitto broker) or a container
    orchestrator (Docker Swarm) can be quickly replaced by other suitable technology
    if needed. In order to change the target technology, a model-to-text transformation
    should be implemented. However, the domain concepts used to model the IoT environment
    are fixed. As a consequence, the models help users to understand the IoT system,
    their relationships and constraints. Besides, the code generated can be analysed
    later on. On the other hand, the target users could be both: a) professional users
    and b) students. Professional users can use the methodology and tools presented
    in this work to define and analyse complex IoT environments where finally heterogeneous
    technology is used. Besides, our approach can be used for teaching purposes because
    it makes it possible for students to learn about IoT concepts and relationships.
    In addition, they can deploy the IoT simulation, and they can study the code generated
    to learn the technology used to deploy the IoT system. Thus, they can understand
    edge technology and integration patterns such as data patterns, IoT characteristics,
    publish-subscribe communication protocols, MQTT (Message Queuing Telemetry Transport)
    communication protocol, containers, NoSQL databases, distributed systems and so
    on. An IoT environment where the nodes are moving throughout the system can be
    partially modelled. These kinds of nodes are needed to define more complex IoT
    simulation environments such as wearables, people on the move, etc. Modeling complex
    node behaviours could be managed by means of dynamic behaviours and self-adaptation
    characteristics which could be defined in order to offer additional mechanisms
    for simulation purposes. For example, currently we are working on Topics elements
    which could be discovered by using a service discovery or using an introspection
    mechanism over the MQTT broker. The node service discovery is a new service deployed
    on Fog and Cloud Node elements able to offer by an API information about the Topics
    available, making possible that the IoT Nodes can connect to, send to and receive
    data from not fixed IoT nodes. The proposal that we are implementing to manage
    Node mobility includes the following aspects: It is possible to model a route
    generation, taking advantage of the geolocation that is already modellable. In
    this way, Node elements that require mobility to perform their functions can be
    moved through the IoT environment in such a way that the user who has modelled
    the environment requires it. The route generation solves the problem that arises
    from the need for mobility of devices in an environment. However, it is also necessary
    to define the coverage of the different Brokers in the environment, so that the
    different devices are able to make the decision to disconnect from one broker
    and connect to another. To solve this problem, it is proposed again the use of
    geolocation. In this way, the user who models the environment can define a radius
    of coverage of the different Brokers deployed, so that the devices, taking into
    account their own geolocation, can determine which Brokers are within reach and
    which are not. Thus, the different mobile devices in the environment can analyse
    which Brokers to connect to and which to disconnect from. The Topic Discovery
    Mechanism is a service that makes it possible to dynamically re-configure the
    Node elements in order to publish or subscribe on compatible Topics. To do this,
    Node elements publish a broadcast package to the network following Topic Services
    available and compatible with a concrete Topic. To answer the broadcast, each
    Node Processing element implements a Topic Discovery Node which answers it with
    the list of Topics available and compatible. Currently, the Topic compatibility
    is based on the Topic Data interchanged, Topic’s name or Topic’s Tags. Initial
    results of this approach to manage node mobility show that IoT nodes can dynamically
    reconfigure their connections to send or receive data. Finally, using the IoT
    simulation environment, users can propose and compare several policies before
    implementing them. Consequently, they can carry out several stress tests on the
    IoT architecture, obtaining valuable data. For instance, users can detect if a
    ProcessNode is running out of RAM. In addition, the bottlenecks in the IoT system
    could be detected by analysing the data gathered, producing valuable data that
    helps users to consider different IoT architectural alternatives. A. Limitations
    Although the domain-specific language and tools presented offer a wide expressiveness,
    they have several limitations to take into account: Node mobility has been partially
    developed following the approach that has been described before by defining the
    Topic Discovery Node (TDN). In this sense, on one hand, the route for nodes can
    be defined, and, on the other hand, the TDN makes it possible re-configuring dynamically
    the WSN deployed. This current version of our simulator IoT environment, for the
    sake of simplicity, allows defining connected nodes by TCP/IP, and we assume that
    connectivity is guaranteed. It is possible to simulate IoT environments defined
    using a high-level domain-specific language. However, the hardware simulation
    is only managed by the size attribute at ProcessNode which implies several constraints
    to avoid creating specific software elements (see Table 2). Obviously, it could
    be considered a simplistic approach to tackle this complex problem but in the
    end, it helps users to model the IoT environments thinking about the hardware
    restrictions. SECTION VII. Conclusion Model-driven development techniques are
    a suitable way to tackle the complexity of domains where heterogeneous technologies
    are integrated. Initially, they focus on modelling the domain by using the well-known
    four-layer metamodel architecture. Then, by using model-to-text transformations
    the code for specific technology could be generated. Thus, in this paper, we are
    tackling the IoT simulation domain allowing users to define and validate models
    conforming to the SimulateIoT metamodel. Then, a model-to-text transformation
    generates code to deploy the IoT simulation model defined. The IoT simulation
    methodology and tools proposed in this work help users to think about the IoT
    system, to propose several IoT alternatives and policies in order to achieve a
    suitable IoT architecture. Finally, the IoT systems modelled can be deployed and
    analysed. Future works include new concepts taking into account the role of connections
    among devices and brokers which could be simulated specifying the type of connection
    or distance among devices. Obviously, the SimulateIoT metamodel will be improved
    by applying these new concepts, although it will require that users define more
    accurately the IoT simulation model. Additionally, dynamic behaviours and self-adaptation
    characteristics could be defined in order to offer additional mechanisms for simulation
    purposes. For example, Topics elements could be discovered by using a service
    discovery or using introspection mechanism over the MQTT broker. Finally, another
    interesting further work includes the definition and generation of new types of
    data generation patterns. Again, these model extensions will improve the IoT simulation.
    Authors Figures References Citations Keywords Metrics More Like This Providing
    Information Services for Wireless Sensor Networks through Cloud Computing 2012
    IEEE Asia-Pacific Services Computing Conference Published: 2012 Healthcare cloud
    computing for underground wireless sensor networks 2017 2nd International Conference
    on Frontiers of Sensors Technologies (ICFST) Published: 2017 Show More IEEE Personal
    Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED
    DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION
    TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732
    981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility
    | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap |
    IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s largest
    technical professional organization dedicated to advancing technology for the
    benefit of humanity. © Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: IEEE Access
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'SimulateIoT: Domain Specific Language to Design, Code Generation and Execute
    IoT Simulation Environments'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors: []
  citation_count: '0'
  description: 'The proceedings contain 84 papers. The special focus in this conference
    is on Inventive Communication and Computational Technologies. The topics include:
    Iot-based wardrobe and steel closet theft detector; intrusion detection and prevention
    systems: A review; a novel task scheduling model for fog computing; a bidirectional
    power converter with shunt active filter for electric vehicle grid integration;
    formal verification of iot protocol: In design-time and run-time perspective;
    automatic network scanning system for monitoring 4g and 5g network elements; comparative
    study of introducing wavelength converters in pre-configured (p)-cycle; a novel
    approach to reduce false-negative alarm rate in network-based intrusion detection
    system using linear discriminant analysis; a low cost iot enabled device for monitoring
    agriculture field and smart irrigation system; deep network for network intrusion
    with concept drift; agro advisory system using big data analytics; paillier homomorphic
    encryption with K-means clustering algorithm (phekc) for data mining security
    in cloud; portax secure automation system using iot—a survey; a review paper on
    the elimination of low-order harmonics in multilevel inverters using different
    modulation techniques; lna architectures for ecg analog front end in cmos technology;
    community detection using graphical relationships; big data technologies: A comprehensive
    survey; preface; mathematical modeling of the data processing problems of heat
    experiments based on multiprocessor computing complexes; automatic face recognition
    and finding occurrence of actors in movies; Signature forgery recognition using
    CNN; image sentiment analysis using deep learning; fake news detection using passive-aggressive
    classifier; recurrent neural network-based character recognition system for tamil
    palm leaf manuscript using stroke zoning.'
  doi: null
  full_citation: '>'
  full_text: '>'
  inline_citation: '>'
  journal: Lecture Notes in Networks and Systems
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 4th International Conference on Inventive Communication and Computational
    Technologies, ICICCT 2020
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Yu X.Y.
  - Guo X.H.
  citation_count: '3'
  description: The intelligent agriculture monitoring is based on the perception and
    analysis of environmental data, which enables the monitoring of the production
    environment and the control of environmental regulation equipment. As the scale
    of the application continues to expand, a large amount of data will be generated
    from the perception layer and uploaded to the cloud service, which will bring
    challenges of insufficient bandwidth and processing capacity. A fog-based offline
    and real-time hybrid data analysis architecture was proposed in this paper, which
    combines offline and real-time analysis to enable real-time data processing on
    resource-constrained IoT devices. Furthermore, we propose a data process-ing algorithm
    based on the incremental principal component analysis, which can achieve data
    dimensionality reduction and update of principal components. We also introduce
    the concept of Squared Prediction Error (SPE) value and realize the abnormal detection
    of data through the combination of SPE value and data fusion algorithm. To ensure
    the accuracy and effectiveness of the algorithm, we design a regular-SPE hybrid
    model update strategy, which enables the principal component to be updated on
    demand when data anomalies are found. In addition, this strategy can significantly
    reduce resource consumption growth due to the data analysis architectures. Practical
    datasets-based simulations have confirmed that the proposed algorithm can perform
    data fusion and exception processing in real-time on resource-constrained devices;
    Our model update strategy can reduce the overall system resource consumption while
    ensuring the accuracy of the algorithm.
  doi: 10.3837/tiis.2020.10.004
  full_citation: '>'
  full_text: '>

    "KSII Transactions on Internet and Information Systems Monthly Online Journal
    (eISSN: 1976-7277) ABOUT HOT DOWNLOADED PAPERS EDITORIAL BOARD DIGITAL LIBRARY
    INFORMATION SPECIAL ISSUES SUBMIT MANUSCRIPT Data anomaly detection and Data fusion
    based on Incremental Principal Component Analysis in Fog Computing Xue-Yong Yu,
    Xin-Hui Guo, Vol. 14, No. 10, October 31, 2020 10.3837/tiis.2020.10.004, Download
    Paper (Free): Incremental Principal Component Analysis Offline and real-time learning
    Fog Computing Data anomaly detection  ABSTRACT The intelligent agriculture monitoring
    is based on the perception and analysis of environmental data, which enables the
    monitoring of the production environment and the control of environmental regulation
    equipment. As the scale of the application continues to expand, a large amount
    of data will be generated from the perception layer and uploaded to the cloud
    service, which will bring challenges of insufficient bandwidth and processing
    capacity. A fog-based offline and real-time hybrid data analysis architecture
    was proposed in this paper, which combines offline and real-time analysis to enable
    real-time data processing on resource-constrained IoT devices. Furthermore, we
    propose a data process-ing algorithm based on the incremental principal component
    analysis, which can achieve data dimensionality reduction and update of principal
    components. We also introduce the concept of Squared Prediction Error (SPE) value
    and realize the abnormal detection of data through the combination of SPE value
    and data fusion algorithm. To ensure the accuracy and effectiveness of the algorithm,
    we design a regular-SPE hybrid model update strategy, which enables the principal
    component to be updated on demand when data anomalies are found. In addition,
    this strategy can significantly reduce resource consumption growth due to the
    data analysis architectures. Practical datasets-based simulations have confirmed
    that the proposed algorithm can perform data fusion and exception processing in
    real-time on resource-constrained devices; Our model update strategy can reduce
    the overall system resource consumption while ensuring the accuracy of the algorithm.  STATISTICS
    Show / Hide Statistics      CITE THIS ARTICLE [IEEE STYLE] X. Yu and X. Guo, \"Data
    anomaly detection and Data fusion based on Incremental Principal Component Analysis
    in Fog Computing,\" KSII Transactions on Internet and Information Systems, vol.
    14, no. 10, pp. 3989-4006, 2020. DOI: 10.3837/tiis.2020.10.004.  [ACM STYLE] Xue-Yong
    Yu and Xin-Hui Guo. 2020. Data anomaly detection and Data fusion based on Incremental
    Principal Component Analysis in Fog Computing. KSII Transactions on Internet and
    Information Systems, 14, 10, (2020), 3989-4006. DOI: 10.3837/tiis.2020.10.004.  [BIBTEX
    STYLE] @article{tiis:23916, title=\"Data anomaly detection and Data fusion based
    on Incremental Principal Component Analysis in Fog Computing\", author=\"Xue-Yong
    Yu and Xin-Hui Guo and \", journal=\"KSII Transactions on Internet and Information
    Systems\", DOI={10.3837/tiis.2020.10.004}, volume={14}, number={10}, year=\"2020\",
    month={October}, pages={3989-4006}} UNIFIED SEARCH (in Title, Author, Abstract,
    and Keywords) CATEGORY SEARCH Title  Author  Abstract  Keywords  DOI  Search  KSII
    Transactions on Internet and Information Systems © 2007~Present, KSII. All Rights
    Reserved."'
  inline_citation: '>'
  journal: KSII Transactions on Internet and Information Systems
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Data anomaly detection and Data fusion based on Incremental Principal Component
    Analysis in Fog Computing
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Bansal S.
  - Kumar D.
  citation_count: '130'
  description: In this era of research and technology, Internet of things (IoT) takes
    a prominent part in the evolution of applications of the various field like health,
    education, smart cities, homes, agriculture etc. This paper provides a survey
    of the IoT ecosystem. All the components of IoT and their significance has been
    elaborated. The smart sensors collaborate through wireless communication and internet,
    with zero human activity, to deliver automated intelligent applications. In this
    internet world, machine-to-machine (M2M) technologies are the first phase of the
    IoT. As IoT is expanding, it is bringing together vast technologies as in Big
    Data, Artificial Intelligent, Machine Learning to tackle the huge data and devices.
    This paper starts by providing an overview of the taxonomy of the IoT ecosystem.
    Then, it provides a technical overview of IoT enabling architectures, devices,
    gateways, operating systems (OS), middleware, platforms, data storage, security,
    communication protocols and interfaces for the data flow in an ecosystem. This
    paper also discusses the key hurdles that need to be tackled for expanding IoT.
    A relation between IoT and new technologies like big data, cloud and fog computing
    has been briefed. Finally, it presents the growing applications that IoT delivers.
  doi: 10.1007/s10776-020-00483-7
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Log in Find a journal Publish
    with us Track your research Search Cart Home International Journal of Wireless
    Information Networks Article IoT Ecosystem: A Survey on Devices, Gateways, Operating
    Systems, Middleware and Communication Published: 13 February 2020 Volume 27, pages
    340–364, (2020) Cite this article Download PDF Access provided by University of
    Nebraska-Lincoln International Journal of Wireless Information Networks Aims and
    scope Submit manuscript Sharu Bansal & Dilip Kumar  4989 Accesses 115 Citations
    3 Altmetric Explore all metrics Abstract In this era of research and technology,
    Internet of things (IoT) takes a prominent part in the evolution of applications
    of the various field like health, education, smart cities, homes, agriculture
    etc. This paper provides a survey of the IoT ecosystem. All the components of
    IoT and their significance has been elaborated. The smart sensors collaborate
    through wireless communication and internet, with zero human activity, to deliver
    automated intelligent applications. In this internet world, machine-to-machine
    (M2M) technologies are the first phase of the IoT. As IoT is expanding, it is
    bringing together vast technologies as in Big Data, Artificial Intelligent, Machine
    Learning to tackle the huge data and devices. This paper starts by providing an
    overview of the taxonomy of the IoT ecosystem. Then, it provides a technical overview
    of IoT enabling architectures, devices, gateways, operating systems (OS), middleware,
    platforms, data storage, security, communication protocols and interfaces for
    the data flow in an ecosystem. This paper also discusses the key hurdles that
    need to be tackled for expanding IoT. A relation between IoT and new technologies
    like big data, cloud and fog computing has been briefed. Finally, it presents
    the growing applications that IoT delivers. Similar content being viewed by others
    IoT Ecosystem: Functioning Framework, Hierarchy of Knowledge, and Intelligence
    Chapter © 2022 Internet of Things (IoT) Enabling Technologies and Applications—A
    Study Chapter © 2021 A Review of Applications, Approaches, and Challenges in Internet
    of Things (IoT) Chapter © 2020 1 Introduction With the advancement of technology,
    people across the globe want to become more connected over the internet [1]. As
    technology is growing, IoT has become one of the most eminent technologies. In
    this technology, billions of devices such as sensors, actuators, gateways and
    controller are connected to one another in an efficient manner and provide the
    countless application in every domain [2, 3]. IoT is a paradigm where the real
    world is connected to the virtual world through the internet. IoT has wide scope
    in each trade of the world starting from engineering, medical, finance, food,
    energy and agriculture. New devices, OS, architectures, platforms, security and
    communication protocol are emerging in terms of IoT. As research is done in IoT,
    many new challenges are coming like massive connectivity, coverage, security,
    scalability. To achieve these goals that create problems a few years back now
    seems easy due to the interconnection of things. Both advancement and challenges
    are growing hand in hand. IoT adds a new taxonomy every day to its definition.
    It will take time to make IoT’s boundary stable [4]. IoT applications can be broadly
    categorized as consumer-based, industrial-based and infrastructure-based application.
    Some of the consumer-based applications are home automation, self-driven vehicles,
    smart wearable, automated healthcare, smart homes etc. Major industrial application
    is smart manufacturing process and control system, smart retail and supply chain,
    internet industry, industrial automation etc. Infrastructure based application
    are smart city, habitat monitoring, smart environment, smart grid etc. [5, 6].
    IoT ecosystem is a system which brings together all the heterogeneous components
    of IoT in a managed way to build an efficient system. It is the integration of
    devices, operating system, controllers, gateways, middleware and platform. All
    these elements are connected through communication protocol and interfaces like
    Zigbee, low power Wi-Fi, Message Queuing Telemetry Transport (MQTT), Low Power
    Personal Area Network for IPv6 (6LoWPAN), Near Field Communication (NFC), Bluetooth
    low energy (BLE) etc. [7]. IoT ecosystem connects a large number of physical devices
    in a single system. These connected devices have been increasing exponentially.
    In 2020 the count will increase to 50–100 billion according to various Information
    and Communication Technology (ICT) reports [8]. The block diagram in Fig. 1 represents
    the IoT ecosystem. The sensor and actuators communicate with the gateway through
    various communication protocols. The sensors which are also called preceptors
    gathers all the information in the form of environmental parameters and gives
    all data to the gateway. The actuator acts on the surroundings and receives instruction
    from the gateway. The gateway can manage hundreds to thousands of sensors and
    actuators. It also manages the flow of data between devices. It performs filtering
    and formatting on data which is received from the sensors. The controller handles
    hundreds of gateways and perform high-level processing of data like classification,
    computation on data and converted the data into meaningful information [9]. Then
    the controller communicates with middleware. The middleware performs the function
    like save all the data into the database server, analysis the data, generates
    the graphs and reports, performs security and privacy, controls and manages the
    whole system which is present below it, all the data can be supported by the cloud
    which is present in the middleware. All the application like smart city, smart
    homes need to consume services and analytical information provided by middleware.
    These services can consume through Application Programming Interface (API). Then
    the application gives the complete IoT view to the user [10]. Fig. 1 Block diagram
    of IoT ecosystem Full size image The motivation of this paper is to identify the
    IoT as an ecosystem by finding the diverse research present on IoT and fitting
    all the elements like devices, OS, middleware, communication, gateways in an ecosystem.
    This research has combined efforts in various sectors and has enabled all sectors
    to be connected. After recognizing the advancement in IoT, this paper explores
    what are the components that build and successfully enables IoT as an ecosystem.
    In past many surveys have been conducted for IoT. As compared to other IoT survey
    papers, the paper provides a detailed thorough summary of all elements that comes
    up together to enable the IoT ecosystem. This would help new researchers and developers
    to get a quick overview of how the different elements fit together to deliver
    functionalities without digging into RFCs and the standards specifications. It
    gives an overview of varied technologies that come together as a phenomenon in
    IoT, thus revolutionizing the world and solving challenges, in the form of real-world
    applications like smart city, smart health care etc. 1.1 Related Work In this
    survey, IoT has been reviewed from different aspects. The architectures of IoT
    gives the illustration that decouples layers and allows frameworks, infrastructures,
    protocols and technologies to fit in the ecosystem. This architecture also helps
    IoT systems to scale and interoperate with better abstraction and in a modularized
    way. There is a comparative analysis of various devices, OS, platforms, communication
    interfaces which enables the correct choice according to the requirement. After
    reviewing all recent studies, the major open issues in the IoT have been explained.
    The priority concerns for IoT applications in terms of security and privacy has
    been explained. The discussion on the significance and need of big data, cloud,
    fog computing in IoT as devices and data increasing has been done for real-time
    data analytics, performance, availability and mobility. In last this survey presented
    how these elements are chosen and bring together everything to deliver services
    of the IoT ecosystem. The survey on this paper is different from the existing
    surveys as it gives an idea on IoT as a complete ecosystem in terms of devices,
    gateways, OS, middleware, platforms and communication technologies. All these
    components work together to give an IoT application. A recent survey [18] cover
    IoT technologies and various application of IoT. Various design aspects of OS
    and challenges are discussed in paper [45]. There is a survey on enabling technologies
    of IoT which also explains research issues on IoT [2]. The paper [16] gives the
    literature survey on IoT architectures, protocols and applications. The survey
    on communication technologies and protocols is discussed in papers [7, 24, 62].
    An extensive study on the capabilities of IoT middleware [73] and components of
    platforms [80] is explained in recent surveys. But there is no comprehensive survey
    on complete IoT ecosystem which cover all IoT components and give various application
    as a complete IoT ecosystem. Table 1 gives an overview of the comparison of existing
    surveys. Table 1 Comparative overview of existing reviews Full size table Relative
    to the existing literature on IoT survey, the paper contribution is summarized
    below: A survey has been shared on the key hurdles in the expansion of IoT and
    how IoT and emerging technologies help in tacking some problems. This survey paper
    compares and contrasts various IoT devices and OS which would help in understanding
    and choosing them based on the requirement. This paper also illustrates the available
    gateways, middleware, platforms and various communication technologies present
    at all layers of IoT. The paper contributes towards a survey on the significance
    of security and privacy in IoT and describes the linkage between IoT and new technologies
    like big data, cloud and fog computing. The paper is organized as follows: In
    Sect. 2 various architectures of IoT are presented. The paper represents the proposed
    taxonomy in Sect. 3. Then the elements for IoT ecosystem is presented in Sect.
    4 in which IoT devices, IoT gateways, IoT operating system, IoT communication,
    middleware, IoT platform, data storage, security and privacy are explained in
    detail. Section 5 explains the various challenges of IoT ecosystem. In Sect. 6,
    various applications in IoT Ecosystem can be explained and the conclusion is there
    in Sect. 7. 2 IoT Architecture The architecture is an outline that specifies major
    physical components, their functional orientation and the underlined principles
    [11]. Different researchers give different architectures based on the IoT application.
    The first and basic architecture of IoT is three-layer architecture. It basically
    consists of three layers-perception layer, network layer and application layer.
    Perception layer basically deals with sensing and actuation. The network layer
    is responsible for transmitting and processing the information. The application
    layer gives a specific application to the user [12]. In five-layer architecture,
    two more layers are there to give more abstraction to the IoT architecture. The
    five layers are perception, transport, processing, middleware and application
    layer. The transport layer is responsible to transfer the data for the processing
    which is obtained from the sensors. The processing layer processes the data which
    is obtained from the transport layer and then analyses that data [13]. In middleware
    architecture, middleware layer plays a big role. This layer is the heart and brain
    of the ecosystem. Middleware layer is not only responsible for managing the complete
    system but also controls the flow of data in the system. In this architecture
    perception layer, access layer and edge layer come under physical plane where
    sensor and actuators are present. Backbone Network Layer and Middleware layer
    are present in a virtualised plane which consists of clouds and servers. The Co-ordination
    and Application Layer is present in application plane which gives a final view
    of IoT to the user [14]. In service-oriented based architecture, the ecosystem
    functionalities are abstracted and exposed through interfaces. Objects and applications
    use these functionalities through services. The benefit of this architecture is
    that API doesn’t change even if the inner technology and code are changed. If
    new functionality is to be introduced, it simply used through a new service without
    impacting the existing system [15]. In fog-based architecture, four layers are
    present between the physical layer and transport layer which are monitoring, pre-processing,
    storage and security. The monitoring layer observes and checks the data obtained
    from the sensors. The pre-processing layer performs operations on the sensed data.
    The storage layer gathers all the processed data. The security layer is responsible
    for the integrity and privacy of the data [16]. All these architectures for IoT
    ecosystem are explained in Fig. 2. The detailed explanation of five-layered architecture
    is as follows [17,18,19]: Fig. 2 IoT architectures, a layered architecture—three
    and five-layer; b middleware based; c service oriented based; d fog based Full
    size image a. Perception layer—This is the layer which is present at ground level
    and mostly deals with sensors and actuators. Sensors in this layer senses and
    gathers information in the form of environmental parameters and physical parameters
    like X–Y–Z coordinates. Sensors transmit the gathered information further. Additionally,
    this layer performs the pre-processing on the data to remove unwanted data. Using
    this layer, a user could take action and sends a signal back to the actuators
    in the physical layer to perform actions accordingly. b. Transport layer—This
    layer is responsible to carry the pre-processed data to the processing layer and
    vice versa through the communication/networking channel. This layer is also responsible
    for node to node communication. It uses various communication protocol like Zigbee,
    Sigfox, BLE, Radio Frequency Identification (RFID) and NFC. c. Processing layer—This
    layer is responsible for filtering and formatting the data, organizing, managing
    and storing the data received from various sensors and nodes through communication
    protocols. d. Middleware layer—This layer is responsible to perform various logical
    and analytical operations on the stored data and using the facts and figures it
    process the data to meaningful information. This meaningful information is then
    to use to produce various analytics by use of communication interfaces. This layer
    makes use of platforms for databases, cloud computing, and big data processing.
    e. Application layer—Using the analytics and observation from the processed data,
    this layer is responsible to deliver an application to provide various services
    to the users by communication protocols like MQTT, Constrained Application Protocol
    (CoAP), Data Distribution Services (DDS) etc. There is a large number of applications
    in which the IoT as a technology can be used to give a complete ecosystem like
    smart city, smart buildings and smart healthcare. 3 IoT Taxonomy Taxonomy of IoT
    is a process of describing the way in which all devices or areas are impacted
    and related by putting them together in a group. This taxonomy would define most
    generalized layers that would always be part of the IoT ecosystem. A taxonomy
    for research in IoT has been proposed in the diagram based on the elements and
    architecture. At perception layer sensors and actuators are important IoT enabling
    devices which can be categorised as low-end, middle-end and high-end devices.
    Sensors collect data and actuators performs actions. Diverse sensors are available
    for location, motion, video and audio detection and capturing, light detection,
    proximation, sensing environmental parameters (temperature, pressure, humidity),
    chemical identification etc. are used in IoT applications. Sensors, actuators,
    motes are low-end devices with constrained OS, memory and battery. At the data
    pre-processing layer there are technologies with limited storage, a small processing
    unit and some security features to filter and summarize data before sending it
    on the middleware. Pre-processors are microprocessors and microcontrollers enabled
    with the scaled OS, higher memory and battery than low-end devices. The various
    OS with their capabilities used in the devices has been classified as low-end
    and high-end based on the resources. Various communication technologies like NFC,
    low-power technologies, WSN and Internet Protocols that are available starting
    from constrained to unconstrained features have been classified for IoT. Devices
    communicate over the wireless network using a diverse protocol. Short-range low
    power communication protocols like RFID and NFC and non-constrained Bluetooth,
    Zigbee, and Wi-Fi are few of the communication technologies that are briefed in
    this paper. This is like a constrained WSN that communicate over the network with
    various protocols and interfaces. A major component, middleware that acts as an
    abstraction layer for the programmer with a lot of complex interconnected systems
    which abstracts the functionality of the system are walked through. Middleware
    can be classified as service-based, actor-based and cloud-based. IoT platforms,
    storage and security are the integrated part of middleware. Cloud computing and
    big data analytics are major functions in middleware that manages data and enables
    complex computational capabilities to enhances interoperability, scalability,
    mobility, availability like features. Security and Privacy are the key components
    to the success of IoT and at the same time a great challenge in a remote location.
    IoT platforms are installed to work along middleware to achieve abstraction and
    program of the whole ecosystem. Application in terms of end-user apps, web and
    API that allows the exchange of data. These applications that have been possible
    because of IoT and have proved to be helpful as in smart home, smart health, smart
    traffic, smart cities, smart agriculture, smart grids etc. Therefore, a large
    number of algorithms and mechanisms have been used by the researchers and implemented
    for each layer of the OSI/TCP model. This section of the paper proposes the taxonomy
    of IoT starting from low-end devices to the IoT application featuring IoT devices,
    operating system, communication interfaces and networks, middleware, platform
    defining their capabilities that give a significant impact on end to end the flow
    of IoT ecosystem. The proposed taxonomy of IoT ecosystem is shown in Fig. 3. Fig.
    3 IoT taxonomy Full size image 4 Elements of IoT Ecosystem This section of the
    paper highlights the major components of the IoT ecosystem. The whole ecosystem
    is divided into six parts which are (i) IoT devices (ii) IoT gateways (iii) IoT
    operating system (iv) IoT communication (v) IoT middleware 4.1 IoT Devices IoT
    devices are the basic building block of the IoT system. These devices are present
    in all the layers of IoT architecture. IoT devices can be classified as open-source
    or proprietary. Open-source IoT devices are those which are publicly available.
    Everything regarding open-source devices can be studied, modified and reproduced
    according to the requirement whereas proprietary IoT devices are licensed and
    details of these devices are not available [20]. IoT devices have limited functionality
    due to low internal storage, memory, computational capability and limited power.
    IoT devices use different types of memory depending on the limited resources,
    cost and working of the device. Major types of RAM (Random Access Memory) are
    Static RAM (SRAM), Dynamic RAM (DRAM), Synchronous DRAM (SDRAM), Double Data Rate
    RAM (DDR), Embedded Multimedia Card (eMMC) etc. SRAM retains the data in static
    form until power is supplied. The memory speed is quite fast and is expensive.
    This type of memory is integrated with microcontrollers and is also used as L1/L2
    cache in the microprocessor. SDRAM is a type of dynamic memory. It stores the
    binary information in the form of electric charges. This type of RAM is directly
    synchronized with the clock of microprocessors and microcontrollers. This type
    of memory is used in devices where the processing of the number of instructions
    per seconds is high. DDR is an advanced SDRAM whose speed is almost double of
    SDRAM. The data is transferred in both the cycles of the clock in DDR as compared
    to SDRAM. The cost is high and it is used in devices where synchronisation with
    the controller clock is required along with higher data transfer rate. eMMC is
    a special type of memory that acts as internal storage which is integrated on
    eMMC chips along with controllers. It is used in smartphones, tablets etc. The
    IoT environment constitutes of various service architectures, protocols and network
    design to deal with millions of IoT devices for exchanging data. IoT should support
    heterogeneous devices based on variant interfaces with a large number of available
    resources. IoT devices can be broadly classified into three categories—Class 0,
    Class 1 and Class 2 which are shown in Fig. 4 [21, 22]. Fig. 4 Categorization
    of IoT devices Full size image Class 0 or low-end IoT devices are devices with
    limited resources like memory, power, computational capability, architecture etc.
    These devices are mostly present at first layer of IoT ecosystem. They have the
    functionality of sensing and actuating. They use lightweight communication protocols.
    They have very basic operating system. The RAM varies from 1 to 50 KB and flash
    memory varies from 10 to 50 KB. These devices are very much vulnerable to threats
    and security is the biggest concern in these low-end devices. These devices are
    closer to environmental parameters like temperature, humidity, pressure etc. Class
    1 or middle-end IoT devices are devices which have more resources as compared
    to low end devices. They provide more functionality than low end IoT devices but
    the computational capability is not enough to handle very complex requirements.
    These are basic microcontrollers. These devices sit over low-end devices in IoT
    ecosystem to manage and improvise the capabilities of low end IoT devices. These
    devices have capabilities like image processing, data filtering etc. These devices
    can have multiple communication technologies installed on them [23]. These devices
    have higher clock speed as compared to low-end devices where clock speed ranges
    from 100 MHz to 1.5 GHz. The RAM varies from 100 KB to 100 MB and flash memory
    varies from 10 KB to 100 MB. Due to more functionalities, these devices can be
    partially secured using encryption of data. Some of middle end IoT devices are
    Arduino, Netduino. They are also present either at first or second layer of IoT
    architecture. These devices have better peripheral interfaces like USB, microUSB.
    These can be considered as basic gateways in the IoT ecosystem [24, 25]. Class
    2 or high-end IoT devices are single-board computers that have a high number of
    resources in terms of CPU, RAM, flash memory etc. These devices support traditional
    operating system such as LINUX, UNIX [26]. These devices support growing technologies
    like artificial intelligence, machine learning, deep learning, nature language
    processing etc. These devices also provide a graphical user interface for development
    purpose. These devices are available up to 64-bit architectures. These devices
    have everything on a single board and support almost all communication protocols.
    The devices have many connectivity interfaces such as HDMI, Wi-Fi, Ethernet, USB,
    Bluetooth etc. and all are present on a single board. These devices support high
    graphics along with multimedia and data analytics. These are highly intelligent
    devices used as complex gateways and controllers in the IoT ecosystem. These have
    relatively less security concern due to the high number of resources [27]. All
    the devices can be compared in terms of platform, clock frequency, architecture,
    memory requirement, the operating system on which the devices run and battery
    required which is presented in Table 2 and the comparison in terms of communication
    networks and interfaces is shown in Table 3. Table 2 Comparison of devices in
    terms of platform, clock, memory, OS Full size table Table 3 Comparison of devices
    in terms of communication and interfaces Full size table 4.2 IoT Gateways IoT
    gateway is a middle-end device that acts as an intermediate between various sensing
    networks and high-end IoT devices or to the cloud platform through the internet.
    Its major task is to manage the heterogeneity due to various kind of data collected
    from different sensors and sends data to the higher controller or platform. The
    data collected by the gateway should be filtered and processed. High-level processing
    of data is done based on the requirement, kind of data and commands. Gateways
    act as a major bridge between different layers of IoT architecture that lies in
    different networks. Gateways manage itself and the terminal nodes attached to
    it in an efficient way to improve performance and form a robust layer in the IoT
    ecosystem. In terms of data transfer gateways act as a proxy between the data
    centers or cloud data source and the low-end IoT devices like sensors. Gateways
    sometimes act as a high-end device when the IoT ecosystem is very large and more
    often acts as a middle-end device when the IoT ecosystem had a small number of
    low-end-devices. Gateways are designed in a way that they are robust to environmental
    conditions in terms of the hardware. They also have the ability to overcome failure
    and tries to solve the communication gap between low-end devices and controllers
    [28]. Gateways also have a small operating system with limited functionalities
    and resources in terms of memory, computational capacity and power consumption.
    So, the gateway performs tiny operations like filtering data, converting data
    of different format into a unique format and should be able to handle the power
    break [29]. In case of power break, the gateway should have a small power backup
    to save system status into the permanent memory and put the system into hibernation
    mode. And when power is back, the gateway should start from the same state. Gateways
    should also have the ability to troubleshoot and reboot, in case any component
    is down and if still issue is not resolved then should be able to communicate
    to IoT platform for user-visible information [30, 31]. In large IoT ecosystem,
    gateways have a high-performance controller on top of it. So, the controller manages
    a large number of gateways. So, a gateway in this system supports following kind
    of communication (i) IoT low-end device to Gateway (ii) Gateway to IoT Platform
    (iii) Gateway to Controller (iv) Gateway to Gateway. Generally, gateways communicate
    through GPS, Wi-Fi, Bluetooth, Ethernet etc. In large IoT system, there exists
    local intranet at the gateway and controller level. Finally, data collected at
    this small intranet level is communicated to the higher device, platform or cloud
    through the internet [32]. Some gateways are designed in a way to support real-time
    device monitoring like auto identification, addition and removal of IoT devices.
    Moreover, it monitors the data and process limited data to produce relevant information
    to be passed onto the ecosystem. This leads to the supply of appropriate data
    to the operating system, database and other IoT devices to improve the real-time
    performance. Like CoAP protocol can be used in constrained IoT network to support
    the communication between the IoT devices [33]. IoT gateways works in three modes:
    Passive, Semi-Automated and Fully Automated [34]. i. Passive: In this mode, it
    is required to add new devices or delete the existing devices manually. The user
    gives permission to the gateway for adding and deletion of the devices. It can
    handle and optimize network operation. The gateway can access to each node or
    sensor. It also accesses each network without changing the communication protocol
    or source code. They are not flexible in nature and not customizable. ii. Semi-Automated:
    In this mode, there is a link between the devices which is added and the gateway
    for the connection. It improves the real-time performance, reliability in terms
    of transferring the data and manages the data in the network. It is based on a
    plug-configurable architecture which shows that the devices can be plugged according
    to the network requirement. It is more flexible than passive gateways because
    of the external interface [35]. iii. Fully Automated: In this mode, the devices
    have the capability for self-configuration. There is no need to take the permission,
    IoT gateways can add or delete the devices itself. This kind of gateways able
    to communicate with various communication protocol and interfaces like Wi-Fi,
    Zigbee, Bluetooth, CoAP etc. [36]. These gateways can easily work with heterogeneous
    networks. It also supports real-time device monitoring so that it can easily modify
    and review the devices by addition or deletion of devices [37]. 4.3 IoT OS OS
    is a set of programs that act as a bridge between application or user and the
    devices. Programs are designed and run over the called operating system. OS is
    installed over IoT devices to make it capable enough for programs to run on the
    IoT device and also manage the device. So, OS can be defined as a component what
    makes hardware a complete IoT device. So, it can be said that OS is responsible
    to manage and monitor power consumption, enable instructions to run, to program
    the IoT device for its attributes and enable devices for to and fro communication.
    OS plays a vital role in the deployment of a scalable and reliable IoT ecosystem.
    Due to the heterogeneous nature of devices in the IoT ecosystem, OS should be
    customizable to meet the requirement of each sub-IoT system. IoT devices have
    important characteristics are computation, capacity, energy capacity and memory
    capacity. In future, IoT devices should exist with these three properties as customizable.
    OS are best suitable if it supports the feature of controlling, connecting and
    communicating that would change with the change in properties of IoT devices [39].
    In addition, there is a requirement of standard development tools that could support
    portability of applications across various architectures and are easy to develop,
    extend and maintain. IoT OS can be classified as: a. High-End IoT OS—which mostly
    is linux based. This operating system runs over high end or middle-end IoT devices
    which are single-board computers with high resources, memory and power e.g. Raspberry
    pi [40]. b. Low-End IoT OS—which may be of linux based or non-linux based as shown
    in Fig. 5. This operating system runs over low and middle-end IoT devices which
    are small board with limited resources, computational power and capacity e.g.
    Arduino [41]. Fig. 5 Various types of IoT operating system Full size image OS
    play a major role in IoT for developing reliable, efficient, scalable and interoperable
    application. Both high and low end IoT devices require OS. OS is described based
    on many aspects that are architecture and kernel, programming model, scheduling,
    memory management, networking protocols, simulator, security, power consumption
    and support for multimedia. Following are key points kept in mind while designing
    an operating system. 1. Architecture—Architecture of an operating system composes
    of the kernel and specifies the services to the user [24]. Based on these parameters,
    architecture can be categorized as follows: a. Monolithic—Used for multilayer
    application system. These are capable of handling higher order complex computation
    and have higher processing speed thus a better throughput. All processes run in
    kernel space. b. Microkernel—This architecture provides only the major functionalities
    like scheduling, inter process communication and synchronization that run on kernel
    space. Other functionalities of OS run in threads. Here processes run both in
    kernel space and user space. They provide high flexibility in processing due to
    plugin availability and moreover allows an OS to be designed over the base system.
    c. VM architecture—This system is a virtual system over the actual running system.
    Due to virtualization, this architecture is slower but they provide a high level
    of portability, flexibility and extensibility. d. Modular architecture—This architecture
    enables adding and replacing components into the kernel at runtime dynamically.
    Each module represents a separate functionality. So, modules can be plugged in
    and out as per the requirement. e. Layered architecture—Multilayered architecture
    is designed for a specific requirement and is not flexible in nature when it comes
    to functionality. But this kind of operating system is easy to operate and handle.
    2. Development model—It defines the specification in which an application or program
    will be modelled. The factors that influences are multithreading, event-driven,
    concurrency handlers and memory design. Now it depends on the IoT device in which
    this OS will be installed so that they could make it flexible, extensible and
    achieving the purpose of the device [42]. OS should be programmed in a way that
    it could be redesigned and upgraded. A Software Development Kit (SDK) present
    in the OS helps in modelling libraries, improvise OS interface, memory model and
    power model. 3. Scheduling—The scheduling strategy is directly proportional to
    the capabilities of an OS. The scheduling algorithms are priority and non-priority
    schedulers accompanied by preemptive and non-preemptive nature. Preemptive performs
    the highest priority task stopping all running task whereas non-preemptive starts
    new task post completion of the current task [43]. 4. Memory management—It refers
    to memory allocation and deallocation. The memory is categorized based on the
    flexibility requirement. If memory is fixed it is static memory and when it is
    required to have a flexible nature then it is called dynamic memory. Moreover,
    it is a major concern to have a different level of memory based on memory speed
    and performance. Performance and memory form a major concern while designed an
    OS. In addition, another important memory for OS is cache memory that is small
    memory which very close to OS-level operations. This memory contains data and
    metadata required by OS [44]. 5. Interfaces and communication protocols—In IoT,
    OS is to be designed to provide maximum interfacing with the devices. Interfacing
    is possible through hardware interfaces and communication protocols. Now it depends
    on the kind of IoT device, location of installation, ecosystem requirement, speed
    and security of data transfer that helps in finalizing the protocols in OS. Various
    communication protocols are CoAP, Zigbee, Wi-Fi, Bluetooth and interfaces are
    like USB, microUSB, HDMI etc. which not only helps in inter-device communication
    but helps in connecting to other devices present in higher and lower hierarchy
    of IoT ecosystem or the internet. This also takes into consideration the heterogeneous
    nature of massive IoT ecosystem. 6. Simulation ability—Simulation is the process
    of predicting the performance in the real world. Simulators are external processes
    that plug into the OS to extend its functionality by analyzing its behavior [45].
    This helps in scalability and cost optimization in an existing system. 7. Security—When
    it comes to the IoT ecosystem, security is a major concern. OS at various level
    in this ecosystem itself needs to have a high level of security to make it a robust
    system. Security not only enables encryption of user data but also enables reliable
    communication in heterogenous devices present at different layers of this ecosystem.
    Security can be in terms of data restriction, user control to access the system
    in terms of authorization and authentication along with physical security in case
    of foreign attacks [46]. The device is not only concerned with security but also
    a recovery system is required that manages the device in case it is in unsafe
    hand to ensure the integrity and avoid loss of data. Another security concern
    comes into play at the communication level so as to avoid data leak during inter-device
    or device internet communication. According to resources, the different OS has
    security systems to overcome attacks. TinyOS has TinySec library to provide message
    authentication, integrity and confidentiality semantic security. Contiki has ContikiSec
    Transport Layer Security (TLS) in 3 modes authentication, confidentiality, integrity.
    RIOT has Cyber-Physical Ecosystem (CPS) to interact, monitor and control smart
    objects. LiteOS has support for the embedded chip to provide security. FreeRTOS
    as has WolfSSL for security, authentication, integrity, confidentiality. Mynewt
    has secured radio communication, secured bootloader and secure updates. uClinux
    uses shepherd process for security along with encrypted storage security. Raspbian
    supports authentication, authorization and encryption for multimedia. Android
    Thing uses verified secure boot and signed over-the-air updates. It provides full
    disk encryption. 8. Power management—This is one of the biggest constraints in
    the IoT ecosystem. IoT devices are constrained devices. They are installed at
    locations starting from the environment to the internet servers. Power management
    needs to be robust to conserve energy, regenerate energy, longing the battery
    life and mitigate physical attacks. It should also be capable enough to save the
    energy, to route power in a new direction in case a device goes down. OS should
    be powerful enough to handle power failure to save the current state. 9. Multimedia
    feature—OS should be designed based on the requirement of multimedia. Multimedia
    processes are power and memory intense. It requires highly complex operations.
    It supports audio, videos in terms of the virtual environment [47]. The various
    operating system which are linux and non-linux based can be compared according
    to design aspects in Table 4 and according to memory requirement and operational
    support is presented in Table 5. Table 4 Comparison of operating system in terms
    of design aspects Full size table Table 5 Comparison of Operating System in terms
    of Memory and Operational Support Full size table 4.4 IoT Communication Iot devices
    are resource-constrained. A large number of heterogeneous devices need to be connected
    through communication protocol and interfaces to the internet [48]. Due to resource-constrained
    nature, there are many communication challenges like the requirement of low power
    communication, less memory-intensive routing protocol, deploy enhanced Wi-Fi,
    addressing and identification and high speed [49]. If IoT devices connect through
    the internet directly, it would require IP stack. IP stack is highly power and
    memory intensive. So, IoT devices should be connected using low power technologies
    like Wi-Fi, Zigbee, Bluetooth, NFC, low power technologies, WSN. Below are some
    major communication technologies [50]. 1. Near field communication (NFC)—It enables
    at very short range (up to 10 cm) of wireless communication. NFC’s underlined
    technology is RFID and uses the magnetic field for data transfer. NFC communication
    is of two types—active and passive [51]. In active type, the magnetic field is
    generated by both communicated devices for data transfer and in passive, energy
    is optimized where one device generates a magnetic field and another device depends
    upon modulation for data transfer [52]. 2. Wireless Sensor Networks (WSN)—It is
    a network of hundreds and thousands of sensors connected through IP. The communication
    is based on IEEE 802.15.4. Inter-network communication may be direct or through
    multi-hop. WSN supports star, mesh and hybrid topology [53, 54]. 3. Internet Protocol
    Stack—Various protocol has been defined at the various layer of communication.
    At the physical layer, IEEE.802.15.4 supports low power and constrained resources.
    The energy consumed is very less in comparison to the existing Wi-Fi network.
    It features robust communication by detecting data loss and re-transfer of loss
    data. In pre-processing layer 6LoWPAN solve the large addressing problem. This
    protocol helps bring stability and scalability in large IoT ecosystem. In the
    network layer, RPL is present [55]. RPL creates a directed graph for all the devices
    in the network which defines how the data would be routed from one device to another
    device and to the gateway. In the application layer, CoAP and extended MQTT protocols
    are present for low resource devices. CoAP protocol has a feature like a resource
    detection, congestion control, data compression etc. [56, 57]. Extended MQTT features
    publish/subscribe message for lightweight communication. 4. Low power technologies—For
    IoT, many low power technologies have been developed to support constrained environment
    and resources. Some of them are Bluetooth low energy (BLE), low power Wi-Fi, Zigbee,
    Low Power Wide-Area Network (LPWAN) etc. The comparative analysis of all these
    technologies are explained in Table 6. BLE transfers a small packet of data at
    1 Mbps [58, 59]. In BLE, various peripheral devices are connected to a central
    device. The peripheral devices are by default is in sleep mode and wakes up when
    a packet is received from the central device. Low power Wi-Fi is an extension
    of old Wi-Fi and is based on IEEE 802.11ah [60]. It consumes low power and has
    a higher range of nearly 1 km. Zigbee is based on IEEE 802.15.4 and communicates
    in a range of 100 m. It provides multi-hop routing, maintenance of routes, identification
    of add/remove of IoT device. LPWAN is used for long-range communication at a low
    data transfer rate [61]. LoRA and NB-IoT (Narrowband-IoT) are LPWAN (Low Power
    Wide Area Network) communication technologies which work on constrained devices
    like IoT and requires low cost and low power usage [62]. Table 6 Comparison of
    low power technologies Full size table i. LoRA—As the name specifies ‘Long Range’.
    LoRA is a technology which operates on a frequency less than 1 GHz. It is given
    by LoRA Alliance in 2015. It is the first low-cost commercial communication technology.
    It acts as low power modulation technology for LoRAWAN. It uses CSS (chirp spread
    spectrum) modulation which is bidirectional in nature. The rate of data transmission
    lies between 300 bps and 50 kbps. The communication protocol which is used by
    LoRA is LoRAWAN [50]. LoRAWAN uses three classes of end devices for IoT applications.
    All these end devices perform two-way communication. Class A: End devices perform
    transmission according to the need of communication. These are the low power device.
    The window which receives the signal open randomly. Most of the time end devices
    are in the sleeping mode. Class B: Receiving windows is greater than Class A windows
    and it opens at the particular scheduled time. Class C: It has the maximum receiving
    windows which is almost open at all time [63]. ii. NB-IoT—It is the technology
    which is given by 3GPP (Third Generation Partnership Project). NB-IoT technology
    is a combination of GSM and LTE. The modulation technique used by NB-IoT technology
    is QPSK and BPSK. In this technology, there is three kind of operations- a stand-alone
    operation which uses only GSM frequencies, guard band operation which uses LTE
    carrier’s guard band, in-band operation which uses LTE carrier resource block
    [64]. It has better performance due to the fast modulation rate with high cost
    and high-power consumption. Apart from these IoT communication technologies, there
    are IoT interfaces that are used by IoT devices like GPIO, ADC, DAC, I2C, SPI,
    UART etc. [65, 66]. GPIO (General Purpose Input Output) performs direct low level
    I/O operations with processors. This is used as an input port for communication
    with CPU where when acting as an output port it can drive an output operation
    based on CPU instructions. It has features like flexibility, easy to implement
    and high portability [67]. Analog to digital convertor/digital to analog converter
    (ADC/DAC) acts as voltage converter where ADC converts analog voltage to digital
    and DAC converts digital to analog. Now it depends on the current signal form
    and the form of input and output signal required if ADC is required or DAC is
    required. But ADC helps in the transmission of signal with accuracy and DAC ensures
    high-speed transmission of the signal. Serial peripheral interface (SPI) [68,
    69]. This type of interfaces enables the serial exchange of data. SPI operates
    in the full-duplex mode which enables the two-way transfer of data at the same
    time. This is used in processing units with peripherals. SPI supports short-range
    communication. These types of interfaces are mostly used in a master–slave scenario
    between devices [50, 70]. Inter IC (I2C) is a bidirectional two-wire serial bus
    which enables the communication between integrated circuits. It is used in devices
    where each chip can become master for initiating the communication. It supports
    serial communication in master–slave scenarios. Universal asynchronous receiver
    transmitter (UART) is either an IC or part of IC for Asynchronous serial communication.
    Such interfaces are used for managing the serial ports. Here the speed of data
    flow is configurable [71, 72]. 4.5 IoT Middleware IoT middleware is a component
    of IoT ecosystem that provides the raw data to the user in form of web application.
    The information gathered from IoT devices must be manipulated in a form such that
    it can support all types of applications related to the IoT ecosystem. The above
    challenges are solved by the concept of IoT middleware. But it has limited functionality
    in terms of interpreting and integration of data [73]. This presents a big challenge
    in terms of inter-device communication, collecting and accessing the data, and
    merge the data of multiple devices to form the flexible composition. IoT middleware
    should be designed in such a way that it should be scalable, adaptable, flexible,
    secure and open source. This kind of middleware would enable researchers and developers
    to configure and compose new applications and also introduce new IoT devices into
    the ecosystem and would avoid low-level reprogramming of complete IoT ecosystem.
    IoT middleware could be broadly categorized into three types based on usability,
    flexibility and adaptive nature [74]. i. Service-Oriented Middleware: This kind
    of middleware enables end-users and developers to add and modify IoT devices into
    IoT ecosystem as services [75]. It provides services like access control, storage
    management, event processing engine. Security models are costly in terms of time
    and memory so they provide limited support in terms of security, privacy and trust.
    In such a system, the control of user data is limited. The security techniques
    in SOA architecture are not designed to support constrained resources [76]. ii.
    Cloud-Oriented Middleware: This middleware enables the collection and interpretation
    of data with ease. However, it limits the growth of the ecosystem in terms of
    types of IoT devices. The security model in cloud-oriented architecture is defined
    by the cloud which is being used [77]. So, privacy and security are defined by
    the cloud system and is not configurable by users. The major concerns in such
    a system are the control of sensitive data and such system are also not designed
    to support constrained resources [78]. iii. Actor-Oriented Middleware: This kind
    of middleware is open source and is designed on a plug and play model. IoT devices
    can be added to the IoT ecosystem as a plugin and when an IoT device is not required,
    it can be easily removed without impacting IoT ecosystem. The security model here
    is configurable by users through plug and play mechanism. Actor based architecture
    is designed to support constrained resources [79]. 4.5.1 IoT Platforms IoT platforms
    are the part of IoT middleware. IoT platforms are software’s specially designed
    to manage the complete IoT system. They are the backbone of the IoT system. IoT
    platform connects devices, gateways, networks to the cloud, server and applications.
    The platform helps the recognition of all devices. They provide a Software Development
    Kit for all IoT system devices [80]. This system enables virtual visualization
    of IoT devices from the perspective of managing, designing and enabling the IoT.
    They manage security. This is the place where rules of IoT ecosystem are defined
    for message evaluation. These platforms are used to define the business of the
    IoT system. They are like a bridge to the cloud and the hardware IoT ecosystem.
    The complete control of the ecosystem in terms of speed, cost, complexity, business,
    data flow is handled here [81]. IoT platforms are the one which enable the cross-device
    compatibility, automation of connected devices. In IoT architecture, IoT platforms
    may act as middleware which helps in versatility, flexibility, reliability and
    scalability of an IoT ecosystem. So, IoT platform as a middleware can be considered
    as a bridge between the hardware and the software. The major tasks are to identify
    devices and to understand heterogeneous inputs of different devices over various
    protocols and keep the system updated. It supports integration among the entirely
    different devices using its artificial intelligence to make the devices communicate
    and take very complex actions [82]. The platform can be described in form of layers.
    It is based on the features of IoT platform that adds to IoT ecosystem forming
    itself a backbone of the system. IoT platforms are responsible for identification,
    communication, computation and the responsiveness of the components [83]. i. Infra
    layer—This layer enables and manages the functioning of the IoT platform. This
    layer is responsible for messaging, device-intercommunication, orchestration and
    management of the ecosystem. ii. Communication layer—This is a layer which enables
    the communication between the hardware and the cloud system in IoT that enables
    data transfer to the data analytics processes. iii. Core layer—This enables the
    diverse and major features of the system which are data collection, device identification
    and management, disaster recovery, system configuration, system software update.
    iv. Visualization, Reporting and Processing layer—This is the layer majorly related
    to processing activity, generating reports and visualizing the analytical outcomes
    of big data that are user understandable. Moreover, this layer enables the user
    to define rules for the way data is processed, report and visualizations are generated.
    The IoT platform connects the devices like gateways, network to the cloud or with
    the application. The whole system is controlled by the central management system
    that acts as the processing unit [84]. IoT consists of devices, sensors, software
    and networks that simultaneously work together and use the IoT platforms to implement
    the application. The factors which enable the requirement of IoT platform are
    network connectivity, optimizing the operation, managing the data, analytics,
    static processing and connection to the application. The features that an IoT
    platform requires stability in terms of portability of carrying the operation
    and availability, flexibility in terms of performing any task according to the
    application, scalable in terms of work with any kind of devices, and affordable
    [85]. The major concerns and research area in IoT platforms are scalability, customizability
    and security. It enables load balancing, flexibility, encryption, enabling comprehensive
    identity, flexible development and manage data and user accessibility [86]. There
    are many platforms which support IoT applications which are shown in Table 7.
    Table 7 Comparison of platforms Full size table 4.5.2 Data Storage Storing the
    data in various form is the one of the abilities of middleware. The data traffic
    volume in IoT is huge and thus require new calibration and analytical techniques
    to support big data. Data mining techniques as in AI, ML and decision-making algorithms
    enable the complex computational processes of useful information for increasing
    raw data of IoT [87]. Cloud technology can manage and meet the complex requirement.
    Cloud has capabilities as in storage and complex computation, support heterogeneous
    application protocols. But still, there are road blockers to be emphasized. Transferring
    edge devices (e.g. sensors, smartphones, etc.) data to the cloud causes issues
    viz. network performances (in terms of delays, bandwidth, congestion, reliability,
    availability, etc.), costs of internet, security and storage cost on cloud, secure
    transmission and privacy, different cloud interoperability, device-cloud security
    and reliability [88]. i. Big Data—Bulk data is generated as a result of interconnection
    between the sensors and a large number of objects. Data generated by IoT devices
    is increasing rapidly. This massive data is called ‘big data’ which represents
    the size of the data set. It is a process of searching and analyse the data and
    finally give the patterns and correlation of the data. Four fundamentals of big
    data are storage, data security issues, big data analysis, impact on day to day
    living. There are various sizes of data and various types of data like numerical,
    text, audio, video, figures etc. Data can be of structured, unstructured or semi-structured.
    Big data is the only way to make the data in a structured form. There is a large
    amount of data even after filtering the redundant data [89]. It is very necessary
    to manage this kind of data. Bigdata technique has the ability to handle a large
    amount of data and deliver that data to the analytics tool. Then this data is
    transfer to the data centre. Big data storage faces a lot of security issues like
    secure transactions, secure data mining, secure filtering and secure computations.
    Big data analytics categorized into three factors volume, variety and velocity.
    Volume deals with the size of data streams. Variety of bigdata means diversity
    of data in the form of audio, video, text etc. Velocity represents the pace at
    which the data can be processed. There is a large number of big data and IoT applications
    which has a direct impact on our daily life like smartwatches which continuously
    measure the health of a person by collecting the data and give the message to
    the doctor if a person falls sick or faces other problems. Big data analytics
    examines a large amount of data to give relevant and efficient decisions [90].
    The combination of IoT and big data is used to improve decision making. The data
    obtained from the ‘connected devices’ is in a large amount. So, there is a need
    for big data analytics which manages the data by using reports, query, training
    data and analytical tools. To perform analytical and logical operations the data
    must be stored in a smart and efficient way. Single processor and limited storage
    are not capable to perform an action on big data. Big data platforms for analytics
    like Apache Hadoop are not sufficient to support the huge data of big IoT system.
    The processing of real-time data in IoT is also a necessity for efficiency. IoT
    needs a common huge analytical platform that delivers to all IoT applications.
    Such analytical unit shouldn’t be an overhead on the overall IoT ecosystem. A
    solution for IoT big data is to keep track of just required and important data
    only. ii. Cloud Computing—Cloud computing is an evolving technological model to
    tackle the on-demand network of shared resources and has ability to configure/manage
    sources such as networks, servers, applications, and services. Cloud computing
    enables remote usage and maintenance of resources in a reliable and cost optimized
    way. Cloud’s storage and computational resources enables IoT to manage, store
    and process this huge data [91]. Some of the major used cloud for IoT are ThingWorx,
    OpenIoT, Google Cloud, Amazon, GENI, etc. [87]. Cloud computing manages big data
    enabling the processing of data and extracting valuable information. Deploying
    cloud computing in IoT is a challenging task. Synchronizing and Standardizing
    heterogenous cloud vendors for real-time services due to interoperability. A balance
    between cloud environments and IoT requirements due to the infrastructure results
    in a challenge. Security is a big concern for IoT cloud due to the different security
    mechanisms involved in all layers of IoT. Cloud services need to be validated
    to ensure quality services. Cloud computing is not a necessity in local infra
    resources as data is limited [92]. The processing and operational cost would grow
    if the cloud is induced. Raw data should be processed on local nodes to reduce
    the reduce internet transferred data thus reducing congestion, latency, costs.
    This would also optimize performances [93]. Cloud here can be replaced with new
    computing techniques as in cloudlet and fog computing that is designed for the
    need for local infrastructure and can act as an extension to or a bridge to cloud
    computing. iii. Fog Computing—Fog is a synonym for “mobile” cloud. Fog Computing
    is also known as cloudlets or edge computing. It comes into play for large-scale
    cloud computing and storage. This layer acts as a bridge between smart devices
    layer and cloud storage layer. It enables extending of cloud computing services
    to the edge devices. Fog computing availability is high to end-users as compared
    to the cloud and hence the performance is improved in terms of delivery, delay
    and availability. It can be referred to as small scale cloud. The fog computing
    overcomes the problems present in cloud computing like mobility, reliability,
    availability etc. The fog is a mini cloud that is close to the ground. It provides
    limited capabilities viz. data storage, processing, filtering, and analysing at
    the edge of the network and is then sent to cloud through expensive communication.
    Fog computing features are low latency, location awareness, distributed nodes,
    mobility, real-time response, interactivity with the cloud. The fog and cloud
    go together in larger IoT and helps achieve optimal performance. Smart gateway
    is employed between underlying networks and the cloud to enable fog computing
    [54]. Fog computing enables smart devices for data pre-processing and improving
    availability. This is not a must due to limited capabilities for complex analysis
    and huge storage. Some basic computations are done at the edge layer. To overcome
    limited resource at local layer pre-processed data is sent to Cloud. But this
    is a solution to the mobility challenges of a cloud. At gateway level fog enables
    smoother data flows. 4.5.3 Security IoT is a real-world network with a real-time
    system. There are major operations without human intervention for large durations
    through wireless communications. Although it results in improved social efficiency,
    it creates a list of new concerns leading to privacy and information security
    breach. Security is the degree of the special considerations to protect the individual’s
    information from exposure to IoT environment, in which almost any physical or
    logical entity can be given a unique identification and the autonomous ability
    to communicate over all kinds of network bidirectionally. Middleware provides
    the security and privacy to the whole ecosystem. The network then broadcasts all
    the gathered information and events to the server for the logical and analytical
    process. The privacy should not be compromised and present at all stages like
    the device, the communication, storing, processing and the applications. The user’s
    privacy and protection of data are one of the largest challenges to be addressed
    in the IoT. Security in the device—There should be no unauthorized data manipulation,
    hardware and software handling for the devices. Sensing devices gather sensitive
    data which should be robust and tamper resistance. Trusted computing technologies
    should be used for device validations, and authorized environments. For devices
    privacy, location privacy of device, identification, protecting from theft or
    loss and protection from side-channel attacks. Barcodes can help in Personal Identifiable
    Information (PII). Blind values calculations could be used for side-channel attacks.
    Security in communication—is achieved through encryption. Encryption can be done
    for the sequence number, IPsec- Security Parameter Index, etc. Securing Communication
    Protocol helps in achieving privacy. Pseudonyms can be an alternative to encryption
    in case the device’s identity is not feasible to reduce vulnerability. Devices
    communication should occur if and only if needed. Security in storage—Only the
    required information should be stored. Mandatory PI should be retained. Information
    browsing should be on the basis of “need-to-know”. Pseudonymization and Anonymization
    could be used for privacy. Statistical data is only made accessible. Differential
    privacy technique could be used. Security in processing data—Personal data must
    be treated as per the intended purpose. Personal data should be disclosed or retained
    to third parties on the consent of the owner. Digital Rights Management systems
    are suitable to control data and defend illegal re-distribution. Trusted and secure
    devices are used by DRM. User’s permit and awareness for distribution of PI data
    are necessary. Devices privacy concerns are raised due to inefficient authentication
    and authorization, no encryption in transport, loopholes in the security of web
    interface, insecure software and firmware, etc. [94]. The concerns of security
    are different in each layer of IoT. In the perception layer, the data flow is
    through built-in sensors. Then data transmission is using modules or machine to
    machine (M2M) device resulting in networking services of multiple sensors. Here
    security of machines is involved in consideration of implementation and node connectivity.
    Perception nodes are distributed but are not monitored. Access to these devices
    is quite easy for others. This could lead to damage or illegal actions on these
    nodes. As analysed and categorized these threats are unauthorized access, the
    Internet and denial of service attack. In the network layer, the network provides
    comprehensive capability to interconnect, effectual and economical connection,
    along with the authentic quality of service in IoTs. Excess of machines sending
    data to a large number of IoT nodes could lead to congestion and thus denial of
    service attacks. In the back-end layer, the gateway, middleware, require effective
    and efficient security. The data gathering, examining real-time sensor data and
    increasing business intelligence are highly critical. The security of IoT system
    should have seven major controls all the time viz; privacy, accessibility, authentication,
    communication layer security, data integrity, data confidentiality and availability.
    In IoT systems, reliability and secured communication protocols are required at
    all layers [95]. Security risk in IoT system is a concern due to the use of wireless
    communications technologies and due to open system, accessibility to components
    like sensors. There should be mechanisms to detect external attacking activities
    and self-healing. Encryption is a key element for information security but encrypting
    big volume of real-time data is the big challenge. Efficient encryption algorithm
    should be used. Implementing complex schemes for securing the environment face
    a challenge of constrained energy. Beside mechanisms, appropriate policies are
    required to protect the privacy and make sure all users are comfortable using
    these IoT solutions. 5 IoT Challenges As the IoT ecosystem grows, more requirements
    of memory, power, computational capability and constrained resources are needed.
    The major challenges in key areas of IoT ecosystem in terms of security, scalability,
    heterogeneity and interoperability are required to implement at different layers
    of the ecosystem [96, 97]. Exchanging and managing personal data is a big threat
    to the IoT ecosystem. IoT quality is directly proportional to resolving future
    complexities and the challenges. IoT vision cannot be analysed due to critical
    challenges. A few of the challenges could be discussed as follow: 1. Heterogeneity—To
    create a large IoT ecosystem there is a need of thousands to millions of devices
    and these devices are completely different from each other. All IoT devices are
    heterogeneous in nature based on the input and output format of information and
    the communication protocols. For all these heterogeneous devices to work together
    it is important that the devices understand the information which is captured
    or transferred and be able to compute, create meaningful data after analysis and
    observations on obtained data [98]. The heterogeneity is also present in the communication
    protocol, communication format, the complexity of computation etc. So, inter-device
    communication, interoperable devices and analysis on the data from all heterogeneous
    device to make reliable IoT ecosystem is a big challenge (Fig. 6). Fig. 6 IoT
    challenges Full size image 2. Security and Privacy—When it comes to heterogeneity
    and a scalable system, security is always a major concern. IoT devices record
    huge data about people daily life that collectively could produce personal information
    when analysed in depth so security is a big concern when it comes to heterogeneous
    devices and devices inter-communication So, encryption of data and protecting
    movement of data in a secure manner is a big challenge in a large ecosystem [99,
    100]. A problem in IoT security is the lack of standards. Privacy is the profile
    access in IoT network. Exchanges of data securely is a necessity without compromising
    privacy. All devices communication required transparent and secured access. An
    effort and standardization are necessary to mature the approach of access control
    in the application. Research is going on to design security and privacy in all
    IoT components. There are many open issues as follow: i. Lightweight security
    on constrained resources—IoT ecosystem operates on constrained resources such
    as low energy, small memory and low-end processors. These directly impact the
    security and privacy of the ecosystem. So, it is difficult to design lightweight
    security for constrained resources. ii. Denial of service attack—As IoT ecosystem
    is with limited resources, the useless calls from a hacking system could exhaust
    memory, processor and can bring down the ecosystem. These calls may be occurring
    at all the layers of the ecosystem. iii. End to end security—Although small securities
    are being implemented at all the layers but when we take the complete IoT ecosystem,
    there are many loopholes. Issues like inter-device communication due to different
    protocols, data format support by middleware for heterogeneous devices, securing
    all communication protocols, information flow at various level, classification
    of information for privacy when data is very large are big challenges for an end
    to end security. 3. Scalability—is the ability to add devices, services and functions
    without impacting the performance of the existing system. Diverse heterogeneous
    hardware and communications is a challenge. Designing to enable extensible services
    and operations is required. Interoperability and scalability go hand in hand in
    IoT environment to deliver scalable services. Scalable mechanisms should support
    new device registration, look-up and discovery and interoperability between objects.
    For a large ecosystem containing thousands of devices is a big challenge in terms
    of power, recovery, data flow, security, managing the network, processing data
    etc. These all impact the IoT system when the IoT devices number grow [91]. 4.
    Interoperability—is another challenge for IoT to handle heterogeneous things across
    platforms. Interoperability needs to consider for application developers and device
    manufacturers. Adding new functionality with zero or negligible impact on the
    integrity of the existing system is a significant criterion in designing IoT.
    To process data to form a fruitful analysis, the IoT devices not only themselves
    have to be intelligent but need to operate along with the neighboring devices.
    They need to understand the format of data and also need to work based on another
    device analysis. So, this is also a great challenge to the IoT ecosystem with
    millions of devices. 5. Management and Architecture—billions or trillions of devices
    causes issues in terms of fault, configuration, accounting, performance, architecture
    and security. This management effort incurs extra cost. Managing is a major factor
    in growing IoT. A robust platform to facilitate the management of IoT assets in
    real-time remotely is required. Maintaining compatibility across all IoT layers
    is required to enhance connectivity and ensure delivery. The architecture plays
    a role in the IoT ecosystem where the same device could become a recovery device
    at one time and at other time is used for measuring a physical property. IoT architecture
    should be robust enough to support the ecosystem in terms of complexity, flexibility,
    artificial intelligence, smartness, device count and heterogeneous nature of IoT
    devices. To cope with these problems in creating a flexible ecosystem architecture
    plays a unique role [101]. 6. Availability—in terms of hardware and software to
    achieve anytime and anywhere services for users is a challenge. This is referred
    to as devices or software compatibility with the IoT functionalities and protocols.
    There are studies and research to assess and evaluate the availability of IoT
    applications at the design stage to maximize availability. 7. Reliability—ensures
    the proper working of the system and aims towards the success of service delivery.
    Availability and reliability complement each other towards success. In an application
    that works on emergency response achieved through efficient communication, reliability
    is critical. Reliability should be present at all layers of IoT. 8. Mobility—Most
    services are to be continuously delivered to mobile users. Transfer of device
    causes service interruption as communication transfers one gateway to another.
    Tunnelling supports service continuity resulting in data accessibility while resource
    unavailability. Distributed service also enables mobility. Performance depends
    on many components’ performance. Continuous improvement in services is necessary
    for performance optimization. IoT devices are monitored and evaluated for best
    performance. Performance of the IoT is evaluated on processing and communication
    speed, device form factor, and cost. All protocols and technologies contribute
    to the performance factor and QoS. Due to the IoT revolution, the number of IoT
    devices and functionality of each device is expanding which requires an intelligent
    controller to monitor several inputs from the devices. Creating an OS that satisfies
    all the requirements of all low- and high-end devices are nearly impossible to
    achieve but there is a choice of open-source OS because of detailed information
    about the functionality and requirement which could help to merge simulator to
    extend functionality. Developing applications that are platform-independent and
    to create a middleware in a system and cross interoperability is one of the solutions
    for IoT challenges. 6 Applications in IoT Ecosystem A diverse set of intelligent
    application has been developed. Many of them are readily available and there is
    still a big scope of research in these applications thus enhancing the quality
    of life like smart home, fitness tracker, smart health monitor, smart city etc.
    i. Smart Home—The popularity of this IoT application is that it is growing globally
    due to improving the comfort of life. The smart devices as in sensors and actuator
    along with wireless networks are maturing at a very good pace. This is not only
    improving life’s quality but also providing better security in homes. Sensors
    are deployed for automation and intelligence services that helps to automate the
    day to day activities. On one end there is a cost involved in the installation
    and operation of smart devices but in the long run, they help in energy conservation.
    A few examples are turning lights off and regularizing electronic appliances.
    The sensors collect environmental data like light, temperature, humidity, gas,
    and fire events. This data from sensors is sent to middleware services and accordingly
    takes actions through actuators [102]. For example, when a human is in home or
    arriving home, the application can automatically turn on the AC. From a security
    point in case of a gas leak, home electricity is cut down and an alarm is sent
    to the owner. The smart home can keep a track of the health of family members
    starting from children to old people and alarms for emergencies. Smartphone applications
    are available, which detect emergency, alarm and handle home security and functionalities.
    But there is security and privacy concern as data being captured is floating on
    the internet. An intruder may attack the insecure system and system could fail.
    ii. Smart Cities—It involves sub smart applications like smart transport, smart
    parking, smart traffic fines, smart driving, smart water management etc. Smart
    traffic manages daily traffic using sensors and AI-enabled middleware systems.
    They track the events and activities leading to traffic congestion and take actions
    to ensure smooth traffic. It also enables smart parking; this helps to avoid accidents
    by the proper routing of traffic. Improper and illegal driving is identified and
    automate fines are sent to their register mobile. Vehicles are uniquely identified
    and the cloud is used here to manage the huge data and observe useful information.
    Traffic patterns are observed and future controls are implemented. All these applications
    are connected to smartphones and keep you posted with the update. The congestion
    is also captured by their accelerometer and gyroscope of mobile for sending your
    movement to middleware and GPS is tracked through google maps and thus analysing
    the congestion. At the same time applications can educate drivers on wrong practice
    taken on the road. IoT applications are available to help drivers in becoming
    safer drivers. Sensors are being installed in smart cars to capture driver behaviour
    like drowsy or sleepy and also detect alcohol consumed by the driver. Such sensors
    avoid starting of cars. Sensors like face detection, eye movement detection, alcohol
    detectors and pressure detectors are installed on steering for smart driving.
    Smart parking enables hassle-free parking through the Internet to find an empty
    parking lot. Smart traffic also gives priority to the ambulance by providing a
    clear path by managing traffic lights. Smart water management manages water resources
    efficiently. The water supply lines are managed accordingly and provide an auto-cut
    option. There are also storm drains available in the city. The leaks are identified
    by water inflow and outflow quantity. Similarly, sensors are installed to track
    storm drains, water storage tanks, and water supply lines and helps in the centralized
    water planning strategy [103]. iii. Smart healthcare—It is the system to monitor
    the health condition of individuals, old people, small children and patients etc.
    through many wearable sensors. They continuously monitor an individual health
    condition. In case of emergency or abnormal sensing, the concerned person is alarmed.
    For minor problems, patients are indicated for health check-ups. Smart health
    devices are regularly used for recording allergies, measuring blood sugar, blood
    pressure and stress recognition. Health care systems keep monitoring GPS location
    during the whole day physical activity, also the sleep and rest information [104].
    Fitness sensors keep a monitor on fitness based on our daily activity level measuring
    the number of steps taken and the exercise done. Pressure sensors, accelerometer,
    gyroscope etc. analyse the patterns of the workout and informs for better options.
    The long health record can help the doctor in case of an emergency and take quick
    actions. The various sub-system in smart healthcare are: Patient Monitoring System
    This use-case targets collecting vital sign of patients and sending them to connected
    nursing stations. Assuming private rooms for patients, light and door sensors
    are deployed to monitor patient’s activity and identification of depression patients.
    Relevant Smart sensors can be used. ZigBee or Z-wave are used for communication
    protocols are used to collect and transfer collected data to the nursing stations.
    Using sensors along with microcontroller or microprocessor helps in providing
    efficient integration with hardware and software. These can use Wi-Fi or IEEE
    802.15.4 to communicate. The sensors, microcontroller or microprocessor act as
    clients to the servers installed at nursing stations. For inter-sensor collaboration,
    routing protocol like RPL is used for enabling the multi-hop communication. Doctors
    can remotely access the processed data at servers by mobile application [105].
    Monitoring and improving Eating Disorders To improve eating habits or eating without
    spilling food, a glove equipped with tiny vibrating MEMS motors could be used.
    These counteract unstable hand movement measured by accelerometer like sensors.
    The accelerometer and vibrating motors communicate with a minimum delay to achieve
    the required functionality. The DDS protocol is chosen for this scenario for quick
    direct communication. The collected information is collected and sent to the nursing
    stations [106]. A proxy is required here to communicate between DDS and the gateway
    for translating and sending it to the station. The eating habits which analysed
    can be shared to the patients over the mobile app as a tutorial (Fig. 7). Fig.
    7 Smart healthcare system Full size image Navigation System for Visually Impaired
    People The application is required to provide a real-time location to the users.
    User held stick could have sensors as in proximity sensor, accelerometer, a real-time
    location sensor and other sensors. These would be connected to a local server
    as well. These would estimate the current location of the user. The local server
    overlays the position on a floorplan and is connected to the Internet. This can
    guide a user with navigation information allowing them to avoid obstacles and
    movement constraints earlier captured by other users on the system [107, 108].
    Sensors in Organ IoT health care still has a big scope of research. It will not
    only affect people life but also boom the healthcare industry. Various applications
    in the medical field are there. UV sensors monitor the level of radiation areas
    wise and notify about the high radiation areas to people. Freezer sensors monitor
    the observational objects and adjust the required temperature accordingly [109].
    The activity of disabled or independently living old age people are observed through
    the installed sensors. Medical sensors monitor the sportsman activity and keep
    the doctors notified on the medical health. Sensors for organ are microdevices
    that are implanted in organs. They precisely replicate organ-level functions by
    the development of the primary function parts and provide real-time measurements
    of the organ and their endurance. These devices are successful even in the field
    of drug testing as well as defence research projects. Digital and 3D Printed Pills
    are the latest medical application that is revolutionizing healthcare. These built-in
    chips implanted in pill records the effects of a drug on individuals and transmits
    the data which are analysed. Some wearable sensors pills sense your body and dose
    your body as required. Smart Wheelchairs eliminate the dependency on handicap
    and older people. The aim is to reduce the effort required to navigate the wheelchair.
    The intelligence used with the collaboration of sensors, AI and IoT which helps
    in ease the usability and interactivity. Smart Wearables are the healthcare monitoring
    system in integration with IoT. These constantly monitors the real-time well-being
    of individuals. The data is sent to the servers which can be analysed by the doctor
    in the annual body check-up or in case of an emergency [110]. iv. Smart Agriculture—Environmental
    parameters such as temperature, humidity, soil concentration, the water level
    is measured through agricultural sensors and keep farmers notified about the condition.
    Adequate manual and automated steps are taken by smart agriculture actuators that
    results in high-quality production. Automated irrigation depending on weather
    conditions, greenhouses are some of the implementations of smart agriculture [111].
    The information is gathered by sensors and sent to middleware through gateways.
    The analytical operations are performed and the required actions result in yield
    quality. Pesticide presence is analysed and the land under the strong influence
    is guided not to be used and that part of the land is improved before using. v.
    Smart Air pollution controlling—Industries, Vehicles, fire etc. cause a lot of
    air pollution. Air pollution monitors have been installed in various part of the
    city through electrochemical toxic gas sensors. Vehicles causing pollution are
    identified by RFID readers placed on roads. Smart traffic helps to avoid traffic
    congestion and thus avoid air pollution. vi. Smart Logistics—In supply chain real-time
    tracking of goods displacement are done using sensor technologies like RFID and
    NFC. Handling information can be identified using the smart sensors and RFID tags
    on the product. In case of loss and damage of the product, an analysis report
    could help to highlight the lag in handling and thus adequate actions are taken
    in future that improves the performance of supply chain systems in long run. viii.
    Smart Energy Conservation—The smart grid is technology-enabled electricity management
    system that optimizes generation, transmission, distribution, and consumption
    by adding AI at each step thus resulting in two-way power flow (between consumer
    and supplier). This saves a lot of energy and controls power flow and also provides
    dynamic pricing to consumers. The sensors are deployed to monitor and enables
    the actuator to switch the supply and surplus energy back to the central grid.
    Two-way power flow benefits consumers that have energy generation systems installed
    in the building like solar or wind power. The surplus power is transmitted and
    is reused. This smart system also keeps a monitor on the health of transmission
    lines for disaster prevention and efficient use. In case of emergency, the alarms
    ensure maintainability, availability and also avoid accidents. Smart meters analyse
    consumption patterns and suggest for optimal options and the user are benefitted
    by these smart applications [112]. 7 Conclusion The rapid and emerging paradigm
    of connecting billions of physical objects, empowering human interaction and quality
    of life both physically and virtually thus make everything automatic around us
    is named as IoT. The proliferation of the IoT is dramatically increasing and already
    covers many prominent domains and disciplines. In addition to existing M2M, many
    empowering emerging technologies are there with capabilities and functionalities.
    This survey intends to describe borders of elements to fit correct elements in
    massive heterogeneous IoT ecosystem. A survey on all the elements of the IoT ecosystem
    helps in understanding the concept of IoT, architecture, devices, operating system,
    middleware and communication interfaces. This paper explains about the various
    architectures for IoT ecosystem based on requirements like multilayer, middleware-based,
    service-oriented etc. The significance of low end, middle-end and high-end devices
    in IoT devices are explained in the paper. All smart devices at ground level have
    been compared based on capabilities like architecture, computation, memory, communication
    interfaces have been discussed. OS facilitates development and subsistence of
    IoT. According to the requirement of the hardware, various IoT OS based on the
    resource constraint is discussed in the paper. A comparative overview of open-source
    IoT OS on aspects like kernel, scheduler, memory management, performance, simulator,
    security, power has been done. IoT platforms and middleware act as a bridge between
    devices and application to support heterogeneity, scalability, security and highly
    complex computational capability. IoT middleware has been analysed ranging from
    consumer-centric cloud-based, light-weight actor-based, and heavyweight service-based.
    Basic communication technologies to support IoT has been described. For data to
    flow in a secured way, it discusses low power communication networks and protocols
    for all the layers starting from the physical layer to the application layer.
    Security and privacy issues grew significantly in direct proportion in advancing
    networking and communicating sectors. This open several issues arising due to
    increasing devices, technological integration, increased traffic, data storage
    and processing, privacy and security etc. that become the key areas of research.
    Cloud computing as a base technology in order to operate and integrate with recent
    technologies such as big data. The technology of cloud computing refers to the
    processing power of the data at the “edge” of a network. Additionally, we could
    say that cloud computing operates in “Fog” environment. The interplay between
    the IoT, big data analytics, cloud and fog computing making it an IoT ecosystem
    resolving the problems like mobility, availability, storage, computational capability
    etc. for real-time scenarios has been discussed. The challenges and issues that
    are of significance for design and deployment of expanding IoT ecosystem have
    been displayed. As technology grows and expands but in parallel challenges also
    comes that becomes the key areas of research and thus paper also illustrates IoT
    challenges. In the last this paper also mentions lifesaver smart healthcare and
    other applications in IoT ecosystem focusing on all the component of the ecosystem.
    The dynamic environment of IoT introduces unseen opportunities for communication,
    which are going to change the perception of computing and networking. Abbreviations
    ADC: Analog to digital convertor BLE: Bluetooth low energy CSI camera port: Camera
    Serial Interface camera port DAC: Digital to analog computer DSI display port:
    Display Serial Interface display port FIFO: First In First Out GPS: Global Positioning
    System HDMI: High Definition Multimedia Interface HTTP: Hyper Text Transfer Protocol
    I2C: Inter IC (Integrated Circuit) IETF: Internet Engineering Task Force LAN:
    Local Area Network LCD: Liquid Crystal Display LoRAWAN: Long Range Wireless Area
    Network LTE: Long Term Evolution lwIP: Lightweight Internet Protocol MCU: Microcontroller
    Unit microUSB: Micro Universal Serial Bus NB-IoT: Narrow Band IoT RFID: Radio
    Frequency Identification RISC: Reduced Instruction Set Computer RPL: Routing protocol
    RTOS: Real Time Operating System SPI: Serial peripheral interface UART: Universal
    Asynchronous Receiver/Transmitter UDP: User Datagram Protocol uIP: Micro Internet
    Protocol USART: Universal Synchronous/Asynchronous Receiver/Transmitter WLAN:
    Wireless Local Area Network References X. Wang, X. Zha, W. Ni, R. P. Liu, Y. J.
    Guo, X. Niu and K. Zheng, Survey on blockchain for Internet of Things, Computer
    Communications, Vol. 36, pp. 10–29, 2019. Google Scholar   A. Čolaković and M.
    Hadžialić, Internet of Things (IoT): a review of enabling technologies, challenges,
    and open research issues, Computer Networks, Vol. 144, pp. 17–39, 2018. Google
    Scholar   I. Mashal, O. Alsaryrah, T. Y. Chung, C. Z. Yang, W. H. Kuo and D. P.
    Agrawal, Choices for interaction with things on Internet and underlying issues,
    Ad Hoc Networks, Vol. 28, pp. 68–90, 2015. Google Scholar   I. Lee and K. Lee,
    The Internet of Things (IoT): applications, investments, and challenges for enterprises,
    Business Horizons, Vol. 58, No. 4, pp. 431–440, 2015. Google Scholar   A. Whitmore,
    A. Agarwal and L. Da Xu, The Internet of Things—a survey of topics and trends,
    Information Systems Frontiers, Vol. 17, No. 2, pp. 261–274, 2015. Google Scholar   S.
    D. T. Kelly, N. K. Suryadevara and S. C. Mukhopadhyay, Towards the implementation
    of IoT for environmental condition monitoring in homes, IEEE Sensors Journal,
    Vol. 13, No. 10, pp. 3846–3853, 2013. Google Scholar   A. Al-Fuqaha, M. Guizani,
    M. Mohammadi, M. Aledhari and M. Ayyash, Internet of things: a survey on enabling
    technologies, protocols, and applications, IEEE Communications Surveys & Tutorials,
    Vol. 17, No. 4, pp. 2347–2376, 2015. Google Scholar   E. Ahmed, I. Yaqoob, A.
    Gani, M. Imran and M. Guizani, Internet-of-things-based smart environments: state
    of the art, taxonomy, and open research challenges, IEEE Wireless Communications,
    Vol. 23, No. 5, pp. 10–16, 2016. Google Scholar   F. Al-Turjman, Artificial Intelligence
    in IoT, SpringerCham, 2019. Google Scholar   A. A.Osuwa, E. B. Ekhoragbon, and
    L. T. Fat, Application of artificial intelligence in Internet of Things. In 2017
    9th international conference on computational intelligence and communication networks
    (CICN), IEEE, New York, pp. 169–173, 2017. S. Krco, B. Pokric, and F. Carrez,
    Designing IoT architecture (s): a European perspective. In 2014 IEEE world forum
    on Internet of Things (WF-IoT), IEEE, New York, pp. 79–84, 2014. O. Novo, Blockchain
    meets IoT: an architecture for scalable access management in IoT, IEEE Internet
    of Things Journal, Vol. 5, No. 2, pp. 1184–1195, 2018. Google Scholar   H. Guo,
    J. Ren, D. Zhang, Y. Zhang and J. Hu, A scalable and manageable IoT architecture
    based on transparent computing, Journal of Parallel and Distributed Computing,
    Vol. 118, pp. 5–13, 2018. Google Scholar   J. Gubbi, R. Buyya, S. Marusic and
    M. Palaniswami, Internet of Things (IoT): a vision, architectural elements, and
    future directions, Future Generation Computer Systems, Vol. 29, No. 7, pp. 1645–1660,
    2013. Google Scholar   R. Chen, J. Guo and F. Bao, Trust management for SOA-based
    IoT and its application to service composition, IEEE Transactions on Services
    Computing, Vol. 9, No. 3, pp. 482–495, 2016. Google Scholar   P. Sethi and S.
    R. Sarangi, Internet of things: architectures, protocols, and applications, Journal
    of Electrical and Computer Engineering, 2017. https://doi.org/10.1155/2017/9324035.
    Article   Google Scholar   J. Ren, H. Guo, C. Xu and Y. Zhang, Serving at the
    edge: a scalable iot architecture based on transparent computing, IEEE Network,
    Vol. 31, No. 5, pp. 96–105, 2017. Google Scholar   S. Balaji, K. Nathani and R.
    Santhakumar, IoT technology, applications and challenges a contemporary survey,
    Wireless Personal Communications, Vol. 108, pp. 1–26, 2019. Google Scholar   S.
    Kraijak, and P. Tuwanut, A survey on IoT architectures, protocols, applications,
    security, privacy, real-world implementation and future trends. In 11th international
    conference on wireless communications, networking and mobile computing (WiCOM
    2015), 2015. N. Singh and M. Vardhan, Distributed ledger technology-based property
    transaction system with support for IoT devices, International Journal of Cloud
    Applications and Computing (IJCAC), Vol. 9, No. 2, pp. 60–78, 2019. Google Scholar   V.
    Vujović and M. Maksimović, Raspberry Pi as a Sensor Web node for home automation,
    Computers & Electrical Engineering, Vol. 44, pp. 153–171, 2015. Google Scholar   T.
    Käfer, S. R. Bader, L. Heling, R. Manke, and A. Harth, Exposing Internet of Things
    devices via REST and linked data interfaces. In Proc. 2nd workshop semantic web
    technol. Internet Things, pp. 1–14, 2017. S. Huh, S. Cho, and S. Kim, Managing
    IoT devices using blockchain platform. In 2017 19th international conference on
    advanced communication technology (ICACT), IEEE, New York, pp. 464–467, 2017.
    E. Baccelli, C. Gündoğan, O. Hahm, P. Kietzmann, M. S. Lenders, H. Petersen, K.
    Schleiser, T. C. Schmidt and M. Wählisch, RIOT: an open-source operating system
    for low-end embedded devices in the IoT, IEEE Internet of Things Journal, Vol.
    5, No. 6, pp. 4428–4440, 2018. Google Scholar   D. Zhai, R. Zhang, L. Cai, B.
    Li and Y. Jiang, Energy-efficient user scheduling and power allocation for NOMA-based
    wireless networks with massive IoT devices, IEEE Internet of Things Journal, Vol.
    5, No. 3, pp. 1857–1868, 2018. Google Scholar   F. Shaikh, E. Bou-Harb, N. Neshenko,
    A. P. Wright and N. Ghani, Internet of malicious things: correlating active and
    passive measurements for inferring and characterizing internet-scale unsolicited
    IoT devices, IEEE Communications Magazine, Vol. 56, No. 9, pp. 170–177, 2018.
    Google Scholar   M. A. R. Shuman, A. Goel, S. Sharma, B. Gupta, A. Aggarwal, I.
    D. Guedalia, R. P. Chandhok, and J. Guedalia, Qualcomm Inc, Establishing groups
    of internet of things (IOT) devices and enabling communication among the groups
    of IOT devices. U.S. Patent 9853826, 2017. P. Desai, A. Sheth, and P. Anantharam,
    Semantic gateway as a service architecture for iot interoperability. In 2015 IEEE
    International Conference on Mobile Services, IEEE, New York, pp. 313–319, 2015.
    G. Aloi, G. Caliciuri, G. Fortino, R. Gravina, P. Pace, W. Russo and C. Savaglio,
    Enabling IoT interoperability through opportunistic smartphone-based mobile gateways,
    Journal of Network and Computer Applications, Vol. 81, pp. 74–84, 2017. Google
    Scholar   B. Kang and H. Choo, An experimental study of a reliable IoT gateway,
    ICT Express, Vol. 4, No. 3, pp. 130–133, 2018. Google Scholar   Q. Zhu, R. Wang,
    Q. Chen, Y. Liu, and W. Qin, Iot gateway: bridging wireless sensor networks into
    internet of things. In 2010 IEEE/IFIP international conference on embedded and
    ubiquitous computing, IEEE, New York, pp. 347–352, 2010. B. Kang, D. Kim and H.
    Choo, Internet of everything: a large-scale autonomic IoT gateway, IEEE Transactions
    on Multi-Scale Computing Systems, Vol. 3, No. 3, pp. 206–214, 2017. Google Scholar   S.
    K. Datta, C. Bonnet, and N. Nikaein, An IoT gateway centric architecture to provide
    novel M2M services. In 2014 IEEE World Forum on Internet of Things (WF-IoT), IEEE,
    New York, pp. 514–519, 2014. H. Chen, X. Jia, and H. Li, October. A brief introduction
    to IoT gateway. In IET international conference on communication technology and
    application (ICCTA 2011), IET, London, pp. 610–613, 2011. S. Guoqiang, C. Yanming,
    Z. Chao, and Z. Yanxu, Design and implementation of a smart IoT gateway. In 2013
    IEEE international conference on green computing and communications and IEEE internet
    of things and IEEE cyber, physical and social computing, IEEE, New York, pp. 720–723,
    2013. F. C. Cheng, Automatic and secure Wi-Fi connection mechanisms for IoT end-devices
    and gateways. In International conference for emerging technologies in computing,
    Springer, Cham, pp. 98–106, 2018. P. Gaur, and M. P. Tahiliani, Operating systems
    for IoT devices: a critical survey. In 2015 IEEE region 10 symposium, IEEE, New
    York, pp. 33–36, 2015. O. Hahm, E. Baccelli, H. Petersen and N. Tsiftes, Operating
    systems for low-end devices in the internet of things: a survey, IEEE Internet
    of Things Journal, Vol. 3, No. 5, pp. 720–734, 2016. Google Scholar   A. Musaddiq,
    Y. B. Zikria, O. Hahm, H. Yu, A. K. Bashir and S. W. Kim, A survey on resource
    management in IoT operating systems, IEEE Access, Vol. 6, pp. 8459–8482, 2018.
    Google Scholar   D. Balsamo, A. Elboreini, B. M. Al-Hashimi, and G. V. Merrett,
    Exploring ARM mbed support for transient computing in energy harvesting IoT systems.
    In 2017 7th IEEE international workshop on advances in sensors and interfaces
    (IWASI), IEEE, New York, pp. 115–120, 2017. A. Dunkels, O. Schmidt, N. Finne,
    J. Eriksson, F. Österlind, and N. T. M. Durvy, The Contiki os: the operating system
    for the internet of things, 2011, http://www.contikios.org. V. J. P. Amorim, S.
    Delabrida, and R. A. R. Oliveira, A constraint-driven assessment of operating
    systems for wearable devices. In 2016 VI Brazilian symposium on computing systems
    engineering (SBESC), IEEE, New York, pp. 150–155, 2016. P. Dutta and A. Dunkels,
    Operating systems and network protocols for wireless sensor networks, Philosophical
    Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences,
    Vol. 370, No. 1958, pp. 68–84, 2012. MathSciNet   MATH   Google Scholar   A. Kazmi,
    M. Serrano and J. Soldatos, Vital-os: an open-source iot operating system for
    smart cities, IEEE Communications Standards Magazine, Vol. 2, No. 2, pp. 71–77,
    2018. Google Scholar   F. Javed, M. K. Afzal, M. Sharif and B. S. Kim, Internet
    of things (IoT) operating systems support, networking technologies, applications,
    and challenges: a comparative review, IEEE Communications Surveys & Tutorials,
    Vol. 20, No. 3, pp. 2062–2100, 2018. Google Scholar   D. Zhang, C. C. Chan and
    G. Y. Zhou, Enabling Industrial Internet of Things (IIoT) towards an emerging
    smart energy system, Global Energy Interconnection, Vol. 1, No. 1, pp. 39–47,
    2018. Google Scholar   A. C. G. Anadiotis, S. Milardo, G. Morabito and S. Palazzo,
    Toward unified control of networks of switches and sensors through a network operating
    system, IEEE Internet of Things Journal, Vol. 5, No. 2, pp. 895–904, 2018. Google
    Scholar   R. Morabito, V. Cozzolino, A. Y. Ding, N. Beijar and J. Ott, Consolidate
    IoT edge computing with lightweight virtualization, IEEE Network, Vol. 32, No.
    1, pp. 102–111, 2018. Google Scholar   S. Iraji, P. Mogensen and R. Ratasuk, Recent
    advances in M2M communications and internet of things (IoT), International Journal
    of Wireless Information Networks, Vol. 24, pp. 240–242, 2017. https://doi.org/10.1007/s10776-017-0362-3.
    Article   Google Scholar   S. Persia, C. Carciofi, and M. Faccioli, NB-IoT and
    LoRA connectivity analysis for M2M/IoT smart grids applications. In 2017 AEIT
    international annual conference, IEEE, New York, pp. 1–6, 2017. E. S. Lohan, M.
    Koivisto, O. Galinina, S. Andreev, A. Tolli, G. Destino, M. Costa, K. Leppanen,
    Y. Koucheryavy and M. Valkama, Benefits of positioning-aided communication technology
    in high-frequency industrial IoT, IEEE Communications Magazine, Vol. 56, No. 12,
    pp. 142–148, 2018. Google Scholar   M. Siekkinen, M. Hiienkari, J. K. Nurminen,
    and J. Nieminen, How low energy is Bluetooth low energy? Comparative measurements
    with zigbee/802.15. 4. In 2012 IEEE wireless communications and networking conference
    workshops (WCNCW), IEEE, New York, pp. 232–237, 2012. M. M. Alam, H. Malik, M.
    I. Khan, T. Pardy, A. Kuusik and Y. Le Moullec, A survey on the roles of communication
    technologies in IoT-based personalized healthcare applications, IEEE Access, Vol.
    6, pp. 36611–36631, 2018. Google Scholar   A. A. Mutlag, M. K. A. Ghani, N. A.
    Arunkumar, M. A. Mohamed and O. Mohd, Enabling technologies for fog computing
    in healthcare IoT systems, Future Generation Computer Systems, Vol. 90, pp. 62–78,
    2019. Google Scholar   P. Pongle, and G. Chavan, A survey: attacks on RPL and
    6LoWPAN in IoT. In 2015 international conference on pervasive computing (ICPC),
    IEEE, New York, pp. 1–6, 2015. C. Bormann, K. Hartke, and Z. Shelby, The constrained
    application protocol (CoAP), RFC 7252, 2015. S. Bansal, and D. Kumar, IoT application
    layer protocols: performance analysis and significance in smart city. In 2019
    10th international conference on computing, communication and networking technologies
    (ICCCNT), IEEE, New York, pp. 1–6, 2019. J. Wan, B. Chen, M. Imran, F. Tao, D.
    Li, C. Liu and S. Ahmad, Toward dynamic resources management for IoT-based manufacturing,
    IEEE Communications Magazine, Vol. 56, No. 2, pp. 52–59, 2018. Google Scholar   A.
    A. Zaidan, B. B. Zaidan, M. Y. Qahtan, O. S. Albahri, A. S. Albahri, M. Alaa,
    F. M. Jumaah, M. Talal, K. L. Tan, W. L. Shir and C. K. Lim, A survey on communication
    components for IoT-based technologies in smart homes, Telecommunication Systems,
    Vol. 69, No. 1, pp. 1–25, 2018. Google Scholar   R. Bonetto, N. Bui, V. Lakkundi,
    A. Olivereau, A. Serbanati, and M. Rossi, Secure communication for smart IoT object
    sacks, use cases and practical examples. In 2012 IEEE international symposium
    on a world of wireless, mobile and multimedia networks (WoWMoM), IEEE, New York,
    pp. 1–7, 2012. S. Al-Sarawi, M. Anbar, K. Alieyan, and M. Alzubaidi, Internet
    of Things (IoT) communication protocols. In 2017 8th international conference
    on information technology (ICIT), IEEE, New York, pp. 685–690, 2017. K. Ponnusamy
    and N. Rajagopalan, Internet of things: a survey on IoT protocol standards. Progress
    in Advanced Computing and Intelligent Engineering, SpringerSingapore, 2018. pp.
    651–663. Google Scholar   B. Vejlgaard, M. Lauridsen, H. Nguyen, I. Z. Kovács,
    P. Mogensen, and M. Sorensen, Coverage and capacity analysis of sigfox, Lora,
    GPRS, and nb-iot. In 2017 IEEE 85th vehicular technology conference (VTC Spring),
    IEEE, New York, pp. 1–5, 2017. M. Lauridsen, H. Nguyen, B. Vejlgaard, I. Z. Kovács,
    P. Mogensen, and M. Sorensen, Coverage comparison of GPRS, NB-IoT, LoRa, and SigFox
    in a 7800 km2 area. In 2017 IEEE 85th vehicular technology conference (VTC Spring),
    IEEE, New York, pp. 1–5, 2017. R. S. Sinha, Y. Wei and S. H. Hwang, A survey on
    LPWA technology: LoRa and NB-IoT, Ict Express, Vol. 3, No. 1, pp. 14–21, 2017.
    Google Scholar   J. Dizdarević, F. Carpio, A. Jukan and X. Masip-Bruin, A survey
    of communication protocols for internet of things and related challenges of fog
    and cloud computing integration, ACM Computing Surveys (CSUR), Vol. 51, No. 6,
    p. 116, 2019. Google Scholar   Y. Chen, and T. Kunz, Performance evaluation of
    IoT protocols under a constrained wireless access network. In 2016 international
    conference on selected topics in mobile & wireless networking (MoWNeT), IEEE,
    New York, pp. 1–7, 2016. U. D. Ulusar, F. Al-Turjman, and G. Celik, An overview
    of Internet of things and wireless communications. In 2017 international conference
    on computer science and engineering (UBMK), IEEE, New York, pp. 506–509, 2017.
    K. Hartke, Observing resources in the constrained application protocol (CoAP)
    (No. RFC 7641), 2015. K. Mekki, E. Bajic, F. Chaxel and F. Meyer, A comparative
    study of LPWAN technologies for large-scale IoT deployment, ICT Express, Vol.
    5, No. 1, pp. 1–7, 2019. Google Scholar   W. Ayoub, A. E. Samhat, F. Nouvel, M.
    Mroue and J. C. Prévotet, Internet of mobile things: overview of LoRaWAN, DASH7,
    and NB-IoT in LPWANs standards and supported mobility, IEEE Communications Surveys
    & Tutorials, Vol. 21, No. 2, pp. 1561–1581, 2018. Google Scholar   M. Centenaro
    and L. Vangelista, Time-power multiplexing for LoRa-based IoT networks: an effective
    way to boost LoRaWAN network capacity, International Journal of Wireless Information
    Networks, Vol. 26, pp. 1–11, 2019. Google Scholar   A. H. Ngu, M. Gutierrez, V.
    Metsis, S. Nepal and Q. Z. Sheng, IoT middleware: a survey on issues and enabling
    technologies, IEEE Internet of Things Journal, Vol. 4, No. 1, pp. 1–20, 2017.
    Google Scholar   M. A. da Cruz, J. J. Rodrigues, A. K. Sangaiah, J. Al-Muhtadi
    and V. Korotaev, Performance evaluation of IoT middleware, Journal of Network
    and Computer Applications, Vol. 109, pp. 53–65, 2018. Google Scholar   S. Bandyopadhyay,
    M. Sengupta, S. Maiti and S. Dutta, Role of middleware for internet of things:
    a study, International Journal of Computer Science and Engineering Survey, Vol.
    2, No. 3, pp. 94–105, 2011. Google Scholar   A. Palade, C. Cabrera, F. Li, G.
    White, M. A. Razzaque and S. Clarke, Middleware for internet of things: an evaluation
    in a small-scale IoT environment, Journal of Reliable Intelligent Environments,
    Vol. 4, No. 1, pp. 3–23, 2018. Google Scholar   C. Pereira, J. Cardoso, A. Aguiar
    and R. Morla, Benchmarking Pub/Sub IoT middleware platforms for smart services,
    Journal of Reliable Intelligent Environments, Vol. 4, No. 1, pp. 25–37, 2018.
    Google Scholar   A. Ranganathan, J. Al-Muhtadi, S. Chetan, R. Campbell and M.
    D. Mickunas, Middleware: a middleware for location awareness in ubiquitous computing
    applications. ACM/IFIP/USENIX International Conference on Distributed Systems
    Platforms and Open Distributed Processing, SpringerBerlin, 2004. pp. 397–416.
    Google Scholar   G. Kokkonis, A. Chatzimparmpas, and S. Kontogiannis, Middleware
    IoT protocols performance evaluation for carrying out clustered data. In 2018
    South-Eastern European design automation, computer engineering, computer networks
    and society media conference (SEEDA_CECNSM), IEEE, New York, pp. 1–5, 2018. H.
    Hejazi, H. Rajab, T. Cinkler, and L. Lengyel, Survey of platforms for massive
    IoT. In 2018 IEEE international conference on future IoT technologies (future
    IoT), IEEE, New York, pp. 1–8, 2018. J. Kim, J. Yun, S. C. Choi, D. N. Seed, G.
    Lu, M. Bauer, A. Al-Hezmi, K. Campowsky and J. Song, Standard-based IoT platforms
    interworking: implementation, experiences, and lessons learned, IEEE Communications
    Magazine, Vol. 54, No. 7, pp. 48–54, 2016. Google Scholar   A. Bröring, S. Schmid,
    C. K. Schindhelm, A. Khelil, S. Käbisch, D. Kramer, D. Le Phuoc, J. Mitic, D.
    Anicic and E. Teniente, Enabling IoT ecosystems through platform interoperability,
    IEEE Software, Vol. 34, No. 1, pp. 54–61, 2017. Google Scholar   G. Keramidas,
    N. Voros and M. Hübner, Components and Services for IoT Platforms, Springer International
    PuCham, 2016. Google Scholar   G. Fortino, C. Savaglio, C. E. Palau, J. S. de
    Puga, M. Ganzha, M. Paprzycki, M. Montesinos, A. Liotta, and M. Llop, Towards
    multi-layer interoperability of heterogeneous IoT platforms: the INTER-IoT approach.
    In Integration, interconnection, and interoperability of IoT systems, Springer,
    Cham, pp. 199–232, 2018. F. Y. Okay and S. Ozdemir, Routing in fog-enabled IoT
    platforms: a survey and an SDN-based solution, IEEE Internet of Things Journal,
    Vol. 5, No. 6, pp. 4871–4889, 2018. Google Scholar   T. Jell, C. Baumgartner,
    A. Bröring, J. Mitic and B. I. G. IoT, interconnecting IoT platforms from different
    domains—first success story. Information Technology-New Generations, SpringerCham,
    2018. pp. 721–724. Google Scholar   B. B. Gupta and D. P. Agrawal, editors., Handbook
    of Research on Cloud Computing and Big Data Applications in IoT, IGI GlobalHershey,
    2019. Google Scholar   A. Ghosh, D. Chakraborty and A. Law, Artificial intelligence
    in Internet of things, CAAI Transactions on Intelligence Technology, Vol. 3, No.
    4, pp. 208–218, 2018. Google Scholar   A. Oussous, F. Z. Benjelloun, A. A. Lahcen
    and S. Belfkih, Big Data technologies: a survey, Journal of King Saud University-Computer
    and Information Sciences, Vol. 30, No. 4, pp. 431–448, 2018. Google Scholar   G.
    Sun, V. Chang, S. Guan, M. Ramachandran, J. Li and D. Liao, Big Data and Internet
    of Things—fusion for different services and its impacts, Future Generation Computer
    Systems, Vol. 86, pp. 1368–1370, 2018. Google Scholar   C. Stergiou, K. E. Psannis,
    B. G. Kim and B. Gupta, Secure integration of IoT and cloud computing, Future
    Generation Computer Systems, Vol. 78, pp. 964–975, 2018. Google Scholar   K. Hossain,
    M. Rahman and S. Roy, IoT data compression and optimization techniques in cloud
    storage: current prospects and future directions, International Journal of Cloud
    Applications and Computing (IJCAC), Vol. 9, No. 2, pp. 43–59, 2019. Google Scholar   Y.
    A. Mo, Data security storage method for IoT under Hadoop cloud computing platform,
    International Journal of Wireless Information Networks, Vol. 26, pp. 152–157,
    2019. https://doi.org/10.1007/s10776-019-00434-x. Article   Google Scholar   B.
    B. Gupta, Computer and Cybersecurity: Principles, Algorithm, Applications, and
    Perspectives, CRC PressBoca Raton, 2018. Google Scholar   C. Stergiou, K. E. Psannis,
    B. B. Gupta and Y. Ishibashi, Security, privacy & efficiency of sustainable cloud
    computing for big data & IoT, Sustainable Computing: Informatics and Systems,
    Vol. 19, pp. 174–184, 2018. Google Scholar   A. Sehgal, V. Perelman, S. Kuryla
    and J. Schonwalder, Management of resource-constrained devices in the internet
    of things, IEEE Communications Magazine, Vol. 50, No. 12, pp. 144–149, 2012. Google
    Scholar   Z. K. Zhang, M. C. Y. Cho, C. W. Wang, C. W. Hsu, C. K. Chen, and S.
    Shieh, IoT security: ongoing challenges and research opportunities. In 2014 IEEE
    7th international conference on service-oriented computing and applications, IEEE,
    New York, pp. 230–234, 2014. A. Dorri, S. S. Kanhere, R. Jurdak, and P. Gauravaram,
    Blockchain for IoT security and privacy: the case study of a smart home. In 2017
    IEEE international conference on pervasive computing and communications workshops
    (PerCom workshops), IEEE, New York, pp. 618–623, 2017. B. Guo, D. Zhang, Z. Wang,
    Z. Yu and X. Zhou, Opportunistic IoT: exploring the harmonious interaction between
    human and the internet of things, Journal of Network and Computer Applications,
    Vol. 36, No. 6, pp. 1531–1539, 2013. Google Scholar   C. Chang, S. N. Srirama
    and R. Buyya, Internet of things (IoT) and new computing paradigms, Fog and Edge
    Computing: Principles and Paradigms, Vol. 6, pp. 1–23, 2019. Google Scholar   I.
    Yaqoob, I. A. T. Hashem, A. Ahmed, S. A. Kazmi and C. S. Hong, Internet of things
    forensics: recent advances, taxonomy, requirements, and open challenges, Future
    Generation Computer Systems, Vol. 92, pp. 265–275, 2019. Google Scholar   M. Chen,
    J. Yang, X. Zhu, X. Wang, M. Liu and J. Song, Smart home 2.0: innovative smart
    home system powered by botanical IoT and emotion detection, Mobile Networks and
    Applications, Vol. 22, No. 6, pp. 1159–1169, 2017. Google Scholar   A. Sharif,
    J. P. Li and M. A. Saleem, Internet of things enabled vehicular and ad hoc networks
    for smart city traffic monitoring and controlling: a review, International Journal
    of Advanced Networking and Applications, Vol. 10, No. 3, pp. 3833–3842, 2018.
    Google Scholar   L. Catarinucci, D. De Donno, L. Mainetti, L. Palano, L. Patrono,
    M. L. Stefanizzi and L. Tarricone, An IoT-aware architecture for smart healthcare
    systems, IEEE Internet of Things Journal, Vol. 2, No. 6, pp. 515–526, 2015. Google
    Scholar   F. Fernandez, and G. C. Pallis, Opportunities and challenges of the
    Internet of Things for healthcare: systems engineering perspective. In 2014 4th
    international conference on wireless mobile communication and healthcare-transforming
    healthcare through innovations in mobile and wireless technologies (MOBIHEALTH),
    IEEE, New York, pp. 263–266, 2014. A. Iyengar, A. Kundu and G. Pallis, Healthcare
    informatics and privacy, IEEE Internet Computing, Vol. 22, No. 2, pp. 29–31, 2018.
    Google Scholar   R. Zgheib, E. Conchon and R. Bastide, Semantic middleware architectures
    for IoT healthcare applications. Enhanced Living Environments, SpringerCham, 2019.
    pp. 263–294. Google Scholar   S. B. Baker, W. Xiang and I. Atkinson, Internet
    of things for smart healthcare: technologies, challenges, and opportunities, IEEE
    Access, Vol. 5, pp. 26521–26544, 2017. Google Scholar   D. A. Gandhi, and M. Ghosal,
    Intelligent healthcare using IoT: a extensive survey. In 2018 second international
    conference on inventive communication and computational technologies (ICICCT),
    IEEE, New York, pp. 800–802, 2018. N. Deshai, S. Venkataramana, B. V. D. S. Sekhar,
    K. Srinivas and G. P. S. Varma, A study on IOT tools, protocols, applications,
    opportunities and challenges. Information Systems Design and Intelligent Applications,
    SpringerSingapore, 2019. pp. 367–380. Google Scholar   K. Lakhwani, H. Gianey,
    N. Agarwal and S. Gupta, Development of IoT for smart agriculture a review. Emerging
    Trends in Expert Applications and Security, SpringerSingapore, 2019. pp. 425–432.
    Google Scholar   J. P. Lemayian and F. Al-Turjman, Intelligent IoT communication
    in smart environments: an overview. Artificial Intelligence in IoT, SpringerCham,
    2019. pp. 207–221. Google Scholar   Download references Author information Authors
    and Affiliations ECE Department, Sant Longowal Institute of Engineering and Technology,
    Longowal, Sangrur, India Sharu Bansal & Dilip Kumar Corresponding author Correspondence
    to Sharu Bansal. Additional information Publisher''s Note Springer Nature remains
    neutral with regard to jurisdictional claims in published maps and institutional
    affiliations. Rights and permissions Reprints and permissions About this article
    Cite this article Bansal, S., Kumar, D. IoT Ecosystem: A Survey on Devices, Gateways,
    Operating Systems, Middleware and Communication. Int J Wireless Inf Networks 27,
    340–364 (2020). https://doi.org/10.1007/s10776-020-00483-7 Download citation Received
    09 October 2019 Revised 08 January 2020 Accepted 05 February 2020 Published 13
    February 2020 Issue Date September 2020 DOI https://doi.org/10.1007/s10776-020-00483-7
    Share this article Anyone you share the following link with will be able to read
    this content: Get shareable link Provided by the Springer Nature SharedIt content-sharing
    initiative Keywords IoT devices OS Middleware Communication Gateways Security
    Use our pre-submission checklist Avoid common mistakes on your manuscript. Sections
    Figures References Abstract Introduction IoT Architecture IoT Taxonomy Elements
    of IoT Ecosystem IoT Challenges Applications in IoT Ecosystem Conclusion Abbreviations
    References Author information Additional information Rights and permissions About
    this article Advertisement Discover content Journals A-Z Books A-Z Publish with
    us Publish your research Open access publishing Products and services Our products
    Librarians Societies Partners and advertisers Our imprints Springer Nature Portfolio
    BMC Palgrave Macmillan Apress Your privacy choices/Manage cookies Your US state
    privacy rights Accessibility statement Terms and conditions Privacy policy Help
    and support 129.93.161.219 Big Ten Academic Alliance (BTAA) (3000133814) - University
    of Nebraska-Lincoln (3000134173) © 2024 Springer Nature"'
  inline_citation: '>'
  journal: International Journal of Wireless Information Networks
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'IoT Ecosystem: A Survey on Devices, Gateways, Operating Systems, Middleware
    and Communication'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Firouzi F.
  - Farahani B.
  - Weinberger M.
  - DePace G.
  - Aliee F.S.
  citation_count: '49'
  description: The Internet is everywhere and touched almost every corner of the globe
    affecting our lives in previously unimagined ways. As a living entity, the Internet
    is constantly evolving, and now, an era of widespread connectivity through various
    smart devices (i.e., things) that connect with the Internet has begun. This paradigm
    change is generally referred to as the Internet of Things (IoT). Welcoming IoT
    will bring significant benefits to economies and businesses as it enables greater
    innovation and productivity. On the other hand, the rapid adoption of IoT presents
    new challenges regarding connectivity, security, data processing, and scalability.
    Because the IoT world is vast and versatile, it cannot be viewed as a single technology.
    IoT looks more like an umbrella covering many protocols, technologies, and concepts
    that depend on specific industries. In this chapter, we will seek to look at the
    history of IoT, more clearly define it, and review its terms and concepts. We
    will also review vertical IoT markets and higher-level use cases that have successfully
    adopted IoT solutions. We will also discuss the details of the business implications,
    business models, and opportunities of IoT. Finally, the complete IoT stack and
    reference architectures from smart objects, to the networks, to the cloud, and
    finally the applications where information is leveraged are explained.
  doi: 10.1007/978-3-030-30367-9_1
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Log in Find a journal
    Publish with us Track your research Search Cart Home Intelligent Internet of Things
    Chapter IoT Fundamentals: Definitions, Architectures, Challenges, and Promises
    Chapter First Online: 22 January 2020 pp 3–50 Cite this chapter Access provided
    by University of Nebraska-Lincoln Download book PDF Download book EPUB Intelligent
    Internet of Things Farshad Firouzi, Bahar Farahani, Markus Weinberger, Gabriel
    DePace & Fereidoon Shams Aliee  4010 Accesses 32 Citations 1 Altmetric Abstract
    The Internet is everywhere and touched almost every corner of the globe affecting
    our lives in previously unimagined ways. As a living entity, the Internet is constantly
    evolving, and now, an era of widespread connectivity through various smart devices
    (i.e., things) that connect with the Internet has begun. This paradigm change
    is generally referred to as the Internet of Things (IoT). Welcoming IoT will bring
    significant benefits to economies and businesses as it enables greater innovation
    and productivity. On the other hand, the rapid adoption of IoT presents new challenges
    regarding connectivity, security, data processing, and scalability. Because the
    IoT world is vast and versatile, it cannot be viewed as a single technology. IoT
    looks more like an umbrella covering many protocols, technologies, and concepts
    that depend on specific industries. In this chapter, we will seek to look at the
    history of IoT, more clearly define it, and review its terms and concepts. We
    will also review vertical IoT markets and higher-level use cases that have successfully
    adopted IoT solutions. We will also discuss the details of the business implications,
    business models, and opportunities of IoT. Finally, the complete IoT stack and
    reference architectures from smart objects, to the networks, to the cloud, and
    finally the applications where information is leveraged are explained. All compromise
    is based on give and take, but there can be no give and take on fundamentals.
    Any compromise on mere fundamentals is a surrender. For it is all give and no
    take. Mahatma Gandhi Access provided by University of Nebraska-Lincoln. Download
    chapter PDF Similar content being viewed by others Internet of Things: An Overview
    Chapter © 2020 Internet of Things Overview: Architecture, Technologies, Application,
    and Challenges Chapter © 2024 IoT Framework, Architecture Services, Platforms,
    and Reference Models Chapter © 2022 Keywords Internet of everything IoT applications
    IoT challenges IoT benefits Digitalization IoT reference models IoT stack IoTWF
    Big data Cloud computing Edge computing Fog computing IoT frameworks and platforms
    Industry 4.0 Smart factory Smart city Smart agriculture Smart grid Smart logistics
    and transportation Business implications Business models LEAN MVP Data monetization
    Minimum viable product (MVP) 1 What Is IoT By now, everyone has heard of the Internet
    of Things (IoT). Internet of Things has been defined as the next logical stage
    of the Internet and its extension into the physical world. It is the broad connection
    of devices that can interact with each other and share data to a larger network,
    where the shared data can be leveraged to extract value. All devices must have
    unique identifiers and use embedded technologies to sense and gather data about
    themselves and their environment and transfer that data to other devices or other
    hosts. Then these data must be correlated and analyzed to inform more intelligent
    decisions. The technical challenges are appealing in themselves, but from an industrial
    and business perspective, IoT presents a grand opportunity to leverage previously
    unknown information and insight to transform and create industrial processes and
    business models. This reality is a much greater opportunity than a simple connection.
    Several companies have defined the Internet of Things in their own terms, and
    it is instructive to examine these terms to see the similarities and differences.
    IBM defines the Internet of Things as “the concept of connecting any device (physical
    object) to the Internet and to other connected devices” [1]. IBM also writes that
    IoT refers to “the growing range of Internet-connected devices that capture or
    generate an enormous amount of information every day” [1]. SAP defines the Internet
    of Things as “the vast network of devices connected to the Internet, including
    smartphones, and tablets and almost anything with a sensor on it – cars, machines
    in production plants, jet engines, oil drills, wearable devices, and more. These
    things collect and exchange data” [2]. Gartner says “IoT is the network of physical
    objects that contain embedded technology to communicate and sense or interact
    with their internal states or the external environment” [3]. The Bosch corporation
    defines the Internet of Things as file sharing, e-commerce, social media, and
    the glue that connects things and devices. The devices can range from sensors
    and security cameras to vehicles and production machines. The connection of devices
    results in data that opens up new insights, business models, and revenue streams.
    The insights can lead to new services complementing conventional product business
    [4]. Oxford Dictionary summarizes IoT as “a proposed development of the Internet
    in which everyday objects have network connectivity, allowing them to send and
    receive data.” Finally, IDC defines the Internet of Things as “a network of networks
    of uniquely identifiable endpoints that communicate without human interaction
    using IP connectivity (local or globally)” [5]. As you noticed, due to rapid emergence
    and convergence of technologies, the definition of IoT is evolving, and thus there
    are several definitions of IoT from different points of view. However, all of
    them have the following fundamental characteristics: Things or Devices – Things
    in IoT (also known as intelligent objects, smart objects, IoT devices, or IoT
    endpoints) are connected objects that can sense, actuate, and interact with other
    objects, systems, or people. In order to be a device on the Internet of Things,
    the device must have a processing unit, power source, sensor/actuator, network
    connection, and a tag/address so that it can be uniquely identified. Connectivity
    – Connectivity empowers the Internet of Things by enabling IoT things to be connected
    to the Internet or other networks. This implies that there must be a connectivity
    module in each IoT device as well as an appropriate communication protocol that
    the network and the device can both understand. Data – There is no IoT without
    (“big”) data collected from IoT things and indeed “data is the new oil.” Data
    is the first step toward action and intelligence. Sent information from IoT devices
    most often include environmental data, diagnostic, location data, or report on
    their status. The data also flows back to the device, for example, a command to
    tell it to sleep, or decrease power consumption. Intelligence – Intelligence is
    the key to unlock IoT potentials because of its ability to extract insights from
    IoT data. For example, the combination of artificial intelligence (AI), machine
    learning, data analytics, and IoT data can avoid unplanned downtime (i.e., predictive
    maintenance), increase operational efficiency, enable new and improved products
    and services, and enhance risk management [6]. Action – Actions are the consequence
    of intelligence. It refers to the automated actions to be taken by the device
    or on the device, but also includes action from the stakeholders in the IoT ecosystem.
    Ecosystem – IoT has to be seen and analyzed through an ecosystem perspective.
    IoT things themselves, the protocols they use, the platforms on which they run,
    the communities interested in the data, as well as the goals and aims of interested
    parties all form the ecosystem. Heterogeneity – The Internet of Things is expected
    to be made up of heterogeneous devices, working on different platforms on different
    networks. Therefore, all the components should be interoperable, i.e., they must
    be able to connect, exchange, and present data in a coordinated manner based on
    a common reference model. Dynamic Changes – The state of devices, the contexts
    in which they operate, the number of connected devices, and the data they transmit
    and receive are all expected to change dynamically. Enormous Scale – The number
    of connected devices will be at least an order of magnitude more than current
    connections. This means there will be a commensurate increase in the amount of
    data generated by the devices, which in turn must be transferred and analyzed
    to be leveraged. Security and Privacy – Security and privacy are an intrinsic
    part of IoT. These issues are critical as personal data will be available online
    (e.g., in a healthcare system, IoT devices could be charting and sharing heart
    rate, blood glucose levels, sleep patterns, and personal well-being). This demands
    data sovereignty, secure networks, secure endpoints, and a scalable data security
    plan to keep all of this information safe. The Internet of Things exists in an
    ecosystem, all the components and the environment that supports IoT and its aims.
    In an IoT ecosystem, there are four major components: things, data, people, and
    process. Let us examine each in turn (see Fig. 1.1) [7]. Of course, all four components,
    things, data, people, and process, must work in concert in order to achieve the
    promises of a more connected world. Fig. 1.1 IoT: The networked connection of
    people, things, data, and process Full size image Things – Things refers to the
    physical devices that operate as part of the Internet of Things. Each device must
    have the ability to connect to other devices or the network in general. This could
    be with a specialized communication protocol such as Zigbee or Bluetooth or the
    more general Internet Protocols (IP). The device needs the energy and processing
    power to handle that communication. Also, to be an IoT device, there must be some
    data to communicate. Most frequently, this is sensor data that is collected by
    the device itself. Some examples include image data from a security camera, temperature
    data from a thermometer, humidity or pressure data from a sensor on an industrial
    manufacturing machine, and so on. The thing or device may also be commanded to
    perform some action, perhaps sending specific data or moving an actuator or some
    other control motor. The device must be able to acknowledge these commands, perform
    these actions, and confirm with the remote controller that the desired action
    is performed. Routers, switches, and gateways are considered as part of the network
    but may also be classified as things. Devices must be equipped to survive the
    environmental conditions in which they are installed and have the necessary power,
    sensors, and communications to fulfill these roles. Data – The data component
    has been partially defined already, as those sensor data being sent from things
    as well as any commands being issued to the things. With the huge number of things
    producing data so often, it is easy to understand that the size of the data itself
    will be enormous. The raw data must be cleaned, that is, checked for errors and
    formatted, and then either stored for analysis or analyzed immediately. This task
    can be done at the edge of the network, close to the devices, or the data can
    be communicated to a more central collection point (e.g., cloud) where it is analyzed.
    The cost, relevance of the time of data to required actions, and communication
    barriers are some factors that determine the configuration of data processing.
    That being said, big data, collected from several IoT things, is most often stored
    and processed in the cloud. People – People are affected by the Internet of Things
    in at least two ways: as the agent of change who must work to make IoT function
    and as the beneficiary of its outcomes. Typically, people work in their own domain
    as a specialist at their job. With IoT, however, there is a much broader sense
    of interconnection between functions, and so people are increasingly finding themselves
    interacting with people in other business sectors. Sometimes this is a counterpart
    more or less with a similar function, or at a similar level, what we call horizontally
    located in the business, but other times it is a more vertical relationship, someone
    that operates at a lower or higher level. People must be interfacing in order
    to make sense of the data being collected and to determine the proper interpretation
    of the outcomes of the analysis of that data. Ultimately, it is people who create
    and maintain the Internet of Things, and their actions which can derive the most
    advantage from what IoT has to offer. The other side is the impact that the consumer
    sees from the IoT, meaning more informed decisions and targeted services from
    companies. People must also be aware of their personal data, who is collecting
    it and what is happening to it. Who owns this data? This is a question that has
    a complex and evolving answer. Process – The final component of the IoT ecosystem
    is process and that is where the benefits of intelligent automation, informed
    decision-making and control, and efficient procedures are realized. All of the
    methods, techniques, and processes currently used in vertical industries (e.g.,
    manufacturing, logistics) can be made more efficient with the right information
    at the right time. Analyzing the data gathered from sensors and delivering this
    information to the appropriate stakeholders is the main idea of the process of
    IoT. 1.1 Internet of Things Terms and Acronyms In this section, we review some
    fundamentals terms and explain how they relate to the Internet of Things. Machine
    to machine communication (M2M): M2M is network communication between devices using
    any channel. Originally, it was used in an industrial context, but has come to
    mean that communication used to transmit data to personal appliances. Internet
    of Things is also communications between devices, but is used to also refer to
    vertical software stacks that automate and manage communications between multiple
    devices, and therefore refers to communication on a larger scale. Table 1.1 highlights
    the key differences between IoT and M2M. Cyber-physical systems (CPS): The National
    Institute of Standards and Technology (NIST) has the following definition for
    CPS: “Cyber-Physical Systems comprise interacting digital, analog, physical and
    human components engineered for function through integrated physics and logic.
    These systems will provide the foundation of our critical infrastructure, form
    the basis of emerging and future smart services, and improve our quality of life
    in many areas.” Many manufacturing processes rely on cyber-physical systems as
    part of manufacturing. A cyber-physical system can also be found beyond manufacturing,
    for example, in the Smart Grid or in Smart Cities [8]. Internet of Everything:
    Cisco invented this term to mean the “people, process, data and things to make
    networked connections more relevant and valuable, turning information into actions’
    that improve everything.” This terminology was abandoned sometime in 2017. Social
    Internet of Things (SIoT): SIoT refers to an IoT in which things are able to create
    a network of social relationships with one another independent of human intervention.
    Objects are able to begin constructing social relationships based on the object’s
    profile, interests (i.e., applications deployed, services used), and activities
    (i.e., movements). These social relationships can also be organized around events
    causing their creation. For example, a co-work relationship can be created between
    objects that work together to generate a common IoT application, such as objects
    that cooperate with each other to provide telemedicine or emergency response.
    A parental relationship may exist between objects that have the same manufacturer,
    are of the same model, or were constructed within the same period because they
    are part of the same batch. Social relationships are created between objects that
    are in contact occasionally or continuously because the object owners are in contact,
    and a co-ownership relationship may be created between heterogeneous objects that
    are owned by the same user. Adoption of the SIoT model offers many advantages
    [9]: The social network created by the SIoT objects can be shaped as needed to
    ensure network navigability, the effective discovery of objects or services, and
    scalability similar to human social networks. Trustworthiness can be created to
    balance the level of interaction among objects that are friends. Models created
    to study social networks can be utilized to address IoT issues related to large
    networks of interconnected objects. Table 1.1 The key differences between IoT
    and M2M Full size table 1.2 Impact of IoT The estimated future impact of the Internet
    of Things is staggering. At the time of writing, it has been estimated that there
    are about 14 billion devices connected to the Internet. According to a Gartner
    forecast, it will go up to 25 billion by 2021. Cisco predicts that by 2020, that
    number will increase to 50 billion things. The government of the United Kingdom
    speculates twice that number, upward of 100 billion things. With this increased
    amount of connectivity, the way we interact with everyday objects will fundamentally
    shift. More of our choices can be driven by data instead of guesswork or habit.
    In our businesses, data-driven decision-making will prove more efficient and profitable.
    In our industries, processes and systems will be better managed and monitored,
    making us safer. Our quality of life will increase as these optimizations save
    us time, money, and energy. New services can be innovated from the data-rich environment,
    further improving our well-being. 1.3 Benefits of IoT An organization that embraces
    the Internet of Things can expect greater safety, comfort, and efficiency. Hazardous
    environments and workspaces can be more carefully measured and the dangers more
    readily managed. The increased information about working conditions allows for
    decisions to improve comfort and consequently productivity, for example, a more
    localized thermostat can show the differences in the temperatures in specific
    offices. Adjustments for only those occupied spaces in temperature or lighting
    can lead to controlled energy costs and greater efficiency. Monotonous tasks can
    be automated, reducing downtime and yielding faster, more accurate, and greater
    results. Leveraging benefits like these can make the workplace more rewarding,
    and that improves employee satisfaction and retention and ultimately improved
    profits and reduces the necessary investment incurred by employee turnaround.
    Organizations can also benefit from more information with which to make business
    decisions. Using large trends in empirical data means that fewer assumptions need
    to be made. It becomes possible to be more responsive to emerging trends. From
    a manufacturing standpoint, there is increased visibility into system behaviors.
    This can lead to shortened testing cycles and a more optimized production process.
    Revenue can also be increased or new streams can be realized by improving current
    procedures or making new ones from the increase in available information. IoT
    is a unique strategic advantage that early adopters will have over competitors
    who choose not to pursue digitalization. A few more benefits of IoT can be listed
    as below: Efficiency: More information about work/operation processes and rich
    data sets obtained from connected sensors leads to process streamlining. IoT enables
    great data sharing, and then manipulating the data as needed helps systems to
    work more efficiently and make smarter, more informed decisions in real time.
    Transparency: IoT digitizes every process and enables physical objects to remain
    connected, providing greater transparency. For example, IoT sensors can identify
    the status of the products in a production line or the location of assets in a
    field and track inventory and parcels. Automation and control: IoT enables the
    connection and digital control of physical objects, requiring extensive automation
    and control within the network. Without requiring human involvement, machines
    communicate with one another, resulting in more time-efficient output. Automation
    also ensures uniform completion of tasks and the quality of services provided.
    Human intervention may only be required in the case of an emergency. Accuracy:
    Monotonous tasks are automated, reducing downtime and errors. Monitoring: IoT
    provides the advantage of monitoring capabilities. Tracking supply quantities
    for business or monitoring the air quality of a home is easily accomplished and
    provides extensive information otherwise not easily obtained. For example, knowing
    that the printer is almost out of paper or that you are running low on coffee
    can enable a user to consolidate shopping and avoid extra trips to purchase supplies.
    In addition, monitoring product expiration dates provide increased safety. Information:
    Access to additional information enables improved decision-making in a diverse
    array of areas, from everyday decisions like choosing what to purchase at the
    market to determine if a business has enough inventory. In each situation more
    knowledge gives the user greater power. Time: The integration of IoT has the potential
    to save large amounts of time, which is valuable to everyone. Safety and comfort:
    It can be difficult to imagine managing and monitoring hazardous environments
    requiring the consideration of multiple factors including human safety and optimizing
    the environment for productivity and comfort. Mundane tasks can be automated resulting
    in energy savings. For example, smart assembly lines can operate without human
    intervention and report errors immediately, resulting in greater productivity
    and less downtime. Automating monotonous tasks would also enable employees to
    engage in more rewarding work, resulting in increased employee satisfaction/retention
    and wider profit margins. Security: Security sensors (e.g., camera) as well as
    location-based sensors (such as GPS) have a significant ability to enhance security.
    Cost/money: The greatest advantage of IoT is the amount of money saved. Fewer
    errors, higher employee retention, improved processes, and energy-efficient behavior
    all reduce costs. IoT will be more widely utilized as long as the cost of monitoring
    equipment is less than the potential cost savings. IoT integration is proving
    highly useful in daily life as appliances communicate with one another, conserving
    energy and reducing costs. Industry-specific view: IoT can revolutionize several
    industries, for instance: Targeted marketing: Greater information leads to individualized
    experiences, improving the interactions of customers with the company and bringing
    the company message to those more likely to become customers. Supply chain enhancements:
    Asset tracking and management, security, optimized logistics, and transport all
    reduce costs of lost inventory, waiting times, and inventory mismatches. Health:
    Individuals can get more information about their own bodies (heart rate, hours
    of sleep, etc.) to help in maintenance or identifying health problems. Smart building:
    Workplace temperature, lighting, and air quality feedback can ensure a pleasant
    working environment, increasing satisfaction and productivity. In terms of security,
    connected cameras can detect the presence of unauthorized individuals. 1.4 IoT
    Challenges Certainly, any changes bring not only benefits but also challenges
    that must be overcome. For any organization it is essential to determine which
    departments are responsible for which changes that must be made. Who will purchase
    and configure the needed IoT hardware (devices, gateways, etc.)? Who will install
    and run the needed software and troubleshoot the hardware and software? Who is
    responsible for networking? Which department will perform the analytics and deliver
    the reports and findings? There are also issues of what to do with legacy devices
    and other specialized solutions that will need to be found and addressed. Any
    potential solution must also be able to scale, to handle current needs but also
    those of the immediate future as the organization continues to adapt and grow.
    Through it all, ownership is necessary to maintain an adequate level of production
    quality, especially as several teams are usually called upon to work together.
    These are major issues that demand sound leadership in order to meet the challenges
    of implementing IoT for any organization. Other challenges are more technical
    in nature. First of all, scalability and heterogeneity are intrinsic parts of
    IoT, which should be addressed via appropriate technologies. In this context,
    the necessary technology standards must be developed or updated including the
    network protocols and data aggregation standards. As mentioned before, a new connection
    paradigm will be needed and possibly described by these new protocols. At every
    stage from gathering data, to transmitting it, to storing and analyzing it, interoperability
    must be considered. Cloud Services are nonstandardized and non-unified, meaning
    that changing providers could incur the undue expense. There is currently no consensus
    on machine to machine protocols, and existing equipment uses a variety of operating
    systems and firmware technology. The surest way to mitigate these differences
    is to move computing tasks to the edge of the cloud and take advantage of fog
    computing models and IoT hubs. This will leave the cloud servers and services
    to handle the analytical and processing tasks for which they are best suited.
    Business must be prepared to handle these challenges with adequate planning and
    a solid business model. The revenue and profits will provide the motivation to
    invest in IoT and expand into vertical markets, horizontal markets, and consumer
    markets. If done properly, a market bubble will be avoided as well as regulatory
    and legal battles. The final, and perhaps the most important, hurdle will be solving
    the issues associated with security. There have already been successful hacks,
    or unauthorized access to several devices on the Internet of Things. Since IoT
    will become a larger part of our daily lives, it should be obvious that the security
    of our sensitive information is becoming vital. Losing control of the radio in
    a car, or the transmissions of a baby monitor, or the home security cameras in
    a dwelling make for a frightening and compromising future. Controlling access
    to these and many other devices is a growing concern and is already being addressed.
    In summary, the main challenges of IoT can be listed as below: Scale: Connecting
    to billions of active connected IoT devices is a big challenge, and the current
    communication models and technologies should be adjusted to address scalability
    challenges. In this context, emerging IoT technologies such as decentralized IoT
    network (e.g., edge/fog computing), peer-to-peer communications, and blockchain
    can be helpful. Heterogeneity: IoT in its nature consists of a plethora of devices
    with different interfaces and communication protocols, and thus there is a necessity
    to form a common way to abstract the underlying heterogeneity. Privacy: All the
    collected data must be kept secure and anonymous when necessary. Data ownership:
    Who is the owner of machine-generated data (MGD)? The entity that owns the IoT
    device or the manufacturer of the device (e.g., in connected cars)? Cybersecurity:
    Defeating attackers who seek to control, steal, or mislead is vital. Legal liability:
    Who is responsible when something goes wrong with an algorithm or an automated
    decision? Sensors: Technically, sensors must be inexpensive, accurate, and energy
    efficient. Networks: Transferring data and commands must be secure, reliable (correct
    and timely), and robust, despite operating in a noisy, busy, dangerous, or harsh
    environment. Big data: Connected devices continuously and simultaneously generate
    large volume and different varieties/forms of data, and thus IoT should be able
    to address time, resources, and processing capabilities. Analysis: The data must
    be properly interpreted and analyzed with fidelity to its meaning, especially
    if automated actions are taken based on data outcomes. Interoperability: There
    is a fierce competition to lead this burgeoning field, and all players must work
    together to be functional and to protect investments and must do so with fairness
    and integrity. 1.5 IoT and Big Data Data coming from the Internet of Things is
    unlike data from the past in at least two important dimensions. First, the large
    amounts of data being generated demand a new data management approach. Traditional
    methods need to be adapted or entirely new approaches need to be discovered to
    handle diverse data constantly streaming from many sources. The second dimension
    is the nonuniformity of the data. Often the raw data is unstructured, or may come
    in several different formats, or may even change depending on the context. The
    new data management techniques must cope with these challenges. Up until now the
    discussion has been about big data without formally defining it. Big data is a
    large set of structured, unstructured, and semi-structured data and the results
    of analyzing that data to gain insights. Doug Laney defined big data as the three
    V’s (see Fig. 1.2): Volume – Storing large amounts of data. Velocity – The rate
    at which data is generated is high, so it must be stored or processed quickly.
    Variety – There are many possible formats of the data, from structured numeric
    to text, e-mails, video, audio, and so on. Fig. 1.2 The definition of big data
    Full size image Turning big data into tangible business insights is one of the
    major benefits of IoT. Most well-known approaches for dealing with IoT data include:
    Analyzing data: Before data becomes useful in making decisions, it must be analyzed.
    Traditional manual analytics, though powerful and informative, simply will not
    be practical in the face of the staggering amount of data that IoT will generate.
    Therefore, some automated analytics must be employed. These analytics need to
    provide descriptive reports of the environment, visualizations, dashboards, trigger
    alerts from data sources, and automated actions to be taken based on the data.
    They will also be used to detect patterns in the data, predict outcomes, and detect
    anomalies. There are open-source frameworks currently available for performing
    automated analytics. The two main approaches are to process the data in batches
    or to analyze the data as it is generated in real time. Which technique to use
    depends on the context of the problem as well as the resources available. The
    analytics can be run in a distributed fashion, also called in the cloud or at
    the edge, in servers nearer the sensors. First, the data is preprocessed, that
    is, duplicates are filtered out, and the data is possibly reordered, aggregated,
    and most likely normalized. These and other similar preprocessing tasks can be
    performed on the IoT device itself or on a gateway device before it is sent upstream.
    The most common automated analytics performed now are machine learning algorithms.
    Machine learning (ML): Traditional mathematical statistical models analyze data
    by fitting the data to a model. Then the model is used to make predictions. This
    is a difficult process to follow especially when the data is dynamic or has many
    variables or the important points of the data are unknown. Machine learning is
    an algorithmic approach where the important parameters are extracted from the
    data in a process called learning. The data itself provides the structure of the
    mathematical model. Machine learning techniques can be applied to historical data
    or data taken in real time. The main way to think of it is that machine learning
    finds patterns or relationships or key variables in data. The model that is learned
    can be updated over time as more data is collected. One of the important applications
    of machine learning in the context of IoT is about finding patterns in the data,
    so that anomalies can be found quickly. Traditionally, anomalies were detected
    when certain values crossed thresholds. Machine learning allows for more complex
    patterns in the data to be identified as anomalous, therefore increasing speed
    and accuracy in detecting problems. The machine-learning-driven intelligence in
    IoT can be used for predictive analytics (what will happen), prescriptive analytics
    (what should we do next), and adaptive or continuous analytics (how can we adapt
    to the latest changes). Edge analytics: When analytics is applied at the edge
    of the network close to the IoT devices that generate the input data, it is referred
    to as edge analytics. Since network traffic is reduced, this is an attractive
    approach to reduce bandwidth and the latency from data gathering to a useful result.
    One drawback is that more processing power is needed in the devices and close
    to them, and cost or the particulars of the environment or device may make this
    prohibitive. On the other hand, sending large amounts of data across a network
    into the cloud may also be too expensive. Often a hybrid of edge and upstream
    analytics in the cloud is used to mitigate these costs. Real-time analytics: Any
    time that data is collected and immediately analyzed is known as real-time analytics.
    This is the best choice when a delay in the results of the analysis would reduce
    the value of the data. Time series data, rolling metrics, running averages, and
    any other occasion where the window of time analysis needs to be controlled are
    also good candidates for real-time analytics. Some real-time analytics frameworks
    available include Apache Storm, Apache Spark, and Flink frameworks. Distributed
    analytics: When the data sets are particularly large, too large to be handled
    by a single node (server), then distributed analytics can be used. As the name
    implies, the analysis tasks can be broken up and spread out to several compute
    nodes, possibly across multiple databases. If the data allows, it could be bucketed
    by time period and thereby effectively split up in order to make it more manageable.
    This is also an example of batch processing. Hadoop provides an ecosystem of frameworks
    for performing analytics. Apache Hadoop is used for batch processing and uses
    the MapReduce engine to process distributed data. Hadoop is a good open-source
    framework and one of the first to become available. It is used successfully for
    historical data analytics. Data storage, besides the data processing, is another
    challenging issue in the era of big data. As more and more devices are connected
    to the Internet of Things, the amount of data they generate will drastically increase.
    They will be sending messages with their status, sensor outputs, metadata, and
    other messages. Despite the large amounts of data, it still must be stored. Two
    common methods are listed here, NoSQL databases and time series databases. Traditional
    techniques (SQL databases) are usually not feasible because of the amount of data
    being stored, with its varied and often unstructured nature. NoSQL databases offer
    high throughput and low latency of storage and retrieval. Since there is no schema,
    dynamic new data types are allowed. Couch Base, Apache Cassandra, Apache Couched,
    MongoDB, and Apache HBase (Hadoop) are examples of frameworks that use NoSQL.
    There is also a NoSQL in the cloud solution offered by IBM’s Cloudant (a distributed
    database) and AWS’ DynamoDB. A time series database can also be a NoSQL database
    or even a relational database. The indexing and queries are all based on timestamps
    in the data. Some frameworks using time series databases are InfluxDB, Prometheus,
    and Graphite. 1.6 IoT and Cloud Computing The two worlds of IoT and Cloud experienced
    swift and independent progress. However, the complementary features of IoT and
    big data generated many new opportunities and advantages. Cloud computing is the
    solution to the increased demand for storage and processing. The cloud is defined
    as a group of servers and computers connected over the Internet in a large, distributed
    infrastructure. The concept is to deliver on-demand services over the Internet.
    The model is typically based on pay for the usage consumed (metered service),
    with the ability to scale up and down as needed (elastic resources). Amazon, Microsoft,
    and Google are dominating this Infrastructure as a Service (IaaS). They also provide
    Platform as a Service (PaaS) and Software as a Service (SaaS). The advantage to
    consumers is a lowered computation cost versus purchasing the hardware and then
    paying to operate and support it in-house. In summary, the main drivers for integration
    of IoT and Cloud are listed below [10]: Device lifecycle management: As the Internet
    of Things grows in size, the number of devices that need to be registered, managed,
    and updated while maintaining security requirements also grows and must be accommodated.
    It is possible for tools to configure and update firmware and software over the
    air (FOTA). The cloud platforms enable device lifecycle management, so devices
    can be connected, registered, on-boarded, updated remotely, and even remotely
    diagnosed should something need to be fixed. This reduces the operation and support
    cost of the devices. That means the enterprise Internet of Things is remotely
    managed, with minimal time and a reduced cost of ownership. In other words, a
    360-degree view of the IoT devices is possible via the cloud. Communication: Cloud
    platform can be leveraged with the help of IoT to deliver scalable domain-independent
    services by providing appropriate service-oriented domain mediators. Resource
    pooling: Physical resources of IoT can be integrated into the cloud resource pool
    enabling us to allocate and share them on demand like regular Infrastructure as
    a Service (IaaS). Storage: IoT drives a real tsunami of big characterized by volume,
    variety, and velocity. In this context, IoT benefits from large-scale and long-lived
    storage of the cloud. Computation: Data processing is typically a very resource-hungry
    task. Therefore, IoT can benefit from virtually unlimited processing resource
    of cloud to aggregate data and execute batch and/or real-time analytics on the
    collected data. Device shadowing or digital twin: Another benefit available through
    cloud computing is device shadowing. The concept here is to have a backup of running
    applications and devices also running in the cloud. Any time there is a fault
    or failure in the original device or application; the twin can be examined to
    extract the result or to help in diagnosing the problem. System availability can
    be increased by using the digital twin as software redundancy. If the original
    system needs to be taken offline for maintenance, the twin can continue the operation
    uninterrupted; it can also provide system behavior statistics and behavior profiles
    for the original system at decreased risk. 1.7 IoT and Digitalization Gartner
    defines “digitalization” as leveraging digital technologies to change business
    models and provide new revenue and value-producing opportunities. The process
    of updating a business to digital technologies is an evolutionary one and indeed
    has been happening for decades. The process is enabled by increased interoperability,
    information transparency across departments and industries, automated assistance
    and support, and a trend toward decentralized decision-making. In this context,
    IoT is considered as the major pillar for digitalization. The other important
    pillars are blockchain, big data, and machine learning. 1.8 IoT and Industry 4.0
    The phrase “Industry 4.0” is rooted in a high-tech, German government research
    and development project in the manufacturing industry. It was initially coined
    at the Hannover Fair in 2011. Although there is some difference of opinion around
    the definition of historical industrial revolutions, Industry 4.0 is considered
    as the fourth industrial revolution. The initial industrial revolution occurred
    in the late 1800s and is responsible for mechanizing the power of steam and water.
    The second industrial revolution began in the early 1900s and was characterized
    by the use of electricity to drive mass production through assembly lines and
    a reorganization of labor. The 1970s brought the third industrial revolution which
    utilized computers to automate production and processes. It is predicted that
    the coming fourth industrial revolution will fully utilize digital manufacturing
    in smart factories. Industry 4.0 is propelled by the merging of technologies such
    as: Industrial Internet of Things (IIoT) and extensive sensor use Analytics and
    big data Machine learning and artificial intelligence (AI) The convergence of
    IT/OT Augmented reality (AR) Advanced robotics Additive manufacturing Benefits
    of Industry 4.0 Industry 4.0 will generate benefits in many areas. Product development
    will move more quickly due to analytics, and original equipment manufacturers
    (OEMs) will utilize analytics to understand better how consumers actually use
    products compared to a product’s anticipated use. Sensor data will be used to
    optimize production through constant status updates that are compared to a digital
    twin (i.e., a perfectly efficient simulation which creates a virtual and digital
    replica of the target physical product/entity or process) to predict the physical
    counterpart’s performance characteristics and guide corrective action and predictive
    maintenance needs. Additive manufacturing will become highly profitable based
    on highly flexible, small production capabilities. Augmented reality will drive
    learning and efficiency, and machines will assist humans with dangerous or complicated
    tasks as they gain autonomy. Many of these technological advancements are already
    occurring on a smaller scale. However, the guiding vision of Industry 4.0 is to
    revolutionize manufacturing and its connected industries. The main goal of the
    Industry 4.0 vision is to help manufacturing and its connected industries to evolve
    away from a logistics or end product focus. This revolution seeks to help these
    fields move toward an efficient customer-responsive business model that generates
    innovative revenue sources. Industry 4.0 also has the potential to revolutionize
    cities and utilities on a larger scale. Industrial IoT The Industrial Internet
    of Things (IIoT) uses actuators and sensors to improve industrial and manufacturing
    processes. The IIoT is vital in many industries such as oil and gas, logistics,
    manufacturing, energy/utilities, transportation, resource mining, and aviation
    as well as other industrial fields or use cases common to these industries. However,
    there are some companies and professional researchers who consider Industry 4.0
    and IIoT to be equivalent. 2 Architectures and Reference Models of IoT: A Layard
    View 2.1 IoTWF Reference Model of IoT There are several standardizations in the
    IoT ecosystem. The IoT World Forum (IoTWF) is an exclusive annual industry event
    hosted by Cisco. As an outcome of their collaboration, they published a Standardized
    Architecture in 2014. The committee was comprised of Cisco, IBM, Rockwell Automation,
    and others. The proposed IoT Architecture is a seven-layer reference model, with
    control originating from the center (e.g., cloud) to the endpoint devices. Generally,
    data is gathered at the endpoint devices and is sent toward the center. The central
    processing can, in fact, be decentralized and implemented as a cloud service.
    The purpose of such a model is to give a common understanding of how the problem
    of creating IoT can be divided. With the different goals of each layer identified,
    and the interfaces specified, different companies can contribute pieces that will
    interoperate. Security can also be enforced at each layer of the model. These
    seven layers include (see Fig. 1.3) [11]: 1. Physical devices and controllers
    (things) – These are the physical devices, sensors, actuators, and controllers
    that form the Internet of Things. Their primary function is to collect data to
    transmit upstream, but they should also be capable of receiving commands, e.g.,
    power down, etc. 2. Connectivity (networking) – This is the layer that serves
    as the medium to bring the sensor data from the devices to the upper layers where
    that data is cleaned and analyzed. The chief responsibility here is for reliable,
    secure, and timely delivery of data. This includes any switching or routing that
    is necessary as well as translation between protocols if necessary. 3. Edge computing
    (data element analysis and transformation) – This is also known as the fog layer
    because it is the layer where data cleaning, aggregation, and processing begin.
    It is the responsibility of this stage to prepare the data for analysis and storage.
    One of the methods to mitigate the enormous data flows is to start the analysis
    as early as possible. Data is evaluated, possibly reformatted or reordered, filtered,
    and checked for warning thresholds. Edge/fog computing facilitates data processing,
    data storage, and networking services between endpoint IoT devices and the center
    (e.g., cloud or data centers). The key idea of edge/fog is to process the data
    and make actions closer to where the data is created. This can ultimately result
    in reducing the traffic between IoT devices and real-time actions (i.e., respond
    fasters to events). 4. Data accumulation (storage) – This is the layer which prepares
    data to be stored in a database, whatever that format is. The key here is that
    after this layer, the data is expected to be able to be retrieved based on queries.
    5. Data abstraction (aggregation and access) – Another layer that deals with the
    data. At this layer, the data is consistent, complete, and validated. In practice,
    data is often stored across multiple databases; the task of this layer is to ensure
    that the data is able to be queried and a unified, reliable result is returned.
    6. Application (reporting, analytics, control) – This is where individual software
    applications can query the data to perform specific functions, such as reporting,
    monitoring, control of devices, visualizations, and analytics. 7. Collaboration
    and processes (involves people and business processes) – This is the layer that
    makes use of the outputs from the software applications of the previous layer.
    Data and conclusions from that data are shared with other entities or applications.
    The collaboration of several data sources illuminates new business practices,
    makes existing processes more efficient, and opens the doors to innovation. This
    is where the benefits of the Internet of Things are largely realized. Fig. 1.3
    IoT reference model by IoTWF Full size image 2.2 Simplified Reference Model of
    IoT A simplified IoT architecture is comprised of the following layers (see Fig.
    1.4) [12, 13]: IoT Things Layer – Consists of all IoT sensors and actuators. IoT
    Network Layer – Includes network components such as IoT gateways, switches, and
    routers responsible for transmitting data in a timely and dependable fashion.
    This layer also includes fog/edge nodes to perform data analysis and transformation
    and information processing as quickly and closely to the things as possible. This
    is very helpful in real-time applications such as IoT healthcare to be able to
    provide low-latency and faster responses to emergencies. IoT Cloud and Application
    Layer – Manages and processes IoT devices, as well as data created by the other
    two layers. It is also responsible for data ingestion, data interpretation through
    software applications, as well as integration with other platforms to improve
    business value. Fig. 1.4 Simplified IoT architecture Full size image 3 IoT Frameworks
    and Platforms 3.1 FIWARE FIWARE is funded by the European Union (EU) to be an
    open-source middleware platform. This means that it specifies interfaces for application
    programmer interfaces, allowing anyone to be able to connect devices to a catalog
    hosted in the cloud. The idea is to simplify the task of integrating devices into
    IoT and enable an economy based on data. Since it is a standard, it relies on
    participation and adoption, but the promise of interoperability is real and appealing.
    To that end there is an active and well-funded community surrounding the platform
    and encouraging participation [14]. 3.2 SmartThings SmartThings is a cloud-based
    platform offered by Samsung that focusses on building and running an IoT-driven
    smart home. The application management system is used to process subscriptions
    from device type handlers. Over 300 different devices are supported in the system,
    to allow the user control over objects in the home. From dimmer switches to sensors
    and alarm systems, SmartThings offers integration of varied devices with third-party
    assistants such as those produced by Amazon or Google. The system can increase
    security and convenience in any home by providing a common connection and integration
    of devices found there. 3.3 AWS IoT With Amazon Web Services (AWS) IoT, Amazon
    offers a managed, cloud-based solution. Platforms and software are all offered
    as a service, with the ability to scale and use its analytics tool on IoT data.
    Things can be registered as devices, and the architecture features a Message Broker,
    Thing Registry, Thing Shadows (Digital Twins), and Rules Engine in addition to
    Security and Identity components. AWS is aimed at home users as well as industrial
    users with its mix of device software, control, and data services. Amazon machine
    learning provides analytics and visualization tools as a service. Users can make
    use of the same technology used by Amazon data scientists internally, but with
    a friendlier wizard-style interface to begin. Getting started building and performing
    IoT tasks or data science functions are painless. The services scale as your needs
    or businesses grow, and stopping is just easy since no capital investment is required
    [15]. 3.4 Microsoft Azure IoT The Azure Internet of Things (IoT) is a collection
    of services that is capable of connecting, controlling, and tracking billions
    of IoT devices. Available services in Microsoft IoT include [16]: Azure Internet
    of Things (IoT) Hub Azure IoT Edge Azure Stream Analytics Azure Machine Learning
    Azure Logic Apps 3.4.1 Azure Internet of Things (IoT) Hub The Azure IoT hub is
    a cloud-hosted service that functions as a centralized, bidirectional message
    hub for an IoT application and its connected devices. It can be used to build
    dependable and secure communications among millions of IoT devices and back-end
    solutions hosted by the cloud. Almost any device can be virtually connected to
    the IoT hub, which supports communication coming from the device to the cloud
    and vice versa. IoT hub is able to support different message patterns used to
    manage devices including file uploads from devices, device-to-cloud telemetry,
    and request-reply methods. IoT hub monitoring is useful for supporting solution
    health because it monitors events including device connections, failures, and
    connections. The IoT hub provides a secure channel for devices to communicate
    and send data [16]: Individual device authentication allows each device to connect
    to the hub securely and to be controlled securely. The IoT hub provides total
    control over device access and can manage each per-device connections. When a
    device initially boots up, the IoT Hub Device Provisioning Service automatically
    provisions devices to the correct IoT hub. Various device capabilities are supported
    by multiple authentication types: SAS Token-Based Authentication Individual X.509
    Certificate Authentication The X.509 CA Authentication IOT hub connects devices
    using the following protocols: AMQP, AMQP over WebSocket, HTTPS, MQTT, MQTT over
    WebSocket IoT hub also includes built-in message routing which provides the flexibility
    to create a rules-based, automated message fan-out. Additionally, the IoT hub
    can be combined with additional Azure services to create comprehensive solutions
    such as: Azure Logic Applications – Business process automation Azure Machine
    Learning – Adds AI models and machine learning to solutions Azure Stream Analytics
    – Provides real-time data analytics on data streaming from devices There are two
    available Software Development Kit (SDK) categories used with the IoT hub: IoT
    Hub Device SDKs – Allow one to create IoT applications to be executed on IoT devices.
    These applications can send telemetry to the IoT hub and include the option to
    receive messages, method, job, or updates from the hub. Compatible languages include
    Python, Node.js, Java, C#, and C/C++. IoT Hub Services SDKs – Allow a developer
    to create back-end applications that manage the hub and schedule jobs, send messages,
    invoke other functions, or send updates to IoT modules or devices. 3.4.2 Azure
    IoT Edge Edge enables an organization to focus on business insights rather than
    focusing on data management by transferring cloud analytics and some business
    logic from cloud to edge. Azure IoT Edge has three main components (see Fig. 1.5)
    [16]: IoT Edge Modules – These are the fundamental execution units that run the
    business logic of the system at the edge. These modules are implemented as Docker-compatible
    containers. There is a possibility to create more complex data processing pipeline
    by connecting several containers to each other. IoT Edge allows you to create
    custom modules or bundle different Azure services into modules able to extract
    insights from IoT data offline at the edge. IoT Edge Runtime – It is located in
    the edge and provides cloud and custom business logic for IoT Edge. In addition,
    it performs communication and management operations including: Manages workload
    installation and updates Manages Azure IoT Edge Security Standards Ensures IoT
    Edge Modules are running Monitors and reports module health remotely Manages communication
    and handles communication between downstream endpoint IoT devices and IoT Edge,
    between modules, and between the cloud and IoT Edge devices IoT Cloud Interface
    – It sits in the cloud and allows remote management and monitoring of IoT Edge
    devices from the cloud. Fig. 1.5 The architecture of Azure IoT Edge Full size
    image 3.4.3 Azure Stream Analytics As an event-processing engine, Azure Stream
    Analytics enables you to monitor large-volume streaming data coming from IoT devices
    as well as data from social media feeds, applications, web sites, etc. You can
    also use Azure Stream Analytics to visualize relationships and find patterns in
    streaming data. Once identified, data patterns can be used to drive downstream
    actions like sending information to reporting tools, storing data, or creating
    data alerts [16]. Azure Stream Analytics utilizes a source of streaming data that
    is ingested into the Azure IoT hub, Azure event hub, or from Azure storage. To
    evaluate the data streams, you must create an analytics job that identifies the
    input data stream source and uses a transformation query to determine how to search
    for data relationships or patterns. When analyzing incoming data is done, you
    are able to identify the desired output and then determine how to respond to the
    analyzed information. For example, you can take follow-up actions including: Trigger
    Alerts/Customized Workflows – Triggers a specific process or function in response
    to an input pattern. Visualize Data – Data is sent to a Power BI (a business intelligence
    framework) dashboard to allow real-time data visualization. Store Data – Utilizes
    Azure storage system to store the data; therefore, you can perform batch analytics
    or train holistic machine learning models based on historical data. 3.4.4 Azure
    Machine Learning Azure Machine Learning is a cloud-based service supportive of
    open-source technology and useful for large-scale training, deploying, automating,
    and managing machine learning models. Azure Machine Learning enables the user
    to access thousands of open-source Python packages that include machine learning
    components such as PyTorch, Scikit-learn, and TensorFlow. Microsoft also offers
    another framework called Azure Machine Learning Studio, a drag-and-drop, a collaborative
    area that allows you to create, test, and deploy machine learning solutions without
    writing code. This workspace also provides preconfigured and pre-built algorithms
    as well as data management modules that make experimenting with machine learning
    modules quick and uncomplicated. Azure Machine Learning Service is beneficial
    instead of Azure Machine Learning Studio, when greater control over the details
    of the machine learning algorithms is needed or you need the flexibility to utilize
    open-source machine learning libraries [16]. 3.4.5 Azure Logic Apps Azure Logic
    Apps is a cloud service used to arrange or automate tasks, workflow, or business
    processes when data, applications, systems, or services must be integrated across
    large enterprises. One of the main benefits of Azure Logic Apps is that it makes
    the designing and implementation of scalable data integration, applications, and
    other system solutions including business-to-business (B2B) communication within
    the cloud or on premises (or both) easier and more straightforward. Below you
    will find examples of workloads that is possible to automate using Azure Logic
    Apps [16]: Event Processing – Events can be processed and routed across cloud
    services and on-premises systems. Email Notification – Email notification can
    be automatically sent via Office 365 when an event occurs in an app, service,
    or system. File Transfer – Uploaded files can be transferred from FTP or SFTP
    servers to Azure storage. Tweet Monitoring – Tweets can be reviewed by subject
    or analyzed based on sentiment and alerts or tasks can be created if the additional
    inspection is required. 4 IoT Applications in Vertical Markets There are many
    areas where the Internet of Things will have a major impact. What follows is a
    sampling and a brief discussion of some of these IoT application areas. 4.1 Smart
    Agriculture Also known as precision farming, since the power of data is brought
    to bear on agricultural decisions, instead of the traditional wisdom and guesswork.
    Smart Greenhouses: An IoT-enabled greenhouse will allow for the finer automation
    and control of environmental parameters. As expected, all aspects of the greenhouse
    can be monitored and recorded, including temperature, sunlight, air quality, humidity,
    and air flow. Adjustments to the environment can be recommended or automatically
    carried out depending on the recommendations of cloud servers. Livestock Monitoring:
    Cattle and other livestock can be monitored with IoT sensors to determine their
    location and vital signs to determine their health. Those animals with warning
    signs of sickness can be identified, quarantined to protect the others, and treated
    to overcome the sickness. This process saves on labor costs, improves the health
    of the overall herd, and reduces the risk to the animals and farmers. Agricultural
    Drones: In addition to placing sensors at key points, farmers can use airborne
    drones to monitor much larger and widespread areas. These drones can be recruited
    to plant seeds, spray existing crops, take soil samples, assess the health of
    crops, or even monitor fields or assets for security purposes simply. Historical
    records of crops can be more easily kept with drones assisting. They could also
    be used for integrated GIS mapping and visualization. All of these data points
    can ease the burdens on farmers, saving time and money and potentially increasing
    the agricultural output of the farm. As an example of IoT in agriculture, we can
    name Cropx company. This company installs sensors to understand better water usage
    in fields growing crops. The data are used to conserve better and utilize irrigation.
    The company also advises on the type and use of pesticides and fertilizers to
    maximize the yields of crops. They do this by collecting data on soil, air quality,
    crop maturity, and even weather and then using algorithms and machine learning
    techniques to determine when and where to intervene. 4.2 Logistics and Transportation
    Logistics is all about moving items from one place to another. Warehouses are
    used to store the items temporarily until they can be loaded onto vehicles and
    moved further along toward their destination. The vehicles use the transportation
    network to maneuver between endpoints and warehouses. Generally, suppliers are
    the ones that dispatch these vehicles to deliver the items to customer locations.
    To succeed at logistics, it is important to reliably, safely, and predictably
    deliver items from suppliers to customers. All stakeholders also want to know
    the status and position of the items in the transportation network and to be able
    to forecast how long it will take to receive these items through borders, customs,
    or other checkpoints. This means that a quality logistics operation has mastery
    over the capacity of each stage in the transport and can optimize vehicle routes
    between endpoints in an energy-efficient and proactive manner. IoT can assist
    with all of these goals, from real-time traffic and environmental conditions for
    vehicles, to real-time monitoring of vehicle and warehouse capacity, to sensors
    to locate and verify that items are in good condition and route. The value of
    items is linked to the length of time they are in transit, so minimizing risk
    in damage or delay is another prime concern, and another one that can be addressed
    with the data that IoT delivers. The vehicle fleet itself can also be monitored
    to ensure that timely maintenance is being done, increasing its availability and
    longevity. Fuel and time can be saved by re-routing around bad weather or accidents,
    and theft and loss can be prevented and stopped with cargo validation and monitoring.
    There may be other business innovation opportunities when the IoT is fully leveraged
    in this field. A few more uses cases of IoT in logistics/transportation are shown
    in Fig. 1.6. Fig. 1.6 A few use cases of IoT in logistics Full size image 4.3
    Smart Grid The traditional power grid consists of monolithic power generation
    plants that deliver electricity across transmission lines to power substations
    where electricity is distributed to customers via distribution lines. The customers
    had meters to record the use of the electricity, and these meters needed to be
    visited to be read. The next generation of power grid adds intelligence at the
    customer end by making those meters able to communicate their readings back to
    the power company. Further, with advanced metering, they can be updated in real-time
    to reflect changing tariffs on power based on loading and time factors. Demand
    can be better understood making power generation timelier and more efficient.
    Energy spikes, equipment failure, and power failures can be detected more quickly
    with smart sensors and the response can be more rapid with the automatic dispatch
    of engineers or even an automated restoration. Power outages and interruptions
    cost several billion dollars every year, so finding solutions to reduce and eliminate
    the occurrences improves quality of life and makes financial sense. Generators
    of electricity can better understand where, how, and how much electricity is used
    on the grid, enabling them to be more adaptive and responsive. Especially as the
    move is toward renewable energy sources and decentralization of electricity generation,
    smart technologies are vital to unlocking wind, solar, and tidal power to its
    full potential. On the consumer side, understanding when and how electricity in
    the home is used can lead to better choices. Home automation can activate appliances
    during off-peak times, and thermostats can control home heating and cooling depending
    on the time of day and occupancy to maximize comfort and energy savings. Electric
    vehicles can serve as power storage for a smart grid, or a micro-grid for the
    neighborhood, being charged during off-peak times, and returning power to the
    grid during the times of highest demand. To address the above challenges, research
    and development to design IoT-driven power grid as a robust, reliable, and secure
    infrastructure is critical to the future of technological advances, since it powers
    all the other technologies. 4.4 Smart Building Large buildings are currently outfitted
    with proprietary solutions to assist in solving the problems faced by facilities
    managers. They need information about how the building is functioning, the heating,
    ventilation and air conditioning system, the boilers, the power, the security
    system, and many other systems and subsystems that make up a modern building.
    While some management systems do a good job, they are often difficult to integrate
    with other solutions. Since they are often hardware based, once they become obsolete,
    it can be costly to update them, making them inflexible. Legacy buildings are
    a significant contributor to the increase in greenhouse gases in the atmosphere,
    with some estimates as high as 36 percent of CO2. Forty percent of total energy
    consumption is from the maintenance of buildings, with as much as 75 percent of
    current structures being inefficient. In 2016, the Paris Climate Agreement specifically
    targeted reducing the high energy consumption of buildings as an excellent method
    for addressing climate change. IoT will bring greater interoperability to these
    older, disparate systems and, through the cloud, allow for greater remote management,
    improving efficiency and response time. The sensors in an IoT-enabled building
    can collect the traditional information but also many other pieces of information
    not currently monitored, like air quality and occupancy. Using this data, building
    services could be improved to make occupants more comfortable and safer and also
    to use less energy. Workers who have greater peace of mind are able to concentrate
    better and be more productive. A smart building can offer this increased comfort
    with targeting thermostats to maintain more consistent temperatures. This results
    in more employee satisfaction, but also in a reduction in facilities calls to
    come and adjust the thermostat. Smart lighting can adjust light levels based on
    time of day and the presence of people needing that light, resulting in added
    savings. As systems change and adapt, software-based solutions will more easily
    adapt to them. The output of the sensors and detectors can be collected and visualized
    for facilities managers, to improve maintenance timing and effectiveness. Several
    companies are working for IoT-integrated solutions for the smart building, including
    Intel. A case study in the possible energy conservation is that of a conference
    room. These rooms are important locations for productive meetings and a valuable
    space in which to work, but whether they are actually being used or not, traditionally
    they receive HVAC services. Intel performed a study using its smart building product
    and showed in its report that it was able to save 4 percent on HVAC costs in conference
    rooms in its subject building. With LED lighting and occupancy detection, it was
    able to reduce lighting wattage used per square foot from 1.09 to 0.39. Through
    analyzing other data points, there is room to innovate other cost savings in offices
    and shared spaces in buildings. Power companies incentivize customers to reduce
    consumption during peak times by offering lower rates or credits called Automated
    Demand Response. IoT-driven smart buildings can take advantage of this by knowing
    the current building power usage and the grid rates and adjusting the load accordingly.
    There may be some load devices whose use can be delayed until an off-peak time,
    for example. If more power is demanded, then solar panels on the building, batteries
    or fuel cells in the building, or even a local power generator (diesel perhaps)
    could be utilized to make up the shortfall. This process can be automated via
    IoT solutions to optimize the cost of power to the building. 4.5 Smart Factory
    Like IoT and other emerging technologies, there is not a unique and universally
    accepted definition for smart factory. However, smart manufacturing or smart factories
    can be explained by their main characteristics and core contributing technologies
    such as IoT, machine learning, 3D printing, cyber-physical system, robotics, big
    data, and blockchain. In the context of IoT, smart factories are manufacturing
    plants that incorporate IoT technologies into their processes to improve and optimize
    each and every aspect of the factory. 4.5.1 Current Manufacturing Model The current
    manufacturing automation is based on a hierarchical architecture consisting of
    the following layers: Level 1: Sensor and Actuator Layer – This is the base level
    where the devices, sensors, and actuators exist on the plant/shop floor to perform
    different manufacturing process. This layer is a part of Operational Technology
    (OT). Level 2: Field Automation Layer – This layer (mostly based on PLC: Programmable
    Logic Controller) monitors and controls the devices that are attached to. This
    layer is also a part of Operational Technology. Level 3: Supervisory and Integration
    Layer – This layer mainly addresses supervisory control of the whole production
    process in the shop floor, shop floor monitoring, data acquisition, and data storage.
    It also functions as a multi-protocol intermediate gateway between the underlying
    industrial systems and the upper enterprise systems. This layer is usually implemented
    by Manufacturing Executive Systems (MESs), and Supervisory Control and Data Acquisition
    systems (SCADA). Level 3 is also a part of Operational Technology. Level 4: Enterprise
    Layer – Finally, decisions at this level concern the business planning, customer
    orders, material acquisition, and administration. Note that this layer is classified
    as an Information Technology (IT) layer. Three important points should be noted
    here. The first point is that the above layers sometimes melt into each other
    in a way that some functions can be implemented at multiple levels. Second, many
    existing factories have not integrated the integration of Information Technology
    (Layer 4) with Operational Technology (Layer 1–3) yet. The third point is that
    the above model is rigidly structured to some extent, meaning that in the first
    two layers, there is almost a strict master-slave communication paradigm, with
    the master taking charge. According to Industry 4.0, the above model can be evolved
    toward a more decentralized model, allowing for more autonomy. In Industry 4.0,
    the decentralization allows for more flexibility, self-governance, self-organization,
    self-maintenance and self-repair. These are all goals of smart manufacturing,
    and is not surprising as Industry 4.0 is a much more recent standard. 4.5.2 Potential
    Use Cases Here are the most popular IoT applications that are reshaping manufacturing
    and factories: Operating Efficiency IoT-based smart factories are more responsive
    to changes in the environment and armed with more detailed and timely data are
    poised to proactively address potential problems or events as soon as they occur
    or even before they occur. In addition, traditional manufacturing plants depend
    on the skill and training of the operators and technicians to produce their output.
    For decades, manufacturing has worked to increase the amount of automation in
    the process. Some benefits were realized, but often new technicians were needed
    to ensure the automation was working optimally. The Internet of Things should
    improve this situation as automation can be better monitored and controlled. A
    networked control system can sense, visualize and control every aspect of the
    manufacturing process even remotely. The smart factory can deliver a cost-effective,
    efficient, sustainable, and safe manufacturing system. Real-Time Quality Control
    Manufacturing business success is dependent upon a rigorous inspection process
    applied across each production phase. IoT enables manufacturers to program equipment
    and utilize big data analytic frameworks within factories to effectively monitor
    the manufacturing line, equipment, raw materials quality, and the quality of completed
    products at each point in the manufacturing process. Integrating IoT in this manner
    provides the following benefits to the quality control process: Enabling real-time
    action in alignment with the manufacturing process Optimizing in-process manufacturing
    using production engineering insights Continuous adaptation and learning based
    on production output Continuous optimization to address process drift or production
    variance Predictive Maintenance The ability to predict difficulties or perform
    predictive maintenance is an advantage with increased uptime and safety. Predictive
    maintenance is repairing or replacing equipment or components before predicted
    failures. Traditionally, historical mean time between failure data was used to
    schedule this maintenance, but with more accurate and timely data from IoT devices,
    a more specific time can be found, meaning good parts are not replaced, or unexpected
    weaknesses can be located and addressed before catastrophic failure. Of course,
    the data must be analyzed to extract these benefits, using machine learning and
    other data analytics techniques as mentioned earlier. Safety Employee safety is
    another area that can be improved with IoT devices. Workers can be observed to
    find lapses in focus or other mistakes, and preventative action can be taken.
    With increased knowledge of activities on the floor, should there be a problem,
    help can be dispatched more quickly and accurately. When all activities are analyzed,
    it is possible to discover new processes or methods to use during the manufacturing
    itself. There is the potential to improve efficiency with these process ideas
    or with real-time solutions as situations develop in the plant. Supply Chain Management
    IoT can help with supply chain management, as sensors track and help manage the
    location and condition of inventory, management can better plan, and schedules
    can be adjusted to optimize output. In addition to sensors, IoT devices can be
    used directly for automation. Integrating robotics can improve worker safety and
    factory throughput and reduce costs by increasing efficiency. Machine as a Service
    (MaaS) This approach will allow updated machines to be deployed from the cloud,
    with remote configuration, connectivity, and monitoring. Services such as these
    will allow for 100% uptime and zero-touch deployment, two desirable goals for
    manufacturers. IT/OT Convergence Since the 1970s, there has been an increase in
    automation in the manufacturing sector. This trend continues as operational technology
    (OT) and information technology (IT) converge with programmable logic controllers,
    computers, networking, and connected devices and sensors. IoT brings manufacturing
    technology and enterprise networks together, eliminating technological silos.
    These improvements will lower costs with scaled, automated, and platform-based
    machine connectivity that will increase monitoring and optimization. It can be
    claimed that the main driving factor in IIoT and IoT in the manufacturing industry
    is the convergence of IT/OT. There are two terms that must be understood before
    discussing the convergence of IT/OT: Information Technology (IT) – Using computers,
    hardware/software, and other telecommunications devices to complete business operations.
    IT is mainly linked with the back-end functions required to handle operations
    including billing, resource planning, asset monitoring, accounts receivable/payable,
    and maintaining client information. Operational Technology (OT) – The foundation
    of modern smart factories. Manages infrastructures powering manufacturing plants
    and ensures factory lines keep running. The value of OT is amplified as additional
    machines or components are connected. IT/OT convergence means operational technologies
    such as meters, sensors, programmable logic controllers, and SCADA are integrated
    to work together in near real time or real time with IT systems. The fields of
    OT and IT have existed side by side since the beginning of modern manufacturing.
    However, they have been siloed, with minimal interaction, resulting in a lack
    of understanding about how individual departments fit into the manufacturing process.
    Before IT/OT convergence, data sharing among departments was guided by the calendar,
    but the birth of the IIoT has vastly reduced the gap between IT and OT. Therefore,
    in a post-integration era, both IT and OT can share data in real time. There are
    several main benefits to IT/OT convergence, including agility, performance, productivity,
    cost, and agility. Combining IT and OT generates a complete picture of operational
    improvement opportunities and challenges facing manufacturers. This increased
    transparency helps IT and OT teams to better define their roles in light of a
    clearer team goal or purpose. Cost: The benefit that most often overlies both
    IT and OT departments is cost. In the area of IT, the cost is tied to predicting
    or illustrating profitability while the cost is generally linked to reducing production
    expenses in the area of OT. In both departments, reducing costs is good for the
    organization’s profit margin. Performance and productivity: The benefits of improved
    performance and productivity are connected. Businesses can enable IT and OT to
    collaborate through a common platform to create accurate key performance indicators
    (KPIs) that equip both departments to work toward common goals together while
    improving company-wide visibility. Agility: When an organization does a better
    job of controlling costs and analyzing KPIs, it is better able to act with agility
    to reduce production time and make space for innovation, which was a highly difficult
    task in a siloed IT/OT environment. 4.5.3 Major Challenges There is the perception
    of several barriers that must be overcome in order to evolve manufacturing plants
    to smart factories. A recent survey of manufacturing executives by Cisco ranked
    these problems for IoT in manufacturing, starting from the most serious [17]:
    Lack of supply chain visibility Lack of visibility of plant floor KPIs Inability
    to access data within production Lack of common metrics across plants Plant floor
    IT apps in silos Employee skills gap The complexity of manufacturing operations
    Inflexible automation Lack of understanding the plant floor Lack of reliable plant
    floor network The process not automated (manual) Lack of clear manufacturing strategy
    Unable to justify return on investment (ROI) Insufficient investment to modernize
    Security threat or fear 4.6 Smart City People have lived in cities for centuries,
    but only relatively recently, the mass migration from rural areas to cities has
    intensified worldwide. In 1950, less than one-third of the world’s population
    lived in cities; that fraction is expected to increase to two-thirds by 2050.
    In raw numbers, that was fewer than 1 billion people, to upward of 4 billion people.
    As these populations increase, it puts tremendous pressure on the local environment.
    The amount of energy consumed, the amounts of food and products that must be brought
    into the city, and waste that must be removed strain the transportation system
    and the city itself. The world’s cities use 60–80% of the energy used in the world.
    They also contribute the most to greenhouse gas emissions. Cities consume 60%
    of potable water in the world, wasting an estimated 20% in leakage. It is important
    to optimize the use of these critical resources and maximize their conservation
    [18]. The main reason cities have not been well designed is because they grew
    organically in response to increases in population. When the population increases
    rapidly, then urban planning cannot keep pace. The other problem is that city
    services are independent of each other, not communicating to solve problems together.
    The way cities are organized prevents collaboration, with each service or department
    getting their own funding and incentivized to solve their narrow problems. This
    leads to redundancy, waste, and shortcomings in meeting the needs of the city
    population. What is needed is a more scalable, collaborative, efficient system
    of city management and improvement. The Internet of Things can provide a city
    with more detailed and timely information and facilitate better solutions to the
    inefficiencies of modern cities. 4.6.1 Smart City Layers As proposed by Cisco,
    an IoT solution for a smart city can be described with four general layers [17]:
    Street Layer: At the base is the street layer. This is where devices and sensors
    are placed in various parts of the city to collect data and take automated or
    commanded actions resulting from the analyzed data. The sensors used will depend
    on the location and function expected of them. Video cameras are currently in
    widespread use in cities for various reasons. Some are aimed at highway sections,
    interchanges, or some city street intersections, and these are used to determine
    and report traffic conditions primarily. Other cameras are mounted at street level
    and are intended to monitor pedestrian behavior or are used for security purposes.
    The improvements in video recognition technology mean that these can be automated
    to perform facial recognition and vehicle recognition and make automated reports
    for security, traffic, and accidents. Device counters or vehicle detectors are
    used to count the number of vehicles passing a certain area, or that are parked
    on streets or in structures. This is another technology that has been in use for
    many years to great benefit. Its use can be expanded to make parking counts more
    available to private drivers and their applications to better coordinate parking.
    They can also be adapted to count other things such as birds behaving as pests
    in public areas. Magnetic sensors are able to detect the presence of vehicles
    in specific locations. This is another sensor that can be applied to the parking
    problem. It can also be used to make traffic lights more responsive. An air quality
    sensor can be used to measure the amounts of particulate matter present in the
    atmosphere. This data can be used to give warnings to citizens when air quality
    is bad or to detect the culprits of high levels of pollution in order to improve
    air quality. There are other sensors and controllers available and the choice
    of which one to be used depends on the problem to be solved and the resources
    available. There are several factors to consider when selecting a sensor. What
    are its lifetime maintenance costs? Can it be mounted on existing infrastructure?
    What is the cost of operation? Can it store its own data, or must it be transmitted
    to the cloud immediately? If such a connection is needed, is it available? How
    can this sensor interoperate with other such sensors? Can it scale? Once these
    questions are answered, then a tradeoff analysis can be conducted and the appropriate
    sensors can be selected. This is another reason why it is more efficient for the
    different departments of a city to work in concert, as they can leverage sensors
    and infrastructure to solve multiple problems. City Layer: The next layer is the
    city layer. This is above the street layer and provides the connectivity for the
    myriad devices in use at the lower layer. This means the network routers and switches
    are at this layer along with the communications protocols that allow the connected
    devices to exchange data. This is also the edge layer and the start of data processing.
    Some sensor data will be time sensitive, while others must be cleaned or reordered
    before transmission to the higher levels. A resilient and reliable network is
    therefore a necessity at this layer. Often, the networking equipment will be placed
    outdoors or in a harsh environment and therefore must be designed to work under
    inhospitable conditions. A malfunction at this layer may cause automated false
    alarms due to missing or mishandled data. Data Center Layer: When the data has
    been collected at the edge and transmitted, possibly over different transport
    protocols, it is delivered to the next layer up, the data center layer. This is
    where the final analysis is performed, and the results of these analytics are
    stored for further use. Therefore, analytics, storage, and some method of making
    results available are the primary functions at this layer. As previously discussed,
    the cloud plays a major role at this stage, providing the required storage and
    processing power. Services Layer: The services layer is the final layer in the
    Internet of Things smart city model. At this point, the results of the sensor
    data are provided to applications that make use of it – for example, a visualization
    tool to show the real-time status of traffic in the city. City managers, law enforcement,
    and private citizens should all have access to the data. City managers will want
    to ensure that the city is running smoothly and could use the data to find opportunities
    to conserve energy, for instance, or to check on the status of waste removal in
    a given neighborhood. Law enforcement could be verifying that tolls were paid
    or the payment made for the use of a public parking space, among other things.
    A private citizen could be looking for an open parking space or for the speediest
    path to the other side of the city. Once the sensors are in place and the data
    made available, then the city is ready to reap the benefits of the Internet of
    Things. 4.6.2 Applications of IoT in Smart City Here is a sample of some areas
    where the Internet of Things is making a positive impact on smart cities. Smart
    Lights – Public outdoor lighting is beneficial to society as it makes public spaces
    safer to live and work. Unfortunately, it is also expensive to operate and often
    wasteful. Many systems merely use a timer to activate and deactivate the lights
    at certain hours of the day. The Internet of Things can make the system more efficient.
    Using sensors to monitor usage and activity at the lights, they can be directed
    to activate the lights only when needed. They can adapt the lighting settings
    to environmental conditions, such as fog or rain, when visibility has decreased.
    Lights can also be used to assist emergency responders or law enforcement by providing
    more lights in high-crime areas or when an accident has occurred. Real-time data
    about the lights themselves can provide operational status, making maintenance
    and replacement tasks proactive. This can increase the longevity and operational
    time of the lights while reducing maintenance costs. Traffic – Traffic lights
    can also benefit from the sensing and command possibilities of being connected
    by the Internet of Things. Real-time traffic data can be used to smooth traffic
    loads throughout cities. The goals are to reduce idling time, to improve flow
    and runtimes through the city, and to reduce pollution and fuel use. The data
    can be collected from cameras and correlated with data from vehicle counters.
    The ideal system would integrate traffic data with private navigation applications,
    so that a centralized view of the city can help direct drivers to balance routes.
    With smart traffic light technology and sensors on roadways, vehicle accidents
    can be detected more quickly, and assistance can be dispatched to the scene more
    efficiently. The path of the responders (e.g., police, ambulance) can be expedited,
    and even emergency rooms can be alerted so they can be prepared to receive victims.
    These efficiencies will help to make our roads safer. Smart Parking – Parking
    in a congested city can be frustrating and wasteful. With access to data about
    traffic patterns and open parking spots, applications can help citizens to locate
    and travel to available parking more efficiently. Kansas City in the United States
    and Paris in Europe have already implemented IoT smart parking solutions. Smart
    Water – Every city needs to manage its water supply. Water treatment plants must
    treat potable water for citizens, and a distribution system must deliver this
    water to residents. Currently, up to 20% of water is lost from the network because
    of leaks. It is difficult to predict water demand, and without accurate predictions,
    treatment plants can run inefficiently. The Internet of Things sensors can be
    used to improve water metering, leakage detection, planning for increased distribution,
    and understanding water use. Having better, more accurate data helps when creating
    water usage models, which improves predictions. More accurate water meters make
    water bills more accurate and build trust between city water authorities and customers.
    Water is a precious commodity for us and it is vital that we manage it in an informed,
    thoughtful and efficient manner. Smart Waste – All cities produce waste and managing
    that waste is a difficult challenge. The most used current solution to the waste
    problem is to use manual collection based on a schedule set by a waste management
    company. The schedule may or may not be effective as it depends on the details
    of the waste management contract. The scope of the waste problem includes the
    collection, transport, processing, and disposal of the various kinds of waste
    generated by a city’s population. Some waste can be recovered by recycling techniques,
    but this must be identified and separated and then transported to a recycling
    facility for processing. The entire process must be managed and monitored all
    at the cost of time, money, and labor. Improvements in the process can benefit
    all the stakeholders, the city council, manufacturing plants and other companies,
    health and safety authorities, and the people themselves. Using the Internet of
    Things to improve the process involves adding sensors in the waste receptacles
    and in the waste removal vehicles. These sensors can detect the amounts of garbage
    and the types of garbage present. In this way, a logistics platform can match
    the collection agents to the receptacles that are at or near capacity. The routes
    that collection trucks use can be optimized for efficiency. 4.6.3 Examples of
    Smart City There are some cities that are already embracing transformative IoT
    technologies to improve the well-being of their citizens. For example, in Stockholm,
    a smart management system in conjunction with smart applications has addressed
    traffic and environmental issues in the city. The city implemented a policy of
    a shared waste management vehicle fleet that resulted in better waste collection
    routes and improved waste collection. In Helsinki, the collective inputs of the
    citizens were leveraged by making over 1 thousand databases publicly available.
    The data concerned transport, economics, employment, and overall well-being of
    the people in the city. This was done via an open urban data platform, called
    the Helsinki Region Infoshare Project. The project won the European Prize for
    Innovation in Public Administration for empowering the citizens of the city. One
    of the chief results was to foster more public involvement in policy- and decision-making
    in the city. 5 IoT Business Implications and Opportunities Internet of Things
    is seen as a strategic topic in many industries. For example, in 2018 the number
    of job postings related to IoT in Germany doubled compared to 2017 [19]. Bain
    & Company projected the global IoT market to reach $318 billion by 2021. Expectations
    are high regarding future IoT-based turnover [20] and emerging new business models
    [21]. Despite those huge expectations, many companies, especially small- and medium-sized
    enterprises, struggle to identify promising business models and solid use cases
    [22]. To be able to design new business models and draft business cases, the key
    business opportunities that IoT provides for a specific company should be analyzed
    and evaluated. In this context, we also need to understand the IoT business ecosystem,
    the stakeholders, as well as their motives. As shown in Fig. 1.7, three business
    opportunities and stakeholders can and should be distinguished when discussing
    the strategic impact of IoT from a company’s point of view: Complete Product and
    Solution Provider (Vendor): These stakeholders aim at creating additional revenue
    streams from smart products/services which comprise the hybrid value proposition
    of IoT solutions [23]. IoT Customer: The customer of an IoT solution on the other
    side is ultimately looking for optimization and cost reductions within its own
    operations. The IoT solution makes the operations of IoT customers smarter and
    optimized. The fundamentally different perspectives of IoT provider and IoT customer
    and their relation can be illustrated better by an example. John Deere is an international
    corporation that manufactures agricultural, construction, and forestry machinery.
    The so-called field connect system from John Deere allows for monitoring the moisture
    levels on various depths of a farmer’s field [24]. The IoT provider (John Deere)
    intends to create additional revenues from an innovative offering based on IoT,
    which he did not sell before. The farmer (IoT customer) on the other hand invests
    money in an IoT solution hoping to reduce the cost for monitoring moisture manually
    on site and waste of water. Component Supplier: Many companies could leverage
    the third strategy as well. A component supplier facilitates the design and deployment
    of the Internet of Things. In this case, no complete IoT solutions are involved,
    but just IoT components. These might be technical components on a single layer
    of the IoT technology stack (e.g., IoT device, gateway, connectivity, and cloud
    platform) or components from two or more layers. Fig. 1.7 Three basic IoT business
    opportunities Full size image 5.1 Component Supplier: Component Business While
    a complete IoT solution comprises the whole IoT stack, IoT components relate to
    one or at maximum three layers of the IoT stack. A company could focus on selling
    such IoT components to complete IoT solution providers who intend to build and
    release complete IoT solutions. Let us examine each layer of the IoT value stack
    and their corresponding stakeholders using a connected electric bike (e-bike)
    example [25]: Physical Object – The physical object (i.e., e-bike) provides the
    initial direct benefit for the user. As with traditional bicycles, the e-bike
    provides an eco-friendly, healthy mode of transportation while also enabling motorized
    cycling. Embedded System – In this layer, the physical thing is equipped with
    a processing unit (e.g., a microcontroller), a connectivity module (e.g., 3G,
    4G, NB-IoT), sensors, and actuating components to become smart. These pieces operate
    locally by gathering data and providing localized benefits. In our example, sensors
    are responsible for monitoring battery status or sensing when motorization is
    required. An example of an embedded system provider is Bosch which designs and
    provides several IoT sensors for years. Connectivity – In this layer the smart
    object and its functions/status (e.g., battery status) can be accessed online
    globally with the help of network providers/operators. Moreover, new services
    could be added to the system e.g., online location monitoring or theft prevention.
    In many IoT solutions such as e-bike, we can use SIM cards and mobile networks
    to be connected to the Internet. Indeed, already in the first quarter of 2016
    in the United States, 69% of newly activated SIM cards were related to non-phone
    devices, like cars, dog collars, etc. Thus, all major mobile network operators
    aim at selling SIM cards as IoT components. Platform (Cloud) – Platforms are one
    of the central foundations of IoT as they unite connectivity, service providers,
    applications, and embedded systems to create specialized IoT solutions for diverse
    industries. Platform providers offer data ingestion, data storage, data analytics,
    data visualization, device/user management, and integration with other third parties
    through SDK or APIs. In our e-bike IoT solution, this layer enables one to track
    the movement patterns of e-bike users, study the difficulty levels of specific
    cycling routes to understand motorized support demand better, or discover the
    location of stolen e-bikes in real time. An example of the platform layer could
    be Amazon. With Amazon Web Services (AWS), the company has been successful in
    the cloud computing business. Indeed, Amazon is now offering an IoT component
    (i.e., AWS) that can be used to build IoT solutions. Application (Service) – This
    final layer combines the options and features provided by the prior layers to
    structure digital services. Users can receive digital services in appropriate
    formats that are independent of location via mobile applications or web tool.
    In our example, this feature enables customers to find e-bikes in the case of
    theft or provides pertinent location information to law enforcement. System Integration
    – The stakeholders of this layer play a large role in the IoT ecosystem because
    not all IoT components are plug-and-play right out of the box. Therefore, system
    integrators are needed to enable individual IoT components to collaborate in the
    best possible way. System integrators should identify a specific niche and then
    make partnerships with other stakeholders. 5.2 Complete Solution and Product Provider:
    Additional Revenue IoT solutions are addressing business problems across several
    vertical markets from health to smart building, transportation/logistics, energy,
    and manufacturing. In this context, many companies, incumbents and startups, seek
    to create revenues from smart connected products. This could include enhancing
    the companies’ already existing products with embedded systems (e.g., sensors,
    connectivity, etc.) in order to enable new features or digital services. But it
    could also mean developing entirely new connected offerings. One of the main challenges
    for such an endeavor lies in handling the rather complex IoT value stack. A company
    from the digital or Internet world or a startup would need to develop and produce
    the connected thing, which would mean to enter the hardware world, with comparatively
    high upfront investments for development and production setup. A manufacturing
    company needs to complement its hardware expertise with the required skills on
    the connectivity, analytics, and service layer, which includes user front ends
    like apps as well. A second aspect which might be new for many manufacturing companies
    is the fact that servers and their software, as well as apps and other user front
    ends, need to be operated and maintained throughout the whole usage phase. This
    poses two challenges. On the one hand, the organization has to bear operating
    cost over the whole lifetime of the offering. And, on the other hand, the organization
    needs to have the capability to perform the abovementioned operations. Especially
    manufacturing companies might need to install new units taking care of those tasks
    [26]. The upside of smart connected products is new revenue sources which wait
    to be captured by an appropriate business model [23]. It provides a hybrid value
    proposition consisting of physical and digital parts. Both parts can be monetized
    either in a product (one-time payment and transfer of ownership) or service manner
    (continuous payments and usage rights). This opens up a space of four potential
    revenue sources. Especially in B2B scenarios, vendors manage to monetize two or
    more of those revenue sources. But even if only the hardware is being monetized,
    prices for connected products are, in many cases, much higher compared to similar
    non-connected products. For example, connected Philips Hue light bulbs sell for
    much higher prices compared to not connected light bulbs [27]. It should be noted
    that the creation of IoT products currently is not directed by specific guidelines
    or a systematic method. The application of a traditional legacy product development
    paradigm to IoT products is generally ineffective and disadvantageous. Agile methodology
    and in particular Lean model is typically considered a good fit for many organizations
    working in the IoT domain. According to this model, when developing an IoT product,
    there are three main stages that are important to constructing a competitive and
    sustainable IoT solution (see Fig. 1.8): Fig. 1.8 Phases of IoT product development
    Full size image Learn – Develop an innovation plan and construct or revise the
    business model. Build – Implement and build a minimum viable product (MVP). Evaluate
    – Measure and evaluate the product and provide feedback to the first stage. 5.3
    IoT Customer: Optimization and Cost Reduction While IoT consumers might buy an
    IoT solution in order to increase their comfort, for the peace of mind or just
    for fun, in business to business cases, the customer always calculates a return
    on investment. For IoT solutions, this usually translates into expected cost reductions
    that amortize the investment. Among the most popular approaches to realize IoT-based
    cost reductions is condition monitoring [28]. Critical parameters in the production
    process, like soil moisture in the John Deere example, are being monitored and
    optimized in order to reduce waste, or equipment is being monitored with the aim
    to reduce downtime. Other approaches include optimizing the supply chain. IoT,
    in terms of RFID technology being applied in a warehouse for example, could lead
    to a much more detailed picture of the actual inventories of raw material. This
    in return could allow for reducing the warehouse stocks, which leads to cost reductions
    as well. In general, the Internet of Things helps to gather data regarding the
    status of the physical world. This could be the condition of machines or other
    equipment, inventories in a warehouse/whereabouts of goods. Those data can be
    analyzed and leveraged by advanced machine learning algorithms and big data analytics
    algorithms to optimize a company’s operations. 5.4 Important Aspects of Implementation
    The three IoT-based business opportunities pose different challenges for companies.
    But in general, they require a significant change in the company’s business model.
    While changing a business model is a serious management challenge already, business
    model innovation poses various additional challenges. Bilgeri et al. identified
    16 barriers to IoT business model innovation. They are distributed along with
    the following innovation phases: idea generation, concept development and evaluation,
    technical implementation, and commercialization. Many of these issues are related
    to organizational questions. As already discussed, IoT solutions require continuous
    efforts, e.g., in back-end operations, maintenance, and development of new features
    throughout the whole lifecycle. Most incumbents from the manufacturing industry
    do not have units for these tasks in their organization yet. To name another example,
    IoT solutions provide the opportunity to sell services in addition to or rather
    than products. However, selling services requires different skills as well as
    controlling and financial mechanisms compared to selling products. 5.5 Data Monetization
    Transforming IoT data into a marketable product is a fast-growing trend many companies
    are considering as a secondary revenue source; however, the idea of selling data
    is not a new one. Gartner has labeled the creation and utilization of data or
    information with the term, “infonomics” [29]. With millions of smart devices connecting
    to the IoT and collecting data, a new market based on data providers and data
    customers has been born (see Fig. 1.7). Profiting from IoT data can be approached
    in two ways [30]: Direct Data Monetization – Regardless of why you may be willing
    to offer your raw data, there are probably consumers interested in using and paying
    for your data. While there are many ways to sell data, a primary means is through
    a data marketplace. When selling data, direct monetization is generally separated
    into two categories [30]: Selling Raw Data – Direct access to data (i.e., APIs
    or data sets) is provided in trade for cryptocurrency or money. There are two
    general marketplaces from which you can choose and the appropriate choice depends
    on your strategic requirements [30]. Centralized Marketplace – This is a platform
    owned by one party that serves as a centralized location to exchange multiple
    kinds of data among diverse participants. In this marketplace, both metadata and
    raw data are stored. Decentralized Marketplace – This is a platform where participants
    are able to exchange data directly in peer-to-peer transactions. In this context,
    the marketplace only stores the metadata to enable data consumers to find the
    provider/owner of the data. Selling Data Insights or Analysis – Performing data
    analytics on raw data improves the quality of the information being sold. Not
    all companies have the capability to analyze data, creating an opportunity for
    monetization that is beneficial for both sides of the transaction. Analysis services
    can be offered in marketplaces or through other channels. Indirect Data Monetization
    – Data can be used to improve business intelligence and function, generate new
    products or services, and create new business models. Generally, there are two
    approaches to making good use of your own data [30]: Data-Driven Optimization
    – Utilizing data in this way decreases cost and increases the effectiveness and
    efficiency of business processes. This optimization is applicable across many
    fields. For example, manufacturing test benches could be optimized by shortening
    the testing time or field data could be utilized to improve the design of a product.
    Data-Driven Business Models – Monetizing by employing this strategy means that
    process or product data is used to generate new business opportunities or attract
    new customer groups through the development of new services or products or by
    improving existing products or services. Building a data-driven business model
    enables you to uncover innovative, new businesses rather than adjacent businesses.
    These models are also important for diversifying revenue streams. For example,
    Bosch makes use of manufacturing data to create customized subscription-based
    services that monitor the conditions of hydraulic systems. The market of IoT data
    will keep growing as companies learn how powerful it can be to provide data to
    others and how much others are willing to pay to obtain data. The primary challenges
    around monetizing IoT data include [29]: Ensuring Data Quality – In order for
    customers to trust the data provided, it must be of high-quality and complete.
    The data should also be accurate and timely and have been obtained ethically.
    Determining Information Type – Providers of data will need to adapt and flex to
    customer needs as companies may require IoT data in diverse forms or may consider
    data that was not originally fit to their particular business model. Customers
    may seek additional information for data points that were not initially recorded.
    Traditional Product Management and Marketing – IoT data is not like a traditional
    physical product. Therefore, companies may need to forego the usual activities
    that help sell physical products such as research, design, development, promotions,
    packaging, or marketing support. Protecting Against Unlicensed Use – It is very
    important to ensure data sovereignty for the creator of the data. It is easy to
    copy data, and thus it can become difficult to make sure customers are not utilizing
    data in unintended manners. Therefore, we need to consider contracts that ensure
    a licensed user understands the appropriate and ethical handling of information
    products, how to audit usage, etc. 5.6 Business Model It is important to understand
    the basic business model before attempting to create an IoT Solution. The term
    “business model” was born toward the end of the 1990s when it became a buzzword
    in popular media. Since that time, it has received significant attention from
    scholars and business practitioners and currently exists as a clear point of interest
    in many areas of IoT. Typically, the business model is defined as an analytical
    model used to determine how a business functions. The available literature regarding
    the business model has not yet reached an agreement regarding which elements are
    vital to the creation of a business model. However, two widely known tools currently
    exist to illustrate business models: St. Galler Magic Triangle and Osterwalder
    Business Model Canvas. The St. Galler Magic Triangle is comprised of four dimensions
    and is illustrated using a triangle shape (see Fig. 1.9) [31]: Who Who are the
    target customers? How can customers be classified into groups? What are the basic
    demographics and shared characteristics of customers? What What is the opportunity
    being offered to the customer? What value is being added for the customer? (value
    proposition) What combination of services or products make up the opportunity?
    How How is the value proposition created, applied, and distributed? How will the
    activities and processes need to provide the product look? What kind of resources
    will be needed? Which IoT business ecosystem stakeholders will be needed and how
    should they be organized? Revenue Does it look as though the opportunity will
    be financially sustainable? What does the cost structure look like? What revenue
    mechanisms will be applicable? How can the value proposition be monetized? Fig.
    1.9 St. Galler Magic Triangle Full size image Thoughtfully answering the questions
    in each of the four areas noted above creates a solid business model and a foundation
    for further innovation in IoT ecosystem. Osterwalder Business Model Canvas, created
    by Osterwalder in 2010, serves as an alternative method to the St. Galler Magic
    Triangle for illustrating a business model (see Fig. 1.10) [32]. It provides a
    well-known guide for explaining a business model in only one page. This model
    includes the following components [32]: 1. Key Partners: Who are the key partners
    and suppliers? 2. Key Activities: What key activities (e.g., marketing, designing,
    producing) our value propositions, distribution channels, customer relationships,
    and revenue streams need? What tasks does the company need to perform to fulfill
    its business purpose [32]. Some typical key activities in IoT business model include
    Research & Development, Production, Marketing, and Sales & Customer Services.
    3. Key Resources: What key resources (e.g., physical resources, intellectual resources,
    human resources, financial resources) do our value propositions, distribution
    channels, customer relationships, and revenue streams require [32]? 4. Key Propositions:
    What value do we deliver to our customers? What bundles of products/services do
    we offer? Which problems of the customer are solved by our products/services?
    To find the key proposition, one can use the Value Proposition Canvas [32]. As
    shown in Fig. 1.11, the Value Proposition Canvas consists of two building blocks
    to be able to model and visualize the relationship between product/service and
    customer/market [32]: Customer Profile: This shows the task/job a customer needs
    to get done, potential pains that the customer might face during and after the
    job, and benefits that a customer expects from the product/service. Value Proposition:
    This shows the list of products/services, explains how they can kill the pains
    of the customer, and demonstrates how the offered products/services can create
    customer gains. 5. Customer Relationship: What type of relationship does each
    of our customer segments expect us to establish and maintain a long-term relationship
    with them? The most common types of customer relationships include transactional,
    personal assistance, self-service, automated services, communities, and co-creation.
    Note that these types of relationships can coexist in a company’s relationship
    [32]. 6. Channels: Through which channels (e.g., website, email) do our customer
    segments want to be reached [32]? 7. Customer Segments: From whom are we creating
    value? Who are our most important customers [32]? 8. Cost Structure: What are
    the most important costs inherent in our business model? Which key resources/activities
    are the most expensive [32]? 9. Revenue Streams: For what value are our customers
    really willing to pay? For what do they currently pay? How are they currently
    paying? How would they prefer to pay? How much does each revenue stream contribute
    to overall revenues [32]? Fig. 1.10 Osterwalder Business Model Canvas Full size
    image Fig. 1.11 Value Proposition Canvas Full size image 5.7 Minimum Viable Product
    (MVP) The concept of a minimum viable product (MVP) was first introduced in Eric
    Ries’ popular book, The Lean Start-Up, in 2001. The goal of an MVP is to evaluate
    if the product fits in the market with the smallest possible amount of risk. In
    this approach, a new product is created with features adequate to satisfy the
    earliest users. The final features are not developed until feedback from initial
    users can be evaluated. In short, the main idea is to construct a very simple,
    testable version of the product. The results of testing can be included in the
    next stage of development during the scaling phase or for revising the business
    model. A “build, evaluate, and learn” approach enables the solution provider to
    build the more important and viable basics into the product as quickly as possible.
    At the start of the process, there is usually a large-scale, almost unreachable
    vision of what the finished product will be, and shaping the vision at such a
    high level can consume large amounts of time and considerable resources. It is
    important to avoid the pitfall of trying to create a perfect IoT product. Instead,
    one should focus on creating a possibly viable IoT product with the potential
    to focus team creativity and original ideas throughout the process, while addressing
    the question of whether the product should even be created at all or not. In order
    to choose the most significant value proposition for creating the MVP, the company
    must concentrate on the specific intersection of the customer’s wants and the
    value of the product as illustrated in Fig. 1.12. As shown in this figure, to
    be able to define the list of important features which should be included in the
    MVP, we can classify the product features based on two dimensions, namely, implementation
    effort and business criticality. Quadrant I – Features in this area are vital
    to the MVP because they are critical to business success and are usually more
    straightforward to implement. Quadrant II – These features are nice, but they
    are not vital and are still easy to implement. Leaving these out of the MVP saves
    both time and resources. Quadrant III – Features in this area are trivial and
    can be hard to implement. They should be avoided in an MVP and in the following
    product iterations. Quadrant IV – These features are business critical, but are
    also arduous to implement. The elements in this quadrant need a maximum amount
    of deliberation and thought. Fig. 1.12 Minimum viable product (MVP) Full size
    image 6 Summary This chapter introduced the Internet of Things (IoT) with several
    definitions and discussed the benefits and challenges of establishing the IoT.
    There are advantages to be gained in the personal lives of individuals as well
    as the operations of businesses and manufacturers. This chapter discussed all
    the promises and challenges of IoT. The complete IoT stack from the sensors and
    devices, to the fog, and to the cloud has also been explained. There are several
    commercial frameworks, cloud technologies, and IoT-enabled devices and ecosystem
    providers, which we presented their offerings briefly. Next, some examples of
    the applications of IoT technology have been listed with their expected impacts
    to varied sectors of our society, from agriculture to the cities in which we live.
    Finally, the details of the business implications, business models, and opportunities
    of IoT have been addressed. References IBM. Available from: https://www.ibm.com
    SAP. Available from: https://www.sap.com/ Gartner Google Scholar   Bosch. Available
    from: https://www.bosch.com/ IDC. Available from: https://www.idc.com Intelligent
    IoT. Available from: https://www2.deloitte.com/insights/us/en/focus/signals-for-strategists/intelligent-iot-internet-of-things-artificial-intelligence.html
    A. Rayes, S. Salam, Internet of Things—From Hype to Reality (The road to Digitization.
    River Publisher Series in Communications, Springer, Denmark, 2017), p. 49. https://www.amazon.de/Internet-Things-Hype-Reality-Digitization/dp/3319448587
    Book   Google Scholar   NIST: National Institute of Standards and Technology.
    Available from: https://www.nist.gov/ P. Raj, A.C. Raman, The Internet of Things:
    Enabling Technologies, Platforms, and Use Cases (Auerbach Publications, 2017)
    Google Scholar   A. Botta et al., Integration of cloud computing and internet
    of things: a survey. Futur. Gener. Comput. Syst. 56, 684–700 (2016) Article   Google
    Scholar   Internet of Things World Forum. Available from: https://www.iotwf.com/
    F. Firouzi et al., Keynote paper: from EDA to IoT eHealth: promises, challenges,
    and solutions. IEEE Trans. Comput. Aided Des. Integr. Circuits Syst. 37(12), 2965–2978
    (2018) Article   Google Scholar   B. Farahani et al., Towards fog-driven IoT eHealth:
    promises and challenges of IoT in medicine and healthcare. Futur. Gener. Comput.
    Syst. 78, 659–676 (2018) Article   Google Scholar   FIWARE. Available from: https://www.fiware.org/
    AWS IoT. Available from: https://aws.amazon.com/iot/ Microsoft Azure IoT. Available
    from: https://azure.microsoft.com/en-us/services/iot-hub/ D. Hanes et al., IoT
    Fundamentals: Networking Technologies, Protocols, and Use Cases for the Internet
    of Things (Cisco Press, 2017) Google Scholar   I.A.T. Hashem et al., The role
    of big data in smart city. Int. J. Inf. Manag. 36(5), 748–758 (2016) Article   Google
    Scholar   Diese Digitalexperten sind bei deutschen Firmen besonders begehrt. Available
    from: https://www.handelsblatt.com/unternehmen/beruf-und-buero/digitaler-jobindex/digitaler-job-monitor-diese-digitalexperten-sind-bei-deutschen-firmen-besonders-begehrt/22957856.html?ticket=ST-1817019-o0qDpTQqZsW0sFKadd20-ap
    Roundup of Internet of Things Forecasts. Available from: https://www.forbes.com/sites/louiscolumbus/2017/12/10/2017-roundup-of-internet-of-things-forecasts/#6a7ab8041480
    E. Fleisch, M. Weinberger, F. Wortmann, Business Models and the Internet of Things,
    Bosch IoT Lab Whitepaper (Bosch Internet of Things and Services Lab, 2014) Google
    Scholar   Businesses are Expected to Continue IoT Adoption Despite Security Risks,
    Survey Says. Available from: https://biztechmagazine.com/article/2017/02/businesses-are-expected-continue-iot-adoption-despite-security-risks-survey-says
    F. Wortmann et al., Ertragsmodelle im Internet der Dinge, in Betriebswirtschaftliche
    Aspekte von Industrie 4.0, (Springer, 2017), pp. 1–28 Google Scholar   John Deere,
    John Deere Prescision Ag Technology, Brochure. Available from: https://www.deere.com/assets/publications/index.html?id=004d03e7#36
    D. Bilgeri, et al., The IoT business model builder. A White Paper of the Bosch
    IoT Lab in collaboration with Bosch Software Innovations GmbH, 2015 Google Scholar   D.
    Bilgeri, F. Wortmann, E. Fleisch, How digital transformation affects large manufacturing
    companies’ organization. 2017 Google Scholar   E. Fleisch et al., Revenue Models
    and the Internet of Things? A Consumer IoT-based Investigation (ETH Zurich, 2016)
    Google Scholar   How the Internet of Things is driving cost-saving efficiencies
    for manufacturers, The shi blog. Available from: https://blog.shi.com/hardware/internet-things-driving-cost-saving-efficiencies-manufacturers/
    D.B. Laney, Infonomics: How to Monetize, Manage, and Measure Information as an
    Asset for Competitive Advantage (Routledge, 2017) Google Scholar   A guide to
    data monetization. Available from: https://blog.bosch-si.com/business-models/a-guide-to-data-monetization/
    O. Gassmann, K. Frankenberger, M. Csik, The St. Gallen business model navigator.
    2013 Google Scholar   Osterwalder Business Model Canvas. Available from: http://alexosterwalder.com/
    Download references Author information Authors and Affiliations Department of
    ECE, Duke University, Durham, NC, USA Farshad Firouzi Shahid Beheshti University,
    Tehran, Iran Bahar Farahani & Fereidoon Shams Aliee Aalen University, Aalen, Germany
    Markus Weinberger University of Rhode Island, Kingston, RI, USA Gabriel DePace
    Editor information Editors and Affiliations Department of ECE, Duke University,
    Durham, NC, USA Farshad Firouzi Department of ECE, Duke University, Durham, NC,
    USA Krishnendu Chakrabarty Radyalis LLC, Austin, TX, USA Sani Nassif Rights and
    permissions Reprints and permissions Copyright information © 2020 Springer Nature
    Switzerland AG About this chapter Cite this chapter Firouzi, F., Farahani, B.,
    Weinberger, M., DePace, G., Aliee, F.S. (2020). IoT Fundamentals: Definitions,
    Architectures, Challenges, and Promises. In: Firouzi, F., Chakrabarty, K., Nassif,
    S. (eds) Intelligent Internet of Things. Springer, Cham. https://doi.org/10.1007/978-3-030-30367-9_1
    Download citation .RIS.ENW.BIB DOI https://doi.org/10.1007/978-3-030-30367-9_1
    Published 22 January 2020 Publisher Name Springer, Cham Print ISBN 978-3-030-30366-2
    Online ISBN 978-3-030-30367-9 eBook Packages Engineering Engineering (R0) Share
    this chapter Anyone you share the following link with will be able to read this
    content: Get shareable link Provided by the Springer Nature SharedIt content-sharing
    initiative Publish with us Policies and ethics Sections Figures References Abstract
    What Is IoT Architectures and Reference Models of IoT: A Layard View IoT Frameworks
    and Platforms IoT Applications in Vertical Markets IoT Business Implications and
    Opportunities Summary References Author information Editor information Rights
    and permissions Copyright information About this chapter Publish with us Discover
    content Journals A-Z Books A-Z Publish with us Publish your research Open access
    publishing Products and services Our products Librarians Societies Partners and
    advertisers Our imprints Springer Nature Portfolio BMC Palgrave Macmillan Apress
    Your privacy choices/Manage cookies Your US state privacy rights Accessibility
    statement Terms and conditions Privacy policy Help and support 129.93.161.219
    Big Ten Academic Alliance (BTAA) (3000133814) - University of Nebraska-Lincoln
    (3000134173) © 2024 Springer Nature"'
  inline_citation: '>'
  journal: 'Intelligent Internet of Things: From Device to Fog and Cloud'
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'IoT Fundamentals: Definitions, Architectures, Challenges, and Promises'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Mani Sekhar S.R.
  - Tewari S.
  - Rahman H.
  - Siddesh G.M.
  citation_count: '1'
  description: As the amount of real-time data is increasing rapidly, the computation
    of these data is a challenging task. These data are being produced by billions
    of IoT devices in the world and processed in the cloud. Meanwhile, around two
    quintillion bytes of information are collected every hour and are predicted to
    rise exponentially in the following years. The restrictions of efficiency, storage
    capacity and security of the end devices in the cloud lead to a new indispensable
    computing paradigm named as ‘Fog Computing.’ In this chapter we try to assimilate,
    the need to collect and manage data, how data differs in different scenarios and
    the various methods implemented at present to collect data such as node-based
    segregation which reduces the requirement of a large number of fog nodes to be
    set up and overloading of these nodes. Exploring techniques wherein raw and passive
    forms of data can be made to evolve and become meaningful with reduced size, understanding
    how bluetooth low energy technology can be used to process collected data through
    gateways and usage of data collectors with wireless low powered sensing systems.
    Finally, the chapter discusses fifteen case studies related to Moving Vehicles,
    Industrial Automation, Underwater Data Collection Water Conservation in Agriculture,
    Indoor Air Quality Monitoring, Health Monitoring System, Telehealth Big Data and
    Healthcare 4.0 related to data analytics by incorporating Cloud, Fog and IoT.
  doi: 10.1007/978-981-15-6044-6_5
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Log in Find a journal
    Publish with us Track your research Search Cart Home Fog Data Analytics for IoT
    Applications Chapter Data Collection in Fog Data Analytics Chapter First Online:
    26 August 2020 pp 79–104 Cite this chapter Access provided by University of Nebraska-Lincoln
    Download book PDF Download book EPUB Fog Data Analytics for IoT Applications S.
    R. Mani Sekhar, Snehil Tewari, Haaris Rahman & G. M. Siddesh  Part of the book
    series: Studies in Big Data ((SBD,volume 76)) 435 Accesses 2 Citations Abstract
    As the amount of real-time data is increasing rapidly, the computation of these
    data is a challenging task. These data are being produced by billions of IoT devices
    in the world and processed in the cloud. Meanwhile, around two quintillion bytes
    of information are collected every hour and are predicted to rise exponentially
    in the following years. The restrictions of efficiency, storage capacity and security
    of the end devices in the cloud lead to a new indispensable computing paradigm
    named as ‘Fog Computing.’ In this chapter we try to assimilate, the need to collect
    and manage data, how data differs in different scenarios and the various methods
    implemented at present to collect data such as node-based segregation which reduces
    the requirement of a large number of fog nodes to be set up and overloading of
    these nodes. Exploring techniques wherein raw and passive forms of data can be
    made to evolve and become meaningful with reduced size, understanding how bluetooth
    low energy technology can be used to process collected data through gateways and
    usage of data collectors with wireless low powered sensing systems. Finally, the
    chapter discusses fifteen case studies related to Moving Vehicles, Industrial
    Automation, Underwater Data Collection Water Conservation in Agriculture, Indoor
    Air Quality Monitoring, Health Monitoring System, Telehealth Big Data and Healthcare
    4.0 related to data analytics by incorporating Cloud, Fog and IoT. Access provided
    by University of Nebraska-Lincoln. Download chapter PDF Similar content being
    viewed by others Fog computing in enabling 5G-driven emerging technologies for
    development of sustainable smart city infrastructures Article 07 January 2022
    Introduction Chapter © 2019 Integration of Fog Computing and Internet of Things:
    An Useful Overview Chapter © 2020 Keywords Data Data collection Fog computing
    Data analytics Methods of data collection Fog data analytics 1 Introduction Data
    is a collection of facts, figures, observations, or a description of things. The
    term data and information are often used interchangeably, though there is a subtle
    difference. Data is raw and unorganized, which can seem random and futile until
    it is organized. When data is structured, processed and presented in a given context
    to make it useful, it is called information. Data is information that is transformed
    into a form that can be moved and analyzed. Data can be classified into three
    categories. Firstly, structured data is the data that can be organized into a
    typical database, i.e. and it can be stored in a table with rows and columns.
    This data can be searched efficiently by human queries or machine algorithms.
    Names, addresses, etc. come under structured data. Unstructured data do not conform
    to any data model. They have internal structure but lack an easily identifiable
    structure, resulting in certain difficulties such as searching and indexing the
    data. Computer programs cannot make use of this data easily. Text, audio, and
    video information, logs, and web activity are part of unstructured data. Semi-structured
    data fits in between structure and unstructured data. They maintain internal tags
    and markings but do not conform to a data model. These organizational properties
    make them easier to analyze by humans but not machines. XML, emails and JSON files
    are few such examples. Data collection is a methodical approach to accumulate
    and regulate information to get a definite understanding of an area of interest.
    Data Collection empowers a person or an institution to answer relevant questions,
    reduce risks incurred due to insufficient data, predict and assess outcomes, understand
    and set new trends. Overall, it gives new insights and a cutting edge over the
    competitors, whereas in the absence of data collection, the companies will still
    have to use the outdated methods to make decisions. Data collected can vary from
    personal data such as demographics, contact details and other identifying factors
    to web data, which comprises any information pulled off from the internet for
    research purposes or otherwise. Most of the data collected is in electronic form;
    hence the size of the collected data is humongous. As a result, this crosses into
    the realm of big data. The fast and steady collection of data in the last two
    decades and the growth of IoT devices over the last couple of years has led to
    a surge in data. Due to this, the term ‘Big Data’ was coined in mid-2005. Any
    huge amount of data structured or unstructured, which must be organized, stocked
    and processed, can be referred to as Big Data, and the metric frequently used
    is with regard to petabytes and exabytes. Data Mining is very often used to collect
    big data, and it is used to decipher patterns and correlations for IoT applications.
    It has been observed that mining data for frequent and repeated patterns have
    been more useful than the regular computing methods. Big data gives intuition
    that helps to make better decisions and strategic business moves. It allows the
    B2C companies to broaden their horizon and prosper by changing the marketing strategies
    and implement new changes with concrete analysis of data to support it. The traditional
    databases cannot monitor big data, and therefore, new computing methods have emerged,
    such as cloud computing, fog computing and quantum computing. The term fog is
    used as an analogy to the real-world fog, and it is a layer between the clouds
    and the ground, which here in our case will be the cloud storage and the IoT devices,
    respectively. Fog computing has a decentralized architecture wherein it has edge
    nodes that have the power to compute loads of data without sending it to distant
    servers. Because of this proximity within the devices, fog computing grants control
    and real-time services and analysis. It facilitates computing near the users and
    provides data security and safety over data leakages. In layman terms, fog nodes
    or gateways are used to crunch through the data and send only the required data
    to the cloud. The remainder of the chapter is organized as follows. Section 2
    highlights the general methods of data collection by various sources and how fog
    computing plays a vital role in data collection. Section 3 explains how optimized
    compression of data can reduce the traffic congestion in the network. Section
    4 gives insights that are helpful in effectively collecting and managing big data.
    Section 5 discusses various case studies in crucial fields such as healthcare,
    agriculture, automation, etc. Section 6 summarizes the data collection methods
    in Fog Data Analytics and concludes the chapter. 2 Methods of Collecting Data
    Over the last few years, there has been an explosion of data from different fields
    through various sources. Data is being collected at a massive rate and pace by
    people and organizations to create a user-friendly environment, perform research
    and increase profits. Some of the ways to collect data are Website visits—A company
    needs to understand user behaviour and traffic on their websites. They use various
    web analytics tools that are available in the market, such as Google Analytics,
    IBM Unica NetInsight, Webtrends Analytics, etc. The website owner, with the aid
    of these tools, collects and visualizes the statistics and perceives the user’s
    activity on the site. This is done in order to understand the different patterns
    in which the user tries to search and access specific choices available throughout
    the website, which is very helpful, for example, in creating a recommender system,
    which makes the website easy to access and saves time. Also, heatmaps can be used
    to track the cursor movements, scrolling areas, and time spent on certain sections.
    Mobile Applications—According to some of the research groups, it is found out
    that as of now, there are approximately 3 million apps present in the play store
    created by Google. These apps can share the information available on mobile phones
    with Google and other third parties. This information can range from the location
    of the user and the nearest phone towers to personal information such as date
    of birth, gender, contact numbers, email ID, etc. The business of advertising
    and data sharing has skyrocketed in recent times and needs to be monitored efficiently.
    Loyalty Programs—It is tougher to maintain a customer base than acquiring the
    customers for the first-time. If not handled and serviced correctly, a customer
    might not return back to the brand/company next time, and thus, to keep the customer’s
    relationship with the brand intact, loyalty programs are used. To be loyal to
    the brand, the user is given offers, discounts, first-access, etc. in return for
    personal information. Sensors—Sensor data is generated by the active gadgets in
    our smart environment and is often associated with the term Internet of Things
    (IoT). This covers everything from counting a number of steps travelled using
    motion or activity trackers, measuring heart rate and pulse, to measuring temperature
    and weather using sensors. Sensor data is generally used for the optimization
    of processes, and machines can adapt to its surroundings by making smart changes.
    For example—Air Asia, in collaboration with GE aviation, uses sensors with IoT
    complemented by AI to cut down its operating costs and boost usage and profits.
    Fog layer acts as a link between the IoT devices and the cloud. Huge amounts of
    data are being generated every day and to deal with the drawbacks of cloud computing,
    it is very important to not only focus on data management, storage, processing,
    analyzing and monitoring but also focus on data collection. If devices are able
    to judge which data is useful and which is redundant or useless, then a lot of
    data will get filtered at the initial layers of networking and computing resulting
    in the intake of data for processing to be reduced by a very significant extent.
    Fog Computing plays a very crucial role in achieving efficient management of data.
    It filters out redundant data and prioritizes the processing of time-sensitive
    data. Data is harvested from the physical environment with the help of sensors
    which are placed in gadgets or IoT devices referred to as Fog devices [25]. A
    number of these devices are connected to large servers of higher configurations
    and the fog devices which are connected to the same server can also interact with
    each other. The efficiency and throughput while processing data and rendering
    the services requested in real-time depends on several factors such as the number
    of linked devices to a server, bandwidth, connectivity of the devices, etc. After
    the necessary evaluations, data is either filtered out or sent to higher levels
    for complex and expensive computation or storage purposes. 3 Optimized Collection
    of Compressive Data Traditional methods of information gathering in wireless sensor
    networks faced many challenges. The sensor data used to be collected continuously
    and stored at a local node. This data would then be forwarded to a central base
    station at regular intervals of time. As a result, this used to congest the entire
    network leading to inefficient data transfer and larger energy consumption [1].
    The need for optimized compression and collection of data was required. According
    to the study by [2], there exist three main categories of schemes used for data
    collection. The first method is that of collecting the critical data or compression
    of original data, and then reconstructing the original data by numerical analysis
    and interpolation techniques [3]. Reconstruction of data results in additional
    energy and time consumption. To solve this issue, an algorithm was developed,
    which reduces the redundancy of data by using the strong correlation among sensory
    data in temporal and spatial spaces [4]. The second method tries to solve the
    efficiency problem by creating advanced routing algorithms and balancing the load
    on the entire network [5, 6]. The final method implements a compressed sensing
    theory where data has a property called sparseness in the transformation process,
    which allows the data to be reconstructed with much fewer samples than Nyquist
    theory [7]. Other methods include collecting data at various time instances, storing
    it in a matrix form, and applying a singular value decomposition technique to
    achieve good compression of the data by choosing the number of singular values
    to be retained without losing out on information [8]. 4 Management of Big Data
    The field of Information Technology has seen a colossal amount of inventions and
    innovations, technological changes, the introduction of tech gadgets and much
    more in the last two decades, and there are no qualms in acknowledging the fact
    that data has become one of the most crucial and fundamental elements of this
    astronomical realm. Therefore, it is important to have an outlook for smart management
    of data, especially big data, to save space and time instead of only focusing
    on computing platforms. The smart management of data leads off from an efficient
    collection of data at the very beginning, and Fog Computing can play a major role
    in achieving it. The data collected from the sensors and several other gadgets
    and devices are transformed from their natural and bland form to an ingenious
    form of data cells that is more substantial in terms of valuable information and
    is also a systematic way of minimizing the load of big data [9]. As soon as the
    data generated from the sensors is collected, then and there, it is processed
    in the local fog, and more relevant data with less velocity and volume is forwarded
    to the cloud for global processing and storage. This also helps in reducing latency
    and communication overhead. 5 Case Studies The following section presents case
    studies discussing how data is collected in various industries such as automotive,
    agriculture and healthcare, etc. in different environment settings and how data
    collected from individuals is utilized in different scenarios. 5.1 Data Collection
    in Moving Vehicles In today’s data-centric world, vehicles are being equipped
    with different kind of instruments. These instrument or sensors provide data such
    as GPS location, vehicle speed, video data, the status of various parts of the
    vehicle and chemical emissions. The data is then used for applications like intelligent
    transportation systems, emergency response systems, traffic monitoring and pollution
    analysis. With the development of the vehicle industry and wireless communication
    technology, the vehicular ad-hoc networks (VANETs) were created. The system mainly
    comprises of an onboard unit (OBU), application unit (AU) and roadside unit (RSU)
    [10]. The OBU is generally mounted on a vehicle for exchanging information with
    RSUs or other OBUs. The AU is a device placed within the vehicle that communicates
    the information with the net via the OBU, which is responsible for all mobile
    and networking function, The RSU is fixed along the roadside or at strategic locations
    for short-range communication. The RSUs extend the transmission range of the network
    by forwarding the data to other OBUs and RSUs and provide internet connectivity
    to the OBUs as well. But VANETs also face various challenges such as signal fading
    due to obstacles between two communication vehicles, bandwidth limitations, connectivity
    due to rapid changes of topology and inefficient routing protocols. To overcome
    these challenges, the concept of fog computing is extended to VANETs. This enhances
    the chances for the optimization of the data gathering process. In [11], a data
    gathering framework based on fog computing (DAFOC) was proposed. Figure 1 shows
    a three-layer data collection framework and analytics involved in each layer.
    The framework intuitively varies the threshold to upload suitable amounts of data
    based on congestion in the network and suppresses unnecessary message transmissions.
    The RSUs in the DAFOC frameworks behave as fog nodes that provide computation
    and storage capabilities among the vehicles. The vehicles have sensors that operate
    on two modes: low-cost sensing (LCS) mode and high-cost sensing (HCS) mode. The
    nodes on LCS mode perceive the environment and produce data at a fairly slow rate.
    The RSUs evaluates the confidence of data and initiates an event validating procedure
    when the confidence is high. Based on this event check, the nodes in HCS mode
    sense more detailed data about the environment. This detailed data is sent to
    the RSU for final event verification where the data may well be advanced to a
    neighbouring node, or another RSU or the cloud directly. This information is processed
    in the cloud, and the decision/feedback is sent back to the RSU. This method lowers
    the overall power requirement of the nodes by implementing the two modes of operation
    and using each mode as and when required. Also, it minimizes unnecessary data
    upload and transmission and reduces transmission costs. Fig. 1 Three-layer architecture
    for data gathering system [11] Full size image 5.2 Fog Computing in Industrial
    Automation Following the trend towards industry 4.0 and cyber-physical organizations,
    the industrial Internet of Things (IIoT) has started taking off. The adoption
    of IIoT is changing industrial automation and leading to greater connectivity
    among industrial systems. Data collected from IIoT applications, such as scheduling
    of paths for industrial robots and manufacturing monitoring, requires real-time
    processing of data, including computing architectures that support low latency
    and efficient response. Cloud computing and IoT have a hand in hand relation.
    The cloud acts as a pathway for the massive amounts of data generated from the
    IoT. But the cloud centres are usually remote, which leads to latency in the transmission
    of data. To offer small latency and positional cognizance for the systems, fog
    computing is adopted in IIoT. A generic framework of fog computing in an industrial
    environment [12], consists of three-layers: things layer, fog layer and distributed
    cloud layer. All the machinery and equipment utilized in the industry are part
    of the things layer. They generate data that has to be managed based on the particular
    request by a certain application. The fog layer includes network devices such
    as routers and gateways to process time-sensitive data since they are closer to
    the things layer. Wired or wireless means of communication can be used with the
    former layer. High-end computing servers form the basis of the distributed cloud
    layer and perform data-intensive computations. This layer uses cellular communication
    or broadband networks to communicate with the fog layer. The communication between
    layers can be performed in numerous ways. The first method involves the IIoT machinery
    to generate data and send requests to the fog nodes for either processing at the
    fog nodes or at the cloud. These fog nodes analyze the requests and transmit the
    results to other fog or cloud nodes. If the workload is light or processing of
    data in real-time is required, the data is sent to the fog nodes. Otherwise, it
    is sent to the cloud. If the data has been sent to the cloud, the clouds nodes
    process the requests, and the results are retrieved by the IIoT nodes. The majority
    of the data is global information for the industry, which is stored in the cloud
    for global data sharing. The second method, unlike the first, performs the tasks
    individually but finally collaborate to complete the tasks in a distributed manner.
    This method demands optimal task allocation since the system is distributed over
    nodes but compensates for the limited computational powers of fog nodes. The final
    method is a multi-tier model that contains two fog layers. The fog layers can
    be of the same or different interaction modes that are centralized or distributed.
    Computationally inexpensive tasks are handled in tier-1, whereas computationally
    demanding tasks can be handled in tier-2. The cloud nodes handle the most demanding
    tasks. In the centralized model, a master node and several fog nodes are present
    at each domain in the fog node. The master node receives the estimated request
    time from each fog node and determines the fog nodes which are idle to perform
    the requested task based on the network conditions, whereas the distributed interaction
    mode does not require a master node. Using a distributed communication protocol,
    the fog nodes communicate with each other. The fog nodes maintain certain variables
    such as waiting time, which are updated in a condition table. The fog nodes choose
    suitable neighbouring nodes for the offloading of tasks. The centralized model
    can be simple to deploy but is prone to single-link failure. That is, if the master
    node fails, the entire system will come to a halt. The distributed mode is not
    vulnerable to single-link failure, but the implementation of a distributed protocol
    is complex, and task distribution is complicated. 5.3 Collection of Data Under
    Water Underwater acoustic sensor networks (UASNs) has been widely accepted for
    data collection schemes underwater. UASNs find applications in ocean disaster
    deterrence, military defence, assisted navigation, monitoring of aquatic life,
    coastline surveillance and protection and resource explorations. These applications
    generate enormous amounts of data such as high-definition video, audio and pictures.
    However, these networks face several issues such as low propagation speed, multipath
    effect and Doppler spread due to the acoustic signals. Therefore, these data collection
    schemes cannot be applied to underwater environment directly and the concept of
    fog computing was extended to these networks. In [13], a fog computing-based,
    four-layer network of underwater sensor cloud system was proposed as depicted
    in Fig. 2. The sensors/nodes in the physical layer have limited storage and computation
    capacities. Fig. 2 Underwater sensor cloud system Full size image They are equipped
    with antennas and are either anchored to the bottom of the ocean or made to float
    at certain depth with the help of buoys. They only sense the data and direct the
    collected information to suitable fog nodes. These fog nodes, in the fog layer,
    have large storage capacities and are computationally stronger than the nodes
    in the physical layer. The main purpose of the fog nodes is to perform localised
    computation on the data received from the physical nodes by discarding redundant
    data, extracting key information and dimensionality reduction of the data. Based
    on this information, the fog nodes, which are generally mobile nodes, make it
    to the surface to distribute the data to nodes in the sink layer if data is delay-insensitive
    or by the transmission of data to sink nodes through multi-hop mode with the help
    of several other above-level mobile fog nodes. The sink nodes in sink layer transmit
    the information to the cloud computing centre by radio signals after data fusion
    operation. This novel method helps to reduce communication delay between the nodes
    and minimize overall energy consumption in the network. 5.4 Water Conservation
    in Agriculture Using Fog and IoT Water is the basic necessity for the survival
    of all living things on Earth. It is essential for ensuring food security to the
    world’s inhabitants. Agriculture is the largest consumer of water accounting to
    about 70% of freshwater. The quality of water is important for physical health
    and fitness. Lack of water or usage of contaminated water can lead to serious
    health problems. The major grounds of water wastage are leakages in pipelines
    during distribution and the use of primitive irrigation method, surface irrigation,
    by drenching areas where no crops can profit from which depletes an enormous portion
    of water. Hence, a smart water management platform is required to sense the amount
    of water required by the agricultural crops and regulate the flow of water to
    where it is required the most. The SWAMP project was undertaken to incorporate
    IoT based solutions for smart water management by monitoring the field based on
    crop status and environment, the condition of the crop and to alter the irrigation
    plot accordingly [14]. The SWAMP system is classified into five layers IoT Services/Sensing
    Layer: A variety of sensors and actuators are utilized to acquire data on soil,
    plant (vegetation index, canopy temperature), weather and precipitation levels.
    The SWAMP pilots use commercial sensors such as drones to take images, as well
    as homemade multiparametric sensor probes [15]. Data Acquisition, Security and
    Management: Distributed databases consisting of cloud and fog nodes work in conjunction
    with each other to deal with large amounts of data coming from the sensing layer.
    Protocols and software for data acquisition along with security are the focus
    of this layer, Data analytics: Analysis of big data is performed in the cloud.
    SWAMP utilizes prevailing algorithms and models. A distributed infrastructure
    of cloud servers and fog nodes are utilized to make the data available to upper
    layers. Management of information: Builds upon application middleware protocols
    in addition to the data analytics facilities in layer 3. This layer acts as an
    API for the final layer. Application Layer: The data that is collected is altered
    into information that is useful to the agriculturalists via user interfaces. The
    SWAMP project has ensured that the layers are generic so as to be adjustable to
    other environmental settings. Layers 1, 2 and 3 are sufficiently elementary to
    be replicable in a variety of settings, whereas layer 4 is a fully customisable
    layer which may need customisation for every deployment. Methodologies in Layer
    5 are application-specific. SWAMP is still in its initial stages, though pilots
    have proven to be successful. 5.5 IoT Implementation for Collection of Data Using
    QR Codes Some specific objects are recognized by using videos which store data
    on the internet. This implementation of IoT model is built on algorithms executed
    in the OpenCV library for python to identify or recognize the objects and use
    Raspberry PI to pile-up the data accumulated from the surrounding. The distinct
    and specific hardware and software used can collectively be called a module [16].
    Every time when there is an object detection the module sends a request to the
    web application. The communication which involves these modules take place through
    HTTP communication and thus, there is a need for active connection to the internet.
    This web application is responsible for storing, monitoring and controlling of
    the data of the objects. In the recent few years, camera monitoring systems have
    become very common and it is observed that a substantial amount of information
    is not being used efficiently. Quick Response Codes, better known as the QR Codes,
    holds the potential to become one of the most intriguing ways of acknowledging
    the recognition of labels or marks, considering the fact that 2D type bar codes
    which are most widely used, encodes alphanumeric characters that have lots of
    information and possible applications. Each QR code is structured in a way so
    that it encompasses data, a code to correct the encountered errors and some orientation
    patterns. The system proposed for implementation can be classified into three-layers,
    as Database Model, Web API and Web Application and the camera module. The system
    enables the user to keep track of the location of an entity at some specific point
    in time. Artificial vision is the most prominent part of this IoT implementation,
    the usual impediments faced are the quality of the camera, the number of frames
    per second and the distinctness of the object. Basically, modules are created
    by the users to gather data and transmit the required information about the respective
    objects in order to dispense that information to all the members of the pool.
    This pool behaves as a reference for the data showcased and also for the upcoming
    data from the modules, hence the pools happen to be the most important since all
    of the data is stacked and registered using a referral or labels. Eventually,
    the user will have contemporary information about various objects. For example,
    this technology can be used to identify vehicles going in and out of a facility
    per day. The facility centre will share the data and the outcome will be available
    to the owner of the car. 5.6 Indoor Air Quality Monitoring Using IoT and Fog With
    the rapid growth of industrialisation and urbanization, the level of pollution
    in the environment has been increasing at an exponential rate. This pollution
    affects the day to day life and quality of living of an individual. Environmental
    pollution can be of air, water or land pollution. Air pollution stands out as
    one of the more prominent forms of pollution as it affects the health conditions
    of people at a larger scale. People today are spending more time indoors (homes,
    offices, work related areas) than outdoors. Due to the rising demand for automation,
    at home and offices, consequently, there has been an increase in the usage of
    electronic devices which have been found to emit many harmful gases and radiations.
    Hence indoor air quality monitoring has become of utmost importance. An IoT enabled
    indoor air quality monitoring system was proposed by [17]. The IoT device/sensor
    samples the air at constant intervals of time. The data was transferred to an
    intermediate node via Bluetooth. This intermediate node then communicates with
    the processing node through Wi-Fi. An alarm was raised whenever the pollution
    level was raised beyond a certain limit. This idea was further improved on by
    [18], as they developed an air monitoring device with the underlying architecture
    strongly formed on the concepts of fog computing. A three-layered approach was
    taken in this system designed as the sensing layer, network layer and application
    layer. The layers communicated with each other through Wi-Fi. The sensing layer
    was the backbone of the entire system. It was used to sense the air quality and
    was deployed over the wide area. The sensing model comprised of the sensor chunk,
    processing unit, communication module and power module. The sensor block consisted
    of various sensors to detect the different types of pollutants and the processing
    module was used to process the raw data from the sensors. The fog computing layer
    used to gather the data from all the sensing layers and passed the data to the
    application layer after necessary processing. The application layer receives data
    from the fog device and provides data visualization either through the website
    or mobile application. The entire model was considered with the sole aim to minimize
    the redundant network traffic, reduce overall power consumption and reduce the
    computational burden on the sensing nodes. With the help of this huge volume of
    data collected and processed, useful messages were generated and sent to the people
    within the confined spaces to raise alerts and create awareness. 5.7 Emotional
    Profiles With the passage of time, people have become more aware of health and
    fitness, and thus many new models have been proposed and developed to apprehend
    the affective state of individuals. More detailed 24/7 calibrated monitoring helps
    to delve deeper into the internal and external worlds experienced by human beings
    [19]. Data such as anatomical signals, speech and facial expressions help to behold
    and assimilate the affective states [20]. This category of data can be accumulated
    effortlessly, with the help of the sensors embedded in today’s smart devices such
    as smartwatches, smart glasses, motion or activity trackers, smartphones, etc.
    Because of the widespread popularity of these devices and their use by the common
    people, there arises an opportunity to develop the existing unorthodox techniques
    to recognize and analyze the various states experienced by the subject and for
    what reason they occur. Also, collecting and analyzing data of this class can
    be helpful in identifying the cause of various emotions, and then based on the
    outcome suggest actions to be taken to deal with them. These devices (smartphones,
    laptops, etc.) are recognized as IoT nodes and are interconnected to each other
    with the help of the internet and other technologies such as radio frequency identification
    (RFID) or other wireless sensor networks. Services in healthcare are omnipresent
    and still have a scope of prevalent research work and great developments. Amidst
    these innumerable devices it is important to collect data but, in the meantime,
    be energy-efficient and cost-effective. One such platform providing energy-aware
    services can be based on REST architecture which stands for Representational State
    Transfer. The energy utilization of the devices can be minimized by logically
    reduplicating the available sensors incorporated within the IoT devices and firmly
    regulating the rate of transfer of data grounded on the reckoning of the energy
    left in the IoT devices. The proposed platform was undertaken to reduce energy
    consumption by the IoT devices and can be classified into three components: Smart
    Devices—Data Collection applications must be installed on every IoT node (smart
    devices) for collecting data related to the emotional state of the people and
    then sending them to fog nodes for further analysis. Central Nodes—These nodes
    act as a hub and sanctions link between the RESTful web services and smart devices
    active in a smart environment. One of the smart devices itself, some other personal
    computer or some special device can take up the job of a central node. RESTful
    web services—The biggest advantage of using this web service is that it is sustainable
    and scalable in nature. Some of the services offered in context to the platform
    discussed are listed in the table Figure 3 is a flowchart displaying the three
    essential components of the proposed architecture and the web services rendered
    essential for complete implementation of the model is listed in Table 1. Fig.
    3 Proposed architecture of the data collection model in fog data analytics [20]
    Full size image Table 1 Required web services provided by the RESTful architecture
    Full size table 5.8 Health Monitoring System Using Fog Computing Healthcare is
    crucial to a country’s economic and wealth development. The rise in people falling,
    accidents and emergencies require hospitals to treat, diagnose and manage all
    these various cases. It is becoming increasingly difficult to monitor that a patient
    is complying by treatment plans and safeguarding them during attacks. To remedy
    this situation, wireless sensor networks are being widely adopted in the field
    of health informatics. Patients wear wireless sensors which can monitor several
    health parameters remotely by the hospital while the patients are at the comfort
    of their homes [21, 22] has proposed a context sensitive fog computing environment
    to improve the state of current healthcare systems. The wireless accessories attached
    to a patient generates huge amounts of data. This data may be useful or redundant.
    Also, the data being collected varies among patients. Cloud computing can cause
    a delay in data transfer from sensor to cloud to hospital, hence to reduce this
    time delay a distributed architecture such as fog computing is required. A three-tier
    architecture consisting of cloud, fog and sensor layer has been proposed. The
    sensors consist of wearable or non-wearable devices such as smartwatches, smart
    glasses or smartphones. The data gathered can be both intrinsic such as blood
    pressure and blood glucose levels or extrinsic such as the temperature of the
    physical location of the patient depending on the context. The collected real-time
    data is then sent to the fog computing layer for data analysis and aggregation.
    The data is distributed among various fog nodes for efficient computing where
    duplication of data is detected and filtered out. Then data is fused to be put
    together as a single entity after which it would be sent to the cloud computing
    tier if further analysis is required. The various health monitoring systems perform
    actions based on this data supervise the actions taken by the fog computing layer.
    The introduction of a fog layer into the cloud computing network reduces the security
    risk associated with patients and the prevention of loss due to a data centre
    failure. The implementation of fog in a health monitoring system is still in its
    primary stages of research and development, but studies have proven it to have
    a fruitful future. 5.9 Collecting Data Related to Elderly Behaviour According
    to various census and surveys, it was reckoned that in the next fifteen years
    there will be a huge shift in the proportion of people living above the age of
    60, this shift can likely be from 11% as of now in 2019, to 17% after a little
    more than a decade in 2030. Therefore, it is necessary to develop effective models
    to make the lives of the older people more smooth, relaxed and supportive in the
    upcoming years. Aged people are equally vulnerable to both physical and cognitive
    diseases such as mild cognitive impairments (MCI) and infirmity [23]. MCI gives
    rise to many significant cognitive changes in the person as noticed during a normal
    conversation in social relationships and daily behaviour and if not acted upon
    the healthcare system, to adapt to the upcoming contrasting requirements then
    there is a possibility of social and economic challenges around the globe. One
    method to acknowledge this issue is, by not considering an elderly person as an
    entity with special requirements. It is the person’s way of living and the cordial
    relationship he maintains with all his colleagues, family and friends what should
    be taken under consideration. The gigantic amount of data accessible today can
    aid in the decision-making process and create smart territory at the service of
    its occupants. Information and Communication Technologies (ICTs) plays an important
    part, by sensing data from the physical domains, managing data and employing,
    with the purpose of facilitating compatible modules upon which newly integrated
    values and personalized assistance can be fabricated. This problem is addressed
    by establishing substructures based on ICTs to observe the ageing behaviour and
    to provide rectifying measures after the data has been completely analyzed with
    the aim of promoting their independent living. Numerous technologies are used
    for surveying elderly people’s behaviour varying from wearable devices to wireless
    sensor networks, vision systems, portable interactive devices, bluetooth low energy
    beacons and augmented reality. Data can also be accumulated using high-end sensor
    devices, but these are not affordable and can create hindrance in implementing
    the data collection model at a large-scale. Therefore, it is important to consider
    the cost of the sensing devices for large scale implementation and it should be
    seen that there is an unobtrusive flow of data. The framework designed for this
    IoT implementation can be divided into two layers, the first layer which is used
    for collecting and managing the data for both indoor and outdoor activities, and
    the second layer then uses this data, analyzes it and then sets off the correct
    measures. The first and foremost requirement for the system is to precisely regulate
    the flow of the collected data from the inharmonious data sources and then assess
    in what aspects the behaviour of the elderly is varying or is consistent in different
    state of indoor and outdoor activities. The optimized data obtained as the output
    will be the prime data for the future works. 5.10 Telehealth Big Data Through
    Fog Computing It is very evident by now, that data gathered with the help of several
    sensors, especially the wearable sensors in healthcare and biomedical application
    is tremendous and will only rise exponentially, and hence there is a need of smart
    information gathering, data storage, data reduction and data analytics at the
    fog layer and then at the further levels [24]. The nested computer gathers the
    discerned data as time series, analyzes it and then tries to decipher similar
    patterns which are present in the collected data. The unique patterns are transmitted,
    and the nested computers draw out the relevant information that is forwarded to
    the cloud. Today some wearable medical sensors like ECG and activity monitors
    when positioned on the human body allows unobstructed 24/7 collection of data
    for health monitoring. Nowadays there are lots of self-regulating devices which
    are present around the human body, including at places like home and office that
    collect real-time data and feed telehealth interventions which help in making
    healthcare a little more affordable and raise awareness of one’s self health.
    This can be cited as a standard example of big data application wherein huge amounts
    of data with real-time information has to undergo a speedy processing to provide
    the optimum healthcare. One of the difficulties faced by the healthcare organizations
    is to project information sensing nodes into the body sensor networks (BSNs) which
    is now facilitated by employing wearable technology devices such as activity trackers,
    smartwatches, belt-worn personal computers, etc. The energy efficiency of these
    edge devices used in telehealth is also a matter of concern. To provide with ceaseless
    monitoring of the patients, BSNs are operated on batteries, and thus it is important
    to keep low power consumption as one of the priorities for BSNs. Generally, the
    procedure of data storage and data transmission devours a lot of energy, and thus
    it is better-off to process the data faster and filter out unwanted data which
    consumes space in storage and consumes energy when it is to be transmitted from
    one layer to another. Fog Computing architectures are extremely useful in achieving
    such objectives, their distinctive features can pull off onsite data analytics
    to lessen the unwanted data from being stacked and transmitted to the cloud. Some
    of the efficient telehealth systems are (1) Philips has come up with a device
    for COPD (chronic obstructive pulmonary disease) patients which basically is an
    adhesive patch ceaselessly gathering information about attributes like respiratory
    function, heart rate and physical activity [25]. (2) Philips is also working on
    developing one of its devices which can be controlled by iPhone and iPads and
    shall be used to subdue the very common tenacious pain suffered by many people
    across the globe [26]. (3) EchoWear is a smartwatch-based system that collects
    approximately 100 Mb data per day per person, who undergo profound speech therapies
    to improve their communication effectiveness [27]. 5.11 BLE-Based Data Collection
    The data gathering is one of the most vital aspect in the implementation of IoT.
    Because on the soaring amount of data being generated every day and which is only
    going to multiply in the coming days, it is crucial that efficient ways of collecting
    data should be focused on. There are many systems proposed with their underlying
    architecture based on Bluetooth Low Energy (BLE) technology to send the data onwards
    from the smart devices, phones or gadgets also referred to as data collectors
    to the fog nodes or hubs for analyzing data [28]. Table 2 compares the attributes
    of some of the similar technologies currently in use. The smart objects are acknowledged
    as the most elementary unit of Internet of Things (IoT) vision. The ideate is
    to connect several devices and objects to each other in our surroundings and bring
    together the data collected by them at any time, from any place and through any
    course of action. According to the data provided by the IoT Analytics, the number
    of internet-connected devices currently active in the world is estimated to be
    around 7 billion, that is a little less than the world population and this number
    is only going to increase insanely as internet connection and consumption increases
    and new devices and gadgets are introduced in the market. There are many applications
    of IoT devices and in various domains such as medicine, industry, agriculture,
    etc. The outpouring of information can be generalized in three phases; the collection
    phase where the data is collected through several IoT devices, the transmission
    phase where the information is filtered through the fog nodes in the fog layer
    and then forwarded to the cloud and the last, the managing, processing and the
    utilization phase. The process of collecting data is a set of techniques and technology
    which is used to sense the real environment and gather the existing data. Smartphones
    are now no more used for carrying out conventional jobs such as to send someone
    a text message or make calls alone but nowadays are also used to sense the environment
    around them. Specialized sensors in smartphone, as shown in Fig. 4, has been a
    huge addition in recent times, such as accelerometer, compass, gyroscope, orientation,
    GPS, proximity, gravity, barometer, light, sensor and some commonly and widely
    used sensors such as microphone and camera. Not only sensors, the smartphones
    also have RFID, NFC and BLE in their arsenal. Bluetooth Low Energy (BLE) is also
    referred to as Smart Bluetooth which was first-time set forth in 2010 as a segment
    of Bluetooth Core Specification version 4.0. It is a technology used to facilitate
    short-range wireless communication. The main aim of this technology is to authorize
    transceivers with low intricacy, low consumption of power, higher shell life and
    lower operating costs than the outstanding transceivers. It is an augmentation
    of the existing Bluetooth technology that permits small battery powered devices
    such as sports sensors, digital and smartwatches, wireless keyboard, etc. to communicate
    with each other. Even though BLE has comparatively less transmission power and
    range, the devices that operate on BLE can stay functional for many years because
    of its highly efficient low power-consuming idle mode. Bluetooth Low Energy (BLE)
    has a major setback that it allows data transmission only over a single hop, however,
    there are many mechanisms coming up in order to tackle this problem using the
    fundamental components of the BLE stack. Table 2 Some specifications of existing
    Low power technologies Full size table Fig. 4 Sensors present in the smart devices
    [28] Full size image 5.12 Safety Management System for Miners Mining contributes
    more than 2.4% of the GDP of the country. It is a source of employment for a large
    section of people, especially those, who reside close to the mines. History serves
    as evidence that even the smallest of mistakes or any form of negligence can prove
    to be lethal in the mining industry such as the Dhanbad and Chasnala disasters
    in India. A maximum number of fatalities occur in the coal mines of India. This
    makes it extremely important to ensure the safety of the mineworkers for which
    it is vital to know their live location and the environment they are working in.
    Cloud computing can be useful but the existing state-of-the-art technologies and
    architectures are unable to garner effective results. Hence many new architectures
    or models are being proposed such as a fog layer being integrated to make the
    system more reliable, dynamic and efficient [29]. Miners are constantly exposed
    to a dangerous and robust environment where toxic gases and dust have adverse
    effects on their health. Several propositions include communication with the help
    of sensors which determine different parameters such as methane gas level, oxygen
    level and water level but they have their own limitations. Even companies have
    tried to set up message centres and implement trained robots for inspection and
    other automation activities but since it is not cost-effective, the practice was
    discontinued. Thus, it is important to make the mineworkers conscious of life-threatening
    situations and also guide them to safe evacuations. One of the recently proposed
    architecture supervises the work environment and the movement of the miners in
    the minefields. A GSM layer has also been added for better navigation and monitoring
    of the action of the miners. Some of these sensors used for determining the level
    of carbon dioxide, carbon monoxide and hydrogen sulfide in the coal mines are
    K-30, MQ-7 and NTMOS H2S gas sensors, respectively. The data from these sensors
    are collected and forwarded to the different sensor nodes which creates a path
    till the fog gateways and then the fog nodes manoeuver the data as per the requirement.
    The fog layer gives an edge to the proposed architecture by reducing latency in
    the time of emergency. The fog layer analyzes the data and notifies the worker
    and the control room if the values of various parameters are on par with the threshold
    limits otherwise it sends the data to the cloud for storage purpose. The data
    stored on the cloud can be used for drills, research and visualization purposes.
    Adding more sensors such as pressure sensors and adding routes for fast and safe
    evacuation at the time of a disaster will alleviate the efficiency and the performance
    level of the architecture. 5.13 Healthcare 4.0 Healthcare industry has swiftly
    and rapidly grown after the evolution of the World Wide Web (WWW), in the last
    three decades. Since inception, Health 2.0 (the mid-2000s) and Health 3.0 have
    already been implemented wherein patients and the doctors are able to use basic
    tools for education, spreading awareness, disseminate elementary health-related
    guidelines and eventually go on to create medical records of the patients and
    store them for future references. These models turned out to be very convenient
    and efficient for the health experts, researchers, hospitals and its other users.
    With the escalating number of medical records and the information stored on a
    daily basis, it was crucial to introduce Cloud Computing in the healthcare industry
    to supplement the processing and storing of information more effectively. Sensors
    and wearable medical devices have developed with the advancing technologies and
    thus have become more reliable and safer to use, as a result of which lots and
    lots of data is being generated everyday and processed and stored in the cloud.
    Although cloud computing mitigates the problems faced regarding the storage and
    processing it still has its own limitations such as the bidirectional transfer
    of data between the user and the cloud is not smooth and fast enough, this impediment
    can lead to life-threatening situations and other blunders in the healthcare industry.
    This is where fog computing can be useful, it can facilitate the job of cloud
    computing in cases of medical emergencies. Fog Computing gives us an edge over
    cloud computing in terms of low latency, i.e. since fog nodes or gateways are
    near to the primitive devices, hence the overhead diminishes; and resilient, i.e.
    it helps to retrieve the lost data and also detect the anomalies in the link connections
    [30]. Fog Computing is also often referred to as SCALE, described in Table 3.
    Different architectures are being proposed that give us an intuition of how fog
    computing can immensely contribute to the Healthcare 4.0. One such three-layer
    architecture proposes the transfer of information between the Medical device layer,
    Fog layer and Cloud layer as per requirements. The first layer, i.e. the Medical
    device layer is the fundamental layer which involves collecting huge amounts of
    data through the different sensors, smart devices and wearable medical devices
    such as smartwatches and glasses. The IoT devices can further be divided into
    devices that digitally monitor the patient''s health and wellness such as ECG,
    glucose, haemoglobin and devices that record parameters based on the surroundings
    such as the number of steps walked, calories burnt, etc. The second layer is the
    fog layer which consists of several computational nodes that function on low power
    and are capable of giving high performance. One of the most valuable benefits
    of using fog computing is the quick responses while processing real-time data.
    The fog nodes are placed geographically near the medical devices and sensors,
    and thus the data which needs to be processed instantly are sent to fog nodes
    to get a prompt response and the rest of the data is forwarded to the cloud. The
    third and the final layer in this architecture is the cloud layer that incorporates
    major high computing data centres which perform on data that is collected by the
    sensors and the medical devices, and is filtered out by the fog layer. The cloud
    layer is also responsible for the storage of the medical records and other information
    which can be accessed by both the medical practitioner or doctors and the patients.
    Further optimisations are required to implement the architecture in the near future
    and make it more scalable. Table 3 Explanation of the acronym SCALE Full size
    table 5.14 Comparison on Case Studies Table 4 shows a set of comparisons drawn
    between multiple case studies formerly presented. It is clear that there is a
    general trend that fog computing proves to be advantageous over general cloud
    computing schemes. Fog computing provides better data security and privacy, reduces
    latency, provides quick decisions and reduces transmission costs. It can also
    allow for efficient real-time analysis, quicker transmission speeds and also filter
    or suppress unwanted data. The boxes shaded in grey show the presence of the specific
    layer in the application mentioned. Table 4 Comparison of different case studies
    Full size table 6 Conclusions The drawbacks of cloud computing, such as latency,
    security and privacy, and eruption in the number of IoT devices in the past decade
    led to the rise of fog computing. Fog brought forward a new era in the world of
    technology. In this chapter, state-of-the-art methods of data collection were
    presented along with several case studies that include summarized descriptions
    of data collection methods in various fog computing applications. The optimized
    collection of useful data was essential in all of the fog applications. There
    was a common theme among the methods used in the various applications. As fog
    nodes were deployed over a large area. Data received from the IoT devices was
    analyzed by these fog nodes and processed according to the significance of the
    data. The redundant data was filtered out and depending on the workload, the computation
    of the data is either performed on the fog node itself or otherwise sent to the
    cloud for further evaluation by the fog node itself. The processed data is then
    sent back to the IoT devices based on its requested service. Case studies in a
    wide range of fields show the importance and emergence of fog computing as a supplement
    to cloud computing. The fog has been widely adopted in fields such as autonomous
    vehicles and healthcare while still being in its infancy stages in fields such
    as agriculture, air quality and emotional profile monitoring systems. Subsequently,
    fifteen case studies were discussed in this work such as Moving Vehicles, Industrial
    Automation, Underwater Data Collection Water Conservation in Agriculture, Indoor
    Air Quality Monitoring, Health Monitoring System, Telehealth Big Data and Healthcare
    4.0 related to data analytics by incorporating Cloud, Fog and IoT. In summary,
    the purpose of this chapter was to provide useful insights into the methods of
    data collection in the fog ecosystem, encapsulating recent research trends in
    data collection and to extend the scope of research and implementation in new
    and exciting domains of fog computing as it will be the part and parcel of the
    cloud computing ecosystem. References Wang, F., Liu, J.: Networked wireless sensor
    data collection: issues, challenges, and approaches. IEEE Commun. Surv. Tut. 13(4),
    673–687 (2010) Article   Google Scholar   Chen, S., Du, L., Wang, K., & Lu, W.:
    Fog computing based optimized compressive data collection for big sensory data.
    In: 2018 IEEE International Conference on Communications(ICC), pp. 1–6. IEEE Google
    Scholar   Zhu, T., Wang, X., Cheng, S., Cai, Z., Li, J.: Critical point aware
    data acquisition algorithm in sensor networks. In: International Conference on
    Wireless Algorithms, Systems, and Applications, pp. 798–808. Springer, Cham (August
    2015) Google Scholar   Cheng, S., Cai, Z., Li, J., Gao, H.: Extracting kernel
    dataset from big sensory data in wireless sensor networks. IEEE Trans. Knowl.
    Data Eng. 29(4), 813–827 (2016) Article   Google Scholar   Dong, M., Ota, K.,
    Liu, A.: RMER: Reliable and energy-efficient data collection for large- scale
    wireless sensor networks. IEEE Internet of Things J. 3(4), 511–519 (2016) Article   Google
    Scholar   Liu, F., Wang, Y., Lin, M., Liu, K., Wu, D.: A distributed routing algorithm
    for data collection in low-duty-cycle wireless sensor networks. IEEE Internet
    of Things J. 4(5), 1420–1433 (2017) Article   Google Scholar   Li, S., Da Xu,
    L., Wang, X.: Compressed sensing signal and data acquisition in wireless sensor
    networks and internet of things. IEEE Trans. Industr. Inf. 9(4), 2177–2186 (2012)
    Article   Google Scholar   de Souza, J.C.S., Assis, T.M.L., Pal, B.C.: Data compression
    in smart distribution systems via singular value decomposition. IEEE Trans. Smart
    Grid 8(1), 275–284 (2015) Article   Google Scholar   Hosseinpour, F., Plosila,
    J., & Tenhunen, H.: An approach for smart management of big data in the fog computing
    context. In: 2016 IEEE International Conference on Cloud Computing Technology
    and Science (CloudCom), pp. 468–471. IEEE (Dec 2016). Google Scholar   Al-Sultan,
    S., Al-Doori, M.M., Al-Bayatti, A.H., Zedan, H.: A comprehensive survey on vehicular
    ad hoc network. J. Netw. Comput. Appl. 37, 380-392 (2014) Google Scholar   Lai,
    Y., Zhang, L., Wang, T., Yang, F., Xu, Y.: Data gathering framework based on fog
    computing paradigm in vanets. In: Asia-Pacific Web (APWeb) and Web-Age Information
    Management (WAIM) Joint Conference on Web and Big Data, pp. 227–236. Springer,
    Cham (July 2017) Google Scholar   Ramli, M.R., Bhardwaj, S., Kim, D.S.: Toward
    reliable fog computing architecture for industrial internet of things (2019) Google
    Scholar   Yu, H., Yao, J., Shen, X., Huang, Y., Jia, M.: Data collection scheme
    for underwater sensor cloud system based on fog computing. In: International Conference
    on Security, Privacy and Anonymity in Computation, Communication and Storage,
    pp. 149–159. Springer, Cham (July 2019) Google Scholar   Kamienski, C., Soininen,
    J. P., Taumberger, M., Fernandes, S., Toscano, A., Cinotti, T. S., Neto, A. T.
    (2018, June). SWAMP: an IoT-based smart water management platform for precision
    irrigation in agriculture. In: 2018 Global Internet of Things Summit (GIoTS),
    pp. 1–6. IEEE. Google Scholar   Kamienski, C., Soininen, J. P., Taumberger, M.,
    Dantas, R., Toscano, A., Salmon Cinotti, T., Torre Neto, A.: Smart water management
    platform: Iot-based precision irrigation for agriculture. Sensors 19(2), 276 (2019)
    Google Scholar   Ibañez, J.F., Castañeda, J.E.S., Santos, J.C.M.: An IoT camera
    system for the collection of data using QR code as object recognition algorithm.
    In: 2018 Congreso Internacional de Innovación y Tendencias en Ingeniería (CONIITI),
    pp. 1–6. IEEE (Oct 2018) Google Scholar   Firdhous, M.F.M., Sudantha, B.H., Karunaratne,
    P.M.: IoT enabled proactive indoor air quality monitoring system for sustainable
    health management. In: 2017 2nd International Conference on Computing and Communications
    Technologies (ICCCT), pp. 216–221. IEEE (Feb 2017) Google Scholar   Idrees, Z.,
    Zou, Z., Zheng, L.: Edge computing based IoT architecture for low cost air pollution
    monitoring systems: a comprehensive system analysis. Des. Consid. Dev. Sens. 18(9),
    3021 (2018) Article   Google Scholar   Swan, M.: Sensor mania! the internet of
    things, wearable computing, objective metrics, and the quantified self 2.0. J.
    Sens. Actuator Netw. 1(3), 217–253 (2012) Google Scholar   Ortega, M.G.S., Rodriguez,
    L.F., Gutierrez-Garcia, J.O.: Energy-aware data collection from the Internet of
    Things for building emotional profiles. In: 2018 Third International Conference
    on Fog and Mobile Edge Computing (FMEC), pp. 234–239. IEEE (2018, April) Google
    Scholar   Kraemer, F.A., Braten, A.E., Tamkittikhun, N., Palma, D.: Fog computing
    in healthcare–a review and discussion. IEEE Access 5, 9206–9222 (2017) Article   Google
    Scholar   Paul, A., Pinjari, H., Hong, W.H., Seo, H.C., Rho, S.: Fog computing-based
    IoT for health monitoring system. J. Sens. (2018) Google Scholar   Almeida, A.,
    Fiore, A., Mainetti, L., Mulero, R., Patrono, L., Rametta, P.: An IoT-aware architecture
    for collecting and managing data related to elderly behavior. Wirel. Commun. Mob.
    Comput. (2017) Google Scholar   Dubey, H., Yang, J., Constant, N., Amiri, A.M.,
    Yang, Q., Makodiya, K.: Fog data: Enhancing telehealth big data through fog computing.
    In: Proceedings of the ASE Bigdata & Socialinformatics 2015, p. 14. ACM (Oct 2015)
    Google Scholar   Naha, R.K., Garg, S., Georgakopoulos, D., Jayaraman, P.P., Gao,
    L., Xiang, Y., Ranjan, R.: Fog computing: survey of trends, architectures, requirements,
    and research directions. IEEE Access 6, 47980–48009 (2018) Article   Google Scholar   Philips:
    Aims to relieve persistent pain with smartphone controlled devices. www.engadget.com/2014/09/17/philips-app-controlled-pain-reliever/
    (17 Sept 2014) Dubey, H., Goldberg, J.C., Abtahi, M., Mahler, L., Mankodiya, K.:
    EchoWear: smartwatch technology for voice and speech treatments of patients with
    Parkinson''s disease. In: Proceedings of the Conference on Wireless Health, p.
    15. ACM (Oct 2015) Google Scholar   Boualouache, A.E., Nouali, O., Moussaoui,
    S., Derder, A.: A BLE-based data collection system for IoT. In: 2015 First International
    Conference on New Technologies of Information and Communication (NTIC), pp. 1–5.
    IEEE (Nov 2015) Google Scholar   Tanwar, S., Vora, J., Kaneriya, S., Tyagi, S.:
    Fog-based enhanced safety management system for miners. In: 2017 3rd International
    Conference on Advances in Computing, Communication & Automation (ICACCA) (Fall),
    pp. 1–6. IEEE (Sept 2017) Google Scholar   Kumari, A., Tanwar, S., Tyagi, S.,
    Kumar, N.: Fog computing for healthcare 4.0 environment: opportunities and challenges.
    Comput. Electr. Eng. 72, 1–13 (2018) Article   Google Scholar   Download references
    Author information Authors and Affiliations Department of Information Science
    and Engineering, Ramaiah Institute of Technology, Bangalore, Karnataka, India
    S. R. Mani Sekhar, Snehil Tewari & G. M. Siddesh Department of Electronics and
    Instrumentation, Ramaiah Institute of Technology, Bangalore, India Haaris Rahman
    Corresponding author Correspondence to S. R. Mani Sekhar . Editor information
    Editors and Affiliations Department of Computer Science and Engineering, Institute
    of Technology, Nirma University, Ahmedabad, Gujarat, India Sudeep Tanwar Rights
    and permissions Reprints and permissions Copyright information © 2020 The Editor(s)
    (if applicable) and The Author(s), under exclusive license to Springer Nature
    Singapore Pte Ltd. About this chapter Cite this chapter Mani Sekhar, S.R., Tewari,
    S., Rahman, H., Siddesh, G.M. (2020). Data Collection in Fog Data Analytics. In:
    Tanwar, S. (eds) Fog Data Analytics for IoT Applications. Studies in Big Data,
    vol 76. Springer, Singapore. https://doi.org/10.1007/978-981-15-6044-6_5 Download
    citation .RIS.ENW.BIB DOI https://doi.org/10.1007/978-981-15-6044-6_5 Published
    26 August 2020 Publisher Name Springer, Singapore Print ISBN 978-981-15-6043-9
    Online ISBN 978-981-15-6044-6 eBook Packages Computer Science Computer Science
    (R0) Share this chapter Anyone you share the following link with will be able
    to read this content: Get shareable link Provided by the Springer Nature SharedIt
    content-sharing initiative Publish with us Policies and ethics Sections Figures
    References Abstract Introduction Methods of Collecting Data Optimized Collection
    of Compressive Data Management of Big Data Case Studies Conclusions References
    Author information Editor information Rights and permissions Copyright information
    About this chapter Publish with us Discover content Journals A-Z Books A-Z Publish
    with us Publish your research Open access publishing Products and services Our
    products Librarians Societies Partners and advertisers Our imprints Springer Nature
    Portfolio BMC Palgrave Macmillan Apress Your privacy choices/Manage cookies Your
    US state privacy rights Accessibility statement Terms and conditions Privacy policy
    Help and support 129.93.161.219 Big Ten Academic Alliance (BTAA) (3000133814)
    - University of Nebraska-Lincoln (3000134173) © 2024 Springer Nature"'
  inline_citation: '>'
  journal: Studies in Big Data
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Data Collection in Fog Data Analytics
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Hiriyannaiah S.
  - Matt S.G.
  - Srinivasa K.G.
  - Patnaik L.M.
  citation_count: '2'
  description: 'Background: In the recent years, due to proliferation of the internet
    and smart computing there has been progress in the areas of energy, manufacturing,
    oil and gas, smart grid and other industrial applications. The progress in these
    areas is due to the advances in the emerging areas such as Big data, cloud computing,
    fog computing and wireless networks. The advancement in these areas has paved
    the way for new industrial evolution, Industry 4.0 or smart factory or Industrial
    Internet of Things (IIoT). IIoT is made up of a collection of devices, with each
    device being able to monitor, collect, exchange, analyze and take decisions intelligently
    based on the environment through proper communication channels. IIoT consists
    of smart solutions in the fields of electricity (smart-grid), home automation
    (smart-home), supply-chains (smart-automation) and agriculture (smart-agriculture).
    The interconnection among the different smart components of IIoT is a key requirement
    for IIoT systems. We revised all the patents relating to industry 4.0 and its
    application in Internet of Services (IoS). Methods: In this paper, a novel three-layered
    architecture is proposed to handle the heterogeneity of components of IIoT, thus
    providing a way for the digital transformation of IIoT systems. Results: The paper
    also provides an overview of underlying components, principles, communication
    standards and enabling technologies for IIoT or smart factory. There is no patent
    information used in the paper for discussing the framework. Conclusion: Recent
    technologies such as cloud computing, fog computing, and big data are the key
    enablers for IIoT systems and are transforming the way in which the industrial
    systems work and operate.'
  doi: 10.2174/1872212113666190624120121
  full_citation: '>'
  full_text: '>

    "My Subscriptions Welcome David Arredondo newsletter banner Mark List Cart 0 Home
    About Publications Publish with us Marketing Opportunities Articles by Disease
    For Librarians For Authors & Editors More Recent Patents on Engineering Editor-in-Chief
    ISSN (Print): 1872-2121 ISSN (Online): 2212-4047 Back Journal Subscribe Review
    Article A Multi-layered Framework for Internet of Everything (IoE) via Wireless
    Communication and Distributed Computing in Industry 4.0 Author(s): Srinidhi Hiriyannaiah*,
    Sidddesh G. Matt, Krishnarajanagar G. Srinivasa and Lalit M. Patnaik Volume 14,
    Issue 4, 2020 Page: [521 - 529] Pages: 9 DOI: 10.2174/1872212113666190624120121
    Price: $65 Purchase PDF Abstract Background: In the recent years, due to proliferation
    of the internet and smart computing there has been progress in the areas of energy,
    manufacturing, oil and gas, smart grid and other industrial applications. The
    progress in these areas is due to the advances in the emerging areas such as Big
    data, cloud computing, fog computing and wireless networks. The advancement in
    these areas has paved the way for new industrial evolution, Industry 4.0 or smart
    factory or Industrial Internet of Things (IIoT). IIoT is made up of a collection
    of devices, with each device being able to monitor, collect, exchange, analyze
    and take decisions intelligently based on the environment through proper communication
    channels. IIoT consists of smart solutions in the fields of electricity (smart-grid),
    home automation (smart-home), supply-chains (smart-automation) and agriculture
    (smart-agriculture). The interconnection among the different smart components
    of IIoT is a key requirement for IIoT systems. We revised all the patents relating
    to industry 4.0 and its application in Internet of Services (IoS). Methods: In
    this paper, a novel three-layered architecture is proposed to handle the heterogeneity
    of components of IIoT, thus providing a way for the digital transformation of
    IIoT systems. Results: The paper also provides an overview of underlying components,
    principles, communication standards and enabling technologies for IIoT or smart
    factory. There is no patent information used in the paper for discussing the framework.
    Conclusion: Recent technologies such as cloud computing, fog computing, and big
    data are the key enablers for IIoT systems and are transforming the way in which
    the industrial systems work and operate. Keywords: Industry 4.0, industrial Internet
    of Things, smart factory, multi-layered framework, wireless communication, distributed
    computing. Graphical Abstract  Mark Item Purchase PDF Rights & Permissions Print
    Cite     We recommend Green Computing for Industrial Wireless Sensor Networks:
    Energy oriented Cross Layer Modelling Mahendra Ram et al., Recent Patents on Engineering,
    2021 Research on Fog Resource Scheduling based on Cloud-fog Collaboration Technology
    in the Electric Internet of Things Youchan Zhu et al., Recent Advances in Electrical
    & Electronic Engineering, 2021 Conceptual Framework to Mitigate Internet of Things-DDoS
    Attacks Using Fog Nodes B.B. Gupta et al., Recent Patents on Engineering, 2020
    Reliability Modeling of Wireless Sensor Networks: A Review Liudong Xing, Recent
    Patents on Engineering, 2019 The QoS Improvement of Wireless Sensor Networks with
    IEEE 802.15.4 Protocol in Three Dimensional Electric Grid Jeetu Sharma et al.,
    Recent Patents on Engineering, 2017 A Survey of Real-time Transmission Scheduling
    Algorithms for Industrial Wireless Network QIU Ying et al., Acta Automatica Sinica,
    2023 Virtual manufacturing in industry 4.0: A review Mohsen Soori et al., Data
    Science and Management, 2023 Study on thermal protection characteristics of non-enclosed
    thermal cloak Miao Yu-Zhao et al., Acta Physica Sinica, 2023 Smart capsules for
    sensing and sampling the gut: status, challenges and prospects Muhammad Rehan
    et al., Gut, 2024 Topological states and quantum effects in magnonics Wang Zhen-Yu
    et al., Acta Physica Sinica, 2023 Powered by Related Journals Recent Advances
    in Electrical & Electronic Engineering Current Alternative Energy Recent Patents
    on Mechanical Engineering View More Related Books Semi-rotary and Linear Actuators
    for Compressed Air Energy Storage and Energy Efficient Pneumatic Applications
    Waste Valorization for Value-added Products One-Dimensional Transient Flow in
    Pipelines Modelling and Simulation View More Article Metrics 12 2 2 Total citations
    2 Recent citations 0.81 Field Citation Ratio n/a Relative Citation Ratio Journal
    Information About Journal Editorial Board Current Issue Volumes /Issues For Authors
    For Editors For Reviewers Explore Articles Open Access For Visitors Counter logo
    © 2024 Bentham Science Publishers | Privacy Policy"'
  inline_citation: '>'
  journal: Recent Patents on Engineering
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: A multi-layered framework for internet of everything (Ioe) via wireless communication
    and distributed computing in industry 4.0
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - El Idrissi M.
  - Elbeqqali O.
  - Riffi J.
  citation_count: '7'
  description: The emergence of IoT (Internet of Things) systems brings several development
    opportunities to many vital fields such as healthcare, agriculture, smart building,
    smart cities, environment monitoring, and transport-logistic domain. The amount
    of data generated by IoT is increasing rapidly, which creates many research challenges
    in data management chain, furthermore, transmission of such amount of data requires
    large bandwidth, and produces significant delay. The contribution of this paper
    is to give a starting point to new searchers interested in IoT data management
    topic. Thus, we draw up a review of IoT technology, and show its impact on big
    data evolution, then show how fog computing, as a new paradigm, can contribute
    to IoT development. Firstly, RFID (Radio Frequency identification) technology
    is presented, then the integration of big data with IoT systems is discussed,
    numerous existing cloud IoT infrastructures are inventoried later, followed by
    a presentation of fog computing advantages and open challenges.
  doi: 10.1109/ISC246665.2019.9071674
  full_citation: '>'
  full_text: '>

    "IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account
    Personal Sign In Browse My Settings Help Access provided by: University of Nebraska
    - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards
    Authors Citations ADVANCED SEARCH Conferences >2019 IEEE International Smart...
    From cloud computing to fog computing: two technologies to serve iot–a review-
    Publisher: IEEE Cite This PDF Mohammed EL IDRISSI; Omar ELBEQQALI; Jamal RIFFI
    All Authors 5 Cites in Papers 225 Full Text Views Abstract Document Sections I.
    Introduction II. Works Related to Fog Computing Paradigm III. Radio Frequency
    Identification Technology (RFID) IV. Big Data Evolution and IOT V. Cloud of Things
    for Sensor Data Management Show Full Outline Authors Figures References Citations
    Keywords Metrics Abstract: The emergence of IoT (Internet of Things) systems brings
    several development opportunities to many vital fields such as healthcare, agriculture,
    smart building, smart cities, environment monitoring, and transport-logistic domain.
    The amount of data generated by IoT is increasing rapidly, which creates many
    research challenges in data management chain, furthermore, transmission of such
    amount of data requires large bandwidth, and produces significant delay. The contribution
    of this paper is to give a starting point to new searchers interested in IoT data
    management topic. Thus, we draw up a review of IoT technology, and show its impact
    on big data evolution, then show how fog computing, as a new paradigm, can contribute
    to IoT development. Firstly, RFID (Radio Frequency identification) technology
    is presented, then the integration of big data with IoT systems is discussed,
    numerous existing cloud IoT infrastructures are inventoried later, followed by
    a presentation of fog computing advantages and open challenges. Published in:
    2019 IEEE International Smart Cities Conference (ISC2) Date of Conference: 14-17
    October 2019 Date Added to IEEE Xplore: 20 April 2020 ISBN Information: ISSN Information:
    DOI: 10.1109/ISC246665.2019.9071674 Publisher: IEEE Conference Location: Casablanca,
    Morocco SECTION I. Introduction Internet of Things (IoT) is defined as all devices
    that can collect and transmit data over internet [1] . IoT systems have been evolved
    thinks to the wide spread of connectivity solutions [2] (e.g.: NFC (Near Field
    Communication), 4G and 5G cellular networks, Bluetooth, ZigBee, ANT/ANT+ networks,
    DASH7, Enocea...). Many researches are focused on energy efficiency of embedded
    sensors, others are concentrated on how to efficiently use frequency spectrum,
    but the major challenge still to conceive the appropriate abstraction, to hide
    physical heterogeneities in developer platforms, first works in this context was
    the implementation of IPV6 (Internet protocol version6) /6LoWPAN (IPV6 Low Power
    Wireless Personal Area Network) protocols [2] over material heterogeneity layers.
    The integration of IoT with the cloud generates cloud of things (CoT) [3] , this
    kind of infrastructures allow IoT systems to overcome storage and processing issues,
    but many problems related to energy consumption, and use of frequency spectrum
    still exist, what makes the use of IoT objects in the battery mode very challenging.
    Generally, this paper has two essential goals, the first one is to draw up a review
    on IoT technology, and show its impact on big data development scene, the second
    one is to show the open researches challenges of fog computing, and the ability
    of this paradigm to minimize transmission delay generated by the network. Next
    sections in this paper are organized as following: works related to fog computing
    concept are presented in section 2 , section 3 presents RFID (Radio Frequency
    Identification) technology characteristics, as being an important communication
    technology used by IoT systems, then section 4 shows the involved relationship
    between IoT and big data, also their trends by application domain, section 5 discusses
    how cloud of things (CoT) infrastructures can be used to manage Wireless Sensor
    Network (WSN) data, based on virtualization technology; an inventory of existing
    cloud IoT infrastructures is presented later in this section, section 6 discusses
    the fog computing open challenges, finally, section 7 is the conclusion. SECTION
    II. Works Related to Fog Computing Paradigm In order to better comprehend the
    fog computing paradigm, and understand points of interest of research community,
    a chronologically sorted list [4] of related works is presented below: In 2012,
    F. Bonomi et al. [5] presented the fog computing characteristics in IoT ecosystem,
    the idea of their contribution is to show the important role of fog computing
    in time-sensitive applications success. In 2013, Hang et al. [6] proposed a mobile
    fog (MF) to serve time-sensitive distributed IoT applications. With this MF, mobiles
    applications can aggregate and process data locally; proposed system supports
    load balancing. In 2014, F. Bonomi et al. [7] proposed a hierarchic distributed
    fog computing architecture, then introduced a smart traffic light system, and
    wind farm use cases to shed light on main characteristics of proposed architecture.
    In the same year, Stojmenovic and Wen [8] treated security issue in fog computing
    paradigm using a MITM (Man in The Middle) attack. In 2015, K. Lee et al. [9] made
    a survey on security and privacy issue. Then K. Saharan and A. Kumar [10] provided
    a review of fog computing as a cloud computing extension. In the same year, N.
    peter [11] summarized fog computing opportunities in relation with real time applications,
    and gave a solution to resolve network congestion and latency issues. M. Aazam
    and E. Huh [12] proposed a resource management model based on fog computing, the
    proposed model is based on a dynamic approach of resources management, it can
    be adapted to prerequisites of different cloud providers. S. Yi et al. [13] made
    a survey on fog computing challenges. V. Gazis et al. [14] proposed also an adaptive
    operation platform (AOP) to manage end to end industrial process requests. Y.
    Shi et al. [15] introduced essential characteristics of fog computing in healthcare
    domain. In 2016, Dastjerdi et al. [16] proposed a reference architecture of fog
    computing to satisfy IoT requests locally rather than escalate them to the cloud.
    M. Chiang and T. Zhang [17] provided a summary of fog computing challenges and
    opportunities focusing on networking context of IoT systems. O. Skarlat et al.
    [18] proposed a framework of fog computing to execute processing, storage, or
    networking tasks. X. Hou et al. [19] proposed a VFC (Vehicle Fog Computing) architecture
    to facilitate collaboration between end users (vehicle) using available resources
    on each vehicle. In 2017, A. Alrawais et al. [20] proposed a mechanism to improve
    the distribution of certificates revocation information among IoT devices, for
    transfer security enhancement, the mechanism is based on fog computing paradigm.
    A. yousefpour et al. [21] proposed a framework to understand, evaluate and model
    service delay in IoT-fog-cloud application scenarios, C. Puliafito et al. [22]
    discussed mobility issue in a fog environment and investigate the main challenges
    of mobility support in three scenarios, S. Khan et al. [23] provided a review
    of fog computing applications to identify common security issues. In 2018, Mahmud
    et al. [24] provided a fog computing taxonomy based on challenges and features
    factors, R. Beraldi et al. [25] proposed a distributed cooperative algorithm between
    fog computing service providers, the proposed algorithm provide mechanisms for
    better collaboration between service provider nodes in order to ensure fault tolerance
    and increase fog processing and storage resources. SECTION III. Radio Frequency
    Identification Technology (RFID) According to [26] , RFID (Radio Frequency Identification)
    is a wireless communication technology using electromagnetic field, it represents
    one of the basis of IoT (Internet of Things) systems. RFID allows IoT devices
    to monitor and interact with the environment without any physical contact. Effectively
    RFID came to ameliorate classical identification techniques such as barre codes,
    due to radio frequency characteristics and multiple advantages of RFID, especially
    contactless identification technique, improved transfer rate and storage capacity,
    as well as cheaper embedded tags. The term IoT was initially conceived to refer
    to some objects that are identifiable using RFID technology, next researches link
    IoT with many other terms like sensors, actuators, GPS devices, and mobile devices.
    Auto-ID with EPC global focused their efforts on the development of EPC (Electronic
    Product Code) model, that support usage of RFID tags in the modern market trading.
    Most of applications use RFID technology in original LF (Low Frequency) and HF
    (High Frequency) bands [27] , but with the new vision of wireless sensors and
    distributed intelligence, many RFID applications tend to adopt UHF (Ultra High
    Frequency) band in order to increase the reading range between object and RFID
    reader, and take benefit from the finer size of embedded antenna and tags. General
    characteristics of RFID standard are cited in the table I Bellow [27] : TABLE
    I General Characteristics of RFID Standard IoT technology industry chain can be
    subdivided into four parts: identification, perception, information transmission,
    and information processing, the key technologies of each link are RFID, sensors,
    wireless transmission and smart chips. Fig. 1. IoT technology industry chain Show
    All Identification: this part is mainly responsible for embedding electronic tags,
    storing static informations into physical objects for identification purpose,
    the key technology of this part is RFID. Perception: this part is responsible
    for using various sensors dynamically to collect informations in real time, and
    transmit them to the network layer, the key technology of this part is sensor.
    Information transmission: collected informations about the environment or the
    object itself are transmitted to the processing part over a wireless or wired
    network, the key technology of this part is mobile network or wireless network.
    Information processing: the massive amount of data transmitted are processed using
    platforms installed somewhere in the cloud, the key technology of this part is:
    cloud computing, mass storage, secure storage. SECTION IV. Big Data Evolution
    and IOT The amount of data generated by sensors, social media, and many other
    applications, becomes big day after day, this volume continue increasing rapidly,
    and takes many different structures, semi-structures, non-structures, and produced
    with a fast rhythm, these three characteristics (3V, volume, variety, velocity)
    define big data according to Gartner [28]. According to McKinsey Global Institute
    [29], big data is defined as the size of data sets that are a better database
    system tool than the usual tools for acquisition, storage, processing, and analyzing
    data [30]. Digital Universe study [31] defines big data as a new architecture
    that aims to extract value from gigantesque volume of data with different formats
    by using velocity, discovery, and analysis. Some other contexts [32] defines big
    data according to five essential proprieties 5V: volume (indicates the big amount
    of data generated by heterogonous sources), variety (data can take many different
    types and formats), velocity (frequency of data generation is extremely big and
    in a real time), veracity (means inexactitude of collected data), value (great
    added value brought to industrial sectors and academic field). Some big data applications
    (e.g., smart cities, smart grids, connected rails...) are normally distributed,
    this remark adds geo distribution dimension to big data proprieties [33]. According
    to [34] big data analytic doesn’t need to satisfy all 5V, on another side, some
    works like [35] add more other characteristics beyond 5V such as variability (means
    different data contexts), validity (indicates the accuracy of data), virality
    (explains data broadcasting speed between nodes), and visualization (data identification
    and interpretation for a better understanding). A. Iot and Big Data Open Trends
    The motivation to introduce big data and IoT into business IS (Information System)
    architecture is to solve specific problems of each domain. For this reason, many
    IoT and big data applications float on the surface, all these applications aim
    to decrease human intervention, and increase machine to machine interaction by
    using prediction methods and decision making techniques, these applications include
    but not limited to the following [36] [37]: Fig. 2. Example of IoT and big data
    applications Show All 1) Agriculture and Environment Monitoring: Big Data: Can
    be used in cost prediction and optimization of farm production, yield analysis,
    agricultural goods commodity pricing-trading analysis, commercial analysis, weather
    forecasts analysis, or natural disaster prevention. Internet of Things: This technology
    can be used in agricultural engine drive and maintenance, optimization of plowing
    patterns, detection of fertilization needs, detection and notification of readiness
    for harvesting, sensing moisture content (from sensors in the field and weather
    data), trunk diameter of plants, microclimate condition and humidity level detection,
    optimization of irrigation water (smart and controlled irrigation). 2) Automotive
    Manufacturing: Big Data: Can be used to predict cost and quality of manufacturing,
    analyze supply chain, analyze warranty, analyze sales and marketing. Internet
    of Things: This technology can be adopted in human capital management, analysis
    of customer sentiment, driving and management of connected vehicles, need for
    maintenance detection, service scheduling, driving history, driving emergency
    detection and response. 3) Healthcare: Big Data: Can be used in cost of care analysis,
    quality of care improvement, risk and fraud detection, analysis of patient’s sentiments,
    study and modeling of epidemics, risk analysis. Internet of Things: Connected
    objects can be used in reducing emergency room wait time, remote health and monitoring,
    ensuring the availability and accessibility of critical hardware, tracking staff
    patient and inventory, enhanced drug management, addressing chronic disease. 4)
    Transport and Logistics: Big Data: Can be used in equipment and crew logistics
    routing, sales and marketing analysis, real estate optimization, human resources
    analysis, customer sentiment analysis. Internet of Things: IoT can be applied
    in traffic optimization (from highway sensor data), traffic control and safety
    insurance, equipment performance and potential failure analysis (from on-board
    sensors), logistics management (from sensors). 5) Insurance: Big Data: Can be
    used in sales and marketing analysis, human resources analysis, risk analysis,
    customer sentiment analysis. Internet of Things: This technology has several applications
    such as property inspections in the event of a damage claim using drones, tracking
    customers using Fitbit, health monitoring for better insurance plan. 6) Banking
    Area: Big Data: Can be used to predict customer expectations in order to provide
    better financial offering, financial analysis, fraud detection, credit worthiness,
    human resources management, and real estate management and optimization. Internet
    of things: IoT is used in banking on wearable applications, pumping up payment,
    smart branching out to connected cars, block chain based smart contracts, banking
    at home (payment using voice commands). 7) Communication Domain: Big Data: Can
    be used in pricing strategies and finance management, customer support and service
    analysis, marketing analysis, supply chain management, logistics and process optimization,
    regulatory compliance, real estate optimization, human capital management, analysis
    of social data. Internet of Things: IoT can be applied in mobile device usage
    monitoring, network quality and availability monitoring (using sensors), network
    fraud detection, extended network management and optimization using social media
    sensors. 8) Consumer Packaged Goods Management: Big Data: Can be used in sales
    and marketing analysis, manufacturing and logistics monitoring, consumer trends
    prediction, and risk analysis. Internet of Things: IoT can be applied in monitoring
    of promotional effectiveness (through social media and in-store sensors), supply
    chain monitoring, state supervision of manufactured goods during transport, product
    placement in retail. 9) Education and Research: Big Data: Can be applied in financial
    analysis of institution or facility, staffing and human capital management, alumni
    profiling, and donation patterns management. Internet of Things: IoT can be applied
    in collecting and analyzing data of students at risk (using sensor), collecting
    data for research purposes using sensors, facilities monitoring, and utilization
    optimization. 10) High Tech and Industrial Manufacturing: Big Data: Can be used
    in supplier and distributor analysis, logistics management, quality of manufacturing
    and warranty analysis. Internet of Things: IoT can be applied in shop-floor production
    and quality monitoring, quality of sub assembly monitoring, product failure and
    pending failure management, automated service requests. 11) Media and Entertainments:
    Big Data: Can be applied in viewer preferences analysis, media channel popularity
    analysis, advertising sales analysis, marketing promotion prediction, customer
    sentiment analysis. Internet of Things: IoT can be used in viewing habit supervision
    (from set top boxes), monitoring of customer behavior at entertainment venues.
    12) Oil and Gas: Big Data: Can be used in drilling exploration costs analysis,
    potential exploration sites, human resources and logistics optimization. Internet
    of Things: IoT can be applied to collect data during drilling exploration operations
    (failure prevention), remote oil well monitoring, tanks temperature and water
    pressure monitoring, remote area pipeline monitoring. 13) Pharmaceuticals: Big
    Data: Can be used in clinical trials including drug interaction research, test
    subject outcome analysis, research and production financial analysis, sales and
    marketing analysis. Internet of Things: IoT can be applied in collecting data
    for clinical research goal using sensors, social behavior and disease tracking,
    genomics data collection, monitoring of logistics chain. 14) Utilities: Big Data:
    Can be used in logistics optimization, grid power delivery analysis, optimizing
    customer energy utilization, human resources analysis. Internet of Things: IoT
    can be used in grid status optimization using smart meters, pro-active maintenance
    and optimization SECTION V. Cloud of Things for Sensor Data Management Cloud of
    things (CoT) refers to infrastructures that are able to perform sensor data management
    homogenously, disregarding manufacturers differences. Data management functionalities
    are executed based on cloud capacities such as storage, processing, networking,
    and virtualization technology; cloud of things concept is introduced in the early
    research [38] , this work identifies the following advantages and benefits of
    CoT infrastructures: CoT manages sensor networks, which are organized on virtualized
    and non-virtualized sensor groups deployed from physical sensors, this deployment
    is executed using cloud performances, what makes it fast and totally automated,
    in order to avoid redundant data capture, and offer more efficacy and effectiveness.
    Exploitation of cloud IoT infrastructures doesn’t require any technicity or high
    level of physical sensor and setting knowledge. Systems of physical sensors have
    to operate in harsh environments, so fault tolerance is insured by cloud IoT infrastructures.
    Cloud of things infrastructures take advantage of power processing and storage
    capacity offered by cloud data centers. Cloud IoT infrastructures offer more scalability,
    they are not limited to predefined applications. Rapid elasticity, and payment
    per use are two characteristics that make the cloud very suitable for IoT generated
    data management. Cloud IoT infrastructures can organize collected data, and present
    them in a user-friendly, readable, and meaningful way. CoT infrastructures are
    beneficial for IoT systems because of their cost-effectiveness and minimal maintenance
    cost. Cloud of things service model can be private where the customers choose
    between a panoply of models such as IaaS (Infrastructure as a service), IoTaaS
    (IoT as a service), or PaaS (Platform as a service), each model can support data
    analysis and visualization or not, and the service is free or requires some fees.
    the table II gives an inventory of some existing cloud of things infrastructures
    [39] [40] : TABLE II Comparison of Some Existing Cloud of Things Platforms Generally,
    cloud of things infrastructures make difference in case of time insensitive applications,
    but when we talk about new emergency systems, that require minimal of latency
    between request and response, we need to implement the new computing approach
    known as fog computing. SECTION VI. Open Challenges of Fog Computing as an Extension
    of Cloud Computing Fog Computing or edge computing is a middleware founded by
    Cisco [41] in 2012 to extend cloud computing resources, by bringing them closer
    to the objects and data sources. generally, each device that can be connected
    to the internet directly or via central gateway, and have its own processing and
    storage capacity can be a fog computing node [42] [43] , open fog consortium defined
    fog computing [44] [45] as “a system-level horizontal architecture that distributes
    resources and services of computing, storage, control and networking anywhere
    along the continuum from Cloud to things”. The integration of IoT with fog computing
    creates fog as a service concept (FaaS) that allows service providers to build
    a group of fog nodes composed of servers, routers, bridges, and arrays of disk
    storage, these resources create a temporary bridge between cloud computing data
    centers and smart objects. Fig. 3 illustrates how a global architecture, composed
    of cloud computing system, fog computing infrastructure, and smart objects layers,
    looks like. Fig. 3. Fog computing, cloud computing and connected objects layers.
    Show All The fog computing paradigm is developed in many works [46] [47] [48]
    [49] to respond to IoT requirements and exceed the classical cloud model limitations
    in terms of: Management of the giant volume of data: the amount of data actually
    generated is in the Exabyte range; it is expected that 50.1 billion objects will
    be online in 2020 [50] [51] , the density of these objects is increasing continuously,
    what makes traditional cloud model unable to process the colossal amount of data
    generated by smart objects. Mobility management: Classical cloud computing model
    is not designed to manage object’s mobility, such as smart vehicles and connected
    trains, and support highly geo-distributed systems like wireless sensor networks
    (WSN), this feature introduces a new dimension to big data known as geo distribution,
    with this dimension, generated data are processed homogenously in a single unit.
    Significant latency produced by the network while transmitting data from the objects
    to the cloud: The time required for a round-trip is not negligible, it can be
    problematic in time-sensitive applications. A time delay of one second can lead
    to undesirable results in disaster management and content delivery applications,
    this delay can be occurred when critical connected devices send their data in
    order to be processed, then wait a significant time for response, before giving
    their own actions. Limited bandwidth of transmission channels: If all connected
    objects send their generated data at the same time to the cloud, in order to be
    stored or processed, transmission flow will be gigantesque resulting network congestion,
    this amount of network traffic will be difficult to filter, or to secure. When
    all objects are online, even IPv6 addressing system cannot provide the necessary
    IP addresses, so the introduction of the intermediate nodes (proxies) provide
    maximum IP address summarization. Generated data are confidential, in order to
    improve security, fog computing adds an additional security layer composed of
    servers, routers, or firewalls to store data on controlled infrastructures within
    the company. These cloud computing limitations can be overcome using fog computing
    approach, however, many challenges are still occupying researchers, these challenges
    aim to improve fog computing performance in many levels like: Real time processing,
    management of big number of IoT objects, IoT devices geo distribution, latency
    minimization, security enhancement, high availability of fog computing services,
    integrity and privacy improvement, processing/storage/networking enhancement.
    Fog computing open challenges are summarized in Fig. 4 . Fig. 4. Fog Computing
    open challenges Show All The famous cloudlet [52] is a complete implementation
    of fog computing model, cloudlet is based on adding resources closer to the mobile
    applications and data sources, to manipulate a portion of networking, storage
    and processing requests instead of destining them all to the cloud, through user
    geolocation. Hua-Jun Hong et al. [53] conceived a fog computing platform for data
    analysis over IoT devices and edge distributed servers, as well as data center
    servers, the proposed platform is based on SSE algorithm that maximizes the probability
    of an edge node to process a given request, in order to minimize network latency
    that may take place. The following is a brief discussion about fog computing open
    challenges: Real time processing: some applications (e.g., gaming, video, streaming)
    require real time delivery, fog computing needs to support real time services.
    Management of big number of IoT devices: It was expected that 50.1billion of connected
    objects will be online in2020, so fog computing resources have to be installed
    closer to end devices and services, and support them all. Geo-distributed IoT
    devices and applications: IoT devices and a variety of applications are widely
    distributed, fog computing needs to provide geo-distributed computing and storage
    resources. Latency minimizing: some applications are time sensitive (e.g., communication
    inter smart vehicles, emergency control systems...), fog computing infrastructure
    needs to provide mechanisms to minimize latency that can be created by the network.
    Security and privacy enhancement: data generated by IoT are confidential, the
    challenge of fog computing is to provide necessary encryption/decryption mechanisms,
    and powerful certificate distribution/revocation methods to protect data from
    being stolen or altered. High availability: devices will be more geo-distributed,
    and implemented in many sensitive fields, where the service needs to be available
    permanently, the most challenge of fog computing is to provide infrastructures
    to avoid service interruption. Integrity and privacy improvement: another issue
    of fog computing is to preserve user’s privacy, since collected data are more
    sensitives, so enhancing confidentiality of generated data is a big research challenge.
    Processing, networking, and storage enhancement: the best service delivery requires
    more power of processing, optimized networking service, and improved storage conditions.
    Parallel processing is one of the techniques adopted by fog computing algorithms
    in order to work with large scale IoT applications. SECTION VII. Conclusion The
    IoT topic interest is increasing continuously with a great enthusiasm, offering
    various opportunities and possibilities to respond to requirements of a wide range
    of businesses, this adaptation faces complexity caused by heterogeneity of IoT
    concept. Furthermore, the rapid rise of real-time data, generated by IoT systems,
    plays a major role in big data technology evolution, notably new methods for data
    analysis, and integration of machine learning and deep learning algorithms in
    making decision process. We opened this paper with a list of fog computing related
    works and contributions sorted chronologically, then we introduced RFID as an
    essential communication technology used by IoT systems, then we talked about big
    data as a direct result of IoT revolution, later, we shown cloud computing limitations
    in terms of latency, consequently fog computing paradigm was appeared, as a new
    approach to extend cloud computing instead of substitute it. We closed this paper
    with a discussion about fog computing open challenges. Authors Figures References
    Citations Keywords Metrics More Like This Guest Editorial Special Section on Cloud
    Computing, Edge Computing, Internet of Things, and Big Data Analytics Applications
    for Healthcare Industry 4.0 IEEE Transactions on Industrial Informatics Published:
    2019 Integration of Cloud Computing with Internet of Things for Network Management
    and Performance Monitoring 2020 18th International Conference on ICT and Knowledge
    Engineering (ICT&KE) Published: 2020 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved."'
  inline_citation: '>'
  journal: 5th IEEE International Smart Cities Conference, ISC2 2019
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'From cloud computing to fog computing: Two technologies to serve iot-a review-'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Idrissi M.E.
  - Elbeqqali O.
  - Riffi J.
  citation_count: '9'
  description: Many vital domains such as smart building, smart cities, healthcare,
    agriculture, and environment monitoring, take benefits from IoT (Internet of Things)
    technology emergence. Recently, the amount of IoT generated data becomes huge,
    creating many research challenges in data management topic, in another side, transmission
    of these amounts of data requires large bandwidth, and generate significant delay.
    From this vision, we prepare this paper to help new searchers interested in IoT
    data management topic, to find out a good starting point. For this reason, we
    shed light on IoT technology, and show its relationship with big data evolution
    scene, then show the importance of the new paradigm known as fog computing to
    overcome most of these problems. At first, we introduce the five elements of an
    IoT object and common communication models used by smart objects, then we discuss
    comparison of hardware IoT platforms, and recommendations to take into consideration
    while choosing a hardware IoT platform, in the next pages we introduce cloud IoT
    infrastructures, followed by a presentation of fog computing advantages and challenges.
  doi: 10.1109/ICDS47004.2019.8942304
  full_citation: '>'
  full_text: '>

    "IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account
    Personal Sign In Browse My Settings Help Access provided by: University of Nebraska
    - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards
    Authors Citations ADVANCED SEARCH Conferences >2019 Third International Conf...
    A Review On Relationship Between Iot– Cloud Computing – Fog Computing (Applications
    And Challenges) Publisher: IEEE Cite This PDF Mohammed El Idrissi; Omar Elbeqqali;
    Jamal RIFfi All Authors 7 Cites in Papers 328 Full Text Views Abstract Document
    Sections I. Introduction II. Five Essential Elements of an Iot Object III. Iot
    Communication Models IV. Hardware Iot Plateforms V. Cloud Iot Infrastructure Show
    Full Outline Authors Figures References Citations Keywords Metrics Abstract: Many
    vital domains such as smart building, smart cities, healthcare, agriculture, and
    environment monitoring, take benefits from IoT (Internet of Things) technology
    emergence. Recently, the amount of IoT generated data becomes huge, creating many
    research challenges in data management topic, in another side, transmission of
    these amounts of data requires large bandwidth, and generate significant delay.
    From this vision, we prepare this paper to help new searchers interested in IoT
    data management topic, to find out a good starting point. For this reason, we
    shed light on IoT technology, and show its relationship with big data evolution
    scene, then show the importance of the new paradigm known as fog computing to
    overcome most of these problems. At first, we introduce the five elements of an
    IoT object and common communication models used by smart objects, then we discuss
    comparison of hardware IoT platforms, and recommendations to take into consideration
    while choosing a hardware IoT platform, in the next pages we introduce cloud IoT
    infrastructures, followed by a presentation of fog computing advantages and challenges.
    Published in: 2019 Third International Conference on Intelligent Computing in
    Data Sciences (ICDS) Date of Conference: 28-30 October 2019 Date Added to IEEE
    Xplore: 27 December 2019 ISBN Information: DOI: 10.1109/ICDS47004.2019.8942304
    Publisher: IEEE Conference Location: Marrakech, Morocco SECTION I. Introduction
    “Things are any identifiable physical object independent of the technology that
    is used for identification or providing status information of the objects and
    its surroundings. Internet in this case refers to everything that goes beyond
    an extranet, thus requiring access to information for more than a small group
    of people or businesses”, according to the extract above from [1], Internet of
    Things (IoT) is a term that is divided on two parts: Things refers to objects
    in the physical world, that can collect and transmit data to provide information
    about the object itself or about its surrounding, and internet refers to extra
    infrastructure that insure connection and interaction between objects themselves
    or objects and users. Many industrial and domestic applications of IoT are emerged
    thanks to several factors, such as development of RFID (Radio Frequency Identification)
    technology, and its embeddedness with objects, without forget the wide spread
    of connectivity solutions [2] (e.g.: NFC (Near Field Communication), 4G and 5G
    cellular networks, Bluetooth, ZigBee, ANT/ANT+ networks, DASH7, Enocea…). Some
    researchers are concentrated on how to efficiently use frequency spectrum, others
    are focused on energy efficiency used by embedded sensors, but one of the biggest
    challenges is to provide the appropriate abstraction conception, in order to hide
    physical heterogeneities in developer and manufacturer platforms, first tries
    in this context was the IPV6(Internet protocol version6)/6LoWPAN (IPV6 Low Power
    Wireless Personal Area Network) implementation [2] over material heterogeneity
    layers. The integration of IoT with the cloud to construct cloud of things (CoT)
    is proposed to resolve storage and processing issues [3] that IoT systems suffer
    from, but still some persistent issues related to energy consumption, and limited
    processing. This paper has two important objectives: Shed the light on IoT technology
    including models and hardware platforms requirements for project prototyping.
    Show classical cloud computing model limitations, especially delay generated by
    the network, and the ability of fog computing model to overcome most of these
    limitations. The rest of this paper is organized as follows: Essential elements
    of an IoT object are presented in section 2, then IoT communication models are
    defined in section 3, section 4 gives a comparison of IoT hardware platforms,
    and some points that should be taken into account while choosing hardware platform
    for IoT project prototyping, section 5 shows how virtualization technology is
    used in Wireless Sensor Network (WSN)-cloud integration in order to build cloud
    of things (CoT) infrastructures, section 6 presents the major role of Fog computing
    to minimize latency that can be occurred, finally, section 7 is the conclusion.
    SECTION II. Five Essential Elements of an Iot Object The Fig. 1 bellow shows the
    essential elements of an IoT object, it is a combination of the following five
    components: Identification of items in supply chain using EPC (Electronic Product
    Code) or uCode (unique code) system. Sensing and gathering data related to a specific
    environment and send it back to a data warehouse, database, or cloud in order
    to be analyzed, to take specific action based on required services. Sensing element
    can be smart actuators, wearable sensing devices, embedded sensors, or RFID tags.
    Communication between all of the heterogeneous devices to provide smart services,
    commonly, IoT objects operates in low power, common protocol used in IoT communication
    are RFID (Radio Frequency Identification) that is defined by [4] as a wireless
    communication technology using electromagnetic field, it represents one of the
    basics of IoT (Internet of Things) systems. RFID allows IoT devices to monitor
    and interact with the environment without any physical contact, Advanced long
    term evolution (LTE), NFC (Near Field Communication), Bluetooth, Wi-Fi, ZigBee,
    and Ultra-Wide-Band for proximity services. Computation can be divided into two
    categories, one deals with processing and command execution, this category is
    represented by processing unit, it means hardware and software ability like CPU
    (Central Processing Unit), microcontroller, FPGA (Field- Programmable Gate Array),
    Arduino, Raspberry pi, and software capability such as embedded operating system
    (OS) that represents the brain of the object, the other deals with processing
    and storage, this category is represented by cloud unit where real time processing
    can be performed, and big data storage is ensured. Services element is divided
    into four major classes: identity related services, in this class, each abstraction
    of physical objects requires identification of those objects. Information aggregation
    services, this class collects and summarizes sensed values that need to be processed
    and reported to the IoT application. Collaborative aware services, this class
    uses data obtained by information aggregation service class to make the right
    decision. Ubiquitous services, this class provides collaborative services according
    to 3A (Anyone, Anytime, Anywhere) principle. Semantics element means ability to
    extract knowledge smartly by different machines to provide required services.
    Fig.1. Five essential elements on a smart object [26]. Show All SECTION III. Iot
    Communication Models After presenting the five essential components of an IoT,
    now let’s focus our discussion on how operationally IoT communicate in light of
    manufacturer differences, communication models are described in RFC 7452: Device
    to device communication: Or non-IP things, in this architecture, a direct communication
    link is established between two or more devices, using a specific non-IP communication
    protocol such as z-wave, BLE, or ZigBee, this model is the simplest one, because
    it doesn’t require any additional infrastructure to be installed between objects,
    in terms of advantages, this model present a built–in security and trust mechanisms,
    in another side most of compatibility problems are overcome. Device to gateway
    communication: or typically, device to application layer gateway, in this model,
    IoT devices have to be connected to a central local gateway device in order to
    reach cloud services, the central gateway node could be a smartphone running an
    application to communicate with the devices and relay data to the cloud services.
    This is the common used model by most of manufacturers, because it offers many
    advantages like providing an additional security layer and data or protocol translation.
    Device to cloud communication: In this communication model, devices integrate
    required protocols and many advanced functionalities to directly communicate with
    the cloud service platform, in this case, the end user uses sophisticated devices
    with extended capabilities beyond native features. In order to resolve interoperability
    issue that can be occurred in this model, cloud service providers and IoT objects
    must be from the same seller. Back end data sharing communication model: This
    architecture is suitable for sharing sensor and IoT data in order to be accessed
    by authorized third parties, otherwise, this conception is an extension of single
    device to cloud model, here a user can extract data from a cloud service provider
    and send it to another service provider, in order to be aggregated and analyzed.
    In this case interoperability between cloud service providers is required. SECTION
    IV. Hardware Iot Plateforms With the IoT concept, everything can be smart and
    connected to the internet using embedded OS, in this context, big IT companies
    and IoT hardware developers propos a panoply of hardware and software platforms,
    as well as several dedicated development tools for prototyping IoT projects, these
    platforms provide different performances in terms of processing, internal storage,
    amount of RAM (Random Access Memory), and other features such as Wi-Fi, Ethernet
    interfaces, Bluetooth, and other pins for sensors connection. We can distinguish
    between two types of commercial hardware devices, including microcontrollers and
    single-board-computers (SBC), both are designed around SoC (System-On-a-Chip)
    systems, these systems offer more capabilities like processing, storage, and connectivity
    on a single printed electronic board. Microcontroller SoC provides processors
    with cores, and multiple quantities of RAM, as well as flash and electrically
    erasable read only memory (EEPROM) to store customizable programs that should
    run on microcontroller. For external connectivity, microcontroller SoCs are provided
    with multiple sizes of analog and digital types of General Purpose Input/output
    (GPIO) pins, these connectors are normally designed for compatible extensions,
    the fact that some generations of microcontroller SoCs don’t have their embedded
    connectivity, GPIO are used to add an Ethernet or Bluetooth ports by means of
    third party shields as an option. Table. I below [27] provides a comparison of
    technical specifications between Arduino Uno, Practical electron, and Espressif
    Systems ESP8266-01 platforms, in terms of data acquisition and control, data processing
    and storage, connectivity, recommended power supply, and other generic characteristics:
    Table I Technical Specifications Comparison Between Arduino Uno, Particle Electron,
    Espressif Systems Esp8266-01. The modern boards can be powered up using one of
    these methods: With USB or micro USB cables using computer, or by using external
    power source providing 5V 500 mA or 5V 100 mA, depending on if the USB is enumerated
    by the computer or not. Using AC to DC adapter plugged into the barrel connector,
    this source provides 9-12V for Arduino Uno. Using 12V DC voltage applied on VIN
    pin for Arduino Uno and particle boards, and 3.3V-300mA applied on VCC pin for
    ESP8266-01 board. As we mentioned above, customize programs are stored in flash
    or EEPROM memory, C is considered the key programming language for embedded IoT
    devices, as for C++ is most likely used for Linux complex implementations, Java
    is the overall most popular programing language, meanwhile Arduino integrated
    development environment (IDE) is compatible for Arduino customize programs development.
    Python language is well suited for data intensive applications, it is supported
    by MicroPython’s PyBoard and WeIO boards, while JavaScript is supported by some
    other development environments such as Tessel, and particle IoT platform. SBCs
    are a sophisticated and improved version of microcontroller boards, they offer
    more capabilities beyond those offered by microcontroller boards type, such as
    connecting keyboards, mice, screens. Processor capability is also improved to
    32bits - GHz ARM instead of 8bits - KHz or MHz for microcontroller type, SBCs
    offer more amount of memory (gigabyte) and more connectivity options like Bluetooth,
    Wi-Fi, and GPS (Global Positioning System). SBCs can be powered up using micro
    USB, or external source plugged in barrel connector. Table. II below summarizes
    the comparison of technical specifications between the three popular SBCs: Raspberry
    Pi 3, BeagleBone Black and DragonBoard, in terms of data acquisition and control,
    data processing and storage, connectivity, recommended power supply, and other
    generic characteristics. Table II Technical Specifications Comparison Between
    Raspberry Pi 3 Model – B -, Beagleb-One Black, Qualcomm Dragonbo-Ard 410C SBC
    capabilities can be extended by adding more stackable boards known as hats in
    Raspberry Pi, and caps in BeagleBone Black [27]. SBC is similar to mini-PC that
    run an embedded operating system typically Linux distribution, consequently several
    programming languages are available for embedded applications development that
    work with sensors, actuators, and other attached devices. Choosing a platform
    is related to the specific environment and the context of implementation, off-the-shelf
    hardware may be the adequate choice to use in the beginning, but later, the following
    requirements should be taken into consideration when choosing a hardware platform:
    Data acquisition, processing, and storage capabilities: this is the most important
    requirement, it reflects the hardware capacities, like processor speed, amount
    of RAM offered, instruction length, all these characteristics are impacted with
    data sampling frequency, and ability to compress data before storage. it reflects
    also the number of sensors that can be connected and managed by the platform.
    Power supply and consumption: while choosing a platform for project prototyping,
    it is recommended to pay attention to the number of managed sensors, and transmission
    range and rate, because it impacts energy consumption, especially when the device
    is powered by batteries. Physical dimensions and design: physical appearance of
    the device is another point to which attention should be paid, it impacts operating
    environment and installation conditions, for example, if the device need to operate
    in a harsh environment, it needs to be covered, resistant to water, dirt, and
    shock. Connectivity requirements: this is another important point, it impacts
    the signal range and power consumption. Chosen Platform may provide multiple connectivity
    ways like Wi-Fi, Bluetooth, or wired Ethernet, project owner can choose between
    integrated connectivity options, or can adds them using extension boards or modules.
    Security requirement: make sure that the platform has enough power processing
    and memory to encrypt and decrypt data in the transmission/reception process.
    This requirement allows to connect the hardware safely in the network. Simplicity
    of deployment and use: project prototyping needs to be quick and easy, project
    owner doesn’t need to be worry about platform complexity, manuals, documentations,
    and development tools have to be simple and delivered by the manufacturer. Cost
    requirement: cost requirement includes hardware and associated components like
    sensors, replacement parts, documentations, maintenance cost, and licensing fees
    of some drivers or software. SECTION V. Cloud Iot Infrastructure Wireless sensor
    infrastructures take advantages from virtualization technology and cloud proprieties,
    wireless sensor virtualization platform is defined as a system able to exploit
    and manage wireless sensors homogeneously, regardless of manufacturers physical
    differences. Cloud IoT infrastructure terminology is introduced by [10], in this
    context and according to [10], advantages of cloud IoT infrastructures can be
    listed as follows: Cloud IoT systems avoid redundant data capture, which offer
    more efficacy and effectiveness. Cloud IoT systems are based on virtual sensor
    and virtual sensor group techniques, they are performed using cloud performances,
    what makes them fast and totally automated. Exploitation of cloud IoT infrastructures
    doesn’t require any technicity or high level of physical sensor and setting knowledge.
    Scalability of cloud IoT infrastructures, they are not limited to predefined applications.
    Systems of physical sensors have to operate in harsh conditions, then fault tolerance
    is insured by cloud IoT infrastructures. Cloud IoT infrastructures take benefits
    from power processing and storage capacity offered by cloud data centers. Rapid
    elasticity, and payment per use are two characteristics that make the cloud very
    suitable for IoT generated data management. Cloud IoT infrastructures can organize
    collected data, and present them in a user-friendly, readable, and in a meaningful
    way. Cloud IoT infrastructures are beneficial because of their cost-effectiveness
    and minimal cost of maintenance. Cloud IoT infrastructures combine contextual
    systems models, event-oriented services models, that support collection, transmission,
    processing, analysis, storage, and contextual information delivery. The main objective
    of cloud IoT infrastructures is to allow connected nodes to dynamically and transparently
    exchange data with information system, in spite of physical differences imposed
    by manufacturers. Cloud IoT services can be public, private, or hybrid depends
    on offers and service providers. Customers can choose in private offers between
    a range of proposed models (Infrastructure as a service, IoT as a service, or
    Platform as a service), depending on if the requested models support data analysis
    and visualization options or if the services are free or paid. Generally, cloud
    IoT infrastructures are beneficial in case of time insensitive applications, but
    when we talk about new emergency systems, that require minimal of latency between
    request and response, we need to implement the new computing approach known as
    fog computing. SECTION VI. Fog Computing is an Extension of Cloud Computing to
    Serve Iot Fog computing or edge computing is a middleware layer founded by Cisco
    [11] in 2012 to extend cloud computing resources, by bringing them closer to the
    objects and data sources. generally, each device that can be connected to the
    internet, and has its own processing and storage capacity can be a fog computing
    node [12] [13], open fog consortium defined fog computing [14] [15] as: “a system-level
    horizontal architecture that distributes resources and services of computing,
    storage, control and networking anywhere along the continuum from Cloud to Things”.
    A brief reading in this definition allows us to extract the following fog computing
    properties: firstly, it is a horizontal system, it means that constitutive components
    are in the same operational level, and communication flow between these elements
    vehicles in a horizontal plan, also constitutive resources and services are geographically
    distributed, in order to build a bridge between cloud computing resources and
    objects. Fig. 2 illustrates how a global architecture, composed of cloud computing
    system, fog computing infrastructure, and sensors/actuators layer, looks like.
    Fig. 2. IoT environnement architecture. Show All Several works like [16] [17]
    [18] [19] have developed fog computing paradigm to respond to IoT requirements
    and overcome limitations of cloud computing model, these limitations are summarized
    as following: Management of the giant volume of data: the amount of data actually
    generated is in the Exabyte range; it is expected that 50.1 billion objects will
    be on line in 2020 [20] [21], the density of these objects is increasing continuously,
    what make traditional cloud model unable to process the colossal amount of object
    generated data. Mobility management: classical cloud computing model is not designed
    to manage object’s mobility, such as smart vehicles and connected trains, and
    support highly geo-distributed systems like wireless sensor networks (WSN), this
    feature introduces a new dimension to big data known as geo distribution. With
    this dimension, generated data are processed homogenously in a single unit. Significant
    latency produced by the network while transmitting data from the objects to the
    cloud: the time required for a round-trip is not negligible, it can be problematic
    in time-sensitive applications. A time delay of one second can lead to undesirable
    results in case of disaster management and content delivery applications, this
    delay can be occurred when critical connected devices send their data in order
    to be processed, wait a significant time before giving their own actions. The
    total latency is calculated in eq. (1): Tdc+Ttr+Tcd=Latency  (1) View Source Where:
    Tdc is the data transfer delay from object to cloud, Ttr is the data processing
    delay in the network nodes, and Tcd is the data transfer delay from cloud to object.
    So as to have a delay comparison between cloud and fog model, let’s take Table.
    III bellow [22] [23] which illustrates variation intervals of accepted delays
    for each data utilization, these delays start from milliseconds until months or
    years. The first interval (milliseconds - couple of seconds) is suitable for real
    time inter machine data interaction, latency is not accepted in this level, because
    data can be used by critical protection and control systems. The next two intervals
    (seconds-couple of minutes and minutes-days) support both human to machine and
    machine to machine interactions, here, data can be used in visualization and reporting
    applications. The last delay interval (days-months or years) represents longterm
    data stored in the cloud, in order to be used for analysis and business intelligence
    processes, using human to machine interaction. Table III Comparison of Data Utilizations
    and Delays Limited bandwidth of transmission channels: If all connected objects
    send their generated data at the same time to the cloud for processing or storage,
    transmission flow will be gigantesque resulting network congestion, this amount
    of network traffic will be difficult to filter, or to secure. When all objects
    are online, even the IPv6 addressing system cannot provide the necessary IP addresses,
    so the introduction of the intermediate nodes provide maximum IP address summarization.
    Generated data are confidential, in order to improve security, fog computing adds
    an additional security layer composed of servers, routers, or firewalls to store
    data on controlled infrastructures within the company. All these cloud computing
    limitations can be overcome using fog computing approach, however, many challenges
    are still occupying researchers, these challenges aim to improve fog computing
    performances in many levels like: Real time processing, management of big number
    of IoT objects, IoT devices geo distribution, latency minimization, security enhancement,
    high availability of fog computing services, integrity improvement, processing/storage/networking
    enhancement. Fog computing challenges are summarized in Fig. 3. Fig. 3. Fog Computing
    challenges. Show All Most of works that aimed to propose a fog computing reference
    model, had encountered the distance constraint between IoT users and classical
    cloud services hosting locations. The main idea of almost proposed models is to
    add nodes and servers between data sources and network core, as so to process
    a portion of temporary storage and analysis requests, instead of sending them
    all to the cloud, thus we relax network bandwidth and cloud resources. The famous
    cloudlet [24] is a complete implementation of fog computing model, cloudlet is
    based on adding resources closer to the mobile applications and data sources,
    to manipulate a portion of networking, storage and processing requests instead
    of destining them all to the cloud through user geolocation. Hua-Jun Hong et al.
    [20] conceived a fog computing platform for data analysis over IoT devices and
    edge distributed servers, as well as data center servers, the proposed platform
    is based on SSE algorithm that maximizes the probability of an edge node to process
    a given request, in order to minimize network latency that may take place. SECTION
    VII. Conclusion The great progress of IoT systems, and the exponential rise of
    real-time data play a major role in the evolution of big data discipline, especially
    new methods for data analysis, and integration of machine learning algorithms
    in making decision process. In this paper, a pyramidal demarche is followed, we
    introduced the five essential elements of a smart object, then we compared some
    hardware IoT platforms, and gave requirements to put in mind while choosing hardware
    platform for project IoT prototyping, later, we shown cloud computing limitations,
    notably latency issue, consequently fog computing paradigm is emerged, as a new
    computing model to bring resources closer to end devices and data sources, this
    model came to extend cloud computing, not to replace it. Authors Figures References
    Citations Keywords Metrics More Like This Internet of Things Platform for Real
    Time Automated Safety System Based on Multi Sensor Network and Bluetooth Module
    2022 5th Conference on Cloud and Internet of Things (CIoT) Published: 2022 A Low-Power
    High-Performance Sensor Node for Internet of Things 2018 Second International
    Conference on Intelligent Computing and Control Systems (ICICCS) Published: 2018
    Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT
    OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES
    PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678
    4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact
    Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics
    Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE
    is the world''s largest technical professional organization dedicated to advancing
    technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: 2019 3rd International Conference on Intelligent Computing in Data Sciences,
    ICDS 2019
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: A Review On Relationship Between Iot- Cloud Computing - Fog Computing (Applications
    And Challenges)
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Stamatescu G.
  - Dragana C.
  - Stamatescu I.
  - Ichim L.
  - Popescu D.
  citation_count: '9'
  description: Large scale monitoring systems, enabled by the emergence of networked
    embedded sensing devices, offer the opportunity of fine grained online spatio-temporal
    collection, communication and analysis of physical parameters. Various applications
    have been proposed and validated so far for environmental monitoring, security
    and industrial control systems. One particular application domain has been shown
    suitable for the requirements of precision agriculture where such systems can
    improve yields, increase efficiency and reduce input usage. We present a data
    analysis and processing approach for distributed monitoring of crops and soil
    where hierarchical aggregation and modelling primitives contribute to the robustness
    of the network by alleviating communication bottlenecks and reducing the energy
    required for redundant data transmissions. The focus is on leveraging the fog
    computing paradigm to exploit local node computing resources and generate events
    towards upper decision systems. Key metrics are reported which highlight the improvements
    achieved. A case study is carried out on real field data for crop and soil monitoring
    with outlook on operational and implementation constraints.
  doi: 10.1109/MED.2019.8798504
  full_citation: '>'
  full_text: '>

    "IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account
    Personal Sign In Browse My Settings Help Access provided by: University of Nebraska
    - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards
    Authors Citations ADVANCED SEARCH Conferences >2019 27th Mediterranean Confe...
    IoT-Enabled Distributed Data Processing for Precision Agriculture Publisher: IEEE
    Cite This PDF Grigore Stamatescu; Cristian Drăgana; Iulia Stamatescu; Loretta
    Ichim; Dan Popescu All Authors 8 Cites in Papers 183 Full Text Views Abstract
    Document Sections I. Introduction II. Related Work III. System Architecture and
    Methodology IV. Experimental Results V. Conclusions Authors Figures References
    Citations Keywords Metrics Abstract: Large scale monitoring systems, enabled by
    the emergence of networked embedded sensing devices, offer the opportunity of
    fine grained online spatio-temporal collection, communication and analysis of
    physical parameters. Various applications have been proposed and validated so
    far for environmental monitoring, security and industrial control systems. One
    particular application domain has been shown suitable for the requirements of
    precision agriculture where such systems can improve yields, increase efficiency
    and reduce input usage. We present a data analysis and processing approach for
    distributed monitoring of crops and soil where hierarchical aggregation and modelling
    primitives contribute to the robustness of the network by alleviating communication
    bottlenecks and reducing the energy required for redundant data transmissions.
    The focus is on leveraging the fog computing paradigm to exploit local node computing
    resources and generate events towards upper decision systems. Key metrics are
    reported which highlight the improvements achieved. A case study is carried out
    on real field data for crop and soil monitoring with outlook on operational and
    implementation constraints. Published in: 2019 27th Mediterranean Conference on
    Control and Automation (MED) Date of Conference: 01-04 July 2019 Date Added to
    IEEE Xplore: 15 August 2019 ISBN Information: ISSN Information: DOI: 10.1109/MED.2019.8798504
    Publisher: IEEE Conference Location: Akko, Israel SECTION I. Introduction Internet
    of Things (IoT) systems are based on distributed sensing, computing and communication
    devices that collaborate in order to monitor and control physical processes. These
    enable the collection of real world data at an unprecedented scale and resolution
    which can then be used to improve the models that define the understanding and
    help the forecasting of the processes, be it technical, social or environmental.
    New data processing infrastructure are thus needed to store and retrieve the information
    collected in an online manner while providing mechanisms to run the analysis and
    control algorithms based on this data. Beyond conventional environmental monitoring
    as initial key driver of IoT design, current domains include (smart) cities, industry
    and agriculture. Finally the outcomes of the analysis are either handled in closed
    loops for control actions or they are supplied to hierarchical entities for decision
    support. Among the applications areas mentioned above, precision agriculture represents
    one of the salient areas where IoT-enabled systems can improve the quality, productivity
    and increase automation [1]. Main challenges in this field relate to reducing
    input use: water, fertiliser, work, and obtaining better crop yields which is
    demanded by the market to keep food costs low under the strains of increasing
    global population. By having access to reliable, on-line information, relayed
    over distributed networks, domain specialists can oversee tangible improvements
    [2]. The conceptual and practical challenges that we approach in the design of
    such systems is related to efficient data reduction and management which impacts
    directly the congestion and energy metrics of the deployed network. This is performed
    by proposing a hierarchical data processing architecture in accordance to fog
    computing design princi-ples. Fog computing as a concept has initially emerged
    as a computing organisation alternative to leverage intelligent network edge devices
    which make up modern loT systems [3]. The limited computing resources available
    on these embedded devices are thus exploited to reduce the large quantities of
    collected data and transmit only higher level information pieces upstream. Given
    the large heterogeneity the processing primitive can run of the edge nodes range
    from basic threshold detection and averaging up to more advanced outlier detection
    and embedded learning algorithms. Wireless sensor networks (WSN) are an enabling
    technology to deploy fog computing systems [4], [5] where hundreds to thousands
    of sensing nodes self organise intro and communicate over low power radio channels.
    As with the case with agriculture, large areas can thus be covered with multi-hop
    communication networks as the networking protocols rely on cluster heads, gateways
    and hubs serving as intermediary data concentrators. One alternative definition
    presents fog systems in opposition or as complementary to conventional centralised
    and large scale cloud infrastructures. The complex functionality of the cloud
    platform is broken down at the field level over functional or spatially distributed
    entities which collaborate to achieve a common monitoring, event-detection and
    control case. In the precision agriculture use case this can help implement an
    optimised distributed irrigation or fertiliser dosage schemes accounting for local
    properties and variance of soil, micro-climate and crop particularities. The need
    to integrate fog computing with cloud computing in this particular scenario lays
    with the fact that joint observations can be derived when federating high-level
    information across multiple farms. The main novelty of the paper is justified
    by the application of fog computing data aggregation and modelling primitives
    in the context of IoT-enabled smart agriculture, a highly active area of research
    currently. The subsequent contributions of the paper can be argued: system architecture
    for hierarchical data processing and analysis based on field level IoT devices;
    data aggregation methodology based on the fog computing paradigm under precision
    agriculture constraints. SECTION II. Related Work In [6] a fog computing framework
    for precision agriculture is introduced. The two tiered system is able to reduce
    significantly the data transmitted in the network. Reducing the computational
    loads, and most important, the cloud computing costs associated with centralised
    processing is highlighted as an essential benefit of the fog approach. The authors
    of [7] propose a hybrid IoT for smart farming in rural areas. The communication
    network uses 6LoWPAN local radio for the field interfaces while long range connections
    are implemented over WiFi. A 6LoWPAN border router and dedicated gateway are used
    to assure cross-domain integration of the networks from field level, intermediate
    long range relays and cloud. Network requirements for smart agriculture applications
    are also discussed in terms of throughput, latency and mobility support. These
    offer a good reference to quantify the data aggregation potential in conjunction
    with the sensing and control requirements. A distributed computing architecture
    is presented in [8] which the agricultural system basic components such as: crop,
    soil, climate, water and nutrients, energy. The messaging system is standardised
    around the Message Queuing Telemetry Transport (MQTT) to interlink sensors, actuators,
    communication nodes, devices and subsystems [9]. A decision tree is designed for
    irrigation control and integrated on the edge devices for in situ decision making.
    At the top level cloud services supply data through an end-user dashboard for
    high level decision support. [10] introduce an intelligent irrigation system based
    on distributed sensor using the LoRA long range, low rate, nodes and gateways.
    The FIWARE infrastructure is leveraged as data management middleware platform
    which provides the support services. Several operation scenarios are discussed
    based on the scalability requirements, in terms of tens of thousands of nodes.
    Reference computational resource assessment for cpu, memory and network is also
    reported. Large scale IoT monitoring is discussed in [11]. The focus is on the
    ground level clustering mechanisms that support the timely collection of data
    and generating of the field level monitoring events. Aerial robotic platform support
    is provided through suitable high level control of trajectories for data collection
    and backhaul. Data reduction is achieved by thresholding over locally computing
    moving averages in conjunction with expert knowledge adapted to the monitored
    processes. Several radio access technologies are available to achieve reliable
    transmissions [12]. SECTION III. System Architecture and Methodology A. System
    Architecture for Data Collection and Processing The proposed system architecture
    that we have designed for the purpose of efficient data collection and processing
    in precision agriculture is illustrated in Figure 1. It consists of the following
    information and physical layers: field layer, fog computing layer, cloud computing
    layer, data presentation layer, which are linked by cross-layer upstream and downstream
    data and control information flows. The layer functionality is detailed next:
    Field layer: includes the actual sensors deployed in the precision agriculture
    application to measure the physical parameters of interest; these include air
    temperature, air humidity, solar radiation, soil temperature at various depths,
    windspeed and rainfall; the field layer can also be expanded to accommodate intelligent
    actuators e.g. for irrigation or fine grained nutrient dosage, to execute commands
    incoming from higher level systems; Fog Computing layer: the fog nodes collect
    data from the sensors and run the data processing primitives for intelligent aggregation
    in order to reduce network traffic and energy expenditure; the main idea is to
    locally derive basic model characteristics of the particular process which are
    sent to the cloud in compact form; correlations between the sensed variables can
    also be exploited at this level for local decisions thus avoiding completely the
    increased cost and latency of the upper layers; Cloud computing layer: data is
    streamed towards a common cloud platform; regarding the particular implementation
    we use the ThingSpeak [13] platform in conjunction with Matlab algorithm development
    for higher level processing routines; at the cloud layer the model parameters
    allow the reconstruction of the time series characteristics if needed, while accounting
    for the inherent modelling errors; Data presentation layer: is concerned with
    the front-end software systems that present the outcomes of the data analysis
    to end-users or decision makers with the ability to provide mobile access and
    timely alerts in the case of event detection; parametrisation of the process by
    domain experts is also achieved at this layer. A more detailed algorithm flowchart
    is provided in Figure 2. It includes the steps for algorithm description which
    runs on the fog computing node. In-field measurements are uploaded to the IoT
    application in two ways depending on the type of information: events and measurements.
    Note that, a primary batching procedure is usually available for most of the monitoring
    systems, basically consisting of performing minimum, maximum and mean value during
    a specific period of time. We consider this as the starting point for further
    local data processing. Primary batch aggregation Note that, a primary batching
    procedure is usually available for most of the monitoring systems, basically consisting
    of performing minimum, maximum and mean value during a specific period of time.
    We consider this as the starting point for further local data processing. For
    instance, batches are defined within 30 minutes. Once a new batch is available,
    min,max and mean values are computed (step A). Check for outliers procedure For
    each batch of measurements, an outliers'' check procedure is performed, considering
    an acceptance bandwidth of data variance for the measured value around the mean
    (step B). The procedure outputs an event if the minimum or maximum values exceeds
    the thresholds. The event E is defined as: E={e( x i )∈Q,  T min < x i < T max
    } (1) View Source where: X 2 is the measured value at iteration i T min and T
    max are thresholds computed as: T min =mean(1−w) T max =mean(1+w) (2) (3) View
    Source where w is a weight for acceptance bandwidth size define. Fig. 1: Distributed
    data processing based on fog computing for precision agriculture Show All Relevant
    data extraction Aggregated data sets are achieved based on different methods.
    All seek for relevant data point, aiming to a reduced size set providing at the
    same time a satisfying reconstruction of the initial data. One effective method,
    in terms of data volume, is based on using the min and max values extraction,
    computed for 24 hours. It is obvious that this method is suitable only for measurements
    that follow a regular shape during time, with insignificant variations during
    a day. A measurement for which this method is suitable is the soil temperature.
    Instead, change detection is a common method applicable for irregular shaped data
    sets. This method follows extraction of data points where trend changes occur.
    Given a set of data point ( x i ,  y i ),i=1,…,n , trend t i is followed for each
    pair x i , x i+1 , such that for x i+1 − x i >δ⇒t(i)=1 x i+1 − x i <δ⇒t(i)=−1
    x i+1 = x i ⇒t(i)=0 (4) View Source Then, if t(i)≠t(i+1) means that a trend change
    is detected. The coresponding data point x ( i+1) is added to the relevant data
    set. Relevant data extraction (step C) is performed when a set of primary aggregated
    batches is available. B. Data Aggregation One reference method of extracting high
    level information from sensor data is Symbolic Aggregate Approximation (SAX) [14].
    It operates by assigning label symbols to segments of the time series thus porting
    it in a unified lower dimension representation. It belongs to the family of time
    series data mining techniques leading to non-parametric modelling. Ranges are
    identified through the data histogram or in a uniform manner. The method provides
    linear complexity and opens up the use and application of multiple statistical
    learning tools. Parametrisation of SAX is highly important by defining the number
    of segments and the alphabet size which can influence the quality and robustness
    of the result. The background on which SAX has been defined is established by
    PAA [15] where symbols are attributed to the aggregated numerical values listed
    by PAA. Several discrete event models can incorporate the resulting aggregated
    segments e.g. Markov models in order to compute the probability of the observed
    patterns for future observations. According to the PAA method description, starting
    with a time series X of length n , this is approximated into a vector X ¯ ¯ ¯
    ¯ =( x ¯ ¯ ¯ 1 , …, x ¯ ¯ ¯ M ) of any length M≤n , with n divisible by M . Each
    element of the vector X ¯ ¯ ¯ ¯ i is calculated by: x ¯ ¯ ¯ i = M n ∑ j=n/M(i−1)+1
    (n/M)i x j (5) View Source Fig. 2: Fog computing algorithm Show All The dimensionality
    of the time series is thus reduced from n to M samples by initially dividing the
    original data into M equally sized frame and then compute the mean values for
    each frame. A new sequence is achieved by putting the mean values together which
    is considered to be the PAA transform (approximation) of the original data. With
    regard to computational considerations, the PAA transform complexity can be reduced
    from O(NM) to O(Mm) with m being the number of frames as tuning parameter of the
    method. The distance measure between two time series vector approximations X ¯
    ¯ ¯ ¯ and Y ¯ ¯ ¯ ¯ is defined as: D PAA ( X ¯ ¯ ¯ ¯ , Y ¯ ¯ ¯ ¯ )= n M − − −
    √ ∑ i=1 M ( x ¯ ¯ ¯ i − y ¯ ¯ ¯ i ) − − − − − − − − − −  ⎷   (6) View Source
    It has been shown by the proposers of the method that PAA satisfies the lower
    bounding condition and guarantees no false dismissals such that: D PAA ( X ¯ ¯
    ¯ ¯ , Y ¯ ¯ ¯ ¯ )≤D(X, Y) (7) View Source C. Interpolant Methods The Cloud-based
    application rebuilds data sets by estimates based on interpolation mechanisms.
    For performance evaluation we showcase three methods: the common linear interpolant
    (also referred as piecewise linear interpolant) and two closely related interpolants,
    cubic spline and shape preserving Piecewise Cubic Hermite Interpolating Polynomial
    (pchip). Given a set of data points ( x i ,  y i ),( x i+1 ,  y i+1 ),…,( x n
    ,  y n ) , the linear interpolation is defined as the concatenation of linear
    interpolants between each pair of data points, thus a set of straight lines between
    each data points. Any pair of data points with x i ≠ x i+1 determines a unique
    polynomial p of degree less than two whose graph passes through the two points
    with the property: p( x i )= y i (8) View Source with the form: p(x)= α 1 x+ α
    0 (9) View Source a 1-D linear interpolation. In general, given n points ( x i
    ,  y i ),i=1,…,n , with disting x i , a polynomial of degree less than n whose
    graph passes through the n points denoted P n (x) , is expressed in the Lagrange
    form as: P n (x)= ∑ x=1 n ⎛ ⎝ ⎜ ⎜ ∏ j=1 j≠i n x− x j x i − x j ⎞ ⎠ ⎟ ⎟ y i (10)
    View Source The Lagrange form in (10) can be written out in power form of an interpolating
    polynomial as, P n (x)= a 1 x n−1 + a 2 x n−2 +…+ a n−1 x+ a n (11) View Source
    where the coefficients a k are computed through a system of linear equations:
    ⎡ ⎣ ⎢ ⎢ ⎢ ⎢ ⎢ x n−1 1 x n−1 2 ⋮ x n−1 n x n−2 1 x n−2 2 ⋮ x n−2 n ⋯ ⋯ ⋮ ⋯ x 1
    x 2 ⋮ x n 1 1 ⋮ 1 ⎤ ⎦ ⎥ ⎥ ⎥ ⎥ ⎥ ⎡ ⎣ ⎢ ⎢ ⎢ ⎢ a 1 a 2 ⋮ a n ⎤ ⎦ ⎥ ⎥ ⎥ ⎥ = ⎡ ⎣ ⎢
    ⎢ ⎢ ⎢ y 1 y 2 ⋮ y n ⎤ ⎦ ⎥ ⎥ ⎥ ⎥ (12) View Source Considering this, a piecewise
    linear interpolant is produced by first computing the divided difference: δ i
    := y i+1 −yi x i+1 −xi (13) View Source Then the interpolant is constructed as:
    P(x)= y i + δ i (x− x i ) (14) View Source Further, for piecewise cubic polynomials,
    considering an interval x i ≤x≤ x i+1 let h i := x i+1 −xi be the length of an
    i th interval and d k := P ′ ( x i ) . Therefore, using this derivative it is
    possible to adjust the interpolant in order to enforce smoothness, by forcing
    the pair of derivatives from consecutive piecewice cubics to agree. All piecewise
    cubic hermite interpolating polynomials are continuous and have a continuous first
    derivative. In particular, spline is oddly smooth, meaning that it''s second derative
    also varies continously. Instead, pchip is not as smooth as spline, it is actually
    designed so that it never overshoots the data. The slopes are chosen so that P(x)
    preserves the shape of data and also respects monotonicity. SECTION IV. Experimental
    Results We collect experimental data from a network of field devices installed
    on site at an experimental research farm. Form the long term monitoring dataset
    we select a sample for analysis that covers one month of data. The data is preprocessed
    for missing values, noise removal and averaged over 30 minute intervals. We first
    illustrate the application of the SAX method on the measured values for soil temperature
    and solar radiation in Figure 3 and Figure 5. Segment levels codify the evolution
    of the respective time series and provide a compact representation with considerable
    impact on the data storage and transmission requirements at the fog node. Finer
    grained patterns can be observed by zooming in at the daily level as is illustrated
    in Figure 5. Based on the selected segment labels, if the expected value deviates
    significantly by entering a different label segment, an event detection primitive
    can trigger a communication message from the node upstream. Fig. 3: Symbolic aggregation
    approximation - soil temperature Show All Fig. 4: Symbolic aggregation approximation
    - solar radiation Show All In order to evaluate reconstructed data consistency,
    achieved through different estimating algorithms, more precisely the proposed
    interpolants, some well known goodness-on-fit statistics are performed: Sum of
    squares of errors (SSE) - measures the total deviation of the response values
    from the fit to the response values and is defined as: SSE= ∑ i=1 n w i ( x i
    −P( x i ) ) 2 (15) View Source where w i is the weight for the i th error between
    estimated i th value and the empiric data Fig. 5: Solar radiation - day level
    aggregation Show All R-square - measures how successful the fit is in explaining
    the variation of the data and is expressed as: R−−square=1− SSE SST (16) View
    Source where SST= ∑ i=1 n w i ( x i − x ¯ ¯ ¯ i ) 2 (17) View Source where x ¯
    ¯ ¯ l is the mean value of x i dataset. Root mean square error (RMSE) - is an
    estimate of the standard deviation of the random component in the data and is
    expressed as: RMSE= SSE n − − − − − √ (18) View Source Results are summarised
    in Table I. Fig. 6: Soil temperatur Show All Fig. 7: Solar radiation Show All
    Fig. 8: Solar radiation - histogram Show All Table I: Goodness-on-fit statistics
    results Figure 6 and Figure 7 graphically depict the results of applying the alternative
    methods of interpolation on the two time series. In Figures 8 and 9 the histograms
    quantify the associated data reduction between the raw input data and the interpolant
    methods presented. For this case, the monotonicity property of pchip is more desirable
    than the smoothness property of spline, which in some places overshoots the data,
    thus one may prefer the good behavior of the shape preserving pchip method. Note
    that, as with the linear interpolation, when there are two consecutive points
    with the same value, the interpolant is constant over that interval. This behaviour
    was expected and it is appropriate in this context. Even if the metrics indicate
    better fitting for linear interpolation through the studied cases, one can choose
    the pchip method, given that the results are quite close and it does a much more
    visual pleasing representation, in particular better modelling the peeks and following
    the expected behaviour around the baseline. Fig. 9: Soil temperature - histogram
    Show All SECTION V. Conclusions The paper presented a system architecture and
    distributed data processing application based on IoT in precision agriculture.
    By exploiting the dense spatial and temporal distributions of the sensing nodes,
    intelligent data reduction through aggregation and model reconstruction is illustrated
    for significants benefits for network congestion and energy efficiency. As the
    results achieved show promise, future work is focused on extensive evaluation
    for online decision making by domain experts in order to improve the reconstructed
    data quality. Authors Figures References Citations Keywords Metrics More Like
    This Precision agriculture: Challenges in sensors and electronics for real-time
    soil and plant monitoring 2017 IEEE Biomedical Circuits and Systems Conference
    (BioCAS) Published: 2017 Design of Multi-parameter Wireless Sensor Network Monitoring
    System in Precision Agriculture 2014 Fourth International Conference on Instrumentation
    and Measurement, Computer, Communication and Control Published: 2014 Show More
    IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS
    VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION
    AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE:
    +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help
    | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting
    | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s
    largest technical professional organization dedicated to advancing technology
    for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: 27th Mediterranean Conference on Control and Automation, MED 2019 - Proceedings
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: IoT-Enabled distributed data processing for precision agriculture
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'

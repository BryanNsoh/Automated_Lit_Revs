- DOI: https://doi.org/10.14257/ijgdc.2016.9.11.24
  analysis: '>'
  authors:
  - S. Vijayarani
  - P. Jothi
  citation_count: 4
  full_citation: '>'
  full_text: '>'
  inline_citation: '>'
  journal: International journal of grid and distributed computing (Print. 2008)
  limitations: '>'
  pdf_link: null
  publication_year: 2016
  relevance_score1: 0
  relevance_score2: 0
  title: A Hybrid Clustering Algorithm for Outlier Detection in Data Streams
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.35940/ijitee.c1027.0193s20
  analysis: '>'
  authors: []
  citation_count: 3
  full_citation: '>'
  full_text: '>'
  inline_citation: '>'
  journal: International journal of innovative technology and exploring engineering
  limitations: '>'
  pdf_link: null
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: Data Preparation in Predictive Learning Analytics (PLA) for Student Dropout
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.31227/osf.io/qc342
  analysis: '>'
  authors:
  - Dwi Ely Kurniawan
  - Agus Fatulloh
  citation_count: 1
  full_citation: '>'
  full_text: '>

    INA-Rxiv Papers My Preprints Add a paper Donate Sign Up Sign In Clustering of
    Social Conditions in Batam, Indonesia Using K-Means Algorithm and Geographic Information
    System  AUTHORS Dwi Ely Kurniawan and Agus Fatulloh AUTHOR ASSERTIONS CONFLICT
    OF INTEREST No Paper_DwiElyKurniawan_ICEE2017.pdf Version: 1 Download previous
    versions Submitted: February 11, 2018 | Last edited: April 20, 2023 Expand Download
    paper Views: 159 | Downloads: 641 Abstract Batam is an archipelago that has different
    social characteristics of each sub-district. Social problems should be a concern
    and responsibility of both the public and government. For the programs launched
    by the government in accordance targeted and it is necessary to determine the
    priorities of the social problems that arise in each region. This study uses k-means
    algorithm to classify social problems in the form of clusters. Each group has
    the same characteristics in the group while the other cluster to form the next
    group according to their characteristics. The results of the study, a k-means
    algorithm determines the group and map the distribution of social issues into
    the Geographic Information System (GIS) to facilitate the social information to
    know each district and identify priorities for help to the government program
    on target. Show more Supplemental Materials https://osf.io/qhb9d/ paper DOI https://doi.org/10.31227/osf.io/qc342
    License CC-By Attribution 4.0 International Disciplines Mining Engineering Other
    Computer Engineering Computer Engineering Engineering Tags clustering GIS social
    issues Original publication date 2017-08-30 Citations APA MLA Chicago Get more
    citations Enter citation style (e.g. "APA") INA-Rxiv: About | Support | Contact
    |  Copyright © 2011-2024 Center for Open Science | Terms of Use | Privacy Policy
    | Status | API TOP Guidelines | Reproducibility Project: Psychology | Reproducibility
    Project: Cancer Biology This website relies on cookies to help provide a better
    user experience. By clicking Accept or continuing to use the site, you agree.
    For more information, see our Privacy Policy and information on cookie use. Accept'
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: null
  publication_year: 2018
  relevance_score1: 0
  relevance_score2: 0
  title: Clustering of Social Conditions in Batam, Indonesia Using K-Means Algorithm
    and Geographic Information System
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1155/2022/8109117
  analysis: '>'
  authors:
  - Yancai Wang
  citation_count: 1
  full_citation: '>'
  full_text: '>

    Journals Publish with us Publishing partnerships About us Blog International Transactions
    on Electrical Energy Systems Journal overview For authors For reviewers For editors
    Table of Contents Special Issues International Transactions on Electrical Energy
    Systems/ 2022/ Article On this page Abstract Results and Analysis Conclusion Data
    Availability Conflicts of Interest References Copyright Related Articles Research
    Article Retraction ! This article has been Retracted. To view the article details,
    please click the ‘Retraction’ tab above. Special Issue Machine Learning-based
    Design Optimization for EMS in Smart Grids and Renewable Energy View this Special
    Issue Research Article | Open Access Volume 2022 | Article ID 8109117 | https://doi.org/10.1155/2022/8109117
    Show citation [Retracted] Analysis on the Particularity of Higher Education Subject
    Development under the Background of Artificial Intelligence Yancai Wang 1 Show
    more Academic Editor: Raghavan Dhanasekaran Received 22 Jul 2022 Revised 10 Aug
    2022 Accepted 05 Sept 2022 Published 11 Oct 2022 Abstract Subject development
    plays a crucial role in higher education (HE), improving student academic performance.
    The HE continuously requires conceptual and empirical development to deliver valuable
    content to the students. The subject reforms offer quality, accessibility, affordability,
    accountability, and equity to accomplish continual learning. The changes in higher
    education subjects require a continuous assessment to understand the relationship
    between the reform and student performance. The subject development quality is
    evaluated using machine learning (ML) and artificial intelligence (AI) techniques.
    The existing researchers use intelligent techniques to identify student academic
    performance. However, the exact relationship between student performance and subject
    changes fails to address. Therefore, higher education learning (HEL) requires
    improvement to manage the Higher Education Subject Development (HESD). To achieve
    the research goal, AdaBoost Adaptive-Bidirectional Associative Memory (AA-BAM)
    network is introduced in this work. The network model uses the Hebbian supervised
    learning (HSL) process to create the training model. The learning process has
    a network parameter updating procedure that reduces the total error and deviation
    between the academic details. In addition, the neural model uses the memory cell
    that stores every processing information that recalls the output patterns with
    maximum accuracy. The output pattern identifies the student’s academic performance,
    which helps to analyze the quality of the subject development in institutions.
    The created system ensures 98.78% accuracy, showing that subject development correlates
    highly with student academic performance. 1. Introduction of Higher Education
    Subject Development Higher education management (HEM) [ 1, 2] concepts and elements
    have been altered at most institutions and colleges. The HEM is essential to postsecondary
    learning because it establishes the learning plan and manages the techniques,
    materials, and structure [ 3]. The HEM system regularly evaluates the educational
    system to raise the standard of instruction and increase its relevance. Therefore,
    proper guidelines and reviews should be developed to improve the education subjects
    [ 4]. The continuous improvement in the education subjects ensures the teaching
    and learning quality. The learning quality is maintained by creating the Higher
    Education Subject Development (HESD) program [ 5, 6] with particular policies
    and University Qualification Framework (UQF). Once the HESD is developed, it has
    to be evaluated using various assessments before approving the subject changes.
    The frequent subject assessments [ 7] help to maintain the system’s flexibility.
    In addition, the newly developed subject framework has been given to the students
    or graduates to get feedback to manage the education standards. In the HESD case,
    student performance plays a significant role because they are the actual participants
    in the learning [ 8, 9]. The performance of participant is evaluated with different
    dimensions such as written work, examination, presentation, and group activities.
    Among the various dimensions, student class participation has half importance
    in improving the HE standards. The teachers continuously monitor student participation,
    contribution, and learning ability during the class. If the subjects have more
    interest, then students have a power-packed performance in those subjects. However,
    student observation and assessment are challenges because they require enormous
    student attributes. Student performance is not only determined via the cumulative
    grade point but also depends on student interactions, comments, and class flow.
    The student who frequently participates in the classroom is attaining positive
    factors. Students’ learning, listening, and teaching abilities impact the student’s
    academic performance. Therefore, HESD requires a quality instructor and effective
    student to improve the overall learning system flexibility reliability and significantly.
    The HESD requires the student perspective and feedback to enhance the subject’s
    nature and teaching quality [ 10]. In most situations, students are ambiguous
    and feel inadequate in understanding the concepts that will affect the HESD quality.
    Therefore, several researchers use machine learning and intelligent techniques
    [ 11, 12] to investigate student learning performance. The research analysis utilizes
    the student’s academic attributes as input and output patterns are derived [ 13,
    14]. However, the existing systems fail to ensure the particular subject’s [ 15]
    related output. In addition, the enormous amount of data [ 16] is challenging
    to handle by the traditional performance analysis performance. The research issues
    are resolved with the help of the AdaBoost Adaptive-Bidirectional Associative
    Memory (AA-BAM). The model uses the memory cells that store every processed input,
    which helps to understand the student’s learning ability. According to the students’
    learning ability, the HESD has been investigated effectively. This research examines
    the rise of intelligent techniques in higher education teaching and learning.
    It examines the educational consequences of new technology on how students learn
    and how educational institutions change and adapt. Researchers examine recent
    technological developments and higher education’s rising use of new technologies
    in order to forecast how higher education will change once artificial intelligence
    is an integral part of our institutions’ fabric as importance contribution in
    this research. For institutions of higher education and students, the use of these
    technologies for teaching, learning, student assistance, and administration presents
    significant problems. The remaining paper is arranged as Section 2, discussing
    the review analysis of the higher education system. Section 3 explores the AA-BAM
    approach’s working process to identify the student performance to the HESD and
    the system’s efficiency discussed in Section 4. Conclusion described in Section
    5. 2. Review Analysis of Higher Education Ho et al. [ 17] explored machine learning
    techniques in higher education to improve remote learning during the COVID-19
    situation. This work uses the Hong Kong self-funded university student information
    for analyzing the emergency remote learning (ERL) during the pandemic. During
    the analysis, around 425 students’ data are collected, which are analyzed according
    to the multiple regression techniques that investigate the student learning satisfaction
    and ensure 65.2% accuracy. The remote learning-based attained results are compared
    with the traditional classroom learning in which the ERL process faces difficulties
    while accessing the Internet and learning devices. Kuleto et al. [ 18] analyzed
    the difficulties and importance of artificial intelligence (AI) approaches and
    machine learning (ML) in higher education institutions (HEI). The study was conducted
    in Serbia, in which different information and reference points were collected
    from commercial sources, multiple academics, and scientific units. This study
    uses around 103 students’ information, which is investigated by applying the ML
    and AI techniques. During the analysis, the correlation matrix and theoretical
    dimensions are computed with the help of regression analysis. The correlation
    values are used to effectively examine the student''s skills and learning. Rodríguez-Hernández
    et al. [ 19] predicted student academic performance by applying the artificial
    neural network (ANN). The system aims to predict higher studies student performance
    and academic performance and the predictors involved in academic performance.
    During the analysis, Colombia’s public and private university’s student information
    is gathered; around 162,030 student educational details are utilized to investigate
    the performance. The ANN recognizes the student performance from 71% to 82%. After
    identifying the student''s performance, school characteristics, prior academic
    achievement, and school characteristics have been analyzed. The derived student
    learning characteristics give recommendations by applying the ANN in higher education.
    Giannakas et al. [ 20] developed deep learning approach (DLA)-based classification
    framework for identifying the student’s team-related academic performance. The
    deep neural network (DNN) uses the two hidden layers for analyzing the student’s
    academic performance to identify the positive and negative impacts on team learning.
    The DLA uses various activation functions such as tanh, rectified linear unit
    (ReLU), and sigmoid to compute the output value. This classification process is
    optimized with the help of AdaDelta and AdaGrad, which minimize the deviations
    between the outputs. The system uses the Shapley Additive Explanations (SAE) to
    interpret with the DLA approach to derive the various features used to improve
    the overall classification accuracy. The author uses the 74 teams and 30000 entries
    to evaluate the introduced system efficiency, and the system ensures 80.76% and
    86.57% accuracy. Zhang et al. [ 21] applied the Sparse Attention Convolutional
    Neural Network (SACNN) approach to predicting the student grade in Chinese higher
    education. The SACNN approach uses the sparse attention layer to identify the
    course target and response. The network utilizes temporal features to investigate
    the student learning process. Fully convolution neural networks process the extracted
    features to predict the grade from the achieved features. The author uses the
    137-course details, and 1307 students’ information is processed to predict the
    student grades. The collected information was evaluated with the help of hold-out
    evolution in which the introduced system attains 85% of prediction accuracy. According
    to the grade performance, learning efficiency and course relationship are evaluated
    to improve the learning efficiency. Hai-tao et al. [ 22] developed school students’
    academic performance by applying the graph convolutional neural network (GCNN).
    This study uses the Chinese-Foreign Cooperation in Running School (CFCRS) student
    information to analyze their academic performance. The collected CFCRS information
    is investigated by applying the GCNN that uses the fully connected layer to explore
    the feature matrix. The computed output values are processed by the Pearson correlation
    coefficient (PCC) to estimate the student similarities. According to the computations,
    student learning efficiency is predicted with 81.5% accuracy. Olabanjo and Wusu
    [ 23] recommended radial basis function neural (RBFN) model to identify secondary
    school student (SSS) academic performance. The author uses the school repository
    information to predict the SSS performance. The dataset consists of student characteristics
    and raw scores collected from 1 to 6 years; the dataset also includes teacher
    ratings. The gathered information is categorized according to the subjects such
    as Major, English, and Mathematics. The student details are processed using principal
    component analysis (PCA) to remove the irrelevant information. Then, noise-removed
    details are investigated RBFN, which predicts the student performance with 93.49%
    accuracy. According to the results, student’s learning performance is improved.
    Dogadina et al. [ 24] introduced hybrid model-related optimized neural networks
    (HMONN) for evaluating high school student (HSS) education. The system intends
    to assess the student homework performance by considering different criteria such
    as school exercises, assignment criteria, and time. The collected information
    is processed by neural models that predict student performance. During the analysis,
    the network uses the backtracking optimization algorithm (BOA), genetic algorithm
    (GA), and particle swarm optimization (PSO) are incorporated to find the homework
    completion time. The above analysis and discussions clearly show that ML and AI
    algorithms are widely utilized in higher education learning (HEL) to improve student
    performance. The existing systems concentrate on student’s entire academic performance
    and grading effectively. However, the existing methods fail to explore the particularity
    of Higher Education Subject Development (HESD). Therefore, the HEL requires improvement
    in the subjects to improve student performance. AdaBoost Adaptive-Bidirectional
    Associative Memory (AA-BAM) network is introduced to address this issue. The AA-BAM
    approach investigates each change in HEL subjects, and student’s adaptions are
    evaluated in a particular period to justify the HESD. Then, the detailed description
    and working process of the AA-BAM-based HESD process are discussed below. 3. AdaBoost
    Adaptive-Bidirectional Associative Memory (AA-BAM) Network-Based HESD 3.1. Higher
    Education Subject Development (HESD) This section reviews, delivers, and develops
    the Higher Education Subject Development (HESD) system using the AdaBoost Adaptive-Bidirectional
    Associative Memory (AA-BAM) approach. The HESD utilizes the set of policies and
    procedures, which regulate the changes and development in higher education (HE)
    subjects. The successful usage of HESD policies helps manage the quality of teaching
    and learning. The HESD should be incorporated with the universities/college''s
    guidelines to improve the student’s learning efficiency. The HE subject improvement
    and development must satisfy the following criteria: (i) Appropriate level: subjects
    are created level by level; they should be adopted to the Academic Qualifications
    Framework (AQF). (ii) Appropriate assessment: institutions or universities are
    needed to assess to compute the workload and student performance. The evaluation
    should be indicative, and the computations are proportional to the entire subject.
    The assessment process must be flexible. (iii) Learning outcome: learning process
    and outcomes are related to the AQF. (iv) Student attributes: subjects must be
    developed according to the student’s learning attributes. According to the above
    criteria, the HE teachers and staff register their policies in institutions. Then,
    the subject outlines are assessed for delivering valuable notes to the students.
    In addition, the HESD must consist of proper resources to satisfy the subject
    requirement. The developed subjects need to be incorporated with the UQF that
    has to be approved by the Teaching Committee (TC). Once the TC supports the subjects
    in HE, the internal subject review process is performed in the end of semester
    review, subject reports, and information distribution. The developed subject-related
    examinations are conducted, and the results are evaluated at the end of the semester.
    During this process, feedback of student and teacher is collected to understand
    the complexity of new subjects. The staff generated a summative subject report
    (SSR) according to the subject coordinator. The developed SSR is submitted to
    the senior faculty and institution dean to explore the subject’s improvement.
    The designated representative investigates the generated SSR report to identify
    the implications and significance of the subjects. Then, the quality administrator
    (QA) assesses the SSR and stores it in the database for further subject improvement.
    According to the reports and feedback, students are trained further, and the subjects
    are changed to improve their learning ability. From the analysis, student performance
    in particular subjects played an important role because it determined the HESD
    efficiency. The collected student academic information is investigated by applying
    ML and AI techniques. The existing techniques fail to address the HESD-related
    feedback and performance, which reduces the learning efficiency. The discussed
    issues are overcome by applying the AA-BAM network to the student academic features.
    A detailed explanation of the AA-BAM process is discussed in the below section.
    SSR may be integrated into teaching and learning activities so that students’
    progress is constantly monitored. High-accuracy algorithms have been used to accurately
    forecast the likelihood of a student failing an assignment or withdrawing from
    a course. 3.2. Student Data Collection This work uses the Higher Education Students
    Performance Evaluation (https://www.kaggle.com/datasets/csafrit2/higher-education-students-performance-evaluation)
    [ 25] dataset. The dataset was gathered from the student of Engineering and Educational
    Sciences in 2019. The dataset was used to evaluate the student performance by
    applying ML and AI techniques. The dataset consists of 32 attributes that include
    student personal information (name, age, family background, scholarship type,
    sex, partner details, transportation, and attendance), and academic information
    (study hours, reading books, frequency of reading, writing, preparation strategies,
    notes, flip-classroom, course ID, cumulative grading points, and output grade).
    The dataset has this information along with the output label, and the attribute
    information is illustrated in Table 1. Table 1  Dataset attribute information.
    The above attributes are considered while developing the student dataset, which
    is more valuable in exploring the importance of the HESD. Once the dataset is
    obtained, it has been processed by applying the introduced AA-BAM approach to
    predict student performance. 3.3. Student Performance Prediction toward HESD The
    first step of the HESD-related student performance prediction is data preparation
    and preprocessing. The data preprocessing utilizes machine learning techniques
    for changing the raw input data into the computation format. The preprocessing
    changes the data into a machine-processable format that helps to predict and interpret
    the data features. The main reason for selecting this step is to identify the
    noisy, inconsistent, and missing values in the heterogeneous data. Increasing
    sophistication in the field of artificial intelligence has prompted educational
    reforms that have modernized higher education, reimagined how schools are operated,
    and improved the way teachers are trained. Lifelong education, a borderless education
    system, intelligent campus building, and so on are all included in the new technologies
    used to achieve these goals. It is through the use of artificial intelligence
    that we are not only improving our ability to educate. By speeding up the transition
    from educational system innovation to governance innovation, China’s higher education
    quality improves over time. Therefore, the data preprocessing procedure is incorporated
    in this study to enhance the overall system performance and data quality. The
    missing values in the dataset reduce the overall statistical data analysis, and
    the outlier and inconsistent data reduce the model learning efficiency, which
    causes false predictions. The preprocessing step consists of data collection,
    cleaning, and outlier identification. The overall data preparation, preprocessing,
    and student performance prediction process are illustrated in Figure 1.    Figure
    1  Student academic performance analysis structure. Initially, the data cleaning
    is performed to remove the outliers, missing values, noise data, and inconsistency.
    The missing value should be addressed first to improve the data quality, done
    manually or by applying numerical methods. Suppose the dataset is high in dimension,
    the tuples are ignored; the missing values need to be filed. In this work, a median
    filter is applied for computing the missing values. If the dataset has an odd
    number of records, the filter selects the median value as the missing value. Consider
    the dataset has n records, and then, the missing value is replaced by computing
    and the estimated using the value. If the dataset has even records, then the missing
    values are replaced by estimating the value. After replacing the missing values,
    noise or variance values are removed from the dataset. The variance data are eliminated
    by applying the discretization process, which minimizes the discrete and continuous
    data cardinality. During this process, similar data are grouped to minimize the
    distinct value involvement. It also enhances the overall data utilization and
    manages the response time while handling the student data without affecting the
    model quality. The binning process manages the attribute relationship and enhances
    the overall student performance analysis system. During the analysis, the binning
    boundaries are identified according to the attributes involved in the dataset.
    The main motive for picking the binning procedure is that it is utilized for investigating
    both categorical and numerical attributes in the dataset. Data have been sorted
    and divided into equal bins in the binning process. Then, inconsistent data have
    to be removed from the dataset to enlighten the data quality. The widespread adoption
    of AI has radically altered traditional educational concepts and practices. More
    college education is being transformed by artificial intelligence for quality
    administrators (QA). The study and use of artificial intelligence by quality administrators
    (QA) is critical to their professional growth. To better prepare students for
    the new era of intelligence, it is vital to teaching students how to take tests
    on their own and use social skills. The inconsistent or outlier data have been
    removed by applying the centroid-based clustering procedure. The clustering process
    utilizes the K-means clustering procedure to explore every data in the dataset.
    The clustering algorithm works according to the unsupervised learning procedure.
    The cluster analysis selects the centroids or K-center points iteratively, and
    the attributes are allocated to the closest centroid. The algorithm selects the
    best center point and reduces the cumulative square distance between the attribute
    to the centroid value. The dataset has a set of attributes such as , which has
    d- dimensional vector that has to be partitioned into the different sets that
    are defined as . The K-means clustering procedure reduces the outliers by reducing
    the variance. Then, the objective of the clustering is attained by applying the
    following equation: In equation (1), the k is defined as the number of clusters,
    x is the attributes that belong to the set or cluster, and the is the mean value
    of the data in the particular set . This process continuously examines the data
    points, and the cluster members are predicted. For every time, the centroid value
    has to be recomputed that is done by using the following equation: The exploration
    of each attribute in the dataset and centroid values are estimated by reducing
    the variance value. The clustering process investigates each data point, and similar
    attributes are grouped. The similarity between the cluster center and other data
    points is used to identify the outliers in the list. According to the discussion,
    the predicted outliers are illustrated in Figure 2.   (a)     (a)  (b)     Figure
    2  Centroid clustering-based outlier elimination (a) Before Clustering, (b) After
    Clustering. After identifying the outlier from the dataset, data points have been
    investigated by applying the AA-BAM network model to predict student performance.
    The AdaBoost Adaptive-Bidirectional Associative Memory (AA-BAM) is one of the
    recurrent neural network (RNN) types that utilize the extensive possibilities
    to predict the HESD between the students. Here, the cleaned student’s information
    is processed by applying the layer of networks that predicts the features or attributes
    from the data. The extracted features are explored using the memory network that
    can process and store every piece of information. In addition, the network has
    feedback signals that can process the multiple functions effectively. The AA-BAM
    approach is a supervised learning system with hetero-associative memory while
    processing the student’s inputs. The network processes the inputs and gives the
    output in a different size because it works according to the human brain function.
    The memory layer helps to recognize the previously processed information. The
    network receives inputs from one form and has been analyzed using different layers,
    generating output patterns. The main reason for choosing the memory-related network
    is to save the hetero-related pattern that can retrieve the exact output pattern,
    even if it has incomplete or noisy inputs. The adaptive memory-associated neural
    network structure is illustrated in Figure 3.    Figure 3  Memory-associated neural
    network structure. Considered the student attributes X with n-dimensional vector
    and respective outputs Y are recalled from memory set with m-dimensional vector.
    The recalling process worked in the backward direction; therefore, Y is denoted
    as input for getting the student performance. The outputs are estimated by using
    the learning or storage process. The model uses the network parameter called weight
    matrix (W) during the learning process. Then, the synaptic weight values are calculated
    using The computed W values are applied to the inputs, and the activation function
    is applied to estimate the output value. The learning process uses the set of
    information and network parameters to generate the output pattern. Then, the testing
    phase is initiated to identify the student’s new input. Here, the associative
    memory model recalls the output value for given inputs by examining the student’s
    academic information and the corresponding output estimation illustrated in In
    equations (4) and (5), W is denoted as the weight value for the given input ,
    and is the output for the input . After recalling the output pattern, the student’s
    performance should be retrieved using the retrieval procedure. The strength of
    associative memory network output computation connections can alter over time
    in response to changes in the stimulation pattern. Neurons can also make new connections
    with other neurons, and whole groups of neurons can migrate from one location
    to another. Learning in the brain is assumed to be based on several mechanisms.
    Learning and memory are underpinned by associative memory network output computation,
    a fundamental biological function. Numerous learning rules detailing how activity
    and training experience alter synaptic efficacies have been computed, as a result,
    using associative memory network output computation. For every unknown student
    input X, the memory layer analyzes and retrieves the input-associated output.
    The output is estimated according to the steps defined in Table 2. Table 2  Steps
    for associative memory network output computation. According to the above algorithm,
    the given student inputs are processed to get the output patterns. The memory-associated
    network learns the data points from different types of data that must be changed
    to the bipolar pattern. Here, the inputs are processed in terms of binary elements
    such as −1’s and 1’s. The dataset information may contain the multiple patterns
    processed by arranging the 2-D patterns embedded in the column for the output.
    As defined in Figure 1, the memory network has a memory cell that relates every
    input with the respective output. The neural model encodes the X input to the
    Y output using pattern mapping. The mapping process has equal dimensions for both
    input and output values. At the time of mapping, the network has input, an output
    layer, and respective network parameters such as synaptic weight. As shown in
    Figure 1, the network has n neurons that can process the input in the input layer
    to get the output value. Initially, the input x is forwarded to the memory cell
    incorporated in the output layer. The input and output patterns determine the
    associative network layer size. Here, the network has five neurons and four memory
    cells for processing the inputs. The introduced network has a memory unit that
    computes the outputs according to several inputs. Each neuron has a specific weight
    involved in the output estimation process. According to the input, the output
    patterns are recalled to identify the student''s performance. After computing
    the output value for each input, the output layer weighted summation result is
    estimated and fed into the bipolar threshold function. Then, the network produces
    the negative (−1) and positive (+1) values as the output. The network manages
    the entire processing parameters, such as input, synaptic weights, memory function,
    and cells, which helps to improve the overall output pattern identification. The
    network uses the Hebbian supervised learning (HSL) algorithm to enhance the system
    performance. The learning process is utilized to recall the output pattern for
    the given input. During the learning process, the X and Y dot products are computed,
    producing the correlation matrix W. Here, the W is defined and the recollected
    output for a given input. The recall process is done by performing the dot product
    or . This analysis keeps most of the weight value and discards the weight values
    when it has zero. The recall process has that is obtained from the input and output
    patterns. During the student performance analysis, the system must handle the
    classification problem due to the incomplete data and weak classifier. The research
    problem is overcome by applying the boosting algorithm. The boosting process is
    used to change the weak learners into strong learners. The boosting algorithm
    generates the training or learning model using the training data. Then, errors
    are identified from the created model, which helps to reduce the error rate in
    student performance analysis. This work uses the adaptive boosting (AdaBoost)
    algorithm to make decisions regarding student performance. The training model
    was developed by considering the equal weights of the entire data points. The
    training process is performed to get the minimum error rate. Suppose the network
    has n data points, then each neuron has 1/n as an equal weight value in every
    node. After computing the equal weight value, Gini Index (GI) value for each feature
    should be estimated: In equation (6), is represented as the student’s academic
    attributes. All student attributes are explored to get the GI value. The GI is
    partially represented as the relative mean absolute difference (RMAD), equivalent
    to the Lorenz curve. The computed GI value identifies the difference between the
    two features, which identifies the student involvement in learning. The GI had
    values between 0 and 1; it helps to identify the positive and negative impact
    of the HESD. After identifying the GI value, the importance of the classifier
    must be analyzed by computing the error rate (equation 7). According to the RMAD,
    the student’s academic attributes, assessment scores, final results, and other
    learning factors are investigated to alert the student interventions. Students''
    privacy concerns can be alleviated by minimizing the requirement for invigilators
    or having access to their accounts because of the high level of accuracy (93%).
    In equation (7), TE is denoted as the total error, estimated by computing the
    summation of the misclassified data points corresponding sample weight value.
    After calculating the classifier importance and TE value, the deviation between
    the actual and computed output is estimated. If the training model has the error
    value, then the network parameter weight value has been updated. Then, the new
    weight value is estimated using In equation (8), is defined as the new weight
    value computed from the old weight value and importance. If the importance has
    a negative value, then the AA-BAM approach correctly classifies the student learning
    performance toward HESD. Suppose the importance value produces the positive, then
    the samples have been misclassified. This process is repeated continuously until
    to get a lower error rate. The effective utilization of the memory cell and AdaBoost
    algorithm improves student performance in HESD. According to the student performance,
    particular subject development in HE feedback is collected from teachers. The
    classifier predicts the positive and negative feedback depending on the cumulative
    grading points and student involvement. The collected reviews are examined, and
    the committee gives the amending outlines for improving the HESD performance.
    3.4. HESD Amending Guidelines The subject development importance should be examined
    according to the student results classified from the AA-BAM. The feedback and
    results of HESD require minor and significant amendments. After making the amendments,
    the committee members re-evaluate the developed subjects to be incorporated into
    higher education. In higher education, artificial intelligence has fulfilled the
    role of low-level instruction. The use of the AA-BAM network in higher education
    institutions is becoming increasingly widespread. Instructors and students may
    better understand each other’s learning situations through data collecting, analysis,
    categorization, and matching. Teaching approaches that encourage students’ creativity,
    collaboration, emotional intelligence, and other social skills will be developed
    so that instructors have new tools to use. Allowing students to leave the classroom
    and no longer be bound by objectives and assignments improves the trajectory of
    higher education growth. 3.4.1. Minor Amendments (i) The student performance assessment
    time needs to be extended to improve the student learning efficiency. (ii) Subject
    task and assessment workload calculator must be utilized for a different task,
    broad content, and model for evaluating the student performance. During the assessment,
    the subject coordinator’s permission needs to be received, and the task weight
    values are unchanged. (iii) The subject coordinator needs to assess the lecturer’s
    notes, reference list, and textbook changes for accepting and rejecting the changes.
    According to the student score, the subject development process has taken almost
    1 to 2 months to approve the HESD. (iv) The contextualization elements are updated
    continuously because it does not impact the subject objectives. Suppose the student
    attains negative feedback or marks; the HESD requires significant amendments.
    After performing the amendment, students are instructed to learn the new subjects,
    and their performance is evaluated to understand the HESD importance. 3.4.2. Major
    Amendments (i) Alter the corequisite or prerequisite of the subject. The lecture
    must give a copy of the subjects to the subject coordinator to enhance the learning
    process. The subject changes are done based on expert accreditation. It may take
    1 to 2 months to prepare. (ii) Helping students in big courses to properly advance
    through their learning experience to reach targeted results, conducting evaluations,
    and providing constructive individualized feedback remained problems required
    for subject-related examinations. (iii) Outline of the subject, code, and name
    of the subject should be considered. The subject coordinator takes charge of updating
    the subject concept, and the changes should be in the rationale. This process
    has also taken almost two months. (iv) The subject teaching framework, answer
    formation, and practical analysis should be reviewed by the Teaching and Learning
    Committee and the Subject Coordinator. According to the importance of the concept,
    the committee members may accept and reject the subjects. In this stage, extra
    support has to be needed to improve the overall learning process. After making
    the appropriate amendment, the changes involved in the subject, proposal, and
    framework should be updated with the lecturer, Dean of Faculty, Subject Coordinator,
    stakeholders, program director, head of the department, and library. These members
    update the subject ideas, and master copies are managed for further assessment.
    4. Results and Analysis Information from the Kalboard 360 Learning Management
    System (LMS) is used to compile this data collection. Using cutting-edge technology,
    Kalboard 360s multi-agent LMS is meant to make learning easier. A system allows
    students to admittance instructional information in real time from somewhat Internet-connected
    device. Using a technology called experience API, learner activity data are gathered.
    Training and learning architecture (TLA) keeps track of how much a student has
    learned and what actions they have taken, such as reading, viewing, and training
    video. Learners, activities, and objects that characterize a knowledge experience
    may be identified using the involvement API. Of 480 student records and 16 different
    characteristics, 150 student records have been considered to make up the dataset
    in this study. It may be divided into three primary groups: (1) gender and nationality
    of demographic characteristics; (2) educational level, grade level, and sector
    of schooling; (3) behavioral characteristics like raising their hands in class,
    opening up resources, and responding to parent surveys are examples. This section
    discusses the efficiency of the AdaBoost Adaptive-Bidirectional Associative Memory
    (AA-BAM) Network-based HESD. The detailed analysis of the statistical findings
    and AA-BAM approach-related student performance is evaluated. Here, Kaggle dataset
    information is utilized for investigating the student performance on HESD; around
    60% of data is used for training purposes and 40% for testing analysis. The collected
    student academic information is processed by the AA-BAM approach that identifies
    the positive and negative impact of the subject development on the learning system.
    To compare and draw conclusions from the data, this article will use research
    methodologies and analysis tailored to specific challenges. According to surveys,
    almost all students (approximately 85–75%) agree that the future of higher education
    may be brightened by the implementation of artificial intelligence (AI). Students
    cannot keep up with today’s fast-paced culture unless we help them develop self-directed
    learning skills using active learning for the rapid growth of higher education
    under AI. The introduced neural classifier resolves the weak learner involvement
    and binary classification problem. The developed neural model should consume the
    minimum error rate, which means the system consumes a minimum deviation between
    the actual and predicted values. The low square value means the computed output
    values are more relevant to the output patterns. The error values are calculated
    by applying the following equation: In equation (9), is defined as the computed
    output value, and it has to be compared with the target output . The calculated
    error values are close to error, which means the introduced algorithm successfully
    predicts the output with maximum accuracy. In addition, accuracy, sensitivity,
    specificity, and correlation metrics are utilized to evaluate the effectiveness
    of the introduced system. These metrics are estimated using the following equations:
    In equations (10–12), true positive (TP) is defined as the AA-BAM approach correctly
    identifying the student performance from their learning attributes. True negative
    (TN) means wrongly identifying the student''s performance, false positive (FP),
    which eliminates the wrong information while analyzing the student''s performance.
    False negative (FN) means rightly rejecting the false student attribute. The discussed
    system was developed using the Python tool. During the analysis, academic-related
    features such as study hours, reading frequency, cumulative grade points, and
    classroom flips are utilized. The obtained results are compared with the existing
    algorithms such as deep learning approach (DLA) [ 20], sparse attention convolution
    neural network (SACNN) [ 21], graph convolutional neural network (GCNN) [ 22],
    and radial basis function neural model (RBFN) [ 23]. Then, the obtained results
    are illustrated in Figure 4.   (a)                 (a)  (b)  (c)  (d)  (e)  (f)  (g)  (h)                 Figure
    4  (a, b) Accuracy analysis; (c, d) sensitivity analysis; (e, f) correlation analysis;
    (g, h) error rate analysis of AA-BAM. Figure 4 illustrates the efficiency analysis
    of the introduced AA-BAM algorithm with the existing method-based student performance
    analysis system. Here, the AA-BAM approach attains 98.78% of accuracy, 98.41%
    of sensitivity, and 98.57% of correlation values for different students’ academic
    records. The analysis is extended for different iterations, and the introduced
    AA-BAM approach attains high results such as 98.54%, 98.52%, and 98.41% of correlation
    analysis values. The above results clearly show that the introduced AdaBoost Adaptive-Bidirectional
    Associative Memory (AA-BAM) approach successfully recognizes student performance
    from data collection. During the analysis, the recommended AA-BAM approach uses
    the student academic features collected from the Kaggle dataset. The attributes
    in the dataset were successfully processed by the data preprocessing and bidirectional
    associative memory network function. A combination of statistical and clustering
    algorithms is utilized in the data preparation and cleaning procedure. The effective
    utilization of the mean filter helps to remove the noise and inconsistent data.
    The less inconsistent values help to improve the overall student performance analysis.
    In addition, the associative memory network uses the memory cell (m) that predicts
    the output pattern for every input effectively. The network uses the training
    model to identify the matching patterns that effectively recognize student performance.
    The training model is generated according to the AdaBoost algorithm that reduces
    the weak learner''s involvement in the classification process. The boosting procedure
    continuously updates the network weight value, . The computed weight values are
    incorporated with the input to get the output pattern. Here, the student information
    is explored in the initial stage to reduce the inconsistent and outlier data by
    applying the centroid-based clustering algorithm. During this process, the K-means
    clustering algorithm estimates the distance between the data and the centroid.
    According to the distance measure, similar data are grouped; this process minimizes
    the error rate. The training model is created by using the supervised learning
    model, which is done by utilizing the Gini Index . The GI value is continuously
    checked to reduce the difference between computed and target output values. In
    addition, the summation of the misclassified data points with corresponding sample
    weight values is estimated via equation (7). These two parameters are widely applied
    to improve the overall student academic performance analysis. The dataset covers
    almost students'' entire academic information that helps to identify the variations
    involved in the student learning activities. According to the derived student
    academic performance, the HESD efficiency is analyzed to get how the student performance
    is interrelated with the subject change. The HESD and student performance relationship
    are analyzed using Spearman’s Rho correlation analysis (SRC). The SRC is one of
    the effective nonparametric tests that help to identify the strong association
    between student learning performance and subject change. If the SRC relation (r)
    has the value of one, both attributes have a strong relationship, and -1 means
    that it has a negative correlation analysis. The SRC value is estimated using
    the following equation: In equation (13), D is defined as the difference between
    the two observations, and n is the quantity of observations. Here, the efficiency
    is assessed for 250 students’ academic records, and the results are illustrated
    in Table 3. Table 3  Spearman’s rho correlation analysis. Table 3 shows the relationship
    between the student’s academic attributes and subject development in higher education.
    Here, the analysis uses the expected outcome of the student attribute with the
    target attribute. The correlation analysis uses the rank value and means value
    for x that identifies the relationship between the two attributes in the computation.
    From the analysis, the system ensures the 0.77% value related to a positive value,
    which means that the student performance also creates the subject development
    in the HE. Therefore, in higher education system, student performance has been
    creating a significant impact on the HESD. If the calculated student performances
    are more significant to the subject development, then it requires minor reforms
    in the subject development. Students are surveyed using HESD to uncover the underlying
    factors contributing to failure or success. It was decided to use Spearman’s correlation
    coefficient model to examine the traits of success and failure that are most closely
    linked. Results suggest a significant association exists between exogenous variables
    such as students'' desire to excel in their education and the job environment.
    Students’ performance is highly influenced by factors specific to the institutions,
    such as the clarity and understanding of the ability of test papers and study
    resources. In light of these findings, this research should take a comprehensive
    and inclusive approach to develop and execute strategies targeted at enhancing
    student performance and avoiding obstacles that impede student achievement. Else,
    significant changes are required, which are described in Section 3.4. According
    to the results, subject development changes are made to improve the overall academic
    performance. Hence, it is suggested to understand the broader context of development,
    research, and assess the changing nature of industry demand, grab new possibilities,
    meet new problems head-on, and collaborate to advance higher education in the
    new millennium. 5. Conclusion Thus, the paper analyzes the AdaBoost Adaptive-Bidirectional
    Associative Memory (AA-BAM)-based Higher Education Subject Development (HESD).
    This work uses Higher Education Students Performance Evaluation dataset information
    to evaluate the relationship between student performance and subject development.
    The collected student details are investigated by applying the preprocessing procedure
    that eliminates the irrelevant, missing data, and outlier information. During
    this process, each data point’s distance and characteristic are examined to form
    the cluster. This centroid-based clustering procedure reduces outlier involvement.
    Then, memory associative neural network is utilized to save the processed information.
    The memory cells are more helpful in recalling the output patterns relevant to
    the inputs. In addition, Hebbian supervised learning (HSL) is incorporated to
    improve the overall student performance detection efficiency by creating the training
    model. The subsequent development of training data reduces the difficulties in
    extensive volume data and subject-based improvement. The created system successfully
    recognized the student performance up to 98.78%. According to the student performance,
    the HESD subjects are amended to improve the learning quality. However, this system
    requires improvement while handling students’ entire academic features. The large
    volume of data has to be reduced by applying the dimensionality reduction technique.
    The selected features help to improve the overall HESD performance. Data Availability
    The data that support the findings of this study are available from the corresponding
    author upon reasonable request. Conflicts of Interest The author declares that
    there are no conflicts of interest regarding the publication of this paper. References
    J. Martins, F. Branco, R. Gonçalves et al., “Assessing the success behind the
    use of education management information systems in higher education,” Telematics
    and Informatics, vol. 38, pp. 182–193, 2019. View at: Google Scholar S. Quarchioni,
    S. Paternostro, and F. Trovarelli, “Knowledge management in higher education:
    a literature review and further research avenues,” Knowledge Management Research
    and Practice, vol. 20, no. 2, pp. 304–319, 2022. View at: Google Scholar D. A.
    Housel, “An exploratory study of instructors who became administrators of post-secondary
    ESOL programs in the United States,” The Journal of Continuing Higher Education,
    pp. 1–15, 2022. View at: Publisher Site | Google Scholar S. Subhash and A. Elizabeth,
    “Cudney Gamified learning in higher education: a systematic review of the literature,”
    Computers in Human Behavior, vol. 87, pp. 192–206, 2018. View at: Google Scholar
    H. J. Machumu, Constructivist-based Blended Learning Environments in Higher Education:
    Student and Teacher Variables in the Tanzanian Context, Vrije Universiteit Brussel,
    Brussels, Belgium, 2018. P. R. Kitula and O. Evans, “Effectiveness of implementing
    continuous assessments in Tanzanian universities,” International Journal of Contemporary
    Applied Researches, vol. 5, no. 7, pp. 1–18, 2018. View at: Google Scholar A.
    S. Mikhaylov and M. Anna Alekseevna, “University rankings in the quality assessment
    of higher education institutions,” Calitatea, vol. 163, pp. 111–117, 2018. View
    at: Google Scholar D. Wang, Y. Sun, and T. Jiang, “The assessment of higher education
    quality from the perspective of students through a case study analysis,” Frontiers
    of Education in China, vol. 13, no. 2, pp. 267–287, 2018. View at: Google Scholar
    C. Adachi, J. H.-M. Tai, and P. Dawson, “Academics’ perceptions of the benefits
    and challenges of self and peer assessment in higher education,” Assessment and
    Evaluation in Higher Education, vol. 43, no. 2, pp. 294–306, 2018. View at: Google
    Scholar A. Armellini, V. T. Antunes, and R. Howe, “Student perspectives on learning
    experiences in a higher education active blended learning context,” TechTrends,
    vol. 65, no. 4, pp. 433–443, 2021. View at: Google Scholar R. Alamri and B. Alharbi,
    “Explainable student performance prediction models: a systematic review,” IEEE
    Access, vol. 9, pp. 33132–33143, 2021. View at: Google Scholar A. Rivas, A. Gonzalez-Briones,
    G. Hernandez, J. Prieto, and P. Chamoso, “Artificial neural network analysis of
    the academic performance of students in virtual learning environments,” Neurocomputing,
    vol. 423, pp. 713–720, 2021. View at: Google Scholar D. Aggarwal, S. Mittal, and
    V. Bali, “Significance of non-academic parameters for predicting student performance
    using ensemble learning techniques,” International Journal of System Dynamics
    Applications, vol. 3, pp. 38–49, 2021. View at: Google Scholar S. F. Shetu, M.
    Saifuzzaman, S. Sultana, and R. Yousuf, “Student’s performance prediction using
    data mining technique depending on overall academic status and environmental attributes,”
    in Proceedings of the International Conference on Innovative Computing and Communications,
    Springer, Berlin, Germany, 2021. View at: Google Scholar J. Annala, M. Mäkinen,
    J. Lindén, and J. Henriksson, “Change and stability in the academic agency in
    higher education curriculum reform,” Journal of Curriculum Studies, vol. 54, no.
    1, pp. 53–69, 2022. View at: Google Scholar J. F. Duque, “A comparative analysis
    of the Chilean and Colombian systems of quality assurance in higher education,”
    Higher Education, vol. 82, no. 3, pp. 669–683, 2021. View at: Google Scholar I.
    M. Ho, K. Y. Cheong, and W. Anthony, “Predicting student satisfaction of emergency
    remote learning in higher education during COVID-19 using machine learning techniques,”
    PLoS One, vol. 16, no. 4, Article ID e0249423, 2021. View at: Google Scholar V.
    Kuleto, M. Ilić, M. Dumangiu et al., “Exploring opportunities and challenges of
    artificial intelligence and machine learning in higher education institutions,”
    Sustainability, vol. 18, Article ID 10424, 2021. View at: Google Scholar R. Hernández,
    C. Felipe, M. Musso, E. Kyndt, and E. Cascallar, “Artificial neural networks in
    academic performance prediction: systematic implementation and predictor evaluation,”
    Computers and Education: Artificial Intelligence, vol. 2, Article ID 100018, 2021.
    View at: Google Scholar F. Giannakas, C. Troussas, I. Voyiatzis, and C. Sgouropoulou,
    “A deep learning classification framework for early prediction of team-based academic
    performance,” Applied Soft Computing, vol. 106, Article ID 107355, 2021. View
    at: Google Scholar Y. Zhang, A. Rui, J. Cui, and X. Shang, “Undergraduate grade
    prediction in Chinese higher education using convolutional neural networks,” in
    Proceedings of theLAK21: 11th International Learning Analytics and Knowledge Conference,
    Association for Computing Machinery, New York, NY, United States, 2021. View at:
    Google Scholar P. Hai-tao, H. Zhang, Y. Bi-Zhen et al., “Predicting the academic
    performance of students in Chinese-foreign cooperation in running schools with
    graph convolutional network,” Neural Computing and Applications, vol. 33, no.
    2, pp. 637–645, 2021. View at: Google Scholar O. Olabanjo and A. Wusu, A Machine
    Learning Prediction of Academic Performance of Secondary School Students Using
    Radial Basis Function Neural Network, 2022, https://www.preprints.org/manuscript/202207.0088/v1.
    E. P. Dogadina, M. V. Smirnov, V. O. Aleksey, and V. S. Stanislav, “Evaluation
    of the forms of education of high school students using a hybrid model based on
    various optimization methods and a neural network,” Informatics, vol. 8, no. 3,
    p. 46, 2021. View at: Google Scholar N. Yälmaz and B. Sekeroglu, “Student performance
    classification using artificial intelligence techniques,” in Proceedings of the
    10th International Conference on Theory and Application of Soft Computing, Computing
    with Words and Perceptions—ICSCCW-2019. ICSCCW 2019, Springer, Berlin, Germany,
    2020. View at: Google Scholar Copyright Copyright © 2022 Yancai Wang. This is
    an open access article distributed under the Creative Commons Attribution License,
    which permits unrestricted use, distribution, and reproduction in any medium,
    provided the original work is properly cited. PDF Download Citation Download other
    formats Order printed copies Views 361 Downloads 345 Citations 1 About Us Contact
    us Partnerships Blog Journals Article Processing Charges Print editions Authors
    Editors Reviewers Partnerships Hindawi XML Corpus Open Archives Initiative Fraud
    prevention Follow us: Privacy PolicyTerms of ServiceResponsible Disclosure PolicyCookie
    PolicyCopyrightModern slavery statementCookie Preferences'
  inline_citation: '>'
  journal: International transactions on electrical energy systems
  limitations: '>'
  pdf_link: https://downloads.hindawi.com/journals/itees/2022/8109117.pdf
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: Analysis on the Particularity of Higher Education Subject Development under
    the Background of Artificial Intelligence
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1145/3593043
  analysis: '>'
  authors:
  - Arda Göknil
  - Phu H. Nguyen
  - Sagar Sen
  - Dimitra Politaki
  - Harris Niavis
  - Karl John Pedersen
  - Abdillah Suyuthi
  - Abhilash Anand
  - Amina Ziegenbein
  citation_count: 2
  full_citation: '>'
  full_text: '>

    This website uses cookies We occasionally run membership recruitment campaigns
    on social media channels and use cookies to track post-clicks. We also share information
    about your use of our site with our social media, advertising and analytics partners
    who may combine it with other information that you’ve provided to them or that
    they’ve collected from your use of their services. Use the check boxes below to
    choose the types of cookies you consent to have stored on your device. Use necessary
    cookies only Allow selected cookies Allow all cookies Necessary Preferences Statistics
    Marketing Show details       skip to main content University of Nebraska Lincoln
    Browse About Sign in Register Journals Magazines Proceedings Books SIGs Conferences
    People Search ACM Digital Library Advanced Search Journal Home Just Accepted Latest
    Issue Archive Authors Editors Reviewers About Contact Us HomeACM JournalsACM Computing
    SurveysVol. 55, No. 14sA Systematic Review of Data Quality in CPS and IoT for
    Industry 4.0 SURVEY SHARE ON A Systematic Review of Data Quality in CPS and IoT
    for Industry 4.0 Authors: Arda Goknil , Phu Nguyen , Sagar Sen , + 6 Authors Info
    & Claims ACM Computing SurveysVolume 55Issue 14sArticle No.: 327pp 1–38https://doi.org/10.1145/3593043
    Published:17 July 2023Publication History 2 citation 923 Downloads eReaderPDF
    ACM Computing Surveys Volume 55, Issue 14s Previous Next Abstract 1 INTRODUCTION
    2 REVIEW PROCESS 3 A CLASSIFICATION SCHEMA/TAXONOMY 4 RESULTS 5 RELATED WORK 6
    THREATS TO VALIDITY 7 CONCLUSIONS ACKNOWLEDGMENTS PRIMARY STUDIES REFERENCES Cited
    By Index Terms Recommendations Comments Skip Abstract Section Abstract The Internet
    of Things (IoT) and Cyber-Physical Systems (CPS) are the backbones of Industry
    4.0, where data quality is crucial for decision support. Data quality in these
    systems can deteriorate due to sensor failures or uncertain operating environments.
    Our objective is to summarize and assess the research efforts that address data
    quality in data-centric CPS/IoT industrial applications. We systematically review
    the state-of-the-art data quality techniques for CPS and IoT in Industry 4.0 through
    a systematic literature review (SLR) study. We pose three research questions,
    define selection and exclusion criteria for primary studies, and extract and synthesize
    data from these studies to answer our research questions. Our most significant
    results are (i) the list of data quality issues, their sources, and application
    domains, (ii) the best practices and metrics for managing data quality, (iii)
    the software engineering solutions employed to manage data quality, and (iv) the
    state of the data quality techniques (data repair, cleaning, and monitoring) in
    the application domains. The results of our SLR can help researchers obtain an
    overview of existing data quality issues, techniques, metrics, and best practices.
    We suggest research directions that require attention from the research community
    for follow-up work. Skip 1INTRODUCTION Section 1 INTRODUCTION The Internet of
    Things (IoT) and Cyber-Physical Systems (CPS) are among the significant driving
    forces behind Industry 4.0 [153], in particular smart manufacturing [82]. They
    facilitate data acquisition from physical sensors and devices on an unprecedented
    scale and employ Artificial Intelligence (AI) techniques, e.g., Machine Learning
    (ML), to exploit the massive interconnection and large volumes of data. AI-enabled
    CPS/IoT systems improve decision-making and perform predictive maintenance (e.g.,
    tool wear and product defect prediction in the manufacturing domain) for industrial
    processes in Industry 4.0. The quality and continuity of data are the bottlenecks
    for these systems. Many things may cause data quality to decline. For instance,
    CPS/IoT systems may encounter sensor flaws and failures (corrupted sensor measurements)
    due to various problems, such as electromagnetic interference, packet loss, and
    signal processing faults. The faith and reliance on these Industry 4.0 systems
    are diminished by poor data quality. Furthermore, the growing neglect of data
    quality leads to the accumulation of dark data (unstructured, untagged, and untapped
    data that has not yet been analyzed) [74] and the impregnation of biases [55].
    It warrants the need for a detailed analysis of data quality problems/issues and
    data quality management techniques (in short, data quality techniques), i.e.,
    techniques improving and maintaining data quality, that can run with CPS and IoT
    in various scenarios, which is the focus of this article. Addressing data quality
    issues/problems is not a new research idea. For various reasons, researchers from
    different fields have already provided different interpretations of data quality
    and disconnected data quality solutions. In the realm of relational databases,
    the notion of data quality concerns the normalization of data [79]. Most data
    quality issues in signal processing refer to a signal/noise ratio. The data science
    community has recently provided numerous tools and methods to “clean” data before
    feeding it into large ML pipelines. The importance of data quality is “the elephant
    in the room” for CPS and IoT, but improving data quality for them is still challenging
    and deserves special attention. First, sensor measurements are often corrupted
    or have missing values due to several (unpredictable) reasons (e.g., electromagnetic
    interference, packet loss, or signal processing faults). Second, CPS/IoT data
    often endure a long journey on the edge-cloud continuum: (i) sensor data obtained
    from monitoring industrial processes is consumed by a rugged industrial computer
    (a programmable logic controller - PLC) to control actuators; (ii) it is transferred
    to an edge device over wired/wireless communication channels using industrial
    communication protocols (e.g., NMEA [134], Bluetooth); and (iii) it is aggregated
    on edge to be transferred to the cloud using protocols (e.g., REST [135], RPC
    [121]). CPS/IoT systems need to detect and manage data quality issues (e.g., erroneous
    values, missing values, noise, data drift) at different stages of this journey
    and preserve data continuity on the edge-cloud continuum. Although several surveys
    and Systematic Literature Reviews (SLR) study and classify data quality research
    for CPS and IoT (see Table 1 for a summary), they do not provide a detailed account
    and unified analysis of data quality research based on the needs and problems
    (data quality definitions, issues, and dimensions), the solutions (data quality
    techniques), and the technological/implementation context (software engineering
    techniques used for improving data quality). For instance, Zhang et al. [156]
    and Liu et al. [110] study the literature on data quality based on quality issues,
    dimensions, and measures but exclude the data quality techniques (e.g., data repair)
    and their solution domain (i.e., the abstract environment where the data quality
    technique is developed). The scope of the SLR conducted by Alwan et al. [58] is
    limited to the data quality challenges and approaches for smart cities. We answer
    three main research questions (ten sub-questions) to address data quality research
    for theoretical and practical implications in a much broader scope for Industry
    4.0. Table 1. Studies Karkouch et al. [100] Wang and Wang [148] Teh et al. [144]
    Liu et al. [110] Zhang et al. [156] Alwan et al. [58] This study Year of completion
    2016 2019 2020 2020 2021 2022 2022 Systematic review? ✗ ✗ ✓ ✓ ✗ ✓ ✓ Number of
    databases used NA NA 3 6 NA 4 4 Show More Table 1. Recent Systematic Literature
    Reviews and Surveys on Data Quality in CPS and IoT for Industry 4.0 RQ1: What
    is data quality for CPS and IoT in Industry 4.0? RQ2: What data quality techniques
    are used for CPS and IoT in Industry 4.0? RQ3: What software engineering solutions
    are used for data quality for CPS and IoT in Industry 4.0? We implement a typical
    four-step SLR process [104, 130, 150]: (i) the definition of research questions,
    (ii) a search strategy including the selection of online repositories and search
    strings, (iii) inclusion and exclusion criteria, and (iv) a data synthesis and
    extraction procedure. The search led to fifty-one (51) primary studies, which
    we analyzed using our taxonomy of data quality in data-driven paradigms to address
    three research questions. We also deliver a high-level summary of data quality
    for CPS and IoT in Industry 4.0. Researchers can use this summary and the taxonomy
    to classify and compare future data quality studies. • The main data quality issues
    addressed by the primary studies are outliers (isolated, erroneous values), missing
    values, noise in data, data timeliness (freshness), high dimensionality, data
    inconsistency, and data veracity. The studies do not address the implications
    of different computing architectures for data quality issues for CPS and IoT.
    There is also little research discussing the reasons for data quality issues (RQ1).
    • Although there is a large spectrum of data quality metrics, no study reports
    the adoption of these metrics in industrial IoT systems as a common practice.
    Across primary studies, data repair techniques address missing values, data veracity,
    and outliers. Most of these techniques are non-AI solutions having limitations
    in the industrial CPS/IoT context. Most data cleaning techniques are domain agnostic
    and may not always detect and clean domain-specific data quality issues. The evaluation
    metrics are mainly used to assess the impact of the data quality techniques on
    the performance of predictive analytics (RQ2). • The existing data quality techniques
    address only particular quality management scenarios (online or offline). They
    are not deployed on different IoT reference architecture layers for diverse scenarios
    depending on the needs of the targeted IoT system. The programming languages,
    technologies, and models used to manage data quality are highly subject to the
    solution domain (e.g., ML, data mining, semantic web). For instance, Python is
    almost the de-facto programming language in the studies providing ML-based solutions.
    There is no direct relation between the database technologies and the data quality
    techniques (RQ3). This article is structured as follows: In Section 2, we present
    our Systematic Literature Review (SLR) approach. Section 3 describes our classification
    schemes for the primary studies. We present the results of our SLR in Section
    4. We discuss the related work in Section 5. Section 6 analyzes threats to the
    validity of our SLR. Section 7 concludes this article. Skip 2REVIEW PROCESS Section
    2 REVIEW PROCESS This section discusses the steps of our review process using
    the popular guidelines [104, 130, 150]: (a) the definition of Research Questions
    (RQs), (b) a search strategy (selecting repositories and search strings), and
    (c) study selection based on inclusion and exclusion criteria. We also provide
    a summary of the search results in this section. 2.1 Research Questions This SLR
    answers the three Research Questions (RQ)s presented in Section 1. We extend each
    one with sub-questions. RQ1 includes three sub-RQs. • RQ1.1-What are the data
    quality issues for CPS and IoT in Industry 4.0? • RQ1.2-What are the application
    domains for data quality research? What types of data are collected? • RQ1.3-What
    is the trade-off between data quality and data security? RQ2 has four sub-RQs.
    • RQ2.1-What are the data quality metrics for data quality monitoring? • RQ2.2-What
    are the data repair techniques? • RQ2.3-What are the data cleaning techniques?
    • RQ2.4-How are data quality techniques evaluated? RQ3 has three sub-RQs. • RQ3.1-What
    programming languages and solutions are used to manage data quality? • RQ3.2-What
    data storage solutions are used to manage data quality? • RQ3.3-What IoT reference
    architecture layers are covered in the primary studies? 2.2 Inclusion and Exclusion
    Criteria Considering the RQs and the basis of our study, we set the inclusion
    and exclusion criteria to reduce bias in our search and selection approach. The
    primary studies must meet ALL the accompanying inclusion criteria (see Table 2).
    Table 2. Inclusion Criteria IC1 The article is written in English. IC2 The article
    addresses data quality in any aspect (directly or indirectly). IC3 The article
    is about collecting and processing data from CPS, IoT, and Industry 4.0. Show
    More Table 2. Inclusion Criteria When more than one paper described different
    aspects of the same approach (e.g., the approach itself, an empirical investigation,
    and an evaluation), we considered those articles part of the same approach. If
    multiple articles detailed the same approach (not different parts) in different
    venues, we included only the most recent one with the most description. We removed
    the ones not written in English, those not peer-reviewed, and those not providing
    much content (less than four pages in double-column format or six pages in single-column
    format), extended abstracts, posters, or presentations. We excluded surveys, SLRs,
    or systematic mapping papers. However, we discussed them in the related work section
    (Section 5). We included all the articles in the search results without setting
    any publication period. 2.3 Search and Selection Strategy We employ two common
    methods to find primary studies: database search [104] and manual search (snowballing)
    [150]. 2.3.1 Database Search. Using online inquiry components of popular publication
    databases is the most notable approach to scan for primary studies when directing
    supplemental studies [104]. We used four popular publication databases, i.e.,
    IEEE Xplore ( https://ieeexplore.ieee.org), ACM Digital Library ( https://dlnext.acm.org),
    ScienceDirect ( https://sciencedirect.com/), and Scopus ( https://scopus.com),
    to search for potential primary studies. Scopus and ACM DL already index SpringerLink
    ( https://www.springer.com) [145]. These databases contain peer-reviewed articles
    and provide advanced search capacities. We defined our search keywords by following
    the guidelines from [104]. The search query was adapted to fit the search engine
    of each publication database. (“Internet of Things” OR “IoT” OR “Cyber Physical
    Systems” OR “Industry 4.0”) AND (“sensor data” OR “data completeness” OR “data
    quality” OR “data repair” OR “sensor calibration”) AND (“machine learning” OR
    “AI” OR “digital twin” OR “reference model”) Figure 1 gives an overview of the
    search and selection steps. We first filtered the candidate articles based on
    their titles and abstracts. When the titles and abstracts were not enough to decide
    whether to discard or keep the articles, we continued to skim and scan through
    the contents of these articles. When a candidate article appeared in more than
    one database, we kept it, at first, in multiple search results. Then, we consolidated
    the outcomes with group discussions among the authors to acquire the first set
    of primary studies with no duplicates. Fig. 1. Fig. 1. Overview of the search
    and selection steps. 2.3.2 Manual Search. It is unattainable to ensure that the
    database search covers all the primary studies. Thus, we supplemented the database
    search with a manual search, as suggested by Wohlin [150]. We found eight more
    primary studies. Please note that we kept candidate papers in doubt for further
    evaluation and cross-checking. Our search and selection process ended with 51
    primary studies at the end of 2021 for data extraction and synthesis. 2.4 Data
    Synthesis and Extraction Method This section discusses the search results and
    extraction methods. We included 51 primary studies in our study. We extracted
    related information from these studies according to our RQs (see Table 3). Table
    3. Research Question Type of Data Extracted RQ1 Data quality issues, their sources,
    data types and application domains, data quality metrics. RQ2 Data quality techniques
    and their reported strengths and limitations. RQ3 Architectures, programming technologies
    and databases used for data quality. Table 3. Data Collection for Each Research
    Question There were 28 conference papers, 21 journal articles, and two workshop
    papers. We gathered papers from ACM International Conference on Distributed and
    Event-Based Systems (DEBS), ACM Symposium on Information, Computer and Communications
    Security (CCS), ACM Multimedia Systems Conference (MMSys), ACM SIGKDD International
    Conference on Knowledge Discovery and Data Mining (KDD), IEEE International Symposium
    on Parallel and Distributed Processing with Applications (ISPA), IEEE International
    Conference on Big Data, and IEEE International Conference on Computer Communications
    and Networks (ICCCN). We also retrieved papers from ACM Transactions on Cyber-Physical
    Systems, Computers in Industry, and Information Systems. They are all well-known
    and credible publication venues for data quality, CPS, and IoT research. There
    is a growth in publication numbers from 2011 to 2021, with a sharp increase after
    2018 (92% of the primary studies are published after 2018). According to this
    trend, we can conclude that data quality research for CPS and IoT has been popular
    in recent years. Skip 3A CLASSIFICATION SCHEMA/TAXONOMY Section 3 A CLASSIFICATION
    SCHEMA/TAXONOMY Kuhn defines a scientific paradigm in his book “Structure of Scientific
    Revolutions” [138] as “universally recognized scientific achievements that, for
    a time, provide model problems and solutions for a community of practitioners”.
    We are inspired by this definition and use the term Data-driven Paradigm for systems
    that leverage large streams/batches of data to control, manage, and optimize processes
    in different industrial sectors. The Data-driven Paradigm is the root node of
    our taxonomy (as shown in Figure 2), which we extend for IoT and CPS that are
    data-driven to a large extent. The Data Quality Management Technique is the main
    entity in our taxonomy. Fig. 2. Fig. 2. Taxonomy of data quality in data-driven
    paradigms. 3.1 Data Quality Management Techniques A data-driven paradigm contains
    zero to many data quality management techniques. Data quality management techniques
    (in short, data quality techniques) aim at improving and maintaining data quality
    across system components. We identify three types of techniques: • Data Monitoring
    : Data is monitored to detect data quality issues such as outliers and noise.
    • Data Cleaning : It is a technique that entails removing corrupt and unusable
    data, e.g., those affected by environmental noise or extreme operating conditions
    such as high temperature. • Data Repair : It is a technique to restore data that
    has been lost, accidentally deleted, corrupted, or made inaccessible, e.g., by
    using simulation data or data from redundant sources (other sensors). Data quality
    techniques can be online (real-time at the data source) and offline (for large
    historical datasets on the cloud). They have zero to many quality standards and
    data quality metrics. Quality Standards provide requirements, guidelines, or characteristics
    used to ensure that materials, products, processes, and services serve their purpose.
    An example standard is a documented agreement on data representation, format,
    and definition. Standardization organizations define data quality standards (e.g.,
    ISO 8000 [87]). Data Quality Metrics are the measurements by which you assess
    your data. They benchmark how complete, valid, accurate, timely, and consistent
    the data is and help differentiate between high-quality and low-quality data.
    A data quality technique has an Automation Level indicating whether it is fully
    Automated, Manual, or supports a human operator with Assisted Decision Making.
    3.2 Algorithms to Support Data Quality Techniques A data quality technique uses
    zero to many Algorithms to enable automation, manual inspection, and assisted
    decision-making. Algorithms typically require one or more sources of Input Data
    and may generate zero to many Output Data. We measure algorithm performance by
    using zero to many Performance KPIs. For instance, input data can be time-series
    data from a sensor, output data can be an anomaly in the input data, and performance
    KPI can be the classification accuracy. We categorize algorithms that support
    data quality techniques as follows: Rules are declarative constraints input data
    need to satisfy for high quality. They can specify what is not expected. ML Algorithms
    [86] are for Supervised, Unsupervised, or Reinforcement learning. They are used
    to detect data quality issues or clean and repair data. Supervised learning maps
    an input to an output based on example input and labeled/classified output pairs.
    Unsupervised learning identifies patterns in input data that are neither classified
    nor labeled. Reinforcement learning is based on rewarding desired actions and
    punishing undesired ones through trial and error. Signal Processing Algorithms
    [127] analyze, modify, and synthesize sensor signals. They support the storage,
    compression, and reconstruction of signals, separation of information from noise,
    and feature extraction from signals. Statistical Algorithms entail the creation
    of a statistical model of the input data and use statistical quantities such as
    min, max, median, standard deviation, and quartiles on the input data to detect
    data quality. 3.3 Software Engineering Solutions to Support Data Quality Techniques
    Software Engineering Solutions (Data Storage Technologies, Programming Language,
    and Software Framework) support data quality techniques. Being aware of multiple
    interpretations, we use the term software framework as a software engineering
    solution (e.g., data pipeline, big data platforms) providing generic software
    functionality that can be selectively changed by additional user-written code,
    thus providing application-specific software. These solutions are built on Architecture/Infrastructure
    Elements in the IoT architecture, such as Sensors, Edge devices, Cloud infrastructure,
    and, in some cases, local Fog infrastructure. An Edge device connects sensors
    or data sources in a local area network. It can also link the local area network
    to a wide area network or the Internet. Cloud infrastructure offers virtual resources
    for scalable and reliable computation and storage. It is available on the Internet
    as Infrastructure as a Service (IaaS). Fog infrastructure consists of an IoT gateway
    within the local area network of Edge devices and connects them to the Cloud.
    Data Storage Solutions. Figure 2 gives the list of data storage solutions in our
    taxonomy. Blockchain stores data in blocks chained together in chronological order.
    The common blockchain application is a ledger for transactions. Distributed file
    systems allow access to files from multiple hosts sharing via a network, making
    it possible for multiple users on multiple machines to share files and storage
    resources. A database is an organized collection of structured information, or
    data, usually controlled by a database management system (DBMS). DBMS can be categorized
    into [88]: (i) relational DBMS, (ii) document-oriented DBMS, (iii) graph-oriented
    DBMS, (iv) column family DBMS, (v) native XML DBMS, (vi) time series DBMS, (vii)
    Resource Description Framework (RDF) stores, and (viii) key-value stores. Programming
    Languages. Our taxonomy covers programming languages in three categories: Interpreted,
    Compiled, and Markup. An interpreted language supports the execution of instructions
    without compiling them to machine code. Query languages are interpreted languages
    for searching, viewing, and changing the content of a database. Compiled languages
    translate source code to machine code as opposed to interpreted languages. Hardware
    description languages are compiled languages that support the automated analysis
    and simulation of electronic circuits. A Markup language is a system for annotating
    a document visually distinguishable from the content. Software Frameworks. Our
    taxonomy classifies software frameworks as ML Frameworks, Data Pipelines, Data
    Visualization, Data Analytics, and Big Data Frameworks. ML Frameworks enable ML
    models to be developed without understanding the underlying algorithms. Data Pipelines
    process data in a sequence where the output from one component becomes the input
    for the next component. Data Visualization frameworks support the process of translating
    large datasets and metrics into charts, graphs, and other visuals. Search Engines
    help find the information by using keywords or phrases. Data Analytics frameworks
    enable data analysis in an organized way. A Big Data Framework is an ecosystem
    of different components that process, handle and store large amounts of data.
    IoT Arcitecture. The IoT World Forum Reference Model [98] is one of the numerous
    IoT architectures in the literature. It supports fine-grained granularity across
    various layers that make up an IoT system. Many large-scale IoT systems have lately
    incorporated this architecture [75]. It has seven layers. L1 Physical Devices
    and Controllers layer contains sensors, edge node devices, and other devices.
    L2 Connectivity layer enables transferring data from the Cloud to devices and
    vice-versa. L3 Edge Computing layer brings computation and storage closer to where
    data are gathered. The protocol conversion, routing to higher-layer functions,
    and “fast path” logic for low-latency decision-making are implemented here. L4
    Data Accumulation layer converts sensor data in motion to data at rest. It stores
    the data in an easy-access format and reduces it through filtering and selective
    storing. L5 Data Abstraction layer focuses on rendering data and their storage
    in ways that enable performance-enhanced applications. Information interpretation
    occurs at L6 Application layer. The software interacts with L5 and data at rest.
    Thus, it does not have to operate at network speeds. L7 Collaboration and Processes
    layer enables human interaction with all the other layers. A simpler IoT architecture
    adopted in the literature (e.g., [44]) consists of three layers: data acquisition/perception
    (L1), network (grouping L2 and L3), and data service/application (grouping L4,
    L5, L6, and L7). Skip 4RESULTS Section 4 RESULTS With the three research questions
    (RQ1, RQ2, and RQ3), we have investigated the context, application, and problem
    domains (data quality issues and sectors where data quality issues are addressed),
    solution domains (data quality techniques, data quality metrics, and how these
    techniques are evaluated), and implementation domains for solutions (programming
    languages, libraries, frameworks, and data storage techniques). 4.1 RQ1 - What
    is Data Quality for CPS and IoT in Industry 4.0? This research question provides
    an overview of typical data quality issues in CPS and IoT for Industry 4.0, their
    sources, and the application domains for data quality research. To respond to
    RQ1, we address the following three sub-questions: 4.1.1 RQ1.1: What are the Data
    Quality Issues for CPS and IoT in Industry 4.0?. Once data is recorded by sensors,
    it is transformed in several stages until it arrives at the control room, where
    a decision is made automatically or manually. Like any other IT system, the principle
    of garbage-in-garbage-out is also valid here. Poor quality data may adversely
    affect the overall decision-making process. Therefore, data has to be trustworthy
    throughout the data value chain. Eliminating data quality issues (data quality
    problems) as early as possible, for example, when data are first captured, is
    far more efficient than handling data quality issues later in the data value chain
    [97]. This research question aims to identify data quality issues experienced
    in CPS and IoT for Industry 4.0 applications. We expect to gain insights into
    the reasons for these issues and later establish the connection among the data
    quality issues, solutions, methodologies, and application domains we investigate
    in the following questions. The reviewed papers address wide-ranging data quality
    issues. They include, amongst others, outliers (isolated, erroneous values) [2,
    8, 9, 12, 13, 15, 18, 28, 29, 34, 35, 36, 40, 42, 43, 45, 47, 49, 50], missing
    values [1, 2, 3, 6, 9, 14, 17, 18, 20, 25, 28, 32, 33, 35, 36, 37, 38, 39, 43,
    44, 45, 46, 50], duplicated records [9, 14, 18], noise in data [5, 18, 30, 33,
    37, 42, 45, 48], data drift [14], data discontinuity [21], data imprecision [25],
    data timeliness (freshness) [1, 3, 10, 16, 20, 22, 26, 38, 39], high dimensionality
    [9, 18, 42, 43], data inconsistency [1, 3, 4, 6, 10, 25], and data veracity [6,
    7, 11, 19, 23, 27, 31, 33, 38, 39]. Data quality issues are mainly addressed using
    data quality dimensions, i.e., attributes representing a single aspect of the
    data quality [147]. One example of a data quality issue is data inconsistency,
    and data consistency is the corresponding data quality dimension. Another one
    is missing values as the data quality issue of data completeness. Some primary
    studies use data quality issues and dimensions interchangeably (e.g., data freshness
    [1]). Data completeness refers to the degree to which all parts of the data are
    specified with no missing information. Data freshness implies that the sensed
    data are recent and no adversary replays old messages. The reader is referred
    to Wang et al. [149] for the definitions of all the other data quality dimensions.
    Missing values are one of the most addressed data quality issues in the primary
    studies. It refers to cases when one variable or attribute does not have any value.
    Another highly addressed data quality issue is outliers, i.e., extreme values
    that deviate from other observations on data. We observe that the most addressed
    data quality issues are highly related to the types of data the most dealt with
    in the primary studies. Time series is the most addressed data type (see RQ1.2),
    and missing values and outliers are common problems for time-series datasets,
    e.g., due to sensor failures at high sampling frequency and network problems.
    A usual CPS/IoT system includes many diversified components such as sensors, actuators,
    backend, Web, Cloud, and Web/mobile software. These components frequently interact
    on different computing architectures (edge, fog, and Cloud computing) and participate
    in various workflows. We analyze the computing architectures presented in the
    primary studies and their relation to data quality issues (see RQ3.3). Here, we
    can briefly state that the studies in our review do not address the implications
    of these architectures for data quality issues and techniques for CPS and IoT.
    For instance, edge-native systems have limited computing and storage capabilities;
    ML applications require massive volumes of training data in high-dimensional feature
    space to ensure several samples with the combination of possible values for each
    feature. ML applications running at the edge need the high dimension in input
    datasets reduced to increase application performance. On the other hand, a crucial
    but one of the least addressed data quality issues in our review is high dimensionality.
    It refers to datasets that contain a large number of features [103]. Data veracity
    refers to how accurate or truthful a dataset may be and answers questions like
    how trustworthy the data source, type, and processing are. We can distinguish
    it from data quality as it is sometimes considered a data security property [19].
    We investigate the relationship between data security and other quality issues
    in a separate research question (see RQ1.3). Most primary studies on data veracity
    address maliciously manipulated sensor signals. For instance, Krotofil et al.
    [19] assume attackers can tamper with sensors to hide actual sensor signals. The
    primary studies have different classifications for some data quality issues. Noise
    is defined as irrelevant or meaningless data [152]. Corrales et al. [9] classify
    missing values, outliers, high dimensionality, and duplicate records as noise.
    Sanyal et al. [33] differentiate Gaussian noise and outliers as distinct data
    quality issues. Some primary studies (e.g., [30, 45]) refer to noise as unwanted
    and wrong data that should be removed. Some of the studies have different interpretations
    of outliers and anomalies. For instance, Huru et al. [15] use terminology that
    maps outliers to measurement errors and anomalies to unusual events in time series
    data such as temperature and humidity collected from sensors placed inside a greenhouse
    environment. Saybani et al. [35] define anomalies as sensor faults that lead to
    missing values and outliers in sensed data, while Kong et al. [18] use “abnormal
    data” as the term for outliers. Yu et al. [48] treat anomalies as deviations different
    from noise, which is erroneous, out of all potential values, and shows up as a
    spike. Anomalies represent system failures and slightly deviate from common values
    but still occur inside the range. They change slowly as system failures take time
    to stop machine operations. Based on this definition, Yu et al. provide a noise
    filter that removes noise and preserves anomalies (see RQ2). Flick et al. [12]
    follow another definition of outliers, noise, and anomalies. Outliers cover both
    noise and anomalies and are observations that deviate so much from others (normal
    data). Noise represents the semantic boundary between normal data and true anomalies.
    It is a weak form of outliers, focusing on a single data point, whereas anomalies
    are inferred collectively from a set of data points. Not many articles discuss
    the reasons for data quality issues (the reasons for data quality problems) and
    their impact on the proposed solutions. The most mentioned reasons are heterogeneous
    multiple data sources [4, 12, 30, 44, 50], sensor malfunctions [15, 31, 35], network
    problems (connection failures, communication delays) [16, 37, 40], high sampling
    frequency [18], and cyber attacks for data tampering [7, 31]. Wang et al. [44]
    state that dependable, raw time series (time series gathered from multiple sensors)
    are very likely to contain missing values, which could harm the accuracy of data
    analytics. They use the reason (multiple data sensors) to devise their data quality
    technique. To reconstruct missing data, they utilize the correlations between
    time series generated by sensors working together. Flick et al. [12] discuss that
    data from different sources lead to several data quality issues, such as missing
    values, outliers, and missing or invalid time stamps. They provide a conceptual
    framework for data pre-processing of diverse data sources. The framework deals
    with different or even not existing timestamps to merge data from multiple data
    sources. It also deploys outlier treatment algorithms to detect outliers in multivariate
    datasets. Another reason for low-quality data is cyber-physical attacks. Casado-Vara
    et al. [7] study incidents where malicious data lead to poor data quality. They
    present a blockchain-based architecture to improve data security, with an edge
    computing layer executing a new algorithm using game theory for false data detection.
    Kong et al. [18] focus on duplicated data, missing values, and outliers caused
    by high sampling frequency and the vast number of installed sensors. They use
    high sampling frequency to calculate the missing value based on the average value
    of the previous and next data. If there is a wide range of missing data, missing
    values are predicted from the data collected from other sensors observing a similar
    phenomenon. As seen in these few studies, the reasons for data quality issues
    can be crucial in devising data quality management techniques. Therefore, we need
    more research to investigate the dependency among data quality issues, their reasons,
    and data quality management techniques. RQ1.1 Conclusion.. Data quality research
    for IoT and CPS mainly addresses missing values, outliers, and data timeliness.
    The studies in our review do not address the implications of different computing
    architectures for data quality issues and techniques for CPS and IoT. There is
    also little research discussing the reasons for data quality issues (e.g., electromagnetic
    interference, high temperatures, loss of connectivity, and signal processing errors).
    Future research should further investigate the reasons and the implications of
    computing architectures for data quality issues to devise better data quality
    management techniques. 4.1.2 RQ1.2: What are the Application Domains for Data
    Quality Research? What Types of Data are Collected in these Application Domains?.
    Various industries are concerned with questions and research around data quality.
    Figure 3 presents the application domains of the primary studies in our review.
    A big part of the literature (55%) stems from research for manufacturing industries
    (e.g., automotive, semiconductor). Healthcare, environmental research, agriculture,
    and logistics follow manufacturing industries. The use of data analytics technologies
    in manufacturing industries to ensure quality is getting more and more attention
    to increase performance and yield, reduce costs, and optimize supply chains. It
    is known as manufacturing analytics and is part of Industry 4.0, where factories
    evolve into self-running and healing entities by adopting new technologies such
    as IoT. Therefore, most primary studies on manufacturing industries propose manufacturing
    analytics frameworks and support data quality as a preprocessing step for data
    analytics input. For instance, Weiss et al. [46] provide methods for continually
    predicting manufactured product quality in semiconductor manufacturing. The proposed
    methods have a data preprocessing step to predict missing input data. We can conclude
    that data quality is crucial to the manufacturing business since manufacturing
    involves multiple sensors in harsh environments (e.g., a shop floor - the area
    of a factory, machine shop), which may lead to various data quality issues. Please
    note that the most-mentioned reasons for data quality issues in RQ1.1, such as
    heterogeneous multiple data sources, sensor malfunctions, and network problems,
    are likely to occur in such environments. Fig. 3. Fig. 3. Application domains
    of the data quality research for CPS and IoT in Industry 4.0. The data types in
    the reviewed literature are manifold (see Figure 4). Time-series data dominate
    the data types. Most evaluations in the primary studies are conducted in a controlled
    research environment rather than in an industrial setting. Only six of 51 studies
    present an evaluation in an industrial environment (e.g., a shop floor). Fig.
    4. Fig. 4. Data types of the data quality research for CPS and IoT in Industry
    4.0. RQ1.2 Conclusion.. Manufacturing industries are the predominant application
    domain in the primary studies, while time series are the most collected data type
    in the application domains. 4.1.3 RQ1.3: What is the Tradeoff between Data Quality
    and Data Security?. Data security is to prevent unauthorized access to data. It
    can be considered part of data quality (see data veracity in RQ1.1) since avoiding
    data corruption caused by unauthorized access improve data quality. Data quality
    techniques, e.g., data cleaning or repair, necessitate flexible read and write
    access to all data. Security problems may arise while running these techniques
    because data can be exchanged with other systems or used by users with different
    access rights. Improving data security may limit the abilities of data quality
    techniques and, in turn, reduce data quality. The need for data security enforces
    certain restrictions on how data is accessed, stored, and analyzed. These restrictions
    may negatively affect overall data quality and increase computational costs. For
    instance, data may need to be anonymized or encrypted in a vault. Encryption techniques
    require different users to encrypt their data with their keys; the identical data
    copies of different users lead to different ciphertexts, making data deduplication
    impossible. Data deduplication eliminates redundant copies, significantly reduces
    storage capacity requirements, and ensures data consistency. Some well-adapted
    strategies, e.g., centralized secret keys within a dedicated entity that allow
    the deduplication process to decrypt data, can be employed to overcome conflicts
    between data quality and security [143]. We have identified only seven papers
    addressing both data quality and security for IoT and CPS. Four of these papers
    [7, 11, 19, 31] investigate how data security solutions can improve data quality
    (in particular, data accuracy). Krotofil et al. [19] propose a process-aware approach
    to detect when a sensor signal is maliciously changed. Similarly, Russel et al.
    [31] present a sensor data validation method that employs sensory substitution
    to mitigate common sensing errors and cyber-physical attacks, such as playback
    attacks. Two blockchain-based approaches [7, 11] support the assessment of the
    trustworthiness of sensor observations and false data detection to improve IoT
    data quality. Only three papers [38, 39, 51] study the tradeoff between data quality
    and security. Zellinger et al. [51] address confidentiality protection in transfer
    learning (an ML approach focusing on storing knowledge gained while solving one
    problem and applying it to a different but related problem). The idea is a module-based
    combination of confidentiality-preserving noise-adding methods with robust transfer
    learning algorithms for intelligent manufacturing applications. They discuss noise
    injection mechanisms achieving a good trade-off between data privacy and accuracy.
    Sicari et al. [38, 39] propose a system architecture addressing data security
    and quality in IoT. The architecture contains three layers: Analysis, Data Annotation,
    and Integration. The Analysis layer extracts the information about the data (e.g.,
    data source, data type, and data security and quality properties) to support other
    layers. Its task is to evaluate whether the input data satisfy data security and
    quality requirements. The layer computes a score for each security property (i.e.,
    data confidentiality, data integrity, source privacy, and source authentication)
    and data quality property (i.e., data accuracy, data precision, information timeliness,
    and completeness). These scores inform IoT users and applications about the security
    and data quality levels. The Data Annotation layer annotates the data with the
    computed scores; the Integration layer exploits the scores about security and
    quality level to select the data resources for data integration. The evaluation
    of the proposed architecture reveals that high-security scores may lead to low-level
    data completeness (the number of collected values over a given time interval divided
    by the number of expected values). On the other hand, high-level data security
    positively contributes to data accuracy (the degree of similarity of a measured
    quantity to its actual value), precision (the degree to which further calculations
    return the same or similar results), and timeliness (the temporal validity of
    data). Different computing architectures (e.g., edge, fog, and Cloud computing)
    have different security risks, affecting the tradeoff between data security and
    quality. For instance, edge applications pose particular security risks (e.g.,
    the dependence on edge computing resources without proper security software) because
    IoT devices are designed for low-cost and low-power usage and are unsuitable for
    complex technology. One technique to mitigate these risks is to monitor all edge
    activity to limit data access rights of native edge applications, including data
    quality techniques running on edge devices. Similar to our findings in RQ1.1,
    none of the primary studies mentioned above discuss the implications of IoT computing
    architectures for the tradeoff between data security and quality. RQ1.3 Conclusion..
    Some primary studies focus on data quality and security separately or study how
    data security can improve data quality and therefore do not address the tradeoff
    between these two. Few papers addressing the tradeoff study data quality and security
    properties, but not how data quality and security techniques affect or limit each
    other on different computing architectures. We need further research on the implications
    of different IoT computing architectures for the tradeoff between data security
    and quality. 4.2 RQ2 - What Data Quality Techniques Are Used for CPS and IoT in
    Industry 4.0? Data quality techniques include approaches and technologies identifying
    and correcting data quality issues. There are different interpretations of data
    quality techniques. Some surveys mix data cleaning and repair under the same category.
    Our SLR has a distinction between data repair and cleaning techniques (see Figure
    2) and reports them in two sub-questions (RQ2.2 and 2.3) since they differ in
    how they treat data quality issues. Data monitoring (identifying quality issues
    in data) is a prerequisite and an integral part of data repair and cleaning. Therefore,
    we investigate it as a sub-activity of data repair and cleaning. To respond to
    RQ2, we address four sub-questions: 4.2.1 RQ2.1: What Are the Data Quality Metrics
    for Data Quality Monitoring?. Data quality metrics are the measurements used to
    assess data. They benchmark how beneficial and relevant data is, and help differentiate
    between high-quality and low-quality data. They can be employed to certify data
    sources in IoT and CPS as fit or not for specific purposes. They can easily be
    related to data quality dimensions, i.e., the measurement attributes of data,
    which we can assess, interpret, and improve. We identified 41 data quality metrics
    in the primary studies. Table 4 presents the data quality dimensions and the corresponding
    metrics with their formulas/explanations. The metrics are either based on a mathematical
    formula or computed by a program on structured data for an observation period.
    Accuracy, completeness, and validity are the most data quality dimensions addressed
    by the quality metrics. We could not find any metric for data orderliness, volume,
    auditability, consistency, accessibility, compliance, efficiency, precision, traceability,
    understandability, portability, recoverability, and integrity. Data consistency
    among these dimensions is the level to which values of an attribute adhere to
    some constraints. Data validity metrics (M31-M40) subsume this definition of data
    consistency. Table 4. DQ Dimension Number Formula / Description Reference Accuracy
    M1 X={ x t |t∈T} is a time series process, and N is the number of observations.
    Degradation of accuracy is detected as deviation in the following properties of
    X . Mean μ= 1 N ∑ N i=1 x i . Standard deviation σ= 1 N−1 ∑ N i=1 ( x t −μ ) 2
    − − − − − − − − − − − − − − − √ . Kurtosis K= 1 N ∑ N i=1 ( x i −μ ) 4 σ 4 . Skewness
    S k = 1 N−1 ∑ N i=1 ( x i − μ 3 ) σ 3 . Sum of absolute values ∑ N i=1 | x i |
    . Number of elements over the mean { x t ∈X: x t >μ} [8] M2 Test campaigns using
    human to detect data quality faults in facility management using cameras and sensors.
    O is the occupancy count obtained from cameras and sensors. O>50 in a 10 meter
    squared room indicates data error. O>0 outside working hours then the sensor is
    frozen. [36] M3 Binary logistic regression p( x i )= 1 1+ e −β x i , where p(
    x i ) is the probability that the data point x i is noisy. [9] Show More Table
    4. Data Quality Metrics in the Primary Studies Several data quality metrics in
    the primary studies are numerically bounded. Some metrics produce a normalized
    score in the range [0,1] as a binary value (M6, M16), percentage (M7, M11, M34),
    score (M4, M21, M25, M28, M40), relative frequency (M5, M10, M13), and probability
    (M3, M41). The bounded metrics appear to be human-understandable. However, due
    to differences in their computation methods, the metrics are not standardized
    for arithmetic comparison and numerical composition with each other. Nevertheless,
    there is one exception where M29 on data trust is a weighted sum of data accuracy
    (M5) and data completeness (M13). Several metrics (M1, M17, M24, M30) use statistical
    properties of batch data instead of statistical properties of reference high-quality
    data. For instance, Sanyal and Zhang [33] compute data uncertainty (M30) as the
    Shannon entropy of batch data without the need for cordoning reference data. Data
    quality metrics are extensively studied in the literature but are not widely used
    by industrial IoT systems having dark data [67]. Dark data is unstructured, untagged,
    and untapped data that has not yet been analyzed or processed. IoT systems accumulate
    it for various reasons, including compliance and security obligations. Beneficial
    data becomes outdated because of the lack of tools and processes to use data in
    a timely manner. Dark data often represents lost opportunities (e.g., revenue,
    products) for a business as data content and quality is unknown. Almost 90% of
    IoT data is dark data [83]. If computed promptly and presented as feedback to
    humans, data quality metrics can instill a company culture to use data before
    it becomes dark. Furthermore, they can improve data audibility and boost the acquisition
    of higher-quality data suitable for products based on ML/AI. RQ2.1 Conclusion..
    We identified a large spectrum of data quality metrics in the literature. However,
    we could not find any study reporting the adoption of these metrics in industrial
    IoT systems as a common practice. We need research to facilitate using quality
    metrics in industrial IoT settings while addressing the problem of dark data.
    In the future, it would be interesting to study the perception of human users
    when AI-driven decisions made on data are presented alongside the data quality
    metrics. 4.2.2 RQ2.2: What Are the Data Repair Techniques?. As described in Section
    3, data repair techniques restore data lost, accidentally deleted, corrupted,
    or made inaccessible, while data cleaning techniques only remove corrupt or noisy
    data. We identified ten primary studies that provide or employ a data repair technique.
    We excluded studies that do not give any detail, e.g., Wei et al. [45] proposing
    data interpolation without explaining how to apply it in the CPS/IoT context.
    Table 5 presents the data repair techniques in the primary studies. The first
    two columns provide the data quality issue and the data repair technique before
    a brief description in the third column. The fourth and fifth columns indicate
    if the repair technique is online (data repair at the data source in real-time)
    and evaluated. We classify it offline (data repair for large historical datasets
    on the Cloud) if the study does not report any deployment for online data repair.
    Table 5. DQ Issue Technique Description of the Technique Online Evaluated Reference
    Missing Values Data Imputation Missing values are calculated based on the average
    value of the previous and next data. When there is a wide range of missing data,
    missing values are filled in according to similar machining data in the manufacturing
    workshop. No Yes Kong et al. [18] Missing Values Median-based Data Imputation
    The median value is determined by arranging data in increasing order. Missing
    values are filled in by the median value. This method underestimates the variance
    in the dataset since the same median value is used for multiple missing values.
    No No Khan et al. [17] Missing Values Guided Process for Data Repair in Regression
    models (DC-RM) - Data Imputation DC-RM provides a procedure for building data
    repair/cleaning process for regression models. For each data quality issue in
    the datasets, a data quality task is suggested. In DC-RM, three data imputation
    techniques are employed: hot deck (missing items are replaced by using values
    from the same dataset), imputation based on missing values (assigns a value to
    a missing one based on measures of central tendency), imputation based on non-missing
    attributes (a regression/classification model is performed). No Yes Corrales et
    al. [9] Show More Table 5. Data Repair Techniques in the Primary Studies Missing
    values are the most data quality issue addressed by the data repair techniques
    (five primary studies). These techniques use data imputation methods (i.e., replacing
    missing values with estimates and analyzing the dataset as if the imputed values
    were actual observed values) from statistics to repair missing values. Different
    studies employ different imputation techniques (median-based [17], mean-based
    [46], average-value [18], and matrix factorization [44]) for missing value repair.
    Corrales et al. [9] provide a guided process with data quality techniques (data
    repair and cleaning). They assume that missing values are represented by special
    characters such as ?, *, blank spaces, or special words (NaN, null). The user
    selects one of the imputation techniques offered (hot deck, imputation based on
    missing attributes, and imputation based on non-missing ones). Most of the repair
    techniques use data from the same sensor to predict missing values. However, it
    is not convenient to use the same dataset when there is a wide range of missing
    values. Kong et al. [18] discuss using data from similar sensors but do not provide
    any implementation. Wang et al. [44] use correlations among sensors to reconstruct
    missing values in a single time series. They provide only offline repair. As mentioned
    in RQ1.1, data veracity is the accuracy or truthfulness of a dataset and is sometimes
    considered a data security property. Four studies [23, 27, 31, 33] provide techniques
    that repair “corrupt” data and increase its accuracy. Three of them [27, 31, 33]
    use reference sensors/monitors or sample data to improve sensor data accuracy.
    For instance, Russel et al. [31] present an approach that repairs the initial
    sensed data from cameras (the processed output from the edge) with the raw data
    from an ambient sensor. It uses sensory substitution to increase the data robustness,
    resilience, and dependability. Lin et al. [23] are different from these three
    studies and repair corrupted data from its origin through computational dependencies
    in a distributed IoT setting. They replay all the dependent computations to correct
    data degraded throughout its life cycle due to hardware malfunction, software
    bugs, or network partitions. ML has the potential for online and offline data
    repair in CPS/IoT as correlations among various data sources (sensors) can be
    learned to substitute one sensor with another sensor and predict missing values
    or new data that replace corrupt data. Non-AI techniques have different constraints
    limiting their applicability. For instance, Lin et al. [23] require all dependent
    data computations in the application state history, which are not always available.
    ML can support more generic repair solutions for IoT systems having multiple sensors
    that can replace each other. However, we revealed only two studies [12, 27] applying
    ML to data repair. Flick et al. [12] use ML (K-means for clustering and regression
    modeling) only to detect outliers in the clusters, not to predict data replacing
    outliers. They employ the overflow, overweight, substitution value, and algebraic
    sign calculations to calculate replacing data. Okafor et al. [27] use linear regression
    and neural networks to correct sensor output. Their approach determines the factors
    affecting data quality, models their effects on the sensor response, and applies
    the calibration model to calibrate sensors. It merges data from multiple sensors
    into the calibration equation to ensure consistent and accurate information for
    the model. The full potential of ML for data repair still needs to be explored
    with the challenges of integrating ML models and components related to the data
    and model evolution. Manufacturing is the dominant application domain of data
    quality research for CPS and IoT (see RQ1.2). Although manufacturing processes
    produce the same products or parts repetitively, there might be occasional, minor
    modifications to product specifications and process parameters (e.g., the need
    to ramp up production) that can render ML models obsolete. Therefore, we need
    solutions that investigate continual learning [114] and domain adaptation [62]
    in conjunction with the continuous deployment of ML models [133]. One challenge
    for data repair research is to create real-time (online) data repair services
    (e.g., quality monitors and repair services on edge gateway) for IoT systems.
    However, we identified only four primary studies [23, 27, 31, 33] addressing online
    data repair. The techniques proposed by these studies detect and repair “corrupt”
    data at the edge/fog devices close to the data source where computation resources
    are limited. Only one technique [27] is an ML-based repair solution. It does not
    address different deployment and versioning scenarios of ML models on edge and
    Cloud. An ML-based data repair technique should be invoked either on edge or Cloud
    to create ML models based on the availability of training data. The models should
    be containerized as online repair services and deployed on edge for real-time
    data repair or on the Cloud for offline repair. Only two data repair techniques
    [17, 46] in our SLR have not been evaluated. They are part of data analytics frameworks.
    Therefore, the focus of the evaluation in their studies is the data analytics
    frameworks, not the outcome of the data repair techniques. One study [31] reports
    the experience with its repair technique and does not quantitatively assess its
    performance. We investigate the details of the evaluation of the data repair techniques
    in RQ2.4. RQ2.2 Conclusion.. Across primary studies, data repair techniques address
    missing values, data veracity, and outliers. Most of these techniques are non-AI
    solutions having limitations in the industrial CPS/IoT context. ML can support
    more generic (online and offline repair) repair solutions for IoT systems having
    multiple sensors that can replace each other. Future research should explore the
    full potential of ML for data repair and address the challenges of integrating
    ML models and components related to the data and model evolution. 4.2.3 RQ2.3:
    What Are the Data Cleaning Techniques?. Data cleaning techniques detect and remove
    corrupt and unusable data, e.g., those affected by environmental noise or extreme
    operating conditions. They do not attempt, for instance, to restore any data deleted
    or corrupted. Table 6 presents data cleaning techniques in the primary studies.
    The table structure is similar to the one in Table 5. Table 6 does not include
    studies that do not give any details (e.g., Saranya and Sivakumar [34]). Table
    6. DQ Issue Technique Description of the Technique Online Evaluated Reference
    Outlier DBSCAN-based Outlier Detection It is a hybrid prediction model that consists
    of Density-Based Spatial Clustering of Applications with Noise (DBSCAN)-based
    outlier detection and Random Forest classification. DBSCAN [81] was used to separate
    outliers from normal sensor data, while Random Forest was utilized to predict
    faults. Yes Yes Syafrudin et al. [40] Outlier Clustering Algorithms Distance measure
    and clustering algorithms detect and remove outliers. No No Wei et al. [45] Noise
    Smoothing Filter The use of smoothing filters [140] is proposed for denoising
    manufacturing data. The details of how a smoothing filter can be applied are not
    explained. No No Wei et al. [45] Show More Table 6. Data Cleaning Techniques in
    the Primary Studies Outlier is the most data quality issue addressed by the data
    cleaning techniques (seven primary studies). These techniques differ in detecting
    outliers, while the cleaning task is standard (i.e., removing the detected outliers
    from the dataset). They use clustering algorithms [9, 40, 45], domain knowledge
    [8, 29, 49], decision trees [35], or distance metrics [45] to detect outliers.
    Syafrudin et al. [40] and Corrales et al. [9] use Density-Based Spatial Clustering
    of Applications with Noise (DBSCAN)-based outlier detection [81] to separate outliers
    from normal sensor data. Specific rules detecting outliers are defined based on
    domain knowledge (manufacturing domain). For example, Yu et al. [49] discard all
    the data points for the machine speed value lower than 8000 since the machine
    is supposed to be shut down at that speed. Cerquitelli et al. [8] use the cycle
    length deciles to detect test cycles of the manufacturing machines and remove
    the data of these test cycles from the dataset. Five primary studies [5, 18, 42,
    45, 48] provide data cleaning techniques that address data noise. Four of them
    [5, 42, 45, 48] use filtering to clean noise. For instance, Yu et al. [48] apply
    noise filters (i.e., the distance between two computation units) to remove two
    types of noise (the long and short duration of noise). Kong et al. [18] employ
    sampling to remove noise in the datasets used for the state prediction of machine
    tools. Data imbalance (a small proportion of nearly-failure state during machine
    tool operation) affects the prediction results (classification). Part of the running
    state data is sampled to constitute a smaller dataset, whose data amount is comparable
    to that of the nearly-failure data. As we noted in RQ1.1, high-dimensionality
    is crucial, especially for ML applications at the edge, but one of the least addressed
    data quality issues in our review. Only three data cleaning techniques [9, 18,
    42] address high dimensionality. Two techniques [9, 18] employ the principal component
    analysis [53] to filter out irrelevant attributes. Villalobos et al. [42, 43]
    provide a guided process using an ML-based model that combines reduction techniques
    with extracted features from time series to recommend the most suitable reduction
    technique. The three techniques are offline, and none of them provide online support
    for reducing high dimensions in input datasets for real-time ML applications.
    All the data cleaning techniques employing clustering algorithms [9, 40, 45],
    decision trees [35], distance metrics [45], noise filters [5, 42, 45, 48], sampling
    [18], or the principal component analysis [9, 18] are domain agnostic. They may
    not always detect and clean domain-specific data quality issues (e.g., removing
    data of machine test cycles [8], data of the machine having a speed value lower
    than 8000 [49], or trajectory data from an agricultural monitoring system when
    the data recording time of two adjacent track points is the same [14]). Therefore,
    we need guided processes using both domain-agnostic data quality monitoring and
    domain knowledge-based heuristics to detect data quality issues. The existing
    ones [9, 42, 43] employ only domain-agnostic techniques. Corrales et al. [9] propose
    the Guided Process for Data Cleaning in Regression Models (DC-RM) that suggests
    a data cleaning task (e.g., removing outliers) for data quality issues found through
    a domain-agnostic monitoring technique (e.g., DBSCAN [81]). We identified five
    online cleaning techniques [5, 8, 29, 40, 48, 49]. As indicated in RQ2.2, ML has
    the potential for developing online solutions (and offline solutions too). Two
    online data cleaning techniques use ML solutions (DBSCAN - an unsupervised learning
    method utilized in ML algorithms [40] and decision trees and random forest classification
    [5]). They do not address the ML model deployment and versioning challenges for
    online data cleaning. Their primary studies do not report on model deployment
    and versioning scenarios on edge and Cloud (see RQ3.1). Half of the data cleaning
    techniques [8, 14, 29, 42, 43, 45, 49] in our SLR have not been evaluated. They
    are part of predictive maintenance or smart manufacturing [8, 29, 45, 49] and
    agriculture machinery monitoring systems [14]. Therefore, the focus of the evaluation
    in the primary studies is not the outcome of the data cleaning techniques. We
    investigate the evaluation details of the data cleaning techniques in RQ2.4. RQ2.3
    Conclusion.. Existing cleaning techniques address outliers, noise, high-dimensionality,
    duplicated records, data drift, and missing values. Most of these techniques are
    domain agnostic and may not always be able to detect and clean domain-specific
    data quality issues. Further research is needed to propose guided processes using
    both domain-agnostic data quality monitoring and domain-knowledge-based heuristics.
    There is also a need for online data cleaning support to reduce high dimensions
    in input datasets for real-time ML applications. 4.2.4 RQ2.4: How Are Data Quality
    Techniques Evaluated?. In this section, we discuss the evaluation metrics used
    and reported in the selected papers, their calculation methods, and their strengths
    and drawbacks. Eight metrics have been used to assess data quality techniques.
    They can be categorized as classification and regression metrics. The former includes
    precision [40], recall [40], and accuracy [18, 40]. The latter contains the Mean
    Absolute Error (MAE) [9, 27, 34], Mean Squared Error (MSE) [34], Root Mean Squared
    Error (RMSE) [27, 34, 44], coefficient of determination ( R 2 ) [27, 34], and
    the true sensor data estimation error [33]. Table 7 lists the metrics used to
    evaluate data quality techniques. These metrics have been mainly used to evaluate
    the data quality techniques by using predictive analytics output (e.g., fault
    and remaining useful life prediction). The main goal is to assess the impact of
    the data quality techniques on the performance of the classification and regression
    models. For instance, Kong et al. [18] use the accuracy metric to show that the
    data processed by the proposed data quality technique improves the classification
    accuracy for tool wear prediction. Table 7. Evaluation Metrics Context Generic
    Evaluation Target References MAE, RMSE, R 2 Repair Yes Data repair approach (regression
    models) Okafor et al. [27] Accuracy Repair Yes Classification Models for Tool
    Wear Prediction Kong et al. [18] RMSE Repair Yes Data repair approach Wang et
    al. [44] Show More Table 7. Metrics used to Evaluate Data Quality Techniques Classification
    Metrics. As seen in Table 8, classification models have four possible outcomes.
    True positive (TP) and true negative (TN) denote the correctly classified points.
    False positive (FP) represents the points incorrectly classified as “yes” (positive)
    when they are actually “no” (negative). And false negative (FN) refers to the
    points incorrectly classified as “no” (negative) when they are actually “yes”
    (positive). According to the definitions of TP, TN, FP, and FN, Table 9 presents
    the precision, recall, and accuracy metrics. Table 8. Classified as “Yes” Classified
    as “No” Actual “Yes” True Positive (TP) False Negative (FN) Actual “No” False
    Positive (FP) True Negative (TN) Table 8. Confusion Matrix of a Classifier Table
    9. Metric Description Formula Precision The ratio of true positive to the total
    predicted positive TP/(TP + FP) Recall The ratio of true positive to the total
    actual positive TP/(TP + FN) Accuracy The ratio of correct predictions to total
    observations (TP + TN)/(TP + TN + FP + FN) Table 9. Precision, Recall, and Accuracy
    Metrics for Classification Models Syafrudin et al. [40] calculate the precision,
    recall, and accuracy of classification models predicting faults with and without
    removing outliers (data cleaning). Although we can use precision and recall to
    assess the performance of data cleaning solutions (e.g., the number of correctly
    removed outliers over all the data points removed), we did not find any study
    using these metrics for that purpose. The accuracy metric uses all TP, TN, FP,
    and FN in Table 8 and is adequate for only balanced datasets. IoT and CPS datasets
    obtained from sensors are imbalanced; they usually have more normal data points
    than erroneous ones, and the class distribution is not even in these datasets.
    Therefore, the accuracy metric is unfair while assessing data quality techniques
    on sensor datasets. It might be why the primary studies ([18, 40]) use the accuracy
    metric only to evaluate the impact of data quality techniques on the performance
    of classification models. Regression Metrics. The MAE, MSE, RMSE, and R 2 metrics
    have been mostly used to assess the performance of the data quality techniques
    on the regression models (see Table 7). MSE is the average squared difference
    (error) between the predicted and observed values. It gives more weight to big
    differences. It might underestimate the model’s accuracy as one big difference
    might increase the MSE significantly. RMSE is the square root of MSE and is more
    interpretable. MAE is the average of the absolute differences. Unlike MSE or RMSE,
    it is less sensitive to big differences since it does not take the square of the
    errors. R-squared ( R 2 ) represents the proportion of the variance for a dependent
    variable explained by an independent variable(s) in a regression model. It can
    be more informative than MAE, MSE, and RMSE, as it can be described as a percentage,
    whereas MAE, MSE, and RMSE have arbitrary ranges. Corrales et al. [9] compare
    the MAE of the regression models trained with the dataset not cleaned versus those
    trained with the same data set cleaned by their data cleaning approach. They show
    that the results achieved by the trained models with the cleaned dataset are better
    than or equal to that with the same dataset not cleaned. Saranya and Sivakumar
    [34] use the MAE, MSE, RMSE, and R 2 to assess the impact of the proposed data
    cleaning technique on the prediction of Remaining Useful Life (RUL). They calculate
    and compare the metrics for the RUL prediction with and without outliers. Different
    from these two works mentioned above, Okafor et al. [27] employ the MAE, RMSE,
    and R 2 metrics to assess the performance of their proposed data repair technique.
    They compare the sensor measurements before and after data repair to reference
    measurements using these three metrics. Wang et al. [44] use the RMSE to evaluate
    the performance of missing value prediction. They compare the RMSE of their proposed
    data repair approach and of the competing methods (e.g., non-negative matrix factorization
    [106] and support vector machine [139]). Sanyal and Zhang [33] propose a specialized
    metric for sensor data estimation error to compare their data repair approach
    with Principal component analysis (PCA) [53], i.e., a classical tool for low dimensional
    linear subspace approximation, as a baseline algorithm in the presence of high
    Gaussian noise with outliers and missing values. This metric is similar to RMSE
    as it is the square root of the sum of the squares of the coordinates of the vectors
    of the estimated and observed sensor data from each IoT node. As mentioned above,
    only three studies (i.e., [27, 33, 44]) use regression metrics to assess the performance
    of data quality techniques, not their impact on the performance of classification/regression
    models. They evaluate data repair approaches predicting missing or corrupted data.
    Therefore, they use regression metrics, i.e., MAE, RMSE, and R 2 , that quantify
    the difference in the estimated and observed values. Although not found in the
    primary studies, precision and recall can assess the performance of data cleaning
    techniques. We could not identify a single study evaluating both the performance
    of a data quality technique and its impact on the performance of a data analytics
    solution. RQ2.4 Conclusion.. Across primary studies, the metrics are standard
    and have been mostly used to assess the impact of the data quality techniques
    on the performance of predictive analytics (e.g., fault and remaining useful life
    prediction). Few studies assess the performance of data quality techniques. No
    study evaluates both the performance of a data quality technique and its impact
    on the performance of predictive analytics. 4.3 RQ3: What Software Engineering
    Solutions Are Used for Data Quality for CPS and IoT in Industry 4.0? Software
    is the heart and soul of any IoT system and CPS, especially for analyzing data
    and its quality. Software engineering solutions for CPS and IoT systems often
    span the edge-fog-Cloud continuum; various software design choices are made based
    on the requirements for real-time and historical data processed by these systems.
    To better understand the role of software engineering in data quality, this research
    question investigates software engineering solutions in the primary studies. We
    use the term software engineering solution to cover any software engineering technique
    (including data storage technologies, programming languages, libraries, and platforms)
    used to implement data quality techniques for CPS and IoT. To respond to RQ3,
    we address the following three subquestions: 4.3.1 RQ3.1: What Programming Languages
    and Solutions are used to Manage Data Quality?. Nineteen papers (out of 51 papers
    considered in our survey) mention a programming language or solution (e.g., programming
    platforms, libraries, and models). Table 10 presents the programming languages
    and solutions used to manage data quality in the papers. Nine of these papers
    (i.e., [2, 15, 21, 29, 34, 40, 49, 50, 51]) propose a data analytic solution as
    part of a CPS or IoT system. Their main goal is not to provide a data quality
    technique. They support data quality as a pre-processing step of their data analytics
    solution. Since these solutions attempt to quantify uncertainty and reason with
    incomplete and inconsistent data, more right data generally results in a better
    output of such solutions [88]. Python, Java, and R are used to implement data
    analytics in the studies. ML libraries TensorFlow [52], Weka [91], MLLib [118],
    scikit-learn [129], and Keras (high-level API of TensorFlow 2) [89] provide a
    proper abstraction to facilitate the development of the proposed data analytics
    solutions. Table 10. Languages Machine Learning Libraries Bigdata Platforms Other
    Java C/ C++ Python R Tensor-Flow [52] Weka [91] MLLib [118] scikit [129] Keras
    [89] Nifi [125] Camel [68] Kafka [99] Spark [142] Jena [69] C-SPARQL [64] Matlab
    [116] CSPOT [151] NOS [132] Data Qualityas a Primary Goal Lin et al. [23] ✓ Saybani
    et al. [35] ✓ Buschjager et al. [5] ✓ ✓ ✓ Show More Table 10. Summary of the Programming
    Languages and Solutions used to Manage Data Quality Only ten papers mentioning
    programming languages and solutions (i.e., [4, 5, 9, 10, 20, 23, 26, 27, 35, 39])
    address data quality techniques for CPS and IoT applications as their primary
    goal. For instance, Lin et al. [23] propose a new approach for repairing corrupted
    data in IoT applications. It automatically tracks causal data dependencies and
    replays dependent computations across multi-tiered IoT deployments. It combines
    the function-as-a-service (FaaS) programming model with versioned, persistent
    storage and causal event tracking to facilitate data repair. The approach extends
    an open-source, distributed, FaaS runtime system called CSPOT [151]. CSPOT runs
    over various devices (e.g., microcontrollers, edge, and public Clouds) and makes
    data repair possible in a distributed IoT setting. Semantic technologies have
    been investigated to enable the integration and interoperability of data produced
    by heterogeneous IoT devices. Bambgboye et al. [4] present a layered software
    framework using semantic technologies to maintain the consistency of data streams
    produced by physical sensors. The framework applies semantic modeling and reasoning
    to validate data stream consistency while highlighting the temporal characteristics
    of the stream. The framework has four layers: the sensing, modeling, reasoning,
    and application layers. The sensing layer receives data from sensors and prepares
    the data for the upper layer. It contains a stream service module that ensures
    the continuous transfer of data streams with Java infrastructure Apache Camel
    [68]. The modeling layer provides an ontology to integrate and enhance reasoning
    for sensor streaming data available as raw numeric data. Semantic reasoning achieves
    the continuous validation of the sensor stream. The reasoning layer validates
    sensor readings within a time window against prevailing disturbances with data
    validation policies and other related sensor readings. To this end, the framework
    layers the Jena rule language [69] with the C-SPARQL query engine [64] for continuous
    queries over RDF data streams. The data collected, processed, and exchanged at
    each stage of CPS and IoT applications might have a different structure, format,
    and velocity and be stored in data silos not available to all the system users
    but only to some users. Cui et al. [10] propose a systematic approach, i.e., Data
    Control Module (DCM), that uses state-of-art big data software to manage data
    silos in manufacturing. A data silo concerns timely monitoring of data changes,
    redundancy, inconsistency, and insecurity. DCM employs big data software (Apache
    NiFi [125], Apache Phoenix [131], and Apache Kafka [99]) to implement functions
    addressing these concerns. The DCM architecture consists of DCM Cloud and several
    DCM Edge systems. Apache NiFi takes responsibility for data monitoring at the
    DCM edge and data collection and allocation at the DCM Cloud. It provides a data
    provenance function to trace data history and check data consistency. Apache Kafka
    is a high-throughput, low-latency messaging framework. Therefore, it transmits
    control messages (including data information such as source location, data source
    computer, expected location, and target data computer) between the DCM Cloud and
    Edge. RQ3.1 Conclusion.. The programming languages and solutions used to manage
    data quality (e.g., TensorFlow, Keras, MATLAB’s fuzzy logic toolbox, Jena, C-SPARQL)
    highly depend on the solution domain (e.g., ML, data mining, semantic web). For
    instance, Python is almost the de-facto programming language in the studies providing
    ML-based solutions. Not many papers mention a programming language, but Python,
    Java, C++, and R are used to implement data quality techniques in the approaches
    we studied in our survey. Big data software platforms such as Apache Kafka and
    Phoenix are suitable for implementing data quality concerns for high-velocity
    data, such as the timely monitoring of data changes, data redundancy, data inconsistency,
    and data insecurity. 4.3.2 RQ3.2: What Data Storage Solutions Are Used to Manage
    Data Quality?. Data storage support depends on data type, where data is stored
    (Local/Edge/Cloud), and in which context data is processed. We analyze the relationship
    between data storage support (e.g., time-series database systems, NoSQL, or a
    blockchain solution) and data quality. We expect to gain new insights into essential
    data storage solutions in CPS, IoT, and Industry 4.0 applications and their impact
    on data quality techniques such as data cleansing and repair. These new insights
    will help organizations choose appropriate data storage for data quality. Twenty
    papers (i.e., [1, 2, 7, 10, 11, 14, 15, 16, 18, 21, 23, 24, 26, 32, 37, 39, 40,
    42, 44, 49]) mention data storage support, e.g., database, file system, or a blockchain
    solution, where data storage is mostly part of data analytics frameworks. Three
    papers [1, 7, 11] employ the blockchain to ensure data security, such as the trustworthiness
    of sensor observations, while the blockchain is also a storage medium. There is
    an explicit dependency between the data storage solution and the data quality
    support (i.e., ensuring data security) in these two works. Mohammed et al. [26]
    employ a Cloud-based solution, i.e., the Google Cloud environment, to store IoT
    data. Some papers refer to some domain-specific database systems (not any well-known
    database system) without detailed information, such as agricultural telematics
    [14] or operation management database [16]. They do not provide any insight into
    database technologies, how data is managed, in what format and quality, and the
    impact of the database technologies on the data quality techniques. Data warehouses
    and distributed file systems are ideal mediums for storing data for big data systems
    [32, 48, 49] that receive data from multiple data sources. Such data systems require
    data cleansing before data gathered from various sources are integrated. They
    may use data warehouses and distributed file systems combined with databases in
    a layered fashion where each layer has its data cleansing. For instance, Santos
    et al. [32] propose data storage layers having different components used in various
    contexts: (a) data streams are stored in a real-time fashion in a NoSQL database
    in the real-time data storage layer; (b) the Staging Area and Big Data Warehouse
    components save data in a more historical perspective in the historical data storage
    layer. In the Staging Area component, the Hadoop distributed file system stores
    data that are available for further use for a limited time. Shah et al. [37] propose
    a plug-and-play solution to use the data storage layers as an interface to data
    storage. This decoupling enables the data storage technologies (e.g., data warehouses,
    relational databases, and distributed file systems) to be easily replaced based
    on the type of stored data. However, replacing the data storage component accessed
    through the layer may require changes in the data quality techniques (e.g., data
    cleansing) due to the data quality support the new component provides. The papers
    do not report a direct relationship between the database technologies and the
    data quality techniques. Table 11 gives a classification of database systems and
    the solutions using these systems. We use the database management system taxonomy
    provided by Gudivada et al. [88]. In addition to the database classes in Table
    11, Gudivada et al. [88] mention Native XML, RDF Stores, and Key-Value Stores
    database classes which none of the papers in our survey report. Most papers report
    the use of column-family database systems (i.e., HBase and Cassandra) since these
    systems support heterogeneous data and tolerate network failures and temporal
    data inconsistency. A column family is a NoSQL database containing columns of
    related data. The column-family database systems such as HBase and Cassandra also
    support time-series data. Table 11. DB Class Used DBs References Description of
    the DB Class by Gudivada et al. [88] Column Family HBase Kong et al. [18], Huru
    et al. [15], Wang et al. [44], Cui et al. [10] Ideal for storing sparse, non-transactional,
    and heterogeneous data and retrieving partial records; accommodate flexible and
    evolving database schema; tolerance to both network failures and temporary data
    inconsistency; increased processing power through horizontal scalability. Cassandra
    Villalobos et al. [42], Apiletti et al. [2] Document Oriented MongoDB Villalobos
    et al. [42], Syafrudin et al. [40], Sicari et al. [39] Ideal for managing semi
    structured, arbitrarily nested hierarchical document data organized in the form
    of key-value pairs in JSON format; support flexible schema evolution; accommodate
    high data variability among data records. Show More Table 11. A Classification
    of Database Systems in the Primary Studies RQ3.2 Conclusion.. We derived the following
    insights into essential data storage solutions in CPS, IoT, and Industry 4.0 applications
    and their impact on data quality techniques: (i) blockchain is an ideal solution
    to ensure data security as part of data quality; (ii) big data systems gathering
    data from various sources combine multiple data storage solutions, which require
    a layered data storage architecture where each layer may require its own data
    quality technique; (iii) there is no direct relation between the key database
    technologies and the data quality techniques; and (iv) the column-family database
    systems are highly preferred since they support heterogeneous data and tolerate
    network failures and temporal data inconsistency. 4.3.3 RQ3.3: What IoT Reference
    Architecture Layers Are Covered in the Primary Studies?. Data can be processed/stored
    at different levels of the IoT reference architecture (see Section 3.3). These
    architecture levels can help understand how and where data is analyzed and processed
    for quality issues. We have identified twenty primary studies that refer to the
    IoT architecture layers (see Table 12 and L1-L7 in Section 3.3). Table 12. Primary
    Study IoT Architecture Perception Network Application L1 L2 L3 L4 L5 L6 L7 Villalobos
    et al. [42] ✓ ✓ ✓ Wang et al. [44] ✓ ✓ ✓ Hui et al. [14] ✓ ✓ ✓ ✓ Show More Table
    12. IoT Reference Architecture Layers in the Primary Studies ✓ = the contribution
    specifies the IoT architectural aspects from the taxonomy Five primary studies
    [1, 14, 26, 42, 44] focus on data quality management in the Cloud-based architecture
    layers (L4, L5, and L6). Three of these studies [14, 42, 44] propose data quality
    management techniques (data repair and cleaning) running on the Cloud. These techniques
    are offline, e.g., data repair for large historical datasets on the Cloud. Sensor
    data in motion are converted for long-term storage and stored in an easily accessible
    format on the Cloud to be further processed, e.g., for historical data validation.
    For instance, Villalobos et al. [42] focus on the layers L4 and L5 for time series
    data captured by machine sensors and accessed using a REST API via a gateway.
    The remaining two primary studies present a Cloud-based approach to measure IoT
    data freshness [26] and a distributed architecture using blockchain and smart
    contracts for data quality in logistics traceability [1]. Six primary studies
    [5, 7, 11, 13, 21, 41] focus on data quality management in edge-based architecture
    levels (L2 and L3). Only one study [5] provides a data quality technique running
    on edge (L3). It is an online data cleaning technique that uses ML (decision trees
    and random forest classification) to filter out unwanted events on raw data on
    the edge before further processing data on the Cloud. One study [7] proposes a
    game theory algorithm running on edge (L3) to detect fraudulent data. Dedeoglu
    et al. [11] use gateways (L2, L3) to calculate trust for sensor observations.
    Guo et al. [13] distribute portions of large volumes of data from machines (L1)
    to the edge (L3). Kufner et al. [21] combine signal acquisition and concurrent
    analysis techniques in a distributed edge-based structure (L2, L3) to achieve
    vertical data continuity. Nine primary studies [4, 8, 10, 16, 23, 24, 31, 40,
    49] cover edge-Cloud orchestration for data processing (not necessarily data quality
    management). Four of these studies [23, 31, 40, 49] provide a data quality management
    technique (data cleaning and repair) in the architecture layers from L1 to L7.
    They are all online techniques and implement data monitoring and cleaning/repair
    across the edge-Cloud continuum. For instance, Syafrudin et al. [40] incorporate
    distributed gateways (L3) that obtain sensor data and application layers (L4,
    L5, and L6) used for detection/removal and fault prediction. The remaining five
    primary studies mention data quality as part of data analytics support or data
    management frameworks. Therefore, they cover almost all the IoT architecture layers
    while addressing data quality management in a subset of these layers. Our observation
    is that the ubiquitousness, complexity, and size of IoT systems pose fundamental
    challenges and limitations in deploying data quality techniques across the IoT
    reference architecture layers. IoT systems may run on several IoT device types
    (e.g., smart camera, thermostat, smart tv, force sensors, vibration sensors) having
    different operational environments (e.g., industrial, enterprise, consumer). These
    devices may operate on several protocols (MQTT, CoAP, AMQP) and connection types
    (device-to-device, device-to-gateway, gateway-to-data systems) with different
    data acquisition systems. Having several device and protocol configurations for
    IoT systems obtaining different kinds of data in different operational environments
    leads to several resource constraints and data quality management scenarios (online
    and offline). For instance, we deploy a data repair technique on the Cloud for
    the historical (offline) repair of high-frequency manufacturing data stored in
    the cloud infrastructure. The same technique may also be deployed on edge to perform
    in-motion (online) data repair for real-time predictive maintenance. We need highly
    configurable data management techniques deployed on different layers of the IoT
    reference architecture for different scenarios, e.g., on a stand-alone machine,
    an edge device, or the Cloud, with access to a long- or short-term database or
    an API provided by a data acquisition system. However, the current data repair
    and cleaning techniques we summarized above address particular scenarios (online
    or offline). They are not deployed on different architecture layers in the edge-Cloud
    continuum for different quality management scenarios based on the needs of the
    targeted IoT system. As we mentioned in RQ2.2 and 2.3, data quality monitoring
    is part of data cleaning and repair. However, there might be cases where the data
    repair or cleaning technique should run together with several data quality monitoring
    techniques deployed on different architecture layers. For instance, the same repair
    technique may predict values for missing values identified by a data monitoring
    approach on edge and values replacing erroneous data identified by another monitoring
    approach in the Cloud as part of historical data validation. Applying decentralized
    ML architectures to data quality management might address all these challenges
    and limitations of the existing techniques related to their deployment on the
    architecture layers depending on the quality management requirements and scenarios.
    We can distribute the ML model training for data repair and cleaning and containerize
    the trained models to be deployed on a standalone machine, edge, or the Cloud
    for different quality management scenarios. On the other hand, we need research
    to address the data and model evolution challenges and limitations caused by integrating
    ML models and components (see Section 4.2.2). RQ3.3 Conclusion.. Most existing
    research focuses only on data processing in (indirect) relation to data quality
    without considering other aspects within the IoT architecture. We found very few
    studies discussing all the layers of IoT architecture where data flow from IoT
    devices, via edge, to the Cloud. The existing data quality techniques do not cover
    different combinations of IoT reference architecture layers for different scenarios
    depending on the needs of the targeted IoT system. We need further research on
    data quality techniques that can run on a standalone machine, edge device, or
    the Cloud, with data access to support online and offline data repair and cleaning.
    4.4 Summary of Data Quality for CPS and IoT in Industry 4.0 Figure 5 summarizes
    the results related to our RQs. It shows the data quality issues for CPS and IoT,
    the sources of these quality issues, the data quality metrics, the data quality
    techniques, the metrics used to evaluate the techniques, and the software engineering
    solutions to manage data quality. It can be used with the taxonomy of data quality
    in data-driven paradigms (see Figure 2) to classify future data quality research
    for CPS and IoT in Industry 4.0. Fig. 5. Fig. 5. Summary of data quality in CPS
    and IoT for Industry 4.0. Skip 5RELATED WORK Section 5 RELATED WORK Several works
    study the literature on CPS and IoT. The focus of most of the surveys for CPS
    is on security and privacy (e.g., [84, 85, 93, 96, 102, 112, 113, 119, 124]).
    Some of them [84, 96, 102] survey the literature for CPS security from a more
    general perspective; some others focus on specialized security topics such as
    intrusion detection systems [119], deep learning-based anomaly detection [113],
    physics-based attack detection [85], differential privacy [92], and model-based
    security engineering [124] for CPS. Gunes et al. [90] and Chen et al. [71] conduct
    secondary studies on the applications and challenges of CPS. Dey et al. [77] focus
    on the research for CPS in the medical domain. Xu et al. [154] survey the literature
    on the intersection between CPS and big data in Industry 4.0. Like the secondary
    studies for CPS, various studies for IoT address security and privacy (e.g., [54,
    56, 59, 70, 72, 73, 93, 94, 108, 115, 117, 122, 146]). Some other studies are
    specialized in interoperability for Industrial IoT (IIoT) [95], IoT protocols,
    technologies, and applications along with related issues [57, 61, 73, 78, 107,
    123, 137], IoT applications in blockchain systems [105], applications of blockchain
    technologies to IoT [158], IoT big data [63], data analytics for IoT [141], IoT-based
    smart cities [60], IoT for agriculture [80], IoT for healthcare [101], and IoT
    in industries [76]. Some secondary studies (e.g., [153]) survey the works for
    CPS and IoT in the context of Industry 4.0. Some other studies (e.g., [109, 111,
    128, 136, 155, 157]) mainly focus on the literature for Industry 4.0, where CPS
    and IoT are considered building blocks of Industry 4.0. None of the works mentioned
    above address data quality for CPS and IoT. We have identified only three SLRs
    and three surveys focusing on data quality in the context of CPS and IoT, as briefly
    presented in Table 1. For each related work in the table, the symbol ‘✓’ indicates
    that the work provides the feature, the symbol ‘✗’ indicates that it does not
    provide the feature, and ‘NA’ indicates that the required information is unavailable.
    Karkouch et al. [100] surveyed 14 papers published between 2012 and 2016. Their
    paper selection was random without a systematic search and selection process of
    systematic reviews [104, 130, 150]. Moreover, we could not find any information
    on how the authors chose the discussed aspects of data quality for IoT (DQ classification
    schema). Karkouch et al. listed four data quality challenges for IoT data: (i)
    the scalability of cleaning methods in distributed systems, (ii) the heterogeneity
    of data sources requiring complex approaches, (iii) the automated verification
    without human interaction, and (iv) the fail-safe distributed architecture. They
    highlighted the need for an abstraction level that supports data quality assessment
    independent from data types. Wang and Wang [148] reviewed the state-of-the-art
    for time series data cleaning and classified time series errors. They mentioned
    four challenges related to time series data cleaning: (i) a large amount of data
    with a high error rate (especially, in industrial settings), (ii) ambiguous reasons
    for errors, (iii) continuous nature requiring online analysis, and (iv) minimum
    modification principle. They identified the need for research for analyzing error
    types defined rather broadly. They highlighted the lack of multivariate cleaning
    algorithms and the potential for utilizing ML for data cleaning. Zhang et al.
    [156] compared 21 IoT data quality frameworks and 5 related standards. The diversity
    in data quality frameworks and various definitions of data quality dimensions
    and metrics hampered the comparability of the survey. The survey revealed the
    need for a more user-friendly data quality assessment methodology based on existing
    generic frameworks. Teh et al. [144] presented a recent SLR on sensor data quality
    problems. They mainly investigated the error types of sensor data and sensor data
    error detection and correction methods. Unlike our SLR, their SLR did not study
    the application domains for data quality research for IoT, the trade-off between
    data quality and security, and software engineering solutions used to manage data
    quality. Teh et al. reported several methods proposed to detect and correct sensor
    data errors. 90% of the studies in the SLR provided proper validation, and 68%
    used not publicly available or reproducible data. Teh et al. highlighted that
    the methods are not comparable without further ado since variations of a common
    idea are utilized in many cases with a varying research methodology (e.g., labeling,
    error injection, or preprocessing method). They revealed the need for a benchmark
    system to compare data quality techniques. Liu et al. [110] conducted an SLR on
    data quality in IoT based on 45 empirical studies from 2012 to 2018. Contrary
    to our study, their SLR is limited to data quality problems (issues), dimensions,
    and measures. It does not cover topics such as data quality techniques, their
    evaluation, application domains for data quality research, and software technologies
    for managing data quality, which are the main points of our SLR. Liu et al. established
    links among data quality dimensions, manifestations of data quality problems,
    and methods utilized to measure data quality. They identified the potential areas
    for future work: (i) developing guidelines for defining specific data quality
    dimensions of IoT data, (ii) addressing data quality problems based on different
    IoT layers, and (iii) constructing data quality frameworks in the IoT context.
    More recently, Alwan et al. [58] conducted another SLR to investigate data quality
    challenges in smart cities as large-scale CPSs and identify the most common techniques
    used to address these challenges. The scope of the SLR is limited to the data
    quality challenges for CPSs, the data quality techniques to overcome these challenges,
    and the effectiveness of these techniques. The SLR does not cover data quality
    metrics, data security, or software engineering solutions to manage data quality.
    Similar to the results we reported (see Section 4.1.1), Alwan et al. revealed
    that data quality issues occur in large-scale CPSs because of sensor malfunctions,
    calibration issues, poor sensor node quality, environmental effects, external
    noise, and networks or communication errors. They categorized the data quality
    solutions into three primary groups: data mining, technical models, and mathematical
    models. Data mining methods (i.e., anomaly detection, classification, clustering,
    and predictive analysis) are the most widely used compared to others. In comparison
    with the SLRs and surveys mentioned above, our SLR investigates exclusively three
    aspects of data quality for IoT, CPS, and Industry 4.0: (i) data quality problems
    (including data quality issues, their resources, application domains, data types,
    and data quality and security tradeoff), (ii) data quality techniques to overcome
    the problems (metrics to monitor data quality, approaches for data repair and
    cleaning, and evaluation of these approaches), and (iii) software engineering
    solutions for data quality (architectures, programming languages, and data storage
    solutions). Existing SLRs focused on one or two aspects with a limited scope.
    For instance, Liu et al. [110] studied the literature on data quality problems
    based on quality dimensions and measures. We approach data quality research for
    theoretical and practical implications in a much broader scope. We also report
    some research directions. Skip 6THREATS TO VALIDITY Section 6 THREATS TO VALIDITY
    Our systematic literature review addresses a wide range of approaches and domains.
    Our review process had automated (e.g., search queries) and manual (e.g., data
    extraction) parts. Therefore, some relevant studies and information might have
    been uncovered. In the following, we summarize several measures taken to mitigate
    this issue. 6.1 Internal Validity Search Queries. We aimed to find as many relevant
    publications as possible by using general terms related to data quality in our
    search queries. We used our inclusion and exclusion criteria to select the papers.
    It is still possible that we should have included more research in the final selection
    of primary studies. To mitigate this risk, we conducted a manual search to limit
    the possibility of missing studies throughout the database search process. We
    discovered most of the primary studies through our database search. The search
    features provided by these online publication databases are not always the same,
    which may lead to misleading search results. To mitigate this risk, we adapted
    our search string for the built-in search features of each database. Study Inclusion
    and Exclusion. Even though we have well-defined inclusion and exclusion criteria,
    including or excluding a study could still be subjective, especially when its
    contribution is indirect to data quality (e.g., some studies support data quality
    as a preprocessing step of data analytics). To mitigate this risk, we conducted
    cross-checks between at least two authors and then group discussion to remove
    papers that did not have enough scientific contribution according to our selection
    criteria. Data Extraction. Missing and misinterpreting information is a risk of
    manual information extraction. To mitigate this risk, we distributed the primary
    studies to the authors for data extraction. They later validated the data extraction
    for each other. One co-author reviewed the data extraction and its validation
    to identify and summarize the data extraction inconsistencies. We settled all
    the conflicts during meetings with the authors. 6.2 External Validity The online
    repositories we used in our SLR restrict our review results. To mitigate this
    risk, we employed repositories that well-known venues have been included in and
    that previous survey papers have extensively used. 6.3 Conclusion Validity The
    primary studies have a variety of application domains, and some of them have primary
    goals different than data quality (e.g., data analytics), which made it difficult
    to determine direct contributions to data quality and draw decisive conclusions.
    To mitigate this issue, we categorized the primary studies based on goals (e.g.,
    data quality as a primary/secondary goal in Table 10) for our research questions.
    6.4 Reliability Validity The readers can replicate our systematic literature review
    study if they follow the steps of our review process. It is still possible to
    have some inconsistent results because of potential differences in the manual
    steps of the review process, such as data extraction and synthesis. To mitigate
    this risk, we provided the details of our review process (see Section 2) and a
    summary of data quality research (Figure 5) that can be used with our taxonomy
    of data quality (Figure 2) in data-driven paradigms to classify and compare future
    primary studies. Skip 7CONCLUSIONS Section 7 CONCLUSIONS This article presented
    the results of our systematic literature review (SLR) regarding data quality research
    for CPS and IoT in Industry 4.0. Obtaining data from IoT and CPS for decision
    support is crucial to improving efficiency and competitiveness in many industrial
    sectors and application domains. Data quality techniques ensure the input quality
    for decision support and become an inherent component of data-centric CPS and
    IoT applications. We followed the common SLR steps (i.e., the definition of research
    questions, a search strategy, inclusion and exclusion criteria, and data synthesis
    and extraction method) to conduct our review. Our systematic search and selection
    process yielded 51 primary studies published between 2011 and 2021 (and three
    SLRs and three surveys). The growing number of studies in recent years indicates
    an increasing interest in data quality research for CPS and IoT. Our objective
    was to analyze how data quality has been treated for data-centric CPS and IoT
    applications and evaluate what the proposed data quality techniques have done
    for those applications. We investigated data quality issues and their sources
    for CPS and IoT, data quality metrics, data quality techniques (including data
    quality monitoring, data repair, and data cleaning), and software engineering
    solutions for handling data quality. To answer three RQs (ten sub-questions),
    we obtained and synthesized data from the primary studies. From our SLR, we conclude
    the following: (a) The primary studies address a variety of data quality issues.
    Outliers, missing values, and data veracity are the three main ones. Not many
    studies discuss the source of data quality issues and the implications of different
    computing architectures for data quality issues. Future research should further
    investigate the reasons and the implications of computing architectures for data
    quality issues to devise better techniques. (b) We could not find any study reporting
    the adoption of data quality metrics in industrial systems. We need research to
    facilitate using quality metrics in industrial settings. (c) Non-AI data repair
    solutions have limitations in the industrial CPS/IoT context (e.g., requiring
    dependent data computations in the application state history, which are not always
    available). Future research should explore machine learning for online and offline
    data repair while addressing model deployment and evolution. (d) Most data cleaning
    techniques are domain agnostic and may not always detect and clean domain-specific
    data quality issues. Further research should address guided processes that use
    domain-agnostic data quality monitoring and domain-knowledge-based heuristics.
    Real-time machine learning applications need online data cleaning support to reduce
    high dimensions in input datasets. (e) Existing data quality management techniques
    do not support deployment on different IoT layers for online and offline scenarios.
    Future techniques should be able to run on a standalone machine, edge device,
    or the Cloud, with data access to support online and offline data repair and cleaning
    on the edge and in the Cloud. (f) The programming languages and solutions for
    managing data quality (e.g., TensorFlow, Keras, MATLAB’s fuzzy logic toolbox)
    highly depend on the solution domain (e.g., ML, data mining). Big data software
    platforms are suitable for addressing data quality concerns for high-velocity
    data (e.g., the timely monitoring of data changes, data redundancy, data inconsistency,
    and data insecurity). (g) We could not reveal any direct relation between the
    database technologies and the data quality techniques. On the other hand, big
    data systems gathering data from various sources combine multiple data storage
    solutions that require a layered data storage architecture where each layer may
    require its own data quality technique. Skip ACKNOWLEDGMENTS Section ACKNOWLEDGMENTS
    We would like to thank Enrique Garcia-Ceja (our former colleague at SINTEF), Nicolas
    Jourdan (PTW TU Darmstadt, Germany), and Beatriz Bretones Cassoli (PTW TU Darmstadt,
    Germany) for their help during the initial phase of this work. PRIMARY STUDIES
    [1] Ahmed Mohamed, Taconet Chantal, Ould Mohamed, Chabridon Sophie, and Bouzeghoub
    Amel. 2021. IoT data qualification for a logistic chain traceability smart contract.
    Sensors 21, 6 (2021). Navigate to [2] Apiletti Daniele, Barberis Claudia, Cerquitelli
    Tania, Macii Alberto, Macii Enrico, Poncino Massimo, and Ventura Francesco. 2018.
    iSTEP, an integrated self-tuning engine for predictive maintenance in Industry
    4.0. In ISPA/IUCC/BDCloud/SocialCom/SustainCom’18. 924–931. Navigate to [3] Azimi
    Shelernaz and Pahl Claus. 2020. A layered quality framework for machine learning-driven
    data and information models. In ICEIS (1). 579–587. Reference 1Reference 2Reference
    3 [4] Bamgboye Oluwaseun, Liu Xiaodong, and Cruickshank Peter. 2019. Semantic
    stream management framework for data consistency in smart spaces. In COMPSAC’19.
    85–90. Navigate to [5] Buschjäger Sebastian and Morik Katharina. 2018. Decision
    tree and random forest implementations for fast filtering of sensor data. IEEE
    Transactions on Circuits and Systems I: Regular Papers 65, 1 (2018), 209–222.
    Navigate to [6] Byabazaire John, O’Hare Gregory, and Delaney Declan. 2020. Using
    trust as a measure to derive data quality in data shared IoT deployments. In ICCCN’20.
    1–9. Navigate to [7] Casado-Vara Roberto, Prieta Fernando de la, Prieto Javier,
    and Corchado Juan M.. 2018. Blockchain framework for IoT data quality via edge
    computing. In BlockSys’18. 19–24. Navigate to [8] Cerquitelli T., Nikolakis N.,
    Bethaz P., Panicucci S., Ventura F., Macii E., Andolina S., Marguglio A., Alexopoulos
    K., Petrali P., Pagani A., Wilgen P. van, and Ippolito M.. 2020. Enabling predictive
    analytics for smart manufacturing through an IIoT platform. In AMEST’20. 179–184.
    Navigate to [9] Corrales David Camilo, Corrales Juan Carlos, and Ledezma Agapito.
    2018. How to address the data quality issues in regression models: A guided process
    for data cleaning. Symmetry 10, 4 (2018). Navigate to [10] Cui Yesheng, Kara Sami,
    and Chan Ka C.. 2020. Monitoring and control of unstructured manufacturing big
    data. In IEEM’20. 928–932. Navigate to [11] Dedeoglu Volkan, Jurdak Raja, Putra
    Guntur D., Dorri Ali, and Kanhere Salil S.. 2019. A trust architecture for blockchain
    in IoT. In MobiQuitous’19. 190–199. Navigate to [12] Flick Dominik, Gellrich Sebastian,
    Filz Marc-André, Ji Li, Thiede Sebastian, and Herrmann Christoph. 2019. Conceptual
    framework for manufacturing data preprocessing of diverse input sources. In INDIN’19.
    1041–1046. Navigate to [13] Guo Ziqi, Bao Tingwen, Wu Wenlong, Jin Chao, and Lee
    Jay. 2019. IAI DevOps: A systematic framework for prognostic model lifecycle management.
    In PHM-Qingdao’19. 1–6. Navigate to [14] Hui Liu, Xiaobo Ye, Zhijun Meng, Lijuan
    Zhou, and Zhong Sun. 2019. An agricultural machinery operation monitoring system
    based on IoT. In DSIT’19. 225–229. Navigate to [15] Huru Dan, Leordeanu Cătălin,
    Apostol Elena, Mocanu Mariana, and Cristea Valentin. 2018. BigClue analytics:
    A middleware component for modeling sensor data in IoT systems. In HPCC/SmartCity/DSS’18.
    891–896. Navigate to [16] Jeong Seunghwan, Yoo Gwangpyo, Yoo Minjong, Yeom Ikjun,
    and Woo Honguk. 2019. Resource-efficient sensor data management for autonomous
    systems using deep reinforcement learning. Sensors 19, 20 (2019). Navigate to
    [17] Khan Mohammad Ayoub and Algarni Fahad. 2020. A healthcare monitoring system
    for the diagnosis of heart disease in the IoMT cloud environment using MSSO-ANFIS.
    IEEE Access 8 (2020), 122259–122269. Navigate to [18] Kong Tianxiang, Hu Tianliang,
    Zhou Tingting, and Ye Yingxin. 2021. Data construction method for the applications
    of workshop digital twin system. Journal of Manufacturing Systems 58 (2021), 323–328.
    Navigate to [19] Krotofil Marina, Larsen Jason, and Gollmann Dieter. 2015. The
    process matters: Ensuring data veracity in cyber-physical systems. In ASIA CCS’15.
    133–144. Navigate to [20] Kuemper Daniel, Iggena Thorben, Toenjes Ralf, and Pulvermueller
    Elke. 2018. Valid.IoT: A framework for sensor data quality analysis and interpolation.
    In MMSys’18. 294–303. Navigate to [21] Küfner Thomas, Schönig Stefan, Jasinski
    Richard, and Ermer Andreas. 2021. Vertical data continuity with lean edge analytics
    for Industry 4.0 production. Computers in Industry 125 (2021), 103389. Navigate
    to [22] Li Fei, Nastic Stefan, and Dustdar Schahram. 2012. Data quality observation
    in pervasive environments. In ICCSE’12. 602–609. Navigate to [23] Lin Wei-Tsung,
    Bakir Fatih, Krintz Chandra, Wolski Rich, and Mock Markus. 2019. Data repair for
    distributed, event-based IoT applications. In DEBS’19. 139–150. Navigate to [24]
    Liu Chao, Roux Léopold Le, Körner Carolin, Tabaste Olivier, Lacan Franck, and
    Bigot Samuel. 2020. Digital twin-enabled collaborative data management for metal
    additive manufacturing systems. Journal of Manufacturing Systems (2020). Navigate
    to [25] Mieth Carina, Meyer Anne, and Henke Michael. 2019. Framework for the usage
    of data from real-time indoor localization systems to derive inputs for manufacturing
    simulation. Procedia CIRP 81 (2019), 868–873. Reference 1Reference 2Reference
    3 [26] Mohammed Fatma, Kayes A. S. M., Pardede Eric, and Rahayu Wenny. 2020. A
    framework for measuring IoT data quality based on freshness metrics. In TrustCom’20.
    1242–1249. Navigate to [27] Okafor Nwamaka U., Alghorani Yahia, and Delaney Declan
    T.. 2020. Improving data quality of low-cost IoT sensors in environmental monitoring
    networks using data fusion and machine learning approach. ICT Express 6, 3 (2020),
    220–228. Navigate to [28] Packianather Michael S., Munizaga Nury Leon, Zouwail
    Soha, and Saunders Mark. 2019. Development of soft computing tools and IoT for
    improving the performance assessment of analysers in a clinical laboratory. In
    SoSE’19. 158–163. Reference 1Reference 2 [29] Proto Stefano, Ventura Francesco,
    Apiletti Daniele, Cerquitelli Tania, Baralis Elena, Macii Enrico, and Macii Alberto.
    2019. PREMISES, a scalable data-driven service to predict alarms in slowly-degrading
    multi-cycle industrial processes. In BigDataCongress’19. 139–143. Navigate to
    [30] Qi Qinglin and Tao Fei. 2018. Digital twin and big data towards smart manufacturing
    and industry 4.0: 360 degree comparison. IEEE Access 6 (2018), 3585–3593. Reference
    1Reference 2Reference 3 [31] Russell Luke, Kwamena Felix, and Goubran Rafik. 2019.
    Towards reliable IoT: Fog-based AI sensor validation. In IEEE Cloud Summit. 37–44.
    Navigate to [32] Santos Maribel Yasmina, Sá Jorge Oliveira e, Andrade Carina,
    Lima Francisca Vale, Costa Eduarda, Costa Carlos, Martinho Bruno, and Galvão João.
    2017. A big data system supporting Bosch Braga Industry 4.0 strategy. International
    Journal of Information Management 37, 6 (2017), 750–760. Navigate to [33] Sanyal
    Sunny and Zhang Puning. 2018. Improving quality of data: IoT data aggregation
    using device-to-device communications. IEEE Access 6 (2018), 67830–67840. Navigate
    to [34] Saranya E. and Sivakumar P. Bagavathi. 2020. Data-driven prognostics for
    run-to-failure data employing machine learning models. In ICICT’20. 528–533. Navigate
    to [35] Saybani Mahmoud Reza, Wah Teh Ying, Amini Amineh, and Yazdi Saeed Reza
    Aghabozorgi Sahaf. 2011. Anomaly detection and prediction of sensors faults in
    a refinery using data mining techniques and fuzzy logic. Scientific Research and
    Essays 6, 27 (2011), 5685–5695. Navigate to [36] Seghezzi Elena, Locatelli Mirko,
    Pellegrini Laura, Pattini Giulia, Giuda Giuseppe Martino Di, Tagliabue Lavinia
    Chiara, and Boella Guido. 2021. Towards an occupancy-oriented digital twin for
    facility management: Test campaign and sensors assessment. Applied Sciences 11,
    7 (2021). Navigate to [37] Shah Devarshi, Wang Jin, and He Q. Peter. 2020. Feature
    engineering in big data analytics for IoT-enabled smart manufacturing – Comparison
    between deep learning and statistical learning. Computers & Chemical Engineering
    141 (2020), 106970. Navigate to [38] Sicari Sabrina, Cappiello Cinzia, Pellegrini
    Francesco De, Miorandi Daniele, and Coen-Porisini Alberto. 2016. A security-and
    quality-aware system architecture for Internet of Things. Information Systems
    Frontiers 18, 4 (2016), 665–677. Navigate to [39] Sicari Sabrina, Rizzardi Alessandra,
    Miorandi Daniele, Cappiello Cinzia, and Coen-Porisini Alberto. 2016. A secure
    and quality-aware prototypical architecture for the Internet of Things. Information
    Systems 58 (2016), 43–55. Navigate to [40] Syafrudin Muhammad, Alfian Ganjar,
    Fitriyani Norma Latif, and Rhee Jongtae. 2018. Performance analysis of IoT-based
    sensor, big data processing, and machine learning model for real-time monitoring
    system in automotive manufacturing. Sensors 18, 9 (2018). Navigate to [41] Tham
    Chen-Khong and Rajagopalan Rajalaxmi. 2020. Active learning for IoT data prioritization
    in edge nodes over wireless networks. In IECON’20. 4453–4458. Reference 1Reference
    2Reference 3 [42] Villalobos K., Ramírez-Durán V. J., Diez B., Blanco J. M., Goñi
    A., and Illarramendi A.. 2020. A three level hierarchical architecture for an
    efficient storage of Industry 4.0 data. Computers in Industry 121 (2020), 103257.
    Navigate to [43] Villalobos Kevin, Vadillo Jon, Diez Borja, Calvo Borja, and Illarramendi
    Arantza. 2018. I4TSPS: A visual-interactive web system for industrial time-series
    pre-processing. In Big Data’18. 2012–2018. Navigate to [44] Wang Chang, Zhu Yongxin,
    Shi Weiwei, Chang Victor, Vijayakumar P., Liu Bin, Mao Yishu, Wang Jiabao, and
    Fan Yiping. 2018. A dependable time series analytic framework for cyber-physical
    systems of IoT-based smart grid. ACM Transactions on Cyber-Physical Systems 3,
    1 (2018), 18 pages. Navigate to [45] Wei Wei, Yuan Jun, and Liu Ang. 2020. Manufacturing
    data-driven process adaptive design method. Procedia CIRP 91 (2020), 728–734.
    Navigate to [46] Weiss Sholom M., Dhurandhar Amit, and Baseman Robert J.. 2013.
    Improving quality control by early prediction of manufacturing outcomes. In KDD’13.
    1258–1266. Navigate to [47] Wu Leon and Kaiser Gail. 2012. An autonomic reliability
    improvement system for cyber-physical systems. In HASE’12. 56–61. Reference 1Reference
    2 [48] Yu Wenjin, Dillon Tharam, Mostafa Fahed, Rahayu Wenny, and Liu Yuehua.
    2019. Implementation of industrial cyber physical system: Challenges and solutions.
    In ICPS’19. 173–178. Navigate to [49] Yu Wenjin, Dillon Tharam, Mostafa Fahed,
    Rahayu Wenny, and Liu Yuehua. 2020. A global manufacturing big data ecosystem
    for fault detection in predictive maintenance. IEEE Transactions on Industrial
    Informatics 16, 1 (2020), 183–192. Navigate to [50] Zacarias Alejandro Gabriel
    Villanueva, Reimann Peter, and Mitschang Bernhard. 2018. A framework to guide
    the selection and configuration of machine-learning-based data analytics solutions
    in manufacturing. Procedia CIRP 72 (2018), 153–158. Navigate to [51] Zellinger
    Werner, Wieser Volkmar, Kumar Mohit, Brunner David, Shepeleva Natalia, Gálvez
    Rafa, Langer Josef, Fischer Lukas, and Moser Bernhard. 2021. Beyond federated
    learning: On confidentiality-critical machine learning applications in industry.
    In ISM’20. 734–743. Navigate to REFERENCES [52] Martín Abadi, Paul Barham, Jianmin
    Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat,
    Geoffrey Irving, Michael Isard, Manjunath Kudlur, Josh Levenberg, Rajat Monga,
    Sherry Moore, Derek G. Murray, Benoit Steiner, Paul Tucker, Vijay Vasudevan, Pete
    Warden, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. 2016. Tensorflow: A system
    for large-scale machine learning. In OSDI’16. 265–283. Reference 1Reference 2
    [53] Abdi Hervé and Williams Lynne J.. 2010. Principal component analysis. Wiley
    Interdisciplinary Reviews: Computational Statistics 2, 4 (2010), 433–459. Navigate
    to [54] Ahmad Rasheed and Alsmadi Izzat. 2021. Machine learning approaches to
    IoT security: A systematic literature review. Internet of Things 14 (2021), 100365.
    Reference [55] Akter Shahriar, McCarthy Grace, Sajib Shahriar, Michael Katina,
    Dwivedi Yogesh K., D’Ambra John, and Shen K. N.. 2021. Algorithmic bias in data-driven
    innovation in the age of AI. International Journal of Information Management 60
    (2021), 102387. Reference [56] Al-Garadi Mohammed Ali, Mohamed Amr, Al-Ali Abdulla
    Khalid, Du Xiaojiang, Ali Ihsan, and Guizani Mohsen. 2020. A survey of machine
    and deep learning methods for Internet of Things (IoT) security. IEEE Communications
    Surveys & Tutorials 22, 3 (2020), 1646–1685. Reference [57] Alam Iqbal, Sharif
    Kashif, Li Fan, Latif Zohaib, Karim Md Monjurul, Biswas Sujit, Nour Boubakr, and
    Wang Yu. 2020. A survey of network virtualization techniques for Internet of Things
    using SDN and NFV. ACM Computing Surveys (CSUR) 53, 2 (2020), 1–40. Reference
    [58] Alwan Ahmed Abdulhasan, Ciupala Mihaela Anca, Brimicombe Allan J., Ghorashi
    Seyed Ali, Baravalle Andres, and Falcarin Paolo. 2022. Data quality challenges
    in large-scale cyber-physical systems: A systematic review. Information Systems
    105 (2022). Reference 1Reference 2Reference 3 [59] Ammar Mahmoud, Russello Giovanni,
    and Crispo Bruno. 2018. Internet of Things: A survey on the security of IoT frameworks.
    Journal of Information Security and Applications 38 (2018), 8–27. Reference [60]
    Arasteh Hamidreza, Hosseinnezhad Vahid, Loia Vincenzo, Tommasetti Aurelio, Troisi
    Orlando, Shafie-khah Miadreza, and Siano Pierluigi. 2016. IoT-based smart cities:
    A survey. In 2016 IEEE 16th International Conference on Environment and Electrical
    Engineering (EEEIC’16). 1–6. Reference [61] Asghari Parvaneh, Rahmani Amir Masoud,
    and Javadi Hamid Haj Seyyed. 2019. Internet of Things applications: A systematic
    review. Computer Networks 148 (2019), 241–261. Reference [62] Azamfar Moslem,
    Li Xiang, and Lee Jay. 2020. Deep learning-based domain adaptation method for
    fault diagnosis in semiconductor manufacturing. IEEE Transactions on Semiconductor
    Manufacturing 33, 3 (2020), 445–453. Reference [63] Bansal Maggi, Chana Inderveer,
    and Clarke Siobhán. 2020. A survey on IoT big data: Current status, 13 v’s challenges,
    and future directions. ACM Computing Surveys (CSUR) 53, 6 (2020), 1–59. Reference
    [64] Barbieri Davide Francesco, Braga Daniele, Ceri Stefano, Valle Emanuele Della,
    and Grossniklaus Michael. 2009. C-SPARQL: SPARQL for continuous querying. In WWW’09.
    1061–1062. Reference 1Reference 2 [65] Bitton Dina and DeWitt David J.. 1983.
    Duplicate record elimination in large data files. ACM Transactions on Database
    Systems 8, 2 (1983), 255–265. Reference [66] Breunig Markus M., Kriegel Hans-Peter,
    Ng Raymond T., and Sander Jörg. 2000. LOF: Identifying density-based local outliers.
    In MOD’00. 93–104. Reference [67] Cafarella Michael, Ilyas Ihab F., Kornacker
    Marcel, Kraska Tim, and Ré Christopher. 2016. Dark data: Are we solving the right
    problems?. In 2016 IEEE 32nd International Conference on Data Engineering (ICDE’16).
    IEEE, 1444–1445. Reference [68] Camel Apache. [n.d.]. https://camel.apache.org/.
    Reference 1Reference 2 [69] Carroll Jeremy J., Dickinson Ian, Dollin Chris, Reynolds
    Dave, Seaborne Andy, and Wilkinson Kevin. 2004. Jena: Implementing the semantic
    web recommendations. In WWW’04. 74–83. Reference 1Reference 2 [70] Celik Z. Berkay,
    Fernandes Earlence, Pauley Eric, Tan Gang, and McDaniel Patrick. 2019. Program
    analysis of commodity IoT applications for security and privacy: Challenges and
    opportunities. ACM Computing Surveys (CSUR) 52, 4 (2019), 1–30. Reference [71]
    Chen Hong. 2017. Applications of cyber-physical system: A literature review. Journal
    of Industrial Integration and Management 2, 03 (2017), 1750012. Reference [72]
    Chen Zhiyan, Liu Jinxin, Shen Yu, Simsek Murat, Kantarci Burak, Mouftah Hussein
    T., and Djukic Petar. 2022. Machine learning-enabled iot security: Open issues
    and challenges under advanced persistent threats. Comput. Surveys 55, 5 (2022),
    1–37. Reference [73] Chettri Lalit and Bera Rabindranath. 2019. A comprehensive
    survey on Internet of Things (IoT) toward 5G wireless systems. IEEE Internet of
    Things Journal 7, 1 (2019), 16–32. Reference 1Reference 2 [74] Corallo Angelo,
    Crespino Anna Maria, Vecchio Vito Del, Lazoi Mariangela, and Marra Manuela. 2021.
    Understanding and defining dark data for the manufacturing industry. IEEE Transactions
    on Engineering Management (2021). Reference [75] Create-IoT. 2018. Deliverable
    D6.02 – Recommendations for Commonalities and Interoperability Profiles of IoT
    Platforms. https://european-iot-pilots.eu/wp-content/uploads/2018/11/D06_02_WP06_H2020_CREATE-IoT_Final.pdf.
    Reference [76] Xu Li Da, He Wu, and Li Shancang. 2014. Internet of Things in industries:
    A survey. IEEE Transactions on Industrial Informatics 10, 4 (2014), 2233–2243.
    Reference [77] Dey Nilanjan, Ashour Amira S., Shi Fuqian, Fong Simon James, and
    Tavares João Manuel R. S.. 2018. Medical cyber-physical systems: A survey. Journal
    of Medical Systems 42 (2018), 1–13. Reference [78] Dizdarević Jasenka, Carpio
    Francisco, Jukan Admela, and Masip-Bruin Xavi. 2019. A survey of communication
    protocols for internet of things and related challenges of fog and cloud computing
    integration. ACM Computing Surveys (CSUR) 51, 6 (2019), 1–29. Reference [79] Dutka
    Alan F. and Hansen Howard H.. 1991. Fundamentals of Data Normalization. Addison-Wesley
    Longman Publishing Co., Inc. Reference [80] Elijah Olakunle, Rahman Tharek Abdul,
    Orikumhi Igbafe, Leow Chee Yen, and Hindia M. H. D. Nour. 2018. An overview of
    Internet of Things (IoT) and data analytics in agriculture: Benefits and challenges.
    IEEE Internet of Things Journal 5, 5 (2018), 3758–3773. Reference [81] Martin
    Ester, Hans-Peter Kriegel, Jörg Sander, and Xiaowei Xu. 1996. A density-based
    algorithm for discovering clusters in large spatial databases with noise. In KDD’96,
    226–231. Navigate to [82] Frank Alejandro Germán, Dalenogare Lucas Santos, and
    Ayala Néstor Fabián. 2019. Industry 4.0 technologies: Implementation patterns
    in manufacturing companies. International Journal of Production Economics 210
    (2019), 15–26. Reference [83] Gimpel Gregory and Alter Allan. 2021. Benefit from
    the Internet of Things right now by accessing dark data. IT Professional 23, 2
    (2021), 45–49. Reference [84] Giraldo Jairo, Sarkar Esha, Cardenas Alvaro A.,
    Maniatakos Michail, and Kantarcioglu Murat. 2017. Security and privacy in cyber-physical
    systems: A survey of surveys. IEEE Design & Test 34, 4 (2017), 7–17. Reference
    1Reference 2 [85] Giraldo Jairo, Urbina David, Cardenas Alvaro, Valente Junia,
    Faisal Mustafa, Ruths Justin, Tippenhauer Nils Ole, Sandberg Henrik, and Candell
    Richard. 2018. A survey of physics-based attack detection in cyber-physical systems.
    ACM Computing Surveys (CSUR) 51, 4 (2018), 1–36. Reference 1Reference 2 [86] Goodfellow
    Ian, Bengio Yoshua, and Courville Aaron. 2016. Machine learning basics. Deep Learning
    1, 7 (2016), 98–164. Reference [87] Grantner Emily. 2007. ISO 8000: A standard
    for data quality. Logistics Spectrum 41, 4 (2007). Reference [88] Gudivada Venkat
    N., Ramaswamy Srini, and Srinivasan Seshadri. 2018. Data management issues in
    cyber-physical systems. In Transportation Cyber-Physical Systems. 173–200. Navigate
    to [89] Gulli Antonio and Pal Sujit. 2017. Deep Learning with Keras. Packt Publishing
    Ltd. Reference 1Reference 2 [90] Gunes Volkan, Peter Steffen, Givargis Tony, and
    Vahid Frank. 2014. A survey on concepts, applications, and challenges in cyber-physical
    systems. KSII Transactions on Internet and Information Systems (TIIS) 8, 12 (2014),
    4242–4268. Reference [91] Hall Mark, Frank Eibe, Holmes Geoffrey, Pfahringer Bernhard,
    Reutemann Peter, and Witten Ian H.. 2009. The WEKA data mining software: An update.
    ACM SIGKDD Explorations Newsletter 11, 1 (2009), 10–18. Reference 1Reference 2
    [92] Hassan Muneeb Ul, Rehmani Mubashir Husain, and Chen Jinjun. 2019. Differential
    privacy techniques for cyber physical systems: A survey. IEEE Communications Surveys
    & Tutorials 22, 1 (2019), 746–789. Reference [93] Mardiana binti Mohamad Noor
    and Wan Haslina Hassan. 2019. Current research on Internet of Things (IoT) security:
    A survey. Computer Networks 148 (2019), 283–294. Reference 1Reference 2 [94] Hassija
    Vikas, Chamola Vinay, Saxena Vikas, Jain Divyansh, Goyal Pranav, and Sikdar Biplab.
    2019. A survey on IoT security: Application areas, security threats, and solution
    architectures. IEEE Access 7 (2019), 82721–82743. Reference [95] Hazra Abhishek,
    Adhikari Mainak, Amgoth Tarachand, and Srirama Satish Narayana. 2021. A comprehensive
    survey on interoperability for IIoT: Taxonomy, standards, and future directions.
    ACM Computing Surveys (CSUR) 55, 1 (2021), 1–35. Reference [96] Humayed Abdulmalik,
    Lin Jingqiang, Li Fengjun, and Luo Bo. 2017. Cyber-physical systems security–A
    survey. IEEE Internet of Things Journal 4, 6 (2017), 1802–1831. Reference 1Reference
    2 [97] International DNV. 2017. Data Quality Assessment Framework: DNV Recommended
    Practice-RP-0497. DNV. Reference [98] Juxtology. 2018. IoT: Architecture. https://www.m2mology.com/iot-transformation/iot-world-forum/.
    Reference [99] Kafka Apache. [n.d.]. https://kafka.apache.org/. Reference 1Reference
    2 [100] Karkouch Aimad, Mousannif Hajar, Moatassime Hassan Al, and Noel Thomas.
    2016. Data quality in Internet of Things: A state-of-the-art survey. Journal of
    Network and Computer Applications 73 (2016), 57–81. Reference 1Reference 2 [101]
    Kashani Mostafa Haghi, Madanipour Mona, Nikravan Mohammad, Asghari Parvaneh, and
    Mahdipour Ebrahim. 2021. A systematic review of IoT in healthcare: Applications,
    techniques, and trends. Journal of Network and Computer Applications 192 (2021),
    103164. Reference [102] Kayan Hakan, Nunes Matthew, Rana Omer, Burnap Pete, and
    Perera Charith. 2022. Cybersecurity of industrial cyber-physical systems: A review.
    ACM Computing Surveys (CSUR) 54, 11s (2022), 1–35. Reference 1Reference 2 [103]
    Khalid Samina, Khalil Tehmina, and Nasreen Shamila. 2014. A survey of feature
    selection and feature extraction techniques in machine learning. In 2014 Science
    and Information Conference. 372–378. Reference [104] Kitchenham Barbara Ann and
    Charters Stuart. 2007. Guidelines for Performing Systematic Literature Reviews
    in Software Engineering. Technical Report EBSE 2007-001. https://www.elsevier.com/__data/promis_misc/525444systematicreviewsguide.pdf.
    Navigate to [105] Lao Laphou, Li Zecheng, Hou Songlin, Xiao Bin, Guo Songtao,
    and Yang Yuanyuan. 2020. A survey of IoT applications in blockchain systems: Architecture,
    consensus, and traffic modeling. ACM Computing Surveys (CSUR) 53, 1 (2020), 1–32.
    Reference [106] Lee Daniel D. and Seung H. Sebastian. 1999. Learning the parts
    of objects by non-negative matrix factorization. Nature 401, 6755 (1999), 788–791.
    Reference [107] Li Shancang, Xu Li Da, and Zhao Shanshan. 2018. 5G Internet of
    Things: A survey. Journal of Industrial Information Integration 10 (2018), 1–9.
    Reference [108] Li Shancang, Xu Li Da, and Zhao Shanshan. 2015. The Internet of
    Things: A survey. Information Systems Frontiers 17 (2015), 243–259. Reference
    [109] Liao Yongxin, Deschamps Fernando, Loures Eduardo de Freitas Rocha, and Ramos
    Luiz Felipe Pierin. 2017. Past, present and future of industry 4.0-a systematic
    literature review and research agenda proposal. International Journal of Production
    Research 55, 12 (2017), 3609–3629. Reference [110] Liu Caihua, Nitschke Patrick,
    Williams Susan P., and Zowghi Didar. 2020. Data quality and the Internet of Things.
    Computing 102, 2 (2020), 573–599. Navigate to [111] Lu Yang. 2017. Industry 4.0:
    A survey on technologies, applications and open research issues. Journal of Industrial
    Information Integration 6 (2017), 1–10. Reference [112] Lun Yuriy Zacchia, D’Innocenzo
    Alessandro, Smarra Francesco, Malavolta Ivano, and Benedetto Maria Domenica Di.
    2019. State of the art of cyber-physical systems security: An automatic control
    perspective. Journal of Systems and Software 149 (2019), 174–216. Reference [113]
    Luo Yuan, Xiao Ya, Cheng Long, Peng Guojun, and Yao Danfeng. 2021. Deep learning-based
    anomaly detection in cyber-physical systems: Progress and opportunities. ACM Computing
    Surveys (CSUR) 54, 5 (2021), 1–36. Reference 1Reference 2 [114] Maschler Benjamin,
    Vietz Hannes, Jazdi Nasser, and Weyrich Michael. 2020. Continual learning of fault
    prediction for turbofan engines using deep learning with elastic weight consolidation.
    In ETFA’20. 959–966. Reference [115] Matheu Sara N., Hernandez-Ramos Jose L, Skarmeta
    Antonio F., and Baldini Gianmarco. 2020. A survey of cybersecurity certification
    for the Internet of Things. ACM Computing Surveys (CSUR) 53, 6 (2020), 1–36. Reference
    [116] Matlab MathWorks. [n.d.]. https://mathworks.com/products/matlab.html. Reference
    [117] Meneghello Francesca, Calore Matteo, Zucchetto Daniel, Polese Michele, and
    Zanella Andrea. 2019. IoT: Internet of threats? A survey of practical security
    vulnerabilities in real IoT devices. IEEE Internet of Things Journal 6, 5 (2019),
    8182–8201. Reference [118] Meng Xiangrui, Bradley Joseph, Yavuz Burak, Sparks
    Evan, Venkataraman Shivaram, Liu Davies, Freeman Jeremy, Tsai DB, Amde Manish,
    Owen Sean, et al. 2016. Mllib: Machine learning in apache spark. Journal of Machine
    Learning Research 17, 1 (2016), 1235–1241. Reference 1Reference 2 [119] Mitchell
    Robert and Chen Ing-Ray. 2014. A survey of intrusion detection techniques for
    cyber-physical systems. ACM Computing Surveys (CSUR) 46, 4 (2014), 1–29. Reference
    1Reference 2 [120] Muangjaroen Supavit and Yingthawornsuk Thaweesak. 2012. A study
    of noise reduction in speech signal using fir filtering. In International Conference
    on Advances in Electrical and Electronics Engineering. Reference [121] Nelson
    Bruce Jay. 1981. Remote Procedure Call. Carnegie Mellon University. Reference
    [122] Neshenko Nataliia, Bou-Harb Elias, Crichigno Jorge, Kaddoum Georges, and
    Ghani Nasir. 2019. Demystifying IoT security: An exhaustive survey on IoT vulnerabilities
    and a first empirical look on internet-scale IoT exploitations. IEEE Communications
    Surveys & Tutorials 21, 3 (2019), 2702–2733. Reference [123] Ngu Anne H., Gutierrez
    Mario, Metsis Vangelis, Nepal Surya, and Sheng Quan Z.. 2016. IoT middleware:
    A survey on issues and enabling technologies. IEEE Internet of Things Journal
    4, 1 (2016), 1–20. Reference [124] Nguyen Phu H., Ali Shaukat, and Yue Tao. 2017.
    Model-based security engineering for cyber-physical systems: A systematic mapping
    study. Information and Software Technology 83 (2017), 116–135. Reference 1Reference
    2 [125] NiFi Apache. [n.d.]. https://nifi.apache.org/. Reference 1Reference 2
    [126] Nose-Filho K., Lotufo A. D. P., and Minussi C. R.. 2011. Preprocessing data
    for short-term load forecasting with a general regression neural network and a
    moving average filter. In IEEE Trondheim PowerTech. 1–7. Reference [127] Orfanidis
    Sophocles J.. 2016. Introduction to Signal Processing. Pearson Education, Inc.
    Reference [128] Oztemel Ercan and Gursev Samet. 2020. Literature review of Industry
    4.0 and related technologies. Journal of Intelligent Manufacturing 31 (2020),
    127–182. Reference [129] Pedregosa Fabian, Varoquaux Gaël, Gramfort Alexandre,
    Michel Vincent, Thirion Bertrand, Grisel Olivier, Blondel Mathieu, Prettenhofer
    Peter, Weiss Ron, Dubourg Vincent, et al. 2011. Scikit-learn: Machine learning
    in Python. Journal of Machine Learning Research 12 (2011), 2825–2830. Reference
    1Reference 2 [130] Petersen Kai, Vakkalanka Sairam, and Kuzniarz Ludwik. 2015.
    Guidelines for conducting systematic mapping studies in software engineering:
    An update. Information and Software Technology 64 (2015), 1–18. Reference 1Reference
    2Reference 3 [131] Phoenix Apache. [n.d.]. https://phoenix.apache.org/. Reference
    [132] platform The Node.js. [n.d.]. https://nodejs.org/en/. Reference [133] Prapas
    Ioannis, Derakhshan Behrouz, Mahdiraji Alireza Rezaei, and Markl Volker. 2021.
    Continuous training and deployment of deep learning models. Datenbank-Spektrum
    21, 3 (2021), 203–212. Reference [134] Protocol NMEA 0183. [n.d.]. https://www.nmea.org/content/STANDARDS/NMEA_0183_Standard.
    Reference [135] REST. [n.d.]. https://restfulapi.net/. Reference [136] Sanchez
    Manuel, Exposito Ernesto, and Aguilar Jose. 2020. Industry 4.0: Survey from a
    system integration perspective. International Journal of Computer Integrated Manufacturing
    33, 10-11 (2020), 1017–1041. Reference [137] Shah Sajjad Hussain and Yaqoob Ilyas.
    2016. A survey: Internet of Things (IOT) technologies, applications and challenges.
    2016 IEEE Smart Energy Grid Engineering (SEGE) (2016), 381–385. Reference [138]
    Shapere Dudley. 1964. The structure of scientific revolutions. The Philosophical
    Review 73, 3 (1964), 383–394. Reference [139] Shi Weiwei, Zhu Yongxin, Zhang Jinkui,
    Tao Xiang, Sheng Gehao, Lian Yong, Wang Guoxing, and Chen Yufeng. 2015. Improving
    power grid monitoring data quality: An efficient machine learning framework for
    missing data prediction. In HPCC/CSS/ICESS’15. 417–422. Reference [140] Simonoff
    Jeffrey S.. 2012. Smoothing Methods in Statistics. Springer Science & Business
    Media. Reference [141] Siow Eugene, Tiropanis Thanassis, and Hall Wendy. 2018.
    Analytics for the Internet of Things: A survey. ACM Computing Surveys (CSUR) 51,
    4 (2018), 1–36. Reference [142] Spark Apache. [n.d.]. https://spark.apache.org/.
    Reference [143] Talha Muhammad, Kalam Anas Abou El, and Elmarzouqi Nabil. 2019.
    Big data: Trade-off between data quality and data security. Procedia Computer
    Science 151 (2019), 916–922. Reference [144] Teh Hui Yie, Kempa-Liehr Andreas
    W., and Wang Kevin I-Kai. 2020. Sensor data quality: A systematic review. Journal
    of Big Data 7, 1 (2020), 11. Reference 1Reference 2 [145] Tran Nguyen Khoi, Sheng
    Quan Z., Babar Muhammad Ali, and Yao Lina. 2017. Searching the Web OF Things:
    State of the art, challenges, and solutions. ACM Computing Surveys (CSUR) 50,
    4 (2017), 55. Reference [146] Waheed Nazar, He Xiangjian, Ikram Muhammad, Usman
    Muhammad, Hashmi Saad Sajid, and Usman Muhammad. 2020. Security and privacy in
    IoT using machine learning and blockchain: Threats and countermeasures. ACM Computing
    Surveys (CSUR) 53, 6 (2020), 1–37. Reference [147] Wang Richard Y. and Strong
    Diane M.. 1996. Beyond accuracy: What data quality means to data consumers. Journal
    of Management Information Systems 12, 4 (1996), 5–33. Reference [148] Wang Xi
    and Wang Chen. 2019. Time series data cleaning: A survey. IEEE Access 8 (2019),
    1866–1881. Reference 1Reference 2 [149] Wang Y Richard, Guarascio Lisa M., and
    Wang Richard. 1991. Dimensions of data quality: Toward quality data by design.
    (1991). Reference [150] Wohlin Claes. 2014. Guidelines for snowballing in systematic
    literature studies and a replication in software engineering. In EASE’14. 38.
    Navigate to [151] Wolski Rich, Krintz Chandra, Bakir Fatih, George Gareth, and
    Lin Wei-Tsung. 2019. CSPOT: Portable, multi-scale functions-as-a-service for IoT.
    In SEC’19. 236–249. Reference 1Reference 2 [152] Xiong Hui, Pandey Gaurav, Steinbach
    Michael, and Kumar Vipin. 2006. Enhancing data analysis with noise removal. IEEE
    Transactions on Knowledge and Data Engineering 18, 3 (2006), 304–319. Reference
    [153] Xu Hansong, Yu Wei, Griffith David, and Golmie Nada. 2018. A survey on industrial
    Internet of Things: A cyber-physical systems perspective. IEEE Access 6 (2018),
    78238–78259. Reference 1Reference 2 [154] Xu Li Da and Duan Lian. 2019. Big data
    for cyber physical systems in industry 4.0: A survey. Enterprise Information Systems
    13, 2 (2019), 148–169. Reference [155] Xu Li Da, Xu Eric L., and Li Ling. 2018.
    Industry 4.0: state of the art and future trends. International Journal of Production
    Research 56, 8 (2018), 2941–2962. Reference [156] Zhang Lina, Jeong Dongwon, and
    Lee Sukhoon. 2021. Data quality management in the Internet of Things. Sensors
    21, 17 (2021), 5834. Reference 1Reference 2Reference 3 [157] Zheng Ting, Ardolino
    Marco, Bacchetti Andrea, and Perona Marco. 2021. The applications of Industry
    4.0 technologies in manufacturing context: A systematic literature review. International
    Journal of Production Research 59, 6 (2021), 1922–1954. Reference [158] Zhu Qingyi,
    Loke Seng W., Trujillo-Rasua Rolando, Jiang Frank, and Xiang Yong. 2019. Applications
    of distributed ledger technologies to the internet of things: A survey. ACM Computing
    Surveys (CSUR) 52, 6 (2019), 1–34. Reference Cited By View all Ravindra Krishna
    Chandar V, Baskaran P, Mohanraj G and Karthikeyan D. (2024). Deep iterative fuzzy
    pooling in unmanned robotics and autonomous systems for Cyber-Physical systems.
    Journal of Intelligent & Fuzzy Systems: Applications in Engineering and Technology.
    46:2. (4621-4639). Online publication date: 1-Jan-2024. https://doi.org/10.3233/JIFS-235721
    Tverdal S, Goknil A, Nguyen P, Husom E, Sen S, Ruh J and Flamigni F. Edge-based
    Data Profiling and Repair as a Service for IoT. Proceedings of the 13th International
    Conference on the Internet of Things. (17-24). https://doi.org/10.1145/3627050.3627065
    Index Terms A Systematic Review of Data Quality in CPS and IoT for Industry 4.0
    Computer systems organization Embedded and cyber-physical systems Embedded systems
    Embedded software Sensor networks Sensors and actuators Information systems Data
    management systems Data structures Data layout Data compression Data encryption
    Database administration Database utilities and tools Information storage systems
    Storage management Information lifecycle management Information systems applications
    Computing platforms Decision support systems Data analytics Online analytical
    processing Process control systems Software and its engineering Software organization
    and properties Software system structures Embedded software Software architectures
    Layered systems Recommendations Data quality and the Internet of Things Abstract
    The Internet of Things (IoT) is driving technological change and the development
    of new products and services that rely heavily on the quality of the data collected
    by IoT devices. There is a large body of research on data quality management and
    ... Read More A Review on Data Cleansing Methods for Big Data Abstract Massive
    amounts of data are available for the organization which will influence their
    business decision. Data collected from the various resources are dirty and this
    will affect the accuracy of prediction result. Data cleansing offers a better
    ... Read More Towards Data Quality into the Data Warehouse Development DASC ''11:
    Proceedings of the 2011 IEEE Ninth International Conference on Dependable, Autonomic
    and Secure Computing Commonly, DW development methodologies, paying little attention
    to the problem of data quality and completeness. One of the common mistakes made
    during the planning of a data warehousing project is to assume that data quality
    will be addressed during ... Read More Comments 150+ References View Issue’s Table
    of Contents Footer Categories Journals Magazines Books Proceedings SIGs Conferences
    Collections People About About ACM Digital Library ACM Digital Library Board Subscription
    Information Author Guidelines Using ACM Digital Library All Holdings within the
    ACM Digital Library ACM Computing Classification System Digital Library Accessibility
    Join Join ACM Join SIGs Subscribe to Publications Institutions and Libraries Connect
    Contact Facebook Twitter Linkedin Feedback Bug Report The ACM Digital Library
    is published by the Association for Computing Machinery. Copyright © 2024 ACM,
    Inc. Terms of Usage Privacy Policy Code of Ethics'
  inline_citation: '>'
  journal: ACM computing surveys
  limitations: '>'
  pdf_link: null
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: A Systematic Review of Data Quality in CPS and IoT for Industry 4.0
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.5194/bg-2023-110
  analysis: '>'
  authors:
  - Martin Jung
  - Jacob A. Nelson
  - Mirco Migliavacca
  - Tarek S. El‐Madany
  - Dario Papale
  - Markus Reichstein
  - Sophia Walther
  - Thomas Wutzler
  citation_count: 1
  full_citation: '>'
  full_text: '>

    Biogeosciences ARTICLES & PREPRINTS SUBMISSION POLICIES PEER REVIEW EDITORIAL
    BOARD ABOUT EGU PUBLICATIONS   Preprint   Preprints Preprint bg-2023-110  https://doi.org/10.5194/bg-2023-110
    © Author(s) 2023. This work is distributed under the Creative Commons Attribution
    4.0 License. Abstract Discussion Metrics 16 Aug 2023 Status: a revised version
    of this preprint was accepted for the journal BG and is expected to appear here
    in due course. Technical Note: Flagging inconsistencies in flux tower data Martin
    Jung, Jacob Nelson, Mirco Migliavacca, Tarek El-Madany, Dario Papale, Markus Reichstein,
    Sophia Walther, and Thomas Wutzler Abstract. Global collections of synthesized
    flux tower data such as FLUXNET have accelerated scientific progress beyond the
    eddy covariance community. However, remaining data issues in FLUXNET data pose
    challenges for users, particularly for multi-site synthesis and modeling activities.
    Here we present complementary consistency flags (C2F) for flux tower data, which
    rely on multiple indications of inconsistency among variables, along with a methodology
    to detect discontinuities in time series. The C2F relates to carbon and energy
    fluxes as well as to core meteorological variables, and consists of: (1) flags
    for daily data values, (2) flags for entire site variables, (3) flags at time
    stamps that mark large discontinuities in the time series. The flagging is primarily
    based on combining outlier scores from a set of predefined relationships among
    variables. The methodology to detect break points in the time series is based
    on a non-parametric test for the difference of distributions of model residuals.
    Applying C2F to the FLUXNET 2015 dataset reveals that: (1) Among the considered
    variables, gross primary productivity and ecosystem respiration data were flagged
    most frequently, in particular during rain pulses under dry and hot conditions.
    This information is useful for modelling and analysing ecohydrological responses.
    (2) there are elevated flagging frequencies for radiation variables (shortwave,
    photosynthetically active, and net). This information can improve the interpretation
    and modelling of ecosystem fluxes with respect to issues in the driver. (3) The
    majority of long-term sites show temporal discontinuities in the time series of
    latent energy, net ecosystem exchange, and radiation variables. This should be
    useful for carefully assessing the results on interannual variations and trends
    of ecosystem fluxes. The C2F methodology is flexible for customizing, and allows
    for varying the desired strictness of consistency. We discuss the limitations
    of the approach that can present starting points for future improvements. How
    to cite. Jung, M., Nelson, J., Migliavacca, M., El-Madany, T., Papale, D., Reichstein,
    M., Walther, S., and Wutzler, T.: Technical Note: Flagging inconsistencies in
    flux tower data, Biogeosciences Discuss. [preprint], https://doi.org/10.5194/bg-2023-110,
    in review, 2023. Received: 13 Jul 2023 – Discussion started: 16 Aug 2023   Download
    Preprint (4059 KB) Metadata XML BibTeX EndNote Short summary We present a methodology
    to detect inconsistencies in perhaps the most important data source for... Read
    more Share Altmetrics Biogeosciences An interactive open-access journal of the
    European Geosciences Union All site content, except where otherwise noted, is
    licensed under the Creative Commons Attribution 4.0 License. Contact | Imprint
    | Data protection'
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: null
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: 'Technical Note: Flagging inconsistencies in flux tower data'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1155/2021/9178461
  analysis: '>'
  authors:
  - Mohamed Jaward Bah
  - Hongzhi Wang
  - Lianfeng Zhao
  - Zhang Ji
  - Jie Xiao
  citation_count: 1
  full_citation: '>'
  full_text: '>

    Journals Publish with us Publishing partnerships About us Blog Complexity Journal
    overview For authors For reviewers For editors Table of Contents Special Issues
    Complexity/ 2021/ Article On this page Abstract Introduction Related Work Preliminaries
    Results Conclusion Data Availability Disclosure Conflicts of Interest Acknowledgments
    References Copyright Related Articles Special Issue Collective Behavior Analysis
    and Graph Mining in Social Networks 2021 View this Special Issue Research Article
    | Open Access Volume 2021 | Article ID 9178461 | https://doi.org/10.1155/2021/9178461
    Show citation EMM-CLODS: An Effective Microcluster and Minimal Pruning CLustering-Based
    Technique for Detecting Outliers in Data Streams Mohamed Jaward Bah ,1Hongzhi
    Wang ,2Li-Hui Zhao ,3Ji Zhang ,4and Jie Xiao5 Show more Academic Editor: Fei Xiong
    Received 07 Jul 2021 Revised 10 Aug 2021 Accepted 23 Aug 2021 Published 13 Sept
    2021 Abstract Detecting outliers in data streams is a challenging problem since,
    in a data stream scenario, scanning the data multiple times is unfeasible, and
    the incoming streaming data keep evolving. Over the years, a common approach to
    outlier detection is using clustering-based methods, but these methods have inherent
    challenges and drawbacks. These include to effectively cluster sparse data points
    which has to do with the quality of clustering methods, dealing with continuous
    fast-incoming data streams, high memory and time consumption, and lack of high
    outlier detection accuracy. This paper aims at proposing an effective clustering-based
    approach to detect outliers in evolving data streams. We propose a new method
    called Effective Microcluster and Minimal pruning CLustering-based method for
    Outlier detection in Data Streams (EMM-CLODS). It is a clustering-based outlier
    detection approach that detects outliers in evolving data streams by first applying
    microclustering technique to cluster dense data points and effectively handle
    objects within a sliding window according to the relevance of their status to
    their respective neighbors or position. The analysis from our experimental studies
    on both synthetic and real-world datasets shows that the technique performs well
    with minimal memory and time consumption when compared to the other baseline algorithms,
    making it a very promising technique in dealing with outlier detection problems
    in data streams. 1. Introduction In the current era, the need to detect abnormal
    behavior to reveal salient facts, observations, and realizing accurate predictions
    of data is extremely significant. Detecting outliers is one such important data
    mining task that aims at detecting objects that deviate from the expected pattern
    of the normal data. The process of detecting outliers is challenging due to the
    advancement in the digital age. For instance, with the revolution of data from
    traditional batch data, we have witnessed the advent of a large volume of data
    that is generated continuously at high speed and dynamically. These kinds of data
    are known as data streams and are generated by many applications [ 1– 3]. In contrast
    to traditional datasets, because of the nature of the data, it is not feasible
    to save in memory the whole data stream or run the data through multiple scans.
    This is because the data are massive and unbounded, have a varying rate, and continue
    to evolve. A significant number of approaches have been proposed to detect outliers
    in data streams [ 8– 11]. Among the different categories of proposed outlier detection
    methods, clustering-based approaches have shown to be popular in static data but
    yet one of the most challenging to adopt for outlier detection tasks in data streams.
    Although they have shown to be efficient for some outlier detection tasks, they
    lead to low computational cost and high scalability in high-dimensional data [
    5, 12]. However, most of the prevailing data stream clustering approaches suffer
    from different drawbacks. They can be improved when we consider the spectrum of
    effectiveness and efficiency, for instance, to deal with the continuous fast-incoming
    data streams, higher computational demand in terms of its memory and time, the
    cluster quality, and the outlier detection rate. The process of clustering and
    detecting outliers in data streams is complicating since the clustering techniques
    often involve several parameters and operate in low- and high-dimensional spaces,
    constrained with excessive distance-based computation of object neighbors, noise,
    and so on. For this reason, clustering-based approach has varying performance
    for different application domains and data types. It is therefore imperative to
    design an effective method that will holistically address the issues and produce
    stable performance in detecting the outliers. In spite of clustering’s occasional
    challenges and caveats, it is still another good alternative and promising solution
    for detecting outliers. The advantage of clustering is that it allows for the
    use of limited amounts of time and memory, which is necessary when processing
    data streams. This is because clustering is the act of grouping elements using
    sets that provide the capability of grouping items that are similar to each other
    that curbs the need of redundant processing and over calculations. Clustering
    methods offer online and offline process support, which is usually used for data
    stream applications and is also flexible in adapting to the evolving nature of
    the data. In this paper, we propose a new microclustering and minimal pruning
    clustering-based unsupervised outlier detection scheme to detect outliers in data
    streams while simultaneously addressing the mentioned challenges. The proposed
    approach involves different stages to adapt to the dynamic changes of data distribution
    that aims at eliminating the limitations of previously proposed methods. The newly
    propose method is called Effective Microcluster and Minimal pruning CLustering-based
    method for Outlier detection in Data Streams (EMM-CLODS), which is a clustering-based
    outlier detection approach. We call it CLODS for short and use this abbreviation
    instead of EMM-CLODS throughout the paper. It detects outliers from evolving data
    streams by first applying the microclustering technique to cluster dense data
    points. It then effectively handles objects within a sliding window according
    to the relevance of their status to their respective neighbors or position through
    minimal pruning technique. In our data stream scenario, where the size of the
    dataset is potentially boundless, we process the data over a fixed period to reduce
    the complexity of the outlier detection task. When new incoming data points arrive,
    the microcluster technique is applied, which identifies objects that are more
    analogous to each other and that meet the fundamental prerequisite of the clustering
    methods. The methods scan the data once and adapt to the time changes as the streaming
    data evolve. It constantly and periodically updates incoming data, and the results
    are obtained. Finally, the CLODS reports key insights from these results to determine
    whether they are outliers or inliers. The advantages of the technique are that
    it can effectively save time and memory, thanks to the microclustering technique
    and minimal pruning. It removes the need to compute every data point in and out
    of the cluster and store every data point in memory. In summary, the major contributions
    of this work are as follows: (i) We propose the CLODS, a new technique based on
    microclustering and minimal pruning of data points outside the clusters, to solve
    the problem of detecting outliers in continuous evolving data streams. (ii) We
    propose the concept of priority handling of evolving objects outside the clusters
    to minimize the memory and time consumption during the updating phase according
    to the relevance of their status to their respective neighbors or position. (iii)
    Our propose method can effectively optimize and solve the problems and challenges
    of time and memory constraints while maintaining its accuracy for detecting outliers
    in data streams. (iv) We demonstrate through an extensive experiment on some benchmark
    datasets the effectiveness of our method against some other methods used for the
    outlier detection process in data streams. The rest of the paper is organized
    as follows: in Sections 2 and 3, we present the related work and problem formulation,
    respectively. In Section 4, we present in details the method we propose. In Section
    5, we present the experimental studies including the results and discussion. Finally,
    in Section 6, we present the conclusion of the paper.    Figure 1  Streaming data.
    2. Related Work Detecting outliers is a well-known domain in the data mining community,
    and it has been applied in a wide range of application areas [ 13, 14] and other
    domains such as community detection [ 15, 16]. It has been studied extensively
    [ 17– 19]. In a recent survey [ 11], we classified outlier detection methods into
    diverse categories and have proposed effective methods among these categories
    to detect outliers in data streams [ 8, 11]. In progress to this study series,
    the clustering-based category has open research gaps and challenges. Proposing
    solutions and improving these methods will greatly contribute to the general body
    of outlier detection methods. The clustering approach is an unsupervised data
    mining method that groups similar dense data points. Several methods using clustering
    techniques and its variant approaches have been proposed for outlier detection
    tasks. However, some earlier proposed clustering methods suffer from drawbacks
    such as the buffering of all data points in memory for future handling or, in
    some cases, not considering data points that often leads to poor clustering. There
    are a significant number of these methods concentrated on both static data and
    streaming data types [ 20, 21]. These methods mostly adopt the two-phase scheme:
    the online and offline phase. The majority of the earlier proposed method for
    stream data clustering deals with static clustering that is in a continuous form.
    One shortcoming of this kind of approach is that recent and outdated data are
    handled the same way. Several moving window models are proposed to solve this
    issue. For evolving data streams, Toshniwal and Yokita et al. [ 20] proposed a
    framework using simple k-means and the attribute weight to detect outliers, while
    Cao et al. [ 22] proposed a technique related to density-based clustering for
    evolving data streams. In their method, the incoming data are selected depending
    on the distance between their centers to either the outlier or potential core
    microcluster. In this case, with an increasing number of outliers, the clustering
    accuracy becomes a problem. Therefore, Liu et al. [ 23] proposed a new technique
    to address this drawback. Although they tried to address the issue, it comes at
    a high computational cost. To salvage the computational cost and improve the clustering
    and outlier detection accuracy, Kumar and Sharma [ 24] applied a technique that
    extracts the boundary points in the overlapped microclusters. Many other clustering
    techniques have been proposed for outlier detection processes, such as density-based
    microclustering [ 22, 25], grid-based clustering [ 6, 26], and partitioning algorithm
    for data streams [ 12, 21]. However, since this is a short paper, Table 1 briefly
    outlines some of these techniques in comparison to our method in terms of the
    summarization technique, evolving data model and outlier detection method. Table
    1  Some key clustering algorithms. Remarkably, from Table 1, no two methods share
    the same approach. Our work is the first to use microclustering in the sliding
    window model using outlier microcluster to handle continuously evolving objects
    with changing features. For a more comprehensive related work to clustering techniques
    for outlier detection, we recommend Wang et al. [ 11] survey paper. 3. Preliminaries
    and Problem Formulation 3.1. Notations and Definitions The key symbols used in
    this paper include but not limited to the following in Table 2. Table 2  List
    of symbols with their interpretations. 3.2. Definition of Key Terms 3.2.1. Outliers
    For a dataset of points, . Whenever the data point or an entire set of data points
    deviates drastically from these other sets, these points are considered outliers.
    3.2.2. Neighbor In the case of two data points and , a data point is considered
    a neighbor of if the distance between the two does not exceed the distance threshold
    value . In other words, if is not further than from , then it is a neighbor of
    . A data point cannot be a neighbor of itself. 3.2.3. Sliding Window In sliding
    window, the time-based window and the count-based window are two types of window
    models commonly used for data streams. The former takes into consideration the
    data points within the time interval of two identify data points, for instance,
    at point and , with and . The latter thus considers the count of the data points
    within a specified window size. 3.2.4. Microclusters A microcluster is formed
    when a data point has a radius of from the center, and in a microcluster, the
    distance between two data points, let us assume and , should not exceed . The
    function of the microcluster in our technique is as follows: we applied the microclusters
    to minimize the range queries and minimize the distance-based computations. The
    microclusters eliminate the need for excessive range queries by storing the neighbor’s
    data points in the microclusters. This, therefore, improves the underlying evaluation
    metrics: the memory and time consumption. The microclusters adopted in the proposed
    methods give the advantage of eliminating the need for range queries and in curbing
    the distance computations. In addition to only storing crucial inliers in memory,
    the microclusters also improve the memory constraints, since a single microcluster
    has the ability to obtain the neighborhood information of each object in the same
    cluster. In Figure 1, we can see that and , where is the current window and is
    the expired window. The fast-incoming data points from 1 to 23 are the data streams.
    By definition, the data stream is an unlimited number of data points within a
    specific timestamp or unbounded sequence. That is, the data stream , with t = time
    and , . Each within its window could have a neighbor or not, but it cannot be
    a neighbor on its own. The neighbor of any particular data point must not exceed
    the required distance threshold , from each other. For instance, in Figure 1,
    are neighbors of 3, while are neighbors of 19. The neighbors play a crucial role
    in the overall outlier detection process; therefore, we pay special attention
    to them.    Figure 2  The framework of CLODS In , or when the window slides, determining
    whether a data point is an outlier or inlier can create additional constraints
    due to the evolving nature of the data points. Some neighbors will expire, such
    as among , and become obsolete when the window slides. In the different window
    stages, the question of how to perform clustering, how to use minimal pruning
    to get the most significant data points, how to deal with incoming and expired
    , and what kind of clustering technique to apply comes up, and also, what requirements
    should the clustering technique meet to ensure that (1) the clusters capture more
    and (2) the inliers or outliers are detected correctly and computed with the lowest
    computational cost possible. 3.3. Problem Formulation Problem statement: the major
    goal of this paper is to present an improved solution to address the problem of
    effectively clustering and detecting outliers in fast-evolving data streams. For
    new data streams arriving continuously, with dimensionality at time , and with
    evolving feature changes as the data speed increases, we need to design a robust
    approach that will deal with the evolving data streams by clustering incoming
    data streams effectively and simultaneously detect all outliers in the shortest
    conceivable time, with low memory usage, while maintaining high detection accuracy.
    Also, we handle data points outside the clusters while dealing with the fading
    of old clusters, new and expired data points, and detecting the outliers. The
    key challenge is that the actively evolving data point position continues to change
    due to either the window slides or the arrival and expiration of some data points.
    This ultimately makes it complicating in addressing the overall problem. It will
    be a challenging task to process and remove data points one at a time as they
    arrive over the stream. It will incur a lot of time. In addition, managing memory
    space presents another challenge since it is not possible to predict how many
    data points arrive and expire a priori. It becomes challenging to cluster essential
    data points and dynamically allocate space for the growing number of unknown data
    points that arrive and expire. This brings us to the essential problem statement
    and question we address in this paper, how do we capture the data points that
    deviate from the others in streaming data which evolve as time progresses with
    these additional constraints: (i) The data point features might change over time.
    (ii) Prior unseen data point features might arrive over time. 4. The Proposed
    Methodology 4.1. Fundamentals of the Proposed Method As data originate from their
    source in the form of fast continuous evolving data streams, they become challenging
    to cluster data points and effectively detect the outliers, as explained in the
    problem statement. There is a need for special attention on the clustering method
    and in handling both the inliers and outliers in this scenario. To do this, we
    propose a new framework, which involves different stages in order to detect the
    outliers efficiently while maintaining high accuracy. The newly proposed method
    called Effective Microcluster and Minimal pruning CLustering-based method for
    Outlier detection in Data Streams (EMM-CLODS) is a kind of clustering-based outlier
    detection approach that detects outliers in evolving data streams using microcluster
    and minimal pruning. This is done by first applying a microclustering technique
    to cluster dense data points and effectively handle the data points according
    to the relevance of their status to their respective neighbors or position in
    the window. We adopt the sliding window model, and within this model, the microclustering
    technique helps to cluster dense data points quickly and eliminate the need for
    a range query search. For the data points outside the clusters, an approximate
    probing is implemented by excluding a set of inliers whose significance in the
    computation is trivial in order to reduce the computation demand. The CLODS makes
    use of both clustering and approximate probing of data points within the adopted
    sliding window model and minimal pruning of data points outside the clusters.
    It simultaneously discovers the outliers and deals with potential outliers outside
    the clusters, even when they continuously evolve as the data point changes state.
    In contrast to other conventional clustering-based approaches, it does not limit
    itself to detecting outliers in static data [ 2, 11, 27], and for those that support
    data streams, the clustering procedure is different [ 12, 20, 28, 29], or they
    are not clustering-based approaches [ 4, 8, 30]. Those with similar clustering
    techniques to ours use a different scheme to deal with data points within the
    window or adopt different window models [ 12, 27, 29]. Furthermore, the handling
    procedure of data points outside the microclusters is different. Unlike some of
    these methods [ 12, 20, 27, 28] that deal with every data point outside the microclusters
    equally, we focus especially on the relevance of data points with respect to its
    neighbors and position to determine its overall role in the outlier detection
    process. This is to ensure we identify potential outliers rather than data points
    that might be falsely labeled as outliers. This consequently saves time and memory
    constraints without a performance decline. 4.2. The Proposed Framework Figure
    2 shows an illustrative representation of the proposed framework. At the onset,
    objects in the form of data streams arrive continuously and in an unprecedented
    manner. We first filter the data through data processing to determine its characteristics.
    Then, we process the preprocessed data in the sliding window model. During a specified
    period in the sliding window, we apply probing and clustering process together
    with pruning the data points outside the clusters and detect the outliers. During
    this phase, additional processing such as handling of crucial inliers and potential
    outliers, and handling of both active and expired data points as the window slides
    is done. In the final stage, the detected outliers are then reported.    Figure
    3  The different phases of processing the outliers in the sliding window. Algorithm
    1 gives the overall framework of CLODS, with line 3–5 depicting the processes.
    In Algorithms 2–4, details of algorithmic process are given to understand the
    whole CLODS algorithm. In Algorithm 5, we extend details of the different steps
    in Algorithm 1. In the first part, we perform preprocessing. The preprocessed
    data stream is then computed in the next stage. In processing data points within
    the window, in line 4 we determine whether they belong to a cluster. If not in
    a cluster, the relevance of their status with respect to the other members is
    checked in line 9. The data points outside the clusters and that are not relevant
    to their respective members can be applied to the function in the last stage and
    reported as an outlier as can be seen in line 11. In Algorithm 2, the processing
    of new data points in the new sliding window is shown. We first discover the cluster
    and if there is a data point within the cluster, we add the new data point or
    else initiate a new cluster accordingly (line 2–6), while in Algorithm 3, it shows
    the processing of the expired data. Similarly, as in 3, we first discover the
    cluster and if a data point is found in the cluster, we ensure that we check the
    relevance status to the other data points before we add it into the cluster (line
    4-5). If not, we try to remove it (line 7). Lastly in Algorithm 4, we process
    and report the detected outliers. We first initialize the count (line 1), and
    if is not in any cluster and less number of neighbors to form a cluster, it is
    returned as an outlier. If it has already expired, it is then removed from data
    points outside the microclusters. Input: Preprocess Data Stream , Data point ,
    Parameters: {distance-threshold , nearest-neighbor count , sliding size , Window
    Size .} Output: Outliers in sliding window (1) Procedure: (2) While the window
    slide or in ⊳ between period to when arrives (3) Deal with data within (4) Deal
    with new and (5) Deal with expired and . (6) Report outliers, Algorithm 1   The
    CLODS algorithm. (1) for in new slide, S do (2) c = discoverCluster (3) if in
    C then (4) c.add () (5) else (6) InitiateNewCluster () (7) else if (8) end for
    Algorithm 2  Process new data in the new slide window. (1) for in expired slide,
    S do (2) c = discoverCluster (3) if in C then (4) CheckRelevance () (5) c.add
    () (6) else (7) remove () (8) end If Algorithm 3  Process expired data point when
    slide expires. (1) Initiate outliers = [ ] (2) Perform all functions (3) for in
    , do (4) if cannot form a new cluster (5) add.Outlier () (6) else (7) Processfunctions
    (8) end if Algorithm 4  Process outlier . Input: Data Stream , Data point , Parameters:
    {distance-threshold , nearest-neighbor count , sliding size , window size .} Output:
    Outliers (1) Procedure: ⊳ Preprocessing (2) Perform Preprocessing ⊳ (3) for for
    each of preprocessed data in do (4) DiscoverInClusters (5) If neighbor then (6)
    InCluster Algorithm 5   Overall procedure of the CLODS. 4.3. The Data Stream Stage
    In a data stream model, the input data are not accessible through random disk
    or memory, such as in the case of static data or batch data in standard databases,
    but rather arrive in the form of one or more continuous data streams. A data stream
    is an unlimited number of sequence data points , within a specific timestamp or
    unbounded sequence with data points, . They are infinite series of data points,
    , observed at a particular time . The streaming data have the following characteristics:
    (i) The data points of streaming data arrive incrementally in real-time. The streaming
    data are active since all inbound objects/items trigger actions on the data rather
    than being invited to participate. (ii) The system has no control over the order
    or sequence in which the items of the streaming data arrive. (iii) The streaming
    data have the possibility of unbounded numbers of data points. The problem of
    detecting or mining outliers in such data with the abovementioned characteristics
    brings a number of significant implications. Firstly, to ensure that the results
    are continuously up-to-date, it is essential to analyze the incoming data within
    the shortest time and minimal memory usage. In the framework in Figure 3, the
    continuous infinite series of data points observed at a particular time is fed
    to the next stage. 4.4. Data Preprocessing Stage As the incoming unbounded sequence
    of data arrives, it is impossible to store the entire data stream. Besides, to
    apply the clustering technique without taking note of the characteristics of the
    data makes the overall process more tedious. Therefore, we initially did some
    preprocessing based on the nature of the data to avoid assumptions about having
    clean and well-structured data and to tailor the data for our propose model. For
    instance, real-world datasets are highly susceptible to missing and inconsistent
    data. Such datasets may give rise to data quality issues, which in turn affects
    the overall result. During the data preprocessing and wrangling phase, we deal
    with the missing data and inconsistent data. Although outliers sometimes can influence
    the quality of the data, in this work we entirely avoid dealing with outliers
    since our primary goal is to detect outliers. For the missing data, we ensure
    that we ignore, fill manually, and compute values. For inconsistent data, we normalize
    the necessary datasets. 4.5. Sliding Window-Based Outlier Detection Stage In this
    phase, we manage the evolving data streams; that is, we implement the CLODS and
    detect data points that deviate from their expected normal behavior when the window
    slides and expires, also when the data points will expire. We notice that it is
    not feasible to perform clustering on data streams during the all probable time.
    We handle the data points at different time windows. The process of exploring
    the evolving data stream during the different time windows provides the users
    with additional insights into the evolving nature and performance of the clusters.
    In terms of processing evolving data streams, different algorithms have adopted
    different window models. Some existing window models include the damped window
    model also known as the fading window model, the landmark window model, the tilted-time
    window model, and the sliding window model. In this paper, we use the sliding
    window model, in which the data are processed before the end of the streaming
    data window. This is as opposed to the landmark window model, which is adopted
    for cases where we want to mine the whole data stream history. It is suitable
    for static data settings. In the sliding window, the streaming data are considered
    from the current time to a certain range in its history. The key idea in the sliding
    window is to do exhaustive analysis of the most up-to-date data items and summarized
    the outdated items. As can be seen in Figure 3, in the second phase, we apply
    the clustering of the data stream in the sliding window model where data points
    expire as the window slides. Moreover, with an increasing time , each data points’
    weight declines as it reaches the expiration point. In setting the window size
    for a distribution that fluctuates dynamically, we increased and set the window
    size large enough to minimize the effect caused by the dynamic change of the data.
    Consequently, this results in increased time usage, which undermines the performance
    of real-time computation. Eventually, it creates a challenge to find a balance
    between these two underlying issues. In Figure 3, as the time increases within
    the time frame, some data points fade out and some data points change state depending
    on the window slide. Some evolving data points expire, some clusters dissolve,
    and new ones are created, and some data points might be classified wrongly as
    an outlier. Therefore, in designing CLODS, we consider the following prerequisite:
    (i) Firstly, we consider the status of the data points, i.e., whether they are
    in a cluster or not and whether data points outside the cluster can be viewed
    as an inlier or outlier. (ii) Secondly, we consider the distance between the clusters
    and data points outside the clusters, whether they are far or close to the clusters,
    and whether they can be viewed as an outlier or inlier. (iii) Thirdly, we consider
    whether the data points share a relationship with few other data points that form
    a cluster, and also, how to handle both the data points within and out of the
    clusters to detect the outliers accurately. (iv) Finally, we consider the characteristics
    of the summary information, and at what instance we should store or discard the
    summary information, and what to do with expired data points. 4.6. CLODS Clustering
    Phase For a data stream with a set of continuous multidimensional data points
    , arriving at different period , we considered a set of active data points during
    the period , which are the most recent n data points at the time in the sliding
    window. During the active period, we employ the microcluster concept, which is
    a fast-efficient method for clustering objects within the sliding window. We applied
    the idea of triangular inequality in metric space [ 30, 31], to guarantee the
    data points’ distance between each other in the microclusters is less than the
    distance threshold . Thus, confirming that every data point is labeled as an inlier
    within the microcluster. Among the labeled inliers, we store in memory only crucial
    inliers to avoid memory congestion, and it is impossible to store every object
    in memory. We stored each newly arrived object in a fix size buffer. If the buffer
    is full, we consider each data point in it as an inlier or outlier, depending
    on the weight of the objects in relation to its distance to the other objects.
    The objects that are labeled as outliers are deleted in memory, while all newly
    incoming labeled inliers are maintained in the updated list. The different actions
    taken depend on the status of the data points in the different phases. Figure
    3 shows the different stages in the window model, which is divided into three
    partitions with the x-axis displaying the arrival time of the data points, while
    the ordinate depicts the number of data points with radius . In the first partition,
    during the current window model space ( to ), we have a set of evolving data streams
    with fixed radius , and a neighbor count threshold from time interval . In this
    partition, for , the microcluster technique is applied to cluster data points
    for the objects in the window. These microclusters are data points within the
    radius of from the center and are not greater than the distance between the two
    data points. The window contains four microclusters, to with radius . The data
    points that are not within the microclusters are probable outliers depending on
    their status in relation to the other neighboring data points. To determine whether
    the probable data points will be labeled as an outlier or not, we consider both
    its ensuing and prior neighbors and, furthermore, its relative strength to its
    neighbors. Also, to consider which objects are stored in memory, we used a similar
    concept as in previous work [ 8] by storing the data points outside the microcluster
    in temporary memory while applying the minimal pruning to minimize the computational
    cost and demand. From Figure 3, the red marked data points show the outliers while
    the other data points, where , are marked in green. In the next phase, some data
    points change state due to the sliding of the window, the appearance of new data
    points, and the expiration of some data points. These new changes create new challenges
    for detecting the outliers smoothly as compared to the previous phase. In this
    case, we have three sliding windows. In the first window, we have a single microcluster,
    outliers, and a full cluster that has some data points that their status will
    be potentially affected during the next slide. In the next window, at the onset,
    although two objects have expired, it does not dissolve the microcluster since
    it has points. However, in the final window, the microcluster dissolves, which
    prompts the remaining data points to become outliers. When new data points arrive,
    they are added to their probable neighboring microclusters, provided it is not
    greater than the distance threshold . Otherwise, it is added to the neighboring
    outlier cluster with more space. If none of the conditions exist, then a new marked
    outlier cluster is initialized. In the final stage, the figure vividly shows the
    status of the different data points. The green data points indicate the inliers,
    yellow expired data points, the orange points are those that have the propensity
    to change state, and the red are the detected outliers. In terms of the memory
    usage, owing to the fast response and limited memory requirements in these kinds
    of environments, it is not practical to store the majority of the data, and it
    is impossible to store all the data in memory. Therefore, to salvage the situation,
    we minimize the memory consumption and stored relevant data points that aid the
    overall clustering and outlier detection process. Furthermore, we minimized the
    number of rearranged microclusters as the update in memory is done. As the continuous
    incoming data arrive, we first determined whether it is in memory or not. If not,
    it is added to the temporary memory, and then an initialization process is done.
    The key inliers are temporarily stored in memory, and as the data evolve due to
    changes in window slides, an update is done with new data points replacing the
    older ones. We calculated the number of inliers, and all expired data points are
    deleted from memory to free the memory space. Finally, summary statistical information
    is obtained, and the outliers are then reported. 4.7. Outlier Detection Stage
    The outlier detection process involves various phases. At the onset, we observe
    the potential outliers through the clusters. By definition, an outlier in an evolving
    data stream is a data point within the computational time frame that deviates
    from the clusters and lies beyond the distance threshold R with fewer than k neighbors
    in the dataset. In every window, data points that do not meet the deviation and
    threshold criteria are labeled as outliers, while the others are labeled as inliers.
    All potential outliers are initialized to one and stored in temporary memory.
    As new potential outliers accumulate, the longstanding vivid outliers stored in
    the outlier list are deleted from memory to free up space after processing. The
    detected outliers are reported, and the outlier list is updated. 5. Experiments
    and Results In this section, we describe the experimental settings including the
    datasets, parameter settings, evaluation metrics, and the baseline methods and
    discuss the performance of in comparison to the other models. 5.1. Experimental
    Setup 5.1.1. Environment We did our experiment using Java to design the source
    code and ran it on Eclipse Java EE IDE on a PC running Windows 10 Operating System
    with 3.20 GHz X4 CPU, 8 GB of RAM, and Disk Space of 230 GB. One of the baseline
    algorithms is from previous work [ 8], and the other was prepared by Tran et al.
    [ 32]. The source code of some baseline methods and all related datasets can be
    found on the online repository [ 32]. 5.1.2. Datasets We use similar benchmark
    datasets that have been adopted in some previous studies [ 8, 32]. As shown in
    Table 3, we use three real-world datasets and one synthetic dataset that are openly
    accessible. The first dataset is the Forest Covertype (FC) [ 7, 32] which is openly
    available and can be found from the UCI Machine Learning Repository and has 581,012
    records with a high-dimensional range of 1–55 attributes. The dataset comprises
    tree observations from four zones of the Roosevelt National Forest in Colorado.
    It has no remote sensing, as the entire observations are cartographic variables
    from 30 m × 30 m sections of the forest. The FC dataset includes information on
    shadow coverage, tree type, distance to nearby landmarks, soil type, and local
    topography. The data are in raw form (not scaled) and contain binary (0 or 1)
    columns of data for qualitative independent variables (wilderness areas and soil
    types). Table 3  Datasets with default values. The second datasets adopted for
    our experiment are the tropical atmospheric ocean project (TAO) datasets [ 32,
    33], which is a low-dimensional dataset with three attributes and 575, 648 records.
    The dataset is real-time data extracted from National Oceanic and Atmospheric
    Administration website [ 33]. TAO was established to get useful insights and forecast
    climate variations related to El Nino and the Southern Oscillation (ENSO). The
    phenomenon, ENSO, signifies the strongest year-to-year climate instability on
    the planet. Its events undoubtedly interrupt normal patterns of weather variability,
    thereby disturbing farming, transport, Pacific marine ecosystems, energy produce,
    and the livelihood of millions of people around the world. The Stock dataset has
    only one attribute, and it is available from UPenn Wharton Research Data Services
    [ 34] with 1,048,575 records. The dataset shows Stock trading traces of about
    1 million transactions throughout the trading hours per day. Since the Wharton
    Research Data Services is not easily accessible, the available data can be found
    on the online repository [ 32] together with the other datasets used in this experiment.
    For the Synthetic dataset, we use the Gauss dataset [ 32]. The dataset is generated
    to produce streams with measured data distribution types and number of outliers.
    It is generated by mixing three Gaussian distributions and a random noise distribution,
    and it contains 1 million records with a single attribute. In each segment of
    the stream, the Gaussian distributed points and noise are randomly distributed.
    5.1.3. Default Parameter Settings Before performing our experiment, we take into
    consideration the slide size , the window size , the distance threshold , and
    the neighboring count threshold . The window size is the key parameter which determines
    the volume of the data streams and number of accommodated clusters, while the
    slide S affects the speed and the remaining parameters help to determine whether
    the evolving data points are inliers or outliers or whether they belong to a cluster
    or not. The default value of , and is shown in Table 3 for the different datasets.
    5.1.4. Evaluation Method We evaluated our method using three evaluation metrics:
    the running time, memory usage, and the clustering quality. The running time is
    the time taken to complete the detection of outliers for each window slide. The
    memory usage is the record of the peak memory used during the outlier detection
    process, including the storage data for each window. Lastly, the clustering quality
    defines how accurately our approach clusters the datasets. 5.1.5. Baseline Algorithms
    We chose three state-of-the-art algorithms, MCOD [ 4, 35] , MCMP for comparison
    with the CLODS. MCOD and were the best performing among the existing methods [
    36] until the hybrid approach called MCMP [ 8] was proposed, which uses the strength
    of both techniques to boost the performance in solving outlier detection problems.
    In MCMP, the key difference when compared to the other baseline methods is in
    dealing with data points within the current window. MCMP implement uses the concept
    of strong and trivial inliers of dealing with the objects outside the microclusters.
    in the majority cases is inferior to both MCOD and MCMP because of their lack
    of memory-efficient microclusters. It uses an index per slide for its neighbor
    search. Its minimal probing principle mitigates the expensive range queries and
    prioritizes the discovery of a minimal number of data points according to their
    arrival time. It has to continually re-evaluate and manage the data points in
    the updated list, which consequently increases its computational demand, while
    MCOD prunes out and minimizes outlier candidates. It uses an index structure called
    a microcluster that helps to prune out unqualified outlier candidates resourcefully.
    However, in MCOD, the absence of clearly distinguishing between the points outside
    the microclusters limits its potential to perform even better. Therefore, MCMP
    improves this shortcoming by using the strength of minimal probing and the memory-efficient
    microcluster and introduces the concept of trivial and strong inliers. This consequently
    improves the overall performance both in terms of reducing time and memory consumption.
    However, the improved performance comes at a cost, and we noticed that the absence
    of the extensive distance-based computation of data points outside the microclusters
    thus would lower the time and memory usage when we focus mainly on the clustering
    and deal with those points according to the relevance of their respective neighbors.
    For in-depth understanding of the baseline methods, we request our audience to
    read the individual references. 5.2. Results and Discussion 5.2.1. CPU Time In
    order to observe the CPU time usage, we take into consideration the following:
    we vary the window size W, the distance threshold , and the nearest neighbor count
    . Figure 4 shows the outcome of varying the window sizes , from 10k–20k for FC
    and TAO and then 10k–200k for Stock and Gauss. The results are shown for fixed
    and an approximate 1% outlier rate across the datasets. In Figure 4, for all datasets,
    in most cases as W increases which means more data points to cluster and compute,
    the CPU time also increases (Figures 4(a) and 4(c)) except for in Figures 4(b)
    and 4(c), and MCOD in Figure 4(d). The CLODS, similar to MCMP and MCOD in FC and
    TAO, shows a steady rise in all the datasets. However, in Gauss, when is above
    50K, we observe a sharp spike for because fewer data points are captured since
    it does not have microclusters. Both CLODS and MCMP show the lowest CPU time usage
    when compared to the others since the use of index structures is absent. The CLODS
    ensures that significant inliers are stored in microclusters, which reduces the
    computational demand of performing range queries for every data point. Generally,
    we observe that when is large enough, there is a tiny effect on the streaming
    data whose distribution changes dynamically. Nevertheless, if becomes too large,
    then it will influence the responding time, and the time will greatly increase,
    which will, in turn, downgrade its performance.   (a)         (a)  (b)  (c)  (d)         Figure
    4  CPU time-varying . (a) FC. (b) TAO. (c) Stock. (d) Gauss. Figure 5 illustrates
    the result of changing the neighbor count threshold k, from 1 to 100 across all
    the datasets. The results are shown for window size, W = 10K for FC and TAO and
    W = 100K for the remaining two datasets with other default parameters been maintained.
    In Figure 5, all the methods showed some changes across the different datasets
    since they depend on the neighbor count threshold k, which affects the outlier
    rate. From the figures, except for in TAO and Stock (Figures 5(b) and 5(c)), which
    demands more probing to find k, the other methods showed very good time consumption
    with CLODS showing superior performance in the majority of the dataset. This is
    because, in the first three datasets, there are not many data points that fall
    within the clusters that will require additional computation. For Figures 5(a)
    and 5(d), an increase in k shows an increase in the time since more probing needs
    to be done. In Figure 5(d), we see that MCMP slightly outperforms CLODS because
    few clusters demand additional computation. Overall, our approach performs well
    for the datasets that have points whose neighbors are close to each other, which
    makes it easy for clustering and thus makes it easy to differentiate between vivid
    or false outliers and crucial or insignificant inliers. Consequently, it shows
    better performance than the others since it can do the least computation possible
    outside the clusters. The likelihood of getting enough neighbors to ensure the
    fast clustering process is relatively low for datasets with sparse data points.
    Therefore, there are fewer clusters in the synthetic dataset, which also results
    in increased processing time when compared to the real-world datasets.   (a)         (a)  (b)  (c)  (d)         Figure
    5  CPU time-varying . (a) FC. (b) TAO. (c) Stock. (d) Gauss. Figure 6 displays
    the result and performance of varying the slide size S, from 1% of W to 100% of
    W. The slide size depicts the changes in the speed of the data stream. Across
    all the datasets, the value of k and R is maintained as in Table 3. In Figure
    6, we can see that across the datasets the CLODS shows the lowest CPU time usage,
    while incurs in the majority of the cases the highest CPU usage above that of
    MCOD and MCMP. In TAO and Stock datasets, we omit the trend of since the CPU time
    incurs far greater than the others, and for the other two cases, it shows an abnormal
    trend when compared to the others. The CLODS and the other algorithm show an increase
    with increase in . It confirms that an increase in results in arrival and expiration
    of more data points, thereby consuming additional time. However, the CLODS showed
    improved performance compared to that of MCMP since it uses less time than MCMP
    and MCOD that tries to update its neighbors after the detection of strong and
    trivial inliers and in identifying the outliers. In addition, we can observe that
    the processing of new arriving data points in CLODS scales well to that of the
    expired data points when the window size increases. In MCOD, for example, the
    time taken to process half of the data points outweighs the time for saving in
    discarding the expired data points. Overall, the slowest CPU time growth is shown
    across the datasets.   (a)         (a)  (b)  (c)  (d)         Figure 6  CPU time-varying
    . (a) FC. (b) TAO. (c) Stock. (d) Gauss. Figure 7 shows the effect of varying
    the distance threshold R through all the datasets, from 0–1000. The results are
    shown for slide size, S = 500 for the first two datasets and S = 5K for Stock
    and Gauss. The other parameters are maintained as shown in Table 3. In each dataset,
    when the value of R is varied, it influences the outlier rate. For Figures 7(c)
    and 7(d), incurs more time due to its trigger list, which makes it difficult to
    find neighbors. Overall, the CLODS showed better performance than the others and
    especially against MCMP since it has less distance computation when compared to
    MCMP that has to deal with strong and trivial inliers. The CLODS takes into consideration
    the relevance of K against each other rather than focusing on the influence of
    R. In Table 4, we notice that the outlier rate of R increases when default value
    of   (a)         (a)  (b)  (c)  (d)         Figure 7  CPU time-varying . (a) FC.
    (b) TAO. (c) Stock. (d) Gauss. Table 4  The outlier rate-varying 5.2.2. Memory
    Usage In Figure 8, as the window sizes increase, it shows that more data points
    need to be processed, which result in an increase in memory usage for the majority
    of the datasets. More inliers will be in the microclusters, crucial inliers will
    be stored in temporary memory, and the objects’ neighbors information will also
    be stored. From the figures, all the methods that make use of microclusters showed
    better performance across the datasets than , which does not have the memory-efficient
    microcluster. Across all the datasets, it consumes more memory since its trigger
    list has to be redone every time the slides expire. In Figure 8(d), the Gauss
    datasets have few neighbors, and it shows an increase in memory usage for the
    various methods when compared to the other datasets, since finding the neighbors
    consumes the temporary memory. Our approach shows almost the same performance
    as MCOD since there is not much computation outside the microclusters like that
    in MCMP, which incurs slightly more memory. The CLODS, in the majority of cases,
    showed the least memory consumption due to freeing up space by deleting in memory
    detected outliers and queuing in temporary memory only significant inliers that
    are outside the microclusters.   (a)         (a)  (b)  (c)  (d)         Figure
    8  Memory-varying . (a) FC. (b) TAO. (c) Stock. (d) Gauss. When we vary the neighbor
    count threshold by increasing the value of k as shown in Figure 9, we expect more
    memory usage since k impacts the storing of the neighbors. For a few scenarios,
    it is almost stable, showing a small difference. For instance, in Figure 9(b),
    difference does not exceed 1MB for , likewise for the other datasets in the same
    figure. The CLODS among the algorithms showed superior performance in most cases
    due to it is not entirely depending on K, as in the case of MCOD and MCMP. As
    K increases, more data points are not in microclusters, thereby occupying the
    temporary memory. For MCMP, the process of differentiating between the inliers
    utilizes some memory, while the CLODS only keeps a significant inlier in memory
    temporarily. One notable difference is in Figures 9(a) and 9(d) for , which shows
    higher memory usage as compared to the others because of the neighbor count list
    that needs to be processed.   (a)         (a)  (b)  (c)  (d)         Figure 9  Memory-varying
    . (a) FC. (b) TAO. (c) Stock. (d) Gauss. In Figure 10, when we vary the distance
    threshold R, there is no constant observable trend across the datasets. Overall,
    the CLODS together with the other algorithms does not make use of range queries;
    therefore, an increase in R does not result proportionally to an increase in memory
    usage. Initially, more memory is used for MCOD and MCMP since not many data points
    can be found in microclusters, and the additional computation to find neighbors
    occupies the memory. The CLODS showed, in most cases, better performance to some
    degree since it does not differentiate every outliers or inlier as in the case
    of MCMP, so it uses less memory at the start. In most cases, the decline in memory
    usage is because an increase in the value of R translates to more neighbors, which
    result in more objects within the microclusters and fewer data points outside
    the microclusters. This thus curbs the memory utilization.   (a)         (a)  (b)  (c)  (d)         Figure
    10  Memory-varying . (a) FC. (b) TAO. (c) Stock. (d) Gauss. Figure 11 shows the
    result of the memory usage when S increases. Across the datasets, the CLODS showed
    a decline in peak memory usage as S increases, likewise the other algorithms.
    The case shows unique performance, since it differs from the others in how it
    processes its data points. at the onset has higher peak memory consumption and
    continues to reduce further. The other memory-efficient microcluster algorithm
    including CLODS showed less memory consumption since it does not make use of trigger
    list as in . Thanks to their microclusters, the CLODS is slightly superior to
    that of MCMP in Figures 11(c) and 11(d), since storing the data points occupies
    the majority of the total memory. The absence of additional computation and to
    queue in memory trivial inliers gives it an advantage.   (a)         (a)  (b)  (c)  (d)         Figure
    11  Memory-varying . (a) FC. (b) TAO. (c) Stock. (d) Gauss. 5.2.3. Space and Time
    Complexity The complexity of the algorithm defines the running time and storage
    space needed by the algorithm in terms of its input size. The space complexity
    signifies the amount of memory space required by CLODS in its life cycle. To calculate
    the worst-case space required by CLODS, we take into consideration the space required
    to store the data and variables that are independent of the size of the problem.
    In Tables 5 and 6, we show the time and space complexity of the algorithms. Table
    5  Time complexity analysis results. Table 6  Space complexity analysis results.
    The time complexity in processing the data points within the current window in
    the worst-case scenario is the time cost of the function to discover whether the
    data point is in cluster or not, which is and in checking the relevance of the
    with respect to their neighbors in the sliding window. Since we are considering
    the worst-case scenario, we take into consideration the cost of computing this,
    which incurs higher cost than the processing of the new data points within the
    slide. The overall cost in this case is the cost of the data point in the window
    by the window slide size, that is . When the data points expire, in the worst-case,
    the process of removing expired data points within the slide does not cost as
    much as when we need to check the relevance of these objects and adding the data
    point if in cluster. In this case, the overall cost is . Therefore, the overall
    time complexity is which can be approximated to . The time complexity of CLODS
    is better than that of MCMP because in CLODS the cost of checking the relevance
    of the neighbors to their respective neighbors is less than that of MCMP cost,
    which incurs additional cost due to the cost of differentiating between the strong
    and trivial inliers. We can see that the overall time complexity of is which is
    approximately . This compared to the time complexity of the other two algorithms
    is almost the same as that of but superior to that of . The reduction in the time
    complexity of MCMP confirms that microcluster using the concept of minimal probing
    by differentiating the strong and trivial inlier reduces the extra time required
    for computing data points outside the clusters as it minimizes the time complexity
    of recalculating and evaluating the all the inliers, as in the case of . Since
    differentiating between the inliers also incurs some amount of cost, however,
    this cost is less compared to the other way around. In terms of the space complexity,
    a simple answer to the detection of continuous evolving outliers over streaming
    data in the window model will involve storing neighbors of each data object in
    the current window. It is apparent such computation in the worst-case will result
    in a quadratic space requirement ; therefore, for larger window size , it will
    be practically unfeasible. For each data point , instead of keeping all the preceding
    and succeeding neighbors , we store a number of neighbors and at most k data point
    will suffice to detect the outliers for specific and . The space complexity for
    managing data points within the current window is . We first calculate the size
    of the preceding neighbors that corresponds to the unexpired data points. When
    the size is less than , then is labeled as an outlier. When the window slides
    and expired, the space required to keep the neighbor counts is similar to that
    of MCMP, that is, since each data point within the window is not stored in for
    each slide. However, in CLODS with in-depth analysis, we could say that it will
    slight outperform MCMP since the space complexity needed in to store extra trivial
    inliers is less than that of saving relevant inliers in queue of the memory. The
    overall worst space complexity of CLODS is which is almost the same as that of
    except that in implies that during the expired window slides, the trivial inliers
    are stored in , with . Then, the number of data points within the window will
    be . That is, the list of data point in will be . From Table 6, we can see that
    space complexity is also better than that of and with and , respectively. It is
    evident that the space needed for differentiating the inliers is negligible and
    better off compared to the space needed for data points outside microclusters
    to save the extra trivial inliers. 5.2.4. The Quality of Data Points in the Clusters
    For clustering-based methods, an important metric to consider is the clustering
    quality, which affects the outlier detection rate in the data streams. Figure
    12 shows the effectiveness and clustering quality of against previous methods
    that also adopted microclustering technique. For the FC dataset in Figure 12(a),
    the percentage of clusters is relatively low since the distance between each object
    is sparse. In another case, for the Gauss dataset, the percentage is almost zero,
    with little or no data points participating in the microclusters. This is because,
    in this particular window, the dataset has few neighbors. shows inferior clustering
    quality when compared to both and CLODS because of its extra distance-based computation
    that involves computing and storing the strong and trivial inliers. In some instances,
    it influences the neighbor count threshold k’s relationship of the points outside
    the microclusters. The CLODS overall showed better clustering quality in almost
    all cases due to the absence of the extra computation that is involved in , and
    it ensures that clusters are generally formed on the basis of their relevance
    to their respective neighbors’ position. This results in some cases of large percentage
    of data points discovered in the clusters, as can be seen in Figure 12 across
    the datasets.   (a)         (a)  (b)  (c)  (d)         Figure 12  Comparison of
    the average percentage of data points in microclusters for , , and when we vary
    . (a) FC. (b) TAO. (c) Stock. (d) FC. 5.2.5. Advantages of CLODS CLODS through
    experiments has shown to outperform the existing methods in most cases and succeeded
    in curbing the computational cost in terms of the time taken and memory usage.
    It is a general solution used as a clustering-based outlier detection method for
    clustering evolving data streams based on microclusters and handling of objects
    within a sliding window according to the relevance of their status to their respective
    neighbors or position, excluding extended extra distance-based computation. The
    CLODS dynamically clusters data streams and offers support to meet flexible mining
    requirements. Furthermore, it has shown robustness in the variation of the different
    performance parameters and its clustering quality with regard to the number of
    data points in its clusters. Finally, it has shown to be an effective method for
    detecting outliers. 6. Conclusion Detecting outliers, which is the process of
    mining abnormal events from data, is a significant and challenging task. In this
    paper, we have proposed a clustering-based method called EMM-CLODS to address
    the problem of detecting outliers in continuous evolving data streams. The proposed
    method adopts the microcluster technique to group similar data points that are
    in proximity in the streaming data. It minimized the computational demand and
    showed an increase in the computational speed while it still maintained its effectiveness
    to detect outliers in the sliding window through minimal computation of data points
    outside the microclusters. It terms of its memory usage, not all objects outside
    the microclusters were stored in memory, and likewise, expired outlier data points
    were deleted from memory to minimize the memory usage. From the experiments performed
    on both real and synthetic datasets, our method showed effectiveness in detecting
    outliers for continuous evolving data streams. In the majority of the cases, it
    shows superior performance in terms of both CPU and memory utilization when compared
    to the other baseline algorithms. It has shown to be a good technique for detection
    outliers in data streams as it is robust to the various parameter variations (,
    , and ). Data Availability The data and source code used to support the findings
    of this study have not been made available. However, all the datasets except for
    the source code used have been clearly explained in the experimental section with
    links of where to directly access these data. Previously reported (FC, TAO, Stock,
    and Gauss) data were used to support this study and are available at http://infolab.usc.edu/Luan/Outlier/.
    These prior studies (and datasets) are cited at relevant places within the text.
    Disclosure Mohamed Jaward Bah, Hongzhi Wang, Li-Hui Zhao, and Ji Zhang are co-first
    authors. Conflicts of Interest The authors declare that they have no conflicts
    of interest regarding this work. Acknowledgments The authors would like to thank
    the support from the Postdoctoral Fund of Hangzhou City (no. 119001-UB2101SJ),
    PI Research Project of Zhejiang Lab (no. 111007-PI2001), Natural Science Foundation
    of China (no. 62172372 and no. U1866602), and Zhejiang Provincial Natural Science
    Foundation (no. LZ21F030001). References V. Chandola, A. Banerjee, and V. Kumar,
    “Anomaly detection: A survey,” ACM Computing Surveys (CSUR), vol. 41, pp. 1–58,
    2009. View at: Publisher Site | Google Scholar X. Su and C. L. Tsai, “Outlier
    detection,” WIREs Data Mining and Knowledge Discovery, vol. 1, no. 3, pp. 261–268,
    2011. View at: Publisher Site | Google Scholar Ji Zhang, “Advancements of outlier
    detection: a survey,” ICST Transactions on Scalable Information Systems, vol.
    13, pp. 1–26, 2013. View at: Publisher Site | Google Scholar L. Cao, Di Yang,
    Q. Wang, Y. Yu, J. Wang, and E. A. Rundensteiner, “Scalable distance-based outlier
    detection over high-volume data streams,” in Proceedings of the 2014 IEEE 30th
    International Conference on Data Engineering, pp. 76–87, IEEE, Chicago, IL, USA,
    April 2014. View at: Publisher Site | Google Scholar S. Guha, M. Adam, N. Mishra,
    R. Motwani, and L. O’Callaghan, “Clustering data streams: theory and practice,”
    IEEE Transactions on Knowledge and Data Engineering, vol. 15, pp. 515–528, 2003.
    View at: Publisher Site | Google Scholar Y. Chen and Li Tu, “Density-based clustering
    for real-time stream data,” in Proceedings of the 13th ACM SIGKDD International
    Conference on Knowledge Discovery and Data Mining, pp. 133–142, San Jose, CA,
    USA, August 2007. View at: Publisher Site | Google Scholar S. Hettich and S. D.
    Bay, The UCI KDD Archive Irvine, Department of Information and Computer Science,
    University of California, Irvine, CA, USA, 1999, http://kdd.ics.uci.edu. M. J.
    Bah, H. Wang, H. Mohamed, F. Zeshan, and H. Aljuaid, “An effective minimal probing
    approach with micro-cluster for distance-based outlier detection in data streams,”
    IEEE Access, vol. 7, pp. 154922–154934, 2019. View at: Google Scholar L. Cao,
    J. Wang, and E. A. Rundensteiner, “Sharing-aware outlier analytics over high-volume
    data streams,” in Proceedings of the 2016 International Conference on Management
    of Data, pp. 527–540, San Francisco, CA, USA, July 2016. View at: Publisher Site
    | Google Scholar J. Tamboli and M. Shukla, “A survey of outlier detection algorithms
    for data streams,” in Proceedings of the 2016 3rd International Conference on
    Computing for Sustainable Global Development (INDIACom), pp. 3535–3540, IEEE,
    New Delhi, India, March 2016. View at: Google Scholar H. Wang, M. J. Bah, and
    M. Hammad, “Progress in outlier detection techniques: a survey,” Ieee Access,
    vol. 7, pp. 107964–108000, 2019. View at: Publisher Site | Google Scholar C. C.
    Aggarwal, P. S. Yu, J. Han, and J. Wang, “A framework for clustering evolving
    data streams,” in Proceedings 2003 VLDB Conference, pp. 81–92, Berlin, Germany,
    September 2003. View at: Publisher Site | Google Scholar P. Caroline Cynthia and
    S. Thomas George, “An outlier detection approach on credit card fraud detection
    using machine learning: a comparative analysis on supervised and unsupervised
    learning,” in Intelligence in Big Data Technologies—Beyond the Hype, J. Dinesh
    Peter, S. L. Fernandes, and A. H. Alavi, Eds., pp. 125–135, Springer Singapore,
    Singapore, 2021. View at: Publisher Site | Google Scholar M. E. Villa-Pérez, M.
    Á. Álvarez-Carmona, O. Loyola-González, M. A. Medina-Pérez, J. C. Velazco-Rossell,
    and K.-K. R. Choo, “Semi-supervised anomaly detection algorithms: a comparative
    summary and future research directions,” Knowledge-Based Systems, vol. 218, Article
    ID 106878, 2021. View at: Publisher Site | Google Scholar F. Liu, S. Xue, J. Wu
    et al., “Deep learning for community detection: progress, challenges and opportunities,”
    in Proceedings of the Twenty-Ninth International Joint Conference on Artificial
    Intelligence, Yokohama, Japan, July 2020. View at: Publisher Site | Google Scholar
    X. Su, S. Xue, F. Liu et al., “A comprehensive survey on community detection with
    deep learning,” 2021. View at: Google Scholar A. Boukerche, L. Zheng, and A. Omar,
    “Outlier detection: methods, models, and classification,” ACM Computing Surveys,
    vol. 53, no. 3, 2020. View at: Publisher Site | Google Scholar X. Ma, J. Wu, S.
    Xue, J. Yang, Z. S. Quan, and H. Xiong, “A comprehensive survey on graph anomaly
    detection with deep learning,” 2021, http://arxiv.org/abs/2106.07178. View at:
    Google Scholar G. Pang, C. Shen, L. Cao, and A. Van Den Hengel, “Deep learning
    for anomaly detection: a review,” ACM Computing Surveys (CSUR), vol. 54, pp. 1–38,
    2021. View at: Publisher Site | Google Scholar D. Toshniwal and Yokita, “A framework
    for outlier detection in evolving data streams by weighting attributes in clustering,”
    Procedia Technology, vol. 6, no. 2012, pp. 214–222, 2012. View at: Google Scholar
    A. Zhou, F. Cao, W. Qian, and C. Jin, “Tracking clusters in evolving data streams
    over sliding windows,” Knowledge and Information Systems, vol. 15, no. 2, pp.
    181–214, 2008. View at: Publisher Site | Google Scholar F. Cao, M. Estert, W.
    Qian, and A. Zhou, “Density-based clustering over an evolving data stream with
    noise,” in Proceedings of the 2006 SIAM International Conference on Data Mining,
    pp. 328–339, SIAM, Bethesda, MD, USA, April 2006. View at: Publisher Site | Google
    Scholar L.-x. Liu, Y.-f. Guo, J. Kang, and H. Huang, “A three-step clustering
    algorithm over an evolving data stream,” in Proceedings of the 2009 IEEE International
    Conference on Intelligent Computing and Intelligent Systems, pp. 160–164, IEEE,
    Shanghai, China, November 2009. View at: Publisher Site | Google Scholar M. Kumar
    and A. Sharma, “Mining of data stream using “DDenStream” clustering algorithm,”
    in Proceedings of the 2013 IEEE International Conference in MOOC, Innovation and
    Technology in Education (MITE), pp. 315–320, IEEE, Jaipur, India, December 2013.
    View at: Google Scholar A. Amini and T. Y. Wah, “A comparative study of density-based
    clustering algorithms on data streams: micro-clustering approaches,” in Intelligent
    Control and Innovative Computing, pp. 275–287, Springer, Berlin, Germany, 2012.
    View at: Publisher Site | Google Scholar A. Amini, T. Y. Wah, and Y. W. Teh, “DENGRIS-Stream:
    A density-grid based clustering algorithm for evolving data streams over sliding
    window,” in Proceedings of the International Conference on Data Mining and Computer
    Engineering, pp. 206–210, Visakhapatnam, India, January 2012. View at: Google
    Scholar L. Duan, L. Xu, Y. Liu, and J. Lee, “Cluster-based outlier detection,”
    Annals of Operations Research, vol. 168, pp. 151–168, 2009. View at: Publisher
    Site | Google Scholar M. Elahi, K. Li, W. Nisar, X. Lv, and H. Wang, “Efficient
    clustering-based outlier detection algorithm for dynamic data stream,” in Proceedings
    of the 2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery,
    pp. 298–304, IEEE, October 2008, Jinan, China. View at: Publisher Site | Google
    Scholar A. Forestiero, C. Pizzuti, and G. Spezzano, “A single pass algorithm for
    clustering evolving data streams based on swarm intelligence,” Data Mining and
    Knowledge Discovery, vol. 26, no. 1, pp. 1–26, 2013. View at: Publisher Site |
    Google Scholar M. S. Sadik and L. Gruenwald, “DBOD-DS: distance based outlier
    detection for data streams,” in International Conference on Database and Expert
    Systems Applications, pp. 122–136, Springer, Berlin, Germany, 2010. View at: Publisher
    Site | Google Scholar M. B. Al-Zoubi, “An effective clustering-based approach
    for outlier detection,” European Journal of Scientific Research, vol. 28, no.
    2, pp. 310–316, 2009. View at: Google Scholar L. Tran, L. Fan, and C. Shahabi,
    Distance-Based Outlier Detection in Data Streams Repository, Information Laboratory
    University of Southern California, Los Angeles, LA, USA. Pacific Marine Environmental
    Laboratory. 2019. Wharton University of Pennsylvania. https://infolab.usc.edu/Luan/Outlier/Datasets/tao.txt.
    Wharton Research Data Services, Distance-Based Outlier Detection in Data Streams
    Repository, Wharton Research Data Services, Philadelphia, PA, USA, 2020, https://wrds-web.wharton.upenn.edu/wrds/.
    M. Kontaki, A. Gounaris, A. N. Papadopoulos, K. Tsichlas, and Y. Manolopoulos,
    “Continuous monitoring of distance-based outliers over data streams,” in Proceedings
    of the 2011 IEEE 27th International Conference on Data Engineering, pp. 135–146,
    IEEE, Hannover, Germany, April 2011. View at: Publisher Site | Google Scholar
    M. Shukla, Y. P. Kosta, and P. Chauhan, “Analysis and evaluation of outlier detection
    algorithms in data streams,” in Proceedings of the 2015 International Conference
    on Computer, Communication and Control (IC4), pp. 1–8, IEEE, Indore, India, September
    2015. View at: Google Scholar Copyright Copyright © 2021 Mohamed Jaward Bah et
    al. This is an open access article distributed under the Creative Commons Attribution
    License, which permits unrestricted use, distribution, and reproduction in any
    medium, provided the original work is properly cited. PDF Download Citation Download
    other formats Order printed copies Views 383 Downloads 733 Citations 2 About Us
    Contact us Partnerships Blog Journals Article Processing Charges Print editions
    Authors Editors Reviewers Partnerships Hindawi XML Corpus Open Archives Initiative
    Fraud prevention Follow us: Privacy PolicyTerms of ServiceResponsible Disclosure
    PolicyCookie PolicyCopyrightModern slavery statementCookie Preferences'
  inline_citation: '>'
  journal: Complexity
  limitations: '>'
  pdf_link: https://downloads.hindawi.com/journals/complexity/2021/9178461.pdf
  publication_year: 2021
  relevance_score1: 0
  relevance_score2: 0
  title: 'EMM-CLODS: An Effective Microcluster and Minimal Pruning CLustering-Based
    Technique for Detecting Outliers in Data Streams'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.22266/ijies2022.1031.12
  analysis: '>'
  authors: []
  citation_count: 0
  full_citation: '>'
  full_text: '>'
  inline_citation: '>'
  journal: International Journal of Intelligent Engineering and Systems
  limitations: '>'
  pdf_link: null
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: Psoriasis Identification from Gene Expression Analysis Using Relative Entropy
    Fuzzy Score Normalization, Genetic Weighted K-Nearest Neighbors Imputation and
    Hybrid Machine Learning Classifier
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.18297/etd/18
  analysis: '>'
  authors:
  - M.F. Ahmed
  - Ehab Ahmed El Sayed
  citation_count: 0
  full_citation: '>'
  full_text: '>

    We use cookies to help provide and enhance our service and tailor content. By
    closing this message, you agree to the use of cookies. Close ThinkIR: The University
    of Louisville''s Institutional Repository My Account FAQ About Home Home > ETD
    > 18 ELECTRONIC THESES AND DISSERTATIONS Multivariate discretization of continuous
    valued attributes. Author Ehab Ahmed El Sayed Ahmed 1978-, University of Louisville
    Date on Master''s Thesis/Doctoral Dissertation 12-2006 Document Type Master''s
    Thesis Degree Name M.S. Department Computer Engineering and Computer Science Committee
    Chair Elmaghraby, Adel S. Committee Co-Chair (if applicable) Eman, Ahmed Committee
    Member Chang, Dar-Jen Committee Member Wong, Julius P. Committee Member Wahba,
    Khaled Author''s Keywords Data mining; Knowledge discovery Subject Data mining;
    Algorithms Abstract The area of Knowledge discovery and data mining is growing
    rapidly. Feature Discretization is a crucial issue in Knowledge Discovery in Databases
    (KDD), or Data Mining because most data sets used in real world applications have
    features with continuously values. Discretization is performed as a preprocessing
    step of the data mining to make data mining techniques useful for these data sets.
    This thesis addresses discretization issue by proposing a multivariate discretization
    (MVD) algorithm. It begins withal number of common discretization algorithms like
    Equal width discretization, Equal frequency discretization, Naïve; Entropy based
    discretization, Chi square discretization, and orthogonal hyper planes. After
    that comparing the results achieved by the multivariate discretization (MVD) algorithm
    with the accuracy results of other algorithms. This thesis is divided into six
    chapters, covering a few common discretization algorithms and tests these algorithms
    on a real world datasets which varying in size and complexity, and shows how data
    visualization techniques will be effective in determining the degree of complexity
    of the given data set. We have examined the multivariate discretization (MVD)
    algorithm with the same data sets. After that we have classified discrete data
    using artificial neural network single layer perceptron and multilayer perceptron
    with back propagation algorithm. We have trained the Classifier using the training
    data set, and tested its accuracy using the testing data set. Our experiments
    lead to better accuracy results with some data sets and low accuracy results with
    other data sets, and this is subject ot the degree of data complexity then we
    have compared the accuracy results of multivariate discretization (MVD) algorithm
    with the results achieved by other discretization algorithms. We have found that
    multivariate discretization (MVD) algorithm produces good accuracy results in
    comparing with the other discretization algorithm. Recommended Citation Ahmed,
    Ehab Ahmed El Sayed 1978-, "Multivariate discretization of continuous valued attributes."
    (2006). Electronic Theses and Dissertations. Paper 18. https://doi.org/10.18297/etd/18
    Download 531 DOWNLOADS Since February 12, 2015 PLUMX METRICS INCLUDED IN Computer
    Engineering Commons SHARE Facebook LinkedIn WhatsApp Email Share   Search Enter
    search terms: Select context to search:                   in this series                        in
    this repository      across all repositories      Advanced Search Notify me via
    email or RSS Browse Collections Disciplines Authors Author Corner Author FAQ Collection
    Policy License Agreements ThinkIR Electronic Resource Guide Submit Research Related
    Links Guidelines for the Preparation and Processing of Theses and Dissertations
    (School of Interdisciplinary & Graduate Studies) (PDF) University of Louisville
    Libraries Research Assistance and Instruction Nonexclusive License to Electronically
    Disseminate UofL ETD (PDF) Data Management Guides for Theses and Dissertations  Contact:
    thinkIR@louisville.edu   Home | About | FAQ | My Account | Accessibility Statement
    Privacy Copyright'
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: https://ir.library.louisville.edu/cgi/viewcontent.cgi?article=1017&context=etd
  publication_year: 2015
  relevance_score1: 0
  relevance_score2: 0
  title: Multivariate discretization of continuous valued attributes.
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'

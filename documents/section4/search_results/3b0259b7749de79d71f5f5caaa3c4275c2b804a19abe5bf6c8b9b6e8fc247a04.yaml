- analysis: '>'
  authors:
  - Khan Z.
  - Yang J.
  citation_count: '0'
  description: Image segmentation focuses at highlighting region of interest within
    the image, by accumulation of pixels based on given properties. This task resembles
    to clustering, yet many standard clustering methods fail to meet the basic requirement
    of image segmentation, that is number of segments is rarely determined automatically.
    The proposed nonparametric K-means clustering (EAIS) overcomes this limitation
    and turns out to be particularly suitable for the task of image segmentation.
    In this paper, we propose a nonparametric K-means clustering approach (EAIS) that
    automatically and adaptively determines the initialization conditions, i.e. number
    of clusters, initial cluster centroids, and subsequently segments the image into
    suitable regions. The proposed approach comprises of five modules that includes
    deep image reconstruction, intra-histogram individual peak level detection, inter-histogram
    peak levels association, mutual consensus-oriented cluster seeds merging, and
    morphological reconstruction-driven spatial post-processing. Deep reconstruction
    performs image smoothing by reducing the variance and outliers in the colour channel
    distribution. The proposed approach utilizes image histograms-based global distribution
    to determine the optimal initialization condition for pixel clustering (image
    segmentation). Followed by dynamic and optimally devised cluster seeds merging
    for redundancy reduction and determination of adequate number of cluster seeds
    for K-means initialization. Finally, morphological reconstruction inducts spatial
    awareness in the clustered space and enhances the spatial consistency of cluster
    member’s (pixels). Diverse experimental results on the BSDS500 benchmark validate
    that our proposed approach is robust to various natural scenarios and comparable
    to state-of-the-art methods regarding segmentation quality and computational efficiency.
  doi: 10.1007/s10044-024-01228-5
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Log in Find a journal Publish
    with us Track your research Search Cart Home Pattern Analysis and Applications
    Article Nonparametric K-means clustering-based adaptive unsupervised colour image
    segmentation Theoretical Advances Published: 28 February 2024 Volume 27, article
    number 17, (2024) Cite this article Download PDF Access provided by University
    of Nebraska-Lincoln Pattern Analysis and Applications Aims and scope Submit manuscript
    Zubair Khan & Jie Yang  74 Accesses Explore all metrics Abstract Image segmentation
    focuses at highlighting region of interest within the image, by accumulation of
    pixels based on given properties. This task resembles to clustering, yet many
    standard clustering methods fail to meet the basic requirement of image segmentation,
    that is number of segments is rarely determined automatically. The proposed nonparametric
    K-means clustering (EAIS) overcomes this limitation and turns out to be particularly
    suitable for the task of image segmentation. In this paper, we propose a nonparametric
    K-means clustering approach (EAIS) that automatically and adaptively determines
    the initialization conditions, i.e. number of clusters, initial cluster centroids,
    and subsequently segments the image into suitable regions. The proposed approach
    comprises of five modules that includes deep image reconstruction, intra-histogram
    individual peak level detection, inter-histogram peak levels association, mutual
    consensus-oriented cluster seeds merging, and morphological reconstruction-driven
    spatial post-processing. Deep reconstruction performs image smoothing by reducing
    the variance and outliers in the colour channel distribution. The proposed approach
    utilizes image histograms-based global distribution to determine the optimal initialization
    condition for pixel clustering (image segmentation). Followed by dynamic and optimally
    devised cluster seeds merging for redundancy reduction and determination of adequate
    number of cluster seeds for K-means initialization. Finally, morphological reconstruction
    inducts spatial awareness in the clustered space and enhances the spatial consistency
    of cluster member’s (pixels). Diverse experimental results on the BSDS500 benchmark
    validate that our proposed approach is robust to various natural scenarios and
    comparable to state-of-the-art methods regarding segmentation quality and computational
    efficiency. Similar content being viewed by others A novel clustering-based image
    segmentation via density peaks algorithm with mid-level feature Article 18 April
    2016 Expanded relative density peak clustering for image segmentation Article
    27 September 2023 Image noise reduction based on adaptive thresholding and clustering
    Article 06 December 2018 1 Introduction Image segmentation [1] is an important
    low-level vision (image processing) task that provides the basis for several high-level
    vision applications, e.g. computer vision [2], scene understanding [3], and pattern
    recognition [4]. The basic objective of image segmentation is to appropriately
    partition the image into visually distinct regions based on certain attributes,
    i.e. colour, texture, depth, and saliency. Clustering is an unsupervised machine
    learning approach and one of the most widely utilized tool for grouping data due
    to ease of applicability and high efficiency. Clustering has numerous applications
    such as market research and customer segmentation [5], biological data and medical
    imaging analysis [6], search result clustering [7], recommendation engine [8],
    pattern recognition [4], social network analysis [9], and image processing [10].
    K-means [11] and fuzzy C-means (FCM) [12] are widely utilized clustering techniques
    for image segmentation due to high efficiency and simple operating procedure.
    K-means has less algorithm complexity while FCM often demonstrates better clustering
    due to cluster-pixel fuzzy membership and robustness against outliers. However,
    the parametric nature of these algorithms and initialization conditions dependability
    deteriorates the expected results [13]. The misappropriate selection of these
    conditions tends to produce unacceptable and unreliable results. Previously, various
    methods have been proposed to solve the initialization conditions issue for clustering
    algorithms. Random cluster seed initialization [14] is the most widely employed
    technique that randomly chooses the initialization seeds for user-defined clusters.
    The guessing of clusters and random selection of cluster seeds makes the clustering
    process vulnerable to poor convergence due to the presence of multiple local minima
    solutions. To solve the cluster seeds random selection and improve the clustering
    performance, K-means++ [15] augmented a heuristic seed selection approach to maintain
    the inter-seed distance. Even though K-means++ manages the seeds to be distant
    apart to cover the whole feature space yet, the automatic determination of clusters
    seeds remains unsolved. Moreover, experimenting with different clusters through
    the hit and trial makes the procedure hectic and inefficient. Mean Shift [16]
    provided a non-parametric clustering solution that avoids making strong assumptions
    about underlying data distribution and utilizes a filtering window (kernel) to
    group pixels based on colour features and proximity. The user-defined window (kernel)
    bandwidth causes a trade-off between over-smoothing and under-smoothing of the
    density estimate, affecting cluster results. As larger kernel bandwidth tends
    to loose attention for smaller regions, whereas a smaller window generates redundant
    regions. Yu et al. [17] presented an adaptive unsupervised algorithm, which takes
    advantage of both ant system and fuzzy C-means techniques. AFHA and ant system
    [18] ascertain the initialization conditions, and FCM performs pixel clustering
    to output the segmented image. The high processing cost of AS module lowers the
    AFHA efficiency. To improve the efficiency of AFHA, Yu et al. [19] proposed a
    revised approach, IAFHA. IAFHA determines the initialization parameters by considering
    only a minute bunch of pixels instead of the complete image. Even though IAFHA
    lowers the processing cost, there is a trade-off between computation cost and
    segmentation quality. Bhoyar and Kakde [20] proposed AJNDH algorithm which utilized
    histogram bins to fetch the number of initialization clusters. The histogram bins
    can be significantly reduced by combining perceptually proximal colour segments.
    The decrease in unique colours makes the application of AJNDH suitable for real-time
    situations. Chen et al. [21] presented a method that first transforms the image
    into a diverse colour space. After that, a peak finding algorithm determines the
    initialization conditions. The process is followed by a spatial FCM application
    to fetch initial segmentation by using the number of clusters found in each colour
    channel. The final amount of clusters is obtained in the ultimate step by fusing
    the initial segmentation outcome. Zheng et al. [22] presented an FCM and spatial
    information-based adaptive image segmentation method; high computation cost made
    it infeasible for real-time image segmentation. Siang Tan and Mat Isa [23] proposed
    a hybrid method (HTFCM) based on histogram thresholding and FCM clustering for
    colour image segmentation. The complexity of the initialization parameter determination
    procedure lowered the efficiency, however, improved the local minima convergence
    of the clustering algorithm. Tan et al. [24] proposed an unsupervised clustering
    algorithm, cluster splitting and merging fuzzy C-means hybrid algorithm (RFHA).
    RFHA comprises of RSM (Region splitting and merging), which determines the initialization
    parameters, and the fuzzy C-means algorithm produces the ultimate segmentation
    results. RFHA has relatively lower processing time compared to AFHA. Tan et al.
    [25] proposed a colour image segmentation method by replacing RGB colour space
    with HSL. The ultimate segmentation results generated comparatively uniform regions
    but with a high computation cost. However, the inadequacies in choosing the initialization
    parameters of PFHA, HTFCM, and RFHA delayed the FCM convergence, thus increasing
    the cumulative computation cost [26,27,28,29,30]. The modified K-means algorithm
    (MKM) presented by Zhang et al. [31] is an adaptive unsupervised clustering method
    for image segmentation. MKM iteratively bisects the clusters until a specific
    inter-cluster similarity criteria are achieved. Thus, the sensitivity threshold
    influences the segmentation results of the MKM. Recently, [32] proposed a method
    to determine the initialization conditions for grey images segmentation. However,
    the grey image consists of single-channel information and has limited applicability
    in the contemporary era. To solve the clustering initialization issue for colour
    images, [33, 34] proposed an approach that provides initialization cluster seeds.
    However, the fixed filtering window and cluster seeds redundancy pose issues,
    e.g. pixels misclassification, over-segmentation, and small noisy pixels, that
    hinders to achieve high-quality image segmentation. In deep learning paradigm,
    several methods are proposed to solve the unsupervised image segmentation task.
    Asako Kanezaki proposed a method Backprop [35] that applied SLIC-based post-processing
    on convolution neural network clustered features and simultaneously optimised
    network parameters via back-propagation. Backprop produced competitive results;
    however, simple feature extraction and continuous refinement process occluded
    small-sized salient objects. Moreover, the main drawbacks of Backprop are inference-time
    optimisation operation and inability to segment unseen images via trained model.
    To overcome this issue, a differential version of Backprop is presented [36] that
    skipped the post-processing step and added a gradient-based loss function. It
    produced over-segmented results compared to Backprop due to the absence of spatial
    post-processing. It also performed model optimization in the inference-time. However,
    this approach presented a framework for segmenting unseen images by first training
    the model on few similar reference images. Zhou et al. [37] proposed an approach
    that incremented the membership refinement procedure in Backprop via cluster centre
    update and obtained the segmentation mask for model learning in inference-time.
    The results were satisfactory, however, abrupt fluctuations in membership refinement
    during model learning required extra convergence iterations. SOD [38] proposed
    a deep unsupervised framework with [35] backbone that performed image segmentation
    and saliency detection, utilising spectral images. It employed deep features instead
    of RGB features to generate SLIC superpixels. The results of SOD are over-segmented
    in comparison with Backprop. The ultimate segmentation results quality also depends
    upon the quality of input image. Imaging devices tend to induce noise during the
    image capturing. Researchers have designed techniques to mitigate it. CAE-TVL
    [39] employs on convolutional auto-encoder (CAE) with total variation loss (TVL)
    as a pre-processing step for SLIC to alleviate the burden of conventional unsupervised
    image segmentation and enhances their performance. Lei et al. [40] proposed a
    morphological reconstruction and membership filtering-based FCM approach to decrement
    noise and induce spatial information in the clustering objective function. Even
    though the segmentation performance increased, however, the efficiency decreased
    significantly with the growing amount of clusters. Lei et al. [41] further proposed
    an adaptive morphological reconstruction for seeded segmentation (SE-AMR-SC) that
    employs image gradients to determine cluster seeds and adaptive filtering window
    to filter the redundant seeds for region growing. The results of SE-AMR-SC displayed
    under-segmentation and loss of information by misclassifying smaller objects in
    the image. Fig. 1 Flow diagram of the proposed EAIS approach. The blocks inside
    the dotted line represent various modules of the proposed approach Full size image
    So, in this approach, we employ deep image reconstruction framework with a smoothed
    reconstruction loss to mitigate the abrupt pixel intensity variations. An efficient
    clustering initialization approach determines adequate number of initial histogram
    levels, followed by a dynamic, adaptive, and histogram distribution-driven filtering
    window for optimal level selection. Redundant cluster seeds are removed utilizing
    a consensus-oriented mechanism with a dynamic threshold. Morphological image reconstruction
    is employed for post-processing to eliminate noisy clustered regions. The overall
    approach enhances the clustering performance for unsupervised image segmentation
    and increases its applicability and effectiveness. The approach is organized in
    multiple modules, and each module benefits the overall objective in a unique dimension.
    Fig. 2 The denseNet architecture of our proposed approach. E’s and D’s represent
    the encoder and decoder layers, respectively. Arrows represent skip-connections.
    The input and output spatial resolution of each network layer is also presented.
    x, y, and c denote rows, columns, and channels, respectively Full size image The
    contributions of the proposed approach are as follows: We present a deep image
    reconstruction framework to eliminate abrupt channel intensity fluctuations. We
    propose an efficient clustering initialization approach with an adaptive filtering
    window for optimal intensity level selection. We propose a consensus-oriented
    seed merging and morphological reconstruction to eliminate cluster seeds redundancy
    and improve clustered regions spatial consistency, respectively. We perform extensive
    experiments and ablation studies to elaborate the significance of each module
    in the proposed approach. The organization of the paper is in three sections.
    In Sect. 2, we explain our proposed approach for clustering-based image segmentation.
    Section 3 presents the comprehensive experimental results and analysis with insightful
    discussions, and Sect. 4 concludes the paper. Fig. 3 Intra-histogram individual
    levels (I/L) detection for image 100,099. a Detection of initial coarse levels
    \\(l_c\\). b Adaptive window-based coarse levels refinement. Filtering window
    is dynamically calculated based on given histogram distribution. c Fine levels
    \\(l_f\\) Full size image 2 Proposed approach This section elaborates the proposed
    clustering-based approach for efficient and accurate image segmentation (EAIS).
    The prime objective of our proposed approach is to devise an automatic, efficient,
    and optimized approach to solve the critical clustering issue with negligible
    human supervision. The pipeline of the proposed approach consists of several modules,
    i.e. deep image reconstruction, intra-histogram levels detection, inter-histogram
    levels association, dynamic and consensus-oriented cluster seed merging, clustering,
    and spatial post-processing to produce the final segmented image, as presented
    in Fig. 1. Each of these modules is discussed in this section. Fig. 4 This representation
    depicts the effect of deep image reconstruction on feature smoothing and feature
    space histogram distribution for image 100,099. (a) represents the original image.
    The reconstructed image in (b) removes the abrupt feature space variations as
    a pre-requisite that is highly convenient for image segmentation. Moreover, a
    huge difference can be spotted in raw and reconstructed Lab histogram distributions.
    The raw histogram distribution in (c) is relatively uniform and contains multiple
    peaks that depicts the presence of pixel intensity variations. On the contrary,
    (d) avoids multiple peaks and pixel variations that confirms the smoothing effect
    induced by deep reconstruction Full size image 2.1 Deep model driven image reconstruction
    Image smoothing is widely utilized as a pre-processing step for various image
    processing applications. Traditional smoothing approaches, e.g. filtering, reduce
    the noisy pixels, however, induce artifacts in the image content. So, in order
    to avoid this, we employ a deep learning driven smoothed image reconstruction
    approach. We employ dense U-Net model that contains an encoder–decoder architecture
    and dense connections, presented in Fig. 2 to optimally reconstruct a smoothed
    image. The deep model explores the insights in the RGB data, minimizes the smoothed
    reconstruction loss function, and obtains a compact and smoothed representation,
    as presented in Fig. 9b that helps to produce better segmentation. Smoothed reconstruction
    loss In order to ensure that the latent space representation reconstructs a smoothed
    image, we introduce a smoothed reconstruction loss constraint in the training
    process. The smoothed reconstruction loss minimization ensures feature smoothing,
    formulation is given in Eqs. 1 and 2: Given the original image x, smoothed image
    v (SLIC) and decoded representation \\(x^R\\). The dense U-Net loss minimization
    is presented in Eq. 1. $$\\begin{aligned} {L_\\textrm{recons}}= & {} {\\left\\|
    {x - {x^R}} \\right\\| ^2} + \\sum \\limits _{i = 1}^N {\\sum \\limits _{j = 1}^M
    {{l_{ij}}} } {\\left\\| {x_i^R - {v_j}} \\right\\| ^2} \\end{aligned}$$ (1) $$\\begin{aligned}
    {v_j}= & {} \\frac{{\\sum \\limits _{j = 1}^K {\\sum \\limits _{i = 1}^N {{x_{ij}}}
    } }}{{\\left| {{Z_j}} \\right| }} \\end{aligned}$$ (2) \\(v_j\\) represents the
    average RGB vector of x, cluster-pixel membership is provided by SLIC label template
    Z. \\(x_{ij}\\) represents the \\({i_{th}}\\) pixel belonging to \\({j_{th}}\\)
    cluster in Z. \\({\\left| {{Z_{j}}} \\right| }\\) is the cardinality of the \\({j_{th}}\\)
    cluster in Z. The effect of reconstruction loss minimization by Eq. 1 can be perceived
    as minimizing the inconsistency of pixel features, thus smoothing out regions.
    Fig. 5 The effect of filtering window range on level selection and segmentation
    results. Inappropriate filtering window range eliminates key levels and fails
    to preserve image objects, as presented in (b) and (c) Full size image 2.2 Intra-histogram
    levels detection and inter-histogram level association The proposed module processes
    the reconstructed image to automatically determine the number of clusters and
    the corresponding cluster seeds based on the histogram distribution. The proposed
    approach ensures that intra-histogram levels detection and the inter-histogram
    levels association achieve the following objectives: Key individual levels should
    be detected for cluster seeds formation. Cluster seeds should be appropriate in
    numbers and capture the feature space. Fig. 6 Inter-histogram levels association
    process. For each fine level \\(l_f\\), a relevant level in other constituent
    channels is determined through intra-histogram processing, as presented in Fig.
    3. a, b, and c represent red, green, and blue cluster seeds component. Same colour
    asterisks constitute a cluster seed. Levels with more than one asterisk represent
    the involvement of a level in multiple clusters (color figure online) Full size
    image The intra-histogram levels detection is a dual-phase process to select the
    optimal representative levels. The process begins with detecting coarse levels
    having higher amplitude than immediate neighbouring levels. These raw levels contain
    redundancy in terms of proximal levels around the key levels, causing histogram
    distribution to over-segment among multiple levels, as presented in Fig. 3a. The
    second phase filters the proximal levels by selecting the highest frequency level
    within a dynamically calculated filtering window range. The window range is adaptively
    and dynamically calculated based on given histogram distribution to achieve optimal
    levels selection. Figure 3b, c graphically presents the window-driven levels refinement
    and resulting fine levels, respectively. Equations 3 and 4 calculate the window
    range as follows: $$\\begin{aligned} F= & {} \\left\\{ {\\tau < {a_l} \\le \\max
    (\\textrm{hist})} \\right\\} _{l = 1}^{256} \\end{aligned}$$ (3) $$\\begin{aligned}
    \\textrm{window} \\ \\ \\textrm{range}= & {} \\left| F \\right| /\\alpha \\end{aligned}$$
    (4) \\(a_l\\) and \\(\\left| F \\right| =n(F)\\) denote the amplitude and cardinality
    of levels, respectively. \\(\\tau\\) and \\(\\alpha\\) represent the lower bound
    frequency of histogram distribution and a scaling factor, assigned a value of
    20 and 12, respectively. Fig. 7 a Representation of fine individual initialization
    levels \\(l_f\\) in Fig. 3c for several images. b Cluster seeds formation using
    level association (Fig. 6). c Consensus-oriented cluster seed merging and refined
    cluster seeds. Diamond, asterisk and pentagram represent red, green, and blue
    channel, respectively. Same colours represent constituent levels of a cluster
    seed. Additional initialization levels (I/L) can be detected in (b) via levels
    association in Fig. 6, compared to initial I/L detection in (a) (color figure
    online) Full size image Let us assume \\(l_c\\) be a coarse initialization level
    detected during the intra-histogram processing, where \\(L = \\{ {l_c}\\} _{c
    = 1}^K\\) represents the set containing coarse levels. Let w represents the filtering
    window range that evaluates each coarse level in L. For a coarse level \\(l_c\\)
    to be selected as fine level \\(l_f\\), the coarse level frequency \\(a_{l_c}\\)
    must be greater than the levels within the level range \\(l_w\\) , i.e. \\(a_{l_c}
    \\ge a_{l_w}\\) (Fig. 4). $$\\begin{aligned} {l_f} = \\{ {a_{l_c}} \\ge \\left[
    {{a_{l - w/2}},{a_{l + w/2}}} \\right] \\} \\ \\forall \\ l_c \\in L \\end{aligned}$$
    (5) The intuition behind the dynamic filtering window range is that the histogram
    distributions having non-uniform distribution pattern contain lesser individual
    levels and requires a smaller filtering window range and vice versa. Smaller window
    range avoids the loss of key levels. On the other hand, larger filtering range
    helps to eliminate slight variations in levels in uniform distributions, caused
    either due to lighting variations or hardware limitations. It prevents the segmentation
    of foreground/background into multiple redundant regions. The effect of filtering
    window range upon fine level selection process is presented in Fig. 5. After identifying
    individual fine levels \\(l_f\\), the next task is to optimally associate each
    fine level with appropriate level from the rest of the channels to complete the
    cluster seed. For this purpose, the inter-histogram level association framework
    processes the pixels related to fine levels, termed as sub-histogram processing,
    detecting single or multiple levels depending on the histogram distribution. This
    process is repeated for each \\(l_f\\) in all the three channels to form cluster
    seeds as presented in Fig. 6. The initial cluster seeds for several histogram
    distributions are presented in Fig. 7b. These cluster seeds contain proximity
    that leads to image over-segmentation. In order to mitigate this, a dynamic threshold
    based consensus-driven cluster seed merging mechanism is introduced. A comprehensive
    graphical representation of \\(l_f\\), level association for cluster seed formation
    and seed merging is presented in Fig. 7 (Fig. 8). Algorithm 1 Consensus-oriented
    cluster seeds merging algorithm. Full size image Fig. 8 Clustered feature spaces
    for image 100,099. a Scatter plot of randomly initialized K-means clustered feature
    space with 8 clusters (C = 8). Undesired cluster split is evident. b Scatter plot
    of EAIS clustered feature space without cluster seed merging (C = 11). Interestingly,
    K-means optimization process took 65 iterations for C = 11, compared to 38 iterations
    for the case of C = 8, that advocates the importance of appropriate number of
    clusters for speedy convergence. Over-segmentation in the feature space is evident.
    c Scatter plot of EAIS clustered feature space after consensus-oriented cluster
    seed merging. Number of clusters are reduced to 8 after seed merging. Appropriate
    merging of redundant clusters reduces the over-segmentation. It is worth mentioning
    that the segmentation quality is quite consistent even in case of random initialization
    (d). This strongly advocates the importance of accurate clusters determination
    to mitigate the K-means limitations. Note: Each colour represents a unique cluster
    Full size image Fig. 9 Representation of original and reconstructed feature space
    scatter plot and convergence trajectories of K-means cluster centre update for
    sample image 100,099. Distribution in (b) clearly depicts compact and dense representation
    compared to highly dispersed Lab colour distribution in (a). c and d represent
    K-means centroid update trajectories for randomly initialized and EAIS centroids,
    respectively. The randomly initialized centroids in (c) took 88 iterations during
    K-means optimization and apparently have a lengthy trail. d EAIS centroids took
    only 38 iteration to reach an optimal solution. It is noteworthy that there is
    imbalance in the update jumps in (c), few centroids converge after minor updates
    while others traverse a lot in feature space. This depicts the importance of better
    centroid initialization upon K-means solution. Note: For randomly initialized
    K-means, number of clusters are same as determined by EAIS. Red and green colour
    for each centroid trail represents starting and ending update (color figure online)
    Full size image 2.3 Dynamic consensus-driven cluster seeds merging Algorithm 1
    presents the pseudo-code for the proposed dynamic consensus-oriented cluster seeds
    merging. The cluster seed merging removes possible redundancy by combining statistically
    similar seeds. This process aims to improve clustering, segmentation quality,
    and reduce over-segmentation. Equation 6 calculates the inter-seeds similarity
    using the L1 distance. $$\\begin{aligned} d\\left( {{c_i},{c_j}} \\right) = \\left|
    {{R_i} - {R_j}} \\right| + \\left| {{G_i} - {G_j}} \\right| + \\left| {{B_i} -
    {B_j}} \\right| \\ \\ \\forall i \\ne j \\end{aligned}$$ (6) where \\(1 \\le i
    \\le M\\), \\(1 \\le j \\le N\\), M and N represent the amount of cluster seeds.
    \\(R_i\\), \\(G_i\\), and \\(B_i\\) and \\(R_j\\), \\(G_j\\) , and \\(B_j\\) are
    the level intensities of red, green, and blue channels of \\(i^{th}\\) and \\(j^{th}\\)
    cluster seeds, respectively. The seed merging threshold T in algorithm 1 is dynamically
    calculated utilizing the mean and standard deviation of maximal and minimal inter-seed
    dissimilarity average, as given in Eqs. 7–10. $$\\begin{aligned} {d_{{i_{\\max
    }}}}= & {} \\max \\left\\{ {\\left\\{ { {{{\\left\\| {c{}_i - c{}_j} \\right\\|
    }_1}} } \\right\\} }_{j = 1}^k \\right\\} _{i = 1}^k \\end{aligned}$$ (7) $$\\begin{aligned}
    {d_{{i_{\\min }}}}= & {} \\min \\left\\{ {\\left\\{ { {{{\\left\\| {c{}_i - c{}_j}
    \\right\\| }_1}} } \\right\\} }_{j = 1}^k \\right\\} _{i = 1}^k \\end{aligned}$$
    (8) \\(c_i\\) and \\(c_j\\) represent the ith and jth cluster seed, respectively.
    $$\\begin{aligned} {d_{avg}} = (d_{{i_{\\max }}} + d_{{i_{\\min }}})_{/2} \\end{aligned}$$
    (9) \\(d_{{i_{\\max }}}\\) and \\(d_{{i_{\\min }}}\\) represent maximum and minimum
    inter-cluster seed dissimilarity. $$\\begin{aligned} T = \\alpha \\times \\mu
    \\left( d_{avg} \\right) - \\times \\sqrt{\\sigma \\left( d_{avg} \\right) } \\end{aligned}$$
    (10) \\(\\mu\\) and \\(\\sigma\\) represent mean and standard deviation, respectively.
    \\(\\alpha\\) is weightage factor and assigned a value of 0.35. Figure 9 presents
    the scatter plot of raw feature space, deep reconstructed feature space, initial
    cluster seeds, and post-merging seeds, respectively. Figure 10a represents the
    effect of redundancy reduction caused by the consensus-driven merging, and it
    causes a significant reduction in the amount of cluster seeds. Moreover, it has
    a significant role in improving the performance of the proposed approach by boosting
    the convergence rate of K-means, as presented in Fig. 10b. Fig. 10 a Cluster seed
    redundancy reduction by dynamic consensus-driven merging and b number of iterations
    performed by K-means with different cluster seeds initialization schemes. The
    proposed EAIS requires the least iterations for optimal solution convergence Full
    size image 2.4 Morphological reconstruction (MR)-based spatial post-processing
    The absence of spatial information during K-means optimization causes inconsistency
    in the clustered pixels in the form of small, noisy regions. So, we introduce
    a morphological reconstruction (MR)-based spatial post-processing to enhance the
    consistency and optimize distribution characteristic of data. MR is able to preserve
    object contour and remove noisy pixels. There are two basic morphological reconstruction
    operations, morphological dilation and erosion reconstructions [42]. Morphological
    dilation reconstruction is denoted by \\(R_s^{\\delta }(m)\\) that is defined
    as: $$\\begin{aligned} R_s^{\\delta }(m) = \\delta _s^{(i)}m \\end{aligned}$$
    (11) where s is the clustered image, m is a marker image, and \\(m \\le s\\),
    \\(\\delta\\) represents dilation operation, and \\(\\delta _s^{(1)}=\\delta (m)
    \\wedge s\\), and \\(\\wedge\\) stands for the pointwise minimum. By duality,
    morphological erosion reconstruction, \\(R_s^{\\varepsilon }(m)\\) is defined
    as: $$\\begin{aligned} R_s^{\\epsilon }(m) = \\varepsilon _s^{(i)}m \\end{aligned}$$
    (12) \\(m \\ge s\\), \\(\\varepsilon\\) represents erosion operation, and \\(\\varepsilon
    _s^{(1)}=\\varepsilon (m) \\vee s\\), and \\(\\vee\\) stands for the pointwise
    maximum. The reconstruction of clustered image depends on the selection of marker
    images and mask images [42]. We employ segmented image as a mask image, and the
    transformation of the segmented image is considered as the marker image. In practical
    applications, \\(m = \\varepsilon (s)\\) meets the condition \\(g \\le f\\) for
    dilation reconstructions and \\(m = \\delta (s)\\) meets the condition \\(g \\ge
    f\\) for erosion reconstructions. Thus, \\(m = \\varepsilon (s)\\) and \\(m =
    \\delta (s)\\) are always used to obtain a marker image due to simplicity and
    efficacy. Based on the composition of erosion and dilation reconstructions, some
    reconstruction operators with stronger filtering capability can be obtained, such
    as morphological opening and closing reconstructions. Because morphological closing
    reconstruction is more suitable for noise removal, we employ \\(R^C\\) to modify
    segmented image and is defined as follows: $$\\begin{aligned} {R^C}\\left( s \\right)
    = R_{R_s^\\delta \\left( {\\varepsilon (s)} \\right) }^\\varepsilon \\left( {\\delta
    \\left( {R_s^\\delta \\left( {\\varepsilon \\left( s \\right) } \\right) } \\right)
    } \\right) \\end{aligned}$$ (13) \\(R^C\\) represents morphological closing that
    subsequently applies morphological dilation and morphological erosion reconstruction.
    Morphological dilation reconstruction employs erosion operation on mask image
    s to generate the marker image \\({\\varepsilon \\left( s \\right) }\\). 3 Experimental
    results and discussion In this section, we evaluate the performance of our proposed
    approach by comparing and analysing the segmentation results of various methods
    on BSDS500 benchmark dataset. The experiments are performed on a PC with an Intel
    Core (TM) i7-6700HQ, 2.60 GHz CPU and 8GB memory. Ground-truth segmentation prepared
    by multiple human subjects are presented in Fig. 11, that capture different visual
    perspectives. We select eleven methods that consists of classical and contemporary
    segmentation methods. These methods include SLIC [43], RFHA [24], HTFCM [23],
    PFHA [25], K-means[11] (random initialization), K-means (K-means++ initialization)
    [44], Backprop [35], SOD [38], SR-FCM [40], SE-AMR-SC [41], and MS [16]. For a
    fair comparison, we set the number of cluster for K-means same as determined by
    EAIS. For SLIC, K-means (Random and K-means++ initialization), Backprop, SR-FCM,
    SE-AMR-SC, and MS, we employ the source codes provided by the authors, and re-implement
    RFHA, HTFCM, PFHA, and SOD. Fig. 11 Multiple groundtruth (GT) representations
    of various sample images in BSDS500 benchmark. BSDS (http://www.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/)
    is a very popular image dataset and it is often used for the evaluation of image
    segmentation algorithms. For each image in BSDS, there are four to nine ground-truths
    segmentations that are delineated by different human subjects Full size image
    3.1 Quantitative evaluation Quantitative evaluation of experimental results is
    important to objectively analyse the performance of the segmentation results.
    Researchers have devised several metrics to assess the quality of segmentation
    results. In this study, we select five widely employed and versatile evaluation
    metrics that include probabilistic rand index (PRI), variation of information
    (VI), global consistency error (GCE), boundary displacement error (BDE), and boundary
    precision-recall (BPR). Higher score of PRI and BPR and lower score of VI, GCE,
    and BDE indicate better segmentation quality. A brief introduction of these metrics
    is given below. For convenience, we denote the machine segmentation as M, whereas
    G represents the ground-truth segmentation. 3.1.1 Probabilistic rand index (PRI)
    It operates by comparing the compatibility of assignments between pairs of cluster
    elements (pixels). The summation of pairs of pixels calculates the rand index
    with identical labels in M and G and different labels in both segmentations, divided
    by the total number of pixel pairs. Variation of the rand index has been proposed
    [45, 46] to deal with the case of multiple ground-truths segmentations. The probabilistic
    rand index, given a family of ground-truth segmentations \\(G_k\\), is defined
    as $$\\begin{aligned} \\textrm{PRI}\\left( {M,\\left\\{ {{G_k}} \\right\\} } \\right)
    = \\frac{1}{S}\\sum \\limits _{i < j} {\\left[ {{c_{ij}}{p_{ij}} + \\left( {1
    - {c_{ij}}} \\right) \\left( {1 - {p_{ij}}} \\right) } \\right] } \\end{aligned}$$
    (14) where \\(c_{ij}\\) represents the event that pixels i and j possess identical
    label and \\(p_{ij}\\) is its probability. S is the number of pixel pairs. 3.1.2
    Variation of information (VI) VI computes the sum of information loss and information
    gain between two segmentations M and G. $$\\begin{aligned} \\textrm{VI}\\left(
    {M,G} \\right) = H\\left( M \\right) + H\\left( G \\right) - 2I\\left( {M,G} \\right)
    \\end{aligned}$$ (15) H and I represent the entropies and mutual information between
    segmentation pair M and G, respectively. 3.1.3 Global consistency error (GCE)
    GCE computes the region intersection for each pixel in M and G. The GCE metric
    is nonnegative, and lower value indicates greater consistency. $$\\begin{aligned}
    \\textrm{GCE}\\left( {M,G} \\right)= & {} \\frac{1}{n}\\min \\left\\{ {\\sum \\limits
    _i {O\\left( {M,G,{p_i}} \\right) },O\\left( {G,M,{p_i}} \\right) } \\right\\}
    \\end{aligned}$$ (16) $$\\begin{aligned} O\\left( {M,G,{p_i}} \\right)= & {} \\frac{{\\left|
    {C\\left( {M,{p_i}} \\right) /C\\left( {G,{p_i}} \\right) } \\right| }}{{C\\left(
    {M,{p_i}} \\right) }} \\end{aligned}$$ (17) where \\(C(M, p_i)\\) and \\(C(G,
    p_i)\\) represent corresponding regions in M and G for a pixel \\(p_i\\) in pixel
    set P, \\(P = \\left\\{ {{p_1},{p_2},{p_3},\\ldots ,{p_n}} \\right\\}\\). Table
    1 Objective performance evaluation of proposed EAIS with several methods on BSD500
    benchmark Full size table Table 2 PRI, VI, GCE, and BDE score of various methods
    for twelve sample images in Figs. 13 and 14 Full size table 3.1.4 Boundary displacement
    error (BDE) BDE computes the average displacement error of boundary pixels in
    a pair of segmentations. Mainly, it defines the error of boundary pixel as the
    distance between the pixel and the closest pixel in the other boundary image as,
    $$\\begin{aligned} \\textrm{BDE}\\left( {M,G} \\right) = \\frac{1}{2}\\left( {\\frac{1}{{{N_1}}}\\sum
    \\limits _i^{{N_1}} {d\\left( {{p_i},M} \\right) } + \\frac{1}{{{N_2}}}\\sum \\limits
    _i^{{N_2}} {d\\left( {{p_i},G} \\right) } } \\right) \\end{aligned}$$ (18) Fig.
    12 a PRI score plot for various methods on BSDS500 benchmark. EAIS maintains a
    higher score for majority of the benchmark. b presents the boundary precision-recall
    plot for the compared methods. EAIS maintains the balance between precision and
    recall Full size image 3.1.5 Boundary precision-recall (BPR) To further evaluate
    the segmentation results in terms of fidelity of segmented region boundaries to
    ground truth and vice versa, boundary precision-recall [47, 48] is employed. Boundary
    precision computes the ratio of boundary pixels in M matching to the boundary
    pixels in G. It considers a boundary pixel at correct spatial location in reference
    to the ground truth when the minimum distance between M and G pixel is within
    a threshold. We set threshold \\(\\epsilon =5\\) in our experiments. $$\\begin{aligned}
    \\textrm{BP}({\\mathcal {B}}^{\\mathcal {M}},\\mathcal {B}^{{\\mathcal {G}}})
    = \\frac{{TP\\left( \\mathcal {B}^{\\mathcal {M}},\\mathcal {B}^{{\\mathcal {G}}}
    \\right) }}{{TP(\\mathcal {B}^{\\mathcal {M}},\\mathcal {B}^{{\\mathcal {G}}})
    + FP(\\mathcal {B}^{\\mathcal {M}},\\mathcal {B}^{{\\mathcal {G}}})}} \\end{aligned}$$
    (19) Boundary recall calculates the proportion of boundary pixels in G matching
    with boundary pixels in M. It adds an extra dimension to the quantitative evaluation
    and depicts the performance in terms of contours purity. $$\\begin{aligned} \\textrm{BR}(\\mathcal
    {B}^{\\mathcal {M}},\\mathcal {B}^{{\\mathcal {G}}}) = \\frac{{TP\\left( \\mathcal
    {B}^{\\mathcal {M}}, \\mathcal {B}^{{\\mathcal {G}}}\\right) }}{{TP(\\mathcal
    {B}^{\\mathcal {M}},\\mathcal {B}^{{\\mathcal {G}}}) + FN(\\mathcal {B}^{\\mathcal
    {M}},\\mathcal {B}^{\\mathcal {G}})}} \\end{aligned}$$ (20) where \\(\\mathcal
    {B}^{\\mathcal {M}} = \\left\\{ {b_1^m,\\ldots } \\right\\}\\) and \\(\\mathcal
    {B}^{{\\mathcal {G}}} = \\left\\{ {b_1^{{g}},\\ldots } \\right\\}\\) denote a
    set of boundary pixels in M and G. FN and TP are the number of false negatives
    and true positives boundary pixels, respectively. If a boundary pixel in M exists
    within a local patch centred on an arbitrary boundary pixel in G, the pixel is
    counted as TP. We present the average quantitative scores for the segmentation
    results of various methods on BSD500 in Table 1. We also employ twelve sample
    images to quantitatively compare the proposed EAIS with other methods presented
    in Table 2. The direction of arrows in the top row represents the desired trend
    in the evaluation metrics, and boldface indicates the best result. Table 1 indicates
    that our proposed approach outperforms the compared segmentation methods. Moreover,
    we also present the PRI score plot for the entire BSD500 benchmark in Fig. 12a.
    The proposed EAIS approach maintains a higher score compared to other methods
    that indicates the consistent results of the proposed approach. Fig. 13 Segmentation
    results of various methods for several sample test images presented in Table 2
    Full size image Fig. 14 Segmentation results of various methods for several sample
    test images presented in Table 2 Full size image 3.2 Qualitative evaluation Quantitative
    evaluation is considered a primary evaluation measure in image segmentation, however,
    it suffers from a low dynamic range of metrics scores. The scores are unable to
    fully map the extent of increment or decrement in the segmentation quality. On
    the other hand, humans possess enormous analytical and evaluation abilities. So,
    we present several segmentation results for a tangible evaluation of segmentation
    results. We compare the segmentation results of twelve sample images in Figs.
    13 and 14. We present original images, false-colour representations, and segmented
    colour images overlayed with region boundaries for better visual understanding.
    The clustering performance of K-means (Random & K-means++) improves by providing
    the optimal number of clusters. K-means++ initialization produces slightly better
    clusters than K-means because of the distant cluster centroids. Backprop and SOD
    display decent performances. The former slightly under-segments the images, while
    the latter exhibits over-segmentation. SR-FCM also performs well, but it is affected
    by the convergence issues e.g. image 41,004. The results produced by SE-AMR-SC
    are more towards the under-segmentation. Even though it achieves a higher PRI
    score, it exhibits the drawback of pixel misclassification. MS achieves overall
    competitive performance; however, it fails to preserve the boundaries for low
    contrast and tiny objects, e.g. 108,073 and 100,080. Our proposed method produces
    a superior segmentation performance by maintaining the balance between over and
    under-segmentation and avoids faulty pixel-cluster assignments. 3.3 Discussion
    Overall, K-means produces over-segmented results, consequently achieves a lower
    precision and higher recall score in BPR plot, presented in Fig. 12b. SR-FCM employs
    morphological reconstruction (MR) in the initial stage for image smoothing as
    a pre-requisite for clustering-based image segmentation and during the cluster-pixel
    membership refinement. However, the results lag by a considerable margin because
    it lacks the initialization mechanism for the FCM clustering algorithm. SE-AMR-SC
    produces acceptable scores in the quantitative evaluation, but the qualitative
    evaluation clearly highlights severe under-segmentation. Moreover, the BPR plot
    also endorses this behaviour as it achieves a higher precision due to under-segmentation
    and a lower recall score represents the misclassified G regions. In Backprop and
    SOD, larger regions tend to occlude the smaller regions due to continuous refined
    label map generation. PFHA, HTFCM, and RFHA suffer from pixel misclassification
    as depicted by the the segmentation results of 100,080, 100,099, and 101,085 images
    in Figs. 13 and 14. HTFCM and PFHA produce over-segmented results for image 135,069
    in Fig. 13. MS produces acceptable results. However, occasionally suffers from
    over-segmentation and merging of foreground regions into the background, e.g.
    image 271031. On the other hand, our proposed EAIS approach provides a dynamic,
    adaptive, content-driven, and multi-module-based hierarchical approach. The first
    module determines intra-histogram coarse levels based on the individual histograms.
    It establishes the association of individual levels to obtain the cluster seeds.
    To eliminate the over-segmentation issue, we fine-tune redundant cluster seeds
    and perform K-means clustering for image segmentation. Morphological reconstruction
    is employed in the final stage to remove noisy regions and induce spatial awareness.
    The detailed qualitative results for our proposed EAIS appraoch are presented
    in Fig. 15. Fig. 15 Qualitative evaluation of the proposed EAIS segmentation results
    on a variety of challenging scenes in BSDS500 benchmark Full size image Although
    our EAIS segmentation approach performs well for a variety of natural scenes,
    however, segmentation quality is reduced in camouflaged foreground and background
    scenes, as can be observed in Fig. 16. EAIS incorporates feature space-based cluster
    seed merging framework in the pre-clustering phase, a future research direction
    could be to explore the induction of spatial-aware region merging mechanism in
    the post-clustering phase. Diverse regional features with spatial-aware region
    merging have the potential to further improve the segmentation results. Fig. 16
    Segmentation results of our proposed EAIS approach on few camouflaged scenes.
    First and second row contains original images and the segmentation results of
    our EAIS approach, respectively Full size image 3.4 Algorithm efficiency The computational
    complexity is a crucial factor in the practicability of any approach, especially
    in real-time consumer electronic products. This section compares the computational
    efficiency of the proposed approach EAIS and other methods. Table 1 tabulates
    the average execution time of the proposed and compared segmentation approaches
    for BSD500 benchmark. The average execution time of SR-FCM, Backprop, and SOD
    is relatively higher than EAIS. The reason is that SR-FCM, Backprop, and SOD require
    a large number of computations to converge. RFHA, HTFCM, and PFHA exhibit a higher
    computation time due to initialization process. EAIS approach’s greater efficiency
    has two reasons. First, initialization mechanism operates on histogram level instead
    of pixel level, that is several hundred times more compact than the pixel feature
    space. Second, the near-optimal initialization ensures the speedy convergence
    of clustering algorithm. 4 Conclusion This paper introduced a nonparametric, autonomous,
    efficient, accurate, and dynamic clustering-based image segmentation approach
    (EAIS). The proposed approach aims to eliminate the dependence of the clustering
    outcome upon the pre-requisite parameters. EAIS initiates with deep image reconstruction
    and intra-histogram-level detection, followed by the inter-histogram-level trio
    formation. Consensus-oriented cluster seed merging framework further optimizes
    the seeds by minimizing the redundancy and suppressing over-segmentation. The
    standard fine-tune seeds cluster the image pixels in a given number of segments.
    Morphological reconstruction is applied to eliminate noisy pixels and enhances
    the segmentation consistency. Our proposed EAIS approach performs well in both
    qualitative and quantitative evaluation measures on the BSD500 benchmark dataset.
    Furthermore, EAIS achieves the least computation time that advocates its real-time
    application feasibility. Data availability The authors confirm that the dataset
    from which this study is conducted can be found in the article. Code availability
    Some or all of the code used during the study is available on request from the
    corresponding author. References Mittal H, Pandey AC, Saraswat M, Kumar S, Pal
    R, Modwel G (2022) A comprehensive survey of image segmentation: clustering methods,
    performance parameters, and benchmark datasets. Multimedia Tools Appl 81(24):35001–35026
    Article   Google Scholar   Xia Y, Nie L, Zhang L, Yang Y, Hong R, Li X (2016)
    Weakly supervised multilabel clustering and its applications in computer vision.
    IEEE Trans Cybern 46(12):3220–3232 Article   PubMed   Google Scholar   Minaee
    S, Boykov Y, Porikli F, Plaza A, Kehtarnavaz N, Terzopoulos D (2022) Image segmentation
    using deep learning: a survey. IEEE Trans Pattern Anal Mach Intell 44(7):3523–3542.
    https://doi.org/10.1109/TPAMI.2021.3059968 Article   PubMed   Google Scholar   Chen
    XW, Huang T (2003) Facial expression recognition: a clustering-based approach.
    Pattern Recognit Lett 24(9–10):1295–1302 Article   ADS   Google Scholar   Jain
    AK (2010) Data clustering: 50 years beyond k-means. Pattern Recognit Lett 31(8):651–666
    Article   ADS   Google Scholar   Li BN, Chui CK, Chang S, Ong SH (2011) Integrating
    spatial fuzzy clustering with level set methods for automated medical image segmentation.
    Comput Biol Med 41(1):1–10 Article   ADS   PubMed   Google Scholar   Cobos C,
    Muñoz-Collazos H, Urbano-Muñoz R, Mendoza M, León E, Herrera-Viedma E (2014) Clustering
    of web search results based on the cuckoo search algorithm and balanced Bayesian
    information criterion. Inf Sci 281:248–264 Article   Google Scholar   Kim KJ,
    Ahn H (2008) A recommender system using GA k-means clustering in an online shopping
    market. Expert Syst Appl 34(2):1200–1209 Article   Google Scholar   Curiskis SA,
    Drake B, Osborn TR, Kennedy PJ (2020) An evaluation of document clustering and
    topic modelling in two online social networks: Twitter and reddit. Inf. Process.
    Manag. 57(2):102034 Article   Google Scholar   Bhange M, Hingoliwala H (2015)
    Smart farming: pomegranate disease detection using image processing. Procedia
    Comput Sci 58:280–288 Article   Google Scholar   Celebi ME, Kingravi HA, Vela
    PA (2013) A comparative study of efficient initialization methods for the k-means
    clustering algorithm. Expert Syst Appl 40(1):200–210 Article   Google Scholar   Ding
    Y, Fu X (2016) Kernel-based fuzzy c-means clustering algorithm based on genetic
    algorithm. Neurocomputing 188:233–238 Article   Google Scholar   Fränti P, Sieranoja
    S (2019) How much can k-means be improved by using better initialization and repeats?
    Pattern Recognit 93:95–112 Article   ADS   Google Scholar   Khan SS, Ahmad A (2004)
    Cluster center initialization algorithm for k-means clustering. Pattern Recognit
    Lett 25(11):1293–1302 Article   ADS   Google Scholar   Arthur D, Vassilvitskii
    S (2006) k-means++: the advantages of careful seeding. Tech. Rep, Stanford Comaniciu
    D, Meer P (2002) Mean shift: a robust approach toward feature space analysis.
    IEEE Trans Pattern Anal Mach Intell 24(5):603–619 Article   Google Scholar   Yu
    Z, Au OC, Zou R, Yu W, Tian J (2010) An adaptive unsupervised approach toward
    pixel clustering and color image segmentation. Pattern Recognit 43(5):1889–1906
    Article   ADS   Google Scholar   Maniezzo ACMDV (1992) Distributed optimization
    by ant colonies. In: Toward a practice of autonomous systems: proceedings of the
    first European conference on artificial life. Mit Press, p 134 Yu Z, Au OC, Zou
    R, Yu W, Tian J (2010) An adaptive unsupervised approach toward pixel clustering
    and color image segmentation. Pattern Recognit 43(5):1889–1906 Article   ADS   Google
    Scholar   Bhoyar K, Kakde O (2010) Color image segmentation based on JND color
    histogram. Int J Image Process (IJIP) 3(6):283 Google Scholar   Chen K, Ma Y,
    Jun L (2012) Segmentation by fusion of self-adaptive SFCM cluster in multi-color
    space components. Int J Image Process (IJIP) 6(2):157 Google Scholar   Zheng J,
    Zhang D, Huang K, Sun Y (2017) Adaptive image segmentation method based on the
    fuzzy c-means with spatial information. IET Image Process 12(5):785–792 Article   Google
    Scholar   Tan KS, Isa NAM (2011) Color image segmentation using histogram thresholding-fuzzy
    c-means hybrid approach. Pattern Recognit 44(1):1–15 Article   ADS   Google Scholar   Tan
    KS, Isa NAM, Lim WH (2013) Color image segmentation using adaptive unsupervised
    clustering approach. Appl Soft Comput 13(4):2017–2036 Article   Google Scholar   Tan
    KS, Lim WH, Isa NAM (2013) Novel initialization scheme for fuzzy c-means algorithm
    on color image segmentation. Appl Soft Comput 13(4):1832–1852 Article   Google
    Scholar   Vantaram SR, Saber E (2011) An adaptive Bayesian clustering and multivariate
    region merging based technique for efficient segmentation of color images. In:
    Acoustics, speech and signal processing (ICASSP), 2011 IEEE international conference
    on. IEEE, pp 1077–1080 Sujaritha M, Annadurai S (2010) Color image segmentation
    using adaptive spatial Gaussian mixture model. Int J Signal Process 6(1):28–32
    Google Scholar   Rosenberger C, Chehdi K (2000) Unsupervised clustering method
    with optimal estimation of the number of clusters: application to image segmentation.
    In: Pattern recognition, 2000. Proceedings. 15th international conference on,
    vol 1. IEEE, pp 656–659 Ilea DE, Whelan PF (2008) CTex-an adaptive unsupervised
    segmentation algorithm based on color-texture coherence. IEEE Trans Image Process
    17(10):1926–1939 Article   ADS   MathSciNet   PubMed   Google Scholar   Ugarriza
    LG, Saber E, Vantaram SR, Amuso V, Shaw M, Bhaskar R (2009) Automatic image segmentation
    by dynamic region growth and multiresolution merging. IEEE Trans Image Process
    18(10):2275–2288 Article   ADS   MathSciNet   PubMed   Google Scholar   Zhang
    Q, Chi Y, He N (2015) Color image segmentation based on a modified k-means algorithm.
    In: Proceedings of the 7th international conference on internet multimedia computing
    and service. ACM, p 46 Khan Z, Ni J, Fan X, Shi P (2017) An improved k-means clustering
    algorithm based on an adaptive initial parameter estimation procedure for image
    segmentation. Int J Innov Comput Inf Control 13(5):1509–1525 Google Scholar   Khan
    Z, Yang J, Zheng Y (2019) Efficient clustering approach for adaptive unsupervised
    colour image segmentation. IET Image Process 13(10):1763–1772. https://doi.org/10.1049/iet-ipr.2018.5976
    Article   Google Scholar   Khan Z, Yang J (2019) Image segmentation via multi
    dimensional color transform and consensus based region merging. Multimedia Tools
    Appl 78:31347–31364. https://doi.org/10.1007/s11042-019-07906-5 Article   Google
    Scholar   Kanezaki A (2018) Unsupervised image segmentation by backpropagation.
    In: 2018 IEEE international conference on acoustics, speech and signal processing
    (ICASSP). IEEE, pp 1543–1547 Kim W, Kanezaki A, Tanaka M (2020) Unsupervised learning
    of image segmentation based on differentiable feature clustering. IEEE Trans Image
    Process 29:8055–8068 Article   ADS   Google Scholar   Zhou L, Wei W (2020) DIC:
    deep image clustering for unsupervised image segmentation. IEEE Access 8:34481–34491
    Article   Google Scholar   İmamoǧlu N, Ding G, Fang Y, Kanezaki A, Kouyama T,
    Nakamura R (2019) Salient object detection on hyperspectral images using features
    learned from unsupervised segmentation task. In: ICASSP 2019—2019 IEEE international
    conference on acoustics, speech and signal processing (ICASSP), pp 2192–2196.
    https://doi.org/10.1109/ICASSP.2019.8682522 Wang C, Yang B, Liao Y (2017) Unsupervised
    image segmentation using convolutional autoencoder with total variation regularization
    as preprocessing. In: 2017 IEEE international conference on acoustics, speech
    and signal processing (ICASSP). IEEE, pp 1877–1881 Lei T, Jia X, Zhang Y, He L,
    Meng H, Nandi AK (2018) Significantly fast and robust fuzzy c-means clustering
    algorithm based on morphological reconstruction and membership filtering. IEEE
    Trans Fuzzy Syst 26(5):3027–3041 Article   Google Scholar   Lei T, Jia X, Liu
    T, Liu S, Meng H, Nandi AK (2019) Adaptive morphological reconstruction for seeded
    image segmentation. IEEE Trans Image Process 28(11):5510–5523 Article   ADS   MathSciNet   PubMed   Google
    Scholar   Chen JJ, Su CR, Grimson WEL, Liu JL, Shiue DH (2011) Object segmentation
    of database images by dual multiscale morphological reconstructions and retrieval
    applications. IEEE Trans Image Process 21(2):828–843 Article   ADS   MathSciNet   PubMed   Google
    Scholar   Achanta R, Shaji A, Smith K, Lucchi A, Fua P, Süsstrunk S (2012) SLIC
    superpixels compared to state-of-the-art superpixel methods. IEEE Trans Pattern
    Anal Mach Intell 34(11):2274–2282 Article   PubMed   Google Scholar   Vassilvitskii
    S, Arthur D (2006) k-means++: the advantages of careful seeding. In: Proceedings
    of the eighteenth annual ACM-SIAM symposium on discrete algorithms, pp 1027–1035
    Unnikrishnan R, Pantofaru C, Hebert M (2007) Toward objective evaluation of image
    segmentation algorithms. IEEE Trans Pattern Anal Mach Intell 29(6):929–944 Article   PubMed   Google
    Scholar   Meilǎ M (2005) Comparing clusterings: an axiomatic view. In: Proceedings
    of the 22nd international conference on machine learning, pp 577–584 Estrada FJ,
    Jepson AD (2005) Quantitative evaluation of a novel image segmentation algorithm.
    In: 2005 IEEE computer society conference on computer vision and pattern recognition
    (CVPR’05), vol 2. IEEE, pp 1132–1139 Stutz D (2015) Superpixel segmentation: an
    evaluation. In: German conference on pattern recognition. Springer, pp 555–562
    Download references Acknowledgements This research is partly supported by NSFC,
    China (No:61572315) and Committee of Science and Technology, Shanghai, China (No:17JC1403000).
    Author information Authors and Affiliations Artificial Intelligence Technology
    Center (AITeC), NCP, Islamabad, Pakistan Zubair Khan Institute of Image Processing
    and Pattern Recognition, Shanghai Jiao Tong University, Shanghai, China Zubair
    Khan & Jie Yang Institute of Medical Robotics, Shanghai Jiao Tong University,
    Shanghai, China Jie Yang Corresponding author Correspondence to Zubair Khan. Ethics
    declarations Conflict of interest The authors declare that they have no known
    competing financial interests or personal relationships that could have appeared
    to influence the work reported in this paper. Additional information Publisher''s
    Note Springer Nature remains neutral with regard to jurisdictional claims in published
    maps and institutional affiliations. Rights and permissions Springer Nature or
    its licensor (e.g. a society or other partner) holds exclusive rights to this
    article under a publishing agreement with the author(s) or other rightsholder(s);
    author self-archiving of the accepted manuscript version of this article is solely
    governed by the terms of such publishing agreement and applicable law. Reprints
    and permissions About this article Cite this article Khan, Z., Yang, J. Nonparametric
    K-means clustering-based adaptive unsupervised colour image segmentation. Pattern
    Anal Applic 27, 17 (2024). https://doi.org/10.1007/s10044-024-01228-5 Download
    citation Received 18 April 2023 Accepted 04 December 2023 Published 28 February
    2024 DOI https://doi.org/10.1007/s10044-024-01228-5 Share this article Anyone
    you share the following link with will be able to read this content: Get shareable
    link Provided by the Springer Nature SharedIt content-sharing initiative Keywords
    Unsupervised colour image segmentation Deep image reconstruction Nonparametric
    K-means clustering Optimal cluster seeds Adaptive threshold Dynamic and mutual
    consensus-driven cluster seed merging Morphological reconstruction Use our pre-submission
    checklist Avoid common mistakes on your manuscript. Sections Figures References
    Abstract Introduction Proposed approach Experimental results and discussion Conclusion
    Data availability Code availability References Acknowledgements Author information
    Ethics declarations Additional information Rights and permissions About this article
    Advertisement Discover content Journals A-Z Books A-Z Publish with us Publish
    your research Open access publishing Products and services Our products Librarians
    Societies Partners and advertisers Our imprints Springer Nature Portfolio BMC
    Palgrave Macmillan Apress Your privacy choices/Manage cookies Your US state privacy
    rights Accessibility statement Terms and conditions Privacy policy Help and support
    129.93.161.219 Big Ten Academic Alliance (BTAA) (3000133814) - University of Nebraska-Lincoln
    (3000134173) © 2024 Springer Nature"'
  inline_citation: '>'
  journal: Pattern Analysis and Applications
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Nonparametric K-means clustering-based adaptive unsupervised colour image
    segmentation
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Wang Y.
  - Li Y.
  - Wang J.
  - Lv H.
  - Guo J.
  citation_count: '0'
  description: During the tracking of moving targets in dynamic scenes, efficiently
    handling outliers in the optical flow and maintaining robustness across various
    motion amplitudes represents a critical challenge. So far, studies have used thresholding
    and local consistency based approaches to deal with optical outliers. However,
    there is subjectivity through expert-defined thresholds or delineated regions,
    and therefore these methods do not perform consistently enough under different
    target motion amplitudes. Other studies have focused on complex statistical-mathematical
    modeling which, although theoretically valid, requires significant computational
    resources. Aiming at the above problems this paper proposes a new method to calculate
    the optical outliers by using stochastic neighborhood graph combined with the
    Borda counting method, which reduces the computation amount on the basis of objectively
    eliminating the outliers. Sparse optical flow (SOF) values are used as the overall
    population and the outlier and inlier SOF values are used as samples. Analyze
    the dissimilarity between SOF data points, obtaining the dissimilarity matrix,
    introducing the Gaussian function to smooth and reduce the dimensionality of the
    dissimilarity matrix, and then normalizing the smoothing matrix to generate the
    binding matrix, where the probability sum of each node to other nodes in the matrix
    is equal to 1. Stochastic neighborhood graphs are then generated based on a binding
    matrix to obtain the outlier probabilities of data points in different neighborhood
    graphs, and outlier samples are obtained based on the probability. To avoid the
    subjectivity of the expert thresholds, the outlier probabilities are weighted
    and ranked to calculate the data point Borda scores to obtain accurate optical
    outliers. The experimental results show that the method in this paper is robust
    to different amplitude motions and real scenarios, and the accuracy, precision
    and recall of outliers elimination are better than the current mainstream algorithms.
  doi: 10.1088/2632-2153/ad1a50
  full_citation: '>'
  full_text: '>

    "We value your privacy Clicking the \"Accept All\" button means you are accepting
    analytics and third-party cookies. We use cookies to optimise site functionality
    and give you the best possible experience. To control which cookies are set, click
    \"Customize\". Privacy and Cookies policy Customize Accept All Skip to content
    IOP Science home Accessibility Help Search Journals Books Publishing Support Login
    Machine Learning: Science and Technology PAPER • THE FOLLOWING ARTICLE IS OPEN
    ACCESS Sparse optical flow outliers elimination method based on Borda stochastic
    neighborhood graph Yifan Wang1, Yang Li2,1, Jiaqi Wang1, Haofeng Lv1 and Jinshi
    Guo1 Published 5 February 2024 • © 2024 The Author(s). Published by IOP Publishing
    Ltd Machine Learning: Science and Technology, Volume 5, Number 1 Citation Yifan
    Wang et al 2024 Mach. Learn.: Sci. Technol. 5 015022 DOI 10.1088/2632-2153/ad1a50
    Download Article PDF Figures References Open science   Article metrics 137 Total
    downloads Submit Submit to this Journal Share this article Article and author
    information   Abstract During the tracking of moving targets in dynamic scenes,
    efficiently handling outliers in the optical flow and maintaining robustness across
    various motion amplitudes represents a critical challenge. So far, studies have
    used thresholding and local consistency based approaches to deal with optical
    outliers. However, there is subjectivity through expert-defined thresholds or
    delineated regions, and therefore these methods do not perform consistently enough
    under different target motion amplitudes. Other studies have focused on complex
    statistical-mathematical modeling which, although theoretically valid, requires
    significant computational resources. Aiming at the above problems this paper proposes
    a new method to calculate the optical outliers by using stochastic neighborhood
    graph combined with the Borda counting method, which reduces the computation amount
    on the basis of objectively eliminating the outliers. Sparse optical flow (SOF)
    values are used as the overall population and the outlier and inlier SOF values
    are used as samples. Analyze the dissimilarity between SOF data points, obtaining
    the dissimilarity matrix, introducing the Gaussian function to smooth and reduce
    the dimensionality of the dissimilarity matrix, and then normalizing the smoothing
    matrix to generate the binding matrix, where the probability sum of each node
    to other nodes in the matrix is equal to 1. Stochastic neighborhood graphs are
    then generated based on a binding matrix to obtain the outlier probabilities of
    data points in different neighborhood graphs, and outlier samples are obtained
    based on the probability. To avoid the subjectivity of the expert thresholds,
    the outlier probabilities are weighted and ranked to calculate the data point
    Borda scores to obtain accurate optical outliers. The experimental results show
    that the method in this paper is robust to different amplitude motions and real
    scenarios, and the accuracy, precision and recall of outliers elimination are
    better than the current mainstream algorithms. Export citation and abstract BibTeX
    RIS Previous article in issue Next article in issue Original content from this
    work may be used under the terms of the Creative Commons Attribution 4.0 license.
    Any further distribution of this work must maintain attribution to the author(s)
    and the title of the work, journal citation and DOI. 1. Introduction Camera movement
    tracking technology (CMTT) [1] has a wide range of applications, such as video
    surveillance [2], robot vision [3], and unmanned vehicles [4], and medical image
    analysis [5]. Video surveillance systems typically require object tracking to
    ensure security [2]. Robot vision systems rely on precise location information
    to perform various tasks [3], while autonomous driving technology depends on CMTT
    for environmental perception and navigation, ensuring safety and efficiency during
    vehicle operation [4]. In the field of medical image analysis, CMTT is used to
    stabilize and calibrate medical images, such as x-rays, CT scans, MRI, and ultrasound
    images. By tracking camera motion, doctors can more accurately locate and diagnose
    a patient''s condition, reducing errors and improving the success rate of surgeries.
    However, there are still some challenges in the application of this technique,
    owing to complex environmental changes and the diversity of target movements.
    Precision optical flow value is the key to achieving CMTT. To improve the accuracy
    of optical flow data, many researchers have obtained a precise optical flow value
    by improving the robustness of the optical flow method. Sparse optical flow value
    (SOF) [6] is the calculation of a SOF field using the main features of the moving
    target (corner points, contours, texture features, etc.) and estimating the position
    of the main features in the next image frame by comparing the pixels of two adjacent
    frames. SOF outliers generated in special scenes usually refer to errors in optical
    flow values caused by factors such as occlusion and illumination changes due to
    large movements of the target, and loss of feature pixels due to small amplitude
    movements. These light displacement group values seriously affect the analysis
    results and need to be eliminated. Currently, researchers have widely used methods
    based on threshold [7–9], local area consistency [10, 11], and statistics [12]
    to eliminate outliers in the optical flow values. The threshold-based method is
    based on the size of the optical flow value of the pixel points in the optical
    flow field. A threshold is set, and the pixel points with an optical flow value
    exceeding the threshold is defined as outliers. Zheng et al [7] combined median
    filtering and total variational regularization techniques to remove outliers and
    noise from optical flow values, improving the robustness and precision of optical
    flow estimation. Silva et al [8] utilized a wavelet transform to decompose the
    signal into different frequency components and performed threshold processing
    based on the statistical characteristics of each component to eliminate optical
    flow errors caused by noise. Doshi and Kiran [9] combines a total variational
    energy function with an optical flow estimation model. This method is able to
    suppress noise while preserving image edge information, but the threshold-based
    method is better able to handle outliers significantly larger than the threshold,
    and it fails for some outliers close to the threshold. Based on the local area
    consistency method, the average optical flow value of the pixel points within
    a local area was calculated, assuming that the optical flow was approximately
    uniform and the pixel points that were larger than the average optical flow value
    were considered outliers. The optical flow field was estimated using an optical
    flow estimator based on a local direction filter [10]. The local direction filter
    filters the optical flow field and protects edge information to eliminate outliers,
    thereby improving the precision of the optical flow method. Rao et al [11] adopted
    an algorithm based on a minimum value filter to reduce the optical flow error
    values introduced by the image noise and distortion. The method based on a statistical
    approach is to model the optical flow field using Gaussian distribution, Laplace
    distribution, etc [12], and to use this model to detect outliers and eliminate
    them. In summary, threshold-based methods are generally not suitable for handling
    non-uniformly distributed outlier values since they cannot adapt to varying outlier
    density across different regions. Local area consistency-based methods miss some
    true outliers when the defined local regions are too small, and they may include
    non-outliers if the regions are too large. Statistical-based methods require complex
    mathematical computations, which can lead to higher computational complexity,
    especially when dealing with large-scale image data. To address the limitations
    of existing methods, this paper proposed a SOF outlier elimination method based
    on Borda stochastic neighborhood graph (B-SNG). The proposed approach employs
    a stochastic neighborhood graph-based method to calculate the outlier probability
    for each optical flow value, avoiding the issue of excessive computational complexity
    associated with statistical methods and eliminating restrictions related to data
    distribution. Additionally, it suggests the use of the Borda counting method to
    prevent the problem of non-uniform density distribution and increased false elimination
    rates caused by manually set thresholds and local area consistency methods. The
    overall logic of the B-SNG algorithm proposed in this study is similar to that
    of the SOS algorithm [13]. The difference is that SOS obtains the affinity matrix
    A by calculating the variance between eigenvalues for dimensionality reduction,
    whereas this study uses the Gaussian function to smooth dimensionality reduction
    to reduce the process of calculating variance and improve the speed of the algorithm.
    The SNG constructed by SOS and the directed edges of the bound nodes are all random
    processes. The resultant values of each calculation are not fixed, and the expert
    threshold is used to determine whether they are outliers, which is subjective.
    In this study, we propose the use of the Borda counting method for multi-weighted
    outlier voting and eliminate outliers by ranking the order of Borda scores. B-SNG
    is an unsupervised learning method that is insensitive to noise and can automatically
    eliminate outliers and eliminate some erroneous vectors caused by motion magnitude,
    etc. In this study, the outlier elimination mechanism is used for robust SOF to
    ensure high recall while improving the accuracy and precision of the SOF under
    different motion modes. As shown in figure 1, depth image information was obtained
    using charge-coupled device (CCD) and velodyne sensor (VS) techniques. Using perspective
    transformation technology, the motion relationship of an object in a 3D video
    stream captured by a mobile camera in space is transformed into the changing relationship
    between pixels in a 2D image sequence at any time. The Lucas–Kanade SOF method
    was used to obtain the optical flow values of feature points in the image sequence
    as the SOF dataset. SOF belongs to clustering distribution, and this study introduces
    stochastic neighborhood graphs and Borda counting method for the elimination of
    optical flow outlier values. First, we used the Euclidean formula to calculate
    the dissimilarity between each data point. The Gaussian function was used to smooth
    the dimension reduction of the dissimilarity matrix to obtain a smooth matrix.
    A smoothing matrix was then normalized to obtain a binding matrix with a probability
    sum of 1 for each element in each row. A stochastic neighborhood graph is generated
    based on the binding matrix, and the outlier probability of data point xa is obtained
    by calculating the probability of selecting data point xa as its neighbor from
    the stochastic data point xb . For different stochastic neighborhood graphs, the
    outlier probabilities of the data points are calculated differently. The Borda
    counting method is used to assign adaptive weights to the data points, and the
    Borda scores of the data points are calculated as outlier probability scores after
    multiple iterations to reduce the subjective influence of expert thresholds. Zoom
    In Zoom Out Reset image size Figure 1. Flow chart of the method in this article.
    Download figure: Standard image High-resolution image The main contributions of
    this study are as follows: (1)   This study constructs an accurate SOF feature
    dataset based on feature point detection, Odataset. It provides strong data support
    for research on optical flow outlier elimination. (2)   The first uses the concepts
    of stochastic neighborhood graphs and Borda counting for SOF outlier elimination.
    The use of stochastic neighborhood graphs to calculate the outlier probability
    of optical flow values avoids a large amount of data volume computation compared
    to statistical based methods. The Broda counting method is also used instead of
    the expert thresholds method, which solves the problem of uneven density distribution
    and false elimination caused by the thresholds and local region consistency based
    methods. (3)   An unsupervised outlier elimination method called B-SNG is proposed.
    This method calculates the outlier probability of optical flow values based on
    stochastic neighborhood graphs and adaptively determines the weight of the outlier
    probability using the Borda counting method. The optical flow outliers can be
    effectively eliminated, and the accuracy and precision of the SOF can be improved,
    while maintaining a high recall rate, which is applicable to the case of different
    motion modes. The study is structured as follows. In section 1, problems with
    existing outlier elimination mechanisms for robust optical flow estimation are
    cited, and the structural arrangement and innovations of the study are presented.
    In section 2, an overview of existing outlier elimination algorithms is provided,
    and the method for obtaining SOF in this study is presented. Section 3 describes
    the main techniques applied to the methodology used in this study. In section
    4, the model training and evaluation metrics are identified. Experimental validation
    and data analyses are completed. Section 5 summarizes the entire text. 2. Related
    work The introduction section reviews and analyses the strengths and weaknesses
    of the methods that have been used to eliminate outlier optical flow values. This
    chapter is further an overview of popular outlier elimination algorithms that
    have not been used for optical flow estimation. It also describes the methods
    used to convert the dense optical flow in a given dataset into SOF values. 2.1.
    Outlier elimination algorithms Popular outlier elimination algorithms include
    methods based on distribution, distance, dimension reduction, density, clustering,
    and trees. Choosing a suitable optical flow outlier elimination algorithm must
    be analyzed on a case-by-case basis. The distribution-based 3σ [14], Z-score [15],
    and Boxplot [16] methods are simple and easy to use, but they cannot accurately
    output the normal range. The judgment mechanism eliminates them one by one, which
    is not suitable for models with large amounts of data. Distance-based K-nearest
    neighbor (KNN) [17] is not required to assume data distribution and can find global
    outliers but cannot find local outliers. Principal component analysis (PCA) [18]
    and AutoEncoder [19] based on dimensionality reduction can simultaneously process
    multiple features and transform them into a new set of unrelated variables. Unifying
    local outlier detection methods via graph neural networks (LUNAR) [20] trained
    a graph neural network (GNN) on a graph to construct a graphical representation
    of the data, where each data point is represented as a node in the graph and the
    edges between the nodes represent the distance between the data points. Different
    outlier detection techniques were then applied to each node in the graph to identify
    outliers. However, the distance-based approach is ineffective for nonlinear data.
    The density-based approach can effectively detect multidimensional outliers without
    limitations in data distribution. The gaussian mixture model (GMM) [21] algorithm
    assumes that the dataset is a mixture of multiple Gaussian distributions, and
    estimates the model parameters by maximizing the likelihood function. Calculate
    the probability density of each data point in the model, which is used as a GMM
    score, and a threshold is used to determine whether the point is an outlier. For
    high-dimensional datasets and datasets with many outliers, the selection of appropriate
    model parameters is not sufficiently robust. The SOS algorithm [13] constructs
    multiple SNGs, with each neighborhood graph randomly selecting a data point as
    the center from the dataset. Then calculate the variance between each data point
    and its data points in the neighborhood graph for dimension reduction processing
    is normalized to obtain the outlier probability of each data point in multiple
    neighborhood graphs, and to judge whether the outlier probability is greater than
    an artificial threshold to eliminate outliers. Copula-based outlier detection
    (COPOD) [22] used kernel density estimation or histogram-based methods to estimate
    the marginal distribution. The copula function is then used to model the dependency
    structure between variables, and the threshold value is set according to the dependency
    degree to eliminate outliers. The density-based method requires a preset density
    threshold, is more sensitive to data distribution, and is susceptible to interference
    from data noise. Clustering-based local subspace clustering and pruning (LSCP)
    [23] clusters feature in subspaces, with each subspace representing a cluster.
    Pruning removes unnecessary or redundant features from the dataset, reduces the
    dimensionality of the feature space, and improves the efficiency of the clustering
    algorithm. Local correlation integral (LOCI) [24] constructed a distance graph
    by calculating the distance between each data point and other points in its neighborhood.
    Then, the local correlation integral (LCI) between each data point and other points
    in its neighborhood was calculated, and the average of the LCI was used as the
    LOCI score of that point. Finally, the threshold value was used to determine whether
    a point was an outlier. The clustering-based algorithm has a high computational
    complexity, requires calculating the distance between each data point and other
    points in its neighborhood, and requires adjusting several parameters for optimization.
    Tree-based isolation nearest-neighbor ensembles (INNE) [25] randomly selects a
    subset of data to construct a decision tree [26]. The decision tree recursively
    divides data into subsets based on randomly selected features and thresholds.
    The decision tree assigns each data point an outlier score that indicates the
    depth of the leaf node in the tree where the data point is located. Data points
    assigned high anomaly scores were regarded as outliers. The tree-based approach
    is relatively ineffective for detecting anomalies in low-dimensional data. 2.2.
    Obtaining SOF values As shown by the green dashed box in the figure, this section
    uses CCD and VS to acquire 3D scene information and then converts the 3D scene
    information into 2D image sequences using perspective transformation techniques.
    The Lucas–Kanade SOF method based on Shi–Tomasi corner point detection is used
    to obtain the SOF values in 2D image sequences. 2.2.1. Obtaining 2D images In
    this section, CCD [27] and VS [28] were used for image acquisition. As shown in
    figure 2, to obtain the 3D coordinate displacement offset values (u, v), a perspective
    transformation global coordinate system was used to transform two adjacent frames
    of 3D feature points from P0 to P, into a camera image 2D datasets. Zoom In Zoom
    Out Reset image size Figure 2. Schematic diagram of perspective transformation
    of 3D motion in a 2D plane. Download figure: Standard image High-resolution image
    All positions and orientations of the CCD with respect to the global coordinate
    system are computed by means of a perspective transformation [27]. The coordinate
    system of CCD takes the direction of vehicle travel as Xc axis, and Xc, Yc and
    Zc are perpendicular to each other to form a three-dimensional coordinate system.
    The global coordinate system was XYZ. [R | t] is the transformation between the
    camera''s current coordinate system and the camera''s initial position coordinate
    system. Assuming that the first ground truth pose is (0, 0, 0) and the input is
    a 3D global coordinate system. The output determines the displacement of the target
    between frames by means of the camera coordinate system and the transformation
    matrix [R | t]. 2.2.2. Shi–Tomasi-based SOF estimation The (x, y) obtained in
    section 2.2.1 is the 2D coordinate point. The method of Kaur et al [29] corner
    point detection was used to extract the corner points with significant motion
    in the image as SOF estimates with a matrix N× 2. The corner point response value
    R introduced in the Harris algorithm [30] is used to determine whether the feature
    points are corner points and boundaries, as in equation (1), where , . The Shi–Tomasi
    corner point detection algorithm is optimized for the R-value equation. As of
    the Harris corner detection algorithm is an empirical value, it is difficult to
    set an optimal value. Shi et al found that the stability corner points are related
    to smaller eigenvalues in matrix M. The R-value formula can be rewritten as: where
    is set to a minimum value of 0.01 to ensure that all corner points satisfying
    the decision conditions are detected. In this study, all pixels were sorted according
    to the magnitude of the eigenvalues, and the top N pixels with the smallest eigenvalues
    were selected as corner points. The Lucas–Kanade SOF method was used to obtain
    the correspondence of feature points of adjacent frames. Let I(x, y, t) be the
    grayscale value of the feature point (x, y) at moment t. u and v are the x and
    y velocity components of the optical flow at that point, assuming that the pixel
    point moves to the point (x + Δx, y + Δy) after time Δt, where Δx = uΔt and Δy
    = vΔt. By comparing the pixel relationship between two adjacent frames of feature
    points using equation (3), we determine whether there is a correspondence between
    two frames of feature points, In equation (3), Ix and Iy represent the grayscale
    gradients in the x and y directions, and It represents the rate of change of grayscale
    over time. The feature points that satisfy the correspondence notation of equation
    (3) are denoted as , and the (u, v) variable values are saved. In CMTT, according
    to the properties of the Lucas–Kanade SOF method with constant luminance, small
    motion, and spatial consistency, it is known that in the same region when time
    and speed are consistent when the time flow estimates (u, v) has the characteristic
    of appearing in clusters. In view of the advantages and disadvantages of the aforementioned
    outlier elimination methods, this study adopts a clustering-based method to eliminate
    outliers in optical flow estimation, which solves the problems of easy false clustering
    and inaccurate elimination when dealing with multiple optical flow vectors. 3.
    The proposed approach The SOF outliers elimination method based on B-SNG is the
    core of this study. As shown in the brown dashed box in figure 1, the optical
    flow estimates corresponding to the pixel positions of the corner points are used
    as the input data points (u, v). The dissimilarity matrix D is obtained by calculating
    the dissimilarity between data points using the Euclidean equation. Then, the
    phase difference matrix is smoothed using a Gaussian function to obtain the smoothing
    matrix S. The elements in matrix S do not match the probability distribution,
    and the smoothed matrix is normalized to obtain binding matrix B. The binding
    matrix is then combined with the SNG to calculate the outlier probabilities. Finally,
    the Borda score is obtained from the outlier probability ranking and score correspondence
    table, and in the case of generating multiple SNGs, the Borda counting method
    is used to assign a ranking to each data point, the higher the ranking the higher
    the outlier probability. 3.1. Dissimilarity matrix The SOF between two frames
    obtained using the Lucas–Kanade SOF method is saved in the flow variable with
    dimension (n_samples, 2), where n_samples is the number of samples, and each sample
    has two features representing the offset (u, v) in the x and y directions, respectively.
    The accuracy of the optical flow values is improved by treating each sample as
    a data point and using B-SNG to detect and filter out data points that may be
    outliers. In the B-SNG algorithm the data set X of SOF is taken as input, each
    data point x= [u, v], the number is n and the size of X is an X = n × 2 matrix.
    The input parameter is a two-dimensional array X, where each row represents a
    data point, and each column represents a feature of the data point. Calculate
    the point-to-point dissimilarity matrix D using Euclidean calculations, where
    dab denotes the difference between points xa and xb. xak denotes the kth eigenvalue
    of the ath data point, and in this study k= 1, 2. Where the values in row a and
    column b represent the Euclidean distance between the ath data point and bth data
    point. Equation (4) satisfies the non-negativity, symmetry, and trigonometric
    inequality, so all elements of the matrix are nonnegative and all elements on
    the diagonal are 0. Figure 3(a) shows an example of randomly selected data points,
    where u and v represent the offsets on the x-axis and y-axis, respectively, i.e.
    SOF. In figure 3(b), the length of the red line represents the difference of the
    other 9 data points from point X2; the longer the red line, the greater the difference.
    Figure 4(a) shows a heatmap of the dissimilarity matrix D for 10 sets of optical
    flow estimates, with color ranging from dark to light indicating dissimilarity
    from high to low. To more clearly represent the deviation of data from each other,
    as shown in figure 3(c), each data point is set as a node, and the distance from
    the other data points to this node is calculated. The variance value of each data
    point, calculated from these distances, indicates the degree of deviation of the
    data points. In the figure, circles are drawn with a radius equal to half the
    variance of each data point, showing that point X4 has the greatest degree of
    deviation. Zoom In Zoom Out Reset image size Figure 3. Schematic diagram of the
    phase dissimilarity matrix (a) example data points (b) dissimilarity matrix D
    (c) deviation into degrees. Download figure: Standard image High-resolution image
    Zoom In Zoom Out Reset image size Figure 4. Heat map of three matrix values (a)
    phase anisotropy matrix D (b) smoothing matrix S (c) binding matrix B. Download
    figure: Standard image High-resolution image 3.2. Smoothing matrix While retaining
    the main features of the data points and on the premise of reflecting the similarity
    relationship between the data, the dimensionality of the data is reduced and the
    D matrix is smoothed and reduced by a Gaussian function to obtain the smoothing
    matrix S, where the dissimilarity from data point a to data point a is 0. The
    smoothing matrix from data point a to data point b is where sigam is the smoothing
    factor, which can control the Gaussian function to make its value smoother after
    dimensionality reduction; the smaller the sigam the smaller the edge weight, which
    can easily lead to distortion of the data value; and sigam= 9 (sigam= 9 is the
    best value obtained through empirical adjustment), which can ensure the accuracy
    of the data after dimensionality reduction on the premise of reducing distortion
    as much as possible. In equation (5), sa denotes the similarity distribution of
    the ath row of the smoothing matrix as data point xa , where saa is 0, Figure
    4(b) shows the smoothed matrix S heat map for example data. The smoothing matrix
    S highlights the affinity between data points more than the phase-difference matrix
    D. The darker color in figure 4(a) indicates greater dissimilarity and distance
    between data points. The darker color in figure 4(b) indicates less dissimilarity
    between data points. 3.3. Binding matrix The probability sum of any node to other
    nodes in the smoothing matrix S is not equal to one and is a non-probability distribution.
    Normalize the smoothing matrix S. The dissimilarity between xa and xb is proportional
    to the probability density of xb . Compute the conditionally bound matrix B such
    that , In equation (8), ba denotes the binding probability distribution of the
    ath row of the binding matrix as the data point xa , where baa is 0, Figure 4(c)
    heat map of the binding matrix B of the example data, the shades of color represent
    the distribution of the binding probability, the higher the binding probability
    the darker the color. 3.4. Binding probability The binding probability defines
    a SNG with n nodes, where each node Va has a random set of neighboring nodes {xa
    }, xa ∈X, and a set of nodes {Va }, Va ∈V. And there is a directed edge EG between
    node Va and all the nodes in {xa }. Let ba be the binding distribution of node
    Va and node Va be the ath row of B. Let each node Va ∈V be independently bound
    to another node Vb , where index b is a→b sampled from the binding distribution
    ba denotes a directed edge from node Va to vertex Vb . In this study, it is defined
    when data point xa selects data point xb as a neighbor in graph G. If node Vb
    is not bound to node Va , i.e., its data of zero degrees in degree G belongs to
    outlier Co. The only values calculated at this point are the outliers Co = 0 and
    non-outlier Co = 1, as shown in equation (9), According to equation (9), the probability
    that its degree G is zero is equal to the probability that node is not bound to
    any node. It is assumed that the nodes V are constant and B is not uniformly distributed;
    therefore, the probability of generating a particular G depends only on the binding
    probability p(G), As shown in figure 5(a), there are 10 nodes in the example with
    directed edges from node V10 to each point, and the sum of the binding probabilities
    from V10 to the remaining 9 nodes is 1. Figure 5(b) shows that the total probability
    of binding each vertex to V10 is not equal to 1. Each vertex Va in the graph is
    associated with the bound probability distribution ba . The binding probabilities
    of V10→V4 is relatively low, and the binding probability of V4→V10 is relatively
    low. Zoom In Zoom Out Reset image size Figure 5. Illustration of binding probability
    (a) binding probability of V10 to the rest of nodes (b) binding probability of
    the rest of nodes to V10. Download figure: Standard image High-resolution image
    Figure 6 shows a schematic diagram of graph G in which the nodes are fixed and
    a node can be bound to multiple nodes. It can be observed that the binding probability
    calculation is not a closed-loop calculation. After obtaining the binding probabilities,
    the neighbor nodes of each node Va in graph G are chosen randomly and the graph
    G = (V, EG ). In figure 6, SNG is a stochastically generated neighborhood graph,
    as in the example when n= 10 nodes; that is, there are (n-1)n SNGs. The two forms
    in the example in figure 6, when {X1, X4, X6, X10} are outliers, have a binding
    probability of 2.85 × 10−5 for graph Ga . When {X2, X3, X7} is an outlier, the
    binding probability of the graph Gb is 2.4345 × 10−10. The higher the binding
    probability, the smaller the dissimilarity between the nodes. Zoom In Zoom Out
    Reset image size Figure 6. Stochastic neighborhood graph (1 node can be bound
    by multiple nodes). Download figure: Standard image High-resolution image 3.5.
    Outlier probability To reduce the computational effort while guaranteeing the
    accuracy rate, in this study, given an SNG, each node is allowed to bind to only
    one node to form a closed-loop outlier probability. The bound probability data
    given in equation (11) is calculated based on a given graph G. The probability
    that a randomly selected data point xb chooses data point xa as its neighbor and
    the probability that data point xa belongs to an outlier is p(xa ∈Co), In equation
    (11), Co denotes an outlier category. In figure 9, node V1 is randomly selected;
    one node can only be bound to one node, and then a closed-loop operation is performed
    along the nearest neighbor to that point. When {X4,X5,X8,X9} are outliers, the
    outlier probability X1 is 0.48921. When {X4} is an outlier, the outlier probability,
    X1 is 0.30502. The greater the outlier probability, the greater the dissimilarity
    between nodes. The xa is an outlier when p(xa ∈Co) > θ. As shown in figure 7,
    with the same threshold θ, the output X1 outlier probability will not be exactly
    the same, even if the nodes are the same and the randomly bound nodes are different
    each time. As shown in figure 8(a), a G is returned using binding matrix B as
    input. Where 0 or 1, indicates whether there is an edge from node a to node b.
    As shown in figure 8(b), the matrix B is combined with matrix S. The zero points
    in S are maintained, and the remaining points are replaced with values in matrix
    B. Zoom In Zoom Out Reset image size Figure 7. Stochastic neighborhood graph (a
    node can only be bound to one node). Download figure: Standard image High-resolution
    image Zoom In Zoom Out Reset image size Figure 8. Schematic diagram of outlier
    probabilities (a) A graph G is stochastically generated (b) A graph G corresponds
    to a binding matrix (c) 10 graphs G correspond to data point outlier probabilities,
    and each row represents a data point outlier probability of a G graph. Download
    figure: Standard image High-resolution image In this section, the Borda count
    [31] was used to obtain data outliers. The Borda count algorithm considers the
    ranking of each data point instead of simply focusing on the vote share, considers
    all candidates for each threshold, effectively avoids vote scattering for data
    values, and assigns a certain number of points to each candidate. The value of
    θ is not defined in this study. The outlier probabilities are calculated by generating
    gn G-graphs, and the output outliers are sorted and labeled L= {L1, L2,..., Ln}
    each time. Figure 8(c) shows the outlier probability values for the data points
    when gn = 10. Assuming that there are N data points in the dataset X and k% of
    outliers are excluded, the ranking and scores of the Borda count are shown in
    table 1. Table 1. Correspondence table between Borda count sequence and score
    of data points. Sequence 1 2 3 4 ... N × k% Others Score ... 0 The total outlier
    score for each data point was obtained by equation (12): In equation (12), gn
    is the number of graphs G. The ranking of the statistical outlier total score
    by equation (11), the vector with the top k% of occurrence frequency or Score(s)
    greater than a threshold, is thresholded, and the feature points with probability
    values higher than a certain threshold are marked as outliers; thus, these outliers
    can be eliminated, and a valid optical flow estimate can be obtained. The B-SNG
    pseudocode proposed in this study is presented in table 2. Table 2. Pseudocode
    of B-SNG. Input: Sparse optical flow estimate (u, v), threshold k, number of nodes
    n。 Output: Outliers //Calculate the phase dissimilarity matrix 1. D = [] 2. for
    a = 1 to n: for b = 1 to n: d = sqrt((u[a] − u[b])^2 + (v[a] − v[b])^2) D[a, b]
    = d // Dimensionality reduction of the phase anisotropy matrix 3. P = exp(−D^2/2sigma^2)
    // Normalize the reduced-dimensional matrix 4. B = P/sqrt(sum(P^2)) // Construct
    stochastic neighborhood graphs 5. G = construct_SNG(B) //Calculate outlier probabilities
    6. p = compute_outlier_prob(G) //Outliers are eliminated using the Borda counting
    method 7. outliers = [] for a = 1 to n: if wavelet_score(a, p) > k: outliers.append(a)
    In this section, we set the top 10% frequency of the occurrence of points as outliers.
    As shown in figure 8(c), the data points {X1,X2,X3,X5, X6,X7,X8,X9,X10} are classified
    as inliers, whereas the data points {X4} are classified as outliers. 4. Experiment
    and performance analysis To evaluate the performance of the B-SNG algorithm, this
    section demonstrates that the B-SNG algorithm proposed in this study is effective
    for outlier elimination on the SOF estimation domain by comparing it with a variety
    of popular outlier elimination algorithms. All the experiments are implemented
    on NVIDIA Quadro P5000 GPUs on the PyTorch platform. 4.1. Datasets Table 3 demonstrates
    that in the outlier elimination algorithm comparison experiments, the dataset
    Odataset includes three motion pattern datasets (Normal amplitude motion scene
    dataset n_datas, small amplitude motion scene dataset s_datas, and large amplitude
    motion scene dataset l_datas), each of which consists of the inlier optical flow
    values (ugt, vgt ) and the outlier optical flow values (uft, vft ). Table 3. Detailed
    description of the Odataset dataset. Reproduced from [32], with permission from
    Springer Nature. Reproduced from [33]. CC BY 3.0. Reproduced with permission from
    [34]. Datasets size Number of sparse optical flow values/group Data sources Mean
    values of u and v n_datas 40 group 100 bamboo_1(frame_0001 ∼ 0010)[34] bamboo_2(frame_0001
    ∼ 0010) [34] temple_2.1(frame_0001 ∼ 0010) [34] temple_2.2(frame_0011 ∼ 0021)
    [34] 15–50 pixels s_datas 30 group 100 alley_1(frame_0001 ∼ 0016)[34] FlyingChairs(6,7,11,12,16,33,40,78,82 104)[35]
    Middlebury(grov(2 ∼ 3)、urban(2 ∼ 3)、venus)[36] >15 pixels l_datas 40 group 100
    ambush_2.1(frame_0001 ∼ 0010)[34] ambush_2.2(frame_0010 ∼ 0021) [34] market_5.1(frame_0001
    ∼ 0010) [34] market_5.2(frame_0011 ∼ 0021) [34] <50 pixels The inlier optical
    flow values: to obtain the inlier optical flow value sample data, some data were
    selected from the standard optical flow datasets of Middlebury [36], Flying chairs
    [35], and MPI [34], and the dense optical flows in these datasets were converted
    to SOFs as the true optical flow value sample data using the method in section
    2.2 Tdataset [ugt, vgt , 1]. Outlier optical flow values: in order to construct
    outlier optical flow value sample data, a random generation method is used to
    generate a specified number of non-realistic optical flow values Fdataset[uft,
    vft , 0]. To ensure that the total number of samples in each data set remains
    the same, some of the data values of Tdataset are replaced with the data values
    of Fdataset composed to form the overall Odataset [uo, vo, outlier], when outlier
    is 0 is an outlier and 1 is the inlier. A partial presentation of the dataset
    is given in figure 9. Zoom In Zoom Out Reset image size Figure 9. The dataset
    of optical flow estimates used for the evaluation. From top to bottom, l_datas
    [34], n_datas [34] and s_datas [34–36], respectively. Reproduced from [32], with
    permission from Springer Nature. Reproduced from [33]. CC BY 3.0. Reproduced with
    permission from [34]. Download figure: Standard image High-resolution image 4.2.
    Evaluation methods The experimental results of the proposed B-SNG are compared
    with those of several state-of-the-art algorithms to provide quantitative metrics
    to demonstrate the superiority of the method in processing optical flow outliers.
    4.2.1. Comparison methods Six outlier elimination algorithms are selected for
    comparison. They are the tree-based INNE (2018), density-based GMM (2019) and
    COPOD (2022), clustering-based SOS (2012), LSCP (2019), and LOCI (2022) algorithms.
    For the INNE, LSCP, GMM, LOCI, COPOD, and SOS algorithms, the parameter n_features=
    2 and random_state= 42, where the value of the n_clusters parameter for GMM is
    4. The above methods were implemented in the Visual Studio Code and tested in
    the same Python 3.97 environment, with default values chosen for all parameters
    of each method. 4.2.2. Evaluation indicators In the comparison experiment of outlier
    elimination algorithm, accuracy, precision, recall, FPR, F1 score [37] and running
    time are used as evaluation indexes to evaluate the performance of outlier elimination
    algorithm in multiple dimensions. The accuracy, precision and recall rate emphasize
    the performance of the model in different aspects, including the overall accuracy,
    the prediction accuracy of the positive samples and the capture degree of the
    positive samples. The F1 score combines the precision rate and recall rate, provides
    a balance index, and considers the trade-off between these two performance aspects.
    The FPR reflects the model ''s ability to prevent misclassification of negative
    samples into positive ones. Finally, the running time is used as an additional
    indicator to evaluate the efficiency of the algorithm, so as to understand its
    feasibility in practical applications. 4.3. Performance comparison of outlier
    elimination algorithms The results of the B-SNG are analyzed for comparison with
    popular elimination algorithms in recent years. Figures 10–16 show the results
    of the comparison of seven of the algorithms (INNE (2018), GMM (2019), COPOD (2022),
    LSCP (2019), LOCI (2022), LUNAR (2021), SOS (2012)) and B-SNG for optical flow
    estimation outliers on the normal motion scene, small amplitude motion scene and
    large amplitude motion scene datasets, respectively, where accuracy, precision,
    recall, FPR, F1 score and runtime (s) are reported. Zoom In Zoom Out Reset image
    size Figure 10. Comparison results of seven algorithms for eliminating optical
    flow estimation outliers on the common motion scene dataset. From top to bottom,
    the bamboo_1 [34], bamboo_2 [34], temple_2.1 [34], and temple_2.2 [34] datasets
    are shown. Download figure: Standard image High-resolution image Zoom In Zoom
    Out Reset image size Figure 11. F1 score performance comparison of seven algorithms
    in a normal motion scenario. From top to bottom, the bamboo_1 [34], bamboo_2 [34],
    temple_2.1 [34], and temple_2.2 [34] datasets are shown. Download figure: Standard
    image High-resolution image Zoom In Zoom Out Reset image size Figure 12. Performance
    comparison of seven algorithms in small amplitude motion scenarios. From top to
    bottom, the alley_1 [34], FlyingChairs [35], G + N (grov, urban) [36], and venus
    [36] datasets are shown. Download figure: Standard image High-resolution image
    Zoom In Zoom Out Reset image size Figure 13. F1 score performance comparison of
    seven algorithms in small amplitude motion scenarios. From left to right, the
    alley_1 [34], FlyingChairs [35], G + N (grov, urban) [36], and venus [36] datasets
    are shown. Download figure: Standard image High-resolution image Zoom In Zoom
    Out Reset image size Figure 14. Performance comparison of the seven algorithms
    in a large amplitude motion scenario. From left to right, the ambush_2.1 [34],
    ambush_2.2 [34], market_5.1 [34], and market_5.2 [34] datasets are shown. Download
    figure: Standard image High-resolution image Zoom In Zoom Out Reset image size
    Figure 15. F1 score performance comparison of seven algorithms for large amplitude
    motion scenarios. From top to bottom, the ambush_2.1 [34], ambush_2.2 [34], market_5.1
    [34], and market_5.2 [34] datasets are shown. Download figure: Standard image
    High-resolution image Zoom In Zoom Out Reset image size Figure 16. Average performance
    comparison of 7 algorithms in different motion modes. Download figure: Standard
    image High-resolution image 4.3.1. Normal amplitude motion scene Figures 10 and
    11 show the results of the comparison of the seven algorithms for eliminating
    optical flow estimation outliers on the common motion scene dataset n_datas. The
    first column in figure 10 shows the number of inlier points as a proportion of
    the entire dataset. The inlier ratios in the bamboo_1, bamboo_2, temple_2.1, and
    temple_2.2 datasets ranged from 13%–85%, 18%–92%, 40%–95%, and 56%–96% respectively,
    with average inlier ratios of 42.5%, 64.2%, 72.4%, and 76.6% respectively. Accuracy.
    The second column of figure 10 reports the accuracy of different datasets at different
    proportions of inlier ratios. In normal amplitude motion scenarios, accuracy is
    not affected by the number of inlier ratios when the number of inlier ratios is
    less than 30%. The LSCP is the most accurate when the proportion of the inlier
    ratio is less than 30%. Compared to the third-best LOCI algorithm, it improved
    by 9.832%. Compared to the worst COPOD, it increased by 18.578%. Precision. The
    third column of figure 10 shows the precision rates for different datasets at
    different inlier ratios. When the proportion of the inlier ratio is less than
    30%, there are too many negative samples, and similar negative samples may exist
    near the positive samples, resulting in lower precision than accuracy. The B-SNG
    algorithm had the best accuracy rate when the proportion of inlier ratios is less
    than 30%. Recall. The fourth column of figure 10 shows the recall rates for different
    datasets with different inlier ratios. The overall trend of recall for all algorithms
    increased as the proportion of the inlier ratios increased. The B-SNG algorithm
    outperformed the other 5 algorithms in terms of average recall, and is inferior
    to the LSCP algorithm, with a 3.473% reduction. It improved by 1.77% compared
    with the third-best INNE algorithm and by 23.57% compared to the worst LOCI. FPR.
    The fifth column of figure 10 shows the FPR for different datasets at different
    inlier ratios. The B-SNG algorithm outperformed the other six algorithms in terms
    of average FPR. It is 0.1544% lower than that of the second-best LOCI algorithm
    and 19.12% lower than that of the worst COPOD. F1 scores. Figure 11 shows the
    F1 scores for the different datasets with different inlier ratios. The B-SNG algorithm
    outperformed the other five algorithms in terms of average F1 scores and is inferior
    to the LSCP algorithm, with a 2.69% decrease compared to the LSCP algorithm. It
    improved by 2.604% compared with the third-best LSCP algorithm. It improved by
    20.508% compared to the worst LOCI. Running time. The average running times for
    SOS, INNE, GMM, LSCP, LOCI, COPOD, and B-SNG on the large-amplitude motion scene
    dataset are 0.905 166 495, 0.130 164 933, 0.098 159 808, 2.433 330 357, 3.636
    093 283, 0.144 511 211, and 0.978 321 s, respectively. Compared with the best
    GMM algorithm this algorithm increases by 89.6661% and 8.082% compared to the
    SOS algorithm. Compared with the worst LOCI algorithm this algorithm decreased
    by 73.09%. The precision rate and FPR of this algorithm are better than those
    of other algorithms in normal motion scenarios. The accuracy, recall, and F1 are
    not as good as those of the LSCP algorithm but outperformed the LSCP algorithm
    in terms of running time. 4.3.2. Small amplitude motion scene Figures 12 and 13
    show the comparison results of the seven algorithms for eliminating optical flow
    estimation outliers on the small-amplitude motion scene dataset s_datas. The first
    column in figure 12 shows the number of inlier ratios as a proportion of the entire
    dataset. The inlier ratios in the alley_1, FlyingChairs, G + N (grov, urban),
    and venus datasets ranged from 9%–85%, 25%–95%, 33%–95%, and 50%–98%, respectively,
    with average inlier ratios of 44.2%, 67%, 70.6%, and 79.7%, respectively. Accuracy.
    The second column of figure 12 shows the accuracy for different datasets at different
    inlier ratios. In small-amplitude motion scenes, the accuracy is not affected
    by the number of inlier ratios when the number of inlier ratios is less than approximately
    25%. When the number of inlier ratios is greater than about 25%, the accuracy
    tends to increase with the number of inlier ratios. The SOS has the best accuracy
    when the inlier ratio is less than 25%. The B-SNG algorithm outperformed the other
    six algorithms in terms of average accuracy. It improved by 0.013% compared with
    the second-best LSCP algorithm. It improved by 13.242% compared to the worst LOCI.
    Precision. The third column of figure 12 shows the precision rates for different
    datasets with different inlier ratios. The B-SNG algorithm outperformed the remaining
    five algorithms in terms of the average precision rate, and is inferior to the
    LSCP algorithm, with a 3.6836% reduction. It improved by 0.053% compared to the
    third-best LOCI algorithm and by 7.821% compared to the worst GMM. Recall. The
    fourth column of figure 12 shows the recall rates for different datasets with
    different inlier ratios. There is an overall increasing trend in recall for all
    algorithms as the inlier ratio increases. The B-SNG algorithm outperformed the
    remaining six algorithms in terms of average recall. It improved by 0.076% compared
    with the second-best LSCP algorithm and by 9.16% compared with the worst LOCI.
    FPR. The fifth column of figure 12 shows the FPR for different datasets with different
    inlier ratios. The B-SNG algorithm outperforms the remaining four algorithms in
    terms of average FPR, and is inferior to the LSCP and LOCI algorithms, with an
    increase of 44.879% and 20.885%, respectively. It decreased by 36.549% compared
    to the worst SOS. F1 scores. Figure 13 shows the F1 scores for the different datasets
    with different inlier ratios. The B-SNG algorithm outperformed the other five
    algorithms in terms of average F1 scores and is inferior to the LSCP algorithm,
    with a 3.701% decrease compared to the LSCP algorithm. It improved by 4.997% compared
    with the third-best INNE algorithm. It improved by 9.248% compared to the worst
    LOCI. Running times. The average running times for SOS, INNE, GMM, LSCP, LOCI,
    COPOD, and B-SNG on the large amplitude motion scene dataset are 0.927 651 906,
    0.128 558 654, 0.101 935 512, 2.470 868 725, 3.800 803 578, 0.221 414 196 and
    0.981 24 s. 86.2609% increase compared to the best GMM algorithm and 5.777% increase
    compared to the SOS algorithm in this study. Compared to the worst LOCI algorithm,
    this algorithm decreases by 74.1834%. The accuracy and recall of this study''s
    algorithm outperformed those of other algorithms in small-amplitude motion scenarios.
    The precision and F1 scores are inferior to those of the LSCP algorithm, and the
    FPR is inferior to the LSCP and LOCI algorithms, but better than the LSCP and
    LOCI algorithms in terms of running time. 4.3.3. Large amplitude motion scene
    Figures 14 and 15 show the comparison results of the seven algorithms for eliminating
    optical flow estimation outliers on l_datas, a dataset of large amplitude motion
    scenes. The first column in figure 14 shows the number of inlier ratios for the
    entire dataset. The inlier ratios in the ambush_2.1 [34] and ambush_2.2 [34] datasets
    ranged from 10%–66% and 5%–89%, respectively, with average inlier ratios of 0.384
    and 0.483, respectively. The inlier ratios in the market_5.1 [34] and market_5.2
    [34] datasets ranged from 17%–87% and 35%–93%, and the average inlier ratios are
    0.575 and 0.703, respectively. Accuracy. The second column of figure 14 shows
    the accuracy for different datasets with different inlier ratios. The algorithm
    accuracy is not affected by the number of inlier ratios when the number of inlier
    ratios is less than approximately 25% for large motion scenarios. When the number
    of inlier ratios is greater than 25%, the accuracy of the algorithm improved as
    the number of inlier ratios increased. The B-SNG algorithm remained consistently
    on the upper side for different inlier ratios for different datasets. The LSCP
    has the best accuracy when the proportion of inlier ratios is less than 10%. The
    B-SNG algorithm outperformed the other six algorithms in terms of average accuracy.
    It improved by 0.265% compared with the second-best SOS algorithm and by 13.411%
    compared with the worst LOCI. Precision. The third column of figure 14 shows the
    precision rates for different datasets with different inlier ratios. When the
    inlier ratio is less than approximately 25%, there are too many negative samples
    and similar negative samples may exist near the positive samples, resulting in
    a lower precision than accuracy. The SOS algorithm had the best precision when
    the inlier ratio is less than 25%. The B-SNG algorithm outperformed the other
    six algorithms in terms of average precision. It improved by 0.120% compared to
    the second-best SOS algorithm and by 16.272% compared to the worst LOCI. Recall.
    The fourth column of figure 14 shows the recall rates for different datasets with
    different inlier ratios. The recall of all algorithms tended to increase as the
    inlier ratios increased. The recall is generally consistent with the precision
    rate, and the SOS algorithm has the best recall when the inlier ratio is less
    than 25%. The B-SNG algorithm outperformed the remaining six algorithms in terms
    of average recall. It improved by 1.456% compared to the second-best GMM algorithm
    and 24.472% compared to the worst LOCI. FPR. The fifth column of figure 14 shows
    the FPR for different datasets with different inlier ratios. The B-SNG algorithm
    outperformed the other five algorithms in terms of the average FPR and is inferior
    to the LOCI algorithm. There is a 21.489% increase compared to the LOCI algorithm.
    It decreased by 0.22% compared with the third-best GMM algorithm and by 15.91%
    compared with the worst COPOD. F1 scores. Figure 15 shows the F1 scores for the
    different datasets with different inlier ratios. The B-SNG algorithm is inferior
    to the SOS algorithm in terms of F1 scores, with a 2.69% decrease compared to
    SOS. The improvement is 2.604% compared with the third-best LSCP algorithm. The
    improvement is 20.508% compared to the worst LOCI. Running times. The average
    running times for SOS, INNE, GMM, LSCP, LOCI, COPOD and B-SNG on the large amplitude
    motion scene dataset are 0.9224, 0.13117, 0.10428, 2.38619, 3.58897, 0.14784,
    and 1.001s, respectively. Compared to the best GMM algorithm, the algorithm in
    this study increased by 85.99% and 8.522%, respectively, compared to the SOS algorithm.
    Compared to the worst LOCI algorithm, this algorithm decreased by 72.109%. The
    accuracy, precision, and recall of this algorithm are better than those of the
    other algorithms in large-amplitude motion scenarios. The FPR is not as good as
    the LSCP algorithm and the F1 score is not as good as the SOS algorithm, but it
    is better than the LSCP algorithm in terms of running time. 4.3.4. Comparison
    of the overall performance of different sports modes Figure 16 shows the average
    resultant values of qualitative outlier elimination on the Odataset (s_datas,
    l_datas, and n_datas) dataset for the seven algorithms. The B-SNG in this outperformed
    the other six algorithms in terms of average accuracy, precision, and recall.
    The average FPR is inferior to that of the LSCP and LOCI algorithms, increasing
    by 8.903% and 14.268%, respectively. The average F1 score is lower than that of
    the LSCP algorithm, with a decrease of 1.1928%. Although the method in this study
    is inferior to the LSCP and LOCI algorithms in terms of the average FPR and F1
    score, it outperforms them in terms of running time, with reductions of 59.3909%
    and 73.1489%, respectively. 4.4. Real scenario application This section discusses
    the application of B-SNG to eliminate outlier optical flow estimation in real
    scenes and evaluates the performance of SOS, INNE, GMM, LSCP, LOCI, COPOD, and
    B-SNG on real video-stream datasets. In figure 17, a sequence of 10 consecutive
    frames from a provincial road moving camera with an image size of 1050 × 480 pixels
    is shown, and the red dashed boxes are the starting frames of the two datasets
    t_data1 and t_data2. Zoom In Zoom Out Reset image size Figure 17. Real video flow
    datasets for evaluation. Download figure: Standard image High-resolution image
    After acquiring the image sequences, the Lucas-Kanade SOF method is used to obtain
    optical flow values (the number of optical flow values in each set is 100). The
    outliers in the optical flow dataset are calibrated by experts, as shown in figures
    18 and 19. To demonstrates show the performance of the comparison algorithm more
    clearly, this section changes the ordering of the proportion of true outliers
    obtained from real image sequences, and the proportion of true outliers is reordered
    according to the lowest to the highest. Zoom In Zoom Out Reset image size Figure
    18. Performance comparison of the seven algorithms in real scenarios. From top
    to bottom, the t_data1 and t_data2 datasets are shown respectively. Download figure:
    Standard image High-resolution image Zoom In Zoom Out Reset image size Figure
    19. F1 score and the average value of each index. Download figure: Standard image
    High-resolution image Figure 18 shows the results of comparing the seven algorithms
    on the real scene dataset by eliminating the optical flow estimation outliers.
    The first column in figure 18 shows the number of outlier ratios for the entire
    dataset. The outlier ratios ranged from 2%–22% and 8.6%–35% for the t_data1 and
    t_data2 datasets, respectively, and the average outlier ratios are 0.1011 and
    0.1940, respectively. The bar chart in figure 19 shows the F1 scores and average
    metrics of the algorithms for the t_data1 and t_data2 datasets. Figure 20 shows
    the outlier elimination effect plots for the four optical flow datasets. Zoom
    In Zoom Out Reset image size Figure 20. Plot of outlier elimination effect of
    B-SNG in different motion modes. Download figure: Standard image High-resolution
    image Accuracy. The second column of figure 18 shows the accuracy rates for different
    data sets with different outlier ratios. The histogram in figure 21 shows that
    the B-SNG algorithm outperformed the remaining six algorithms in terms of average
    accuracy. The improvement is 1.013% compared to the second-best LSCP algorithm
    and 14.2119% compared to the worst SOS. Precision. The third column of figure
    18 shows the precision rates for different data sets with different outlier ratios.
    The B-SNG algorithm outperformed the other six algorithms in terms of the average
    precision rate. The improvement is 0.4953% compared to the second-best LSCP algorithm.
    It improved by 7.953% compared to the worst SOS. Recall. The fourth column of
    figure 18 shows the recall rates for different data sets with different outlier
    ratios. The histogram in figure 20 shows that the B-SNG algorithm outperformed
    the remaining six algorithms in terms of the average precision rate. The improvement
    is 1.675% compared to the second-best LSCP algorithm and 8.644% compared to the
    worst SOS. FPR. The fifth column of figure 18 shows the outlier ratios for different
    datasets with different outlier ratios. The B-SNG algorithm outperforms the remaining
    three algorithms in terms of average outlier ratios and is inferior to the INNE,
    GMM, and LSCP algorithms. This is an increase of 32.185% compared to the algorithm.
    This is an increase of 3.261% compared to the third-best GMM algorithm. This is
    an increase of 66.18% compared to that of the LSCP. A 32.6565% decrease compared
    to the worst SOS. F1 scores. Figure 19 shows the F1 scores for the different datasets
    with different outlier ratios. The B-SNG algorithm outperformed the remaining
    six algorithms in terms of average F1 scores. The improvement is 0.8% compared
    with the second-best LSCP algorithm. The improvement is 8.024% compared to the
    worst SOS. Running times. The average running times of SOS, INNE, GMM, LSCP, LOCI,
    COPOD, and B-SNG on real data sets t_data1 and t_data2 are 1.15454, 0.1371, 0.1267,
    2.5656, 3.9473, 0.1551, and 1.0967s. Compared with the best GMM algorithm this
    study''s algorithm increased by 76.5589% and 5.00985% compared to the SOS algorithm.
    Compared to the worst LOCI algorithm, this algorithm decreased by 72.2165%. The
    accuracy, precision, recall, and F1 score of this study''s algorithm outperformed
    those of other algorithms in real motion scenarios. The FPR is inferior to the
    INNE, GMM, and LSCP algorithms, but outperforms them in terms of running time.
    5. Conclusion In this study, we propose a method for outlier elimination of SOF
    values based on the B-SNG, which can effectively improve the accuracy and precision
    of SOF values. First, 3D video stream acquisition is performed using CCD and VS.
    The 3D video stream information is converted to 2D image sequence information
    using perspective transformation technique. Then, the Lucas–Kanade SOF method
    is used to extract the optical flow values of feature points between adjacent
    image sequences. Next, the SOF values are used as the input dataset, the phase
    dissimilarity matrix between the data values is calculated, and the smoothing
    matrix is obtained by smoothing the reduced dimensional phase dissimilarity matrix
    using a Gaussian filter. The smoothing matrix is processed using normalization
    to obtain the binding matrix, and the outlier probability of the data values is
    calculated using the binding matrix and stochastic neighborhood graph. Finally,
    outliers with high scores are obtained by ranking the outlier probabilities, assigning
    weights to each data value, and calculating the Borda scores of the data values.
    Experiments are carried out on Odataset (n_datas, s_datas and l_datas) and real
    scenario (t_data1 and t_data2) datasets, and the experimental results show that
    the method in this study achieves the highest accuracy, precision and recall in
    terms of average performance when compared with the state-of-the-art methods.
    There is an increase in running time compared to tree and density-based algorithms,
    mainly because the method in this study requires multiple clustering and iterative
    computations. However, compared to the clustering-based outlier elimination method,
    the operational efficiency of the algorithm in this study was improved. Considering
    all the indicators, the method in this study has strong robustness and reliability
    in the application of light displacement outlier elimination in real scenes. In
    future research, more attention should be paid to the efficiency and practicality
    of the algorithm, and the running time should be reduced as much as possible to
    meet the needs of a wider range of applications. Acknowledgments Thanks the Science
    and technology development plan of Jilin Province for help identifying collaborators
    for this work. Data availability statement All data that support the findings
    of this study are included within the article (and any supplementary files). Conflict
    of interest The authors declare no conflicts of interest. Credit author contribution
    sheet Yifan Wang: Software, verification, writing. Yang Li: Conceptualization.
    Jiaqi Wang and Haofeng Lv: Format editing. Jinshi Guo: Monitor. Funding Department
    of Science and Technology of Jilin Province ( 20230101174JC). Show References
    Abstract 1. Introduction 2. Related work 3. The proposed approach 4. Experiment
    and performance analysis 5. Conclusion Acknowledgments Data availability statement
    Conflict of interest Credit author contribution sheet Funding References You may
    also like JOURNAL ARTICLES Non-equilibrium current and relaxation dynamics of
    a charge-fluctuating quantum dot Design a Group Decision Support System Model
    to Determine Accreditation of Early Childhood Education Institutions Consensus
    ranking for multi-objective interventions in multiplex networks Major Mergers
    Are Not the Dominant Trigger for High-accretion AGNs at z ∼ 2 Solar Flare Index
    Prediction Using SDO/HMI Vector Magnetic Data Products with Statistical and Machine-learning
    Methods Charge transport through single molecules, quantum dots and quantum wires
    Quantum Integrated Circuit (IC) Designer Rigetti Computing DevOps-Engineer/Sysadmin
    (35) ELI Beamlines Postdoctoral fellow – plasma betatron (197) ELI Beamlines More
    jobs Post a job IOPSCIENCE Journals Books IOP Conference Series About IOPscience
    Contact Us Developing countries access IOP Publishing open access policy Accessibility
    IOP PUBLISHING Copyright 2024 IOP Publishing Terms and Conditions Disclaimer Privacy
    and Cookie Policy PUBLISHING SUPPORT Authors Reviewers Conference Organisers This
    site uses cookies. By continuing to use this site you agree to our use of cookies.
    IOP Publishing Twitter page IOP Publishing Facebook page IOP Publishing LinkedIn
    page IOP Publishing Youtube page IOP Publishing WeChat QR code IOP Publishing
    Weibo page"'
  inline_citation: '>'
  journal: 'Machine Learning: Science and Technology'
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Sparse optical flow outliers elimination method based on Borda stochastic
    neighborhood graph
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Chen X.
  - Ma Q.
  - He Z.
  - Sun X.
  - Ren Y.
  citation_count: '0'
  description: Structured light measurement is widely used in welding seam tracking
    because of its high precision and robustness. For the narrow butt joint, the positioning
    method by reconstructing the weld contour is not suitable for the welding of the
    narrow butt joint because it is difficult for the laser stripe to produce obvious
    deformation when projected to the weld. In this study, high-quality images with
    laser stripes and narrow butt joints are captured by the improved structured light
    vision sensor, which is equipped with an auxiliary light source. A two-step processing
    framework, including semantic segmentation and groove positioning, is raised to
    locate the feature point of the narrow butt joint. Firstly, we design the strip
    pooling ENet (SP-ENet), a real-time network specifically designed to accurately
    segment narrow weld images. Our proposed network outperforms other classical segmentation
    networks in terms of segmentation accuracy and proves to be highly suitable for
    the detection of narrow butt joint welds. Secondly, a combining method of random
    sample consensus (RANSAC) and iterative fitting to calculate the sub-pixel coordinates
    of weld feature points accurately. Finally, a trajectory smoothing model based
    on the Kalman filter is proposed to reduce the trajectory jitter. The above methods
    were tested on a self-built robotic welding experimental platform. Experimental
    results show that the proposed method can be used for real-time detection and
    positioning of narrow butt joints. The positioning trajectory is smooth, with
    most positioning errors less than 2 pixels. The mean tracking error reaches 0.207
    mm, which can meet the practical welding requirements.
  doi: 10.1088/1361-6501/ad16b9
  full_citation: '>'
  full_text: '>

    "We value your privacy Clicking the \"Accept All\" button means you are accepting
    analytics and third-party cookies. We use cookies to optimise site functionality
    and give you the best possible experience. To control which cookies are set, click
    \"Customize\". Privacy and Cookies policy Customize Accept All Skip to content
    IOP Science home Accessibility Help Search Journals Books Publishing Support Login
    Measurement Science and Technology PAPER Real-time detection and localization
    method for weld seam of narrow butt joint based on semantic segmentation Xinyu
    Chen1, Qihao Ma2,1, Zhuzhen He1, Xiaoyu Sun1 and Yan Ren1 Published 27 December
    2023 • © 2023 IOP Publishing Ltd Measurement Science and Technology, Volume 35,
    Number 3 Citation Xinyu Chen et al 2024 Meas. Sci. Technol. 35 035205 DOI 10.1088/1361-6501/ad16b9
    Download Article PDF Figures References Open science   Article metrics 95 Total
    downloads Submit Submit to this Journal Permissions Get permission to re-use this
    article Share this article Article and author information   Abstract Structured
    light measurement is widely used in welding seam tracking because of its high
    precision and robustness. For the narrow butt joint, the positioning method by
    reconstructing the weld contour is not suitable for the welding of the narrow
    butt joint because it is difficult for the laser stripe to produce obvious deformation
    when projected to the weld. In this study, high-quality images with laser stripes
    and narrow butt joints are captured by the improved structured light vision sensor,
    which is equipped with an auxiliary light source. A two-step processing framework,
    including semantic segmentation and groove positioning, is raised to locate the
    feature point of the narrow butt joint. Firstly, we design the strip pooling ENet
    (SP-ENet), a real-time network specifically designed to accurately segment narrow
    weld images. Our proposed network outperforms other classical segmentation networks
    in terms of segmentation accuracy and proves to be highly suitable for the detection
    of narrow butt joint welds. Secondly, a combining method of random sample consensus
    (RANSAC) and iterative fitting to calculate the sub-pixel coordinates of weld
    feature points accurately. Finally, a trajectory smoothing model based on the
    Kalman filter is proposed to reduce the trajectory jitter. The above methods were
    tested on a self-built robotic welding experimental platform. Experimental results
    show that the proposed method can be used for real-time detection and positioning
    of narrow butt joints. The positioning trajectory is smooth, with most positioning
    errors less than 2 pixels. The mean tracking error reaches 0.207 mm, which can
    meet the practical welding requirements. Export citation and abstract BibTeX RIS
    Previous article in issue Next article in issue 1. Introduction In recent years,
    the industrial production level has been moving towards automation and intelligence,
    and the massive investments in welding robots have improved welding conditions
    and productivity. Currently, the mainstream of welding robots with traditional
    laser vision sensors is to project laser light onto the surface of the weldment,
    and reconstruct the three-dimensional contour data of the weld. Based on the contour
    data, the customized groove detection algorithm is developed to realize the positioning
    of the weld [1, 2]. It is more suitable for workpieces with large bevels, such
    as V-groove, T-groove, lap grooves, corner joints and so on [3, 4]. However, for
    weldments without bevels or small angle bevels, such as narrow butt joints, there
    is no significant deformation of the laser stripes at the weld when the laser
    is projected into this type of weld [5]. Therefore, the above weld detection methods
    based on 3D contour data are unsuitable for application of narrow weld seam guide
    welding. Shao et al [6] designed a laser vision system for narrow weld seam localization,
    which reconstructs the 3D contour of the weld seam using binocular vision with
    two red laser beams and a third green laser to measure the edge and centerline
    of the weld seam, and finally obtains the 3D coordinates by projecting the weld
    seam information onto the fitted plane through a vision model. However, this method
    has high requirements for weldments. Based on the fact that the line laser does
    not reflect back to the camera at the narrow gap weld, several researchers proposed
    some combination methods of image denoising and grayscale statistics to calculate
    the positions of weld feature points [7, 8]. Fang et al [9] calculated the features
    of the weld seam in the weld image based on the geometric relationship between
    the initialization and tracking stages of the weld seam, and proposed an initial
    weld point location method. Meanwhile, these methods only consider the case of
    small noise, and cannot achieve a good extraction effect when the noise in the
    image is large. Several researchers have attempted to achieve the goal of positioning
    welding seams by modifying the measuring device. Xue et al [10] projected the
    crosshair laser onto the surface of the workpiece, and combined the 2D and 3D
    information in the collected images to calculate the three-dimensional coordinates
    of the groove and the normal vector of the weldment surface. Wei et al [11] designed
    a monocular vision, dual-position weld tracking system, and proposed an improved
    Harris algorithm and grayscale scanning method to improve the accuracy of image
    processing. Wang et al [12] designed a measurement system containing multiple
    optical amplifiers and combined the narrow depth of field (NDOF) method to solve
    the narrow weld seam measurement problem. However, these methods are not suitable
    for narrow butt welds due to significant tracking errors. As deep learning technology
    has gradually matured, several researchers have integrated deep learning and other
    technologies into the field of seam tracking, leading to notable advancements.
    Based on the powerful knowledge representation ability of deep learning, Zou et
    al [13] trained a lightweight semantic segmentation network to filter out reflections,
    splashes, and other noise in the image to extract weld feature points. In addition,
    they also proposed a two-stage weld feature point localization method that combines
    convolutional filters and reinforcement learning (CF-DRL), which has achieved
    good results in the welding task of large groove welds [14]. Yang et al [15] proposed
    a new weld image denoising method to remove spatter, arc light, and smoke during
    welding using the powerful contextual feature expression ability of deep convolutional
    neural network (DCNN). From the above research results, the method of locating
    the weld position by extracting the contour feature points is not applicable due
    to the lack of obvious contour features of the narrow butt weld. Moreover, the
    weld feature point extraction algorithm based on traditional image processing
    is greatly affected by ambient light. Inspired by the data representation capability
    of deep learning, a two-stage method is proposed to solve the problem of locating
    narrow butt welds. Our work can be summarized in the following two steps: (1)   The
    regions of interest (ROI) of weld and laser stripe are obtained by semantic segmentation.
    (2)   The center points of the weld and laser stripes are extracted respectively,
    and the coordinates of the weld feature point are calculated by fitting their
    respective center points and solving their intersection point. In order to ensure
    extraction accuracy, a trick of combination of RANSAC method and iterative fitting
    is raised in the step (2) to achieve the sub-pixel precision. Based on this, the
    welding task is accomplished through the integration of a seam tracking method,
    as previously shown [16]. 2. System description The robotic weld seam tracking
    system mainly consists of a six-degree-of-freedom welding robot, a robot controller,
    a line laser sensor, a welding torch, and a computer, as shown in figure 1. The
    laser sensor is used to capture the images of the weld seam and transmit the images
    to the computer for butt joint positioning. Then the errors between weld seam
    and torch are returned to the robot controller, which guides the robot to correct
    the welding torch movement in real time. Zoom In Zoom Out Reset image size Figure
    1. System structure. Download figure: Standard image High-resolution image For
    the detection of large groove welds, the laser stripe has obvious geometric features
    modulated by the groove, as shown in figure 2, so the positioning task can be
    completed by extracting the geometric feature points of the laser stripe. However,
    for narrow butt-jointed seams, the laser stripe is not modulated to generate significant
    geometric deformation due to the closely adhering welding plates. Different from
    the conventional laser sensor, a strip-shaped ambient light source is added at
    the bottom of the laser sensor in this paper, as shown in figure 3. A blue light
    source with the wavelength of 450 nm that corresponding to the laser emitter,
    which makes both the weld seam and the laser stripe clearly visible. Zoom In Zoom
    Out Reset image size Figure 2. V-groove weld seam image captured by a conventional
    laser sensor. Download figure: Standard image High-resolution image Zoom In Zoom
    Out Reset image size Figure 3. Improved vision sensor and weld seam image captured
    by it. Download figure: Standard image High-resolution image In the actual welding
    process, whether it is gas welding or laser welding, spatter is an inevitable
    imaging interference factor. Our many practical welding experiments have shown
    that fewer splashes entering the imaging system can be ensured by installing an
    arc-blocking device behind the sensor to prevent arc and splash, reducing the
    aperture size and exposure time of industrial cameras. 3. Positioning of narrow
    butt joint weld In order to achieve the tracking of narrow butt joint weld, the
    feature point localization designed in this paper includes the following steps:
    (1)   Appropriate preprocessing is performed on weld seam images to expand the
    gray level difference between the background, weld seam and laser stripes, such
    as gamma transformation correction. Secondly, the processed image is fed into
    a deep learning network model to get the pixel-level semantic segmentation of
    the three regions. (2)   The segmented weld seam region and the laser stripe region
    are thinned, then the skeleton centers of both regions are extracted separately.
    (3)   Firstly, a straight line fitting is conducted using all the center points
    of the weld seam and laser stripes as samples respectively, allowing for the calculation
    of the initial position of the weld seam feature. Subsequently, based on this
    initial point, resampling of the central points within the designated threshold
    range and again fitting are performed to acquire more precise coordinates of the
    weld feature points. (4)   To improve the positioning accuracy and stability,
    the Kalman filtering algorithm is employed to process the pixel coordinates obtained
    in step (3). The detailed flow of our method is illustrated as figure 4. Zoom
    In Zoom Out Reset image size Figure 4. Narrow butt joint positioning flow chart.
    Download figure: Standard image High-resolution image 3.1. Weld segmentation network
    In actual welding tasks, when welding equipment is deployed to a new production
    environment or used for different workpieces, the staff needs to spend a lot of
    time to adjust the parameters of the feature extraction algorithm or even customize
    a new detection algorithm due to the different characteristics of the welding
    targets. For the solution of the time-consuming and laborious field deployment
    problem, this paper uses deep learning techniques to extract the region of interest
    of the labeled target in the weld image, which provides stable information for
    the subsequent feature point localization. ENet [17], a real-time semantic segmentation
    network, is widely used in embedded devices for its fast speed and small model.
    The SP-ENet network proposed in this paper is similar to overall structure of
    ENet. By improving the RegularBottleneck module in ENet and trimming model output
    channels, the model finally inherits the real-time performance of ENet, meanwhile
    improving the segmentation accuracy of the model. The structure of the RegularBottleneck
    module in ENet is shown in figure 5. The improved bottleneck structure called
    SP-RegularBottleneck is shown in figure 6, and the SP-ENet structure information
    is shown in table 1. Zoom In Zoom Out Reset image size Figure 5. RegularBottleneck
    module structure in ENet. Download figure: Standard image High-resolution image
    Zoom In Zoom Out Reset image size Figure 6. SP-RegularBottleneck module structure.
    Download figure: Standard image High-resolution image Table 1. SP-ENet structure
    when the input size is 1 × 3 × 640 × 480. Stage Name Type Output size 1 Initial   1
    × 8 × 320 × 240 2 Bottleneck1.0 Downsampling 1 × 32 × 160 × 120 4*SP-RegularBottleneck1.x
    Regular 1 × 32 × 160 × 120 3 Bottleneck2.0 Downsampling 1 × 64 × 80 × 60 SP-RegularBottleneck2.1
    Regular 1 × 64 × 80 × 60 SP-RegularBottleneck2.2 Dilated 2 1 × 64 × 80 × 60 SP-RegularBottleneck2.3
    Asymmetric 5 1 × 64 × 80 × 60 SP-RegularBottleneck2.4 Dilated 4 1 × 64 × 80 ×
    60 SP-RegularBottleneck2.5 Regular 1 × 64 × 80 × 60 SP-RegularBottleneck2.6 Dilated
    8 1 × 64 × 80 × 60 SP-RegularBottleneck2.7 Asymmetric 5 1 × 64 × 80 × 60 SP-RegularBottleneck2.8
    Dilated 16 1 × 64 × 80 × 60 4 Repeat stage3 without Bottleneck2.0 5 Bottleneck4.0
    Upsampling 1 × 32 × 160 × 120 Bottleneck4.1 Regular 1 × 32 × 160 × 120 Bottleneck4.2
    Regular 1 × 32 × 160 × 120 6 Bottleneck5.0 Upsampling 1 × 8 × 320 × 240 Bottleneck5.1
    Regular 1 × 8 × 320 × 240 7 Transposed Convolution   1 × n × 640 × 480 a a n denotes
    the number of segmentation categories, which was set to 3 in this study, including
    background, weld seam, and laser stripe. The image resolution captured by the
    laser sensor is 1280 × 960, and the larger input image resolution will restrict
    the inference speed of the network more seriously, therefore, the image size is
    resized to 640 × 480 using the bilinear interpolation method. Stage 1–Stage 4
    of the network structure is the encoding part, which is responsible for extracting
    image features; Stage 5–Stage 6 is the decoding part, which is responsible for
    recovering image details. Table 1 shows that compared with ENet, SP-ENet built
    in this paper uses SP-RegularBottleneck in the main convolutional Bottleneck module
    in stages 2–4 of the encoding Stage. The output feature map of each layer has
    half as many channels as the original. The improvement of the RegularBottleneck
    module takes full advantage of the long and narrow characteristics of the segmentation
    targets (both weld region and laser stripe region). The literature [18] points
    out that standard spatial pooling has the role of collecting spatial contextual
    information. However, it will inevitably contain many irrelevant regions when
    dealing with irregularly shaped objects. Compared with spatial pooling that relies
    on square kernels, strip pooling makes it easier to establish long-term dependencies
    between discrete distributed regions, as shown in figure 7. At the same time,
    the strip pooling operation also possesses the ability to capture local detail
    information with small convolutional kernels due to the narrow and long kernels.
    After the central convolution of the auxiliary branch of RegularBottleneck, the
    improved bottleneck structure uses the convolution kernels of size 1 × 3 and 3
    × 1 to pool the extracted new feature maps in the vertical and horizontal directions
    respectively, and then convolves and expands the pooling results in turn. Finally,
    the expanded feature maps in the vertical and horizontal directions are summed
    and processed with the 1 × 1 convolution kernel. In a certain sense, strip pooling
    is also an attention mechanism in the improved bottleneck module by establishing
    the relationship between each position in the input tensor and each position in
    the output tensor through the product operation with the input features. Zoom
    In Zoom Out Reset image size Figure 7. Strip pooling. Download figure: Standard
    image High-resolution image Different from average pooling, strip pooling regards
    each row and column of the feature map as a workplace. It operates in the spatial
    extent of H × 1 or . As a result of averaging all pixels in each row or column
    of the feature map, the strip pooling operation can be expressed as: where the
    denotes the pixel value at the position of the ith row and jth column of the feature
    map, and are the outputs of vertical strip pooling and horizontal strip pooling,
    respectively. 3.2. Weld feature point positioning Since laser stripes are difficult
    to be modulated by narrow butt welds, the intersection of the weld seam and the
    laser stripe center by line fitting is defined as the feature point in this study.
    Firstly, the center points of the weld seam and laser stripe are extracted from
    the segmentation map. Then, the weld feature point coordinate can be obtained
    by fitting the center points and calculating the intersection coordinates. After
    network segmentation inference, the segmentation maps of the weld seam, laser
    stripe, and background can be fetched, as shown in figure 8(b). Semantic segmentation
    achieves region segmentation by classifying each pixel point in the image. In
    each segmentation image, a different target is represented by a different color.
    Yellow is used to indicate the laser stripe region, and red is used to indicate
    the weld seam region. As a result, the ROI of the weld seam and laser stripe lose
    their gray gradient. Based on this, we utilize the Zhang-Suen [19] algorithm to
    thin the weld seam and laser stripe regions to obtain the skeleton centers as
    shown in figure 8(c). The non-skeleton pixel points are removed from the image
    by continuously iterating. Zoom In Zoom Out Reset image size Figure 8. The flow
    of weld image processing. (a) Image acquired by the sensor. (b) The result of
    SP-ENet segmentation. (c) Center profile of weld seam and laser stripe. (d) The
    result of RANSAC denoising. (e) The result of initial positioning. (f) The result
    of refined positioning. Download figure: Standard image High-resolution image
    In order to balance the real-time and generalization of the segmentation model,
    it is difficult to achieve zero-error segmentation with the deployed model. Because
    of the effect of manual spot welding, a certain amount of speckle noise is inevitable
    in the segmentation results, as marked part in figure 8(b). The RANSAC algorithm
    [20] is applied to denoise the center points to eliminate the error brought by
    the interference points in the fitting solution. During the sampling process,
    some outlier points are excluded from the sets of centroids, as marked part in
    figure 8(c). Two points, and , are randomly selected from the set of extracted
    center points at each iteration to determine a line , which is given as: All points
    are divided into inner and outer points by the fitted line and the set distance
    threshold are given as follows: According to the model segmentation accuracy,
    the iteration times of the RANSAC algorithm are set to 20 to ensure less processing
    time for the system. After repeated sampling, the inner points set with the largest
    number of elements is selected as the final result of sampling, respectively,
    noted as WPr and SPr , where WPr denotes the set of sampled weld center points
    and SPr denotes the set of sampled laser stripe center points. The sampling result
    is shown in figure 8(d). Considering the shape type of the weld in the actual
    welding, the least square method is employed to fit the line. The initial positioning
    result of the feature point is the intersection of the two lines, denoted as .
    However, the actual weld trajectory is not a completely straight line. Therefore,
    the initial positioning result mostly deviates from the actual weld feature point,
    which has a great impact on the final welding quality, as shown in figure 8(e).
    The yellow box indicates the ground truth (GT) weld feature point position, and
    the blue box indicates the calculated position of the weld feature point. To eliminate
    this bias, the skeleton center points located within 100 pixels around are resampled
    based on the point sets WPr and SPr . Finally, the refined coordinates of the
    intersection points are solved to eliminate the influence of distant points from
    the actual feature point, as shown in figure 8(f). 3.3. Trajectory smoothing based
    on Kalman filter To address the issue of welding trajectory jitter caused by positioning
    algorithm errors and various types of noise, the Kalman filter algorithm [21]
    is employed to achieve a smoother welding trajectory. Under the assumption of
    disregarding the shape of the workpiece and stable scanning of the weld seam by
    the robot, in the pixel coordinate system, the velocities of the feature points
    in the x and y directions are expected to be very small (approximated as 0). Consequently,
    the motion of the weld seam feature point under pixel coordinate system can be
    represented as: where x(k) and y(k) represent the coordinates of the weld seam
    feature points on the image plane''s X- and Y-axis at time k, respectively, while
    and represent the process noise that introduces uncertainties in the state of
    the weld seam feature point components. We define the state feature vector of
    the weld feature point coordinate as: . The state transition equation and observation
    equation of feature points can be expressed as: where Z(k) represents the refined
    positioning result, that is, the observed value. is the process noise, and it
    conforms to a normal distribution with mean 0 and variance Q, denoted . is the
    measurement noise in the refined positioning results, and it conforms to a normal
    distribution with mean 0 and variance R, denoted . Q and R are the covariance
    matrices of the two noises, respectively. Define the state transition matrix as
    and the observation matrix as . The prediction and update stages in Kalman filtering
    can be expressed as: where is the estimated state of the feature point calculated
    according to the state transition model, is the estimated value of the covariance
    matrix, is the Kalman gain matrix, and are the corrected feature point state and
    covariance matrix. 4. Experimental verification and analysis 4.1. Data acquisition
    To capture the image data of the narrow butt joint weld, a robot welding system
    platform was built, as shown in figure 9, which mainly includes a welding robot,
    an improved laser seam tracking sensor, some welding experiment workpieces, and
    a weld seam tracking control system. The robot is a MOTOMAN-GP12 arc welding robot
    with a YRC1000 robot controller developed by YASKAWA. The sensor is a line laser
    vision sensor developed by our research team. The industrial computer configuration
    is as follows: Intel i7-12 700KF, RTX 3080Ti. In the experiment, the sensor was
    installed 100 mm before the welding torch. The installation height was 174 mm.
    The width of the laser stripe projected onto the workpiece surface was 150 mm.
    The laser sensor installation diagram is shown in figure 10. Zoom In Zoom Out
    Reset image size Figure 9. Robot welding physical platform. In our experiments,
    two types of welds were used to test the performance of our narrow butt weld positioning
    algorithm. (a) Straight butt weld, workpiece size is 200 × 100 × 8 mm. (b) Circular
    butt weld, diameter is 65 mm. Download figure: Standard image High-resolution
    image Zoom In Zoom Out Reset image size Figure 10. The laser sensor installation
    diagram. Download figure: Standard image High-resolution image The welding method
    used is gas metal arc welding (GMAW). Detailed welding parameters are shown in
    table 2. All the image data were acquired under this condition. In order to validate
    the segmentation effectiveness of the designed deep learning network and the performance
    of the feature point extraction algorithm, we collected multiple sets of narrow
    butt weld seam images under varied environmental illumination and robot poses
    for the training of the welding seam segmentation network in section 3.1. Additionally,
    multiple narrow butt welding seam detection videos were captured at 10 mm s−1
    to test the weld feature point positioning method proposed in section 3.2. The
    sampling frequency of the laser vision sensor was 40 Hz. The Control cycle of
    the robot was about 50 ms. Table 2. Welding parameters. Parameters Value Parameters
    Value Welding method GMAW Gas flow 10 l min−1 Workpiece material Q235 Welding
    voltage 20 V Welding speed 10 mm s−1 Welding current 120A Shielding gas Argon
    gas Wire diameter 1.2 mm 4.2. The segmentation network training experiment To
    facilitate the training of the proposed semantic segmentation network, we built
    a narrow butt welding images dataset, meticulously annotated using Labelme to
    define regions corresponding to the background, weld, and laser stripes. The dataset
    comprises a total of 560 images showcasing narrow butt welds under different illumination
    and different materials. To enhance the generalization capability of the model,
    we expanded the dataset to 917 images using techniques such as image translation,
    rotation, scaling, and brightness adjustment. During the training phase, we partitioned
    the dataset into three subsets: a training set with 638 images, a validation set
    with 190 images, and a test set with 89 images. Table 3 shows the detailed dataset
    distribution. The training loss employed the cross-entropy loss function with
    weights. Considering the significant differences in the number of pixels of background,
    weld, and laser stripes in the dataset. The class weight is set to weight = [1.4414,
    36.1888, 33.0642] to balance the influence of different class distributions on
    the training results. Each class weight in the dataset can be obtained as follows:
    where Nc is the number of pixels of class c in the dataset, T is the total number
    of pixels in the dataset. Dropout is a regularization method often used in convolutional
    neural networks to prevent overfitting and improve generalization ability. It
    stops the activation of specific neurons with a certain probability. A high dropout
    leads to too much information loss and the training effect of the model decreases.
    A low dropout leads to insufficient generalization ability of the model. Our neuron
    deactivation experiment shows that adding a dropout with a deactivation probability
    of 0.1 to the end of the auxiliary branch in the bottleneck structure enables
    SP-ENet to train to the best state. The experimental results are presented in
    table 4. For optimization, the stochastic gradient descent (SGD) was utilized,
    along with exponential decay as the learning rate decay method. The network segmentation
    accuracy was evaluated using the mean intersection over union (MIoU). The hardware
    and software settings used in training are listed in table 5. Table 3. Narrow
    butt joint weld seam dataset. Category Quantity Ratio Training set 638 70% Validation
    set 190 20% Test set 89 10% Table 4. Training results with different dropout rates.
    No. Dropout rate MIoU (%) 1 0 54.8 2 0.1 82.3 3 0.2 77.7 4 0.3 76.0 5 0.4 73.8
    Table 5. Software and hardware environment. Name Parameter System Windows 10 CPU
    i7-12700KF 3.60 GHz GPU NVIDIA GeForce RTX 3080 Ti Cuda 11.7 Software environment
    Pytorch 1.12.1+Python 3.7.4 After completing the training of the SP-ENet model,
    we also trained several classic semantic segmentation networks, including DeepLabV3
    [22] (backbone: MobileNetV2 [23]), PSPNet [24] (backbone: ResNet34 [25]), SegNet
    [26] and ENet. The total number of model parameters (Params), floating point operations
    (FLOPs), and frames per second (FPS) are used as the evaluation criterion for
    the complexity and inference speed of the network. Params indicates the number
    of parameters that can be learned in the model, which is used to evaluate the
    complexity and storage cost of the model. FLOPs indicates the number of floating-point
    operations required by the network to perform a forward propagation, which is
    used to evaluate the computational complexity and efficiency of the model. FPS
    indicates the number of images that can be processed per second. Notably, there
    is not a strong correlation between FLOPs and FPS. The FPS metrics of all models
    were tested on the RTX 3080Ti with the same input resolution, as depicted in table
    6. Compared our SP-ENet with DeepLabV3, PSPNet, SegNet, and ENet, the improvements
    are respectively 4.2%, 4.5%, 1% and 2.8% in the MIoU. Table 6. Network performance
    comparison. Model Resolution Params (M) FLOPs (G) MIoU (%) FPS DeepLab V3 1 ×
    3 × 640 × 480 7.556 39.668 78.1( 4.2) 120 PSPNet 1 × 3 × 640 × 480 23.395 132.009
    77.8( 4.5) 45 SegNet 1 × 3 × 640 × 480 29.445 188.332 81.3( 1) 43 ENet 1 × 3 ×
    640 × 480 0.349 2.480 79.5( 2.8) 82 SP-ENet (Ours) 1 × 3 × 640 × 480 0.583 1.174
    82.3 64 After completing the segmentation network training, we conducted actual
    segmentation tests on the trained network using the test set data. For a comprehensive
    evaluation, we selected six representative weld images and compared the segmentation
    results, as depicted in figure 11. Notably, compared to other networks, our SP-ENet
    exhibited several advantages, including reduced glitches, less noise, enhanced
    continuity in the segmentation of weld seams and laser stripes, and a greater
    ability to achieve detailed target segmentation. Even when dealing with images
    that are too bright and too dark due to illumination, our SP-ENet shows excellent
    segmentation results, especially for the recognition of laser stripes, as shown
    in figure 11(a)-2. This advantage is attributed to the strip pooling module, which
    makes the model pay more attention to the strip targets in the image during the
    training phase. Although there are still some minor errors in the segmentation
    results, our subsequent introduction of the RANSAC method can easily solve the
    problem as well. As a result, our system is also suitable for some reflective
    materials. Zoom In Zoom Out Reset image size Figure 11. Comparison of segmentation
    effects. (a) The input images. (b) DeepLab V3. (c) PSPNet. (d) SegNet. (e) ENet.
    (f) SP-ENet. (g) The ground truth. Download figure: Standard image High-resolution
    image 4.3. Positioning algorithm experiment Narrow butt welds are commonly encountered
    in actual production environments. To assess the general applicability of the
    proposed positioning algorithm, we selected two different seam tracking sequences
    from the collected video data, which included a straight butt welding sequence
    and a circular butt welding sequence, as shown in figure 9. The ground truth positions
    in these sequences were accurately labeled. We employed the proposed two-stage
    positioning method to compute the pixel coordinates of the weld feature points.
    During the experiment, we utilized the weld feature points marked in the tracking
    sequences as the ground truth and evaluated the errors of the two positioning
    stages. The error comparison result is shown in figure 12. The blue curve denotes
    the initial positioning error, and the red curve denotes the refined positioning
    error. The initial positioning stage uses all weld center points as fitting samples,
    which makes the fitted lines inaccurately describe the weld track. As a result,
    there is a large error in the initial positioning. Conversely, the samples used
    for the refined positioning fitting are generally located around the feature points.
    The method of local sampling eliminates the errors caused by remote pixel points.
    Under the assumption of disregarding labeling errors, the majority of positioning
    errors can be effectively constrained within 2 pixels. The detailed positioning
    error statistics are provided in table 7. Zoom In Zoom Out Reset image size Figure
    12. Errors comparison between initial and refined positioning. (a) Straight butt
    welding sequence. (b) Circular butt welding sequence. Download figure: Standard
    image High-resolution image Table 7. Positioning error statistics of initial and
    refined positioning. Weld sequence Positioning phase Mean error (pixel) Percentage
    for error 2(%) Straight butt welding sequence(a) Initial positioning 1.24 92.64
    Refined positioning 0.87 96.99 Circular butt welding sequence(b) Initial positioning
    1.79 70.71 Refined positioning 1.52 77.38 After the pixel coordinates of feature
    points are obtained through initial positioning and precise positioning, the initial
    state of the Kalman filter model is set as follows: After the pixel coordinates
    of the filtered feature points are obtained, the welding trajectory can be obtained
    by combining the parameters of the calibrated robot hand-eye system and the laser
    vision sensor. In order to prevent the calibration errors of the hand-eye system
    and the vision system from being introduced into the positioning method, the actual
    trajectory is obtained by labeling the sampling frames. The experimental results
    are shown in figure 13. For a more intuitive view of weld trajectories, the trajectory
    in X-O-Y plane is shown for straight butt weld, and the trajectory in X-O-Z plane
    is shown for circular butt weld. The Euclidean distance between the welding position
    after Kalman filtering and the labeled actual welding position is used to represent
    the welding error. Detailed error statistics are shown in table 8. It is worth
    noting that in two experiments, the mean tracking error of our method is less
    than 0.21 mm, and the root mean square error (RMSE) reaches 0.219 mm. Besides,
    the trajectory smoothness index proposed in the literature [27] is employed to
    quantitatively analyze the trajectory before and after filtering. A lower index
    value indicates a smoother trajectory. The results are presented in table 9. Zoom
    In Zoom Out Reset image size Figure 13. Comparison of the actual trajectory, refined
    positioning trajectory and filtered trajectory, and error analysis. Download figure:
    Standard image High-resolution image Table 8. Trajectory error analysis. Workpiece
    Mean error (mm) Minimum (mm) Maximum (mm) Error range (mm) RMSE (mm) Straight
    butt weld seam (a) 0.207 0.058 0.476 0.418 0.219 Circular butt weld seam (b) 0.177
    0.018 0.552 0.534 0.207 Table 9. Comparison of smoothness index before and after
    filtering. Workpiece Before filtering After filtering Straight butt weld seam
    (a) 0.0776 0.0381 Circular butt weld seam (b) 0.0549 0.0288 As depicted in figure
    13, the weld trajectory after Kalman filtering exhibits smoother characteristics
    compared to the refined positioning. The experimental results show that our method
    can be used to locate and detect narrow butt welds. Further scrutinizing the overall
    positioning process, we identified the primary sources of positioning errors,
    which are as follows: (1)   Errors in the annotation of weld feature points for
    the long sequence tracking video. (2)   Errors in segmentation inference of the
    weld seam and laser stripes. (3)   Errors in extracting the center points of the
    weld seam and laser stripe regions by skeleton method. 4.4. Applications of the
    proposed localization method The localization method proposed in this study is
    based on the concept of deep learning, which makes it highly resistant to variations
    in illumination. Since this method requires images with little splash, we recommend
    that it be used in welding tasks with little splash during welding, such as laser
    welding, GMAW (shielding gas is argon), and gas tungsten arc welding (GTAW). Besides,
    our SP-ENet also shows good segmentation on weld images of reflective materials,
    making it ideal for the welding task of narrow butt workpieces with reflective
    materials. 5. Conclusions The following conclusions can be drawn from this study:
    (1)   To solve the problem that traditional laser vision sensors cannot be applied
    to narrow butt welding seam welding, we improve the existing laser sensors and
    propose a two-step method for narrow butt weld positioning, including semantic
    segmentation and feature point positioning. (2)   We design a real-time segmentation
    network for narrow butt joint welds called SP-ENet. Under the constraint of maintaining
    real-time performance, the network achieves an average segmentation accuracy of
    82.3%, outperforming other classical segmentation networks regarding segmentation
    effectiveness. (3)   In the feature point positioning phase, we introduce an innovative
    approach that combines random sampling consistency and iterative fitting to locate
    the weld feature point based on segmented images, enabling sub-pixel level positioning.
    (4)   A trajectory smoothing model based on the Kalman filter is proposed to reduce
    welding jitter and improve the smoothness of the weld trajectory. (5)   The experimental
    results demonstrate that the proposed method is suitable for narrow butt welding.
    The overall welding seam trajectory is smooth, with most positioning errors effectively
    controlled within 2 pixels. Additionally, the mean tracking error reaches 0.207
    mm. Data availability statement The data cannot be made publicly available upon
    publication because they contain commercially sensitive information. The data
    that support the findings of this study are available upon reasonable request
    from the authors. Funding This study was supported by the Basic Research Project
    (General Project) of the Education Department of Liaoning Province (No. JYT2020018),
    Natural Science Foundation of Liaoning Province (No. 2020-MS-235) and Science
    Foundation of Education Department of Liaoning Province (No. LJKZ0219). Show References
    Abstract 1. Introduction 2. System description 3. Positioning of narrow butt joint
    weld 4. Experimental verification and analysis 5. Conclusions Data availability
    statement Funding References You may also like JOURNAL ARTICLES Welding Seam Detection
    and Tracking Based on Laser Vision for Robotic Arc Welding The Influence of Control
    Parameters on Precision of Welding Seam Tracking in Manually Control Master-slave
    Robot Remote Welding System Nanoparticles reinforced joints produced using friction
    stir welding: a review LABVIEW Based Simulation on Welding Seam Tracking Using
    Edge Detection Technique Welding seam recognition and tracking for a novel mobile
    welding robot based on multi-layer sensing strategy The characteristic of interface
    microstructure for aluminum-steel butt joint by arc assisted laser welding-brazing
    Technicians & Engineers CEA-Irfu Postdoctoral Researcher- Cloud microphysics and
    aerosol-cloud interactions Lawrence Livermore National Laboratory More jobs Post
    a job IOPSCIENCE Journals Books IOP Conference Series About IOPscience Contact
    Us Developing countries access IOP Publishing open access policy Accessibility
    IOP PUBLISHING Copyright 2024 IOP Publishing Terms and Conditions Disclaimer Privacy
    and Cookie Policy PUBLISHING SUPPORT Authors Reviewers Conference Organisers This
    site uses cookies. By continuing to use this site you agree to our use of cookies.
    IOP Publishing Twitter page IOP Publishing Facebook page IOP Publishing LinkedIn
    page IOP Publishing Youtube page IOP Publishing WeChat QR code IOP Publishing
    Weibo page"'
  inline_citation: '>'
  journal: Measurement Science and Technology
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Real-time detection and localization method for weld seam of narrow butt
    joint based on semantic segmentation
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Qian Q.
  - He M.
  - Sun F.
  - Liu X.
  citation_count: '0'
  description: Increasing bacteria levels in the Lower Neches River caused by Hurricane
    Harvey has been of a serious concern. This study is to analyze the historical
    water sampling measurements and real-time water quality data collected with wireless
    sensors to monitor and evaluate water quality under different hydrological and
    hydraulic conditions. The statistical and Pearson correlation analysis on historical
    water samples determines that alkalinity, chloride, hardness, conductivity, and
    pH are highly correlated, and they decrease with increasing flow rate due to dilution.
    The flow rate has positive correlations with Escherichia coli, total suspended
    solids, and turbidity, which demonstrates that runoff is one of the causes of
    the elevated bacteria and sediment loadings in the river. The correlation between
    E. coli and turbidity indicates that turbidity greater than 45 nephelometric turbidity
    units in the Neches River can serve as a proxy for E. coli to indicate the bacterial
    outbreak. A series of statistical tools and an innovative two-layer data smoothing
    filter are developed to detect outliers, fill missing values, and filter spikes
    of the sensor measurements. The correlation analysis on the sensor data illustrates
    that the elevated sediment/bacteria/algae in the river is either caused by the
    first flush rain and heavy rain events in December to March or practices of land
    use and land cover. Therefore, utilizing sensor measurements along with rainfall
    and discharge data is recommended to monitor and evaluate water quality, then
    in turn to provide early alerts on water resources management decisions.
  doi: 10.1016/j.wse.2023.10.002
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Abstract Keywords 1. Introduction 2. Materials and methods 3. Results
    and discussion 4. Summary and conclusions Declaration of competing interest References
    Show full outline Figures (14) Show 8 more figures Tables (2) Table 1 Table 2
    Water Science and Engineering Volume 17, Issue 1, March 2024, Pages 21-32 Monitoring
    and evaluation of the water quality of the Lower Neches River, Texas, USA Author
    links open overlay panel Qin Qian a, Mengjie He b, Frank Sun c, Xinyu Liu b Show
    more Add to Mendeley Share Cite https://doi.org/10.1016/j.wse.2023.10.002 Get
    rights and content Under a Creative Commons license open access Abstract Increasing
    bacteria levels in the Lower Neches River caused by Hurricane Harvey has been
    of a serious concern. This study is to analyze the historical water sampling measurements
    and real-time water quality data collected with wireless sensors to monitor and
    evaluate water quality under different hydrological and hydraulic conditions.
    The statistical and Pearson correlation analysis on historical water samples determines
    that alkalinity, chloride, hardness, conductivity, and pH are highly correlated,
    and they decrease with increasing flow rate due to dilution. The flow rate has
    positive correlations with Escherichia coli, total suspended solids, and turbidity,
    which demonstrates that runoff is one of the causes of the elevated bacteria and
    sediment loadings in the river. The correlation between E. coli and turbidity
    indicates that turbidity greater than 45 nephelometric turbidity units in the
    Neches River can serve as a proxy for E. coli to indicate the bacterial outbreak.
    A series of statistical tools and an innovative two-layer data smoothing filter
    are developed to detect outliers, fill missing values, and filter spikes of the
    sensor measurements. The correlation analysis on the sensor data illustrates that
    the elevated sediment/bacteria/algae in the river is either caused by the first
    flush rain and heavy rain events in December to March or practices of land use
    and land cover. Therefore, utilizing sensor measurements along with rainfall and
    discharge data is recommended to monitor and evaluate water quality, then in turn
    to provide early alerts on water resources management decisions. Previous article
    in issue Next article in issue Keywords Water qualityPearson correlation analysisLower
    Neches RiverYSI wireless sensorsNon-point pollution 1. Introduction Increasing
    non-point pollution levels in waters due to flooding have been top natural hazards
    for the southeast Texas coastal waterbodies, and they contribute to the hypoxia
    in the Gulf of Mexico (Slaff and Drane-Maury, 2019). The Neches River flowing
    669 km from headwaters in Van Zandt County (at 32°30′N and 95°45′W) to its mouth
    on the Sabine Lake (at 29°58′N and 93°51′W) is one of the main water resources
    of the region. The basin has a drainage area of 28 518 km2 with total rainfall
    of 7.4 × 109 m3 per year including the major tributaries of the Angelina River,
    Village Creek, and Attoyac, Ayish, and Pine Island bayous. High rainfall rates
    produce frequent flooding of low-lying areas, and large and long-duration floods
    occur on the average every five years according to the Texas State Historical
    Association (https://www.tshaonline.org). The lower Neches River Basin is flat
    terrain with a substrate composed of sand, gravel, and mud. Significant portions
    of the river basin upstream the Saltwater Barrier are undeveloped and flow through
    protected natural lands. However, the downstream of the barrier has a major shipping
    channel, with highly industrialized urban/suburban areas. Flooding has elevated
    non-point pollution sources possible from wastewater treatment plants, failing
    septic systems, domestic and wild animal wastes, and urban runoff to prompt the
    decay of water quality (Novotny, 1999; TCEQ, 2021). Excess nutrients and organic
    wastes flushed by Hurricane Harvey have caused the Neches River tidal section
    impaired for high concentrations of bacteria and polychlorinated biphenyls (PCBs)
    in edible tissue, which indicates a health risk to people who swim or wade in
    the river, as reported by the Texas Integrated Report (TCEQ, 2021). A total maximum
    daily load (TMDL) and implementation plan (I-Plan) to reduce bacteria and protect
    recreational safety in the Neches River tidal section are being developed by the
    stakeholders and the Texas Commission on Environmental Quality (TCEQ; https://www.tceq.texas.gov/waterquality/tmdl/nav/118-nechestidal-bacteria).
    The Pine Island Bayou, the main tributary of the Neches River above the Saltwater
    Barrier, was identified as the source of the depressed dissolved oxygen (DO) and
    elevated Escherichia coli since Spring 2018 (TCEQ, 2021). Higher bacteria and
    E. coli change the microbial water quality and have a severe negative impact on
    the ecosystem, wild animals, and inhabitants (Maes et al., 2022). Moreover, the
    drinking water pump station for the City of Beaumont is located at the upstream
    of the Saltwater Barrier to provide over 70 % drink water for over 120 000 residents.
    To support sustainable water quality management and secure safe drinking water
    resources, there is an urgent need to monitor and evaluate water quality under
    changing climatic and hydrological conditions. Ecological studies have identified
    the co-occurrence of particular species of algae and bacteria, suggesting the
    presence of their specific interactions in aquatic ecosystems (Muñoz and Guieysse,
    2006). Climate change and extreme weather events present an additional challenge
    to monitor and predict both algal blooms and pathogenic bacteria movement and
    concentration (Cavicchioli et al., 2019). Population of algae, aquatic vegetation,
    grazers, and/or nutrients can change the E. coli concentration or alter the aquatic
    community structure (Vanden Heuvel et al., 2010). Algae and aquatic vegetation
    supply carbon (Ramanan et al., 2016), compete with E. coli for nutrients (Quero
    et al., 2015), shelter E. coli from solar radiation (Curtis et al., 1994), and
    release toxins and stimulants (Martin et al., 2017). The resulting interactions
    between these constituents appear to be convoluted with feedback loops and interrelations
    (Cho et al., 2022). Therefore, different types of algae and aquatic vegetation
    can have different impacts on E. coli survival. Currently, only limited field
    monitoring data of E. coli are available in the Lower Neches River and the Pine
    Island Bayou because microbial analyses are time-consuming, expensive, and difficult
    to perform in remote areas. It is important to find more easily extracted water
    parameters that can serve as a proxy for E. coli to be used as an early indicator
    of bacterial outbreak and fecal contamination. Measuring the intensity of fluorescence
    is traditionally applied to reveal pollution of bacteria as natural dissolved
    organic matter (DOM) plays an important role for bacteria growth (Kroer, 1993).
    Fluorescence increases with increasing DOM in aquatic systems either transported
    from the landscape to waterbodies or created in situ through microbial activity
    (Thomas and Burgess, 2007). The YSI multi-parameter EXO2 sensors can be used for
    continuous and long-term monitoring and recording of DO, turbidity, pH, conductivity,
    temperature, total dissolved solids (TDS), water depth, and fluorescence/chlorophyll/blue-green
    algae. Both chlorophyll and blue-green algae sensors rely on fluorescence to detect
    the pigment concentration (YSI, 2006). A chlorophyll sensor can be used to estimate
    entire phytoplankton populations and recommended in the Standard Methods for the
    Examination of Water and Wastewater (APHA, 1998) to estimate algal populations
    although it only provides a rough estimate of biomass (Schulz, 2007) as it assumes
    that all algae and cyanobacteria have the same levels of chlorophyll a (YSI, 2006).
    A blue-green algae sensor can be used to estimate cyanobacteria concentrations
    specifically (Speer, 1997). Fluorescence, chlorophyll, and blue-green algae are
    linearly related (YSI, 2006). These measurements are used to develop parameter
    limits for bodies of water. For example, the New Hampshire Department of Environmental
    Services (NHDES) provides the following chlorophyll guidelines for river water
    quality: a chlorophyll measurement below 7 μg/L is within a desirable range, 7–15
    μg/L is less than desirable, and over 15 μg/L is considered problematic (NHDES,
    2009). Therefore, the measurement of fluorescence/chlorophyll/blue-green algae
    may be an alternative indicator for excess amounts of algae/bacteria loadings
    and high levels of nutrients from fertilizers, septic systems, sewage treatment
    plants, and urban runoff. A complex EXO2 YSI sensor system was installed at the
    Saltwater Barrier (Fig. 1) downstream the water supply pump station to monitor
    the water quality. Due to the harsh field environmental conditions, time-series
    multi-parameter datasets have error codes (−99.99) and outliers caused by sensor
    deficits (Qian et al., 2019). Data preprocessing to remove the outliers/errors
    and fill the data are necessary because the outliers change the mean and variance
    and shaft the data trend. Based on the data sample size and the distribution type
    of the data, Seo (2006) established guidelines for the choices of outlier detection
    methods in skewed sensor data (Qian et al., 2022). The distributions of time-series
    data are influenced by the geology, land use, and hydrology of its origin, and
    can be investigated under changing hydrological and hydraulic conditions. Download
    : Download high-res image (425KB) Download : Download full-size image Fig. 1.
    Water quality monitoring sites (https://cms.lcra.org/map.aspx?basin=6), rainfall
    data collection sites (https://dd6.onerain.com), and YSI sensor system. The objective
    of this study is to analyze the historical field water sampling measurements and
    real-time water quality data collected with wireless sensors to better monitor
    and evaluate the water quality under changing hydrological and hydraulic conditions.
    The Pearson''s correlation model is applied on the historical field water sampling
    data to understand the relationship between the water quality data under different
    flow rates and define the parameter limits for bodies of water. Sensor measurements
    are firstly preprocessed with a series of newly developed statistical tools. Data
    analysis is conducted to understand the relationship among different water quality
    parameters, e.g., turbidity and fluorescence/chlorophyll, to define an alternative
    indicator for elevated bacteria and algae loadings. The recommendations are provided
    to monitor and evaluate the water quality for securing safe drinking water resources.
    2. Materials and methods 2.1. Study area The land cover and land use for the Pine
    Island Bayou and the Neches River tidal watersheds are dominated by the cultivated
    crop, pasture, forest, and woody wetlands above the Saltwater Barrier, while becomes
    urban/suburban areas downstream of the barrier, as shown in Fig. 1. The Pine Island
    Bayou contributes 10% of the total flow of the Neches River tidal section. To
    assess the water quality close to the drinking water supply pump station, the
    laboratory measured water quality data from water samples collected at stations
    10599, 15343, 10579, and 20774 (left panel in Fig. 1) were obtained from the Lower
    Neches Valley Authority (LNVA) in October 2021. The pH, alkalinity, ammonia-N,
    nitrate-nitrite, chloride, hardness, total phosphorus, sulfate, total suspended
    solids (TSS), turbidity, DO, conductivity, Secchi depth, E. coli (Enterococcus
    at station 20774), and flow rate were collected from 2006 to 2022 at stations
    10599 and 15434, from 2014 to 2020 at station 10579, and from 2010 to 2020 at
    station 20774. As shown in Fig. 1 (right panel), YSI sensors were installed 4.46
    m above the river bottom, in front of the barrier, which typically submerged about
    2–3 m of water. They measured 15-min interval water temperature, water depth,
    DO, pH, turbidity, conductivity/TDS, and fluorescence/chlorophyll/blue-green algae
    starting on March 3, 2016. However, the system was damaged by Hurricane Harvey
    in 2017, and a new system was reinstalled in June 2020. The retreated data from
    March 3, 2016 to April 5, 2017 and from June 5, 2020 to October 12, 2021 were
    preprocessed to assess the water quality before and after Hurricane Harvey occurring
    on August 25–29, 2017. The historical field monitoring data were sufficient to
    identify the water quality issue caused by Hurricane Harvey. YSI time-series data
    were analyzed with rainfall and discharge data to study the relationships among
    hydrological conditions, hydraulic conditions, and water quality for future monitoring
    and evaluation. 2.2. Data analysis on water samples collected at four stations
    The statistical analysis on the historical water quality field data indicates
    that the ranges of the parameters were (1) pH: 5.9–8.0; (2) alkalinity: 10–85
    mg/L; (3) ammonia-N: 0.02–1.20 mg/L; (4) nitrate-nitrite: 0.02–0.47 mg/L; (5)
    chloride: 6.8–15.20 mg/L (freshwater); (6) hardness: 12–90 (freshwater); (7) total
    phosphorus: 0.03–1.51 mg/L; (8) sulfate: 4.00–34.80 mg/L (freshwater); (9) TSS:
    5.00–81.00 mg/L; (10) turbidity: 6.0–99.2 nephelometric turbidity units (NTU);
    (11) DO: 2.2–11.5 mg/L; (12) conductivity: 29–21 590 μS/cm; (13) Secchi depth:
    0.11–0.80 m; (14) E. coli: 1–2 400 most probable number (MPN) per 100 mL; (15)
    temperature: 4°C–36°C; and (16) water elevation above the mean sea level (MSL):
    −1–11 m. The salt water at station 20774 was indicated by high values of chloride,
    hardness, sulfate, and conductivity. To better understand the relationships of
    hydrological parameters to surface water quality, the data from the four stations
    were analyzed for the degree of association between two variables by using Pearson''s
    correlation coefficient (Waskom, 2021). The relationships between flow rate and
    each water quality parameter and between two water quality parameters were investigated.
    2.3. Data smoothing and outlier detection for sensor data The long-term deployment
    with the YSI EXO2 multiparameter sonde inevitably encountered some unexpected
    failure events caused by biofouling and hardware issues, which caused some missing
    and inaccurate data for extended periods. For instance, we missed the DO sensor
    data from March 3, 2016 to April 5, 2017. The pH and water depth sensors created
    some erratic readings from time to time. Initially the sonde was calibrated every
    three months. The current protocol is to calibrate every month to improve the
    reliability and accuracy of the data. The recorded fluorescence, chlorophyll,
    and blue-green algae were linearly correlated as expected. However, negative values
    of blue-green algae were recorded due to the very low level of cyanobacteria concentrations
    at 2–3 m below the water surface. The raw dataset consists of 15-min interval
    measurements of water temperature, conductivity/TDS, chlorophyll/fluorescence,
    and DO (only from June 5, 2020 to October 12, 2021). The water depth/discharge
    from the United States Geological Survey (USGS) 08041780 station, about 500 m
    upstream from the sensor location, was retreated to the dataset for correlation
    analysis. Because the head loss between USGS 08041780 gage station and the installation
    site of the sonde sensors was less than 0.25 cm (Qian et al., 2019), the differences
    in water depth and discharge between two locations could be ignored. A data smoothing
    and outlier/error detection tool was developed in Python to clean individual variable
    in the raw data before correlation analysis. The data cleaning procedure is outlined
    as follows: (1) Labelling missing data caused by hardware failure. The data acquisition
    system recorded any erratic data as –99.99. It was replaced with NaN, which stands
    for “Not A Number” and is the common way to represent missing values in Python.
    (2) Labelling unrealistic data as missing data (NaN) based on the established
    ranges of field measurements. The valid ranges were set as pH of 5.9–8.0, DO of
    2.2–11.5 mg/L, conductivity of 29–21 590 μS/cm, turbidity of 6.0–99.2 NTU, temperature
    of 4°C–36°C, and chlorophyll of 1–20 μg/L. (3) Outlier detection. Outliers are
    data points that are significantly different from the rest of the data, which
    could inflate the variance and distort statistical analyses. Outliers could be
    originated from measurement/sampling errors or natural variability. To avoid removal
    of genuine but extreme values, only extreme outliers were detected and labelled
    as NaN. Extreme outliers are defined as the data points that are more than three
    times the interquartile range (RIQ) from the first quartile Q1 (the 25th percentile)
    and the third quartile Q3 (the 75th percentile), i.e., data values greater than
    Q3 + 3RIQ or less than Q1 − 3RIQ. The interquartile range is the range of middle
    50% of the data, equal to Q3 – Q1. The boxplot is commonly used for graphical
    display of the statistical distribution and outliers as shown in Fig. 2. As an
    example, the outlier detection for turbidity and fluorescence is depicted in Fig.
    3. Download : Download high-res image (87KB) Download : Download full-size image
    Fig. 2. Using boxplots to identify extreme outliers. Download : Download high-res
    image (233KB) Download : Download full-size image Fig. 3. Outlier detection for
    turbidity and fluorescence. (4) Filling values. Fill the NaN with piecewise cubic
    spline interpolation of neighboring valid measurements. (5) Data smoothing with
    the Savitzky–Golay filter. Some spike noises were observed even after outlier
    removal. Given the relatively slow change in the measured variables with respect
    to the sampling period of 15 min, spikes were likely random noises caused by the
    random electromagnetic interference and should be removed. Numerous algorithms
    have been developed on spike removal and de-noising. In this study, the Savitzky–Golay
    (S–G) filter (Savitzky and Golay, 1964) was adopted. The S–G filter is a lowpass
    digital filter originally designed to smooth noisy data obtained from a chemical
    spectrum analyzer, and later was extended for the treatment of two- and three-dimensional
    data, which has been found to be attractive in application of electrocardiogram
    processing (Pandia et al., 2010). The basic idea is to fit a successive sub-set
    of adjacent data points of a length of m with a nth-order polynomial by the least
    square fitting method. When the data points are equally spaced, the fitted polynomial
    is identical to a fixed linear combination of the subset of the input samples.
    That is, the filtered value can be computed by a discrete convolution of the form
    with fixed convolution coefficients: (1) where h(j − i) is the convolution coefficient,
    x(i) is the observed value, and y(j) is the filtered value. For the detailed derivation
    of the convolution coefficients, the readers can refer to the seminal paper (Savitzky
    and Golay, 1964). The window length m and polynomial order n were judiciously
    selected to be 21 and 2, respectively, to have significant noise reduction while
    minimizing signal distortion. The S–G filter is implemented in Python by the SciPy
    API function savgol_filter(). 3. Results and discussion 3.1. Data analysis results
    for water samples Compared with available limits of parameters (TCEQ, 2021), field
    measurements did not reveal any concerns for pH, alkalinity, nitrate-nitrite,
    chloride, hardness, sulfate, and conductivity, although low pH (5.9 < 6.0) and
    alkalinity (10 mg/L < 20 mg/L) were observed (Qian et al., 2022). The depressed
    DO (< 3 mg/L) at stations 10599 and 20774 was observed during the summer due to
    high temperatures. Significant high concentrations of ammonia-N, total phosphorus,
    TSS, and E. coli were detected at all four stations after Hurricane Harvey on
    February 14, 2018, which implies that flooding had caused the elevated nutrient,
    sediment, and bacteria loadings from livestock, pet wastes, and faulty septic
    systems in the watershed. In addition, the E. coli concentration at station 10599
    in the Pine Island Bayou was higher than station 10579 in the Neches River. Therefore,
    controlling bacteria in the Pine Island Bayou is critical for water quality improvement
    in the Neches River. Even though no quantitative criteria for TSS can be found
    in literature, its significance in water quality is well recognized. The United
    States Environmental Protection Agency (USEPA, 1986) reported that when TSS was
    increased to 80 mg/L, the macroinvertebrate population decreased by 60%. The maximum
    TSS reaching 81 mg/L at station 15343 can be a concern of the aquatic ecosystem.
    The Pearson''s correlation model was used to demonstrate correlations among the
    measurements. As shown in Fig. 4, Fig. 5, Fig. 6 through 7, some of the correlations
    were consistent, but some of them were different among stations. Alkalinity, chloride,
    hardness, conductivity, and pH were highly correlated, and they had negative correlations
    with flow rate as expected due to dilution. The flow rate had positive correlations
    with the E. coli concentration (with correlation coefficients of 0.538, 0.307,
    0.195, and 0.034), TSS (0.329, 0.090, 0.315, and 0.306), and turbidity (0.303,
    0.138, 0.784, and 0.272) and had negative correlations with Secchi depth (−0.225,
    −0.053, −0.284, and −0.078), which indicates that flooding could be one of the
    causes of the elevated bacteria and sediment loadings from the watershed. TSS
    and turbidity were highly correlated, with correlation coefficients of 0.286–0.756,
    and both of them increased with the E. coli concentration and decreased with Secchi
    depth. Therefore, the excess bacteria and sediment loadings occurred at the same
    time. In addition, ammonia-N had positive correlation coefficients with phosphorus
    (0.385–0.564) in the fresh water, which indicates that the excess nutrient loadings
    could be from cultivated crop lands and affected by agriculture activities in
    the watershed. Download : Download high-res image (642KB) Download : Download
    full-size image Fig. 4. Correlation among different field measurements at station
    10599. Download : Download high-res image (639KB) Download : Download full-size
    image Fig. 5. Correlation among different field measurements at station 15343.
    Download : Download high-res image (628KB) Download : Download full-size image
    Fig. 6. Correlation among different field measurements at station 10579. Download
    : Download high-res image (629KB) Download : Download full-size image Fig. 7.
    Correlation among different field measurements at station 20774. The runoff discharging
    at station 10599 of the Pine Island Bayou is mainly from cultivated crop, pasture,
    and residential areas. As shown in Fig. 4, E. coli, TSS, and turbidity had significant
    positive correlations with flow rate, which indicates that the excess bacteria
    and sediment were the main non-point sources to affect the water quality of the
    Pine Island Bayou. The value of DO at station 10599 showed strong positive correlations
    with pH (0.373) and flow rate (0.421), but nitrate-nitrite and phosphorus showed
    weak correlations with flow rate as −0.098 and 0.005, respectively. This implies
    that excess nutrients from fertilizers, herbicides, and insecticides may not directly
    relate to excess runoff. The sub-basin runoff discharging at station 15343 of
    the Neches River is dominated in natural forest areas. As shown in Fig. 5, DO
    had high correlations with alkalinity (−0.389) and sulfate (0.181). Both E. coli
    and nitrate-nitrite showed positive correlations with flow rate. The relationship
    demonstrates that excess bacteria and nutrients from livestock in the forest were
    notable, but TSS and turbidity were not affected by the high flow rate as the
    national forest land acts as a buffer to clean up the sediment in the runoff.
    The sub-basin had mainly urban/suburban areas discharging runoff at station 10579
    of the Neches River. As shown in Fig. 6, DO was highly correlated to alkalinity,
    E. coli, TSS, and turbidity, and E. coli, nitrate-nitrite, TSS, and turbidity
    had positive correlations with flow rate. Therefore, the excess sediment, bacteria,
    and nutrients may be from upstream discharge, and runoff included the urban storm
    water, pet wastes, and possible leaking septic tank overflow. Station 20774 is
    located downstream the Saltwater Barrier. DO had high correlations with alkalinity
    (−0.603), chloride (−0.269), hardness (−0.551), nitrate-nitrite (−0.409), TSS
    (0.449), conductivity (−0.552), sulfate (−0.484), Secchi depth (−0.525), and turbidity
    (0.488). TSS and turbidity had positive correlations with flow rate, but the correlation
    between E. coli and flow rate was weaker than that of upstream stations. In summary,
    the amount of the excess sediment, nutrient, and bacteria brought by the runoff
    to the river was strongly dependent on land cover and land uses in the sub-watershed.
    Both excess sediment and bacteria were loaded with the runoff at the same time
    in the watershed. Therefore, the relationship between E. coli and turbidity was
    investigated at each site. The results demonstrate that it is reasonable to determine
    the turbidity limit using the limit of E. coli of river water. As shown in Fig.
    8, E. coli was over the limit (> 35 MPN per 100 mL) when turbidity was greater
    than 45 NTU for water samples collected during January to March at station 10579.
    As shown in Fig. 1, station 10579 was at the highline crossing 0.55 km downstream
    the Pine Island Bayou confluence and 0.71 km upstream the YSI sensor installation
    location in the Neches River. Therefore, it is applicable that the real-time turbidity
    recorded with the YSI sensor can be used to monitor and evaluate possible excess
    bacteria loadings. Download : Download high-res image (109KB) Download : Download
    full-size image Fig. 8. Determining critical turbidity with high E. coli at station
    10579. 3.2. Data analysis results for sensor data The preprocessed 15-min interval
    data were resembled to be hourly interval data. The statistical analysis for the
    total data of 9 554 records in 2016–2017 and 11 858 records in 2020–2021 are summarized
    in Table 1, Table 2, which include the mean, standard deviation, minimum, maximum,
    and 25%, 50%, and 75% quantiles. Although the two datasets were very close to
    each other, slight increases in the average temperature, maximum turbidity, fluorescence,
    and chlorophyll were found after Hurricane Harvey. Turbidity values greater than
    45 NTU were observed in both datasets. Undesirable chlorophyll concentrations
    (> 7 μg/L) were observed before Hurricane Harvey, but both undesirable and problematic
    chlorophyll concentrations (> 15 μg/L) appeared only after Hurricane Harvey. Table
    1. Statistical analysis for hourly water quality data from March 3, 2016 to April
    5, 2017. Statistics Turbidity (NTU) Fluorescence (%FS) Chlorophyll (μg/L) Conductivity
    (μS/cm) TDS (mg/L) Temperature (°C) Gage height above MSL (m) Mean 35.34 1.58
    6.33 120.35 82.91 22.61 0.86 Standard deviation 7.80 0.63 2.52 35.48 22.71 5.52
    0.57 Minimum 19.40 0.55 2.21 34.31 39.00 10.04 −0.06 25% quantile 30.64 1.18 4.73
    100.20 69.72 18.33 0.51 50% quantile 34.89 1.45 5.79 123.93 84.18 22.23 0.75 75%
    quantile 38.93 1.80 7.21 142.62 95.78 27.81 0.97 Maximum 64.01 3.76 14.96 208.66
    169.59 33.45 3.23 Table 2. Statistical analysis for hourly water quality data
    from June 5, 2020 to October 12, 2021. Statistics DO (mg/L) Turbidity (NTU) Fluorescence
    (%FS) Chlorophyll (μg/L) Conductivity (μS/cm) TDS (mg/L) Temperature (°C) Gage
    height above MSL (m) Mean 6.88 29.78 1.58 6.31 116.12 77.89 23.27 0.75 Standard
    deviation 1.81 8.02 0.55 2.18 30.36 16.27 6.81 0.46 Minimum 3.36 8.64 0.00 1.79
    33.97 39.04 4.92 −0.15 25% quantile 5.67 23.27 1.17 4.67 99.35 68.32 18.85 0.48
    50% quantile 6.51 28.57 1.45 5.81 118.21 80.87 24.70 0.65 75% quantile 8.31 34.67
    1.91 7.66 142.44 87.87 29.32 0.89 Maximum 11.50 66.04 4.05 16.21 181.10 118.26
    33.46 3.26 The preprocessed sensor data were also selected to conduct correlation
    analysis using the Pearson correlation. However, no strong correlation was detected.
    The hourly time series water quality data in Fig. 9 show that DO decreased when
    the discharge increased, and low TDS and conductivity were observed during high
    discharge periods due to dilution. High turbidities (over the limit of 45 NTU)
    during the low flow period (December to March) were consistent with the observation
    made with the field water sampling measurements. The output of the chlorophyll
    sensor was automatically processed via the sonde software to provide readings
    in either generic fluorescence units (percent full scale, %FS) or micrograms per
    liter (μg/L) of chlorophyll. The calibration of the sensor showed that 1.75%FS
    of fluorescence was equivalent to 7 μg/L of chlorophyll. High chlorophyll concentrations
    (> 7 μg/L) were observed during high discharge periods of March to July 2016,
    March to April 2017, and April to June 2021. Download : Download high-res image
    (1MB) Download : Download full-size image Fig. 9. Hourly water quality time-series
    data from March 3, 2016 to April 5, 2017 and from June 5, 2020 to October 12,
    2021. The rainfall sensor site at 4100 Plant Road (Fig. 1) from the drainage district
    6 (DD6; https://dd6.onerain.com) is located in the sub-watershed above the Saltwater
    Barrier. The historical hourly rainfall data (rainfall intensity in mm/h) and
    discharge at the USGS 08041780 gage station were collected and plotted in Fig.
    10, Fig. 11 to show the hydrological and hydraulic conditions. There were more
    rainfalls in the spring and summer than in the fall and winter in the area studied.
    The peak discharge over 2 000 m3/s was caused by the heavy rainfall events of
    the whole watershed in early March 2016, late May to early June 2016, and late
    May to early June 2021. Some of the heavy rainfalls in the sub-watershed did not
    cause an extreme increase in discharge, e.g., August 2016 and December 2020. Therefore,
    both the rainfall and USGS gage data were critical to water quality monitoring.
    Download : Download high-res image (237KB) Download : Download full-size image
    Fig. 10. Rainfall intensity in sub-watershed and river discharge from March 3,
    2016 to April 4, 2017. Download : Download high-res image (252KB) Download : Download
    full-size image Fig. 11. Rainfall intensity in sub-watershed and river discharge
    from June 5, 2020 to October 12, 2021. The turbidity and chlorophyll under high
    discharge conditions (> 400 m3/s) were plotted in Fig. 12. Turbidity and chlorophyll
    increased with the discharge at the rising limb, but decreased with the increasing
    flow due to dilution during March 8 to 22, 2016. Chlorophyll did not vary significantly
    during May 28 to June 14, 2016, although this trend was still observed for turbidity
    but much weaker correlated than the previous event. As shown in Fig. 10, frequent
    rainfall events after the early March event increased the peak discharge higher
    than the previous event. However, a smaller rainfall intensity has less capacity
    to flush the non-point sources, and the sediment/bacteria and algae in the sub-watershed
    may not have enough time to accumulate after the first flush. As shown in Fig.
    11, the discharge increased slowly during small intensity rain events and increased
    fast following high intensity rain events late in May 2021. Turbidity increased
    significantly on April 25, 2021 and decreased during April 26 to June 13, 2021,
    while chlorophyll decreased with the increasing discharge. These correlations
    imply that heavy rainfall after a long-time dry season can elevate sediment/bacteria/algae
    dramatically to cause water quality problems, but it may not be the case in the
    late summer after more frequent rain events. Download : Download high-res image
    (659KB) Download : Download full-size image Fig. 12. Variation of turbidity and
    chlorophyll with discharge after heavy rain events. Correlations between turbidity
    and chlorophyll under moderate discharge conditions (200–400 m3/s) were plotted
    in Fig. 13 when elevated turbidities were observed (December 3 to 11, 2016; January
    18 to February 3, 2017; December 13 to 19, 2020; January 1 to 18, 2021; and February
    17 to 25, 2021). The highest rainfall intensities during these periods in Fig.
    10, Fig. 11 were between 19.05 and 44.45 mm/h. Turbidity increased to over 45
    NTU as the discharge began to ramp up, but started to decline at some point way
    before the peak discharge arrived. Chlorophyll did not witness the similar trend.
    Undesirable chlorophyll was only observed on January 13, 2020. These correlations
    imply that the small rain events with higher rainfall intensities during the winter
    season elevated sediment/bacteria to cause water quality problems but did not
    elevate algae loadings. Download : Download high-res image (1MB) Download : Download
    full-size image Fig. 13. Variation of turbidity and chlorophyll with discharge
    after small rain events. The relationships between turbidity and chlorophyll under
    low flow conditions (< 200 m3/s) were plotted in Fig. 14. It reveals very weak
    negative correlations, but no obvious elevated turbidity and chlorophyll are noted.
    It is clear that hydrological and hydraulic conditions play a very important role
    in water quality as the non-point sources of sediment and bacteria in the watershed
    can be transported by excess rainfall. Download : Download high-res image (667KB)
    Download : Download full-size image Fig. 14. Turbidity versus chlorophyll under
    dry conditions. In summary, the YSI sensor system was used to monitor the real-time
    turbidity, fluorescence, and chlorophyll, which could trigger alerts on potential
    water quality issues. At the same time, recorded rainfall depths and rainfall
    intensities in the sub-watershed and discharges at USGS gages were considered
    along with YSI sensor data to better understand the cause of the water quality
    issue because elevated bacteria and sediment were mainly caused by rain events
    either during the dry season (winter) or first flush during the wet season (spring).
    Both field monitoring data and real-time measurements indicated that elevated
    bacteria/sediment and excess algae can be caused by non-point sources from livestock,
    pet wastes, and faulty septic systems due to high-intensity rain events. The ongoing
    TMDL and I-plan study (TCEQ, 2021) is necessary to control non-point sources in
    the watershed. In addition, USEPA (https://www.epa.gov/nps/non-point-source-pollution-technical-guidance-and-tools)
    has developed non-point source technical guidance and tools to provide national
    management measures for agriculture, urban areas, forestry, hydromodification,
    etc. These best management practices need to be considered by the local governments
    to improve the ecosystem of the Lower Neches River. 4. Summary and conclusions
    The study applied the statistical and Pearson correlation model to the historical
    field water sampling measurements at four stations in the study area. The correction
    demonstrated that alkalinity, chloride, hardness, conductivity, and pH were highly
    related, and they decreased with the increasing flow rate due to dilution. Flow
    rate has positive correlations with E. coli, TSS, and turbidity and showed negative
    correlations with Secchi depth, which demonstrated that excess rainfall was one
    of the causes of elevated bacteria/sediment loadings in the watershed. The correlation
    between E. coli and turbidity determines that turbidity greater than 45 NTU in
    the Neches River can serve as a proxy for E. coli to indicate the bacterial outbreak.
    To better monitor and evaluate the water quality under different hydrological
    and hydraulic conditions, an array of YSI sensors was installed at the Saltwater
    Barrier to measure 15-min interval water temperature, water depth, DO, pH, turbidity,
    conductivity/TDS, and fluorescence/chlorophyll/blue-green algae. The data were
    preprocessed with a series of newly developed statistical tools and an innovative
    two-layer data smoothing filter to detect outliers, fill missing values, and filter
    spikes of the real-time sensor measurements. Data analysis was conducted to define
    an alternative indicator for elevated bacteria/algae loadings using parameter
    limits for turbidity (> 45 NTU), fluorescence (> 1.75%FS), and chlorophyll (>
    7 μg/L). The correlations between turbidity and chlorophyll under different discharge
    levels were investigated to illustrate the role of heavy rain events on the deteriorated
    water quality characterized by elevated sediment, bacteria, and algae. It is clear
    that the impact of non-point source pollution on the water quality was dependent
    on hydrological and hydraulic conditions. In conclusion, monitoring and evaluation
    of water quality with YSI sensors along with rainfall and discharge data to secure
    safe drinking water resources were recommended. The best management practices
    need to be considered to control non-point sources of sediment and bacteria in
    the watershed. Declaration of competing interest The authors declare no conflicts
    of interest. References APHA, 1998 APHA Standard Methods for the Examination of
    Water and Wastewater (20th Edition), APHA-AWWA-WEF, Washington, D.C (1998) Google
    Scholar Cavicchioli et al., 2019 R. Cavicchioli, W.J. Ripple, K.N. Timmis, F.
    Azam, L.R. Bakken, M. Baylis, M.J. Behrenfeld, A. Boetius, P.W. Boyd, A.T. Classen,
    et al. Scientists'' warning to humanity: Microorganisms and climate change Nat.
    Rev. Microbiol., 17 (2019), pp. 569-586, 10.1038/s41579-019-0222-5 View in ScopusGoogle
    Scholar Cho et al., 2022 K.H. Cho, J. Wolny, J.A. Kase, T. Unno, Y. Pachepsky
    Interactions of E. coli with algae and aquatic vegetation in natural waters Water
    Res., 209 (2022), Article 117952, 10.1016/j.watres.2021.117952 View PDFView articleView
    in ScopusGoogle Scholar Curtis et al., 1994 T.P. Curtis, D.D. Mara, N.G.H. Dixo,
    S.A. Silva Light penetration in waste stabilization ponds Water Res., 28 (1994),
    pp. 1031-1038, 10.1016/0043-1354(94)90188-0 View PDFView articleView in ScopusGoogle
    Scholar Kroer, 1993 N. Kroer Bacterial growth efficiency on natural dissolved
    organic matter Limnol. Oceanogr., 38 (6) (1993), pp. 1282-1290, 10.4319/lo.1993.38.6.1282
    View in ScopusGoogle Scholar Maes et al., 2022 S. Maes, M. Odlare, A. Jonsson
    Fecal indicator organisms in northern oligotrophic rivers: An explorative study
    on Escherichia coli prevalence in a mountain region with intense tourism and reindeer
    herding Environ. Monit. Assess., 194 (2022), p. 264, 10.1007/s10661-022-09865-1
    View in ScopusGoogle Scholar Martin et al., 2017 R.M. Martin, S.P. Dearth, G.R.
    LeCleir, S.R. Campagna, E.M. Fozo, E.R. Zinser, S.W. Wilhelm Microcystin-LR does
    not induce alterations to transcriptomic or metabolomic profiles of a model heterotrophic
    bacterium PLoS One, 12 (2) (2017), Article e0189608, 10.1371/journal.pone.0189608
    View in ScopusGoogle Scholar Muñoz and Guieysse, 2006 R. Muñoz, B. Guieysse Algal–bacterial
    processes for the treatment of hazardous contaminants: A review Water Res., 40
    (2006), pp. 2799-2815, 10.1016/j.watres.2006.06.011 View PDFView articleView in
    ScopusGoogle Scholar New Hampshire Department of Environmental Services, 2009
    New Hampshire Department of Environmental Services (NHDES) Assessment of Chlorophyll-A
    and Phosphorus in New Hampshire Lakes for Nutrient Criteria Development NHDES,
    Concord (2009) https://www.des.nh.gov/sites/g/files/ehbemt341/files/documents/2020-01/r-wd-09-29.pdf
    Google Scholar Novotny, 1999 V. Novotny Diffuse pollution from agriculture–A worldwide
    outlook Water Sci. Technol., 39 (3) (1999), pp. 1-13, 10.2166/wst.1999.0124 View
    PDFView articleGoogle Scholar Pandia et al., 2010 K. Pandia, S. Ravindran, R.
    Cole, G. Kovacs, L. Giovangrandi Motion artifact cancellation to obtain heart
    sounds from a single chest-worn accelerometer Proceedings of the 2010 IEEE International
    Conference on Acoustics, Speech and Signal Processing, IEEE, Dallas (2010), pp.
    590-593, 10.1109/ICASSP.2010.5495553 View in ScopusGoogle Scholar Qian et al.,
    2019 Q. Qian, B. Sun, X. Li, F. Sun, C.-J. Lin, L. Jiang Water quality evaluation
    on an urban stormwater retention pond using wireless sensor networks and hydrodynamic
    modeling J. Irrigat. Drain. Eng., 145 (12) (2019), Article 05019011, 10.1061/(ASCE)IR.1943-4774.0001434
    Google Scholar Qian et al., 2022 Q. Qian, F. Sun, B. Sun, J. Zhang, Y. Zhang Forecasting
    water quality using AI with monitoring data collected by wireless sensors Proceedings
    of the World Environmental and Water Resources Congress 2022, ASCE, Henderson
    (2022), pp. 37-49, 10.1061/9780784484258.004 View in ScopusGoogle Scholar Quero
    et al., 2015 G.M. Quero, L. Fasolato, C. Vignaroli, G.M. Luna Understanding the
    association of Escherichia coli with diverse macroalgae in the lagoon of Venice
    Sci. Rep., 5 (2015), Article 10969, 10.1038/srep10969 View in ScopusGoogle Scholar
    Ramanan et al., 2016 R. Ramanan, B.-H. Kim, D.-H. Cho, H.-M. Oh, H.-S. Kim Algae–bacteria
    interactions: Evolution, ecology and emerging applications Biotechnol. Adv., 34
    (1) (2016), pp. 14-29, 10.1016/j.biotechadv.2015.12.003 View PDFView articleView
    in ScopusGoogle Scholar Savitzky and Golay, 1964 A. Savitzky, M.J.E. Golay Smoothing
    and differentiation of data by simplified least squares rrocedures Anal. Chem.,
    36 (8) (1964), pp. 1627-1639, 10.1021/ac60214a047 View in ScopusGoogle Scholar
    Schulz, 2007 K. Schulz Phytoplankton measuring and culture techniques Phytoplankton
    Ecology (Lecture), State University of New York, Syracuse (2007) http://www.esf.edu/efb/schulz/phytotechniques.doc
    Google Scholar Seo, 2006 S. Seo Review and comparison of methods for detecting
    outliers in univariate data sets. Master Thesis. University of Pittsburgh, Pittsburgh
    http://d-scholarship.pitt.edu/7948/ (2006) Google Scholar Slaff and Drane-Maury,
    2019 J. Slaff, M. Drane-Maury NOAA Forecasts Very Large ‘Dead Zone’ for Gulf of
    Mexico National Oceanic and Atmospheric Administration, Washington, D.C (2019)
    https://www.noaa.gov/media-release/noaa-forecasts-very-large-dead-zone-for-gulf-of-mexico
    Google Scholar Speer, 1997 B.R. Speer Photosynthetic pigments UCMP Glossary (Online),
    University of California, Berkeley Museum of Paleontology, Berkeley (1997) https://ucmp.berkeley.edu/glossary/gloss3/pigments.html
    Google Scholar Texas Commission on Environmental Quality, 2021 Texas Commission
    on Environmental Quality (TCEQ) 2020 Texas Integrated Report - Assessment Results
    for Basin 6 - Neches River Basin TCEQ, Austin (2021) https://www.tceq.texas.gov/assets/public/waterquality/swqm/assess/20txir/2020_Basin6.pdf
    Google Scholar Thomas and Burgess, 2007 O. Thomas, C. Burgess UV-visible Spectrophotometry
    of Water and Wastewater, Techniques and Instrumentation in Analytical Chemistry
    Elsevier, Amsterdam, Boston (2007) Google Scholar USEPA, 1986 USEPA Quality Criteria
    for Water 1986, EPA440/5-86-001 Office of Water Regulations and Standards, USEPA,
    Washington, D.C (1986) https://www.epa.gov/sites/default/files/2018-10/documents/quality-criteria-water-1986.pdf
    Google Scholar Vanden Heuvel et al., 2010 A. Vanden Heuvel, C. McDermott, R. Pillsbury,
    T. Sandrin, J. Kinzelman, J. Ferguson, M. Sadowsky, M. Byappanahalli, R. Whitman,
    G.T. Kleinheinz The green alga, Cladophora, promotes Escherichia coli growth and
    contamination of recreational waters in Lake Michigan J. Environ. Qual., 39 (1)
    (2010), pp. 333-344, 10.2134/jeq2009.0152 Google Scholar Waskom, 2021 M. Waskom
    Seaborn: Statistical data visualization J. Open Source Softw., 6 (2021), p. 3021,
    10.21105/joss.03021 Google Scholar YSI, 2006 YSI YSI 6131 and 6132 Blue-green
    algae sensors: Phycocyanin and phycoerythrin sensors YSI Sensor Brochure. YSI,
    Yellow Springs (2006) https://www.fondriest.com/pdf/ysi_6131_6132_spec.pdf Google
    Scholar Cited by (0) This work was supported by Center for Resiliency (CfR) at
    Lamar University (Grant No. 22PSS01). Peer review under responsibility of Hohai
    University. © 2023 Hohai University. Production and hosting by Elsevier B.V. Recommended
    articles Impact of geometric features of impermeable discrete bedform on hyporheic
    exchange Water Science and Engineering, 2024 Xue-yong Wang, Jing-yu Fan View PDF
    An efficient approach for mesoscale fracture modeling of fully-graded hydraulic
    concrete Water Science and Engineering, Volume 15, Issue 4, 2022, pp. 337-347
    Lei Xu, …, Qing-wen Ren View PDF Experiments on two-phase flow in hydraulic jump
    on pebbled rough bed: Part 1–Turbulence properties and particle chord time and
    length Water Science and Engineering, Volume 16, Issue 4, 2023, pp. 359-368 Farhad
    Bahmanpouri, …, Hubert Chanson View PDF Show 3 more articles Article Metrics Captures
    Readers: 4 Mentions News Mentions: 1 View details About ScienceDirect Remote access
    Shopping cart Advertise Contact and support Terms and conditions Privacy policy
    Cookies are used by this site. Cookie settings | Your Privacy Choices All content
    on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors.
    All rights are reserved, including those for text and data mining, AI training,
    and similar technologies. For all open access content, the Creative Commons licensing
    terms apply."'
  inline_citation: '>'
  journal: Water Science and Engineering
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Monitoring and evaluation of the water quality of the Lower Neches River,
    Texas, USA
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Tortorici O.
  - Péraud C.
  - Anthierens C.
  - Hugel V.
  citation_count: '0'
  description: Underwater remotely operated vehicles (ROVs) are linked to the surface
    through a tether that is usually controlled by a human operator. The length of
    the tether being deployed in the water in real time is a critical determinant
    of the success of the mission, and the problems of entanglement and cable stretching
    must be anticipated to the greatest possible extent. This paper describes a low-cost
    and setup-friendly solution for managing the length of a neutrally buoyant tether
    using a balanced buoy–ballast system implemented on the part of the tether proximal
    to the ROV. Embedded in the system is a curvature sensor that helps to control
    the cable feeder on the surface. This represents a useful solution for smoothing
    tether movements and to damp external disturbances. The results of experiments
    carried out in water tanks demonstrate the benefits of this solution in allowing
    the cable to maintain a semi-stretched shape while ensuring that the ROV avoids
    being pulled by the cable. Possible applications for a surface vehicle linked
    to an ROV through a tether equipped with this compliant buoy–ballast system include
    exploration or cartography missions in shallow waters.
  doi: 10.3390/jmse12020279
  full_citation: '>'
  full_text: '>

    "This website uses cookies We use cookies to personalise content and ads, to provide
    social media features and to analyse our traffic. We also share information about
    your use of our site with our social media, advertising and analytics partners
    who may combine it with other information that you’ve provided to them or that
    they’ve collected from your use of their services. Consent Selection Necessary
    Preferences Statistics Marketing Show details                 Deny Allow selection
    Allow all    Journals Topics Information Author Services Initiatives About Sign
    In / Sign Up Submit   Search for Articles: Journal of Marine Science and Engineering
    (JMSE) All Article Types Advanced   Journals JMSE Volume 12 Issue 2 10.3390/jmse12020279
    Submit to this Journal Review for this Journal Propose a Special Issue Article
    Menu Academic Editor Cristiano Fragassa Subscribe SciFeed Recommended Articles
    Related Info Link More by Authors Links Article Views 788 Table of Contents Abstract
    Introduction Modeling of The Compliant Buoy–Ballast Sensing System Simulations
    Description of Setup, Control Mode, and ROV Trajectories for Real Experiments
    Results And Discussion Conclusions Author Contributions Funding Informed Consent
    Statement Data Availability Statement Acknowledgments Conflicts of Interest Appendix
    A. Statics Analysis of the Buoy–Ballast System References share Share announcement
    Help format_quote Cite question_answer Discuss in SciProfiles thumb_up Endorse
    textsms Comment first_page settings Order Article Reprints Open AccessArticle
    Automated Deployment of an Underwater Tether Equipped with a Compliant Buoy–Ballast
    System for Remotely Operated Vehicle Intervention by Ornella Tortorici 1, Charly
    Péraud 2, Cédric Anthierens 2 and Vincent Hugel 2,* 1 Institute for Mechatronics
    in Mechanics, 21073 Hamburg, Germany 2 COSMER, Université de Toulon, 83041 Toulon,
    France * Author to whom correspondence should be addressed. J. Mar. Sci. Eng.
    2024, 12(2), 279; https://doi.org/10.3390/jmse12020279 Submission received: 10
    January 2024 / Revised: 31 January 2024 / Accepted: 1 February 2024 / Published:
    3 February 2024 (This article belongs to the Special Issue Advances in Underwater
    Robots for Intervention) Download keyboard_arrow_down     Browse Figures Versions
    Notes Abstract Underwater remotely operated vehicles (ROVs) are linked to the
    surface through a tether that is usually controlled by a human operator. The length
    of the tether being deployed in the water in real time is a critical determinant
    of the success of the mission, and the problems of entanglement and cable stretching
    must be anticipated to the greatest possible extent. This paper describes a low-cost
    and setup-friendly solution for managing the length of a neutrally buoyant tether
    using a balanced buoy–ballast system implemented on the part of the tether proximal
    to the ROV. Embedded in the system is a curvature sensor that helps to control
    the cable feeder on the surface. This represents a useful solution for smoothing
    tether movements and to damp external disturbances. The results of experiments
    carried out in water tanks demonstrate the benefits of this solution in allowing
    the cable to maintain a semi-stretched shape while ensuring that the ROV avoids
    being pulled by the cable. Possible applications for a surface vehicle linked
    to an ROV through a tether equipped with this compliant buoy–ballast system include
    exploration or cartography missions in shallow waters. Keywords: underwater robotics;
    tethered robot; buoy–ballast system; length control 1. Introduction Most underwater
    exploration and inspection tasks are achieved by remotely operated vehicles (ROVs),
    whose maneuverability and reliability are at the heart of a mission’s success
    [1,2]. Maintenance missions include the inspection of ship hulls, pontoons, offshore
    wind farms, oil platforms, risers, and seabed pipelines as well as all artificial
    sensing structures integrated in the oceans for monitoring the seas or conducting
    physics experiments, such as the neutrino telescope in the Mediterranean Sea [3].
    ROVs are linked to a surface control vessel by a tether that can transmit data
    and even supply power if necessary [4,5]. However, the tether is likely to apply
    undesirable forces on the ROV through its attachment point [6,7], which can affect
    the ROV’s mobility and its planned trajectory while increasing power consumption
    [8,9,10,11]. Tether constraints are even more important for small and less powerful
    ROVs, which are also widely used in shallow waters. A slack, passive tether increases
    the risk of entanglement and seabed drag, resulting in premature wear [12,13,14].
    To take advantage of the cables linked to underwater robots, a control system
    for varying cable length is required. One of the main challenges in underwater
    robotics is to provide robots with more navigation autonomy and maneuverability,
    whereas tether deployment remains under the control of a skilled human operator.
    In the literature, there exist three main solutions for the management of subsea
    tethers, namely involving tether customization/instrumentation, use of surface
    winches, or use of an underwater tether management system (TMS), which can be
    implemented by an auxiliary robot. Tethers are often customized by buoys and ballasts
    to change their buoyancy, shape, or behavior [7,15,16]. Such systems are passive,
    and their positive impact on cable management is limited when they are not used
    in conjunction with active length control. Cables can also be fitted with external
    or internal sensors to monitor their behavior and shape, e.g., taking measurements
    at several specific nodes along the cable through inertial or tension sensors
    [7,17] or continuously along the entire cable through embedded fiber optic solutions
    [18,19,20]. The first solution generates an irregular shape, whereas the second
    can be very expensive. Surface winches are used for cable winding and unwinding
    and are often operated either manually or simply based on cable tension [21,22].
    They are commonly placed on the surface vessel, but they can also be embedded
    on the ROV itself, which involves technological challenges [15]. tether management
    systems (TMSs) are widely used for deep water systems [1,23,24,25]. Located between
    the surface and the ROV, they manage the portion of the cable connected to the
    ROV. They are usually combined with a depressor weight to limit the transmission
    of heave motion from the surface vessel to the ROV via the tether. An auxiliary
    ROV can also play the role of a TMS [2]. It can be remotely controlled by an operator
    or automatically manage the shape of passive weighing cables [26]. However, this
    solution introduces the potential risk of collision between the robots. This paper
    presents a mechatronic solution for automating the deployment of a tether that
    links a remotely operated vehicle to the surface while limiting unwanted disturbances
    to the ROV. This solution is designed to be installed easily on an existing neutrally
    buoyant and lightweight cable. It is a low-cost solution that consists of combining
    two buoys and a ballast located between the buoys, and a flex sensor is mounted
    at the ballast. The buoy–ballast system is also built to be neutrally buoyant
    and behave as a compliant system in preventing the ROV from being pulled by the
    cable and enabling active cable management using the flex sensor. Unlike most
    existing solutions designed for weighing cables, the system presented in this
    article is original and suitable for neutrally buoyant cables, which do not carry
    energy. Alternative solutions for lightweight neutral cables include the use of
    a force sensor at the end of the winding/unwinding unit. However, these solutions
    are expensive, and the instrumented winch system must be carefully designed. In
    addition, the longer the cable, the more difficult it will be for these solutions
    to acquire information about the cable tension state on the ROV side. The contributions
    of this work include the following: The modeling, design, and implementation of
    the compliant-actuated system to equip the tether, which is composed of two symmetric
    buoys, one ballast, and one flex sensor located at the ballast; Tether length
    control by the feeder system on the surface, used to maintain the tether in a
    semi-stretched shape according to flex sensor feedback from the ROV; Simulations
    and real experiments to validate the solution by employing a compact underwater
    vehicle and a neutrally buoyant tether. The paper is organized as follows. Section
    2 focuses on the modeling of the buoy–ballast sensing system. Section 3 describes
    the simulations that were conducted to test the system. Section 4 details the
    system setup, sensor layout, control scheme, and experimental trajectories carried
    out in water pools. Section 5 is dedicated to the discussion of the results. 2.
    Modeling of The Compliant Buoy–Ballast Sensing System 2.1. Neutral Buoyancy of
    The Buoy–Ballast System Given a neutrally buoyant tether, the static equilibrium
    of the buoy–ballast system, namely the V-system, depends on the apparent weights
    of the buoys and the ballast. The ballast is placed between the two identical
    buoys on the cable (Figure 1). In order to ensure a neutral balance, the apparent
    weight of the ballast must be compensated by the apparent weights of the buoys:
    𝑊 𝑏𝑢𝑜𝑦 = | 𝜌 𝑏𝑢𝑜𝑦 − 𝜌 𝑤 |. 𝑉 𝑏𝑢𝑜𝑦 .𝑔=( 𝜌 𝑤 − 𝜌 𝑏𝑢𝑜𝑦 ). 𝑉 𝑏𝑢𝑜𝑦 .𝑔 (1) 𝑊 𝑏𝑎𝑙𝑙𝑎𝑠𝑡
    = ( 𝜌 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 − 𝜌 𝑤 ). 𝑉 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 .𝑔=2. 𝑊 𝑏𝑢𝑜𝑦 (2) where 𝑊 𝑏𝑢𝑜𝑦 and 𝑊 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 stand
    for the gravity forces minus the buoyancy of the buoy and ballast, respectively.
    𝜌 𝑏𝑢𝑜𝑦 , 𝜌 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 , and 𝜌 𝑤 are the density of the buoy, ballast, and water,
    respectively. 𝑉 𝑏𝑢𝑜𝑦 and 𝑉 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 designate the volumes of the buoy and the ballast,
    respectively. g is the gravity constant. Figure 1. The compliant buoy–ballast
    system mounted on a neutrally buoyant cable. The ballast is chosen from among
    off-the-shelf spherical weights, and the volume of the buoy is adjusted by machining
    it into a cuboid shape with rounded edges, since it is made of foam (LAST-A-FOAM®
    R-3318), taking into account the following equation obtained from the above equations:
    𝑉 𝑏𝑢𝑜𝑦 = 1 2 . 𝜌 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 − 𝜌 𝑤 𝜌 𝑤 − 𝜌 𝑏𝑢𝑜𝑦 . 𝑉 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 (3) 2.2. Drag Forces In
    steady state, the velocities of the buoys and ballast are considered constant,
    and a static analysis is conducted to estimate the relationship of the distance
    between the buoys as a function of the drive speed. The forces exerted by the
    fluid on the buoys and the ballast depend on the type of flow, which can be laminar,
    turbulent, or in a transitional state between both. Usually, the moving object’s
    related Reynolds number is used to identify the type of water flow around the
    object, regardless of whether it creates turbulence: 𝑅𝑒 = 𝜌 𝑤 .𝑣.𝐿 𝜇 (4) where
    v is the relative speed between the object and the fluid, 𝜇 is the water viscosity,
    which is approx. 10 −3 kg/m/s at 20 °C, and L is the characteristic length of
    the object, perpendicular to the direction of motion, such as for the diameter
    of a sphere. For a Reynolds number below 10, the flow can be considered as laminar,
    which is the case for very small objects. Above 10 6 , the flow is turbulent at
    the surface and behind the object. Between 10 and 10 6 , the flow can be either
    laminar or turbulent, or in a transitional state. The order of magnitude of a
    4 cm long compact buoy or ballast, moving at the average speed of 0.5 m/s is 𝑅𝑒
    = 10 3 0.54. 10 −2 10 −3 ≈2. 10 4 (5) When the water flow is laminar, the drag
    force 𝐹 𝑙𝑎𝑚 𝑑 is proportional to the velocity, where the drag force in turbulent
    flow is quadratic, namely 𝐹 𝑡𝑢𝑟𝑏 𝑑 . The formulae for these two forces are given
    below. 𝐹 𝑙𝑎𝑚 𝑑 = 𝑘.𝜇.𝑣 (6) 𝐹 𝑡𝑢𝑟𝑏 𝑑 = 1 2 . 𝐶 𝐷 .𝐴. 𝜌 𝑤 . 𝑣 2 (7) where k is a
    coefficient that depends on the shape of the object. For a sphere of radius R,
    𝑘=6𝜋.𝑅 . 𝐶 𝐷 is the dimensionless quadratic drag coefficient, which is a property
    of the object. For a spherical shape, 𝐶 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 𝐷 ≈0.47 , and for a cuboid shape,
    𝐶 𝑏𝑢𝑜𝑦 𝐷 ≈1.05 . A is the cross-sectional area of the object, perpendicularly
    to the motion, which can be approximated by 𝜋. 𝑅 2 /2 , with 𝑅=𝐿/2 . 2.3. Distance
    Versus Speed in Steady-State Mode Figure 2 presents the scheme of the buoy–ballast
    V-shape model, showing the forces exerted on the buoys and ballast. It is assumed
    that the entire system moves at a constant velocity v driven by the ROV in the
    left–right direction. Figure 2. Model of the buoy–ballast V-system. The buoys
    and ballast move at the same constant speed. The total number of independent equations
    that govern the force compensation of the elements of the V-shape system at constant
    speed is 7 (detailed in Appendix A), which are 𝑇 𝑥 𝐵1 = 𝐹 𝑏𝑢𝑜𝑦 𝑑 + 𝑇 1 (8) 𝑇 𝑦
    𝐵1 =− 𝑊 𝑏𝑢𝑜𝑦 (9) 𝑇 𝑥 𝐵2 =− 𝐹 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 𝑑 − 𝐹 𝐶 𝐵 1 𝑑 − 𝐹 𝐶 𝐵 2 𝑑 − 𝐹 𝑏𝑢𝑜𝑦 𝑑 𝑇 1
    (10) 𝑇 𝑦 𝐵2 =− 𝑊 𝑏𝑢𝑜𝑦 (11) 𝑇 2 =2. 𝐹 𝑏𝑢𝑜𝑦 𝑑 + 𝐹 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 𝑑 (12) ( 𝐹 𝑏𝑢𝑜𝑦 𝑑 + 𝑇
    1 + 1 2 . 𝐹 𝐶 𝐵 1 𝑑 ).ℓ.cos 𝜃 1 − 𝑊 𝑏𝑢𝑜𝑦 .ℓ.sin 𝜃 1 =− 𝐶 𝑠 [2( 𝜋 2 − 𝜃 1 )+( 𝜋
    2 + 𝜃 2 )] −( 𝐹 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 𝑑 + 𝐹 𝑏𝑢𝑜𝑦 𝑑 + 𝑇 1 + 𝐹 𝐶 𝐵 1 𝑑 + 1 2 . 𝐹 𝐶 𝐵 2 𝑑 ).ℓ.cos
    𝜃 2 − 𝑊 𝑏𝑢𝑜𝑦 .ℓ.sin 𝜃 2 (13) = 𝐶 𝑠 [2( 𝜋 2 + 𝜃 2 )+( 𝜋 2 − 𝜃 1 )] (14) where 𝑇
    𝑥 𝐵1 and 𝑇 𝑦 𝐵1 are the components of the force 𝐓 𝐁𝟏 that is exerted by the cable
    portion 𝐶 𝐵 1 of length ℓ onto the left buoy. 𝑇 𝑥 𝐵2 and 𝑇 𝑦 𝐵2 are the components
    of the force 𝐓 𝐁𝟐 that is exerted by the cable portion 𝐶 𝐵 1 of length ℓ onto
    the right buoy. 𝐹 𝑏𝑢𝑜𝑦 𝑑 is the intensity of the drag force exerted by the fluid
    on the buoy. 𝐹 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 𝑑 is the intensity of the drag force exerted by the fluid
    on the ballast. 𝐹 𝐶 𝐵 1 𝑑 and 𝐹 𝐶 𝐵 2 𝑑 are, respectively, the intensity of the
    drag force exerted by the fluid on the cable portion 𝐶 𝐵 1 and 𝐶 𝐵 2 . 𝐶 𝑠 is
    the bending stiffness coefficient of the cable. 𝜃 1 and 𝜃 2 are, resp., the vertical
    angle of the 𝐶 𝐵 1 cable portion and the 𝐶 𝐵 2 cable portion. 𝑇 1 is the magnitude
    of the horizontal scalar force exerted by the cable that links the left buoy to
    the remote station. 𝑇 2 is the horizontal scalar force exerted by the cable that
    links the right buoy to the ROV. In the case of the figure, the intensity 𝑇 2
    is positive since the ROV pulls on the cable to move from left to right. The drag
    force magnitudes 𝐹 𝐶 𝐵 1 𝑑 and 𝐹 𝐶 𝐵 2 𝑑 are calculated as follows, based on the
    diameter 𝑑 𝑐 of the cable 𝐹 𝐶 𝐵 1 𝑑 𝐹 𝐶 𝐵 2 𝑑 = = 1 2 . 𝐶 𝑐𝑎𝑏𝑙𝑒 𝐷 . 𝑑 𝑐 .ℓ.cos
    𝜃 1 . 𝜌 𝑤 . 𝑣 2 1 2 . 𝐶 𝑐𝑎𝑏𝑙𝑒 𝐷 . 𝑑 𝑐 .ℓ.cos 𝜃 2 . 𝜌 𝑤 . 𝑣 2 where 𝐶 𝑐𝑎𝑏𝑙𝑒 𝐷 is
    dependent on the ratio of length to diameter. The forces exerted on the portion
    of cable from the station to 𝐵 1 are the drag force, namely 𝑇 𝑑 1 , and the resisting
    force exerted by the winch on the station side, namely 𝑇 1𝑐 , which depends on
    the design of the feeder rotary joint. Since the cable is neutrally buoyant, there
    is no horizontal tension caused by apparent gravity (which would exist in the
    case of a weighing cable that takes the shape of a catenary in resting mode).
    𝑇 1 = 𝑇 𝑑 1 + 𝑇 1𝑐 where 𝑇 1𝑐 is considered as a constant in the steady-state
    mode, whereas 𝑇 𝑑 1 can be expressed as 𝑇 𝑑 1 = 1 2 𝐶 𝑐𝑎𝑏𝑙𝑒 𝐷 . 𝑑 𝑐 .𝑑ℎ. 𝜌 𝑤 .
    𝑣 2 where 𝑑ℎ is the depth offset between 𝐵 1 and the other extremity of the cable
    on the station side. Equations (13) and (14) can be numerically solved for 𝜃 1
    and 𝜃 2 to obtain the evolution of the inter-buoy distance 𝑑=ℓ(sin 𝜃 1 −sin 𝜃
    2 ) as a function of the velocity v (see Section 3.3). After linearization using
    small angles, the horizontal distance d between the buoys can be calculated as
    𝑑 ≈ ℓ( 𝜃 1 − 𝜃 2 ) (15) ≈ ℓ. ℓ( 𝐹 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 𝑑 +2. 𝐹 𝑏𝑢𝑜𝑦 𝑑 +2. 𝑇 1 + 3 2 𝐹 𝐶 𝐵 1
    * 𝑑 + 1 2 𝐹 𝐶 𝐵 2 * 𝑑 )+3𝜋. 𝐶 𝑠 ℓ. 𝑊 𝑏𝑢𝑜𝑦 +3. 𝐶 𝑠 (16) with 𝐹 𝐶 𝐵 1 * 𝑑 = 1 2
    . 𝐶 𝑐𝑎𝑏𝑙𝑒 𝐷 . 𝑑 𝑐 .ℓ. 𝜌 𝑤 . 𝑣 2 and 𝐹 𝐶 𝐵 2 * 𝑑 = 1 2 . 𝐶 𝑐𝑎𝑏𝑙𝑒 𝐷 . 𝑑 𝑐 .ℓ. 𝜌
    𝑤 . 𝑣 2 . The distance between buoys in the rest position can be calculated by
    zeroing the drag forces: 𝑑 𝑟𝑒𝑠𝑡 ≈ ℓ. 2.ℓ. 𝑇 1𝑐 +3𝜋. 𝐶 𝑠 ℓ. 𝑊 𝑏𝑢𝑜𝑦 +3. 𝐶 𝑠 (17)
    Given the 𝐶 𝑠 value of cable stiffness and the estimation of 𝑇 1𝑐 , ℓ and 𝑉 𝑏𝑢𝑜𝑦
    can then be adjusted to obtain the desired distance between buoys in the rest
    position. 2.4. Dynamics Analysis through Differential Equations Taking into account
    small angles, i.e., tan 𝜃 𝑖 ≈sin 𝜃 𝑖 ≈ 𝜃 𝑖 , the dynamics equations of motion
    of the buoys in the left–right horizontal direction are 𝑚 𝑏𝑢𝑜𝑦 𝑑 𝑣 𝐵1 𝑑𝑡 = − 𝐹
    𝑏𝑢𝑜𝑦,1 𝑑 + 𝑇 1 + 𝑊 𝑏𝑢𝑜𝑦 . 𝜃 1 − 𝐶 𝑠 ℓ [2( 𝜋 2 − 𝜃 1 )+( 𝜋 2 + 𝜃 2 )] (18) 𝑚 𝑏𝑢𝑜𝑦
    𝑑 𝑣 𝐵2 𝑑𝑡 = − 𝐹 𝑏𝑢𝑜𝑦,2 𝑑 + 𝑇 2 + 𝑊 𝑏𝑢𝑜𝑦 . 𝜃 2 + 𝐶 𝑠 ℓ [2( 𝜋 2 + 𝜃 2 )+( 𝜋 2 −
    𝜃 1 )] (19) Then, distance d is expressed as 𝑑(𝑑) 𝑑𝑡 = 𝑑( 𝑟 𝐵 1 𝐵 2 ) 𝑑𝑡 = 𝑣 𝐵2
    − 𝑣 𝐵1 (20) The subtraction of Equation (19) from (18) yields 𝑚 𝑏𝑢𝑜𝑦 𝑑 2 (𝑑) 𝑑
    𝑡 2 = 𝐹 𝑏𝑢𝑜𝑦1 𝑑 − 𝐹 𝑏𝑢𝑜𝑦,2 𝑑 + 𝑊 𝑏𝑢𝑜𝑦 ( 𝜃 2 − 𝜃 1 )+ 𝑇 12 +3. 𝐶 𝑠 ℓ ( 𝜃 2 − 𝜃
    1 +𝜋) (21) with 𝑇 12 = 𝑇 2 − 𝑇 1 . Since 𝑑≈ℓ( 𝜃 1 − 𝜃 2 ) , 𝑚 𝑏𝑢𝑜𝑦 𝑑 2 (𝑑) 𝑑 𝑡
    2 = 𝐹 𝑏𝑢𝑜𝑦,1 𝑑 − 𝐹 𝑏𝑢𝑜𝑦,2 𝑑 −( 𝑊 𝑏𝑢𝑜𝑦 +3 𝐶 𝑠 ℓ ). 𝑑 ℓ + 𝑇 12 +3𝜋. 𝐶 𝑠 ℓ (22) In
    addition, 𝐹 𝑏𝑢𝑜𝑦,1 𝑑 − 𝐹 𝑏𝑢𝑜𝑦,2 𝑑 = 𝐷.( 𝑣 𝐵1 − 𝑣 𝐵2 )=−𝐷. 𝑑(𝑑) 𝑑𝑡 (23) where 𝐷=𝑘.𝜇
    for a laminar water flow. 𝐷=𝐷( 𝑣 𝐵1 , 𝑣 𝑏2 )= 1 2 . 𝐶 𝐷 .𝐴. 𝜌 𝑤 .( 𝑣 𝐵1 + 𝑣 𝐵2
    ) for a turbulent water flow. Noting that 𝐸= 𝑊 𝑏𝑢𝑜𝑦 +3 𝐶 𝑠 ℓ , the differential
    equation relative to d is the 𝑚 𝑏𝑢𝑜𝑦 𝑑 2 (𝑑) 𝑑 𝑡 2 +𝐷. 𝑑(𝑑) 𝑑𝑡 + 𝐸 ℓ .𝑑 = 𝑇 12
    +3𝜋. 𝐶 𝑠 ℓ (24) The undamped pulsation is 𝜔 0 = 𝐸 ℓ. 𝑚 𝑏𝑢𝑜𝑦 − − − − − √ . The
    following transfer function of the linearized system can be written as 𝐻(𝑗𝜔) =
    𝑑 𝑇 12 +3𝜋. 𝐶 𝑠 ℓ = ℓ/𝐸 1+(𝑗𝜔) 𝐷.ℓ 𝐸 + (𝑗𝜔) 2 . ℓ. 𝑚 𝑏𝑢𝑜𝑦 𝐸 (25) In the case of
    a laminar flow, the buoy–ballast system can be seen as a second-order low-pass
    filter for small angles with the damping coefficient 𝜉= 1 2 .𝑘.𝜇. ℓ. 𝐸. 𝑚 𝑏𝑢𝑜𝑦
    − − − − − √ . In the case of a turbulent flow, if we consider the sum of velocities
    ( 𝑣 𝐵1 + 𝑣 𝐵2 ) to be above a certain threshold and to vary around an average
    velocity 𝑣 𝑠 , then the buoy–ballast system can be seen as a second-order low-pass
    filter for small angles, with the damping coefficient 𝜉= 1 2 . 1 2 . 𝐶 𝐷 .𝐴. 𝜌
    𝑤 . 𝑣 𝑠 . ℓ. 𝐸. 𝑚 𝑏𝑢𝑜𝑦 − − − − − √ . The setting of the damping coefficient to
    a few units above 1, namely 𝜉 𝑡ℎ𝑟𝑒𝑠ℎ𝑜𝑙𝑑 , helps with adjusting parameters ℓ and
    𝑉 𝑏𝑢𝑜𝑦 in minimizing 𝑣 𝑠 as much as possible, taking into account the other constraints
    (value of 𝑑 𝑟𝑒𝑠𝑡 and ℓ not too high with regard to the size of the ROV): 𝜉 > 𝜉
    𝑡ℎ𝑟𝑒𝑠ℎ𝑜𝑙𝑑 (26) 𝑣 𝑠 > 4 𝐶 𝐷 .𝐴. 𝜌 𝑤 . 𝐸. 𝑚 𝑏𝑢𝑜𝑦 ℓ − − − − − − − √ . 𝜉 𝑡ℎ𝑟𝑒𝑠ℎ𝑜𝑙𝑑
    (27) 2.5. Conclusions on the Use of Modeling The steady-state model is useful
    for determining the theoretical variation in the distance between the buoys as
    a function of the speed via numerical resolution. This theoretical variation is
    compared with the variation obtained in the simulator (see Section 3, dedicated
    to simulations, where the influence of 𝑇 1𝑐 is discussed). The steady-state model
    is also used in the control scheme to determine the target distance between buoys
    as a function of the ROV speed such that the whole system converges to the steady-state
    mode (see Section 4.2). The dynamics analysis allows the behavior of the V-shape
    system to be determined as a second-order low-pass filter after linearization.
    However, as the system is underactuated, it is not possible to separately control
    the velocities of each of the buoys. In addition, Equations (17) and (27) are
    used to define a zone of validity for parameters ℓ and 𝑉 𝑏𝑢𝑜𝑦 . The limits of
    the validity zone can be defined by the following equations: 𝑑 𝑚𝑖𝑛 < 𝑑 𝑟𝑒𝑠𝑡 <
    𝑑 𝑚𝑎𝑥 (28) 4 𝐶 𝐷 .𝐴. 𝜌 𝑤 . 𝐸. 𝑚 𝑏𝑢𝑜𝑦 ℓ − − − − − − − √ . 𝜉 𝑡ℎ𝑟𝑒𝑠ℎ𝑜𝑙𝑑 < 𝑣 𝑠 (29)
    using 𝑑 𝑚𝑖𝑛 =0.1 m, 𝑑 𝑚𝑎𝑥 =0.3 m, 𝜉 𝑡ℎ𝑟𝑒𝑠ℎ𝑜𝑙𝑑 =1 , and 𝑣 𝑠 =0.1 m/s, where these
    values are the result of design choices. 3. Simulations This section focuses on
    the following: The numerical modeling of the V-shape system with Matlab–Simulink™
    for precise sizing of the parameters ℓ and 𝑉 𝑏𝑢𝑜𝑦 . A series of simulations run
    with the Vortex® simulator to check the validity of the V-shape system. In particular,
    the variation in the distance between buoys as a function of speed is observed
    and compared with the variation obtained using the theoretical model to check
    the steady-state mode. The influence of the V-shape system in terms of power consumption
    of the ROV is also evaluated. Then, a complete trajectory with varying depth,
    turns, and speed is simulated to observe the behavior of the V-shape system. 3.1.
    Numerical Modeling for Precise Sizing For precise sizing purposes, the V-shape
    system was modeled using finite solids and simulated in the Matlab–Simulink environment
    using the Simscape and Multibody toolbox. This numerical model is composed of
    twenty-four 5 cm long rigid elements linked to their neighbors by revolute joints
    whose stiffness is equal to 10 −3 N.m/rad, which was experimentally determined
    using the Fathom Slim tether cable of BlueRobotics™ [6]. The damping behavior
    is a result of the buoys’ drag force. Figure 3 is a representative screenshot
    from the video that shows the dynamic behavior of the V-shape system returning
    to rest state. This validates the physical assumptions for the design of the proposed
    mechanical model. Moreover, it confirms that the V-shape system does not acquire
    a droplet shape, which is crucial for guaranteeing the monotony of the output
    signal provided by the flex sensor mounted at the ballast [27]. This embedded
    instrumentation provides a suitable signal related to the compliance state that
    is appropriate for use as feedback for the winch command. Figure 3. Snapshot of
    the numerical model obtained for the buoy–ballast system using Matlab–Simulink™
    (https://www.youtube.com/watch?v=PtQigrKUr9E (accessed on 1 December 2023)). The
    V-shape system should not be excessive in size with respect to the robot’s dimensions.
    A distance of 1.2 m between the buoys was chosen for a 1 m range of distance compliance
    between buoys and a minimal distance of 0.2 m at rest, which yields ℓ = 0.6 m
    for each section 𝐶 𝐵 1 and 𝐶 𝐵 2 . The value of 𝑉 𝑏𝑢𝑜𝑦 was set to approx. 36 cm
    3 . 3.2. Configuration for the Simulator Simulations of the complete system, including
    the cable, buoy–ballast system, ROV (which is speed-controlled in open-loop),
    and cable feeder, were carried out using the Vortex® simulator, version 2021a
    (2021.1.0.66). This software integrates the modeling of cables from a mass–spring
    model, taking into account their physical parameters for realistic rendering.
    The tether is a complex non-homogeneous object comprising several twisted strands
    and different coating layers. Some of its physical parameters are assumed to be
    constant and are directly provided by the manufacturers or easy to measure directly
    through experimental setups. Other parameters are more difficult to determine,
    requiring the use of abacuses. Table 1 summarizes the parameters used for simulation.
    The simulated tether mimics the Fathom Slim tether. Breaking strength, radius,
    and linear density were obtained from datasheets. Bending stiffness, torsional
    stiffness, axial stiffness, damping, and drag coefficients were determined through
    experiments [6]. Table 1. Parameters used for simulation of the Fathom Slim tether.
    Values marked with an asterisk (*) are approximate estimates. The simulated ROV
    is adapted from the BlueROV2-Heavy from BlueRobotics™, which has four vertical
    thrusters and four thrusters for the horizontal movements arranged in vectorial
    mode. 3.3. Study of the Distance between Buoys The distance between both buoys
    and its variation are observed while the ROV moves forward at a constant speed
    (Figure 4). The coordinates of the centers of the buoys are used to calculate
    the distance and the variation. In this simulation, the ROV starts at a horizontal
    distance of 4 m from the remote station and a depth of 0.5 m. A length of 10 m
    of cable is unwound and then, at 11 s, the ROV starts to move 7 s forward at a
    controlled speed of 0.4 m/s. The desired speed is reached after 1.3 s. During
    the simulation, the difference between the length of the deployed cable and the
    distance of the ROV from the remote station is greater than 3 m. The time evolution
    of the distance between buoys shows that the system returns to its rest position
    in 5.5 s after the ROV stops. The 5% response time is 3.8 s. Thus, the system
    behaves like a damper. The impact of the 120 ms delay of the flex sensor, due
    to filtering post-processing, is negligible, and the acquisition/control frequency
    of 25 Hz is sufficient. Despite the damping effect, the variations in ROV speed
    immediately affect the distance between the buoys, which supports the interest
    in using this parameter to control the automatic distribution of the cable. Figure
    4. Distance between buoys and its variation when the ROV moves at constant speed.
    To observe the behavior of the damped system, the relationship between the distance
    between the buoys and the ROV forward speed at 0.5 m depth is shown in Figure
    5. The figure displays the curve obtained from simulation and the curves obtained
    from the theoretical model for values of 𝑇 1𝑐 equal to 0 N, 0.01 N, 0.03 N, 0.05
    N, and 0.1 N. The drag forces were considered quadratic. Despite some slight offset,
    the curve issued from the steady-state model with an order of magnitude of 0.03
    N for 𝑇 1𝑐 is close to the curve obtained in the simulation. The value of 𝑇 1𝑐
    depends on the design of the feeder built for the simulation. The inter-buoy distance
    is close to its maximum when the ROV reaches a speed of 0.8 m/s. This value represents
    the speed limit for optimal behavior of the system. The distance versus speed
    relationship can be used to define a target inter-buoy distance as a function
    of the ROV speed to help the system converge to the steady-state mode. this is
    not possible since labels are not compatible with tex symbols Figure 5. Distance
    between buoys versus ROV speed. Comparison between theoretical steady-state model
    and simulation using Vortex. Influence of 𝑇 1𝑐 , the constant part of the cable
    tension from the left side. 3.4. Influence of Buoy–Ballast System on ROV Power
    The power of the ROV is calculated using the manufacturer data of the T200 brushless
    motors that equip the BlueRov. The manufacturer datasheets provide the motor power
    as a function of the motor speed, and the thrust as a function of the motor speed.
    The motors’ speeds are controlled to achieve the desired vehicle speed. The total
    power is then calculated by summing the motor powers. The speed of the ROV is
    not affected by the presence of the compliant system since the simulated ROV is
    velocity-controlled. However, the total power of the ROV thrusters observed in
    simulation, represented in Figure 6, is 2% higher globally with the compliant
    system. This is due to the drag forces on the buoy–ballast system that the cable
    transmits to the ROV. The passive compliant system introduces slightly more tension
    in the cable throughout the movement of the ROV compared with a free cable with
    sufficient length. However, this increase in tension is not significant, and the
    compliant system on the cable prevents the cable from pulling strongly on the
    ROV. Figure 6. Comparison of cable impact on ROV power with and without passive
    compliant system. 3.5. Generation of ROV Trajectories for Further Analysis Generation
    of trajectories. Trajectories are defined as a sequence of depth, orientation,
    and speed commands of the ROV. The ROV is speed-controlled with a PID control
    loop and with a proportional control loop in heave, yaw, roll, and pitch. Figure
    7 presents the curves for the velocity, depth, and angle commands as well as the
    values measured during the simulation for an untethered ROV. Keyframes are indicated
    on this trajectory to provide reference points. This trajectory starts with forward
    movement of the ROV along its longitudinal axis at different successive speeds
    between points 0 and 1 (0.1 m/s, 0.2 m/s, and then 0.3 m/s) in parallel with a
    depth control of 0.5 m. Then, a command for a forward speed of 0.3 m/s is sent
    again (point 1), followed by a depth command at 2 m (point 2). Then, while moving
    forward at a constant speed, the ROV receives successive yaw commands: 45deg to
    the left (point 3), 45deg to the right (point 4), 0deg , 90deg to the right (point
    5), and 180deg (point 6). Finally, the forward speed command is set to zero, while
    the depth command is kept to 2 m (point 7). The trajectory projected in the horizontal
    plane, deduced from the longitudinal speed and the orientation of the ROV, is
    also presented at the bottom right. The difference between the set point and the
    actual displacements of the ROV is due to hydrodynamic phenomena, which slow down
    the ROV in water. Moreover, when there are changes of set point in depth and yaw,
    a significant acceleration is required, resulting in overloading of the thrusters
    and affecting the speed along the x-axis (Figure 7). Figure 7. Simulated trajectories
    of the ROV. Control schemes. The behavior of the system is compared for five different
    modes listed below. Cable not controlled and without compliant system: the cable
    length is fixed to 15 m along the simulation. Cable with passive compliant system
    (not controlled): the cable length is fixed to 15 m along the simulation. Cable
    controlled with ROV speed command as input: the delivery speed of the cable is
    set to the ROV speed. Cable controlled with distance between the buoys: a closed-loop
    PD controller maintains a target distance of 0.8 m between the buoys. Hybrid control
    of the cable based on ROV speed and distance between buoys, which combines buoy
    distance PD controller and P controller using an ROV speed command. Furthermore,
    the target distance between the buoys is set to vary according to the ROV speed.
    The proportional part of the PD controller on the buoys’ distance works only if
    the distance is at least 5 cm longer than the target (taut cable) or if it is
    less than the target for more than 1 s (slack cable). Distance between buoys.
    Figure 8 depicts the evolution of the distance between buoys for passive configuration
    and the three control modes. Figure 8. Comparison of the evolution of the distance
    between the buoys in passive mode and in three control modes. Unsurprisingly,
    the best control is obtained with the buoy distance-based control, which keeps
    the distance between buoys around 0.8 m, despite oscillations that appear when
    the ROV is turning, from keyframe 3 to shortly after keyframe 6. The hybrid controller
    allows the distance to be kept within reasonable values, between 0.4 m and 0.9
    m. The distance between the buoys reaches more extreme limits (0.16 m and 1.1
    m) when the cable is not controlled or ROV speed-controlled. Cable delivery speed.
    Figure 9 shows the delivery speed for the three control modes. Figure 9. Comparison
    of the delivery speed for different control modes with a complex trajectory. When
    the ROV moves forward at low speed (before keyframe 1), the feeder’s speed is
    almost the same for the three control modes. As only the linear speed is considered
    for the ROV speed-based control, the cable delivery speed remains constant between
    keyframes 1 and 7, not taking into account the orientation of the ROV. Oscillations
    are more pronounced for the hybrid controller than for the buoy distance-based
    controller, resulting in a smoother cable delivery speed. Overall cable shape.
    The overall shape of the cable is depicted in Figure 10 for all cable control
    configurations at two different keyframes of the trajectory, namely keyframe 5,
    when the ROV finishes its forward motion, and after keyframe 7, when the ROV returns
    close to the feeder. With the hybrid control, the cable behaves correctly, except
    for when a slight excess of cable forms a lobe as the ROV moves toward the feeder.
    The length of free cable is too long with the ROV speed controller. In contrast,
    the length of free cable is tightly adjusted when using the buoy distance-based
    controller. When the cable is not controlled, loops appear on the water surface
    before the ROV starts to move away, as the cable length is far too long. These
    loops remain throughout the trajectory, generating a significant risk of snagging
    or entanglement of the cable. Figure 10. Views of the system configuration for
    di this is not possible since labels are not compatible with tex symbolsfferent
    cable control modes at two points of the complex trajectory (video available at
    this link: https://www.youtube.com/watch?v=ZC2zStwkdSo (accessed on 1 December
    2023)). Conclusions from controller analysis. Of the three controllers evaluated
    in the simulation, the ROV speed-based controller is not sufficiently responsive
    and generates a static error on the buoys’ distance that is never corrected. It
    is therefore not robust to external disturbances. The control mode based on the
    distance between buoys is rather smooth, robust, and reactive. The hybrid control
    is quite reactive but presents some more pronounced oscillations while remaining
    rather stable. Hybrid control could possibly be improved by replacing the ROV
    command speed with the actual ROV speed, which would require the use of more sensors
    on the ROV, such as a Doppler velocity log (DVL). 4. Description of Setup, Control
    Mode, and ROV Trajectories for Real Experiments The simulations described in the
    previous section allowed validation of the behavior of the V-shape system by comparing
    the different modes of cable control. This section describes the preparation for
    real experiments that took place in water tanks. This preparation includes the
    setup, control scheme, and two kinds of trajectories that were used to check the
    system behavior in real conditions. To ensure the ground truth of the movements
    of the cable, compliant buoy–ballast system, and ROV, an underwater motion capture
    system was implemented. 4.1. Setup The cable feeder was fixed on the border of
    a 16 × 8 m water tank and connected to the ROV through a 25 m long 4 mm diameter
    tether, namely the Fathom Slim, equipped with the buoy–ballast system, of which
    a technological description can be found in [27]. The ROV used was a BlueROV2-Heavy,
    as in the simulation. A flex sensor was mounted on the cable at the ballast location
    using a fixed bracket and guides along the cable (Figure 11). The sensor has negligible
    bending stiffness. It was wrapped in a thin plastic envelope for waterproofing.
    The sensor resistance varies when the cable is bent. This varying resistance is
    transformed into a voltage signal through a voltage divider, then filtered, centered,
    and trimmed. The variation in the resulting signal is used to fit the corresponding
    distance between the buoys through a third-order polynomial (Figure 12). Figure
    11. Mounting of the flex sensor near the eballast. Figure 12. Measured distance
    between the buoys as a function of the centered resistance of the flex sensor
    with experimental data points. Table 2 summarizes the characteristics of the buoy–ballast
    system to which the Fathom Slim tether is equipped, taking into account the previously
    described modeling analysis. Table 2. Specifications and characteristics of the
    buoy–ballast system adapted for the Fathom Slim tether. The controller board inside
    the robot was run on a Linux/ROS-1 system with the mavros library to interface
    the high level control with the autopilot ArduSub. The BlueROV2 was controlled
    remotely via a gamepad connected to the control computer. The remote control computer
    contains the embedded ROS master. It was connected to the feeder for the transmitting
    of control commands while taking into consideration the data received from the
    flex sensor through the ROS system embedded in the robot. The diagram in Figure
    13 shows the architecture of the ROS nodes for controlling the global system during
    the experiments. Figure 13. Graph of the global ROS nodes architecture for the
    control. The oval boxes correspond to the nodes and the rectangular boxes to the
    topics exchanged by these nodes. The robot and the cable were tracked by a camera
    motion-tracking system, namely Qualisys, with five underwater optical cameras
    Miqus M5u at 180 frames per second. The cameras use blue LEDs, whose light is
    reflected by markers placed on the ROV and the cable. Data are recorded from the
    QTM software, version 2020.3 build 6020, which is controlled from a dedicated
    computer during the experiments. This software computes the current 3D position
    of each marker provided they are detected by several cameras. Across the experiments,
    the position residuals of the markers were about 1.3 mm for the ROV, with a minimum
    of 0.9 mm and a maximum of 10 mm. 4.2. Control Scheme Figure 14 is the control
    block diagram of the feeder, which can be controlled using the measured distance
    between buoys, namely buoy gap on the figure, or using a desired cable length.
    The control for the feeder consists of a main control loop with proportional controllers,
    which includes a speed control loop with a proportional–integral controller and
    anti-windup system. Flex sensor processing, presented in Section 4.1, is used
    to estimate the inter-buoy distance, which is sent to the feeder by the ROV. Figure
    14. Control block diagram of the feeder using the steady-state model and length
    and speed control loops. R is the radius of the feeder wheel and N is the number
    of ticks of the encoder counter. In normal mode, namely buoy gap control mode,
    the feeder speed is controlled as the ROV moves to regulate the gap between both
    buoys. The target buoy gap is defined from the actual ROV speed using the steady-state
    model that gives the variations in the buoy gap as a function of the ROV speed
    (see Section 2.3 and Figure 5). The target buoy gap is then compared to the current
    gap measured by the flex sensor to update the rotation speed of the feeder. In
    length control mode, the cable length can be directly controlled by setting a
    desired length. The feeder can actually be operated to release the cable when
    necessary; e.g., when the V-system is stretched, 2 m of cable is uncoiled after
    a 10 s period until the V-system is released. Buoy gap control and length control
    modes are separately activated as required. Cable length is computed in the speed
    control loop such that it is accessible even when length control is disabled.
    The target rotation speed is first bounded to avoid exceeding the motor limits.
    Embedded in the speed control loop is a proportional–integral corrector, which
    is applied to the error between the bounded target speed and the measured speed.
    This corrector has an anti-windup system that limits the sum of past errors to
    stabilize the system. It outputs a raw PWM signal, which is then bounded and smoothed
    by a low-pass filter before being transmitted to the motor control board. 4.3.
    Trajectories The experimental results of cable control validation were obtained
    during a series of tests carried out in the pool of the CIRS (Underwater Robotics
    Research Center) in Girona in the context of a TNA (TransNational Access) European
    project. Two kinds of ROV trajectories were defined to represent two configurations
    where cable control must be useful to reduce risks of cable snagging or entanglements
    as below. A linear trajectory where the ROV goes forwards and then backwards First,
    a forward thrust command of 25% is sent for 15 s (between keyframes 1 and 2).
    Then, a zero command is sent for 5 s (between points 2 and 3). Finally, a backward
    thrust command of 25% is sent for 10 s (between points 3 and 4). A curvilinear
    S-shape trajectory comprising the following steps: - a forward thrust of 40% for
    15 s (between points 1 and 2); - a right turn composed of a yaw thrust of 11.25%
    combined with a forward thrust of 40% for 6.5 s to turn right (between points
    2 and 3); - a left turn with the same thrust command values as the left turn,
    for 6 s (between points 3 and 4); - a forward thrust of 40% for 4 s (between points
    4 and 5). All these trajectories were associated with 1.5 m depth control. The
    ROV was open-loop-controlled to follow these trajectories by driving the corresponding
    thrusters. For each trajectory, three kinds of cable management were tested: Passive
    slack cable, where cable of sufficient length was deployed in the water from the
    beginning. Passive taut cable, where the cable is stretched between the feeder
    and the ROV when the ROV moves away from the feeder, which means that the buoy–ballast
    system is also completely stretched and has no real influence on the ROV. The
    feeder is not powered. When the ROV comes closer to the feeder, the cable is no
    longer taut, and the buoy gap tends to be reduced to a minimum. Cable control,
    using buoy gap control mode. A 25% and 40% forward thrust is associated with a
    buoy gap of about 0.7 mn and 0.8 m, respectively, according to the steady-state
    model. 5. Results And Discussion 5.1. Linear Trajectory Figure 15 illustrates
    the cable management results for the linear trajectory including buoy distance
    control mode, passive slack mode, and passive taut mode. The feeder appears to
    be quite reactive and smooth in winding/unwinding the cable depending on ROV motion
    and the distance between buoys. The buoy–ballast system exhibits highly dynamic
    transient behavior between points 2 and 4 due to the changes in velocity. When
    moving backward, the feeder also takes more time for buoy gap convergence back
    to the target distance (0.7 m). Figure 15. Distance between buoys, feeder speed,
    and unwound length of cable in control mode, passive slack mode, and passive taut
    mode for forward–backward trajectory. (https://youtu.be/owekUkN_UtM for control
    mode, https://youtu.be/1RTT23-USDY for passive taut mode, https://youtu.be/FG5iyNfjzck
    for passive slack mode (accessed on 1 December 2023)). Figure 16 presents the
    paths followed by the ROV projected onto the horizontal plane as measured by the
    Qualisys system for the three cable modes. Figure 16. Top view of actual forward–backward
    trajectories of the ROV using cable control, slack, or passive taut cable. Paths
    are superimposed at point 2 for easier comparison. If there were no external disturbances
    at all, the path would be rectilinear. The ROV shifts slightly to the left when
    the cable is slack. This deviation is slightly larger in the control mode and
    is observed during both its forward and backward motion. The deviation is significantly
    greater in passive taut mode. Furthermore, the distance covered by the ROV is
    shorter with the taut cable. Figure 17 shows the evolution of depth control of
    the ROV for the three modes. Only the control mode is efficient in helping to
    regulate the ROV depth. In addition, the vertical thrusters’ work significantly
    increases more when the cable is not controlled than when it is controlled. Figure
    17. ROV depth and vertical depth control thrust in the three modes. 5.2. Curvilinear
    Trajectory Figure 18 shows the snapshots at keyframes 1, 3, and 4 in cable control
    mode. Figure 19 presents the results in terms of buoy gap, feeder speed, and delivered
    cable length. Figure 20 presents the yaw angle. Figure 21 shows the executed trajectories
    in the cases of passive slack cable, passive taut cable, and control mode. Figure
    18. Views of the overall system at different points along the curvilinear trajectory
    when the cable is controlled. The red arrows indicate the direction of motion
    of the ROV (video at https://youtu.be/fy-JTc8PvIY (accessed on 1 December 2023)).
    Figure 19. Distance between buoys (flex sensor), feeder speed, and unwound length
    of cable in control mode, passive slack mode, and passive taut mode for the curvilinear
    trajectory (videos at https://youtu.be/LR4BKefRSnM for passive slack mode and
    at https://youtu.be/74p5Bzee9kY for passive taut mode (accessed on 1 December
    2023)). Figure 20. Comparison of the ROV yaw angle (measured with the embedded
    compass) along the curvilinear trajectory with or without cable control. The angle
    was initialized to 0 𝑜 at the beginning of the trajectories to facilitate their
    comparison. An increase in the angle represents a rotation to the right of the
    ROV. Figure 21. Comparison of the actual curvilinear path of the ROV in top view,
    measured by the Qualisys system, with or without cable control. These paths are
    superimposed on point 2 for easier comparison. In control mode, the compliant
    system keeps its V-shape and a buoy gap average close to the target distance (0.8
    m), except for during turns, where the behavior is highly dynamic because of the
    increased forward speed and the opposing directions of the successive turns, which
    causes the buoy gap to reach its bounds, namely 0.2 m and 1.2 m, during a short
    period of time. The buoy gap resulting from passive taut and passive slack modes
    demonstrates the added value of automatic cable length management in maintaining
    an average buoy gap, which allows the cable shape between the station and the
    buoy–ballast system to be controlled. For a flawless system without any disturbance,
    the yaw angle (Figure 20) must be constant during the ROV straight line commands
    (before point 2 and after point 5). It must also be linear during rotating commands
    (between points 2 and 3, then 3 and 4). There is a slight deviation of about 20
    deg to the right during the first straight line (2.6 m) command of the ROV for
    the passive slack cable. This deviation is oriented to the left and its absolute
    value is doubled with the controlled cable and doubled again with the passive
    taut cable. In fact, the cable is fixed on the left side of the back of the ROV,
    which induces a slight deviation to the left for the controlled cable, both in
    a straight line and during a right rotation. This deviation is much larger for
    the passive taut cable. The left rotation of the ROV appears to be less affected
    in the control and passive taut modes. The impact of these deviations is observed
    in Figure 21, in which the ROV paths in top view are shown for the three modes.
    The distances traveled are quite similar for the controlled cable and the passive
    slack cable, whereas the turns are slightly different. The path of the ROV with
    the passive taut cable is completely distorted. The first rotation to the right
    (between points 2 and 3) is tightly confined, and the rotation to the left (between
    points 3 and 4) is quite irregular (much wider curvature in the middle than at
    the beginning and the end). The experiments also showed there is effective control
    of the cable using the compliant buoy–ballast system, which keeps the cable in
    a semi-stretched configuration, and the delivered length is appropriately managed,
    preventing the creation of cable loops that can occur in passive slack mode and
    reducing the risks of snagging and tangles, considering that turns in passive
    taut mode can cause the cable to become entangled with the robot. The control
    mode generates slight tension in the cable, which is transmitted to the ROV and
    results in a minor deviation in the trajectory of the system, which can be avoided
    by fixing the cable closer to the ROV’s center of gravity. In addition, the passive
    compliance system appears to improve the stability of the depth control of the
    ROV. 6. Conclusions In this paper, a mechatronic solution for ROV deployment is
    introduced in which the length of the cable that connects the robot to the surface
    is automatically controlled. This solution consists of designing and setting up
    a balanced and compliant buoy–ballast system for the cable, which allows the cable
    feeder to be controlled using the readings from the flex sensor placed along a
    part of the cable near the ballast. The simulations and the experiments conducted
    with a BlueROV and a neutral cable demonstrated the validity of the concept. The
    steady-state model was used in the control loop to obtain a target distance between
    the buoys from the ROV speed command. The feeder appeared to react as expected
    with respect to the command speeds of the ROV. The shape of the cable was kept
    in a semi-stretched configuration during the experiments of linear and curved
    trajectories. This solution is easy to set up and can be useful in preventing
    the cable from pulling on the ROV, thus avoiding entanglement of the cable with
    its surroundings. The aim for future developments will be to implement the cable
    feeder on a surface vehicle (USV). The measurement of the consumed current will
    help in estimating the cable strain on the USV side. It will also be possible
    to equip the tether with strain sensors on the ROV side to increase the accuracy
    of closed-loop control with respect to the distance between buoys. Possible prospects
    include navigation synchronization between the ROV and the USV to optimize displacement
    of the vehicles in terms of power consumption and to increase seabed coverage
    in shallow waters. Author Contributions Conceptualization, methodology, writing,
    and data curation, O.T.; formal analysis and investigation, C.P.; project administration,
    supervision, validation, writing, formal analysis, review, and editing, C.A. and
    V.H. All authors have read and agreed to the published version of the manuscript.
    Funding This research was funded by the Provence-Alpes-Côte d’Azur (PACA) region
    for the ‘Emploi jeunes doctorants’ (EJD) project, and the 3rd TransNational Access
    (TNA) H2020 European project related to EuMarineRobots. Informed Consent Statement
    Informed consent was obtained from all subjects involved in the study. Data Availability
    Statement No new data were created or analyzed in this study. Data sharing is
    not applicable to this article. Acknowledgments The authors greatly thank the
    CIRS lab (Underwater Robotics Research Center) in Girona, Spain, especially Pere
    Ridao and Guillem Vallicrosa Massaguer for their welcome and administrative and
    technical support during the week of experiments in the frame of the TNA project.
    Conflicts of Interest The authors declare no conflicts of interest. Appendix A.
    Statics Analysis of the Buoy–Ballast System The entire system is assumed to move
    at a constant velocity v driven by the ROV in the left–right direction. Assuming
    that all forces intersect at 𝐵 1 , the compensation of forces exerted on the left
    buoy is calculated as 𝑊 𝑏𝑢𝑜𝑦 + 𝑇 𝑦 𝐵1 = 0 (A1) − 𝐹 𝑏𝑢𝑜𝑦 𝑑 − 𝑇 1 + 𝑇 𝑥 𝐵1 = 0 (A2)
    where 𝑇 𝑥 𝐵1 and 𝑇 𝑦 𝐵1 are the components of the force 𝐓 𝐁𝟏 that is exerted by
    the cable portion 𝐵 1 𝐶 onto the left buoy. 𝐹 𝑏𝑢𝑜𝑦 𝑑 is the intensity of the drag
    force exerted by the fluid on the buoy. 𝑇 1 >0 is the magnitude of the horizontal
    scalar force exerted by the cable that links the left buoy to the remote station.
    Assuming that all forces intersect at 𝐵 2 , the compensation of forces exerted
    on the right buoy is calculated as 𝑊 𝑏𝑢𝑜𝑦 + 𝑇 𝑦 𝐵2 = 0 (A3) − 𝐹 𝑏𝑢𝑜𝑦 𝑑 + 𝑇 2 +
    𝑇 𝑥 𝐵2 = 0 (A4) where 𝑇 𝑥 𝐵2 and 𝑇 𝑦 𝐵2 are the components of the force 𝐓 𝐁𝟐 that
    is exerted by the cable portion 𝐵 2 𝐶 onto the right buoy. 𝑇 2 is the algebraic
    horizontal scalar force exerted by the cable that links the right buoy to the
    ROV. In the case of the figure, the intensity 𝑇 2 is positive since the ROV pulls
    on the cable to move from left to right. Taking into account a drag force of intensity
    𝐹 𝐶 𝐵 1 𝑑 and 𝐹 𝐶 𝐵 2 𝑑 , resp., on the cable portions 𝐶 𝐵 1 and 𝐶 𝐵 2 , the compensation
    of forces exerted on the ballast is − 𝑊 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 − 𝑇 𝑦 𝐵1 − 𝑇 𝑦 𝐵2 = 0 (A5) − 𝐹
    𝑏𝑎𝑙𝑙𝑎𝑠𝑡 𝑑 − 𝐹 𝐶 𝐵 1 𝑑 − 𝐹 𝐶 𝐵 2 𝑑 − 𝑇 𝑥 𝐵1 − 𝑇 𝑥 𝐵2 = 0 (A6) Equation (A5) is
    actually not useful since it was already set that 𝑊 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 =2. 𝑊 𝑏𝑢𝑜𝑦 , which
    can be found again using Equations (A1) and (A3). In addition, the cable stiffness
    must be taken into account in the compensation of the efforts exerted on cable
    portions 𝐶 𝐵 1 and 𝐶 𝐵 2 . Taking C as a reference point, the compensation of
    the moments of force and torques exerted on 𝐶 𝐵 1 is expressed as [ 𝐫 𝐂𝐁 𝟏 ×(−
    𝐓 𝐁𝟏 )+ 𝟏 𝟐 𝐫 𝐂𝐁 𝟏 × 𝐅 𝐂𝐁 𝟏 𝐝 + 𝐓𝐪 𝐬 𝐁 𝟏 + 𝐓𝐪 𝐬 𝐂,𝐫𝐢𝐠𝐡𝐭 ].𝐳=𝟎 and on 𝐶 𝐵 2 as
    [ 𝐫 𝐂𝐁 𝟐 ×(− 𝐓 𝐁𝟐 )+ 𝟏 𝟐 𝐫 𝐂𝐁 𝟐 × 𝐅 𝐂𝐁 𝟐 𝐝 + 𝐓𝐪 𝐬 𝐁 𝟐 + 𝐓𝐪 𝐬 𝐂,𝐥𝐞𝐟𝐭 ].𝐳=𝟎 where
    𝐫 𝐂𝐁 𝟏 and 𝐫 𝐂𝐁 𝟐 are the position vectors of 𝐵 1 and 𝐵 2 , resp., with regard
    to C, and 𝐓𝐪 𝐬 𝐁 𝟏 is the cable bending torque exerted onto the branch 𝐵 1 𝐶 at
    𝐵 1 , and 𝐓𝐪 𝐬 𝐁 𝟐 is the cable bending torque exerted onto the branch 𝐵 2 𝐶 at
    𝐵 2 . 𝐓𝐪 𝐬 𝐂,𝐫𝐢𝐠𝐡𝐭 and 𝐓𝐪 𝐬 𝐂,𝐥𝐞𝐟𝐭 are the cable bending torques exerted by the
    right and left parts, resp., at C. These torques are proportional to a bending
    stiffness coefficient named 𝐶 𝑠 . The equations above yield ( 𝑇 𝑥 𝐵1 + 1 2 . 𝐹
    𝐶 𝐵 1 𝑑 ).ℓ.cos 𝜃 1 + 𝑇 𝑦 𝐵1 .ℓ.sin 𝜃 1 + 𝐶 𝑠 [2( 𝜋 2 − 𝜃 1 )+( 𝜋 2 + 𝜃 2 )] (
    𝑇 𝑥 𝐵2 + 1 2 . 𝐹 𝐶 𝐵 2 𝑑 ).ℓ.cos 𝜃 2 + 𝑇 𝑦 𝐵2 .ℓ.sin 𝜃 2 − 𝐶 𝑠 [2( 𝜋 2 + 𝜃 2 )+(
    𝜋 2 − 𝜃 1 )] = = 0 0 The number of independent equations is therefore 𝑊 𝑏𝑢𝑜𝑦 +
    𝑇 𝑦 𝐵1 =0 − 𝐹 𝑏𝑢𝑜𝑦 𝑑 − 𝑇 1 + 𝑇 𝑥 𝐵1 =0 𝑊 𝑏𝑢𝑜𝑦 + 𝑇 𝑦 𝐵2 =0 − 𝐹 𝑏𝑢𝑜𝑦 𝑑 + 𝑇 2 + 𝑇
    𝑥 𝐵2 =0 − 𝐹 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 𝑑 − 𝐹 𝐶 𝐵 1 𝑑 − 𝐹 𝐶 𝐵 2 𝑑 − 𝑇 𝑥 𝐵1 − 𝑇 𝑥 𝐵2 =0 ( 𝑇 𝑥 𝐵1 +
    1 2 . 𝐹 𝐶 𝐵 1 𝑑 ).ℓ.cos 𝜃 1 + 𝑇 𝑦 𝐵1 .ℓ.sin 𝜃 1 + 𝐶 𝑠 [2( 𝜋 2 − 𝜃 1 )+( 𝜋 2 +
    𝜃 2 )]=0 ( 𝑇 𝑥 𝐵2 + 1 2 . 𝐹 𝐶 𝐵 2 𝑑 ).ℓ.cos 𝜃 2 + 𝑇 𝑦 𝐵2 .ℓ.sin 𝜃 2 − 𝐶 𝑠 [2(
    𝜋 2 + 𝜃 2 )+( 𝜋 2 − 𝜃 1 )]=0 Replacing 𝑇 𝑥 𝐵1 , 𝑇 𝑦 𝐵1 , 𝑇 𝑥 𝐵2 , and 𝑇 𝑦 𝐵2 in
    the last two equations yields 𝑇 𝑥 𝐵1 = 𝐹 𝑏𝑢𝑜𝑦 𝑑 + 𝑇 1 𝑇 𝑦 𝐵1 =− 𝑊 𝑏𝑢𝑜𝑦 𝑇 𝑥 𝐵2
    =− 𝐹 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 𝑑 − 𝐹 𝐶 𝐵 1 𝑑 − 𝐹 𝐶 𝐵 2 𝑑 − 𝐹 𝑏𝑢𝑜𝑦 𝑑 − 𝑇 1 𝑇 𝑦 𝐵2 =− 𝑊 𝑏𝑢𝑜𝑦 𝑇 2 =2.
    𝐹 𝑏𝑢𝑜𝑦 𝑑 + 𝐹 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 𝑑 ( 𝐹 𝑏𝑢𝑜𝑦 𝑑 + 𝑇 1 + 1 2 . 𝐹 𝐶 𝐵 1 𝑑 ).ℓ.cos 𝜃 1 − 𝑊 𝑏𝑢𝑜𝑦
    .ℓ.sin 𝜃 1 =− 𝐶 𝑠 [2( 𝜋 2 − 𝜃 1 )+( 𝜋 2 + 𝜃 2 )] −( 𝐹 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 𝑑 + 𝐹 𝑏𝑢𝑜𝑦 𝑑 + 𝑇
    1 + 𝐹 𝐶 𝐵 1 𝑑 + 1 2 . 𝐹 𝐶 𝐵 2 𝑑 ).ℓ.cos 𝜃 2 − 𝑊 𝑏𝑢𝑜𝑦 .ℓ.sin 𝜃 2 = 𝐶 𝑠 [2( 𝜋 2
    + 𝜃 2 )+( 𝜋 2 − 𝜃 1 )] References Christ, R.; Wernli, R. The ROV Manual a User
    Guide for Remotely Operated Vehicles, 2nd ed.; Elsevier: Amsterdam, The Netherlands,
    2014. [Google Scholar] Khatib, O.; Yeh, X.; Brantner, G.; Soe, B.; Kim, B.; Ganguly,
    S.; Stuart, H.; Wang, S.; Cutkosky, M.; Edsinger, A.; et al. Ocean one: A robotic
    avatar for oceanic discovery. IEEE Robot. Autom. Mag. 2016, 23, 20–29. [Google
    Scholar] [CrossRef] Destelle, J.J.; Vallée, C. The MEUST infrastructure for neutrino
    astronomy. Nucl. Instrum. Methods Phys. Res. Sect. A Accel. Spectrometers Detect.
    Assoc. Equip. 2013, 725, 227–229. [Google Scholar] [CrossRef] Capocci, R.; Dooly,
    G.; Omerdić, E.; Coleman, J.; Newe, T.; Toal, D. Inspection-Class Remotely Operated
    Vehicles—A Review. J. Mar. Sci. Eng. 2017, 5, 13. [Google Scholar] [CrossRef]
    Ajwad, S.A.; Iqbal, J. Recent Advances and applications of tethered robotic systems.
    Sci. Int. 2014, 26, 2045–2051. [Google Scholar] Tortorici, O.; Anthierens, C.;
    Hugel, V.; Barthelemy, H. Towards active self-management of umbilical linking
    ROV and USV for safer submarine missions. IFAC-PapersOnLine 2019, 52, 265–270.
    [Google Scholar] [CrossRef] McLain, T.W.; Rock, S.M. Experimental Measurement
    of ROV Tether Tension. In Proceedings of the ROV’92, San Diego, CA, USA, 10–12
    June 1992; p. 6. [Google Scholar] Bevilacqua, L.; Kleczka, W.; Kreuzer, E. On
    the Mathematical Modeling of ROV’S. IFAC Proc. Vol. 1991, 24, 51–54. [Google Scholar]
    [CrossRef] Soylu, S.; Buckham, B.J.; Podhorodeski, R.P. Dynamics and control of
    tethered underwater-manipulator systems. In Proceedings of the OCEANS 2010 MTS/IEEE
    SEATTLE, Seattle, WA, USA, 20–23 September 2010; pp. 1–8. [Google Scholar] Fang,
    M.C.; Hou, C.S.; Luo, J.H. On the motions of the underwater remotely operated
    vehicle with the umbilical cable effect. Ocean Eng. 2007, 34, 1275–1289. [Google
    Scholar] [CrossRef] Feng, Z.; Allen, R. Evaluation of the effects of the communication
    cable on the dynamics of an underwater flight vehicle. Ocean Eng. 2004, 31, 1019–1035.
    [Google Scholar] [CrossRef] Gay Neto, A.; de Arruda Martins, C. Structural stability
    of flexible lines in catenary configuration under torsion. Mar. Struct. 2013,
    34, 16–40. [Google Scholar] [CrossRef] Coyne, J. Analysis of the formation and
    elimination of loops in twisted cable. IEEE J. Ocean. Eng. 1990, 15, 72–83. [Google
    Scholar] [CrossRef] Drumond, G.; Pasqualino, I.; Pinheiro, B.; Estefen, S. Pipelines,
    risers and umbilicals failures: A literature review. Ocean Eng. 2018, 148, 412–425.
    [Google Scholar] [CrossRef] Brignone, L.; Raugel, E.; Opderbecke, J.; Rigaud,
    V.; Piasco, R.; Ragot, S. First sea trials of HROV the new hybrid vehicle developed
    by IFREMER. In Proceedings of the OCEANS 2015—Genova, Genova, Italy, 18–21 May
    2015; pp. 1–7. [Google Scholar] Viel, C. Self-management of the umbilical of a
    ROV for underwater exploration. Ocean Eng. 2022, 248, 110695. [Google Scholar]
    [CrossRef] Frank, J.E.; Geiger, R.; Kraige, D.R.; Murali, A. Smart Tether System
    for Underwater Navigation and Cable Shape Measurement. U.S. Patent US8437979B2,
    7 May 2013. [Google Scholar] Duncan, R.G.; Froggatt, M.E.; Kreger, S.T.; Seeley,
    R.J.; Gifford, D.K.; Sang, A.K.; Wolfe, M.S. High-accuracy fiber-optic shape sensing.
    In Proceedings of the SPIE Smart Structures and Materials + Nondestructive Evaluation
    and Health Monitoring, San Diego, CA, USA, 18–22 March; p. 65301S. Xu, C.; Chen,
    J.; Yan, D.; Ji, J. Review of Underwater Cable Shape Detection. J. Atmos. Ocean.
    Technol. 2016, 33, 597–606. [Google Scholar] [CrossRef] Xu, C.; Wan, K.; Chen,
    J.; Yao, C.; Yan, D.; Ji, J.; Wang, C. Underwater cable shape detection using
    ShapeTape. In Proceedings of the OCEANS 2016 MTS/IEEE Monterey, Monterey, CA,
    USA, 19–23 September 2016; pp. 1–4. [Google Scholar] Banerjee, A.K.; Do, V.N.
    Deployment control of a cable connecting a ship to an underwater vehicle. J. Guid.
    Control. Dyn. 1994, 17, 1327–1332. [Google Scholar] [CrossRef] Zhao, C.; Thies,
    P.R.; Johanning, L. Investigating the winch performance in an ASV/ROV autonomous
    inspection system. Appl. Ocean Res. 2021, 115, 102827. [Google Scholar] [CrossRef]
    Raugel, E.; Opderbecke, J.; Fabri, M.; Brignone, L.; Rigaud, V. Operational and
    scientific capabilities of Ariane, Ifremer’s hybrid ROV. In Proceedings of the
    OCEANS 2019—Marseille, Marseille, France, 17–20 June 2019. [Google Scholar] Zhou,
    H.; Cao, J.; Yao, B.; Lian, L. Hierarchical NMPC–ISMC of active heave motion compensation
    system for TMS–ROV recovery. Ocean Eng. 2021, 239, 109834. [Google Scholar] [CrossRef]
    Lubis, M.B.; Kimiaei, M.; Efthymiou, M. Alternative configurations to optimize
    tension in the umbilical of a work class ROV performing ultra-deep-water operation.
    Ocean Eng. 2021, 225, 108786. [Google Scholar] [CrossRef] Laranjeira, M.; Dune,
    C.; Hugel, V. Catenary-based visual servoing for tether shape control between
    underwater vehicles. Ocean Eng. 2020, 200, 107018. [Google Scholar] [CrossRef]
    Tortorici, O.; Anthierens, C.; Hugel, V. A new flex-sensor-based umbilical-length
    management system for underwater robots. In Proceedings of the European Conference
    on Mobile Robotics, Coimbra, Portugal, 4–7 September 2023. [Google Scholar] Disclaimer/Publisher’s
    Note: The statements, opinions and data contained in all publications are solely
    those of the individual author(s) and contributor(s) and not of MDPI and/or the
    editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to
    people or property resulting from any ideas, methods, instructions or products
    referred to in the content.  © 2024 by the authors. Licensee MDPI, Basel, Switzerland.
    This article is an open access article distributed under the terms and conditions
    of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/).
    Share and Cite MDPI and ACS Style Tortorici, O.; Péraud, C.; Anthierens, C.; Hugel,
    V. Automated Deployment of an Underwater Tether Equipped with a Compliant Buoy–Ballast
    System for Remotely Operated Vehicle Intervention. J. Mar. Sci. Eng. 2024, 12,
    279. https://doi.org/10.3390/jmse12020279 AMA Style Tortorici O, Péraud C, Anthierens
    C, Hugel V. Automated Deployment of an Underwater Tether Equipped with a Compliant
    Buoy–Ballast System for Remotely Operated Vehicle Intervention. Journal of Marine
    Science and Engineering. 2024; 12(2):279. https://doi.org/10.3390/jmse12020279
    Chicago/Turabian Style Tortorici, Ornella, Charly Péraud, Cédric Anthierens, and
    Vincent Hugel. 2024. \"Automated Deployment of an Underwater Tether Equipped with
    a Compliant Buoy–Ballast System for Remotely Operated Vehicle Intervention\" Journal
    of Marine Science and Engineering 12, no. 2: 279. https://doi.org/10.3390/jmse12020279
    Note that from the first issue of 2016, this journal uses article numbers instead
    of page numbers. See further details here. Article Metrics Citations No citations
    were found for this article, but you may check on Google Scholar Article Access
    Statistics Article access statistics Article Views 3. Feb 8. Feb 13. Feb 18. Feb
    23. Feb 28. Feb 4. Mar 9. Mar 14. Mar 19. Mar 24. Mar 29. Mar 3. Apr 0 1000 250
    500 750 For more information on the journal statistics, click here. Multiple requests
    from the same IP address are counted as one view.   J. Mar. Sci. Eng., EISSN 2077-1312,
    Published by MDPI RSS Content Alert Further Information Article Processing Charges
    Pay an Invoice Open Access Policy Contact MDPI Jobs at MDPI Guidelines For Authors
    For Reviewers For Editors For Librarians For Publishers For Societies For Conference
    Organizers MDPI Initiatives Sciforum MDPI Books Preprints.org Scilit SciProfiles
    Encyclopedia JAMS Proceedings Series Follow MDPI LinkedIn Facebook Twitter Subscribe
    to receive issue release notifications and newsletters from MDPI journals Select
    options Subscribe © 1996-2024 MDPI (Basel, Switzerland) unless otherwise stated
    Disclaimer Terms and Conditions Privacy Policy"'
  inline_citation: '>'
  journal: Journal of Marine Science and Engineering
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Automated Deployment of an Underwater Tether Equipped with a Compliant Buoy–Ballast
    System for Remotely Operated Vehicle Intervention
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Guo S.
  - Gallego G.
  citation_count: '0'
  description: 'Event cameras are bio-inspired visual sensors that capture pixel-wise
    intensity changes and output asynchronous event streams. They show great potential
    over conventional cameras to handle challenging scenarios in robotics and computer
    vision, such as high-speed and high dynamic range. This paper considers the problem
    of rotational motion estimation using event cameras. Several event-based rotation
    estimation methods have been developed in the past decade, but their performance
    has not been evaluated and compared under unified criteria yet. In addition, these
    prior works do not consider a global refinement step. To this end, we conduct
    a systematic study of this problem with two objectives in mind: summarizing previous
    works and presenting our own solution. First, we compare prior works both theoretically
    and experimentally. Second, we propose the first event-based rotation-only bundle
    adjustment (BA) approach. We formulate it leveraging the state-of-the-art Contrast
    Maximization (CMax) framework, which is principled and avoids the need to convert
    events into frames. Third, we use the proposed BA to build CMax-SLAM, the first
    event-based rotation-only SLAM system comprising a front-end and a back-end. Our
    BA is able to run both offline (trajectory smoothing) and online (CMax-SLAM back-end).
    To demonstrate the performance and versatility of our method, we present comprehensive
    experiments on synthetic and real-world datasets, including indoor, outdoor and
    space scenarios. We discuss the pitfalls of real-world evaluation and propose
    a proxy for the reprojection error as the figure&#x00A0;of merit to evaluate event-based
    rotation BA methods. We release the source code and novel data sequences to benefit
    the community. We hope this work leads to a better understanding and fosters further
    research on event-based ego-motion estimation.'
  doi: 10.1109/TRO.2024.3378443
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Journals & Magazines >IEEE Transactions on Robotics
    >Early Access CMax-SLAM: Event-based Rotational-Motion Bundle Adjustment and SLAM
    System using Contrast Maximization Publisher: IEEE Cite This PDF Shuang Guo; Guillermo
    Gallego All Authors 32 Full Text Views Abstract Authors Keywords Metrics Media
    Abstract: Event cameras are bio-inspired visual sensors that capture pixel-wise
    intensity changes and output asynchronous event streams. They show great potential
    over conventional cameras to handle challenging scenarios in robotics and computer
    vision, such as high-speed and high dynamic range. This paper considers the problem
    of rotational motion estimation using event cameras. Several event-based rotation
    estimation methods have been developed in the past decade, but their performance
    has not been evaluated and compared under unified criteria yet. In addition, these
    prior works do not consider a global refinement step. To this end, we conduct
    a systematic study of this problem with two objectives in mind: summarizing previous
    works and presenting our own solution. First, we compare prior works both theoretically
    and experimentally. Second, we propose the first event-based rotation-only bundle
    adjustment (BA) approach. We formulate it leveraging the state-of-the-art Contrast
    Maximization (CMax) framework, which is principled and avoids the need to convert
    events into frames. Third, we use the proposed BA to build CMax-SLAM, the first
    event-based rotation-only SLAM system comprising a front-end and a back-end. Our
    BA is able to run both offline (trajectory smoothing) and online (CMax-SLAM back-end).
    To demonstrate the performance and versatility of our method, we present comprehensive
    experiments on synthetic and real-world datasets, including indoor, outdoor and
    space scenarios. We discuss the pitfalls of real-world evaluation and propose
    a proxy for the reprojection error as the figure of merit to evaluate event-based
    rotation BA methods. We release the source code and novel data sequences to benefit
    the community. We hope this work leads to a better understanding and fosters further
    research on event-based ego-motion estimation. Published in: IEEE Transactions
    on Robotics ( Early Access ) Page(s): 1 - 20 Date of Publication: 18 March 2024
    ISSN Information: DOI: 10.1109/TRO.2024.3378443 Publisher: IEEE Authors Keywords
    Metrics Media More Like This Simultaneous localization and mapping of a mobile
    robot with surveillance and flying cameras 2018 SICE International Symposium on
    Control Systems (SICE ISCS) Published: 2018 Real-Time Robot Trajectory Estimation
    and 3D Map Construction using 3D Camera 2006 IEEE/RSJ International Conference
    on Intelligent Robots and Systems Published: 2006 Show More IEEE Personal Account
    CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS
    Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL
    INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT
    & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms
    of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy
    Policy A not-for-profit organization, IEEE is the world''s largest technical professional
    organization dedicated to advancing technology for the benefit of humanity. ©
    Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: IEEE Transactions on Robotics
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'CMax-SLAM: Event-based Rotational-Motion Bundle Adjustment and SLAM System
    using Contrast Maximization'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Sfaxi H.
  - Lahyani I.
  - Yangui S.
  - Torjmen M.
  citation_count: '0'
  description: Smart IoT devices and applications in smart cities exchange important
    real-time information with their environment. However, a subset of these systems
    may face limitations in analyzing and processing the required large amounts of
    data to meet ultra-low-latency criteria. This limitation could be attributed to
    factors such as constrained CPU and battery resources. Thanks to the 5G and edge
    computing capabilities, a viable solution involves migrating a subset of these
    latency-sensitive and computationally intensive tasks to edge nodes and servers.
    This strategic service placement ensures a safe continuity of the application.
    In this paper, autonomous cars operating in smart cities, engaging in continuous
    data exchange with their external environment to meet real-time and latency-sensitive
    requirements, serve as an illustrative example of smart applications. The car&#x2019;s
    decision service is strategically placed on edge nodes through a proactive (re)placement
    approach designed for dynamic and mobile environments. This approach uses a quality
    of service (QoS) metric prediction degradation module, which leverages Exponential
    smoothing methods to identify a suitable edge node for hosting the car&#x2019;s
    decision module, with latency as a key criterion. Multiple configurations for
    outlier detection techniques are evaluated. A proof-of-concept validates the chosen
    model by comparing it to the AutoRegressive Integrated Moving Average (ARIMA)
    and the proposed proactive service (re)placement approach. This approach ensures
    the continuity of the placed module, suggesting the feasibility of locating non-critical
    modules on edge nodes.
  doi: 10.1109/TNSM.2024.3375970
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Journals & Magazines >IEEE Transactions on Network ...
    >Early Access Latency-Aware and Proactive Service Placement for Edge Computing
    Publisher: IEEE Cite This PDF Henda Sfaxi; Imene Lahyani; Sami Yangui; Mouna Torjmen
    All Authors 81 Full Text Views Open Access Under a Creative Commons License Abstract
    Authors Keywords Metrics Abstract: Smart IoT devices and applications in smart
    cities exchange important real-time information with their environment. However,
    a subset of these systems may face limitations in analyzing and processing the
    required large amounts of data to meet ultra-low-latency criteria. This limitation
    could be attributed to factors such as constrained CPU and battery resources.
    Thanks to the 5G and edge computing capabilities, a viable solution involves migrating
    a subset of these latency-sensitive and computationally intensive tasks to edge
    nodes and servers. This strategic service placement ensures a safe continuity
    of the application. In this paper, autonomous cars operating in smart cities,
    engaging in continuous data exchange with their external environment to meet real-time
    and latency-sensitive requirements, serve as an illustrative example of smart
    applications. The car’s decision service is strategically placed on edge nodes
    through a proactive (re)placement approach designed for dynamic and mobile environments.
    This approach uses a quality of service (QoS) metric prediction degradation module,
    which leverages Exponential smoothing methods to identify a suitable edge node
    for hosting the car’s decision module, with latency as a key criterion. Multiple
    configurations for outlier detection techniques are evaluated. A proof-of-concept
    validates the chosen model by comparing it to the AutoRegressive Integrated Moving
    Average (ARIMA) and the proposed proactive service (re)placement approach. This
    approach ensures the continuity of the placed module, suggesting the feasibility
    of locating non-critical modules on edge nodes. Published in: IEEE Transactions
    on Network and Service Management ( Early Access ) Page(s): 1 - 1 Date of Publication:
    11 March 2024 ISSN Information: DOI: 10.1109/TNSM.2024.3375970 Publisher: IEEE
    Authors Keywords Metrics More Like This An Edge Computing Matching Framework With
    Guaranteed Quality of Service IEEE Transactions on Cloud Computing Published:
    2022 Statistical quality of service provisioning over edge computing mobile wireless
    networks MILCOM 2017 - 2017 IEEE Military Communications Conference (MILCOM) Published:
    2017 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details
    PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES
    PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678
    4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact
    Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics
    Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE
    is the world''s largest technical professional organization dedicated to advancing
    technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: IEEE Transactions on Network and Service Management
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Latency-Aware and Proactive Service Placement for Edge Computing
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Xiang M.
  - Chai H.
  - Wu X.
  - Tang M.
  - Fan H.
  - Zhang Y.
  - Yang Z.
  citation_count: '0'
  description: During high dynamic gravity measurements conducted on unmanned surface
    vehicle, the presence of low-frequency noise caused by the vertical and horizontal
    motion disturbances of the carrier in conjunction with the low-frequency excitation
    noise from the sensor, results in a direct mixture within the frequency band of
    the gravity signal. Admittedly, conventional filtering techniques such as finite
    impulse response (FIR) or infinite impulse response (IIR) filtering prove insufficient
    in eliminating the measurement noise, ultimately leading to a decrease in gravity
    measurement accuracy.In this regard, this paper proposes the use of the kalman
    smoothing method as a replacement for the traditional frequency domain low-pass
    filtering technique. This method allows for the identification of gravity anomaly
    information even in the presence of noise by employing optimal estimation methods.Given
    that the gravity measurement data is processed offline, this paper further utilizes
    the optimal fixed interval smoothing algorithm to process the gravity measurement
    data obtained from unmanned surface vehicle. This algorithm enhances the accuracy
    beyond what is achievable with traditional frequency domain low-pass filtering
    techniques. To validate the effectiveness of our proposed algorithm, we have conducted
    processing on real sea test data, confirming its efficacy.
  doi: 10.1117/12.3021099
  full_citation: '>'
  full_text: '>

    "This website uses cookies to provide you with a variety of services and to improve
    the usability of our website. By using the website, you agree to the use of cookies
    in accordance with our Privacy Policy. Close Sign In View Cart Help    CONFERENCE
    PROCEEDINGS PAPERS PRESENTATIONS JOURNALS EBOOKS ADVANCED SEARCH > Home > Proceedings
    > Volume 12980 > Article 19 January 2024 Data processing method of high dynamic
    gravity measurement for unmanned surface vehicle at sea Minzhi Xiang, Hongzhou
    Chai, Xingtao Wu, Minqiang Tang, Haopeng Fan, Yong Zhang, Zhen Yang Author Affiliations
    +      Proceedings Volume 12980, Fifth International Conference on Geoscience
    and Remote Sensing Mapping (ICGRSM 2023); 129801T (2024) https://doi.org/10.1117/12.3021099
    Event: Fifth International Conference on Geoscience and Remote Sensing Mapping
    (ICGRSM 2023), 2023, Lianyungang, China ARTICLE FIGURES & TABLES REFERENCES CITED
    BY     Abstract During high dynamic gravity measurements conducted on unmanned
    surface vehicle, the presence of low-frequency noise caused by the vertical and
    horizontal motion disturbances of the carrier in conjunction with the low-frequency
    excitation noise from the sensor, results in a direct mixture within the frequency
    band of the gravity signal. Admittedly, conventional filtering techniques such
    as finite impulse response (FIR) or infinite impulse response (IIR) filtering
    prove insufficient in eliminating the measurement noise, ultimately leading to
    a decrease in gravity measurement accuracy.In this regard, this paper proposes
    the use of the kalman smoothing method as a replacement for the traditional frequency
    domain low-pass filtering technique. This method allows for the identification
    of gravity anomaly information even in the presence of noise by employing optimal
    estimation methods.Given that the gravity measurement data is processed offline,
    this paper further utilizes the optimal fixed interval smoothing algorithm to
    process the gravity measurement data obtained from unmanned surface vehicle. This
    algorithm enhances the accuracy beyond what is achievable with traditional frequency
    domain low-pass filtering techniques. To validate the effectiveness of our proposed
    algorithm, we have conducted processing on real sea test data, confirming its
    efficacy. (2024) Published by SPIE. Downloading of the abstract is permitted for
    personal use only. Citation Download Citation Minzhi Xiang, Hongzhou Chai, Xingtao
    Wu, Minqiang Tang, Haopeng Fan, Yong Zhang, and Zhen Yang \"Data processing method
    of high dynamic gravity measurement for unmanned surface vehicle at sea\", Proc.
    SPIE 12980, Fifth International Conference on Geoscience and Remote Sensing Mapping
    (ICGRSM 2023), 129801T (19 January 2024); https://doi.org/10.1117/12.3021099 ACCESS
    THE FULL ARTICLE ORGANIZATIONAL Sign in with credentials provided by your organization.
    Organizational Username Organizational Password INSTITUTIONAL Select your institution
    to access the SPIE Digital Library. SELECT YOUR INSTITUTION PERSONAL Sign in with
    your SPIE account to access your personal subscriptions or to use specific features
    such as save to my library, sign up for alerts, save searches, etc. PERSONAL SIGN
    IN No SPIE Account? Create one PURCHASE THIS CONTENT SUBSCRIBE TO DIGITAL LIBRARY
    50 downloads per 1-year subscription Members: $195 Non-members: $335 ADD TO CART
    25 downloads per 1 - year subscription Members: $145 Non-members: $250 ADD TO
    CART PURCHASE SINGLE ARTICLE Includes PDF, HTML & Video, when available Members:
    $17.00 Non-members: $21.00 ADD TO CART PROCEEDINGS 9 PAGES DOWNLOAD PAPER SAVE
    TO MY LIBRARY GET CITATION Advertisement Advertisement RIGHTS & PERMISSIONS Get
    copyright permission  Subscribe to Digital Library Receive Erratum Email Alert
    Access provided by Univ. of Nebraska-Lincoln Site Map Home Conference Papers Conference
    Presentations Journals eBooks About Subscriptions Information for Authors Proceedings
    Authors Journal Authors eBook Authors Information for Reviewers Reviewer Guidelines
    Reviewer Training Program Information for Librarians Resources Subscriptions Contact
    & Support TECHNICAL SUPPORT spiedlsupport@spie.org CUSTOMER SERVICE +1 360 676
    3290 Hours: 8:00 am to 5:00 pm PST Help Center | Contact Us Connect SPIE Privacy
    Policy | Terms of Use © 2024 SPIE"'
  inline_citation: '>'
  journal: Proceedings of SPIE - The International Society for Optical Engineering
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Data processing method of high dynamic gravity measurement for unmanned surface
    vehicle at sea
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Zhang X.
  - Li D.
  - Cheng Z.
  - Zhu J.
  - Tao Z.
  - Qiu L.
  citation_count: '0'
  description: In modern technologies, such as digital twin, it is essential to make
    real-time estimations of unknown time-varying boundary conditions from sensor
    measured data in given thermal systems, which leads to inverse heat transfer problems
    (IHTPs). However, due to the complexity of IHTPs, it’s quite challenging to obtain
    a stabilized solution for online estimation with affordable computational cost.
    In this work, a rapid yet robust inversion algorithm called ANN-based extended
    Kalman smoothing algorithm is developed to realize the online estimation of unknown
    time-varying boundary conditions. Under the state-space representation of the
    extended Kalman smoothing algorithm, pre-trained fast ANN structures are deployed
    to replace the conventional CFD-based state transfer models, from which the computational
    process can be further accelerated by reducing the dimension of state variables.
    Two-dimensional tube convective heat transfer problem was employed as the case
    study to test the algorithm. The results show that the proposed algorithm is indeed
    a computational-light and anti-interference approach for solving IHTPs. The proposed
    algorithm can achieve estimation of unknown boundary conditions with a dimensionless
    average error of 0.0580 under noisy temperature measurement with a standard deviation
    of 10 K and its computational cost is reduced drastically compared with conventional
    approach from 12.23 s per time step to 3.506 ms.
  doi: 10.1007/978-3-031-44947-5_17
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Log in Find a journal
    Publish with us Track your research Search Cart Home Computational and Experimental
    Simulations in Engineering Conference paper Rapid Online Estimation of Time-Varying
    Thermal Boundary Conditions in Convective Heat Transfer Problem by ANN-Based Extended
    Kalman Smoothing Algorithm Conference paper First Online: 25 January 2024 pp 203–218
    Cite this conference paper Access provided by University of Nebraska-Lincoln Download
    book PDF Download book EPUB Computational and Experimental Simulations in Engineering
    (ICCES 2023) Xinxin Zhang, Dike Li, Zeyuan Cheng, Jianqin Zhu, Zhi Tao & Lu Qiu  Part
    of the book series: Mechanisms and Machine Science ((Mechan. Machine Science,volume
    146)) Included in the following conference series: International Conference on
    Computational & Experimental Engineering and Sciences 215 Accesses Abstract In
    modern technologies, such as digital twin, it is essential to make real-time estimations
    of unknown time-varying boundary conditions from sensor measured data in given
    thermal systems, which leads to inverse heat transfer problems (IHTPs). However,
    due to the complexity of IHTPs, it’s quite challenging to obtain a stabilized
    solution for online estimation with affordable computational cost. In this work,
    a rapid yet robust inversion algorithm called ANN-based extended Kalman smoothing
    algorithm is developed to realize the online estimation of unknown time-varying
    boundary conditions. Under the state-space representation of the extended Kalman
    smoothing algorithm, pre-trained fast ANN structures are deployed to replace the
    conventional CFD-based state transfer models, from which the computational process
    can be further accelerated by reducing the dimension of state variables. Two-dimensional
    tube convective heat transfer problem was employed as the case study to test the
    algorithm. The results show that the proposed algorithm is indeed a computational-light
    and anti-interference approach for solving IHTPs. The proposed algorithm can achieve
    estimation of unknown boundary conditions with a dimensionless average error of
    0.0580 under noisy temperature measurement with a standard deviation of 10 K and
    its computational cost is reduced drastically compared with conventional approach
    from 12.23 s per time step to 3.506 ms. Keywords Digital twin Artificial neural
    network Inverse problem Kalman filter Near real-time estimation Access provided
    by University of Nebraska-Lincoln. Download conference paper PDF Similar content
    being viewed by others Smoothing by cubic spline modified applied to solve inverse
    thermal problem Article 24 October 2016 Solution of inverse heat conduction problem
    using the Tikhonov regularization method Article 18 January 2017 Estimation of
    Time-Varying Heat Flux for One-Dimensional Heat Conduction Problem by Hybrid Inverse
    Method Chapter © 2020 1 Introduction In many transient convective heat transfer
    problems, the unknown time-varying thermal boundary conditions (BCs) are difficult
    to be measured directly [1], yet whose online estimation is essential for improving
    the stability and performance of the thermal system in various engineering applications,
    such as aerospace thermal protection [2], chip cooling [3], metallurgical reactors
    [4, 5] and food engineering [6]. The inverse heat transfer problems (IHTPS) have
    been developed to estimate the unknown time-varying boundary conditions from the
    interior temperature fields. With the aid of the IHTP algorithm, it is possible
    to reconstruct the full temperature field as well as the thermal boundary condition
    from the online data measured by temperature sensors installed somewhere in the
    fluid domain. The technology is also known as digital twin. However, the traditional
    methods to solve IHTPs faces the following challenges and drawbacks. Firstly,
    it is difficult to obtain relatively stable and accurate solutions under noisy
    input data due to the inherent ill-posedness of IHTPs [7], which means it is difficult
    to obtain relatively stable and accurate solutions under noisy input data. Secondly,
    it is difficult to invert the unknown heat flux from delayed sensor measurements
    since the thermal disturbance decays at the downstream due to the diffusive nature
    of heat transfer. Thirdly, the traditional algorithm to solve IHTPs is a computation-intensive
    and time-consuming process [8], which is difficult to be applied to online estimations.
    The solutions for estimating time-varying BCs can be divided into two categories,
    namely, the whole domain algorithm and the sequential algorithm. The whole domain
    algorithm, by definition, is an offline method to calculate the unknown boundary
    conditions when all the time measurements in full time period are available. The
    algorithm transforms the IHTPs to an optimization problem, iteratively calculating
    the forward heat transfer process to minimize the error between the assumed and
    exact value of the unknown BCs by traditional optimization algorithms like Levenberg–Marquardt
    Method [9] or heuristic algorithms like repulsive particle swarm algorithm [10],
    ant colony optimization, and cuckoo search algorithm [11]. The sequential algorithms,
    on the other hand, work in the online mode. With continuously measured instantaneous
    temperature, the real-time or near real-time estimation of the unknown BCs can
    be achieved. Many sequential inversion methods have been brought up, including
    the sequential function specification method (SFSM) [12], dynamic matrix control
    method [13], multiple model adaptive inverse (MMAI) method [14], artificial neural
    network (ANN) algorithm [8, 15, 16], and digital filter (DF) approach [2, 4, 17,18,19,20,21,22,23],
    etc. Beck [12] firstly introduced the concept of future measurement into IHTPs,
    which tackles the sensing delay issues to ensure a stabilized solution without
    time-lag or distortion. In order to reduce the interference caused by the noises,
    the digital filtering approach [2, 4, 17,18,19,20,21,22,23] are employed. Owing
    to its statistical trade-off between the sensor measurement and model prediction
    towards a smoothed result, the Kalman filtering approach is relatively more robust
    under noisy input data, which serves as a valuable tool for tackling the ill-posed
    problem [7]. Scarpa and Milano [24] employed the Kalman filtering (KF) technique
    to solve a linear one-dimensional heat conduction problem, which shows the anti-interference
    ability of KF algorithms. The algorithm could be coupled with Rauch-Tung-Strieber
    (RTS) smoothing, which utilizes future time measurement to reduce the time lag
    in the prediction results. Although standard KF technique can be used to tackle
    liner IHTPs efficiently, it does not show pleasant for nonlinear IHTPs. Therefore,
    the extended version of Kalman filtering (EKF) technique [25], unscented Kalman
    smoothing algorithm [26], and other KF related methods [4, 17, 18, 21] are developed
    to deal with nonlinear IHTPs. Although the KF-related algorithms work well under
    noisy environment, but all of them share a common drawback, which is the prohibitively
    high computational cost caused by repetitive CFD forward calculations required
    in the sensitivity analysis. Other algorithm, such as the artificial neural network
    (ANN) algorithm, with its powerful mapping ability [27] and high computational
    efficiency, may help to reduce computational cost. For instance, Najafi et al.
    [15, 16] utilized ANN models to directly correlate unknown BCs with sensor-measured
    temperatures, while Huang et al. [8] utilized well-trained ANN structures as the
    rapid forward solver, coupled with inverse algorithm, indirectly realizing the
    online estimation of unknown BCs. Both works demonstrate that the ANN algorithm
    could accelerate the computation of IHTPs with satisfactory accuracy. However,
    the major drawbacks of ANN algorithm are that, the training of ANN requires vast
    amount of dataset under high representation load, and it tends to overfitting
    when the sensor measurements are contaminated with noises. To summarize, the KF-related
    approach is a robust method when measurement noise is non-negligible, but its
    high computational cost limits its applications towards online estimation task.
    The ANN models, on the other hand, as the universal approximators, could be employed
    to improve the computational efficiency of KF-related algorithm. Thus, in this
    work, we try to combine the extended Kalman smoothing algorithm and ANN algorithm
    to establish a rapid yet robust solution to IHTPs. Moreover, to reduce the redundant
    calculation of sensitivity analyzes requires in the traditional EKF approach,
    we developed a reduced form of EKF state vector with the aid of ANN model to further
    improve the computational efficiency. A two-dimensional convective heat transfer
    problem is selected as the case study for the implementation and evaluation of
    the proposed algorithm. 2 Inversion Procedure by Extended Kalman Smoothing 2.1
    The Benchmark Problem The case study is showed in Fig. 1, which describes a convective
    heat transfer problem on a two- dimensional rectangular region. A sensor is placed
    in the field, providing us with real-time temperature measurement while a time-varying
    heat flux, as the unknown BCs, is applied on the upper boundary. The main objective
    of our proposed algorithm is to estimate this unknown BCs in online mode by utilizing
    the continuously measured sensor temperatures. Fig. 1 The schematic of a 2D heat
    convection inverse problem Full size image The lower boundary is considered to
    be adiabatic. On the left boundary, fully developed air with an initial temperature
    \\(T_{in} = 300\\,{\\text{K}}\\) and an average inlet velocity \\(u_{m} = 0.033\\,{\\text{m/s}}\\)
    passes through the region. The default sensor location is (0.820, 0.089) and other
    detailed parameters are showed in Table 1. Table 1 Detailed parameters for the
    numerical example Full size table Then, we give the governing equation for the
    above problem, $$\\rho C_{p} \\frac{{\\partial T\\left( {X,Y,t} \\right)}}{\\partial
    t} + \\rho C_{p} u\\left( Y \\right)\\frac{{\\partial T\\left( {X,Y,t} \\right)}}{\\partial
    X} = k_{c} \\frac{{\\partial^{2} T(X,Y,t)}}{{\\partial Y^{2} }}$$ (1) where the
    boundary conditions and initial conditions are $$k_{c} \\frac{\\partial T(X,Y
    = h,t)}{{\\partial Y}} = q(t)$$ (2) $$k_{c} \\frac{\\partial T(X,Y = 0,t)}{{\\partial
    Y}} = 0$$ (3) $$u(X = 0,Y,t) = u(Y) = 6u\\left[ {\\frac{Y}{h}\\left( {1 - \\frac{Y}{h}}
    \\right)} \\right]$$ (4) $$T(0,Y,t) = T_{in}$$ (5) 2.2 Extended Kalman Filtering
    In this work, the IHTPs is solved by the ANN-based extended Kalman smoothing algorithm
    (ANN-EKS) which compose of two main parts, ANN-based forward solver and extended
    Kalman smoothing algorithm. The entire procedure is summarized as Fig. 2. The
    extended Kalman smoothing algorithm gives estimation of the unknown boundary conditions
    step by step and is accelerated based on the fast prediction of local temperature
    field and sensitivity analysis made by ANN-based forward solver. Fig. 2 The procedure
    of estimating time-varying heat flux at t = k by the proposed algorithm Full size
    image The extended Kalman smoothing algorithm can be further separated into two
    sections, namely, the extended Kalman filtering (EKF) algorithm and the Rauch-Tung-Strieber
    (RTS) smoothing algorithm. The RTS smoothing algorithm enables the EKF algorithm
    to include future measurement into the estimation of unknown heat flux, which
    can address the sensing delay issue of IHTPs. As aforementioned, the IHTPs is
    ill-posed by nature [7], which means small disturbance of the input data may cause
    large error in the output result. To solve this challenge, the extended Kalman
    filtering algorithm is employed, which uses the state-space representation to
    describe this two-dimensional convective heat transfer process and statistically
    quantifies the model error and the measuring noises. The algorithm compromises
    between the original prediction and the noisy measurements so that a more precise
    estimation could be made. At first, the benchmark problem needs to be described
    under the state-space representation, whose nonlinear forms are respectively showed
    in Eqs. (6) and (7), $$x_{k + 1} = \\Gamma \\left( {x_{k} ,z_{k} } \\right) +
    \\omega_{k + 1}$$ (6) $$y_{k + 1} = {\\rm H}\\left( {x_{k + 1} } \\right) + \\upsilon_{k
    + 1}$$ (7) where x is the state vector of the system describing its current state,
    y is the measurement vector, and \\(z_{k}\\) is the input of the system. The nonlinear
    operator \\(\\Gamma\\) describes the dynamics of the system over time. and the
    nonlinear measurement operator \\({\\text{H}}\\) maps the state vector to the
    measurement vector. The \\(\\omega\\) and are \\(\\nu\\) respectively the state
    transfer model error and measurement noise, which are assumed to be independent
    zero-mean Gaussian noises with covariance matrix \\(Q\\) and \\(R\\). In order
    to apply the EKF algorithm for solving IHTPs, proper state variables need to be
    selected to fully describe the state of given thermal system. In literature [24,25,26],
    state vector \\(x_{k}^{*}\\) in the following form was employed, $$x_{k}^{*} =
    [T_{k}^{1} \\, T_{k}^{2} \\ldots T_{k}^{i} \\ldots T_{k}^{N} \\, q_{k} ]^{T}$$
    (8) where \\(T_{k}^{i} (i = 1,2,\\ldots ,N)\\) is the temperature of node \\(i\\)
    at time \\(k\\), and \\(N\\) is the amount of mesh nodes used in the numerical
    computation of the benchmark problem, representing the temperature field in the
    discretized form. It is noteworthy that, the unknown boundary heat flux \\(q_{k}\\),
    which was predicted and corrected with the EKF approach in each time step, was
    augmented into the state vectors in order to estimate the unknown heat flux. In
    IHTPs, the measurement vector \\(y\\) is the sensor-measured temperature and the
    nonlinear measurement operator \\({\\text{H}}\\) is then reduced to a linear matrix
    \\(H\\) showed as follows, $$H = \\left[ {\\begin{array}{*{20}c} 0 & 0 & \\ldots
    & {\\underbrace {1}_{{i = n_{s} }}} & \\ldots & 0 \\\\ \\end{array} } \\right]_{1,N
    + 1}$$ (9) where the node index \\(n_{s}\\) corresponds to the sensor location
    in the temperature field. The EKF approach estimates the next-time-step unknown
    boundary heat flux in two phases, the prediction phase and the correction phase.
    In the prediction phrase, the EKF approach predict the unknown state vector as
    well as its probability distribution for the next-time step, which are realized
    by updating the means and covariance matrix of state vector \\(x_{k + 1}^{*}\\)
    based on the current \\(x_{k}^{*}\\) and the following state space model, $$x_{k
    + 1}^{*} = \\Gamma \\left( {x_{k}^{*} } \\right) + \\omega_{k + 1}$$ (10) $$y_{k
    + 1} = Hx_{k + 1}^{*} + \\upsilon_{k + 1}$$ (11) To calculate the means and covariance
    matrix of \\(x_{k + 1}^{*}\\), the EKF approach further linearize this problem
    by approximating \\(\\Gamma (x_{k}^{*})\\) with first-order Taylor expansion at
    \\(\\tilde{x}_{k}^{*}\\), $$\\Gamma \\left( {x_{k}^{*} } \\right) = \\Gamma \\left(
    {\\tilde{x}_{k}^{*} } \\right) + \\left. {\\frac{\\partial \\Gamma }{{\\partial
    x_{k}^{*} }}} \\right|_{{x_{k}^{*} = \\tilde{x}_{k}^{*} }} \\left( {x_{k}^{*}
    - \\tilde{x}_{k} } \\right) + o\\left( {x_{k}^{*} - \\tilde{x}_{k}^{*} } \\right)$$
    (12) where \\(\\tilde{x}_{k}^{*}\\) is the corrected estimation result at last
    time step \\(k\\), and \\(\\frac{\\partial \\Gamma }{{\\partial x_{k}^{*} }}\\)
    is the Jacobi matrix of the state vector, denoted as \\(F_{k}\\), $$\\left. {F_{k}
    = \\frac{\\partial \\Gamma }{{\\partial x_{k}^{*} }}} \\right|_{{x_{k}^{*} = \\tilde{x}_{k}^{*}
    }} = \\left[ {\\begin{array}{*{20}c} {\\frac{{\\partial \\Gamma_{1} }}{{\\partial
    x_{k,1}^{*} }}} & \\ldots & {\\frac{{\\partial \\Gamma_{1} }}{{\\partial x_{k,N
    + 1}^{*} }}} \\\\ \\vdots & \\vdots & \\vdots \\\\ {\\frac{{\\partial \\Gamma_{N
    + 1} }}{{\\partial x_{k,1}^{*} }}} & \\cdots & {\\frac{{\\partial \\Gamma_{N +
    1} }}{{\\partial x_{k,N + 1}^{*} }}} \\\\ \\end{array} } \\right]_{(N + 1) \\times
    (N + 1)}$$ (13) It can be numerically calculated by the following means, $$\\frac{{\\partial
    \\Gamma_{i} }}{{\\partial x_{k,j}^{*} }} \\approx \\frac{{\\Gamma_{i} \\left(
    {x_{k}^{*} + e_{j} \\varepsilon x_{k,j}^{*} } \\right) - \\Gamma_{i} \\left( {x_{k}^{*}
    - e_{j} \\varepsilon x_{k,j}^{*} } \\right)}}{{2\\varepsilon x_{k,j}^{*} }}$$
    (14) where \\(e_{j} = \\;\\left[ {0 \\, 0 \\cdots \\underbrace {{1^{ * } }}_{j}
    \\cdots \\, 0} \\right]_{N + 1}^{T}\\) and \\(\\varepsilon = 10^{ - 4}\\). Therefore,
    the final predicted results \\(\\hat{x}_{k + 1}^{*}\\)(means of \\(x_{k + 1}^{*}\\))
    and its error covariance matrix \\(P_{k + 1}\\) are given below, $$\\hat{x}_{k
    + 1}^{*} = \\Gamma \\left( {\\tilde{x}_{k}^{*} } \\right)$$ (15) $$\\hat{y}_{k
    + 1}^{*} = H\\hat{x}_{k + 1}^{*}$$ (16) $$P_{k + 1} = F_{k} P^{\\prime}_{k} F_{k}^{T}
    + Q$$ (17) where \\(\\hat{y}_{k + 1}\\) are the predicted measurement temperature
    at time step k + 1 and P′ is the corrected error covariance matrix at time step
    k. In the correction phase, the Kalman gain is calculated as follows, which can
    be considered as the confidence level ratio between the model prediction and sensor
    measurements. $$K^{\\prime} = P_{k + 1} H^{T} (HP_{k + 1} H^{T} + R)^{ - 1}$$
    (18) Then the estimation results and the covariance matrix are corrected using
    the Kalman gain. $$\\tilde{x}_{{{\\text{k}} + 1}}^{*} = \\hat{x}_{{\\text{k}}}^{*}
    + K^{\\prime}\\left( {y_{k + 1} -H\\hat{x}_{{{\\text{k}} + 1}}^{*} } \\right)$$
    (19) $$P^{\\prime}_{k + 1} = P_{k} - K^{\\prime}H_{k} P_{k}$$ (20) 2.3 RTS Smoothing
    The EKF approach is a real-time inversion algorithm, which utilizes the current
    available data to estimate the unknown boundary heat flux. However, due to the
    diffusive nature of heat transfer process, the thermal response at sensor location
    lags behind the changing boundary heat flux, which is difficult to be captured
    by EKF approach itself. In this work, a fixed interval smoothing algorithm called
    the Rauch-Tung-Strieber (RTS) smoothing technique is employed to include the data
    of future time measurement into the algorithm for better estimations. As showed
    in Fig. 3, the RTS algorithm loops Kalman filtering procedures forwardly by \\(n_{f}\\)
    times and then slides back by \\(n_{f}\\) times to obtain a smoothed result. In
    the forward filtering procedures, we have already calculated the predicted \\(\\hat{x}_{k}^{*}\\),
    the corrected estimation \\(\\tilde{x}_{k}^{*}\\), the corresponding predicted
    error covariance \\(P_{k}\\), the corrected \\(P^{\\prime}_{k}\\), and the Jacobi
    matrix \\(F_{k}\\) at time step \\(k(k = k_{0} \\ldots k_{0} + n_{f} )\\). Thus,
    the backward recursion procedures can be proceeded as follows, $$G_{k} = P^{\\prime}_{k}
    F_{k}^{T} (P_{k + 1} )^{ - 1}$$ (21) $$\\tilde{x}^{\\prime\\prime {*}}_{k} = \\tilde{x}_{k}^{*}
    + G_{k} (\\tilde{x}^{\\prime\\prime {*}}_{k + 1} - \\tilde{x}_{k + 1}^{*} )$$
    (22) Fig. 3 The procedure of RTS smoothing at time step k Full size image where
    \\(\\tilde{x}^{\\prime\\prime {*}}_{k}\\) and \\(\\tilde{x}^{\\prime\\prime {*}}_{k
    + 1}\\) are the smoothed results at time step \\(k,k + 1\\) and \\(G_{k}\\) represents
    the RTS version of Kalman gain. 3 The ANN-Based Rapid State Transfer Model In
    traditional KF-related approaches, the state transfer is usually achieved by CFD
    simulations, whose computation may take longer than the physical time in complex
    flow and heat transfer problems, thus being unsuitable for online inversion. Alternatively,
    the artificial neural network is employed as a surrogate model for temperature
    field prediction by CFD, which can significantly reduce computational cost while
    holds certain level of accuracy [27]. More importantly, given that the ANN prediction
    does not require the information of entire temperature field, it allows to reduce
    the dimension of state vector in the EKS algorithm, which can tremendously reduce
    the computational cost and eventually realize online predictions. 3.1 The General
    Form of ANN-Based State Transfer Model The key model in EKS algorithm is the state
    transfer model, which is composed of two parts. The first part approximates the
    next time step heat flux from step k to step k + 1 as showed in Eq. (23) $$q_{k
    + 1} = q_{k} + \\omega_{q}$$ (23) where we consider the induced error by this
    approximation as a part of the noise ω applied to the state transfer model. The
    second part forwardly calculates the next-time-step temperature field based on
    current temperature field and heat flux, which is achieved by ANN model. The input
    of ANN is the current state vector \\(x_{k}^{*} = [T_{k}^{1} \\, T_{k}^{2} \\ldots
    T_{k}^{i} \\ldots T_{k}^{N} \\, q_{k} ]^{T}\\), and the output is the next-time-step
    temperature field \\(T_{k + 1} = [T_{k + 1}^{1} \\, T_{k + 1}^{2} \\ldots T_{k
    + 1}^{i} \\ldots T_{k + 1}^{N} ]^{T}\\). Despite the proven feasibility of this
    chosen state vector [24,25,26], the computational cost is still prohibitively
    expensive for online estimations. Large amounts of redundant sensitivity analysis
    are generated from this high-dimensional state vector containing the entire temperature
    field of all mesh nodes. To address this problem, a novel state transfer model
    of reduced dimension is designed here with the aid of ANN algorithm. The reduced
    form of state vector is as follows, $$x_{k}^{*} = \\left[ {\\begin{array}{*{20}c}
    {T_{k}^{{n_{s} }} } & {T_{k}^{{n_{s} + a}} } & {T_{k}^{{n_{s} - a}} } & {T_{k}^{{n_{s}
    + b}} } & {T_{k}^{{n_{s} + b}} } & {q_{k} } \\\\ \\end{array} } \\right]^{T}$$
    (24) where the temperature value of sensor location \\(T_{k}^{n_{s}}\\) is listed
    on the state vector along with the temperatures of four other points close to
    the sensor. Then, the structure of ANN surrogate model should be organized as
    follows, $${\\text{Inputs}}{:}\\,\\left[ {\\begin{array}{*{20}c} {T_{k}^{{n_{s}
    }} } & {T_{k}^{{n_{s} + a}} } & {T_{k}^{{n_{s} - a}} } & {T_{k}^{{n_{s} + b}}
    } & {T_{k}^{{n_{s} + b}} } & {q_{k} } \\\\ \\end{array} } \\right]^{T}$$ (25)
    $${\\text{Outputs}}{:}\\,\\left[ {\\begin{array}{*{20}c} {T_{k + 1}^{{n_{s} }}
    } & {T_{k + 1}^{{n_{s} + a}} } & {T_{k + 1}^{{n_{s} - a}} } & {T_{k + 1}^{{n_{s}
    + b}} } & {T_{k + 1}^{{n_{s} + b}} } \\\\ \\end{array} } \\right]^{T}$$ (26) 3.2
    The Generation of Dataset and the Training Procedure of ANNs To train the ANN
    models, large amounts of numerical simulations are conducted to generate the training
    dataset. The transient temperature field are calculated by solving the covering
    equations described in Sect. 2.1 with finite volume method, which applies upwind
    differential scheme in x direction, central differential scheme in y direction,
    and the implicit scheme is adopted for the time marching [11]. The total mesh
    size is \\(25 \\times 50\\) with \\({\\vartriangle} x = 0.04\\,{\\text{m}}\\)
    and \\({\\vartriangle} {\\text{y}} = 0.002\\,{\\text{m}}\\). To cover a variety
    of changing thermal boundary conditions on the heated wall, as shown in Fig. 4,
    a series of heat flux evolutions were adopted such as step functions, polynomial
    functions, sinusoid waves and triangular waves in different amplitudes and frequencies,
    which will generate rich state transfer information for the training of ANN models.
    Moreover, the training dataset could be furthered expanded by applying Eq. (14)
    during the above simulation, so as to simulate the sensitivity analysis by elevating
    and lowering one of the state variable’s value and then calculating the next-time
    results. Fig. 4 The schematic of generating dataset by applying various form of
    heat flux and obtaining temperature distribution over time. a Step heat flux.
    b Triangular heat flux. c Parabolic heat flux. d Sinusoid heat flux Full size
    image Therefore, the final training heat flux, with a total times steps of 6794
    (time duration of 67.94 s on the testing computer), is applied to the benchmark
    problem including the four above forms of heat fluxes showed in Fig. 4 with different
    amplitudes and frequencies. The CFD predicted temperature field is then reorganized
    into the standard form of inputs and outputs of ANN for training purpose. The
    final dataset includes state transfer data needed in Eq. (10) as well as the sensitivity
    analysis data needed in Eq. (14). However, the data volume of the former is only
    1/12 of the latter. The unbalanced dataset may cause the ANN model fitting more
    closely to the pattern of sensitivity analysis but works poorly under state transfer
    scenario. To resolve this unbalanced dataset problem, we choose to divide the
    dataset and train two ANN models used for state transfer prediction and sensitivity
    analysis respectively. Therefore, 6794 sets of data are used for training the
    state transfer ANN model and the remaining 81,529 sets of data are used for training
    the sensitivity ANN model. The fully connected multi-layer perception (MLP) neural
    network is chosen in this work. Both ANN models compose of three layers, with
    10 neurons in the hidden layer. The inputs and outputs are standardized in order
    to enhance training performance. The hyperbolic tangent (tanh) function is chosen
    as the active function and the Levenberg–Marquardt backpropagation algorithm is
    used to train the neural network. The training procedure of ANN model for state
    transfer prediction ends after 1422 iterations when the performance of the network
    stops improving in the validation dataset for 6 consecutive epochs. To validate
    the training method, datasets are randomly divided into three parts, 70% of which
    are used for training, 15% for validation and 15% for testing respectively. The
    pre-trained neural network eventually achieves a mean square error of 7.14 × 10−9
    in the testing dataset and the regression R value reaches 0.99999, while the training
    procedure of ANN model for sensitivity analysis ends after 552 iterations and
    achieves a mean square error of 8.02 × 10−9 in the testing dataset and the regression
    R value reaches 0.99997, indicating that the training is successful and the obtained
    neural network can meet the accuracy criterion for surrogating the state transfer
    models. 4 Results and Discussions 4.1 Verification on the Feasibility of the Proposed
    Algorithm and Discussions In order to test the feasibility of the proposed algorithm,
    a transient CFD simulation is performed, in which the heat flux on the upper wall
    is varying in the manner showed in Fig. 5 (solid line). The CFD predicted temperature
    variation at the point (x, y), is then extracted to simulate the temperature measurements
    with a sensor. Fig. 5 Comparison between the real heat flux and the estimation
    results under noise level m = 2 (Plot interval: every 11 time steps) Full size
    image Given that the sensor-measured temperature is inevitably contaminated with
    noises, a zero-mean Gaussian noise (\\(\\sigma \\sim N\\left( {0,1} \\right)\\))
    with a noise level m is imposed on the simulated temperature evolution at the
    point (x, y) to simulate the noisy measurements \\(y_{k}\\), $$y_{k} = T_{k} +
    m\\sigma .$$ (27) where \\(T_{k}\\) is the simulated real temperature value at
    sensor location of time step k. In this test, the noise level is set to be m = 2.
    Feeding the artificial measurements \\(y_{k}\\) into the ANN-EKS algorithm as
    the input, one can get the output \\(q_{k}\\). Figure 5 compares \\(q_{k}\\) with
    the wall thermal boundary condition used in the CFD simulation \\(q^{\\prime\\prime}_{k}\\),
    which could be treated as the “true” value. The results show that the predicted
    heat flux evolution agrees well with the “true” value, indicating the ANN-EKS
    based IHTPs solver works well to predict the historical thermal boundary condition
    that varied with complex wave functions, such as step function, a triangular wave
    and an arbitrary smooth curve. To evaluate the algorithm’s performance quantitatively,
    the average error (AE) is defined to describe the accuracy of the estimation results,
    $$AE = \\sqrt {\\frac{1}{n}\\sum\\limits_{k = 1}^{n} {\\left( {\\overline{q}_{k}^{\\prime
    \\prime } - \\overline{q}_{k} } \\right)^{2} } }$$ (28) where the \\(\\overline{q}_{k}^{\\prime
    \\prime }\\) and \\(\\overline{q}_{k}\\) are the dimensionless form of applied
    heat flux and estimation results and n is the number of total time steps. And
    the average computing time per time step is defined to evaluate the computational
    efficiency of our algorithm. All the simulations involved in this work are performed
    on a personal computer with 2.50 GHz Intel (R) Core (TM) i7-11700F processor and
    32 GB of RAM. 4.2 Comparison Study with Other Algorithms In order to highlight
    the advantage of the proposed algorithm, it is compared with the inverse ANN algorithm
    [15, 16] and the extended Kalman smoothing algorithm (EKS) [24, 25]. The inverse
    ANN algorithm [15, 16] mainly utilizes the artificial neural network model to
    directly map the sensor-measured temperature to the unknown boundary conditions.
    The inputs of the ANN model are the past and future temperature measurement \\(\\left[
    {T_{{k + n_{p} }} \\ldots T_{k - 1} \\, T_{k} \\, T_{k + 1} \\ldots \\, T_{k +
    nf} } \\right]^{T}\\) at the sensor locations, and the outputs are the boundary
    heat flux \\(\\left[ {q_{k} } \\right]\\) in the current time step. The inverse
    ANN algorithm possesses high computational efficiency due to its direct ANN-aided
    prediction of unknown BCs from the sensor measurements, but it may tend to overfitting
    and performs poorly when the measurement noises are relatively high. The extended
    Kalman smoothing algorithm [24, 25] employs the full form of the state vector,
    the transfer of which is calculated based on the traditional CFD methods. Though
    this algorithm copes well under noisy measurement, the redundant sensitivity analysis,
    caused by the high-dimensionality of the full-form state vector, lead to tremendously
    high computational cost and limits its applications toward online estimations.
    It can be seen that the proposed algorithm has a lower accuracy than the traditional
    inverse ANN algorithm under relatively lower noise level. However, it outperforms
    the inverse ANN algorithm when the noise level is higher than 10, indicating that
    the proposed algorithm works robustly under noisy input data. Moreover, the AE
    of the proposed algorithm is close to that of the CFD-based EKS algorithm, which
    proves that the simplification of our work in the state vector is reasonable.
    Notably, Fig. 6 shows the inversion results of the above three algorithm (scatter)
    against the testing heat flux (solid line) under a relatively high noise level
    of m = 10. The results of our ANN-EKS algorithm and traditional EKS algorithm
    match the real heat flux well with an AE of 0.0580 and 0.0609 respectively while
    the inverse ANN algorithm seemingly oscillates greatly under this high noise level
    and performs the worst with an AE of 0.0825. Also, we can notice that the proposed
    ANN-EKS algorithm possesses better ability to suppress overshooting and oscillation
    of the prediction compared with the other two methods, which further proves the
    robustness of our algorithm in noisy environments. Fig. 6 The estimation results
    of the three algorithms under noise level m = 10 k (Plot interval: every 9 time
    steps). a The ANN-based EKS results with AE = 0.0580. b The EKS results with AE = 0.0609.
    c The inverse ANN results with AE = 0.0825 Full size image More importantly, our
    proposed algorithm also has great advantages in terms of computational efficiency.
    our ANN-EKS algorithm can drastically reduce the computational time of the conventional
    EKS approach from 11.3 s per time step to 5.43 ms in the comparison study. Since
    the primary goal of our algorithm is online estimation, we set a criterion to
    evaluate the algorithm’s online ability, which is the computing time per time
    step should not exceed the computational time interval (0.01 s in this case).
    Judged by the criterion for online estimation, 5.43 ms is significantly shorter
    than the time step interval of 0.01 s, which means our algorithm is fully capable
    of performing online estimation task while the conventional EKS approach cannot.
    Based on the comparison results, it is safe to say that our proposed algorithm
    is indeed a robust and rapid approach and capable of achieving online estimation
    task for solving IHTPs. 5 Conclusion A rapid yet robust inversion algorithm, ANN-based
    extended Kalman smoothing algorithm, is developed to realize the online estimation
    of time-varying thermal boundary conditions in a two-dimensional tube convective
    heat transfer problem. The major findings are summarized as follows: 1. The proposed
    algorithm is a computational-light online approach for the estimation of the unknown
    boundary conditions. Compared with conventional CFD-based EKS algorithm, the computational
    costs of the proposed are reduced drastically from 11.3 s per time step to 5.31
    ms, which makes our algorithm fully capable of performing online estimation task.
    2. The proposed algorithm is relatively robust to handle measurement data with
    high noise-signal ratio. An average error of 0.0580 for estimating unknown boundary
    heat flux can be achieved via our algorithm, whose accuracy is basically equivalent
    to the conventional EKS algorithm with an average error of 0.0609 and improves
    significantly compared to the inverse ANN algorithm with an average error of 0.0825.
    References Ku, C.Y., Liu, C.Y., Xiao, J.E., Hsu, S.M., Yeih, W.: A collocation
    method with space-time radial polynomials for inverse heat conduction problems.
    Eng. Anal. Boundary Elem. 122, 117–131 (2021) Article   MathSciNet   Google Scholar   Uyanna,
    O., Najafi, H., Rajendra, B.: An inverse method for real-time estimation of aerothermal
    heating for thermal protection systems of space vehicles. Int. J. Heat Mass Transf.
    177(2), 121482 (2021) Article   Google Scholar   Jang, H.-Y., Cheng, C.-H.: Nonlinear
    optimal on-line heat-dissipation control methodology in electronic devices. Int.
    J. Heat Mass Transf. 52(7), 2049–2058 (2009) Article   Google Scholar   LeBreux,
    M., Désilets, M., Lacroix, M.: An unscented Kalman filter inverse heat transfer
    method for the prediction of the ledge thickness inside high-temperature metallurgical
    reactors. Int. J. Heat Mass Transf. 57(1), 265–273 (2013) Article   Google Scholar   Wang,
    G., et al.: Fuzzy identification of the time- and space-dependent internal surface
    heat flux of slab continuous casting mold. J. Heat Transf. 140(12) (2018) Google
    Scholar   Białobrzewski, I.: Determination of the heat transfer coefficient by
    inverse problem formulation during celery root drying. J. Food Eng. 74(3), 383–391
    (2006) Article   Google Scholar   Alifanov, O.M.: Inverse Heat Transfer Problems
    (1994) Google Scholar   Huang, S., et al.: On-line heat flux estimation of a nonlinear
    heat conduction system with complex geometry using a sequential inverse method
    and artificial neural network. Int. J. Heat Mass Transf. 143 (2019) Google Scholar   Golsorkhi,
    N.A., Tehrani, H.A.: Levenberg-marquardt method for solving the inverse heat transfer
    problems (2014) Google Scholar   Lee, K.H.: Application of repulsive particle
    swarm optimization for inverse heat conduction problem—parameter estimations of
    unknown plane heat source. Int. J. Heat Mass Transf. 137, 268–279 (2019) Article   Google
    Scholar   Udayraj, et al.: Performance analysis and feasibility study of ant colony
    optimization, particle swarm optimization and cuckoo search algorithms for inverse
    heat transfer problems. Int. J. Heat Mass Transf. 89, 359–378 (2015) Google Scholar   Beck,
    J.V.: Nonlinear estimation applied to the nonlinear inverse heat conduction problem.
    Int. J. Heat Mass Transf. 13(4), 703–716 (1970) Article   Google Scholar   Li,
    Y., Wang, G., Chen, H.: Simultaneously regular inversion of unsteady heating boundary
    conditions based on dynamic matrix control. Int. J. Therm. Sci. 88, 148–157 (2015)
    Article   Google Scholar   Wang, G., et al.: A multiple model adaptive inverse
    method for nonlinear heat transfer system with temperature-dependent thermophysical
    properties. Int. J. Heat Mass Transf. 118, 847–856 (2018) Article   Google Scholar   Najafi,
    H., Uyanna, O., Zhang, J.: Application of artificial neural network as a near-real
    time technique for solving non-linear inverse heat conduction problems in a one-dimensional
    medium with moving boundary. In: Proceedings of the ASME 2020 Summer Heat Transfer
    Conference (2020) Google Scholar   Najafi, H., Woodbury, K.A.: Online heat flux
    estimation using artificial neural network as a digital filter approach. Int.
    J. Heat Mass Transf. 91, 808–817 (2015) Article   Google Scholar   Daouas, N.,
    Radhouani, M.S.: A new approach of the Kalman filter using future temperature
    measurements for nonlinear inverse heat conduction problems. Numer. Heat Transf.
    Part B Fundam. 45(6), 565–585 (2004) Article   Google Scholar   Wen, S., et al.:
    Application of KF-RLSE algorithm for on-line estimating the time-dependent melting
    thickness and input heat flux in participating media. Int. J. Therm. Sci. 125,
    1–10 (2018) Article   Google Scholar   Ko, Y.-H., et al.: Inverse estimation problem
    of determining the unknown timewise-varying strength of a primer rapid heat source.
    Procedia Eng. 79, 295–304 (2014) Article   Google Scholar   Wen, S., et al.: An
    on-line extended Kalman filtering technique for reconstructing the transient heat
    flux and temperature field in two-dimensional participating media. Int. J. Thermal
    Sci. 148 (2020) Google Scholar   Wen, S., et al.: Real-time estimation of time-dependent
    imposed heat flux in graded index media by KF-RLSE algorithm. Appl. Therm. Eng.
    150, 1–10 (2019) Article   Google Scholar   da Silva, W.B., et al.: Sequential
    particle filter estimation of a time-dependent heat transfer coefficient in a
    multidimensional nonlinear inverse heat conduction problem. Appl. Math. Model.
    89, 654–668 (2021) Article   MathSciNet   Google Scholar   Jahangiri, A., Mohammadi,
    S., Akbari, M.: Modeling the one-dimensional inverse heat transfer problem using
    a Haar wavelet collocation approach. Physica A 525, 13–26 (2019) Article   MathSciNet   Google
    Scholar   Scarpa, F., Milano, G.: Kalman smoothing technique applied to the inverse
    heat conduction problem. Numer. Heat Transf. Part B Fundam. 28(1), 79–96 (1995)
    Google Scholar   Gaaloul, N., Daouas, N.: An extended approach of a Kalman smoothing
    technique applied to a transient nonlinear two-dimensional inverse heat conduction
    problem. Int. J. Therm. Sci. 134, 224–241 (2018) Article   Google Scholar   Wen,
    S., et al.: Simultaneous estimation of internal temperature field and boundary
    time-dependent heat flux in absorbing and scattering media using the unscented
    Kalman smoothing technique. J. Quant. Spectrosc. Radiat. Transf. 255 (2020) Google
    Scholar   Hornik, K., Stinchcombe, M., White, H.: Multilayer feedforward networks
    are universal approximators. Neural Netw. 2(5), 359–366 (1989) Article   Google
    Scholar   Download references Author information Authors and Affiliations Beihang
    University, Beijing, 100191, PR China Xinxin Zhang, Dike Li, Zeyuan Cheng, Jianqin
    Zhu, Zhi Tao & Lu Qiu Corresponding author Correspondence to Lu Qiu . Editor information
    Editors and Affiliations Dept of Civil and Env''l Engg, University of California,
    Berkeley, Berkeley, CA, USA Shaofan Li Rights and permissions Reprints and permissions
    Copyright information © 2024 The Author(s), under exclusive license to Springer
    Nature Switzerland AG About this paper Cite this paper Zhang, X., Li, D., Cheng,
    Z., Zhu, J., Tao, Z., Qiu, L. (2024). Rapid Online Estimation of Time-Varying
    Thermal Boundary Conditions in Convective Heat Transfer Problem by ANN-Based Extended
    Kalman Smoothing Algorithm. In: Li, S. (eds) Computational and Experimental Simulations
    in Engineering. ICCES 2023. Mechanisms and Machine Science, vol 146. Springer,
    Cham. https://doi.org/10.1007/978-3-031-44947-5_17 Download citation .RIS.ENW.BIB
    DOI https://doi.org/10.1007/978-3-031-44947-5_17 Published 25 January 2024 Publisher
    Name Springer, Cham Print ISBN 978-3-031-44946-8 Online ISBN 978-3-031-44947-5
    eBook Packages Engineering Engineering (R0) Share this paper Anyone you share
    the following link with will be able to read this content: Get shareable link
    Provided by the Springer Nature SharedIt content-sharing initiative Publish with
    us Policies and ethics Sections Figures References Abstract Introduction Inversion
    Procedure by Extended Kalman Smoothing The ANN-Based Rapid State Transfer Model
    Results and Discussions Conclusion References Author information Editor information
    Rights and permissions Copyright information About this paper Publish with us
    Discover content Journals A-Z Books A-Z Publish with us Publish your research
    Open access publishing Products and services Our products Librarians Societies
    Partners and advertisers Our imprints Springer Nature Portfolio BMC Palgrave Macmillan
    Apress Your privacy choices/Manage cookies Your US state privacy rights Accessibility
    statement Terms and conditions Privacy policy Help and support 129.93.161.219
    Big Ten Academic Alliance (BTAA) (3000133814) - University of Nebraska-Lincoln
    (3000134173) © 2024 Springer Nature"'
  inline_citation: '>'
  journal: Mechanisms and Machine Science
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Rapid Online Estimation of Time-Varying Thermal Boundary Conditions in Convective
    Heat Transfer Problem by ANN-Based Extended Kalman Smoothing Algorithm
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Del Priore E.
  - Lampani L.
  citation_count: '0'
  description: The real-time reconstruction of the displacement field of a structure
    from a network of in situ strain sensors is commonly referred to as “shape sensing”.
    The inverse finite element method (iFEM) stands out as a highly effective and
    promising approach to perform this task. In the current investigation, this technique
    is employed to monitor different plate structures experiencing flexural and torsional
    deformation fields. In order to reduce the number of installed sensors and obtain
    more accurate results, the iFEM is applied in synergy with smoothing element analysis
    (SEA), which allows the pre-extrapolation of the strain field over the entire
    structure from a limited number of measurement points. For the SEA extrapolation
    to be effective for a multitude of load cases, it is necessary to position the
    strain sensors appropriately. In this study, an innovative sensor placement strategy
    that relies on a multi-objective genetic algorithm (NSGA-II) is proposed. This
    approach aims to minimize the root mean square error of the pre-extrapolated strain
    field across a set of mode shapes for the examined plate structures. The optimized
    strain reconstruction is subsequently utilized as input for the iFEM technique.
    Comparisons are drawn between the displacement field reconstructions obtained
    using the proposed methodology and the conventional iFEM. In order to validate
    such methodology, two different numerical case studies, one involving a rectangular
    cantilevered plate and the other encompassing a square plate clamped at the edges,
    are investigated. For the considered case studies, the results obtained by the
    proposed approach reveal a significant improvement in the monitoring capabilities
    over the basic iFEM algorithm with the same number of sensors.
  doi: 10.3390/s24020608
  full_citation: '>'
  full_text: '>

    "This website uses cookies We use cookies to personalise content and ads, to provide
    social media features and to analyse our traffic. We also share information about
    your use of our site with our social media, advertising and analytics partners
    who may combine it with other information that you’ve provided to them or that
    they’ve collected from your use of their services. Consent Selection Necessary
    Preferences Statistics Marketing Show details                 Deny Allow selection
    Allow all     Journals Topics Information Author Services Initiatives About Sign
    In / Sign Up Submit   Search for Articles: Sensors All Article Types Advanced   Journals
    Sensors Volume 24 Issue 2 10.3390/s24020608 Submit to this Journal Review for
    this Journal Propose a Special Issue Article Menu Academic Editors Nader Vahdati
    Fook Fah Yap Subscribe SciFeed Recommended Articles Related Info Links More by
    Authors Links Article Views 576 Citations 1 Table of Contents Abstract Introduction
    Theoretical Background Case Studies Conclusions Author Contributions Funding Institutional
    Review Board Statement Informed Consent Statement Data Availability Statement
    Acknowledgments Conflicts of Interest References share Share announcement Help
    format_quote Cite question_answer Discuss in SciProfiles thumb_up Endorse textsms
    Comment first_page settings Order Article Reprints Open AccessArticle Shape Sensing
    in Plate Structures through Inverse Finite Element Method Enhanced by Multi-Objective
    Genetic Optimization of Sensor Placement and Strain Pre-Extrapolation by Emiliano
    Del Priore and Luca Lampani * Dipartimento di Ingegneria Meccanica e Aerospaziale,
    Sapienza Università di Roma, 00184 Rome, Italy * Author to whom correspondence
    should be addressed. Sensors 2024, 24(2), 608; https://doi.org/10.3390/s24020608
    Submission received: 18 December 2023 / Revised: 12 January 2024 / Accepted: 16
    January 2024 / Published: 18 January 2024 (This article belongs to the Special
    Issue Sensors for Vibration Control and Structural Health Monitoring) Download
    keyboard_arrow_down     Browse Figures Versions Notes Abstract The real-time reconstruction
    of the displacement field of a structure from a network of in situ strain sensors
    is commonly referred to as “shape sensing”. The inverse finite element method
    (iFEM) stands out as a highly effective and promising approach to perform this
    task. In the current investigation, this technique is employed to monitor different
    plate structures experiencing flexural and torsional deformation fields. In order
    to reduce the number of installed sensors and obtain more accurate results, the
    iFEM is applied in synergy with smoothing element analysis (SEA), which allows
    the pre-extrapolation of the strain field over the entire structure from a limited
    number of measurement points. For the SEA extrapolation to be effective for a
    multitude of load cases, it is necessary to position the strain sensors appropriately.
    In this study, an innovative sensor placement strategy that relies on a multi-objective
    genetic algorithm (NSGA-II) is proposed. This approach aims to minimize the root
    mean square error of the pre-extrapolated strain field across a set of mode shapes
    for the examined plate structures. The optimized strain reconstruction is subsequently
    utilized as input for the iFEM technique. Comparisons are drawn between the displacement
    field reconstructions obtained using the proposed methodology and the conventional
    iFEM. In order to validate such methodology, two different numerical case studies,
    one involving a rectangular cantilevered plate and the other encompassing a square
    plate clamped at the edges, are investigated. For the considered case studies,
    the results obtained by the proposed approach reveal a significant improvement
    in the monitoring capabilities over the basic iFEM algorithm with the same number
    of sensors. Keywords: structural health monitoring; shape sensing; sensor placement;
    inverse finite element method; smoothing element analysis; multi-objective genetic
    algorithm 1. Introduction A structural health monitoring (SHM) system integrates
    strategically placed sensors to gather essential data about the structure and
    its environment, enabling a comprehensive assessment of its overall condition
    [1]. The primary aim is not only to evaluate the structural integrity, but also
    to monitor and check the system’s performance in operational scenarios [2]. The
    combination of SHM and non-destructive testing offers detailed insight into the
    structural conditions, optimizing maintenance strategies and ensuring long-term
    safety [3]. Shape sensing is a specific branch of SHM dedicated to the real-time
    reconstruction of the displacement field of a structure from a set of in situ
    strain measurements. It allows for the continuous tracking of both static and
    dynamic responses within the system [4]. Furthermore, reconstructing the displacement
    field serves as an initial step in assessing stresses across either the entire
    structure or specific regions [5]. The attention towards shape-sensing techniques
    has increased alongside the advent of new strain sensor technologies. In addition
    to traditional strain gauges, contemporary solutions incorporate fiber optic sensors
    (FOSs). FOSs offer notable advantages, such as insensitivity to electromagnetic
    radiation, light weight, small size, great sensitivity and resolution, and suitability
    to be embedded into structures [6] These sensors have found numerous shape-sensing
    applications in civil and aerospace engineering [7]. The methods for solving shape-sensing
    problems can be broadly classified into four categories [8]. The first category
    encompasses analytical approaches, such as Ko’s displacement theory [9], which
    involves direct or numerical integration of experimentally measured strain. The
    second category includes methods that utilize continuous basis functions to approximate
    displacements. Modal methods (MM) [10,11], for example, fall into this class as
    they use known spatial functions like mode shapes to describe the displacement
    field, with unknown weights determined through a curve-fitting process using experimental
    strains. The third category involves computational models that use artificial
    neural networks (ANNs) [12]. The fourth, and last, class is represented by the
    inverse finite element method (iFEM), developed by Tessler and Spangler [13].
    This technique is based on the least-squares variational principle and finite
    element discretization. Ko’s displacement theory is limited to beam-like structures
    as it relies on the kinematic assumptions in the Euler–Bernoulli theory. On the
    other hand, methods employing ANNs have not been applied widely due to their results
    being heavily reliant on training datasets. Thus, among the four classes, MM and
    iFEM exhibit higher general applicability to various kinds of structures. Few
    studies in the literature focus on comparing these two approaches. For instance,
    ref. [14] provides an experimental comparison for a stiffened panel equipped with
    fiber optic sensors, while ref. [15] presents numerical analysis involving iFEM,
    MM, and Ko’s theory for a composite wingbox. These works emphasize that MM is
    a useful tool in the presence of uncertainties, since it is less influenced by
    them, although it achieves a lower reconstruction accuracy than iFEM. Other than
    its high accuracy, the inverse finite element method’s key strengths lie in its
    ability to monitor the displacement field even under unknown loading conditions
    and material properties [16], along with its computational speed which enables
    real-time applications. Over the past decade, a variety of inverse elements has
    been developed on the basis of the first-order shear deformation theory (FSDT).
    Among the FSDT-based iFEM elements is a three-node inverse-shell element, designated
    as iMIN3 [17]; a four-node quadrilateral inverse-shell element, denoted as iQS4
    [18]; an eight-node curved inverse shell element, referred to as iCS8 [19]; and
    a two-node inverse-beam element [20]. In addition, Kefal and Oterkus [21] have
    introduced a novel isogeometric inverse element (iKLS), which utilizes Non-Uniform
    Rational B-Splines (NURBS) as shape functions to achieve a geometrically exact
    representation of curved thin shell structures. Subsequently, this isogeometric
    approach has also been extended to the reconstruction of the displacement field
    in beam-like geometries [22,23]. The abovementioned elements enable real-time
    monitoring of isotropic structures like beams, plates, and shells by means of
    the inverse finite element method. More recently, a novel class of elements [24]
    has been introduced, leveraging the refined zig-zag theory [25], to exploit the
    iFEM technique in moderately thick sandwich and laminated composite structures.
    Over the last few years, iFEM has found both numerical and/or experimental applications
    in shape-sensing analyses across various interesting case studies, including marine
    vessels [26], offshore wind turbine towers [27], and stiffened panels [14,28,29].
    The precision of the inverse finite element method in reconstructing the displacement
    field is significantly influenced by the number of sensors used. The installation
    of hundreds of sensors, required to achieve a low error, may be prohibitively
    expensive and is to be avoided in particular industries, like aerospace, where
    weight is an important factor to be taken into account. Thus, it may be useful
    to make use of pre-extrapolation techniques to obtain the input strain field on
    a more refined mesh from a reduced number of sensors. Notable works addressing
    this issue include those by Abdollahzdeh et al. [30] and Kefal et al. [31]. The
    first study employed polynomial extrapolation to approximate the strain field
    from sensor data, while the latter utilized a smoothing procedure based on the
    minimization of penalized least-squares functionals, known as smoothing element
    analysis (SEA) [32]. SEA discretizes the structural domain using least-squares
    finite elements, where the variable to be smoothed (e.g., stress or strain) is
    interpolated within each element using piecewise continuous functions. Oboe et
    al. [33] conducted a comparison between these two pre-extrapolation techniques
    on a plate subjected to a compressive load. The authors observed that SEA demonstrated
    a higher level of adaptability to the input strain field, allowing it to achieve
    more versatile results. The accuracy of pre-extrapolation performed with SEA depends
    on the sensor placement and on the complexity of the strain field. For example,
    the uniform distribution of sensors on the structure may not optimally reconstruct
    the strain field since it might not correctly identify its peaks. Consequently,
    optimizing sensor placement becomes crucial to enhance the effectiveness of the
    pre-extrapolation process under specific loading conditions. Within the iFEM framework,
    various studies have focused on optimizing sensor placement. As an example, Zhao
    et al. [34] utilized particle swarm optimization (PSO) to derive optimal sensor
    schemes for beam structures based on eigenvalue analysis. Ghasemzadeh et al. [35]
    employed a genetic algorithm to strategically position sensors on selected inverse
    elements within the mesh of simple 2D and 3D structures under concentrated and
    distributed loads. Their approach aimed at minimizing the error in the reconstructed
    displacement field as the objective function. However, this study did not incorporate
    any pre-extrapolation mechanism, and each optimization was conducted based on
    a single predefined load (a sensor pattern was optimal only for a single loading
    condition). In contrast, Roy et al. [36] explored the reconstruction of two mode
    shapes of a cantilevered plate using iFEM pre-extrapolated with SEA. Although
    they considered efficient and easy-to-implement sensor placement patterns, these
    were not the result of an optimization process. In this study, we achieve full-field
    displacement reconstruction using iFEM with pre-extrapolated SEA strains as input.
    To enhance the effectiveness of pre-extrapolation, we introduce an innovative
    approach employing a genetic algorithm to optimize sensor placement, aiming to
    closely match the pre-extrapolated strain field with the actual one. Ensuring
    the validity of the sensor pattern across diverse loading conditions, the optimization
    process is multi-objective, utilizing the well-established non-dominated sorting
    genetic algorithm (NSGA-II [37]). Specifically, we focus on analyzing a cantilevered
    rectangular plate and a square plate clamped on all four sides, optimizing sensor
    placement for the improved reconstruction of a pre-selected set of vibration mode
    shapes. A comparative analysis is conducted between the displacement field reconstructions
    obtained through our proposed methodology, the conventional iFEM, and the combined
    use of the iFEM and SEA with a uniformly distributed sensor pattern. The results
    from our approach reveal a significant enhancement in monitoring capabilities
    compared to the standard iFEM algorithm, despite utilizing the same number of
    sensors. 2. Theoretical Background 2.1. Inverse Finite Element Method Within the
    iFEM framework, the structural domain is discretized with a set of inverse finite
    elements. The algorithm computes the nodal displacements of the discretized mesh,
    taking into account the structure’s geometry, boundary conditions, and a set of
    in situ strain measurements. In the present work, an element formulation based
    on the first-order shear deformation theory has been adopted. Therefore, the displacement
    field can be described in terms of the membrane displacements, 𝑢(𝒙) and 𝑣(𝒙) ,
    the deflection 𝑤(𝒙) , as well as the rotations around the mid-plane axis 𝑥 and
    𝑦 , expressed by 𝜃 𝑥 (𝒙) and  𝜃 𝑦 (𝒙) , respectively ( 𝒙 denotes the mid-plane
    coordinates). The Cartesian displacement components are written as: 𝑢 𝑥 =𝑢(𝒙)+𝑧
    𝜃 𝑦 (𝒙) 𝑢 𝑦 =𝑣(𝒙)−𝑧 𝜃 𝑥 (𝒙) 𝑢 𝑧 =𝑤(𝒙) (1) where 𝑧∈[−ℎ,+ℎ] indicates the through-the-thickness
    coordinate. The strain field is obtained by derivation of the kinematic variables:
    ⎧ ⎩ ⎨     𝜀 𝑥𝑥 𝜀 𝑦𝑦 𝛾 𝑥𝑦 ⎫ ⎭ ⎬     = ⎧ ⎩ ⎨     𝑢 𝑥,𝑥 𝑢 𝑦,𝑦 𝑢 𝑥,𝑦 +
    𝑢 𝑦,𝑥 ⎫ ⎭ ⎬     = ⎧ ⎩ ⎨     𝑢 ,𝑥 𝑣 ,𝑦 𝑣 ,𝑥 + 𝑢 ,𝑦 ⎫ ⎭ ⎬     +𝑧 ⎧ ⎩
    ⎨     𝜃 𝑦,𝑥 − 𝜃 𝑥,𝑦 𝜃 𝑦,𝑦 − 𝜃 𝑥,𝑥 ⎫ ⎭ ⎬     =𝒆+𝑧𝒌 { 𝛾 𝑥𝑧 𝛾 𝑦𝑧 }={ 𝑢 𝑥,𝑧
    + 𝑢 𝑧,𝑥 𝑢 𝑦,𝑧 + 𝑢 𝑧,𝑦 }={ 𝑤 ,𝑥 + 𝜃 𝑦 𝑤 ,𝑦 − 𝜃 𝑥 }=𝒈 (2) where 𝒆 , 𝒌 , and 𝒈  are
    the membrane, bending, and transverse shear section strains, respectively. The
    goal of the inverse finite element method is to determine the nodal degrees of
    freedom values that minimize the error between the reconstructed strain field
    and the one measured using a discrete set of points. For a single inverse element,
    the error in the reconstruction is quantified by means of a weighted least-squares
    functional, defined as follows: 𝚽 𝑒 = 𝑤 𝑚 ‖( 𝒆 𝑖 − 𝒆 𝜀 𝑖 )‖ 2 + 𝑤 𝑏 (2ℎ) 2 ‖(
    𝒌 𝑖 − 𝒌 𝜀 𝑖 )‖ 2 + 𝑤 𝑠 ‖( 𝒈 𝑖 − 𝒈 𝜀 𝑖 )‖ 2 (3) where the superscript 𝜀 is used
    to denote the values measured from an in situ strain sensor. In Equation (3) 𝑤
    𝑚 , 𝑤 𝑏 , and 𝑤 𝑠 are positive-valued weighting constants associated with membrane
    strains, bending curvatures, and shear strains, respectively. In the present work,
    the structure’s geometry is discretized with four-node inverse elements, known
    in the literature as iQS4 (displayed in Figure 1a). The kinematic variables inside
    each element are, thus, interpolated using a set of anisoparametric [38] shape
    functions: [𝑢  𝑣  𝑤   𝜃 𝑥  𝜃 𝑦 ] 𝑇 = 𝑵 𝑒 𝒖 𝑒         (  𝒖 𝑒 𝑇 =[ 𝑢 𝑖   𝑣 𝑖   𝑤
    𝑖   𝜃 𝑥 𝑖  𝜃 𝑦 𝑖  𝜃 𝑧 𝑖 ], 𝑖=1, …, 4) (4) Figure 1. (a) iQS4 element; (b) discrete
    surface strains at i-th measurement point. In this context, 𝑵 𝑒 denotes the matrix
    of the shape functions, and 𝒖 𝑒 is the vector representing the nodal degrees of
    freedom for each element. A single element is characterized by 24 DOF, consisting
    of three displacements and three rotations per node. It should be noted that 𝜃
    𝑧 𝑖 denotes the drilling rotation of the i-th node. Although not considered a
    kinematic variable in the FSDT formulation, it is utilized in the element interpolation
    of membrane displacements. By substituting Equation (4) into Equation (2), the
    numerical strain components can be expressed as the product between the matrices
    𝑩 𝑚 , 𝑩 𝑏 , and 𝑩 𝑠 containing the derivatives of the shape functions, and the
    element nodal displacements 𝒖 𝑒 . 𝒆( 𝒖 𝑒 )= 𝑩 𝑚 𝒖 𝑒        𝒌( 𝒖 𝑒 )= 𝑩 𝑏 𝒖 𝑒        𝒈(
    𝒖 𝑒 )= 𝑩 𝑠 𝒖 𝑒 (5) If an element is equipped with 𝑛 strain sensors, the least-squares
    functional can be rewritten by means of the Euclidean norm, as follows: 𝚽 e (
    𝒖 𝑒 )= 1 𝑛 ⎛ ⎝ ⎜ ⎜ ⎜ ⎜ 𝑤 𝑚 ∫ 𝐴 𝑒 ∑ 𝑖=1 𝑛 (𝒆 ( 𝒖 𝑒 ) 𝑖 − 𝒆 𝜀 𝑖 ) 2 + 𝑤 𝑏 (2ℎ) 2
    ∫ 𝐴 𝑒 ∑ 𝑖=1 𝑛 (𝒌 ( 𝒖 𝑒 ) 𝑖 − 𝒌 𝜀 𝑖 ) 2 + 𝑤 𝑠 ∫ 𝐴 𝑒 ∑ 𝑖=1 𝑛 (𝒈 ( 𝒖 𝑒 ) 𝑖 − 𝒈 𝜀
    𝑖 ) 2 ⎞ ⎠ ⎟ ⎟ ⎟ ⎟ (6) By inserting Equation (5) into the functional of Equation
    (6) and minimizing it with respect to 𝒖 𝑒 , one obtains a system of linear equations:
    ∂𝚽( 𝒖 𝑒 ) ∂ 𝒖 𝑒 =𝟎    →     𝑲 𝑒 𝒖 𝑒 = 𝑭 𝑒 (7) with 𝑲 𝑒 = ∫ 𝐴 𝑒 ( 𝑤 𝑚 𝑩 𝑚 𝑇 𝑩 𝑚
    + (2ℎ) 2 𝑩 𝑏 𝑇 𝑩 𝑏 + 𝑤 𝑠 𝑩 𝑠 𝑇 𝑩 𝑠 )𝑑𝐴 (8) 𝑭 𝑒 = 1 𝑛 ∫ 𝐴 𝑒 ∑ 𝑖=1 𝑛 ( 𝑤 𝑚 𝑩 𝑚 𝑇
    𝒆 𝜀 𝑖 + (2ℎ) 2 𝑩 𝑏 𝑇 𝒌 𝜀 𝑖 + 𝑤 𝑠 𝑩 𝑠 𝑇 𝒈 𝜀 𝑖 )𝑑𝐴 (9) Given a structure equipped
    with a set of surface-mounted strain sensors, the experimental membrane and curvature
    strains at the i-th measurement point (Figure 1b) can be derived as follows: 𝒆
    𝜀 𝑖 = 1 2 ⎧ ⎩ ⎨     𝜀 + 𝑥𝑥 + 𝜀 − 𝑥𝑥 𝜀 + 𝑦𝑦 + 𝜀 − 𝑦𝑦 𝜀 + 𝑥𝑦 + 𝜀 − 𝑥𝑦 ⎫ ⎭ ⎬
                𝒌 𝜀 𝑖 = 1 2ℎ ⎧ ⎩ ⎨     𝜀 + 𝑥𝑥 − 𝜀 − 𝑥𝑥 𝜀 + 𝑦𝑦 − 𝜀 − 𝑦𝑦 𝜀 +
    𝑥𝑦 − 𝜀 − 𝑥𝑦 ⎫ ⎭ ⎬     (10) The superscripts + and − refer to the quantities
    corresponding to the top and bottom surface, respectively. It is not mandatory
    to equip every element in the mesh with sensors; the iFEM technique remains numerically
    stable even if certain elements lack in situ strain measurements. In such instances,
    the associated weights are assigned smaller values, e.g., 10 −4 (otherwise they
    are set to unity). In general, transverse shear strains cannot be directly measured
    using surface-mounted strain gauges: therefore, 𝒈 𝜀 𝑖 is considered as 𝟎 , and
    the corresponding weight, 𝑤 𝑠 , is selected to be small. The matrices 𝑲 𝑒 and
    𝑭 𝑒 , computed for each element within the domain, can be assembled into a system
    of linear equations for the global degrees of freedom: 𝑲𝑼=𝑭 (11) where 𝑲 is a
    matrix depending on the shape functions and strain-sensor locations, whereas 𝑭
    is a vector which encompasses the measured data. The matrix 𝑲 is computed and
    inverted only once (after applying the appropriate boundary conditions) in the
    monitoring process, while the vector 𝑭 needs to be updated each time new strain
    measures are acquired. 2.2. Smoothing Element Analysis To enhance the precision
    and cost effectiveness of shape-sensing analysis, especially when dealing with
    a limited number of sensors, a viable strategy involves pre-extrapolating the
    structure’s strain field. The inverse problem is then addressed by means of the
    iFEM, utilizing the pre-extrapolated data as an input [39]. This approach enables
    the use of a finer mesh with a large number of measurement samples, ensuring higher
    accuracy in the reconstruction of the displacement field. Smoothing element analysis
    (SEA) is a robust technique, which can be employed to pre-extrapolate the input
    strain field. The numerical formulation of SEA relies on a variational principle
    employing a penalized discrete least-squares (PDLS) functional [40]. The algorithm
    adopts a finite element approach, in which the geometry is discretized into a
    triangular mesh. Let us define a general measured strain as 𝜀 ℎ 𝑖 (which could
    be 𝜀 + 𝑥𝑥 , for example), while the corresponding strain after smoothing is denoted
    as 𝜀( 𝒙 𝑖 ) . For a single mesh element (shown in Figure 2), the PDLS functional
    is expressed as: Ψ= 1 𝑛 ∑ 𝑖=1 𝑛 ( 𝜀( 𝑥 𝑖 )− 𝜀 ℎ 𝑖 ) 2 +𝛼 ∫ 𝑆 (  (  𝜀 ,𝑥 − 𝜅 𝑥
    ) 2 + (  𝜀 ,𝑦 − 𝜅 𝑦 ) 2 )𝑑𝑆+𝛽𝑆  ∫ 𝑆 (  (  𝜅 𝑥,𝑥 ) 2 + (  𝜅 𝑦,𝑦 ) 2 + 1 2 (  𝜅
    𝑥,𝑦 + 𝜅 𝑦,𝑥 ) 2 )𝑑𝑆 (12) Figure 2. Triangular smoothing element with nodes 1,
    2, 3 and their corresponding DOF. Here, 𝑛 is the total number of measurements
    within the element; (·) ,𝑥 and (·) ,𝑦 represent the partial derivative operator
    with respect to 𝑥 and 𝑦 ; 𝜅 𝑥 and 𝜅 𝑦  are the analytical counterparts of the
    partial derivatives of the experimental strain along directions 𝑥 and 𝑦 , respectively.
    The first term in the equation is a discrete least-squares functional, which enforces
    a match between the extrapolated strain field and the experimental strain data.
    The second term introduces a penalty constraint functional, which depends on the
    dimensionless parameter 𝛼 . For large values of 𝛼 (e.g., 10 2 – 10 6 ), such term
    ensures the limiting condition of 𝐶 1 continuity for 𝜀 . The third term serves
    as a regularization functional, relying on the positive parameter 𝛽 . This term
    imposes an additional constraint on the derivatives 𝜅 1 and 𝜅 2 , the severity
    of which is governed by the value of the parameter 𝛽 . Particularly, when the
    sampled data is reasonably accurate, 𝛽 should be significatively small with respect
    to 𝛼 (e.g., 10 −3 – 10 −4 ). The field variables are expressed with an anisoparametric
    interpolation within each element: 𝜀=𝑷𝒔+𝑴 𝒔 𝑥 +𝑳 𝒔 𝑦 𝜅 𝑥 =𝑷 𝒔 𝑥 𝜅 𝑦 =𝑷 𝒔 𝑦 (13)
    where 𝒔= [ 𝜀 1 ,  𝜀 2 ,  𝜀 3 ] 𝑇 ,   𝒔 𝑥 = [ 𝜅 𝑥1 ,  𝜅 𝑥2 ,  𝜅 𝑥3 ] 𝑇 , 𝒔 𝑦 =
    [ 𝜅 𝑦1 ,  𝜅 𝑦2 ,  𝜅 𝑦3 ] 𝑇 are the vectors of the nodal DOF of the element, 𝑷
    is a row vector of linear shape functions, while 𝑴 and 𝑳 are the row vectors of
    quadratic shape functions. We can define 𝒅 𝑒 = [𝒔,  𝒔 𝑥 , 𝒔 𝑦 ] 𝑇 , an array containing
    the nine unknowns of each element. By substituting Equation (13) into the functional
    of Equation (12), the condition for which Ψ is minimized can be written as: ∂Ψ(
    𝒅 𝑒 ) ∂ 𝒅 𝑒 =0 ⇒ 𝑨 𝑒 𝒅 𝑒 = 𝑯 𝑒 (14) 𝑨 𝑒 = 1 𝑛 ∑ 𝑖=1 𝑛 [  (𝑵( 𝒙 𝑖 )) 𝑇 (𝑵( 𝒙 𝑖
    ))]+𝛼  ∫ 𝑠 𝒁 𝛼 𝑇 𝒁 𝛼  𝑑𝐴+𝛽𝑆  ∫ 𝑠 𝒁 𝛽 𝑇 𝑫 𝛽 𝒁 𝛽  𝑑𝐴 (15) 𝑯 𝑒 = 1 𝑛  ∑ 𝑖=1 𝑛 (𝑵(
    𝒙 𝑖 )) 𝑇 𝜀 ℎ 𝑖 (16) In which: 𝑵= [𝑷, 𝑴, 𝑳] 𝑇 (17) 𝒁 𝛼 =[ 𝑷 ,𝑥 𝑷 ,𝑦 𝑴 ,𝑥 −𝑷 𝑴 ,𝑦
    𝑳 ,𝑥 𝑳 ,𝑦 −𝑷 ] (18) 𝒁 𝛽 = ⎡ ⎣ ⎢ ⎢ ⎢ 𝟎 𝟎 𝟎 𝑷 ,𝑥 𝟎 𝑷 ,𝑦 𝟎 𝑷 ,𝑦 𝑷 ,𝑥 ⎤ ⎦ ⎥ ⎥ ⎥ (19)
    𝑫 𝛽 = ⎡ ⎣ ⎢ ⎢ 1 0 0 0 1 0 0 0 1/2 ⎤ ⎦ ⎥ ⎥ (20) Note, that if an element does not
    have any input strain, both 𝑯 𝑒 and the first term of 𝑨 𝑒 will be absent, and
    the second and third term of Equation (15) will be the only ones contributing
    to the element stiffness matrix. After discretizing the geometry with multiple
    smoothing elements, a global system of equations is assembled, which can easily
    be solved for the unknown nodal degrees of freedom of the mesh (i.e., the strain
    field, and its derivatives in each node). Although the imposition of boundary
    conditions is not mandatory in smoothing element analysis, they may be applied
    if the exact solution is known in specific regions [33]. Once the linear system
    is solved, it is possible to compute the strain field at any arbitrary point in
    the domain by means of the shape functions. 2.3. Multi-Objective Genetic Algorithm
    A genetic algorithm (GA) is a heuristic optimization approach inspired by natural
    selection principles [41]. The process involves initiating a population, conducting
    reproduction, mutating genes, and applying natural selection to attain an optimal
    population. In a GA, a chromosome (or individual) represents a potential solution
    to the problem the algorithm is trying to solve. Chromosomes are composed of discrete
    units known as genes. Each gene regulates specific features of the chromosome.
    A GA operates with a collection of chromosomes, forming a population that is typically
    initialized randomly. As the search progresses, the population evolves to include
    increasingly fit solutions, until convergence is reached. A GA employs two key
    operators for generating new solutions from existing ones: crossover and mutation
    [42]. In the crossover process, two chromosomes, known as parents, are combined
    to produce an offspring. The parents are chosen using a selection operator that
    favors fitter individuals from the existing population. Through the iterative
    application of the crossover operator, genes from superior chromosomes are more
    likely to be incorporated into the population, contributing to the overall convergence
    to a favorable solution. The mutation operator introduces random changes to the
    characteristics of the chromosomes. Mutation is pivotal in a GA as it injects
    genetic diversity into the population, aiding the search in escaping local optima.
    By combining these mechanisms, a GA dynamically refines its population, iteratively
    improving solutions to reach an optimal outcome. For multi-objective optimization
    problems, attaining a solution that is optimal for every objective is often impossible
    [43]. Instead, the concept of Pareto domination and Pareto optimal solutions are
    introduced. NSGA-II, a multi-objective genetic algorithm, serves as an optimization
    tool to find a Pareto-optimal set of solutions. NSGA-II works similarly to a single-objective
    GA, but incorporates specific operations in the selection process [44]: Fast non-dominated
    sorting approach: The population is sorted into different non-dominated fronts.
    Individuals in the first non-dominated front are identified, and their rank is
    set to 1. The remaining individuals in the population, excluding those with rank
    1, continue to be sorted using the same procedure. This process continues until
    all fronts are identified. Crowding distance assignment: Individuals with the
    same rank are arranged based on the crowding distance, which represents the average
    distance between a solution and its neighboring solutions on the front in the
    objective space. Selection operator: The binary tournament selection is employed
    to choose the parents. Two individuals are randomly selected from the population,
    and if their ranks differ, the one with the smaller rank is chosen. If their ranks
    are the same, the individual with the larger crowding distance is selected. This
    method ensures a more even distribution of solutions along the Pareto front, preventing
    overcrowding in specific regions. 2.4. Proposed Methodology In this study, SEA
    is employed to pre-extrapolate the strain field, which serves as input for the
    inverse finite element method. Through the smoothing process, a continuous description
    of the strain field is produced, allowing the application of the iFEM on a fine
    mesh. The use of a fine mesh is theoretically feasible even with a relatively
    low number of sensors in the standard iFEM, as the weights of the individual elements
    can be adjusted to account for the presence or absence of a measurement. However,
    maintaining a sufficient ratio between the number of elements with strain data
    and the total number of elements in the mesh is crucial to avoid a significant
    degradation of the results. Therefore, employing SEA allows the use of particularly
    dense meshes, where each element has measurement data, ensuring high accuracy.
    To obtain good results though, it is crucial that the pre-extrapolated strain
    field closely approximates the real one. To accomplish this, we optimize the sensor
    placement process by means of a genetic algorithm. Since a structure can undergo
    various loading conditions, it makes sense to perform a multi-objective optimization
    based on multiple operational scenarios. Therefore, the proposed optimization
    strategy involves the use of NSGA-II. For the case studies under consideration,
    we optimized the sensor placement to enable SEA to accurately reconstruct the
    deformation fields associated with a specific set of structural mode shapes. We
    made this choice since it is generally possible to decompose a general linear
    state of deformation into a sum of weighted mode shapes. The starting point in
    the process is the finite element (FE) model of the structure (in our case a plate),
    which serves a dual purpose: it generates the discrete strain data (simulating
    what would be read by actual sensors in real-world applications) and provides
    a reference for evaluating the accuracy of the results obtained from the shape-sensing
    code. A modal analysis is performed on the FE model, allowing us to extract the
    first 𝑁 𝑚 natural modes of the structure. The number of sensors to be placed on
    the structure, denoted as 𝑁 𝑠 , is determined a priori. It is chosen in such a
    way that the measurement points are sufficient for pre-extrapolating the strain
    field in an appropriate manner, considering both the field behavior and the error
    level; consequently, a more complex strain field requires a higher number of installed
    sensors. Certainly, the number of measurement points was limited to a reasonable
    value, ensuring that the use of pre-extrapolation remains beneficial. Therefore,
    the goal of the optimization is to find a set of Pareto optimal sensor positions.
    The possible locations for the sensors are selected among the centroids of four-node
    quadrilateral shell elements in the FE mesh. Once the number of sensors to be
    installed is determined, a generic chromosome is defined by a matrix of 𝑁 𝑠 rows.
    Each row (gene) is a vector ( 𝑥 𝑠 ,  𝑦 𝑠 ) of the coordinates extracted from the
    set of centroids belonging to the FE mesh. The number of individuals in the population
    is referred to as 𝑁 𝑝𝑜𝑝 . The initial population is randomly generated, with care
    taken to avoid the rare event of duplicating the same individual in the process.
    In a subsequent step, the fitness of each chromosome is evaluated. Thus, for each
    chromosome, the six strain components ( 𝑒 𝑥𝑥 ,  𝑒 𝑦𝑦 ,  𝑒 𝑥𝑦 ,  𝑘 𝑥𝑥 ,  𝑘 𝑦𝑦 ,  𝑘
    𝑥𝑦 ) are reconstructed through smoothing element analysis, and the pre-extrapolated
    values are compared with the FEM ones at a set of sampling points for each target
    mode. In this work, since all the considered cases exhibit zero membrane strain,
    the objective function to minimize is chosen as the sum of the root mean square
    error in the SEA extrapolation across the three curvature components for a single
    mode: 𝑓 𝑟 = 𝑤 𝑟 1 1 𝑆 ∑ 𝑖=1 𝑆 ( 𝑘 𝑥𝑥 𝑆𝐸𝐴 𝑖 − 𝑘 𝑥𝑥 𝐹𝐸𝑀 𝑖 ) 2 − − − − − − − − −
    − − − − − − − − − − − −  ⎷   + 𝑤 𝑟 2 1 𝑆 ∑ 𝑖=1 𝑆 ( 𝑘 𝑦𝑦 𝑆𝐸𝐴 𝑖 − 𝑘 𝑦𝑦 𝐹𝐸𝑀 𝑖
    ) 2 − − − − − − − − − − − − − − − − − − − − −  ⎷   + 𝑤 𝑟 3 1 𝑆 ∑ 𝑖=1 𝑆 ( 𝑘
    𝑥𝑦 𝑆𝐸𝐴 𝑖 − 𝑘 𝑥𝑦 𝐹𝐸𝑀 𝑖 ) 2 − − − − − − − − − − − − − − − − − − − − −  ⎷             (𝑟=1,…,  𝑁
    𝑚 ) (21) where 𝑆 is the number of sampling points in which the rms error is evaluated
    and 𝑤 𝑟 𝑖  (𝑖=1, 2, 3) are the weights associated with the rms error of each component.
    In our study, each weight was set to 1, although, in general, it is theoretically
    possible to make more suitable choices based on the deformation field to be pre-extrapolated.
    Since we are in a multi-objective optimization context, we will need to evaluate
    𝑁 𝑚 different fitness functions (one for each mode shape), with the goal of finding
    the Pareto optimal solutions. In this study, the sampling points have been selected
    as a subset of the centroids of the FE mesh. In principle, the entire set of centroids
    could be used for this purpose, but given the large number, it leads to a significant
    increase in computational time when running the genetic algorithm. In Figure 3a,
    a square plate with the FE mesh and the set of centroids from which possible sensor
    coordinates are extracted is presented as an example, while in Figure 3b, a subset
    of sampling points is illustrated. Figure 3. (a) Example of FE mesh with element
    centroids; (b) example of evaluation points. After evaluating the fitness of each
    individual in the population, a ranking is performed based on the Pareto fronts
    and crowding distance, as described in the previous section. To create the next
    generation, the parents are selected through binary tournament selection. Crossover
    can occur with a probability denoted as 𝑝 𝑐𝑟𝑜𝑠𝑠 . The present study employs a
    uniform crossover, in which each gene is selected randomly from one of the corresponding
    genes of the parent chromosomes with equal probability. In Figure 4a, an example
    of such crossover in our problem is illustrated. The blue and red dot patterns
    on the left represent Parent 1 and Parent 2, respectively. Following the crossover,
    the two resulting children inherit some sensor positions from Parent 1 (blue dots)
    and the remaining positions from Parent 2 (red dots). After the reproduction phase,
    some offspring may undergo a mutation process. For each offspring, a random real
    number between 0 and 1 is drawn, and if it exceeds 𝑝 𝑚𝑢𝑡 , the mutation probability,
    then the mutation occurs. In this work, mutation involves changing the positions
    of 𝑛 𝑚𝑢𝑡 random sensors belonging to the individual’s pattern with other random
    positions, among the set of centroids in the FE model. Moreover, 𝑛 𝑚 , the number
    of mutated genes, varies between 1 and 𝑛 𝑚𝑎𝑥 𝑚𝑢𝑡 (it should not be too high otherwise
    its effects may be too disruptive). In the studied cases, the value 𝑛 𝑚𝑎𝑥 𝑚𝑢𝑡
    varied depending on the number of sensors to be installed on the structure. Figure
    4b shows an example of the mutation in our approach: on the left, the individual
    before mutation with two circled sensors randomly chosen to undergo the process;
    on the right, the individual after mutation, with the purple dots indicating the
    new positions of the two mutated sensors. Figure 4. (a) Uniform crossover: blue
    dots represent sensor positions coming from Parent 1 meanwhile red dots are those
    coming from Parent 2; (b) mutation process: yellow dots represent sensor positions
    of the original offspring meanwhile purple dots are the mutated ones. At the end
    of the mutation process, elitism is applied to form the new population for reproduction,
    keeping only the best 𝑁 𝑝𝑜𝑝 individuals among the parents, offspring, and mutated
    individuals. A ranking is needed to choose the best 𝑁 𝑝𝑜𝑝 solutions and, thus,
    the non-dominated sorting and crowding distance are employed. The use of elitism
    ensures that there is no loss of good genes between generations, leading to a
    monotonic convergence into the optimal solution. The selection, crossover, mutation,
    and elitism operators are applied at each iteration of the genetic algorithm until
    convergence, or a maximum number of iterations is reached, at which point the
    whole process is terminated. In Figure 5, a flowchart that depicts the main steps
    in the optimization process is depicted. Figure 5. Flowchart of the optimization
    process. 3. Case Studies The proposed approach is validated using two different
    case studies: a rectangular cantilevered plate and a clamped square plate. 3.1.
    Rectangular Cantilevered Plate The first case study focuses on a cantilevered
    plate, as depicted in Figure 6, with dimensions of 10 m in length, 4 m in width,
    and a thickness of 0.01 m . On the left vertical side, the following geometric
    constraints are enforced: 𝑢=𝑣=𝑤=0  and 𝜃 𝑥 = 𝜃 𝑦 = 𝜃 𝑧 =0 . The structure is assumed
    to be made of an isotropic material, with properties similar to an aluminum alloy
    ( 𝐸=70 Gpa , 𝜈=0.3 , 𝜌=2700 kg/ m 3 ). The plate was modeled using MSC NASTRAN,
    with a mesh comprising 162 × 30 CQUAD4 elements, which was selected following
    a convergence study, as illustrated on the left in Figure 6. Employing the SOL
    103 solver, a modal analysis was conducted to extract the structure’s first three
    natural modes, identified at frequencies of 0.0841 Hz , 0.4398 Hz , and 0.5247
    Hz . The first and third modes exhibit a purely flexural behavior, while the second
    mode is a torsional one. As previously mentioned, the pre-extrapolation produces
    a continuous strain field across the entire structure, enabling the use of a finer
    mesh in the reconstruction process. Therefore, the mesh shown on the left of Figure
    6 is also employed by the smoothed iFEM. In this case study, we make use of 12
    strain rosettes for the monitoring of the three mode shapes. Indeed, if the membrane
    strain is zero, as in this problem, it is sufficient to place the strain rosettes
    in only one area, among the top and bottom surface of Figure 1b. To optimize the
    sensor positioning, it is necessary to define a mesh for the smoothing element
    analysis (SEA). This triangular mesh consists of 320 elements, as shown in the
    middle of Figure 6. It should be noted that the mesh is finer near the plate’s
    constraint and gradually becomes sparser away from it. This design aims to capture
    steep strain gradients near the constraint, effectively. The mesh dimensions of
    the SEA were chosen following a series of tests to ensure that the pre-extrapolation
    technique adequately captured the shape and values of the strain field, while
    also taking into account the computational time of the pre-extrapolation (which
    affects both the time needed in the optimization process and the applicability
    of the method in real-time applications). Figure 6. Cantilevered rectangular plate.
    FE mesh (left); SEA mesh (center); standard iFEM mesh (right). The third, and
    final, mesh utilized in this analysis is illustrated on the right in Figure 6
    and corresponds to the standard iFEM (without pre-extrapolation and optimization).
    It comprises 6 × 2 inverse elements, each featuring a strain rosette at the centroid.
    Thus, the number of elements in the standard iFEM mesh was chosen to be equal
    to the number of sensors to be installed. This is because, when so few measurement
    points are present on the structure, using a finer mesh with some empty elements
    leads to the degradation of the results. The multi-objective genetic algorithm
    was run with a population of 300 individuals for 100 iterations, at the end of
    which convergence was achieved. The crossover and mutation probability are set
    at 𝑝 𝑐𝑟𝑜𝑠𝑠 =0.9 and 𝑝 𝑚𝑢𝑡 =0.1 , respectively; the maximum number of mutated genes
    is selected as 𝑛 𝑚𝑎𝑥 𝑚𝑢𝑡 =2 ; and the number of elites is equal to 𝑁 𝑝𝑜𝑝 (thus,
    selecting the top 300 individuals among the parents, offspring, and mutants).
    The rms error for the fitness function was calculated using a set of 280 sampling
    points taken from the centroids of the FEM mesh. The optimization process was
    repeated multiple times to account for the inherent randomness of the genetic
    algorithm. From all the runs, the final population that exhibited superior global
    fitness was selected for extracting a single solution, which was then used in
    the comparison with the standard iFEM. To pick a single optimal chromosome from
    the final population, we selected a solution from the first Pareto front with
    well-balanced results for all three modes. The chosen sensor arrangement is illustrated
    in Figure 7a. As can be observed, most of the measurement points are arranged
    near the fixed end, where there is a higher strain concentration. Additionally,
    note that the obtained distribution is slightly asymmetric. This issue could be
    easily addressed by introducing constraints in the optimization process. However,
    in the present study we decided to follow a more general approach. In Figure 7b,
    a uniformly distributed sensor pattern is also shown, intended for validating
    the optimization process. Such pattern will be utilized for SEA pre-extrapolation
    and, subsequently, the iFEM will be applied; the results obtained will then be
    compared with those coming from the sensor layout generated through optimization.
    Figure 7. (a) Selected optimal sensor arrangement for the cantilevered rectangular
    plate; (b) uniform sensor placement used for validation. By applying the smoothing
    element analysis with the optimal sensor arrangement, we are able to generate
    the continuous spatial distribution of the three curvature components 𝑘 𝑥𝑥 , 𝑘
    𝑦𝑦 , and 𝑘 𝑥𝑦 for each mode. In Figure 8, the curvature distribution of 𝑘 𝑥𝑥 (in
    1/m ) pre-extrapolated with the pattern from Figure 7a is shown as an example
    and is compared to the reference field provided by the finite element model. Figure
    8. Pre-extrapolated 𝑘 𝑥𝑥  ( 1 m )  on the left vs. reference on the right for
    the first 3 modes of the cantilevered plate. As can be observed, the reconstructed
    distributions visually appear very similar to their reference counterpart, with
    nearly coincident scale values. A similar behavior is exhibited by the other two
    curvature components. Overall, the correlation for 𝑘 𝑦𝑦 tends to be slightly lower
    for each mode, given that it is the smallest among the components. Consequently,
    its reconstruction is less accurate, though its influence on the displacement
    field is also minor. The smoothed field obtained through the SEA is then employed
    as input for the inverse finite element method utilizing the fine mesh shown on
    the left in Figure 6. For the three mode shapes under consideration, the only
    displacement field component different from zero is 𝑤 (since 𝑢=𝑣=0 ). In Figure
    9, a comparison is shown between the deflection reconstructed by the iFEM aided
    by optimization and pre-extrapolation (on the left), and the reference solution
    from the FE model (on the right). The results are presented in dimensional form
    ( m ). By analyzing the graphs, it appears evident that the selected sensor layout
    effectively captures the trends and values of the 𝑤 field. Figure 9. Cantilevered
    plate’s first three modes deflection 𝑤 (m) for iFEM aided by NSGA-II and SEA (left)
    and reference solution (right). To better quantify the method’s accuracy, we define
    the reconstruction error as follows: 𝑒𝑟𝑟(𝒙)= | 𝑤 𝑟𝑒𝑐 (𝒙)− 𝑤 𝑟𝑒𝑓 (𝒙)| 𝑚𝑎𝑥(| 𝑤 𝑟𝑒𝑓
    (𝒙)|) ·100 (22) where 𝑤 𝑟𝑒𝑐 is the reconstructed deflection and 𝑤 𝑟𝑒𝑓 is the reference
    FE one. This metric allows us to compare the shape-sensing capabilities of the
    iFEM, the iFEM with pre-extrapolation using the pattern in Figure 7b, and the
    iFEM with pre-extrapolation using the optimized pattern in Figure 7a. The error
    percentage for each of these three approaches is presented in Figure 10. As evident
    from the images on the left, the standard iFEM accurately captures the first two
    modes with minimal errors (below 2% in both cases). However, it fails in reconstructing
    appropriately the third mode, with a maximum error of 16%. In the center of Figure
    10, the reconstruction error using the pattern from Figure 7b is depicted. Notably,
    this sensor layout shows no improvement over the standard iFEM for the first mode,
    and it even worsens the results for the second one (increasing the maximum error
    and displaying a broader error distribution across the domain). However, there
    is a substantial increase in accuracy for the third mode, with improvements exceeding
    10% on the maximum error. On the right, the error trends obtained using the optimized
    pattern from Figure 7a are shown. This layout yields lower error values compared
    to the other two approaches (maximum values below 1% for the first two modes and
    around 2.6% for the third), with more confined error distributions in space. This
    comparison highlights the significant benefits, in terms of overall accuracy,
    when employing pre-extrapolation coupled with optimal sensor placement compared
    to conventional iFEM and smoothed iFEM with a uniformly distributed sensor layout.
    Figure 10. Cantilevered plate’s reconstruction percentage error of the first three
    modes for standard iFEM (left), smoothed iFEM with uniformly distributed sensors
    (center), and smoothed iFEM with optimal layout (right). 3.2. Clamped Square Plate
    The second case study considered is a square plate clamped on all sides, as shown
    in Figure 11. The plate has dimensions of 1 m in length, 1 m in width, and a thickness
    of 0.01 m . The geometric constraints enforcing 𝑢=𝑣=𝑤=0  and 𝜃 𝑥 = 𝜃 𝑦 = 𝜃 𝑧 =0
    are applied on each side. The structure is assumed to be made of an isotropic
    material, with properties similar to an aluminum alloy ( 𝐸=70 Gpa , 𝜈=0.3 , 𝜌=2700
    kg/ m 3 ). The plate was modeled using MSC NASTRAN, with a mesh comprising 90
    × 90 CQUAD4 elements, which was selected after a convergence study, as illustrated
    on the left in Figure 11. Employing the SOL 103 solver, modal analysis was conducted
    to extract the structure’s first four natural modes, identified at frequencies
    of 88.12 Hz , 179.57 Hz , 179.57 Hz , and 264.40 Hz . As conducted in the previous
    case study, the mesh shown on the left of Figure 11 is also employed by the smoothed
    iFEM. In this study, we employ 36 strain rosettes to monitor the four mode shapes.
    In the sensor positioning optimization, we make use of a triangular SEA mesh of
    200 elements, depicted in the middle of Figure 11. Similar considerations apply
    to the SEA mesh dimensions as those made for the clamped rectangular plate. The
    final mesh, represented on the right in Figure 11, corresponds to the standard
    iFEM one and consists of 6 × 6 inverse elements, each featuring a strain rosette
    at its centroid. Figure 11. Clamped square plate. FE mesh (left); SEA mesh (center);
    standard iFEM mesh (right). Within the genetic algorithm, a population of 300
    chromosomes was employed, and the maximum number of iterations was set at 150.
    The crossover and mutation probability are set at 𝑝 𝑐𝑟𝑜𝑠𝑠 =0.9 and 𝑝 𝑚𝑢𝑡 =0.1
    , respectively; the maximum number of mutated genes is selected as 𝑛 𝑚𝑎𝑥 𝑚𝑢𝑡 =3
    ; and the number of elites is equal to 𝑁 𝑝𝑜𝑝 . In the calculation of the fitness
    function, a regularly spaced grid of 289 sampling points was utilized. In this
    case study as well, the optimization process was repeated multiple times, and
    the optimal individual for comparison with the standard iFEM was chosen from the
    first Pareto front among those displaying balanced results for each of the four
    modes. The selected pattern is illustrated in Figure 12a. On the other hand, a
    uniformly distributed sensor pattern used for validating the optimization process
    is displayed in Figure 12b. Figure 12. (a) Selected optimal sensor arrangement
    for the clamped square plate; (b) uniform sensor placement used for validation.
    In Figure 13, the SEA 𝑘 𝑥𝑥 ( 1/m ) curvature obtained using the optimal sensor
    pattern in Figure 12a is compared with the FEM reference for each mode. Figure
    13. Pre-extrapolated 𝑘 𝑥𝑥  ( 1 m )  on the left vs. reference on the right for
    the first four modes of the clamped plate. The shape of the field is accurately
    captured and, numerically, the values are closely aligned. Similar behaviors are
    observed for the other two curvature components, 𝑘 𝑦𝑦 and 𝑘 𝑥𝑦 , and are not reported
    for brevity. Since the sensor pattern is not symmetrical, asymmetry is evident
    in the pre-extrapolated curvatures, subsequently affecting the reconstructed displacement
    field. However, it should again be noted that adopting simple strategies can easily
    rectify such asymmetry. For the four mode shapes under consideration, the only
    displacement field component different from zero is 𝑤 (since 𝑢=𝑣=0 ). In Figure
    14, a comparison is shown between the deflection (in m ) reconstructed by the
    iFEM aided by optimization and pre-extrapolation (on the left), and the reference
    solution from the FE model (on the right). By analyzing the graphs, one can observe
    that also in this case study the optimal sensor layout can reconstruct the spatial
    distribution of 𝑤 appropriately. Figure 14. Clamped plate’s first four modes deflection
    𝑤 (m) for iFEM aided by NSGA-II and SEA (left) and reference solution (right).
    We use the error defined in Equation (22) to draw a comparison between the shape-sensing
    performance among the standard iFEM, the iFEM with pre-extrapolation using the
    pattern in Figure 12b, and the iFEM with pre-extrapolation using the optimized
    layout in Figure 12a. The percentage error for each of these approaches is illustrated
    in Figure 15. As observed from the color maps on the left, the application of
    the standard iFEM to the clamped plate results in significant errors: the maximum
    error is approximately 7% for the first mode, around 10% for the second and third
    modes, and approximately 13% for the fourth mode. Conversely, the central graphs
    in Figure 15 demonstrate the beneficial impact of using pre-extrapolation with
    a uniformly distributed sensor layout, leading to a substantial reduction in error
    compared to the conventional iFEM: the maximum error for the first mode is 1.72%,
    for the second and third modes is 4.63%, and for the fourth mode is 10.83%. The
    graphs on the right represent the error obtained with the sensor pattern resulting
    from the optimization process. While the maximum error for the first three modes
    remains close to that achieved with uniformly distributed sensors (slightly lower
    for the first mode and slightly higher for the second and third modes), an analysis
    of the spatial distribution of the error reveals that, for modes 2 and 3, the
    maximum error is confined to one of the two peaks, with the rest of the field
    exhibiting errors below 2%. This implies that, although the maximum error is of
    the same order as the uniformly distributed layout, the use of the pattern in
    Figure 12a leads to a reduction in the average error. For the fourth and final
    mode, there is a 2.5% improvement in the maximum error compared to the uniformly
    distributed pattern, with the error once again primarily localized to one of the
    four peaks, while the rest of the geometry maintains a sufficiently low error.
    Overall, for this case study, the use of pre-extrapolation yields substantially
    better results than the standard iFEM, and opting for an optimized pattern over
    a uniformly distributed one for SEA generally lowers the average error in the
    field. Figure 15. Clamped plate’s reconstruction percentage error of the first
    four modes for standard iFEM (left), smoothed iFEM with uniformly distributed
    sensors (center), and smoothed iFEM with optimal layout (right). 4. Conclusions
    This study introduces an innovative approach to the shape-sensing problem involving
    plate structures by integrating smoothed element analysis (SEA) and the non-dominated
    sorting genetic algorithm II (NSGA-II) with the inverse finite element (iFEM)
    methodology. The proposed method optimizes sensor placement to pre-extrapolate
    strain fields with minimal root mean square error compared to reference solutions
    across diverse loading conditions. The pre-extrapolated strains are then utilized
    as input for the inverse finite element method. The effectiveness of this approach
    is demonstrated through notable improvements over the standard iFEM in reconstructing
    a set of mode shapes in two case studies involving a cantilevered rectangular
    plate and a clamped square plate. This methodology effectively enhances monitoring
    capabilities with a limited number of strain sensors and is not necessarily confined
    to planar problems. The SEA has demonstrated successful application to three-dimensional
    structures like curved shells [45] and stiffened panels [46]. Therefore, the integration
    of sensor placement optimization with strain pre-extrapolation in the implementation
    of the inverse finite element method can be extended to industrial systems, offering
    a practical and efficient choice for structural health monitoring (SHM) applications.
    Author Contributions Conceptualization, E.D.P. and L.L.; methodology, E.D.P. and
    L.L.; software, E.D.P.; validation, E.D.P. and L.L.; formal analysis, E.D.P.;
    investigation, E.D.P.; resources, E.D.P. and L.L.; data curation, E.D.P.; writing—original
    draft preparation, E.D.P.; writing—review and editing, E.D.P. and L.L.; visualization,
    E.D.P.; supervision, L.L.; project administration, L.L. All authors have read
    and agreed to the published version of the manuscript. Funding This research received
    no external funding. Institutional Review Board Statement Not applicable. Informed
    Consent Statement Not applicable. Data Availability Statement The data are contained
    within the article. Acknowledgments This work is framed within the Italian national
    project “MOST-Spoke 1—AIR MOBILITY—WP5”, which studies innovative solutions for
    next-generation green aircrafts. Conflicts of Interest The authors declare no
    conflicts of interest. References Güemes, A.; Fernandez-Lopez, A.; Pozo, A.R.;
    Sierra-Pérez, J. Structural Health Monitoring for Advanced Composite Structures:
    A Review. J. Compos. Sci. 2020, 4, 13. [Google Scholar] [CrossRef] Lampani, L.;
    Gaudenzi, P. Innovative Composite Material Component with Embedded Self-Powered
    Wireless Sensor Device for Structural Monitoring. Compos. Struct. 2018, 202, 136–141.
    [Google Scholar] [CrossRef] Eslamlou, A.D.; Ghaderiaram, A.; Schlangen, E.; Fotouhi,
    M. A Review on Non-Destructive Evaluation of Construction Materials and Structures
    Using Magnetic Sensors. Constr. Build. Mater. 2023, 397, 132460. [Google Scholar]
    [CrossRef] You, R.; Ren, L.; Yuan, C.; Song, G. Two-Dimensional Deformation Estimation
    of Beam-Like Structures Using Inverse Finite-Element Method: Theoretical Study
    and Experimental Validation. J. Eng. Mech. 2021, 147, 04021019. [Google Scholar]
    [CrossRef] Abdollahzadeh, M.A.; Kefal, A.; Yildiz, M. A Comparative and Review
    Study on Shape and Stress Sensing of Flat/Curved Shell Geometries Using C0-Continuous
    Family of IFEM Elements. Sensors 2020, 20, 3808. [Google Scholar] [CrossRef] [PubMed]
    Zubia, J.; Durana, G.; Aldabaldetreku, G.; Villatoro, J. Optical Fiber Sensors
    for Aircraft Structural Health Monitoring. Sensors 2015, 15, 15494–15519. [Google
    Scholar] [CrossRef] Floris, I.; Adam, J.M.; Calderón, P.A.; Sales, S. Fiber Optic
    Shape Sensors: A Comprehensive Review. Opt. Lasers Eng. 2021, 139, 106508. [Google
    Scholar] [CrossRef] Gherlone, M.; Cerracchio, P.; Mattone, M. Shape Sensing Methods:
    Review and Experimental Comparison on a Wing-Shaped Plate. Prog. Aerosp. Sci.
    2018, 99, 14–26. [Google Scholar] [CrossRef] Ko, W.L.; Richards, W.L.; Fleischer,
    V.T. Applications of Ko Displacement Theory to the Deformed Shape Predictions
    of the Doubly-Tapered Ikhana Wing; National Aeronautics and Space Administration;
    Nasa/Tp-2009-214652; Dryden Flight Research Center: Edwards, CA, USA, 2009. [Google
    Scholar] Bogert, P.; Haugse, E.; Gehrki, R. Structural Shape Identification from
    Experimental Strains Using a Modal Transformation Technique. In Proceedings of
    the 44th AIAA/ASME/ASCE/AHS/ASC Structures, Structural Dynamics, and Materials
    Conference, San Diego, CA, USA, 23–27 January 2003. [Google Scholar] Kang, L.H.;
    Kim, D.K.; Han, J.H. Estimation of Dynamic Structural Displacements Using Fiber
    Bragg Grating Strain Sensors. J. Sound Vib. 2007, 305, 534–542. [Google Scholar]
    [CrossRef] Bruno, R.; Toomarian, N.; Salama, M. Shape Estimation from Incomplete
    Measurements: A Neural-Net Approach. Smart Mater. Struct. 1994, 3, 92–97. [Google
    Scholar] [CrossRef] Tessler, A.; Spangler, J.L. A Least-Squares Variational Method
    for Full-Field Reconstruction of Elastic Deformations in Shear-Deformable Plates
    and Shells. Comput. Methods Appl. Mech. Eng. 2005, 194, 327–339. [Google Scholar]
    [CrossRef] Esposito, M.; Mattone, M.; Gherlone, M. Experimental Shape Sensing
    and Load Identification on a Stiffened Panel: A Comparative Study. Sensors 2022,
    22, 1064. [Google Scholar] [CrossRef] [PubMed] Esposito, M.; Gherlone, M. Material
    and Strain Sensing Uncertainties Quantification for the Shape Sensing of a Composite
    Wing Box. Mech. Syst. Signal Process. 2021, 160, 107875. [Google Scholar] [CrossRef]
    Niu, S.; Guo, Y.; Bao, H.; Leng, G. A Unified Measurement Method for Shape Sensing
    of Plate Structure. IEEE Trans. Instrum. Meas. 2023, 72, 7500713. [Google Scholar]
    [CrossRef] Tessler, A.; Spangler, J. Inverse FEM for Full-Field Reconstruction
    of Elastic Deformations in Shear Deformable Plates and Shells. In Proceedings
    of the 2nd European Workshop on Structural Health Monitoring, Munich, Germany,
    7–9 July 2004; pp. 83–90. [Google Scholar] Kefal, A.; Oterkus, E.; Tessler, A.;
    Spangler, J.L. A Quadrilateral Inverse-Shell Element with Drilling Degrees of
    Freedom for Shape Sensing and Structural Health Monitoring. Eng. Sci. Technol.
    Int. J. 2016, 19, 1299–1313. [Google Scholar] [CrossRef] Kefal, A. An Efficient
    Curved Inverse-Shell Element for Shape Sensing and Structural Health Monitoring
    of Cylindrical Marine Structures. Ocean Eng. 2019, 188, 106262. [Google Scholar]
    [CrossRef] Gherlone, M.; Cerracchio, P.; Mattone, M.; Di Sciuva, M.; Tessler,
    A. Shape Sensing of 3D Frame Structures Using an Inverse Finite Element Method.
    Int. J. Solids Struct. 2012, 49, 3100–3112. [Google Scholar] [CrossRef] Kefal,
    A.; Oterkus, E. Isogeometric IFEM Analysis of Thin Shell Structures. Sensors 2020,
    20, 2685. [Google Scholar] [CrossRef] Zhao, F.; Xu, L.; Bao, H.; Du, J. Shape
    Sensing of Variable Cross-Section Beam Using the Inverse Finite Element Method
    and Isogeometric Analysis. Meas. J. Int. Meas. Confed. 2020, 158, 107656. [Google
    Scholar] [CrossRef] Zhao, F.; Kefal, A.; Bao, H. Nonlinear Deformation Monitoring
    of Elastic Beams Based on Isogeometric IFEM Approach. Int. J. Non. Linear. Mech.
    2022, 147, 104229. [Google Scholar] [CrossRef] Kefal, A.; Tabrizi, I.E.; Tansan,
    M.; Kisa, E.; Yildiz, M. An Experimental Implementation of Inverse Finite Element
    Method for Real-Time Shape and Strain Sensing of Composite and Sandwich Structures.
    Compos. Struct. 2021, 258, 113431. [Google Scholar] [CrossRef] Tessler, A.; Di
    Sciuva, M.; Gherlone, M. A Refined Zigzag Beam Theory for Composite and Sandwich
    Beams. J. Compos. Mater. 2009, 43, 1051–1081. [Google Scholar] [CrossRef] Kefal,
    A.; Oterkus, E. Displacement and Stress Monitoring of a Panamax Containership
    Using Inverse Finite Element Method. Ocean Eng. 2016, 119, 16–29. [Google Scholar]
    [CrossRef] Li, M.; Kefal, A.; Oterkus, E.; Oterkus, S. Structural Health Monitoring
    of an Offshore Wind Turbine Tower Using IFEM Methodology. Ocean Eng. 2020, 204,
    107291. [Google Scholar] [CrossRef] Cerracchio, P.; Gherlone, M.; Tessler, A.
    Real-Time Displacement Monitoring of a Composite Stiffened Panel Subjected to
    Mechanical and Thermal Loads. Meccanica 2015, 50, 2487–2496. [Google Scholar]
    [CrossRef] Esposito, M.; Roy, R.; Surace, C.; Gherlone, M. Hybrid Shell-Beam Inverse
    Finite Element Method for the Shape Sensing of Stiffened Thin-Walled Structures:
    Formulation and Experimental Validation on a Composite Wing-Shaped Panel. Sensors
    2023, 23, 5962. [Google Scholar] [CrossRef] [PubMed] Abdollahzadeh, M.A.; Tabrizi,
    I.E.; Kefal, A.; Yildiz, M. A Combined Experimental/Numerical Study on Deformation
    Sensing of Sandwich Structures through Inverse Analysis of Pre-Extrapolated Strain
    Measurements. Meas. J. Int. Meas. Confed. 2021, 185, 110031. [Google Scholar]
    [CrossRef] Kefal, A.; Tabrizi, I.E.; Yildiz, M.; Tessler, A. A Smoothed IFEM Approach
    for Efficient Shape-Sensing Applications: Numerical and Experimental Validation
    on Composite Structures. Mech. Syst. Signal Process. 2021, 152, 107486. [Google
    Scholar] [CrossRef] Tessler, A.; Riggs, H.R.; Macy, S.C. A Variational Method
    for Finite Element Stress Recovery and Error Estimation. Comput. Methods Appl.
    Mech. Eng. 1994, 111, 369–382. [Google Scholar] [CrossRef] Oboe, D.; Colombo,
    L.; Sbarufatti, C.; Giglio, M. Comparison of Strain Pre-Extrapolation Techniques
    for Shape and Strain Sensing by IFEM of a Composite Plate Subjected to Compression
    Buckling. Compos. Struct. 2021, 262, 113587. [Google Scholar] [CrossRef] Zhao,
    Y.; Du, J.; Bao, H.; Xu, Q. Optimal Sensor Placement Based on Eigenvalues Analysis
    for Sensing Deformation of Wing Frame Using IFEM. Sensors 2018, 18, 2424. [Google
    Scholar] [CrossRef] [PubMed] Ghasemzadeh, M.; Kefal, A. Sensor Placement Optimization
    for Shape Sensing of Plates and Shells Using Genetic Algorithm and Inverse Finite
    Element Method. Sensors 2022, 22, 9252. [Google Scholar] [CrossRef] Roy, R.; Tessler,
    A.; Surace, C.; Gherlone, M. Efficient Shape Sensing of Plate Structures Using
    the Inverse Finite Element Method Aided by Strain Pre-Extrapolation. Thin-Walled
    Struct. 2022, 180, 109798. [Google Scholar] [CrossRef] Deb, K.; Pratap, A.; Agarwal,
    S.; Meyarivan, T. A Fast and Elitist Multiobjective Genetic Algorithm: NSGA-II.
    IEEE Trans. Evol. Comput. 2002, 6, 182–197. [Google Scholar] [CrossRef] Tessler,
    A.; Hughes, T.J.R. A Three-Node Mindlin Plate Element with Improved Transverse
    Shear. Comput. Methods Appl. Mech. Eng. 1985, 50, 71–101. [Google Scholar] [CrossRef]
    Yu, D.; Wang, S.; Li, W.; Yang, Y.; Hong, J. Shape Sensing for Thin-Shell Spaceborne
    Antennas with Adaptive Isogeometric Analysis and Inverse Finite Element Method.
    Thin-Walled Struct. 2023, 192, 111154. [Google Scholar] [CrossRef] Tessler, A.;
    Riggsb, H.R.; Freesec, C.E.; Cookd, M. An Improved Variational Method for Finite
    Element Stress Recovery and a Posteriori Error Estimation. Comput. Methods Appl.
    Mech. Eng. 1998, 155, 15–30. [Google Scholar] [CrossRef] Katoch, S.; Chauhan,
    S.S.; Kumar, V. A Review on Genetic Algorithm: Past, Present, and Future; Multimedia
    Tools and Applications; Springer: Berlin/Heidelberg, Germany, 2021; Volume 80,
    ISBN 1104202010139. [Google Scholar] Konak, A.; Coit, D.W.; Smith, A.E. Multi-Objective
    Optimization Using Genetic Algorithms: A Tutorial. Reliab. Eng. Syst. Saf. 2006,
    91, 992–1007. [Google Scholar] [CrossRef] Zhang, P.; Qian, Y.; Qian, Q. Multi-Objective
    Optimization for Materials Design with Improved NSGA-II. Mater. Today Commun.
    2021, 28, 102709. [Google Scholar] [CrossRef] Wang, S.; Zhao, D.; Yuan, J.; Li,
    H.; Gao, Y. Application of NSGA-II Algorithm for Fault Diagnosis in Power System.
    Electr. Power Syst. Res. 2019, 175, 105893. [Google Scholar] [CrossRef] Yazdani,
    A.A.; Riggs, H.R.; Tessler, A. Stress Recovery and Error Estimation for Shell
    Structures. Int. J. Numer. Methods Eng. 2000, 47, 1825–1840. [Google Scholar]
    [CrossRef] Tessler, A.; Riggs, H.R.; Dambach, M. A Novel Four-Node Quadrilateral
    Smoothing Element for Stress Enhancement and Error Estimation. Int. J. Numer.
    Methods Eng. 1999, 44, 1527–1543. [Google Scholar] [CrossRef] Disclaimer/Publisher’s
    Note: The statements, opinions and data contained in all publications are solely
    those of the individual author(s) and contributor(s) and not of MDPI and/or the
    editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to
    people or property resulting from any ideas, methods, instructions or products
    referred to in the content.  © 2024 by the authors. Licensee MDPI, Basel, Switzerland.
    This article is an open access article distributed under the terms and conditions
    of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/).
    Share and Cite MDPI and ACS Style Del Priore, E.; Lampani, L. Shape Sensing in
    Plate Structures through Inverse Finite Element Method Enhanced by Multi-Objective
    Genetic Optimization of Sensor Placement and Strain Pre-Extrapolation. Sensors
    2024, 24, 608. https://doi.org/10.3390/s24020608 AMA Style Del Priore E, Lampani
    L. Shape Sensing in Plate Structures through Inverse Finite Element Method Enhanced
    by Multi-Objective Genetic Optimization of Sensor Placement and Strain Pre-Extrapolation.
    Sensors. 2024; 24(2):608. https://doi.org/10.3390/s24020608 Chicago/Turabian Style
    Del Priore, Emiliano, and Luca Lampani. 2024. \"Shape Sensing in Plate Structures
    through Inverse Finite Element Method Enhanced by Multi-Objective Genetic Optimization
    of Sensor Placement and Strain Pre-Extrapolation\" Sensors 24, no. 2: 608. https://doi.org/10.3390/s24020608
    Note that from the first issue of 2016, this journal uses article numbers instead
    of page numbers. See further details here. Article Metrics Citations Crossref   1
    Google Scholar   [click to view] Article Access Statistics Article access statistics
    Article Views 18. Jan 28. Jan 7. Feb 17. Feb 27. Feb 8. Mar 18. Mar 28. Mar 0
    200 400 600 800 For more information on the journal statistics, click here. Multiple
    requests from the same IP address are counted as one view.   Sensors, EISSN 1424-8220,
    Published by MDPI RSS Content Alert Further Information Article Processing Charges
    Pay an Invoice Open Access Policy Contact MDPI Jobs at MDPI Guidelines For Authors
    For Reviewers For Editors For Librarians For Publishers For Societies For Conference
    Organizers MDPI Initiatives Sciforum MDPI Books Preprints.org Scilit SciProfiles
    Encyclopedia JAMS Proceedings Series Follow MDPI LinkedIn Facebook Twitter Subscribe
    to receive issue release notifications and newsletters from MDPI journals Select
    options Subscribe © 1996-2024 MDPI (Basel, Switzerland) unless otherwise stated
    Disclaimer Terms and Conditions Privacy Policy"'
  inline_citation: '>'
  journal: Sensors
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Shape Sensing in Plate Structures through Inverse Finite Element Method Enhanced
    by Multi-Objective Genetic Optimization of Sensor Placement and Strain Pre-Extrapolation
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Tian N.
  - Qiu X.
  - Pan Q.
  citation_count: '0'
  description: Detecting sources in digital images and videos is crucial to multimedia
    forensics research. The inherent physical properties of imaging sensors result
    in the presence of Photo Response Non-Uniformity Noise (PRNU) within the captured
    multimedia content. This particular noise, often called the “fingerprint,” is
    a unique and stable feature for identifying the source camera. However, the compression
    of images by platform codecs on social network media introduces varying degrees
    of quantization noise, making to address this issue, a noise extractor based on
    variance stabilizing transform and adaptive block clustering principal component
    analysis (PCA) is proposed, along with an enhanced processing model that incorporates
    cyclic residual recycling. Firstly, the GAT and adaptive block clustering PCA
    filtering are applied to extract noises from the images. The obtained noises are
    then subjected to zero-mean and diagonal artifact elimination processing. Next,
    the real and imaginary parts of the noise spectrum are individually subjected
    to real-time iterative least squares smoothing based on half-quadratic optimization.
    Due to the presence of PRNU information in the residual between the pre-smoothed
    and post-smoothed signals, additional cyclic smoothing is applied to refine the
    signal further. Finally, the smoothed signals are accumulated to obtain the enhanced
    PRNU noise. Experimental comparisons conducted on the public dataset Dresden demonstrate
    that the proposed model significantly outperforms existing methods in terms of
    source camera identification for low-resolution and strong JPEG compression images.
  doi: 10.1007/s11042-024-18255-3
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Log in Find a journal Publish
    with us Track your research Search Cart Home Multimedia Tools and Applications
    Article An improved PRNU noise extraction model for highly compressed image blocks
    with low resolutions Published: 24 January 2024 (2024) Cite this article Download
    PDF Access provided by University of Nebraska-Lincoln Multimedia Tools and Applications
    Aims and scope Submit manuscript Nili Tian, Xian Qiu & Qing Pan   90 Accesses
    1 Altmetric Explore all metrics Abstract Detecting sources in digital images and
    videos is crucial to multimedia forensics research. The inherent physical properties
    of imaging sensors result in the presence of Photo Response Non-Uniformity Noise
    (PRNU) within the captured multimedia content. This particular noise, often called
    the “fingerprint,” is a unique and stable feature for identifying the source camera.
    However, the compression of images by platform codecs on social network media
    introduces varying degrees of quantization noise, making to address this issue,
    a noise extractor based on variance stabilizing transform and adaptive block clustering
    principal component analysis (PCA) is proposed, along with an enhanced processing
    model that incorporates cyclic residual recycling. Firstly, the GAT and adaptive
    block clustering PCA filtering are applied to extract noises from the images.
    The obtained noises are then subjected to zero-mean and diagonal artifact elimination
    processing. Next, the real and imaginary parts of the noise spectrum are individually
    subjected to real-time iterative least squares smoothing based on half-quadratic
    optimization. Due to the presence of PRNU information in the residual between
    the pre-smoothed and post-smoothed signals, additional cyclic smoothing is applied
    to refine the signal further. Finally, the smoothed signals are accumulated to
    obtain the enhanced PRNU noise. Experimental comparisons conducted on the public
    dataset Dresden demonstrate that the proposed model significantly outperforms
    existing methods in terms of source camera identification for low-resolution and
    strong JPEG compression images. Similar content being viewed by others A fast
    source camera identification and verification method based on PRNU analysis for
    use in video forensic investigations Article 19 October 2020 Enhancing Source
    Camera Identification Using Weighted Nuclear Norm Minimization De-Noising Filter
    Chapter © 2019 Source camera identification via low dimensional PRNU features
    Article 31 October 2018 1 Introduction The rapid advancement of portable cameras,
    digital cameras, and smartphones, driven by continuous innovations in digital
    imaging technology, has revolutionized the way digital images and videos are used
    as primary carriers of information. Consequently, the widespread practice of sharing
    photos online has become a cultural norm. However, this proliferation of visual
    media on the internet has also opened the door to various forms of misuse, including
    the dissemination of false information and engagement in illegal activities. This
    has led to an increasing demand for technologies that can trace the origins of
    these visual assets, making source device identification a critical component
    of investigations. In addition to criminal investigations, source camera identification
    technology finds applications in a wide range of fields such as digital forensics,
    copyright protection, and content verification for news agencies. This technology
    can help in verifying the authenticity of images and videos in news reports, ensuring
    that the public receives accurate and trustworthy information. It’s also utilized
    in copyright enforcement to identify the source of unauthorized image or video
    distribution, helping content creators protect their intellectual property. As
    technology continues to evolve, the applications of source camera identification
    are expected to expand further, playing a pivotal role in ensuring the reliability
    and credibility of visual content across various domains. It’s worth noting that
    images uploaded to social platforms often undergo various levels of compression,
    sometimes even multiple times, as they travel across the internet. This further
    underscores the significance of accurately determining the source devices of compressed
    images in contexts where ensuring the authenticity and integrity of visual content
    is paramount [1, 2]. Therefore, this article focuses on addressing the challenges
    associated with identifying the source devices of compressed images. 1.1 Related
    work Existing source camera identification methods predominantly utilize unique
    characteristics and patterns embedded within images by hardware and software during
    acquisition and processing. These traces consist of errors in pixel information,
    including bad pixels [3], blurring effects resulting from Color Filter Array interpolation
    [4], block effects from JPEG compression algorithms [5], lens distortion [6],
    and Sensor Pattern Noises (SPN). Due to its unique and stable characteristics
    for each camera, SPN has become the distinctive “fingerprint” of the camera. This
    has gained significant interest within the field of source camera identification.
    The origin of SPN can be attributed to the imperfections in camera sensor fabrication
    and the non-uniformity of silicon wafers. The primary constituent of SPN is the
    multiplicative noise known as PRUN noise. In their publication [7], Lukas et al.
    introduced the use of SPN for identifying the source camera. They processed the
    images using a wavelet noise reduction filter and obtained the mean noise residual
    value of a group of images taken by the same camera as the reference SPN. The
    Normalized Correlation Coefficient (NCC) was then calculated between the reference
    SPN and the noise residual of an unknown image to determine if it was taken by
    that camera. However, it is worth noting that the accuracy and reliability of
    SPN-based source camera identification methods can be affected by various factors
    such as image content, color interpolation, and JPEG compression. Subsequently,
    to improve the matching accuracy, scholars have proposed a series of methods to
    enhance the quality of SPN. Chen et al. [8] proposed a Maximum Likelihood Estimation
    (MLE) method to extract the multiplicative factor of PRNU, Zero Mean (ZM) operation
    with the Fourier spatial Wiener Filter (WF) enhanced algorithm is applied to suppress
    non-PRNU components. Cortiana et al. [9] introduced the more advanced BM3D filter
    for PRNU extraction and compared its impact on source camera recognition performance
    with other filters. Kang et al. [10] introduced the Camera Reference Phase SPN
    method to remove periodic noise and non-white noise components in the noise residual
    spectrum. This method calculates the average Phase information after whitening
    the noise of multiple pictures and inverse Fourier transforms to obtain the reference
    pattern noise and proposes the Cyclic Cross-Correlation Norm (CCN) as a similarity
    detector. Zeng et al. [11] proposed a content-adaptive guided image filter (CAGIF)
    to extract PRNU. CAGIF can adaptively adjust the filter radius according to the
    image texture intensity. Li et al. [12] proposed a spectrum equalization algorithm
    (SEA) to solve the artifacts produced by JPEG compression. SEA weakens the excessive
    peak value through local contrast and uses the mean filter to make the spectrum
    too smooth. Mayank et al. [13] believed that the extracted noise residuals had
    low-frequency defects and proposed to delete the low-frequency component in the
    discrete cosine transform (DCT) transform domain and proposed the SEA+HF method
    based on the SEA algorithm. However, discarding many low-frequency components
    resulted in poor performance in compressed image recognition. Rao et al. [14]
    proposed a method to remove correlation to suppress non-PRNU noise, decompose
    the reference noise into blocks and perform eigenvalue decomposition, project
    the sub-blocks into PCA space, and attenuate the dimension whose eigenvalue is
    greater than the variance of the reference noise. Zeng et al. [15] adopted a filter
    based on dual-tree complex wavelet transform (DTCWT) and proposed to use the symmetric
    boundary extension method to improve the quality of PRNU. Quan et al. [16] investigated
    the influence of ISO settings on source camera identification and introduced a
    technique named Content-based Inference of ISO Speeds to deduce ISO from image
    information. Taspinar et al. [17] offered a way of averaging frames in the spatial
    domain to extract fingerprints, which greatly enhances the efficiency of PRNU
    extraction. Nonetheless, addressing scenes with complex textures can be a demanding
    task. Lawgely et al. [18] proposed an enhanced Adaptive DCT filter along with
    a weighted average fingerprint estimation method. López et al. [19] addressed
    video recognition challenges by applying small weight factors to robust components
    within the wavelet transform domain, effectively reducing the influence of scene
    details. This approach was complemented by the integration of unsupervised grouping
    technology.Fabio et al. [20] solves video recognition problems by assigning small
    weight factors to strong components in the wavelet transform domain to attenuate
    the interference of scene details and combining it with unsupervised grouping
    technology. Ana et al. [21] employed the Kullback-Leibler divergence of the probability
    density function between the reference noise and the unknown noise to quantify
    their similarity. Su et al. [22] proposed a variance-stabilized transform with
    an improved dual-tree complex wavelet filter and an MLE estimator combined with
    QP value weights to improve the source camera identification performance for shorter
    compressed videos. Bruni et al. [23] introduced a coherence measure as a similarity
    metric, which effectively minimizes the occurrence of misassignments. Different
    from the traditional signal processing method for source camera identification,
    deep learning has been introduced into this research recently, such as Timmerman
    et al. [24] proposed Constrained-Net to suppress scene content to extract better
    fingerprint features for video identification. Hui et al. [25] proposed a multiscale
    feature fusion network to improve recognition accuracy by fusing content-independent
    SPN features at different scales. Wang et al. [26] proposed a prototype construction
    with ensemble projection to achieve rich fingerprint information extraction from
    small samples.Zamir et al. [27] proposed a multi-stage progressive neural network,
    which segmented the image into non-overlapping blocks to obtain information at
    different scales and used cross-stage feature fusion to improve the noise reduction
    effect [28]. Berdich et al. [29] addressed the problem of source camera identification
    for dark images by utilizing mid-low frequency coefficients of DCT and a wide
    neural network. Bernacki et al. [30] Proposed a CNN with three convolutional layers
    and two fully connected layers, which can still correctly identify camera equipment
    even when the image is severely degraded.Yanhui et al. [31] proposed a densely
    connected hierarchical network that utilizes dense connections and residual learning
    to extract PRNU noise, achieving a significant reduction in network parameters.
    Hong et al. [32] devised an adaptive dual-branch fusion network for source camera
    recognition, enhancing PRNU signal capture with SE and residual modules while
    incorporating an attention mechanism to prioritize valuable information, yet this
    approach heavily relies on an extensive training dataset, making predictions for
    untrained capture devices challenging. Yunxia et al. [33] improved camera recognition
    by carefully selecting diverse image patches using multiple criteria. They also
    reduced scene content interference with a deep residual prediction module and
    used an enhanced VGG network for training aimed to enhance camera identification
    accuracy and robustness. Sugandha et al. [34] introduced two deep learning-based
    methods for image enhancement and denoising. One method used deep learning technology
    and the CLAHE algorithm to denoise images, achieving significant improvement in
    the PSNR evaluation metric. The other method used gradient information to restore
    image details and improve denoising performance through adaptive learning. In
    recent years, camera manufacturers have introduced advanced features such as Image
    Stabilization (IS) and High Dynamic Range (HDR). Following capturing photos or
    videos by imaging sensors, a series of post-processing techniques are employed,
    including cropping, rotation, translation, upsampling, and multi-frame synthesis.
    Traditional source camera identification methods based on PRNU rely on precise
    pixel-level correspondence. Consequently, incorporating stabilization and HDR
    technologies renders these conventional approaches ineffective. Accordingly, the
    crucial challenge in source camera identification revolves around the blind reversal
    of these post-processing operations. To address this issue, researchers have proposed
    several methods. For example, Mandelli et al. [35] used particle swarm optimization
    (PSO) to speed up the estimation of translation and rotation factors and explored
    the problem of “hybrid” recognition of images and videos. Altinisik et al. [36]
    proposed a three-level hierarchical grid search to solve the source identification
    of strongly stable video and reduce the computational burden of searching for
    stable transformation parameters. Fanfani et al. [37] proposed an advanced neural
    network that integrates geometric transformation and image registration techniques
    to efficiently estimate the transformation factor of a stabilized video. Hosseini
    et al. [38] suggested using standard dynamic range images to estimate fingerprints
    and simplify HDR images into a weighted sum of three different exposure images,
    dividing high dynamic range images into overlapping blocks, and calculating PCE
    between these blocks and the blocks near the corresponding fingerprint to estimate
    the offset and correct the offset caused by different exposure combinations. Achieving
    effective filtering results for small-sized images is crucial for accurately aligning
    the displacements between three different exposure images. The extraction of PRNU
    noise from these small-sized images is also utilized in image tampering detection
    [8, 15]. 1.2 Motivation In previous studies, source camera identification based
    on PRNU has shown effectiveness in determining the origin of images. Challenges
    arise when identifying the source camera for low-resolution and JPEG-compressed
    images. This is primarily due to the limited amount of PRNU information available
    in low-resolution images, which makes it vulnerable to interference from filtering
    defects that affect the image content. The JPEG format is widely favored and commonly
    used on various network platforms due to its excellent compatibility and less
    computing resource requirements, however, it must be recognized that JPEG compression
    will remove high-frequency components and fine details in the image, while introducing
    significant quantization noise, which can seriously contaminate the noise residue,
    leading to potential issues in source camera identification. Existing algorithms
    face difficulties in preserving image textures while effectively suppressing noise.
    This is attributed to the fixed-basis reconstruction utilized by multiscale transformations,
    which struggle to accurately represent the complex texture details in natural
    images. Additionally, the Wiener filter fails to adaptively adjust filtering strength,
    leading to signal distortion. Furthermore, current enhancement methods aim to
    eliminate non-PRNU components in a specific transform domain, approximating the
    noise characteristics to Gaussian white noise for suppressing artifacts. On the
    contrary, it often results in the excessive removal of peaks in the transform
    domain, leading to the loss of some PRNU information. Therefore, the accuracy
    of source camera identification is significantly downgraded when dealing with
    strongly JPEG-compressed images and small image blocks. Deep learning holds considerable
    potential in the realm of source camera identification, although it brings forth
    a set of challenges. To begin with, this approach necessitates an extensive and
    diverse dataset for effective training, enabling the model to comprehend the subtleties
    inherent in various devices. Inadequate diversity within the dataset can impede
    the model’s capacity to generalize effectively across different devices. Furthermore,
    the protracted duration of model training and the substantial computational resources
    required can impose limitations, particularly in real-time operational scenarios.
    Lastly, models often encounter difficulties when confronted with untrained devices,
    necessitating the acquisition of substantial new data and subsequent retraining.
    1.3 Contribution This paper introduces a novel PRNU extraction model to address
    the drawbacks of current models and address the challenges of source camera identification
    in low-resolution and compressed images. The proposed model consists of a noise
    extractor that combines the Generalized Anscombe Transform (GAT) and an adaptive
    block clustering PCA filter, as well as a noise enhancement algorithm composed
    of Real-Imaginary Separation Smoothing (RISS) based on semi-quadratic optimization
    and Cyclic Residual Recycling (CRR). These improvements effectively overcome the
    shortcomings of existing algorithms. Specifically, this paper makes the following
    contributions in three aspects: An adaptive block clustering PCA noise extractor
    based on GAT is introduced. GAT modulates the PRNU components related to the noise-free
    signal into Gaussian-like signals. During the filtering process, adaptive parameter
    estimation is achieved through the combination of PCA transformation, Local Polynomial
    Approximation, and Intersection of Confidence Intervals (LPAICI) technique. Moreover,
    a suboptimal filter is introduced to effectively retain complex texture variations.
    A globally optimized RISS method is proposed based on half-quadratic optimization.
    Fast and effective global optimization smoothing is achieved by separately processing
    the real and imaginary parts of the signal after Fourier transformation, combined
    with half-quadratic optimization and real-time iterative least squares. This approach
    enables better adjustment of the fluctuation characteristics of cosine and sine
    signals, rectifies unreasonable regions in the frequency domain, and reduces the
    impact of non-uniqueness artifacts. A cyclic residual recycling strategy is proposed
    to address the partial PRNU information loss caused by the enhancement algorithm.
    By cyclically applying the RISS smoothing process to the difference between the
    pre-smoothed and post-smoothed signals, the strategy gradually recycles the PRNU
    information that was lost during the RISS process, allowing for the construction
    of a noise signal with complete PRNU information. In summary, the innovations
    presented in this paper revolve around the creation of a comprehensive PRNU extraction
    model to address the challenges of source camera identification in low-resolution
    and compressed image situations. The novel techniques presented in this study,
    including adaptive GAT-based noise extraction, globally optimized RISS, and cyclic
    residual recycling, work synergistically to increase the accuracy and reliability
    of source camera identification methods. 1.4 Article structure The remaining sections
    of this paper are organized as follows: Section 2 provides an introduction to
    the background of image source camera identification based on PRNU. Section 3
    explores the proposed PRNU extraction model and provides a comprehensive analysis
    of each component. Section 4 provides practical verification and evaluation of
    the results. Finally, Section 6 concludes the paper. 2 Background According to
    PRNU noise extraction modeling in literature [8] , photos taken by digital cameras
    can be expressed as: $$\\begin{aligned} \\varvec{I}={{\\varvec{I}}_{0}}+\\varvec{K}{{\\varvec{I}}_{0}}+\\theta
    , \\end{aligned}$$ (1) where \\({{\\varvec{I}}_{0}}\\) represents a noiseless
    image, \\({{\\varvec{K}}}\\) represents the multiplicative factor of PRNU noise,
    and \\(\\theta \\) means non-PRNU noise. Source camera identification technology
    based on PRNU is to estimate the reference PRNU through the image filter, defining
    the discrepancy between the original image and the filtered image as the noise
    residual \\(\\varvec{W}\\). Assuming there are N photos for denoising, each noise
    residual \\(\\varvec{W}_{i}\\) is expressed as: $$\\begin{aligned} {{\\varvec{W}}_{i}}={{\\varvec{I}}_{i}}-F({{\\varvec{I}}_{i}})
    ,i=1,2,3\\cdots ,N {\\ } , \\end{aligned}$$ (2) where \\({{\\varvec{W}}_{i}}\\)
    is the noise residual of the i-th image, \\({{\\varvec{I}}_{i}}\\) represents
    the i-th original image, \\(F({{\\varvec{I}}_{i}})\\) represents the filtered
    image. Equation (2) is referred to as noise extraction, with its essence lying
    in filter design. After the noise residuals of N photos are obtained, the maximum
    likelihood estimation of N noise residuals is carried out through equation (3)
    to obtain the multiplicative factor \\(\\varvec{K}\\) of camera sensor mode noise
    [9], as follow: $$\\begin{aligned} \\varvec{K}=\\frac{\\underset{i=1}{\\overset{N}{\\mathop
    {\\sum }}}\\, {{\\varvec{W}}_{i}}{{\\varvec{I}}_{i}}}{\\underset{i=1}{\\overset{N}{\\mathop
    {\\sum }}}\\,\\varvec{I}_{i}^{2}}. \\end{aligned}$$ (3) The camera fingerprint
    \\(\\varvec{R}\\) is obtained by multiplying and averaging the factor \\(\\varvec{K}\\)
    with the reference image, as follow: $$\\begin{aligned} \\varvec{R}=\\frac{\\underset{i=1}{\\overset{N}{\\mathop
    {\\sum }}}\\, \\varvec{K}{{\\varvec{I}}_{i}}}{N}. \\end{aligned}$$ (4) The test
    image is also extracted using the same image filter to obtain the noise residual
    \\(\\varvec{W}\\) . However, there is still non-SPN information, such as CFA interpolation
    noise and JPEG compression quantitative noise in \\(\\varvec{W}\\) and \\(\\varvec{R}\\)
    , which essentially interferes with the recognition result. Therefore, it is essential
    to enhance the noise using an enhancement model before it is applied to eliminate
    interference noise. The Peak Correlation Energy (PCE) [39] can be used to evaluate
    the degree of correlation between noise residual W of the test image and fingerprint
    R of the camera. Finally, a threshold value can be applied to ascertain if the
    test image corresponds to the camera of interest, $$\\begin{aligned} PCE\\left(
    \\varvec{W},\\varvec{R} \\right) =\\frac{{{\\rho }^{2}}\\left( \\varvec{W},\\varvec{R}
    \\right) }{\\frac{1}{s-|\\Omega |}\\underset{s\\notin \\text { }\\Omega \\text
    { }}{\\mathop {\\sum }}\\,{{\\rho }^{2}}\\left( \\varvec{W},\\varvec{R} \\right)
    }, \\end{aligned}$$ (5) where \\(\\rho \\) is the normalized cross-correlation
    between \\(\\varvec{W}\\) and \\(\\varvec{R}\\) , s is the product of the number
    of rows and columns of \\(\\rho \\) , \\(\\Omega \\) indicates a localized region
    surrounding \\({{\\rho }_{(0,0)}}\\) , and \\(|\\Omega |\\) represents the size
    of area \\(\\Omega \\) , $$\\begin{aligned} \\rho \\left( \\varvec{W},\\varvec{R}
    \\right) =\\frac{\\left( \\varvec{W}-\\varvec{\\bar{W}} \\right) \\odot \\left(
    \\varvec{R}-\\varvec{\\bar{R}} \\right) }{\\left\\| \\varvec{W}-\\varvec{\\bar{W}}
    \\right\\| \\centerdot \\left\\| \\varvec{R}-\\varvec{\\bar{R}} \\right\\| },
    \\end{aligned}$$ (6) where \\(\\left\\| * \\right\\| \\) denotes the L2 parametrization
    of \\(* \\), \\(\\bar{*}\\) denotes the mean of the matrix \\(* \\), and \\(\\odot
    \\) denotes the dot product of the matrix. Furthermore, the utilization of Signed
    Peak Correlation Energy (SPCE) [12] can lead to improved classification results,
    $$\\begin{aligned} SPCE\\left( \\varvec{W},\\varvec{R} \\right) =\\frac{sign\\left(
    \\rho \\left( \\varvec{W},\\varvec{R} \\right) \\right) \\times {{\\rho }^{2}}\\left(
    \\varvec{W},\\varvec{R} \\right) }{\\frac{1}{s-|\\Omega |}\\underset{s\\notin
    \\text { }\\Omega \\text { }}{\\mathop {\\sum }}\\,{{\\rho }^{2}}\\left( \\varvec{W},\\varvec{R}
    \\right) }, \\end{aligned}$$ (7) where sign denotes the mathematical sign function.
    Fig. 1 A diagram of source camera identification based on PRNU Full size image
    The flow chart of the source identification task of the digital image is shown
    in Fig. 1. The modules that have the most significant impact on recognition performance
    are the noise extraction module, noise enhancement module, fingerprint estimation
    module, and similarity measurement module. The primary improvement in this paper
    lies in the noise extraction and enhancement model, which corresponds to the blue
    dashed box in Fig. 1. These improvements will be introduced in detail in Chapter
    3. 3 Proposed PRNU extraction model An improved model for extracting image PRNU
    noise is introduced in this paper, which consists of a noise extractor combining
    GAT [40, 41] with adaptive block clustering PCA filter [42], as well as an enhancement
    processing model involving spectrum real-imaginary separation smoothing and Cyclic
    Residual Recycling. These improvements will be discussed in the subsequent sections.
    3.1 Adaptive block clustering pca noise extractor based on GAT As shown in Fig.
    2, a noise residue extraction model based on the GAT and adaptive clustered PCA
    denoiser is proposed to extract the noise residue from the image. The process
    begins with the GAT applied to the image. Subsequently, an adaptive filter is
    utilized for denoising. After the denoising process, the image is restored using
    the inverse of GAT. Finally, the noise residue is derived by computing the difference
    between the filtered image and the input image. Fig. 2 Noise extraction model
    Full size image The reason for proposing this extraction model is that existing
    source camera filtering algorithms encounter several challenges. These issues
    arise during the multi-scale decomposition of the image, where textures and PRNU
    components are mixed in high-frequency subbands, making it difficult to separate
    them effectively using filtering techniques. Additionally, the fixed basis used
    in multi-scale decomposition is insufficient to represent complex textures adequately.
    While Wiener filtering demonstrates good denoising performance, it tends to excessively
    smooth out details in regions with complex textures, negatively impacting source
    camera identification precision. To address these challenges, this study introduces
    a similar image block approach to estimate noise and constructs an adaptive basis
    using PCA on a set of similar blocks. A suboptimal Wiener filter is then used
    to mitigate the interference of texture information to PRNU noise during the filtering
    process, aiming to improve the effectiveness of source camera identification.
    Furthermore, existing algorithms face difficulties in extracting PRNU components
    related to the noise-free signal due to the use of Gaussian noise filters, which
    can only extract PRNU components unrelated to the image. To overcome this limitation,
    a variance-stabilizing transform is employed to convert signal-independent components
    into signals resembling Gaussian distributions. Subsequently, denoising is performed
    using a Gaussian noise filter, followed by inverse variance-stabilizing transform
    to restore the image. This approach effectively estimates both signal-dependent
    and signal-independent PRNU components. In the following, a comprehensive explanation
    of the proposed noise extraction model will be presented. 3.1.1 Generalized anscombe
    transform Typically, image-denoising algorithms assume that image noise follows
    an additive Gaussian white noise model, which is uncorrelated with the noise-free
    signal. On the contrary, PRNU noise is signal-correlated, posing a challenge for
    conventional Gaussian noise filters to estimate PRNU noise accurately. Hence,
    PRNU noise can be described as a composite model that incorporates both Poisson
    noise and Gaussian noise components, $$\\begin{aligned} \\varvec{I}\\text {=}\\eta
    P({{\\varvec{I}}_{0}})+\\psi , \\end{aligned}$$ (8) where \\(\\eta \\) is the
    Poisson distribution gain factor, \\(P({{\\varvec{I}}_{0}})\\) is the Poisson
    distribution of the noise-free image \\({{\\varvec{I}}_{0}}\\) , \\(\\psi \\)
    is Gaussian white noise with mean \\(\\mu \\) and standard deviation \\(\\sigma
    \\) . Poisson noise causes the noise variance to be correlated with the noise-free
    signal. The variance stabilization transform (VST) is employed to transform the
    Poisson-Gaussian mixture noise into Gaussian-like white noise. Subsequently, a
    denoising method based on Gaussian noise is applied to effectively eliminate the
    noise, leading to a more precise estimation of the PRNU signal. The GAT is a well-known
    variance stabilization transform that plays a crucial role in stabilizing the
    noise variance within a specific range. By applying this nonlinear transformation,
    the noise variance is decoupled from the noise-free signal. After using the GAT
    to the image, the transformed image is filtered, and the inverse GAT transform
    is then performed to obtain an estimation of the clean image. GAT can be expressed
    as: $$\\begin{aligned} {{\\varvec{I}}_{v}}=\\left\\{ \\begin{array}{cc} \\frac{2}{\\eta
    }\\sqrt{\\eta \\varvec{I}+s{{\\eta }^{2}}+{{\\sigma }^{2}}}\\quad &{}\\varvec{I}>-s\\eta
    -\\frac{{{\\sigma }^{2}}}{\\eta } \\\\ 0 &{}\\varvec{I}\\le -s\\eta -\\frac{{{\\sigma
    }^{2}}}{\\eta } \\\\ \\end{array} \\right. , \\end{aligned}$$ (9) where \\({{\\varvec{I}}_{v}}\\)
    is the image after GAT processing, constant \\(s=0.375\\) , gain factor \\(\\eta
    =1\\) . Then \\({{\\varvec{I}}_{v}}\\) is denoised using a Gaussian noise filter
    to obtain \\({{\\varvec{I}}_{vd}}\\) . To better estimation, the closed approximation
    method of the exact unbiased inverse of GAT [41] is chosen to be utilized in the
    proposed way, so the estimation of the clean image can be expressed as : $$\\begin{aligned}
    {{\\varvec{I}}_{i}}=\\frac{1}{4}\\varvec{I}_{vd}^{2}+\\frac{1}{4}\\varvec{I}_{vd}^{-1}-\\frac{11}{8}\\varvec{I}_{vd}^{-2}+\\frac{5}{8}\\sqrt{\\frac{3}{2}}\\varvec{I}_{vd}^{-3}-\\frac{1}{8}-{{\\sigma
    }^{2}}. \\end{aligned}$$ (10) 3.1.2 Adaptive block clustering PCA filter The denoising
    process is performed on the image after GAT transformation, where the noise correlated
    with the noise-free signal has been modulated into Gaussian-like noise. Preserving
    texture variations is crucial for the denoising algorithm. It is often challenging
    to retain small-scale or random texture variations located in the high-frequency
    domain, and they are prone to be smoothed out during the noise-removal process.
    A nonlocal PCA texture variation adaptive image denoising method, proposed in
    [42], was employed in our study. This technique combines patch grouping based
    on nonlocal image self-similarity with denoising using a non-fixed basis PCA transformation.
    This filtering technique effectively preserves textures during denoising operations
    while it is associated with longer processing times. For this reason, modified
    by using non-overlapping blocks instead of traditional overlapping blocks for
    processing. The denoising estimation of small blocks is now performed solely within
    the boundaries of the current large block. Experimental results demonstrated that
    the performance difference between the two approaches in PRNU extraction applications
    was minimal while significantly reducing the computation time. The technique applied
    in our algorithm can be simplified into the following steps: First, large non-overlapping
    blocks are extracted using a large sliding window \\({\\textbf {SW}}_1\\). Then,
    small overlapping blocks within the large non-overlapping blocks are obtained
    using a small sliding window \\({\\textbf {SW}}_2\\). Next, each vectorized small
    block within the current large overlapping block is adaptively clustered, and
    the resulting clusters are concatenated into a joint matrix. The joint matrices
    are then subjected to PCA transformation to eliminate noise-dominant dimensions,
    and a suboptimal Wiener filter is applied to further denoise the signal-dominant
    dimensions. Finally, these blocks are aggregated to generate the filtered image.
    Block matching has several key purposes, including efficiently utilizing natural
    image redundancies, reducing noise interference, and improving image signals.
    Natural images often contain many similar blocks with shared structural, textural,
    or feature characteristics. Noise in images is typically randomly distributed,
    leading to varying noise levels in different blocks. However, the underlying signal
    remains consistent. Aggregating similar blocks helps reduce the negative impact
    of noise, resulting in better image quality. Additionally, these similar blocks
    often contain valuable structural and textural information, further enhancing
    the image signal and overall quality. It is essential to acknowledge, however,
    that the high-dimensional nature of image blocks imposes a significant computational
    burden when clustering a large number of clusters. Moreover, the absence of prior
    knowledge to determine the required number of clusters necessitates the adoption
    of a divide-and-conquer strategy to expedite this process. The adaptive clustering
    technique employs a divide-and-conquer methodology [43], whereby the data is initially
    roughly clustered into several clusters. Initially, we employ k-means clustering
    to coarsely categorize image blocks into several initial clusters. Subsequently,
    within each initial cluster, we perform an additional round of k-means clustering
    to further refine the number of clusters. Following the multiple rounds of clustering
    mentioned earlier, we then move on to merging clusters that exhibit potential
    similarity. This merging process relies on the proximity of their centers, where
    the distance \\(D\\text {(}\\varvec{A},\\varvec{B}\\text {)}\\) between cluster
    \\(\\varvec{A}\\) and \\(\\varvec{B}\\) is determined by both their center-to-center
    distance and the size of the current cluster. $$\\begin{aligned} D\\text {(}\\varvec{A},\\varvec{B}\\text
    {)}=\\left\\{ \\begin{matrix} \\displaystyle \\frac{\\left\\| {{\\varvec{A}}_{c}}-{{\\varvec{B
    }}_{c}} \\right\\| _{2}^{2}}{\\kappa } &{} \\min ({{N}_{A}},{{N}_{B}})>200 \\\\
    \\left\\| {{\\varvec{A}}_{c}}-{{\\varvec{B}}_{c}} \\right\\| _{2}^{2} &{} otherwise
    \\\\ \\end{matrix} \\right. , \\end{aligned}$$ (11) where \\(\\varvec{A}\\) and
    \\(\\varvec{B}\\) indicate two clusters, \\({{*}_{c}}\\) indicates the center
    of the cluster \\({{*}}\\), \\({{N}_{*}}\\) indicates the number of individuals
    in the cluster \\({{*}}\\). In cases where the number of individuals within a
    cluster exceeds 200, a scaling factor \\(\\kappa =0.7\\) is applied to reduce
    the probability of merging the larger clusters. Cluster merging in adaptive clustering
    algorithms is determined based on the definition of distance. The distance calculation
    between clusters takes into account the size of the clusters and the similarity
    between them. When two clusters are similar but different sizes, the merging threshold
    is different. In this case, increasing the merging threshold reduces the probability
    of merging between clusters with different characteristics. When two large clusters
    are combined, the noise effect in the center of the cluster is small. In this
    case, we need to adjust the merging threshold based on the cluster size. Therefore,
    by properly adjusting the clustering merging threshold, the accuracy of clustering
    can be significantly improved. Suppose there are two clusters A and B with large
    differences in size in a specific situation, and the noise variance at the center
    of cluster A is negligible. In this case, it is feasible to calculate the cluster
    merging threshold by evaluating the spatial interval between these two clusters.
    Then, when the spatial distance between clusters falls below a predefined threshold,
    they need to be combined into a single cluster. For the patches in each cluster,
    the PCA transform is used instead of the fixed basis transform for denoising.
    The PCA transform can characterize complex textures in natural environments more
    effectively while also reducing the artifacts generated by the denoising process
    [42]. For vectorization of each small block in cluster \\(\\varvec{A}\\) is combined
    into a joint matrix \\({{\\varvec{A}}_{M}}\\) , the size of \\({{\\varvec{A}}_{M}}\\)
    is \\(C\\times {{N}_{A}}\\) which means the size of the small sliding window \\({\\textbf
    {SW}}_2\\) multiplied by the number of individuals in cluster \\(\\varvec{A}\\).
    The singular value decomposition of \\({{\\varvec{A}}_{M}}\\) can be expressed
    as: $$\\begin{aligned} {{\\varvec{A}}_{M}}=\\underset{k=1}{\\overset{\\min (C,{{N}_{A}})}{\\mathop
    {\\sum }}}\\,\\sqrt{{{N}_{A}}{{\\xi }_{k}}}{{u}_{k}}v_{k}^{T} , \\end{aligned}$$
    (12) where \\(\\sqrt{{{N}_{A}}{{\\xi }_{k}}}\\) represents the singular value
    of \\({{\\varvec{A}}_{M}}\\), u and v represent singular vectors. The noise-dominant
    dimensions, characterized by the lowest eigenvalues, typically do not preserve
    the texture information effectively. Hence, it is necessary to discard these noise-dominant
    dimensions. Based on the Gaussian spiked population model [44], suppose \\(\\gamma
    = \\text {C}/{{N}_{A}}\\;\\), \\(\\xi _{r}=\\sigma ^{2}{{(1+\\sqrt{\\gamma })}^{2}}\\)
    , where \\({{\\sigma }^{2}}\\) is noise variance. The reserved rank R as the signal-dominant
    dimensions can be expressed as: $$\\begin{aligned} R=\\underset{k=1}{\\overset{\\text
    {C}}{\\mathop {\\sum }}}\\,\\left( {{\\xi }_{k}}>\\mu {{\\xi }_{r}} \\right) ,
    \\end{aligned}$$ (13) where \\(\\mu =1.1\\) to eliminate more noise, equation
    (13) counts the number of eigenvalues greater than \\(\\mu {{\\xi }_{r}}\\) ,
    effectively screening out the signal-dominant dimensions, so preliminary denoising
    of \\({{\\varvec{A}}_{M}}\\) can be represented by a low-rank approximate matrix
    \\({{\\varvec{A}}_{R}}\\): $$\\begin{aligned} {{\\varvec{A}}_{R}}=\\underset{k=1}{\\mathop
    {\\overset{R}{\\mathop {\\sum }}\\,}}\\,\\sqrt{{{N}_{A}}{{\\xi }_{k}}}{{u}_{k}}v_{k}^{T}.
    \\end{aligned}$$ (14) After selecting the signal-dominated dimension through low-rank
    approximation, local estimation of filter parameters is performed using the coefficients
    of the selected dimension. An adaptive suboptimal Wiener filter is then employed
    for denoising, which helps to reduce the distortion caused by global estimation
    parameters and the optimal Wiener filter. Suppose a coefficient of the current
    dimension is \\(\\varvec{C}(x)={{\\varvec{C}}_{0}}(x)+\\varvec{\\omega }(x)\\),
    where \\({{\\varvec{C}}_{0}}(x)\\) denotes noiseless coefficient, \\(\\varvec{\\omega
    }(x)\\) denotes zero mean Gaussian white noise with variance \\({{\\sigma }^{2}}\\).
    According to the literature [45], the local polynomial approximation combined
    with the intersection of confidence intervals (LPA-ICI) algorithm is utilized
    to estimate the local filtering parameters through adaptive windows. This method
    adjusts the window size of estimated parameters by considering the fluctuation
    degree of coefficients in dimensions. LPA is first used to identify the neighborhoods
    in which the current coefficients show high similarity to determine the appropriate
    window size. Zero-order polynomials are used for fitting to improve computing
    efficiency. Supposed a window of size h centered at x, there  are coefficients
    in the window. A constant \\({{C}_{\\text {x},h}}\\) can approximate all coefficients
    in the window, and a loss function can be defined as: $$\\begin{aligned} L(x)=\\frac{1}{{{N}_{h}}}\\underset{\\text
    {s}=}{1}{\\overset{{{N}_{h}}}{\\mathop {\\sum }}}\\,{{\\rho }_{\\text {h}}}({{x}_{s}}-x){{(\\varvec{C}({{x}_{s}})-{{C}_{\\text
    {x},h}})}^{2}}, \\end{aligned}$$ (15) where \\(\\rho \\left( * \\right) \\) is
    a rectangular window function, in particular, \\({{\\rho }_{h}}\\left( * \\right)
    \\text {=}{\\rho \\left( {*}/{h}\\; \\right) }/{h}\\;\\) . When the window size
    is determined to be h, the constant \\({{C}_{\\text {x},h}}\\) and standard deviation
    \\(st{{d}_{\\text {x},h}}\\) can be expressed as: $$\\begin{aligned} \\left\\{
    \\begin{matrix} {{C}_{x,h}}=\\displaystyle \\frac{1}{{{N}_{h}}}\\underset{\\text
    {s}=}{1}{\\overset{{{N}_{h}}}{\\mathop {\\sum }}}\\,\\varvec{C}({{x}_{s}}) \\\\
    \\text {st}{{\\text {d}}_{x,h}}=\\displaystyle \\frac{\\sigma }{\\sqrt{{{N}_{h}}}}
    \\\\ \\end{matrix} \\right. , \\end{aligned}$$ (16) Initially employing a small
    window and gradually enlarging it, the mean and standard deviation are calculated
    to generate different confidence intervals. The confidence interval \\(C{{I}_{e}}\\)
    of the window with serial number e can be expressed as: $$\\begin{aligned} C{{I}_{e}}=
    \\!\\![\\!\\!\\text { }{{L}_{e}}\\text {,}{{U}_{e}}\\text { }\\!\\!]\\!\\!\\text
    { }\\left\\{ \\begin{matrix} {{L}_{e}}={{C}_{x,h}}-\\tau \\text {st}{{\\text {d}}_{x,h}}
    \\\\ {{U}_{e}}={{C}_{x,h}}+\\tau \\text {st}{{\\text {d}}_{x,h}} \\\\ \\end{matrix}
    \\right. , \\end{aligned}$$ (17) where \\(\\tau \\) is a threshold parameter.
    Using the intersection of confidence intervals (ICI) technique to select the appropriate
    window, the intervals are sorted by window size, finding the window that best
    matches the current coefficients when the intervals are met \\({{U}_{e}}= \\min
    \\{{{U}_{e}},{{U}_{e-1}}\\}\\) . The result is that coefficients with higher fluctuations
    correspond to smaller window sizes, and vice versa. Once the window size is determined,
    the auto-covariance \\({{R}_{\\text {x}}}\\) of the current point can be estimated
    as follows: $$\\begin{aligned} {{R}_{\\text {x}}}\\text {=}\\frac{1}{{{N}_{h}}}\\underset{\\text
    {s}=}{1}{\\overset{{{N}_{h}}}{\\mathop {\\sum }}}\\,\\varvec{C}{{({{x}_{s}})}^{2}}.
    \\end{aligned}$$ (18) Algorithm 1 Adaptive block clustering PCA noise extractor
    based on generalized anscombe transform. Full size image After the local auto-covariance
    is obtained by local window estimation, the suboptimal Wiener filter [46] algorithm
    is used to process the coefficients in signal-dominant, which is different from
    the optimal Wiener filter system function \\({{h}_{0}}=1-{{g}_{0}}\\), where \\({{g}_{0}}\\text
    {=}{{\\sigma }^{2}}/{{R}_{x}}\\), the suboptimal Wiener filter introduces an attenuation
    coefficient \\(\\vartheta \\in [0,1]\\) to reduce signal distortion: $$\\begin{aligned}
    {{h}_{\\text {s}}}=1-\\vartheta {{g}_{0}}\\text {=}1-\\vartheta \\frac{{{\\sigma
    }^{2}}}{{{R}_{x}}}. \\end{aligned}$$ (19) The selection of the attenuation coefficient
    \\(\\vartheta \\) is based on the two indices: noise reduction intensity \\({{\\varsigma
    }_{nr}}\\left( {{h}_{s}} \\right) \\triangleq {{\\sigma }^{2}}/E\\left\\{ {{\\left[
    {{h}_{s}}\\varvec{\\omega }(x) \\right] }^{2}} \\right\\} \\) and signal distortion
    \\({{v}_{sd}}\\left( {{g}_{s}} \\right) \\triangleq E\\left\\{ {{\\left[ \\varvec{C}(x)-{{h}_{s}}\\varvec{C}(x)
    \\right] }^{2}} \\right\\} /\\sigma _{\\varvec{C}}^{2}\\) , where \\(\\sigma _{\\varvec{C}}^{2}\\)
    indicates the variance of \\(\\varvec{C}(x)\\). The optimal parameters can be
    obtained by maximizing the discriminative cost function presented below: $$\\begin{aligned}
    J(\\vartheta )=\\frac{{{\\varsigma }_{nr}}\\left( {{h}_{s}} \\right) }{{{\\varsigma
    }_{nr}}\\left( {{h}_{o}} \\right) }-\\beta \\frac{{{v}_{sd}}\\left( {{g}_{s}}
    \\right) }{{{v}_{sd}}\\left( {{g}_{o}} \\right) }=\\frac{{{\\sigma }^{2}}+{{g}_{o}}{{R}_{\\text
    {x}}}{{g}_{o}}-2{{\\sigma }^{2}}{{g}_{o}}}{{{\\sigma }^{2}}+{{\\vartheta }^{2}}{{g}_{o}}{{R}_{\\text
    {x}}}{{g}_{o}}-2\\vartheta {{\\sigma }^{2}}{{g}_{o}}}-\\beta {{\\vartheta }^{2}}.
    \\end{aligned}$$ (20) Where \\(\\beta =0.7\\) is used to adjust the proportion
    between signal preservation and noise reduction intensity in the discriminative
    cost function \\(J(\\vartheta )\\). After determining \\(\\vartheta \\), the estimated
    value of the coefficient is expressed as \\(\\varvec{\\hat{C}}\\left( x \\right)
    ={{h}_{s}}\\varvec{C}\\left( x \\right) \\). After suboptimal Wiener filtering
    is applied to the coefficients of each signal-dominant dimension, the resulting
    denoised cluster matrix is inverse-transformed using PCA. Then, the denoised cluster
    matrix is transformed back into the estimation blocks. Finally, the image block
    is restored to its corresponding position, and the filtered pixels from different
    sliding windows are averaged for the estimation of clean image. The noise extractor
    in this paper is shown in Algorithm 1. 3.2 Enhancement model based on RISS and
    CRR The enhancement model proposed in this study comprises three main parts. Firstly,
    the Remove Diagonal Artifacts technique is employed to suppress diagonal artifacts
    by setting the two-dimensional wavelet diagonal components of the preliminary
    extracted PRNU to zero. Secondly, the Real-time Iterative Least Square based on
    fast additive half-quadratic minimization is utilized to smooth the amplitude
    of the real and imaginary parts of the frequency domain signal. This global optimization
    algorithm efficiently smooths the signal while preserving reasonable peak values,
    thus decreasing the loss of PRNU information. Lastly, the Cyclic Residual Recycling
    strategy is employed in the third component to recycle the PRNU information that
    is lost during the PRNU spectrum smoothing process at different levels. Figure
    3 shows the flow chart of the enhancement model. Fig. 3 Proposed enhancement model
    Full size image The reason for proposing this model is that the utilization of
    enhancement models has been employed by researchers to enhance the quality of
    the filtered noise residual, aiming to align the frequency characteristics of
    the noise residuals with those resembling white noise. This approach effectively
    mitigates the impact of non-unique artifacts on the recognition process, resulting
    in superior identification performance compared to unenhanced noise residue. However,
    in scenarios involving small image blocks or heavily compressed images, the amount
    of PRNU information contained within the noise becomes limited. Excessively attenuating
    the peaks in the spectrum in such cases may lead to a decline in the effectiveness
    of camera source identification. Therefore, this study suggests that excessively
    attenuating the majority of the spectrum is not recommended. Certain prominent
    regions in the spectrum may also contain components of PRNU. To address this concern,
    a fine-grained processing algorithm is employed in this study to facilitate the
    flattening of the spectrum while enabling the preservation of localized peak regions
    reasonably. Moreover, existing enhancement algorithms generally focus on the spectrum’s
    magnitude and scale the frequency domain signal’s real and imaginary parts proportionally.
    In contrast, separate and more refined processing is performed on the real and
    imaginary parts in this research. This approach allows for better adjustment of
    the variations in basic signals and correction of unreasonable regions in the
    frequency domain signal. Furthermore, the residual between the pre- and post-enhancement
    results is further processed and incorporated into the previous enhancement results,
    resulting in improved camera identification performance. This observation implies
    that the lost signals after enhancement also retain certain PRNU information.
    Consequently, the difference between the pre- and post-enhancement signals undergoes
    cyclic retrieval and additional processing. This cyclic procedure, referred to
    as cyclic residual cycling, facilitates better preservation of the PRNU information
    through these enhancements. 3.2.1 Remove diagonal high-frequency Most existing
    enhancement models primarily focus on addressing periodic artifacts in noise,
    while diagonal artifacts may still exist in the extracted noise. A diagonal shared
    structure in the camera fingerprint was also identified in the literature [47].
    Our investigation observed that the diagonal high-frequency components of the
    noise residuals could disrupt camera identification. Additionally, PRNU is characterized
    by medium to high frequencies. When employing an additive white noise filter to
    extract the noise residuals, there is a relatively even energy distribution across
    various frequency bands. Notably, the highest frequency component contains substantial
    thermal noise, which can impede camera identification. Based on this observation,
    a zeroing operation is performed on the diagonal component of the two-dimensional
    wavelet transform, which aims to suppress the diagonal structure and reduce the
    interference caused by high-frequency thermal noise in the signal. Suppose \\({{\\varvec{W}}_{\\varvec{ZM}}}\\)
    is the noise residual after undergoing ZM [8] processing and two-dimensional discrete
    wavelet transform is performed on \\({{\\varvec{W}}_{\\varvec{ZM}}}\\), $$\\begin{aligned}{}[\\varvec{D,V,H,A}]=DWT2\\left(
    {{\\varvec{W}}_{\\varvec{ZM}}} \\right) , \\end{aligned}$$ (21) where DWT2 denotes
    two-dimensional discrete wavelet transform, the diagonal high-frequency component
    \\(\\varvec{D}\\), the vertical high-frequency component \\(\\varvec{V}\\), the
    horizontal high-frequency component \\(\\varvec{H}\\), and the low-frequency component
    \\(\\varvec{A}\\) of the signal, next diagonal high-frequency components are set
    to zero, $$\\begin{aligned} \\varvec{\\tilde{D}}=zeros(\\varvec{D}). \\end{aligned}$$
    (22) The wavelet inverse transform is used to reconstruct the signal using the
    remaining three components, denoting the two-dimensional wavelet inverse transform,
    $$\\begin{aligned} {{\\varvec{W}}_{\\varvec{Z}{{\\varvec{M}}_{\\varvec{-}}}\\varvec{RD}}}=IDWT2(\\varvec{\\tilde{D},V,H,A}),
    \\end{aligned}$$ (23) where IDWT2 denotes inverse two-dimensional discrete wavelet
    transform with employing the Haar wavelet, the existing diagonal artifacts are
    effectively eliminated, and the influence of noise in the highest frequency band
    is reduced. This algorithm is referred to as RD (Remove Diagonal Artifacts) in
    this paper. 3.2.2 Real-imaginary separation smoothing PRNU noise exhibits characteristics
    similar to Gaussian white noise, so the ideal PRNU noise should have a relatively
    flat spectrum. Furthermore, for more effective handling of variations in the cosine
    and sine signals, a method called RISS is proposed. After applying the ZM and
    Remove Diagonal Artifacts (RD) processing to the PRNU noise, it is transformed
    into the frequency domain. The amplitude of the real and imaginary components
    of the frequency signal is separately subjected to Real-time Iterative Least Square
    (RILS) smoothing. This process not only suppresses excessively large amplitude
    points but also fills in the gaps in the signal, resulting in a PRNU signal with
    amplitude-frequency characteristics closer to Gaussian white noise. Moreover,
    RILS, a global optimization-based method, has advantages over local smoothing
    algorithms such as SEA [12]. Global optimization-based image smoothing methods
    are effective in avoiding issues like gradient reversal and halo artifacts. A
    conspicuous drawback is their higher computational complexity. Among these methods,
    the iterative least squares approach stands out as an efficient global optimization
    algorithm [48, 49]. Inspired by this algorithm, the additive half-quadratic optimization
    method is adopted to tackle the optimization problem of non-convex penalized objective
    regularization functions. Combining this method with RILS for global optimization-based
    smoothing effectively reduces computational complexity. Ultimately, iteratively
    performing Fourier transform and inverse Fourier transform can achieve edge-preserving
    frequency domain smoothing tasks with fewer computational resources. This approach
    effectively suppresses artifacts and preserves reasonable local peaks in the spectrum,
    thereby reducing the loss of PRNU information caused by smoothing. Applying the
    ZM and RD operations to obtain the noise residual \\({{\\varvec{W}}_{\\varvec{Z}{{\\varvec{M}}_{\\varvec{-}}}\\varvec{RD}}}\\),
    the Fourier transform is performed on the processed noise residual . The zero-frequency
    component is then repositioned at the center of the spectrum, resulting in the
    real part \\({{\\varvec{\\tilde{F}}}_{real}}\\) and imaginary part \\({{\\varvec{\\tilde{F}}}_{imag}}\\)
    of the frequency domain signal of the noise, $$\\begin{aligned} \\left\\{ \\begin{matrix}
    {{{\\varvec{\\tilde{F}}}}_{real}}=real\\left( shift\\left( \\mathcal {F}\\left(
    {{\\varvec{W}}_{\\varvec{Z}{{\\varvec{M}}_{\\varvec{-}}}\\varvec{RD}}} \\right)
    \\right) \\right) \\\\ {{{\\varvec{\\tilde{F}}}}_{imag}}=imag\\left( shift\\left(
    \\mathcal {F}\\left( {{\\varvec{W}}_{\\varvec{Z}{{\\varvec{M}}_{\\varvec{-}}}\\varvec{RD}}}
    \\right) \\right) \\right) \\\\ \\end{matrix} \\right. , \\end{aligned}$$ (24)
    where \\(\\mathcal {F}\\) denotes Fourier transform, shift denotes the operation
    of shifting the zero-frequency component to the center of the matrix, real denotes
    the operation of taking the real part, and imag denotes the operation of taking
    the imaginary part. Note that \\({{\\varvec{\\tilde{F}}}_{*}}\\) is the imaginary
    part or the real part. RILS smoothing is performed for the amplitudes of the imaginary
    and real parts, respectively, and the global optimal smoothing of the signal \\({{\\varvec{\\tilde{F}}}_{*}}\\)
    is achieved by minimizing the objective function defined as follows, $$\\begin{aligned}
    E(l,f)=\\underset{s}{\\mathop {\\sum }}\\,\\left( {{\\left( {{l}_{s}}-{{f}_{s}}
    \\right) }^{2}}+\\lambda \\underset{*\\in \\{x,y\\}}{\\mathop {\\sum }}\\,{{\\phi
    }_{W}}\\left( \\nabla {{l}_{*,s}} \\right) \\right) , \\end{aligned}$$ (25) where
    \\({{f}_{s}}\\) denotes the amplitude of \\({{\\varvec{\\tilde{F}}}_{*}}\\) at
    position s, \\({{l}_{s}}\\) denotes the amplitude of the smoothed signal at position
    s, \\(\\lambda \\) is the parameter to adjust the smoothing intensity. \\(\\nabla
    {{l}_{*,s}}\\) denotes the gradient of the spectrum points along the x-axis or
    y-axis, are calculated using the discrete differential operator \\(\\left[ 1,-1
    \\right] \\) and \\({{\\left[ 1,-1 \\right] }^{T}}\\) . The penalty function is
    chosen from the Welsch penalty function proposed by Badri et al., where the parameter
    \\(\\gamma \\) controls the sharpening intensity: $$\\begin{aligned} \\text {
    }\\!\\!~\\!\\!\\text { }{{\\phi }_{W}}(x)=2{{\\gamma }^{2}}\\left( 1-\\exp \\left(
    \\frac{{{x}^{2}}}{2{{\\gamma }^{2}}} \\right) \\right) . \\end{aligned}$$ (26)
    Using the half-quadratic minimization technique to solve the equation (26), given
    a strictly convex function \\(h\\left( x \\right) ={c{{x}^{2}}}/{2}\\;-{{\\phi
    }_{W}}\\), and defining \\(\\mu ={h}''\\left( y \\right) \\), then \\(y={{\\left(
    {{h}''} \\right) }^{-1}}\\left( \\mu \\right) \\), an inequality relation can
    be represented as: $$\\begin{aligned} {{\\phi }_{\\text {W}}}(x)\\le \\frac{c}{2}{{x}^{2}}-\\mu
    x+\\frac{1}{2c}{{\\mu }^{2}}-\\frac{1}{2c}{{\\mu }^{2}}-h\\left( {{\\left( {{h}''}
    \\right) }^{-1}}(\\mu ) \\right) +\\mu {{\\left( {{h}''} \\right) }^{-1}}(\\mu
    ). \\end{aligned}$$ (27) Defining \\(\\psi (\\mu )=-\\frac{1}{2c}{{\\mu }^{2}}-h\\left(
    {{\\left( {{h}''} \\right) }^{-1}}(\\mu ) \\right) +\\mu {{\\left( {{h}''} \\right)
    }^{-1}}(\\mu )\\), if and only if meeting \\(\\mu ={h}''\\left( x \\right) ={h}''\\left(
    y \\right) =cx-{h}''\\left( \\mu \\right) \\) the inequality takes equal, also
    means \\(\\mu ={h}''\\left( x \\right) ={h}''\\left( y \\right) =cx-{h}''\\left(
    \\mu \\right) \\), so the penalty function can be expressed as: $$\\begin{aligned}
    {{\\phi }_{W}}(x)=\\underset{\\mu }{\\mathop {\\min }}\\,\\left\\{ \\frac{1}{2}{{\\left(
    \\sqrt{c}x-\\frac{1}{\\sqrt{c}}\\mu \\right) }^{2}}+\\psi (\\mu ) \\right\\} .
    \\end{aligned}$$ (28) Under the condition of \\(\\mu =cx-{{\\phi }_{W}}^{\\prime
    }(x)\\), an energy function \\({{\\tilde{E}}_{A}}\\) can be defined as follows,
    $$\\begin{aligned} \\begin{aligned}&{{{\\tilde{E}}}_{A}}\\left( l,f,{{l}_{x}},{{l}_{y}}
    \\right) = \\\\&\\underset{s}{\\mathop {\\sum }}\\,\\left( {{\\left( {{l}_{s}}-{{f}_{s}}
    \\right) }^{2}}+\\lambda \\underset{*\\in \\{x,y\\}}{\\mathop {\\sum }}\\,\\left(
    \\frac{1}{2}{{\\left( \\sqrt{c}\\nabla {{l}_{*,s}}-\\frac{1}{\\sqrt{c}}{{l}_{*,s}}
    \\right) }^{2}}+\\psi \\left( {{l}_{*,s}} \\right) \\right) \\right) \\\\ \\end{aligned}.
    \\end{aligned}$$ (29) According to the energy function \\({{\\tilde{E}}_{A}}\\),
    the objective function can be converted as: $$\\begin{aligned} E(l,f)=\\underset{{{\\mu
    }_{x}},{{\\mu }_{y}}}{\\mathop {\\min }}\\,{{\\tilde{E}}_{A}}\\left( l,f,{{l}_{x}},{{l}_{y}}
    \\right) . \\end{aligned}$$ (30) In the condition of \\({{l}_{*,s}}=c\\nabla {{l}_{*,s}}-\\phi
    _{w}^{\\prime }\\left( \\nabla {{l}_{*,s}}\\right) \\text { }\\!\\!~\\!\\!\\text
    { }\\), according to equation (29) and (30), three variables l, \\({{l}_{x}}\\),
    \\({{l}_{y}}\\) in (30) are updated alternately and the value of l in each iteration
    can be expressed as: $$\\begin{aligned} {{l}^{m+1}}=\\underset{u}{\\mathop {\\arg
    \\min }}\\,{{\\tilde{E}}_{A}}\\left( l,f,l_{x}^{m},l_{y}^{m} \\right) . \\end{aligned}$$
    (31) where m refers to the number of iterations. And the calculation of \\(l_{x}^{m}\\)
    and \\(l_{y}^{m}\\) is performed iteratively by: $$\\begin{aligned} l_{*,s}^{m}=c\\nabla
    l_{*,s}^{m}-\\phi _{W}^{\\prime }\\left( \\nabla l_{*,s}^{m} \\right) =c\\nabla
    l_{*,s}^{m}-2\\nabla l_{*,s}^{m}\\exp \\left( -\\frac{{{\\left( \\nabla l_{*,s}^{m}
    \\right) }^{2}}}{2{{\\gamma }^{2}}} \\right) ,*\\in \\{x,y\\}. \\end{aligned}$$
    (32) In the calculation of \\({{l}^{m+1}}\\), the values of \\(l_{x}^{m}\\) and
    \\(l_{y}^{m}\\) are determined, so \\(\\psi \\left( {{\\varvec{l}}_{*,s}} \\right)
    \\) becomes a constant term can be omitted. Next, iterative least squares can
    be employed to address the LS problem. Moreover, the computational effectiveness
    is improved by employing the Fourier transform. So equation (31) can be rewritten
    as: $$\\begin{aligned} {{l}^{m+1}}={{\\mathcal {F}}^{-1}}\\left( \\frac{\\mathcal
    {F}(f)+\\frac{\\lambda }{2}\\left( \\overline{\\mathcal {F}\\left( {{\\nabla }_{x}}
    \\right) }\\cdot \\mathcal {F}\\left( \\varvec{l}_{x}^{m} \\right) +\\overline{\\mathcal
    {F}\\left( {{\\nabla }_{y}} \\right) }\\cdot \\mathcal {F}\\left( l_{y}^{m} \\right)
    \\right) }{\\mathcal {F}(1)+\\frac{c}{2}\\cdot \\lambda \\left( \\overline{\\mathcal
    {F}\\left( {{\\nabla }_{x}} \\right) }\\cdot \\mathcal {F}\\left( {{\\nabla }_{x}}
    \\right) +\\overline{\\mathcal {F}\\left( {{\\nabla }_{y}} \\right) }\\cdot \\mathcal
    {F}\\left( {{\\nabla }_{y}} \\right) \\right) } \\right) , \\end{aligned}$$ (33)
    where \\(\\mathcal {F}\\) and \\({{\\mathcal {F}}^{-1}}\\)denotes Fourier transform
    and inverse Fourier transform, \\(\\overline{\\mathcal {F}\\left( * \\right) }\\)
    denotes the complex conjugate of \\(\\mathcal {F}\\left( * \\right) \\), \\(\\overline{\\mathcal
    {F}\\left( {{\\nabla }_{x}} \\right) }\\cdot \\mathcal {F}\\left( l_{x}^{m} \\right)
    +\\overline{\\mathcal {F}\\left( {{\\nabla }_{y}} \\right) }\\cdot \\mathcal {F}\\left(
    l_{y}^{m} \\right) =\\mathcal {F}\\left( {{\\nabla }_{\\_}}l_{x}^{m}+{{\\nabla
    }_{\\_}}l_{y}^{m} \\right) \\) can be used to simplify the numerator, \\(\\mathcal
    {F}\\left( 1 \\right) \\) is the Fourier transform of the delta function. Assuming
    that the amplitude of \\({{\\varvec{\\tilde{F}}}_{*}}\\) after m iterations to
    the smoothed signal, where \\({{l}^{m}}\\) denotes the amplitude of the smoothed
    signal at position s. After that, the amplitudes of the smoothed imaginary and
    real parts are obtained separately and the phase is restored, while the zero frequency
    component is shifted back to zero point and the Fourier inverse transform is performed
    to get the initial smoothed signal \\({{\\varvec{S}}_{1}}\\). 3.2.3 Cyclic residual
    recycling The flow chart of the RISS combined with CRR is shown in Fig. 4, where
    \\(\\varvec{Re}\\) and \\(\\varvec{Im}\\) represent the real part and imaginary
    part of the Fourier transform result of the signal respectively, and \\(\\varvec{S}\\)
    represents the signal after each RISS processing. The RISS processing can suppress
    the artifacts, but it must be noted that some of the PRNU information is lost
    in the processed signal because it is not possible to determine which components
    are PRNU information during the processing of the spectrum. In this paper, the
    discrepancy between the pre-enhanced processed signal and the post-enhanced processed
    signal is reprocessed. The reprocessed signal is superimposed on the pre-enhanced
    signal. It is found that the recognition performance is further improved, indicating
    that some of the PRNU information is lost while the noise quality is enhanced.
    Consequently, a CRR algorithm is proposed in this paper. More specifically, the
    residuals of the signals before and after RISS processing become the input of
    the following RISS process. The residuals are reprocessed each time cyclically,
    and the smoothed items are finally superimposed, which can effectively retain
    the complete PRNU information and further improve theaccuracy of identification.
    Fig. 4 Diagram of enhanced model based on CRR Full size image To be more specific,
    The j-th CRR process is that the j-th residual \\(\\varvec{Re}{{\\varvec{s}}_{j}}\\)
    is processed by RISS to obtain \\({{\\varvec{S}}_{j}}\\), $$\\begin{aligned} {{\\varvec{S}}_{j}}=RISS\\left(
    \\varvec{Re}{{\\varvec{s}}_{j}} \\right) , j=1,2,3\\cdots n . \\end{aligned}$$
    (34) After performing the RISS process cyclically, the smoothing parameter \\(\\lambda
    \\) in equation (25) is divided by 2 to decrease the smoothing intensity sequentially.
    Then the new residual \\(\\varvec{Re}{{\\varvec{s}}_{j+1}}\\) obtained by differentiating
    \\(\\varvec{Re}{{\\varvec{s}}_{j}}\\) and \\({{\\varvec{S}}_{j}}\\), as follow:
    $$\\begin{aligned} \\varvec{Re}{{\\varvec{s}}_{j+1}}=\\varvec{Re}{{\\varvec{s}}_{j}}-{{\\varvec{S}}_{j}}
    , j=1,2,3\\cdots n . \\end{aligned}$$ (35) \\(\\varvec{Re}{{\\varvec{s}}_{j+1}}\\)
    then undergoes RISS processing and enters the next circle, and finally after several
    times residual recycle, the \\({{\\varvec{S}}_{j}}\\) after each RISS process
    is superimposed, and the noise signal \\({{\\varvec{W}}_{p}}\\) after the enhancement
    process is represented by the superposition of \\({{\\varvec{S}}_{j}}\\) generated
    by multiple cycles, resulting in a superposition of multiple signals smoothed
    in the frequency domain. So \\({{\\varvec{W}}_{p}}\\) can be expressed as: $$\\begin{aligned}
    {{\\varvec{W}}_{p}}=\\underset{j=1}{\\mathop {\\overset{n}{\\mathop {\\sum }}\\,}}\\,{{S}_{j}},n=1,\\cdot
    \\cdot \\cdot ,j . \\end{aligned}$$ (36) Algorithm 2 Enhancement model based on
    RISS and CRR. Full size image It is found that the recognition performance increases
    as the number of cycles j increases. It is worth noting that the recognition performance
    starts to decrease after four cycles. Although the recycling algorithm successfully
    preserves PRNU information through a certain number of cycles, it should be noted
    that beyond this point, non-PRNU information may be introduced, leading to potential
    interference with recognition. There are also different recycling cases for various
    scenes of noise, so the number of cycles depends on the noise from different backgrounds.
    Suppose the signal superimposed to the j-th time is \\({{\\varvec{W}}_{j}}\\).
    It was experimentally discovered that the number of cycles j could be determined
    by the trend of the SPCE values of \\({{\\varvec{W}}_{j}}\\) and \\({{\\varvec{W}}_{Z{{M}_{-}}RD}}\\)
    to balance artifact suppression and PRNU information retention. With the increase
    of j, the SPCE between both gradually decreases, and the SPCE values are calculated
    for \\({{\\varvec{W}}_{j}}\\) and \\({{\\varvec{W}}_{j+1}}\\) of two adjacent
    times with \\({{\\varvec{W}}_{Z{{M}_{-}}RD}}\\), respectively, when the difference
    of SPCE between two adjacent times is less than a threshold value. Indicating
    that the gap between \\({{\\varvec{W}}_{j}}\\) and \\({{\\varvec{W}}_{j+1}}\\)
    is minimal, at which point out the CRR algorithm has essentially recovered the
    PRNU information, i.e., when satisfying: $$\\begin{aligned} \\left| \\text {SPCE}\\left(
    {{\\varvec{W}}_{Z{{M}_{-}}RD}},{{\\varvec{W}}_{j+1}} \\right) -\\text {SPCE}\\left(
    {{\\varvec{W}}_{Z{{M}_{-}}RD}},{{\\varvec{W}}_{j}} \\right) \\right| <\\Gamma
    , \\end{aligned}$$ (37) CRR terminates at this time. Where \\(\\Gamma \\text {=}100\\).
    The flow of the improved enhancement processing algorithm proposed in this paper
    is shown in Algorithm 2. Fig. 5 Fingerprint spectrum of Agfa-DC-830i (a) noise
    spectrum without preprocessing (b) Noise spectrum without preprocessing in the
    range of 0-200 (c) spectrum after \\(\\text {ZM+WF}\\) (d) spectrum after SEA
    (e) spectrum after \\(\\text {SEA+HF}\\) (f) spectrum after the proposed algorithm
    Full size image To compare the modification of the spectrum for each enhancement
    model, 512\\(\\times \\)512 sub-images from the center of a photo taken with the
    Agfa-DC-830i camera are selected to estimate the camera fingerprint. The comparison
    of the spectrum after different enhanced steps is shown in Fig. 5. In Fig. 5(a),
    the origin noise residual without enhancement shows several prominent peaks in
    the spectrum, indicating the presence of periodic artifacts in the noise. Figure
    5(b) limits the Z-axis range of Fig. 5(a) to 0-200. Figure 5(c) shows the spectrum
    after \\(\\text {ZM+WF}\\) processing, which appears too flat. Using a mean filter
    by SEA in Fig. 5(d) makes the spectrum too smooth, and \\(\\text {SEA+HF}\\) in
    Fig. 5(e) causes the loss of a lot of low-frequency information. Figure 5(f) shows
    the spectrum processed by the algorithm proposed in this paper. The RISS processing
    effectively suppresses the spectrum peak, and the CRR algorithm superimposes several
    signals with a relatively flat spectrum, resulting in a relatively flat signal
    spectrum similar to the origin spectrum, thereby reducing the loss of PRNU information.
    Additionally, the signal is attenuated at high frequencies since RD removes the
    diagonal high-frequency components. 4 Experiment and analysis 4.1 Experimental
    setup The Dresden Image Database [50], a publicly available dataset, is chosen
    to assess the effectiveness of proposed model. The images in this dataset are
    of the highest available JPEG quality or are losslessly compressed with the maximum
    available resolution. Photos from 20 cameras in the dataset are selected, including
    multiple cameras of the same model. The experiments in this paper involve estimating
    the fingerprint \\(\\varvec{R}\\) using noise residuals from 50 photos per camera
    and testing with an additional 100 images, resulting in a total of 2000 unknown
    photos evaluated. The images captured by each model have different resolutions.
    Table 1 lists the 20 camera models that were tested in this paper. Three typical
    situations were considered to compare the performance of source camera recognition
    under different compression scenarios: C1, where the reference and test images
    are not compressed; C2, where the reference images are uncompressed and the test
    images are compressed; and C3, where both the reference and test images are compressed.
    The difficulty of source camera identification in these three cases increases
    sequentially. Table 2 lists the sources of noise extraction for each of the three
    cases. 4.2 Evaluation indicators Matching and identifying the SPCE value calculated
    by the noise residual of each test photo with the reference PRNU of the 20 cameras
    is to evaluate the performance of the various methods. Kappa statistics, ROC curves
    (Receiver Operating Characteristic curves), and the area under the ROC curve (AUC)
    are used for analysis to ensure a direct and objective evaluation. Kappa is expressed
    as: $$\\begin{aligned} Kappa=\\frac{O-e}{U-e}, \\end{aligned}$$ (38) where U is
    the total number of samples, O is the actual number of correctly predicted samples,
    and e is the number of theoretically correctly predicted samples. The ROC curve
    reflects the true positive rate TPR (True Positive Rate) and false positive rate
    FPR (False Positive Rate) at different thresholds: $$\\begin{aligned} TPR=\\frac{TP}{TP+FN},
    \\end{aligned}$$ (39) $$\\begin{aligned} FPR=\\frac{FP}{FP+TN}, \\end{aligned}$$
    (40) where True Positive (TP) refers to the number of positive samples correctly
    identified by the classifier, while False Positive (FP) indicates the number of
    negative samples mistakenly identified as positive. On the other hand, True Negative
    (TN) represents the number of negative samples correctly identified, and False
    Negative (FN) reflects the number of positive samples mistakenly classified as
    negative. In this paper, only the ROC curves of FPR are intercepted when the FPR
    is small, because the gap between the ROC curves of different model stores gradually
    decreases as the FPR increases, and comparing TPR when the FPR is small can better
    reflect the differences of each algorithm. Furthermore, TPR, when FPR=\\(10^{-3}\\),
    is also compared to meet the requirement of low FPR in practical applications.
    Table 1 Devices used for experiments Full size table Table 2 Different cases of
    fingerprint and noise estimation Full size table 4.3 Performance comparison Eleven
    PRNU extraction algorithms from the current cutting-edge are included for comparison
    in order to assess the recognition performance of the proposed PRNU extraction
    model. In this paper, we refer to the method in literature [7] as Basic, the method
    in literature [8] as MLE, the method in literature [9] as BM3D, the method in
    literature [10] as Phase, the method in literature [12] as SEA, the method in
    literature [11] as CAGIF, the method in literature [13] as SEA+HF, the method
    in literature [15] as DTCWT, the method in literature [17] as SDA, the method
    in literature [27] as MPR, method in literature [22] as VST and method in literature
    [31] as DHDN. The current algorithm can achieve excellent results under high-resolution
    images, but extracting noise and PCE calculation under large resolutions is time-consuming.
    It also takes up a lot of computer memory. Small-resolution image matching is
    essential in image tamper detection and HDR image source identification. In this
    paper, the image blocks clipping out of the central region of each photo have
    been experimented with, and three image blocks of varied sizes are selected for
    experiments, with the resolution of image blocks being 128\\(\\times \\)128, 256\\(\\times
    \\)256, and 512\\(\\times \\)512 respectively. In addition,128\\(\\times \\)128
    is often the size used for image tampering detection [15]. Firstly, the highest
    JPEG quality (QF=100) is compared, and the experimental results are presented
    in Table 3, Fig.7 and Fig.6. Table 3 presents a detailed comparative evaluation
    of source camera identification methods across three distinct block sizes: 128\\(\\times
    \\)128, 256\\(\\times \\)256, and 512\\(\\times \\)512 pixels, all at the highest
    JPEG quality factor (QF=100). The Kappa coefficient data in Table 3 clearly show
    that the choice of resolution significantly impacts the performance of these methods.
    As the resolution increases from lower to higher, there is a consistent and substantial
    improvement in the recognition accuracy across the board. It can be seen that
    the proposed method outperforms other methods in all three resolutions, with improvements
    of 0.0268, 0.0216 and 0.0037 compared to the second-ranked method. DHDN is highly
    competitive, ranking second in all three resolutions. In the 128\\(\\times \\)128
    resolution category, VST, BM3D and DTCWT are the closest competitors. At 256\\(\\times
    \\)256 and 512\\(\\times \\)512 resolution, BM3D remains a strong challenger to
    the proposed model, closely following in performance. Interestingly, the VST method
    demonstrates a degree of similarity to the proposed model, achieving high Kappa
    coefficients across various resolutions. This suggests that VST shares some features
    with the proposed model, especially in the 512\\(\\times \\)512 resolution category.
    However, notable similarities and competitiveness are also observed among several
    methods, particularly in the 128\\(\\times \\)128 resolution category. The Basic,
    Phase, SEA, CAGIF, and SEA+HF methods exhibit comparable performance and are positioned
    toward the end of the ranking. SDA achieves performance close to Basic while reducing
    running time. Table 3 Kappa coefficient of different block size with QF=100 Full
    size table Fig. 6 When FPR=\\(10^{-3}\\), the value of TPR in different Block
    Size with QF=100 Full size image Fig. 7 ROC curve comparison of different block
    sizes with QF=100 Full size image By observing Fig. 7, our method consistently
    outperforms the other algorithms at all three resolutions. DHDN is very close
    to the proposed model. The VST, DTCWT, and BM3D methods exhibit remarkably similar
    performance, positioning them in the second tier at 128\\(\\times \\)128 and 256\\(\\times
    \\)256 resolutions. Meanwhile, the remaining methods fall into the third tier,
    with MPR and SEA+HF demonstrating comparatively lower performance levels. At the
    512\\(\\times \\)512 resolution, SDA and Basic lag behind, particularly at lower
    FPR . This can be attributed to their susceptibility to substantial non-PRNU noise
    interference, primarily due to the lack of enhancement procedures. On the other
    hand, the BM3D, DTCWT, MLE, Phase, VST, and SEA methods exhibit closely aligned
    performance, forming a cohesive second-tier group. Figure 6 displays the TPR at
    FPR=\\(10^{-3}\\). At 128\\(\\times \\)128 resolution, DHDN surpasses the proposed
    model, while BM3D is close to the proposed model and ranks second. The proposed
    model outperforms the remaining models at the other two resolutions. Consistent
    with the previous observations, the performance of DHDN is very close to that
    of the proposed model, but the proposed model has more advantages in other metrics.
    VST, DTCWT, and BM3D show similar performance, placing them in the second tier.
    As the resolution increases, the performance gaps between these algorithms and
    others gradually narrow. Subsequently, we proceed to compare the recognition performance
    on strongly JPEG-compressed images. Lossy image compression results in a degradation
    of fine image details and a partial loss of PRNU information. Furthermore, it
    introduces JPEG periodic artifacts into the noise residuals, thereby degrading
    the quality of PRNU, especially under strong JPEG compression or multiple rounds
    of JPEG compression. To simulate the source camera identification of compressed
    images uploaded to social media and assess the robustness of various algorithms
    to strong JPEG compression, the images from the Dresden dataset are subjected
    to JPEG compression. Specifically, photos with different quality factors (QF)
    are selected to represent varying compression levels for source camera identification.
    The QF values range from 0 to 100, where lower values indicate lower image quality
    with more pronounced compression. For this study, QF values ranging from 40 to
    90 are chosen. Table 4 Kappa coefficient of compressed testing image only Full
    size table Two common scenarios can be observed in the context of source camera
    identification for compressed images. The first scenario involves using uncompressed,
    high-quality images to estimate the reference fingerprint. The second scenario
    occurs when both the reference and test images are subjected to compression. These
    scenarios are denoted as C2 and C3 in Table 2, respectively. During the experimentation,
    it was noticed that the performance at resolutions of 128\\(\\times \\)128 and
    256\\(\\times \\)256 was unsatisfactory and lacked practical significance for
    both C2 and C3 scenarios. As a result, this study focuses solely on the 512\\(\\times
    \\)512 resolution. The experimental results for the C2 scenario are presented
    in Table 4, Figs. 8 and 9, while Table 5, Figs. 10 and 11 showcase the experimental
    outcomes for the C3 scenario, where both the reference and test images undergo
    the same level of compression. Table 4 presents an analysis of the Kappa coefficient
    between the compressed test image and the original image. The results unambiguously
    demonstrate that the Proposed method consistently attains near-perfect consistency
    grades across all Quality Factors (QFs), significantly surpassing the performance
    of other methods. For instance, at QF=90, the Proposed method achieves a Kappa
    coefficient of 0.9753, outperforming the second-ranking DHDN method by 0.0206.
    Similarly, at QF=40, the Proposed method attains a Kappa coefficient of 0.8000,
    surpassing the second-ranking DHDN method by 0.0774. In contrast, the SEA+HF method
    consistently lags behind, consistently delivering notably inferior performance
    across all QFs. For example, at QF=90, the SEA+HF method records a Kappa coefficient
    of 0.8411, which is 0.0536 lower than that of the second-lowest Basic method.
    Likewise, at QF=40, the SEA+HF method yields a Kappa coefficient of 0.3384, trailing
    the second-lowest Basic method by 0.17. The remaining methods fall between the
    Proposed and SEA+HF methods in terms of performance. Notably, the BM3D, DTCWT,
    and VST methods exhibit relatively better performance, while the Basic, Phase,
    SDA, and MPR methods perform relatively worse. For instance, at QF=90, the Kappa
    coefficients of BM3D, DTCWT, and VST methods all exceed 0.93, whereas the Kappa
    coefficients of the Basic, Phase, SDA, and MPR methods remain below 0.92. At QF=40,
    BM3D, DTCWT, and VST methods maintain Kappa coefficients above 0.64, while the
    Basic, Phase, SDA, and MPR methods all have Kappa coefficients below 0.55. Moving
    on to Table 5, it showcases Kappa coefficients for compressed test and reference
    images with identical QFs. Once again, the Proposed method emerges as the top
    performer across all QFs. For example, at QF=90, the Proposed method boasts a
    Kappa coefficient of 0.9674, outperforming the second-ranked VST method by 0.0269.
    Similarly, at QF=40, the Proposed method achieves a Kappa coefficient of 0.4237,
    surpassing the second-ranked VST method by 0.0532. Conversely, the SEA+HF method
    consistently exhibits the poorest performance. Among the other methods, DHDN,BM3D,
    DTCWT, and VST perform relatively better, whereas Basic, Phase, SDA, and MPR methods
    exhibit comparatively weaker performance. For instance, at QF=90, the Kappa coefficients
    of DHDN, BM3D, DTCWT, and VST methods exceed 0.92, while the Kappa coefficients
    of Basic, Phase, SDA, and MPR methods remain below 0.89. At QF=40, BM3D, DTCWT,
    and VST methods maintain Kappa coefficients above 0.35, while the Basic, Phase,
    SDA, and MPR methods all register Kappa coefficients below 0.30. Furthermore,
    when examining the TPR values in Figs. 8 and 10, our model exhibits better performance
    than the others, particularly under strong compression conditions. The low image
    quality in both the C2 and C3 scenarios exacerbates the challenging task of source
    camera identification. In the C3 scenario, the reference fingerprint is additionally
    affected by JPEG compression, leading to further performance degradation compared
    to the C2 scenario. The proposed model starts to show the leading performance
    below QF=80. Figure 8 and Fig. 10 DHDN also shows a good performance in second
    place, VST and BM3D are very close to each other, and the performance of DTCWT
    declines a bit faster with the increase of compression degree. Except for SEA+HF,
    the rest of the methods also have good performance. It is worth noting that in
    Fig. 10, the TPR is very small after the QF is lower than 60, and it loses its
    meaning in the real application, too low QF images should be considered to be
    matched with larger size images. Fig. 8 When FPR=\\(10^{-3}\\),the value of TPR
    of compressed testing image only Full size image Fig. 9 ROC curve comparison of
    compressed testing image only Full size image Table 5 Kappa coefficient of the
    reference image and test image with the same quality factor Full size table Fig.
    10 When FPR=\\(10^{-3}\\), the value of TPR of the reference image and test image
    with the same quality factor Full size image Fig. 11 ROC curve comparison of the
    reference image and test image with the same quality factor Full size image The
    ROC curves depicted in Figs. 9 and 11 demonstrate the superior performance of
    our model compared to the competing models. In Fig. 9 DHDN stays in second place,
    BM3D, DTCWT, and VST keep a good competitive performance very close to each other,
    and the rest of the models are in the third tier except for the SEA+HF model which
    is the worst performer. Figure 11, the performance of DHDN slips keeping close
    to BM3D, DTCWT, VST. This condition where the reference image is also compressed,
    useful PRNU information is very sparse, and the model will be the gap is gradually
    decreasing, but it is worth noting that the MPR has a problem at QF=40, and the
    ROC curve becomes diagonal indicating that the recognition has been invalidated,
    and is already randomly assigned. The PRNU information within the extracted noise
    residuals under strong JPEG compression is already quite weak. Excessive enhancement
    processing further diminishes the peak values in the spectrum, resulting in a
    greater loss of PRNU information within the signal. The enhancement algorithms
    SEA, Phase, and SEA+HF demonstrate superior performance compared to the Basic
    algorithm at higher image qualities. It is certainly noticeable that as the image
    quality factor decreases, the ROC curves of the unenhanced images begin to outperform
    some of the enhanced ROC curves. Especially SEA+HF has the worst performance in
    strong compressed images. This observation indicates that existing enhancement
    model excessively weaken spectral components, leading to a negative impact of
    PRNU information loss that outweighs the positive effect of suppressing non-unique
    artifacts. Among the other models, SDA shows a performance close to the Basic
    model despite a significant reduction in time complexity. In the scenario of C3
    with QF=40, the MPR model demonstrates a failure in recognition. Specifically,
    the Kappa value is only 0.0142, the ROC curve appears almost linear. Additionally,
    the AUC value is approximately 0.5, suggesting that the model’s predictive power
    is equivalent to random chance. The DHDN,VST, BM3D, and DTCWT models exhibit superior
    performance, ranking 2nd to 5th, respectively. Comparing the Kappa coefficient,
    ROC curves, AUC values, and TPR at FPR=\\(10^{-3}\\), it is evident that the proposed
    model in this study outperforms other models in estimating PRNU noise in compressed
    images and low-resolution images. The proposed approach reduces the interference
    from image details by utilizing the GAT to modulate PRNU into a Gaussian-like
    signal and employing an adaptive block clustering PCA filter to extract the noise
    in small image blocks. Moreover, the enhancement algorithm proposed in this study
    demonstrates robustness to strong image compression, as it effectively removes
    non-unique artifacts while preserving a significant amount of PRNU information
    through iterative recycling, making it more robust to strong compression compared
    to other algorithms. To comprehensively evaluate the performance of our algorithm
    under diverse conditions, we present three sets of confusion matrices. These matrices
    correspond to three distinct scenarios: in C1, we consider images with a resolution
    of 512 pixels, while in C2 and C3, we examine images with a fixed quality factor
    of 70. For each scenario, we not only showcase the classification confusion matrix
    (CM) but also introduce a specialized confusion matrix that highlights instances
    where the Probability of PCE exceeds the 60 threshold (CM60). Figure 12 shows
    two distinct matrices for each of the three scenarios, with the left side representing
    the confusion matrix for classification results and the right side depicting the
    matrix for cases where PCE exceeds 60. Two confusion matrix also visually illustrates
    that the influence of JPEG compression is increasing across these three scenarios,
    resulting in an increase in false positives from unrelated cameras. The reason
    is that the values of intra-class PCE are continually decreasing, making it challenging
    to effectively distinguish between positive and negative samples. From the experimental
    results, we can observe that cameras 10 and 11 exhibit poorer performance, which
    could be attributed to a variety of factors such as internal processing, lighting
    conditions, hardware disparities, image post-processing, and data sample. Fig.
    12 The proposed model’s comparison of two confusion matrices in each of the three
    scenarios Full size image Figure 13 presents the statistical data on the execution
    time of different PRNU extraction models. The tests were performed on 512\\(\\times
    \\)512 image blocks, with them being run 100 times and the average execution time
    being calculated. These tests were conducted on a desktop computer equipped with
    a 3.7GHz AMD R9-5900X CPU, RTX 3090 GPU and 64 GB of memory, using MATLAB 2021b
    and Python 3.6. In particular, MPR and DHDN run on the GPU while the other models
    run on the CPU, and these two deep learning methods do not encapsulate the training
    time, and only the time taken to extract PRNUs is compared here. SDA demonstrates
    the fastest execution time among the models. DHDN has the longest execution time,
    but it must be admitted that the proposed model is the slowest except for deep
    learning. This is primarily due to the time-consuming clustering process in noise
    extraction and the couple times of iterative least squares employed in CRR. Nevertheless,
    these computationally intensive steps enable the algorithm to estimate the PRNU
    signal more accurately from the image and effectively adjust the frequency characteristics
    of the noise. Fig. 13 Comparison of running times Full size image 5 Conclusion
    To enhance the quality of PRNU and address the challenges posed by strong JPEG
    compression, an improved PRNU extraction model is proposed. An adaptive block
    clustering PCA filter, combined with variance-stabilizing transformation, is initially
    utilized to extract the noise. This improved filter is capable of effectively
    reducing the interference of image texture in the PRNU and accurately separating
    the PRNU components associated with the noise-free signal. The wavelet transform
    is then employed to eliminate the diagonal high-frequency components of the mean-zero
    processed noise. Subsequently, the real and imaginary parts of the noise spectrum
    are separated and smoothed iteratively. To preserve more comprehensive PRNU information,
    further propose a cyclic recycling strategy. Experimental results on the Dresden
    public dataset demonstrate that the proposed PRNU extraction model outperforms
    other models. Our proposed PRNU extraction model offers several notable advantages.
    Firstly, it significantly enhances PRNU quality, particularly excelling in scenarios
    involving small image blocks and high compression levels. This improved performance
    can be invaluable in source camera identification tasks where image quality is
    often compromised. Additionally, our model stands out by not requiring any prior
    information, in contrast to some deep learning-based approaches. This absence
    of the need for prior information simplifies the workflow and potentially widens
    its applicability to a broader range of scenarios. However, it’s important to
    acknowledge that our model does have some limitations. One significant drawback
    is its running times, which tends to be longer compared to certain other methods.
    Another is that our model is the presence of hyperparameters, which could render
    it highly sensitive to parameter settings. This sensitivity may necessitate meticulous
    tuning to achieve optimal performance, potentially resulting in instability and
    reduced generality in practical applications. 6 Future work In our upcoming work,
    we will concentrate on elevating source camera recognition through deep learning
    and extending our model’s capabilities to accommodate both images and videos,
    thus addressing the requirements of multi-modal media data. This endeavor entails
    enhancing source camera recognition accuracy through the utilization of deep convolutional
    neural networks, encompassing deeper architectural designs, integrating attention
    mechanisms, and incorporating generative models. Furthermore, our goal is to create
    models adept at seamlessly processing both static images and dynamic videos, thereby
    catering to the intricacies of real-world scenarios involving multi-modal media
    data. Data Availability Data sharing not applicable to this article as no datasets
    were generated or analyzed during the current study. References Rocha A, Scheirer
    W, Boult T, Goldenstein S (2011) Vision of the unseen: Current trends and challenges
    in digital image and video forensics. ACM Comput Surv (CSUR) 43(4):1–42 Article   Google
    Scholar   Goljan M, Chen M, Comesaña P, Fridrich J (2016) Effect of compression
    on sensor-fingerprint based camera identification. Electron Imaging 28:1–10 Article   Google
    Scholar   Geradts Z.J, Bijhold J, Kieft M, Kurosawa K, Kuroki K, Saitoh N (2001)
    Methods for identification of images acquired with digital cameras. In: Enabling
    technologies for law enforcement and security, vol 4232, pp 505–512 .SPIE Swaminathan
    A, Wu M, Liu KR (2007) Nonintrusive component forensics of visual sensors using
    output images. IEEE Trans Inf Forensics Secur 2(1):91–106 Article   Google Scholar   Alles
    EJ, Geradts ZJ, Veenman CJ (2009) Source camera identification for heavily jpeg
    compressed low resolution still images. J Forensic Sci 54(3):628–638 Article   Google
    Scholar   San Choi K, Lam EY, Wong KK (2006) Source camera identification using
    footprints from lens aberration. In: Digital photography II, vol 6069, pp 172–179.
    SPIE Lukas J, Fridrich J, Goljan M (2006) Digital camera identification from sensor
    pattern noise. IEEE Trans Inf Forensics Secur 1(2):205–214 Article   Google Scholar   Chen
    M, Fridrich J, Goljan M, Lukás J (2008) Determining image origin and integrity
    using sensor noise. IEEE Trans Inf Forensics Secur 3(1):74–90 Article   Google
    Scholar   Cortiana A, Conotter V, Boato G, De Natale FG (2011) Performance comparison
    of denoising filters for source camera identification. In: Media watermarking,
    security, and forensics III, vol. 7880, pp 60–65. SPIE Kang X, Li Y, Qu Z, Huang
    J (2011) Enhancing source camera identification performance with a camera reference
    phase sensor pattern noise. IEEE Trans Inf Forensics Secur 7(2):393–402 Article   Google
    Scholar   Zeng H, Kang X (2016) Fast source camera identification using content
    adaptive guided image filter. J Forensic Sci 61(2):520–526 Article   Google Scholar   Lin
    X, Li C-T (2015) Preprocessing reference sensor pattern noise via spectrum equalization.
    IEEE Trans Inf Forensics Secur 11(1):126–140 Article   MathSciNet   Google Scholar   Gupta
    B, Tiwari M (2018) Improving performance of source-camera identification by suppressing
    peaks and eliminating low-frequency defects of reference spn. IEEE Signal Process
    Lett 25(9):1340–1343 Article   Google Scholar   Rao Q, Wang J (2017) Suppressing
    random artifacts in reference sensor pattern noise via decorrelation. IEEE Signal
    Process Lett 24(6):809–813 Article   Google Scholar   Zeng H, Wan Y, Deng K, Peng
    A (2020) Source camera identification with dual-tree complex wavelet transform.
    IEEE Access 8:18874–18883 Article   Google Scholar   Quan Y, Li C-T (2020) On
    addressing the impact of iso speed upon prnu and forgery detection. IEEE Trans
    Inf Forensics Secur 16:190–202 Article   Google Scholar   Taspinar S, Mohanty
    M, Memon N (2020) Camera fingerprint extraction via spatial domain averaged frames.
    IEEE Trans Inf Forensics Secur 15:3270–3282 Article   Google Scholar   Lawgaly
    A, Khelifi F (2016) Sensor pattern noise estimation based on improved locally
    adaptive dct filtering and weighted averaging for source camera identification
    and verification. IEEE Trans Inf Forensics Secur 12(2):392–404 Article   Google
    Scholar   López RR, Orozco ALS, Villalba LJG (2021) Compression effects and scene
    details on the source camera identification of digital videos. Expert Syst Appl
    170:114515 Article   Google Scholar   Bellavia F, Fanfani M, Colombo C, Piva A
    (2021) Experiencing with electronic image stabilization and prnu through scene
    content image registration. Pattern Recognit Lett 145:8–15 Article   Google Scholar   Quintanar-Reséndiz
    AL, Rodríguez-Santos F, Pichardo-Méndez JL, Delgado-Gutiérrez G, Ramírez OJ, Vázquez-Medina
    R (2021) Capture device identification from digital images using kullback-leibler
    divergence. Multimed Tools Appl 80:19513–19538 Article   Google Scholar   Su K,
    Tian N, Pan Q (2022) Multimedia source identification using an improved weight
    photo response non-uniformity noise extraction model in short compressed videos.
    Forensic Sci Int Digit Investig 42:301473 Article   Google Scholar   Bruni V,
    Tartaglione M, Vitulano D (2022) Coherence of prnu weighted estimations for improved
    source camera identification. Multimed Tools Appl 81(16):22653–22676 Article   Google
    Scholar   Timmerman D, Bennabhaktula S, Alegre E, Azzopardi G (2020) Video camera
    identification from sensor pattern noise with a constrained convnet. arXiv:2012.06277
    Hui C, Jiang F, Liu S, Zhao D Source camera identification with multi-scale feature
    fusion network. In: 2022 IEEE international conference on multimedia and Expo
    (ICME), pp 1–6 (2022). IEEE Wang B, Yu F, Ma Y, Zhao H, Hou J, Zheng W (2023)
    Pcep: Few-shot model-based source camera identification. Mathematics 11(4):803
    Article   Google Scholar   Zamir SW, Arora A, Khan S, Hayat M, Khan FS, Yang M-H,
    Shao L (2021) Multi-stage progressive image restoration. In: Proceedings of the
    IEEE/CVF conference on computer vision and pattern recognition, pp 14821–14831
    Lin X, Li C-T (2020) Prnu-based content forgery localization augmented with image
    segmentation. IEEE Access 8:222645–222659 Article   Google Scholar   Gloe T, Böhme
    R (2010) The’dresden image database’for benchmarking digital image forensics.
    In: Proceedings of the 2010 ACM symposium on applied computing, pp 1584–1590 Bernacki
    J Robustness of digital camera identification with convolutional neural networks.
    (2021) Multimed Tools Appl 80(19):29657–29673 Xiao Y, Tian H, Cao G, Yang D, Li
    H (2022) Effective prnu extraction via densely connected hierarchical network.
    Multimed Tools Appl 81(15):20443–20463 Article   Google Scholar   Zheng H, You
    C, Wang T, Ju J, Li X (2023) Source camera identification based on an adaptive
    dual-branch fusion residual network. Multimed Tools Appl , pp 1–17 Liu Y, Zou
    Z, Yang Y, Law N-FB, Bharath AA (2021) Efficient source camera identification
    with diversity-enhanced patch selection and deep residual prediction. Sensors
    21(14):4701 Article   Google Scholar   Chakraverti S, Agarwal P, Pattanayak HS,
    Chauhan SPS, Chakraverti AK, Kumar M (2023) De-noising the image using dbst-lcm-clahe:
    A deep learning approach. Multimed Tools Appl, pp 1–26 Mandelli S, Bestagini P,
    Verdoliva L, Tubaro S (2019) Facing device attribution problem for stabilized
    video sequences. IEEE Trans Inf Forensics Secur 15:14–27 Article   Google Scholar   Altinisik
    E, Sencar HT (2020) Source camera verification for strongly stabilized videos.
    IEEE Trans Inf Forensics Secur 16:643–657 Article   Google Scholar   Fanfani M,
    Piva A, Colombo C (2022) Prnu registration under scale and rotation transform
    based on convolutional neural networks. Pattern Recognit 124:108413 Article   Google
    Scholar   Darvish Morshedi Hosseini M, Goljan M (2019) Camera identification from
    hdr images. In: Proceedings of the ACM workshop on information hiding and multimedia
    security, pp 69–76 Goljan M (2008) Digital camera identification from images–estimating
    false acceptance probability. In: International workshop on digital watermarking,
    pp 454–468. Springer Starck J-L, Murtagh FD, Bijaoui A (1998) Image processing
    and data analysis: the multiscale approach. Cambridge University Press Makitalo
    M, Foi A (2012) Optimal inversion of the generalized anscombe transformation for
    poisson-gaussian noise. IEEE Trans Image Process 22(1):91–103 Article   MathSciNet   Google
    Scholar   Zhao W, Liu Q, Lv Y, Qin B (2019) Texture variation adaptive image denoising
    with nonlocal pca. IEEE Trans Image Process 28(11):5537–5551 Article   MathSciNet   Google
    Scholar   Ahirwar G (2014) A novel k means clustering algorithm for large datasets
    based on divide and conquer technique. Pradnyesh J Bhisikar (IJCSIT) Int J Comput
    Sci Inf Technol 5(1):301–305 Bigot J, Deledalle C, Féral D (2017) Generalized
    sure for optimal shrinkage of singular values in low-rank matrix denoising. J
    Mach Learn Res 18(1):4991–5040 MathSciNet   Google Scholar   Katkovnik V (1999)
    A new method for varying adaptive bandwidth selection. IEEE Trans Signal Process
    47(9):2567–2571 Article   Google Scholar   Chen J, Benesty J, Huang Y, Doclo S
    (2006) New insights into the noise reduction wiener filter. IEEE Trans Audio Speech
    Lang Process 14(4):1218–1234 Article   Google Scholar   Gloe T, Pfennig S, Kirchner
    M (2012) Unexpected artefacts in prnu-based camera identification: a’dresden image
    database’case-study. In: Proceedings of the on multimedia and security, pp 109–114
    Liu W, Zhang P, Huang X, Yang J, Shen C, Reid I (2020) Real-time image smoothing
    via iterative least squares. ACM Trans Graph(TOG) 39(3):1–24 Zeng L, Chen Y, Yang
    Y, Pan Z (2023) Edge-aware image smoothing via weighted sparse gradient reconstruction.
    Signal, Image and Video Processing, pp 1–9 Google Scholar   Gloe T, Böhme R (2010)
    The’dresden image database’for benchmarking digital image forensics. In: Proceedings
    of the 2010 ACM symposium on applied computing, pp 1584–1590 Download references
    Funding This research was funded by the National Natural Science Foundation of
    China (61901123). Author information Authors and Affiliations School of Information
    Engineering, Guangdong University of Technology, Guangzhou, 510006, China Nili
    Tian, Xian Qiu & Qing Pan Corresponding author Correspondence to Qing Pan. Ethics
    declarations Conflicts of interest The authors declare no competing interests.
    Additional information Publisher''s Note Springer Nature remains neutral with
    regard to jurisdictional claims in published maps and institutional affiliations.
    Rights and permissions Springer Nature or its licensor (e.g. a society or other
    partner) holds exclusive rights to this article under a publishing agreement with
    the author(s) or other rightsholder(s); author self-archiving of the accepted
    manuscript version of this article is solely governed by the terms of such publishing
    agreement and applicable law. Reprints and permissions About this article Cite
    this article Tian, N., Qiu, X. & Pan, Q. An improved PRNU noise extraction model
    for highly compressed image blocks with low resolutions. Multimed Tools Appl (2024).
    https://doi.org/10.1007/s11042-024-18255-3 Download citation Received 22 July
    2023 Revised 16 October 2023 Accepted 09 January 2024 Published 24 January 2024
    DOI https://doi.org/10.1007/s11042-024-18255-3 Share this article Anyone you share
    the following link with will be able to read this content: Get shareable link
    Provided by the Springer Nature SharedIt content-sharing initiative Keywords Image
    forensics Source camera identification Photo response non-uniformity Image processing
    algorithms Compressed image identification Use our pre-submission checklist Avoid
    common mistakes on your manuscript. Sections Figures References Abstract Introduction
    Background Proposed PRNU extraction model Experiment and analysis Conclusion Future
    work Data Availability References Funding Author information Ethics declarations
    Additional information Rights and permissions About this article Advertisement
    Discover content Journals A-Z Books A-Z Publish with us Publish your research
    Open access publishing Products and services Our products Librarians Societies
    Partners and advertisers Our imprints Springer Nature Portfolio BMC Palgrave Macmillan
    Apress Your privacy choices/Manage cookies Your US state privacy rights Accessibility
    statement Terms and conditions Privacy policy Help and support 129.93.161.219
    Big Ten Academic Alliance (BTAA) (3000133814) - University of Nebraska-Lincoln
    (3000134173) © 2024 Springer Nature"'
  inline_citation: '>'
  journal: Multimedia Tools and Applications
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: An improved PRNU noise extraction model for highly compressed image blocks
    with low resolutions
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Oliveira A.J.
  - Ferreira B.M.
  - Cruz N.A.
  - Diamant R.
  citation_count: '0'
  description: 'The calibration of sensors stationed along a cable in marine observatories
    is a time-consuming and expensive operation that involves taking the mooring out
    of the water periodically. In this paper, we present a method that allows an underwater
    vehicle to approach a mooring, in order to take reference measurements along the
    cable for in-situ sensor calibration. We use the vehicle&#x0027;s Mechanically
    Scanned Imaging Sonar (MSIS) to identify the cable&#x0027;s reflection within
    the sonar image. After pre-processing the image to remove noise, enhance contour
    lines, and perform smoothing, we employ three detection steps: 1) selection of
    regions of interest that fit the cable&#x0027;s reflection pattern, 2) template
    matching, and 3) a track-before-detect scheme that utilized the vehicle&#x0027;s
    motion. The later involves building a lattice of template matching responses for
    a sequence of sonar images, and using the Viterbi algorithm to find the most probable
    sequence of cable locations that fits the maximum speed assumed for the surveying
    vessel. Performance is explored in pool and sea trials, and involves an MSIS onboard
    an underwater vehicle scanning its surrounding to identify a steel-core cable.
    The results show a sub-meter accuracy in the multi-reverberant pool environment
    and in the sea trial. For reproducibility, we share our implementation code.'
  doi: 10.1109/TMC.2024.3354126
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Journals & Magazines >IEEE Transactions on Mobile C...
    >Early Access Probabilistic Positioning of a Mooring Cable in Sonar Images for
    In-Situ Calibration of Marine Sensors Publisher: IEEE Cite This PDF António J.
    Oliveira; Bruno M. Ferreira; Nuno A. Cruz; Roee Diamant All Authors 31 Full Text
    Views Abstract Authors Keywords Metrics Abstract: The calibration of sensors stationed
    along a cable in marine observatories is a time-consuming and expensive operation
    that involves taking the mooring out of the water periodically. In this paper,
    we present a method that allows an underwater vehicle to approach a mooring, in
    order to take reference measurements along the cable for in-situ sensor calibration.
    We use the vehicle''s Mechanically Scanned Imaging Sonar (MSIS) to identify the
    cable''s reflection within the sonar image. After pre-processing the image to
    remove noise, enhance contour lines, and perform smoothing, we employ three detection
    steps: 1) selection of regions of interest that fit the cable''s reflection pattern,
    2) template matching, and 3) a track-before-detect scheme that utilized the vehicle''s
    motion. The later involves building a lattice of template matching responses for
    a sequence of sonar images, and using the Viterbi algorithm to find the most probable
    sequence of cable locations that fits the maximum speed assumed for the surveying
    vessel. Performance is explored in pool and sea trials, and involves an MSIS onboard
    an underwater vehicle scanning its surrounding to identify a steel-core cable.
    The results show a sub-meter accuracy in the multi-reverberant pool environment
    and in the sea trial. For reproducibility, we share our implementation code. Published
    in: IEEE Transactions on Mobile Computing ( Early Access ) Page(s): 1 - 15 Date
    of Publication: 15 January 2024 ISSN Information: DOI: 10.1109/TMC.2024.3354126
    Publisher: IEEE Authors Keywords Metrics More Like This Sonar-based Cable Detection
    for in-situ Calibration of Marine Sensors 2022 IEEE/OES Autonomous Underwater
    Vehicles Symposium (AUV) Published: 2022 An Activity-Triggered 95.3 dB DR − 75.6
    dB THD CMOS Imaging Sensor With Digital Calibration IEEE Journal of Solid-State
    Circuits Published: 2009 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved."'
  inline_citation: '>'
  journal: IEEE Transactions on Mobile Computing
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Probabilistic Positioning of a Mooring Cable in Sonar Images for In-Situ
    Calibration of Marine Sensors
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Ding S.
  - Chen J.
  - Wang Y.
  - Kang Y.
  - Song W.
  - Cheng J.
  - Cao Y.
  citation_count: '0'
  description: 'Event cameras, such as dynamic vision sensors (DVS), are biologically
    inspired vision sensors that have advanced over conventional cameras in high dynamic
    range, low latency and low power consumption, showing great application potential
    in many fields. Event cameras are more sensitive to junction leakage current and
    photocurrent as they output differential signals, losing the smoothing function
    of the integral imaging process in the RGB camera. The logarithmic conversion
    further amplifies noise, especially in low-contrast conditions. Recently, researchers
    proposed a series of datasets and evaluation metrics but limitations remain: 1)
    the existing datasets are small in scale and insufficient in noise diversity,
    which cannot reflect the authentic working environments of event cameras; and
    2) the existing denoising evaluation metrics are mostly referenced evaluation
    metrics, relying on APS information or manual annotation. To address the above
    issues, we construct a large-scale event denoising dataset (multilevel benchmark
    for event denoising, E-MLB) for the first time, which consists of 100 scenes,
    each with four noise levels, that is 12 times larger than the largest existing
    denoising dataset. We also propose the first nonreference event denoising metric,
    the event structural ratio (ESR), which measures the structural intensity of given
    events. ESR is inspired by the contrast metric, but is independent of the number
    of events and projection direction. Based on the proposed benchmark and ESR, we
    evaluate the most representative denoising algorithms, including classic and SOTA,
    and provide denoising baselines under various scenes and noise levels. The corresponding
    results and codes are available at https://github.com/KugaMaxx/cuke-emlb.'
  doi: 10.1109/TMM.2023.3260638
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Journals & Magazines >IEEE Transactions on Multimedia
    >Volume: 26 E-MLB: Multilevel Benchmark for Event-Based Camera Denoising Publisher:
    IEEE Cite This PDF Saizhe Ding; Jinze Chen; Yang Wang; Yu Kang; Weiguo Song; Jie
    Cheng; Yang Cao All Authors 1 Cites in Paper 407 Full Text Views Abstract Document
    Sections I. Introduction II. Related Works III. E-MLB Dataset IV. Event Structural
    Ratio V. Experimental Results Show Full Outline Authors Figures References Citations
    Keywords Metrics Footnotes Abstract: Event cameras, such as dynamic vision sensors
    (DVS), are biologically inspired vision sensors that have advanced over conventional
    cameras in high dynamic range, low latency and low power consumption, showing
    great application potential in many fields. Event cameras are more sensitive to
    junction leakage current and photocurrent as they output differential signals,
    losing the smoothing function of the integral imaging process in the RGB camera.
    The logarithmic conversion further amplifies noise, especially in low-contrast
    conditions. Recently, researchers proposed a series of datasets and evaluation
    metrics but limitations remain: 1) the existing datasets are small in scale and
    insufficient in noise diversity, which cannot reflect the authentic working environments
    of event cameras; and 2) the existing denoising evaluation metrics are mostly
    referenced evaluation metrics, relying on APS information or manual annotation.
    To address the above issues, we construct a large-scale event denoising dataset
    (multilevel benchmark for event denoising, E-MLB) for the first time, which consists
    of 100 scenes, each with four noise levels, that is 12 times larger than the largest
    existing denoising dataset. We also propose the first nonreference event denoising
    metric, the event structural ratio (ESR), which measures the structural intensity
    of given events. ESR is inspired by the contrast metric, but is independent of
    the number of events and projection direction. Based on the proposed benchmark
    and ESR, we evaluate the most representative denoising algorithms, including classic
    and SOTA, and provide denoising baselines under various scenes and noise levels.
    The corresponding results and codes are available at https://github.com/KugaMaxx/cuke-emlb
    . Published in: IEEE Transactions on Multimedia ( Volume: 26) Page(s): 65 - 76
    Date of Publication: 22 March 2023 ISSN Information: DOI: 10.1109/TMM.2023.3260638
    Publisher: IEEE Funding Agency: SECTION I. Introduction Event cameras, such as
    the Dynamic Vision Sensor (DVS), are novel biologically inspired devices [1],
    [2]. In contrast to traditional frame-based cameras, which capture global scene
    brightness at a fixed rate, event cameras can asynchronously perceive the environmental
    brightness change in each pixel and report log-intensity change signals at microsecond
    resolution [3], [4]. These features show great application potential in many fields,
    such as optical flow estimation [5], [6], [7], high-speed video interpolation
    [8], [9], [10], feature tracking/detection [11], [12], [13] and simultaneous localization
    and mapping (SLAM) [14], [15], [16], [17], [18], [19]. However, due to its differential
    imaging mechanism, the event camera is sensitive to various types of noise [4],
    [20]. In this paper, we are mainly concerned with background activity (BA) noise
    [21], which is the main type of noise in event cameras. As shown in Fig. 1(a),
    with the overall brightness reduction, the noise level in the event camera output
    will gradually increase. More specifically, the input signal will be disturbed
    due to the perturbation of incoming light before the receiving photodiodes and
    junction leakage current of the imaging circuit, as shown in Fig. 1(b). In conventional
    cameras, such noise input will be suppressed to a great extent because of the
    smoothness of the integration function, thus maintaining good imaging quality.
    However, in the event camera, the noise is much more obvious due to the continuous
    differential sampler, and the logarithmic operation will further amplify the noise,
    leading to the production of BA, as shown in Fig. 1(c). Fig. 1. Difference between
    event and RGB cameras in signal processing. (a) illustrates that the light intensity
    is inversely correlated to the noise level of captured events, i.e., with the
    light intensity gradually decreasing, the noise level increases in the event frame
    1 . (b) and (c) explain why the event camera generates so much noise in poor lighting
    conditions. The main reason is that the continual sampling (or differential sampling)
    in the event camera cannot smooth noisy signals in the integrated sampling manner
    of a frame-based camera, which makes the event-based denoising task unique and
    challenging. Show All Several event denoising datasets [22], [23], [24] and denoising
    metrics [22], [25], [26] have been proposed to date. Based on these, various event
    denoising algorithms [22], [23], [24], [25], [26], [27], [28], [29], [30], [31],
    [32], [33], [34], [35], [36], [37] have been presented and have achieved remarkable
    progress. However, existing event denoising datasets and denoising metrics still
    have the following limitations: 1) the scale of existing datasets is small, and
    the noise diversity is limited and unable to cover authentic working environments
    of event cameras. Specifically, the events in existing datasets are mainly captured
    in similar lighting conditions, resulting in small variances in different event
    sequences, which cannot cover the real noise distribution in practical environments.
    2) The existing denoising evaluation metrics are mostly reference evaluation metrics,
    relying on active pixel sensors (APS) and inertial measurement unit (IMU) information
    [22] or manual annotation [25], [26]. However, APS information is not always available,
    and its quality cannot be guaranteed, especially in low-light environments. In
    addition, the microsecond event camera can output millions of events per second,
    and it is impractical to label each event manually. To better study the influence
    of noise on event-based visual cues and enable future research on event denoising,
    we propose a large-scale event denoising dataset and a nonreference event denoising
    metric. First, we construct a novel large-scale event denoising dataset, which
    has three advantages over existing datasets: 1) Various scenes. The number of
    sequences in the E-MLB dataset is 12 times larger than existing datasets. 2) Varying
    light conditions. To better cover the actual lighting conditions in DVS working
    environments, we collected a large number of event sequences at different times
    (from day to night). We placed neutral density (ND) filters with fractional transmittances
    of 1/4, 1/16 and 1/64 in front of the event camera to simulate different light
    intensities. Thus, four event sequences with different noise levels were obtained
    for any given scene. 3) Multiple motion types. Our dataset contains events generated
    by objects with different motion types, including translation, rotation, and a
    combination of both 2D and 3D with perspective changes. Second, we propose a novel
    nonreference event denoising metric, termed the event structural ratio (ESR),
    to reduce the dependence of evaluation metrics on APS information and manual annotation.
    It has the following advantages: 1) Effective ranked noise level. The principle
    of ESR is to judge the noise level of an event stream. Since each denoising method
    leads to different noise levels, we can use ESR to evaluate these denoising events
    and, as a result, distinguish the denoising effect indirectly; 2) Reflect the
    intrinsic property of events. The calculated ESR is not dependent on either the
    number of events or the projection directions. Therefore, it is an intrinsic property
    of the events alone. 3) Easy to calculate. The only information needed to calculate
    ESR is the event data, and only basic arithmetic operations are needed1. In summary,
    the main contributions of this paper are threefold: We construct a large-scale
    event denoising dataset Multi-Level Benchmark (E-MLB) for the first time, which
    is 12 times larger than the largest existing dataset. Our proposed dataset far
    exceeds existing datasets in rich real-world scenes and multiple noise levels.
    We propose the first nonreference event denoising metric, the event structural
    ratio (ESR), which measures the structural intensity of events without additional
    information sources such as the APS frame and IMU data. The proposed ESR is easy
    to calculate and faithfully indicates the noise level of event data under various
    scenes and lighting conditions. We conduct extensive experiments with 11 state-of-the-art
    denoising methods on the E-MLB dataset and give the ESR score of each algorithm.
    We hope that the comparative analysis will contribute to future event denoising
    research. The remainder of the paper proceeds as follows. In Section II, we introduce
    relevant works on event denoising datasets, metrics and algorithms. In Section
    III, we describe the collection details of our E-MLB dataset. Then, we illustrate
    our proposed event denoising metrics and provide a detailed rigorous mathematical
    proof in Section IV. In Sections V and VI, we report the experimental results
    and give a conclusion, respectively. SECTION II. Related Works A. Event Denoising
    Datasets Some denoising datasets have been presented recently to suppress the
    impact of noise on event cameras. DVSNOISE20 [22] provides 48 event sequences
    on 16 stationary scenes, which were captured by a DAVIS 346 mounted in a gimbal
    restricted to rotation-only movement. It also provides ground-truth labels representing
    event generation probability by combining the APS and IMU information. ENFS [24]
    contains 100 sequences. DAVIS 346 camera was mounted on top of a table and shot
    a monitor playing the need-for-speed (NFS) [38] dataset. RGB DAVIS [23] provides
    20 real event sequences from a DAVIS 240 camera, including indoor and outdoor
    scenes, as well as high-resolution frames from a conventional RGB camera. Although
    these datasets provide a large quantity of realistic noisy data, they were collected
    under limited lighting conditions; some of them (e.g.DVSNOISE20 and ENFS) contain
    only restricted motion, which cannot cover authentic camera working scenarios.
    To solve the lack of ground truth labels, DND21 [39] collected realistic pure
    noise and pure signal sequences and then synthesized hybrid noisy sequences. Additionally,
    some simulators, such as ESIM [40] and V2E [41], can be used to generate synthetic
    DVS events from provided image or video datasets and control noise generation.
    However, due to the complexity of the actual noise distribution, the above methods
    cannot reflect real situations. B. Event-Based Denoising Metrics Percentage of
    signal/noise remaining (PSR/PNR) [25] treats the events that fall in the manually
    generated bounding box as signals, calculating the percentage of remaining events
    inside (or outside) the bounding box. Noise in real (NIR) [26] and relative plausibility
    measure of denoising (RPMD) [22] annotate the probability of each event. The former
    convolves the event stream with a Gaussian kernel, and the latter combines APS
    and IMU to calculate the probability of event occurrence in each space-time coordinate.
    In addition, there are some metrics designed on synthetic datasets. Event denoising
    precision (EDP) [42] can briefly report the ratio of the total number between
    the denoised event stream and the original event stream. [39] plots receiver operating
    characteristic (ROC) curves to compare different event data. Although the aforementioned
    metrics can evaluate denoising algorithm performance, some methods rely heavily
    on synthetic data and this generalization to real event data is still unclear.
    Others need ground truth data by either manually labeling or introducing additional
    information sources, which may become invalid in a practical environment where
    labels are not always available. C. Event-Based Denoising Algorithms Statistical
    methods were the earliest classical approaches for event-based denoising. In [28],
    outliers are filtered by calculating the density for each event in their local
    spatial-temporal neighborhood and setting the threshold to judge low-density events.
    Then, based on this theory, approaches such as [29], [32], [39], [42], [43] reduce
    the operating complexity by setting different event storage strategies. Other
    works, such as [25], [26], [44], introduce additional process stages to eliminate
    dead pixels or sharpen edges. However, these density statistics methods are difficult
    to apply across a wide variety of noise and require manually finetuning parameters
    to deal with different scenarios. Other algorithm filters conduct event denoising
    in the context of surface fitting. EV-Gait [36] performs local plane optical flow
    estimation and filters noisy events to smooth the optical flow surface. Afterward,
    the guided event filter (GEF) [23] combines the gradient of active pixel sensor
    (APS) frames. In contrast, time surface (TS) [30], [34], [35] transforms events
    from unit impulses into a representation that is monotonically decreasing with
    time, which solves the sparsity problem in the local plan fitting process. These
    fitting methods are well suited for a single moving object but perform poorly
    in low-light conditions or complex scenarios. Learning-based methods have been
    widely used in event-based denoising most recently. For example, a K-SVD method
    [31] was proposed to extract the sparse features from several noise-free event
    frames. In [39], a multilayer perceptron denoising filter (MLPF) was used to calculate
    the probability of noise event-by-event. In addition, some convolutional neural
    network (CNN) methods [22], [24], [45], [46] have also been proposed recently.
    EDnCNN [22] trains a binary classification network using the probability tag of
    each event, which is estimated by combining APS and IMU information. EDnCNN can
    classify individual events as signals or noise well but is a time-consuming network.
    EventZoom [24] is a high-efficiency U-Net that achieves event denoising in a noise-to-noise
    fashion. SECTION III. E-MLB Dataset In this section, we introduce the collection
    details of our E-MLB dataset. We first introduce our capture device. Then, the
    shooting details and photographic accessories used are presented. Finally, the
    comparison of E-MLB with the existing datasets is given. A. Event Sensor The type
    of event camera we used was a DAVIS346, which can simultaneously output a spatially
    aligned event stream (120 dB) and intensity images (56 dB) with a resolution of
    346×260 . In addition, to simulate different lighting conditions, we placed three
    neutral density filters (ND filters) with different transmittance in front of
    the lens, as shown in Fig. 2(a). Fig. 2. (a) The event camera and ND filters were
    used for capturing event sequences. (b) The captured event stream with different
    ND filters 2 . The noise level gradually increases with the amount of light entering
    the lens reduction. (c) Examples of event sequences in the E-MLB from daytime
    to night. In each square, the lower-left is the converted event frame, and the
    upper-right is the hybrid image, including the event and APS frame. Show All 1)
    Collection Details Benefiting from the high dynamic property, the DVS is widely
    used in extreme light conditions, such as low-light and overexposed conditions
    [47], [48]. However, the noise level output by DVS gradually increases as the
    light intensity increases/decreases, as shown in Fig. 1. To better analyze the
    relationship between noise level and light intensity, we place the ND filter to
    simulate the different light conditions, as shown in Fig. 2(a). For each scene,
    we first capture the original scene in the natural light condition. Then, we add
    the ND filter in front of the DVS and repeat the capture process. In this paper,
    we use three kinds of ND filters with different transmittance (1/4, 1/16, and
    1/64), which are denoted as ND4, ND16, and ND64, respectively. The captured samples
    are shown in Fig. 2(b). For each light condition, we repeatedly shoot the scene
    3 times. The simulated light intensity and diversity are highly dependent on the
    original natural light intensity. Thus, to further increase the light diversity,
    we change the capture time from day to night to guarantee the diversity of natural
    lighting conditions. In addition to changing the light intensity, we also change
    the shooting scene to guarantee the diversity of the content of the captured event
    sequence. In this paper, we select 100 scenes, including both indoor and outdoor
    scenes and diverse motion types (translation, rotation, and combination of both
    in 2D and 3D with perspective change). In addition, we provide the corresponding
    APS frame and IMU data for each captured event sequence. It should be noted that
    the APS quality will decrease as light intensity decreases. Considering that the
    event camera has a superior high dynamic range, we also include some special sequences
    that create more challenges for denoisers, such as extremely low light scenes
    (with high background activity and blurred edges), special weather conditions
    (rainy and snowy days), and high-speed objects. Some example sequences can be
    found in Fig. 2(c). A comparison of our E-MLB with the existing event denoising
    dataset is reported in Table I2. TABLE I The Comparison of Our Proposed E-MLB
    With Existing Event Denoising Dataset SECTION IV. Event Structural Ratio In Section
    IV-A, we review the working principle of event cameras and the event contrast
    measurement, in which event contrast is the main inspiration of our denoising
    metric. In Section IV-B, we introduce our proposed event structure ratio, and
    the relevant derivation and proof can be found in Section IV-C. Evaluations on
    ESR are conducted in Section IV-D, including both synthetic and real experiments,
    which demonstrate that our proposed ESR is a good denoising indicator. A. Preliminaries
    1) Working Principle In event cameras, each pixel works asynchronously and will
    trigger an event e k :=( x x k , t k , p k ) when its logarithmic brightness change
    reaches the predefined contrast threshold c , which can be defined as: ΔL≐L( x
    x k , t k )−L( x x k , t k −Δ t k )=c⋅ p k (1) View Source where x x k :=( x k
    , y k ) is the pixel position of the k -th event. t k is the timestamp, and Δ
    t k is the time interval since pixel ( x k , y k ) last reaches the threshold.
    p k ∈{−1,+1} is the polarity, representing the decrease and increase in brightness,
    respectively. L( x x k , t k ):=logI( x x k , t k ) denotes the log intensity.
    The difference between log intensity in a duration of t can be obtained by integrating
    the sequences of events [49]: L( x x,t)−L( x x,0)≐c⋅ ∫ t 0 ∑ k e k ( x x,τ)dτ
    (2) View Source where e k ( x x,t) can be described by using Dirac function δ(⋅)
    : e k ( x x,t)= p k ⋅δ( x x− x x k ,t− t k ) (3) View Source 2) Event Contrast
    Since event cameras are highly responsive to the moving edges of an object [50],
    a set of events will occur on the edge trajectories as long as relative movement
    occurs between the camera and objects. In contrast, given a set of events { e
    k } N , we can project (warp) these events to a reference time t ref along these
    trajectories by a warping function W : e k :=( x x k , t k , p k ) ↦ W e ′ k :=(
    x x k , ′ t ref , p k ) (4) View Source After projecting, we obtain an accumulated
    2D histogram, also known as an image of warped events (IWE) [51]: IWE( x x)= ∑
    k=1 N b k δ( x x− x x ′ k ) (5) View Source where b k is the weight of the summation
    of e k . Here, we set b k =1 to facilitate the subsequent derivations. Usually,
    the warping function can be modeled as linear motion (optic flow), rotational
    motion, 4-DOF motion and so on [52]. If we correctly model the warping function
    and estimate accurate parameters, the IWE will form an edge-like image. Taking
    Fig. 3 as an example, for some simple shapes performing translation motion relative
    to the camera, we can project events along the translation direction to obtain
    a clear and sharp edge-like IWE. Fig. 3. Since the event camera is responsive
    to edges, we will obtain an image of the objects'' edges after projecting the
    events along the trajectories to the 2D dimension, which helps us to analyze its
    statistical characteristics more easily. Show All Because edge strength is directly
    related to image contrast [51], we can use IWE to measure scene contrast. Here,
    we use an image-based contrast metric named the total sum of squares (TSS): TSS=
    ∑ x x IWE 2 ( x x), (6) View Source where the summation is carried over all the
    pixels. The area of spatial support L (the total number of pixels that output
    events) can be defined as: L:= ∑ IWE( x x)>0 1, (7) View Source TSS and L are
    inversely correlated most of the time. Given a number of events, the more aggregated
    the events are in IWE, the less spatial support L the event image has. In other
    words, the event contrast will decrease when the data are influenced by noise,
    which we believe is an important clue to judging the impact of noise. However,
    TSS and other contrast metrics are highly dependent on the number of events, and
    they cannot be directly used as event denoising metrics. Taking TSS as an example,
    it will always assign the highest score for the denoising method that outputs
    the maximum number of events. In practice, we cannot guarantee that the different
    denoising methods keep the same number of events. B. Definition of ESR To address
    the above issues, we extract an invariant from the TSS, which is called the normalized
    TSS (NTSS): NTSS:= ∑ i=1 K n i ( n i −1) N(N−1) (8) View Source where K is the
    total number of pixels in the IWE. N is the total number of events, and n i is
    the sum of all events that occur on pixel ( x i , y i ) . NTSS is used to represent
    the relative contrast of the scene regardless of the number of events. Nevertheless,
    due to the intrinsic deficiency of the contrast metric, the NTSS tends to assign
    a higher score to the method that performs overdenoising. An extreme case is that
    if only one event remains, the calculated NTSS will reach the upper bound and
    fail to faithfully represent the noise situation. Therefore, we add a penalty
    coefficient before NTSS, which is defined as: L N :=K− ∑ i=1 K (1− M N ) n i (9)
    View Source where L N is the number of nonzero pixels (or the area of spatial
    support) in the IWE. M is the reference number of events used for interpolation,
    which is fixed during the entire evaluation process. In this way, the normalized
    contrast of any N events can be interpolated to that of fixed M events. Based
    on the invariant representation of scene contrast NTSS and penalty coefficient
    L N , we can finally define the proposed ESR as: ESR:= NTSS⋅ L N − − − − − − −
    − − √ , (10) View Source C. Proof of NTSS and L N For small duration Δt , the
    probability of a given number of events follows the Poisson distribution [32]:
    P( N x x (t)=m)= e − λ x x t ( λ x x t ) m m! (11) View Source where P( N x x
    (t)=m) is the probability of m events occurring. Event rate λ x x is the rate
    of triggering events at pixel per unit time [49], which can be derived from (2)
    as: λ x x := 1 Δt ⋅ L( x x,t)−L( x x,0) c = ∫ t 0 ∑ k e k ( x x,τ)dτ Δt (12) View
    Source then we can obtain the uniform event rate as: p x x = λ x x ∑ x x λ x x
    , (13) View Source where p x x represents the relative portion of event rate λ
    x,y and sums to 1. Given the sum of the number of events, the joint probability
    distribution of the number of events in different pixels follows a multinomial
    distribution, provided the number of events in each pixel follows the Poisson
    distribution and all the pixels are independent. Therefore, events can be viewed
    as drawn from a multinomial distribution provided that the number of events is
    fixed. Let the total number of pixels of the event image be K , and use flattened
    index i∈{1,2,…K}=( x i , y i ) to represent different pixels for simplicity of
    notation; then we have: ( n 1 ,… n K )|Y n i |Y Y n i =N∼Multinomial(N,( p 1 ,…
    p K )), =N∼Binomial(N, p i ), = ∑ i=1 K n i , = N x x i (t). (14) (15) (16) (17)
    View Source After deriving the uniform event rate p x x , we can further derive
    the NTSS and L N . The expectation of TSS is: E[TSS|Y=N]= ∑ i=1 K E[ n 2 i |Y=N].
    (18) View Source Because the distribution of N i (t) conditioned on M(t) is binomial,
    we introduce f(x,p)=(px+(1−p) ) N , (19) View Source then from (15), we have:
    E[ n 2 i |Y= = N]= ∑ k=1 N k 2 ( N k ) p k (1−p ) N−k (x ∂ ∂x ) 2 ∘f(x, p i )
    | x=1 =N p i +N(N−1) p 2 i . (20) (21) View Source so for TSS, there is: E[TSS|Y=N]
    = ∑ i=1 K N p i +N(N−1) p 2 i =N+N(N−1) ∑ i=1 K p 2 i . (22) (23) View Source
    ∑ K i=1 p 2 i is an inherent property of the scene and is invariant with respect
    to the number of events N . In effect, it can be estimated by: ∑ i=1 K p 2 i ≈
    ∑ i=1 K n i ( n i −1) N(N−1) . (24) View Source ∑ K i=1 p 2 i can be viewed as
    the normalized TSS, and its estimation is denoted as NTSS: NTSS:= ∑ i=1 K n i
    ( n i −1) N(N−1) . (25) View Source The expectation of L is: E[L|Y =N]=E[ ∑ i=1
    K 1 n i >0 |Y=N] = ∑ i=1 K P( n i >0|Y=N) =K− ∑ i=1 K P( n i =0|Y=N) ≈K− ∑ i=1
    K e −N p i . (26) (27) View Source There is no simple scene invariant from the
    expression because N and p i are tightly coupled; however, by introducing a new
    random variable α n i , we can interpolate the resultant L to any given number
    of M as if it were calculated by exactly M events. The expectation of this new
    random variable is: E[ α n i |Y=N] = ∑ k=1 N α k p k i (1− p i ) N−k ( N k ) =(1+(α−1)
    p i ) N ≈ e (α−1)N p i . (28) (29) View Source Thus, by setting (α−1)N=−M , or
    equivalently α=1− M N , we can interpolate any L when Y=M from N events, defined
    as: L N :=K− ∑ i=1 K (1− M N ) n i . (30) View Source D. Experimental Verification
    To verify that the proposed NTSS, L N and ESR are independent of the number of
    events, we conduct experiments on real-world event sequences. We conduct three
    experiments with N = 15,000, 17,500, and 20,000. M is set to 15,000 in all three
    experiments. Events in the whole sequence are split into packets of events with
    equal sizes of N . Then, we compute the NTSS, L N , and ESR values for each event
    packet with predefined parameters and draw the NTSS, L N , and ESR curves of the
    entire sequence. As shown in Fig. 4(a) and (b), when the number N changes from
    15,000 to 20,000, the NTSS and L N curves are very close, which verifies their
    independence from the event number N . As a result, the ESR curve is also independent
    of N , as shown in Fig. 4(c). Then, we test the relationship between the ESR and
    noise level. We manually add random noise (the noise ratio is set to 10%, 20%,
    and 40%) to the original sequence and calculate the corresponding ESR curve. As
    shown in Fig. 4(d), the noisy ESR curves have the same shape as the original curve,
    and the noisier the ESR curve is, the lower the ESR value, which validates that
    it can indicate the noise level and can be used as an event-based denoising evaluation
    metric. Fig. 4. Effect of event number and noise level on ESR. The NTSS and L
    N are robust to the number of events, as in (a) and (b), which results in the
    obtained ESR also being robust to the number of events, as in (c). (d) shows that
    the proposed ESR is inversely correlated to the noise level, and a higher noise
    level corresponds to a lower ESR. Show All The proposed ESR is calculated in the
    event frame to simplify the calculation, whereas the existing algorithms adopt
    different projection methods during the process. For example, EventZoom uses projections
    along the time axis, and GEF uses projections along the motion axis, which leads
    to a change in the event distribution after denoising. Therefore, we need to test
    the influence of different projection methods on the ESR value to verify its robustness
    on different algorithms. As shown in Fig. 5, we calculate the ESR value of the
    same event packet in different projection directions; the resultant ESR values
    are quite close, so the proposed ESR is also invariant to the change in projection
    direction. In conclusion, although the calculation is performed in the frame space,
    the resultant ESR is independent of the number of events and the projection method
    only represents the event quality, which is thus, an intrinsic property of events.
    Fig. 5. Effect of projection directions on ESR. Although events are projected
    along different directions, the ESR values are relatively close. Show All SECTION
    V. Experimental Results In this section, we first provide the mean ESR (MESR)
    score of each representative denoiser in both our E-MLB and other existing datasets
    and present some typical visualization results. Then, a comparison of ESR with
    another denoising metric is given, which proves the superiority of ESR. A. Event
    Denoising Baselines We select the 11 most representative event denoising methods
    for comparison: BAF [28], KNoise [32] & DWF [39] follow the same denoising theory.
    The background activity filter (BAF) counts the density of each incoming event
    in its eight neighborhood pixels within a time interval and filters out noise
    events according to a predetermined threshold. KNoise improves on this basis by
    allocating two blocks of memory to store the latest events of rows and columns,
    which gains the advantage of O(N) space complexity. The double window filter (DWF)
    further reduces the memory footprint by using a first-in-first-out (FIFO) queue,
    which stores only a few recent events and determines whether to insert a new event
    into this queue by comparing it with in-queue events. TS [30] & IETS [34] convert
    a sparse event stream into a dense representation. First, the time surface (TS)
    converts the Dirac function of time into a logarithmic decay representation, in
    which case the effective events form a regular manifold called the time surface.
    Then, it eliminates events that destroy the smoothness of the surface. The inceptive
    event time surface (IETS) introduces predefined time thresholds to eliminate redundant
    events within the same edge. EvFlow [36] calculates the gradient by local plane
    fitting to attain optical flow and then achieves event denoising by filtering
    all the events with abnormal flow values. YNoise [26] calculates the density of
    each incoming event in its spatiotemporal domain and then achieves event denoising
    by passing events with high density. MLPF [39] is a kind of multilayer perceptron
    (MLP) method with a single hidden layer, which is trained by adding simulated
    noise events in the noise-free sequences. EDnCNN [22] is a convolutional neural
    network. The probability of an event can be calculated by fusing APS and IMU data,
    which are used as the labels for each training event. GEF [23] provides two denoising
    modes. In the frame-guide mode, the guided event filter (GEF) extracts mutual
    structures between the event frame (project along optical flow) and the gradient
    of the APS image (by Sobel operator), then deletes unreasonable events and reallocates
    back to spatiotemporal space. When the APS quality is not high, GEF changes to
    self-guide mode, aligning two adjacent event frames and erasing inconsistent events.
    EventZoom [24] follows a noise-to-noise fashion that utilizes paired noisy event
    sequences to train a U-net and performs event reconstruction guidance using good
    quality videos on the network branch. 1) Experimental Details All sequences in
    the E-MLB dataset are tested with the above denoising algorithms. To ensure a
    fair comparison, we manually fine-tune the adjustable parameters of all methods
    in each sequence. It should be noted that EDnCNN trained on our dataset performs
    inferior to the pretrained EDnCNN. The reason is that EDnCNN is highly dependent
    on its exclusive event noise probability labels, which are restricted to stationary
    scenes with rotation-only camera motion; otherwise, it will be trained with incorrect
    training data, and our dataset does not strictly meet this requirement. Therefore,
    we choose a pretrained network on their DVSNOISE20 dataset and then fine-tune
    it on our rotation-only sequences. In terms of GEF, we set the frame-guide model
    in ND1 sequences while changing to self-guided in ND4, ND16 and ND64 sequences.
    As mentioned in Section III, in ND1 sequences frame-guide performs better because
    of the high-quality frames. However, in ND4 to ND64 frames, the quality falls
    and the self-guided mode can provide more reasonable denoising results. Considering
    that we do not provide similar paired noise sequences as in the ENFS dataset,
    we only trained EventZoom on its ENFS dataset sequences. To calculate MESR, we
    slice the event sequence E:={ e k } consecutively along the time, which can make
    the set of nonoverlapping event groups {{ e k } 1 ,{ e k } 2 ,…,{ e k } G ⊆E}
    , where G is the number of event groups. Each group is a subset that belongs to
    the original sequence. In the experiment, we specified that each event group contains
    30,000 events; therefore, we chose M=20,000 and N=30,000 for all sequences for
    a fair comparison. B. Experimental Results 1) Quantitative Evaluation The mean
    ESR (MESR) results are reported in Table II. As shown in the first row, the MESR
    score of the E-MLB dataset decreases as the noise level increases (from ND1 to
    ND64), which again verifies the inverse correlation between the ESR value and
    noise level. The only exception is that the MESR score of ND1 is slightly lower
    than that of ND4 in the daytime sequences. We also provide MESR scores in some
    other event-based denoising datasets, i.e., RGB DAVIS, DVSNOISE20, ENFS and DND21.
    Their ESR results are similar to those sequences in our daytime E-MLB dataset
    because they were all captured under normal light conditions. TABLE II The Mean
    ESR (MESR) Results of Different Denoising Methods on Both E-MLB Dataset and Public
    Available Event Denoising Datasets. We Mark the best and second Best For the different
    denoising methods, it is clear that almost all the denoised sequences report better
    ESR scores compared to the raw sequences, especially in the higher score improvement
    in the night sequences. Overall, we can determine that BAF, Knoise and DWF receive
    approximate ESR scoring results as they follow a similar denoising principle.
    Considering that IETS eliminates a large number of effective signals, it reports
    the poorest score. GEF outperforms other denoising methods when the APS quality
    is good, namely, in ND1 sequences of E-MLB and other datasets that provide related
    frames. Nevertheless, the denoising score drops to the second tier when GEF enters
    the self-guided mode. EventZoom reports the highest MESR score in almost all normal
    light sequences, e.g., E-MLB in the daytime, while EDnCNN presents the best performance
    when the noise level is higher, as shown in the ND4 to ND64 columns at night E-MLB.
    It is also worth noting that our ESR still works effectively for algorithms that
    can generate new possible events (such as EventZoom and GEF). However, the other
    existing event-based denoising metrics almost fail to evaluate such self-generated
    events from denoisers, providing lower scores despite good denoising performance.
    2) Qualitative Evaluation First, we visualize the denoising results of different
    algorithms in some challenging ND1 sequences to determine the performance boundary
    of each denoiser, as shown in Fig. 6 (Daytime) and Fig. 7 (Night). Fig. 6. Visual
    comparison from different denoising algorithms in some representative daytime
    sequences, including (a) a static object shoot against strong sunlight, in which
    case a lot of single polarity noise will be generated, and (b) multiple fast-moving
    objects in a noise-free environment, which is challenging for speed-sensitive
    denoisers. Show All Fig. 7. Visual comparison from different denoising algorithms
    in some representative night sequences, including (a) a vehicle under a street
    light and (b) nonrigid body motion. Note that in night sequences, we have no choice
    but to increase exposure times as much as possible to acquire visible frames,
    which creates some inevitable problems such as smear or blur. Show All Generally,
    BAF remains noisy after denoising because it only performs simple density statistics
    on the event stream but can preserve the edges from being damaged. Although KNoise
    and DWF follow the same denoising principles as BAF, they perform inferiorly in
    some complex structural scenes such as Fig. 6(a). This is because they limit the
    memory space, resulting in a large number of valid events being filtered out rapidly
    owing to memory limitations and the high noise density. EvFlow performs well when
    the scene motion type is limited to a single object motion such as Fig. 6(a).
    To some extent, YNoise and TS perform similarly, but they have distinguished denoising
    strategies. In detail, TS removes as much noise as possible by local plane fitting,
    which may damage the texture and details. In contrast, YNoise is a kind of kernel
    density estimation method that can preserve more structural information. However,
    YNoise may become invalid in some high-intensity mono-polar noise sequences such
    as in Fig. 6(a); additionally, YNoise actually costs much more human labor on
    adjustment. As a denoising method for fast corner detection, IETS destroys the
    distribution of real events. Although it is highly suppressed in background activities,
    the edge of the target is no longer obvious. Benefiting from the addition of APS
    information, the GEF output contains sharp edges and rich texture details, as
    shown in Fig. 6(a) and (b). However, when the quality of the APS image is poor,
    the quality of output events also decreases drastically. For example, in Fig.
    7(a), we can see that GEF cannot generate a reasonable event distribution because
    motion blur occurs. For neural networks, since MLPF has a simple structure (only
    2 hidden layers), it can be difficult to extract global information, resulting
    in poor performance in complicated scenes such as Fig. 6(a). However, MLPF has
    the lowest computational and parameter costs compared with other networks. Although
    EDnCNN can preserve edges well, it loses some texture information of the scene.
    In addition, we can see EDnCNN''s weakness in dealing with object motion in Fig.
    7(a) or extreme noise environment in Fig. 7(b). Comparatively, EventZoom has more
    robust performances in various sequences; however, it can cause time and pixel
    jittering in each event, such as in Fig. 6(a). Second, we present the denoising
    results in the same scene with different lighting conditions in Fig. 8. As seen
    in Fig. 8, the performance of all methods decreases as the noise level increases,
    and most fail in ND64 sequences. For BAF, NN and KNoise, their denoising sequences
    are contaminated as the noise level increases, but they have the least computational
    consumption. As GEF switches to self-guide mode due to the poor quality of the
    APS frames, it only performs well under moderate noise levels (ND4 and ND16).
    When the noise level continues to increase (ND64), GEF loses many real events.
    TS, IETS and YNoise outperform the other methods at medium noise levels and below
    in Fig. 8(a) and (b), but IETS loses performance at extreme noise conditions in
    Fig. 8(c). With regard to EDnCNN and EventZoom, each has its own merits: EDNcNN
    performs well in texture preservation, while EventZoom can retain more edge information.
    However, both of them may have undesirable performance in some high-noise scenes,
    specifically compared with TS and YNoise in Fig. 8(c). Fig. 8. Visual comparison
    of different denoising algorithms on multiple noise levels of the E-MLB dataset.
    (a)–(c) contain a cyclist who maintains the same movement at an almost consistent
    distance from the event camera; as the noise level increases, the edges become
    more blurred, and details disappear. Show All 3) Comparison between ESR and RPMD
    The proposed ESR in this paper is the first nonreference event denoising metric,
    which solves the difficulties in obtaining real event labels. In Fig. 9, we provide
    a comparison with another common public reference metric, RPMD. Since other methods
    are not suitable for evaluation on our E-MLB dataset (PSR/PNR and NIR require
    manual labeling, EDP and ROC require noise-free reference), we do not provide
    them here. Fig. 9. Comparison of ESR with RPMD. (a) shows a normal light sequence,
    and both methods give reliable scores. (b)-(c) provide an overexposed and a low
    light sequence correspondingly, which leads to the unexpected results of RPMD,
    but the proposed ESR still works. Show All We visualize the MESR and RPMD scores
    on 3 representative scenes under normal light, overexposed, and low light conditions
    in Fig. 9. As seen, the denoised event frames look better for all the sequences
    by human perception. However, RPMD fails to give a better score under overexposed
    and low light sequences. This is because the correct calculation of RPMD requires
    high-quality and properly aligned APS and IMU data, which is not always met when
    the event camera is used in the real world. In comparison, the proposed ESR is
    not dependent on additional information sources and faithfully represents the
    noise level under all circumstances. Overall, our metric could ignore the restriction
    to lighting conditions and give more reasonable scores. SECTION VI. Discussion
    In this paper, we propose a large-scale event denoising dataset E-MLB and a nonreference
    event denoising metric ESR for the first time. The scale of E-MLB is 12 times
    larger than the largest existing event-denoising dataset and rich in noise levels
    and scene types. The ESR represents the intrinsic property of events without needing
    any other information sources. With the proposed dataset and event denoising metric,
    we conduct extensive experiments with 11 state-of-the-art denoising methods and
    present a comparative analysis on event denoising. However, there are still some
    limitations that need to be noted. As discussed in [41], the dominant event noise
    source changes from random photocurrent fluctuation to structural junction leakage
    current as light intensity increases. However, due to the complexity of the scene
    light sources, we do not discuss and classify the sources of various noise types
    in our proposed dataset. The proposed metric is easily affected by hot pixels,
    which are events emitted on some pixels at abnormally high rates. Therefore, we
    recommend eliminating these unexpected pixels in preprocessing. In future work,
    we will work on solving the above problems. We hope all these contributions can
    contribute to the event community to advance future research on event denoising.
    Authors Figures References Citations Keywords Metrics Footnotes More Like This
    Two-Dimensional Transient Temperature Distribution Measurement of GaN Light-Emitting
    Diode Using High Speed Camera IEEE Journal of the Electron Devices Society Published:
    2021 Proposal of Tear Meniscus Measurement for Minor Dry-eye Detection Using Smart-phone
    Camera and Ring-light 2021 36th International Technical Conference on Circuits/Systems,
    Computers and Communications (ITC-CSCC) Published: 2021 Show More IEEE Personal
    Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED
    DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION
    TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732
    981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility
    | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap |
    IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s largest
    technical professional organization dedicated to advancing technology for the
    benefit of humanity. © Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: IEEE Transactions on Multimedia
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'E-MLB: Multilevel Benchmark for Event-Based Camera Denoising'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - He S.
  - Zhou H.
  - Tian Y.
  - Huang D.
  - Yang J.
  - Wang C.
  - Huang W.
  citation_count: '0'
  description: 'High-frequency radars (HFRs) are important for remote sensing of the
    marine environment due to their ability to provide real-time, wide-coverage, and
    high-resolution measurements of the ocean surface current, wave height, and wind
    speed. However, due to the intricate multidimensional processing demands (e.g.,
    time, Doppler, and space) for internal data and effective suppression of external
    noise, conducting quality control (QC) on radar-measured data is of great importance.
    In this paper, we first present a comprehensive quality evaluation model for both
    radial current and synthesized vector current obtained by direction-finding (DF)
    HFRs. In the proposed model, the quality factor (QF) is calculated for each current
    cell to evaluate its reliability. The QF for the radial current depends on the
    signal-to-noise ratio (SNR) and DF factor of the first-order Bragg peak region
    in the range–Doppler (RD) spectrum, and the QF for the synthesized vector current
    can be calculated using an error propagation model based on geometric dilution
    of precision (GDOP). A QC method is then proposed for processing HFR-derived surface
    current data via the following steps: (1) signal preprocessing is performed to
    minimize the effect of unwanted external signals such as radio frequency interference
    and ionospheric clutter; (2) radial currents with low QFs and outliers are removed;
    (3) the vector currents with low QFs are also removed before spatial smoothing
    and interpolation. The proposed QC method is validated using a one-month-long
    dataset collected by the Ocean State Monitoring and Analyzing Radar, model S (OSMAR-S).
    The improvement in the current quality is proven to be significant. Using the
    buoy data as ground truth, after applying QC, the correlation coefficients (CCs)
    of the radial current, synthesized current speed, and synthesized current direction
    are increased by 4.33~102.91%, 1.04~90.74%, and 1.20~62.67%, respectively, and
    the root mean square errors (RMSEs) are decreased by 2.51~49.65%, 7.86~27.22%,
    and 1.68~28.99%, respectively. The proposed QC method has now been incorporated
    into the operational software (RemoteSiteConsole v1.0.0.65) of OSMAR-S.'
  doi: 10.3390/rs15235553
  full_citation: '>'
  full_text: '>

    "This website uses cookies We use cookies to personalise content and ads, to provide
    social media features and to analyse our traffic. We also share information about
    your use of our site with our social media, advertising and analytics partners
    who may combine it with other information that you’ve provided to them or that
    they’ve collected from your use of their services. Consent Selection Necessary
    Preferences Statistics Marketing Show details                 Deny Allow selection
    Allow all    Journals Topics Information Author Services Initiatives About Sign
    In / Sign Up Submit   Search for Articles: Remote Sensing All Article Types Advanced   Journals
    Remote Sensing Volume 15 Issue 23 10.3390/rs15235553 Submit to this Journal Review
    for this Journal Propose a Special Issue Article Menu Academic Editor Silvia Piedracoba
    Subscribe SciFeed Recommended Articles Related Info Link More by Authors Links
    Article Views 627 Table of Contents Abstract Introduction QF Models and QC Method
    Experimental Results Discussion Conclusions Author Contributions Funding Data
    Availability Statement Conflicts of Interest References share Share announcement
    Help format_quote Cite question_answer Discuss in SciProfiles thumb_up Endorse
    textsms Comment first_page settings Order Article Reprints Open AccessArticle
    Quality Control for Ocean Current Measurement Using High-Frequency Direction-Finding
    Radar by Shuqin He 1, Hao Zhou 1,*, Yingwei Tian 1, Da Huang 1, Jing Yang 1, Caijun
    Wang 1 and Weimin Huang 2 1 The School of Electronic Information, Wuhan University,
    Wuhan 430072, China 2 The Faculty of Engineering and Applied Science, Memorial
    University of Newfoundland, St. John’s, NL A1B 3X5, Canada * Author to whom correspondence
    should be addressed. Remote Sens. 2023, 15(23), 5553; https://doi.org/10.3390/rs15235553
    Submission received: 26 October 2023 / Revised: 26 November 2023 / Accepted: 27
    November 2023 / Published: 29 November 2023 (This article belongs to the Special
    Issue Sustained Ocean Surface Observation Using HF Radar: From Data to Societal
    Applications II) Download keyboard_arrow_down     Browse Figures Versions Notes
    Abstract High-frequency radars (HFRs) are important for remote sensing of the
    marine environment due to their ability to provide real-time, wide-coverage, and
    high-resolution measurements of the ocean surface current, wave height, and wind
    speed. However, due to the intricate multidimensional processing demands (e.g.,
    time, Doppler, and space) for internal data and effective suppression of external
    noise, conducting quality control (QC) on radar-measured data is of great importance.
    In this paper, we first present a comprehensive quality evaluation model for both
    radial current and synthesized vector current obtained by direction-finding (DF)
    HFRs. In the proposed model, the quality factor (QF) is calculated for each current
    cell to evaluate its reliability. The QF for the radial current depends on the
    signal-to-noise ratio (SNR) and DF factor of the first-order Bragg peak region
    in the range–Doppler (RD) spectrum, and the QF for the synthesized vector current
    can be calculated using an error propagation model based on geometric dilution
    of precision (GDOP). A QC method is then proposed for processing HFR-derived surface
    current data via the following steps: (1) signal preprocessing is performed to
    minimize the effect of unwanted external signals such as radio frequency interference
    and ionospheric clutter; (2) radial currents with low QFs and outliers are removed;
    (3) the vector currents with low QFs are also removed before spatial smoothing
    and interpolation. The proposed QC method is validated using a one-month-long
    dataset collected by the Ocean State Monitoring and Analyzing Radar, model S (OSMAR-S).
    The improvement in the current quality is proven to be significant. Using the
    buoy data as ground truth, after applying QC, the correlation coefficients (CCs)
    of the radial current, synthesized current speed, and synthesized current direction
    are increased by 4.33~102.91%, 1.04~90.74%, and 1.20~62.67%, respectively, and
    the root mean square errors (RMSEs) are decreased by 2.51~49.65%, 7.86~27.22%,
    and 1.68~28.99%, respectively. The proposed QC method has now been incorporated
    into the operational software (RemoteSiteConsole v1.0.0.65) of OSMAR-S. Keywords:
    direction finding; high-frequency radar; geometric dilution of precision; radio
    frequency interference; quality control; quality factor Graphical Abstract 1.
    Introduction High-frequency radar (HFR) has attracted extensive attention from
    the research community, coastal managers, and private organizations due to its
    ability to map ocean surface currents well beyond the horizon with fine spatial
    and temporal scales. It has become a valuable tool for operational oceanography
    [1,2,3,4,5], including ocean dynamics modeling [6], sea ice sensing [7], and other
    applications [8]. In recent years, there has been a growing interest in developing
    HFR networks [9]. These HFR networks can provide high-precision measurement of
    ocean surface current, which is essential for marine science, environmental protection,
    and maritime security, etc. As the coverage and applications of these networks
    continue to expand, the importance of the quality control (QC) of radar data becomes
    increasingly evident. The quality of the radar signal will be affected by the
    complexity of electromagnetic scattering, frequent external interference from
    other radio users and lightning, and internal signal-processing algorithms involved
    in current mapping. There are many uncertainties in different aspects of single-site
    HFR processing, such as the identification of Doppler lines in the first-order
    Bragg region and the averaging in the spatial and temporal domain [10]. These
    uncertainties will also be propagated to the final vector current estimates when
    multiple radar sites are used for current synthesis. Therefore, it is necessary
    to perform QC to ensure the reliability and accuracy of the current measurements
    before they are put into practical use. Many coastal countries have developed
    their HFRs with different types of receiving antennas and corresponding signal-processing
    algorithms. For example, the SeaSonde system [11] uses a compact crossed-loop/monopole
    antenna (CMA), and the Wellen Radar (WERA) [12] uses a uniform linear array (ULA).
    For compact radar with CMA, direction finding (DF) instead of beamforming should
    be used to identify the direction of arrival (DOA) of each Doppler cell due to
    its wide beam. In general, compact direction-finding (DF) radars are somewhat
    inferior to beamforming radars in both the accuracy and detection range of current
    measurements, but they are often preferred in practical application owing to their
    ease of deployment. Correspondingly, different QC measures should be taken for
    different types of radar systems. Numerous efforts have been made to enhance QC
    methods for current measurements using HFR. Lipa described the methods to derive
    the uncertainties of the radial and vector current for the SeaSonde and provided
    suggestions to minimize these uncertainties [13]. Laws et al. reported how to
    estimate and assess the current measurement errors related to antenna pattern
    distortion (APD) for the SeaSonde [14]. They also introduced a model for assessing
    HFR current measurement error based on subperiod measurement variance [15], which
    was demonstrated to be able to improve the assessment of current measurement uncertainty.
    Kirincich et al. developed QC thresholds by examining signal-to-noise ratio (SNR)-related
    radial metrics and DF quality metrics, which improved the root mean square error
    (RMSE) of current measurement by up to 2 cm/s based on a two-month-long dataset
    [16]. Roarty et al. continuously worked on the development of operational QC methods
    and laid out the framework for quality assurance (QA) methods and QC tests for
    the entire data processing chain [17,18]. Kim presented examples of the data quality
    assessment of radial currents obtained by HFR using statistical and dynamical
    approaches in a hindcast mode [19]. Paolo et al. examined the use of radial metrics
    outputs from the SeaSonde to enhance the accuracy of radial current measurements
    and reduce error [20]. Haines et al. implemented a QC method using non-velocity
    metrics of the signal quality and solutions to address the challenge of the coexistence
    of high and low currents [21]. Ren et al. applied a nudging data assimilation
    algorithm to incorporate real-time HFR current measurements into a numerical model,
    which improved the predictive capability of the numerical model [22]. Cosoli et
    al. developed a real-time and offline QC methodology based on the determination
    of Doppler line SNR values that contribute to hourly radial current at each range-bearing
    pair for the SeaSonde [23,24]. Doppler velocities are weighted by their SNR values
    and spectral quality factors. Velocities are then averaged to produce a final
    output. Michael et al. developed a unified radial data delay mode QC method, which
    consists of a five-step QC process [25]. The effectiveness of the method was verified
    by comparing the post-processed radial current with the original radial file generated
    by the remote site. Lorente et al. [26] proposed a combined quality control methodology
    and applied it to real-time web monitoring of nonvelocity-based diagnostic parameters
    to infer both radar site status and HF radar system performance. The validation
    of HF radar data with independent in situ observations from a moored current meter
    was conducted. The results show that the accuracy assessment of radial and total
    vectors is highly consistent. Lipa et al. developed a QC method for broad-beam
    HFR current measurements, which involves an internal consistency check between
    the measured Doppler spectra and the values predicted from fundamental equations
    [27]. Emery and Washburn concluded that the main sources of error in oceanographic
    HFR came from DF uncertainties and that these DF uncertainties were suitable for
    assimilation into numerical models [28]. Due to a vested interest in collecting
    high-quality national scale data, the United States Integrated Ocean Observing
    System (U.S. IOOS) continued to develop QC protocols for real-time HFR measurements
    [29]. Previous studies on wide-beam radar have shown that the QC methods based
    on the SNR and spatial–spectral metrics can improve the quality of radar current
    data. However, the QC methods mentioned above mainly provide quality flags such
    as pass, not evaluated, suspected, failed, and missing. No quality factors (QFs)
    based on the quantified relation between the SNR and spatial–spectral metrics
    as well as the reliability factor have been used. Moreover, the connection between
    the quality of vector current and that of radial current has not been investigated
    yet. As a result, it is a challenge for different users to select radials and
    vectors of specific quality levels that meet their needs using these existing
    QF models. Extensive evaluations and comparisons with in situ observations including
    drifters, acoustic Doppler current profilers, buoys, and point-based current meters
    [30,31,32,33,34,35,36] have demonstrated that HFR can accurately measure ocean
    surface currents. A series of field experiments have shown that the root mean
    square error (RMSE) between radar and in situ current measurements typically falls
    within the range of 5 to 67 cm/s, and the correlation coefficient (CC) often remains
    below 0.92, as shown in Table 1. In addition, some other factors such as radio
    frequency interference (RFI), impulse interference (IMI), and ionospheric clutter
    can also affect the quality of the surface current. Thus, there is still much
    room to further improve the quality of radar measurements. Table 1. Radar accuracies
    in references. Aiming at QC for the current measured by compact DF HFRs, this
    study proposes QF models for radial current and vector current, respectively,
    which provide a basis for the presented QC method. Firstly, signal preprocessing
    is performed to remove IMI and RFI that frequently occur in the HF band. Then,
    the QF for each radial current is calculated based on signal metrics, including
    the SNR and angular spectrum. Finally, in the synthesis of vector current, the
    QF for each vector current is obtained via an error propagation model according
    to the geometric dilution of precision (GDOP). Based on the proposed model, more
    effective data can be achieved for both radial and vector currents. The proposed
    QC method is validated using a one-month-long HFR dataset collected by the Ocean
    State Monitoring and Analyzing Radar, model S (OSMAR-S) [37] in comparison with
    buoy measurements. The remainder of this paper is organized as follows: Section
    2 describes the proposed QF models for radial current and vector current, and
    the QC method. Section 3 shows the improvement in radar current measurements resulting
    from QC. Section 4 provides some discussions and Section 5 draws the conclusion.
    2. QF Models and QC Method To address the challenge of evaluating and improving
    HFR current measurements, a QC method is developed for radial current and vector
    current, respectively. Within the QC method, a QF is calculated for each radial
    current or vector current to indicate its reliability level. Data users can then
    select currents of certain qualities for different marine applications. 2.1. QF
    Model for Radial Current The radial currents are extracted from the Doppler lines
    in the first-order Bragg region in the HFR range–Doppler spectrum. Correspondingly,
    an empirical QF model is constructed here using the underlying signal indices,
    including the SNR- and DF-related metrics. 2.1.1. SNR-Related QF As described
    in [14], the SNR plays a key role in identifying each Doppler line in the first-order
    Bragg region and subsequent DOA estimation. Therefore, the SNR of each Doppler
    line is taken as a major quality metric. In this study, the noise floor is estimated
    by averaging the spectrum in the region beyond ±1.8 times the Bragg frequency
    at each range bin. Using an SNR reference value of 12 dB, the SNR-related QF is
    given by 𝑞 𝑠𝑛𝑟 =min(10lg( 𝑃 𝑆 / 𝑃 𝑁 )/12,1), (1) where 𝑃 𝑆 is the power of the
    Doppler line and 𝑃 𝑁 is the power of the noise floor. To strike a balance between
    the radial current qualities and detection range, an empirical range-dependent
    SNR threshold [37], η, is used to select strong Doppler lines in the first-order
    Bragg region for further current extraction, and it is given by 𝜂= ⎧ ⎩ ⎨   
     10 dB , (12−𝑟/20) dB, 8 dB,    0<𝑟<40 km 40 km≤𝑟<80 km 𝑟≥80 km , (2) where 𝑟
    is the radar range. 2.1.2. DF-Related QF For each Doppler line in the first-order
    Bragg region, DF is used to estimate the DOA of the radial current. Errors in
    the DOA will cause biases in the estimated radial velocity and thus degrade the
    accuracy of the final estimates of the vector current field. Consequently, the
    quality of the radial current measurement also highly relies on the accuracy of
    the DOA estimation. In this study, the MUltiple SIgnal Classification (MUSIC)
    algorithm is used to calculate the spatial spectrum and determine the DOA. The
    DOA variance associated with MUSIC in the case of a single source can be found
    in [38], which is given by var( 𝜃 ∧ )= 1 2𝐾⋅SNR ⎧ ⎩ ⎨   1+ [ 𝑎 𝐻 (𝜃)𝑎(𝜃)] −1
    SNR ⎫ ⎭ ⎬   /ℎ(𝜃), (3a) ℎ(𝜃)= 𝑎 ˙ 𝐻 (𝜃){I−𝑎(𝜃) [ 𝑎 𝐻 (𝜃)𝑎(𝜃)] −1 𝑎 𝐻 (𝜃)} 𝑎
    ˙ (𝜃), (3b) where 𝜃 is the incident azimuth, 𝑎(𝜃) is the steering vector, 𝑎 ˙
    (𝜃) is the derivative of 𝑎(𝜃) , 𝑎 𝐻 (𝜃) is the transposition of 𝑎(𝜃) , and 𝐾 is
    the number of snapshots. The use of measured antenna patterns has been reported
    to be beneficial to the accuracy of current measurements [39], but it may also
    result in blanking regions in the radial current map. When measured patterns are
    available, they can be substituted into (3), and correspondingly the variance
    should be calculated numerically. Otherwise, an analytical solution can be sought
    using the ideal model. For the CMA antenna used in this study, the ideal steering
    vector can be expressed as [39] 𝑎(𝜃)=[1,cos(𝜃+𝜋/4),sin(𝜃+𝜋/4)], (4) and the corresponding
    DOA variance estimation is given by [40] var( 𝜃 ∧ )= 1 2𝐾⋅SNR (1+ 1 2SNR ). (5)
    This DOA variance is independent of the actual DOA and decreases monotonically
    as the SNR increases, as shown in Figure 1. In OSMAR-S, the number of snapshots
    is 17, so at the SNR threshold for radial current extraction (≥8 dB) the standard
    deviation of the DOA error is less than 4.1° in theory. This error is relatively
    small and acceptable for radial current mapping, but it has a significant effect
    on the overall error in the vector current measurements. Figure 1. Standard deviation
    of the DOA estimated by the CMA with ideal patterns. The DF error-related QF is
    written as 𝑞 𝑑𝑜𝑎 =min( 2.5 var( 𝜃 ̂  ) − − − − − − √ ,1), (6) where 2.5° is the
    standard deviation of the DOA estimation when the SNR is 12 dB. As described in
    (5), the DF-related QF also relies on the SNR value but in an indirect way. The
    DOA can be determined according to the peak of the MUSIC spectrum. Because the
    MUSIC algorithm decomposes the data into signal and noise subspaces, the prominence
    of the eigenvalue(s) can also serve as an indicator of quality. Thus, the ratio
    of the eigenvalue(s) of the signal subspace to that of the noise subspace can
    be used to form an eigenvalue-related QF. In the case of a single source, the
    eigenvalue-related QF is given by 𝑞 𝑒𝑣 =min(lg[2 𝜆 1 /( 𝜆 2 + 𝜆 3 )],1), (7) while
    in the case of dual sources, it is calculated as 𝑞 𝑒𝑣,𝑖 =min(lg( 𝜆 𝑖 / 𝜆 3 ),1),(𝑖=1,2),
    (8) where 𝜆 1 , 𝜆 2 , and 𝜆 3 are the three eigenvalues sorted in a descending
    order. Since the CMA has three elements, the maximum number of sources resolvable
    at the same Doppler frequency is two. Considering that the DF accuracy in the
    case of dual sources is lower than that of a single source, an extra QF is introduced
    as 𝑞 𝑛𝑜𝑠 ={ 1,        for single source 0.9,      for dual sources . (9) Based
    on the above analyses, the overall DF-related QF is 𝑞 𝑑𝑓 = 𝑞 𝑑𝑜𝑎 × 𝑞 𝑒𝑣 × 𝑞 𝑛𝑜𝑠
    . (10) 2.1.3. Overall QF of Radial Current The overall QF for radial current is
    obtained as the product of 𝑞 𝑠𝑛𝑟 and 𝑞 𝑑𝑓 , i.e., 𝑞 𝑅𝐶 = 𝑞 𝑠𝑛𝑟 × 𝑞 𝑑𝑓 . (11) Note
    0≤ 𝑞 𝑅𝐶 ≤1 . This QF can also serve as a model for error propagation in radial
    current extraction. The variance of the initial speed quantization error can be
    determined in terms of the Doppler resolution as 𝜎 2 𝑣 =𝑣𝑎𝑟( 𝛿 𝑣 )=𝑣𝑎𝑟( 𝜆𝛥𝑓 2
    )= 𝜆 2 48 (𝑀𝑇) 2 , (12) where 𝜎 𝑣 is the standard deviation of radial current
    speed, and 𝛿 𝑣 is the quantization error of speed, 𝑇 is the sweep period and M
    is the number of points in the window for calculating the power spectrum, and
    𝜆 is the wavelength of radar wave. Taking OSMAR-S as an example, M is 1024, T
    is 0.38 s, when the system operates at 13 MHz, the standard deviation 𝜎 𝑣 is 1.71
    cm/s. The variance in radial current speed is a key contributor to the accuracy
    of the HFR surface current. The question is how to establish a relationship between
    QF and the variance of a given radial current. Assuming this relation is deterministic,
    then the variance propagation factor, k, is a function of the radial current QF,
    𝑞 , 𝑘=𝑓(𝑞). (13) Thus, if the base variance is 𝜎 2 (for 𝑞 = 1), the propagated
    variance for an arbitrary q becomes 𝑘 𝜎 2 . This relation enables a quantized
    description of the QF propagation from the radial current to the vector current.
    2.2. QF Model for the Vector Current Generally, a vector current is synthesized
    using the radial currents derived from two or more stations [41]. As a result,
    any estimation error from the radial current will be propagated to the vector
    current. The GDOP plays a key role in this propagation, and it consists of various
    factors [42] such as spatial geometry and errors in radial currents from each
    station. Large GDOP values often appear in the radar baseline area as well as
    at the edge of the vector grid. Considering the dataset used in this study was
    collected from two radar stations, we will present the analysis and expression
    for the case with two radars here. Those for the case involving three or more
    radars can be derived in a similar way. 2.2.1. Principle of Vector Current Synthesis
    Figure 2 shows a schematic diagram of synthesizing two radial currents into a
    vector current. Assume the two radial speeds are 𝑣 𝑟1 and 𝑣 𝑟2 , their directions
    are 𝜃 1 and 𝜃 2 (angle to the north and positive angle runs clockwise), and the
    vector current speed and direction are 𝑉 and 𝜃 , respectively. The east–west and
    south–north components can be determined as 𝑢= 𝑣 𝑟1 cos 𝜃 2 − 𝑣 𝑟2 cos 𝜃 1 sin(
    𝜃 1 − 𝜃 2 ) , (14a) 𝑣= 𝑣 𝑟2 sin 𝜃 1 − 𝑣 𝑟1 sin 𝜃 2 sin( 𝜃 1 − 𝜃 2 ) . (14b) Figure
    2. Vector current synthesis using radial currents from two remote radars. Thus,
    the vector current speed and direction are 𝑉= 𝑢 2 + 𝑣 2 − − − − − − √ , 𝜃=arctan
    𝑢 𝑣 , respectively. 2.2.2. QF of the Vector Current Using the function theory
    of random variables [43], we can derive the variance in the vector current from
    those in the radial currents as 𝜎 2 𝑆 = (𝑢cos 𝜃 2 −𝑣sin 𝜃 2 ) 2 𝜎 2 1 + (𝑢cos
    𝜃 1 −𝑣sin 𝜃 1 ) 2 𝜎 2 2 𝑉 2 sin 2 ( 𝜃 1 − 𝜃 2 )      = sin 2 (𝜃− 𝜃 2 ) 𝜎 2 1 +
    sin 2 (𝜃− 𝜃 1 ) 𝜎 2 2 sin 2 ( 𝜃 1 − 𝜃 2 ) , (15) where 𝜎 2 1 and 𝜎 2 2 are the
    variances in radial currents obtained from two stations, respectively. Once the
    variances in the radial currents involved in the vector synthesis are obtained,
    the final vector current variance can be calculated by considering the geometry.
    It should be noted that the effects of the distances of the grid point to the
    radar sites have been implied in the radial variances 𝜎 2 1 and 𝜎 2 2 . Equation
    (15) depicts the GDOP for vector synthesis, but besides the geometry of the grid
    cell and the radars, it is also dependent on the radial current speed variance
    and vector current direction. This means the GDOP varies with current distribution,
    environmental noise level, and radar parameters, etc. In other words, the GDOP
    should not be determined only according to the geometry. The QF calculation process
    for the vector current is shown in Figure 3. The variance in the radial current
    is calculated using (13). Then the variance in the vector current is obtained
    from (15). Finally, an empirical reference variance is selected, and the QF of
    the vector current is calculated based on the ratio of the vector current variance
    to the reference variance. Figure 3. Flow of the vector current QF calculation.
    2.3. QC Method The accuracy and reliability of HFR measurements may be decreased
    by strong external noises such as interference and ionospheric clutter, which
    can result in raised noise levels and a reduced detection range. Particularly,
    when the interference and clutter overlap with the Bragg peak, they can lead to
    erroneous measurements of ocean surface currents. In the OSMAR-S system, the effective
    detection range is up to 150 km when operating with an average transmission power
    of 100 W at 13 MHz. For a range resolution of 2.5 km, the maximum number of range
    bins with radial current information is 60. 2.3.1. Interference Detection and
    Suppression Because IMI often has a strong effect on both range and Doppler dimensions,
    it may severely contaminate useful signals. Therefore, it is essential to detect
    and suppress IMI to ensure the accuracy and reliability of the received signals.
    The steps of IMI suppression are illustrated as follows. Firstly, the time series
    of the average power for the range bins greater than 60 (i.e., reserved range
    bins) is obtained. Secondly, the histogram of the series is generated and a reference
    power is determined as the value at which the cumulative percentage exceeds a
    specified threshold (e.g., 70%). Thirdly, the power threshold is calculated as
    the summation of the reference value and a preset SNR threshold (e.g., 10 dB).
    Finally, samples exceeding this power threshold are identified as IMI and set
    to zero. To avoid the negative effect due to truncating the data over a long interval,
    it is necessary to check the duration of IMI. If it exceeds a certain number of
    points (e.g., 200 points), only those IMI samples near the peak power are removed
    to avoid high sidelobes caused by the nulling. Figure 4 shows an example of IMI
    suppression. Figure 4a depicts a range–Doppler (RD) spectrum containing severe
    interference. Strong IMI overlaps with the negative Bragg peak and it significantly
    affects the extraction of sea state information. The range–time spectrum is displayed
    in Figure 4b, where strong IMI is observed across the range bins. Figure 4c illustrates
    the histogram and cumulated percentage of the range–time spectra. The corresponding
    threshold obtained is presented in Figure 4d. After nulling of the frames containing
    IMI, the resulting RD spectrum is displayed in Figure 4e. Notably, Figure 4e clearly
    demonstrates the effectiveness of IMI suppression, the negative Bragg peak, previously
    overwhelmed by interference, is now visible, and the noise level also drops. Figure
    4f illustrates the Doppler spectra at the 30th range bin before and after IMI
    suppression, from which the Bragg peaks can be easily observed after IMI suppression.
    However, some RFIs still exist at around −1.095 Hz, −0.6735 Hz, −0.3907 Hz, and
    0.7763 Hz. Figure 4. An example of the IMI suppression results. (a) RD spectrum
    at 07:52 on 26 February 2013; (b) The range–time spectrum; (c) Histogram and accumulation
    numbers of the range–time spectrum from 60 to 100; (d) IMI decision based on the
    threshold; (e) RD spectrum after IMI suppression; (f) Doppler spectra at the 30th
    range bin before and after IMI suppression. RFI detection is then performed on
    the mean Doppler spectrum across the reserved range bins using a similar decision-making
    process to that used for IMI. After that, the orthogonal projection filter in
    the range domain [37] is used to suppress RFI. The RFI suppression results are
    displayed in Figure 5. Comparing Figure 5a with Figure 4e, we can see those RFIs
    are almost completely suppressed while the noise level remains low and flat. The
    Doppler spectra at the 30th range bin before and after RFI suppression are shown
    in Figure 5b for a more detailed comparison. Figure 5. An example of the RFI suppression
    results. RD spectrum at 07:52 on 26 February 2013. (a) RD spectrum after RFI suppression;
    (b) Doppler spectra at the 30th range bin before and after IMI and RFI suppression.
    2.3.2. Ionospheric Clutter Detection and Exclusion Ionospheric clutter is another
    factor that can significantly degrade the performance of HFR in the surface current
    measurement. Therefore, it is necessary to identify and suppress the ionosphere
    clutter. Various methods for detecting ionospheric clutter have been developed,
    e.g., [44]. Considering the difficulty in efficient suppression of ionospheric
    clutter with a compact radar, those range bins containing ionospheric clutter
    are typically excluded to prevent large errors. An example of radar data containing
    ionospheric clutters is shown in Figure 6a, in which strong ionospheric clutters
    appear near the 16th, 110th, and 125th range bins. Figure 6b illustrates the spectrum
    at the 16th range bin, where the negative Bragg peak is contaminated by the ionospheric
    clutter. Figure 6. An example of radar data containing ionospheric clutter. (a)
    RD spectrum at 17:20 on 26 February 2013; (b) Doppler spectrum with ionospheric
    clutter. 2.3.3. Flow of QC HFR performance can be easily affected by the external
    environment if no QC measure is taken. To improve the reliability of radar data,
    preprocessing of the radar signals is essential to suppress interference and exclude
    the ionospheric clutter regions. The flow charts for the radial current mapping
    and signal preprocessing are depicted in Figure 7. The processing for the radial
    current extraction with OSMAR-S is shown in Figure 7a. Further details on the
    mapping of the radial and vector currents can be found in [37]. Figure 7b shows
    the flow of RFI and ionospheric clutter suppression. Here, QC measures are taken
    in every module throughout the current extraction, including the radial and vector
    currents mapping. Figure 7. Flow chart for the radial current mapping and signal
    preprocessing (i.e., interference detection and suppression). (a) Current mapping;
    (b) Signal preprocessing. 3. Experimental Results 3.1. Description of Experiment
    The proposed QC method was validated using the datasets collected from a field
    experiment that involved two HFRs at SHLI and XIAN, respectively. The HFRs were
    OSMAR-S, whose parameters are listed in Table 2. Four buoys (A, B, D, and E) were
    deployed within the overlapping coverage areas of the two radars to provide in
    situ current velocity measurements. The map of the investigated sea area is shown
    in Figure 8, in which the position of the radar stations and buoys are marked.
    The red dots represent the locations of the two radar stations, while the red
    triangles indicate the positions of the buoys. The maximum range of surface current
    mapping reaches 100 km and is denoted by the black dotted line. Table 3 shows
    information about the distances between the radar and buoys, as well as the water
    depth. The dataset was collected over one month from 1 February 2013 to 28 February
    2013. Figure 8. Map of the experiment area. “A”, “B”, “D”, and “E” indicate the
    buoy locations. The depth of water is indicated by the color bar. Table 2. Radar
    parameters. Table 3. Distances between the radars and buoys and water depths at
    the buoy locations. 3.2. Radial Current The proposed QF modeling and QC methods
    were incorporated into the OSMAR-S software (RemoteSiteConsole v1.0.0.65) for
    current extraction. The QF for each current also enables a detailed evaluation
    of the various QFs involved. Table 4 and Table 5 show the CC and RMSE results
    over different QF intervals for the radial currents derived by the SHLI and XIAN
    radars, respectively. The data presented in these tables reveal that the current
    cells whose QFs are greater than 0.6 account for the vast majority of all the
    data and generally have higher CCs and smaller RMSEs. The rest of the current
    cells whose QFs are below 0.6 often display either low CCs or large RMSEs. In
    addition, although point B is closer to the SHLI station than other buoy locations
    (say, A, D, and E), its CC is much lower. This is because the radial current speed
    values at point B are much smaller than those at other points (see Figure 9).
    A similar phenomenon can be observed at point E for the XIAN station. Figure 9.
    Radial current before and after QC at the SHLI station compared with buoys. (a)
    Buoy at A; (b) Buoy at B; (c) Buoy at D; (d) Buoy at E. Table 4. Statistics of
    the radial currents within different QF intervals at the SHLI station. Table 5.
    Statistics of the radial currents within different QF intervals at the XIAN station.
    According to the above analysis, only those current cells whose QFs are above
    0.6 are retained for further processing, and this is a core criterion for the
    QC in this study. Table 6 depicts the comparison of the CC and RMSE results between
    the radar-derived and buoy-measured currents before and after QC incorporating
    different QF components. Table 6. Accuracy of the OSMAR-S radial current incorporating
    different QF components. As can be seen from Table 6, before QC, the RMSEs between
    the radar-derived and buoy-measured radial current generally range from 0.12 to
    0.22 m/s, whereas the CCs vary from 0.33 to 0.94. By a detailed observation of
    the time series (see Figure 9 and Figure 10), it can be found that the CCs below
    0.5 mainly occur when the radial current speeds are small (within ±0.4 m/s, see
    point B for SHLI and points D and E for XIAN) and a relatively weak tidal property
    is seen. After QC, all the corresponding CCs and RMSEs were improved. Particularly
    with respect to point D, which is more than 80 km from both radar stations, the
    CCs increased by 27.04% and 102.91%, respectively, and the RMSEs reduced by 49.65%
    and 37.22%, respectively. Figure 10. Radial current before and after QC at the
    XIAN station compared with (a) Buoy at A; (b) Buoy at B; (c) Buoy at D; (d) Buoy
    at E. Since the proposed QF model consists of both SNR- and DF-related components,
    to find out their respective contribution to the QC performance, the CCs and RMSEs
    are calculated after QC according to 𝑞 𝑠𝑛𝑟 and 𝑞 𝑑𝑓 separately. A threshold of
    0.6 is also used for both cases. It can be easily seen that the DF-related component
    leads to a greater improvement than the SNR-related one. This suggests that more
    work should be focused on decreasing the DF error in the radial current measurement.
    However, the combination of both components generally leads to the best performance
    (especially the smallest RSMEs), which confirms the validity of the proposed QF
    model. Figure 9 and Figure 10 show the time series of the radial currents of buoy
    data and the radar-derived results before and after QC for the SHLI and XIAN stations.
    These figures highlight a strong agreement between the radar-derived radial currents
    and buoy data, characterized by a fairly high correlation. Furthermore, the radial
    current velocities appeared smoother and more consistent with the buoy data after
    QC. Figure 11 and Figure 12 show the scatter plots of the radial current. The
    plots include the linear fit line (black line) and ideal relationship (red line)
    between radar and buoy data, as well as the frequency of different current speeds.
    The results demonstrate that the radar current result is generally consistent
    with the buoy data, with slightly less accuracy observed at buoy B for SHLI and
    buoy E for XIAN due to the small magnitudes of radial current speed. After QC,
    the radar radial current results and buoy data are more consistent. Figure 11.
    Radial current scattering point comparisons between buoys A, B, D, E, and OSMAR-S
    radar at the SHLI station. (a,e,i,m) are radial currents comparisons between buoy
    data at A, B, D, E, and radar before QC, respectively. (c,g,k,o) are radial current
    comparisons between buoy data at A, B, D, E, and radar after QC, respectively.
    (b,f,j,n) are comparisons of the number of occurrences of different current speed
    intervals between buoy data at A, B, D, E, and radar before QC, respectively.
    (d,h,l,p) are comparisons of the number of occurrences of different current speed
    intervals between buoy data at A, B, D, E, and radar after QC, respectively. Figure
    12. Radial current scattering point comparisons between buoys A, B, D, E, and
    OSMAR-S radar at the XIAN station. (a,e,i,m) are radial current comparisons between
    buoy data at A, B, D, E, and radar before QC, respectively. (c,g,k,o) are radial
    current comparisons between buoy data at A, B, D, E, and radar after QC, respectively.
    (b,f,j,n) are comparisons of the number of occurrences of different current speed
    intervals between buoy data at A, B, D, E, and radar before QC, respectively.
    (d,h,l,p) are the number of occurrences of different current speed intervals comparison
    between buoy data at A, B, D, E, and radar after QC, respectively. 3.3. Vector
    Current To obtain the ocean surface current field, relying solely on radial current
    information from a single radar station is insufficient as it cannot provide a
    comprehensive view of the current distribution. Therefore, we need to use two
    or more radar stations to obtain the vector current map. A vector current map
    obtained is shown in Figure 13a. Figure 13b shows the QFs corresponding to the
    vector current field. As can be seen from Figure 13b, buoy A is located at the
    position with a relatively high QF, and the QFs gradually decrease with the increase
    in the distance from the two radar stations. In addition, there are a few points
    at the edge of the overlapping region with high QFs, possibly due to target signals
    such as ships. Figure 13. Vector current map and QFs at 22:00:00 on 1 February
    2013. “A”, “B”, “D”, and “E” indicate the buoy locations. (a) Vector current map;
    (b) QFs. The QC method proposed in this paper was applied to the radar-measured
    data to evaluate its effectiveness. Figure 14 shows the time series of the buoy
    data and radar current after QC. As can be seen, the current speed and direction
    obtained from the radars are in good agreement with the buoy data. Especially
    the data at points A and B show a better consistency with the buoy data. Figure
    14. Time series comparison of radar current after QC and buoy data. (a,c,e,g)
    are the current speeds of radar after QC and buoys A, B, D, and E, respectively;
    (b,d,f,h) are the current directions of radar after QC and buoys A, B, D, and
    E, respectively. Figure 15 displays the scatter plots of the current speed and
    directions after QC. In the plots, the red line represents the ideal relationship,
    while the black line represents the linear fit. As can be seen, the consistency
    between the radar-derived current speed and buoy data at point A is the best,
    while the consistency for point B, point D, and point E is slightly poor. The
    radar-derived currents are mainly concentrated in two directions, i.e., −120°
    and 60°, differing by 180°, which is a typical tidal current feature. Figure 15.
    Comparison of current scattering points between buoy and radar after QC. (a,c,e,g)
    are the current speed scatter points of the radar data after QC with buoys A,
    B, D, and E, respectively; (b,d,f,h) are the current direction scatter points
    of the radar data after QC with the buoy A, B, D and E, respectively. To further
    validate the effectiveness of the QC method, Table 7 summarizes the CC and RMSE
    of the radar-measured vector current before and after QC compared with the buoy
    data. As can be seen, the radar-derived vector current had the highest correlation
    with buoy A. This is because location A is relatively close to SHLI and XIAN,
    thus in positions with high radar measurement accuracy. The performance of buoy
    locations B, D, and E is slightly worse. However, after QC, the CCs of the radar-derived
    current speed at these three locations are increased by 38.50%, 90.74%, and 31.56%,
    respectively, and the RMSEs are decreased by 27.22%, 24.15%, and 10.50%, respectively.
    The CCs of the current direction are increased by 16.70%, 58.70%, and 62.67%,
    respectively. The RMSEs of the current direction are decreased by 12.37%, 28.99%,
    and 3.07%, respectively. This shows that the accuracy of the radar-derived ocean
    currents was greatly improved after QC. Table 7. Current accuracy statistics of
    OSMAR-S radar. 4. Discussion Researchers have shown that when interference or
    ionospheric clutter overlaps with the Bragg peak in the RD spectrum, it can result
    in inaccurate measurements of ocean surface currents [37,44]. In this work, we
    propose a preprocessing procedure to suppress interference and exclude ionospheric
    clutter regions, which can reduce outliers and avoid strong interference or clutter,
    improving the accuracy of the radial current estimation. Over the past decades,
    the SNR and spatial–spectral metrics have been proven effective in improving the
    data quality of wide-beam radars [24,27]. However, these studies mainly focus
    on the qualitative evaluation of the quality of ocean current data. Specifically,
    the collected data after applying the QF model are labeled with “pass”, “not evaluated”,
    “suspected”, “failed”, and “missing”, i.e., lacking a quantitative relationship
    with the SNR and spatial–spectral metrics. Moreover, the relationship between
    the quality of the vector current and that of the radial current has not been
    fully explored. In this work, we propose a QC method for both radial and vector
    currents. We build a radial current quality model and use the SNR and spectral
    QFs to determine radial current quality. By setting the SNR threshold, we can
    select strong sea echoes to provide more stable estimates of ocean currents. Moreover,
    we build a relationship between the radial current quality and vector current
    quality based on the GDOP. The effectiveness of the proposed method is verified
    using radar-derived and buoy-measured currents. The QF model and the corresponding
    QC method can be applied to three or more radars. Here, we only focus on the expressions
    and results associated with two radars since the data used were collected from
    two radar stations. However, the method can be applied to the case with three
    or more radars. In the future, we will analyze the error in synthesizing the vector
    currents in the multiple station case to further evaluate the effectiveness of
    the proposed QC technique. In this work, we use the SNR and spatial–spectral metrics
    as the indicators of data quality. With a lower SNR threshold, the number of sea
    echo spectral points available for calculation increases, but lower SNR values
    may lead to abnormal radial current speed. However, with a higher SNR threshold,
    the number of available spectral points decreases dramatically, which can result
    in a large number of blank areas in the ocean current map. In addition, the QF
    of the spatial–spectral metrics is also affected by the SNR (e.g., 𝑞 𝑑𝑜𝑎 ). Therefore,
    the setting of the SNR threshold will affect the QF of ocean currents, thereby
    affecting the mapping results of ocean currents. When setting the SNR threshold
    in the model, we need to adopt empirical values of the radar system for various
    environmental conditions. The QF model in this study is semi-empirical, and there
    are some preset key parameters that will affect the final quality factors of currents.
    The optimization of their values will be further studied via more field experiments
    with in situ measurements. Improvement of the QC measures should also be accomplished
    through collaboration between oceanographic researchers and users. In the future,
    we will apply the QF model and the QC measure to other HFR data products, such
    as wave height, wave period, and wind speed. 5. Conclusions To improve the performance
    of the compact HFR system OSMAR-S in ocean surface current measurement, a QC method
    was developed. The QC process involves several key steps: (1) Data preprocessing,
    mainly to suppress IMI and RFI and exclude ionospheric clutter. By removing the
    data with interference, the quality of the radar signals is improved. (2) Create
    quantifiable quality models for the radial current and vector current. QFs in
    these quality models can be used to evaluate data quality. The effectiveness of
    the radial current and vector current QF model was verified by comparing the results
    before and after QC. After QC, the accuracy of the OSMAR-S-derived ocean currents
    was improved due to the removal of the radial current and vector current with
    low QFs. Compared with buoy data, after applying QC, the CCs of radial current,
    vector current speed, and vector current direction were increased by 4.33~102.91%,
    1.04~90.74%, and 1.20~62.67%, respectively, and the RMSEs were decreased by 2.51~49.65%,
    7.86~27.22%, and 1.68~28.99%, respectively. These results prove that the application
    of QC significantly improved the data quality. Author Contributions Conceptualization,
    S.H. and H.Z.; Data curation, Y.T., J.Y., and C.W.; Funding acquisition—Y.T.;
    Methodology, S.H.; Data analysis, S.H.; Validation, H.Z. and W.H.; writing—original
    draft preparation, S.H. and H.Z.; writing—review and editing, S.H., H.Z., W.H.,
    and D.H. All authors have read and agreed to the published version of the manuscript.
    Funding This research was funded by the National Natural Science Foundation of
    China, grant numbers 62071337 and 41806215, and the Guangdong Province Key Area
    Research and Development Program, grant 2020B1111020003. Data Availability Statement
    For the results and data generated during the study, please contact the corresponding
    author. Conflicts of Interest The authors declare no conflict of interest. References
    Barrick, D.E. Remote sensing of sea state by radar. In Proceedings of the Ocean
    72—IEEE International Conference on Engineering in the Ocean Environment, Newport,
    RI, USA, 13–15 September 1972; pp. 186–192. [Google Scholar] Gurgel, K.W.; Antonischki,
    G.; Essen, H.H.; Schlick, T. Wellen Radar (WERA): A new ground-wave HF radar for
    ocean remote sensing. Coast. Eng. 1999, 37, 219–234. [Google Scholar] [CrossRef]
    Lipa, B.; Nyden, B. Directional wave information from the SeaSonde. IEEE J. Ocean.
    Eng. 2005, 30, 221–231. [Google Scholar] [CrossRef] Yang, J.; Wang, C.; Tian,
    Y.; Zhou, H.; Wen, B. Wind Direction Inversion Using Shore-Based UHF Radar. IEEE
    Trans. Geosci. Remote Sens. 2022, 60, 1–16. [Google Scholar] [CrossRef] Wyatt,
    L.R.; Mantovanelli, A.; Heron, M.L.; Roughan, M.; Steinberg, C.R. Assessment of
    Surface Currents Measured with High-Frequency Phased-Array Radars in Two Regions
    of Complex Circulation. IEEE J. Ocean. Eng. 2018, 43, 484–505. [Google Scholar]
    [CrossRef] Tian, Y.; Tian, Z.; Zhao, J.; Wen, B.; Huang, W. Wave Height Field
    Extraction From First-Order Doppler Spectra of a Dual-Frequency Wide-Beam High-Frequency
    Surface Wave Radar. IEEE Trans. Geosci. Remote Sens. 2020, 58, 1017–1029. [Google
    Scholar] [CrossRef] Zhang, W.; Ebuchi, N.; Fukamachi, Y.; Cheng, F.; Ohshima,
    K.I.; Emery, B.M.; Toyota, T.; Abe, H.; Shirasawa, K. Sea Ice Observation with
    Oceanographic HF Radar. IEEE Trans. Geosci. Remote Sens. 2020, 58, 378–390. [Google
    Scholar] [CrossRef] Huang, W.; Gill, E.W. Ocean Remote Sensing Technologies-High
    Frequency, Marine and GNSS-Based Radar; SciTech Publishing: Luxembourg, 2021.
    [Google Scholar] De Vos, S.J.; Cosoli, S.; Munroe, J. The Traveling Wave Loop
    Antenna: A Terminated Wire Loop Aerial for Directional High-Frequency Ocean RADAR
    Transmission. Remote Sens. 2020, 12, 2800. [Google Scholar] [CrossRef] Corgnati,
    L.P.; Mantovani, C.; Griffa, A.; Berta, M.; Penna, P.; Celentano, P.; Bellomo,
    L.; Carlson, D.F.; Adamo, R.D. Implementation and Validation of the ISMAR High-Frequency
    Coastal Radar Network in the Gulf of Manfredonia (Mediterranean Sea). IEEE J.
    Ocean. Eng. 2019, 44, 424–445. [Google Scholar] [CrossRef] Chuang, L.Z.H.; Chung,
    Y.; Tang, S.T. A Simple Ship Echo Identification Procedure with SeaSonde HF Radar.
    IEEE Geosci. Remote Sens. Lett. 2015, 12, 2491–2495. [Google Scholar] [CrossRef]
    Roarty, H.; Cook, T.; Hazard, L.; George, D.; Harlan, J.; Cosoli, S.; Wyatt, L.;
    Alvarez Fanjul, E.; Terrill, E.; Otero, M.; et al. The Global High Frequency Radar
    Network. Front. Mar. Sci. 2019, 6, 164–189. [Google Scholar] [CrossRef] Lipa,
    B. Uncertainties in SeaSonde current velocities. In Proceedings of the IEEE/OES
    Seventh Working Conference Current Measurement Technology, San Diego, CA, USA,
    13–15 March 2003; Rizoli, J.A., Ed.; pp. 95–100. [Google Scholar] Laws, K.E.;
    Paduan, J.D.; Vesecky, J. Estimation and Assessment of Errors Related to Antenna
    Pattern Distortion in CODAR SeaSonde High-Frequency Radar Ocean Current Measurements.
    J. Atmos. Ocean. Technol. 2010, 27, 1029–1043. [Google Scholar] [CrossRef] Laws,
    K.E.; Vesecky, J.F.; Paduan, J.D. Error assessment of HF radar-based ocean current
    measurements: An error model based on sub-period measurement variance. In Proceedings
    of the 2011 IEEE/OES 10th Current, Waves, and Turbulence Measurement (CWTM), Monterey,
    CA, USA, 20–23 March 2011; pp. 70–76. [Google Scholar] Kirincich, A.R.; de Paolo,
    T.; Terrill, E. Improving HF Radar Estimates of Surface Currents Using Signal
    Quality Metrics with Application to the MVCO High-Resolution Radar System. J.
    Atmos. Ocean. Technol. 2012, 29, 1377–1390. [Google Scholar] [CrossRef] Roarty,
    H.; Smith, M.; Kerfoot, J.; Kohut, J.; Glenn, S. Automated Quality Control of
    High Frequency Radar Data. In Proceedings of the 2012 Oceans Conference, Hampton
    Roads, VA, USA, 14–19 October 2012; pp. 1–7. [Google Scholar] Roarty, H.; Palamara,
    L.; Kohut, J.; Glenn, S. Automated quality control of high frequency radar data
    II. In Proceedings of the OCEANS 2016 MTS/IEEE Conference, Monterey, CA, USA,
    19–23 September 2016; pp. 1–3. [Google Scholar] Kim, S.Y. Quality Assessment Techniques
    Applied to Surface Radial Velocity Maps Obtained from High-Frequency Radars. J.
    Atmos. Ocean. Technol. 2015, 32, 1915–1927. [Google Scholar] [CrossRef] De Paolo,
    T.; Terrill, E.; Kirincich, A. Improving SeaSonde radial velocity accuracy and
    variance using radial metrics. In Proceedings of the OCEANS 2015 Conference, Genova,
    Italy, 18–21 May 2015; pp. 1–9. [Google Scholar] Haines, S.; Seim, H.; Muglia,
    M. Implementing Quality Control of High-Frequency Radar Estimates and Application
    to Gulf Stream Surface Currents. J. Atmos. Ocean. Technol. 2017, 34, 1207–1224.
    [Google Scholar] [CrossRef] Ren, L.; Hartnett, M. Hindcasting and Forecasting
    of Surface Flow Fields through Assimilating High Frequency Remotely Sensing Radar
    Data. Remote Sens. 2017, 9, 932. [Google Scholar] [CrossRef] Cosoli, S.; Grcic,
    B.; de Vos, S.; Hetzel, Y. Improving Data Quality for the Australian High Frequency
    Ocean Radar Network through Real-Time and Delayed-Mode Quality-Control Procedures.
    Remote Sens. 2018, 10, 1476. [Google Scholar] [CrossRef] Cosoli, S.; Bolzon, G.;
    Mazzoldi, A. A Real-Time and Offline Quality Control Methodology for SeaSonde
    High-Frequency Radar Currents. J. Atmos. Ocean. Technol. 2012, 9, 1313–1328. [Google
    Scholar] [CrossRef] Lorente, P.; Piedracoba, S.; Soto-Navarro, J.; Alvarez-Fanjul,
    E. Evaluating the Surface Circulation in the Ebro Delta (Northeastern Spain) with
    Quality-Controlled High-frequency Radar Measurements. Ocean Sci. 2015, 11, 921–935.
    [Google Scholar] [CrossRef] Smith, M.; Glenn, S.; Merz, C.; Liu, Y.G.; Weisberg,
    R.; Shay, L.; Howden, S.; Knap, A. A Unified Approach to HF Radar Radial Quality
    Control for Understanding Gulf Ocean Systems. In Proceedings of the OCEANS 2021,
    San Diego, CA, USA, 20–23 September 2021. [Google Scholar] Lipa, B.; Barrick,
    D.; Whelan, C. A Quality Control Method for Broad-Beam HF Radar Current Velocity
    Measurements. J. Mar. Sci. Eng. 2019, 7, 112. [Google Scholar] [CrossRef] Emery,
    B.; Washburn, L. Uncertainty Estimates for SeaSonde HF Radar Ocean Current Observations.
    J. Atmos. Ocean. Technol. 2019, 36, 231–247. [Google Scholar] [CrossRef] Manual
    for Real-Time Quality Control of High Frequency Radar Surface Current Data. Available
    online: https://cdn.ioos.noaa.gov/media/2022/07/HFR_QARTOD_Manual_Update_Final-1b.pdf
    (accessed on 18 November 2023). Emery, B.M.; Washburn, L.; Harlan, J.A. Evaluating
    Radial Current Measurements from CODAR High-Frequency Radars with Moored Current
    Meters. J. Atmos. Ocean. Technol. 2004, 21, 1259–1271. [Google Scholar] [CrossRef]
    Kaplan, D.M.; Largier, J.; Botsford, L.W. HF radar observations of surface circulation
    off Bodega Bay (northern California, USA). J. Geophys. Res. 2005, 110, 1–25. [Google
    Scholar] [CrossRef] Cosoli, S.; Mazzoldi, A.; Gačić, M. Validation of Surface
    Current Measurements in the Northern Adriatic Sea from High-Frequency Radars.
    J. Atmos. Ocean. Technol. 2010, 27, 908–919. [Google Scholar] [CrossRef] Paduan,
    J.D.; Kim, K.C.; Cook, M.S.; Chavez, F.P. Calibration and Validation of Direction-Finding
    High-Frequency Radar Ocean Surface Current Observations. IEEE J. Ocean. Eng. 2006,
    31, 862–875. [Google Scholar] [CrossRef] Rubio, A.; Reverdin, G.; Fontán, A.;
    González, M.; Mader, J. Mapping near-inertial variability in the SE Bay of Biscay
    from HF radar data and two offshore moored buoys. Geophys. Res. Lett. 2011, 38,
    570–583. [Google Scholar] [CrossRef] Solabarrieta, L.; Rubio, A.; Castanedo, S.;
    Medina, R.; Charria, G.; Hernández, C. Surface water circulation patterns in the
    southeastern Bay of Biscay: New evidences from HF radar data. Cont. Shelf Res.
    2014, 74, 60–76. [Google Scholar] [CrossRef] Lorente, P.; Piedracoba, S.; Fanjul,
    E.A. Validation of high-frequency radar ocean surface current observations in
    the NW of the Iberian Peninsula. Cont. Shelf Res. 2015, 92, 1–15. [Google Scholar]
    [CrossRef] Zhou, H.; Wen, B. Portable High Frequency Surface Wave Radar OSMAR-S,
    Intelligent Environmental Sensing; Smart Sensors, Measurement and Instrumentation;
    Springer: Berlin/Heidelberg, Germany, 2015; Volume 13, pp. 79–110. [Google Scholar]
    Stoica, P.; Nehorai, A. MUSIC, Maximum Likelihood, and Cramer-Rao bound. IEEE
    Trans. Acoust. Speech Signal Process. 1989, 37, 720–741. [Google Scholar] [CrossRef]
    Chen, H.; Sarkar, T.K.; Zhu, M.-D.; Salazar-Palma, M. Use of Computational Electromagnetics
    to Enhance the Accuracy and Efficiency of Antenna Pattern Measurements. IEEE J.
    Multiscale Multiphys. Comput. Tech. 2018, 3, 214–224. [Google Scholar] [CrossRef]
    Tian, Y.; Wen, B.; Tan, J.; Li, Z. Study on Pattern Distortion and DOA Estimation
    Performance of Crossed-Loop/Monopole Antenna in HF Radar. IEEE Trans. Antennas
    Propag. 2017, 65, 6095–6106. [Google Scholar] [CrossRef] Islam, T.; Howden, S.D.;
    Diercks, A.R.; Cambazoglu, M.K. Comparison of Ocean Model and HF Radar Surface
    Currents. In Proceedings of the OCEANS 2022 Conference, Hampton Roads, VA, USA,
    17–20 October 2022; pp. 1–5. [Google Scholar] Yarlagadda, R.; Ali, I.; Al Dhahir,
    N.; Hershey, J. GPS GDOP metric. IEEE Proc. Radar Sonar Navig. 2000, 147, 259–264.
    [Google Scholar] [CrossRef] Mitzenmacher, M.; Upfal, E. Probability and Computing:
    Randomized Algorithms and Probabilistic Analysis; Cambridge University Press:
    Cambridge, UK, 2005. [Google Scholar] He, S.; Zhou, H.; Tian, Y.; Shen, W. Ionospheric
    Clutter Suppression with an Auxiliary Crossed-Loop Antenna in a High-Frequency
    Radar for Sea Surface Remote Sensing. J. Mar. Sci. Eng. 2021, 9, 1165. [Google
    Scholar] [CrossRef] Disclaimer/Publisher’s Note: The statements, opinions and
    data contained in all publications are solely those of the individual author(s)
    and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s)
    disclaim responsibility for any injury to people or property resulting from any
    ideas, methods, instructions or products referred to in the content.  © 2023 by
    the authors. Licensee MDPI, Basel, Switzerland. This article is an open access
    article distributed under the terms and conditions of the Creative Commons Attribution
    (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Share and Cite
    MDPI and ACS Style He, S.; Zhou, H.; Tian, Y.; Huang, D.; Yang, J.; Wang, C.;
    Huang, W. Quality Control for Ocean Current Measurement Using High-Frequency Direction-Finding
    Radar. Remote Sens. 2023, 15, 5553. https://doi.org/10.3390/rs15235553 AMA Style
    He S, Zhou H, Tian Y, Huang D, Yang J, Wang C, Huang W. Quality Control for Ocean
    Current Measurement Using High-Frequency Direction-Finding Radar. Remote Sensing.
    2023; 15(23):5553. https://doi.org/10.3390/rs15235553 Chicago/Turabian Style He,
    Shuqin, Hao Zhou, Yingwei Tian, Da Huang, Jing Yang, Caijun Wang, and Weimin Huang.
    2023. \"Quality Control for Ocean Current Measurement Using High-Frequency Direction-Finding
    Radar\" Remote Sensing 15, no. 23: 5553. https://doi.org/10.3390/rs15235553 Note
    that from the first issue of 2016, this journal uses article numbers instead of
    page numbers. See further details here. Article Metrics Citations No citations
    were found for this article, but you may check on Google Scholar Article Access
    Statistics Article access statistics Article Views 7. Jan 17. Jan 27. Jan 6. Feb
    16. Feb 26. Feb 7. Mar 17. Mar 27. Mar 0 200 400 600 800 For more information
    on the journal statistics, click here. Multiple requests from the same IP address
    are counted as one view.   Remote Sens., EISSN 2072-4292, Published by MDPI RSS
    Content Alert Further Information Article Processing Charges Pay an Invoice Open
    Access Policy Contact MDPI Jobs at MDPI Guidelines For Authors For Reviewers For
    Editors For Librarians For Publishers For Societies For Conference Organizers
    MDPI Initiatives Sciforum MDPI Books Preprints.org Scilit SciProfiles Encyclopedia
    JAMS Proceedings Series Follow MDPI LinkedIn Facebook Twitter Subscribe to receive
    issue release notifications and newsletters from MDPI journals Select options
    Subscribe © 1996-2024 MDPI (Basel, Switzerland) unless otherwise stated Disclaimer
    Terms and Conditions Privacy Policy"'
  inline_citation: '>'
  journal: Remote Sensing
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Quality Control for Ocean Current Measurement Using High-Frequency Direction-Finding
    Radar
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Raghu S.T.P.
  - Macisaac D.
  - Scheme E.
  citation_count: '1'
  description: 'Post-processing techniques have been shown to improve the quality
    of the decision stream generated by classifiers used in pattern-recognition-based
    myoelectric control. However, these techniques have largely been tested individually
    and on well-behaved, stationary data, failing to fully evaluate their trade-offs
    between smoothing and latency during dynamic use. Correspondingly, in this work,
    we survey and compare 8 different post-processing and decision stream improvement
    schemes in the context of continuous and dynamic class transitions: majority vote,
    Bayesian fusion, onset locking, outlier detection, confidence-based rejection,
    confidence scaling, prior adjustment, and adaptive windowing. We then propose
    two new temporally aware post-processing schemes that use changes in the decision
    and confidence streams to better reject uncertain decisions. Our decision-change
    informed rejection (DCIR) approach outperforms existing schemes during both steady-state
    and transitions based on error rates and decision stream volatility whether using
    conventional or deep classifiers. These results suggest that added robustness
    can be gained by appropriately leveraging temporal context in myoelectric control.'
  doi: 10.1109/JBHI.2023.3316599
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Journals & Magazines >IEEE Journal of Biomedical an...
    >Volume: 27 Issue: 12 Decision-Change Informed Rejection Improves Robustness in
    Pattern Recognition-Based Myoelectric Control Publisher: IEEE Cite This PDF Shriram
    Tallam Puranam Raghu; Dawn MacIsaac; Erik Scheme All Authors 1 Cites in Paper
    186 Full Text Views Abstract Document Sections I. Introduction II. Review of Established
    DSQI Algorithms III. Newly Proposed Dynamic Rejection Schemes IV. Methods V. Results
    Show Full Outline Authors Figures References Citations Keywords Metrics Footnotes
    Abstract: Post-processing techniques have been shown to improve the quality of
    the decision stream generated by classifiers used in pattern-recognition-based
    myoelectric control. However, these techniques have largely been tested individually
    and on well-behaved, stationary data, failing to fully evaluate their trade-offs
    between smoothing and latency during dynamic use. Correspondingly, in this work,
    we survey and compare 8 different post-processing and decision stream improvement
    schemes in the context of continuous and dynamic class transitions: majority vote,
    Bayesian fusion, onset locking, outlier detection, confidence-based rejection,
    confidence scaling, prior adjustment, and adaptive windowing. We then propose
    two new temporally aware post-processing schemes that use changes in the decision
    and confidence streams to better reject uncertain decisions. Our decision-change
    informed rejection (DCIR) approach outperforms existing schemes during both steady-state
    and transitions based on error rates and decision stream volatility whether using
    conventional or deep classifiers. These results suggest that added robustness
    can be gained by appropriately leveraging temporal context in myoelectric control.
    Published in: IEEE Journal of Biomedical and Health Informatics ( Volume: 27,
    Issue: 12, December 2023) Page(s): 6051 - 6061 Date of Publication: 18 September
    2023 ISSN Information: PubMed ID: 37721893 DOI: 10.1109/JBHI.2023.3316599 Publisher:
    IEEE Funding Agency: SECTION I. Introduction Surface Electromyography (sEMG) signals
    contain rich information about user intent, and as such, have been studied extensively
    in fields such as prosthesis control [1], gesture recognition [2] and rehabilitation
    [3]. Several new techniques and improvements have been proposed for the sEMG Pattern
    Recognition (PR) pipeline including novel features [4], deep Learning (DL) classifier
    models [5], and pre-processing techniques [6]. However, factors such as variation
    in contraction intensity and limb position still degrade the performance of PR
    systems and manifest as errors in the resulting classification decision stream
    [7]. This has motivated researchers to propose a class of algorithms that use
    additional context (e.g. confidence stream) to increase the accuracy and stability
    of the decision stream. These algorithms can broadly be grouped together as Decision
    Stream Quality Improvement (DSQI) algorithms. DSQI techniques include, for example,
    post-processing algorithms [8], adaptive classifiers [9], and outlier rejection
    [10]. Although such techniques have been shown to improve accuracy, it has also
    been reported that improvements in accuracy do not necessarily translate to improvements
    in online usability [11]. As such, a usability test such as a Fitt''s law test
    is often encouraged to assess the impact of algorithm changes on user-in-the-loop
    performance [12]. Nevertheless, offline evaluation remains widely in use because
    it is more convenient and reproducible, and enables the direct comparison of approaches
    on the same dataset. In a previous study [13], we highlighted that the lack of
    correlation between offline accuracy and usability may be due to the controlled
    conditions for offline tests, which do not represent the real-world device usage
    [14]. Most offline studies collect a set of separate motions (steady-state or
    ramp contractions) that are used to train and then test the sEMG-PR algorithms.
    Such constrained protocols simplify the labeling process, but do not reflect the
    feed-forward use of sEMG-PR devices, which necessarily involves dynamic transitions
    between various contractions. Thus, the accuracies reported by offline studies
    provide an incomplete picture of the overall performance of the sEMG-PR system.
    In [13] we proposed a novel framework consisting of several metrics that assess
    classifier performance during transitions in addition to steady-state to bridge
    this gap in offline evaluation. Using this framework, we showed that the behaviour
    of classifiers may differ substantially during transitions even if their steady-state
    performance is comparable. In this work, we build on our previous work by using
    the proposed framework to study the impact of various DSQI algorithms on offline
    performance and use dynamic data containing transitions. Several DSQI algorithms
    have been proposed in the literature, but none have been fully evaluated against
    each other, nor have they been evaluated in the context of data containing transitions.
    Consequently, this work makes the following contributions: A review of established
    DSQI algorithms with a head-to-head comparison. Two novel techniques that adapt
    and respond to transitionary behaviours. An evaluation of these algorithms on
    a new large dynamic dataset using both steady-state and transition metrics. SECTION
    II. Review of Established DSQI Algorithms Various DSQI techniques have been reported
    in the literature with some success. For instance, post-processing rejection is
    well-established in the context of dynamic movements [15], [16], and is widely
    used [17], [18]. Established DSQI schemes can be grouped into three categories
    based on the primary source of information being used: Feature-Based Schemes,
    Confidence-Based Schemes, and Decision-Based Schemes. An overview of this taxonomy
    is shown in Fig. 1. Note that most rejection schemes are confidence-based because
    they rely on the confidence output from the classifier. In order to delineate
    the schemes, we first define some common terminology. Let EMG∈ R N S × N CH be
    the EMG dataset containing N S samples from N CH channels. Let EMG i ∈ R M× N
    CH be the ith EMG frame which is a matrix of size M× N CH with M=Frame Length×Sample
    Rate denoting the number of samples in a frame. Then we can consider EMG i to
    be a collection of signals across channels, i.e. EMG i =[ S i1 , S i2 ,…, S i
    N CH ] , S ij ∈ R M . Let h() denote the feature extractor function that takes
    in EMG i and returns the corresponding feature vector X i ∈ R d . Assuming that
    there are N frames and K classes, let the corresponding supervised labels be denoted
    by Y=[ y 1 , y 2 ,…, y N ] where y i ∈{1,…,K},i=1,…,N . X i is the input to an
    arbitrary classifier f() which outputs a vector of confidences C i =[ c i1 , c
    i2 ,…, c iK ] for frame i which corresponds to confidence values of the k=1,…,K
    classes. Then by definition: X i = C i = 0≤ c sum i = y ^ i = c ˇ i = h( EMG i
    ) f( X i ) c ik ≤1 ∑ k=1 K c ik =1 arg max k ( c ik ) max k ( c ik ) (1) (2) (3)
    (4) (5) (6) View Source where c ˇ i is the highest confidence for frame i across
    all K classes, and y ^ i ∈{1,…,K} is the class decision corresponding to the maximum
    confidence value. Fig. 1. Decision Stream Quality Improvement (DSQI) schemes grouped
    by the main source of information used. Show All Having established this terminology,
    the various DSQI algorithms are described below, and summarized in Table I, categorized
    by decision-based, confidence-based, and feature-based schemes. TABLE I Summary
    of DSQI Schemes Decision-based Schemes: Decision-based schemes use the decision
    outputs from a classifier to smooth out the decision stream. Though classifiers
    in PR-based myoelectric control traditionally treat each frame as being independent
    from each other, there is an inherent temporal ordering in the frames. The temporal
    evolution of the frames belonging to a given contraction is governed by the dynamics
    of the movement, which provides context that can be used to further improve the
    quality of the decision stream. Two common schemes in this group are: Majority
    Vote: Majority Vote (MV) [19] is a simple but popular scheme that combines the
    current decision y ^ i and past m decisions ( y ^ i−1 , y ^ i−2 ,…, y ^ i−m )
    [for a total window length of m+1 ] to re-estimate the new decision y ~ i as given
    by: y ~ i =mode( y ^ i , y ^ i−1 , y ^ i−2 ,…, y ^ i−m ) (7) View Source where
    mode(.) returns the most frequent value. MV is simple to implement and effectively
    removes small blips in the decision stream at the cost of an introduced lag that
    is proportional to the MV length, m . Prior-Adjustment LDA: In prior-Adjustment
    Linear Discriminant Analysis (pLDA) [9], instead of assuming equal prior probabilities
    across classes (as is typically the case) the class priors are dynamically varied
    by a supervisory system after each decision, favouring recently observed decisions.
    The pLDA update rule is as follows: P(k| y ^ i+1 ) P + (k| y ^ i ) Δ n ={ P +
    (k| y ^ i ), P(k| y ^ i ) P + (k| y ^ i )< P max o.w. =P(k| y ^ i )+ Δ n = b s
    (8) View Source where P(k| y ^ i ) represents the prior probability of observing
    class k given decision y ^ i , b represents the growth rate, s represents the
    number of consecutive decisions of the same class, and P max represents the maximum
    permitted prior ( 0< P max <1 ). pLDA is a simple tweak to the Linear Discriminant
    Analysis (LDA) classifier and as such, it is easy to implement with Bayesian-type
    classifiers. This technique, however, is difficult to use with models like SVM
    that do not capture the underlying distribution of the classes, which is required
    for Bayesian inference. Confidence-based Schemes: Confidence-based schemes are
    designed to utilise the confidence stream that a classifier can output, in addition
    to the decisions. The confidence values can be used to accept a decision, or change
    it to smooth the decision stream. Four popular schemes in this group are: Confidence
    Based Rejection: Confidence-based rejection (CBR) [15] involves overwriting class
    decisions with low confidences to a different class. This relies on the classifiers
    themselves being able to provide a measure of the confidence of the output class
    (e.g. via posterior probabilities) that can be used to gauge if the decision is
    to be accepted or rejected. CBR is given by: y i ~ ={ y ^ i ⨂ if c ˇ i >T h Rej
    , o.w. (9) View Source where T h Rej is called the ‘Rejection Threshold’ and ⨂
    is the class that the decision will be assigned to if the class confidence is
    below the rejection threshold. Rejection is useful to mitigate unintended low
    confidence movements that degrade usability. However, the performance of rejection
    depends on the confidence distribution of the classifiers [20], and the selection
    of an appropriate threshold. In this work, we reject low confidence decisions
    to the No Motion (NM) class ( k NM ). Confidence Scaling: Confidence Scaling (CS)
    does not assume uniform class risk and correspondingly scales the class confidences
    c ik , enabling the emphasis of certain classes more than others [9]. The original
    study used this to emphasize the NM class, which results in the scheme behaving
    similar to CBR since NM class is emphasized during periods of low confidences,
    potentially resulting in the output being overridden to the NM class. The scheme
    in the original work was labelled ‘Cost Modification’ and was based on the LDA,
    but the scaling can be trivially extended to any classifier. The new confidences
    c ik ~ are given by: c ~ ik =δ× c ik × s k (10) View Source where δ is a constant
    used to scale c ~ ik so that (4) holds true and s k is a scaling factor associated
    with class k . The corresponding class decision y ~ i is determined as in (5).
    Similar to CBR, this emphasizes the NM class, suppressing low confidence decisions,
    but relies on having a good confidence distribution. If a classifier is over-confident
    in its decision, then the scheme may have minimal impact. Bayesian Fusion: Bayesian
    Fusion (BF) [8] is similar to MV, but operates on confidences rather than the
    decision itself. A flaw in MV is that decisions with low and high confidences
    are given equal weighting, which is undesirable as low confidence (and potentially
    incorrect decisions) significantly impact the output decisions. BF addresses this
    issue by assigning weights that are proportional to the confidence of a decision
    and how temporally separated a decision is from the current one. More specifically,
    it uses the current confidence values c ik and past m class confidences ( c (i−1)k
    , c (i−2)k ,…, c (i−m)k ) [for a total window length of m+1 ] to re-estimate the
    new class confidences c ~ ik and is given by: c ~ ik =δ ∏ n=0 m ( c (i−n)k + a
    n ) (11) View Source where δ is a constant to scale c ~ ik so that (4) holds true,
    and a n is a constant given by: a n =10× exp(−0.5× n+1 m+1 ) ∑ m+1 l=1 exp(−0.5×
    l m+1 ) (12) View Source The corresponding class decision y ~ i is determined
    as in (5). Similar to MV, BF trades-off lag for smoothness, however the lag may
    be less pronounced than MV due to BFs weighting process. Adaptive Windowing: Adaptive
    Windowing (AW) is based on the fact that, while shorter frames are desirable to
    improve responsiveness, longer frames provide more stable estimates and thus higher
    accuracy [21]. Instead of holding the frame length fixed, adaptive windowing allows
    the frame length to be varied dynamically based on the confidence. Initially,
    features are extracted for a small frame length. If the confidence corresponding
    to the class decision for that frame is less than a threshold ( T h AW ), the
    scheme simply increases the frame length and reattempts the classification. This
    is repeated until either the confidence is high enough, or a maximum frame length
    is reached. Every time the confidence is ascertained to be low, the PR system
    returns the NM class ( k NM ) and increases the frame length. This has the effect
    of appending new EMG samples to the existing EMG frame and reclassifying the new
    data. If the max frame length is reached but the confidence is still low, k NM
    is returned until the target confidence is reached. The scheme therefore acts
    similar to CBR. The frame length is reset to the base value once the target confidence
    is reached. The scheme is delineated in Algorithm 1. AW may help mitigate errors
    due to smaller window sizes, but introduces computational burden as features from
    multiple window lengths must be extracted for training classifiers. Additionally,
    AW was designed with conventional classifiers (such as the LDA) in mind, but interactions
    with temporal classifiers such as the Long Short-Term Memory (LSTM), which requires
    both current and past frame values, remain unclear. Feature-based Schemes: Feature-based
    schemes are designed to utilize information directly from the stream of feature
    vectors X i . Although the classifiers are served these same features, discrete
    categorization during classification may lead to missed context in the decision
    stream. This context can be re-introduced in post-processing. SECTION Algorithm
    1: Adaptive Window Algorithm. FL←160ms ; /* Frame Length */ FI←16ms ; /*Frame
    Increment */ ML←256ms ; /*Max Frame Length */ // While new samples are available
    while EMG do /*Generate a frame from the latest samples */ EMG i ←w(EMG,FL,FI)
    ; X i ←h( EMG i ) ; c ˇ i ←f( X i ) ; if c ˇ i ≥T h AW then y i ~ ← y ^ i ; FL←160ms
    ; else if FL<ML then FL←FL+FI ; end y i ~ ← k NM ; end end Onset Locking: Onset
    Locking (OL) uses amplitude information to detect the onset and offset of movements
    to ‘lock’ the decision stream of the PR system [22]. This relies on that assumption
    that low amplitude values indicate a lack of active contraction, and therefore
    all decisions during this period can be locked to NM class ( k NM ). If a period
    of low amplitude is followed by a period of high amplitudes, then an onset of
    movement is assumed. Frames with high amplitudes values are then locked to the
    MV of the initial few decisions made by the classifier. In this work, we used
    the mean of the Mean Absolute Values (MAV) as the measure of activity, as given
    by: y i ~ ={ k NM LD i if MAV ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ i <T h MAV , o.w. (13) View
    Source where MAV ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ i ∈R is the proportional control signal
    and T h MAV is the threshold used to detect onset of movement. Let MAV ij ∈R represent
    the MAV of channel j for frame i and let MAV i ∈ R N CH represent a vector of
    MAVs across all channels, then MAV ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ i is determined as:
    MAV ij =μ(| S ij |) MAV i =[ MAV i1 ,…, MAV iJ ] MAV ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ i
    =μ( MAV i ) View Source where μ(.) returns the mean. T h MAV is determined using
    the NM class proportional control values across all the frames in the training
    data: MAV ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ NM =[ MAV ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ i ∣k= k NM
    ] T h MAV =μ( MAV ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ NM )+3×σ( MAV ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯
    ¯ NM ) View Source where σ(.) returns the standard deviation. LD i in (13) is
    the locked decision calculated from the moment of onset. If the onset of movement
    is detected at frame l , then L i is determined by: LD i ={ y ^ i MV( y ^ l ,…,
    y ^ l+m−1 ) ifi−l<m, o.w. (14) View Source That is, LD i is locked to the MV of
    the first m decisions from the onset of movement at frame l . The decision is
    locked until an offset is detected, at which point the process is reset until
    the next onset of movement is detected. OL may suppress spurious changes in the
    decision stream due to the locking behaviour, but necessitates a transition to
    NM between subsequent classes. Outlier Detection: Outlier Detection (OD) attempts
    to reject decisions based on the deviation of features in the test data from distributions
    observed during training. Since most classifiers in PR systems are trained as
    multi-class classifiers, they inherently assign one of the known class labels
    to all incoming frames. This can lead the classifiers to incorrectly assign labels
    to outlier data (such as during transitions), leading to errors in the decision
    stream. Outlier detection schemes not only classify the data, but also verify
    that the current frame falls into the expected class distribution of that class
    using a one-class classifier (OCC). Various OCC algorithms have been used to detect
    outliers, including Support Vector Data Description (SVDD) [10], [23], Gaussian
    Mixture Models (GMMs) [24], Hidden Markov Models [25], and Mahalanobis Distance
    (MD) [26]. If g k (.) is an arbitrary OCC for class k that returns −1 if the input
    feature is an outlier, otherwise returns a +1 . The scheme is given by: y i ^
    ={ y ^ i ⨂ if max k ( g k ( X i ))>0, o.w. (15) View Source where ⨂ is the class
    that the decision will be assigned if the feature vector corresponding to the
    frame is an outlier. OD may reject out-of-domain patterns, but requires multiple
    one-class classifiers and may not be resilient to in-domain, but previously unseen
    patterns (such as due to confounding factors). SECTION III. Newly Proposed Dynamic
    Rejection Schemes A major challenge with CBR-based schemes is how to determine
    the optimal rejection threshold ( T h Rej ). Setting a high value for T h Rej
    will increase the rate at which incorrect decisions are rejected, but will also
    lead to an increase in rejecting correct decisions and vice-versa. In this work,
    we attempt to get the best of both worlds by introducing two new rejection schemes
    that vary the rejection threshold dynamically to react to changes in the decision
    stream. Our experience with continuous EMG suggests that most erroneous decisions
    have a locally volatile nature (particularly during transitions) motivating the
    need for a time-varying rejection threshold based on the temporal nature of the
    decision stream. In other words, if the decision stream is highly unstable, it
    might be prudent to set a high rejection threshold. The threshold can then be
    relaxed when the instability drops to avoid over-rejection in steady-state. Consequently,
    we propose the follow two new schemes: Decision-Change Informed Rejection: Decision-Change
    Informed Rejection (DCIR) is designed to react to changes in the decision stream.
    It models the determination of rejection threshold in a manner similar to that
    of the voltage across a capacitor: every time a change in decision is detected
    in the decision stream, (i.e. y ^ i ≠ y ^ i−1 ), the threshold is set to a high
    value to reject all but very confident decisions. Over time, as the decisions
    stabilise to a single class, the threshold decays exponentially to avoid over-rejection.
    In effect, this scheme behaves like a high-pass filter where high frequency changes
    in decisions are penalized heavily. The rejection threshold for frame i , T h
    Rej i is determined by: T h Rej i = Th min +( Th max − Th min )× exp −l τ (16)
    View Source where Th min represents the minimum rejection threshold, Th max represents
    the maximum rejection threshold, τ represents the time constant, and l≥0 represents
    the number of frames since the last decision change. Variance of Confidence Informed
    Rejection: Variance of Confidence-Based Rejection (VoCIR) is designed to react
    to changes in the confidence stream. This scheme simply sets the rejection threshold
    proportionally to the variability in the confidence stream: a large variability
    in the confidence stream corresponds to large uncertainties and/or fluctuations
    in decisions, and therefore the threshold is set to a high value to reject all
    but very confident rejections. The rejection threshold for frame i , T h Rej i
    is determined by: T h Rej i =min( Th max , Th min +β× v i ) (17) View Source where
    Th min represents the minimum rejection threshold, Th max represents the maximum
    rejection threshold, β represents the sensitivity, and v i represents the maximum
    variance of the confidence stream across all the classes in the current and last
    m frames, given by: v i = max k ( σ 2 ( c ik , c (i−1)k ,…, c (i−m)k )) View Source
    where σ 2 (.) returns the variance. SECTION IV. Methods A. Data Acquisition Data
    was collected from forty three able-bodied participants (age: 25.98±5.8 , 26 M,
    17F), recruited mainly from a graduate student population. All participants gave
    informed consent. The study was approved by the University of New Brunswick''s
    Research Ethics Board (REB #2021-116). Surface EMG signals were collected from
    six bipolar electrodes placed around the circumference of the forearm, a third
    of the way down the forearm, proximal to the elbow. The electrodes were affixed
    in an equidistant clockwise fashion starting above the middle of the flexor carpi
    radialis muscles. A Delsys Trigno System [27] was used to record sEMG signals
    which were sampled at 2kHz with a 16-bit Analog-To-Digital converter. Additionally,
    a Leap Motion Controller [28] was used to simultaneously record the position of
    the hand to serve as a ground truth for identifying transition regions. The Leap
    Motion Controller samples position data at a variable rate, up to a maximum of
    120Hz . Both the Leap and EMG signals were recorded with a custom data collection
    program built using Python (version 3.10). The EMG signals were bandpass filtered
    between 20 Hz to 450 Hz using a 4 th order zero-phase filter to remove any low
    or high frequency noise [29], [30]. B. Training and Testing Protocol The data
    collection protocol used in this study was similar to the one used in our previous
    work, with some added elements [13]. Each training record included a set of 6
    ramp contractions starting from a neutral position and ending with a 3s steady
    state contraction in Wrist Flexion (WF), Wrist Extension (WE), Wrist Pronation
    (WP), Wrist Supination (WS), Chuck Grip (CG), or Hand Open (HO). No Movement (NM)
    was also included yielding 7 classes per record. Participants completed 5 trials
    guided by a visual computer prompt. Participants held each contraction for 3 seconds,
    and then returned to a neutral position for 3 seconds before being prompted to
    start the next contraction.After segmenting out the neutral periods, 5 repetitions
    ( 3s long) of each of the 7 classes per participant were used as training data.
    Each test record included a continuous transition from each class to all others,
    generating a total of 7 x 6 = 42 transitions. Participants were guided by a visual
    computer prompt to move randomly from one contraction to another holding each
    in steady-state for 3s . The motion leap position data was used to identify the
    bounds of transition regions based on a velocity calculated from the hand orientation
    vectors. A threshold based on variability in the no movement data was used to
    accommodate random fluctuations. Based on this identification process, 6 steady-state
    segments for each class were identified along with the 42 transitions in each
    record. Participants completed six trials. C. Comparing DSQI Algorithms 1) Classifiers
    The training and test records were segmented into overlapping frames with a length
    of 160ms and an increment of 16ms . The Low-Sampling Frequency 4 (LSF4) feature
    set [7], [31] was extracted from each frame, as this feature set has been shown
    to robust and generalizable. Three classifiers were trained with the ramp training
    data features: a Linear Discriminant Analysis (LDA) classifier, a Support Vector
    Machine (SVM) classifier, and a Long Short-Term Memory (LSTM) classifier. The
    classifiers were chosen to represent generative, discriminative, and deep learning
    models, respectively, and have been shown to perform well in offline EMG PR analysis
    [16], [32], [33]. LDA was implemented as described in [15], SVM was implemented
    using Scikit-Learn (ver 1.1.2) [34], and LSTM was implemented using Keras (ver
    2.10) [35]. The hyperparameters of SVM and LSTM were tuned using a grid-search
    method and data from five randomly chosen participants using 10-fold cross-validation
    using only the ramp training data. Since five participants represent only a small
    subset of dataset, this ensures that hyperparameters were not overtuned to this
    specific dataset. For the SVM, we varied the C and γ values in steps, and for
    the LSTM, we varied the number of units. Based on those pilot results, a single
    value was chosen for each hyper-parameter and used for the remainder of the experiment.
    For the SVM, the chosen hyperparameters were: C=100 , RBF Kernel with γ=0.01 ;
    and for the LSTM network, the architecture is shown in Fig. 2. The Adam optimizer
    was used with a learning rate of 2× 10 −4 , the batch size was set to 64, and
    the network was trained for 100 epochs with early stopping to prevent over-fitting.
    Fig. 2. LSTM Network architecture. The number of units and the activation functions
    are shown in parentheses, as applicable. Show All 2) DSQI Hyperparameters The
    following hyperparameters were set for the DSQI algorithms: MV: We used m=8 past
    values based on empirical testing. pLDA: We set P max =0.97 and b=0.5 based on
    the results of a grid search method. CBR: The rejection threshold for LDA was
    set to T h Rej =0.97 based on [9]. For SVM, it was set to T h Rej =0.6 based on
    [16], and for LSTM, it was set to T h Rej =0.6 based on a grid search. CS: We
    set the scaling factor for NM class to be 0.97, and all the others to be 0.05,
    based on the original study. BF: We used m=8 past values, as with MV. AW: We varied
    the frame length from the default of 160ms to 256ms in increments of 16ms . The
    rejection threshold for LDA was set to T h AW =0.97 based on [9], and to T h AW
    =0.6 for SVM based on [16] AW was not used with the LSTM as it is was unclear
    how it could be implemented with a temporal classifier. OL: We set m=6 , as in
    the original study. OD: We used the SVDD to reject outlier frames to the NM class
    ( k NM ). DCIR: We set Th min =0.4 , Th max =0.989 , and τ=30 . These were tuned
    to provide comparable steady-state rejection to CBR. VoCIR: We used m=8 past values,
    similar to MV. We set Th min =0.4 , Th max =0.989 , and β=4.0 . Similar to DCIR,
    these were tuned to provide comparable steady-state rejection to CBR. 3) Assessing
    Performance We evaluated the 30 scheme-classifier combinations using 3 steady-state
    region metrics - Active Error Rate (AER), Total Error Rate (TER), and Instability
    (INS) along with 6 transition region metrics - Offset Delay ( T OFFSET ), Onset
    Delay ( T ONSET ), Transition Duration ( T TRANSITION ), Instability (INS), Tertiary
    Class Error (TCE), and Percent No Movement (PNM), as described in our previous
    work [13]. To calculate the transition metrics, it was necessary to identify when
    each classifier moved in and out of steady-states. This was done for each steady-state
    segment by comparing the known state class (based on the prompt) with the classifier
    decision stream in the region of a transition bound (as identified with the leap
    data). The first decision beyond a transition entry bound that did not correspond
    to the known state was considered to be associated with steady-state offset. Likewise,
    the first decision beyond a transition exit bound that did correspond to the known
    state was considered to be associated with steady-state onset. Majority vote was
    used across 9 frames in both cases to handle blips in the decision stream. For
    each participant, the various metrics were first averaged across steady-states
    and across transitions within a continuous test trial, then across the six test
    trials. The results were analysed for significant differences using a One-Way
    Analysis of Variance (ANOVA). When significant differences were indicated, we
    performed a paired t-test (with Holm correction) to identify the groups that differ
    from each other. For all cases, α=0.05 was used to denote significance. The statistical
    analysis was done using the statsmodels (ver 0.13.2) [36] and scikit-posthocs
    (ver 0.7.0) [37] Python packages, and the visualisation was done using the matplotlib
    (ver 3.6.1) [38], Pandas [39], and Seaborn (ver 0.12.0) [40] Python packages.
    SECTION V. Results Our goal was to compare different DSQI schemes in conjunction
    with different types of classifiers in the context of transitions as well as steady-states
    and to highlight the trade-offs made by the schemes. A visual depiction of the
    confidence streams obtained from the three classifiers for an example set of transitions
    is shown in Fig. 3. The plots show colour-coded confidence streams, where the
    color of each decision point denotes the classifier-assigned label, and the ground
    truth labels derived from the Leap sensor as color-shaded regions. The plots exemplify
    the typical confidence distribution and decision stream characteristics observed
    across the three classifiers. A further comparison of the effects of each of the
    post-processing scheme is shown in the subplots 1 to 11 in Fig. 4. Fig. 3. Decision
    stream comparison of the three classifiers (LDA, SVM, and LSTM) without any post-processing
    scheme. The 5 seconds shown include two transition zones representative of typical
    behaviour. Colours of the data points represent the classifiers decision (as indicated
    in the legend), and values represent confidence; shaded regions denote the ground
    truth class (based on the Leap data). Show All Fig. 4. Comparison of the different
    post-processing schemes with an LDA decision stream. The 5 seconds shown include
    two transition zones representative of typical behaviour for LDA. Colours of the
    data points represent the classifiers decision (as indicated in the legend), and
    values represent confidence; shaded regions denote the ground truth class (based
    on the Leap data); and black circles denote frames that are rejected by the post-processing
    scheme. (1): No Post-processing, (2): MV, (3): PLDA, (4): CBR, (5): CS, (6): BF,
    (7): AW, (8): OD, (9): OL, (10): DCIR, (11): VoCIR. Show All Figs. 5 and 6 depict
    box plots of the observed steady-state and transition metrics, respectively, for
    the various the DSQI schemes tested. Fig. 5. Box-plots of steady-state metrics
    across all classifiers and schemes. Show All Fig. 6. Box-plots of transition metrics
    across all classifiers and schemes. Show All Results of the ANOVA test suggest
    a statistically significant difference across the schemes for all steady-state
    and transition metrics. Post-hoc tests reveal that without any post-processing,
    LDA, SVM, and LSTM do not exhibit statistically different steady-state AER and
    TER. However, all three classifiers were statistically different from each other
    when considering INS, with the LSTM exhibiting substantially smaller INS than
    LDA or SVM ( p<0.0001 ). The LDA had the second best steady-state INS performance
    followed by the SVM, which had the worst INS performance across all cases. The
    rejection schemes tended to trade a reduction in AER for an increase in TER, as
    seen in previous works [16], [20], and explained in [41]. Though Post-hoc analysis
    indicates that OD had the best AER, it also revealed that the OD and OL schemes
    exhibit substantially poorer performance in TER; both schemes saw a >40% increase
    in TER, a seemingly unfavourable trade-off. As a result, for the rest of the analysis,
    OD and OL are excluded from the analysis. For the remaining schemes, LDA tended
    to yield lower average AER than SVM and LSTM, although no statistically significant
    differences were noted. All of the rejection schemes reduced steady-state INS.
    However, when applied with LDA and SVM, the MV and BF schemes could do no better
    than the baseline LSTM ( p>0.9 for LDA, and p>0.3 for SVM). Moreover, the addition
    of MV or BF to the LSTM reduced the steady-state INS further, making it significantly
    better than the baseline LSTM ( p<0.0005 ), and thus, outperforming both LDA and
    SVM with those schemes. Nevertheless, the newly proposed DCIR with LSTM was found
    to be the best combination in terms of steady-state INS, and was revealed to be
    statistically different than all other schemes ( p<0.001 ) except for CS with
    LSTM. The transition metrics indicate that without any post-processing, LDA and
    SVM had similar transition delay characteristics for T OFFSET , T ONSET , and
    T TRANSITION , indicating that these two classifiers take similar amount of time
    to transition between any two classes ( p>0.9 , p>0.1 , and p>0.9 respectively).
    However, the LSTM had statistically slower responsiveness and transition time
    than LDA and SVM ( p<0.005 ), indicated by its larger T OFFSET , T ONSET , and
    T TRANSITION values. The LSTM also tended to have the lowest transition INS among
    the classifiers, exhibiting similar trends to the steady-state metrics. Generally,
    most DSQI schemes had similar impact on the delay metrics, however, the largest
    increase in delay was seen in CS with the LSTM, suggesting that this combination
    may yield potential over-rejection. Only rejection-based schemes appear to have
    impacted TCE and PNM, which may be expected as they are able to suppress uncertain
    decisions. The best classifier-scheme combination was the new LSTM with DCIR,
    which produced significantly lower TCE than all of schemes except CS with LSTM
    ( p<0.0001 ). SECTION VI. Discussions In this work, we explored the performance
    trade-offs of 8 previously established post-processing algorithms and 2 novel
    approaches on EMG-based pattern recognition decision stream quality. We used our
    recently proposed framework to show how these algorithms perform during steady-state
    as well as in the context of transitions, which are substantially more challenging
    and contribute disproportionately to overall classifier error. In general, we
    observed that the newly proposed decision-change informed rejection (DCIR) approach,
    which dynamically adjusts rejection thresholds based on decision stream volatility,
    is a promising algorithm that reduced transition errors and INS metrics. It performed
    substantially better than confidence-based rejection (CBR) during transitions
    with comparable steady-state TER, indicating that the addition of temporal information
    into conventional rejection systems is beneficial. With this added context, however,
    the new schemes trade off these performance gains with a slight decrease in responsiveness
    of the classifiers. Nevertheless, this trade-off is still an improvement over
    approaches like majority vote (MV), which also decreases responsiveness with no
    improvements in TCE. Based on the increase in steady-state TER, the onset locking
    (OL) and outlier detection (OD) schemes were the worst performers in combination
    with any classifier. Both of these schemes make assumptions that only work with
    well-behaved data, which may explain the results under our more challenging test
    conditions. OL assumes that all movements are followed by a period of rest (i.e.,
    NM class) [22]. This may be reasonable in very specific circumstances, such as
    gesture recognition, but is generally not true in myoelectric applications. The
    researchers in [22] acknowledged that their scheme may break down under dynamic
    conditions, and we were indeed able to demonstrate this in our test conditions.
    In our test dataset, the participants transitioned from one class to another without
    necessarily resting in between, which led to the OL scheme locking onto a class
    but not unlocking after a transition. This phenomenon can be observed in the decision
    stream plot for OL in Fig. 4, (9). This results in the substantial increase in
    TER, which can be seen in the box plots in Fig. 5. Similarly, the OD schemes assume
    that the distribution of test data are perfectly consistent with those observed
    in training conditions. Though the scheme may reject frames from contractions
    that are not part of the training set [23], it may also incorrectly reject frames
    from contractions that are part of the training set due to factors such as co-variate
    shift. Even the ramp data used to train the classifiers is more well-behaved than
    the data seen in the continuous test dataset, resulting in the scheme over-rejecting
    a substantial amount of test data as ‘outliers’. The confidence scaling (CS) scheme
    was promising in conjunction with the LSTM, though in this case, it appears that
    the scaling was overly aggressive. The weights across the different classifiers
    were set based on reported work [9], but our results suggest that these could
    be tweaked further in the case of the LSTM and SVM to possibly achieve a better
    trade-off between different metrics. Further exploration for optimization is warranted,
    but caution should be taken to avoid over-tuning parameters for any one dataset.
    The adaptive windowing (AW) scheme appears to provide very limited gains in performance
    while also being one of the more computationally demanding algorithms. AW requires
    that the classifiers be trained with features extracted from all possible frame
    lengths [21], which leads to a substantial increase in processing time. In addition,
    it is unclear how the temporal schemes such as the LSTM should be trained for
    this scheme, as the temporal dynamics change with frame length, which does not
    affect the LDA or SVM, but significantly affects the LSTM. The original work compared
    AW with MV and Bayesian fusion (BF) schemes, but not rejection-based schemes.
    We found AW to be arguably better than MV and BF, in agreement with the original
    study, but CBR, DCIR, and VoCIR all provide comparable or better performance across
    the metrics while being significantly less computationally demanding. The LSTM
    classifier had the least baseline instability, though it also took slightly longer
    to transition to a new class. LSTM is a temporal classifier and takes into account
    the past frames along with the current frame when making a decision. Therefore,
    it has additional context, and is able to suppress blips in the decision stream.
    However, the training data used to train classifiers in myoelectric control is
    well-behaved and does not contain dynamics associated with transitions, and therefore,
    the LSTM struggles to understand when it should be transitioning into (or out
    of) a class. Our empirical testing suggests that training an LSTM with data containing
    transitions may allow the LSTM to learn these dynamics and transition faster;
    however the user burden associated with collecting all such transitions for training
    may be prohibitive. The rejection schemes were overall better than MV and BF smoothing
    schemes. They not only reduced TCE (by increasing PNM), but also slightly improved
    INS. In contrast, MV and BF only served to reduce INS (in line with previous results
    [19]), without tangibly affecting other metrics. DCIR was found to be the most
    promising in this regard, as it significantly increases PNM (and consequently
    reduces TCE) without also correspondingly increasing steady-state TER. Although
    LDA was the most promising baseline classifier, in line with findings from our
    previous study [13], it does not benefit as much from the rejection schemes, particularly
    DCIR and VoCIR, as compared to the LSTM and SVM. This can be attributed to the
    significant overlap in confidence value distributions of the LDA corresponding
    to the different types of decisions (correct, incorrect, and transitions). In
    other words, the LDA is often too confident, even with the wrong decisions. This
    leads to the undesirable situation where it is not possible to reject the wrong
    decisions without also rejecting many correct decisions. However, in the case
    of LSTM and SVM, the confidence values of the different types of decisions have
    a smaller overlap, allowing the rejection schemes to make much better use of the
    temporal characteristics of the confidence streams. With DCIR, both the LSTM and
    SVM saw a >40% increase in PNM, resulting in a much lower TCE, and consequently,
    a reduction in unwanted motions during transitions. It is currently unclear how
    these techniques may interact with other approaches to myoelectric control, such
    as regression [42]. Regression is promising as it may enable the simultaneous
    independent control of multiple degrees of freedom; however, it requires a more
    controlled training protocol than classification and suffers from many similar
    challenges as classification based approaches (e.g. inadvertent activation of
    tertiary classes during transitions). Consequently, more work is required to fully
    understand how DSQI approaches such as DCIR may be adapted to benefit regression
    control. SECTION VII. Conclusion Existing work [16] indicates that errors during
    transitions greatly degrade usability, which supports the inclusion of transition
    metrics as part of offline classification comparison studies. Evaluating classifier
    schemes with continuous test data enables transition metrics to be considered
    along with steady state ones and using this approach, we demonstrated that the
    LSTM-DCIR combination is a strong offline performer. Nevertheless, it is not yet
    clear how to weight the importance of each of the metrics from a usability perspective
    and our results clearly indicate that trade-offs are necessary; for instance,
    the LSTM-DCIR trades reduced responsiveness for improved tertiary errors counts.
    Studies have reported that prosthesis users have noted inadvertent or unwanted
    activation as being destructive to their sense of agency [43], and that users
    prefer over-rejection over responsiveness [20]. These findings suggest that TCE
    may be an important metric, but further research is warranted to explore the relationship
    between offline steady-state and transition metrics and online performance directly,
    through a usability study. Authors Figures References Citations Keywords Metrics
    Footnotes More Like This Surface electromyography (sEMG) feature extraction based
    on Daubechies wavelets 2013 IEEE 8th Conference on Industrial Electronics and
    Applications (ICIEA) Published: 2013 Feature extraction of surface electromyography
    (sEMG) and signal processing technique in wavelet transform: A review 2016 IEEE
    International Conference on Automatic Control and Intelligent Systems (I2CACIS)
    Published: 2016 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase
    Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS
    PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA:
    +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE
    Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved."'
  inline_citation: '>'
  journal: IEEE Journal of Biomedical and Health Informatics
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Decision-Change Informed Rejection Improves Robustness in Pattern Recognition-Based
    Myoelectric Control
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Fernandes M.R.
  - Magalhaes G.M.
  - Zuniga Y.R.C.
  - Do Val J.B.R.
  citation_count: '0'
  description: This article adopts a matrix Lie group dynamic model aggregating in
    a single element position, velocity, attitude, and inertial measurement unit (IMU)
    biases. Relying on Kalman filtering on Lie groups, it develops an extended Kalman
    filter inbuilt into a smoother for loosely coupled integration of global navigation
    satellite-based system/inertial navigation system (GNSS/INS), tailored for postprocessing
    applications. The design is motivated by a drone-borne differential interferometric
    SAR (DinSAR) application requiring high-precision navigation information for short-flight
    missions using low-cost microelectromechanical systems (MEMS) sensors. The filter
    and the Rauch-Tung-Striebel (RTS) smoother are both implemented and validated.
    To cope with heading alignment, the article presents a Bayesian algorithm to initialize
    the heading value since magnetometers are useless and the INS gyroscopes lack
    gyro-compassing precision. Also, a statistical test addresses the practical issue
    of outlier rejection for GNSS detrimental data. This article uses synthetic data
    for comparison with classic navigation schemes based on multiplicative quaternions
    and Euler angles. A DinSAR imagery reconstitution field test shows better performance
    than state-of-the-art commercial software.
  doi: 10.1109/TAES.2023.3290575
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Journals & Magazines >IEEE Transactions on Aerospac...
    >Volume: 59 Issue: 6 GNSS/MEMS-INS Integration for Drone Navigation Using EKF
    on Lie Groups Publisher: IEEE Cite This PDF Marcos R. Fernandes; Giorgio M. Magalhães;
    Yusef Rafael Cáceres Zúñiga; João B. R. do Val All Authors 447 Full Text Views
    Abstract Document Sections I. Introduction II. Filtering and Smoothing on Lie
    Groups III. Inertial Navigation System IV. Integration GNSS/INS V. Data Experiments
    Show Full Outline Authors Figures References Keywords Metrics Footnotes Abstract:
    This article adopts a matrix Lie group dynamic model aggregating in a single element
    position, velocity, attitude, and inertial measurement unit (IMU) biases. Relying
    on Kalman filtering on Lie groups, it develops an extended Kalman filter inbuilt
    into a smoother for loosely coupled integration of global navigation satellite-based
    system/inertial navigation system (GNSS/INS), tailored for postprocessing applications.
    The design is motivated by a drone-borne differential interferometric SAR (DinSAR)
    application requiring high-precision navigation information for short-flight missions
    using low-cost microelectromechanical systems (MEMS) sensors. The filter and the
    Rauch-Tung-Striebel (RTS) smoother are both implemented and validated. To cope
    with heading alignment, the article presents a Bayesian algorithm to initialize
    the heading value since magnetometers are useless and the INS gyroscopes lack
    gyro-compassing precision. Also, a statistical test addresses the practical issue
    of outlier rejection for GNSS detrimental data. This article uses synthetic data
    for comparison with classic navigation schemes based on multiplicative quaternions
    and Euler angles. A DinSAR imagery reconstitution field test shows better performance
    than state-of-the-art commercial software. Published in: IEEE Transactions on
    Aerospace and Electronic Systems ( Volume: 59, Issue: 6, December 2023) Page(s):
    7395 - 7408 Date of Publication: 29 June 2023 ISSN Information: DOI: 10.1109/TAES.2023.3290575
    Publisher: IEEE Funding Agency: SECTION I. Introduction Motivated by the navigation
    information requirements in the differential interferometric SAR (DinSAR) [1],
    3-D mapping [2], and applications requiring high-fidelity position and attitude
    information [3], this article brings the following main contributions. 1) Employ
    a Lie group especially tailored for integrating global navigation satellite-based
    system/inertial navigation system (GNSS/INS) in 3-D navigation, including bias
    estimation in a Kalman-like smoothing procedure appropriate to Lie groups. 2)
    Take advantage of the Lie group and the corresponding Lie algebra interplay, allowing
    an additive noise model evolving in the algebra to translate into a noisy behavior
    appropriate to rigid bodies. This understanding indicates that Lie-based models
    embedded into extended Kalman filters (EKF) are bound to accommodate the nonlinearities
    well and perform better than standard Euler angles or quaternion models [4]. Comparison
    experiments verify this assertion. 3) Benefit from the postprocessed scenario
    using the EKF-Lie filter inbuilt into a Rauch-Tung-Striebel (RTS) smoother on
    Lie groups for improved accuracy (see Lemma II.2). The smoother comes from stochastic
    principles, and the deterministic approach via observers [5] does not allow a
    smoother synthesis, as far as the authors are aware. 4) Due to poor heading estimation
    accuracy, propose a Bayesian calibration procedure tailored to the postprocessing
    scenario. Heading alignment is recognizably difficult in attitude estimation,
    e.g., see [5] and [6]. The drone carries a single inertial measurement unit (IMU)
    lacking gyro-compassing precision and a single GNSS antenna with a known lever
    arm. No magnetometer is attached due to the radars and drone motor magnetic field
    interferences. 5) Create synthetic data from actual flights to benchmark and present
    field tests of a radar bourne terrain imagery application (DinSAR). The application
    requires highly accurate flight path reconstruction (position and attitude) to
    render sufficiently well-marked terrain imagery. 6) Quality comparison with industry-standard
    software favorable to the devised scheme. It indicates the applicability of the
    Lie-based method developed here, which includes an outlier rejection method for
    GNSS measurements. These stages complete a full engineering design cycle. It is
    known that a strap-down inertial navigation system (INS) based on microelectromechanical
    systems (MEMS) technology provides position, velocity, and attitude (PVA) information
    from accelerometers and gyroscopes at high rates but with unqualified errors after
    a period of discrete-time integration. These low-cost off-the-shelf sensors are
    inevitably affected by biases and white noise [7], thus, requiring adequate noise
    modeling. On the other hand, a GNSS can provide position and velocity with strict
    error bounds but at a lower frequency. Differential GNSS attains high precision,
    achieving centimeter-level precision using code and phase measurements [8]. A
    GNSS/INS integrated navigation system combines each sensor''s strengths for better
    PVA estimates. Possible GNSS/INS integration types have appeared [9], and we adopt
    the loosely coupled (LC) structure for simplicity. The LC scheme combines the
    position-ready estimate provided by the GNSS with the IMU measurements. Kalman
    like filters have been investigated for GNSS/ INS integration algorithms, e.g.,
    see [10], [11], and [12]. To achieve high-order approximations, unscented or particle
    filters offer alternatives to the EKF. They might provide better estimation but
    require more computational resources; for this reason, the EKF remains the most
    common GNSS/INS integration technique, the reference filter within the aerospace
    industry, cf., [13]. Several parameterizations apply to represent the attitude
    of a vehicle, such as Euler angles, quaternions, rotation vectors, and rotation
    matrices, cf., [9]. The challenge in choosing an adequate representation of attitude
    is that some have singularities or added constraints; see [4] for a thorough discussion.
    The kinematic equations for Euler angles involve trigonometric functions, which
    make the model highly nonlinear, cf., [14]. Quaternions are appealing for attitude
    representation, cf., [15]. However, they must satisfy a normalization constraint
    to represent rotations, which is disregarded by the measurement update step of
    the EKF, cf., [16]. To circumvent such constraint [14], [17] use a multiplicative
    form of quaternion update. Nevertheless, most of these techniques consider models
    on Euclidean space and Gaussian distributed driving noise. More recently, the
    Lie group theory-based framework has attracted much attention from sensor fusion
    communities for rigid-body-related data fusion. In robotics, [18] acknowledges
    that the unknown position of a differential-drive robot distribution displays
    a banana-shaped distribution, which can be produced with the aid of the exponential
    map of the SE(2) Lie group. A discrete EKF on Lie groups (D-LIE-EKF) appears in
    [19] and [20], generalizing the usual Kalman Filter framework when the system
    dynamic or measurement model can be cast as a Lie group element. Within D-LIE-EKF,
    the noise is Gaussian distributed, but acting in the Lie algebra, which induces
    a concentrated Gaussian distributed in the Lie group, cf., [21]. In this work,
    we exploit the generalization of EKF on Lie groups to implement an LC Integration
    of GNSS/MEMS-INS. The double direct isometries Lie group SE 2 (3) (see [22]) is
    adopted to embed the attitude, velocity, and position states, combined with the
    translation group T(6) to accommodate the accelerometer and gyroscope biases.
    Besides, the proposed filter is inbuilt into RTS smoothing on Lie groups, see
    Lemma II.2 or [23], to benefit from the postprocessing approach to the referred
    applications. The RTS gathers all information available to leverage state estimates
    at each time step, attaining higher precision and accuracy requirements than the
    plain filter result. In the context of navigation, Lie groups have been applied
    to industrial unmanned aerial vehicle (UAV) systems [13], real-time UAV helicopter
    navigation [24], and also land vehicle navigation [25]. However, none of these
    previous studies aimed at developing a complete navigation system to meet the
    accuracy requirements such as the DinSAR''s. Most current works focus on land
    vehicle navigation and filtering solutions only. A concurrent approach for PVA
    estimation is based on observers from a vein of nonlinear system theory [26],
    with extra efforts to deal with inherent disturbances [5]. Although the synthesis
    of observers often comes with a corresponding convergence analysis, the ongoing
    assumptions are sometimes hard to verify. The quest for stability also appears
    in the Lie-based filter synthesis, e.g., see [27], [28]. In the course of using
    the EKF-Lie filter inbuilt into an RTS smoother, the stability was never an issue,
    except when low-quality GNSS data were fed into the GNSS/INS scheme. We propose
    an outlier rejection statistical method based on the Mahalanobis distance and
    a χ 2 -test with good results (see Section IV-C). In addition to the above-mentioned
    choices, a good alignment process is indispensable to achieving centimeter-level
    precision. It is well known that the heading alignment hinders low-cost GNSS/INS
    integration systems. Solutions based on fuzzy [6] or wavelet neural networks [29]
    are available for long-term applications. Magnetometers are unavailable, the drone
    flights are short-duration, and corrections along the flight are not needed when
    the initial alignment is good. Also, because of the postprocessing nature of the
    applications in focus, one can benefit from a highly accurate flight estimation
    via the smoothing procedure, a better solution than just filtering. A Bayesian
    method to optimize heading alignment in such a scenario is developed in Section
    IV-E. The strategy inbuilt into the D-LIE-EKF to deal with inherent nonlinearities
    relies on the interplay between matrix groups and the associated algebra. It is
    a powerful form of reducing the effect of nonlinearities to a minimum. It is better
    tailored to deal with non-Euclidean noise models for rigid bodies than other approximate
    filtering methods in the literature. Together with the statistical method devoted
    to the head alignment problem, they provide a way to develop optimal estimates
    given the adopted distributions. Deterministic nonlinear observers cannot mirror
    this scenario. Using synthetic data from actual flights, we show that the proposed
    filter and smoother outperform conventional quaternion and Euler angles-based
    approaches. In a second comparison, we use a real dataset to show that the Lie
    group-based filtering inbuilt into the RTS smoothing yields better performances
    for DinSAR imagery processing than the state-of-the-art commercial software Inertial
    Explorer. The rest of this article is organized as follows. Section II-A briefly
    introduces the mathematical concepts for understanding the Kalman filter algorithm
    on Lie groups. Section II describes the modeling of dynamic systems and random
    variables on Lie groups, followed by the description of filtering and smoothing
    methods. Section III develops the navigation and sensors model, and Section IV
    describes the integration scheme. After that, experimental evaluations using both
    simulated and real data appear in Section V. Finally, Section VI concludes this
    article. The following notation is adopted: x γ βα for a vector x represents the
    coordinates of some kinematic property (position, velocity, etc.) of frame α w.r.t.
    frame β , expressed in the frame γ . The navigation frame is the North-East-Down
    (NED) local-level frame, abbreviated by the index n ; the body frame is indicated
    by b , the inertial frame by i , whereas the earth centered earth fixed (ECEF)
    frame is indexed by e . SECTION II. Filtering and Smoothing on Lie Groups A. Elements
    of Lie Group Theory A brief introduction to Lie theory, main concepts, notation,
    and equations are handy for further understanding. A Lie group is a mathematical
    structure that combines the concept of a differentiable manifold with the concept
    of a group. For rigid-body applications, the analysis relies on a subgroup of
    the general linear group GL(n,R) , also called matrix Lie groups [30]. The GL(n,R)
    is the group formed with all invertible n×n matrices of real numbers with group
    operation given by the matrix product. In this article, we also restrict our consideration
    to connected and unimodular Lie groups, as it is required for the way the uncertainty
    on Lie groups is modeled. An important structure in the Lie group theory is the
    Lie algebra, a vector space equipped with a bracket product [[⋅,⋅]] called the
    Lie bracket. It is always possible to find a Lie algebra associated with a Lie
    group [30]. For matrix Lie groups, in particular, the associated Lie algebra is
    the vector space of matrices with Lie bracket given by the commutator [[X,Y]]=XY−YX
    . The importance of the Lie algebra lies in that most of the Lie group''s properties
    come from the Lie algebra. The exponential map exp G :g→G , which for a matrix
    Lie group reduces to the usual matrix exponential function, provides a connection
    between elements of the Lie algebra and elements of the Lie group. In general,
    the exponential map is not bijective; however, it is possible to show that there
    exist open neighborhoods of the identity element on the Lie group and of the zero
    element on the Lie algebra, for which the exponential map is a diffeomorphism.1
    In these open sets, one defines the logarithm map log G :G→g as the inverse of
    the exponential map. Since the Lie algebra is a vector space, it is possible to
    represent any element as a linear combination of its basis. Therefore, instead
    of manipulating the elements X as matrices for computing purposes, one can deal
    with the coefficients associated with its basis. With that in mind, the following
    isomorphisms are defined: [⋅ ] ∨ G :g X → R p ↦[X ] ∨ G [⋅ ] ∧ G : R p x →g ↦[x
    ] ∧ G . (1) View Source For brevity, the following notations are used hereafter:
    exp ∧ G (x):= exp G ([x ] ∧ G ), log ∨ G (g):=[ log G (g) ] ∨ G (2) View Source
    where x∈ R p , g∈G and when we write g= exp ∧ G (x) we assume that log ∨ G (g)=x
    , i.e., we work only on the subsets where exp G (⋅) and log G (⋅) are bijective.
    Note that the exponential map can be interpreted as a parameterization for the
    Lie group in local coordinates around the identity element. This parameterization
    can be extended to the neighborhood of any element μ∈G in a connected Lie group
    using left translation as follows, L μ (ϵ):=μ exp ∧ G (ϵ),∀ϵ∈ R p . The left translation
    action is illustrated in Fig. 1. Fig. 1. Left translation. Show All Since the
    exponential map is locally a diffeomorphism, there exist open neighborhoods of
    μ∈G and 0∈ R p for which this parameterization is one-to-one. A Lie group, in
    general, is not a commutative structure, which can complicate the algebraic manipulations.
    However, a concept overcomes this issue: the adjoint representation. There are
    two adjoint representations. The first one represents the Lie group on its Lie
    algebra, i.e., the linear map that takes an element of the Lie group to a linear
    transformation in the Lie algebra. The adjoint representation can be defined as
    [31] Ad G (g)y= [g[y ] ∧ G g −1 ] ∨ G (3) View Source where g∈G , y∈ R p . Note
    that Ad G (g)∈ R p×p is a linear transformation that can be applied to any vector
    y∈ R p . The second adjoint representation is the representation of the Lie algebra
    on itself so that each element of the Lie algebra defines a linear transformation
    in the Lie algebra. This adjoint representation is defined by the Lie bracket
    [31] in the form [ ad G (x)y ] ∧ G :=[[[x ] ∧ G ,[y ] ∧ G ]] where x,y∈ R p .
    Since the Lie bracket for matrix Lie groups is the commutator operator, we write
    ad G (x)y=[[x ] ∧ G [y ] ∧ G −[y ] ∧ G [x ] ∧ G ] ∨ G . (4) View Source Furthermore,
    in many applications of the Lie group, particularly in filtering and smoothing,
    one is interested in analyzing the behavior of a Lie group element g∈G as a function
    of time, and, naturally, its time derivative, g ˙ (t) . From the theory of differential
    manifolds, g ˙ (t) is a vector in the vector space tangent to G at the element
    g(t) , i.e., g ˙ (t)∈ T g(t) G . As stated before, working in Lie algebra is a
    common approach to dealing with Lie groups. It turns out that the tangent space
    at an arbitrary element of the Lie group is isomorphic to the tangent space at
    identity by performing a left translation so that g −1 g ˙ ∈g . The right-Jacobian
    matrix, following [31], is given as: J r (x)= ∑ k=0 ∞ (−1 ) k (k+1)! ad G (x )
    k . (5) View Source Let us consider a local parameterization in the form g=μ exp
    ∧ G (x) . The relation of the time variation of g to the time variation of the
    local coordinates x , represented in the Lie algebra, is given by g −1 g ˙ =[
    J r (x) x ˙ ] ∧ G . Notice that the matrix J r (x) is responsible for relating
    local coordinates variations to Lie group element variations. B. Random Variables
    on Lie Group First, recall that for a random variable (r.v.) x on the Euclidean
    space with mean μ∈ R n and covariance P= P ⊺ ≻0 associated with a pdf p(x) , one
    has 0 n×1 = P= ∫ R n (x−μ)p(x)dx ∫ R n (x−μ)(x−μ ) ⊺ p(x)dx (6a) (6b) View Source
    where the integration is w.r.t. the Lebesgue measure. This definition can be naturally
    extended to Lie groups as follows. Given a matrix Lie group G , a random matrix
    X∈G with pdf p(X) has mean μ∈G and covariance P= P ⊺ ≻0 defined by 0 n×n = P=
    ∫ G log ∨ G ( μ −1 X)p(X)dX ∫ G log ∨ G ( μ −1 X) log ∨ G ( μ −1 X ) ⊺ p(X)dX
    (7) (8) View Source where the integration is w.r.t. the Haar measure [31]. From
    this standpoint, the concept of concentrated Gaussian distribution (CGD) [23]
    is used to define a probability density tailored to matrix Lie groups. The group
    defines the mean, and the covariance is in the Lie algebra. Accordingly, a Gaussian
    random variable on a matrix Lie group is expressed as follows: X=μ exp ∧ G (ϵ)
    (9) View Source and the pdf of X takes the form p(X):=αexp(− 1 2 ∥ log ∨ G ( μ
    −1 X) ∥ 2 P −1 ) (10) View Source where α∈R is a normalizing factor to ensure
    ∫p(X)dX=1 . From (9), ϵ= log ∨ G ( μ −1 X) and assuming that P has small eigenvalues
    then p( exp ∧ G (ϵ)) concentrates around the group identity. With those working
    assumptions, the distribution of ϵ in the Lie algebra becomes the classical Gaussian
    distribution, i.e., ϵ∼N(0,P) . The distribution of X is called a CGD on G , denoted
    by X∼ N G (μ,P) . An illustration of the relationship between the neighborhood
    of the identity element with the Lie Algebra is depicted in Fig. 2 together with
    the tangent space and its respective Gaussian distribution. Fig. 2. Concentrated
    Gaussian distribution in the neighborhood of the identity element. Notice the
    curved shape of the distribution on the Lie group. Show All C. Dynamic System
    Once an r.v. is defined on a Lie group, a stochastic dynamic system can be modeled
    such that its states are embedded on a matrix Lie group G . Let X∈G be the system
    state. Let the stochastic differential equation be expressed by dX=X[Ω(X,u)dt+dW
    ] ∧ G (11) View Source where Ω:G× R m → R p is the left velocity function and
    W is a multidimensional Wiener process with covariance Q c , i.e. W( t 2 )−W(
    t 1 )∼N(0,( t 2 − t 1 ) Q c ) with t 1 < t 2 . Also, consider that measurements
    are available in discrete time instants in the form y k+1 =h( X k )+ ν k (12)
    View Source where y k ∈ R m is the measurement vector, h:G→ R m is the measurement
    function, and ν k ∼ iid N(0, R k ) is the measurement noise. For small sample
    time Δt , the discrete form of the dynamic system (11) can be approximated as
    X k+1 = X k exp ∧ G (Ω( X k , u k )Δt+ w k ) (13) View Source where w k ∼ iid
    N(0, Q k ) and Q k = Q c Δt . D. Kalman Filter on Lie Groups With the definition
    of r.v.s and stochastic dynamic systems on Lie groups, one can employ the Kalman
    filtering framework to generate state estimates of a dynamic system state evolving
    on a Lie group. For convenience, denote Ω ^ k :=Ω( X ^ k , u k )Δt . The D-EKF
    on a Lie group [19], [20] is presented next. Lemma II.1 (D-LIE-EKF): The following
    equations constitute the D-EKF on a Lie group: X ^ k+1|k = P k+1|k = K= X ^ k+1|k+1
    = P k+1|k+1 = X ^ k|k exp ∧ G ( Ω ^ k ) F P k|k F ⊺ + J r ( Ω ^ k ) Q k J r (
    Ω ^ k ) ⊺ P k+1|k H ⊺ ( R k+1 +H P k+1|k H ⊺ ) −1 X ^ k+1|k exp ∧ G (K( y k+1
    −h( X ^ k+1|k ))) (I−KH) P k+1|k (∙ ) ⊺ +K R k+1 K ⊺ (14a) (14b) (14c) (14d) (14e)
    View Source where F:= C k := H:= Ad G ( exp ∧ G (− Ω ^ k ))+ J r ( Ω ^ k ) C k
    ∂ ∂ϵ [Ω( X ^ k|k exp ∧ G (ϵ))] ∣ ∣ ϵ=0 ∂ ∂ϵ [h( X ^ k+1|k exp ∧ G (ϵ))] ∣ ∣ ϵ=0
    . (14f) (14g) (14h) View Source Proof: See Appendix A. □  E. Smoothing on Lie
    Groups This section presents the RTS smoother on Lie groups with the D-LIE-EKF
    inbuilt, as proposed in [23]. Unlike a Kalman recursive filter, the smoother uses
    all available measurements to compute the state estimates using a forward pass,
    given by the D-LIE-EKF, followed by a backward pass [32]. Thus, the RTS applies
    offline in a postprocessing amelioration. Lemma II.2 (D-LIE-RTS): Given the filter
    solution { X ^ k|k , P k|k } 1:T , the Rauch–Tung–Striebel recursion on Lie groups
    for k=T−1,…,1 are X ^ k+1|k = P k+1|k = G k = X ^ s k = P s k = X ^ k|k exp ∧
    G ( Ω ^ k ) F P k|k F ⊺ + J r ( Ω ^ k ) Q k J r ( Ω ^ k ) ⊺ P k|k F ⊺ P −1 k+1|k
    , X ^ k|k exp ∧ G ( G k log ∨ G ( X ^ −1 k+1|k X ^ s k+1 )) P k|k + G k ( P s
    k+1 − P k+1|k ) G ⊺ k . (15a) (15b) (15c) (15d) (15e) View Source Proof: See Appendix
    B. □  Remark The D-LIE-EKF presented is in close correspondence with the version
    presented in [19], [20], and [23]. However, we adopt the Joseph form in (44) in
    the Appendix A. for better numeric stability. In addition, the LIE-RTS smoother
    is derived using the left-error definition instead of the right-error definition
    presented originally in [23]. SECTION III. Inertial Navigation System The section
    presents the PVA kinematic navigation equations in continuous time [9], [33],
    and the IMU measurement model. A. Navigation Equations They are given as C ˙ e
    b = p ˙ e eb = v ˙ e eb = C e b [ ω b ib ] × − [ ω e ie ] × C e b , v e eb , C
    e b f b ib −2 [ ω e ie ] × v e eb + g e (16a) (16b) (16c) View Source where the
    position p e eb = [ x e eb y e eb z e eb ] ⊺ is coordinated in the ECEF frame,
    and ω e ie =[ ω e cos(L)0− ω e sin(L) ] ⊺ View Source where ω e is the earth rotation
    rate, and L is the latitude; ω b ib , f b ib ∈ R 3 are the angular velocity and
    specific force, respectively. The gravity may be obtained through a gravity model.
    This article adopts the model presented in [34] for simplicity. Remark The GNSS
    navigation solution is given in the ECEF frame. The INS kinematic model is also
    defined in the ECEF, so the GNSS measurements are used to update the trajectory
    with no coordinate transformation. If a navigation solution is required in the
    local frame coordinates, one can quickly transform from ECEF to NED coordinates
    (see [9]). B. IMU Measurement Model As pointed out in [35], the INS kinematic
    model in (16) is exact since there is no model error or uncertainty. Hence, the
    uncertainty in navigation problems comes from the sensors and the local gravity
    anomalies. Gyroscopes and accelerometers are subject to errors that limit the
    accuracy at which angular rotations or specific forces are measured. Thus, sensor
    models are essential for the filter and smoothing navigation to achieve reliable
    results. In particular, we consider the following inertial sensor model: ω ~ b
    ib = f ~ b ib = ω b ib + b g + ε g f b ib + b a + ε a (17a) (17b) View Source
    where ε g ∼ iid N(0, σ 2 g ) and ε a ∼ iid N(0, σ 2 a ) are white noise and are
    related to the angular random walk (ARW) and velocity random walk parameters of
    the IMU. In addition, b g , b a are the gyroscope and accelerometer biases, respectively.
    The biases are modeled as random walk processes in the form d b g = d b a = B
    g d W g B a d W a (18a) (18b) View Source where W g and W a are Wiener processes
    of appropriate dimensions and B g and B a are diffusion matrices associated with
    the IMU''s bias instability. Remark Note that in (17) f ~ b ib and ω ~ b ib are
    IMU''s noisy values of the specific force and angular velocity, respectively.
    Note also that the biases are expressed in the body frame. SECTION IV. Integration
    GNSS/INS A. Modeling Navigation and INS Measurements This work employs the double
    direct isometries Lie group SE 2 (3) [22], for embedding the kinematic states
    in a compound with a translation group T(6) , which accommodates both accelerometer
    and gyroscope biases. The resulting group structure G= SE 2 (3)×T(6) is X= ⎡ ⎣
    ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ C e b 0 1×3 0 1×3 v e 1 0 p e 0 1 0 7×5 0 5×7 I 6×6 0 1×6 b 1 ⎤
    ⎦ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ 12×12 (19) View Source where b=[ b a b g ]∈ R 6 . Lemma IV.1 The
    velocity function Ω:G× R 6 → R 15 associated with the navigation equations (16)
    embedded into the Lie group from (19) is given by Ω(X,u)= ⎡ ⎣ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ω
    ~ b ib − b g − ω b ie f ~ b ib − b a −2 C b e [ ω e ie ] × v e eb + C b e g e
    C b e v e eb 0 0 ⎤ ⎦ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ (20) View Source where u=[ f ~ b ib ω ~ b ib
    ]∈ R 6 is the IMU''s noisy input measurement. In addition, the process noise is
    given by dW= ⎡ ⎣ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ − σ a d W 1 − σ g d W 2 0 B a d W a B g d W g ⎤ ⎦
    ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ =Γd W ~ (21) View Source where d W ~ = [d W ⊺ 1 d W ⊺ 2 d W ⊺ a d
    W ⊺ g ] ⊺ such that W ~ is a standard 12-dim Wiener process. Proof From (16) and
    (19), one gets X −1 dX= = ⎡ ⎣ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ C b e d C e b 0 0 C b e d v e eb 0
    0 C b e d p e eb 0 0 0 7×5 0 5×7 0 6×6 0 1×6 db 0 ⎤ ⎦ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ 12×12 [Ω(X,u)dt+dW
    ] ∧ G View Source which implies (20) and (21). □  B. GNSS Measurement Model The
    rover GNSS antenna is rigidly fixed relative to the IMU, and the lever arm from
    the IMU to the GNSS antenna phase center is known, expressed as l b in the body
    frame. The GNSS position measurements p GNSS =[xyz ] ⊺ are modeled as p GNSS =
    p e eb + C e b l b +ν (22) View Source where ν ∼ iid N(0,R) stands for the GNSS
    noise that is uncorrelated white noise with covariance R=diag( σ 2 x , σ 2 y ,
    σ 2 z ) . C. Outlier Rejection Outliers are spurious data that differ dramatically
    from the statistical distribution, leading to erroneous behavior of the filtering
    algorithm. When adopting GNSS measurements, outliers are inevitably present due
    to satellite blockage, multipath noise, or cycle slip. To make the proposed algorithm
    robust against GNSS outliers, the Mahalanobis distance combined with the χ 2 -test
    is employed to define a rejection scheme. Define the squared normalized residue
    (SNR) as ζ k :=∥ y k − y ^ k ∥ 2 Ξ −1 k (23) View Source where Ξ k = R k + H k
    P k+1|k H ⊺ k , see (14). Assuming that the SNR obeys a chi-square distribution
    with 3 degrees of freedom, i.e., ζ k ∼ χ 2 3 , a valid GNSS is declared if ζ k
    ≤κ where κ is a threshold level. Fig. 3 illustrate the region of valid GNSS (green
    shadow) where the SNR is less than the specified threshold. Fig. 3. GNSS outlier
    rejection using Mahalanobis distance. Show All However, instead of completely
    discarding a possible outlier when the threshold is exceeded, another approach,
    similar to [36], is to mitigate the influence of the respective GNSS measurement.
    We choose to weight the filter innovation with the following factor: γ=min(1,
    κ ζ ). (24) View Source Accordingly, the update equation (14d) becomes X ^ k+1|k+1
    := X ^ k+1|k exp ∧ G (γK( y k+1 −h( X ^ k+1|k ))). (25) View Source Note that
    when γ=1 , the filter is unaltered ( ζ≤κ ). But if ζ>κ , γ becomes less than one,
    scaling down the filter innovation impact on the estimate X ^ k+1|k+1 . D. Alignment
    and Initial Conditions A critical factor for achieving accurate navigation is
    the initialization of the inertial navigation system. Before the take-off, the
    INS is immobile; the initial velocity is null. The initial position can be obtained
    with satisfactory accuracy by averaging GNSS measurements in a sufficiently long
    time window. Likewise, the initial values for the gyroscope biases can be estimated
    using the average of its measurements during the immobile period. Moreover, the
    leveling method [9] can be used to obtain the initial pitch ( θ 0 ) and roll (
    ϕ 0 ) angles as well. The principle of leveling is that when the INS is immobile,
    the accelerometer triad only detects gravity acceleration. Hence, the initial
    pitch and roll angles can be obtained as θ 0 = ϕ 0 = arctan ⎛ ⎝ ⎜ ⎜ ⎜ f ¯ b ib,x
    ( f ¯ b ib,y ) 2 + ( f ¯ b ib,z ) 2 − − − − − − − − − − − − − − − √ ⎞ ⎠ ⎟ ⎟ ⎟
    arctan 2 (− f ¯ b ib,y ,− f ¯ b ib,z ) (26a) (26b) View Source where f ¯ b ib,x
    , f ¯ b ib,y , f ¯ b ib,z are the average accelerometer output during a time window.
    Note that the four-quadrant arc tangent function should be used for roll. The
    accuracy of (26) is determined by the accelerometer biases [33]. Regarding the
    initial heading alignment, the gyro-compassing method or a magnetometer compass
    could be used for the initial heading. However, an accurate heading initialization
    requires expensive navigation-grade gyroscope sensors capable of measuring the
    earth’s rotation rate, whereas magnetometers usually do not attain the required
    precision, apart from the mentioned hindrances for their use. As a result, it
    is mandatory to conceive a method relying solely on low-cost MEMs for a satisfactory
    initialization of the heading value. We propose a Bayesian optimization method
    to this end, described in the next section. E. Postprocessed Heading Alignment
    To provide a reliable initialization of the heading angle ( ψ 0 ) using only low-cost
    MEM sensors, the Bayesian parametric estimation scheme described in [37, cap.12]
    is adapted to our scenario. The method applies when all data are collected after
    the drone flight, represented generically by the data y 1:N . It consists of evaluating
    the posterior distribution p( ψ 0 | y 1:N ) and taking the most likely value for
    the initial heading ψ 0 . For this purpose, note that p( ψ 0 | y 1:N )∝p( y 1:N
    | ψ 0 )p( ψ 0 ) (27) View Source where p( ψ 0 ) is some prior distribution. For
    simplicity, we consider p( ψ 0 )=N(0, σ 2 ψ ) , namely, ψ 0 =0 is the a priori
    heading reference. Moreover, p( y 1:N | ψ 0 ) can be factored in the form p( y
    1:N | ψ 0 )= ∏ k=1 N p( y k | y 1:k−1 , ψ 0 ). (28) View Source We assume that
    the marginal measurement distribution p( y k | y 1:k−1 , ψ 0 ) is a Gaussian distribution
    of form p( y k | y 1:k−1 , ψ 0 )=N(h( X ^ ψ 0 k|k−1 ), R k +H P ψ 0 k|k−1 H ⊺
    ) (29) View Source where X ^ ψ 0 k|k−1 and P ψ 0 k|k−1 come from the filtering
    solution with some fixed ψ 0 value. Accordingly, the most likely value for the
    initial heading can be found by solving min ψ 0 −log(p( ψ 0 | y 1:N )) . Let φ(
    ψ 0 )=−log(p( ψ 0 | y 1:N )) then one has φ( ψ 0 )= = ∑ k=1 N −log(p( y k | y
    1:k−1 , ψ 0 ))−log(p( ψ 0 )) ∑ k=1 N 1 2 log(2π ∣ ∣ S ψ 0 k ∣ ∣ )+ 1 2 ∥ ∥ z ψ
    0 k ∥ ∥ 2 ( S ψ 0 k ) −1 + 1 2 σ 2 ψ ∥ ψ 0 ∥ 2 (30) View Source with S ψ 0 k =
    R k +H P k|k−1 H ⊺ and z ψ 0 k = y k −h( X ^ ψ 0 k|k−1 ) . Remark Note that, for
    each value of ψ 0 , (30) provides the respective log-likelihood up to a constant
    as p( ψ 0 | y 1:N )∝exp(−φ( ψ 0 )) . Thus, for a sufficient number of evaluations
    of different values for ψ 0 , one can build the distribution p( ψ 0 | y 1:N )
    using the filtering solution. Also, we propose the following approximation p(
    ψ 0 | y 1:N )≈N( ψ ∗ 0 , σ 2 ψ ∗ ) . This implies that the log-likelihood (30)
    is approximated quadratic w.r.t ψ 0 ; hence, one can obtain the approximated log-likelihood
    function by evaluating three distinct points. In summary, the proposed heading
    alignment scheme consists of three independent D-LIE-EKF evaluations, each with
    different heading values [ ψ 1 ψ 2 ψ 3 ] . After these runnings, three samples
    from the log-likelihood are obtained. Thereafter, a parabola c= m 1 ψ 2 + m 2
    ψ+ m 3 is fitted to the samples solving Am=c for m where A= ⎡ ⎣ ⎢ ⎢ ψ 2 1 ψ 2
    2 ψ 2 3 ψ 1 ψ 2 ψ 3 1 1 1 ⎤ ⎦ ⎥ ⎥ ,c= ⎡ ⎣ ⎢ c 1 c 2 c 3 ⎤ ⎦ ⎥ ,m= ⎡ ⎣ ⎢ m 1 m
    2 m 3 ⎤ ⎦ ⎥ . (31) View Source The best estimate of the initial heading is then
    chosen as the parabola minimum value, ψ ∗ 0 :=− m 2 /2 m 1 . Fig. 4 shows an example
    of the proposed optimization-based heading alignment with ψ 1 =− 30 ∘ , ψ 2 =
    0 ∘ and ψ 3 = 30 ∘ applied to a real dataset. For this case, the best initial
    heading was ψ ∗ 0 = 3.72 ∘ . The actual log-likelihood (blue curve) was computed
    by a grid of values for ψ 0 from − 60 ∘ to + 60 ∘ with 5 ∘ increment. Notice that
    the blue curve is close to the red curve (quadratic approximation) near its minimum.
    In Section V-C, a numeric experiment using synthetic data illustrates the performance
    of the proposed heading alignment strategy. Fig. 4. Example of the proposed optimization-based
    heading alignment using − 30 ∘ , 0 ∘ ,+ 30 ∘ guesses for the initial heading.
    The blue curve indicates the log-likelihood function, and the red curve is the
    proposed approximation. Show All F. GNSS/INS Integration Scheme The proposed scheme
    for LC GNSS/INS integration using Lie group consists of four steps. First, the
    accelerometer data from the IMU during an initial stationary period is used to
    perform leveling and obtain initial values for pitch and roll as in Section IV-D.
    Then, the heading alignment method described in Section IV-E is applied to obtain
    the initial heading value. Next, a fourth pass of the D-LIE-EKF algorithm is performed
    to obtain a filtered solution with ψ ∗ 0 as the initial heading. Finally, the
    D-LIE-EKF-RTS smoother (or D-LIE-EKS for short) generates the final output. Fig.
    5 illustrates these four steps. Fig. 5. Proposed loosely coupled GNSS/INS integration
    using Lie group for postprocessing applications. Show All SECTION V. Data Experiments
    A. Settings This work was especially motivated by the drone-borne DinSAR application
    described in [1] and [38]. It requires high-fidelity PVA information to provide
    reliable interferometric results (see Table I). The drone with the radar system
    is shown in Fig. 6. It consists of a DJI Matrice 600-Pro equipped with a radar
    system for remote sensing. An INS is mounted independent from the native onboard
    navigation system, exclusively to provide PVA information for the radar system,
    consisting of a 6-DOF IMU ADIS16495 from Analog Devices. The IMU is rigidly mounted
    on the radar antenna so that the attitude measurement from the IMU can be easily
    transformed into the radar''s orientation information. TABLE I DinSAR Specifications
    [38] Fig. 6. Drone-borne DinSAR system [1]. Show All In complement, the u-blox
    ZED F9P GNSS system is installed to provide raw code, and post-processed phase
    measurements using the open-source package RTKlib [39]. B. Comparisons With Synthetic
    Data The objective here is to get realistic and “noiseless” trajectories, such
    as those produced by one elaborate flight simulator, for performance comparison
    among Euler, quaternions, and Lie filtering and smoothing schemes. This precedes
    actual field tests, presented in Section V-E. The starting point is to get a real
    dataset from drone trajectories, as illustrated in Fig. 7, which is then processed
    with centimeter-level accuracy. Then, inverse strap-down mechanization similar
    to [40] but adapted to the Lie group model is implemented to emulate perfect measurements.
    Fig. 7. Example of three flight scenarios. (a) Helicoidal. (b) Rectangular. (c)
    Circular. Show All More specifically, let { C e b (k), p e (k), v e (k) } k=1:N
    be the reference trajectory generated with a sample rate F s =1/Δt . For each
    time instant k , an SE 2 (3) element is built to represent the system state in
    the form S k =[ C e b (k) 0 v e (k) I p e (k) ]. (32) View Source Thereafter,
    the left-velocity vector is computed using Ω= log ∨ G ( S −1 k S k+1 ) Δt =[ Ω
    ω Ω f ]. (33) View Source From (20), one obtains the angular velocity and the
    specific force as follows: ω b ib (k)= f b ib (k)= Ω ω + ω e ie Ω f +2 C b e (k)[
    ω e ie ] × v e eb (k)− C b e (k) g e . View Source From such sequences, one can
    integrate back using zero-order hold or another rule to get time continuous input
    and state representations, yielding a ground truth trajectory for performance
    comparisons. Remark We choose to generate { C e b (k), p e (k), v e (k) } k=1:N
    with the commercial software Inertial Explorer for GNSS/INS integration, for the
    sake of independence, but we could choose to process with the proposed scheme
    equally well. Finally, perturbations reflecting characteristic errors of actual
    sensors should be introduced to the emulated measurements, namely, IMU artificial
    noises are added to form the simulated IMU measurements ω ~ b ib (k)= f ~ b ib
    (k)= ω i ib (k)+ b g (k)+ N g w(k) f i ib (k)+ b a (k)+ N a w(k) View Source where
    w a , w g ∼N(0,I) and N a , N g are the VRW and ARW parameters of the emulated
    IMU. Besides, b a , b g are the accelerometer and gyroscope biases simulated using
    Ornstein-Uhlenbeck processes as follows: b a (k+1)= b g (k+1)= b a (k)+ τ a (
    β a − b a (k))Δt+ B a Δt − − − √ w ba (k) b g (k)+ τ g ( β g − b g (k))Δt+ B g
    Δt − − − √ w bg (k) View Source where τ a , τ b are the biases'' correlation time,
    β a , β b are the turn-on constant biases, w ba , w bg ∼N(0,I) and B a , B g are
    parameters to influence the bias instability. Unlike the random walk process,
    the Ornstein-Uhlenbeck process is a mean-reverting process, better fitting the
    IMU biases behavior. The GNSS data is rendered by down-sampling the reference
    trajectory to 1 Hz and adding the lever-arm component together with a 3-dimensional
    white noise as follows: y(n)= p e (n F s )+ C e b (n F s ) l b +ε(n) (34) View
    Source for n=0,1,…,⌊ N F s ⌋ , ε∼N(0,R) . The parameters used in all simulations
    were chosen to match the ADIS16495 data sheet and the centimeter-level precision
    of RTK-GNSS and are given in Table II. The covariance matrix P 0 is formed as
    a diagonal matrix whose individual elements are chosen according to each state''s
    expected 99.7% confidence interval (three standard deviations), as follows: P
    0 = diag(( 1 3 ∘ ) 2 ,( 1 3 ∘ ) 2 ,( 5 3 ∘ ) 2 ( 0.001 3 m/s ) 2 ,( 0.001 3 m/s
    ) 2 ,( 0.001 3 m/s ) 2 ( 0.1 3 m ) 2 ,( 0.1 3 m ) 2 ,( 0.1 3 m ) 2 ( 1 3 mg )
    2 ,( 1 3 mg ) 2 ,( 1 3 mg ) 2 ( 15 3 deg s ) 2 ,( 15 3 deg s ) 2 ,( 15 3 deg s
    ) 2 ). View Source TABLE II Simulation Parameters C. Heading Alignment Performance
    To analyze the accuracy of the heading alignment method described in Section IV-E
    we perform some experiments with synthetic data using different initial heading
    values. The optimization-based method is applied in each experiment, and the best
    estimate of the initial heading is obtained. The experiments support that the
    proposed heading alignment can achieve an error less than 2 ∘ as required in Table
    I, when the true heading is between − 20 ∘ and + 20 ∘ as shown in Fig. 8. Fig.
    8. Heading alignment error. Show All D. Navigation Performance Three flight scenarios
    were simulated to evaluate the proposed processing scheme''s performance: helicoidal,
    rectangular, and circular. These profiles are shown in Fig. 7. For comparisons,
    for each scenario, the following algorithms were implemented: Lie group-based
    filter (D-LIE-EKF) inbuilt into the smoother (D-LIE-EKS); multiplicative quaternion-based
    filter (MEKF) and smoother (MEKS); Euler-based filter (EULER-EKF), and smoother
    (EULER-EKS). Thereafter, 100 Monte Carlo realizations were performed, and each
    algorithm''s respective rmse was computed. All algorithms are initialized with
    the same parameters for a fair comparison. Table III summarizes the performance
    for each online processing phase using filtering only. Table IV shows the off-line
    performance after applying the respective smoother algorithm. TABLE III RMSE Comparison
    for 100 Monte Carlo Simulations Using Filter Only TABLE IV RMSE Comparison for
    100 Monte Carlo Simulations Using Filter and RTS Smoother Note that using the
    Lie group-based algorithm the heading error is lower for the three scenarios in
    rmse terms. The D-LIE-EKS shows an overall performance gain of about 40% over
    the MEKS for both helicoidal and circular flight profiles and about 9% for the
    rectangular profile. This result indicates the superiority of the Lie group approach,
    which becomes more noticeable for curved trajectories. E. In Field Drone-Borne
    DinSAR Performance This section reports the performance results obtained from
    a complete experiment of image reconstruction with the drone-borne DInSAR system
    described in [1]. The digital surface model (DSM) is obtained using the cross-track
    interferometry information provided by the two C-band antennae and applied in
    the DInSAR calculation. The controlled experiment was conducted using three trihedral
    corner reflectors with square sides and edge lengths of 0.6 m to serve as a ground
    reference. Fig. 9 illustrates the drone-borne DinSAR geometry. Fig. 9. Drone-borne
    DinSAR geometry. Show All The experiment accurately assesses the DinSAR processing
    using the proposed GNSS/INS technique and consists of the following steps. The
    GNSS ground station is placed close to the starting position of the drone, and
    the GNSS recording is initiated. Then, three flights are carried out, each consisting
    of the following successive steps: 1) turning on the drone and the radar and waiting
    15 min for simultaneous and stationary recording of the ground station and drone
    GNSS data; 2) taking off and executing the same west-east flight track; and 3)
    landing and waiting 15 min for simultaneous and stationary recording of the ground
    station and radar GNSS data. Turning off. The GNSS ground station and drone are
    dismounted, and the acquired data is downloaded for postprocessing. For comparisons,
    we test the results against commercially produced navigation software specialized
    for IMU-GNSS integration, the NovAtel Inertial Explorer (IE), using its offline
    processing mode. After the flights, the data are processed in two steps for the
    Lie group-based processing. First, the ground station and rover GNSS receivers
    are processed using RTKlib [39] to generate centimeter-accuracy position information
    at 1 Hz. Second, the Lie group filter-smoother algorithm generates the final position,
    velocity, and attitude solution by combining the GNSS information with the 200
    Hz IMU measurements. We refer to this solution as D-LIE-EKS. The GNSS and IMU
    raw data for the IE processing is fed directly to the software. Although the proposed
    scheme is LC, we compare it with IE''s loosely coupled (IE-LC) and tightly coupled
    (IE-TC) solutions. Now, with the navigation information at hand, the raw radar
    data are processed on the imaging module, recording each resulting single-look
    complex (SLC) image. After that, the interferometry is performed, yielding the
    interferogram, topography subtraction, and phase-to-height conversion. The output
    consists of two deformation maps plus the three SLC images, all in slant range
    geometry. Each interferogram is calculated with 0.047 m resolution in azimuth
    and 1.228 m resolution in the slant range. From the close inspection of the reflector''s
    positioning, we can not detect any noticeable advantages from one or the other
    procedure, even in the IE-TC mode. After these evaluations, we attempted to spot
    subtle differences by subtracting images of subsequent flights and looking for
    terrain inconsistencies. Fig. 10 shows the relative error of subsequent flights
    for the three different navigation processing. Notice that the resulting pattern
    is almost identical for all algorithms. Fig. 10. Relative DinSAR Error Image of
    subsequent flights. For all algorithms, the patterns are almost identical. Show
    All Fig. 11 depicts the relative error for only one azimuth line (horizontal cross-section
    of Fig. 10). Between slant-range 0–100 m, one can observe an increase in relative
    error for IE-LC and IE-TC, while for the D-LIE-EKS, the error magnitude remains
    steady. Fig. 11. Relative error of DinSAR for one azimuth line. Show All Table
    V summarizes the overall error of the three algorithms. We observe that the proposed
    D-LIE-EKS scheme outperforms both IE-LC and IE-TC in these experiments in terms
    of rmse. TABLE V DinSAR RMSE Relative Errors SECTION VI. Conclusion A LC GNSS/INS
    integration scheme was developed based on Lie group theory, tailored for postprocessing
    applications seeking the highest accuracy. It incorporates the online Kalman filter
    inbuilt into the offline RTS smoother to provide estimates of PVA to this goal.
    The double direct isometry group SE 2 (3) compound with the translation group
    T(6) was adopted to model the kinematic and cope with biased navigation system
    measurements. The article includes a Bayesian adjustment devised to tackle the
    heading estimation problem, seeking full trajectory error mitigation. It also
    contains an outlier test conceived to deal with low-quality GNSS measurements.
    To our best knowledge, this is the first implementation of LC GNSS/INS integration
    tailored for postprocessing applications, combining Kalman filtering and RTS smoothing
    on Lie groups, applied to drone-borne remote sensing applications. It includes
    a few numeric experiments based on synthetic data generated using inverse strap-down
    mechanization. They show that the Lie group approach consistently outperforms
    classical methods based on quaternion and Euler parametrization of the attitude
    matrix. The advantage of the Lie group is further highlighted when using helicoidal
    and circular trajectories in which, due to the curvy paths, the proposed scheme
    attains better rms performance. Furthermore, in a field comparison, the Lie group
    also exhibits superior performance and better accuracy than the navigation software
    Inertial Explorer in a DinSAR drone-borne application. Surprisingly, the simpler
    LC setting of the proposed technique presented superior performance than the IE''s
    more complex tightly coupled configuration. A favorable quality comparison with
    industry-standard software in this experiment indicates the novelty and the applicability
    of the Lie-based method devised here for low-cost and high-precision flight navigation
    reconstitution. In a word, this work brings a complete cycle of engineering design,
    revealing that the Lie group theory of filtering and smoothing forms an appealing
    framework for high-quality aerial navigation. Finally, as an aside, these experiments
    point out that the air-borne radar scheme provides an excellent benchmark for
    low-cost INS evaluations. The scheme circumvents the need for an expensive navigation-grade
    INS unit in pairing tests, the usual form of calibration and evaluation of such
    devices. ACKNOWLEDGMENT The authors would like to thank the Radaz Indústria e
    Comércio de Produtos Eletrônicos S.A. for supporting this work. Appendix SECTION
    A. D-LIE-EKF Equations Proof: Lemma II.1. Let X k = X ^ k|k exp ∧ G ( ϵ k|k )
    with ϵ k|k ∼N(0, P k|k ) and X ^ k+1|k = X ^ k|k exp ∧ G ( Ω ^ k ) . Employing
    a first-order approximation for Ω k around X ^ k|k , yields Ω k =Ω( X ^ k|k exp
    ∧ G ( ϵ k|k ))≊Ω( X ^ k|k )+ C k ϵ k|k (35) View Source where C k := ∂ ∂ϵ [Ω(
    X ^ k|k exp ∧ G (ϵ))] ∣ ∣ ϵ=0 . From (13), one has ϵ k+1|k = = = X ^ −1 k+1|k
    X k+1 exp ∧ G (− Ω ^ k ) X ^ −1 k|k X k exp ∧ G ( Ω k + w k ) exp ∧ G (− Ω ^ k
    ) exp ∧ G ( ϵ k|k ) exp ∧ G ( Ω ^ k + C k ϵ k|k + w k ). (36) View Source Assuming
    that C k ϵ k|k + w k is small, then using the relationship from [41] and the fact
    that g exp ∧ G (x)= exp ∧ G ( Ad G (g)x)g one gets ϵ k+1|k = exp ∧ G (F ϵ k|k
    + J r ( Ω ^ k ) w k ) (37) View Source with F= Ad G ( exp ∧ G (− Ω ^ k ))+ J r
    ( Ω ^ k ) C k . Therefore, we conclude that X k+1 ∼ N G ( X ^ k+1|k , P k+1|k
    ) where P k+1|k =F P k|k F ⊺ + J r ( Ω ^ k ) Q k J r ( Ω ^ k ) ⊺ . (38a) View
    Source Now, for the measurement-update step, consider X k+1 = X ^ k+1|k exp ∧
    G ( ϵ k+1|k ) where ϵ k+1|k ∼N(0, P k+1|k ) . Note that the measurement distribution
    is p( y k+1 | X k+1 )=N( y k+1 ;h( X k+1 ), R k+1 ) and the prior state distribution
    is p( X k+1 | y 1:k )= N G ( X ^ k+1|k , P k+1|k ) . Thus, from the Bayes'' rule,
    one has p( X k+1 | y 1:k+1 )= p( y k+1 | X k+1 )p( X k+1 | y 1:k ) p( y k+1 |
    y 1:k ) ∝exp(− 1 2 ∥ y k+1 −h( X k+1 ) ∥ 2 R −1 k+1 − 1 2 ∥ ϵ k+1|k ∥ 2 P −1 k+1|k
    ). (39) View Source Let the posterior distribution be parametrized in the form
    p( X k+1 | y 1:k+1 )=p( X ^ k+1|k exp ∧ G (v)| y 1:k+1 ). (40) View Source Therefore,
    the maximum a posteriori (MAP) estimate is X ^ k+1|k+1 = X ^ k+1|k exp ∧ G ( v
    ∗ ) such that v ∗ =arg min v ℓ(v) where ℓ(v) is the negative log-likelihood given
    by ℓ(v):= 1 2 ∥ y k+1 −h( X ^ k+1|k exp ∧ G (v)) ∥ 2 R −1 k+1 + 1 2 ∥v ∥ 2 P −1
    k+1|k . View Source If a linear approximation is adopted, then one can obtain
    a set of filtering equations similar to the EKF. For this purpose, consider a
    first-order approximation of (12) in the form h( X ^ k+1|k exp ∧ G (ϵ))≊h( X ^
    k+1|k )+Hϵ with H= ∂ ∂ϵ [h( X ^ k+1|k exp ∧ G (ϵ))] ∣ ∣ ϵ=0 . Thus ℓ(v)≊ 1 2 ∥
    z k+1 −Hv ∥ 2 R −1 k+1 + 1 2 ∥v ∥ 2 P −1 k+1|k (41) View Source where z k+1 :=
    y k+1 −h( X ^ k+1|k ) is the residual. The minimum of (41) is straightforward
    given by v ∗ =K z k+1 where, K=( P −1 k+1|k + H ⊺ R −1 k+1 H ) −1 H ⊺ R −1 k+1
    which also can be written as K= P k+1|k H ⊺ ( R k+1 +H P k+1|k H ⊺ ) −1 . Thus
    X ^ k+1|k+1 = X ^ k+1|k exp ∧ G (K z k+1 ). (42) View Source Let the state error
    be ϵ k+1|k+1 := log ∨ G ( X ^ −1 k+1|k+1 X k+1 ) . From (42), the posterior error
    follows: ϵ k+1|k+1 = = = = ≈ = log ∨ G ( X ^ −1 k+1|k+1 X k+1 ) log ∨ G ( exp
    ∧ G (−K z k+1 ) X ^ −1 k+1|k X k+1 ) log ∨ G ( exp ∧ G (−K z k+1 ) exp ∧ G ( ϵ
    k+1|k )) −K( y k+1 −h( X ^ k+1|k ))+ ϵ k+1|k −K(H ϵ k+1|k + ν k+1 )+ ϵ k+1|k (I−KH)
    ϵ k+1|k −K ν k+1 (43) View Source where a linear approximation z k+1 ≈H ϵ k+1|k
    + ν k+1 is employed. Define P k+1|k+1 :=E[ ϵ k+1|k+1 ϵ ⊺ k+1|k+1 ] . Assuming
    that E[ ϵ k+1|k ν ⊺ k+1 ]=0 , one gets P k+1|k+1 =(I−KH) P k+1|k (∙ ) ⊺ +K R k+1
    K ⊺ . (44) View Source □  SECTION B. Rauch-Tung-Striebel Smoother on Lie Groups
    Proof: Lemma II.2. Following the lines of [37], from a Bayesian perspective, the
    RTS smoother on Lie groups can be derived as the MAP estimate of the following
    joint pdf: p( X k , X k+1 | y 1:T )= = = p( X k | X k+1 , y 1:k )p( X k+1 | y
    1:T ) p( X k+1 | X k )p( X k | y 1:k ) p( X k+1 | y 1:k ) p( X k+1 | y 1:T ) p(
    X k+1 , X k | y 1:k ) p( X k+1 | y 1:k ) p( X k+1 | y 1:T ). (45) View Source
    Assume that p( X k+1 , X k | y 1:k )= p( X k | y 1:k )= p( X k+1 | y 1:T )= p(
    X k+1 | y 1:k )= N G×G ( X ^ k|k , X ^ k+1|k ,P) N G ( X ^ k|k , P k|k ) N G (
    X ^ s k+1 , P s k+1 ) N G ( X ^ k+1|k , P k+1|k ) (46a) (46b) (46c) (46d) View
    Source where P=[ P k|k F k P k|k P k|k F ⊺ k P k+1|k ] and { X ^ k|k , P k|k }
    k=1:N comes from the D-LIE-EKF. Accordingly, (45) becomes p( X k , X k+1 | y 1:T
    ) ∝exp(− 1 2 ∥ ∥ ∥ ∥ ∥ ⎡ ⎣ ⎢ log ∨ G [ X ^ −1 k|k X k ] log ∨ G [ X ^ −1 k+1|k
    X k+1 ] ⎤ ⎦ ⎥ ∥ ∥ ∥ ∥ ∥ 2 P −1 + 1 2 ∥ ∥ log ∨ G [ X ^ −1 k+1|k X k+1 ] ∥ ∥ 2
    P −1 k+1|k − 1 2 ∥ ∥ ∥ log ∨ G [ ( X ^ s k+1 ) −1 X k+1 ] ∥ ∥ ∥ 2 ( P s k+1 )
    −1 ). (47) View Source Parametrize X k = X ^ k|k exp ∧ G ( δ k ) and X k+1 = X
    ^ s k+1 exp ∧ G ( δ k+1 ) . Thereafter, taking the negative logarithm of (47)
    yields ℓ( δ k , δ k+1 )= 1 2 ∥ ∥ ∥ [ δ k log ∨ G [ exp ∧ G ( z s ) exp ∧ G ( δ
    k+1 )] ] ∥ ∥ ∥ 2 P −1 − 1 2 ∥ log ∨ G [ exp ∧ G ( z s ) exp ∧ G ( δ k+1 )] ∥ 2
    P −1 k+1|k + 1 2 ∥ δ k+1 ∥ 2 ( P s k+1 ) −1 (48) View Source where z s := log
    ∨ G [ X ^ −1 k+1|k X ^ s k+1 ] . Assuming that both z s and δ k+1 are small, one
    has ℓ( δ k , δ k+1 ) = 1 2 ∥ ∥ ∥ [ δ k z s + δ k+1 ] ∥ ∥ ∥ 2 P −1 − 1 2 ∥ z s
    + δ k+1 ∥ 2 P −1 k+1|k + 1 2 ∥ δ k+1 ∥ 2 ( P s k+1 ) −1 = 1 2 ∥Aδ+b∥ 2 W (49)
    View Source where δ:=[ δ k δ k+1 ],A:= ⎡ ⎣ ⎢ ⎢ ⎢ I 0 0 0 0 I I I ⎤ ⎦ ⎥ ⎥ ⎥ ,b:=
    ⎡ ⎣ ⎢ ⎢ ⎢ 0 z s z s 0 ⎤ ⎦ ⎥ ⎥ ⎥ (50) View Source and W=blkdiag( P −1 ,− P −1 k+1|k
    ,( P s k+1 ) −1 ) . The optimal solution of (49) is straightforward given by δ
    ∗ = = ( A ⊺ WA ) −1 A ⊺ Wb [ δ ∗ k δ ∗ k+1 ]=[ G k z s 0 ]. (51) View Source Finally,
    the smoothed state estimate is X ^ s k = X ^ k|k exp ∧ G ( G k z s ) and the final
    covariance is obtained from the first block diagonal of ( A ⊺ WA ) −1 (see [23]).
    □  Authors Figures References Keywords Metrics Footnotes More Like This Fault
    Detection in Inertial Measurement Unit and Global Navigation Satellite System
    of an Unmanned surface vehicle 2022 22nd International Conference on Control,
    Automation and Systems (ICCAS) Published: 2022 Known Vulnerabilities of Global
    Navigation Satellite Systems, Status, and Potential Mitigation Techniques Proceedings
    of the IEEE Published: 2016 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved."'
  inline_citation: '>'
  journal: IEEE Transactions on Aerospace and Electronic Systems
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: GNSS/MEMS-INS Integration for Drone Navigation Using EKF on Lie Groups
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Zhao H.
  - Chen W.
  - Zhou S.
  - Zheng F.
  - Liu Y.H.
  citation_count: '0'
  description: This brief presents real-time configuration estimation and motion planning
    for the industrial tractor-trailers vehicle composed of a full-scale car-like
    tractor and multiple full trailers. For the real-life vehicle, determining the
    configuration is challenging. With only on-tractor sensors, we solve this problem
    by fusing information from system dynamics propagation, geometrical constraints
    among the articulated units, and matching with the prebuilt environment map. The
    solution is efficiently achieved by formulating and solving a maximum a posterior
    (MAP) estimation problem in the pose-graph optimization framework. With the complicated
    tractor-trailers' structure, small mismatch between actual and planned trajectories
    is crucial to inherit obstacle-free guarantee from planning to execution. We consider
    the dynamics and focus on facilitating the reduction of the mismatch by proposing
    a controller-based smoothing method to perform online motion planning. The given
    waypoint path is smoothed by forward propagation using a deliberately designed
    controller to generate the trajectory. The efficiently computed trajectories are
    also obstacle-free and dynamically feasible. The controller is also applied in
    execution to precisely reproduce the planned system evolvement. We demonstrate
    the performance with the real-life industrial tractor-trailers' vehicle.
  doi: 10.1109/TCST.2023.3275497
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Journals & Magazines >IEEE Transactions on Control ...
    >Volume: 31 Issue: 6 Localization and Motion Planning of Industrial Tractor–Trailers
    Vehicles Publisher: IEEE Cite This PDF Hongchao Zhao; Wen Chen; Shunbo Zhou; Fan
    Zheng; Yun-Hui Liu All Authors 1 Cites in Paper 290 Full Text Views Abstract Document
    Sections I. Introduction II. Dynamic Modeling III. Configuration Estimation IV.
    Online Trajectory Planning V. Implementation Results Show Full Outline Authors
    Figures References Citations Keywords Metrics Abstract: This brief presents real-time
    configuration estimation and motion planning for the industrial tractor–trailers
    vehicle composed of a full-scale car-like tractor and multiple full trailers.
    For the real-life vehicle, determining the configuration is challenging. With
    only on-tractor sensors, we solve this problem by fusing information from system
    dynamics propagation, geometrical constraints among the articulated units, and
    matching with the prebuilt environment map. The solution is efficiently achieved
    by formulating and solving a maximum a posterior (MAP) estimation problem in the
    pose-graph optimization framework. With the complicated tractor–trailers’ structure,
    small mismatch between actual and planned trajectories is crucial to inherit obstacle-free
    guarantee from planning to execution. We consider the dynamics and focus on facilitating
    the reduction of the mismatch by proposing a controller-based smoothing method
    to perform online motion planning. The given waypoint path is smoothed by forward
    propagation using a deliberately designed controller to generate the trajectory.
    The efficiently computed trajectories are also obstacle-free and dynamically feasible.
    The controller is also applied in execution to precisely reproduce the planned
    system evolvement. We demonstrate the performance with the real-life industrial
    tractor–trailers’ vehicle. Published in: IEEE Transactions on Control Systems
    Technology ( Volume: 31, Issue: 6, November 2023) Page(s): 2928 - 2936 Date of
    Publication: 05 June 2023 ISSN Information: DOI: 10.1109/TCST.2023.3275497 Publisher:
    IEEE Funding Agency: SECTION I. Introduction The tractor–trailers’ vehicle is
    among the most commonly applied vehicle systems in industrial environments such
    as cargo terminals, warehouses, and airports. An autonomous tractor–trailers’
    system is promising to further significantly improve the efficiency and relieve
    the labor shortage issue. The commonly seen industrial vehicle (see Figs. 1 and
    2) that we are dealing with in this brief is characterized by an actively controlled
    car-like tractor towing multiple passive full trailers [1]. Arbitrary number of
    on-axle and off-axle joints can appear in the system. This vehicle system is classified
    into the general n -trailers’ system [2]. Our motivation is to achieve autonomous
    forward driving of the vehicle in industrial environments. Oriented to practical
    implementation, this brief studies the real-time configuration estimation (localization
    of the tractor and all the trailers) and motion planning of the full-scale industrial
    tractor–trailers’ system. These two problems are crucial challenges to overcome
    before the real-world application. Fig. 1. Industrial tractor towing two full
    trailers. Show All Fig. 2. Geometry of the tractor towing two full trailers. Show
    All A. Related Work There exist a large number of works addressing motion planning
    problems of tractor–trailers’ vehicles. One can refer to our previous works [1],
    [3], [4] for a detailed review. Most PnC works were conducted on small-scale vehicles
    or in simulations. Few works handled full-scale systems. Besides, most works consider
    only the kinematic model. In practice, configuration of the full-scale vehicle
    requires to be estimated online. Unfortunately, in contrast to the scale-down
    vehicles whose configuration is easily determined by installing encoders on the
    hitch joints, it is challenging to estimate the configuration for full-size tractor–trailers’
    vehicles. First, due to the mechanism of and the huge forces on the hitch joints,
    it is difficult to install encoders or other sensors to measure the hitch angles.
    Second, the power supply and data communication for the sensors are big issues.
    Third, in real-world industrial operations, trailers are added and removed frequently.
    Existence of configuration sensors will introduce significant inconvenience. Numerous
    works in the literature have addressed the localization and mapping problem for
    normal mobile agents. However, localization for full-scale articulated robots
    like the tractor–trailers vehicles’ is rarely seen. Ljungqvist et al. [5] in their
    ground-braking work proposed to use a LiDAR to estimate configuration of the full
    trailer. However, the method can be applied only when one full trailer exists.
    In this brief, we apply only on-tractor sensors to conduct configuration estimation
    for the tractor towing multiple full trailers. In industrial scenarios, online
    motion planning is required to avoid obstacles. Dynamic constraints need to be
    considered since the vehicle is heavy and the actively controlled tractor has
    velocity and acceleration bounds as well as the steering saturations. Due to the
    long and articulated structure, the most important requirement is that the planning
    level should facilitate the reduction of mismatch between the actual trajectory
    and the planned trajectory such that the system can inherit the obstacle-free
    guarantee from motion planning level to motion execution level. Few works on PnC
    of autonomous vehicles focused on reducing the trajectory mismatch. A similar
    idea of using controller-based smoothing for motion planning can be found in [6].
    In this brief, we only consider the forward motion, since reverse motion of the
    many-trailer vehicle is unstable and will cause severe jack-knife phenomena. The
    kinematics is naturally stable in forward motion, which means the passive trailers
    will tend to align with the tractor [7], [8]. For trailers behind, being collision-free
    is satisfactory enough for real-life applications. We consider the motion planning
    problem from a more practical perspective. Somehow like the ideas in [9], we essentially
    conduct motion planning for merely the lead tractor. But different from [9] and
    most previous works, the trajectories are online planned, dynamical constraints
    and input saturations of the tractor are considered, and we meanwhile ensure that
    the resultant trajectories of the trailers are also obstacle-free. Besides, we
    plan trajectories that enjoy smaller tracking errors in execution of the tractor
    helping to inherit obstacle-free guarantee from planning to execution. B. Contribution
    of This Brief The first contribution of this brief is an innovative method to
    online estimate the configuration of the industrial tractor–trailers’ vehicle
    using only the normal on-tractor sensors (encoders and LiDAR). The second contribution
    of this brief is the controller-based smoothing method to generate the planned
    trajectories. The trajectories reduce planned–actual mismatch. They are collision-free,
    dynamically feasible, and highly efficient for real-time implementation. The third
    contribution of this brief is the implementation of the configuration estimation
    and motion planning algorithms on the full-scale industrial tractor–trailers’
    vehicle, leading to its satisfactory autonomous driving performance in industrial
    environments. C. Organization The rest of the brief is organized as follows. Section
    II presents the dynamic model of the system. The proposed configuration estimation
    and motion planning methods are presented in Sections III and IV, respectively.
    Section V shows results of practical implementation. Section VI gives conclusions.
    SECTION II. Dynamic Modeling Due to the holonomic constraints, i.e., the geometric
    relationships among the units imposed by the mechanical structure, we can fully
    describe the configuration of the tractor–trailers’ vehicle using the configuration
    vector q=[ x 0 , y 0 , θ 0 , β 1 , β 2 , β 3 ,…, β n ] ′ ∈ R n+3 , where β i =
    θ i − θ i−1 denotes the hitch angle at the corresponding on-axle or off-axle joint,
    indicating the orientation difference between trailer i and trailer i−1 (or the
    tractor). x i =[ x i , y i , θ i ] , i=0,1,2,3,…,n denotes the pose (position
    and orientation) of the tractor or the trailers in the global manner (see Fig.
    2). Letting μ=[ x 0 , x 1 , x 2 ,…, x n ] ′ and applying the holonomic constraints,
    we can map the configuration to the poses via μ= F h (q) . One can easily derive
    the formulation of F h (q) , and thus, the derivation is omitted here. Thanks
    to the nonholonomic constraints, (1) can be obtained, in which J nh (q,δ)∈ R n+3
    , and v 0 denotes the longitudinal velocity of the tractor. δ is the steering
    angle. One can refer to our previous work [1] for detailed formulation of (1)
    with different numbers of full trailers q ˙ = J nh (q,δ) v 0 . (1) View Source
    Also from [1], steering and velocity dynamics of the tractor can be simply expressed
    by δ ˙ = v ˙ 0 = f s f v (2) (3) View Source where f s and f v are two virtual
    control inputs. Equations (1)–(3) constitute the complete dynamic model of the
    industrial tractor–trailers’ vehicle. With the given control inputs ( f v and
    f s ) and the initial configuration, this model can be integrated to predict future
    vehicle states. Also, with the measurable longitudinal tractor velocity v 0 and
    tractor steering angle δ , (1) can also be used to predict future configurations.
    SECTION III. Configuration Estimation Real-time vehicle configuration serves as
    the initial point from which the online planning part generates the state trajectory.
    In this brief, we only use ordinary on-tractor sensors to solve the configuration
    estimation problem, without installing any extra devices on the trailers. The
    sensor suite includes only one LiDAR and three encoders. Two of the encoders are
    installed at two rear wheels and the third encoder is mounted at the steering
    wheel, as shown in Figs. 1 and 9. We can get the longitudinal velocity v 0 at
    up to 1500 Hz by averaging the speed measurements of the two encoders on rear
    wheels. The steering angle δ with frequency up to 1500 Hz is provided by the encoder
    at the steering wheel. We also have the prebuilt point-cloud map of the environment
    serving as inputs. The map is built using simultaneous localization and mapping
    (SLAM) methods in [10]. In practice, it is common to do mapping first and localization
    afterward. The configuration initialization is discussed in Section V, and now
    we assume the configuration is well initialized. The configuration estimation
    is formulated and solved as a maximum a posterior (MAP) problem in the pose-graph
    optimization framework. For sake of clarity and conciseness, we without loss of
    generality present our method for the case where the tractor tows two full trailers
    (four trailers), as shown in Fig. 2. Same procedures can be applied for cases
    with more or less trailers. Fig. 3. Pose graph for configuration estimation. Poses
    to be estimated at current time h are modeled by the five differently colored
    nodes. Poses computed at h−1 are treated as known and fixed and are modeled by
    black nodes. Measurements and constraints are encoded as factors between nodes.
    Show All Fig. 4. Workflow for relative pose measurement between the tractor and
    the last trailer. Show All Fig. 5. Framework of online trajectory planning. Show
    All Fig. 6. Nudging of the waypoint path. Show All Fig. 7. Geometry of the pure
    pursuit controller. Show All Fig. 8. Collision check of the sampled configuration.
    Show All Fig. 9. Experimental setup. Show All A. Poses As mentioned in Section
    II, the poses and the configuration vector are mapped bijectively with function
    F h . Instead of directly estimating the configuration vector q , in an equivalent
    but more straightforward manner, we estimate the poses of the tractor and all
    the trailers. We denote the set of poses to be estimated with X={ x 0 , x 1 ,
    x 2 , x 3 , x 4 } , as shown in Fig. 2. To facilitate the notation, we also write
    the global pose x i ∈X interchangeably as transformation matrix W T i , which
    lives in SE(2) with respect to the world frame x i : = W T i = ⎡ ⎣ ⎢ cos θ i sin
    θ i 0 −sin θ i cos θ i 0 x i y i 1 ⎤ ⎦ ⎥ ∈SE(2). (4) View Source B. Measurements
    To achieve a good estimation of the poses, not only do we need to apply the sensory
    information but also we need to take advantage of the explicit or implicit constraints.
    Our novelty is mainly in the use of the sensor measurements and the constraints
    associated with the vehicle. 1) Global Matching: We conduct the pose-graph optimization
    once a point-cloud scan from the LiDAR is received. The frequency is about 10
    Hz. The current timestamp of LiDAR scan is denoted with h , and h−1 denotes the
    previous timestamp. The point-cloud scan is matched to the global map using the
    famous G-ICP method [11]. After matching, we obtain a measurement of the global
    tractor pose W T ~ h 0 . We use M 0 to represent the incident of this measurement.
    2) Dynamics Integration Measurements: With the high-frequency measurement of v
    0 and δ , we can tightly integrate the dynamics (1) from h−1 to h . Hence, the
    dynamics integration gives the odometry-like measurements for every unit x i at
    current time h . The measurement is denoted as D i , i∈{0,1,2,3,4} . 3) Geometric
    Constraints: Imposed by the mechanical structure, the inherent geometric relationships
    between the consecutive units in the vehicle remain unchanged during running.
    These geometric constraints are important cues for configuration estimation. We
    denote them with G jk , (j,k)∈{(0,1),(1,2),(2,3),(3,4)} . 4) Bonus Measurement:
    We introduce an extra optional measurement: the relative pose measurement between
    the tractor and the last trailer measured by LiDAR. Although we can already give
    a good estimation of the poses using the above three kinds of measurements, the
    introduction of this measurement further improves the estimation, as shown in
    Section V. The reason is that the additional relative pose measurement helps construct
    a closed-loop pose graph with poses of all the units included, as shown in Fig.
    3. Analogous to the loop-closure constraints in a SLAM system, this measurement
    further refines the estimation. We use a rectangular wooden board mounted on the
    last trailer to facilitate the measurement; see Fig. 9. The relative pose between
    the wooden board and the last trailer is given. The workflow is illustrated in
    Fig. 4. First, the predicted (same as dynamics integration measurement) current
    tractor pose x ~ h 0 and the predicted pose of the last trailer x ~ h 4 are combined
    with the current point cloud S h to find the LiDAR points that are reflected by
    the wooden board. When points belonging to the board are identified, they are
    projected to the same height level and fit with a line segment (see the visualization
    in Figs. 10 and 11) using RANSAC techniques implemented in the point cloud library
    (PCL) [12]. The pose extraction module then determines the pose of the line segment
    by setting the middle point as the position and the norm direction as the heading.
    Finally, the relatively pose measurement 0 T ~ h 4 is obtained. We use L 04 to
    represent the incident of this measurement. In summary, the collection of measurements
    at the current timestamp h is Z={ M 0 , D i , G jk , L 04 }. View Source Fig.
    10. Experimental environment. Show All Fig. 11. Test run with two full trailers
    using the proposed estimation and planning methods. Show All C. Pose Graph and
    MAP Estimation Given the prior configuration X 0 and all the probabilistic measurements
    Z , the goal is to find the optimal MAP estimate X ⋆ , which corresponds to the
    maximum value of the following equation: p(X|Z)∝p( X 0 )p(Z|X). (5) View Source
    Equivalently, X ⋆ is also associated with the minimum of the negative log-posterior
    of (5) [13]. Hence, the configuration estimation problem can be formulated as
    X ⋆ =arg min X − log e p(X|Z)= argmin X C(X) (6) View Source where C(X) is the
    objective function. We represent C(X) using the pose graph [14] as shown in Fig.
    3. Under the assumption of Gaussian noise with zero mean, C(X) can be written
    as the summation of squared residual errors C(X)=∑ ∥ r 0 i ∥ 2 Σ 0 i +∑ ∥ ∥ r
    G jk ∥ ∥ 2 Σ G jk +∑ ∥ r D i ∥ 2 Σ D i + ∥ r M 0 ∥ 2 Σ M + ∥ r L 04 ∥ 2 Σ L (7)
    View Source where r 0 i , r D i , r G jk , r M 0 , and r L 04 are the residual
    errors associated with the measurements or constraints. Σ 0 i , Σ D i , Σ M ,
    Σ G jk , and Σ L are the corresponding covariance matrices that are determined
    empirically. Note that ∥r ∥ 2 Σ = r T Σ −1 r . D. Residual Errors Conceptually,
    a residual error is a function of X that quantifies the mismatch between a measured
    quantity and its expected value computed by the state X and the prior. Expressions
    for the residual errors are provided in this part. Since the configuration is
    well initialized, to compute the current vehicle configuration at time h , the
    poses calculated at h−1 are treated as known and fixed. 1) r D i and r 0 i : The
    dynamics integration is the odometry-like measurement that connects the poses
    of the tractor–trailers’ vehicle between two consecutive timestamps. The known
    poses at time h−1 are denoted with X h−1 , and the associated configuration vector
    is q h−1 . With the given 1500-Hz measurement of v 0 and δ from the encoder, we
    can tightly integrate the system dynamics (1) between h−1 and h (0.1 s) to get
    an measured poses X ~ h ={ x ~ h 0 , x ~ h 1 , x ~ h 2 , x ~ h 3 , x ~ h 4 }:=
    { W T ~ h 0 , W T ~ h 1 , W T ~ h 2 , W T ~ h 3 , W T ~ h 4 } at the current time
    h X ~ h = F n ( ∫ h h−1 J nh (q(t),δ(t)) v 0 (t)dt)+ X h−1 . (8) View Source In
    practical implementation, (8) is numerically integrated with integral step Δt≈0.001
    . To facilitate the computation, the residual error for dynamics integration measurements
    is formulated in the Lie algebra vector form [15] r D i =Log( W T ~ h i ⋅ ( W
    T h i ) −1 ). (9) View Source In this work, we let X 0 = X ~ h . That means the
    pose prior is also set by the measurement of dynamics integration, with r 0 i
    = r D i . Thus, we omit the r 0 i terms in (7). 2) r G jk : The poses of the units
    in the tractor–trailers vehicle are inherently constrained by the mechanical structure.
    As shown in Fig. 2, G 01 and G 23 are the off-axle connection constraints, while
    G 12 and G 34 are the on-axle connection constraints. The residual errors for
    on-axle constraints are formulated as r G 12 = r G 34 = ( x 2 + L 2 cos θ 2 y
    2 + L 2 sin θ 2 )−( x 1 y 1 ) ( x 4 + L 4 cos θ 4 y 4 + L 4 sin θ 4 )−( x 3 y
    3 ) (10) (11) View Source which means the 2-D position of the steer trailer in
    the full trailer is expected to be away from the counterpart nonsteer trailer
    with length L i and in the direction of nonsteer trailer’s heading. The residual
    errors for off-axle constraints are r G 01 = r G 23 = ( x 0 − x 1 y 0 − y 1 )−(
    L 1 cos θ 1 + c 0 cos θ 0 L 1 sin θ 1 + c 0 sin θ 0 ) ( x 2 − x 3 y 2 − y 3 )−(
    L 3 cos θ 3 + c 2 cos θ 2 L 3 sin θ 3 + c 2 sin θ 2 ) (12) (13) View Source with
    r G 23 actually representing the difference between vector v ⃗  2 + v ⃗  3 and
    v ⃗  23 in Fig. 2. r G 01 quantifies, in the same way, the disagreement of the
    off-axle geometric constraint between the first trailer and the tractor. 3) r
    M 0 and r L 04 : The residual errors for the global point-cloud matching and the
    relative pose measurement between the tractor and the last trailer are simply
    formulated as follows: r M 0 = r L 04 = Log( W T ~ h 0 ⋅ ( W T h 0 ) −1 ) Log(
    ( 0 T ~ h 4 ) −1 ⋅ ( W T h 0 ) −1 ( W T h 4 )). (14) (15) View Source For each
    estimation process at the corresponding timestamp, the pose graph is constructed
    and the optimal poses X ⋆ are computed efficiently by solving (6). The open-sourced
    general graph optimization library g2o [16] is applied to solve the least-squares
    problem. The pose-graph optimization is conducted at 10 Hz, while the vehicle
    configuration can be online provided up to 1500 Hz for low-level motion control,
    thanks to the encoder measurements. The results of the configuration estimation
    will be fed into the trajectory planning module. SECTION IV. Online Trajectory
    Planning Given the estimated vehicle configuration, we can then do online trajectory
    planning. Due to the complicated tractor–trailers’ structure, bad tracking performance
    in the execution level may result in the violation of collision-free conditions
    satisfied in the planning level. In this brief, the proposed method focuses on
    generating obstacle-free and dynamically feasible trajectories that, most importantly,
    facilitate the reduction of mismatch between the planned trajectory and the actual
    one. Note that the vehicle always drives forward to avoid the jack-knife phenomenon.
    Fig. 5 shows the framework of the proposed trajectory planning method. The planning
    part is running at 10 Hz. The online trajectory is updated once a new pose-graph
    solution of configuration estimation is computed. A. Waypoint Nudge In industrial
    environments, routes from one spot to another are usually unchanged. Hence, path
    planning can be significantly simplified in our work. We take the given discrete
    waypoint sequence, representing the centerline of the route lanes, in front of
    our tractor as the coarse path. This path needs to be further processed to generate
    obstacle-free and dynamically feasible trajectory. As shown in Figs. 5 and 6,
    the discrete waypoint path is first nudged to get away from the obstacles. The
    2-D coarse waypoint path is denoted with P ′ ={ p ′ 1 , p ′ 2 ,…, p ′ n } , with
    p ′ i =( x p ′ i , y p ′ i ) . p ′ 1 is the nearest 2-D way point away from the
    current tractor position, and n is the planning horizon. The nudged waypoint set
    P ⋆ ={ p ⋆ 1 ,…, p ⋆ n } is achieved by minimizing the following objective function:
    P ⋆ = argmin P ∑ i=1 n ω c ∥ ∥ p i − p ′ i ∥ ∥ 2 + ∑ i=2 n−1 ω s ( p i − p i−1
    )⋅( p i − p i+1 ) ∥ p i − p i−1 ∥∥ p i − p i+1 ∥ + ∑ i ∑ j ω o f( d i j , d min
    j )+ ∑ i ω b f( b i , r v ) (16) View Source where the first term is the quadratic
    distance between the nudged way point and the original one. By minimizing this
    term, the new path is kept close to the old. The second term minimizes the angle
    difference between two consecutive line segments to make the path smoother. The
    third term keeps the waypoint away from the obstacles. f(x,y) is a piecewise-continuous
    and differentiable barrier function defined as f(x,y)= ⎧ ⎩ ⎨ ⎪ ⎪ ( y−(x−ϵ) s 1
    ) s 2 , 0, if x<y+ϵ otherwise . (17) View Source We use a disk with radius r j
    to represent the detected obstacle indexed by j . d i j ( p i ) is the distance
    between the i th waypoint and the center point of the j th obstacle. d min j =
    r v + r j is the minimum distance permitted, lower than which the penalty is in
    effect. r v characterizes the circular clearance area required for the waypoint
    and is determined by the size of the tractor. s 1 , s 2 , and ϵ are tunable parameters.
    For the cases when the boundary is not traversable, the fourth term of (16) is
    imposed. b i is the distance between the waypoint and the polyline-represented
    boundary. ω c , ω s , ω o , and ω b are tunable scalar gains. A similar waypoint
    nudging method can be found in [17]. B. Controller-Based Smoothing The resultant
    n way points after nudging are then connected with line segments to form a piecewise
    linear reference path r , as shown in Fig. 7. r is then fed into the famous pure
    pursuit controller [18] to generate a preliminary tractor trajectory s p using
    forward simulation. s p will be further refined by the designed dynamic controller.
    Fig. 7 shows the geometry of the pure pursuit controller. To track the reference
    path r in front of the tractor, the instantaneous steering angle is given by δ(t)=
    δ p (t)= tan −1 ( 2 L 0 sin(α(t)) l fw ) (18) View Source where l fw is the empirically
    determined look-ahead distance, and α is the angle between tractor’s heading and
    the look-ahead vector. To respect the mechanical steering limits, δ p (t) is numerically
    bounded in (− δ max , δ max ) , with δ max =0.44 for our tractor. We further design
    the longitudinal velocity to respect the maximum speed ( v 0max ) limit and the
    maximum lateral acceleration ( a lat max ) limit. Hence, the longitudinal velocity
    associated with the pure pursuit steering controller is designed as follows: v
    0 (t)= v p (t)=min{ a lat max κ p (t) − − − − − √ , v 0max } (19) View Source
    where κ p is defined by κ p (t)=tan δ p (t)/ L 0 . With the control input (18),
    (19) and the given current tractor pose [ x 0 (0), y 0 (0), θ 0 (0)] from the
    online configuration estimation module (the current time in a trajectory planning
    cycle is denoted as t=0 s), we can numerically propagate the tractor-related dynamics
    in (1) to generate a tractor trajectory s p (t)=[ x p (t), y p (t), θ p (t), v
    p (t)] . The tractor trajectory s p is smooth and respects the steering and velocity
    limits. However, an implicit assumption of s p is that the velocity v 0 and steering
    angle δ of the tractor can change instantaneously to precisely follow the designed
    v p (t) and δ p (t) , respectively. That assumption ignores the steering dynamics
    (2) and velocity dynamics (3). Directly tracking s p in execution can cause unwanted
    mismatch. Therefore, to deliberately facilitate the reduction of mismatch between
    the planned and actual trajectories, we further incorporate dynamics (2) and (3)
    by designing the dynamic controller f v and f s to make the tractor states follow
    s p . The dynamic controller will also be the one applied in the low-level motion
    execution. Hence, by numerically propagating the vehicle dynamics (1)–(3) with
    f s and f v serving as the inputs, the generated trajectory mimics the real-life
    behavior of the actively controlled tractor and thus helping to reduce the trajectory
    tracking errors in real execution. To design f v and f s , we first express the
    tracking errors in the moving Frenet frame attached on s p x e = y e = ( x 0 −
    x p )cos θ p +( y 0 − y p )sin θ p , θ e = θ 0 − θ p −( x 0 − x p )sin θ p +(
    y 0 − y p )cos θ p , v e = v 0 − v p . (20) View Source Computing time derivatives
    and applying the tractor-related dynamics in (1)–(3), we have the following error
    dynamics: x ˙ e = y ˙ e = θ ˙ e = v ˙ e = C ˙ δ = v 0 cos θ e + θ ˙ p y e − v
    p v 0 sin θ e − θ ˙ p x e v 0 C δ − θ ˙ p f v − v ˙ p ( 1 L 0 + L 0 C 2 δ ) f
    s (21) (22) (23) (24) (25) View Source where C δ =tanδ/ L 0 is the curvature of
    the tractor. We further define the two intermediate variables u and d e as follows:
    u= d e = −k x e z 1 −k y e z 2 − k θ θ e + θ ˙ p v p C δ −u (26) (27) View Source
    with gains k, k θ >0 , z 1 =(cos θ e −1)/ θ e , and z 2 =sin θ e / θ e . The control
    laws for f s and f v are finally designed as f s = f v = 1 1 L 0 + L 0 C 2 δ (
    u ˙ − v 0 θ e − k d d e ) v ˙ p − k v v e −k x e + k θ θ 2 e − θ ˙ p v p θ e (28)
    (29) View Source with gains k d , k v >0 . We claim that f s and f v defined by
    (28) and (29) makes [ x e , y e , θ e , v e ]=0 asymptotically stable. That means
    the tractor states [ x 0 , y 0 , θ 0 , v 0 ] asymptotically follow s p . We give
    a brief proof here by choosing the following scalar function V as the Lyapunov
    function candidate: V= 1 2 (k x 2 e +k y 2 e + θ 2 e + v 2 e + d 2 e ). (30) View
    Source Taking the time derivative and applying (21)–(29) yields V ˙ = = k x e
    x ˙ e +k y e y ˙ e + θ e θ ˙ e + v e v ˙ e + d e ( C ˙ δ − u ˙ ) − k θ v r θ 2
    e − k v v 2 e − k d d 2 e ≤0. (31) View Source Hence, we conclude that lim t→∞
    V ˙ =0 , which means lim t→∞ θ e =0, lim t→∞ v e =0, lim t→∞ d e =0. (32) View
    Source Then we investigate how x e and y e behave when V ˙ =0 , i.e., v e = v
    0 − v p =0, θ e = θ 0 − θ p =0, C δ =u. (33) View Source First, v e =0 indicates
    v ˙ e =0 . From (24) and (29), we conclude that x e =0 . Second, θ e =0 tells
    that θ ˙ e =0 . From (23) and (26), we can conclude that y e =0 . Therefore, [
    x e , y e , θ e , v e ]=0 is the only point these four states are stuck at when
    V ˙ =0 . According to LaSalle’s invariance theorem [19], [ x e , y e , θ e , v
    e ]=0 is globally asymptotically stable. Before applying (28) and (29), f s and
    f v are further numerically limited in (− δ ˙ max , δ ˙ max ) and (− v ˙ 0max
    , v ˙ 0max ) , respectively, to reflect the actuation limits in real execution.
    In our case, δ ˙ max =0.31rad/s and v ˙ 0max =1.5 m 2 /s . Finally, with the given
    current configuration q(0) and the measurable v 0 (0) and δ(0) , we generate the
    state trajectory q(t)=[ x 0 (t), y 0 (t), θ 0 (t), β 1 (t), β 2 (t),…, β n (t)]
    , t∈[0, t f ] for the whole tractor–trailers’ vehicle by forward propagating the
    system dynamics (1)–(3) as follows: q(t)= δ(t)= v 0 (t)= ∫ t f 0 J nh (q(t),δ(t))
    v 0 (t)dt+q(0) ∫ t f 0 f s (t)dt+δ(0) ∫ t f 0 f v (t)dt+ v 0 (0) (34) View Source
    where t f is the temporal horizon. The resultant trajectory q(t) can be efficiently
    computed. It takes consideration of the vehicle dynamical behaviors in real execution,
    and hence, it is dynamically feasible by construction. C. Collision Check and
    Obstacle Redefine To ensure that the planned trajectory is obstacle-free, q(t)
    is sampled with constant resolution from 0 to t f for collision check. At each
    sampling point, poses of the tractor and all the trailers are checked against
    obstacles. As shown in Figs. 8 and 10, we use the two-disk representation to approximate
    the rectangular-shaped tractor and the full trailers. r i is determined to just
    cover the four vehicle corners. We simply investigate distances between the vehicle
    disks and the obstacle disks. For each sampled configuration q( t ⋆ ) at a future
    time t ⋆ , the collision-free condition is d i j ( t ⋆ )≥ r i + r j & b i ( t
    ⋆ )≥ r i ,i=0, 0 ′ ,1,2… View Source The second condition needs to be satisfied
    when there are untraversable road boundaries. If the obstacle-free conditions
    are satisfied at all the sampled points, the planned trajectory q(t) is the final
    vehicle trajectory, and the associated tractor trajectory [ x 0 (t), y 0 (t),
    θ 0 (t), v 0 (t)] is then passed to the low-level controller for execution. One
    can refer to [4] for details of motion execution. Essentially, the controllers
    (28) and (29) derived in this brief are also applied in the low-level control.
    On the other hand, the collision-free conditions may sometimes be violated at
    some sampling point. We handle this issue by simply adding virtual disk obstacles
    at the collision point, and the associated disk radius is set equal to the collision
    depth, as shown in Fig. 8. After placing the virtual obstacles, we discard the
    old planned trajectory and start over again to nudge the waypoint path against
    the new obstacle set. After again going through the pipeline shown in Fig. 5,
    we get a new trajectory for collision check. These procedures are conducted iteratively
    until a collision-free trajectory is found. SECTION V. Implementation Results
    A. Setup We implement the proposed configuration estimation and trajectory planning
    algorithms on the full-scale industrial tractor towing multiple full trailers,
    as shown in Figs. 11 and 15. Fig. 9 shows the experimental setup. Both the tractor
    and full trailers are standard models that have been in operation at many airports
    and big warehouses around the world. The diesel tractor is the Toyota 52-2TD25
    model. We retrofit the tractor by installing external motors to automatically
    actuate the throttling, braking, and steering in a position-based manner. The
    dimensions of the tractor and the trailers are given. Fig. 12. Pose estimation
    errors of the tractor in the run with two full trailers. Show All Fig. 13. Pose
    estimation errors of trailer 2 in the run with two full trailers. Show All Fig.
    14. Tracking errors of the tractor with our planner versus TEB planner. Show All
    Fig. 15. Test run with three full trailers. Show All We use three HEIN LANZ encoders
    and one 3-D LiDAR Velodyne VLP-16 for configuration estimation and trajectory
    planning. The Xsens MTi-300 IMU and the force sensor are mounted for motion control,
    which essentially implements the controller (28) and (29) [4]. To evaluate the
    performance of configuration estimation, we apply an integrated ultra-wideband
    (UWB) system (fusing UWB, IMU, and wheel encoders) to provide “ground-truth” positioning
    of the tractor. Besides, as shown in Fig. 9, we mount a data collection platform
    to serve as another localization system to provide “ground-truth” poses of the
    corresponding beneath trailer. The data collection platform uses a LiDAR, an IMU,
    several cameras, and prebuilt map to do localization. The wooden board mentioned
    in Section III is mounted at the last trailer to improve localization. The vehicle
    is initialized in a lined-up configuration (see Fig. 10 for example), where all
    the hitch angles are approximately zero. Thanks to the open-loop stability [7],
    the initialization can be easily achieved by driving along a straight line until
    the trailers automatically align shortly. B. Experimental Environment As shown
    in Fig. 10, we conduct the experiments inside a big warehouse. The roundabout
    route is adopted to imitate the real-world industrial routes for cargo transportation.
    The point-cloud map and the discrete centerline waypoint path are given. Lane
    boundaries are traversable as in many industrial scenarios. Two different obstacles
    will be placed in the way to test obstacle avoidance. The visualization ratio
    is 1:1. C. Test Run With Two Full Trailers We first connect two identical full
    trailers behind the tractor and conduct a test run around the experimental route
    with obstacles in the way. Fig. 9 exactly depicts the setups in this part. We
    investigate the performance of configuration estimation by comparison against
    the “ground truth.” Fig. 11 shows the complete process of the test run with our
    proposed estimation and planning algorithms. The planned velocity is 1 m/s during
    the whole running, since we set v 0max =1m/s . The duration is set to be 110 s.
    As shown in Fig. 9, the data collection platform is mounted to provide ground-truth
    poses of the second trailer ( x 2 ). We can see from Fig. 11 that the obstacle-free
    trajectories are successfully achieved and the vehicle conducts a smooth running
    and perfectly avoids the two obstacles. One can refer to the attached video for
    detailed running process. In the video, the online planned trajectories and the
    estimated configurations are all visualized in real-time. In Section III, we introduce
    a bonus relative-pose measurement between the tractor and the last trailer by
    installing a wooden board. In this test run, we use two synchronous computing
    threads to conduct configuration estimation with and without the bonus measurements,
    respectively. Note that the planning part adopts the better estimation results
    with the bonus measurements. Figs. 12 and 13, respectively, show the pose estimation
    errors (with and without the wooden board measurement) of the tractor and the
    second trailer during the test run. The position error is the positive distance
    between the estimated 2-D position and the ground-truth position. The heading
    error is the scalar difference between the estimated and ground-truth orientation.
    As shown in Fig. 12, the biggest position estimation error for the tractor is
    around 0.08 m, and the heading error is smaller than 0.06 rad during the whole
    test, which presents satisfactory pose estimation performance. The introduction
    of the bonus measurement makes little difference for the tractor pose estimation.
    That is because we set Σ M and Σ D 0 much smaller due to the higher accuracy expectation.
    The corresponding global matching and the dynamic integration measurements have
    constrained the tractor pose so tightly that other constraints brought by trailers
    cannot impose any influence. As shown in Fig. 13, when incorporating the bonus
    measurement, the biggest position error for trailer 2 is around 0.1 m and the
    biggest heading error is about 0.07 rad, which also represents satisfactory pose
    estimation performance. However, for the case without wooden board measurements,
    both the position and heading errors grow obviously (about 15%). That means the
    closed-loop pose graph (see Fig. 3) constructed with the bonus measurement can
    significantly improve the pose estimation accuracy for the trailers behind. Note
    that here we indeed take trailer 2 as a representative for evaluation of trailer
    pose estimation. Due to the constraints and measurements in our proposed estimation
    scheme, we can reasonably assume that other trailers have similar pose estimation
    accuracy. To demonstrate the superiority of our planning algorithm in reducing
    the trajectory tracking errors, we compare our approach against the open-sourced
    state-of-the-art timed elastic band (TEB) online trajectory planner [20], which
    can also plan dynamically feasible and obstacle-free trajectories. We further
    conduct two comparative test runs with two full trailers using our planner and
    the TEB trajectory planner, respectively. Apart from the planning part, all other
    settings (such as the configuration estimation scheme, the low-level motion controller,
    the start point, the route, the obstacles, and the duration) are the same in the
    two runs and are same with the test run illustrated in Fig. 11. Since both of
    them are online planners with the planned trajectories starting from the real-time
    estimated configurations, the nonzero trajectory tracking errors exist between
    two consecutive planning instants. Therefore, to better illustrate the difference,
    in this two test runs, the motion planning is performed every 10 s, which means
    the frequency is 0.1 Hz (normally the frequency is 10 Hz as mentioned). Fig. 14
    shows the trajectory tracking errors of the lead tractor with the two planners.
    The estimated pose of the tractor is used to calculate the errors. We can see
    that the tracking performance using both the planners is satisfactory, which shows
    the good performance of our motion controller [4]. However, with the same configuration
    estimator and the same motion controller, the tractor has obviously smaller trajectory
    tracking errors when executing the trajectories provided by our planner than executing
    trajectories generated by the TEB planner. Considering the tracking errors of
    the tractor, similarly, we can also expect smaller trajectory tracking errors
    occurred on the trailers with our planner. D. Test Run With Three Full Trailers
    To further verify the configuration estimation performance, we connect three full
    trailers and conduct another roundabout test run, as shown in Fig. 15. The data
    collection platform is also mounted on trailer 2. The wooden board is installed
    on the trailer 6, and the bonus measurement is used. Figs. 16 and 17, respectively,
    show the pose estimation errors of the tractor and trailer 2. Comparing Figs.
    12 and 16, the pose estimation for the tractor has similar accuracy in cases with
    two and three full trailers, whose reason has been mentioned. Comparing Figs.
    13 and 17, it is observed that with one more full trailer, the pose estimation
    errors of trailer 2 increases. The reason for the reduced accuracy is the extended
    distance between the tractor and the last trailer due to existence of the additional
    full trailer. The increasing distance undermines the accuracy of detecting and
    fitting of the wooden board, and thus deteriorating the relative pose measurements.
    Therefore, we expect to have larger estimation errors for trailers when more full
    trailers are towed behind. Fig. 16. Pose estimation errors of the tractor with
    three full trailers. Show All Fig. 17. Pose estimation errors of trailer 2 in
    the run with three full trailers. Show All SECTION VI. Conclusion To enable autonomous
    driving of the industrial tractor-trailers’ vehicle, this brief has presented
    real-time configuration estimation and online trajectory planning for the system.
    Implementations on the full-size vehicle were conducted, and industrially satisfactory
    performance was achieved. The tractor and trailers are precisely localized by
    fusing information from system dynamics propagation, geometric constraints between
    trailers, and global matching of the point-cloud measurement with the environment
    map. The solution is efficiently achieved by formulating and solving an MAP estimation
    problem in the pose-graph optimization framework. Our proposed motion planning
    method mainly focused on reducing the mismatch between planned trajectories and
    actual trajectories, which is crucial for the complicated-structure vehicle to
    travel in industrial scenarios without colliding into obstacles. A controller-based
    smoothing method was proposed to generate trajectories that mimic the state evolving
    process in real motion execution. The planned obstacle-free trajectories are efficiently
    computed and are dynamically feasible by construction. Authors Figures References
    Citations Keywords Metrics More Like This A real-time system based on a neural
    network model to control hexacopter trajectories 2014 International Symposium
    on Power Electronics, Electrical Drives, Automation and Motion Published: 2014
    Estimation of velocity and distance measurement for projectile trajectory prediction
    of 2D image and 3D graph in real time system 2017 International Conference on
    Energy, Communication, Data Analytics and Soft Computing (ICECDS) Published: 2017
    Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT
    OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES
    PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678
    4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact
    Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics
    Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE
    is the world''s largest technical professional organization dedicated to advancing
    technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: IEEE Transactions on Control Systems Technology
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Localization and Motion Planning of Industrial Tractor-Trailers Vehicles
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Zhu Z.
  - Lu J.
  - Zhu S.
  citation_count: '0'
  description: In this paper, a novel dynamic response reconstruction method based
    on multi-rate Kalman filtering (MRKF) is presented. The proposed method starts
    with representing the structural system by the state-space equation. Then, different
    observation equations are defined, and that selection is based on the availability
    of sensor types at a specific time. Not only can the multi-type sensor data sampled
    at different rates be fused directly, but the presented method also relaxes the
    collocated monitoring requirement. In addition, future observations are used to
    benefit the current state estimation by the Rauch, Tung, and Striebel smoothing
    procedure. The unobserved structural dynamic responses are estimated using the
    MRKF virtual sensing technique with multi-rate sensor data. Several demonstrative
    numerical tests are performed to verify the superiority and robustness of the
    presented MRKF method on one benchmark shear frame model. The experimental test
    employed a computer-vision-based displacement tracking technique. Results show
    that the proposed method surmounts the obstacle to deploying consumer-grade cameras
    in structural health monitoring applications, which provide a low-cost sensing
    solution without sacrificing response estimation accuracies.
  doi: 10.1016/j.engstruct.2023.116573
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords 1. Introduction 2. Mathematical formulation
    3. Numerical examples 4. Experimental validation 5. Conclusions CRediT authorship
    contribution statement Declaration of Competing Interest Acknowledgement Data
    availability References Show full outline Figures (12) Show 6 more figures Tables
    (9) Table 1 Table 2 Table 3 Table 4 Table 5 Table 6 Show all tables Engineering
    Structures Volume 293, 15 October 2023, 116573 Multi-rate Kalman filtering for
    structural dynamic response reconstruction by fusing multi-type sensor data with
    different sampling frequencies Author links open overlay panel Zimo Zhu, Jubin
    Lu, Songye Zhu Show more Share Cite https://doi.org/10.1016/j.engstruct.2023.116573
    Get rights and content Highlights • Developed a multi-rate dynamic response reconstruction
    method, termed MRKF. • Fusion of multi-type sensor data sampled at different rates.
    • Overcome the long-existing limitation of traditional single-rate Kalman filtering.
    • Improve virtual sensing accuracy using future observations and RTK smoothing.
    • Enable the application of consumer-grade cameras in structural health monitoring.
    Abstract In this paper, a novel dynamic response reconstruction method based on
    multi-rate Kalman filtering (MRKF) is presented. The proposed method starts with
    representing the structural system by the state-space equation. Then, different
    observation equations are defined, and that selection is based on the availability
    of sensor types at a specific time. Not only can the multi-type sensor data sampled
    at different rates be fused directly, but the presented method also relaxes the
    collocated monitoring requirement. In addition, future observations are used to
    benefit the current state estimation by the Rauch, Tung, and Striebel smoothing
    procedure. The unobserved structural dynamic responses are estimated using the
    MRKF virtual sensing technique with multi-rate sensor data. Several demonstrative
    numerical tests are performed to verify the superiority and robustness of the
    presented MRKF method on one benchmark shear frame model. The experimental test
    employed a computer-vision-based displacement tracking technique. Results show
    that the proposed method surmounts the obstacle to deploying consumer-grade cameras
    in structural health monitoring applications, which provide a low-cost sensing
    solution without sacrificing response estimation accuracies. Previous article
    in issue Next article in issue Keywords Structural health monitoringResponse reconstructionVirtual
    sensingMulti-rate Kalman filteringSensor data fusionSmoothing 1. Introduction
    Structural health monitoring (SHM) techniques have flourished and matured over
    the past decades; and have been successfully deployed in various structures [1],
    [2], [3], [4], [5]. One of the prime objectives of SHM is to record structural
    responses and provide useful information for structural health condition assessment.
    For example, accelerations in wide frequency and amplitude ranges can be recorded
    by accelerometers with a relatively high sampling rate. Dynamic displacements
    are related to structural deformation, providing direct information on structural
    condition assessment. Although, theoretically, displacement can be calculated
    by double integrating acceleration signals, the results are generally unreliable
    because of errors accumulated during integration. In particular, quasi-static
    displacement cannot be calculated through this method. Consequently, a comprehensive
    SHM-oriented sensing system is commonly equipped with multi-type sensors to obtain
    accurate structural responses. Sensors are typically installed on hotspots to
    assess structural health conditions efficiently. A densely distributed sensor
    network will increase budget and deployment difficulties. Structural response
    reconstruction techniques (also known as virtual sensing techniques), which aim
    to provide full-field structural response estimations through partial sensor observations,
    have been widely explored in SHM. Early-stage response reconstruction algorithms
    were performed in the frequency domain, such as the transmissibility-based methods
    [6], [7]. Recent research efforts have been more dedicated to the time domain
    methods. Response reconstruction based on empirical mode decomposition (EMD) is
    one example in the time domain. He et al. [8] presented the EMD method with intermittency
    criteria and transformation equations derived from a finite element model. The
    inverse optimization-based method is another method in the time domain, wherein
    the reconstruction problem is defined as an inverse optimization problem subject
    to constraints [9]. However, representing complex structures using simple functions
    is ambiguous, otherwise the computational cost is scarcely affordable for real-world
    civil structures. More virtual sensing algorithms have been proposed recently,
    such as the Bayesian method by Kullaa [10] and the multi-resolution analysis by
    Saltari et al. [11]. Meanwhile, structural response reconstruction algorithms
    with affordable computational requirements have a promising future. Specifically,
    Kalman filter (KF) based methods have undergone extensive research. KF proposed
    in 1960 [12] can provide a least-square unbiased estimation based on noisy observations.
    KF estimates structural responses through partial observations. A multi-scale
    KF-based response reconstruction algorithm was presented by Zhu et al. in 2013
    [13]. By representing the state space equation in modal coordinates, high vibration
    modes can be truncated to simplify the calculation [14] and reduce state estimation
    errors [15] for MDOF structures. Extended KF (EKF) considers the nonlinearities
    in structural systems and can be regarded as a nonlinear version of KF. Lei et
    al. [16] presented an adaptive EKF approach to track changes in structural parameters.
    Furthermore, structural identification and control through partial observation
    were achieved in tandem by EKF [17]. When the external input is unknown, most
    current algorithms [18], [19], [20] are based on the filters proposed by Gillijns
    and De Moor [21], [22]. The availability and number of accelerometers determine
    the rank of the feedthrough matrix in the state-space equation, and a corresponding
    response reconstruction filter shall be selected according to that rank. Current
    response reconstruction algorithms usually need multi-type sensors to guarantee
    the state estimation accuracy. The direct fusion of different types of sensing
    signals may be challenging. Zhang et al. [23], [24] solved the matrix illness
    problem encountered during multi-type sensor data fusion by KF iterations. Zhang
    and Xu [25] extended this method to response reconstruction under unknown input.
    The number and spatial arrangements of multi-type sensors were decided by adding
    the optimal sensor that minimized the estimation error of reconstructed responses.
    Li et al. [26] adopted the multi-scale attention-based neural network for sensor
    location selection, and the seismic response can be predicted. Nearly all the
    existing research regarding multi-type sensors in response reconstruction focused
    on optimizing sensor numbers and locations, assuming that all sensors have the
    same sampling frequency. The measurement of structural displacement is a preordained
    but exigent task. As aforementioned, displacement could not be reliably estimated
    by integrating acceleration signals, and thus obtaining accurate displacement
    responses is genuinely challenging. Therefore, direct displacement measurement
    using various displacement sensors is conventionally adopted in the current SHM
    sensing system. Depending on sensor installation methods, displacements can be
    measured in two ways. The first is the direct-contact displacement measurement
    using linear variable differential transducers (LVDTs), potentiometers, etc. These
    types of sensors measure relative displacements between two ends. Measuring absolute
    displacements requires a fixed platform/frame installed near the tested structure,
    which could be difficult, if not impractical, in a real structure. Thus, contact
    displacement sensors are more suited to small-scale testing in a laboratory environment.
    The other alternative is non-contact displacement sensing, including GPS, laser
    displacement sensors, radar interferometry systems, and the newly developed computer-vision-based
    displacement tracking techniques. These sensors can record structural displacement
    without direct contact with a structure. Therefore, the measurement is more accessible
    than the contact type. One of the major problems of the non-contact displacement
    sensors is their low sampling rate compared with accelerometers. Most of the survey-grade
    GPS receivers used in SHM operate between 1 and 10 Hz [27]. With the recent advance
    in computer-vision techniques, displacement measurement using high-speed cameras
    is a propitious trend. Common methods include optical flow methods [28], template
    matching methods [29], and feature matching techniques [30]. Some high-speed cameras
    can have a frame rate of up to 1000 fps with high precision, but the price is
    barely affordable in civil SHM projects. The sampling frequency for standard consumer-grade
    cameras is usually 30 fps–60 fps. These sampling frequencies are generally much
    lower than those of accelerometers. How to combine multi-type sensor data sampled
    at different frequencies is challenging. Recently, some researchers have set sights
    on multi-rate sensor data fusion for improving displacement measurement accuracies.
    Smyth and Wu [31] presented a multi-rate KF approach to combine displacement and
    acceleration data collected simultaneously with different sampling frequencies
    to estimate structural displacement responses. Given that displacement signals
    were sampled at a lower frequency than the acceleration signals, the measurement
    update in KF would be conducted when displacement data were available. Otherwise,
    only the time update was carried out. A smoothing step was also adopted to improve
    accuracy. The laboratory test for data fusion of acceleration and computer-vision-based
    displacement sensing was completed by Chang and Xiao in 2010 [32]. This algorithm
    was further applied by Zhu et al. [33] in 2020 to beam-like tall buildings for
    data fusion of strain and acceleration data. Kim et al. [34] presented the autonomous
    state estimation technique considering acceleration measurement bias to enhance
    the computation efficiency and facilitate online monitoring. A two-stage KF was
    adopted, and the convergence rate of the gain matrix KF was improved compared
    with the previous algorithm [31]. The method was improved by defining the state
    vector using acceleration bias and integration error [35], and dynamic displacement
    can be estimated accordingly. By assuming the acceleration bias as the input vector
    to be estimated, Zheng et al. [36] presented an algorithm for dynamic displacement
    estimations based on KF. Ma et al. [37] developed an asynchronous data fusion
    technique to improve displacement estimation accuracies. Notably, all the abovementioned
    studies were designed for a single-degree-of-freedom (SDOF) system, wherein the
    displacement and acceleration were measured at a single point to improve displacement
    measurement accuracy. The response reconstruction for MDOF systems by fusing multi-type
    sensors sampled at different frequencies remains unexplored. Despite recent progress
    in multi-type sensor data fusion, combining the multiple sampling rate data in
    dynamic structural response reconstruction remains to be addressed. The past investigations
    have several limitations: (1) Existing algorithms are designed to improve displacement
    measurement accuracies for an SDOF system with both accelerometer and displacement
    sensors installed. In practical SHM, the collocated installation of multi-type
    sensors is not always available. (2) Structural dynamic response reconstruction
    for unmonitored locations by fusing multi-rate sensor data has not been the subject
    of previous research. The existing techniques can be considered a model-free method
    to improve displacement measurement accuracy without considering structural dynamic
    properties. Therefore, response reconstruction through partial sensor observations
    is beyond the bounds of the possibility of these existing techniques. This paper
    proposes a state-of-the-art multi-rate Kalman (MRKF) filtering technique for multi-type
    multi-rate sensor data fusion in structural dynamic response reconstruction. Data
    sampled at different rates, such as acceleration and displacement, are fused via
    two sets of observation equations. The partially observed MDOF system is allowed,
    and the unobserved responses will be estimated through the KF virtual sensing
    technique. The collocated installation requirement is relaxed in the proposed
    algorithm. By proposing the first structural response reconstruction algorithm
    with multi-rate sensor data fusion, this new method will provide a low-cost sensing
    solution by deploying consumer-grade cameras in real SHM projects. The structure
    of this paper is organized as follows. The mathematical formulation of the algorithm
    is first presented, including the state-space equation, KF, MRKF, and Rauch, Tung,
    and Striebel (RTS) smoother. The numerical simulation of a benchmark eight-story
    frame is subsequently discussed. The experimental laboratory validation is presented
    on the basis of a cantilever beam and computer-vision-based displacement measurement
    using an iPhone. The response reconstruction performance and effectiveness are
    further examined. 2. Mathematical formulation 2.1. State-space equation For a
    linear structural system with DOFs, the equation of motion is frequently expressed
    as a second-order differential equation: (1) where , , and are the nodal acceleration,
    velocity, and displacement vectors, respectively. Structural dynamic responses
    depend on external loads, mass matrix , damping matrix , and stiffness matrix
    . These matrices are commonly used to model the dynamics of a structure mathematically.
    Formulating and solving this equation enables us to predict and analyze the dynamic
    response of the structure subject to various dynamic excitations. is the spatial
    distribution matrix for the external load , and its nonzero entries correspond
    to the DOFs with the load. By augmenting structural nodal displacement and velocity,
    the state vector can be written as . The equation (1) can therefore be rewritten
    in a first-order differential form: (2) (3) Equation (2) is the state equation,
    in which is the system matrix, and is the input matrix. The subscript c stands
    for continuous time. The observation equation (3) is expressed by the output influence
    matrix , and the input feedthrough matrix . Without loss of generality, we can
    consider that the observation vector includes structural displacements, velocities,
    and accelerations measured at selected DOFs, which can be obtained on the basis
    of the spatial selection matrices , , and , respectively. These selection matrices
    are Boolean matrices including 0s and 1s only, where 0 represents false (no sensor
    at this DOF) and 1 represents true (with a sensor at this DOF). The dimensions
    of these selection matrices are determined by the numbers of sensors and structural
    DOFs. (4) Therefore, the state-space matrices can be written as (5) (6) where
    the input feedthrough matrix in the observation equation is nonzero only if accelerations
    are measured. In SHM applications, structure responses are digitalized by a data
    acquisition system with prespecified sampling frequencies. The continuous state-space
    model in equations (2), (3) should be transferred into discrete difference equations
    to facilitate numerical calculation. Given a sampling interval , the discrete
    state-space model reads as follows: (7) (8) The discrete system matrix and input
    matrix are calculated by the following: (9) (10) Assuming zero-order-hold (ZOH)
    for external input , the discrete output influence matrix , and the discrete input
    feedthrough matrix . System error and measurement noises are assumed as independent
    normally-distributed white noises. The noise matrices are defined by the system
    error covariance matrix and measurement noise error covariance matrix . 2.2. Kalman
    filtering KF is an unbiased estimator based on the least-square technique considering
    system and measurement uncertainties. The KF calculation includes two steps: the
    time update and the measurement update of the state vector. Through these two-step
    recursive iterations, the minimum-variance unbiased state estimation could be
    obtained. Time update of state vector (11) (12) Measurement update of state vector
    (13) (14) (15) where refers to the covariance matrix of the state estimation error,
    and is the Kalman gain matrix. 2.3. MRKF with RTS smoother Considering a representative
    case in SHM, the observation vector includes displacement and acceleration measurements,
    and their sampling frequencies are SF_acc and SF_dis, respectively. Usually, the
    sampling frequency of the accelerometers is several times that of the displacement
    sensors. Therefore, we define N = SF_acc/SF_dis. That is, at a certain time point
    k, only acceleration measurement is available. Based on the availability of displacement
    measurement, two sets of observation vectors are defined as follows: (16) (17)
    where includes both displacement and acceleration measurements, and and are the
    selection matrices for displacement and acceleration measurements, respectively.
    The observation equation in equation (8) can be rewritten as follows: (18) (19)
    where , , , and . The time update of state vector equations (11), (12) will be
    conducted for each time step k. If only acceleration observation is available,
    the measurement update of the state vector will be conducted on the basis of equation
    (18). Otherwise, equation (19) will be adopted. The smoothing process is generally
    used in offline calculations, where future measurements beyond the current time
    point are used to generate a better state estimation. The RTS smoother was proposed
    by Rauch, Tung, and Striebel in 1965 [38] and is a commonly-used fixed-interval
    smoother. The interval for RTS smoothing shall be pre-defined. When is small,
    the RTS smoother is nearly online. However, shall be long enough for the smoother
    to obtain stable results. Thus, should be determined in consideration of computational
    accuracy and time delay. Given the state estimation up to time tt, for k = tt −
    to k = tt − 1, the smoothing process is accomplished by first initializing the
    state vector and covariance matrix , where the subscript f refers to the forward
    KF calculated using equations (11), (12), (13), (14), (15), (16), (17), (18),
    (19). The optimized state estimation after the RTS smoothing can be obtained by
    conducting another backward KF iteration from k = tt − 1 to k = tt − . The calculation
    steps for RTS smoothing are presented in equations (20), (21), (22), (23). (20)
    (21) (22) (23) Table 1 summarizes the detailed iteration steps. Table 1. MRKF
    with RTS smoothing. 3. Numerical examples 3.1. Eight-story shear frame model This
    section adopts the eight-story shear frame presented by Callafon et al. [39] and
    Azam et al. [40] to verify the capability and robustness of the proposed algorithm.
    As shown in Fig. 1, the 2-D frame has a uniform floor mass of 625,000 kg. The
    lateral story stiffness provided by two columns is 106 kN/m. The damping ratio
    is 2 % for all modes. Table 2 presents the undamped natural frequencies of this
    frame. Download : Download high-res image (114KB) Download : Download full-size
    image Fig. 1. Overview of the eight-story 2D shear frame. Table 2. Undamped natural
    frequencies of the eight-story frame. Mode No. 1 2 3 4 5 6 7 8 Frequency (Hz)
    1.17 3.48 5.67 7.67 9.41 10.83 11.87 12.52 3.2. Baseline analysis As aforementioned,
    accelerometers in SHM usually operate at high frequencies to capture the structure’s
    high-order modes, and thus the sampling frequencies shall be determined according
    to the tested structure’s natural frequencies; whereas displacements are commonly
    measured at relatively lower sampling frequencies (1–10 Hz for traditional GPS
    and 30–60 Hz for consumer-grade cameras). Therefore, in the baseline numerical
    case, data fusion for 100 Hz acceleration and 5 Hz displacement measurement is
    conducted. Three displacement sensors and three accelerometers are installed along
    the frame height, as shown in Fig. 1. Table 3 presents six different fusion schemes
    considered to verify the filter performance. Schemes 1 and 2 are designed to reconstruct
    structural responses by only one sensor type. Schemes 3 and 4 are traditional
    data fusion techniques based on a single sampling frequency, wherein Scheme 3
    uses the low sampling frequency of the displacement measurements. Scheme 5 presents
    the proposed MRKF algorithm without the RTS smoother, whereas Scheme 6 presents
    the performance of the MRKF with the RTS smoother. Notably, Schemes 1–4 are not
    designed for multi-rate data fusion; thus, the traditional KF can be applied.
    MRKF algorithm have to be adopted in Schemes 5 and 6. Table 3. Detailed information
    of comparison schemes. Scheme Sampling frequency (Hz) Acceleration Displacement
    1 Acceleration only 100 N/A 2 Displacement only N/A 5 3 Single rate (low) 5 5
    4 Single rate (high) 100 100 5 MRKF 100 5 6 MRKF + RTS 100 5 In this baseline
    case, the excitation applied on DOF2 has a frequency range of 0.01–20 Hz, whereas
    that on DOF8 has 20–50 Hz. The amplitude is 2000 kN for both excitations. The
    excitation frequency range is designed to cover the natural frequencies of the
    shear frame. Collocated monitoring is adopted in this baseline numerical case.
    Accelerations and displacements are installed on DOF2, DOF5, and DOF8. In this
    simulation, the measurement noise and system noise are calculated in consideration
    of the variance of the structural responses. Random measurement noise, whose standard
    deviation is calculated as 5 % of the response standard deviation, is added to
    the theoretical responses to obtain noise-corrupted observations. The measurement
    noise covariance matrix is obtained on the basis of . Similarly, the system noise
    covariance matrix is also calculated on the basis of 5 % of the standard deviation
    of state vectors. The RTS interval is assumed as 5 in this baseline analysis,
    which means RTS smoothing is conducted for every 5 displacement observations.
    Fig. 2 compares the time histories of the reconstructed displacement responses
    using different schemes. At DOF1, DOF3, DOF4, DOF6, and DOF7, neither displacement
    nor acceleration is monitored, and the responses are estimated from response reconstruction.
    Scheme 2 (i.e., response reconstruction by displacement only) fails to produce
    reasonable results. This failure happens because the discretization of the system
    matrix and the input matrix are based on the sampling interval , as presented
    in equations (9), (10). Low sampling frequency leads to inaccuracies in the discretization
    process (e.g., in and matrices) and losses the ability to track high-frequency
    structural responses. The same explanation holds for the results of response reconstruction
    in Scheme 3 using a single low sampling rate. Scheme 1 uses acceleration observations
    only, and thus the displacement estimation obtained has relatively large errors.
    The remaining three schemes (Schemes 4–6) have competitive performances. Scheme
    4 has the best performance among different schemes because of its high sampling
    rates in both acceleration and displacement measurements. Since Scheme 5 uses
    much less available displacement measurements in MRKF than Scheme 4, the former
    exhibits larger estimation errors than the latter. However, after the RTS smoothing
    procedure, the reconstruction errors are reduced effectively in Scheme 6 because
    more future observations are used in the current estimations. Fig. 3 illustrates
    the reconstructed time histories of the acceleration and velocity responses at
    DOF7 using different schemes, wherein only 2-s duration is presented to illustrate
    the comparison clearly. Fig. 4 shows the corresponding reconstruction errors compared
    with the real value. The proposed MRKF algorithm with RTS smoothing (i.e., Scheme
    6) can achieve satisfactory response reconstruction results and substantially
    reduce the errors, compared with the results based on one sensor type (i.e., Schemes
    1 and 2) and single low sampling frequency data fusion (Scheme 3). The MRKF algorithm
    alone (Scheme 5) can estimate acceleration responses accurately; however, its
    reconstructed displacements exhibit apparently larger errors than Scheme 4, because
    of the low sampling rate in displacement observations in Scheme 5. After RTS smoothing,
    the response reconstruction accuracy has been considerably improved in Scheme
    6, especially for the displacement reconstruction. The performance of MRKF + RTS
    (Scheme 6) is nearly the same as the traditional data fusion with high sampling
    frequencies for both acceleration and displacement (i.e., Scheme 4). Download
    : Download high-res image (1015KB) Download : Download full-size image Fig. 2.
    Reconstructed displacement results at verification DOFs in the numerical baseline
    case (a) DOF1, (b) DOF3, (c) DOF4, (d) DOF6, and (e) DOF7. Download : Download
    high-res image (559KB) Download : Download full-size image Fig. 3. Response reconstruction
    results at DOF7 in the numerical baseline case: (a) acceleration and (b) velocity.
    Download : Download high-res image (954KB) Download : Download full-size image
    Fig. 4. Comparison of reconstruction errors at DOF7 in the numerical baseline
    case: (a) acceleration, (b) velocity, and (c) displacement. Fig. 5 presents the
    acceleration reconstruction results in the frequency domain at DOF7. Except Scheme
    2 (i.e., displacement only) and Scheme 3 (i.e., single rate low), all other schemes
    can successfully capture the first two natural frequencies of the frame. However,
    more oscillations are observed in the reconstructed spectra by Scheme 1 (i.e.,
    acceleration only) and Scheme 5 (MRKF algorithm), especially in the range of 0–10 Hz.
    After RTS smoothing, the proposed Scheme 6 show comparable performance with Scheme
    4, both of which agree well with the true value. The multi-rate sensor data fusion
    technique in structural response reconstruction deserves further research efforts.
    Download : Download high-res image (195KB) Download : Download full-size image
    Fig. 5. Comparison of the reconstructed acceleration results in the frequency
    domain at DOF7 in the numerical baseline case. Normalized root mean square error
    (NRMSE) is adopted as the performance indicator in the quantitative comparison
    of the filter performance. Root mean square error (RMSE) is calculated first to
    assess the accuracy of state estimation compared with real response . (24) NRMSE
    is further defined to facilitate comparing different DOFs and scenarios. The RMSE
    is normalized by the difference between maximum and minimum values to obtain NRMSE
    in this paper. A smaller NRMSE indicates higher precision. (25) Table 4 shows
    the steady-state NRMSE for displacement obtained by different schemes (as described
    in Table 3) in this baseline analysis. Response reconstruction by displacement
    only (Scheme 2) has the worst performance because of the discretization problem.
    The failure of response reconstruction by a single rate (low) (Scheme 3) proves
    that the down-sampling-based data fusion technique is problematic, though it is
    a common practice when signals are sampled at different frequencies. It is unsurprising
    that the single rate (high) (Scheme 4) generally has the best accuracy because
    both accelerations and displacements are sampled at 100 Hz. In comparison, the
    proposed MRKF algorithm with RTS (Scheme 6) has extremely competitive performances
    for most of the DOFs, which implies that a high sampling frequency of displacement
    observation is unnecessary given the proposed MRKF. Notably, the responses at
    DOF2, DOF5, and DOF8, are directly measured by displacement sensors and accelerometers.
    The NRMSEs for the displacements at these three DOFs are 1.323 %, 1.168 %, and
    0.841 %, respectively, which are even lower than measurement noise. Thus, the
    estimated displacements at three DOFs are more accurate than the direct measurements
    by sensors. Table 4. Steady-state NRMSE for displacement obtained by different
    schemes in the numerical baseline case. Scheme NRMSE for displacement (%) DOF1
    DOF2a DOF3 DOF4 DOF5a DOF6 DOF7 DOF8a 1 Acc only 2.863 2.190 2.843 3.303 3.468
    3.639 3.499 3.135 2 Dis only 22.60 23.94 28.13 31.39 30.37 33.30 32.67 29.01 3
    Single rate (low) 18.77 17.70 22.37 23.36 23.17 24.92 24.76 21.62 4 Single rate
    (high) 2.012 0.761 1.199 1.092 0.605 0.914 0.586 0.492 5 MRKF 2.500 1.530 1.987
    2.081 1.979 2.143 2.044 1.837 6 MRKF + RTS 1.837 0.933 1.258 1.211 0.900 1.039
    0.974 0.868 a These DOFs are directly measured by sensors. The comparison between
    Scheme 1 and Scheme 5 indicates that given the MRKF algorithm, even adding low-sampling-rate
    displacement measurements to acceleration measurements can considerably improve
    the estimation accuracy by 13 %–43 %. The comparison between Scheme 5 and Scheme
    6 indicates that the RTS smoothing process can further reduce the estimation error
    by approximately 20 %–50 %. The NRMSE for velocity is similar to the displacement
    results and therefore omitted for the sake of brevity. Table 5 presents the acceleration
    estimation results. The NRMSEs at the three DOFs with accelerometers are 0.612 %,
    0.993 %, and 0.702 % in Scheme 1, which are slightly smaller than sensor measurement
    noise. The good performance of Scheme 1 indicates that reconstructing acceleration
    by using accelerometer measurements only can produce reasonable results. MRKF
    has a comparable performance with Scheme 1. However, the reconstruction errors
    can be considerably reduced after the RTS smoothing. The estimation errors in
    Scheme 6 are even smaller than those obtained through high-frequency data fusion
    (Scheme 4). Acceleration reconstructions in Schemes 2 and 3 are unsatisfactory
    because capturing high-order structural vibrations through low-frequency observations
    is difficult. Table 5. Steady-state NRMSE for acceleration obtained by different
    schemes in the numerical baseline case. Sensing scheme NRMSE for acceleration
    (%) DOF1 DOF2a DOF3 DOF4 DOF5a DOF6 DOF7 DOF8a 1 Acc only 3.231 0.612 4.092 4.524
    0.993 4.194 3.577 0.702 2 Dis only 15.42 16.31 19.34 21.02 22.87 18.46 21.91 14.73
    3 Single rate (low) 12.42 2.401 14.50 15.20 3.191 14.00 18.62 3.626 4 Single rate
    (high) 3.036 0.603 3.814 4.219 0.979 4.034 3.057 0.681 5 MRKF 3.237 1.707 4.163
    4.538 1.271 4.197 3.566 1.441 6 MRKF + RTS 2.557 0.561 3.320 3.707 0.934 3.241
    2.668 0.622 a These DOFs are directly measured by sensors. Fig. 6 plots the data
    presented in Table 4, Table 5 to provide a clear comparison of estimation accuracies.
    The proposed algorithm with RTS smoothing achieves superior reconstruction accuracy
    even without high-frequency displacement measurements. The comparison confirms
    that, given the proposed MRKF + RTS algorithm, a high sampling frequency of displacement
    observation is unnecessary. Download : Download high-res image (382KB) Download
    : Download full-size image Fig.6. NRMSE in the numerical baseline case: (a) displacement,
    (b) acceleration. 3.3. Parametric analysis Seven cases (Cases 2–8) shown in Table
    6 are designed and compared with the baseline analysis (Case 1) to examine the
    filter robustness and performance under different scenarios. Different influencing
    factors are considered in these simulations. Considering that the displacement
    sampling frequency varies with different sensor types, Case 2 is designed to check
    filter performance with displacement observations sampled at a relatively higher
    frequency (i.e., 50 Hz). In Case 3, two random loadings are replaced by a harmonic
    excitation of 10 Hz plus a combination of harmonic excitations of 0.1 Hz and 50 Hz.
    The comparison between Cases 1 and 4 aims to examine the influence of the number
    of excitations. Case 5 considers the non-collocated sensor arrangement (i.e.,
    the accelerometer and displacement sensor are installed at different DOFs). The
    different levels of measurement noise (Case 1 vs. Case 6) and system noise (Case
    1 vs. Case 7) are studied. In Case 8, is set to 1, which means RTS smoothing is
    conducted for every displacement measurement. Table 6. Simulation cases in parametric
    analysis. Case Input location Input type Sampling frequency (Hz) Sensor location
    Measurement noise System noise acc dis acc dis 1 2 8 random 100 5 5 2 5 8 2 5
    8 5 % 5 % 2 2 8 random 100 50 5 2 5 8 2 5 8 5 % 5 % 3 2 8 harmonic 100 5 5 2 5
    8 2 5 8 5 % 5 % 4 2 5 8 random 100 5 5 2 5 8 2 5 8 5 % 5 % 5 2 8 random 100 5
    5 8 2 5 % 5 % 6 2 8 random 100 5 5 2 5 8 2 5 8 20 % 5 % 7 2 8 random 100 5 5 2
    5 8 2 5 8 5 % 20 % 8 2 8 random 100 5 1 2 5 8 2 5 8 5 % 5 % Table 7 shows the
    steady-state reconstruction NRMSEs for DOF7 by using different schemes (Table
    3) in eight simulation cases (Table 6). The NRMSEs for the displacement, velocity,
    and acceleration estimations at this unobserved DOF are listed. The comparison
    shows that the proposed MRKF algorithm with RTS smoothing (Scheme 6) achieves
    satisfactory accuracies in various cases; it is constantly better than the traditional
    down-sampled single rate (low) method (Scheme 3). For displacement reconstruction,
    the proposed method (Scheme 6) has comparable performance with the single rate
    (high) method (Scheme 4). Comparing Cases 1 and 2 indicates when the displacement
    sampling frequency is much lower than that of acceleration, the traditional down-sampling
    data fusion method could be problematic because most acceleration data are disregarded.
    Cases 3–5 verify the good performance of the proposed MRKF + RTS algorithm under
    various excitation conditions. In real SHM applications, the sensor noises may
    be high, and the structural model may be inaccurate. To facilitate the applications
    in real practice, Cases 6 and 7 are designed to examine the influences of measurement
    and system noise levels. The proposed MRKF algorithm is quite robust even under
    relatively high noise levels. In Case 8, is reduced to 1, and RTS smoothing is
    conducted more frequently. Compared with the baseline Case 1, Case 8 has a faster
    computing speed and smaller time delay. The algorithm can be regarded as nearly
    online. However, the state estimation error is increased slightly compared with
    Case 1. The selection of the RTS interval should be determined according to specific
    requirements in consideration of a tradeoff between computational real-timing
    and accuracies. Through this parametric analysis, the robustness and superiority
    of the proposed algorithm are well verified. Table 7. Steady-state NRMSE for DOF7
    obtained by different schemes under eight simulation cases. Reconstructed response
    Sensing scheme NRMSE for DOF 7 (%) Case1 Case 2 Case3 Case 4 Case 5 Case 6 Case
    7 Case 8 dis 1 Acc only 3.50 3.50 7.32 1.90 3.91 5.16 7.69 3.50 2 Dis only 32.7
    28.4 25.8 20.1 70.8 63.0 23.7 32.7 3 Single rate (low) 24.8 2.45 16.9 13.4 68.0
    60.8 5.06 24.8 4 Single rate (high) 0.59 0.59 0.73 0.35 2.00 1.29 0.74 0.59 5
    MRKF 2.04 0.74 4.02 1.16 3.11 3.23 4.36 2.04 6 MRKF + RTS 0.97 0.57 1.55 0.58
    2.26 2.25 1.74 1.07 vel 1 Acc only 3.14 3.14 5.07 2.65 3.47 4.26 6.65 3.14 2 Dis
    only 33.5 21.9 36.7 27.6 40.1 48.2 22.7 33.5 3 Single rate (low) 29.5 6.53 34.5
    22.4 37.2 46.8 17.3 29.5 4 Single rate (high) 2.34 2.34 3.20 2.01 2.88 3.24 4.46
    2.34 5 MRKF 2.84 2.43 4.25 2.42 3.29 3.65 5.94 2.84 6 MRKF + RTS 2.12 2.02 2.79
    1.83 2.52 2.93 4.35 2.33 acc 1 Acc only 3.58 3.58 3.75 3.77 4.37 4.76 5.95 3.58
    2 Dis only 21.9 17.0 19.5 20.7 17.4 16.8 20.1 21.9 3 Single rate (low) 18.6 5.82
    14.1 19.5 32.8 16.6 7.54 18.6 4 Single rate (high) 3.06 3.06 2.86 3.24 3.92 4.63
    4.12 3.06 5 MRKF 3.57 3.18 3.59 3.76 4.35 4.78 5.76 3.57 6 MRKF + RTS 2.67 2.78
    2.60 2.78 3.06 4.01 4.03 2.89 4. Experimental validation 4.1. Experimental setup
    A steel cantilever beam was tested in the laboratory to examine the effectiveness
    of the proposed algorithm. As shown in Fig. 7, the cantilever beam with a cross-section
    of 50 mm × 3.14 mm was installed on a shake table. The total height of the beam
    was 1,180 mm and was equally divided into eight elements in its numerical model.
    Download : Download high-res image (119KB) Download : Download full-size image
    Fig. 7. Layout of the sensors in the laboratory test. The APS420 long-stroke shaker
    generated the ground excitation. Acceleration responses were measured by three
    accelerometers (Type 4382, Brüel & Kjær, Denmark), installed at DOF2, DOF4, and
    DOF6, and denoted as Sa_E2, Sa_E4, and Sa_E6 in Fig. 7. The beam displacement
    was recorded by an iPhone 11 placed in front of the beam. Markers were attached
    to the locations where beam displacements were to be extracted. The displacement
    was extracted from the recorded video by using the Kanade-Lucas-Tomasi (KLT) tracking
    algorithm. Four laser displacement meters (IL-300, Keyence Corporation of America,
    USA) were also installed to examine the accuracy of the KLT tracking algorithm.
    The iPhone 11 and the laser displacement meters recorded absolute displacements,
    which include the shake table displacement. The excitation time history generated
    by the shake table was recorded by an accelerometer Sa_E0. The data acquisition
    (DAQ) system was KYOWA EDX-100A, and the sampling frequency for accelerometers
    and laser displacement sensors was set to 1000 Hz. Fig. 8 shows the photos of
    the experimental setup in the laboratory. Download : Download high-res image (327KB)
    Download : Download full-size image Fig. 8. Laboratory experimental setup: (a)
    whole picture, (b) accelerometer, (c) iPhone11, and (d) laser displacement sensor.
    The natural frequencies of the tested beam were identified using the stochastic
    subspace identification (SSI) technique. The measured first three frequencies
    were 1.706 Hz, 10.834 Hz, and 30.260 Hz, respectively. The model updating was
    conducted to match the measured results. The steel density was assumed as 7850 kg/m3,
    and Young’s modulus was 210 GPa. The damping ratios for all modes were assumed
    as 2 % in the calculation. 4.2. Camera tracking results Although a professional
    high-speed camera can provide accurate motion tracking at high frame rates, its
    application is hindered by the exorbitant price. Motion tracking by using consumer-grade
    cameras is quite propitious in SHM applications. The KLT tracking algorithm is
    one of the target-free computer-vision methods. It was successfully applied to
    the motion tracking of one six-story shear frame by Yoon et al. [41] in 2016.
    Fig. 9 shows the vision-based displacement measurement procedure in this experimental
    test. An iPhone 11 recorded the structure motions by filming videos, and the available
    frame rates were 30 and 60 fps. Regions of Interest (ROIs) were selected in the
    first frame and were automatically tracked in the following video frames. The
    ROIs were equivalent to the sensor locations in traditional SHM. Although the
    markers are not really required by the KLT method, they were still used in this
    test to improve the tracking quality because the beam thickness was too thin.
    Once the ROIs are selected for the first frame, the KLT algorithm can track the
    point pixel locations for the entire duration of the video. By calculating the
    pixel distance between two points with known physical lengths, the pixel-to-mm
    convention was obtained. The structural displacement could be obtained thereafter.
    Download : Download high-res image (101KB) Download : Download full-size image
    Fig. 9. Vision-based displacement measurement procedure using KLT tracking. As
    shown in Fig. 8, the light absorbing background was placed behind the test beam,
    and the markers were placed on each beam node and the shake table. The pixel-to-mm
    coefficient was determined as 0.37 in this test, i.e., one pixel in the video
    frame is 0.37 mm displacement in physical coordinate. Fig. 10 compares the displacements
    measured by the laser displacement meters and iPhone 11. The results obtained
    by the iPhone agree well with the laser displacement meter measurements. The RMSEs
    for DOF1, DOF3, DOF5, and DOF7 are only 0.245 mm, 0.477 mm, 0.514 mm, and 0.540 mm,
    respectively. More importantly, one iPhone model could track structural motions
    at many points; whereas one laser displacement meter could only measure one single
    point, and it usually has a narrow operating distance range. The tracking results
    in this experiment demonstrate the great potential for deploying the consumer-grade
    camera for displacement measurements in SHM applications. Download : Download
    high-res image (794KB) Download : Download full-size image Fig. 10. Compare displacement
    measured by iPhone and laser displacement seonsor in laboratory test: (a) DOF1,
    (b) DOF3, (c) DOF5, and (d) DOF7. 4.3. Response reconstruction results A random
    ground motion with a frequency range of 0–50 Hz and peak ground acceleration of
    0.82 g was applied to the cantilever beam. The frequency was selected to cover
    the first three natural frequencies of the tested beam. Out of the three installed
    accelerometers, only Sa_E2 and Sa_E4 observations were used to reconstruct structural
    responses. The acceleration recorded by Sa_E6 was used for the comparison with
    the reconstructed responses. Displacements at all eight DOFs could be extracted
    from the recorded videos. In this experimental test, only two displacements at
    DOF3 and DOF5 were included in the observation vector. Displacement measurements
    at other locations were used to verify filter accuracies. The standard deviation
    of measurement noise was estimated to be around 10 % of the standard deviation
    of the measured responses. The variance of system noise was set as the square
    of 5 % of the standard deviation of the state vector. The sampling frequency of
    the accelerometers and laser displacement meters was set as 1000 Hz. The video
    frame rate of the iPhone11 camera was 60 fps. Considering the proposed MRKF algorithm
    only applies to the case where the sampling frequency of the acceleration is integer
    multiples of the displacement, the camera-tracked displacements were down-sampled
    from 60 fps to 20 fps for calculation. Fig. 11 presents the reconstructed displacement
    time histories at verification DOFs. The same six different data fusion schemes
    shown in Table 3 were adopted for a better illustration of the algorithm performance
    and consistency with the numerical simulation. The reconstructed displacements
    are compared with the KLT tracking results. Displacement estimation by using displacement
    sensors (Scheme 2) and single rate low (Scheme 3) failed to produce satisfactory
    results, which is consistent with the conclusion reached in the numerical simulation.
    Response reconstruction by using data sampled at low frequencies will lose the
    ability to capture higher-order structural vibration modes. Given that high-frequency
    displacement data were unavailable from the vision-based tracking, displacements
    recorded by laser displacement meters were used in the single rate (high) data
    fusion based on 1000 Hz acceleration and displacement measurements (Scheme 4).
    Fig. 11 shows that the proposed MRKF algorithm with RTS smoothing process yields
    competitive results with data fusion by high single rate observations. The estimations
    agree fairly with the measured sensor data. If only acceleration observation is
    used in the observation, the reconstructed displacements have larger errors than
    the MRKF results. Table 8 presents the NRMSEs for the reconstructed displacements
    in the laboratory test. The MRKF errors can be further reduced by approximately
    1–25 % if the RTS smoothing procedure is applied. After the smoothing, the reconstruction
    errors in Scheme 6 were reduced by around 30–80 % compared with estimation using
    acceleration only (Scheme 1) and by over 90 % compared with traditional down-sampling
    single rate data fusion (Scheme 3). Download : Download high-res image (979KB)
    Download : Download full-size image Fig. 11. Displacement estimations at verification
    DOFs in laboratory test (a) DOF2, (b) DOF4, (c) DOF6, and (d) DOF8. Table 8. Steady-state
    NRMSE for displacement obtained by using different schemes for the tested beam.
    Scheme NRMSE for displacement (%) DOF1 DOF2 DOF3 DOF4 DOF5 DOF6 DOF7 DOF8 1 Acc
    only 16.85 16.63 16.32 16.77 16.30 16.99 17.86 18.72 2 Dis only 37.34 41.58 46.52
    58.54 54.23 58.45 60.54 72.78 3 Single rate (low) 39.41 43.92 49.43 62.66 57.80
    62.33 64.53 78.08 4 Single rate (high)* 10.41 8.797 6.864 5.981 3.392 2.605 3.144
    6.337 5 MRKF 11.62 10.03 8.152 7.154 4.228 3.495 4.401 6.983 6 MRKF + RTS 11.48
    10.01 8.047 6.811 4.205 2.958 3.285 6.149 *Laser displacement sensor is used given
    that high frequency camera reading is unavailable. Fig. 12 compares the reconstructed
    acceleration and the accelerometer measurement at DOF6. Except for Schemes 2 and
    3, all other schemes achieve similar performance. A similar conclusion can be
    reached from the data presented in Table 9. If only structural accelerations are
    required to be estimated under known input, response reconstruction by using acceleration
    only will provide acceptable estimations. However, if displacement and velocity
    responses are of interest as well, data fusion shall be conducted to obtain better
    structural state estimations. Download : Download high-res image (339KB) Download
    : Download full-size image Fig. 12. Acceleration time history at DOF6 in laboratory
    test. Table 9. Steady-state NRMSE for acceleration obtained by using different
    schemes in the test. Scheme NRMSE for acceleration (%) DOF2 DOF4 DOF6 1 Acc only
    0.136 0.096 9.352 2 Dis only 37.90 37.05 45.58 3 Single rate (low) 0.972 1.024
    56.47 4 Single rate (high)* 0.136 0.096 9.685 5 MRKF 0.592 0.463 11.89 6 MRKF + RTS
    0.163 0.115 10.18 *Laser displacement sensor is used because high-frequency camera
    reading is unavailable. 5. Conclusions A novel MRKF data fusion algorithm combined
    with an RTS smoothing technique for structural dynamic response reconstruction,
    which enables the direct fusion of signals sampled at different frequencies, is
    presented in this paper for the first time. The proposed method adopts two sets
    of observation equations for the measurements. The measurement update using displacement
    and acceleration will be conducted only when the displacement data are available;
    otherwise, the acceleration observation equation will be adopted. The RTS smoothing
    procedure is further applied to enhance the estimation precisions. The proposed
    algorithm surmounts the obstacle to deploying low-cost consumer-grade cameras
    in SHM applications. Through the numerical simulations and laboratory tests of
    different structures in various scenarios, the robustness and superiority of the
    proposed MRKF algorithm are successfully verified. Below are the major conclusions
    of this paper: 1. The proposed MRKF algorithm is the first response reconstruction
    technique for an MDOF structural system that considers the fusion of multi-type
    sensor data sampling at different rates. 2. The partially observed system is allowed,
    and the collocated sensor monitoring requirement is relaxed. Unobserved responses
    will be estimated through the proposed MRKF iterations. 3. Compared with traditional
    KF-based algorithms, the proposed algorithm is relatively robust and insensitive
    to noises. Satisfactory state estimations could still be obtained even with high
    measurement and system noises. 4. The RTS smoothing process leads to time delay
    to some extent in response reconstruction. When the RTS interval is small, the
    algorithm is nearly online but will produce larger estimation errors. The selection
    of the RTS interval should be determined according to specific requirements by
    considering a tradeoff between computational real-timing and accuracies. 5. MRKF
    solves the inherent problem of the low sampling rate of displacement monitoring
    by consumer-grade cameras. Through the proposed MRKF iterations and RTS smoothing,
    the state estimation results can be comparable to those obtained by high-frequency
    acceleration and displacement measurements. This finding can potentially reduce
    the SHM sensing system budget by avoiding using an expensive high-speed camera.
    The presented findings illustrate the superiority and robustness of the proposed
    algorithm in various scenarios. However, the current algorithm only applies to
    linearly elastic systems and the cases when the acceleration sampling frequency
    is integer multiples of the displacement sampling frequency. The input excitation
    should also be measured. Future studies will be carried out to extend the proposed
    algorithm to more generic cases and improve filter practicability. CRediT authorship
    contribution statement Zimo Zhu: Conceptualization, Methodology, Software, Validation,
    Formal analysis, Investigation, Data curation, Writing – original draft, Visualization.
    Jubin Lu: Methodology. Songye Zhu: Conceptualization, Methodology, Resources,
    Writing – review & editing, Supervision, Project administration, Funding acquisition.
    Declaration of Competing Interest The authors declare that they have no known
    competing financial interests or personal relationships that could have appeared
    to influence the work reported in this paper. Acknowledgement This research was
    supported by the Research Grants Council of Hong Kong through Theme-based Research
    Scheme (T22-502/18-R), Research Impact Fund (PolyU R5020-18), and General Research
    Fund (15213122), the Hong Kong Branch of the National Rail Transit Electrification
    and Automation Engineering Technology Research Center (No. K-BBY1), and The Hong
    Kong Polytechnic University (ZE2L, ZVX6). Data availability Data will be made
    available on request. References [1] Y.Q. Ni, Y.W. Wang, C. Zhang A Bayesian approach
    for condition assessment and damage alarm of bridge expansion joints using long-term
    structural health monitoring data Eng Struct, 212 (2020), Article 110520 View
    PDFView articleView in ScopusGoogle Scholar [2] Y.Q. Ni, Y. Xia, W.Y. Liao, J.M.
    Ko Technology innovation in developing the structural health monitoring system
    for Guangzhou New TV Tower Struct Control Health Monit, 16 (1) (2009), pp. 73-98
    CrossRefView in ScopusGoogle Scholar [3] Y. Xia, P. Zhang, Y.Q. Ni, H.P. Zhu Deformation
    monitoring of a super-tall structure using real-time strain data Eng Struct, 67
    (2014), pp. 29-38 View PDFView articleView in ScopusGoogle Scholar [4] D. Feng,
    M.Q. Feng Computer vision for SHM of civil infrastructure: from dynamic response
    measurement to damage detection–a review Eng Struct, 156 (2018), pp. 105-117 View
    PDFView articleView in ScopusGoogle Scholar [5] P. Moyo, J.M.W. Brownjohn, R.
    Suresh, S.C. Tjin Development of fiber Bragg grating sensors for monitoring civil
    infrastructure Eng Struct, 27 (2005), pp. 1828-1834 View PDFView articleView in
    ScopusGoogle Scholar [6] D.C. Kammer Estimation of structural response using remote
    sensor locations J Guid Control Dyn, 20 (3) (1997), pp. 501-508 CrossRefView in
    ScopusGoogle Scholar [7] S.S. Law, J. Li, Y. Ding Structural response reconstruction
    with transmissibility concept in frequency domain Mech Syst Signal Process, 25
    (3) (2011), pp. 952-968 View PDFView articleView in ScopusGoogle Scholar [8] J.
    He, X. Guan, Y. Liu Structural response reconstruction based on empirical mode
    decomposition in time domain Mech Syst Signal Process, 28 (2012), pp. 348-366
    View PDFView articleView in ScopusGoogle Scholar [9] M.P. Limongelli Optimal location
    of sensors for reconstruction of seismic responses through spline function interpolation
    Earthq Eng Struct Dyn, 32 (7) (2003), pp. 1055-1074 View in ScopusGoogle Scholar
    [10] J. Kullaa Bayesian virtual sensing in structural dynamics Mech Syst Signal
    Process, 115 (2019), pp. 497-513 View PDFView articleView in ScopusGoogle Scholar
    [11] F. Saltari, D. Dessi, F. Mastroddi Mechanical systems virtual sensing by
    proportional observer and multi-resolution analysis Mech Syst Signal Process,
    146 (2021), Article 107003 View PDFView articleView in ScopusGoogle Scholar [12]
    R.E. Kalman A new approach to linear filtering and prediction problems J. Basic
    Eng., 82 (1) (Mar 1960), pp. 35-45, 10.1115/1.3662552 Google Scholar [13] S. Zhu,
    X.H. Zhang, Y.L. Xu, S. Zhan Multi-type sensor placement for multi-scale response
    reconstruction Adv Struct Eng, 16 (10) (2013), pp. 1779-1797 CrossRefView in ScopusGoogle
    Scholar [14] Y.L. Xu, X.H. Zhang, S. Zhu, S. Zhan Multi-type sensor placement
    and response reconstruction for structural health monitoring of long-span suspension
    bridges Sci Bull, 61 (4) (2016), pp. 313-329 View PDFView articleGoogle Scholar
    [15] X.H. Zhang, Z. Zhu, G.K. Yuan, S. Zhu Adaptive mode selection integrating
    Kalman filter for dynamic response reconstruction J Sound Vib, 515 (2021), Article
    116497 View PDFView articleView in ScopusGoogle Scholar [16] Y. Lei, H. Zhou,
    Z.L. Lai A computationally efficient algorithm for real-time tracking the abrupt
    stiffness degradations of structural elements Comput-Aided Civ Inf, 31 (6) (2016),
    pp. 465-480 CrossRefView in ScopusGoogle Scholar [17] Y. Lei, J. Lu, J. Huang
    Synthesize identification and control for smart structures with time-varying parameters
    under unknown earthquake excitation Struct Control Health Monit, 27 (4) (2020),
    Article e2512 View in ScopusGoogle Scholar [18] M. Ebrahimzadeh Hassanabadi, A.
    Heidarpour, S. Eftekhar Azam, M. Arashpour A Bayesian smoothing for input-state
    estimation of structural systems Comput-Aided Civ Inf, 37 (3) (2022), pp. 317-334
    CrossRefView in ScopusGoogle Scholar [19] J. Hwang, D. Kwon, A. Kareem A modal-based
    Kalman filtering framework for mode extraction and decomposition of damped structures
    Comput-Aided Civ Inf (2022), pp. 1-16 Google Scholar [20] M. Ebrahimzadeh Hassanabadi,
    Z. Liu, S. Eftekhar Azam, D. Dias-da-Costa A linear Bayesian filter for input
    and state estimation of structural systems Comput-Aided Civ Inf (2023), pp. 1-18
    Google Scholar [21] S. Gillijns, B. De Moor Unbiased minimum-variance input and
    state estimation for linear discrete-time systems Automatica, 43 (1) (2007), pp.
    111-116 View PDFView articleView in ScopusGoogle Scholar [22] S. Gillijns, B.
    De Moor Unbiased minimum-variance input and state estimation for linear discrete-time
    systems with direct feedthrough Automatica, 43 (5) (2007), pp. 934-937 View PDFView
    articleView in ScopusGoogle Scholar [23] X.H. Zhang, Y.L. Xu, S. Zhu, S. Zhan
    Dual-type sensor placement for multi-scale response reconstruction Mechatronics,
    24 (4) (2014), pp. 376-384 View PDFView articleCrossRefGoogle Scholar [24] X.H.
    Zhang, S. Zhu, Y.L. Xu, X.J. Homg Integrated optimal placement of displacement
    transducers and strain gauges for better estimation of structural response Int
    J Struct Stab Dyn, 11 (03) (2011), pp. 581-602 View in ScopusGoogle Scholar [25]
    C.D. Zhang, Y.L. Xu Optimal multi-type sensor placement for response and excitation
    reconstruction J Sound Vib, 360 (2016), pp. 112-128 View PDFView articleView in
    ScopusGoogle Scholar [26] T. Li, Y. Pan, K. Tong, C.E. Ventura, C.W. de Silva
    A multi-scale attention neural network for sensor location selection and nonlinear
    structural seismic response prediction Comput Struct, 248 (2021), Article 106507
    View PDFView articleView in ScopusGoogle Scholar [27] M.R. Kaloop, E. Elbeltagi,
    J.W. Hu, A. Elrefai Recent advances of structures monitoring and evaluation using
    GPS-time series monitoring systems: a review ISPRS Int J Geoinf, 6 (12) (2017),
    Article 382 CrossRefView in ScopusGoogle Scholar [28] C. Dong, O. Celik, F. Catbas,
    E. O’Brien, S. Taylor Structural displacement monitoring using deep learning-based
    full field optical flow methods Struct Infrastruct Eng, 16 (1) (2020), pp. 51-71
    CrossRefView in ScopusGoogle Scholar [29] Y. Xu, J. Zhang, J. Brownjohn An accurate
    and distraction-free vision-based structural displacement measurement method integrating
    Siamese network based tracker and correlation-based template matching Measurement,
    179 (2021), Article 109506 View PDFView articleView in ScopusGoogle Scholar [30]
    C. Dong, F.N. Catbas A non-target structural displacement measurement method using
    advanced feature matching strategy Adv Struct, 22 (16) (2019), pp. 3461-3472 CrossRefView
    in ScopusGoogle Scholar [31] A. Smyth, M. Wu Multi-rate Kalman filtering for the
    data fusion of displacement and acceleration response measurements in dynamic
    system monitoring Mech Syst Signal Process, 21 (2) (2007), pp. 706-723 View PDFView
    articleView in ScopusGoogle Scholar [32] C.C. Chang, X. Xiao An integrated visual-inertial
    technique for structural displacement and velocity measurement Smart Struct Syst,
    6 (9) (2010), pp. 1025-1039 CrossRefView in ScopusGoogle Scholar [33] H. Zhu,
    K. Gao, Y. Xia, F. Gao, S. Weng, Y. Sun, et al. Multi-rate data fusion for dynamic
    displacement measurement of beam-like supertall structures using acceleration
    and strain sensors Struct Health Monit, 19 (2) (2020), pp. 520-536 CrossRefView
    in ScopusGoogle Scholar [34] J. Kim, K. Kim, H. Sohn Autonomous dynamic displacement
    estimation from data fusion of acceleration and intermittent displacement measurements
    Mech Syst Signal Process, 42 (1–2) (2014), pp. 194-205 View PDFView articleView
    in ScopusGoogle Scholar [35] K. Kim, J. Choi, G. Koo, H. Sohn Dynamic displacement
    estimation by fusing biased high-sampling rate acceleration and low-sampling rate
    displacement measurements using two-stage Kalman estimator Smart Struct Syst,
    17 (4) (2016), pp. 647-667 CrossRefView in ScopusGoogle Scholar [36] Z. Zheng,
    H. Qiu, Z. Wang, S. Luo, Y. Lei Data fusion based multi-rate Kalman filtering
    with unknown input for on-line estimation of dynamic displacements Measurement,
    131 (2019), pp. 211-218 View PDFView articleCrossRefGoogle Scholar [37] Z. Ma,
    J. Choi, H. Sohn Real-time structural displacement estimation by fusing asynchronous
    acceleration and computer vision measurements Comput-Aided Civ Inf, 37 (6) (2022),
    pp. 688-703 CrossRefView in ScopusGoogle Scholar [38] H.E. Rauch, F. Tung, C.T.
    Striebel Maximum likelihood estimates of linear dynamic systems AIAA J, 3 (8)
    (1965), pp. 1445-1450, 10.2514/3.3166 View in ScopusGoogle Scholar [39] R.A. De
    Callafon, B. Moaveni, J.P. Conte, X. He, E. Udd General realization algorithm
    for modal identification of linear dynamic systems J Eng Mech, 134 (9) (2008),
    pp. 712-722 View in ScopusGoogle Scholar [40] S.R. Azam, E. Chatzi, C. Papadimitriou
    A dual Kalman filter approach for state estimation via output-only acceleration
    measurements Mech Syst Signal Process, 60 (2015), pp. 866-886 View in ScopusGoogle
    Scholar [41] H. Yoon, H. Elanwar, H. Choi, M. Golparvar Fard, B.F. Spencer Jr
    Target-free approach for vision-based structural system identification using consumer-grade
    cameras Struct Control Health Monit, 23 (12) (2016), pp. 1405-1416 CrossRefView
    in ScopusGoogle Scholar Cited by (0) View Abstract © 2023 Published by Elsevier
    Ltd. Recommended articles Fatigue life evaluation of bridge stay cables subject
    to monitoring traffic and considering road roughness Engineering Structures, Volume
    293, 2023, Article 116572 Jian-An Li, Dongming Feng View PDF Multi-performance
    blast pressure-duration curves for point-supported laminated and monolithic glass
    panes Engineering Structures, Volume 293, 2023, Article 116620 Mohammadreza Eslami,
    …, Chase C. Young View PDF Tensile behaviors and configurations of double-headed
    bar overlap connections for precast concrete members Engineering Structures, Volume
    293, 2023, Article 116701 Zihao Liang, …, Zhaoxin Hou View PDF Show 3 more articles
    Article Metrics Captures Readers: 2 View details About ScienceDirect Remote access
    Shopping cart Advertise Contact and support Terms and conditions Privacy policy
    Cookies are used by this site. Cookie settings | Your Privacy Choices All content
    on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors.
    All rights are reserved, including those for text and data mining, AI training,
    and similar technologies. For all open access content, the Creative Commons licensing
    terms apply."'
  inline_citation: '>'
  journal: Engineering Structures
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Multi-rate Kalman filtering for structural dynamic response reconstruction
    by fusing multi-type sensor data with different sampling frequencies
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Yamamoto S.
  - Yoshino M.
  - Nakanishi K.
  - Yogo K.
  - Kamada K.
  - Yoshikawa A.
  - Koshikawa N.
  - Kataoka J.
  citation_count: '1'
  description: High-resolution and real-time imaging of the trajectories of alpha
    particles is desired in nuclear medicine and nuclear engineering. Although an
    imaging method using a scintillator plate combined with a magnifying unit and
    a cooled electron multiplying charge-coupled device (EM-CCD) camera is a possible
    method of obtaining high-resolution trajectory images, the spatial resolution
    of the system is limited to ∼2 μm. To overcome the spatial resolution limitations
    of this method on trajectory imaging, we used a cooled complementally metal oxide
    (CMOS) camera in which the sensor had a much larger number of pixels, which were
    also smaller. Using the CMOS camera based imaging system, we could measure the
    trajectories of alpha particles in real time with the spatial resolution of 0.34
    μm FWHM. With smoothing of the images to reduce image noise, spatial resolution
    was still kept to less than 0.75 μm. We conclude that this CMOS camera-based alpha-particle
    trajectory-imaging system is promising for alpha-particle or other particles imaging
    where ultrahigh spatial resolution is required.
  doi: 10.1088/1748-0221/18/10/T10003
  full_citation: '>'
  full_text: '>

    "We value your privacy Clicking the \"Accept All\" button means you are accepting
    analytics and third-party cookies. We use cookies to optimise site functionality
    and give you the best possible experience. To control which cookies are set, click
    \"Customize\". Privacy and Cookies policy Customize Accept All Skip to content
    IOP Science home Accessibility Help Search Journals Books Publishing Support Login
    Journal of Instrumentation TECHNICAL REPORT Sub-micrometer real-time imaging of
    trajectory of alpha particles using GAGG plate and CMOS camera Seiichi Yamamoto4,1,
    Masao Yoshino4,2, Kohei Nakanishi3, Katsunori Yogo3, Kei Kamada2, Akira Yoshikawa2,
    Nanase Koshikawa1 and Jun Kataoka1 Published 10 October 2023 • © 2023 IOP Publishing
    Ltd and Sissa Medialab Journal of Instrumentation, Volume 18, October 2023 Citation
    Seiichi Yamamoto et al 2023 JINST 18 T10003 DOI 10.1088/1748-0221/18/10/T10003
    Download Article PDF References Article metrics 64 Total downloads 1 Permissions
    Get permission to re-use this article Share this article Article and author information
    Abstract High-resolution and real-time imaging of the trajectories of alpha particles
    is desired in nuclear medicine and nuclear engineering. Although an imaging method
    using a scintillator plate combined with a magnifying unit and a cooled electron
    multiplying charge-coupled device (EM-CCD) camera is a possible method of obtaining
    high-resolution trajectory images, the spatial resolution of the system is limited
    to ∼2 μm. To overcome the spatial resolution limitations of this method on trajectory
    imaging, we used a cooled complementally metal oxide (CMOS) camera in which the
    sensor had a much larger number of pixels, which were also smaller. Using the
    CMOS camera based imaging system, we could measure the trajectories of alpha particles
    in real time with the spatial resolution of 0.34 μm FWHM. With smoothing of the
    images to reduce image noise, spatial resolution was still kept to less than 0.75
    μm. We conclude that this CMOS camera-based alpha-particle trajectory-imaging
    system is promising for alpha-particle or other particles imaging where ultrahigh
    spatial resolution is required. Export citation and abstract BibTeX RIS Previous
    article in issue Next article in issue Show References Abstract References You
    may also like JOURNAL ARTICLES X-ray topography of crystallographic defects in
    wide-bandgap semiconductors using a high-resolution digital camera Nonlocal electron
    kinetics and spectral line emission in the positive column of an argon glow discharge
    Basic study on evaluation of X-ray dose distribution using plastic scintillator
    plate and digital CMOS camera Using a pseudo-thermal light source to teach spatial
    coherence Characterization of a new scintillation imaging system for proton pencil
    beam dose rate measurements Influence of absorption coefficient and coherence
    length on time-reverse scattering suppression using digital phase-conjugate light
    IOPSCIENCE Journals Books IOP Conference Series About IOPscience Contact Us Developing
    countries access IOP Publishing open access policy Accessibility IOP PUBLISHING
    Copyright 2024 IOP Publishing Terms and Conditions Disclaimer Privacy and Cookie
    Policy PUBLISHING SUPPORT Authors Reviewers Conference Organisers This site uses
    cookies. By continuing to use this site you agree to our use of cookies. IOP Publishing
    Twitter page IOP Publishing Facebook page IOP Publishing LinkedIn page IOP Publishing
    Youtube page IOP Publishing WeChat QR code IOP Publishing Weibo page"'
  inline_citation: '>'
  journal: Journal of Instrumentation
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Sub-micrometer real-time imaging of trajectory of alpha particles using GAGG
    plate and CMOS camera
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Berghout T.
  - Benbouzid M.
  citation_count: '3'
  description: 'Featured Application: This study proposes a well-structured methodology
    to assist in intelligent decision making and the real-time monitoring of flight
    conditions of safety-critical aircraft whose major use results in the establishment
    of a well-planned maintenance schedule. The diagnosis and prognosis of aeronautical-bearing
    health conditions are essential to proactively ensuring efficient power transmission,
    safety, and reduced downtime. The rarity of failures in such safety-critical systems
    drives this process towards data-driven analytics of fault injection and aging
    experiments, rather than complex physics-based modeling. Nonetheless, data-based
    condition monitoring is very challenging due to data complexity, unavailability,
    and drift resulting from distortions generated by harsh operating conditions,
    scarcity of failure patterns, and rapid data change, respectively. Accordingly,
    the objective of this work is three-fold. First, to reduce data complexity and
    improve feature space representation, a robust data engineering scheme, including
    feature extraction, denoising, outlier removal, filtering, smoothing, scaling,
    and balancing, is introduced in this work. Second, collaborative selection-based
    incremental deep transfer learning (CSIDTL) is introduced to overcome the problem
    of the lack of patterns, incrementing the number of source domains in different
    training rounds. Third, long short-term memory (LSTM) adaptive learning rules
    are fully taken into account to combat further data complexity and data change
    problems. The well-structured methodology is applied on a huge dataset of aeronautical
    bearings dedicated to both diagnostic and prognosis studies, which perfectly addresses
    the above challenges in a form of a classification problem with 13 different conditions,
    7 operating modes, and 3 stages of damage severity. Conducting CSIDTL following
    a three-fold cross-validation process allows us to improve classification performance
    by about 12.15% and 10.87% compared with state-of-the-art methods, reaching classification
    accuracy rates of 93.63% and 95.65% in diagnosis and prognosis, respectively.'
  doi: 10.3390/app131910916
  full_citation: '>'
  full_text: '>

    "This website uses cookies We use cookies to personalise content and ads, to provide
    social media features and to analyse our traffic. We also share information about
    your use of our site with our social media, advertising and analytics partners
    who may combine it with other information that you’ve provided to them or that
    they’ve collected from your use of their services. Consent Selection Necessary
    Preferences Statistics Marketing Show details                 Deny Allow selection
    Allow all   Journals Topics Information Author Services Initiatives About Sign
    In / Sign Up Submit   Search for Articles: Applied Sciences All Article Types
    Advanced   Journals Applied Sciences Volume 13 Issue 19 10.3390/app131910916 Submit
    to this Journal Review for this Journal Propose a Special Issue Article Menu Academic
    Editors Andrew Teoh Beng Jin Wei Huang Subscribe SciFeed Recommended Articles
    Related Info Link More by Authors Links Article Views 1111 Citations 4 Table of
    Contents Featured Application Abstract Introduction Dataset Description and Processing
    Methods, Application, and Result Discussion Conclusions Author Contributions Funding
    Institutional Review Board Statement Informed Consent Statement Data Availability
    Statement Acknowledgments Conflicts of Interest References Altmetric share Share
    announcement Help format_quote Cite question_answer Discuss in SciProfiles thumb_up
    1 Endorse textsms Comment first_page settings Order Article Reprints Open AccessArticle
    Diagnosis and Prognosis of Faults in High-Speed Aeronautical Bearings with a Collaborative
    Selection Incremental Deep Transfer Learning Approach by Tarek Berghout 1 and
    Mohamed Benbouzid 2,3,* 1 Laboratory of Automation and Manufacturing Engineering,
    University of Batna 2, Batna 05000, Algeria 2 Institut de Recherche Dupuy de Lôme
    (UMR CNRS 6027), University of Brest, 29238 Brest, France 3 Logistics Engineering
    College, Shanghai Maritime University, Shanghai 201306, China * Author to whom
    correspondence should be addressed. Appl. Sci. 2023, 13(19), 10916; https://doi.org/10.3390/app131910916
    Submission received: 27 August 2023 / Revised: 14 September 2023 / Accepted: 28
    September 2023 / Published: 2 October 2023 (This article belongs to the Section
    Aerospace Science and Engineering) Download keyboard_arrow_down     Browse Figures
    Versions Notes Featured Application This study proposes a well-structured methodology
    to assist in intelligent decision making and the real-time monitoring of flight
    conditions of safety-critical aircraft whose major use results in the establishment
    of a well-planned maintenance schedule. Abstract The diagnosis and prognosis of
    aeronautical-bearing health conditions are essential to proactively ensuring efficient
    power transmission, safety, and reduced downtime. The rarity of failures in such
    safety-critical systems drives this process towards data-driven analytics of fault
    injection and aging experiments, rather than complex physics-based modeling. Nonetheless,
    data-based condition monitoring is very challenging due to data complexity, unavailability,
    and drift resulting from distortions generated by harsh operating conditions,
    scarcity of failure patterns, and rapid data change, respectively. Accordingly,
    the objective of this work is three-fold. First, to reduce data complexity and
    improve feature space representation, a robust data engineering scheme, including
    feature extraction, denoising, outlier removal, filtering, smoothing, scaling,
    and balancing, is introduced in this work. Second, collaborative selection-based
    incremental deep transfer learning (CSIDTL) is introduced to overcome the problem
    of the lack of patterns, incrementing the number of source domains in different
    training rounds. Third, long short-term memory (LSTM) adaptive learning rules
    are fully taken into account to combat further data complexity and data change
    problems. The well-structured methodology is applied on a huge dataset of aeronautical
    bearings dedicated to both diagnostic and prognosis studies, which perfectly addresses
    the above challenges in a form of a classification problem with 13 different conditions,
    7 operating modes, and 3 stages of damage severity. Conducting CSIDTL following
    a three-fold cross-validation process allows us to improve classification performance
    by about 12.15% and 10.87% compared with state-of-the-art methods, reaching classification
    accuracy rates of 93.63% and 95.65% in diagnosis and prognosis, respectively.
    Keywords: aircraft bearing; aircraft engine; deep learning; fault diagnosis; health
    stage; long short-term memory; prognosis; transfer learning 1. Introduction The
    condition monitoring of aircraft engines is of utmost importance, as it plays
    a critical role in ensuring safety, reliability, and efficiency of aircraft operations.
    Thus, it enables the early detection of failures, facilitates proactive/reactive
    maintenance, enhances operational efficiency, and ensures compliance with regulatory
    standards [1]. The real-time condition monitoring of such critical systems solely
    depends on the accurate modeling of the systems themselves and the interaction
    of their sub-components. As some of the main critical sub-components of aeroengines,
    bearings are vital for load support, friction reduction, heat dissipation, vibration
    absorption, reliability, durability, and overall safety. For numerous reasons,
    monitoring system vibration and bearing quality is critical in high-speed aerospace
    applications [2]. First, vibrations might suggest possible problems within the
    aircraft, such as misalignment or imbalanced loads, which can result in mechanical
    breakdowns and jeopardize safety. Second, bearing condition monitoring assists
    in identifying wear, excessive heat, and lubrication concerns that, if not treated
    promptly, can lead to catastrophic failures. Finally, monitoring these indicators
    allows for preventative maintenance, which reduces downtime and increases aircraft
    availability [2]. In another way, their proper operation and maintenance are essential
    to the efficient and safe operation of aircraft engines. In this context, bearing
    failure and degradation modeling can usually be performed through physics-based
    modeling, data-driven modeling, or hybrid physics- and data-driven modeling. However,
    various difficulties exist in this particular case. Extreme temperatures and strong
    G-forces are common operating conditions in high-speed aerospace applications
    that can impair the accuracy and reliability of monitoring systems. Furthermore,
    the complexity of aerospace systems, as well as the requirement for real-time
    data processing, presents hurdles in terms of data interpretation and rapid decision
    making [3]. Because of the intrinsic complexity of aircraft engine modeling, physics-based
    modeling is a difficult undertaking that induces less generalization, forcing
    it to be constrained to particular defined components and conditions [4,5]. Data-driven
    models, on the other hand, are strongly encouraged, as they have fewer modeling
    needs and the ability to undertake fault injections and aging tests in environments
    specially built by specialized laboratories. In this regard, this part is dedicated
    to providing the motivation, research gaps, contributions, and outline of this
    study, with the main goal of the data-driven modeling of aeronautical bearings
    for diagnostic and prognostic studies. 1.1. Motivations Data-driven modeling often
    encounters three major data challenges: complexity, unavailability, and drift.
    The existence of outliers or anomalies in historical data, which are data points
    that deviate considerably from others, is referred to as data complexity. These
    anomalies are caused by extremely complicated working conditions and severe environments,
    which distort sensor readings. These outliers can impact the learnability of the
    model, misleading the learning process or creating confusion in the patterns [6].
    Such a problem should be addressed by considering different relevant analytical
    or trainable methods that could improve data representation, including feature
    engineering, outlier detection and removal, denoising, smoothing, filtering, etc.
    [7]. On the other hand, data unavailability is the result of scarcity of failure
    patterns, whether under real conditions or in artificial failure generation and
    aging tests. Practically, such unavailability occurs owing to the rarity of downtime
    caused by continuous preventative maintenance function. Similarly, in accelerated
    aging and failure generation tests, failure modes are constrained to a set of
    operating conditions, and/or modes do not exactly emulate practical applications
    at some point. The problem created by such a challenge is the lack of representative
    data to effectively train a machine learning model. Without enough quality data,
    it becomes difficult for the model to learn different patterns, make accurate
    predictions, or generalize to new, unseen data well. Therefore, the requirement
    for generative modeling and/or transfer learning is critical, since they can give
    additional sources of expertise to address data unavailability gaps (see Figure
    2 form [6]). Additionally, data drift refers to rapid change and quickly outdated
    data. Because data are constantly changing and evolving, trained models on old
    data may not accurately represent the current state of the system. This can lead
    to biased or inaccurate predictions, as learning models are not able to adapt
    to rapid changes in data. Correspondingly, the key solution is to constantly update
    and retrain machine learning models in order to remain up to date with quickly
    changing data. Indeed, learning models need to be adaptive, up-to-date, and resilient
    to this problem [6]. For instance, LSTM networks, adaptive least squares methods
    with a forgetting mechanism, are very helpful, as they address specific penalization
    parameters acting as a memory focusing on new driven sequences [8]. Motivated
    by the urgent need for data-driven diagnosis and prognosis of aeronautical bearing
    health conditions in accordance with the aforementioned challenges, this work
    contributes further significant findings in this field. Accordingly, the following
    sections will also introduce a very interesting contribution to this field. This
    study looks into a more appropriate solution to such a problem by offering a well-structured
    research-gap extraction approach, well-defined analysis criteria, and a collection
    of contributions filling these gaps. Finally, at the end of this section, the
    key points of this work will be stated. 1.2. Extracting Research Gaps from Related
    Works Developing a methodology to solve or improve a solution to a specific problem
    requires extensive literature research and analysis, and research gaps need to
    be clarified. Accordingly, this section highlights the methodology for collecting
    papers, analysis criteria of related works, and extracted research gaps. 1.2.1.
    Research Work Collection Methodology As previously foretold, this study is based
    on a specific dataset of aeronautical bearings related to diagnostic and prognostic
    studies. When the gathered research articles are processed on the same dataset/topic,
    this is highly valuable in this context. By comparing identical endeavors using
    the same criteria, it becomes much simpler to trace developments in contributions
    in a given topic and disclose its gaps. It should be emphasized that this work
    used data from the Politecnico di Torino bearing test bench, which is open to
    the public at [7]. As a result, we followed its citations until the end of July
    2023 and discovered that it is receiving a lot of attention, with a total of 70
    citations as clarified by the Scopus citation monitoring database. The majority
    of citations are explicitly dedicated to the application, rather than only making
    a passing reference to it. As a result, it was quite challenging to compile and
    evaluate all the relevant works under this specific circumstance. Accordingly,
    the search mechanism, in this case, was forced to restrict the search period to
    2023, and we came up with a total of six research publications that were considered
    sufficient to conduct an in-depth up-to-date analysis. 1.2.2. Analysis Criteria
    We needed to create a strong criterion for analyzing the gathered works to guarantee
    that research gaps were identified and to support the robustness of and need for
    our suggested technique. Such criterion had to meet previous challenges and condition
    monitoring needs. The bearing dataset introduces massive sets of bearing tests,
    the “variable speed and load set” and the “endurance set”. The first one includes
    13 subsets of different operating conditions and 7 records of operating modes,
    including healthy and unhealthy operating modes (further details will be revealed
    in the data description section). It is mainly dedicated to diagnosis studies
    solving a multi-class classification problem with imbalanced data with higher
    levels of volume (i.e., 46,592,000 samples × 6 channels 46,592,000 𝑠𝑎𝑚𝑝𝑙𝑒𝑠×6 𝑐ℎ𝑎𝑛𝑛𝑒𝑙𝑠)
    , velocity, and variety. The endurance test, with size of 54,067,200 samples ×
    6 channels, contains a set of three damage severity levels with class portions
    of (0.27, 0.22, 0.50) , respectively. It is generated for a specific type of bearing
    and dedicated to studying degradation process regression in a sort of health stage
    classification. It is also important that data can result in a different class
    distribution ratio, creating another challenge of imbalance classification. Accordingly,
    in addition to the three aforementioned challenges of data-driven modeling, other
    analysis criteria, such as whether the authors consider prognosis, diagnostic
    studies, or both, must also be discussed. Also, discussing the treated operating
    conditions is of great importance to revealing the complexity of the study and
    its correspondence to real-world problems. Additionally, the methods used for
    targeting the above challenges, whether data engineering or learning tools, must
    also be discussed to reveal research interest in reducing data complexity and
    improving data representativeness. In this context, the following list of criteria
    was chosen to conduct this analysis: data complexity (i.e., automatic/analytic
    feature extraction, outlier removing, noise suppression/reduction, data imbalance),
    data unavailability (i.e., generative modeling, transfer learning), data drift
    (i.e., adaptive learning), the problem treated (i.e., diagnosis, prognosis, operating
    conditions), and finally, the learning algorithms used. 1.2.3. Related-Work Analysis
    The study in [9] uses a collection of real-world cases, some of which include
    the previously mentioned aeronautical bearing dataset [7]. To identify sensitive
    features, minimize noise, and prevent the loss of important information, the authors
    suggested a multi-scale slip-averaging method based on sensitive multi-scale symbol
    dynamic entropy. This is an important breakthrough in feature engineering. The
    data are randomly divided into training and test sets using a 50% ratio, and classification
    is performed using a support vector machine. Three-fold cross-validation is used
    for SVM evaluation and tuning. While the endurance test associated with prognosis
    was not addressed, the challenges raised here are closely connected to diagnosis.
    Recall, precision, specificity, and F1 score were the four measures employed in
    the evaluation. Thus, this work did not target the problem of data unavailability
    and drift but only focused on data complexity. In [10], the authors suggested
    a full graph dynamic autoencoder, which consists of modules for graph attention
    and full connection autoencoders. Damage severity was not explored in this situation;
    rather, it was solely considered in terms of multi-condition fault identification
    (i.e., diagnosis). The method was also used in many examples, including the study’s
    primary dataset. Dealing with automated feature extraction, denoising, imbalanced
    classification, and data drift were all part of this. However, in this case, only
    a small number of samples (i.e., hundreds) were used, and the problem complexity
    was lowered by dividing it into just two operating modes (i.e., healthy and unhealthy),
    even though the total number of data was massive (i.e., 46,592,000 samples), and
    the presence of seven operating modes greatly increased the prediction complexity.
    Furthermore, the suggested model was evaluated using the same metrics previously
    used in [9]. In general, this approach does not address data unavailability and
    complexity at any point. In [11], a multilayer wavelet attention convolutional
    neural network was suggested to provide machine fault diagnostics while overcoming
    the distorted effects of noise. Utilizing a discrete wavelet attention layer,
    physics-based knowledge is added to the deep network as an extra source of information.
    While other data complexity challenges (e.g., outliers) are not completely taken
    into account, an adaptive learning technique is employed to combat data drift.
    The discrete wavelet attention layer is used to address data unavailability. Although
    the exact method by which the authors employed the moving window to reduce the
    number of samples is unknown, it seems that about 75% of the samples were used
    for training, and the other 25%, for testing. Multi-scale three-dimensional Holo–Hilbert
    spectral entropy, a coarse-grained entropy-based processing technique, was developed
    in [12], and almost identical research was performed in [9] to extract features
    from bearing failures while addressing complexity challenges overall. Bat-optimized
    support vector machine, which is similarly employed for classification (i.e.,
    fault diagnosis only), was then used. The work appears to have decent findings;
    nevertheless, the author’s usage of a limited number of samples (30 for training
    and 20 for testing) was deemed insufficient for such analysis. Despite the findings’
    accuracy, it is impossible to generalize the obtained conclusions for such very
    complicated investigation. Additionally, this study did not focus on data drift
    or availability problems. The authors of [13] treated the problem of data unavailability
    and its drawbacks in the generalization process. To find out more about learning
    behavior in various settings and to acquire general knowledge, they employed transfer
    learning across working conditions. To address the issues of feature extraction
    (i.e., automated data engineering) and fault diagnosis, deep transfer learning
    based on graph convolutional networks was presented. No particular attention was
    paid to the effects of numerous distortions, which include outliers, noise, and
    other disturbances. The unique aspect of this experiment is that only data from
    three loads with speed fluctuations between 6000 and 24,000 rpm were chosen to
    confirm the viability of the suggested approach. As a result, this study had several
    limitations and did not examine the complete diagnosis dataset. Additionally,
    no work was performed on prognosis issues. Likewise, the problem of data drift
    and system’s dynamics received no attention. Interesting work was performed in
    [14] to provide solutions to both data unavailability and data drift using domain
    adaptation, generative modeling, and adaptive learning. Complexity was seen as
    a problem of automatic feature extraction via deep learning, but no additional
    data complexity and outlier analysis were considered, with the exception of sliding-window
    overlap sampling, which increases the number of samples while normalization is
    performed, without further details regarding dataset splitting and the evaluation
    methodology. 1.2.4. Research Gaps Analysis using these precise criteria uncovered
    some significant research gaps in the literature on data-driven diagnosis and
    prognosis of aeronautical bearings, the most significant of which are given below:
    Most of the discussed related works (i) limited their study to a specific set
    of subsets and working conditions (e.g., [13]), (ii) reduced the problem complexity
    by turning it into the healthy–non-healthy problem only without in-depth multi-class
    classification of the seven operating modes (e.g., [10]), or (iii) sub-sampled
    the dataset by increasing the sliding-window length (e.g., [12]). This considerably
    reduces the complexity of the problem in general and also reduces the effectiveness
    of the model in terms of generalization when it comes to real-world application;
    Data complexity from the noise reduction perspective received a little interest
    only from a few works (i.e., [9,11]), while the outlier removal problem has not
    been considered; Solving the common problem of imbalanced classification by ensuring
    fair representation of all classes was not discussed in these cases, which is
    a big problem of model bias to be considered; Most of the time, feature extraction
    techniques were performed automatically by involving deep learning (i.e., [10,13,14]);
    on the contrary, it is of great importance to explore the spectral nature of the
    recorded signal before obtaining better representations (e.g., [9,11,12,15]);
    Most of the time, evaluation procedures were performed by considering training
    and test sets that were randomly selected and split. This does not guarantee the
    learning model’s generalizability, nor does it prevent the risk of overfitting;
    Only a few works considered the use of generative modeling and/or domain adaptation
    transfer learning to overcome the data unavailability issue [13,14]; however,
    it is necessary to target such a problem, especially when data are artificially
    generated (i.e., failure patterns forced to exist and not naturally occurring)
    and not collected from deterioration or a failure mechanism; Data drift and its
    dynamics behind the considered system were only addressed in a few works (i.e.,
    [11,14]); None of these works took into account the second endurance subset, which
    is tightly linked to the prognosis and severity of bearing damage. Overall, these
    shortcomings lead to important conclusions about the generalizability of the models
    discussed in this work and the need for ongoing improvements, including the need
    for our contributions in this work. 1.3. Contributions Based on the above-mentioned
    gaps, our work makes the following contributions: In this work, in an attempt
    to keep the originality of the problem in terms of complexity, a time window with
    a size of 100 samples is used for extracting time-domain and frequency-domain
    features, while an overlap of 20 samples is used to increase the number of samples
    and provide further insights into the correlations among time windows. Compared
    with previous works, the number of samples is massively increased, to about 45,732
    samples. Unlike previous works, we make sure that data scatters represent a very
    complex feature space difficult to separate, as in real-world applications. This
    is to make sure that the addressed problems are real-like and not easy; A robust
    data engineering scheme, including feature extraction, a list of denoising algorithms,
    a set of outlier removals, filtering, smoothing, scaling, and balancing, is introduced
    in this work to serve against multiple types of data distortion and provides a
    better and more meaningful representation of the feature space while uncovering
    hidden patterns. Data imbalance is taken into account in this work by introducing
    a synthetic minority oversampling technique (SMOTE) for augmenting data with low
    proportions and preventing loss of information. This work takes advantage of 15
    time- and frequency-domain features to improve the classification performance
    of the learning process by making the new feature space more robust to noise and
    providing efficient and interpretable representation more flexible and adaptable
    to the system current conditions; Compared with previous works, all of which used
    a random training/test data division process when evaluating the learning model,
    this work uses a three-fold cross-validation process, resulting in the analysis
    of approximately 195 confusion matrices for the diagnostic process and about 18
    confusion matrices for the prognostic process. These numerous results are all
    analyzed to ensure the certainty of the performance of the evaluation procedure.
    CSIDTL, a methodology for selecting and aggregating top learners to transfer additional
    information at different levels of complexity in different cycles, is proposed
    in this work. The goal is to achieve better performance using the pattern separation
    ability of the top learners in each round by taking advantage of the pretrained
    learning weights to initialize the learning model each time; This work adopts
    adaptive learning rules of the LSTM network, which adapts to data shifting in
    time-series analysis better than convolutional networks and other deep learning
    models [6]; Unlike previous works, the proposed CSIDTL model is further investigated
    on another complex endurance test classification problem that includes data of
    higher complexity and cardinality, where many samples of different classes look
    similar to each other at certain points of the representation. This provides further
    insights into using the model for prognostics investigations, providing better
    information for predictive maintenance (i.e., maintenance planning). 1.4. Outline
    To make these contributions clearly illustrated in this work, this article is
    divided into four sections. Besides the introduction in Section 1, in Section
    2, the description of the dataset, as well as its processing methodology, will
    be introduced. The description will be oriented towards the necessary information
    required for the understanding and reproduction of the experiments in the progress
    of this work. Likewise, some important illustrative examples will be used to understand
    the main purposes of the processing scheme and the advantages brought to data
    representation. Section 3 will introduce the proposed CSIDTL approach, its main
    concepts, and learning rules. In addition, this section is also devoted to describing
    the application procedures and the main results with enough illustrations and
    discussions. Finally, Section 4 will conclude this work and will also provide
    interesting hints on future opportunities. 2. Dataset Description and Processing
    The test rig depicted in Figure 1 was utilized to produce the data used in this
    study. It consists of a high-speed spindle that rotates a shaft supported by three
    roller bearings, two accelerometers, and a load cell. The load cell is used to
    measure the axial force applied to the shaft, while the accelerometers are positioned
    at two separate points along the shaft, A1 and A2. Additionally, the test rig
    has a lubrication system distributing oil to the bearings throughout the test.
    The test rig was developed to monitor system vibration while different measurements
    are taken under varying operating conditions with variously damaged bearings.
    Specially designed for high-speed aerospace applications, bearings designated
    B1, B2, and B3 have varying characteristics in terms of pitch diameter, roller
    diameter, contact angle, and number of rolling components. In fact, the introductory
    paper provides a comprehensive analysis of the behavior of different bearing types
    and sizes under various working conditions. However, it is worth mentioning that
    the authors did not study each bearing separately. Instead, these bearings were
    studied as a single system coupled to a single shaft. This is the reason why the
    authors carried out all their experiments on the B1 bearing (see first paragraph
    of Section 3.1 in [7]). The Dynamic Identification and Research Group (DIRG) of
    Politecnico di Torino provided, from this test bed, a huge dataset with two main
    subsets (i.e., 46,592,000 samples × 6 channels and 54,067,200 samples × 6 channels,
    respectively) [7]. The first subset, “Variable speed and load”, includes tests
    under different working conditions up to 30,000 rpm and tests with different types
    and levels of damage and is mainly dedicated to diagnosis studies. The second
    one is the “endurance” set, comprising experiments verifying the speed of damage
    severity under standard operating conditions of load and speed and is dedicated
    to prognosis studies. Accordingly, six channels with duration  𝑇 and sampling
    frequency 𝑓 𝑠 were collected. Each time-domain acceleration record consists of
    𝑇 × 𝑓 𝑠 s samples, while the values of 𝑇 and 𝑓 𝑠 are given differently for the
    two investigations performed on the bearings. The data were collected using accelerometric
    acquisitions at variable rotational speed, radial load, and level of damage, as
    well as temperature measurements. Specific accelerometer sensitivity values were
    set in the OR38 signal analyzer, so the files contain acceleration time histories
    in m/s2. The accuracy of the OR38 input channels is as follows: phase of ±0.02°,
    amplitude of ±0.02 dB, frequency of ±0.005%. The introductory paper [7] does not
    explicitly mention any potential sources of bias or limitations in the dataset.
    However, it is important to note that the data were collected under specific working
    conditions and may not be representative of all possible scenarios. Additionally,
    the analysis techniques used in the paper may have limitations and may not be
    applicable to all types of data. This work uses both subsets to test the capability
    of the proposed data engineering scheme associated with the SCIDTL methodology.
    Accordingly, this section is dedicated to describing the most important features
    of the dataset and its processing steps while passing through some important illustrative
    examples. Figure 1. Overview of the test rig and its main components: (a) the
    test rig; (b) accelerometers’ and reference system’s positions; (c) roller bearing
    shaft. Reproduced from [7], Elsevier: 2019. 2.1. Variable Speed and Load The variable-speed
    and -load experiment aimed to study the behavior of bearings with damage of different
    types and sizes under different operating conditions of rotational speed and load.
    The test was mainly carried out on the bearing in position B1 (see Figure 1a–c),
    which was designed to be easily removed from its support to allow for the artificial
    crafting of different types of defects, mounting, and the monitoring (i.e., taking
    photos) of bearings with damage of different types and sizes during testing. The
    test involved running the bearings at different speeds and under different loads
    to collect data on bearing behavior and performance using vibration sensors. Table
    1 discusses different experimental conditions in this case. Table 1 demonstrates
    that there are 17 operational conditions in this scenario; however, only 13 are
    available in the public dataset files. Unfortunately, there is no direct and explicit
    explanation of this matter in the dataset’s original introductory publication
    [7]. However, according to paragraph 2 on page 265 in [7], the differences between
    the 17 conditions in Table 1 and the 13 conditions publicly available in the dataset
    may be attributed to the fact that only a restricted number of samples for each
    condition were used in the study. The remaining samples might have been removed
    for a variety of reasons, including data quality concerns or a desire to reduce
    the computational cost of the study. It is assumed that the load voltage was actually
    measured during the experiment. Its different values are provided in Appendix
    A, Table A1 in [7]. Table 1. Different operating conditions of the tested bearings
    in the variable-speed and -load experiment [7]. As a result, a list of several
    operating modes was investigated, including one healthy mode (0A) and six unhealthy/fault
    ones (1A–6A). Using a Rockwell tool, the localized faults on the rolling components
    resulted in a conical indentation on the inner ring or on a single roller. The
    damaged elements are reported in Table 2. The size of the resultant circular region
    is indicated by its approximate measured diameter (i.e., 150 mm, 250 mm, 450 mm).
    The entire process took around 30 min, and the greatest rotating speeds were not
    achieved under heavier load conditions due to the restricted power of the inverter.
    Table 2. Different types of crafted defects of tested bearings [7]. Figure 2 is
    a further example showing the indentation of bearing 4A. This indentation is considered
    to be very useful, as monitoring its evolution makes it possible to understand
    fault characteristics (e.g., severity and location), assess their impact on bearing
    performance, guide design improvements, and evaluate corrective maintenance actions.
    Figure 2. Example of initial indentation of bearing 4A. Reproduced from [7], Elsevier,
    2019. 2.2. Endurance Test An endurance test verifies the damage propagation rate
    under standard operating conditions (load and speed) and highlights the influence
    of lubricating oil. The bearing was not brought to failure during the endurance
    test, and the physical variations of the indentation, both in shape and in extension,
    were quite limited. Identifying the evolution of damage given such small and limited
    variations is a very challenging task. The endurance test was carried out under
    the same conditions for each measurement, with a rated speed of 300 Hz and a load
    of 1800 N. The lubricating oil was changed before starting the endurance test,
    and the new oil had almost the same viscosity as the previous one. However, the
    lubricating oil was not specifically designed for high-speed applications. Standard
    oil was not used during the endurance test because it is neurotoxic, and changing
    it is a mandatory requirement for laboratory experiment safety. The experiment
    consisted of a long test lasting around 330 h on the 4A bearing at constant speed
    and load (this information is not revealed in the original article due to non-disclosure
    arguments). Three different groups of endurance data can be highlighted. These
    clusters correspond to the groups of acquisitions 19–70 h (End1), 70–124 h (End2),
    124–223 h (End3). The clustering of the data is due to the mounting and dismounting
    of the bearing for the purpose of inspecting the damage and producing the images
    in Figure 3 in different life stages, while the pictures in sub-figures (c,d)
    were taken at 300 rpm and 1800 N. Figure 3. Illustrative damage propagation examples
    in endurance test on bearing 4A: (a) fault patterns after 19 h; (b) fault patterns
    after 70 h; (c) fault patterns after 124 h; (d) fault patterns after 232 h. Reproduced
    from [7], Elsevier, 2019. To sum up, Figure 4 shows a summary of the data generation
    experiments that more clearly addresses the experimental objectives and circumstances.
    The numbering (1–3), in this case, indicates different steps performed in order,
    and the time and type of each experiment are indicated. Figure 4. Dataset generation
    goals and scenarios. 2.3. Data Processing To provide a clean and meaningful feature
    space to feed into the proposed CSIDTL learning process, a set of well-defined
    steps are followed, namely, feature extraction, a list of denoising algorithms,
    a set of outlier removals, filtering, smoothing, scaling, and balancing. Figure
    5 addresses this data processing methodology by introducing these steps in the
    form of six different layers. The order of the presented layers is very important
    for the process to run smoothly. It should be mentioned that this section and
    the next ones contain many interesting tools and metrics that are used and discussed.
    Therefore, describing the mathematical background of these tools and their demonstration
    is not appropriate for this paper in terms of length and number. Instead, a set
    of very interesting references already well known in the literature will be cited
    and referred to when describing these tools. Furthermore, this work concentrates
    solely on the mathematical background of the innovative new formulas that are
    the focus of this paper and makes them easy to present for replication in programming
    terms. Figure 5. Illustration of the data processing methodology. Finally, it
    should be noted that the tools described in the following section might be well
    known in the literature. However, the main contribution of this paper in terms
    of data processing lies in the use of these tools in the form of different layers
    (which will be explained in the next sub-sections) in specific order. In addition,
    the combination of these different tools is specifically designed to tackle problems
    presented by data. The order of these layers is defined based on the authors’
    area of expertise in maintaining feature scales according to the algorithmic requirements
    of deep learning. The following sub-sections will also give examples of layer
    order and the repetition of certain layers to solve similar problems. 2.3.1. Scaling
    Layer Measurements are filtered with moving average, fixed window, and three-order
    one-dimensional median filtering [16]. Median filtering helps to effectively remove
    impulsive noise from vibration signals without distorting the underlying data.
    It is particularly useful in applications where preserving sharp edges and details
    as signal descriptors is important to maintain the general shape of this signal.
    The scaling layer also involves another step of fixed-time-window averaging based
    on the time-domain smoothing of signal amplitudes [17]. This further helps reduce
    noise and smooth signal data and improves overall data quality while achieving
    more accurate and reliable results. Afterwards, a final min–max normalization
    slice is included to scale each channel record in the range [0, 1], allowing for
    the better tuning of learning systems on different channels with different scales
    [18]. It is important to use this layer in different places and not just at the
    beginning of the data processing phase. For example, the extraction layer and
    the denoising layer can change the feature scales, and it is better to rescale
    them again to ensure the importance of the data after such steps. 2.3.2. Feature
    Extraction Layer In this particular case, a set of well-known features are selected
    to be extracted from both the time domain and the frequency domain, in particular
    from vibration signals, which are well studied in this work. Based on prior research,
    these features have proven to be effective in diagnosis and prognosis studies,
    particularly for bearings. For instance, the work presented in [19,20,21] showcased
    the capability of these features to achieve higher prognosability. In other words,
    they allow for the distinguishing between data clusters of healthy and non-healthy
    patterns. Time-domain features include mean value, standard deviation (Std), skewness,
    kurtosis, peak to peak (peack2peak), square root of the arithmetic mean (RMS),
    crest factor, form, impulse factor, margin factor, and energy. Additionally, frequency-domain
    features include mean value of spectral kurtosis (SKMean), standard deviation
    of spectral kurtosis (SKStd), spectral kurtosis of skewness (SKSKewness), and
    spectral kurtosis of kurtosis (SKKurtosis). A detailed mathematical representation
    of these characteristics can be seen in Appendix A in [19]. It should be mentioned
    that a time window with a length of 100 samples is slid over the six channels
    to extract these features with an overlap of 20 samples. This helps reduce computational
    complexity by reducing 6 × 100 dimensional features to 1 × 15 features for each
    window while avoiding loss of information by using overlap and the most important
    features. 2.3.3. Denoising Layer The extracted features are passed through another
    slice of denoising. The denoising process, in this case, is based on Cauchy a
    priori wavelets. Such algorithm is very useful in denoising, because it takes
    advantage of the inherent sparsity of wavelet coefficients and the robustness
    provided by the Cauchy prior [9]. The Cauchy prior assumes a heavy-tailed distribution
    for noise, which is often a more realistic model for real-world data. This helps
    to remove outliers or extreme noise values, thereby improving denoising performance.
    Additionally, by using wavelet coefficients, which encode the signal into various
    frequency components, the method can effectively separate the noise from the signal
    in the wavelet domain and adaptively estimate the noise-free coefficients. This
    allows for better preservation of important signal features while reducing noise,
    making it a powerful technique for denoising applications [9]. According to recent
    works on bearing fault diagnosis, such as [22,23], the wavelet denoising algorithm
    can help to improve fault signature extraction, increase classification accuracy,
    improve robustness to noise and outliers, improve multi-resolution signal analysis,
    improve feature extraction, enable the use of traditional machine learning and
    deep learning methods, and achieve a more interpretable signal representation.
    2.3.4. Outlier Removal Being the most important layer in the proposed flowchart
    of data processing, the outlier removal layer is very effective in improving data
    quality, especially when aircraft engines are considered, as they are highly dynamic
    systems susceptible to outliers due to harsh operating conditions. In this case,
    an outlier detection list that is based on different types of distances and statistical
    tests (i.e., Grubbs test; Mahalanobis, Euclidean, and Minkowski distances) is
    used. Overall, these distances and statistical tests play a vital role in outlier
    detection by quantifying the dissimilarity or anomaly of data points compared
    with the majority of the dataset. They provide valuable insights into the presence
    of outliers, helping to identify potential errors, anomalies, or interesting patterns
    in the data [24]. A mixture of these tools is used to strengthen the outlier detection
    process and overcome the shortcomings of each by helping to eliminate/reduce outliers
    as much as possible. It should be mentioned that in such a situation, it is necessary
    to take into account that each class of data must be processed separately by such
    algorithm, because processing global data all at once would lead to a massive
    loss of data samples, as different classes can be seen as tools for others, and
    so on. A different class is supposed to contain different models, and different
    models are more similar to each other. 2.3.5. Data Balancing Layer This work follows
    a minority oversampling technique (SMOTE) [25] with k-nearest neighbors, which
    is a powerful method used in machine learning and data analysis to solve class
    imbalance problems. The technique offers several advantages. First, it helps solve
    the problem of data scarcity or lack of representative samples for the minority
    class by generating synthetic samples that closely resemble real instances. This
    improves the model’s ability to learn patterns and make accurate predictions for
    the minority class. Second, SMOTE reduces the bias towards the majority class,
    ensuring a fair representation of both classes in the dataset. This leads to better
    model performance and avoids the risk of misclassification or underestimation
    of the minority class. Overall, by effectively improving the training data, SMOTE
    significantly improves the performance and reliability of machine learning models.
    2.4. Illustrative Example of Processed Data The variable-speed and -load test
    includes a list of 13 operating conditions, and each condition has seven operating
    mode scatters (i.e., healthy (0A) and unhealthy (1A–6A)). On the other hand, the
    endurance test has unknown operating conditions of speed and load that have not
    been disclosed due to some undisclosed agreements. It includes three stages of
    bearing severity reflecting the damage propagation process of the bearings. Accordingly,
    this sub-section will present examples of data scatters in both cases while comparing
    prepared data and raw data. Comparing scatter plots of raw data and prepared data
    helps to assess the impact of data preprocessing techniques or methods. It allows
    for examining how data manipulation has influenced the distribution and pattern
    of the data points. 2.4.1. Variable-Speed and -Load Set Regarding the variable-speed
    and -load test, since data scatters are very numerous, we decided to take some
    interesting examples of load and speed to be able to observe their effect on data
    complexity. Accordingly, four conditions, namely, 1, 4, 8, 13, with nominal speed
    (Hz) and voltage load (mV) of {(100, 0), (100, 900), (300, 500), (500, 500)} corresponding
    to the qualitative variables of {(minimum speed, minimum load), (minimum speed,
    maximum load), (average speed, maximum load), (maximum speed, maximum load)} are
    selected. The reason for selecting only these conditions is that the dataset is
    massive and contains a wide range of subsets and classes, which cannot be illustrated
    at once. Therefore, these examples are considered very adequate to obtain a general
    conclusion on the whole dataset, since they contain information on almost all
    possible cases of variations in load and working conditions. In our example, we
    provide rounded values for load voltage with sensitivity of 0.499 mV/N (see first
    paragraph, page 6 in [7]). In this context, t-Distributed Stochastic Neighbor
    Embedding (t-SNE) is used to map high-dimensional data to a low-dimensional space
    while preserving similarities among data points, with emphasis on distances relative
    to each other. As a result, the data scatters in Figure 6 are obtained to visualize
    and explore our dataset. Figure 6a refers to healthy operating modes, low distortions,
    and less harsh working conditions. There is minimum speed and null load, and the
    bearings are completely healthy. In this case, it can be observed that samples
    of different data classes have some pattern agglomeration of different operating
    modes (e.g., class 4 and class 2) that can be easily distinguished even with a
    simple linear model. On the other hand, comparing these representations with each
    other or with other classes clearly explains the complexity of the data, reflected
    by higher cardinality. Contrariwise, the prepared version in Figure 6e increases
    this classification capability by showing an additional number of distinguished
    classes (e.g., 0, 4, 2, 6). This clearly illustrates the efficiency of data processing,
    especially denoising and removing outliers. It should be mentioned that these
    details only appear in two-dimensional t-SNE distributions. Thus, it is possible
    to observe better performance of the proposed data engineering details if we explore
    three-dimensional data visualization. The same explanation could be projected
    onto Figure 6b–d when comparing them to their prepared version in Figure 6f–h.
    This clearly shows that data engineering helps to reveal some important patterns
    in the data that are hidden in the original feature spaces. Finally, further mapping
    processes using CSITDL could improve representations of feature spaces. Figure
    6. Comparison between raw and processed data scatters of variable-speed and -load
    experiments: (a–d) raw data scatters of conditions 1, 4, 8, 13, respectively;
    (e–h) prepared data scatters of conditions 1, 4, 8, 13, respectively. So far,
    presentation and argumentation are based on comparing dataset scatters of raw
    data and prepared data. However, to obtain a clear conclusion about data characteristics
    beneficial for the next stages of adaptive deep learning, another important note
    in this case can be mentioned. We can observe, in Figure 6e–h, that the harsher
    the conditions are (i.e., greater speed and load), the more they lead to numerous
    distortions. This further complicates the process of understanding and distinguishing
    different kinds of patterns, increasing the level of cardinality, which definitely
    increases the complexity of the deep learning process. 2.4.2. Endurance Set Concerning
    the endurance test, the experiments show regression in the long-term damage of
    bearing 4A. This means that the data are highly correlated and the propagation
    of damage is regressive and slow. Therefore, as the experiment is related to damage
    severity, the correlation among samples is higher, while it is more difficult
    to highlight the different patterns of each health stage separately. In this case,
    we modify the outlier removing layer using a loop, repeating the process over
    and over for 20 times while also increasing the span of the time window to 50
    samples. In another way, no matter the complexity of the diagnosis problem in
    the first experiment of variable speed and load, the endurance test resembles
    a set of very complex data scatters with further complexity. Figure 7a represents
    the original feature space, reflecting a mixture of data patterns and a higher
    level of complexity. By comparing it with the prepared version, the data representations
    seem a kind of agglomeration of samples holding some similar patterns. It is actually
    a very positive indication that the data engineering process helps to process
    data classes and uncover hidden patterns. An additional comparison between data
    in the endurance test and variable-speed and -load test can be made in this case.
    If we compare the raw and prepared data of the first version with those of the
    second one, it is clearly confirmed that the endurance data are more complex,
    as previously indicated. In other words, the model reconstruction process also
    requires further abstractions in this case than in the variable-speed and -load
    experiment. The agglomeration of the samples shown in Figure 7b is caused by continuous
    smoothing and filtering as a result of repeating the scaling layer several times,
    thus allowing similar patterns to be grouped together, thereby improving the quality
    of the data. Figure 7. Comparison between raw and processed data scatters of endurance
    experiments: (a) raw data scatters; (b) prepared data scatters. 3. Methods, Application,
    and Result Discussion This section presents the CSIDTL method, its main learning
    rules, its application, and the result discussion, focusing only on the new mathematical
    representation, while the well-known mathematics available in the literature are
    not considered for description in this section but are referenced herein using
    straight-to-the-point references. 3.1. Proposed Approach Figure 8 is a simplified
    schematic diagram of the proposed CSIDTL. The CSIDTL algorithmic architecture
    can be simplified in three particular steps. Figure 8. Schematic diagram of the
    proposed CSIDTL approach: (a) training a set of learning models separately for
    each operating condition; (b) using the cross-validation technique to evaluate
    model performance; (c) selecting and storing the learning parameters of the best
    learners based on accuracy; (d) unleashing the aggregation process only for selected
    parameters and determine initial parameters of following rounds. Step 1: A set
    of homogeneous learning models, namely, LSTM networks (refer to [26] for details
    on the mathematical background of LSTM networks), are trained in a loop on the
    different subsets (13 subsets related to operating conditions) of the variable-speed
    and -load dataset. This means that each LSTM network is trained for the classification
    process of 7 different operating modes. In the first round, 𝑘=0 , the LSTM networks’
    learning parameters are randomly initialized from specific probability distribution
    𝑃 with mean 𝜇 and standard deviation 𝛿 as in (1). {𝑤 𝑖 𝑘 ,  𝑤 𝑟 𝑘 ,  𝑏 𝑘 }=𝑃(𝜇,𝛿)
    (1) In this case, the 3-fold cross-validation technique is used to train each
    network per condition in different rounds 𝑘 . Consequently, there is a total of
    13 × 3 trained LSTM networks in each round. Step 2: Among these 13 × 3 models,
    only a few models are selected to accomplish the training process of LSTM networks
    in upcoming rounds. The selection process involves some specific criteria (i.e.,
    testing accuracy, in our case) to perform the following SCIDTL rounds. These models
    are then stored, and their parameters, aggregated and transferred to initialize
    all deep networks in the following rounds, and so on. It should be mentioned that
    the number of stored learning models is incremented. This means that in each new
    round, both the old, selected models and the newest ones are used for the aggregation
    and initialization of the learning parameters using transfer learning. Step 3:
    Weight initialization involves the aggregation of collected weights under different
    conditions. This can be referred to as a collaborative training, where the global
    learning parameters combine information across all different conditions. The transfer
    learning concept, in this case, appears in both cases of aggregation and weight
    initialization. This means collaboration across conditions and the fine tuning
    of the LSTM network for upcoming rounds. So, if we think of global loss in specific
    round 𝑘 ( 𝑙 𝐺(𝑘) ) as our main objective function to be minimized, 𝑙 𝐺(𝑘) can
    be presented as the minimization of loss in both the source domain and the target
    domain as in (2). 𝑙 𝐺(𝑘) =‖ 𝑙 (𝑘−1)+ 𝑙 (𝑘) ‖  (2) In our case of the LSTM network,
    from the set of input weights 𝑤 𝑖 (𝑐,𝑓,𝑘) and recurrent weights 𝑤 𝑟 (𝑐,𝑓,𝑘) and  𝑏
    (𝑐,𝑓,𝑘) , where 𝑘=1:𝑚 is the number of rounds, we only select a few models and
    limit them to a new set of parameters, { 𝑤 𝑖 𝑠 , 𝑤 𝑟 𝑠 ,  𝑏 𝑠 }, where 𝑠=1:𝑛 is
    the number of selected models incremented in each round. (𝑐,𝑓) , in this case,
    refer to the condition label and the cross-validation fold index, respectively.
    Afterwards, these collected parameters are aggregated using an averaging method
    as illustrated in Equations (3) and (4) and used as initial parameters { 𝑤 𝑖 0
    , 𝑤 𝑟 0 ,  𝑏 0 } of the all the models in all following rounds. 𝑆 refers to the
    selected model index; 𝑛 is the total number of selected models per round; 𝑐 is
    the number of conditions; 𝑓 is the number of folds; 𝑘 is the index of a round;
    and 𝑚 the is maximum number of rounds. Subscript 0 refers to initial parameters.
    ∀{ 𝑤 𝑖 𝑠 , 𝑤 𝑟 𝑠 ,  𝑏 𝑠 } 𝑛 𝑠=1 ∈  {𝑤 𝑖 (𝑐,𝑓,𝑘) ,  𝑤 𝑟 (𝑐,𝑓,𝑘) ,  𝑏 (𝑐,𝑓,𝑘) }
    𝑚 𝑘=1  | 𝐴𝑐𝑐𝑢𝑟𝑎𝑐𝑦≥ 90%, { 𝑤 𝑖 0 , 𝑤 𝑟 0 ,  𝑏 0 }= 1 𝑛 ∑ 𝑛 𝑠=1 { 𝑤 𝑖 𝑠 , 𝑤 𝑟 𝑠
    ,  𝑏 𝑠 } (3) 𝑛= 𝑛 𝑘 +𝑛 𝑘−1  |  𝑛 0 =0 (4) If we consider this approach as an algorithm
    running on a single microprocessor in a sort of repetitive loop under different
    working conditions, the pseudo-code of such CSIDTL can be presented as in Algorithm
    1. Algorithm 1: Simplified CSIDTL pseudo-code. Inputs: Inputs 𝑥  and labels 𝑦
    ; Number of conditions 𝑐 ; Number of cross-validation folds 𝑓 ; Maximum number
    of rounds 𝑚 ; Outputs: Best initialization parameters { 𝑤 𝑖 0 , 𝑤 𝑟 0 ,  𝑏 0 }
    % Initialize the learning model randomly {𝑤 𝑖 0 ,  𝑤 𝑟 0 ,  𝑏 0 }=𝑃(𝜇,𝛿) ; For
    𝑘=1:𝑚 For 𝑐=1: 13 For 𝑓=1:3 % Train the model and extract its parameters; s.t.
    𝑙 𝐺(𝑘) =‖ 𝑙 (𝑘−1)+ 𝑙 (𝑘) ‖  % Involvement of transfer learning % Select 𝑛 and
    aggregate best learners’ parameters according to a specified criterion; % Initialize
    learning parameters for upcoming rounds ∀{ 𝑤 𝑖 𝑠 , 𝑤 𝑟 𝑠 ,  𝑏 𝑠 } 𝑛 𝑠=1 ∈  {𝑤
    𝑖 (𝑐,𝑓,𝑘) ,  𝑤 𝑟 (𝑐,𝑓,𝑘) ,  𝑏 (𝑐,𝑓,𝑘) } 𝑚 𝑘=1  | 𝐴𝑐𝑐𝑢𝑟𝑎𝑐𝑦≥ 90% , { 𝑤 𝑖 0 , 𝑤 𝑟
    0 ,  𝑏 0 }= 1 𝑛 ∑ 𝑛 𝑠=1 { 𝑤 𝑖 𝑠 , 𝑤 𝑟 𝑠 ,  𝑏 𝑠 } ; 𝑛= 𝑛 𝑘 +𝑛 𝑘−1  |  𝑛 0 =0 ;
    End End End 3.2. Application and Result Discussion In this work, we launched two
    experiments on two subsets of the dataset using a laptop with a four-core i7 microprocessor,
    16 GB RAM, and 12 MB cache memory. In the first experiment of “variable speed
    and load”, the CSIDTL algorithm was run for five particular rounds in an amount
    of time of 5.9170 h. Since the process is very slow, there is a small chance of
    involving random search algorithms and the grid search mechanism for hyperparameter
    tuning. Therefore, the LSTM network parameters were manually tuned based on an
    error-and-trial basis instead. Three-fold cross-validation was involved in studying
    the performance of the proposed approach, while well-known metrics, such as 𝐴𝑐𝑐𝑢𝑟𝑎𝑐𝑦
    , 𝑅𝑒𝑐𝑎𝑙𝑙 , 𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 , and 𝐹1 𝑠𝑐𝑜𝑟𝑒 , were used to evaluate the performance of
    the training process. For the mathematical background and significance of these
    metrics, please refer to the paper [27]. During the evaluation, we focused on
    collecting testing performance, as it is very important to assess both the approximation
    and generalization capabilities of learning models. The selection of the best
    learners was constrained by 𝐴𝑐𝑐𝑢𝑟𝑎𝑐𝑦 ≥ 90% . All trained models of three-folds
    were involved in the transfer learning-based selection and aggregation process,
    while the resulting illustration of each model per condition is the average value
    of the values obtained from the results. Accordingly, a single-layer LSTM network
    with 40 neurons, 𝑙 2 regularization parameter = 1 × 10−4, initial learning rate
    = 1 × 10−2, minibatch size of 200 samples, and the maximum number of epochs of
    600 was adopted for the used hyperparameters. After the training process, the
    best results were collected and labeled as best-round training. It should be mentioned
    that the results, in this case, were numerous, as a matrix of 4 × 13 elements
    was obtained per round. Additionally, about 13 × 3 × 5 confusion matrices were
    analyzed in this case. Therefore, an average of the entire matrix was used to
    better illustrate and compare global results, because it is difficult to showcase
    such numerous results. 3.2.1. Variable-Speed and -Load Experiment Accordingly,
    Figure 9 is introduced to showcase the obtained global results of the CSIDTL approach
    compared with the LSTM network, while Table 3 is used to indicate in which rounds
    the best learners were obtained under each condition. In this case, the classification
    performance metrics were improved by about 12.15% compared with traditional LSTM.
    This means that the accuracy was about 93.63% for the entire variable-speed and
    -load dataset. This is considered an excellent improvement in the field. More
    specifically, the LSTM network is considered a robust generalizer only when data
    are processed under less harsh conditions, as it is seen for conditions 3, 6,
    and 8 in Figure 9a. Contrariwise, the CSIDTL showed its performance on the entire
    subset. This means that the adopted approach of selecting and aggregating the
    best learners and transferring them across conditions better helps to overcome
    the lack of representative data and not only benefits the data drift mechanism
    of LSTM. Figure 9. Comparison of classification performance of studied models:
    (a) LSTM network; (b) LSTM network with CSIDTL learning methodology. Table 3.
    Best learners per rounds. Table 3 introduces the best training models per round
    under each specific condition. It is clear that the load had an impact on the
    training process more than rotational speed. This is why the harsh conditions
    highlighted in green color show that the model needed further and deeper representations
    (i.e., CSIDTL) than ordinary deep learning (i.e., LSTM). The models also expressed
    their need for additional information across working conditions, leading to consuming
    more learning time to reach a better data representation. This fully confirms
    our initial perception: “learning under data unavailability, complexity, and drift
    requires generative modeling, adaptive learning, and deep learning all together
    in a global learning process”. 3.2.2. Endurance Experiment For the endurance experiment,
    the best learning parameters obtained (Equations (1) and (2)) from the fifth round
    of the first experiment were transferred as they were to the learning process
    dedicated to prognosis. In this case, a single subset of three different classes
    related to different damage severity related to bearing health conditions was
    treated. The same learning CSIDTL options were kept in this case. The only thing
    that changed was the number of training rounds. So, the models seemed to have
    achieved great results in round 1 (see Table 4) in this case (meaning round 7
    if we count the first five rounds in the first experiment resulting in weight
    initialization in the second experiment). Similarly, in this case, there were
    3 × 3 confusion matrices, which are difficult to be illustrated in this case.
    Instead, the averaged results are showcased in Figure 10. Accordingly, after the
    learning process, which took about 0.1754 h, the learning performance was improved
    by about 10.87%, reaching about 95.65% accuracy, which is considered a great achievement
    for a very complex dataset with a higher level of complexity and drift. Figure
    10. Results obtained in the endurance test dataset for each round. Table 4. Best
    learners per rounds. 3.3. General Discussion In general terms, the problem addressed
    in the case of the two experiments shows the following: The need to transfer learning
    across conditions to improve classification performance in terms of the generalization
    of the learning model (Figure 9 and Table 3); CSDTL better expresses the relationships
    between the number of rounds required for training and data complexity to overcome
    data drift problems. This is highlighted by the more rounds needed for further
    complex conditions, as shown in Table 3; The training process showcases the effectiveness
    of LSTM by retaining adaptive learning, especially for less complex datasets.
    This is why it needs to be boosted by transfer learning and collaborative aggregation;
    The best results on the endurance set were obtained quickly compared with the
    variable-speed and -load experiment. This was due to the benefits of directly
    transferring the learning parameters from the fifth round (i.e., holding enough
    additional information across conditions) to the first learning round. The improvement
    rates of performance in both diagnosis and prognosis also reflect the importance
    of the procedure in the training process. Overall, the proposed data engineering
    scheme helps, as the primary step for data complexity reduction, to extract meaningful
    features and patterns, improving accuracy and reliability in bearing fault diagnosis
    and prognosis. Techniques like time-domain analysis, frequency-domain analysis,
    wavelet analysis, and statistical feature extraction help to distinguish among
    different types of patterns in sensor data of different fault types. The transfer
    learning and aggregation process leverages additional knowledge from diverse models
    trained on diverse conditions in other domains, which improves the accuracy and
    effectiveness of fault diagnosis and prediction algorithms. The LSTM adaptive
    deep learning capability effectively helps to follow data shifting, keeping the
    model always up to date and focused on new data. Thus, potentially, depending
    on the performance of the entire proposed data engineering methodology and CSIDTL,
    this approach could be applied to fault diagnosis, prognosis, and remaining-useful-life
    assessment, as well as data anomaly detection and mitigation. From the perspective
    of the aerospace industry, where reliability and safety are paramount, this coupled
    data engineering scheme within CSIDTL could significantly improve maintenance
    practices. Additionally, it could help identify potential bearing failures or
    anomalies, enabling timely maintenance and reducing the risk of critical malfunctions.
    Additionally, the real-time monitoring provided by CSIDTL fault diagnosis/prognosis
    could help optimize operational efficiency by minimizing downtime and increasing
    productivity. This methodology could also be extended beyond aerospace to other
    areas, such as automotive or industrial machinery, where bearing efficiency and
    performance are vital. As a result, the practical application of such methodology
    for real-world fault diagnosis/prognosis has great potential for improving asset
    management and safety in a variety industries. 3.4. Comparison with Previous State-of-the-Art
    Works As mentioned earlier in the section on research gaps, previous state-of-the-art
    works transformed datasets into less complex feature spaces by performing sub-sampling,
    selecting a few sets to illustrate the performance of their model, or merging
    different sub-classes of unhealthy modes to reduce the number of classes, thereby
    reducing the complexity of the problem to be solved. While doing so, most of the
    experiments discussed a simple random splitting of the dataset, while the prognosis
    case was not considered the main goal of their studies. As a result, these works
    clearly achieved great accuracy in this case. However, as far as generalization
    is concerned, their models lack generalization at some point compared with this
    study. In fact, this study is conducted on a way-too-massive feature space, with
    multi-class classification problems (i.e., seven operating modes) and different
    case-study scenarios (diagnosis and prognosis). Additionally, this paper treats
    the data unavailability problem, drift, and complexity instead of only treating
    complexity as in previous works. Furthermore, this paper specifically introduces
    a well-structured data engineering scheme, justified by data challenges, that
    leads to outstanding data representation as the primary step to target data complexity.
    The proposed work delves deeper into details than previous works, yielding outstanding
    results despite the increased complexity. This is why a numerical comparison between
    the results obtained in this paper and in previous ones cannot be performed and
    would not be fair, as our work and previous works follow different approaches
    and reach different objectives and conclusions. 4. Conclusions This work supports
    the hypothesis that diagnosis and prognosis using data-driven methods in highly
    dynamic systems, in particular safety-critical systems, must take into account
    three main challenges: data drift, complexity, and unavailability. This work,
    therefore, addresses this hypothesis by introducing a learning model called CSIDTL
    that involves adaptive learning, deep learning, and transfer learning to address
    these challenges, respectively. The model is constructed to involve incremental
    selective learning and collaborative transfer learning in different learning rounds
    to address these challenges in a regressive manner. Compared with traditional
    deep learning models such as LSTM and, in general, compared with previous work
    that mainly tackles data complexity issues, the model achieves better results,
    whose stability is demonstrated using cross-validation. This confirms, to a large
    extent, the need for such a mix of learning tools and domains to perform such
    a complex process. In terms of future prospects and opportunities and concerning
    feature engineering, further algorithms and tools for detecting and removing outliers/noise
    should be discussed to further enhance data quality, and suggesting tools for
    assessing such quality instead of data visualization would be a great advantage.
    Further, from the perspective of learning systems, this work uses a single-layer
    LSTM model to realize the CSIDTL process, so the introduction of a deeper architecture
    and adaptive learning variants, such as bidirectional LSTM and gated recurrent
    units, with a different learning philosophy such as ensemble learning, in addition
    to additional generative modeling tools, could enable the three data-related challenges
    to be tackled at a higher level. Author Contributions Conceptualization, T.B.;
    methodology, T.B. and M.B.; validation, T.B. and M.B.; formal analysis, T.B. and
    M.B.; investigation, T.B.; resources, T.B.; data curation, T.B. and M.B.; writing—original
    draft preparation, T.B.; writing—review and editing, T.B. and M.B. All authors
    have read and agreed to the published version of the manuscript. Funding This
    research received no external funding. Institutional Review Board Statement Not
    applicable. Informed Consent Statement Not applicable. Data Availability Statement
    All the materials required to reproduce the findings of this study are available
    at https://zenodo.org/record/8385839 (accessed on 27 August 2023). Acknowledgments
    The authors would like to thank the Dynamic Research and Identification Group
    (DIRG) of Politecnico di Torino and the authors of the introductory article (Daga,
    A.P.; Fasana, A.; Marchesiello, S.; Garibaldi, L.) for making their dataset publicly
    available, which proved very important and useful for conducting the proposed
    CSIDTL experiments. Conflicts of Interest The authors declare no conflict of interest.
    References Berghout, T.; Mouss, M.-D.; Mouss, L.; Benbouzid, M. ProgNet: A Transferable
    Deep Network for Aircraft Engine Damage Propagation Prognosis under Real Flight
    Conditions. Aerospace 2022, 10, 10. [Google Scholar] [CrossRef] Rejith, R.; Kesavan,
    D.; Chakravarthy, P.; Narayana Murty, S.V.S. Bearings for Aerospace Applications.
    Tribol. Int. 2023, 181, 108312. [Google Scholar] [CrossRef] Wei, Z.; Zhang, S.;
    Jafari, S.; Nikolaidis, T. Gas Turbine Aero-Engines Real Time on-board Modelling:
    A Review, Research Challenges, and Exploring the Future. Prog. Aerosp. Sci. 2020,
    121, 100693. [Google Scholar] [CrossRef] Saxena, A.; Goebel, K.; Simon, D.; Eklund,
    N. Damage Propagation Modeling for Aircraft Engine Run-to-Failure Simulation.
    In Proceedings of the International Conference on Prognostics and Health Management,
    Denver, CO, USA, 6–9 October 2008; pp. 1–9. [Google Scholar] Arias Chao, M.; Kulkarni,
    C.; Goebel, K.; Fink, O. Aircraft Engine Run-to-Failure Dataset under Real Flight
    Conditions for Prognostics and Diagnostics. Data 2021, 6, 5. [Google Scholar]
    [CrossRef] Berghout, T.; Benbouzid, M. A Systematic Guide for Predicting Remaining
    Useful Life with Machine Learning. Electronics 2022, 11, 1125. [Google Scholar]
    [CrossRef] Daga, A.P.; Fasana, A.; Marchesiello, S.; Garibaldi, L. The Politecnico
    Di Torino Rolling Bearing Test Rig: Description and Analysis of Open Access Data.
    Mech. Syst. Signal Process. 2019, 120, 252–273. [Google Scholar] [CrossRef] Berghout,
    T.; Mouss, L.H.; Kadri, O.; Saïdi, L.; Benbouzid, M. Aircraft Engines Remaining
    Useful Life Prediction with an Adaptive Denoising Online Sequential Extreme Learning
    Machine. Eng. Appl. Artif. Intell. 2020, 96, 103936. [Google Scholar] [CrossRef]
    Tan, H.; Xie, S.; Zhou, H.; Ma, W.; Yang, C.; Zhang, J. Sensible Multiscale Symbol
    Dynamic Entropy for Fault Diagnosis of Bearing. Int. J. Mech. Sci. 2023, 256,
    108509. [Google Scholar] [CrossRef] Yan, S.; Shao, H.; Min, Z.; Peng, J.; Cai,
    B.; Liu, B. FGDAE: A New Machinery Anomaly Detection Method towards Complex Operating
    Conditions. Reliab. Eng. Syst. Saf. 2023, 236, 109319. [Google Scholar] [CrossRef]
    Wang, H.; Liu, Z.; Peng, D.; Zuo, M.J. Interpretable Convolutional Neural Network
    with Multilayer Wavelet for Noise-Robust Machinery Fault Diagnosis. Mech. Syst.
    Signal Process. 2023, 195, 110314. [Google Scholar] [CrossRef] Zheng, J.; Ying,
    W.; Tong, J.; Li, Y. Multiscale Three-Dimensional Holo–Hilbert Spectral Entropy:
    A Novel Complexity-Based Early Fault Feature Representation Method for Rotating
    Machinery. Nonlinear Dyn. 2023, 111, 10309–10330. [Google Scholar] [CrossRef]
    Zhao, X.; Zhu, X.; Yao, J.; Deng, W.; Cao, Y.; Ding, P.; Jia, M.; Shao, H. Intelligent
    Health Assessment of Aviation Bearing Based on Deep Transfer Graph Convolutional
    Networks under Large Speed Fluctuations. Sensors 2023, 23, 4379. [Google Scholar]
    [CrossRef] Wang, X.; Jiang, H.; Wu, Z.; Yang, Q. Adaptive Variational Autoencoding
    Generative Adversarial Networks for Rolling Bearing Fault Diagnosis. Adv. Eng.
    Inform. 2023, 56, 102027. [Google Scholar] [CrossRef] Thelaidjia, T.; Chetih,
    N.; Moussaoui, A.; Chenikher, S. Successive Variational Mode Decomposition and
    Blind Source Separation Based on Salp Swarm Optimization for Bearing Fault Diagnosis.
    Int. J. Adv. Manuf. Technol. 2023, 125, 5541–5556. [Google Scholar] [CrossRef]
    Ohki, M.; Zervakis, M.E.; Venetsanopoulos, A. N. 3-D Digital Filters. Control.
    Dyn. Syst. 1995, 69, 49–88. [Google Scholar] Smith, S.W. Moving Average Filters.
    In Digital Signal Processing; Elsevier: Amsterdam, The Netherlands, 2003; pp.
    277–284. [Google Scholar] Han, J.; Kamber, M.; Pei, J. Data Preprocessing. In
    Data Mining; Elsevier: Amsterdam, The Netherlands, 2012; pp. 83–124. [Google Scholar]
    Qiu, G.; Gu, Y.; Chen, J. Selective Health Indicator for Bearings Ensemble Remaining
    Useful Life Prediction with Genetic Algorithm and Weibull Proportional Hazards
    Model. Meas. J. Int. Meas. Confed. 2020, 150, 107097. [Google Scholar] [CrossRef]
    Zhang, J.; Xu, B.; Wang, Z.; Zhang, J. An FSK-MBCNN Based Method for Compound
    Fault Diagnosis in Wind Turbine Gearboxes. Meas. J. Int. Meas. Confed. 2021, 172,
    108933. [Google Scholar] [CrossRef] Schneider, T.; Helwig, N.; Schutze, A. Automatic
    Feature Extraction and Selection for Condition Monitoring and Related Datasets.
    In Proceedings of the IEEE International Instrumentation and Measurement Technology
    Conference (I2MTC), Houston, TX, USA, 14–17 May 2018; pp. 1–6. [Google Scholar]
    [CrossRef] Fu, S.; Wu, Y.; Wang, R.; Mao, M. A Bearing Fault Diagnosis Method
    Based on Wavelet Denoising and Machine Learning. Appl. Sci. 2023, 13, 5936. [Google
    Scholar] [CrossRef] Yan, R.; Shang, Z.; Xu, H.; Wen, J.; Zhao, Z.; Chen, X.; Gao,
    R.X. Wavelet Transform for Rotary Machine Fault Diagnosis:10 Years Revisited.
    Mech. Syst. Signal Process. 2023, 200, 110545. [Google Scholar] [CrossRef] Smiti,
    A. A Critical Overview of Outlier Detection Methods. Comput. Sci. Rev. 2020, 38,
    100306. [Google Scholar] [CrossRef] Chawla, N.V.; Bowyer, K.W.; Hall, L.O.; Kegelmeyer,
    W.P. SMOTE: Synthetic Minority Over-Sampling Technique. Ecol. Appl. 2011, 30,
    e02043. [Google Scholar] [CrossRef] Yu, Y.; Si, X.; Hu, C.; Zhang, J. A Review
    of Recurrent Neural Networks: LSTM Cells and Network Architectures. Neural Comput.
    2019, 31, 1235–1270. [Google Scholar] [CrossRef] [PubMed] Tharwat, A. Classification
    Assessment Methods. Appl. Comput. Inform. 2021, 17, 168–192. [Google Scholar]
    [CrossRef] Disclaimer/Publisher’s Note: The statements, opinions and data contained
    in all publications are solely those of the individual author(s) and contributor(s)
    and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility
    for any injury to people or property resulting from any ideas, methods, instructions
    or products referred to in the content.  © 2023 by the authors. Licensee MDPI,
    Basel, Switzerland. This article is an open access article distributed under the
    terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/).
    Share and Cite MDPI and ACS Style Berghout, T.; Benbouzid, M. Diagnosis and Prognosis
    of Faults in High-Speed Aeronautical Bearings with a Collaborative Selection Incremental
    Deep Transfer Learning Approach. Appl. Sci. 2023, 13, 10916. https://doi.org/10.3390/app131910916
    AMA Style Berghout T, Benbouzid M. Diagnosis and Prognosis of Faults in High-Speed
    Aeronautical Bearings with a Collaborative Selection Incremental Deep Transfer
    Learning Approach. Applied Sciences. 2023; 13(19):10916. https://doi.org/10.3390/app131910916
    Chicago/Turabian Style Berghout, Tarek, and Mohamed Benbouzid. 2023. \"Diagnosis
    and Prognosis of Faults in High-Speed Aeronautical Bearings with a Collaborative
    Selection Incremental Deep Transfer Learning Approach\" Applied Sciences 13, no.
    19: 10916. https://doi.org/10.3390/app131910916 Note that from the first issue
    of 2016, this journal uses article numbers instead of page numbers. See further
    details here. Article Metrics Citations Crossref   4 Scopus   3 Web of Science   1
    Google Scholar   [click to view] Article Access Statistics Article access statistics
    Article Views 7. Jan 17. Jan 27. Jan 6. Feb 16. Feb 26. Feb 7. Mar 17. Mar 27.
    Mar 0 250 500 750 1000 1250 For more information on the journal statistics, click
    here. Multiple requests from the same IP address are counted as one view.   Appl.
    Sci., EISSN 2076-3417, Published by MDPI RSS Content Alert Further Information
    Article Processing Charges Pay an Invoice Open Access Policy Contact MDPI Jobs
    at MDPI Guidelines For Authors For Reviewers For Editors For Librarians For Publishers
    For Societies For Conference Organizers MDPI Initiatives Sciforum MDPI Books Preprints.org
    Scilit SciProfiles Encyclopedia JAMS Proceedings Series Follow MDPI LinkedIn Facebook
    Twitter Subscribe to receive issue release notifications and newsletters from
    MDPI journals Select options Subscribe © 1996-2024 MDPI (Basel, Switzerland) unless
    otherwise stated Disclaimer Terms and Conditions Privacy Policy"'
  inline_citation: '>'
  journal: Applied Sciences (Switzerland)
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Diagnosis and Prognosis of Faults in High-Speed Aeronautical Bearings with
    a Collaborative Selection Incremental Deep Transfer Learning Approach
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Taşcı B.
  - Omar A.
  - Ayvaz S.
  citation_count: '1'
  description: Traditional maintenance approaches often result in either premature
    replacement of machine parts or downtime in production lines due to malfunctions.
    Consequently, these lead to significant amount waste in material, time and, ultimately,
    money. In this study, a machine learning-based predictive maintenance approach
    is proposed to predict the Remaining Useful Life of production lines in manufacturing.
    Using data collected from integrated IoT sensors in a real-world factory, we attempted
    to address the problem of predicting potential equipment failures on assembly-lines
    before they occur through machine learning models in real-time. To evaluate the
    effectiveness of the approach, we developed several predictive models using ML
    algorithms, including Random Forests (RF), XGBoost (XGB), Multilayer Perceptron
    (MLP) and Support Vector Regression (SVR) and compared the results for all possible
    variations. Furthermore, the impact of noise filtering, smoothing and clustering
    techniques on the performance of ML models were investigated. Among all the methods
    evaluated, RF, an ensemble bagging method, showed the best performance, followed
    by XGB and implemented in production systems. The implemented prediction model
    achieved successful results and was able to prevent about 42 percent of actual
    production line failures.
  doi: 10.1016/j.cie.2023.109566
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords 1. Introduction 2. Literature review 3. Methods
    & analysis 4. Results 5. Discussion 6. Conclusion Funding Ethical statement Informed
    consent CRediT authorship contribution statement Declaration of competing interest
    Data availability References Show full outline Cited by (1) Figures (15) Show
    9 more figures Tables (13) Table 1 Table 2 Table 3 Table 4 Table 5 Table 6 Show
    all tables Computers & Industrial Engineering Volume 184, October 2023, 109566
    Remaining useful lifetime prediction for predictive maintenance in manufacturing
    Author links open overlay panel Bernar Taşcı a, Ammar Omar b, Serkan Ayvaz c d
    Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.cie.2023.109566
    Get rights and content Under a Creative Commons license open access Highlights
    • The study proposes a machine learning-based predictive maintenance approach
    in manufacturing. • ML Models are developed using real-world big data from IoT
    sensors on assembly lines. • Hybrid solutions were applied by combining filtering,
    clustering and forecasting methods. • The system predicts the Remaining Useful
    Life before production lines stops in real-time. • Comparative evaluations demonstrated
    the system is effective in identifying production stops. Abstract Traditional
    maintenance approaches often result in either premature replacement of machine
    parts or downtime in production lines due to malfunctions. Consequently, these
    lead to significant amount waste in material, time and, ultimately, money. In
    this study, a machine learning-based predictive maintenance approach is proposed
    to predict the Remaining Useful Life of production lines in manufacturing. Using
    data collected from integrated IoT sensors in a real-world factory, we attempted
    to address the problem of predicting potential equipment failures on assembly-lines
    before they occur through machine learning models in real-time. To evaluate the
    effectiveness of the approach, we developed several predictive models using ML
    algorithms, including Random Forests (RF), XGBoost (XGB), Multilayer Perceptron
    (MLP) and Support Vector Regression (SVR) and compared the results for all possible
    variations. Furthermore, the impact of noise filtering, smoothing and clustering
    techniques on the performance of ML models were investigated. Among all the methods
    evaluated, RF, an ensemble bagging method, showed the best performance, followed
    by XGB and implemented in production systems. The implemented prediction model
    achieved successful results and was able to prevent about 42 percent of actual
    production line failures. Previous article in issue Next article in issue Keywords
    Predictive maintenanceMachine learningRemaining useful lifetimeManufacturing 1.
    Introduction While Industry 4.0, a new era in industrial production, is rapidly
    transforming the mechanisms by which companies produce products, artificial intelligence-driven
    manufacturing is expanding its place in our daily lives day by day (Lee, Davari,
    Singh, & Pandhare, 2018). The rapid increase in population created the need for
    complex production lines to meet demand. With the technological and industrial
    developments in manufacturing, more intelligent and complex machines have taken
    their place in production lines, creating smarter ecosystems. However, the maintenance
    of such complex systems has become vital for reliability and sustainability. Recent
    innovations in technology have begun to change the traditional behavior of human–machine
    interaction. Advances in artificial intelligence (AI) and big data along with
    ever-increasing processing power of computers have made this interaction bidirectional.
    This change has found its place not only in daily life, but also in industry and
    production environments in terms of automation. In order to stay competitive,
    companies began to depend more and more on automation to increase productivity
    (Wright & Schultz, 2018). Thanks to the advances in device-to-device communication
    technologies, the concept of the Internet of Things (IoT) has emerged, which facilitates
    interconnectivity and enables active monitoring of systems in production lines.
    The constant communication of such devices creates what is called big data, which
    must be dealt with systematically in industrial facilities. Big data provides
    the capability for self-calibration and system performance improvements, enabling
    system coordination and feedback across devices (Wang, Wan, Zhang, Li, & Zhang,
    2016). While conventional maintenance approaches continued until recent years,
    the integration of AI and Industrial Internet of Things (IIoT) into the manufacturing
    formed a new phase where Predictive Maintenance (PdM) become the main objective.
    With the implementation of PdM, planned maintenance approaches led the way to
    efficient use of machinery up to their useful life. This has diminished the effects
    of unintentional and unnecessary stops for maintenance purposes, creating a cost-saving,
    high-efficiency, fully optimized manufacturing perspective. Correctly predicted
    alerts can help prevent unnecessary waste from downtime until the time of a restart,
    as production lines cannot produce usable goods until they are fully functional
    again. The aim of this study was to develop a predictive maintenance system to
    detect future failures and send alerts before they occur, using machine learning
    algorithms based on data collected through IoT sensor readings in a real-world
    manufacturing facility. In order to create such a system, different data-driven
    approaches and machine learning algorithms were applied on a real-world dataset
    in a comparative manner. The main contributions of this paper can be listed as
    follows: • The study proposes a hybrid machine learning-based predictive maintenance
    approach for manufacturing that combines filtering, feature engineering using
    Autoencoders, clustering, and prediction. • Machine learning models are developed
    using real-world high-dimensional data from IoT sensors on consumer goods production
    assembly lines. • The proposed system provides a validated, end-to-end solution
    for predicting the remaining useful lifetime before production lines stop, based
    on extensive evaluations. The rest of the paper is organized as follows: In Section
    2, the related work is reviewed. Section 3 introduces the dataset used for the
    study, describes the data preprocessing steps and explains the proposed predictive
    maintenance system and the algorithms in detail. In the subsequent section, the
    results of the evaluations assessing the effectiveness of the proposed methods
    are presented. Section 5 discusses the findings of this study. Finally, the conclusion
    and the plans for future work are given in Section 6. 2. Literature review Predictive
    Maintenance (PdM) is an important issue in industry and manufacturing due to the
    costs associated with unplanned, failure-induced downtime in plants or operating
    machines. Various studies have investigated the predictive maintenance problem
    from different perspectives. Some studies offered statistical approaches (Francis
    and Mohan, 2019, Rivera-Gómez et al., 2021, Shimada and Sakajo, 2016), while others
    proposed data-driven solutions for predictive maintenance (Ayvaz and Alpay, 2021,
    Cakir et al., 2021, Del Buono et al., 2022, Nasir and Sassani, 2021, Soltanali
    et al., 2021). 2.1. Statistical approaches to predictive maintenance From a statistical
    perspective, Shimada & Sakajo proposed a method based on probability distributions
    for maintenance scheduling in their study (Shimada & Sakajo, 2016). The focus
    of their approach was mainly on the timing of maintenance after the warning given
    by the model. This was developed using a characteristic index obtained by the
    cumulative failure probability distribution. An approach that analyzes the alert
    state to failure can improve the performance of model predictions by estimating
    the time required for maintenance after the model alert occurs and reducing the
    burden on maintenance workers. Their method was able to reduce the failure rate
    by 12 percent. In another study, Ho et al. utilized Autoregressive Integrated
    Moving Average (ARIMA) and Recurrent Neural Network (RNN) models to predict failures
    (Ho, Xie, & Goh, 2002). A combination of historical values and errors was used
    in ARIMA to model a non-seasonal time series. Their findings showed that both
    methods perform better at short-term dependencies. However, a comparison demonstrated
    that feedforward neural networks performed poorly compared to ARIMA and RNN. Similarly,
    Kanawaday and Sane investigated the ARIMA forecasting to predict failures and
    quality defects in real-world data collected from Slitting Machines (Kanawaday
    & Sane, 2017). They proposed a two-stage approach: the first stage begins with
    data analysis, clustering and supervised learning methods to obtain information,
    and it is followed by the implementation of the predictive model using ARIMA.
    Their proposed system architecture consisted of two stack systems, one with ARIMA
    to predict parameter values for upcoming cycles, and the other with supervised
    models that predicted whether the cycle was abnormal or not. Deep Neural Network
    (DNN) model used in the study outperformed the other models. Francis & Mohan explored
    the use of ARIMA for trend analysis and forecasting process (Francis & Mohan,
    2019). Their proposed method used ARIMA for trend analysis on time series data.
    The predicted values were then passed through Principal Component Analysis (PCA)
    for feature reduction by removing highly correlated variables. Finally, the Support
    Vector Regression (SVR) algorithm was used for the maintenance forecasting approach.
    While the performance of statistical approaches has been extensively studied in
    the literature, it is widely known that Long Short-Term Memory (LSTM) tends to
    outperform ARIMA when it comes to long-term dependencies. It has also been observed
    that LSTM and Gated Recurrent Unit (GRU) perform significantly better than ARIMA
    while producing similar predictions (Karpathy, Johnson, & Fei-Fei, 2015). 2.2.
    Data-driven artificial intelligence applications In recent years, there have been
    numerous studies applying data-driven Artificial Intelligence models in the field
    of predictive maintenance and failure prediction from various perspectives (Del
    Buono et al., 2022, Nasir and Sassani, 2021, Soltanali et al., 2021). Some studies
    focused on failure prediction in the context of data classification (Coelho et
    al., 2022, Lee et al., 2019), while others used machine learning methods as a
    regression task to estimate the time remaining until an error occurs (Chen et
    al., 2022, Jiang et al., 2022, Lee et al., 2022, Pacheco et al., 2022). In the
    study by Zhang et al. NASA’s C-MAAPSS engine dataset was used to predict system
    performance degradation (Zhang, Wang, Yan, & Gao, 2018b). Using data from sensors
    commonly found in aircraft engines, the authors revealed the temporal dependence
    of sensor data in predicting engine degradation. Due to the nature of time series
    data, it is preferable to use deep learning-based models that are successful in
    capturing data dependency. The main focus of the study was the use of LSTM-based
    models for prediction as LSTM is capable of capturing long-term dependencies.
    They evaluated the proposed model and compared its performance with various ML
    algorithms, including SVR, Multilayer Perceptron (MLP), Relevance Vector Regression
    (RVR) and Deep Convolutional Neural Networks (DCNN) using 200 synthetically generated
    curves. They showed that the LSTM model performed significantly better than the
    others, and the model prediction performance increased, respectively, if the prediction
    curve decreased (Zhang, Wang, Yan, & Gao, 2018a). The authors compared various
    machine learning methods, as in the proposed framework. Unlike our study, they
    evaluated their approach using only simulation-based synthetic data, not real-world
    data. Similarly, W.J. Lee et al. investigated the predictive maintenance algorithms
    in two different datasets, the cutting tool and spindle motor wear datasets. The
    milling cutter wear estimation is essential for cutting performance where an estimation
    of Remaining Useful Life (RUL) is required to avoid wasted material as well as
    faulty manufacturing. Since the spindle motor is a rotating element similar to
    a milling cutter, it is a vital component of production quality. The datasets
    in the study were collected until a system failure occurred. The authors applied
    two different classification algorithms, SVM and Convolutional Neural Network
    (CNN), to evaluate wear prediction performance. Using a confusion matrix, the
    predictions were classified into three groups: normal, warning, and failure. They
    reported that frequency domain results using CNN yielded highly accurate prediction
    results (Lee et al., 2019). While this study employed an approach to predict the
    remaining useful life using machine learning methods as in the case of our current
    study, however, the authors simulated only two ML algorithms for predictive maintenance
    modeling on two experimental datasets. In another study, Traini et al. proposed
    an approach for milling cutter maintenance. They provided a framework that combines
    both regression and classification algorithms in analog sensor readings to improve
    the human–machine interaction from a PdM perspective. The regression algorithms
    they used in this study were Linear Regression (LR), Decision Forest Regression
    (DF), Bayesian Linear Regression (BLR), Boosted Decision Tree Regression (BDT),
    and Neural Network Regression (NN). Classification algorithms used included Logistic
    Regression (LogR), DF, Decision Jungle (DJ), BDT, Neural Network (NN). The estimation
    of flank wear (VB) and RUL values was evaluated using regression algorithms, while
    the classification algorithms were applied to predict the type of samples as Safe
    and Worn. They found that the best results for regression were obtained in the
    NN regression models with the highest value, and the best results for classification
    were obtained using Two-Class BDT in terms of accuracy metric (Traini, Bruno,
    D’Antonio, & Lombardi, 2019). Although they have applied a similar approach in
    another domain to predict the remaining useful life of milling machines for predictive
    maintenance, their work has focused on a single historical dataset rather than
    a real-time implementation as in our framework. Rivera et al. presented an approach
    for predictive maintenance of a hydraulic pump component in an injection molding
    machine. This study focused on the same data with a top-down approach, in which
    expert knowledge was omitted from the preparation process unlike their previous
    work (Rivera, Scholz, Fritscher, Krauss, & Schilling, 2018). Differently, their
    current estimation approach relies on anomaly detection based on a statistical
    method, kernel density estimation. Without depending on the knowledge of underlying
    machine physics, they fed the entire raw data into a local-outlier-factor (LOF)
    algorithm to detect unusual loops, after applying PCA. The detection of hidden
    patterns among the variables can be considered as one of the advantages of this
    approach. Ultimately, the authors noted the importance of expert knowledge, as
    reducing unnecessary data could improve performance by reducing computational
    efforts (Rivera et al., 2018). We also acknowledged the benefit of leveraging
    expert knowledge, particularly in the feature engineering and data interpretation
    phases, as predictive maintenance is a domain dependent subject. From a similar
    perspective, Li et al. offered a data mining-based fault diagnosis framework consisting
    of five modules. They studied failure prediction and maintenance strategy optimization
    using online machine condition monitoring data at a remote customer site. Their
    study focused particularly on the prognosis of a backlash error. They have implemented
    error correction and maintenance application for practical use. As part of the
    data mining module, they developed an Artificial Neural Network (ANN) model to
    predict future errors based on data from the past three weeks. Although the proposed
    ANN model has capabilities such as fault tolerance, adaptability and generalization,
    the model is still data dependent and vulnerable to the influence of various factors.
    Similar to Rivera et al. (2018), they also stated the importance of expert knowledge
    for the development of an accuracy model (Li, Wang, & Wang, 2017). The predictive
    maintenance problem has also attracted a significant number of research studies
    involving deep learning solutions (Canziani et al., 2017, Chen et al., 2020, Gensler
    et al., 2016, Mohammadi et al., 2018, Xie et al., 2021). In Xie et al. (2021),
    Xie et al. emphasized the importance of deep learning in IoT and Smart City applications
    containing time series data. In particular, the predictive performance of LSTM
    networks was stated in time series data due to LSTM’s ability to preserve long-term
    dependencies. They developed an LSTM model combined with Gaussian Naive Bayes
    to detect anomalies for their use case. Later, they evaluated the performance
    of the proposed combined model in comparison to an LSTM model and an MLP model
    by using three different real-world datasets. From a different perspective, Chen
    et al. proposed a new approach called Cox proportional hazards deep learning (CoxPHDL)
    to address data resilience and data censorship that are commonly cited in the
    analysis of operational maintenance data (Chen et al., 2020). Their main idea
    was to offer an integrated solution by leveraging deep learning and reliability
    analysis. In the first phase, an autoencoder was adopted to transform the nominal
    data into a robust representation. Secondly, a Cox proportional hazards model
    (Cox PHM) was utilized to estimate the Time Between Failure of censored data.
    Lastly, a long short-term memory (LSTM) network model was developed to predict
    the Time-to-Failure based on preprocessed maintenance data. They found that LSTM
    provided the best results on a real-world dataset compared to the RNN, ANN, DCNN,
    and SVM models. From a predictive maintenance point of view, Canziani et al. examined
    the performance requirements in a real-world deep neural network application.
    Their findings showed a detailed comparison of the performance requirements of
    a deep learning application while preserving efficiency. They noticed the relationship
    between accuracy and computational cost, and a small amount of increase in accuracy
    resulted in a gradual increase in computation time (Canziani et al., 2017). These
    findings are in line with the approach in our study, which takes into account
    computational power requirements and processing times for model selection. Data-driven
    machine learning algorithms are evaluated in this study because of their applicability
    in real-time prediction applications. Predictive maintenance systems face different
    challenges depending on the field of application. Gupta et al. explored the feasibility
    of applying a machine learning based predictive maintenance system to baggage
    handling conveyors at airports (Gupta, Mitra, Koenig, Kumar, & Tiwari, 2023).
    The authors drew attention to the problem of random noise captured by IoT sensors
    due to the movement of luggage on the interconnected components of the conveyors
    that they encountered. In our study, we also observed the problem of random noise
    generated by high-frequency IoT sensors in our use case production environment
    (Ayvaz & Alpay, 2021). Additionally, we had to take into account the latency and
    scalability of the approach due to the issues of high dimensionality and complexity
    of the manufacturing assembly lines. Recently, Ayvaz and Alpay have proposed a
    data-driven predictive maintenance framework for assembly lines producing customer
    hygiene products in their most recent work. The framework uses a set of machine
    learning models to detect signals in data generated from IoT sensors in real-time
    before potential failures occur. They focused on the scalability of the proposed
    architecture, pointing to the performance of the implemented algorithms. It is
    noteworthy that the ensemble learning algorithms used, Random Forest (RF) and
    XGBoost (XGB), achieved the highest scores of 0.982 and 0.979, respectively. Besides,
    they also pointed out another additional contribution of the implementation of
    the framework to the advancement of the facility’s digital transformation (Ayvaz
    & Alpay, 2021). In this article, we aimed to present a brief review of related
    studies with an emphasis on IoT-based predictive maintenance using machine learning.
    For a more comprehensive review of relevant predictive maintenance studies, we
    refer interested readers to the following literature review papers (Carvalho et
    al., 2019, Rieger et al., 2019, Zonta et al., 2020). Rieger et al. provided a
    review of real-time IoT-based data processing using deep learning algorithms for
    predictive maintenance (Rieger et al., 2019). In another study, Zonta et al. offered
    a comprehensive survey of Industry 4.0 based predictive maintenance approaches
    to categorize the applications, standards, and methods (Zonta et al., 2020). 3.
    Methods & analysis An overview of the process flow of the proposed approach is
    presented in Fig. 1. In the proposed approach, instant data from Internet of Things
    (IoT) sensors embedded on production lines in the factory are transmitted to a
    database for storage. Simultaneously, the recorded data are sent to the pre-trained
    machine learning model deployed on the live system for real-time predictions.
    Based on data from sensors, the ML model in the system automatically detects signals
    for potential stops and guides operational preventive actions for upcoming stop.
    Download : Download high-res image (431KB) Download : Download full-size image
    Fig. 1. Process flow of the proposed system. 3.1. Data collection and preprocessing
    The data used in this study were collected from a real-world assembly line that
    manufactures consumer hygiene products. Each production line is integrated with
    various IoT sensors that measure and collect various sensor readings. These sensors
    measure the instantaneous change of relevant values in the production environment
    such as weight, speed, temperature, electric current, vacuum and air pressure
    over time. Each sensor collects data in periods of 3 to 6 s. In this study, two
    complementary datasets, sensor data and unplanned stop data, were used. The sensor
    dataset was collected and stored in a database for one year. This dataset consisted
    of 101 features and 8,668,431 instances. Of these features, 50 were sensor readings
    and 50 timestamps were related to each sensor type in this dataset. The dataset
    also contained an output feature named status, which represented the state of
    the line. A value of zero means the production line is running and any non-zero
    value indicates the line is not working properly. This variable was used as a
    control mechanism in the analysis. Real-time sensor data from production lines
    do not have RUL values until the next unplanned downtime. Because a production
    error occurs unexpectedly and data can only be collected retrospectively, after
    the error has occurred. Consequently, this prediction problem cannot be addressed
    with a real-time time series approach, as RUL values are not available at the
    time of sensor readings. The second dataset used in this study was the stops dataset,
    which consisted of 34 columns and 6787 rows. This dataset was generated from the
    production lines, where any instances of production stops were noted over the
    course of a year with various features including the cause of stop, time, duration,
    team, line, status (if planned or not), and comments. The dataset had 27 unique
    failure types that caused a production stop. 228 of these were related to a single
    type of failure, which was the most common to avoid on the production line. Due
    to the nature of the problem in question, this makes the prediction task very
    challenging, as having 228 stops per year is a small number for model training.
    3.1.1. Data cleaning and normalization Due to the nature of IoT sensor data, the
    value ranges of features in the dataset vary widely. Therefore, it requires data
    normalization before modeling. Min–max normalization was applied to the sensor
    values by using the scikit-learn library. On the other hand, most of the features
    were completely populated in the dataset. Approximately one percent of the data
    was missing only. It was not clear what the reasons for the missing data were.
    It is anticipated that the missing values may have occurred due to connectivity
    issues between IoT devices or temporary sensor measurement issues. Since a very
    small number of samples contained missing values, the instances were filled with
    median values of the corresponding feature before model fitting. The database
    containing the sensor readings provided UNIX timestamps with the stops, recording
    the time information in the local time domain (Turkey GTM+3). This issue was noticed
    in the first trials of tests, where poor results were observed and thoroughly
    investigated. Actual error times in the stop dataset and the newly created dataset
    did not match. We were able to overcome this problem by converting the local time
    of the stops to UNIX timestamps. 3.1.2. Feature engineering The prediction problem
    in this study can be treated simply as a classification task. However, it is not
    appropriate to predict the failure as a classification problem at the time of
    stop, but to detect warning signals in a continuous stream of data so that potential
    failures can be prevented before they occur. For this reason, the problem is considered
    as a regression task, which allows that necessary actions can be taken before
    malfunctions occur and unnecessary stops in the production line can be avoided.
    Therefore, the preprocessing task includes generating the necessary RUL values
    for the dataset. Given the size of the data stored, SQL was useful in handling
    data preparation tasks such as selecting and combining required features and creating
    the RUL feature. The information required for RUL feature creation is as follows:
    i. StartTime: Start time and date of stop instance. ii. Downtime: Duration of
    stop in seconds. iii. Cause: Cause of the stop. The next step in the preprocessing
    was to rank the samples to find the exact stop instance by calculating the difference
    between the Unix time of each stop and the timestamp of the sensor data. Because
    the sensors data were collected as a series of rows, the data rows had to be associated
    with the next production stop record to calculate the RUL value. The sensor readings
    were mapped to the next production stop by sorting and subtracting the time difference
    of the corresponding records as Unix timestamps. After this step, each instance
    of stop was marked. The records that fall between start time and end time of stops
    were marked as error and thus have no RUL value. The remaining records in the
    sensor data were updated with the calculated RUL value. To reduce the number of
    features in our dataset, the use of Principal Component Analysis was explored
    in feature engineering. Additionally, the effect of PCA on the prediction performance
    was compared against the features selected using expert knowledge. The model results
    were comparable in terms of prediction performance when using PCA. However, the
    PCA had a negative impact on interpretability of the results since PCA extracts
    new features out of original ones. Therefore, we proceeded with the list of features
    compiled by the experts instead of PCA in the study for better explainability
    and insights while alerting the operators for preventive actions. With the help
    of expert knowledge, a total of 18 sensor features related to the error type were
    selected and a new dataset was created to be used in the modeling phase, as shown
    in Table 1. Table 1. Output of newly generated dataset. Sts Timestamp a1 a2 a3
    ... a16 a17 a18 RUL 0 1558138770 887.0 855.0 24210 ... 1212.0 −16.1 40.9 37331
    0 1558138776 886.0 852.0 2465.0 ... 1212.0 −16.6 41.7 37325 0 1558138779 884.0
    853.0 2406.0 ... 1212.0 −16.6 41.5 37322 0 1558138785 885.0 852.0 2462.0 ... 1212.0
    −16.3 41.2 37316 3.1.3. Alternative dataset – Stops removed Another important
    observation during the preprocessing stage was that the sensors on the production
    line were constantly populating data, whether or not production is stopped. Despite
    the data samples having a value of zero for RUL for the duration of each stop,
    the sensors on the production line continue to read data from the environment
    since the sensors remain connected. However, these measurements can be a misleading
    input for the trained model. For this reason, another dataset was created in which
    each row with a value of zero after the first stop was removed from the dataset
    before model training. 3.1.4. Dataset splitting Splitting the dataset into training
    and test sets is a vital step to avoid potential over-fitting and under-fitting
    issues prior to modeling. To obtain reliable results, 70 percent of the dataset
    was used for model training while models were tested using the test set containing
    30 percent of the original dataset. During hyperparameter tuning of the model
    training, 5-fold cross validation was applied to the dataset. A separate validation
    set was used in hyperparameter tuning to prevent potential data leakage to model
    fitting. 3.1.5. Correlation While the sensors selected for the prediction problem
    are known for their direct association with the relevant error, detailed exploratory
    correlation analysis was performed. As shown in Fig. 2, several highly correlated
    features can be observed in the correlation plot. This can be expected in our
    case because some sensors transmit information from the same production area where
    multiple sensors are placed and measure different features for detailed monitoring.
    As shown in Fig. 3, another dataset was created where highly correlated features
    were removed from the dataset for comparison purposes. This newly created dataset
    had eleven features, while the original dataset contained eighteen. Download :
    Download high-res image (370KB) Download : Download full-size image Fig. 2. Correlation
    plot of the dataset. Download : Download high-res image (304KB) Download : Download
    full-size image Fig. 3. Correlation plot after removing highly correlated features.
    3.1.6. Developing autoencoder models We examined the potential of autoencoders
    to capture the signal effect from sensor data before line stops. For this purpose,
    unsupervised autoencoder models were trained using sensor values at normal runtime
    with no errors from the production lines. Then, the autoencoder model was optimized
    using a validation dataset containing data from both normal runtime and error
    times. We integrated the reconstruction error value, which is the output of the
    obtained autoencoder model, into the prediction model as a new feature and trained
    the regression models. Consequently, we measured the effect of the autoencoder
    model on the prediction performance of the regression models. The details of the
    evaluation results are given in Section 4.2.6. After evaluating several different
    options within the hyperparameter space for the models, the following parameters
    were found optimal under the specified conditions. For the XGBoost Regressor model,
    we noticed that the hyperparemeters of maximum depth of 5, the learning rate of
    0.3 and the number of estimators of 100 were the best options. Likewise, for the
    training of the Random Forest Regressor model, various alternatives were tested
    to optimize the number of tree estimators. The model parameter with 51 tree estimators
    was found to be performing well. We evaluated different options for optimizing
    the hyperparameters of the autoencoder model. Based on our evaluations, we found
    that hyperparameters including the batch size of 256, three encoder layers with
    18, 8 and 4 shapes, a bottleneck layer with two neurons, and three decoder layers
    with shapes symmetrical to the encoder, as well as the Exponential Linear Unit
    (ELU), activation functions and adam-optimizer were optimal. We trained the models
    over 100 epochs using the mean squared error as the loss metric. 3.2. Prediction
    models The machine learning models were created using the Python programming language
    in this study. Keras and xgboost python libraries were used to develop the machine
    learning models. 3.2.1. Constituent models Support Vector Regression. As a supervised
    learning approach, Support Vector Regression (SVR) is a popular algorithm for
    nonlinear problems as in this study. It can map data with high dimensional features
    to achieve good performance. In our case, an SVR model with a Radial Basis Function
    (RBF) core was used in comparison to a linear SVR. Multilayer perceptron. MLP
    is a type of feed-forward NN that includes three layers: input layer, hidden layer
    and output layer. It is a powerful algorithm for solving nonlinear problems. MLP
    has many algorithmic hyperparameters that can significantly affect the prediction
    results. In this study, we examined various hyperparameters in model development.
    Hyperparameters of Relu activation function, adam optimizer, 50 hidden layer nodes
    and epsilon 1e−08 were found to fit well to the dataset based on hyperparameter
    tuning. More details about the hyperparameter tuning process are given in the
    subsequent sections. 3.2.2. Ensemble learning Ensemble learning algorithms consist
    of a combination of multiple weak learners. The strength of the ensemble learning
    algorithm comes from the fact that the output of multiple weak learners can create
    a well-performing predictive model, even though the performance of these individual
    algorithms may not be high. These algorithms can be of three types: Bagging, Boosting
    and Stacking. The following subsections describe the ensemble learning algorithms
    used in this study. Random forest. RF is a bagging ensemble method consisting
    of multiple decision trees that can be applied to classification or regression
    problems. The main issue with decision trees is their tendency to overfit the
    data. RF addresses this problem by creating subsets of data and training each
    with different tree nodes. Each tree in the RF makes a prediction, and the resulting
    prediction is either the majority vote or the average of all predictions generated
    by the decision trees. In this study, RF algorithm was used for training a regression
    model. The estimator parameter of 51 was found to perform well for RF model based
    on hyperparameter tuning with random search with 5-fold cross validation. eXtreme
    gradient boosting. XGB is a type of optimized Gradient Boosting algorithm. Compared
    to RF, XGB creates trees with fewer splits and so it can overcome the overfitting
    problem. Due to its precision and efficiency, it is widely used in prediction
    problems. The results of hyperparameter tuning showed that XGB performed best
    at maximum depth of 5, learning rate of 0,3 and the number of estimators was selected
    as 100. 3.2.3. Clustering analysis Due to the nature of the problem in this study,
    it is essential to estimate the RUL value until the next error rather than the
    class value if there is an error at the time of recording. However, it was important
    to examine whether the similarities between data records had a signal effect on
    the estimation of RUL. Therefore, unsupervised clustering algorithms were applied
    to the dataset as the output of the clustering can provide additional information
    for the prediction approach. Elbow method was applied to determine the number
    of clusters. This method simply generates and calculates each number of possible
    clusters (k), and for each k the Within-Cluster Sum of Square (WCSS) was calculated.
    WCSS represents the sum of the distances between the centroid and each point in
    the cluster. The resulting plot provides an elbow-like graph from which the method
    gets its name. The point where the graph begins to continue almost parallel to
    the x-axis represents favorable cluster numbers. KMeans algorithm from scikit-learn
    library was used for clustering. 4. Results 4.1. Evaluations In the study, four
    measurement techniques were applied to evaluate model performance results. The
    first metric was the coefficient of determination, also known as R-squared ( ),
    a parameter commonly used for performance evaluation in regression models. It
    represents the ratio of variance explained for a dependent variable. The Root
    Mean Squared Error (RMSE) was another metric used, which describes how far the
    predictions disperse from the actual values. In other words, it represents the
    dispersion of the prediction according to the best fit (Hyndman & Koehler, 2006).
    Another performance metric used in the evaluations was Mean Absolute Error (MAE),
    which measures the mean difference between actual and predicted values by removing
    their direction. Similarly, the Mean Absolute Percentage Error (MAPE) was used
    to express the mean absolute error as a percentage. The main advantage of this
    metric is the use of absolute error over percent deviation. Moreover, to help
    better interpret the model performance results, the inverse MAPE was calculated
    (Willmott & Matsuura, 2005). 4.1.1. Median filter The median filter is a type
    of non-linear filter known for its performance in reducing noises in the dataset.
    In this study, it was used to eliminate the effects of random spikes caused by
    noisy inputs from sensors and to smooth the prediction results. The Medfilt algorithm
    from the SciPy library was utilized to perform the median filter on the estimation
    dataset. In the evaluations, the kernel values define the size of the windows
    to calculate 10, 50 and 100 of the Kernel values used for filtering. 4.1.2. True
    Positive – False Positive approach In the evaluations, we noticed that although
    the ML models were able to accurately predict some errors, they also produced
    a large number of false positive signals. Therefore, it was important to measure
    how well the models performed in scenarios where the RUL estimates were consistent
    before a failure and the alarms allowed ample time to take preventative action.
    For the new assessment, “True Positive” (TP) and “False Positive” (FP) metrics
    had to be redefined in our case. As shown in Fig. 4, if the prediction model predicts
    the RUL value of 14400 (4 h in UNIX time), the timestamp of that instance is flagged.
    Starting from that timestamp until 4 h have passed, it is checked whether there
    was a stop within the four-hour time frame using the real data set. If so, it
    is marked as “True Positive” otherwise it is marked “False Positive”. In order
    to verify the results, actual label values (RUL values) were checked. The main
    purpose of this evaluation was to identify models that increase the True Positive
    values as well as reduce the False Positive values. For the reliability of the
    forecasts, it is essential that the production line reduces false alarms that
    cause unnecessary operations and, as a result, system stops for maintenance. During
    production, the system was set to send an alarm if it detects a RUL value of 4
    h or less. A new performance evaluation was performed that aimed to change the
    way alarms were sent and reduce FP alarms during production, taking into account
    the previous assessment results. Download : Download high-res image (239KB) Download
    : Download full-size image Fig. 4. True Positive–False Positive Approach with
    Median Filtering. 4.1.3. True Positive – False Positive approach with median filtering
    To reduce the effect of high variation of predicted RUL values, we applied a data
    smoothing technique to the prediction results. Instead of choosing the instance
    of predicted RUL value, we considered the median of the last n number of predicted
    RUL values, where n is the window size for smoothing. Our initial trials produced
    a high number of TP values compared to FP values, which was not expected considering
    the performance implications of the model. This was due to the methodology used
    to generate the RUL values in the preprocessing task, where RUL values were marked
    as zero within a downtime. In the calculation of TP values, repeating zero values
    in the RUL feature were used. The process of calculating TP-FP scores after completing
    the prediction of RUL value for each record instance is illustrated in Fig. 5
    and explained as follows: Download : Download high-res image (246KB) Download
    : Download full-size image Fig. 5. TP-FP approach with median filtering script
    diagram. i Calculate the median of “n” number of rows in the window. ii If the
    median value of the “n” number of rows is between 0 and 4 h 15 m, check if there
    is a stop in the next 4 h duration in the original dataset (starting from th row).
    • If so, mark TP and return to ii for the next “n” number of rows in prediction.
    • If not, mark FP and return to ii for the next “n” number of rows in prediction.
    iii If not, return to ii and continue to the next n number of rows. The selected
    median sizes were 50, 100, 150 and 200 rows. Each line represents about 3 s, with
    a total of 10 min of median RUL calculated at most. As the dataset contains stops
    that last a long duration, the actual RUL values are the recurring rows of zero
    values, which causes the algorithm to generate a large number of TP values. To
    resolve the recurring TP values, the timestamps of each TP value were stored as
    an array and checked for unique timestamps of the TP values. By doing this, we
    were able to obtain unique TP values. As a minor improvement in the computation
    process, we changed the behavior after TP detection, where previously the filter
    scanned the next n rows. With the modification, the process calculates the median
    of n rows immediately after the row where the TP value is determined. This last
    approach slightly reduced the TP and FP values, but increased the accuracy of
    the model performance. 4.1.4. Confusion matrix To measure the real-world preventive
    power of the models, there was a need to link specific model signals to the observed
    stops. The evaluation metrics used previously were not actionable metrics. Using
    the confusion matrix distribution, we were able to calculate the sensitivity of
    the applied model, also called Recall, to measure model performance. Our focus
    on a confusion matrix in this study pointed to TP and FP values. The TP value
    represents the situation where an actual error occurs as predicted by the model
    within the time frame of the prediction window. On the contrary, FP represents
    modeling error prediction when there was actually no error. In our case, the total
    number of stops and the number of positive values (P) were already known because
    the dataset included the stops that occurred. Using these three variables, we
    were able to calculate the Precision and Sensitivity of the prediction model.
    4.2. Test set 4.2.1. Standard dataset After the model fitting processes were completed
    and the most suitable parameters were determined for each model, the models created
    were evaluated for the test dataset. The evaluation results of the models are
    demonstrated in Table 2. As a model evaluation technique, inverse MAPE was calculated
    by subtracting the result from 100 and used to describe the model’s performance
    in terms of an error-free percentage. The best results were obtained using the
    Random Forests model, which seemed to fit the data significantly better, with
    an value close to one showing how accurate the prediction was (Table 2). This
    was followed by XGBoost, which achieved an of 0.65. Similarly, when MAPE scores
    were compared, the RF model outperformed the others with a score of 2.09 percent.
    Table 2. Performance results of standard dataset. Algorithm MAE MAPE Inv. MAPE
    RMSE RF 0.990 8855.15 2.09 97.91 45316.91 XGB 0.650 173771.26 41.04 58.96 272467.00
    SVR −0.435 407963.56 96.3 3.7 551882.41 MLP 0.450 234300.15 55.31 44.69 341651.11
    Model prediction results were plotted and observed for detailed analysis. From
    the actual and predicted plots shown in Fig. 6, we observed how well the RF model
    fit the model and plotted a prediction line similar to the actual RUL values.
    These prediction plots also showed potential in prediction, although XGB and MLP
    scored relatively lower. The worst performance was obtained with the SVR model
    and was not used in further tests. Table 3. Performance results of stops-removed
    dataset. Algorithm MAE MAPE Inverse MAPE RMSE RF 0.994 4895.14 1.12 98.88 37567.86
    XGB 0.744 167505.2 38.49 61.51 253658.63 MLP 0.695 192165.52 44.15 55.85 276604.36
    Download : Download high-res image (828KB) Download : Download full-size image
    Fig. 6. Predicted vs. actual plot of RUL for standard dataset. 4.2.2. Stops-removed
    dataset When examining the poor performance of MLP and SVR compared to RF and
    XGB, it was clear that RUL values of zero for downtime were misleading some models.
    The Stops-Removed dataset was used to generate and predict model results for comparison
    purposes. Because this dataset contained only stop occurrence instances rather
    than the entire downtime, filtered information can improve the performance of
    the prediction model. This problem was addressed after reviewing the sensor readings
    during stops. It was observed that some sensor readings did not change during
    the stops, while others changed during the observations. This issue can cause
    a promising prediction model to fail to fit. The results of the stops-removed
    dataset are shown in the Table 3, where improvements were observed in all models
    supporting the approach for the filtered dataset. The evaluation results of the
    filtered datasets, including Stops-removed, Correlations-removed, and Stops-removed
    and cluster applied, are demonstrated in Fig. 7, Fig. 8, Fig. 10, respectively.
    Download : Download high-res image (574KB) Download : Download full-size image
    Fig. 7. Predicted vs. actual plot of RUL for stops-removed dataset. 4.2.3. Correlations
    removed dataset The third approach for the test set continued with the use of
    the correlations removed dataset in which the high correlated features were removed.
    The test results for the dataset are demonstrated in Table 4. Compared to previous
    models, a slight decrease in prediction performance was observed. Similar to our
    first two trials, the RF model fitted the test set well. XGB, on the other hand,
    scored its the lowest performance in the evaluations when using the correlations
    removed dataset. Table 4. Performance results of correlations removed dataset.
    Algorithm MAE MAPE Inverse MAPE RMSE RF 0.99 9093.31 2.15 97.85 46234.43 XGB 0.626
    181337.89 42.81 57.19 281839.40 MLP 0.467 235424.8 55.57 44.43 336252.33 Download
    : Download high-res image (623KB) Download : Download full-size image Fig. 8.
    Predicted vs. actual plot of RUL for correlations removed dataset. 4.2.4. Stops-removed
    and clustering applied dataset Our next approach was to measure the impact of
    clustering on model performance. The purpose of this approach was to add external
    information to the dataset using internal dynamics. We aimed to observe the cluster
    distributions and add the cluster label as a new feature to the dataset. Clustering
    methods are often used in the literature as classification approach to maintenance.
    Since our problem was based on regression and RUL prediction in terms of time
    interval, a meaningful class distribution could lead to improvements in prediction
    performance. By calculating the WCSS score and using the elbow method, we were
    able to determine the number of optimal candidate clusters present in the dataset
    distribution. Fig. 9 shows the number of clusters explored during observations
    and their corresponding WCSS scores. When the original dataset was used for clustering,
    the resulting graph did not provide a clear cluster breakpoint. The reason behind
    the creation of the stops-removed dataset mentioned in Section 4.2.4 can help
    explain this observation. In this regard, the stops-removed dataset was used for
    clustering and there were three significant clusters as illustrated in Fig. 9.
    Download : Download high-res image (177KB) Download : Download full-size image
    Fig. 9. Elbow method plot of WCSS vs. number of clusters. The created cluster
    labels were added to the dataset as a new feature and the models were developed
    using the dataset including this extra attribute. Meanwhile, the cluster model
    was also stored and label values were added to each new row for post-testing and
    predictions were made using this new feature as shown in Table 5. The results
    regarding the clustering of the applied dataset were very promising as performance
    improvements were observed in each model. This showed that our clustering approach
    was effective. Checking the plots for predictions versus actual data, both XGB
    and MLP better fitted the actual values compared to previous approaches, keeping
    RF performance nearly the same with a slight improvement. Table 5. Performance
    results of stops-removed and clustering applied dataset. Algorithm MAE MAPE Inverse
    MAPE RMSE RF 0.994 4954.07 1.14 98.86 38118.35 XGB 0.748 165838.26 38.1 61.9 251425.99
    MLP 0.709 186614.23 42.88 57.12 270425.70 Download : Download high-res image (565KB)
    Download : Download full-size image Fig. 10. Predicted vs. actual plot of RUL
    for stops-removed and clustering applied dataset. 4.2.5. PCA applied dataset Our
    next approach was focused on dimension reduction to see if it was possible to
    obtain more meaningful results while decreasing the number of features and computational
    costs. When applying PCA, we set the proportion of variance explained to 97 percent.
    This resulted in the creation of 12 features, while our original dataset contained
    18 features by taking expert knowledge into consideration. We compared predictive
    performance models using PCA-generated features and a feature set based on expert
    knowledge. The performances of the models developed by the newly created dataset
    are shown in Table 6. It was observed that similar performance outputs were obtained
    with RF, but other models showed poor results. Considering the interpretability
    issues of PCA features, we decided to exclude PCA from real-time implementation
    and move forward with a set of expert-derived features for better explainability
    of generated alerts. Although variance for the PCA was selected 97 percent, it
    was observed that considering expert knowledge in determining dataset features
    resulted in better model fit and predictions. Although RF managed to predict salient
    results, XGB and MLP showed poor results as shown in Fig. 11. Table 6. Performance
    results of PCA applied dataset. Algorithm MAE MAPE Inverse MAPE RMSE RF 0.98 9288.11
    2.12 97.88 59635.33 XGB 0.083 199411.1 45.48 54.52 304102.19 MLP −5.07 312793.55
    71.33 28.67 427923.49 Download : Download high-res image (665KB) Download : Download
    full-size image Fig. 11. Predicted vs. actual plot of RUL for PCA applied dataset.
    4.2.6. Autoencoder applied dataset After integrating unsupervised autoencoder
    (AE) models into our proposed framework, we evaluated the effect of AE in capturing
    signals from sensor data before the line stops. We compared the prediction performance
    of regression models with integrating autoencoder models against the standard
    dataset results as baseline. The test results with the AE reconstruction loss
    added dataset are shown in Table 7. The results showed that integrating the AE
    model is effective and the hybrid approach incorporating AE models was able to
    moderately improve the prediction results for all evaluated ML models. The most
    important output of AE models can be explained by the results of reconstruction
    loss. When examined, we expected to see high peaks close to the unplanned stop
    points. Since we trained our model excluding stops with three-hour intervals,
    these stop points were causing anomalies in the model. In Fig. 12(a), it can be
    noticed that a high peak is generated in terms of reconstruction loss, indicating
    an upcoming stop. It was also observed that when two stops occur in a short time
    interval in the dataset, the first stop adds a random noise and distortion to
    the upcoming stop as demonstrated in Fig. 12(b). Table 7. Performance results
    of autoencoder applied dataset. Algorithm MAE MAPE Inverse MAPE RMSE RF 0.99 8896.01
    2.1 97.9 37557.42 XGB 0.36 171668.92 40.52 59.48 45055.75 MLP −0.211 231827.09
    54.72 45.28 339401.20 Similar to the standard dataset results, the RF model prediction
    performance was the most promising among other models as presented in Fig. 13.
    Download : Download high-res image (280KB) Download : Download full-size image
    Fig. 12. Two sample plots for Reconstruction loss before unplanned stops. Download
    : Download high-res image (631KB) Download : Download full-size image Fig. 13.
    Predicted vs. actual plot of RUL for autoencoder applied dataset. 4.3. New validation
    set After completing the evaluations on the existing dataset, we were able to
    obtain a new dataset from the following month and used it to validate the results
    of the aforementioned models. The new dataset was preprocessed in the same way
    as previously described. The results were unexpected for the standard dataset.
    The model performance results indicated how poorly each model performed in the
    prediction as demonstrated in Table 8. These results required detailed monitoring
    of the predictions to find a meaningful explanation. After observing the graphs,
    we were able to see how the model managed to fit the actual values in some intervals.
    While RF clearly achieved the best fit among the other models, the trend in the
    prediction was somewhat representative of the actual values in the other models
    shown in Fig. 14. Table 8. Performance results of newly generated validation set.
    Algorithm MAE MAPE Inverse MAPE RMSE RF −2.15 210479.27 121.56 −21.56 286963.58
    XGB −0.295 140958.46 81.41 18.59 183876.99 MLP −222.02 2079551.73 1200.98 −1100.98
    2413377.23 Similar results were obtained when other models were checked for the
    remaining three dataset approaches. Consequently, those results were omitted from
    this study as no additional information was obtained. Download : Download high-res
    image (455KB) Download : Download full-size image Fig. 14. Predicted vs. actual
    plot of RUL for new validation set. 4.4. New evaluation approach Due to the unsatisfactory
    performance results in the new validation test set, our focus shifted to the evaluation
    of model performances. 4.4.1. Median filter After completing the model performance
    evaluations using the training and test sets and deploying the models, the newly
    created validation set was used for real-time prediction. Using the preferred
    prediction model with the newly created 1-month dataset, we were able to see the
    model prediction performance results shown in Fig. 14. The variance of the prediction
    compared to the actual RUL values resulted in poor prediction results. Since the
    predicted RUL values decreased linearly and the prediction results were not distributed
    as expected, new methods were applied. Random spikes in prediction caused the
    model to perform poorly. Our first approach to tackling this problem was to use
    median filtering. The median filtering was applied to the results after the predictions
    to smooth out the predicted RUL values as well as the overall distribution. However,
    since the predictions were already unevenly distributed, it was not sufficient
    to simply use a median filter for improving model performance in cases where random
    spikes were still present as shown in Fig. 15. Different parameters were explored
    for the median filter. These parameters represent the number of rows used to calculate
    the median and applied to the prediction results. Increasing the median range
    resulted in a smoother treatment on the RUL values, but had a high impact on the
    data as it changed the results more drastically than anticipated. Lower values
    of median parameters performed poorly. Using the results obtained from the median
    filtered RUL values, no significant change was observed in the performance of
    the model. Our next approach in this issue was to focus on computing True-Positive
    and False-Positive values. Download : Download high-res image (266KB) Download
    : Download full-size image Fig. 15. Median filter applied prediction results for
    RF model. 4.4.2. True Positive – False Positive approach The fact that the median
    filter alone did not address the high variance in prediction results using the
    new validation set shifted our attention to defining global True and False variables.
    This task was a method of filtering out false alarms while providing appropriate
    RUL predictions as signals for the assembly line. Another output of this task
    was to generate an evaluation metric for model performance and calculate sensitivity
    using the confusion matrix technique. The results for the base model are given
    in Table 9. As it can be seen from the results of the TP-FP task, the method had
    to be rearranged because meaningful outputs could not be obtained. The high figures
    in TP and FP values were inconsistent. When the algorithm was checked, the flaws
    in the approach were fixed. Table 9. Validation set TP-FP results. Model TP FP
    RF 234 667 XGB 33 3834 MLP 5 557 4.4.3. True Positive – False Positive approach
    with median filtering As noted in the methodology, this approach was a new observational
    approach in our study, where our concern was the overall accuracy of the model
    for RUL prediction rather than the correct prediction of each sample. This new
    approach also brings implementation details into focus. Since the dataset used
    in this study was from real-world production lines, the approach had to be implemented
    and useful in real-time as well. The evaluation results reported in Tables 10,
    11, 12, and 13 were obtained using RF models only. The MLP and XGB models failed
    to achieve as promising results as the RF models. This was not surprising given
    the previously observed estimates for the new validation set. Four different modeling
    approaches were used for this new methodology to observe model performance results.
    Each model was presented in its respective table (Tables 10, 11, 12, and 13).
    The tables show four different window sizes of the median values used to calculate
    TP-FP values. Each model was tested for four different RUL values as a time interval.
    These values represent the actual behavior of the model running on the production
    line. The minimum time interval selected for model alarm was 1 h, and the maximum
    was 3 h. Unique values represent the amount of unique stops detected from the
    original dataset. The dataset tested above contains 29 unplanned stops. Table
    10. Main dataset RF model prediction results on validation set. RUL alarm Median
    size TP FP Unique TP Unique FP Prec. Sens. 3600 s (1 h) 50 73 1 11 1 0,917 0,379
    100 36 1 10 1 0,909 0,345 150 20 1 7 1 0,875 0,241 200 19 0 8 0 1,000 0,276 5400
    s (1,5 s) 50 113 3 12 3 0,800 0,414 100 58 2 10 2 0,833 0,345 150 34 2 7 2 0,778
    0,241 200 28 1 8 1 0,889 0,276 7200 s (2 h) 50 155 5 13 5 0,722 0,448 100 79 2
    10 2 0,833 0,345 150 49 3 7 3 0,700 0,241 200 39 1 8 1 0,889 0,276 10800 s (3
    h) 50 222 5 14 5 0,737 0,483 100 113 3 11 3 0,786 0,379 150 71 2 7 2 0,778 0,241
    200 57 1 9 1 0,900 0,310 Table 11. Stops removed dataset RF model prediction results
    on validation set. RUL alarm Median size TP FP Unique TP Unique FP Prec. Sens.
    3600 s (1 h) 50 47 1 12 1 0,923 0,414 100 21 1 8 1 0,889 0,276 150 13 0 6 0 1,000
    0,207 200 11 5 0 1,000 0,172 5400 s (1,5 s) 50 84 1 12 1 0,923 0,414 100 40 1
    8 1 0,889 0,276 150 25 0 7 0 1,000 0,241 200 18 0 6 0 1,000 0,207 7200 s (2 h)
    50 123 2 12 2 0,857 0,414 100 58 1 8 1 0,889 0,276 150 39 0 8 0 1,000 0,276 200
    28 0 7 0 1,000 0,241 10800 s (3 h) 50 182 4 13 4 0,765 0,448 100 89 1 9 1 0,900
    0,310 150 58 1 8 1 0,889 0,276 200 43 0 7 0 1,000 0,241 Table 12. Correlations
    removed dataset RF model prediction results on validation set. RUL alarm Median
    size TP FP Unique TP Unique FP Prec. Sens. 3600 s (1 h) 50 75 2 13 2 0,867 0,448
    100 36 1 9 1 0,900 0,310 150 22 2 8 2 0,800 0,276 200 19 1 8 1 0,889 0,276 5400
    s (1,5 s) 50 116 2 13 2 0,867 0,448 100 57 1 9 1 0,900 0,310 150 36 2 8 2 0,800
    0,276 200 27 1 8 1 0,889 0,276 7200 s (2 h) 50 154 4 13 4 0,765 0,448 100 75 1
    9 1 0,900 0,310 150 50 3 8 3 0,727 0,276 200 37 1 8 1 0,889 0,276 10800 s (3 h)
    50 224 10 14 10 0,583 0,483 100 111 5 11 5 0,688 0,379 150 72 4 8 4 0,667 0,276
    200 54 3 8 3 0,727 0,276 Table 13. Cluster added dataset RF model prediction results
    on validation set. RUL alarm Median size TP FP Unique TP Unique FP Prec. Sens.
    3600 s (1 h) 50 24 19 3 19 0,136 0,103 100 11 9 2 9 0,182 0,069 150 7 7 2 7 0,222
    0,069 200 5 5 2 5 0,286 0,069 5400 s (1,5 s) 50 39 40 3 39 0,071 0,103 100 19
    20 3 20 0,130 0,103 150 13 13 3 13 0,188 0,103 200 9 9 2 9 0,182 0,069 7200 s
    (2 h) 50 58 59 3 58 0,049 0,103 100 28 30 3 30 0,091 0,103 150 18 21 4 21 0,160
    0,138 200 14 14 3 14 0,176 0,103 10800 s (3 h) 50 92 86 3 84 0,034 0,103 100 46
    41 3 41 0,068 0,103 150 31 29 4 29 0,121 0,138 200 22 21 3 21 0,128 0,103 At first
    glance, it was observed how the stops-removed dataset, to which cluster labels
    were added, performed poorly, detecting four TP values as the best prediction
    while producing a high number of FP values. Using the confusion matrix metrics
    and calculating the Precision and Sensitivity of all results, it was observed
    that the predictions of RF model generated from the stops-removed dataset outperformed
    the other alternatives. The best results were obtained using the median size of
    50. In terms of time intervals, 1 h and 1,5 h results were similar to each other
    and produced the most accurate predictions. 5. Discussion In this study, a predictive
    maintenance approach is proposed for predicting RUL of a real-life production
    line. By using machine learning algorithms trained on real-world datasets collected
    from integrated IoT sensors, we aimed to detect possible future failures on assembly-lines,
    and an early maintenance task was scheduled for preventive maintenance. The first
    decision to be made in our study was to decide how to make the prediction approach.
    In our real-world scenario, where the model would make predictions based on a
    data instance, it would not be appropriate to choose a classification approach
    as it does not allow sufficient time to take preventive action before the error
    occurs. To obtain a suitable preventive model, we focused on the regression task
    and estimated RUL in the time domain. As a result of our discussions with the
    experts on the production line, it was decided that it is important to know an
    error up to 4 h before it occurs. Therefore, for the “True Positive” (TP) metric,
    we considered the 4 h threshold for prediction accuracy. While a large body of
    the literature reviewed has focused on time series data analysis in this area,
    this was not a viable approach in our case. Because it is not possible for the
    model to verify the occurrence of a failure in real-time. Four different machine
    learning algorithms including two ensemble and two constituent algorithms, namely
    RF, XGB, MLP and SVR, were selected and trained to predict possible failures.
    To assess the performance of the models, four datasets were collected for different
    evaluation cases. An additional validation dataset was created to test the model
    implemented on the real assembly line. The model prediction results showed the
    performance of the RF algorithm, which produced the highest value in all cases.
    We think that this was due to the complex nature of the model, which in our case
    created multiple decision trees resulting in better data fitting. With the introduction
    of the newly created dataset, we had the opportunity to test our models on the
    new validation set. The performance results were unexpectedly low when compared
    to the model evaluations on test sets. We further investigated the prediction
    results to understand the problem. While the problem of overfitting in models
    is often the first thing to consider for the issue, examining these results revealed
    that this was not the case. When the prediction plots were analyzed for the new
    validation set, a remarkable model fit was observed for the RF models. Generating
    linearly decreasing RUL values until the next error date, as in our RUL generation
    method, does not always reflect the real-world randomness of errors. Actual faults
    that occur on the production lines are sometimes caused by a raw material feed
    instance and have nothing to do with equipment defects. Considering the problem
    in this way, it can be said that our previously trained models learned the data
    as well as the error states. The reason for the unsuccessful results from the
    RF model can be explained by the high amount of variance in the prediction results
    observed from the plots. Given that the model fits the plot, our focus shifted
    to assessing the real-world value of the prediction results and we introduced
    the TP-FP approach, a new layer in RUL prediction. In other words, how many of
    real errors could be avoided by using alarms generated by models. This approach
    has two important aspects. First, we try to predict the RUL of the assembly line
    by providing the relevant results to take the necessary actions. It was observed
    that constituent ML algorithms were not sufficient for such real-world production
    datasets, where unpredictable effects were present in the dataset compared to
    a synthetic dataset. Second, it is not enough to simply present a prediction model
    in situations where human–machine interaction and communication is vital, which
    is one of the most important findings of this study. Our new approach can be seen
    as a framework definition where we try to minimize the effects caused by the real-world
    system and provide an information technique based on ML results. Our initial approach
    resulted in inconsistent values as many true or false alarms made no sense. The
    problem with the first approach was caused by the filtering method, where we scan
    the dataset line by line after each FP value obtained. Although this detail was
    mentioned and corrected, we had not yet achieved practical results. Based on our
    observations of the predictions, variation in the prediction distribution led
    the approach to filtering techniques, but models with filtering were simply not
    sufficient to yield promising results. Our final approach was to combine these
    two methods described above to create a final evaluation method. Unlike the previous
    TP-FP approach, we introduced median window sizes in this new method. While we
    could not obtain promising results from the median filter alone, we decided to
    use the median filter for prediction result smoothing before the TP-FP control.
    This new method showed promising results, where we were able to obtain a value
    of 0.923 for the precision of the results. A key finding of the study was that
    we realized that AI models were able to capture meaningful, actionable inferences
    in the IoT data obtained from the production lines. After implementing the model
    in the production facility, it was observed that the model was able to accurately
    predict more than 50 percent of unplanned production stops. This means that half
    of the unplanned downtimes that occur on the lines due to equipment failures were
    prevented by the system. Consequently, 50 percent savings were achieved in product
    discards, which is a significant cost. The proposed approach not only helps to
    reduce costs and increase production efficiency but also contributes to sustainability
    by reducing the hundreds of thousands of discarded products per year. Although
    the machine learning models are data dependent and cannot be directly used in
    all manufacturing conditions, we think that the proposed methodology can be generalized
    and applied to similar production environments. Considering the size of our datasets
    and the computational power required for training, complex deep learning models
    were omitted from the study due to limitations on available computational resources.
    For future work, more computationally complex deep learning models will be investigated
    to compare with the current work. 6. Conclusion With the continuous advancements
    in machine learning, more and more industry 4.0 applications are expected to emerge.
    Due to the integration of artificial intelligence into the industry, it has begun
    to change the characteristics of previously implemented human–machine interactions.
    The aim of this study was to propose a prediction model for a real-life production
    line. Four different ML algorithms, RF, XGB, MLP and SVR, were used to create
    models with different approaches to the existing data set. It is very important
    to note that the problem for the ML application begins with the data cleaning
    and preprocessing procedures. Using real-world data collected from the production
    lines, we developed four different predictive approaches and compared the results
    for all possible variations. Among all the proposed methods, RF, an ensemble bagging
    method, turned out to perform best with our dataset followed by XGB. Although
    remarkable results have been obtained from other ML algorithms, previously created
    models gave insufficient results when implementing and testing models with the
    new validation dataset. With this new approach, we tried to filter the results
    from the prediction model and eliminate the effects of high variability in the
    prediction results. This layer, added to the prediction model, yielded reasonable
    results and, based on the dataset, prevented approximately 42 percent of production
    line errors. In future work, we plan to test our proposed method on a long-term
    dataset for comparison and extend our hybrid approach with additional methods
    for RUL prediction. Funding The authors did not receive support from any organization
    for the submitted work. Ethical statement The authors consciously assure that
    this material is the authors’ own original work, which is not currently being
    considered for publication elsewhere. This article does not contain any studies
    with human participants or animals performed by any of the authors. Informed consent
    This article does not contain any studies with human participants or animals performed
    by any of the authors. The consent is not a requirement for this study. CRediT
    authorship contribution statement Bernar Taşcı: Conceptualization, Data curation,
    Methodology, Programming, Writing – original draft, Writing – review & editing.
    Ammar Omar: Conceptualization, Data curation, Methodology, Writing – review &
    editing. Serkan Ayvaz: Conceptualization, Methodology, Programming, Supervision,
    Writing – review & editing. Declaration of competing interest The authors declare
    that they have no known competing financial interests or personal relationships
    that could have appeared to influence the work reported in this paper. Data availability
    The authors do not have permission to share data. References Ayvaz and Alpay,
    2021 Ayvaz S., Alpay K. Predictive maintenance system for production lines in
    manufacturing: A machine learning approach using IoT data in real-time Expert
    Systems with Applications, 173 (2021), Article 114598 View PDFView articleView
    in ScopusGoogle Scholar Cakir et al., 2021 Cakir M., Guvenc M.A., Mistikoglu S.
    The experimental application of popular machine learning algorithms on predictive
    maintenance and the design of IIoT based condition monitoring system Computers
    & Industrial Engineering, 151 (2021), Article 106948 View PDFView articleView
    in ScopusGoogle Scholar Canziani et al., 2017 Canziani A., Paszke A., Culurciello
    E. An analysis of deep neural network models for practical applications (2017)
    arXiv:1605.07678 [cs] Google Scholar Carvalho et al., 2019 Carvalho T.P., Soares
    F.A., Vita R., Francisco R.d.P., Basto J.P., Alcalá S.G. A systematic literature
    review of machine learning methods applied to predictive maintenance Computers
    & Industrial Engineering, 137 (2019), Article 106024 View PDFView articleView
    in ScopusGoogle Scholar Chen et al., 2020 Chen C., Liu Y., Wang S., Sun X., Di
    Cairano-Gilfedder C., Titmus S., et al. Predictive maintenance using cox proportional
    hazard deep learning Advanced Engineering Informatics, 44 (2020), Article 101054
    View PDFView articleView in ScopusGoogle Scholar Chen et al., 2022 Chen C., Shi
    J., Lu N., Zhu Z.H., Jiang B. Data-driven predictive maintenance strategy considering
    the uncertainty in remaining useful life prediction Neurocomputing, 494 (2022),
    pp. 79-88 View PDFView articleView in ScopusGoogle Scholar Coelho et al., 2022
    Coelho D., Costa D., Rocha E.M., Almeida D., Santos J.P. Predictive maintenance
    on sensorized stamping presses by time series segmentation, anomaly detection,
    and classification algorithms Procedia Computer Science, 200 (2022), pp. 1184-1193
    View PDFView articleView in ScopusGoogle Scholar Del Buono et al., 2022 Del Buono
    F., Calabrese F., Baraldi A., Paganelli M., Guerra F. Novelty detection with autoencoders
    for system health monitoring in industrial environments Applied Sciences, 12 (10)
    (2022), p. 4931 CrossRefView in ScopusGoogle Scholar Francis and Mohan, 2019 Francis
    F., Mohan M. ARIMA model based real time trend analysis for predictive maintenance
    2019 3rd international conference on electronics, communication and aerospace
    technology, IEEE, Coimbatore, India (2019), pp. 735-739 CrossRefView in ScopusGoogle
    Scholar Gensler et al., 2016 Gensler A., Henze J., Sick B., Raabe N. Deep learning
    for solar power forecasting — An approach using AutoEncoder and LSTM neural networks
    2016 IEEE international conference on systems, man, and cybernetics, IEEE, Budapest,
    Hungary (2016), pp. 002858-002865 Google Scholar Gupta et al., 2023 Gupta V.,
    Mitra R., Koenig F., Kumar M., Tiwari M.K. Predictive maintenance of baggage handling
    conveyors using IoT Computers & Industrial Engineering, 177 (2023), Article 109033
    View PDFView articleView in ScopusGoogle Scholar Ho et al., 2002 Ho S., Xie M.,
    Goh T. A comparative study of neural network and Box-Jenkins ARIMA modeling in
    time series prediction Computers & Industrial Engineering, 42 (2–4) (2002), pp.
    371-375 View PDFView articleView in ScopusGoogle Scholar Hyndman and Koehler,
    2006 Hyndman R.J., Koehler A.B. Another look at measures of forecast accuracy
    International Journal of Forecasting, 22 (4) (2006), pp. 679-688 View PDFView
    articleView in ScopusGoogle Scholar Jiang et al., 2022 Jiang Y., Dai P., Fang
    P., Zhong R.Y., Zhao X., Cao X. A2-LSTM for predictive maintenance of industrial
    equipment based on machine learning Computers & Industrial Engineering, 172 (2022),
    Article 108560 View PDFView articleView in ScopusGoogle Scholar Kanawaday and
    Sane, 2017 Kanawaday A., Sane A. Machine learning for predictive maintenance of
    industrial machines using IoT sensor data 2017 8th IEEE international conference
    on software engineering and service science, IEEE, Beijing, China (2017), pp.
    87-90 CrossRefView in ScopusGoogle Scholar Karpathy et al., 2015 Karpathy A.,
    Johnson J., Fei-Fei L. Visualizing and understanding recurrent networks (2015)
    arXiv:1506.02078 [cs] Google Scholar Lee et al., 2018 Lee J., Davari H., Singh
    J., Pandhare V. Industrial artificial intelligence for industry 4.0-based manufacturing
    systems Manufacturing Letters, 18 (2018), pp. 20-23 View PDFView articleGoogle
    Scholar Lee et al., 2022 Lee G., Kim J., Lee C. State-of-health estimation of
    Li-ion batteries in the early phases of qualification tests: An interpretable
    machine learning approach Expert Systems with Applications, 197 (2022), Article
    116817 View PDFView articleView in ScopusGoogle Scholar Lee et al., 2019 Lee W.J.,
    Wu H., Yun H., Kim H., Jun M.B., Sutherland J.W. Predictive maintenance of machine
    tool systems using artificial intelligence techniques applied to machine condition
    data Procedia CIRP, 80 (2019), pp. 506-511 View PDFView articleView in ScopusGoogle
    Scholar Li et al., 2017 Li Z., Wang Y., Wang K.-S. Intelligent predictive maintenance
    for fault diagnosis and prognosis in machine centers: Industry 4.0 scenario Advances
    in Manufacturing, 5 (4) (2017), pp. 377-387 CrossRefView in ScopusGoogle Scholar
    Mohammadi et al., 2018 Mohammadi M., Al-Fuqaha A., Sorour S., Guizani M. Deep
    learning for IoT big data and streaming analytics: A survey (2018) arXiv:1712.04301
    [cs] Google Scholar Nasir and Sassani, 2021 Nasir V., Sassani F. A review on deep
    learning in machining and tool monitoring: methods, opportunities, and challenges
    International Journal of Advanced Manufacturing Technology, 115 (9) (2021), pp.
    2683-2709 CrossRefView in ScopusGoogle Scholar Pacheco et al., 2022 Pacheco A.L.,
    Flesch R.C., Flesch C.A., Iervolino L.A., Barros V.T. Tool based on artificial
    neural networks to obtain cooling capacity of hermetic compressors through tests
    performed in production lines Expert Systems with Applications, 194 (2022), Article
    116494 View PDFView articleView in ScopusGoogle Scholar Rieger et al., 2019 Rieger
    T., Regier S., Stengel I., Clarke N. Fast predictive maintenance in industrial
    Internet of Things (IIoT) with deep learning (DL): A review Internet of Things
    (2019), p. 11 CrossRefGoogle Scholar Rivera et al., 2018 Rivera D.L., Scholz M.R.,
    Fritscher M., Krauss M., Schilling K. Towards a predictive maintenance system
    of a hydraulic pump IFAC-PapersOnLine, 51 (11) (2018), pp. 447-452 View PDFView
    articleView in ScopusGoogle Scholar Rivera-Gómez et al., 2021 Rivera-Gómez H.,
    Gharbi A., Kenné J.-P., Ortiz-Zarco R., Corona-Armenta J.R. Joint production,
    inspection and maintenance control policies for deteriorating system under quality
    constraint Journal of Manufacturing Systems, 60 (2021), pp. 585-607 View PDFView
    articleView in ScopusGoogle Scholar Shimada and Sakajo, 2016 Shimada J., Sakajo
    S. A statistical approach to reduce failure facilities based on predictive maintenance
    2016 international joint conference on neural networks, IEEE, Vancouver, BC, Canada
    (2016), pp. 5156-5160 CrossRefView in ScopusGoogle Scholar Soltanali et al., 2021
    Soltanali H., Khojastehpour M., Farinha J.T., Pais J.E.D.A.E. An integrated fuzzy
    fault tree model with Bayesian network-based maintenance optimization of complex
    equipment in automotive manufacturing Energies, 14 (22) (2021), p. 7758 CrossRefView
    in ScopusGoogle Scholar Traini et al., 2019 Traini E., Bruno G., D’Antonio G.,
    Lombardi F. Machine learning framework for predictive maintenance in milling IFAC-PapersOnLine,
    52 (13) (2019), pp. 177-182 View PDFView articleView in ScopusGoogle Scholar Wang
    et al., 2016 Wang S., Wan J., Zhang D., Li D., Zhang C. Towards smart factory
    for industry 4.0: A self-organized multi-agent system with big data based feedback
    and coordination Computer Networks, 101 (2016), pp. 158-168 View PDFView articleGoogle
    Scholar Willmott and Matsuura, 2005 Willmott C.J., Matsuura K. Advantages of the
    Mean Absolute Error (MAE) over the root mean square error (RMSE) in assessing
    average model performance Climate Research, 30 (1) (2005), pp. 79-82 CrossRefView
    in ScopusGoogle Scholar Wright and Schultz, 2018 Wright S.A., Schultz A.E. The
    rising tide of artificial intelligence and business automation: Developing an
    ethical framework Business Horizons, 61 (6) (2018), pp. 823-832 View PDFView articleView
    in ScopusGoogle Scholar Xie et al., 2021 Xie X., Wu D., Liu S., Li R. IoT data
    analytics using deep learning (2021) arXiv:1708.03854 [cs] Google Scholar Zhang
    et al., 2018a Zhang J., Wang P., Yan R., Gao R.X. Deep learning for improved system
    remaining life prediction Procedia CIRP, 72 (2018), pp. 1033-1038 View PDFView
    articleCrossRefGoogle Scholar Zhang et al., 2018b Zhang J., Wang P., Yan R., Gao
    R.X. Long short-term memory for machine remaining life prediction Journal of Manufacturing
    Systems, 48 (2018), pp. 78-86 View PDFView articleCrossRefGoogle Scholar Zonta
    et al., 2020 Zonta T., Da Costa C.A., da Rosa Righi R., de Lima M.J., da Trindade
    E.S., Li G.P. Predictive maintenance in the Industry 4.0: A systematic literature
    review Computers & Industrial Engineering, 150 (2020), Article 106889 View PDFView
    articleView in ScopusGoogle Scholar Cited by (1) A data-driven construction method
    of aggregated value chain in three phases for manufacturing enterprises 2024,
    Computers and Industrial Engineering Show abstract © 2024 The Authors. Published
    by Elsevier Ltd. Recommended articles SCR-CUSUM: An illness-death semi-Markov
    model-based risk-adjusted CUSUM for semi-competing risk data monitoring Computers
    & Industrial Engineering, Volume 184, 2023, Article 109530 Ruoyu Liu, …, Yuqian
    Liu View PDF Production, distribution, and capacity planning for an integrated
    buyer-vendor system incorporating different production and shipping scenarios
    Computers & Industrial Engineering, Volume 184, 2023, Article 109545 Mahtab Karimpoor,
    …, Sayyed Ehsan Monabbati View PDF Optimization for vaccination demand allocation
    and distribution routes in pandemics based on a hierarchy decision model Computers
    & Industrial Engineering, Volume 184, 2023, Article 109568 Haixiang Guo, …, Wenkai
    Zhang View PDF Show 3 more articles Article Metrics Captures Readers: 42 View
    details About ScienceDirect Remote access Shopping cart Advertise Contact and
    support Terms and conditions Privacy policy Cookies are used by this site. Cookie
    settings | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier
    B.V., its licensors, and contributors. All rights are reserved, including those
    for text and data mining, AI training, and similar technologies. For all open
    access content, the Creative Commons licensing terms apply."'
  inline_citation: '>'
  journal: Computers and Industrial Engineering
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Remaining useful lifetime prediction for predictive maintenance in manufacturing
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Ji S.
  - Lin C.
  citation_count: '1'
  description: A human motion pattern recognition algorithm based on Nano-sensor and
    deep learning is studied to recognize human motion patterns in real time and with
    high accuracy. First, human motion data are collected by micro electro mechanical
    system, and the noise in such data is filtered by smoothing filtering method to
    obtain high-quality motion data. Second, key time-domain features are extracted
    from high-quality motion data. Finally, after fusing and processing the key time-domain
    features, it is input into the deep long and short-term memory (LSTM) neural network
    to build a deep LSTM human motion pattern recognition model and complete human
    motion pattern recognition. The results show that the proposed algorithm can realize
    the recognition of various motion patterns with high accuracy of data acquisition,
    the average recognition accuracy is 94.8%, the average recall reaches 89.7%, and
    the F1 score of the algorithm are high, and the recognition time consuming is
    short, which can realize accurate and efficient human motion pattern recognition
    and provide guarantee for effective monitoring of the target human motion health.
  doi: 10.5755/j01.itc.52.3.33155
  full_citation: '>'
  full_text: '>

    "HOME ABOUT CURRENT ARCHIVES Search Register Login Home > Archives > Vol. 52 No.
    3 (2023) > Articles Human Motion Pattern Recognition Based on Nano-sensor and
    Deep Learning Sha Ji Chengde Lin Krirk University DOI: https://doi.org/10.5755/j01.itc.52.3.33155
    Keywords: Human motion, Recognition, Nano-sensor, Deep learning, Smoothing filtering
    method, Time domain features, LSTM neural network Abstract A human motion pattern
    recognition algorithm based on Nano-sensor and deep learning is studied to recognize
    human motion patterns in real time and with high accuracy. First, human motion
    data are collected by micro electro mechanical system, and the noise in such data
    is filtered by smoothing filtering method to obtain high-quality motion data.
    Second, key time-domain features are extracted from high-quality motion data.
    Finally, after fusing and processing the key time-domain features, it is input
    into the deep long and short-term memory (LSTM) neural network to build a deep
    LSTM human motion pattern recognition model and complete human motion pattern
    recognition. The results show that the proposed algorithm can realize the recognition
    of various motion patterns with high accuracy of data acquisition, the average
    recognition accuracy is 94.8%, the average recall reaches 89.7%, and the F1 score
    of the algorithm are high, and the recognition time consuming is short, which
    can realize accurate and efficient human motion pattern recognition and provide
    guarantee for effective monitoring of the target human motion health. PDF Published
    2023-09-26 Issue Vol. 52 No. 3 (2023) Section Articles License Copyright terms
    are indicated in the Republic of Lithuania Law on Copyright and Related Rights,
    Articles 4-37. Impact Factor 1.1 (2022)        Information For Readers For Authors
    For Librarians Print ISSN: 1392-124X  Online ISSN: 2335-884X"'
  inline_citation: '>'
  journal: Information Technology and Control
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Human Motion Pattern Recognition Based on Nano-sensor and Deep Learning
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Shi M.
  - Lu H.
  - Li Z.X.
  - Zhu D.M.
  - Wang Z.Q.
  citation_count: '0'
  description: Grasp detection is a visual recognition task where the robot makes
    use of its sensors to detect graspable objects in its environment. Despite the
    steady progress in robotic grasping, it is still difficult to achieve both real-time
    and high accuracy grasping detection. In this paper, we propose a real-time robotic
    grasp detection method, which can accurately predict potential grasp for parallel-plate
    robotic grippers using RGB images. Our work employs an end-to-end convolutional
    neural network which consists of a feature descriptor and a grasp detector. And
    for the first time, we add an attention mechanism to the grasp detection task,
    which enables the network to focus on grasp regions rather than background. Specifically,
    we present an angular label smoothing strategy in our grasp detection method to
    enhance the fault tolerance of the network. We quantitatively and qualitatively
    evaluate our grasp detection method from different aspects on the public Cornell
    dataset and Jacquard dataset. Extensive experiments demonstrate that our grasp
    detection method achieves superior performance to the state-of-the-art methods.
    In particular, our grasp detection method ranked first on both the Cornell dataset
    and the Jacquard dataset, giving rise to the accuracy of 98.9% and 95.6%, respectively
    at real-time calculation speed.
  doi: 10.1007/s11390-022-1458-5
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Log in Find a journal Publish
    with us Track your research Search Cart Home Journal of Computer Science and Technology
    Article Accurate Robotic Grasp Detection with Angular Label Smoothing Regular
    Paper Published: 30 September 2023 Volume 38, pages 1149–1161, (2023) Cite this
    article Download PDF Access provided by University of Nebraska-Lincoln Journal
    of Computer Science and Technology Aims and scope Submit manuscript Min Shi, Hao
    Lu, Zhao-Xin Li, Deng-Ming Zhu & Zhao-Qi Wang  107 Accesses 1 Altmetric Explore
    all metrics Abstract Grasp detection is a visual recognition task where the robot
    makes use of its sensors to detect graspable objects in its environment. Despite
    the steady progress in robotic grasping, it is still difficult to achieve both
    real-time and high accuracy grasping detection. In this paper, we propose a real-time
    robotic grasp detection method, which can accurately predict potential grasp for
    parallel-plate robotic grippers using RGB images. Our work employs an end-to-end
    convolutional neural network which consists of a feature descriptor and a grasp
    detector. And for the first time, we add an attention mechanism to the grasp detection
    task, which enables the network to focus on grasp regions rather than background.
    Specifically, we present an angular label smoothing strategy in our grasp detection
    method to enhance the fault tolerance of the network. We quantitatively and qualitatively
    evaluate our grasp detection method from different aspects on the public Cornell
    dataset and Jacquard dataset. Extensive experiments demonstrate that our grasp
    detection method achieves superior performance to the state-of-the-art methods.
    In particular, our grasp detection method ranked first on both the Cornell dataset
    and the Jacquard dataset, giving rise to the accuracy of 98.9% and 95.6%, respectively
    at real-time calculation speed. Article PDF References Kumra S, Kanan C. Robotic
    grasp detection using deep convolutional neural networks. In Proc. the 2017 IEEE/RSJ
    International Conference on Intelligent Robots and Systems, Sept. 2017, pp.769–776.
    https://doi.org/10.1109/IROS.2017.8202237. Aoki Y, Goforth H, Srivatsan R A, Lucey
    S. PointNetLK: Robust & efficient point cloud registration using Point-Net. In
    Proc. the 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition,
    Jun. 2019, pp.7163–7172. https://doi.org/10.1109/CVPR.2019.00733. Choy C, Dong
    W, Koltun V. Deep global registration. In Proc. the 2020 IEEE/CVF Conference on
    Computer Vision and Pattern Recognition, Jun. 2020, pp.2511–2520. 10.1109/CVPR42600.2020.00259.
    Wang Y, Solomon J. Deep closest point: Learning representations for point cloud
    registration. In Proc. the 2019 IEEE/CVF International Conference on Computer
    Vision, Oct. 27–Nov. 2, 2019, pp.3522–3531. https://doi.org/10.1109/ICCV.2019.00362.
    Zhou Q Y, Park J, Koltun V. Fast global registration. In Proc. the 14th European
    Conference on Computer Vision, Oct. 2016, pp.766–782. https://doi.org/10.1007/978-3-319-46475-6_47.
    Lenz I, Lee H, Saxena A. Deep learning for detecting robotic grasps. The International
    Journal of Robotics Research, 2015, 34(4/5): 705–724. https://doi.org/10.1177/0278364914549607.
    Article   Google Scholar   Krizhevsky A, Sutskever I, Hinton G E. ImageNet classification
    with deep convolutional neural networks. Communications of the ACM, 2017, 60(6):
    84–90. https://doi.org/10.1145/3065386. Article   Google Scholar   Redmon J, Angelova
    A. Real-time grasp detection using convolutional neural networks. In Proc. the
    2015 IEEE International Conference on Robotics and Automation, May 2015, pp.1316–1322.
    https://doi.org/10.1109/ICRA.2015.7139361. Zhou X W, Lan X G, Zhang H B, Tian
    Z Q, Zhang Y, Zheng N. Fully convolutional grasp detection network with oriented
    anchor box. In Proc. the 2018 IEEE/RSJ International Conference on Intelligent
    Robots and Systems, Oct. 2018, pp.7223–7230. https://doi.org/10.1109/IROS.2018.8594116.
    He K M, Zhang X Y, Ren S Q, Sun J. Deep residual learning for image recognition.
    In Proc. the 2016 IEEE Conference on Computer Vision and Pattern Recognition,
    Jun. 2016, pp.770–778. https://doi.org/10.1109/CVPR.2016.90. Park D, Chun S Y.
    Classification based grasp detection using spatial transformer network. arXiv:
    1803.01356, 2018. https://arxiv.org/abs/1803.01356, Oct. 2023. Asif U, Tang J
    B, Harrer S. GraspNet: An efficient convolutional neural network for real-time
    grasp detection for low-powered devices. In Proc. the 27th International Joint
    Conference on Artificial Intelligence, July 2018, pp.4875–4882. https://doi.org/10.24963/ijcai.2018/677.
    Kumra S, Joshi S, Sahin F. Antipodal robotic grasping using generative residual
    convolutional neural network. In Proc. the 2020 IEEE/RSJ International Conference
    on Intelligent Robots and Systems, Oct. 2020, pp.9626–9633. https://doi.org/10.1109/IROS45743.2020.9340777.
    Karaoguz H, Jensfelt P. Object detection approach for robot grasp detection. In
    Proc. the 2019 International Conference on Robotics and Automation, May 2019,
    pp.4953–4959. https://doi.org/10.1109/ICRA.2019.8793751. Chu F J, Xu R N, Vela
    P A. Real-world multiobject, multigrasp detection. IEEE Robotics and Automation
    Letters, 2018, 3(4): 3355–3362. https://doi.org/10.1109/LRA.2018.2852777. Article   Google
    Scholar   Wang C Y, Liao H Y M, Wu Y H, Chen P Y, Hsieh J W, Yeh I H. CSPNet:
    A new backbone that can enhance learning capability of CNN. In Proc. the 2020
    IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, Jun.
    2020, pp.390–391. https://doi.org/10.1109/CVPRW50498.2020.00203. Pavlakos G, Zhou
    X W, Chan A, Derpanis K G, Daniilidis K. 6-DoF object pose from semantic keypoints.
    In Proc. the 2017 IEEE International Conference on Robotics and Automation, May
    29–June 3, 2017, pp.2011–2018. https://doi.org/10.1109/ICRA.2017.7989233. Satish
    V, Mahler J, Goldberg K. On-policy dataset synthesis for learning robot grasping
    policies using fully convolutional deep networks. IEEE Robotics and Automation
    Letters, 2019, 4(2): 1357–1364. https://doi.org/10.1109/LRA.2019.2895878. Article   Google
    Scholar   Tekin B, Sinha S N, Fua P. Real-time seamless single shot 6D object
    pose prediction. In Proc. the 2018 IEEE/CVF Conference on Computer Vision and
    Pattern Recognition, Jun. 2018, pp.292–301. https://doi.org/10.1109/CVPR.2018.00038.
    Peng S D, Liu Y, Huang Q X, Zhou X W, Bao H J. PVNet: Pixel-wise voting network
    for 6DoF pose estimation. In Proc. the 2019 IEEE/CVF Conference on Computer Vision
    and Pattern Recognition, Jun. 2019, pp.4556–4565. https://doi.org/10.1109/CVPR.2019.00469.
    He Y S, Sun W, Huang H B, Liu J R, Fan H Q, Sun J. PVN3D: A deep point-wise 3D
    keypoints voting network for 6DoF pose estimation. In Proc. the 2020 IEEE/CVF
    Conference on Computer Vision and Pattern Recognition, Jun. 2020, pp.11632–11641.
    https://doi.org/10.1109/CVPR42600.2020.01165. Wang C, Xu D F, Zhu Y K, Martín-Martín
    R, Lu C W, Li F F, Savarese S. DenseFusion: 6D object pose estimation by iterative
    dense fusion. In Proc. the 2019 IEEE/CVF Conference on Computer Vision and Pattern
    Recognition, Jun. 2019, pp.3338–3347. https://doi.org/10.1109/CVPR.2019.00346.
    Choi C, Schwarting W, DelPreto J, Rus D. Learning object grasping for soft robot
    hands. IEEE Robotics and Automation Letters, 2018, 3(3): 2370–2377. https://doi.org/10.1109/LRA.2018.2810544.
    Article   Google Scholar   Liang H Z, Ma X J, Li S, Görner M, Tang S, Fang B,
    Sun F C, Zhang J W. PointNetGPD: Detecting grasp configurations from point sets.
    In Proc. the 2019 International Conference on Robotics and Automation, May 2019,
    pp.3629–3635. https://doi.org/10.1109/ICRA.2019.8794435. Pas A, Gualtieri M, Saenko
    K, Platt R. Grasp pose detection in point clouds. The International Journal of
    Robotics Research, 2017, 36(13/14): 1455–1473. https://doi.org/10.1177/0278364917735594.
    Article   Google Scholar   Mahler J, Liang J, Niyaz S, Laskey M, Doan R, Liu X
    Y, Ojea J A, Goldberg K. Dex-Net 2.0: Deep learning to plan robust grasps with
    synthetic point clouds and analytic grasp metrics. arXiv: 1703.09312, 2017. https://arxiv.org/abs/1703.09312,
    Oct. 2023. Mousavian A, Eppner C, Fox D. 6-DOF GraspNet: Variational grasp generation
    for object manipulation. In Proc. the 2019 IEEE/CVF International Conference on
    Computer Vision, Oct. 27–Nov. 2, 2019, pp.2901–2910. https://doi.org/10.1109/ICCV.2019.00299.
    Jiang Y, Moseson S, Saxena A. Efficient grasping from RGBD images: Learning using
    a new rectangle representation. In Proc. the 2011 IEEE International Conference
    on Robotics and Automation, May 2011, pp.3304–3311. https://doi.org/10.1109/ICRA.2011.5980145.
    Guo D, Sun F C, Liu H P, Kong T, Fang B, Xi N. A hybrid deep architecture for
    robotic grasp detection. In Proc. the 2017 IEEE International Conference on Robotics
    and Automation, May 29–June 3, 2017, pp.1609–1614. https://doi.org/10.1109/ICRA.2017.7989191.
    Ren S Q, He K M, Girshick R, Sun J. Faster R-CNN: Towards real-time object detection
    with region proposal networks. In Proc. the 29th Annual Conference on Neural Information
    Processing Systems, Dec. 2015, pp.91–99. Depierre A, Dellandréa E, Chen L M. Jacquard:
    A large scale dataset for robotic grasp detection. In Proc. the 2018 IEEE/RSJ
    International Conference on Intelligent Robots and Systems, Oct. 2018, pp.3511–3516.
    https://doi.org/10.1109/IROS.2018.8593950. Redmon J, Farhadi A. YOLOV3: An incremental
    improvement. arXiv: 1804.02767, 2018. https://arxiv.org/abs/1804.02767, Oct. 2023.
    Hu J, Shen L, Sun G. Squeeze-and-excitation networks. In Proc. the IEEE Conference
    on Computer Vision and Pattern Recognition, Aug. 2020, pp.7132–7141. https://doi.org/10.1109/TPAMI.2019.2913372.
    Morrison D, Corke P, Leitner J. Learning robust, real-time, reactive robotic grasping.
    The International Journal of Robotics Research, 2020, 39(2/3): 183–201. https://doi.org/10.1177/0278364919859066.
    Article   Google Scholar   Kingma D P, Ba J. Adam: A method for stochastic optimization.
    arXiv: 1412.6980, 2014. https://arxiv.org/abs/1412.6980, Oct. 2023. Download references
    Author information Authors and Affiliations School of Control and Computer Engineering,
    North China Electric Power University, Beijing, 102206, China Min Shi & Hao Lu
    Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190,
    China Zhao-Xin Li, Deng-Ming Zhu & Zhao-Qi Wang Corresponding author Correspondence
    to Zhao-Xin Li. Supplementary Information ESM 1 (PDF 139 kb) Rights and permissions
    Reprints and permissions About this article Cite this article Shi, M., Lu, H.,
    Li, ZX. et al. Accurate Robotic Grasp Detection with Angular Label Smoothing.
    J. Comput. Sci. Technol. 38, 1149–1161 (2023). https://doi.org/10.1007/s11390-022-1458-5
    Download citation Received 22 March 2021 Accepted 14 August 2022 Published 30
    September 2023 Issue Date September 2023 DOI https://doi.org/10.1007/s11390-022-1458-5
    Share this article Anyone you share the following link with will be able to read
    this content: Get shareable link Provided by the Springer Nature SharedIt content-sharing
    initiative Keywords robotic grasp detection attention mechanism angular label
    smoothing anchor box deep learning Use our pre-submission checklist Avoid common
    mistakes on your manuscript. Sections References Abstract Article PDF References
    Author information Supplementary Information Rights and permissions About this
    article Advertisement Discover content Journals A-Z Books A-Z Publish with us
    Publish your research Open access publishing Products and services Our products
    Librarians Societies Partners and advertisers Our imprints Springer Nature Portfolio
    BMC Palgrave Macmillan Apress Your privacy choices/Manage cookies Your US state
    privacy rights Accessibility statement Terms and conditions Privacy policy Help
    and support 129.93.161.219 Big Ten Academic Alliance (BTAA) (3000133814) - University
    of Nebraska-Lincoln (3000134173) © 2024 Springer Nature"'
  inline_citation: '>'
  journal: Journal of Computer Science and Technology
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Accurate Robotic Grasp Detection with Angular Label Smoothing
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Wen X.
  - Hu J.
  - Chen H.
  - Huang S.
  - Hu H.
  - Zhang H.
  citation_count: '2'
  description: Light Detection and Ranging (LiDAR), a laser-based technology for environmental
    perception, finds extensive applications in intelligent transportation. Deployed
    on roadsides, it provides real-time global traffic data, supporting road safety
    and research. To overcome accuracy issues arising from sensor misalignment and
    to facilitate multi-sensor fusion, this paper proposes an adaptive calibration
    method. The method defines an ideal coordinate system with the road’s forward
    direction as the X-axis and the intersection line between the vertical plane of
    the X-axis and the road surface plane as the Y-axis. This method utilizes the
    Kalman filter (KF) for trajectory smoothing and employs the random sample consensus
    (RANSAC) algorithm for ground fitting, obtaining the projection of the ideal coordinate
    system within the LiDAR system coordinate system. By comparing the two coordinate
    systems and calculating Euler angles, the point cloud is angle-calibrated using
    rotation matrices. Based on measured data from roadside LiDAR, this paper validates
    the calibration method. The experimental results demonstrate that the proposed
    method achieves high precision, with calculated Euler angle errors consistently
    below 1.7%.
  doi: 10.3390/s23177542
  full_citation: '>'
  full_text: '>

    "This website uses cookies We use cookies to personalise content and ads, to provide
    social media features and to analyse our traffic. We also share information about
    your use of our site with our social media, advertising and analytics partners
    who may combine it with other information that you’ve provided to them or that
    they’ve collected from your use of their services. Consent Selection Necessary
    Preferences Statistics Marketing Show details                 Deny Allow selection
    Allow all   Journals Topics Information Author Services Initiatives About Sign
    In / Sign Up Submit   Search for Articles: Sensors All Article Types Advanced   Journals
    Sensors Volume 23 Issue 17 10.3390/s23177542 Submit to this Journal Review for
    this Journal Propose a Special Issue Article Menu Academic Editor Balázs Székely
    Subscribe SciFeed Recommended Articles Related Info Links More by Authors Links
    Article Views 734 Citations 3 Table of Contents Abstract Introduction The Basic
    Principles of Point Cloud Calibration Method Experiments Discussion Conclusions
    Author Contributions Funding Institutional Review Board Statement Informed Consent
    Statement Data Availability Statement Conflicts of Interest References share Share
    announcement Help format_quote Cite question_answer Discuss in SciProfiles thumb_up
    Endorse textsms Comment first_page settings Order Article Reprints Open AccessArticle
    Research on an Adaptive Method for the Angle Calibration of Roadside LiDAR Point
    Clouds by Xin Wen , Jiazun Hu , Haiyu Chen , Shichun Huang , Haonan Hu and Hui
    Zhang * School of Intelligent Systems Engineering, Sun Yat-sen University, Shenzhen
    518107, China * Author to whom correspondence should be addressed. Sensors 2023,
    23(17), 7542; https://doi.org/10.3390/s23177542 Submission received: 20 July 2023
    / Revised: 23 August 2023 / Accepted: 25 August 2023 / Published: 30 August 2023
    (This article belongs to the Section Radar Sensors) Download keyboard_arrow_down     Browse
    Figures Versions Notes Abstract Light Detection and Ranging (LiDAR), a laser-based
    technology for environmental perception, finds extensive applications in intelligent
    transportation. Deployed on roadsides, it provides real-time global traffic data,
    supporting road safety and research. To overcome accuracy issues arising from
    sensor misalignment and to facilitate multi-sensor fusion, this paper proposes
    an adaptive calibration method. The method defines an ideal coordinate system
    with the road’s forward direction as the X-axis and the intersection line between
    the vertical plane of the X-axis and the road surface plane as the Y-axis. This
    method utilizes the Kalman filter (KF) for trajectory smoothing and employs the
    random sample consensus (RANSAC) algorithm for ground fitting, obtaining the projection
    of the ideal coordinate system within the LiDAR system coordinate system. By comparing
    the two coordinate systems and calculating Euler angles, the point cloud is angle-calibrated
    using rotation matrices. Based on measured data from roadside LiDAR, this paper
    validates the calibration method. The experimental results demonstrate that the
    proposed method achieves high precision, with calculated Euler angle errors consistently
    below 1.7%. Keywords: LiDAR; angle calibration; Euler angles; point cloud; Kalman
    filter; RANSAC; vehicle trajectory; ITS Graphical Abstract 1. Introduction The
    comprehensive perception and real-time monitoring of traffic information throughout
    the entire highway network are of great significance for optimizing traffic management
    strategies and alleviating traffic congestion [1]. To date, traffic information
    collection and processing technologies have made significant advancements. Among
    them, the utilization of roadside sensing devices for achieving a holographic
    perception of traffic information has become a current research hotspot [2]. However,
    in practical applications, inaccurate vehicle trajectory detection results (Figure
    1) are often caused by the suboptimal installation pose of the Light Detection
    and Ranging (LiDAR, Figure 2). This can also lead to increased difficulties in
    data analysis and processing during the fusion perception of multiple data sources.
    Therefore, how to calibrate this offset angle has become a topic worthy of exploration.
    Figure 1. Schematic diagram of LiDAR error detection. Figure 2. Schematic diagram
    of the wrong LiDAR mounting angle. The commonly used roadside device perception
    technologies mainly include sensing technologies composed of devices such as Light
    Detection and Ranging (LiDAR) [3,4], Millimeter Wave Radar (MMW-Radar) [5,6],
    inductive sensors [7], cameras [8,9], etc. These sensing technologies can be used
    to monitor and collect real-time data on the movement of vehicles within a certain
    range on the road surface through either single-sensor perception or multi-sensor
    fusion perception. Based on this, comprehensive and accurate data on traffic conditions
    throughout the entire road segment can be obtained. Wang [10] summarized the advantages,
    disadvantages, and detection ranges of the aforementioned perception devices,
    as shown in Table 1. LiDAR is characterized by high accuracy, high resolution,
    and a wide perception range [11], enabling a more precise perception and measurement
    of vehicle trajectories. When placed at elevated points in a traffic scene, it
    allows for an overhead view to observe the overall situation, enabling real-time
    perception of the high-precision motion trajectories of each object in the traffic
    scene. However, in practical applications, inaccuracies in the installation angle
    of LiDAR or minor movements that occur during the installation process can lead
    to deviations in the scanning results of the LiDAR, as shown in Figure 3 (the
    point cloud data sourced from the KITTI dataset [12]). These factors can have
    a significant impact on perceiving the trajectories of vehicles, primarily manifested
    as follows: Figure 3. Schematic of the point cloud visualization effect in the
    case of a normal point cloud and angular deviation (the colored point cloud is
    the normal case; the gray point cloud is the wrong case). Table 1. Performance
    comparison of some roadside sensors. Positioning deviation: Angle deviations in
    LiDAR detection can lead to spatial deviations in vehicle positions, resulting
    in a decrease in the positioning accuracy of vehicle trajectories. Trajectory
    drift: Angle deviations can cause an amplification of the offset error between
    the LiDAR-perceived vehicle trajectory and the actual trajectory, leading to the
    presence of trajectory drift. Trajectory shape changes: Due to the presence of
    angle deviations, the perceived shape of the vehicle trajectory may undergo changes,
    potentially causing errors in determining the vehicle’s driving state and impacting
    subsequent traffic information processing and analysis. Negative impact on multi-sensor
    fusion perception: Angle deviations in LiDAR can result in inconsistencies between
    the perceived data and the data obtained from other sensors such as cameras and
    radars. Such inconsistencies make it challenging to accurately integrate and process
    data in a multi-sensor fusion perception system, affecting the comprehensive understanding
    and holistic analysis of traffic situations. The angle calibration of LiDAR point
    clouds refers to adjusting the collected point cloud data’s posture or rotation
    to align or align them with a specific reference coordinate system. To date, a
    significant amount of research has been conducted by domestic and international
    experts and scholars on angle calibration methods for LiDAR point clouds. These
    methods can be roughly classified into two categories: those with fixed reference
    objects and those with non-fixed reference objects. Methods with fixed reference
    objects primarily involve identifying known reference objects’ shape, position,
    and other information to calculate the LiDAR’s angular deviation, achieving the
    purpose of calibration. For example, Y. Park [13] proposed the use of a polygon
    plane identification board, Z. Pusztai [14] introduced a standard square marker
    board, and Zhu [15] employed a checkerboard marker board for calibration. However,
    these methods still have certain limitations for the angle calibration of roadside
    LiDAR point clouds. Operators need to set up reference markers for angle calibration,
    which not only requires significant effort but also poses safety concerns for
    the operators. Methods with non-fixed reference objects can be classified into
    two types: shape-based calibration and motion-based calibration [16]. For example,
    Y. Shen [17] proposed using detected object contours as references, and P. Moghadam
    [18] introduced a shape-based calibration method based on line features from depth
    sensors and cameras. These methods belong to shape-based calibration. Additionally,
    Z. Taylor [19] proposed the use of hand–eye calibration for the external parameter
    calibration of multiple sensors, which falls under motion-based calibration. These
    methods effectively calibrate and accurately position the geometric relationship
    between LiDAR and cameras or other sensing devices. However, they are not suitable
    for the angle calibration of individual LiDAR point cloud. Additionally, to facilitate
    the subsequent processing and analysis of point cloud segmentation and trajectory
    data, researchers prefer the detected road point clouds to be parallel to a specific
    coordinate plane in the LiDAR system’s coordinate system, while the direction
    of the road should align with a particular coordinate axis. In the field of intelligent
    transportation, point clouds registration [20,21] is a common method used to merge
    different LiDAR point cloud data and perform angle calibration. Its purpose is
    to align point cloud data from different LiDAR sensors into a shared coordinate
    system. By utilizing feature point matching algorithms, corresponding point pairs
    between different point clouds are identified, and the pose transformation (such
    as translation and rotation) between them is calculated to calibrate the coordinate
    systems of different LiDAR sensors. This enables precise data fusion and analysis.
    Zhang [22] proposed a three-dimensional registration method based on prior knowledge
    of traffic signs and traffic scenes. Y. Rui [23] proposed a method for registering
    data from multiple roadside LiDAR sensors based on point cloud features. These
    methods have shown remarkable performance in addressing the fusion and registration
    problem of multiple LiDAR information. However, when it comes to fusing vehicle
    trajectory information from different types of roadside sensing devices, determining
    a universally applicable coordinate system becomes crucial for achieving data
    fusion. Based on the above, this paper proposes a method for calibrating the angle
    deviation of roadside LiDAR point clouds. Unlike traditional calibration methods,
    this method does not rely on fixed reference objects but instead utilizes traffic
    elements (road heading direction and ground surface) as reference objects. By
    establishing an ideal coordinate system, the road heading direction is defined
    as the X-axis direction, and the direction of the intersection line perpendicular
    to the X-axis plane and the road surface plane is chosen as the Y-axis direction,
    thus constructing a reference framework adapted to the road. In this ideal coordinate
    system, the XY plane is essentially parallel to the road surface. This method
    primarily utilizes the Kalman filter (KF) to improve the smoothness of the trajectory.
    Afterward, based on a certain number of vehicle trajectory points and the fitted
    road surface plane, it calculates the projection of the ideal coordinate system
    XYZ onto the LiDAR system’s coordinate system xyz. In this projection, the road
    heading direction is taken as the X-axis direction, and the direction of the intersection
    line perpendicular to the X-axis plane and the road surface plane is taken as
    the Y-axis direction. Finally, the Euler angles are computed to achieve point
    cloud calibration using rotation matrices. The primary contributions of this article
    can be summarized as follows: Adaptive calibration method: This paper proposes
    a simple and efficient adaptive calibration method to address the accuracy issues
    of LiDAR sensors in roadside intelligent perception systems. By leveraging the
    Kalman filter (KF) and the random sample consensus (RANSAC) algorithm, this method
    ensures real-time calibration without the need for manual intervention. Ideal
    coordinate system definition: The method defines an ideal coordinate system based
    on the road’s forward direction as the X-axis and the intersection line between
    the vertical plane of the X-axis and the road surface plane as the Y-axis. This
    ideal coordinate system serves as a reference for calibration, enhancing the precision
    and stability of the calibration process. Additionally, it provides a universally
    applicable reference for further multi-sensor fusion perception. As mentioned
    earlier, research on methods for obtaining vehicle trajectories using LiDAR is
    already quite mature. Therefore, this paper does not provide a further description
    of vehicle trajectory perception methods using LiDAR. Instead, it primarily focuses
    on validating the feasibility of the calibration method based on the analysis
    of vehicle trajectory data derived from measured roadside point cloud data. The
    results demonstrate that the calculated Euler angles have an error rate consistently
    below 1.7%, indicating extremely high precision. The rest of the paper Is organized
    as follows: Section 2 provides a detailed introduction to the basic principles
    and working mechanism of the proposed point cloud calibration method. In Section
    3, comprehensive analysis and experimental validation are conducted using the
    measured data to assess the feasibility and effectiveness of the calibration method.
    Finally, in Section 4, the summary and discussion section, the experimental results
    are summarized, conclusions are drawn, and future research prospects are outlined.
    2. The Basic Principles of Point Cloud Calibration Method The paper presents a
    calibration method for addressing angle deviations in roadside LiDAR. Its application
    scenario is depicted in Figure 4, utilizing traffic elements (road heading direction
    and ground surface) as reference objects. The objective is to improve the accuracy
    of vehicle position detection and facilitate subsequent data processing and analysis.
    This section provides a detailed introduction to the basic principles of this
    calibration method, with Figure 5 illustrating the basic algorithm flow of the
    point cloud calibration method. As the methods for vehicle trajectory perception
    using LiDAR are already well developed, this section primarily focuses on introducing
    the calibration method as the main content. Figure 4. Schematic diagram of the
    application scenario. Figure 5. Flow chart of the point cloud calibration algorithm.
    2.1. Statistical Analysis of Vehicle Driving Directions The vehicle’s driving
    direction, based on LiDAR perception, is a crucial reference for calculating the
    projection of the road’s forward direction onto the coordinate system of the LiDAR
    system. This paper presents a statistical analysis of the angles between the perceived
    vehicle driving directions and the road heading directions based on four sets
    of measured LiDAR data. The LiDAR used in the experiments has been calibrated
    for angles using fixed reference markers, aligning the X-axis of the system’s
    coordinate system parallel to the road heading direction. The perception range
    was set as a 12 m segment, with 6 m in front and 6 m behind the LiDAR, as depicted
    in Figure 6. The statistical results are shown in Figure 7 and Figure 8. Figure
    6. Schematic diagram of the experimental scenario for the statistical analysis
    of vehicle travel directions. Figure 7. Boxplot: statistical analysis of the heading
    angles (in degrees) in four vehicle trajectory data sets. Figure 8. Statistical
    analysis of probability distribution: the angle (in degrees) between the vehicle’s
    driving direction and the forward direction of the road. The experimental results
    indicate that the expected value of the angle between the vehicle’s driving direction
    and the road heading direction is close to zero. Therefore, theoretically, it
    is possible to estimate the road heading direction based on a certain amount of
    vehicle trajectory data. 2.2. Smoothing of Vehicle Trajectories The Kalman filter
    (KF) is an efficient recursive filter, also known as an autoregressive filter,
    which is capable of estimating the state of a dynamic system from a series of
    incomplete and noisy measurements [24]. Due to the detection distance and occlusion
    issues, vehicle trajectory data based on LiDAR perception may suffer from false
    detections. The purpose of using the KF is to optimize the vehicle trajectories
    and improve their smoothness, making them closer to the true trajectory data.
    Compared to other trajectory smoothing algorithms, the KF exhibits a series of
    distinct advantages, which is the primary reason for selecting the KF in this
    paper. The following are the main advantages of the KF: Adaptability: The KF demonstrates
    outstanding adaptability to trajectory smoothing problems in linear systems when
    the data satisfy the conditions of linearity and Gaussian distribution. Under
    such conditions, the KF provides accurate and stable estimation results. Low computational
    cost: The KF exhibits relatively low computational complexity. By processing data
    using a recursive approach, it does not require a substantial amount of computational
    resources, making it suitable for real-time applications or scenarios with limited
    computational capacity. Optimality: Under the assumptions of linearity and Gaussian
    distribution, the KF represents the optimal solution for minimum mean square error
    estimation. This implies that under ideal conditions, it can achieve the best
    trajectory smoothing effect and deliver the most accurate estimation results.
    Low storage requirement: The KF only necessitates storing the current state and
    covariance information, without the need to retain historical data. Therefore,
    it places relatively low demands on storage resources, making it advantageous
    for applications in resource-constrained environments, such as embedded systems.
    In the KF, the state transition and measurement models are expressed as: 𝒙 ̂  𝑘
    =𝑨 𝒙 ̂  𝑘−1 +𝑩 𝒖 𝑘 + 𝑾 𝑘 (1) 𝒛 𝑘 =𝑯 𝒙 ̂  𝑘 + 𝑽 𝑘 (2) where 𝒙 ̂  𝑘 is the estimate
    of the prior state at time 𝑘 , 𝒖 𝑘 is the control vector at time 𝑘 , and 𝑾 𝑘 is
    the process noise at time 𝑘 , which follows a Gaussian distribution with mean
    0 and covariance denoted as 𝑸 𝑘 . 𝒛 𝑘 is the observed value at time 𝑘 , which
    is the detected vehicle position and is a known value, and 𝑽 𝑘 is the measurement
    noise at time 𝑘 , which also follows a Gaussian distribution with mean 0 and covariance
    denoted as 𝑹 𝑘 . 𝑨 is the state transition matrix that maps the state at time
    𝑘−1 to the state at time 𝑘 , 𝑩 is the control input matrix that maps the state
    at time 𝑘−1 to the control input at time 𝑘 , and 𝑯 is the transformation matrix
    that maps the state to the measurement space. If the observed value 𝒛 𝑘 is known,
    then the true state 𝑩 of the estimated system can be obtained. The prediction
    process can be represented as follows: 𝒙 ̂  𝑘∣𝑘−1 =𝑨 𝒙 ̂  𝑘−1∣𝑘−1 +𝑩 𝒖 𝑘 (3) 𝑷
    𝑘|𝑘−1 =𝑨 𝑷 𝑘−1|𝑘−1 𝑨 𝑇 + 𝑸 𝑘 (4) The filtering process can be represented as follows:
    𝑲 𝑘 = 𝑷 𝑘|𝑘−1 𝑯 𝑇 · (𝑯 𝑷 𝑘|𝑘−1 𝑯 𝑇 + 𝑹 𝑘 ) −1 (5) 𝒙 ̂  𝑘∣𝑘 = 𝒙 ̂  𝑘∣𝑘−1 + 𝑲 𝑘
    ( 𝒛 𝑘 −𝑯 𝒙 ̂  𝑘∣𝑘−1 ) (6) 𝑷 𝑘|𝑘 =(𝑰− 𝑲 𝑘 𝑯) 𝑷 𝑘|𝑘−1 (7) where 𝑲 𝑘 is the Kalman
    gain at time 𝑘 . 𝑷 𝑘|𝑘−1 and 𝑷 𝑘|𝑘 are the covariance at time 𝑘 and the filtered
    covariance at time 𝑘 , respectively, obtained based on the state at time 𝑘−1 .
    Their initial values can be any non-zero number. 𝒙 ̂  𝑘∣𝑘−1 and 𝒙 ̂  𝑘∣𝑘 are the
    state prediction at time 𝑘 and the filtered state at time 𝑘 (i.e., the final predicted
    state 𝒙 ̂  𝑘 ), obtained based on the state at time 𝑘−1 , respectively. They can
    have any initial values. 𝑰 is the identity matrix. Taking the driving trajectory
    of a vehicle with lane-changing behavior from the highD dataset [25] as an example,
    the effectiveness of the KF was tested by introducing some noise, as shown in
    Figure 9. It can be observed that the trajectory was optimized to a certain extent.
    Although the test was conducted using two-dimensional vehicle trajectories, the
    KF can also be applied to optimize three-dimensional vehicle driving trajectories
    [26]. Figure 9. Schematic diagram of the effect of the KF algorithm on the smoothing
    of vehicle trajectory points. 2.3. The Principles of Fitting the Ideal Coordinate
    System Based on statistical analysis of vehicle trajectory and the RANSAC algorithm,
    this paper determines the projection of the ideal coordinate system in the coordinate
    system of the LiDAR system. First, by performing a statistical analysis of the
    vehicle trajectory data, it is possible to fit the X-axis direction of the ideal
    coordinate system. Next, the RANSAC algorithm is utilized to fit the ground and
    find the intersection between the plane perpendicular to the X-axis and the ground,
    which serves as the Y-axis direction of the ideal coordinate system. Finally,
    the cross-product operation between the X-axis and Y-axis is performed to determine
    the Z-axis direction of the ideal coordinate system. The design of this process
    ensures that the three coordinate axes of the ideal coordinate system are mutually
    orthogonal. 2.3.1. Fitting the X-Axis This paper utilizes the accumulated direction
    vectors of vehicle trajectory to calculate the direction of the X-axis of the
    ideal coordinate system in the coordinate system of the LiDAR system. The algorithm
    flow for fitting the X-axis can be summarized into the following four steps: Preprocessing
    and data preparation: The original data are preprocessed to filter the vehicle
    trajectory data within the region of interest. Calculating the direction of travel
    vector for each vehicle: Calculate the motion direction vector for each vehicle
    and record it. Statistical analysis of travel direction vectors: Perform statistical
    analysis on the computed vehicle motion direction vectors to determine the direction
    of road advancement in the coordinate system. Evaluation and validation: Validate
    the analysis results to determine if there is a significant deviation from the
    ideal road advancement direction. Equation (8) represents the formula for vector
    summation. 𝒗 𝑋 = [ 𝒗 1 + 𝒗 2 +…+ 𝒗 𝑛 ] ‖[ 𝒗 1 + 𝒗 2 +…+ 𝒗 𝑛 ]‖ = [ 𝑥 1 + 𝑥 2 +…+
    𝑥 𝑛 , 𝑦 1 + 𝑦 2 +…+ 𝑦 𝑛 , 𝑧 1 + 𝑧 2 +…+ 𝑧 𝑛 ] ‖[ 𝑥 1 + 𝑥 2 +…+ 𝑥 𝑛 , 𝑦 1 + 𝑦 2
    +…+ 𝑦 𝑛 , 𝑧 1 + 𝑧 2 +…+ 𝑧 𝑛 ]‖ (8) where 𝒗 𝑋 =[ 𝑎 𝑋 , 𝑏 𝑋 , 𝑐 𝑋 ] is the sum vector
    (normalized) indicating the direction of the X-axis. 𝒗 1 , 𝒗 2 ,…, 𝒗 𝑛 are the
    normalized direction vectors of a vehicle’s motion, where 𝒗 𝑖 =[ 𝑥 𝑖 , 𝑦 𝑖 , 𝑧
    𝑖 ] . 2.3.2. Fitting the Y-Axis This paper considers the direction of the intersection
    between the X-axis vertical plane and the ground plane as the Y-axis direction.
    The main approach is based on implementing the RANSAC algorithm for fitting the
    ground plane. Random sample consensus (RANSAC) [27] is an iterative method used
    to estimate mathematical model parameters based on a set of observation data containing
    outliers. RANSAC is a non-deterministic algorithm as it produces reasonable results
    with a certain probability, and this probability increases with the number of
    allowed iterations. The method is commonly employed for fitting plane equations.
    Here are the advantages of the RANSAC algorithm compared to other plane fitting
    algorithms: Robustness: RANSAC is capable of handling data sets containing outliers
    and noise, as it can ignore these abnormal values and produce better fitting results.
    No dependency on initial values: RANSAC does not require initial values or prior
    information. It obtains an initial fitting model through random sampling, eliminating
    the need for preliminary estimations. Simplicity and efficiency: The basic idea
    of the RANSAC algorithm is straightforward, making it easy to understand and implement.
    By randomly selecting samples and iterating to find the best model, it exhibits
    high computational efficiency in most cases. Adjustable parameters: RANSAC allows
    setting parameters to control the number of samples and the fitting threshold,
    enabling fine-tuning according to specific problem requirements and achieving
    improved fitting results. The algorithm flow for fitting a plane using the RANSAC
    algorithm is as follows: Set the maximum number of iterations, 𝑚𝑎𝑥_𝑖𝑡𝑒𝑟𝑎𝑡𝑖𝑜𝑛𝑠
    . Set the distance threshold, 𝑡ℎ𝑟𝑒𝑠ℎ𝑜𝑙𝑑 , for determining inliers. Initialize
    the parameters for the best-fitting plane: 𝑏𝑒𝑠𝑡_𝑝𝑙𝑎𝑛𝑒=𝑁𝑜𝑛𝑒 and 𝑏𝑒𝑠𝑡_𝑖𝑛𝑙𝑖𝑒𝑟𝑠 are
    set as an empty set, 𝑏𝑒𝑠𝑡_𝑛𝑢𝑚_𝑖𝑛𝑙𝑖𝑒𝑟𝑠=0 . Iterate 𝑚𝑎𝑥_𝑖𝑡𝑒𝑟𝑎𝑡𝑖𝑜𝑛𝑠 times: a. Randomly
    select the smallest set of points from the input data. b. Use the selected points
    to estimate plane parameters (e.g., through least-squares fitting). c. By calculating
    the distance between each point and the estimated plane, identify the inliers.
    d. Calculate the number of inliers with distances below 𝑡ℎ𝑟𝑒𝑠ℎ𝑜𝑙𝑑 . e. If the
    number of inliers is greater than 𝑏𝑒𝑠𝑡_𝑛𝑢𝑚_𝑖𝑛𝑙𝑖𝑒𝑟𝑠 , update 𝑏𝑒𝑠𝑡_𝑛𝑢𝑚_𝑖𝑛𝑙𝑖𝑒𝑟𝑠 ,
    𝑏𝑒𝑠𝑡_𝑖𝑛𝑙𝑖𝑒𝑟𝑠 , and 𝑏𝑒𝑠𝑡_𝑝𝑙𝑎𝑛𝑒 . Re-fit the plane using all inliers from step 4(e)
    to obtain the final estimated plane parameters. The final result, A, represents
    the plane obtained via fitting using the RANSAC algorithm. Due to the possibility
    that 𝑏𝑒𝑠𝑡_𝑝𝑙𝑎𝑛𝑒 may not be parallel to the X-axis, the intersection between 𝑏𝑒𝑠𝑡_𝑝𝑙𝑎𝑛𝑒
    and 𝑃 𝑥 , which is perpendicular to the X-axis, is taken as the direction of the
    Y-axis. The calculation process for the direction vector of the Y-axis is as follows:
    Determine the normal vectors of the two planes: The normal vector of 𝑏𝑒𝑠𝑡_𝑝𝑙𝑎𝑛𝑒
    is 𝒏 𝐺 =[ 𝑥 𝑔 ,  y 𝑔 ,  z 𝑔 ] . The normal vector of plane 𝑃 𝑥 is 𝒏 𝑃 =[ 𝑥 𝑝 ,  y
    𝑝 ,  z 𝑝 ] . Calculate the direction vector of the intersection, 𝒏 𝑛 : 𝒏 𝑛 = 𝒏
    𝐺 × 𝒏 𝑃 =[ 𝑥 𝑛 ,  y 𝑛 ,  z 𝑛 ]=[ 𝑦 𝑔 ∙ 𝑧 𝑝 − 𝑧 𝑔 ∙ 𝑦 𝑝 , 𝑧 𝑔 ∙ 𝑥 𝑝 − 𝑥 𝑔 ∙ 𝑧 𝑝
    , 𝑥 𝑔 ∙ 𝑦 𝑝 − 𝑦 𝑔 ∙ 𝑥 𝑝 ] (9) Normalize the direction vector of the intersection:
    The magnitude ‖ 𝒏 𝑛 ‖ of the intersection’s direction vector can be calculated
    using Equation (10): ‖ 𝒏 𝑛 ‖= 𝑥 2 𝑛 +y 2 𝑛 +z 2 𝑛 − − − − − − − − − √ (10) The
    normalized 𝒗 𝑌 = 𝒏 𝑛 /‖ 𝒏 𝑛 ‖=[ 𝑎 𝑌 , 𝑏 𝑌 , 𝑐 𝑌 ] represents the direction of
    the Y-axis. 2.3.3. Fitting the Z-Axis The direction of the Z-axis, 𝒗 𝑍 =[ 𝑎 𝑍
    , 𝑏 𝑍 , 𝑐 𝑍 ] , can be obtained through the cross-product operation of the X-axis
    direction vector 𝒗 𝑋 and the Y-axis direction vector 𝒗 𝑌 , and the calculation
    process can be represented using Equation (11): 𝒗 𝑍 = 𝒗 𝑋 × 𝒗 𝑌 =[ 𝑎 𝑋 , 𝑏 𝑋 ,
    𝑐 𝑋 ]×[ 𝑎 𝑌 , 𝑏 𝑌 , 𝑐 𝑌 ]=[ 𝑏 𝑋 𝑐 𝑌 − 𝑐 𝑋 𝑏 𝑌 , 𝑐 𝑋 𝑎 𝑌 − 𝑎 𝑋 𝑐 𝑌 , 𝑎 𝑋 𝑏 𝑌 −
    𝑏 𝑋 𝑎 𝑌 ] (11) 2.4. Principles of Point Cloud Angle Calibration This paper employs
    rotation matrices to achieve angle calibration of LiDAR point clouds. A mathematical
    relationship exists between Euler angles and rotation matrices, where Euler angles
    are a method of describing the rotational orientation of objects in three-dimensional
    space using three consecutive angles of rotation. The rotation matrix [28] is
    a linear transformation matrix used to convert the rotational operations described
    by Euler angles into matrix multiplication, enabling the rotation transformation
    of three-dimensional objects. In this subsection, the LiDAR point cloud is treated
    as a three-dimensional object, and angle calibration of the point cloud is achieved
    by calculating Euler angles to obtain the rotation matrix. 2.4.1. Euler Angle
    Euler angles are used to describe the rotational orientation of an object in three-dimensional
    Euclidean space [29]. They consist of three rotation angles, typically denoted
    by symbols (𝛼,𝛽,𝛾) . Each angle represents the amount of rotation around a specific
    axis. Referring to Figure 10, xyz represents the reference axes of the reference
    frame, and XYZ represents the object’s own coordinate axes. The intersection line
    of the xy plane and the XY plane is denoted by N. For a zxz intrinsic Euler angle
    convention, the angles can be statically defined as follows: 𝛼 (precession angle)
    is the angle between the X-axis and N, 𝛽 (nutation angle) is the angle between
    the z-axis and Z-axis, and 𝛾 (spin angle) is the angle between N and the x-axis.
    The reference frame composed of xyz (fixed frame) is also known as the laboratory
    reference frame, which remains stationary. On the other hand, the coordinate system
    composed of XYZ (body-fixed frame) is fixed to the object and rotates with the
    object during its rotation. Figure 10. Three Euler angles: (𝛼,𝛽,𝛾) . The red axes
    represent the XYZ axes, and the blue axes represent the xyz axes. The black line
    is the intersection line (N). Regarding the order and labeling of angles, as well
    as the specification of the two axes of the angle, there are no conventions. Therefore,
    when using Euler angles, it is essential to explicitly define the rotation angles
    and rotation axes. In practical applications, different proper Euler angles can
    be used to describe the rotation of an object. 2.4.2. Rotation Matrix This paper
    utilizes rotation matrices to achieve the angle calibration of point cloud data.
    The specified rotation matrix is composed of three elementary rotation matrices,
    as shown in Equation (12): [𝑹]= ⎡ ⎣ ⎢ ⎢ ⎢ cos𝛾 −sin𝛾 0 sin𝛾 cos𝛾 0 0 0 1 ⎤ ⎦ ⎥
    ⎥ ⎥ ⎡ ⎣ ⎢ ⎢ ⎢ 1 0 0 0 cos𝛽 −sin𝛽 0 sin𝛽 cos𝛽 ⎤ ⎦ ⎥ ⎥ ⎥ ⎡ ⎣ ⎢ ⎢ cos𝛼 −sin𝛼 0 sin𝛼
    cos𝛼 0 0 0 1 ⎤ ⎦ ⎥ ⎥ (12) In the equation, from right to left, it represents rotations
    around the Z-axis ( 𝛼 ), the intersection line ( 𝛽 ), and the z-axis ( 𝛾 ). After
    some calculations, we obtain: [𝑹]= ⎡ ⎣ ⎢ ⎢ ⎢ cos𝛼cos𝛾−cos𝛽sin𝛼sin𝛾 −cos𝛼sin𝛾−cos𝛽sin𝛼cos𝛾
    sin𝛽sin𝛼 sin𝛼cos𝛾+cos𝛽cos𝛼sin𝛾 −sin𝛼sin𝛾+cos𝛽cos𝛼cos𝛾 −sin𝛽cos𝛼 sin𝛽sin𝛾 sin𝛽cos𝛾
    cos𝛽 ⎤ ⎦ ⎥ ⎥ ⎥ (13) 3. Experiments In the experiment, researchers selected a mechanical
    LiDAR (Light Detection and Ranging) system with 64 channels and the capability
    of performing three-dimensional high-speed scanning. The LiDAR’s scanning frequency
    is 10 Hz, with a horizontal resolution of 0.09° , a vertical field of view of
    26.8° , a distance accuracy of 2 cm, and a maximum detectable range of 120 m.
    3.1. Experimental Procedure The roadside perception system in the experiment involved
    mounting an uncalibrated LiDAR system at a height of 3 m on the side of a highway.
    The system continuously collected data for approximately 15 min, capturing trajectory
    information for nearly 1200 vehicles. Subsequently, the researchers used fixed
    reference markers for measurements to calculate the offset angle of the LiDAR
    system. This allowed them to determine the transformation relationship between
    the LiDAR system coordinate system and the ideal coordinate system, expressed
    as zxz Euler angles: 𝛼=4° , 𝛽=10° , and 𝛾=6° . These data were used to validate
    the accuracy of the proposed LiDAR point cloud angle calibration method. To provide
    a clear description of the validation process, this paper includes a validation
    algorithm flowchart for the LiDAR angle calibration method, as shown in Figure
    11. The flowchart illustrates the steps and computations involved in the validation
    process, ensuring the accuracy of the calibration method. Figure 11. Verification
    algorithm flowchart for the LiDAR angle calibration method. 3.2. Experimental
    Results and Analysis This paper validates the proposed calibration method for
    the LiDAR system. Based on the collected vehicle trajectory data, vehicle trajectories
    within a 10-m range before and after the LiDAR deployment locations are selected.
    The trajectory data is categorized into four experimental groups based on the
    vehicle IDs, with lower ID numbers being assigned to vehicles that entered the
    recording area earlier. These experimental groups are specifically labeled as
    Group A, Group B, Group C, and Group D in accordance with academic conventions.
    The partial calculation results for (𝛼,𝛽,𝛾) are shown in Table 2, and the summarized
    results of all calculations are presented in Figure 12. Figure 12. Calculated
    results of (𝛼,𝛽,𝛾) : Complete set of calculation results for the four experimental
    groups, with approximately 280 vehicles fitted in each group. Table 2. Euler angle
    computation results (partial) for Group A experiments: Euler angle calculation
    results for vehicle trajectories fitted with 1–30 vehicles. The experimental results
    indicate that there is almost no error between the calculated values of 𝛼 and
    𝛽 (their reference values: 𝛼=4° and 𝛽=10° ). However, for 𝛾 (reference value:
    𝛾=6° ), there is a relatively larger error. The relationship between the fitted
    vehicle trajectory count and the calculated result of 𝛾 , as well as its relationship
    with the amplitude variation, are shown in Figure 13. It can be observed that
    when the number of fitted vehicles exceeds 50, the calculated results for 𝛾 stabilize,
    and the error rate for 𝛾 remains below 1.7%. This demonstrates that the method
    possesses a high level of reliability and accuracy in addressing the calibration
    issues of LiDAR point clouds. Figure 13. Calculated results of the calibration
    angle (angle 𝛾 ): Temporal evolution and amplitude analysis of angle 𝛾 . 4. Discussion
    In typical scenarios, when deploying a LiDAR within a roadside environment, factors
    such as the minor vibrations induced during the LiDAR’s operation, suboptimal
    mounting angles, and vibrations caused by high-speed vehicle passages can collectively
    result in deviations between the LiDAR’s scanning angles and the ideal scenario.
    Such deviations in scanning angles may potentially undermine the efficacy of the
    roadside LiDAR perception system, subsequently increasing the intricacy of post-data
    processing and analysis. Therefore, the investigation of methods for LiDAR angle
    deviation calibration holds utmost significance. This paper presents a calibration
    method suitable for roadside LiDAR systems, the essence of which lies in establishing
    an ideal coordinate system and leveraging traffic elements (including the ground
    and vehicle trajectories) as reference benchmarks. Calibration is achieved through
    precise processing of LiDAR point cloud data. The feasibility of this method is
    validated through a comprehensive experimental design. The experimental results
    unequivocally demonstrate that this method has achieved remarkable effectiveness
    in addressing the angle calibration challenges of roadside LiDAR systems. In comparison
    to conventional calibration methods based on a fixed reference board [13,14,15],
    this approach offers the following advantages: Cost and resource savings: In remote
    urban areas, embedding the program into the perception system is sufficient to
    achieve adaptive calibration. Furthermore, it can automatically calibrate the
    angle deviation of LiDAR periodically, ensuring the perception system maintains
    high-precision sensing capabilities. Applicability to multi-LiDAR systems: In
    scenarios with a linear layout of the perception area and the presence of multiple
    LiDAR sensors, relying on known LiDAR deployment positions greatly simplifies
    the challenges of fusing data from multiple sources, thereby enhancing the accuracy
    of fused perception results. However, in reality, the method of using fixed reference
    boards still holds a prominent position in terms of accuracy. Researchers’ analyses
    reveal that the crucial factor affecting the calibration accuracy of the method
    lies in the vehicle trajectory detection algorithm. Future research efforts will
    be concentrated on optimizing this aspect. The method proposed in [22] suggests
    using traffic signs as calibration references, essentially applying the fixed
    reference boards approach to roadside environments. Nevertheless, in certain road
    scenarios, available traffic signs might not always be present, limiting the applicability
    of this method. In [23], point cloud features are employed as references, and
    the registration of point clouds is achieved through optimization algorithms.
    Methods [22,23] are better suited for registering and fusing point clouds from
    multiple LiDAR sensors, yet they do not adequately address the issue of LiDAR
    angle deviations. Consequently, these methods fail to effectively enhance the
    precision of vehicle trajectory recognition. In summary, addressing the issue
    of LiDAR angle deviations in roadside LiDAR perception systems, the proposed method
    in this paper offers a sound solution to this problem, while also streamlining
    the challenges of multi- LiDAR data fusion and registration. The primary advantages
    of this method can be summarized as follows: Simplified parameter configuration:
    As an adaptive calibration method, it requires only the specification of the vehicle
    trajectory data for fitting, eliminating the need for intricate parameter tuning.
    Cost-effectiveness: It significantly saves human and material resources. High
    safety: It enhances operational safety by eliminating the need for manual intervention
    by operators at the roadside. Non-interference with normal operations: Embedded
    within the perception system’s program, it does not disrupt the normal sensing
    functionality of the LiDAR system, accurately capturing vehicle information and
    trajectory data. Adaptation to multi-LiDAR fusion perception: For continuous placement
    of multiple LiDAR sensors along long straight road sections, this calibration
    method simplifies the complexity of multi-source data fusion perception by requiring
    only the determination of LiDAR deployment positions. Enhancing trajectory data
    accuracy: By addressing the issue of angular deviation, this approach contributes
    to the improved perception accuracy of vehicle trajectory data. Consequently,
    it establishes a more precise foundational dataset for subsequent applications.
    The limitations of this method can be summarized as follows: Initial instability:
    During the initial operational phase of the system, when vehicles exhibit behaviors
    like lane changes within the region of interest, the limited quantity of fitted
    vehicle trajectory data might lead to reduced perception accuracy. However, as
    the number of fitted vehicle trajectories increases, accuracy gradually improves.
    Real-time impact: In the early stages of system operation, performing the calibration
    algorithm for almost every perceived vehicle trajectory data point might affect
    the real-time nature of the perception system, resulting in increased algorithm
    execution times. Applicability to complex road segments: This calibration method
    performs optimally on straight road segments; however, it might be challenging
    to find suitable road segments for calibration in complex road scenarios. Future
    research will extensively explore the application of the calibration algorithm
    to handle complex road segments with varying curvatures. Simultaneously, efforts
    will be directed toward enhancing algorithm efficiency and robustness. 5. Conclusions
    This paper introduces an innovative LiDAR angle calibration method that eliminates
    the need for a calibration board, effectively tackling the problem of point cloud
    angle deviation caused by the suboptimal installation poses of roadside LiDAR
    systems. The proposed method relies solely on perception targets (vehicle trajectories
    and the ground) for calibration. This paper validates the feasibility of the proposed
    calibration method based on real-world roadside data. The experimental results
    demonstrate that when the number of fitted vehicle trajectories exceeds 50, the
    calculated Euler angles remain relatively stable, with an error rate of less than
    1.7%. These experimental results fully demonstrate that the proposed calibration
    method in this paper possesses extremely high accuracy and reliability. During
    the initialization phase of roadside perception systems, this method can be utilized
    to achieve adaptive calibration of point cloud angles. Notably, this approach
    is robust to the influence of road slopes. By adopting this calibration method,
    the perception performance can be significantly enhanced, providing more standardized
    inputs for subsequent data processing and information fusion. With a forward-looking
    perspective, this technique shows tremendous potential in enhancing the precision
    and dependability of roadside LiDAR systems, thereby fostering improved safety
    and efficiency across diverse applications, including autonomous vehicles, traffic
    monitoring, and environmental sensing. Further research and development in this
    direction could lead to even more sophisticated calibration techniques, ultimately
    optimizing the overall performance and applicability of roadside LiDAR perception
    systems. Author Contributions Conceptualization, X.W. and H.Z.; data curation,
    H.H.; formal analysis, X.W.; funding acquisition, H.Z.; investigation, S.H.; methodology,
    X.W.; project administration, H.Z.; resources, J.H.; software, X.W.; supervision,
    H.Z.; validation, X.W., J.H. and H.C.; visualization, X.W.; writing—original draft,
    X.W.; writing—review and editing, H.Z. All authors have read and agreed to the
    published version of the manuscript. Funding This research received no external
    funding. Institutional Review Board Statement Not applicable. Informed Consent
    Statement Not applicable. Data Availability Statement The data are not publicly
    available due to restrictions on privacy. Conflicts of Interest The authors declare
    no conflict of interest. References Azimjonov, J.; Ozmen, A. Vision-Based Vehicle
    Tracking on Highway Traffic Using Bounding-Box Features to Extract Statistical
    Information. Comput. Electr. Eng. 2022, 97, 107560. [Google Scholar] [CrossRef]
    Wang, S.J.; Pi, R.D.; Li, J.; Guo, X.M.; Lu, Y.F.; Li, T.; Tian, Y. Object Tracking
    Based on the Fusion of Roadside LiDAR and Camera Data. IEEE Trans. Instrum. Meas.
    2022, 71, 1–14. [Google Scholar] [CrossRef] Sun, P.P.; Sun, C.H.; Wang, R.M.;
    Zhao, X.M. Object Detection Based on Roadside LiDAR for Cooperative Driving Automation:
    A Review. Sensors 2022, 22, 9316. [Google Scholar] [CrossRef] [PubMed] Lan, X.W.;
    Wang, C.; Lv, B.; Li, J.; Zhang, M.; Zhang, Z.Y. 3D Point Cloud Stitching for
    Object Detection with Wide FoV using Roadside LiDAR. Electronics 2023, 12, 703.
    [Google Scholar] [CrossRef] Chang, Y.Z.; Yu, H.Y. Trajectory Prediction Based
    on Roadside Millimeter Wave Radar and Video Fusion. In Proceedings of the 2021
    2nd International Seminar on Artificial Intelligence, Networking and Information
    Technology (AINIT), Shanghai, China, 15–17 October 2021; pp. 285–288. [Google
    Scholar] [CrossRef] Zhang, R.; Liu, H.Q.; Teng, K.M. A Trajectory Compensation
    Method Considering the Car-Following Behavior for Data Missing of Millimeter-Wave
    Radar in Roadside Detection Applications. Sensors 2023, 23, 1515. [Google Scholar]
    [CrossRef] Jung, J.; Tok, A.; Ritchie, S.G. Determining Optimal Sensor Locations
    under Uncertainty for a Truck Activity Monitoring System on California Freeways.
    J. Intell. Transp. Syst. 2021, 23, 221–234. [Google Scholar] [CrossRef] Du, Y.C.A.;
    Wang, F.Q.; Zhao, C.; Zhu, Y.F.; Ji, Y.X. Quantifying the Performance and Optimizing
    the Placement of Roadside Sensors for Cooperative Vehicle-Infrastructure Systems.
    IET Intell. Transp. Syst. 2022, 16, 908–925. [Google Scholar] [CrossRef] Cho,
    G.; Shinyama, Y.; Nakazato, J.; Maruta, K.; Sakaguchi, K. Object Recognition Network
    using Continuous Roadside Cameras. In Proceedings of the 2022 IEEE 95th Vehicular
    Technology Conference (VTC2022-SPRING), Helsinki, Finland, 19–22 June 2022. [Google
    Scholar] [CrossRef] Wang, Z.J.; Wu, Y.; Niu, Q.Q. Multi-Sensor Fusion in Automated
    Driving: A Survey. IEEE Access 2020, 8, 2847–2868. [Google Scholar] [CrossRef]
    Barad, J. Roadside Lidar Helping to Build Smart and Safe Transportation Infrastructure.
    In Proceedings of the Business of Automated Mobility (BAM) Forum, Virtual, 23–24
    June 2021. [Google Scholar] [CrossRef] Geiger, A.; Lenz, P.; Stiller, C.; Urtasun,
    R. Vision Meets Robotics: The KITTI Dataset. Int. J. Robot. Res. 2013, 32, 1231–1237.
    [Google Scholar] [CrossRef] Park, Y.; Yun, S.; Won, C.S.; Cho, K.; Um, K.; Sim,
    S. Calibration between Color Camera and 3D LIDAR Instruments with a Polygonal
    Planar Board. Sensors 2014, 14, 5333. [Google Scholar] [CrossRef] Pusztai, Z.;
    Eichhardt, I.; Hajder, L. Accurate Calibration of Multi-LiDAR-Multi-Camera Systems.
    Sensors 2018, 18, 2139. [Google Scholar] [CrossRef] Zhu, J.; Dong, Y.; Xu, X.;
    Wang, J.; Wu, J. A Spatiotemporal Registration Method between Roadside Lidar and
    Camera. In Proceedings of the 2022 International Symposium on Semiconductor and
    Electronic Technology (ISSET 2022), Fuzhou, China, 12–14 August 2022; p. 012003.
    [Google Scholar] [CrossRef] Wang, Z.; Shen, H.; Du, H.; Zhou, J.; Jin, X. Research
    on Calibration Method of Extrinsic Parameters of Lidar and Camera Carried by UAV.
    In Proceedings of the 2022 4th International Conference on Data-driven Optimization
    of Complex Systems (DOCS), Chengdu, China, 28–30 October 2022; pp. 1–6. [Google
    Scholar] [CrossRef] Shen, Y.; Addis, D.; Liu, H.; Hussain, F. A LIDAR-Based Tree
    Canopy Characterization under Simulated Uneven Road Condition: Advance in Tree
    Orchard Canopy Profile Measurement. J. Sens. 2017, 2017, 8367979. [Google Scholar]
    [CrossRef] Moghadam, P.; Bosse, M.; Zlot, R. Line-Based Extrinsic Calibration
    of Range and Image Sensors. In Proceedings of the 2013 IEEE International Conference
    on Robotics and Automation (ICRA), Karlsruhe, Germany, 6–10 May 2013; pp. 3685–3691.
    [Google Scholar] Taylor, Z.; Nieto, J. Motion-Based Calibration of Multimodal
    Sensor Extrinsics and Timing Offset Estimation. IEEE Trans. Robot. 2016, 32, 1215–1229.
    [Google Scholar] [CrossRef] Yang, L.; Ma, H.W.; Nie, Z.; Zhang, H.; Wang, Z.Y.;
    Wang, C.W. 3D LiDAR Point Cloud Registration Based on IMU Preintegration in Coal
    Mine Roadways. Sensors 2023, 23, 3473. [Google Scholar] [CrossRef] [PubMed] Li,
    Y.; Yang, F.; Zheng, W.N. A Novel Point Cloud Registration Method Based on ROPNet.
    Sensors 2023, 23, 993. [Google Scholar] [CrossRef] [PubMed] Zhang, Z.Y.; Zheng,
    J.Y.; Tao, Y.Y.; Xiao, Y.; Yu, S.M.; Asiri, S.; Li, J.C.; Li, T.S. Traffic Sign
    Based Point Cloud Data Registration with Roadside LiDARs in Complex Traffic Environments.
    Electronics 2022, 11, 1559. [Google Scholar] [CrossRef] Yue, R.; Xu, H.; Wu, J.Q.;
    Sun, R.J.; Yuan, C.W. Data Registration with Ground Points for Roadside LiDAR
    Sensors. Remote Sensing 2019, 11, 1354. [Google Scholar] [CrossRef] Zhang, Q.;
    Bhattarai, N.; Chen, H.; Xu, H.; Liu, H.C. Vehicle Trajectory Tracking Using Adaptive
    Kalman Filter from Roadside Lidar. J. Transp. Eng. Part A-Syst. 2023, 149, 04023043.
    [Google Scholar] [CrossRef] Krajewski, R.; Bock, J.; Kloeker, L.; Eckstein, L.
    The highD Dataset: A Drone Dataset of Naturalistic Vehicle Trajectories on German
    Highways for Validation of Highly Automated Driving Systems. In Proceedings of
    the 2018 21st International Conference on Intelligent Transportation Systems (ITSC),
    Maui, HI, USA, 4–7 November 2018; pp. 2118–2125. [Google Scholar] Guo, G.; Zhao,
    S.J. 3D Multi-Object Tracking with Adaptive Cubature Kalman Filter for Autonomous
    Driving. IEEE Trans. Intell. Veh. 2023, 8, 512–519. [Google Scholar] [CrossRef]
    Fischler, M.A.; Bolles, R.C. Random Sample Consensus: A Paradigm for Model Fitting
    with Applications to Image Analysis and Automated Cartography–ScienceDirect. Read.
    Comput. Vis. 1987, 24, 726–740. [Google Scholar] [CrossRef] Sarabandi, S.; Thomas,
    F. Solution Methods to the Nearest Rotation Matrix Problem in Double-Struck Capital
    R-3: A Comparative Survey. Numer. Linear Algebra Appl. 2023, e2492. [Google Scholar]
    [CrossRef] Zhu, B.; Chen, M.; Li, T. Prescribed Performance-Based Tracking Control
    for Quadrotor UAV under Input Delays and Input Saturations. Trans. Inst. Meas.
    Control 2022, 44, 2049–2062. [Google Scholar] [CrossRef]  Disclaimer/Publisher’s
    Note: The statements, opinions and data contained in all publications are solely
    those of the individual author(s) and contributor(s) and not of MDPI and/or the
    editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to
    people or property resulting from any ideas, methods, instructions or products
    referred to in the content.  © 2023 by the authors. Licensee MDPI, Basel, Switzerland.
    This article is an open access article distributed under the terms and conditions
    of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/).
    Share and Cite MDPI and ACS Style Wen, X.; Hu, J.; Chen, H.; Huang, S.; Hu, H.;
    Zhang, H. Research on an Adaptive Method for the Angle Calibration of Roadside
    LiDAR Point Clouds. Sensors 2023, 23, 7542. https://doi.org/10.3390/s23177542
    AMA Style Wen X, Hu J, Chen H, Huang S, Hu H, Zhang H. Research on an Adaptive
    Method for the Angle Calibration of Roadside LiDAR Point Clouds. Sensors. 2023;
    23(17):7542. https://doi.org/10.3390/s23177542 Chicago/Turabian Style Wen, Xin,
    Jiazun Hu, Haiyu Chen, Shichun Huang, Haonan Hu, and Hui Zhang. 2023. \"Research
    on an Adaptive Method for the Angle Calibration of Roadside LiDAR Point Clouds\"
    Sensors 23, no. 17: 7542. https://doi.org/10.3390/s23177542 Note that from the
    first issue of 2016, this journal uses article numbers instead of page numbers.
    See further details here. Article Metrics Citations Crossref   3 ads   1 PMC   2
    PubMed   2 Web of Science   2 Scopus   2 Google Scholar   [click to view] Article
    Access Statistics Article access statistics Article Views 7. Jan 17. Jan 27. Jan
    6. Feb 16. Feb 26. Feb 7. Mar 17. Mar 27. Mar 0 200 400 600 800 1000 For more
    information on the journal statistics, click here. Multiple requests from the
    same IP address are counted as one view.   Sensors, EISSN 1424-8220, Published
    by MDPI RSS Content Alert Further Information Article Processing Charges Pay an
    Invoice Open Access Policy Contact MDPI Jobs at MDPI Guidelines For Authors For
    Reviewers For Editors For Librarians For Publishers For Societies For Conference
    Organizers MDPI Initiatives Sciforum MDPI Books Preprints.org Scilit SciProfiles
    Encyclopedia JAMS Proceedings Series Follow MDPI LinkedIn Facebook Twitter Subscribe
    to receive issue release notifications and newsletters from MDPI journals Select
    options Subscribe © 1996-2024 MDPI (Basel, Switzerland) unless otherwise stated
    Disclaimer Terms and Conditions Privacy Policy"'
  inline_citation: '>'
  journal: Sensors
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Research on an Adaptive Method for the Angle Calibration of Roadside LiDAR
    Point Clouds
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Parsons I.L.
  - Norman D.A.
  - Karisch B.B.
  - Webb S.L.
  - Stone A.E.
  - Proctor M.D.
  - Street G.M.
  citation_count: '1'
  description: 'Body weight is a critical component for monitoring animal body mass,
    body condition, nutritional status, and health. However, traditional methods of
    collecting body weight are stressful, costly, and logistically impractical with
    cattle on extensive landscapes. Remote systems capable of collecting individual
    animal body weight provide a potential solution, but automatic systems may collect
    spurious weight measurements. The objectives of this study were to (1) describe
    the utility of using a remote weight capture system, (2) develop methods for identifying
    and removing spurious measurements, and (3) cross-validate automatically collected
    weights with static chute collected weights. Beef steers (n = 10) were tagged
    with electronic Radio Frequency Identification tags and grazed for 286 days in
    an improved pasture (±11.54 ha) containing Bermuda (Cynodon dactylon) and Tall
    Fescue (Festuca arundinacea) and inter-seeded with Annual Ryegrass (Secale cereale).
    A walk-over-weigh (WOW) system was designed from a platform scale connected to
    a TruTest® scale head and paired with a computer to save data files. In total,
    5,466 raw weights associated with individuals were collected (0 kg < weight <
    1,000 kg). We assessed the use of whole herd and individual means ± 1 standard
    deviation calculated either daily or over the entire trial to identify potential
    outliers. Additionally, 3 data smoothing methods were tested: a linear quadratic
    model, cubic splines, and polynomial regression. Each method was evaluated for
    total weight events recorded, event frequency, measured body mass and average
    daily gain. Further, accuracy and precision were calculated using cross-validation
    with paired chute weights (n = 8). Whole herd means ± 1 SD identified the fewest
    spurious data points and showed a stronger relationship with paired chute weights
    (R2 = 0.90) whereas individual daily means ± 1 SD identified the most and exhibited
    a weaker relationship (R2 = 0.68). Repeated quadratic regression models provided
    the best results, identifying 3,759 clean weight points and providing an R2 =
    0.96 between paired chute and WOW measurements. A real-time simulation analysis
    found that both individual and the herd means ± 1 SD performed similarly with
    an average of 30% of data classified as spurious and removed from the analysis,
    resulting in agreement (R2 = 0.93 for both individual and herd means) between
    chute and WOW weight measurements. These results indicate the utility of using
    a simple WOW system to collect data for measuring individual animal body mass
    and associated metrics, which has implications on making management and marketing
    decisions in near real-time.'
  doi: 10.1016/j.compag.2023.108113
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords 1. Introduction 2. Materials and methods
    3. Results 4. Discussion 5. Conclusion CRediT authorship contribution statement
    Declaration of Competing Interest Acknowledgements Appendix A. Supplementary data
    Data availability References Show full outline Cited by (1) Figures (9) Show 3
    more figures Tables (2) Table 1 Table 2 Extras (1) Supplementary data 1 Computers
    and Electronics in Agriculture Volume 212, September 2023, 108113 Automated walk-over-weigh
    system to track daily body mass and growth in grazing steers Author links open
    overlay panel Ira L. Parsons a, Durham A. Norman a, Brandi B. Karisch b, Stephen
    L. Webb c, Amanda E. Stone b, Mike D. Proctor d, Garrett M. Street a Show more
    Share Cite https://doi.org/10.1016/j.compag.2023.108113 Get rights and content
    Highlights • Body weight is a critical component for monitoring body mass, body
    condition, in grazing animals, but traditional methods are stressful, costly,
    and impractical to conduct frequently in extensive landscapes. • Remote systems
    automatically collecting body mass measurements often collect spurious weight
    measurements. • Multiple methods to identify and remove spurious weight points
    exist, each with a varying degree of accuracy, and it is important for researchers
    to identify and use the appropriate means which best fits their research objectives.
    • Robust regression provides a repeatable means of identifying and removing potentially
    spurious weight points in an automated fashion, with a high degree of precision
    and accuracy observed in the final body weights. Abstract Body weight is a critical
    component for monitoring animal body mass, body condition, nutritional status,
    and health. However, traditional methods of collecting body weight are stressful,
    costly, and logistically impractical with cattle on extensive landscapes. Remote
    systems capable of collecting individual animal body weight provide a potential
    solution, but automatic systems may collect spurious weight measurements. The
    objectives of this study were to (1) describe the utility of using a remote weight
    capture system, (2) develop methods for identifying and removing spurious measurements,
    and (3) cross-validate automatically collected weights with static chute collected
    weights. Beef steers (n = 10) were tagged with electronic Radio Frequency Identification
    tags and grazed for 286 days in an improved pasture (±11.54 ha) containing Bermuda
    (Cynodon dactylon) and Tall Fescue (Festuca arundinacea) and inter-seeded with
    Annual Ryegrass (Secale cereale). A walk-over-weigh (WOW) system was designed
    from a platform scale connected to a TruTest® scale head and paired with a computer
    to save data files. In total, 5,466 raw weights associated with individuals were
    collected (0 kg < weight < 1,000 kg). We assessed the use of whole herd and individual
    means ± 1 standard deviation calculated either daily or over the entire trial
    to identify potential outliers. Additionally, 3 data smoothing methods were tested:
    a linear quadratic model, cubic splines, and polynomial regression. Each method
    was evaluated for total weight events recorded, event frequency, measured body
    mass and average daily gain. Further, accuracy and precision were calculated using
    cross-validation with paired chute weights (n = 8). Whole herd means ± 1 SD identified
    the fewest spurious data points and showed a stronger relationship with paired
    chute weights (R2 = 0.90) whereas individual daily means ± 1 SD identified the
    most and exhibited a weaker relationship (R2 = 0.68). Repeated quadratic regression
    models provided the best results, identifying 3,759 clean weight points and providing
    an R2 = 0.96 between paired chute and WOW measurements. A real-time simulation
    analysis found that both individual and the herd means ± 1 SD performed similarly
    with an average of 30% of data classified as spurious and removed from the analysis,
    resulting in agreement (R2 = 0.93 for both individual and herd means) between
    chute and WOW weight measurements. These results indicate the utility of using
    a simple WOW system to collect data for measuring individual animal body mass
    and associated metrics, which has implications on making management and marketing
    decisions in near real-time. Previous article in issue Next article in issue Keywords
    AgroecologyAnimal-welfareBody conditionBody massIn-pasture body weightUngulates
    1. Introduction Body weight is frequently used to monitor body mass and change
    over time for management and research because it is indicative of body condition,
    animal health, and nutritional status. Nutritionists, geneticists, forage agronomists,
    range scientists, and livestock producers have long recognized the direct relationship
    between nutrient quality, breed composition, feeding behavior, and environment
    on animal health and weight gain (NASEM, 2016, Parsons et al., 2020). Measuring
    body weight in the traditional manner requires animals to be walked through an
    alley across a scale platform under a working chute or other restraint. Now modern
    technology and a greater adoption of regenerative agriculture have renewed the
    interest in remote methods to precisely monitor animal weight and changes in body
    mass. Traditional methods are labor intensive, time consuming, and place stress
    on animals and handlers. Range and beef cattle scientists have envisioned an in-pasture
    system for weighing cattle since the 1960′s (Martin et al., 1967). An in-pasture,
    near real-time weigh system would vastly increase the number of weights collected,
    thereby increasing the power and precision of measuring body mass and rate of
    gain in experimental studies (Reuter and Moffet, 2016). Individual animal management,
    supplemented by individual animal identification through radio frequency identification
    (RFID) tags and readers, has proven an extremely valuable advancement for livestock
    production (Brown et al., 2014). For livestock producers, precisely managing cattle
    growth curves and range conditions creates opportunities for meeting economic
    and environmental management goals on pastures and rangelands (Currie et al.,
    1989). Real-time measurements of animal weight and rate of gain also can serve
    as surrogates for animal age at maturity, nutritional status, and forage quality
    (NASEM, 2016, Van Soest, 1994). Pursuant to these improvements, here we demonstrate
    application of the walk-over-weigh (WOW) system built as part of a larger study
    to assess energy budgets and animal efficiency of grazing beef cattle on pasture.
    The WOW system includes a platform scale connected to a data recording device,
    which is situated so animals must walk across the platform to reach feed, mineral
    and/or water (Fig. 2). Typical platform scales designed for livestock use feature
    a front and back gate, allowing the animal to be restrained while recording the
    weight. Although these typical platform scales are accurate, they are not useful
    for automated data collection in pasture settings. By contrast, near real-time,
    automatic WOW systems can collect in pasture body weight, but the system can contain
    erroneous weights from, for example, two animals on the scale simultaneously,
    only a portion of an individual animal on the scale, or attribution of weight
    to another RFID in proximity to the reader. Thus, an algorithm capable of sorting
    between accurate and erroneous readings is necessary for the utilization and design
    of an in-field WOW system. The accuracy and repeatability of weights measured
    using a WOW is less studied in grazing beef cattle although much promising work
    has been conducted in feedlot cattle (MacNeil et al., 2021), dairy cows (Alawneh
    et al., 2011, Aldridge et al., 2017), and sheep (Brown et al., 2015, González-García
    et al., 2021, González-García et al., 2018a). In pasture WOW systems have been
    successfully utilized to predict calving in extensively managed beef cows (Aldridge
    et al., 2017) and measure animal live weight (Charmley et al., 2006, Imaz et al.,
    2020, Wells et al., 2021). Proprietary systems, such as those used by MacNeil
    et al., 2021, Wells et al., 2021, may use confidential data-cleaning algorithms,
    which while necessary, prevent researchers from accessing complete raw data. The
    objectives of this study were to: 1) describe the functionality of an automated
    WOW system with grazing steers, and 2) evaluate methods to identify and remove
    spurious weight data points. We evaluated the use of whole herd and individual
    mean weights ± 1 standard deviation calculated either daily or over the entire
    trial to identify potential outliers. Finally, we also 3) compared WOW measured
    weights to chute measured weights collected on the same day to validate the accuracy
    and precision of the WOW system. 2. Materials and methods 2.1. Animals and equipment
    This study was part of a broader research project that assessed fundamental grazing
    ecology principles on animal growth and fitness. Yearling Brahman (Bos taurus
    indicus) crossbred steers (n = 10; BW 232 ± 32 kg) were grazed together continuously
    on pasture from February 21st, 2020 to December 3rd, 2020, which resulted in 286
    days for the grazing trial. The study was located at the Pasture Demonstration
    Farm (Ardmore, Oklahoma, USA), owned and operated by Noble Research Institute.
    The area around the study site received 1,093 mm of precipitation, and mean temperature
    of 17 ± -10C with a relative humidity of 70 ± 15 percent (https://www.mesonet.org;
    Newport, OK site, accessed 08 December 2020). We used a single paddock (11.5 ha)
    throughout the entirety of the study, which was comprised of bermudagrass (Cynodon
    dactylon), tall fescue (Festuca arundinacea) and inter-seeded with winter annual
    ryegrass (Secale cereale) in November 2019. Water was provided via an automatic,
    ball type waterer situated in the fence line between adjoining pastures. Portable
    panels (J&I Manufacturing Inc., Madill, OK, USA) were used to construct an enclosure
    accessible via an alley way built over a platform scale for animals to enter the
    watering area (Fig. 1, Fig. 2). The scale (TruTest EziWeigh, Tru-Test Ltd., Mineral
    Wells, TX, USA) was powered by a deep cycle battery, which maintained charge using
    a solar panel battery charger (Texas Energy Control Products, Inc., Fort Worth,
    TX, USA). A technician calibrated the scale prior to the trial start, and whenever
    a system failure was detected (Appendix D). An RFID panel reader (Tru-Test Ltd.,
    Mineral Wells, TX, USA) was affixed to the side of the chute to read half duplex
    RFID tags (Alflex HDX, Merck and Co. Kenilworth, NJ, USA) assigned to each animal
    at the start of the study. Tags were replaced in two animals during the trial
    duration due to tag malfunctions. This system recorded animal weight upon entry
    and exit from the enclosure, which was the primary source of water, so animals
    had to walk across the scale twice per visit. Chute weights were collected monthly
    (n = 8), except for March, April, and May due to the COVID-19 pandemic, in a typical
    industry squeeze chute mounted on weigh-bars (Tru-Test LTD., Mineral Wells, TX,
    USA). Download : Download high-res image (2MB) Download : Download full-size image
    Fig. 1. Picture of the walk-over-weigh scale, solar panels, and waterer used to
    construct the experimental automated weighing system used to record body mass
    data on extensively managed grazing beef steers. Download : Download high-res
    image (199KB) Download : Download full-size image Fig. 2. Layout of the walk-over-weigh
    (WOW) system used for the grazing study period which featured a platform scale
    which the animals crossed to enter a pen created using portable panels around
    the water source and mineral tub. A solar panel was used to power the system which
    included the scale, and data recorder. The dotted line identifies where cattle
    panels were placed to form the watering pen, and the path used by cattle to enter,
    and exit portrayed using cattle tracks. 2.2. Data management and analysis All
    data were stored in comma-separated value (.csv) files created daily and stored
    on the scale head. Data were collected manually by a technician and then transferred
    to network system storage for processing and analysis. All static chute weights
    were recorded manually and later recorded in a spreadsheet (Excel, Office 365,
    Microsoft Corp., Seattle, WA, USA), which was then uploaded to network storage.
    Program R (R Core Team, 2021) was used for all analysis. At the conclusion of
    the study, all weight data were merged into one data set for each data source
    for analysis. We then examined the functionality of the WOW system by visually
    and numerically assessing the total number and temporal consistency of individual
    steer weight records. We examined the total number of WOW records and temporal
    interval between visits (Imaz et al., 2020). Normality of recorded weights were
    evaluated using the Shapiro-Wilke’s normality test via the shapiro.test function
    and coefficient of variation (CV). One animal demonstrated excessive missing data,
    indicating a tag or system failure, and was removed from the analysis. Then, the
    temporal variation in WOW visit frequency among animals was evaluated using a
    two-way Anova. Finally, the inter-weight interval and weight difference was calculated
    using the lag times between each recorded weight record and the immediately preceding
    record for each animal. This was used to assess the number of weight records associated
    with a single drinking event by assessing the proportion of events occurring at
    increasing intervals length, and statistically comparing them to a 0 null hypothesis
    using the t-test (Imaz et al., 2020). Also, weight differences served as an approximate
    metric for estimating weight gain attributed to water consumption. This provided
    two robust datasets representing animal weight records across a long temporal
    period using both an automated WOW and static chute scale systems. 2.2.1. Whole
    period After identifying the data set containing weight records with both temporal
    consistency and within a plausible biological range, we used the following procedures
    to develop robust methods to produce a clean dataset free of spurious weight records
    by identifying and removing them in a repeatable and rational fashion. Two primary
    approaches were employed to scan for spurious data: 1) mean weight ± 1 standard
    deviation (SD), calculated for the whole herd and individual daily and during
    the whole trial, and 2) smooth animal predicted body weight as a function of time
    using each of three smoothing algorithms: cubic splines, polynomial regression
    and robust regression. Using WOW recorded weights, herd and individual means and
    standard deviations were calculated via the mean and sd functions, respectively.
    We classified any points exceeding ± 1SD from the mean as spurious and removed
    them from the final dataset. To create smoothed prediction curves, we used 3 equations
    to predict animal weight as a function of time. Two polynomial smoothing functions
    including cubic splines and loess prediction models; each was created via the
    smooth.splines and loess functions, respectively. For each smoothed curve, we
    calculated a 95% confidence interval using the predict function within the stats
    package (R Core Team, 2021), and identified and removed all data points falling
    outside this interval from the data. Finally, we implemented Robust Regression
    via the rlm function via the MASS package (Fox and Fox, 2016, Venables et al.,
    2002), and identified spurious weight records with locations weights greater than
    0.99. After fitting each model and removing identified spurious weights, each
    smoothing model was refit to the cleaned weight data to generate a smoothed growth
    curve. 2.2.2. Real-time data analysis To evaluate the utility of using the WOW
    system as a management tool, we used methods identical to that described above,
    but conducted in a temporally sequential fashion analogous to what would be experienced
    in a real-time management scenario. For each study day, data were filtered to
    include only previously collected data, and weight data were evaluated for spurious
    data points according to each method. Following removal of spurious data points,
    cleaned data were fitted to a growth curve to evaluate animal performance to that
    point in the study. Thus, a unique growth curve was fitted on each trial day for
    each animal. Results from cross-validation procedures were averaged across the
    entire trial for each animal. 2.2.3. Cross-validation with static weights Finally,
    for the third objective, we evaluated the accuracy and precision of the WOW system
    compared to static chute weights using a cross-validation procedure. We conducted
    cross-validation using a linear regression model to compare chute versus average
    WOW recorded body weights. This is a common technique to test performance of competing
    or alternative methodology (here an automated WOW system) whereby performance
    is evaluated based on a 1-to-1 agreement between traditional (static chute weights)
    and experimental (WOW system) measured cattle weights (Harrell, 2001, Tedeschi,
    2006). Model fit was assessed using the summary to report R2 (precision indicated
    by R2 approaching 1), and intercept and slope (accuracy indicated by intercept
    = 0 and slope = 1). We also calculated the Lin’s Concordance Correlation Coefficient
    as an index of model precision, accuracy, and reproducibility using the CCC function
    in DescTools (Lin, 1989, Signorell, 2021, Tedeschi, 2006). Finally, we conducted
    a t-test using the t.test function to test the direction and significance of differences
    between paired WOW and chute weights. This provided a robust framework from which
    to make comparisons between a static chute weighing method common in the beef
    cattle industry and an automated data collection system. 3. Results 3.1. Function
    and performance of WOW system The WOW system collected 8,706 weights, of which
    3,301 were equal to 0 and removed along with records associated faulty ear tags.
    Due to the low numbers of recorded visits caused by RFID reader issues and refusal
    to use the WOW platform, steer 6063 was removed from further analysis. This left
    5,419 remaining weight records within the biologically plausible weight range,
    and the total frequency of scale visits collected per head per day is reported
    in Table 1 and Fig. 3. Animals exhibited significant variation (F = 44.21, P <
    0.01; DF days = 1 and DF animal = 9) in visit frequency across days and among
    animals, indicating variation in usage. Approximately 50% of total weights recorded
    had an inter-weight interval of less than 50 min, indicating animals were recorded
    both entering and leaving the watering area (Fig. 4). The average weight gain
    between entering and leaving the watering area, or gain attributed to water intake,
    was 31.77 ± 144.13, indicating that steers consumed ∼ 31.77 L of water per visit.
    Table 1. Summary of methods used to identify spurious weight records from the
    entire study (study length = 286 days) from grazed Brahman (*Bos taurus indicus*)
    steers grazed on improved pasture and weighed using an in-pasture walk-over-weigh
    system located in front of the water source. Cleaning methoda Recorded weights,
    nb Visit frequency, n/dc Frequency, SDd Prop retained, %e CVf Weight difference,
    kgg R2h Intercepti Slopej CCCk Raw weights 5,419 3.74 2.48 62.24 27.78 8.98 0.37
    −6.88 1.04 0.52 Mean ± 1 SD 4,223 3.08 1.86 48.51 13.28 12.46 0.90 40.43 0.93
    0.92 Mean per day, ±1 SD 4,171 3.09 1.98 47.91 18.25 9.91 0.93 26.25 0.96 0.94
    Individual mean ± 1 SD 4,212 3.07 1.94 48.38 14.47 14.07 0.87 27.77 0.97 0.90
    Individual daily mean ± 1 SD 3,914 3.17 1.71 44.96 22.86 15.37 0.68 −89.22 1.25
    0.74 Splines 775 1.78 1.07 8.90 11.52 19.78 0.61 18.48 1.00 0.70 LOESS 690 1.67
    0.95 7.93 13.64 11.49 0.99 6.68 0.99 0.88 Robust regression 3,537 2.78 1.62 40.63
    12.48 7.62 0.96 −4.38 1.03 0.97 a Cleaning Method used to identify spurious datapoints.
    b Number of weights used to monitor animal body mass change after applying each
    cleaning method. c Average records per day, n: Average number of weight records
    collected daily over the whole trial. d Variation in records per day, SD: Variation
    in recorded weight frequency per day measured over the course of the whole trial.
    e CV: Coefficient of variation between consequetively collected weights. f Weight
    difference, kg: Difference between paired static chute weights and WOW weight
    determined using paired t test. g R2: R-squared of linear models between static
    chute weights and WOW weights. h Intercept: Intercept of the linear model regression
    between paired WOW and chute weights. I Slope: Slope of linear model regression
    between paired WOW and chute weights. j CCC: Concordance Correlation Coefficient.
    Download : Download high-res image (895KB) Download : Download full-size image
    Fig. 3. This figure demonstrates the individual weight gain observed using 8,706
    raw walk-over-weigh system weights for 10 animals grazed at the Noble Research
    Institute’s Pasture Development for the 286-d study period. A visually observed
    trendline of clustered pointes indicates the ability of the system to capture
    accurate individual bodyweights, while the high number of outliers and points
    equal to 0 indicate the need to develop a quantifiable method to identify and
    remove spurious weight observations from the raw dataset. Download : Download
    high-res image (640KB) Download : Download full-size image Fig. 4. Percent of
    total weights recorded as inter-weight interval increases. Fifty percent of weight
    visits were recorded with an interval of less than 45 min, indicating that the
    system observed steers both entering and leaving the watering pen. Panel a) demonstrates
    that 90% of scale visits occurred with an interval of less than 24 h (1,440 min),
    indicating steers visited the waterer at least once per day. Panel b) Provides
    a zoomed in perspective of Panel a, which shows that approximately 50% of all
    weight records occurred with an interval of less than 45-minutes. Panel c) Demonstrates
    the change in the number of observed weights with an inter-weight interval an
    increasing interval plotted on the x-axis. The point where the number of observed
    inter-weight intervals were not statistically different from zero, measured using
    a t-test significance defined at P < 0.05, was used as the appropriate interval
    to define a single entry and exit bout from the watering area. 3.2. Whole trial
    spurious weight identification 3.2.1. Standard deviation filtering Results for
    data cleaned using SD (Aldridge et al., 2017) around means are reported in Table
    1 and cross-validation performance demonstrated in Fig. 5. Both whole herd and
    individual day-to-day methods exhibited less variation and higher agreement between
    static chute weights when compared to uncleaned WOW weights without spurious data
    points identified. The number of spurious data points identified ranged from 1,196
    to 5,419, with entire population mean and SD identifying the least, and individual
    mean and SD per day identifying the most (Table 1). Finally, we tested the accuracy
    and precision of cleaning methods using cross-validation between each cleaned
    dataset and static chute weights (Fig. 5, panels b - e). Precision (R2) values
    ranged from 0.68 to 0.93, while accuracy (Concordance Correlation Coefficient)
    ranged from 0.52 to 0.94. Daily means calculated using weights collected from
    the cohort provided the best accuracy and precision compared to static chute weights.
    Download : Download high-res image (847KB) Download : Download full-size image
    Fig. 5. Here are demonstrated the cross-validation plots showing agreement between
    static chute and walk-over-weigh (WOW) animal bodyweights. Panel a) Walk-over-weigh
    weights removing weights less than 0 and more than 1,000 kg. Panel b) Cross-validation
    agreement between WOW weights after removing weights greater than 1 standard deviation
    from the mean. Panel c) Cross-validation between WOW weights cleaned by removing
    weights greater than 1SD from the herd’s daily mean. Panel d) Cross-validation
    agreement after removing WOW collected weights greater than 1SD from each individual
    animal mean. Panel e) Cross-validation agreement after removing WOW weights greater
    than 1SD from each animal’s daily body weight. Panel f) Agreement after removing
    WOW weights outside the 95% confidence interval of a fitted cubic splines regression.
    Panel g) Cross-validation agreement after removing WOW weights greater than the
    standard error of a local polynomial regression line. Panel h) Cross-validation
    agreement after removing WOW weight observations with Robust Regression weights
    less than 0.985. 3.2.2. Smoothing functions Smoothing functions identified the
    most spurious weight points for removal, returned the lowest coefficient of variation,
    and increased the accuracy and precision of modeled weights compared to paired
    chute weights (Table 1). Local polynomial regression and smoothing splines retained
    4,331 and 4,644 clean observations from the original dataset, and returned coefficient
    of variation of 13.64 and 11.52, respectively. Compared to paired chute weights,
    smoothing functions were more accurate and precise, with CCC values of 0.88 and
    0.7, for polynomial regression and smoothing splines respectively. Precision also
    increased to 0.99 and 0.61 for polynomial regression and smoothing splines, respectively
    (Fig. 5, panels f - g and Table 1). Robust regression identified 1,868 wt records
    as outliers for removal, resulting in an average of 2 retained weight records
    per day over the entire study period. Robust regression returned a coefficient
    of variation of 12.48 while retaining 41 % of all WOW weight observations (Table
    1). Further, robust regression returned the highest accuracy (Cross-validation
    R2 = 0.96) and precision (Cross-validation intercept = −4.38 and slope = 1.03)
    among the methods used to sort the whole study dataset (Fig. 5, panel h). This
    is more accurate and precise than the smoothing functions, with a CCC value of
    0.97, and is demonstrated by the smallest difference between paired chute and
    WOW weights (Weight difference = 7.62 ± 0.86 kg, Table 1). 3.2.3. Real-time simulation
    spurious weight identification 3.2.3.1. Standard deviation filtering Simulation
    of real-time data management had minimal effect on the total number of spurious
    data points identified, accuracy, and precision of WOW weights compared to chute
    weights collected on the same day (Table 2)). Removing spurious weights based
    upon 1 SD from the average weight of either the entire herd or individuals yielded
    similar results, 5.67 and 5.44 points identified for analysis (Table 2 and Fig.
    6). In general, the percentage of total data points identified as spurious decreased
    throughout the study and with increasing number of recorded weights in the WOW
    database, while measured differences between paired static chute weights and WOW
    weights decreased (Fig. 6). Table 2. Summary of methods simulated in real-time
    to identify spurious weight records from the study (study length = 286 days) from
    grazed Brahman (*Bos taurus indicus*) steers grazed on improved pasture, and weighed
    using an in-pasture walk-over-weigh system located in front of the water source.
    2 Proportion retained, %b Visit frequency, n/dc frequency, SD n/dd CVe Weight
    difference, kgf R2g Intercepth Slopei CCCj Herd ± 1SD 5.67 1.62 1.08 65.11 −40.91
    0.82 340.75 0.22 0.50 Individual ± 1SD 5.44 1.56 0.91 96.90 −36.60 0.83 300.91
    0.31 0.53 Smoothing lag, 5d 32.55 2.44 1.55 15.16 19.03 0.61 54.82 0.92 0.73 Smoothing
    lag, 7d 32.17 2.39 1.53 14.38 13.98 0.70 22.90 0.98 0.80 Robust Regression, no
    filter 77.32 2.91 1.88 17.96 17.27 0.87 26.19 0.98 0.88 Robust Regression, filtered
    15.26 2.00 1.38 23.63 7.06 0.99 −7.01 1.03 0.99 aMethod used to identify spurious
    datapoints. b Proportion retained, %: Percent of total weights collected identified
    for retention. c Average records per day, n: Average number of weight records
    collected daily over the whole trial. d Variation in records per day, SD: Variation
    in recorded weight frequency per day measured over the course of the whole trial.
    e CV: Coefficient of variation between consequetively collected weights. f Weight
    difference, kg: Difference between paired static chute weights and WOW weight
    determined using paired t test. g R2: R-squared of linear models between static
    chute weights and WOW weights. h Intercept: Intercept of the linear model regression
    between paired WOW and chute weights. i Slope: Slope of linear model regression
    between paired WOW and chute weights. j CCC: Concordance Correlation Coefficient.
    Download : Download high-res image (311KB) Download : Download full-size image
    Fig. 6. Sequentially using data to simulate real-time observation of the data,
    a) Calculated R2 when using the entire dataset of weights to that point in time
    to calculate parameters used to identify spurious points, b) Body weight difference
    between static scale weight and paired walk-over-weigh (WOW) data from whole herd
    ± 1SD filtered data, c) Precision (R2) for real-time data filtered using individual
    mean ± 1SD, d) Mean difference between paired static chute weights and WOW recorded
    body weight filtered using individual mean ± 1SD. 3.2.3.2. Real-time smoothing
    functions We tested methods described by Wells et al. (2021) in an identical WOW
    weighing system. First, we used weights from a 5-day lag period to construct a
    ± 12% confidence interval, which we then used to determine the certainty of each
    data point (Wells et al., 2021). An average of 33% of total WOW weights were within
    the acceptable range for the 9 animals over the study period (Table 2. Cleaned
    weights demonstrated greater variation than other smoothing methods (CV = 15.16,
    and lower accuracy and precision (CCC = 0.73; R2 = 0.61) compared to other simulated
    real-time results (Table 2, Fig. 7, panel a). Next, we constructed an optimization
    curve to assess the correct lag time for removing spurious data points (Fig. 7,
    panel c). A 7-day lag time was determined to be the optimal period, and, on average,
    32% of available weight records were retained over the duration of the study.
    Analysis of paired WOW and chute weights indicated a smaller difference between
    chute and WOW weights (weight difference = 14.0 kg) and increased the accuracy
    and repeatability (CCC = 0.80, Table 2). This demonstrates the importance of optimizing
    the lag time, when one is used, to ensure the best fit possible is obtained. Download
    : Download high-res image (618KB) Download : Download full-size image Fig. 7.
    Optimization curve to identify the appropriate lag time to identify spurious datapoints
    for each animal throughout the duration of the trial. a) Linear model fit with
    data cleaned using a 5-day lag time. b) Linear model fit using a 7-day lag time.
    c) Number of data points removed at different lag times. d) Linear model precision
    (R2) at different lag times. Robust regression retained 77.32% of total WOW records,
    with animals averaging 2.91 ± 1.88 visits per day, with a lower coefficient of
    variation (CV = 17.96) compared to other real time methods. Robust regression
    cleaned weights demonstrated higher accuracy and precision (CCC = 0.88, R2 = 0.87,
    Slope = 0.98, Intercept = 26.19) compared to other methods (Table 2, Fig. 8, panels
    a and c). Next, we instituted a lag time to test the required temporal length
    required to successfully implement Robust Regression. Lag time was increased from
    a minimum of 2 to a maximum of 100 days prior to each trial day retained for analysis.
    Cross-validation metrics indicated a greater accuracy and precision as lag time
    increased, with minimal increases observed at greater than 20 days lag time (Fig.
    9, panel a). This is further demonstrated with the proportion of weights identified
    as either In Range or Outliers, with minimal changes exhibited after lag time
    exceeded 20 days (Fig. 8 panel b). Robust Regression can successfully filter spurious
    weights even at short temporal periods, and further exemplifies the importance
    of optimizing lag time. Download : Download high-res image (494KB) Download :
    Download full-size image Fig. 8. Real-time demonstration using robust regression
    to identify outliers. a) Demonstration of identifying outliers but not removed
    from future analysis. b) Demonstration of identifying and removing outliers in
    real-time. c) Cross-validation regression between chute collected weights and
    WOW values with spurious weights identified, but not removed from future analysis.
    d) Cross-validation regression between chute collected weights and WOW values
    with spurious weights identified and removed from future analysis. Download :
    Download high-res image (641KB) Download : Download full-size image Fig. 9. To
    find the appropriate lag period for real-time analysis using Robust Regression,
    lag times between 1 and 100-days were fitted to the data. Panel a) demonstrates
    the relative increase in the accuracy and precision between WOW and static chute
    weights using each lag time to identify spurious weights for removal, with an
    optimal threshold being approached for accuracy (Slope) and precision (R2) at
    a lag time of 11-days. Panel b) demonstrates the proportion of WOW recorded weights
    classified as either In Range (green) or Outliers (Red) at each tested lag-period.
    Both classes reached the maximum level at a lag period of 11-days, with no change
    in proportions observed at longer periods. (For interpretation of the references
    to colour in this figure legend, the reader is referred to the web version of
    this article.) 4. Discussion This study demonstrates the potential of using a
    WOW system to capture real-time body weight and mass change easily and efficiently
    in grazing steers. Removal of spurious data points increases the accuracy and
    precision of animal weights and is necessary for reliable information. WOW systems
    have been successfully utilized to predict calving dates in beef cattle (Aldridge
    et al., 2017), and track days to breeding in grazing dairy cattle (Alawneh et
    al., 2011). In our study, steers were recorded crossing the WOW system 3.7 times
    per day on average, which is significantly less than that found by Aldridge et
    al. (2017) in long bred beef cows. Removing data greater than 1 standard deviation
    from the average weight calculated over the trial period identified 1 spurious
    data point per day per animal in the present study, which resulted in an overall
    greater frequency of recorded scale visits compared to that shown in beef cows.
    We found strong agreement between static chute weight and measured WOW system
    weights, with R2 values ranging from 0.37 to 0.99. This is similar to agreements
    between chute weights and remotely recorded bodyweights using a partial weight
    recording system (MacNeil et al., 2021). Further, this was accomplished with minimal
    labor, and reduced animal stress (Cooke, 2014, MacNeil et al., 2021, Martin et
    al., 1967). Cleaning methods provided results consistent with similar research
    found in feeder calves (Wells et al., 2021), and dairy cows (Alawneh et al., 2011,
    Dickinson et al., 2013), demonstrating variability in data quality, and improvements
    after removing spurious body weight data. WOW systems have been successfully deployed
    in a wide diversity of livestock production scenarios, including calving cows
    in extensive rangelands (Aldridge et al., 2017), grazing dairy cows (Mardhati
    et al., 2021), and sheep (González-García et al., 2018b). However, it is important
    to consider practical hurdles which may inhibit producers from readily adopting
    this technology into their operations. These include both the skill required to
    assemble the automated weighing system from disparate parts, and the technical
    expertise required to download, process, and present the data in a fashion which
    is conducive to decision making processes. These hurdles will be overcome with
    the continued integration of sensor technology and integrated information systems
    (Tedeschi et al., 2021), which can incorporate these procedures into production
    of decision support tools for producers. 4.1. Whole trial The extended duration
    of the study over multiple seasons encompassing 286 days is a distinct advantage
    compared to 30 days using feeder cattle (Wells et al., 2021), and 100 days in
    grazing dairy cows (Alawneh et al., 2011). Aldridge et al. (2017) found individual,
    and group means ± 1 SD performed similarly when predicting calving events in extensively
    managed beef cattle. Similar results are presented in Table 1, and which identify
    a similar number of spurious weight points for removal. Further, the limited number
    of WOW weight observations influenced accuracy of means and SD calculated daily,
    which decreased the precision of the system, resulting in the greatest difference
    between static and WOW weights (Table 1), due to the removal of more weight observations
    that could occur naturally. A positive association between static chute weight
    and measured WOW system weights indicates strong agreement between chute weights
    and a newer novel system. This agreement provides a strong form of validation
    of the WOW system. Smoothing functions allow lines of best fit, accompanied by
    a confidence interval to be created around disharmonious data. After employing
    either smoothing splines or local polynomial regression, we found they identified
    the greatest number of spurious data points compared to all other methods, which
    seems implausible. Aldridge et al. (2017) found similar issues with poorly performing
    smoothing functions used to predict calving events. In both cases, this indicates
    smoothing functions removed weights indicative of realized rapid body mass changes.
    However, both smoothing functions produced growth curves and average daily gain
    predictions in close agreement with paired static chute weights as demonstrated
    by high precision and accuracy metrics from cross-validation. Another study removed
    a similar number of spurious weight data and agreement between body mass predicted
    using smoothing splines on WOW collected weights and static scale weights in grazing
    steers (González et al., 2014). This would suggest the extended study period likely
    allowed for smoothing daily fluctuations due to rumen fill, while predicting the
    true growth curve (Adams et al., 1987, Gregorini et al., 2008, Heitschmidt, 1982,
    Imaz et al., 2020). 4.2. Real time data management Real-time recording, and analysis
    of cattle weights has successfully predicted calving events, managed post calving
    weight gain and feeding and watering behavior can indicate morbidity in feeder
    steers (Alawneh et al., 2011, Aldridge et al., 2017, Kayser et al., 2019). In
    our study, real-time simulations provided similar results to the retrospective
    analysis presented previously (Table 2). The herd generated mean ± 1 SD retained
    70 % of the weight points, while providing the lowest SD and higher R2 and CCC
    values, 0.95 and 0.86, respectively. Individual means and SD provided similar
    results (Table 2). Wells et al. (2021) employed a 5-day lag time to calculate
    an individual animal’s average weight, and then identified all weights falling
    outside 12% confidence interval for removal. Weights collected within 15 min on
    both the WOW and Vyttele Sense (Vytelle LLC, Hermiston, OR, USA) weight systems
    presented a 0.99 R2, with average weight differences of 5–6 kg expected (Wells
    et al., 2021). However, in our study, using a similar strategy resulted in lower
    agreement between static and WOW weights, with R2 and CCC of 0.45 and 0.60, respectively
    (Table 2). We conducted a sensitivity analysis to test the effect of increasing
    lag-time, and found increasing the number of previous days of data included in
    the analysis from 5 to 7 increased the precision and accuracy of spurious weight
    removal from WOW weight data (Fig. 7). A lag time greater than 7 days demonstrated
    a plateau in the number of spurious weights removed and increase in agreement
    with static chute weights as demonstrated by cross-validation (Fig. 7, panel C).
    5. Conclusion The current study demonstrates the functionality of a WOW system
    to efficiently collected stress free animal weights at a much greater frequency
    than that capable through traditional means. Further, we demonstrated the precision
    and accuracy of the system when compared to traditional static chute weights in
    both a whole study and real-time application, with robust regression providing
    the best results overall. Employment of this system can enable livestock managers
    to easily identify animals with sickness, injury, or other disorder, while improving
    management of forage and supplementation, and aid in genetic selection. Incorporation
    of this technology and subsequent data cleaning processes will promote technology
    adoption by lowering the technological skill levels required for entry. This promises
    to provide a cost-effective means of quickly and efficiently capturing high frequency
    animal weights stands to greatly benefit livestock producers in all environments
    and management systems. CRediT authorship contribution statement Ira L. Parsons:
    Funding acquisition, Project administration, Resources, Supervision, Writing –
    review & editing. Durham A. Norman: Funding acquisition, Project administration,
    Resources, Supervision, Writing – review & editing. Brandi B. Karisch: Funding
    acquisition, Project administration, Resources, Supervision, Writing – review
    & editing. Stephen L. Webb: Funding acquisition, Project administration, Resources,
    Supervision, Writing – review & editing. Amanda E. Stone: Funding acquisition,
    Project administration, Resources, Supervision, Writing – review & editing. Mike
    D. Proctor: Funding acquisition, Project administration, Resources, Supervision,
    Writing – review & editing. Garrett M. Street: Funding acquisition, Project administration,
    Resources, Supervision, Writing – review & editing. Declaration of Competing Interest
    The authors declare the following financial interests/personal relationships which
    may be considered as potential competing interests: The authors declare no conflict
    or competing interests. This work was supported by Thinking Like a Mountain to
    Improve Animal Production Systems Ecology, Energy Budgets, and Mechanistic Models,
    grant no. 2018-67016-27481/project accession no.1014926 from the USDA National
    Institute of Food and Agriculture, Mississippi Agriculture and Forestry Experiment
    Station (MAFES), and Noble Research Institute, LLC. Acknowledgements This work
    was supported by Thinking Like a Mountain to Improve Animal Production Systems
    Ecology, Energy Budgets, and Mechanistic Models, grant no. 2018-67016-27481/project
    accession no. 1014926 from the USDA National Institute of Food and Agriculture,
    Mississippi Agriculture and Experiment Station (MAFES), and the Noble Research
    Institute, LLC. The authors would like to thank Ronald Trett and Ryan Hicks of
    the Noble Research Institute for their invaluable time and effort put into this
    project and to the QuEST lab group for reading this manuscript. Thanks to Dr.
    Luis Tedeschi of Texas A&M for his recommendation to implement Robust Regression.
    Appendix A. Supplementary data The following are the Supplementary data to this
    article: Download : Download Word document (2MB) Supplementary data 1. Data availability
    Data will be made available on request. References Adams et al., 1987 D.C. Adams,
    P.O. Currie, B.W. Knapp, T. Mauney, D. Richardson An automated range-animal data
    acquisition system J. Range Manag., 40 (1987), p. 256, 10.2307/3899091 Google
    Scholar Alawneh et al., 2011 J.I. Alawneh, M.A. Stevenson, N.B. Williamson, N.
    Lopez-Villalobos, T. Otley Automatic recording of daily walkover liveweight of
    dairy cattle at pasture in the first 100 days in milk J. Dairy Sci., 94 (2011),
    pp. 4431-4440, 10.3168/jds.2010-4002 View PDFView articleView in ScopusGoogle
    Scholar Aldridge et al., 2017 M.N. Aldridge, S.J. Lee, J.D. Taylor, G.I. Popplewell,
    F.R. Job, W.S. Pitchford The use of walk over weigh to predict calving date in
    extensively managed beef herds Anim. Prod. Sci., 57 (2017), p. 583, 10.1071/AN15172
    View in ScopusGoogle Scholar Brown et al., 2014 D.J. Brown, D.B. Savage, G.N.
    Hinch Repeatability and frequency of in-paddock sheep walk-over weights: Implications
    for individual animal management Anim. Prod. Sci., 54 (2014), p. 207, 10.1071/AN12311
    View in ScopusGoogle Scholar Brown et al., 2015 D.J. Brown, D.B. Savage, G.N.
    Hinch, S. Hatcher Monitoring liveweight in sheep is a valuable management strategy:
    A review of available technologies Anim. Prod. Sci., 55 (2015), p. 427, 10.1071/AN13274
    View in ScopusGoogle Scholar Charmley et al., 2006 E. Charmley, T.L. Gowan, J.L.
    Duynisveld Development of a remote method for the recording of cattle weights
    under field conditions Aust. J. Exp. Agric., 46 (2006), p. 831, 10.1071/EA05314
    View in ScopusGoogle Scholar Cooke, 2014 R.F. Cooke Growth, health, and reproductive
    responses in bos taurus and bos indicus cattle J. Anim. Sci., 92 (2014), pp. 5325-5333,
    10.2527/jas2014-8017 View in ScopusGoogle Scholar Currie et al., 1989 P.O. Currie,
    J.D. Volesky, D.C. Adams, B.W. Knapp Growth patterns of yearling steers determined
    from daily live weights J. Range Manag., 42 (1989), pp. 393-396, 10.2307/3899546
    View in ScopusGoogle Scholar Dickinson et al., 2013 R.A. Dickinson, J.M. Morton,
    D.S. Beggs, G.A. Anderson, M.F. Pyman, P.D. Mansell, C.B. Blackwood An automated
    walk-over weighing system as a tool for measuring liveweight change in lactating
    dairy cows J. Dairy Sci., 96 (2013), pp. 4477-4486, 10.3168/jds.2012-6522 View
    PDFView articleView in ScopusGoogle Scholar Fox and Fox, 2016 J. Fox, J. Fox Applied
    regression analysis and generalized linear models (third ed.), SAGE, Los Angeles
    (2016) Google Scholar González et al., 2014 L.A. González, G. Bishop-Hurley, D.
    Henry, E. Charmley Wireless sensor networks to study, monitor and manage cattle
    in grazing systems Anim. Prod. Sci., 54 (2014), p. 1687, 10.1071/AN14368 View
    in ScopusGoogle Scholar González-García et al., 2018a E. González-García, M. Alhamada,
    J. Pradel, S. Douls, S. Parisot, F. Bocquier, J.B. Menassol, I. Llach, L.A. González
    A mobile and automated walk-over-weighing system for a close and remote monitoring
    of liveweight in sheep Comput. Electron. Agric., 153 (2018), pp. 226-238, 10.1016/j.compag.2018.08.022
    View PDFView articleView in ScopusGoogle Scholar González-García et al., 2018b
    E. González-García, P.D.O. Golini, P. Hassoun, F. Bocquier, D. Hazard, L.A. González,
    A.B. Ingham, G.J. Bishop-Hurley, P.L. Greenwood An assessment of walk-over-weighing
    to estimate short-term individual forage intake in sheep Animal, 12 (2018), pp.
    1174-1181, 10.1017/S1751731117002609 View PDFView articleView in ScopusGoogle
    Scholar González-García et al., 2021 E. González-García, M. Alhamada, H. Nascimento,
    D. Portes, G. Bonnafe, C. Allain, I. Llach, P. Hassoun, J.M. Gautier, S. Parisot
    Measuring liveweight changes in lactating dairy ewes with an automated walk-over-weighing
    system J. Dairy Sci., 104 (2021), pp. 5675-5688, 10.3168/jds.2020-19075 View PDFView
    articleView in ScopusGoogle Scholar Gregorini et al., 2008 P. Gregorini, S.A.
    Gunter, P.A. Beck, K.J. Soder, S. Tamminga REVIEW: The interaction of diurnal
    grazing pattern, ruminal metabolism, nutrient supply, and management in cattle
    The Professional Animal Scientist, 24 (2008), pp. 308-318 10.15232/S1080-7446(15)30861-5
    View PDFView articleView in ScopusGoogle Scholar Harrell, 2001 F.E. Harrell Chapter
    5: Resampling, validating, describing, and simplifying the model Regression Modeling
    Strategies with Applications to Linear Models, Logisitic Regression, and Survival
    Analysis, Springer, New York (2001), pp. 87-101 CrossRefGoogle Scholar Heitschmidt,
    1982 R.K. Heitschmidt Diurnal variation in weight and rates of shrink of range
    cows and calves J. Range Manag., 35 (1982), p. 717, 10.2307/3898247 Google Scholar
    Imaz et al., 2020 J.A. Imaz, S. Garcia, L.A. González Using automated in-paddock
    weighing to evaluate the impact of intervals between liveweight measures on growth
    rate calculations in grazing beef cattle Comput. Electron. Agric., 178 (2020),
    Article 105729, 10.1016/j.compag.2020.105729 View PDFView articleView in ScopusGoogle
    Scholar Kayser et al., 2019 W.C. Kayser, G.E. Carstens, K.S. Jackson, W.E. Pinchak,
    A. Banerjee, Y. Fu Evaluation of statistical process control procedures to monitor
    feeding behavior patterns and detect onset of bovine respiratory disease in growing
    bulls J. Anim. Sci., 97 (2019), pp. 1158-1170, 10.1093/jas/sky486 View in ScopusGoogle
    Scholar Lin, 1989 L.I. Lin A concordance correlation coefficient to evaluate reproducibility
    Biomatrics, 45 (1989), pp. 255-268 CrossRefGoogle Scholar MacNeil et al., 2021
    MacNeil, M.D., Berry, D.P., Clark, S.A., Crowley, J.J., Scholtz, M.M., 2021. Evaluation
    of partial body weight for predicting body weight and average daily gain in growing
    beef cattle. Translational Animal Science 5, txab126. https://doi.org/10.1093/tas/txab126.
    Google Scholar Mardhati et al., 2021 M. Mardhati, L.A. González, P.C. Thomson,
    C.E.F. Clark, S.C. García Short-term liveweight changes of dairy cows measured
    by stationary and walk-over weighing scales J. Dairy Sci., 104 (2021), pp. 8202-8213,
    10.3168/jds.2020-19912 View PDFView articleView in ScopusGoogle Scholar Martin
    et al., 1967 S.C. Martin, K.K. Barnes, L. Bashford A step toward automatic weighing
    of range cattle J. Range Manag., 20 (1967), p. 4, 10.2307/3895952 Google Scholar
    NASEM, 2016 NASEM, 2016. Nutrient requirements of beef cattle. https://doi.org/10.17226/19014.
    Google Scholar Parsons et al., 2020 I.L. Parsons, J.R. Johnson, W.C. Kayser, L.O.
    Tedeschi, G.E. Carstens Characterization of feeding behavior traits in steers
    with divergent residual feed intake consuming a high-concentrate diet J. Anim.
    Sci., 98 (2020), pp. 1-9, 10.1093/jas/skaa189 View in ScopusGoogle Scholar R Core
    Team, 2021 R Core Team R: A language and environment for statistical computing
    R Foundation for Statistical Computing, Vienna, Austria (2021) Google Scholar
    Reuter and Moffet, 2016 R.R. Reuter, C.A. Moffet Invited review: Designing a grazing
    experiment that can reliably detect meaningful differences Prof. Anim. Sci., 32
    (2016), pp. 19-30 10.15232/pas.2015-01424 View PDFView articleCrossRefView in
    ScopusGoogle Scholar Signorell, 2021 Signorell, A., 2021. Tools for descriptive
    statistics. Google Scholar Tedeschi, 2006 L.O. Tedeschi Assessment of the adequacy
    of mathematical models Agr. Syst., 89 (2006), pp. 225-247, 10.1016/j.agsy.2005.11.004
    View PDFView articleView in ScopusGoogle Scholar Tedeschi et al., 2021 L.O. Tedeschi,
    P.L. Greenwood, I. Halachmi Advancements in sensor technology and decision support
    intelligent tools to assist smart livestock farming J. Anim. Sci., 99 (2021),
    p. skab038, 10.1093/jas/skab038 View in ScopusGoogle Scholar Van Soest, 1994 P.J.
    Van Soest Nutritional ecology of the ruminant Cornell University Press (1994)
    Google Scholar Venables et al., 2002 W.N. Venables, B.D. Ripley, W.N. Venables
    Modern applied statistics with s (4th ed.), Statistics and computing, Springer,
    New York (2002) Google Scholar Wells et al., 2021 R.S. Wells, S.M. Interrante,
    S.S. Sakkuma, R.S. Walker, T.J. Butler Accuracy of the VYTELLE SENSE in-pen weighing
    positions Appl. Animal Sci., 37 (2021), pp. 626-634 10.15232/aas.2021-02183 View
    PDFView articleCrossRefView in ScopusGoogle Scholar Cited by (1) Improving Dry
    Matter Intake Estimates Using Precision Body Weight on Cattle Grazed on Extensive
    Rangelands 2023, Animals View Abstract © 2023 Elsevier B.V. All rights reserved.
    Recommended articles ECG augmented pulse oximetry in Atlantic salmon (Salmo salar)—A
    pilot study Computers and Electronics in Agriculture, Volume 212, 2023, Article
    108081 E. Svendsen, …, J.A. Alfredsen View PDF Navigating route planning for multiple
    vehicles in multifield agriculture with a fast hybrid algorithm Computers and
    Electronics in Agriculture, Volume 212, 2023, Article 108021 Amalia Utamima, Torsten
    Reiners View PDF ODL Net: Object detection and location network for small pears
    around the thinning period Computers and Electronics in Agriculture, Volume 212,
    2023, Article 108115 Yuqi Lu, …, Weikuan Jia View PDF Show 3 more articles Article
    Metrics Citations Citation Indexes: 1 Captures Readers: 9 View details About ScienceDirect
    Remote access Shopping cart Advertise Contact and support Terms and conditions
    Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices
    All content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors.
    All rights are reserved, including those for text and data mining, AI training,
    and similar technologies. For all open access content, the Creative Commons licensing
    terms apply."'
  inline_citation: '>'
  journal: Computers and Electronics in Agriculture
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Automated walk-over-weigh system to track daily body mass and growth in grazing
    steers
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'

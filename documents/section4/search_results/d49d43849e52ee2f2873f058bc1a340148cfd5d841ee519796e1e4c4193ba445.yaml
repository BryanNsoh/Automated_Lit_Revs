- analysis: '>'
  authors:
  - Chakoory O.
  - Barra V.
  - Rochette E.
  - Blanchon L.
  - Sapin V.
  - Merlin E.
  - Pons M.
  - Gallot D.
  - Comtet-Marre S.
  - Peyret P.
  citation_count: '0'
  description: In recent decades, preterm birth (PTB) has become a significant research
    focus in the healthcare field, as it is a leading cause of neonatal mortality
    worldwide. Using five independent study cohorts including 1290 vaginal samples
    from 561 pregnant women who delivered at term (n = 1029) or prematurely (n = 261),
    we analysed vaginal metagenomics data for precise microbiome structure characterization.
    Then, a deep neural network (DNN) was trained to predict term birth (TB) and PTB
    with an accuracy of 84.10% and an area under the receiver operating characteristic
    curve (AUROC) of 0.875 ± 0.11. During a benchmarking process, we demonstrated
    that our DL model outperformed seven currently used machine learning algorithms.
    Finally, our results indicate that overall diversity of the vaginal microbiota
    should be taken in account to predict PTB and not specific species. This artificial-intelligence
    based strategy should be highly helpful for clinicians in predicting preterm birth
    risk, allowing personalized assistance to address various health issues. DeepMPTB
    is open source and free for academic use. It is licensed under a GNU Affero General
    Public License 3.0 and is available at https://deepmptb.streamlit.app/. Source
    code is available at https://github.com/oschakoory/DeepMPTB and can be easily
    installed using Docker (https://www.docker.com/).
  doi: 10.1186/s40364-024-00557-1
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Search Explore
    journals Get published About BMC Login Biomarker Research Home About Articles
    Submission Guidelines Submit manuscript Correspondence Open access Published:
    14 February 2024 DeepMPTB: a vaginal microbiome-based deep neural network as artificial
    intelligence strategy for efficient preterm birth prediction Oshma Chakoory, Vincent
    Barra, Emmanuelle Rochette, Loïc Blanchon, Vincent Sapin, Etienne Merlin, Maguelonne
    Pons, Denis Gallot, Sophie Comtet-Marre & Pierre Peyret  Biomarker Research  12,
    Article number: 25 (2024) Cite this article 736 Accesses 8 Altmetric Metrics Abstract
    In recent decades, preterm birth (PTB) has become a significant research focus
    in the healthcare field, as it is a leading cause of neonatal mortality worldwide.
    Using five independent study cohorts including 1290 vaginal samples from 561 pregnant
    women who delivered at term (n = 1029) or prematurely (n = 261), we analysed vaginal
    metagenomics data for precise microbiome structure characterization. Then, a deep
    neural network (DNN) was trained to predict term birth (TB) and PTB with an accuracy
    of 84.10% and an area under the receiver operating characteristic curve (AUROC)
    of 0.875 ± 0.11. During a benchmarking process, we demonstrated that our DL model
    outperformed seven currently used machine learning algorithms. Finally, our results
    indicate that overall diversity of the vaginal microbiota should be taken in account
    to predict PTB and not specific species. This artificial-intelligence based strategy
    should be highly helpful for clinicians in predicting preterm birth risk, allowing
    personalized assistance to address various health issues. DeepMPTB is open source
    and free for academic use. It is licensed under a GNU Affero General Public License
    3.0 and is available at https://deepmptb.streamlit.app/. Source code is available
    at https://github.com/oschakoory/DeepMPTB and can be easily installed using Docker
    (https://www.docker.com/). To the editor Preterm birth (PTB) is a leading cause
    of neonatal mortality worldwide and the second most common cause of child deaths
    under the age of five years [1]. Additionally, premature neonates are at risk
    of numerous health complications, including neurological damage in early childhood
    but also respiratory and gastrointestinal disorders. Existing diagnostic methods
    involve the collection of maternal obstetric history and cervical measurements
    via transvaginal ultrasound imaging conducted in the first and second trimesters
    of pregnancy. However, diagnoses are often inaccurate, as physician experience
    varies and the processes can be time-consuming. Existing literature suggests that
    vaginal microbial communities could be involved in the pathophysiology of PTB
    delivery [2]. This microbiome is extremely important to the host tissue, as it
    maintains an acidic environment, inhibits the growth of pathogenic bacteria, and
    modulates inflammation by cross-kingdom signalling. Despite the efforts of longitudinal
    studies and meta-analyses, no clear distinct microbial signatures have been characterized
    to identify the risk of PTB [3]. We propose DeepMPTB, a vaginal microbiota-based
    deep neural network (DNN) for efficient PTB prediction (Fig. 1; Supplementary
    Material). Fig. 1 Overview of model training and phenotype prediction. For model
    training (step 1), the shotgun metagenomics sequences of 1290 vaginal samples
    from 561 pregnant women were retrieved from public databases in the form of fastq
    files (Table S1) [3,4,5,6,7]. The RiboTaxa pipeline [8] was used to obtain taxonomic
    profiles from the metagenomics datasets using the SILVA SSU 138.1 NR99 database.
    Vaginal microbiota profiles differed greatly (Welch’s t-test, p < 0.05) within
    individual cohorts, illustrating the heterogeneity of the vaginal population.
    No significant difference in the α-diversity measure was found between the TB
    or PTB groups. All the output taxonomy tables were grouped into a single table
    containing all the bacterial and eukaryotic species-level profiles of 1290 samples.
    In addition, the clinical data of each sample were considered. The normalized
    species abundances (Fig. S1) and vectorized clinical data were used to train and
    optimize the neural network. Features contributing to explaining the model were
    extracted and visualized using SHAP. To predict the phenotype based on new unknown
    vaginal microbiota samples (step 2), a list of features with important biomarkers
    contributing to the prediction was output Full size image A total of 234 786 trainable
    parameters were optimized and the optimal hyperparameter combination for the final
    model (Fig. 2A, Fig. S2), included 416 units (neurons) in the 1st hidden layer
    and a total of 3 hidden layers, with the number of units in each layer set to
    half that in the preceding layer (Fig. S3). To deal with class imbalance (1029
    TB and 261 PTB) in our datasets, we evaluated model performance using multiple
    metrics (Supplementary Material). The 20 most important features contributing
    to these results were also determined by the SHAP explainer (Fig. 2B). Interestingly,
    low-abundance species were also observed to contribute to PTB classification.
    Moreover, these contributing features included clinical and demographic data.
    Fig. 2 Performance of DeepMPTB based on the 20% test set (239 samples). A During
    model evaluation, the three metadata features (age, ethnicity and trimester of
    sample collection) were associated with each sample. For each sample, the true
    and predictive phenotypes were compared to evaluate the performance of DeepMPTB.
    B A summary plot for the SHAP values was generated to understand the contributions
    of the first 20 features in this performance analysis. Features related to clinical/demographic
    metadata are indicated by an asterisk. Each dot represents a sample. Negative
    and positive SHAP values are associated to TB and PTB prediction, respectively.
    Low and high SHAP values are shown in blue and red, respectively. TB: Term birth;
    PTB: Preterm birth Full size image The performance of DeepMPTB was compared with
    that of seven state-of-the-art classification algorithms, namely, the decision
    tree (DT), K-nearest neighbour (KNN), random forest (RF), naïve Bayes (NB), extreme
    gradient boosting (XGBoost), logistic regression (LR), and support vector machine
    (SVM) models, which were trained and optimized based on the same input data as
    the DNN (Supplementary Material). DeepMPTB outperformed all other prediction models,
    with an AUROC score of 0.877 ± 0.11 (p < 0.05 for ANOVA test) and an accuracy
    of 84.10% (Table S2). The model trained based on the third trimester data displayed
    the highest accuracy of 88%, suggesting that samples collected during the third
    trimester may lead to better prediction rates, although the models trained based
    on first and second trimester data obtained also very good accuracies of 71% and
    83%, respectively (Fig. S4). We also argue that input data quality has a significant
    impact on model performance (Fig. S5). We compared performance of three DNN trained
    using species coupled to their relative abundances determined with RiboTaxa [8]
    or two other popular metagenomics classifiers (p < 0.05 for ANOVA test) using
    only the biggest cohort (Supplementary Material). The DNN trained based on input
    data from RiboTaxa [8] showed the best performance, with an AUROC score of 0.898 ± 0.09.
    The DNN trained based on DeepMicrobes [9] and MetaPhlAn3 [10] data showed an AUROC
    score of 0.838 ± 0.14 and 0.795 ± 0.08, respectively. When only microbiome data
    obtained with RiboTaxa (without metadata, keeping phenotype) were used for model
    training, the AUROC value decreased to 0.831 ± 0.12 (p > 0.05 for Mann‒Whitney
    U test). To show the generality of this model, we used a completely new set of
    694 vaginal metagenomic data (430 TB and 264 PTB cases) from Baud et al. [11].
    Overall, the optimized DNN successfully identified 80% of TB samples and 66% of
    the PTB samples. Importantly, phenotype prediction, especially in the case of
    PTB, is not determined by the presence of the same species or group of species
    (Fig. S6). In conclusion, the present study presents a cutting-edge deep learning
    model to efficiently predict TB and PTB using vaginal microbiome data of pregnant
    women combined to clinical data. This new model based on data from 5 cohorts outperforms
    previously published machine learning-based model for PTB prediction [11, 12].
    Continued accumulation of high-quality microbiome data and complete phenotypic
    data in perfectly controlled cohorts will certainly improve the individual phenotype
    prediction performance of deep learning models. Furthermore, including virome
    information, known to drive microbiota dynamics, would help to reach better performances.
    Finally, DNN enables to distinguish complex interindividual microbial interactions
    related to term and preterm deliveries, to highlight in-depth microorganisms potentially
    associated to phenotype. Interestingly we observed that different microbial profiles
    led to the same phenotype. This efficient TB and PTB predictive diagnosis should
    be highly helpful for clinicians in a personalized medicine context. Data availability
    All raw sequencing data and metadata analysed during this study were obtained
    from these published articles: Feehily et al. [3]. under the BioProject PRJEB34536
    (61.49 Gb), Tortelli et al. [7] under the BioProject PRJNA639592 (8.52 Gb), and
    Goltsman et al. [5]. under the BioProject PRJNA288562 (115.53 Gb). Raw data (2.77
    Tb) and metadata for Fettweis et al. [4]. cohort were received from the authors
    of the study following data access approval from National Institute of Health
    (NIH). Raw sequencing for the Pace et al. [6] cohort were available under the
    BioProject PRJNA451212 (15.92 Gb) and the metadata were received from the authors
    of the study. Supplementary material describes methods and complementary results.
    Abbreviations AUC: Area-under-the-curve AUROC: Area under the receiver operating
    characteristic curve DL: deep learning DNN: Deep neural network PTB: Preterm birth
    TB: Term birth References Liu L, et al. Global, regional, and national causes
    of child mortality in 2000-13, with projections to inform post-2015 priorities:
    an updated systematic analysis. Lancet. 2015;385(9966):430–40. Article   PubMed   Google
    Scholar   Menon R, Williams SM, Lamont RF. Research to achieve a reduction in
    the global rate of preterm birth needs attention: Preface to the special issue
    by the preterm Birth International Collaborative (PREBIC). Placenta. 2019;79:1–2.
    Article   PubMed   Google Scholar   Feehily C, et al. Shotgun sequencing of the
    vaginal microbiome reveals both a species and functional potential signature of
    preterm birth. NPJ Biofilms Microbiomes. 2020;6(1):50. Article   CAS   PubMed   PubMed
    Central   Google Scholar   Fettweis JM, et al. The vaginal microbiome and preterm
    birth. Nat Med. 2019;25(6):1012–21. Article   CAS   PubMed   PubMed Central   Google
    Scholar   Goltsman DSA, et al. Metagenomic analysis with strain-level resolution
    reveals fine-scale variation in the human pregnancy microbiome. Genome Res. 2018;28(10):1467–80.
    Article   CAS   PubMed   PubMed Central   Google Scholar   Pace RM, et al. Complex
    species and strain ecology of the vaginal microbiome from pregnancy to postpartum
    and association with preterm birth. Med. 2021;2(9):1027–49. Article   CAS   PubMed   Google
    Scholar   Tortelli BA, Lewis AL, Fay JC. The structure and diversity of strain-level
    variation in vaginal bacteria. Microb Genom, 2021. 7(3). Chakoory O, Comtet-Marre
    S, Peyret P. RiboTaxa: combined approaches for rRNA genes taxonomic resolution
    down to the species level from metagenomics data revealing novelties. NAR Genom
    Bioinform. 2022;4(3):lqac070. Article   PubMed   PubMed Central   Google Scholar   Liang
    Q, et al. DeepMicrobes: taxonomic classification for metagenomics with deep learning.
    NAR Genom Bioinform. 2020;2(1):lqaa009. Article   PubMed   PubMed Central   Google
    Scholar   Beghini F et al. Integrating taxonomic, functional, and strain-level
    profiling of diverse microbial communities with bioBakery 3. Elife, 2021. 10.
    Baud A, et al. Microbial diversity in the vaginal microbiota and its link to pregnancy
    outcomes. Sci Rep. 2023;13(1):9061. Article   CAS   PubMed   PubMed Central   ADS   Google
    Scholar   Park S, et al. Predicting preterm birth through vaginal microbiota,
    cervical length, and WBC using a machine learning model. Front Microbiol. 2022;13:912853.
    Article   PubMed   PubMed Central   Google Scholar   Download references Acknowledgements
    We are grateful to the Mésocentre Clermont Auvergne University and AuBi platform
    for providing help and computing and storage resources. Computations were performed
    on the supercomputer facilities of the Mésocentre Clermont Auvergne University.
    Funding O.C. and S.C-M. were supported, respectively by ANR Intelligence Artificielle
    (MIA: Artificial Intelligence for clerMont) co-financed by FEDER funds and Clermont
    Auvergne Innovation (CAI), respectively. Author information Authors and Affiliations
    Université Clermont Auvergne, INRAE, MEDIS, F-63000, Clermont-Ferrand, France
    Oshma Chakoory, Sophie Comtet-Marre & Pierre Peyret Université Clermont Auvergne,
    CNRS, Mines de Saint-Étienne, Clermont-Auvergne-INP, LIMOS, Clermont-Ferrand,
    France Vincent Barra Department of Pediatrics, CRECHE Unit, CHU Clermont-Ferrand,
    Inserm CIC 1405, F-63000, Clermont-Ferrand, France Emmanuelle Rochette, Etienne
    Merlin & Maguelonne Pons Team “Translational approach to epithelial injury and
    repair”, Université Clermont Auvergne, CNRS, Inserm, iGReD, F-63000, Clermont-Ferrand,
    France Loïc Blanchon, Vincent Sapin & Denis Gallot Biochemistry and Molecular
    Genetics Department, CHU Clermont-Ferrand, 63000, Clermont- Ferrand, France Vincent
    Sapin Department of Obstetrics, CHU Clermont-Ferrand, F-63000, Clermont- Ferrand,
    France Denis Gallot Contributions SC-M, PP, VB, ER, LB, VS, EM, DG and MP designed
    the study. OC processed the data, prepared the figures and wrote the draft manuscript.
    OC, SC-M and PP analysed and interpreted data. VB, SC-M and PP revised draft the
    manuscript. The authors read and approved the final manuscript. Corresponding
    authors Correspondence to Sophie Comtet-Marre or Pierre Peyret. Ethics declarations
    Competing interests The authors declare that they have no conflicts of interests.
    Consent for publication Not applicable. Ethics approval and consent to participate
    Not applicable. Additional information Publisher’s Note Springer Nature remains
    neutral with regard to jurisdictional claims in published maps and institutional
    affiliations. Electronic supplementary material Below is the link to the electronic
    supplementary material. Supplementary Material 1 Rights and permissions Open Access
    This article is licensed under a Creative Commons Attribution 4.0 International
    License, which permits use, sharing, adaptation, distribution and reproduction
    in any medium or format, as long as you give appropriate credit to the original
    author(s) and the source, provide a link to the Creative Commons licence, and
    indicate if changes were made. The images or other third party material in this
    article are included in the article’s Creative Commons licence, unless indicated
    otherwise in a credit line to the material. If material is not included in the
    article’s Creative Commons licence and your intended use is not permitted by statutory
    regulation or exceeds the permitted use, you will need to obtain permission directly
    from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.
    The Creative Commons Public Domain Dedication waiver (http://creativecommons.org/publicdomain/zero/1.0/)
    applies to the data made available in this article, unless otherwise stated in
    a credit line to the data. Reprints and permissions About this article Cite this
    article Chakoory, O., Barra, V., Rochette, E. et al. DeepMPTB: a vaginal microbiome-based
    deep neural network as artificial intelligence strategy for efficient preterm
    birth prediction. Biomark Res 12, 25 (2024). https://doi.org/10.1186/s40364-024-00557-1
    Download citation Received 14 November 2023 Accepted 02 January 2024 Published
    14 February 2024 DOI https://doi.org/10.1186/s40364-024-00557-1 Share this article
    Anyone you share the following link with will be able to read this content: Get
    shareable link Provided by the Springer Nature SharedIt content-sharing initiative
    Keywords Preterm birth Vaginal microbiome Predictive diagnosis Deep neural network
    Artificial intelligence Machine learning Pregnancy Microbial signature Clinical
    data Phenotype prediction Model explainability. Download PDF Sections Figures
    References Abstract To the editor Data availability Abbreviations References Acknowledgements
    Funding Author information Ethics declarations Additional information Electronic
    supplementary material Rights and permissions About this article Advertisement
    Biomarker Research ISSN: 2050-7771 Contact us General enquiries: journalsubmissions@springernature.com
    Read more on our blogs Receive BMC newsletters Manage article alerts Language
    editing for authors Scientific editing for authors Policies Accessibility Press
    center Support and Contact Leave feedback Careers Follow BMC By using this website,
    you agree to our Terms and Conditions, Your US state privacy rights, Privacy statement
    and Cookies policy. Your privacy choices/Manage cookies we use in the preference
    centre. © 2024 BioMed Central Ltd unless otherwise stated. Part of Springer Nature."'
  inline_citation: '>'
  journal: Biomarker Research
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'DeepMPTB: a vaginal microbiome-based deep neural network as artificial intelligence
    strategy for efficient preterm birth prediction'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Yin K.
  - Guo H.
  - Yang W.
  citation_count: '0'
  description: The management and decision-making of the shipping market rely heavily
    on the accurate forecasting of the China Containerized Freight Index (CCFI); however,
    this is still a challenging task. Furthermore, CCFI is influenced by many factors
    and exhibits complex nonlinear characteristics, which may cause the evolution
    of its distributions over time, i.e., the concept drift issue. However, previous
    studies mainly focused on the simple application of single data preprocessing
    and machine learning, while ignoring the significance of real-time and multi-step
    forecasting, which may not effectively deal with the concept drift issue and result
    in unsatisfactory results. Additionally, some studies disregarded the data leakage
    problem caused by the one-time decomposition of all datasets. Therefore, a novel
    real-time multi-step forecasting system with multiple rolling decomposition strategy
    based on streaming data is designed. It includes data preprocessing, forecasting,
    and evaluation modules. A three-stage data preprocessing strategy is proposed
    in the first module to overcome the single preprocessing defect. It can eliminate
    the adverse effects of outliers, extract main features, and reduce system complexity.
    Moreover, the forecasting and evaluation modules are designed to enhance the forecasting
    performance and verify the system's validity. Considering the obvious concept
    drift problem of CCFI during the Coronavirus Disease 2019 (COVID-19) epidemic,
    datasets from the COVID-19 epidemic are selected for experimental verification
    to verify the system's ability to solve this problem. Empirical studies demonstrate
    the superiority of the developed system over the compared models in terms of universality
    and robustness. Therefore, the proposed system is an effective prediction method
    for the containerized freight market in the post epidemic period and an alternative
    for forecasting other streaming data with the concept drift issue.
  doi: 10.1016/j.eswa.2024.123141
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords 1. Introduction 2. Literature review 3. Framework
    of the proposed forecasting system 4. Detailed process of the proposed forecasting
    system 5. Experiments 6. Discussion 7. Conclusion Conflict of interest CRediT
    authorship contribution statement Declaration of competing interest Acknowledgments
    Data availability References Show full outline Figures (4) Tables (13) Table 1
    Table 2 Table 3 Table 4 Table 5 Table 6 Show all tables Expert Systems with Applications
    Volume 246, 15 July 2024, 123141 A novel real-time multi-step forecasting system
    with a three-stage data preprocessing strategy for containerized freight market
    Author links open overlay panel Kedong Yin a b, Hongbo Guo a, Wendong Yang a b
    1 Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.eswa.2024.123141
    Get rights and content Highlights • A real-time multi-step forecasting system
    is developed in container freight market forecasting. • A data preprocessing strategy
    with multiple rolling decomposition is proposed for streaming data. • Accurate
    and stable forecasting results are provided under the impact of COVID-19. • The
    scientific experiments and comprehensive evaluation module are established. •
    The developed real-time system is validated well in different datasets. Abstract
    The management and decision-making of the shipping market rely heavily on the
    accurate forecasting of the China Containerized Freight Index (CCFI); however,
    this is still a challenging task. Furthermore, CCFI is influenced by many factors
    and exhibits complex nonlinear characteristics, which may cause the evolution
    of its distributions over time, i.e., the concept drift issue. However, previous
    studies mainly focused on the simple application of single data preprocessing
    and machine learning, while ignoring the significance of real-time and multi-step
    forecasting, which may not effectively deal with the concept drift issue and result
    in unsatisfactory results. Additionally, some studies disregarded the data leakage
    problem caused by the one-time decomposition of all datasets. Therefore, a novel
    real-time multi-step forecasting system with multiple rolling decomposition strategy
    based on streaming data is designed. It includes data preprocessing, forecasting,
    and evaluation modules. A three-stage data preprocessing strategy is proposed
    in the first module to overcome the single preprocessing defect. It can eliminate
    the adverse effects of outliers, extract main features, and reduce system complexity.
    Moreover, the forecasting and evaluation modules are designed to enhance the forecasting
    performance and verify the system’s validity. Considering the obvious concept
    drift problem of CCFI during the Coronavirus Disease 2019 (COVID-19) epidemic,
    datasets from the COVID-19 epidemic are selected for experimental verification
    to verify the system’s ability to solve this problem. Empirical studies demonstrate
    the superiority of the developed system over the compared models in terms of universality
    and robustness. Therefore, the proposed system is an effective prediction method
    for the containerized freight market in the post epidemic period and an alternative
    for forecasting other streaming data with the concept drift issue. Previous article
    in issue Next article in issue Keywords Real-time forecastingMulti-step forecastingMachine
    learningThree-stage data preprocessingStreaming data 1. Introduction Container
    transportation makes a significant contribution to the global supply chain (Azab
    and Morita, 2022), which is significant for the growth of the global economy and
    trade (Chen and Chen, 2010). The global shipping market is instable and intensely
    volatile due to various reasons, such as economic recession and seasonality. The
    fluctuating market and dynamic prices have impacted the container shipping market’s
    revenue, increasing the commercial risk associated with container trading and
    the survival challenges for shipping market stakeholders. Therefore, accurately
    predicting the trend of container freight rate is significant for business risk
    reduction and management decision-making for container shipping enterprises. Research
    on the shipping freight index has focused more on the forecasting and fluctuation
    of the Baltic Dry Index (Kuo et al., 2020, Hasan et al., 2021) and Baltic Exchange
    Dirty Tanker Index (Chen et al., 2017, Jafari and Rahimi, 2018); however, there
    has been little research on that of the containerized freight index (Ak, 2019,
    Zhang and Ding, 2016). The China Containerized Freight Index (CCFI) is considered
    a significant indicator of the state of container freight rates and the global
    shipping market. Therefore, it is significant to select CCFI as the prediction
    object and accurately forecast it. However, affected by many factors, CCFI has
    the characteristics of nonlinearity and multi-scale, even has the concept drift
    problem, and accurate prediction is still challenging. The mode decomposition
    algorithm and real-time rolling prediction are ideal methods for solving problems.
    Although the mode decomposition algorithm, which has been used in many fields,
    has a great processing effect on non-stationary data, it is not widely used in
    the shipping freight forecasting field, particularly in the container freight
    forecasting field. Therefore, in this research, the mode decomposition algorithm
    is used for multiple roll decomposition, preventing the data leakage problem caused
    by the one-time decomposition of data. The real-time rolling forecasting of CCFI
    is implemented, effectively improving the prediction effect. Based on these, a
    real-time forecasting system is established to solve the above problems in CCFI
    forecasting. During the COVID-19 epidemic (Chen et al., 2021, Kuca, 2020), CCFI
    has an obvious conceptual drift problem. Therefore, different datasets before
    and after the epidemic were considered, which validate the excellent performance
    of the forecasting system in handling streaming media data and concept drift problems.
    The remaining sections are organized as follows. Section 2 reviews the relevant
    research, and introduces the motivation and contributions of the study. Section
    3 presents the proposed forecasting system’s framework. The detailed process of
    the developed forecasting system is described in Section 4. Experimental datasets,
    analysis, results, and system performance evaluation are presented in Section
    5. Sections 6 and 7 present the discussions and conclusions and propose some orientations
    for future work, respectively. 2. Literature review Current shipping freight index
    forecasting primarily uses linear and nonlinear forecasting methods. Mainstream
    forecasting models include single and combined models. Table 1 shows the relevant
    forecasting studies in this field. Table 1. Summary of the most relevant forecasting
    research work introduced in this article. Reference Objective(s) Methodology Model
    type Chen and Chen, 2010 Container throughputs GP, X-11, SARIMA ML Munim and Schramm
    (2016) Container freight rates ARIMARCH ME Abouarghoub et al., 2018 Freight earnings
    HTS CM Du et al., (2019a) Container throughputs VMD-BOA -ELM CM Kim et al. (2019)
    Baltic Dry Index LSTM DL Tsatsaronis et al. (2019) Shipping markets price SVMs
    ML Yang and Mehmed (2019) Baltic Panamax Index ANN ML Zhang et al. (2019) Baltic
    Dry Index DFN, AI ML Kamal et al. (2020) Baltic Dry Index RNN, LSTM, GRU DL Munim
    and Schramm (2021) Container freight rates ARIMA, VAR, ANN CM Objective(s): Value-at-Risk.
    Methodology: Genetic Programming (GP), Seasonal Decomposition Method (X-11), Seasonal
    Auto Regression Integrated Moving Average (SARIMA), Autoregressive Integrated
    Moving Average and Autoregressive Conditional Heteroscedasticity (ARIMA-ARCH),
    Hierarchical Time Series Approaches (HTS), Variational Mode Decomposition (VMD),
    Butterfly Optimizer Algorithm optimized Extreme Learning Machine (BOA-ELM), Long
    Short Term Memory (LSTM), Support Vector Machines (SVMs), Artificial Neural Network
    (ANN), Dynamic Fluctuation Network (DFN), Artificial Intelligence method (AI),
    Recurrent Neural Network (RNN), Gate Recurrent Unit (GRU), Autoregressive Integrated
    Moving Average (ARIMA), Vector Autoregressive (VAR). Model type: Combined models
    (CM), Multivariate econometric models (ME), Deep learning methods (DL), Machine
    learning methods (ML). 2.1. Linear prediction models for forecasting shipping
    freight rates Univariate, multivariate econometric, and their extended models
    are frequently used in the application research of linear prediction models. Munim
    and Schramm (2016) combined two econometric models to develop the Autoregressive
    Integrated Moving Average and Autoregressive Conditional Heteroscedasticity (ARIMA-ARC-H)
    forecasting model for container shipping freight rates, which outperformed individual
    econometric models. Similarly, Du (2019) developed various models based on several
    distributions to predict the risk of the bulk shipping market. However, because
    of factors such as major emergencies (Gavriilidis et al., 2018, Rousset and Ducruet,
    2020), market supply and demand (Wang and Liu, 2018, Teplova et al., 2019), bunker
    price (Kurt et al., 2021, Xu and Yin, 2021), and goods circulation velocity (Chao-Chi,
    2015, Munim and Schramm, 2021), the shipping freight index presents complex fluctuation
    characteristics, such as nonlinearity, seasonal volatility, and uncertainty (Coto-Millan
    and Inglada-Pérez, 2020, Ishizaka et al., 2018, Población and Serna, 2021, Zhao
    and Tansuchat, 2019, Zhang and Mani, 2021). Nonlinear prediction methods are increasingly
    being studied because linear prediction cannot adapt to the complex situation
    of data. 2.2. Nonlinear prediction models for forecasting shipping freight rates
    Nonlinear models, including neural network methods (Feng and Niu, 2021, Li et
    al., 2021, Xiao et al., 2021, El-Dahshan et al., 2022, Zhang et al., 2022a), Artificial
    Intelligence (AI) algorithm (Castilla-Rodriguez et al., 2020, Du et al., 2019b,
    Wu et al., 2022, Yang et al., 2022, Jurdana et al., 2020 Zhang et al., 2023),
    and deep learning methods (Albuquerque et al., 2022, Kim et al., 2019, Urolagin
    et al., 2021), are gradually being used in this prediction field. Pao (2008) achieved
    better prediction results than multiple linear regression using the Artificial
    Neural Network (ANN) model to analyze the problems associated with various industrial
    capital structures. Tsatsaronis et al. (2019) used the Support Vector Machine
    (SVM) method to predict the freight volume for various routes and industries.
    The SVM method outperformed the standard econometric models. Yang and Mehmed (2019)
    used multivariable dynamic models to evaluate the forecasting performance of the
    Baltic Panamax Index (BPI) and Baltic forward assessment. Zhang et al. (2019)
    proposed a novel model using Dynamic Fluctuation Network (DFN) and AI techniques
    for Baltic Dry Index (BDI) forecasting. This novel model was demonstrated to be
    more suitable for BDI forecasting. Similarly, Kamal et al. (2020) integrated Recurrent
    Neural Network (RNN), Long Short Term Memory (LSTM), Gate Recurrent Unit (GRU),
    and other deep learning models for one-step and multi-step BDI forecasting. Single
    and combined model forecasting methods are the mainstream in the application of
    nonlinear models. However, a single forecasting model finds it challenging to
    reflect the features of the shipping freight index and is prone to over-fitting.
    Meanwhile, the combined model forecasting method outperforms the single model
    method in terms of forecasting (Wang et al., 2018, Xu et al., 2019, Yang et al.,
    2019c, Hao et al., 2020, Tu and Chen, 2021, Guo et al., 2022, Zhang et al., 2022),
    and it has gradually become an important method for shipping market forecasting
    (Abouarghoub et al., 2018, Ansorena, 2019). 2.3. Decomposition methods for forecasting
    shipping freight rate However, the general combination forecasting model finds
    it difficult to further explore the complex, nonlinear, and multi-scale characteristics
    of shipping freight series. To address the data complexity issue caused by various
    factors, decomposition approaches are widely used to identify and extract the
    main feature of data (Ping et al., 2021). Typical decomposition methods include
    the Wavelet Transform (WT), Empirical Mode Decomposition (EMD), Ensemble Empirical
    Mode Decomposition (EEMD), Complementary Ensemble Empirical Mode Decomposition
    (CEEMD), and others. Additionally, the decomposition integration-based hybrid
    models have been widely accepted and used in various fields (Hao and Tian, 2018,
    Liu et al., 2022, Du et al., 2019a, Wen et al., 2022). Based on the characteristics
    of different components, targeted forecasting is performed to improve the forecasting
    accuracy. For example, Zhu et al. (2019) proposed a hybrid forecasting model,
    which employed EEMD and optimal combined forecasting model, to forecast the West
    Texas Intermediate (WTI) and Crude Oil Price (COP) with effective results. Similarly,
    Wu et al. (2020) successfully forecasted wind power using the secondary decomposition-model
    and sample selection of the autonomous learning method, which is established for
    multi-step forecasting of points and intervals. 2.4. Motivation and contributions
    of the study 2.4.1. Motivation of proposed analysis However, several models in
    earlier studies were based on one-time decomposition of all datasets. That is,
    all-time series data are decomposed at one-time and divided as fixed training
    set and testing set. However, this approach has disadvantages: 1. it means that
    the future data to be tested are known, which obviously runs counter to prediction.
    2. decomposing all datasets at one-time and using fixed datasets cannot accurately
    show the real-time characteristics of data and ignores the data concept drift
    problem, which reduces prediction accuracy. To address these issues, the real-time
    multi-step forecasting system with three-stage data preprocessing strategy dealing
    with streaming data is proposed, which is not common in the forecasting field,
    and has never been used in the forecasting of freight indexes. The previous studies
    have demonstrated that there are still some challenging problems that should be
    improved. First, shipping freight rate time series data are extremely complex
    and nonlinear. Currently, improving its prediction accuracy is still a challenge
    and a focus for concern. Second, compared with other shipping freight indexes
    such as BDI and BPI, CCFI has received less attention, but container transportation
    has grown significantly in maritime trade and is demanding more attention. Third,
    previous research had not considered the inspection and processing of containerized
    freight index outliers. Owing to the complexity and timeliness of the index, there
    may be outliers the day of which characteristics are inconsistent with most data,
    making accurate prediction challenging. Fourth, numerous previous studies have
    relied on fixed data to predict results and have not focused on the concept drift
    problem. Previous forecasting methods cannot adapt to the concept drift caused
    by a continuous change in data distribution. Particularly under the influence
    of the epidemic, the data concept drift problem has become serious, making accurate
    forecasting significantly difficult. Fifth, in the past, only a few studies adopted
    the decomposition algorithm, and they all used methods for decomposing all datasets
    at one-time. The training and testing data are extracted from the dataset which
    was processed with the one-time decomposing. However, the one-time decomposing
    of the dataset cannot really show the main features of the data; it might even
    cause data leakage with exposing the testing data in advance. Finally, the COVID-19
    had a significant impact on every industry and on the containerized freight index.
    However, studies on the prediction of containerized freight index have not considered
    or analyzed the post epidemic forecasting. 2.4.2. Main contributions of the study
    A novel real-time multi-step forecasting system with a three-stage data preprocessing
    strategy that deals with streaming data was successfully developed. It addresses
    the limitations of using a fixed training set with decomposing all datasets at
    one-time, the complexity and nonlinearity of the containerized freight rate index
    time series, the data concept drift problem, and the high forecasting accuracy
    of innovative systems. Particularly, the rolling preprocessing of the original
    data is conducted using the data correction and decomposition technology. The
    real-time components should be reorganized to reduce the complexity, improve the
    operation efficiency, and present the law of the data better. Furthermore, the
    Extreme Learning Machine (ELM) model is used to forecast each reconstructed component.
    Then, the forecasting value of the containerized freight index is obtained by
    integrating the results from all components. Finally, the datasets of two containerized
    freight index before and after the epidemic are selected to validate the feasibility
    of the novel real-time forecasting system based on streaming data. Five commonly
    used forecasting evaluation criteria and two statistical indicators including
    Forecasting Effectiveness (FE) and Grey Relational Analysis (GRA) are used to
    evaluate the forecasting performance of the proposed system. According to the
    experiments, a real-time multi-step forecasting system with a three-stage data
    preprocessing strategy based on streaming data outperforms the comparison models
    and can significantly improve the forecasting accuracy of containerized freight
    index. This study’s main contributions can be summarized as follows: First, the
    study develops a hybrid multi-step forecasting system for container freight market
    forecasting. A novel real-time forecasting system with a three-stage data preprocessing
    strategy for handling streaming data is developed for the multi-step containerized
    freight market forecasting, which can provide participants in the shipping market
    with more valuable and useful information. Second, the study proposes a novel
    data preprocessing strategy and a forecasting method. The main difference from
    the previous research in the shipping market forecasting field is the implementation
    of multiple roll decomposition mode, a three-stage data preprocessing strategy
    with a rolling mode based on streaming data and real-time forecasting method are
    developed to greatly improve the prediction accuracy of the system. Third, the
    study achieves multi-step forecasting with high accuracy of CCFI. Compared with
    the previous one-step prediction of shipping market prediction, the multi-step
    forecasting of the containerized freight index not only demonstrates the robustness
    and superior performance of the real-time forecasting system, but also helps shipping
    market practitioners make long-term decisions to mitigate certain risks. Fourth,
    it establishes scientific experiments and a comprehensive evaluation module. In
    the experiments, four datasets for two indexes are established before and after
    the epidemic, and the common performance evaluation criteria and related comparison
    models are used to thoroughly evaluate the proposed system. The experimental results
    indicate that the system can effectively improve the forecasting performance better
    than the other models. Finally, it improves the accuracy and stability of forecasting
    system under the impact of emergencies. Container markets have been resilient
    to the influence of COVID-19 and changes in data distribution and unusual rise
    in the containerized freight index is presented. The novel real-time forecasting
    system based on streaming data can provide helpful results in the post-COVID-19
    recovery process, thus the trend of container market will be judged more accurately.
    3. Framework of the proposed forecasting system The rolling decomposition real-time
    forecasting system framework is shown in Fig. 1. The developed prediction system
    can be described in more detail as follows: • Revise Outliers. The corresponding
    dataset for each test data is constructed using the data rolling mode. Following
    construction, the Hampel filtering technology is used to filter and revise each
    raw containerized freight index dataset. • Roll decompose and reconstruct. Use
    Complete Ensemble Empirical Mode Decomposition Adaptive Noise (CEEMDAN) technology
    to roll decompose the revised streaming data into a few sub-sequences. Permutation
    Entropy (PE) is used to determine the complexity of each sub-sequence. Both the
    decomposition results of CEEMDAN and PE value are considered, sub-sequences with
    approximate characteristics and similar entropy values are merged and reconstructed.
    • Real-time and multi-step forecasting. The ELM-based forecasting module is proposed
    to forecast each integrated sub-sequence for the containerized freight index using
    a rolling real-time forecasting method. Add up the prediction results of each
    integrated sub-sequence to achieve the ultimate results of the system. The three-step
    forecasting is implemented using the system. That is, numerical prediction at
    time , , and are performed at time . The details process is as follows. Firstly,
    to output the predicted value , the relevant sub-sequences are obtained by decomposing
    the sequence at time 1 to , and the sub-sequences are reconstructed to form new
    modes. Mode uses data at time 1 to to train the model, using , , , as input, and
    adding the predicted values to of each mode to obtain the the final predicted
    value. Then, predicting the data at time , each new mode is formed by decomposing
    and reconstructing the data at time 1 to . The training model is trained using
    to and of the new mode, using , , , as the input, and as output. Then adding the
    predicted values of each mode to obtain the the final predicted value. Similarly,
    during prediction at each layer, the predicted value at time and , , of each mode
    are taken as inputs to obtain the predicted value at time . Finally, the three
    step predicted values of the modes are added to obtain the final multi-step predicted
    value of CCFI. The three-step forecasting of each mode is shown in lower right
    sub graph of Fig. 1. • Evaluate performance. Designing four experiments and seven
    comparable models will help verify the performance of the rolling real-time forecasting
    system. The performance validation is conducted not only by common metrics but
    also by accuracy of the grey correlation analysis and two typical evaluation methods.
    • Further evaluate. Adopt the discussion method based on comparative analysis
    and correlation strength to further evaluate the superiority of the rolling decomposition
    real-time forecasting system. Download : Download high-res image (566KB) Download
    : Download full-size image Fig. 1. Real-time multi-step forecasting system framework.
    4. Detailed process of the proposed forecasting system A novel real-time multi-step
    forecasting system is developed, which contains three modules: data preprocessing,
    forecasting, and evaluation modules. 4.1. Module 1: Data preprocessing module
    This module includes two phases: original sequence processing and component sequence
    analysis. 4.1.1. Stage 1: Outlier correction processing The Hampel filter algorithm
    is a type of decision filter used to identify outliers in a time sequence and
    replace them with more appropriate values. The filter assumes that the given time
    series follows a distribution and probability model, then adopts an inconsistency
    test to process the time sequence according to the hypothesis (Bhowmik & Jelfs,
    2017). The Hampel filter and the 3 criteria have similar decision rules, but whether
    the filtered data are singular no longer depends on the evaluation rules of the
    mean and standard deviation; instead, it depends on the median evaluation rules
    (Pearson, 2002). In the time sequence , the median mean square error denotes the
    median of the root mean square error. The mean absolute percent error is determined,
    where , , thus median denotes the median of . The threshold can be denoted as
    . When the value of the calculated threshold is greater than three, the corresponding
    sequence value is considered abnormal. 4.1.2. Stage 2: Original sequence processing
    The CEEMDAN technical method, which is based on EMD, was developed by Torres et
    al. (Torres et al., 2011). The EMD algorithm decomposes a time series into several
    Intrinsic Mode Functions (IMF). For each IMF, the sequence must meet two conditions:
    there are extreme points and zero crossings with the same number or a difference
    of 1 and the average of the upper and lower envelopes formed by the local extreme
    points is zero. However, the EMD and other EMD-based algorithms have shortcomings.
    The CEEMDAN method not only ameliorates the mode aliasing problem that occurs
    easily in EMD, but also solves the problem of residual noise and false components
    of EEMD and CEEMD, resulting in a sequence with less reconstruction errors (Jun
    et al., 2021). The CEEMDAN method, which has been recognized as an effective data
    preprocessing tool in the forecasting field, can indirectly improve the performance
    of the prediction models. The process of CEEMDAN can be expressed as follows:
    Step 1. The adaptive white noise data are appended to the given original sequence
    to form a modified sequence data. (1) where, represents the adaptive coefficient
    and indicates the white noise data added for the time. Step 2. The EMD algorithm
    is used to decompose the data for multiple times. represents the N-th component
    acquired using EMD decomposition. Calculate the mean value of the decomposition
    results to obtain the first modal component and residual component of CEEMDAN.
    (2) (3) Step 3. The adaptive white noise sequence is added to the residual component
    to form a new sequence data, then the EMD technology is applied to obtain its
    mean value, so as to obtain the second sequence data. (4) (5) Step 4. The N-th
    residual component and modal component can be obtained as follows: (6) (7) Step
    5. Repeat the previous step until the residual component can no longer be decomposed,
    and finally decompose the original sequence into multiple IMF components and trend
    items. (8) The CEEMDAN method maintains the integrity of the decomposition and
    accurately reconstructs the original data. 4.1.3. Stage 3: Component sequence
    analysis PE, which can quickly and accurately detect the mutation and randomness
    of signals, is considered to be an effective tool for evaluating the complexity
    of time series (Bandt and Pompe, 2002). It is suitable for the time series and
    sub-sequences complexity analysis. The PE value of sub-sequences shows a downward
    trend, this also indicates that the randomness of sub-sequences from high to low
    frequencies decreases. This research adopts the direct addition mode of sub-sequences
    based on their approximate characteristics and similar PE values to merge them.
    The method has been proved to be effective in some researches (Si et al., 2019,
    Ruiz-Aguilar and Turias, IGonzalez-Enrique, J. Urda, D. Elizondo, D. , 2021).
    The basic principle of the algorithm is as follows: Definition 1 The phase space
    of the given is reconstructed, and the phase space matrix is obtained as follows:
    (9) In Eq. (9), represents embedding dimension, is the time delay, and . Definition
    2 Rearrange the reconstructed components in ascending order to obtain a group
    of symbol series, which are composed of column numbers of each element position
    in the vector. (10) Definition 3 The probability of each reconstructed component
    is calculated as follows: , and . Definition 4 The PE value of can be defined
    as follows: (11) where , and when , reaches the maximum value, that is . Definition
    5 To facilitate the comparison of entropy values, the PE is normalized as . The
    PE represents the degree of randomness and mutation of X. The smaller the entropy,
    the simpler the time series, the better the regularity, and the weaker the randomness.
    The mutation probability increases and the randomness becomes stronger as the
    entropy increases. 4.2. Forecasting module The original ELM is presented in this
    module. Numerous studies in the forecasting field have used the ELM developed
    by Huang et al. (Huang et al., 2004) because of its simple structure, high precision,
    fast operation speed, and few training sample requirements. Examples include electricity
    price prediction (Yang et al., 2019a) and wind energy prediction (Yang et al.,
    2019b). Compared with some neural networks and other models, ELM has performance
    advantages. It has gradually emerged as one of the widely used and superior methods
    in the forecasting field. Given the training dataset, , with N samples, the ELM
    model with S hidden nodes can be expressed as: (12) where indicates the weight
    connection, which is between the ith-hidden node and the output node. F denotes
    the excitation function, denotes the input weight vector, and denotes the hidden
    bias. Eq. (12) can be expressed as follows: (13) (14) where H denotes the output
    matrix of the hidden layer. Hence, to solve the following minimum question, the
    output weight can be received using the following equation: (15) The optimal solution
    can be expressed as follows: (16) where represents the Moore–Penrose generalized
    inverse matrix of the output matrix for a hidden layer, which is defined using
    the following equation: (17) 4.3. Evaluation module This section describes the
    rigorous evaluation module. In addition to the evaluation measurement metrics
    that previous studies have demonstrated to be effective, the FE and GRA are proposed
    to verify the performance from a statistical viewpoint. 4.3.1. Common error criteria
    It is well known that researchers have not established a unified standard to test
    the effectiveness of predictions during an experiment. The Mean Absolute Error
    (MAE), Root Mean Square Error (RMSE), Mean Absolute Percent Error (MAPE), Index
    of Agreement (IA), and Theil U statistic are selected as common error criteria
    are shown in Table 2. Given, and denote the average value of the actual value
    and the actual value of the ith data respectively, denotes the predicted value
    of the ith data and N represents the length of the dataset. Table 2. Performance
    metric criteria. Metric Definition Equation MAE The absolute average of N error
    squares RMSE The square root of average of the error squares MAPE The average
    of N absolute percentage errors IA The index of agreement of forecasting results
    TIC The theil''s inequality coefficient of forecasting results 4.3.2. Typical
    evaluation methods The FE and GRA methods are typical evaluation methods selected
    in this module. 4.3.2.1. Forecasting effectiveness The FE value should be used
    to estimate the effect of the proposed system. The calculation process is shown.
    The pth-order forecasting effectiveness unit is expressed as follows: (18) where
    indicates the accuracy of prediction and denotes the discrete probability distribution.
    The sum of is 1. Suppose we do not know the state of the probability distribution,
    is presumed as 1/N. The FE with p-order can be expressed as follows: The FE with
    first order (FE-1) indicates the prediction accuracy, which is expressed as ,
    when denotes a single variable continuous function. The FE with second order (FE-2)
    is described as the difference between the standard deviation and the expected
    value, which is , when is a two-variable continuous function. 4.3.2.2. Grey relational
    analysis The GRA is used as an evaluation method to determine the relationship
    based on the similarity of data series between the forecasting values and the
    observed values in this section. The main calculation process is as follows: The
    comparison series are and the reference series are . The series can be standardized
    using the following equation: (19) The correlation coefficient between and is
    expressed as follows: (20) The grey relation degree between and is expressed as
    follows: (21) 5. Experiments The COVID-19 pandemic has impacted the CCFI fluctuation
    trend; therefore, to illustrate the effectiveness of the real-time multi-step
    system in container freight forecasting, we used two datasets before and after
    the epidemic to conduct Experiments I and II. To further verify the robustness
    and effectiveness of the proposed system, Experiment III using the Shanghai Containerized
    Freight Index (SCFI) dataset is established in Subsection 5.5. All datasets are
    from the Prospective database (https://x.qianzhan.com/). The experiments were
    conducted on a macOS 10.14.6, Intel (R) Core CPU (Core-i5 2.6 GHz), 8 G RAM. Additionally,
    to ensure fairness, all experimental models are assigned the same parameters.
    Based on previous literature and empirical tests, the key parameters of PE embedding
    dimension and time delay are 4 and 1 respectively. The moving window length of
    Hampel is 7, the number of standard deviations for testing outliers is 3.The signal-to-noise
    ratio, noise addition times, and maximum iteration times of CEEMDAN are set to
    0.5, 500, 5000, respectively. The number of input, output, and hidden neurons
    in ELM is 4, 1, 9 respectively. 5.1. Data descriptions The COVID-19, which first
    surfaced in January 2020, has significantly impacted the shipping market. Hence,
    the CCFI weekly data from January 11, 2002 to December 27, 2019 are selected as
    the first dataset, which size is 915. And the second dataset includes the data
    from January 11, 2002 to September 10, 2021, which size is 1001. To meet the development
    needs of derivatives of the international containerized freight index, the SCFI
    was reformed and released officially on October 16, 2009, by the Shanghai Shipping
    Exchange. The price on this day is also used as the base period price. In this
    study, the weekly SCFI experimental datasets consist of data from October 16,
    2009, to September 10, 2021. The SCFI data from October 16, 2009, to December
    27, 2019, are selected as the third dataset, which size is 507. And the fourth
    dataset includes data from October 16, 2009, to September 10, 2021, which size
    is 593. The four datasets used in this experiment are shown in Fig. 2, and the
    descriptive statistical results are shown in Table 3. The curves in the figure
    and the statistical values in the table from the four datasets reflect different
    fluctuation trends and statistical characteristics. Download : Download high-res
    image (454KB) Download : Download full-size image Fig. 2. Four containerized freight
    index datasets. Table 3. Statistical values of four datasets. Datasets Statistical
    Values Max. Median Min. Ave. Std. Dataset 1 All Samples 1583.1800 947.5800 400.4300
    959.3547 244.1929 Training set 1583.1800 1074.2900 484.1400 1075.7337 233.0989
    Testing set 990.2400 796.3900 400.4300 780.7129 122.8990 Dataset 2 All Samples
    4568.1600 981.1900 400.4300 1131.6534 659.3215 Training set 1583.1800 1030.6400
    400.4300 1001.7842 259.2088 Testing set 4568.1600 889.0450 646.5900 1386.8464
    1030.5731 Dataset 3 All Samples 1335.8600 1017.0800 632.3600 993.1774 147.4691
    Training set 1335.8600 1064.1300 712.5800 1048.9757 111.9583 Testing set 891.3200
    808.7400 632.3600 793.6985 61.0895 Dataset 4 All Samples 3157.6000 1021.0100 632.3600
    1039.8019 300.3183 Training set 1335.8600 1043.7700 632.3600 1018.3870 139.9540
    Testing set 3157.6000 845.0350 743.7100 1125.5686 604.3515 5.2. Experimental setup
    To verify the effectiveness, universal applicability, and superiority of the proposed
    system, four experiments are set up and completed. In Experiment I, the first
    dataset is applied to the proposed hybrid system and several comparison models,
    which are the ELM-based models for fixed datasets with one-time decomposition
    (ELM-F, H-ELM-F, CEEMDAN-PE-ELM-F, and H-CEEMDAN-PE-ELM-F) and the ELM-based models
    with a rolling decomposition real-time forecasting method (ELM-R, H-ELM-R, CEEMDAN-PE-ELM-R,
    and H-CEEMDAN-PE-ELM-R). Simultaneously, the models are marked as Model 1 to Model
    8. In Experiment II, the second dataset is applied to the above models to demonstrate
    the robustness and superiority of the system. If the system using the SCFI dataset
    outperforms the comparison systems, it can be reasonably concluded that the real-time
    forecasting system has universal applicability based on those datasets with the
    obviously differential features. Hence, the SCFI is selected in the comparative
    experiments (Experiment III). To further confirm the superiority of the proposed
    system, Experiment IV is designed to evaluate the performance by FE and GRA using
    the four datasets. 5.3. Experiment I: Pre-epidemic CCFI forecasting In this subsection,
    seven comparison models and five common error criteria are designed to validate
    the superiority of the developed system in container freight forecasting. This
    experiment has performed one-step, two-step, and three-step CCFI forecasting using
    pre-epidemic data. The Hampel, CEEMDAN-PE, rolling decomposition strategy, and
    ELM, which are components of the developed system, are used as the benchmark models
    to verify the superiority of the proposed forecasting system. Meanwhile, the multi-step
    prediction of the fixed set and real-time method is designed as the main comparative
    study. The results of all models used in the CCFI forecasting experiment in Table
    4 indicate that the proposed H-CEEMDAN-PE-ELM-R system can achieve a more outstanding
    accuracy with the least MAE, RMSE, MAPE, and TIC, and the maximum IA, than the
    comparable models, demonstrating the superior forecasting abilities of the hybrid
    system. Our forecasting system outperforms other comparable models for container
    freight forecasting. Particularly, the results of these eight different forecasting
    systems are shown in Table 4 and Fig. 3. Table 4. Results of Experiment I. Models
    Evaluation Empty Cell Improvement MAE RMSE MAPE IA TIC Empty Cell MAE RMSE MAPE
    IA TIC 1 STEP Model 1 15.84916 20.21241 2.01417 0.97252 0.01271 66.99251 65.91079
    66.97337 2.48941 65.93234 Model 2 14.12353 17.99533 1.79440 0.97738 0.01130 62.95961
    61.71090 62.92843 1.97978 61.68142 Model 3 6.32706 8.36638 0.81582 0.99491 0.00525
    17.31689 17.64359 18.46130 0.18293 17.52381 Model 4 5.95628 7.76982 0.75529 0.99580
    0.00489 12.16984 11.32034 11.92656 0.09339 11.45194 Model 5 8.64526 11.15070 1.10671
    0.99160 0.00700 39.48811 38.20792 39.89303 0.51735 38.14286 Model 6 8.62036 11.06616
    1.10129 0.99173 0.00695 39.31332 37.73585 39.59684 0.50417 37.69784 Model 7 5.76403
    7.47809 0.73380 0.99615 0.00470 9.24041 7.86083 9.34680 0.05822 7.87234 Model
    8 5.23141 6.89025 0.66521 0.99673 0.00433 – – – – – 2 STEP Model 1 22.33119 28.33450
    2.83342 0.94565 0.01783 75.03577 74.12815 74.95175 5.35505 74.14470 Model 2 20.65528
    26.58019 2.63026 0.94965 0.01667 73.01024 72.42059 73.01707 4.91128 72.34553 Model
    3 7.00877 9.05721 0.89831 0.99396 0.00569 20.45951 19.06271 20.99380 0.23442 18.98067
    Model 4 6.11250 8.10052 0.77712 0.99538 0.00509 8.79656 9.50383 8.67308 0.09142
    9.43026 Model 5 16.01832 20.06429 2.03869 0.97274 0.01260 65.19729 63.46414 65.18734
    2.42100 63.41270 Model 6 15.91269 19.96462 2.02299 0.97291 0.01254 64.96626 63.28175
    64.91725 2.40310 63.23764 Model 7 6.12958 8.01051 0.77611 0.99557 0.00503 9.05070
    8.48698 8.55344 0.07232 8.34990 Model 8 5.57481 7.33066 0.70972 0.99629 0.00461
    – – – – – 3 STEP Model 1 28.32417 35.46282 3.61051 0.91653 0.02233 76.02969 75.11932
    76.11855 8.51582 75.19033 Model 2 25.00073 32.44327 3.18614 0.92647 0.02035 72.84323
    72.80364 72.93778 7.35156 72.77641 Model 3 9.11991 11.86615 1.18673 0.98901 0.00745
    25.55420 25.64235 27.34339 0.56319 25.63758 Model 4 8.55633 11.36147 1.08285 0.99125
    0.00716 20.65068 22.33936 20.37306 0.33594 22.62570 Model 5 22.32605 28.08765
    2.84080 0.94581 0.01763 69.58983 68.58623 69.64790 5.15643 68.57629 Model 6 21.95323
    27.88781 2.78933 0.94650 0.01750 69.07339 68.36112 69.08786 5.07977 68.34286 Model
    7 6.99712 8.86433 0.88809 0.99445 0.00557 2.96879 0.46185 2.91087 0.01307 0.53860
    Model 8 6.78939 8.82339 0.86224 0.99458 0.00554 – – – – – Download : Download
    high-res image (312KB) Download : Download full-size image Fig. 3. Multi-step
    forecasting results of Dataset 1. The detailed comparisons and analysis between
    the proposed system and others are described as follows: First, from the comparison
    results between Models 1 (ELM-F) and 5 (ELM-R), Models 2 (H-ELM-F) and 6 (H-ELM-R),
    Models 3 (CEEMDAN-PE-ELM-F) and 7(CEEMDAN-PE-ELM-R), and Models 4 (H-CEEMDAN-PE-ELM-F)
    and 8 (H-CEEMDAN-PE-ELM-R), a series of models using the rolling decomposition
    real-time forecasting method can obtain better values of the five evaluation indicators
    compared with a series of models using fixed sets by decomposing all datasets
    at one-time using multi-step forecasting. This demonstrates that our designed
    rolling decomposition real-time forecasting system has superior ability and more
    stable predication results in making multi-step CCFI forecasting. Second, when
    comparing Models 1 and 3, and Models 5 and 7, it is distinctly found that Model
    7 outperforms Model 5 and Model 3 outperforms Model 1, indicating that decomposition
    methods clearly enhance forecasting performance than these models without it.
    The performance improvement is more evident with the fixed set. The average comparison
    results of the multi-step prediction demonstrate that Model 3′s MAE, RMSE, and
    MAPE can improve by 65.4985 %, 64.3938 %, and 64.9742 %, respectively, compared
    with that of Model 1. Third, through four pairs of comparison models, Models 2
    and 1, Models 4 and 3, Models 6 and 5, and Models 8 and 7, the Hampel approach
    has a positive impact on the prediction effect improvement. Additionally, the
    data preprocessing module significantly relies on the application of data correction
    algorithms. Fourth, using Model 1 as the benchmark model, Model 5 has an advantage
    over Model 1 in that it uses real-time prediction methods, whereas Model 4 adds
    a data preprocessing module compared with Model 1. According to the comparison
    results, the real-time prediction method’s ability to improve model performance
    is less than that of the data preprocessing module. Finally, overall, the one-step
    forecasting results of the models are almost always superior to the two-step and
    three-step forecasting results. Through comparison, it can be seen that the two-step
    and three-step prediction results of models 1, 2, 5, and 6 fluctuate significantly
    compared to the one-step prediction results. The two-step and three-step evaluation
    indicators of models 3, 4, 7, and 8 are relatively stable, indicating that the
    data preprocessing module has a positive impact on the multi-step forecasting.
    Then comparing the four models using real-time forecasting, it is easy to quantify
    that the average improvement of MAPE of the developed forecasting system compared
    with the other three models is 29.6122 %, 46.2193 %, and 47.2155 %, respectively,
    in one-step, two-step, and three-step forecasting. Therefore, our system has more
    stability and superior multi-step forecasting performance. 5.4. Experiment II:
    Post-epidemic CCFI forecasting To verify the robustness and superiority of the
    system under different conditions, the post epidemic CCFI streaming data were
    specially selected to conduct the relevant experiment. The epidemic impacted the
    container market, making the data characteristics significantly different from
    before. Although the overall performance of the evaluation index of Dataset 2
    in Table 5 and Fig. 4 is weaker than that of Dataset 1, the proposed system still
    performs the best and most effective. Table 5. Results of Experiment II. Models
    Evaluation Empty Cell Improvement MAE RMSE MAPE IA TIC Empty Cell MAE RMSE MAPE
    IA TIC 1 STEP Model 1 179.49817 421.96410 8.52367 0.74933 0.18611 94.94010 96.65971
    90.98675 33.43387 97.02864 Model 2 173.02551 406.83568 8.27052 0.77406 0.17870
    94.75082 96.53550 90.71086 29.17087 96.90543 Model 3 94.03777 225.84939 4.59215
    0.95013 0.09390 90.34173 93.75919 83.27015 5.23402 94.11076 Model 4 64.48347 157.92525
    3.07941 0.97814 0.06464 85.91512 91.07499 75.05171 2.22054 91.44493 Model 5 16.16272
    26.15538 1.25317 0.99952 0.01028 43.80636 46.11113 38.69467 0.03402 46.20623 Model
    6 15.17623 25.55862 1.21502 0.99955 0.01004 40.15365 44.85289 36.76977 0.03101
    44.92032 Model 7 9.82208 14.63287 0.86476 0.99985 0.00574 7.53058 3.67686 11.15917
    0.00100 3.65854 Model 8 9.08242 14.09484 0.76826 0.99986 0.00553 – – – – – 2 STEP
    Model 1 180.86096 413.44696 8.92565 0.76354 0.18207 93.15271 95.01637 88.64251
    30.92962 95.55665 Model 2 176.87213 404.79239 8.73635 0.77679 0.17777 92.99829
    94.90982 88.39641 28.69630 95.44918 Model 3 91.87255 197.69400 5.09692 0.96376
    0.08121 86.52037 89.57750 80.11093 3.72914 90.03817 Model 4 89.33276 211.40877
    4.32668 0.95725 0.08780 86.13713 90.25364 76.57026 4.43458 90.78588 Model 5 28.65671
    46.71236 2.30238 0.99847 0.01841 56.78471 55.89035 55.97034 0.12319 56.05649 Model
    6 28.40501 44.71874 2.26861 0.99859 0.01763 56.40178 53.92388 55.31493 0.11116
    54.11231 Model 7 13.38450 22.09983 1.10827 0.99966 0.00868 7.47447 6.76553 8.53041
    0.00400 6.79724 Model 8 12.38408 20.60466 1.01373 0.99970 0.00809 – – – – – 3
    STEP Model 1 192.16876 429.22189 9.73854 0.73680 0.18981 91.68385 93.51916 87.45952
    35.64875 94.24161 Model 2 188.91034 420.78265 9.62564 0.75159 0.18570 91.54040
    93.38918 87.31243 32.97942 94.11416 Model 3 109.66609 240.95687 5.78070 0.94191
    0.10034 85.42754 88.45554 78.87349 6.10993 89.10704 Model 4 91.31290 208.72248
    4.52071 0.95854 0.08692 82.49858 86.67265 72.98522 4.26899 87.42522 Model 5 43.92324
    69.68083 3.39620 0.99653 0.02758 63.61596 60.07916 64.04040 0.29402 60.36983 Model
    6 41.72651 66.43548 3.28939 0.99685 0.02629 61.70049 58.12904 62.87275 0.26182
    58.42526 Model 7 16.75143 30.12244 1.25564 0.99936 0.01184 4.59889 7.65300 2.73805
    0.01001 7.68581 Model 8 15.98105 27.81717 1.22126 0.99946 0.01093 – – – – – Download
    : Download high-res image (293KB) Download : Download full-size image Fig. 4.
    Experiment results of Dataset 2. Based on the comparison results, some similar
    conclusions are presented in the case of Dataset 1. Specifically, the developed
    data preprocessing model and rolling real-time forecasting method are applied
    to the data after the epidemic, both of which can still play positive roles in
    improving the prediction system’s forecasting performance. The one-step forecasting
    results of the models are almost always superior to the two-step and three-step
    forecasting results. However, there are still a few novel findings. Unlike Data
    1, the improvement effect of the two-step and three-step forecasting evaluation
    indicators of the models are relatively stable and similar to the trend of the
    one-step forecasting, especially the performance of Models 1, 2 and 3. The performance
    of models 5, 6, 7, and 8 is significantly better than that of models 1, 2, 3,
    and 4 in one-step, two-step, and three-step forecasting, indicating that the real-time
    forecasting method has a positive impact on the forecasting results. When Models
    1, 4, and 5 are compared, the results show that the real-time prediction method
    improves the performance more than the data preprocessing module. Compared with
    Models 1 and 8, the superiority and contribution of rolling decomposition and
    the real-time forecasting method can be verified. The improvement rate of the
    proposed prediction system on Dataset 2 is higher. For example, the Model 8′s
    evaluation indexes MAE, RMSE, MAPE, IA, and TIC are improved by 66.9925 %, 65.9108
    %, 66.9734 %, 2.4895 %, and 65.9301 % using Dataset 1 in one-step forecasting,
    whereas using Dataset 2 they are improved by 94.9401 %, 96.6597 %, 90.9868 %,
    33.4339 %, and 97.0305 %. It was reasonably and clearly demonstrated that the
    proposed real-time forecasting system has a more stable and accurate prediction
    ability in the case of drastic changes in the law of data fluctuation and provides
    a more efficient method for the accurate prediction of CCFI after the epidemic.
    Remark: The occurrence and prevalence of epidemic situations cause violent and
    sudden fluctuations in streaming data, which makes accurate prediction more challenging.
    However, the proposed system outperforms the one-time decomposition and fixed
    set forecasting model in terms of performance, and the improvement rate based
    on Dataset 2 is higher than that based on Dataset 1. Hence, the proposed system
    can correct the defects caused by decomposing all datasets at one-time and fixed
    set prediction in previous studies and has better generalization and forecasting
    ability. 5.5. Experiment III: Further experiment ——SCFI forecasting To further
    evaluate the robustness and generalization of the real-time multi-step forecasting
    system, this study regards the SCFI time series before and after the epidemic
    as new experimental datasets. Similar to Experiments I and II, seven comparison
    models and five evaluation indexes are used to analyze and test the performance
    of the proposed forecasting system. The detailed experimental results, which are
    shown in Table 6, Table 7, demonstrate that the proposed real-time multi-step
    forecasting system consistently has the highest prediction accuracy compared with
    all other experimental methods. This further verifies the significant performance
    of the developed system in the multi-step SCFI prediction, and the ability of
    the system can be extended to different shipping indices in the future. Table
    6. Results of Experiment III for dataset 3. Models Evaluation Empty Cell Improvement
    MAE RMSE MAPE IA TIC Empty Cell MAE RMSE MAPE IA TIC 1 STEP Model 1 50.84829 63.35977
    6.96093 0.92905 0.03947 62.68864 59.64290 63.54098 6.39193 58.93246 Model 2 45.64798
    55.68936 6.22960 0.94501 0.03470 58.43805 54.08429 59.26083 4.59466 53.28781 Model
    3 20.50939 29.37022 2.63190 0.98503 0.01874 7.49508 12.93847 3.57213 0.34547 13.47211
    Model 4 19.50893 27.58217 2.56304 0.98691 0.01755 2.75125 7.29460 0.98133 0.15391
    7.64015 Model 5 32.11675 43.50433 4.35461 0.96575 0.02757 40.92743 41.22387 41.71952
    2.34886 41.20058 Model 6 31.85338 43.26576 4.33804 0.96627 0.02740 40.43900 40.89976
    41.49692 2.29335 40.84008 Model 7 19.44047 26.07966 2.57764 0.98803 0.01654 2.40876
    1.95361 1.54199 0.04048 2.00097 Model 8 18.97219 25.57017 2.53789 0.98843 0.01621
    – – – – – 2 STEP Model 1 59.98207 74.83867 8.31619 0.89820 0.04642 66.62599 64.50178
    67.39851 9.93990 63.74604 Model 2 56.77602 71.20143 7.85187 0.90490 0.04440 64.74142
    62.68840 65.47063 9.12553 62.09995 Model 3 21.75622 28.88577 2.88817 0.98560 0.01840
    7.98760 8.02947 6.12728 0.19105 8.52856 Model 4 21.16250 26.78301 2.87808 0.98716
    0.01696 5.40618 0.80877 5.79811 0.03201 0.80170 Model 5 51.21250 63.53233 6.96693
    0.92356 0.04028 60.91107 58.18445 61.08467 6.92118 58.22452 Model 6 49.99895 62.49255
    6.80595 0.92585 0.03957 59.96232 57.48870 60.16424 6.65660 57.47283 Model 7 20.65245
    26.59097 2.77026 0.98746 0.01686 3.07001 0.09243 2.13179 0.00172 0.20164 Model
    8 20.01842 26.56639 2.71120 0.98748 0.01683 – – – – – 3 STEP Model 1 66.79647
    86.18210 9.32384 0.86127 0.05350 68.40035 67.91193 69.86827 14.52304 67.31089
    Model 2 65.05711 83.56073 9.03420 0.87183 0.05208 67.55550 66.90530 68.90225 13.13510
    66.42155 Model 3 23.08426 31.03165 3.02133 0.98313 0.01980 8.56345 10.88396 7.01349
    0.32763 11.67172 Model 4 23.69406 34.14777 3.10948 0.98004 0.02182 10.91668 19.01616
    9.64931 0.64406 19.83039 Model 5 61.50662 77.05519 8.34791 0.88318 0.04884 65.68263
    64.11121 66.34566 11.68168 64.18757 Model 6 60.32779 75.61873 8.20909 0.88735
    0.04786 65.01206 63.42946 65.77657 11.15684 63.45800 Model 7 22.30696 29.24196
    3.01431 0.98477 0.01851 5.37726 5.42981 6.79687 0.15983 5.52615 Model 8 21.10745
    27.65418 2.80943 0.98635 0.01749 – – – – – Table 7. Results of Experiment III
    for dataset 4. Models Evaluation Empty Cell Improvement MAE RMSE MAPE IA TIC Empty
    Cell MAE RMSE MAPE IA TIC 1 STEP Model 1 362.68749 764.66282 13.96566 0.70663
    0.26791 93.45248 95.57835 85.68632 41.47857 96.33832 Model 2 363.56032 772.79125
    13.79694 0.69748 0.27111 93.46820 95.62485 85.51128 43.33458 96.38154 Model 3
    123.16991 267.04511 4.86476 0.97865 0.08264 80.72009 87.33894 58.90856 2.15399
    88.12924 Model 4 70.70076 157.98142 3.29069 0.99336 0.04720 66.41189 78.59828
    39.25286 0.64126 79.21610 Model 5 38.15561 54.85571 3.12170 0.99928 0.01598 37.76263
    38.36423 35.96438 0.04503 38.61076 Model 6 38.09470 54.35171 3.11158 0.99929 0.01582
    37.66311 37.79268 35.75611 0.04403 37.98989 Model 7 25.37374 35.53759 2.13232
    0.99970 0.01032 6.41092 4.85922 6.25234 0.00300 4.94186 Model 8 23.74705 33.81074
    1.99900 0.99973 0.00981 – – – – – 2 STEP Model 1 375.48825 778.57918 14.90250
    0.69166 0.27388 92.66388 94.85819 84.52434 44.52477 95.75361 Model 2 369.97997
    767.91924 14.68293 0.70402 0.26951 92.55466 94.78681 84.29292 41.98744 95.68476
    Model 3 153.86135 341.04553 5.77619 0.96278 0.10740 82.09669 88.26167 60.07299
    3.82642 89.17132 Model 4 130.95436 286.84223 5.36726 0.97499 0.08894 78.96498
    86.04353 57.03096 2.52618 86.92377 Model 5 63.66162 88.37867 5.18249 0.99811 0.02584
    56.73016 54.70280 55.49900 0.15129 54.99226 Model 6 62.58552 85.91223 5.06949
    0.99822 0.02511 55.98618 53.40237 54.50706 0.14025 53.68379 Model 7 29.45711 41.60675
    2.35175 0.99959 0.01208 6.48682 3.78229 1.93430 0.00300 3.72517 Model 8 27.54628
    40.03306 2.30626 0.99962 0.01163 – – – – – 3 STEP Model 1 394.30032 795.39710
    16.37091 0.67256 0.28125 92.06838 94.22843 84.93633 48.61128 95.25689 Model 2
    366.23796 742.84129 15.17113 0.73087 0.25935 91.46063 93.82009 83.74505 36.75483
    94.85637 Model 3 198.23634 446.16478 7.29810 0.92967 0.14405 84.22367 89.71077
    66.20956 7.51127 90.73933 Model 4 128.11793 270.14732 5.36148 0.97810 0.08356
    75.58935 83.00671 54.00412 2.18792 84.03542 Model 5 86.31067 119.19700 6.74956
    0.99653 0.03497 63.76529 61.48652 63.46340 0.29803 61.85302 Model 6 85.84263 118.73667
    6.65071 0.99655 0.03486 63.56773 61.33721 62.92035 0.29602 61.73264 Model 7 32.74015
    47.56720 2.65393 0.99946 0.01382 4.47686 3.49041 7.07894 0.00400 3.47323 Model
    8 31.27442 45.90691 2.46606 0.99950 0.01334 – – – – – The detailed results for
    the experiment with Datasets 3 and 4 considered in this section are presented
    in Table 6, Table 7. These results included five common evaluation metrics for
    all models. Remark: The SCFI data rule is different from the CCFI data rule, but
    it is also impacted by the epidemic, and the system performance based on the two
    datasets is still different. However, the improvement rate between the system
    and other models, particularly the percent improvement of MSE (PMSE) and percent
    improvement of RMSE (PRMSE) values for the system based on Dataset 4, further
    demonstrate the prediction stability and superiority of the proposed system. 5.6.
    Experiment IV: Evaluating based on FE and GRA To further demonstrate the superiority
    of the real-time multi-step forecasting system, the FE is applied to demonstrate
    the prediction accuracy of each model. Simultaneously, GRD is selected to reveal
    the correlation between the predicted and actual data. The forecasting performance
    results and grey relational degree for each model applied on the two datasets
    are presented in Table 8. According to the index attribute, the higher the index
    result, the better is the prediction performance of the model. Table 8. Results
    for the FE and GRD based on CCFI. Models Dataset 1 Dataset 2 Models FE-1 FE-2
    GRA FE-1 FE-2 GRA 1 STEP Model 1 0.9799 0.9639 0.6977 0.9148 0.7864 0.7810 Model
    2 0.9821 0.9678 0.7104 0.9173 0.7941 0.7940 Model 3 0.9918 0.9844 0.8472 0.9541
    0.8831 0.8526 Model 4 0.9924 0.9862 0.8475 0.9692 0.9197 0.9151 Model 5 0.9889
    0.9795 0.7931 0.9875 0.9763 0.9626 Model 6 0.9890 0.9797 0.7934 0.9878 0.9763
    0.9634 Model 7 0.9927 0.9867 0.8456 0.9914 0.9844 0.9754 Model 8 0.9933 0.9877
    0.8581 0.9923 0.9864 0.9772 2 STEP Model 1 0.9717 0.9497 0.6932 0.9107 0.7873
    0.8162 Model 2 0.9737 0.9523 0.6977 0.9126 0.7917 0.8222 Model 3 0.9910 0.9836
    0.8780 0.9490 0.8789 0.8676 Model 4 0.9922 0.9855 0.8778 0.9619 0.9055 0.9129
    Model 5 0.9796 0.9641 0.7412 0.9770 0.9561 0.9316 Model 6 0.9798 0.9643 0.7422
    0.9773 0.9575 0.9458 Model 7 0.9922 0.9859 0.8742 0.9889 0.9803 0.9717 Model 8
    0.9929 0.9869 0.8855 0.9899 0.9818 0.9739 3 STEP Model 1 0.9639 0.9369 0.6879
    0.9026 0.7763 0.8366 Model 2 0.9681 0.9417 0.6981 0.9037 0.7802 0.8422 Model 3
    0.9881 0.9776 0.8774 0.9422 0.8629 0.8806 Model 4 0.9892 0.9798 0.8684 0.9548
    0.8873 0.9367 Model 5 0.9716 0.9501 0.7128 0.9660 0.9368 0.9067 Model 6 0.9721
    0.9504 0.7190 0.9671 0.9383 0.9357 Model 7 0.9911 0.9843 0.8781 0.9874 0.9766
    0.9711 Model 8 0.9914 0.9844 0.8820 0.9878 0.9781 0.9734 The evaluation criterion
    values for FE and GRD of the proposed forecasting system using Datasets 1 and
    2 in one-step to three-step forecasting are both higher than those of other benchmark
    models, signifying that the proposed system outperforms the other models in terms
    of containerized freight index forecasting performance. Although the order of
    FE-1 and FE-2 is inconsistent, nevertheless, we can still quantitatively evaluate
    the positive effect of the data preprocessing module and rolling forecasting by
    comparing the developed forecasting system with Models 4 and 5. Additionally,
    the values for GRD for Models 1 to 8 in Dataset 2 are 0.7810, 0.7940, 0.8526,
    0.915, 0.9626, 0.9634, 0.9754, and 0.9772, respectively. Hence, we can further
    evaluate the effectiveness of the developed forecasting system using FE and GRD
    in addition to the MAE, RMSE, and MAPE presented in the above section. 6. Discussion
    In this section, the improvement percentages between several groups of comparison
    models are discussed to show the contribution of each system component based on
    Datasets 1 and 2. Next, the strength of the correlation between the actual and
    predicted data is determined using the Pearson test. Then, the performance of
    the dataset before and after the epidemic is discussed in detail. Finally, convolutional
    neural networks-based model is implemented, further demonstrating the advantages
    of the proposed system. 6.1. Discussion I: Improvement percentages To demonstrate
    the advantages of the developed prediction system and draw some important findings,
    the improvement percentages of MAE, RMSE, and MAPE among some models are discussed.
    The results of the percent improvement are shown in Table 9, which can quantify,
    compare, and analyze the contribution of each component in the developed real-time
    forecasting system. Meanwhile, it shows the situation of selecting different datasets
    for CCFI forecasting before and after the epidemic. Table 9. Improvement percentages
    of the comparison models. Metric Dataset 1 Dataset 2 Dataset 1 Dataset 2 Model
    5 → Model 1 Model 6 → Model 2 Performance of forecasting method PMAE(%) 31.6330
    84.0981 24.7050 84.3604 PRMSE(%) 31.6057 88.7563 25.8119 88.9606 PMAPE(%) 31.4735
    74.8763 24.7229 75.0561 PIA(%) 2.6742 33.1361 2.0261 30.1058 PTIC(%) 31.7741 89.9441
    25.7667 90.1022 Performance of Hampel technology Model 4 → Model 3 Model 8 → Model
    7 PMAE(%) 8.2759 16.9760 7.0866 6.5346 PRMSE(%) 7.3154 12.1717 5.6032 6.0318 PMAPE(%)
    9.8881 23.2834 6.9370 7.4759 PIA(%) 0.1532 1.3460 0.0476 0.0050 PTIC(%) 7.1647
    12.1401 5.5869 6.0471 Performance of CEEMDAN-PE Model 3 → Model 1 Model 4 → Model
    2 PMAE(%) 65.4985 46.5819 64.6700 54.6294 PRMSE(%) 64.3939 47.5075 63.7759 53.1173
    PMAPE(%) 64.9742 43.2205 64.7922 55.4254 PIA(%) 5.1066 26.9530 4.5642 25.7104
    PTIC(%) 64.4519 50.6915 63.6691 55.8771 The improvement percentages of the average
    values for multi-step prediction results in some models based on Datasets 1 and
    2 are shown in Table 9. It can be concluded that: First, by contrasting the improvement
    percentages between Models 5 to 1 and Models 6 to 2, the effectiveness of the
    real-time forecasting method relative to the basic method can be validated. Meanwhile,
    the contribution of the real-time forecasting method can be demonstrated. Second,
    compared with Models 4 and 3 and Models 8 and 7, the effectiveness of the Hampel
    method is evaluated on the models using the fixed set prediction and real-time
    prediction methods, respectively. Third, according to the comparison results,
    the contribution of each component and the reason for selection are clearly displayed.
    On average, all the improvement percentages are significant and positive. Therefore,
    it can be confirmed that the proposed real-time prediction system performs well
    in the containerized freight index. 6.2. Discussion II: Correlation strength test
    In this section, the Pearson test is employed to determine the strength of the
    correlation between actual and predicted values to verify that the developed real-time
    multi-step forecasting system with a three-stage data preprocessing strategy based
    on streaming data outperforms the other models. According to the Pearson test,
    an absolute correlation coefficient value closer to 1 denotes a stronger linear
    correlation, whereas an absolute correlation coefficient value closer to 0 denotes
    a weaker correlation. The results of the Pearson test for multi-step prediction
    based on all models tested on Datasets 1 and 2 are shown in Table 10; the Pearson
    test results for the developed real-time prediction system are outstanding. Table
    10. Results for Pearson test. Empty Cell Dataset 1 Dataset 2 Empty Cell 1 STEP
    2 STEP 3 STEP 1 STEP 2 STEP 3 STEP Model 1 0.94691 0.89772 0.84734 0.94783 0.95412
    0.95005 Model 2 0.95583 0.90423 0.86145 0.95186 0.95694 0.95258 Model 3 0.99269
    0.99180 0.98908 0.98341 0.98308 0.97700 Model 4 0.99255 0.99173 0.98660 0.99496
    0.98927 0.99311 Model 5 0.98335 0.94692 0.89660 0.99920 0.99738 0.99423 Model
    6 0.98359 0.94720 0.89789 0.99921 0.99764 0.99483 Model 7 0.99250 0.99146 0.98994
    0.99974 0.99947 0.99894 Model 8 0.99372 0.99292 0.98964 0.99975 0.99951 0.99913
    6.3. Discussion III: Comparison of datasets before and after the epidemic situation
    According to the characteristics of basic data in Fig. 2 and the statistical indicators
    in Table 3, the epidemic’s major emergency has a significant impact on the container
    freight market, which further tests the stability of the proposed system. Some
    important conclusions are drawn from the CCFI forecasting using the two datasets.
    First, Datasets 1 and 2 have significantly different prediction effects. The comparison
    results of the average improvement rate of evaluation criteria for the proposed
    system compared to other models from one-step forecasting to three-step forecasting
    are shown in Table 11. All evaluation indexes for Dataset 1 perform better, but
    the improvement percentages of evaluation indexes based on Dataset 2 in the proposed
    real-time prediction system perform significantly better. The results demonstrate
    the real-time system’s exceptional stability and generalization ability. Particularly
    when the streaming data fluctuate violently in a short time, the effect of a real-time
    forecasting system is more stable and effective. According to a comparative study
    of multi-step forecasting, the improvement of evaluation indicators shows that
    two-step forecasting is better than one-step forecasting, three-step forecasting
    is better than all. The results demonstrate that the two-step and three-step prediction
    capabilities of real-time forecasting system are better than other models. Table
    11. Results of average improvement percentages. Dataset Average improvement percentages
    PMAE(%) PRMSE(%) PMAPE(%) PIA(%) PTIC(%) Dataset 1 1 STEP 35.35438 34.34146 35.58948
    0.83218 34.32894 2 STEP 45.21662 44.33545 45.18482 2.21266 44.27163 3 STEP 48.10140
    47.61627 48.34563 3.85940 47.66968 Dataset 2 1 STEP 65.34834 67.52432 60.94901
    10.01790 67.75355 2 STEP 68.49564 69.47673 64.79083 9.71828 69.82799 3 STEP 68.72367
    69.69968 65.18312 11.36756 70.19556 Second, the improvement rates for Model 4
    compared with Model 1 and those of Model 5 compared with Model 1, as shown in
    Table 12, reflect the contribution of the data preprocessing module based on one-time
    decomposition and the real-time forecasting method using the two datasets, respectively.
    It is reasonable to conclude from comparing the performance improvement rates
    on the two datasets, for dataset 1, the data preprocessing module based on one-time
    decomposition performs better than the real-time forecasting method; however,
    for dataset 2, the opposite is true. It has been demonstrated that the same system
    performs differently on different datasets, but for the streaming data of sudden
    instability, the real-time forecasting method is more effective for increasing
    the forecasting accuracy. Table 12. Results of improvement percentages. Improvement
    percentages Dataset 1 Dataset 2 Empty Cell Empty Cell 1 STEP 2 STEP 3 STEP 1 STEP
    2 STEP 3 STEP Model 4 →Model 1 PMAE(%) 62.4189 72.6280 69.7914 64.0757 50.6069
    52.4830 PRMSE(%) 61.5591 71.4111 67.9623 62.5738 48.8667 51.3719 PMAPE(%) 62.5010
    72.5730 70.0083 63.8722 51.5253 53.5792 PIA(%) 2.3938 5.2588 8.1525 30.5353 25.3700
    30.0950 PTIC(%) 61.5264 71.4526 67.9355 65.2679 51.7768 54.2068 Model 5 →Model
    1 PMAE(%) 45.4529 28.2693 21.1767 90.9956 84.1554 77.1434 PRMSE(%) 44.8324 29.1878
    20.7969 93.8015 88.7017 83.7658 PMAPE(%) 45.0536 28.0484 21.3186 85.2978 74.2049
    65.1262 PIA(%) 1.9619 2.8647 3.1947 33.3885 30.7685 35.2511 PTIC(%) 44.9253 29.3326
    21.0479 94.4764 89.8885 85.4697 6.4. Discussion IV: Comparison of convolutional
    neural networks (CNN)-based model In this section, convolutional neural networks-based
    model is discussed as comparison, further demonstrating the advantages of the
    proposed system. H-CEEMDAN-PE-CNN-R is selected for comparative model which are
    marked as Model 9. The results of CNN-based model and the proposed system for
    CCFI are shown in Table 13. Meanwhile, some conclusions can be reached. CNN-based
    model is more complex and its training time takes much longer. Conclusions different
    from ELM, the evaluation indexes for Dataset 1 and 2 sets on CNN-based model is
    similar. It can be seen that CNN with the proposed strategy has good performance,
    however it is still slightly inferior to the ELM-based model. Table 13. Results
    of CNN-based model and the proposed system for CCFI. Empty Cell Models Evaluation
    Empty Cell MAE RMSE MAPE IA TIC Dataset 1 1 STEP Model 8 5.23141 6.89025 0.66521
    0.99673 0.00433 Model 9 11.64484 14.95562 1.48373 0.98449 0.00731 2 STEP Model
    8 5.57481 7.33066 0.70972 0.99629 0.00461 Model 9 14.27782 17.54968 1.81123 0.97583
    0.00966 3 STEP Model 8 6.78939 8.82339 0.86224 0.99458 0.00554 Model 9 17.76953
    21.58435 1.93194 0.96512 0.01617 Dataset 2 1 STEP Model 8 9.08242 14.09484 0.76826
    0.99986 0.00553 Model 9 12.21735 15.66997 1.54953 0.98341 0.00769 2 STEP Model
    8 12.38408 20.60466 1.01373 0.99970 0.00809 Model 9 17.49218 21.84954 2.13245
    0.88673 0.01585 3 STEP Model 8 15.98105 27.81717 1.22126 0.99946 0.01093 Model
    9 19.86253 24.96055 2.50461 0.85514 0.02132 7. Conclusion The container market
    is the most significant component of maritime trade, which contributes significantly
    to the overall national or regional economic. Therefore, accurate prediction of
    containerized freight index is of great significance to the government shipping
    market and its participants. However, because of the impact of emergencies, its
    complexity, nonlinear characteristics, and the concept drift problem, containerized
    freight index modeling and forecasting is still a challenging task. Considering
    this, to achieve high precision, excellent universality, and robust prediction
    performance, a novel real-time multi-step forecasting system with a three-stage
    data preprocessing strategy based on containerized freight index streaming data
    is developed. The system successfully addresses the shortcomings associated with
    the containerized freight index prediction without compromising the advantages
    of accuracy, stability, and universality. Four time series datasets with different
    characteristics gathered from the CCFI and SCFI are used as cases for multi-step
    forecasting research to confirm the effectiveness of the real-time system. The
    comparison results demonstrate that the system can significantly outperform the
    comparison models in terms of prediction accuracy, stability, and generalization,
    making it more appropriate for multi-step container freight index forecasting.
    In summary, the real-time prediction system proposed in this study can provide
    accurate and stable containerized freight index forecasting results for decision-makers
    and shipping participating enterprises, particularly in the post epidemic period,
    which provides a new feasible choice for the time series forecasting of the shipping
    price index. Considering the developed system’s excellent and reasonable forecasting
    capabilities, the system is better able to withstand data instability and the
    sudden situation of the market, making it possible to popularize other time series
    forecasting in other fields, such as metal prices and the energy market. Moreover,
    considering the characteristics of large data volume and long running time required
    for deep learning models, these methods were not adopted in this article. However,
    there has been some research on the forecasting field of deep learning models
    under the influence of COVID-19 (Bassiouni et al., 2023, Shankar et al., 2020).
    In the future, improved deep learning models can be considered for predictive
    analysis of the container market. Meanwhile, the factors, such as national policy,
    shipping price, and container turnover, can be further considered for multi-factor
    studies. Conflict of interest The authors declare that there are no conflicts
    of interest regarding the publication of this paper. CRediT authorship contribution
    statement Kedong Yin: Conceptualization, Methodology, Funding acquisition. Hongbo
    Guo: Conceptualization, Methodology, Writing – review & editing, Validation. Wendong
    Yang: Conceptualization, Methodology, Funding acquisition. Declaration of competing
    interest The authors declare that they have no known competing financial interests
    or personal relationships that could have appeared to influence the work reported
    in this paper. Acknowledgments This work was supported by Humanities and Social
    Science Fund of the Ministry of Education of the People’s Republic of China (Grant
    No. 21YJCZH198); Major Program of the National Social Science Foundation of China
    (Grant No. 22&ZD126); National Natural Science Foundation of China (Grant No.
    72301157, 72101138); and Natural Science Foundation of Shandong Province, China
    (Grant No. ZR2021QG034, ZR2022QG036). Data availability Data will be made available
    on request. References Abouarghoub et al., 2018 W. Abouarghoub, N.K. Nomikos,
    F. Petropoulos On reconciling macro and micro energy transport forecasts for strategic
    decision making in the tanker industry Transportation Research Part E Logistics
    and Transportation Review, 11 (113) (2018), pp. 225-238, 10.1016/j.tre.2017.10.012
    View PDFView articleView in ScopusGoogle Scholar Ak, 2019 A. Ak Volatility spillover
    from global container freight indices to port throughputs in turkey International
    Journal of Economics and Innovation, 5 (1) (2019), pp. 101-113 10.20979/ueyd.519545
    Google Scholar Albuquerque et al., 2022 P.C. Albuquerque, D.O. Cajueiro, M. Rossi
    Machine learning models for forecasting power electricity consumption using a
    high dimensional dataset Expert Systems with Application(Jan.), 187 (115917) (2022),
    10.1016/j.eswa.2021.115917 Google Scholar Ansorena, 2019 I.L. Ansorena Forecasting
    of traffic flows at ferry terminals. a hybrid model International Journal of Agile
    Systems and Management, 12 (1) (2019), pp. 27-43, 10.1504/IJASM.2019.10019943
    View in ScopusGoogle Scholar Azab and Morita, 2022 A. Azab, H. Morita Coordinating
    truck appointments with container relocations and retrievals in container terminals
    under partial appointments information Transportation Research Part E: Logistics
    and Transportation Review, 160 (2022), Article 102673, 10.1016/j.tre.2022.102673
    View PDFView articleView in ScopusGoogle Scholar Bhowmik and Jelfs, 2017 Bhowmik,
    S., Jelfs, B. (2017). Arjunan, S.P., & Kumar, D. K., Outlier removal in facial
    surface electromyography through Hampel filtering technique, 2017 IEEE Life Sciences
    Conference (LSC). IEEE , 258-261. https://doi.org/10.1109/LSC.2017.8268192. Google
    Scholar Bandt and Pompe, 2002 C. Bandt, B. Pompe Permutation entropy: A natural
    complexity measure for time series Physical Review Letters, 88 (17) (2002), Article
    174102, 10.1103/PhysRevLett.88.174102 Google Scholar Bassiouni et al., 2023 M.M.
    Bassiouni, R.K. Chakrabortty, O.K. Hussain, H.F. Rahman Advanced deep learning
    approaches to predict supply chain risks under COVID-19 restrictions Expert Systems
    with Application, 211 (2023), Article 118604, 10.1016/j.eswa.2022.118604 View
    PDFView articleView in ScopusGoogle Scholar Castilla-Rodriguez et al., 2020 I.
    Castilla-Rodriguez, C. Exposito-Izquierdo, B. Melian-Batista, R.M. Aguilar, J.M.
    Moreno-Vega Simulation-optimization for the management of the transshipment operations
    at maritime container terminals Expert Systems with Application, 139 (1) (2020),
    pp. 1-10, 10.1016/j.eswa.2019.112852 Google Scholar Du et al., 2019a Du, P., Wang,
    J, Yang, W., & Niu, T. (2019a). Container throughput forecasting using a novel
    hybrid learning method with error correction strategy. Knowledge-Based Systems,182,
    104853.1-104853.12. https://doi.org/10.1016/j.knosys.2019.07.024. Google Scholar
    Chao-Chi, 2015 C. Chao-Chi Long memory analysis of container freight indices with
    volatility process Nephron Clinical Practice, 14 (2015), pp. 52-67, 10.6665/JLYIT.2015.14.52
    Google Scholar Chen et al., 2017 F. Chen, Y. Miao, K. Tian, X. Ding, T. Li Multifractal
    cross-correlations between crude oil and tanker freight rate Physica A: Statistical
    Mechanics and Its Applications, 474 (2017), pp. 344-354, 10.1016/j.physa.2017.01.069
    View PDFView articleView in ScopusGoogle Scholar Chen and Chen, 2010 S.H. Chen,
    J.N. Chen Forecasting container throughputs at ports using genetic programming
    Expert Systems with Application, 3 (37) (2010), pp. 2054-2058, 10.1016/j.eswa.2009.06.054
    View PDFView articleView in ScopusGoogle Scholar Chen et al., 2021 Z. Chen, X.
    Zhang, J. Chai The dynamic impacts of the global shipping market under the background
    of oil price fluctuations and emergencies Complexity, 1 (2021), pp. 1-13, 10.1155/2021/8826253
    View PDFView articleGoogle Scholar Coto-Millan and Inglada-Pérez, 2020 P. Coto-Millan,
    L. Inglada-Pérez Testing for nonlinearity and chaos in liquid bulk shipping Transportation
    Research Procedia, 48 (2) (2020), pp. 1605-1614, 10.1016/j.trpro.2020.08.202 View
    PDFView articleView in ScopusGoogle Scholar Du et al., 2019b P. Du, J. Wang, W.
    Yang, T. Niu A novel hybrid model for short-term wind power forecasting Applied
    Soft Computing, 80 (2019), pp. 93-106, 10.1016/j.asoc.2019.03.035 View PDFView
    articleView in ScopusGoogle Scholar Du, 2019 Du, Q. (2019). Forecasting and backtesting
    of var in international dry bulk shipping market under skewed distributions. American
    Journal of Industrial and Business Management, 09 (5), 1168-1186. https://doi.org/10.
    4236/ajibm.2019.95079. Google Scholar El-Dahshan et al., 2022 E.S.A. El-Dahshan,
    M.M. Bassiouni, A. Hagag, R.K. Chakrabortty, H. Loh, U.R. Acharya Rescovidtcnnet:
    A residual neural network-based framework for COVID-19 detection using TCN and
    EWT with chest x-ray images Expert Systems with Applications, 204 (2022), Article
    117410, 10.1016/j.eswa.2022.117410 View PDFView articleView in ScopusGoogle Scholar
    Feng and Niu, 2021 Z.K. Feng, W.J. Niu Hybrid artificial neural network and cooperation
    search algorithm for nonlinear river flow time series forecasting in humid and
    semi-humid regions European Journal of Medicinal Chemistry: Chimie Therapeutique,
    211 (2021), Article 106580, 10.1016/j.knosys.2020.106580 View PDFView articleView
    in ScopusGoogle Scholar Gavriilidis et al., 2018 K. Gavriilidis, D.S. Kambouroudis,
    K. Tsakou, D.A. Tsouknidis Volatility forecasting across tanker freight rates:
    The role of oil price shocks Transportation Research Part E: Logistics and Transportation
    Review, 118 (2018), pp. 376-391, 10.1016/j.tre.2018.08.012 View PDFView articleView
    in ScopusGoogle Scholar Guo et al., 2022 H. Guo, K. Yin, C. Huang Modeling of
    direct economic losses of storm surge disasters based on a novel hybrid forecasting
    system Frontiers in Marine Science, 8 (2022), Article 804541, 10.3389/fmars.2021.804541
    View in ScopusGoogle Scholar Hao and Tian, 2018 Y. Hao, C. Tian The study and
    application of a novel hybrid system for air quality early-warning Applied Soft
    Computing, 74 (2018), pp. 729-746, 10.1016/j.asoc.2018.09.005 Google Scholar Hao
    et al., 2020 Y. Hao, C. Tian, C. Wu Modelling of carbon price in two real carbon
    trading markets Journal of Cleaner Production, 244 (2020), Article 118556, 10.1016/j.jclepro.2019.118556
    View PDFView articleView in ScopusGoogle Scholar Hasan et al., 2021 M.B. Hasan,
    M. Mahi, T. Sarker, M.R. Amin Spillovers of the covid-19 pandemic: Impact on global
    economic activity, the stock market, and the energy sector Journal of Risk and
    Financial Management, 14 (5) (2021), pp. 1-18, 10.3390/jrfm14050200 View in ScopusGoogle
    Scholar Huang et al., 2004 Huang, G. Bin, Zhu, Q.Y., Siew, C.K. (2004). Extreme
    learning machine: a new learning scheme of feedforward neural networks. In: IEEE
    International Conference on Neural Networks - Conference Proceedings, 25-29. https://doi.org/10.1109/IJCNN.2004.
    1380068. Google Scholar Ishizaka et al., 2018 M. Ishizaka, K. Tezuka, M. Ishii
    Evaluation of risk attitude in the shipping freight market under uncertainty Maritime
    Policy & Management, 45 (2018), pp. 1042-1056, 10.1080/03088839.2018.1463107 View
    in ScopusGoogle Scholar Jafari and Rahimi, 2018 H. Jafari, G. Rahimi Forecasting
    dirty tanker freight rate index by using stochastic differential equations International
    Journal of Financial Engineering, 05 (04) (2018), pp. 637-659, 10.1142/S2424786318500342
    Google Scholar Jurdana et al., 2020 Jurdana, I., Krylov, A., & Yamnenko, J. (2020).
    Use of artificial intelligence as a problem solution for maritime transport. Journal
    of Marine Science and Engineering, 8 (3), 201.1. https://doi.org/0.3390/jmse8030201.
    Google Scholar Jun et al., 2021 B. Jun, B. Jca, Y.C. Shan, C.B. Ming Short-term
    forecasting of natural gas prices by using a novel hybrid method based on a combination
    of the ceemdan-se-and the pso-als-optimized gru network Energy, 233 (1) (2021),
    Article 121082, 10.1016/j.energy.2021.121082 Google Scholar Kamal et al., 2020
    I.M. Kamal, H. Bae, S. Sunghyun, H. Yun Dern: Deep ensemble learning model for
    short- and long-term prediction of baltic dry index Applied Sciences, 10 (4) (2020),
    p. 1504, 10.3390/app10041504 View in ScopusGoogle Scholar Kim et al., 2019 D.
    Kim, H. Kim, S. Sim, Y. Choi, H. Yun Prediction of dry bulk freight index using
    deep learning Journal of Korean Institute of Industrial Engineers, 45 (2) (2019),
    pp. 111-116, 10.7232/JKIIE.2019.45.2. 111 Google Scholar Kuca, 2020 K. Kuca The
    2019 novel coronavirus (covid-19) outbreak in china and world: A new lesson for
    public health system Letters in Drug Design & Discovery, 17 (2020), pp. 364-365,
    10.2174/1570180817999200317145125 View in ScopusGoogle Scholar Kuo et al., 2020
    P.L. Kuo, C.L. Chiu, C.S. Chen, M.C. Wang The dynamic relationships between the
    baltic dry index and the brics stock markets: A wavelet analysis Asian Economic
    and Financial Review, 10 (3) (2020), pp. 340-351 10.18488/journal.aefr.2020.103.340.351
    CrossRefView in ScopusGoogle Scholar Kurt et al., 2021 I. Kurt, M. Aymelek, E.
    Boulougouris, O. Turan Operational cost analysis for a container shipping network
    integrated with offshore container port system: A case study on the west coast
    of north america Marine Policy, 126 (2021), Article 104400, 10.1016/j.marpol.2021.104400
    View PDFView articleView in ScopusGoogle Scholar Liu et al., 2022 J. Liu, P. Wang,
    H. Chen, J. Zhu A combination forecasting model based on hybrid interval multi-scale
    decomposition: Application to interval-valued carbon price forecasting Expert
    Systems with Application(Apr.), 191 (2022), Article 116267, 10.1016/j.eswa.2021.116267
    View PDFView articleView in ScopusGoogle Scholar Li et al., 2021 W. Li, J. Dai,
    Y. Xiao, S. Yang, C. Song Estimating waterway freight demand at three gorges ship
    lock on yangtze river by backpropagation neural network modeling Maritime Economics
    & Logistics, 23 (611) (2021), pp. 1-27, 10.1057/s41278-020-00169-0 Google Scholar
    Munim and Schramm, 2016 Z.H. Munim, H.J. Schramm Forecasting container shipping
    freight rates for the far east- northern europe trade lane Maritime Economics
    & Logistics, 19 (2016), pp. 106-125, 10.1057/s41278-016-0051-7 Google Scholar
    Munim and Schramm, 2021 Z.H. Munim, H.J. Schramm Forecasting container freight
    rates for major trade routes: A comparison of artificial neural networks and conventional
    models Maritime Economics & Logistics, 23 (2021), pp. 310-327, 10.1057/s41278-020-00156-5
    View in ScopusGoogle Scholar Pao, 2008 H.T. Pao A comparison of neural network
    and multiple regression analysis in modeling capital structure Expert Systems
    with Application, 3 (35) (2008), pp. 720-727, 10.1016/j.eswa.2007.07.018 View
    PDFView articleView in ScopusGoogle Scholar Pearson, 2002 R.K. Pearson Outliers
    in process modeling and identification IEEE Transactions on Control Systems Technology,
    10 (1) (2002), pp. 55-63, 10.1109/87.974338 View in ScopusGoogle Scholar Ping
    et al., 2021 J.A. Ping, B. Zl, C. Jw, B. Lz Decomposition-selection-ensemble forecasting
    system for energy futures price forecasting based on multi-objective version of
    chaos game optimization algorithm Resources Policy, 73 (2021), Article 102234,
    10.1016/j.resourpol.2021.102234 Google Scholar Población and Serna, 2021 J. Población,
    G. Serna Measuring bulk shipping prices risk Maritime Economics & Logistics, 23
    (2021), pp. 291-309, 10.1057/s41278-019-00129-3 View in ScopusGoogle Scholar Rousset
    and Ducruet, 2020 L. Rousset, C. Ducruet Disruptions in spatial networks: A comparative
    study of major shocks affecting ports and shipping patterns Networks and Spatial
    Economics, 20 (2020), pp. 423-447, 10.1007/s11067-019-09482-5 View in ScopusGoogle
    Scholar Ruiz-Aguilar and Turias, IGonzalez-Enrique, J. Urda, D. Elizondo, D. ,
    2021 Ruiz-Aguilar, J. J.Turias, IGonzalez-Enrique, J.Urda, D.Elizondo, D. (2021).
    A permutation entropy-based emd-ann forecasting ensemble approach for wind speed
    prediction. Neural computing & applications, 33(7), 2369-2391. https://doi.org/10.1007/s00521-020-05141-w.
    Google Scholar Shankar et al., 2020 S. Shankar, P.V. Ilavarasan, S. Punia, S.P.
    Singh Forecasting container throughput with long short-term memory networks Industrial
    Management & Data Systems, 120 (3) (2020), pp. 425-441, 10.1108/IMDS-07-2019-0370
    View in ScopusGoogle Scholar Si et al., 2019 L. Si, Z. Wang, C. Tan, X. Liu A
    feature extraction method based on composite multi-scale permutation entropy and
    laplacian score for shearer cutting state recognition Measurement, 145 (2019),
    pp. 84-93, 10.1016/j.measurement.2019.05.070 View PDFView articleView in ScopusGoogle
    Scholar Teplova et al., 2019 T.V. Teplova, V.V. Lysenko, T.V. Sokolova Shocks
    to supply and demand in the oil market, the equilibrium oil price, and country
    responses in economic indicators Energy Systems, 10 (4) (2019), pp. 843-869, 10.1007/s12667-018-0303-y
    View in ScopusGoogle Scholar Torres et al., 2011 Torres M.E., Colominas M.A.,
    Schlotthauer G., & Flandrin P. (2011). A complete ensemble empirical mode decomposition
    with adaptive noise. IEEE International Conference on Acoustics. IEEE, 12176054.
    https://doi.org/10.1109/ICASSP.2011.5947265. Google Scholar Tsatsaronis et al.,
    2019 Tsatsaronis, M., Syriopoulos, T., & Karamanos, I. (2019). Shipping Freights
    Forecasting using Machine Learning Methods. International Conference on Business
    & Economics of the Hellenic Open University 2019. Google Scholar Tu and Chen,
    2021 L. Tu, Y. Chen An unequal adjacent grey forecasting air pollution urban model
    Applied Mathematical Modelling, 99 (2021), pp. 260-275, 10.1016/j.apm.2021.06.025
    View PDFView articleView in ScopusGoogle Scholar Urolagin et al., 2021 S. Urolagin,
    N. Sharma, T.K. Datta A combined architecture of multivariate lstm with mahalanobis
    and z-score transformations for oil price forecasting Energy, 231 (2021), Article
    120963, 10.1016/j.energy.2021.120963 View PDFView articleView in ScopusGoogle
    Scholar Wang and Liu, 2018 D. Wang, W. Liu International dry bulk shipping market
    supply and demand and bdi index forecasting research——based on the analysis of
    simultaneous equation models Price: Theory & Practice, 6 (2018), pp. 78-81 10.19851/j.cnki.cn11-1010/f.2018.0
    View in ScopusGoogle Scholar Wang et al., 2018 J. Wang, W. Yang, D. Pei, N. Tong
    A novel hybrid forecasting system of wind speed based on a newly developed multi-objective
    sine cosine algorithm Energy Conversion and Management, 163 (2018), pp. 134-150,
    10.1016/j.enconman.2018.02.012 View PDFView articleView in ScopusGoogle Scholar
    Wen et al., 2022 K. Wen, G. Zhao, B. He, J. Ma, H. Zhang A decomposition-based
    forecasting method with transfer learning for railway short-term passenger flow
    in holidays Expert Systems with Application(Mar.), 189 (2022), Article 116102,
    10.1016/j.eswa.2021.116102 View PDFView articleView in ScopusGoogle Scholar Wu
    et al., 2022 C. Wu, J. Wang, Y. Hao Deterministic and uncertainty crude oil price
    forecasting based on outlier detection and modified multi-objective optimization
    algorithm Resources Policy, 77 (2022), Article 102780, 10.1016/j.resourpol.2022.102780
    View PDFView articleView in ScopusGoogle Scholar Wu et al., 2020 Z. Wu, X. Xia,
    L. Xiao, Y. Liu Combined model with secondary decomposition-model selection and
    sample selection for multi-step wind power forecasting Applied Energy, 261 (2020),
    Article 114345, 10.1016/j.apenergy.2019.114345 View PDFView articleView in ScopusGoogle
    Scholar Xiao et al., 2021 W. Xiao, C. Xu, H. Liu, X. Liu A hybrid lstm-based ensemble
    learning approach for china coastal bulk coal freight index prediction Journal
    of Advanced Transportation, 4 (2021), pp. 1-23, 10.1155/2021/5573650 Google Scholar
    Xu and Yin, 2021 H. Xu, Z. Yin The optimal icebreaking tariffs and the economic
    performance of tramp shipping on the northern sea route Transportation Research
    Part A Policy and Practice, 149 (610) (2021), pp. 76-97, 10.1016/j.tra.2021.04.017
    View PDFView articleView in ScopusGoogle Scholar Xu et al., 2019 S. Xu, H.K. Chan,
    T. Zhang Forecasting the demand of the aviation industry using hybrid time series
    sarima-svr approach Transportation Research Part E: Logistics and Transportation
    Review, 122 (2019), pp. 169-180, 10.1016/j.tre.2018.12.005 View PDFView articleView
    in ScopusGoogle Scholar Yang et al., 2019a W. Yang, J. Wang, T. Niu, P. Du A hybrid
    forecasting system based on a dual decomposition strategy and multi-objective
    optimization for electricity price forecasting Applied Energy, 235 (2) (2019),
    pp. 1205-1225, 10.1016/j.apenergy.2018.11.034 View PDFView articleView in ScopusGoogle
    Scholar Yang et al., 2022 W. Yang, M. Hao, Y. Hao Innovative ensemble system based
    on mixed frequency modeling for wind speed point and interval forecasting Information
    Sciences (2022), 10.1016/j.ins.2022.11.145 Google Scholar Yang et al., 2019 W.
    Yang, J. Wang, H. Lu, T. Niu, P. Du Hybrid wind energy forecasting and analysis
    system based on divide and conquer scheme: A case study in China Journal of Cleaner
    Production, 222 (6) (2019), pp. 942-959, 10.1016/j.jclepro.2019.03.036 View PDFView
    articleView in ScopusGoogle Scholar Yang et al., 2019c W. Yang, J. Wang, T. Niu,
    P. Du A novel system for multi-step electricity price forecasting for electricity
    market management Applied Soft Computing, 88 (2019), pp. 281-297, 10.1016/j.asoc.2019.106
    029 View in ScopusGoogle Scholar Yang and Mehmed, 2019 Z. Yang, E.E. Mehmed Artificial
    neural networks in freight rate forecasting Maritime Economics & Logistics, 21
    (3) (2019), pp. 390-414, 10.1057/s41278-019-00121-x View in ScopusGoogle Scholar
    Zhang et al., 2022a Zhang, K., Yin, K., & Yang, W. (2022a). Predicting bioenergy
    power generation structure using a newly developed grey compositional data model:
    A case study in China. Renewable Energy, 198, 695-711. https://doi.org/10.10 16/j.renene.2022.08.050.
    Google Scholar Zhang and Mani, 2021 Zhang, S., & Mani, G. (2021). Popular cryptoassets
    (Bitcoin, Ethereum, and Dogecoin), Gold, and their relationships: Volatility and
    correlation modeling. Data Science and Management, 4, 30-39. https://doi.org/10.
    1016/j.dsm.2021.11.001. Google Scholar Zhang et al., 2023 K. Zhang, K. Yin, W.
    Yang Probabilistic accumulation grey forecasting model and its properties Expert
    Systems with Applications, 223 (2023), p. 119889, 10.1016/j.eswa.2023.119889 View
    PDFView articleView in ScopusGoogle Scholar Zhang et al., 2022 S. Zhang, C. Wang,
    P. Liao, L. Xiao, T. Fu Wind speed forecasting based on model selection, fuzzy
    cluster, and multi-objective algorithm and wind energy simulation by betz''s theory
    Expert Systems with Application(May), 193 (2022), Article 116509, 10.1016/j.eswa.2022.116509
    View PDFView articleView in ScopusGoogle Scholar Zhang et al., 2019 X. Zhang,
    M.Y. Chen, M.G. Wang, Y.E. Ge, H.E. Stanley A novel hybrid approach to baltic
    dry index forecasting based on a combined dynamic fluctuation network and artificial
    intelligence method Applied Mathematics and Computation, 36 (2019), pp. 499-516,
    10.1016/j.amc.2019.05.043 View PDFView articleGoogle Scholar Zhang and Ding, 2016
    Z.P. Zhang, T. Ding Short-term analysis and forecasting of yangtze river container
    freight index based on arima-arch model Logistics Technology, 035 (006) (2016),
    pp. 86-89, 10.3969/j.issn.1005-152X.2016.06.019 View in ScopusGoogle Scholar Zhao
    and Tansuchat, 2019 Z. Zhao, R. Tansuchat Volatility spillover and co-movement
    among chinese shipping sector stock index, oil futures price, ocean freight charge
    and exchange rate Journal of Physics Conference Series, 1324 (2019), Article 012108,
    10.1088/1742-6596/1324/1/012108 View in ScopusGoogle Scholar Zhu et al., 2019
    J. Zhu, J. Liu, P. Wu, H. Chen, L. Zhou A novel decomposition-ensemble approach
    to crude oil price forecasting with evolution clustering and combined model International
    Journal of Machine Learning and Cybernetics, 10 (2019), pp. 3349-3362, 10.1007/s13042-019-00922-9
    View in ScopusGoogle Scholar Cited by (0) 1 ORCID: 0000-0003-3443-4432. View Abstract
    © 2024 Elsevier Ltd. All rights reserved. Recommended articles Detecting video
    anomalies by jointly utilizing appearance and skeleton information Expert Systems
    with Applications, Volume 246, 2024, Article 123135 Wenfeng Pang, …, Noman Ahmed
    View PDF A novel hybrid model for crude oil price forecasting based on MEEMD and
    Mix-KELM Expert Systems with Applications, Volume 246, 2024, Article 123104 Jingjing
    Li, …, Cuicui Yu View PDF BGaitR-Net: An effective neural model for occlusion
    reconstruction in gait sequences by exploiting the key pose information Expert
    Systems with Applications, Volume 246, 2024, Article 123181 Somnath Sendhil Kumar,
    …, Lipo Wang View PDF Show 3 more articles Article Metrics Captures Readers: 1
    View details About ScienceDirect Remote access Shopping cart Advertise Contact
    and support Terms and conditions Privacy policy Cookies are used by this site.
    Cookie settings | Your Privacy Choices All content on this site: Copyright © 2024
    Elsevier B.V., its licensors, and contributors. All rights are reserved, including
    those for text and data mining, AI training, and similar technologies. For all
    open access content, the Creative Commons licensing terms apply."'
  inline_citation: '>'
  journal: Expert Systems with Applications
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: A novel real-time multi-step forecasting system with a three-stage data preprocessing
    strategy for containerized freight market
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Saleh M.A.M.
  - Hicham A.
  - Maâti M.L.B.
  - Taha H.
  - Mohammed Y.M.A.
  citation_count: '0'
  description: Transporting containers advances the economy forward and hastens global
    transformation. Despite this swift change, ports face many difficulties, including
    how to store and extract containers. We provide a strategic, sustainable, dynamic
    model inspired by cubic data and artificial intelligence to solve the problem
    of container storage. This study creates a smart model based on cubic data and
    spatiotemporal data by integrating matrices into a multidimensional structure
    to overcome the uncertainty. The model proactively conjures data expressing yard
    components and examines what is compatible with or serves the situation it is
    trying to solve. This approach tries to bring together various concerned entities
    in the terminal yard, determine their properties and attributes, and process them
    in real-time. Moreover, the results of this study showed good agreement when compared
    with previous publications.
  doi: 10.1016/j.kjs.2023.100174
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Abstract Keywords Introduction Literature review Methodology Smart dynamic
    container stacking based on the data cubic model (SDCSDCM) Results and discussion
    Conclusions Declaration of competing interest Acknowledgments Data availability
    References Show full outline Figures (11) Show 5 more figures Tables (5) Table
    1 Table 2 Table 3 Table 4 Table 5 Kuwait Journal of Science Volume 51, Issue 2,
    April 2024, 100174 Full length article Development of a sustainable strategy model
    for predicting optimal container stacking locations in container yards using artificial
    intelligence and cubic data Author links open overlay panel Mohammed Ahmed Moqbel
    Saleh a c, Attariuas Hicham a, M.L. Ben Maâti a, Hatem Taha b, Yahya M.A. Mohammed
    a Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.kjs.2023.100174
    Get rights and content Under a Creative Commons license open access Abstract Transporting
    containers advances the economy forward and hastens global transformation. Despite
    this swift change, ports face many difficulties, including how to store and extract
    containers. We provide a strategic, sustainable, dynamic model inspired by cubic
    data and artificial intelligence to solve the problem of container storage. This
    study creates a smart model based on cubic data and spatiotemporal data by integrating
    matrices into a multidimensional structure to overcome the uncertainty. The model
    proactively conjures data expressing yard components and examines what is compatible
    with or serves the situation it is trying to solve. This approach tries to bring
    together various concerned entities in the terminal yard, determine their properties
    and attributes, and process them in real-time. Moreover, the results of this study
    showed good agreement when compared with previous publications. Previous article
    in issue Next article in issue Keywords Artificial intelligenceImprove container
    stackingMachine learningReal-time decisionStorage space allocation Introduction
    The transportation of goods in maritime environments and ports holds equal significance
    to the transportation of goods through air and land ports, as it accounts for
    a substantial portion of the worldwide commerce volume, estimated to be between
    70% and 80% (Sirimanne et al., 2019). The container terminals at each port serve
    as the central hub for coordinating all supply operations conducted within the
    facility, encompassing activities such as berthing, stacking, gate operations,
    and container drainage systems. The container transportation industry has experienced
    significant growth, leading to a doubling in the number of containers being transported.
    As a result, container stations are encountering challenges and operational difficulties
    due to the strain on their resources and existing infrastructure. This has subsequently
    led to a decline in productivity levels (Saxon and Stone, 2017). Gunawardhana
    et al. (2021), indicated that the issue relating to the real-time prediction and
    identification of the precise and best storage positions for newly arriving containers
    within the yard has not received much consideration in the literature. In container
    terminals, there are many resources, the most important of which are cranes, yards,
    and vehicles. The main objective of the plant operators is the efficient use of
    these resources while carrying out various operations (Salebeh and Debo, 2020).
    The containers remain awaiting truck, train, or ship conveyance. Stacking containers
    refers to the practice of arranging and placing containers on top of each other
    in a systematic manner, typically within a container yard or terminal. This is
    done to efficiently utilize available space and organize containers for storage,
    transport, or other logistical purposes. The process involves carefully positioning
    containers on top of each other in designated areas or slots within the yard,
    taking into consideration factors such as container type, size, weight, and accessibility
    for retrieval. The goal of stacking containers is to optimize space usage while
    ensuring easy access for loading, unloading, and transportation operations. Stacks
    impose access to only the top containers directly. If a container is set to be
    discharged but is buried under other containers, a rearrangement process will
    be necessary to access it, which is a non-productive movement (Saleh et al., 2023).
    This aligns precisely with our objective of minimizing the unproductive movement
    of containers or implementing reshuffling measures through the use of an AI model
    and cubic data. When searching for a solution to the problem, we should consider
    that many different sides participate in the completion of the storage process
    in the station’s yard, in which the interests of many parties intersect, the logistical
    players interact with the various interests within the station (Rodriguez-Molins
    et al., 2012), and each party has an important role that cannot be neglected,
    taking into account the uncertainties associated with storing newly arrived containers
    (Rekik and Elkosantini, 2019). According to Timmer (2012), he studied a method
    for retrieval of containers; the storage methods of containers based on the static
    and dynamic methodologies that different stations deal with require that the storage
    issue be dealt with separately from the other (Rekik et al., 2015, Ries et al.,
    2014). Salido et al. (2011), Salido et al. (2009), used artificial intelligence
    (AI) to solve container stacking and berth problems by constructing a metaheuristic
    method for berth allocation that optimizes vessel order based on berth restrictions,
    and a heuristic planner proposed to calculate the number of container reshuffles
    needed for the given vessel berth, in which terminal operators can choose the
    best one for each circumstance. In addition to flexibility in dealing with the
    various systems in the station, such as the berthing system and the gate system
    (truck entry and exit), the official and his team face a race against time when
    a ship arrives to unload it on time or in dealing with discharge containers that
    are due to be discharged. The presence of the containers on the sidewalk or in
    the storage site does not serve the stakeholders; the purpose is to see them on
    the backs of trucks traveling through the gates (Alkheder et al., 2022). The remainder
    of this paper is structured as follows: In Section “Literature review”, we briefly
    provide an examination of relevant prior research. Then, Section “Methodology”
    discusses and delineates the solution approach and theoretical ideas. Subsequently,
    we elucidate the theoretical and mathematical framework for the model, specifically
    the Smart Dynamic Containers Stacking Based on the Data Cubic Model (SDCSDCM)
    in Section “Smart dynamic container stacking based on the data cubic model (SDCSDCM)”.
    The implementation details and results of the model are presented in Section “Results
    and discussion”. Finally, the conclusions and potential directions for future
    research are summarized in “Conclusions”. Literature review Our objective is to
    develop a model that can accommodate all incoming containers; in contrast, Gunawardhana
    et al. (2021) proposed a real-time Rule-Based Dynamic Container Stacking (RBDCS)
    model that addresses the limitations of current Dynamic Container Stacking (DCS)
    models, which have higher levels of uncertainty. Their model determines the optimal
    yard openings for incoming containers by implementing a sorting mechanism to accept
    or reject containers based on their compatibility with the model properties. The
    double bay theory (Saleh et al., 2023) integrates various processes such as cranes,
    whose processes must be activated and direct their movement in each period of
    time. According to jiangang (2012), the yard crane deployment problem is to deploy
    and route the yard crane across the entire storage yard based on the workload
    distribution. Ting et al. (2010), proposed a reservation system for the container
    terminal that offers valuable information regarding the timing of container receipts
    before they arrive at the terminal, so this will affect the productivity of handling
    activities. This system serves as a beneficial tool for decision-making during
    the transit period when containers are awaiting reception by the consignees as
    they are being transported from the organizing yard to the container yard. Indeed,
    this one-stack problem is very complex (Avriel et al., 2000). Hence, it is only
    natural that studying the detailed site allocation problems of a single stack
    is ineffective in the block. The uncertainty problem in container stacking refers
    to the various unpredictable factors that can impact the optimal arrangement of
    containers, potentially leading to operational inefficiencies, safety concerns,
    and increased costs. In realistic environments, several uncertain factors, such
    as weather conditions, voyage complications, engine malfunctions, and so forth,
    may result in deviating from the originally planned schedules for unloading or
    loading operations, causing delays (Zhen, 2014), and he details two general types
    of factors of uncertainty: unloading plan changes and loading plan changes. In
    reference to the study conducted by Fancello et al. (2011), the station adopts
    a strategy of allocating excessive resources each shift (including human resources
    and equipment such as the number of cranes) in order to mitigate the uncertainty
    arising from the unanticipated arrival of ships. The continuous change in stacking
    structures (stacks and rows) usually occurs due to continuous yard operations,
    especially receiving and delivering containers, whether by ship or by the gate
    system. Container stacking in a terminal yard is a dynamic process that requires
    a combination of advanced technologies, data-driven decision-making, and effective
    communication to address uncertainties and optimize operations. Therefore, our
    strategy to overcome uncertainties is real-time data integration; implementing
    data integration and evoking data in real-time about container arrivals, departures,
    and other variables in the terminal yard can help adjust stacking plans on the
    fly. This is what we strive to achieve in our model by combining the features
    that a 3D matrix provides with an artificial intelligence model. Hamdi et al.
    (2012) noted a concept that pertains to the heuristic movement algorithm employed
    to estimate the flow rate, queue, and time allocation necessary for storing containers
    in the station yard; thus, the procedure necessitates the use of intelligent flow
    control techniques during container storage to regulate movement. Ayachi et al.
    (2013) proposed a genetic algorithm to solve the container storage problem in
    the port. The objective is to determine the best container arrangement that meets
    customers’ delivery dates and reduces the number of container reshuffles. All
    types of containers were considered. The proposed methodology has yielded promising
    outcomes in comparison to the Last-In-First-Out (LIFO) algorithm employed by the
    manual planner in the port. Terán Cobo (2018) proposed an Efficient Stacking Algorithm
    (ESA) to solve the location assignment issue, with the primary objective of minimizing
    energy consumption and maximizing productivity in yard handling activities. Rodriguez-Molins
    et al. (2012) presented a domain-dependent heuristically guided planner that uses
    planning techniques from artificial intelligence to get the best reshuffling plan
    for solving the container stacking problem. The planner can also be used for finding
    the best allocation of containers in the yard to minimize the number of reshuffles,
    as well as for simulation tasks and obtaining conclusions about possible yard
    configurations. Feng et al. (2022) proposed the concept of Smart Stacking (SS)
    that enables the terminal operator to incorporate the customer information to
    solve the Storage Location Assignment Problem (SLAP) for import containers at
    an automated container terminal; according to the (SS) approach, the customer’s
    smart (free-flow) containers are kept in specific stacks to ensure that they do
    not need to be moved throughout the retrieval process. On the other hand, the
    non-smart (non-free-flow) containers are stored together in shared stacks. Furthermore,
    we discovered through literary analysis that some container ports use various
    storage techniques to suit their needs. The main container terminals have temporary
    spaces set aside for containers that have just been loaded onto ships or emptied
    off ships, as well as separate storage areas for export and import containers.
    The containers for import and export can occasionally be combined into blocks
    or even bays. The station must reorganize mixed containers based on species distinction
    and future retrieval operations as a result of this adoption of stacking methods.
    This increases the cost, time, and effort of the cranes; there is no doubt that
    this reduces the productivity and competitiveness of the terminal. This procedure
    (rearrangement) requires informed and appropriate decision-making as it affects
    the efficiency of the container yard’s productivity. Kim and Park (2003) examined
    the allocation of storage space for outgoing containers upon their arrival at
    a storage yard. Two heuristic techniques are proposed in this study, one based
    on the duration of stay of containers and the other using the sub-gradient optimization
    methodology. A numerical experiment was undertaken to compare the performance
    of the two. According to Ries et al. (2014), who supported the decision of assigning
    space to incoming containers at the yard of a container terminal in real-time
    to deal with a high degree of uncertainty in the arrival of containers at the
    yard, he presented an approach consisting of a 2-phase framework based on a fuzzy
    rule concept. As stated by Steenken et al. (2004), the maintenance of ship stability
    requires the preallocation of places at the shipyard. Subsequently, the containers
    are arranged in accordance with the weight concept, starting with the smaller
    containers and progressing to the larger ones. Within the second segment, several
    terminals use online procedures that implement decentralized planning and do not
    require a prior reservation of space. Upon the arrival of newly acquired containers,
    promptly determine the berthing area of the vessel. Subsequently, proceeding to
    efficiently allocate the containers within the defined yard space, taking into
    account their respective categories in a dynamic manner. As described by Jiang
    et al. (2021), the “New HRL” algorithm was successful in solving the container
    relocation problem. The researchers reach the conclusion that the new heuristic
    for reinforcement learning has a performance level that is comparable to that
    of the most well-recognized heuristic. The authors claim that including a heuristic
    that aligns with the underlying principles of the issue may facilitate the convergence
    of the reinforcement learning algorithm. Consequently, they propose augmenting
    the heuristic algorithm within the framework of the reinforcement learning algorithm
    by introducing additional constraints. The issue of optimal site allocation occurs
    in the context of import and export container management. These site allocation
    choices are consistently made in real-time as inbound and outbound containers
    arrive and leave, sometimes with varying schedules (estimated time of arrival).
    Balster et al. (2020) described the structure of the Estimated Time of Arrival
    (ETA) prediction model in which schedule-based and non-schedule-based transports
    are combined based on machine learning (ML). in accordance with known stowage
    schemes for ships and container handling sequences; the findings of this study
    enable decision-makers to proactively inform participants in the intermodal transportation
    chain about disruptive impacts. Salido et al. (2011) presented an artificial intelligence-based
    integrated system to relate these problems. Firstly, a metaheuristic algorithm
    was developed for berth allocation that generates an optimized order of vessels
    to be served according to existing berth constraints. Secondly, a domain-oriented
    heuristic planner was developed for calculating the number of reshuffles needed
    to allocate containers in the appropriate place for a given berth order of vessels.
    Jin et al. (2004) presented a case study to verify the validity of an intelligent
    simulation method for regulating container yard operations on container terminals.
    He established a control architecture based on Fuzzy Artificial Neural Networks
    (FANN). The regulation process includes two phases: the prediction phase forecasts
    container quantity through a fuzzy multiobjective programming problem, then makes
    a decision on the operation rule and stack height using the inference phase. This
    algorithm proved an effective solution for optimal container yard operation scheduling
    problems with the features of uncertainty, computation complexity, and ambiguity
    in a real-time environment. Methodology Optimum storage space use and expedited
    retrieval procedures are crucial to terminal productivity. Container stacking
    entails arranging containers and specifying their ideal stacking position in the
    terminal yard for quick access, retrieval, and loading into ships or vehicles.
    The problem is to accommodate a large number of containers with different features,
    sizes, kinds, and destinations while maintaining safety and space efficiency.
    Stacking principles organize containers for safety, accessibility, space efficiency,
    and operation. Covic (2018) provided a comprehensive overview and wide-ranging
    literature review that discusses container stacking problems. The courtyard takes
    the following form: The composition of the terminal yard as shown in Fig. 1 is
    a group of blocks; the blocks are divided into multiple bays, and each bay consists
    of aligning a group of rows so that the stack consists of the intersection of
    the row with the bay and holds the bay and the stack within its composition, the
    tier. The tier is the storage level, thus The top hatch is the smallest unit of
    storage in the block. According to Saleh et al. (2023), discussed a methodology
    for managing locations within a block that operates the location inside bays according
    to time, specifically chronic two bays in one block. This study demands that the
    container’s location in the storage yard be arranged according to the departure
    time as if each slot of the container is defined by date-time, and therefore the
    processing of container storage begins according to the containers with the farthest
    time range. It has been stated that the inbound containers are arranged sequentially
    based on the time dimension rule, specifically following the principle of Farest
    Date is First In (FDFI). Similarly, outbound containers are organized according
    to the rule of Earliest Date First Out (EDFO). This work presents a methodology
    for the development of stacking strategies that may effectively handle the challenges
    posed by escalating trade volume while simultaneously mitigating any potential
    loss in productivity. The methodology that we are going to explain is related
    to the methodology of bay timing (Saleh et al., 2023). The current method is based
    on combining several ideas, such as cubic data, three-dimensional matrices, artificial
    intelligence, and machine learning. It is based on the yard division method, the
    double bays methodology, and site chronology. It is also important to think about
    the temporal dimension (location chronological) and the determination of the spatial
    dimension during stacking. Download : Download high-res image (491KB) Download
    : Download full-size image Fig. 1. General shape and components of the terminal
    yard. Serban and Carp (2016), Gheith et al. (2013). The graphical representation
    of the different divisions of block in the station yard is depicted in Fig. 2.
    This representation includes many elements such as bays, stacks and tiers, rows,
    and slots (a). Additionally, part (b) presents the mathematical representation
    corresponding to the block. We will notice the combination between the idea of
    cubic data and the ordered form of data (matrix) that the AI model needs (Fig.
    2), which are the inputs and outputs and the supporting and supportive properties
    that permeate. The concept of cubed data is employed to develop a model that may
    be effectively executed through artificial intelligence techniques, to identify
    an optimal and intelligent approach for arranging containers within a terminal
    yard. In addition, the cubic data of the containers accommodates the multi-perspective
    observation data of the yard (containers, spatial, and time). Download : Download
    high-res image (284KB) Download : Download full-size image Fig. 2. Graphical (a)
    and Mathematical (b) representation of the block divisions in the station yard.
    Fig. 3 shows an artificial intelligence model developed using neural network technology.
    The present model offers a prediction of the optimal placement for the new inbound
    containers inside the container yard based on the constituent structures of the
    block, namely bay, row, stack, and tier. Following the mentioned structures of
    a block, we can systematically use AI capabilities to access and observe singular
    data points of containers, extract vacancy-location data, and extract non-vacancy-location
    data from the information system of the terminal, then decide which of these vacancy-locations
    are right for stacking the containers. Inbound containers arrive and depart continuously,
    requiring real-time site allocation decisions. Uncoordinated storage yard activities
    lead to ill-advised, costly rearrangements and carrier traffic congestion. It
    should be noted that there are researchers who have provided solutions to this
    problem by linking it to heuristic (Hamdi et al., 2012), and others through genetic
    algorithms (GA) (Ayachi et al., 2013); fuzzy logic (Ries et al., 2014); artificial
    intelligence (Rodriguez-Molins et al., 2012), Feng et al. (2022) named it as smart
    stacking; and others (Ting and Wu, 2017) proposed an inline radiometric search
    algorithm with heuristics to evaluate problems with the least number of problems
    in terms of transfers and a shorter time, the problem was addressed here partly,
    and there are other cases that the author referred it to in the issue of future
    expansion; in addition to the fact that the issue of storage will continue to
    suffer from the same problem when moving containers to new unstudied positions.
    Download : Download high-res image (470KB) Download : Download full-size image
    Fig. 3. The proposed Long Short-Term Memory (LSTM) based neural network model.
    Based on the objective of optimizing storage space in container terminals, the
    proposed solution aligns with the operator’s orientation and effectively caters
    to terminals with limited space by maximizing utilization of all available sites
    and efficiently managing storage operations. Furthermore, when placing a container
    on a site that is fully vacant, the sites above this container are first populated
    with a suitable date of departure. We will deal with a synthetic name consisting
    of block number, bay, row, column, and tier. In their study, Feng et al. (2022),
    they worked on the principle that each container is linked to a customer. So containers
    belonging to the same client will form a group. In the event that a container’s
    customer information is unknown, this container constitutes a collection on its
    own. The advent of digitization and artificial intelligence has brought about
    significant transformations in the logistics industry and port operations, yielding
    notable benefits such as cost reduction, time efficiency, enhanced speed, and
    improved overall performance. Ries et al. (2014), used a 2-phase framework based
    on a fuzzy rule idea. Regarding Abbas (2016), the best approach to the issue of
    the unproductive move in the container stacking system is a genetic algorithm.
    Regarding Kozan and Preston (1999) claimed that genetic algorithm (GA) techniques
    are employed to shorten the time it takes to handle and transfer containers and
    accelerate handling procedures. According to Salido et al. (2009), the container
    stacking problem is modeled from the perspective of artificial intelligence; he
    advised using stacks with five tiers in high-loaded terminals because they require
    fewer reshuffles and presented a planning tool for determining the best arrangement
    of containers in a bay. A proposed approach combining the cubic data of containers
    and AI for enhancing terminal yard operations At the container terminal, it is
    clear that stakeholders need new approaches to put the amount of information from
    the various sources they deal with on a daily basis into a suitable context to
    derive value from; our idea based on integrating homogeneous multi-data structures
    for containers Fig. 4 with AI to systematically access and view one-point data
    of containers, extract vacancy-locations data, and extract non-vacancy-locations
    data from the information system of the terminal, then decide which of these vacancy-locations
    are right for stacking the containers. This model will explain the importance
    and relationship of container covariates, semantically enrich AI outputs, combine
    them with linked existing data to create new value chains, and allow spatial–temporal
    container terminal yard visual analytics. This process definitely enhances the
    human experience. To produce a homogeneous data cube that AI algorithms can analyze,
    we fill in the data of new containers in the appropriate vacant positions to complete
    the series of arrays related to containers, their storage locations, and their
    discharging times. Download : Download high-res image (262KB) Download : Download
    full-size image Fig. 4. Graphical representation (3D matrix) of the yard block
    — CTL (Container, Time, Location). Smart dynamic container stacking based on the
    data cubic model (SDCSDCM) The goal is to process pre-configured data, explore
    time series (departure dates) and spatial series (locations), use feature engineering
    techniques, feed known machine learning algorithms the necessary inputs for learning,
    and then predict the optimal storage locations. Formulation: Input parameters
    Let us consider the following variables: CI: Container Inbound. Cst: Container
    Stacked. N: The total number of slots. n: The rank of the slots. X: The input
    (the containers). x: Slot, r: row, t: tier, b: bay. cl: Column, pb: paired-bay.
    Pe: Position-empty (vacacy slot). fs: Full-slot. tes: Typical-empty-slot. ad:
    Arrival date, Id: left date. t: Container type. tg: Time group of the arrival
    container (probability variable). Cgi: The container groups (group(i)). tc: The
    input (container) that is located under the empty slot (the element of decision
    for stacking). Pr: The probability of the time group. Pr(ad)(tg): The probability
    of the time group of the arrival container(tg) with arrival date(ad). Pr(ld)(tc):
    The probability of the already storage container (tc) with the left date(ld).
    i: index. n1: Maximum rows number on the axis x, necessary to change the x, y,
    z. n2: Maximum stacks number on the axis y. n3: Maximum tiers number on the axis
    z. di: delivery date of each container i. att: attributes. Matrix definition Based
    on the objective function that we use in our methodology (Saleh et al., 2023),
    (1) (2) We can define the shape of the cubic matrix 5 used in our work as shown:
    • Cmtrx: Containers data matrix, Cmtrx=[ID, Type, Destination port, Source port,
    Owner] • Tmtrx: Time data matrix, Tmtrx = [date/time arrive, date/time departure]
    • Lmtrx: Location data matrix, Lmtrx = [block, bay, row, stack, tier] • CTLmtrx
    [][][] = [Cmtrx[], Tmtrx[], Lmtrx[]] (3) denote to the attributes of the object.
    Download : Download high-res image (226KB) Download : Download full-size image
    Fig. 5. CTL matrix. Concatenating the matrices: (4) (5) Where [a] represents the
    attribute of the object. The new container’s flow represents finite-dimensional
    algebraic matrices. These dimensions are the properties of the object necessary
    to create the interactions that are interrelated with each other and related to
    time within the dynamic system of receiving and stacking containers; that is,
    the development of the interactions in the subsequent steps depends on the time
    matrix (departure date, residence time, etc.). Evoke structure refers to fetching
    data from the terminal’s yard Fig. 8. The three-dimensional structure will also
    be evoked from the terminal yard, which consists of an array of containers with
    a matrix of time and locations, whether vacant or occupied, symmetrical or asymmetric.
    When comparing the fetched structures [ and ], we will have some cases: • The
    cubic matrix’s attributes are matches with vacancies slots the decision is that
    containers can be placed. • Y(CTL) get the vacancies slots, L(bloc, bay, row,stack,tier).
    • The cubic matrix’s attributes are matches with no vacancies slots Closed dimension
    the decision is that containers cannot be placed, looking for other evoked structures.
    • The cubic matrix’s attributes are not match with vacancies slots and the time
    matrix of is closer to the extraction than the decision is that containers can
    be placed. • The cubic matrix’s attributes are not match with vacancies slots
    and the time matrix of is further extracted than the decision is that the containers
    cannot be placed. When there is a completely empty The decision is that the containers
    can be placed. (a) The mathematical representation of the inbound containers data
    matrix is: (6) Where Lmtrx[a] is empty or unknown (7) Where L matrix is the decision
    variable (b) The mathematical matrix of the data that is evoked from the actual
    configuration of the container terminal yard is (see Box I): (c) Merge and compare.
    (9) (d) Decisions Variables: (optimal location) Loc(x, y, z, i). It is a structure
    with two more variables: Container (C) and Time (T) data. (10) Where: , , z Box
    I (8) Smart stacking container’s cubic data model This paper presents a proposed
    real-time approach for determining the appropriate placement of incoming containers.
    The objective of the created model is to be applicable across many types of infrastructures,
    including those with varying degrees of efficiency (simple, medium, and high).
    Its purpose is to effectively manage the challenges posed by significant levels
    of uncertainty, with the ultimate goal of enhancing the efficiency of container
    handling during stacking and discharging operations. Assumptions The formulation
    of the model is based on the following assumptions: a. The model considers the
    proposed division of bays in our methodology (paired-bay) (Saleh et al., 2023).
    b. The model determines the optimal location in the yard for the containers, which
    consist of the following attributes: - Container characteristics, time dimension,
    and spatial dimension Fig. 6. c. Our model feeds by container information as container
    groups based on the following parameters: departure date, carrier, destination,
    etc. d. Based on point (c), in the case that the number of the formed group is
    completely less than the number of sites in the double bay, then the ideal site
    available is treated without taking the concept of storage as a group. e. If the
    number of sites in the formed group is greater or equal to the number of sites
    in the double bay, then the ideal site is dealt with in the double bay as a whole
    (stacking on paired-bay level is treated). f. The height of container stacking
    depends on the infrastructure at each port. g. The model is completely based on
    the data already in the yard: the temporal dimension, the spatial dimension, and
    the data of each container, then deducing the vacant slots, and occupied slots,
    and predicting the slots that will be empty at a specific time in the future,
    etc. h. The storage rule used depends on storing the furthest date first (Saleh
    et al., 2023). i. Filling in the vacant places step by step is also the way we
    follow, whether dealing with one container or with a group of containers, so the
    mobilization step by step makes you take advantage of what is available and avoid
    random prose. j. Assuming that there are no reasons that obstructed or delayed
    the arrival of the ship. k. The decision that the model will make is to show the
    vacant and ideal site for stacking containers. l. The average duration of berthing
    in the ports for container ships is two days (Sirimanne et al., 2019). Download
    : Download high-res image (233KB) Download : Download full-size image Fig. 6.
    CTL characteristics. SDCSDCM model formulation In order to formulate the model,
    we employ the subsequent three fundamental concepts: spatial–temporal, object
    (container) features, and cube concept; additionally, some concepts, such as artificial
    intelligence, evoke or extract current data in real-time or proactively, then
    manipulate it. The model was proposed based on the methodology outlined in Section
    “Methodology”. The model has four steps in Fig. 7 to determine the optimal slots
    in the yard as follows: • Step 1 — Sorting and putting similar containers in groups.
    • Step 2 — Extracting transport containers to the Gate system, and rail system.
    • Step 3 — Evoking all vacant feasible/unfeasible and vacant yard slots. • Step
    4 — Selecting the optimal slot from feasible empty slots. (1) Step 1: Sorting
    and putting similar containers in groups This step represents the first point
    in dealing with the model, the first step that receiving information from the
    berth system (the output of the berth system is input for the stacking system).
    The purpose of this step is to put the containers that have the same characteristics
    in one group which facilitates alignment of the new arrival containers with the
    already existing configuration in the yard in both dimensional (temporal and spatial),
    which facilitates the appropriateness of the optimal vacant slots. The transport
    containers will coordinate with the gate or rail system to carry them out of the
    terminal. The components of the SDCSDCM model in Step 1 are as follows: (i) Inputs
    received from the berthing system (facts) (ii) Knowledge Base (initial alignment
    with yard configuration) (iii) Inference Chain (the transport containers and the
    dwell’s containers) (2) Step 2: Extracting transport containers to send them to
    the gate system and rail system The process represents the first point of the
    relationship between the gate system and the first step results of our model that
    sends transport containers to the gate/trail system (dispatch out of the yard),
    so it requires strong coordination controlling when the truck enters from the
    gate and the equipment that will load the container onto the truck. This step
    creates a knowledge base for dwell containers; the model provides a strategy for
    dispatching and managing transit containers (uncertainty) and confirming their
    certainty. The components of the SDCSDCM model in Step 2 are as follows: (i) Inputs
    from the first step of the model (facts) (ii) Knowledge Base (dispatching through
    gate system and truck entry schedule) (iii) Inference Chain (Dispatching Transport
    Containers - Condition of Certainty) (3) Step 3: Evoking all empty feasible/unfeasible
    and empty yard slots This process represents the issue of dealing with the second
    set of containers (housing containers), which is often uncertain in general, linking
    the upcoming containers to the issue of uncertainty that we seek to manage and
    control by examining the spatial capacity of their storage in the terminal yard
    in real-time, taking into account the process extraction, and avoiding random
    scattering; thus, we strive to provide a solid foundation for dealing with these
    cases through the use of artificial intelligence models and with the help of the
    data cube concept. Through the three-dimensional data matrix provided by the current
    configuration of the yard, this step aims to manage the modeling of the housing
    container storage process, identifying feasible places to store containers based
    on the temporal dimension (precedence of the date of discharge), the spatial dimension
    (bay, row, stack, tier), and in addition to container data. The components of
    the SDCSDCM model in Step 3 are as follows: (i) Inputs from the first step of
    the model (facts, dwell containers) (ii) Knowledge Base (yard configuration set
    of dwell containers) • Configure and list the container’s characteristics. • Check
    the different configurations in the yard. – Evoke similar vacant locations in
    the yard configurations. – Evoke different vacant locations in the yard configurations.
    – Evoke empty locations * Check and compare * Get the feasible locations. (iii)
    Inference Chain (sets of feasible locations) (4) Step 4: Determine the optimal
    slots from the feasible vacant slots. Spatial time is used when data is collected
    across both space and time. The person thinks spatial and temporal to solve multi-step
    problems by envisioning how things move in space and time, as if in this processing
    we rewrite time and space with the data of container properties in a new way.
    Here we form the cube, which contains more organized data and specific points
    that are not scattered at all. Physically, the place (slot) is fixed, and logically,
    it is fixed and definite data that represents the place (bay, row, stack, tier)
    accurately, and it represents time and also represents the data of the container
    itself; so the cube that formed is a multidimensional block with a complete description,
    referring to a single point. With the tendency to use AI, it will be possible
    to make the right decision in real-time. The components of the SDCSDCM model in
    Step 4 are as follows: (i) Inputs from the third step of the model (facts, evoking
    feasible spatiotemporal sets) (ii) Knowledge Base (sets of feasible slots) • Check
    and compare feasible sites. • Get the optimal slots. (iii) Inference chain (choose
    the optimal slots) • Configure and list the container’s characteristics. • Check
    the different configurations in the yard. – Evoke similar vacant locations in
    the yard configurations. – Evoke different empty locations in the yard configurations.
    – Evoke vacant locations – Check and compare – Chose the optimal location Download
    : Download high-res image (229KB) Download : Download full-size image Fig. 7.
    Phases of stacking containers in terminal yards. The algorithm When new containers
    arrive, the following will be done Fig. 8: – Receiving, sorting, and dividing
    the incoming containers into groups according to specific parameters like the
    date of departure, carrier, and destination – Evoke the not vacant formations
    in the yard in its three dimensions (container data, time dimension, storage location).
    – Evoking vacant sites in the courtyard (spatial dimension). switch case: Case
    1: The inbound containers do not correspond to containers that already existed
    in the yard formation for instance on the departure date. switch case: Case1:
    Searching for an empty vacancy (bay, row, stack, tier), If any, in which containers
    are placed directly. Case else: In the absence of a completely vacant formation,
    the departure date is compared with the departure date of the containers already
    in the formation. If the departure date the departure date (of the already existing
    containers), then it will not be placed. Else if the departure date the departure
    date (of the already existing containers), then stacking the container (optimal
    location). Case 2: If the evoke has a similar configuration in the yard with the
    same parameter (departure date, destination port, and carrier) in its three dimensions
    (container data, time, stacking location) then stock the containers. – Comparing
    the information of inbound containers with the customer’s information and the
    schedule of truck entries. Once this comparison is made, a gate entry document
    is prepared and sent to the gate, enabling the appropriate trucks to enter. Download
    : Download high-res image (505KB) Download : Download full-size image Fig. 8.
    Data flow for evoking optimal location from multi-matrices of terminal yard data.
    Results and discussion In Fig. 9, our model indicates the course of the values
    in each of the “Validation Loss” and “Training Loss” values, which are generally
    graphed together. The goal is to assess model performance and identify tweaking
    needs. Underfitting, overfitting, and excellent fit are typical values. Our model
    indicated that training loss was larger than validation loss, stabilized at a
    point, and decreased with distance. This means the model fits optimally without
    overfitting or underfitting. Download : Download high-res image (132KB) Download
    : Download full-size image Fig. 9. Performance comparison of AI model: Training
    loss vs. Validation loss. Data analysis The accuracy assessment of the artificial
    intelligence (AI) model’s performance offers valuable insights into the quality
    and reliability of its predictions. The key statistical measures shed light on
    various aspects of the model’s accuracy distribution, and behavior in Table 1,
    Fig. 10, Fig. 11: Mean Accuracy (0.654): The AI model averages 65.4% accuracy
    across validation samples. This mean value indicates the accuracy results’ central
    trend. Standard Error (0.0280): The mean accuracy estimate’s precision is shown
    by the 2.8% standard error. This low number shows the sample mean matches the
    population mean. Median Accuracy (0.758): The Middle of the accuracy distribution
    is a median accuracy of 75.8%. This number is near the mean, indicating that many
    predictions cluster around this degree of accuracy. Mode Accuracy (0.006): The
    most common accuracy value is 0.6%. This mode shows the AI model’s typical accuracy.
    Standard deviation (0.280): Accuracy values spread 28.0% about the mean accuracy
    with a modest standard deviation. This number measures accuracy variability. Sample
    Variance (0.078): The sample variance of 7.8% shows how much accuracy results
    range from the mean. Kurtosis (−0.084): The accuracy distribution has a little
    lower peak than a normal distribution. This means the dataset has fewer severe
    outliers. Skewness (−1.138): The accuracy distribution has a skewed tail. This
    shows the AI model’s forecasts focus on accuracy. Range (0.916): The range between
    the greatest and lowest accuracy results is 0.922. This number measures the accuracy
    span. Minimum Accuracy (0.003): The AI model’s lowest prediction accuracy is 0.003.
    Maximum Accuracy (0.919): The model’s best accuracy is 91.9%. The sum of Accuracy
    (65.382): The dataset’s total accuracy value is 65.382, representing the model’s
    cumulative accuracy over validation samples. Count (100): The accuracy values
    count represents the number of validation samples needed to construct these statistics.
    Confidence Level (95.0%, 0.056): The confidence interval of 0.056 suggests that
    the real mean accuracy stands within 95% of the sample mean. Table 1. Statistical
    analysis of accuracy metrics for trained AI model. Validation Accuracy Mean 0.654
    Standard Error 0.028 Median 0.758 Mode 0.006 Standard Deviation 0.280 Sample Variance
    0.078 Kurtosis 0.084 Skewness −1.138 Range 0.916 Minimum 0.003 Maximum 0.919 Sum
    65.382 Count 100 Confidence level (95.0%) 0.056 These statistical insights collectively
    provide a comprehensive picture of the AI model’s accuracy distribution, its central
    tendencies, variability, and overall performance characteristics. Download : Download
    high-res image (239KB) Download : Download full-size image Fig. 10. Analyzing
    accuracy and loss patterns in trained AI model. Download : Download high-res image
    (254KB) Download : Download full-size image Fig. 11. Analyzing validation accuracy
    and validation loss patterns in trained AI model. Comparison results Through this
    comparative study, we aimed to evaluate the performance of various algorithms
    in predicting container stacking locations within container yards. The standard
    deviation, serving as a measure of the dispersion or variability in the results,
    was employed to assess the stability and consistency of the algorithms. As shown
    in Table 2, Zhang et al. (2023) compared his algorithm (decision tree) with random
    forest, Deep Neural Network (DNN), and Self-Attention-based Neural Network (SANN),
    the decision tree with a standard deviation of 0.806 maintains a low level of
    variability in its predictions compared with random forest, which is slightly
    higher at 0.85, DNN, which maintains a consistent standard deviation of 0.855,
    and SANN, which is slightly higher at 0.869 but remains within a reasonable range
    of standard deviation. Furthermore, Rekik et al. (2018) compared his algorithm
    (developed heuristic) with fuzzy logic, combined strategy, and Remaining Stack
    Capacity (RSC). It appears clearly that the developed heuristic exhibits a high
    standard deviation of 11.71, indicating a wide variability in predictions, while
    the fuzzy logic framework, with a standard deviation of 35.01, displays substantial
    variability in predictions. Similarly, the combined strategy has a higher standard
    deviation of 12.79. The RSC strategy exhibits the highest standard deviation at
    45.21. The proposed LSTM algorithm stands out with an exceptionally low standard
    deviation of 0.28. It signifies exceptional stability, making the LSTM a robust
    and reliable algorithm for container stacking location prediction. The comparative
    study underscores the stability and reliability of machine learning and neural
    network-based models, such as decision trees, random forests, and DNNs, for predicting
    container stacking locations, while developed heuristic, fuzzy logic, and combined
    strategy, tend to exhibit greater variability. In closing, this revised analysis
    based on the corrected definitions provides valuable insights into the stability
    and consistency of various algorithms for predicting container stacking locations.
    It reaffirms the reliability of machine learning and neural network models and
    underscores the exceptional stability of the LSTM. While further research may
    be necessary to understand the strengths and limitations of each approach. Table
    2. The comparison results with recent algorithms (the low standard deviation).
    Ref. Algorithm Standard deviation Zhang et al. (2023) Decision tree 0.806 Random
    forest 0.850 DNN 0.855 SANN 0.869 Rekik et al. (2018) Developed heuristic 11.71
    Fuzzy logic framework 35.01 Combined strategy 12.79 RSC 45.21 Proposed LSTM 0.28
    Table 3. Sample of evoked data — vacant slots matrix. Id Departure date Index
    priority Slot vacant Index loc bay row col tier Right order 17 0 0 1 31 154 3
    1 15 4 3 17 0 1 1 31 154 3 1 15 4 3 25 0 0 1 41 224 4 1 22 4 3 25 0 1 1 41 224
    4 1 22 4 3 49 0 0 1 71 434 7 1 43 4 3 49 0 0 1 71 434 7 1 43 4 3 57 0 0 1 81 504
    8 1 50 4 3 57 0 1 1 81 504 8 1 50 4 3 141 0 0 1 33 174 3 3 17 4 2 Table 4. Sample
    of evoked data — occupied slots matrix. Id Departure date Index priority Slot
    vacant Index loc bay row col tier Right order 1 9 2 2 1114 1 1 1 4 2 2 15 3 2
    1113 1 1 1 3 2 3 24 4 2 1112 1 1 1 2 2 4 1 1 2 1111 1 1 1 1 2 4 1 1 2 1114 1 1
    1 4 1 1 9 2 2 1113 1 1 1 3 1 2 15 3 2 1112 1 1 1 2 1 3 24 4 2 1111 1 1 1 1 1 Table
    5. New container’s data matrix after filling the empty sites. Empty Cell Id Departure
    date Index priority Slot vacant Index loc bay row col tier Right order 0 1 9 2
    2 1114 1 1 1 4 2 1 2 15 3 2 1113 1 1 1 3 2 2 3 24 4 2 1112 1 1 1 2 2 3 4 1 1 2
    1111 1 1 1 1 2 4 4 1 1 2 1114 1 1 1 4 1 5 1 9 2 2 1113 1 1 1 3 1 6 2 15 3 2 1112
    1 1 1 2 1 7 3 24 4 2 1111 1 1 1 1 1 8 9 2 1 2 2184 2 1 8 4 1 9 10 14 2 2 2183
    2 1 8 3 1 10 11 21 3 2 2182 2 1 8 2 1 11 12 24 4 2 2181 2 1 8 1 1 12 9 2 1 2 2184
    2 1 8 4 1 13 10 14 2 2 2183 2 1 8 3 1 14 11 21 3 2 2182 2 1 8 2 1 15 12 24 4 2
    2181 2 1 8 1 2 16 99 917 25 0 2 31 154 3 1 15 4 2 17 18 10 2 2 31 153 3 1 15 3
    1 18 19 23 4 2 31 152 3 1 15 2 1 19 20 22 3 2 31 151 3 1 15 1 1 20 99 917 66 1
    2 31 154 3 1 15 4 1 21 18 10 2 2 31 153 3 1 15 3 1 22 20 22 3 2 31 152 3 1 15
    2 1 23 10 22 4 2 31 151 2 1 15 1 1 24 99 925 77 0 2 41 224 4 1 22 4 1 25 26 4
    2 2 41 223 4 1 22 3 1 26 27 16 3 2 41 222 4 1 22 2 1 27 28 25 4 2 41 221 4 1 22
    1 1 Evoking data and proactive solution In the context of this study, a comprehensive
    data-driven approach was used to improve container allocation within the container
    stacking yard. This process includes various phases aimed at enhancing efficiency
    and reducing operational complexities. At first, preemptively fetches the data
    for various configurations within the container stacking yard block. This includes
    obtaining relevant information regarding empty and occupied storage locations.
    These data matrices, which represent vacant sites Table 3 and occupied sites Table
    4 within the yard, serve as critical inputs for subsequent analyses, and to facilitate
    experimentation, a raw data set representing the putative incoming containers
    data were provided Table 5. These experimental data help in evaluating the effectiveness
    of the proposed approach to select the ideal storage locations for containers
    received within the ideal vacant locations that have been previously evoked. Conclusions
    The objective of this study is to create a strategic, sustainable, and intelligent
    framework that incorporates spatiotemporal and cubic data principles via the integration
    of diverse matrix series with the use of artificial intelligence. This model integrates
    the interconnected entities with their respective qualities and attributes to
    solve the stacking problem of containers and facilitate real-time processing.
    The model collects data on the many components of the yard, evaluates their suitability
    or advantages within the given context, and then specifies the proper solution.
    Furthermore, there is also a chance that this project could be improved in the
    future by adding more functions to each matrix, tailoring specific bays to accommodate
    lines with higher levels of activity, examining the error rate associated with
    the utilization of artificial intelligence techniques in container storage, and
    establishing connections between the current work and the gate system to streamline
    truck entry and exit processes. Declaration of competing interest The authors
    declare that they have no known competing financial interests or personal relationships
    that could have appeared to influence the work reported in this paper. Acknowledgments
    We would like to express my sincere gratitude to my supervisor, Professor M. Larabi
    Ben Maâti, for his exceptional scientific and professional leadership and invaluable
    assistance during this work. We would also like to acknowledge Professor Attariuas
    Hicham for his valuable and constructive ideas in this study. We are also grateful
    to the editor for handling this paper and to the referees for their valuable remarks.
    Data availability The data that support the findings of this study are available
    on request from the corresponding author. The data are not publicly available
    due to privacy or ethical restrictions. References Abbas, 2016 Abbas, F., 2016.
    Intelligent Container Stacking System at Seaport Container Terminal. (Dissertation).
    URL https://urn.kb.se/resolve?urn=urn:nbn:se:bth-11678. Google Scholar Alkheder
    et al., 2022 Alkheder S., Naif D., Musaed D., Shrekah S.A., Rshaid M.A., Anzi
    N.A., Baqer I. Cleaner Logistics and Supply Chain Maritime transport management
    in Kuwait toward an automated port logistical city Clean. Logist. Supply Chain,
    3 (September 2021) (2022), Article 100031, 10.1016/j.clscn.2022.100031 View PDFView
    articleView in ScopusGoogle Scholar Avriel et al., 2000 Avriel M., Penn M., Shpirer
    N. Container ship stowage problem: complexity and connection to the coloring of
    circle graphs Discrete Appl. Math., 103 (1–3) (2000), pp. 271-279, 10.1016/S0166-218X(99)00245-0
    View PDFView articleView in ScopusGoogle Scholar Ayachi et al., 2013 Ayachi I.,
    Kammarti R., Ksouri M., Borne P., LAGIS M.A., Ecole Centrale de Lille N.A., LACS
    I., Ecole Nationale des Ingenieurs de Tunis A genetic algorithm to solve the container
    storage space allocation problem (2013), 10.48550/arXiv.1303.1051 arXiv preprint
    arXiv:1303.1051 Google Scholar Balster et al., 2020 Balster A., Hansen O., Friedrich
    H., Ludwig A. An ETA prediction model for intermodal transport networks based
    on machine learning Bus. Inf. Syst. Eng., 62 (2020), pp. 403-416, 10.1007/s12599-020-00653-0
    View in ScopusGoogle Scholar Covic, 2018 Covic F. A literature review on container
    handling in yard blocks Computational Logistics: 9th International Conference,
    ICCL 2018, Vietri Sul Mare, Italy, October 1–3, 2018, Proceedings 9, Springer
    (2018), pp. 139-167, 10.1007/978-3-030-00898-7_9 View in ScopusGoogle Scholar
    Fancello et al., 2011 Fancello G., Pani C., Pisano M., Serra P., Zuddas P., Fadda
    P. Prediction of arrival times and human resources allocation for container terminal
    Marit. Econ. Logist., 13 (2011), pp. 142-173, 10.1057/mel.2011.3 View in ScopusGoogle
    Scholar Feng et al., 2022 Feng Y., Song D.-P., Li D. Smart stacking for import
    containers using customer information at automated container terminals European
    J. Oper. Res., 301 (2) (2022), pp. 502-522, 10.1016/j.ejor.2021.10.044 View PDFView
    articleView in ScopusGoogle Scholar Gheith et al., 2013 Gheith M., El-Tawil A.,
    Harraz N. A proposed heuristic for solving the container pre-marshalling problem
    The 19th International Conference on Industrial Engineering and Engineering Management,
    Springer (2013), pp. 955-964, 10.1007/978-3-642-37270-4_91 View in ScopusGoogle
    Scholar Gunawardhana et al., 2021 Gunawardhana J.A., Perera H.N., Thibbotuwawa
    A. Rule-based dynamic container stacking to optimize yard operations at port terminals
    Marit. Transp. Res., 2 (March) (2021), Article 100034, 10.1016/j.martra.2021.100034
    View PDFView articleView in ScopusGoogle Scholar Hamdi et al., 2012 Hamdi S.E.,
    Mabrouk A., Thomas B. A heuristic for the container stacking problem in automated
    maritime ports IFAC Proc. Vol., 45 (6) (2012), pp. 357-363, 10.3182/20120523-3-RO-2023.00410
    View PDFView articleView in ScopusGoogle Scholar Jiang et al., 2021 Jiang T.,
    Zeng B., Wang Y., Yan W. A new heuristic reinforcement learning for container
    relocation problem J. Phys. Conf. Ser., 1873 (1) (2021), Article 012050, 10.1088/1742-6596/1873/1/012050
    View in ScopusGoogle Scholar jiangang, 2012 jiangang J. Storage yard management
    for container transshipment terminals (2012) URL http://scholarbank.nus.edu.sg/handle/10635/37586
    Google Scholar Jin et al., 2004 Jin C., Liu X., Gao P. An intelligent simulation
    method based on artificial neural network for container yard operation Advances
    in Neural Networks-ISNN 2004: International Symposium on Neural Networks, Dalian,
    China, August 19-21, 2004, Proceedings, Part II 1, Springer (2004), pp. 904-911,
    10.1007/978-3-540-28648-6_144 View in ScopusGoogle Scholar Kim and Park, 2003
    Kim K.H., Park K.T. A note on a dynamic space-allocation method for outbound containers
    European J. Oper. Res., 148 (1) (2003), pp. 92-101, 10.1016/S0377-2217(02)00333-8
    View PDFView articleView in ScopusGoogle Scholar Kozan and Preston, 1999 Kozan
    E., Preston P. Genetic algorithms to schedule container transfers at multimodal
    terminals Int. Trans. Oper. Res., 6 (3) (1999), pp. 311-329, 10.1111/j.1475-3995.1999.tb00158.x
    View PDFView articleView in ScopusGoogle Scholar Rekik and Elkosantini, 2019 Rekik
    I., Elkosantini S. A Multi Agent System for the online Container Stacking in Seaport
    terminals J. Comput. Sci., 35 (2019), pp. 12-24, 10.1016/j.jocs.2019.06.003 View
    PDFView articleView in ScopusGoogle Scholar Rekik et al., 2015 Rekik, I., Elkosantini,
    S., Chabchoub, H., 2015. Container stacking problem: a literature review. In:
    International Conference on Computers and Industrial Engineering. CIE45. Google
    Scholar Rekik et al., 2018 Rekik I., Elkosantini S., Chabchoub H. A case based
    heuristic for container stacking in seaport terminals Adv. Eng. Inform., 38 (2018),
    pp. 658-669, 10.1016/j.aei.2018.08.016 View PDFView articleView in ScopusGoogle
    Scholar Ries et al., 2014 Ries J., González-Ramírez R.G., Miranda P. A fuzzy logic
    model for the container stacking problem at container terminals González-Ramírez
    R.G., Schulte F., Voß S., Ceroni Díaz J.A. (Eds.), Computational Logistics, Springer
    International Publishing, Cham (2014), pp. 93-111, 10.1007/978-3-319-11421-7_7
    View in ScopusGoogle Scholar Rodriguez-Molins et al., 2012 Rodriguez-Molins M.,
    Salido M.A., Barber F. Expert Systems with Applications Intelligent planning for
    allocating containers in maritime terminals Expert Syst. Appl., 39 (1) (2012),
    pp. 978-989, 10.1016/j.eswa.2011.07.098 View PDFView articleView in ScopusGoogle
    Scholar Salebeh and Debo, 2020 Salebeh T., Debo A. Study of service levels in
    lattakia international container terminal lict Tishreen Univ. J.-Eng. Sci. Ser.,
    40 (5) (2020) URL https://journal.tishreen.edu.sy/index.php/engscnc/article/view/9991
    Google Scholar Saleh et al., 2023 Saleh M.A.M., Hicham A., Ben Maâti M., Taha
    H., Admeur S. Improving the stockpiling sites for inbound, outbound containers
    by timing the place of stacking Int. J. Inf. Technol. (2023), pp. 1-7, 10.1007/s41870-023-01351-2
    Google Scholar Salido et al., 2011 Salido M.A., Rodriguez-Molins M., Barber F.
    Artificial intelligence techniques for the berth allocation and container stacking
    problems in container terminals Bramer M., Petridis M., Hopgood A. (Eds.), Research
    and Development in Intelligent Systems XXVII, Springer London, London (2011),
    pp. 295-308, 10.1007/978-0-85729-130-1_23 View in ScopusGoogle Scholar Salido
    et al., 2009 Salido M., Sapena O., Barber F. The container stacking problem: an
    artificial intelligence planning-based approach The International Workshop on
    Harbour, Maritime and Multimodal Logistics Modelling and Simulation (2009) URL
    https://api.semanticscholar.org/CorpusID:6132141 Google Scholar Saxon and Stone,
    2017 Saxon S., Stone M. Container Shipping: The Next 50 Years McKinsey (2017)
    Google Scholar Serban and Carp, 2016 Serban C., Carp D. Optimization of container
    stowage in a yard block using a genetic algorithm Stud. Inf. Control, 25 (1) (2016),
    pp. 123-130 URL https://api.semanticscholar.org/CorpusID:8990990 View in ScopusGoogle
    Scholar Sirimanne et al., 2019 Sirimanne, S.N., Hoffman, J., Juan, W., Asariotis,
    R., Assaf, M., Ayala, G., Benamara, H., Chantrel, D., Hoffmann, J., Premti, A.,
    et al., 2019. Review of maritime transport 2019. In: United Nations Conference
    on Trade and Development. Geneva, Switzerland. Google Scholar Steenken et al.,
    2004 Steenken D., Voß S., Stahlbock R. Container terminal operation and operations
    research-a classification and literature review OR spectrum, 26 (2004), pp. 3-49,
    10.1007/s00291-003-0157-z View in ScopusGoogle Scholar Terán Cobo, 2018 Terán
    Cobo P. Optimization of Yard Operations in Container Terminals from an Energy
    Efficiency Approach Universitat Politècnica de Catalunya (2018), 10.5821/dissertation-2117-121008
    URL http://hdl.handle.net/2117/121008 Google Scholar Timmer, 2012 Timmer R. Container
    stacking and retrieval strategies for problems with full information (2012) URL
    https://api.semanticscholar.org/CorpusID:54122638 Google Scholar Ting et al.,
    2010 Ting S.-C., Wang J.-S., Kao S.-L., Pitty F.M. Categorized stacking models
    for import containers in port container terminals Marit. Econ. Logist., 12 (2010),
    pp. 162-177, 10.1057/mel.2010.4 View in ScopusGoogle Scholar Ting and Wu, 2017
    Ting C.-J., Wu K.-C. Optimizing container relocation operations at container yards
    with beam search Transp. Res. E, 103 (2017), pp. 17-31, 10.1016/j.tre.2017.04.010
    View PDFView articleView in ScopusGoogle Scholar Zhang et al., 2023 Zhang C.,
    Wang Q., Yuan G. Novel models and algorithms for location assignment for outbound
    containers in container terminals European J. Oper. Res., 308 (2) (2023), pp.
    722-737, 10.1016/j.ejor.2022.12.004 View PDFView articleView in ScopusGoogle Scholar
    Zhen, 2014 Zhen L. Storage allocation in transshipment hubs under uncertainties
    Int. J. Prod. Res., 52 (1) (2014), pp. 72-88, 10.1080/00207543.2013.828166 View
    in ScopusGoogle Scholar Cited by (0) © 2023 The Author(s). Published by Elsevier
    B.V. on behalf of Kuwait University. Recommended articles Rate of approximation
    of blending type modified univariate and bivariate λ-Schurer-Kantorovich operators
    Kuwait Journal of Science, Volume 51, Issue 1, 2024, Article 100168 Reşat Aslan
    View PDF Dynamic properties of large amplitude nonlinear oscillations using Hamiltonian-based
    frequency formulation Kuwait Journal of Science, Volume 51, Issue 2, 2024, Article
    100186 Kang-Jia Wang View PDF Evaluation and risk assessment of heavy metals in
    King tuber mushroom in the contest of COVID-19 pandemic lockdown in Sokoto state,
    Nigeria Kuwait Journal of Science, Volume 51, Issue 2, 2024, Article 100193 Prince
    Onyedinma Ukaogo, …, Chizoba Thelma Ukaogo View PDF Show 3 more articles Article
    Metrics Captures Readers: 5 View details About ScienceDirect Remote access Shopping
    cart Advertise Contact and support Terms and conditions Privacy policy Cookies
    are used by this site. Cookie settings | Your Privacy Choices All content on this
    site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights
    are reserved, including those for text and data mining, AI training, and similar
    technologies. For all open access content, the Creative Commons licensing terms
    apply."'
  inline_citation: '>'
  journal: Kuwait Journal of Science
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Development of a sustainable strategy model for predicting optimal container
    stacking locations in container yards using artificial intelligence and cubic
    data
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Wu Y.
  - Yang G.
  - Sun J.
  - Cui L.
  - Wang M.
  citation_count: '0'
  description: Temperature and stress serve as crucial indicators for monitoring the
    health of LNG storage tanks. To address the limitations of traditional point-based
    monitoring and transition to comprehensive digital monitoring, this paper introduces
    the application of digital twin (DT) technology. The DT model plays a pivotal
    role in accurately representing the state of the physical entity and serves as
    the foundation for monitoring services and meeting application requirements within
    DT systems. This article introduces a numerical simulation method guided by temperature
    sensor data. It utilizes a temperature and stress calculation program as a platform
    to create twin models for real-time assessment of the temperature and stress within
    the storage tank. By comparing with the Fluent simulation of physical field leakage,
    the DT model realizes real-time inversion of the temperature field and stress
    field from sensor data to the whole region. To enhance the diagnostic and predictive
    capabilities of the DT system, we flatten the computed temperature nephogram from
    the DT model and employ machine vision techniques to extract cloud map features.
    Machine learning methods such as support vector machine (SVM) and linear regression
    are utilized to achieve leakage diagnosis, leakage volume calculation, and leakage
    location calculation. Additionally, we introduce the sequence-to-sequence (Seq2seq)
    framework and combine it with convolutional neural networks (CNN) and long short-term
    memory (LSTM) to train the time series of nephogram, enabling spatiotemporal prediction
    of leakage areas.
  doi: 10.1016/j.measurement.2024.114374
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords 1. Introduction 2. Digital twin modeling
    approach 3. Leakage diagnosis 4. Conclusion and future works CRediT authorship
    contribution statement Declaration of competing interest Acknowledgement Data
    availability References Show full outline Figures (24) Show 18 more figures Tables
    (4) Table 1 Table 2 Table 3 Table 4 Measurement Volume 228, 31 March 2024, 114374
    Digital twin modeling and leak diagnosis of temperature and stress fields in LNG
    storage tanks Author links open overlay panel Yujian Wu a, Gang Yang a, Jiangang
    Sun b, Lifu Cui b, Mengzhu Wang a Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.measurement.2024.114374
    Get rights and content Highlights • Established a twin model for temperature and
    stress monitoring in LNG storage tanks. • Integrate artificial intelligence and
    digital twin technology to achieve LNG tank leak diagnosis. • Integrating Seq2seq,
    CNN, and LSTM to achieve spatiotemporal prediction of leakage areas. Abstract
    Temperature and stress serve as crucial indicators for monitoring the health of
    LNG storage tanks. To address the limitations of traditional point-based monitoring
    and transition to comprehensive digital monitoring, this paper introduces the
    application of digital twin (DT) technology. The DT model plays a pivotal role
    in accurately representing the state of the physical entity and serves as the
    foundation for monitoring services and meeting application requirements within
    DT systems. This article introduces a numerical simulation method guided by temperature
    sensor data. It utilizes a temperature and stress calculation program as a platform
    to create twin models for real-time assessment of the temperature and stress within
    the storage tank. By comparing with the Fluent simulation of physical field leakage,
    the DT model realizes real-time inversion of the temperature field and stress
    field from sensor data to the whole region. To enhance the diagnostic and predictive
    capabilities of the DT system, we flatten the computed temperature nephogram from
    the DT model and employ machine vision techniques to extract cloud map features.
    Machine learning methods such as support vector machine (SVM) and linear regression
    are utilized to achieve leakage diagnosis, leakage volume calculation, and leakage
    location calculation. Additionally, we introduce the sequence-to-sequence (Seq2seq)
    framework and combine it with convolutional neural networks (CNN) and long short-term
    memory (LSTM) to train the time series of nephogram, enabling spatiotemporal prediction
    of leakage areas. Previous article in issue Next article in issue Keywords LNG
    storage tanksTemperatureStressDigital twinMachine visionLeakage 1. Introduction
    The climate crisis continues to worsen as human activities have a profound impact
    on the global climate. The effects of global warming are evident through the occurrence
    of devastating climate events like heat waves, floods, droughts, forest fires,
    and rising sea levels [1]. To combat these challenges, countries are actively
    striving to reduce carbon emissions by promoting renewable energy usage, enhancing
    energy efficiency, and implementing carbon reduction measures [2]. Natural gas
    serves as an efficient and environmentally friendly energy source, acting as a
    transitional fuel on the path from high-carbon to zero-carbon energy systems.
    Given the increasing global demand for natural gas, receiving stations equipped
    with large LNG (Liquefied Natural Gas) storage tanks have become a preferred method
    for energy storage and transportation [3], [4]. To strike a balance between economy
    and safety, natural gas is usually stored as liquid and stored in LNG storage
    tanks. The temperature in these tanks is maintained at about −162 ℃, and the pressure
    will be slightly higher than about 1 atmosphere. However, a leak in an LNG storage
    tank can have catastrophic consequences. The extremely low temperature of LNG
    can lead to insulation failure and sudden changes in the performance of the outer
    tank''s concrete structure. Furthermore, LNG can undergo rapid phase changes,
    and when mixed with air, it has the potential to trigger cloud explosions, posing
    severe threats to human life and the environment. Hence, the monitoring of temperature
    and stress levels in LNG storage tanks has become a key area of research in recent
    years. Such monitoring is crucial for ensuring the safety management and effective
    emergency response of LNG storage tanks [5]. The primary indicators for LNG tank
    leakage monitoring are the temperature field and the external tank stress field.
    Temperature serves as the evaluative criterion for tank leakage, while external
    tank stress is the outcome of temperature changes post-leakage and is an indicator
    of tank material damage. The construction of traditional LNG tank leakage monitoring
    platforms often relies on point and surface monitoring. For instance, methods
    such as Fiber Bragg Grating (FBG) single-point monitoring [6], thermal imaging
    monitoring [7], and magnetic-thermal integrated monitoring [8] are employed. While
    these diverse methods in monitoring platforms offer real-time feedback on temperature
    changes, they still exhibit drawbacks such as singular monitoring, data isolation,
    and poor data interaction, meaning they cannot comprehensively reflect overall
    temperature changes in a certain sense. Therefore, the quest for a comprehensive
    leakage monitoring system from points and surfaces to the entire volume is one
    of the issues that need to be addressed in LNG tank health monitoring. Digital
    transformation is a crucial step in upgrading various industries. A Digital Twin
    (DT) is a virtual, digital model that replicates real-world entities or systems,
    enabling them to undergo simulation, monitoring, and analysis in a digital environment
    [9], [10], [11], [12]. In the realm of monitoring, the application of digital
    twins can enhance efficiency, improve decision-making processes, and address the
    shortcomings of insufficient information during monitoring. This provides a new
    development direction for innovative digital monitoring systems [13], [14]. The
    use of DT is in its infancy, and most of the research is still in the theoretical
    stage, lacking corresponding industry standards, for example, there are great
    differences in the total architecture level, the way of DT model building, and
    the main functions of the system, etc. DT model, as one of the most important
    modules in the framework connecting data and application platform, is a multi-domain,
    multi-disciplinary, and multi-dimensional integration model, however, the way
    of building by scholars also differs according to the application scenario. Mukherjee
    [15] constructed DT models that fuse mechanical models, sensors, control models,
    statistical models, big data, and machine learning to identify product attributes
    in 3D printing in a visual and highly accurate manner. Ritto [16] combined computational
    models with machine learning classifiers to construct DT models for the dynamic
    assessment of structural damage. The improved CycleGAN method of Zhao [17] maps
    the simulation data in virtual space to physical space and predicts the remaining
    life of rolling bearings by using the simulation data. Martinez [18] matches the
    simulation model with the initial dynamic model tree and realizes DT model simulation
    through data interaction. Negri [19] to balance the computing workload and accuracy,
    the DT model formed by the simulation model is introduced into the black box module
    to activate the corresponding model under specific behaviors. Wang [20] uses the
    Unity game engine as a platform and combines external data to generate a DT model,
    thus realizing a digital simulation of automatic driving. Aivaliotis [21] suggests
    that hierarchical modeling should be used to build the DT model, and modeling
    levels should be divided according to the importance of components in physical
    structure, to form a high-fidelity DT model. Ghosh [22] constructed the DT model
    using the hidden Markov model. Sun [23] combines point cloud data and theoretical
    models to build DT model, which is used to debug the assembly of high-precision
    products. Lu [24] studies resource virtualization as the key technology to create
    smart factory DT, and recommends Web language, Web Ontology Language (OWL), and
    Apache Jena (Jena) as modeling languages. The way scholars construct DT models
    can be summarized as simulation-based, data-based, or mathematical modeling, etc.,
    or in terms of driving methods, they are classified as data-driven and model-driven,
    etc. [25]. No matter how the model is built, the mapping of related indicators
    of physical entities is finally realized, but it can''t be universally applicable.
    To build DT model of temperature field and stress field of LNG storage tank, we
    understand DT model from the perspective of monitoring industry, which should
    have the ability to fuse local sensing data and realize real-time mapping of structural
    static and dynamic response [26]. Therefore, considering the precision, standardization,
    lightweight, and interactive visualization aspects of the twin model, this paper
    combines numerical simulation with sensor temperature data to construct a DT model.
    Furthermore, to achieve diagnostic and predictive capabilities for tank leakage
    scenarios, the temperature cloud map of the digital model is used for machine
    learning and deep learning. The method proposed in this paper offers several key
    contributions when compared to existing approaches. The main contributions can
    be summarized as follows: • We have utilized a temperature sensor network as the
    data-driven foundation and integrated a developed finite element computational
    model for temperature and stress in LNG storage tanks. This integration has resulted
    in the creation of a real-time monitoring digital twin model for tank temperature
    and stress. By comparing it with numerical simulations and theory, this model
    can comprehensively depict the physical state of the field. • Write an algorithm
    to flatten the DT temperature field nephogram, extract image features using machine
    vision, and use machine learning to achieve tank leakage diagnosis, leakage volume
    calculation, and leakage location calculation. • We utilized temperature cloud
    maps as samples in a time series, introducing the Seq2seq framework. Combining
    algorithms such as CNN, LSTM, and Self-Attention, we achieved spatiotemporal forecasting
    of the leakage area. The paper is organized in the following manner. Research
    background and related work is shown in section 1. Section 2 builds a DT model
    of the temperature and stress fields of LNG storage tanks. Section 3 uses artificial
    intelligence techniques such as machine vision, machine learning, and deep learning
    to achieve leak diagnosis and related prediction. Section 4 includes a conclusion
    and future works. 2. Digital twin modeling approach A digital twin (DT) model
    is an approach for modeling and simulating real physical entities. In traditional
    simulation methods, updates to physical entities and the transfer of model param
    often occur offline. In contrast, DT enables interaction between the physical
    model and the entity, facilitating the exchange of information and automatic updates
    of model param. To achieve this mapping from physical structures to digital models,
    the DT model integrates elements such as physical param, geometric models, point
    cloud models, network models, finite element models, and sensor networks, as shown
    in Fig. 1. Download : Download high-res image (266KB) Download : Download full-size
    image Fig. 1. DT model building process. 2.1. Finite element calculation model
    of temperature field and stress field The physical model of the selected liquefied
    natural gas (LNG) storage tank adopts a 160000 m3 full-capacity storage tank,
    which is located in the first phase project of Zhoushan LNG receiving and filling
    station in Zhejiang Province, China, and its structure is shown in Fig. 2. Storage
    tanks primarily consist of a concrete outer shell, an insulating layer, and a
    steel inner tank. The insulation layer of the LNG storage tank is composed of
    various materials to effectively reduce temperature transfer and heat loss. Specifically,
    the insulation materials are arranged in layers from the innermost to the outermost,
    consisting of fiberglass blankets, expanded perlite, and foam glass bricks reaching
    a height of 5 m. The combination of these insulation layers helps to maintain
    a relatively constant temperature state under the condition of the large temperature
    difference between the inside and outside of the storage tank, thus improving
    the efficiency and reliability of the storage tank. Download : Download high-res
    image (484KB) Download : Download full-size image Fig. 2. Structural diagram of
    160000 m3 LNG storage tank. With the fluctuation in temperature, the thermal and
    physical properties of the storage tank''s structural materials also change accordingly.
    To streamline calculations, it is common in engineering practice to approximate
    these thermal param as constants (Table 1). Table 1. Storage tank material properties.
    Material Density/(kg/m3) Thermal conductivity/(W/m.°C) Specific heat capacity/(J/kg.°C)
    Prestressed concrete 2500 2.326 837.21 Glass brick 146 0.05592 837.49 Elastic
    felt 16 0.03838 792 Liquefied Natural Gas 424 0.0687 4000 Pumice 65 0.0391 753.74
    2.1.1. Temperature field The heat transfer in LNG storage tanks primarily involves
    two modes: conduction and convection (Eqs. (1–2)). In this process, conduction
    mainly occurs between different materials within the tank structure, while convection
    predominantly takes place on the outer tank wall''s surface exposed to the environment.
    In the generalized coordinate system, Conservation of energy and Fourier''s law
    are applied to the system, and the thermal control equation obtained is shown
    in Eq. (3). (1) (2) (3) Where is the heat source; convective heat transfer coefficient,W/(m2.°C);
    represents the heat transfer conductivity, W/(m.°C); is the outer tank surface
    temperature; is the environmental convective temperature; is the specific heat,
    J/(kg.°C); is the heat source. Our objective is to acquire sensor data and use
    a finite element model for real-time temperature calculations. As a result, the
    governing differential equations are in a steady-state form. In addition, there
    is no heat source in the tank and the heat transfer conductivity is isotropic,
    the simplified matrix form of Eq. (3) is: (4) Among them: Differential control
    equations, as shown in Eq. (4), can be solved using certain differential methods.
    However, this solving approach often encounters significant challenges due to
    factors like the complexity of the structure and boundary conditions. In practical
    engineering, numerical computation methods such as finite difference methods,
    variational methods, and finite element analysis are commonly employed. Among
    these, the finite element analysis method stands out due to its generality, high
    precision, and broad applicability. It plays a crucial role in addressing real-world
    engineering problems involving fluid dynamics, electromagnetics, and thermal-solid
    coupling, and is widely used across various domains. In this paper, to simplify
    the control equations, the Galerkin method is chosen for solving [27], and use
    the linear shape function of the tetrahedral element as the weakening weight function,
    and get the governing equation as follows: (5) Applying Green''s formula to Weakened
    Control Equations: (6) Eq. (6) contains two terms, the first term can be understood
    as the heat conduction term, and the second term is the natural boundary term.
    Bringing convective boundary Eq. (2) into Eq. (6) yields: (7) Applying the control
    equations to the discretized grid: (8) Where is the node temperature and the integration
    matrix can be determined from the M−matrix consisting of the node coordinates
    as follows: Then the stiffness matrix and convective load matrix on the grid element:
    Structure''s load matrix and stiffness matrix: Where is the number of nodes in
    the solution domain; is the transformation matrix. The above is the finite element
    calculation flow of temperature field based on Galerkin method. After the computational
    model is written in Python, it is applied to the case with fixed boundary and
    convective boundary. By solving the equations composed of stiffness matrix and
    load matrix, the numerical solution of the temperature of the system nodes can
    be obtained. 2.1.2. Stress field Prestressed concrete is the main material used
    in the outer shell of LNG storage tanks, serving as a secondary protective component.
    In the event of a leak, if the outer shell comes into contact with low-temperature
    liquid, the significant temperature difference between the inner and outer walls
    could potentially lead to damage. Therefore, we use the temperature calculated
    by the twin temperature model as an external load, integrating it with the developed
    stress calculation model to generate a twin stress model for real-time stress
    monitoring of the outer shell. The finite element calculation of stress field
    is a vector field problem, which is solved numerically by the displacement of
    nodes in three directions. The governing equation of the stress problem is obtained
    by the combination of a geometric equation, physical equation, and equilibrium
    equation in elasticity. The governing equation of solid stress in statics is as
    follows: (9) Where is the differential operator; is the elastic matrix; is the
    displacement vector; is the body force. Similarly, in order to solve the partial
    differential equation, it is necessary to determine the boundary conditions of
    the structure, the boundary of the stress field contains two main categories:
    (10) (11) Where is the surface force; is the boundary displacement vector. The
    weight function is expressed by the linear shape function N of tetrahedral element,
    and Galerkin is applied to the governing equation. At the same time, the boundary
    Eq. (10) and Green''s formula are combined to simplify the governing equation,
    and the governing equation is obtained: (12) Since this paper focuses on determining
    the stresses due to temperature changes on the outer concrete tank, the initial
    strains due to temperature changes need to be taken into account, and since thermal
    expansion produces only line strains [28], the temperature initial strains are
    shown below: Where is the coefficient of linear expansion, °C−1; is the structure
    temperature, °C; and is the initial temperature, °C. Consider the initial strain
    as the nodal equivalent load added to the control equation: The structural temperature
    stress in LNG storage tanks is greater than the structural stress caused by the
    gravity load as well as the pre-stress load of the external tank due to the specificity
    of the storage medium, so we only consider the effect of temperature on the system
    and apply the control equations to the grid as follows: (13) Where is the node
    displacement; is the integration matrix, which can be determined from the inverse
    matrix of the tetrahedral node position matrix . The matrix is as follows: Then
    the system stiffness matrix and load matrix are as follows: The finite element
    calculation methods for both temperature and stress fields are solving a system
    of equations composed of matrices. In order to speed up the calculation efficiency
    of the program, the coefficient matrix is often blocked, that is, the known and
    unknown boundaries are separated, and the blocking matrix is as follows: Where
    the subscript E represents the fixed boundary and F represents the solution boundary
    The result of the equation solution is the nodal displacement, and the unit stress
    is found by inverse of the geometric and physical equations (Eq. (14)). Engineering
    often chooses to evaluate material damage using either the principal stress, which
    is an eigenvalue of the unit stress matrix (Eq. (15)), or the effective stress,
    which is derived from the principal stress (Eq. (16)). Once all the stresses on
    the nodes have been sought, we use the nodal smoothing principle to assign the
    cell stresses to the nodes, then the nodal stress values of the mesh model can
    be obtained. (14) (15) (16) 2.2. Verification of temperature and stress finite
    element calculations To validate the accuracy of the developed temperature and
    stress computation models, we opted to model the insulation layer and the outer
    wall of the LNG storage tank (Fig. 3). Using Python, we performed mesh generation
    and finite element calculations. Simultaneously, we compared the computed results
    with those obtained from Fluent simulations under identical conditions, as well
    as with theoretical expectations. This comparison is crucial in ensuring the reliability
    and accuracy of the models. By assessing how well the computed values align with
    Fluent simulations and theoretical predictions, we can establish the credibility
    of our models and their ability to accurately represent the temperature and stress
    behaviors in the selected components of the LNG storage tank. The bottom of the
    structure is a fixed boundary with a thickness of 0.5 m, the ambient temperature
    is preset to 30 °C, and the initial temperature of the structure is 22 °C. Download
    : Download high-res image (391KB) Download : Download full-size image Fig. 3.
    Schematic diagram of thermal conductivity of insulation layer. The theoretical
    calculation of the temperature field is based on Fourier''s law, which reduces
    the layers of material to a thermal resistance conduction problem, and the heat
    transfer equation for each layer of thermal resistance is shown below: Where is
    the respective material boundary temperature, °C; is the heat transfer conductivity,
    W/(m.°C); is the material thickness, m; is the heat flow density, J/(m2.s); is
    the outside temperature, °C; is the outside tank wall temperature, °C; is the
    material thickness, m; is the convection coefficient, 25 W/(m2.°C). The results
    of the Fluent calculation and the temperature model are shown in Fig. 4. The temperature
    profiles along the thickness direction calculated by the three methods are shown
    in Fig. 5. Download : Download high-res image (151KB) Download : Download full-size
    image Fig. 4. Calculated temperature field distribution of adiabatic layer structure.
    Download : Download high-res image (211KB) Download : Download full-size image
    Fig. 5. Comparison of the interface temperature of the insulation layer calculated
    by different methods. As shown in Fig. 4, the temperature distribution of each
    material calculated by the two methods is linear, which is consistent with the
    isotropic characteristics of thermophysical param of materials. Further from the
    statistical results in Fig. 5, it can be observed that the interface temperature
    values calculated by the three methods are similar, and the error is within 1
    °C. This shows that our temperature calculation model has high accuracy. The stress
    field of the outer tank is caused by temperature change. The concrete temperatures
    calculated by the temperature model were imported into the prepared stress model
    to solve for the thermal stresses. Also, the Fluent calculated temperature results
    were imported into the static structure module of ANSYS Workbench for thermal
    stress calculation. The total displacement and effective stresses of the concrete
    structure calculated in both ways are shown in Fig. 6 and Fig. 7. Download : Download
    high-res image (104KB) Download : Download full-size image Fig. 6. Python calculation
    results. Download : Download high-res image (112KB) Download : Download full-size
    image Fig. 7. ANSYS calculation results. From Fig. 6 and Fig. 7, it can be seen
    that the total displacement and effective stress distribution calculated by the
    two methods have high similarity, and the maximum total displacement is kept at
    0.165 mm, but there is a certain difference in the maximum effective stress, and
    the difference value is about 0.23 MPa. The reason for this difference is the
    different smoothing algorithms in the process of distributing the unit stress
    to the node stress, the mean value distribution principle applied in this paper,
    ANSYS The mixed threshold, and the mean distribution principle applied in this
    paper. From the comparison of stress distribution and stress values, the stress
    calculation model prepared in this paper can accurately reflect the stress distribution
    of the structure due to temperature changes. 2.3. LNG storage tank digital twin
    model building 2.3.1. Sensing network determination The DT model includes two
    parts: finite element calculation model and sensing network, and the construction
    of the DT model requires not only accurate calculation methods but also the integration
    of precise sensing data. We have opted for Fiber Bragg Grating (FBG) sensors for
    our sensor network. This choice stems from the fact that these sensors do not
    require electrical power and can be connected in series, rendering them highly
    suitable for application in hazardous storage environments [29], [30]. Many gratings
    are installed on the optical fiber in a certain proportion to form FBG. When a
    beam of light irradiates the fiber grating, part of it is transmitted, and part
    of it is reflected back. Among the reflected light, there is a special wavelength
    of light, which is formed by the weak reflection of a large number of gratings.
    It can be identified by a demodulator. The reflection wavelength is related to
    the grating spacing (grating period) and the refractive index of the optical fiber.
    When temperature or strain changes, it will affect the grating spacing and the
    refractive index of the optical fiber, thereby affecting the reflection wavelength.
    Therefore, scholars have applied FBG to temperature, strain, or stress monitoring,
    forming one of the most widely used sensors in the current monitoring industry.
    To investigate the sensing range of Fiber Bragg Grating (FBG), we conducted a
    temperature sensing experiment. The experiment was conducted on a vertical tank
    with a floating roof, measuring 2.6 m in height and 3 m in diameter. Liquefied
    petroleum gas was used as a simulated combustion heat source. Five serially connected
    FBG temperature sensors were strategically placed around the tank wall, as illustrated
    in Fig. 8. The FBG and data acquisition equipment were supplied by Beijing Dakai
    Technology Co., Ltd., featuring an integrated device with a fused light source
    emitter and demodulator. The param of the FBG are detailed in Table 2. To eliminate
    data errors caused by external tank deformations, the FBG sensors were encased
    in aluminum tubes and securely fastened using heat-resistant tape. Download :
    Download high-res image (387KB) Download : Download full-size image Fig. 8. Layout
    scheme of temperature sensing experiment. Table 2. The main parameters of FBG.
    Protection grade IP66 Measuring range −169℃ ∼ +120℃ Grating period 1525 nm～1565
    nm Accuracy ±0.5℃ Using fatigue Reuse Resolution 0.1℃ Number 5 Package Explosion
    proof shell surface nickel plating During the experimental process, the height
    of the floating roof was 1.9 m. The sensors were positioned 0.2 m away from the
    surface of the floating roof, and the combustion source was placed on the floating
    roof surface. The burning continued for 60 min, and temperature data distribution
    was collected and calculated, as shown in Fig. 9. Download : Download high-res
    image (153KB) Download : Download full-size image Fig. 9. Sensor temperature distribution.
    By observing Fig. 9, it can be seen that the temperature change pattern of the
    measuring point is closely related to the distance between the measuring point
    and the fire source. For example, the No.1 sensor, which is 0.75 m away from the
    fire source, shows obvious temperature change, its temperature change rate is
    large, and its temperature rise rate is fast, which indicates that it is fast
    and sensitive to the fire source; The temperature of sensors 2 and 5 with a distance
    between 1 m and 1.5 m varies to some extent, but the heating amplitude and rate
    are not significant, indicating a certain perception of the fire source; The sensors
    3 and 4 have weaker sensitivity to fire sources and experience minimal temperature
    changes. Therefore, applying the FBG at a distance of approximately 3 m is ideal
    within the temperature monitoring network. The arrangement of storage tank sensors
    is shown in Fig. 10. Download : Download high-res image (117KB) Download : Download
    full-size image Fig. 10. Distribution of temperature measurement points in LNG
    storage tanks. 2.3.2. Digital twin model building We build the sensor network
    and the finite element calculation method, the next is to use Python fusion to
    build DT model. Firstly, we model the 160,000 m3 storage tank by finite element
    method. In the process of constructing the finite element model, we need to discretize
    the structure, and the discretized nodes are similar to the point cloud model
    in engineering. To create the node model for finite element analysis, we utilized
    Revit and Geomagic Design X to generate a point cloud model of the storage tank.
    Additionally, to enhance the quality of the point cloud, we applied Python''s
    Open3d and Pyvista modules to downsample, smooth, and convert the point cloud
    into tetrahedral meshes. In order to improve the calculation efficiency, the LNG
    element is not included in the finite element calculation model. Each parameterized
    model is shown in Fig. 11. Download : Download high-res image (459KB) Download
    : Download full-size image Download : Download high-res image (302KB) Download
    : Download full-size image Fig. 11. Temperature and stress calculation model.
    By integrating geometric, point cloud, and finite element models into a computational
    model, we can perform temperature field calculations for the storage tank. However,
    to reflect the temperature data of the physical field, it is essential to consider
    the initial conditions of sensor data. At this point, we can continuously read
    sensor temperature data and, based on the twin model, compute the overall temperature
    data in real-time, thus achieving the transition from sensor point monitoring
    to global temperature data monitoring. At the same time, node temperature data
    as equivalent load input to the external tank stress field calculation model,
    to solve the displacement and stress of the external tank, thus generating the
    LNG tank stress field DT model. In order to verify the mapping effect of the DT
    model, we simulate the physical field leakage with Fluent, the leakage location
    is set in the inner wall of glass fiber blanket (X: 40 m, Y: 0 m, Z: 8 m), the
    leakage area is 0.01 m2, the leakage adopts multiphase flow VOF (Volume of Fluid)
    model, and the insulation layer is simulated using porous media. In the calculation
    process, we will output the corresponding node temperature in the sensor network
    in real-time. Using Python, we store the sensing data for each time step in rows
    into a local MYSQL database list. Then, we can use the Pymysql module to read
    these temperature data and transmit them to DT model for real-time temperature
    and stress calculation. When the leakage duration reaches 900 s, the results of
    temperature field and stress field calculated by DT model are shown in Fig. 12
    and Fig. 13. Download : Download high-res image (249KB) Download : Download full-size
    image Fig. 12. Temperature field calculation cloud. Download : Download high-res
    image (393KB) Download : Download full-size image Fig. 13. Calculation nephogram
    of stress and displacement of external tank. Based on the calculation results
    in Fig. 12, it is evident that when a leak occurs, the leaked liquid from the
    inner tank initially spreads downward. The diffusion range is symmetrically distributed
    at the leakage position. In addition, because the insulation layer is a porous
    medium, the liquid seepage velocity is slow, so the boundary profile is relatively
    smooth. It is worth noting that the temperature field calculated by DT model is
    consistent with the physical field temperature distribution simulated by Fluent,
    although there may be some slight differences on the boundary of the leakage area
    due to the difference in the grid. Fig. 13 shows the total displacement and effective
    stress nephogram of the nodes of the concrete outer tank calculated by the two
    methods due to temperature change. The thermal-solid coupling responses calculated
    by the two methods are also similar in value and distribution state, and there
    is stress concentration at the leakage position. The effective stress at the bottom
    of the tank wall is lower than the stress in the leakage area, which shows that
    the thermal protection angle has an obvious insulation effect on the bottom of
    the tank wall. In order to compare the temperature and stress values calculated
    by the two methods, the temperature and stress along the height at the leakage
    location are extracted as shown in Fig. 14. Download : Download high-res image
    (314KB) Download : Download full-size image Fig. 14. Nodal response comparison
    curve along the height. From the results in Fig. 14 (a), it can be observed that
    no matter which calculation method, the temperature distribution shows that the
    temperature near the leakage point is the lowest, while the temperature far away
    from the leakage point gradually increases. Additionally, the thermal protection
    angle can effectively safeguard the bottom area of the storage tank, resulting
    in minimal temperature variations in that region. From the change trend of the
    whole curve and the temperature value, the temperature difference between the
    two calculation methods at the leakage point is about 15 °C, and the temperature
    at other height positions is similar. From Fig. 14 (b), due to the differences
    in grid division density and node stress smoothing algorithm of the two methods,
    there are slight differences in their values, and the maximum difference is about
    2.5 MPa at the vertex of thermal protection angle. This reason may be the stress
    change caused by the difference between the two grids when Fluent transfers node
    temperature to ANSYS static structure. However, from an unfavorable point of view,
    the maximum values of both calculated effective stresses occur at the location
    of the leakage point, and the maximum values do not differ much, which indicates
    that the DT model can map the stress state of the physical field at the stress
    field calculation, and can provide stress data for the management and safety evaluation
    of LNG storage tanks. 3. Leakage diagnosis DT monitoring platform for LNG storage
    tank temperature and stress should have real-time and highly sensitive sensing
    ability, especially provide timely feedback and alarm when leakage events occur.
    With the development of computer level, artificial intelligence algorithm(AI)
    is gradually applied to system diagnosis, prediction, decision-making, management
    optimization, and other functional modules [31], [32], [33]. With powerful data
    processing ability, adaptive learning ability, and multi-source data integration
    ability, it provides managers with more accurate, comprehensive, and timely prediction
    and diagnosis results. Applying AI algorithms to the leak diagnosis module of
    the DT platform requires reasonable sample features. Temperature scalar field
    data can reflect the structural state more clearly than the stress field, so we
    use the node temperatures calculated by the DT model as samples and introduce
    machine learning or deep learning to achieve leak determination, leak volume calculation,
    leak location calculation, and temporal prediction of the leak range. If we use
    the full node temperature values as parallel features for training, this not only
    has low computational efficiency, but also the data does not reflect the spatial
    correlation between nodes well. In order to solve this problem, we flattened the
    mesh of the interface between the glass fiber blanket and perlite, and extracted
    the features of the flattened temperature nephogram by machine vision, which was
    used as an effective sample of the training model. The LNG storage tank has a
    circumferential symmetric structure, and the flattening of the grid is also a
    node flattening. As shown in Fig. 15, the point P1 on the plane is flattened to
    P2 around the center point P, and the P2 coordinate can be obtained according
    to the coordinate axis transformation (Eq. (17)). Taking the sensor anomalies
    identified by the system as the center point, we flatten all nodes on the interface
    between perlite and glass fiber blanket by coordinate transformation, and record
    the corresponding transformation index. The flattened plane is shown in Fig. 16.
    (17) The coordinates of are ; the coordinates of are ; the coordinates of are
    ; is the radius of the intersection. Download : Download high-res image (57KB)
    Download : Download full-size image Fig. 15. Schematic diagram of point coordinate
    transformation. Download : Download high-res image (256KB) Download : Download
    full-size image Fig. 16. DT model calculates the temperature nephogram spreading.
    In order to build a training sample set, we use Fluent to simulate leakage conditions
    at different heights. The simulated sensing data is collected once in 1 s and
    uploaded to the local database and DT platform in real time. The DT platform outputs
    the calculated temperature flattening nephogram, and the size of the nephogram
    is 256*256. Because the LNG storage tank is of circumferential symmetry, Fluent
    simulates that the leakage hole is located on the intersection line between x-z
    plane and the inner wall of glass fiber blanket, and the leakage hole is square.
    The specific working conditions are shown in Table 3. Table 3. Fluent simulation
    information for different leakage conditions. Conditions H/m A/m2 t/s Nephogram
    Conditions H/m A/m2 t/s Nephogram 1 2 0.01 1800 7 10 0.04 600 2 2 0.04 600 8 10
    0.0025 1800 3 2 0.0025 1800 9 12 0.01 1800 4 5 0.01 1800 10 15 0.01 1800 5 8 0.01
    1800 11 20 0.01 1800 6 10 0.01 1800 12 25 0.01 1800 Where H is the distance of
    the leak hole from the bottom of the tank; A is the area of the leak hole; t is
    the collection time. 3.1. Leak diagnosis, volume calculation and leak location
    calculation Leak diagnosis, calculation of leak volume and calculation of leak
    location can be regarded as typical classification and regression problems in
    machine learning. We take the spreading temperature nephogram as a sample and
    use Opencv for feature extraction of the image. The leak diagnosis can extract
    the grayscale information of the temperature nephogram and classify 0 and 1 using
    support vector classification (SVC). Leak volume calculation uses the mask algorithm
    to extract the area of the leak area and find out the relationship between the
    area and the real leak volume according to linear regression. The leak location
    calculation can extract the center coordinates of the leak area at the early stage
    of the leak as a feature, and compare the calculation effect of three algorithms:
    linear regression, random forest regression, and vector machine regression. The
    specific process is shown in Fig. 17. Download : Download high-res image (486KB)
    Download : Download full-size image Fig. 17. Leak diagnosis flow chart. From the
    Fig. 17, it can be seen that the leak diagnosis belongs to a relatively simple
    0,1 classification, and the SVM classification can achieve very accurate accuracy.
    The prediction of leakage volume relies on the morphological features of the image,
    by calculating the area of the leakage region by extracting temperature-dependent
    colors within the range of [-110 °C, −162 °C] as the feature. Traditional calculation
    methods attempt to reverse calculate the area of the region to obtain the true
    area, and then multiply it by the thickness to obtain the leakage volume, but
    this method obviously has issues with rigorous calculation. In order to solve
    this challenge, we chose to use the area of the region as a feature, and used
    the true leakage volume as an indicator for machine learning. We used 4201 images
    as learning samples, with a training set to test set ratio of 9:1. Due to the
    fact that the extracted leakage area is the incomplete projection of the leaked
    fluid on the interface, there is a strong correlation between them. Therefore,
    from the fitting results of the test set (Fig. 18), it can be observed that linear
    regression can achieve high prediction accuracy. This image-based morphological
    and machine learning method provides an effective and accurate approach for predicting
    leakage volume, overcoming the limitations of traditional calculation methods.
    Download : Download high-res image (85KB) Download : Download full-size image
    Fig. 18. Leakage volume prediction regression curve. The leak location can be
    vaguely judged in the interactive module of the system. To determine the leak
    location more accurately, we take the nephogram of 12 working conditions for 30
    s as samples, and use Opencv to extract the central position of the leak area
    as features. Because the correlation between features and prediction indicators
    is not high, we use three algorithms to train the model: linear regression, vector
    machine regression and random forest regression. The prediction results of the
    three models for the test set (working condition (5) are shown in Table 4. Table
    4. Statistics of leakage height indicators predicted by regression algorithm.
    Algorithm Predicted leakage height (m) Leakage position error (m) MSE Linear regression
    7.3 0.7 1.31 Vector Machine (SVR) 9.98 1.98 9.17 Random Forest 9.58 1.58 6.2 As
    can be seen from Table 4, the support Vector Regression (SVR) is a nonlinear regression
    algorithm based on the maximum interval principle, and the random forest is an
    integrated learning regression method based on decision trees. The calculation
    of leak height by both methods is not as effective as linear regression, and the
    linear regression predicts the leak height error of 0.7 m, indicating that there
    is a linear correlation between the leak location and the center of the initial
    leak area. Therefore, the linear regression algorithm can be introduced in the
    diagnosis module after a leak occurs in an LNG storage tank to assist managers
    in grasping specific leak location information. The diagnostic module that applies
    the trained model to DT is shown in Fig. 19. Download : Download high-res image
    (289KB) Download : Download full-size image Fig. 19. Training model for platform
    visualization. 3.2. Spatiotemporal prediction of leakage area Spatio-temporal
    prediction of leakage area can help managers master more information of leakage
    range in the future, and provide data for management and protection after leakage.
    Traditional forecasting methods include analytical and statistical methods, which
    are time-consuming and labor-intensive, and have low accuracy. With the development
    of computer technology, the prediction method of artificial intelligence is gradually
    applied to the data processing of time series, but the application cases in image
    time series are still very few. LSTM (Long Short-Term Memory) is a special kind
    of Recurrent Neural Network (RNN), which can simply realize the prediction of
    long and short time series of gray images. The principle is to expand the image
    data into one-dimensional vectors for training, which causes the algorithm to
    only pays attention to the sequence information and ignores the spatial correlation
    of images. Moreover, if it is used in the three-channel (RGB) images collected
    in this paper, the prediction effect is worse. Therefore, we introduce Convolutional
    Neural Network (CNN), which is a typical deep learning feedforward network that
    can effectively extract effective features of images with strong discriminative
    ability and generalization capability. We can use CNN to extract features from
    images and expand the extracted effective features into one-dimensional vectors
    for LSTM training. In addition, because the final output of LSTM is still a one-dimensional
    vector, in order to extend the vector to a three-channel image format, Seq2Seq
    (Sequence-to-Sequence) architecture is introduced. Seq2Seq architecture includes
    Encoder and Decoder. The Encoder can extract features from input pictures by convolution,
    input features to LSTM for time series training, and output trained data to Decoder.
    The Decoder includes several deconvolution, and generates three-channel images
    from one-dimensional vectors. At the same time, in order to solve the problem
    of miscellaneous input information and assign weights to input sequences, Self-Attention
    Mechanism is introduced. The specific implementation flow is shown in Fig. 20.
    Download : Download high-res image (453KB) Download : Download full-size image
    Fig. 20. Spatio-temporal prediction flow of leakage area. We select the temperature
    nephogram of Working Condition (1) as the sample set, the temperature nephogram
    size is 256*256, and the sample set size is 1800. In order to improve the calculation
    speed, the sample set is down-sampled every 10 s, totaling 180 pictures. The training
    slide window is 16, that is, the first 16 pictures in time sequence predict the
    17th picture. We use the first 160 images of the sample as the training set and
    the last 20 images as the test set. The loss function curves generated by the
    training model and the training output results are shown in Fig. 21. Download
    : Download high-res image (142KB) Download : Download full-size image Fig. 21.
    Model loss error diagram. As can be seen from Fig. 21, the loss error of image
    time series prediction under Seq2Seq architecture decreases rapidly, which is
    due to the high proportion of blank areas in image features. From the prediction
    results of deconvolution output, with the increase of iteration times, the chromatographic
    characteristics of the predicted image gradually approach the training sample,
    and when the iteration times are 1500 times, the color distribution of the model
    output map is close to the sample map. In order to test the prediction ability
    of the model, we do prediction analysis on the validation set and predict the
    images outside the acquisition time, and the prediction results are shown in Fig.
    22, and the statistical leakage area is shown in Fig. 23. Download : Download
    high-res image (228KB) Download : Download full-size image Fig. 22. Model prediction
    nephogram. Download : Download high-res image (134KB) Download : Download full-size
    image Fig. 23. Comparison of leakage area on predicted nephogram with real value.
    It can be seen from Fig. 22 that the prediction results of the model on the test
    set are similar to the leakage contour of the true nephogram, and the nephogram
    outside the prediction time range can also keep a reasonable range and spread
    symmetrically. From the statistics in Fig. 23, it can be seen that the mean error
    between the predicted leakage area and the area of the true value on the graph
    is about 17 Pixels, which maps to a leakage volume of about 12 m3 on the tank,
    and this prediction error is acceptable for a large structure like an LNG storage
    tank. In addition, the area prediction outside the time range is also linear-like,
    and the growth gradient of the area of the leaking region is similar to the real
    gradient. Therefore, this paper is based on the Seq2Seq architecture under the
    fusion of CNN and LSTM image space–time sequence algorithms, which can predict
    the future changes of the leaking area better. The trained model can be put into
    the prediction module of DT. When leakage occurs, it can predict the leakage temperature
    nephogram in real time and strengthen learning, and give visual location information
    for targeted prevention after leakage. Fig. 24 shows mapping the prediction results
    of the training model to the storage tank. Download : Download high-res image
    (284KB) Download : Download full-size image Fig. 24. Mapping of predicted contours.
    4. Conclusion and future works Temperature field and stress field are vital monitoring
    indicators for ensuring the safe operation of LNG storage tanks. To achieve real-time,
    multidirectional perception of the temperature field and stress field in storage
    tanks, we have employed Digital Twin (DT) technology for monitoring LNG storage
    tanks and investigated key technologies such as DT model construction and leakage
    diagnosis. The specific tasks conducted in this study are as follows: ● We have
    employed a temperature sensor network as a bridge connecting the physical and
    digital structures. By integrating geometric models, point cloud models, and a
    developed finite element model, we created a digital twin model for real-time
    inversion of the overall temperature and stress in LNG storage tanks. Through
    comparison with theoretical and numerical simulation results, this digital twin
    model not only accurately reflects the temperature and stress field states of
    LNG tanks but also provides comprehensive data support for the safety assessment
    of the tanks. ● In order to realize intelligent diagnosis of LNG storage tank,
    the temperature nephogram calculated by DT model is flattened, and features such
    as gray histogram, leakage area, center position, and contour are extracted by
    machine vision. Machine learning algorithms such as SVM and linear regression
    are used to realize leakage judgment, leakage volume calculation, and leakage
    position calculation. ● By combining algorithms such as CNN, LSTM, Seq2seq, and
    Self-attention, the flattened nephogram of the time series was trained to achieve
    spatiotemporal prediction of the leakage area. Compared with the test set, the
    fusion algorithm has good performance and high accuracy in predicting image time
    series. Establishing DT model of temperature and stress of LNG storage tank is
    one of the key researches in the digital transformation of LNG storage tank monitoring.
    Through the establishment of this model, we can more accurately understand and
    predict the temperature and stress changes of LNG storage tanks, and then take
    timely measures to ensure the safety and reliability of its operation. This research
    is not only of great significance in the field of tank monitoring, but also provides
    a powerful reference for the application of digital technology in other fields.
    However, there is still something to discuss in this paper on the way to build
    DT model. At present, the application of DT technology is in the initial stage,
    and there is no industry standard at home and abroad to provide reference and
    comparison, especially the construction of such an important module as DT model.
    From the DT model building methods of domestic and foreign scholars, they can
    basically be classified as data-driven, model-driven, physically-driven and numerically-driven,
    etc. However, DT models are the result of multidisciplinary collaboration, and
    each method cannot be fully applicable to different industries. We believe that
    no matter which method is applied, it should start from the actual engineering
    problems. First of all, the method in this paper is a DT model constructed by
    integrating sensor data with finite element model. Although it lacks experimental
    comparison support, it can be seen from the comparison results with widely used
    finite element software and theoretical formulas that the model constructed in
    this paper has a high accuracy. In addition, there are still some problems in
    the simulation calculation of the massive structure of the digital twin model,
    such as calculation delay and low robustness. It seems that machine learning or
    deep learning can solve these problems, but through our preliminary experiments,
    these trainings not only need a large number of samples, but also too many nodes
    lead to slow training speed and poor spatial correlation, thus leading to poor
    training results. So we still need to explore better methods to improve the built
    DT model. In addition, this paper does the leakage range prediction under time
    series for nephogram, although the method is better than doing prediction with
    node temperature data, but there are still disadvantages such as large image data,
    slow training process, and poor prediction for samples with different leakage
    conditions, we still need to explore new algorithms so as to have higher generalization
    ability and learning ability. This article establishes temperature and stress
    digital twin models for LNG storage tanks. In the process of model establishment,
    the framework ideas and basic data were borrowed from our previously published
    article “Research on digital twin based temperature field monitoring system for
    LNG storage tanks” to ensure the completeness of this paper and enrich the twin
    framework proposed. Overall, in order to achieve the work of perception, recognition,
    and evaluation of smart digital monitoring, this study extends the temperature
    twin model to the stress model and applies artificial intelligence algorithms
    to tank leakage diagnosis, which basically achieves functions such as perception
    and recognition. Heat stress assessment is the final result of this twin system,
    which requires us to conduct a large number of mechanical simulations and experiments
    on prestressed concrete outer tanks to establish corresponding safety standards.
    This is also one of our future work goals. Although digital twins are an innovative
    and disruptive concept, they may not mature in the short term. However, throughout
    the research process, steady breakthroughs in each key technology are crucial.
    CRediT authorship contribution statement Yujian Wu: Writing – review & editing,
    Writing – original draft, Visualization, Software, Formal analysis, Data curation,
    Conceptualization. Gang Yang: Writing – original draft, Resources, Project administration,
    Conceptualization. Jiangang Sun: Writing – original draft, Resources, Project
    administration, Methodology, Conceptualization. Lifu Cui: Visualization, Validation,
    Data curation, Conceptualization. Mengzhu Wang: Formal analysis, Data curation,
    Conceptualization. Declaration of competing interest The authors declare that
    they have no known competing financial interests or personal relationships that
    could have appeared to influence the work reported in this paper. Acknowledgement
    This work was supported by the National Natural Science Foundation of China. The
    fund number of the project is 51878124. Data availability No data was used for
    the research described in the article. References [1] Grammelis, Panagiotis. Energy,
    Transportation and Global Warming / Monograph. 2016. Print. Green Energy and Technology.
    Google Scholar [2] United Nations. Paris Agreement[EB/OL]. (2015-12-12)[2022-11-11].
    https://www.un.org/zh/ documents/treaty/ FCCC-CP-2015-L.9-Rev.1.1. Google Scholar
    [3] C. Lee, Y. Lim, C. Han Operational strategy to minimize operating costs inliquefied
    natural gas receiving terminals using dynamic simulation Korean J. Chem. Eng.,
    29 (4) (2012), pp. 444-451 CrossRefView in ScopusGoogle Scholar [4] Y. Li, X.
    Chen, M.H. Chein Flexible and cost-effective optimization of BOG (boil-off gas)
    recondensation process at LNG receiving terminals Chem. Eng. Res. Des., 90 (2012),
    pp. 1500-1505 View PDFView articleView in ScopusGoogle Scholar [5] W. Hong, S.
    Shen, Z. Wang, et al. A cryogenic sensor based on fiber Bragg grating for storage
    monitoring of liquefied natural gas[J] Cryogenics, 97 (2019), pp. 7-12 View PDFView
    articleView in ScopusGoogle Scholar [6] L. Zhao, G.W. Zhang, Q. Zhang, et al.
    Multi-point temperature monitoring system for the LNG storage tank Appl Mech Mater,
    511–512 (2014), pp. 282-285 View in ScopusGoogle Scholar [7] G.W. Fan, Y. Shen,
    X.W. Hao, et al. Large-Scale wireless temperature monitoring system for liquefied
    petroleum gas storage tanks Sensors (basel), 15 (9) (2015), pp. 23745-23762 CrossRefView
    in ScopusGoogle Scholar [8] G. He, T. He, K. Liao, et al. A novel three-dimensional
    non-contact magnetic stress inspection technology and its application on LNG pipeline
    //International Pipeline Conference Am. Soc. Mech. Eng., 84461 (2020) V003T04A028
    Google Scholar [9] F. Tao, J. Cheng, Q. Qi, M. Zhang, H. Zhang, F. Sui Digital
    Twin-Driven Product Design, Manufacturing and Service With Big Data Int. J. Adv.
    Manuf. Technol, 94 (9–12) (2018), pp. 3563-3576 CrossRefView in ScopusGoogle Scholar
    [10] C. Li, S. Mahadevan, Y. Ling, S. Choze, L. Wang Dynamic Bayesian Network
    for Aircraft Wing Health Monitoring Digital Twin AIAA J., 55 (3) (2017), pp. 930-941
    View in ScopusGoogle Scholar [11] E. Grange L.A Roadmap for Adopting a Digital
    Lifecycle Approach to Offshore Oil and Gas Production Offshore Technology Conference,
    Houston (2018) Google Scholar [12] M.G. Shirangi, E. Furlong, K.S. Sims Digital
    Twins for Well Planning and Bit Dull Grade Prediction SPE Norway Subsurface Conference,
    Virtual (2020) Google Scholar [13] G. Chen, J. Zhu, Y. Zhao Digital twin modeling
    for temperature field during friction stir welding J. Manuf. Process., 64 (2021),
    pp. 898-906 View PDFView articleView in ScopusGoogle Scholar [14] Y. Liu, H. Ren
    Acquisition method of evaluation stress for the digital twin model of ship monitoring
    structure Appl. Ocean Res., 129 (2022), Article 103368 View PDFView articleView
    in ScopusGoogle Scholar [15] T. Mukherjee DEBROY T.A digital twin for rapid quali-fication
    of 3D printed metallic components.Applied Ma-Terials Today, 14 (2019), pp. 59-65
    View PDFView articleView in ScopusGoogle Scholar [16] T.G. Ritto, F.A. Rochinha
    Digital twin, physics-based model, and machine learning applied to damage detection
    in structures Mech. Syst. Sig. Process., 107614 (2021) Google Scholar [17] W.
    Zhao, C. Zhang, B. Fan, et al. Research on rolling bearing virtual-real fusion
    life prediction with digital twin Mech. Syst. Sig. Process., 110434 (2023) Google
    Scholar [18] G. Martinez, S. Sierla, T. Karhela, et al. Automaticgeneration of
    a simulation-based digital twin of an industrialprocess plant //IECON 2018–44th
    Annual Conferenceof the IEEE Industrial Electronics Society IEEE, Washington (2018),
    pp. 3084-3089 CrossRefGoogle Scholar [19] E. Negri, L. Fumagalli, C. Cimino, et
    al. FMU-supported simulation for CPS digital twin.Procedia Manufacturing, 28 (2019),
    pp. 201-206 View PDFView articleView in ScopusGoogle Scholar [20] Z. Wang, K.
    Han, P. Tiwari Digital Twin Simulation of Connected and Automated Vehicles with
    the Unity Game Engine[C] 2021 IEEE 1st International Conference on Digital Twins
    and Parallel Intelligence (2021), pp. 1-4 Google Scholar [21] P. Aivaliotis, K.
    Georgoulias, Z. Arkouli, et al. Methodology for enabling digital twin using advanced
    physics-based modelling in predictive maintenance Procedia CIRP, 81 (2019), pp.
    417-422 View PDFView articleView in ScopusGoogle Scholar [22] A. Ghosh, A. Ullah,
    A. Kubo, Hidden Markov model-based digital twin construction for futuristic manufacturing
    systems .Ai Edam,2019,33(3):317-331. Google Scholar [23] X. Sun, J. Bao, J. Li,
    et al. A digital twin-driven approach for the assembly-commissioning of high precision
    products. Robotics and Computer-ntegrated Manufacturing,2020,61:101839. Google
    Scholar [24] Y. Lu, Xu x. Resource virtualization:a core technology for developing
    cyber-physical production systems.Journal of Manuf. Syst., 47 (2018), pp. 128-140
    View PDFView articleView in ScopusGoogle Scholar [25] A. Rasheed, O. San, T. Kvamsdal
    Digital twin: values, chal-lenges and enablers from a modeling perspective IEEE
    Access, 8 (2020), pp. 21980-22012 CrossRefView in ScopusGoogle Scholar [26] F.
    Tao, M. Zhang, A.Y.C. Nee Chapter 1 - background and concept of digital twin F.
    Tao, M. Zhang, A.Y.C. Nee (Eds.), Digital Twin Driven Smart Manufacturing, Academic
    Press (2019), pp. 3-28 View PDFView articleView in ScopusGoogle Scholar [27] J.
    Fish, T. Belytschko A First Course in Finite Elenments John Wiley & Sons Ltd,
    England (2007) Google Scholar [28] S. Moaveni Finite Element Analysis: Theory
    and Application with ANSYS (Tird Edition), Publishing House of Electronics Industry,
    Beijing (2008) Google Scholar [29] S.W. James, R.P. Tatam, A. Twin, et al. Strain
    response of fibre Bragg grating sensors at cryogenic temperatures Meas Sci Technol,
    13 (2002), pp. 1535-1539 View in ScopusGoogle Scholar [30] P. Saidi, P.R.L.N.
    Sai, G.D. Sen, et al. Polymer-coated fiber Bragg grating sensor for cryogenic
    temperature measurements Microwave Opt Technol Lett, 53 (5) (2011), pp. 1095-1100
    Google Scholar [31] P. Sotirios, F. Fabio, L. Marida, et al. Feature investigation
    with Digital Twin for predictive maintenance following a machine learning approach
    IFAC-PapersOnLine, 55 (2) (2022), pp. 132-137 Google Scholar [32] J. Lu, Z. Yan,
    J. Han, et al. Data-Driven Decision-Making (D3M): Framework, Methodology, and
    Directions IEEE Transactions on Emerging Topics in Computational Intelligence,
    3 (4) (2019), pp. 286-296 CrossRefView in ScopusGoogle Scholar [33] Z. Ren, J.
    Wan, P. Deng Machine-Learning- Driven Digital Twin for Lifecycle Management of
    Complex Equipment IEEE Trans. Emerg. Top. Comput., 10 (1) (2022), pp. 9-22 CrossRefView
    in ScopusGoogle Scholar Cited by (0) View Abstract © 2024 Elsevier Ltd. All rights
    reserved. Recommended articles Hierarchical detection of wildfire flame video
    from pixel level to semantic level Expert Systems with Applications, Volume 42,
    Issue 8, 2015, pp. 4097-4104 Yaqin Zhao, …, Mingming Xu View PDF High-Precision
    large deformation measurement of array SAR based on FBG strain monitoring and
    initial state reconstruction Measurement, Volume 228, 2024, Article 114381 Chunyu
    Qu, …, Junfang Bao View PDF Evaluation of onboard sensors for track geometry monitoring
    against conventional track recording measurements Measurement, Volume 229, 2024,
    Article 114354 Hengcheng Zhang, …, Michael E. Cholette View PDF Show 3 more articles
    About ScienceDirect Remote access Shopping cart Advertise Contact and support
    Terms and conditions Privacy policy Cookies are used by this site. Cookie settings
    | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V.,
    its licensors, and contributors. All rights are reserved, including those for
    text and data mining, AI training, and similar technologies. For all open access
    content, the Creative Commons licensing terms apply."'
  inline_citation: '>'
  journal: 'Measurement: Journal of the International Measurement Confederation'
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Digital twin modeling and leak diagnosis of temperature and stress fields
    in LNG storage tanks
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Kumari S.
  - Tulshyan V.
  - Tewari H.
  citation_count: '0'
  description: Due to rising cyber threats, IoT devices’ security vulnerabilities
    are expanding. However, these devices cannot run complicated security algorithms
    locally due to hardware restrictions. Data must be transferred to cloud nodes
    for processing, giving attackers an entry point. This research investigates distributed
    computing on the edge, using AI-enabled IoT devices and container orchestration
    tools to process data in real time at the network edge. The purpose is to identify
    and mitigate DDoS assaults while minimizing CPU usage to improve security. It
    compares typical IoT devices with and without AI-enabled chips, container orchestration,
    and assesses their performance in running machine learning models with different
    cluster settings. The proposed architecture aims to empower IoT devices to process
    data locally, minimizing the reliance on cloud transmission and bolstering security
    in IoT environments. The results correlate with the update in the architecture.
    With the addition of AI-enabled IoT device and container orchestration, there
    is a difference of 60% between the new architecture and traditional architecture
    where only Raspberry Pi were being used.
  doi: 10.3390/info15030126
  full_citation: '>'
  full_text: '>

    "This website uses cookies We use cookies to personalise content and ads, to provide
    social media features and to analyse our traffic. We also share information about
    your use of our site with our social media, advertising and analytics partners
    who may combine it with other information that you’ve provided to them or that
    they’ve collected from your use of their services. Consent Selection Necessary
    Preferences Statistics Marketing Show details                 Deny Allow selection
    Allow all    Journals Topics Information Author Services Initiatives About Sign
    In / Sign Up Submit   Search for Articles: Information All Article Types Advanced   Journals
    Information Volume 15 Issue 3 10.3390/info15030126 Submit to this Journal Review
    for this Journal Propose a Special Issue Article Menu Academic Editors Krzysztof
    Szczypiorski Daniel Paczesny Subscribe SciFeed Recommended Articles Related Info
    Link More by Authors Links Article Views 1045 Table of Contents Abstract Introduction
    Related Work Methodology Design and Implementation Evaluation Conclusions Author
    Contributions Funding Institutional Review Board Statement Informed Consent Statement
    Data Availability Statement Conflicts of Interest References share Share announcement
    Help format_quote Cite question_answer Discuss in SciProfiles thumb_up Endorse
    textsms Comment first_page settings Order Article Reprints Open AccessArticle
    Cyber Security on the Edge: Efficient Enabling of Machine Learning on IoT Devices
    by Swati Kumari 1,2,†, Vatsal Tulshyan 1,† and Hitesh Tewari 1,* 1 School of Computer
    Science & Statistics, Trinity College Dublin, D02 PN40 Dublin, Ireland 2 Thapar
    Institute of Engineering & Technology, Patiala 147004, Punjab, India * Author
    to whom correspondence should be addressed. † These authors contributed equally
    to this work. Information 2024, 15(3), 126; https://doi.org/10.3390/info15030126
    Submission received: 5 January 2024 / Revised: 9 February 2024 / Accepted: 19
    February 2024 / Published: 23 February 2024 (This article belongs to the Special
    Issue Cyber Security in IoT) Download keyboard_arrow_down     Browse Figures Versions
    Notes Abstract Due to rising cyber threats, IoT devices’ security vulnerabilities
    are expanding. However, these devices cannot run complicated security algorithms
    locally due to hardware restrictions. Data must be transferred to cloud nodes
    for processing, giving attackers an entry point. This research investigates distributed
    computing on the edge, using AI-enabled IoT devices and container orchestration
    tools to process data in real time at the network edge. The purpose is to identify
    and mitigate DDoS assaults while minimizing CPU usage to improve security. It
    compares typical IoT devices with and without AI-enabled chips, container orchestration,
    and assesses their performance in running machine learning models with different
    cluster settings. The proposed architecture aims to empower IoT devices to process
    data locally, minimizing the reliance on cloud transmission and bolstering security
    in IoT environments. The results correlate with the update in the architecture.
    With the addition of AI-enabled IoT device and container orchestration, there
    is a difference of 60% between the new architecture and traditional architecture
    where only Raspberry Pi were being used. Keywords: IoT; cyber threats; distributed
    computing; AI-enabled chips; container orchestration; DDoS attacks 1. Introduction
    1.1. Background Since cyber security threats are rising, securing the Internet
    of Things (IoT) is crucial to daily life. Since IoT hardware cannot manage sophisticated
    workloads, they cannot run complex security risk detection algorithms on themselves,
    making them vulnerable to high-level security attacks. Instead, they must send
    data to cloud nodes to process inputs, leaving a loophole for attackers to steal
    data midway. However, if they could run those models, they could process their
    real-time packets or inputs. Security is still important when embedded technology
    advances and becomes robust enough to create apps on it to make life easier. Security
    adaptation cannot keep up with rapid technology change. Growing IoT devices have
    caused exponential growth. Imagine its economic impact on global markets. Distributed
    computing on the edge is desired to offload activities and improve resource planning
    and IoT device use due to cloud reliability, latency, and privacy problems [1].
    Most workloads are in the cloud, making data transit vulnerable to hackers. Fitness
    trackers broadcast important data like heart rate and blood pressure to the cloud,
    which might be compromised during transmission [2,3]. To circumvent these issues,
    it is necessary to compute close to IoT devices to scale edge computing and make
    them capable of processing large amounts of data. Container orchestration is essential
    for IoT application management and deployment. Developers may automate container
    deployment, scaling, and administration to optimize IoT device resources. The
    dynamic and resource-constrained nature of IoT settings requires load balancing,
    auto-scaling, and fault tolerance, which container orchestration provides. IoT
    service dependability and availability are improved, updates and maintenance are
    simplified, and developers can focus on developing creative, robust solutions
    that respond to changing conditions in real time [4]. The methodology involves
    setting up IoT devices with static IP addresses, building a machine learning model
    for DDoS detection, and setting up traditional devices (e.g., Raspberry Pi) in
    a distributed computing environment with an AI-embedded chip IoT device and a
    container orchestration tool. A Raspberry Pi-only distributed computing cluster
    with and without container orchestration tools would be compared to this cluster.
    All clusters will be evaluated by running ML models and comparing their performance
    and hardware metrics (CPU and Memory). This research aims to find whether scaling
    up traditional IoT devices with AI-enabled chips can help with running complex
    models and whether lightweight orchestration tools could help the resource utilisation
    on IoT devices and help them to run machine learning and apply them to cyber security
    improvement. Figure 1 shows the proposed state-of-the-art architecture in this
    research. It combines AI-enabled IoT devices with other IoT devices to form a
    cluster. This design would enable near-edge computation by sending IoT packets
    to the AI IoT device for processing to detect anomalies. The cloud would preserve
    these anomalies for future improvements. The figure’s network cloud is any usable
    network interface such as WiFi or swap networks. Due to the AI IoT device’s sole
    purpose of processing and communicating with the cloud, it remains a secure route
    to transmit information. With the help of container orchestration tools and AI
    IoT Devices in a networking architecture, the IoT devices will be able to run
    machine learning models efficiently on the edge to tackle attacks like DDoS by
    reducing CPU utilization. Figure 1. General Architecture. 1.2. Research Contribution
    This research aims to scale up the performance of IoT devices to support machine
    learning models and perform security risk detections on top of them with the help
    of AI-enabled IoT device and container orchestration like Microk8s. This research
    accomplished its goals by employing the following methods: Use of AI-enabled architecture
    in the cluster; Use of machine learning models for the detection of DDos and other
    attacks; Use of container orchestration tool like Microk8s; Use of different forms
    of architecture with AI-enabled IoT devices or simple IoT devices like Raspberry
    Pi; Use of Docker images for microservices; An overall decrease of 60% in CPU
    utilisation from the traditional architecture of Raspberry Pi to Microk8s architecture
    with Nvidia is achieved; Container orchestration-as-a-solution: it provides a
    way to efficiently manage the autoscaling of the resources if required and did
    a great job with job scheduling. 2. Related Work 2.1. Cyber Security as a Challenge
    to IoT Devices IoT devices are being used in many fields. This covers manufacturing,
    logistical, medical, military, etc. Research predicts 100 billion devices will
    be in use by 2025 [5]. Considering the predicted amount of devices [5], it is
    clear that attackers are targeting the IoT. The attackers would compromise selected
    nodes in the architecture to access the source code and infect the remainder of
    the deployments, including cloud resources. IoT deployments have violated local
    laws in earlier studies. Current IoT security methods often rely on manual intervention
    for maintenance and updates, leading to a lag in protection and an inability to
    learn and adapt to evolving threats. The unity and integrity of IoT, which spans
    terminals, networks, and service platforms, necessitate security solutions capable
    of effectively handling massive amounts of complex data [6]. Traditional data
    transfer to central servers is still popular. The data are usually sent over MQTT
    or HTTP. Previous research has shown transmission problems with MQTT and HTTP
    protocols [7,8]. Attackers find transfer scenarios to be the entryway to their
    target information. They would use man-in-the-middle attacks to infect routers
    that could sneak malicious packets to the main servers. The attackers also turned
    IoT devices in the large-scale infrastructure into botnets by planting malicious
    malware. After that, these devices send simultaneous requests to primary servers,
    causing a Distributed Denial of Service on cloud servers. If the main servers
    cannot receive data from legitimate IoT devices, incorrect or timed-out responses
    during data transmission cause data overload. In such a scenario, the data start
    collecting and rendering the legitimate devices to shut down operations [9]. 2.2.
    Solutions Implemented to Solve Security Vulnerabilities Malicious attacks have
    taken many forms. Attackers know that IoT security breaches take time to detect.
    Due to hardware issues, botnet and malware detection in the IoT environment might
    be difficult. However, edge computing with machine learning models on IoT devices
    has yielded novel solutions. Edge computing is a computing method in which the
    workload is divided amongst nodes to form a distributed architecture. It is an
    important area in research for IoT as this minimises the bandwidth and response
    time in an IoT environment. Moreover, it reduces the burden of a centralized server
    [10]. There have been detection methods which have been developed to be used in
    an edge computing scenario. Myneni et al. [11] suggest “SmartDefense”, a two-stage
    DDoS detection solution that utilizes deep learning algorithms and operates on
    the provider edge (PE) and consumer edge (CE). The PE and CE refer to the routers
    which are close to consumers and Internet service providers (ISPs). Edge computing
    helps SmartDefense detect and stop DDoS attacks near their source, reducing bandwidth
    waste and provider edge delay. The method also uses a botnet detection engine
    to detect and halt bot traffic. SmartDefense improves DDoS detection accuracy
    and reduces ISP overhead, according to the study. By detecting botnet devices
    and mitigating over 90% of DDoS traffic coming from the consumer edge, it can
    cut DDoS traffic by up to 51.95%. Bhardwaj et al. [12] suggest a method called
    ShadowNet that makes use of computational capabilities at the network’s edge to
    speed up a defence against IoT-DDoS attacks. The edge tier, which includes fog
    computing gateways and mobile edge computing (MEC) access points, can manage IoT
    devices’ massive Internet traffic using edge services. As IoT packets pass through
    gateways, edge functions build lightweight information profiles that are quickly
    acquired and sent to ShadowNet web services. IoT-DDoS attacks are initially prevented
    by ShadowNet’s analysis of edge node data. It detects IoT-DDoS attacks 10 times
    faster than victim-based methods. It can also react to an attack proactively,
    stopping up to 82% of the malicious traffic from getting to the target and harming
    the Internet infrastructure. Mirzai et al. [13] discovered the benefits of building
    a dynamic user-level scheduler to perform real-time updates of machine learning
    models and analysed the performance of the hardware of Nvidia Jetson Nano and
    Raspberry Pi. The scheduler allows local parallel model retraining on the IoT
    device without stopping the IDS, eliminating cloud resources. The Nvidia unit
    could retrain models while detecting anomalies, and the scheduler outperformed
    the baseline almost often, even with retraining! The Raspberry Pi unit underperformed
    due to its hardware’s architecture. The experiments showed that the dynamic user-level
    scheduler improves the system’s throughput, which reduces the attack detection
    time, and dynamically allocates resources based on attack suspicion. The results
    show that the suggested technique improves IDS performance for lightweight and
    data-driven ML algorithms for IoT. 2.3. Container Orchestration Applied to IoT
    Devices Google’s Borg was turned into Kubernetes using Go programming for Docker
    and Docker containers for orchestration. Kubernetes expanded on Google’s Borg,
    which inspired its development. Later, Kubernetes was viewed as a strong edge
    computing solution, which led to the creation of lightweight container orchestration
    solutions like k3s, Microk8s, and others because Kubernetes required intensive
    hardware specs that IoT platforms lack. Performance of lightweight container orchestration
    technologies has been studied. All research is from the last two to three years.
    The researchers [14] established a Kubernetes cluster using readily available
    Raspberry Pi devices. The cluster’s capacity to handle IoT components as gateways
    for sensors and actuators was tested utilizing synchronous and asynchronous connection
    situations. Linux containers like Docker can be used to quickly deploy microservices
    on near-end and far-end devices. Container technologies isolate processes and
    hardware within an operating system. Due to its fast deployment, communication
    management, high availability, and controlled updates, Kubernetes may be a solution
    for IoT. The paper draws attention to the paucity of research on deploying Kubernetes
    in the IoT setting and the need for additional research to analyze its applicability
    and limitations. Performance testing, evaluating response times, request rates,
    and cluster stability revealed the architecture’s pros and cons [15]. Lightweight
    solutions have been developed in recent years: Minikube, Microk8s, k3s, k0s, KubeEdge,
    and Microshift. In several tests, the authors tested tiny clusters of lightweight
    k8s distributions under high workloads. These insights can assist researchers
    in locating the lightweight k8s distribution for their use case. The researchers
    have basically found the resource consumption on idle for different k8s distributions,
    finding the resource consumption when the pods are being created, deleted, updated
    or being read and when the pods are assigned intensive workloads. Azure VMs, not
    IoT devices, powered the research. It would have been ideal to collaborate with
    IoT devices near to production. The researchers acknowledge the above shortcoming
    and suggest replacing artificial benchmark situations with production workloads
    and using black-box measures instead of white-box techniques. If the controller
    node has at least 1–2 GB of RAM and worker nodes have even less hardware, all
    lightweight k8s distributions perform well on low-end single-board computers,
    according to the study. 2.4. Mitigation to DDoS Attacks on IoT Devices While the
    detection work has been seen to be a work in progress, mitigation mechanisms after
    a DDoS attack happen are also being given due attention. Blockchain with the help
    of smart contracts is one interesting way of implementing this. Although, the
    solution at large is not localised to the IoT devices but seems to be making the
    solution work through the cloud. Hayat et al. [16] explore IoT DDoS defences,
    including smart contracts and blockchain-based methods. Multiple-level DDoS (ML-DDoS)
    is being developed to protect IoT devices and compute servers against DDoS attacks
    using blockchain. It prevents devices turning into bots and increases security
    with gas restriction blockchain, device blacklisting, and authentication. Blockchain
    technology is also called a public ledger with unchangeable records. It facilitates
    peer agreements in asset management, finance, and other fields via consensus methods.
    The decentralized and open-source Ethereum blockchain is promoted for protocol-based
    transactional protocols between parties. Comparison of ML-DDoS performance in
    the presence of bot-based scenarios shows that it outperforms other cutting-edge
    methods including PUF, IoT-DDoS, IoT-botnet, collaborative-DDoS, and deep learning-DDoS
    in terms of throughput, latency, and CPU use. 2.5. Research Gap Table 1 highlights
    the issues of cyber security in IoT. Hardware complexity, linear cloud complexity
    increase that does not match IoT’s exponential development, data manipulation
    by attackers, infrastructure botnets, and DDoS or Man in the Middle attacks on
    servers were mentioned. In the literature, deploying detection methods on routers
    for edge computing still leaves devices vulnerable because they are not secured.
    Additionally, infected devices are blocked from accessing the main servers. The
    detection model deployment should treat the device instead of rendering it useless.
    An IoT device with AI capabilities, including hardware configuration for machine
    learning algorithms, was proposed in [6]. In [13]. Nvidia Jetson Nano, an AI IoT
    Device, was shown to have significant potential above Raspberry Pi. Even IoT research
    has advanced with container orchestration which is shown in [14,15]. These studies
    suggest that edge computing, container orchestration, AI IoT devices, and IoT
    devices in general can be combined to achieve more. This study combines various
    concepts to work cohesively. Table 1. Literature review. 3. Methodology The CICDDoSDataset2019
    has been used for training the machine learning model. The dataset is shown in
    Table 2. This dataset has 2 Million entries and 80 columns after preprocessing.
    The preprocessing involved replacing spaces with no spaces in every column wherever
    applicable, dropping columns such as FlowID, SourceIP, DestinationIP, Timestamp,
    SimillarHTTP, SourcePort, and DestinationPort. Since the numeric data were in
    text format so those were converted into the numeric format. There are 2,180,000
    samples for DDoS packets and 1542 samples are benign samples. This indicates a
    heavy imbalance between the classes [19]. Table 2. DDoS dataset. 3.1. DDoS Detection
    Model Three Machine learning models were trained for the detection of DDoS. Dummy
    Classifier: A dummy classifier is a simple and baseline machine learning model
    used for comparison and benchmarking purposes. It is typically employed when dealing
    with imbalanced datasets or as a reference to assess the performance of more sophisticated
    models. The dummy classifier makes predictions based on predefined rules and does
    not learn from the data. The dummy classifier with the strategy of predicting
    the most frequent class is utilised for the baseline. The most frequent class
    classifier always predicts the class that appears most frequently in the training
    data. This is useful when dealing with imbalanced datasets where one class is
    significantly more prevalent than others [20]. Logistic Regression: Logistic regression
    is a popular and widely used classification algorithm in machine learning. Despite
    its name, it is used for binary classification tasks, where the output variable
    has two classes (e.g., “Yes” or “No”, “True” or “False”). The logistic regression
    model calculates the probability that an input data point belongs to a particular
    class. It does this by transforming its output through the logistic function (also
    known as the sigmoid function). The logistic function maps any real-valued number
    to a value between 0 and 1, which can be interpreted as a probability [21]. Deep
    Learning Model: The deep learning model has three layers to it. The first layer
    is the input layer. It has got the input shape of 80 neurons which outputs a shape
    of (None, 128). A dropout regularisation enables this layer to handle overfitting
    of the data. This is followed by another dense layer which also has a dropout
    regularisation. In the end, the model has an output layer with one neuron giving
    a probability as an output due to the sigmoid function being used in the last
    layer. Performance Metrics F1 score: It combines the precision and recall scores
    of a model. It is usually more useful than accuracy, especially if you have an
    uneven class distribution. The equation is provided in Equation (1). 𝐹1𝑆𝑐𝑜𝑟𝑒=2∗
    𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛∗𝑅𝑒𝑐𝑎𝑙𝑙 𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛+𝑅𝑒𝑐𝑎𝑙𝑙 (1) 𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛= 𝑇𝑟𝑢𝑒𝑃𝑜𝑠𝑖𝑡𝑖𝑣𝑒𝑠 𝑇𝑟𝑢𝑒𝑃𝑜𝑠𝑖𝑡𝑖𝑣𝑒𝑠+𝐹𝑎𝑙𝑠𝑒𝑃𝑜𝑠𝑖𝑡𝑖𝑣𝑒𝑠
    (2) 𝑅𝑒𝑐𝑎𝑙𝑙= 𝑇𝑟𝑢𝑒𝑃𝑜𝑠𝑖𝑡𝑖𝑣𝑒𝑠 𝑇𝑟𝑢𝑒𝑃𝑜𝑠𝑖𝑡𝑖𝑣𝑒𝑠+𝐹𝑎𝑙𝑠𝑒𝑁𝑒𝑔𝑎𝑡𝑖𝑣𝑒𝑠 (3) 3.2. Technology Used
    3.2.1. Python Python Programming Language has been used throughout the complete
    research. There are some important frameworks used as part of this research. Flask:
    This is a framework defined under the Python language for hosting REST APIs. The
    programmer can define the business logic which interacts with the front end. It
    provides an interface between the end user and databases. Tensorflow (TF): This
    is a package built by Google for deep learning-based workloads. This package comes
    along with Keras as shown in Figure 2. Keras is an Application Programming Interface
    which allows the programmer to build layers for Artificial Neural Networks [22].
    Figure 2. Model definition of Keras model. 3.2.2. Microk8s Microk8s has been developed
    by canonical and is being provided as a snap package as part of Ubuntu. It controls
    containerized services at the edge [23]. The previous researches have mentioned
    that the Microk8s requires atleast 4 GB of RAM usage. The Microk8s initially ships
    with the basics of k8s for example the controller, API server, dqlite storage,
    scheduler, and so on. Additionally, there are more add-ons that can be enabled
    by running “microk8s enable service name”. The name of the service can be Prometheus,
    DNS, metallb, helm, metrics-server, Kubernetes-dashboard, and so on [15]. 3.3.
    Components This study used four Raspberry Pis with 4 GB RAM each and one Nvidia
    Jetson Nano with 4 GB RAM as part of the device infrastructure. A total of 4 MicroSD
    cards with 16 GB capacity were used for Raspberry Pi and a 64 GB MicroSD card
    was used for Nvidia Jetson Nano. Ubuntu Server 18.04 was installed on the Raspberry
    and Nvidia jetpack on the Nvidia Jetson Nano. The devices were connected with
    LAN wires and a switch as a medium between them. A WiFi adapter was also used
    with Nvidia Jetson Nano because Jetson does not come with an onboard WiFi module.
    The switch model is Netgear JGS524E ProSafe Plus 24-Port Gigabit Ethernet Switch.
    3.3.1. Nvidia Jetson Nano A robust single-board computer made specifically for
    AI and robotics applications is the Nvidia Jetson Nano. The Nvidia Tegra X1 processor,
    which houses a quad-core ARM Cortex-A57 CPU and a 128-core Nvidia Maxwell GPU,
    powers the Jetson Nano [24]. This GPU is especially well suited for jobs requiring
    parallel processing, making it the best choice for effectively executing deep
    learning models and AI workloads. There are other variations of the Jetson Nano
    available, but the most typical model comes with 4 GB of LPDDR4 RAM, a microSD
    card slot for storage, Gigabit Ethernet, and USB 3.0 ports for fast data transfer.
    Its capabilities for robotics and computer vision are increased with the addition
    of GPIO ports, a MIPI CSI camera connection, and Display Serial Interface (DSI)
    for interacting with cameras and displays. The device is displayed in Figure 3.
    Figure 3. Nvidia Jetson Nano. 3.3.2. Raspberry Pi The fourth version of the successful
    and adaptable single-board computer created by the Raspberry Pi Foundation is
    known as the Raspberry Pi 4. It became available in June 2019. It has a quad-core
    ARM Cortex-A72 CPU that runs up to 1.5 GHz, giving it a substantial performance
    advantage over earlier iterations. The RAM is 4 GB for the device being used in
    this project. The device is displayed in Figure 4 [25]. Figure 4. Raspberry Pi.
    3.3.3. Netgear Switch Netgear JGS524E ProSafe Plus 24-Port Gigabit Ethernet Switch
    has got 24 ports on it. A gigabit connection delivers up to 2000 Mbps of dedicated,
    non-blocking bandwidth per port. It is a plug-and-play type of device. The device
    is shown in Figure 5. Figure 5. Netgear switch. 3.4. Networking Architectures
    The architecture figures that you would see below have a cloud named Network Cloud.
    The network cloud in general means any sort of networking interface can be used,
    which could be a switch, WiFi network, or maybe a private 5G network. For this
    study, a switch and WiFi have been used to network the device together. 3.4.1.
    Traditional Architecture and Nvidia Architecture Figure 6a shows an architecture
    which has been used widely. This kind of architecture is used in a fashion to
    interact with the real world and collects data from the sensors connected to the
    Raspberry Pi. The devices like Raspberry Pi transport the data to the cloud for
    processing and running detection models. When this architecture is used, the computational
    workloads become a problem. Figure 6. Traditional architecture and Nvidia architecture.
    As introduced previously, in the general architecture utilise the AI-enabled IoT
    Device and replace one of the nodes in the Raspberry Pi architecture with an AI-IoT
    device. In this situation, the architecture is introduced with an Nvidia Jetson
    Nano which is responsible for running various types of security breach detection
    models and transporting anomaly data to the cloud for further inspection. This
    way the amount of data stored in the cloud decreases by a major margin and goes
    light on storage as well. So, the only data which are stored are the anomalies
    which allow better analysis and deploy recovery automation solutions. The architecture
    is shown in Figure 6b. 3.4.2. Raspberry Pi Microk8s Archtitecture and Nvdida Raspberry
    Pi Microk8s Architecture The architecture introduces Microk8s as a resource management
    and container orchestration tool. This architecture with Microk8s has been previously
    seen in various research. Although, these researchers have not performed major
    load testing on the cluster for example running a machine learning model on the
    architecture. This study finds the CPU utilisation in the case of load testing
    related to running machine learning. The architecture is shown in Figure 7a. Figure
    7. Raspberry Pi Microk8s archtitecture and Nvdida Raspberry Pi Microk8s architecture.
    Nvdida Raspberry Pi Microk8s architecture is introduced as the state-of-the-art
    architecture which includes the capabilities provided by the GPU provided in the
    Nvidia Jetson Nano as well as resource management tools like Microk8s. Together,
    these both provide exceptional abilities of efficient scheduling of memory and
    keeping track of microservices on the network as well as running the detection
    models with comparatively less CPU utilisation as compared to other network elements.
    The architecture is shown in Figure 7b. 3.5. Validation of Hypothesis 3.5.1. Machine
    Learning Validation When it comes to Machine Learning model performance, it is
    expected that the model is able to predict classes distinctively without any major
    misclassification issue. In such scenarios, the F1 score associated with the classes
    should be substantial enough to make a feasible prediction to not fail when running
    on production systems. As we have seen earlier, the F1 score is the weighted harmonic
    mean of Precision and Recall, the changes in the F1 score indicate an overall
    improvement as compared to the previous model. The Dummy classifier indicates
    the baseline performance that needs to be outperformed by other models. This study
    explores the logistic regression model and the neural network for the detection
    models. These models would be expected to perform better than the baseline, and
    the state-of-the-art neural network to perform better than Logistic Regression.
    3.5.2. Architecture Improvement Validation For validation, it is expected that
    the traditional architecture will perform the poorest in terms of CPU utilisation
    and memory because of the hardware specifications of Raspberry Pi being used in
    the architecture. Therefore, the performance obtained in this architecture becomes
    the baseline which needs to be beaten by other architectures. Next, the Nvidia-enabled
    architecture is expected to utilise 20% less CPU as compared to traditional architecture.
    The Raspberry Pi architecture with Microk8s is expected to perform 10% less than
    the Nvidia enabled architecture because it is running an efficient container orchestration
    tool. In the end, the state-of-the-art architecture where the Nvidia device and
    Microk8s are together is expected to perform at least 60% less than the traditional
    architecture.This is demonstrated in Figure 8. Figure 8. Validation of architecture.
    4. Design and Implementation 4.1. Cluster Setup Two network structures were used
    for this research. Raspberry Pi Cluster and Nvidia-Raspberry Pi Cluster In the
    cluster shown in Figure 9a, four Raspberry Pis were used and one of them was made
    the master to handle operations in the Kubernetes environment. In a non-Kubernetes
    environment, the device was used to host the message queue Flask server and run
    the machine learning model. Figure 9. Raspberry Pi Cluster and Nvidia-Raspberry
    Pi Cluster. In the cluster shown in Figure 9b, three Raspberry Pis and one Nvidia
    Jetson Nano were used and one of the Raspberry Pis was made the master to handle
    operations in the Kubernetes environment. In a non-Kubernetes environment, the
    Nvidia device was used to host the message queue Flask server and run the machine
    learning model. 4.2. Docker Docker [26] is a containerisation service which is
    used to build microservices. For all the microservices, i.e., the Flask server
    for the message queue, the ML model, and the data sending micro-services were
    converted into respective Docker images. These microservices all have Docker files
    in their directory. These Docker files can build using “docker build -t < name
    of the build >”. Once the build is complete, the Docker image needs to be pushed
    to the Docker hub. An account on the Docker hub is required and three Docker hub
    repositories are required. For every repository, the Docker image built previously
    needs to be pushed. For doing so, first the image needs to be tagged against the
    path of the repository location on the Docker hub. For example, “docker tag <
    name of user >/< name of online repository >:< tag >< name of the build >”. Once
    this is completed, the ”docker push < name of user >/< name of online repository
    >:<tag>” command needs to be executed. An example of building and pushing a Docker
    image of a Machine learning microservice to the Docker hub is shown in Figure
    10. Before pushing the Docker image to the Docker hub, it is required to first
    authorize your push by login into your ID associated with the Docker repository.
    One last step before pushing the image is to associate the name of the Docker
    hub repository with the name of the local Docker build. This is achieved by the
    “docker tag” command. Figure 10. Docker tag and push. 4.3. Kubernetes Terminologies
    Kubernetes is an open-source container orchestration platform used for automating
    the deployment, scaling, and management of containerized applications. It was
    originally developed by Google and is now maintained by the Cloud Native Computing
    Foundation (CNCF). Kubernetes provides a powerful and flexible framework for managing
    containerized applications across a cluster of machines [27]. 4.3.1. Pods The
    smallest deployable compute units that Kubernetes allows you to construct and
    control are called pods. A collection of one or more containers, with common storage
    and network resources, and a specification for how to execute the containers,
    is referred to as a “pod” (as in a pod of whales or peas). The components of a
    pod are always co-located, co-scheduled, and executed in the same environment.
    A pod includes one or more closely connected application containers and serves
    as a representation of an application-specific “logical host”. Apps running on
    the same physical or virtual system are comparable to cloud apps running on the
    same logical host in non-cloud scenarios [28]. 4.3.2. Deployment A deployment
    is a crucial object in Kubernetes that controls the scaling and deployment of
    a collection of identical pods. One of the higher-level abstractions offered by
    Kubernetes to make managing containerized apps easier is this one. Using a deployment,
    you may provide the container image, the number of replicas (identical pods),
    and the update method to describe the intended state of your application [29].
    4.3.3. Namespaces A method for separating groupings of resources inside the same
    cluster is provided by namespaces. Within a namespace, but not between namespaces,
    resource names must be distinctive. Only namespace-based scoping is applicable
    to cluster-wide items, such as Storage Class, Nodes, and Persistent Volumes, not
    namespace-based objects (such as Deployments, Services, etc.) [30]. 4.4. Design
    Flow A visual representation of the workflow of the initial design is shown in
    Figure 11. The idea initially for the workflow about traditional implementation
    was to implement a complete DDoS happening environment where a real test on the
    devices could be done. The design goes as the record of performance metrics would
    be commenced to be written into a file followed by starting the Flask server on
    the master node. Once these steps are done, the worker nodes would be administered
    a SYN Flood attack from the Kali virtual machine running on the laptop. Simultaneously,
    a Docker container of cicflowmeter would be started. Figure 11. Initial design
    flow. CICFLowmeter 4.0 is a software which allows the network-related data stored
    in a PCAP format to be transformed into the CSV format of the network logs based
    on the physical interfaces of the device. This CSV data would be sent to the Message
    queue running on the Flask server. Once these messages are received, the machine
    learning script would be executed in a cronjob timed 1 min which would first check
    for availability of the logs, if there are any, it will start fetching until the
    message queue is empty. This keeps on looping until the Flask server is stopped
    or crashes due to some reason. Once the Flask server is stopped, the logs can
    be stopped from recording and stored. The design described above could not be
    followed because CICFlowmeter is an archive library which has outdated dependencies.
    Even though those dependencies were configured, the program was not able to function
    as needed. The other option available was to use a Docker container but that did
    not work as well since the container would get crashed due to Java dependencies
    issues. So, the only way to use CICFlowmeter was to directly generate a PCAP file
    on a Windows computer and then utilise the CSV file generated which was not feasible
    in this research’s use case because the cicflowmeter workflow needs to be automated.
    Message Queue Implementation The intuition behind having a message queue is to
    store the logs for the machine learning model to fetch from. For a message queue
    (MQ), a First In First Out (FIFO) implementation is required. A normal queue has
    a fixed size for the array. But for this use case of the message queue, the dynamic
    length of an array is required which can extend based on logs being inserted from
    worker nodes. Therefore, the Doubly Linked List becomes an eventually important
    choice as the list can be traversed bidirectionally and insertions and deletions
    can be performed from both the ends. Due to initial design issues, the CICFlowmeter
    was skipped. The dataset provided above sends data to the message queue. The message
    queue Flask server is executed after hardware performance metrics are recorded.
    After the Flask server gets requests, the script to send data is executed, and
    the message queue stores the data until the ML model script demands it. The ML
    model script checks if the message queue is active and then processes data from
    it. After using message queue data, the ML model scripts stop and run on a 1-min
    cronjob time. The above is presented in a visual form in the Figure 12. Figure
    12. Workflow without Kubernetes. For the Kubernetes cluster, different devices
    need to be first formed into a cluster. For that, one of the nodes is decided
    as a master node. The /etc/hosts file is updated with the hostname of the other
    devices and their respective static IP addresses. It is necessary that all the
    devices are connected to the internet and same access point. Once this is completed,
    the “microk8s add-node\" run on the master node, which provides a connection string
    which needs to be executed on the other devices so that they know which is the
    master node. After this, additional services need to be enabled on the cluster.
    The services are as follows: DNS (Domain Name Service): This is required for the
    pods to resolve the flask-app service internally when the machine learning/data-sending
    script is executed. Metallb (Metal Load Balancer): This load balancer is required
    to load balance if there are multiple pods for flask service running. Ingress.
    GPU: This only applies to Nvidia-based hardware and given that the device should
    have an Nvidia GPU. The Microk8s detect the GPU and execute the tasks which require
    GPU if the deployment is launched. Metrics-server: This is required for recording
    the performance metrics of the Kubernetes cluster. This service enquires about
    the utilisation of CPU and memory for every pod running in a particular namespace.
    After finishing the instructions, start the pods. Before Flask deployment, the
    performance metrics recording script is run. Flask-app service must be checked
    after starting the flask pod. To verify the status of the flask-app service, use
    “kubectl get services”. Data-send deployment can begin after the pod is up. When
    data-send pods are active, Flask receives data via internal domain name resolution.
    To verify requests, use “kubectl logs < name of flask pod >”. The name of the
    Flask pod may be obtained with “kubectl get pods | grep flask”. After seeing the
    requests, the deployment file’s cronjob option can perform and clock the machine
    learning model deployment every minute. Requests appear in Flask server logs after
    execution. This completes the flow shown in Figure 13. The monitor script can
    be stopped and the performance metrics can be noted. Figure 13. Kubernetes workflow
    diagram. 4.5. Implementation of Non-Microk8s Architecture 4.5.1. Performance Metrics
    Figure 14 shows the execution of the command to start recording the performance
    parameters of CPU and Memory. For this, ‘while true’ is used to execute a never-ending
    loop until the script is stopped. echo “%CPU %MEM ARGS $(date)” is printed at
    the top of every output which is printed into the file. Figure 14. Performance
    metrics collection. The provided Linux shell command is a pipeline that extracts
    and logs information about processes on the system with CPU usage. It begins by
    executing the ps command with the -e flag, which selects all processes running
    on the system. The -o pcpu,pmem,args flag customizes the output format, displaying
    CPU usage percentage, memory usage percentage, and the command with its arguments.
    The results are then sorted based on CPU usage using the –sort=pcpu flag. The
    cut command is used with the -d flag to extract the first five columns (CPU usage,
    memory usage, and command) from each line. The ‘tail’ command displays the last
    few lines of the sorted output, representing processes with the highest CPU usage.
    Finally, the » ps.log command appends the selected output to a file named “ps.log”,
    providing users with a log of processes’ CPU usage for analysis and future reference.
    And sleep 5 is used for recording entries every 5 s. This script can be stopped
    once the Flask server is killed or stopped. In the Flask framework, Figure 15
    displays the transfer of information to the REST API server. The “Success” print
    presents the successful request to the REST API server. Figure 15. Data sent execution
    in Flask framework. 4.5.2. Machine Learning Execution Figure 16 displays the execution
    of the Machine Learning model on the Raspberry Pi platform. At the end of the
    verbose, the prediction is displayed. The implementation of the Nvidia enabled
    architecture remains the same as mentioned for the Raspberry Pi. The machine learning
    model and the Flask script runs on the Nvidia device. In Figure 17, the Nvidia
    Tegra X1 is detected as a GPU because Tegra X1 contains the CPU and GPU inside
    it. The CPU’s clock speed is displayed as 0.91 GHz. The memory of the device is
    displayed as 3.86 GB. Figure 16. Machine learning script execution. Figure 17.
    Nvidia machine learning script execution. 4.5.3. Reading Performance File In Figure
    18, ‘cat’ is used for reading the file of performance metrics. The output of this
    command is piped together with a word selection command called “grep”. Grep is
    used to select those lines where the word occurs. For example, it shows the line
    where the word dl_new.py occurs. Figure 18. Viewing the performance metrics. 4.6.
    Implementation of Microk8s Architecture In Figure 19, the nodes running in a cluster
    are enlisted. The image displays all the Raspberry Pis online at the moment when
    the command “kubectl get no” is executed. Figure 20 presents the execution of
    the deployment file called “flask-app-dep.yml”. Figure 19. “kubectl get no” command.
    Figure 20. Flask app deployment. Performance Metrics For performance metrics to
    be recorded, the metrics-server add-on needs to be enabled on Microk8s. With this
    enabled, a shell script is used to get the output of the command “microk8s kubectl
    top pods” to receive the information of CPU and Memory utilisation into a file.
    This information gets recorded every 10 s while the script is running. Figure
    21 shows the output of the command. In the output, the pulling image signifies
    the cluster is telling the Docker hub to fetch the Docker image while the statement
    above it resembles the successful image pull and the master node assigning the
    job to a node automatically if not specified otherwise. Figure 21. Output of “kubectl
    describe po” command. Figure 22 displays the output of the command “kubectl get
    pods”. This command is followed by a “-o” flag with the keyword “wide” which displays
    additional information such as the node, IP address, Nominated Node and Readiness
    Gate. The image signifies the Flask pod in the creation stage and the pod is running
    on the raspberrypi1 node. Figure 22. “kubectl get pods” command. Figure 23 displays
    the IP addresses on which the Flask app can be accessed. Kubernetes allows domain
    name resolution which could be used by other pods to resolve “flask-app-service”
    into the corresponding internal cluster IP addresses. Figure 23. “kubectl get
    services” command. Therefore, no hard coding is required for the IP addresses
    in the scripts of the data-sending and machine-learning model. The external IP
    address is the IP address which is not the IP address of any node inside the cluster
    but a different address altogether which allows the \"flask-service\" to be accessed
    from the external world. Since this address does not correspond to any node, it
    provides extensive security to the nodes as they are hidden from the external
    world and thus remain protected from attacks. Also, the external IP address is
    provided by a load balancer called “metallb”. This load balances the requests
    across the pods running the Flask app deployment. Figure 24 displays the container
    logs of the pod running the Flask API microservice. It shows the Flask server
    is up and running. The 127.0.0.1:5001 is the local host API deployment which can
    be accessed from the pod itself while the 10.1.245.3:5001 is the IP address for
    the internal resolution to the other pods for accessing the service if required.
    Figure 25 shows the execution of the “csv-data-dep.yml”. This YML file holds the
    name of the Docker image which needs to be sourced from the Docker hub. This deployment
    is responsible for sending the information to the Flask deployment. Figure 24.
    Flask logs after pod deployment. Figure 25. CSV data send deployment. Figure 26
    shows the logs of the Flask pod after the csv data-sending pods use the Flask
    server’s endpoint to send the data. Once the request is served by the Flask, it
    logs into the output shown. Figure 27 shows the execution of the “ml-model-dep.yml”.
    This YML file holds the name of the Docker image which needs to be sourced from
    the Docker hub. This deployment is responsible for retrieving the data from the
    Flask server for running the machine learning model. Figure 26. Insertion of logs
    after CSV pod deployment. Figure 27. Machine learning pod deployment. Figure 28a
    shows the fetch_data API endpoint used in the logs of Flask pod. It signifies
    that the Machine learning pod made requests to fetch the data. The implementation
    of the Nvidia Microk8s remains the same as mentioned above in the Raspberry Pi
    implementation of Microk8s but the only thing that changes is the static allocation
    of the machine learning pod on the Nvidia device. Therefore, this pod cannot be
    scheduled on any other node other than Nvidia. So, any number of pods which are
    scheduled will be handled by the Nvidia device. Figure 28b shows the Nvidia as
    a node in the Kubernetes cluster. Figure 28. Pod deployment. Figure 29 shows the
    different pods running different micro-service but if observed for the machine
    learning pod, the pod is scheduled to run the Nvidia device, thereby utilizing
    the power of the GPU. The Nvidia deployment is different from the one used for
    Raspberry Pi. It includes the node Selector in the deployment script which points
    to the Nvidia hostname. So, the master node will look for the node with the hostname
    “nvidia” and launch the pod over that node. Figure 29. kubectl get pods (Nvidia
    machine learning). 4.7. Challenges Microk8sSnap package manager has many Microk8s
    variants. This requires choosing the proper version for the use case. Initial
    use of the current version caused issues with the Kubelet API server and connecting
    devices through Microk8s. These flaws were also in the lower version. The author
    consulted the Microk8s community to locate a version that supported Prometheus,
    Grafana, and GPU add-ons. Despite version difficulties, all versions allowed the
    addition of devices and capabilities of Kubernetes provided through the Microk8s.
    The version suggested by them was 1.22. Nvidia Jetson Nano Setup Finding the appropriate
    operating system was initially difficult due to the variety of versions and their
    features, some of which were outdated and unsupported by hardware. Operating system
    images were available for prior Nvidia chipsets. Nvidia forums and community helped
    choose the correct image. Nvidia crashed when a 16 GB Micro SD card was used because
    the image size was 14 GB after installation. Nvidia could no longer use the SD
    card for utility software. This was carried out later with a 64 GB card. TFLite
    Model on Nvidia Jetson The TFLite model dependencies could not run on Nvidia Jetson
    due to the Tensorflow version being very different from other IoT device versions.
    This is because of the hardware architecture of Nvidia. Therefore, the H5 model
    is used because it is able to run on both platforms and allows a fair comparison
    between the traditional Raspberry Pi and Nvidia-enabled architecture. Prometheus
    and Grafana These services are offered as add-ons to the Microk8s (version 1.22+).
    They are responsible for capturing resource utilisation of every pod in each namespace
    or node in the cluster. Prometheus and Grafana were initially tested on the cluster.
    Still, the resource utilisation by the Prometheus namespace was high which was
    crashing the Microk8s service on the nodes when the other deployments were being
    initiated. Therefore, it is suggested to have at least 8 GB of RAM on the node’s
    hardware. 5. Evaluation 5.1. Machine Learning The classes which are classified
    as 0 are the DDoS Packets while 1 indicates the normal packets. 5.1.1. Dummy Classifier
    Performance In Figure 30a, The F1 score for class 0 (DDoS) is predicted as 1.00
    because it has samples with the highest frequency. This is supported by the reason
    that the strategy for the dummy classifier was set as the most frequent. The F1
    score of class 1 is 0 because it has fewer samples as compared to class 0. Figure
    30. Dummy Classifier and Logistic Regression Performance. 5.1.2. Logistic Regression
    Performance In Figure 30b, The F1 score for the benign class improves more than
    when it was previously 0 in the baseline model. There is an improvement over there.
    5.1.3. Neural Network Performance In Neural Network, a regularized architecture
    has been defined as shown in Figure 31. There is a 3% improvement as compared
    to the F1 score of class 1 in Logistic Regression Performance. Figure 31. Neural
    Network Performance. Given all of this above architecture, the prediction for
    class 0 is an absolute 100 because of the biased samples in the dataset. Even
    if the undersampling is carried out, the relative samples for class 1 would still
    be undermined. Therefore, an improvement in such scenarios is difficult in this
    kind of unbalanced situation. Although, the model can be improved when the real
    data come into the IoT devices by retraining the network in real-time. Apart from
    the DDoS attacks, the proposed architecture can also run detections for example,
    the Man in the Middle attacks and anomaly detection. Abdelkader et al. [31] have
    conducted MITM detection on the IoT devices. Using the same methodology, the models
    can be launched in the proposed architecture as well. Ibrahim et al. [32] show
    that the Anomaly detection can be done on the network traffic and associated fog
    layers. Therefore, these examples explain that the machine learning models are
    classification problems mostly and the DDoS model used in the current study is
    similar to that. Therefore, the resilience noticed with the current results should
    be similar whenever other cyber threat detection runs on the proposed architecture.
    5.2. Architecture In Table 3, the CPU and memory utilisation is displayed for
    all the architectures obtained from the experiments. The data in the table are
    sourced from the experiments conducted and the evidence has been provided below
    in the figures. Looking at the table, it is observable that the Non-Microk8s architecture
    has the highest CPU utilisation compared to the others. The CPU utilisation drops
    down to 73% when the Nvidia-enabled architecture is brought in. There is definitely
    an improvement over there which showcases one of the reasons where the GPU assists
    the CPU in running the machine learning models in an efficient manner. Having
    looked at the memory utilisation, it is increasing because Nvidia uses a Graphic-based
    User Interface of Ubuntu which also runs other System operations as well whereas
    the memory utilisation is less because of the server image of Ubuntu being used.
    Table 3. CPU and memory usage comparison. Discussing the Microk8s architectures,
    the Raspberry Pi architecture performs better in terms of both CPU and Memory
    utilisation as compared to non-microk8s architecture and, interestingly, 10% less
    than the Nvidia Non-Microk8s architecture. Microk8s does a good job of managing
    the resources. While looking at the state-of-the-art architecture where the Nvidia
    and Microk8s have been used, a CPU utilisation of 31.5% is noticed which is 60%
    of the traditional architecture. Figure 32a, displays the CPU utilisation in the
    leftmost column while the column beside it displays the memory utilisation of
    the Raspberry Pi traditional architecture. The ‘dl_new.py’ is the file which holds
    the logic to fetch the data from the message queue and run the machine learning
    model once the data are available in the memory. The image, therefore, shows the
    continuous CPU consumed with time and a constant rate of increase. Figure 32.
    Raspberry Pi Traditional & Nvidia Enabled Architecture Performance. Figure 32b
    presents the CPU utilisation in the leftmost column while the column beside it
    displays the memory utilisation of the Nvidia-enabled architecture. The Nvidia-enabled
    architecture starts with a similar amount of CPU utilisation when the script initiates
    but over time the difference between traditional and this architecture grows larger.
    In the end, the final CPU utilisation is observed to be 73.4%. Figure 33 and Figure
    34 presents the name of the pods, the CPU utilisation and memory utilisation for
    the Raspberry Pi Microk8s architecture & Nvidia-Raspberry Pi Microk8s Architecture
    respectively. In the red box, the machine learning pod can be seen with the CPU
    utilisation and Memory utilisation beside it. The CPU utilisation is 64% & 31.5%
    respectively. Figure 33. Raspberry Pi Microk8s performance. Figure 34. Nvidia
    Raspberry Pi Microk8s performance. 5.2.1. Energy Consumption Going by the energy
    formula, 𝐸𝑛𝑒𝑟𝑔𝑦(𝑊ℎ)=𝑃𝑜𝑤𝑒𝑟(𝑊) * 𝑇𝑖𝑚𝑒(ℎ) , the energy consumed by the Nvidia Jetson
    Nano can be calculated. For three raspberry Pis sending the logs to the machine
    learning model running on Nvidia Jetson Nano, having the Jetson nano configured
    to use the maximum available power and also considering the Kubernetes running
    on the Jetson, the maximum power taken by the Jetson at any particular time is
    10 W. We only considered the window when the machine learning model is executing.
    The time taken was approximately 1 min for all the device’s logs to be transferred
    and processed. In that particular case, the energy consumed is 0.016 h * 10 W
    = 0.16 Wh. Therefore, on increasing the devices in the edge network, the number
    of logs transferred to the Nvidia Jetson Nano also increases. As said before,
    the maximum power is 10 W for operating the nvidia Jetson nano. The energy consumed
    would be proportional to the total time taken by the machine learning model to
    be executed. The total power consumed by any one of the Raspberry Pis in the network
    depends on the role of the Pi device along with transferring the logs. The power
    consumption can vary in a real world scenario. In our particular case, it was
    designed to transfer network logs to the Nvidia Jetson Nano which involved running
    a python script and Kubernetes running on the device. The execution time of the
    python script was 15 s (0.25 min). The power consumed at any particular instant
    was reported to be 6 W. Therefore, the energy consumed by the device during this
    particular operation was 6 * (0.25/60) = 0.025 Wh and for 3 devices, it is 0.075
    Wh. Thus, the total the energy consumed during the machine learning model execution
    was approximately 0.235 Wh. 5.2.2. Scalability and Latency The scalability is
    measured based on the number of IoT devices (non-AI) which can be added to the
    network without having the Nvidia Jetson Nano (AI IoT Device) being overwhelmed
    in terms of CPU utilization. In the current architecture where there were 3 raspberry
    pi devices, 31.5% of utilization is reported. When we increase the number of devices,
    the operation of the Nvidia Jetson Nano is not affected much. It can run multiple
    neural networks together and is able to handle concurrent requests from different
    nodes. The CPU utilization increases to 40% when the number of devices are more
    than 10. Whereas latency is between 10ms to 15ms on varying loads and with an
    increasing number of devices. Latency involved in this particular experiment would
    be ideal to be observed for the logs being transferred between the raspberry Pi
    and the Nvidia Jetson Nano. Theoretically speaking, the latency is said to be
    the time difference of when the data packet leaves the source device and at the
    time when the data packet was received at the destination device. In this experiment,
    the devices were connected through LAN cables over a Gigabit switch. Given this
    kind of network setup between the devices, the latency between the devices would
    be low as compared to a wide area network setup. For example, the latency in transporting
    the logs between the Raspberry Pi and cloud would definitely be higher than the
    setup in this experiment. While looking at the metrics of the experiment, the
    latency at any particular time when the packets were transferred were close to
    10 ms. This is in the case of three devices transferring the logs to the flask
    server. This would be more or less the same on increasing the devices since the
    physical memory is utilized on the Nvidia Jetson Nano to store the incoming logs
    into a message queue. A comparative analysis of latency with the existing state-of-the-art
    is given in Table 4. Table 4. Comparative analysis of latency. 5.2.3. Efficiency,
    Security and Cost Effectiveness A comparative analysis of efficiency, security
    and cost effectiveness of the proposed model with the existing state-of-the-art
    is given in Table 5. Table 5. Efficiency, security, and cost effectiveness. 5.3.
    Real-World Applications There are potential applications of such research in the
    industry as well. For example, when smart cities are considered, there are traffic
    lights being used at every traffic junction and their functioning is being scaled
    up using CCTV cameras and computer vision. To keep their functionality working
    properly without any security breaches to avoid traffic jams, the general architecture
    shown before is where computer vision can run directly at the junction without
    transferring the data to the nearby data centre. Meghana et al. [39] developed
    a method in which aRaspberry Pi along with a Pi Camera is used to capture events
    at a traffic junction and image processing of the data happens on the device.
    This research showcases that these kind of jobs are viable but the problem comes
    down to the overwhelming of the Pi devices. With the proposed architecture in
    this research, it would be a game changer since the job of image processing would
    be done by AI IoT devices which are capable of running multiple neural network
    operations at once. All the image streams from these Raspberry Pis can be provided
    to AI IoT devices and hence more operations can be done at once. The practical
    challenges associated with using the architecture is that the devices would be
    used outside on the junction which comes along with weather challenges and devices
    are supposed to operate within a desired temperature range. Especially using Nvidia
    devices, they are fragile to varying temperatures and would affect its performance.
    Regular maintenance is a minor one but it has to be carried out regularly given
    the device’s physical condition. Another example is the application in the field
    of medical industry, where hospitals in Ireland for instance are providing wearable
    devices to patients to record their health metrics while they are being transferred
    to another location in the hospital or a situation where they cannot be monitored
    with specialized equipment. The protection of data that the wearable stores should
    be prioritized. In such cases, a local deployment of a general architecture could
    be useful. There can be much more instances where the use of such an architecture
    will be of great utility. In this particular research [40], the idea seems similar
    to what is being discussed here. The paper presents the idea of the wearable IoT
    devices in the sphere of hospitals and how their communications are modelled to
    transmit data to the cloud. This paper does not discuss any cyber challenges associated
    with this transmission but what seems obvious is that there are multiple layers
    of communications involved until it reaches the central servers. The proposed
    architecture overcomes the challenge of going through multiple layers of communication
    until it reaches the cloud servers. All the processing is offloaded on the AI
    IoT device while storage of data can be carried out locally at the hospitals.
    Practical Challenges associated with this model would be implementing redundancy
    and failover mechanisms that become essential to prevent data loss or system downtime.
    In case, let us say, the hospital decides to keep data in the cloud, outages may
    disrupt the communication between wearable devices and central systems. The major
    challenge of all would be to ensure that systems remain robust even when hospital
    is dealing with large volume of patients. 6. Conclusions This research investigates
    distributed computing on the edge, using AI-enabled IoT devices and container
    orchestration tools to handle data in real time. Security is improved by identifying
    and mitigating threats like DDoS attacks while minimizing CPU usage. It compares
    typical IoT devices with and without AI-enabled chips, container orchestration,
    and machine learning model performance in different cluster settings. By enabling
    IoT devices to process data locally, the suggested design seeks to reduce reliance
    on cloud transmission and improve IoT environment security. Results align with
    architecture update. The following statements are concluded after looking at the
    results: Comparison Of Raspberry Pi to Microk8s Raspberry Pi: Reduction of almost
    30% (CPU) and 99% (Memory). Comparison Of Nvidia—Raspberry Pi to Microk8s Nvidia—Raspberry
    Pi: Reduction of almost 42% (CPU) and 98% (Memory). Comparison of Raspberry Pi
    and Nvidia-Raspberry Pi: Reduction of almost 21% (CPU) and Increase of 62.5% (Memory).
    Comparison of Microk8s Architecture—Raspberry Pi vs. Nvidia-Raspberry Pi: Reduction
    of almost 32.5% (CPU) & Increase of 95% (Memory). An overall decrease of 60% in
    CPU utilisation from the traditional architecture of Rasp berry Pi to Microk8s
    architecture with Nvidia. Container Orchestration-as-a-solution: It managed resources
    efficiently, auto-scaled when needed, and scheduled jobs well. Since the solutions
    are not directly distributed to the host, malware implantation can be stopped
    by restarting another pod for that deployment, making it security-reliable. Future
    Work Use of Google Coral Device: The Google gadget has a Tensor Processing Unit.
    Eventually, this gadget and Raspberry Pi can be compared to Nvidia Jetson Nano
    for performance analysis. This can be clustered or standalone. Realtime updating
    of Machine Learning Model: When data become available on the platform, cloud updating
    of the machine learning model affects the model’s real-time performance reliability.
    If this could be conducted on the edge with CPU optimization in mind, imagine
    what IoT devices could achieve with merely data coming in and the model being
    updated in real time without sending it to the cloud. Adversarial AI for Malware
    Detection: Attackers must escape IoT devices after planting botnets to avoid leaving
    cyber fingerprints. Adversarial AI that predicts evasion and avoids malware plants.
    This would preserve the attackers’ fingerprints and make tracking malware to its
    source easier. Generative Adversarial Network implementation in malware detection
    is also receiving interest. Looking at the above results and future work, there
    is tremendous potential which can be unlocked with the introduction of Kubernetes
    and AI-enabled IoT devices to the existing network of IoT devices. This will yield
    better product line-ups for industries in this business. With the scale at which
    IoT devices grow, these solutions will be able to keep security growing as well.
    Author Contributions Conceptualization, S.K. and H.T.; methodology, S.K.; software,
    V.T.; validation, S.K., H.T. and V.T.; formal analysis, S.K.; investigation, H.T.;
    resources, S.K.; data curation, V.T.; writing—original draft preparation, S.K.;
    writing—review and editing, S.K and H.T.; visualization, V.T.; supervision, H.T.;
    project administration, H.T.; funding acquisition, H.T. All authors have read
    and agreed to the published version of the manuscript. Funding This research was
    conducted with the financial support of Ripple.com under their University Blockchain
    Research Initiative (UBRI) and the Science Foundation Ireland at ADAPT, the SFI
    Research Centre for AI-Driven Digital Content Technology at Trinity College Dublin
    [13/RC/2106_P2]. Institutional Review Board Statement Not applicable. Informed
    Consent Statement Not applicable. Data Availability Statement Data are contained
    within the article. Conflicts of Interest The authors declare no conflicts of
    interest. References Merenda, M.; Porcaro, C.; Iero, D. Edge machine learning
    for ai-enabled iot devices: A review. Sensors 2020, 20, 2533. [Google Scholar]
    [CrossRef] [PubMed] Ghosh, A.; Chakraborty, D.; Law, A. Artificial intelligence
    in Internet of things. CAAI Trans. Intell. Technol. 2018, 3, 208–218. [Google
    Scholar] [CrossRef] Covi, E.; Donati, E.; Liang, X.; Kappel, D.; Heidari, H.;
    Payvand, M.; Wang, W. Adaptive extreme edge computing for wearable devices. Front.
    Neurosci. 2021, 15, 611300. [Google Scholar] [CrossRef] [PubMed] Fayos-Jordan,
    R.; Felici-Castell, S.; Segura-Garcia, J.; Lopez-Ballester, J.; Cobos, M. Performance
    comparison of container orchestration platforms with low cost devices in the fog,
    assisting Internet of Things applications. J. Netw. Comput. Appl. 2020, 169, 102788.
    [Google Scholar] [CrossRef] Taylor, R.; Baron, D.; Schmidt, D. The world in 2025-predictions
    for the next ten years. In Proceedings of the 2015 10th International Microsystems,
    Packaging, Assembly and Circuits Technology Conference (IMPACT), Taipei, Taiwan,
    21–23 October 2015; IEEE: Piscataway, NJ, USA, 2015; pp. 192–195. [Google Scholar]
    Wu, H.; Han, H.; Wang, X.; Sun, S. Research on artificial intelligence enhancing
    internet of things security: A survey. IEEE Access 2020, 8, 153826–153848. [Google
    Scholar] [CrossRef] Shakdher, A.; Agrawal, S.; Yang, B. Security vulnerabilities
    in consumer iot applications. In Proceedings of the 2019 IEEE 5th Intl Conference
    on Big Data Security on Cloud (BigDataSecurity), IEEE Intl Conference on High
    Performance and Smart Computing, (HPSC) and IEEE Intl Conference on Intelligent
    Data and Security (IDS), Washington, DC, USA, 27–29 May 2019; IEEE: Piscataway,
    NJ, USA, 2019; pp. 1–6. [Google Scholar] Dinculeană, D.; Cheng, X. Vulnerabilities
    and limitations of MQTT protocol used between IoT devices. Appl. Sci. 2019, 9,
    848. [Google Scholar] [CrossRef] Pokhrel, S.; Abbas, R.; Aryal, B. IoT security:
    Botnet detection in IoT using machine learning. arXiv 2021, arXiv:2104.02231.
    [Google Scholar] Alrowaily, M.; Lu, Z. Secure edge computing in IoT systems: Review
    and case studies. In Proceedings of the 2018 IEEE/ACM Symposium on Edge Computing
    (SEC), Seattle, WA, USA, 25–27 October 2018; IEEE: Piscataway, NJ, USA, 2018;
    pp. 440–444. [Google Scholar] SmartDefense: A distributed deep defense against
    DDoS attacks with edge computing. Comput. Netw. 2022, 209, 108874. [CrossRef]
    Bhardwaj, K.; Miranda, J.C.; Gavrilovska, A. Towards {IoT-DDoS} Prevention Using
    Edge Computing. In Proceedings of the USENIX Workshop on Hot Topics in Edge Computing
    (HotEdge 18), Boston, MA, USA, 11–13 July 2018. [Google Scholar] Mirzai, A.; Coban,
    A.Z.; Almgren, M.; Aoudi, W.; Bertilsson, T. Scheduling to the Rescue; Improving
    ML-Based Intrusion Detection for IoT. In Proceedings of the 16th European Workshop
    on System Security, Rome, Italy, 8 May 2023; pp. 44–50. [Google Scholar] Beltrão,
    A.C.; de França, B.B.N.; Travassos, G.H. Performance Evaluation of Kubernetes
    as Deployment Platform for IoT Devices. In Proceedings of the Ibero-American Conference
    on Software Engineering, Curitiba, Brazil, 4–8 May 2020. [Google Scholar] Koziolek,
    H.; Eskandani, N. Lightweight Kubernetes Distributions: A Performance Comparison
    of MicroK8s, k3s, k0s, and Microshift. In Proceedings of the 2023 ACM/SPEC International
    Conference on Performance Engineering, Coimbra, Portugal, 15–19 April 2023; pp.
    17–29. [Google Scholar] Hayat, R.F.; Aurangzeb, S.; Aleem, M.; Srivastava, G.;
    Lin, J.C.W. ML-DDoS: A blockchain-based multilevel DDoS mitigation mechanism for
    IoT environments. IEEE Trans. Eng. Manag. 2022, 1–14. [Google Scholar] [CrossRef]
    Todorov, M.H. Deploying Different Lightweight Kubernetes on Raspberry Pi Cluster.
    In Proceedings of the 2022 30th National Conference with International Participation
    (TELECOM), Sofia, Bulgaria, 27–28 October 2022; IEEE: Piscataway, NJ, USA, 2022;
    pp. 1–4. [Google Scholar] Ferdowsi, A.; Saad, W. Generative adversarial networks
    for distributed intrusion detection in the internet of things. In Proceedings
    of the 2019 IEEE Global Communications Conference (GLOBECOM), Waikoloa, HI, USA,
    9–13 December 2019; IEEE: Piscataway, NJ, USA, 2019; pp. 1–6. [Google Scholar]
    Elsayed, M.S.; Le-Khac, N.A.; Dev, S.; Jurcut, A.D. Ddosnet: A deep-learning model
    for detecting network attacks. In Proceedings of the 2020 IEEE 21st International
    Symposium on “A World of Wireless, Mobile and Multimedia Networks” (WoWMoM), Cork,
    Ireland, 31 August–3 September 2020; IEEE: Piscataway, NJ, USA, 2020; pp. 391–396.
    [Google Scholar] Kannavara, R.; Gressel, G.; Fagbemi, D.; Chow, R. A Machine Learning
    Approach to SDL. In Proceedings of the 2017 IEEE Cybersecurity Development (SecDev),
    Cambridge, MA, USA, 24–26 September 2017; IEEE: Piscataway, NJ, USA, 2017; pp.
    10–15. [Google Scholar] Bapat, R.; Mandya, A.; Liu, X.; Abraham, B.; Brown, D.E.;
    Kang, H.; Veeraraghavan, M. Identifying malicious botnet traffic using logistic
    regression. In Proceedings of the 2018 Systems and Information Engineering Design
    Symposium (SIEDS), Charlottesville, VA, USA, 27 April 2018; IEEE: Piscataway,
    NJ, USA, 2018; pp. 266–271. [Google Scholar] Ma, L.; Chai, Y.; Cui, L.; Ma, D.;
    Fu, Y.; Xiao, A. A deep learning-based DDoS detection framework for Internet of
    Things. In Proceedings of the ICC 2020—2020 IEEE International Conference on Communications
    (ICC), Dublin, Ireland, 7–11 June 2020; IEEE: Piscataway, NJ, USA, 2020; pp. 1–6.
    [Google Scholar] Debauche, O.; Mahmoudi, S.; Guttadauria, A. A new edge computing
    architecture for IoT and multimedia data management. Information 2022, 13, 89.
    [Google Scholar] [CrossRef] Süzen, A.A.; Duman, B.; Şen, B. Benchmark analysis
    of jetson tx2, jetson nano and raspberry pi using deep-cnn. In Proceedings of
    the 2020 International Congress on Human-Computer Interaction, Optimization and
    Robotic Applications (HORA), Ankara, Turkey, 26–28 June 2020; IEEE: Piscataway,
    NJ, USA, 2020; pp. 1–5. [Google Scholar] Gizinski, T.; Cao, X. Design, Implementation
    and Performance of an Edge Computing Prototype Using Raspberry Pis. In Proceedings
    of the 2022 IEEE 12th Annual Computing and Communication Workshop and Conference
    (CCWC), Las Vegas, NV, USA, 26–29 January 2022; IEEE: Piscataway, NJ, USA, 2022;
    pp. 0592–0601. [Google Scholar] Docker Docs. Docker Overview. 2023. Available
    online: https://docs.docker.com/get-started/overview/ (accessed on 25 July 2023).
    Redhat. “What is kuberentes?”. 2023. Available online: https://www.redhat.com/en/topics/containers/what-is-kubernetes
    (accessed on 25 July 2023). Kubernetes. “Pods”. 2023. Available online: https://kubernetes.io/docs/concepts/workloads/pods/
    (accessed on 25 July 2023). Kubernetes. “Deployment”. 2023. Available online:
    https://kubernetes.io/docs/concepts/workloads/controllers/deployment/ (accessed
    on 25 July 2023). Kubernetes. “Namespaces”. 2023. Available online: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/
    (accessed on 25 July 2023). Lahmadi, A.; Duque, A.; Heraief, N.; Francq, J. MitM
    attack detection in BLE networks using reconstruction and classification machine
    learning techniques. In Proceedings of the Joint European Conference on Machine
    Learning and Knowledge Discovery in Databases, Bilbao, Spain, 14–18 September
    2020; Springer: Cham, Switzerland, 2020; pp. 149–164. [Google Scholar] Alrashdi,
    I.; Alqazzaz, A.; Aloufi, E.; Alharthi, R.; Zohdy, M.; Ming, H. Ad-iot: Anomaly
    detection of iot cyberattacks in smart city using machine learning. In Proceedings
    of the 2019 IEEE 9th Annual Computing and Communication Workshop and Conference
    (CCWC), Las Vegas, NV, USA, 7–9 January 2019; IEEE: Piscataway, NJ, USA, 2019;
    pp. 0305–0310. [Google Scholar] Atutxa, A.; Franco, D.; Sasiain, J.; Astorga,
    J.; Jacob, E. Achieving low latency communications in smart industrial networks
    with programmable data planes. Sensors 2021, 21, 5199. [Google Scholar] [CrossRef]
    [PubMed] Ferrari, P.; Sisinni, E.; Brandão, D.; Rocha, M. Evaluation of communication
    latency in industrial IoT applications. In Proceedings of the 2017 IEEE International
    Workshop on Measurement and Networking (M&N), Naples, Italy, 27–29 September 2017;
    IEEE: Piscataway, NJ, USA, 2017; pp. 1–6. [Google Scholar] Cui, L.; Xu, C.; Yang,
    S.; Huang, J.Z.; Li, J.; Wang, X.; Ming, Z.; Lu, N. Joint optimization of energy
    consumption and latency in mobile edge computing for Internet of Things. IEEE
    Internet Things J. 2018, 6, 4791–4803. [Google Scholar] [CrossRef] Azari, A.;
    Stefanović, Č.; Popovski, P.; Cavdar, C. On the latency-energy performance of
    NB-IoT systems in providing wide-area IoT connectivity. IEEE Trans. Green Commun.
    Netw. 2019, 4, 57–68. [Google Scholar] [CrossRef] Javed, A.; Malhi, A.; Kinnunen,
    T.; Främling, K. Scalable IoT platform for heterogeneous devices in smart environments.
    IEEE Access 2020, 8, 211973–211985. [Google Scholar] [CrossRef] Badiger, S.; Baheti,
    S.; Simmhan, Y. Violet: A large-scale virtual environment for internet of things.
    In Proceedings of the Euro-Par 2018: Parallel Processing: 24th International Conference
    on Parallel and Distributed Computing, Turin, Italy, 27–31 August 2018; Proceedings
    24. Springer: Cham, Switzerland, 2018; pp. 309–324. [Google Scholar] Meghana,
    V.; Anisha, B.; Kumar, P.R. IOT based Smart Traffic Signal Violation Monitoring
    System using Edge Computing. In Proceedings of the 2021 2nd Global Conference
    for Advancement in Technology (GCAT), Bangalore, India, 1–3 October 2021; IEEE:
    Piscataway, NJ, USA, 2021; pp. 1–5. [Google Scholar] Surantha, N.; Atmaja, P.;
    Wicaksono, M. A review of wearable internet-of-things device for healthcare. Procedia
    Comput. Sci. 2021, 179, 936–943. [Google Scholar] [CrossRef]     Disclaimer/Publisher’s
    Note: The statements, opinions and data contained in all publications are solely
    those of the individual author(s) and contributor(s) and not of MDPI and/or the
    editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to
    people or property resulting from any ideas, methods, instructions or products
    referred to in the content.  © 2024 by the authors. Licensee MDPI, Basel, Switzerland.
    This article is an open access article distributed under the terms and conditions
    of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/).
    Share and Cite MDPI and ACS Style Kumari, S.; Tulshyan, V.; Tewari, H. Cyber Security
    on the Edge: Efficient Enabling of Machine Learning on IoT Devices. Information
    2024, 15, 126. https://doi.org/10.3390/info15030126 AMA Style Kumari S, Tulshyan
    V, Tewari H. Cyber Security on the Edge: Efficient Enabling of Machine Learning
    on IoT Devices. Information. 2024; 15(3):126. https://doi.org/10.3390/info15030126
    Chicago/Turabian Style Kumari, Swati, Vatsal Tulshyan, and Hitesh Tewari. 2024.
    \"Cyber Security on the Edge: Efficient Enabling of Machine Learning on IoT Devices\"
    Information 15, no. 3: 126. https://doi.org/10.3390/info15030126 Note that from
    the first issue of 2016, this journal uses article numbers instead of page numbers.
    See further details here. Article Metrics Citations No citations were found for
    this article, but you may check on Google Scholar Article Access Statistics Article
    access statistics Article Views 23. Feb 28. Feb 4. Mar 9. Mar 14. Mar 19. Mar
    24. Mar 29. Mar 3. Apr 0 1000 250 500 750 1250 For more information on the journal
    statistics, click here. Multiple requests from the same IP address are counted
    as one view.   Information, EISSN 2078-2489, Published by MDPI RSS Content Alert
    Further Information Article Processing Charges Pay an Invoice Open Access Policy
    Contact MDPI Jobs at MDPI Guidelines For Authors For Reviewers For Editors For
    Librarians For Publishers For Societies For Conference Organizers MDPI Initiatives
    Sciforum MDPI Books Preprints.org Scilit SciProfiles Encyclopedia JAMS Proceedings
    Series Follow MDPI LinkedIn Facebook Twitter Subscribe to receive issue release
    notifications and newsletters from MDPI journals Select options Subscribe © 1996-2024
    MDPI (Basel, Switzerland) unless otherwise stated Disclaimer Terms and Conditions
    Privacy Policy"'
  inline_citation: '>'
  journal: Information (Switzerland)
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Cyber Security on the Edge: Efficient Enabling of Machine Learning on IoT
    Devices'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Maestri S.
  - Furlan M.
  - Mulroney L.
  - Tarrero L.C.
  - Ugolini C.
  - Pozza F.D.
  - Leonardi T.
  - Birney E.
  - Nicassio F.
  - Pelizzola M.
  citation_count: '0'
  description: N6-methyladenosine (m6A) is the most abundant internal eukaryotic mRNA
    modification, and is involved in the regulation of various biological processes.
    Direct Nanopore sequencing of native RNA (dRNA-seq) emerged as a leading approach
    for its identification. Several software were published for m6A detection and
    there is a strong need for independent studies benchmarking their performance
    on data from different species, and against various reference datasets. Moreover,
    a computational workflow is needed to streamline the execution of tools whose
    installation and execution remains complicated. We developed NanOlympicsMod, a
    Nextflow pipeline exploiting containerized technology for comparing 14 tools for
    m6A detection on dRNA-seq data. NanOlympicsMod was tested on dRNA-seq data generated
    from in vitro (un)modified synthetic oligos. The m6A hits returned by each tool
    were compared to the m6A position known by design of the oligos. In addition,
    NanOlympicsMod was used on dRNA-seq datasets from wild-type and m6A-depleted yeast,
    mouse and human, and each tool’s hits were compared to reference m6A sets generated
    by leading orthogonal methods. The performance of the tools markedly differed
    across datasets, and methods adopting different approaches showed different preferences
    in terms of precision and recall. Changing the stringency cut-offs allowed for
    tuning the precision-recall trade-off towards user preferences. Finally, we determined
    that precision and recall of tools are markedly influenced by sequencing depth,
    and that additional sequencing would likely reveal additional m6A sites. Thanks
    to the possibility of including novel tools, NanOlympicsMod will streamline the
    benchmarking of m6A detection tools on dRNA-seq data, improving future RNA modification
    characterization.
  doi: 10.1093/bib/bbae001
  full_citation: '>'
  full_text: '>

    "Advertisement Journals Books Issues Submit Alerts About Briefings in Bioinformatics
    This issue                      Bioinformatics and Computational Biology Books
    Journals Oxford Academic                                   Advanced Search Volume
    25 Issue 2 March 2024 Article Contents Abstract INTRODUCTION RESULTS DISCUSSION
    METHODS ACKNOWLEDGEMENTS FUNDING DATA AVAILABILITY References Author notes Supplementary
    data < Previous Next > JOURNAL ARTICLE Benchmarking of computational methods for
    m6A profiling with Nanopore direct RNA sequencing Simone Maestri, Mattia Furlan,
    Logan Mulroney, Lucia Coscujuela Tarrero, Camilla Ugolini, Fabio Dalla Pozza,
    Tommaso Leonardi, Ewan Birney, Francesco Nicassio, Mattia Pelizzola Author Notes
    Briefings in Bioinformatics, Volume 25, Issue 2, March 2024, bbae001, https://doi.org/10.1093/bib/bbae001
    Published: 26 January 2024 Article history PDF Split View Cite Permissions Share
    Abstract N6-methyladenosine (m6A) is the most abundant internal eukaryotic mRNA
    modification, and is involved in the regulation of various biological processes.
    Direct Nanopore sequencing of native RNA (dRNA-seq) emerged as a leading approach
    for its identification. Several software were published for m6A detection and
    there is a strong need for independent studies benchmarking their performance
    on data from different species, and against various reference datasets. Moreover,
    a computational workflow is needed to streamline the execution of tools whose
    installation and execution remains complicated. We developed NanOlympicsMod, a
    Nextflow pipeline exploiting containerized technology for comparing 14 tools for
    m6A detection on dRNA-seq data. NanOlympicsMod was tested on dRNA-seq data generated
    from in vitro (un)modified synthetic oligos. The m6A hits returned by each tool
    were compared to the m6A position known by design of the oligos. In addition,
    NanOlympicsMod was used on dRNA-seq datasets from wild-type and m6A-depleted yeast,
    mouse and human, and each tool’s hits were compared to reference m6A sets generated
    by leading orthogonal methods. The performance of the tools markedly differed
    across datasets, and methods adopting different approaches showed different preferences
    in terms of precision and recall. Changing the stringency cut-offs allowed for
    tuning the precision-recall trade-off towards user preferences. Finally, we determined
    that precision and recall of tools are markedly influenced by sequencing depth,
    and that additional sequencing would likely reveal additional m6A sites. Thanks
    to the possibility of including novel tools, NanOlympicsMod will streamline the
    benchmarking of m6A detection tools on dRNA-seq data, improving future RNA modification
    characterization. RNA modifications, N6-methyladenosine, Nanopore, dRNA-seq, benchmarking,
    machine learning Issue Section: Review INTRODUCTION RNA molecules are known to
    be decorated by more than 160 different chemical modifications, which can be found
    on both the nitrogenous base and the ribose sugar [1] and have profound consequences
    on the fate of coding and non-coding RNA species [2]. Many studies have been conducted
    to investigate the prevalence, transcriptome distribution, and functional role
    of N6-methyladenosine (m6A), the most abundant internal modification of eukaryotic
    coding transcripts [3, 4]. m6A is a reversible and dynamic mark deposited by methyltransferases,
    mainly at the RRACH (R = A/G, H = U/A/C) consensus motif, removed by demethylases,
    and recognized by specific effector proteins which mediate a large set of effects
    [3]. Indeed, m6A has been shown to markedly impact RNA metabolism, including processing,
    degradation, translation and localization [5, 6]. Additionally, m6A has been shown
    to be involved in wide-ranging roles of gene expression regulation, both in physiological
    conditions, including cellular differentiation, meiosis, heat stress response,
    gametogenesis and neurons activity [7], and pathological conditions, such as viral
    infection and several types of cancer [8, 9]. The development of various methods
    for quantification and mapping of RNA modifications was pivotal for the surge
    of RNA modifications research in the last decade [10]. In particular, various
    approaches based on high-throughput sequencing were developed for m6A profiling
    that rely on immunoprecipitation of modified molecules (e.g. MeRIP-seq [11], m6A-seq
    [12], m6A-seq2 [13], miCLIP [14], miCLIP2 [15] and m6A-LAIC-seq [16]), or on biochemical
    treatments that leave characteristic footprints on the cDNA, depending on the
    presence of the RNA modification of interest (e.g. PA-Seq [17], MAZTER-seq [18],
    m6A-REF-seq [19], DART-seq [20], m6A-SEAL-seq [21], m6A-label-seq [22], GLORI
    [23] and m6A-SAC-seq [24]). However, specific antibodies, enzymes and chemical
    compounds are currently available only for a limited set of RNA modifications,
    they can have low specificity, they are typically semi-quantitative, they are
    inadequate for profiling more than one modification simultaneously [25, 26], and
    they lack isoform and single molecule-resolution. Recently, Oxford Nanopore Technologies
    (ONT) launched a platform to directly sequence native RNA molecules (dRNA-seq)
    [27]. The electric signal recorded by ONT sequencing platform was shown to be
    altered by the presence of RNA modifications [27–29]. This paved the way to the
    single-molecule and single-base characterization of RNA modifications and prompted
    the development of computational tools to profile m6A from dRNA-seq data [30,
    31]. These tools can be divided into two main groups: (i) single-condition tools,
    which require training a machine learning algorithm capable of distinguishing
    between modified and unmodified nucleotides and (ii) multi-condition tools, which
    require sequencing an additional condition devoid of the modification(s) of interest.
    The latter is typically generated through knock-down, knock-out or pharmacological
    inhibition of methyltransferases or by in vitro transcription. Tools can be additionally
    divided depending on whether they rely on the ionic current signal, or errors
    in the base calling. Furthermore, some tools can provide the modification stoichiometry,
    and some can achieve base-level or single-molecule resolution depending on whether
    they work in the genome or transcriptome reference space [32]. More than a dozen
    tools were already published, and others are likely to be released in the near
    future. These tools are often complex to install and have high demands in terms
    of storage and computing power [33]. Although each software has already been compared
    against selected tools at the time of publication, only recently a study covered
    multiple tools for m6A detection on dRNA-seq data focusing on the mouse epitranscriptome
    [34]. Altogether, users are left with limited guidance on how to prioritize the
    choice of the tool, on how to set significance cut-offs, and on how to coherently
    test additional novel tools. To address these needs and open questions, we developed
    NanOlympicsMod, a computational workflow designed to maximize reproducibility
    and portability in the comparative assessment of dRNA-seq m6A detection tools.
    We used NanOlympicsMod to execute and compare 14 tools on four different dRNA-seq
    datasets differing in terms of synthetic/biological origin, transcriptome size
    and coverage depth. The results were benchmarked against reference m6A sets obtained
    from established orthogonal techniques. This study showed a remarkable heterogeneity
    in the performances of the tools, underlying the importance of a critical selection
    of the software and cut-off settings depending on the desired precision and recall
    targets. RESULTS The NanOlympicsMod benchmarking framework We set up NanOlympicsMod,
    a framework to benchmark software profiling RNA modifications on Nanopore dRNA-seq
    data. This framework was adopted for the comparative evaluation of 14 computational
    tools (Supplementary Table 1, see Supplementary Data available online at http://bib.oxfordjournals.org/)
    and was designed to facilitate the inclusion and test of additional tools. NanOlympicsMod
    includes a computational pipeline based on Nextflow [35] workflow manager, and
    was applied to four different dRNA-seq datasets, together with a set of corresponding
    reference sets of m6A hits generated by various short-reads sequencing based techniques
    (Figure 1). Figure 1 Open in new tabDownload slide The NanOlympicsMod workflow
    and adopted datasets. (A) Schema of NanOlympicsMod, including input data, pre-processing
    steps, tools execution, post-processing and comparative analyses. (B) Experimental
    design for the four different datasets analysed by NanOlympicsMod; the methods
    used to generate the reference set of m6A hits in yeast and mouse are illustrated.
    NanOlympicsMod relies on Nextflow, guaranteeing portability across platforms and
    support for different job schedulers, and adopts Docker and Singularity container
    technologies, removing the need to install required software dependencies and
    ensuring reproducibility. The pipeline includes a pre-processing module, preparing
    the input files required by each tool, a module for the parallel execution of
    the tools, a post-processing module converting the output of the tools in a common
    format, and a module implementing a set of analyses for the assessment of the
    tools results, their mutual concordance, and their agreement with independent
    reference sets of m6A hits (Figure 1A). We applied NanOlympicsMod to three recently
    released dRNA-seq datasets for the profiling of m6A on synthetic RNAs, yeast,
    and mouse transcriptomes, and to a dRNA-seq dataset produced in the context of
    this work for the profiling of m6A on human transcriptome (Figure 1B and Supplementary
    Table 2, see Supplementary Data available online at http://bib.oxfordjournals.org/).
    Each dataset includes an m6A-depleted condition to be used for the comparative
    tools. The datasets are fully described in the Supplementary data. Various matching
    reference sets of m6A hits were considered that encompass different methods for
    the profiling of the mark, either relying or not on m6A-specific antibodies, including
    m6A-seq and MAZTER-seq for yeast, miCLIP2 and GLORI for mouse and GLORI for human
    (Figure 1B and Supplementary Table 3, see Supplementary Data available online
    at http://bib.oxfordjournals.org/). Computational requirements, number and location
    of hits We ran all the 14 considered tools (Supplementary Table 1, see Supplementary
    Data available online at http://bib.oxfordjournals.org/) on the four test datasets
    (Figure 1). For some of the tools we were not able to complete the analysis or
    to obtain exploitable results in some of the datasets. Eventually, we were able
    to complete the analysis for 12 tools in the synthetic oligos dataset, 9 tools
    in the yeast dataset, 11 tools in the mouse dataset and 11 tools in the human
    dataset. For nine of these tools, we were able to obtain results in all four datasets.
    We were unable to complete the analysis in any of the four datasets with one tool,
    nanoDoc. Each software had different computational requirements, which were influenced
    by the size of the reference and/or the amount of available sequencing reads (Supplementary
    Figure S1, see Supplementary Data available online at http://bib.oxfordjournals.org/).
    The various tools differ in terms of parameters that can be tuned to set significance
    cut-offs or filtering thresholds, thus defining the stringency of the analysis,
    and each tool has its own default value for these settings (Supplementary Table
    4, see Supplementary Data available online at http://bib.oxfordjournals.org/).
    We initially decided to run each tool with their respective default settings.
    In these conditions the tools returned a number of hits that varied by several
    orders of magnitude, ranging from less than one hundred to more than 1e5 hits.
    The tools ranking in terms of numerosity of the hits was relatively consistent
    across the yeast, mouse and human datasets (Figure 2A-D). Figure 2 Open in new
    tabDownload slide Key results executing the tools with default settings. (A) Number
    of hits detected by NanOlympicsMod for each tool in the Oligos dataset. (B) As
    (A) for the yeast dataset. (C) As (A) for the mouse dataset. (D) As (A) for the
    human dataset. (E) Distribution of m6A hits for each tool along the synthetic
    oligos. (F) as (E) for the yeast metagene. (G) as (E) for the mouse metagene.
    (H) as (E) for the human metagene. (I) Heatmap reporting the overlap of m6A hits
    for each pair of tools executed with default settings on the oligos dataset. The
    value in a cell represents, for each pair of tools, the proportion of hits in
    common to the number of hits of the tool on the row (see the schema on the left
    of the panel). (J) As in (I) for the yeast dataset. (K) As in (I) for the mouse
    dataset. (L) As in (I) for the human dataset. The patterning of m6A hits returned
    by each tool was determined along the length of the synthetic oligos, and along
    a meta-gene for the yeast, mouse and human datasets. For the modified oligos,
    all adenosines were replaced by m6A resulting in an even distribution of the modification
    across the entire RNA length. Given that the sequencing coverage for this dataset
    is rather uniform, we expected the m6A hits returned by the tools to be uniformly
    distributed. Indeed, most of the tools returned a relatively flat profile of m6A
    hits along the oligos. Only MINES, m6Anet, EpiNano-SVM and EpiNano-Error favoured
    specific parts of the oligos (Figure 2E). In yeast, mouse and human, the m6A hits
    returned by most of the tools were enriched at 3′ ends and at the stop codon,
    in agreement with the known location of m6A marks for these species [4]. Only
    MINES and m6Anet found the m6A hits for the yeast dataset enriched in the mid
    part of the coding region (Figure 2F-H). Overlap among the tools Once we determined
    the number and location of m6A hits for each tool, we compared them across the
    tools. Since Nanopore-based analyses are reflecting the combined influence of
    a k-mer of bases, typically a 5-mer, it is not trivial to assign m6A hits to specific
    bases, especially when k-mers contain multiple As. For this reason, we decided
    to bin the query space (i.e. the oligos or the transcribed portion of yeast, mouse
    and human genomes). This also allowed to avoid penalizing the concordance between
    tools whose m6A hits might be separated by a few bases and to avoid inflating
    the concordance between tools which report multiple adjacent hits for a single
    modification event. We then determined, for each pair of tools, the overlap of
    bins with at least one identified m6A. In the oligos dataset, the tools that identified
    the most m6A sites (> 1000) were in very good agreement among each other, with
    an average overlap of 0.93 (Figure 2I). The same was observed for the tools with
    fewer identified m6A sites, in the order of dozens, whose sites were largely a
    subset of the tools with a higher number of sites. Similar results were obtained
    for yeast, mouse and human (Figure 2J-L), where the m6A sites identified by the
    tools with fewer calls were largely confirmed by the sites of the tools with the
    largest number of calls. The tools that completed the analysis on both yeast and
    mouse datasets had similar mutual concordance. Agreement with reference sets of
    m6A sites Once we established that the pattern of m6A hits was plausible and assessed
    that the tools concordance was largely driven by the number of identified sites,
    we set to evaluate the tools precision and recall. To this end, the various datasets
    are differently informative. The distribution of m6A marks in yeast, mouse and
    human is dictated by the in vivo constraints, yet there is no ground truth about
    the location of the marks. On the contrary, the distribution of m6A marks in the
    synthetic oligo dataset is artificial, yet their location is known by design.
    We determined the precision and recall for each tool using each tool’s documented
    default settings. We also calculated the F1 score to capture the collective impact
    of both metrics. In the oligo dataset, the precision was high (>0.75) for all
    tools, while they returned either very high or very low recall F1 score (Figure
    3A). In particular, the multi-sample tools performed better than the single-sample
    tools, except for EpiNano-SVM. We then generated precision-recall curves by considering
    various significance cut-offs in addition to the default setting, as described
    in the Methods (Figure 3B). Even with very different settings the performance
    of the tools was always good in terms of precision, while it recapitulated the
    preference for low or high recall obtained at default settings. Tools performed
    similarly also in terms of Area Under the Precision-Recall Curve (AUPRC), with
    a high fraction of overlapping AUPRCs 95% Confidence Intervals (Supplementary
    Figure S2, see Supplementary Data available online at http://bib.oxfordjournals.org/).
    This is due to the small number of positive bins (1543) which resulted in large
    CIs compared to the range covered by the AUPRCs (the median CI covered 27% of
    the range). Noticeably, this resulted in the overlap of four tools with the random
    classifier whose AUPRC was inflated due to the high fraction of positive bins.
    Figure 3 Open in new tabDownload slide Agreement with reference sets of m6A hits.
    (A) Precision, recall and F1 score for each tool executed at default conditions
    on the oligos dataset. According to Supplementary Table 1, GM and TM identify
    tools working on the genome (G) or transcriptome (T) space and require multiple
    conditions, respectively. GS and TS identify tools working on the genome (G) or
    transcriptome (T) space and requiring a single condition, respectively. (B) Precision
    and recall curves at different cut-off values for the tools indicated in (A) on
    the oligos dataset; for each tool, the default cut-off is indicated by a square;
    the performance of a random classifier is included. (C) As in (A) for the yeast
    dataset. (D) as in (A) for the mouse dataset. (E) as in (A) for the human dataset.
    (F) as in (B) for the yeast dataset. (G) as in (B) for the mouse dataset. (H)
    as in (B) for the human dataset. For the yeast, mouse and human datasets, we integrated
    various orthogonal methods based on short reads sequencing for the profiling of
    m6A as surrogate of the missing ground truth: m6A-seq, MAZTER-seq, miCLIP2 and
    GLORI (as outlined in Figure 1B and detailed in the Supplementary Data, see Supplementary
    Data available online at http://bib.oxfordjournals.org/). The performance of all
    tested tools in these datasets was significantly worse than the oligos dataset,
    especially in terms of recall. None of the tools were able to obtain both high
    precision and high recall using the default settings. Furthermore, the tool’s
    performance for precision and recall was different among the three non-synthetic
    datasets, especially comparing mammalian with yeast datasets (Figure 3C-E). The
    precision-recall curves generalized this trend (Figure 3F-H). Indeed, the yeast
    dataset presented large AUPRC CIs due to the limited number of positive bins (1453),
    while the opposite was true in mESC and HEK293T (84 060 and 18 932 positive bins
    respectively); this resulted in a variable fraction of overlapping tools (Supplementary
    Figure S2, see Supplementary Data available online at http://bib.oxfordjournals.org/).
    In the latter datasets, the overlaps were more frequent when considering smaller
    bin sets (RRACH+ and/or high-coverage bins). Nevertheless, only Tombo CIs consistently
    overlapped with those of Nanocompore (in yeast) and Yanocomp (in human). Noticeably,
    the best performing tool for each analysis usually did not overlap with others
    independently from the number of positive bins. The tuning of the significance
    cut-off allowed exploring the precision-recall space, penalizing one metric in
    favour of increased performance for the other. Performance at RRACH and for highly
    expressed sites The analysis presented above ignores three key features of m6A,
    which distinguish the yeast, mouse and human datasets from the oligos one: the
    existence of preferred sequence contexts, the existence of exclusion zones where
    m6A is unlikely to be deposited, and the in vivo stoichiometry of the marks. Indeed,
    m6A is preferentially found at RRACH sequence motifs [4], and typically has low
    prevalence and stoichiometry [36]. In addition, it has recently been found to
    be markedly excluded from extreme transcripts ends and from the regions adjacent
    to exon–intron junctions [37]. Therefore, we tested whether restricting the analyses
    to those bins containing RRACH sequence motifs, falling outside of exclusion zones,
    or having substantial expression would improve the performance of the considered
    tools. Reassessing the mouse precision-recall curves in the context of the RRACH
    containing bins only marginally improved the tools performance in terms of precision
    (compare Figure A and B with Figure 3D and G). Re-evaluating the tools only for
    those bins that are outside exclusion zones did not significantly contribute to
    increasing the metrics (Figure C and D). Rather, imposing a filter on expression
    markedly improved the performance, especially in terms of recall (Figure E and
    F). The positive impact of the filter on expression was confirmed in human (Supplementary
    Figure S3, see Supplementary Data available online at http://bib.oxfordjournals.org/).
    Figure 4 Open in new tabDownload slide Agreement with reference sets of m6A hits
    on RRACH+, accessible, and high-coverage bins. (A) Precision, recall and F1 score
    for each tool executed at default conditions on the mouse dataset on RRACH+ bins.
    According to Supplementary Table 1, GM and TM identify tools working on the genome
    (G) or transcriptome (T) space and requiring multiple conditions, respectively.
    GS and TS identify tools working on the genome (G) or transcriptome (T) space
    and requiring a single condition, respectively. (B) Precision and recall curves
    at different cut-off values for the tools indicated in (A) on the mouse dataset;
    for each tool, the default cut-off is indicated by a square; the performance of
    a random classifier is included. (C) as in (A) for DRACH+ bins outside of splice-site
    exclusion zones. (D) as in (B) for DRACH+ bins outside of splice-site exclusion
    zones. (E) as in (A) for bins with high coverage. (F) as in (B) for bins with
    high coverage. Sequence features associated to true positive, false positive and
    false negative hits We then asked whether there are specific sequence features
    where m6A marks are particularly easier or more difficult to detect. For each
    tool, we tested if there are sequence features that are enriched within either
    true positive (TP) or false positive (FP) bins. We determined for each tool the
    accuracy of all the 12 variants of the RRACH motif, finding up to several fold
    differences (Figure 5A). Interestingly, the most common variants—those that are
    more often associated with m6A marks in vivo—are also those with the highest accuracy
    for all the tools (Figure 5B). Regarding the false positive bins, we searched
    for enriched motifs compared to a shuffled background (Figure 5C). We recapitulated
    the expected AC pattern only for the tools which constitutively analyse RRACH
    sites. For the other software, we obtained repetitive sequences mainly enriched
    in Ts and As which did not match with any known m6A motif. Figure 5 Open in new
    tabDownload slide Sequence features associated with true positive, false positive
    and false negative hits. (A) m6A hits of each tool were stratified based on their
    association to specific RRACH motifs, and their number and accuracy on the mouse
    dataset was reported. (B) Distribution of accuracy stratified for common and uncommon
    RRACH motifs. (C) De novo motif enrichment analysis was performed on 50 nt regions
    centred at false positive hits for each tool on the mouse dataset, and the most
    significant motif was reported, together with statistical significance and consensus
    motif; tools marked with * are restricted to RRACH/DRACH motifs by implementation.
    (D) Distribution of the GC content for 50 nt regions centred at true positive
    (TP), false negative (FN) and false positive (FP) m6A hits. (E) as (D) for the
    free energy. (F) as (D) for the Shannon entropy. We also characterized TP, FP
    and false negative (FN) bins in terms of GC content, free energy, which are proxy
    for the transcripts structural complexity, and Shannon Entropy, which is indicative
    of sequence information content. For all the tools we observed lower GC content
    and higher free energy in FN bins compared to TP ones, suggesting that all methods
    tend to miss m6A hits in less structured sequence contexts (Figure 5D and E).
    Rather, FP bins exhibited lower and more heterogeneous Shannon entropy compared
    to the other two classes (Figure 5F). This observation is in agreement with the
    repetitive motifs that we observed for tools not restricted to RRACHs, suggesting
    that FP in Nanopore based methods tend to occur in low complexity regions. Saturation
    analysis Finally, we exploited the high coverage of the in house sequenced human
    dataset to thoroughly assess the impact of coverage depth on the tools’ performances.
    Indeed, while it is clear that higher coverage is beneficial for a more comprehensive
    identification of m6A sites, it is unclear, at the considered sequencing coverage,
    how closely we are reaching the saturation of m6A calling. To this end, we determined
    the number of m6A hits identified by each tool on 25%, 50% and 75% of the reads
    for the human dataset and compared it to the number of hits called on the entire
    dataset. We observed an increase in the number of hits with higher coverage for
    all the tools (Figure 6A) —with the exception of DiffErr, which showed the opposite
    trend. We then evaluated the impact of sequencing depth on the F1 score for each
    tool’s default conditions and observed marginally improved performances with higher
    sequencing coverage, except for EpiNano-SVM and DiffErr, which showed an opposite
    trend (Figure 6B and Supplementary Figure S4, see Supplementary Data available
    online at http://bib.oxfordjournals.org/, respectively). Finally, when exploring
    precision and recall values obtained varying the confidence parameter, we noticed
    a consistent increase in AUPRC with higher sequencing coverage, except for EpiNano-SVM
    (Figure 6C). Altogether, these results indicated that, while with the coverage
    of a PromethION flow-cell we are getting closer to saturation, additional sequencing
    would be likely beneficial and lead to the identification of additional m6A sites.
    Figure 6 Open in new tabDownload slide m6A calling saturation analysis. (A) Saturation
    analysis for m6A calling by various tools on the human dataset; the number of
    hits (y-axis) identified on subsets of the whole dataset (x-axis) is reported
    as a proportion of the number of hits identified on the whole dataset. (B) As
    in (A) where the y-axis reports the corresponding F1 score. (C) as in (A) where
    the y-axis reports the AUPRC. Replicates merging For all the analyses discussed
    so far, replicates were presented as separate samples to the methods designed
    to handle them; in agreement with the specifications of the developers. To address
    this aspect, we focused on the tools capable of replicates analysis, and we reanalyzed
    the yeast dataset by providing either replicates as separate samples or combining
    them. Most of the tools involved in this analysis were indeed affected by the
    merging of replicates (Supplementary Figure S5, see Supplementary Data available
    online at http://bib.oxfordjournals.org/). While the two configurations typically
    differed in terms of number of significant sites, the number of replicate samples
    was not predictive of the number of identified sites. However, the hits of the
    configuration with the smaller set of methylated sites were typically a subset
    of the other configuration (overlap always greater than 59%, and over 99% for
    four out of six tools). DISCUSSION The advent of Nanopore sequencing of native
    transcripts generated rich datasets whose potential is still being explored. Numerous
    computational methods were developed for the analysis of these data, converting
    ionic current features into valuable information regarding RNA sequence, splicing
    variants, structure and polyA tails. These data promised to be highly informative
    on the multitude of modifications that decorate coding and non-coding transcripts.
    Indeed, numerous methods were published in a few years to profile the epitranscriptional
    landscape from dRNA-seq data, and others are likely to be available soon. However,
    users are left with limited guidance on how to prioritize the choice of the tool.
    We benchmarked 14 tools—all those that were available in November 2022—for the
    detection of m6A on these data (Supplementary Table 1, see Supplementary Data
    available online at http://bib.oxfordjournals.org/). We applied them to the analysis
    of four different dRNA-seq datasets with specific strengths and limitations (Figure
    1). The oligos dataset represents an artificial condition that poorly recapitulates
    the relative location and frequency of in vivo marks, and that lacks the confounding
    effect of additional modifications that might be present in proximity of m6A marks—even
    though in a yet unknown manner. However, as an important advantage, the ground
    truth in terms of m6A positioning and abundance is known in the oligos dataset.
    The yeast, mouse and human datasets lack a ground truth, but fully represent in
    vivo conditions of location, stoichiometry and context of m6A marks. While the
    yeast transcriptome is compact, and sequenced at high depth, the mouse transcriptome
    is significantly larger but sequenced at lower depth. To complement these datasets,
    we sequenced a human dataset taking advantage of the higher throughput PromethION
    platform, which could provide dRNA-seq of a transcriptome of complexity comparable
    to the mouse’s, but at a higher sequencing depth. The datasets processed for this
    work were heavy and complex, consisting of >22 M files totalling 4 TB of raw data,
    and likewise is the effort required for their analysis. We experienced difficulties
    completing the run for several tools, and for few of them we had to renounce,
    due to lack of evident progress in the run or the unexpected generation of empty
    output files. The tools returned a remarkably different number of hits. However,
    these had a plausible distribution, given the expected location in each specific
    test datasets, and pairwise overlap (Figure 2). These results suggested that the
    tools might have different performance in terms of precision and recall. The m6A
    calls returned by the tools were compared to reference sets of m6A hits (Figure
    1) to define precision, recall and F1 scores (Figure 3). In the case of the oligos
    dataset, the reference set is known by design and includes all the As available
    in the artificial sequences. For yeast, mouse and human, the reference set was
    obtained by integrating various independent datasets obtained with recent leading
    approaches for m6A profiling relying on short reads high-throughput sequencing.
    The analysis of precision and recall indicated that the tools performed very well
    on the synthetic oligos dataset, while the yeast, mouse and human datasets represented
    a more challenging task. The precision versus recall curves showed that the default
    settings for some of the tools nicely identify a good trade-off between precision
    and recall. For other tools, these curves could be used to point to better cut-off
    conditions for those users aiming at maximizing both metrics. Altogether, these
    analyses showed that, if needed, there is broad space to steer the preference
    towards either one of the two metrics. The low F1 scores in the yeast, mouse,
    and human datasets compared to the oligos dataset can possibly be attributed to
    the stoichiometry of m6A marks at each position or differences in bias between
    the orthogonal reference m6A sets and nanopore based m6A techniques. By mixing
    unmodified reads and modified reads from the oligos datasets, we could simulate
    a more biologically equivalent m6A stoichiometry in the synthetic oligos to address
    its effect on nanopore m6A detection. Most of the software tools had lower F1
    scores at lower m6A stoichiometry in the in silico mixed samples (Supplementary
    Figure S6, see Supplementary Data available online at http://bib.oxfordjournals.org/),
    which agrees with previous observations using a subset of the tools we tested
    with NanOlympicsMod (Nanocompore and xPore). This suggests that the lower expected
    m6A stoichiometry in the biological datasets is at least partially responsible
    for the observed reduced F1 scores. The tested tools can be grouped according
    to the genome or the transcriptome being the required reference sequence, and
    according to their requirement or not of a baseline sample depleted of the modification
    of interest (Supplementary Table 1, see Supplementary Data available online at
    http://bib.oxfordjournals.org/). Tools of any class performed well with the synthetic
    oligos dataset, especially in terms of precision, while at default settings they
    had different preferences in terms of recall, the multi-sample tools typically
    achieving higher recall values. The high precision obtained by all tools in this
    dataset is also a consequence of the high density of m6A nucleotides, constraining
    the minimum precision value to the ratio of m6A+ bins to all the bins. The multi-sample
    tools, such as ELIGOS, Yanocomp, DiffErr and Nanocompore performed better in the
    yeast dataset, probably benefiting from the higher coverage. Rather, the single-sample
    tools working in transcriptome space, such as m6Anet and DENA, performed better
    in the mouse and human datasets, likely because they were able to capture m6A
    features in complex transcriptomes. Interestingly, m6Anet and DENA were applied
    for the analysis of yeast and mouse datasets despite they were trained on data
    obtained for Homo sapiens and Arabidopsis thaliana species (Supplementary Table
    1, see Supplementary Data available online at http://bib.oxfordjournals.org/),
    which might partially explain those tools’ reduced performance in the yeast dataset.
    Similarly, EpiNano-SVM and Nanom6A were trained on synthetic oligos which lack
    the complexity of real transcriptomes and potential confounding factors like endogenous
    RNA modifications, potentially impacting their performances when applied to yeast,
    mouse and human data. We tested whether restricting to specific sets of bins,
    such as those associated with RRACH motifs, high coverage or far from exclusion
    zones, could improve the performance (Figure :). We found that, for those tools
    that are limited by design to only test RRACH or DRACH sites, this reassessment
    had limited chances of significant improvement. Only by filtering for highly expressed
    bins significatively boosted precision and recall. Finally, we identified specific
    sequence features that characterized TP, FP and FN bins (Figure 5). We showed
    that m6A at specific RRACH variants can be detected with higher accuracy and that
    the tested tools differ in terms of sequence motifs that could divert them. Additionally,
    we revealed that all the considered Nanopore-based tools tend to miss hits in
    unstructured regions, while identifying m6A unsupported by orthogonal techniques
    in low complexity domains. These observations are indicative of sequencing platforms-specific
    biases. For instance, the systematic occurrence of FNs in low-entropy bins could
    stem from the suboptimal performance of dRNA-seq with homopolymers, or from short
    reads alignment issues in repetitive sequences. Furthermore, short-read based
    methods may exhibit biases towards less structured transcripts, where antibodies
    and chemical compounds could more efficiently access the substrate. Further in-depth
    studies are warranted, likely with both short-read and Nanopore based approaches,
    to better understand and assess these limitations. We then evaluated the tools’
    performances in terms of number of hits, F1 score at default conditions and area
    under the PR curve at different coverage depth values. Results from this saturation
    analysis showed a marked increase in the number of hits at higher coverage depth,
    with a decrease in the slope of the curve between 75% and 100% of the available
    coverage, suggesting the curve was about to reach a plateau. Interestingly, DiffErr
    showed an opposite trend, suggesting that the tool may be designed to use the
    additional information to restrict the set of candidate hits. When considering
    the F1 score value at default conditions, we observed only marginally improving
    performances with higher sequencing coverage for most of the tools. This result
    may suggest that the increase in coverage depth leads to an increase in the number
    of hits which, in turn, results in a higher sensitivity; however, the increase
    in sensitivity is also accompanied by a decrease in precision, with an overall
    effect of saturation of the F1 score. Finally, most of the tools showed an increase
    in the AUPRC with higher coverage depth, consistent with an overall improvement
    in m6A identification with higher coverage. This result also suggests that cut-off
    settings should be tuned also considering the available coverage depth. Only EpiNano-SVM
    showed a decrease in the AUPRC value at higher coverage depth: this result may
    be explained by features of the dataset used for the training of the algorithm.
    Interestingly, we showed that tools based on differential errors identification,
    as ELIGOS and DiffErr, were able to identify a consistent number of hits also
    in both the mouse and human datasets, confirming the presence of a differential
    error due to the presence/lack of m6A, despite the different sequencing platform
    and the associated base-calling model. In general, we recommend focusing on high-coverage
    regions, as this allows obtaining a marked increase in the tools’ performances.
    We observed that m6Anet outperformed all the tools both in the mouse and in the
    human dataset. On the oligos and yeast datasets, m6Anet was not among the top
    performers, possibly due to the fact that we were using the default neural network
    trained on a human dataset. If it is not possible to re-train m6Anet on a dataset
    from a related species, we advise the users to run multi-sample tools for yeast,
    such as ELIGOS and Nanocompore, as they were the top performers in terms of AUC
    in yeast and oligos datasets. As an alternative, we advise the users to integrate
    the predictions from multiple tools for obtaining a more accurate set of m6A modifications.
    The set of tools may be chosen by ranking them by the AUC value obtained in this
    study. In particular, the user may want to build a meta-classifier integrating
    the performances of multiple tools. We picked the top 5 performing tools, according
    to the AUC value, in the analysis of high-coverage bins of human dataset, and
    tested the performance of three meta-classifiers obtained as either the intersection,
    the majority vote or the union of their predictions. The majority vote classifier
    was the most balanced among the three in terms of recall and precision, allowing
    to obtain the highest F1 score at default conditions (0.40) (Supplementary Figure
    S7, see Supplementary Data available online at http://bib.oxfordjournals.org/),
    outperforming the best tool (MINES, F1 score = 0.38). A recent study from Zhong
    et al. [34] benchmarked multiple tools for m6A detection on dRNA-seq data focusing
    on the mouse epitranscriptome. Our results are largely consistent with the results
    reported by the Zhong study. However, we would like to stress key points where
    our study significantly improves compared to what has been published. First, in
    our study we describe the development and release of NanOlympicsMod, a Nextflow
    pipeline exploiting containerized technology for the benchmarking of m6A detection
    tools on dRNA-seq. A similar resource was completely missing in the Zhong paper
    and will be of utmost importance in the field. Not only for reproducing the results,
    but also for testing further tools that are likely to be published soon in this
    very active research field. Second, we benchmarked 14 tools on datasets from three
    different species, yeast, mouse, and human. The Zhong paper was primarily focused
    on a mouse dataset only. Third, the production of a high sequencing depth dataset
    for human allowed us to perform a saturation analysis of m6A calling that was
    not included in the Zhong paper. Fourth, we also tested the tools on a dataset
    relying on synthetic oligos, which was missing in the Zhong paper. This is particularly
    important, since it is the only condition in which the ground truth is known,
    being the position of m6A known by design of the oligos. Altogether, our analyses
    indicate that the target sequencing depth and the adopted cut-off settings are
    likely the most important choices for m6A profiling on dRNA-seq data. The choice
    of the specific tool likely depends also on whether one wishes to map the m6A
    hits directly on specific transcripts or not (genome versus transcriptome-based
    tools), whether one wishes to have direct evidence of the modification of interest
    (multi-sample versus single-sample tools) and whether m6A or other marks are sought.
    The NanOlympicsMod framework represents a portable, reproducible, and scalable
    resource to run and compare Nanopore Direct RNA Sequencing-based tools for the
    profiling of m6A or other marks, which will facilitate these decisions and will
    streamline the test of additional detection tools. Moreover, we think that the
    produced sequencing dataset will serve as a valuable resource for set-up and validation
    of novel dRNA-seq based tools. METHODS Cell culture treatment with STM2457 HEK293T
    cells were grown using Dulbecco''s Modified Eagle Medium (DMEM) supplemented with
    10% Fetal Bovine Serum (FBS) and 1% penicillin–streptomycin. Cells were treated
    with vehicle (Ethanol 100%) or with 20 μM STM2457 and incubated for 24 hours at
    37 °C. RNA extraction and mRNA purification Total RNA was extracted from 10 million
    cells using Qiazol (Qiagen 79306) and RNeasy Micro Kit (Qiagen 74004). mRNA purification
    was performed with 100 ug of Total RNA using μMACS™ mRNA Isolation Kit (Miltenyi
    Biotec 130–075-201) following the manufacturer’s protocol. Bulk m6A quantification
    Bulk m6A mRNA levels were quantified using Elisa kit (EpiQuik-Epigentek). A total
    of 100 ng of mRNA were loaded. Samples were incubated with m6A antibody for 1
    h following manufacturer’s protocol. The detected signal was quantified colorimetrically
    by reading the absorbance in a microplate spectrophotometer at a wavelength of
    450 nm. Nanopore direct RNA sequencing A total of 150 ng of mRNA were used as
    an input for Nanopore Direct RNA sequencing libraries preparation. A total of
    152 ng and 120 ng of library were obtained for HEK293T control and HEK293T Storm,
    respectively. Both samples were loaded on PromethION flow cells, with 7562 pores
    for HEK293T control and 8233 pores for HEK293T treated with STM2457. Reference
    files and datasets preparation See Supplemental Data for a comprehensive description
    of the considered and produced datasets. The description on how the data were
    processed follows here: Synthetic oligos The sequences of synthetic oligos were
    downloaded from [38] and concatenated into a single fasta file. Then, the coordinates
    of all ‘A’ nucleotides were obtained using vMatchPattern function of Biostrings
    v2.66.0 R package and saved to file in bed format. Yeast dataset The yeast Nanopore
    dRNA-seq data were retrieved from [39]. Reference genome and transcriptome files
    for SK1 yeast strain, together with the set of reference peaks, were downloaded
    from [39]. In particular, ‘MvO’ genome assembly was downloaded from http://cbio.mskcc.org/public/SK1_MvO/,
    while ‘SGD_2015_JRIH00000000’ reference transcriptome was downloaded from http://sgd-archive.yeastgenome.org/sequence/strains/.SK1/SK1_SGD_2015_JRIH00000000/.
    Since we could not retrieve a proper gtf annotation file for SK1 strain, we first
    aligned the transcriptome to the genome with minimap2 v2.24.0 [40] with -x splice
    mode. We then converted the alignment bam file in bed12 format with bedtools bamtobed
    v2.30.0 [41] and finally obtained a gtf annotation file using a combination of
    bedToGenePred and genePredTogtf from UCSC tools v377 (https://github.com/ucscGenomeBrowser/kent).
    The m6A hits reference set was obtained combining the hits from MAZTER-seq [18]
    and m6A-seq [42] released as supplemental material in Garcia-Campos et al. and
    Schwartz et al., respectively, and collapsing overlapping hits with bedtools merge
    v2.30.0 [41]. Mouse dataset The mouse Nanopore dRNA-seq data were retrieved from
    [43]. Reference genome and transcriptome fasta files for mouse, together with
    gtf annotation file, were downloaded from https://www.gencodegenes.org/mouse/release_M23.html.
    The m6A reference set was obtained combining the hits from miCLIP2 [15] and GLORI
    [23] released as supplemental material in Körtel et al. and Liu et al. respectively,
    and collapsing overlapping hits with bedtools merge v2.30.0 [41]. Human dataset
    The human dRNA-seq data were produced as part of this work and were uploaded to
    SRA (BioProject ID: PRJNA995902). The reference genome for human was downloaded
    from https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz, while
    the gtf annotation file was downloaded from https://ftp.ensembl.org/pub/release-109/gtf/homo_sapiens/Homo_sapiens.GRCh38.109.gtf.gz.
    Sequence and annotations for chromosome chr1 were then subset from the full files
    with bash custom scripts. The transcriptome fasta file for human was generated
    from the reference fasta and the annotation gtf files with bedtools getfasta v2.30.0
    [41]. The m6A reference set was obtained downloading GLORI hits release as supplemental
    material in Liu et al. [23] and subsetting hits from chromosome chr1. The NanOlympicsMod
    workflow The NanOlympicsMod workflow is composed of four steps: pre-processing,
    tools execution, post-processing and comparative analyses (Figure 1A). Pre-processing
    FAST5 files for the four datasets were re-basecalled using Guppy v6.2.1 with command
    ‘guppy_basecaller -i <input_path> -r -x “auto” -s <save_path> --fast5_out -c rna_r9.4.1_70bps_hac.cfg’.
    FAST5 files are converted from multi-reads to single-read with multi_to_single
    ONT API v4.0.0 (https://github.com/nanoporetech/ont_fast5_api) and the base-called
    sequences are extracted in FASTQ format with Poretools v0.6.0 [44]. Then, sequencing
    reads are aligned to the transcriptome (−x map-ont) and to the genome (−x splice)
    with Minimap2 v2.24.0 [40]. Alignment files are then used for signal resquiggling
    with both Tombo v1.5.1 [45] and Nanopolish v0.8.4 [46]. The pre-processing steps
    are performed in parallel for all the samples involved in the analysis, and the
    resulting files are then provided to each tool according to their requirements.
    Tools execution Fourteen tools for m6A detection on dRNA-seq data are run in parallel
    and the corresponding output is stored in a dedicated folder tree. As outlined
    in Supplementary Table 1, we ran ELIGOS v2.1.0 [43], m6Anet v1.1.0 [47], MINES
    [48], Tombo v1.5.1 [45], DRUMMER [49], EpiNano-SVM v1.2 [38], EpiNano-Error v1.2
    [38], DENA [50], Yanocomp v0.2 [51], Nanocompore v1.0.3 [39], xPore v2.0 [52],
    DiffErr v0.2 [29], nanom6A [53] and nanoDoc [54]. If replicates are available,
    they are provided as separate samples to the tools designed to handle them (Yanocomp,
    xPore, Nanocompore, m6Anet, ELIGOS, DiffErr and DRUMMER); otherwise they are merged.
    Post-processing Post-processing is based on an R script that collects all the
    tools output. This is heterogeneous in terms of format and information and this
    workflow step converts each tool’s output into a common file format. First, for
    those tools which rely on transcriptome alignment, a lift-over from transcriptome-based
    to genome-based coordinates is also performed with the transcriptToGenome function
    from ensembldb v2.18.4 R package. Although this may not be a compulsory step in
    a standard analysis, it was required for comparing these tools to those providing
    hits in genome-based coordinates and to the reference sets. Finally, a BED file
    for each tool is produced, which contains the genomic position of each call, its
    modification status (modified or unmodified) - defined according to criteria suggested
    by the developers - and the numerical value which drove the classification, if
    available (i.e. False Discovery Rate, modification probability, P-value). Comparative
    analyses The comparative analysis consists of an R script designed to process
    all the BED files returned by the post-processing step and to perform the analyses
    described in the main text. The details of these analyses are described in the
    section Additional analyses. Additional analyses Binning The gene space is first
    binned into fixed-size windows, starting from the 3′ end of the gene. In case
    the gene length is not multiple of the window size, the last window at the 5′
    end is discarded. We chose 5 nt as window size for the oligos dataset, and 50
    nt for yeast, mouse and human datasets. Smaller windows of 40, 30, 20 and 10 nt
    were also tested for the human dataset, showing a small while progressive increase
    in the AUC with increasing window size (Supplementary Figure S8, see Supplementary
    Data available online at http://bib.oxfordjournals.org/). The smaller window size
    for the oligos dataset was required by the high density of As, since a larger
    window size would have resulted in having only m6A+ bins. Collecting the m6A hits
    of each tool A matrix of m6A hits with number of rows equal to the number of bins
    and number of columns equal to the number of tools plus 1 (the reference set)
    is created. The matrix columns are initialized to 0 or − 1, depending on whether
    the confidence parameter for the tool needs to be maximized (i.e. probability
    of modification) or minimised (i.e. P-value), respectively. For each tool, the
    overlaps between the hits and the genes bins are evaluated and the value of the
    confidence parameter is reported in the corresponding cell of the matrix. In case
    multiple hits occur within the same bin, the value corresponding to the least
    confident hit is reported. In case smaller confidence parameter values imply higher
    confidence for a tool (e.g. P-value), scores for that tool are multiplied by −1.
    This is required by PRROC v1.3.1 R package [55] that we used for plotting Precision-Recall
    curves, as it expects that higher values of the parameter correspond to higher
    confidence calls (see below). An auxiliary binary matrix of hits is also created,
    containing 1 or 0 depending on whether the bin should be called as m6A+ or not
    after filtering the hits at the default parameter threshold. This matrix is then
    used for evaluating the hits’ overlaps and for evaluating recall, precision and
    F1 score at default conditions. Overlap analyses The overlap of m6A hits for each
    pair of tools is stored in a matrix with the number of rows and columns equal
    to the number of tools. Each (i,j) cell of this matrix reports the number of m6A+
    bins identified by both tools i and j, divided by the number of m6A+ bins identified
    by tool i (the one reported in the rows in Figure 3). The matrix was then visualised
    as a heatmap with the pheatmap function of pheatmap v1.0.12 R package. Comparison
    of hits to reference m6A set The tools default conditions were defined as described
    in Supplementary Table 4, see Supplementary Data available online at http://bib.oxfordjournals.org/.
    The binary matrix of m6A hits at default conditions was used to compare the bins
    identified as m6A+ for a given tool to the bins classified as m6A+ according to
    the reference set of each dataset. The recall was then determined as the ratio
    of m6A+ bins in the reference set that were identified as m6A+ also by the tool,
    while the precision was computed as the ratio of m6A+ bins identified by the tool
    that were confirmed by the reference set. The F1 score was determined as the harmonic
    mean of precision and recall. For assessing precision and recall at various stringency
    cut-offs, the scores of the matrix of m6A hits were screened according to each
    cut-off and compared to the hits of the corresponding reference m6A set to define
    true and false positive bins for each tool. Precision-Recall curves were plotted
    with the pr.curve function of PRROC v1.3.1 R package [55] which also provided
    the corresponding AUPRC. The approach described in [56] was applied to estimate
    AUPRCs 95% Confidence Intervals. Selection of RRACH, accessible, and high-coverage
    bins RRACH-containing bins were determined using the vMatchPattern function of
    Biostrings v2.66.0 R package. Accessible bins were identified as those bins overlapping
    to ‘GGACC’, ‘AGACA’, ‘TGACT’, ‘AGACT’, ‘GAACT’, ‘GGACA’ and ‘GGACT’ motifs, occurring
    outside of inaccessible regions, defined as 100 nt at the ends of each exon, using
    a combination of vMatchPattern and resize function of GenomicFeatures package.
    High-coverage bins were determined importing genome alignment files in R v4.2.1
    using readGAlignments function of GenomicAlignments v1.32.1 R package and evaluating
    the read counts for each exon, using a combination of makeTxDbFromGFF, exons and
    findOverlaps functions of GenomicFeatures v1.48.3 package. The genomic coordinates
    of exons with more than 100 read counts were saved to a file in BED format and
    were used to identify the subset of high-coverage bins. Metagene plots Starting
    from BED files including genomic coordinates of m6A hits filtered at default parameter
    values, we produced metagene plots showing m6A hits distribution along transcriptional
    units using GuitarPlot function of Guitar v2.12.0 package. Sequence features associated
    with either true or false positive calls We first annotated genomic bins with
    a specific motif, in case a single hit in the reference set overlapped to the
    bin and to a RRACH motif. We then evaluated the accuracy (i.e. the recall) of
    each tool at detecting true positive bins for each motif and produced a barplot.
    Moreover, we performed a de novo motif enrichment analysis on the sequence of
    false positive bins using XSTREME program from MEME Suite v5.5.2 [57] (online
    implementation). The gene sequence of 50 nt bins where the tools detected m6A
    hits that were not confirmed by the reference set was extracted and used for a
    motif enrichment analysis, using shuffled input sequences as control. Only the
    top motif for each tool was reported, together with its statistical significance
    and the resulting consensus motif. We additionally obtained the sequences of false
    negative bins for each tool, which are bins not called by the tool but present
    in the reference set. For each tool and bin in the true positive, false negative,
    and false positive sets, we calculated the GC content using R, we determined the
    free energy using RNAfold v2.5.0 from the Vienna RNA package [58], and we calculated
    the Shannon entropy using the Entropy method from the R package DescTools (v0.99.49).
    Source code The source code for the NanOlympicsMod workflow, and for reproducing
    all the results included in this study, are available at the following GitHub
    repository: https://github.com/mfurla/NanOlympicsMod. Key Points Nanopore direct
    RNA-seq sequencing (dRNA-seq) allows the identification of various RNA modifications
    including N6-Methyladenosine (m6A) Numerous tools were developed to identify m6A
    from dRNA-seq data, however a comprehensive benchmarking across species and against
    established orthogonal methods is missing We developed the NanOlympicsMod workflow
    to facilitate comparing tools for m6A detection on dRNA-seq data, and we used
    it to benchmark 14 software on synthetic RNA oligos, yeast, mouse and human transcriptomes
    The performance of the tools varies between synthetic and real datasets and is
    particularly sensitive to the expression of the tested regions Tools relying on
    specific approaches, i.e. working on transcriptome or genome space and requiring
    single or multiple conditions, have different preferences in terms of precision
    and recall ACKNOWLEDGEMENTS We would like to acknowledge that the research activity
    herein was carried out using the IIT, IEO and EBI HPC infrastructure. We also
    would like to acknowledge Giulio Pavesi for insightful discussions, and Piero
    Carninci, Clelia Peano and personnel of the Human Technopole High-Throughput Sequencing
    Operations unit for the sequencing of the human dataset. FUNDING This work was
    supported by grants from the Italian Association for Cancer Research (AIRC) -
    project IG 2020 (ID. 24784) to M.P., and project IG 2019 (ID. 22851) to F.N.;
    a grant from National Center for Gene Therapy and Drugs based on RNA Technology
    (CN00000041) supported by European Union—NextGenerationEU PNRR MUR—M4C2 to F.N;
    the Giorgio Boglio fellowship from AIRC (ID.26611) to M.F; a fellowship from AIRC
    to C.U.; and an EMBL ETPOD fellowship to L.M. DATA AVAILABILITY Human Nanopore
    sequencing data generated as part of this study are available in SRA (BioProject
    ID: PRJNA995902). Oligos, Yeast and Mouse Nanopore sequencing data were derived
    from sources in the public domain as indicated in Supplementary Table 2.The source
    code for the NanOlympicsMod workflow, and for reproducing all the results included
    in this study, are available at the following GitHub repository: https://github.com/mfurla/NanOlympicsMod.
    Simone Maestri is an engineer expert in bioinformatics and Nanopore sequencing
    data. He was computational postdoc in Pelizzola’s group at the Istituto Italiano
    di Tecnologia. He moved at the University of Milano, working on the analysis of
    Nanopore sequencing data in the Lab of Stem Cell Biology and Pharmacology of Neurodegenerative
    Diseases. Mattia Furlan is a physicist expert in bioinformatics, transcriptional
    regulation, RNA modifications and Nanopore sequencing. He works as computational
    postdoc in Pelizzola’s group at the Istituto Italiano di Tecnologia. Logan Mulroney
    is expert in bioinformatics, RNA modifications and Nanopore sequencing. He has
    been joint postdoc with European Bioinformatic Institute and Istituto Italiano
    di Tecnologia. He now works as computational postoc in Nicassio’s group at the
    Istituto Italiano di Tecnologia. Lucia Coscujuela Tarrero is expert in cancer
    RNA biology, RNA modifications and genomics. He works as postdoc in Pelizzola’s
    group at the Istituto Italiano di Tecnologia. Camilla Ugolini is a physicist expert
    in bioinformatics, RNA modifications and Nanopore sequencing. He works as PhD
    student in Nicassio’s group at the Istituto Italiano di Tecnologia. Fabio Dalla
    Pozza worked as bioinformatician in Pelizzola’s group at the Istituto Italiano
    di Tecnologia. Tommaso Leonardi is expert in bioinformatics, RNA modifications
    and Nanopore sequencing. He worked as Researcher at the Istituto Italiano di Tecnologia.
    Ewan Birney is Deputy Director General of EMBL. He is also Director of EMBL-EBI
    with Dr Rolf Apweiler. He runs a research group studying between-individual differences
    in both Japanese rice fish (Medaka) and humans, and exploring novel algorithms
    in sequence methods, in particular around nanopore technology. Francesco Nicassio
    is Senior Researcher at the Istituto Italiano di Tecnologia, Principal Investigator
    of the Genomic Science research line. Scientific interests are centered on the
    exploitation of genomic approaches to the study of mechanisms in control of gene
    expression dynamics provided by non-coding RNAs (microRNAs and long noncoding
    RNAs) and their impact on cell behaviour and human disease, with emphasis on Cancer.
    Mattia Pelizzola is a computational biologist with background in biotechnology
    affiliated at the Istituto Italiano di Tecnologia and Associate Professor at the
    Dept. of Biotechnology and Biosciences, Milano-Bicocca University. He leads a
    research group studying how co- and post- transcriptional events shape gene expression
    programs. His group employs an interdisciplinary approach combining cutting edge
    experimental and computational methods, including the profiling of nascent and
    modified RNA, single-molecule Nanopore sequencing, and mathematical modelling.
    References 1. Boccaletto P, Bagiński B. MODOMICS: an operational guide to the
    use of the RNA modification pathways database. RNA Bioinformatics 2021;2284:481–505.
    Google Scholar WorldCat   2. Roundtree IA, Evans ME, Pan T, He C. Dynamic RNA
    modifications in gene expression regulation. Cell 2017;169:1187–200. Google Scholar
    CrossrefPubMed WorldCat   3. He PC, He C. M6a RNA methylation: from mechanisms
    to therapeutic potential. EMBO J 2021;40:e105977. Google Scholar CrossrefPubMed
    WorldCat   4. Boulias K, Greer EL. Biological roles of adenine methylation in
    RNA. Nat Rev Genet 2023;24:143–60. Google Scholar CrossrefPubMed WorldCat   5.
    Wang S, Lv W, Li T, et al.  Dynamic regulation and functions of mRNA m6A modification.
    Cancer Cell Int 2022;22:48. Google Scholar CrossrefPubMed WorldCat   6. Yang Y,
    Hsu PJ, Chen Y-S, Yang YG. Dynamic transcriptomic m6A decoration: writers, erasers,
    readers and functions in RNA metabolism. Cell Res 2018;28:616–24. Google Scholar
    CrossrefPubMed WorldCat   7. Jiang X, Liu B, Nie Z, et al.  The role of m6A modification
    in the biological functions and diseases. Sig Transduct Target Ther 2021;6:74.
    Google Scholar Crossref WorldCat   8. Dang W, Xie Y, Cao P, et al.  N6-Methyladenosine
    and viral infection. Front Microbiol 2019;10:417. Google Scholar CrossrefPubMed
    WorldCat   9. Barbieri I, Kouzarides T. Role of RNA modifications in cancer. Nat
    Rev Cancer 2020;20:303–22. Google Scholar CrossrefPubMed WorldCat   10. Moshitch-Moshkovitz
    S, Dominissini D, Rechavi G. The epitranscriptome toolbox. Cell 2022;185:764–76.
    Google Scholar CrossrefPubMed WorldCat   11. Meyer KD, Saletore Y, Zumbo P, et
    al.  Comprehensive analysis of mRNA methylation reveals enrichment in 3′ UTRs
    and near stop codons. Cell 2012;149:1635–46. Google Scholar CrossrefPubMed WorldCat   12.
    Dominissini D, Moshitch-Moshkovitz S, Schwartz S, et al.  Topology of the human
    and mouse m6A RNA methylomes revealed by m6A-seq. Nature 2012;485:201–6. Google
    Scholar CrossrefPubMed WorldCat   13. Dierks D, Garcia-Campos MA, Uzonyi A, et
    al.  Multiplexed profiling facilitates robust m6A quantification at site, gene
    and sample resolution. Nat Methods 2021;18:1060–7. Google Scholar CrossrefPubMed
    WorldCat   14. Linder B, Grozhik AV, Olarerin-George AO, et al.  Single-nucleotide-resolution
    mapping of m6A and m6Am throughout the transcriptome. Nat Methods 2015;12:767–72.
    Google Scholar CrossrefPubMed WorldCat   15. Körtel N, Rücklé C, Zhou Y, et al.  Deep
    and accurate detection of m6A RNA modifications using miCLIP2 and m6Aboost machine
    learning. Nucleic Acids Res 2021;49:e92. https://academic.oup.com/nar/article/49/16/e92/6307904.
    Google Scholar WorldCat   16. Molinie B, Wang J, Lim KS, et al.  m6A-LAIC-seq
    reveals the census and complexity of the m6A epitranscriptome. Nat Methods 2016;13:692–8.
    Google Scholar CrossrefPubMed WorldCat   17. Chen K, Lu Z, Wang X, et al.  High-resolution
    N6 -Methyladenosine (m6a) map using photo-crosslinking-assisted m6a sequencing.
    Angew Chem Int Ed 2015;54:1587–90. Google Scholar Crossref WorldCat   18. Garcia-Campos
    MA, Edelheit S, Toth U, et al.  Deciphering the “m6A code” via antibody-independent
    quantitative profiling. Cell 2019;178:731–747.e16. Google Scholar CrossrefPubMed
    WorldCat   19. Zhang Z, Chen L-Q, Zhao Y-L, et al.  Single-base mapping of m6a
    by an antibody-independent method. Sci Adv 2019;5:eaax0250. Google Scholar CrossrefPubMed
    WorldCat   20. Meyer KD. DART-seq: an antibody-free method for global m6A detection.
    Nat Methods 2019;16:1275–80. Google Scholar CrossrefPubMed WorldCat   21. Wang
    Y, Xiao Y, Dong S, et al.  Antibody-free enzyme-assisted chemical approach for
    detection of N6-methyladenosine. Nat Chem Biol 2020;16:896–903. Google Scholar
    CrossrefPubMed WorldCat   22. Shu X, Cao J, Cheng M, et al.  A metabolic labeling
    method detects m6A transcriptome-wide at single base resolution. Nat Chem Biol
    2020;16:887–95. Google Scholar CrossrefPubMed WorldCat   23. Liu C, Sun H, Yi
    Y, et al.  Absolute quantification of single-base m6A methylation in the mammalian
    transcriptome using GLORI. Nat Biotechnol 2022;41:355–66. Google Scholar CrossrefPubMed
    WorldCat   24. Hu L, Liu S, Peng Y, et al.  m6A RNA modifications are measured
    at single-base resolution across the mammalian transcriptome. Nat Biotechnol 2022;40:1210–9.
    Google Scholar CrossrefPubMed WorldCat   25. Anreiter I, Mir Q, Simpson JT, et
    al.  New twists in detecting mRNA modification dynamics. Trends Biotechnol 2021;39:72–89.
    Google Scholar CrossrefPubMed WorldCat   26. Khoddami V, Yerra A, Mosbruger TL,
    et al.  Transcriptome-wide profiling of multiple RNA modifications simultaneously
    at single-base resolution. Proc Natl Acad Sci U S A 2019;116:6784–9. Google Scholar
    CrossrefPubMed WorldCat   27. Workman RE, Tang AD, Tang PS, et al.  Nanopore native
    RNA sequencing of a human poly(a) transcriptome. Nat Methods 2019;16:1297–305.
    Google Scholar CrossrefPubMed WorldCat   28. Garalde DR, Snell EA, Jachimowicz
    D, et al.  Highly parallel direct RNA sequencing on an array of nanopores. Nat
    Methods 2018;15:201–6. Google Scholar CrossrefPubMed WorldCat   29. Parker MT,
    Knop K, Sherwood AV, et al.  Nanopore direct RNA sequencing maps the complexity
    of Arabidopsis mRNA processing and m6A modification. Elife 2020;9:e49658. https://elifesciences.org/articles/49658/.
    Google Scholar WorldCat   30. Begik O, Mattick JS, Novoa EM. Exploring the epitranscriptome
    by native RNA sequencing. RNA 2022;28:1430–9. Google Scholar CrossrefPubMed WorldCat   31.
    Acera Mateos P, Zhou Y, Zarnack K, Eyras E. Concepts and methods for transcriptome-wide
    prediction of chemical messenger RNA modifications with machine learning. Brief
    Bioinform 2023;24:bbad163. Google Scholar CrossrefPubMed WorldCat   32. Wan YK,
    Hendra C, Pratanwanich PN, Göke J. Beyond sequencing: machine learning algorithms
    extract biology hidden in Nanopore signal data. Trends Genet 2022;38:246–57. Google
    Scholar CrossrefPubMed WorldCat   33. Furlan M, Delgado-Tejedor A, Mulroney L,
    et al.  Computational methods for RNA modification detection from nanopore direct
    RNA sequencing data. RNA Biol 2021;18:31–40. Google Scholar CrossrefPubMed WorldCat   34.
    Zhong Z-D, Xie Y-Y, Chen H-X, et al.  Systematic comparison of tools used for
    m6A mapping from nanopore direct RNA sequencing. Nat Commun 2023;14:1906. Google
    Scholar CrossrefPubMed WorldCat   35. Di Tommaso P, Chatzou M, Floden EW, et al.  Nextflow
    enables reproducible computational workflows. Nat Biotechnol 2017;35:316–9. Google
    Scholar CrossrefPubMed WorldCat   36. Tegowski M, Flamand MN, Meyer KD. scDART-seq
    reveals distinct m6A signatures and mRNA methylation heterogeneity in single cells.
    Mol Cell 2022;82:868–878.e10. Google Scholar CrossrefPubMed WorldCat   37. Uzonyi
    A, Dierks D, Nir R, et al.  Exclusion of m6A from splice-site proximal regions
    by the exon junction complex dictates m6A topologies and mRNA stability. Mol Cell
    2023;83:237–251.e7. Google Scholar CrossrefPubMed WorldCat   38. Liu H, Begik
    O, Lucas MC, et al.  Accurate detection of m6A RNA modifications in native RNA
    sequences. Nat Commun 2019;10:4079. Google Scholar CrossrefPubMed WorldCat   39.
    Leger A, Amaral PP, Pandolfini L, et al.  RNA modifications detection by comparative
    Nanopore direct RNA sequencing. Nat Commun 2021;12:7198. Google Scholar CrossrefPubMed
    WorldCat   40. Li H. Minimap2: pairwise alignment for nucleotide sequences. Bioinformatics
    2018;34:3094–100. Google Scholar CrossrefPubMed WorldCat   41. Quinlan AR, Hall
    IM. BEDTools: a flexible suite of utilities for comparing genomic features. Bioinformatics
    2010;26:841–2. Google Scholar CrossrefPubMed WorldCat   42. Schwartz S, Agarwala
    SD, Mumbach MR, et al.  High-resolution mapping reveals a conserved, widespread,
    dynamic mRNA methylation program in yeast meiosis. Cell 2013;155:1409–21. Google
    Scholar CrossrefPubMed WorldCat   43. Jenjaroenpun P, Wongsurawat T, Wadley TD,
    et al.  Decoding the epitranscriptional landscape from native RNA sequences. Nucleic
    Acids Res 2021;49:e7–7. Google Scholar CrossrefPubMed WorldCat   44. Loman NJ,
    Quinlan AR. Poretools: a toolkit for analyzing nanopore sequence data. Bioinformatics
    2014;30:3399–401. Google Scholar CrossrefPubMed WorldCat   45. Stoiber M, Quick
    J, Egan R, et al.  De novo identification of DNA modifications enabled by genome-guided
    Nanopore signal processing. bioRxiv 2017;094672. https://www.biorxiv.org/content/10.1101/094672v2.
    46. Loman NJ, Quick J, Simpson JT. A complete bacterial genome assembled de novo
    using only nanopore sequencing data. Nat Methods 2015;12:733–5. Google Scholar
    CrossrefPubMed WorldCat   47. Hendra C, Pratanwanich PN, Wan YK, et al.  Detection
    of m6A from direct RNA sequencing using a multiple instance learning framework.
    Nat Methods 2022;19:1590–8. Google Scholar CrossrefPubMed WorldCat   48. Lorenz
    DA, Sathe S, Einstein JM, Yeo GW. Direct RNA sequencing enables m6A detection
    in endogenous transcript isoforms at base specific resolution. RNA 2019;26:19–28.
    Google Scholar CrossrefPubMed WorldCat   49. Abebe JS, Price AM, Hayer KE, et
    al.  DRUMMER—rapid detection of RNA modifications through comparative nanopore
    sequencing. Bioinformatics 2022;38:3113–5. Google Scholar CrossrefPubMed WorldCat   50.
    Qin H, Ou L, Gao J, et al.  DENA: training an authentic neural network model using
    Nanopore sequencing data of Arabidopsis transcripts for detection and quantification
    of N6-methyladenosine on RNA. Genome Biol 2022;23:25. Google Scholar CrossrefPubMed
    WorldCat   51. Parker MT, Barton GJ, Gordon G. Simpson. Yanocomp: robust prediction
    of m6A modifications in individual nanopore direct RNA reads. bioRxiv 2021.06.15.448494.
    https://www.biorxiv.org/content/10.1101/2021.06.15.448494v1. 52. Pratanwanich
    PN, Yao F, Chen Y, et al.  Identification of differential RNA modifications from
    nanopore direct RNA sequencing with xPore. Nat Biotechnol 2021;39:1394–402. Google
    Scholar CrossrefPubMed WorldCat   53. Gao Y, Liu X, Wu B, et al.  Nanom6A - quantitative
    profiling of N6-methyladenosine at single-base resolution in stem-differentiating
    xylem of Populus trichocarpa using Nanopore direct RNA sequencing. Genome Biol
    2021;22:22. Google Scholar CrossrefPubMed WorldCat   54. Ueda H. nanoDoc: RNA
    modification detection using Nanopore raw reads with deep one-class classification.
    bioRxiv 2020.09.13.295089. https://www.biorxiv.org/content/10.1101/2020.09.13.295089v2.
    55. Grau J, Grosse I, Keilwagen J. PRROC: computing and visualizing precision-recall
    and receiver operating characteristic curves in R. Bioinformatics 2015;31:2595–7.
    Google Scholar CrossrefPubMed WorldCat   56. Boyd K, Eng KH, Page CD. Area under
    the precision-recall curve: point estimates and confidence intervals. Machine
    Learning and Knowledge Discovery in Databases 2013;8190:451–66. Google Scholar
    WorldCat   57. Bailey TL, Johnson J, Grant CE, Noble WS. The MEME suite. Nucleic
    Acids Res 2015;43:W39–49. Google Scholar CrossrefPubMed WorldCat   58. Gruber
    AR, Lorenz R, Bernhart SH, et al.  The Vienna RNA Websuite. Nucleic Acids Res
    2008;36:W70–4. Google Scholar CrossrefPubMed WorldCat   Author notes Simone Maestri,
    Mattia Furlan and Logan Mulroney equally contributed to the work. Francesco Nicassio
    and Mattia Pelizzola equally contributed to the work. © The Author(s) 2024. Published
    by Oxford University Press. This is an Open Access article distributed under the
    terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/),
    which permits unrestricted reuse, distribution, and reproduction in any medium,
    provided the original work is properly cited. Supplementary data Maestri_SupplementaryData_bbae001
    - docx file Advertisement CITATIONS 2 VIEWS 2,834 ALTMETRIC More metrics information
    Email alerts Article activity alert Advance article alerts New issue alert In
    progress issue alert Receive exclusive offers and updates from Oxford Academic
    Recommended Nanopore direct RNA sequencing detects DUX4-activated repeats and
    isoforms in human muscle cells Satomi Mitsuhashi et al., Human Molecular Genetics,
    2021 MeRIPseqPipe: an integrated analysis pipeline for MeRIP-seq data based on
    Nextflow Xiaoqiong Bao et al., Bioinformatics, 2022 Resolving single-cell copy
    number profiling for large datasets Wang Ruohan et al., Briefings in Bioinformatics,
    2022 Psychosocial-Behavioral Phenotyping: A Novel Precision Health Approach to
    Modeling Behavioral, Psychological, and Social Determinants of Health Using Machine
    Learning Marissa Burgermaster et al., Annals of Behavioral Medicine, 2022 Variation
    in type two taste receptor genes is associated with bitter tasting phenylthiocarbamide
    consumption in mature Targhee and Rambouillet rams Kimberly M Davenport et al.,
    Translational Behavioral Medicine, 2021 Multimodal Studies in Hepatitis B Virus
    Associated Hepatocellular Carcinoma Runze Xie et al., Infectious Diseases & Immunity,
    2022 Powered by Citing articles via Google Scholar Latest Most Read Most Cited
    Integrated modeling of protein and RNA ConvNeXt-MHC: improving MHC–peptide affinity
    prediction by structure-derived degenerate coding and the ConvNeXt model Multilevel
    superposition for deciphering the conformational variability of protein ensembles
    PCAO2: an ontology for integration of prostate cancer associated genotypic, phenotypic
    and lifestyle data Graphormer supervised de novo protein design method and function
    validation More from Oxford Academic Bioinformatics and Computational Biology
    Biological Sciences Science and Mathematics Books Journals About Briefings in
    Bioinformatics Editorial Board Author Guidelines Facebook Twitter Purchase Recommend
    to your Library Advertising and Corporate Services Journals Career Network Online
    ISSN 1477-4054 Copyright © 2024 Oxford University Press About Oxford Academic
    Publish journals with us University press partners What we publish New features  Authoring
    Open access Purchasing Institutional account management Rights and permissions
    Get help with access Accessibility Contact us Advertising Media enquiries Oxford
    University Press News Oxford Languages University of Oxford Oxford University
    Press is a department of the University of Oxford. It furthers the University''s
    objective of excellence in research, scholarship, and education by publishing
    worldwide Copyright © 2024 Oxford University Press Cookie settings Cookie policy
    Privacy policy Legal notice Oxford University Press uses cookies to enhance your
    experience on our website. By selecting ‘accept all’ you are agreeing to our use
    of cookies. You can change your cookie settings at any time. More information
    can be found in our Cookie Policy. Cookie settings Accept all"'
  inline_citation: '>'
  journal: Briefings in Bioinformatics
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Benchmarking of computational methods for m6A profiling with Nanopore direct
    RNA sequencing
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Carballo Mato J.
  - González Vázquez S.
  - Fernández Águila J.
  - Delgado Rodríguez Á.
  - Lin X.
  - Garabato Gándara L.
  - Sobreira Seoane J.
  - Silva Castro J.
  citation_count: '0'
  description: The excessive accumulation of foam in wastewater treatment plant (WWTP)
    tanks can impede proper aeration, hindering the effective removal of organic matter
    from the water. This study proposes a novel technique to monitor in real time
    the presence of foams in WWTP tanks by using texture segmentation models trained
    with centralized and federated approaches. These models are designed to segment
    the foam and quantify the percentage of foam coverage across the entire tank surface.
    This data provides plant operators with crucial information for identifying the
    optimal time for foam removal. The proposed methodology is integrated into an
    image processing pipeline that involves acquiring images using a PTZ camera, ensuring
    the absence of anomalies in the captured images, and implementing a real-time
    communication method for event notifications to plant operators. The models exhibit
    noteworthy performance, achieving an 86% Dice score in foam segmentation, with
    comparable results obtained through both centralized and federated training. Implemented
    in a wastewater treatment plant, this integrated pipeline enhances operational
    efficiency while concurrently reducing costs.
  doi: 10.3390/w16030390
  full_citation: '>'
  full_text: '>

    "This website uses cookies We use cookies to personalise content and ads, to provide
    social media features and to analyse our traffic. We also share information about
    your use of our site with our social media, advertising and analytics partners
    who may combine it with other information that you’ve provided to them or that
    they’ve collected from your use of their services. Consent Selection Necessary
    Preferences Statistics Marketing Show details                 Deny Allow selection
    Allow all   Journals Topics Information Author Services Initiatives About Sign
    In / Sign Up Submit   Search for Articles: Water All Article Types Advanced   Journals
    Water Volume 16 Issue 3 10.3390/w16030390 Submit to this Journal Review for this
    Journal Propose a Special Issue Article Menu Academic Editor Min Ji Subscribe
    SciFeed Recommended Articles Related Info Link More by Authors Links Article Views
    730 Table of Contents Abstract Introduction Materials and Methods Results Discussion
    Author Contributions Funding Data Availability Statement Conflicts of Interest
    Abbreviations References Altmetric share Share announcement Help format_quote
    Cite question_answer Discuss in SciProfiles thumb_up Endorse textsms Comment first_page
    settings Order Article Reprints Open AccessArticle Foam Segmentation in Wastewater
    Treatment Plants by Joaquín Carballo Mato *, Sonia González Vázquez *, Jesús Fernández
    Águila , Ángel Delgado Rodríguez , Xin Lin , Lucía Garabato Gándara , Juan Sobreira
    Seoane and Jose Silva Castro Instituto Tecnológico de Galicia, Cantón Grande 9,
    Planta 3, 15003 A Coruña, Spain * Authors to whom correspondence should be addressed.
    Water 2024, 16(3), 390; https://doi.org/10.3390/w16030390 Submission received:
    4 December 2023 / Revised: 15 January 2024 / Accepted: 18 January 2024 / Published:
    24 January 2024 Download keyboard_arrow_down     Browse Figures Versions Notes
    Abstract The excessive accumulation of foam in wastewater treatment plant (WWTP)
    tanks can impede proper aeration, hindering the effective removal of organic matter
    from the water. This study proposes a novel technique to monitor in real time
    the presence of foams in WWTP tanks by using texture segmentation models trained
    with centralized and federated approaches. These models are designed to segment
    the foam and quantify the percentage of foam coverage across the entire tank surface.
    This data provides plant operators with crucial information for identifying the
    optimal time for foam removal. The proposed methodology is integrated into an
    image processing pipeline that involves acquiring images using a PTZ camera, ensuring
    the absence of anomalies in the captured images, and implementing a real-time
    communication method for event notifications to plant operators. The models exhibit
    noteworthy performance, achieving an 86% Dice score in foam segmentation, with
    comparable results obtained through both centralized and federated training. Implemented
    in a wastewater treatment plant, this integrated pipeline enhances operational
    efficiency while concurrently reducing costs. Keywords: waste water treatment
    plants; semantic segmentation; federated learning; Deeplabv3+; One Shot Texture
    Segmentation; SDG6 1. Introduction Texture segmentation plays an important part
    in image analysis and understanding. Basically, it involves the identification
    of regions with the same texture features, so that further analysis can be performed
    on the respective regions alone. An effective segmentation algorithm is very useful
    in many areas, such as industrial monitoring of product quality, medical image
    analysis, or image retrieval. This paper focuses on the analysis of images obtained
    from wastewater treatment plants. In these plants, various processes are carried
    out to facilitate the removal of organic matter, nitrification, denitrification
    of the influent, as well as the removal of suspended solids. In the case of plants
    such as the ones used in this research, the removal of organic matter and nitrogen
    in the MBBR (Moving Bed Biofilm Reactor) [1] is achieved through a biological
    treatment using AnoxKaldnes technology. AnoxKaldnes™ technology is based on the
    growth of biomass (in the form of a biofilm) on continuously moving plastic media
    in the biological reactor. These media are small in size but have a high specific
    surface area per unit volume, allowing for a high level of contact between the
    wastewater and the biofilm, thus allowing the biofilm to consume the organic matter
    of the wastewater. In the event of any abnormal chemical spills in water, aeration
    issues or the accumulation of suspended solids, large foams can be formed in the
    tanks of biological treatments [2]. The foams have to be removed because they
    can cover the tanks causing serious operational problems and preventing proper
    aeration. Currently, this activity is done manually in the wastewater treatment
    plant considered in this research, leaving aside any metric that indicates the
    most appropriate time when defoamers should be used. Foam analysis has traditionally
    been performed in a manual manner in different domains of study. However, manual
    measurement of some foam and liquid properties can be time-consuming, and certain
    important geometric and dynamic measures are difficult or impossible to quantify
    using manual methods. In the work by Collivignarelli et al. [2], two on-site foam
    measurement methods, namely Foam Surface Covered (FSC) and Foam Volume (FV), were
    described. It is important to note that these methods come with certain limitations,
    such as the requirement for the camera to be positioned orthogonally to the tank
    or the necessity of employing devices such as hydrometers to calculate the foam
    volume. In the study by Wang et al. [3], a method based on texture analysis was
    proposed to effectively segment liquid from foam. Additionally, the approach aims
    to identify the boundaries of individual bubbles within the foam layer. Furthermore,
    alternative techniques for foam segmentation based on the watershed method were
    explored in Refs. [4,5]. Forbes and de Jager [4] presented a novel approach that
    combines a texture measure with two stages of watershed. This method has been
    demonstrated to facilitate the segmentation of images containing both large and
    small bubbles. In the context of Ref. [5], various implementations of the watershed
    method are presented for both semantic and instance segmentation. However, it
    is important to note that these papers primarily concentrate on foams formed by
    relatively large bubbles, which differ from the characteristics of the foams observed
    in the wastewater treatment plant tanks that will be the focus of our investigation.
    In Ref. [6], an image processing method is presented for quantifying foam coverage
    across the entire surface of tanks in sewage plants. However, the paper notes
    that the effectiveness of this method may be influenced by complex environmental
    factors. Given the limitations observed in classical methods documented in the
    literature, it was opted for the application of deep learning methods due to their
    versatility in handling images with diverse characteristics. To the best of our
    knowledge, there are currently no deep learning algorithms specifically tailored
    for foam segmentation. Therefore, the decision was made to employ models created
    to solve a similar problem, specifically, texture segmentation. Various deep learning
    algorithms for segmenting and classifying textures in different domains are documented
    in the literature. Typically, these models utilize classic Convolutional Neural
    Networks (CNN) for image segmentation to extract characteristic textures. For
    instance, in Ref. [7], diverse deep learning models, such as AlexNet, VGG16, or
    ResNet34, are utilized to identify various diseases in tomato leaves. The prompt
    identification and timely treatment of these diseases can mitigate potential losses
    in tomato production. Similarly, in Ref. [8], convolutional neural networks are
    applied to segment breast density in mammographic imaging. This way, in Ref. [9],
    an energy efficient system based on deep convolutional neural networks for early
    smoke detection in both normal and foggy environments is created. The proposed
    architecture is a VGG-16 pre-trained in Imagenet. Moreover, this model is fine-tuned
    in a new dataset, created by the authors of the paper, consisting of 72,012 images
    from 4 different classes: nonsmoke, smoke, nonsmoke with fog, and smoke with fog.
    In 2021, a new work was published [10], where they present a CNN-based smoke detection
    and segmentation framework for both clear and hazy environments. Regarding the
    detection an EfficientNet architecture is introduced, which outperforms the results
    acquired in Ref. [9]. Concerning the semantic segmentation of the smoke regions,
    a DeepLabv3+ model is used. The classification and segmentation models are tested
    on the dataset presented in Ref. [9], obtaining better metrics than previous models.
    Finally, in Ref. [11] a highly adaptable model was introduced for texture segmentation,
    namely One Shot Texture Segmentation (OSTS), which does not require fine-tuning
    on specific problems or a large amount of annotated data for training. The key
    feature of the proposed architecture is the utilization of two input images: the
    image to be segmented and an image of the desired texture to be segmented. Additionally,
    this model is trained on a novel dataset named CollTex, created from texture images
    sourced from the Describable Texture Data (DTD) (https://www.robots.ox.ac.uk/~vgg/data/dtd/
    (accessed on 2 December 2022)). The achieved results surpass 90% accuracy on images
    composed of two textures. Recognizing potential challenges in acquiring a sufficient
    quantity of images with adequate variability from individual wastewater treatment
    plant, the feasibility of employing federated learning instead of a centralized
    approach was explored to keep data privacy and increase communication efficiency
    [12]. An analysis of different aggregation methods and major libraries was conducted,
    examining their functionality, advantages, and disadvantages. The most commonly
    used aggregation method is FedAvg (Federated Averaging), which involves alternatively
    selecting a subset of client nodes in each iteration and applying a weighted average
    of the local models to update the global model. Another prominent method is FedSGD
    (Federated Stochastic Gradient Descent), which averages the gradients in each
    round. As for the main frameworks or libraries, Flower (https://flower.dev (accessed
    on 7 November 2022)), NVIDIA Flare (https://developer.nvidia.com/flare (accessed
    on 9 November 2022)), TensorFlow Federated (https://www.tensorflow.org/federated
    (accessed on 8 November 2022)), and IBM Federated Learning Framework (https://www.ibm.com/docs/en/cloud-paks/cp-data/4.7.x?topic=models-federated-learning
    (accessed on 8 November 2022)) stand out. These libraries, except for NVFlare,
    are known for their user-friendly nature, making them highly attractive tools
    for research purposes. However, their commercial use is limited due to the lack
    of security they provide. NVFlare, on the other hand, is specifically designed
    for developing commercial products and addresses these security concerns. The
    fundamental purpose of this initiative is to achieve a more efficient management
    of the WWTP. Therefore, our main contributions are the following: Implement innovative
    solutions with the aim of reducing costs and improving efficiency. To do so, we
    introduced a computer vision system that enables real-time monitoring of foam
    parameters, ensuring timely and accurate treatment interventions; Comparison between
    centralized and federated data treatment. To achieve the objectives, two foam
    segmentation models, DeepLabv3+ [10] and OSTS [11], have been implemented and
    trained using images from a real WWTP. The former was selected due to the power
    of DeepLabv3+ segmenting smoke and the similarity between smoke and foam. The
    latter will contribute with its capacity to get good performance on small training
    datasets. The foam percentage on the tank surface can be calculated from the segmented
    foam. This is crucial for determining the appropriate time to remove excess of
    foam, therefore enhancing the response speed to foam accumulations. Moreover,
    the foam segmentation methodology is part of a complete computer vision pipeline
    that includes image capture, the selection of the suitable images for further
    processing, and the transmission of operationally significant data to the responsible
    personnel at the WWTP. Regarding federated learning, the possibility of working
    with multiple clients has been explored in order to create a flexible model that
    works in different environments maintaining the privacy of each client’s data
    and reducing data communications compared to centralized training. This study
    surpasses prior research by leveraging powerful and highly flexible models, utilizing
    datasets composed of a large number of images with diverse characteristics, and
    offering a complete remote sensing system based on image analysis to monitor foam
    coverage on WWTP tanks, which ranges from the automatic and periodic image capturing
    process to the sending of alerts to WWTP operators. The rest of this work is organized
    as follows. Section 2 provides the datasets that are used throughout the work
    and describes the proposed methodology. The experimental evaluations and the characteristics
    of the deployment are described in Section 3. Finally, this work is concluded
    in Section 4 with the key findings and future directions. 2. Materials and Methods
    2.1. Datasets In response to the unavailability of publicly accessible datasets
    of foams and the encountered delays in procuring images from the wastewater treatment
    plant where the investigation was conducted, the project was developed in three
    stages. In the first stage, public datasets of other domains were used. The first
    dataset, named DeepSmoke dataset, is described in Ref. [10]. It comprises 18,532
    smoke images, 18,532 foggy images with smoke, 17,474 smoke-free images, and 17,474
    foggy images without smoke. One image with smoke and one image with smoke and
    fog are shown in Figure 1. The use of this dataset is due to the similarity between
    smoke and foam textures. Figure 1. Images from DeepSmoke dataset: (a) Image with
    smoke. (b) Image with smoke and fog. The second dataset [11], named CollTex, is
    composed of collages formed with textures (Figure 2). Figure 2. Two images from
    OSTS dataset. However, since the problem is the segmentation of foam, and in order
    to make the dataset resemble the images that will be captured from the tanks of
    the WWTP as closely as possible, the dataset was slightly modified in order to
    create images with only two randomly distributed textures throughout the image.
    To create these new collages, 50 random centroids were selected in the image and
    we associated each of these points with one of the two arbitrarily chosen textures.
    Subsequently, the remaining points were assigned to the nearest centroid (Figure
    3). Figure 3. Adaptation of the OSTS dataset to generate a collage with only two
    textures: Given two textures from the original dataset represented on (a,b); the
    new collage (c) is formed by selecting 50 random centroids and associating each
    centroid to one of the textures. In the second stage of the project, since a camera
    had not yet been fixed in the WWTP, a series of images were manually captured
    at the WWTP. We will refer to this dataset as “Manual Dataset”. These images were
    captured using a PTZ camera (Hanwhavision XNP-8250: https://hanwhavision.eu/es/producto/xnp-8250/
    (accessed on 5 October 2022)) over a specific day, for an hour, and under particular
    lighting conditions. In particular, 383 images of size 3328 × 1872 were captured
    from a unique tank from 12 a.m. to 1 p.m. Figure 4 shows some of the captured
    images. Figure 4. Two images included on manual dataset. In the third stage of
    the project, a set of 5 images every 10 min were captured, with the same PTZ camera
    used to generate the manual dataset, in 2 tanks of the WWTP with a resolution
    of 1920 × 1080 from 7 a.m. to 8 p.m. from February to May. We will refer to this
    dataset as the “Final Dataset”. Figure 5 shows two views taken with the PTZ camera
    installed in the plant, each centered on one of the two tanks considered in this
    dataset. Figure 5. Tanks of the WWTP used in the research: (a) Tank 1. (b) Tank
    2. There are two differences between the images of the manual and final datasets.
    The first difference is the variability in lighting conditions throughout the
    day. This resulted in images with different colors, shadows, varying levels of
    darkness, or images that change depending on the weather conditions. The second
    difference is the resolution due to storage limitations. Nevertheless, the structure
    of the foam texture is clearly seen in both types of images. Figure 6 shows an
    example of images captured at different times on 4 March 2023, showcasing the
    variations in lighting conditions and visual appearance. Figure 6. Images from
    final dataset: (a) Image captured at 8 a.m. (b) Image captured at 10 a.m. (c)
    Image captures at 12 a.m. (d) Image captured at 8:45 p.m. 2.2. Labeling As the
    segmentation models used in this work are supervised models, it is necessary to
    have the ground truth segmentation of the images. To simplify the annotation process
    of the manual dataset, an image processing algorithm was developed in order to
    generate the initial masks to be used in the training. The steps involved, as
    shown in Figure 7, are as follows: Figure 7. Labelling process to get the ground
    truth mask of images from the manual dataset: (a) Original image. (b) Step 1:
    Homography. (c) Step 2: H channel of the homography image in HSV. (d) Step 3:
    Thresholding of the step 2 image. (e) Step 4: Application of the step 3 mask to
    the step 1 image in greyscale. (f) Step 5: Adaptive thresholding of the step 4
    image. (g) Step 6: Opening + closing of the step 5 image. (h) Step 7: Mask refined
    by an expert. (1) A homography transform was applied to focus on the relevant
    part of the image; (2) The image was converted from RGB to HSV, and the first
    channel, which defines the hue of the image, was extracted; (3) An Otsu’s thresholding
    method was applied to retain only the areas of the image where plastic supports
    were not present; (4) The original image was converted to greyscale and masked
    using the result obtained in step 3; (5) Adaptive thresholding was applied to
    the resulting image from step 4. This method performs thresholding considering
    a small number of neighbouring pixels. Adaptive thresholding avoids issues that
    may arise from global thresholding in images with shadows or varying colour intensities
    across different areas of the image; (6) To refine the mask, two morphological
    operations, opening and closing, were performed. These operations aim to eliminate
    spurious pixels. Finally, the masks were sent to experts for further refinement.
    The algorithm previously presented for mask creation cannot be directly applied
    to the images from the final dataset because it was specifically designed for
    images captured under certain lighting conditions. The new algorithm involves
    directly applying adaptive thresholding, followed by opening and closing operations
    to remove spurious pixels and refine the masks. Figure 8 shows an example of an
    image with and without shadows and its corresponding mask calculated using the
    new algorithm. This demonstrates that the algorithm performs sufficiently well
    under different lighting variations. Figure 8. Labelling process to get the ground
    truth mask of images from the final dataset: (a) Two homographies of images with
    and without shadows. (b) Initial segmentation masks of both images. (c) Masks
    of both images refined by an expert. 2.3. Architecture of Models To address the
    foam segmentation problem, two deep learning models have been analysed. The use
    of these models is due to their power segmenting similar images to the ones from
    the WWTP and their capacity working with small texture datasets. 2.3.1. One Shot
    Texture Segmentation This model, presented in Ref. [11], is based on obtaining
    a numerical representation of the image to be segmented and the reference texture
    (the texture to segment in the image), and subsequently comparing which parts
    of the image contain the reference texture. The main advantage of OSTS with respect
    to other models is the use of two input images, the collage to be segmented, and
    the reference texture to segment, which enables the model to achieve better texture
    segmentation. In addition, OSTS is well known by its power to work well with small
    datasets. The architecture of the model, presented in the Figure 9, is divided
    in four parts: Figure 9. Architecture of the model OSTS. Source: Ref. [11]. (A)
    The first part consists of a VGG architecture, which aims to obtain a numerical
    representation of both the image to be segmented and the reference texture; (B)
    The second part is an encoder, designed to ensure that the numerical representation
    obtained in step A has the same size as the original image. This way, the feature
    vector at each spatial position can be considered as a representation of the texture
    at that position; (C) In the third part, the numerical representations of the
    image and reference texture are compared to determine which parts of the image
    contain the reference texture. The result is an image of the same size as the
    original image, highlighting the positions with a texture similar to the reference
    texture; (D) Finally, a decoder is employed to refine the segmentation. 2.3.2.
    DeepLabv3+ In Ref. [10], the DeepLabv3+ architecture (Figure 10) is employed to
    address the smoke segmentation problem. This model is based on an encoder-decoder
    architecture and its main feature is the use of atrous convolutions at different
    scales. Atrous convolutions are crucial as they reduce the number of parameters
    in the filters while increasing the receptive field. Additionally, due to the
    model’s flexibility, various encoders can be used. As shown in the results section,
    in this work the following encoders have been tested: Figure 10. Architecture
    of the model DeepLabv3+. Source: Ref. [10]. MobiletNet [13]: a lightweight network
    designed for efficient inference on mobile devices; ResNet [14]: Residual Neural
    Network, which introduces skip connections to overcome the vanishing gradient
    problem; HRNet [15]: a deep learning model that addresses the limitations of traditional
    convolutional neural networks by simultaneously maintaining high-resolution representations
    at different scales. The flexibility of the model, together with the reduced number
    of parameters due to the use of atrous convolutions, makes this architecture outperform
    previous convolutional models. 2.4. Federated Learning Federated Learning (FL)
    emerges with the objective of training a machine learning model on multiple local
    datasets stored on decentralized peripheral devices without exchanging data samples.
    In this privacy-preserving approach, a server typically receives parameters (e.g.,
    gradients or neural network weights) from locally trained models on decentralized
    peripheral devices and averages these parameters to construct a global model.
    Subsequently, the averaged parameters of the global model are sent back to the
    peripheral devices to update their local models. This process is repeated until
    the global model converges or a stopping condition is met. In this research project,
    the FedAvg (Federated Averaging) algorithm has been chosen as the aggregation
    method for parameter averaging. In Figure 11 it is graphically explained how a
    federated architecture works when having two nodes. Figure 11. Architecture of
    federated learning. The application of federated learning in foam segmentation
    of WWTPs tanks enables the utilization of images from diverse WWTPs. This allows
    for a larger number of images, encompassing varying lighting conditions and shadows,
    thereby enhancing the robustness of the trained models. In this research, the
    training has been conducted on two tanks of the same WWTP as if they were two
    separate WWTPs. This approach was adopted due to the impossibility of involving
    another WWTP using the same biological treatment method in the project. 2.5. Implementation
    Details Regarding the models, their implementation was performed using Python
    3.8 as the programming language and PyTorch 1.12.1 as the deep learning framework.
    Moreover, the training of the models was conducted on a server equipped with an
    NVIDIA RTX A6000 GPU. Furthermore, NVIDIA Flare has been selected as the library
    for federated learning. This choice is based on its design for developing commercial
    software, ensuring strong security in the communications between the server and
    clients. 3. Results In this section, the results obtained from various experiments
    conducted are described. First, the outcomes of the model training phase employing
    publicly available texture datasets are delineated. Subsequent to this, the pretrained
    models derived from the aforementioned step are retrained using the manual dataset.
    Then, the training results obtained using the final dataset are summarized. Lastly,
    an exhaustive comparison between the two evaluated training paradigms, namely
    centralized and federated, is expounded upon. Regarding the evaluation metrics,
    Dice and IoU scores are utilized to assess the performance: IoU is the area of
    overlap between the predicted segmentation and the ground truth divided by the
    area of union between the predicted segmentation and the ground truth. This metric
    ranges from 0 to 1 (0–100%) with 0 signifying no overlap and 1 meaning perfectly
    overlapping segmentation; The Dice metric is defined as twice the Area of Overlap
    divided by the total number of pixels in both images. It is a metric equivalent
    to the F1-score in classification problem, so it balances the precision and the
    recall. Both metrics presented are positively correlated, so if classifier A is
    better than B under one metric, it is also better than classifier B under the
    other metric. However, the difference between the two metrics is that the IoU
    penalizes under -and over- segmentation more than Dice. 3.1. Training with Public
    Texture Datasets Since the manual dataset is formed by a limited number of images
    with little variation in terms of lighting conditions, firstly the models were
    trained using public datasets to further perform transfer learning to the manual
    dataset. 3.1.1. OSTS The model OSTS was trained using 2000 images of collages
    as presented in Figure 3, where 1500 form the train set, 250 were used for validation,
    and 250 for testing. Regarding the training parameters, the model was trained
    for 29 epochs, which took approximately 1 h and 15 min. The metrics on the test
    set are shown in Table 1. In addition to the metrics, Figure 12 presents the segmentation
    results for three images from the test set. Figure 12. Results of the model OSTS
    in CollTex dataset. The first column corresponds to the image to be segmented,
    the second column displays the reference textures to be segmented, the third column
    shows the mask, the fourth column represents the texture segmentation, and the
    last column shows the intersection (AND) between the segmentation and the original
    image. Table 1. Metrics of OSTS in the modified public dataset CollTex. 3.1.2.
    Deeplabv3+ The DeepLabv3+ model was trained using 395 images of size 128 × 128
    from the DeepSmoke dataset presented in Ref. [10]. Out of these images, 75% were
    used for training, while the remaining 25% were divided between validation and
    testing. The model underwent 38 epochs of training, which lasted approximately
    11 min. This model allows the use of different encoders. In order to find the
    model that provides the best results, the metrics on the test set were compared
    using MobileNet, ResNet50, and HRNetv2-32 as encoders (Table 2). Although the
    metrics for the different models are similar, ResNet50 was chosen as the encoder
    due to its simplicity. Table 2. Metrics of DeepLabv3+ using different encoders
    in the public dataset DeepSmoke. Figure 13 displays the segmentation results on
    the test set using this model. Figure 13. Results of the model DeepLabv3+ in the
    DeepSmoke dataset. The first column corresponds to the image to be segmented,
    the second column represents the mask, the third column shows the model’s prediction,
    and the fourth column displays the overlay of the original image and the model’s
    prediction. 3.2. Transfer Learning to Manual Dataset Both the OSTS and DeepLabv3+
    models were retrained with the manual dataset. The results obtained in the test
    set are shown in Table 3. Table 3. Metrics of OSTS and DeepLabv3+ applying transfer
    learning in the manual dataset. The segmentation results for three different images
    are shown for both the OSTS and DeepLabv3+ models (Figure 14). These results show
    good metrics for both models, DeepLabv3+ achieving relatively better results in
    either IoU and Dice. Moreover, although metrics can be improved, qualitative results
    are fairly good since it is very difficult to decide what is or is not foam. Figure
    14. Resulting images after applying transfer learning in the manual dataset: (a)
    Results after applying OSTS model. (b) Results after applying Deeplabv3+ model.
    3.3. Training with the Final Dataset The installation of the PTZ camera at the
    WWTP made it possible to capture a sufficient number of images to train the models
    without the need for transfer learning. Additionally, the variability in lighting
    conditions (Figure 6) throughout the day allows for training a robust model capable
    of handling changes in image brightness. Having such diverse images (with varying
    lighting, shadows, and different weather conditions such as rain or wind) enables
    the construction of a more flexible model. However, it also poses challenges in
    creating a more powerful predictive model. To train the best predictive model,
    images from both tanks of the WWTP were utilized. Specifically, the training process
    involved 2000 images from each tank, with 1500 images used for training, 250 for
    validation, and 56 for testing. Regarding the model, DeepLabv3+ was chosen. This
    decision was made because, although the OSTS model is also suitable for segmenting
    images without variations in lighting conditions, the challenge of selecting a
    valid reference texture for all types of images makes it less effective for the
    entire image set. Table 4 and Figure 15a display the metric results obtained by
    DeepLabv3+ in the test set, as well as the application of the trained model to
    three images from the test set, respectively. The obtained metrics are good, but
    the variability of lighting conditions in the image dataset achieved higher scores.
    Moreover, it is important to point out that the differences between IoU and Dice
    metric in the final dataset is lower than when doing transfer learning. This is
    due to the fact that when doing transfer learning, more instances of bad segmentation
    appear and IoU tends to penalize this cases. Furthermore, it can be observed in
    the test set images that it is not always clear what is and what is not foam,
    which in general makes this segmentation problem difficult to solve. Figure 15.
    Resulting images of training with the full dataset: (a) Results of the centralized
    training. (b) Results of the federated training. Table 4. Metrics of DeepLabv3+
    in the final dataset. Comparison between metrics in centralized and federated
    training. 3.4. Federated Training Regarding the model parameters, two clients
    were selected, each containing the data from one of the tanks in the WWTP. In
    this case, similar to centralized training, each client was trained with 2000
    images. As shown in Table 4, the results are similar to those obtained in centralized
    training. This closeness can be attributed to the similarity of the datasets from
    both clients. Results of the application of the federated model to the final dataset
    can be seen in Figure 15b. The parameters used in the different training processes
    are as follows: an image size of 128 × 128, a training of 200 epochs with early
    stopping of 10 epochs without improving the validation loss, a learning rate of
    0.001 with step size of 0.1 each 20 epochs, a batch size of 32, and Adam as optimizer.
    3.5. Deployment The deployment process was conducted on a server equipped with
    an NVIDIA GeForce RTX 3060 GPU. It consisted of four steps: image capture, validation
    of captured images for correctness or anomalies, prediction of the percentage
    of foam over the total surface area of each tank, and sending the data and images
    to the event server to store and monitor the foam measurement in the tanks and
    notify the WWTP operator in case the amount of foam exceeds a certain threshold
    (Figure 16). Figure 16. Steps in the deployment of the project. 3.5.1. Capture
    of Images The image capture process is set to acquire 5 images from each tank
    of the WWTP every 10 min. The captured images are stored in a MinIO (https://min.io/
    (accessed on 17 January 2023)) bucket for further processing by the vision algorithms.
    The acquisition time for 5 images from each of the 2 camera positions capturing
    each tank is 24 s. 3.5.2. Image Validation against Anomalies Method The purpose
    of introducing anomaly detection algorithms in the preprocessing stage is to identify
    images that do not correspond to the expected reality. This can be due to problems
    with the position of the PTZ camera, the presence of unexpected elements nearby
    tanks, such as people or seagulls, and cyberattacks. Three types of checks are
    performed to determine if an image is anomalous or not: (i) An image is considered
    anomalous if its size differs from the defined one; (ii) An image is considered
    anomalous if it is exactly the same as the previous image. To verify if two images
    are exactly the same, the Mean Square Error (MSE) between them is calculated.
    A value of zero indicates that the images are exactly identical. This method helps
    detect possible “man-in-the-middle” attacks that provide fake images through loops
    or repetitions; (iii) An image is considered anomalous based on similarity if
    its similarity percentage with a reference image falls below a threshold. To further
    understand the possible anomalies, a more in-depth explanation of the checks is
    provided. The first two checks are straightforward. In case of the third, given
    a non-anomalous reference image, four areas or patches have been selected as reference
    zones (marked with a green rectangle in Figure 17). Then, to check if an image
    is anomalous based on similarity, the Learned Perceptual Image Patch Similarity
    (LPIPS [16]) is calculated between the reference areas of the reference image
    and the reference areas of the newly captured image. What LPIPS does is to calculate
    the similarity between the activations of two image patches given a predefined
    neural network. One advantage of this measure is that it has been shown to align
    well with human perception. In this case, a VGG neural network is used as the
    reference network. Moreover, in order to make the method robust to certain occlusions,
    only the top 3 patches with the highest similarity to the patches of the reference
    image are considered. Figure 17. Image of the WWTP showing the patches used for
    anomalous image detection (marked in green). Regarding the algorithm for detecting
    anomalies, it is based on comparing the newly captured image from the PTZ camera
    with a reference image. The reference image is set as the first image captured
    on the previous day. Subsequently, if the first image captured today matches the
    reference image, it becomes the new reference image. The second image captured
    today is compared to the first image of the day, provided that it was classified
    as correct. If the second image of the day is also deemed correct, it becomes
    the new reference image, and so on. If an image capture is detected as anomalous,
    it is not selected as the new reference image, and the last image detected as
    correct remains the reference. The objective of this process is to compare a new
    image with the most recent reference image to mitigate the influence of lighting
    changes. Validation In order to validate the method, a dataset consisting of 47
    images, including both correct and anomalous images, has been created. The anomalous
    images encompass variations in size, repeated images, and discrepancies in similarity
    compared to the reference image patches. Since the first two cases are trivial,
    the focus will be on the anomalous images based on their similarity to a reference
    image. Thus, several investigated cases are presented as examples: (i) Changes
    in the camera parameters: the reference image was captured with the following
    camera parameters: pan is set to 281, tilt to 9.81, and zoom to 2.2 (Figure 17).
    To simulate different anomalous images, the images were captured with varying
    parameter values. For the pan parameter, images were captured in the range 277–285.
    Regarding tilt, the dataset contains images from tilt equals to 5.81 to tilt equals
    to 13.81. As for the zoom parameter, images range from zoom equal to 1.3 to zoom
    equal to 3.2. Some examples are shown in Figure 18, with the differing parameter
    value highlighted in bold; Figure 18. Anomalous images by the position of the
    camera: (a) Image with parameter pan = 282, tilt = 9.81 and zoom = 2.2. (b) Image
    with parameter pan = 280, tilt = 9.81 and zoom = 2.2. (c) Image with parameter
    pan = 281, tilt = 10.81 and zoom = 2.2. (d) Image with parameter pan = 281, tilt
    = 8.81 and zoom = 2.2. (e) Image with parameter pan = 281, tilt = 9.81 and zoom
    = 2.7. (f) Image with parameter pan = 281, tilt = 9.81 and zoom = 1.7. (ii) Occlusions
    in the received images: to validate the algorithm’s robustness against certain
    occlusions, we will refer to Figure 19a, where one of the patches is occluded
    by a bird. Since the method considers only the top 3 patches with the highest
    similarity to a reference image, the occlusion of a patch will not affect the
    accurate prediction of an image as anomalous or non-anomalous; Figure 19. Other
    anomalous image: (a) Image with occlusion. (b) Image of a wrong scenario. (iii)
    Images completely different from the expected ones: to validate this point, a
    completely different image from the expected ones, presented in Figure 19b, was
    introduced, which was detected as anomalous by the applied method. Once the LPIPS
    values were calculated for the validation image set, a threshold of 0.3 was set
    to classify an image as anomalous or non-anomalous. By using this threshold, all
    images in the validation set were correctly classified as either anomalous or
    non-anomalous. 3.5.3. Inference Once the images are captured and verified to be
    correct, the segmentation process is performed using the corresponding model.
    The resulting output includes the segmented image, the original image, and the
    foam percentage over the total surface area of the tank. Figure 20 displays the
    segmentation results for images captured under different atmospheric conditions,
    showcasing the model’s effectiveness in each case. Figure 20. Original images
    with the percentage of foam superimposed and segmented images: (a) Image with
    a lot of foam. (b) Image with little foam. (c) Image raining. (d) Image with shadow.
    The time required for the anomaly detection and performing inference is 17 s for
    every set of 5 images. 3.5.4. Data Submission to the Event-Server The Event-Server,
    or event consumer, serves as a global repository for storing images and alphanumeric
    values resulting from the application of various AI models. Additionally, the
    Event-Server is capable of processing these events to generate, record, and send
    notifications to end users if the event inferred meets the established criteria
    based on user-defined parameters for a relevant event. Regarding anomalies, three
    types of events are being sent based on the detected anomaly: repeated image,
    incorrect image size, and incorrect camera position or erroneous image. As for
    inference, an event is sent to record and track the segmentation results, including
    the following information: (i) The original image with the overlaid segmentation
    percentage (Figure 20, left); (ii) The resulting image obtained by performing
    an AND operation between the original image after applying homography and the
    foam segmentation result (Figure 20, right); (iii) A numeric value representing
    the percentage of the tank occupied by foam. Additionally, an alert has been set
    up in the Event Server based on the foam percentage value. This alert triggers
    a notification to the designated person when the foam percentage exceeds a predefined
    threshold specified in the alert. 4. Discussion The calculation of foam percentage
    on the total surface area of a WWTP tank using computer vision algorithms can
    become a highly complex problem. This work presented a complete remote sensing
    system based on imagen analysis to segment foams and monitor in real time the
    amount of foam in WWTP tanks. The developed segmentation models have been applied
    and validated in tanks of a biological reactor of a wastewater treatment plant
    with an MBBR (Moving Bed Biofilm Reactor) system. Due to the lack of a large set
    of tank images in the early stages of the research, the segmentation models have
    been trained on large public datasets used in similar segmentation applications
    and then retrained on the small foam dataset. In a later stage, the dataset collected
    at the plant was large enough to train the models from scratch using only foam
    images. Additionally, the research carried out a comparison between two types
    of training: centralized and federated. The proposed methodology involves a complete
    computer vision pipeline that includes automatic image capture, ensuring the absence
    of anomalies in the captured images, image processing to segment foams and quantify
    the foam percentage of the total surface area of a tank, and the transmission
    of operationally significant data to the responsible personnel at the WWTP to
    support the foam removal at the right time. Regarding limitations, managing lighting
    variations emerged as a primary challenge in achieving superior metrics. Additionally,
    accurately defining what is foam on the tank surface presented another notable
    limitation. In this research, two texture segmentation models applied to foam
    segmentation are presented, yielding results surpassing 85% in the Dice metric
    and 75% in IoU. Furthermore, the percentage of foam on each tank calculated with
    the models has been validated by experts from the wastewater treatment plant using
    different images, thus verifying the proper functioning of the model. The experts’
    confidence implies that the system developed in this research is ready to be used
    in new WWTPs. The comparison between centralized and federated training yielded
    similar results as both clients in the federated training have used images from
    the same WWTP. Nevertheless, the conducted research has allowed for the validation
    of the federated architecture. Consequently, it can be extrapolated for future
    use in different wastewater treatment stations. Furthermore, the methodology explained
    in this paper has already been integrated into a real WWTP for their use, obtaining
    the following benefits: Reduction of maintenance requirements; Prevention of oxygen
    transfer issues; Avoidance of biomass washout; Enhanced monitoring and control;
    Avoid odour problems; Energy savings; Mitigation of risks accidents. Moreover,
    due to the fact that foam formation can also commonly occur in other types of
    WWTPs reactors and processes, it is important to note that the technology presented
    can be implemented in plants using other biological treatments such as in Activated
    Sludge Processes, Anaerobic Reactors, or Sedimentation Tanks. However, such applicability
    needs to be tested and verified by applying the models in additional WWTPs. Finally,
    it is important to state the relevance of this work in achieving the SDG6, as
    the techniques presented help improving the wastewater treatment, which is one
    of the six outcome targets of the goal. For future work, the use of the federated
    framework in different wastewater treatment plants and the comparison of results
    with centralized training remains to be explored. A successful outcome in the
    utilization of various WWTP in the federated training could lead to a global foam
    segmentation model for WWTPs. Moreover, the utilization of distinct models depending
    on the month of the year may serve to mitigate the impact of atmospheric conditions
    on image segmentation. Author Contributions Conceptualization, J.C.M., S.G.V.,
    J.F.Á., Á.D.R. and J.S.C.; methodology, J.C.M., S.G.V., Á.D.R. and J.S.C.; software,
    J.C.M., S.G.V., X.L. and J.S.C.; validation, J.C.M., S.G.V. and Á.D.R.; formal
    analysis, J.C.M. and S.G.V.; investigation, J.C.M., S.G.V., J.F.Á., X.L. and J.S.C.;
    resources, J.C.M., S.G.V., J.F.Á., Á.D.R. and L.G.G.; data curation, J.C.M. and
    J.S.C.; writing—original draft preparation, J.C.M.; writing—review and editing,
    J.C.M., S.G.V. and J.F.Á.; visualization, J.C.M.; supervision, S.G.V.; project
    administration, S.G.V., J.F.Á., Á.D.R., L.G.G. and J.S.S.; funding acquisition,
    S.G.V., L.G.G. and J.S.S. All authors have read and agreed to the published version
    of the manuscript. Funding This research has been supported by the project EDAR360
    (IN852B 2021/14), part of the Conecta Hubs 2021 programme, subsidized by the Galician
    Innovation Agency (GAIN) and co-financed by ERDF funds within the framework of
    the Feder Galicia 2014–2020 operational programme and also by the projects CEL.IA
    (CER-20211022) and CONFIA, financed by the CERVERA Research Program of CDTI, the
    Industrial and Technological Development Centre of Spain, in 2021 and 2023 respectively.
    Data Availability Statement The data from public datasets presented in this study
    are openly available in [10,11]. The data from the WWTP presented in this study
    are available on request from the corresponding author. The data are not publicly
    available due to privacy restrictions. Conflicts of Interest The authors declare
    no conflicts of interest. The funders had no role in the design of the study;
    in the collection, analyses, or interpretation of data; in the writing of the
    manuscript; or in the decision to publish the results. Abbreviations The following
    abbreviations are used in this manuscript: OSTS One Shot Texture Segmentation
    WWTPs Waste Water Treatment Plants MBBR Moving Bed Biofilm Reactor SDG6 Sustainable
    Development Goal 6 References Madan, S.; Madan, R.; Hussain, A. Advancement in
    biological wastewater treatment using hybrid moving bed biofilm reactor (MBBR):
    A review. Appl. Water Sci. 2022, 12, 141. [Google Scholar] [CrossRef] Collivignarelli,
    M.C.; Baldi, M.; Abba, A.; Caccamo, F.M.; Milno, M.C.; Rada, E.C.; Torretta, V.
    Foams in Wastewater Treatment Plants: From Causes to Control Methods. Appl. Sci.
    2020, 10, 2716. [Google Scholar] [CrossRef] Wang, W.; Huang, X.; Esmaili, A. Texture-Based
    Foam Segmentation and Analysis. Ind. Eng. Chem. Res. 2011, 50, 6071–6081. [Google
    Scholar] [CrossRef] Forbes, G.; de Jager, G. Texture measures for improved watershed
    segmentation of froth images. In Proceedings of the Fifteenth Annual Symposium
    of the Pattern Recognition Association of South Africa, Grabouw, South Africa,
    25–26 November 2004. [Google Scholar] Kornilov, A.; Safonov, I.; Yakimchuk, I.
    A Review of Watershed Implementations for Segmentation of Volumetric Images. J.
    Imaging 2022, 8, 127. [Google Scholar] [CrossRef] Zhu, L. A Research on Foam-Detection
    Based on Image Analysis in the Process of Sewage Treatment. In Proceedings of
    the 11th International Symposium on Distributed Computing and Applications to
    Business, Engineering & Science, Guilin, China, 19–22 October 2012; pp. 429–431.
    [Google Scholar] [CrossRef] Tan, L.; Lu, J.; Jiang, H. Tomato Leaf Diseases Classification
    Based on Leaf Images: A Comparison between Classical Machine Learning and Deep
    Learning Methods. AgriEngineering 2021, 3, 542–558. [Google Scholar] [CrossRef]
    Saffari, N.; Rashwan, H.A.; Abdel-Nasser, M.; Singh, V.K.; Arenas, M.; Mangina,
    E.; Herrera, B.; Puig, D. Fully Automated Breast Density Segmentation and Classification
    Using Deep Learning. Diagnostics 2020, 10, 988. [Google Scholar] [CrossRef] Khan,
    S.; Muhammad, K.; Mumtaz, S.; Baik, S.W.; de Albuquerque, V.H.C. Energy-Efficient
    Deep CNN for Smoke Detection in Foggy IoT Environment. IEEE Internet Things J.
    2019, 6, 9237–9245. [Google Scholar] [CrossRef] Khan, S.; Muhammad, K.; Hussain,
    T.; Ser, J.D.; Cuzzolin, F.; Bhattacharyya, S.; Akhtar, Z.; de Albuquerque, V.H.C.
    DeepSmoke: Deep Learning Model for Smoke Detection and Segmentation in Outdoor
    Environments. Expert Syst. Appl. 2021, 182, 115125. [Google Scholar] [CrossRef]
    Ustyuzhaninov, I.; Michaelis, C.; Brendel, W.; Bethge, M. One-shot Texture Segmentation.
    arXiv 2018, arXiv:1807.02654. [Google Scholar] [CrossRef] Kone, J.; McMahan, H.B.;
    Yu, F.X.; Rich, P.; Theertha, A.; Bacon, D. Federated Learning: Strategies for
    Improving Communication Efficiency. arXiv 2016, arXiv:1610.05492. [Google Scholar]
    [CrossRef] Howard, A.; Zhu, M.; Chen, B.; Kalenichenko, D.; Wang, W.; Weyand,
    T.; Andreetto, M.; Adam, H. MobileNets: Efficient Convolutional Neural Networks
    for Mobile Vision Applications. arXiv 2017, arXiv:1704.04861. [Google Scholar]
    [CrossRef] He, K.; Zhang, X.; Ren, S.; Sun, J. Deep Residual Learning for Image
    Recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern
    Recognition (CVPR), Las Vegas, NV, USA, 27–30 June 2016; pp. 770–778. [Google
    Scholar] [CrossRef] Wang, J.; ke, S.; Cheng, T.; Jiang, B.; Deng, C.; Zhao, Y.;
    Liu, D.; Mu, Y.; Tan, M.; Wang, X.; et al. Deep High-Resolution Representation
    Learning for Visual Recognition. IEEE Trans. Pattern Anal. Mach. Intell. 2020,
    43, 3349–3364. [Google Scholar] [CrossRef] Zhang, R.; Isola, P.; Efros, A.; Shechtman,
    E.; Wang, O. The Unreasonable Effectiveness of Deep Features as a Perceptual Metric.
    In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,
    Salt Lake City, UT, USA, 18–23 June 2018; pp. 586–595. [Google Scholar] [CrossRef]
    Disclaimer/Publisher’s Note: The statements, opinions and data contained in all
    publications are solely those of the individual author(s) and contributor(s) and
    not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility
    for any injury to people or property resulting from any ideas, methods, instructions
    or products referred to in the content.  © 2024 by the authors. Licensee MDPI,
    Basel, Switzerland. This article is an open access article distributed under the
    terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/).
    Share and Cite MDPI and ACS Style Carballo Mato, J.; González Vázquez, S.; Fernández
    Águila, J.; Delgado Rodríguez, Á.; Lin, X.; Garabato Gándara, L.; Sobreira Seoane,
    J.; Silva Castro, J. Foam Segmentation in Wastewater Treatment Plants. Water 2024,
    16, 390. https://doi.org/10.3390/w16030390 AMA Style Carballo Mato J, González
    Vázquez S, Fernández Águila J, Delgado Rodríguez Á, Lin X, Garabato Gándara L,
    Sobreira Seoane J, Silva Castro J. Foam Segmentation in Wastewater Treatment Plants.
    Water. 2024; 16(3):390. https://doi.org/10.3390/w16030390 Chicago/Turabian Style
    Carballo Mato, Joaquín, Sonia González Vázquez, Jesús Fernández Águila, Ángel
    Delgado Rodríguez, Xin Lin, Lucía Garabato Gándara, Juan Sobreira Seoane, and
    Jose Silva Castro. 2024. \"Foam Segmentation in Wastewater Treatment Plants\"
    Water 16, no. 3: 390. https://doi.org/10.3390/w16030390 Note that from the first
    issue of 2016, this journal uses article numbers instead of page numbers. See
    further details here. Article Metrics Citations No citations were found for this
    article, but you may check on Google Scholar Article Access Statistics Article
    access statistics Article Views 24. Jan 3. Feb 13. Feb 23. Feb 4. Mar 14. Mar
    24. Mar 3. Apr 0 200 400 600 800 1000 For more information on the journal statistics,
    click here. Multiple requests from the same IP address are counted as one view.   Water,
    EISSN 2073-4441, Published by MDPI RSS Content Alert Further Information Article
    Processing Charges Pay an Invoice Open Access Policy Contact MDPI Jobs at MDPI
    Guidelines For Authors For Reviewers For Editors For Librarians For Publishers
    For Societies For Conference Organizers MDPI Initiatives Sciforum MDPI Books Preprints.org
    Scilit SciProfiles Encyclopedia JAMS Proceedings Series Follow MDPI LinkedIn Facebook
    Twitter Subscribe to receive issue release notifications and newsletters from
    MDPI journals Select options Subscribe © 1996-2024 MDPI (Basel, Switzerland) unless
    otherwise stated Disclaimer Terms and Conditions Privacy Policy"'
  inline_citation: '>'
  journal: Water (Switzerland)
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Foam Segmentation in Wastewater Treatment Plants
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Niederhauser L.
  - Prabhakar A.
  - Reber D.
  - Billard A.
  citation_count: '0'
  description: Robust in-hand manipulation of objects with movable content requires
    estimation and prediction of the contents' motion with enough anticipation to
    allow time to compensate for resulting internal torques. The quick estimation
    of the objects' dynamics can be challenging when the objects' motion properties
    (e.g., type, amount, dynamics) cannot be observed visually due to robot occlusions
    or opacity of the container. This can be further complicated by the computational
    requirements of onboard hardware available for real-time processing and control
    for robotics. In this work, we develop a simple learning framework that uses echo
    state networks to predict the torques experienced on the robotic hand with enough
    anticipation to allow for adaptive controls and sufficient efficiency for real-time
    prediction without GPU processing. We demonstrate the efficacy of this formulation
    for tactile force prediction on the Allegro robotic hand with a Tekscan tactile
    skin using both material-specific and material-agnostic learned models. We show
    that while both are effective, the material-specific models show an improvement
    in accuracy due to the difference in inertial properties between the different
    materials. We also develop a prediction model that uses audio feedback to augment
    the tactile predictions. We show that adding auditory feedback improves the prediction
    error, though it significantly increases the computation cost of the model. We
    validate this formulation for online prediction on the robotic hand moving materials
    in real-time and adapting grip for slip detection.
  doi: 10.1109/LRA.2023.3340614
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Journals & Magazines >IEEE Robotics and Automation ...
    >Volume: 9 Issue: 2 A Predictive Model for Tactile Force Estimation Using Audio-Tactile
    Data Publisher: IEEE Cite This PDF Loïc Niederhauser; Ahalya Prabhakar; Dominic
    Reber; Aude Billard All Authors 351 Full Text Views Open Access Under a Creative
    Commons License Abstract Document Sections I. Introduction II. Related Work III.
    Methods IV. Results V. Conclusion Authors Figures References Keywords Metrics
    Media Footnotes Abstract: Robust in-hand manipulation of objects with movable
    content requires estimation and prediction of the contents'' motion with enough
    anticipation to allow time to compensate for resulting internal torques. The quick
    estimation of the objects'' dynamics can be challenging when the objects'' motion
    properties (e.g., type, amount, dynamics) cannot be observed visually due to robot
    occlusions or opacity of the container. This can be further complicated by the
    computational requirements of onboard hardware available for real-time processing
    and control for robotics. In this work, we develop a simple learning framework
    that uses echo state networks to predict the torques experienced on the robotic
    hand with enough anticipation to allow for adaptive controls and sufficient efficiency
    for real-time prediction without GPU processing. We demonstrate the efficacy of
    this formulation for tactile force prediction on the Allegro robotic hand with
    a Tekscan tactile skin using both material-specific and material-agnostic learned
    models. We show that while both are effective, the material-specific models show
    an improvement in accuracy due to the difference in inertial properties between
    the different materials. We also develop a prediction model that uses audio feedback
    to augment the tactile predictions. We show that adding auditory feedback improves
    the prediction error, though it significantly increases the computation cost of
    the model. We validate this formulation for online prediction on the robotic hand
    moving materials in real-time and adapting grip for slip detection. Published
    in: IEEE Robotics and Automation Letters ( Volume: 9, Issue: 2, February 2024)
    Page(s): 1596 - 1603 Date of Publication: 07 December 2023 ISSN Information: DOI:
    10.1109/LRA.2023.3340614 Publisher: IEEE Funding Agency: SECTION I. Introduction
    Safe in-hand manipulation of objects requires the ability to estimate and adapt
    to the forces experienced by the robot hand from the objects'' inertial forces
    during motion. This is particularly relevant when adaptation requires grip changes
    that depends on sufficient time to execute. In these situations, force prediction
    must occur on longer time horizons, allowing for anticipation of slip into the
    future, as opposed to high-speed reactive controls. This can be more challenging
    when vision is impaired, due to occlusion by the robot or opacity of the container,
    as objects have different inertial properties that can lead to different force
    trajectories exerted on the hand during motion. These additional inertial forces
    can make it difficult for the robotic hand to maintain a stable grasp on the container
    during manipulation. Most research in this area primarily focuses on either utilizing
    vision for state estimation and prediction, or short-term slip prediction and
    detection for reactive torque controllers. Here, we focus on the problem of tactile
    prediction on a longer time horizon without the aid of vision. We develop a framework
    using echo state networks (ESNs) that enable tactile force prediction for a longer-time
    horizon. We train ESN models that predict the movement and amplitude of forces
    exerted on the hand during motion. We show that the learned models work over different
    materials and motion speeds for a given motion type. We demonstrate the differences
    in tactile forces caused by different materials even during the same motion, and
    validate the benefits of learning material- and motion-specific models. Furthermore,
    we show that utilizing auditory feedback in a multimodal prediction model improves
    the performance of tactile prediction for all materials. Importantly, the use
    of ESNs as a framework for the proposed approach allows for lower computational
    requirements, enabling successful execution with low computation resources (i.e.,
    a laptop with only a CPU). Finally, we validate the framework in a real-world
    experiment, demonstrating both tactile prediction on-line and its use for slip-anticipation
    for an adaptive grip control in real-time. SECTION II. Related Work Tactile estimation
    and prediction research has been of great interest in manipulation applications.
    Much of the research focuses on slip detection and reactive adaptation, discussed
    in detail in [1], [2]. Some methods use neural networks for slip detection using
    tactile data or vision-based tactile sensors for classifying contact or slippage
    [3], [4], [5], [6], [7]. Tactile and audio data are sometimes used in neural networks
    for content estimation, such as weight estimation or liquid height [8], [9]. Other
    methods learn models of liquid flow of unknown materials by using tactile or force
    data to estimate physical properties of the contents, including mass, volume and
    viscosity [10], [11]. These models are used to classify unknown liquids and for
    content estimation, which could be used to predict flow over time for manipulation.
    Here, we investigate the use of low-dimensional model learning for general content
    estimation, without imposing the structure of physical models of liquid flow that
    the learning here relies upon. Other research uses tactile force estimation and
    prediction for control and manipulation, discussed in depth in [12]. Many methods
    use estimation of contact point, force and curvature to drive control for manipulation
    [6], [13], [14]. Other research methods use neural networks to learn contact force
    estimation from tactile data [7], [15]. Su et al. [7] uses a neural network to
    predict the contact forces in the fingertips. The contact force estimation focuses
    on static grasping (i.e. when the container contents are not moving) to enable
    slip detection and slip prevention during grasping. [16] also performs force estimation
    for Biotac sensors located in the fingertips. They use convolutional neural networks
    to estimate forces during contact, which could be used in a grasp controller.
    [17] and [18] use graph neural networks and convolutional LSTMs respectively to
    predict contact forces in the fingertips during grasping. Both use the prediction
    models to assess grasp stability during lifting. Other methods use deep learning
    or reinforcement learning to drive touch-based manipulation through unsupervised
    learning [19], [20]. These methods require large amounts of data (3000–5000 trajectories)
    and prediction is done on short time horizons (15–18 time steps) due to the complexity
    of the prediction model. The approach proposed in this letter however focuses
    developing prediction models that have faster training times and lower complexity
    for longer time horizon predictions (up to 3 seconds into the future) to accommodate
    reactive controllers that require grasp adaptation. Echo state networks [21],
    [22] are a type of recurrent neural network with a random dynamical resevoir (i.e.,
    randomly connected neurons within the reservoir). These networks have been shown
    to be faster to train, requiring fewer parameters to be optimized and not suffering
    from gradient issues found in methods that use gradient-based optimization (i.e.,
    backpropogation). [23] uses echo state networks to predict the tactile signature
    of an antenna from action. They use the ESN for the 1-dimensional tactile prediction
    to discriminate when contact is occurring, rather than for grip control. Furthermore,
    their work uses echo state networks to predict one time step into the future,
    rather than for a longer time horizon (e.g., 300 steps into the future) as performed
    in this work. Furthermore, the other work only use tactile sensors for prediction
    and estimation. Here, we use auditory feedback to augment the tactile prediction.
    While there has been research in using auditory feedback for tactile applications
    [24], [25], [26], [27], most work focuses on using the multimodal perception for
    classification and object property identification, rather than real-time tactile
    prediction. SECTION III. Methods We develop a framework for learning and predicting
    the tactile pressure distribution experienced in a robotic hand. Specifically,
    we use echo state networks (ESNs) [21] to learn a predictive model of the magnitude
    and center of pressure on the hand caused by the objects'' movement during manipulation.
    We describe below the experimental setup and the formulation for the model learning
    and tactile force prediction. A. Experimental Setup The experimental setup, shown
    in Fig. 1, uses a Kuka IIWA 7 with an attached Allegro hand for robotic manipulation.
    A Tekscan tactile sensor consisting of 1050 tactile pixels of 4.6 × 4.6 [mm] covering
    palm and fingers provides pressure data across the Allegro hand and is sampled
    at a rate of approximately 100 Hz. The tactile data values are calibrated and
    normalized such that they range from 0 to 255 values (similar to values of 8-bits
    gray scale images) and then converted to Newtons by multiplying the value by a
    factor of 0.007. We represent the tactile sensors on the hand as 13 sections covering
    the palm and the fingers, as shown in Fig. 2. From each section of the hand, we
    calculate the center of pressure (CoP) and amplitude of the activated sensors
    over the region. The motion of the CoP and its amplitude over the different sections
    reflects the torques exerted on the hand during the motions by the contents. We
    train our model (discussed in detail below) to predict the CoP position and amplitude
    in each section. An audio microphone is attached to the Allegro hand (shown in
    Fig. 1), capturing the sounds inside the container during manipulation with a
    sampling rate of 16 kHz. Fig. 1. Description of experimental setup. It consists
    of a Kuka IIWA robot arm mounted with an Allegro hand and a microphone fixed on
    the robotic hand close to the container. The hand is covered with a Tekscan tactile
    skin sensor. The hand holds a bottle that is filled with unknown content. In the
    experiments, content may consist of water, a high-viscosity slurry, rice, or gummies.
    The robot rotates the bottle from left to right such that the content slides inside
    the bottle. Changes in distribution of mass within the object is revealed through
    change in pressure exerted on the palm. From the Tekscan data, the position of
    the center of pressure (cop) and the total force on each surface of the of the
    hand links is computed. As the content slides, it also generates noise that can
    be picked up by the microphone. Tactile and audio data are captured and used to
    refine prediction of tactile response. Show All Fig. 2. Diagram of the Tekscan
    sensor showing the cells and the numbered sections covering the hand. Show All
    B. Data Collection To generate data, we develop a robot controller that rotates
    the container a desired amount in a specified period. The rotation motion uses
    a position-based dynamical system (DS) controller that combines a DS control to
    maintain the desired position, while changing the orientation a specified range
    in a sinusoidal pattern to generate the motion. Throughout the motion, the Allegro
    hand maintains a envelop grasp on the container with a base torque of 1.5 Nm.
    We train prediction models for 4 classes of material contents with different inertial
    properties: water, a high-viscosity slurry, rice and gummies. The total weight
    of the content is 700 [g], 750 [g], 500 [g] and 450 [g] respectively. We collect
    demonstrations of 4 trials of 10 rotations for each material with orientation
    range of 120 ∘ over a period of 3 seconds. Between each trial, the bottle is replaced
    in the hand and the grasp is reset leading to variance in grasp between trials.
    C. Model Learning Echo state networks are used for tactile pressure prediction.
    Echo state networks (ESNs) [21], [22] consist of a recurrent neural network (RNN)
    with randomly assigned connectivity and weights for the hidden layer. While RNNs
    are trained with backpropagation, echo-state networks only optimize the weights
    of the output neurons, enabling computationally efficient model learning which
    effectively captures nonlinear time series behavior. The implementation used in
    this work follows the method introduced in [28], which introduces additional parameters
    for improving performance (e.g., leakage, skipped connections). We optimize the
    parameters using particle swarm optimization, within the bounds listed in Table
    I. For testing, all ESN models were run on a computer with an Intel Core i7-6700
    CPU@3.40 GHz and 16 GB RAM, with no GPU.1 TABLE I Particle Swarm Optimization
    Ranges for Hyperparameters for Echo State Network Models 1) Tactile Pressure Prediction
    Tactile pressure prediction consists of an echo state network model predicting
    the pressure experienced over the hand throughout the motion. The echo state network
    input and output consists of the CoP position (x and y) and total force for each
    of the 13 sections over the hand. For each material, the data is split in training/testing
    sets with a 50%−50% ratio. Each set is then further split into 4000–4500 time
    windows of 150 samples, depending on the length of the trial. The ESN is primed
    with 150 samples and trained to predict the following 300 samples in open loop.
    Accuracy of the network''s prediction is assessed using the testing set, which
    is composed of an equal number of time windows. In addition, the capacity of the
    ESN to predict position on unseen material is assessed, as well as it''s capacity
    to work with different movement speed by varying the movement speed for a single
    material. We also assess the results of the prediction while the robot is running
    in a real-time scenario, described below in Section III-E. D. Audio-Based Tactile
    Prediction We also develop a learning model that takes in auditory feedback to
    improve the tactile force predictions. We train an ESN to predict the tactile
    data for 10 time steps in the future based on 1.5 seconds of audio data. The audio
    data is broken into smaller time windows of 0.1 seconds, from which Mel spectrograms
    are generated. These spectrograms are fed into the ESN sequentially and the next
    10 time steps of tactile data is predicted in one shot. To integrate this prediction
    with the tactile prediction, we implement a weighted combination of the predictions
    from the audio and tactile ESNs and feed the result back into the tactile ESN
    through the open-loop routine of the prediction. We use particle swarm optimization
    to optimize the parameters of the audio-based ESN described in Table II. TABLE
    II Particle Swarm Optimization Ranges for Hyperparameters for Audio-Based Echo
    State Network Models E. Robotics Implementation We validate the learned models
    in a robotic experiment on the Kuka IIWA with the attached Allegro hand for real-time
    prediction and control. We perform a slip prediction experiment that utilizes
    the trained models to perform online tactile prediction to anticipate when slip
    will occur as illustrated on Fig. 3. We place the container on the robotic hand
    with the hand in the open position. The hand performs a small rotation in one
    direction (10 degrees) in which the bottle remains stable on the hand followed
    by a wider rotation in the opposite direction (45 degrees), during which the container
    will slip out of the hand. For training, we collect data with the hand in the
    open configuration and the bottle attached securely to the palm to prevent the
    bottle from slipping out of the hand. We collect 20 trials of data with a bottle
    filled with water using a rotation motions of 5 seconds. For the experimental
    study, as the hand executes the rotation motion, we use the tactile predictions
    to anticipate when slip will occur, and accordingly execute a close motion on
    the hand to grasp it. We define the slip threshold as when the force amplitude
    is close to 0 (i.e under 1 N) or when the CoP measurements are close to the side
    of the palm (i.e closer to 5 mm from the side of the palm). We perform the experiment
    in both directions, five times by starting the rotation towards the thumb and
    five times by starting the rotation towards the ring finger. To evaluate performance,
    we analyze the closing time of the hand over the container. Early and on time
    closings are both considered successful, while late closings are classified as
    failures. Early closing is when the hand closes when the bottle doesn''t move
    or is still stable (i.e, during the smaller first rotation thumb side). On time
    closing refers to the hand closing when the bottle is moving but has not yet slipped
    out of the hand during the larger rotation. Late closing occurs when the hand
    begins to close after the bottle has fallen. Fig. 3. Example of robotic experiment
    for slip prediction and recovery. Initially, the container is placed on the robotic
    palm with the fingers open. As the hand rotates, the model predicts the tactile
    forces during the motion and anticipates when slip will occur. Upon slip prediction,
    the robotic hand changes the grip in to a closed envelop grasp over the container
    to maintain stability. Show All SECTION IV. Results In this section, we discuss
    the results of the tactile and audio-tactile model learning and the experimental
    studies conducted. Fig. 4 shows the data of the CoP and total force data over
    a rotation for each material. While the overall temporal patterns caused by the
    rotation of the contents on the hand resemble each other, the inertial dynamics
    of each material has a significant impact on both the CoP location and total force
    exerted on the hand, highlighting the importance of taking material content into
    account for force prediction. Fig. 4. Center of pressure and amplitude data over
    time for each material (water; slurry; rice; gummies). Mean (line) and variance
    (shading) is shown for all trials of each material. The effect of different dynamics
    of each material on both CoP location and amplitude can be seen over the rotation.
    Show All Fig. 5 shows the FFT decomposition of the signal for different material.
    In this case, the robot noise induces some similarity in the frequency decomposition
    for different material. However, differences in shape and intensities are still
    observed for different materials. Fig. 5. FFT of the audio signal for different
    material. Across materials it shows similarities in shape due to the noise of
    the robot being similar across different material. Differences can be seen in
    intensity and shape of the peaks. Show All Fig. 6 shows the results for open-loop
    tactile prediction using the material-specific ESN of the CoP and force for water
    for 300 timesteps (or one rotation). The motion of the center of pressure caused
    by the contents moving back and forth over the palm is accurately predicted for
    the full rotation by the ESN. Fig. 6(a)–(d) shows the results for a single trial.
    Fig. 6(e)–(f) shows the average error over all the trials. Overall, the ESN is
    able to accurately predict the center of pressure and amplitude over time for
    all trials with water. Fig. 6. Prediction of center of pressure over palm for
    water using the material specific model. (a) and (b) Shows the ground truth (blue)
    and predicted trajectories (red) in the x-domain and y-domain respectively over
    time for a single trial. (c) Shows the ground truth data and predicted trajectories
    of the center of pressure over the palm in the x-y domain. (d) Shows the ground
    truth and predicted amplitude of pressure on the palm over time. (e) And (f) show
    the errors over time for the CoP position and amplitude respectively for all trials.
    The mean (line) and variance (shading) are shown for all trials. Show All Table
    III compares the performances and complexity2 of different prediction models.
    The MLP model was implemented by giving the full primer as input (0.1 [s] of signal)
    and predicting 3 [s] of signal which means that the minimal number of weights
    it can have is 2101. The LSTM is implemented in the same sequential manner as
    the ESN. The result show that for a long time horizon, a simple linear interpolation
    doesn''t yield good result. MLP needs about 7 times more complexity than the ESN
    to match its performance; however, vastly increasing the complexity of the model
    can yield better results than the ESN. The LSTM network can match ESN performances,
    and even improve on it, but also requires a lot more complexity to improve on
    the performances. In all those methods ESN''s are showing better performance at
    the lowest complexity. TABLE III Comparison of Performances for Different Algorithms
    Figs. 7 and 8 show the average CoP and force prediction errors for 300 steps into
    the future respectively over all trials for each material using the material-specific
    ESNs. The material-specific models accurately predict the CoP position for 300
    timesteps into the future for all materials. For both the slurry and gummies,
    the mean and variance in error is higher, as the motion of the materials inside
    the container varied depending on how the material stuck to the container and
    moved during rotation. For both rice and water, which were more predictable in
    the flow, the overall error during the prediction was lower. Fig. 7. Average CoP
    error for training set (shown in blue) and test set (shown in red) during forward
    prediction of the tactile data values during motion using the material-specific
    echo state network. Show All Fig. 8. Average total force error for training set
    (shown in blue) and test set (shown in red) during forward prediction of the tactile
    data values during motion using the material-specific echo state network. Show
    All Fig. 9 compares the results for generalized and specific model learning. Fig.
    9 shows average prediction error for CoP position and total force for each material
    for both the generalized and material-specific models. Fig. 9 shows that material-specific
    models results in lower prediction error compared to the generalized model; however,
    the generalized model performed better for materials were more predictable flow
    (i.e., water, slurry and rice) compared to those with more stochastic flows. The
    generalized model performed comparably well compared to the material-specific
    models for total force prediction for all materials. Fig. 9. Comparison of CoP
    and amplitude prediction errors using generalized and material-specific models
    as well as model trained on only a subset of material to assess generalization
    properties. Show All In addition, ESNs trained on only a subset of materials generally
    result in better performances on the materials within the training set (water
    and gummies). For unseen materials, the model performs with similar performances
    as the material-agnostic model but with generally higher variance. Fig. 10 shows
    that frequency-specific models result in significantly better performance compared
    to the generalized model, both in CoP and amplitude prediction. In addition, the
    frequency-agnostic model trained on only 3 of the frequencies show the same performances
    as one trained on all 5 frequencies, showing the model''s ability to generalize
    to unseen frequencies in the vicinity of the ones it was trained on. Fig. 10.
    Comparison of CoP and amplitude prediction errors using generalized, frequency-specific
    ESN, as well as generalized ESNs tested on frequencies unseen in training. Show
    All Fig. 11 compares the results of using the audio-tactile ESN model compared
    with the tactile-only ESN. Fig. 11(a) shows that incorporating the audio data
    into the prediction significantly improves the prediction of the CoP location
    throughout the trajectory. On the other hand, Fig. 11(b) shows that the amplitude
    prediction is not significantly improved with audio-data augmentation. This is
    possibly due to the audio data does not correlating with amount of force the material
    was exerting on the hand. Fig. 12 showed that for all materials, the audio-tactile
    models resulted in better performance. However, for slurry, the improvement was
    not significant. Fig. 11. (a) CoP and (b) amplitude prediction error over palm
    over time in water trial using the tactile-only and audio-tactile ESN models.
    The tactile-only baseline (in red) and audio-tactile model (in blue) are shown
    with the mean and variance over all trials. Times when the audio prediction is
    incorporated into the prediction for the audio-tactile model are indicated with
    the black vertical lines. Show All Fig. 12. Comparison of average CoP and amplidude
    prediction errors for the tactile-only (unimodal) and audio-tactile (multimodal)
    models. The mutlimodal models resulted in performance improvement for all materials
    in both CoP position and amplitude. Show All Tables IV shows the results of the
    experimental study conducted using online tactile prediction and control for grip
    closure. As described above in Section III-E, the container is placed in the open
    palm, and online tactile prediction is used to anticipate when slip will occur
    and enact the grip closure command accordingly. As the prediction is done for
    a shorter time frame, i.e. before the first time step for use of audio data, audio
    is not used in this setting. For both directions of rotation, as the prediction
    horizon increases, the number of failed (i.e., late closures) that occur decrease
    to 0. Importantly, the 10-ms prediction time is insufficient to both recognize
    and enact the grip closure command in time to prevent the container slipping.
    For both the 30 and 50 ms prediction horizons, the longer prediction horizons
    allow for greater anticipation, enabling the robot to complete grip closure with
    additional time (i.e., early closing). It is of note that by predicting for shorter
    time frame the ESN has lower variance in the result as can be seen in Fig. 7 making
    the experiment more repeatable While this additional time may not be necessary
    for this scenario, the necessity of long-time horizon predictions is highlighted
    when reactive torque changes are not sufficient, but grip changes need to occur
    for stable manipulation. TABLE IV Result of the Hand Rotation for Five Trials
    With Different Prediction Lengths for Rotations Starting Either From Thumb or
    Pinky Side SECTION V. Conclusion In this letter, we introduced a novel formulation
    for enabling long-time horizon tactile pressure prediction. We show that echo
    state networks are capable of accurately predicting tactile pressure trajectory
    during motion within real-time time bounds and on experimental data collected
    using the Allegro hand mounted on a Kuka IIWA robot. We show that material-specific
    echo state networks are effective for capturing and predicting the tactile pressure
    flow and the additional benefits of audio-data augmentation. We compare the ESN''s
    to other machine learning models, and show that ESN''s have the lowest computational
    complexity while being able to predict tactile data with sufficient accuracy,
    making them the best choice when looking to minimize the computational impact
    of tactile prediction on any low capacity hardware. We validate our results for
    different material contents and online in a real-world experimental setup, where
    for models with lower computational requirements are required. Finally, we highlight
    the importance of long-time tactile prediction for manipulation in tasks where
    grip changes need to occur. Future work seeks to improve the model to accommodate
    a wider variety of materials and motion types. Furthermore, we seek to use the
    proposed framework with a more complex grasp planner that would benefit from long-time
    horizon prediction. ACKNOWLEDGMENT We would like to thank Stanislas Furrer, Lorenzo
    Panchetti, and Maxime Perret for their help in the initial experimental setups
    for this work. Authors Figures References Keywords Metrics Media Footnotes More
    Like This Contact Force Estimation of Robot Manipulators With Imperfect Dynamic
    Model: On Gaussian Process Adaptive Disturbance Kalman Filter IEEE Transactions
    on Automation Science and Engineering Published: 2023 Camera Configuration Models
    for Machine Vision Based Force Estimation in Robot-Assisted Soft Body Manipulation
    2022 International Symposium on Medical Robotics (ISMR) Published: 2022 Show More
    IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS
    VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION
    AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE:
    +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help
    | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting
    | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s
    largest technical professional organization dedicated to advancing technology
    for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: IEEE Robotics and Automation Letters
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: A Predictive Model for Tactile Force Estimation Using Audio-Tactile Data
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Maser R.
  - Andaloussi M.A.
  - Lamoline F.
  - Husch A.
  citation_count: '0'
  description: Advancements in computational power and algorithmic refinements have
    significantly amplified the impact and applicability of machine learning (ML),
    particularly in medical imaging. While ML in general thrives on extensive datasets
    to develop accurate, robust, and unbiased models, medical imaging faces unique
    challenges, including a scarcity of samples and a predominance of poorly annotated,
    heterogeneous datasets. This heterogeneity manifests in varied acquisition conditions,
    target populations, data formats and structures. Data acquisition of large datasets
    is often additionally hampered by compatibility issues of source specific downloading
    tools with high-performance computing (HPC) environments. To address these challenges,
    we introduce the unified retrieval tool (URT), a tool that unifies the acquisition
    and standardization of diverse medical imaging datasets to the brain imaging data
    structure (BIDS). Currently, downloads from the cancer imaging archive (TCIA),
    OpenNeuro and Synapse are supported, easing access to large-scale medical data.
    URT’s modularity allows the straightforward extension to other sources. Moreover,
    URT’s compatibility with Docker and Singularity enables reproducible research
    and easy application on HPCs.
  doi: 10.1007/978-3-658-44037-4_83
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Log in Find a journal
    Publish with us Track your research Search Cart BVM Workshop BVM 2024: Bildverarbeitung
    für die Medizin 2024 pp 328–333Cite as Home Bildverarbeitung für die Medizin 2024
    Conference paper Unified Retrieval for Streamlining Biomedical Image Dataset Aggregation
    and Standardization Raphael Maser, Meryem Abbad Andaloussi, François Lamoline
    & Andreas Husch  Conference paper First Online: 20 February 2024 228 Accesses
    Part of the book series: Informatik aktuell ((INFORMAT)) Abstract Advancements
    in computational power and algorithmic refinements have significantly amplified
    the impact and applicability of machine learning (ML), particularly in medical
    imaging. While ML in general thrives on extensive datasets to develop accurate,
    robust, and unbiased models, medical imaging faces unique challenges, including
    a scarcity of samples and a predominance of poorly annotated, heterogeneous datasets.
    This heterogeneity manifests in varied acquisition conditions, target populations,
    data formats and structures. Data acquisition of large datasets is often additionally
    hampered by compatibility issues of source specific downloading tools with high-performance
    computing (HPC) environments. To address these challenges, we introduce the unified
    retrieval tool (URT), a tool that unifies the acquisition and standardization
    of diverse medical imaging datasets to the brain imaging data structure (BIDS).
    Currently, downloads from the cancer imaging archive (TCIA), OpenNeuro and Synapse
    are supported, easing access to large-scale medical data. URT’s modularity allows
    the straightforward extension to other sources. Moreover, URT’s compatibility
    with Docker and Singularity enables reproducible research and easy application
    on HPCs. This is a preview of subscription content, log in via an institution.
    Preview References Brown T, Mann B, Ryder N, Subbiah M, Kaplan JD, Dhariwal P
    et al. Language models are few-shot learners. Adv Neural Inf Process Syst. 2020;33:1877–901.
    Google Scholar   Kaplan J, McCandlish S, Henighan T, Brown TB, Chess B, Child
    R et al. Scaling laws for neural language models. arXiv preprint arXiv:2001.08361.
    2020. Tan M, Le Q. Efficientnet: rethinking model scaling for convolutional neural
    networks. Proc PMLR. PMLR. 2019:6105–14. Google Scholar   Dosovitskiy A, Beyer
    L, Kolesnikov A, Weissenborn D, Zhai X, Unterthiner T et al. An image is worth
    16x16 Words: transformers for image recognition at scale. Proc ICLR. 2021. Google
    Scholar   Xie Z, Zhang Z, Cao Y, Lin Y,Wei Y, Dai Qet al. On data scaling in masked
    image modeling. Proc IEEE CVPR. 2023:10365–74. Google Scholar   Zhai X, Kolesnikov
    A, Houlsby N, Beyer L. Scaling vision transformers. Proc IEEE CVPR. 2022:12104–13.
    Google Scholar   Gorgolewski KJ, Auer T, Calhoun VD, Craddock RC, Das S, Duff
    EP et al. The brain imaging data structure, a format for organizing and describing
    outputs of neuroimaging experiments. Sci Data. 2016;3(1):160044. Google Scholar   Varoquaux
    G, Cheplygina V. Machine learning for medical imaging: methodological failures
    and recommendations for the future. NPJ Digit Med. 2022;5(1):48. Google Scholar   Willemink
    MJ, Koszek WA, Hardell C, Wu J, Fleischmann D, Harvey H et al. Preparing medical
    imaging data for machine learning. Radiol. 2020;295(1):4–15. Google Scholar   Deng
    J, Dong W, Socher R, Li LJ, Li K, Fei-Fei L. ImageNet: a large-scale hierarchical
    image database. Proc IEEE ICCV. Ieee. 2009:248–55. Google Scholar   Schilling
    MP, Ahuja N, Rettenberger L, Scherr T, Reischl M. Impact of annotation noise on
    histopathology nucleus segmentation. Cur Direct Biomed Eng. Vol. 8. (2). De Gruyter.
    2022:197–200. Google Scholar   Gavrielides MA, Kinnard LM, Myers KJ, Peregoy J,
    Pritchard WF, Zeng R et al. A resource for the assessment of lung nodule size
    estimation methods: database of thoracic CT scans of an anthropomorphic phantom.
    Opt Express. 2010;18(14):15244–55. Google Scholar   Garcia Santa Cruz B, Bossa
    MN, Sölter J, Husch AD. Public Covid-19 X-ray datasets and their impact on model
    bias: a systematic review of a significant problem. Med Image Anal. 2021;74:102225.
    Google Scholar   Clark K, Vendt B, Smith K, Freymann J, Kirby J, Koppel P et al.
    The cancer imaging archive (TCIA): maintaining and operating a public information
    repository. J Digit Imaging. 2013;26:1045–57. Google Scholar   Markiewicz CJ,
    Gorgolewski KJ, Feingold F, Blair R, Halchenko YO, Miller E et al. The OpenNeuro
    resource for sharing of neuroscience data. eLife. 2021;10:e71774. Google Scholar   Zwiers
    MP, Moia S, Oostenveld R. BIDScoin: a user-friendly application to convert source
    data to brain imaging data structure. Front Neuroinform. 2022;15:65. Google Scholar   Varrette
    S, Bouvry P, Cartiaux H, Georgatos F. Management of an academic HPC cluster: the
    UL experience. Proc IEEE HPCS. 2014:959–67. Google Scholar   Download references
    Author information Authors and Affiliations Esch-Belval Belvaux, Luxembourg Raphael
    Maser, Meryem Abbad Andaloussi, François Lamoline & Andreas Husch Corresponding
    author Correspondence to Andreas Husch . Editor information Editors and Affiliations
    Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Bayern, Deutschland
    Andreas Maier Peter L. Reichertz Institut für Medizinische Informatik, Technische
    Universität Braunschweig, Braunschweig, Niedersachsen, Deutschland Thomas M. Deserno
    Institut für Medizinische Informatik, Universität zu Lübeck, Lübeck, Schleswig-Holstein,
    Deutschland Heinz Handels Medical Image Computing, E230, Deutsches Krebsforschungszentrum
    (DKFZ), Heidelberg, Baden-Württemberg, Deutschland Klaus Maier-Hein Informatik
    und Mathematik, OTH Regensburg, Regensburg, Deutschland Christoph Palm Institut
    für Medizinische Informatik, Charité - Universitätsmedizin Berlin, Berlin, Berlin,
    Deutschland Thomas Tolxdorff Rights and permissions Reprints and permissions Copyright
    information © 2024 Der/die Autor(en), exklusiv lizenziert an Springer Fachmedien
    Wiesbaden GmbH, ein Teil von Springer Nature About this paper Cite this paper
    Maser, R., Andaloussi, M.A., Lamoline, F., Husch, A. (2024). Unified Retrieval
    for Streamlining Biomedical Image Dataset Aggregation and Standardization. In:
    Maier, A., Deserno, T.M., Handels, H., Maier-Hein, K., Palm, C., Tolxdorff, T.
    (eds) Bildverarbeitung für die Medizin 2024. BVM 2024. Informatik aktuell. Springer
    Vieweg, Wiesbaden. https://doi.org/10.1007/978-3-658-44037-4_83 Download citation
    .RIS.ENW.BIB DOI https://doi.org/10.1007/978-3-658-44037-4_83 Published 20 February
    2024 Publisher Name Springer Vieweg, Wiesbaden Print ISBN 978-3-658-44036-7 Online
    ISBN 978-3-658-44037-4 eBook Packages Computer Science and Engineering (German
    Language) Publish with us Policies and ethics Access via your institution Buying
    options Chapter USD   29.95 Price excludes VAT (USA) Available as PDF Read on
    any device Instant download Own it forever Buy Chapter eBook USD   79.99 Softcover
    Book USD   99.99 Tax calculation will be finalised at checkout Purchases are for
    personal use only Learn about institutional subscriptions Sections References
    Abstract Preview References Author information Editor information Rights and permissions
    Copyright information About this paper Publish with us Discover content Journals
    A-Z Books A-Z Publish with us Publish your research Open access publishing Products
    and services Our products Librarians Societies Partners and advertisers Our imprints
    Springer Nature Portfolio BMC Palgrave Macmillan Apress Your privacy choices/Manage
    cookies Your US state privacy rights Accessibility statement Terms and conditions
    Privacy policy Help and support 129.93.161.219 Big Ten Academic Alliance (BTAA)
    (3000133814) - University of Nebraska-Lincoln (3000134173) © 2024 Springer Nature"'
  inline_citation: '>'
  journal: Informatik aktuell
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Unified Retrieval for Streamlining Biomedical Image Dataset Aggregation and
    Standardization
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Singh A.
  - Bajaj D.
  - Safa M.
  - Arulmurugan A.
  - John A.
  citation_count: '0'
  description: Aquaponics is a sustainable farming method that combines aquaculture
    and hydroponics to grow plants and fish in a closed-loop system. In this research
    paper, an irrigation system based on aquaponics is proposed, which uses real-time
    sensor data from the fish tank and crop soil to improve the efficiency of the
    system. The system is designed to make informed decisions about crop irrigation
    needs by visualizing the data for analytics. The study compares the accuracy of
    three classification algorithms, KNN, Naive Bayes, and ANN, to decide when to
    irrigate the soil based on real-time sensor data. The proposed irrigation system
    includes two sets of sensors, one for the fish tank and the other for the crop
    soil, which is processed by an Arduino board and sent to Adafruit’s cloud platform
    for visualization and analytics. This cloud-based platform allows easy access
    to real-time data, enabling efficient monitoring and control of the irrigation
    system. Additionally, the study visualizes the results obtained from using regular
    water and lake water in the aquaponics system.
  doi: 10.1007/978-981-99-8451-0_17
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Log in Find a journal
    Publish with us Track your research Search Cart International Conference on Soft
    Computing and Signal Processing ICSCSP 2023: Soft Computing and Signal Processing
    pp 199–208Cite as Home Soft Computing and Signal Processing Conference paper IoT-Based
    Smart Irrigation System in Aquaponics Using Ensemble Machine Learning Aishani
    Singh, Dhruv Bajaj, M. Safa, A. Arulmurugan & A. John  Conference paper First
    Online: 17 February 2024 41 Accesses Part of the book series: Lecture Notes in
    Networks and Systems ((LNNS,volume 840)) Abstract Aquaponics is a sustainable
    farming method that combines aquaculture and hydroponics to grow plants and fish
    in a closed-loop system. In this research paper, an irrigation system based on
    aquaponics is proposed, which uses real-time sensor data from the fish tank and
    crop soil to improve the efficiency of the system. The system is designed to make
    informed decisions about crop irrigation needs by visualizing the data for analytics.
    The study compares the accuracy of three classification algorithms, KNN, Naive
    Bayes, and ANN, to decide when to irrigate the soil based on real-time sensor
    data. The proposed irrigation system includes two sets of sensors, one for the
    fish tank and the other for the crop soil, which is processed by an Arduino board
    and sent to Adafruit’s cloud platform for visualization and analytics. This cloud-based
    platform allows easy access to real-time data, enabling efficient monitoring and
    control of the irrigation system. Additionally, the study visualizes the results
    obtained from using regular water and lake water in the aquaponics system. Keywords
    Aquaponics IoT Smart monitoring Sustainable farming Machine learning Smart agriculture
    Access provided by University of Nebraska-Lincoln. Download conference paper PDF
    1 Introduction Agricultural practices are rapidly changing in the face of the
    increasing demand for food and water resources. Traditional methods of irrigation
    have proven to be inefficient, causing water scarcity and soil degradation. The
    concept of aquaponics, a combination of aquaculture and hydroponics, offers an
    alternative solution to sustainable agriculture. It utilizes a closed-loop system
    where fish and plants are grown in the same environment, creating a symbiotic
    relationship where the waste from fish is utilized as nutrients for plants, and
    the plants clean the water for the fish. Fish waste is converted into nitrates
    by bacteria present in the soil, which can be readily absorbed by the plants.
    This system also provides the plants with a much more consistent nutrient supply
    as compared to traditional irrigation systems. Experts say that the aquaponic
    way of irrigation conserves as much as 90% of the water that is wasted in traditional
    irrigation systems. It is also observed that plants grow faster in this system
    because nutrients are readily available to them and they do not have to expend
    energy searching for them. Overall, the nutrient-rich, controlled environment
    of an aquaponics system provides the ideal conditions for plant growth, making
    it a superior option for growing plants. The proposed system takes various samples
    of tap water as well as Potheri Lake water with varying differences in pH, turbidity,
    and water temperature. The pH level of lake water can vary widely depending on
    various factors such as the surrounding environment, the presence of aquatic life,
    and the weather conditions. In general, lake water can have a lower or higher
    pH level than tap water, depending on the lake''s distinctive characteristics
    and the way the local area''s tap water is treated. For instance, tap water is
    usually treated to have a pH level between 6.5 and 8.5, which is considered safe
    for human consumption and does not cause corrosion in pipes. The naturally occurring
    presence of suspended particles like silt, sand, and algae in lake water can cause
    it to have a greater turbidity level than tap water. 2 Literature Review The hardware
    design of one system [1] includes various components such as sensors, actuators,
    relays, an Ethernet shield, Arduino, and routers. The monitoring of temperature
    and humidity is accomplished using an Arduino microcontroller, an Ethernet Shield,
    an FC-28 humidity sensor, and a DHT11 temperature sensor. A router is utilized
    to connect the Arduino Ethernet to a server. The relay module functions as a control
    switch for various actuators, which respond to the sensor output. The aquaponic
    box contains several actuators, such as two 12V DC exhaust fans, a mist maker,
    a 5V DC fan, two LED Grow Light lamps, and a 12V DC pump [2]. Another system kept
    track of numerous environmental factors, and over time it would be able to control
    how the farm operated and create a fully automated system. Publishers (nodes),
    brokers (local servers), and subscribers (local servers) all communicated via
    the MQTT protocol, which allows for the use of any data type. Monitoring can also
    be done with the help of a GUI program, a communication network, and [3] wireless
    sensors. A graphical user interface is provided by AWSM to address the aforementioned
    issues. Farmers can get real-time notifications and advice about water quality
    even when they are not there by using AWSM''s mobile applications built on IoT
    technology. When compared to the conventional approach, the introduction of the
    AWSM-based IoT application in the Aquaponics system has shown substantial gains.
    Additionally, it is feasible to [4] investigate many characteristics observed
    by smart systems, IoT technologies, and aquaponics. A ZigBee module [5] can be
    used in place of the Wi-Fi module to broadcast the data gathered by the Arduino
    while also displaying the values on the LCD without performing any control actions.
    A fish tank, a grow bed, and a light panel that simulates the sun''s rays for
    plant growth make up the aquaponics system described in [6]. The fish waste provides
    nutrients to the plants, which in turn receive water from the fish tank as a filter.
    The system makes use of actuators to operate the water pump, light panel, heater,
    and oxygen provider as well as sensors to monitor and control pH levels, temperature,
    and humidity. To direct the actual citrus production process, nutrient monitoring
    [7] in citrus plants can also be done in real time according to the soil situation.
    Another method that primarily focuses on finding magnesium and nitrogen deficiencies
    in image processing [8] in MATLAB for the detection of rice illnesses and nutritional
    deficiencies. A Raspberry Pi, a DHT11 temperature and humidity sensor, and solenoid
    valves make up the hardware employed in this technique. A deep learning method
    can help in the detection of diseases and the prediction of crop growth by utilizing
    many sensors that measure the pH value, temperature, humidity, and water level
    [9]. Astute farming is described by the author of reference [10] as the integration
    of a wireless sensor and irrigation system that keeps track of factors including
    soil moisture, nutritional content, and pH levels. A GSM module is used to manage
    the system via wireless communication. 3 Architecture Diagram The proposed system
    shown in Fig 1 comprises two sets of sensors—one for the fish tank and the other
    for the crop soil. The data from these sensors are sent to the Arduino board.
    The Arduino board processes the data and sends it to the NodeMCU Wi-Fi module
    which sends it to the Adafruit cloud platform for visualization and analytics
    [11,12,13,14,15]. The system gathers real-time sensor data from the fish tank
    and crop soil using a variety of sensors, including a soil moisture sensor, temperature
    and humidity sensor, pH sensor, turbidity sensor, and water temperature sensor.
    The physical layer or sensor is made up of this. The data is gathered and transferred
    to the Arduino board regularly. Fig. 1 Architecture diagram of proposed system
    Full size image 4 Methodology The construction of an aquaponics monitoring system
    for effective irrigation is the main goal of the suggested system. The system
    uses a variety of sensors, including a soil moisture sensor placed in a tomato
    plant, pH, water temperature, and turbidity sensors. The irrigation process is
    controlled by the readings from these sensors. Hardware Setup: The hardware setup
    consists of an Arduino board that, via Arduino programming in the Arduino IDE,
    receives data from the sensors. The NodeMCU Wi-Fi module, which is set up to work
    on any internet network, receives the data after that. A personal hotspot or local
    Wi-Fi network was used for this project. The data is sent from the NodeMCU to
    Adafruit.io, a cloud-based platform for IoT data analytics and visualization.
    On this platform, real-time data changes can be tracked and examined. Every 30–45
    s, the sensors update their readings. A CSV file containing the data gathered
    from the Adafruit.io platform can be downloaded. Then, using the downloaded data,
    three classification algorithms—KNN, ANN, and Naive Bayes—are trained and tested.
    To forecast the soil''s irrigation needs, data is analyzed. Jupyter Notebook is
    used to analyze and visualize machine learning. Utilizing visualization techniques,
    the three classification systems are compared for accuracy. The system’s overall
    goal is to create an aquaponics monitoring system that controls irrigation by
    using a variety of sensors. Machine learning algorithms are used to analyze the
    sensor data and estimate the need for irrigation, which can result in more effective
    irrigation and higher agricultural yields. 4.1 Machine Learning Algorithms Used
    KNN (K-Nearest Neighbor). To use KNN, we must first select a value for k, which
    specifies the number of neighbors to take into account. Then, when we have a fresh
    batch of data to categorize, we determine how far away each point in the training
    set is from the fresh data and select the k-nearest points. Finally, we designate
    the class for the new data point as being the one that is most prevalent among
    those k points. Naïve Bayes’ classifier. Based on the Bayes theorem, which quantifies
    the likelihood of a hypothesis given evidence, it is a probabilistic categorization
    model. The term “naive” refers to the assumption made in Naive Bayes that the
    features are conditionally independent of the class. ANN (Artificial Neural Network).
    It is a machine learning model that takes its cues from how the human brain is
    organized and works. It is made up of many interconnected layers of neurons that
    analyze data and produce predictions. The features of the instance to be classified
    are sent to the input layer of an ANN classification model, and the predicted
    class is generated by the output layer. There are one or more hidden layers in
    between that process the input and transmit data to the output layer. The weighted
    total of the inputs is applied by each neuron in the hidden layers using a nonlinear
    activation function. 5 Components Used 5.1 Hardware The proposed irrigation system
    based on aquaponics uses various components to measure and transmit real-time
    data to the cloud platform for visualization and analytics. The sensors used in
    the system are summarized below. Soil moisture sensor (LM393). An electrical tool
    called the soil moisture sensor (LM393) measures the amount of water in the soil.
    It measures the soil moisture using the LM393 comparator integrated circuit and
    outputs a digital signal based on the predetermined moisture threshold. This sensor
    comprises two probes that are put into the soil; as a function of the moisture
    content of the soil, the resistance between the probe changes. Temperature and
    humidity sensor (DHT11). A widely used electrical device that can detect both
    temperature and humidity levels in the environment is the DHT11 temperature and
    humidity sensor. It uses a capacitive humidity sensor to monitor humidity levels
    and a Negative Temperature Coefficient (NTC) thermistor to measure temperature.
    The sensor sends digital outputs of temperature and humidity data to an 8-bit
    microcontroller through a one-wire protocol. pH sensor and turbidity sensor: A
    pH sensor is an electronic device that determines whether a solution is acidic
    or alkaline. The pH scale, which has a range of 0–14 with 0 being the most acidic,
    14 being the most alkaline, and 7 being neutral, serves as the basis for how it
    functions. The fish tank’s water clarity, which is crucial for fish health, is
    measured by the turbidity sensor. Water temperature sensor. A common sensor for
    measuring the temperature of liquids, including water, is the DS18B20. This sensor
    is a digital thermometer that communicates with other devices via a 1-Wire interface.
    With an accuracy of 0.5 °C in the range of − 10 to + 85 °C, the DS18B20 can measure
    temperatures from − 55 to + 125 °C. Arduino board. Arduino Uno is based on the
    ATmega328P microcontroller. It is an open-source hardware board created for people
    of all skill levels who want to develop a variety of electronic projects. The
    board contains a USB port, a power jack, six analog inputs, an ICSP header, and
    14 digital input/output pins. The Arduino programming language, which is based
    on C/C++, can be used to program the board. NodeMCU Wi-Fi module. The board is
    a great option for IoT applications because it combines the capabilities of a
    microcontroller and a Wi-Fi module. The Arduino IDE or the Lua programming language
    is used to creating programs for the NodeMCU ESP8266 device. Various sensors,
    actuators, and other electronic devices can be connected to the board''s GPIO
    pins. Additionally, it has Wi-Fi connectivity functionality built-in, enabling
    it to connect to the internet and communicate with other devices. A USB cable
    or an external power source can be used to power the board. 6 Implementation The
    sensor data was collected for over a month on an hourly basis. Visualizations
    were created based on the data. The data was also collected in the form of CSV,
    and three different binary classification algorithms were applied to it, namely
    KNN, ANN, and Naive Bayes. The working model of the aquaponic system is shown
    in Fig. 2. Fig. 2 Turbidity, water temperature, and pH sensor along with connections
    Full size image 7 Results The suggested technique gives a thorough strategy for
    effective aquaponic irrigation management. Real-time sensor data visualization
    and analytics offer insightful information on fish and agricultural growth conditions.
    The three machine learning methods’ comparison offers useful insights into effective
    irrigation prediction in aquaponics. For visualization and analysis, the Adafruit
    platform can be accessed on a smartphone, laptop, tablet, or any other electronic
    device that can be connected to the internet. Visualization on Adafruit.io is
    shown in Figs. 3 and 4. Fig. 3 Real-time values of data acquired from sensors
    Full size image Fig. 4 Variation of different parameters with time Full size image
    7.1 Comparing the Accuracy of Various Classification Models The selection of a
    classification algorithm for agricultural data is influenced by the details of
    the data, the resources at hand, and the objectives of the classification activity.
    A standard criterion for assessing a classification model''s performance is accuracy.
    It calculates the percentage of cases in the dataset that were correctly categorized.
    To put it another way, accuracy is the proportion of true positives and true negatives
    in all instances. The model is operating effectively and properly predicting the
    class labels of the instances in the dataset when the accuracy value is high.
    A classification model could be taught to determine whether or not a certain soil
    sample needs irrigation based on its characteristics, such as its temperature,
    humidity, and soil moisture content. In this situation, a classification model
    with high accuracy might be helpful since it can make precise predictions about
    the soil samples’ irrigation requirements. As a result, farmers may be better
    able to decide when and how much to irrigate their crops, which may result in
    the more effective use of water resources and higher crop yields. On comparing
    the accuracy of all three algorithms as in Fig. 5, Naive Bayes was observed to
    have the highest accuracy of 94.12%. This is followed by ANN with an accuracy
    of 91.18% and then by KNN having an accuracy of 88.24. Fig. 5 Grouped bar chart
    for comparison of the accuracy of different models used Full size image 8 Conclusion
    In conclusion, we have presented an irrigation system based on aquaponics that
    utilizes real-time sensor data to monitor and irrigate crops efficiently. The
    system gathers information from a variety of sensors, including soil moisture
    sensors, temperature and humidity sensors, pH sensors, turbidity sensors, and
    water temperature sensors. This information is then processed and instantly displayed
    on the Adafruit platform. Furthermore, we evaluated the performance of three classification
    algorithms, namely KNN, Naive Bayes’, and ANN, for deciding when to irrigate the
    soil. We discovered that ANN had the maximum accuracy, making it the best algorithm
    for our system''s irrigation timing prediction. As a future scope, we plan to
    further enhance our system by incorporating features that will enable the user
    to receive alerts on their mobile device, indicating when the crop needs water.
    We also plan to compare our results with additional classification algorithms
    to identify the best-performing algorithm for our system. Overall, this system
    provides a significant advancement in the automation of aquaponics-based irrigation,
    offering a more efficient, accurate, and sustainable way of managing crops. References
    Vernandhes W, Salahuddin N, Kowanda A, Sari SP (2017) Smart aquaponic with monitoring
    and control system based on IoT. In: 2017 second international conference on informatics
    and computing (ICIC). https://doi.org/10.1109/iac.2017.8280590 Nichani A, Saha
    S, Upadhyay T, Ramya A, Tolia M (2018) Data acquisition and actuation for aquaponics
    using IoT. In: 2018 3rd IEEE international conference on recent trends in electronics,
    information & communication technology (RTEICT). https://doi.org/10.1109/rteict42901.2018.9012260
    Menon PC (2020) IoT enabled aquaponics with wireless sensor smart monitoring.
    In: 2020 fourth international conference on I-SMAC (IoT in social, mobile, analytics,
    and cloud) (I-SMAC). https://doi.org/10.1109/i-smac49090.2020.9243368 Yanes AR,
    Martinez P, Ahmad R (2020) Towards automated aquaponics: a review on monitoring,
    IoT, and smart systems. J Clean Prod 263:121571. https://doi.org/10.1016/j.jclepro.2020.121571
    Prabha R et al (2020) IoT controlled aquaponic system. In: 2020 6th international
    conference on advanced computing and communication systems (ICACCS). IEEE Google
    Scholar   Butt MFU, Yaqub R, Hammad M, Ahsen M, Ansir M, Zamir N (2019) Implementation
    of aquaponics within IoT framework. In: 2019 SoutheastCon. https://doi.org/10.1109/southeastcon42311.2019.9020390
    Zhang X, Zhang J, Li L, Zhang Y, Yang G (2017) Monitoring citrus soil moisture
    and nutrients using an IoT based system. Sensors 17(3):447. https://doi.org/10.3390/s17030447
    Rau AJ, Sankar J, Mohan AR, Das Krishna D, Mathew J (2017) IoT based smart irrigation
    system and nutrient detection with disease analysis. In: 2017 IEEE region 10 symposium
    (TENSYMP). https://doi.org/10.1109/tenconspring.2017.8070100 Park H, Eun JS, Kim
    SH (2017) Image-based disease diagnosing and predicting of the crops through the
    deep learning mechanism. In: 2017 international conference on information and
    communication technology convergence (ICTC). https://doi.org/10.1109/ictc.2017.8190957
    Chetan Dwarkani M, Ganesh Ram R, Jagannathan S, Priyatharshini R (2015) Smart
    farming system using sensors for agricultural task automation. In: 2015 IEEE technological
    innovation in ict for agriculture and rural development (TIAR). https://doi.org/10.1109/tiar.2015.7358530
    Ghandar A, Ahmed A, Zulfiqar S, Hua Z, Hanai M, Theodoropoulos G (2021) A decision
    support system for urban agriculture using digital twin: a case study with aquaponics.
    IEEE Access 9:35691–35708. https://doi.org/10.1109/access.2021.3061722 Article   Google
    Scholar   Kumawat S et al (2017) Sensor based automatic irrigation system and
    soil pH detection using image processing. Int Res J Eng Technol 4:3673–3675 Google
    Scholar   Abbasi R, Martinez P, Ahmad R (2022) Data acquisition and monitoring
    dashboard for IoT enabled aquaponics facility. In: 2022 10th international conference
    on control, mechatronics and automation (ICCMA). https://doi.org/10.1109/iccma56665.2022.10011594
    Dhal SB, Bagavathiannan M, Braga-Neto U, Kalafatis S (2022) Can machine learning
    classifiers be used to regulate nutrients using small training datasets for aquaponic
    irrigation? A comparative analysis. PLOS One 17(8):e0269401. https://doi.org/10.1371/journal.pone.0269401
    Paul B, Agnihotri S, Kavya B, Tripathi P, Narendra Babu C (2022) Sustainable smart
    aquaponics farming using IoT and data analytics. J Inf Technol Res 15(1):1–27.
    https://doi.org/10.4018/jitr.299914 Download references Author information Authors
    and Affiliations Department of Computing Technologies, SRM Institute of Science
    and Technology, Kattankulathur, Chennai, India Aishani Singh & A. Arulmurugan
    Department of Networking and Communications, SRM Institute of Science and Technology,
    Kattankulathur, Chennai, India Dhruv Bajaj & M. Safa Department of Computer Science
    and Information Engineering, National Chung Cheng University, Chiayi, Taiwan A.
    John Corresponding author Correspondence to M. Safa . Editor information Editors
    and Affiliations Faculty of Science and Technology, International Institute of
    Advance Technology (ICATSUC), Sarawak, Malaysia Hushairi Zen Department of Computer
    Science, University of South Australia, Adelaide, SA, Australia Naga M. Dasari
    Department of Electronics and Communication Engineering, Malla Reddy Engineering
    College for Women, Secunderabad, India Y. Madhavee Latha Department of Electronics
    and Communication Engineering, Malla Reddy College of Engineering and Technology,
    Hyderabad, Telangana, India S. Srinivasa Rao Rights and permissions Reprints and
    permissions Copyright information © 2024 The Author(s), under exclusive license
    to Springer Nature Singapore Pte Ltd. About this paper Cite this paper Singh,
    A., Bajaj, D., Safa, M., Arulmurugan, A., John, A. (2024). IoT-Based Smart Irrigation
    System in Aquaponics Using Ensemble Machine Learning. In: Zen, H., Dasari, N.M.,
    Latha, Y.M., Rao, S.S. (eds) Soft Computing and Signal Processing. ICSCSP 2023.
    Lecture Notes in Networks and Systems, vol 840. Springer, Singapore. https://doi.org/10.1007/978-981-99-8451-0_17
    Download citation .RIS.ENW.BIB DOI https://doi.org/10.1007/978-981-99-8451-0_17
    Published 17 February 2024 Publisher Name Springer, Singapore Print ISBN 978-981-99-8450-3
    Online ISBN 978-981-99-8451-0 eBook Packages Intelligent Technologies and Robotics
    Intelligent Technologies and Robotics (R0) Share this paper Anyone you share the
    following link with will be able to read this content: Get shareable link Provided
    by the Springer Nature SharedIt content-sharing initiative Publish with us Policies
    and ethics Download book PDF Download book EPUB Sections Figures References Abstract
    Introduction Literature Review Architecture Diagram Methodology Components Used
    Implementation Results Conclusion References Author information Editor information
    Rights and permissions Copyright information About this paper Publish with us
    Discover content Journals A-Z Books A-Z Publish with us Publish your research
    Open access publishing Products and services Our products Librarians Societies
    Partners and advertisers Our imprints Springer Nature Portfolio BMC Palgrave Macmillan
    Apress Your privacy choices/Manage cookies Your US state privacy rights Accessibility
    statement Terms and conditions Privacy policy Help and support 129.93.161.219
    Big Ten Academic Alliance (BTAA) (3000133814) - University of Nebraska-Lincoln
    (3000134173) © 2024 Springer Nature"'
  inline_citation: '>'
  journal: Lecture Notes in Networks and Systems
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: IoT-Based Smart Irrigation System in Aquaponics Using Ensemble Machine Learning
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Tshakwanda P.M.
  - Kumar H.
  - Arzo S.T.
  - Devetsikiotis M.
  citation_count: '0'
  description: 'In the imminent era of 6G dominance and the expanding realm of interconnected
    IoT devices, ensuring seamless connectivity is vital. This paper introduces the
    Scalable and Efficient DevOps (SE-DO) methodology - a scalable multi-agent system
    designed for next-gen networks. SE-DO''s avant-garde architecture dynamically
    integrates new agents, mirroring evolving IoT ecosystems. Two sets of agents manage
    vast IoT data in urban matrices: extraction agents collect, and preprocessing
    agents refine for computational tasks. Anticipating 6G''s prowess, training agents
    optimize machine learning models for real-time traffic analytics. Augmented by
    predictor agents, SE-DO prioritizes accuracy, efficiency, and security, validated
    empirically. SE-DO''s adaptability ensures scalable proficiency amid IoT integrations,
    facilitating a smooth transition to the 6G era. Addressing IoT challenges, SE-DO,
    rooted in a robust multi-agent system, optimizes agent performance in resource-constrained
    environments. Real-world experiments highlight SE-DO''s high accuracy and efficiency,
    making it pivotal for future network optimization. Access SE-DO''s future on GitHub
    - where innovation meets accessibility. As next-gen networks demand reliable solutions,
    SE-DO emerges as an indispensable tool for navigating emergent network paradigms.'
  doi: 10.1109/CCWC60891.2024.10427717
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >2024 IEEE 14th Annual Computi... SE-DO:
    Navigating the 6G Frontier with Scalable and Efficient DevOps for Intelligent
    Agents Optimization Publisher: IEEE Cite This PDF Petro M. Tshakwanda; Harsh Kumar;
    Sisay T. Arzo; Michael Devetsikiotis All Authors 51 Full Text Views Abstract Document
    Sections I. Introduction II. Related Work III. SE-DO: Adaptive Agent Deployment
    in Environments with Limited Resources IV. Experimental Evaluations V. Conclusion
    Authors Figures References Keywords Metrics Abstract: In the imminent era of 6G
    dominance and the expanding realm of interconnected IoT devices, ensuring seamless
    connectivity is vital. This paper introduces the Scalable and Efficient DevOps
    (SE-DO) methodology—a scalable multi-agent system designed for next-gen networks.
    SE-DO’s avant-garde architecture dynamically integrates new agents, mirroring
    evolving IoT ecosystems. Two sets of agents manage vast IoT data in urban matrices:
    extraction agents collect, and preprocessing agents refine for computational tasks.
    Anticipating 6G’s prowess, training agents optimize machine learning models for
    real-time traffic analytics. Augmented by predictor agents, SE-DO prioritizes
    accuracy, efficiency, and security, validated empirically. SE-DO’s adaptability
    ensures scalable proficiency amid IoT integrations, facilitating a smooth transition
    to the 6G era. Addressing IoT challenges, SE-DO, rooted in a robust multi-agent
    system, optimizes agent performance in resource-constrained environments. Real-world
    experiments highlight SE-DO’s high accuracy and efficiency, making it pivotal
    for future network optimization. Access SE-DO’s future on GitHub—where innovation
    meets accessibility. As next-gen networks demand reliable solutions, SE-DO emerges
    as an indispensable tool for navigating emergent network paradigms. Published
    in: 2024 IEEE 14th Annual Computing and Communication Workshop and Conference
    (CCWC) Date of Conference: 08-10 January 2024 Date Added to IEEE Xplore: 13 February
    2024 ISBN Information: DOI: 10.1109/CCWC60891.2024.10427717 Publisher: IEEE Conference
    Location: Las Vegas, NV, USA Funding Agency: SECTION I. Introduction The telecommunications
    landscape has rapidly transformed with the emergence of 5G networks, setting the
    stage for the impending arrival of 6G networks. Envisioned to surpass their forerunners,
    6G networks pledge faster data speeds, decreased latency, robust security, and
    unparalleled compatibility with cutting-edge technologies like immersive media
    and the Internet of Things (IoT). As the intricacy of interconnected devices and
    communication patterns intensifies, the traditional microservice-based design
    encounters limitations, impeding its adaptability to the dynamic requirements
    of next-gen networks [1]. This inflexibility may result in inefficient resource
    utilization and scalability concerns, necessitating innovative design approaches
    to unlock the full potential of 6G networks. To address these challenges, a modular
    design supported by multi-agents emerges as a promising solution, providing increased
    flexibility, adaptability, and fault tolerance. This agent-oriented approach becomes
    pivotal in intelligent network design, essential for resilience and adaptability
    amid swift changes in traffic behavior and diverse application demands in next-gen
    networks. However, the deployment of intelligent agents within resource-constrained
    environments, a challenge frequently encountered in the Internet of Things (IoT),
    poses a significant and formidable hurdle [2]. In recognition of this challenge,
    the present paper introduces the Scalable and Efficient Development Operations
    (SE-DO) methodology. This methodology is conceived as a comprehensive and strategic
    approach explicitly designed to enhance the performance of intelligent agents
    operating within the constraints of resource-restricted environments. By introducing
    SE-DO, this research responds to the pressing need for sophisticated and adaptive
    solutions, addressing the inherent difficulties associated with deploying intelligent
    agents in environments characterized by limited resources. The SE-DO methodology
    is poised as a significant advancement in optimizing intelligent agent operations,
    offering a holistic framework to tackle the unique challenges posed by resource
    constraints in environments like the IoT. Despite prior efforts in proposing network
    architectures for next-gen networks, a noticeable divergence remains between theoretical
    concepts and their practical applications [3]. This gap poses a challenge in realizing
    the full potential of these conceptual frameworks in real-world scenarios. The
    SE-DO methodology presented in this study emerges as a crucial bridge addressing
    this disparity. By introducing a multi-agent intelligent network system, specifically
    tailored for environments constrained by the Internet of Things (IoT), SE-DO not
    only narrows the theoretical-practical gap but also aligns with the practical
    intricacies and challenges presented by IoT-constrained environments. This deliberate
    alignment ensures that the SE-DO methodology is not merely a conceptual framework
    but a tangible and applicable solution, marking a significant step towards the
    seamless integration of theoretical advancements into practical, real-world network
    architectures. This paper delivers the following key contributions: Introduction
    of the SE-DO methodology as a comprehensive approach for optimizing intelligent
    agent performance in resource-restricted IoT environments. Bridging the gap between
    theoretical concepts and practical applications in the domain of network architectures
    for next-gen networks. Provision of a modular design strategy supported by multi-agents
    for increased flexibility, adaptability, and fault tolerance in intelligent network
    systems. Presentation of a practical framework for deploying intelligent network
    systems in constrained IoT contexts, with real-world applicability. The subsequent
    sections explore related works, the core SE-DO methodology, experimental evaluations,
    and the overarching implications of this framework. The paper concludes by summarizing
    the notable contributions of SE-DO, paving the way for future research and advancements
    in networking. SECTION II. Related Work This section extensively explores the
    deployment of intelligent agents in resource-limited environments, emphasizing
    challenges and inventive solutions. Integrating intelligent agents, especially
    in Internet of Things (IoT) networks, encounters significant obstacles due to
    restricted CPU, memory, and storage capacities, as well as limitations in data
    collection, storage, and communication latency. Pioneering research has diligently
    tackled these challenges, focusing on optimizing computational, storage, and communication
    resources while ensuring high agent performance. A. Comparison: Multi-Agent and
    Microservices Systems The widely embraced microservices paradigm in cloud applications
    offers advantages such as scalability, upgradability, fault tolerance, and efficient
    testing. Despite its merits, there are persistent challenges associated with decomposition,
    orchestration, communication, and integration testing overheads. On the other
    hand, the agent-based approach, grounded in autonomous agents with interactive
    capabilities, proves beneficial in dynamic and unpredictable settings. This approach
    excels in overseeing intricate and dispersed systems, minimizing the reliance
    on centralized coordination. Furthermore, the agent-based model stands out as
    particularly well-suited for the development of intelligent and adaptive systems.
    Its inherent structure seamlessly integrates advanced machine learning and artificial
    intelligence (AI) technologies, providing a fertile ground for the implementation
    of autonomous adaptation mechanisms. This unique combination of the agent-based
    model with cutting-edge technologies empowers systems to dynamically adjust and
    evolve based on changing environmental conditions and emerging patterns. The incorporation
    of machine learning and AI not only enhances the adaptability of the system but
    also contributes to the overall intelligence, enabling autonomous decision-making
    and responses in dynamic and unpredictable scenarios. In essence, the agent-based
    model becomes a robust foundation for the development of systems that possess
    not only intelligence but also the capacity for continuous learning and self-improvement.
    Despite its complexity and potential security concerns, the agent-based model
    emerges as a compelling alternative for dynamic and intelligent systems [4], [5].
    Table I presents a comprehensive synthesis of microservices and multi-agent system
    definitions, elucidating the correlation between the principles of microservices
    and MAS. B. Intelligent Agent Deployment in Environments with Limited Resources:
    Issues and Resolutions In environments where computational resources are constrained,
    the challenge of scarcity necessitates innovative solutions. A pioneering work
    by Han et al. [6] introduced deep compression techniques for neural networks,
    strategically balancing resource usage while preserving optimal agent performance.
    Similarly, He et al. [7] proposed channel pruning methods specifically tailored
    to conserve computational resources in convolutional neural networks. Addressing
    storage constraints, Han et al. [6] and Wen et al. [8] independently contributed
    by introducing deep compression and weight quantization methods, respectively.
    These methodologies aim to reduce storage requirements without compromising the
    efficiency of intelligent agents, providing crucial advancements in optimizing
    resource utilization in resource-limited settings. The challenges posed by communication
    bandwidth limitations have been systematically addressed in notable studies. Lee
    et al. [9] and Lin et al. [10] proposed effective approaches involving compression
    and weight quantization, demonstrating successful mitigation of bandwidth requirements.
    Another significant contribution by Mao et al. [11] focused on overcoming challenges
    related to data collection, storage, and latency through innovative data compression
    techniques. In contrast, Wang et al. [12] introduced a distributed training method,
    strategically reducing both storage demands and training latency. Despite the
    promises associated with enhanced network performance through the integration
    of multi-agent systems and machine learning techniques, inherent challenges such
    as increased complexity and potential underperformance emerge. To address these
    concerns, compelling strategies include streamlining cognitive components, enhancing
    computational efficiency, and implementing adaptable decision-making frameworks.
    Enhancing precision in decision-making and accuracy is achieved through the integration
    of fault-tolerant functionalities and advanced data analytics techniques. This
    paper presents \"SE-DO,\" an innovative and holistic methodology designed to cover
    the entire ecosystem. SE-DO establishes a harmonious equilibrium by addressing
    aspects such as the reliability of data collection and analytic agents, the accuracy
    of training and prediction agents, and environmental constraints. By providing
    practical and scalable solutions, SE-DO makes a substantial contribution to the
    field, positioned to improve network performance across a range of applications.
    SECTION III. SE-DO: Adaptive Agent Deployment in Environments with Limited Resources
    SE-DO, an innovative and highly scalable methodology, is designed to effortlessly
    accommodate additional agents in alignment with the evolving objectives of the
    system. Within our innovative architectural framework, we incorporate secure data
    collection agents with the primary responsibility of compiling data. Simultaneously,
    preprocessing agents play a crucial role in refining the compiled data for subsequent
    analysis or training stages. The collaborative efforts of training agents involve
    leveraging this meticulously preprocessed data to optimize machine learning models.
    Additionally, the integration of predictor agents enhances the system’s capability
    to generate real-time predictions. TABLE I: Comparison of Microservices and MAS.
    This dynamic and efficient architectural design is strategically engineered to
    ensure a superior level of accuracy, efficiency, and security. These attributes
    are meticulously maintained and fine-tuned within the specified resource constraints,
    showcasing the adaptability and scalability of the system. The comprehensive approach
    of our architecture positions it as an advanced and promising solution for the
    challenges posed by next-generation network environments. SE-DO emerges as a robust
    contender, poised to meet the evolving demands of the dynamic and sophisticated
    networks of the future. Our innovative approach addresses resource constraints,
    consistently delivering exceptional levels of accuracy, efficiency, and security.
    SE-DO remains perpetually adaptable to fluctuations in network conditions, ensuring
    ongoing updates and optimal performance of the intelligent network system. Illustrated
    in Fig. 1 (SE-DO Workflow), our methodology unfolds as a series of continuous
    processes, encompassing data collection, analysis, training, and prediction. This
    orchestrated sequence ensures the perpetual advancement of our intelligent system.
    With a deliberate focus on crafting a seamless workflow meticulously designed
    for the development and deployment of intelligent agents within resource-constrained
    environments, SE-DO accentuates the pivotal role played by its key components.
    These components serve as the foundational pillars that underpin the effectiveness
    and adaptability of the workflow. Their strategic placement and interaction contribute
    to the harmonious progression of processes, ensuring that each stage seamlessly
    integrates into the next. In essence, the SE-DO methodology encapsulates a holistic
    and dynamic approach, where the continuous workflow becomes instrumental in optimizing
    the capabilities of intelligent agents within challenging resource limitations.
    These components play a critical role in enabling the continuous development,
    deployment, and monitoring of intelligent agents, ensuring a streamlined and adaptive
    process. A strategic approach is employed in the placement of various agent types
    throughout the SE-DO lifecycle. This strategic placement serves to optimize and
    guarantee effective operations, particularly tailored to function seamlessly within
    the inherent limitations of resource-constrained environments. The orchestrated
    integration of SE-DO’s key components not only ensures operational efficiency
    but also attests to its adaptability, presenting a robust solution that aligns
    with the evolving landscape of constrained resource environments. A. Dynamic Agent
    Lifecycle Orchestration for Resource-Constrained Environments In this innovative
    strategy for managing the lifecycle of intelligent agents in environments with
    limited resources, our approach consists of four crucial agent categories strategically
    placed throughout the lifecycle to optimize development, deployment, and monitoring
    processes. The Data Collector Agent operates in the Continuous Integration (CI)
    phase, ensuring seamless integration and code change testing. Swift identification
    and correction of potential issues enhance the development process. During the
    Continuous Delivery (CD) phase, the Data Analytics or Preprocessing Agent oversees
    an automated deployment process specifically designed for resource-constrained
    environments, ensuring reliability, efficiency, and scalability in the everevolving
    digital landscape. Situated strategically within the Infrastructure as Code (IaC)
    phase, the Data Training Agent plays a pivotal role by leveraging microservices
    to oversee the deployment of agents. This strategic approach capitalizes on the
    concept of treating infrastructure as code, offering a streamlined and scalable
    management framework. The utilization of microservices ensures that the deployment
    process is not only efficient but also adaptable to the dynamic needs of the system.
    Moving forward, in the subsequent Monitoring and Logging phase, the role of the
    Data Predictor Agent becomes instrumental. This agent is dedicated to facilitating
    real-time performance tracking, both at the individual agent level and across
    the entire system. By leveraging logs and metrics, the Data Predictor Agent operates
    as a vigilant overseer, promptly identifying and resolving operational issues.
    This proactive approach significantly contributes to enhancing the overall efficiency
    and effectiveness of the system. It ensures that the system operates at peak performance
    by swiftly addressing any anomalies or challenges that may arise during the operation.
    In essence, the coordination of these agents across different phases establishes
    a robust framework for seamless system management and optimization. Fig. 1: SE-DO
    Approach: a cyclical process using multiple agents per stage with embedded DevOps
    principles. Show All Our dynamic agent lifecycle orchestration presents a pioneering
    solution for navigating resource limitations while optimizing the performance
    and adaptability of intelligent agents in diverse applications. The integration
    of an array of specialized agents, inclusive of Quality of Service (QoS) agents,
    is facilitated through the SE-DO model, making it an all-encompassing strategy
    for network administration in up-and-coming networks such as 6G. Central to the
    tenets of the SE-DO framework is the insistence on regular amalgamation and examination
    of code modifications. This anticipatory measure provides a platform for the timely
    recognition and resolution of potential hurdles during the developmental phase,
    guaranteeing a robust and dependable network milieu. Further, the deployment of
    intelligent agents, specifically within environments with limited resources, is
    mechanized by the SE-DO model. Such mechanization lessens manual input, thereby
    mitigating the likelihood of inaccuracies and leading to a swifter and more effective
    institution of network management solutions. Integral to the SE-DO paradigm is
    its emphasis on collaboration and communication among team members. The achievement
    of a successful multi-agent system is contingent on effective teamwork. By endorsing
    the exchange of knowledge, coordination, and synergy, the SE-DO framework cultivates
    a cooperative workspace that augments the efficacy of network management initiatives.
    The SE-DO model is founded on real-time performance tracking and logging. These
    methods ensure that operational issues are swiftly identified and rectified, thereby
    guaranteeing ongoing network performance optimization. The mechanization of testing,
    deployment, and monitoring processes by the model not only minimizes errors but
    also streamlines operations and improves overall system efficacy. Such automation
    allows the system to dynamically scale and adjust to the increasing demands of
    emerging services and applications. Through the adoption of the SE-DO model, the
    development and deployment of intelligent agents in resource-limited settings
    become a cyclic and iterative process. Such repetition assures scalability, reliability,
    and efficiency, meeting the stringent requisites of forthcoming networks. Network
    administrators are provided with an exhaustive framework by the SE-DO model to
    overcome resource limitations and manage complex network environments effectively.
    It guarantees the delivery of high-performance network services, satisfying the
    evolving needs of emerging applications and services. B. Cognitive Enhancement
    for Scalable and Adaptive Agent Deployment Building upon the foundational principles
    of SE-DO, our research advances the internal architecture of agents, as depicted
    in Fig. 2, through the integration of sophisticated cognitive components, ushering
    in a new era of decision-making capabilities in network management [1], [4], [13].
    This innovative augmentation represents a transformative enhancement that endows
    agents with robust capabilities in handling inputs and outputs. This empowerment
    ensures that agents possess the capabilities to meticulously monitor and analyze
    the dynamic state of the network. Furthermore, the enhanced agents exhibit a heightened
    ability to exert fine-tuned control over various aspects of the network. This
    augmentation not only bolsters the overall proficiency of agents but also underscores
    their adaptability and effectiveness in dynamically responding to the intricacies
    of the network environment. The refined input and output proficiencies contribute
    to a more sophisticated and nuanced understanding of network dynamics, ultimately
    elevating the agents’ capacity to make informed decisions and interventions within
    the network landscape. The core of this cognitive enhancement lies in the integration
    of advanced components that elevate the intellectual capabilities of agents. These
    components serve as the intellectual core, facilitating strategic and informed
    decision-making based on the assimilation of knowledge. The decision outcomes
    transform actionable tactics through the planning component, while the validation
    component operates as a vital checkpoint, verifying the suitability of enacted
    actions. This layered approach to network automation ensures unparalleled precision,
    efficacy, and reliability in network management, as illustrated in Fig. 2. The
    figure highlights the agents’ proficiency in administering the network in compliance
    with predetermined requisites. By implementing this groundbreaking architecture,
    our research pioneers the optimization of network management, guaranteeing a more
    efficient and dependable network for users. SECTION IV. Experimental Evaluations
    A. Validating SE-DO in Real-world 6G Network Configurations To assess the SE-DO
    framework’s performance in real-world 6G network configurations, extensive experimental
    evaluations were conducted. Using NetSim version 13.3, the experiment employed
    Raspberry Pi devices to emulate data-gathering entities [14], creating a dynamic
    6G network representation. The OsBrain framework facilitated distributed computing
    setups, utilizing Docker images for multi-agent structures. In the Docker environment,
    smart agents communicated seamlessly through the RESTful API, promoting loose
    component coupling and enabling horizontal system expansion without a centralized
    broker. Despite the absence of a formal worldwide 6G network specification as
    of November 2023, the Docker-enabled multi-agent model anticipates potential aspects
    of future 6G networks. The Postman application managed API calls, overseeing performance
    monitoring, and Docker’s containerized structure permitted agent operation across
    varied machines or clusters, promoting effective resource usage and fault tolerance.
    The micro-service approach via OsBrain ensured scalability, resilience, and data
    security, highlighting the advantages of the model. This approach allows in-depth
    understanding and optimization of 6G network performance, adapting effectively
    to real-world network conditions. The experimental evaluations aim to validate
    the practicality and efficacy of the SE-DO framework, providing valuable insights
    into its real-world applicability B. Dataset In crafting our experimental blueprint,
    we capitalized on a dynamic, self-adjusting network configuration, as depicted
    in Fig. 3, mirroring the inherent complexity of 6G networks. The continuous flow
    of information from a consortium of Raspberry Pi devices, functioning as data
    acquisition entities, faithfully represents real-time network conditions with
    an unprecedented level of fidelity. These components meticulously document network
    oscillations, becoming indispensable elements in fabricating an authentic 6G network
    representation within the NetSim virtual platform. An assortment of network parameters
    is extracted from the harvested information, encapsulating rudimentary data such
    as data packet dimensions. Integral metrics, including training and validation
    deficits, precision in training and validation, mean deviation in prognoses, and
    total prognostic precision, are compiled. The comprehensiveness of this data repository
    is vital for enhancing the precision and reliability of the subsequent analysis
    and optimization stages, significantly contributing to the overall efficacy of
    our proposed model. C. Scalable, Resilient, and Efficient: Unveiling the Performance
    of Multi-Agent Systems in 6G-IoT Networks through the SE-DO Framework The study
    introduces a smart, multi-agent system through the SE-DO framework designed for
    critical operations in 6G-IoT networks. Four expert agents—Data Collector, Data
    Analytic, Model Training, and Model Evaluation—are deployed, each empowered with
    machine learning methodologies for optimal efficiency. The Data Collector Agent
    employs the Scapy and Pulp libraries to extract key attributes, targeting cost
    reduction in data acquisition. The Data Analytic Agent improves data quality by
    handling missing entries, converting non-numeric fields, standardizing features,
    and employing onehot encoding for categorical elements. The Model Training Agent
    utilizes Artificial Neural Networks, Convolutional Neural Networks, and Recurrent
    Neural Networks with dropout regularization, fostering a conducive environment
    for machine learning. The Model Evaluation Agent rigorously appraises trained
    models, anticipating future data trends while minimizing energy, computational
    resources, and memory utilization. Together, these agents enhance data governance
    efficiency, offering valuable insights into machine-learning model effectiveness,
    and exhibiting resilience, scalability, and operational efficiency in 6G networks.
    The Data Collector Agent maintains vigilance for an optimal balance between data
    acquisition and resource usage. The Model Training Agent adapts to data variations,
    continually enhancing model precision. The Model Evaluation/Predictor Agent provides
    real-time model performance analysis, reacting promptly to changes. The SE-DO
    framework’s Data Collector Agent is illustrated in Algorithm 1, demonstrating
    efficiency in optimizing data gathering for intelligent agent operations in resource-constrained
    IoT networks. Blessed with intrinsic flexibility and adaptability, our multi-agent
    system exhibits resilience to the rising demands of future network generations.
    It sets a new standard in intelligent networking, thus positioning itself as a
    compelling benchmark in the forthcoming 6G era. Fig. 2: Cognitive-Driven Agent
    Architecture: Internal structure integrating cognitive, planning, and validation
    components for informed decision-making in network management. Adapted from [1].
    Show All Algorithm 1 Efficient Multi-Objective Optimization Algorithm for Network
    Data Collection Our investigation targets the issues related to the monumental
    data influx triggered by interconnected Internet of Things (IoT) devices and the
    intricate nature of forthcoming network generations, such as 6G. Proposing SE-DO
    (Scalable and Efficient DevOps), a proficient and expandable solution, this study
    aims to enhance the efficacy of smart agents operating within IoT realms that
    are innately resource-limited. We scrutinized the effectiveness of three divergent
    model architectures (Convolutional Neural Networks, Artificial Neural Networks,
    and Recurrent Neural Networks) across a spectrum of packet sizes within two distinct
    deployment tactics: service-micro based and agent-centered. D. Scalability Analysis
    Scalability in a system refers to its inherent capability to uphold or even elevate
    performance when supplemented with additional resources such as data or memory.
    Pertaining to our Multi-Agent System (MAS), the models exhibited profound scalability
    traits. As data packet size expanded, the performance of models surged, as observed
    in both service-micro and agent-centric approaches, as illustrated in Tables II
    and III. This performance enhancement was discernible in several metrics, including
    a downturn in training and validation losses, and a climb in accuracies. Specifically,
    the agent-oriented approach surpassed the micro-service approach consistently,
    primarily when data packet sizes swelled. This implies the superior scalability
    inherent in the agent-based method, promising potential advantages for MAS deployments
    that need to manage more substantial data loads. Similarly, prediction precision
    and mean absolute error (MAE) exhibited advancement as packet sizes rose, further
    substantiating the scalability of the proposed approaches (as shown in Fig. 4).
    Fig. 3: Illustration of 6G network setup: Raspberry Pi devices, NetSim simulation,
    and OsBrain multi-agent configurations. Show All Fig. 4: Comparing accuracy: Microservices
    vs. Agent-based strategies across CNN, ANN, and RNN networks. Show All E. In-depth
    Analysis of Data Collection Agents: Comparative Assessments on Resource Allocation,
    Energy Utilization, and Cost Dynamics Drawing upon the data gathered and presented
    in Tables IV and V, and exemplified beautifully in Fig. 5, several pertinent observations
    can be deduced, thereby steering the decision-making process related to the allocation
    of resources, enhancement of energy efficiency, optimization of memory requirements,
    application of processing power, time management, and cost considerations tied
    to data gathering. The methodology built on Micro-services manifests a more pronounced
    resource allocation, as exemplified by the greater quantities of accumulated data,
    energy usage, memory deployment, and processing capabilities. In contrast, the
    Agent-based strategy showcases superior prowess in optimizing energy use, thereby
    curtailing the overall consumption of energy. Additionally, the Agent-based methodology
    demonstrates significant benefits in limiting memory necessities, leading to more
    efficient memory management. While the data-gathering duration showcases negligible
    variation between the two techniques, it is important to highlight that the Micro-services-centric
    method stipulates greater processing capabilities. Most notably, the monetary
    implications associated with data gathering are substantially escalated when the
    Micro-services-oriented technique is employed, leading to increased expenditure.
    Such insights pave the way for well-rounded decision-making, granting stakeholders
    the discretion to either underscore resource allocation and versatility or to
    hone in on the twin facets of energy efficiency and cost containment, subject
    to their individual targets and operational limitations. F. Communication Delays
    Analysis between Agents The analysis of inter-agent communication delays within
    a RESTful API framework, measured in microseconds (µs), is detailed in Table VI.
    These microsecond-level metrics serve as a foundation for understanding and optimizing
    message exchange efficiency to mitigate latency in agent-centric architectures.
    The tabulated results offer nuanced observations of delay durations across diverse
    agent pairs and varying packet magnitudes. TABLE II: Scalability and Resilience
    Analysis (Microservices-based Strategy) TABLE III: Scalability and Resilience
    Analysis (Agent-based Strategy) This rigorous investigation has implications for
    academia and industry, providing crucial insights to enhance communication process
    performance and reduce latencies, thereby strengthening the robustness of agent-oriented
    systems. Applying this knowledge can accelerate the evolution of smart systems,
    fostering seamless communication among agents operating across various fields.
    In this analysis, NTCA refers to Network Traffic Classifier Agent, NTPA to Network
    Traffic Preprocessing Agent, NTTA to Network Traffic Training Agent, and NTPrA
    to Network Traffic Predictor Agent. Fig. 5: Data Collector Agents (f(x)) performance
    across varied dataset sizes. Upper graph: Microservices-based. Lower graph: Agent-based.
    Show All SECTION V. Conclusion This paper introduces the Scalable and Efficient
    DevOps (SE-DO) framework as a groundbreaking advancement for intelligent agents
    in resource-constrained IoT networks. SE-DO, rooted in a robust multi-agent system
    architecture, offers a dual promise of reactive responses and proactive anticipation.
    The framework addresses the complexities of the evolving IoT landscape, advocating
    for autonomous, intelligent networks with self-management, self-healing, and self-configuration
    capabilities. Positioned as a transformative strategy, SE-DO is highlighted for
    its adaptability in the transition from 5G to 6G networks, providing a dynamic,
    multi-agent-supported modular design. The integration of machine and deep learning
    algorithms is emphasized as a roadmap for addressing challenges and solutions
    in resource-limited environments. SE-DO is presented not just as a strategy but
    as a comprehensive approach for optimizing network management in emerging systems
    like 6G. Its unique architecture, adaptivity to network conditions, and collaborative
    issue resolution make it stand out. The paper emphasizes the innovative optimization
    strategy for data collection agents, setting a new standard for resource utilization
    and energy consumption within the objective function. TABLE IV: Data collector
    agent f(x) performance across varied dataset sizes (Agent-based approach). TABLE
    V: Variation in data collector agent f(x) performance across diverse dataset sizes
    (Microservices-based approach). TABLE VI: Communication delay via RESTful API
    (in µs) between different agents. The SE-DO framework is positioned to transcend
    conventional approaches, offering a holistic solution to the challenges of intelligent
    agents in resource-constrained IoT networks. It not only promises efficiency but
    envisions a paradigm shift in network management, preparing for unprecedented
    advancements. The conclusion outlines the overarching implications of SE-DO and
    its potential to usher in a new era of self-aware, adaptive networks. The paper’s
    contributions are twofold: the introduction and successful implementation of the
    SE-DO framework and the establishment of a benchmark for evaluating AI performance
    in emerging network architectures. Future research directions are suggested to
    explore the nuanced interplay of intelligent agents in dynamic environments, extending
    and adapting SE-DO. Additionally, integrating emerging technologies and refining
    optimization techniques are identified as exciting avenues for ongoing exploration.
    ACKNOWLEDGMENT This study is partially funded by the U.S. National Science Foundation
    through the cooperative agreement Grant OIA1757207 within the framework of the
    New Mexico SMART Grid Center - EPSCoR. Authors Figures References Keywords Metrics
    More Like This Smart house simulation based multi-agent system and internet of
    things 2017 International Conference on Mathematics and Information Technology
    (ICMIT) Published: 2017 Extended multi-agent system based service composition
    in the Internet of things 2018 3rd International Conference on Pattern Analysis
    and Intelligent Systems (PAIS) Published: 2018 Show More IEEE Personal Account
    CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS
    Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL
    INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT
    & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms
    of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy
    Policy A not-for-profit organization, IEEE is the world''s largest technical professional
    organization dedicated to advancing technology for the benefit of humanity. ©
    Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: 2024 IEEE 14th Annual Computing and Communication Workshop and Conference,
    CCWC 2024
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'SE-DO: Navigating the 6G Frontier with Scalable and Efficient DevOps for
    Intelligent Agents Optimization'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors: []
  citation_count: '0'
  description: 'The proceedings contain 33 papers. The special focus in this conference
    is on Artificial Intelligence and Communication Technology. The topics include:
    Optimal Design of Hydrodynamic Journal Bearing Based on BP Neural Network Optimized
    by Improved Particle Swarm Algorithm; the Intelligent Human–Computer Interaction
    Method for Application Software of Electrical Energy Metering Based on Deep Learning
    Algorithm; Short Text Classification of Invoices Based on BERT-TextCNN; design
    of Fully Automatic Calibration Scheme for Load Box Based on Visual Recognition;
    deepScan: Revolutionizing Garbage Detection and Classification with Deep Learning;
    Chapter 16 Research on Portable Methane Telemetry System Based on TDLAS; Recommendation
    Algorithm Based on Wide&Deep and FM; simulation of E-Commerce Big Data Classification
    Model Based on Artificial Intelligence Algorithm; research and Implementation
    of Data Feature Extraction Technology for Multisource Heterogeneous Data in Electric
    Distribution Network; extraction and Fusion of Geographic Information from Multi-source
    Remote Sensing Images Based on Artificial Intelligence; chapter 20 Design and
    Optimization of Business Decision Support System Based on Deep Learning; performance
    Evaluation of Container Identification Detection Algorithm; application and Prospect
    of Deep Learning and Machine Learning Technology; chapter 23 Simulation of Intelligent
    Image Processing Model Based on Machine Learning Algorithm; Chapter 24 Design
    and Implementation of a Health Monitoring Management Platform Based on IoT and
    DL; chapter 25 Design of Hospital Equipment Information Management System Based
    on Computer Vision Technology; chapter 26 Design and Implementation of an Internet
    of Things-Based Real-Time Five-Layer Security Surveillance System; chapter 27
    Logistics Security Integrated Communication System Under the Background of 5G
    Artificial Intelligence.'
  doi: null
  full_citation: '>'
  full_text: '>'
  inline_citation: '>'
  journal: Smart Innovation, Systems and Technologies
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: International Conference on Artificial Intelligence and Communication Technology,
    ICAICT 2023
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Kawalkar S.A.
  - Bhoyar D.B.
  citation_count: '0'
  description: In the current era of cloud computing where most of the Organizations
    are shifting from local Infrastructure to Cloud network and hence Cloud security
    where most of sensitive data is stored is one of the key concerns for highly scalable
    and critical network deployments. As there is high increase in the use of cloud
    networks and computing because of simple Virtual machines and containers, the
    necessity for strong and stringent security measures to protect against complex
    cyber-attacks is very important than it was few years before.. Traditional cloud
    security models often grapple with limitations such as centralized data vulnerabilities,
    static security policies, and inadequate access control mechanisms. Cyber-attacks
    are getting complex and impacting organization with critical information and business
    loss. Dark Web attacks are more sophisticated and impacting tactically via various
    ways and mechanisms on cloud. The paper surveys the state-of-the-art in cloud
    n etwork and infrastructure security models and essentially evaluates their performance
    based on various risks, threats, vulnerabilities and empirical dataset collection
    and samples. The paper discusses the advantages and disadvantages of each model
    and highlights their suitability for different types of attacks. To address these
    challenges, this research introduces a groundbreaking complex and stringent security
    techniques and security framework, synergizing Federated Learning, Blockchain
    technology, AI-Driven Security Policy Management, and Zero Trust Network Access
    (ZTNA) principles. The proposed model leverages Federated Learning to decentralize
    machine learning processes, thereby safeguarding data privacy and minimizing the
    risks associated with centralized data repositories. Concurrently, the integration
    of Blockchain technology ensures immutable and transparent transaction records,
    enhancing the integrity and trustworthiness of cloud interactions. Complementing
    these, AI-Driven Security Policy Management, employing algorithms like Reinforcement
    Learning and Decision Trees, automates the generation and implementation of dynamic
    security policies. This AI-based approach is adept at responding to evolving threats
    and adapting to changing network conditions in real-time scenarios. Furthermore,
    the adoption of Zero Trust principles, operationalized through Software-Defined
    Perimeter frameworks, enforces a stringent 'never trust, always verify' approach.
    This paradigm shift is critical in fortifying access controls, effectively mitigating
    the risks of unauthorized access and insider threats. The interplay of these technologies
    culminates in a robust, resilient cloud security architecture sets. Empirical
    evaluation in varied cloud scenarios showcases notable enhancements in security
    metrics. The integrated model outperforms existing methods, achieving a 3.5% increase
    in precision, 4.9% in accuracy, 2.4% in recall, 3.5% in Area Under the Curve (AUC),
    and 1.9% in specificity, alongside a 4.5% reduction in response delay. These improvements
    signal a significant leap in cloud network security, offering a comprehensive
    solution to contemporary cyber threats. The impact of this work is profound, paving
    the way for more secure, reliable, and efficient cloud computing environments.
  doi: null
  full_citation: '>'
  full_text: '>'
  inline_citation: '>'
  journal: International Journal of Intelligent Systems and Applications in Engineering
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Design of an Efficient Cloud Security Model through Federated Learning, Blockchain,
    AI-Driven Policies, and Zero Trust Frameworks
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Rathore N.
  - Rajavat A.
  citation_count: '0'
  description: In today’s digital age, the Internet of Things (IoT) is gaining popularity.
    IoT has made everything smart, for example, smart cities (smart buildings and
    smart homes), smart healthcare (personal monitoring, smart wearables), industrial
    automation (especially manufacturing), commercial (shopping systems, retail),
    and even that agriculture too. IoT is becoming increasingly important in today’s
    digital age, resulting in a rapid rise in the number of devices connected to it.
    Massive amounts of data will be produced by such widely distributed IoT devices
    at the network’s edge. Processing these massive amounts of data in the centralized
    cloud is expected to result in increased 400bandwidth utilization, latency, and
    network congestion. Edge computing has become a popular paradigm in recent years
    for reducing network congestion and serving real-time IoT applications by providing
    services close to enduser devices. Agriculture is the foundation of the economy
    of any nation in the world. By 2050, the world population will need a 70% increase
    in food production to feed an estimated global population of more than 9 billion
    people. Potatoes are consumed all over the world and its production plays an important
    role in agriculture. The two primary diseases that adversely affect the yield
    of potato crop production are early blight and late blight. Therefore, in this
    work, we used containerized microservices to deploy machine learning models to
    resource restricted edge nodes on agricultural land for real-time disease and
    irrigation water requirement prediction in potato crops. Containers are lightweight
    and easy to deploy, making them the ideal choice for running machine learning
    models on resource-constrained edge nodes. We examined AlexNet, MobileNet, and
    VGG16, three deep convolutional neural networks (CNN), to detect these diseases
    automatically. A dataset of 7128 images containing healthy and diseased leaves
    of potato plants was used to train all three CNN models on the cloud. Even if
    training is outsourced, trained models need a lot of RAM; hence, the first aim
    of this study is to find a lightweight CNN model that can easily fit into resource-constrained
    devices. To improve potato crop yield and reduce economic losses, we found and
    deployed lightweight CNN model at the edge node to identify diseases in real time
    using leaf pictures recorded by in-place camera devices. The advantage of the
    developed technique is that by classifying potato leaf pictures in real time on-premises,
    there is no need to transfer images to the cloud for probable disease identification,
    which increases network congestion. The lightweight CNN model achieved 99.87%
    accuracy for both train and test images, according to the results. Precision (P),
    Recall (R), and F1 score (F1) are also displayed, to visualize the model’s efficiency.
    Similarly for real-time prediction of irrigation water requirement in potato crop,
    we trained two machine learning models, Support Vector Machine (SVM) and Logistic
    Regression (LR) on 100,000 values of records. Each record has four input parameters
    (soil moisture, temperature, humidity, and how many days the crop was planted
    before). With four input parameters in each record (soil moisture, temperature,
    humidity, and how many days before the crop was planted), the model decides whether
    the water pump should be turned on or off. The SVM model and the LR model attained
    92 and 73% accuracy, respectively, in determining whether the water pump should
    be turned ON or OFF.
  doi: 10.1201/9781003435228-24
  full_citation: '>'
  full_text: '>

    "Access Provided By:University of Nebraska-Lincoln T&F eBooks ‍ Advanced Search
    Login About Us Subjects Browse Products Request a trial Librarian Resources What''s
    New!! HomeEnvironment & AgricultureAgriculture & Environmental SciencesAgriculturePrecision
    Agriculture for SustainabilitySmart Farming Based on IOT-Edge Computing: Applying
    Machine Learning Models For Disease And Irrigation Water Requirement Prediction
    In Potato Crop Using Containerized Microservices Chapter Smart Farming Based on
    IOT-Edge Computing: Applying Machine Learning Models For Disease And Irrigation
    Water Requirement Prediction In Potato Crop Using Containerized Microservices
    ByNitin Rathore, Anand Rajavat Book Precision Agriculture for Sustainability Edition
    1st Edition First Published 2024 Imprint Apple Academic Press Pages 26 eBook ISBN
    9781003435228 Share ABSTRACT In today’s digital age, the Internet of Things (IoT)
    is gaining popularity. IoT has made everything smart, for example, smart cities
    (smart buildings and smart homes), smart healthcare (personal monitoring, smart
    wearables), industrial automation (especially manufacturing), commercial (shopping
    systems, retail), and even that agriculture too. IoT is becoming increasingly
    important in today’s digital age, resulting in a rapid rise in the number of devices
    connected to it. Massive amounts of data will be produced by such widely distributed
    IoT devices at the network’s edge. Processing these massive amounts of data in
    the centralized cloud is expected to result in increased 400bandwidth utilization,
    latency, and network congestion. Edge computing has become a popular paradigm
    in recent years for reducing network congestion and serving real-time IoT applications
    by providing services close to enduser devices. Agriculture is the foundation
    of the economy of any nation in the world. By 2050, the world population will
    need a 70% increase in food production to feed an estimated global population
    of more than 9 billion people. Potatoes are consumed all over the world and its
    production plays an important role in agriculture. The two primary diseases that
    adversely affect the yield of potato crop production are early blight and late
    blight. Therefore, in this work, we used containerized microservices to deploy
    machine learning models to resource restricted edge nodes on agricultural land
    for real-time disease and irrigation water requirement prediction in potato crops.
    Containers are lightweight and easy to deploy, making them the ideal choice for
    running machine learning models on resource-constrained edge nodes. We examined
    AlexNet, MobileNet, and VGG16, three deep convolutional neural networks (CNN),
    to detect these diseases automatically. A dataset of 7128 images containing healthy
    and diseased leaves of potato plants was used to train all three CNN models on
    the cloud. Even if training is outsourced, trained models need a lot of RAM; hence,
    the first aim of this study is to find a lightweight CNN model that can easily
    fit into resource-constrained devices. To improve potato crop yield and reduce
    economic losses, we found and deployed lightweight CNN model at the edge node
    to identify diseases in real time using leaf pictures recorded by in-place camera
    devices. The advantage of the developed technique is that by classifying potato
    leaf pictures in real time on-premises, there is no need to transfer images to
    the cloud for probable disease identification, which increases network congestion.
    The lightweight CNN model achieved 99.87% accuracy for both train and test images,
    according to the results. Precision (P), Recall (R), and F1 score (F1) are also
    displayed, to visualize the model’s efficiency. Similarly for real-time prediction
    of irrigation water requirement in potato crop, we trained two machine learning
    models, Support Vector Machine (SVM) and Logistic Regression (LR) on 100,000 values
    of records. Each record has four input parameters (soil moisture, temperature,
    humidity, and how many days the crop was planted before). With four input parameters
    in each record (soil moisture, temperature, humidity, and how many days before
    the crop was planted), the model decides whether the water pump should be turned
    on or off. The SVM model and the LR model attained 92 and 73% accuracy, respectively,
    in determining whether the water pump should be turned ON or OFF. Previous Chapter
    Next Chapter Your institution has not purchased this content. Please get in touch
    with your librarian to recommend this.  To purchase a print version of this book
    for personal use or request an inspection copy  GO TO ROUTLEDGE.COM  Policies
    Privacy Policy Terms & Conditions Cookie Policy Journals Taylor & Francis Online
    Corporate Taylor & Francis Group Help & Contact Students/Researchers Librarians/Institutions
    Connect with us Registered in England & Wales No. 3099067 5 Howick Place | London
    | SW1P 1WG © 2024 Informa UK Limited"'
  inline_citation: '>'
  journal: 'Precision Agriculture for Sustainability: Use of Smart Sensors, Actuators,
    and Decision Support Systems'
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'SMART FARMING BASED ON IOT-EDGE COMPUTING: APPLYING MACHINE LEARNING MODELS
    FOR DISEASE AND IRRIGATION WATER REQUIREMENT PREDICTION IN POTATO CROP USING CONTAINERIZED
    MICROSERVICES'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Hu L.
  - Kar P.
  citation_count: '0'
  description: A health monitoring system (HMS) is an integrated system that includes
    the sub-systems of health data gathering through sensors, health data analysis,
    and patient-doctor real-time communication. HMS allows patients to get medical
    care remotely, and doctors to provide real-time information to patients. The system
    not only reduces patients' time-cost, but also increases the quality of medical
    care. To solve the security problem of centralized management of data, blockchain
    technology has been introduced, as it contains the properties of immutability,
    transparency, and distribution. To take advantage of the blockchain network structure,
    this article proposes a system framework integrated with decentralized machine
    learning, aiming to improve the system performance in terms of throughput and
    model accuracy. It is a combination of the Hyperledger Fabric network and ModelChain
    model training method, where Hyperledger Fabric allows users to be grouped and
    managed in the form of organizations, while ModelChain uses the characteristics
    of grouped users to explore more valuable information. This article proposes the
    scheme to allow access control on a Hyperledger Fabric system and the algorithm
    to implement ModelChain on a Hyperledger Fabric network. Furthermore, the system
    is built and measured by tools, such as Hyperledger Caliper, Docker, and Weka,
    and is evaluated in terms of system throughput and accuracy.
  doi: 10.1109/MCOM.002.2300610
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Journals & Magazines >IEEE Communications Magazine >Volume:
    62 Issue: 1 Design of a Blockchain-Based Secure Health Monitoring System Using
    Decentralized Machine Learning Technique Publisher: IEEE Cite This PDF Longwen
    Hu; Pushpendu Kar All Authors 194 Full Text Views Abstract Document Sections Introduction
    Related Works Proposed System Design Simulation Results Conclusion Authors Figures
    References Keywords Metrics Abstract: A health monitoring system (HMS) is an integrated
    system that includes the sub-systems of health data gathering through sensors,
    health data analysis, and patient-doctor real-time communication. HMS allows patients
    to get medical care remotely, and doctors to provide real-time information to
    patients. The system not only reduces patients'' time-cost, but also increases
    the quality of medical care. To solve the security problem of centralized management
    of data, blockchain technology has been introduced, as it contains the properties
    of immutability, transparency, and distribution. To take advantage of the blockchain
    network structure, this article proposes a system framework integrated with decentralized
    machine learning, aiming to improve the system performance in terms of throughput
    and model accuracy. It is a combination of the Hyperledger Fabric network and
    ModelChain model training method, where Hyperledger Fabric allows users to be
    grouped and managed in the form of organizations, while ModelChain uses the characteristics
    of grouped users to explore more valuable information. This article proposes the
    scheme to allow access control on a Hyperledger Fabric system and the algorithm
    to implement ModelChain on a Hyperledger Fabric network. Furthermore, the system
    is built and measured by tools, such as Hyperledger Caliper, Docker, and Weka,
    and is evaluated in terms of system throughput and accuracy. Published in: IEEE
    Communications Magazine ( Volume: 62, Issue: 1, January 2024) Page(s): 46 - 52
    Date of Publication: 04 September 2023 ISSN Information: DOI: 10.1109/MCOM.002.2300610
    Publisher: IEEE Funding Agency: Introduction To take advantage of the block-chain
    network structure, the authors propose a system frame-work integrated with decentralized
    machine learning, aiming to improve the system performance in terms of throughput
    and model accuracy in health monitoring systems. Healthcare is always the major
    concern for everyone, which includes diagnosis, consultation as well as treatment.
    However, the modern hospital system is still facing the problem of being time-consuming
    and lack of timely medical care. An HMS has been considered as a forward leap
    to these issues, as it is an incorporated frame-work including distant-wellbeing
    information gathering, well-being information examination, and patient-specialist
    constant correspondences [1]. It acts as an alternative to the traditional management
    system of patients'' health data. An HMS achieves remote surveillance of a patient
    and can provide real-time communication with a doctor [2]. The system has already
    shown its strength in chronic disease monitoring [1]. However, since the system
    gathers user healthcare data, it makes the security of the system to be the main
    issue. Current HMS stores patients'' health data on a central server. This has
    threatened the system with confidentiality-based and availability-based attacks
    [3]. Arisen from this issue, blockchain technology has been introduced to integrate
    with HMS to protect data security. Blockchain technology consists of a distributed
    network, containing tamper-resistant data in forms, which guarantees all data
    in the system is secure and trusted [4]. It contains the properties of immutability,
    transparency, and distribution. To achieve these features, blockchain has its
    unique structure. In a block-chain network, all the data is stored as blocks in
    each node and each block is linked by containing the hash value of the previous
    block. Even if only making a small change in the previous block, the hash value
    in all subsequent blocks is changed. In this way, both the security and transparency
    of users'' data are preserved. In addition to managing patients'' data securely,
    data processing is also significant for an HMS. Data processing includes data
    analysis, which is often achieved on a central server. When doing the data analysis
    in a central server, it increased the possibility to threaten data security, also,
    it has the potential to face the problem of single-point failure and communication
    overhead [5]. Decentralized machine learning has been proposed to solve these
    problems as well as been evaluated to be feasible and integrated with blockchain-based
    HMS [6]. As proposed by Hathaliya et al. [7], an HMS integrated with both blockchain
    and decentralized machine learning can improve the quality of patient care, as
    the integrated system provides user preventive measures by decentralized machine
    learning and real-time communication with doctors. Besides, reliable data in blockchain
    networks helps to achieve better performance of decentralized machine learning,
    which can further support doctors to diagnose diseases. Motivation The existing
    HMSs have considered using block-chain techniques combined with machine learning
    to improve data security and system efficiency. However, as powered by blockchain''s
    unique features of immutability, finality, distributed ledger and transparency,
    existing HMSs are required to pay extra attention to maintaining data privacy
    as well as designing a feasible pipeline for patient-doctor communication integrated
    with machine learning model training. In addition, as all nodes are participating
    in a public blockchain, the throughput of the validation process and the user''s
    data storage become the new challenge impacting system performance. Therefore,
    the novelty of the proposed system is designing an integrated system that combines
    blockchain and decentralized machine learning to improve overall system performance
    while keeping data secure and confidential. As a blockchain network keeps a ledger
    distributed in every node, when the network consists of model training sites that
    store a different data set, the whole HMS is co-trained on the same model taking
    the advantage of a large volume of data. Our proposed HMS intends to integrate
    model training and health monitoring into a single system. Contribution Based
    on the above facts, the main goal of this work includes two parts: propose a new
    HMS framework and evaluate its performance. The proposed HMS provides a new scheme
    for user data access control and solves the problem of breach of privacy in data
    storage. Also, it combines blockchain techniques and decentralized machine learning
    to achieve better data utilization. Furthermore, the proposed system is evaluated
    in terms of throughput and co-trained model accuracy. The specific objectives
    of the proposed system are summarized as follows: Design a new framework by integrating
    the blockchain and decentralized machine learning in the health monitoring context
    Develop the system to achieve the functionality of allowing secure communications
    between patients and doctors as well as users'' data access control Evaluate the
    system performance in terms of throughput and model accuracy. Related Works Blockchain
    technology has been introduced and integrated with a healthcare information system
    in past works. Bhuiyan et al. [8] designed a general concept of integrating blockchain
    with big data in healthcare information systems. Their prototype provided a three-tier
    solution to solve the problem of data security and data sharing between two hospitals.
    Awotunde et al. [9] integrated access control in the Ethereum network while considering
    the system performance which guaranteed patients'' data confidentiality for an
    EHR system. Saveetha et al. [10] proposed financial data management system allowing
    a 100 percent success rate for transaction processing with limited transaction
    size to achieve an integrated data-base system. In addition to the above frameworks,
    Chen et al. [11] and Tanwar et al. [4] considered implementing both secure data
    sharing and data management in one architecture. As designed by Chen et al. [11],
    the whole system is built on Ethereum with encrypted data on the cloud server.
    More specifically, the data owner first encrypts the data and sends it to the
    cloud server, which contains the unique index to be the identifier. The index
    is then added to the Ethereum network, together with the reward that the data
    user required for using their data. The index-based system provides full access
    control for user data, but increases the training cost for an integrated machine
    learning module as it requires extra stages for index searching and health data
    decryption. As a blockchain network keeps a ledger distributed in every node,
    when the network consists of model training sites that store a different data
    set, the whole HMS is co-trained on the same model taking the advantage of a large
    volume of data. Tanwar et al. [4] proposed the framework based on hyperledge fabric.
    It is a private and consortium blockchain network, which means all users in the
    network have been certificated by a certificate authority (CA). In the network,
    there are four types of participants, including admin, user, clinicians, and laboratory
    staff and they all maintain the same ledger together. To protect users'' privacy,
    the EHR in the network does not contain the user''s identity data. Instead, the
    identification data of the user name or contact information is replaced with a
    public ID. The clinicians can update records or write reports to the block-chain
    when they are authorized by users using their private keys. Additionally, all
    the clinical data is shared over the blockchain publicly so that each agent is
    allowed to utilize it. However, the design of above schemes do not consider the
    feature of distributed data and how to take advantage of it. Our work integrates
    machine learning assisted pre-diagnosis as an integrated module to the system,
    which utilizes the distributed feature of blockchain network. In the above schemes,
    they have all achieved secure patient-doctor communication and the function of
    user data access control, which makes both consortium and public blockchain networks
    proper for being the base architecture for the proposed system. Considering their
    different advantages, on the one hand, the combination of LearningChain and Ethereum-based
    networks shares the same property of being designed on a public blockchain network,
    but it requires a well-designed algorithm to keep data secure from malicious attacks
    and face the problem of large storage requirements for both the hospital side
    and user side. On the other hand, ModelChain and hyperledger fabric-based network
    shares the feature of being built on the private blockchain network and both of
    them requires separate data storage, which reduces the requirement for single-point
    storage. Proposed System Design The objective of this work is to propose a new
    system design and implementation scheme of a secure blockchain-based health information
    system with an integrated module to achieve users'' health status monitoring.
    Here we proposed a new framework for building such a health information system
    by combining Hyperledger Fabric and ModelChain. System Architecture As shown in
    Fig. 1, the system starts with data collection from users by using wearable devices,
    like smartwatches or pectoral girdles. The collected data is uploaded to the user''s
    terminal and is further uploaded to the Fabric blockchain network. Before the
    data is accepted, the Fabric network is required to validate the user''s certificate
    which is managed by the membership service from the hospital organization administrator.
    In the Fabric network, nodes are grouped and managed in the form of an organization.
    Our proposed system includes two types of organizations, the hospital organization,
    and the model training organization. The hospital organization contains one type
    of hospital node as the admin manager taking charge of the chain code update and
    channel policy modification, and other peer nodes comprised by patients in the
    hospital. In contrast to a public blockchain network, like Ethereum, one peer
    node does not need to maintain the health data from all other network participants.
    Instead, they are only required to maintain the ledger from the local hospital
    which reduces the burden of heavy data storage. Moreover, as each hospital contains
    different patients record, it is more possible to provide valuable information
    to improve model accuracy. Figure 1. Architecture of the proposed system, Show
    All Use of Hyperledger Fabric and Modelchain Hyperledger Fabric is a type of consortium
    block-chain, which contains the property that only authorized parties can participate
    in the network. There is the concept of organization in this type of blockchain
    network, in which, there exists a Certificate Authorization (CA) manager in charge
    of participant control. In this case, each hospital can be referred to as an organization
    taking charge of the member management in the hospital''s ledger, which further
    eliminates the threats from potential consensus attacks as a CA manager from the
    hospital can require identification information for user certificate authorization.
    In addition, based on the design of the framework, the ModelChain is achieved
    by the participation of computing sites in different hospitals because the machine
    learning process requires large computing power and high efficiency. Furthermore,
    the combination of hyperledger fabric and ModelChain avoids huge storage problems
    caused by a public blockchain. It is solved by having each hospital maintain its
    own ledger, while each patient only needs to participate in appointed ledger maintenance
    (the hospital where they have been to). In this case, the user''s data is still
    confidential to other hospitals, since the information shared between hospitals
    is just the co-trained model. Therefore, when patients authenticated the current
    hospital on their data, the trustfulness remains. Based on the scheme, it keeps
    the system from consensus protocol attacks, while also maintaining users'' data
    privacy. In addition, with the high extensibility and elimination of regional
    problems, the hospital in different regions can share their information on morbidity,
    which enables to have earlier detection and faster responses to pandemics, like
    COVID-19, as the shared information on user''s EHR provides alerts for each hospital
    crossing all regions in the network. Hyperledger Fabric A blockchain network can
    be considered as an immutable distributed ledger, where data is distributed in
    the whole network and all nodes are in an identical transaction sequence. In the
    Hyperledger Fabric network, maintaining the transaction sequence is implemented
    by a separate module called consensus set. A consensus set consists of a predefined
    number of order nodes, which are in charge of ordering submitted data based on
    consensus algorithms, like Kafka. In addition to consensus implementation, Hyperledger
    Fabric involves a CA module to take charge of participants'' certificate management
    to avoid possible consensus attacks. To complete one data sub-mission, it requires
    the participation from different peers. There are three types of working nodes,
    the endorse node, the order node and the peer node. When an authorized user sends
    a transaction proposal to endorsed nodes, these nodes will execute all the proposals
    and sign on them if they are valid. The user then collects all the signatures
    until the total amount meets the requirement defined in the endorsement policy.
    The process contributes to a valid transaction, which can be submitted to order
    nodes and further to peer nodes. When peer nodes receive the transaction, they
    will check the validation before adding the transaction to the local ledger, as
    there could be a double spending problem caused by the lag time. Although ledgers
    in a common Fabric network are allowed to be shared across organizations, the
    proposed system restricts the ledgers to be shared only inside one organization.
    In this design, each hospital will participate in two organizations as different
    roles, one in organization managing local patients'' data as the administrator
    and the other in the model training organization as a peer node. In a model training
    organization, the administrator could be the government taking charge of the authorization
    for all hospitals. While for each user, they can participate in any number of
    hospitals by simply joining the corresponding organizations. Modelchain According
    to the prototype proposed by Kuo et al. [12], ModelChain consists of computing
    sites with their local data. In the proposed system, the computing site refers
    to the hospital node and the local data refers to the ledger shared in the organization.
    To train a model using ModelChain, there are four stages, including model initialization,
    model update, model evaluation, and model transfer. Each of them matches the flag
    of INITIALIZE, UPDATE, EVALUATE and TRANSFER. One block in a ModelChain network
    contains the model, the flag, the hash of the site and the model error rate evaluated
    by the local data set. A ModelChain model training in the proposed system starts
    with model initialization. Each site generates a model trained with a local data
    set and then submits the model along with the flag INITIALIZE and local error
    rate. Each site waits until a predefined number of sites have finished local model
    training. Afterward, the site with the lowest error rate is granted with the privilege
    to further update the model, hence it writes a block with the flag TRANSFER to
    the blockchain network. After a new model is generated from the TRANSFER site,
    other sites test the model with the local data set and write the result along
    with the flag EVALUATE into the blockchain network. If all other sites have a
    smaller error rate after evaluating the model, the model is considered as well-trained,
    since the data set from the local site has already contained the most hidden information
    for this model. Otherwise, the model training continues. The Hyperledger Fabric
    network architecture fits the design of ModelChain. As the users are grouped by
    hospital organizations, each organization can be considered as one site. Also,
    each site could be presented in the form of computing clusters, providing greater
    computing power to facilitate the model training process. Additionally, as the
    computing site is also involved in data ledger maintenance, it can directly train
    the model with authorized new data after it is updated into the ledger. Health
    Monitoring System Before uploading the gathered data from smart devices, user-identifiable
    data is first encrypted by the user''s public key. Afterward, the data is examined
    by the trained model. The predicted result is classified into different risk levels.
    If the result is above “middle risk,” the system alerts the user about the potential
    risk and asks whether to authorize the doctor to view this record. After doctor''s
    update on the record, the system notices user to view the notes, which could be
    “Keep recording date and observing the symptom” or “Go to the hospital soon.”
    The notes are also encrypted by the user''s public key, which guarantees users''
    data privacy during user-doctor communication. Figure 2 presents the overall system
    data flow, which includes the stages of system initialization, data sharing and
    model training. In system initialization stage, the network is set up by configuring
    network size and endorsement policy. Afterwards, a CA server checks and delivers
    certificates to authorized peer nodes for uploading. In the data sharing stage,
    system encrypts the user''s identifiable data to make the user''s data secure
    before uploading into the blockchain network. After the data is updated in hospital
    site, it runs the machine learning model to check the user''s health status and
    present the examination result to the corresponding doctor. When the health status
    is examined in risk, user''s terminal then gathers all the data stored in local
    database and starts private data sharing. Figure 2. Proposed health monitoring
    system flow chart. Show All Although ledgers in a common Fabric network are allowed
    to be shared across organizstons, the proposed system restricts the ledgers to
    be shared only inside one organization. Private data is the encrypted data with
    the content of the whole EHR ID set and the user''s private key. To generate private
    data, EHR ID set in local database is combined with the user''s private key, and
    the combined data are encrypted by hospital''s public key. Next, the encrypted
    data is sent to the doctor''s side to get further examined. After decrypting by
    hospital''s private key, the doctor can query the user''s EHRs by searching the
    user''s EHR ID and get the user''s identity by decrypting the identity cipher
    with the user''s private key. Users can call Revoke-Authorization chaincode to
    delete this private data. Data security is guaranteed in the data-sharing stage
    by applying asymmetric encryption. In the model training stage, the system applies
    the ModelChain model training technique. ModelChain training algorithm works as
    a daemon service allowing the hospital site to leave and join without worrying
    about single-point failure. The system provides hospital sites with an application
    to start the ModelChain training from initialization as well as a join-in function
    to allow other sites to join training later. Simulation Results Simulation Setup
    The system is built on Hyperledger Fabric 2.2.4. To simulate the peer nodes and
    hospital sites, the docker engine is used. The docker engine allows building a
    virtual network on a single computer, while each site in the virtual network can
    run its own programs and its own library decencies. In the system, CouchDB is
    used to store EHR identifiers as it provides high flexibility with JSON data type.
    The docker engine generates containers running on different ports for the simulated
    system, which includes four peer nodes, two hospital administrator nodes, one
    ordering node, one CA management node, and one CouchDB node. The simulated network
    is further evaluated by Hyperledger Caliper in terms of system throughput. As
    for the modeling training algorithm, the Weka library is used in this system.
    Compare to other machine learning algorithms, Weka is a Java machine learning
    library providing various tools, such as classification, regression, clustering,
    association rules, and visualization. Applying Weka makes the system scalable
    to future research on different model training methods in the Model-Chain model
    training stage. Results Analysis System performance is measured in terms of the
    system throughput and model accuracy by Hyperledger Caliper. It is measured in
    scenarios of calling different chaincodes and under different numbers of organizations
    and peers. The different chaincodes include the submission of EHR and private
    data, and query EHR and private data. When executing each measurement, the system
    is simulated to execute 1000 transactions for each round and 5 rounds for each
    measurement. Each round is in different transaction submission speed. The submit
    speed is set by using a different Transaction Load, which is the unit defining
    the number of transactions submitted to the system at one time. The value of the
    Transaction Load used in the measurement includes 10, 50, 100, 150, and 200. Each
    measurement is executed three times, and the final results are generated by calculating
    the mean value. The throughput is measured by calculating the number of successfully
    committed transactions in the network within the given Transaction Load. Suppose,
    NTL denotes the total number of transactions loaded into the network for execution
    per time, and NF denotes the number of failed committed transactions. LT refers
    to the latency for one transaction. TE is the execution time for each transaction.
    The system throughput ST for a given Transaction Load can be presented as: S T
    = N s ( T E + L T )× N s + L T × N F (1) View Source where N S denotes the number
    of successfully committed transactions, which is the difference between the total
    number of transactions ( N TL ) and the number of failed transactions ( N F ).
    Comparing the Performance with Different Network Sizes The system is measured
    on the network size, which includes two organizations with one peer in each (Org2Peer1),
    two organizations with two peers in each (Org2Peer2), two organizations with three
    peers in each (Org2Peer3), and three organizations with one peer in each (Org3Peer1).
    Each of the networks is measured by executing the submitEHR chaincode with the
    block size set to 10. As shown in Fig. 3, the system performance on throughput
    gets smaller when the network contains more peers. The same trend also happens
    when increasing the organization''s size. Comparing the Org2Peer1 with Org3Peer1,
    Org-3Peer1 network, a network with less number of organizations has a higher system
    throughput, but the gap between them gets smaller as the transaction speed increases.
    The network size is not the only factor in the system''s performance. For Transaction
    Loads 10 and 50, the system throughput largely depends on the number of organizations,
    but when the Transaction Load is 150 or 200, the performance is dominated by other
    factors, such as block size or endorsement policies. Moreover, the disproportionate
    relationship between throughput and Transaction Load also shows that the dominant
    factor is changing as the Transaction Load increases. When the Transaction Load
    is 100 and 150, the larger gap of throughput is on the number of peers, instead
    of the number of organizations. When Transaction Load is 100, the largest gap
    between Org2Peer2 and Org2Peer3 is 4.15, while the one between Org2Peer1 and Org-3Peer1
    is 0.85. For Transaction Load is 150, the largest gap between Org2Peer1 and Org2Peer2
    is 1.92, while the one between Org2Peer1 and Org-3Peer1 is 1.07. The largest gap
    is calculated by: G Largest =| T system1 + E system1 − T system2 + E system2 |
    (2) View Source where the T System1 denotes the mean throughput of system 1, E
    system1 denotes the error range of system 1, T system2 denotes the mean throughput
    of system 2 and E system2 denotes the error range of system 2. Figure 3. System
    throughput on different network size. Show All Comparing the Performance with
    Different Chaincodes In this scenario, different chain- codes in tested on a network
    Org2Peer1. The chaincodes include submit EHR, submit EHR with private data, query
    a EHR and query a private data. As shown in Fig. 4, query function is considerably
    faster than a submit function. When calling the chaincode to submit EHR with private
    data, the system writes to the ledger twice, once in public collection, once in
    private collection. Moreover, it also contains the stage to gather all previous
    EHR and EHR encryption. However, based on the result from system throughput, the
    influence of EHR gathering and EHR encryption gets smaller as the network transaction
    speed increases. The largest minimum gap of the system throughput is 1.2 (TPS)
    when the range of Transaction Load is 100 to 200, while the value for Transaction
    Load 50 is 7.1 (TPS) (Fig. 4). The same trend also happens on the two query chaincode.
    Query a private data chaincode contains the encrypted data, which combines user''s
    previous EHR IDs and user''s private key. The difference on data size is the reason
    for difference in performance. According to the figure, there is a gap between
    the system throughput on calling these two query chaincode when the Transaction
    Load is relatively small (10 and 50), but the gap gets smaller as Transaction
    Load increased, and get near to the same when the Transaction Load is 200. When
    the transaction load increases, the result is largely affected by the system framework,
    less affected by the difference of method calls. Figure 4. System throughput on
    different chaincode. Show All Comparing Decentralized Machine Learning with Traditional
    Machine Learning In Fig. 5, the accuracy of different machine learning algorithms
    is presented. The algorithms include 3-Nearest Neighbor, K-Star, and Hoeffding
    Tree. Compared to KNN, K-Star is also an instance-based model training algorithm
    but applies an entropy function to measure the distance, which handles the entity
    with missing data or noise by the entropy function [13]. As ModelChain trains
    an incremental model, there could be an overall gap in the data set from different
    organizations. For example, people living in an area with different elevations
    have different average heart rates. K-Star is expected to reduce the regional
    difference and improve its performance. For the Hoeffding Tree algorithm, it allows
    data input as a stream, which will generate an incremental decision tree [14].
    The ModelChain training switches the training data set continuously, which is
    expected to improve its training speed. As shown in Fig. 5, the Hoeffding Tree
    algorithm shows its strength with an averaged cost of 46(ms) compared to 237(ms)
    for 3-NN and 695(ms) for K-Star but generates a less accurate model (0.6213 percent
    accuracy compared to 0.8994 percent for 3-NN and 0.9024 percent for K-Star). Since
    there are only two organizations included in the system, the data set just switches
    between these two sets, which could be one of the reasons leading to Hoeffding
    Tree''s poor performance. In addition, the model from hospitals and ModelChain
    applying K-Star and Hoeffding Tree have only slight changes in accuracy. As the
    data sets for hospitals 1 and 2 are limited in size, the K-Star algorithm does
    not show its strength in handling problems, as the regional difference. Particularly,
    the model accuracy for all three models applying the Hoeffding Tree algorithm
    is relatively low, as Hoeffding Tree is highly dependent on a big volume of data.
    The size of the data set in each site is not sufficient enough to generate a relatively
    good model by applying the Hoeffding Tree algorithm. Figure 5. Comparison on model
    accuracy. Show All Comparing System Throughput with Existing System To compare
    the system throughput with the existing system from Tanwar et al. [4] under the
    settings of transaction rate at 50, 100, 150, 200, Fig. 6 presents the results
    under 2 organizations and 1 peer. With the data set [15] containing the attributes
    of age, upper/lower body pressure, body glucose, body temperature, and heart rate,
    querying one existing transaction for the proposed system achieves an approximate
    20 percent increase in average throughput. Figure 6. Comparison on system throughput
    Show All The above criterion evaluates the proposed scheme in terms of throughput
    and model accuracy, which provides referential performance and feasibility to
    further optimize for real deployment. Considering the benefits of secure communication,
    additional functions of data access control, and machine learning-assisted healthcare
    monitoring, it is believed to have a better performance in health data management
    as well as healthcare monitoring over current systems. Conclusion Blockchain as
    an emerging technology has shown its feasibility for being a basic framework for
    an information system. The proposed system fits real-world scenarios as each organization
    in the network is designed to match one hospital and the process of both data
    management and model co-training considers each hospital as an entity. To evaluate
    the proposed scheme, the system is configured in a different working environment
    and measured in terms of throughput. It is also integrated with a decentralized
    machine learning scheme to compare the model performance with traditional methods.
    Simulating under different network settings has shown the possibility to be further
    optimized for real-world deployment. In the future, we plan to benchmark the system
    performance by applying different encryption schemes in terms of throughput and
    accuracy. Moreover, the system can be scaled to larger setting and measured for
    calling chaincodes for other functions, like medical imaging diagnosis. ACKNOWLEDGMENT
    This work is supported by Ningbo Science and Technology Bureau under Commonweal
    Programme with project code 202002N3135. Authors Figures References Keywords Metrics
    More Like This P2PCompute: A Peer-to-peer computing system 2007 International
    Symposium on Collaborative Technologies and Systems Published: 2007 Ad hoc Grid:
    An Adaptive and Self-Organizing Peer-to-Peer Computing Grid 2010 10th IEEE International
    Conference on Computer and Information Technology Published: 2010 Show More IEEE
    Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW
    PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION
    AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE:
    +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help
    | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting
    | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s
    largest technical professional organization dedicated to advancing technology
    for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: IEEE Communications Magazine
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Design of a Blockchain-Based Secure Health Monitoring System Using Decentralized
    Machine Learning Technique
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Nishikawa Y.
  - Nishijima S.
  - Hirano A.
  citation_count: '0'
  description: We have proposed autonomous network diagnosis platform for operation
    of future large capacity and virtualized network, including 5G and beyond 5G services.
    As for the one candidate of information collection and analyzing function blocks
    in the platform, we proposed novel optical sensing techniques that utilized tapped
    raw signal data acquired from digital coherent optical receivers. The raw signal
    data is captured before various digital signal processing for demodulation. Therefore,
    it contains various waveform deformation and/or noise as it experiences through
    transmission fibers. In this paper, we examined to detect two possible failures
    in transmission lines including fiber bending and optical filter shift by analyzing
    the above-mentioned raw signal data with the help of machine learning. For the
    purpose, we have implemented Docker container applications in WhiteBox Cassini
    to acquire real-time raw signal data. We generated CNN model for the detections
    in off-line processing and used them for real-time detections. We have confirmed
    successful detection of optical fiber bend and/or optical filter shift in real-time
    with high accuracy. Also, we evaluated their tolerance against ASE noise and invented
    novel approach to improve detection accuracy. In addition to that, we succeeded
    to detect them even in the situation of simultaneous occurrence of those failures.
  doi: 10.1587/transcom.2022OBP0002
  full_citation: '>'
  full_text: '>

    "Browse About J-STAGE News and PR Support Sign in Cart EN IEICE Transactions on
    Communications Online ISSN : 1745-1345 Print ISSN : 0916-8516 Journal home All
    issues About the journal J-STAGE home / IEICE Transactions on Communic ... / Volume
    E106.B (2023) Issue 11 / Article overview Joint Special Section on Opto-electronics
    and Communications for Future Optical Network Real-Time Detection of Fiber Bending
    and/or Optical Filter Shift by Machine-Learning of Tapped Raw Digital Coherent
    Optical Signals Yuichiro NISHIKAWA, Shota NISHIJIMA, Akira HIRANO Author information
    Keywords: optical communication, digital coherent transmission, optical performance
    monitoring, artificial intelligence JOURNAL RESTRICTED ACCESS 2023 Volume E106.B
    Issue 11 Pages 1065-1073 DOI https://doi.org/10.1587/transcom.2022OBP0002 Browse
    “Advance online publication” version Details Download PDF (5624K) Download citation
    RIS (compatible with EndNote, Reference Manager, ProCite, RefWorks) BIB TEX (compatible
    with BibDesk, LaTeX) Text How to download citation Contact us Article overview
    Abstract References (20) Content from these authors Share   Abstract We have proposed
    autonomous network diagnosis platform for operation of future large capacity and
    virtualized network, including 5G and beyond 5G services. As for the one candidate
    of information collection and analyzing function blocks in the platform, we proposed
    novel optical sensing techniques that utilized tapped raw signal data acquired
    from digital coherent optical receivers. The raw signal data is captured before
    various digital signal processing for demodulation. Therefore, it contains various
    waveform deformation and/or noise as it experiences through transmission fibers.
    In this paper, we examined to detect two possible failures in transmission lines
    including fiber bending and optical filter shift by analyzing the above-mentioned
    raw signal data with the help of machine learning. For the purpose, we have implemented
    Docker container applications in WhiteBox Cassini to acquire real-time raw signal
    data. We generated CNN model for the detections in off-line processing and used
    them for real-time detections. We have confirmed successful detection of optical
    fiber bend and/or optical filter shift in real-time with high accuracy. Also,
    we evaluated their tolerance against ASE noise and invented novel approach to
    improve detection accuracy. In addition to that, we succeeded to detect them even
    in the situation of simultaneous occurrence of those failures. References (20)
    Sign in with Subscription Number to view this section Content from these authors
    © 2023 The Institute of Electronics, Information and Communication Engineers Previous
    article Next article Favorites & Alerts Add to favorites Additional info alert
    Citation alert Authentication alert Related articles  Recently viewed articles
    Announcements from publisher IEICE Members can download the PDF from https://search.ieice.org/cs/
    PPV is availble from http://search.ieice.org/cs/index.html Please contact trans-b
    [a] ieice.org, if you want to unlock PDF security. Edited and published by The
    Institute of Electronics, Information and Communication Engineers Production services
    Sanbi Printing Co.,Ltd. Top BROWSE All titles All subject areas All publishers
    Search articles Search J-STAGE Data ABOUT J-STAGE Overview Services and features
    Public data Terms and Policy NEWS AND PR News Maintenance information Special
    contents Media resources SUPPORT User manuals Browser compatibility FAQ Contact
    Sitemap feedback Register with J-STAGE for free! Register Already have an account?
    Sign in here"'
  inline_citation: '>'
  journal: IEICE Transactions on Communications
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Real-Time Detection of Fiber Bending and/or Optical Filter Shift by Machine-Learning
    of Tapped Raw Digital Coherent Optical Signals
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Aguado D.
  - Noriega-Hevia G.
  - Serralta J.
  - Seco A.
  citation_count: '0'
  description: 'The availability of real-time measurements of primary quality water
    variables is one of the key challenges in the wastewater treatment industry. However,
    due to the cost and maintenance requirements of sensors and probes for on-line
    measurement of primary quality variables, the prediction of these variables via
    data-driven approaches using as inputs easy-to-measure process variables has attracted
    research interest. In this paper, different machine learning techniques: feed-forward
    artificial neural network, random forest, support vector machine, gaussian process
    regression and partial least squares were used to predict in real-time the total
    ammonium nitrogen concentration during the operation of a hollow fibre membrane
    contactor. This recently developed technology allows the recovery of nitrogen
    from nitrogen rich streams (i.e. supernatant of anaerobic digesters in wastewater
    treatment plants) as ammonium sulphate (a marketable fertilizer). These contactors
    are usually operated in batch mode, pumping the high nitrogen concentration feed
    from the storage tank, where the total ammonium nitrogen concentration decreases
    progressively as the fertilizer is produced. Knowing the real-time concentration
    of total ammonium nitrogen in the storage tank would enable the optimization of
    the process operation, avoiding its operation with conservative fixed-time batch
    duration. The pH is an easy-to-measure process variable usually available in wastewater
    treatment plants that was used as input of the tested data-driven models, together
    with two extracted features from this variable (its derivative and increments
    after each reagent dosing). The number of total ammonium nitrogen measurements
    in the collected database is 2350 data points (corresponding to 8 complete batches,
    which were divided into 6 for training the data-driven models and 2 for testing
    them), ranging from 987 to 2.5 mg NH4+-N/L which covers almost the complete range
    of total ammonium nitrogen concentration values in the membrane contactor. The
    predictive ability of the developed predictive models was evaluated on the test
    data set by four indices, namely: the root-mean-square error, the slope and the
    intercept of the linear fit between the measured and predicted concentrations
    and the determination coefficient. The results showed a strong predictive ability
    of the fitted ANN that outperformed the other approaches exhibiting a determination
    coefficient of 0.99 and the lowest root-mean-square error (19.87 mg/L) in the
    test set. Permutation variable importance demonstrated that all machine learning
    techniques depended mainly on the two variables extracted from the pH: its derivative
    and increments, which resulted to be more important than the pH itself to predict
    the total ammonium nitrogen concentration.'
  doi: 10.1016/j.engappai.2023.107330
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Graphical abstract Keywords Abbreviations 1. Introduction
    2. Background on nitrogen in wastewater 3. Materials and methods 4. Results and
    discussion 5. Conclusions CRediT authorship contribution statement Declaration
    of competing interest Acknowledgements Data availability References Show full
    outline Figures (7) Show 1 more figure Tables (1) Table 1 Engineering Applications
    of Artificial Intelligence Volume 126, Part D, November 2023, 107330 Using machine
    learning techniques to predict ammonium concentration in membrane contactors for
    nitrogen recovery as a valuable resource Author links open overlay panel D. Aguado
    a, G. Noriega-Hevia a, J. Serralta a, A. Seco b Show more Add to Mendeley Share
    Cite https://doi.org/10.1016/j.engappai.2023.107330 Get rights and content Highlights
    • Real-time pH measurements were used to accurately predict the real-time evolution
    of TAN concentration. • ANN outperformed the other machine learning approaches,
    exhibiting RMSE <20 mg/L. • The relationship between the target and the inputs
    is non-linear. • Real-time TAN prediction relies on a pH sensor, being the extracted
    features the strongest predictors. • A pH sensor together with ML allows monitoring
    the HFMC process and optimizing batch duration. Abstract The availability of real-time
    measurements of primary quality water variables is one of the key challenges in
    the wastewater treatment industry. However, due to the cost and maintenance requirements
    of sensors and probes for on-line measurement of primary quality variables, the
    prediction of these variables via data-driven approaches using as inputs easy-to-measure
    process variables has attracted research interest. In this paper, different machine
    learning techniques: feed-forward artificial neural network, random forest, support
    vector machine, gaussian process regression and partial least squares were used
    to predict in real-time the total ammonium nitrogen concentration during the operation
    of a hollow fibre membrane contactor. This recently developed technology allows
    the recovery of nitrogen from nitrogen rich streams (i.e. supernatant of anaerobic
    digesters in wastewater treatment plants) as ammonium sulphate (a marketable fertilizer).
    These contactors are usually operated in batch mode, pumping the high nitrogen
    concentration feed from the storage tank, where the total ammonium nitrogen concentration
    decreases progressively as the fertilizer is produced. Knowing the real-time concentration
    of total ammonium nitrogen in the storage tank would enable the optimization of
    the process operation, avoiding its operation with conservative fixed-time batch
    duration. The pH is an easy-to-measure process variable usually available in wastewater
    treatment plants that was used as input of the tested data-driven models, together
    with two extracted features from this variable (its derivative and increments
    after each reagent dosing). The number of total ammonium nitrogen measurements
    in the collected database is 2350 data points (corresponding to 8 complete batches,
    which were divided into 6 for training the data-driven models and 2 for testing
    them), ranging from 987 to 2.5 mg NH4+-N/L which covers almost the complete range
    of total ammonium nitrogen concentration values in the membrane contactor. The
    predictive ability of the developed predictive models was evaluated on the test
    data set by four indices, namely: the root-mean-square error, the slope and the
    intercept of the linear fit between the measured and predicted concentrations
    and the determination coefficient. The results showed a strong predictive ability
    of the fitted ANN that outperformed the other approaches exhibiting a determination
    coefficient of 0.99 and the lowest root-mean-square error (19.87 mg/L) in the
    test set. Permutation variable importance demonstrated that all machine learning
    techniques depended mainly on the two variables extracted from the pH: its derivative
    and increments, which resulted to be more important than the pH itself to predict
    the total ammonium nitrogen concentration. Graphical abstract Download : Download
    high-res image (276KB) Download : Download full-size image Previous article in
    issue Next article in issue Keywords Anaerobic digesterMachine learningMembrane
    contactorNitrogen recoverySoft-sensor Abbreviations ANN Artificial Neural Network
    GPR Gaussian Process Regression HFMC Hollow Fibre Membrane Contactor ML Machine
    Learning R2 Coefficient of Determination RF Random Forest PLS Partial Least Squares
    RMSE Root Mean Square Error SVM Support Vector Machine TAN Total Ammonia Nitrogen
    WWTP Wastewater Treatment Plant 1. Introduction The water industry is fully immersed
    in its digital transformation, showing the positive impact of the deployed digital
    solutions in different aspects: operational costs reduction, increase of its current
    infrastructure and operation efficiency, enhancement the customer experience,
    and increase the efficiency of the labour force (IWA 2022). The foundation of
    this digitalization is the collected real-time data from the water system, which
    constitute the basis of good decision making (Ingildsen and Olsson, 2016). As
    highlighted by Ingildsen and Olsson (2016), although the collected data are the
    basis of a smart water facility, to become smart these data must be transformed
    (through proper analysis and processing) into intelligent actions which enable
    to improve the operation of the facility. Real-time reliable measurements are
    essential to know the status of any process and its temporal evolution, thus,
    enabling its automatic control and real-time optimization. A wide range of physical
    and chemical parameters relevant to the operation of wastewater treatment facilities
    can be nowadays measured continuously or semi-continuously with commonly used
    sensors and analysers (IWA, 2022). However, the laborious maintenance needs of
    instrumentation are frequently pointed out by operators as a barrier for its efficient
    use (Eerikäinen et al., 2020) and the cost of the advanced sensors for quality
    variables (e.g. ammonium, nitrate, nitrite and phosphate) limit their widespread
    use in medium and small size wastewater treatment facilities (Thürlimann et al.,
    2018). Lack of maintenance make these expensive sensors less reliable, preventing
    a wider application of the advanced control algorithms that are dependent on them
    (Yuan et al., 2019). There are simpler sensors (e.g. dissolved oxygen, pH, temperature,
    flow, level) that have been proven to be robust, cheap, sufficiently accurate
    and need minimum maintenance (Haimi et al., 2013; Schneider et al., 2019). These
    simpler sensors together with the large amount of process data routinely measured
    and collected in modern facilities has stimulated the use of data-driven modelling
    as a useful strategy for soft-sensor development (Haimi et al., 2013). A soft-sensor
    estimates target(s) variable(s) (usually primary quality variables) through a
    data-driven technique (artificial neural networks, partial least squares, gaussian
    process regression, …) using as inputs process data collected by cheap and simpler
    sensors (also known as process variables or secondary variables), thus avoiding
    the expenditure of an advanced hardware sensor (Kadlec et al., 2009; Ching et
    al., 2022). Thus, for on-line monitoring, software sensors can serve as convenient,
    economical alternative to hardware sensors. A recent review of the current status
    of the development of software sensors in wastewater treatment plants can be found
    in Ching et al. (2021). The digital transformation is not the only major change
    that municipal wastewater treatment facilities are facing. There is also a paradigm
    shift towards a sustainable and circular water economy, in which resource recovery
    from wastewater (water, energy, and nutrient recovery) plays a fundamental role
    for its effective implementation (Salminen et al., 2022). Many processes applicable
    for this new paradigm already existed, and others have been further developed
    (struvite-crystallization, membrane contactors, air-stripping, ionic exchange,
    electrodialysis, direct osmosis, etc.). Recently, resource recovery processes
    have been extensively developed and investigated to optimize their operation (Robles
    et al., 2020). Resource recovery from wastewater is not something new (e.g., anaerobic
    digestion to produce biogas as energy recovery strategy has been practiced with
    success for over 100 years in different parts of the world), but in global terms
    worldwide, only a small fraction of the resources that are conveyed within wastewater
    are recovered (Pikaar et al., 2020). Reducing the energy consumption at full-scale
    facilities and recovering water, nutrients and energy, the wastewater treatment
    sector is reducing its contribution to greenhouse gas emissions and thus its impact
    on climate change (IWA, 2022b). Noriega-Hevia et al. (2021) estimated that nitrogen
    recovery from the supernatant of the anaerobic digestion of a full-scale Wastewater
    Treatment Plant (WWTP) treating a hydraulic flow of 40000 m3/day would avoid the
    emissions to the atmosphere of 10.2 tonnes of carbon dioxide equivalents per year.
    Nitrogen can be highlighted among the valuable resources that worth recovering
    from wastewater (Cifuentes-Cabezas et al., 2023). It is an essential component
    present in most of the commercial fertilizers as it is required by many crops
    (Yahaya et al., 2023). Among the different processes for nitrogen recovery, the
    advantages exhibited by the hollow fibre membrane contactors (HFMCs) have turned
    it in an attractive membrane-based solution for this nutrient recovery (Rongwong
    et al., 2022). Different studies have pointed out the need of further research
    to improve the operation of these contactors and to optimize their process efficiency,
    enhancing in this way their commercial applicability (Robles et al., 2020). These
    contactors are usually operated in batch mode, pumping the nitrogen rich solution
    from a storage tank, where the Total Ammonia Nitrogen (TAN) concentration decreases
    progressively as the fertilizer is produced (Cifuentes-Cabezas et al., 2023).
    Knowing the real-time TAN concentration in the feed storage tank would enable
    the optimization of the process operation taking into account the dynamic nature
    of the process (avoiding its operation with conservative fixed-time batch length)
    and providing the flexibility to cope with influent changing conditions. In this
    paper, different data-driven approaches are used to predict in real-time the total
    ammonium nitrogen (TAN) concentration during the operation of a HFMC using as
    input data from an inexpensive and easy-to-measure process sensor usually available
    in every WWTP: the pH (together with its derivative and increments). To the best
    of authors’ knowledge, four of the machine learning models proposed and evaluated
    in this work (feed-forward artificial neural network, random forest, support vector
    machine and gaussian process regression) are applied for the first time to predict
    TAN in HFMCs. 2. Background on nitrogen in wastewater Urban wastewater contains
    a high amount of essential nutrients (Sheikh et al., 2023). The discharge of these
    nutrients (nitrogen and phosphorus) into natural aquatic ecosystems causes several
    detrimental environmental effects, such as eutrophication (Smith, 2003), toxicity
    (due to free ammonia) and reduction of the amount of dissolved oxygen in water
    (Metcalf and Eddy, 2013). To avoid these environmental problems and to protect
    human health, WWTP were traditionally designed to remove pollutants from wastewater.
    Conventional biological wastewater treatment removes the nitrogen via nitrification
    and denitrification processes in the secondary treatment. Nitrification (as well
    as organic matter removal) is an aerobic process that requires oxygen to be supplied
    which is an energy-demanding operation. Typically, aeration energy can account
    for more than 50 % of the total wastewater operational costs (Drewnowski et al.,
    2019). The main byproduct of a WWTP is the sludge associated to the primary and
    secondary treatment that must be treated before final disposal (Shi et al., 2021).
    Anaerobic digestion is a widely used sludge treatment method to reduce the organic
    content while generating bioenergy in form of biogas (Vu et al., 2021). This anaerobic
    treatment generates a liquid stream (supernatant) with high content in nitrogen
    and phosphorous that it is usually returned to the pre-treatment of the WWTP,
    thus increasing the concentration of nutrients to be removed in the secondary
    treatment. The total nitrogen and phosphorous entering the secondary treatment
    (around 25% and 8% of the total nitrogen and phosphorous concentrations, respectively)
    makes that the separated treatment of the supernatant of the anaerobic digestion
    gain special interest in the last years (Soler-Cabezas et al., 2018). Nitrogen
    recovery from wastewater presents three major advantages. The more nitrogen recovered:
    (1) the lower amount of atmospheric nitrogen gas has to be fixed through the energy-intensive
    and fuel gas dependent Haber-Bosch process (Cruz et al., 2019); (2) the lower
    oxygen requirements for nitrification in the aerobic reactor of the secondary
    treatment of the WWTP; and (3) the lower nitrogen content can be discharged to
    aquatic ecosystems, thus preventing environmental pollution. 3. Materials and
    methods 3.1. Experimental set-up Data used in this work was collected in a lab-scale
    HFMC set-up for recovering the nitrogen contained in the supernatant generated
    in a full-scale anaerobic mesophilic digester. Fig. 1 shown a scheme of this set-up.
    The composition of the supernatant was 820 ± 180 mg NH4+-N/L, 30.5 ± 1.5 mg PO43--P/L,
    1320 ± 15 mg COD/L, pH 8.1 ± 0.1 and alkalinity 2733.9 ± 31.1 mg CaCO3/L. The
    collected supernatant was pre-treated as follows: pH increment (dosing NaOH 1M),
    to get most of TAN as free ammonia, followed by 8 min settling and finally filtration
    through 0,45 μm pore size, to remove the suspended solids and possible precipitates
    (like calcium carbonate and calcium phosphate) that could have formed at high
    pH and could clog or damage the membrane. This pre-treated supernatant was the
    N-rich feed solution stored in the feed storage tank. The TAN concentration in
    the feed solution during the experimentation varied from 987 to 2 mg NH4+-N/L.
    Download : Download high-res image (232KB) Download : Download full-size image
    Fig. 1. Laboratory-scale HFMC set-up used in the experimentation for nitrogen
    recovery. Two electronic sensors SP10T (Consort®) were used for real-time measurement
    of temperature and pH (one value recorded every 20 s) in each storage tank. A
    multi-parametric analyser (Consort C832) collected the signals from the sensors
    and sent the measurement information to a personal computer (PC) that was used
    for visualizing the data and store the data. Due to the short duration of the
    experiments (around 1 h) and the fact that were carried out in the laboratory,
    the experiments were carried out at constant temperature. Eight experiments were
    performed in laboratory at 25 °C, at a feed flow rate of 2.5 × 10−5 m3/s varying
    the pH between 9.5 and 11. Each experiment (batch) started with a high initial
    TAN concentration (around 900 mg TAN/L as supernatant from an anaerobic digester
    from full scale wastewater treatment facility was used), and lasted until the
    N-recovery was higher than 90% (around 60 min). The TAN concentration were analysed
    in grab samples using a photometer SMARTCHEN® 450 from AMS-Alliance. During the
    HFMC operation, free ammonia is transferred from the nitrogen-rich feed solution
    (this is the solution that circulates through the lumen) to the sulphuric acid
    solution that circulates within the hollow fibres. Each solution (nitrogen rich
    stream and sulphuric acid) was recycled to its respective storage tank. Both tanks
    were closed to avoid the loss of free ammonia through stripping, but none of tanks
    were sealed. The difference between free ammonia concentration at both sides of
    the membranes is the driving force for the transference process. During the nitrogen
    recovery process, both the TAN concentration and the pH of the feed solution decrease
    due to free ammonia stripping that when crosses the membrane forms ammonium sulphate
    (a soil fertilizer) consuming protons from the acid solution, thus increasing
    the pH in the acid tank. To assure that free ammonia predominated in the nitrogen
    rich solution the pH was kept high via automatic dosing of sodium hydroxide (NaOH
    1M) with a precision dosing unit (711 Liquino and 700 Dosino of Metrohm®) whenever
    its pH was below 8.5 throughout each experiment. Recall that in an aqueous solution,
    free ammonia (NH3) exists in equilibrium with ammonium ion (NH4+) and hydroxide
    ion (OH−). The equilibrium for this chemical reaction (H2O + NH3 ⇄ OH− + NH4+)
    depends on the temperature and the pH of the solution. The higher the pH, the
    higher the percentage of the total ammonium nitrogen present as free ammonia.
    The amount of sodium hydroxide required to raise the pH (in order to keep the
    N-recovery rate high) depends on the ammonium/alkalinity ratio. The higher alkalinity
    (i.e., lower ratio ammonium/alkalinity), the greater amount of sodium hydroxide
    will be required (affecting the economics of the process). The criteria to replace
    the sulphuric acid solution was the occurrence of a sudden pH increase, which
    occurred due to the acid solution exhaustion. 3.2. Machine learning models development
    The main aim of this work was to develop, evaluate and compare different data-driven
    techniques to predict the ammonium concentration evolution in the HFMC, using
    as input an easy-to-measure process variable: the pH (which is usually available
    in almost every WWTP), together with its derivative and its increments after each
    NaOH dosing. These two additional input variables were extracted from the pH via
    feature engineering because they could carry relevant information as demonstrated
    in Aguado et al. (2022). Note that converting pH data into TAN concentration would
    be especially useful for HFMC process monitoring, optimization and control of
    nitrogen recovery. It should be highlighted, that four of the predictive models
    included in this work: feed-forward artificial neural network (ANN), random forest
    (RF), support vector machine (SVM), and gaussian process regression (GPR), are
    proposed and evaluated for TAN concentration prediction in HFMCs for the first
    time, as far as the authors know. To develop the predictive models, evaluate them
    and compare them fairly: • the same three inputs (pH, pH_derivative, pH_increments)
    and target (TAN concentration) were used; • the same training data set (75% of
    the available data set, i.e. 6 experiments) were used for model fitting and the
    same testing data set (the remaining 25% of the available data, i.e. 2 experiments)
    was used for assessing their performance. Note that within each experiment, there
    is a time-series structure of the recorded variables, thus the data set was split
    into complete experiments, in order to preserve the temporal dynamics of the data.
    Being a limited number of experiments (8 in total), cross-validation was chosen
    to determine the hyperparameters of the machine learning models. Splitting the
    8 experiments into three fixed data sets (training, validation and testing), would
    have markedly reduced the number of samples used for learning, and the results
    could more easily depend on the particular random choice for the pair of training-validation
    data sets; • the same data pre-treatment was applied: centred and scaled to unit
    variance. Additionally, to assess the importance of each input variable in each
    developed predictive model, an inspection technique known as Permutation was applied.
    This technique is based on breaking the relationship between each input variable
    and the target. The breakage in this relationship will lead to a drop in the predictive
    performance of the model which is indicative of how much the model depends on
    the permutated variable. This will make it possible to find out if one or a few
    input variables are strong predictors for the target variable. In the following
    paragraphs there is a brief description of each machine learning model and a visual
    summary of all the models is shown in Fig. 2. Download : Download high-res image
    (980KB) Download : Download full-size image Fig. 2. Handmade schematic representation
    of the structure of each machine learning model used in this paper. 3.2.1. Partial
    least squares regression PLS is a multivariate projection method able to relate
    two blocks of variables exploiting the correlation structure among the variables.
    These two blocks are: the matrix X which contain the input variables (also known
    as features, explicative variables or predictors) and the matrix Y which contain
    the output variables (also known as response variables, target variables, i.e.,
    the variables to be predicted). In this case, there is only one target variable:
    the TAN concentration, thus, the block Y is actually a vector. The criteria used
    to extract the latent variables, is to maximize the covariance between X and Y.
    This multivariate statistical technique aims at finding new variables (i.e., latent
    variables that are linear combination of the variables in matrices X and Y) that
    explain as much variance in X as possible, but enabling the best prediction of
    the variables in matrix Y. Fig. 2 PLS shows a visual representation of this model
    for predicting one target variable. 3.2.2. Artificial neural network ANNs are
    computing algorithms whose design was inspired by the biological neural networks
    found in the brains of animals. A population of neurons are interconnected at
    synapses which transmit the signal processed in the neuron to the following neurons.
    The typical processing within the ANN consists of a weighted sum of the input
    signals whose result is passed through an activation function and the output sent
    to the following neurons. Due to their capacity to capture non-linear relationships
    and learn from large amounts of data, they have been widely used in the wastewater
    treatment research context to develop predictive models of inflow and water quality
    variables from the influent wastewater and the effluent (Ching et al., 2022; Ye
    et al., 2020). In this research, a multi-layer feed forward fully connected neural
    network was used to predict the TAN concentration in the HFMC (Fig. 2 ANN). Initial
    weights were randomly initialized to avoid any initial symmetry and allow the
    neurons to learn through the training process. Different activation functions
    were tested: hyperbolic tangent, sigmoid and Rectified Linear Unit (ReLU). The
    latter is now a widely used activation function which shows efficient computation,
    is scale-invariant and non-saturating activation function. Thus, it does not suffer
    from vanishing gradient, in contrast with the saturating activation functions.
    Adam optimizer was used to find the optimal values of the weights as it is a fast
    and efficient algorithm. 3.2.3. Random forest regression In random forest a combination
    of decision trees is trained for regression and their outputs are combined to
    produce the final prediction. It is an ensemble learning method which builds multitude
    of decision trees during the training (Fig. 2 RF). The predictions of all trees
    are averaged to improve the predictive accuracy of the final model prediction.
    In a decision tree the function to model is encoded in a flowchart-like structure
    that can be easily navigated. The top is the root, then the tree splits into branches
    based on the fulfilment of a specific condition at each internal node. The end
    of the branch that does not split anymore is the conclusion (leaf). 3.2.4. Support
    vector machine regression Support Vector Machine (SVM) is a powerful supervised
    machine learning technique able to perform linear or non-linear classification
    and regression. In the regression mode it constructs a set of hyperplanes trying
    to stay as close as possible of the training data set, i.e. it tries to fit as
    many observations as possible on the hyperplanes or within the margin of tolerance
    (epsilon) while limiting the margin violations (Fig. 2 SVM). The regression is
    performed in a higher dimension than the input space. The kernel is the function
    that transforms the data into a higher dimensional space in which the problem
    can be solved linearly. A regularization hyper-parameter (C) helps to avoid overfitting,
    allowing some margin violations. C adds a penalty to each observation outside
    the margin, thus the larger C the lower margin violations. The value of epsilon
    defines a margin of tolerance where no penalty is given to errors. 3.2.5. Gaussian
    process regression GPR is a kernel regression method that models the data as a
    collection of random variables being the target''s prediction given as a Gaussian
    probability density function. Thus, the predicted value of the target comes with
    an estimation of its variance, which is interpreted as an uncertainty measure
    of the prediction (Rasmussen and Williams, 2005). Fig. 2 GPR shows a schematic
    representation of this machine learning model. In GPR, the prediction is a linear
    combination of previously observed values, i.e., the prediction for any test sample
    is obtained as a linear combination of the known targets from the training data
    set. The coefficients of this linear combination are determined by the distance
    (in the kernel space) between the test data point and the training data points.
    The closer in kernel space of a training data point to the test data point to
    be predicted, the stronger its contribution to the prediction. It is a powerful
    algorithm that relies on the collected data and the selected kernel to make the
    predictions instead of having to learn an extensive set of parameters. The kernel
    (i.e., the covariance function of the Gaussian process) determines the structure
    and the generalization properties of the developed GPR model. Thus, a proper kernel
    has to be selected, which allows to incorporate prior knowledge of the system
    (Rasmussen and Williams, 2005). The kernel''s parameters are learned from the
    training data set, having the estimation process the risk of ending in a local
    optima. To reduce this risk, the optimizer was re-started one thousand times in
    order to find the kernel''s parameters which maximize the log-marginal likelihood.
    The determination of the PLS internal parameters (model fitting and predictions)
    was done using the software SIMCA-P 10.0 (Umetrics, Sweden), while the fitting
    and prediction of the remaining predictive algorithms were done with Phyton and
    its module Scikit-learn (Pedregosa et al., 2011). 4. Results and discussion Fig.
    3 shows the pH and TAN concentration temporal evolutions in the feed storage tank
    of the HFMC set-up recorded along an experiment. During the N-recovery process,
    both variables in the feed storage tank decrease due to free ammonia stripping.
    In this figure, several interesting aspects can also be highlighted: • There are
    three pH increments at time instants 11, 21 and 37 min. These pH increments are
    due to the pH control system that dosed NaOH to raise the pH every time the pH
    dropped until a pH value of 10. These control actions were done to assure that
    free ammonia predominated in the N-rich feed solution thus keeping high the N-recovery
    rate along the experiment. Moreover, it can also be seen that the pH increment
    at minute 37 is significatively higher than the first pH increment (after 11 min
    of experiment), despite having dosed the same amount of NaOH. The lower the TAN
    concentration in the feed tank, the higher the pH increment after dosing a given
    amount of NaOH. Thus, the pH increments convey relevant information on the TAN
    concentration in the feed storage tank. • The pH decreases linearly along the
    experiment as the TAN concentration in the feed tank also decrease. The three
    NaOH dosages determine four periods (within the same experiment) of linear pH
    decrease. In each period of linear pH decline, the derivative (slope) was calculated
    fitting a linear regression to the pH data of that section (see four red lines
    in Fig. 3). The slope of the linear fitting is annotated in the Figure close to
    the corresponding data. Note that the absolute value of the slope is lower as
    the TAN concentration in the feed tank decreases. The pH slope depends on nitrogen
    recovery rate which in turns depends on free ammonia concentration in the feed
    tank. • The TAN concentration decreases faster at the beginning of the experiment
    (when its concentration in the feed storage tank is high) and slows down as the
    TAN concentration decreases in the feed storage tank. Thus, the decrease in TAN
    concentration is not linear, but more closely approximates a first-order kinetics.
    Finally, it should be highlighted that in this experiment the TAN concentration
    in the feed decreased from an initial concentration of 985 mg/L to a final concentration
    of 11 mg/L, thus implying a N-recovery higher than 98%. Download : Download high-res
    image (241KB) Download : Download full-size image Fig. 3. pH and TAN concentration
    temporal evolution along one experiment (batch). For each section of descending
    pH, the best linear fit was calculated (red lines) and the value of the descending
    slope (i.e., the derivative) is annotated. Fig. 4 shows the time series plot of
    pH and TAN concentration along the eight experiments performed in the laboratory
    using the pre-treated supernatant from the full-scale anaerobic mesophilic digester.
    As can be seen in this figure the duration of the experiments ranged from 45 to
    75 min. The experimental TAN concentrations were determined in the laboratory
    (represented as black dots in Fig. 4), and the continuous dashed line was used
    to train and test the machine learning models as it allowed to have the same data
    frequency as the pH (the recorded input variable): one TAN concentration value
    every 20 s. Download : Download high-res image (309KB) Download : Download full-size
    image Fig. 4. pH and TAN concentration temporal evolution along the eight experiments
    performed (8 batches). When the TAN concentration in the N-rich storage tank decreases
    below the pre-set level, the process operation should be stopped, the feed storage
    tank discharged and filled again with fresh pre-treated supernatant (i.e., new
    N-rich solution). This operational mode is known as batch mode, and it is how
    HFMCs are usually operated. The length of each recovery stage can be established
    from the percentage of nitrogen recovery desired or directly establishing a set-point
    for the final TAN concentration. Although TAN sensors and analysers exist in the
    market, they are expensive, have high maintenance requirements and their measuring
    range is limited. Thus, data-driven models that use as input the information from
    an easy-to-measure process variable (the pH) together with relevant extracted
    features (pH increments and the pH derivative), can be an appealing alternative
    to predict the TAN concentration (target) in the feed storage tank. The major
    benefit for the HFMC process would be to make it possible the optimization of
    its operation taking into account the dynamic nature of the process and providing
    flexibility to cope with influent changing composition. This would avoid the typical
    operation with a conservative fixed-time batch length. For this purpose, different
    machine learning models are assessed and compared in terms of their capacity to
    predict the TAN concentration in the feed storage tank. All of the fitted and
    tested models have a multiple input single output (MISO) structure, using the
    same three input variables to predict the TAN concentration. The detailed architecture
    for each data-driven model is presented below: • PLS: Cross-validation was used
    to determine the number of statistically significant latent variables, which resulted
    to be two in this case. The PLS model were well balanced, exhibiting fit and prediction
    performance values over 90 %. • ANN: The typical feed-forward multilayer perceptron
    was the chosen architecture to develop the TAN predictive model. According to
    cross-validation, only one-hidden layer with four neurons was necessary to obtain
    an excellent ANN model, using Rectified Linear Unit (ReLU) as activation function.
    • RF: The RF model uses regression trees to capture the nonlinear relationship
    between the TAN concentration and the input variables. According to cross-validation,
    the best values for the hyperparameters to develop the RF model were: 200 decision
    trees in the forest, a maximum depth of a tree of 8, and the number of features
    considered by each tree when splitting a node fixed to the root square of the
    number of variables. • SVR: To enable the SVR model map the nonlinear relationship
    between the TAN concentration and the input variables, a nonlinear kernel was
    selected: the Radial Basis Function (RBF) kernel. According to cross-validation
    the SVR model hyper-parameters were set as follows: gamma = 0.3334, C = 16 and
    epsilon = 0.8. • GPR: The prior mean was assumed to be constant and equal to the
    training data''s mean. The prior''s covariance was specified through the kernel
    used to compute the Gaussian Process''s covariance between datapoints. The structure
    of the kernel consisted in a Radial basis function kernel plus a white noise kernel
    to account for the noise level in the dataset. To reduce the risk of local optima,
    the optimization algorithm (L-BFGS-B) used to optimize the kernel''s parameters
    was restarted 1000 times. To assess and compare the performance of all developed
    data-driven models, Fig. 5 shows the measured TAN concentration versus the predicted
    TAN by each developed model in the test data set. The regression fit between the
    measured concentrations and the predicted values is included together with the
    coefficient of determination (R2) and the Root Mean Squared Error (RMSE). In these
    informative plots, the best performance and accuracy of the model will be reflected
    by the calculated parameters from the linear regression fit. A predictive model
    is better as the slope of the linear regression fit is closer to 1, as the constant
    (y-intercept) closer to 0, as the determination coefficient (R2) is closer to
    1 and as the RMSE exhibits a lower value. These metrics used to evaluate the performance
    of the developed machine learning models are also collected in Table 1 to facilitate
    their comparison. Download : Download high-res image (666KB) Download : Download
    full-size image Fig. 5. (a) Observed TAN concentration in the test data set versus
    the predicted values by each data-driven model (b) Importance of each input variable
    in each data-driven model. Table 1. Performance metrics of each developed model
    on the test data set. Model RMSE (mg/L) Slopea Intercepta R2 PLS 61.54 0.9520
    17.6980 0.9378 ANN 19.87 1.0109 −3.0669 0.9914 RF 29.79 0.9860 −0.6906 0.9808
    SVM 20.74 1.0029 −3.2955 0.9907 GPR 21.75 0.9872 −2.3648 0.9902 a Corresponding
    to the linear fit between measured TAN concentrations and predicted concentrations
    by the corresponding machine learning model. Looking at Fig. 5a, it is evident
    that according to these metrics, the ANN modelling was found to outperform all
    the other techniques exhibiting a very high determination coefficient (R2 = 0.99)
    and the lowest RMSE (19.87 mg/L) in the test set. It should be highlighted that
    a RMSE around 20 mg N/L is sufficiently suitable for the main practical purpose
    pursued in this work, which is to allow determining the end of each batch from
    the percentage of nitrogen recovery desired. As previously commented, the most
    direct application of having a predicted value of the TAN concentration in the
    feed storage tank is monitoring the evolution of the process and its control and
    automation. In the case of control, to determine the end of each batch, the percentage
    of nitrogen recovery can be set. Thus, the length of each batch would not be fixed,
    and can be automatically adapted to the dynamic nature of the process and the
    feed characteristics. This would avoid the HFMC process operation with conservative
    fixed-time batch duration. Since the initial TAN concentration in the feed storage
    tank is around 900 mg N/L, for a 95% of N-recovery, the process should be stopped
    at 45 mg N/L. An error of ±20 mg N/L in the TAN concentration would imply an error
    lower than 3% in the N-recovery, which is perfectly acceptable. As can be seen
    in Fig. 5a, all the non-linear machine learning models could be reasonably used
    for this purpose, although the ANN would be the best option, closely followed
    by the GPR and SVR models. Far behind it stays the linear model that would be
    discouraged in its present form due to its elevated RMSE value, its largest deviation
    from the perfect fit slope, smallest R2 and prediction of negative concentrations.
    Moreover, with the PLS model the TAN concentration is constantly underestimated
    at concentrations higher than 600 mg NH4+-N/L, while the contrary occurs in the
    lower range (i.e., concentrations lower than 300 mg NH4+-N/L) the TAN concentration
    is continuously overestimated. However, as demonstrated in Aguado et al. (2022),
    this linear model could be significatively improved expanded the input variables
    with several non-linear terms (e.g., quadratic, cubic, …) to allow the PLS model
    capture the nonlinear relationship between the TAN concentration and the input
    variables, thus making it useful to predict the TAN concentration in the present
    application. On the other hand, as can be seen in Fig. 5b, according to the permutation
    procedure it is evident that all machine learning techniques depended mainly on
    the features extracted from the pH (its derivative and increments) to predict
    the TAN concentration and that the importance of the measured pH itself is really
    low in all data-driven models tested. This fact emphasizes the importance of data
    pre-treatment (which include stages like feature engineering to extract relevant
    features from the recorded variables that are used to expand and enrich the inputs)
    in the application of data-driven models. To obtain these good prediction results
    for the TAN concentration in the feed storage tank, it was not necessary to use
    lagged variables. This reflects that the pH signal and extracted features convey
    the relevant temporal and sequential information required for predicting the real-time
    TAN concentration evolution along each batch. Testing and leveraging explicitly
    the time-series structure of the recorded variables using deep learning architectures,
    as done in other chemical engineering applications (Miao et al., 2021; Skrobek
    et al., 2022) will be carried out in a future work. In addition to process control
    and automation, the predicted TAN concentration by the data-driven model, can
    be used to monitor the N-recovery process, thus making it possible to track if
    the process is evolving as expected along each batch. This application would allow
    to visualize and track the state of the process, transforming the predicted data
    into useful and actionable information constituting the basis of good decision
    making. As an illustrative example, in Fig. 6 it is plotted the evolution of the
    ANN and GPR models’ predictions along one test experiment with the corresponding
    confidence limits together with the measured TAN concentrations. Download : Download
    high-res image (417KB) Download : Download full-size image Fig. 6. Evolution of
    TAN concentration in the HFMC storage tank along one experiment (batch) from the
    test data set together with the predicted TAN by the ANN model and the GPR model
    with the 95% confidence limits (a) the complete experiment (b) zoom at TAN concentrations
    lower than 200 mg NH4+-N/L. An inexpensive solution for real-time TAN concentration
    prediction in the feed storage tank of the membrane contactor has been shown.
    The solution is based on real-time pH measurements processed after feature extraction
    through a one-hidden layer artificial neural network. The gains of the proposed
    solution are the following: • Having a real-time, low-cost and reliable estimation
    of the TAN concentration in the feed storage tank of the hollow fibre membrane
    contactor. • The real-time estimation of the TAN concentration makes it possible
    to monitor the nitrogen recovery process in the membrane contactor as well as
    to adapt the duration of each batch to the dynamic nature of the process and the
    characteristics of the feed (in this study: supernatant of the anaerobic digester
    of a full-scale wastewater treatment plant). This avoids the operation of the
    membrane contactor with conservative fixed-time batch duration. • The TAN concentration
    estimation relies on both the real-time measurements from the pH sensor and the
    fitted artificial neural network. The pH is an inexpensive and easy-to-measure
    process variable. There is a pH sensor available in almost every wastewater treatment
    plant. • The elevated investment cost and the laborious maintenance by skilled
    staff of the commercially available real-time TAN measurement equipment (in-situ
    ion selective electrodes or ex-situ analysers) are avoided. The implementation
    of the solution in the lab-scale set-up is as follows: • The personal computer
    receives the real-time pH signal, and process it using the code implemented in
    an ad-hoc software: - to check the quality of the incoming data. - to calculate
    the pH signal derivative and the pH increments after reagent dosing. - to predict
    the TAN concentration at each time-instant using the fitted artificial neural
    network. - to monitor the TAN concentration evolution along time. - when the predicted
    TAN concentration in the feed storage tank is low enough and thus, the desired
    nitrogen-recovery has been reached, the nitrogen-rich solution in the storage
    tank must be replaced to start a new batch. - When the pH drops below 8.5 the
    nitrogen recovery rate is greatly reduced due to the low percentage of TAN in
    the form of free ammonia. Therefore, the pH should be maintained over this value
    by adding chemical reagents (NaOH) every time the process requires it. The pH
    increment after dosing the reagent is recorded. • In full-scale facilities the
    solution would be implemented somewhat similarly to the lab-scale set-up. The
    real-time sensor signal is received in these cases by the supervisory control
    and data acquisition system (SCADA). The code for all the data processing would
    be implemented in the commercial platform that the facility is already using to
    connect the SCADA to plant information systems, and other available data sources
    through industry-standard interface such as OPC. • Note that the implementation
    of the proposed solution in the HFMC of another facility requires training the
    ANN. Thus, data (pH and TAN concentration) from several batches should be recorded
    and used to train the ANN. The values of the biases and weights of the machine
    learning model are case-dependent. For example, the influent composition from
    one WWTP to another can be quite different. An important difference could be in
    the alkalinity of the influent. The alkalinity of the nitrogen rich feed solution
    (i.e., the supernatant from the anaerobic digester) affects the pH variations.
    For a given TAN concentration, the higher alkalinity in the feed solution (i.e.,
    lower ammonium/alkalinity ratio), the lower the pH variations. This would be accounted
    for during the training of the artificial neural network. Alkalinity of the feed
    solution also affects the economics of the HFMC process since it determines the
    amount of NaOH that is needed to raise the pH to assure a high percentage of TAN
    present as free ammonia thus enabling high nitrogen recovery rates. 5. Conclusions
    Process efficiency of membrane contactors for nitrogen recovery can be optimized
    via real-time measurements of TAN concentration in the nitrogen-rich feed storage
    tank. An inexpensive solution for real-time TAN concentration prediction is proposed
    based on real-time pH measurements processed after feature extraction using machine
    learning models. This work has demonstrated that it is possible to use the real-time
    pH measurements to accurately forecast the real-time time-evolution of TAN concentration
    in the feed storage tank of the membrane contactor set-up. The pH signal and extracted
    features (its derivative and increments after reagent dosing) convey enough relevant
    information to accurately predict the TAN concentration. The relationship between
    the TAN concentration (target) and the inputs (the pH signal and extracted features)
    is non-linear, thus to develop a useful predictive tool this non-linearity should
    be adequately captured. Among the different ML models tested in this work (PLS,
    ANN, SVM, RF and GPR), the feed-forward artificial neural network with one-hidden-layer
    showed the strongest predictive ability and outperformed the other tested ML models,
    exhibiting a high determination coefficient (R2 = 0.99) and a RMSE of 19.87 mg/L.
    The ANN has 4 neurons in the hidden layer with ReLU as activation function and
    the input layer is composed by 3 variables (the pH signal and its two extracted
    features). The accuracy of other non-linear data-driven techniques evaluated (like
    GPR and SVR) was also enough to allow the predictive model to be used in the intended
    application. Since the TAN concentration prediction relies on the pH sensor, for
    a reliable and accurate prediction, regular pH sensor maintenance is highly recommended.
    This can include different actions like sensor cleaning, calibration, validation,
    and replacement (when required) following standard operating procedures (SOPs)
    to assure the quality of the measurements. Having a real-time prediction of the
    TAN concentration allows monitoring the evolution of the nitrogen recovery process
    and optimize each batch duration according to the evolution of the process and
    the nitrogen-rich feed characteristics. In further work, once an expanded data
    set is available (after carrying out additional experimental work with the membrane
    contactor) it is planned analyse and quantify the benefits to explode the time-series
    structure of the recorded variables. This will be carried out using Recurrent
    Neural Networks (RNN) such as Long Short-Term Memory (LSTM) and Gated Recurrent
    Units (GRU), to predict the TAN concentration in the feed storage tank. CRediT
    authorship contribution statement D. Aguado: Conceptualization, Methodology, Formal
    analysis, Writing – original draft. G. Noriega-Hevia: Data curation, Investigation.
    J. Serralta: Conceptualization, Methodology, Reviewing. A. Seco: Supervision.
    Declaration of competing interest The authors declare that they have no known
    competing financial interests or personal relationships that could have appeared
    to influence the work reported in this paper. Acknowledgements This research was
    financially supported by the Spanish Ministry of Economy and Competitiveness (MINECO
    projects CTM2014-54980-C2-1/2-R and CTM2017-86751-C2-1/2-R) with the European
    Regional Development Fund (ERDF) as well as the Universitat Politècnica de València
    via a pre-doctoral FPI fellowship to Guillermo Noriega. We would also like to
    thank the anonymous reviewers for their suggestions that have contributed to improving
    this work. Data availability The data that has been used is confidential. References
    Aguado et al., Aguado, D. and Noriega-Hevia, G. and Ferrer, J. and Seco, A. and
    Serralta, J., Pls-Based Soft-Sensor to Predict Ammonium Concentration Evolution
    in Hollow Fibre Membrane Contactors for Nitrogen Recovery. J. Water Proc. Eng.,
    47, 102735, https://doi.org/10.1016/j.jwpe.2022.102735.. Google Scholar Ching
    et al., 2021 M.L. Ching, H.Y. Richard, T. So, Morck Advances in soft sensors for
    wastewater treatment plants: a systematic review J. Water Proc. Eng., 44 (2021),
    Article 102367, 10.1016/j.jwpe.2021.102367 View in ScopusGoogle Scholar Ching
    et al., 2022 P.M.L. Ching, X. Zou, D. Wu, R.H.Y. So, G.H. Chen Development of
    a wide-range soft sensor for predicting wastewater BOD5 using an eXtreme gradient
    boosting (XGBoost) machine Environ. Res., 210 (2022), Article 112953, 10.1016/j.envres.2022.112953
    View PDFView articleView in ScopusGoogle Scholar Cifuentes-Cabezas et al., 2023
    M. Cifuentes-Cabezas, M.J. Luján-Facundo, B. Cuartas-Uribe, A. Iborra-Clar, J.A.
    Mendoza-Roca Nitrogen recovery from sludge centrate by membrane contactor: influence
    of operating parameters and cleaning conditions J. Environ. Manag., 341 (2023),
    Article 118051, 10.1016/j.jenvman.2023.118051 View PDFView articleView in ScopusGoogle
    Scholar Cruz et al., 2019 H. Cruz, Y.Y. Law, J.S. Guest, K. Rabaey, D. Batstone,
    B. Laycock, W. Verstraete, I. Pikaar Mainstream ammonium recovery to advance sustainable
    urban wastewater management Environ. Sci. Technol., 53 (19) (2019), pp. 11066-11079,
    10.1021/acs.est.9b00603 2019 View in ScopusGoogle Scholar Drewnowski et al., 2019
    J. Drewnowski, A. Remiszewska-Skwarek, S. Duda, G. Łagód Aeration process in bioreactors
    as the main energy consumer in a wastewater treatment plant. Review of solutions
    and methods of process optimization Processes, 7 (5) (2019), p. 311, 10.3390/pr7050311
    View in ScopusGoogle Scholar Eerikäinen et al., 2020 S. Eerikäinen, H. Haimi,
    A. Mikola, R. Vahala Data analytics in control and operation of municipal wastewater
    treatment plants: qualitative analysis of needs and barriers Water Sci. Technol.,
    82 (12) (2020), pp. 2681-2690 CrossRefView in ScopusGoogle Scholar Haimi et al.,
    2013 H. Haimi, M. Mulas, F. Corona, R. Vahala Data-derived soft-sensors for biological
    wastewater treatment plants: an overview Environ. Model. Software, 47 (2013),
    pp. 88-107, 10.1016/j.envsoft.2013.05.009 2013 View PDFView articleView in ScopusGoogle
    Scholar Ingildsen and Olsson, 2016 P. Ingildsen, G. Olsson Smart Water Utilities:
    Complexity Made Simple IWA Publishing, London (2016) Google Scholar IWA and Grievson,
    2022 IWA A strategic digital transformation for the water industry Oliver Grievson
    (Ed.), Timothy Holloway and Bruce Johnson, IWA Publishing, London (2022) ISBN
    9781789063394 Google Scholar IWA and Liu, 2022b IWA Quantification and modelling
    of fugitive greenhouse gas emissions from urban water systems Ye Liu (Ed.), Jose
    Porro and Ingmar Nopens (2022) ISBN 9781789060454IWA Publishing. London Google
    Scholar Kadlec et al., 2009 P. Kadlec, B. Gabrys, S. Strandt Data-driven soft
    sensors in the process industry Comput. Chem. Eng., 33 (4) (2009), pp. 795-814,
    10.1016/j.compchemeng.2008.12.012 View PDFView articleView in ScopusGoogle Scholar
    Metcalf and Eddy, 2013 Metcalf, Eddy Wastewater Engineering: Treatment and Reuse
    (fifth ed.), 9780073401188 McGraw-Hill, New York (2013) Google Scholar Miao et
    al., 2021 S. Miao, C. Zhou, S.A. AlQahtani, M. Alrashoud, A. Ghoneim, Z. Lv Applying
    machine learning in intelligent sewage treatment: a case study of chemical plant
    in sustainable cities Elsevier Sustain. Cities Soc., 72 (2021), pp. 103009-103016,
    10.1016/j.scs.2021.103009 View in ScopusGoogle Scholar Noriega-Hevia et al., 2021
    G. Noriega-Hevia, J. Serralta, A. Seco, J. Ferrer Economic analysis of the scale-up
    and implantation of a hollow fibre membrane contactor plant for nitrogen recovery
    in a full-scale wastewater treatment plant Separ. Purif. Technol., 275 (2021),
    10.1016/j.seppur.2021.119128 Google Scholar Pedregosa et al., 2011 F. Pedregosa,
    G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer,
    R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M.
    Perrot, E. Duchesnay Scikit-learn: machine learning in Python JMLR, 12 (2011),
    pp. 2825-2830 Google Scholar Pikaar et al., 2020 I. Pikaar, X. Huang, F. Fatone,
    S. 232 Resource recovery from water: from concept to standard practice Water Res.,
    178 (2020), Article 115856, 10.1016/j.watres.2020.115856 View PDFView articleView
    in ScopusGoogle Scholar Rasmussen and Williams, 2005 Rasmussen, Williams Gaussian
    Process for Machine Learning (Adaptive Computation and Machine Learning Series)
    The MIT Press, Cambridge, Massachusetts, London, England (2005) Google Scholar
    Robles et al., 2020 A. Robles, D. Aguado, R. Barat, L. Borrás, A. Bouzas, J.B.
    Giménez, N. Martí, J. Ribes, M.V. Ruano, J. Serralta, J. Ferrer, A. Seco New frontiers
    from removal to recycling of nitrogen and phosphorus from wastewater in the Circular
    Economy Bioresour. Technol., 300 (2020), Article 122673, 10.1016/j.biortech.2019.122673
    View PDFView articleView in ScopusGoogle Scholar Rongwong et al., 2022 W. Rongwong,
    T.-H. Bae, R. Jiraratananon Economic optimization of hollow fiber membrane contactors
    for ammonia nitrogen recovery from anaerobic digestion effluents J. Environ. Chem.
    Eng., 10 (6) (2022), Article 108631, 10.1016/j.jece.2022.108631 View PDFView articleView
    in ScopusGoogle Scholar Salminen et al., 2022 J. Salminen, K. Määttä, H. Haimi,
    M. Maidell, A. Karjalainen, K. Noro, J. Koskiaho, S. Tikkanen, J. Pohjola Water-smart
    circular economy – conceptualisation, transitional policy instruments and stakeholder
    perception J. Clean. Prod., 334 (2022), 10.1016/j.jclepro.2021.130065 Google Scholar
    Skrobek et al., 2022 D. Skrobek, J. Krzywanski, M. Sosnowski, A. Kulakowska, A.
    Zylka, K. Grabowska, K. Ciesielska, W. Nowak Implementation of deep learning methods
    in prediction of adsorption processes Adv. Eng. Software, 173 (2022), 10.1016/j.advengsoft.2022.103190
    Google Scholar Schneider et al., 2019 M.Y. Schneider, J.P. Carbajal, V. Furrer,
    B. Sterkele, M. Maurer, K. Villez Beyond signal quality: the value of unmaintained
    pH, dissolved oxygen, and oxidation-reduction potential sensors for remote performance
    monitoring of on-site sequencing batch reactors Water Res., 161 (2019), pp. 639-651,
    10.1016/j.watres.2019.06.007 View PDFView articleView in ScopusGoogle Scholar
    Sheikh et al., 2023 M. Sheikh, H.R. Harami, M. Rezakazemi, C. Valderrama, J.L.
    Cortina, T.M. Aminabhavi Efficient NH3-N recovery from municipal wastewaters via
    membrane hybrid systems: nutrient-Energy-Water (NEW) nexus in circular economy
    Chem. Eng. J., 465 (2023), Article 142876, 10.1016/j.cej.2023.142876 View PDFView
    articleView in ScopusGoogle Scholar Shi et al., 2021 X. Shi, L. Zhu, B. Li, J.
    Liang, X. Li Surfactant-assisted thermal hydrolysis off waste activated sludge
    for improved dewaterability, organic release, and volatile fatty acid production
    Waste Manag., 124 (2021), pp. 339-347, 10.1016/j.wasman.2021.02.024 View PDFView
    articleView in ScopusGoogle Scholar Smith, 2003 V.H. Smith Eutrophication of freshwater
    and coastal marine ecosystems a global problem Environ. Sci. Pollut. Res., 10
    (2003), pp. 126-139, 10.1065/espr2002.12.142 View in ScopusGoogle Scholar Soler-Cabezas
    et al., 2018 J.L. Soler-Cabezas, J.A. Mendoza-Roca, M.C. Vincent-Vela, M.J. Lujan-Facundo,
    L. Pastor-Alcañiiz Simultaneous concentration of nutrients from anaerobically
    digested sludge centrate and pre-treatment of industrial effluents by forward
    osmosis Sep. Purif. Technol., 193 (2018), pp. 289-296, 10.1016/j.seppur.2017.10.058
    View PDFView articleView in ScopusGoogle Scholar Thürlimann et al., 2018 C.M.
    Thürlimann, D.J. Dürrenmatt, K. Villez Soft-sensing with qualitative trend analysis
    for wastewater treatment plant control Control Eng. Pract., 70 (2018), pp. 121-133,
    10.1016/j.conengprac.2017.09.015 View PDFView articleView in ScopusGoogle Scholar
    Vu et al., 2021 M.T. Vu, L.N. Nguyen, M.A. Hasan Johir, X. Zhang, L.D. Nghiem,
    M. Elimelech Biogas sparging to control fouling and enhance resource recovery
    from anaerobically digested sludge centrate by forward osmosis J. Membr. Sci.,
    625 (2021), Article 119176, 10.1016/j.memsci.2021.119176 View PDFView articleView
    in ScopusGoogle Scholar Yahaya et al., 2023 S.M. Yahaya, A.A. Mahmud, M. Abdullahi,
    A. Haruna Recent advances in the chemistry of nitrogen, phosphorus and potassium
    as fertilizers in soil: a review Pedosphere, 33 (3) (2023), pp. 385-406, 10.1016/j.pedsph.2022.07.012
    View PDFView articleView in ScopusGoogle Scholar Ye et al., 2020 Z. Ye, J. Yang,
    N. Zhong, X. Tu, J. Jia, J. Wang Tackling environmental challenges in pollution
    controls using artificial intelligence: a review Sci. Total Environ., 699 (2020),
    Article 134279, 10.1016/j.scitotenv.2019.134279 View PDFView articleView in ScopusGoogle
    Scholar Yuan et al., 2019 Z. Yuan, G. Olsson, R. Cardell-Oliver, K. van Schagen,
    A. Marchi, A. Deletic, C. Urich, W. Rauch, Y. Liu, G. Jiang Sweating the assets
    – the role of instrumentation, control, and automation in urban water systems
    Water Res., 155 (2019), pp. 381-402, 10.1016/j.watres.2019.02.034 2019 View PDFView
    articleView in ScopusGoogle Scholar Cited by (0) View Abstract © 2023 Elsevier
    Ltd. All rights reserved. Recommended articles Multiscale simulations of shale
    gas transport in micro/nano-porous shale matrix considering pore structure influence
    Journal of Natural Gas Science and Engineering, Volume 64, 2019, pp. 28-40 Hao
    Yu, …, HengAn Wu View PDF Hybrid path planning based on adaptive visibility graph
    initialization and edge computing for mobile robots Engineering Applications of
    Artificial Intelligence, Volume 126, Part D, 2023, Article 107110 Junlin Ou, …,
    Yi Wang View PDF A priori compression of convolutional neural networks for wave
    simulators Engineering Applications of Artificial Intelligence, Volume 126, Part
    C, 2023, Article 106973 Hamza Boukraichi, …, David Ryckelynck View PDF Show 3
    more articles Article Metrics Captures Readers: 5 View details About ScienceDirect
    Remote access Shopping cart Advertise Contact and support Terms and conditions
    Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices
    All content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors.
    All rights are reserved, including those for text and data mining, AI training,
    and similar technologies. For all open access content, the Creative Commons licensing
    terms apply."'
  inline_citation: '>'
  journal: Engineering Applications of Artificial Intelligence
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Using machine learning techniques to predict ammonium concentration in membrane
    contactors for nitrogen recovery as a valuable resource
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Li R.
  - Zhang J.
  - Zhao X.
  - Wang D.
  - Hann M.
  - Greaves D.
  citation_count: '3'
  description: Accurate prediction of ocean waves plays an essential role in many
    ocean engineering applications, such as the control of wave energy converters
    and floating wind turbines. However, existing studies on phase-resolved wave prediction
    using machine learning mainly focus on two-dimensional wave data, while ocean
    waves are usually three-dimensional. In this work, we investigate, for the first
    time, the phase-resolved real-time prediction of three-dimensional waves using
    machine learning methods. Specifically, the wave prediction is modeled as a supervised
    learning task aiming at learning mapping relationships between the input historical
    wave data and the output future wave elevations. Four frequently-used machine
    learning methods are employed to tackle this task and a novel Dual-Branch Network
    (DBNet) is proposed for performance improvement. A group of wave basin experiments
    with nine directional wave spectra under three sea states are first conducted
    to collect the data of 3D waves. Then the wave data are used for verifying the
    effectiveness of the machine learning methods. The results demonstrate that the
    upstream wave data measured by the gauge array can be used for control-oriented
    wave forecasting with a forecasting horizon of more than 20 s, where the directional
    information provided by the upstream gauge array is vital for accurately predicting
    the downstream wave elevations. In addition, further investigations show that
    by using only local wave data (which can be easily obtained), the very short-term
    phase-resolved prediction (less than 5 s) can be achieved.
  doi: 10.1016/j.apenergy.2023.121529
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords Nomenclature 1. Introduction 2. Methodology
    3. Results and discussions 4. Conclusions CRediT authorship contribution statement
    Declaration of Competing Interest Acknowledgments Data availability References
    Show full outline Cited by (3) Figures (12) Show 6 more figures Tables (6) Table
    1 Table 2 Table 3 Table 4 Table 5 Table 6 Applied Energy Volume 348, 15 October
    2023, 121529 Phase-resolved real-time forecasting of three-dimensional ocean waves
    via machine learning and wave tank experiments Author links open overlay panel
    Rui Li a, Jincheng Zhang a, Xiaowei Zhao a, Daming Wang b, Martyn Hann b, Deborah
    Greaves b Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.apenergy.2023.121529
    Get rights and content Under a Creative Commons license open access Highlights
    • Phase-resolved real-time forecasting for 3D ocean waves is achieved. • A novel
    machine learning method is proposed based on CNN and MLP. • A group of wave tank
    experiments are carried out to collect 3D wave data. • Both upstream and local
    wave information are explored for wave forecasting. • The significance of directional
    information for 3D wave forecasting is investigated. Abstract Accurate prediction
    of ocean waves plays an essential role in many ocean engineering applications,
    such as the control of wave energy converters and floating wind turbines. However,
    existing studies on phase-resolved wave prediction using machine learning mainly
    focus on two-dimensional wave data, while ocean waves are usually three-dimensional.
    In this work, we investigate, for the first time, the phase-resolved real-time
    prediction of three-dimensional waves using machine learning methods. Specifically,
    the wave prediction is modeled as a supervised learning task aiming at learning
    mapping relationships between the input historical wave data and the output future
    wave elevations. Four frequently-used machine learning methods are employed to
    tackle this task and a novel Dual-Branch Network (DBNet) is proposed for performance
    improvement. A group of wave basin experiments with nine directional wave spectra
    under three sea states are first conducted to collect the data of 3D waves. Then
    the wave data are used for verifying the effectiveness of the machine learning
    methods. The results demonstrate that the upstream wave data measured by the gauge
    array can be used for control-oriented wave forecasting with a forecasting horizon
    of more than 20 s, where the directional information provided by the upstream
    gauge array is vital for accurately predicting the downstream wave elevations.
    In addition, further investigations show that by using only local wave data (which
    can be easily obtained), the very short-term phase-resolved prediction (less than
    5 s) can be achieved. Previous article in issue Next article in issue Keywords
    3D wavesConvolutional neural networkMachine learningMultilayer perceptronPhased-resolved
    wave forecastingWave tank experiments Nomenclature Abbreviations 2D Two-Directional
    3D Three-Directional ANN Artificial Neural Network BN Batch Normalization BNN
    Bayesian Neural Network CBR CNN + BN + ReLU CNN Convolutional Neural Network CRNN
    Convolutional Recurrent Neural Network DBNet Dual-Branch Network GRU Gated Recurrent
    Unit HF High Frequency HOS Higher-Order Spectral LSTM Long Short-Term Memory MAE
    Mean Absolute Error ML Machine Learning MLP Multilayer Perceptron MPC Model Predictive
    Control NLS Non-Linear Schrödinger ReLU Rectified Linear Unit RNN Recurrent Neural
    Network RMSE Root Mean Square Error SCRTP Scientific Computing Research Technology
    Platform SVM Support Vector Machines WEC Wave Energy Converter WG Wave Gauge Symbols
    The expected loss The ML model The significant wave height The whole number of
    predictions in the training set The historical time steps for the input The loss
    function The predicted time horizon using local wave information The whole number
    of predictions in the test set The predicted time horizon using upstream wave
    information The current time step The peak spectral wave period The reference
    future wave elevations measured by wave gauges The approximate future wave elevations
    predicted by ML models The input historical wave information measured by wave
    gauges The approximate future wave elevation of WG4 predicted by the ML model
    from time steps to The historical wave information measured by WG4 from time steps
    to The historical wave information measured by WG2, WG5, WG6, WG7 and WG8 from
    time steps to The approximate wave elevation of WG4 predicted by the ML model
    at time step The wave elevation measured by WG4 at time step The wave elevation
    measured by WG2, WG5, WG6, WG7 and WG8 at time step The tradeoff parameter of
    The parameters of the ML model The regularization term 1. Introduction As one
    of the main renewable energy sources, wave energy is an important and promising
    low-carbon alternative to fossil fuels. Although many kinds of Wave Energy Converters
    (WECs) have been designed and verified [1], [2], when compared to solar and wind
    energy, wave energy is still far from being commercially competitive [3]. One
    major challenge in further reducing the cost of wave energy is the design of a
    control technique suitable for various sea states. To improve the control performance,
    the preview-based hydrodynamic control [4], [5], [6] has been proposed where the
    controller is designed to react in advance before the waves hit the WEC structures.
    It can significantly enhance the power generation of WECs [7]. For example, the
    investigation of an Azura WEC under experimental conditions showed that a 36%
    improvement in power generation could be achieved by the Model Predictive Control
    (MPC) compared with the standard fixed damping control [8]. However, the WEC control
    is a non-causal optimal control problem [9] where the current control decision
    must be based on the future wave excitation force [6]. Thus, the real-time forecasting
    of the wave information is essential for executing energy-maximizing controllers
    [10]. A feasible and promising scheme to obtain the future wave excitation force
    is to compute it from wave elevation predictions [11], [12]. Indeed, as an essential
    technology in WEC control design, wave elevation prediction has drawn a lot of
    attention and has now become an active research area. Based on the spectral transport
    and energy balance equations, the traditional phase-averaged wave forecasting
    method aims at predicting the wave spectrum instead of the wave profile shape
    [13]. The frequently-used third-generation models such as WAVEWATCH III [14],
    SWAN [15] and WAM [16] can provide statistical quantities, such as sea states
    defined by 1-hour or 3-hour statistics, including the significant wave height
    ( ), the peak spectral wave period ( ) and the mean wave direction [17]. Although
    meaningful guidance for the WEC design can be derived from these works, they cannot
    be used in real-time WEC control applications as the phase-resolved wave elevation
    is unavailable [18]. The phase-resolved wave model has drawn more and more attention
    in recent years, which is of particular interest for the preview-based control
    of WECs [19]. To significantly enhance the performance of the WEC controllers,
    a forecast with at least a 20 s time horizon is usually required [20]. However,
    achieving an accurate prediction for such a long-time horizon is exceptionally
    challenging, which has become one of two essential barriers in practical applications
    for WEC control (the other barrier is the physical implementation of the control
    system) [21]. Although the models [22], [23] based on linear wave theory can forecast
    the downstream wave elevation from the upstream information in real-time, they
    are only effective for the very short-term prediction and are limited to the sea
    states with small steepness [17]. Thus, more and more non-linear approaches such
    as Higher-Order Spectral (HOS) methods have been proposed in recent years [24],
    [25]. For example, a novel wave forecast model coupling ensemble Kalman filter
    and HOS method was proposed in [24] and enhanced in [26] by simultaneously estimating
    the ocean current field. In practice, restricted by the intensive computational
    requirement of HOS, the reduced order or approximate equations are usually considered
    efficient alternatives [19]. For example, many prediction models are based on
    the model equations, such as the weakly Non-Linear Schrödinger (NLS) models [27],
    [28]. Typically, the high-order NLS equation is an order faster than the HOS method
    but is less accurate, as the former normally assumes a narrow-banded wave field
    and small steepness [28]. Recently, Machine Learning (ML), a data-driven method,
    has shown great potential in automatically capturing non-linear and hierarchical
    features. A series of ML-based studies have been conducted to predict the statistical
    wave characteristics such as the significant wave height [29], [30], [31], peak
    spectral wave period [32], [33], [34] and wave speed [35]. The machine learning
    method has also been applied to phase-resolved wave forecasting. For example,
    in [19], a Convolutional Recurrent Neural Network (CRNN) was proposed to predict
    non-linear dispersive non-breaking wave evolution including rogue waves. The Artificial
    Neural Network (ANN) was adopted by [17] for unidirectional wave prediction. The
    ANN model was also applied in long-crest wave prediction [18] and verified under
    unknown sea states [36]. Two forecast algorithms, including an ML-based Support
    Vector Machines (SVM) regression, were used in [37] to forecast wave elevations
    and wave excitation forces, which were then applied for feed-forward control of
    offshore floating wind turbines. The Bayesian Neural Network (BNN) was also introduced
    and applied to phase-resolved real-time wave prediction in [38], where both the
    aleatory and epistemic uncertainties were thoroughly investigated. However, two
    critical limitations hugely reduce their practical value in engineering applications.
    First, a single model cannot handle different sea states. For example, in [18],
    four ANN models were trained respectively for four different sea states (i.e.
    sea state 4–7) and then used to forecast the corresponding wave elevations. When
    generalizing a trained model to an unknown sea state, the error would surge significantly
    (about 6 to 11 times compared to the trained sea state) [36]. In [19], the performance
    of their CRNN was only verified by sea state 6. Three ANN models were trained
    for three different wave conditions in [39] based on simulated multi-directional
    waves. Obviously, a universal model that can cope with different sea states is
    better than multiple models for different scenarios, as the latter is not only
    time-consuming but also error-prone. Second, the existing ML-based phase-resolved
    forecasting works still mainly focus on unidirectional waves, such as [17], [37].
    In practice, ocean waves are usually three-dimensional (3D) except for near-shore
    areas where waves align due to shoaling [40]. Thus, the prediction of 3D ocean
    waves needs great attention. Download : Download high-res image (212KB) Download
    : Download full-size image Fig. 1. The layout of the wave basin experiments, where
    WG2, WG5, WG6, WG7 and WG8 constitute the pentagonal gauge array. As shown in
    Table 1, the existing phase-resolved wave forecasting methods based on deep learning
    mainly focus on 2D wave data, where the only research involving 3D wave [39] is
    still based on simulation data instead of more realistic tank experiments. Moreover,
    most deep learning models for wave forecasting can only handle a single sea state,
    while different sea states need multiple and separately-trained models to predict.
    This issue seriously limits their practical use as the model will need a pre-processing
    procedure to identify the state of the input historical wave data. If the sea
    state was wrongly classified or the input data was not enough to be distinguished,
    then the prediction accuracy would be very low as the adopted model would not
    match the sea state (about 6 to 11 times lower compared to the matched model for
    2D waves [36]). To overcome the above limitations of existing works, this paper
    employs four ML-based methods and proposes a novel Dual-Branch Network (DBNet)
    for the phase-resolved forecasting of 3D waves, where the ML models are designed
    to handle multiple sea states simultaneously. To be specific, in this work, a
    group of wave basin experiments is conducted first, where nine different directional
    wave spectra under three sea states are generated. Then, four frequently-used
    ML-based methods, including Gated Recurrent Unit (GRU) network, Long Short-Term
    Memory (LSTM) network, Multilayer Perceptron (MLP) and Convolutional Neural Network
    (CNN), are trained and adopted to forecast the wave elevation for all nine wave
    conditions under three sea states without retraining multiple times. Further,
    by combining the advantages of both MLP and CNN, a novel DBNet is proposed with
    an MLP-based branch and a CNN-based branch for wave prediction, which can predict
    future wave elevation with better performance than the other four ML-based methods.
    As far as we know, this work is the first attempt to apply machine learning for
    the phase-resolved real-time forecasting of 3D waves based on wave tank experiments.
    The results of the experimental data show that the relative Root Mean Square Error
    (RMSE) of the proposed DBNet is about 11.6% normalized by the significant wave
    height (averaged for nine wave conditions), which is much better than the scheme
    for unidirectional wave prediction in [36] (where the problem itself is easier
    than the prediction of 3D waves) which generalizes a trained model to unknown
    sea states (14.7% on average). The main contributions and novelties of this paper
    are summarized as follows: Table 1. The comparison of the proposed wave forecasting
    method with existing methods in the literature, where Multiple means multiple
    models are trained for different sea states and Universal means a single universal
    model is trained for different sea states. Reference Main contribution Wave and
    model features Empty Cell Empty Cell Data generation Wave dimensions Model [18]
    An ANN-WP model for prediction Tank experiments 2D Multiple [36] The ANN-WP for
    unknown sea states Tank experiments 2D Multiple [37] Wave prediction for control
    Tank experiments 2D Multiple [19] A CRNN model for prediction Numerical simulations
    2D Multiple [39] An ANN model for prediction Numerical simulations 2D & 3D Multiple
    [17] An ANN model for prediction Numerical simulations 2D Universal [38] The evaluation
    of prediction uncertainty Tank experiments 2D Universal This work A DBNet model
    for 3D wave prediction Tank experiments 3D Universal (1) The phase-resolved real-time
    forecasting of 3D waves using machine learning methods is comprehensively investigated.
    Two major limitations of existing works that significantly hinder the potential
    of ML-based wave prediction, i.e. the generalization of the model to diverse sea
    states and the prediction of 3D waves (the existing works based on ML and wave
    tank experiments are all on 2D waves), are both tackled in this paper. The comparison
    of the proposed wave forecasting method with existing methods in the literature
    is summarized in Table 1. (2) The performance of four frequently-used machine
    learning methods, including GRU, LSTM, MLP and CNN, are investigated and verified
    for the phase-resolved forecasting of 3D waves. Moreover, a novel DBNet is proposed
    to further enhance the accuracy of ML-based methods which can take advantage of
    both MLP and CNN. (3) A series of wave tank experiments are conducted with nine
    different directional wave spectra under three sea states. The above five ML-based
    phase-resolved prediction models are then trained, validated and tested to learn
    the mapping relationships between the input historical wave data and the output
    future wave elevations. (4) Two types of input historical wave data are studied
    for predictions of 3D waves, i.e. the upstream wave information measured by the
    gauge array and the local wave information measured by a single gauge. The quantitative
    results show that the former can enable the model to achieve control-oriented
    phase-resolved prediction (more than 20 s), while the latter can achieve very
    short-term prediction (less than 5 s). Moreover, the significance of the directional
    information for phase-resolved forecasting is also demonstrated. The remaining
    part of this paper is organized as follows: the wave basin experiments, the problem
    formalization and the ML-based models are described in Section 2. The results
    are reported and discussed in Section 3. The conclusions are finally drawn in
    Section 4. 2. Methodology 2.1. Wave basin experiments The wave basin experiments
    are conducted according to the characteristics of the WaveHub test site located
    16 km offshore from Hayle on the north coast of Cornwall at the eastern edge of
    the Atlantic Ocean with an average water depth of 50 m. Two High Frequency (HF)
    radars are installed to cover the same ocean area to obtain the directional information
    of waves which collect 3161 hourly high-quality directional wave spectra from
    April 2nd, 2012 to December 4th, 2012. Then, the -means clustering technique is
    employed to obtain a small number of conditions that can represent the characteristics
    of the measured ocean area, where nine typical conditions clustered in three groups
    are eventually determined. Based on the -means clustering results, those nine
    representative conditions are then divided into three corresponding groups (one,
    three and five spectrum/spectra in each group, respectively). After that, the
    corresponding wave basin experiments are carried out based on the representative
    conditions. As shown in Fig. 1, eight Wave Gauges (WGs) are mounted in the basin
    to measure the wave elevation. Nine representative directional wave spectra are
    created using a single summation method, which means each frequency component
    has a unique wave direction. Based on MATLAB, the wave creation files for different
    wave cases are created by defining the wave amplitude, direction and phase angle
    with corresponding frequency components. Before the creation of the input file,
    each directional wave spectrum is adjusted to guarantee that the dominant wave
    direction is the same as the wave maker direction. The scale ratio of the wave
    is 1:25 and the repeat time for the directional wave generation is 45 min (3.75
    h in full scale with a scaling factor of using the Froude scaling law). For each
    condition, about points are sampled. The measured values of the significant wave
    height ( ) and the peak spectral wave period ( ) of each directional spectrum
    are shown in Table 2. Table 2. The measured and of nine directional wave spectra,
    which have been transformed to the full scale. Group Wave condition Sea state
    (m) (s) 1 1 4 1.875 8.845 2 2 5 2.550 8.930 3 5 4.000 9.890 4 4 1.400 8.310 3
    5 4 1.325 8.385 6 5 3.375 9.575 7 6 4.775 10.565 8 5 3.300 8.645 9 4 2.300 8.655
    2.2. Problem formalization Two different types of inputs, i.e. the historical
    wave information measured by the upstream gauge array and by the local gauge,
    are investigated for the phase-resolved forecasting of 3D waves, which are illustrated
    in Fig. 2. For the first scenario, as shown in Fig. 2(a), the historical upstream
    wave information from time steps to measured by the WG2, WG5, WG6, WG7 and WG8
    is selected as the input, while the downstream future wave elevation from time
    steps to measured by WG4 is chosen as the output. Then, the target of an ML-based
    model is to predict the future wave elevation, i.e. from to based on the historical
    upstream wave information, i.e. from to , which can be expressed as: (1) where
    is the ML-based model and represents the parameters of . means the historical
    time steps and indicates the predicted future time steps. represents the future
    wave elevation of WG4 predicted by the ML model from time steps to , while denotes
    the historical wave information measured by WG2, WG5, WG6, WG7 and WG8 from time
    steps to . Download : Download high-res image (195KB) Download : Download full-size
    image Fig. 2. The phase-resolved real-time forecasting of 3D waves using (a) the
    wave information measured by the upstream gauge array and (b) the wave information
    measured by the local gauge. For the second scenario, as shown in Fig. 2(b), the
    historical local wave information from time steps to measured by the WG4 itself
    is selected as the input, while the future wave elevation from time steps to measured
    by WG4 is chosen as the output. Then, the target of an ML-based model is to predict
    the future wave elevation, i.e. from to based on the historical local wave information,
    i.e. from to , which can be expressed as: (2) where indicates the predicted future
    time steps. represents the future wave elevation of WG4 predicted by the ML model
    from time steps to , while denotes the local historical wave information measured
    by WG4 itself from time steps to . Hence, given an ML-based model , the target
    is to narrow the gap between the predicted wave elevation approximation and the
    real measured wave elevation as closely as possible by optimizing the parameters
    : (3) where and represent the future wave elevations measured by the gauge and
    predicted by the ML model, while means the input historical wave information.
    indicates the expected loss, where the loss function measures the disparity between
    the real measured and predicted wave elevation and is the regularization term
    weighted by the trade-off parameter . represents the whole number of predictions
    in the training set. 2.3. Machine learning methods As illustrated in Section 2.2,
    the input and output of the phase-resolved wave forecasting are both time-series
    wave elevations, which can be naturally modeled as a sequence-to-sequence problem
    from the machine learning perspective [41], [42]. Therefore, four frequently-used
    sequence-to-sequence models, i.e. GRU, LSTM, MLP and CNN, are employed for resolving
    the wave forecasting problem. Meanwhile, to further improve the accuracy, a novel
    DBNet is proposed which combines the advantages of MLP and CNN. Download : Download
    high-res image (184KB) Download : Download full-size image Fig. 3. The structure
    of the proposed DBNet, where FCLayer means the fully connected layer and CBR represents
    the convolutional layer with the BN operation and the ReLU activation function.
    Table 3. The detailed setting of each layer in the DBNet where the wave elevations
    measured by the upstream gauge array are used as input. Name Input size Output
    size Channel Kernel Stride Padding CBR Conv 4 (3, 7) (1, 1) (1, 3) BN 4 – – –
    ReLU – – – – Conv 1 (5, 3) (1, 1) (0, 1) FCLayer1 – – – – FCLayer2 – – – – 2.3.1.
    LSTM and GRU LSTM and GRU are two typical Recurrent Neural Networks (RNNs), while
    RNNs are designed to address sequential data with temporal dependencies such as
    text, audio and video. The LSTM is proposed to overcome the short-term memory
    problem of RNN [43]. An additional memory cell is equipped to store the information
    and three gates, i.e. input gate, output gate and forget gate, are designed to
    control the inside state of the LSTM cell. As a simple variant of LSTM, GRU only
    has two gates, named the update gate and the reset gate [44]. Without any extra
    memory cells to keep the information, what GRU can control is only the information
    inside the unit. The number and size of the hidden layer in the LSTM and GRU are
    set as 1 and 128 for the phase-resolved wave prediction. 2.3.2. MLP As one of
    the most classical kinds of neural networks, MLP consists of three layers, i.e.
    the input layer, the middle hidden layer and the output layer. Each layer constitutes
    several neurons, while each connection between neurons has its own weight. The
    information flows are unidirectionally transferred from the input layer to the
    output layer, passing through the hidden layers. Those perceptrons in the same
    layer share the same activation function, which is usually a sigmoid function
    for the hidden layer. The activation function for the output layer depends typically
    on the practical application, which can be a sigmoid or a linear function. The
    MLP used in the comparison study is a three-layer structure with a sigmoid activation
    function after the second layer. The output sizes of the first two layers of the
    MLP are 256 and 128, while the length of prediction steps determines the output
    size of the third layer. 2.3.3. CNN CNN is originally employed for image pattern
    recognition with the ability to extract hierarchical features. Normally, CNN is
    constructed by four different layers: convolutional layer, non-linear activation
    layer, pooling layer and fully connected layer. With a set of kernels, convolutional
    layers convolve the input pixels, thereby generating the so-called feature map
    that summarizes the presence of detected features in the input. Then, the obtained
    feature map is activated by the element-wise non-linear activation layers. Next,
    pooling layers aggregate adjacent pixels based on the max or mean operation, which
    is not used in our wave prediction task. Finally, each node in the previous layer
    is directly connected to every node in the next layer by the fully connected layer.
    For comparison, the structure of CNN is designed the same as the CNN-branch (i.e.
    the CBR1, CBR2, CBR3, Conv and FCLayer2 in Fig. 3 with the detailed setting in
    Table 3) of the proposed DBNet. 2.3.4. DBNet Obviously, both linear and non-linear
    relationships exist between the input historical wave information and output future
    wave elevation. Thus, for phase-resolved forecasting of 3D waves, a novel Dual-Branch
    Network is proposed where an extra MLP-based branch is designed to be parallel
    with a CNN-based branch for enhancing linear features and long-range dependencies.
    The structure of the proposed DBNet can be seen in Fig. 3. The MLP-based branch
    is a relatively simple structure constructed with only a single fully connected
    layer without any activation function, i.e. FCLayer1 in Fig. 3. Without the activation
    function, the MLP is a linear regression model which can only learn linear relationships
    in the data. Meanwhile, as all input points are directly and fully connected by
    the MLP layer, the long-range dependencies between the input can be then captured.
    On the other hand, for the CNN-based branch, three convolutional layers with the
    Batch Normalization (BN) operation and the Rectified Linear Unit (ReLU) activation
    function, i.e. CBR1, CBR2 and CBR3, are stacked. With the ReLU, the non-linearity
    property can be introduced to the CNN-based branch. Finally, the output of the
    CBR3 is fed into a convolutional layer to reduce the number of feature map channels.
    The features extracted by the MLP-based and CNN-based branches are added first
    and then fed into the final fully connected layer, i.e. FCLayer2, thereby generating
    the final future wave elevation sequence. The details of each component within
    the DBNet are provided in Table 3. 2.4. Model training The data collected by the
    wave basin experiment are first re-sampled on a scale of 8, generating about 45,000
    re-sampled points. Then, each re-sampled point represents 0.3 s in the real world.
    Thereafter, 40% of the re-sampled points (the first 18.0 min of each wave condition)
    are selected as the training set, 10% (18.0–22.5 min of each wave condition) for
    validation and 50% (the last 22.5 min of each wave condition) for testing. For
    training the machine learning models, the Mean Squared Error (MSE) is selected
    as the loss function: (4) By minimizing , the model is driven to approximate the
    real measured wave elevation as closely as possible. 2.5. Evaluation metrics The
    performance of the ML-based models is evaluated by Mean Absolute Error (MAE) to
    measure the mean absolute difference and Root Mean Squared Error (RMSE) to reflect
    the square root of the average squared difference: (5) (6) where is the whole
    number of predictions in the test set, while and represent the measured and predicted
    future wave elevations respectively. The metrics are then normalized by the corresponding
    significant height to observe the relative errors: (7) (8) 3. Results and discussions
    To comprehensively analyze the phase-resolved forecasting of 3D waves, two prediction
    scenarios, i.e. wave forecasting using upstream information and local information,
    are designed. In the first scenario, the performance of all five methods is thoroughly
    compared. Then, the significance of the directional information is verified by
    the comparative studies. Finally, the impacts of the different lengths of input
    and output time horizons are investigated. In the second scenario, using the local
    wave information as the input, all five methods are compared first and then the
    errors with different output future time horizons are explored. Download : Download
    high-res image (564KB) Download : Download full-size image Fig. 4. The error distributions
    of ML-based methods over the whole prediction time domain using upstream historical
    wave information measured by WG2, WG5, WG6, WG7 and WG8, where the error for each
    time step is averaged over all the experimental wave data in the test set. (a)–(i)
    represent the nine wave conditions. Download : Download high-res image (1MB) Download
    : Download full-size image Fig. 5. The wave elevations measured in experiments
    (red) and the prediction results by DBNet (blue) during the 7400 s to 7800 s,
    where the inputs are the upstream historical wave information measured by WG2,
    WG5, WG6, WG7 and WG8. (a)–(i) represent the nine wave conditions. Download :
    Download high-res image (1MB) Download : Download full-size image Fig. 6. The
    wave elevations measured in experiments (red) and the prediction results by DBNet
    (blue) during the 7400 s to 7800 s, where the inputs are the upstream historical
    wave information measured by WG2, WG7 and WG8. (a)–(i) represent the nine wave
    conditions. Download : Download high-res image (1MB) Download : Download full-size
    image Fig. 7. The wave elevations measured in experiments (red) and the prediction
    results by DBNet (blue) during the 7400 s to 7800 s, where the inputs are the
    upstream historical wave information measured by WG2. (a)–(i) represent the nine
    wave conditions. 3.1. Wave forecasting using upstream information In this part,
    wave forecasting using upstream information is investigated. Specifically, the
    input of models is set as the historical upstream wave information measured by
    the gauge array, i.e. WG2, WG5, WG6, WG7 and WG8, while the target output is the
    future wave elevation measured by WG4. 3.1.1. Performance of different methods
    Five machine learning methods are trained by the data of all nine wave conditions
    under three sea states. That is to say, each model is designed to learn mapping
    relationships between input and output for all nine wave conditions simultaneously
    instead of training three different models for three sea states. In these studies,
    the length of input points is set as 300 (90 s in full scale) and 85 for output
    (25.5 s in full scale). As shown in Table 4, all ML-based models can perform relatively
    well, especially considering the unavoidable noises during the wave basin experiments.
    Although the MAE and RMSE have considerable disparity for different wave conditions,
    the relative errors, i.e. MAE% and RMSE% normalized by the significant height,
    maintain the same level, demonstrating that the normalized prediction errors are
    better metrics for overall performance. Table 4. The prediction errors measured
    by MAE (m), RMSE (m), MAE% and RMSE% for all methods under nine wave conditions
    using upstream wave information. Each method is trained, validated and tested
    ten times and then the means and standard deviations are reported. Please notice
    the MAE and RMSE are transformed to the full scale. Con. Method MAE RMSE MAE%
    RMSE% 1 GRU 0.17528 ± 0.00146 0.22353 ± 0.00168 9.348 ± 0.078 11.992 ± 0.090 LSTM
    0.16986 ± 0.00166 0.21681 ± 0.00210 9.059 ± 0.089 11.563 ± 0.112 MLP 0.17756 ±
    0.00079 0.22590 ± 0.00094 9.470 ± 0.042 12.048 ± 0.050 CNN 0.17587 ± 0.00146 0.22427
    ± 0.00172 9.380 ± 0.078 11.961 ± 0.092 DBNet 0.16982 ± 0.00057 0.21704 ± 0.00068
    9.057 ± 0.030 11.576 ± 0.036 2 GRU 0.23358 ± 0.00117 0.29686 ± 0.00162 9.160 ±
    0.046 11.642 ± 0.063 LSTM 0.23086 ± 0.00172 0.29357 ± 0.00228 9.053 ± 0.068 11.513
    ± 0.090 MLP 0.23035 ± 0.00064 0.29246 ± 0.00082 9.033 ± 0.025 11.469 ± 0.032 CNN
    0.23611 ± 0.00190 0.29936 ± 0.00225 9.259 ± 0.075 11.740 ± 0.088 DBNet 0.22900
    ± 0.00063 0.29079 ± 0.00081 8.980 ± 0.025 11.404 ± 0.032 3 GRU 0.37291 ± 0.00264
    0.47972 ± 0.00337 9.323 ± 0.066 11.993 ± 0.084 LSTM 0.38649 ± 0.00574 0.49763
    ± 0.00716 9.662 ± 0.143 12.441 ± 0.179 MLP 0.36157 ± 0.00132 0.46534 ± 0.00157
    9.039 ± 0.033 11.633 ± 0.039 CNN 0.36894 ± 0.00305 0.47399 ± 0.00369 9.223 ± 0.076
    11.850 ± 0.092 DBNet 0.35724 ± 0.00116 0.46019 ± 0.00141 8.931 ± 0.029 11.505
    ± 0.035 4 GRU 0.14331 ± 0.00133 0.18155 ± 0.00169 10.237 ± 0.095 12.968 ± 0.120
    LSTM 0.13547 ± 0.00177 0.17171 ± 0.00230 9.676 ± 0.126 12.265 ± 0.164 MLP 0.14465
    ± 0.00070 0.18350 ± 0.00089 10.322 ± 0.050 13.107 ± 0.064 CNN 0.14141 ± 0.00115
    0.17914 ± 0.00140 10.100 ± 0.082 12.796 ± 0.100 DBNet 0.13731 ± 0.00037 0.17408
    ± 0.00047 9.808 ± 0.027 12.435 ± 0.033 5 GRU 0.13460 ± 0.00112 0.17076 ± 0.00128
    10.159 ± 0.085 12.888 ± 0.096 LSTM 0.12573 ± 0.00143 0.15936 ± 0.00182 9.489 ±
    0.108 12.027 ± 0.138 MLP 0.13581 ± 0.00070 0.17061 ± 0.00086 10.250 ± 0.053 12.876
    ± 0.065 CNN 0.12979 ± 0.00082 0.16440 ± 0.00098 9.795 ± 0.062 12.408 ± 0.074 DBNet
    0.12606 ± 0.00034 0.15976 ± 0.00043 9.514 ± 0.025 12.057 ± 0.032 6 GRU 0.30010
    ± 0.00146 0.38391 ± 0.00201 8.892 ± 0.043 11.375 ± 0.059 LSTM 0.30250 ± 0.00277
    0.38762 ± 0.00342 8.963 ± 0.082 11.485 ± 0.101 MLP 0.29169 ± 0.00081 0.37382 ±
    0.00104 8.643 ± 0.024 11.076 ± 0.031 CNN 0.30098 ± 0.00268 0.38554 ± 0.00312 8.918
    ± 0.080 11.423 ± 0.093 DBNet 0.29096 ± 0.00098 0.37358 ± 0.00119 8.621 ± 0.029
    11.069 ± 0.035 7 GRU 0.46248 ± 0.00296 0.60028 ± 0.00428 9.685 ± 0.062 12.571
    ± 0.090 LSTM 0.48255 ± 0.00936 0.62557 ± 0.01156 10.106 ± 0.196 13.101 ± 0.242
    MLP 0.44957 ± 0.00193 0.58447 ± 0.00256 9.415 ± 0.041 12.240 ± 0.054 CNN 0.44456
    ± 0.00324 0.57721 ± 0.00383 9.310 ± 0.068 12.088 ± 0.080 DBNet 0.43487 ± 0.00126
    0.56505 ± 0.00151 9.107 ± 0.026 11.833 ± 0.032 8 GRU 0.31521 ± 0.00121 0.39941
    ± 0.00162 9.552 ± 0.037 12.103 ± 0.049 LSTM 0.31813 ± 0.00171 0.40338 ± 0.00228
    9.640 ± 0.052 12.224 ± 0.069 MLP 0.30688 ± 0.00071 0.38868 ± 0.00096 9.299 ± 0.022
    11.778 ± 0.029 CNN 0.31537 ± 0.00348 0.39990 ± 0.00447 9.557 ± 0.105 12.118 ±
    0.135 DBNet 0.30607 ± 0.00088 0.38793 ± 0.00114 9.275 ± 0.027 11.755 ± 0.035 9
    GRU 0.21181 ± 0.00135 0.26933 ± 0.00149 9.209 ± 0.059 11.710 ± 0.065 LSTM 0.20713
    ± 0.00148 0.26357 ± 0.00195 9.006 ± 0.064 11.460 ± 0.085 MLP 0.21177 ± 0.00072
    0.26821 ± 0.00091 9.207 ± 0.031 11.662 ± 0.040 CNN 0.21464 ± 0.00199 0.27282 ±
    0.00237 9.332 ± 0.086 11.862 ± 0.103 DBNet 0.20760 ± 0.00066 0.26401 ± 0.00080
    9.026 ± 0.029 11.479 ± 0.035 Avg. GRU 0.26103 ± 0.00163 0.33393 ± 0.00212 9.435
    ± 0.059 12.070 ± 0.076 LSTM 0.26208 ± 0.00307 0.33547 ± 0.00387 9.473 ± 0.111
    12.125 ± 0.140 MLP 0.25665 ± 0.00093 0.32811 ± 0.00117 9.277 ± 0.034 11.859 ±
    0.042 CNN 0.25863 ± 0.00220 0.33074 ± 0.00265 9.348 ± 0.080 11.954 ± 0.096 DBNet
    0.25099 ± 0.00076 0.32138 ± 0.00094 9.072 ± 0.027 11.616 ± 0.034 The prediction
    errors of two RNN models, i.e. GRU and LSTM, are larger than other methods, whose
    average RMSE% are about 12.1%. The reason is that it is still an extremely challenging
    task for RNNs to learn dependencies between distant positions, especially for
    long input sequences, albeit LSTM and GRU have been specifically optimized to
    resolve the short-term memory problem. The results of MLP and CNN are slightly
    better than RNN models and have similar error levels, which are about 11.9% and
    12.0% measured by RMSE%. For the proposed DBNet, as the parallel structure combines
    the advantages of both CNN and MLP, the errors measured by MAE and RMSE are the
    lowest for all nine wave conditions among five ML-based methods. As for the average
    error, the performance of the DBNet is about 0.2% better than the sub-optimal
    MLP in MAE% and RMSE%. Most importantly, the developed DBNet is a computational-friendly
    model. It takes only 2772 s to complete the whole training procedure on a standard
    desktop with a single Intel Core i7-7700 CPU and 32, 768 MB RAM, while the prediction
    for a 25.5 s time horizon only costs 0.865 s (including the whole data processing
    and model loading procedure) which obviously meets the real-time requirement.
    As what most active control systems require is about a 20 s future time horizon
    [20], a 25.5 s prediction is enough for the control-oriented wave elevation prediction,
    indicating the huge potential of the proposed DBNet for the model predictive control
    of WECs. In Fig. 4, in order to visually identify the prediction accuracy of different
    ML-based wave prediction methods, the error distributions over the whole prediction
    time domain, i.e. 85 prediction points for 25.5 s in the real world, are investigated.
    The RMSE of the prediction results compared with the experimental values for five
    ML-based methods at different time horizons are calculated and visualized, where
    the RMSE for each time step is averaged over all the experimental wave data in
    the test set. As can be seen, the error distribution tendencies of all ML-based
    methods are quite similar for all nine wave conditions. Specifically, the errors
    are relatively low and stable for the first 12.0 s, which experience a gradual
    growth during 12.0 s to 17.4 s and then grow rapidly and finally reach the peak
    at 25.5 s where the error is about twice that of the initial stage. Such a tendency
    is related to the theoretically predictable zone, whose physically meaningful
    boundaries can be explained based on the linear theory of wave propagation. To
    be specific, in our case, the historical wave information is recorded by the upstream
    gauges (i.e. WG2, WG5, WG6, WG7 and WG8). Then, the beginning and the end of the
    theoretically predictable zone are moments when recorded wave components at the
    upstream gauges fully reach the downstream gauge (i.e. WG4) and those components
    initially leave the downstream gauge, respectively. In other words, the boundaries
    are determined respectively by the timings that the slowest wave passes the downstream
    gauge at the earliest time and the fastest wave passes the downstream gauge at
    the latest time. Thus, the increased errors in the last period beyond the predictable
    zone are reasonable and expected. More analyses about the theoretically predictable
    zone can refer to [17], [45]. For all nine wave conditions, the proposed DBNet
    holds the lead in most of the prediction time horizons, demonstrating the advantage
    of the DBNet compared with other ML-based methods. Another superiority of the
    DBNet is the better prediction performance during the first 12.0 s, which is especially
    obvious for wave conditions 1–3 (Fig. 4(a)–(c)) and wave conditions 7–9 (Fig.
    4(g)–(i)). In Fig. 5, we further illustrate the wave elevations measured in the
    experiments and the predicted results by the proposed DBNet during the 7400 s
    to 7800 s for nine wave conditions. As can be seen, the predicted results of the
    DBNet show a high agreement with the experimental data under all nine wave conditions.
    Taking wave condition 3 (Fig. 5(c)) as an example, the wave elevation experiences
    a dramatic surge at around 7700 s which increases from about −1.5 m to almost
    2.5 m directly. The proposed DBNet successfully tracks this striking change with
    quite a high accuracy. Download : Download high-res image (408KB) Download : Download
    full-size image Fig. 8. The absolute errors of three types of input with different
    upstream gauges data. (a) wave condition 1 during 7460 s to 7600 s and (b) wave
    condition 8 during 7580 s to 7720 s, where DBNet#1, DBNet#3 and DBNet#5 represent
    the input from 1, 3 and 5 upstream gauges. 3.1.2. The significance of the directional
    information The comparative studies are conducted in this section to investigate
    the significance of the directional information in predictions of 3D waves. Specifically,
    the directional information is implicit within the data measured by the pentagonal
    gauge array (WG2, WG5, WG6, WG7 and WG8). Thus, two additional studies are conducted
    based on the proposed DBNet: the input upstream wave information for the former
    is measured by WG2, WG7 and WG8, while the latter is only WG2. The quantitative
    comparison between three input scenarios can be seen in Table 5. Apparently, the
    wave data measured by three gauges contain less directional information than those
    of five gauges. Thus, the errors of the DBNet with input measured by three gauges
    increase marginally for all wave conditions. As the directional information can
    be still extracted from three upstream gauges, the average MAE% and RMSE% merely
    witness a slight increase from 9.1% to 9.6% and 11.6% to 12.3%, respectively.
    In sharp contrast, when the input becomes the data only from a single gauge, i.e.
    without any directional information, the errors obviously surge to a high level,
    which increases by more than 4.0% in MAE% and 5.0% in RMSE%. The prediction results
    of those two scenarios can be seen in Fig. 6, Fig. 7. With three upstream wave
    gauges, the DBNet demonstrates a satisfactory performance which holds a similar
    accuracy compared with the prediction with five upstream wave gauges. However,
    when only a single upstream gauge is available, the prediction errors dramatically
    rise to a very high level, especially for those scenarios with tremendous changes.
    For example, the wave emerges a violent fluctuation at about 7460 s in Fig. 7(h).
    Although the fluctuation trend is correctly captured and predicted by the model,
    the prediction accuracy is far from satisfactory which is more than 1.0 m (30%
    normalized by the significant height) measured by MAE. Two cases of absolute errors
    with three types of input are visually illustrated in Fig. 8, where black dashed
    rectangles mark the typical discrepancies between three circumstances. Clearly,
    the error level of only one gauge’s input is significantly higher than the other
    two scenarios. By comparison, the error distributions between the circumstances
    with three and five gauges’ inputs are quite similar along the time span, indicating
    that the directional information is indeed necessary for the model to extract
    and reconstruct the features of 3D waves. From the above studies and comparisons,
    we can conclude that directional information plays an important role in the phase-resolved
    forecasting of 3D waves. Table 5. The prediction errors measured by MAE (m), RMSE
    (m), MAE% and RMSE% using different upstream gauges under nine wave conditions.
    Each method is trained, validated and tested ten times and then the means are
    reported. Please notice the MAE and RMSE are transformed to the full scale. Con.
    Gauges MAE RMSE MAE% RMSE% 1 1 0.24981 0.31430 13.323 16.763 3 0.17971 0.23083
    9.585 12.311 5 0.16982 0.21704 9.057 11.576 2 1 0.34404 0.43165 13.492 16.927
    3 0.24139 0.30837 9.466 12.093 5 0.22900 0.29079 8.980 11.404 3 1 0.50390 0.63715
    12.597 15.929 3 0.37912 0.49164 9.478 12.291 5 0.35724 0.46019 8.931 11.505 4
    1 0.20476 0.25627 14.626 18.305 3 0.14460 0.18351 10.329 13.108 5 0.13731 0.17408
    9.808 12.435 5 1 0.18546 0.23155 13.997 17.476 3 0.13273 0.16899 10.017 12.754
    5 0.12606 0.15976 9.514 12.057 6 1 0.43366 0.54544 12.849 16.161 3 0.30599 0.39555
    9.066 11.720 5 0.29096 0.37358 8.621 11.069 7 1 0.59221 0.75581 12.402 15.828
    3 0.46057 0.60673 9.645 12.706 5 0.43487 0.56505 9.107 11.833 8 1 0.46168 0.58463
    13.990 17.716 3 0.31845 0.40610 9.650 12.306 5 0.30607 0.38793 9.275 11.755 9
    1 0.31477 0.39539 13.686 17.191 3 0.21823 0.27934 9.488 12.145 5 0.20760 0.26401
    9.026 11.479 Avg. 1 0.36559 0.46136 13.214 16.676 3 0.26453 0.34123 9.561 12.334
    5 0.25099 0.32138 9.072 11.616 Download : Download high-res image (222KB) Download
    : Download full-size image Fig. 9. The prediction errors measured by MAE and RMSE
    using upstream wave information for different lengths of the (a) output time horizon
    and the (b) input time horizon. 3.1.3. The length of input and output time horizon
    Intuitively, the difficulty of phase-resolved wave forecasting will be positively
    associated with the length of the output but negatively correlated with the length
    of the input. In this part, the above hypothesis is explored by quantitative tests.
    Five output time horizons, i.e. 22.5 s, 24.0 s, 25.5 s, 27.0 s and 28.5 s and
    five input time horizons, i.e. 130 s, 110 s, 90 s, 70 s and 50 s are compared
    using the proposed DBNet. The prediction errors of these settings are reported
    in Fig. 9. As can be seen, the errors indeed increase with the extended length
    of the prediction time horizon, especially for those longer than 25.5 s. For the
    input sequence, the impact of the length is not very obvious, especially for those
    longer than 90 s. 3.2. Wave forecasting using local information In this part,
    wave forecasting using local information is investigated. To be specific, the
    input of models is set as the historical local wave information measured by WG4
    itself, while the target output is the future wave elevation measured by WG4.
    3.2.1. Performance of different methods Apparently, as the input only contains
    local wave data without either directional information or upstream historical
    wave elevation, the predictable time horizon is expected to be much shorter than
    the scenario with the upstream wave data. Thus, a small prediction time horizon
    (4.5 s) is selected in this condition, while the input historical time horizon
    is still 90 s. As shown in Table 6, even though all ML-based methods have a decent
    performance, the errors of GRU and LSTM are still more considerable than others
    due to the long input sequences. Since the output is a relatively short sequence,
    the gaps between MLP, CNN and DBNet are very small, but the proposed DBNet still
    holds a slim advantage. Table 6. The prediction errors measured by MAE (m), RMSE
    (m), MAE% and RMSE% for all methods under nine wave conditions using local wave
    information. Each method is trained, validated and tested ten times and then the
    means and standard deviations are reported. Note that the MAE and RMSE are transformed
    to the full scale. Con. Methods MAE RMSE MAE% RMSE% 1 GRU 0.16417 ± 0.00049 0.22038
    ± 0.00061 8.755 ± 0.026 11.754 ± 0.033 LSTM 0.15601 ± 0.00134 0.21236 ± 0.00197
    8.320 ± 0.071 11.326 ± 0.105 MLP 0.15957 ± 0.00072 0.21562 ± 0.00111 8.510 ± 0.039
    11.500 ± 0.059 CNN 0.15755 ± 0.00282 0.21580 ± 0.00318 8.403 ± 0.150 11.510 ±
    0.170 DBNet 0.15673 ± 0.00226 0.21484 ± 0.00263 8.359 ± 0.120 11.458 ± 0.140 2
    GRU 0.21852 ± 0.00151 0.29513 ± 0.00203 8.569 ± 0.059 11.574 ± 0.080 LSTM 0.21212
    ± 0.00226 0.28839 ± 0.00279 8.319 ± 0.089 11.309 ± 0.110 MLP 0.20889 ± 0.00111
    0.28459 ± 0.00145 8.192 ± 0.043 11.160 ± 0.057 CNN 0.21098 ± 0.00380 0.28875 ±
    0.00421 8.274 ± 0.149 11.324 ± 0.165 DBNet 0.20985 ± 0.00298 0.28753 ± 0.00345
    8.230 ± 0.117 11.276 ± 0.135 3 GRU 0.36341 ± 0.00421 0.48700 ± 0.00547 9.085 ±
    0.105 12.175 ± 0.137 LSTM 0.36377 ± 0.00573 0.48608 ± 0.00674 9.094 ± 0.143 12.152
    ± 0.168 MLP 0.34212 ± 0.00181 0.46200 ± 0.00191 8.553 ± 0.045 11.550 ± 0.048 CNN
    0.33802 ± 0.00563 0.45751 ± 0.00542 8.450 ± 0.141 11.438 ± 0.135 DBNet 0.33643
    ± 0.00412 0.45566 ± 0.00429 8.411 ± 0.103 11.392 ± 0.107 4 GRU 0.12599 ± 0.00076
    0.17020 ± 0.00115 8.999 ± 0.054 12.157 ± 0.082 LSTM 0.11840 ± 0.00191 0.16333
    ± 0.00250 8.457 ± 0.136 11.666 ± 0.179 MLP 0.12761 ± 0.00092 0.17365 ± 0.00145
    9.115 ± 0.066 12.404 ± 0.104 CNN 0.12533 ± 0.00246 0.17302 ± 0.00282 8.952 ± 0.176
    12.359 ± 0.201 DBNet 0.12473 ± 0.00213 0.17237 ± 0.00251 8.909 ± 0.152 12.312
    ± 0.179 5 GRU 0.12339 ± 0.00052 0.16616 ± 0.00092 9.313 ± 0.039 12.540 ± 0.070
    LSTM 0.11541 ± 0.00210 0.15833 ± 0.00267 8.710 ± 0.158 11.950 ± 0.201 MLP 0.12472
    ± 0.00092 0.16894 ± 0.00136 9.413 ± 0.069 12.750 ± 0.103 CNN 0.12085 ± 0.00248
    0.16638 ± 0.00276 9.121 ± 0.187 12.557 ± 0.209 DBNet 0.12040 ± 0.00211 0.16587
    ± 0.00245 9.087 ± 0.159 12.518 ± 0.185 6 GRU 0.29478 ± 0.00316 0.39612 ± 0.00384
    8.734 ± 0.094 11.737 ± 0.114 LSTM 0.29204 ± 0.00338 0.39352 ± 0.00392 8.653 ±
    0.100 11.660 ± 0.116 MLP 0.28053 ± 0.00145 0.38047 ± 0.00161 8.312 ± 0.043 11.273
    ± 0.048 CNN 0.27810 ± 0.00495 0.37777 ± 0.00507 8.240 ± 0.147 11.193 ± 0.150 DBNet
    0.27683 ± 0.00374 0.37640 ± 0.00403 8.202 ± 0.111 11.153 ± 0.119 7 GRU 0.45898
    ± 0.00707 0.60425 ± 0.00891 9.612 ± 0.148 12.654 ± 0.187 LSTM 0.47510 ± 0.00952
    0.62322 ± 0.01080 9.950 ± 0.199 13.052 ± 0.226 MLP 0.43218 ± 0.00255 0.57684 ±
    0.00299 9.051 ± 0.053 12.081 ± 0.063 CNN 0.42723 ± 0.00658 0.57535 ± 0.00552 8.947
    ± 0.138 12.049 ± 0.116 DBNet 0.42557 ± 0.00442 0.57300 ± 0.00404 8.913 ± 0.093
    12.000 ± 0.085 8 GRU 0.29070 ± 0.00245 0.39550 ± 0.00357 8.809 ± 0.074 11.985
    ± 0.108 LSTM 0.28752 ± 0.00329 0.39208 ± 0.00407 8.713 ± 0.100 11.881 ± 0.123
    MLP 0.27744 ± 0.00151 0.38202 ± 0.00192 8.407 ± 0.046 11.576 ± 0.058 CNN 0.27993
    ± 0.00517 0.38556 ± 0.00579 8.483 ± 0.157 11.684 ± 0.176 DBNet 0.27899 ± 0.00348
    0.38477 ± 0.00419 8.454 ± 0.105 11.660 ± 0.127 9 GRU 0.19582 ± 0.00074 0.26490
    ± 0.00114 8.514 ± 0.032 11.517 ± 0.050 LSTM 0.18822 ± 0.00166 0.25686 ± 0.00222
    8.184 ± 0.072 11.168 ± 0.096 MLP 0.18857 ± 0.00097 0.25661 ± 0.00133 8.199 ± 0.042
    11.157 ± 0.058 CNN 0.19031 ± 0.00327 0.26062 ± 0.00365 8.274 ± 0.142 11.331 ±
    0.159 DBNet 0.18940 ± 0.00256 0.25950 ± 0.00302 8.235 ± 0.111 11.283 ± 0.131 Avg.
    GRU 0.24842 ± 0.00232 0.33329 ± 0.00307 8.979 ± 0.084 12.047 ± 0.111 LSTM 0.24540
    ± 0.00347 0.33046 ± 0.00419 8.870 ± 0.125 11.944 ± 0.151 MLP 0.23796 ± 0.00133
    0.32231 ± 0.00168 8.601 ± 0.048 11.650 ± 0.061 CNN 0.23648 ± 0.00413 0.32231 ±
    0.00427 8.547 ± 0.149 11.650 ± 0.154 DBNet 0.23544 ± 0.00309 0.32110 ± 0.00340
    8.510 ± 0.112 11.606 ± 0.123 Download : Download high-res image (1MB) Download
    : Download full-size image Fig. 10. The wave elevations measured in experiments
    (red) and the prediction results by DBNet (blue) during the 7400 s to 7800 s,
    where the inputs are the local historical wave information measured by WG4. (a)–(i)
    represent the nine wave conditions. The measured wave elevation and predicted
    results by the proposed DBNet during the 7400 s to 7800 s are shown in Fig. 10.
    As illustrated, the predictions most often match with the measured wave elevation
    (which is used as the reference value). For example, at about 7475 s in Fig. 10(a),
    the wave considerably fluctuates from around −1.3 m to 1.3 m three times, while
    the proposed DBNet nicely predicts such striking changes with very small errors.
    Meanwhile, some differences exist between peaks in the experiment results and
    DBNet predictions. The first reason is that the local wave measured by the WG4
    itself does not contain any direction information. As shown in Section 3.1.2,
    the direction information is actually essential for the phase-resolved prediction
    of 3D waves. The second factor which undermines prediction accuracy is the existence
    of inevitable measurement errors. 3.2.2. The length of output time horizon This
    part investigates wave forecasting using local information for different lengths
    of future time horizons. Specifically, taking the same length (90 s) of historical
    local wave information measured by WG4 as the input, the prediction errors for
    different output time horizons including 4.5 s, 5.1 s and 6.0 s are explored.
    As shown in Fig. 11, the errors obviously enlarge with the increase of the prediction
    time horizons. For example, when predicting future 6.0 s wave elevation, the RMSE
    increases more than 20% compared with the 4.5 s time horizon, indicating the limited
    predictable future time horizon using local wave information. Download : Download
    high-res image (101KB) Download : Download full-size image Fig. 11. The prediction
    errors measured by MAE and RMSE using local wave information for different lengths
    of the output time horizon. 3.3. Ablation study about the hyper-parameters In
    this part, the ablation study about the hyper-parameters of different machine
    learning methods used in our work is conducted. For the ablation study, the input
    is set as the 90 s historical wave information measured by the upstream gauges
    and the output is the 25.5 s future downstream wave elevation. All methods are
    trained and tested ten times and the average MAE and RMSE are reported in Fig.
    12. To investigate the effect of the number of convolutional layers, we add a
    CBR and delete a CBR in the DBNet and the CNN, respectively. As seen in Fig. 12,
    either adding a CBR (DBNet1 and CNN1) or deleting a CBR (DBNet2 and CNN2) can
    lead to a marginal decrease in accuracy. For MLP, the output sizes of the first
    two layers are set as (128, 64) to construct MLP1 and (512, 256) to build MLP2.
    However, both of those two modifications would weaken the performance. As to LSTM
    and GRU, the number and size of the hidden layer for LSTM1 and GRU1 are set as
    1 and 256, while LSTM2 and GRU2 are 2 and 128. The results demonstrate that the
    increase in the size of the hidden layer would slightly increase errors, while
    errors would obviously rise with the increase in the number of hidden layers.
    Based on this ablation study, the final hyper-parameters used in this work are
    obtained which are reported in Section 2.3. Download : Download high-res image
    (187KB) Download : Download full-size image Fig. 12. The ablation study about
    the hyper-parameters of different machine learning methods used in our work. 3.4.
    Discussion It is worth mentioning that the phase-resolved forecasting of 3D waves
    based on local wave information only requires the local wave measurement which
    is usually directly available, while the prediction based on the upstream wave
    information, as investigated in Section 3.1, requires additional upstream wave
    measurement. However, the local wave data can only meet the very short-term wave
    prediction requirement within 5 s which is far from the standard of control-oriented
    wave forecasting (at least 20 s future wave elevation [20]). By contrast, although
    the measurement process is more complicated and expensive (at least three gauges
    installed on the upstream), the upstream information can be used for control-oriented
    wave forecasting. Thus, these two kinds of formulations have their corresponding
    advantages and disadvantages. Therefore, they will target different application
    scenarios according to the specific needs. Based on the experiments conducted
    in this paper, the main findings are summarized as: (1) The ML methods can achieve
    the real-time deterministic forecasting of 3D waves (with a time horizon of more
    than 20 s) based on the historical upstream wave information measured by the gauge
    array. The forecasting time horizon is sufficient to enable preview-based control
    of WECs. (2) The study shows that the directional wave information captured by
    the upstream wave gauge array is necessary for achieving accurate wave forecasting.
    Also, the errors of phase-resolved wave forecasting are positively associated
    with the length of the output and negatively correlated with the length of the
    input. (3) The results also demonstrate that with the local historical information
    (which can be obtained more easily compared with the directional upstream information)
    as the input, the ML methods can achieve very short-term wave forecasting (i.e.
    4.5 s) accurately. 4. Conclusions To the best of our knowledge, this work investigated,
    for the first time, the phase-resolved real-time prediction of 3D waves based
    on ML and wave tank experiments. Two major barriers in phase-resolved wave prediction,
    i.e. the generalization of the model to diverse sea states and the deterministic
    prediction of 3D waves, were both resolved. Specifically, the experimental results
    demonstrated that the set of ML models developed in this paper was effective for
    different wave conditions and sea states without retraining multiple times. In
    particular, the proposed DBNet showed better performance than other ML methods.
    The preview-based hydrodynamic control is a very important and effective strategy
    to improve the power generation of WECs [7] significantly. However, as a non-causal
    optimal control problem, forecasting for future wave elevations with at least
    a 20 s time horizon is normally required for those WEC controllers [20]. Thus,
    the machine learning model proposed in this work, which can achieve the control-oriented
    phase-resolved prediction of 3D waves for multiple sea states in real-time, is
    greatly useful to enable the MPC approaches to enhance the energy conversion efficiency
    of WECs. Our future works may involve the investigation of more sea states, the
    validation of the model to full-scale wave data measured in real-world ocean sites,
    and the application of the proposed model for WEC controller optimization. CRediT
    authorship contribution statement Rui Li: Conceptualization, Data curation, Formal
    analysis, Investigation, Methodology, Project administration, Software,Validation,
    Visualization, Writing – original draft. Jincheng Zhang: Conceptualization, Data
    curation, Formal analysis, Investigation, Methodology, Project administration,
    Software, Visualization, Writing – review & editing. Xiaowei Zhao: Conceptualization,
    Formal analysis, Funding acquisition, Investigation, Methodology, Project administration,
    Resources, Supervision, Writing – review & editing. Daming Wang: Data curation,
    Investigation, Project administration, Writing – review & editing. Martyn Hann:
    Resources, Supervision, Writing – review & editing. Deborah Greaves: Funding acquisition,
    Investigation, Project administration, Resources, Supervision, Writing – review
    & editing. Declaration of Competing Interest The authors declare that they have
    no known competing financial interests or personal relationships that could have
    appeared to influence the work reported in this paper. Acknowledgments This work
    has received funding from the UK Engineering and Physical Sciences Research Council
    (grant number: EP/S000747/1). The authors acknowledge the Scientific Computing
    Research Technology Platform (SCRTP) at the University of Warwick for providing
    High-Performance Computing resources. Daming Wang’s contribution to this work
    is part-funded by the EU funded MaRINET 2 project (grant agreement ID:731084)
    and the School of Engineering, Computing and Mathematics at the University of
    Plymouth . Data availability Data will be made available on request. References
    [1] Czech B., Bauer P. Wave energy converter concepts: Design challenges and classification
    IEEE Ind Electron Mag, 6 (2) (2012), pp. 4-16 View in ScopusGoogle Scholar [2]
    Rosa-Santos P., Taveira-Pinto F., Rodríguez C.A., Ramos V., López M. The CECO
    wave energy converter: Recent developments Renew Energy, 139 (2019), pp. 368-384
    View PDFView articleView in ScopusGoogle Scholar [3] Li G., Weiss G., Mueller
    M., Townley S., Belmont M.R. Wave energy converter control by wave prediction
    and dynamic programming Renew Energy, 48 (2012), pp. 392-403 View PDFView articleView
    in ScopusGoogle Scholar [4] Zhan S., Li G. Linear optimal noncausal control of
    wave energy converters IEEE Trans Control Syst Technol, 27 (4) (2018), pp. 1526-1536
    Google Scholar [5] Zhang Y., Li G. Non-causal linear optimal control of wave energy
    converters with enhanced robustness by sliding mode control IEEE Trans Sustain
    Energy, 11 (4) (2019), pp. 2201-2209 Google Scholar [6] Zhang Y., Stansby P.,
    Li G. Non-causal linear optimal control with adaptive sliding mode observer for
    multi-body wave energy converters IEEE Trans Sustain Energy, 12 (1) (2020), pp.
    568-577 CrossRefView in ScopusGoogle Scholar [7] Liao Z., Gai N., Stansby P.,
    Li G. Linear non-causal optimal control of an attenuator type wave energy converter
    m4 IEEE Trans Sustain Energy, 11 (3) (2019), pp. 1278-1286 Google Scholar [8]
    Ling B.A., Bosma B., Brekken T.K. Experimental validation of model predictive
    control applied to the Azura wave energy converter IEEE Trans Sustain Energy,
    11 (4) (2019), pp. 2284-2293 Google Scholar [9] Ringwood J.V., Bacelli G., Fusco
    F. Energy-maximizing control of wave-energy converters: The development of control
    system technology to optimize their operation IEEE Control Syst Mag, 34 (5) (2014),
    pp. 30-55 CrossRefView in ScopusGoogle Scholar [10] Falnes J. Optimum control
    of oscillation of wave-energy converters The eleventh international offshore and
    polar engineering conference, OnePetro (2001) Google Scholar [11] Nguyen H.-N.,
    Tona P. Short-term wave force prediction for wave energy converter control Control
    Eng Pract, 75 (2018), pp. 26-37 View PDFView articleView in ScopusGoogle Scholar
    [12] Nguyen H.-N., Tona P. Wave excitation force estimation for wave energy converters
    of the point-absorber type IEEE Trans Control Syst Technol, 26 (6) (2017), pp.
    2173-2181 Google Scholar [13] Hlophe T., Wolgamot H., Taylor P.H., Kurniawan A.,
    Orszaghova J., Draper S. Wave-by-wave prediction in weakly nonlinear and narrowly
    spread seas using fixed-point surface-elevation time histories Appl Ocean Res,
    122 (2022), Article 103112 View PDFView articleView in ScopusGoogle Scholar [14]
    Tolman H.L., et al. User manual and system documentation of WAVEWATCH III TM version
    3.14 Tech Note MMAB Contrib, 276 (220) (2009) Google Scholar [15] Booij N., Ris
    R.C., Holthuijsen L.H. A third-generation wave model for coastal regions: 1. Model
    description and validation J Geophys Res: Oceans, 104 (C4) (1999), pp. 7649-7666
    View in ScopusGoogle Scholar [16] Group T.W. The WAM model—A third generation
    ocean wave prediction model J Phys Oceanogr, 18 (12) (1988), pp. 1775-1810 Google
    Scholar [17] Law Y., Santo H., Lim K., Chan E. Deterministic wave prediction for
    unidirectional sea-states in real-time using artificial neural network Ocean Eng,
    195 (2020), Article 106722 View PDFView articleView in ScopusGoogle Scholar [18]
    Duan W., Ma X., Huang L., Liu Y., Duan S. Phase-resolved wave prediction model
    for long-crest waves based on machine learning Comput Methods Appl Mech Engrg,
    372 (2020), Article 113350 View PDFView articleView in ScopusGoogle Scholar [19]
    Mohaghegh F., Murthy J., Alam M.-R. Rapid phase-resolved prediction of nonlinear
    dispersive waves using machine learning Appl Ocean Res, 117 (2021), Article 102920
    View PDFView articleView in ScopusGoogle Scholar [20] Fusco F., Ringwood J.V.
    A study of the prediction requirements in real-time control of wave energy converters
    IEEE Trans Sustain Energy, 3 (1) (2011), pp. 176-184 Google Scholar [21] Sheng
    W. Wave energy conversion and hydrodynamics modelling technologies: A review Renew
    Sustain Energy Rev, 109 (2019), pp. 482-498 View PDFView articleView in ScopusGoogle
    Scholar [22] Wijaya A.P., Naaijen P., van Groesen E., et al. Reconstruction and
    future prediction of the sea surface from radar observations Ocean Eng, 106 (2015),
    pp. 261-270 View PDFView articleView in ScopusGoogle Scholar [23] Ruban V.P. Predictability
    of the appearance of anomalous waves at sufficiently small Benjamin–Feir indices
    JETP Lett, 103 (9) (2016), pp. 568-572 CrossRefView in ScopusGoogle Scholar [24]
    Wang G., Pan Y. Phase-resolved ocean wave forecast with ensemble-based data assimilation
    J Fluid Mech, 918 (2021) Google Scholar [25] Qi Y., Wu G., Liu Y., Kim M.-H.,
    Yue D.K. Nonlinear phase-resolved reconstruction of irregular water waves J Fluid
    Mech, 838 (2018), pp. 544-572 CrossRefView in ScopusGoogle Scholar [26] Wang G.,
    Zhang J., Ma Y., Zhang Q., Li Z., Pan Y. Phase-resolved ocean wave forecast with
    simultaneous current estimation through data assimilation J Fluid Mech, 949 (2022),
    p. A31 View in ScopusGoogle Scholar [27] Simanesew A., Trulsen K., Krogstad H.E.,
    Borge J.C.N. Surface wave predictions in weakly nonlinear directional seas Appl
    Ocean Res, 65 (2017), pp. 79-89 View PDFView articleView in ScopusGoogle Scholar
    [28] Cousins W., Onorato M., Chabchoub A., Sapsis T.P. Predicting ocean rogue
    waves from point measurements: An experimental study for unidirectional waves
    Phys Rev E, 99 (3) (2019), Article 032201 View in ScopusGoogle Scholar [29] Fan
    S., Xiao N., Dong S. A novel model to predict significant wave height based on
    long short-term memory network Ocean Eng, 205 (2020), Article 107298 View PDFView
    articleView in ScopusGoogle Scholar [30] Gracia S., Olivito J., Resano J., Martin-del
    Brio B., de Alfonso M., Álvarez E. Improving accuracy on wave height estimation
    through machine learning techniques Ocean Eng, 236 (2021), Article 108699 View
    PDFView articleView in ScopusGoogle Scholar [31] Kumar N.K., Savitha R., Al Mamun
    A. Ocean wave height prediction using ensemble of extreme learning machine Neurocomputing,
    277 (2018), pp. 12-20 View PDFView articleGoogle Scholar [32] Jain P., Deo M.,
    Latha G., Rajendran V. Real time wave forecasting using wind time history and
    numerical model Ocean Model, 36 (1–2) (2011), pp. 26-39 View PDFView articleView
    in ScopusGoogle Scholar [33] Wang N., Chen Q., Zhu L., Sun H. Integration of data-driven
    and physics-based modeling of wind waves in a shallow estuary Ocean Model, 172
    (2022), Article 101978 View PDFView articleView in ScopusGoogle Scholar [34] Wu
    M., Stefanakos C., Gao Z. Multi-step-ahead forecasting of wave conditions based
    on a physics-based machine learning (PBML) model for marine operations J Mar Sci
    Eng, 8 (12) (2020), p. 992 CrossRefGoogle Scholar [35] Domala V, Lee W, Kim T-w.
    Wave data prediction with optimized machine learning and deep learning techniques.
    J Comput Des Eng 9(3). Google Scholar [36] Ma X., Huang L., Duan W., Jing Y.,
    Zheng Q. The performance and optimization of ANN-WP model under unknown sea states
    Ocean Eng, 239 (2021), Article 109858 View PDFView articleView in ScopusGoogle
    Scholar [37] Ma Y., Sclavounos P.D., Cross-Whiter J., Arora D. Wave forecast and
    its application to the optimal control of offshore floating wind turbine for load
    mitigation Renew Energy, 128 (2018), pp. 163-176 View PDFView articleView in ScopusGoogle
    Scholar [38] Zhang J., Zhao X., Jin S., Greaves D. Phase-resolved real-time ocean
    wave prediction with quantified uncertainty based on variational Bayesian machine
    learning Appl Energy, 324 (2022), Article 119711 View PDFView articleView in ScopusGoogle
    Scholar [39] Le Quang T., Dao M.H., Lu X. Prediction of near-field uni-directional
    and multi-directional random waves from far-field measurements with artificial
    neural networks Ocean Eng, 278 (2023), Article 114307 View PDFView articleView
    in ScopusGoogle Scholar [40] Marsaleix P., Michaud H., Estournel C. 3D phase-resolved
    wave modelling with a non-hydrostatic ocean circulation model Ocean Model, 136
    (2019), pp. 28-50 View PDFView articleView in ScopusGoogle Scholar [41] Pirhooshyaran
    M., Snyder L.V. Forecasting, hindcasting and feature selection of ocean waves
    via recurrent and sequence-to-sequence networks Ocean Eng, 207 (2020), Article
    107424 View PDFView articleView in ScopusGoogle Scholar [42] Gehring J., Auli
    M., Grangier D., Yarats D., Dauphin Y.N. Convolutional sequence to sequence learning
    International conference on machine learning, PMLR (2017), pp. 1243-1252 View
    in ScopusGoogle Scholar [43] Hochreiter S., Schmidhuber J. Long short-term memory
    Neural Comput, 9 (8) (1997), pp. 1735-1780 CrossRefView in ScopusGoogle Scholar
    [44] Cho K, van Merriënboer B, Bahdanau D, Bengio Y. On the Properties of Neural
    Machine Translation: Encoder–Decoder Approaches. In: Proceedings of SSST-8, eighth
    workshop on syntax, semantics and structure in statistical translation. 2014,
    p. 103–11. Google Scholar [45] Qi Y., Wu G., Liu Y., Yue D.K. Predictable zone
    for phase-resolved reconstruction and forecast of irregular waves Wave Motion,
    77 (2018), pp. 195-213 View PDFView articleView in ScopusGoogle Scholar Cited
    by (3) Development of pyramid neural networks for prediction of significant wave
    height for renewable energy farms 2024, Applied Energy Show abstract Wave force
    prediction on truncated cylinders with arbitrary symmetric cross-sections using
    machine learning 2024, Ocean Engineering Show abstract A multi-target cow face
    detection model in complex scenes 2024, Visual Computer © 2023 The Authors. Published
    by Elsevier Ltd. Recommended articles Online optimization of energy management
    strategy for FCV control parameters considering dual power source lifespan decay
    synergy Applied Energy, Volume 348, 2023, Article 121516 Dagang Lu, …, Jing Wang
    View PDF Robust planning and economic analysis of park-level integrated energy
    system considering photovoltaic/thermal equipment Applied Energy, Volume 348,
    2023, Article 121538 Chaoyi Zhang, …, Keer Ning View PDF Reward adaptive wind
    power tracking control based on deep deterministic policy gradient Applied Energy,
    Volume 348, 2023, Article 121519 Peng Chen, Dezhi Han View PDF Show 3 more articles
    Article Metrics Citations Citation Indexes: 1 Captures Readers: 15 View details
    About ScienceDirect Remote access Shopping cart Advertise Contact and support
    Terms and conditions Privacy policy Cookies are used by this site. Cookie settings
    | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V.,
    its licensors, and contributors. All rights are reserved, including those for
    text and data mining, AI training, and similar technologies. For all open access
    content, the Creative Commons licensing terms apply."'
  inline_citation: '>'
  journal: Applied Energy
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Phase-resolved real-time forecasting of three-dimensional ocean waves via
    machine learning and wave tank experiments
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Datta S.
  - Sinha D.
  citation_count: '3'
  description: 'This work aims to address two major issues in forest fire management:
    accurate real-time forecast and end-to-end secured data delivery between validated
    entities. To do so, we introduce BSEIFFS, a secured and intelligent forest fire
    prediction architecture realized through the convergence of Blockchain technology,
    mist computing, edge computing and machine learning paradigms. The proposed architecture
    renders Blockchain-backed security and Support Vector Regression based wildfire
    prediction at the edge by offloading the execution overheads to containerized
    cloud applications. Two algorithms namely Uncorrelated Data Transmission (UDT)
    algorithm and Blockchain based Audit Trail validation (BAT) algorithm are proposed
    to reduce number of repetitive packet transmissions and rendering a lightweight
    Blockchain based identity validation scheme at the edge respectively. The prediction
    model is trained using real-world meteorological data and tested on a steel manufacturing
    facility where controlled combustion and quenching processes closely resemble
    fire and rain scenarios. Apart from the Google Cloud Platform, tools such as IBM
    NodeRed, Siemens IBA PDA softwares are used to implement the BSEIFFS architecture.
    Extensive experimentation and comparative evaluation are performed with relevant
    baseline approaches. BSEIFFS achieves a prediction accuracy of 98.61%, ROC AUC
    score of 0.9668 with 0.1127 as false positive rate. The BSEIFFS SVR predictor
    with rbf kernel (MAE = 1.840, RMSE = 5.728) performs better than similar baseline
    approaches. The proposed UDT algorithm causes 82.02% reduction in packet transmissions
    through the network. BSEIFFS also achieves atleast 44.84% lesser energy consumption,
    11.91% higher throughput and 71.91% lesser roundtrip time in comparison with baseline
    approaches. BSEIFFS can massively extend the benefits of the imminent B5G/6G technologies
    to perform fine-grained and faster computations.'
  doi: 10.1016/j.future.2023.04.015
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords 1. Introduction 2. Related work 3. Proposed
    methodology 4. Performance evaluation 5. Conclusion CRediT authorship contribution
    statement Declaration of Competing Interest Acknowledgement Appendix A. Supplementary
    data Data availability References Vitae Show full outline Cited by (3) Figures
    (31) Show 25 more figures Tables (8) Table 1 Table 2 Table 3 Table 4 Table 5 Table
    6 Show all tables Extras (3) Download all MMC S1 MMC S2 MMC S3 Future Generation
    Computer Systems Volume 147, October 2023, Pages 59-76 BSEIFFS: Blockchain-secured
    edge-intelligent forest fire surveillance Author links open overlay panel Sreemana
    Datta, Ditipriya Sinha Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.future.2023.04.015
    Get rights and content Highlights • A four-layer secure and intelligent forest
    fire prediction architecture is proposed comprising of: IoT Sensory Layer (ISL);
    Mist Control Layer (MCL); Edge Coordination Layer (ECL); Secured and Intelligent
    Cloud Layer (SICL). • An Uncorrelated Data Transmission (UDT) algorithm is proposed
    to discard repetitive packets transmitted through the network and reduce the overall
    number of packets transferred. • Blockchain based Audit Trail validation (BAT)
    algorithm is proposed to provide lightweight Blockchain based identity validation
    considering the resource constrained nodes. • Real world implementation of BSEIFFS
    using real-time computation of FWI parameters. Abstract This work aims to address
    two major issues in forest fire management: accurate real-time forecast and end-to-end
    secured data delivery between validated entities. To do so, we introduce BSEIFFS,
    a secured and intelligent forest fire prediction architecture realized through
    the convergence of Blockchain technology, mist computing, edge computing and machine
    learning paradigms. The proposed architecture renders Blockchain-backed security
    and Support Vector Regression based wildfire prediction at the edge by offloading
    the execution overheads to containerized cloud applications. Two algorithms namely
    Uncorrelated Data Transmission (UDT) algorithm and Blockchain based Audit Trail
    validation (BAT) algorithm are proposed to reduce number of repetitive packet
    transmissions and rendering a lightweight Blockchain based identity validation
    scheme at the edge respectively. The prediction model is trained using real-world
    meteorological data and tested on a steel manufacturing facility where controlled
    combustion and quenching processes closely resemble fire and rain scenarios. Apart
    from the Google Cloud Platform, tools such as IBM NodeRed, Siemens IBA PDA softwares
    are used to implement the BSEIFFS architecture. Extensive experimentation and
    comparative evaluation are performed with relevant baseline approaches. BSEIFFS
    achieves a prediction accuracy of 98.61%, ROC AUC score of 0.9668 with 0.1127
    as false positive rate. The BSEIFFS SVR predictor with rbf kernel (MAE   1.840,
    RMSE   5.728) performs better than similar baseline approaches. The proposed UDT
    algorithm causes 82.02% reduction in packet transmissions through the network.
    BSEIFFS also achieves atleast 44.84% lesser energy consumption, 11.91% higher
    throughput and 71.91% lesser roundtrip time in comparison with baseline approaches.
    BSEIFFS can massively extend the benefits of the imminent B5G/6G technologies
    to perform fine-grained and faster computations. Previous article in issue Next
    article in issue Keywords Wildfire predictionBlockchainSecured data transferEdge
    intelligenceEnergy efficiency 1. Introduction One of the most important aspects
    of forest fire management is timely detection. Delay in identifying the location
    of outbreak may cause severe and widespread damage. There is evidence of power
    law behaviour [1] suggesting that more than 90% of forest area is burnt due to
    1% of the forest fires [2]. If a forest fire outbreak can be predicted beforehand
    with sufficiently acceptable accuracy, there is high chance that a major outbreak
    may be avoided. Moreover, it is important to convey the data from the sensor network
    to the decision-controller in a secured manner to obtain an accurate forecast.
    1.1. The need for secured and intelligent system for forest fire prediction The
    use of Blockchain technology has proliferated to diverse application domains such
    as privacy-preserving in Internet of Things (IoT) based smart city [3], medical
    data Transmission [4], [5], IoT healthcare [6] and electronic health records [7].
    Moreover, Blockchain technology is being increasingly used for rendering a secured
    architecture alongside the intelligent prediction mechanisms by using artificial
    intelligence [4], artificial neural networks (ANNs) [8] and convolution neural
    networks (CNNs) [7]. Blockchain technology have also been successfully integrated
    within Industrial IoT (IIoT) architectures running on the cloud [7] and also to
    edge-intelligent network architectures [5]. This motivated us to research on the
    potential of Blockchain-coupled artificially intelligent forest fire prediction
    architecture leading to our proposition, the Blockchain-secured edge-intelligent
    forest fire surveillance (BSEIFFS) architecture. State-of-the-art research on
    forest fire prediction domain entails developing the models based on pre-recorded
    data from data-sets, both in the form of images [9], [10], [11], [12] and/or parametric
    readings [13], [14], [15], [16]. These architectures establish their accuracy
    based on algorithms applied on stored data and are highly architecture specific.
    Another important consideration during tackling of forest fires through SFFS systems
    [13], [14], [15], [16] is the privacy and security of data. The existing SFFS
    systems [13], [14], [15], [16] fails to provide strong identity management leading
    to security threats such as sybil attacks [17], [18]. It is seen that although
    the fire outbreak is correctly sensed, due to lack of security during data transportation,
    the control arrives at false-negative conclusions [18]. Hence, in order to enable
    fast and accurate response, intelligent prediction with acceptable accuracy levels
    along with secured end-to-end data transfer is one of the supremely important
    considerations for forest fire management. 1.2. Blockchain-secured edge-intelligent
    surveillance : The proposed solution In this work, we propose a four-layered,
    secured, loosely coupled, multi-agent architecture leveraging the benefits of
    blockchain technology, edge-intelligence, Mist-intelligence and Micro-services
    architecture, for which we coin the term BSEIFFS : Blockchain-secured edge-intelligent
    forest fire surveillance system. The introduced concept along with the multi-technology
    conglomeration renders architecting BSEIFFS, for intelligent forest fire prediction
    based on real-time meteorological parameters. The BSEIFFS architecture is capable
    of calculating the Fire Weather Index (FWI) parameters (FFMC, DMC, DC, ISI as
    detailed in Cortez et al.’s work [19]) in real-time (Section 3.2.3, Eqs. (3),
    (4), (5), (6), (7), (8), (9), (10), (11), (12), (13), (14), (15), (16), (17),
    (18), (19), (20), (21), (22), (23), (24), (25), (26), (27), (28), (29), (30),
    (31), (32), (33)) thereby arriving at an intelligent decision to classify and
    predict fire/no-fire scenarios. At each layer of the proposed architecture, multiple
    agents can be deployed to offer further fault tolerance and eliminate single-point-of-failure.
    The architecture is seamlessly scalable as it decouples the performance from the
    computational capabilities of the individual nodes. It turns machine-learning
    backed intelligence and blockchain-backed securities as utility services deployed
    through discrete micro-services at the Secured and Intelligent Cloud Layer (SICL).
    We demonstrate the efficacy of the proposed architecture by developing and deploying
    an experimental prototype in a real-world steel manufacturing plant where controlled
    combustion activities are undertaken regularly. We also evaluate the performance
    of the BSEIFFS architecture in terms of prediction accuracy, prediction error,
    energy consumption, throughput and roundtrip time. 1.3. Motivation Even in 2021,
    numerous countries across the globe witnessed devastating forest fires. We have
    come across harrowing stories related to the human misery, damage to life and
    property due to prolonged and intense forest fires. According to the Copernicus
    Atmosphere Monitoring Service (CAMS) scientists [20], in 2021, globally, forest
    fires led to an estimated total of 1760 megatonnes of carbon emissions, equivalent
    of 6450 megatonnes of CO2. This volume is 148% more than total European Union’s
    fossil fuel emissions in 2020. An elaborate study done on the relevant contemporary
    forest fire prediction researches (Section 2) reveal the need for devising a practically
    deployable prediction architecture and also cognize the secured data delivery
    issue to prevent intrusion-led suppression of genuine alerts or triggering of
    false alerts. This, in turn, would decimate the sole purpose of intelligent surveillance.
    Decentralized trust offered by blockchain technology makes it the technology of
    choice for designing [17], [18] an IoT-integrated secured and intelligent architecture.
    1.4. Contribution Concerning the achievement of a secured, intelligent forest
    fire prediction architecture suitable for application in resource-constrained
    use-cases, we propose the BSEIFFS architecture to inter-operate between the intelligent
    forest fire prediction and secured data transfer from source to decision. Our
    specific contributions are as follows: 1. A four-layer secure and intelligent
    forest fire prediction architecture comprising of: • IoT Sensory Layer (ISL).
    • Mist Control Layer (MCL). • Edge Coordination Layer (ECL). • Secured and Intelligent
    Cloud Layer (SICL). 2. At the MCL, an Uncorrelated Data Transmission (UDT) algorithm
    (Section 3.1.1, algorithm 1) is proposed to discard repetitive packets transmitted
    through the network and reduce the overall number of packets transferred. 3. At
    the SICL, Blockchain based Audit Trail validation (BAT) algorithm (Section 3.3.1,
    algorithm 2) is proposed to provide lightweight Blockchain based identity validation
    considering the resource constrained nodes at the ISL and MCL. 4. The work incorporates
    the proposed BSEIFFS framework into a real-world experimental testbed where the
    intelligence engine has been trained to real-world meteorological data (detailed
    in Section 3.4.1) through real-time computation of FWI parameters(detailed in
    Section 3.2.3). As it is difficult to emulate a full-scale forest fire scenario
    for efficacy evaluation, the experimental prototype has been implemented in a
    real-world steel manufacturing facility where controlled combustion and water
    quenching activities are undertaken regularly. It closely resembles the fire outbreak
    and extinguishment respectively. The remaining part of this paper is organized
    as follows; Section 2 presents the research regarding related works in the forest
    fire prediction domain. Section 3 details the BSEIFFS architecture specifications
    including the hardware implementation, designing of the Prediction Engine (PE).
    Section 4 presents the performance evaluation of the proposed architecture along
    with the result analysis of the experimental setup. Section 5 concludes the article
    with discussion on the findings and future directions of the research. Acknowledgement
    section mentions and acknowledges the support received from external agencies
    in order to carry out and complete this research work. 2. Related work Moving
    on from traditional post-ignition forest fire surveillance mechanisms, the state-of-the-art
    proposes several interesting systems and efforts to predict forest fire outbreaks
    before actual spark-off. Notable works in the domain such as the one by Elshewey
    et al. proposes a methodology involving Linear Regression, Ridge Regression, Lasso
    Regression on the UCI machine learning repository forest fires dataset [19]. This
    work reported Linear Regression to be most accurate (upto 99%) in predicting burnt
    area on the dataset with a 70%–30% train–test split [21]. Wood proposed a data-mining
    based Transparent Open Box (TOB) algorithm as a breakaway from correlation and
    regression-based approaches. The work also performs a feature selection sensitivity
    analysis to identify drought code (DC) and relative humidity (RH) as the most
    influential parameters, of the thirteen variables considered, on TOB’s total burned
    area predictions. The work reported upto 84% accuracy upto hectares burnt area
    prediction [22]. Yang et al. introduced a logistic-regression based conceptual
    model based on remote sensing data. This approach, built on the Fire Information
    for Resource Management System (FIRMS) Hotspot data, provided by NASA utilizes
    a 5-layer neural network to obtain the predicted confidence of a fire hotspot
    in a particular area within the dataset. The work devised a simulation prototype
    named ‘Agni’ and reported upto 81% accuracy with custom loss functions [23]. Mohajane
    et al. proposed five new hybrid machine learning algorithms namely, Frequency
    Ratio-Multilayer Perceptron (FR-MLP), Frequency Ratio-Logistic Regression (FRLR),
    Frequency Ratio-Classification and Regression Tree (FR-CART), Frequency Ratio-Support
    Vector Machine (FR-SVM), and Frequency Ratio-Random Forest (FR-RF), for mapping
    forest fire susceptibility in the north of Morocco. The work, developed on image
    datasets obtained from FIRMS (NASA) and MODIS [24] employ five aforesaid techniques
    and perform a comparative analysis of them. It reports Random Forest to be the
    most accurate on the basis of area under Receiver Operating Characteristics curve
    (AUC=0.989) followed by Support Vector Machine (AUC=0.959) on the concerned datasets
    [25]. Kumar et al. proposed an image processing and machine learning based wildfire
    prediction mechanism. The authors used the faster R-CNN object detection model
    and SVM for classifying the candidate region to either real fire or non-fire.
    The work reported a detection rate of 92% and false-alarm rate of 8% for images
    containing fire or flame [26]. Mohammed proposes a deep-learning based real-time
    forest fire and smoke detection system. The author suggested a transfer learning
    framework to extract features of forest fire and smoke using a pre-trained Inception-ResNet-v2
    network on the ImageNet dataset consisting of 1102 images for each fire and smoke
    classes. The author reported an accuracy 99.09% for the images on the dataset
    containing fire or smoke [27]. Li et al. proposed a Geographically Weighted Logistic
    Regression Model (GWLR) for evaluation of forest fire in Yunnan province of China.
    Data for this study was sourced from Yunnan province’s decadal (2010–2020) satellite
    monitoring forest fire data, Land use, vegetation data, daily meteorological data,
    and Yunnan Digital Elevation Model (DEM) terrain data. The study reports an accuracy
    of 80.1% for a 60%–40% train–test split of the dataset inclusive of 5 rounds of
    sampling [28]. Rosadi et al. introduces an hybrid approach between clustering
    based on Self Organizing Map (SOM) approach and classification using Boosting
    (AdaBoost) approach for predicting forest fires using the UCI machine learning
    repository forest fires dataset [19]. The work reportedly outperforms fuzzy c-means
    clustering and presents the proposed approach as a potent method for forest fire
    prediction [29]. Nuryanto et al. introduces models to establish early warning
    system for seasonal forest fires. This study discusses the relationship between
    climatology and forest fires on a deterministic approach. Although it cannot pinpoint
    the location of fire outbreak, it reported an accuracy of 83% in predicting seasonal
    forest fires in Sumatra and Borneo (Kalimantan) islands of Indonesia [30]. Sun
    et al. presents an adaptive forest fire spread simulation algorithm based on cellular
    automata. The proposed model can adapt and adjust the time step of cellular automata
    through indices such as speed change rate. The work simulates a forest fire spread
    in line with the real world fire propagation models. The work reports a simulation
    accuracy of 96.9% based on data from forest fires occurring in Mianning County,
    Liangshan Prefecture, Sichuan Province of China in 2020 [31]. Download : Download
    high-res image (318KB) Download : Download full-size image Fig. 1. Basic overview
    of the four-layer BSEIFFS architecture. 2.1. Synthesis It is interesting to note
    that the several works undertaken in the recent times aiming to forecast forest
    fires which have reported very high degree of prediction accuracy (for their respective
    datasets). Although, many of these approaches have been observed to have several
    shortcomings en route to their implementation in the real world for intelligent
    forest fire prediction. It may be noted that multiple approaches have been built
    on the popular UCI machine learning repository forest fires dataset [19] alone.
    This dataset has only 517 entries and 13 parameters. The dataset is extremely
    skewed as 247 tuples out of 517 contains 0 in the ’area burnt’ column : the basis
    of the regression and classification tasks of the majority of the works reviewed
    [21], [22], [29]. Most of the works primarily focus on developing a theoretical
    model or performing simulation and establishing accuracy on its basis. Several
    considerations need to be encompassed to be able to translate these theoretical
    models into practically implementable solutions. Moreover, costs associated vis-à-vis
    QoS metrics post the deployment of these solutions in the real world require further
    research. Further there are issues with feasibility, comparative analysis on a
    common minimum criteria and replication ability, which need to be resolved through
    deeper reasoning and research before these propositions can be deployed for efficient
    forest fire forecasting in the real world [21], [22], [23], [26], [27], [29],
    [30], [31]. Another interesting observation is that none of these works lay emphasis
    on the security of data being transmitted through their respective architectures.
    Although, it is primarily motivating for designing an intrusion-free forest fire
    prediction framework deployable in the real world. Even, data security issues
    have been reported to be threatening to forest fire surveillance architectures
    [17], [18], [32], [33]. Hence ensuring security and privacy of data becomes important
    considerations for solution architects. Also, recent researches have demonstrated
    the coordination capabilities of Blockchain and Edge computing paradigms. [34]
    proposes a collaborative framework bringing together the benefits of Edge computing
    and Blockchain technology to provide a secure, yet lightweight scheme for monitoring
    patients at the edge. The work ensures early detection, faster response and easy
    scalability through the proposed architecture. The work also proposes a queuing
    based priority assignment method to optimize transactions received from different
    sources. The proposed framework fulfils the QoS requirements of health entities
    and also provides a robust, secure and efficient architecture for undertaking
    large scale medical data exchange. This motivates us to render a forest fire prediction
    architecture leveraging the benefits of both Edge computing and Blockchain technology.
    Summarily, there is a pressing need in the forest fire forecasting research space
    for an alternate computing paradigm which is considerate towards data privacy
    and security. 3. Proposed methodology In this section, we discuss in detail about
    the proposed methodology of BSEIFFS. Section 3 is organized as shown in Fig. 2.
    Download : Download high-res image (299KB) Download : Download full-size image
    Fig. 2. Organization of Section 3 (Proposed methodology). 3.1. BSEIFFS architecture
    specifications As shown in Fig. 1, the proposed BSEIFFS architecture comprises
    of four-layers as follows: 1. IoT Sensory Layer (ISL) : It is the lowest layer
    in the architecture. It comprises of composite sensor nodes deployed at the forest
    area for sensing primary meteorological parameters such as temperature, humidity
    and wind speed. It also has a GPS sensor for capturing location of the deployed
    nodes. It communicates with the Mist Control Layer (MCL) through hard wired interface.
    2. Mist Control Layer (MCL) : Placed just above the ISL on the hierarchy, the
    MCL comprises of low cost micro-controlling agents. It receives data from the
    ISL and performs primary computations and initial decision making. Responsibilities
    entrusted on the MCL include: • Computing the FWI parameters such as FFMC, DMC,
    DC and ISI : Data received from the ISL consists of Sender node ID, location and
    primary sensed data such as temperature, humidity and wind speed. The MCL nodes
    compute the additional FWI parameters such as FFMC, DMC, DC, ISI from the primary
    sensed data received from ISL. • It executes the proposed UDT algorithm (Section
    3.1.1, algorithm 1) to decide on sending or not sending the data packet to the
    next layer for the current cycle. • If directed by the UDT algorithm (Section
    3.1.1, algorithm 1), the MCL nodes transfer data from the forest area to the control
    station using LoRaWAN for further processing. The MCL sits at the extreme edge
    of the network performing preliminary computations on the primary data. This keeps
    the Edge Coordination Layer (ECL) free from the recurrent computational workloads.
    It enhances the performance of the overall network due to job delegation and load
    sharing. 3.1.1. Uncorrelated Data Transmission (UDT) algorithm In this section,
    we detail about the proposed Uncorrelated Data Transfer (UDT) algorithm executing
    in the MCL. During our experimentation with BSEIFFS and also study of related
    works in the edge-intelligence domain, it is observed that an important concern
    regarding implementation of edge-intelligent architectures in the real world is
    the high volume of data needed to be transported through such networks. The problem
    becomes more serious in cases where edge-intelligence is to be rendered on resource-constrained
    networks, such as ours. Through this work, we propose to tackle the issue with
    two approaches. First, the use of discretized cloud-based micro-services and second,
    reducing the number of data transmissions by using the UDT algorithm. The UDT
    algorithm works on a simple premise that most of the data captured by the sensors,
    cycle after cycle, is repeated. Out of which, only the data which shows abnormal
    increment/decrement causing threshold breach, is of particular interest to the
    decision controller. The UDT algorithm is detailed as Algorithm 1. Download :
    Download high-res image (313KB) Download : Download full-size image 3. Edge Coordination
    Layer (ECL) : Placed just above the MCL, the ECL comprises of intelligent coordinating
    controllers. ECL nodes perform the following tasks in each cycle: • ECL nodes
    receive data from MCL nodes over LoRaWAN. • They validate the sender node identity
    by invoking the proposed Blockchain based Audit Trail validation (BAT) algorithm
    (Section 3.3.1, algorithm 2) through the Security Micro-service (SMS). If the
    BAT validation is unsuccessful, a potential security threat alert is generated
    and the respective sender node is flagged as malicious. • If the validation is
    successful, they invoke the Intelligence Micro-service (IMS) to obtain the prediction.
    • If a prediction score of is obtained, a fire alert is generated for the fire
    station. Although intelligent decision-making is rendered at the Edge, the ECL
    remains free from the cyclic computational load. In the BSEIFFS architecture,
    this is achieved through independent task-specific micro-services deployed in
    the cloud. These containerized applications work independently, extracting scalability
    benefits of cloud computing to maintain the performance requirements while catering
    to varying workloads. In the proposed architecture, the intelligent edge is not
    burdened with the computational aspects of executing machine learning algorithms;
    rather, it is employed to undertake fast decision-making and coordinate between
    the job requirements and the specific micro-services catering to them. 4. Secured
    and Intelligent Cloud Layer (SICL) : The topmost layer in the BSEIFFS hierarchy
    lies the SICL. The SICL communicates with the ECL on-demand from ECL. The SICL
    houses two major components, • The Security Engine (SE) : Hosting the Security
    Micro-service (SMS). The SMS executes the proposed Blockchain based Audit Trail
    validation (BAT) algorithm detailed as section Section 3.3.1, algorithm 2. It
    provides decentralized identity validation whenever any data transfer request
    is initiated to the ECL. This micro-service ensures that only valid nodes participate
    in the data transfer and the network remains secured from adversaries without
    depending on any semi-trusted third-party. • The Prediction Engine (PE) : Hosting
    the Intelligence Micro-service (IMS). As detailed in Section 3.4, the IMS houses
    a pre-trained model based on real-life data-set sourced from the India Meteorology
    Department (IMD) (Section 3.4.1). Table 1 summarizes details of the aforementioned
    real-life data-set. On demand from the ECL, this pre-trained model is utilized
    to render predictions in real-time. The same is then communicated with the ECL
    which takes decision accordingly to interpret the result as fire alert or normal
    case scenario. These engines are hosted in separate containerized virtual instances
    with specific ingress and egress communication rules. This ensure task isolation
    and parallel execution whenever required. It renders computational elasticity
    to the BSEIFFS architecture to support peak workloads. These situations usually
    occur just before an actual ignition or if there is some adversary trying to deliberately
    mislead the control for false positive alert generation. In either case, the scenario
    is tackled by the PE and SE respectively. Table 1. Details of dataset sourced
    from IMD. Source of Data India Meteorological Department (IMD) observatory at
    Ranchi, Jharkhand, India Start date of recording data 01.01.2016 End date of recording
    data 31.12.2020 Number of attributes 12 Number of records 1828 Attributes Year,
    Month, Date, Maximum temperature, Minimum temperature, Maximum humidity, Minimum
    humidity, Wind direction (@0830 IST), Wind speed (@0830 IST), Wind direction (@1730
    IST), Wind speed (@1730 IST), Daily rainfall Download : Download high-res image
    (1005KB) Download : Download full-size image Fig. 3. Control flow of the BSEIFFS
    architecture. 3.2. BSEIFFS control flow In the BSEIFFS architecture, the control
    flow is segregated into two phases, the Initiation Phase and the Steady-State
    Phase. Fig. 3 illustrates the control flow in the proposed BSEIFFS architecture.
    3.2.1. Initiation phase The Initiation Phase occurs only once in the life-cycle,
    at the time of setting up the network. Activities undertaken in this phase are:
    • All the sensors in the ISL are calibrated pre-deployment. • The antenna power
    is adjusted for MCL and ECL nodes to obtain optimum coverage for the LoRaWan network.
    • The Blockchain network is created. For providing unique identifiers to all the
    nodes in ISL, MCL and ECL we extend the concept of Identity Sets [17]. At the
    initiation stage, the Identity Set for each of the node in the Blockchain network
    is created. Each block in the Blockchain contains the Identity Set data for all
    valid nodes. This data is later utilized in the proposed BAT algorithm (Section
    3.3.1, algorithm 2) for providing identity validation (see Fig. 4, Fig. 5). Download
    : Download high-res image (67KB) Download : Download full-size image Fig. 4. Identity
    Set [17] generated for each node during Initiation Phase. Download : Download
    high-res image (207KB) Download : Download full-size image Fig. 5. Computation
    of derived FWI parameters from data sensed by ISL nodes. 3.2.2. Steady state phase
    Once the Initiation Phase is over, the Steady-State Phase begins and executes
    in a cyclic fashion. For each round, the layer-wise responsibilities in the Steady-State
    Phase are as follows: • IoT Sensory Layer (ISL) – Capture primary data : Temperature,
    Humidity, Wind-Speed and Location (Longitude, Latitude) from the forest area.
    – Convey the captured data to the corresponding MCL controller. • Mist Control
    Layer (MCL) – Compute FWI parameters : FFMC, DMC, DC, ISI from the data received
    from ISL and form the message tuple ¡ ¿. – Execute the proposed Uncorrelated Data
    Transmission (UDT) Algorithm (Section 3.1.1, algorithm 1) and obtain the value
    of newDataBit as 0 or 1. – If the value of newDataBit is 1, then send the Identity
    Set to the ECL and raise a new data request. – If the new data request is approved
    by the ECL, then send the message tuple to the ECL over LoRaWan for further processing,
    else terminate cycle. 3.2.3. Calculation of Fire Weather Index (FWI) parameters
    • Apart from the primary sensed parameters (Temperature, Humidity, Wind Speed,
    Rain), the MCL computes four more Fire Weather Index (FWI) parameters to render
    prediction based on the Realtime Augmented Dataset. Variable names and daylength
    adjustment factors used in Eqs. (3), (4), (5), (6), (7), (8), (9), (10), (11),
    (12), (13), (14), (15), (16), (17), (18), (19), (20), (21), (22), (23), (24),
    (25), (26), (27), (28), (29), (30), (31), (32), (33) are same as the Canadian
    FWI indices [35]. Interpretations of the additional FWI parameters computed and
    their respective formulae are detailed as follows: – Fine Fuel Moisture Code (FFMC):
    The Fine Fuel Moisture Code (FFMC) is a numeric score given to the moisture content
    of the forest floor litter and other cured fine fuels. This value indicates the
    relative ease of ignition and the flammability of fine fuel [36], [37], [38].
    It is computed using the following equations: (3) (4) (5) (6) (7) (8) (9) (10)
    (11) (12) (13) (14) (15) – Duff Moisture Code (DMC): The Duff Moisture Code (DMC)
    is a score given to the mean moisture content of loosely bound organic biomass
    layers at a moderate depth. This score indicates the fuel consumption rate in
    moderate duff layers and medium-sized wood-like material. It is computed using
    the following equations [36], [37], [38]: (16) (17) (18) (19) (20) (21) (22) (23)
    (24) – Drought Code (DC): The Drought Code (DC) is a score of the mean moisture
    content of deep and compact organic biomass layers in the forest floor. This score
    indicates the impact of seasonal droughts on forest fuels and the amount of slow
    burning in the deep duff layers and large woody logs. It is computed using the
    following equations [36], [37], [38]: (25) (26) (27) (28) (29) (30) – Initial
    Spread Index (ISI): The Initial Spread Index (ISI) is a score of the anticipated
    rate of fire spread. It depends on wind speed and the FFMC. Unlike other FWI parameters,
    it is independent of fuel type. Actual rate of spread differs with fuel types
    at the same ISI value. It is computed using the following equations [36], [37],
    [38]: (31) (32) (33) • Edge Coordination Layer (ECL) – Whenever there is a new
    data request from the MCL, invoke the Security Micro-service (SMS) from the Security
    Engine (SE) in the SICL. – If the identity validation is successful, approve the
    new data request and intimate the MCL. – In identity validated scenarios, receive
    the message tuple from the MCL and invoke the Intelligence Micro-service (IMS)
    from the Prediction Engine (PE) and obtain the forecast value. Also, send the
    message tuple to the SICL for updation in the Augmented Dataset (ADS) along with
    the forecast value. – If the forecast value is , generate a fire alert. Else,
    begin next cycle of operations. • Secured and Intelligent Cloud Layer (SICL) –
    Whenever there is a validation request raised by the ECL, execute the proposed
    Blockchain based Audit Trail validation (BAT) algorithm (Section 3.3.1, algorithm
    2). If the identity validation is successful, request the ECL for the message
    tuple for further processing. If the validation fails, inform the ECL and raise
    a Security Alert. – In identity validated scenarios, obtain the message tuple
    from the ECL and invoke the Prediction Engine (PE) to execute the Intelligence
    Micro-service (IMS) (The Prediction Engine is further detailed in Section 3.4).
    Transfer the forecast value to the ECL for further decision-making. – The SICL
    also maintains an Realtime Augmented Dataset (RADS) consisting of the Initial
    Dataset and identity-validated message tuples appended to it in real-time by the
    ECL (Details of the RADS is given in Section 3.6). 3.3. Design of the Security
    Engine (SE) At the core of the BSEIFFS Security Engine (SE), lies the proposed
    Blockchain based Audit Trail Validation (BAT) algorithm (Algorithm 2) performing
    decentralized identity validation of MCL nodes intending to transfer data to the
    ECL. The BAT algorithm makes use of Merkle trees [39] to validate identity sets
    of the intending nodes. As shown in Fig. 6, Merkle trees are essentially hash-trees
    whose leaves represent hashes of the data chunks (Node Identity Sets in our case)
    and the parent nodes represents the concatenated hashes of the leaf-level hashes.
    Download : Download high-res image (86KB) Download : Download full-size image
    Fig. 6. Basic structure of a generic Merkle tree. Let us refer to Fig. 7 to conceptually
    understand how the proposed audit_trail based validation works. If the verifier
    wants to verify that “C” chunk is present in the data file as well as the file
    is untampered, the verifier requests a list of all highest level hashes which
    do not contain “C”. In this case, the verifier receives Hash(D) and Hash(AB).
    This information is called audit_trail. The verifier then computes Hash(CD) from
    Hash(C) and the Hash(D) it has received. The verifier also computes Hash(ABCD)
    from Hash(CD) just computed and the Hash(AB) received earlier. Download : Download
    high-res image (92KB) Download : Download full-size image Fig. 7. Example of Audit
    Trail based Merkle tree validation. Now, this computed Hash(ABCD) can be used
    to search for the file in the Blockchain network. If the hashes match, the validation
    is successful and the proof validates that the chunk is present in the tree and
    is not tampered/corrupted. If the validation fails, the verifier flags the node
    as malicious and requests for the same chunk from any other node in the Blockchain
    network. This method is called audit proofing. If the audit proofing fails and
    no node in the network can verify the data, it is ascertained that the data file
    has been tampered too and is discarded. Thus, the concept of audit trail and audit
    proofing helps to validate both data and identity. 3.3.1. Blockchain based Audit
    Trail validation (BAT) algorithm The proposed BAT algorithm is detailed as follows:
    Download : Download high-res image (272KB) Download : Download full-size image
    3.4. Design of the Prediction Engine (PE) In this section, we detail the design
    of the BSEIFFS Prediction Engine (PE). The PE, running as a micro-service in the
    SICL performs Support vector regression based on correlative comparison of the
    message tuple data received from the ECL with the Realtime Augmented Dataset maintained
    in the cloud datastore. We elaborate the BSEIFFS prediction methodology and alert
    generation mechanism as follows: 3.4.1. Sourcing and pre-processing dataset Several
    related works (detailed in Section 2) approaching the forest fire prediction problem
    utilized the popular UCI machine learning repository forest fires dataset [19]
    (referred to as UCI dataset hereafter). Although the data-set is complete, yet
    it has a record of only 517 recorded forest fires at Montesinho National Park,
    in north-east Portugal. In order to build a more accurate model, we decided to
    apply the prediction algorithms on a larger dataset. Hence, we sourced data from
    India Meteorological Department consisting of meteorological data from 01.01.2016
    to 31.12.2020, around the observatory located at Ranchi, Jharkhand. The sourced
    dataset (referred to as IMD dataset hereafter) consists of location, date of recording
    observations, Temperature, Humidity and Rain columns in 1828 observations. 3.4.2.
    Preparation of Experimental Dataset (ED) To prepare the IMD dataset for comparative
    analysis against the existent approaches, we pre-processed the dataset following
    the same methodology detailed the parent work using the UCI dataset [19]. We utilized
    UCI dataset as the training dataset and the IMD dataset for testing and populating
    the ‘area’ output. Obviously the values are skewed, in both datasets, with most
    of the ‘area’ values being zero, the ‘area’ column is first transformed using
    an function. After fitting the models, the outputs are post-processed with and
    inverse transform. The experiments are conducted using a 10-fold (cross-validation)
    30 runs. This leads to the development of the Experimental Dataset (ED). The BSEIFFS
    Experimental Dataset (ED) has been made available at https://github.com/sreemanadatta/bseiffs/blob/main/forestfires_IMD.csv.
    3.4.3. Pre-processing data from Experimental Dataset (ED) The following steps
    are undertaken on the ED as a part of pre-processing: • Step 1:At first, the ‘day’
    column is pruned. As it is unlikely to have any effect on the fire outbreak. •
    Step 2:The dataset is splitted two parts, Training dataset (70%) and Testing dataset(30%).
    • Step 3:Numeric feature variables of the dataset are standardized using a standard
    scaler. • Step 4:Important features are identified using Principal Component Analysis
    [40] and Logistic Regression based Linear Discriminant Analysis [41]. Both these
    techniques indicate similar outcomes. Temperature, Relative humidity, Rain, Wind,
    DC, DMC, FFMC, ISI, Y-coordinate, and X-coordinate are found to be most important
    features respectively. In order to eliminate any positional bias, we further prune
    Y-coordinate and X-coordinate. Thus, Temperature, Relative humidity, Rain, Wind,
    DC, DMC, FFMC, ISI are selected as most important features for further processing.
    Fig. 8 illustrates the important features identified against their importance
    indices calculated using Random Forest classifier. • Step 5: A correlation matrix
    was also plotted for the pre-processed data. This shows the correlation between
    various meteorological parameters with one another. This helped us understand
    the behaviour of a parameter based on the variation in others. Fig. 9 illustrates
    the correlation matrix. The correlation matrix shows that the parameters FFMC,
    DMC, DC, ISI and Temperature show relatively higher correlation. Download : Download
    high-res image (118KB) Download : Download full-size image Fig. 8. Important features
    identified using PCA and LDA. Download : Download high-res image (272KB) Download
    : Download full-size image Fig. 9. Correlation matrix between the important features.
    3.4.4. Choice of prediction model It was initially envisaged to model the fire
    affected area via multivariate regression. But, the exploratory data analysis
    and the correlation matrix clearly shows that the correlation of ‘area’ with other
    FWI parameters is very less. Moreover, predicting burnt area only based on the
    dataset parameters can train a model into finding a pattern which might not be
    generalizable to other datasets. To verify our hypothesis quantitatively, we approached
    the problem as a regression task. Hence, we require to select an algorithm, which
    can most accurately predict the burnt area with minimum tolerance for error. We
    implement the following techniques on the experimental dataset : Support Vector
    Machine, Decision Tree, Random Forest, Deep Neural Network. In each case, we determined
    the best parameters for a particular regressor using Grid Search to tune the optimum
    values of the hyperparameters. In order to have a comparative analysis, we plot
    the Regression error characteristics (REC) curve as follows: Regression Error
    Characteristic (REC) curves illustrate the absolute deviation tolerance versus
    the fraction of the exemplars predicted correctly within the tolerance interval.
    The resulting curve estimates the cumulative distribution function of the error
    [42]. The maximum tolerance for error was kept at 20 (hectares). It was observed
    that SVM with rbf kernel performs the best among the four models. Within individual
    models too, we iterated through different variants to find the best variant using
    grid search method. The REC plot (Fig. 10) shows the comparison between highest
    accuracy achieved for each model variant placed against one another. SVM with
    rbf kernel is observed to have minimum error for lesser prediction values (area)
    which is of our specific interest; to predict even minor outbreaks so as to eliminate
    any false negative alerts. Download : Download high-res image (195KB) Download
    : Download full-size image Fig. 10. REC Curve for comparative analysis between
    models. 3.4.5. Reformulation of the problem statement In the exploratory data
    analysis step, it was observed that the forest fires usually take place in absence
    of rain. This motivated us to approach the problem as a classification problem
    rather than a regression problem. Decision boundary of the conditions that lead
    to forest fire may be found by this classification problem. As a large number
    of burnt area values in the dataset are 0.0, hence this classification task becomes
    feasible to be engineered into a new feature. Thus, the problem is re-formulated
    as a classification task and the following classes are finalized for the Support
    Vector Classifier: • Class 1 : area 0 • Class 2 : • Class 3 : • Class 4 : • Class
    5 : Classes 3, 4 are identified as moderately alarming. Class 5 is identified
    as highly alarming with immediate alert generation for the fire station. 3.4.6.
    Support vector machine based forest fire prediction model Support vector machine
    (SVM) is a popular technique used for non-linear regression and pattern classification.
    This general machine learning algorithm works on the principle of structural risk
    minimization. It tries to use a classifying hyperplane as a decision surface so
    that the isolated edges between the positive and negative examples get maximized
    [43]. For our specific use-case, a Radial Basis Function (rbf) kernel with ’c
    value’ 1.0 and degree : 3 gave best results at 72.05% accuracy on the IMD dataset.
    The same model provided 55.97% accuracy on the UCI dataset. Fig. 11, Fig. 12 represents
    the model accuracy for both UCI dataset as well as IMD dataset. This trained model
    was serialized using pickle and stored in the Intelligence Micro-service (IMS)
    running within the security engine. In order to generate real-time predictions
    based on live data, the IMS makes use of the saved model and keeps on appending
    the prediction values on the ‘area’ column in the Augmented Dataset (ADS) maintained
    in the SICL for all validated data. Now based on this prediction value, an alert
    for the fire station is triggered if the predicted value is more than 50 (few
    cases of class 4 and entire class 5). Details of the physical implementation of
    the BSEIFFS architecture through hardware setup and software simulations is discussed
    the subsequent sections. Download : Download high-res image (165KB) Download :
    Download full-size image Fig. 11. Model accuracy on UCI dataset. Download : Download
    high-res image (152KB) Download : Download full-size image Fig. 12. Model accuracy
    on IMD dataset. 3.5. The BSEIFFS experimental prototype Table 2. BSEIFFS architecture
    hardware specifications. Layer Module Details ISL Temperature sensor DHT22 sensor
    Humidity sensor Wind speed sensor Anemometer (0–5 V) sensor Rain sensor Raindrops
    detection module Location Sensor Neo 6M GPS module MCL Mist Controller Heltec
    Wifi LoRa 32 V2 (865 MHz) ECL Edge Communication Controller Heltec Wifi LoRa 32
    V2 (865 MHz) Edge Coordination Controller Raspberry Pi 4 Model B (8 GB RAM) running
    IBM Node-Red MQTT Broker HiveMQ SICL Cloud Prediction Engine Google Cloud VM Instance
    running BSEIFFS Prediction Engine Cloud Security Engine Google Cloud VM Instance
    running BSEIFFS Blockchain Engine Download : Download high-res image (285KB) Download
    : Download full-size image Fig. 13. Hardware design of the BSEIFFS prototype.
    Download : Download high-res image (685KB) Download : Download full-size image
    Fig. 14. Hardware implementation of the BSEIFFS prototype. 3.5.1. Hardware setup
    To evaluate the efficacy of the proposed BSEIFFS architecture in the real world,
    we developed a working model (prototype) of the same. As it is very difficult
    to emulate wildfire scenarios to test the model, we chose an use-case which closely
    follows the traits of forest fire ignition and extinguishment, especially with
    respect to measurable ambient meteorological parameters. We deploy our model in
    a continuous annealing furnace of an integrated steel plant. In the annealing
    furnace, heat treatment is given to the steel to achieve desired physical and
    chemical properties. As a process requirement, fuel gas is directly burnt with
    burners to heat the steel. This process closely resembles an wildfire outbreak.
    Shortly after the burners are fired, an water quenching is performed to cool the
    strip in order to adhere to the annealing cycle. This process resembles a rainfall
    in BSEIFFS parlance. This controlled firing of burners and quenching in water
    are carried out in frequent intervals which motivated us to test our proposed
    model at the facility. We considered the duration of burner firing as the duration
    of wildfire spread and used the well established Rothermel’s fire spread model
    [44] to calculate the area of fire spread and hence damage. Similarly, the duration
    of water quenching at each cycle is considered for calculating the rainfall factor
    for our model. Data obtained from each cycle was used to build the Realtime Augmented
    Dataset (RADS). The details of the hardware design of the BSEIFFS prototype is
    shown in Fig. 13, Fig. 14, Fig. 15, Fig. 16. Specifications of the BSEIFFS hardware
    architecture is given in Table 2, [55] Download : Download high-res image (263KB)
    Download : Download full-size image Fig. 15. Types of Fire and No-fire scenarios
    encountered by the BSEIFFS prototype at the Steel Manufacturing Facility. Download
    : Download high-res image (282KB) Download : Download full-size image Fig. 16.
    Types of Fire and No-fire scenarios encountered by the BSEIFFS prototype at the
    Steel Manufacturing Facility. 3.5.2. Software engine The BSEIFFS software engine
    is divided into two modules; BSEIFFS Prediction Engine and BSEIFFS Security Engine.
    Each of these modules are hosted as micro-services within the Google cloud. We
    utilized GCP VM instances to host the IMS and SMS. The source code of the simulator
    is available at https://github.com/sreemanadatta/bseiffs. The SICL communicates
    with the ECL through a MQTT based communicator developed in IBM Node-Red available
    at http://34.135.70.83:1880/flow/ad0647da2e648308. Specifications of the BSEIFFS
    software is detailed in Table 3. In Fig. 17, we illustrate the implementation
    of the BSEIFFS Edge Coordination Layer (ECL) in IBM Node-Red (logic for the same
    is detailed in Fig. 3). Backend execution of the SICL SMS module is illustrated
    in Fig. 18. It shows the details of the mined transactions from identity validated
    nodes in the Identity Set Blockchain. Backend execution of the proposed BAT algorithm
    (Section 3.3.1, algorithm 2) in the SICL is illustrated in Fig. 19. Here, a tampered
    audit trail is observed to fail in the validator. This logic is implemented in
    a Python function node in Node red named as BAT Validator (Fig. 17). Both the
    IMS and SMS render their services on-demand to the ECL (as shown in Fig. 17).
    Table 3 summarizes the technologies used to realize the BSEIFFS software. Download
    : Download high-res image (506KB) Download : Download full-size image Fig. 17.
    Control flow at the BSEIFFS Edge Coordination Layer (ECL). Table 3. BSEIFFS architecture
    software specifications. Module (Layer) Host Platform Backend Frontend ISL and
    MCL functionalities Heltec LoRa 32 Wifi V2 Arduino C++ Onboard OLED Display ECL
    functionalities Raspberry Pi 4 Model B IBM Node-Red Node.js Node-Red Editor IMS
    GCP VM instance with 12 GB RAM, 128 GB SSD GCP app engine Python 3.8.8 Streamlit
    SMS GCP VM instance with 12 GB RAM, 128 GB SSD GCP app engine Python 3.8.8 Flask
    Download : Download high-res image (702KB) Download : Download full-size image
    Fig. 18. Backend of the BSEIFFS Security Micro-service (SMS). Download : Download
    high-res image (629KB) Download : Download full-size image Fig. 19. Backend of
    the proposed BAT Algorithm execution. 3.6. Real-time Augmented Dataset (RADS)
    : Genesis and justification In this work, the popular UCI dataset [19] is considered
    as the baseline dataset. Then the IMD dataset is used to train and obtain a more
    accurate prediction engine based on support vector regression (detailed in sub-Section
    3.4). The baseline approach (Cortez [19]) provides 55.97% accuracy on the UCI
    dataset. The real-world IMD dataset with same 13 features and 1828 data samples
    provides 72.05% accuracy using a similar support vector regression approach. But
    our use-case of predicting even small fire outbreaks in near-real-time service
    provisioning requires a far more accurate model. Only then, it can be applied
    in real-world scenarios. To address this issue, the problem statement is re-formulated
    from a regression task trying to predict the area of burnt forest land, to a classification
    task trying to predict whether or not a fire outbreak will occur. Thus, for all
    outbreak predictions with score , we label the result as positive fire outbreak
    prediction. Whereas, all predictions with score are labelled as negative fire
    outbreak prediction. As detailed in sub-Section 3.5.1, the BSEIFFS architecture
    is deployed in a real-world steel manufacturing facility and the data obtained
    constitutes the Realtime Augmented Dataset (RADS). The RADS consists of 13 features
    and 10000 sample count consisting of timeStamp, FFMC, DMC, DC, ISI, temperature,
    relative humidity, wind speed, rain, calculated burnt Area, predicted burnt area,
    Actual fire outbreak label (1/0), Predicted fire outbreak label (1/0). Data was
    collected from the annealing furnace every five minutes using the BSEIFFS experimental
    prototype model from 28.12.2021 to 01.02.2022. Predictions for each fire/no-fire
    cases were cross-validated using the camera based fire detection prototype developed
    in Datta et al.’s work [18]. Thus the RADS, available at https://github.com/sreemanadatta/bseiffs/blob/main/RADS.csv,
    offers itself as an organically sourced, cross validated dataset capable of supporting
    regression as well as classification tasks for forest fire prediction. The development
    of this dataset is an important contribution of this work. Download : Download
    high-res image (157KB) Download : Download full-size image Fig. 20. Model accuracy
    on RADS Dataset. Download : Download high-res image (82KB) Download : Download
    full-size image Fig. 21. BSEIFFS confusion matrix for Realtime Augmented Dataset.
    Table 4. Dataset wise model accuracy comparison. Dataset Features Samples Model
    Accuracy UCI Dataset 13 517 55.97% IMD Dataset 13 1828 72.05% RADS 13 10000 82.84%
    4. Performance evaluation In this section we define the performance metrics used
    to evaluate the efficiency of the proposed BSEIFFS system against numerous relevant
    baseline approaches. The metrics considered and the corresponding comparative
    analyses are as follows: 1. Metrics related to forest fire prediction • Model
    Accuracy: The SVM model detailed in sub-Section 3.4.6 was tested on the RADS with
    identical rbf kernel. Table 4 summarizes the model accuracy achieved for UCI,
    IMD datasets and the RADS. Figs. 11, 12, 20 illustrate the model accuracy obtained
    for the UCI, IMD datasets and the RADS respectively. • Confusion Matrix: Confusion
    matrix represents true positive (tp), true negative (tn), false positive (fp)
    and false negative (fn) predictions. Prediction counts are tabulated in a matrix
    form where the -axis represents true classes and the -axis represents the predicted
    classes. Fig. 21 shows the BSEIFFS confusion matrix for the RADS. Low values of
    false predictions (fp 1% and fn 0.24%) testifies the applicability of the BSEIFFS
    architecture in real-world scenarios. • ROC Curve and ROC AUC Score The area under
    the ROC curve or ROC AUC Score is equivalent to calculating the rank correlation
    between predictions and targets. Essentially, it is the measure of the ability
    of a classifier to distinguish between classes (fire and no-fire in our case).
    Fig. 22 represents the ROC curve for BSEIFFS architecture. • Precision, Recall,
    Prediction accuracy and F1 Score Table 5 tabulates the derived metrics’ formulae
    and values based on the confusion matrix for BSEIFFS. It testifies the high accuracy
    and applicability of the architecture in real-world use-cases. In order to evaluate
    the efficacy of the proposed BSEIFFS Support Vector Regression based forest fire
    prediction model, we consider the following metrics: Mean Absolute Error (MAE),
    Mean Square Error (MSE), Root Mean Square Error (RMSE), Goodness of Fit ( ). Table
    6 depicts definition, formulae and values of MAE, MSE, RMSE and for the BSEIFFS
    prediction architecture. The RMSE and MAE values were compared with three other
    existent baseline approaches on SVM based forest fire prediction. The results
    of the comparative analysis is tabulated in Table 7. To comparatively evaluate
    the performance of the proposed BSEIFFS forest fire prediction model, it was compared
    with four other existing baseline approaches discussed by Pham et al. [45] based
    on the ROC AUC scores. The Receiver Operating Characteristic (ROC) curve visualizes
    the tradeoff between true positive rate (tpr) and false positive rate (fpr). A
    classifier with high tpr value and low fpr value is considered better [46]. In
    general, the Area Under the Curve (AUC) of a ROC curve measures the ability of
    a classifier/model to distinguish between classes. It is interpreted as the summary
    of the ROC curve. It is understood that higher the AUC, the better the performance
    of the model at distinguishing between the positive and negative classes [47].
    The results tabulated in Table 8 testify the superior performance of the proposed
    BSEIFFS approach. 2. Packets per second vs Time : With and Without UDT algorithm:
    One of the important contributions of this work is the design and implementation
    of the Uncorrelated Data Transmission algorithm (Section 3.1.1, algorithm 1).
    It effectively reduces the number of packets being transmitted through the network
    by eliminating (not transferring) those packets which carry sufficiently similar
    information. To analyse and evaluate the benefits accrued by implementing the
    algorithm in our real-world implementation, we used the Wireshark network monitoring
    tool to analyse the number of packets being transmitted per unit time through
    the network. Fig. 23 represents the same architecture being operated with and
    without implementing the UDT algorithm for 650 s (3900 cycles). Without the UDT
    algorithm, the approximate number of packets transmitted per second remains approximately
    constant throughout the execution. When the UDT algorithm is implemented, the
    number of new packets transmitted per unit time is much lesser owing to packets
    with repeated information going un-transmitted. Temporal spikes of enhanced rates
    of packet transmission justify transmission of those packets which carry significantly
    new information. As shown in Fig. 23, the UDT algorithm (Section 3.1.1, algorithm
    1) accounts for 82.02% reduction in number of packets being transmitted through
    the network. 3. Energy Consumption : An important consideration in forest fire
    prediction system design is that of energy optimization. Forest area networks
    operate in resource-constrained scenarios and hence rendering edge intelligence
    at the cost of energy inefficiency would effectively diminish the benefits of
    a predictive control mechanism. In Fig. 25, we compare the proposed BSEIFFS architecture
    against Kang et al.’s [51] Hybrid X-MAC protocol based forest fire prediction
    system. In order to calculate the energy consumption at each edge device in BSEIFFS,
    we use the Eversame USB digital power meter. Fig. 24 illustrates the energy measurement
    setup for the BSEIFFS prototype on the RADS generated from the realtime environment.
    The BSEIFFS architecture achieves 44.84% and 45.56% lesser energy consumption
    compared to baseline approaches X-MAC and ADX-MAC respectively. The enhanced energy
    efficiency is attributable to the decoupling of control and prediction engines,
    reducing number of packets transmitted using UDT algorithm (Section 3.1.1, algorithm
    1) and rendering prediction-as-a-service from the IMS and Blockchain-based validation-as-a-service
    from the SMS respectively. 4. Throughput : In our implementation of the BSEIFFS
    experimental prototype, we used the Wireshark network monitoring tool to compute
    the throughput of our network against varying number of nodes. We compared the
    results with Kang et al.’s [51] forest fire prediction architecture. The BSEIFFS
    architecture achieves 24.89% and 11.91% higher throughput compared to baseline
    approaches X-MAC and ADX-MAC respectively. Due to intelligent load sharing and
    implementation of an additional Mist Control Layer (MCL), a sizeable amount of
    computation is rendered at the Mist and Edge layers. This reduces the burden on
    the network and enhances throughput as observed in Fig. 26. In Fig. 27, we evaluate
    the throughput of BSEIFFS in presence of malicious nodes by comparing it with
    Ahmed et al.’s work [52] as the baseline. In this case, it is observed that BSEIFFS
    consistently achieves higher throughput due to the blockchain backed security
    enabled through the proposed BAT algorithm (Algorithm 2). It leads to detection
    of malicious nodes before data transmission thereby avoiding packets the attacker
    intends to transmit. 5. Roundtrip Time : In our use-case, Roundtrip time is the
    sum of time taken for the sensor data to reach the SICL for decision making and
    the corresponding response to reach the ECL for further processing. In our implementation
    of the BSEIFFS experimental prototype, we used the Wireshark network monitoring
    tool to compute the Roundtrip time for the network against varying number of nodes.
    We compared the results with Itkin et al.’s [53] architecture. The BSEIFFS architecture
    achieves 71.91% lesser turnaround time compared to the baseline approach (Fig.
    28). This improvement is attributable to the proposed UDT algorithm (Section 3.1.1,
    algorithm 1), discretizing edge intelligence from its computational overheads
    and Blockchain backed security from its resource intensity. All these effectively
    reduce the number of unnecessary packets being transmitted through the network.
    It also frees up the resources to enhance scalability and robustness of the network.
    In Fig. 29, the BSEIFFS roundtrip time is compared with Krishnan et al.’s work
    [54] in presence of malicious nodes. Here also, the Blockchain backed security
    rendered through the proposed BAT algorithm (Algorithm 2) enables quick detection
    of potential attackers. Thus, the roundtrip time remains lesser than the baseline
    as there is no dependency on a semi-trusted third-party of deciding on whether
    an entity intending to transmit a packet is an attacker or not. Table 5. Derived
    Metrics from Confusion Matrix for BSEIFFS. Metric Formula Value Precision 0.8421
    Recall 0.9448 Prediction Accuracy 0.9861 F1 Score 0.8905 True Positive Rate 0.9448
    False Positive Rate 0.1127 ROC AUC Score Area under ROC Curve 0.9668 Download
    : Download high-res image (83KB) Download : Download full-size image Fig. 22.
    ROC curve for BSEIFFS Prediction Engine on RADS. Table 6. Performance metrics
    for SVR based BSEIFFS predictor. Metric Definition Formula Value MAE Sum of absolute
    differences between actual and predicted values 1.840 MSE Average squared difference
    between the estimated values and the actual value 32.810 RMSE Standard deviation
    of error (residual error) 5.728 measures the strength of the relationship between
    the prediction model and the dependent variable. 0.973 Table 7. Comparison of
    RMSE and MAE with existing SVM based baseline approaches. Approach Reference RMSE
    MAE SVM with rbf kernel Proposed BSEIFFS architecture 5.728 1.840 SVM with polynomial
    kernel Kerdprasop et al. [48] 7.65 6.48 SVM Cortez et al. [19] 64.70 12.71 SVM
    Al Janabi et al. [49] 54.00 282.40 Parallel SVM Singh et.al. [50] 63.45 453 Table
    8. Comparison of ROC AUC Score with existing baseline approaches discussed by
    Pham et al. [45]. Approach ROC AUC Score Proposed BSEIFFS SVR with rbf kernel
    0.967 Bayes Network [45] 0.96 Decision Tree [45] 0.94 Naïve Bayes [45] 0.939 Multivariate
    Logistic Regression [45] 0.937 Download : Download high-res image (228KB) Download
    : Download full-size image Fig. 23. Number of packets per second vs Time : With
    and Without UDT Algorithm. Download : Download high-res image (225KB) Download
    : Download full-size image Fig. 24. Energy measurement setup for BSEIFFS Prototype.
    Download : Download high-res image (192KB) Download : Download full-size image
    Fig. 25. Comparison of Energy consumption vs Number of Nodes with Kang et al.
    [51]. Download : Download high-res image (173KB) Download : Download full-size
    image Fig. 26. Comparison of Throughput vs Number of Nodes with Kang et al. [51].
    Download : Download high-res image (125KB) Download : Download full-size image
    Fig. 27. Comparison of Throughput vs Number of Malicious Nodes with Ahmed et al.
    [52]. Download : Download high-res image (263KB) Download : Download full-size
    image Fig. 28. Comparison of Roundtrip time vs Number of nodes with Itkin et al.
    [53]. Download : Download high-res image (154KB) Download : Download full-size
    image Fig. 29. Comparison of Roundtrip time vs Number of malicious nodes with
    Krishnan et al. [54]. 5. Conclusion This work proposes BSEIFFS, that provisions
    Blockchain-backed security and real-time forest fire prediction as utility services
    from a secured and intelligent cloud backbone. The secured intelligence is rendered
    at the edge through an utility based computing model. The QoS-aware and resource-constrained
    edge devices are not burdened with the intricate implementations of machine learning
    models and performing Blockchain based identity validation. In future, forest
    fire mitigation mechanisms will depend heavily on intelligent pre-ignition prediction
    capabilities. Timely detection no longer remains the solo constraint. Accurate
    prediction before actual spark-off, secured and timely communication of an anticipated
    outbreak to the stakeholders extend the problem statement to incite deeper research
    in the domain. The results obtained reinstate the applicability of the proposed
    architecture to real-world use-cases. It is also encouraging to learn that QoS
    metrics of accuracy, energy efficiency is maintained although the architecture
    executes in a lean life cycle. In future, the proliferation of B5G/6G technologies
    would open up the pathways to much fine grained analysis at much lower latency
    requirements. CRediT authorship contribution statement Sreemana Datta: Conceptualization,
    Methodology, Software, Data curation, Writing – original draft, Visualization,
    Investigation. Ditipriya Sinha: Supervision, Validation, Writing – review & editing.
    Declaration of Competing Interest The authors declare that they have no known
    competing financial interests or personal relationships that could have appeared
    to influence the work reported in this paper. Acknowledgement The authors express
    their gratitude to Steel Authority of India Limited, Bokaro Steel Plant, for providing
    the necessary infrastructure and resources which helped in carrying out this research.
    The authors would also like to thank India Meteorological Department, Ranchi centre
    for providing invaluable data used in this work. Appendix A. Supplementary data
    Download all supplementary files included with this article What’s this? The following
    is the Supplementary material related to this article. Download : Download Comma
    Separated Value file (98KB) MMC S1. Download : Download Comma Separated Value
    file (749KB) MMC S2. Download : Download Comma Separated Value file (25KB) MMC
    S3. Data availability Datasets attached as supplementary material to the revised
    submission. References [1] Reed W.J., McKelvey K.S. Power-law behaviour and parametric
    models for the size-distribution of forest fires Ecol. Model., 150 (3) (2002),
    pp. 239-254 View PDFView articleView in ScopusGoogle Scholar [2] Song W., Zhang
    H., Chen T., Fan W. Power-law distribution of city fires Fire Saf. J., 38 (5)
    (2003), pp. 453-465 View PDFView articleView in ScopusGoogle Scholar [3] Gheisari
    M., Najafabadi H.E., Alzubi J.A., Gao J., Wang G., Abbasi A.A., Castiglione A.
    OBPP: An ontology-based framework for privacy-preserving in IoT-based smart city
    Future Gener. Comput. Syst., 123 (2021), pp. 1-13 View PDFView articleView in
    ScopusGoogle Scholar [4] Alzubi O.A., Alzubi J.A., Shankar K., Gupta D. Blockchain
    and artificial intelligence enabled privacy-preserving medical data transmission
    in Internet of Things Trans. Emerg. Telecommun. Technol., 32 (12) (2021), Article
    e4360 View in ScopusGoogle Scholar [5] Abdellatif A.A., Samara L., Mohamed A.,
    Erbad A., Chiasserini C.F., Guizani M., O’Connor M.D., Laughton J. Medge-chain:
    Leveraging edge computing and blockchain for efficient medical data exchange IEEE
    Internet Things J., 8 (21) (2021), pp. 15762-15775 View in ScopusGoogle Scholar
    [6] Alzubi J.A. Blockchain-based lamport Merkle digital signature: authentication
    tool in IoT healthcare Comput. Commun., 170 (2021), pp. 200-208 View PDFView articleView
    in ScopusGoogle Scholar [7] Alzubi J.A., Alzubi O.A., Singh A., Ramachandran M.
    Cloud-IIoT-based electronic health record privacy-preserving by CNN and blockchain-enabled
    federated learning IEEE Trans. Ind. Inform., 19 (1) (2022), pp. 1080-1087 Google
    Scholar [8] Movassagh A.A., Alzubi J.A., Gheisari M., Rahimi M., Mohan S., Abbasi
    A.A., Nabipour N. Artificial neural networks training algorithm integrating invasive
    weed optimization with differential evolutionary model J. Ambient Intell. Humaniz.
    Comput. (2021), pp. 1-9 Google Scholar [9] Wu D., Zhang C., Ji L., Ran R., Wu
    H., Xu Y. Forest fire recognition based on feature extraction from multi-view
    images Traitement Du Signal, 38 (3) (2021) Google Scholar [10] Babu KV S., Roy
    A., Prasad P.R. Forest fire risk modeling in uttarakhand himalaya using TERRA
    satellite datasets Eur. J. Remote Sens., 49 (1) (2016), pp. 381-395 CrossRefGoogle
    Scholar [11] Sunar F., Özkan C. Forest fire analysis with remote sensing data
    Int. J. Remote Sens., 22 (12) (2001), pp. 2265-2277 View in ScopusGoogle Scholar
    [12] Chen Y., Zhang Y., Xin J., Wang G., Mu L., Yi Y., Liu H., Liu D. UAV image-based
    forest fire detection approach using convolutional neural network 2019 14th IEEE
    Conference on Industrial Electronics and Applications, ICIEA, IEEE (2019), pp.
    2118-2123 CrossRefView in ScopusGoogle Scholar [13] M. Rainha, P. Fernandes, D.
    Viegas, Using the Canadian Fire Weather Index (FWI) in the Natural Park of Montesinho,
    NE Portugal: calibration and application to fire management, in: Proceedings of
    the IV International Conference on Forest Fire Research. Luso, Portugal, 2002.
    Google Scholar [14] Storer J., Green R. PSO trained neural networks for predicting
    forest fire size: A comparison of implementation and performance 2016 International
    Joint Conference on Neural Networks, IJCNN, IEEE (2016), pp. 676-683 View in ScopusGoogle
    Scholar [15] Xie Y., Peng M. Forest fire forecasting using ensemble learning approaches
    Neural Comput. Appl., 31 (9) (2019), pp. 4541-4550 CrossRefView in ScopusGoogle
    Scholar [16] Al-Kahlout M.M., Ghaly A.M.A., Mudawah D.Z., Abu-Naser S.S. Neural
    network approach to predict forest fires using meteorological data Int. J. Acad.
    Eng. Res. (IJAER), 4 (9) (2020) Google Scholar [17] Datta S., Kumar S., Sinha
    D., Das A.K. BSSFFS: blockchain-based sybil-secured smart forest fire surveillance
    J. Ambient Intell. Humaniz. Comput. (2021), pp. 1-32 Google Scholar [18] Datta
    S., Sinha D. BESDDFFS: Blockchain and EdgeDrone based secured data delivery for
    forest fire surveillance Peer-to-Peer Netw. Appl., 14 (6) (2021), pp. 3688-3717
    CrossRefView in ScopusGoogle Scholar [19] Cortez P., Morais A.d.J.R. A data mining
    approach to predict forest fires using meteorological data (2007) Google Scholar
    [20] Zhongming Z., Linong L., Wangqiang Z., Wei L., et al. Devastating wildfires
    cause record emissions in Northern hemisphere (2021) Google Scholar [21] Elshewey
    A.M., Elsonbaty A.A. Forest fires detection using machine learning techniques
    (2020), pp. 510-517 View in ScopusGoogle Scholar [22] Wood D.A. Prediction and
    data mining of burned areas of forest fires: Optimized data matching and mining
    algorithm provides valuable insight Artif. Intell. Agric., 5 (2021), pp. 24-42
    View PDFView articleView in ScopusGoogle Scholar [23] Yang S., Lupascu M., Meel
    K.S. Predicting forest fire using remote sensing data and machine learning (2021)
    arXiv preprint arXiv:2101.01975 Google Scholar [24] Justice C., Giglio L., Korontzi
    S., Owens J., Morisette J., Roy D., Descloitres J., Alleaume S., Petitcolin F.,
    Kaufman Y. The MODIS fire products Remote Sens. Environ., 83 (1–2) (2002), pp.
    244-262 View PDFView articleView in ScopusGoogle Scholar [25] Mohajane M., Costache
    R., Karimi F., Pham Q.B., Essahlaoui A., Nguyen H., Laneve G., Oudija F. Application
    of remote sensing and machine learning algorithms for forest fire mapping in a
    Mediterranean area Ecol. Indic., 129 (2021), Article 107869 View PDFView articleView
    in ScopusGoogle Scholar [26] Mohana Kumar S., Sowmya B., Priyanka S., Ruchita
    Sharma S.T., et al. Forest fire prediction using image processing and machine
    learning NVEO-Nat. Volatiles Essential Oils J. — NVEO (2021), pp. 13116-13134
    View in ScopusGoogle Scholar [27] K. Mohammed R. A real-time forest fire and smoke
    detection system using deep learning Int. J. Nonlinear Anal. Appl., 13 (1) (2022),
    pp. 2053-2063 Google Scholar [28] Li W., Xu Q., Yi J., Liu J. Prediction and evaluation
    of forest fire in Yunnan of China based on geographically weighted logistic regression
    model (2021) Google Scholar [29] Rosadi D., Andriyani W., Arisanty D., Agustina
    D. Prediction of forest fire using hybrid SOM-AdaBoost method Journal of Physics:
    Conference Series, Vol. 2123, IOP Publishing (2021), Article 012030 CrossRefView
    in ScopusGoogle Scholar [30] Nuryanto D., Pradana R., Putra I., Heriyanto E.,
    Linarka U., Satyaningsih R., Hidayanto N., Sopaheluwakan A., Permana D. Developing
    models to establish seasonal forest fire early warning system IOP Conference Series:
    Earth and Environmental Science, Vol. 909, IOP Publishing (2021), Article 012005
    CrossRefView in ScopusGoogle Scholar [31] Sun L., Xu C., He Y., Zhao Y., Xu Y.,
    Rui X., Xu H. Adaptive forest fire spread simulation algorithm based on cellular
    automata Forests, 12 (11) (2021), p. 1431 CrossRefView in ScopusGoogle Scholar
    [32] S. Suganthi, D. Usha, Energy Efficient Game Theory Based Attacks Detection
    for Disaster Management in IoT Networks. Google Scholar [33] Resco de Dios V.,
    Nolan R.H. Some challenges for forest fire risk predictions in the 21st Century
    Forests, 12 (4) (2021), p. 469 CrossRefView in ScopusGoogle Scholar [34] Abdellatif
    A.A., Samara L., Mohamed A., Erbad A., Chiasserini C.F., Guizani M., O’Connor
    M.D., Laughton J. Medge-chain: Leveraging edge computing and blockchain for efficient
    medical data exchange IEEE Internet Things J., 8 (21) (2021), pp. 15762-15775
    View in ScopusGoogle Scholar [35] Van Wagner C., Pickett T. Equations and FORTRAN
    Program for the Canadian Forest Fire Weather Index System (1985) Google Scholar
    [36] W.J. De Groot, et al., Interpreting the Canadian forest fire weather index
    (FWI) system, in: Proc. of the Fourth Central Region Fire Weather Committee Scientific
    and Technical Seminar, 1998. Google Scholar [37] Van Wagner C., et al. Structure
    of the Canadian Forest Fire Weather Index Environment Canada, Forestry Service
    Ontario (1974) Google Scholar [38] Carvalho A., Flannigan M.D., Logan K., Miranda
    A.I., Borrego C. Fire activity in Portugal and its relationship to weather and
    the Canadian fire weather index system Int. J. Wildland Fire, 17 (3) (2008), pp.
    328-338 View in ScopusGoogle Scholar [39] Merkle R.C. A digital signature based
    on a conventional encryption function Conference on the Theory and Application
    of Cryptographic Techniques, Springer (1987), pp. 369-378 Google Scholar [40]
    Wold S., Esbensen K., Geladi P. Principal component analysis Chemometr. Intell.
    Lab. Syst., 2 (1–3) (1987), pp. 37-52 View PDFView articleView in ScopusGoogle
    Scholar [41] Izenman A.J. Linear discriminant analysis Modern Multivariate Statistical
    Techniques, Springer (2013), pp. 237-280 CrossRefGoogle Scholar [42] J. Bi, K.P.
    Bennett, Regression error characteristic curves, in: Proceedings of the 20th International
    Conference on Machine Learning (ICML-03), 2003, pp. 43–50. Google Scholar [43]
    Li Y., Feng Z., Chen S., Zhao Z., Wang F. Application of the artificial neural
    network and support vector machines in forest fire prediction in the Guangxi Autonomous
    Region, China Discrete Dyn. Nat. Soc., 2020 (2020) Google Scholar [44] Rothermel
    R.C. A Mathematical Model for Predicting Fire Spread in Wildland Fuels Intermountain
    Forest & Range Experiment Station, Forest Service, US … (1972) Google Scholar
    [45] Pham B.T., Jaafari A., Avand M., Al-Ansari N., Dinh Du T., Yen H.P.H., Phong
    T.V., Nguyen D.H., Le H.V., Mafi-Gholami D., et al. Performance evaluation of
    machine learning methods for forest fire modeling and prediction Symmetry, 12
    (6) (2020), p. 1022 CrossRefView in ScopusGoogle Scholar [46] Fawcett T. ROC graphs:
    Notes and practical considerations for researchers Mach. Learn., 31 (1) (2004),
    pp. 1-38 CrossRefGoogle Scholar [47] Huang J., Ling C.X. Using AUC and accuracy
    in evaluating learning algorithms IEEE Trans. Knowl. Data Eng., 17 (3) (2005),
    pp. 299-310 View in ScopusGoogle Scholar [48] Kerdprasop N., Poomka P., Chuaybamroong
    P., Kerdprasop K. Forest Fire Area estimation using support vector machine as
    an approximator IJCCI (2018), pp. 269-273 CrossRefView in ScopusGoogle Scholar
    [49] Al_Janabi S., Al_Shourbaji I., Salman M.A. Assessing the suitability of soft
    computing approaches for forest fires prediction Appl. Comput. Inform., 14 (2)
    (2018), pp. 214-224 View PDFView articleCrossRefView in ScopusGoogle Scholar [50]
    Singh K.R., Neethu K., Madhurekaa K., Harita A., Mohan P. Parallel SVM model for
    forest fire prediction Soft Comput. Lett., 3 (2021), Article 100014 View PDFView
    articleView in ScopusGoogle Scholar [51] Kang J.-G., Lim D.-W., Jung J.-W. Energy-efficient
    forest fire prediction model based on two-stage adaptive duty-cycled hybrid x-mac
    protocol Sensors, 18 (9) (2018), p. 2960 View in ScopusGoogle Scholar [52] Ahmed
    M.R., Ahmed M. Impact of malicious nodes on throughput, packets dropped and average
    latency in MANETs IOSR J. Comput. Eng., 17 (6) (2015), pp. 55-63, 10.9790/0661-176155631
    View in ScopusGoogle Scholar [53] Itkin M., Kim M., Park Y. Development of cloud-based
    UAV monitoring and management system Sensors, 16 (11) (2016), p. 1913 CrossRefView
    in ScopusGoogle Scholar [54] Krishnan R.S., Julie E.G., Robinson Y.H., Kumar R.,
    Son L.H., Tuan T.A., Long H.V. Modified zone based intrusion detection system
    for security enhancement in mobile ad hoc networks Wirel. Netw., 26 (2) (2020),
    pp. 1275-1289 CrossRefView in ScopusGoogle Scholar [55] K. Pearson, Correlation
    coefficient, in: Royal Society Proceedings, Vol. 58, 1895, p. 214. Google Scholar
    Cited by (3) Blockchain-based auditing of legal decisions supported by explainable
    AI and generative AI tools 2024, Engineering Applications of Artificial Intelligence
    Show abstract Potential of blockchain technology in wood supply chains 2024, Computers
    and Electronics in Agriculture Show abstract A Systematic Literature Review of
    Blockchain Technology: Applications Fields, Platforms, and Consensus Protocols
    2023, ACM International Conference Proceeding Series Sreemana Datta is pursuing
    Ph.D. degree in the Department of Computer Science and Engineering from National
    Institute of Technology (NIT), Patna, Bihar (800005), India. She received her
    M.E. degree in Multimedia Development from Jadavpur University, Kolkata, India.
    Her current research interests include Wireless Sensor Networks, Blockchain Technology.
    Mailing Address: Quarter Number 1130, Sector 4F, Bokaro Steel City, Jharkhand,
    Pincode — 827004. Email Address: sreemanad.phd18.cs@nitp.ac.in Ditipriya Sinha
    has received Ph.D. degree from the Department of Computer Science and Technology,
    Indian Institute of Engineering Science and Technology (IIEST), Shibpur and Master
    of Technology from West Bengal University of Technology in the department of Software
    Engineering. She is the silver medal winner during M.Tech. She is presently serving
    as an Assistant Professor in the Department of Computer Science and Engineering,
    National Institute of Technology, Patna. She is a former Assistant Professor in
    the Department of Computer Science and Engineering, Birla Institute of Technology,
    Mesra. Her area of research is Mobile Ad-hoc Networks, Wireless Sensor Networks,
    Blockchain technology, Security and Scheduling algorithms. Mailing Address: Department
    of Computer Science and Engineering, National Institute of Information Technology
    Patna, Patna-800005, India. Email Address: ditipriyasinha87@gmail.com View Abstract
    © 2023 Elsevier B.V. All rights reserved. Recommended articles On efficient matching
    of spatiotemporal rules Future Generation Computer Systems, Volume 146, 2023,
    pp. 250-259 Xiaofeng Yu, …, Zhanqi Cui View PDF Load balanced locality-aware parallel
    SGD on multicore architectures for latent factor based collaborative filtering
    Future Generation Computer Systems, Volume 146, 2023, pp. 207-221 Selcuk Gulcan,
    …, Cevdet Aykanat View PDF Assessing Saiph, a task-based DSL for high-performance
    computational fluid dynamics Future Generation Computer Systems, Volume 147, 2023,
    pp. 235-250 Sandra Macià, …, Vicenç Beltran View PDF Show 3 more articles Article
    Metrics Citations Citation Indexes: 2 Captures Readers: 11 View details About
    ScienceDirect Remote access Shopping cart Advertise Contact and support Terms
    and conditions Privacy policy Cookies are used by this site. Cookie settings |
    Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V.,
    its licensors, and contributors. All rights are reserved, including those for
    text and data mining, AI training, and similar technologies. For all open access
    content, the Creative Commons licensing terms apply."'
  inline_citation: '>'
  journal: Future Generation Computer Systems
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'BSEIFFS: Blockchain-secured edge-intelligent forest fire surveillance'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Nandi A.
  - Xhafa F.
  - Kumar R.
  citation_count: '2'
  description: In the high-performance computing (HPC) domain, federated learning
    has gained immense popularity. Especially in emotional and physical health analytics
    and experimental facilities. Federated learning is one of the most promising distributed
    machine learning frameworks because it supports data privacy and security by not
    sharing the clients’ data but instead sharing their local models. In federated
    learning, many clients explicitly train their machine learning/deep learning models
    (local training) before aggregating them as a global model at the global server.
    However, the FL framework is difficult to build and deploy across multiple distributed
    clients due to its heterogeneous nature. We developed Docker-enabled federated
    learning (DFL) by utilizing client-agnostic technologies like Docker containers
    to simplify the deployment of FL frameworks for data stream processing on the
    heterogeneous client. In the DFL, the clients and global servers are written using
    TensorFlow and lightweight message queuing telemetry transport protocol to communicate
    between clients and global servers in the IoT environment. Furthermore, the DFL’s
    effectiveness, efficiency, and scalability are evaluated in the test case scenario
    where real-time emotion state classification is done from distributed multi-modal
    physiological data streams under various practical configurations.
  doi: 10.1007/s00607-023-01179-5
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Log in Find a journal
    Publish with us Track your research Search Cart Home Computing Article A Docker-based
    federated learning framework design and deployment for multi-modal data stream
    classification Regular Paper Published: 11 May 2023 Volume 105, pages 2195–2229,
    (2023) Cite this article Download PDF Access provided by University of Nebraska-Lincoln
    Computing Aims and scope Submit manuscript Arijit Nandi, Fatos Xhafa & Rohit Kumar  876
    Accesses 2 Citations Explore all metrics Abstract In the high-performance computing
    (HPC) domain, federated learning has gained immense popularity. Especially in
    emotional and physical health analytics and experimental facilities. Federated
    learning is one of the most promising distributed machine learning frameworks
    because it supports data privacy and security by not sharing the clients’ data
    but instead sharing their local models. In federated learning, many clients explicitly
    train their machine learning/deep learning models (local training) before aggregating
    them as a global model at the global server. However, the FL framework is difficult
    to build and deploy across multiple distributed clients due to its heterogeneous
    nature. We developed Docker-enabled federated learning (DFL) by utilizing client-agnostic
    technologies like Docker containers to simplify the deployment of FL frameworks
    for data stream processing on the heterogeneous client. In the DFL, the clients
    and global servers are written using TensorFlow and lightweight message queuing
    telemetry transport protocol to communicate between clients and global servers
    in the IoT environment. Furthermore, the DFL’s effectiveness, efficiency, and
    scalability are evaluated in the test case scenario where real-time emotion state
    classification is done from distributed multi-modal physiological data streams
    under various practical configurations. Similar content being viewed by others
    Federated Learning with Exponentially Weighted Moving Average for Real-Time Emotion
    Classification Chapter © 2023 Federated learning inspired privacy sensitive emotion
    recognition based on multi-modal physiological sensors Article 24 September 2023
    FTL-Emo: Federated Transfer Learning for Privacy Preserved Biomarker-Based Automatic
    Emotion Recognition Chapter © 2024 1 Introduction Artificial intelligence (AI)
    has emerged as the de-facto technology for a wide range of applications (such
    as smart industry, healthcare, and Unmanned Areal Vehicle (UAV) applications etc.),
    coinciding with the growth of Cloud Computing (CC) [1]. More applications are
    migrating from private infrastructures to cloud data centers to reap its benefits,
    such as scalability, elasticity, agility, and cost efficiency [2]. Bringing AI
    to the cloud is advantageous because computing resources are efficiently utilized,
    and costs for application deployment and operation are minimized by appropriately
    distributing physical resources in clouds, such as CPU, memory, storage, and network
    resources, to various cloud applications [3]. With the recent advances in technology,
    the number of connected Internet of Things (IoT) devices has increased enormously
    and according to CISCO, this number could exceed 75 billion by 2025, which is
    2.5 times the amount of data produced in 2020 (i,e. 31 billion) [4]. So, managing
    enormous, continuous, diverse, and dispersed IoT data appears to be hard while
    offering services at a specific performance level using cloud infrastructure.
    However, in traditional AI systems with CC enabled, data producers (such as IoT
    devices) most frequently transfer and exchange data with other parties (such as
    cloud servers), in order to train their models (such as Deep Learning(DL) or Machine
    Learning (ML)) to improve the performance of the system. This design pattern is
    unfeasible because of the high bandwidth requirements, legality, and privacy risks.
    For that, Federated Learning (FL) concept has recently emerged as a promising
    solution for mitigating the problems of data privacy, and legalization. Because
    Fl enables the distribution of computing load and training sensitive data locally
    without the need to transfer it to a primary server for privacy considerations
    [5]. In FL, each client (i.e., mobile, IoT and vehicular etc.) trains its local
    deep neural network (DNN) model with local data, which is then aggregated into
    a shared global model by the centralized server [6]. This scenario is repeated
    multiple rounds for better results and convergence. Having said that, Edge Computing
    (EC), bringing the Cloud Computing (CC) services closer to the data sources, is
    a revolutionary architecture that lowers latency and bandwidth costs while enhancing
    network resilience and availability. As a result, the EC-enabled architecture
    may satisfy the needs of time-critical applications with specific Service Level
    Agreement (SLA) requirements [4]. Additionally, the FL in the EC is a promising
    technique to handle IoT data by benefiting from distributed heterogeneous computing
    resources and relieving numerous clients’ privacy concerns because the generated
    raw data do not be exposed to the third party (cloud servers) [4]. It is seen
    that FL with EC has solved most of the problems, such as data privacy, legalization,
    lowering the latency, and minimizing the bandwidth, which is an outstanding achievement.
    However, it is also seen that, with the huge number of IoT devices, the data have
    velocity because of the high data generation rate and sequential arrival in time,
    according to data streams [7]. The data tuple needs to be processed and analyzed
    as soon as it arrives because operating to the edge has many limitations, such
    as limited computing resources, intermittent/denied network connectivity, etc.
    [8]. Apart from that, the underlying DL/ML model should be able to adapt to the
    changes from the continuous data stream in the dynamic environment. Nowadays,
    containers are easy-to-deploy software packages and containerized applications
    are easily distributed, making them a natural fit for EC with FL solutions [9].
    Edge containers can be deployed in parallel to geographically diverse points of
    presence (PoPs) to achieve higher levels of availability when compared to a traditional
    cloud container [10]. The edge containers are located at the edge of the network,
    much closer to the end user. With the introduction of the container and microservice
    design, it is now possible to increase the scalability and elasticity of application
    deployment and delivering [10, 11]. There is a plethora of different FL platforms
    and frameworks from academia and industry. These are complex to use and deeper
    knowledge in FL is required [12]. Most of the existing FL systems from academia
    are mostly research-oriented such as LEAF [13], TFF [14], and PySyft [15]. These
    are not straightforward for the interested people in FL and have a lack of support
    to build the FL prototype and run it in production. Industrial FL frameworks such
    as FATE [16] and PaddleFL [17] are not friendly to beginners and researchers due
    to the complex environment setup and heavy system design [12]. Apart from the
    complex development and deployability of these FL frameworks, the local dataset
    is distributed over different clients in order to build the local model. That
    means data does not arrive sequentially, the way data arrives in the case of data
    streams. Hence, these FL frameworks are incapable of processing data streams in
    real time to adapt the changes in today’s dynamic environment. To address these
    issues, in this paper, we design and deploy the Docker-enabled Federated Learning
    framework (DFL) by taking the advantage of Docker-Containers and with the capability
    of processing the data streams in real-time. The DFL simplifies the deployment
    of the FL among numerous clients by utilizing Docker containers and it can handle
    multi-modal data streams to make the classification in real time. In particular,
    in the proposed DFL, each client and the global server implemented by TensorFlow
    is installed on a Docker container. Also, the communication between clients and
    the server is done by the lightweight MQTT protocol, which enables DFL to be used
    IoT environment. Additionally, the DFL’s efficacy, efficiency, and scalability
    are assessed in the test case scenario, which involves real-time emotion state
    classification from distributed multi-modal physiological data streams in a variety
    of real-world setups. The main contributions of our work are as follows: We proposed
    a Docker-enabled Federated Learning framework (DFL) which simplifies the deployment
    of the FL among numerous clients by utilizing the Docker-container solutions to
    integrate multi-modal data stream processing along with a lightweight MQTT protocol
    for the IoT environment. We deploy a multi-modal data streaming in an HPC system
    to implement the proposed DFL and leverage the docker-container solution to guarantee
    the scalability of the framework. A real-time emotion classification from multimodal
    physiological data stream use case is adapted for the DFL framework to process
    the high-velocity data streams. The experimental results verify its feasibility,
    scalability and privacy preserving in multi-modal data processing and online ML
    applications on cloud computing infrastructure. The rest of the paper is structured
    as follows: Sect. 3 introduces briefly the multi-modal data stream classification,
    docker technology and federate learning. The proposed DFL architecture is explained
    and illustrated in Sect. 4. Following to this, the deployment in real infrastructure,
    experimental method and performance evaluation of the proposed DFL are presented
    in Sect. 5 along with the experimental results and discussion. Finally, the paper
    ends with the conclusion in Sect. 6. 2 Related work This section presents the
    previous literature on data stream classification, FL and the Docker-based deployment
    in the EC paradigm. Furthermore, the pitfalls of data stream classification approaches
    and the existing FL systems are mentioned. The digital revolution is characterized
    by an ongoing data collection process, which results in data being fed into the
    corresponding machine learning algorithms across various applications [18]. In
    the context of distributed machine learning, continuous data collection provides
    training data in the form of a data stream for each \"node\" in the distributed
    system. Given that \"(full) batch processing\" is realistically impractical in
    the face of continuous data delivery and distributed training of models using
    streaming data needs (single-pass) [18]. In the following two instances, streaming
    data is typically processed: (1) For the master-worker learning architecture,
    the data stream comes at a single master node and is then dispersed among a total
    of N worker nodes to distribute the computational load and speed up training time;
    (2) The objective of the FL and EC frameworks is to develop a machine learning
    model utilizing data from all of the nodes in a collection of N geographically
    scattered nodes, each of which receives its own independent stream of data, without
    sharing the data to other parties [18]. In the literature, most of the data stream
    classification approaches follow the first master-worker approach. These approaches
    ranging from different model ensemble to feature fusion, in order to increase
    the overall performance of the predictive system, such approaches are Accuracy
    Weighted Ensemble classifier (AWE) [19], Adaptive Random Forest classifier (ARF)
    [20], Dynamic Weighted Majority ensemble classifier (DWM) [21], Learn++.NSE ensemble
    classifier [22], Learn++ ensemble classifier [23], Streaming Random Patches ensemble
    classifier (SRPE) [24] and many more. There have been several approaches developed
    to address the complexity of FL integration. For instance, Google, the original
    FL developer [6], intends to improve their TensorFlow engine to allow distributed
    learning with TensorFlow Federated [14]. The framework includes crucial functions
    including the ability to subscribe to a small number of events to track the execution
    stages and enable third-party integration. The framework also includes the tools
    needed for a quick start as well as the datasets that are often utilized. But
    because the framework only works with TensorFlow models, it is more challenging
    for researchers to combine FL with models created using different training engines.
    There are also FL frameworks that are engine-specific, such as PaddleFL [17],
    which supports the PaddlePaddle engine, and FedToch [25], which exclusively supports
    PyTorch models. In contrast to the previously stated frameworks, FedML [26] offers
    a comprehensive framework that originally served as a fair benchmarking tool for
    methods utilizing federated learning. From client selection through aggregation
    and validation, the whole federated workflow is integrated. Their architecture,
    which is essential for parallel client simulation and enables executions to take
    place within or outside of a single host, offers message-passing interface-based
    (MPI) settings, in contrast to other systems where tests only run locally [26].
    Also, to test their performances, MNIST handwritten digits and the CIFAR for images
    are the popular benchmark datasets used in the literature [27]. Also, the industrial
    FL frameworks like FATE [16] and PaddleFL [17] are not user- and researcher-friendly
    because of the complicated environment setup and sophisticated system design [28].
    There is a plethora of master-worker-based approaches for data stream processing.
    The major disadvantages of these approaches are as follows: (1) privacy and security
    issues, because data streams need to be sent to the master server; (2) sending
    the data to the master server causes a high bandwidth overload (3) most of the
    approaches process the data in batch mode hence they are incapable of processing
    high-velocity data streams. Whereas, FL with EC is more reliable in this regard,
    fulfilling all the needs (as mentioned in the introduction). In addition to the
    complicated design and deployment of these FL frameworks, the local dataset is
    distributed across several clients to construct the local model, indicating that
    data does not come timely, as it does in data streams. As a result, these FL frameworks
    cannot handle data streams in real-time to respond to the changes in today’s dynamic
    environment. Also, the analysis of computation resources needed to run the models
    on the client side is missing in all the available FL systems, making these even
    harder to use in a real-world scenario. Regarding the deployment of FL in edge
    devices, Docker containers are the best suitable option to utilize as they are
    simple to install software packages, and containerized applications are simple
    to distribute [29]. It can make the deployment quickly, has a tiny footprint,
    and has high performance making it a potentially viable Edge Computing platform
    [30]. Also, the CPU, memory, storage and network performance is minimal as compared
    to the Virtual Machines (VMs) running on hypervisor [31]. Dockers run 26X faster
    than VMs and can run on small devices with lower resources, hence the best fit
    for FL in EC [32]. So, the docker based FL deployment is a solution to run efficiently
    on the edge devices. 3 Background In this section, we present a brief introduction
    to multi-modal steam classification, docker technology and federated learning.
    3.1 Multi-modal stream classification Classifying continuous incoming unbounded
    data tuples produced from multiple sources/sensors in real-time is called multi-modal
    stream classification [33]. In this case, the base classifier learns and updates
    itself progressively (called online learning) from the data stream [19]. As a
    consequence, the online classifier performs poorly at the initial stage but improves
    performance gradually as it sees more data tuples. The progressive (online) learning
    steps of a stream classifier are presented as follows [19]: 1. Receive incoming
    data instance or tuple (\\(x_t\\)) without the actual label (\\(y_t\\)). Where
    t is the time of arrival. 2. Predict the class \\(\\hat{y}_t = M_t(x_t)\\) for
    \\(x_t\\), where \\(M_t\\) is the current model. 3. Immediately after classifying
    \\(x_t\\), receive the corresponding actual label \\(y_t\\). 4. Train the model
    \\(M_t\\) with the actual label \\(y_t\\) and update the performance metrics using
    \\((\\hat{y_t}, y_t)\\). 5. Proceed to the next data tuple. Now, in the case of
    multi-modal data stream classification, the extracted features of the received
    data tuples from each modality are fused (using the concatenation approach) and
    fed to the stream classifier for the class prediction, which follows the previously
    mentioned progressive learning steps. In Fig. 1 the process of multi-modal data
    stream classification is depicted. The main noticeable point in Fig. 1 is the
    time (t) dimension, where different data tuple arrives in a stream mode at a different
    time (\\(t_1,t_2 \\cdots \\)) from different modality. Fig. 1 Multi-modal data
    stream classification in online mode Full size image In this work, the following
    assumptions are made to classify multi-modal data stream: The arrival of data
    tuples is sequential (one at a time). The base model first receives the unlabeled
    data tuples of the stream and immediately after the class prediction, the true/actual
    class label of the corresponding data tuple arrives. Hence it is supervised stream
    classification approach. The model is tested first and then trained based on the
    arrived true class label, also known as interleaved test-then-train approach.
    Model can see the received data tuples at most once, hence multiple runs through
    the data is not possible. Only temporary storage for the data stream is available,
    meaning no loop back through the received data tuples. In this research study,
    we have considered the feature fusion approach (shown in Fig. 1) for multi-modal
    data stream classification. In feature fusion approach includes (1) feature extraction
    from data streams from every single modal; (2) performing a feature fusion to
    create a single feature representation; (3) performing the data stream classification
    and updating the model progressively (online learning). 3.2 Docker technology
    Docker is a well-known, open-source and very popular containerization framework
    in the software industry [34]. It automates the development and deployment of
    application containers by allowing us to bundle an application with its run-time
    requirements into a container image and then execute that image on a host system
    [11]. The Docker Engine is installed on the host machine and is presently supported
    by the majority of operating systems. Containers are an abstraction at the application
    layer that groups together code and dependencies. Users can easily acquire binaries
    or libraries by providing the operating system release. The important part is
    that there is no need to install a new operating system; containers just get the
    kernel of the operating system, which may be shared among containers. In comparison
    to new system installation, which can take tens of gigabytes and boot slowly,
    container images are often tens of megabytes in size and start quickly. Docker
    images are a lightweight, stand-alone, compact and executable package that includes
    all the necessary requirements to run software including code, libraries, environment
    variables and configuration files [1]. Due to this property, an image is heavily
    customizable based on the contents with a little change. For that users create
    a Dockerfile with a simple syntax for defining the steps needed to build an image
    and run it. In summary, Dockerfile is the builder of an image and a container
    is a runnable instance of an image. In Fig. 2 the Docker ecosystem is presented.
    Fig. 2 Overview of docker ecosystem Full size image 3.3 Federated learning The
    Federated Learning ( [6, 35]) approach intends to provide system support for cooperatively
    training machine learning (ML) or deep learning (DL) models using distributed
    data silos while maintaining privacy and model performance. The main system design
    to support training models \"in-place\", which differs from traditional ML/DL
    model training, in which data is collected and managed centrally over a fully
    controlled distributed cluster [36]. The main advantage of such an \"in-place\"
    training system (FL) is that it facilitates privacy and security protections,
    which have led to new legislation such as the General Data Protection Regulation
    (GDPR) and the Health Insurance Portability and Accountability Act (HIPAA), which
    prohibits transferring user private data to a centralized location [36]. Based
    on the scale of the federation, FL is divided into two types – cross-silo and
    cross-device. In the case of cross-silo, the number of clients is usually small
    but has huge computational ability [37]. On the other hand, when it comes to cross-device
    the number of clients are enormous and have low computation power. From the model
    training and availability aspect, the organization (cross-silo) to be available
    is not the same as mobile devices (cross-device) [28]. In cross-device the poor
    network and limited computation resources can hamper the device’s availability.
    In this work, we have considered the cross-device federation approach for our
    DFL development. In Fig. 3, the system overview of cross-device FL is presented.
    Fig. 3 System overview of cross-device federated learning Full size image The
    FL has three major components as follows [7]: Clients These are the stakeholders
    in FL. Only clients have data accessibility because data is generated at this
    end. The main responsibilities of clients are local model training from the generated
    data at its end and sharing their model parameters with the global server. The
    important point is that no raw data is shared with other parties anywhere. Server
    The server/global server is usually the strong computation node. It handles the
    communications between the clients and itself to create the global model based
    on the received local models from the clients. Aggregation framework FL’s aggregation
    framework performs two tasks: computation and communication activities. Computation
    occurs on both the client and the global server, and communication occurs between
    clients and management. The computational component is utilized for model training,
    while the communication component is used to communicate model parameters. Federated
    Averaging (FedAvg) is FL’s most popularly used aggregation framework. 3.4 Realtime
    multimodal emotion classification system ReMECS (Realtime Multimodal Emotion Classification
    System) is our previously developed emotion classification system using multimodal
    physiological data streams in real-time (details see [33]). In ReMECS, the multimodal
    data stream arrives, and the feature extraction is done for the corresponding
    stream modality. Then the extracted features are sent to the corresponding modality
    classifier classification. The base classifier for ReMECS was a 3-layer feed-forward
    neural network, and the Stochastic Gradient Descent (SGD) was used to train the
    classifier in an online fashion. In the end, emotion class predictions from the
    corresponding classifier for each sensor modality are collected, and a decision
    fusion (Dynamic Weighted Majority voting) is done to predict the final emotion
    prediction. However, in this study, feature fusion has been taken into consideration
    rather than decision fusion to lessen the complexity of the real-time classifier
    inside the DFL framework. As a result, our ReMECS is altered in this regard, but
    the system’s fundamental design and operation have remained the same. 4 DFL architecture
    In this section, the overall architecture of the proposed DFL framework is presented.
    The motivation of this work is to make easy development and deployment of a federated
    learning framework using the cloud-native solution called Docker-container which
    is capable of processing real-time multi-modal data streams and handling scalability
    (multiple clients). The DFL architecture is presented in Fig. 4. Fig. 4 The proposed
    DFL’s architecture Full size image From Fig. 4, it can be seen that the DFL consists
    of one global server/node and multiple client nodes. At the global server, there
    is two layers (global model creation layer and model transfer layer) running inside
    the docker container. These are coupled together, hence a multi-layer structure.
    The model transfer layer is mainly the MQTT broker running whose main function
    is to receive the local models from client nodes and send them to the global model
    creation layer, and send the created global model to each client nodes for next
    round in FL. Now, global model creation layer, as the name suggests, it is responsible
    for performing federated averaging on all the local models collected at time t
    and creating the global model to send it to the MQTT broker. However, selecting
    the appropriate protocol is totally application-dependent; MQTT and CoAP are widely
    used in IoT contexts. The four key reasons for using MQTT over CoAP in our DFL
    development are as follows: Message queuing is supported in MQTT for disconnected
    subscribers, but not in CoAP. The maximum message size in MQTT is 256MB, however,
    it is 1152 Bytes (1.1KB) in COAP. The message (model communicated by clients to
    the server) size for our DFL framework was 25KB, however, this varies depending
    on neural network designs. MQTT works best as a live data (data in motion)communications
    bus. Our DFL framework collects data in the stream and shares local models with
    the global server in real-time. MQTT has many-to-many support, whereas CoAP is
    one-to-one. In client nodes, each node runs inside the docker container (one container
    for each) and connects with the global server/node. The client node and global
    server/node communicate via MQTT protocol. In each client node, there are three
    layers, the first is the data access layer, the second one is data transfer layer
    and the third one is the online ML layer. Each layer is connected with each other
    making it a hierarchical multi-layer structure as shown in Fig. 4. The data access
    layer is responsible for accessing the data stream acquisition and decoding the
    data streams. Data transfer layer temporarily stores the data tuples received
    from the data access layer in the buffer (message queue) and further sends it
    to the online ML layer for real-time processing. In the online ML layer does the
    real-time processing part, which involves the model testing (prediction), training
    and model weight sharing to the global server for federated averaging. Inside
    the online ML layer, the model update functionality is mainly responsible for
    sharing the model parameters (weights) with the global server and receiving the
    global model from the global server; also updating each client’s local model weights
    with the received global model. Last but not least, to the best of our knowledge,
    DFL is the distributed cloud native federated learning framework that integrates
    both real-time data stream processing applications and online ML pipelines to
    explore the innovative analysis of data streams. Another speciality of DFL is
    that it is even suitable in the IoT environment. The source code and implementation
    details of our proposed DFL framework can be found on GitHub 1and the images for
    the global server (fed-server) side and client side (fed-clients) can be found
    in DockerHub. 2\\(^{,}\\) 3\\(^{,}\\) 4 5 Experimental materials and methods To
    evaluate the feasibility of our proposed DFL framework in data stream processing
    we have considered a use-case scenario where real-time emotion classification
    is done using multi-modal physiological data streams. In this section, we have
    discussed the orchestration and management of the proposed DFL in the real infrastructure,
    the dataset considered for the multi-modal data stream, the experimental study
    and the steps involved in DFL framework. Along with these, the experimental setup
    and the considered performance metrics are presented in the end. 5.1 Deployment
    in real infrastructure The proposed DFL is deployed in Eurecat’s High-Performance
    Computing (HPC) system, Datura. The reason for deploying the DFL in the Datura
    infrastructure is to test the DFL framework’s behaviour in the large distributed
    infrastructure. That means each component of the DFL framework can be analyzed
    and monitored individually regarding performance, reliability, and scalability.
    Datura is an Infrastructure as a Service (IaaS) platform providing cloud computing
    services to our internal data analytic projects with high computation requirements
    in Eurecat. Datura cloud consists of huge computing resources of 5.5 Tera Bytes(TB)
    RAM and 5 Peta Bytes(PB) storage with high-speed internal bandwidth. The platform
    is managed using the Red Hat OpenStack platform to provide and manage the required
    infrastructure support. In Fig. 5 the high-level architecture of the Datura HPC
    platform is presented: Fig. 5 High level architecture of Eurecat’s Datura HPC
    Full size image The deployment of DFL in the real infrastructure is divided into
    two categories: Global server and MQTT broker integration, Application integration
    on client side. In both the global server and client incoming results visualization
    is available. Global server and MQTT broker integration: The global server and
    MQTT broker are integrated together so that multiple clients can connect to the
    server for the FL. In the global server, the federated averaging (FedAvg) script
    runs which takes all the local model weights as input and produces a global model.
    The FedAvg is developed using Python 3.7 and TensorFlow 2.0. 5 For the MQTT broker,
    we have used an open-source and distributed IoT message broker framework called
    EMQ X broker. 6 The reason for choosing EMQ X as the MQTT broker is because it
    is the most scalable MQTT Broker for IoT and connects 100 M+ IoT devices in 1
    cluster at 1ms latency (as mentioned in the official website. 7) Having said that,
    both the global server and EMQ X broker of DFL run inside a docker container at
    Datura HPC. The detailed overview of this integration is pictorially shown in
    Fig. 4 (see the \"Global server\" part). A snippet of the global server-side Command
    Line Interface (CLI) output only accessible for the DFL maintainer (not accessible
    from clients) is presented in Fig. 6. Fig. 6 Global server-side CLI output Full
    size image Application integration in client-side: This integration runs on the
    client side. When the end users (clients) connect this integration runs. The details
    of this integration are mentioned in the DFL architecture (see Fig. 4, especially
    the client node). For this implementation, we have made this very simple and it’s
    shown in CLI. In the CLI, the current data stream classifier’s performance details
    will be shown, along with the classifier’s real-time prediction vs the actual
    class of the current data tuple in the stream. A sample view of the CLI on the
    client side is shown in Fig. 7. The admin’s side CLI (Fig. 6) view is for code
    debugging to any sort of error handling. On the other hand, client-side CLI (Fig.
    7) is for just visualizing the current emotional state. Because later, we will
    be showing this in a GUI from the CLI for better visual, just an add-on to the
    existing DFL framework, a cosmetic change. Fig. 7 Client’s side CLI view Full
    size image 5.2 Dataset description To assess the feasibility and effectiveness
    of our proposed DFL framework in real-time emotion classification, we have used
    the most popular and widely used benchmark dataset DEAP [38]. The following is
    a brief description of the DEAP 8 [38] (Database for Emotion Analysis using Physiological
    Signals) dataset. In the DEAP dataset, Electrodermal Activity (EDA) signal is
    available in channel no. 37 and Respiratory Belt (RB) signal is in channel no.
    38. In this experiment, the EDA and RB signals are considered for the multi-modal
    physiological data stream (see Table 1 for a brief description). Table 1 Brief
    description of DEAP dataset Full size table 5.3 Experimental study The following
    steps are the experimental study of our proposed DFL framework for real-time emotion
    classification using multi-modal physiological data streams (for example, EDA+RB
    data streams for DEAP dataset): Data set consideration and data rearrangement:
    The multi-modal data stream is created using the pre-processed multi-modal DEAP
    data. The DEAP is stored in 3D matrix form, so a data rearrangement is conducted
    to transform the data to 1D matrix form for a simpler understanding of EDA and
    RB data. The representation is as follows: $$\\begin{aligned}{}[{\\mathrm{participant,video,data,valence\\,
    class, arousal\\, class}}] \\end{aligned}$$ In the experiment with the DEAP dataset,
    the EDA and RB multi-modal data streams are utilized to classify discrete emotion
    states based on valence-arousal measures. While streaming from the DEAP dataset,
    an automated mapping of the valence (V) and arousal (A) values to 0–1 is performed.
    Based on our previous experiment Fed-ReMECS [7], we followed the same V-A mapping
    and the next step discrete emotion conversion in the experiment. In Table 2 the
    discrete emotion labels (where L-Low, M-Middle and H-High) are presented: Table
    2 Discrete emotion mapping using valence-arousal state Full size table Stream
    reading: For each participant’s data streaming in the multi-modal data (DEAP)
    a non-overlapping sliding window protocol is used. As the physiological data recordings
    in the DEAP are 60 s long [38]; therefore the sliding window size can go to a
    maximum of 60 s. However, for this experiment, we set it at 30 s (taken from previous
    literature [39, 40]). The multi-modal data stream rate for the DEAP data is approximately
    9Mb/30 s. Feature extraction and fusion: The wavelet feature extraction approach
    is employed in this experiment to extract features from multi-modal signal streams
    (EDA and RB signals from the DEAP dataset). The wavelet Daubechies 4 (Db4) is
    the base function used for feature extraction. In our experiment, we decompose
    EDA and RB into three levels. A feature fusion technique (concatenation approach)
    combines the collected features from the EDA and RB modalities. The fused features
    are subsequently passed to the client-side emotion classifier. Emotion classifier:
    A three-layer Feed Forward Neural Network (FFNN) is used as the basis classifier
    to categorize the discrete emotion labels (in Table 2) in real-time from multi-modal
    input streams (EDA and RB). The effectiveness of FFNN best classifier for real-time
    emotion classification from multi-modal physiological data streams is already
    been established in our previous work [33]. The 9 different discrete emotion classes
    are in Table 2. Local model test-train: In online fashion, the FFNN model is trained
    using Stochastic Gradient Descent (SGD). As mentioned before, the interleaved
    test-then-train technique is the evaluator of the base classifier [19]. It validates
    the model before training and then updates the performance metrics using the received
    data tuple. That means the base classifier is evaluated on the newly received
    data tuples. The basic classifier initially performs poorly, but when it encounters
    more data tuples from multi-modal data streams, it develops stability and increases
    performance. Local model sending and global model receiving: The required time
    to send the local model and receive the global model varies from problem to problem
    and also depends on the developer of the experiment. In this experiment, we assess
    the transmitting and receiving time using the DEAP dataset experimental design.
    In the DEAP dataset, each participant views a 60-second video at a time, therefore
    the local model is constructed at that time. After each 60-second video is completed,
    the local model is transferred to the MQTT broker, and then to the global server
    for global model creation. Once the global model is built, the global server transmits
    it to the MQTT broker, who then delivers it to all of the clients involved in
    the federated learning. Finally, all of the clients update their local models
    using the received global model (see Fig. 8 for better understanding). Global
    model creation: The global server is in charge of constructing the global model
    after performing Federated Averaging (FedAvg) on all of the received local models
    at a certain point in time. The FedAvg formula is as follows (in Eq. (1)): $$\\begin{aligned}
    w_{t}^{g} = {\\frac{1}{|nT |}\\sum _{i=1}^{|nT |} w_{t-1,i}^{l}} \\end{aligned}$$
    (1) where \\(w_{t}^{g}\\) is the global model created at time t, \\(|nT |\\) is
    the total number of the local model received at the global server, \\(w_{t-1,i}^{l}\\)
    is the local model received from all clients at time t. For this work, we assumed
    full participation from all available clients in FedAvg, but clients can join
    and leave in the FL process at any point in time, hence the framework is highly
    asynchronous. Local model update: When each client receives the global model,
    its local model is updated with the global model, and the next federated learning
    iteration begins at each client side. The following Eq: 2 is used to update the
    weight of each local model. $$\\begin{aligned} w_{t+1, i}^{l} \\leftarrow w_{t}^{g}
    - \\lambda \\bigtriangledown _{w_{t}^{g}} L(w_{t}^{g}) \\end{aligned}$$ (2) Where
    L is the loss function, \\(\\bigtriangledown _{w_{t}^{g}}\\) is the local model
    gradient of each client and \\(\\lambda \\) is the learning rate. It is worth
    noting that the categorical cross-entropy loss function is utilized to train the
    FFNN base classifier. The mathematical formula of the categorical cross-entropy
    loss function is in Eq. 3. $$\\begin{aligned} L = - \\sum _{i=1}^{|nC |}{y^o_c
    \\log (p^o_c)} \\end{aligned}$$ (3) Where \\(|nC |\\) is the number of classes
    (in our experiment, there are a total of 9 emotion class labels), y is the binary
    indicator (0 or 1) of the class label c for the observation o, and p is the projected
    probability that observation o belongs to class c [7]. Figures 8 and 9 show the
    proposed DFL architecture and the sequence diagram, respectively, while real-time
    emotion classification from multi-modal physiological data stream is performed
    on Eurecat’s Datura HPC platform. Fig. 8 The proposed DFL framework Full size
    image Fig. 9 The DFL framework’s sequence diagram for real-time emotion classification
    from multi-modal physiological signals Full size image 5.3.1 Experiment and parameter
    setup In the DFL deployment, we used two servers. On one, the global server and
    EMQ X broker running, and on the other server, the clients are created. The hardware
    configurations and software specifications for the DFL framework are presented
    in Table 3. Table 3 Hardware configurations and software specifications of DFL
    testbed Full size table 5.3.2 Performance metrics For the classifiers performance
    evaluation, accuracy (Acc) and \\(F1_{micro}\\) score are used. The metrics are
    calculated as follows [41]: $$\\begin{aligned}{} & {} Acc = \\frac{{\\sum \\nolimits
    _{i = 1}^{|nC |} {\\frac{{T{P_i} + T{N_i}}}{{T{P_i} + F{N_i} + F{P_i} + T{N_i}}}}
    }}{{|nC |}} \\end{aligned}$$ (4) $$\\begin{aligned}{} & {} F1_{micro} = 2*\\frac{{Pre_{micro}
    * Rec_{micro} }}{{Pre_{micro} + Rec_{micro}}} \\end{aligned}$$ (5) where \\(|nC
    |\\) is the number of classes. True positives (\\(TP_i\\)), True negatives (\\(TN_i\\)),
    False positives (\\(FP_i\\)) and False negatives (\\(FN_i\\)). The \\(FM_{micro}\\)
    is the weighted average of Precision (\\(Pre_{micro}\\)) and Recall (\\(Rec_{micro}\\)).
    Therefore, this score takes both false positives and false negatives into account.
    5.4 Results, analysis and discussion In this section, we present the experimented
    results of our proposed DFL framework for real-time emotion classification from
    a multi-modal physiological data stream. For the multi-modal physiological data
    stream the popular DEAP benchmark dataset is used. The proposed DFL is tested
    under different numbers of clients running in parallel. We have considered 6 different
    client settings (5, 10, 15, 20, 25, 32); meaning the first experiment is conducted
    using 5 clients running in parallel, the second one is 10 clients running in parallel
    and so on. Running clients in parallel means, at each client side the data reading
    and sending for processing is done using ReMECS approach (see Sect. 3 for more
    details) but with a twist that instead of decision fusion we used feature fusion
    in the DFL framework to reduce the computation. That means when clients connect
    to the server it runs the ReMECS at their end. The performance of our proposed
    DFL framework is examined in two different ways (1) Scalability vs performance
    test (see Sect. 5.4.1) and (2) Memory-CPU consumption test (see Sect. 5.4.2).
    Apart from the different client settings comparison, we have further compared
    (see Sect. 5.4.3 for more details) the proposed DFL framework with the existing
    literature based on the following criteria: Infrastructure-based (Centralised
    vs Distributed) and Training mode (Batched vs Online (streaming/real-time)) works:
    In this comparison, we have considered state-of-the-art (SOTA) studies that utilizes
    the same DEAP dataset, an ML/DL-based classifier for emotion classification using
    multi-modal physiological data. Additionally, the effectiveness of the emotion
    classifiers in distributed and centralized modes are compared. Furthermore, we
    have compared batch mode vs. online model training methods with the same objective.
    5.4.1 Scalability vs performance test In this test, we have tested the scalability
    vs the overall performance of our DFL framework in different numbers of client
    configurations. For the performance measure, the average testing accuracy and
    \\(F1_{micro}\\) score of the global model is reported in Table 4 and Fig. 10
    shows the performance changes over the real-time emotion classification process.
    Table 4 Average testing accuracy and \\(F1_{micro}\\) score of the global model
    Full size table Fig. 10 The overall performance of the global model in terms of
    accuracy and \\(F1_{micro}\\) while real-time emotion classification under different
    numbers of clients Full size image In the real-time emotion classification from
    multi-modal physiological data streaming using the DFL framework, the classification
    is done at each client’s end. That means the generated data is strictly accessible
    to each client, there is no way to access the data from the global server. That
    is why the global model’s testing accuracy and \\(F1_{micro}\\) are calculated
    by taking the average of all local models’ performance after updating the model
    with the current global model weights. Now, from Table 4, we can see that the
    DFL framework is capable of classifying emotions in real-time with adequate average
    accuracy and \\(F1_{micro}\\). Also, it is worth noticing that the DFL framework
    is also capable of handling multiple clients running in parallel, hence proving
    scalability. Now, from Fig. 10, the global model’s testing performance in terms
    of accuracy (left Fig. 10a) and \\(F1_{micro}\\) (right Fig. 10b) has changed
    over the time. The reason is because of the diverse local models received from
    different clients. The diversity in local models is because different clients’
    physiological responses are different resulting in different characteristics in
    data (EDA+RB) streams, even though they are using the same sensors. However, in
    some rounds, the global model’s accuracy and \\(F1_{micro}\\) have dropped because
    the global model performance calculation is done by taking an average of the local
    models’ performance. So, a large drop in one of the local model’s performance
    can cause a significant drop in global model performance. One interesting point
    to notice here is that the F1-score and the accuracy are similar because in our
    DFL framework, the data tuple arrives sequentially (online scenario), and every
    data tuple is classified into exactly one class out of 9 emotion classes. The
    performance metrics update sequentially based on every data tuple’s arrival. Also,
    we have considered micro-averaging of the F1-score for our model performance evaluation,
    and our classification is multi-class, hence the precision, recall, and that are
    all identical to accuracy. Nevertheless, from the average testing accuracy and
    \\(F1_{micro}\\) scores along with the overall performance of proposed our DFL
    framework in real-time emotion classification using multi-modal data streams without
    accessing the sensitive data streams, we can conclude that it has the capability
    of handling multiple clients in parallel and still marinating adequate performance.
    Also, DFL is capable of preserving the privacy issue by not accessing the data
    streams and developing a powerful global model for real-time emotion classification.
    5.4.2 Memory and CPU usage test In this test, we have calculated the CPU and memory
    usage of each component in DFL framework. The calculation is done using the default
    docker stats functionality, which provides all these details. By this test, we
    can confirm the overall computation cost and power consumption that is required
    to run the proposed DFL. In Fig. 11, the memory and CPU consumption of the docker-containers
    while running different numbers of clients is presented. This Fig. 11 will help
    us to understand each docker-containers power consumption needed to do real-time
    emotion classification using multi-modal data streams on the client side. Having
    said that, it can also give us the idea of running this container in low-powered
    IoT devices. Also, in Table 5, the CPU and memory consumption of different client
    containers are presented for the better understanding of the Fig. 11. Fig. 11
    The memory and CPU consumption of the docker-containers while different numbers
    of clients running in parallel Full size image As we can see from Fig. 11, the
    memory usage of each client running the container, in the beginning, is 200 Mebibytes
    (MiB) (209 Mb where 1 MiB = 1,048,576 Mb, see Table 5) equals to approximately
    1.3% of the total memory available and it takes a maximum of 250 MiB (260 Mb \\(\\approx
    \\) 1.6%, see Table 5) memory out of the total memory available in the server
    (mentioned in Table 3). Also, the memory usage depends on the incoming data tuples
    and the frequency of the model sharing happens while the FL process. On the other
    side, the CPU usage by each client-side container takes a maximum of 53% approximately.
    The maximum CPU usage happens when the emotion classification happens and the
    model update happens. Another point here worth noticing in the CPU usage plots
    is that initially there is a spike in the CPU usage. From the plots, we can see
    that the usage is very high. We checked and re-run the test over and over again
    and it stays the same but after some troubling shooting, we found out that it
    was docker containers not because of the processes running inside the client containers.
    Nevertheless, from the overall comparison, we can see that the docker-container
    at the client side takes less computation to do the emotion classification, hence
    it is capable of integration into IoT devices (low-powered devices). Table 5 The
    summary of the CPU and memory consumption of different client containers in different
    settings Full size table On the other side, the memory and CPU consumption is
    also calculated using the docker stats functionality. As the global server has
    two major (the MQTT broker and the FedAvg component) components running, we have
    calculated both of the component’s power consumption separately. In Figs. 12 and
    13, the memory and CPU consumption of the MQTT broker and FedAvg component are
    presented, respectively. In these plots (Figs. 12 and 13), on the X-axis, the
    time (in sec) and the Y-axis, the memory (in MiB) consumption change and also
    the CPU consumption change over time are presented, respectively. Here the time
    (in sec) means how long the DFL framework runs for the emotion classification
    test case. Fig. 12 The memory and CPU consumption of the EMQ X MQTT Broker in
    different numbers of clients setting Full size image Fig. 13 The memory and CPU
    consumption of the FedAvg component in different numbers of clients setting Full
    size image From the memory and CPU consumption Fig. 12 of EMQ X MQTT broker, we
    can see that the memory usage (see Fig. 12a) increases when the number of clients
    increases and takes part in the federated learning. In our experiment, the highest
    number of clients is 32 and in this case, the memory usage is about above 150
    MiB. Similarly in the CPU usage plot (see Fig. 12b), we can see the maximum usage
    is 6% and other than that it’s below 4%. Now, in the FedAvg component at the global
    server, the memory consumption is around 210 MiB (shown in Fig. 13a). Memory usage
    increases when the number of clients increases in the FL. As the FedAvg is done
    by aggregating all the local models received at some point of time and to do so
    the FedAvg component uses a queue to hold all the incoming local models before
    aggregation. Similarly, the CPU usage of the FedAvg component is a maximum of
    37% as shown in Fig. 13b. The CPU usage goes higher when there are local models
    coming for the global model creation and the rest of the time the CPU usage is
    below 1%. 5.4.3 Comparison with state-of-the-art works In [42], the authors have
    developed an 1D Convolutional Neural Network (CNN) Auto Encoder (AE) model (i.e.,
    1D-CNNAE) for real-time emotion classification (2-class i.e. valence and arousal)
    using photoplethysmogram (PPG) and galvanic skin response (GSR) signals. The proposed
    1D-CNNAE model’s efficiency is evaluated using DEAP datadset. In another recent
    work [43], researchers have developed emotion aware healthcare systems utilizing
    multi-modal physiological signals (such as PPG, RB and fingertip temperature (FTT)
    sensors). To accomplish the multi-modal emotion classification authors have used
    decision-level fusion and the base emotion classifier is Random Forest (RF). Another
    very interesting work in [44], authors have proposed an emotion-based music recommendation
    framework, which gauges a user’s mood based on signals from wearable physiological
    sensors. To recognize the emotions authors have used decision tree (DT), RF, SVM
    and k-nearest neighbors (k-NN) algorithms with/out feature fusion from GSR and
    PPG. Authors in [45] have used an unsupervised deep belief network (DBN) for depth
    level feature extraction form the fused observations from EDA, PPG and Zygomaticus
    Electromyography (zEMG) sensors signals. After that, a feature-fusion vector is
    created by combining the DBN-produced features with statistical features from
    EDA, PPG, and zEMG. The fused feature vector is then used to classify five basic
    emotions namely Happy, Relaxed, Disgust, Sad and Neutral. In order to classify
    these 5 basic emotion, the Fine Gaussian Support Vector Machine (FGSVM) is used
    with radial basis function kernel is used in the end. Similarly, in [46] authors
    have proposed a substructure-based joint probability domain adaptation algorithm
    (SSJPDA) to combat the noise impact of physiological signals. By using this approach,
    the sample level matching’s noise susceptibility and the domain level matching’s
    excessive roughness is avoided. In Table 6, the comparison between our proposed
    DFL and the selected state-of-the-art literature is presented. Table 6 Comparison
    with the selected state-of-the-art works for emotion classification using multi-modal
    physiological signals Full size table From the comparison presented in Table 6,
    we can see that our proposed DFL approach has performed better in classifying
    more granular emotion labels among other considered works expect the work present
    in [45]. Still our proposed DFL is better than  [45] is because our proposed DFL
    real-time, distributed and the base classifier is less complex that the DBN. In
    addition, the DFL approach provides the advantage of data diversity by gathering
    data from more subjects if required and also secures the sensitive data better
    than the centralized approaches by training the models locally where the data
    is accessible to only the corresponding end user not other parties. 6 Conclusion
    and future work In this paper, we have discussed and analyzed the easy development
    and deployment of the federated learning framework using cloud-native solutions
    such as Docker-Containers called DFL in an HPC environment. We mainly emphasize
    the easy deployment of the federated learning framework using the docker by ensuring
    scalability, fewer hardware resources consumption, privacy-preserving, and IoT
    environment friendly. We have deployed our proposed DFL in a real infrastructure
    at Eurecat’s HPC system (Datura) using the benchmark DEAP dataset for real-time
    emotion classification from multi-modal physiological data streams. An extensive
    experimental study is conducted on efficiency, memory usage, and CPU consumption
    by varying numbers of clients running in parallel. The results show that the DFL
    can handle multiple clients running in parallel. The overall performance is good
    regarding average accuracy and \\(F1_{micro}\\) while classifying real-time emotions
    from multi-modal data streams. Having said that, the DFL ensures privacy preservation
    by not accessing (generated data streams are only accessible to the clients) clients’
    data to develop a robust global model. In our future work, we plan to extend the
    development of the DFL framework in an application back end by adding GUI functionality
    and database storage at the clients’ end and supporting other ML/DL models. Also,
    we have plans to add different protocols other than MQTT and test its efficiency.
    With these additional functions, we plan to make it an open-source project so
    other researchers can use it. Availability of data and materials Publically available
    DEAP dataset [38]. Code availability https://github.com/officialarijit/Fed-ReMECS-Docker.
    Notes DFL’s source code: https://github.com/officialarijit/Fed-ReMECS-Docker.
    DockerHub: https://hub.docker.com/. Fed-clients: https://hub.docker.com/repository/docker/arijitnandi/fedclient.
    Fed-server: https://hub.docker.com/repository/docker/arijitnandi/fedserver. https://www.tensorflow.org/.
    https://github.com/emqx/emqx. https://www.emqx.io/. DEAP dataset link: https://www.eecs.qmul.ac.uk/mmv/datasets/deap/.
    References Kim J, Kim D, Lee J (2021) Design and implementation of kubernetes
    enabled federated learning platform. In: 2021 international conference on information
    and communication technology convergence (ICTC), pp. 410–412. https://doi.org/10.1109/ICTC52510.2021.9620986
    Shivadekar S, Mangalagiri J, Nguyen P, Chapman D, Halem M, Gite R (2021) An intelligent
    parallel distributed streaming framework for near real-time science sensors and
    high-resolution medical images. In: 50th international conference on parallel
    processing workshop. ICPP Workshops ’21. Association for computing machinery,
    New York, NY, USA. https://doi.org/10.1145/3458744.3474039 Chen Z, Liao W, Hua
    K, Lu C, Yu W (2021) Towards asynchronous federated learning for heterogeneous
    edge-powered internet of things. Digital Commun Netw 7(3):317–326. https://doi.org/10.1016/j.dcan.2021.04.001
    Article   Google Scholar   Abreha HG, Hayajneh M, Serhani MA (2022) Federated
    learning in edge computing: a systematic survey. Sensors. https://doi.org/10.3390/s22020450
    Article   Google Scholar   Wan X, Guan X, Wang T, Bai G, Choi B-Y (2018) Application
    deployment using microservice and docker containers: Framework and optimization.
    J Netw Comput Appl 119:97–109. https://doi.org/10.1016/j.jnca.2018.07.003 Article   Google
    Scholar   McMahan B, Moore E, Ramage D, Hampson S, Arcas BAy (2017) Communication-efficient
    learning of deep networks from decentralized data. In: Singh A, Zhu J (eds.) Proceedings
    of the 20th international conference on artificial intelligence and statistics.
    Proceedings of machine learning research, vol 54, pp 1273–1282. https://proceedings.mlr.press/v54/mcmahan17a.html
    Nandi A, Xhafa F (2022) A federated learning method for real-time emotion state
    classification from multi-modal streaming. Methods 204:340–347. https://doi.org/10.1016/j.ymeth.2022.03.005
    Article   Google Scholar   Novakouski M, Lewis G (2021) Operating at the edge.
    Carnegie Mellon University’s Software Engineering Institute Blog. Accessed 2023
    Jan 24 (2021). http://insights.sei.cmu.edu/blog/operating-at-the-edge/ Pitstick
    K, Ratzlaff J (2022) Containerization at the Edge. Carnegie Mellon University’s
    Software Engineering Institute Blog. Accessed 24 Jan 2023 (2022). http://insights.sei.cmu.edu/blog/containerization-at-the-edge/
    Damián Segrelles Quilis J, López-Huguet S, Lozano P, Blanquer I (2023) A federated
    cloud architecture for processing of cancer images on a distributed storage. Futur
    Gen Comput Syst 139:38–52. https://doi.org/10.1016/j.future.2022.09.019 Article   Google
    Scholar   Zou Z, Xie Y, Huang K, Xu G, Feng D, Long D (2022) A docker container
    anomaly monitoring system based on optimized isolation forest. IEEE Trans Cloud
    Comput 10(1):134–145. https://doi.org/10.1109/TCC.2019.2935724 Article   Google
    Scholar   Zhuang W, Gan X, Wen Y, Zhang S (2022) Easyfl: a low-code federated
    learning platform for dummies. IEEE Internet Things J 9(15):13740–13754. https://doi.org/10.1109/JIOT.2022.3143842
    Article   Google Scholar   Caldas S, Duddu SMK, Wu P, Li T, Konečnỳ J, McMahan
    HB, Smith V, Talwalkar A (2018) Leaf: a benchmark for federated settings. arXiv
    preprint arXiv:1812.01097 Tensorflow Federated. https://www.tensorflow.org/federated
    Ryffel T, Trask A, Dahl M, Wagner B, Mancuso J, Rueckert D, Passerat-Palmbach
    J (2018) A generic framework for privacy preserving deep learning. arXiv preprint
    arXiv:1811.04017 FederatedAI: Federatedai/Fate: An Industrial Grade Federated
    Learning Framework. https://github.com/FederatedAI/FATE Ma Y, Yu D, Wu T, Wang
    H (2019) Paddlepaddle: an open-source deep learning platform from industrial practice.
    Front Data Comput 1(1):105–115 Google Scholar   Nokleby M, Raja H, Bajwa WU (2020)
    Scaling-up distributed processing of data streams for machine learning. Proc IEEE
    108(11):1984–2012. https://doi.org/10.1109/JPROC.2020.3021381 Article   Google
    Scholar   Bifet A, Holmes G, Kirkby R, Pfahringer B (2010) Moa: Massive online
    analysis. J Mach Learn Res 11:1601–1604 Google Scholar   Gomes HM, Bifet A, Read
    J, Barddal JP, Enembreck F, Pfharinger B, Holmes G, Abdessalem T (2017) Adaptive
    random forests for evolving data stream classification. Mach Learn 106:1469–1495
    Article   MathSciNet   Google Scholar   Kolter JZ, Maloof MA (2007) Dynamic weighted
    majority: an ensemble method for drifting concepts. J Mach Learn Res 8(91):2755–2790
    MATH   Google Scholar   Elwell R, Polikar R (2011) Incremental learning of concept
    drift in nonstationary environments. IEEE Trans Neural Netw 22(10):1517–1531.
    https://doi.org/10.1109/TNN.2011.2160459 Article   Google Scholar   Polikar R,
    Upda L, Upda SS, Honavar V (2001) Learn++: an incremental learning algorithm for
    supervised neural networks. IEEE Trans Syst Man Cybernet Part C (Appl Rev) 31(4):497–508.
    https://doi.org/10.1109/5326.983933 Article   Google Scholar   Gomes HM, Read
    J, Bifet A (2019) Streaming random patches for evolving data stream classification.
    In: 2019 IEEE international conference on data mining (ICDM), pp 240–249. https://doi.org/10.1109/ICDM.2019.00034
    Haddadpour F, Kamani MM, Mokhtari A, Mahdavi M (2020) Federated learning with
    compression: unified analysis and sharp guarantees. arXiv preprint arXiv:2007.01154
    He C, Li S, So J, Zhang M, Wang H, Wang X, Vepakomma P, Singh A, Qiu H, Shen L,
    Zhao P, Kang Y, Liu Y, Raskar R, Yang Q, Annavaram M, Avestimehr S (2020) Fedml:
    a research library and benchmark for federated machine learning. arXiv:2007.13518
    Abdulrahman S, Tout H, Ould-Slimane H, Mourad A, Talhi C, Guizani M (2021) A survey
    on federated learning: the journey from centralized to distributed on-site learning
    and beyond. IEEE Internet Things J 8(7):5476–5497. https://doi.org/10.1109/JIOT.2020.3030072
    Article   Google Scholar   Arafeh M, Otrok H, Ould-Slimane H, Mourad A, Talhi
    C, Damiani E (2023) Modularfed: leveraging modularity in federated learning frameworks.
    Internet of Things 22:100694. https://doi.org/10.1016/j.iot.2023.100694 Article   Google
    Scholar   Ismail BI, Mostajeran Goortani E, Ab Karim MB, Ming Tat W, Setapa S,
    Luke JY, Hong Hoe O (2015) Evaluation of docker as edge computing platform. In:
    2015 IEEE conference on open systems (ICOS), pp 130–135. https://doi.org/10.1109/ICOS.2015.7377291
    Anderson C (2015) Docker [software engineering]. IEEE Softw 32(3):102–3. https://doi.org/10.1109/MS.2015.62
    Article   Google Scholar   Ismail BI, Jagadisan D, Khalid MF (2011) Determining
    overhead, variance & isolation metrics in virtualization for iaas cloud. In: Lin
    SC, Yen E (eds) Data driven e-Science. Springer, New York, NY, pp 315–330 Chapter   Google
    Scholar   Felter W, Ferreira A, Rajamony R, Rubio J (2015) An updated performance
    comparison of virtual machines and linux containers. In: 2015 IEEE International
    Symposium on Performance Analysis of Systems and Software (ISPASS), pp. 171–172.
    https://doi.org/10.1109/ISPASS.2015.7095802 Nandi A, Xhafa F, Subirats L, Fort
    S (2021) Real-time multimodal emotion classification system in e-learning context.
    In: Proceedings of the 22nd engineering applications of neural networks conference,
    pp 423–435 Wan Z, Zhang Z, Yin R, Yu G (2022) Kfiml: Kubernetes-based fog computing
    iot platform for online machine learning. IEEE Internet Things J 9(19):19463–19476.
    https://doi.org/10.1109/JIOT.2022.3168085 Article   Google Scholar   Zhang Y,
    Jiang C, Yue B, Wan J, Guizani M (2022) Information fusion for edge intelligence:
    a survey. Inf Fusion 81:171–186 Article   Google Scholar   Zawad S, Yan F, Anwar
    A (2022) In: Ludwig, H., Baracaldo, N. (eds.) Introduction to federated learning
    systems, pp. 195–212. Springer, Cham. https://doi.org/10.1007/978-3-030-96896-0_9
    Chahoud M, Otoum S, Mourad A (2023) On the feasibility of federated learning towards
    on-demand client deployment at the edge. Inf Process Manag 60(1):103150. https://doi.org/10.1016/j.ipm.2022.103150
    Article   Google Scholar   Koelstra S, Muhl C, Soleymani M, Lee J-S, Yazdani A,
    Ebrahimi T, Pun T, Nijholt A, Patras I (2012) Deap: a database for emotion analysis;using
    physiological signals. IEEE Trans Affect Comput 3(1):18–31 Article   Google Scholar   Ayata
    D, Yaslan Y, Kamaşak M (2016) Emotion recognition via random forest and galvanic
    skin response: comparison of time based feature sets, window sizes and wavelet
    approaches. In: Medical technologies national congress, pp 1–4 Candra H, Yuwono
    M, Chai R, Handojoseno A, Elamvazuthi I, Nguyen HT, Su S (2015) Investigation
    of window size in classification of EEg-emotion signal with wavelet entropy and
    support vector machine. In: 37th annual international conference of the IEEE EMBS,
    pp 7250–7253 Nandi A, Jana ND, Das S (2020) Improving the performance of neural
    networks with an ensemble of activation functions. In: 2020 international joint
    conference on neural networks (IJCNN), pp 1–7. https://doi.org/10.1109/IJCNN48605.2020.9207277
    Kang D-H, Kim D-H (2022) 1d convolutional autoencoder-based ppg and gsr signals
    for real-time emotion classification. IEEE Access 10:91332–91345. https://doi.org/10.1109/ACCESS.2022.3201342
    Article   Google Scholar   Ayata D, Yaslan Y, Kamasak EM (2020) Emotion recognition
    from multimodal physiological signals for emotion aware healthcare systems. J
    Med Biol Eng 149–157 Ayata D, Yaslan Y, Kamasak ME (2018) Emotion based music
    recommendation system using wearable physiological sensors. IEEE Trans Consum
    Electron 64(2):196–203. https://doi.org/10.1109/TCE.2018.2844736 Article   Google
    Scholar   Hassan MM, Alam MGR, Uddin MZ, Huda S, Almogren A, Fortino G (2019)
    Human emotion recognition using deep belief network architecture. Inf Fusion 51:10–18.
    https://doi.org/10.1016/j.inffus.2018.10.009 Article   Google Scholar   Fu Z,
    Zhang B, He X, Li Y, Wang H, Huang J (2022) Emotion recognition based on multi-modal
    physiological signals and transfer learning. Front Neurosci. https://doi.org/10.3389/fnins.2022.1000716
    Article   Google Scholar   Download references Acknowledgements Arijit Nandi is
    a fellow of Eurecat’s \"Vicente López\" PhD grant program. This study has been
    partially funded by ACCIÓ, Spain (Pla d’Actuació de Centres Tecnológics 2021)
    under the project TutorIA. We would like to thank the authors of DEAP dataset
    [38] for sharing with us. Funding Project TutorIA, ACCIÓ, Generalitat de Catalunya,
    Spain. Author information Authors and Affiliations Department of CS, Universitat
    Politècnica de Catalunya, 08034, Barcelona, Spain Arijit Nandi & Fatos Xhafa Eurecat,
    Centre Tecnològic de Catalunya, 08005, Barcelona, Spain Arijit Nandi & Rohit Kumar
    Contributions All authors contributed to designing the model and the computational
    framework, implementation, analysis of the results and writing of the manuscript.
    Corresponding authors Correspondence to Arijit Nandi or Fatos Xhafa. Ethics declarations
    Conflict of interest Not applicable. Ethics approval Not applicable. Consent to
    participate Not applicable. Consent for publication All authors have agreed on
    the publication. Additional information Publisher''s Note Springer Nature remains
    neutral with regard to jurisdictional claims in published maps and institutional
    affiliations. Rights and permissions Springer Nature or its licensor (e.g. a society
    or other partner) holds exclusive rights to this article under a publishing agreement
    with the author(s) or other rightsholder(s); author self-archiving of the accepted
    manuscript version of this article is solely governed by the terms of such publishing
    agreement and applicable law. Reprints and permissions About this article Cite
    this article Nandi, A., Xhafa, F. & Kumar, R. A Docker-based federated learning
    framework design and deployment for multi-modal data stream classification. Computing
    105, 2195–2229 (2023). https://doi.org/10.1007/s00607-023-01179-5 Download citation
    Received 14 November 2022 Accepted 19 April 2023 Published 11 May 2023 Issue Date
    October 2023 DOI https://doi.org/10.1007/s00607-023-01179-5 Share this article
    Anyone you share the following link with will be able to read this content: Get
    shareable link Provided by the Springer Nature SharedIt content-sharing initiative
    Keywords Federated learning High performance computing Multi-modal data streaming
    Docker-container Real-time emotion classification Mathematics Subject Classification
    68W15 94A16 68M20 68T05 68T07 68P27 Use our pre-submission checklist Avoid common
    mistakes on your manuscript. Sections Figures References Abstract Introduction
    Related work Background DFL architecture Experimental materials and methods Conclusion
    and future work Availability of data and materials Code availability Notes References
    Acknowledgements Funding Author information Ethics declarations Additional information
    Rights and permissions About this article Advertisement Discover content Journals
    A-Z Books A-Z Publish with us Publish your research Open access publishing Products
    and services Our products Librarians Societies Partners and advertisers Our imprints
    Springer Nature Portfolio BMC Palgrave Macmillan Apress Your privacy choices/Manage
    cookies Your US state privacy rights Accessibility statement Terms and conditions
    Privacy policy Help and support 129.93.161.219 Big Ten Academic Alliance (BTAA)
    (3000133814) - University of Nebraska-Lincoln (3000134173) © 2024 Springer Nature"'
  inline_citation: '>'
  journal: Computing
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: A Docker-based federated learning framework design and deployment for multi-modal
    data stream classification
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Forte G.
  - Antonelli M.
  - Brunazzi E.
  - Simmons M.J.
  - Stitt H.
  - Alberini F.
  citation_count: '2'
  description: Smart at- or online process sensors, which employ machine learning
    (ML) to process data, have been the subject of extensive research in recent years,
    due to their potential for real-time process control. In this paper, a passive
    acoustic emission process sensor has been used to detect gas–liquid regimes within
    a stirred, aerated vessel using novel ML approaches. Pressure fluctuations (acoustic
    emissions) in an air-water system were recorded using a piezoelectric sensor installed
    on the external wall of three identical cylindrical tanks of diameter, T = 160
    mm, filled to a volume of 5 L (height, H = 1.5 T). The tanks were made of either
    glass, steel, or aluminium, and each tank was equipped with a Rushton turbine
    of diameter, D = 0.35 T. The investigated flow regimes, flooding, loading, complete
    dispersion, and un-gassed, were obtained by changing the air feed flow rates and
    by varying the impeller speed. The acoustic spectra obtained were processed to
    select an optimal number of features characterizing each of the regimes, and these
    were used to train three different ML algorithms. The pre-processing includes
    a principal component analysis (PCA) step, which reduces the volume of data fed
    to the ML algorithms, saving computational time up to a factor of 5. The algorithms
    (decision tree, k-nearest neighbour, and support vector machines) were challenged
    to use these features to identify the correct flow regime. Accurate predictions
    of the three gas–liquid regimes of interest have been achieved. The accuracy of
    the prediction ranges from 90% to 99%, and this difference is related to the material
    used for the vessel.
  doi: 10.1002/cjce.24831
  full_citation: '>'
  full_text: '>

    "UNCL: University Of Nebraska - Linc Acquisitions Accounting Search within Login
    / Register The Canadian Journal of Chemical Engineering RESEARCH ARTICLE Full
    Access Flow regime identification in aerated stirred vessel using passive acoustic
    emission and machine learning Giuseppe Forte,  Matteo Antonelli,  Elisabetta Brunazzi,  Mark
    J. Simmons,  Hugh Stitt,  Federico Alberini First published: 15 January 2023 https://doi.org/10.1002/cjce.24831Citations:
    1 SECTIONS PDF TOOLS SHARE Abstract Smart at- or online process sensors, which
    employ machine learning (ML) to process data, have been the subject of extensive
    research in recent years, due to their potential for real-time process control.
    In this paper, a passive acoustic emission process sensor has been used to detect
    gas–liquid regimes within a stirred, aerated vessel using novel ML approaches.
    Pressure fluctuations (acoustic emissions) in an air-water system were recorded
    using a piezoelectric sensor installed on the external wall of three identical
    cylindrical tanks of diameter, T = 160 mm, filled to a volume of 5 L (height,
    H = 1.5 T). The tanks were made of either glass, steel, or aluminium, and each
    tank was equipped with a Rushton turbine of diameter, D = 0.35 T. The investigated
    flow regimes, flooding, loading, complete dispersion, and un-gassed, were obtained
    by changing the air feed flow rates and by varying the impeller speed. The acoustic
    spectra obtained were processed to select an optimal number of features characterizing
    each of the regimes, and these were used to train three different ML algorithms.
    The pre-processing includes a principal component analysis (PCA) step, which reduces
    the volume of data fed to the ML algorithms, saving computational time up to a
    factor of 5. The algorithms (decision tree, k-nearest neighbour, and support vector
    machines) were challenged to use these features to identify the correct flow regime.
    Accurate predictions of the three gas–liquid regimes of interest have been achieved.
    The accuracy of the prediction ranges from 90% to 99%, and this difference is
    related to the material used for the vessel. 1 INTRODUCTION Improvement in process
    monitoring and control is a critical driver for improved productivity, product
    quality, and reduced environmental impact within the process industries sector,
    whose products include chemicals, biochemical, food, and pharmaceuticals.[1, 2]
    A recent development is the use of ‘inferential or soft sensors’ as an enabler
    for data-driven model predictive control. The desired characteristics of such
    monitoring devices include low-cost, non-invasiveness, and fast response with,
    among others, acoustic sensors being a potential technology solution.[1] Acoustic
    emissions (AE) has been proven to be a powerful monitoring tool across a range
    of applications. These include the fault monitoring of bearing components[3-5]
    and the detection of leakages in pressurized pipes,[6] which are both relevant
    to the process and water industries. Other industrial applications include corrosion
    detection,[7] the integrity of pressure vessels,[7] and the monitoring of chemical
    reactions.[8, 9] Some applications are also found in the monitoring of particulate
    liquid processes[10] and in gas–liquid slug flow.[11] Passive AE in stirred vessels
    have also received significant attention in the academic literature for various
    gas–liquid systems. AE have been used for gas-bubble sizing[12] and the interrelationship
    between mass transfer and the sound spectra emitted by sparger, impeller, and
    bubbles have been investigated.[13-15] Many techniques have been applied to identify
    flow regime transitions, for example, fibre optic probe,[16] resistivity probe,[17]
    impedance probes,[18] level probes,[19] ultrasonic[20, 21] computer tomography
    coupled with computational fluid dynamics (CFD),[22] x-ray tomography,[23, 24]
    particle image velocimetry (PIV) coupled with CFD,[25] γ-ray,[26] and electrical
    resistance tomography (ERT).[27, 28] All of these methods have been successful
    in identifying flow regimes, but their implementation on the industrial scale
    is limited by practical factors such as cost, reliability, retrofitting, opacity
    of the system, intrusion, safety, installation time, cost, and response time.
    Despite the considerable academic interest, uptake of AE by the process industries
    has been limited, mainly because of the difficulties in interpreting the complexity
    of both the acquired signal and the multiphase processes themselves. However,
    the advent of multivariate techniques and machine learning (ML) algorithms, together
    with the availability of high-performance computing power, presents a valuable
    opportunity to address these issues and empower the use of data-rich AE signals
    for diagnostics of complex systems.[12, 29] A previous study by Forte et al.[2]
    illustrated the potential of combining AE with ML to identify gas–liquid flow
    regimes in a 3 L cylindrical stirred tank. The system was operated under three
    different flow regimes (completely dispersed, loading, and un-gassed), and the
    capability to classify the mixing regime correctly using four different ML algorithms
    was examined. An accuracy of over 90% in the categorization of the mixing regime
    was obtained, thus indicating AE as a possible monitoring tool for such unit operations.
    In this study, the method used by Forte et al.[2] is enhanced by the use of principal
    component analysis (PCA) for data pre-processing. PCA is used herein to reduce
    the number of parameters fed to the ML algorithms, thereby improving the speed
    by reducing the CPU requirements. Moreover, the developed methodology is tested
    using three geometrically identical 5 L vessels made from different materials:
    glass, stainless steel, and aluminium. The latter two were chosen to demonstrate
    the potential to be used on process vessels used by industry, with the former
    being used to enable the flow regime to be visually checked. 2 THEORY 2.1 Gas–Liquid
    mixing Gas–liquid mixing in mechanically agitated vessels is ubiquitous in both
    the chemical and biochemical industries.[13-15, 30] The gas phase is dispersed
    into a continuous liquid phase to obtain the desired mixing rate, mass, and heat
    exchange to complete the industrial transformations needed for the specific process.[24]
    In a gas–liquid stirred vessel, for a fixed gas flow rate, Qg, three major gas-flow
    regimes may be identified based upon the impeller velocity speed, N. These regimes
    are flooding, loading, and complete dispersion.[31, 32] In the first case, the
    impeller is not capable of overcoming the buoyancy of the gas, and hence dispersion
    is low, with gas leaving the tank along the shaft. This is generally undesirable.
    In the loading regime, the gas is well dispersed in the upper part of the vessel,
    above the impeller, but very little is present beneath it. In the completely dispersed
    regime, the gas bubbles are fully dispersed through the whole volume of the tank.
    The transition between the regimes is generally described using gas-flow maps.
    These maps are drawn using two dimensionless numbers[31]: the Froude impeller
    number (Fr), and the gas flow number (Flg). The Froude number expresses the ratio
    between inertia and gravity: (1) where N is the impeller speed, D is the impeller
    diameter, and g the gravity acceleration. The gas flow number (Flg) is the ratio
    between the radial velocity and the superficial velocity through the impeller
    swept region: (2) where is the volumetric gas flow rate. The choice of regime
    affects the fluid dynamics, the concentration and temperature fields, and the
    interfacial area distribution of the system, which in turn affects mass transfer
    and heat transfer.[13] Therefore, extensive attention has been given to identify
    different gas–liquid regimes and the transition between them.[33, 34] 2.1.1 Importance
    of material of vessel on the acoustic response Passive AE relies on the physics,
    which is controlled by the transient elastic waves within a material, caused by
    the rapid release of localized stress energy.[35] The prediction of the sound
    field radiated by a vibrating body is a problem shared by many theoreticians and
    practitioners in the field of engineering acoustics, including the designers of
    active sonar transducers, submarine hulls, car engines, and loudspeaker cabinets.
    Often, simulations provide clear insight into the underlying physical processes
    in complex systems and generate full field information, but they often only approximately
    describe the real-world time-evolution of the system.[36] Analytical estimates
    are largely limited to bodies of regular geometry that can be modelled as rigidly
    baffled flat plates or cylindrical shells. Generally, the investigated systems
    are limited to air or a static continuous environment due to little physical understanding
    of the non-linearities introduced by more complex systems. Non-linear effects
    within vibro-acoustic sensor measurements include time-domain signal distortions,
    generation of higher harmonics, frequency shifts, and signal modulations.[37]
    This often is translated in real measurements in the mechanical resonance and
    coincidence effects between the structural and acoustical modes, which are affected
    by the perturbations in the input impedance induced by the wall vibrations.[38]
    Therefore, in this work, the effects of different wall materials are investigated.
    2.2 Machine learning The high amount of data provided by industrial processes
    can generate an overload of information. In general, a significant part of the
    data set are not useful and some parameters are interdependent causing redundancy
    and correlation between them. Use of ML and multivariate analysis can help to
    overcome these challenges and hence fit well with the smart manufacturing/Industry
    4.0 trend.[39] ML algorithms can be categorized into three classes, namely, supervised
    learning, unsupervised learning, and reinforcement learning. Supervised and unsupervised
    learning both cover 80%–90% of the industrial applications, while reinforcement
    learning is not much used in these fields.[40] ML problems can be then divided
    into classification and regression problems. In this study, three supervised algorithms
    were tested on AE data, namely, support vector machine (SVM) with linear, quadratic,
    and cubic kernel; decision tree with fine splitting scheme; and k-nearest neighbour
    (k-NN) with cubic and weighted distance functions. Decision tree algorithms[41]
    classify the instances by parameter values using hierarchical, sequential, and
    binary classifications. Each node of the decision tree represents a feature of
    an instance (or observation) that needs to be classified. Each branch represents
    a value that the feature can assume, and the leaf represents the predicted value
    for the objective variable resulting from the path between the root node and the
    leaf node. The advantage of decision trees is their ease of reading and that the
    concept behind them is easy to grasp for the user.[42] Among decision tree algorithms,[41]
    the most used is the Iterative Dichotomizer 3 (ID3).[42] The main parameter of
    this algorithm is the maximum number of splits, which, in turn, controls the final
    depth of the tree.[43] Within this work, a fine tree with a maximum number of
    splits equal to 100 was considered. k-NN algorithms[44] classify the unlabelled
    instances looking at the classes of the labelled instances near them; the basic
    principle is that if a case is near to cases of a specific family, it will also
    be more likely that it belongs to them. The algorithm measures the sum of a distance
    function of the questioned case from the labelled examples points and finds the
    minimum. The main parameters used to describe the method are the number, K, of
    nearest neighbours that are considered to define the class of the instance and
    the method used to evaluate the distance between the instance analyzed and the
    labelled points. In this work, two distance functions are used for the analysis:
    cubic and weighted functions. SVM is a relatively recently emerged class of learning-by-example
    algorithms introduced in 1992 by Boser et al.,[45] and it is considered one of
    the most accurate and robust algorithms among the commonly used methods.[46] Given
    a dataset, SVM finds the best classification function that divides the instances
    into two classes. The ‘best’ function is identified as the hyperplane (which equation
    depends on the definition of the kernel function that characterizes the method)
    that has the most significant margin between the planes on which lie the closest
    points of the classes that must be separated. In the case of this work, three
    kernel functions were chosen: linear, quadratic, and cubic. The main advantages
    and disadvantages of the above-mentioned algorithms are discussed by Kotsiantis
    et al.[47] in terms of several features, which include accuracy of the model,
    speed of learning, tolerance, and other specific features that can favour one
    algorithm over the other. 3 MATERIALS AND METHODS 3.1 Stirred tank configuration
    Three geometrically identical vessels, made of glass, steel, and aluminium, were
    used. Despite steel being the most frequently used material for vessels in manufacturing
    lines, we decided to extend the proposed methodology to consider other materials
    that may be applicable to vessels used at smaller scales for research and innovation
    or product development. At the laboratory scale, glass is a common material, and
    if heat transfer is required, aluminium is employed as well. The vessel''s internal
    diameter, T, was 160 mm, filled to a volume of 5 L and equivalent to a liquid
    height of 240 mm (HL/T = 1.5). The vessels were equipped with four baffles with
    a width B equal to 12 mm (B/T = 0.1) and an L-shaped air sparger, located in the
    centre of the vessel. A Rushton disc turbine (RDT-6) with six blades and a diameter,
    D, of 56 mm (D/T = 0.35) with a blade width and height of 10 mm was used to agitate
    the fluid in each vessel. The geometric and material properties of the vessels
    are given in Table 1 with reference to the vessel schematic presented in Figure
    1. TABLE 1. Geometrical characteristics of the vessel and physical properties
    of the vessels. Property Glass Steel Aluminium Vessel internal height, H (m) 0.315
    0.315 0.315 Vessel internal diameter, T (m) 0.160 0.160 0.160 Baffles width, B
    (m) 0.012 0.012 0.012 Liquid height, HL (m) 0.240 0.240 0.240 Liquid volume, VL
    (L) 5 5 5 Sensor height, HSENSOR (m) 0.0800 0.0800 0.0800 Impeller clearance,
    C (m) 0.0800 0.0800 0.0800 Wall thickness (m) 0.0054 0.0041 0.0060 Density (kg m−3)
    2600 7670 2700 Acoustic impedance (105 kg m−2 s−1) 105–145 454–567 171 FIGURE
    1 Open in figure viewer PowerPoint (A) Schematic showing dimensions of the vessels
    and the sensor location and (B) picture of the experimental set up. The fluids
    used in the system were compressed air and water. A regime flow-map is shown in
    Figure 2 as a plot of Fr versus Flg,[48] with the flow regimes being classified
    upon the examination of short video frames taken using a high-speed Photron SA-3
    camera as used in Forte et al.[28] The flow regimes were considered independent
    of the vessel wall material. Five gas flow rates were tested (5, 10, 15, 20, and
    25 L/min, corresponding to 1, 2, 3, 4, and 5 vvm), and for each, three points
    in each regime were acquired, allowing coverage of 0.004 < Fr <1.586 and between
    0.028 < Flg <2.847. The impeller Reynolds number, , where ρ and μ are, respectively,
    the density and viscosity of the liquid, was investigated in the range of 2600 < Re < 52 200.
    FIGURE 2 Open in figure viewer PowerPoint Gas–liquid flow regime map for this
    study. Example images of the different flow regimes obtained at a constant gas
    flow rate of 15 L/min, as a function of impeller speed, are shown in Figure 3.
    FIGURE 3 Open in figure viewer PowerPoint Examples of high-speed camera footage
    of flow regimes detected as (A) flooding: Fr: 0.016 FL: 0.854, Q = 15 L/min, N
    = 100 rpm; (B) loading: Fr: 0.254 FL: 0.214, Q = 15 L/min, N = 400 rpm; and (C)
    complete dispersion: Fr: 1.284 FL: 0.095, Q = 15 L/min, N = 900 rpm. 3.2 Data
    acquisition Pressure fluctuations, generated by the interaction of the two-phase
    fluids, were detected at the vessel wall using a passive acoustic piezoelectric
    sensor (Vallen Systeme GmbH, Icking, Germany) with a resonance frequency of 375 kHz.
    The sensor was placed on the external wall at a height corresponding to the impeller
    region, equal to the off-bottom clearance C. The sensor was connected to a preamplifier
    (+40 dB gain, Vallen Systeme GmbH, Icking, Germany). The amplified signal was
    then decoupled from the noise introduced by the amplifier in the decoupling box
    DCPL2 + 28 … 30 Vdc- (Vallen Systeme GmbH, Icking, Germany). The amplified and
    decoupled signal was then recorded using an oscilloscope (PicoScope 5243b, Pico
    Technology Ltd., UK) connected to a laptop. A schematic of the acoustic data acquisition
    system is given in Figure 4. In Table 2, the parameters used to set the oscilloscope
    capture options are listed. FIGURE 4 Open in figure viewer PowerPoint Schematic
    of the aerated vessel experimental rig. AE, acoustic emission; RPM, revolutions
    per minute. TABLE 2. PicoScope six chosen parameters for the acoustic data acquisition.
    Setting Value Total collection time (s) 200 Number of samples (samples/buffer)
    1 500 000 Number of buffers 100 Sampling interval (s/buffer) 2 Sampling rate (samples/s)
    744 000 Number of samples (actual samples captured by the oscilloscope) (samples/buffer)
    1 488 095 Input range (V) ±1 3.3 Data pre-processing The overall structure of
    the data-processing work carried out in this research is reported in Figure 5.
    The first step follows the approach taken previously by Forte et al.,[2] which
    led us to select the ‘bench case algorithm’ for further data processing evaluation.
    FIGURE 5 Open in figure viewer PowerPoint Complete scheme of the acoustic emissions
    (AE) data pre-processing analysis and the training-optimization-test of the algorithms.
    KNN, k-nearest neighbour; PCA, principal component analysis; SVM, support vector
    machined. Specifically, the data were pre-processed, to reduce the dimensionality
    of the problem. The data were brought into the frequency domain using a Fourier
    transform,[1] and a high pass filter was applied to remove frequencies concerning
    external noise (below 4 kHz).[2] An example of AE data in the time domain and
    in the frequency domain for the same sample and the four regimes are given in
    Figure 6. FIGURE 6 Open in figure viewer PowerPoint Comparison of acoustic emissions
    (AE) data in the time domain (A) and in the frequency domain (B) for the same
    sample and the four regimes (from up to down side, from left to right side: flooding,
    loading, complete dispersion, and un-gassed). The complete frequency samples were
    then reduced to a limited number of frequency points with the highest relative
    variance (Equations (3-5)) to further reduce the dimensionality of the problem
    and speed up the training and implementation of ML algorithms.[2] (3) (4) (5)
    (6) (7) (8) where xij is the value of the intensity at a given frequency (‘j’)
    for the ‘i’ run, μ is the average intensity for the ‘j’ frequency, and N is the
    number of frequencies. The range of the points chosen was considered as a first
    optimization parameter and ranged between 1000 and 50 000 points. Feature scaling
    and mean normalization[2] (Equations (6-8)) have been applied to the dataset to
    make the amplitudes belonging to different frequencies comparable. Finally, the
    complete pre-processed dataset was divided in three sub-matrixes with a percentage
    division of the samples of 60–20–20, respectively, named training matrix, cross-validation
    matrix (used to optimize the parameters), and final test matrix. After these stages,
    the reduced set of data (glass only) is used for a training-optimization-validation
    cycle as described in the work by Forte et al.[2] for the evaluation of ‘bench
    case algorithm’ for the new vessel geometry. Then, for the second step, again
    the reduced set of data (glass only) are split in 60–20–20. A further reduction
    step is added to the ‘Training Data set’ and this is achieved using PCA.[49] Implementation
    of ML algorithms requires a high number of computational operations. At the same
    time, a high number of points may be a cause of bias in the implementation of
    the classification algorithms. Therefore, a standard component for the pre-processing
    phase is the features reduction. One widely applied method to reduce the dimensionality
    of the problem while keeping the information contained, based on the variance
    definition, is PCA. PCA consists of a reduction of the number of features representing
    the same amount of characteristics of the phenomenon to several new latent features.
    These are created by linearly combining the original features.[50, 51] The number
    of principal components taken during the analysis was considered a second optimization
    parameter. In Table 3, all the combinations of the two parameters used for the
    optimization phase are shown. TABLE 3. Matrix of tested input using the cross-validation/optimization
    dataset: Combination of number of frequencies and number of principal components
    (PC). PC Number of reduced scaled frequencies considered 5 50 000 30 000 10 000
    5000 4000 3000 2000 1000 10 50 000 30 000 10 000 5000 4000 3000 2000 1000 15 50 000
    30 000 10 000 5000 4000 3000 2000 1000 20 50 000 30 000 10 000 5000 4000 3000
    2000 1000 25 50 000 30 000 10 000 5000 4000 3000 2000 1000 30 50 000 30 000 10 000
    5000 4000 3000 2000 1000 This leads us to obtain a series of set of ‘new scaling
    features’ (number of PC and N° of reduced scaled frequencies, as presented in
    Table 3), which are evaluated based on training time and accuracy. Then, the best
    scaling feature is selected for the optimization step. The same ‘selected new
    scaling feature’ is then used for all three materials and used as input for the
    different algorithms to test their performance in terms of accuracy for the different
    materials. 3.4 Machine learning training, optimization, and test The algorithms
    used to solve the problem are of the supervised type,[47] so together with the
    acoustic data, the training algorithm was fed with a label identifying the corresponding
    gas–liquid regime for each observation. The labels used were as follows: (1) for
    the flooding regime, (2) for the loading regime, (3) for complete dispersion,
    and (4) for the un-gassed case. The Classification Learner application of MATLAB®
    was used to train the algorithms. The algorithms chosen for the training are those
    most used for supervised learning[47]: Decision Tree, SVMs, and k-NN. 4 RESULTS
    AND DISCUSSION Following the scheme summarized in Figure 5, the first step of
    the pre-processing analysis was approached similarly to the previous work by Forte
    et al.[2] While in the previous work,[2] a 3 L Perspex cylindrical tank was used,
    in this work, 5 L tanks were used, following the same strategy to test the performance
    of the different algorithms. The process of training and testing the ML algorithm
    is repeated 10 times, and for each repetition, the datasets included in the training
    and testing are randomly selected. This is done to avoid bias in evaluating the
    algorithm''s performance. The reported results are the average values obtained
    in the 10 repeated steps, showing similar trends as in the previous works.[2]
    The accuracy results, together with the F1-score,[52] which is a measure of a
    test''s accuracy in statistical analysis of binary classification, are shown in
    Tables 4 and 5. They show that better performance is obtained by the SVM algorithms,
    which are the primary parameter of comparison. If it is required to select the
    overall best among the two SVMs, the quadratic could be identified, given that
    it is a simpler algorithm and less computationally expensive than the cubic one
    and yet provides the same performance. Hence, the choice of the algorithm is a
    trade-off between its performance, the accuracy obtained on the cross-validation
    data set, and the training time needed.[2] TABLE 4. Accuracy of the machine learning
    algorithms for the different regimes in the gas–liquid case (performances have
    been evaluated following the scheme reported by Forte et al.[2]). Method accuracy(%)
    Regime Logistic regression Fine tree Medium tree Linear SVM Quadratic SVM Cubic
    SVM Fine KNN Medium KNN Coarse KNN Ungassed 87.5 85 85 80 100 100 100 80 100 Loading
    86.6 63.3 63.3 83.3 90 90 77.5 56.7 0 Complete dispersion 96.6 86.7 86.7 66.7
    90 90 76 80 0 Global 90 79 79 77 94 94 82 73 40 Abbreviations: KNN, k-nearest
    neighbour; SVM, support vector machine. TABLE 5. Weighted F1-score for the different
    algorithms in gas–solid–liquid regime prediction (the performances have been evaluated
    following the scheme reported by Forte et al.[2]). Regime Logistic regression
    Fine tree Medium tree Linear SVM Quadratic SVM Cubic SVM Fine KNN Medium KNN Coarse
    KNNa F1 score 0.918 0.843 0.843 0.801 0.940 0.940 0.834 0.717 - Abbreviations:
    KNN, k-nearest neighbour; SVM, support vector machined. a No value was calculated
    for the coarse KNN because of a null denominator. The SVMQUADRATIC was chosen
    as the algorithm to be used for the optimization phase due to its better performance
    dealing with the aerated system in question, as shown also by Forte et al.[2,
    51] The different volumes of the tanks did not change the sensitivity of the algorithms,
    as might be expected, making the SVMQUADRATIC again the top scorer. Once the algorithm
    was identified, a further reduction in frequency was employed, and the data set
    was re-trained using the PCA as the discriminant for the frequency selection (Figure
    5 shows the new scaling feature in the training data test). This improves the
    training time, reducing the required computational power to achieve full training.
    Thus, the approach of Forte et al.[2] was extended by feeding further reduced
    AE data in the frequency domain to ML algorithms to identify the gas–liquid mixing
    regime. The next step (Figure 5, the new scaling feature in the optimization data
    test), was to evaluate the performance for the different combinations of the spectrum
    parameters (listed in Table 3). The best combination was used for the final optimization
    phase. To evaluate the optimal data input volume reduction, an analysis of the
    accuracy of the cross-validation was carried out by plotting every combination
    of reduced frequencies and principal components. The other perspective used for
    the selection of the optimal conditions was to plot the training time versus every
    combination of reduced frequencies and principal components. Using these two representations,
    it was possible to select the optimum highlighted in the plots having the same
    X and Y coordinates. The selection was done by simply weighting accuracy and training
    time with the same intensity and identifying the best compromise between the two
    fluctuating parameters by calculating the minimum of both contributions. Plots
    obtained for the SVMQUADRATIC are shown in Figures 7 and 8, with the optimum point
    being 25 PCs and 5000 frequencies. FIGURE 7 Open in figure viewer PowerPoint Optimization
    plot: Accuracy on cross-validation dataset versus number of principal components
    (PC) used in the training versus number of frequencies used in the training. Glass
    vessel for the selected SVMQUADRATIC algorithm. PCA, principal component analysis.
    SVM, support vector machined. FIGURE 8 Open in figure viewer PowerPoint Optimization
    plot: Training time with training dataset versus number of principal components
    (PC) used in the training versus number of frequencies used in the training. Glass
    vessel for the selected SVMQUADRATIC algorithm. SVM, support vector machined.
    The complete data analysis outlined in Section 6 above was carried out for the
    glass-walled vessel. The optimization parameters found were then used for the
    two metal-walled vessels to demonstrate the transferability of the method. All
    of the algorithms were trained/tested using the optimal PCA input parameters (selected
    scaling features) and were then tested on a second, unseen set of data, namely,
    the test dataset (Figure 5). Table 6 gives a summary of the overall results, which
    are commonly displayed in the form of a confusion matrix or parity plot.[2] Generally,
    as expected from the previous analysis, SVM quadratic and cubic perform better
    among the other algorithms for all materials. The results indicate high repeatability
    and accuracy of the method in the cases of steel, aluminium, and glass, the latter
    giving the worst performance in classification (97% global accuracy, which is
    still a very good performance). TABLE 6. Evaluated accuracy on the test dataset
    for the chosen supervised machine learning algorithms using 5000 reduced frequencies
    and 25 principal components Algorithm AccuracyGLASS (%) AccuracyALUMINIUM (%)
    AccuracySTEEL(%) Decision tree 90.33 94.42 97.83 SVMLINEAR 93.00 98.42 99.67 SVMQUADRATIC
    97.08 99.08 99.67 SVMCUBIC 95.58 99.25 99.75 k-N-NWEIGTHED 87.00 94.00 95.50 k-N-NCUBIC
    86.83 92.92 95.00 Abbreviation: k-N-N, k-nearest neighbour. The other general
    trend is that steel vessels give better accuracy compared to aluminium and glass.
    This is not surprising because the impedance for steel is three times larger than
    for the other materials, allowing for better propagation within the vessel wall
    and hence better propagation to the sensor.[53] Another reason might reside in
    the fact that the vessels do not have the same wall thickness, in particular,
    the steel vessel is the thinnest of the three (Table 1). This has an impact on
    the transmission of sound, in particular, considering that the intensity of the
    pressure waves travelling in a material is proportional to the exponential of
    the negative product between the travelled distance and the attenuation factor.
    The last, however, is also dependent upon the frequency of the travelling wave.[54]
    SVM, as observed before,[2] outperformed the predictions of the other algorithms,
    while the worst results were obtained using the k-N-N methods. Moreover, the worst
    accuracy for all the models is generally obtained for the flooding case, while
    the accuracies of prediction for the rest of the regimes are similar for all the
    different algorithms. The better performance for the SVM methods can be explained
    by their higher tolerance of redundant or noise attributes (like points exceeding
    the decision boundaries) and, in general, with their better prediction accuracy
    in comparison to k-N-N and decision tree, which are generally easier to understand
    for the user but have the performance. In particular, k-N-N presented the worst
    performances on the flooding condition. The reason is that the flooding points
    in the space of principal components are sparser than in other regimes. Since
    k-N-N works on the distance between the test instances and the training points,
    if a flooding point is near a cluster of another regime, there will be more data
    belonging to the different regimes near it, and it will be addressed with that
    class, while for a separation boundary with a soft margin (SVM), it would have
    been still considered flooding. It is, therefore, important for data problems
    such as this one, where there is a high possibility of finding noise in the data
    or data in the transitional area between two regimes, to have a model that is
    not influenced too much by redundant or irrelevant features, such as SVM. Following
    these findings, the option of a single algorithm for all materials was tested;
    but as expected, there was a discrepancy in the prediction accuracy. Three options
    were investigated: the first selecting alternatively one of the three algorithms
    for the single material and then tested for the other remaining two as well. This
    led to a discrepancy in accuracy between the materials of the vessel and the chosen
    algorithm. Alternatively, for the second option, a single training-optimization-validation
    loop with all the data input from the three materials was used, and a drastic
    reduction in the performance of the prediction algorithm (70%) was achieved. This
    suggests that the acoustic impedance is a critical physical parameter that affects
    the raw signal acquired by the PA sensor, but there are also other physical parameters
    that affect the raw signal. For the third option, an extra step for the material
    selection, based on the reduced frequency used as input for the SVM algorithm,
    is added. This is done using a classification learner approach where the frequencies
    of each data set in the same working condition (same Froude number and gas flow
    number) for the different materials, are used as predictors. As shown in Figure
    9, the classification performance is very high given the difference among the
    selected frequencies for each material, mostly in terms of intensity for the given
    material. Thus, following this step, the single material is selected, and then
    the specific algorithm for the material is selected automatically. This ensured
    the performance would be maintained according to the previous findings for the
    single material. FIGURE 9 Open in figure viewer PowerPoint Confusion matrix for
    the classification of the material based on the frequencies selected for SVMQUADRATIC
    algorithm. SVM, support vector machined. Finally, this led us to conclude that,
    despite the need to retrain the algorithm for each possible material, the method
    developed is universal in terms of its applicability to systems of different volumes
    and construction materials. 5 CONCLUSIONS AE was used to identify regimes in aerated
    stirred tank coupled with supervised ML algorithms. The method, previously tested
    on a 3 L Perspex vessel,[2] has been tested on different vessel materials (glass,
    aluminium, and steel) and stirred using a Rushton six-blade turbine and aerated
    using a L-shape sparger. The classification problem was solved by comparing different
    ML algorithms. In all cases, the accuracy was >90%. Among the algorithms used,
    the SVMQUADRATIC achieved an accuracy between 97% and 99% for the three different
    materials. The different results obtained for the materials highlighted that the
    physical properties of the vessels play an important role in the transmission
    of acoustic data and, hence, in the separation of the frequency data in the feature
    space once a principal component decomposition is applied. From the application
    perspective, encouraging results are presented, showing that the most used material
    in manufacturing environments, stainless steel, performs better than the others,
    possibly due to the acoustic impedance and thinner thickness of the wall of the
    vessel, which enhance the ratio between noise to signal. The method proved to
    be successful with different materials and suitable in situations of abundance
    of data, where it is difficult for the user to differentiate between the different
    acoustic contributions of the phenomena due to their complexity. Moreover, it
    has been demonstrated that, through the selection of the best ML algorithm and
    the calibration of the parameters for the specific system, it is possible to obtain
    reliable predictions for different systems (regardless of the opacity of the system),
    with a verifiable accuracy on data not used for training, as demonstrated by Forte
    et al.[2] (gas–liquid and gas–liquid–solid systems) and confirmed by this work
    (gas–liquid system using different vessel materials). The coupling of PCA with
    the ML algorithm thus offers a way to reduce the computational time for the data
    processing by more than five times. Moreover, feeding less data means less CPU
    power is required. This is very promising for future applications. AUTHOR CONTRIBUTIONS
    Giuseppe Forte: Conceptualization; data curation; formal analysis; methodology;
    validation; visualization; writing – original draft. Matteo Antonelli: Investigation.
    Elisabetta Brunazzi: Methodology; supervision; validation; writing – original
    draft; writing – review and editing. Mark J. Simmons: Formal analysis; methodology;
    validation; writing – original draft. Hugh Stitt: Methodology; validation; visualization;
    writing – review and editing. Federico Alberini: Conceptualization; formal analysis;
    investigation; methodology; supervision; validation; visualization; writing –
    original draft; writing – review and editing. ACKNOWLEDGEMENTS Giuseppe Forte
    was an EngD student at the University of Birmingham, funded jointly by the Engineering
    & Physical Sciences Research Council (EPSRC) Centre for Doctoral Training in Formulation
    Engineering (EP/L015153/1) and Johnson Matthey. Matteo Antonelli was a MEng visiting
    student at the University of Birmingham from the University of Pisa, funded by
    an Erasmus + scholarship academic for the year 2018–2019. CONFLICT OF INTEREST
    On behalf of all authors, the corresponding author states that there are no conflicts
    of interest. Open Research REFERENCES Citing Literature Volume101, Issue10 October
    2023 Pages 5670-5682 Figures References Related Information Recommended Tracking
    Pyrometeors With Meteorological Radar Using Unsupervised Machine Learning N. F.
    McCarthy,  A. Guyot,  A. Protat,  A. J. Dowdy,  H. McGowan Geophysical Research
    Letters Gas‐Liquid Mixing in a Grid‐Disc Impeller Stirred Tank Fengling Yang,  Haiyao
    Sun,  Cuixun Zhang Chemical Engineering & Technology Flow regime identification
    in horizontal pneumatic conveying by nonintrusive acoustic emission detection
    Peng Zhang,  Sihang Tian,  Yao Yang,  Zhengliang Huang,  Jingyuan Sun,  Zuwei
    Liao,  Binbo Jiang,  Jingdai Wang,  Yongrong Yang,  Lei Xie,  Hongye Su AIChE
    Journal Water detection framework for industrial electric arc furnaces: Boundary
    modelling and formulation Hamzah Alshawarghi,  Farzad Hourfar,  Behzad Moshiri,  Ali
    Almansoori,  Ali Elkamel The Canadian Journal of Chemical Engineering Gas Flow
    A Users Guide to Vacuum Technology, [1] Download PDF Additional links ABOUT WILEY
    ONLINE LIBRARY Privacy Policy Terms of Use About Cookies Manage Cookies Accessibility
    Wiley Research DE&I Statement and Publishing Policies Developing World Access
    HELP & SUPPORT Contact Us Training and Support DMCA & Reporting Piracy OPPORTUNITIES
    Subscription Agents Advertisers & Corporate Partners CONNECT WITH WILEY The Wiley
    Network Wiley Press Room Copyright © 1999-2024 John Wiley & Sons, Inc or related
    companies. All rights reserved, including rights for text and data mining and
    training of artificial technologies or similar technologies."'
  inline_citation: '>'
  journal: Canadian Journal of Chemical Engineering
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Flow regime identification in aerated stirred vessel using passive acoustic
    emission and machine learning
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Selvaraj V.
  - Min S.
  citation_count: '6'
  description: Ability to detect faults in manufacturing machines have become crucial
    in the era of Smart Manufacturing to enable cost savings from erratic downtimes,
    in an effort towards Green Manufacturing. The power consumption data provides
    myriad of information that would facilitate condition monitoring of manufacturing
    machines. In this work, we retrofit an ultra-precision CNC machine using an inexpensive
    power meter. The data collected from the power meter were streamed in real-time
    to Amazon Web Services (AWS) servers using industry standard Message Query Telemetry
    Transport (MQTT) protocol. The error identification study was carried out in two-folds,
    we first identify if the error has occurred followed by classifying the type of
    controller error. The study also develops anomaly detection models to identify
    normal operating condition of the machine from the anomalous error states. Anomaly
    detection was particularly favorable for manufacturing machines as it requires
    data only from the normal operating conditions of the machine. The developed models
    performed with macro F1-Score of 0.9971 ± 0.0012 and 0.9974 ± 0.0018 for binary
    and multiclass classification respectively. The anomaly detection models were
    able to identify the anomalous data instances with an average accuracy of 95%.
    A feature importance study was then carried out to identify the most valuable
    feature for error identification. Finally, the trained models were containerized
    and hosted at AWS. The overarching goal of this project was to develop a complete
    inexpensive ML pipeline that would enable industries to detect operation anomalies
    in manufacturing machines just from the energy consumption data of the machine.
  doi: 10.1007/s40684-022-00497-x
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Log in Find a journal Publish
    with us Track your research Search Cart Home International Journal of Precision
    Engineering and Manufacturing-Green Technology Article Real-Time Fault Identification
    System for a Retrofitted Ultra-Precision CNC Machine from Equipment''s Power Consumption
    Data: A Case Study of an Implementation Regular Paper Published: 26 January 2023
    Volume 10, pages 925–941, (2023) Cite this article Download PDF Access provided
    by University of Nebraska-Lincoln International Journal of Precision Engineering
    and Manufacturing-Green Technology Aims and scope Submit manuscript Vignesh Selvaraj
    & Sangkee Min   592 Accesses 7 Citations 1 Altmetric Explore all metrics Abstract
    Ability to detect faults in manufacturing machines have become crucial in the
    era of Smart Manufacturing to enable cost savings from erratic downtimes, in an
    effort towards Green Manufacturing. The power consumption data provides myriad
    of information that would facilitate condition monitoring of manufacturing machines.
    In this work, we retrofit an ultra-precision CNC machine using an inexpensive
    power meter. The data collected from the power meter were streamed in real-time
    to Amazon Web Services (AWS) servers using industry standard Message Query Telemetry
    Transport (MQTT) protocol. The error identification study was carried out in two-folds,
    we first identify if the error has occurred followed by classifying the type of
    controller error. The study also develops anomaly detection models to identify
    normal operating condition of the machine from the anomalous error states. Anomaly
    detection was particularly favorable for manufacturing machines as it requires
    data only from the normal operating conditions of the machine. The developed models
    performed with macro F1-Score of 0.9971 ± 0.0012 and 0.9974 ± 0.0018 for binary
    and multiclass classification respectively. The anomaly detection models were
    able to identify the anomalous data instances with an average accuracy of 95%.
    A feature importance study was then carried out to identify the most valuable
    feature for error identification. Finally, the trained models were containerized
    and hosted at AWS. The overarching goal of this project was to develop a complete
    inexpensive ML pipeline that would enable industries to detect operation anomalies
    in manufacturing machines just from the energy consumption data of the machine.
    Similar content being viewed by others Machine learning-based techniques for fault
    diagnosis in the semiconductor manufacturing process: a comparative study Article
    06 August 2022 Goals and measures for analyzing power consumption data in manufacturing
    enterprises Article Open access 25 March 2021 Monitoring Electrical and Operational
    Parameters of a Stamping Machine for Failure Prediction Chapter © 2022 1 Introduction
    In the era of Industry 4.0 or Smart Manufacturing, detecting faults in manufacturing
    machines is becoming crucial to enable automation and support the increasing production
    demands. Currently, with the advancement in technologies like Industrial Wireless
    Sensor Networks (IWSNs), Artificial Intelligence (AI), Cloud Computing, Cyber
    Physical Systems (CPS) etc., it is becoming possible to develop reliable systems
    that could detect and provide inferences in real-time, and at the same time be
    able to continuously monitor itself to realize when the inferences made were unreliable.
    In the field of Smart Manufacturing, developing models to detect and identify
    faults/defects is important, but it is also equally important to develop tools,
    techniques, architectures, and pipelines that can be used to implement the developed
    models and reliably track them over time. As there is no better way to test the
    robustness of the model than by implementing them in a real industrial scenario.
    Energy consumption monitoring of the Computer Numerical Control (CNC) machine
    tools has been a topic of interest and several studies were conducted to better
    understand the patterns embedded in the energy/power consumption data to either
    develop energy saving strategies or to better understand the manufacturing processes
    [1,2,3]. In [4], an online approach for energy monitoring of the machine tools
    was discussed by developing an architecture for DAQ (Data Acquisition). The work
    categorizes the overall energy consumed by the equipment into constant energy
    and variable energy, followed by identifying the state of the machine by observing
    the power consumption profile for a single cutting operation. Real-time monitoring
    of the energy consumption has been an element of importance for the research community.
    In [5], an event stream processing technique was introduced to automate the energy
    consumption monitoring of the vast number of manufacturing machines. The work
    also describes the importance of energy consumption monitoring, particularly focusing
    on reducing the energy usage, reducing disruptions in operations, ability to track
    the maintenance state of the machines, and finally the ability to detect the impact
    on the environment. Hence, monitoring the energy consumed by the machine in real-time
    could provide valuable insights into the condition of the machine thereby enabling
    us to identify operation anomalies, preventing unforeseen equipment failures.
    Fault detection and/or anomaly detection of manufacturing machines is a subtopic
    within smart manufacturing that is teeming with research. The ability to detect
    defects becomes crucial as it enables manufacturers to better track their equipment’s
    life and improve product quality [6,7,8,9,10]. In a typical manufacturing facility,
    major proportion of the machines used does not have the ability to be connected
    to the cloud, neither do they have the means to collect data about their operation
    pre-built. Several studies explored the possibility of resolving this issue, in
    [11], a NVX 5080 vertical machining center was retrofitted with a slew of sensors
    to collect data on the machine’s operation in real-time. Using the retrofitted
    sensors, the authors were able to monitor the state of the machine, detect chatter,
    and predict the coolant level. In [12], which is the derivative of the work mentioned
    above, signals from the various sensors like acceleration, temperature, digital
    I/O were used to improve the maintenance operation of the machines. Even though
    power sensors were used in this study, it was not applied towards the anomaly
    detection of machines but rather used to identify strategies to reduce the power
    consumed by the machine. On contrast to retrofitting the machine with sensors,
    certain CNC controllers can relay the information regarding its operation using
    the protocols like MTConnect, OPC UA, etc. In [13], developed a Cyber Physical
    System using the above mentioned protocols to create Digital Twins of the machines
    in a manufacturing facility. In [14], utilized the OPC UA client to collect information
    on the machine’s different operation parameters to predict the power consumption
    of the machine using a data-driven model. When interfacing with the machine controllers
    for developing data driven model for anomaly detection, there are two challenges
    that needs to be addressed. Firstly, reliable communication with the machine’s
    controller without any loss in data packets is not always guaranteed, and secondly,
    not all the machines in a manufacturing facility would have a digital controller
    or the means to interface with one. In [15, 16], a systematic review of the applications
    of deep learning models on the machine health monitoring were discussed. With
    the increase in the data size, due to the abundance of sensors used to collect
    data on machines, deep learning (DL) and machine learning (ML) tools have enabled
    easier and effective processing of the data. In [17], a stethoscope sensor unit
    was developed and attached to the joints of a 6-axis industrial robot. The data
    gathered form the sensors were used to train a Convolutional Neural Network (CNN)
    model to detect collisions. Similarly, in [18], the acoustic signals acquired
    using a microphone were used to determine the operating status of multitude of
    machines in a shop floor. Bearing fault diagnosis is another application for using
    deep learning to detect faults from retrofitted sensor data, particularly acceleration
    sensors. In [15], a comprehensive survey was conducted on various deep learning
    algorithms used towards bearing fault diagnosis. The industrial environment with
    complex and noisy working condition hinders the construction of physical models,
    making the modelling of complex dynamic systems very difficult [15]. The physics-based
    models are also unable to be updated in real-time with the data from the sensors
    installed on machines, thereby limiting their effectiveness and flexibility. To
    extract information from the sensor data and to provide meaningful inference with
    limited domain knowledge, machine learning and deep learning have become important
    in the era of Industry 4.0. The reasoning behind why this research work was conducted
    is as follows: First, as we are currently at the edge of this transition, it is
    highly unlikely that the sensors required are already present in the OEMs. Second,
    retrofitting of the manufacturing machines can quickly become expensive and invasive,
    considering a plethora of sensors that needs to be installed on the machine to
    make reliable inference. Third, majority of the work presented above showcase
    a model development process that works very well in a controlled scenario. The
    deployment scenario with various challenges associated with the input distribution
    drift, sensor perturbations etc., were not discussed. Fourth, there is no baseline
    that was previously developed that discusses the complete model development cycle.
    In addition, none of works presented above and to the extent of our knowledge
    have open-sourced the code in a plug-and-play fashion to either replicate our
    work or improve it. Fifth, our work was conducted on ultraprecision machines where
    the material removal rate is very low. Hence, visually identifying and trimming
    the patterns from the power consumption data is challenging. Sixth, it is not
    easy to detect and classify the anomalies in real-time from the energy data and
    publish the interface online for the public to interact. To achieve the above-mentioned
    objectives, we have implemented an anomaly detection system along with the ability
    to identify the type of defect using the equipment’s power consumption data. The
    work describes the complete process from retrofitting the machine, designing the
    data pipeline, model selection and identification, model training, model evaluation,
    model deployment and finally model tracking and updates. The paper is structured
    as follows: In Sect. 2, a brief background on the various data communication protocols
    and model architectures are provided. In Sect. 3, the objectives and the problem
    description are discussed. In Sect. 4, the methodologies behind the anomaly detection
    process, and power consumption of the machine as an indicator of anomaly are discussed.
    In Sect. 5, the implementation scenario conducted at an ultra-precision CNC machine
    is discussed. In Sect. 6, the results and inference from the implementation scenario
    and the data analysis are discussed. Finally, in Sect. 7, conclusion and the future
    work of this project is discussed. To enable people to replicate and modify our
    work the complete code database, along with the preliminary training data, is
    published at https://github.com/vigneshuw/machine_fault_identification.git. The
    equipment is monitored in real-time and different input power parameters are continuously
    logged. A link has been provided where anyone can download the data for different
    points in time of the machine’s operation. 2 Background In this section we briefly
    describe the various techniques used to deploy the real-time Data Acquisition
    (DAQ) and inference system. We start by discussing the various communication protocols
    used in the data transfer process, followed by the data storage-retrieval mechanisms.
    We then discuss the different models that were used to detect and identify the
    machine fault states using both unsupervised and supervised learning techniques.
    2.1 Modbus Modbus is a serial communication protocol that has been commonly used
    by industrial electronic devices. The protocol features communication to and from
    multiple devices and are used in acquiring data from multiple devices using a
    single master Fig. 1. The Modbus RTU primarily uses RS-232 or RS-485 serial interfaces
    for communication. Majority of the commercially available DAQ devices and software
    support the protocol, hence the reason behind using this protocol to retrofit
    our machine. Fig. 1 Modbus-RTU in Master–Slave configuration Full size image 2.2
    MQTT (Message Query Telemetry Transport) MQTT [19] is a lightweight messaging
    protocol for the Internet of Things (IoT) devices, particularly for WSNs (Wireless
    Sensor Networks). It follows a publish/subscribe model to transmit data between
    the MQTT broker and clients. In our case, the MQTT broker corresponds to the AWS
    (Amazon Web Services), and the clients were the retrofitted sensors. This protocol
    supports bi-directional communication and is scalable to millions of IoT devices,
    Fig. 2. The reliability of the communication is maintained through quality-of-service
    levels to ensure that the data are not lost due to interruption in the communication.
    Fig. 2 MQTT publish/subscribe model for bi-directional data communication Full
    size image 2.3 Supervised Learning The classification learning is sometimes called
    the Supervised learning. The training data were provided with appropriate labels
    and the model learns to categorize them. In this study, the models considered
    were Decision Trees (DT), Ensemble classifiers – Bagging classifier and Random
    Forest classifier (RT), k-Nearest Neighbor (k-NN) classifier, and Support Vector
    Machines (SVM). 2.3.1 Decision Trees (DT) Decision trees [20] are one of the most
    widely used and practical method for inductive inference. A typical learned decision
    tree can be re-represented as sets of if–then rules which enables human readability.
    At each node, the DT algorithm measures the information gain to determine the
    best attribute that separates the training data. In the field of smart manufacturing,
    decision trees have been widely used for fault detection/fault identification,
    quality control, etc. Some of the key advantages of decision trees are that they
    are simple and easy to interpret, ability to handle both numerical and categorical
    data, and cost of prediction is logarithmic in the number of data points used
    to train the tree. The key disadvantage of using a decision tree is their tendency
    to overfit the data – it is possible to add branches to the tree that improves
    its performance on the training data while sacrificing its performance on instances
    outside the training set. 2.3.2 k-Nearest Neighbor (k-NN) In contrast to learning
    methods that requires an explicit description of the target function when the
    training data were provided, instance-based learning methods like k-NN simply
    store the entire training data. Each time a new data instance is provided, its
    relationship with the previously stored examples is examined before assigning
    the new instance to a class. The instance-based methods were referred to as “lazy”
    learning because there is no training involved and the computation is done during
    the prediction time. The key disadvantage of this method is that for higher dimensional
    data the method becomes less effective due to the “curse of dimensionality” [21].
    2.3.3 Support Vector Machines (SVM) The support vector machines are a supervised
    learning method, used in classification and regression. SVC can be used for binary
    classification and multiclass classification. In the case of multiclass classification,
    the “one-versus-one” approach is implemented which is extended to “one-versus-rest”.
    To implement SVM for this study, libsvm package [22] was used. The key advantages
    of SVMs are effective in high dimensional spaces, memory efficient, and versatile
    with the choices on different kernels. Hence in this study, SVMs were chosen as
    one of models for defect identification. 2.3.4 Ensemble Classifiers Typical machine
    learning involves an iterative process flow where different models were fitted
    onto the dataset until we identify the one that performs the best. This process
    may involve a lot of trial and error to identify a single model for our use case
    scenario. A complementary approach is training multiple different models and combining
    the results at the end. This model is called the ensemble model and the process
    is called the ensemble learning. The hope is that the ensemble model is more robust
    than the individual. In an industrial implementation scenario going through the
    process of finding the right model may be time consuming in some application.
    Hence, to expeditiously develop and implement machine learning models, ensemble
    learning was used in this study. Furthermore, from our study it was found that
    the ensemble model was the most robust when it comes to perturbations to input
    features, see Sect. 6.3. The two types of ensemble learning used in this study
    were Bagging ensemble [23] and its extension Random forests [24]. 2.4 Unsupervised
    Learning Unsupervised learning process involves learning the patterns from the
    data without the presence of any labels indicating either the number of classes
    present in the dataset or the class association of the data points. In the case
    of fault detection, unsupervised learning is beneficial as it eliminates the need
    to generate data corresponding to the defective instances, saving time and money.
    In this work, we are interested in identifying if the defect has occurred. Hence,
    with regards to unsupervised learning, our case primarily involves in identifying
    anomalies. Three different approaches were developed to identify the anomalies
    in the data gathered from the sensors, two of three involves estimating the distribution
    of the good scenario and using that to identify the anomalies, and the last one
    is a model-based anomaly detector. 2.4.1 Density Estimation Two approaches were
    followed to estimate the density of the good scenario in this study. In a typical
    manufacturing industry obtaining data from the good scenario should not be challenging
    as a machine is expected to operate normally for a major portion of its lifetime.
    The first approach involves estimating the distribution by simply computing the
    mean and covariance of the data corresponding to the good scenario. From the estimated
    distribution, Mahalanobis distance distribution was then determined by computing
    the distance of each good instance from its mean. The threshold was set at 3σ
    from the center of Mahalanobis distance distribution to classify the data instances
    appropriately. The second approach involves estimating the distribution of data
    instances corresponding to the good class directly by fitting kernel of choice.
    In this approach, the density of the data is estimated directly, invalidating
    the requirement to have any distance metric to detect anomalies. The anomalies
    are detected by computing the probability that the new data instance is from the
    distribution corresponding to the normal operation of the machine. A threshold
    was set on the probability to levels to identify anomalies. 2.4.2 Isolation Forest
    The third approach is model based, meaning that the anomalies were detected without
    profiling the normal instances. The model works by fitting multiple classification
    trees onto the dataset, the anomalies are identified by measuring the tree path
    lengths required to isolate each data point. The concept behind this approach
    is that the anomalies are far away from the normal instances, hence can be isolated
    with shortest path lengths. The one caveat behind this approach is that the anomalies
    need to be present in the dataset used for training, and they should be a minority
    [25], else there will be a case of overfitting. 3 Problem Description In the case
    of ultra-precision manufacturing detecting anomalies is particularly important.
    At the current level, a typical ultra-precision manufacturing operation requires
    long operation hours, hence, any anomalies in its operation might typically go
    unnoticed leading to a poor product quality. Also, due to the long processing
    hours requirements, the equipment availability loss increases reducing the throughput
    of the manufacturing facility. Even though we are at the threshold of fourth industrial
    revolution, majority of the manufacturing machines in manufacturing industries
    are legacy machines. Retrofitting legacy machines are a common practice in the
    field of smart manufacturing to enable connectivity and DAQ, and several research
    work have been conducted regarding the same [26]. Reliable detection of anomalies
    requires acquiring data continuously from the machine, typically, the data were
    then analyzed by the people with sufficient domain knowledge to identify anomalies.
    However, this process could easily become challenging when number of data sources
    increases or when there is a real-time requirement. In majority of the cases,
    generating data for each of the defective categories is challenging. It requires
    us to synthetically generate defects on a machine which is otherwise operating
    effectively. The key challenges in the field of fault detection of manufacturing
    machines are as follows [10, 27,28,29]: Imbalance in the data distribution between
    the normal and anomalous cases Inability to differentiate between noise and anomalous
    instances Drifts in the data distribution of the input signals over a period Variations
    associated with the DAQ devices, sensors, etc., leading to an inability in transferring
    models across machines without re-training or transfer learning Requirement to
    monitor the model performance continuously to identify when they go out of specifications
    In this work we aim to identify the operation anomalies in an ultra-precision
    CNC machine by retrofitting it. Controlled experiments were conducted to gather
    data corresponding to different error states of the machine. Traditional machine
    learning algorithms were then used to classify the error states of the machine.
    The developed models were rigorously tested across combination of equipment operating
    states and working components. The methodologies developed from this work considers
    the possibility of implementing an anomaly detection system in real manufacturing
    industries. In a typical industry, generating data for each of the defect classes
    are time consuming and, in some cases, it is practically impossible, as we cannot
    possibly determine all possible states that machine could be in. Hence, anomaly
    detection study was also considered for the same problem. The anomaly detection
    models were tested against the known anomalies and unknown anomalies to test their
    generalization ability. All the developed models were also compared among each
    other using several metrics to identify the best performing ones. Finally, the
    developed models were deployed online using AWS servers to make detection and
    identification in real-time. To summarize, through this study we aim to understand
    the following: Firstly, we aim to see if the anomalous states that were common
    for the equipment under study can be identified from its power consumption. Even
    though the overtravel state of the machine has a specific pattern, they were indiscernible
    between the axis of the machine. Secondly, we aim to provide a complete pipeline
    of retro fitment of legacy machines from model development to model deployment
    and monitoring, which we found to be missing from literature. Finally, to accurately
    model the energy consumption of the machine and eventually predict the energy
    consumed, it is required to better understand machine design and the components
    in play, which might be not readily available, or it could be confidential, like
    our case. Through our preliminary work, we realized that the state of the equipment,
    like the axis in motion, feed rate, and operating components can be inferred from
    the equipment’s energy consumption data [30]. We believe that through our work
    by better understanding the equipment states we can fill in up gaps to accurately
    develop energy models for equipment. Additionally, through the feature importance
    study we aim to identify the power consumption features that were most important
    when it comes to energy consumption monitoring. 4 Methodology In this section
    we aim to articulate the framework behind the real-time inference system. The
    framework, as shown in Fig. 3, involves the development, deployment, and monitoring
    of the fault detection system. Furthermore, we discuss the reasoning behind using
    the input energy consumption as an indicator of anomaly detection in manufacturing
    machines. Fig. 3 Framework for the fault detection system based on the equipment
    power consumption Full size image 4.1 Framework The framework is provided to guide
    other practitioners who are interested in using energy as one of the means to
    detect anomalies in the equipment’s operation. The framework consists of three
    major segments – model training, model deployment, and model monitoring. 4.1.1
    Retrofitting Legacy Machines The first step towards implementing a fault detection
    system on a legacy machine is to retrofit them with sensors that are conducive
    to identifying the operation patterns of the machine. In our case, the sensors
    used were power and energy meters – WattNode Wide-Range Modbus from Continental
    Control Systems, LLC. These sensors were compact and inexpensive and can potentially
    enable widespread deployment of the system in a manufacturing facility. The retrofitted
    sensors communicate over RS-485 half-duplex using the Modbus RTU protocol. The
    sensor data was processed by an edge device that which correlates the sensor data
    with the machine ID based on the slave addresses on the Modbus line. The processed
    data was then packaged and sent to a NoSQL (Not Only Structured Query Language)
    low latency database located in the cloud. The low latency is particularly importance
    considering the real-time requirement for the inference and monitoring. The data
    was transmitted wirelessly using the MQTT protocol on multiple topics for visualization,
    storage, and processing. 4.1.2 Model Training Once retrofitted and deployed, data
    collection process occurs continuously and were timestamped for future use. In
    addition to the real-time data collection, the machine states at any point in
    time was also continuously monitored. During the model training process, the required
    sensor data were queried from the database and correlated with the data from the
    machine’s controller. This process helped in identifying the state of the machine.
    The sensor data further undergoes processing to augment the features of interest
    corresponding to the classification task in hand. After data labelling and pre-processing,
    machine learning models were trained to classify and cluster the different error
    states of the machine. The model training in this study typically involves hyper-parameter
    optimization followed by tenfold Cross-Validation (CV) on the best performing
    hyper-parameters. The best performing models were chosen based on the F1-Score,
    ROC (Receiver Operating Curve), and AUC (Area Under Curve). 4.1.3 Model Deployment
    The models developed in this study were not computationally intensive, hence,
    they could be potentially deployed at the edge or at the cloud. During the inference
    phase, the data were periodically queried from the database and sent to the model
    for prediction. To reduce False Positive Rate (FPR), for a single segment of data
    for prediction, multiple overlapping predictions were made, and a majority voting
    was taken for the whole segment to decide on a prediction. Several studies have
    explored the benefits of different model architecture in different scenarios/application
    [10]; hence, this framework was developed to allow ensemble of separately trained
    models to make inferences without any dependence on each other. A majority voting
    system can then be followed to arrive at a single inference. Machine learning
    and Deep learning are almost always a lifelong learning process [31]. Monitoring
    the performance of the deployed models is an active field of research and several
    studies are being conducted to determine when the model’s inference was not reliable.
    Luckily, in our case, we can interact with the machine’s controller, the model’s
    performance evaluation is complemented by the information extracted from the controller.
    Furthermore, the equipment’s operator can continuously perform corrective actions
    during erroneous inferences creating a loss-gain scenario. This process will be
    integrated as a reinforcement learning scenario where there are rewards for correct
    inferences and penalties for incorrect inferences. Through this process the weights
    of the trained models will be updated over time leading to a reduction in FPR
    and improvement in model’s robustness over time. The framework for the model development
    can be seen in Fig. 3. 4.2 Relation Between Power Consumption and Machine Error
    States The power meters were attached to the 3-phase input of the equipment to
    ensure reliable monitoring of the power consumed by different components of the
    machine. Cutting process accounts for only about 15% of total energy consumed
    by the machine, which varies depending on machining scenarios. The components
    external to cutting consumes the most energy [5]. Hence, it is vital to go beyond
    the tool-chip interface for monitoring the condition of the machine using the
    power consumption data. The power consumed by the machine can be broadly classified
    into three categories: (1) Power consumed by the accessories, (2) Power consumed
    by the motors controlling the axes and spindle, and finally (3) Power consumed
    when cutting, which is highly dependent on the cutting parameters, and material
    types. Several works have tried to characterize the equipment solely based on
    the energy consumption data [1]. Real-time data collection and visualization from
    our setup provides an insight into the equipment’s operation, as can be seen in
    Fig. 4. Without the application of any sophisticated algorithms, it was possible
    to determine equipment’s state with reasonable accuracy. To determine the impact
    that the operation anomalies have on the power consumption data, errors were induced
    on the otherwise normally operating equipment. As can be seen from the Fig. 4b,
    the power consumption data generates a distinct pattern. This pattern varies between
    different error or anomalous instances and the axis impacted. On contrasting with
    the normal operating condition of the equipment, Fig. 4a, the pattern was very
    distinctive. Different components of the equipment have distinct power consumption
    pattern, by isolating the components individually we can observe their power consumption
    as well, Fig. 4c, thereby determining the state of the equipment. In Fig. 4d,
    the patterns are from scribing a 20 mm × 20 mm aluminum block with a depth-of-cut
    of 0.014 mm and feedrate of 60 mm/min. The spike in the plot corresponds to the
    acceleration and deceleration of the axis involved in the scribing operation,
    in this case the Z-axis of the equipment. As can be inferred, the patterns in
    the power consumption of a machine tool have valuable information that are readily
    available and provide a slew of information on the equipment’s condition when
    used appropriately. This task can quickly become insurmountable when considering
    the different operating states of the machine, different cutting operations, tool-workpiece
    interactions feedrates, etc. Fig. 4 Visualizing the active power consumption pattern
    for different equipment states Full size image 5 Engineering Application In this
    section we aim to apply the methodologies discussed to evaluate the ability to
    detect the anomalies in the operation of an Ultra-precision CNC machine: FANUC
    ROBONANO-α0iB. The objectives of this section are as follows: 1. Retrofit a legacy
    machine to obtain the power consumption data in real-time 2. Develop models to
    extract patterns of interest to enable us in identifying the machine error states
    in real-time 3. Develop and deploy a machine learning pipeline, from model development
    to deployment and monitoring. 5.1 DAQ by Retrofitting The equipment involved in
    this study is a 5-axis Ultra-precision CNC machine tool from FANUC. The machine
    has three linear axes, X, Y, and Z, and two rotary axes, B, and C. The specifications
    of the equipment can be seen in Table 1. The power meter that was attached to
    this equipment is a WattNode Wide-Range Modbus from Continental Control Systems.
    The power meter can update data at a rate of 10 Hz and can communicate over RS485
    using Modbus protocol. The power meter was attached to the input of the machine,
    using 3P3W (3 Phase 3 Wire) configuration. The DAQ software was custom written
    and can be found in the GitHub link associated with this work. Totally 32 input
    power and energy parameters were obtained from the 3-phase input of the machine
    and were packaged into JSON (JavaScript Object Notation) for transmission. The
    retrofitted setup can be seen in Fig. 5. The data update rate was set at 1 s but
    can be programmatically reduced to 0.1 s. Table 1 Specifications of the ultra-precision
    CNC machine Full size table Fig. 5 Retrofitting the CNC machine with energy meters
    Full size image The edge device validates and timestamps the sampled data and
    then sends it to a remote NoSQL databased through MQTT protocol. The rules engine
    was implemented at the AWS servers to further process the data. The database used
    was DynamoDB and the MQTT broker used in our case was the AWS IoT Core. The process
    involved in the data acquisition is shown in Fig. 6. The dataset for this study
    was created by synthetically generating anomalies on the machine tool and from
    real production processes. This was feasible because the power consumption data
    was continuously collected from the machine irrespective of its state, which was
    then cleaned and categorized appropriately. Fig. 6 The data acquisition and storage
    process Full size image 5.2 Model Development Once the machine has been retrofitted
    with appropriate sensors, and the process flow has been defined for data storage
    and retrieval, the data collection process happens continuously and in real-time.
    The next challenge was to correlate the data collected from the sensors to the
    events and anomalies associated with the sensor. In this work, the correlation
    was done manually by controlled experiments. The different states of the machines
    were observed and tagged on the database, the equipment was manually pushed to
    anomalous states / error states and the appropriate energy consumption patterns
    were also tagged at the database. The process flow involved in the model development
    can be seen in Fig. 7. The model development process can be categorized into three
    major categories (1) Data preprocessing, (2) Model training, and (3) Model development
    and monitoring. Fig. 7 Supervised and Unsupervised model development flowchart
    Full size image 5.2.1 Data Preprocessing In this section, the input data to the
    model was processed to augment the training process. The first step involved labelling
    the data that was collected continuously and stored at a NoSQL database. As far
    as this study is concerned, the labelling process was done manually by associating
    the machine controller information and controlled experiments. The labelling process
    involves assigning classes to different time intervals. The power meter catalogs
    32 different input energy parameters, based on our preliminary study, 9 of them
    were selected for this study. The input energy parameters chosen were, Active
    Power, Reactive Power, and Apparent Power for the 3-phase input of the machine.
    The time series data was then segmented using windows of size 15 s, 30 s, 60 s,
    and 120 s, with an overlap rate of 60%. The choice on the window size was determined
    later, see Sect. 6.2. After segmentation, the features were extracted from the
    chosen 9 input parameters. The features that were extracted can be seen in Table
    2. Totally, 153 features, encompassing time domain, frequency domain, and time–frequency
    domain, were extracted from each segment. If required, the dimension reduction
    techniques were applied to improve computational efficiency. The data were then
    standardized to a standard normal distribution to complement the model training
    process, as the variations in magnitude between the features were high. Table
    2 Features extracted from the data Full size table Before model development, the
    data was visualized to better understand the relationship between the classes
    in an unsupervised manner. To visualize the data in two dimensions, the 153-dimensional
    features were reduced to 50 using PCA (Principal Component Analysis), followed
    by t-SNE (t-distributed Stochastic Neighbor Embedding) to 2-dimensions. The machine
    states considered in the visualization process: normal, machine not referenced,
    overtravel in X, Y, and Z. From the t-SNE plot, Fig. 8, the “normal” state, the
    “not-referenced” state, and combined “overtravel” state clusters were clearly
    separated from each other. On the other hand, the clusters corresponding to overtravel
    in X, Y, and Z were overlapping, indicating the prospective issues the model might
    face when generalizing with regards to these classes. The “machine not referenced”
    state in this work corresponds to the machine’s state after a power cycle, where
    a referencing operation is required before beginning operations on the machine.
    In ultra-precision machine used in this study, it was challenging to identify
    and classify this state of the machine. Through our preliminary work [30], it
    was ensured that the change in power consumption during the “overtravel” and “machine
    not referenced” states was correlated with the machine''s state and not the sensor’s
    state. The overtravel of the axes in general leads to an increase in the power
    consumption because of them being in the extreme ends of the axis travel. The
    difference in overtravel energy consumption between the five axes of the machine
    was dependent on the machine design and was indiscernible visually from the energy
    profiles. Since the “overtravel” and “machine not referenced” states were determined
    not to be a part of the sensor artifact, the impact of different sensors in different
    machines on the model development process can be safely ignored. Fig. 8 t-SNE
    visualization of the model’s input data Full size image 5.2.2 Model Training The
    model training process was categorized into supervised and unsupervised learning
    depending on the application domain. In the case of fault detection models, unsupervised
    learning prevents the generation of data for the defects, thereby simplifying
    the implementation process. 5.2.2.1 Supervised Model Development Before the start
    of the training process the hyperparameters of the models were optimized using
    an exhaustive grid search. Once the best performing hyperparameters were identified,
    the models were trained using a tenfold Cross Validation (CV). The six models
    that were developed from this process were then evaluated based on their performance
    on the testing data, and robustness in field, see Sect. 6.1, and the evaluation
    metrics can be seen in Table 3. 5.2.2.2 Unsupervised Model Development Unsupervised
    anomaly detection was conducted using two approaches: density estimation by profiling
    the normal instances, and model based. In the density-estimation based approach,
    the normal instances corresponding to the good operation condition of the machine
    were used to estimate the distribution of the data corresponding to the good state
    of the machine. Two methods were used to estimation the distribution of the normal
    instances: (a) Mahalanobis distance-based approach, and (b) Kernel density estimation.
    The input power consumption corresponding to the normal operating condition of
    the machine, particularly when the machine was on idle, i.e., not preforming any
    manufacturing operation, was assumed to closely resemble a normal distribution.
    Hence in the case of the Mahalanobis distance-based anomaly detection, Eq. (1),
    the distribution corresponding to the “normal” instances was determined by computing
    the mean and the covariance of the respective data. The covariance helps in understanding
    the dependence between the 153-dimensional features. As the dimensions increase,
    due to the “curse of dimensionality” it will get challenging to train, and/or
    make robust inferences, hence, the dimensions of the data were reduced using dimension
    reduction techniques. For a new data point, the Mahalanobis distance determines
    the distance of the data point from the center of the distribution. The Mahalanobis
    distance threshold to identify an anomaly was set at 3σ level of the distribution,
    ensuring a theoretical TPR of 99.7%. $${D}_{M}\\left(x\\right)=\\sqrt{{\\left(\\overline{x
    }-\\overline{\\mu }\\right)}^{T}{\\Sigma }^{-1}\\left(\\overline{x }-\\overline{\\mu
    }\\right)}$$ (1) where \\(x=({x}_{1}, {x}_{2}, {x}_{3}, \\dots )\\), \\(\\mu\\)
    is mean, and \\(\\Sigma\\) is covariance. For Kernel Density Estimation (KDE),
    the density of the “normal” instances was estimated directly using a gaussian
    kernel. The density estimation process using a kernel function can be seen in
    Eq. (2). Once the probability density function (pdf) has been estimated, the data
    instances corresponding to the normal state of the machine were scored using the
    determined pdf and the threshold for anomaly detection was determined using trial
    and error. $${f}_{h}\\left(x\\right)=\\frac{1}{nh} \\sum_{i=1}^{n}{K}_{h}(\\frac{x-{x}_{i}}{h})$$
    (2) where, \\({K}_{h}(x-{x}_{i})\\) is the kernel function. The methods discussed
    so far were density estimation techniques, where different approaches were used
    to estimate the probability density function (pdf) of the normal instances corresponding
    to the normal operating conditions of the machine. For the case of model based
    anomaly estimation, a technique called the Isolation Forest [25] was used to identify/detect
    anomalies and outliers in the data. The Isolation Forest was trained on the normal
    operating conditions of the machine and was tested on the anomalous instances.
    All the developed models and their hyperparameters were summarized in Table 4.
    Table 3 Performance evaluation of the six models using tenfold CV Full size table
    Table 4 Model developed and their tuned hyperparameters Full size table 5.3 Model
    Deployment and Monitoring Once the model training was completed, they were containerized
    with the necessary packages that complement the inference process. The containers
    were then hosted using Python-based microservices, as CaaS (Container as a Service)
    using AWS Sagmaker Serverless endpoints. The process flow involved in the model
    deployment can be seen in Fig. 9. During the inference process, any user querying
    the API, located at the AWS Amplify frontend, with the appropriate power consumption
    data was first validated to ensure the data integrity, followed by directing the
    request to the AWS Sagemaker with the input data. The inferences from all the
    models deployed were made using a serverless interface and was then returned to
    the user as well logged with appropriate timestamp for further analytics down
    the line. The inference was categorized into anomaly detection followed by defect
    identification. The final inference provided to the user was the majority vote
    of the inferences from all the models trained. The model’s performance was monitored
    periodically by accessing the inference logs and comparing it with the known states
    of the machine. Currently, the process of model updates was done manually by assigning
    weighted positive and negative scores to correct and incorrect inferences. The
    weight determination for the scores depends on how reliably a particular state
    can be identified by using the controller data. Repeated application of this process
    will enable us in obtaining a robust training data over a period, which will then
    be used to update the model weights. The principle behind this approach lays down
    the foundation for reinforcement learning, which will be further augmented as
    a future work. Fig. 9 Model deployment and monitoring process flow Full size image
    5.4 Inference Process As mentioned in the previous section, the window size for
    the segment was set at 60 s. In our application scenario, getting an inference
    every 120 s was satisfactory. Hence, in order to reduce the number of false positives,
    60 s overlapping inference over the 120 s of data was conducted by shifting the
    inference window by 10 s for every inference made. This process leads to 6 inferences
    per 120 s segment, and then majority voting was conducted to determine the error
    state of the machine. In case of a tie, it was always broken by choosing the normal
    operating state of the machine. The segmentation process can be seen in Fig. 10.
    Fig. 10 Segmented inference process Full size image 6 Results and Discussion This
    section aims to present the results of the model training process, both supervised
    and unsupervised learning techniques. This is followed by the analysis of the
    impact energy consumption monitoring on the anomaly detection of manufacturing
    machines. 6.1 Model Evaluation In the case of supervised learning model development,
    the models were trained using a tenfold Cross Validation. The performance metrics
    that were used to assess the models performance were F1-Score, Precision Score,
    and Recall Score for the minority labels with micro-averaging to eliminate the
    impact of class imbalance [32]. Precision quantifies the number of correct positive
    predictions out of all the positive predictions. Recall quantifies the number
    of correct positive predictions made from all the correct positive predictions
    that could have been made. Recall can indicate the missed positive predictions.
    Maximizing the precision will minimize the number of false positive errors, whereas
    maximizing the recall will minimize the number of false negative errors [33].
    Based on the above metrics the models that performed well were Random Forests
    and Bagging Classifier. $${\\text{Precision}} = \\,\\frac{{{\\text{True}}\\,{\\text{Positives}}}}{{{\\text{True}}\\,{\\text{Positives}}
    + {\\text{False}}\\,{\\text{Positives}}}}$$ $${\\text{Recall}} = \\frac{{{\\text{True}}\\,{\\text{Positives}}}}{{{\\text{True}}\\,{\\text{Positives}}
    + {\\text{False}}\\,{\\text{Negatives}}}}$$ $$F1\\,{\\text{Score}} = \\frac{{2
    \\, \\times \\,{\\text{Precision }}\\, \\times \\,{\\text{Recall}}}}{{{\\text{Precision}}\\,
    + \\,{\\text{Recall}}}}$$ The confusion matrices corresponding to the each of
    the models can be seen in Fig. 11. From the confusion matrices, across all the
    models, the worst performing classes were the overtravel in X, Y, and Z. The effect
    is particularly amplified in the models Logistic Regression and Support Vector
    Machines. This reflects on the fact that the data clusters were not easily separable
    when using t-SNE visualization, as seen in Fig. 8. Fig. 11 Confusion matrices
    for supervised learning models Full size image In case of unsupervised learning
    models, the models were trained either by estimating the density of the normal
    instances. Once the training was completed the models were tested against the
    anomalous instances, which corresponds to the different error states of the machine,
    as well as other unseen “normal” instances. The metrics used to evaluate the model’s
    performance were Precision, Recall and F1-Score. For the unsupervised learning
    models: Mahalanobis-distance based, and isolation forest, the F1-Score was determined
    to be 0.9848, and 0.9701, respectively. To better understand how Mahalanobis distance
    was used to determine the threshold for anomaly detection, the distribution corresponding
    the Mahalanobis distances was plotted for each of the classes considered in this
    study, see Fig. 12. From the plot, the data instances corresponding to the normal
    operation of the machine are closer to zero, and the distributions of the overtravel
    in X, Y, and Z tend to overlap leading to a difficulty in categorizing without
    supervised model training. Fig. 12 Distribution of Mahalanobis distances for all
    classes Full size image The threshold level in this work was set to be at 3σ level
    of the Mahalanobis distance distribution. To better understand the impact of threshold
    levels, the precision and recall values were computed for different pre-determined
    thresholds: 1σ, 2σ, 3σ¸ and 4σ, and were plotted in Fig. 13. Depending on the
    requirement the σ levels can be updated accordingly. Fig. 13 Impact of threshold-levels
    on the performance metrics Full size image 6.2 Impact of Data-Segmentation Window
    Sizes The segmentation window sizes determine how quickly a prediction can be
    made. Smaller the size of the segmentation window quicker an inference can be
    made, considering no overlapping windows/inferences. Reducing the segmentation
    window size below a threshold can lead to unreliable model performance, because
    the input data packet to the model might not contain sufficient information to
    make a reliable inference. Hence identifying an optimal window was required to
    enable real-time inference. Based on the study that was conducted there was a
    noticeable trend as the window size was reduced, as can be seen in Fig. 14. In
    all the models, except k-NN and SVC, the window of size 15s has slightly better
    performance than other window sizes. In our case, the window size of 60s was optimal
    as that provided a balance between the inference speed and information packet
    size. Fig. 14 Impact of segmentation window sizes Full size image 6.3 Feature
    Importance Study In this section we focus on measuring the impact input power
    consumption of the machine have on energy consumption monitoring and anomaly detection.
    In ultra-precision machining operation, the Material Removal Rate (MRR) is very
    low to visually understand the power consumption patterns present in the data.
    Hence sophisticated tools are required to better extract and analyze the patterns.
    In the first scenario, we aim to understand the top-5 important features among
    the 153 input features to the models. The method used in identifying the important
    features is called Permutation Importance. The feature importance study was repeated
    100 times with different random seed for every model, and the average decrease
    in the mean accuracy was computed on the testing dataset. To better understand
    the impact of the input features, dimension reduction techniques were not applied
    during this study. The most impactful features for the anomaly detection process
    were identified by selecting 10 features for each model that have the highest
    decrease in the mean accuracy. This amounts to a total of 60 items, 10 for each
    model used in this study, then, the frequency of occurrence of each feature were
    computed, see Fig. 15. The top-5 importance features i.e., the most frequently
    occurring ones, were Wavelet Packet Decomposition (WPD)-3 energy, peak value,
    WPD-2 energy, WPD-3 energy, and peak FFT, in the order of their importance. Out
    of the top-5 features, majority falls under the time–frequency domain features
    category. Fig. 15 Two-folded feature Importance study Full size image The feature
    extraction process in this study were done in two levels, first, the features
    corresponding to the input power components, second, the features extracted in
    time, frequency, and time–frequency domain from each of the input power component.
    From the Fig. 15, the top-5 power components were Active Power of Phase-3 (Power3),
    Reactive Power of Phase-3 (PowerReac3), Active Power of Phase-1 and Phase-2, and
    Apparent Power of Phase-3 (PowerApp3). From the above analysis the following inferences
    can be made: (a) Time–frequency domain features have the most impact in enabling
    the defect identification process. This aligns with our hypothesis that within
    a segment of data that was used to identify any anomalies, it is important to
    understand the frequency components present and the time at which they occur.
    (b) The Active Power component is the most important for anomaly detection, this
    is followed by the Reactive Power. This again aligns with our hypothesis and has
    been validate by our preliminary work on equipment state identification using
    Deep Learning [34]. When anomaly detection/defect identification was carried out
    in real-time on a machine under operation, effectively we are looking into the
    motors controlling the machine’s axes. Hence, the Reactive Power components becomes
    important. (c) The energy meter was attached to the input of the machine so that
    the power consumed by all components of the machine can be tracked and measured.
    The reasoning behind why the 3rd Phase power components were the most important
    was because of the fact all the motors controlling the five axes of the machine
    were attached to the input Phase-3. Hence, they had the most impact when detection
    anomalies corresponding to the machine’s operation. Finally, using the feature
    importance study, the robustness of the developed models was tested. It was found
    that the ensemble models, bagging trees and random forest, were highly robust
    to the permutation of any single input feature. The mean decrease in accuracy
    for these models was lowest when compared to all the other models used in this
    study. The Fig. 16 shows the mean decrease in accuracy for the random forest classifier
    with the error bars for standard deviation after 100 repetitions of the feature
    importance study. As can be seen from the plot, the average decrease in the mean
    accuracy was 0.05%. Fig. 16 Top-10 important features for Random Forest classification
    algorithm Full size image 6.4 Comparison with other DAQ Devices In an industrial
    scenario, it might not always be possible to use identical DAQ devices across
    all manufacturing machines. Since feature extraction was adopted in this study
    instead of feature learning process, the models developed should be transferrable
    to other DAQ devices without the need for retraining. Hence, in this section the
    robustness of the developed models was tested by evaluating their performance
    on the data collected by a different power analyzer. The models were trained using
    the data from a WattNode and were tested on a high precision one by Fluke, Norma-4000.
    All the models used in this study performed well. The F1-Score, Precision, and
    Recall were respectively, 0.9829, 0.9871, and 0.9789 for the Random Forest classifier.
    It can be seen from this study that the developed models can be easily ported
    across different power meters of different resolution and accuracy without the
    need for any re-training if the input features to the models were kept consistent.
    We believe this would enable or at the very least complement easier deployment
    of machine learning models across the manufacturing facility swiftly, enabling
    widespread deployment. However, further validation with more DAQ devices is necessary.
    7 Conclusion In this work we studied and explored the potential of energy consumption
    monitoring to detect and classify operation anomalies in manufacturing machines.
    Through this work we were able to accomplish the following: 1. Framework for real-time
    monitoring of the equipment’s operating condition by retrofitting a CNC machine
    using an inexpensive energy consumption monitoring sensor was developed. 2. Supervised
    and unsupervised machine learning models that could detect the operation anomalies
    of an ultra-precision CNC machine were developed. The models were able to detect
    anomalies and classify their type using supervised learning with an average macro
    F1-Score of 0.9971 ± 0.0012 and 0.9974 ± 0.0018 respectively. 3. A case study
    showcasing the complete model development and deployment process right from retrofitting
    of a legacy machine to model deployment at the AWS, and to the continuous monitoring
    of the model’s performance was conducted. 4. Finally, an elaborate model evaluation
    and feature importance study was conducted to test the robustness of the developed
    models and identify the most important input power parameters when it comes to
    detecting anomalies in equipment’s operation. Using equipment’s energy consumption
    data as a parameter for anomaly detection of manufacturing machines has proved
    effective. But there are some limitations with this approach that needs to be
    acknowledged to enable the effective implementation of the developed methodologies.
    Firstly, in the case of fault identification, it is required to collect data on
    all possible error states of the equipment. This requires the faults to be artificially
    induced in the manufacturing equipment and might not be a favorable option for
    many manufacturers. Secondly, in the case of anomaly detection, which aims to
    overcome the problem of artificially introducing error states on the machine,
    the data collected should encompass all possible good states of the machine. The
    process of identifying and collecting data on all normal operating states of the
    machine can be time-consuming. The model monitoring segment of this work aims
    to overcome the second challenge, but it requires a closed-loop feedback system
    where the operator inputs are required to update the model parameters over time.
    Hence the final challenge could be the slight increase in the workload of the
    machine tool operators who compare the actual and inferred scenarios and provide
    feedback on the model’s performance. To the extent of our knowledge, we believe
    that this is the first work that has conducted an elaborative study on monitoring
    the energy consumption of the machine to detect operation anomalies. In addition
    to that, to extent of our knowledge, we also believe that this is first work to
    showcase the development of a complete pipeline for the anomaly detection model
    development, deployment, and monitoring for real-time inferences. The robustness
    of the machine learning models will be a key consideration when deploying them
    in manufacturing industries, either due to the input data distribution drift over-time
    or due to the perturbations associated with sensors, equipment setup, etc. It
    is challenging to fully test the robustness of the models in a laboratory scenario,
    as it is difficult to cover all possible scenarios that the models go through
    during their lifecycle. Hence, we believe through this work we enable easier deployment
    and tracking of the models developed in a laboratory setting for further research.
    The complete codebase used this work has been published at https://github.com/vigneshuw/machine_fault_identification.git
    for replication/modification for further development. Also, it was ensured that
    the codebase is modular so the model development content can be replaced with
    custom models for quick deployments. The future work for this study involves extending
    the models developed to identify anomalies over a wide range of defects, combination
    of different operating state of the machine, and cutting operation. This will
    be followed by automating the process of updating the model weights to improve
    the inferences using reinforcement learning. Data availability The complete codebase
    used this work has been published at https://github.com/vigneshuw/machine_fault_identification.git
    for further development. Abbreviations \\({D}_{M}\\left(x\\right)\\) : Mahalanobis
    distance of the data instance \\(x\\) \\({K}_{h}(x-{x}_{i})\\) : Kernel function
    of choice for Kernel Density Estimation (KDE) \\({f}_{h}\\left(x\\right)\\) :
    Density estimate at a point \\(x\\) \\(h\\) : Bandwidth parameter, controls the
    smoothness of the estimated density distribution References Duflou, J. R., et
    al. (2012). Towards energy and resource efficient manufacturing: A processes and
    systems approach. CIRP Annals, 61(2), 587–609. https://doi.org/10.1016/j.cirp.2012.05.002
    Article   Google Scholar   Lee, J.-Y., et al. (2016). A simplified machine-tool
    power-consumption measurement procedure and methodology for estimating total energy
    consumption. Journal of Manufacturing Science and Engineering, 138(5), 051004.
    https://doi.org/10.1115/1.4031713 Article   Google Scholar   Behrendt, T., Zein,
    A., & Min, S. (2012). Development of an energy consumption monitoring procedure
    for machine tools. CIRP Annals, 61(1), 43–46. https://doi.org/10.1016/j.cirp.2012.03.103
    Article   Google Scholar   Hu, S., Liu, F., He, Y., & Hu, T. (2012). An on-line
    approach for energy efficiency monitoring of machine tools. Journal of Cleaner
    Production, 27, 133–140. https://doi.org/10.1016/j.jclepro.2012.01.013 Article   Google
    Scholar   Vijayaraghavan, A., & Dornfeld, D. (2010). Automated energy monitoring
    of machine tools. CIRP Annals, 59(1), 21–24. https://doi.org/10.1016/j.cirp.2010.03.042
    Article   Google Scholar   Gao, R. X., Wang, L., Helu, M., & Teti, R. (2020).
    Big data analytics for smart factories of the future. CIRP Annals, 69(2), 668–692.
    https://doi.org/10.1016/j.cirp.2020.05.002 Article   Google Scholar   Shi, W.,
    Cao, J., Zhang, Q., Li, Y., & Xu, L. (2016). Edge computing: Vision and challenges.
    IEEE Internet of Things Journal, 3(5), 637–646. https://doi.org/10.1109/JIOT.2016.2579198
    Article   Google Scholar   Lessmeier, C., Kimotho, J. K., Zimmer, D., & Sextro,
    W. (2016). Condition monitoring of bearing damage in electromechanical drive systems
    by using motor current signals of electric motors: A benchmark data set for data-driven
    classification. PHM Society European Conference. https://doi.org/10.36001/phme.2016.v3i1.1577
    Article   Google Scholar   Rai, R., Tiwari, M. K., Ivanov, D., & Dolgui, A. (2021).
    Machine learning in manufacturing and industry 4.0 applications. International
    Journal of Production Research, 59(16), 4773–4778. https://doi.org/10.1080/00207543.2021.1956675
    Article   Google Scholar   Zhang, S., Zhang, S., Wang, B., & Habetler, T. G. (2020).
    Machine learning and deep learning algorithms for bearing fault diagnostics: A
    comprehensive review. IEEE Access, 8, 29857–29881. https://doi.org/10.1109/ACCESS.2020.2972859
    Article   Google Scholar   Fujishima, M., Ohno, K., Nishikawa, S., Nishimura,
    K., Sakamoto, M., & Kawai, K. (2016). Study of sensing technologies for machine
    tools. CIRP Journal of Manufacturing Science and Technology, 14, 71–75. https://doi.org/10.1016/j.cirpj.2016.05.005
    Article   Google Scholar   Fujishima, M., Mori, M., Nishimura, K., Takayama, M.,
    & Kato, Y. (2017). Development of sensing interface for preventive maintenance
    of machine tools. Procedia CIRP, 61, 796–799. https://doi.org/10.1016/j.procir.2016.11.206
    Article   Google Scholar   Liu, C., Vengayil, H., Lu, Y., & Xu, X. (2019). A cyber-physical
    machine tools platform using OPC UA and MTConnect. Journal of Manufacturing Systems,
    51, 61–74. https://doi.org/10.1016/j.jmsy.2019.04.006 Article   Google Scholar   He,
    Y., Wu, P., Wang, Y., Tao, F., & Hon, B. K. K. (2020). An OPC UA based framework
    for predicting energy consumption of machine tools. Procedia CIRP, 90, 568–572.
    https://doi.org/10.1016/j.procir.2020.02.133 Article   Google Scholar   Zhao,
    R., Yan, R., Chen, Z., Mao, K., Wang, P., & Gao, R. X. (2019). Deep learning and
    its applications to machine health monitoring. Mechanical Systems and Signal Processing,
    115, 213–237. https://doi.org/10.1016/j.ymssp.2018.05.050 Article   Google Scholar   Wang,
    J., Ma, Y., Zhang, L., Gao, R. X., & Wu, D. (2018). Deep learning for smart manufacturing:
    Methods and applications. Journal of Manufacturing Systems, 48, 144–156. https://doi.org/10.1016/j.jmsy.2018.01.003
    Article   Google Scholar   Yun, H., Kim, H., Kim, E., & Jun, M. B. G. (2020).
    Development of internal sound sensor using stethoscope and its applications for
    machine monitoring. Procedia Manufacturing, 48, 1072–1078. https://doi.org/10.1016/j.promfg.2020.05.147
    Article   Google Scholar   Kim, J., Lee, H., Jeong, S., & Ahn, S.-H. (2021). Sound-based
    remote real-time multi-device operational monitoring system using a Convolutional
    Neural Network (CNN). Journal of Manufacturing Systems, 58, 431–441. https://doi.org/10.1016/j.jmsy.2020.12.020
    Article   Google Scholar   Hunkeler, U., Truong, H. L., & Stanford-Clark, A. (2008).
    MQTT-S: A publish/subscribe protocol for wireless sensor networks. International
    Conference on Communication Systems Software and Middleware and Workshops. https://doi.org/10.1109/COMSWA.2008.4554519
    Article   Google Scholar   Loh, W. (2011). Classification and regression trees.
    WIREs Data Mining and Knowledge Discovery, 1(1), 14–23. https://doi.org/10.1002/widm.8
    Article   Google Scholar   Mitchell, T. M. (1997). Machine learning. McGraw-Hill.
    MATH   Google Scholar   Chang, C.-C., & Lin, C.-J. (2011). LIBSVM: A library for
    support vector machines. ACM Transactions Intelligent Systems and Technology,
    2(3), 1–27. https://doi.org/10.1145/1961189.1961199 Article   Google Scholar   Breiman,
    L. (1996). Bagging predictors. Machine Learning, 24(2), 123–140. https://doi.org/10.1007/BF00058655
    Article   MATH   Google Scholar   Hastie, T., Tibshirani, R., & Friedman, J. (2009).
    Random forests. The elements of statistical learning. New York: Springer. https://doi.org/10.1007/978-0-387-84858-7_15
    Chapter   MATH   Google Scholar   Liu, F. T., Ting, K. M., & Zhou, Z.-H. (2008).
    Isolation forest. Eighth IEEE International Conference on Data Mining. https://doi.org/10.1109/ICDM.2008.17
    Article   Google Scholar   Yang, H., Kumara, S., Bukkapatnam, S. T. S., & Tsung,
    F. (2019). The internet of things for smart manufacturing: A review. IISE Transactions,
    51(11), 1190–1216. https://doi.org/10.1080/24725854.2018.1555383 Article   Google
    Scholar   Hsieh, R.-J., Chou, J., & Ho, C.-H. (2019). Unsupervised online anomaly
    detection on multivariate sensing time series data for smart manufacturing. IEEE
    12th Conference on Service-Oriented Computing and Applications (SOCA). https://doi.org/10.1109/SOCA.2019.00021
    Article   Google Scholar   Li, C., Zhang, S., Qin, Y., & Estupinan, E. (2020).
    A systematic review of deep transfer learning for machinery fault diagnosis. Neurocomputing,
    407, 121–135. https://doi.org/10.1016/j.neucom.2020.04.045 Article   Google Scholar   Marcus,
    G. (2018). Deep learning: A critical appraisal. arXiv preprint arXiv:1801.00631.
    Xu, Z., Selvaraj, V., & Min, S. (2022). State identification of a 5-axis ultra-precision
    CNC machine tool using energy consumption data assisted by multi-output densely
    connected 1D-CNN model. Journal of Intelligent Manufacturing. https://doi.org/10.1007/s10845-022-02030-y
    Article   Google Scholar   Parisi, G. I., Kemker, R., Part, J. L., Kanan, C.,
    & Wermter, S. (2019). Continual lifelong learning with neural networks: A review.
    Neural Networks, 113, 54–71. https://doi.org/10.1016/j.neunet.2019.01.012 Article   Google
    Scholar   Krawczyk, B. (2016). Learning from imbalanced data: Open challenges
    and future directions. Progress in Artificial Intelligence, 5(4), 221–232. https://doi.org/10.1007/s13748-016-0094-0
    Article   Google Scholar   Sokolova, M., & Lapalme, G. (2009). A systematic analysis
    of performance measures for classification tasks. Information Processing and Management,
    45(4), 427–437. https://doi.org/10.1016/j.ipm.2009.03.002 Article   Google Scholar   Selvaraj,
    V., Xu, Z., & Min, S. (2022). Intelligent operation monitoring of an ultra-precision
    CNC machine tool using energy data. International Journal of Precision Engineering
    and Manufacturing-Green Technology. https://doi.org/10.1007/s40684-022-00449-5
    Article   Google Scholar   Download references Acknowledgements The material is
    based on the work supported by the Wisconsin Alumni Research Foundation (WARF,
    MSN237362). Authors gracefully acknowledge the donation of the ROBONANO α-0iB
    to the University of Wisconsin Madison by FANUC Corporation, Japan. Author information
    Authors and Affiliations Manufacturing Innovation Network Laboratory, Department
    of Mechanical Engineering, University of Wisconsin Madison, Madison, WI, 53706,
    USA Vignesh Selvaraj & Sangkee Min Corresponding author Correspondence to Sangkee
    Min. Additional information Publisher''s Note Springer Nature remains neutral
    with regard to jurisdictional claims in published maps and institutional affiliations.
    This paper was presented at PRESM2022. Rights and permissions Springer Nature
    or its licensor (e.g. a society or other partner) holds exclusive rights to this
    article under a publishing agreement with the author(s) or other rightsholder(s);
    author self-archiving of the accepted manuscript version of this article is solely
    governed by the terms of such publishing agreement and applicable law. Reprints
    and permissions About this article Cite this article Selvaraj, V., Min, S. Real-Time
    Fault Identification System for a Retrofitted Ultra-Precision CNC Machine from
    Equipment''s Power Consumption Data: A Case Study of an Implementation. Int. J.
    of Precis. Eng. and Manuf.-Green Tech. 10, 925–941 (2023). https://doi.org/10.1007/s40684-022-00497-x
    Download citation Received 27 July 2022 Revised 20 October 2022 Accepted 07 December
    2022 Published 26 January 2023 Issue Date July 2023 DOI https://doi.org/10.1007/s40684-022-00497-x
    Share this article Anyone you share the following link with will be able to read
    this content: Get shareable link Provided by the Springer Nature SharedIt content-sharing
    initiative Keywords Energy monitoring Industry 4.0 Industrial AI Fault detection
    Real-time inference Smart manufacturing Use our pre-submission checklist Avoid
    common mistakes on your manuscript. Sections Figures References Abstract Introduction
    Background Problem Description Methodology Engineering Application Results and
    Discussion Conclusion Data availability Abbreviations References Acknowledgements
    Author information Additional information Rights and permissions About this article
    Advertisement Discover content Journals A-Z Books A-Z Publish with us Publish
    your research Open access publishing Products and services Our products Librarians
    Societies Partners and advertisers Our imprints Springer Nature Portfolio BMC
    Palgrave Macmillan Apress Your privacy choices/Manage cookies Your US state privacy
    rights Accessibility statement Terms and conditions Privacy policy Help and support
    129.93.161.219 Big Ten Academic Alliance (BTAA) (3000133814) - University of Nebraska-Lincoln
    (3000134173) © 2024 Springer Nature"'
  inline_citation: '>'
  journal: International Journal of Precision Engineering and Manufacturing - Green
    Technology
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Real-Time Fault Identification System for a Retrofitted Ultra-Precision
    CNC Machine from Equipment''s Power Consumption Data: A Case Study of an Implementation'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Almaraz-Rivera J.G.
  citation_count: '3'
  description: Network monitoring is crucial to analyze infrastructure baselines and
    alert whenever an abnormal behavior is observed. However, human effort is limited
    in time and scope since many variables must be considered in real-time. In addition,
    infrastructures such as Kubernetes are complex by nature since they do not consider
    fixed equipment from which to gather data; instead, these infrastructures consider
    distributed, event-driven, and ephemeral containers that make it complicated to
    capture and track metrics. Artificial Intelligence models have demonstrated high
    detection rates for anomaly detection; therefore, there is a need to design and
    implement a global solution to collect complex data and orchestrate the whole
    Machine Learning Operations workflow. This document shares the findings and learnings
    from defining a cloud-native Artificial Intelligence infrastructure at Aligo to
    develop an anomaly-based detection system for monitoring on-premise Kubernetes
    infrastructures. After Chaos Engineering experiments, it is shown that the resulting
    deployed system is strong when alerting outliers and that an end-to-end infrastructure
    has been developed for conducting future Artificial Intelligence projects at the
    company.
  doi: 10.1109/TLA.2023.10068850
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Journals & Magazines >IEEE Latin America Transactions
    >Volume: 21 Issue: 3 An Anomaly-based Detection System for Monitoring Kubernetes
    Infrastructures Publisher: IEEE Cite This PDF Josue Genaro Almaraz-Rivera All
    Authors 2 Cites in Papers 230 Full Text Views Abstract Authors Citations Keywords
    Metrics Abstract: Network monitoring is crucial to analyze infrastructure baselines
    and alert whenever an abnormal behavior is observed. However, human effort is
    limited in time and scope since many variables must be considered in real-time.
    In addition, infrastructures such as Kubernetes are complex by nature since they
    do not consider fixed equipment from which to gather data; instead, these infrastructures
    consider distributed, event-driven, and ephemeral containers that make it complicated
    to capture and track metrics. Artificial Intelligence models have demonstrated
    high detection rates for anomaly detection; therefore, there is a need to design
    and implement a global solution to collect complex data and orchestrate the whole
    Machine Learning Operations workflow. This document shares the findings and learnings
    from defining a cloud-native Artificial Intelligence infrastructure at Aligo to
    develop an anomaly-based detection system for monitoring on-premise Kubernetes
    infrastructures. After Chaos Engineering experiments, it is shown that the resulting
    deployed system is strong when alerting outliers and that an end-to-end infrastructure
    has been developed for conducting future Artificial Intelligence projects at the
    company. Published in: IEEE Latin America Transactions ( Volume: 21, Issue: 3,
    March 2023) Page(s): 457 - 465 Date of Publication: 14 March 2023 Electronic ISSN:
    1548-0992 DOI: 10.1109/TLA.2023.10068850 Publisher: IEEE Authors Citations Keywords
    Metrics More Like This Non-contact Measurement Systems for Physiological Data
    Monitoring of Military Pilots During Training on Simulators: Review and Application
    2019 International Conference on Military Technologies (ICMT) Published: 2019
    Anomaly Detection in Molecular Communications With Applications to Health Monitoring
    Networks IEEE Transactions on Molecular, Biological and Multi-Scale Communications
    Published: 2020 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase
    Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS
    PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA:
    +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE
    Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved."'
  inline_citation: '>'
  journal: IEEE Latin America Transactions
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: An Anomaly-based Detection System for Monitoring Kubernetes Infrastructures
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Park H.J.
  - Cho S.W.
  - Nanda A.
  - Park J.H.
  citation_count: '3'
  description: This study investigates a method for improving real-time decisions
    regarding the storage location of export containers while the containers are arriving.
    To manage the decision-making process, we propose a two module-based data-driven
    dynamic stacking strategy that facilitates stowage planning. Module 1 generates
    the Gaussian mixture model (GMM) specific to each container group for container
    weight classification. Module 2 implements the data-driven dynamic stacking strategy
    as an online algorithm to determine the storage location of an arriving container
    in real time. Numerical experiments were conducted using real-life data to validate
    the effectiveness of the proposed method compared to other alternative stacking
    strategies. These experiments revealed that the performance of the proposed method
    is robust, and therefore it can improve yard operations and container terminal
    competitiveness.
  doi: 10.1007/s10696-022-09457-8
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Log in Find a journal Publish
    with us Track your research Search Cart Home Flexible Services and Manufacturing
    Journal Article Data-driven dynamic stacking strategy for export containers in
    container terminals Open access Published: 27 June 2022 Volume 35, pages 170–195,
    (2023) Cite this article Download PDF You have full access to this open access
    article Flexible Services and Manufacturing Journal Aims and scope Submit manuscript
    Hyun Ji Park , Sung Won Cho , Abhilasha Nanda & Jin Hyoung Park   2594 Accesses
    3 Citations 1 Altmetric Explore all metrics Abstract This study investigates a
    method for improving real-time decisions regarding the storage location of export
    containers while the containers are arriving. To manage the decision-making process,
    we propose a two module-based data-driven dynamic stacking strategy that facilitates
    stowage planning. Module 1 generates the Gaussian mixture model (GMM) specific
    to each container group for container weight classification. Module 2 implements
    the data-driven dynamic stacking strategy as an online algorithm to determine
    the storage location of an arriving container in real time. Numerical experiments
    were conducted using real-life data to validate the effectiveness of the proposed
    method compared to other alternative stacking strategies. These experiments revealed
    that the performance of the proposed method is robust, and therefore it can improve
    yard operations and container terminal competitiveness. Similar content being
    viewed by others Intelligent Modeling Essential to Get Good Results: Container
    Storage Inside a Container Terminal Chapter © 2015 A study of the sensitivity
    of sequence stacking strategies for the storage location assignment problem for
    out-bound containers in a maritime terminal Article 20 July 2018 Assessment System
    for a Large Container Management and Optimization Problem Chapter © 2024 1 Introduction
    With the development of container transportation, the task of efficiently managing
    scarce storage space resources in container terminals has become an important
    role for marine transport hubs. Containers arrive at the storage area randomly
    and are stacked on the ground in the arrangement of a yard block as shown in Fig.
    1. Yard cranes (YCs) must first handle the containers located at the top tier,
    and the containers already stacked are rehandled to access the target container
    buried beneath them. Thus, inefficient handling can result in excessive operational
    delays, which can lead to bottlenecks in container flows. Therefore, to improve
    the productivity of container terminals, effective methods for determining the
    most efficient storage location of the arriving containers must be employed (Zhang
    et al. 2003). Fig. 1 Yard block configuration Full size image Container terminals
    handle various types of incoming containers, which can be classified as import
    or export containers depending on the vehicles that carry them. Import containers
    are discharged from vessels and loaded onto external trucks (ETs), whereas export
    containers are transported to the terminal by ETs and are loaded onto vessels.
    All of these containers are temporarily stored in the yard, and the goal of the
    storage strategy is to minimize the amount of time the vehicles that are to be
    loaded stay in the terminal. For this reason, the way the containers are stored
    depends on the characteristics of the vehicles that are to be loaded, such as
    the vehicles’ capacities and their arrival times. For example, ETs have small
    carrying capacities and large uncertainties in arrival times depending on the
    traffic conditions. Therefore, import containers are stacked at higher tiers,
    as the estimated retrieval times are shorter. In contrast, vessels carry large
    quantities of containers, and their arrival times are expected via berth plans.
    Thus, export containers are stored through decisions at two different levels:
    planning and operational (Chen and Lu 2012; Jiang and Jin 2017; Zhou et al. 2020;
    He et al. 2020a, b; Feng et al. 2021). At the planning level, containers are assigned
    to sub-blocks based on the container group, which is defined as a group of containers
    having the same departing vessel, port of destination (POD), size, and type (Kim
    et al. 2004; Zhen 2013, 2014; Jiang and Jin 2017; He et al. 2020a). At the operational
    level, containers are stacked within the range of a single yard bay in consideration
    of the loading operation (Kim et al. 2000; Zhang et al. 2010, 2014a, b). In the
    loading operation, planners schedule the loading sequence with two objectives:
    minimizing the handling effort of quay cranes (QCs) and YCs, and ensuring the
    stability of the vessel (Kim et al. 2000). Therefore, the storage configuration
    of export containers must be in a good shape to generate an efficient loading
    sequence. In this study, we focus on the container stacking problem (CSP) for
    export containers at the operational level in order to aid planners in constructing
    optimal load sequences. The CSP for export containers is a real-time decision
    problem because incomplete and imperfect information is involved (Steenken et
    al. 2004; Borgman et al. 2010; He et al. 2020b). First, as most studies assume,
    the time at which the containers arrive at the yard cannot be accurately predicted
    because the arrival times are dynamically updated depending on the traffic conditions.
    Therefore, it is difficult to achieve the optimal results. Second, information
    on the weight of the containers to be loaded onto the vessel is uncertain. Many
    studies assume that container weight falls within one of three classes: heavy
    (H), medium (M), and light (L) (Kim et al. 2000; Zhang et al. 2010, 2014a). Some
    extended studies have converted the uncertainty of the weight information into
    probabilities (Kang et al. 2006; Zhang et al. 2014b). In practice, the estimated
    weight class can be identified as a different weight class when the container
    arrives at the terminal. Because of this, terminal operators use their experience
    as the basis for classifying container weights into different classes for each
    vessel. Third, the stowage instructions are not known one to two weeks in advance.
    Container ships are berthed at multiple ports along the shipping line, and stowage
    instructions vary depending on the loading operations performed at the previous
    port. For example, as shown in Fig. 2, heavier containers are required in section
    A and lighter containers are required in section B. This requires a stacking strategy
    that responds flexibly to this uncertain environment. Lastly, the YC workload
    at the time of container arrival is unknown in advance (Jiang and Jin 2017). Therefore,
    containers are dynamically allocated to multiple bays depending on the YC''s workload
    at the time of arrival, resulting in different container weight distributions
    in each bay. Fig. 2 Example of a set of stowage instructions Full size image In
    this study, we propose a stacking strategy based on an online algorithm in which
    decisions are made with incomplete knowledge of the future (Karp 1992). Unlike
    an offline algorithm that yields optimal solutions with extensive computations,
    an online algorithm facilitates operations in dynamic environments that do not
    have ample time to compute before performing tasks. Because containers cannot
    be held after they arrive and the order in which they arrive cannot be controlled,
    an online algorithm that allocates storage locations when containers arrive at
    the block is appropriate (Murty et al. 2005). A number of studies have employed
    online algorithms for the CSP (Dekker et al. 2006; Borgman et al. 2010; Park et
    al. 2011; Chen and Lu 2012; Ambrosino et al. 2013; Güven and Eliiyi 2014, 2019;
    He et al. 2020b), but they do not take into account many practical considerations
    such as uncertainty of the weight, type and arrival timing of containers, uncertainty
    about the stowage instruction of the vessel, and the dynamic nature of YC workload
    according to other interconnected operations. Therefore, this study proposes a
    data-driven dynamic stacking strategy (DSS) based on an online algorithm. The
    data-driven DSS consists of two modules. The first is the Gaussian mixture model
    (GMM) generation module, which clusters the container weight into several weight
    classes. The second is the DSS module based on the online algorithm to determine
    the storage location of an arriving container in real time. This module adjusts
    itself to dynamically respond to the environment. The remainder of this paper
    is organized as follows. In Sect. 2, relevant literature on the CSP is reviewed.
    A detailed description of the proposed method is provided in Sect. 3. In Sect.
    4, computational experiments are conducted and interpreted. Finally, the conclusions
    are drawn in Sect. 5. 2 Literature review In this section, we review previous
    studies related to the CSP in container terminals. Many researchers have studied
    on the related problem, and we refer to Vis and De Koster (2003), Steenken et
    al. (2004), Stahlbock and Voß (2008), and Carlo et al. (2014) which conducted
    comprehensive reviews of numerous studies on the efficient operation of container
    terminals. The solutions to the CSP have been classified into two types: one for
    import containers and one for export containers. For import containers, De Castillo
    and Daganzo (1993) proposed two stacking strategies: a non-segregation strategy
    that includes all stacks of the same size from all vessels, and a segregation
    strategy in which containers from different vessels are segregated. Kim and Kim
    (1999) implemented a segregation strategy for import containers that estimated
    the expected total number of rehandles. They presented a mathematical model for
    the relationship between the height of the stack and the number of rehandles.
    They also considered the uncertainty in the arrival times of import containers
    for constant, periodic, and dynamic arrival rates. Kim and Kim (2002) proposed
    a cost model that determines the optimal storage space and number of transfer
    cranes for import containers. The cost model included the costs of space, transfer
    cranes, and ETs, and they illustrated the effectiveness of their deterministic
    and stochastic models using numerical examples. Ting et al. (2010) proposed a
    category stacking strategy (also called a clustering stacking strategy) for import
    containers by analyzing historical data. They presented a pick-up booking system
    that categorizes the containers into several groups according to the pick-up priority
    predicted by historical data. Sauri and Martin (2011) extended the work of De
    Castillo and Daganzo (1993) and developed a segregation strategy that generates
    the fewest number of rehandles by mixing containers from different vessels. In
    addition, they considered the different probabilities of the time that elapsed
    before each container left the terminal as a function of the time each container
    arrived. Ambrosino et al. (2013) modeled import containers being loaded onto a
    train by comparing train loading policies (sequential, non-sequential, and partially
    sequential) for different stacking strategies (random, based on container weight,
    and based on container weight and commercial priority) in a container terminal.
    Maldonado et al. (2019) proposed three different stacking strategies based on
    the prediction (nominal, numerical, and nominal and numerical) of expected dwell
    times using the random forest method. They assessed their proposed method by applying
    it to two strategies (horizontal and vertical) in two scenarios (average and stressed).
    Because the storage periods for import containers vary depending on the arrival
    time of ETs and trains, the CSP for import containers has been studied in a way
    that enables the arrival times to be predicted probabilistically. In contrast,
    the CSP for export containers considers vessel characteristics. Kim et al. (2000)
    proposed a dynamic programming (DP) model to determine the storage locations of
    export containers based on their weights. They assumed that heavier containers
    should be loaded onto the lower tiers of a vessel to guarantee its stability.
    Therefore, heavier containers are stacked at the higher tiers of the yard block
    to reduce the expected number of rehandles. Furthermore, they developed a decision
    tree to support real-time decisions. Duinkerken et al. (2001) evaluated the performance
    of the remaining stack capacity (RSC) strategy, which considers the stack height
    and container category using various stacking strategies (random, levelling, and
    closest position). Dekker et al. (2006) proposed a category stacking strategy
    that allows online optimization to facilitate loading operations. They used a
    simulation method to compare random stacking with category stacking based on the
    number of rehandles. Kang et al. (2006) presented a stacking strategy for export
    containers with uncertain weight information using a simulated annealing approach
    to minimize the number of rehandles. Furthermore, they proposed an advanced stacking
    strategy that overcomes the uncertainty in container weight through machine learning
    techniques. Park et al. (2011) proposed stacking strategies to dynamically determine
    the stacking location as the operational environment changes. The proposed strategies,
    which were based on an online algorithm, were generated by evaluating the weights
    of the decision criteria during the evaluation period. Simulations were conducted
    for a variety of stacking strategies, which were demonstrated to be effective
    in reducing QC delays. Chen and Lu (2012) proposed a hybrid sequence stacking
    algorithm (HSSA) based on an online algorithm to make decisions in real time.
    They observed that the HSSA outperformed the random and vertical stacking strategies
    in terms of the number of rehandles. Zhang et al. (2010) analyzed the error of
    a key model transformation in Kim et al. (2000) and presented the correct form.
    Zhang et al. (2014a), which was an extension of the studies by Kim et al. (2000)
    and Zhang et al. (2010), proposed two conservative models by reinterpreting the
    punishment coefficient for stacking light containers on top of stacks loaded with
    heavy containers. The proposed models outperformed the previous optimized models
    in terms of static and dynamic indicators. Zhang et al. (2014b) considered adjusting
    the proportion of unarrived containers in each weight class to a non-constant
    proportion in the constant proportion DP model proposed by Kim et al. (2000) and
    Zhang et al. (2010). In numerical experiments, they demonstrated that the proposed
    models with the adjusted weight class proportions for the remaining containers
    improved the stacking quality. Hu et al. (2014) proposed a branch-and-bound method
    based on the least-cost priority queue (LCBB) to obtain an optimal solution in
    which the number of rehandles is minimized, using the HSSA proposed by Chen and
    Lu (2012) to calculate the upper bound for the LCBB. Güven and Eliiyi (2014) studied
    two stacking strategies (random stacking and category stacking) for export containers.
    They considered container weight as another category attribute, and grouped containers
    with a weight of less than three tons into the same category. Güven and Eliiyi
    (2019) extended Güven and Eliiyi (2014) and expanded the stacking strategies to
    include all types of containers (export, transit, import, and empty containers).
    They compared three stacking strategies (random stacking, attribute-based stacking,
    and weight-relaxed stacking) through simulations. He et al. (2020b) studied stacking
    strategies that consider the uncertainty in the arrival sequence of vessels, assuming
    that the weight information and arrival order of the containers are known. Based
    on the three stacking rules (least reshuffle rule, lowest stack rule, and nearest
    stack rule), five heuristic algorithms were proposed according to a set of rules.
    The contributions of our study in the context of the aforementioned studies are
    summarized as follows. First, this is the first study that applies predictive
    analytics for container weight classification to prescribe optimal decisions for
    the CSP. Most previous studies have simplified the problem by assuming three classes
    (light, medium, and heavy), and certain studies (Kang et al. 2006; Zhang et al.
    2014b) have considered the weight uncertainty for each class. However, in practice,
    these assumptions are not practical because the weight is classified according
    to the size of the vessel and the range of weights of the containers to be loaded.
    Therefore, this study analyzes the historical data for container weight, and estimates
    the classification model for container weight class as a GMM using a machine learning
    technique. Second, we propose a dynamic stacking strategy that considers multiple
    bays. To the best of our knowledge, most studies have focused on the CSP for a
    single bay, and the stacking strategy was applied homogeneously to each bay. However,
    in a real-world environment, the proportion of containers in each weight class
    assigned to each bay is not constant. Hence, the remaining containers must respond
    dynamically to the containers that are already stacked. Therefore, this study
    presents a stacking strategy that responds to the configurations of multiple bays.
    Third, we develop a category stacking strategy to present practical alternatives
    that reflect real-world considerations. In most studies on the CSP for export
    containers (the exceptions being Dekker et al. 2006; Güven and Eliiyi 2019), the
    problem is defined as minimizing the expected number of rehandles based on the
    weight class. However, heavier containers are normally loaded onto lower tiers,
    depending on the configuration of the stowage and the precise weight of the containers.
    The category stacking that clusters containers with similar weights into the same
    stack can facilitate stowage planning by providing containers of various weights
    on the top tier in the yard. 3 Problem description This study aims to optimize
    real-time decisions regarding the precise storage location of export containers
    for a given storage area while the containers are arriving. The storage area consists
    of multiple stacks in a bay, as shown in Fig. 3. In this study, the decision on
    the storage location refers to the selection of one stack in the storage area.
    In practice, the storage areas of export containers are not shared with those
    of import containers (Kim and Kim 1999; He et al. 2020b; Hu et al. 2021). Furthermore,
    each storage area designates areas for containers belonging to the same container
    group (Kim et al. 2004; Zhen 2013, 2014; Jiang and Jin 2017; He et al. 2020a).
    For these reasons, different stacking decisions are made depending on the container
    group. Therefore, we focus on stacking decisions that apply to the containers
    in a single container group. Fig. 3 Yard bay configuration Full size image The
    goal is to assign an arriving container to a stack in a way that conforms to the
    category stacking strategy. Category stacking for export containers aims to cluster
    containers with similar weights in the same stack. However, it is difficult to
    achieve this outcome due to the randomness of the arriving containers. The following
    two aspects need to be considered to improve the stacking quality according to
    the category stacking strategy: (1) how to define the similarity in container
    weights and (2) how to define the specific location assignment rules for each
    storage area. For aspect (1), researchers have manually classified container weights
    into several weight classes with approximate weight ranges. For aspect (2), the
    location assignment rules have been executed in the same way for all storage areas.
    However, predictive analytics for container weight classification and container
    assignment rules specific to dynamic storage areas can enhance the stacking strategy.
    In this respect, we propose a data-driven DSS that outperforms existing stacking
    strategies. The proposed container stacking system is divided into two modules,
    as shown in Fig. 4. Module 1 is executed in advance, and module 2 is triggered
    by a container arriving at the port. In module 1, GMM-based predictive models,
    which cluster the container weights into several weight classes for each container
    group, are generated. Next, once a container has arrived, the pre-selected storage
    area is given, and the weight class for the container is predicted by the GMM
    generated in module 1. In module 2, the precise storage location (i.e., stack)
    for the container is selected using the proposed dynamic stacking strategy for
    the given storage area. The proposed stacking strategy is intended to dynamically
    adjust itself depending on the stack configuration in the storage area. A detailed
    description of the modules is provided in the following subsections. Fig. 4 Overview
    of the proposed container stacking system Full size image 3.1 Module 1: generation
    of GMM In module 1, we aggregate the historical data for the container weights
    over the entire voyage for each container group, and then generate the GMM specific
    to each container group for the container weight classification. The GMM is a
    model that represents a population as a linear superposition of subpopulations,
    and it assumes that each subpopulation follows a Gaussian distribution. Because
    the class label (i.e., subpopulation) of the data point is unknown, the GMM is
    an unsupervised learning method (Figueiredo and Jain 2002). In addition, the GMM
    is a soft clustering method that uses probabilistic inference to explain how much
    a given data point is associated with a certain cluster (i.e., subpopulation).
    Due to these characteristics, the GMM has been widely employed in unsupervised
    classification applications in which data tend to follow multimodal and complex
    distributions. In this study, the container weight class was defined for each
    cluster of the GMM. Furthermore, the probable weight class was predicted for new
    container input. For the detailed description, the following notations are introduced:
    Notation \\(G\\) Set of container groups, indexed by \\(g\\) \\({K}_{g}\\) Set
    of clusters (i.e., weight class) for container group \\(g\\), indexed by \\(k\\)
    \\(x\\left(i\\right)\\) Container weight of container \\(i\\) \\(g\\left(i\\right)\\)
    Container group of container \\(i\\) \\(k\\left(i\\right)\\) Probable weight class
    of container \\(i\\) \\({\\mu }_{k}^{g}\\) Mean of cluster \\(k\\) for container
    group \\(g\\) \\({\\Sigma }_{k}^{g}\\) Covariance of cluster \\(k\\) for container
    group \\(g\\) \\({\\pi }_{k}^{g}\\) Mixture weight of cluster \\(k\\) for container
    group \\(g\\); \\(0\\le {\\pi }_{k}^{g}\\le 1\\) and \\(\\sum_{k\\in {K}_{g}}{\\pi
    }_{k}^{g}=1\\) \\({z}_{k}^{g}\\) Latent indicator variable; defined as 1 if the
    observation data belongs to cluster \\(k\\) and 0 otherwise; \\(\\sum_{k\\in {K}_{g}}{z}_{k}^{g}=1\\),
    \\(p\\left({z}_{k}^{g}=1\\right)={\\pi }_{k}^{g}\\) \\(p\\left(x|g\\right)\\)
    Marginal probability distribution of container weight \\(x\\) for container group
    \\(g\\) \\(\\gamma \\left({z}_{k}^{g}|g\\right)\\) Posterior probability (i.e.,
    “responsibility”) that container weight \\(x\\) is observed from cluster \\(k\\)
    for container group \\(g\\); \\(\\gamma \\left({z}_{k}^{g}|g\\right)=p\\left({z}_{k}^{g}=1|x,g\\right)\\)
    The GMM is parameterized by the mean \\({\\mu }_{k}^{g}\\), covariance \\({\\Sigma
    }_{k}^{g}\\), and mixture weight \\({\\pi }_{k}^{g}\\). The assignment of the
    unknown class label \\({z}_{k}^{g}\\) is considered a latent variable instead
    of a parameter. It enables the joint distribution \\(p\\left(x,{z}_{k}^{g}\\right)\\)
    to marginalize the variable \\({z}_{k}^{g}\\) out to define the cost function
    independently of \\({z}_{k}^{g}\\). The resulting standard form of the GMM is
    written as $$p\\left( {x{|}g} \\right) = \\mathop \\sum \\limits_{{k \\in K_{g}
    }} p\\left( {z_{k}^{g} } \\right)p\\left( {x{|}z_{k}^{g} } \\right) = \\mathop
    \\sum \\limits_{{k \\in K_{g} }} \\pi_{k}^{g} N\\left( {x{|}\\mu_{k}^{g} , \\Sigma_{k}^{g}
    } \\right).$$ (1) To estimate the three parameters of the GMM, the objective function
    is to maximize the marginal likelihood of the data (\\(p\\left(x|g\\right)\\)).
    Because there is no analytical solution, a numerical method was employed for the
    maximum likelihood estimation. The most widely used method is expectation maximization
    (EM). The EM algorithm estimates the model parameters through iterations of the
    expectation step (E step) and maximization step (M step). Given the initialized
    model parameters and the log-likelihood estimate, the E step uses the model parameters
    to evaluate the responsibility \\(\\gamma \\left({z}_{k}|g\\right)\\) via $$\\gamma
    \\left( {z_{k}^{g} {|}g} \\right) = C_{g} \\times \\pi_{k}^{g} N\\left( {x{|}\\mu_{k}^{g}
    , \\Sigma_{k}^{g} } \\right),$$ (2) where \\({C}_{g}=1/\\sum_{k\\in {K}_{g}}{\\pi
    }_{k}^{g}N\\left(x|{\\mu }_{k}^{g}, {\\Sigma }_{k}^{g}\\right)\\). Then the M
    step re-estimates the model parameters using this responsibility value. These
    iterations lead to the convergence of the model parameters, and the resulting
    trained GMM provides the probable weight class of the new container input via
    $$k\\left( i \\right) = \\mathop {{\\text{argmax}}}\\limits_{{k \\in K_{g} }}
    \\gamma \\left( {z_{k}^{g} {|}g} \\right)$$ (3) 3.2 Module 2: dynamic stacking
    strategy In module 2, we executed the DSS as an online algorithm to determine
    the storage location of an arriving container in real time. The overall framework
    of the proposed DSS is shown in Fig. 5. The algorithm inputs include the GMM-based
    prediction results for the weight class as well as the yard stack configuration
    of the pre-selected storage area for the arriving container. The storage location
    for the container is determined after the weight class-to-stack assignment. Both
    methods accommodate the GMM-based prediction results for the weight class obtained
    from module 1. Furthermore, the weight class-to-stack assignment method adapts
    the adjustment mechanism according to the dynamic change in the stack configuration,
    which leads to the generation of the stacking strategy that is specific to the
    storage area. Fig. 5 Framework of the proposed dynamic stacking strategy Full
    size image For the weight class-to-stack assignment, conventional approaches of
    category stacking apply the assignment method homogeneously for all storage areas,
    and they remain consistent during the period in which containers are arriving.
    However, in real-world environments, the stack configuration cannot be the same
    for all storage areas, and thus the stacking strategy must be adjusted according
    to the different stack configurations. Taking into account the limitations of
    conventional methods, we propose an improved approach to accommodate the dynamic
    change in the stack configuration of the storage areas. For the detailed description,
    the following notations are introduced: Notation   \\({A}_{g}\\) Set of storage
    areas for container group \\(g\\), indexed by \\(a\\) \\({S}_{a}\\) Set of stacks
    in storage area \\(a\\), indexed by \\(s\\) \\({K}_{as}\\) Set of weight classes
    designated for stack \\(s\\) in storage area \\(a\\), indexed by \\(k\\) \\({R}_{k}^{g}\\)
    Range of cumulative mixture weight values for weight class \\(k\\) \\({R}_{as}\\)
    Range of cumulative mixture weight values for stack \\(s\\) in storage area \\(a\\)
    \\(a\\left(i\\right)\\) Pre-selected storage area for container \\(i\\) \\(s\\left(i|a\\right)\\)
    Stack to be selected for container \\(i\\) given storage area \\(a\\) \\({t}_{as}\\)
    Remaining slot capacity (in number of containers) of stack \\(s\\) in storage
    area \\(a\\) \\({f}_{as}^{k}\\) Contribution of weight class \\(k\\) to \\({R}_{as}\\)
    for \\(k\\in {K}_{as}^{g}\\) \\({X}_{as}^{g}\\) List of container weights for
    stack \\(s\\) in storage area \\(a\\) of container group \\(g\\) First, we describe
    the procedure for the weight class-to-stack assignment. This assignment satisfies
    a many-to-many relationship. Regarding the GMM-based prediction results for the
    weight class, we focus on the mixture weight \\({\\pi }_{k}^{g}\\), which represents
    the estimated size of the weight class \\(k\\). Given that the indices of the
    GMM are sorted in ascending order according to weight, the cumulative range of
    \\({\\pi }_{k}^{g}\\) for each weight class can be represented by $$R_{k}^{g}
    = \\left\\{ {r : \\mathop \\sum \\limits_{{\\begin{array}{*{20}c} {k^{\\prime}
    \\in K_{g} } \\\\ {k^{\\prime} < k } \\\\ \\end{array} }} \\pi_{{k^{\\prime}}}^{g}
    < r \\le \\mathop \\sum \\limits_{{\\begin{array}{*{20}c} {k^{\\prime} \\in K_{g}
    } \\\\ {k^{\\prime} \\le k } \\\\ \\end{array} }} \\pi_{{k^{\\prime}}}^{g} , r
    \\in {\\mathbb{R}}} \\right\\}.$$ (4) Likewise, given that the indices of the
    stacks are sorted, the cumulative range of \\({\\pi }_{k}^{g}\\) for each stack
    can be represented by $$R_{as} = \\left\\{ {r :\\mathop \\sum \\limits_{{\\begin{array}{*{20}c}
    {s^{\\prime} \\in S_{a} } \\\\ {s^{\\prime} < s } \\\\ \\end{array} }} C_{a} \\times
    t_{{as^{\\prime}}} < r \\le \\mathop \\sum \\limits_{{\\begin{array}{*{20}c} {s^{\\prime}
    \\in S_{a} } \\\\ {s^{\\prime} \\le s } \\\\ \\end{array} }} C_{a} \\times t_{{as^{\\prime}}}
    , r \\in {\\mathbb{R}}} \\right\\},{ }$$ (5) where \\({C}_{a}=1/\\sum_{s\\in {S}_{a}}{t}_{as}\\).
    Equation (5) calculates the coverage range for each stack based on the number
    of remaining slots, \\({t}_{as}\\). For example, if the storage area consists
    of four empty stacks, the cumulative ranges \\({R}_{as}\\) are set to (0, 0.25],
    (0.25, 0.5], (0.5, 0.75], and (0.75, 1]. Then, $$K_{as}^{g} = \\left\\{ {k: R_{k}^{g}
    \\cap R_{as} \\ne \\emptyset , k \\in K_{g} } \\right\\}$$ (6) defines the weight
    class-to-stack assignment \\({K}_{as}^{g}\\) such that the membership of the weight
    classes in a stack is determined by whether the elements of \\({R}_{k}^{g}\\)
    lie in the specified \\({R}_{as}\\). The variable \\({K}_{as}^{g}\\) is continuously
    adjusted because dynamic container placements change \\({t}_{as}\\), which impact
    \\({R}_{as}\\). Figures 6 and 7 provide an example of the adjustment mechanism
    in the weight class-to-stack assignment procedure. It is supposed that two storage
    areas are assigned containers that belong to the same container group. The number
    of weight classes is set to four for the container group, and the number of stacks
    is set to four for both storage areas. The mixture weights \\({\\pi }_{k}^{g}\\)
    are set to 0.25 for all weight classes. Figure 6 shows the initialized \\({K}_{as}^{g}\\)
    in which there are no differences between the storage areas. Fig. 6 Illustration
    of an initialized weight class-to-stack assignment (\\({{\\varvec{\\pi}}}_{{\\varvec{k}}}^{{\\varvec{g}}}=0.25\\;{\\mathbf{for}\\;\\mathbf{k}}=1,2,3,4\\))
    Full size image Fig. 7 Illustration of an adjusted weight class-to-stack assignment
    (\\({{\\varvec{\\pi}}}_{{\\varvec{k}}}^{{\\varvec{g}}}=0.25\\;{\\mathbf{for}\\;\\mathbf{k}}=1,2,3,4\\))
    Full size image In contrast, Fig. 7 shows the adjusted \\({K}_{as}^{g}\\) after
    a total of 22 containers are stacked. The adjustment varies depending on the storage
    area. We now elaborate the steps to derive \\({K}_{as}^{g}\\) for storage area
    “A” using Eqs. (4)-(6). First, \\({R}_{k}^{g}\\) is always (0, 0.25], (0.25, 0.5],
    (0.5, 0.75], and (0.75, 1] for the weight classes. Second, \\({R}_{as}\\) is initialized
    as (0, 0.25], (0.25, 0.5], (0.5, 0.75], and (0.75, 1] for the empty storage area.
    After three, three, one, and three containers are stacked in each stack, \\({R}_{as}\\)
    is updated as (0, 0.2], (0.2, 0.4], (0.4, 0.8], and (0.8, 1] for the stacks. Therefore,
    it is necessary to check whether there is an overlap between \\({R}_{k}^{g}\\)
    and \\({R}_{as}\\). For weight class 1, the infimum and supremum of \\({R}_{k}^{g}\\)
    lie in \\({R}_{as}\\) for stacks 1 and 2, respectively. Accordingly, \\({K}_{as}^{g}\\)
    of weight class 1 includes stacks 1 and 2. In this way, the \\({K}_{as}^{g}\\)
    of the weight classes are dynamically updated when the stack configuration is
    changed, establishing the stacking strategy specific to the storage area. Next,
    we describe the procedure for the storage location assignment for a container,
    given the weight class-to-stack assignment. Regarding the GMM-based prediction
    results for the weight class, we focus on the responsibility value \\(\\gamma
    \\left({z}_{k}^{g}|g\\right)\\), which represents the probability that a container
    belongs to a certain weight class. If a single weight class is assigned to each
    stack (e.g., the weight class-to-stack assignment is 1–1, 2–2, 3–3, 4–4), as shown
    in Fig. 6, an effective strategy is to select a stack with the largest \\(\\gamma
    \\left({z}_{k}^{g}|g\\right)\\) for the corresponding weight class \\(k\\). However,
    because multiple weight classes can be assigned to each stack, as shown in Fig.
    7, a more sophisticated strategy that considers the contributions of multiple
    weight classes should be employed. In this context, $$f_{as}^{k} = {\\text{min}}\\left\\{
    {\\sup R_{k}^{g} ,\\sup R_{as} } \\right\\} - {\\text{max}}\\left\\{ {\\inf R_{k}^{g}
    ,\\inf R_{as} } \\right\\}$$ (7) defines the contribution of weight class \\(k\\)
    to \\({R}_{as}\\). Then, $$s\\left( {i{|}a} \\right) = \\mathop {{\\text{argmax}}}\\limits_{{s
    \\in S_{a} }} \\mathop \\sum \\limits_{{k \\in K_{as}^{g\\left( i \\right)} }}
    C_{as} \\times f_{as}^{k} \\times \\gamma \\left( {z_{k} {|}g\\left( i \\right)}
    \\right),$$ (8) where \\({C}_{as}=1/\\sum_{k\\in {K}_{as}^{g\\left(i\\right)}}{f}_{as}^{k}\\),
    indicates the proposed strategy that ensures the selection of a stack with the
    largest weighted average of \\(\\gamma \\left({z}_{k}^{g}|g\\right)\\) according
    to the normalized \\({f}_{as}^{k}\\). Figure 8 provides an example of the storage
    location assignment procedure, extending the example for storage area “A” in Fig.
    7. In this example, \\({f}_{as}^{k}\\) of stack 1 is derived as \\({f}_{A1}^{1}=\\mathrm{min}\\left\\{\\mathrm{0.25,0.2}\\right\\}-\\mathrm{max}\\left\\{\\mathrm{0,0}\\right\\}=0.2-0=0.2\\)
    for weight class 1. Similarly, the resulting \\({f}_{as}^{k}\\) of stack 2 for
    weight classes 1 and 2 are \\({f}_{A2}^{1}=0.25-0.2=0.05\\) and \\({f}_{A2}^{2}=0.4-0.25=0.15\\),
    respectively. Then the weighted averages of \\(\\gamma \\left({z}_{k}^{g}|g\\right)\\)
    are derived as \\({f}_{A1}^{1}/{f}_{A1}^{1}\\times \\gamma \\left({z}_{1}^{g}|g\\right)\\)
    for stack 1 and \\({f}_{A2}^{1}/\\left({f}_{A2}^{1}+{f}_{A2}^{2}\\right)\\times
    \\gamma \\left({z}_{1}^{g}|g\\right)+{f}_{A2}^{2}/\\left({f}_{A2}^{1}+{f}_{A2}^{2}\\right)\\times
    \\gamma \\left({z}_{2}^{g}|g\\right)\\) for stack 2. Thus, for a new container
    input, the stack that yields the largest weighted average of \\(\\gamma \\left({z}_{k}^{g}|g\\right)\\)
    is selected among all the stacks in the given storage area. Fig. 8 Illustration
    of the storage location assignment procedure (\\({{\\varvec{\\pi}}}_{{\\varvec{k}}}^{{\\varvec{g}}}=0.25\\;{\\mathbf{for}\\;\\mathbf{k}}=1,2,3,4\\))
    Full size image The overall procedure of the DSS is described by Algorithm 1.
    4 Numerical experiments We conducted numerical experiments to validate the data-driven
    DSS (also called a GMM-DSS), which features the GMM-based weight clustering and
    dynamic adjustment mechanism for storage location assignment. We illustrate the
    improvements achieved by our proposed method through the experiments comparing
    with the stacking strategies that do not employ GMMs and/or dynamic adjustment
    mechanisms. First, the input data in the numerical experiment are described. Second,
    as a result of module 1, the generated GMM to define the weight class for each
    test instance is reported. Third, the impacts of the unit number of stacks on
    the algorithm performance are analyzed. Finally, an analysis comparing the stacking
    performances of the container stacking strategies is presented. This analysis
    shows how the wealth of data can be applied in the CSP to provide valuable decision
    support. All the algorithms were coded in Python and executed on a PC with an
    i5-6600H 3.3 GHz Intel Core processor and 8.0 GB of RAM. 4.1 Input data The input
    data used in the numerical experiments were collected for 10 months in 2018 from
    a typical container terminal in Busan, Republic of Korea. The original data included
    detailed container information, such as the time of arrival and departure, departing
    vessel, POD, size, type, and weight of each container. Because the stacking decisions
    are made according to the container group, the original data were classified into
    container groups with the same attributes (e.g., departing vessel, POD, size,
    and type). In addition, only 20-foot containers were used in this study. Subsequently,
    a dataset of 12 container groups was used for the analysis. Table 1 reports the
    details of the selected 12 instances. Table 1 Test instances for numerical experiments
    Full size table Next, we present the input data distributions over the entire
    voyage to check the justification for converting the container weights. This analysis
    comes from our assumption that the probability distribution of the container weights
    can be made available from the historical data due to the repeated tendencies
    over the voyage. It is rarely studied in literature to handle the information
    on container weights. Only a few studies, such as Kang et al. (2006) and Zhang
    et al. (2014b), utilized the true probability distribution or portion of the weight
    groups assuming such information is given or estimated by analysis of historical
    data in advance. Figure 9 shows the distribution of the container weights over
    the entire voyage for instances 4 and 7. The x-axis indicates the range of container
    weight uniformly divided by 10 classes, and the y-axis indicates the number of
    containers for each voyage which is normalized to a value between 0 and 1. In
    this case, the distribution of container weights was similar over the entire voyage
    of the same instance. This is reasonable because the composition of the export
    cargo tends to be similar for each voyage. Due to the extensive data, GMM-based
    predictions for weight classes can be a powerful tool for effective category stacking
    in yards. Fig. 9 Distribution of container weights over the entire voyage (Instances
    4 and 7) Full size image For container groups of a general type, the terminal
    had 19 blocks consisting of 50 bays each, as well as 10 stacks and six tiers.
    The storage area for the same container group was reserved in a unit of stacks.
    Because the unit number of stacks is usually set to 10 stacks (i.e., one bay)
    or five stacks, we conducted the experiments for both cases where the experimental
    results are presented in Sect. 4.5. The total number of storage areas was set
    to the minimum value required for the corresponding container group. Considering
    the buffer storage space for rehandling operations that exists in practice, the
    maximum allowable tier for containers was limited to the fifth tier. 4.2 Design
    of experiments For each instance in this study, we divided a training dataset
    for generating the GMM in module 1 and a test dataset for simulation. The test
    dataset is constructed by randomly selecting a voyage and collecting a corresponding
    list of loaded containers from the historical data of the test ship-lanes (test
    instances). The training dataset is the remainder of historical data except for
    the test dataset. The results of GMM-based clustering with the training dataset
    are provided in Sect. 4.3, followed by sensitivity and comparative analysis results.
    In simulation experiments, two kinds of randomness are considered: the container
    arrival sequence and assignment to a storage area. The detailed list of the to-be-stacked
    containers is unknown in advance and even unpredictable in practice. Further,
    a pre-selected storage area is given because the designation of the storage area
    for an arriving container is dynamically assigned depending on the workload of
    the YC. Therefore, the container arrival sequence was made by randomly selecting
    a container list in the test dataset, and a storage area was randomly assigned
    to a container in the simulations. The stacking performance was evaluated based
    on category stacking, which aims to cluster containers with similar weights into
    the same stack. Therefore, we introduced an evaluation function $$E\\left( g \\right)
    = \\frac{{\\mathop \\sum \\nolimits_{{a \\in A_{g} }} \\mathop \\sum \\nolimits_{{s
    \\in S_{a} }} SD\\left( {X_{as}^{g} } \\right)}}{{\\mathop \\sum \\nolimits_{{a
    \\in A_{g} }} \\left| {S_{a} } \\right|}},$$ (9) where the standard deviation
    of the container weights in the stack was measured. The evaluation function \\(E\\left(g\\right)\\)
    indirectly minimizes the makespan during future loading operations for a given
    category stacking strategy. 4.3 GMM-based clustering for container weights Using
    12 test instances, we employed the GMM method to cluster the container weights
    into \\(K\\) clusters. For the training data, a set of preliminary experiments
    was conducted to investigate the appropriate value of \\(K\\) for each test instance,
    varying \\(K\\) from 1 to 5 in steps of 1. The value of \\(K\\) was assigned the
    smallest value based on the Bayesian information criterion (BIC). Figure 10 shows
    the resulting GMM for the two test instances. The histogram in Fig. 10 indicates
    that the container weights exhibited a multi-peak distribution, and in both instances,
    it can be seen that five clusters are most appropriate. Figure 10 shows that GMM
    obtained via statistical modeling reasonably represents a distribution that is
    difficult to express as a single normal distribution. The results of module 1
    for all the instances are presented in Appendix A. Fig. 10 Histogram and GMM-based
    density curve of the container weights (Instances 7 and 11) Full size image 4.4
    Sensitivity analysis of the unit number of stacks This section validates the performance
    of GMM-DSS according to the unit number of stacks. The unit number of stacks within
    a storage area is usually set to 10 stacks for export containers, but it varies
    from terminal to terminal. For the sensitivity analysis of the unit number of
    stacks, \\(\\left|{S}_{a}\\right|\\) was set to 5, 10, 15, and 20. The GMM was
    generated using the training dataset, and then GMM-DSS was implemented using the
    test dataset. Table 2 reports the change in the average of \\(E\\left(g\\right)\\)
    according to the variation in the unit number of stacks \\(\\left|{S}_{a}\\right|\\).
    In the case of instance 1, it was excluded from experiments on more than 15 stacks
    as the number of tested containers was less than 50. In most instances, it is
    observed that \\(E\\left(g\\right)\\) decreases as the unit number of stacks increases.
    These results imply that as the number of unit stacks increases, the weight distribution
    of containers may have been relatively stable and homogeneous over storage areas
    since the containers are less scattered into multiple storage areas. Meanwhile,
    Instances 3, 5, and 6 yield the minimum \\(E\\left(g\\right)\\) when the unit
    number of stacks is equivalent to 10 and 15, although the differences of \\(E\\left(g\\right)\\)
    in instances are not significant. The GMM-DSS works reliably to comply with the
    category stacking strategy, including the case of 10 stacks widely used in container
    terminals. Thus it is believed to be worth being introduced into the terminal
    operating system. Table 2 Impact of the unit number of stacks on average \\({\\varvec{E}}\\left({\\varvec{g}}\\right)\\)
    Full size table 4.5 Comparative analysis of container stacking strategies For
    comparison purposes, we implemented four alternative stacking strategies: a GMM-based
    static stacking strategy (GMM-SS), current practice, hybrid sequence stacking
    strategy (HSSS), and a random stacking strategy (RSS). For the GMM-SS, the weight
    classes and storage locations of the containers were determined by our GMM-based
    dynamic stacking strategy (GMM-DSS), while the dynamic adjustment mechanism in
    the weight class-to-stack assignment was ignored. For the current practice, the
    weight classes were defined by dividing the container weights into weight classes
    by ‘number of stacks in a bay,’ where each weight class has equal size of weight
    range according to the historical data. In addition, the storage locations of
    the containers were determined in such a way that the stack and weight classes
    were allocated on a one-to-one basis. For the HSSS proposed by Chen and Lu (2012),
    the weight classes were defined by dividing the container weights weight classes
    by ‘(number of stacks in a bay)\\(+\\)(number of tiers in a stack)\\(-3.\\)’ Then,
    HSSS induces heavier containers to be stacked in the left upper locations and
    lighter containers to be stacked in the right lower locations. In the RSS, the
    containers were stacked in a way that filled the stack sequentially according
    to the arrival order without considering the container weights. All five strategies,
    including our proposed method, were executed in seconds; thus, they are suitable
    for an online algorithm. We conducted a simulation to compare the proposed method
    to the four alternative strategies for two different cases where the unit of storage
    area is five stacks or 10 stacks. The resulting performance for the stacking strategies
    is presented in Tables 3 and 4 for the cases in terms of the average \\(E\\left(g\\right)\\)
    for 100 repetitions. For both cases, the proposed GMM-DSS method obtained the
    minimum \\(E\\left(g\\right)\\) on average for all test instances. Specifically,
    for the case of five stacks in Table 3, the GMM-DSS performed better than the
    GMM-SS by 6.0%. This is the result of the dynamic adjustment mechanism in the
    weight class-to-stack assignment. In addition, the performance of the GMM-DSS
    was better than the current practice, HSSS, and RSS by 33.1, 41.6 and 44.1%, respectively.
    This result implies that the proposed method was more effective as the data-driven
    approach as well as the dynamic adjustment mechanism was incorporated into the
    stacking strategy. For the case of 10 stacks in Table 4, the results show that
    proposed method is superior to the other methods as in the case of five stacks.
    The performance of the GMM-DSS was better than the GMM-SS, current practice, HSSS,
    and RSS by 8.1, 43.6, 52.8, and 59.6%, respectively. Moreover, Fig. 11 demonstrates
    the robust performance of our proposed method for the experimental repetitions.
    The current practice performed better on average than the HSSS and RSS, and the
    proposed GMM-DSS and GMM-SS are dominant over the current practice. Therefore,
    we can conclude that the proposed GMM-DSS method is worth introducing in practice
    because it has the most reliable and best performance. Table 3 Experimental results
    for the test instances (the unit of storage area = five stacks) Full size table
    Table 4 Experimental results for the test instances (the unit of storage area = 10
    stacks) Full size table Fig. 11 Box plots of experimental results for \\(E\\left(g\\right)\\)
    after 100 repetitions (the unit of storage area = 10 stacks, Instances 10 and
    12) Full size image 4.6 Comparative analysis according to variability This section
    validates the algorithm performances according to variability in container weights.
    The proposed GMM-DSS utilizes the information on container weights from historical
    data and creates a GMM to approximate the distribution of container weights; thus
    it should be verified whether the GMM-DSS and GMM-SS can yield robust performance
    under a certain degree of variability. To this end, container weights \\(x\\left(i\\right){^{\\prime}}\\)
    for the test were randomly generated as follows: \\({x\\left(i\\right)}^{^{\\prime}}=\\mathrm{min}\\left(\\mathrm{max}\\left(x\\left(i\\right)+500\\times
    \\sigma \\times N\\left(0, 1\\right),LB\\left(i\\right)\\right),UB\\left(i\\right)\\right)\\)(kg),
    where \\(x\\left(i\\right)\\) is a randomly selected sample data from the training
    dataset, \\(\\sigma\\) is related to the variability, \\(N\\left(0, 1\\right)\\)
    is the random generator from a standard normal distribution, and \\(LB\\left(i\\right)\\)
    and \\(UB\\left(i\\right)\\) are the lower bound and upper bound on weights of
    container \\(i\\) introduced to avoid extreme values. \\(\\sigma\\) was set to
    0, 1, 2, 3, and 4. Figure 12 shows the performance of five stacking algorithms
    for the experimental repetitions under variability on container weights. For all
    the cases of σ, the proposed GMM-DSS and GMM-SS dominantly outperform the other
    algorithms in terms of \\(E\\left(g\\right)\\). GMM-DSS slightly outperforms GMM-SS.
    Furthermore, although performance degrades as variability increases, there is
    no significant difference in the change compared to other algorithms. Thus, it
    can be concluded that the proposed algorithms are robust to variabilities by taking
    advantage of predictive analytics. Fig. 12 Results according to variability on
    \\(E\\left(g\\right)\\) (the unit of storage area = 10 stacks, Instances 5 and
    9) Full size image 5 Conclusion The goal of this paper is to introduce the wealth
    of data generated by the container terminal into the methodology of determining
    the storage location of the arriving containers. We presented a two module-based
    DSS to manage the CSP in container terminals. In our study, the CSP was solved
    by a category stacking strategy to facilitate stowage planning. In contrast to
    previous studies, the proposed method applies predictive analytics for container
    weight classification using historical data, and container assignment to a specific
    storage area is executed dynamically to outperform the existing stacking strategies.
    To the best of our knowledge, these two main features have not been introduced
    in the literature before. Specifically, in module 1, we generated a container
    group-specific GMM for container weight classification. In module 2, we implemented
    the DSS as an online algorithm to determine the storage location of an arriving
    container in real time. We conducted numerical experiments to validate the effectiveness
    of the proposed method using real-life data from a typical container terminal
    in Busan, Republic of Korea. For the generality of terminal environments, two
    different cases for the reservation unit in a storage area are considered in the
    experiments. The experimental results showed that the proposed method outperforms
    four other alternative stacking strategies (i.e., the GMM-SS, current practice,
    HSSS, and RSS). Therefore, our proposed method performs robustly and can further
    improve yard operations and terminal competitiveness. The experimental results
    are encouraging in that it implies that the improvements in the stacking performance
    are related to the category stacking. The proposed method is expected to achieve
    greater improvements in practice when data-driven inferences can be derived from
    more historical data. In future research, our method could be extended to transshipment
    containers by considering the detailed characteristics of those operations. In
    addition, novel stacking strategies, such as the flexible space-sharing strategy
    and related operations such as stowage planning, could be integrated into our
    method to generate greater effectiveness in terminal operations. Availability
    of data and material Not applicable. Code availability Not applicable. References
    Ambrosino D, Caballini C, Siri S (2013) A mathematical model to evaluate different
    train loading and stacking policies in a container terminal. Marit Econo Logist
    15(3):292–308. https://doi.org/10.1057/mel.2013.7 Article   Google Scholar   Borgman
    B, van Asperen E, Dekker R (2010) Online rules for container stacking. OR Spectr
    32(3):687–716. https://doi.org/10.1007/s00291-010-0205-4 Article   MATH   Google
    Scholar   Carlo HJ, Vis IF, Roodbergen KJ (2014) Storage yard operations in container
    terminals: literature overview, trends, and research directions. Eur J Oper Res
    235(2):412–430. https://doi.org/10.1016/j.ejor.2013.10.054 Article   MATH   Google
    Scholar   Chen L, Lu Z (2012) The storage location assignment problem for outbound
    containers in a maritime terminal. Int J Prod Econ 135(1):73–80. https://doi.org/10.1016/j.ijpe.2010.09.019
    Article   Google Scholar   De Castillo B, Daganzo CF (1993) Handling strategies
    for import containers at marine terminals. Transp Res B Methodol 27(2):151–166.
    https://doi.org/10.1016/0191-2615(93)90005-U Article   Google Scholar   Dekker
    R, Voogd P, Asperen EV (2006) Advanced methods for container stacking. OR Spectr
    28(4). https://doi.org/10.1007/s00291-006-0038-3 Duinkerken MB, Evers JJ, Ottjes
    JA (2001) A simulation model for integrating quay transport and stacking policies
    on automated container terminals. In: Proceedings of the 15th European Simulation
    Multiconference, pp 909–916. Feng Y, Song DP, Li D (2021) Smart stacking for import
    containers using customer information at automated container terminals. Eur J
    Oper Res. https://doi.org/10.1016/j.ejor.2021.10.044 Article   MATH   Google Scholar   Figueiredo
    MAT, Jain AK (2002) Unsupervised learning of finite mixture models. IEEE Trans
    Pattern Anal Mach Intell 24(3):381–396. https://doi.org/10.1109/34.990138 Article   Google
    Scholar   Güven C, Eliiyi DT (2014) Trip allocation and stacking policies at container
    terminal. Transp Res Proc 3:565–573. https://doi.org/10.1016/j.trpro.2014.10.035
    Article   Google Scholar   Güven C, Eliiyi DT (2019) Modelling and optimisation
    of online container stacking with operational constraints. Marit Policy Manag
    46(2):201–216. https://doi.org/10.1080/03088839.2018.1450529 Article   Google
    Scholar   He J, Tan C, Yan W, Huang W, Liu M, Yu H (2020a) Two-stage stochastic
    programming model for generating container yard template under uncertainty and
    traffic congestion. Adv Eng Inform 43:101032. https://doi.org/10.1016/j.aei.2020.101032
    Article   Google Scholar   He Y, Wang A, Su H (2020b) The impact of incomplete
    vessel arrival information on container stacking. Int J Prod Res 58(22):6934–6948.
    https://doi.org/10.1080/00207543.2019.1686188 Article   Google Scholar   Hu W,
    Wang H, Min Z (2014) A storage allocation algorithm for outbound containers based
    on the outer–inner cellular automaton. Inf Sci 281:147–171. https://doi.org/10.1016/j.ins.2014.05.022
    Article   MathSciNet   Google Scholar   Hu H, Mo J, Zhen L (2021) Improved Benders
    decomposition for stochastic yard template planning in container terminals. Transp
    Res c Emerg Technol 132:103365. https://doi.org/10.1016/j.trc.2021.103365 Article   Google
    Scholar   Jiang XJ, Jin JG (2017) A branch-and-price method for integrated yard
    crane deployment and container allocation in transshipment yards. Transp Res B
    Methodol 98:62–75. https://doi.org/10.1016/j.trb.2016.12.014 Article   Google
    Scholar   Kang J, Ryu KR, Kim KH (2006) Deriving stacking strategies for export
    containers with uncertain weight information. J Intell Manuf 17(4):399–410. https://doi.org/10.1007/s10845-005-0013-x
    Article   Google Scholar   Karp RM (1992) On-line algorithms versus off-line algorithms:
    How much is it worth knowing the future? In: IFIP Congress (1), Vol. 12, pp. 416–429.
    Kim KH, Kim HB (1999) Segregating space allocation models for container inventories
    in port container terminals. Int J Prod Econ 59(1–3):415–423. https://doi.org/10.1016/S0925-5273(98)00028-0
    Article   Google Scholar   Kim KH, Kim HB (2002) The optimal sizing of storage
    space and handling facilities for import containers. Transp Res B Methodol 36(9):821–835.
    https://doi.org/10.1016/S0191-2615(01)00033-9 Article   Google Scholar   Kim KH,
    Park YM, Ryu KR (2000) Deriving decision rules to locate export containers in
    container yards. Eur J Oper Res 124(1):89–101. https://doi.org/10.1016/S0377-2217(99)00116-2
    Article   MATH   Google Scholar   Kim KH, Kang JS, Ryu KR (2004) A beam search
    algorithm for load sequencing of outbound containers in port container terminals.
    OR Spectr 26(1):93–116. https://doi.org/10.1007/s00291-003-0148-0 Article   MATH   Google
    Scholar   Maldonado S, González-Ramírez RG, Quijada F, Ramírez-Nafarrate A (2019)
    Analytics meets port logistics: a decision support system for container stacking
    operations. Decis Support Syst 121:84–93. https://doi.org/10.1016/j.dss.2019.04.006
    Article   Google Scholar   Murty KG, Liu J, Wan YW, Linn R (2005) A decision support
    system for operations in a container terminal. Decis Support Syst 39(3):309–332.
    https://doi.org/10.1016/j.dss.2003.11.002 Article   Google Scholar   Park T, Choe
    R, Kim YH, Ryu KR (2011) Dynamic adjustment of container stacking policy in an
    automated container terminal. Int J Prod Econ 133(1):385–392. https://doi.org/10.1016/j.ijpe.2010.03.024
    Article   Google Scholar   Sauri S, Martin E (2011) Space allocating strategies
    for improving import yard performance at marine terminals. Transp Res E Logist
    Transp Rev 47(6):1038–1057. https://doi.org/10.1016/j.tre.2011.04.005 Article   Google
    Scholar   Stahlbock R, Voß S (2008) Operations research at container terminals:
    a literature update. OR Spectr 30(1):1–52. https://doi.org/10.1007/s00291-007-0100-9
    Article   MathSciNet   MATH   Google Scholar   Steenken D, Voß S, Stahlbock R
    (2004) Container terminal operation and operations research—a classification and
    literature review. OR Spectr 26(1):3–49. https://doi.org/10.1007/s00291-003-0157-z
    Article   MATH   Google Scholar   Ting SC, Wang JS, Kao SL, Pitty FM (2010) Categorized
    stacking models for import containers in port container terminals. Marit Econ
    Logist 12(2):162–177. https://doi.org/10.1057/mel.2010.4 Article   Google Scholar   Vis
    IF, De Koster R (2003) Transshipment of containers at a container terminal: an
    overview. Eur J Oper Res 147(1):1–16. https://doi.org/10.1016/S0377-2217(02)00293-X
    Article   MATH   Google Scholar   Zhang C, Liu J, Wan YW, Murty KG, Linn RJ (2003)
    Storage-space allocation in container terminals. Transp Res B Methodol 37(10):883–903.
    https://doi.org/10.1016/S0191-2615(02)00089-9 Article   Google Scholar   Zhang
    C, Chen W, Shi L, Zheng L (2010) A note on deriving decision rules to locate export
    containers in container yards. Eur J Oper Res 205(2):483–485. https://doi.org/10.1016/j.ejor.2009.12.016
    Article   MATH   Google Scholar   Zhang C, Wu T, Kim KH, Miao L (2014a) Conservative
    allocation models for outbound containers in container terminals. Eur J Oper Res
    238(1):155–165. https://doi.org/10.1016/j.ejor.2014.03.040 Article   MathSciNet   MATH   Google
    Scholar   Zhang C, Wu T, Zhong M, Zheng L, Miao L (2014b) Location assignment
    for outbound containers with adjusted weight proportions. Comput Oper Res 52:84–93.
    https://doi.org/10.1016/j.cor.2014.06.012 Article   MathSciNet   MATH   Google
    Scholar   Zhen L (2013) Yard template planning in transshipment hubs under uncertain
    berthing time and position. J Oper Res Soc 64(9):1418–1428. https://doi.org/10.1057/jors.2012.108
    Article   Google Scholar   Zhen L (2014) Container yard template planning under
    uncertain maritime market. Transp Res E Logist Transp Rev 69:199–217. https://doi.org/10.1016/j.tre.2014.06.011
    Article   Google Scholar   Zhou C, Wang W, Li H (2020) Container reshuffling considered
    space allocation problem in container terminals. Transp Res E Logist Transp Rev
    136:101869. https://doi.org/10.1016/j.tre.2020.101869 Article   Google Scholar   Download
    references Acknowledgements The authors are grateful to the anonymous reviewers
    for reading the manuscript carefully and providing constructive comments which
    greatly helped to improve this paper. Funding This research is a part of the project
    titled “Development of Open Platform Technologies for Smart Maritime Safety and
    Industries” funded by the Korea Research Institute of Ships and Ocean Engineering
    (PES4450). Author information Authors and Affiliations Maritime Safety and Environmental
    Research Division, Korea Research Institute of Ships and Ocean Engineering, Daejeon,
    Republic of Korea Hyun Ji Park, Sung Won Cho, Abhilasha Nanda & Jin Hyoung Park
    Contributions HJP: Conceptualization of this study, Methodology, Validation, Formal
    analysis, Writing—Original Draft, Writing—Review Editing. SWC: Conceptualization
    of this study, Methodology, Formal analysis, Writing—Original Draft, Writing—Review
    Editing, Project administration, Supervision. AN: Software, Data Curation, Visualization.
    JHP: Writing—Review Editing, Project administration, Supervision, Funding acquisition.
    Corresponding author Correspondence to Sung Won Cho. Ethics declarations Conflict
    of interest The authors declare no conflict of interest. Additional information
    Publisher''s Note Springer Nature remains neutral with regard to jurisdictional
    claims in published maps and institutional affiliations. Appendix A: The results
    of module 1 for the test instances Appendix A: The results of module 1 for the
    test instances See Table 5. Table 5 Parameters of GMM Full size table Rights and
    permissions Open Access This article is licensed under a Creative Commons Attribution
    4.0 International License, which permits use, sharing, adaptation, distribution
    and reproduction in any medium or format, as long as you give appropriate credit
    to the original author(s) and the source, provide a link to the Creative Commons
    licence, and indicate if changes were made. The images or other third party material
    in this article are included in the article''s Creative Commons licence, unless
    indicated otherwise in a credit line to the material. If material is not included
    in the article''s Creative Commons licence and your intended use is not permitted
    by statutory regulation or exceeds the permitted use, you will need to obtain
    permission directly from the copyright holder. To view a copy of this licence,
    visit http://creativecommons.org/licenses/by/4.0/. Reprints and permissions About
    this article Cite this article Park, H.J., Cho, S.W., Nanda, A. et al. Data-driven
    dynamic stacking strategy for export containers in container terminals. Flex Serv
    Manuf J 35, 170–195 (2023). https://doi.org/10.1007/s10696-022-09457-8 Download
    citation Accepted 05 June 2022 Published 27 June 2022 Issue Date March 2023 DOI
    https://doi.org/10.1007/s10696-022-09457-8 Share this article Anyone you share
    the following link with will be able to read this content: Get shareable link
    Provided by the Springer Nature SharedIt content-sharing initiative Keywords Container
    terminals Container stacking problem (CSP) Machine learning Gaussian mixture model
    (GMM) Use our pre-submission checklist Avoid common mistakes on your manuscript.
    Sections Figures References Abstract Introduction Literature review Problem description
    Numerical experiments Conclusion Availability of data and material Code availability
    References Acknowledgements Funding Author information Ethics declarations Additional
    information Appendix A: The results of module 1 for the test instances Rights
    and permissions About this article Advertisement Discover content Journals A-Z
    Books A-Z Publish with us Publish your research Open access publishing Products
    and services Our products Librarians Societies Partners and advertisers Our imprints
    Springer Nature Portfolio BMC Palgrave Macmillan Apress Your privacy choices/Manage
    cookies Your US state privacy rights Accessibility statement Terms and conditions
    Privacy policy Help and support 129.93.161.219 Big Ten Academic Alliance (BTAA)
    (3000133814) - University of Nebraska-Lincoln (3000134173) © 2024 Springer Nature"'
  inline_citation: '>'
  journal: Flexible Services and Manufacturing Journal
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Data-driven dynamic stacking strategy for export containers in container
    terminals
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Fenton K.
  - Simske S.
  - Luu J.
  citation_count: '2'
  description: 'In the United States alone, approximately 2 billion tons of hazardous
    material products are manufactured each year for both household and industrial
    applications and contribute to thousands of worker chemical exposures with as
    many as 50,000 deaths from prolonged exposure each year. The potential hazards
    and impacts of these chemicals for human health and the environment are primarily
    communicated to the public through Safety Data Sheets (SDSs) from the chemical
    vendors or distributors. These documents provide a standardized approach for how
    and what information is provided to product users to assist them with assessment
    of precautionary measures, hazard mitigation, emergency response or cleanup procedures,
    and environmental, health, and safety (EHS) management. Despite the criticality
    for hazard communication (HAZCOM) precision, legacy SDS management and industry
    business practices leave the overall ability to effectively manage chemicals vulnerable
    to significant liability through a lack of full constituent disclosure, injection
    of data quality errors through various handling of SDS information and manual
    data entry, and the lack of direct SDS-to-product association. Chemical spills
    and accidents often require individuals to look for the appropriate SDS on a local
    computer, online, or in workplace binders; each of which results in information
    returned that is often found to be outdated or incorrect. Workplace HAZCOM violations
    remain among the top citations during EHS inspections by regulatory agencies.
    More important, however, is the lack of precise association of SDS to hazardous
    products that can occur through chemical management lifecycles. Incorrect SDSs
    can yield significant liability, as subsequent environmental and occupational
    health analyses and reporting are based upon incorrect and, in some cases, entirely
    different chemical formulations. This paper focuses on the need for a paradigm
    shift in our chemical management systems and how a standardized management system
    and various recent technological advances can be incorporated into Environmental
    Management System operations to reduce or eliminate these liabilities. The following
    advancements can be used to enhance the lifecycle management of workplace chemicals,
    reduce potential exposure and spill risks, reduce workplace hazards, and increase
    the efficiency and accuracy of environmental reporting through a more streamlined
    systems approach. EHS system enhancement applications discussed in this paper
    include the following: the need for a centralized universal SDS repository with
    full chemical disclosure of all product constituents and a nationally adopted
    machine language SDS standard. The use of artificial intelligence/machine learning
    in environmental systems and how they can be used as a medium to transition toward
    an automated standard by reverse-engineering and partitioning SDS components into
    machine-encoded text that can be validated and uploaded to a centralized repository.
    Algorithmic and meta-algorithmic approaches to SDS requirement and data validation,
    hazard characteristic code calculations, and determination of potentially less
    hazardous substitutions. Application of Natural Language Processing methods for
    real-time updates from scientific journals, regulatory agencies, and other reputable
    sources to produce “living” SDSs capable of informing users of relevant regulatory
    updates, news, and research. Embedded SDSs or SDS links in product barcodes with
    QR code reader technology to retrieve precise SDSs for each product in emergency
    situations. Use of advanced QR codes embedding authentication layers, authenticity
    verification, and alerts of potential product or inventory problems or discrepancies.
    Benefits of radio frequency identification technology in providing accurate SDS
    associations while also minimizing manual tracking of hazardous material and hazardous
    waste containers and monitoring for expired shelf life, incompatible storage,
    temperature sensitivities, and other inventory concerns.'
  doi: 10.1021/acsomega.2c07244
  full_citation: '>'
  full_text: '>

    "ACS ACS Publications C&EN CAS Access provided byUNIV OF NEBRASKA - LINCOLN Log
    In Pair your account to your Institution Click the pair button to affiliate your
    institution with your personal account PAIR Turn off this notification more info...
    My Activity Publications ADVERTISEMENT RETURN TO ISSUEPREVARTICLENEXT Mitigation
    of Chemical Reporting Liabilities through Systematic Modernization of Chemical
    Hazard and Safety Data Management Systems Kevin Fenton* , Steve Simske , and Jonathan
    Luu Cite this: ACS Omega 2023, 8, 5, 4928–4936 Publication Date:January 24, 2023
    https://doi.org/10.1021/acsomega.2c07244 Copyright © 2023 The Authors. Published
    by American Chemical Society. This publication is licensed under CC-BY-NC-ND 4.0.
    Article Views 1328 Altmetric 3 Citations 1 LEARN ABOUT THESE METRICS Share Add
    to Export RIS PDF (5 MB) SUBJECTS:Chemical calculations,Industrial manufacturing,Materials,Redox
    reactions,Safety ACS Omega Abstract In the United States alone, approximately
    2 billion tons of hazardous material products are manufactured each year for both
    household and industrial applications and contribute to thousands of worker chemical
    exposures with as many as 50,000 deaths from prolonged exposure each year. The
    potential hazards and impacts of these chemicals for human health and the environment
    are primarily communicated to the public through Safety Data Sheets (SDSs) from
    the chemical vendors or distributors. These documents provide a standardized approach
    for how and what information is provided to product users to assist them with
    assessment of precautionary measures, hazard mitigation, emergency response or
    cleanup procedures, and environmental, health, and safety (EHS) management. Despite
    the criticality for hazard communication (HAZCOM) precision, legacy SDS management
    and industry business practices leave the overall ability to effectively manage
    chemicals vulnerable to significant liability through a lack of full constituent
    disclosure, injection of data quality errors through various handling of SDS information
    and manual data entry, and the lack of direct SDS-to-product association. Chemical
    spills and accidents often require individuals to look for the appropriate SDS
    on a local computer, online, or in workplace binders; each of which results in
    information returned that is often found to be outdated or incorrect. Workplace
    HAZCOM violations remain among the top citations during EHS inspections by regulatory
    agencies. More important, however, is the lack of precise association of SDS to
    hazardous products that can occur through chemical management lifecycles. Incorrect
    SDSs can yield significant liability, as subsequent environmental and occupational
    health analyses and reporting are based upon incorrect and, in some cases, entirely
    different chemical formulations. This paper focuses on the need for a paradigm
    shift in our chemical management systems and how a standardized management system
    and various recent technological advances can be incorporated into Environmental
    Management System operations to reduce or eliminate these liabilities. The following
    advancements can be used to enhance the lifecycle management of workplace chemicals,
    reduce potential exposure and spill risks, reduce workplace hazards, and increase
    the efficiency and accuracy of environmental reporting through a more streamlined
    systems approach. EHS system enhancement applications discussed in this paper
    include the following: the need for a centralized universal SDS repository with
    full chemical disclosure of all product constituents and a nationally adopted
    machine language SDS standard. The use of artificial intelligence/machine learning
    in environmental systems and how they can be used as a medium to transition toward
    an automated standard by reverse-engineering and partitioning SDS components into
    machine-encoded text that can be validated and uploaded to a centralized repository.
    Algorithmic and meta-algorithmic approaches to SDS requirement and data validation,
    hazard characteristic code calculations, and determination of potentially less
    hazardous substitutions. Application of Natural Language Processing methods for
    real-time updates from scientific journals, regulatory agencies, and other reputable
    sources to produce “living” SDSs capable of informing users of relevant regulatory
    updates, news, and research. Embedded SDSs or SDS links in product barcodes with
    QR code reader technology to retrieve precise SDSs for each product in emergency
    situations. Use of advanced QR codes embedding authentication layers, authenticity
    verification, and alerts of potential product or inventory problems or discrepancies.
    Benefits of radio frequency identification technology in providing accurate SDS
    associations while also minimizing manual tracking of hazardous material and hazardous
    waste containers and monitoring for expired shelf life, incompatible storage,
    temperature sensitivities, and other inventory concerns. This publication is licensed
    under CC-BY-NC-ND 4.0. 1. Introduction ARTICLE SECTIONSJump To 1.1. Hazard Communication
    Breakdown Over 2 billion tons of hazardous and toxic chemicals are manufactured
    in the United States each year. (1) According to the 2019 U.S. Environmental Protection
    Agency (EPA) Toxic Release Inventory (TRI), U.S. Federal Facilities alone managed
    a total of 30.7 billion tons of TRI-listed chemicals and production-related waste
    during 2019. (2) Of the 30.7 billion tons managed, 11%, or 3.38 billion tons,
    were released into the environment (proportions released to air, water, and land).
    In addition to environmental concerns, each year in the U.S., thousands of workers
    become sick from workplace chemical exposures with as many as 50,000 people dying
    each year from the adverse effects of long-term chemical exposure. (3) One of
    the primary factors in both the documentation of toxic releases and in the proper
    assessment of workplace exposure hazards is the vendor-communicated Safety Data
    Sheet (SDS) information, which provides the chemical ingredients, composition
    information, physical and chemical attributes, and hazard information needed to
    derive such calculations (Figure 1). Figure 1 Figure 1. 2019 Toxic Release Inventory
    data and locations. The current hazard communication (HAZCOM) system allows for
    opportunities of missing and/or incomplete data and various errors through the
    processing and handling of data through the chemical lifecycle. These issues,
    in turn, lend themselves to other problems including our ability for precise SDS
    selection, fast retrieval of SDSs during emergencies, and accurate cradle-to-grave
    tracking of these hazardous containers. These problems include the following:
    missing SDS data from vendors non-GHS compliant SDSs SDS data errors manual data
    entry errors in downstream user databases costs associated with manual entry of
    data in downstream systems confusion associated with SDSs reproduced by suppliers
    lack of product-to-SDS association incorrect reporting due to tracking inefficiencies
    1.2. Lack of SDS Accessibility, Precision, and Data Quality Correct SDSs are often
    difficult to find due to numerous variations of similar products, variations among
    manufacturers/vendors/distributors, and hosting of SDSs spread across thousands
    of chemical manufacturer domains. Due to these inefficiencies, workplace users
    often receive violations regarding incorrect SDSs, outdated SDSs, and in some
    cases no SDSs for the chemicals they are using. Perhaps of greater concern is
    the liability these issues pose in the form of incorrect chemical calculations
    for environmental compliance and incorrect employee chemical exposure assessments
    (4) resulting in inappropriate personal protective equipment. For example, chemical
    usage for a product with a unit of measure of a gallon (Gal) is calculated by
    (5) Chemical Lbs.Used=∑GalUsed×SpecGrav(lb/gal)×%Chemical ∑ (1) An incorrect SDS
    has the potential to alter the ingredient list, chemical composition, and specific
    gravity (SG) (or density); yielding incorrect usage calculations for the total
    number of product containers associated with that SDS. Liabilities not only exist
    for management of the products themselves but also for treatment, cleanup, and
    disposal. SDS content can be used in support of tort claims in civil litigation
    suits and in determining where the fault lies depending on how the hazardous content
    was reported on the SDS and how the employer used and managed that information.
    (6) In the case of Tolley and Tolley v ACF Industries, the SDS was used as evidence
    to support claims that the employer was aware of an isocyanate hazard. (7) The
    term “SDS” resulted in 814 citations in the legal case repository CaseText.com,
    reflecting the importance of HAZCOM in regard to liabilities for manufacturers,
    employers, and chemical users. SDSs are also used for user-knowledge hazardous
    waste characterization, which could result in incorrect waste treatment or disposal
    with large-scale contamination concerns of landfills and other processing facilities.
    In order to retrieve SDSs for chemical products used in the workplace, chemical
    users are largely responsible for finding the appropriate SDS that corresponds
    with each product used. SDSs are commonly housed on manufacturer websites and
    differ from site to site (including seasonal formulations) with further confusion
    often introduced as distributors can create their own SDSs, making product matches
    difficult. Lastly, not all chemicals in product formulations are required by the
    manufacturer on the SDS. Instead, only those that are deemed as hazardous chemicals
    by the manufacturer. (8) As chemical research progresses and new chemicals are
    added by the EPA as emerging contaminants, (9) liability exists in the now-hazardous
    chemicals that were previously omitted from older SDSs because they were not deemed
    hazardous at the time of SDS creation. As a study in 2002 showed, limitations
    to Material SDSs existed since Occupational Health and Safety Administration (OSHA)
    permitted chemical exclusions when the manufacturer deemed it as non-hazardous
    or protected as a trade secret. (10) These limitations hold true today. Per- and
    polyfluoroalkyl substances (PFASs), for instance, were added under the EPA Toxic
    Substances Control Act (11) and TRI (12) in 2020. Prior SDS for products containing
    these chemicals largely omitted these making it now difficult to quantify PFAS
    inventory and usage in the workforce. 1.3. Manual Process Inefficiencies PDF remains
    the predominant format for the millions of SDSs in circulation today. Downstream
    users rely on the data from these SDSs for environmental, safety, and occupational
    health compliance and must typically hand enter this information into their respective
    compliance systems. Each time manual data entry is performed, potential for data
    quality errors increases, subsequently increasing the potential for compliance
    liability. These PDFs often also require validation by SDS data managers to ensure
    all regulatory fields have been provided and additional follow-up with chemical
    manufacturers for clarification on data fields or requesting additional information
    for necessary compliance calculations. Direct vendor communication of SDSs using
    XML or equivalent transfer methods is needed to eliminate the need for separate
    manual data entry and current outdated communication methods. While some organizations
    have made significant strides in this area (e.g., SDS-XML, EDASx, and SDScomXML),
    a single universal standard has not been adopted by the globally harmonized system
    (GHS) or the Registration, Evaluation, Authorization and restriction of Chemicals
    (REACH) in the European Union. 1.4. Lack of Immediate SDS Retrieval Abilities
    U.S. OSHA listed failures in HAZCOM as the second highest most frequently cited
    standard. (13) In total, 3624 HAZCOM enforcement citations occurred in the fiscal
    year 2019 totaling approximately $4,682,380 in proposed penalties. (14) Unfortunately,
    many current procedures still include maintaining binders of printed SDSs or available
    copies downloaded on neighboring workstations. These methods are consistently
    found during inspections to include numerous records that are the incorrect SDS
    for specific products or are out-of-date, incomplete, and illegible. For environmental,
    health, and safety (EHS) systems that require the loading of SDS for exposure
    and environmental reporting calculations, non-EHS personnel are frequently used
    to find the correct SDS for the products they are using and often not provided
    sufficient training to determine whether SDSs are GHS compliant and the proper
    version for the product. OSHA recommends employers “designate a person(s) responsible
    for maintaining SDSs”; it does not reference training for the nuances of precise
    SDS selection and management. (15) 1.5. Loss in Inventory Accountability Lastly,
    inventory accountability and management are difficult to maintain, as shown in
    a recent study of chemical storage at research laboratories. (16) For hazardous
    material users, maintaining accurate inventory counts, SDS-inventory associations,
    proper material segregation, and usage logs can prove an arduous task provided
    that for many users these are side compliance tasks to their primary duties; often
    what the materials are being used for. While many of the proposed applications
    in this paper are not inherently novel, the applications of these in industry,
    individually and as part of a more robust, integrated system, remain uncommon
    and their use could help improve or resolve many of the more common EHS violations.
    2. EHS Technology Optimization ARTICLE SECTIONSJump To 2.1. Universal SDS Database
    and Repository Benefits: Single accessible source of chemical data for all chemical
    users, elimination of separate duplicative systems across the industry, product
    comparisons for safer product selection, personnel and time savings from researching
    SDSs across thousands of vendor websites, data quality control, point source for
    systems to electronically access SDS data, and the singular source for precise
    SDS access methods. One change that would provide immediate benefit on many of
    these issues is also the most difficult to implement and would require a paradigm
    shift in the regulatory compliance measures imposed on chemical vendors. This
    shift would be for a single universal SDS repository for all chemical users. Although
    some repositories such as SDS.com exist, existing SDS repositories are not all
    inclusive, can require membership payments, and have varying levels of quality
    assurance. A single national or universal SDS repository would allow (and require)
    a standardized SDS formatting directly from manufacturers into one centralized
    database that is accessible by any downstream user requiring SDS information (Figure
    2). Standardized values and format would, in turn, produce a significant reduction
    in varying or missing information, a reduction in back-and-forth communication
    between data users and manufacturers, a significant time and monetary savings
    in accessing thousands of manufacturer websites in addition to reducing duplicative
    loading of SDS across numerous existing repositories. While SDSs largely remain
    on chemical vendor websites or various locations, the complexity for systematic
    improvement remains challenging. Pollutant reduction assessments, including greenhouse
    gases, could be performed much more efficiently by product comparison and allow
    for greater visibility of the usage of these products nationwide. A universal
    SDS system could be created using an existing SDS repository as a model to be
    expanded upon. For example, the Department of Defense (DoD) Hazardous Material
    Information Resource System (17) already serves as an effective repository for
    hundreds of thousands of SDSs while ensuring quality control and includes an XML
    standard for streamlined digital transfer. A system such as this could be expanded
    upon to serve as the singular HAZCOM platform for the public. Figure 2 Figure
    2. Centralized SDS repository. For an effective so-named Universal SDS system,
    the system would need to address the many possible ways SDSs can be received and
    how these varying SDS submittals methods can be consolidated into a single management
    approach. Ideally, SDSs would be transmitted via a user interface directly to
    the centralized repository in a standardized XML or equivalent data transfer form.
    Additionally, for new SDSs creations, a manual creation option would allow vendors
    to efficiently create new GHS-compliant SDSs with immediate loading into the universal
    SDS repository. Finally, the last SDS feature would allow other systems using
    SDSs to communicate the information directly to the centralized universal system
    via interfaces following the same XML or equivalent data standard. Regardless
    of the SDS submittal method, standardized validation algorithms could be run to
    ensure SDSs are complete, GHS compliant, and contain accurate data values. Chemical
    management responsibility has quickly surged to the forefront of global needs
    and a universal SDS system would be a large step in our ability to reduce our
    environmental global footprint while increasing safety and occupational health
    standards. (18) From climate change to chemical exposure reduction, data quality
    and chemical analysis precision are paramount in our ability to gather actionable
    data and use it for effective pollution and exposure reduction. 2.2. Artificial
    Intelligence/Machine Learning for SDS Processing Benefits: Significant reduction
    in manual data entry needs, cost savings, provides transitionary method as industry
    moves toward the streamlined automated approach. While a direct vendor-to-SDS
    repository automated chemical data transfer would be the ideal state, an intermediate
    solution would be needed to transition from our current methodologies to an automated
    approach. For the millions of SDSs that still reside in PDF form, one obstacle
    that many EHS systems have is the need to manually enter chemical information
    from SDSs into their respective systems for reporting calculations and tracking
    needs. The 2012 OSHA HAZCOM Standard provided an economic analysis for the cost
    of compliance, and SDS document management costs were estimated between $75,000
    and $100,000 for small global companies and over $100,000 for larger global companies.
    (19,20) Optical Character Recognition (OCR) allows for these documents to be broken
    down into machine-encoded text using a variety of prominent OCR tools (e.g., Adobe
    Pro, Abbey, and Google Tesseract). One difficulty with SDSs is the vast differences
    in format from manufacturer to manufacturer. Although GHS and REACH regulations
    have provided some structure in required sections, how and where the data is relayed
    to readers varies widely. Artificial neural networks (ANNs) allow us to take OCR
    another step further and use machine learning applications to provide structure
    to unstructured data sets and essentially learn to “read” an SDS and parse desired
    fields as required. The benefits of incorporating this technology can yield significant
    time and monetary savings for organizations that require data entry teams to manually
    load thousands of these documents each year. Various segments of the SDS are essentially
    broken down and classified based upon trained models segregating specific SDS
    values into usable text yielding a level of confidence with each assignment. If
    the level of confidence is sufficient based upon measured thresholds, the values
    are recorded. A meta-algorithmic approach is then applied using a machine learning
    key-value pattern array and tessellation and recombination of the neural network
    and pattern array results allowing for further validation and reducing the probability
    of false positives. (21) Similar to the use of neural networks for SDS text parsing
    and classification, neural networks can also be used for image recognition of
    GHS or other regulatory pictograms on an SDS. This can be used to ensure proper
    labeling and validation of the SDS itself. For instance, an ANN performs recognition
    on a GHS pictogram and classifies it as a corrosive pictogram. Validation can
    occur through the text recognition of the pH and determine whether the pH value
    accurately supports this classification. Analytics and validation queries can
    be applied to virtually all SDS fields to ensure correct formatting, values are
    within expected thresholds, GHS requirements have been met, flag banned or chemicals
    of concern, and to calculate additional necessary (but not always provided) data
    points. For workplaces containing personnel with various languages, SDSs can be
    maintained on job sites in various languages but still need translation for EHS
    assessment and data entry. Once OCR has been performed on SDSs, an Application
    Programming Interface (API) can be used for a variety of automatic translation
    services. Translation can occur through general basic translations or through
    automated machine-learning translations that can meet domain-specific needs. For
    large industrial operations, this can yield considerable savings in translation
    services. The end results of the OCR AI parsed text are machine-encoded files
    formatted to a given standard for upload into a host SDS repository saving considerable
    time and manual data entry (Figure 3). Figure 3 Figure 3. SDS OCR and AI processing
    system. 2.3. SDS Data Analytics, Hazard Classification Calculation, and Meta-Algorithmic
    Validation Benefits: Automated hazard calculation for storage compatibility, validation
    of GHS compliance and required fields, and improved SDS data extraction accuracy.
    Analytics provide data quality control and actionable data for business practice
    improvement opportunities. Regardless of input type (i.e., XML, PDF, and manual
    input), analytical and validation layers can be applied to the SDS processing
    to ensure data standardization, document completeness, and GHS validation while
    also calculating hazard characteristic codes (HCCs) and performing meta-algorithmic
    validation (advanced hybridization of two or more algorithms) between computer
    vision-derived pictogram classification and HCC classification. The HCC is a code
    used by the United States DoD to classify materials by their primary hazard for
    proper segregation and storage of hazardous materials. These codes are calculated
    based on values extracted or derived from SDSs. The use of HCC assures uniformity
    in the identification and management of hazardous materials and will assist in
    the proper recognition and safe storage by compatibility. (22) Once calculated
    using SDS values (whether XML or OCR-based machine learning), these codes can
    be used for both validation purposes and to enhance the advanced labeling methods
    described below [e.g., use of radio frequency identification (RFID) for storage
    proximity warnings for incompatible hazardous materials]. The HCC can be calculated
    using the OCR-derived fields (e.g., flashpoint, boiling point, pH, etc.) and can
    then be used to validate the computer vision-derived hazardous classification
    pictogram on the SDS (e.g., C1-acid, corrosive, and inorganic HCC matches the
    corrosive GHS pictogram). Once verified, the HCC has additional benefits such
    as being used in conjunction with RFID tags to ensure storage compatibility. With
    a centralized SDS repository, product comparison queries can be run for potential
    chemical replacement initiatives. For product comparison, naturally, a common
    denominator must exist by which we can assess similar materials. One such way
    in the federal logistics system is the national stock number (NSN). Despite varying
    manufacturers, product names, and chemical characteristics, similarly used products
    with closely associated size ranges are often assigned the same NSN. This allows
    for queries of a chemical of concern on one SDS that can be used to trace back
    to all other product chemical detail associations for various products falling
    under the same NSN to determine if another product would effectively serve as
    an eco-friendlier substitute with a more benign chemical formulation. Additionally,
    resources such as the General Services Administration Green Procurement Compilation
    provides listings of potential alternatives for sustainable acquisition covered
    by mandatory and non-mandatory federal environmental programs (e.g., Bio-Preferred,
    Safer Choice, and Energy Star). (23) Transactional analytics can also be employed
    for chemical usage monitoring and accuracy assessments. While manual data entry
    is still largely used in the industry for chemical reporting systems, minor data
    entry errors can yield significant errors and liabilities in reporting. An incorrect
    SG or documentation of whether the SG is relative to air or water, for instance,
    can result in exponential errors in chemical usage. Simple threshold analysis
    can ensure these values are within expected thresholds likewise for SDS numerical
    values. The SDS preparation dates can also serve as a useful metric to analyze
    chemical usage accuracy. Since the GHS adoption by chemical manufacturers in 2015,
    all manufacturers have been required to abide by GHS standardization requirements
    ensuring that the oldest preparation dates for products created should be no older
    than 2015. Many manufacturers also commonly revise or release new SDSs for their
    products on a nearly annual basis. While some exceptions certainly exist, most
    deteriorative hazardous products commonly have an associated SDS within a year
    or two of manufacture. Trend analysis of older SDS associations to recently used
    materials can often be used to indicate potential EHS data reporting discrepancies.
    2.4. “Living” SDSs Using NLP Benefits: Proactive chemical analysis and alerting
    measures by providing immediate notification of applicable research, news, and
    regulatory updates. NLP is a branch of artificial intelligence that combines computational
    linguistics with statistical, deep learning, and machine learning models. NLP
    allows computers to process text and voice recognition using a rule-based model
    of human language and understand the meaning, intent, and sediment of the language
    expressed. Regarding SDSs, this allows us to transform SDSs into a “living” document
    capable of receiving and interpreting feeds on changes to regulatory chemical
    listings, product recalls, product newsfeeds, and alternative products. Incorporation
    of NLP into a centralized SDS repository would offer significant enhancement and
    auxiliary services dramatically expanding on HAZCOM to chemical end users. The
    consistent monitoring and tracking of chemical updates in suitable research publications,
    EPA publications, and manufacturer recalls are largely infeasible given the tens
    if not hundreds of thousands of chemicals large organizations can potentially
    manage. NLP allows for precision chemical literature curation and can provide
    recommendation reviews and prioritized classification of these feeds for human
    review. SDS data points, such as Chemical Abstract Service (CAS) numbers, chemical
    names, product trade names, and part numbers, would be classified and then run
    through a named entity recognizer before external document analysis and recommendations
    would be researched. Given the numerous synonyms for chemicals, an additional
    semantic dictionary mapper would be needed to replace synonym references to the
    primary chemical name or CAS. References, in turn, would be run through document
    analysis and recognition process to identify potential items of interest but also
    perform filtration on irrelevant terminology and reduce inflectional forms of
    these key terms. (24) Vector space models would then be used for identification
    of SDS term frequency and inverse document frequency for term importance analysis
    and pairwise cosine similarity between each document. (25,26) If pairwise frequency
    thresholds are sufficient, the document can become a candidate for recommendation.
    Lastly, SDS data stewards would have a final review and relevant feedback could
    then be propagated back into the system for machine learning and relevance weighting
    and relevant NLP feedback tied to the chemical of interest for knowledge distribution.
    2.5. Label Advancements Benefits: Precise SDS-to-product association, increased
    tracking ability, product authenticity, and anti-counterfeit measures. Improvements
    to precise SDS selection and information availability to the user can be made
    by moving from traditional legacy product barcodes to the following modern applications
    than can be used to quickly direct users to the product’s SDS. 2.5.1. Basic SDS
    Quick-Response (QR) Codes In the advent of the COVID-19 global pandemic, the use
    of QR codes has seen a dramatic rise with many restaurants replacing hard copy
    menus with digitally accessible versions online using common cell phone camera
    applications. QR codes are available in two forms─static and dynamic, dependent
    on whether a user wants data essentially hardcoded into a barcode or using a URL
    that can be modified after printing. (27) Numerous QR code generators exist for
    chemical vendors or EHS personnel to create these codes at little to no additional
    cost. These codes could be printed on custom organizational barcodes or, ideally,
    by the vendors on the products themselves. The ability to immediately retrieve
    the correct SDS for any hazardous material by any personnel with a cell phone
    helps alleviate the reliance on often unmaintained SDS binders and greatly expedites
    the time for personnel to access these SDSs in the event of an emergency. (28)
    Additionally, direct association of the SDS has the added benefit of remaining
    tied to the product outside of the workplace, should the product move from its
    original intended use location. Lastly, association of a product to the chemical
    SDS is mandatory for many environmental, health, and safety compliance systems
    that use the ingredients and hazards on the SDS to calculate usage for regulatory
    reporting, determine exposure for personnel, and employ appropriate safety measures.
    Direct QR code association from a vendor would greatly increase the speed and
    efficiency in loading SDS information into downstream user systems by eliminating
    the need for manual research on vendor sites. QR code storage capacity depends
    on the size and version used. Modern QR codes (currently version 40) contain 31,329
    squares encoding up to 3 KB of data translating to 7089 numeric characters or
    4269 alphanumerics (additionally Kanji/Kana, Arabic, and other languages can be
    stored with varying capacities). (29) The average website URL contains approximately
    40–50 alphanumeric characters so the potential clearly exists for schema development
    that could provide numerous relevant hazardous material data points to a user.
    2.5.2. QR Code Application Data Expansion In addition to retrieving SDSs from
    a cloud-based server, the additional benefits of the expansion of product-related
    data that can be retrieved can greatly enhance industrial operations. One example
    is the direct transmission of an SDS to a downstream user system. If an XML or
    equivalent file is hosted on the server, the machine-encoded file could be transmitted
    directly to subsequent systems (assuming an XML standard is met). If the file
    is in PDF, a combination of OCR and AI meta-algorithmics (described above) can
    be used to reverse engineer and parse and validate SDS fields into a usable format
    by the downstream system. This eliminates not only the need for the chemical user
    to scour the internet looking for the correct SDS but also immediately submits
    it to a database in the machine-encoded text, which would greatly expedite if
    not eliminate the need for SDS manual data entry for hazardous material tracking
    needs. The SDS is automatically routed for environmental, safety, and occupational
    health review (which could also be performed via mobile application). Second,
    the QR code can be used to retrieve other product-related data to enhance inventory
    operations. Information such as unique SDS identifiers, product batch/lot information,
    container numbers, NSNs, container/unit/package information (e.g., 16 oz bottle),
    manufacturer, trade name, noun, manufacture date, and expiration date could all
    be retrieved by the same API connection. For the DoD, expiration dates could include
    not only the original product expiration but also return updated expiration and
    service life dates based upon lab result testing or user extension, whereas traditional
    barcodes are simply printed with the original dates and require database searches
    for these updates (Figure 4). Figure 4 Figure 4. Examples of various expanded
    QR codes capable of product authentication and SDS data retrieval via object library
    association. Object storage services are used to provide supplemental material
    such as images (SDSs, technical data sheets, and specifications) and any other
    associated documents to the downstream user. QR codes have also advanced for uses
    in supply control measures and counterfeit detection. (30,31) Several anti-counterfeit
    designs have been created including QR codes containing secure graphics that can
    verify the authenticity of the product and provide detailed information on the
    location and devices used to scan the product. While this technology was originally
    developed for security needs, it can also be used to meet a host of EHS needs
    and requirements and can be used to forward SDSs to an AI processing system, which
    would read and load the SDS into the host repository while maintaining supply
    chain authentication (Figure 5). Figure 5 Figure 5. QR code SDS retrieval and
    AI processing methodology. The proposed methodology can not only provide numerous
    benefits to chemical users but to the manufacturers as well. Negative implications
    are primarily cost-driven, so the cost–benefit analysis would depend on the potential
    workload savings and the monetary losses associated with counterfeit products.
    The many benefits to chemical vendors include the following: reduction of back-and-forth
    correspondence to chemical users on SDS locations and SDS data points marketing
    of new added benefits of streamlined SDSs and product information to users benefitting
    from brand protection while greatly reducing counterfeiting and offering validation
    of product authenticity increased customer engagement in their products significant
    reduction in counterfeit products; greater product security 2.6. Container Tracking
    Optimization Benefits: Automated tracking ability, cost/time savings from manual
    tracking reduction, compatibility validation, and warning opportunities for inventory
    concerns. 2.6.1. RFID Container Tracking Another possible labeling improvement
    that could either work in conjunction with QR code systems or as an alternative
    to traditional barcodes is the use of RFID tags on hazardous materials and hazardous
    waste, either by the vendor or by downstream user labeling upon receipt. Hazardous
    material and hazardous waste management typically require a database for large
    operations to accurately and consistently monitor where containers are and closely
    observe the amount of time containers exist at these sites and approach regulatory
    thresholds. Movement of containers from site to site within the database thus
    requires manual transactions that must occur for transfer documentation. The use
    of RFID technology can be used to eliminate the need to track hazardous material
    containers from supply points to end users or waste containers as they move from
    satellite accumulation points to centrally managed hazardous waste storage areas
    or treatment, storage, and disposal facilities. Rather than relying on follow-up
    manual transfers to occur, sensors at each location would automatically document
    the movement and record the appropriate transaction in the host database. RFID
    tags also eliminate the need for a line of sight between tags and readers allowing
    expedited inventory management and accountability. (30) Many inventories in the
    DoD are still performed either by manual count or scanning using legacy barcode
    scanners. RFID tags enable constant accurate accounting of inventory. Similarly,
    emergency response personnel can be equipped with technologies that not only provide
    what chemicals are stored in a response location based on receipt transactions
    but also what products and chemicals RFID tags are communicating that exist within
    the RFID boundaries (Figure 6). Figure 6 Figure 6. RFID hazardous material/waste
    tracking. Microchips in RFID tags can be either read-only or read-write. The latter
    allows users to add data to the RFID tag, such as the waste profile number for
    the waste, the accumulation start date, and the site-specific regulatory start
    date. Likewise, for hazardous materials, SDS IDs, expiration dates, and other
    inventory data points can be loaded against the RFID tag. The benefits of incorporating
    this technology could yield significant time savings of personnel, monetary savings
    of reduced data entry and tracking, and increased EHS accountability of these
    containers. Additionally, dangers associated with improper hazard segregation
    could be mitigated by cross-analysis of incompatible storage items through RFID
    proximity. For instance, acids should not be stored with bases or flammable products
    should not be stored with oxidizers. RFID technologies could be used to trigger
    a warning system of possible incompatible storage. Similar warnings can be presented
    to inventory managers on a host of other potential inventory concerns such as
    expiration, shortages, max allotment exceedances, and temperature threshold concerns.
    Active RFID tags can store between 16 bytes and 128 KB, and passive UHF tags are
    capable of 32 KB at a frequency between 865 and 956 MHz allowing for longer ranges,
    (32) both offering ample capacity for the limited EHS inventory fields desired.
    3. Results and Discussion ARTICLE SECTIONSJump To While a national centralized
    SDS repository would likely require regulatory agency approval, some of the other
    proposed advancements have been implemented or are in the process of being implemented
    in various industrial sectors. NASA’s Dryden Flight Research Center developed
    a working solution using RFID to provide real-time information on usage, shipment,
    tracking, and storing of chemicals. (33) The system included abilities to notify
    personnel using a light system if containers were incorrectly removed or added,
    and to verify that users were properly authorized and trained on the chemicals
    they were using. NASA plans for a secondary phase to automatically check vehicles
    entering and leaving access points for RFID-tagged items and track climate-controlled
    chemicals. QR code technology also continues to advance, allowing authentication
    and security protocols to be embedded in the code itself. Scantrust, a Switzerland-based
    firm, has developed such technology which has improved product validation, reduced
    counterfeiting, and improved supply chain management and customer engagement.
    (34) Scantrust has developed technology that expands on standard QR codes by adding
    secure serialization (unit-level detail with the delivery of targeted messages),
    authentication, verification, and alerts and messaging in a single QR format.
    QR codes such as these can be used not only to retrieve product SDSs but also
    to validate product authenticity to reduce counterfeit products and increase tracking
    abilities down to the specific users, locations, and models of phones used to
    scan products. Additionally, QR codes could work in conjunction with the proposed
    RFID solutions. We (the authors) have also conducted studies on meta-algorithmic
    applications using AI for SDS processing. As part of ongoing research for the
    DoD, a prototype is currently in development, which has the potential to reduce
    over $3 million in manual data entry costs while greatly expediting the time for
    SDSs to get loaded. Using the previously mentioned meta-algorithmic approach,
    we have improved upon the 77 and 71% accuracy rates for convolutional neural networks
    and key-value pattern arrays, respectively. The meta-algorithmic tessellation
    and recombination of the other algorithms improved SDS data point extraction to
    a 92% accuracy rate (Figure 7). (21) Building upon this approach, Colorado State
    University was awarded research funding for proof-of-concept prototype development
    of a web-based application that can process thousands of records and retrieve
    greater than 90% accuracy of the desired fields. Figure 7 Figure 7. AI SDS meta-algorithmic
    processing results. The objective will be for the AI prototype to develop into
    a fully operational system and serve as an intermediary tool as the DoD pursues
    efforts to require XML SDSs from its vendors for a more streamlined data transfer.
    The end system will be designed to accommodate PDF data parsing through the discussed
    approach as well as accept XML in the DoD SDS XML, through the manual creation
    of an SDS (for institutions without the resources to accommodate XML), and interface
    with systems procuring SDSs. Regardless of the submittal method, all SDSs will
    be validated with a standardized set of validation algorithms and will perform
    other SDS-specific calculations. 4. Conclusions ARTICLE SECTIONSJump To The discussed
    technologies all represent possibilities in employing 21st technologies to increase
    safety and minimize human and environmental exposures. To minimize greenhouse
    gas emissions and our chemical footprints, we first need an accurate account of
    the products we use and translate this into actionable data. Additionally, upgrades
    in EHS are needed for a more proactive approach to hazard identification and minimization.
    These process additions would effectively allow us instant HAZCOM in emergencies
    and more efficient, accurate, and robust HAZCOM allowing us access to the latest
    changes in regulatory tracking and chemical research. Proactivity would also extend
    to safety measures informing personnel of chemical temperature or incompatibility
    warnings before reaction and adding efficiency gains for chemical lifecycle tracking.
    While each of the discussed methods can be employed either as a combined system
    or independently in existing industrial management processes, all of which would
    benefit from a centralized and universal SDS repository providing an easily accessible
    and standardized data source while minimizing data quality issues garnered from
    data transfers. Applications like machine learning and the proposed meta-algorithmic
    approach provide a quicker and more efficient means by which to transition to
    fully automated HAZCOM. The number of hazardous communication failure findings
    remains staggering and associated hazard data quality loss and availability is
    insufficient and unacceptable for emergencies, both immediate and the longer-term
    climate change emergencies. We have the means to currently implement these suggestions
    and move the industry forward; it only requires action. Author Information ARTICLE
    SECTIONSJump To Corresponding Author Kevin Fenton - Systems Engineering, Colorado
    State University, Fort Collins, Colorado80523-6029, United States;  https://orcid.org/0000-0002-0528-6349;  Email:
    Kevin.fenton@colostate.edu Authors Steve Simske - Systems Engineering, Colorado
    State University, Fort Collins, Colorado80523-6029, United States Jonathan Luu
    - School of Aerospace Medicine, United States Air Force, Wright-Patterson AFB,
    Dayton, Ohio45433, United States Notes The authors declare no competing financial
    interest. Acknowledgments ARTICLE SECTIONSJump To The authors would like to thank
    the Colorado State University Systems Engineering Department and the United States
    Air Force School of Aerospace Medicine for their support of this work. References
    ARTICLE SECTIONSJump To This article references 34 other publications. 1United
    States Occupational Safety & Health Administration. Toxic Release Inventory National
    Analysis, 2019. Google Scholar 2United Nations General Assembly. Principles on
    Human Rights and the Protection of Works from Exposure to Toxic Substances. In
    Human Rights Council 42nd session ; 2019. Google Scholar 3National Institute of
    Environmental Health Sciences. Chemical Exposure (nih.gov). 2022. Google Scholar
    4Glass, D.; Sim, M. The challenges of exposure assessment in health studies of
    Gulf War veterans. Philos. Trans. R. Soc., B 2006, 361, 627– 637,  DOI: 10.1098/rstb.2006.1822
    Google Scholar 5Pennsylvania Department of Environmental Protection. Chemical
    Calculator (state.pa.us), 2022. Google Scholar 6Yu, K. N. Your Client Is In Flames,
    The Structure Is In Flames, Now What? 2020. www.plaintiffmagazine.com. Google
    Scholar 7Zakaib, P. Tolley and Tolley v. ACF Industries, Inc., et al. 2002. http://www.courtswv.gov/supreme-court/docs/fall2002/30461.htm.
    Google Scholar 8United States Occupational Safety & Health Administration. 2019.
    https://www.osha.gov/top10citedstandards. Google Scholar 9United States Environmental
    Protection Agency. Emerging Contaminants and Federal Facility Contaminants of
    Concern, 2022. https://www.epa.gov/fedfac/emerging-contaminants-and-federal-facility-contaminants-concern.
    Google Scholar 10Bernstein, J. Material Safety Data Sheets: Are they reliable
    in identifying human hazards?. J. Allergy Clin. Immunol. 2002, 110, 35– 38,  DOI:
    10.1067/mai.2002.124891 Google Scholar 11United States Environmental Protection
    Agency. TSCA Chemical Substance Inventory, 2022. Google Scholar 12United States
    Environmental Protection Agency. Tri-Listed Chemicals, 2022. https://www.epa.gov/toxics-release-inventory-tri-program/tri-listed-chemicals.
    Google Scholar 13United States Occupational Safety & Health Administration. Hazardous
    Communication Standard, 2012. Google Scholar 14United States Occupational Safety
    & Health Administration. OSHA Brief Hazard Communication Standard: Safety Data
    Sheets, 2022. Google Scholar 15DeMasi, A.; Elston, H.; Langerman, N. Safety Data
    Sheets: Challenges for Authors, Expectations for End Users. ACS Chem. Health Saf.
    2022, 29, 369– 377,  DOI: 10.1021/acs.chas.2c00015 Google Scholar 16Kuzmina, O.;
    Hartrick, E.; Marchant, A.; Edwards, E.; Brandt, J.; Hoyle, S. Chemical Management:
    Storage and Inventory in Research Laboratories. ACS Chem. Health Saf. 2022, 29,
    62– 71,  DOI: 10.1021/acs.chas.1c00086 Google Scholar 17Defense Logistics Agency
    Hazardous Material Information Resource System, 2022. https://www.dla.mil/Information-Operations/Services/Applications/HMIRS/.
    Google Scholar 18Baibus, J.; Boxall, A.; Fenske, R.; McKone, T.; Zeise, L. Implications
    of Global Climate Change for the Assessment and Management of Human Health Risks
    of Chemicals in the Natural Environment. Environ. Toxicol. Chem. 2013, 32, 62–
    78,  DOI: 10.1002/etc.2046 Google Scholar 19United States Occupational Safety
    & Health Administration. Hazardous Communication Standard, 2022. https://www.osha.gov/sites/default/files/publications/OSHA3514.pdf.
    Google Scholar 20Hazard Communication (1910.1200), Industrial Safety & Hygiene
    News, 2020. https:www.ishn.com/articles/112068-hazard-communication-1901200. Google
    Scholar 21Fenton, K.; Simske, S. Engineering of an artificial intelligence safety
    data sheet document processing system for environmental, health, and safety compliance.
    In Proceedings of the 21st ACM Symposium on Document Engineering (DocEng ’21);
    Association for Computing Machinery: New York, 2021; Article 12, pp 1– 4. Google
    Scholar 22United States Department of Defense. Storage and Handling of Hazardous
    Materials, DLAI 4145.11, 1999. Google Scholar 23United States General Services
    Administration, 2022. https://sftool.gov/greenprocurement. Google Scholar 24Sharma,
    B.; Willis, V.; Huettner, C.; Beaty, K.; Snowdon, J.; Xue, S.; South, B.; Jackson,
    G.; Weeraratne, D.; Michelini, V. Predictive article recommendation using natural
    language processing and machine learning to support evidence updates in domain-specific
    knowledge graphs. JAMIA Open 2020, 3, 332– 337,  DOI: 10.1093/jamiaopen/ooaa028
    Google Scholar 25Salton, G.; McGill, M. Introduction to Modern Information Retrieval;
    McGraw-Hill, Inc.: New York, 1986. Google Scholar 26Salton, G.; Wong, A.; Yang,
    C. A vector space model for automatic indexing. Commun. ACM 1975, 18, 613– 620,  DOI:
    10.1145/361219.361220 Google Scholar 27Moore, C.; Davis, K.; Spear, S.; Bombaci,
    S. Link and Learn: How to Use QR Codes to Communicate Science; Colorado State
    University, 2021. Google Scholar 28Langerman, N. Material Safety Data Sheets -
    Who Uses Them?. Chem. Health Saf. 1995, 2, 26– 29,  DOI: 10.1021/acs.chas.8b02611
    Google Scholar 29Abas, A.; Yusof, Y.; Din, R.; Azali, F.; Osman, B. Increasing
    Data Storage of Coloured QR Code Using Compress, Multiplexing, and Multilayered
    Technique. Bull. Electr. Eng. Inform. 2020, 9, 2555– 2561,  DOI: 10.11591/eei.v9i6.2481
    Google Scholar 30Gaubatz, M.; Simske, S. Towards a feature set for robust printing-imaging
    cycle device identification using structured printed markings. In IEEE International
    Workshop on Information Forensics and Security ; 2010; pp 1– 6. Google Scholar
    31Picard, J.; Landry, P.; Bolay, M. Counterfeit detection with QR codes. In Proceedings
    of the 21st ACM Symposium on Document Engineering (DocEng ’21); Association for
    Computing Machinery: New York, 2021; Article 16, pp 1– 4. Google Scholar 32Pais,
    S.; Symonds, J. Data Storage on a RFID Tag for a Distributed System. Int. J. UbiComp
    2011, 2, pp 26− 38,  DOI: 10.5121/iju.2011.2203 . Google Scholar 33NASA Tries
    RFID for HAZMAT. RFID Journal, 2021. www.RFIDJournal.com. Google Scholar 34Scantrust
    SA, 2021. www.scantrust.com. Google Scholar Cited By ARTICLE SECTIONS Jump To
    Citation Statements beta Supporting 0 Mentioning 2 Contrasting 0 Explore this
    article''s citation statements on scite.ai powered by   This article is cited
    by 1 publications. Lauren Goulding. Spotlights: Historical Perspectives on Safety,
    Modernizing Safety Data Sheets, and Values-Based Safety Leadership. ACS Chemical
    Health & Safety 2024, 31 (1) , 6-7. https://doi.org/10.1021/acs.chas.3c00119 Download
    PDF close the sidebar. Figures References Abstract Figure 1 Figure 1. 2019 Toxic
    Release Inventory data and locations. Figure 2 Figure 2. Centralized SDS repository.
    Figure 3 Figure 3. SDS OCR and AI processing system. Figure 4 Figure 4. Examples
    of various expanded QR codes capable of product authentication and SDS data retrieval
    via object library association. Figure 5 Figure 5. QR code SDS retrieval and AI
    processing methodology. Figure 6 Figure 6. RFID hazardous material/waste tracking.
    Figure 7 Figure 7. AI SDS meta-algorithmic processing results. Partners 1155 Sixteenth
    Street N.W. Washington, DC 20036 Copyright © 2024 American Chemical Society About
    About ACS Publications ACS & Open Access ACS Membership ACS Publications Blog
    Resources and Information Journals A-Z Books and Reference Advertising Media Kit
    Institutional Sales ACS Publishing Center Privacy Policy Terms of Use Support
    & Contact Help Live Chat FAQ Connect with ACS Publications This website uses cookies
    to improve your user experience. By continuing to use the site, you are accepting
    our use of cookies. Read the ACS privacy policy. CONTINUE"'
  inline_citation: '>'
  journal: ACS Omega
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Mitigation of Chemical Reporting Liabilities through Systematic Modernization
    of Chemical Hazard and Safety Data Management Systems
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'

- DOI: https://doi.org/10.1155/2016/2821680
  analysis: '>'
  authors:
  - Silvia Mirri
  - Catia Prandi
  - Paola Salomoni
  - Franco Callegati
  - Andrea Melis
  - Marco Prandini
  citation_count: 39
  full_citation: '>'
  full_text: '>

    Journals Publish with us Publishing partnerships About us Blog Mobile Information
    Systems Journal overview For authors For reviewers For editors Table of Contents
    Special Issues Mobile Information Systems/ 2016/ Article On this page Abstract
    Introduction Background and Related Work Conclusion References Copyright Related
    Articles Special Issue Crowdsensing and Vehicle-Based Sensing View this Special
    Issue Research Article | Open Access Volume 2016 | Article ID 2821680 | https://doi.org/10.1155/2016/2821680
    Show citation A Service-Oriented Approach to Crowdsensing for Accessible Smart
    Mobility Scenarios Silvia Mirri ,1Catia Prandi ,1Paola Salomoni,1Franco Callegati,2Andrea
    Melis ,2and Marco Prandini1 Show more Academic Editor: Enrico Natalizio Received
    20 May 2016 Accepted 01 Sept 2016 Published 20 Oct 2016 Abstract This work presents
    an architecture to help designing and deploying smart mobility applications. The
    proposed solution builds on the experience already matured by the authors in different
    fields: crowdsourcing and sensing done by users to gather data related to urban
    barriers and facilities, computation of personalized paths for users with special
    needs, and integration of open data provided by bus companies to identify the
    actual accessibility features and estimate the real arrival time of vehicles at
    stops. In terms of functionality, the first “monolithic” prototype fulfilled the
    goal of composing the aforementioned pieces of information to support citizens
    with reduced mobility (users with disabilities and/or elderly people) in their
    urban movements. In this paper, we describe a service-oriented architecture that
    exploits the microservices orchestration paradigm to enable the creation of new
    services and to make the management of the various data sources easier and more
    effective. The proposed platform exposes standardized interfaces to access data,
    implements common services to manage metadata associated with them, such as trustworthiness
    and provenance, and provides an orchestration language to create complex services,
    naturally mapping their internal workflow to code. The manuscript demonstrates
    the effectiveness of the approach by means of some case studies. 1. Introduction
    As world populations concentrate in cities, mobility in urban environments is
    becoming one of the most prominent and interesting research fields in the smart
    city context. A well-known definition of smart city is provided in [ 1] and says
    that a smart city is “a city well performing in a forward-looking way in economy,
    people, governance, mobility, environment, and living, built on the smart combination
    of endowments and activities of self-decisive, independent and aware citizens.”
    The World Health Organization has recently released a report about Urban health
    [ 2], which claims that about 3.7 billion people live in cities today and that
    a further 1 billion people will be added by 2030, with 90% of the growth being
    in low- and middle-income countries. According to this study, the ways that cities
    are planned and built can profoundly affect the ability of their citizens to live
    long, healthy, and productive lives. Urban mobility plays a key-role in this context,
    because it is strategic in making cities age-friendly and accessible for communities,
    with particular regard to those persons with disabilities [ 2]. Hence, providing
    and adequately orchestrating services devoted to improving urban mobility is fundamental
    in achieving smart mobility [ 3]. In this context, the crowdsensing and the mobility
    as service paradigms are emerging. In particular, crowdsensing is rising thanks
    to the widespread diffusion of mobile devices: it involves people who are moving
    and collecting data from different places and routes, by carrying sensors integrated
    in their mobile devices, such as smartphones and tablets [ 4]. Here, we can identify
    the three interrelated components (space, people, and technology) of the urban
    computing systems, as presented in [ 5]. The concept of Mobility as a Service
    (MaaS) was born in Finland and it is rapidly spreading worldwide [ 6] as an effective
    approach to achieve business efficiency, traveler satisfaction, and government
    agenda fulfillment through smart mobility. Given this background, we envision
    the creation of ICT infrastructures based on microservices. This modern and renowned
    development model [ 7] fosters the creation of an ecosystem of reusable components.
    In the context of MaaS, microservices shall efficiently and flexibly combine heterogeneous
    data sources, such as available transport options, real-time data regarding vehicles
    and infrastructures, and pricing, to provide customized travel planning, information,
    and ticketing to final users, as well as monitoring and strategic planning tools
    to policy-makers. In this context, crowdsensing plays a fundamental role, letting
    the users and their devices be a significant actor in the whole picture, becoming
    one of the data sources. As emerging by the results found in [ 8], crowdsensing
    from citizens’ devices is an important advantage and opens a range of potential
    applications and tools. This would improve data and applications made available
    by operators, policy-makers, and transport providers, enriching the entire smart
    mobility context. This paper presents the design of an infrastructure as a marketplace
    for mobility services, called Smart Mobility for All (SMAll). A prototype of such
    infrastructure has been developed and its architecture is described in the remainder
    of this paper, as well as some of the provided services. In our vision, SMAll
    is the enabling technology to solve the challenges of the MaaS market, from developing
    user-contributed, crowdsourced applications and crowdsensing services to launching
    a MaaS operator and to planning effective and sustainable transport policies for
    smart cities. Particular attention has been given to specific services offered
    with the aim of supporting mobility of citizens with disabilities and special
    needs within urban environments. The remainder of this paper is organized as follows.
    Section 2 presents the background and some of the main related work which have
    inspired and driven our research. Section 3 describes the overall system architecture
    we have designed and developed, which is based on services orchestration. Two
    broad categories of services, namely, data quality management and data sources,
    are illustrated in detail in Sections 4 and 5, respectively, before their orchestration
    is described in Section 6. Two case studies are introduced in Section 7, and,
    finally, Section 8 concludes the paper and presents some future works. 2. Background
    and Related Work An emerging trend introduced with cloud computing [ 9] defines
    a new category of models which can be identified under the umbrella term Everything
    as a Service (XaaS) [ 10]. The basic idea behind cloud computing is to concentrate
    resources, such as hardware and software, into few physical locations and offer
    those resources as services to a large number of users who are located in many
    different geographical locations around the world in an effective way. In this
    context, three major service models have been traditionally exploited: infrastructure-as-a-service,
    platform-as-a-service, and software-as-a-service. The main common element among
    them is that they all provide resources as a service. These models arose a wide
    popularity and starting from them, several similar yet context-specific models
    have been proposed [ 11]. One of these ones is the Sensing as a Service (SaaS)
    model, which can be considered a solution based on IoT infrastructure and it has
    the capability to address some of the most challenging issues in smart cities
    [ 12]. Many everyday objects are equipped with sensors and the European Commission
    has predicted that, by 2020, there will be 50 to 100 billion devices connected
    to the Internet [ 13]. This represents a strong motivation behind the diffusion
    and the opportunity of efficiently exploiting the SaaS model. In a typical SaaS
    cloud, multiple sensing servers can be deployed to handle sensing requests from
    different locations [ 14]. Usually, a SaaS cloud works as follows. When a cloud
    user initiates sensing requests through a Web front-end from either mobile phone
    or a computer, the request will be forwarded to a sensing server which will then
    push the request to a subset of mobile phones that happen to be in the area of
    interest [ 15]. Such mobile devices will fulfill the corresponding sensing task.
    The sensed data will then be collected by a sensing server, stored in a database
    and returned to the cloud user who requests the service. An interesting feature
    is that in such a system a mobile user can be at the same time a provider and
    a consumer of the sensing services [ 15, 16]. And this is the case of the sensing
    service prototype we are going to present in Section 4.2 of this paper. Taking
    into account mobile phone sensing, we can identify two primary paradigms [ 17]:
    (1) Participatory sensing: mobile users actively engage in sensing activities
    by manually determining how, when, what, and where to sense. (2) Opportunistic
    sensing: sensing activities are fully automated without the involvement of mobile
    users. It is worth mentioning that, despite the fact that in traditional sensor
    network the owner is typically a single organization, in mobile phone and sensors
    the control is spread between different individual users. This means that mobile
    sensing activities and resulting data are not controllable and not easy to predict
    [ 14]. In some contexts, in particular in the participatory sensing ones, SaaS
    is considered as a crowdsourcing system that depends on mobile users to provide
    data [ 15], and it can also be referred to as crowdsensing [ 18], which has been
    also defined as a subtype of crowdsourcing, where the outsourced job is a sensing
    task [ 4]. Crowdsensing is recognized as an important technological enabler for
    smart cities that has attracted several research efforts, with the aim of improving
    sensing quality on mobile devices, promoting user participation, and validating
    collected data [ 19, 20]. Compared to infrastructure-based sensing, crowdsensing
    has several advantages, even if it can bring some additional issues. A system
    based on crowdsensing can potentially be cheaper than infrastructure-based sensing
    solutions, because it does not require the deployment of expensive fixed infrastructure.
    Moreover, it is easier to deploy and can be used in areas where deploying a fixed
    infrastructure can be difficult or maybe impossible, but it can introduce additional
    complexity and challenges. In general, mobile devices used for crowdsensing and
    infrastructure-based sensing are complementary technology that can cooperate to
    enable sensing in smart cities [ 18]. In the smart city context, crowdsensing
    can be exploited by involving sensors which are moving (since they are carried
    by users) and human intelligence into the sensing process [ 4]. Some of these
    use cases address tasks related to urban transportation systems, such as tracking
    of public vehicles (e.g., buses, trams, and subways) or others like mapping bumps
    on the road to inform authorities. Crowdsensing can provide great support in optimizing
    urban transportation. Traffic can be unpredictable; moreover, most influenced
    public transportation lines can bear shorter or longer delays. Weather conditions
    can influence the traveling speed of vehicles in the city. In [ 21], an effective
    way of describing the entities of a crowdsourced public transit networks (including
    locations and vehicles) was presented and discussed. A system devoted to monitoring
    public transport vehicles with an application running on traveling users’ mobile
    phones and detecting the stopping places of vehicles is described in [ 22]. An
    interesting example of participatory sensing is represented by the platform called
    Waze [ 23], which supports car drivers to get information on road conditions.
    Thanks to its versatility, it was the wider community-assisted navigation app
    in 2015. To improve routing, users can report changes in local maps to keep them
    up to date [ 4]. It is important to note that systems based on crowdsensing need
    to reach a critical mass of gathered data in effectively and efficiently providing
    services. For this reason, contributors have to feel motivated and involved in
    collecting data. Different research works have proved that resorting in intrinsic
    motivation (the activity is perceived as intrinsically rewarding) and/or extrinsic
    motivation (the action is driven by an external outcome, as rewards or an increase
    of reputation) makes it possible to engage contributors in participating, with
    an increment of the quantity and quality of collected data [ 24, 25]. An interesting
    concept that some of the authors are investigating is the one about the use of
    gamification so as to motivate the participation of the crowd in gathering data
    about the urban environment (see, e.g., [ 26– 28]). Some among the several crowdsourcing
    and crowdsensing systems and applications developed in the smart cities paradigm
    are devoted to let citizens collaborate in improving the quality of life in their
    urban environment [ 29, 30]. A part of them aims to collect data about urban accessibility
    [ 31], improving the quality of life and the level of independence of persons
    with disabilities [ 32, 33]. Many sensing apps have been developed to monitor
    human activities and a part of them could be effectively used to detect accessibility/pedestrian
    barriers (such as stairs) and facilities (such as zebra crossing). These researches
    present sensing architectures and algorithms studied to be used in different contexts,
    so they need to be adapted in order to be exploited in detecting barriers and
    facilities (see, e.g., [ 34, 35]). In [ 36], the authors (by using data obtained
    by a smartphone accelerometer) aim to recognize the position where a pedestrian
    stops and crosses a street ruled by a traffic light. Some barriers and facilities
    could be recognized more easily by using cooperative sensing, working on detecting
    movement of groups of people [ 37]. In [ 38, 39], the authors propose methodologies
    for developing large scale accessibility map with personal sensing by using smart
    phones. In particular, the idea is to exploit devices held by wheelchair citizens
    and then to apply machine learning technologies (i.e., supervised learning techniques)
    with the aim of estimating types of ground surfaces. Using moving sensors in crowdsourcing
    is called mobile crowdsensing (MCS) [ 4]. MCS differs from the deployed sensor
    networks in involving people who are moving and collecting data from different
    places and paths. People can carry sensors integrated to their mobile devices
    and they can provide information about the surroundings manually [ 19]. The MCS
    as a Service (MCSaaS) paradigm has been proposed in [ 40]. The authors discussed
    about the MCSaaS vision and presented a platform prototype and its evaluation.
    In particular, regarding the MCSaaS vision, the authors proposed to implement
    such an approach by splitting the MCS application deployment into two domains:
    the infrastructure and the application ones. Another important and interesting
    concept that is at the basis of our work is Mobility as a Service (MaaS) [ 6].
    One of the main advantages of a MaaS provider is that it shall offer a unique
    and seamless interface to users, aggregating heterogeneous transport options offered
    by different mobility providers (e.g., different agencies providing transportation
    by taxi, bus, train, airplane, and car-sharing, including the public transportation
    providers) and handling the whole experience of traveling, from providing information
    to travel planning and payments [ 41]. All these concepts and studies have inspired
    our work and the resulting system we present in this paper. In particular, our
    prototype is exploiting sensing, mobile crowdsourcing, and mobility as a service
    with the specific purpose of supporting citizens in wandering the city (i.e.,
    in the context of smart mobility). A specific attention has been paid to meet
    the needs of those people who would get more benefits than the others from the
    availability of information about urban accessibility in terms of barriers and
    facilities. 3. Smart Mobility for All (SMAll) From a software engineering point
    of view, it is useful to frame the various functions needed to build any smart-city
    vertical application within a common reference model based on microservices [
    7]. By modeling and implementing every component of a mobility application as
    a service, several remarkable advantages emerge. Data can be transparently collected
    from different sources that, wrapped inside a microservice, become available through
    a standard interface. Preprocessing and labeling of data, for example, to assign
    trustworthiness values, can be implemented by means of different algorithms available
    as services; these, in turn, can take advantage of shared knowledge bases, for
    example, managing user ratings. Sharing databases through services instead of
    giving direct access means having a finer control on access policies, both in
    terms of simple access rights and in terms of precomputations that allow providing
    properly aggregated or otherwise sanitized data to applications. It is worth noting
    that security issues can emerge from this kind of open structure, yet the platform
    itself can play a crucial role in mitigating them [ 41, 42]. Generally speaking,
    a platform to “glue” mobility services together could enable the establishment
    of Mobility as a Service operators. One way to develop a MaaS-enabling infrastructure
    is to structure it as a marketplace (Figure 1) for mobility services, where the
    definition of open standards for service invocation guarantees interoperability,
    the availability of infrastructural components (i.e., authentication, access control,
    QoS negotiation, and business intelligence) lowers the effort needed for the development
    of applications, and an orchestration framework streamlines the composition of
    available services into more complex applications. We are developing a prototype
    of this system called SMAll.    Figure 1  Architecture of a marketplace for mobility
    services. Indeed, we already classified some macrocategories of services that
    we can expect to find in such a marketplace. Figure 2 outlines some of the most
    important ones, arranged in layers of increasing complexity—in this context, “complex”
    means the creation of functionalities on top of other “simple” services. Starting
    from the bottom, we find services that are either wrappers for legacy software,
    for example, travel planners that do not include real-time functionalities, or
    services that process basic data. The aim of this class of services is to standardize
    the data and the interfaces of legacy software to make them available to other
    services. Other more complex services, found in the upper layers, orchestrate
    these basic ones to implement their behaviors, up to the very refined policies
    of MaaS operators and similar applications.    Figure 2  Service categories in
    SMAll. As mentioned at the beginning of the section, we envisage the adoption
    of microservices to provide seamless implementation of these categories of components:
    (i) Wrappers converting legacy data source into standard services (ii) Helper
    services (e.g., authentication, authorization, scheduling, routing, and orchestration)
    (iii) The service registry storing the definition of all the services deployed
    on the platform (iv) The actual business logic deployed by operators or intermediaries,
    collecting, storing, and processing data to offer some data-related insight on
    the usage of services. According to this model, there is no single actor responsible
    for data quality and service correctness, so we are introducing a layer of services
    to manage the quality issues of data resulting from crowdsourcing. This layer
    will offer metadata management services, such as the evaluation of data provenance,
    data reliability, and data trustworthiness, and the propagation of these indicators
    across services which compose data, ready to be exploited in coordination with
    any service that exposes data. The microservices architecture is suitable for
    this kind of scenario, because it allows creating independent services for specific
    tasks (and for different implementation of the same task) of the data quality
    management process. On the SMAll platform, it will be possible to exploit these
    services through orchestration. The concept is illustrated in Figure 3.    Figure
    3  Organization of crowdsensing orchestration layers. On the bottom level, we
    have the services that expose data. These services are heterogeneous in terms
    of amount, sensitivity, expressiveness, representativeness, and so forth. Above
    the data level, there are the microservices in charge of the implementation of
    the mechanisms dealing with each of the data management problems described (provenance,
    trustworthiness, etc.). While the two levels are kept separated to highlight their
    different function, there is no hierarchical relation between them. From an architectural
    point of view, every box is a service, and their invocation is defined by a workflow,
    representing the desired data quality policies, and implemented through the orchestration
    mechanism. 4. Data Sources Various kinds of data sources feed the system. We can
    classify them in broad categories, according to their provenance (e.g., official
    data about the transport infrastructure versus crowdsourced POIs) and their timescale
    (e.g., real-time information versus planned timetables and static features). Indeed,
    each stored data includes specific information and has peculiar characteristics
    depending on its own source. For instance, traffic data feeds are automatically
    posted and updated in the system; instead, the quantity and quality of crowdsourced/crowdsensed
    data are strongly influenced by the voluntary nature of the action and engagement
    of the participant [ 43]. In any case, all the data sources, independently of
    their category, will be accessed in a homogeneous fashion, through appropriate
    microservices. 4.1. Profiling System To provide personalized services, we have
    to build a category of services that exploits a user (JSON-based) profile, structured
    in three interconnected parts: (A) the Generic Profile (GProfile) which includes
    some general data about the user, such as personal info, language, unit of measurement,
    device(s) in use, average walking speed, data about his/her credibility, and data
    about his/her favorite public means of transport routes; (B) the Urban Profile
    (UProfile), which describes users preferences related to the urban environment,
    expressed according to his/her needs, and preferences about the urban Point of
    Interests (POI); a specific section of such a part of the profile is devoted to
    describing the user’s preferences about the urban barriers (such as stairs) and
    facilities (such as curb cuts); and (C) the eAccessibility Profile (eAProfile),
    which describes users preferences related to the e-accessibility and to the interface
    of the application. 4.1.1. Generic Profile The Generic Profile describes the general
    information about the user. It includes personal data and data about the device
    in use, as well as the language and the unit of measurement. These latter data
    can be automatically set by the service, deriving them from users location, or
    manually set up by the user. In such part of the profile, the user can also declare
    his/her average speed when he/she moves in an urban environment. Alternatively,
    such data can be automatically derived from device sensor, which can track the
    users movement and then compute his/her average speed. This information is essential
    for our system, because the routing algorithms compute the best personalized paths
    taking them into account. For example, when combined to real time availability
    of buses (when the paths include the use of public means of transports), the user’s
    ability to reach a stop in time to catch the bus prunes the set of feasible different
    paths. Finally, the user could store here information about his/her traveling
    habits, providing data about his/her favorite bus routes. The user can provide
    a location in the city by exploiting his/her current position or an address (i.e.,
    street and number). Then, our system provides all the bus stops that the user
    can reach (in a configured time) with a list of the bus routes available at those
    stops; finally, the user can choose bus stops and routes of interest. 4.1.2. Urban
    Profile The Urban Profile stores information about users preferences related to
    the urban environment. In particular, the urban elements are called Point of Interests
    (POIs) and users can set their preferences, classifying them as NEUTRAL, LIKE,
    UNLIKE, and AVOID on the basic of their degree of interest, preference, and/or
    need. Some examples of POIs mapped in our system are bus stops; subway stations;
    bicycle-sharing stations; parking; and so on. An interesting subset of POIs is
    related to identify urban barriers and facilities in the city. Such specific POIs
    are defined as aPOIs (accessibility Points of Interests). We have classified the
    aPOIs in categories that derive from the mobility context, in particular for those
    people with disabilities that we treat in the use cases of this work (see Section
    7). These categories include items such as gaps, crosses, obstructions, and surface
    descriptions. Users have the possibility of defining their preferences about the
    above-listed aPOIs (stored in the Urban Accessibility Profile (UAProfile)) as
    follows: (i) NEUTRAL: the user has neither difficulties nor preferences related
    to the aPOI type. The presence of this type of barrier/facility on a path is irrelevant
    to the user. (ii) LIKE: the user prefers aPOIs of this type, when they are available.
    The presence of this type of barrier/facility on a path is positive to the user.
    (iii) DISLIKE: the user can face this aPOI type, but with some efforts. In this
    case, an alternative path is preferred (when available), but it is not necessary.
    The presence of this type of barrier facility on a path is negative to the user.
    (iv) AVOID: the user cannot face this aPOI type and an alternative path is necessary.
    The presence of this type of barrier/facility on a path prevents the user from
    following this path. A more detailed description of such urban accessibility preferences
    can be found in [ 33, 44]. On the basis of them, our system computes an accessible
    route that comes across the LIKEd aPOIs when feasible, gets round the DISLIKE
    aPOIs if it is possible, and avoids the AVOIDed aPOIs every time. It is worth
    noting that positive preferences can be associated with barriers and negative
    preferences can be associated with facilities. As an example, a blind user can
    set as LIKE some specific barriers, such as stairs and steps, because they can
    represent a reference point. Analogously, wheelchair users can set tactile paving
    as DISLIKE, because such surfaces can be uncomfortable for them. 4.1.3. eAccessibility
    Profile The e-Accessibility Profile is devoted to storing preferences and needs
    in terms of maps rendering. The main selection is the one related to textual/graphical
    representation of the map. On the basis of it, users can choose specific styles
    to represent POIs. For instance, the graphical representation can be personalized
    in terms of colors and size of the POIs icons in the map, addition of textual
    labels, and visualization (show or hide) of POI categories or of POI types. In
    particular, different style rules can be associated with the whole application,
    to a specific preference (LIKE, DISLIKE, etc.) or to a single type of POI. 4.2.
    Data Sensing We designed and developed a specific sensing service prototype that
    would be exploited on users smartphones, with the aim of sensing stairs, automatically
    storing information about such a kind of urban barrier. Stairs are commonly placed
    in pedestrian areas of the urban environment, in particular in European cities,
    due to their old origins. As an example, we report in Figure 4 a picture taken
    in Bologna. Bologna is famous for its porticos, which are devoted to pedestrian
    paths all over the city (over 45 kilometers of arcades) and where stairs often
    affect the urban accessibility.    Figure 4  Stairs in Bologna porticos. The design
    issues of such an ad hoc service were based on the need of low energy consumption
    and of high precision, minimizing false positive and false negative results. Analyzing
    the sensors available on a smart phone, we focused on gyroscopes, accelerometers,
    and magnetometers. The idea was to create a service, which would be used in background,
    without affecting other uses activities, applying an opportunistic sensing. Several
    methodologies have been evaluated, such as sensors fusion (combining data coming
    from the gyroscope, the accelerometers, and the magnetometer, with the aim of
    identifying the device inclination), Fourier analysis, Kalman filtering, convolution
    (cross-correlation and signal analysis of the forces applied on the device, with
    the aim of reconstructing and interpreting the device movements). We have exploited
    this latter method, by using only the accelerometer. In particular, our prototype
    compares the signal recorded by the smartphone accelerometer with a set of presampled
    ones, so as to assess the actual presence of a stair. Such presampled signals
    correspond to signals obtained climbing stairs up and down, by a group of different
    users equipped with their smartphones in different modalities (by walking, by
    running, and by keeping the smartphone in the pocket, in hand, in a bag, or in
    a backpack). The use of this method (and in particular of the sole accelerometer)
    lets us avoid the use of the gyroscope, then limiting the energy consumption and
    false positives and negatives. The sensing prototype we have developed is based
    on Android operating systems; it exploits the spatial components thanks to the
    accelerometer, which senses the force applied to all spatial components. Once
    our sensing service prototype recognizes the presence of a stair, data about its
    position are sensed and stored. Hence, our prototype records the sensed data,
    analyses them, and stores the corresponding signal. A screenshot of a corresponding
    plot is shown in Figure 5.    Figure 5  A screenshot of the signal sensed by means
    of the accelerometer. 4.3. Transit Infrastructure Information regarding the operation
    of buses, trains, and other means of transport is possibly the most complete example
    of variety that benefits from the standardization offered by wrapper services.
    (i) Operators are usually the authoritative source for static information about
    the transport infrastructure (stops, routes, etc.) and planned services (timetables,
    vehicles features, etc.). Operators can make this data available through different
    open data formats. GTFS [ 45] is rapidly growing to the status of de facto standard,
    yet many company-specific formats are still in use. A set of wrapper services
    is useful not only to convert these formats into a standard one but also to offer
    more sensible ways to access data, for example, allowing for discovering nearby
    stops given an address or set of coordinates, to know the set of bus lines serving
    a given stop, and so forth. (ii) Real-time information about the transport services
    is, again, usually provided by operators. Depending on the end-user needs, it
    could be useful to know either the position of a vehicle or its delay with respect
    to planned operation or the estimated time of arrival at a given stop. Of course,
    these data are all mutually related, and it turns out that different operators
    may decide to provide different views of the same basic information (in our region,
    e.g., the biggest bus operator provides the arrival time of the next two buses
    at a given stop to the public, but at the same time, it feeds the “raw” GPS position
    of each vehicle to the regional transport authority, which is considering to make
    these data available for crowdsourced applications). By wrapping the composition
    between the available kind(s) of data and other information (e.g., position of
    vehicles crowdsensed by passengers, travel times measured on street segments),
    it is possible to obtain all the needed views and even to improve the precision
    of estimates. (iii) Real-time information about the transport infrastructure comes
    from many different sources, such as public administrations announcing planned
    or extraordinary works, emergency teams intervening on accidents, operators giving
    notice of strikes of vehicle failures, weather reports, and of course people in
    the streets. 5. Data Quality Management Services Various kinds of data sources
    feed the system. We can classify them in broad categories, according to their
    provenance (e.g., official data about the transport infrastructures versus crowdsourced
    POIs) and their timescale (e.g., real-time information versus planned timetables
    and static features). Indeed, each stored data includes specific information and
    has peculiar characteristics depending on its own source. For instance, traffic
    data feeds are automatically posted and updated in the system; instead, the quantity
    and quality of crowdsourced/crowdsensed data are strongly influenced by the voluntary
    nature of the action and engagement of the participant [ 43]. In any case, all
    the data sources, independently of their category, will be accessed in a homogeneous
    fashion, through appropriate microservices. 5.1. Data Provenance Data Provenance
    for single hosts sources is a known problem in literature. According to works
    like [ 46], this problem could be solved only with a creation of private and public
    key system for data stream certification. A good reference is the system developed
    in [ 47], describing a cryptographic provenance verification approach for ensuring
    data properties and integrity for single hosts. Specifically, the authors designed
    and implemented an efficient cryptographic protocol that enforces keystroke integrity.
    This kind of protocol can be integrated as a microservice in our architecture.
    However, public-key schemes are known for their significant computational load,
    thus existing techniques may not be suitable for high-rate, high-volume data sources.
    Moreover, there could be the need for an algorithm for the propagation of provenance
    data. In some cases, data originated from the composition of raw (or otherwise
    “lower ranked”) sources should be accompanied by suitable metadata that allows
    verifying the provenance of the input values, in a cryptographically strong way.
    Merkle hash trees could be a good candidate to build proofs for composed data
    pieces [ 48]. 5.2. Data Trustworthiness Trustworthiness often referred to measuring
    and quantifying the quality of information coming from online resources and systems
    [ 49]. Several studies have been conducted with the aim of supporting users in
    quickly judging the trustworthiness of information they get, providing automatically
    computed values, which can be continuously updated [ 49, 50]. The authors of [
    51] based the trustworthiness model on users mobility and on the usefulness of
    their past contributions to the system. This work focuses on data integrity (for
    data coming from automatic readings from devices), data correctness, and quality.
    Users contributions are compared with those ones provided by local authoritative
    data sources, certified by the data provenance microservice. The trustworthiness
    microservice considers information provided by authoritative data sources (i.e.,
    local administrations, municipalities) as a gold set. Thus, our idea is to compare
    information provided by users with trustworthy and correct data. Hence, it is
    possible to base our trustworthiness service on the computation and assignment
    of more effective credibility values to users, similar to what has been done in
    other works, for example, [ 52]. 5.3. Data Reliability and Reporting Service Once
    we are able to verify the provenance and trustworthiness of the data intended
    as verification of the correct elaboration process, we have to verify that the
    results or the data displayed are actually correct. The process of correctness
    verification of the results of a crowdsourced data can be done in two ways: through
    an automated system with artificial intelligence embedded or through a reporting
    system with a trusted source approach. Considering that this work is mainly aimed
    at helping disabled people, who are known to be more collaborative in using reporting
    systems, has obviously led us to implement the second solution. The description
    of the reporting system for our architecture is inspired from the mPASS model
    [ 32], which is based on the mapping of POI. Each POI and its related data can
    be added to our system by means of one or more reports. Reports are classified
    in three different source classes, according to how they are collected. The three
    source classes have a growing validity: (i) U-report (report obtained by users):
    users can add POI to the DB system. This can be done in two ways: (i) spontaneously,
    a user encountering a specific barrier or an accessibility facility can send a
    report to the reporting service (RS); (ii) on demand, the RS can ask users to
    improve validity of an existing POI (usually a POI reported by sensors). Hence,
    the system will exploit the user report instead of sensor ones and the user gets
    an award badge on his/her public profile. (ii) S-report (report obtained by sensors):
    the RS can automatically produce data by sensing from mobile devices sensors.
    These reports are supposed to have a low validity. (iii) E-report (report produced
    by experts): experts are people working for organizations involved in monitoring
    urban accessibility (such as local administrations and municipalities or disability
    right organizations). Being professionally able to correctly classify and measure
    every kind of POI and POIs, their reports are considered totally valid. Reports
    from administrators can be added in two ways: (i) spontaneously: administrators
    add reports according to their program of activities, sending to the RS reports
    on barriers or accessibility facilities; (ii) on demand: the RS can ask administrators
    to improve validity of an existing POI (usually a user-added one). Hence, the
    system will use the administrator report instead of user ones. Hence, the RS can
    have more reports of the same POI, classified with one or more different source
    classes. Both the map provided to users and the data set considered by the routing
    algorithm are based on the more valid reports available. For example, if a POI
    is added by both sensors and users, U-reports are used instead of S-reports, since
    they are considered more valid. Analogously, if a POI is added by both users and
    administrators, E-reports are used instead of U-reports, because they are considered
    more valid. To populate the RS database, we also added some POIs and reports obtained
    by converting, filtering, and mashing up existing data. 5.4. Feedback Scoring
    System The Feedback Scoring System service is linked with the reporting service,
    an algorithm that calculates the reliability of a report based on the assigned
    scores on the basis of certain characteristics. It can happen, however, that in
    some cases these reports are uncertain, or missing, or simply they are too few
    to yield a reliable result. In this case, we can ask for the user interaction
    in order to give a feedback of a specific case. When uncertainty occurs on a POI,
    we activate a simple mechanism of user request, asking to confirm the presence/absence
    of this POI or to confirm parameters about measures of this POI. This feedback
    cannot always be sharp; it can include a confidence score, showing how much the
    user trusts the POI features to be correct. This score will be used to recalculate
    the reliability of the crowdsourced data. 6. Orchestration The core of this architecture
    is the orchestration process. As previously described, as service orchestration
    we mean the composition of microservices, tools, and processes invoked and the
    connection and automation of workflows to deliver a defined service [ 53]. To
    this end, our platform can natively run orchestration tasks written in Jolie [
    54], a programming language offering several structural advantages: it provides
    workflow constructs such as sequence, parallelism, and nondeterministic choice
    for composing communication interactions, it deals with statefulness by activating
    different workflow instances for each business task to manage, and it implements
    interfaces to almost every communication protocol commonly used. Figure 6 represents
    one of the possible workflows managed by the orchestrator. The idea is that the
    evaluation of data quality is carried out by suitably combining one or more specific
    microservices.    Figure 6  Example of orchestration workflow. In our case, the
    workflow represents the composition of data management services that, according
    to the legacy service policy, will produce results and an evaluation of their
    quality at the same time. To do that, the orchestrator begins invoking a service
    of the data management layer, in this case the data provenance service that certifies
    the provider. The results can be used by the service caller to refine authentication
    data as well feed back the data provenance service. This result will improve the
    data quality evaluation in subsequent data source service invocations. 7. Use
    Cases In order to prove the effectiveness of our approach, we tested our system
    with many different user profiles (such as users with reduced mobility, elderly
    people, blind users, and users with low vision). In this section, we present two
    scenarios illustrating urban accessibility issues involving a wheelchair user
    and an elderly user. More generally, different scenarios can be pictured, involving
    all the different aspects of the smart mobility context. For instance, an interesting
    use case can be envisioned by considering a bicycle-sharing system together with
    subway/bus stops: real time subway/bus information are automatically provided
    by the transportation provider company, while data related to the bicycle-sharing
    stations with available bikes or open docks are crowdsourced by users and/or derived
    by crowdsensed data obtained in the activity of bike block/unblock, exploiting,
    for example, RFID/NFC technologies and GPS position. In this way, the SMAll system
    can compute personalized paths by taking into account the actual time of the interested
    subway or bus and the effective availability of bikes or of open docks suggesting
    the best bicycle-sharing station to reach, according to the defined destination
    of the route. Another interesting use case that we are currently developing involves
    particular rural areas, whose main features are a low population density and a
    difficult road conditions due to rugged environmental conditions. For these particular
    areas, in general, many public transport services such as buses and trains are
    not economically justified by the current demand. Conversely, however, more accessible
    urban public transport services become essential to reach other important social
    services such as healthcare which are often far apart. SMAll provides the following
    solution. The public transport network is acting as a targeted service on request
    for each applicant. A network of taxis satisfies every single request. The SMAll
    task is to coordinate the various taxi operators who have the assigned races,
    from call handling to profit redistribution. SMAll would deal to merge close calls
    in an efficient way (e.g., Uber Pool). The advantage is twofold, the administration
    spends less to provide a service and the quality of the service for citizen is
    improved. Moreover, this can be considered an example of fostering and supporting
    community awareness in rural area [ 55]. In the two user cases here detailed,
    the users request personalized paths, by using their own smartphones. In particular,
    let us consider a male user equipped with a manual wheelchair (first scenario)
    and an elderly woman (second scenario); both of them ask for a specific path (including
    bus routes) in the city of Bologna (Italy), with the same starting point A and
    the same destination B (shown in Figures 7 and 8). The path usually proposed by
    the most commonly used geospatial mapping platforms (e.g., Google Maps, Bing Maps)
    takes 17 minutes as a whole and is structured in three parts: (i) A pedestrian
    part to reach the bus stop: this part is supposed to take 8 minutes to the user.
    (ii) A part of a bus route (from the blue bus stop to the green bus stop): this
    part is supposed to take 8 minutes (with four in-between stops). (iii) Another
    pedestrian part from the arrival bus stop to the final destination: this part
    is supposed to take 1 minute.    Figure 7  Path proposed by our system, tailored
    on a wheelchair user profile.    Figure 8  Path proposed by our system, tailored
    on an elderly user profile. This path presents some issues our users have to face:
    (1) There is a stair in the first pedestrian part of the path and there is no
    information about its presence; this means that our wheelchair user cannot afford
    the suggested pathway, but he has to find another alternative and accessible route.
    (2) There is no information about accessibility of the public mean of transport
    and of the bus stops; in particular, not all the vehicles are provided with facilities
    to support our specific user, such as ramps, kneeler features, and lifts. (3)
    Estimated time to reach the departure bus stop from the starting point (8 minutes,
    for 600 meters) is computed taking into account abilities and speed of an average
    user, instead of considering the actual abilities average speed of our specific
    users. (4) Information about bus arrival time is derived from a time table, instead
    of referring to the real bus position and availability. The following subsections
    detail the scenarios about the sensing and the data consuming activities of two
    different users with different needs and preferences about the urban environment.
    The design of the interface is under investigation and some preliminary results
    can be found in [ 56]. 7.1. First Scenario As a first scenario, let us consider
    a wheelchair user who asks for an accessible path starting from A to the destination
    B. He has set up his UAProfile declaring that he stated as LIKE ramps and curb
    cuts (as gap facilities), parking slots reserved to people with disabilities (as
    parking facility), sidewalks with an adequate width (in the pathway category),
    and zebra crossing and traffic lights (as crossing facilities). He initialized
    uneven road surface and tactile paving (in the surface category) as DISLIKE and
    Gap category aPOIs and obstructions barriers as AVOID. Handrails and audible traffic
    lights are NEUTRAL for him, as well as street lighting. Algorithm 1 shows a fragment
    of his profile in JSON format. "UAProfile": "style": "neutral": "_style": "hidden"
    , "like": "_style": "ok" Algorithm 1  When this user asks for a path from the
    starting point A to the destination B, then our system computes a personalized
    route taking into account the users profile (i.e., avoiding such barriers which
    affect him and including as much as possible the LIKEd facilities). Our system
    computes a personalized path, by taking into account real data about bus availability
    and the users profile, in terms of barriers to avoid, LIKEd facilities to include
    as much as possible, and users personal average speed (set up as 0.98 m/s, according
    to [ 57]). This path is structured in three parts (shown in Figure 7), where only
    the first part is different from the path previously described. In particular,
    (1) our path suggests a different first pedestrian part of the path, taking into
    account the presence of that stair, and finds an alternative accessible path,
    including a ramp (highlighted in Figure 7 with a green icon); (2) information
    about the accessibility of the public means of transport is provided; in particular,
    the path is computed taking into account a bus equipped with a kneeler and wheelchair
    anchorage features; (3) estimated time to reach the departure bus stop from the
    starting point is computed taking into account our specific users abilities and
    average speed, as declared in his profile (16 minutes, for 900 meters); (4) information
    about bus arrival time is provided taking into account open data about the real
    bus position and eventual delays, provided by the local public means of transport
    operator. The time to complete the path is estimated to be 30 minutes and it is
    computed according to the users average speed and real bus availability (by considering
    real time data about eventual delays, traffic, and so on, coming from open data
    made available by the public transportation provider), as follows: 16 minutes
    for the first part, 12 minutes for the second part, and 2 minutes for the last
    one. Meanwhile, crowdsensing and crowdsourcing services are exploited on the user’s
    mobile device, with the aim of collecting data and reports about urban barriers
    and facilities. 7.2. Second Scenario As a second scenario, let us consider an
    elderly woman who asks for a path from A to B, tailored according to her preferences.
    She has set up her UAProfile declaring that she stated as LIKE streets lighting,
    crossing facilities, sidewalks, ramps, curb cuts, and handrails. She also stated
    as LIKE stairs, because her doctor suggested her to do some exercise, climbing
    stairs. She stated as DISLIKE garbage bins, while steps, gaps, uneven road surface,
    and tactile paving are NEUTRAL. Algorithm 2 shows a fragment of her profile in
    JSON format. "UAProfile": "style": "neutral": "_style": "hidden" , "like": "_style":
    "ok" Algorithm 2  Once such a user asks for a pedestrian path, our system computes
    a personalized route from the starting point (A) to the destination point (B)
    taking into account her profile (i.e., stairs) and real data about bus availability.
    Also in this case the personalized path is structured in three parts and it is
    similar to the one previously described, including the stairs in its first part.
    Since this user is equipped with a smart phone, she would actively provide data
    coming from her mobile device accelerometer, so as to enrich the available information
    that are exploited by SMAll, with the aim of equipping citizens with smart mobility
    applications and data. 8. Conclusion Smart mobility is a key point in supporting
    citizens in their daily activities and in offering them a feasible smart city.
    Information about urban transportation (including taxis, buses, trains, and car-sharing),
    urban barriers and facilities, and pedestrian and multimodal paths would be of
    great benefit in this context, as well as all the information about the whole
    experience of traveling and wandering the city, including travel planning and
    payments. Crowdsensing and Mobility as a Service can play a key role in this background.
    As discussed in Sections 3–6, in providing a complete and smart urban mobility
    service, different requirements need to be considered and orchestrated. In particular,
    an efficient service-oriented approach for smart mobility needs (i) real time
    data about public means of transport; (ii) updated urban data collected via crowdsensing
    and crowdsourcing; (iii) a model able to calculate the trustworthiness of collected
    data; (iv) a definition of a precise profile according to user’s preferences and
    needs. Keeping into account these design issues, we designed and prototyped an
    infrastructure as a marketplace for mobility services, called Smart Mobility for
    All (SMAll). A prototype of such infrastructure has been developed and its architecture
    has been described in the paper, as well as some of the provided services. In
    particular, two use cases have been presented, focusing on a wheelchair user and
    an elderly person. We are now doing further studies with the aim of profiling
    users by tracking their daily journeys, by exploiting machine learning techniques,
    integrating them in crowdsensing activities. Adaptation mechanisms will be applied
    to the profile, so as to dynamically and automatically modify it according to
    users actual abilities and habits. The adopted SOA approach will make all future
    additions easy to integrate, since each new algorithm or service will be developed
    as an independent microservice and plugged into the orchestration logic as needed.
    As future work, we are planning to conduct the evaluation of the system in terms
    of (i) efficiency, scalability, and robustness and (ii) effectiveness, user experience,
    and usability. Competing Interests The authors declare that there is no conflict
    of interests regarding the publication of this paper. References R. Giffinger
    and H. Gudrun, “Smart cities ranking: an effective instrument for the positioning
    of the cities?” ACE: Architecture, City and Environment, vol. 4, no. 12, pp. 7–26,
    2010. View at: Google Scholar WHO, Urban health: major opportunities for improving
    global health outcomes, despite persistent health inequities, http://www.who.int/mediacentre/news/releases/2016/urban-health-report/en/
    H. Chourabi, T. Nam, S. Walker et al., “Understanding smart cities: an integrative
    framework,” in Proceedings of the 45th IEEE Hawaii International Conference on
    System Sciences (HICSS ''12), pp. 2289–2297, Maui, Hawaii, USA, January 2012.
    View at: Publisher Site | Google Scholar Á. Petkovics, V. Simon, I. Gódor, and
    B. Böröcz, “Crowdsensing solutions in smart cities: introducing a horizontal architecture,”
    in Proceedings of the 13th International Conference on Advances in Mobile Computing
    and Multimedia (MoMM ''15), pp. 33–37, ACM, 2015. View at: Publisher Site | Google
    Scholar H. Kukka, J. Ylipulli, A. Luusua, and A. K. Dey, “Urban computing in theory
    and practice: towards a transdisciplinary approach,” in Proceedings of the 8th
    Nordic Conference on Human-Computer Interaction (NordiCHI ''14), pp. 658–667,
    ACM, Helsinki, Finland, October 2014. View at: Publisher Site | Google Scholar
    K. P. Sami Pippuri, Sampo Hietanen. Maas finland, http://maas.fi/ S. Newman, Building
    Microservices, O''Reilly Media, Farnham, UK, 2015. V. Kostakos, T. Ojala, and
    T. Juntunen, “Traffic in the smart city: exploring city-wide sensing for traffic
    control center augmentation,” IEEE Internet Computing, vol. 17, no. 6, pp. 22–29,
    2013. View at: Publisher Site | Google Scholar S. Patidar, D. Rane, and P. Jain,
    “A survey paper on cloud computing,” in Proceedings of the 2nd International Conference
    on Advanced Computing and Communication Technologies (ACCT ''12), pp. 394–398,
    January 2012. View at: Publisher Site | Google Scholar P. Banerjee, R. Friedrich,
    C. Bash et al., “Everything as a service: powering the new information economy,”
    Computer, vol. 44, no. 3, Article ID 5719575, pp. 36–43, 2011. View at: Publisher
    Site | Google Scholar M. Zhou, R. Zhang, D. Zeng, and W. Qian, “Services in the
    cloud computing era: a survey,” in Proceedings of the 4th International Universal
    Communication Symposium (IUCS ''10), pp. 40–46, IEEE, Beijing, China, October
    2010. View at: Publisher Site | Google Scholar C. Perera, A. Zaslavsky, P. Christen,
    and D. Georgakopoulos, “Sensing as a service model for smart cities supported
    by internet of things,” European Transactions on Telecommunications, vol. 25,
    no. 1, pp. 81–93, 2014. View at: Publisher Site | Google Scholar H. Sundmaeker,
    P. Guillemin, P. Friess, and S. Woelfflé, “Vision and challenges for realising
    the Internet of Things,” EUR-OP, vol. 20, no. 10, 2010. View at: Google Scholar
    X. Sheng, J. Tang, X. Xiao, and G. Xue, “Sensing as a service: challenges, solutions
    and future directions,” IEEE Sensors Journal, vol. 13, no. 10, pp. 3733–3741,
    2013. View at: Publisher Site | Google Scholar X. Sheng, X. Xiao, J. Tang, and
    G. Xue, “Sensing as a service: a cloud computing system for mobile phone sensing,”
    in Proceedings of the 11th IEEE SENSORS 2012 Conference, pp. 1–4, IEEE, Taipei,
    Taiwan, 2012. View at: Google Scholar A. Melis, S. Mirri, C. Prandi, M. Prandini,
    P. Salomoni, and F. Callegati, “Crowdsensing for smart mobility through a serviceoriented
    architecture,” in Proceedings of the 2nd IEEE International Smart Cities Conference,
    2016. View at: Google Scholar N. D. Lane, E. Miluzzo, H. Lu, D. Peebles, T. Choudhury,
    and A. T. Campbell, “A survey of mobile phone sensing,” IEEE Communications Magazine,
    vol. 48, no. 9, pp. 140–150, 2010. View at: Publisher Site | Google Scholar G.
    Cardone, L. Foschini, P. Bellavista et al., “Fostering participaction in smart
    cities: a geo-social crowdsensing platform,” IEEE Communications Magazine, vol.
    51, no. 6, pp. 112–119, 2013. View at: Publisher Site | Google Scholar R. K. Ganti,
    F. Ye, and H. Lei, “Mobile crowdsensing: current state and future challenges,”
    IEEE Communications Magazine, vol. 49, no. 11, pp. 32–39, 2011. View at: Publisher
    Site | Google Scholar M. Talasila, R. Curtmola, and C. Borcea, “Improving location
    reliability in crowd sensed data with minimal efforts,” in Proceedings of the
    6th Joint IFIP Wireless and Mobile Networking Conference (WMNC ''13), pp. 1–8,
    IEEE, Dubai, UAE, April 2013. View at: Publisher Site | Google Scholar A. Vemula,
    N. Patil, V. Paharia et al., “Improving public transportation through crowd-sourcing,”
    in Proceedings of the 7th International Conference on Communication Systems and
    Networks (COMSNETS ''15), pp. 1–6, Bangalore, India, January 2015. View at: Publisher
    Site | Google Scholar Á. Petkovics and K. Farkas, “Efficient event detection in
    public transport tracking,” in Proceedings of the International Conference on
    Telecommunications and Multimedia (TEMU ''14), pp. 74–79, July 2014. View at:
    Publisher Site | Google Scholar Waze, crowdsensing applicaiton, http://www.waze.com/
    A. Sassi and F. Zambonelli, “Coordination infrastructures for future smart social
    mobility services,” IEEE Intelligent Systems, vol. 29, no. 5, pp. 78–82, 2014.
    View at: Publisher Site | Google Scholar J. Goncalves, S. Hosio, J. Rogstadius,
    E. Karapanos, and V. Kostakos, “Motivating participation and improving quality
    of contribution in ubiquitous crowdsourcing,” Computer Networks, vol. 90, pp.
    34–48, 2015. View at: Publisher Site | Google Scholar P. Salomoni, C. Prandi,
    M. Roccetti, V. Nisi, and N. J. Nunes, “Crowdsourcing urban accessibility: some
    preliminary experiences with results,” in Proceedings of the the 11th Biannual
    Conference on Italian SIGCHI Chapter, pp. 130–133, ACM, Rome, Italy, September
    2015. View at: Publisher Site | Google Scholar C. Prandi, V. Nisi, P. Salomoni,
    and N. J. Nunes, “From gamification to pervasive game in mapping urban accessibility,”
    in Proceedings of the the 11th Biannual Conference, pp. 126–129, Rome, Italy,
    September 2015. View at: Publisher Site | Google Scholar C. Prandi, M. Roccetti,
    P. Salomoni, V. Nisi, and N. J. Nunes, “Fighting exclusion: a multimedia mobile
    app with zombies and maps as a medium for civic engagement and design,” Multimedia
    Tools and Applications, 2016. View at: Publisher Site | Google Scholar F. Zambonelli,
    “Pervasive urban crowdsourcing: visions and challenges,” in Proceedings of the
    9th IEEE International Conference on Pervasive Computing and Communications Workshops
    (PERCOM Workshops ''11), pp. 578–583, IEEE, Seattle, Wash, USA, March 2011. View
    at: Publisher Site | Google Scholar N. Bicocchi, A. Cecaj, D. Fontana, M. Mamei,
    A. Sassi, and F. Zambonelli, “Collective awareness for human-ICT collaboration
    in smart cities,” in Proceedings of the IEEE 22nd International Workshop on Enabling
    Technologies: Infrastructure for Collaborative Enterprises (WETICE ''13), pp.
    3–8, Hammamet, Tunisia, June 2013. View at: Publisher Site | Google Scholar S.
    Mirri, L. A. Muratori, and P. Salomoni, “Monitoring accessibility: large scale
    evaluations at a Geo-political level,” in Proceedings of the 13th International
    ACM SIGACCESS Conference on Computers and Accessibility (ASSETS ''11), pp. 163–170,
    ACM, October 2011. View at: Publisher Site | Google Scholar C. Prandi, P. Salomoni,
    and S. Mirri, “mPASS: integrating people sensing and crowdsourcing to map urban
    accessibility,” in Proceedings of the IEEE 11th Consumer Communications and Networking
    Conference (CCNC ''14), pp. 591–595, Las Vegas, Nev, USA, January 2014. View at:
    Publisher Site | Google Scholar S. Mirri, C. Prandi, P. Salomoni, F. Callegati,
    and A. Campi, “On combining crowdsourcing, sensing and open data for an accessible
    smart city,” in Proceedings of the 8th International Conference on Next Generation
    Mobile Apps, Services and Technologies (NGMAST ''14), pp. 294–299, IEEE, Oxford,
    UK, September 2014. View at: Publisher Site | Google Scholar S. Choi, R. Lemay,
    and J.-H. Youn, “On-board processing of acceleration data for real-time activity
    classification,” in Proceedings of the IEEE 10th Consumer Communications and Networking
    Conference (CCNC ''13), pp. 68–73, IEEE, January 2013. View at: Publisher Site
    | Google Scholar A. Anjum and M. U. Ilyas, “Activity recognition using smartphone
    sensors,” in Proceedings of the IEEE 10th Consumer Communications and Networking
    Conference (CCNC ''13), pp. 914–919, IEEE, Las Vegas, Nev, USA, January 2013.
    View at: Publisher Site | Google Scholar A. Bujari, B. Licar, and C. E. Palazzi,
    “Movement pattern recognition through smartphone''s accelerometer,” in Proceedings
    of the IEEE Consumer Communications and Networking Conference (CCNC ''12), pp.
    502–506, January 2012. View at: Publisher Site | Google Scholar M. B. Kjærgaard,
    M. Wirz, D. Roggen, and G. Tröster, “Detecting pedestrian flocks by fusion of
    multi-modal sensors in mobile phones,” in Proceedings of the ACM Conference on
    Ubiquitous Computing (UbiComp ''12), pp. 240–249, 2012. View at: Publisher Site
    | Google Scholar Y. Iwasawa, K. Nagamine, I. E. Yairi, and Y. Matsuo, “Toward
    an automatic road accessibility information collecting and sharing based on human
    behavior sensing technologies of wheelchair users,” Procedia Computer Science,
    vol. 63, pp. 74–81, 2015. View at: Publisher Site | Google Scholar Y. Iwasawa,
    K. Nagamine, Y. Matsuo, and I. Eguchi Yairi, “Road sensing: personal sensing and
    machine learning for development of large scale accessibility map,” in Proceedings
    of the 17th International ACM SIGACCESS Conference on Computers & Accessibility,
    pp. 335–336, ACM, Lisbon, Portugal, October 2015. View at: Publisher Site | Google
    Scholar G. Merlino, S. Arkoulis, S. Distefano, C. Papagianni, A. Puliafito, and
    S. Papavassiliou, “Mobile crowdsensing as a service: a platform for applications
    on top of sensing clouds,” Future Generation Computer Systems, vol. 56, pp. 623–639,
    2016. View at: Publisher Site | Google Scholar F. Callegati, A. Campi, A. Melis,
    M. Prandini, and B. Zevenbergen, “Privacy-preserving design of data processing
    systems in the public transport context,” Pacific Asia Journal of the Association
    for Information Systems, vol. 7, no. 4, 2015. View at: Google Scholar A. Melis,
    M. Prandini, L. Sartori, and F. Callegati, “Public transportation, IoT, trust
    and urban habits,” in Internet Science, F. Bagnoli, A. Satsiou, I. Stavrakakis
    et al., Eds., vol. 9934 of Lecture Notes in Computer Science, pp. 318–325, Springer,
    Berlin, Germany, 2016. View at: Publisher Site | Google Scholar M. Roccetti, S.
    Ferretti, C. E. Palazzi, P. Salomoni, and M. Furini, “Riding the web evolution:
    from egoism to altruism,” in Proceedings of the 5th IEEE Consumer Communications
    and Networking Conference (CCNC ''08), pp. 1123–1127, IEEE, Las Vegas, Nev, USA,
    January 2008. View at: Publisher Site | Google Scholar S. Mirri, C. Prandi, and
    P. Salomoni, “A context-aware system for personalized and accessible pedestrian
    paths,” in Proceedings of the International Conference on High Performance Computing
    and Simulation (HPCS ''14), pp. 833–840, July 2014. View at: Publisher Site |
    Google Scholar Google, “General Transit Feed Specification,” https://developers.google.com/transit/gtfs/reference
    View at: Google Scholar Y. L. Simmhan, B. Plale, and D. Gannon, A Survey of Data
    Provenance Techniques, vol. 47405, Computer Science Department, Indiana University,
    Bloomington, Ind, USA, 2005. K. Xu, H. Xiong, C. Wu, D. Stefan, and D. Yao, “Data-provenance
    verification for secure hosts,” IEEE Transactions on Dependable and Secure Computing,
    vol. 9, no. 2, pp. 173–183, 2012. View at: Publisher Site | Google Scholar R.
    C. Merkle, “A digital signature based on a conventional encryption function,”
    in Advances in Cryptology—CRYPTO ''87, vol. 293 of Lecture Notes in Computer Science,
    pp. 369–378, Springer, Berlin, Germany, 2000. View at: Publisher Site | Google
    Scholar C. Shahabi, “Towards a generic framework for trustworthy spatial crowdsourcing,”
    in Proceedings of the 12th International ACM Workshop on Data Engineering for
    Wireless and Mobile Acess (MobiDE ''13), pp. 1–4, ACM, New York, NY, USA, June
    2013. View at: Publisher Site | Google Scholar P. G. Ipeirotis, F. Provost, and
    J. Wang, “Quality management on amazon mechanical turk,” in Proceedings of the
    ACM SIGKDD Workshop on Human Computation (HCOMP ''10), pp. 64–67, ACM, New York,
    NY, USA, 2010. View at: Publisher Site | Google Scholar P. Gilbert, L. P. Cox,
    J. Jung, and D. Wetherall, “Toward trustworthy mobile sensing,” in Proceedings
    of the 11th Workshop on Mobile Computing Systems and Applications (HotMobile ''10),
    pp. 31–36, Annapolis, Md, USA,, February 2010. View at: Publisher Site | Google
    Scholar C. Prandi, S. Ferretti, S. Mirri, and P. Salomoni, “Trustworthiness in
    crowd- sensed and sourced georeferenced data,” in Proceedings of the 13th IEEE
    International Conference on Pervasive Computing and Communication (PerCom ''15),
    pp. 402–407, March 2015. View at: Publisher Site | Google Scholar T. Erl, Service-Oriented
    Architecture: Concepts, Technology, and Design, Prentice Hall PTR, River Edge,
    NJ, USA, 2005. F. Montesi, C. Guidi, and G. Zavattaro, “Composing services with
    JOLIE,” in Proceedings of the 5th IEEE European Conference on Web Services (ECOWS
    ''07), pp. 13–22, Halle, Germany, November 2007. View at: Publisher Site | Google
    Scholar N. Taylor and K. Cheverst, “Supporting community awareness with interactive
    displays,” Computer, vol. 45, no. 5, Article ID 6171144, pp. 26–32, 2012. View
    at: Publisher Site | Google Scholar S. Mirri, C. Prandi, and P. Salomoni, “Personalizing
    pedestrian accessible way-finding with mPASS,” in Proceedings of the 13th IEEE
    Annual Consumer Communications & Networking Conference (CCNC ''16), pp. 1119–1124,
    Las Vegas, Nev, USA, January 2016. View at: Publisher Site | Google Scholar M.
    L. Tolerico, D. Ding, R. A. Cooper et al., “Assessing mobility characteristics
    and activity levels of manual wheelchair users,” Journal of Rehabilitation Research
    and Development, vol. 44, no. 4, pp. 561–571, 2007. View at: Publisher Site |
    Google Scholar Copyright Copyright © 2016 Silvia Mirri et al. This is an open
    access article distributed under the Creative Commons Attribution License, which
    permits unrestricted use, distribution, and reproduction in any medium, provided
    the original work is properly cited. PDF Download Citation Download other formats
    Order printed copies Views 2393 Downloads 2073 Citations 46 About Us Contact us
    Partnerships Blog Journals Article Processing Charges Print editions Authors Editors
    Reviewers Partnerships Hindawi XML Corpus Open Archives Initiative Fraud prevention
    Follow us: Privacy PolicyTerms of ServiceResponsible Disclosure PolicyCookie PolicyCopyrightModern
    slavery statementCookie Preferences'
  inline_citation: '>'
  journal: Journal of mobile information systems
  limitations: '>'
  pdf_link: https://downloads.hindawi.com/journals/misy/2016/2821680.pdf
  publication_year: 2016
  relevance_score1: 0
  relevance_score2: 0
  title: A Service-Oriented Approach to Crowdsensing for Accessible Smart Mobility
    Scenarios
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1007/978-3-540-44918-8_5
  analysis: '>'
  authors:
  - Laure Berti‐Équille
  citation_count: 13
  full_citation: '>'
  full_text: '>

    Your privacy, your choice We use essential cookies to make sure the site can function.
    We also use optional cookies for advertising, personalisation of content, usage
    analysis, and social media. By accepting optional cookies, you consent to the
    processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Log in Find a journal
    Publish with us Track your research Search Cart Home Quality Measures in Data
    Mining Chapter Measuring and Modelling Data Quality for Quality-Awareness in Data
    Mining Chapter pp 101–126 Cite this chapter Access provided by University of Nebraska-Lincoln
    Download book PDF Quality Measures in Data Mining Laure Berti-Équille  Part of
    the book series: Studies in Computational Intelligence ((SCI,volume 43)) 1198
    Accesses 9 Citations 3 Altmetric Keywords Data Quality Association Rule Data Warehouse
    Record Linkage Data Mining Process These keywords were added by machine and not
    by the authors. This process is experimental and the keywords may be updated as
    the learning algorithm improves. Access provided by University of Nebraska-Lincoln.
    Download to read the full chapter text Chapter PDF References Avenali A, Batini
    C, Bertolazzi P, and Missier P. A formulation of the data quality optimization
    problem. In Proc. of the Intl. CAiSE Workhop on Data and Information Quality (DIQ),
    pages 49-63, Riga, Latvia, 2004. Google Scholar   Karakasidis A, Vassiliadis P,
    and Pitoura E. Etl queues for active data warehousing. In Proc. of the 2nd ACM
    SIGMOD Workshop on Information Quality in Information Systems (IQIS) in conjunction
    with ACM PODS/SIGMOD, pages 28-39, Baltimore, MD, USA, 2005. Google Scholar   McCallum
    A, Nigam K, and Ungar LH. Efficient clustering of high-dimensional data sets with
    application to reference matching. In Proc. of the 6th ACM SIGKDD Conf. on Knowledge
    Discovery and Data Mining (KDD), pages 169-178, Boston, MA, USA, 2000. Google
    Scholar   Monge A. Matching algorithms within a duplicate detection system. IEEE
    Data Eng. Bull., 23(4):14-20, 2000. Google Scholar   Sheth A, Wood C, and Kashyap
    V. Q-data: Using deductive database technology to improve data quality. In Proc.
    of Intl. Workshop on Programming with Logic Databases (ILPS), pages 23-56, 1993.
    Google Scholar   Simitsis A, Vassiliadis P, and Sellis TK. Optimizing etl processes
    in data warehouses. In Proc. of the 11th Intl. Conf. on Data Engineering (ICDE),
    pages 564-575, Tokyo, Japan, 2005. Google Scholar   Dempster AP, Laird NM, and
    Rubin DB. Maximum likelihood from incomplete data via the em algorithm. Journal
    of the Royal Statistical Society, 39:1-38, 1977. MATH   MathSciNet   Google Scholar   Kahn
    B, Strong D, and Wang R. Information quality benchmark: Product and service performance.
    Com. of the ACM, 45(4):184-192, 2002. Article   Google Scholar   Batini C, Catarci
    T, and Scannapiceco M. A survey of data quality issues in cooperative information
    systems. In Tutorial presented at the 23rd Intl. Conf. on Conceptual Modeling
    (ER), Shanghai, China, 2004. Google Scholar   Djeraba C. Association and content-based
    retrieval. IEEE Transactions on Knowledge and Data Engineering (TDKE), 15(1):118-135,
    2003. Article   Google Scholar   Fox C, Levitin A, and Redman T. The notion of
    data and its quality dimensions. Information Processing and Management, 30(1),
    1994. Google Scholar   Ordonez C and Omiecinski E. Discovering association rules
    based on image content. In Proc. of IEEE Advances in Digital Libraries Conf. (ADL’99),
    pages 38-49, 1999. Google Scholar   Carlson D. Data stewardship in action. DM
    Review, 2002. Google Scholar   Loshin D. Enterprise Knowledge Management: The
    Data Quality Approach. .Morgan Kaufmann, 2001. Google Scholar   Pyle D. Data Preparation
    for Data Mining. Morgan Kaufmann, 1999. Google Scholar   Quass D and Starkey P.
    Record linkage for genealogical databases. In Proc. of ACM SIGKDD’03 Workshop
    on Data Cleaning, Record Linkage and Object Consolidation, pages 40-42, Washington,
    DC, USA, 2003. Google Scholar   Theodoratos D and Bouzeghoub M. Data currency
    quality satisfaction in the design of a data warehouse. Special Issue on Design
    and Management of Data Warehouses, Intl. Journal of Cooperative Inf. Syst., 10(3):299-326,
    2001. Article   Google Scholar   Paradice DB and Fuerst WL. A mis data quality
    management strategy based on an optimal methodology. Journal of Information Systems,
    5(1):48-66, 1991. Google Scholar   Ballou DP and Pazer H. Designing information
    systems to optimize the accuracy-timeliness trade-off. Information Systems Research,
    6(1), 1995. Google Scholar   Ballou DP and Pazer H. Modeling completeness versus
    consistency trade-offs in information decision contexts. IEEE Transactions on
    Knowledge and Data Engineering (TDKE), 15(1):240-243, 2002. Google Scholar   Guérin
    E, Marquet G, Burgun A, Loral O, Berti- Équille L, Leser U, and Moussouni F. Integrating
    and warehousing liver gene expression data and related biomedical resources in
    gedaw. In Proc. of the 2nd Intl. Workshop on Data Integration in the Life Science
    (DILS), San Diego, CA, USA, 2005. Google Scholar   Knorr E and Ng R. Algorithms
    for mining distance-based outliers in large datasets. In Proc. of the 24th Intl.
    Conf. on Very Large Data Bases (VLDB), pages 392-403, New York City, USA, 1998.
    Google Scholar   Rahm E and Do H. Data cleaning: Problems and current approaches.
    IEEE Data Eng. Bull., 23(4):3-13, 2000. Google Scholar   Caruso F, Cochinwala
    M, Ganapathy U, Lalk G, and Missier P. Telcordia’s database reconciliation and
    data quality analysis tool. In Proc. of the 26th Intl. Conf. on Very Large Data
    Bases (VLDB), pages 615-618, Cairo, Egypt, September 10-14 2000. Google Scholar   Naumann
    F. Quality-Driven Query Answering for Integrated Information Systems, volume 2261
    of LNCS. Springer, 2002. Google Scholar   Naumann F, Leser U, and Freytag JC.
    Quality-driven integration of hetero-geneous information systems. In Proc. of
    the 25th Intl. Conf. on Very Large Data Bases (VLDB), pages 447-458, Edinburgh,
    Scotland, 1999. Google Scholar   De Giacomo G, Lembo D, Lenzerini M, and Rosati
    R. Tackling inconsistencies in data integration through source preferences. In
    Proc. of the 1rst ACM SIGMOD Workshop on Information Quality in Information Systems
    (IQIS), pages 27-34, Paris, France, 2004. Google Scholar   Delen G and Rijsenbrij
    D. The specification, engineering and measurement of information systems quality.
    Journal of Software Systems, 17:205-217, 1992. Article   Google Scholar   Liepins
    G and Uppuluri V. Data Quality Control: Theory and Pragmatics. M. Dekker, 1990.
    Google Scholar   Navarro G. A guided tour to approximate string matching. ACM
    Computer Surveys, 33(1):31-88, 2001. Article   Google Scholar   Shankaranarayan
    G, Wang RY, and Ziad M. Modeling the manufacture of an information product with
    ip-map. In Proc. of the 6th Intl. Conf. on Information Quality, Boston, MA, USA,
    2000. Google Scholar   Mihaila GA, Raschid L, and Vidal M. Using quality of data
    metadata for source selection and ranking. In Proc. of the 3rd Intl. WebDB Workshop,
    pages 93-98, Dallas, TX, USA, 2000. Google Scholar   Tayi GK and Ballou DP. Examining
    data quality. Com. of the ACM, 41(2):54-57,1998. Article   Google Scholar   Galhardas
    H, Florescu D, Shasha D, Simon E, and Saita C. Declarative data cleaning: Language,
    model and algorithms. In Proc. of the 9th Intl. Conf. on Very Large Data Bases
    (VLDB), pages 371-380, Roma, Italy, 2001. Google Scholar   Müller H, Leser U,
    and Freytag JC. Mining for patterns in contradictory data. In Proc. of the 1rst
    ACM SIGMOD Workshop on Information Quality in Information Systems (IQIS) in conjunction
    with ACM PODS/SIGMOD, pages 51-58, Paris, France, 2004. Google Scholar   Pasula
    H, Marthi B, Milch B, Russell S, and Shpitser I. Identity uncertainty and citation
    matching. In Proc. of the Intl. Conf. Advances in Neural Information Processing
    Systems (NIPS), pages 1401-1408, Vancouver, British Colombia, 2003. Google Scholar   Newcombe
    HB, Kennedy JM, Axford SJ, and James AP. Automatic linkage of vital records. Science,
    130:954-959, 1959. Article   Google Scholar   Fellegi IP and Sunter AB. A theory
    for record linkage. Journal of the American Statistical Association, 64:1183-1210,
    1969. Article   Google Scholar   Celko J and McDonald J. Don’t warehouse dirty
    data. Datamation, 41(18), 1995. Google Scholar   Rothenberg J. Metadata to support
    data quality and longevity. In Proc. Of the 1st IEEE Metadata Conf., 1996. Google
    Scholar   Schlimmer J. Learning determinations and checking databases. In Proc.
    Of AAAI Workshop on Knowledge Discovery in Databases, 1991. Google Scholar   Schafer
    JL. Analysis of Incomplete Multivariate Data. Chapman & Hall, 1997. Google Scholar   Ullmann
    JR. A binary n-gram technique for automatic correction of substitution, deletion,
    insertion and reversal errors in words. The Computer Journal, 20(2):141-147, 1997.
    Article   Google Scholar   Fan K, Lu H, Madnick S, and Cheung D. Discovering and
    reconciling value conflicts for numerical data integration. Information Systems,
    26(8):235-656, 2001. Article   Google Scholar   Huang K, Lee Y, and Wang R. Quality
    Information and Knowledge Management. Prentice Hall, New Jersey, 1999. Google
    Scholar   Berti- Équille L. Data quality awareness: a case study for cost-optimal
    association rule mining. Knowl. Inf. Syst., 2006. Google Scholar   English L.
    Improving Data Warehouse and Business Information Quality. Wiley, New York, 1998.
    Google Scholar   Gravano L, Ipeirotis PG, Jagadish HV, Koudas N, Muthukrishnan
    S, Pietarinen L, and Srivastava D. Using Q-grams in a DBMS for Approximate String
    Processing. IEEE Data Eng. Bull., 24(4), December 2001. Google Scholar   Gravano
    L, Ipeirotis PG, Koudas N, and Srivastava D. Text joins in an rdbms for web data
    integration. In Proc. of the 12th Intl. World Wide Web Conf. (WWW), pages 90-101,
    Budapest, Hungary, 2003. Google Scholar   Lim L, Srivastava J, Prabhakar S, and
    Richardson J. Entity identification in database integration. In Proc. of the 9th
    Intl. Conf. on Data Engineering (ICDE), pages 294-301, Vienna, Austria, 1993.
    Google Scholar   Liu L and Chi L. Evolutionary data quality. In Proc. of the 7th
    Intl. Conf. on Information Quality (IQ), MIT, Cambridge, USA, 2002. Google Scholar   Santis
    LD, Scannapieco M, and Catarci T. Trusting data quality in cooperative information
    systems. In Proc. of the Intl. Conf. on Cooperative Information Systems (CoopIS),
    pages 354-369, Catania, Sicily, Italy, 2003. Google Scholar   Bilenko M and Mooney
    RJ. Adaptive duplicate detection using learnable string similarity measures. In
    Proc. of the 9th ACM SIGKDD Conf. on Knowledge Discovery and Data Mining (KDD),
    pages 39-48, Washington, DC, USA, 2003. Google Scholar   Bouzeghoub M and Peralta
    V. A framework for analysis of data freshness. In Proc. of the 1st ACM SIGMOD
    Workshop on Information Quality in Information Systems (IQIS), pages 59-67, Paris,
    France, 2004. Google Scholar   Breunig M, Kriegel H, Ng R, and Sander J. Lof:
    Identifying density-based local outliers. In Proc. of 2000 ACM SIGMOD Conf., pages
    93-104, Dallas, TX, USA, May 16-18 2000. Google Scholar   Buechi M, Borthwick
    A, Winkel A, and Goldberg A. Cluemaker: a language for approximate record matching.
    In Proc. of the 8th Intl. Conf. on Information Quality (IQ), MIT, Cambridge, USA,
    2003. Google Scholar   Goodchild M and Jeansoulin R. Data Quality in Geographic
    Information: From Error to Uncertainty. Hermès, 1998. Google Scholar   Hernandez
    M and Stolfo S. Real-world data is dirty: Data cleansing and the merge/purge problem.
    Data Mining and Knowledge Discovery, 2(1):9-37, 1998. Article   Google Scholar   Jarke
    M, Jeusfeld MA, Quix C, and Vassiliadis P. Architecture and quality in data warehouses.
    In Proc. of the 10th Intl. Conf. on Advanced Information Systems Engineering (CAiSE),
    pages 93-113, Pisa, Italy, 1998. Google Scholar   Piattini M, Calero C, and Genero
    M, editors. Information and Database Quality, volume 25. Kluwer International
    Series on Advances in Database Systems, 2002. Google Scholar   Piattini M, Genero
    M, Calero C, Polo C, and Ruiz F. Chapter 14: Advanced Database Technology and
    Design, chapter Database Quality, pages 485-509. Artech House, 2000. Google Scholar   Scannapieco
    M, Pernici B, and Pierce E. Advances in Management Information Systems - Information
    Quality Monograph (AMIS-IQ), chapter IP-UML: A Methodology for Quality Improvement
    Based on IP-MAP and UML. Sharpe, 2004. Google Scholar   Weis M and Naumann F.
    Detecting duplicate objects in xml documents. In Proc. of the 1st Intl. ACM SIGMOD
    Workshop on Information Quality in Information Systems (IQIS) in conjunction with
    ACM PODS/SIGMOD, pages 10-19, Paris, France, 2004. Google Scholar   Jeusfeld MA,
    Quix C, and Jarke M. Design and analysis of quality information for data warehouses.
    In Proc. of 17th Intl. Conf. Conceptual Modelling (ER), pages 349-362, Singapore,
    1998. Google Scholar   Elfeky MG, Verykios VS, and Elmagarmid AK. Tailor: A record
    linkage toolbox. In Proc. of the 19th Intl. Conf. on Data Engineering (ICDE),
    pages 1-28, San Jose, CA, USA, 2002. Google Scholar   Brodie ML. Data quality
    in information systems. Information and Management, 3:245-258, 1980. Article   Google
    Scholar   Lavrač N, Flach PA, and Zupan B. Rule evaluation measures: A unifying
    view. In Proc. of the Intl. Workshop on Inductive Logic Programming (ILP), pages
    174-185, Bled, Slovenia, 1999. Google Scholar   Benjelloun O, Garcia-Molina H,
    Su Q, and Widom J. Swoosh: A generic approach to entity resolution. Technical
    report, Stanford Database Group., 2005. Google Scholar   ıane O, Han J, and Zhu
    H. Mining recurrent items in multimedia with progressive resolution refinement.
    In Proc. of the 16th Intl. Conf. on Data Engineering (ICDE), p.461-476, San Diego,
    CA, USA, 2000. Google Scholar   Christen P, Churches T, and Hegland M. Febrl -
    a parallel open source data linkage system. In Proc. of the 8th Pacific Asia Conf.
    on Advances in Knowledege Discovery and Data Mining (PAKDD), pages 638-647, Sydney,
    Australia, May 26-28 2004. Google Scholar   Missier P and Batini C. A multidimensional
    model for information quality in cis. In Proc. of the 8th Intl. Conf. on Information
    Quality (IQ), MIT, Cambridge, MA, USA, 2003. Google Scholar   Perner P. Data Mining
    on Multimedia, volume LNCS 2558. Springer, 2002. Google Scholar   Vassiliadis
    P. Data Warehouse Modeling and Quality Issues. PhD thesis, Technical University
    of Athens, Greece, 2000. Google Scholar   Vassiliadis P, Simitsis A, Georgantas
    P, and Terrovitis M. A framework for the design of etl scenarios. In Proc. of
    the 15th Intl. Conf. on Advanced Information Systems Engineering (CAiSE), pages
    520-535, Klagenfurt, Austria, 2003. Google Scholar   Vassiliadis P, Bouzeghoub
    M, and Quix C. Towards quality-oriented data warehouse usage and evolution. In
    Proc. of the 11th Intl. Conf. on Advanced Information Systems Engineering (CAiSE),
    pages 164-179, Heidelberg, Germany, 1999. Google Scholar   Vassiliadis P, Vagena
    Z, Skiadopoulos S, and Karayannidis N. ARKTOS: A Tool For Data Cleaning and Transformation
    in Data Warehouse Environments. IEEE Data Eng. Bull., 23(4):42-47, 2000. Google
    Scholar   Tan PN, Kumar V, and Srivastava J. Selecting the right interestingness
    measure for association patterns. In Proc. of the 8th ACM SIGKDD Conf. on Knowledge
    Discovery and Data Mining (KDD), pages 32-41, Edmonton, Canada, 2002. Google Scholar   Agrawal
    R, Imielinski T, and Swami AN. Mining association rules between sets of items
    in large databases. In Proc. of the 1993 ACM SIGMOD Conf., pages 207-216, Washington,
    DC,USA, 1993. Google Scholar   Ananthakrishna R, Chaudhuri S, and Ganti V. Eliminating
    fuzzy duplicates in datawarehouses. In Proc. of the 28th Intl. Conf. on Very Large
    Data Bases (VLDB), pages 586-597, Hong-Kong, China, 2002. Google Scholar   Baxter
    R, Christen P, and Churches T. A comparison of fast blocking methods for record
    linkage. In Proc. of ACM SIGKDD’03 Workshop on Data Cleaning, Record Linkage and
    Object Consolidation, pages 27-29, Washington, DC, USA, 2003. Google Scholar   Wang
    R. A product perspective on total data quality management. Com. Of the ACM, 41(2):58-65,
    1998. Article   Google Scholar   Wang R. Advances in Database Systems, volume
    23, chapter Journey to Data Quality. Kluwer Academic Press, Boston, MA, USA, 2002.
    Google Scholar   Wang R, Storey V, and Firth C. A framework for analysis of data
    quality research. IEEE Transactions on Knowledge and Data Engineering (TDKE),
    7(4):670-677, 1995. Google Scholar   Little RJ and Rubin DB. Statistical Analysis
    with Missing Data. Wiley, New-York, 1987. MATH   Google Scholar   Pearson RK.
    Data mining in face of contaminated and incomplete records. In Proc. of SIAM Intl.
    Conf. Data Mining, 2002. Google Scholar   Hamming RW. Error-detecting and error-correcting
    codes. Bell System Technical Journal, 29(2):147-160, 1950. MathSciNet   Google
    Scholar   Chaudhuri S, Ganjam K, Ganti V, and Motwani R. Robust and efficient
    fuzzy match for online data cleaning. In Proc. of the 2003 ACM SIGMOD Intl. Conf.
    on Management of Data, pages 313-324, San Diego, CA, USA, 2003. Google Scholar   Tejada
    S, Knoblock CA, and Minton S. Learning object identification rules for information
    integration. Information Systems, 26(8), 2001. Google Scholar   Ahmed T, Asgari
    AH, Mehaoua A, Borcoci E, Berti- Équille L, and Kormentzas G. End-to-end quality
    of service provisioning through an integrated management system for multimedia
    content delivery. Special Issue of Computer Communications on Emerging Middleware
    for Next Generation Networks, 2005. Google Scholar   Dasu T and Johnson T. Exploratory
    Data Mining and Data Cleaning. Wiley, New York, 2003. Book   MATH   Google Scholar   Dasu
    T, Johnson T, Muthukrishnan S, and Shkapenyuk V. Mining database structure or
    how to build a data quality browser. In Proc. of the 2002 ACM SIGMOD Intl. Conf.,
    pages 240-251, Madison, WI, USA, 2002. Google Scholar   Johnson T and Dasu T.
    Comparing massive high-dimensional data sets. In Proc. of the 4th Intl. Conf.
    KDD, pages 229-233, New York City, New York, USA, 1998. Google Scholar   Redman
    T. Data Quality: The Field Guide. Digital Press, Elsevier, 2001. Google Scholar   Raman
    V and Hellerstein JM. Potter’s wheel: an interactive data cleaning system. In
    Proc. of the 26th Intl. Conf. on Very Large Data Bases (VLDB), pages 381-390,
    Roma, Italy, 2001. Google Scholar   DuMouchel W, Volinsky C, Johnson T, Cortez
    C, and Pregibon D. Squashing flat files flatter. In Proc. of the 5th ACM SIGKDD
    Conf. on Knowledge Discovery and Data Mining (KDD), pages 6-16, San Diego, CA,
    USA, 1999. Google Scholar   Madnick SE Wang R, Kon HB. Data quality requirements
    analysis and modeling. In Proc. of the 9th Intl. Conf. on Data Engineering (ICDE),
    pages 670-677, Vienna, Austria, 1993. Google Scholar   Hou WC and Zhang Z. Enhancing
    database correctness: A statistical approach. In Proc. of the 1995 ACM SIGMOD
    Intl. Conf. on Management of Data, San Jose, CA, USA, 1995. Google Scholar   Winkler
    WE. Methods for evaluating and creating data quality. Information Systems, 29(7),
    2004. Google Scholar   Winkler WE and Thibaudeau Y. An application of the fellegi-sunter
    model of record linkage to the 1990 u.s. decennial census. Technical Report Statistical
    Research Report Series RR91/09, U.S. Bureau of the Census, Washington, DC, USA,
    1991. Google Scholar   Low WL, Lee ML, and Ling TW. A knowledge-based approach
    for duplicate elimination in data cleaning. Information System, 26(8), 2001. Google
    Scholar   Cui Y and Widom J. Lineage tracing for general data warehouse transformation.
    In Proc. of the 27th Intl. Conf. on Very Large Data Bases (VLDB), pages 471-480,
    Roma, Italy, September 11-14 2001. Google Scholar   Zhu Y and Shasha D. Statstream:
    Statistical monitoring of thousands of data streams in real time. In Proc. of
    the 10th Intl. Conf. on Very Large Data Bases (VLDB), pages 358-369, Hong-Kong,
    China, 2002. Google Scholar   Download references Author information Authors and
    Affiliations IRISA, University of Rennes I, France Laure Berti-Équille Editor
    information Editors and Affiliations LINA-CNRS FRE 2729, Ecole polytechnique de
    l''université de Nantes, Rue Christian-Pauc-La Chantrerie, 60601, 44306, NANTES
    Cedex 3, France Fabrice J. Guillet Department of Computer Science, University
    of Regina, SK S4S 0A2, Regina, Canada Howard J. Hamilton Rights and permissions
    Reprints and permissions Copyright information © 2007 Springer-Verlag Berlin Heidelberg
    About this chapter Cite this chapter Berti-Équille, L. (2007). Measuring and Modelling
    Data Quality for Quality-Awareness in Data Mining. In: Guillet, F.J., Hamilton,
    H.J. (eds) Quality Measures in Data Mining. Studies in Computational Intelligence,
    vol 43. Springer, Berlin, Heidelberg. https://doi.org/10.1007/978-3-540-44918-8_5
    Download citation .RIS.ENW.BIB DOI https://doi.org/10.1007/978-3-540-44918-8_5
    Publisher Name Springer, Berlin, Heidelberg Print ISBN 978-3-540-44911-9 Online
    ISBN 978-3-540-44918-8 eBook Packages Engineering Engineering (R0) Share this
    chapter Anyone you share the following link with will be able to read this content:
    Get shareable link Provided by the Springer Nature SharedIt content-sharing initiative
    Publish with us Policies and ethics Sections References Chapter PDF References
    Author information Editor information Rights and permissions Copyright information
    About this chapter Publish with us Discover content Journals A-Z Books A-Z Publish
    with us Publish your research Open access publishing Products and services Our
    products Librarians Societies Partners and advertisers Our imprints Springer Nature
    Portfolio BMC Palgrave Macmillan Apress Your privacy choices/Manage cookies Your
    US state privacy rights Accessibility statement Terms and conditions Privacy policy
    Help and support 129.93.161.219 Big Ten Academic Alliance (BTAA) (3000133814)
    - University of Nebraska-Lincoln (3000134173) © 2024 Springer Nature'
  inline_citation: '>'
  journal: Studies in computational intelligence
  limitations: '>'
  pdf_link: null
  publication_year: 2007
  relevance_score1: 0
  relevance_score2: 0
  title: Measuring and Modelling Data Quality for Quality-Awareness in Data Mining
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1007/s10115-006-0006-x
  analysis: '>'
  authors:
  - Laure Berti‐Équille
  citation_count: 20
  full_citation: '>'
  full_text: '>

    Your privacy, your choice We use essential cookies to make sure the site can function.
    We also use optional cookies for advertising, personalisation of content, usage
    analysis, and social media. By accepting optional cookies, you consent to the
    processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Log in Find a journal Publish
    with us Track your research Search Cart Home Knowledge and Information Systems
    Article Data quality awareness: a case study for cost optimal association rule
    mining Regular Paper Published: 28 March 2006 Volume 11, pages 191–215, (2007)
    Cite this article Download PDF Access provided by Big Ten Academic Alliance (BTAA)
    Knowledge and Information Systems Aims and scope Submit manuscript Laure Berti-Équille  309
    Accesses 12 Citations Explore all metrics Abstract The quality of discovered association
    rules is commonly evaluated by interestingness measures (commonly support and
    confidence) with the purpose of supplying indicators to the user in the understanding
    and use of the new discovered knowledge. Low-quality datasets have a very bad
    impact over the quality of the discovered association rules, and one might legitimately
    wonder if a so-called “interesting” rule noted LHS→ RHS is meaningful when 30%
    of the LHS data are not up-to-date anymore, 20% of the RHS data are not accurate,
    and 15% of the LHS data come from a data source that is well-known for its bad
    credibility. This paper presents an overview of data quality characterization
    and management techniques that can be advantageously employed for improving the
    quality awareness of the knowledge discovery and data mining processes. We propose
    to integrate data quality indicators for quality aware association rule mining.
    We propose a cost-based probabilistic model for selecting legitimately interesting
    rules. Experiments on the challenging KDD-Cup-98 datasets show that variations
    on data quality have a great impact on the cost and quality of discovered association
    rules and confirm our approach for the integrated management of data quality indicators
    into the KDD process that ensure the quality of data mining results. Article PDF
    Similar content being viewed by others MOGACAR: A Method for Filtering Interesting
    Classification Association Rules Chapter © 2015 Mining Association Rules from
    Database Tables with the Instances of Simpson’s Paradox Chapter © 2013 A Framework
    for Interestingness Measures for Association Rules with Discrete and Continuous
    Attributes Based on Statistical Validity Chapter © 2015 References Avenali A,
    Batini C, Bertolazzi P, Missier P (2004) A formulation of the data quality optimization
    problem. In: Proceedings of the international CAiSE workhop on data and information
    quality (DIQ), Riga, Latvia, pp 49–63 Ballou DP, Pazer H (1995) Designing information
    systems to optimize the accuracy-timeliness trade-off. Inf Syst Res 6(1) Ballou
    DP, Pazer H (2002) Modeling completeness versus consistency trade-offs in information
    decision contexts. IEEE Trans Knowl Data Eng (TDKE) 15(1):240–243 Google Scholar   Batini
    C, Catarci T, Scannapiceco M (2004) A survey of data quality issues in cooperative
    information systems. In: Tutorial presented at the 23rd international conference
    on conceptual modeling (ER), Shanghai, China Benjelloun O, Garcia-Molina H, Su
    Q, Widom J (2005) Swoosh: A generic approach to entity resolution. Technical Report,
    Stanford Database Group Berti-Équille L, Moussouni F (2005) Quality-aware integration
    and warehousing of genomic data. In: Proceedings of the 10th international conference
    on information quality (IQ''05), MIT, Cambridge, USA Bilenko M, Mooney RJ (2003)
    Adaptive duplicate detection using learnable string similarity measures. In: Proceedings
    of the 9th ACM SIGKDD conference on knowledge discovery and data mining (KDD),
    Washington, DC, USA, pp 39–48 Bouzeghoub M, Peralta V (2004) A framework for analysis
    of data freshness. In: Proceedings of the 1st ACM SIGMOD workshop on information
    quality in information systems (IQIS), Paris, France, pp 59–67 Breunig M, Kriegel
    H, Ng R, Sander J (2000) LOF: Identifying density-based local outliers. In: Proceedings
    of 2000 ACM SIGMOD conference, Dallas, TX, USA, pp 93–104 Brodie ML (1980) Data
    quality in information systems. Inform Manage 3:245–258 Article   Google Scholar   Celko
    J, McDonald J (1995) Don''t warehouse dirty data. Datamation 41(18) Chaudhuri
    S, Ganjam K, Ganti V, Motwani R (2003) Robust and efficient fuzzy match for online
    data cleaning. In: Proceedings of the 2003 ACM SIGMOD international conference
    on management of data, San Diego, CA, USA, pp 313–324 Cui Y, Widom J (2001) Lineage
    tracing for general data warehouse transformation. In: Proceedings of the 27th
    international conference on very large data bases (VLDB), Roma, Italy, September
    11–14, pp 471–480 Dasu T, Johnson T (2003) Exploratory data mining and data cleaning.
    Wiley, New York MATH   Google Scholar   Dasu T, Johnson T, Muthukrishnan S, Shkapenyuk
    V (2002) Mining database structure or, how to build a data quality browser. In:
    Proceedings of the 2002 ACM SIGMOD international conference on management of data,
    Madison, WI, USA, pp 240–251 De Giacomo G, Lembo D, Lenzerini M, Rosati R (2004)
    Tackling inconsistencies in data integration through source preferences. In: Proceedings
    of the 1st ACM SIGMOD workshop on information quality in information systems (IQIS),
    Paris, France, pp 27–34 Delen G, Rijsenbrij D (1992) The specification, engineering
    and measurement of information systems quality. J Softw Syst 17:205–217 Article   Google
    Scholar   Elfeky MG, Verykios VS, Elmagarmid AK (2002) Tailor: A record linkage
    toolbox. In: Proceedings of the 19th international conference on data engineering
    (ICDE), San Jose, CA, USA, pp 1–28 English L (1998) Improving data warehouse and
    business information quality. Wiley, New York Google Scholar   Fan K, Lu H, Madnick
    S, Cheung D (2001) Discovering and reconciling value conflicts for numerical data
    integration. Inform Syst 26(8):235–656 Article   Google Scholar   Fellegi IP,
    Sunter AB (1969) A theory for record linkage. J Am Stat Assoc 64:1183-1210 Article   Google
    Scholar   Fox C, Levitin A, Redman T (1994) The notion of data and its quality
    dimensions. Information Processing and Management 30(1) Gravano L, Ipeirotis PG,
    Koudas N, Srivastava D (2003) Text joins in an RDBMS for web data integration.
    In: Proceedings of the 12th international world wide web conference (WWW), Budapest,
    Hungary, pp 90–101 Hernandez M, Stolfo S (1998) Real-world data is dirty: Data
    cleansing and the merge/purge problem. Data Min Knowl Discov 2(1):9–37 Article   Google
    Scholar   Hou WC, Zhang Z (1995) Enhancing database correctness: A statistical
    approach. In: Proceedings of the 1995 ACM SIGMOD international conference on management
    of data, San Jose, CA, USA Huang K, Lee Y, Wang R (1999) Quality information and
    knowledge management. Prentice Hall, New Jersey Google Scholar   Jarke M, Jeusfeld
    MA, Quix C, Vassiliadis P (1998) Architecture and quality in data warehouses.
    In: Proceedings of the 10th international conference on advanced information systems
    engineering (CAiSE), Pisa, Italy, pp 93–113 Johnson T, Dasu T (1998) Comparing
    massive high-dimensional data sets. In: Proceedings of the 4th international conference
    KDD, New York City, New York, USA, pp 229–233 Kahn B, Strong D, Wang R (2002)
    Information quality benchmark: Product and service performance. Com. ACM 45(4):184–192
    Article   Google Scholar   Knorr E, Ng R (1998) Algorithms for mining distance-based
    outliers in large datasets. In: Proceedings of the 24th international conference
    on very large data bases (VLDB), New York City, USA, pp 392–403 Lavrač N, Flach
    PA, Zupan B (1999) Rule evaluation measures: A unifying view. In: Proceedings
    of the international workshop on inductive logic programming (ILP), Bled, Slovenia,
    pp 174–185 Liepins G, Uppuluri V (1990) Data quality control: Theory and pragmatics.
    Marcel Dekker, New York Google Scholar   Lim L, Srivastava J, Prabhakar S, Richardson
    J (1993) Entity identification in database integration. In: Proceedings of the
    9th international conference on data engineering (ICDE), Vienna, Austria, pp 294–301
    Little RJ, Rubin DB (1987) Statistical analysis with missing data. Wiley, New
    York MATH   Google Scholar   Liu L, Chi L (2002) Evolutionary data quality. In:
    Proceedings of the 7th international conference on information quality (IQ), MIT,
    Cambridge, USA McCallum A, Nigam K, Ungar LH (2000) Efficient clustering of high-dimensional
    data sets with application to reference matching. In: Proceedings of the 6th ACM
    SIGKDD conference on knowledge discovery and data mining (KDD), Boston, MA, USA,
    pp 169–178 Mihaila GA, Raschid L, Vidal M (2000) Using quality of data metadata
    for source selection and ranking. In: Proceedings of the 3rd international WebDB
    workshop, Dallas, TX, USA, pp 93–98 Missier P, Batini C (2003) A multidimensional
    model for information quality in CIS. In: Proceedings of the 8th international
    conference on information quality (IQ), MIT, Cambridge, MA, USA Monge A (2000)
    Matching algorithms within a duplicate detection system. IEEE Data Eng Bull 23(4):14–20
    Google Scholar   Müller H, Leser U, Freytag JC (2004) Mining for patterns in contradictory
    data. In: Proceedings of the 1st ACM SIGMOD workshop on information quality in
    information systems (IQIS) in conjunction with ACM PODS/SIGMOD, Paris, France,
    pp 51–58 Naumann F, Leser U, Freytag J (1999) Quality-driven integration of heterogeneous
    information systems. In: Proceedings of the 25th international conference on very
    large data bases (VLDB), Edinburgh, Scotland, pp 447–458 Naumann F (2002) Quality-driven
    query answering for integrated information systems. LNCS 2261, Springer, Berlin
    Heidelberg New York MATH   Google Scholar   Pasula H, Marthi B, Milch B, Russell
    S, Shpitser I (2003) Identity uncertainty and citation matching. In: Proceedings
    of the international conference advances in neural information processing systems
    (NIPS), Vancouver, British Colombia, pp 1401–1408 Pearson RK (2002) Data mining
    in face of contaminated and incomplete records. In: Proceedings of SIAM international
    conference on data mining Perner P (2002) Data mining on multimedia. LNCS 2558,
    Springer, Berlin Heidelberg New York MATH   Google Scholar   Piattini M, Genero
    M, Calero C, Polo C, Ruiz F (2000) Database quality. Chapter 14: Advanced database
    technology and design. Artech House, Norwood, MA, pp 485–509 Piattini, M, Calero
    C, Genero M (eds)(2002) Information and database quality. The Kluwer International
    Series on Advances in Database Systems, 25 Pyle D (1999) Data preparation for
    data mining. Morgan Kaufmann, San Mateo, CA Rahm E, Do H (2000) Data cleaning:
    Problems and current approaches. IEEE Data Eng Bull 23(4):3–13 Google Scholar   Raman
    V, Hellerstein JM (2001) Potter''s wheel: An interactive data cleaning system.
    In: Proceedings of the 26th international conference on very large data bases
    (VLDB), Roma, Italy, pp 381–390 Redman T (2001) Data quality: The field guide.
    Digital Press, Elsevier Rothenberg J (1996) Metadata to support data quality and
    longevity. In: Proceedings of the 1st IEEE metadata conference, Silver Spring,
    MD Santis LD, Scannapieco M, Catarci T (2003) Trusting data quality in cooperative
    information systems. In: Proceedings of the international conference on cooperative
    information systems (CoopIS), Catania, Sicily, Italy, pp 354–369 Scannapieco M,
    Pernici B, Pierce E (2004) IP-UML: A methodology for quality improvement based
    on IP-MAP and UML. Advances in Management Information Systems-Information Quality
    Monograph (AMIS-IQ), Sharpe Schafer JL (1997) Analysis of incomplete multivariate
    data. Chapman & Hall, London MATH   Google Scholar   Schlimmer J (1991) Learning
    determinations and checking databases. In: Proceedings of AAAI workshop on knowledge
    discovery in databases, AAAI–1991 Anaheim California Tan P-N, Kumar V, Srivastava
    J (2002) Selecting the right interestingness measure for association patterns.
    In: Proceedings of the 8th ACM SIGKDD conference on knowledge discovery and data
    mining (KDD), Edmonton, Canada, pp 32–41 Theodoratos D, Bouzeghoub M (2001) Data
    currency quality satisfaction in the design of a data warehouse. Special Issue
    on design and management of data warehouses. Int J Coop Inf Syst 10(3):299–326
    Google Scholar   Vassiliadis P, Bouzeghoub M, Quix C (1999) Towards quality-oriented
    data warehouse usage and evolution. In: Proceedings of the 11th international
    conference on advanced information systems engineering (CAiSE), Heidelberg, Germany,
    pp 164–179 Vassiliadis P, Simitsis A, Georgantas P, Terrovitis M (2003) A framework
    for the design of ETL scenarios. In: Proceedings of the 15th international conference
    on advanced information systems engineering (CAiSE), Klagenfurt, Austria, pp 520–535
    Vassiliadis P (2000) Data warehouse modeling and quality issues. PhD thesis, Technical
    University of Athens, Greece Wang R, Kon HB, Madnick SE (1993) Data quality requirements
    analysis and modeling. In: Proceedings of the 9th international conference on
    data engineering (ICDE), Vienna, Austria, pp 670–677 Wang R, Storey V, Firth C
    (1995) A framework for analysis of data quality research. IEEE Trans Knowl Data
    Eng (TDKE) 7(4):670–677 Google Scholar   Wang R (1998) A product perspective on
    total data quality management. Com. ACM 41(2):58–65 Article   Google Scholar   Wang
    R (2002) Journey to data quality, vol 23 of Advances in database systems. Kluwer,
    Boston, MA, USA Google Scholar   Wang K, Zhou S, Yang Q, Yeung JMS (2005) Mining
    customer value: From association rules to direct marketing. J Data Min Knowl Discov
    Weis M, Naumann F (2004) Detecting duplicate objects in XML documents. In: Proceedings
    of the 1st international ACM SIGMOD workshop on information quality in information
    systems (IQIS) in conjunction with ACM PODS/SIGMOD, Paris, France, pp 10–19 Winkler
    WE (2004) Methods for evaluating and creating data quality. Inf Syst 29(7) Download
    references Author information Authors and Affiliations IRISA, University of Rennes
    I, Campus Universitaire de Beaulieu, 35042, Rennes, France Laure Berti-Équille
    Corresponding author Correspondence to Laure Berti-Équille. Rights and permissions
    Reprints and permissions About this article Cite this article Berti-Équille, L.
    Data quality awareness: a case study for cost optimal association rule mining.
    Knowl Inf Syst 11, 191–215 (2007). https://doi.org/10.1007/s10115-006-0006-x Download
    citation Received 09 May 2005 Revised 01 November 2005 Accepted 14 January 2006
    Published 28 March 2006 Issue Date February 2007 DOI https://doi.org/10.1007/s10115-006-0006-x
    Share this article Anyone you share the following link with will be able to read
    this content: Get shareable link Provided by the Springer Nature SharedIt content-sharing
    initiative Keywords Quality awareness mining Data quality management Data quality
    metadata Cost model Association rule mining Use our pre-submission checklist Avoid
    common mistakes on your manuscript. Sections References Abstract Article PDF References
    Author information Rights and permissions About this article Advertisement Discover
    content Journals A-Z Books A-Z Publish with us Publish your research Open access
    publishing Products and services Our products Librarians Societies Partners and
    advertisers Our imprints Springer Nature Portfolio BMC Palgrave Macmillan Apress
    Your privacy choices/Manage cookies Your US state privacy rights Accessibility
    statement Terms and conditions Privacy policy Help and support 129.93.161.219
    Big Ten Academic Alliance (BTAA) (3000133814) - University of Nebraska-Lincoln
    (3000134173) © 2024 Springer Nature'
  inline_citation: '>'
  journal: Knowledge and Information Systems
  limitations: '>'
  pdf_link: null
  publication_year: 2006
  relevance_score1: 0
  relevance_score2: 0
  title: 'Data quality awareness: a case study for cost optimal association rule mining'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/electronics9122083
  analysis: '>'
  authors:
  - John Byabazaire
  - Gregory M. P. O’Hare
  - Declan Delaney
  citation_count: 23
  full_citation: '>'
  full_text: '>

    Web Store Add shortcut Name URL Customize Chrome'
  inline_citation: '>'
  journal: Electronics
  limitations: '>'
  pdf_link: https://www.mdpi.com/2079-9292/9/12/2083/pdf
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: 'Data Quality and Trust: Review of Challenges and Opportunities for Data
    Sharing in IoT'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/info10120374
  analysis: '>'
  authors:
  - Otmane Azeroual
  citation_count: 7
  full_citation: '>'
  full_text: '>

    Web Store Add shortcut Name URL Customize Chrome'
  inline_citation: '>'
  journal: Information (Basel)
  limitations: '>'
  pdf_link: https://www.mdpi.com/2078-2489/10/12/374/pdf?version=1575009317
  publication_year: 2019
  relevance_score1: 0
  relevance_score2: 0
  title: Text and Data Quality Mining in CRIS
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1007/s42486-020-00054-y
  analysis: '>'
  authors:
  - Nasr Kasrin
  - Aboubakr Benabbas
  - Golnaz Elmamooz
  - Daniela Nicklas
  - Simon Steuer
  - Michael Sünkel
  citation_count: 5
  full_citation: '>'
  full_text: ">\nVol:.(1234567890)\nCCF Transactions on Pervasive Computing and Interaction\
    \ (2021) 3:76–93\nhttps://doi.org/10.1007/s42486-020-00054-y\n1 3\nREGULAR PAPER\n\
    Data‑sharing markets for integrating IoT data processing \nfunctionalities\nNasr Kasrin1\
    \  · Aboubakr Benabbas1 · Golnaz Elmamooz1 · Daniela Nicklas1 · Simon Steuer1 ·\
    \ Michael Sünkel1\nReceived: 16 July 2020 / Accepted: 24 December 2020 / Published\
    \ online: 26 February 2021 \n© The Author(s) 2021\nAbstract\nThe recent evolution\
    \ of the Internet of Things into a cyber-physical reality has spawned various\
    \ challenges from a data \nmanagement perspective. In addition, IoT platform designers\
    \ are faced with another set of questions. How can platforms \nbe extended to\
    \ smoothly integrate new data management functionalities? Currently, data processing\
    \ related tasks are typi-\ncally realized by manually developed code and functions\
    \ which creates difficulties in maintenance and growth. Hence we \nneed to explore\
    \ other approaches to integration for IoT platforms. In this paper we cover both\
    \ these aspects: (1) we explore \nseveral emerging data management challenges,\
    \ and (2) we propose an IoT platform integration model that can combine \ndisparate\
    \ functionalities under one roof. For the first, we focus on the following challenges:\
    \ sensor data quality, privacy in \ndata streams, machine learning model management,\
    \ and resource-aware data management. For the second, we propose an \ninformation-integration\
    \ model for IoT platforms. The model revolves around the concept of a Data-Sharing\
    \ Market where \ndata management functionalities can share and exchange information\
    \ about their data with other functionalities. In addition, \ndata-sharing markets\
    \ themselves can be combined into networks of markets where information flows\
    \ from one market to \nanother, which creates a web of information exchange about\
    \ data resources. To motivate this work we present a use-case \napplication in\
    \ smart cities.\nKeywords Internet of Things · Infrastructure Design · Information\
    \ Integration · Data Management Systems · Resource-\nAwareness · Data Quality ·\
    \ Privacy · Machine Learning Model Management\n1 Introduction\nOver the last years,\
    \ the Internet of Things has evolved from \na high-level vision of always-connected\
    \ devices to a real \ncyber-physical system class that appears in many applica-\n\
    tion domains, from healthcare Pike et al. (2019) over smart \ncities Zanella et al.\
    \ (2014) to smart farming and precision \nagriculture Kamilaris et al. (2016).\
    \ IoT has introduced radi-\ncal changes in the way data are processed. The amount\
    \ of \nIoT data, the velocity of change, and variety of sources/for-\nmats implies\
    \ new challenges to process and inter-operate \nbetween heterogeneous data sources\
    \ and formats Elsaleh \net al. (2020).\nIn addition, we are faced with another\
    \ set of challenges \non platform design level. Assuming these emerging data \n\
    management challenges are solved, how can we extend IoT \nplatforms to smoothly\
    \ integrate new data management func-\ntionalities? This is an especially pressing\
    \ problem since vari-\nous available IoT platforms are not easily extendable beyond\
    \ \nthe original use-cases assumed by their designers. We have \n * Nasr Kasrin\
    \ \n \nnasr.kasrin@uni-bamberg.de\n \nhttp://www.uni-bamberg.de/mobi\n \nAboubakr\
    \ Benabbas \n \naboubakr.benabbas@uni-bamberg.de\n \nhttp://www.uni-bamberg.de/mobi\n\
    \ \nGolnaz Elmamooz \n \ngolnaz.elmamooz@uni-bamberg.de\n \nhttp://www.uni-bamberg.de/mobi\n\
    \ \nDaniela Nicklas \n \ndaniela.nicklas@uni-bamberg.de\n \nhttp://www.uni-bamberg.de/mobi\n\
    \ \nSimon Steuer \n \nsimon.steuer@uni-bamberg.de\n \nhttp://www.uni-bamberg.de/mobi\n\
    \ \nMichael Sünkel \n \nmichael.sunkel@uni-bamberg.de\n \nhttp://www.uni-bamberg.de/mobi\n\
    1 \nChair of Mobile Systems, University of Bamberg, An der \nWeberei 5, 96047 Bamberg,\
    \ Germany\n77\nData-sharing markets for integrating IoT data processing functionalities\
    \ \n1 3\nhad firsthand experience with several IoT platforms12 and \nhave faced\
    \ various issues related to extending platforms with \ndata management functionalities.\
    \ Currently, data processing \nrelated tasks are typically realized by manually\
    \ developed \ncode and functions which are deployed smart devices (AKA \nedge\
    \ nodes), in the cloud, or on in-between on so-called fog \nnodes. This creates\
    \ future difficulties in maintenance and \ngrowth of the platforms. Hence it is\
    \ needed to explore other \napproaches to designing IoT platforms that can be\
    \ extenda-\nble to integrate emerging functionalities. Overall these chal-\nlenge\
    \ relate to devising approaches, techniques, and system \nplatforms that ease\
    \ the development and maintenance for the \ndeveloper and operator of systems.\n\
    In this paper we cover both these aspects: (1) we explore \nseveral emerging data\
    \ management challenges, and (2) we \npropose an IoT platform integration model\
    \ that can combine \ndisparate functionalities under one roof.\nWe call the IoT\
    \ integration model we develop the \nInformation Basin (IB) model. The IB model\
    \ is informa-\ntion-driven in the sense that data is shared by exchanging \ninformation\
    \ that describes the data. We model each data \nmanagement functionality/component\
    \ as an agent that \ndescribes its data and shares its descriptions with other\
    \ \nagents. The IB model revolves around the concept of a data-\nsharing market\
    \ which is a shared information space where \nmultiple agents contribute by curating\
    \ and ‘advertising’ their \ndata resources and discovering those of others. So\
    \ for the \nIoT platform use case, various IoT functionalities integrate \nby\
    \ exchanging the data descriptions of their inputs and out-\nputs within data-sharing\
    \ markets. To allow more sophisti-\ncated organizations of data exchange and integration,\
    \ the IB \nmodel has a distributed network structure, where vertices \nare data-sharing\
    \ markets and directed edges are information \nflow between them where data descriptions\
    \ travel from one \nmarket to another. This enables more complex hierarchies of\
    \ \ndata-sharing markets to form. We will discuss the IB model \nin more details\
    \ in the approach section in this paper.\nRegarding the data management challenges\
    \ we explore, \nlet us first look at the landscape of IoT data management \nchallenges.\
    \ Abbasi et al. (2017) present a set of data manage-\nment challenges In the IoT,\
    \ their list includes: standardiza-\ntion, data storage management, confidentiality\
    \ and privacy, \nintegrity, energy constraints, device mobility and heteroge-\n\
    neity, device security and backup, availability, and internal \nadversaries. From\
    \ the big data side we have the four Vs of \nvolume, velocity, variety, and veracity.\
    \ The challenge we \ndiscuss in this paper intersect with several of those topics.\
    \ \nThe topics we do not cover include: security, data volume, \nintegrity, and\
    \ standardization. Next we introduce the set of \ndata management challenge covered\
    \ in this paper. \n1. CQuality. Many IoT applications are based on sensor \ndata\
    \ which is never perfect; we have to deal with data \nquality issues which might\
    \ even change depending on \nthe context of the sensor. Hence, the need for method-\n\
    ologies that model sensor data quality for processing and \ndecision making open\
    \ the door to the challenge we call \nthe CQuality challenge.\n2. CPrivacy. IoT\
    \ devices are ubiquitous, sensors are pre-\nsent in more devices that produce\
    \ continuous streams of \ndata about their environment. This leads to the situation\
    \ \nwhere people are not aware of the information they share \nwith others, which\
    \ paves the way for the challenge of \nprivacy preserving data stream processing,\
    \ which we \nrefer to as the CPrivacy challenge.\n3. CModel. Recently there has\
    \ been work in utilizing \nmachine learning to train models that then replace\
    \ \nmanually programmed or modeled functions, e.g., for \nactivity recognition.\
    \ We consider the life-cycle manage-\nment of these models as part of a (higher-level)\
    \ data \nmanagement. We refer to this challenge as the CModel \nchallenge.\n4.\
    \ CResource. Data management is distributed geographi-\ncally between the sensor/actuators,\
    \ gateways up to the \ncloud. This distribution leads to a high heterogeneity\
    \ \nbetween the processing nodes in terms of computing \nresources, system security\
    \ and connectivity; this cre-\nates the opportunity for building solutions that\
    \ tackle the \nmanagement problem from a resource-aware approach, \nwhich we call\
    \ the CResource challenge.\nThe rest of the paper is structured as follows: in\
    \ Sect. 2 we \npresent a motivating use-case for the paper, and in Sect. 3 \n\
    we discuss our approach to IoT platform design. Next we \npresent the challenges:\
    \ in Sect. 4 the CQuality challenge, in \nSect. 5 we highlight issues related\
    \ to the CPrivacy challenge, \nand in Sect. 6 we discuss the CModel challenge.\
    \ In Sect. 7 \nwe cover the CResource challenge, in Sect. 8 we discuss \nrelated\
    \ work, and wrap up in Sect. 9 with conclusions and \nfuture work.\n2  Use case\n\
    The establishment of smart cities can be supported by the \nInternet of Things\
    \ (IoT) platforms with sensors collecting \ndata and improve the life quality\
    \ and resource efficiency in \nfuture cities. Many smart city applications use\
    \ their gathered \ndata to measure city-wide processes like mobility, energy,\
    \ \nor environmental factors like air quality. Various challenges \narise in managing\
    \ this huge amount of data consistently.\n1 ThingsBoard, https ://thing sboar\
    \ d.io/.\n2 Cumulocity, https ://www.softw areag .cloud /site/produ ct/cumul ocity\
    \ \n-iot.html.\n78\n \nN. Kasrin et al.\n1 3\nTo define the challenges, explain\
    \ and provide appropri-\nate solutions first, we describe our use-case, a smart\
    \ city \nplatform, the so-called Living Lab Bamberg. This testbed \nprovides a\
    \ user-centric environment to test and use different \nsensing systems. The Living\
    \ Lab is open for industry part-\nners and citizens who help us receive new sensor\
    \ systems \nand find installations locations. Furthermore, the University \nof\
    \ Bamberg is not a campus university with the advantage \nthat we can place lots\
    \ of sensors in different buildings inside \nthe city.\nIn general, we use different\
    \ kinds of stationary and mobile \nsensors systems. An example of a stationary\
    \ sensor is a peo-\nple-counting camera, and an example for a mobile sensor \n\
    is a sensor box in a city bus to measure air quality. These \nsensing systems\
    \ produce data that we use in our different \napplication scenarios. We describe\
    \ some of these application \nscenarios below.\nOne application scenario is indoor\
    \ and outdoor locali-\nzation management. Every year many people visit a lot of\
    \ \nstreet festivals in the world’s cultural heritage, Bamberg. \nBamberg is a\
    \ medieval city with many narrow alleys and \nsmall lanes that make it difficult\
    \ to plan events with a lot of \nvisitors. The goal was to flow-track the movement\
    \ of visi-\ntors in the area of the festival, as well as learn movement \nmodels\
    \ of the civilians and groups of people. This can help \non a short term basis\
    \ to predict escape routes on the fly, or \nin retrospect to plan for future planning\
    \ of street festivals.\nFor the measurement, we used a combination of different\
    \ \nsensing technologies like manual counting, camera-based \ncounting, and Wi-Fi\
    \ tracking of mobile phones. In addition, \nthe people tracking camera system\
    \ helps us to collect trajec-\ntories from people inside buildings (an example\
    \ of indoor \nlocalization would be an iBeacon network). In this environ-\nment,\
    \ we can simulate tourist information panels inside the \nuniversity or guides\
    \ for city museums.\nAlready in such a scenario we have several data manage-\n\
    ment challenges arising. We also highlight the information-\ndrivne aspect of\
    \ each challenge since this is the key property \nwe use in the proposed information\
    \ integration model, the \nInformation Basin (IB) model. \n1. Festival Sensor\
    \ Data Quality. The above sensors, like \nmost other sensors, produce readings\
    \ that are never per-\nfect. However for it should be possible to build quality\
    \ \nmodels for data–using sensor models and environmental \ncontext–to enrich\
    \ them with quality information. This \ncan greatly help in correcting some kinds\
    \ of faultiness \nor at least in describing the nature of the faultiness of \n\
    the sensor data. Such quality information can be invalu-\nable for developing\
    \ machine learning models for exam-\nple (see below). The CQuality challenge we\
    \ present in \nthis paper forms an instance of studying this problem. \nIt must\
    \ be noted that in the above approach sensor qual-\nity models, as well as quality\
    \ information attached to \ndata sets (ex. metadata) are both structured information,\
    \ \nwhich can be represented, exchanged and processed by \nothers in the IB network.\n\
    2. Visitors’ Privacy. As data is collected about festival \nattendees, vulnerability\
    \ of the visitors’ privacy is the \nWi-Fi tracking of mobile phones arises. How\
    \ can we \ncollect data from the festival attendees while protect-\ning their\
    \ identities? The CPrivacy covers this aspect of \nthe problem. Although not as\
    \ information-driven as the \nsensor data quality challenge, information representing\
    \ \nwhich parts of the data are privacy sensitive, or what \nalgorithms and parameters\
    \ to run on them, are structured \ninformation that drives privacy data processing.\n\
    3. Festival Attendees Movement Models. Developing \nmovement models helps to predict,\
    \ mange emergen-\ncies and support the planning of future festivals. Sensor \n\
    data and its quality information can be used to develop \nthese models which in\
    \ part are also structured informa-\ntion that can be processed by different systems.\
    \ This \nforms the CModel investigation in this paper. Examples \nof strucutre\
    \ information driving this data management \nfunctionality include, training datasets\
    \ used, learning \nparameters, and the learned models themselves are all \nstructured\
    \ information that are key to driving machine \nlearning model management.\n4.\
    \ Resource-aware Computation of Festival Data. So far \nwe have assumed that computation\
    \ is managed locally or \nby some high-performance machine. But the IoT reality\
    \ \nhas given us many options to run computations. For pri-\nvacy, it can greatly\
    \ benefit if data is for example pseudo \nanatomized on the fog node, or the nearest\
    \ gateway, if it \nhas such computational capabilities. Also for developing \n\
    machine learning models, resource-aware computation \ncan provide various alternatives\
    \ to pre-process, clean-\nup, or run jobs across nodes. This challenges, as opposed\
    \ \nto the three above, is a service challenge that supports \nother data management\
    \ functionalities.\n5. Integration. Various data management functionalities \n\
    arise in this use-cases, and IoT platforms suffer from \na lack of fluidity when\
    \ new features or functions are \nadded to the platform. So with discussing all\
    \ the above \nchallenges, a natural question arises, how can we inte-\ngrate such\
    \ functionalities together? Towards this end \nwe present an information-driven\
    \ paradigm for IoT \nplatform design. We model the data management func-\ntionalities\
    \ referenced above as agents, which processes \ndata and consumes and produces\
    \ information about this \ndata. Then integrating the different functionalities\
    \ into \na common framework by sharing and exchanging all this \ninformation.\
    \ We present this model in the next section.\n79\nData-sharing markets for integrating\
    \ IoT data processing functionalities \n1 3\nMobility sensing is just one use\
    \ case for smart cities. With \nsuch a small use-case, we already see various\
    \ motivating \nrequirement for the challenges and approach presented in \nthis\
    \ paper. Similar challenges can be found in other applica-\ntions as well in such\
    \ as environmental sensing, using distrib-\nuted air quality measurements and\
    \ analysis.\n3  Platform integration: the information \nbasin model\nWe have introduced\
    \ several IoT platform functionalities so \nfar. From a platform design perspective\
    \ we model each func-\ntionality as a functional dimension of the IoT platform,\
    \ as \ndefined below.\nDefinition 1 (Functional Dimension) A functional dimen-\n\
    sion is a component of an IoT platform that: (1) adds inde-\npendent functionality\
    \ or value of its own (i.e. processing, \ninput to output dynamics), and (2) is\
    \ expected to integrate \nwith the platform (ex. by producing or consuming data/\n\
    information).\nSensor data quality management (CQuality) is an exam-\nple of functional\
    \ dimension of an IoT platform since it adds \nan independent functionality (processing\
    \ sensor data and \nsensor information and producing data quality models, etc.)\
    \ \nand it must integrate into a larger platform so that its results \ncan be\
    \ used by other systems. Machine learning model man-\nagement (CModel) shares\
    \ a similar structure to CQuality as \na functional dimension, and so on.\nDistributed\
    \ resource-aware computing (CResource) can \nalso be understood as a functional\
    \ dimension in the sense \nthat it adds functionality and produces results/data\
    \ back to \nthe platform. A similar argument can be made about CPri-\nvacy in\
    \ the sense of adding functionality and integrating into \nthe larger system.\n\
    Faced with expanding requirements, innovations, and \nfunctionalities of IoT platforms,\
    \ we must find ways to design \nplatforms so that they can handle multiple functional\
    \ dimen-\nsions as well as be extendable to integrate new ones. To \nachieve this\
    \ we use a model we are developing3 called the \nInformation Basin (IB) model,\
    \ which revolves around the \nconcept of a data-sharing market.\nDefinition 2\
    \ (Data-Sharing Market) A data-sharing market \nis a shared information space\
    \ where multiple organizations \ncan describe and ‘advertise’ their data resources\
    \ as well as \ndiscover those of others.\nOnline open-data repositories are one\
    \ example of a \ndata-sharing market, however their underlying model for \ninformation\
    \ representation (i.e. list + keywords) might be \nprimitive for more sophisticated\
    \ applications. The informa-\ntion representation model we currently use is more\
    \ akin to a \nlightweight semantic graph model driven by shared domain \nmodels.\n\
    Definition 3 (The Information Basin (IB) Model) The IB \nmodel is a platform design\
    \ model for enabling data-sharing \nand exchange networks across multiple groups,\
    \ users, or sys-\ntems. The basic building block of the IB model is (1) a set\
    \ \nof data-sharing markets and (2) information flow between \nthem. The IB model\
    \ is ‘information-driven’ in the sense \nthat data is shared by exchanging information\
    \ about data. \nAn IB network is ‘animated’ when (1) information about \nnew data\
    \ resources is added to a market, or (2) information \nflows from one market to\
    \ another, thereby creating a kind \nof living web-of-markets. Since we are dealing\
    \ with (struc-\ntured) information here, if we assume that markets can have \n\
    different domain models, information flow must include a \nmapping stage from\
    \ the source domain model to the destina-\ntion model.\nContinuing with the online\
    \ open-data repository exam-\nple, implementing an IB network using them will\
    \ require \nestablishing a mechanism whereas some selection of entries \nfrom\
    \ one repository can be propagated to other repositories, \nwhere each repository\
    \ might have a different set of users, \nvisibility etc.\nSo how can we apply\
    \ the IB model to establish an expand-\nable IoT platform with multiple functional\
    \ dimensions? \nWe can design a simple IB network where each functional \ndimension\
    \ has its own internal data-sharing market, and in \naddition declare an IoT platform-wide\
    \ market where infor-\nmation flows from the respective feature dimension markets\
    \ \nto the main one.\nA primitive IB network would be a single IoT platform-\n\
    wide market shared by all functional dimensions, and \nalthough this can work,\
    \ this assumes that all the dimensions \nmust adhere to the same domain model\
    \ of information, as \nwell as being forced to share all produced data to this\
    \ mar-\nket. Usually functional dimensions would have some local/\nprivate data\
    \ that is not meant to be shared, in addition to \nhaving domain models that are\
    \ specialized differently. So for \nthese reasons we will opt for a multi-market\
    \ IB network. Fig-\nure 1 depicts this IB network, where IoT-Mark is the name\
    \ \nof the IoT-wide shared market. Regarding the contributors \nin the different\
    \ markets, we can assume that each functional \ndimension market is accessible\
    \ only by users/systems of that \nfunctional dimension and the IoT-Mark market\
    \ is accessible \nand writable by all the users/systems of all the functional\
    \ \ndimension.\n3 Submitted, awaiting review.\n80\n \nN. Kasrin et al.\n1 3\n\
    Next we will looking at the example of how the above \nIB network can support\
    \ an IoT platform with the multiple \nfunctional dimensions covered in this paper.\
    \ First regarding \ndomain models across markets, we can give the IoT-Mark \n\
    market an abstract domain model that is specialized by each \nmarket differently.\
    \ By specialized we mean the abstract \nmodel is extended by adding new types\
    \ that must be a sub-\ntype of some element in the abstract model. Figure 2 depicts\
    \ \none such model, where the ‘p:’ prefix denotes that the type \ncomes from the\
    \ PROV W3C provenance recommendation4.\nThe CQuality market can further specialize\
    \ the above \nmodel by defining a rich sub-hierarchy of sensors and sen-\nsor\
    \ quality models, the CModel market on the other hand \ncan define a rich sub-hierarchy\
    \ of type DataSet above, and so \non. Let us look at a concrete example of how\
    \ the functional \ndimensions can integrated within the IoT platform.\nExample\
    \ 1 The CQuality solution processes a DataSet and \nits context and produces a\
    \ reliability model. Let’s assume \nthis reliability model is defined in the abstract\
    \ domain model \non the DataSet type, hence it is understood by the other \ngroups.\
    \ The CQuality market would have a forwarding rule \nto the IoT-Mark market for\
    \ all new reliability information, \nand hence this piece of information about\
    \ this particular \nDataSet instance will be propagated. In the IoT-Mark market\
    \ \nthe CModel group can query for all DataSets with reliability \ninformation\
    \ and use that information as parameters to their \nlearning algorithms and produce\
    \ a learning model where \nthey declare that the DataSet above has been used as\
    \ train-\ning data. Let’s say that hypothetically, a problem occurs with \nthe\
    \ learning model and someone would like to diagnose the \npossible reasons, with\
    \ the information about which DataSets \nwhere used in the training they can trace\
    \ this same DataSet \nback to the CQuality group and can explore more informa-\n\
    tion about how the reliability information was derived, and \nso on.\nIn essence,\
    \ a functional dimension = (structured) infor-\nmation + operations (that use\
    \ and produce more informa-\ntion). And an IB network = information models / mappings\
    \ \n+ markets + information flow.\nWe will not go into more details regarding\
    \ the approach \ndue to scope. The goal of this section was to show an IoT \n\
    platform model where a set of IoT functionalities can be \ncombined under a common\
    \ roof collaborate and exchange \ninformation and data to achieve the goals of\
    \ an IoT platform. \nThe remainder of this paper will dive into the various chal-\n\
    lenges introduced earlier.\nFig. 1  The IoT platform IB \nnetwork with clouds\
    \ denoting \nmarkets and arrows denoting \ninformation flow\nFig. 2  Abstract\
    \ shared model, with arrows denoting the type-of relation\n4 https ://www.w3.org/TR/prov-overv\
    \ iew/.\n81\nData-sharing markets for integrating IoT data processing functionalities\
    \ \n1 3\n4  CQuality: data quality challenges in IoT \nenvironments\nThis challenge\
    \ revolves around the quality of data in the \ncontext of IoT. Most applications\
    \ deal with data coming \nfrom different sources. These sources can be human or\
    \ \nnon-human. Non-human data can come from other similar \ndevices or from sensors\
    \ that capture the phenomena happen-\ning around and quantifying them.\nTo show\
    \ the importance of data quality, we can relate \nto the use cases in Sect. 2,\
    \ where machine learning models \nare created on the basis of sensors. If these\
    \ datasets are not \nchecked for quality, the models created could give a skewed\
    \ \nview on the actual observation/behavior. Any predictions \nbased on the learned\
    \ models from raw data will result in \nwrong predictions. In this section, we\
    \ focus on the main \nchallenges of data quality in IoT environments with regards\
    \ \nto the stream processing applications. Since most of the \ndata in IoT context\
    \ is generated from sensors, we know \nhow faulty can the data be. Besides, we\
    \ note that decision-\nmaking is made on the fly. Those two aspects make the data\
    \ \nquality an important issue in the process of data evaluation \nand usage.\
    \ First, we start by enumerating the different chal-\nlenges that face the developers\
    \ of IoT applications and then \nwe describe them individually in this section.\n\
    When we talk about data quality, we have to precisely \ndefine what quality means.\
    \ This definitions can be defined \nby introducing the dimensions that make up\
    \ the data quality. \nThis challenge is concerned with the definition of data\
    \ qual-\nity. After having a clear idea of the quality dimensions and \ntheir\
    \ metrics, we have to determine the values of those met-\nrics. This poses the\
    \ second challenge of data quality compu-\ntation. We also want to make the use\
    \ of quality-aware data \nprocessing as easy as possible by having an easy integration\
    \ \nfor application developers.\nTo summarize, this challenge focuses on the following\
    \ \nresearch question: How can we integrate quality-aware data \nprocessing in\
    \ IoT applications through semi-automatic and \nautomatic methods?\n4.1  Related\
    \ work\nIn this part, we give a background on the relevant research \nthat addresses\
    \ the different aspects of data quality in IoT \nenvironments.\n4.1.1  Data quality\
    \ definition\nThe first challenge is to clearly define what data quality is. \n\
    According to Buchholz and Schiffers (2003), quality is “Any \ninformation that\
    \ describes the quality of information that is \nused as context information”.\
    \ Batini et al. define the data \nquality in terms of specific dimensions Batini\
    \ et al. (2006) \nlike accuracy, completeness, volatility and timeliness. Klein\
    \ \nand Lehner (2009) define data quality as the accuracy and \nresolution of\
    \ the data as it goes though the steps of a data \nprocessing chain. With these\
    \ definitions of data quality, we \nhave to distinguish between inherent quality\
    \ dimensions and \ndomain-specific dimensions.\nThe inherent quality dimensions\
    \ can be automatically \ncomputed like those given by Batini. However, the domain-\n\
    specific dimensions must be defined by the application \ndevelopers. This makes\
    \ the task of data quality definition \nusing a specific tool a little bit tricky.\n\
    In order to deal with data quality representation, we can \nuse semantic tools\
    \ like ontologies to define both types of \nquality dimensions. The inherent quality\
    \ dimensions can \nhave their own terms in an ontology like the SSN ontology \n\
    Compton et al. (2012). The domain-specific dimensions can \nbe expressed through\
    \ extensions of ontologies or by enabling \nthe inclusion of user-defined terms\
    \ to include these. How-\never, the definition of any data quality dimension or\
    \ process \nmust be simple and clear to encourage any users to adopt it.\n4.1.2\
    \  Data quality processing\nThe challenges in the area of data processing are\
    \ numer-\nous. Should the quality dimensions be computed online or \noffline?\
    \ Do we output data with quality annotations or meta-\ndata about the quality?\n\
    The online approaches are mostly present in applica-\ntions that process the data\
    \ on the fly as an incoming stream. \nGeisler et al. (2016) introduces a Data\
    \ Quality ontology-\nbased framework for data stream applications. The ontology\
    \ \ngives quality metrics for content, queries and applications. \nThe framework\
    \ is based on an ontology for the description \nof sensor and quality dimensions.\
    \ Kuka and Nicklas (2014) \ngive an approach for quality-aware sensor data processing\
    \ \nbased on the SSN ontology Compton et al. (2012). The \nontology is used to\
    \ describe context information about the \nsensors deployed. The Gaussian Mixture\
    \ Models are used \nto assess the probability of a data element being an outlier.\n\
    Schmidt et al. (2004) adopt a deterministic data stream \nprocessing approach\
    \ with a system called QStream. Klein \nand Lehner (2009) propose a flexible model\
    \ of data quality \nprocessing and propagation in a stream processing network\
    \ \nfor sensor data in a smart environment. We also applied \nonline data stream\
    \ processing for quality estimation of sen-\nsor data in Benabbas et al. (2018,\
    \ 2019, 2020); Aboubakr \net al. (2017a).\nThe mentioned approaches process the\
    \ data on the fly and \ncan be also applied offline. These approaches include\
    \ pro-\ncesses for the computation of the said quality dimensions. \nThe user-defined\
    \ quality dimensions come with user-defined \n82\n \nN. Kasrin et al.\n1 3\nprocedures\
    \ to determine the values of the quality dimen-\nsions. Besides, we need to consider\
    \ the trade-off between \nthe accuracy of the computed quality and the costs in\
    \ terms \nof computation overhead and delay. Some of the approaches \nneed a training-set\
    \ to develop a model for their quality-aware \nprocessing Wu et al. (2007), while\
    \ some do not need any \ntraining to start their process. These two variants give\
    \ the \nuser a choice between a delay-free quality-aware process-\ning and one\
    \ with an up-start time. The challenge is to find a \nhybrid approach that enables\
    \ the choice between the differ-\nent models and the activation/deactivation of\
    \ quality com-\nputation processes.\n4.1.3  Data quality integration\nThis challenge\
    \ builds on the first two challenges. Given that \nall the challenges above are\
    \ solved, how do we make the \nintegration of quality aware processing as easy\
    \ and as seam-\nless as possible? From the above discussion, we note that \nmost\
    \ systems deal with data quality as a parallel process or \na pre-processing step\
    \ before passing the data to the actual \napplication. This challenge implies\
    \ that for any quality-\naware solution to be adopted, it must be simple enough\
    \ and \nintuitive enough to be wide-spread over all the IoT applica-\ntions. This\
    \ gives rise to the following two challenges:\n• Simplify the use of semantic\
    \ models to describe the \nquality-aware processes.\n• Automatically generate\
    \ the processes from the semantic \ndescriptions.\n4.2  Our approach\nThe first\
    \ challenge must be addressed through the introduc-\ntion of processing patterns,\
    \ which can be deduced from the \nbasic structures of the participating data sources\
    \ in the IoT \napplications. The second challenge can be solved by having \nprocesses\
    \ in the background to perform the translation from \nthe semantic model to the\
    \ actual quality-aware processes. \nA first step towards these goals is done in\
    \ a previous con-\ntribution Benabbas et al. (2020), where we define the first\
    \ \nprocessing patterns and their use with an automatic genera-\ntion of the quality-aware\
    \ processes. The target is to be able \nto provide templates of sensor models\
    \ to be used by the IoT \napplication developers to deal with the quality issues\
    \ wher-\never applicable. Besides, we want to leverage large scale \nmodels that\
    \ contain multiple sensors to find the target groups \nfor data quality checks.\n\
    Figure 3 shows the cycle of data quality integration into \nIoT platforms. Developers\
    \ design their applications by hav-\ning models of the data sources and sensors\
    \ they have. To \nwrite the models, we can use the aforementioned SSN ontol-\n\
    ogy. The models are fed to the Data Quality Management \nTool that extracts the\
    \ data quality processing patterns from \nthe model. The patterns can be identified\
    \ through the seman-\ntic relationships between the sensors and other spatially\
    \ col-\nlocated sensors or with other data sources. The automatic \nrecognition\
    \ of such quality patterns and the generation of \nthe queries should solve the\
    \ second challenge. The process-\ning patterns indicate the method of checking\
    \ the data qual-\nity. Then, the process of quality-aware processing queries \n\
    generation.\nThe output of the process are quality-aware queries, \nwhich can\
    \ be deployed on data stream management sys-\ntems (DSMS) to perform the data\
    \ quality metrics compu-\ntation. The results of those queries are quality-annotated\
    \ \ndata, which are ready to be used by the IoT applications. \nAny changes in\
    \ the application model can be updated in the \nmodel and this triggers a chain\
    \ of updates on the queries to \nreflect the change in the model.\nThe third challenge\
    \ of Data Quality Integration is the \nlong term goal for IoT applications, where\
    \ the above steps \nof model creation and query generation should be standard-\n\
    ized and made as a part of any IoT development platform. \nThe developers should\
    \ have all the necessary tools to make \nquality-aware processing a permanent\
    \ part of the develop-\nment of applications.\n5  CPrivacy: privacy‑preserving\
    \ data stream \nprocessing\nIoT devices are ubiquitous. Sensors are present in\
    \ more and \nmore devices not just in smart phones or wearables. This \nleads\
    \ to the problem that the people are not aware what \ninformation about their\
    \ daily lives they share with others. \nAn example like a fitness tracking app\
    \ that gives away loca-\ntion of secret US army bases Hern (2020) seems funny,\
    \ but \nthere are too many privacy fails that this problem could be \nignored.\n\
    Fig. 3  Cycle of data quality integration in IoT applications\n83\nData-sharing\
    \ markets for integrating IoT data processing functionalities \n1 3\nRecently\
    \ laws are being published to ensure the security \nand privacy features of IoT\
    \ devices. For example, the federal \nstate of California has prohibited the use\
    \ of standard pass-\nwords (2020). This is a good first step to define standards\
    \ \nfor private IoT devices.\nThe problem is that nowadays you can be monitored\
    \ by \nsensors without knowing that. Especially if companies like \nsupermarkets\
    \ use systems to track customer to analyze their \nshops. In 2018 the European\
    \ GDPR was launched and pro-\nvided a good foundation for privacy. Since that\
    \ time super-\nmarkets were not allowed anymore to store private informa-\ntion\
    \ like the mac addresses of the customer’s mobile devices \nin plain text.\nWe\
    \ want to analyze stream of stakeholders of a street \nfestival to create new\
    \ security and safety concepts. How \ncan we set up long-running city-wide sensor\
    \ campaigns and \nshare the data without compromising the citizen’s privacy? \n\
    We integrate different state-of-the art privacy methods to \nreduce the risk of\
    \ leaks in data publication to a minimum. In \na next step we adopt our prototype\
    \ to data streams. We will \nrefer this challenge as the privacy-preserving data\
    \ stream \nprocessing challenge.\nTo summarize, this challenge focuses on the\
    \ following \nresearch question: How can we process privacy-preserving \ndata\
    \ streams without publishing sensitive information’s?\n5.1  Related work\nWe already\
    \ defined our privacy-preserving architecture for \nour smart city testbed in\
    \ Steuer et al. (2016). One of the \nmain challenges is the publication anonymous\
    \ data. Privacy-\nPreserving Data Publishing (PPDP) is a good fundamen-\ntal for\
    \ our research in this domain. Fung et al. treated also \nmoving object data in\
    \ their survey Fung et al. (2010) as \nprivacy in location-based services (LBS).\
    \ “Location privacy \nis defined as the ability to prevent untrusted third parties\
    \ to \nreveal current or past location[s] of an individual” Pelekis \nand Theodoridis\
    \ (2014). There are two general approaches \nto prevent re-identification in trajectories:\
    \ spatial cloaking \nand perturbation Pelekis and Theodoridis (2014).\nIn the\
    \ cloaking approach the generalization increases the \nquery region until the\
    \ region contains at least k users. The \nprobability of de-identification is\
    \ not higher then 1/k. Exam-\nples for cloaking are based on k-anonymity like\
    \ Always-\nWalk-with-Others. The cloaking approach is just possible \nif we have\
    \ a high number of trajectories, if we do not have \nthis then we need perturbation\
    \ like in the Never-Walk-Alone \napproach or decide not to publish data sets Pelekis\
    \ and Theo-\ndoridis (2014).\nIn data publication we focus on k-anonymity because\
    \ we \nhave just slightly sensitive data that can be anonymized eas-\nily without\
    \ much risk. Our goal is to use k-anonymity also \nfor data streams. There have\
    \ been several scientific articles \nover the years, which try to extend the concept\
    \ of k-anonym-\nity to streaming data. The Continuously Anonymizing Data \nStreams\
    \ algorithm (Castle), presented in Cao et al. (2011), \nhas the most similarities\
    \ to our approach.\nExisting privacy-preserving techniques such as k-ano-\nnymity\
    \ are designed for static data sets. The adaption to data \nstreams is challenging\
    \ because of the differences to classical \ndata bases. In data streams the data\
    \ input is continues and \ndoes not stop. Furthermore the data arrives in real\
    \ time in \nan ordered sequence of items Golab and Özsu (2003). In our \nuse case\
    \ in Sect. 2 entities can appear more than one time if \na visitor enters a new\
    \ region and then immediately returns.\n5.2  Our approach\nIn our approach, we\
    \ decided to use generalization with \nk-anonymity. In the first step, we analyze\
    \ our stored data set \nfrom the crowd monitoring use case in Sect. 2. The identi-\n\
    fiers in our data set are the mac address and a combination \nof time stamps and\
    \ location points, which makes it possible \nto encrypt stakeholders.\nMac address\
    \ is the sensitive attribute that we protect via \npseudonymisation with hashing.\
    \ Regarding the quasi iden-\ntifier time stamp and location, we conclude that\
    \ we need a \nlocation point (e.g. City Hall) and a time stamp categoriza-\ntion\
    \ (morning, afternoon, evening and overnight) as clusters. \nThe trajectories\
    \ just consist of these cluster set of elements. \nA typical trajectory looks\
    \ like:\nCity Hall[morning] - Lower Bridge[morning] - Upper \nBridge[morning]\n\
    Our goal is to see, how k-anonymity can be applied to \ndata streams with the\
    \ data set from our crowd monitoring \nuse case presented in Sect. 2. Towards\
    \ enable privacy-pre-\nserving data stream processing, we want to extend our data\
    \ \nstream management system (DSMS) Odysseus Appelrath \net al. (2012). Therefore,\
    \ we want to implement a standard \noperator, so that adding anonymization to\
    \ data streams \nbecomes easy for developers and can be enforced easily.\nHence,\
    \ very similar to the static data set, the identifying \ninformation of stakeholders\
    \ the mac address is removed. \nAfter that, we focus on the following questions:\
    \ (1) How \nmany tuples are stored temporarily before they get published \nas\
    \ clusters? (2) What should be a good window size, so that \nwe can guarantee\
    \ the privacy in the diversity of trajectories \nand that we do not lose too much\
    \ data sets? After answering \nthe questions (1) and (2), we can use a predicate\
    \ window \nwith a predefined size so that tuples have to fulfill the predi-\n\
    cate cluster_size ≥ k to get published.\nThe anonymization operator is optimized\
    \ for one data set \nin one specific use case. In order to make it useful for\
    \ devel-\nopers, more crowd sensing use cases have to be supported. \nFor this\
    \ end, we want to define a set of the most probably \nscenarios and define the\
    \ concrete parameters for them.\n84\n \nN. Kasrin et al.\n1 3\n6  CModel: ML model\
    \ management\nIoT platforms are made of a huge number of different sen-\nsory\
    \ devices that produce a huge volume of data. There are \ndifferent applications\
    \ of IoT in different environments, like \nthe smart city described in Sect. 2.\
    \ Many different services \ncan be defined in such environments as smart mobility\
    \ \nmonitoring, smart traffic management, and smart build-\nings. These different\
    \ services should provide appropriate \nknowledge and insight into the environment\
    \ and support \ndomain experts in making critical decisions.\nFor example, in\
    \ the smart city scenario, all the people \ncan use a traffic management service,\
    \ which suggests the \nshortest path to the destination based on different possible\
    \ \npaths’ traffic load.\nThe word machine learning refers to a computer pro-\n\
    gram that is said to optimize a learning criterion using \nexample data and post\
    \ experiences Alpaydin (2020). \nMachine learning (ML) and data analytics techniques\
    \ are \npowerful tools that provide us the ability to extract knowl-\nedge from\
    \ transmitted data. Based on the requirements, \ndifferent ML and data analytics\
    \ techniques should be \napplied to provide a service in an IoT platform Samie\
    \ et al. \n(2019); Cui et al. (2018). To design the best ML model \nframework\
    \ that manages all the ML models in our IoT \nplatforms, first, we have to define\
    \ the challenges related to \nML model management. This section reviews the related\
    \ \nworks for ML model development and management in an \nIoT platform, and then\
    \ we define and discuss the chal-\nlenges related to ML model management. In the\
    \ end, we \ndescribe our approach and explain how we can overcome \nthe challenges\
    \ and answer the research question.\nThe research question for ML model management\
    \ \nwould be: how we can integrate and manage a variety of \nML models with different\
    \ properties in an IoT platform in \na unified and scalable framework?\n6.1  Related\
    \ work\nA variety of ML and data analytics techniques have been \nintroduced to\
    \ deal with a massive amount of heterogene-\nous data gathered by the IoT infrastructure\
    \ Samie et al. \n(2019); Cui et al. (2018). Different ML models can extract \n\
    different patterns and knowledge needed by applications. \nBased on the application\
    \ demands, the appropriate ML \nmodel with the proper properties can be defined.\n\
    Data should go through stages of ML pipeline and \nsometimes combined with context\
    \ knowledge to gain \nthe appropriate knowledge. ML pipeline consists of dif-\n\
    ferent ML techniques for data cleaning, preprocessing, \ndata segmentation, feature\
    \ selection, processing, and \npostprocessing. So many related works focused on\
    \ devel-\noping different ML models and combining the ML models \nfrom different\
    \ stages of pipeline to extract the accurate \nresults Chin et al. (2017); Patil\
    \ and Thorat (2016); Mah-\ndavinejad et al. (2018). Some mature works like Vla-\n\
    cheas et al. (2013) introduced an ML model management \nframework with some level\
    \ of automation for selecting \nthe ML models. Besides, combining the context\
    \ knowl-\nedge like what has been done in Sasidharan and Somov \n(2014) improved\
    \ the accuracy of ML models. However, \nall the mentioned works are developed\
    \ for some limited \napplications.\nIn addition, each ML model has its evolution\
    \ life-cycle. \nThis means that every time an ML model is developed, it \nmust\
    \ be evaluated and deployed Schelter et al. (2018). The \nlife-cycle of an ML\
    \ model produces different versions of an \nML with other properties.\nThe rapid\
    \ speed of growing IoT platforms and matura-\ntion of ML techniques address the\
    \ need to have a unified \nframework for managing the ML models and correspond-\n\
    ing metadata and connections for each model to overcome \nthe aforementioned challenges.\
    \ The ML model manage-\nment should allow us to integrate new ML models to the\
    \ \nframework, elevate existing models, track and access differ-\nent ML models\
    \ with corresponding metadata, and decide \nwhich model should be used to extract\
    \ the desirable knowl-\nedge. Such an ML management framework should be able \n\
    to overcome the challenges of managing ML models that \ncan be divided into three\
    \ main categories. In the following, \nwe explain each challenge, describe the\
    \ related works, and \ndiscuss the shortcomings and new insights.\n6.1.1  ML models\
    \ for different applications\nIoT platforms can cover a vast area like a city\
    \ Steuer et al. \n(2016), a building Elmamooz et al. (2017), or a farm Kami-\n\
    laris et al. (2016). Different users and agents with different \ndemands can be\
    \ defined in an IoT covered environment. For \nexample, taxi drivers, tourists,\
    \ and citizens of a city can ben-\nefit from smart mobility monitoring service\
    \ with different \napplications Zanella et al. (2014). A taxi driver needs the\
    \ \nfastest path to the destination, a tourist needs a recommen-\ndation for the\
    \ next interesting place in the city, and a user \ncan use a traffic load app\
    \ to decide on the hours for shop-\nping. So many different ML techniques have\
    \ been introduced \nto extract relevant knowledge for an application. The ML \n\
    techniques can be categorized into three main categories of \nsupervised learning,\
    \ unsupervised learning, and reinforce-\nment learning Kavakiotis et al. (2017).\
    \ Different techniques \nare introduced to extract hidden knowledge from data.\
    \ This \nknowledge can be in the form of classified data, frequent \npatterns,\
    \ sequential patterns, and so forth. This knowledge \nshould be presented in an\
    \ understandable way for the end \n85\nData-sharing markets for integrating IoT\
    \ data processing functionalities \n1 3\nuser. Moreover, based on the application\
    \ demands, different \nML models should be executed offline or online over differ-\n\
    ent data segments Zorbas et al. (2015). In some cases, it is \nneeded to execute\
    \ an ML model over various window sizes \nto extract the hidden patterns and anomalies\
    \ in different time \nand space granularities.\nMost of the recent works focus\
    \ on developing the algo-\nrithms that fit best to the specific demand like Mahdavine-\n\
    jad et al. (2018); Kavakiotis et al. (2017); Sasidharan and \nSomov (2014). However,\
    \ managing ML models should not \njust focus on developing the most efficient\
    \ models but also \non model management efficiently. This means that an ML \n\
    model management framework should be developed in a \nscalable way to make the\
    \ integration of new models easier. \nIn addition, different components of a framework\
    \ can be (re)\nused for other domains and applications.\n6.1.2  Pipeline of ML\
    \ models\nThe data transmitted from sensory devices in big IoT plat-\nforms are\
    \ completely heterogeneous and full of noise and \nmissing values, as mentioned\
    \ in Sect. 4. Moreover, each \nbunch of raw data gathered from a specific kind\
    \ of sensor \nhas its own characteristics like the type of data and num-\nber\
    \ of fields. Gathered data from heterogeneous sensors \nin different places and\
    \ time should be processed to return \nthe desired result. The process of converting\
    \ raw data into \nknowledge consists of different steps called ML pipeline \n\
    Schelter et al. (2018). These stages are data cleaning, data \npreprocessing,\
    \ data segmentation, feature selection, process-\ning, and postprocessing.\nEach\
    \ step in the pipeline includes one or more ML model \nthat receives an input\
    \ dataset and converts it to the output \ndataset. In the cleaning and preprocessing\
    \ step, some ML \nmodels should be used to leverage the quality of data for \n\
    further usage like noise reduction, data segmentation, and \nresampling. In data\
    \ segmentation and feature extraction, the \ndata is divided into batches based\
    \ on time and space, and \ndifferent features of a batch can be selected based\
    \ on their \neffects on the evaluation of the model. In the processing step, \n\
    based on the application, different supervised, unsupervised, \nor reinforcement\
    \ ML models can be chosen to extract the \nknowledge out of data. As the last\
    \ step, in some cases, the \nresult of the second step of the pipeline should\
    \ be further \nprocessed to produce understandable knowledge.\nIt should be mentioned\
    \ that combinations of different ML \nmodels can change the evaluation results.\
    \ For example, some \npreprocessing techniques like discretization can enhance\
    \ the \naccuracy of some ML models that cannot work with con-\ntinuous values\
    \ Zhu and Collette (2015). Therefore, the ML \nmodel management framework should\
    \ be able to keep and \nretrieve different ML models in different stages of the\
    \ pipe-\nline based on the connections between the models. Such a \nframework\
    \ should help choose a suitable (combination of) \nML model(s) to get the desirable\
    \ results.\n6.1.3  The life‑cycle of ML model evolution\nDeveloping an ML model\
    \ is a continuous task. This means \nthat every time an ML model is developed,\
    \ the model should \nbe validated with the data and be improved based on the \n\
    validation results. Figure 4 illustrates the life-cycle of ML \nmodels.\nThe life-cycle\
    \ of an ML model consists of three stages, \nincluding model development, model\
    \ evaluation, and model \ndeployment Schelter et al. (2018). After defining the\
    \ train-\ning data, selecting the features, and training the model with \nthe\
    \ training dataset, the model should be evaluated with test \ndatasets. In most\
    \ cases, an ML model is a combination of \nfeature transformation and a learning\
    \ algorithm with tuned \nparameters. An ML model is implemented and integrated\
    \ to \naccept domain specific input data and return reliable results. \nTherefore,\
    \ the selection of features and tuning the param-\neters can be made based on\
    \ the distribution of data. The \nperformance and accuracy of an ML model can\
    \ change over \ntime and space with changes in the data distribution. To keep\
    \ \nthe results of ML models reliable, ML models should be \nvalidated and improved\
    \ over time.\nThe continuous life-cycle of ML models raises the \ndemand to keep\
    \ the trace and information about different \nML over time and space. Introduced\
    \ ML model management \nframeworks mostly keep the current version of ML models\
    \ \nMahdavinejad et al. (2018). Keeping the current version of \nML models without\
    \ the history of evolution is not enough \nfor most of the recent IoT platforms.\
    \ Keeping the trace of \nthe ML model evolution helps us to use and compare differ-\n\
    ent versions on different datasets and produce new versions \nwithout losing the\
    \ previous versions.\n6.2  Our approach\nBased on the discussed challenges, various\
    \ ML models \nwith different properties can be developed for an IoT plat-\nform.\
    \ These properties can include information about the \ninput, output, parameters,\
    \ evaluation results, and con-\nnections to other models. Besides, ML models might\
    \ be \nFig. 4  Life-cycle of ML models\n86\n \nN. Kasrin et al.\n1 3\ndeveloped\
    \ in different development environments. To be \nable to integrate all ML models\
    \ that are implemented in \ndifferent environments, we need to define an efficient\
    \ ML \nmodel management framework that can fulfill the follow-\ning goals:\n–\
    \ The framework should be scalable\n– The framework should manage several executions\
    \ of \nML models on different input\n– The framework should keep the metadata\
    \ for different \nML models\nOne of the main capabilities of the ML model management\
    \ \nframework is scalability. This means the development and \nintegration of\
    \ new ML models in the framework should be \npossible. Such a framework should\
    \ be easily extended to \nconsider new data sources and new ML models that can\
    \ \ndeal with the data from new sources. As an example, we \ncan mention continuous\
    \ ML models in the form of queries \nfor streams of data and incremental ML models\
    \ for batches \nof input data.\nThe second goal is to have a framework that can\
    \ manage \nthe execution of one or more ML models on the data with \ndifferent\
    \ spatio-temporal granularity. The combination of \nthe results of several executions\
    \ brings new knowledge \nand insight into the data. To make it understandable,\
    \ a \nsimple ML model like detection of the top points of inter-\nest from the\
    \ trajectory of tourists in smart city use-case \ncan be considered. The top ten\
    \ points of interest (POIs) \nduring the week-days might differ from the top ten\
    \ POIs \nat the weekend. Weather conditions, festivals, and school \ntime can\
    \ also change the top ten POIs in a city. By com-\nbining the results from several\
    \ executions of the top POIs \ndetection model, we can discover the mobility patterns\
    \ of \ntourists in the city.\nIn addition, to integrate different ML models and\
    \ track \ndifferent versions of an ML model, the framework should \nbe able to\
    \ keep the metadata of each ML model and con-\nnections between ML models. Metadata\
    \ in the form of \nconnections can be defined between different ML models. \n\
    For example, an ML model can have different evolutionary \nversions that should\
    \ be traceable. Moreover, a combination \nof some special ML models can have a\
    \ noticeable effect \non accuracy. As the framework supports the scalability and\
    \ \nreusability of ML components, different adapted versions \nof an ML model\
    \ on heterogeneous data can be developed. \nEach version of an ML model has its\
    \ own properties, as \nmentioned before.\nOne of the main future goals in the\
    \ context of ML model \nmanagement framework is to reuse the framework and com-\n\
    ponents in different IoT platforms with minor changes for \nadapting ML models\
    \ to manage and automate all the ML \nrelated tasks.\n7  CResource: resource‑aware\
    \ data \nmanagement\nThe data that needs to be managed in an IoT ecosystem \n\
    steadily grows in all of its three big data dimensions: vol-\nume, velocity and\
    \ variety. The volume increases due to \nthe elevating amount of data generating\
    \ devices Atzori \net al. (2010); Gubbi et al. (2013) and velocity by advances\
    \ \nin communication technologies like 5g Rath and Kumar \n(2018). Kaur et al.\
    \ even calls it Internet-of-Big-data (IoBd) \nKaur et al. (2020).\nThe processing\
    \ of this huge amount of data utilizes \nmany resources. Current IoT platforms\
    \ are mainly cen-\ntralized and lack the feature of resource-aware processing\
    \ \nin the sense of edge and fog processing Mineraud et al. \n(2016). Centralized\
    \ processing is generally sub-optimal \nsince it uses the WAN bandwidth highly\
    \ inefficiently due \nto sending all data to the cloud in order to process it\
    \ there. \nFurthermore, cloud computing induces high latency, high \nenergy consumption\
    \ and arises privacy concerns. There \nexists a rule of thumb that you prefer\
    \ computation over \ncommunication when considering resource-awareness. \nProperly\
    \ positioning the processing along the way from \nthe data sources to the sinks\
    \ is the intended strategy. Ena-\nbling edge and fog processing is crucial for\
    \ being resource \nefficient and for real-time low latency applications. The \n\
    data processing in IoT is geographically distributed by the \nnature of the ecosystem\
    \ Chandra et al. (2018); Heintz et al. \n(2015).\nTo summarize, this challenge\
    \ focuses on the following \nresearch question: How can a global query be distributed\
    \ \nin a geographically-distributed data stream management \nsystem considering\
    \ the limitations of the IoT ecosystem?\n7.1  Related work\nIn data stream query\
    \ optimization a query is optimized to \nimprove runtime performance in the sense\
    \ of throughput, \nlatency and resource usage. The throughput is wanted to \n\
    be as high as possible and states how many data points \ncan be processed in a\
    \ specific time unit. The latency is \nwanted to be as less as possible and states\
    \ the time it takes \nfrom a data point entering the processing pipeline until\
    \ \nthe very same data point being reflected in the results. \nThe resource usage\
    \ is wanted to be as low as possible and \nstates the usage of CPU, RAM, network\
    \ bandwidth and \neven battery-/energy-consumption.\nData stream query optimization\
    \ approaches can be cate-\ngorized in 11 classes. An optimization technique can\
    \ either \nchange the data flow/operator-graph or leave it unchanged, \ncan either\
    \ change the semantics of a query, which means \n87\nData-sharing markets for integrating\
    \ IoT data processing functionalities \n1 3\nthat the output will differ from\
    \ the original one, or leave it \nunchanged and can be applied statically before\
    \ runtime or \ndynamically during runtime. An overview of all the query \noptimization\
    \ categories is shown in Table 1.\nThe data stream query optimization category,\
    \ which the \nresource-awareness of data stream processing in IoT fits best, \n\
    is operator placement. This kind of optimization usually \nassigns data stream\
    \ operators to hosts and cores reducing \neither resource usage due to less communication\
    \ or better \nutilizes available resources Schneider et al. (2013); Hirzel \n\
    et al. (2014, 2018).\nAccording to Sharma et al. (2019) who did a survey on \n\
    cost-based distributed query optimizers there are two types \nof query optimization\
    \ procedures which are either cost-\nbased or heuristic.\nDaum et al. proposed\
    \ a framework called Data Stream \nApplication Manager (DSAM) Lauterwald et al.\
    \ (2012) to \ncontrol a network of heterogeneous data stream management \nsystems.\
    \ A cost model Daum et al. (2011) is used to mini-\nmize the overall processing\
    \ and communication costs where \nthe operator placement query optimization is\
    \ modelled as a \ntask assignment problem.\nXu et al. optimize data stream queries\
    \ for distributed/\nedge processing to minimize latency providing a framework\
    \ \ncalled QueryGuard Xu et al. (2018). They are also using a \ncost model and\
    \ a dynamic programming enumeration algo-\nrithm in combination with heuristic\
    \ rules to prune unsatis-\nfied branches in the search space. This approach also\
    \ guar-\nantees preserved privacy for edge computing.\nPietzuch et al. (2006)\
    \ propose a virtual stream-based \noverlay network using a multidimensional metric\
    \ space to \nfind a good latency bandwidth trade-off for operator place-\nment.\
    \ A spring relaxation algorithm minimizes the network \nutilization of a query\
    \ while keeping the latency low.\nFan et al. (2020) used reinforcement learning\
    \ to dynami-\ncally allocate resources to IoT tasks based on historical data.\
    \ \nThe sub-optimal decisions made in real time aim to mini-\nmize computational\
    \ and communication delay.\n7.2  Our approach\nTo enable resource-awareness in\
    \ the IoT ecosystem a dis-\ntributed data stream management system (DDSMS) is\
    \ devel-\noped. As a base, an existing data stream management system \n(DSMS)\
    \ is used which already provides mechanisms and \nabstractions to gain control\
    \ over the data flow. Data stream \nmanagement systems provide semantics for data\
    \ streams and \ndata steam operators enabling high-level query languages \nand\
    \ data stream query optimization.\nThe network of distributed data stream processing\
    \ nodes \nconsist of DSMS nodes and smart sensors. Those nodes are \ncontrolled\
    \ by a central unit, which provides holistic control \nfor the whole network and\
    \ is aware of all node and network \nproperties like bandwidth utilization and\
    \ latency. The DSMS \nnodes are fully fledged data stream management systems \n\
    and capable of processing streaming data using predefined \noperators. Whereas\
    \ the smart sensors provide an interface \nin order to remotely configure basic\
    \ edge processing on the \nsensor itself including select, aggregate and filter\
    \ operators.\nIn the central unit, different distribution strategies can \nbe\
    \ implemented which optimize the resource utilization for \nspecific parameters\
    \ according to a cost model like proposed \nby Wang et al. (2009). A resource\
    \ monitor tracks the per-\nformance of a global query executed under a certain\
    \ distri-\nbution strategy. The monitoring enables the evaluation of \ndifferent\
    \ operator placement strategies for specific use cases \nto minimize resource\
    \ utilization for constrained devices or \nthe overall system.\nThe existing data\
    \ stream management system Odys-\nseus Appelrath et al. (2012) is extended to\
    \ implement this \napproach.\n7.2.1  Resource‑aware dairy cattle activity monitoring\n\
    For demonstration purpose the approach above is applied to \nthe dairy cattle\
    \ activity monitoring.\nTable 1  Query optimization \ncategories\n#\nOptimization\n\
    Graph\nSemantics\nDynamic\n1\nOperator reordering\nChanged\nUnchanged\n(Depends)\n\
    2\nRedundancy elimination\nChanged\nUnchanged\n(Depends)\n3\nOperator separation\n\
    Changed\nUnchanged\nStatic\n4\nFusion\nChanged\nUnchanged\n(Depends)\n5\nFission\n\
    Changed\n(Depends)\n(Depends)\n6\nPlacement\nUnchanged\nUnchanged\n(Depends)\n\
    7\nLoad balancing\nUnchanged\nUnchanged\n(Depends)\n8\nState sharing\nUnchanged\n\
    Unchanged\nStatic\n9\nBatching\nUnchanged\nUnchanged\n(Depends)\n10\nAlgorithm\
    \ selection\nUnchanged\n(Depends)\n(Depends)\n11\nLoad shedding\nUnchanged\nChanged\n\
    Dynamic\n88\n \nN. Kasrin et al.\n1 3\nThe models trained in the training pipeline\
    \ are used to \nmonitor the cattle behavior in the prediction pipeline. The \n\
    prediction pipeline consists of the following steps: \n1. Measurement via sensor\
    \ system\n2. Segmentation\n3. Feature Calculation\n4. Prediction\nIn this pipeline,\
    \ there are many parameters, which need to be \ntuned to be resource-efficient.\
    \ In step 1 the data is generated \nand it may be best for prediction accuracy\
    \ to get as many \ndata as possible but for resource-efficiency you want to have\
    \ \na good trade-off between data frequency and accuracy.\nIn step 2 the sensor\
    \ data is segmented into windows \nwhere a good window size depends on the duration\
    \ of the \nactivities to recognize. However, the window stride param-\neter, which\
    \ configures the amount of window overlap, has \na direct impact on the computational\
    \ costs. Here you want \nto have a good window stride/accuracy trade-off reducing\
    \ \ncomputational costs arising from window overlap.\nIn step 3 the data points\
    \ segmented in windows are aggre-\ngated to features. Optimizing the resource-efficiency\
    \ of the \nfeature calculation relies on a good feature selection strategy. \n\
    You will get a higher accuracy including more features to \nthe model but there\
    \ might be a minimal feature subset which \nhas a nice feature/accuracy trade-off\
    \ reducing computational \ncosts and still fulfilling accuracy needs.\nIn step\
    \ 4 the trained models are fed with the features and \nthe activity is predicted.\
    \ Machine learning algorithms differ \nin computational prediction costs. Therefore,\
    \ choosing a ML \napproach providing less accuracy but reducing resource uti-\n\
    lization significantly is a viable optimization strategy in this \nstep. As project\
    \ complexity grows the amount of training \nmodels and their associated information\
    \ becomes complex \nand usually re-usability and sharing drops due to lack of\
    \ \nframework to manage this ML life-cycle process, paving the \nway to the CModel\
    \ challenge.\nBesides the distribution-agnostic resource optimizations \nmentioned\
    \ above there is another important point to think \nabout. It is crucial to decide\
    \ where which computation will \ntake place. The cloud processing approach which\
    \ sends all \nthe data from step 1 to the cloud and performs steps 2-4 \nthere\
    \ is obviously not optimal due to network bandwidth \nutilization. Computing steps\
    \ 2-3 on the edge and step 4 in \nthe fog or even steps 2-4 on the edge will perform\
    \ better \naccording to resource utilization.\nThe different processing steps\
    \ in the prediction pipe-\nline are implemented as data stream operators in a\
    \ DSMS. \nAccording to the proposed approach above different distri-\nbution strategies\
    \ can be evaluated in the monitoring sys-\ntem of the distributed data stream\
    \ management system to \nfind a resource-saving setup. Also the data stream operators\
    \ \nimplementing steps 1-4 can be parameterized to evaluate \nparameter settings\
    \ for the single processing steps.\n8  Related work\nThe landscape of the work\
    \ related to our discussion here \nis varied and multi-dimensional. It includes\
    \ topics such \nas: IoT, smart cities, data management, analytics, sensor \nnetworks,\
    \ communication protocols, and others. One way \nwe can understand this space\
    \ would be to simplify it into a \ntwo-dimensional vertical and horizontal space.\
    \ Vertically, \nwe will use the IoT architectural structure of: sensor/actua-\n\
    tor, device, gateway, middleware and application provided in \nGuth et al. (2016)\
    \ as a guide, as well as the definitions they \nprovide for these components.\n\
    Sensors and actuators are hardware components, whereas \na sensor measures parameters\
    \ of its physical environment, \nan actuator acts, controls or manipulates its\
    \ environment. A \ndevice is a hardware component as well that connects to a \n\
    sensor/actuator, it can process data from sensors or control \nactuators. Gateways\
    \ can be used to compensate communi-\ncation limitations of devices. IoT (Integration)\
    \ middleware \nserves as a middle point between applications and devices/\ngateways,\
    \ by processing or evaluating received data or send-\ning commands to be executed\
    \ by actuators Guth et al. (2016). \nHorizontally we can place orthogonal fields\
    \ of study that \nintersect with IoT such as smart cities, big data analytics,\
    \ \ndistributed data processing, sensor networks, etc. Figure 5 \ndepicts one\
    \ possible interpretation of the related work space.\nGubbi et al. (2013) present\
    \ an overall vision of IoT is \npresented that is influenced by wireless sensor\
    \ networks. In a \nsimilar vain Pike et al. (2019) applies the intersection of\
    \ IoT \nand sensor networks to the domain of healthcare. Alavi et al. \n(2018)\
    \ apply the IoT approach to the smart cities domain and \nFig. 5  Related work\
    \ space\n89\nData-sharing markets for integrating IoT data processing functionalities\
    \ \n1 3\nfocus on the middleware and application side of the problem, \nwhile\
    \ using the motivating scenarios of smart cities to drive \nthe design of their\
    \ vision.\nMoving on in the distributed data processing pipelines \nand streams,\
    \ Hernandez et al. (2020) models intelligent data \npipelines using an actor-based\
    \ model for IoT-based applica-\ntions. The focus here is to support application\
    \ developers \nin building intelligent data processing actors in a common \necosystem.\
    \ To continue the look into data streams in IoT, \nElsaleh et al. (2020) present\
    \ a lightweight ontology to model \nIoT data streams to support easy data analytics\
    \ and event \ndetection services.\nTurning to existing IoT platforms that are\
    \ beyond research \nwork, we have recently been experimenting with Things-\nBoard5\
    \ and Cumulocity6 and the possibilities of using them \nin our stack. Both these\
    \ solutions implement the basic IoT \nrequirements, and in retrospect we don’t\
    \ see our work as \ncompeting with them but as integrating with them to ben-\n\
    efit from the rich support for communication protocols, and \ndashboarding.\n\
    Another horizontal dimension of work focuses on the \nrepresentation of domain\
    \ entities & assets relevant to the \nIoT platform, be they sensors, actuators,\
    \ users, or others. \nFor example, Mormul and Stach (2020) present a context \n\
    model for holistic monitoring and management of complex \nIT environments, to\
    \ be used in conjunction with the larger \nIoT platform. On the other hand, Sasidharan\
    \ and Somov \n(2014) propose a framework where these assets are modeled \nas either:\
    \ real world objects, virtual objects or composite \nvirtual objects. In many\
    \ ways such solutions have a similar \naim in representing data about domain entities\
    \ at different \nlevels of the IoT platform.\nThe challenges we tackle here can\
    \ be positioned in the \nspace depicted in Fig. 5. The CResource challenge covers\
    \ \nthe continuous space of device, gateway, sensor networks, \nand middleware.\
    \ The CQuality challenge touches on sensor, \ndevice, gateway, middleware, sensor\
    \ networks, smart cities \nas well as linked data. The CModel challenge, touches\
    \ on \nanalytics, smart cities, middleware, applications, and linked \ndata. Our\
    \ approach toward the CPrivacy challenge crosses \nthe IoT stack from sensors\
    \ up to middleware. And finally, \nthe approach we develop to IoT platform design\
    \ falls in the \nlinked data, middleware, and applications.\nAs distinguished\
    \ from the related work discussed ear-\nlier, in this paper, we combine paradigms\
    \ and focus on a \nset of data management problems at different levels of the\
    \ \ndata management stack. For example although an IoT plat-\nform is used as\
    \ a hub for many of the data streams it is not \nthe end goal in itself. Smart\
    \ city scenarios act as a problem \nscenario to motivate the choice of problems\
    \ to solve. Data is \nprocessed at different locations in the web of devices.\
    \ With \nour focus on enriching data quality information, provenance \nand data\
    \ descriptions, we provide new opportunities to work \nwith data. Integrating\
    \ that with the model management and \nlearning, it becomes and multi-function\
    \ data management \ntool-set that is applicable to both research and industry\
    \ use \ncases.\nThe work presented here extends our previous discus-\nsion in\
    \ Steuer et al. (2016) and adds new challenges such \nas model management, sensor\
    \ data quality and knowledge \nmanagement.\n9  Conclusion and future work\nFrom\
    \ the discussion in this paper, we can see that there are \nmany research challenges\
    \ left for data management in IoT \nthat go beyond the discussion of big data\
    \ processing.\nTo optimize data flows across the available edge-fog-\ncloud infrastructure\
    \ (CResource) to save energy and band-\nwidth, the system needs to be aware of\
    \ the operator seman-\ntics. Techniques from the well-known relational algebra\
    \ \ncan be applied to regain control over these heterogeneous \nenvironments.\
    \ However, the cost models used in this optimi-\nzation step need to be re-defined\
    \ to cover novel aspects like \nenergy-consumption of operators or privacy constraints\
    \ (if \ncertain raw data is not allowed to leave a processing node). \nIn addition,\
    \ the algebra might need to be extended to cover \nnovel operators like ML model\
    \ based prediction.\nSince most IoT systems are based on sensors, the achiev-\n\
    able data quality needs to be considered not only during \ninstallation, but also\
    \ online during operation of IoT sys-\ntems (CQuality). If we leave this task\
    \ to the applications, \nsystem-wide and consistent data quality control will\
    \ hardly \nbe achievable. While certain dimensions of data quality \nare application-specific,\
    \ we can model general data qual-\nity dimensions and how they depend on installation\
    \ context \nfor sensors. This model can then be used to auto-generate \nonline\
    \ quality assessment within large-scale IoT infrastruc-\ntures, thus dis-burdening\
    \ the application developers from \nthis tedious step.\nSince more and more sensor-based\
    \ IoT applications are \nbased on machine learning (ML) techniques, ex. for activ-\n\
    ity recognition, the management of the trained ML models \nbecome part of the\
    \ data management challenges (CModel). \nAs we can see from the use case of mobility\
    \ analytics and \nthe dairy cattle use case, the continuous life-cycle of ML \n\
    models raises the demand to keep the information about dif-\nferent ML over time\
    \ and space, so that we can manage and \nautomate all ML related tasks.\nA crosscutting\
    \ concern of large-scale IoT system is pri-\nvacy (CPrivacy), since devices often\
    \ collect raw data that \n5 https ://thing sboar d.io/.\n6 https ://www.softw\
    \ areag .cloud /site/produ ct/cumul ocity -iot.html.\n90\n \nN. Kasrin et al.\n\
    1 3\ncould be used to derive sensitive information, which is not \nalways needed\
    \ or even allowed. We discussed that issue \nwithin the use case of mobility data:\
    \ While individual mobil-\nity is highly sensitive, aggregated mobility is not.\
    \ To fully \nleverage the insights that we could get from such aggregated \nmobility\
    \ data, we need to develop trustable online tech-\nniques for anonymization. As\
    \ with data quality, the task of \nproper data anonymization should be provided\
    \ as standard \nfunctions from an IoT infrastructure so that its application is\
    \ \nnot dependent on the programming skill of single developer \nteams.\nFinally,\
    \ an approach to IoT platform design is needed to \nbe able to integrate such\
    \ heterogeneous data management \nfunctionalities under one roof. The approach\
    \ we follow is \ninfluenced by meta-data management approaches to enable a \n\
    higher level of system support within the IoT infrastructure. \nIn many IoT application\
    \ domains (ex. smart cities), these \ninfrastructures span different organizations\
    \ and stakeholders. \nHence, we propose the IB model and data-sharing markets\
    \ \nto support multiple groups, systems, and functionalities and \nintegrate their\
    \ data in an information-driven manner. The \nsuch structured information can\
    \ be used both by automa-\ntion system (ex. distributed query optimizers or data\
    \ quality \nassessment) and by human stake-holders, like developers, \noperators,\
    \ or even end users (ex. to gain transparency about \ninstalled systems in their\
    \ work environment).\nAs we can see from this discussion, data management for\
    \ \nlarge-scale IoT systems has still many unsolved challenges. \nWhile they all\
    \ could be tackled by individual software devel-\noped and within application-code,\
    \ it is key for long-term \noperation, maintenance, and transparency of such systems\
    \ \nto get more and more support by frameworks and higher-\nlevel programming\
    \ concepts like query languages. Like a \ndatabase system that hides many implementation\
    \ details like \ndata distribution or index usage, future IoT infrastructures\
    \ \nmight as well provide a high-level interface with pre-build \nsupport for\
    \ resource-aware query optimization, online qual-\nity assessment, ML model management,\
    \ privacy-preserving \ndata aggregation, and a cross-organizational knowledge\
    \ \nmanagement.\nFunding Open Access funding enabled and organized by Projekt\
    \ \nDEAL.\nCompliance with ethical standards \nConflict of interest On behalf\
    \ of all authors, the corresponding author \nstates that there is no conflict\
    \ of interest.\nOpen Access This article is licensed under a Creative Commons\
    \ Attri-\nbution 4.0 International License, which permits use, sharing, adapta-\n\
    tion, distribution and reproduction in any medium or format, as long \nas you\
    \ give appropriate credit to the original author(s) and the source, \nprovide\
    \ a link to the Creative Commons licence, and indicate if changes \nwere made.\
    \ The images or other third party material in this article are \nincluded in the\
    \ article’s Creative Commons licence, unless indicated \notherwise in a credit\
    \ line to the material. If material is not included in \nthe article’s Creative\
    \ Commons licence and your intended use is not \npermitted by statutory regulation\
    \ or exceeds the permitted use, you will \nneed to obtain permission directly\
    \ from the copyright holder. To view a \ncopy of this licence, visit http://creat\
    \ iveco mmons .org/licen ses/by/4.0/.\nReferences\nAbbasi, M.A., Memon, Z.A.,\
    \ Syed, T.Q., Memon, J., Alshboul, R.: \nAddressing the Future Data Management\
    \ Challenges in IoT: A \nProposed Framework. Int. J. Adv. Comput. Sci. Appl. (IJACSA)\
    \ \n8(5), 197–207 (2017)\nAboubakr, B., Steuer, S., Nicklas, D.: Towards Quality\
    \ Aware Sensor \nData Stream Processing in a Smart City Living Lab pp. 36–41 \n\
    (2017). http://ceur-ws.org/Vol-1858/paper 8.pdf\nAlavi, A.H., Jiao, P., Buttlar,\
    \ W.G., Lajnef, N.: Internet of Things-\nenabled smart cities: State-of-the-art\
    \ and future trends. Measure-\nment 129, 589–606 (2018) https ://doi.org/10.1016/j.measu\
    \ remen \nt.2018.07.067. http://www.scien cedir ect.com/scien ce/artic le/pii/\n\
    S0263 22411 83069 12\nAlpaydin, E.: Introduction to Machine Learning. MIT Press\
    \ (2020). \nGoogle-Books-ID: tZnSDwAAQBAJ\nAppelrath, H.J., Geesen, D., Grawunder,\
    \ M., Michelsen, T., Nicklas, \nD.: Odysseus: a highly customizable framework\
    \ for creating effi-\ncient event stream management systems. In: Proceedings of\
    \ the \n6th ACM International Conference on Distributed Event-Based \nSystems\
    \ - DEBS ’12, pp. 367–368. ACM Press, Berlin, Germany \n(2012). https ://doi.org/10.1145/23354\
    \ 84.23355 25. http://dl.acm.\norg/citat ion.cfm?doid=23354 84.23355 25\nAtzori,\
    \ L., Iera, A., Morabito, G.: The Internet of Things: A sur-\nvey. Computer Networks\
    \ 54(15), 2787–2805 (2010)https ://doi.\norg/10.1016/j.comne t.2010.05.010. https\
    \ ://linki nghub .elsev ier.\ncom/retri eve/pii/S1389 12861 00015 68\nBatini,\
    \ C., Scannapieco, M.: Data Quality: Concepts, Method-\nologies and Techniques.\
    \ Data-Centric Systems and Applica-\ntions. Springer-Verlag, Berlin Heidelberg\
    \ (2006). https ://doi.\norg/10.1007/3-540-33173 -5. https ://www.sprin ger.com/de/\n\
    book/97835 40331 728\nBenabbas, A., Geißelbrecht, M., Nikol, G.M., Mahr, L., Nähr,\
    \ D., \nSteuer, S., Wiesemann, G., Müller, T., Nicklas, D., Wieland, T.: \nMeasure\
    \ particulate matter by yourself: data-quality monitoring in \na citizen science\
    \ project. Journal of Sensors and Sensor Systems \n8(2), 317–328 (2019) https\
    \ ://doi.org/10.5194/jsss-8-317-2019. \nhttps ://jsss.coper nicus .org/artic les/8/317/2019/\n\
    Benabbas, A., Hornig, H., Nicklas, D.: Semi-Automatic Ontology \nPopulation for\
    \ Online Quality Assessment of Particulate Mat-\nter Sensors. In: I. Chatzigiannakis,\
    \ Y. Tobe, P. Novais, O. Amft \n(eds.) Intelligent Environments 2018—Workshop\
    \ Proceedings of \nthe 14th International Conference on Intelligent Environments,\
    \ \nRome, Italy, 25-28 June 2018, Ambient Intelligence and Smart \nEnvironments,\
    \ vol. 23, pp. 119–128. IOS Press (2018). https ://\ndoi.org/10.3233/978-1-61499\
    \ -874-7-119\nBenabbas, M.A., Steuer, M.S., Nicklas, D.: Towards Adaptive Sensor\
    \ \nData Quality Improvement based on Context Models. Workshop \non Context and\
    \ Activity Modeling and Recognition (CoMoReA) \np. 6 (2020)\nBuchholz, T., Schiffers,\
    \ M.: Quality of Context: What It Is And Why \nWe Need It. In: In Proceedings\
    \ of the 10th Workshop of the Open-\nView University Association: OVUA’03 (2003)\n\
    Cao, J., Carminati, B., Ferrari, E., Tan, K.L.: CASTLE: Continuously \nanonymizing\
    \ data streams. Dependable Secure Comput. IEEE \nTrans. 8, 337–352 (2011). https\
    \ ://doi.org/10.1109/TDSC.2009.47\n91\nData-sharing markets for integrating IoT\
    \ data processing functionalities \n1 3\nChandra, A., Heintz, B., Sitaraman, R.:\
    \ Optimizing Geo-Distributed \nStreaming Analytics. In: Sakr, S., Zomaya, A. (eds.)\
    \ Encyclopedia \nof Big Data Technologies, pp. 1–5. Springer International Publish-\n\
    ing, Cham (2018)\nChin, J., Callaghan, V., Lam, I.: Understanding and personalising\
    \ smart \ncity services using machine learning, The Internet-of-Things \nand Big\
    \ Data. In: 2017 IEEE 26th International Symposium on \nIndustrial Electronics\
    \ (ISIE), pp. 2050–2055 (2017). https ://doi.\norg/10.1109/ISIE.2017.80015 70.\
    \ ISSN: 2163-5145\nCompton, M., Barnaghi, P., Bermudez, L., García-Castro, R.,\
    \ Corcho, \nO., Cox, S., Graybeal, J., Hauswirth, M., Henson, C., Herzog, A.,\
    \ \nHuang, V., Janowicz, K., Kelsey, W.D., Le Phuoc, D., Lefort, L., \nLeggieri,\
    \ M., Neuhaus, H., Nikolov, A., Page, K., Passant, A., \nSheth, A., Taylor, K.:\
    \ The SSN ontology of the W3C semantic \nsensor network incubator group. Journal\
    \ of Web Semantics 17, \n25–32 (2012) https ://doi.org/10.1016/j.webse m.2012.05.003.\
    \ \nhttp://www.scien cedir ect.com/scien ce/artic le/pii/S1570 82681 \n20005 71\n\
    Cui, L., Yang, S., Chen, F., Ming, Z., Lu, N., Qin, J.: A survey on appli-\ncation\
    \ of machine learning for Internet of Things. Int. J. Mach. \nLearn. Cybern. 9(8),\
    \ 1399–1417 (2018). https ://doi.org/10.1007/\ns1304 2-018-0834-5\nDaum, M., Lauterwald,\
    \ F., Baumgärtel, P., Pollner, N., Meyer-Wegener, \nK.: Efficient and cost-aware\
    \ operator placement in heterogene-\nous stream-processing environments. In: Proceedings\
    \ of the 5th \nACM international conference on Distributed event-based sys-\n\
    tem—DEBS ’11, p. 393. ACM Press, New York, New York, USA \n(2011). https ://doi.org/10.1145/20022\
    \ 59.20023 27. http://porta \nl.acm.org/citat ion.cfm?doid=20022 59.20023 27\n\
    Elmamooz, G., Finzel, B., Nicklas, D.: Towards Understanding \nMobility in Museums.\
    \ In: B. Mitschang, N. Ritter, H. Schwarz, \nM. Klettke, A. Thor, O. Kopp, M. Wieland\
    \ (eds.) Datenbank-\nsysteme für Business, Technologie und Web (BTW 2017), 17.\
    \ \nFachtagung des GI-Fachbereichs ,,Datenbanken und Informations-\nsysteme” (DBIS),\
    \ 6.-10. März 2017, Stuttgart, Germany, Work-\nshopband, LNI, vol. P-266, pp.\
    \ 127–134. GI (2017). https ://dl.gi.\nde/20.500.12116 /904\nElsaleh, T., Enshaeifar,\
    \ S., Rezvani, R., Acton, S.T., Janeiko, V., \nBermudez-Edo, M.: IoT-Stream: A\
    \ Lightweight Ontology for \nInternet of Things Data Streams and Its Use with\
    \ Data Analytics \nand Event Detection Services. Sensors 20(4), 953 (2020) https\
    \ \n://doi.org/10.3390/s2004 0953. https ://www.mdpi.com/1424-\n8220/20/4/953.\
    \ Number: 4 Publisher: Multidisciplinary Digital \nPublishing Institute\nFan,\
    \ Q., Bai, J., Zhang, H., Yi, Y., Liu, L.: Delay-aware Resource \nAllocation in\
    \ Fog-assisted IoT Networks Through Reinforcement \nLearning. arXiv :2005.04097\
    \ [cs, eess] (2020)\nFung, B.C.M., Wang, K., Chen, R., Yu, P.S.: Privacy-preserving\
    \ data \npublishing: A survey of recent developments. ACM Comput. \nSurv. 42(4),\
    \ 14:1–14:53 (2010)\nGeisler, S., Quix, C., Weber, S., Jarke, M.: Ontology-Based\
    \ Data \nQuality Management for Data Streams. J. Data Inf. Qual. 7(4), \n18:1–18:34\
    \ (2016). https ://doi.org/10.1145/29683 32\nGolab, L., Özsu, M.T.: Issues in\
    \ data stream management. ACM SIG-\nMOD Record 32(2), 5–14 (2003). https ://doi.org/10.1145/77698\
    \ \n5.77698 6\nGubbi, J., Buyya, R., Marusic, S., Palaniswami, M.: Internet of\
    \ Things \n(IoT): A vision, architectural elements, and future directions. \n\
    Fut. Gen. Comput. Syst. 29(7), 1645–1660 (2013)https ://doi.\norg/10.1016/j.futur\
    \ e.2013.01.010. http://www.scien cedir ect.com/\nscien ce/artic le/pii/S0167\
    \ 739X1 30002 41\nGuth, J., Breitenbücher, U., Falkenthal, M., Leymann, F., Reinfurt,\
    \ L.: \nComparison of IoT platform architectures: A field study based \non a reference\
    \ architecture. In: 2016 Cloudification of the Inter-\nnet of Things (CIoT), pp.\
    \ 1–6 (2016). https ://doi.org/10.1109/\nCIOT.2016.78729 18\nHeintz, B., Chandra,\
    \ A., Sitaraman, R.K.: Optimizing Grouped \nAggregation in Geo-Distributed Streaming\
    \ Analytics. In: Pro-\nceedings of the 24th International Symposium on High-Per-\n\
    formance Parallel and Distributed Computing - HPDC ’15, pp. \n133–144. ACM Press,\
    \ Portland, Oregon, USA (2015). https ://\ndoi.org/10.1145/27492 46.27492 76.\
    \ http://dl.acm.org/citat ion.\ncfm?doid=27492 46.27492 76\nHern, A.: Fitness\
    \ tracking app strava gives away location of secret \nus army bases. https ://www.thegu\
    \ ardia n.com/world /2018/jan/28/\nfitne ss-track ing-app-gives -away-locat ion-of-secre\
    \ t-us-army-bases \n. Accessed: 2020-10-11\nHernandez, A., Xiao, B., Tudor, V.:\
    \ ERAIA - Enabling Intelligence \nData Pipelines for IoT-based Application Systems.\
    \ In: 2020 IEEE \nInternational Conference on Pervasive Computing and Communi-\n\
    cations (PerCom), pp. 107–116. Austin, Texas, USA (2020)\nHirzel, M., Soulé, R.,\
    \ Gedik, B., Schneider, S.: Stream Query Optimiza-\ntion. In: Sakr, S., Zomaya,\
    \ A. (eds.) Encyclopedia of Big Data Tech-\nnologies, pp. 1–9. Springer International\
    \ Publishing, Cham (2018)\nHirzel, M., Soulé, R., Schneider, S., Gedik, B., Grimm,\
    \ R.: A catalog \nof stream processing optimizations. ACM Computing Surveys \n\
    46(4), 1–34 (2014). https ://doi.org/10.1145/25284 12\nKamilaris, A., Gao, F.,\
    \ Prenafeta-Boldu, F.X., Ali, M.I.: Agri-IoT: A \nsemantic framework for Internet\
    \ of Things-enabled smart farm-\ning applications. In: 2016 IEEE 3rd World Forum\
    \ on Internet of \nThings (WF-IoT), pp. 442–447 (2016). https ://doi.org/10.1109/\n\
    WF-IoT.2016.78454 67\nKaur, N., Sood, S.K., Verma, P.: Cloud resource management\
    \ using \n3Vs of Internet of Big data streams. Computing 102(6), 1463–\n1485 (2020)\
    \ https ://doi.org/10.1007/s0060 7-019-00732 -5. http://\nlink.sprin ger.com/10.1007/s0060\
    \ 7-019-00732 -5\nKavakiotis, I., Tsave, O., Salifoglou, A., Maglaveras, N., Vlahavas,\
    \ \nI., Chouvarda, I.: Machine Learning and Data Mining Methods \nin Diabetes\
    \ Research. Computational and Structural Biotech-\nnology Journal 15, 104–116\
    \ (2017) https ://doi.org/10.1016/j.\ncsbj.2016.12.005. http://www.scien cedir\
    \ ect.com/scien ce/artic le/\npii/S2001 03701 63007 33\nKlein, A., Lehner, W.:\
    \ Representing Data Quality in Sensor Data \nStreaming Environments. J. Data Inf.\
    \ Qual. 1(2), 10:1–10:28 \n(2009). https ://doi.org/10.1145/15778 40.15778 45\n\
    Kuka, C., Nicklas, D.: Supporting quality-aware pervasive applications \nby probabilistic\
    \ data stream management. In: Proceedings of the 8th \nACM International Conference\
    \ on Distributed Event-Based Systems, \nDEBS ’14, pp. 330–333. Association for\
    \ Computing Machinery, \nMumbai, India (2014). https ://doi.org/10.1145/26112\
    \ 86.26113 19\nLauterwald, F., Pollner, N., Daum, M., Meyer-Wegener, K.: Data\
    \ \nStream Application Manager (DSAM). In: Proceedings of the \n6th ACM International\
    \ Conference on Distributed Event-Based \nSystems - DEBS ’12, pp. 381–382. ACM\
    \ Press, Berlin, Germany \n(2012). https ://doi.org/10.1145/23354 84.23355 32.\
    \ http://dl.acm.\norg/citat ion.cfm?doid=23354 84.23355 32\nMahdavinejad, M.S.,\
    \ Rezvan, M., Barekatain, M., Adibi, P., Barnaghi, \nP., Sheth, A.P.: Machine\
    \ learning for internet of things data analy-\nsis: a survey. Digital Communications\
    \ and Networks 4(3), 161–\n175 (2018) https ://doi.org/10.1016/j.dcan.2017.10.002.\
    \ http://\nwww.scien cedir ect.com/scien ce/artic le/pii/S2352 86481 73024 7X\n\
    Mineraud, J., Mazhelis, O., Su, X., Tarkoma, S.: A gap analysis of \nInternet-of-Things\
    \ platforms. Comput. Commun. 89–90, 5–16 \n(2016) https ://doi.org/10.1016/j.comco\
    \ m.2016.03.015. http://\nwww.scien cedir ect.com/scien ce/artic le/pii/S0140\
    \ 36641 63007 31\nMormul, M., Stach, C.: A Context Model for Holistic Monitoring\
    \ and \nManagement of Complex IT Environments. In: Proceedings of \nthe 2020 IEEE\
    \ International Conference on Pervasive Comput-\ning and Communications Workshops\
    \ (CoMoRea), pp. 1-1. IEEE \nComputer Society (2020). Backup Publisher: Universität\
    \ Stuttgart, \nFakultät Informatik, Elektrotechnik und Informationstechnik, Ger-\n\
    many Type: Workshop-Beitrag\n92\n \nN. Kasrin et al.\n1 3\nPatil, S.S., Thorat,\
    \ S.A.: Early detection of grapes diseases using \nmachine learning and IoT. In:\
    \ 2016 Second International Confer-\nence on Cognitive Computing and Information\
    \ Processing (CCIP), \npp. 1–5 (2016). https ://doi.org/10.1109/CCIP.2016.78028\
    \ 87\nPelekis, N., Theodoridis, Y.: Privacy-Aware Mobility Data Exploration. \n\
    In: Pelekis, N., Theodoridis, Y. (eds.) Mobility Data Management \nand Exploration,\
    \ pp. 169–185. Springer, New York (2014)\nPietzuch, P., Ledlie, J., Shneidman,\
    \ J., Roussopoulos, M., Welsh, M., \nSeltzer, M.: Network-Aware Operator Placement\
    \ for Stream-Pro-\ncessing Systems. In: 22nd International Conference on Data\
    \ Engi-\nneering (ICDE’06), pp. 49-49. IEEE, Atlanta, GA, USA (2006). \nhttps\
    \ ://doi.org/10.1109/ICDE.2006.105. http://ieeex plore .ieee.org/\ndocum ent/16174\
    \ 17/\nPike, M., Mustafa, N.M., Towey, D., Brusic, V.: Sensor Networks and \n\
    Data Management in Healthcare: Emerging Technologies and \nNew Challenges. In:\
    \ 2019 IEEE 43rd Annual Computer Software \nand Applications Conference (COMPSAC),\
    \ vol. 1, pp. 834–839 \n(2019). https ://doi.org/10.1109/COMPS AC.2019.00123 .\
    \ ISSN: \n0730-3157\nRath, D.K., Kumar, A.: A Primer on Internet of Things Ecosystem\
    \ \nand 5G Networks. In: 2018 International Conference on Informa-\ntion Technology\
    \ (ICIT), pp. 233–238. IEEE, Bhubaneswar, India \n(2018). https ://doi.org/10.1109/ICIT.2018.00055\
    \ . https ://ieeex \nplore .ieee.org/docum ent/87241 46/\nSamie, F., Bauer, L.,\
    \ Henkel, J.: From Cloud Down to Things: An \nOverview of Machine Learning in\
    \ Internet of Things. IEEE Inter-\nnet Things J. 6(3), 4921–4934 (2019). https\
    \ ://doi.org/10.1109/\nJIOT.2019.28938 66. Conference Name: IEEE Internet of Things\
    \ \nJournal\nSasidharan, S., Somov, A., Biswas, A.R., Giaffreda, R.: Cognitive\
    \ \nmanagement framework for Internet of Things: — A prototype \nimplementation.\
    \ In: 2014 IEEE World Forum on Internet of \nThings (WF-IoT), pp. 538–543 (2014).\
    \ https ://doi.org/10.1109/\nWF-IoT.2014.68032 25\nSchelter, S., Bießmann, F.,\
    \ Januschowski, T., Salinas, D., Seufert, S., \nSzarvas, G.: On Challenges in\
    \ Machine Learning Model Manage-\nment. IEEE Data Eng, Bull (2018)\nSchmidt, S.,\
    \ Berthold, H., Lehner, W.: QStream: Deterministic Query-\ning of Data Streams\
    \ (2004). https ://doi.org/10.1016/B978-01208 \n8469-8/50148 -0\nSchneider, S.,\
    \ Hirzel, M., Gedik, B.: Tutorial: stream processing optimi-\nzations. In: Proceedings\
    \ of the 7th ACM international conference \non Distributed event-based systems\
    \ - DEBS ’13, p. 249. ACM \nPress, Arlington, Texas, USA (2013). 10.1145/2488222.2488268.\
    \ \nhttp://dl.acm.org/citat ion.cfm?doid=24882 22.24882 68\nSharma, M., Singh,\
    \ G., Singh, R.: A review of different cost-based dis-\ntributed query optimizers.\
    \ Prog. Artif. Intell. 8(1), 45–62 (2019). \nhttps ://doi.org/10.1007/s1374 8-018-0154-8\n\
    Steuer, S., Benabbas, A., Kasrin, N., Nicklas, D.: Challenges and \nDesign Goals\
    \ for an Architecture of a Privacy-preserving Smart \nCity Lab. Datenbank-Spektrum\
    \ 16(2), 147–156 (2016)\nVlacheas, P., Giaffreda, R., Stavroulaki, V., Kelaidonis,\
    \ D., Foteinos, \nV., Poulios, G., Demestichas, P., Somov, A., Biswas, A.R., Moe-\n\
    ssner, K.: Enabling smart cities through a cognitive management \nframework for\
    \ the internet of things. IEEE Commun. Mag. 51(6), \n102–111 (2013). https ://doi.org/10.1109/MCOM.2013.65256\
    \ 02. \nCommunications Magazine Conference Name: IEEE\nWang, S., Tan, Z., Gao,\
    \ X.: Query Optimization over Distributed \nData Stream. In: 2009 Ninth International\
    \ Conference on Hybrid \nIntelligent Systems, pp. 415–418. IEEE, Shenyang, China\
    \ (2009). \nhttps ://doi.org/10.1109/HIS.2009.198. http://ieeex plore .ieee.org/\n\
    docum ent/52544 96/\nWeak passwords banned in california from 2020. https ://www.bbc.com/\n\
    news/techn ology -45757 528. Accessed: 2020-10-11\nWu, W., Cheng, X., Ding, M.,\
    \ Xing, K., Liu, F., Deng, P.: Localized Outly-\ning and Boundary Data Detection\
    \ in Sensor Networks. IEEE Trans. \nKnowl. Data Eng.19(8), 1145–1157 (2007) https\
    \ ://doi.org/10.1109/\nTKDE.2007.1067. http://ieeex plore .ieee.org/docum ent/42625\
    \ 42/\nXu, R., Palanisamy, B., Joshi, J.: QueryGuard: Privacy-Preserving \nLatency-Aware\
    \ Query Optimization for Edge Computing. In: \n2018 17th IEEE International Conference\
    \ On Trust, Security And \nPrivacy In Computing And Communications/ 12th IEEE\
    \ Interna-\ntional Conference On Big Data Science And Engineering (Trust-\nCom/BigDataSE),\
    \ pp. 1097–1106. IEEE, New York, NY, USA \n(2018). https ://doi.org/10.1109/Trust\
    \ Com/BigDa taSE.2018.00153 \n. https ://ieeex plore .ieee.org/docum ent/84560\
    \ 22/\nZanella, A., Bui, N., Castellani, A., Vangelista, L., Zorzi, M.: Internet\
    \ \nof Things for Smart Cities. IEEE Internet Things J. 1(1), 22–32 \n(2014).\
    \ https ://doi.org/10.1109/JIOT.2014.23063 28. Conference \nName: IEEE Internet\
    \ of Things Journal\nZhu, J., Collette, M.: A dynamic discretization method for\
    \ reliability infer-\nence in Dynamic Bayesian Networks. Reliab. Eng. Syst. Saf.\
    \ 138, \n242–252 (2015) https ://doi.org/10.1016/j.ress.2015.01.017. http://\n\
    www.scien cedir ect.com/scien ce/artic le/pii/S0951 83201 50002 77\nZorbas, N.,\
    \ Zissis, D., Tserpes, K., Anagnostopoulos, D.: Predicting \nObject Trajectories\
    \ from High-Speed Streaming Data. In: 2015 \nIEEE Trustcom/BigDataSE/ISPA, vol. 2,\
    \ pp. 229–234 (2015). \nhttps ://doi.org/10.1109/Trust com.2015.588\nNasr Kasrin\
    \ has had experience \nin both industry and academia. \nHe completed an Engineering\
    \ \ndegree with a focus on Computer \nScience from the German Uni-\nversity in\
    \ Cairo (GUC), Egypt in \n2008. He began his career work-\ning as a teaching assistant\
    \ and \nresearching in the cognitive sci-\nences and artificial intelligence.\
    \ \nAfter completing his masters \nproject and publishing two \npapers from it,\
    \ he moved on to \nwork in a medium-sized organi-\nzation that developed social\
    \ \nmedia applications, where he \nworked on product design as well as software\
    \ architecture. He later \nworked as a lecturer at The International University\
    \ of Technology \nTwintech (IUTT), Sana’a, Yemen. Since 2015 he has been employed\
    \ at \nthe Chair of Mobile Software Systems / Mobility at the University of \n\
    Bamberg, Germany, working in the area of data management. His cur-\nrent research\
    \ interest is in designing distributed models for dataset shar-\ning and exchange\
    \ across organizations. He adopts an information-based \napproach where datasets\
    \ are shared by sharing information about them.\nAboubakr Benabbas graduated \n\
    from the TU Ilmenau in 2014 \nwith a master’s degree. Since \n01.06.2014 he works\
    \ as a \nresearch assistant at the Chair of \nMobile Systems at the University\
    \ \nof Bamberg. He is currently \ndoing his doctorate at Uni-Bam-\nberg with the\
    \ research topic \n“Data quality in sensor-based \napplications” and is project\
    \ \nleader of Living-Lab Bamberg, a \nresearch environment for sensor \napplications.\
    \ Since 2015 he has \nalso been a course advisor for the \ndegree program “Master\
    \ Interna-\ntional Software Systems Science”.\n93\nData-sharing markets for integrating\
    \ IoT data processing functionalities \n1 3\nGolnaz Elmamooz Since June \n2016,\
    \ Golnaz Elmamooz has \nbeen a research assistant at the \nUniversity of Bamberg\
    \ at the \nChair of Computer Science, in \nparticular mobile systems. She \nreceived\
    \ her Masters in Com-\nputer Software Engineering from \nIslamic Azad University,\
    \ \nNajafabad, Iran in 2013. She \nworked on predicting type 2 dia-\nbetes using\
    \ Bayesian classifiers. \nHer research interests are learn-\ning from sensor-based\
    \ data and \nmanaging the Machine Learning \nmodels. It focuses on the con-\n\
    tinuous management of location-related data from sensors and other \nactive data\
    \ sources and their integration into so-called context-sensitive \napplications.\
    \ She is currently working on data stream and ML model \nmanagement technologies.\
    \ These technologies can be applied to the \nareas of smart cities and smart farming.\n\
    Daniela Nicklas Since 2014, Dan-\niela Nicklas is full professor at \nthe University\
    \ of Bamberg, Ger-\nmany, and holds the Chair of \nComputer Science, in particular\
    \ \nMobile Software Systems / \nMobility. Before that, she was a \njunior professor\
    \ for database and \ninternet technologies at the Uni-\nversität Oldenburg and\
    \ member \nof the Member of Executive \nBoard in the Transportation divi-\nsion\
    \ at the OFFIS institute for \ncomputer science. She came \nthere from a PostDoc\
    \ position at \nthe Universität Stuttgart (2006-\n2008) where she also obtained\
    \ her PhD in 2005, working on the inte-\ngration of large-scale spatial context\
    \ models for mobile applications. \nHer research interests are computer systems\
    \ that bridge the gap \nbetween the physical world and the digital world. She\
    \ focuses on the \ncontinuous management of data from sensors and other active\
    \ data \nsources and their incorporation in so-called context-aware applications.\
    \ \nCurrently, she works on data stream management technologies. She \napplies\
    \ these technologies to the domains of smart cities, smart facto-\nries, pervasive\
    \ computing, intelligent transportation systems, and situ-\national awareness\
    \ in general. In 2009, she received the IBM Explora-\ntory Stream Analytics Innovation\
    \ \"Award for Data Stream Technology \nfor Future Energy Grid Control\". She is\
    \ a member of many programme \ncommittees and organizing committees of pervasive\
    \ computing and \ndatabase conferences and workshops (e.g., PerCom, MDM, BTW,\
    \ ...), \nand of IEEE, ACM, and the German Gesellschaft für Informatik (GI).\n\
    Simon Steuer Since August 2016 \nhe is working in the University \nBamberg. Currently\
    \ he is chang-\ning his reasearch directions from \nlocation privacy in data streams\
    \ \nto hybrid location models in \nsmart agriculture.\nMichael Sünkel completed\
    \ his \nmaster’s degree in applied com-\nputer science at the University of \n\
    Bamberg in 2017. Until 2018 he \ntaught as an external lecturer for \nthe chair\
    \ for foundations of com-\nputer science. Since 12.03.2018 \nhe has been working\
    \ as a \nresearch assistant at the chair of \nmobile systems. There he is \ninvolved\
    \ in the research network \nFutureIOT with the research \nfocus on data management\
    \ for \nsensor-based applications and \ndistributed data stream \nmanagement.\n"
  inline_citation: '>'
  journal: CCF Transactions on Pervasive Computing and Interaction
  limitations: '>'
  pdf_link: https://link.springer.com/content/pdf/10.1007/s42486-020-00054-y.pdf
  publication_year: 2021
  relevance_score1: 0
  relevance_score2: 0
  title: Data-sharing markets for integrating IoT data processing functionalities
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1145/3603707
  analysis: '>'
  authors:
  - Hadi Fadlallah
  - Rima Kilany
  - Houssein Dhayne
  - Rebecca Haddad
  - Rafiqul Haque
  - Yéhia Taher
  - Ali Jaber
  citation_count: 1
  full_citation: '>'
  full_text: '>

    This website uses cookies We occasionally run membership recruitment campaigns
    on social media channels and use cookies to track post-clicks. We also share information
    about your use of our site with our social media, advertising and analytics partners
    who may combine it with other information that you’ve provided to them or that
    they’ve collected from your use of their services. Use the check boxes below to
    choose the types of cookies you consent to have stored on your device. Use necessary
    cookies only Allow selected cookies Allow all cookies Necessary Preferences Statistics
    Marketing Show details       skip to main content University of Nebraska Lincoln
    Browse About Sign in Register Journals Magazines Proceedings Books SIGs Conferences
    People Search ACM Digital Library Advanced Search Journal Home Just Accepted Latest
    Issue Archive Authors Editors Reviewers About Contact Us HomeACM JournalsJournal
    of Data and Information QualityVol. 15, No. 3Context-aware Big Data Quality Assessment:
    A Scoping Review SURVEY SHARE ON Context-aware Big Data Quality Assessment: A
    Scoping Review Authors: Hadi Fadlallah , Rima Kilany , Houssein Dhayne , + 4 Authors
    Info & Claims Journal of Data and Information QualityVolume 15Issue 3Article No.:
    25pp 1–33https://doi.org/10.1145/3603707 Published:22 August 2023Publication History
    0 citation 567 Downloads eReaderPDF Journal of Data and Information Quality Volume
    15, Issue 3 Previous Next Abstract 1 INTRODUCTION 2 RESEARCH METHODOLOGY 3 BACKGROUND
    4 SCOPING REVIEW RESULTS 5 DISCUSSION 6 DATA QUALITY ASSESSMENT ARCHITECTURE –
    A PROPOSAL FOR A METHODOLOGICAL FRAMEWORK 7 OPEN CHALLENGES 8 CONCLUSION AND FUTURE
    WORK Footnotes REFERENCES Index Terms Recommendations Comments Skip Abstract Section
    Abstract The term data quality refers to measuring the fitness of data regarding
    the intended usage. Poor data quality leads to inadequate, inconsistent, and erroneous
    decisions that could escalate the computational cost, cause a decline in profits,
    and cause customer churn. Thus, data quality is crucial for researchers and industry
    practitioners. Different factors drive the assessment of data quality. Data context
    is deemed one of the key factors due to the contextual diversity of real-world
    use cases of various entities such as people and organizations. Data used in a
    specific context (e.g., an organization policy) may need to be more efficacious
    for another context. Hence, implementing a data quality assessment solution in
    different contexts is challenging. Traditional technologies for data quality assessment
    reached the pinnacle of maturity. Existing solutions can solve most of the quality
    issues. The data context in these solutions is defined as validation rules applied
    within the ETL (extract, transform, load) process, i.e., the data warehousing
    process. In contrast to traditional data quality management, it is impossible
    to specify all the data semantics beforehand for big data. We need context-aware
    data quality rules to detect semantic errors in a massive amount of heterogeneous
    data generated at high speed. While many researchers tackle the quality issues
    of big data, they define the data context from a specific standpoint. Although
    data quality is a longstanding research issue in academia and industries, it remains
    an open issue, especially with the advent of big data, which has fostered the
    challenge of data quality assessment more than ever. This article provides a scoping
    review to study the existing context-aware data quality assessment solutions,
    starting with the existing big data quality solutions in general and then covering
    context-aware solutions. The strength and weaknesses of such solutions are outlined
    and discussed. The survey showed that none of the existing data quality assessment
    solutions could guarantee context awareness with the ability to handle big data.
    Notably, each solution dealt only with a partial view of the context. We compared
    the existing quality models and solutions to reach a comprehensive view covering
    the aspects of context awareness when assessing data quality. This led us to a
    set of recommendations framed in a methodological framework shaping the design
    and implementation of any context-aware data quality service for big data. Open
    challenges are then identified and discussed. Skip 1INTRODUCTION Section 1 INTRODUCTION
    Data quality is the measure of how much data can fit its intended use [124]. Assessing
    data quality levels is critically important to choose whether or not to use the
    data to make more accurate decisions. Since the decision-making process relies
    mainly on data, measuring data quality based on its intended use is a sine qua
    non. Strong et al. [124] have categorized data quality factors into four categories:
    (1) Intrinsic: The quality factors independent of the context of use, such as
    accuracy, believability, objectivity, and reputation. (2) Contextual: The elements,
    such as completeness and timeliness, that reflect how much data is helpful within
    a specific context. (3) Representational: The factors that show the presentation
    quality for the consumers, such as ease of understanding. (4) Accessibility: The
    factors that reflect if consumers can access the data when needed. Wang et al.
    [134] differentiated information from data and described the information as data
    that has been processed in some manner. Then, Pipino et al. [112] developed the
    concepts, principles, and procedures for defining, measuring, analyzing, and improving
    information products called Total Data Quality Management (TDQM). In addition
    to standard data quality, a more refined approach called context-aware data quality
    was introduced. The term “context” is subjective and can be related to the data
    life cycle phase (ingestion, processing, analysis), the data types, the domain
    of data, organizational policy, decision-making policy, the time range within
    which the analysis is done, the security level, or the available resources. In
    ISO/IEC 9126-1 [71] and ISO/IEC 25000 [73] standards, contextual data quality
    is defined from a generic standpoint, which is the following: the quality-in-use
    level. Quality-in-use considers the information as the subject and reflects the
    quality level when data is used in real conditions by including the execution
    environment, decision-making policies, permissions, and every quality characteristic
    related to the context in the assessment operation. Wang et al. [135] described
    the main quality factors reflecting this category: (1) Added value: determines
    the amount of data that gives a competitive edge and adds value to operations.
    (2) Relevancy: determines how much information is applicable, relevant, valuable,
    and usable. (3) Timeliness: determines the age of data. (4) Completeness: determines
    the breadth, depth, and scope of the information contained in the data. (5) The
    appropriate amount of data: determines the amount of data that is suitable for
    the task. Merino et al. [96] identified other contextual characteristics such
    as accuracy, consistency, credibility, compliance, confidentiality, and understandability.
    Additionally, Ge et al. [53] categorized the data quality problems between context-independent
    and context-dependent, and Woodall et al. [138] further extended this categorization.
    In this research, we heavily focus on how a data quality assessment method can
    be developed to adapt flexibly to different contexts. Typically, the properties
    of context are diverse; therefore, data quality assessment solutions must have
    the ability to be used within any context and to take into consideration all related
    conditions. Considering this critical factor, we define context awareness as follows:
    It is the ability of data quality solutions to evaluate the quality of data considering
    the generic properties of context, which enables the solutions to be used in any
    context. The data quality solutions must check whether the data properties are
    suitable with related policies and available resources in addition to the contextual
    factors. Data quality assessment is less challenging in traditional technologies
    such as data warehouses. The data model follows the relational schema principles,
    data size is reasonable, and the data is at rest. Leading companies such as Microsoft
    [30, 31], Oracle [32], Informatica [69], and Talend [130] offer many tools and
    frameworks that can be used to develop and administer ETL jobs and address the
    majority of data quality issues. However, these technologies limitations are three-fold:
    (i) the ability to adapt to different contexts, (ii) the generalization of data
    quality assessment methods remains an issue, and (iii) these technologies confront
    challenges when handling large datasets with high variety, and generated at high
    speed. More explicitly, traditional technologies still need to be appropriately
    used for non-relational massive data [94], such as processing wireless sensor
    feeds in real-time [6]. The operational limitation of traditional technologies
    can be tackled using highly advanced processing resources and distributed technologies
    such as distributed file systems (e.g., HDFS) developed over the past decade.
    However, these technologies do not address quality assessment standardization;
    instead, the quality issues are handled using different heuristics [118]. The
    quality assessment approaches need yet to reach a level of maturity that the industries
    would accept [104]. In short, quality assessment techniques within the big data
    domain remain an open research issue [11]. Furthermore, context-aware quality
    assessment is a critical concern, since any meaningless quality dimension measurement
    would consume time and resources and cannot yet be dealt with by state-of-the-art
    big data technologies. A context-aware quality assessment solution for assessing
    the quality attributes of big data is strongly required. The properties of the
    context should be generic for the solution to be used/adopted in any context.
    Such a data quality assessment solution would greatly help extract value-added
    intelligence from data that the industry is currently seeking. These requirements
    give rise to the following research questions: What are the challenges of building
    a context-aware big data quality assessment framework? What are the requirements
    for building such a framework? We conducted a deep and wide survey to answer these
    questions. This scoping review article presents our survey results on context-aware
    big data quality solutions. Only generally applicable solutions not related to
    a specific domain were selected in this survey. The strength and weaknesses of
    existing solutions are outlined comprehensively and discussed intensively. Moreover,
    we presented a sketch of a solution that could address the limitations of existing
    solutions. Finally, we identified the open challenges for building such a solution.
    The rest of this article is organized as follows: Section 2 describes our research
    methodology. Section 3 defines the main terms and concepts used in this work.
    Section 4 provides a literature review of the recent research about context-aware
    data quality and big data quality. Section 5 highlights the significant results
    and elements that should be considered in future research. Section 6 describes
    a methodological framework for a context-aware big data quality assessment solution
    based on the literature investigation. Section 7 lists the open challenges. Section
    8 concludes this work. Skip 2RESEARCH METHODOLOGY Section 2 RESEARCH METHODOLOGY
    Since our research aims to study the need for a context-aware big data quality
    assessment solution, as well as the challenges of building such a solution, two
    topics were covered by our research: (1) Assessing the data quality in the domain
    of big data. (2) Achieving context awareness while assessing data quality. We
    tried to answer five general research questions that are essential for building
    a context-aware big data quality assessment solution: What does a data quality
    assessment solution require to handle big data? How is data context defined in
    the existing data quality assessment solutions? How is context-aware data quality
    different in big data compared to traditional context-aware data quality? What
    key components/methods are used to achieve context awareness during data quality
    assessment? What are the main limitations and open challenges when building a
    context-aware data quality assessment solution that handles big data? To our knowledge,
    no surveys about context-aware big data quality assessment methods have been published.
    To bridge this research gap, in this article, we studied the existing data quality
    assessment solutions that consider the context or are designed for big data. Then,
    we tried to link both concepts to derive the main recommendations for building
    a context-aware big data quality assessment solution. Following Munn et al. [100]
    guidance when choosing between a systematic or scoping review approach, researchers
    should conduct a scoping review when they try to scope a body of literature, identify
    knowledge gaps, and clarify the key concepts. Thus, we found a scoping review
    more suitable than a systematic review, since—to our knowledge—no surveys about
    context-aware big data quality assessment methods have been published to date.
    We aimed in this survey to fill this research gap by studying the existing data
    quality assessment solutions that consider the context and/or are designed for
    big data. Then, we tried to link both concepts to derive the main recommendations
    for building a context-aware big data quality assessment solution. Our research
    started by searching for the following keywords: “context data quality”, “contextual
    data quality”, “context-aware quality”, “big data quality”, “data lake quality”,
    “context-aware big data quality”, “context-aware information quality”, “data quality
    in use” over the following scholarly literature indexes: Google Scholar,1 IEEE
    Xplore,2 and DBLP3 in addition to using the Mendeley search engine4 and the ResearchGate5
    social network. The first research phase resulted in more than a hundred articles.
    To select only the articles that are within our research scope, we defined two
    selection criteria: (1) The generally applicable big data quality assessment solutions
    that focus on handling the big data characteristics while assessing the data quality
    and excluding those related to a specific domain (for example, we excluded the
    healthcare quality assessment solutions). (2) The data quality assessment solutions
    where the data context is defined and considered. Since this was only a scoping
    review, no limits were placed on the publication date or research methodology.
    After filtering the search results based on the selection criteria, we identified
    three highly cited articles6 that are considered a primary reference for most
    contextual data quality research: “Data Quality in Context” (1,964 citations)
    [124], “Beyond Accuracy: What Data Quality Means to Data Consumers” (5,852 citations)
    [135], “A Product Perspective on Total Data Quality Management” (1,403 citations)
    [134]. Then, we searched over the citing articles. As a result, our scoping review
    covered 27 articles (Table 1) published between 2005 and 2021 (Figure 1); 18 were
    about context-aware data quality assessment, and 9 were about big data quality
    assessment where the data context was not considered. Fig. 1. Fig. 1. Articles
    distribution over the years. Table 1. Reference Year Citations Handling big data
    context awareness Even et al. [46] 2005 52 X Even et al. [47] 2007 159 X Helfert
    et al. [62] 2009 24 X Show More Table 1. Classification of the Publications Discussed
    in This Review Limitations and strengths A wide range of information was collected,
    analyzed, and fruitfully combined into a methodological framework offering an
    integrated context-aware big data quality solution. However, this scoping review
    started by searching for specific keywords, which may have resulted in unintentionally
    discarding some relevant research. Moreover, we intentionally excluded domain-specific
    big data quality assessment solutions, since our ultimate goal was to propose
    a framework that is general enough to be used in any domain. Skip 3BACKGROUND
    Section 3 BACKGROUND This section lays out the background of the concepts covered
    by our research. It provides a conceptual description of data quality assessment
    and big data quality. 3.1 Data Quality Ensuring data quality requires assessment
    and improvement techniques to be implemented during any phase of the data life
    cycle. Each stage may have different quality requirements. For example, data credibility
    may be optional while ingesting data from social media. In contrast, it is critical
    in the analysis phase. The data quality level is calculated based on several quality
    characteristics defining the data’s quality aspects, such as the accuracy and
    completeness level [72]. These characteristics are measured through specific measurement
    methods. The quality measurement methods are implemented using quality assessment
    techniques in the real data environment. Data quality techniques can generally
    be informative (assessment) or operational (improvement). Below, we explain these
    techniques. Data quality assessment techniques. Various techniques can be used
    to assess data quality. These techniques can be grouped into two categories: (1)
    objective techniques that measure the data quality based on the data characteristics
    and (2) subjective that ask the data consumer to rate the data quality [27]. An
    objective measurement is mainly done using the following techniques: Data quality
    models: Each data quality model is composed of several data quality dimensions
    measured using several quality metrics [53, 96, 124, 135, 138]. Data profiling:
    This technique collects statistics or informative summaries about data (e.g.,
    the percentage of null values within a dataset and the number of duplicates).
    It is used before and after storing data [7, 89, 97, 105, 129]. Data provenance:
    This technique describes the origin and history of the data [23, 111]. Data integration:
    It is the process of integrating a dataset with other knowledge bases or data
    from credible sources to assess the accuracy and consistency of the data [26,
    137]. As for the subjective measurement of data quality, it is done using one
    of the following techniques: Crowdsourcing: This technique engages a crowd to
    achieve a common goal. It is one of the techniques used to assess the quality
    of specific information. Mainly, this technique is used for unstructured data
    (text, videos, images...) [3, 50, 65, 87, 140]. Survey and questionnaires: Data
    consumers should rate the data quality after using it [113]. Data quality improvement
    techniques. Researchers have proposed a wide variety of techniques to improve
    data quality. Below is the list of the techniques we found in the literature.
    Data cleansing: Detecting and fixing inaccurate and erroneous values within records
    [85, 114]. Data enrichment: This technique adds additional information to the
    current data records from other external sources or uses advanced statistical
    techniques [8, 82]. Data fusion: It integrates related data from different sources
    to reject non-credible, inaccurate, and inconsistent data [40]. Data deduplication:
    It is the process of removing data records that store the same information [60,
    93]. Machine learning-guided cleaning: Classifying duplicate pairs in deduplication,
    estimating the most likely value for a missing value, predicting a transformation,
    or classifying values as normal or outliers [66]. 3.2 Big Data Quality Big data
    quality is critical to performing effective analysis and extracting meaningful
    insights [37]. As mentioned earlier, the traditional data quality assessment and
    improvement techniques must be improved to meet big data requirements. Until today,
    big data quality is still an open research issue. Batini et al. [11] showed the
    importance of data quality assessment when handling big data. They described the
    emerging challenges, such as handling a wide variety of data types, data generated
    at high speed, massive amounts of data analyzing maps, linked open data, and wireless
    sensors. Moreover, they described how the data sources and quality characteristics
    have evolved, leading to these new challenges. Saha et al. [118] provided an overview
    of the existing traditional data quality tools, then described the process of
    discovering and learning data quality semantics and repairing inconsistency at
    various stages in the big data domain. Clarke et al. [28] considered data accuracy,
    precision, timeliness (temporal applicability, Up-to-Dateness, Currency), and
    completeness as the main big data quality factors. They also described the primary
    quality assurance processes applicable in all data stages. Clarke et al. [28]
    also described the quality factors needed in the decision-making process as the
    data relevance, the data meaning, and the transparency of the decision-making
    process. While studying the quality assurance techniques for big data applications,
    Zhang et al. [141] considered data accuracy, scalability, correctness, consistency,
    and security as the main factors for big data quality assessment. Gao et al. [52]
    described the leading big data quality assurance parameters as data accuracy,
    currency, timeliness, correctness, consistency, usability, security, privacy,
    completeness, accessibility, accountability, and scalability. Then, they classified
    the data quality issues between (1) enterprise management issues (organization
    management issue, big data management issue, data quality assurance issue) and
    (2) big data processing and services issues (data collection issue, data conversion
    issue, data service scalability issue, data transformation issue). They demonstrated
    that poor data quality might lead to (1) higher costs for enterprises and businesses,
    (2) inefficient service operations, (3) as well as it may reduce business revenues
    and (4) affect the accuracy of the data analysis. They mentioned that data validation
    must be implemented within data collection, cleaning, transformation, loading,
    aggregation, and analysis operations to guarantee high quality. Finally, they
    described the main challenges facing organizations regarding data quality assurance
    in the context of big data as (1) the lack of awareness and a good understanding
    of big data quality assurance and validation, (2) the lack of well-defined enterprise-oriented
    big data assurance standards, (3) the lack of available research results on big
    data quality models and evaluation metrics, and (4) the lack of well-established
    big data certification program and standards. Big data quality and machine learning.
    Big data quality is crucial for many other computer science fields, such as data
    analytics and machine learning. The use of machine learning often requires big
    data. Machine learning algorithms face several challenges that arise from the
    big data Vs.: Volume, Velocity, Veracity...[133]. A wide variety of data sources
    and collection methods can result in noisy and uncertain data [139] that highly
    affect the learning process and result in inaccurate models. It is impossible
    for several machine learning algorithms, particularly deep learning algorithms,
    to achieve their full potential without large, well-maintained training sets [143].
    L’Heureux et al. [92] stated that handling dirty and noisy data is one of the
    main challenges that face machine learning algorithms in a big data context. They
    also stated that it is difficult for a machine learning algorithm to learn from
    data that lacks objectivity or absolute truth, such as social media posts or crowdsourcing.
    Zhou et al. [143] recommended developing algorithms that can assess the trustworthiness
    or credibility of data or data sources to handle data veracity challenges when
    training machine learning models using big data so unreliable or contradictory
    data are filtered during pre-processing. Gudivada et al. [55, 56] considered big
    data and machine learning applications’ main challenge as developing an automated
    tool to resolve data quality issues such as streaming data, disparate data types,
    and integration difficulties. However, machine learning techniques are useful
    while handling big data quality. Four areas could be identified under the umbrella
    of data quality that machine learning helps to address [66, 68]: Handling missing
    values within the data. Assessing the data source relevance to a specific domain
    without user intervention. Anomaly detection: In a data pool, machine learning
    programs can detect patterns, associations, and rare occurrences. Data deduplication:
    Machine learning techniques can be more efficient in handling inconsistent data,
    stale data, or data with typos. Dai et al. [34] proposed a solution that detects
    erroneous data using deep learning and outlier detection techniques to improve
    big data quality. Skip 4SCOPING REVIEW RESULTS Section 4 SCOPING REVIEW RESULTS
    Big data quality and context-aware data quality assessment have been discussed
    in a large body of literature. This article investigated the quality models and
    techniques used to assess data quality and achieve context awareness in the big
    data context. Moreover, since context-aware big data quality assessment is not
    widely addressed, our study was extended to include valuable research on big data
    quality. We categorized our review as follows: (1) Big data quality assessment:
    covers the solutions designed to handle big data without considering the context.
    (2) Context-aware data quality assessment frameworks: covers the data quality
    assessment frameworks that consider the context. (3) Context modeling: covers
    the existing approaches for expressing and modeling the context during data quality
    assessment. We start with an overview of the reviewed literature and summarize
    the works we studied in Table 2. Existing solutions are compared based on three
    main aspects: (1) the data source types they can handle, (2) how they guarantee
    context awareness, and (3) how they handle big data. Moreover, we highlighted
    the solutions’ strengths and weaknesses to derive essential recommendations. Then,
    each solution is discussed separately, focusing on providing more technical details.
    Table 2. Solution Data Type Context Awareness Big data Strengths Weakness Batini
    et al. [25] Structured, semi-structured, unstructured Data context is defined
    based on the data sources, conceptual entities, and organizational units Knowledge
    extraction techniques to extract the schema from unstructured data Handling unstructured
    data + using schema matching techniques Does not handle other big data characteristics
    such as streams and huge volume Bicevskis et al. [19] [18], Bicevska et al. [16]
    [17], Nikiforova et al. [107] [108] Structured, semi-structured Data object, domain-specific
    language Not mentioned Formal language + requirements written by end-user Tabular
    data + data at rest + experts must be involved Even et al. [46] [47] Structured
    Intrinsic numeric value based on the customer’s point of view Not for big data
    Convert context business rules into quantitative methods + treat data as its value
    from the user perspective Only for tabular data + limited context definition Show
    More Table 2. Literature Summarization 4.1 Big Data Quality Assessment Cai et
    al. [24] proposed a two-layer big data quality standard for assessing data quality.
    The first layer contains the data quality dimensions, and the second layer contains
    each of the characteristics of each dimension. Then, they defined the primary
    indicators used to evaluate each quality characteristic. After defining the data
    quality dimensions, characteristics, and indicators, they proposed a data quality
    assessment process for big data, having four phases: (1) preparation, (2) pre-processing
    and assessment, (3) evaluation and troubleshooting, and (4) the analysis phase.
    Preparation phase: This phase requires a clear understanding of the work, since
    data consumers should determine the goals of data collection, the data source
    types, volume, and other parameters. Then, they should select data quality elements
    (characteristics). For each quality element, assessment indicators should be specified.
    Finally, a quality evaluation baseline should be formulated. This phase can well
    define the project scope. Pre-processing and assessment phase: This phase starts
    with the data collection operation. After collecting data, data quality is improved
    by detecting and removing typing errors and inconsistencies (pre-processing/cleaning).
    After data cleaning, the data quality assessment is performed. Evaluation and
    troubleshooting phase: After quality assessment, the data quality levels are compared
    with the previous evaluation baseline; if it meets baseline standards, then a
    quality report is generated. Otherwise, iterative improvement is achieved by returning
    to the data collection step. Analysis phase: If results do not reach the goal
    after many attempts, then the data quality assessment baseline may not be reasonable.
    In this case, data mining and analysis techniques may improve the evaluation baseline
    to obtain results aligned with the goals. This proposal provides a systematic
    approach to studying, evaluating, and monitoring data quality, which is very efficient.
    Using quality indicators is a great added value, since it simplifies quality measurement.
    Moreover, using data mining and analysis techniques to improve the evaluation
    baseline increases the quality assessment’s context awareness level. However,
    the proposed process cannot handle big data, since it does not address unstructured
    data quality assessment, nor the data volume challenges. In addition, the solution
    requires high user intervention, which is not valid with high-velocity data. Dmitriyev
    et al. [38] proposed SOA-Enabled ELTA, a new approach for extract, load, and transform
    (ELT) operations to prepare business intelligence solutions for big data. SOA-Enabled
    ELTA is built using a service-oriented architecture to perform data transformations
    and validate data through defined business rules. This provides high-level business
    concept representation, which can be published and discovered in a distributed
    network and reused to build new (business) functions and applications. Still,
    it is unclear how data quality can be assessed, since only the data cleaning process
    is described. Moreover, handling unstructured data is not covered, meaning this
    solution does not address the big data variety challenge. Ramaswamy et al. [115]
    considered the data accuracy, error rate, frequency, availability, timeliness,
    validity, and trustworthiness to evaluate data quality within a federated sensors
    network. They proposed a cloud-based solution to host the domain application and
    a central data quality repository. They used markup language to describe sensor
    feeds containing actual data quality metadata, while historical data quality metadata
    was stored in an aggregated form for optimizing storage. Using a cloud-based solution
    gives the ability to efficiently handle big data, since it enables high scalability
    and gives the ability to perform stream and batch processing. Moreover, storing
    only aggregates of historical data quality measurements can avoid a high-speed
    growing data volume and decreases the needed resources. However, this solution
    is proposed specifically for wireless sensor feeds and cannot handle different
    types of data sources. Moreover, it lacks essential quality dimensions such as
    completeness and uniqueness. To assess social media data quality, Immonen et al.
    [67] considered data accuracy, believability, completeness, consistency, corroboration,
    coverage (amount of data), validity, popularity, relevancy, timeliness, and verifiability
    as the relevant characteristics for the quality model. To describe each quality
    characteristic, they adopted Niemelä et al.’s [106] proposal by considering a
    group of quality metrics to evaluate a quality attribute (characteristic). Each
    metric is defined by the description, purpose, target, applicability, formula,
    value range, acceptable value, and rule. One of the main weaknesses of this solution
    is that the data quality rules and decision-making policies should be manually
    specified for each data source, knowing that automating the assessment operation
    is essential in a big data environment. Besides, the solution is designed to assess
    data ingested from social media and does not support other data sources. To assess
    data quality, they proposed a metadata management extension implemented within
    a big data reference architecture proposed by Paakkonen et al. [109]. The extension
    will be used during all data life cycle phases. In the data extraction phase,
    the organizational policy facilitates the process by defining an acceptable data
    source, quality attributes, applicability time of the quality attribute, as well
    as metrics and methods to evaluate the quality. After extraction, the imported
    data is stored in a data storage. The quality metadata is created for the dataset,
    and the evaluated values for quality attributes are automatically inserted into
    the metadata repository. The organizational policy helps select datasets for processing/analysis
    purposes and helps to attach applicable quality attributes for metadata of datasets.
    The decision-making policy facilitates the selection of relevant data for decision-making
    purposes. When evaluating the significance of a dataset for a specific purpose,
    the decision-making policy helps to weigh the relevant quality attributes for
    the practical situation. One of the main advantages of this extension is implementing
    organizational and decision-making policies to meet the context requirements.
    Besides, it guarantees data provenance by storing metadata from all data life
    cycle phases. However, it does not systematically select relevant data quality
    characteristics. It requires a high user interaction, which is not preferred in
    a big data context. To assess and monitor data quality from the heterogeneous
    data source, Ehrlinger et al. [45] proposed a high-level architecture for a data
    quality assessment solution that is composed of four components: (1) Data profiling
    component, (2) data quality repository, (3) time-series analytics, and (4) user
    interface. This solution’s core is the data quality repository, which contains
    an ontological description of the assessed information system schema and a database
    that stores only the measurement of the data quality metrics commonly used and
    the ones related to the time-series analysis. The time series analysis is performed
    to detect temporal data outliers affecting data quality. This proposal is a high-level
    architecture where many features are not described clearly, such as how data sources
    are integrated with the ontological description found within the quality repository.
    Using this kind of repository is very beneficial to address data variety by linking
    data with a unified description. Later, Ehrlinger et al. proposed QuaIIe [43,
    44], an unsupervised data quality monitoring tool that allows continuous data
    quality verification. It uses data source connectors to read from structured data
    such as Oracle database and semi-structured data such as XML and comma-separated
    values. One of the main advantages of QuaIIE is that it performs ad hoc quality
    analysis on integrated data sources. In contrast, its main weakness is that it
    does not handle schema-less data and only supports equijoins operation to integrate
    multiple data sources. Gu et al. [54] proposed SparkDQ, a data quality management
    framework for Apache Spark,7 to improve the data quality in a big data environment.
    They implemented several flexible quality issues detection and repair algorithms
    to customize data detection and repair logic for specific needs. The main weakness
    of this framework is that it can handle only structured data and does not handle
    the format variety aspect in the big data context. Schelter et al. [119] proposed
    a declarative language that automates measuring large-scale data accuracy, consistency,
    and completeness using incremental data quality scoring and machine learning techniques
    to predict values and anomalies based on historical data. Still, the proposed
    solution lacks essential data quality dimensions, such as timeliness. Also, the
    logical operators are defined based on the author’s definition of each quality
    dimension, while these definitions may vary based on the data consumer perspective,
    meaning that this solution may not be implemented in a different context. 4.2
    Context-aware Data Quality Assessment Frameworks Batini et al. extended their
    previously proposed data quality solution for structured data to address the data
    heterogeneity issue [10] with the ability to assess data quality for unstructured
    and semi-structured data [25]. They proposed an entity-relationship “Meta-Model”
    to associate the needed data quality dimensions and the included conceptual entities
    with each data source used by organizational units. After defining the data context
    (data sources, conceptual entities, organizational units), information is extracted
    from the data to perform a data quality assessment. The extraction process is
    done using two techniques (1) reverse engineering and (2) schema mapping (with
    the Meta-Model). While this solution addresses the data variety challenge, it
    can only handle a small data volume. Bronselaer et al. [21] proposed an operational
    approach for data quality measurement where quality is assessed in terms of the
    cost of task completion using the data. Unlike the value-driven quality assessment,
    the operational approach considers the time and resources needed to complete the
    required task. At the same time, it ignores the intrinsic characteristics of the
    data, which means that a descriptive quality assessment must precede this type
    of assessment. Moreover, the authors assumed that data is finite, making this
    proposal unable to fit the big data requirements. To assess data quality, Helfert
    et al. [62] used the quality characteristics defined in Reference [135]. Then,
    they classified these characteristics based on semiotics layers (pragmatics, semantics,
    syntactic) and the quality aspects (quality of design and conformance) and defined
    the measurement approach for each group. To evaluate the context, the proposed
    framework requires an analysis of the information system environment before measuring
    quality dimensions. Depending on the specific context, we can select and prioritize
    different information quality dimensions by applying a metric such as Leung’s
    metric for importance, urgency, and cost [90]. In their proposed framework, the
    authors defined the data context as a combination of (1) the end-user requirements,
    (2) the application task, and (3) the information system environment. This framework
    guarantees high data consumer satisfaction, since its requirements are essential.
    Moreover, using a systematic approach to select the needed quality dimensions
    increases the framework’s robustness. However, this framework requires a high
    user interaction, which is not recommendable when handling massive data volumes.
    Organizational policies and available resources are not considered a part of the
    data context. Taleb et al. [127] classified the data quality characteristics into
    two categories: intrinsic and contextual. They proposed a quality framework for
    the data pre-processing phase. The framework is composed of four main components:
    (1) data quality profile selection, (2) adaptation, (3) data quality control,
    and (4) monitoring. First, the user should select a data quality profile containing
    all related pre-processing activities (cleansing algorithms and targeted data
    quality) based on the data domain, user-defined business rules, and auto-discovery
    techniques. The quality profile is sent as XML to the data quality profile execution
    component. After receiving the profile, the cleansing algorithm is distributed
    across the big data cluster nodes and executed over a data sample. When the data
    processing finishes, the quality controller components check whether the cleansed
    data meets the quality requirements. If so, then the cleansing algorithm is executed
    over the whole dataset. Two main factors make this framework very efficient while
    handling big data: using a MapReduce paradigm and performing data quality profiling
    over a data sample to check if it is acceptable. Although it is adaptable to different
    contexts, it only assesses the data quality during the pre-processing phase and
    does not consider the representational and accessibility quality dimensions. Merino
    et al. [96] proposed a data quality model based on ISO/IEC 25010, 25012 [72, 122],
    and 25024 [74] standards. They classified the ISO/IEC 25012 quality characteristics
    based on 3A’s model, an improved form of the quality categories used by Strong
    et al. [124]. They regrouped the categories as (1) contextual adequacy (contextual
    data quality), (2) operational adequacy (accessibility, representation, and intrinsic
    qualities), and (3) temporal adequacy (the authors separated it from the contextual
    category due to the growing significance of time analysis). They proposed a data
    quality-in-use framework grounded on the quality measures from ISO/IEC 25024 to
    calculate the level of fulfillment of the data quality characteristics (ISO/IEC
    25012). Accordingly, to measure the data quality-in-use level, first, (1) the
    data quality requirements delimited by the scope need to be established. Then,
    (2) the appropriate adequacy type must be selected in addition to identifying
    the relevant quality characteristics. (3) The user-defined business rules and
    the quality measures defined within the context should be gathered. (4) The quality
    measures are evaluated, and finally, (5) a quality report is generated. This framework’s
    main advantages are using ISO standards and the context awareness guaranteed by
    the user-defined business rules and quality measures. However, it fails to consider
    the velocity and variety characteristics of big data, since it cannot handle streams
    and unstructured data. Ardagna et al. [7] used accuracy, consistency, completeness,
    and timeliness as data quality characteristics and added precision, distinctness,
    volume, and trustworthiness to meet the big data quality requirements. The proposed
    framework’s main components are (1) the Data quality profiling module that provides
    metrics to measure and monitor the overall data quality such as the number of
    values, number of null values, number of distinct values, maximum, minimum, mean,
    and standard deviation. Furthermore, (2) the Assessment modules are in charge
    of computing data quality dimensions. Data profiling starts automatically after
    the data source is registered; the source analyzer detects the source metadata
    and the appropriate quality dimensions (based on data type and format) to be measured.
    Then, the data quality profiling module executes an initial profiling operation
    and stores the data profile within the quality metadata repository. Unlike data
    profiling, the data assessment phase is executed on-demand; the data quality service
    interface allows users/applications to access the data quality service, browse
    the data quality metadata repository, or set up the quality assessment operation.
    All configurations are saved to the custom settings repository and a configuration
    file. The data quality adapter uses the external configuration file to tune the
    result’s precision. Since data quality evaluation can be expensive on massive
    data, the adapter can select a subset to provide a faster evaluation but with
    lower precision. The main parameters of the data quality adapter are (CCT model):
    Confidence: the size of the sample dataset/size of the whole dataset Budget (cost):
    the number of computational nodes (resources available) Time: the estimated execution
    time. The user must select one of the following three scenarios: Confidence maximization
    = maximum cost + maximum time Cost minimization = minimum confidence + maximum
    time Time minimization = minimum confidence + maximum cost. Once the confidence
    level is selected, the data quality assessment is executed. This framework is
    built using a service-oriented architecture (SOA) paradigm, which ensures high
    interoperability. The data profiling module solves the context-dependent quality
    assessment issues. At the same time, adopting the CCT model allows the execution
    of the assessment operation on commodity machines with low resources. The three
    predefined scenarios can be very efficient in minimizing user interaction. Using
    knowledge repositories (settings, quality metadata) helps prevent repetitive operations
    and allows the framework to handle streams (low user interaction is required).
    However, this framework shows many weaknesses: Unlike the data quality assessment,
    data quality profiling is performed on the whole dataset, which may be time-consuming
    and may require more resources than available. Moreover, the selected scenario
    (CCT model) may be incompatible with the real environment (i.e., the user may
    select the confidence maximization scenario while having insufficient resources).
    Finally, this solution cannot integrate with reference data sources that may be
    needed to evaluate data consistency. Taleb et al. [128] listed and classified
    unstructured data sources based on their domain and types to assess data quality
    for unstructured big data. They specified six steps: (1) Knowing the data (type,
    format, domain). (2) Specifying the data quality dimensions to use. (3) Specifying
    the data quality metrics to consider. (4) Identifying the attributes to evaluate.
    (5) Choosing a sampling strategy. (6) Choosing a quality assessment methodology.
    These six steps were implemented within a data quality assessment model. Knowledge
    extraction and mining techniques were used to gather information required for
    quality assessment. The classification of the data sources based on the domain
    and types gives the model the ability to adapt to different contexts. However,
    this classification needs to be updated and evaluated periodically. Mylavarapu
    et al. [101] proposed a context-aware big data accuracy assessment tool based
    on a collection of datasets already stored in the data lake. The quality assessment
    is done in three phases: training, record linkage, and accuracy assessment. The
    idea is to use word embeddings and record linkage techniques to identify the most
    accurate reference data, which will serve as a basis for the accuracy assessment
    process of the input dataset. For the same purpose, Talha et al. [131] distinguished
    between intrinsic and contextual data accuracy and proposed a method to select
    a reference dataset from a data lake to assess the contextual accuracy of input
    data. They defined several accuracy criteria to select the appropriate reference
    dataset. The proposed solution first collects several datasets from different
    providers and assigns a value for each dataset for each accuracy criterion; it
    uses schema-matching techniques to map between the input data and the selected
    datasets. Then, it uses record linkage and data sampling techniques to match records
    and filter the datasets that do not match the input dataset before assessing the
    data quality. Mylavarapu et al. [102] proposed another solution to assess information
    consistency based on its context. The proposed solution uses feature selection
    algorithms to extract the context information from a data record, then perform
    a record linkage to match it with existing datasets within a data lake to perform
    a consistency check. These assumptions can be correct if it is guaranteed that
    the data in the lake are correct and up to date, which is generally not the case.
    Moreover, the input data may even be of better quality. Besides, these solutions
    focus on only one quality dimension: data accuracy or consistency, while other
    essential dimensions should also be considered in a big data context. 4.3 Context
    Modeling 4.3.1 Expressing Context as Objects. To make data quality requirements
    executable, Bicevskis et al. [18] proposed a data quality model composed of three
    components: (1) data object, (2) quality requirements, and (3) quality evaluation
    process. Then, they divided data quality requirements into two categories: (1)
    syntactic (the quality of the data object itself) and (2) semantic (contextual).
    Two types of semantic quality control were considered: (1) contextual control
    on interrelated data to ensure the quality of the interconnected data objects
    and (2) contextual control on the entire dataset. The quality requirements are
    expressed in diagrams using a domain-specific language and then converted to executable
    tasks by IT and domain experts. They implemented their work using DIMOD, a derivative
    of the graphical tool-building platform GrTp [9]. This work was extended and demonstrated
    by Bicevska et al. [16, 17], where semantic quality control is divided into three
    categories: (1) contextual quality control of interrelated data, (2) contextual
    quality control over the data within a database, (3) contextual control over data
    stored within several databases/systems. This notion was extended in Reference
    [19], where the authors focused on how to design the informal model for the quality
    requirements (platform-independent model of the individual data object) and the
    executable task created by programmers from this informal model (platform-specific
    model for individual data object). Later, Nikiforova et al. [107, 108] extended
    this research by expressing the data context as separate data objects that are
    connected to the primary data object (the data for which we need to evaluate quality).
    The quality requirements of the primary data object are defined based on the secondary
    related objects. While this model-driven data quality assessment is efficient,
    since requirements are expressed in a formal language by the end-users, it cannot
    be implemented in the big data context, since it only applies to simple tabular
    data at rest. Also, it requires IT and domain experts to be involved in converting
    formal language into executable tasks. 4.3.2 Expressing Context Quantitatively.
    Even et al. [46, 47] proposed a contextual quantitative data quality assessment
    for tabular datasets from the perspective of data utility (value). The authors
    proposed a measurement method to assign an intrinsic numeric value for each record/dataset
    based on the customer’s point of view. Then, they used this intrinsic value to
    measure the data quality dimensions such as data completeness, currency, validity,
    and accuracy. They also defined four principles to ensure the consistency of the
    measurement methods, which are (1) interpretation consistency, (2) representation
    consistency, (3) aggregation consistency, and (4) impartial contextual consistency.
    The proposed approach is beneficial for data quality assessment research, since
    it can convert the context business rules into quantitative methods and use their
    values by statistical analysis or machine learning algorithms. Moreover, it treats
    data based on its value from the user’s perspective. However, it can only be used
    in tabular data and does not fit the big data quality requirements. Moreover,
    this approach does not consider all context characteristics, such as available
    system resources and time. Skip 5DISCUSSION Section 5 DISCUSSION After going through
    the literature, it was noticeable that each solution dealt only with a partial
    view of the context. In this section, we compare these quality models and solutions
    to reach a comprehensive view covering the whole aspects of context awareness
    when assessing data quality. This analysis has led us to some essential recommendations
    we compiled into a methodological framework we propose and describe at the end
    of this article. 5.1 Quality Models In Table 3, we summarize the classification
    approaches, as specified for each data quality model in the literature, to understand
    its purpose and scope of use. The table’s term “No classification” means that
    the author did not adopt any data quality characteristic classification. Table
    3. Quality Model Classification Approach Bicevskis et al. [18, 19], Bicevska et
    al. [16, 17], Nikiforova et al. [107, 108] Classified as Intrinsic, Contextual
    Strong et al. [124], Wang et al. [135] Classified as intrinsic, contextual, representational
    or accessibility Helfert et al. [62] Classified as quality of design or quality
    of conformance based onsemiotics level Show More Table 3. Classification Approaches
    Used in Data Quality Models After looking through all data quality characteristics
    listed in (Table 4), we can see that the ISO/IEC 25012 standard data quality characteristics
    do not fit the big data requirements (data uniqueness, amount of data) and thus
    need to be extended. Context-related features such as data fitness also need to
    be added to measure to what degree the data fits the context needs. It is also
    worth noting that many context-specific quality characteristics related to ingesting
    data from wireless sensors are missing, i.e., error rate and frequency [115].
    This means that even when considering the adoption of ISO standards for big data
    quality assessment, there is a need to define additional context-specific quality
    characteristics. Table 4. Data Quality Characteristic Helfert el al. [62] Taleb
    et al. [127] Merino et al. [96] Arad-agna et al. [7] Cai et al. [24] Ramas-wamy
    et al. [115] Anne Immonen et al. [67] Batini et al. [25] Schelter et al. [119]
    Ehrlinger et al. [44] ISO/IEC 25012 [122] Accuracy X X X X X X X X X X X Completeness
    X X X X X X X X X Consistency X X X X X X X X Show More Table 4. Data Quality
    Characteristics Used in the Literature From this summary, we drew the following
    conclusions and decided that the representational and accessibility categories
    defined in References [24, 124, 135] should be considered in the context of use.
    Second, we found no need to separate the temporal characteristics from the contextual
    category [96], since temporal factors are context-dependent. At another level,
    it was clear that the ISO/IEC 25012 classification standard could meet the needed
    context awareness requirements, since inherent characteristics can be considered
    intrinsic data quality characteristics and system-dependent ones as context-related
    characteristics. In addition, we can use the semiotics classification to define
    and classify the measurement methods of the quality characteristics [62] that
    are not listed in the ISO/IEC 25012 standard, since the ones listed have their
    quality measures and measurement function defined in the ISO/IEC 25024 and ISO/IEC
    25021 standards. In fact, all of the characteristics listed in Table 4, which
    are not found in the ISO/IEC 25012 standard, cannot be considered inherent and
    are system-dependent due to the following reasons: Representational quality characteristic
    depends on the current task, organizational policies, and user needs [135]. Uniqueness
    [7], Amount of Data, and Added Value are classified as contextual data quality
    characteristics [124, 135]. Validity, Frequency, Verfiablity, Popularity, Error
    rate characteristics are related to the wireless sensors [115] and social media
    contexts [67] and measured based on reference data or task-oriented business rules.
    Minimality, Pertinence are used within an integrated information systems [44]
    context and require a reference data to be measured. 5.2 Achieving Context Awareness
    in Big Data Quality Assessment Based on the literature, we can define data context
    as the information about the data itself (e.g., metadata, source reputation),
    organization policies, domain business rules, and the available system resources
    to handle the data. Achieving context awareness in big data is very important
    when performing data quality assessment; each measurement/operation should be
    carefully selected and executed, because each operation will cost a reasonable
    amount of time and resources. An essential part of the data quality measurement
    is context-related [124]. Moreover, extracting the context information in a big
    data context is much more challenging. It cannot be achieved using the traditional
    data quality assessment methods, as it requires more intelligent techniques that
    can handle a wide variety of data formats. In addition, handling a massive amount
    of data generated at a high velocity requires a well-designed and automated quality
    assessment solution that relies on a scalable infrastructure. Regarding the existing
    solutions, we can summarize their main weaknesses as follows: They cannot handle
    huge data volumes [16, 17, 18, 19, 21, 24, 107, 108]. They cannot handle unstructured
    data [16, 17, 18, 19, 24, 38, 43, 44, 45, 46, 47, 54, 96, 107, 108]. The end-user
    manually implements quality rules [7, 16, 17, 18, 19, 107, 108]. They only assess
    the data quality at rest [7, 24, 62, 96, 101, 102, 109, 131]. It is hard to implement
    within different contexts [67, 115, 128]. They lack essential data quality dimensions
    for the big data context [67, 101, 102, 115, 119, 131]. They require high user
    intervention during the quality assessment operation [24, 62, 109]. The following
    are the recommendations a data quality assessment solution must consider to achieve
    context awareness in a big data setting: Service-oriented architecture (SOA) and
    microservices. Service-oriented architecture (SOA) is an enterprise-wide software
    design approach that allows loosely coupled services to communicate independently
    from operating systems, platforms, and languages [5, 35]. For example, Dmitriyev
    et al. [38] proposed a data-centric service to be consumed by different stakeholders
    using tools such as Weka8 and Pentaho BI9; thus, following the SOA approach allowed
    a wider range of tools to be used seamlessly for accessing the enterprise data.
    While Dmitriyev et al.’s [38] solution may be efficient as an enterprise solution,
    it may not be able to scale up once needed, since all components are tightly coupled.
    In contrast, Ardagna et al.’s [7] proposal guarantees higher scalability as the
    data quality service is separated from the data sources and the enterprise management
    system. Moreover, splitting the data quality solution into two separate modules
    (data profiling and data quality assessment service) allows each module to scale
    up separately once needed and increases the reusability and portability of the
    service components. This software development paradigm is known as Microservices,
    which is a must for building scalable [58] and distributed applications [41].
    Data sampling. Data sampling allows us to perform data profiling and quality assessment
    operations on a subset of the original dataset, which decreases resources and
    time consumption [7, 128]. Data sampling techniques can be based on probability;
    different statistical models are used to ensure no correlation between the points
    chosen for the sample. Alternatively, it could be extracted based on the analyst’s
    judgment [20]. Three solutions implemented data sampling techniques before the
    data quality assessment process: Taleb et al. [127, 128] used the Bag of Little
    Boostrap sampling algorithm to create a data sample that combines the results
    of bootstrapping multiple small subsets of a big dataset. In contrast, Ardagna
    et al. [7] implemented the Simple Random Sampling algorithm, where tuples are
    selected randomly, with an equal probability of being included in the sample.
    It is worth mentioning that choosing a big data sampling algorithm highly affects
    the data analysis and quality assessment process; the generated sample should
    be unbiased and representative of the original data, which is rarely guaranteed
    by Simple Random Sampling. In addition, the sampling algorithm must be easily
    parallelizable to be implemented in a parallel or distributed computing environment.
    Other optimized sampling methods for big data were proposed in the literature
    [29, 61, 86, 117]. Still, data sampling is a challenging topic in the domain of
    big data [103]. Using MapReduce-like paradigm. MapReduce is a parallel programming
    model presented by Google [36]. The MapReduce framework has attracted significant
    attention across a wide range of areas. It is considered a practical model for
    data-focused applications because of its basic programming interface, high elasticity,
    and resilience to defects. Additionally, it is well suited for preparing large
    data volumes in distributed computing environments. MapReduce has proven helpful
    in many different areas [42]. The accelerated growth in data size requires horizontal
    scaling, which is the ability to extend the data over additional servers [99].
    The support of a MapReduce-like paradigm allows the solution to handle streams
    and massive volumes of data by distributing tasks over multiple nodes [127], which
    meets the data scalability requirement. Currently, several distributed processing
    technologies with good stability are used. We can name, for example, Apache Spark10
    [54, 136] and Apache Storm11 [70, 123], among many others. Besides its stability,
    selecting the distributed processing technology depends on other factors, such
    as its ability to handle data at rest or data in motion. For example, the Hadoop
    MapReduce solution proposed by Taleb et al. [127] was used to assess the quality
    of data at rest, while the Apache Spark-based solution used by Gu et al. [54]
    and Ardagna et al. [7] was used to assess data quality for streaming data and
    data at rest. Cloud-based infrastructure. Big data is often collected by cloud-based
    applications [120]. A cloud-based infrastructure guarantees higher scalability
    of the solution. It enables adding storage and processing units when and as needed
    [115]. Due to its scalable nature, the cloud infrastructure is a good match for
    MapReduce processing paradigms; Ardagna et al. [7] created a data quality service
    that relies on Apache Spark cluster and deployed it on the Microsoft Azure cloud.
    Moreover, the Anything-as-a-Service (XaaS) model allowed providing a complete
    big data ecosystem as an on-demand service [126]. Still, managing and securing
    data on the cloud is an open challenge [80]. Metadata repository. As used in Reference
    [128], this repository is used to store all metadata extracted from schemaless
    datasets such as data structure [83, 142], recognized entities, context information
    [51, 125]. This metadata can be used in future operations to decrease redundancy
    while handling the same data sources. For example, in the case of handling data
    that is ingested continuously from wireless sensors, there is no need to extract
    the data structure for the data generated by the same sensors each time a quality
    assessment operation is needed; the structure will be retrieved directly from
    the metadata repository. Data quality repository. This repository is used to store
    the data quality score for each data source [43, 44, 45]; it is used to compute
    the data source reputation and prevent the execution of the quality evaluation
    process for data sources with a low reputation. A profile must be created for
    each data source where a history of data profiling and quality assessment results
    are stored. This will also allow performing incremental profiling and assessment
    operations [119] over continuously growing data sources (i.e., data ingested from
    sensors) rather than reading the whole data each time. This repository could be
    combined with the metadata repository proposed by Ardagna et al. [7], where data
    profiling and quality assessment results are stored to support any further data
    quality assessment task. Physical resources analysis. As we discussed the CCT
    model proposed in Reference [7], selecting predefined scenarios could be harmful,
    since the user selection may require an unavailable amount of system resources
    to perform the quality assessment operation. In contrast, a context-aware framework
    would scan the available system resources and estimate the needed time to assess
    the data quality for the input dataset. In addition, such a framework can also
    recommend an acceptable sampling ratio for optimal resource utilization and time-saving.
    We should note that although Helfert et al. [62] considered the information system
    environment as a part of the data context, they only considered the solution architecture
    and the data domain and ignored the available system resources. Data profiling.
    The data profiling service performs the exploratory data analysis to extract summaries
    that can be used in quality assessment operations, such as minimums, maximums,
    counts, averages, distinct values count, and null values percentages. The data
    profiling operations are essential to extract context information from the data,
    such as the data types, formats, and dates range. Metrics such as Null Values
    percentage are also essential to calculate quality dimensions such as Completeness.
    A critical concern about big data profiling is whether this operation should be
    executed before the data sampling task proposed by Ardagna et al. [7] or after
    data sampling as proposed by Taleb et al. [128]. After investigating the literature,
    we came up with a conclusion that two data profiling operations should be performed:
    A data profiling should retrieve the information needed to perform data sampling,
    such as the data size, lines/words count, and data format (media files, text files,
    tabular data). After the data sampling phase, data profiling should extract all
    information needed for the data quality assessment, since it is meaningless and
    resource-intensive to extract information from the initial data that is excluded
    from the quality assessment task. Several data profiling techniques were proposed
    in the domain of big data [2, 33, 91]. Still, data heterogeneity is an open challenge
    for data profiling techniques [1]. Automating data quality dimensions prioritization.
    As stated in Reference [62], using a systematic approach to prioritize data quality
    dimensions based on user needs and context is the key to building a context-aware
    solution. This is essential, since the data quality characteristics importance
    often changes based on the data context information and the user needs. The quality
    characteristics (dimensions) should be weighed automatically without user intervention.
    This step should be performed automatically after gathering all context information.
    This can be done using a knowledge database [98], machine learning techniques,
    or using a systematic approach [62]. ISO standards. Using ISO standards improves
    the compliance of our solution with universal standards and helps solve the plethora
    of data quality dimensions’ definitions found in the literature (Table 4). In
    fact, ISO standards are not just helpful regarding the data quality characteristics
    (dimensions) definitions [73]. Still, they also provide the metrics used to measure
    data quality as well as the measurement methods [75, 78] and functions [74]. While
    the ISO/IEC 25012 [72] standard does not support quality dimensions related to
    the big data domain, more guidance regarding the design, development, and management
    of big data applications are provided in ISO/IEC 20547 [76] standard. This standard
    is considered a big data reference architecture that illustrates the various big
    data components, processes, and systems in the context of an overall big data
    conceptual model. It also specifies the security and privacy aspects applicable
    to the big data reference architecture, including the big data roles, activities,
    and functional components. Also, it provides guidance on security and privacy
    operations for big data. Regarding data analytics and machine learning solution,
    ISO/IEC AWI 5259 [77], a new universal standard that describes the data quality
    measures, process, management requirements, and governance, is currently under
    development. Domain knowledge repositories. These repositories contain all business
    rules and organizational policies that are required in a specific domain [25].
    Rules and policies must be defined by domain experts and organization managers
    [98]. For example, data reputation is critical while handling social media feeds,
    while it is less important in other domains. Using these repositories will prevent
    users/developers from hard-coding business rules each time. A domain knowledge
    database can be created as an ontology [22, 98, 137], a database [10], or a knowledge
    graph [63]. Knowledge extraction techniques. As described in References [125,
    128], a set of techniques is used to extract metadata, hidden patterns, and context
    information from the data sources once needed, especially when handling unstructured
    data such as text or media files. As mentioned by Taleb et al. [128], the knowledge
    extraction techniques can be categorized into four categories based on the data
    source format (Table 5). Table 5. Data format Knowledge extraction technique Text
    Text mining, entity extraction Media files Features extraction: file metadata,
    extracting media characteristics Social media Sentiment analysis, opinion analysis,
    recommendation analysis Show More Table 5. Knowledge Extraction Techniques Based
    on the Data Format Context and quality rules abstraction. As defined in References
    [16, 17, 18, 19, 107, 108], using an object-oriented approach (data object class)
    to express data and context quality requirements will minimize the lines of code
    needed and allow the solution to be implemented easily within different contexts.
    Moreover, having a unified form to express data context and quality rules will
    help make the solution implementable in different contexts. Reference dataset
    election. Even though a reference dataset election may not be easily applicable,
    nor recommended when assessing the quality of critical data such as radiation
    pollution sensors feed [48, 49], it may still be recommended in certain cases.
    For example, References [101, 102, 131] stated that electing a reference dataset
    from the organization data lake could be helpful in case a reference dataset is
    required in the quality assessment process. A reference dataset and domain knowledge
    does not exist, and no other choices are available. This could be, for example,
    acceptable when analyzing a firm’s demographic and employment information as applied
    by Mylavarapu et al. [101]. Several string matching [64], schema matching [13,
    110, 121], and MapReduce-based data fusion solutions [39] were proposed in the
    literature and can be used when electing a reference dataset from a data lake.
    Still, this domain is considered an open challenge [81]. Skip 6DATA QUALITY ASSESSMENT
    ARCHITECTURE – A PROPOSAL FOR A METHODOLOGICAL FRAMEWORK Section 6 DATA QUALITY
    ASSESSMENT ARCHITECTURE – A PROPOSAL FOR A METHODOLOGICAL FRAMEWORK In this section,
    we propose a high-level methodological framework for a context-aware big data
    quality assessment solution covering all these essential properties and supporting
    all the above-detailed recommendations (Figure 2). The proposed architecture follows
    a Microservice-oriented paradigm, where each component is composed of one or multiple
    independent modules. The data quality assessment is done in six phases: (1) initial
    configuration, (2) source analysis, (3) data profiling and sampling, (4) metadata
    extraction, (5) context information gathering, and (6) quality evaluation. Fig.
    2. Fig. 2. Methodological framework architecture. 6.1 Initial Configuration Before
    starting the quality assessment process, several configurations must be done by
    the user: Sampling ratio: Users must define the data sampling ratio to apply within
    the data sampling method. Choosing the sampling ratio is critical, since it will
    impact the quality assessment confidence level (for example, if a sampling ratio
    is set to 70%, then the quality assessment score has a confidence level of 70%,
    since it was performed over 70% of the data). The sampling ratio will also determine
    the amount of data to be processed, affecting the resources and time needed to
    process the data. Maximum amount of allowed resources: Users can define the maximum
    amount of resources (processing nodes, memory utilization) to be used while processing
    the data. Specifying a maximum amount of resources will prevent the system from
    failing or getting out of memory. It will also be used to check if the available
    resources can meet the quality measurement requirements; if not, then the user
    will be asked to change the data sampling ratio. All these configurations are
    saved within a configuration file to prevent users from repeating the configuration
    and to automate the data quality assessment operation. Configurations can be assigned
    to a specific dataset or even set as default, regardless of the data source. 6.2
    Source Analyzer The Source Analyzer is a service that aims to: (1) Recognize the
    data type (structured, semi-structured, unstructured). (2) Select the most feasible
    data sampling method among several predefined methods based on the data type,
    available resources, and sampling ratio. (3) Perform a primary data profiling
    operation over the dataset to retrieve the information needed to perform data
    sampling, such as the data size, lines/words count, and data format (media files,
    text files, tabular data). (4) Select the most feasible data profiling method
    among several predefined methods based on the data type, available resources,
    and data sample size. After performing all these operations, the results are sent
    to the Data Profiling and Sampling component. 6.3 Data Profiling and Sampling
    This component comprises two services: (1) The Data Sampling Service and (2) the
    Data Profiling Service. First, the Data Sampling Service receives the data sampling
    ratio and the selected data sampling method from the Source Analyzer service.
    Then, it performs the data sampling operation. Data Sampling is performed to decrease
    computational expenses and help investigate a subset instead of the whole set.
    After data sampling is complete, the Data Profiling Service receives the selected
    data profiling method from the Source Analyzer and the data sample generated from
    the Data Sampling Service. Then, data profiling is performed over the data sample.
    The data profiling service performs the exploratory data analysis to extract summaries
    that can be used in quality assessment operations, such as minimums, maximums,
    counts, averages, distinct values count, and null values percentages. 6.4 Metadata
    Extraction After the data profiling and sampling phase, if the data is schema-less
    (unstructured), then the Knowledge Extraction Service provides a set of techniques
    to extract metadata from the data sources. The needed techniques are selected
    based on the data format as defined in Table 5. This metadata is stored within
    a repository to avoid repeating knowledge extraction operations on the same dataset
    and to be used for further analysis. In addition to analyzing unstructured data,
    the Knowledge Extraction Service uses several techniques such as Named Entity
    Recognition (NER) [51, 125] to extract the included entities and the data domain.
    6.5 Gathering Context Information After performing the data sampling, profiling,
    and metadata extraction, information is sent to the Context Analyzer Service to
    gather all information related to the data context. To define the data context,
    the Context Analyzer Service needs the following information: Metadata: All metadata
    gathered by the Source Analyzer service, Data Profiling Service, and the Knowledge
    Extraction Service such as the data type, format, data domain, and entities (i.e.,
    persons, organizations, places). Organizational policies: A set of business rules
    defined by the organization regarding the data. As an example, an organization
    can reject data from a specific date range. Domain-specific rules: Based on the
    suggested domain by the Knowledge Extraction Service, the Context Analyzer will
    gather all related rules from a domain knowledge repository (described in Section
    5.2). Available system resources: The available physical resources (machines,
    cores, memory, storage) in the information system besides the related configuration
    defined in the initial configuration. Quality characteristics: The ISO data quality
    standards are aligned with the domain knowledge database and gathered business
    rules to determine quality dimensions and metrics. After gathering all needed
    context information, the Context Analyzer Service generates a list of data quality
    characteristics and their measurement functions using a markup language such as
    XML or YAML and sends them to the Quality Evaluation component after assessing
    the available resources. Available resources analysis. The Context Analyzer Service
    should verify if the available physical resources are sufficient to handle the
    sampled data size in an acceptable time. If there are insufficient resources,
    then the users should be notified to change the data sampling ratio and the maximum
    amount of resources to be more relevant before assessing the data quality. If
    there are insufficient resources, then the data quality service will still use
    the results of the data sampling, profiling, and knowledge extraction operations,
    if possible, to prevent repeating redundant operations. For example, suppose the
    user can increase the maximum number of allowed resources without changing the
    sampling ratio. In that case, the data quality service can reuse the previously
    stored results besides the existing data sample to prevent repeating the data
    preparation operations (profiling, sampling...) and decrease the processing time.
    6.6 Quality Evaluation After receiving the data context details, the data quality
    characteristics should be prioritized using a systematic approach [62] based on
    the context requirements; the quality characteristics prioritization information
    is stored within the domain knowledge database. The service should then check
    the possible data quality measurements that can be performed on the data; for
    example, uniqueness is not measurable while handling texts. If the data quality
    measures require reference data, then the quality evaluation service checks if
    it already exists for this data source. If not, then a reference data election
    is run using schema matching and machine learning techniques [13, 39, 110, 121]
    to select the most appropriate dataset from the organizational data lake as described
    in References [101, 102, 131]. After identifying the measurable quality characteristics,
    the data quality service should convert the measurement function sent by the Context
    Analyzer Service into an executable code by following the quality measurement
    methods described in ISO/IEC 15939 [75] and ISO/IEC 25000 [73] standards. The
    result is stored within a repository that can be used to calculate aggregates
    of the measured values in further analysis once needed. Finally, the data quality
    score is calculated based on the quality characteristics priority measured before,
    and a user-friendly quality report is generated. 6.7 Mapping the Methodological
    Framework to ISO/IEC 20547 Big Data Reference Architecture The ISO/IEC 20547 [76]
    series is intended to provide users with a standardized approach to developing
    and implementing big data architectures. This standard provides an architecture
    framework for describing the big data components, processes, and systems to establish
    a common language for the various stakeholders named big data reference architecture
    (BDRA). As illustrated in Figure 3, we show how the components of the proposed
    methodological framework can be seamlessly mapped to the big data reference architecture
    components provided by ISO/IEC 20547 standard: Fig. 3. Fig. 3. Methodological
    framework components mapped to the ISO/IEC 20547 big data reference architecture.
    The end-user is mapped to the big data consumer role. The components used to store
    the information are mapped to the big data platform layer. The components used
    to perform all operations needed to assess the data quality are mapped to the
    data preparation component in the big data application layer. The generated data
    quality report is mapped to the data visualization component in the big data application
    layer. Skip 7OPEN CHALLENGES Section 7 OPEN CHALLENGES This section will summarize
    the challenges we identified while reviewing the literature on building context-aware
    big data quality assessment solutions. Abstraction and standardization Implementing
    data quality operations within different contexts increases the need to have a
    unified definition of the data quality dimensions and the primitives that will
    be used in designing big data quality measuring applications. Several declarative
    solutions are found in the literature [85, 119], providing a good level of abstraction.
    Still, every solution relies on its own definition of the data quality characteristics
    and metrics, increasing the need to adopt universal standards such as ISO/IEC
    25000 [73], ISO/IEC 15939 [75], and ISO/IEC 20547 [76]. Big data management In
    big data management, challenges relate to those an organization faces regarding
    data privacy, security, integration, ingestion, and governance [104]. Furthermore,
    they might be caused by the lack of qualified professionals knowledgeable about
    the latest tools and techniques for dealing with each data phase [116]. Big data
    sampling The data sampling output affects the accuracy of all other operations,
    i.e., the data profiling task can be costly for large datasets. Obtaining effective
    results using sampling depends on the data sampling criteria used [57]. Data sampling
    is essential for big data profiling to reduce the computational pressure and speed
    up the process of data profiling [91]. Several optimized sampling methods for
    big data were proposed in the literature [29, 61, 86, 117]. Still, data sampling
    is a challenging topic in the domain of big data [103], especially when analyzing
    unstructured data [91] or when training a machine learning model. For example,
    several real-world applications that use machine learning face numerous challenges
    due to imbalances in datasets that occur when the sample size and distribution
    are inaccurate [88]. Big data profiling Data profiling operations are essential
    for data quality control, because they are needed to verify and review different
    data types. This domain has become increasingly important in the field of big
    data. As within huge data silos, if a dataset metadata is not present, then this
    data becomes invisible [4]. Several data profiling techniques were proposed in
    the domain of big data [2, 33, 91]. Still, data heterogeneity is an open challenge
    for data profiling techniques [1]. Cloud-based infrastructure challenges Even
    if the cloud-based infrastructure scalability is feasible for big data solutions,
    there are still several challenges that face cloud-based solutions [59, 80]. Data
    security and privacy can be considered the main challenges due to the increased
    risk of data theft [84, 95]. Managing the tradeoff between scalability and cost
    is yet another critical challenge to address [12]. Physical resources analysis
    Estimating the performance and required resources of a data processing task executed
    using distributed technologies in a cloud environment is increasingly important
    because of its influence on development time and resource management. However,
    estimating the performance concerning parallel processes is complex for iterative,
    multi-stage applications [14]. Several statistical models were proposed to calculate
    the estimated time based on variables such as the dataset, available resources,
    and processes [15, 79, 132]. Still, these models are not validated over distributed
    tasks performed by large-scale applications. Reference data Contextual data quality
    measurement often requires a reference dataset while measuring several dimensions,
    such as accuracy and consistency. Several solutions were provided to elect a reference
    dataset from the organizational data lake if not present [101, 102, 131]. Still,
    there is no guarantee that the data lake contains an accurate reference set. Skip
    8CONCLUSION AND FUTURE WORK Section 8 CONCLUSION AND FUTURE WORK Data quality
    is critical, since poor quality can lead to bad decisions. While assessing data
    quality has reached a high level of maturity in traditional data technologies,
    it is still very challenging in big data. In this article, we explained what makes
    big data quality assessment different. And knowing that data quality is context-dependent,
    we also investigated the quality models and techniques used to achieve context
    awareness in the big data era. The results showed that none of the existing data
    quality assessment solutions could achieve context awareness while handling big
    data, thus, we provided several recommendations for building a context-aware big
    data quality assessment solution. Moreover, we compiled those recommendations
    into a methodological framework that could address the limitations of existing
    solutions. We also identified several open challenges to be addressed when building
    such a solution. A list of tasks is lined up to be done in the future. We must
    delve into the components of the methodological framework to select the most suitable
    methods and technologies at each layer (data profiling, knowledge extraction,
    quality evaluation) and address the open challenges we previously identified.
    We should start validating the design by implementing and testing it on various
    big data sets in different scenarios and contexts. In addition, we are looking
    to improve our methodological framework by considering the machine learning techniques
    that may be applied at certain levels in the quality assessment process. Footnotes
    1 https://scholar.google.com/. Footnote 2 https://ieeexplore.ieee.org. Footnote
    3 https://dblp.org/. Footnote 4 https://www.mendeley.com/search/. Footnote 5 https://www.researchgate.net/.
    Footnote 6 The citation count is taken from Google Scholar. Footnote 7 https://spark.apache.org/.
    Footnote 8 https://sourceforge.net/projects/weka/. Footnote 9 https://www.hitachivantara.com/en-us/products/infrastructure-management-analytics/pentaho.html.
    Footnote 10 https://spark.apache.org/. Footnote 11 https://storm.apache.org/.
    Footnote REFERENCES [1] Abedjan Ziawasch, Golab Lukasz, and Naumann Felix. 2017.
    Data profiling: A tutorial. In Proceedings of the 2017 ACM International Conference
    on Management of Data (2017), 1747–1751. Reference 1Reference 2 [2] Abedjan Ziawasch,
    Golab Lukasz, Naumann Felix, and Papenbrock Thorsten. 2018. Data profiling. Synthes.
    Lect. Data Manag. 10, 4 (2018), 1–154. Reference 1Reference 2 [3] Acosta Maribel,
    Zaveri Amrapali, Simperl Elena, Kontokostas Dimitris, Auer Sören, and Lehmann
    Jens. 2013. Crowdsourcing linked data quality assessment. In The Semantic Web–ISWC
    2013: 12th International Semantic Web Conference, Sydney, NSW, Australia, October
    21–25, 2013, Proceedings, Part II 12. Springer, 260–276. Reference [4] Agrawal
    Divyakant, Bernstein Philip, Bertino Elisa, Davidson Susan, Dayal Umeshwas, Franklin
    Michael, Gehrke Johannes, Haas Laura, Halevy Alon, Han Jiawei et al. 2011. Challenges
    and Opportunities with Big Data [White Paper]. Technical Report. Computing Research
    Association. Retrieved from http://cra.org/ccc/docs/init/bigdatawhitepaper.pdf.
    Reference [5] Al-Jaroodi Jameela and Mohamed Nader. 2018. Service-oriented architecture
    for big data analytics in smart cities. In 18th IEEE/ACM International Symposium
    on Cluster, Cloud and Grid Computing (CCGRID’18). 633–640. Reference [6] AlShaer
    Mohammed, Taher Yehia, Haque Rafiqul, Hacid Mohand-Saïd, and Dbouk Mohamed. 2019.
    IBRIDIA: A hybrid solution for processing big logistics data. Fut. Gen. Comput.
    Syst. 97 (2019), 792–804. Reference [7] Ardagna Danilo, Cappiello Cinzia, Samá
    Walter, and Vitali Monica. 2018. Context-aware data quality assessment for big
    data. Fut. Gen. Comput. Syst. 89 (2018), 548–562. Navigate to [8] Azeroual Otmane
    and Abuosba Mohammad. 2019. Improving the data quality in the research information
    systems. arXiv preprint arXiv:1901.07388 (2019). Reference [9] Bārzdiņš Jānis,
    Zariņš Andris, Čerāns Kārlis, Kalniņš Audris, Rencis Edgars, Lāce Lelde, Liepiņš
    Renārs, and Sprog̀is Artūrs. 2007. GrTP: Transformation based graphical tool building
    platform. In 10th International Conference on Model-driven Engineering Languages
    and Systems, Models. Reference [10] Batini Carlo, Cabitza Federico, Cappiello
    Cinzia, and Francalanci Chiara. 2008. A comprehensive data quality methodology
    for web and structured data. Int. J. Innov. Comput. Applic. 1, 3 (2008), 205–218.
    Reference 1Reference 2 [11] Batini Carlo, Rula Anisa, Scannapieco Monica, and
    Viscusi Gianluigi. 2015. From data quality to big data quality. J. Datab. Manag.
    26, 1 (2015), 60–82. Reference 1Reference 2 [12] Bello Sururah A., Oyedele Lukumon
    O., Akinade Olugbenga O., Bilal Muhammad, Delgado Juan Manuel Davila, Akanbi Lukman
    A., Ajayi Anuoluwapo O., and Owolabi Hakeem A.. 2021. Cloud computing in construction
    industry: Use cases, benefits and challenges. Automat. Construct. 122 (2021),
    103441. Reference [13] Bernstein Philip A., Madhavan Jayant, and Rahm Erhard.
    2011. Generic schema matching, ten years later. Proc. VLDB Endow. 4, 11 (2011),
    695–701. Reference 1Reference 2 [14] Bhimani Janki, Mi Ningfang, Leeser Miriam,
    and Yang Zhengyu. 2017. FiM: Performance prediction for parallel computation in
    iterative data processing applications. In IEEE 10th International Conference
    on Cloud Computing (CLOUD’17). 359–366. Reference [15] Bhimani Janki, Mi Ningfang,
    Leeser Miriam, and Yang Zhengyu. 2019. New performance modeling methods for parallel
    data processing applications. ACM Trans. Model. Comput. Simul. 29, 3 (2019), 1–24.
    Reference [16] Bicevska Zane, Bicevskis Janis, and Oditis Ivo. 2017. Domain-specific
    characteristics of data quality. Federated Conference on Computer Science and
    Information Systems (FedCSIS’17). 999–1003. Navigate to [17] Bicevska Zane, Bicevskis
    Janis, and Oditis Ivo. 2018. Models of data quality. In Information Technology
    for Management. Ongoing Research and Development: 15th Conference, AITM 2017,
    and 12th Conference, ISM 2017, Held as Part of FedCSIS, Prague, Czech Republic,
    September 3–6, 2017, Extended Selected Papers 15. Springer, 194–211. Navigate
    to [18] Bicevskis Janis, Bicevska Zane, and Karnitis Girts. 2017. Executable data
    quality models. Procedia Comput. Sci. 104 (2017), 138–145. Navigate to [19] Bicevskis
    Janis, Bicevska Zane, Nikiforova Anastasija, and Oditis Ivo. 2018. An approach
    to data quality evaluation. In Fifth International Conference on Social Networks
    Analysis, Management and Security (SNAMS’18). 196–201. Navigate to [20] Biscobing
    Jacqueline. 2018. What Is Data Sampling? Retrieved from https://www.techtarget.com/searchbusinessanalytics/definition/data-sampling.
    Reference [21] Bronselaer Antoon, Nielandt Joachim, Boeckling Toon, and Tré Guy
    De. 2018. Operational measurement of data quality. In Information Processing and
    Management of Uncertainty in Knowledge-Based Systems. Applications: 17th International
    Conference, IPMU 2018, Cádiz, Spain, June 11–15, 2018, Proceedings, Part III 17.
    Springer, 517–528. Navigate to [22] Brüggemann Stefan and Grüning Fabian. 2009.
    Using ontologies providing domain knowledge for data quality management. Networked
    Knowledge-Networked Media: Integrating Knowledge Management, New Media Technologies
    and Semantic Systems. Springer, 187–203. Reference [23] Buneman Peter and Davidson
    Susan B.. 2010. Data provenance–The foundation of data quality. In Workshop: Issues
    and Opportunities for Improving the Quality and Use of Data within the DoD, Arlington,
    26–28. Reference [24] Cai Li and Zhu Yangyong. 2015. The challenges of data quality
    and data quality assessment in the big data era. Data Sci. J. 14 (2015). Navigate
    to [25] Carlo Batini, Daniele Barone, Federico Cabitza, and Simone Grega. 2011.
    A data quality methodology for heterogeneous data. Int. J. Datab. Manag. Syst.
    3, 1 (2011), 60–79. Navigate to [26] Choi O.-Hoon, Lim Jun-Eun, Na Hong-Seok,
    and Baik Doo-Kwon. 2008. An efficient method of data quality using quality evaluation
    ontology. 2008 Third International Conference on Convergence and Hybrid Information
    Technology 2 (2008), 1058–1061. Reference [27] Cichy Corinna and Rass Stefan.
    2019. An overview of data quality frameworks. IEEE Access 7 (2019), 24634–24648.
    Reference [28] Clarke Roger. 2014. Quality Factors in Big Data and Big Data Analytics.
    Xamax Consultancy Pty Ltd. Reference 1Reference 2 [29] Cormode Graham and Duffield
    Nick. 2014. Sampling for big data: A tutorial. In Proceedings of the 20th ACM
    SIGKDD International Conference on Knowledge Discovery and Data Mining. 1975–1975.
    Reference 1Reference 2 [30] Corporation Microsoft. 2013. Data Quality Services.
    Retrieved from https://docs.microsoft.com/en-us/sql/data-quality-services/data-quality-services?view=sql-server-ver15.
    Reference [31] Corporation Microsoft. 2018. SQL Server Integration Services. Retrieved
    from https://docs.microsoft.com/en-us/sql/integration-services/sql-server-integration-services?view=sql-server-ver15.
    Reference [32] Corporation Oracle. 2013. Comprehensive Data Quality with Oracle
    Data Integrator and Oracle Enterprise Data Quality [White Paper]. Technical Report.
    Oracle Corporation. Retrieved from https://www.oracle.com/technetwork/middleware/data-integrator/overview/oracledi-comprehensive-quality-131748.pdf.
    Reference [33] Dai Wei, Wardlaw Isaac, Cui Yu, Mehdi Kashif, Li Yanyan, and Long
    Jun. 2016. Data profiling technology of data governance regarding big data: Review
    and rethinking. In Information Technology: New Generations: 13th International
    Conference on Information Technology. Springer, 439–450. Reference 1Reference
    2 [34] Dai Wei, Yoshigoe Kenji, and Parsley William. 2018. Improving data quality
    through deep learning and statistical models. In Information Technology-New Generations:
    14th International Conference on Information Technology. 515–522. Reference [35]
    Daki Houda, Hannani Asmaa El, Aqqal Abdelhak, Haidine Abdelfattah, and Dahbi Aziz.
    2017. Big Data management in smart grid: Concepts, requirements and implementation.
    J. Big Data 4, 1 (2017), 1–19. Reference [36] Dean Jeffrey and Ghemawat Sanjay.
    2008. MapReduce: simplified data processing on large clusters. Commun. ACM 51,
    1, 107–113. Reference [37] Dhayne Houssein, Haque Rafiqul, Kilany Rima, and Taher
    Yehia. 2019. In search of big medical data integration solutions—A comprehensive
    survey. IEEE Access 7 (2019), 91265–91290. Reference [38] Dmitriyev Viktor, Mahmoud
    Tariq, and Marín-Ortega Pablo Michel. 2015. Int. J. Inf. Syst. Proj. Manag. 3,
    3 (2015), 49–63. Navigate to [39] Dong Xin Luna, Berti-Equille Laure, and Srivastava
    Divesh. 2013. Data fusion: Resolving conflicts from multiple sources. Handbook
    of Data Quality: Research and Practice. Springer, 293–318. Reference 1Reference
    2 [40] Dong Xin Luna and Srivastava Divesh. 2013. Big data integration. In IEEE
    29th International Conference on Data Engineering (ICDE’13). IEEE, 1245–1248.
    Reference [41] Dragoni Nicola, Lanese Ivan, Larsen Stephan Thordal, Mazzara Manuel,
    Mustafin Ruslan, and Safina Larisa. 2018. Microservices: How to make your application
    scale. In Perspectives of System Informatics: 11th International Andrei P. Ershov
    Informatics Conference, PSI 2017, Moscow, Russia, June 27–29, 2017, Revised Selected
    Papers 11. Springer, 95–104. Reference [42] Durairaj M. and Poornappriya T. S..
    2018. Importance of MapReduce for big data applications: A survey. Asian J. Comput.
    Sci. Technol. 7, 1 (2018), 112–118. Reference [43] Ehrlinger Lisa, Werth Bernhard,
    and Wöß Wolfram. 2018. Automated continuous data quality measurement with QuaIIe.
    Int. J. Advanc. Softw. 11, 3 (2018), 400–417. Navigate to [44] Ehrlinger Lisa,
    Werth Bernhard, and Wöß Wolfram. 2018. QuaIIe: A data quality assessment tool
    for integrated information systems. In 10th International Conference on Advances
    in Databases, Knowledge, and Data Applications (DBKDA’18). 21–31. Navigate to
    [45] Ehrlinger Lisa and Wöß Wolfram. 2017. Automated data quality monitoring.
    In 22nd MIT International Conference on Information Quality (ICIQ’17). 15–1. Navigate
    to [46] Even Adir and Shankaranarayanan Ganesan. 2005. Value-driven data quality
    assessment. In International Conference on Information Quality (ICIQ’05). Navigate
    to [47] Even Adir and Shankaranarayanan Ganesan. 2007. Utility-driven assessment
    of data quality. ACM SIGMIS Datab.: DATAB. Adv. Inf. Syst. 38, 2 (2007), 75–93.
    Navigate to [48] Fadlallah Hadi, Taher Yehia, Haque Rafiqul, and Jaber Ali. 2019.
    ORADIEX: A big data driven smart framework for real-time surveillance and analysis
    of individual exposure to radioactive pollution. In International Conference on
    Big Data and Cybersecurity Intelligence (BDCSIntell’19). 52–56. Reference [49]
    Fadlallah Hadi, Taher Yehia, and Jaber Ali. 2018. RaDEn: A scalable and efficient
    radiation data engineering. In International Conference on Big Data and Cybersecurity
    Intelligence (BDCSIntell’18). 89–93. Reference [50] Salas Óscar Figuerola, Adzic
    Velibor, Shah Akash, and Kalva Hari. 2013. Assessing internet video quality using
    crowdsourcing. In 2nd ACM International Workshop on Crowdsourcing for Multimedia.
    23–28. Reference [51] Finkel Jenny Rose, Grenager Trond, and Manning Christopher
    D.. 2005. Incorporating non-local information into information extraction systems
    by Gibbs sampling. In 43rd Annual Meeting of the Association for Computational
    Linguistics (ACL’05). 363–370. Reference 1Reference 2 [52] Gao Jerry, Xie Chunli,
    and Tao Chuanqi. 2016. Big data validation and quality assuranceIssues, challenges,
    and needs. In IEEE symposium on service-oriented system engineering (SOSE16).
    433–441. Reference [53] Ge Mouzhi and Helfert Markus. 2007. A review of information
    quality research-develop a research agenda. In International Conference on Information
    Quality (ICIQ’07). 76–91. Reference 1Reference 2 [54] Gu Rong, Qi Yang, Wu Tongyu,
    Wang Zhaokang, Xu Xiaolong, Yuan Chunfeng, and Huang Yihua. 2021. SparkDQ: Efficient
    generic big data quality management on distributed data-parallel computation.
    J. ParallelDistrib. Comput. 156 (2021), 132–147. Navigate to [55] Gudivada Venkat,
    Apon Amy, and Ding Junhua. 2017. Data quality considerations for big data and
    machine learning: Going beyond data cleaning and transformations. Int. J. Advanc.
    Softw. 10, 1 (2017), 1–20. Reference [56] Gudivada Venkat N., Rao Dhana, and Grosky
    William I.. 2016. Data quality centric application framework for big data. In
    International Conference on Big Data, Small Data, Linked Data and Open Data (ALLDATA’16).
    Reference [57] Hariri Reihaneh H., Fredericks Erik M., and Bowers Kate M.. 2019.
    Uncertainty in big data analytics: Survey, opportunities, and challenges. J. Big
    Data 6, 1 (2019), 1–16. Reference [58] Hasselbring Wilhelm. 2016. Microservices
    for scalability: Keynote talk abstract. In Proceedings of the 7th ACM/SPEC on
    International Conference on Performance Engineering. 133–134. Reference [59] Hay
    Brian, Nance Kara, and Bishop Matt. 2011. Storm clouds rising: Security challenges
    for IaaS cloud computing. In 2011 44th Hawaii International Conference on System
    Sciences. 1–7. Reference [60] He Qinlu, Li Zhanhuai, and Zhang Xiao. 2010. Data
    deduplication techniques. In 2010 International Conference on Future Information
    Technology and Management Engineering 1 (2010), 430–433. Reference [61] He Qing,
    Wang Haocheng, Zhuang Fuzhen, Shang Tianfeng, and Shi Zhongzhi. 2015. Parallel
    sampling from big data with uncertainty distribution. Fuzzy Sets Syst. 258 (2015),
    117–133. Reference 1Reference 2 [62] Helfert Markus and Foley Owen. 2009. A context
    aware information quality framework. In 2009 Fourth International Conference on
    Cooperation and Promotion of Information Resources in Science and Technology.
    187–193. Navigate to [63] Hogan Aidan, Blomqvist Eva, Cochez Michael, d’Amato
    Claudia, Melo Gerard de, Gutierrez Claudio, Kirrane Sabrina, Gayo José Emilio
    Labra, Navigli Roberto, Neumaier Sebastian, et al. 2021. Knowledge graphs. ACM
    Comput. Surv. 54, 4 (2021), 1–37. Reference [64] Hosseini Kasra, Nanni Federico,
    and Ardanuy Mariona Coll. 2020. DeezyMatch: A flexible deep learning approach
    to fuzzy string matching. In Conference on Empirical Methods in Natural Language
    Processing: System Demonstrations. 62–69. Reference [65] Hoßfeld Tobias, Hirth
    Matthias, Korshunov Pavel, Hanhart Philippe, Gardlo Bruno, Keimel Christian, and
    Timmerer Christian. 2014. Survey of web-based crowdsourcing frameworks for subjective
    quality assessment. In IEEE 16th International Workshop on Multimedia Signal Processing
    (MMSP’14). 1–6. Reference [66] Ilyas Ihab F. and Chu Xu. 2019. Data Cleaning.
    ACM New York, NY. Reference 1Reference 2 [67] Immonen Anne, Pääkkönen Pekka, and
    Ovaska Eila. 2015. Evaluating the quality of social media data in big data architecture.
    IEEE Access 3 (2015), 2028–2043. Navigate to [68] Inc. Talend2022. Data Quality
    and Machine Learning: What’s the Connection? Retrieved from https://www.talend.com/resources/machine-learning-data-quality/.
    Reference [69] Informatica. 2018. Informatica Data Quality Data Sheet. Technical
    Report. Informatica. Retrieved from https://www.informatica.com/content/dam/informatica-com/en/collateral/data-sheet/en_informatica-data-quality_data-sheet_6710.pdf.
    Reference [70] Iqbal Muhammad Hussain, Soomro Tariq Rahim et al. 2015. Big data
    analysis: Apache Storm perspective. Int. J. Comput. Trends Technol. 19, 1 (2015),
    9–14. Reference [71] ISO/IEC. 2001. ISO/IEC 9126-1:2001. Software Engineering
    – Product Quality – Part 1: Quality Model. Standard. ISO/IEC. Retrieved from https://www.iso.org/standard/22749.html.
    Reference [72] ISO/IEC. 2008. 25012:2008 Software Engineering – Software Product
    Quality Requirements and Evaluation (SQuaRE) – Data Quality Model. Standard. ISO/IEC.
    Retrieved from https://www.iso.org/standard/35736.html. Reference 1Reference 2Reference
    3 [73] ISO/IEC. 2014. ISO/IEC 25000:2014. Systems and Software Engineering – System
    and Software Quality Requirements and Evaluation (SQuaRE) – Guide to SQuaRE. Standard.
    ISO/IEC. Retrieved from https://www.iso.org/standard/64764.html. Navigate to [74]
    ISO/IEC. 2015. ISO/IEC 25024:2015 Systems and Software Engineering – Systems and
    Software Quality Requirements and Evaluation (SQuaRE) – Measurement of Data Quality.
    Standard. ISO/IEC. Retrieved from https://www.iso.org/standard/35749.html. Reference
    1Reference 2 [75] ISO/IEC. 2017. ISO/IEC 15939:2017 Systems and Software Engineering
    – Measurement Process. Standard. ISO/IEC. Retrieved from https://www.iso.org/standard/71197.html.
    Reference 1Reference 2Reference 3 [76] ISO/IEC. 2020. ISO/IEC 20547-3:2020 Big
    Data Reference Architecture - Part 3: Reference Architecture. Standard. ISO/IEC.
    Retrieved from https://www.iso.org/standard/71277.html. Reference 1Reference 2Reference
    3 [77] ISO/IEC. 2022. ISO/IEC AWI 5259-1 Artificial Intelligence – Data Quality
    for Analytics and Machine Learning (ML) – Part 1: Overview, Terminology, and Examples.
    Standard. ISO/IEC. Retrieved from https://www.iso.org/standard/81088.html. Reference
    [78] ISO/TS. 2011. ISO/TS 8000-1:2011 - Data Quality - Part 1: Overview. Standard.
    ISO/TS. Retrieved from https://www.iso.org/standard/50798.html. Reference [79]
    Iverson Michael A., Ozguner Fusun, and Potter Lee C.. 1999. Statistical prediction
    of task execution times through analytic benchmarking for scheduling in a heterogeneous
    environment. In Proceedings Eighth Heterogeneous Computing Workshop (HCW’99).
    99–111. Reference [80] Ji Changqing, Li Yu, Qiu Wenming, Awada Uchechukwu, and
    Li Keqiu. 2012. Big data processing in cloud computing environments. In 2012 12th
    International Symposium on Pervasive Systems, Algorithms and Networks (2012),
    17–23. Reference 1Reference 2 [81] Kadadi Anirudh, Agrawal Rajeev, Nyamful Christopher,
    and Atiq Rahman. 2014. Challenges of data integration and interoperability in
    big data. In 2014 IEEE International Conference on Big Data (big data) (2014),
    38–40. Reference [82] Kaiser Jiří. 2014. Dealing with missing values in data.
    J. Syst. Integr. 5, 1 (2014) 42–51. Reference [83] Karami Amir, Gangopadhyay Aryya,
    Zhou Bin, and Kharrazi Hadi. 2015. A fuzzy approach model for uncovering hidden
    latent semantic structure in medical text collections. In iConference 2015. Reference
    [84] Karmakar Anurag, Raghuthaman Anaswara, Kote Om Sudhakar, and Jayapandian
    N.. 2022. Cloud computing application: Research challenges and opportunity. In
    International Conference on Sustainable Computing and Data Communication Systems
    (ICSCDS’22). IEEE, 1284–1289. Reference [85] Khayyat Zuhair, Ilyas Ihab F., Jindal
    Alekh, Madden S., Ouzzani M., Papotti Paolo, Quiané-Ruiz Jorge-Arnulfo, Tang Nan,
    and Yin Si. 2015. BigDansing: A system for big data cleansing. In SIGMOD Conference.
    Reference 1Reference 2 [86] Kim Jae Kwang and Wang Zhonglei. 2019. Sampling techniques
    for big data analysis. Int. Statist. Rev. 87 (2019), S177–S191. Reference 1Reference
    2 [87] Kontokostas Dimitris, Zaveri Amrapali, Auer Sören, and Lehmann Jens. 2013.
    TripleCheckMate: A tool for crowdsourcing the quality assessment of linked data.
    In Knowledge Engineering and the Semantic Web: 4th International Conference, KESW
    2013, St. Petersburg, Russia, October 7–9, 2013. Proceedings 4. Springer, 265–272.
    Reference [88] Kumar Pradeep, Bhatnagar Roheet, Gaur Kuntal, and Bhatnagar Anurag.
    2021. Classification of imbalanced data: Review of methods and applications. IOP
    Conference Series: Materials Science and Engineering 1099, 1 (2021), 012077. Reference
    [89] Kusumasari Tien Fabrianti et al. 2016. Data profiling for data quality improvement
    with OpenRefine. In International Conference on Information Technology Systems
    and Innovation (ICITSI’16). 1–6. Reference [90] Leung Hareton K. N.. 2001. Quality
    metrics for intranet applications. Inf. Manag. 38, 3 (2001), 137–152. Reference
    [91] Liu Zhicheng and Zhang Aoqian. 2020. Sampling for big data profiling: A survey.
    IEEE Access 8 (2020), 72713–72726. Navigate to [92] L’Heureux Alexandra, Grolinger
    Katarina, Elyamany Hany F., and Capretz Miriam A. M.. 2017. Machine learning with
    big data: Challenges and approaches. IEEE Access 5 (2017), 7776–7797. Reference
    [93] Malhotra Jyoti and Bakal Jagdish. 2015. A survey and comparative study of
    data deduplication techniques. In International Conference on Pervasive Computing
    (ICPC’15). 1–5. Reference [94] McKelvey Nigel, Curran Kevin, and Toland Luke.
    2016. The Challenges of Data Cleansing with Data Warehouses. 77–82. DOI: Reference
    [95] Mehrtak Mohammad, SeyedAlinaghi SeyedAhmad, MohsseniPour Mehrzad, Noori Tayebeh,
    Karimi Amirali, Shamsabadi Ahmadreza, Heydari Mohammad, Barzegary Alireza, Mirzapour
    Pegah, Soleymanzadeh Mahdi, et al. 2021. Security challenges and solutions using
    healthcare cloud computing. J. Med. Life 14, 4 (2021), 448. Reference [96] Merino
    Jorge, Caballero Ismael, Rivas Bibiano, Serrano Manuel, and Piattini Mario. 2016.
    A data quality in use model for big data. Fut. Gen. Comput. Syst. 63 (2016), 123–130.
    Navigate to [97] Mihindukulasooriya Nandana, García-Castro Raúl, Priyatna Freddy,
    Ruckhaus Edna, and Saturno Nelson. 2017. A linked data profiling service for quality
    assessment. In The Semantic Web: ESWC 2017 Satellite Events: ESWC 2017 Satellite
    Events, Portorož, Slovenia, May 28–June 1, 2017, Revised Selected Papers 14. Springer,
    335–340. Reference [98] Missier Paolo, Embury Suzanne, Greenwood Mark, Preece
    Alun, and Jin Binling. 2006. Quality views: Capturing and exploiting the user
    perspective on data quality. In International Conference on Very Large Data Bases.
    Reference 1Reference 2Reference 3 [99] Mousannif Hajar, Sabah Hasna, Douiji Yasmina,
    and Sayad Younes Oulad. 2014. From big data to big projects: A step-by-step roadmap.
    In 2014 International Conference on Future Internet of Things and Cloud. 373–378.
    Reference [100] Munn Zachary, Peters Micah D. J., Stern Cindy, Tufanaru Catalin,
    McArthur Alexa, and Aromataris Edoardo. 2018. Systematic review or scoping review?
    Guidance for authors when choosing between a systematic or scoping review approach.
    BMC Med. Res. Methodol. 18 (2018), 1–7. Reference [101] Mylavarapu Goutam, Thomas
    Johnson P., and Viswanathan K. Ashwin. 2019. An automated big data accuracy assessment
    tool. In IEEE 4th International Conference on Big Data Analytics (ICBDA’19). 193–197.
    Navigate to [102] Mylavarapu Goutam, Viswanathan K. Ashwin, and Thomas Johnson
    P.. 2019. Assessing context-aware data consistency. In IEEE/ACS 16th International
    Conference on Computer Systems and Applications (AICCSA’19). 1–6. Navigate to
    [103] Najafabadi Maryam M., Villanustre Flavio, Khoshgoftaar Taghi M., Seliya
    Naeem, Wald Randall, and Muharemagic Edin. 2015. Deep learning applications and
    challenges in big data analytics. J. Big Data 2, 1 (2015), 1–21. Reference 1Reference
    2 [104] Nargesian Fatemeh, Zhu Erkang, Miller Renée J., Pu Ken Q., and Arocena
    Patricia C.. 2019. Data lake management: Challenges and opportunities. Proc. VLDB
    Endow. 12, 12 (2019), 1986–1989. Reference 1Reference 2 [105] Naumann Felix. 2014.
    Data profiling revisited. ACM SIGMOD Rec. 42, 4 (2014), 40–49. Reference [106]
    Niemelä Eila, Evesti Antti, and Savolainen Pekka. 2008. Modeling quality attribute
    variability. In International Conference on Evaluation of Novel Approaches to
    Software Engineering (ENASE’08). 169–176. Reference [107] Nikiforova Anastasija
    and Bicevskis Janis. 2019. An extended data object-driven approach to data quality
    evaluation: Contextual data quality analysis. In International Conference on Enterprise
    Information Systems (ICEIS’19). 274–281. Navigate to [108] Nikiforova Anastasija,
    Bicevskis Janis, Bicevska Zane, and Oditis Ivo. 2020. User-oriented approach to
    data quality evaluation. J. Univers. Comput. Sci. 26, 1 (2020), 107–126. Navigate
    to [109] Pääkkönen Pekka and Pakkala Daniel. 2015. Reference architecture and
    classification of technologies, products and services for big data systems. Big
    Data Res. 2, 4 (2015), 166–186. Navigate to [110] Patel-Schneider Peter F.. 2015.
    Towards large-scale schema and ontology matching. Retrieved from https://www.semanticscholar.org/paper/Towards-Large-scale-Schema-And-Ontology-Matching-Patel-Schneider/ceee2bdaef83a0f09480fa6fb191cf3372137152.
    Reference 1Reference 2 [111] Pérez Beatriz, Rubio Julio, and Sáenz-Adán Carlos.
    2018. A systematic review of provenance systems. Knowl. Inf. Syst. 57 (2018),
    495–543. Reference [112] Pipino Leo L., Lee Yang W., and Wang Richard Y.. 2002.
    Data quality assessment. Commun. ACM 45, 4 (2002), 211–218. Reference [113] Price
    Rosanne, Neiger Dina, and Shanks Graeme. 2008. Developing a measurement instrument
    for subjective aspects of information quality. Commun. Assoc. Inf. Syst. 22, 1
    (2008), 3. Reference [114] Rahul Kumar and Banyal R. K.. 2019. Data cleaning mechanism
    for big data and cloud computing. In 6th International Conference on Computing
    for Sustainable Global Development (INDIACom’19). 195–198. Reference [115] Ramaswamy
    Lakshmish, Lawson Victor, and Gogineni Siva Venkat. 2013. Towards a quality-centric
    big data architecture for federated sensor services. In 2013 IEEE International
    Congress on Big Data. 86–93. Navigate to [116] Rawat R. and Yadav R.. 2021. Big
    data: Big data analysis, issues and challenges and technologies. IOP Conference
    Series: Materials Science and Engineering 1022, 1 (2021), 012014. Reference [117]
    Sadineni Praveen Kumar. 2020. Sampling based join-aggregate query processing technique
    for big data. Indian J. Comput. Sci. Eng. 11, 5, 532–546. Reference 1Reference
    2 [118] Saha Barna and Srivastava Divesh. 2014. Data quality: The other face of
    big data. In 2014 IEEE 30th International Conference on Data Engineering. 1294–1297.
    Reference 1Reference 2 [119] Schelter Sebastian, Lange Dustin, Schmidt Philipp,
    Celikel Meltem, Biessmann Felix, and Grafberger Andreas. 2018. Automating large-scale
    data quality verification. Proc. VLDB Endow. 11, 12 (2018), 1781–1794. Navigate
    to [120] Sharma Gaurav. 2021. Data Quality. Retrieved from https://www.computer.org/publications/tech-news/trends/big-data-and-cloud-computing.
    Reference [121] Siegmund Norbert, Rosenmüller Marko, Kuhlemann Martin, Kästner
    Christian, Apel Sven, Duchateau Fabien, and Fagnan Justin. 2015. Schema matching
    bibtex. In Proceedings of the VLDB Endowment. Reference 1Reference 2 [122] Software
    Calidad. 2022. ISO/IEC 25012. Retrieved from https://iso25000.com/index.php/en/iso-25000-standards/iso-25012.
    Reference 1Reference 2Reference 3 [123] Stojanović Dragan, Stojanović Natalija,
    and Turanjanin Jovan. 2015. Processing big trajectory and Twitter data streams
    using Apache STORM. (2015), 301–304. Retrieved from https://www.semanticscholar.org/paper/Schema-Matching-Bibtex-Siegmund-Rosenm%C3%BCller/a4d94ddaab429e5874386dd29822e470b57d6ee4.
    Reference [124] Strong Diane M., Lee Yang W., and Wang Richard Y.. 1997. Data
    quality in context. Commun. ACM 40, 5 (1997), 103–110. Navigate to [125] Taher
    Yehia, Haque Rafiqul, AlShaer Mohammed, Heuvel Willem Jan van den, Hacid Mohand-Saïd,
    and Dbouk Mohamed. 2016. A context-aware analytics for processing tweets and analysing
    sentiment in realtime (short paper). In On the Move to Meaningful Internet Systems:
    OTM 2016 Conferences: Confederated International Conferences: CoopIS, C&TC, and
    ODBASE 2016, Rhodes, Greece, October 24–28, 2016, Proceedings. Springer, 910–917.
    Reference 1Reference 2Reference 3 [126] Taher Yehia, Haque Rafiqul, and Hacid
    Mohand-Said. 2017. BDLaaS: Big data lab as a service for experimenting big data
    solution. In IEEE 2nd International Workshops on Foundations and Applications
    of Self* Systems (FAS* W’17). 155–159. Reference [127] Taleb Ikbal, Dssouli Rachida,
    and Serhani Mohamed Adel. 2015. Big data pre-processing: A quality framework.
    (2015), 191–198. Navigate to [128] Taleb Ikbal, Serhani Mohamed Adel, and Dssouli
    Rachida. 2018. Big data quality assessment model for unstructured data. In International
    Conference on Innovations in Information Technology (IIT’18). 69–74. Navigate
    to [129] Taleb Ikbal, Serhani Mohamed Adel, and Dssouli Rachida. 2019. Big data
    quality: A data quality profiling model. In Services–SERVICES 2019: 15th World
    Congress, Held as Part of the Services Conference Federation, SCF 2019, San Diego,
    CA, USA, June 25–30, 2019, Proceedings 15. Springer, 61–77. Reference [130] Talend.
    2020. How to Manage Modern Data Quality [White Paper]. Technical Report. Talend.
    Retrieved from https://www.talend.com/resources/definitive-guide-data-quality-how-to-manage.
    Reference [131] Talha Mohamed, Elmarzouqi Nabil, and Kalam Anas Abou El. 2020.
    Towards a powerful solution for data accuracy assessment in the big data context.
    Int. J. Advanc. Comput. Sci. Applic. 11, 2 (2020). Navigate to [132] Venkataraman
    Shivaram, Yang Zongheng, Franklin Michael, Recht Benjamin, and Stoica Ion. 2016.
    Ernest: Efficient performance prediction for large-scale advanced analytics. In
    13th USENIX Symposium on Networked Systems Design and Implementation (NSDI’16).
    363–378. Reference [133] Wang Lidong and Alexander Cheryl Ann. 2016. Machine learning
    in big data. Int. J. Math., Eng. Manag. Sci. 1, 2 (2016), 52–61. Reference [134]
    Wang Richard Y.. 1998. A product perspective on total data quality management.
    Commun. ACM 41, 2 (1998), 58–65. Reference 1Reference 2 [135] Wang Richard Y.
    and Strong Diane. 1996. Beyond accuracy: What data quality means to data consumers.
    J. Manag. Inf. Syst. 12 (1996), 5–33. Navigate to [136] Wang Xinxin, Dang Depeng,
    and Guo Zixian. 2020. Evaluating the crowd quality for subjective questions based
    on a Spark computing environment. Fut. Gen. Comput. Syst. 106 (2020), 426–437.
    Reference [137] Wei-Liang Chen, Shi-Dong Zhang, and Xiang Gao. 2009. Anchoring
    the consistency dimension of data quality using ontology in data integration.
    (2009), 201–205. Reference 1Reference 2 [138] Woodall Philip, Oberhofer Martin,
    and Borek Alexander. 2014. A classification of data quality assessment and improvement
    methods. Int. J. Inf. Qual. 3, 4 (2014), 298–321. Reference 1Reference 2 [139]
    Zaslavsky Arkady, Perera Charith, and Georgakopoulos Dimitrios. 2013. Sensing
    as a service and big data. arXiv preprint arXiv:1301.0159 (2013). Reference [140]
    Zaveri Amrapali, Kontokostas Dimitris, Sherif Mohamed A., Bühmann Lorenz, Morsey
    Mohamed, Auer Sören, and Lehmann Jens. 2013. User-driven quality evaluation of
    DBpedia. In 9th International Conference on Semantic Systems. 97–104. Reference
    [141] Zhang Pengcheng, Zhou Xuewu, Li Wenrui, and Gao Jerry. 2017. A survey on
    quality assurance techniques for big data applications. (2017), 313–319. Reference
    [142] Zhang Zhenrong, Zhang Jianshu, Du Jun, and Wang Fengren. 2022. Split, embed
    and merge: An accurate table structure recognizer. Pattern Recognit. 126 (2022),
    108565. Reference [143] Zhou Lina, Pan Shimei, Wang Jianwu, and Vasilakos Athanasios
    V.. 2017. Machine learning on big data: Opportunities and challenges. Neurocomputing
    237 (2017), 350–361. Reference 1Reference 2 Index Terms Context-aware Big Data
    Quality Assessment: A Scoping Review Information systems Data management systems
    Recommendations BIGQA: Declarative Big Data Quality Assessment In the big data
    domain, data quality assessment operations are often complex and must be implementable
    in a distributed and timely manner. This article tries to generalize the quality
    assessment operations by providing a new ISO-based declarative data ... Read More
    A Data Quality in Use model for Big Data Beyond the hype of Big Data, something
    within business intelligence projects is indeed changing. This is mainly because
    Big Data is not only about data, but also about a complete conceptual and technological
    stack including raw and processed data, ... Read More Context-aware data quality
    assessment for big data Abstract Big data changed the way in which we collect
    and analyze data. In particular, the amount of available information is constantly
    growing and organizations rely more and more on data analysis in order to achieve
    their competitive ... Highlights Data Quality assessment is a key success point
    for applications using big data. Read More Comments Login options Check if you
    have access through your login credentials or your institution to get full access
    on this article. Sign in Full Access Get this Article Information Contributors
    Published in Journal of Data and Information Quality   Volume 15, Issue 3 September
    2023326 pages ISSN: 1936-1955 EISSN: 1936-1963 DOI: 10.1145/3611329 Editor: Tiziana
    Catarci Issue’s Table of Contents Permission to make digital or hard copies of
    all or part of this work for personal or classroom use is granted without fee
    provided that copies are not made or distributed for profit or commercial advantage
    and that copies bear this notice and the full citation on the first page. Copyrights
    for components of this work owned by others than the author(s) must be honored.
    Abstracting with credit is permitted. To copy otherwise, or republish, to post
    on servers or to redistribute to lists, requires prior specific permission and/or
    a fee. Request permissions from permissions@acm.org. Publisher Association for
    Computing Machinery New York, NY, United States Publication History Published:
    22 August 2023 Online AM: 13 June 2023 Accepted: 8 May 2023 Revised: 23 March
    2023 Received: 16 April 2022 Published in JDIQ Volume 15, Issue 3 Permissions
    Request permissions about this article. Request Permissions Check for updates
    Author Tags Data qualitybig datacontext awarenessdata quality assessment Qualifiers
    Survey Bibliometrics Citations0 Article Metrics 0 Total Citations View Citations
    567 Total Downloads Downloads (Last 12 months) 567 Downloads (Last 6 weeks) 130
    Other Metrics View Author Metrics PDF Format View or Download as a PDF file. PDF
    eReader View online with eReader. eReader [1] Abedjan Ziawasch, Golab Lukasz,
    and Naumann Felix. 2017. Data profiling: A tutorial. In Proceedings of the 2017
    ACM International Conference on Management of Data (2017), 1747–1751. Reference
    1Reference 2 [2] Abedjan Ziawasch, Golab Lukasz, Naumann Felix, and Papenbrock
    Thorsten. 2018. Data profiling. Synthes. Lect. Data Manag. 10, 4 (2018), 1–154.
    Reference 1Reference 2 [3] Acosta Maribel, Zaveri Amrapali, Simperl Elena, Kontokostas
    Dimitris, Auer Sören, and Lehmann Jens. 2013. Crowdsourcing linked data quality
    assessment. In The Semantic Web–ISWC 2013: 12th International Semantic Web Conference,
    Sydney, NSW, Australia, October 21–25, 2013, Proceedings, Part II 12. Springer,
    260–276. Reference [4] Agrawal Divyakant, Bernstein Philip, Bertino Elisa, Davidson
    Susan, Dayal Umeshwas, Franklin Michael, Gehrke Johannes, Haas Laura, Halevy Alon,
    Han Jiawei et al. 2011. Challenges and Opportunities with Big Data [White Paper].
    Technical Report. Computing Research Association. Retrieved from http://cra.org/ccc/docs/init/bigdatawhitepaper.pdf.
    Reference [5] Al-Jaroodi Jameela and Mohamed Nader. 2018. Service-oriented architecture
    for big data analytics in smart cities. In 18th IEEE/ACM International Symposium
    on Cluster, Cloud and Grid Computing (CCGRID’18). 633–640. Reference [6] AlShaer
    Mohammed, Taher Yehia, Haque Rafiqul, Hacid Mohand-Saïd, and Dbouk Mohamed. 2019.
    IBRIDIA: A hybrid solution for processing big logistics data. Fut. Gen. Comput.
    Syst. 97 (2019), 792–804. Reference [7] Ardagna Danilo, Cappiello Cinzia, Samá
    Walter, and Vitali Monica. 2018. Context-aware data quality assessment for big
    data. Fut. Gen. Comput. Syst. 89 (2018), 548–562. Navigate to [8] Azeroual Otmane
    and Abuosba Mohammad. 2019. Improving the data quality in the research information
    systems. arXiv preprint arXiv:1901.07388 (2019). Reference [9] Bārzdiņš Jānis,
    Zariņš Andris, Čerāns Kārlis, Kalniņš Audris, Rencis Edgars, Lāce Lelde, Liepiņš
    Renārs, and Sprog̀is Artūrs. 2007. GrTP: Transformation based graphical tool building
    platform. In 10th International Conference on Model-driven Engineering Languages
    and Systems, Models. Reference [10] Batini Carlo, Cabitza Federico, Cappiello
    Cinzia, and Francalanci Chiara. 2008. A comprehensive data quality methodology
    for web and structured data. Int. J. Innov. Comput. Applic. 1, 3 (2008), 205–218.
    Reference 1Reference 2 [11] Batini Carlo, Rula Anisa, Scannapieco Monica, and
    Viscusi Gianluigi. 2015. From data quality to big data quality. J. Datab. Manag.
    26, 1 (2015), 60–82. Reference 1Reference 2 [12] Bello Sururah A., Oyedele Lukumon
    O., Akinade Olugbenga O., Bilal Muhammad, Delgado Juan Manuel Davila, Akanbi Lukman
    A., Ajayi Anuoluwapo O., and Owolabi Hakeem A.. 2021. Cloud computing in construction
    industry: Use cases, benefits and challenges. Automat. Construct. 122 (2021),
    103441. Reference [13] Bernstein Philip A., Madhavan Jayant, and Rahm Erhard.
    2011. Generic schema matching, ten years later. Proc. VLDB Endow. 4, 11 (2011),
    695–701. Reference 1Reference 2 [14] Bhimani Janki, Mi Ningfang, Leeser Miriam,
    and Yang Zhengyu. 2017. FiM: Performance prediction for parallel computation in
    iterative data processing applications. In IEEE 10th International Conference
    on Cloud Computing (CLOUD’17). 359–366. Reference [15] Bhimani Janki, Mi Ningfang,
    Leeser Miriam, and Yang Zhengyu. 2019. New performance modeling methods for parallel
    data processing applications. ACM Trans. Model. Comput. Simul. 29, 3 (2019), 1–24.
    Reference [16] Bicevska Zane, Bicevskis Janis, and Oditis Ivo. 2017. Domain-specific
    characteristics of data quality. Federated Conference on Computer Science and
    Information Systems (FedCSIS’17). 999–1003. Navigate to [17] Bicevska Zane, Bicevskis
    Janis, and Oditis Ivo. 2018. Models of data quality. In Information Technology
    for Management. Ongoing Research and Development: 15th Conference, AITM 2017,
    and 12th Conference, ISM 2017, Held as Part of FedCSIS, Prague, Czech Republic,
    September 3–6, 2017, Extended Selected Papers 15. Springer, 194–211. Navigate
    to [18] Bicevskis Janis, Bicevska Zane, and Karnitis Girts. 2017. Executable data
    quality models. Procedia Comput. Sci. 104 (2017), 138–145. Navigate to [19] Bicevskis
    Janis, Bicevska Zane, Nikiforova Anastasija, and Oditis Ivo. 2018. An approach
    to data quality evaluation. In Fifth International Conference on Social Networks
    Analysis, Management and Security (SNAMS’18). 196–201. Navigate to [20] Biscobing
    Jacqueline. 2018. What Is Data Sampling? Retrieved from https://www.techtarget.com/searchbusinessanalytics/definition/data-sampling.
    Reference [21] Bronselaer Antoon, Nielandt Joachim, Boeckling Toon, and Tré Guy
    De. 2018. Operational measurement of data quality. In Information Processing and
    Management of Uncertainty in Knowledge-Based Systems. Applications: 17th International
    Conference, IPMU 2018, Cádiz, Spain, June 11–15, 2018, Proceedings, Part III 17.
    Springer, 517–528. Navigate to [22] Brüggemann Stefan and Grüning Fabian. 2009.
    Using ontologies providing domain knowledge for data quality management. Networked
    Knowledge-Networked Media: Integrating Knowledge Management, New Media Technologies
    and Semantic Systems. Springer, 187–203. Reference [23] Buneman Peter and Davidson
    Susan B.. 2010. Data provenance–The foundation of data quality. In Workshop: Issues
    and Opportunities for Improving the Quality and Use of Data within the DoD, Arlington,
    26–28. Reference [24] Cai Li and Zhu Yangyong. 2015. The challenges of data quality
    and data quality assessment in the big data era. Data Sci. J. 14 (2015). Navigate
    to [25] Carlo Batini, Daniele Barone, Federico Cabitza, and Simone Grega. 2011.
    A data quality methodology for heterogeneous data. Int. J. Datab. Manag. Syst.
    3, 1 (2011), 60–79. Navigate to [26] Choi O.-Hoon, Lim Jun-Eun, Na Hong-Seok,
    and Baik Doo-Kwon. 2008. An efficient method of data quality using quality evaluation
    ontology. 2008 Third International Conference on Convergence and Hybrid Information
    Technology 2 (2008), 1058–1061. Reference [27] Cichy Corinna and Rass Stefan.
    2019. An overview of data quality frameworks. IEEE Access 7 (2019), 24634–24648.
    Reference [28] Clarke Roger. 2014. Quality Factors in Big Data and Big Data Analytics.
    Xamax Consultancy Pty Ltd. Reference 1Reference 2 [29] Cormode Graham and Duffield
    Nick. 2014. Sampling for big data: A tutorial. In Proceedings of the 20th ACM
    SIGKDD International Conference on Knowledge Discovery and Data Mining. 1975–1975.
    Reference 1Reference 2 [30] Corporation Microsoft. 2013. Data Quality Services.
    Retrieved from https://docs.microsoft.com/en-us/sql/data-quality-services/data-quality-services?view=sql-server-ver15.
    Reference [31] Corporation Microsoft. 2018. SQL Server Integration Services. Retrieved
    from https://docs.microsoft.com/en-us/sql/integration-services/sql-server-integration-services?view=sql-server-ver15.
    Reference [32] Corporation Oracle. 2013. Comprehensive Data Quality with Oracle
    Data Integrator and Oracle Enterprise Data Quality [White Paper]. Technical Report.
    Oracle Corporation. Retrieved from https://www.oracle.com/technetwork/middleware/data-integrator/overview/oracledi-comprehensive-quality-131748.pdf.
    Reference [33] Dai Wei, Wardlaw Isaac, Cui Yu, Mehdi Kashif, Li Yanyan, and Long
    Jun. 2016. Data profiling technology of data governance regarding big data: Review
    and rethinking. In Information Technology: New Generations: 13th International
    Conference on Information Technology. Springer, 439–450. Reference 1Reference
    2 [34] Dai Wei, Yoshigoe Kenji, and Parsley William. 2018. Improving data quality
    through deep learning and statistical models. In Information Technology-New Generations:
    14th International Conference on Information Technology. 515–522. Reference [35]
    Daki Houda, Hannani Asmaa El, Aqqal Abdelhak, Haidine Abdelfattah, and Dahbi Aziz.
    2017. Big Data management in smart grid: Concepts, requirements and implementation.
    J. Big Data 4, 1 (2017), 1–19. Reference [36] Dean Jeffrey and Ghemawat Sanjay.
    2008. MapReduce: simplified data processing on large clusters. Commun. ACM 51,
    1, 107–113. Reference [37] Dhayne Houssein, Haque Rafiqul, Kilany Rima, and Taher
    Yehia. 2019. In search of big medical data integration solutions—A comprehensive
    survey. IEEE Access 7 (2019), 91265–91290. Reference [38] Dmitriyev Viktor, Mahmoud
    Tariq, and Marín-Ortega Pablo Michel. 2015. Int. J. Inf. Syst. Proj. Manag. 3,
    3 (2015), 49–63. Navigate to [39] Dong Xin Luna, Berti-Equille Laure, and Srivastava
    Divesh. 2013. Data fusion: Resolving conflicts from multiple sources. Handbook
    of Data Quality: Research and Practice. Springer, 293–318. Reference 1Reference
    2 [40] Dong Xin Luna and Srivastava Divesh. 2013. Big data integration. In IEEE
    29th International Conference on Data Engineering (ICDE’13). IEEE, 1245–1248.
    Reference [41] Dragoni Nicola, Lanese Ivan, Larsen Stephan Thordal, Mazzara Manuel,
    Mustafin Ruslan, and Safina Larisa. 2018. Microservices: How to make your application
    scale. In Perspectives of System Informatics: 11th International Andrei P. Ershov
    Informatics Conference, PSI 2017, Moscow, Russia, June 27–29, 2017, Revised Selected
    Papers 11. Springer, 95–104. Reference [42] Durairaj M. and Poornappriya T. S..
    2018. Importance of MapReduce for big data applications: A survey. Asian J. Comput.
    Sci. Technol. 7, 1 (2018), 112–118. Reference [43] Ehrlinger Lisa, Werth Bernhard,
    and Wöß Wolfram. 2018. Automated continuous data quality measurement with QuaIIe.
    Int. J. Advanc. Softw. 11, 3 (2018), 400–417. Navigate to [44] Ehrlinger Lisa,
    Werth Bernhard, and Wöß Wolfram. 2018. QuaIIe: A data quality assessment tool
    for integrated information systems. In 10th International Conference on Advances
    in Databases, Knowledge, and Data Applications (DBKDA’18). 21–31. Navigate to
    [45] Ehrlinger Lisa and Wöß Wolfram. 2017. Automated data quality monitoring.
    In 22nd MIT International Conference on Information Quality (ICIQ’17). 15–1. Navigate
    to [46] Even Adir and Shankaranarayanan Ganesan. 2005. Value-driven data quality
    assessment. In International Conference on Information Quality (ICIQ’05). Navigate
    to [47] Even Adir and Shankaranarayanan Ganesan. 2007. Utility-driven assessment
    of data quality. ACM SIGMIS Datab.: DATAB. Adv. Inf. Syst. 38, 2 (2007), 75–93.
    Navigate to [48] Fadlallah Hadi, Taher Yehia, Haque Rafiqul, and Jaber Ali. 2019.
    ORADIEX: A big data driven smart framework for real-time surveillance and analysis
    of individual exposure to radioactive pollution. In International Conference on
    Big Data and Cybersecurity Intelligence (BDCSIntell’19). 52–56. Reference [49]
    Fadlallah Hadi, Taher Yehia, and Jaber Ali. 2018. RaDEn: A scalable and efficient
    radiation data engineering. In International Conference on Big Data and Cybersecurity
    Intelligence (BDCSIntell’18). 89–93. Reference [50] Salas Óscar Figuerola, Adzic
    Velibor, Shah Akash, and Kalva Hari. 2013. Assessing internet video quality using
    crowdsourcing. In 2nd ACM International Workshop on Crowdsourcing for Multimedia.
    23–28. Reference [51] Finkel Jenny Rose, Grenager Trond, and Manning Christopher
    D.. 2005. Incorporating non-local information into information extraction systems
    by Gibbs sampling. In 43rd Annual Meeting of the Association for Computational
    Linguistics (ACL’05). 363–370. Reference 1Reference 2 [52] Gao Jerry, Xie Chunli,
    and Tao Chuanqi. 2016. Big data validation and quality assuranceIssues, challenges,
    and needs. In IEEE symposium on service-oriented system engineering (SOSE16).
    433–441. Reference [53] Ge Mouzhi and Helfert Markus. 2007. A review of information
    quality research-develop a research agenda. In International Conference on Information
    Quality (ICIQ’07). 76–91. Reference 1Reference 2 [54] Gu Rong, Qi Yang, Wu Tongyu,
    Wang Zhaokang, Xu Xiaolong, Yuan Chunfeng, and Huang Yihua. 2021. SparkDQ: Efficient
    generic big data quality management on distributed data-parallel computation.
    J. ParallelDistrib. Comput. 156 (2021), 132–147. Navigate to [55] Gudivada Venkat,
    Apon Amy, and Ding Junhua. 2017. Data quality considerations for big data and
    machine learning: Going beyond data cleaning and transformations. Int. J. Advanc.
    Softw. 10, 1 (2017), 1–20. Reference [56] Gudivada Venkat N., Rao Dhana, and Grosky
    William I.. 2016. Data quality centric application framework for big data. In
    International Conference on Big Data, Small Data, Linked Data and Open Data (ALLDATA’16).
    Reference [57] Hariri Reihaneh H., Fredericks Erik M., and Bowers Kate M.. 2019.
    Uncertainty in big data analytics: Survey, opportunities, and challenges. J. Big
    Data 6, 1 (2019), 1–16. Reference [58] Hasselbring Wilhelm. 2016. Microservices
    for scalability: Keynote talk abstract. In Proceedings of the 7th ACM/SPEC on
    International Conference on Performance Engineering. 133–134. Reference [59] Hay
    Brian, Nance Kara, and Bishop Matt. 2011. Storm clouds rising: Security challenges
    for IaaS cloud computing. In 2011 44th Hawaii International Conference on System
    Sciences. 1–7. Reference [60] He Qinlu, Li Zhanhuai, and Zhang Xiao. 2010. Data
    deduplication techniques. In 2010 International Conference on Future Information
    Technology and Management Engineering 1 (2010), 430–433. Reference [61] He Qing,
    Wang Haocheng, Zhuang Fuzhen, Shang Tianfeng, and Shi Zhongzhi. 2015. Parallel
    sampling from big data with uncertainty distribution. Fuzzy Sets Syst. 258 (2015),
    117–133. Reference 1Reference 2 [62] Helfert Markus and Foley Owen. 2009. A context
    aware information quality framework. In 2009 Fourth International Conference on
    Cooperation and Promotion of Information Resources in Science and Technology.
    187–193. Navigate to [63] Hogan Aidan, Blomqvist Eva, Cochez Michael, d’Amato
    Claudia, Melo Gerard de, Gutierrez Claudio, Kirrane Sabrina, Gayo José Emilio
    Labra, Navigli Roberto, Neumaier Sebastian, et al. 2021. Knowledge graphs. ACM
    Comput. Surv. 54, 4 (2021), 1–37. Reference [64] Hosseini Kasra, Nanni Federico,
    and Ardanuy Mariona Coll. 2020. DeezyMatch: A flexible deep learning approach
    to fuzzy string matching. In Conference on Empirical Methods in Natural Language
    Processing: System Demonstrations. 62–69. Reference [65] Hoßfeld Tobias, Hirth
    Matthias, Korshunov Pavel, Hanhart Philippe, Gardlo Bruno, Keimel Christian, and
    Timmerer Christian. 2014. Survey of web-based crowdsourcing frameworks for subjective
    quality assessment. In IEEE 16th International Workshop on Multimedia Signal Processing
    (MMSP’14). 1–6. Reference [66] Ilyas Ihab F. and Chu Xu. 2019. Data Cleaning.
    ACM New York, NY. Reference 1Reference 2 [67] Immonen Anne, Pääkkönen Pekka, and
    Ovaska Eila. 2015. Evaluating the quality of social media data in big data architecture.
    IEEE Access 3 (2015), 2028–2043. Navigate to [68] Inc. Talend2022. Data Quality
    and Machine Learning: What’s the Connection? Retrieved from https://www.talend.com/resources/machine-learning-data-quality/.
    Reference [69] Informatica. 2018. Informatica Data Quality Data Sheet. Technical
    Report. Informatica. Retrieved from https://www.informatica.com/content/dam/informatica-com/en/collateral/data-sheet/en_informatica-data-quality_data-sheet_6710.pdf.
    Reference [70] Iqbal Muhammad Hussain, Soomro Tariq Rahim et al. 2015. Big data
    analysis: Apache Storm perspective. Int. J. Comput. Trends Technol. 19, 1 (2015),
    9–14. Reference [71] ISO/IEC. 2001. ISO/IEC 9126-1:2001. Software Engineering
    – Product Quality – Part 1: Quality Model. Standard. ISO/IEC. Retrieved from https://www.iso.org/standard/22749.html.
    Reference [72] ISO/IEC. 2008. 25012:2008 Software Engineering – Software Product
    Quality Requirements and Evaluation (SQuaRE) – Data Quality Model. Standard. ISO/IEC.
    Retrieved from https://www.iso.org/standard/35736.html. Reference 1Reference 2Reference
    3 [73] ISO/IEC. 2014. ISO/IEC 25000:2014. Systems and Software Engineering – System
    and Software Quality Requirements and Evaluation (SQuaRE) – Guide to SQuaRE. Standard.
    ISO/IEC. Retrieved from https://www.iso.org/standard/64764.html. Navigate to [74]
    ISO/IEC. 2015. ISO/IEC 25024:2015 Systems and Software Engineering – Systems and
    Software Quality Requirements and Evaluation (SQuaRE) – Measurement of Data Quality.
    Standard. ISO/IEC. Retrieved from https://www.iso.org/standard/35749.html. Reference
    1Reference 2 [75] ISO/IEC. 2017. ISO/IEC 15939:2017 Systems and Software Engineering
    – Measurement Process. Standard. ISO/IEC. Retrieved from https://www.iso.org/standard/71197.html.
    Reference 1Reference 2Reference 3 [76] ISO/IEC. 2020. ISO/IEC 20547-3:2020 Big
    Data Reference Architecture - Part 3: Reference Architecture. Standard. ISO/IEC.
    Retrieved from https://www.iso.org/standard/71277.html. Reference 1Reference 2Reference
    3 [77] ISO/IEC. 2022. ISO/IEC AWI 5259-1 Artificial Intelligence – Data Quality
    for Analytics and Machine Learning (ML) – Part 1: Overview, Terminology, and Examples.
    Standard. ISO/IEC. Retrieved from https://www.iso.org/standard/81088.html. Reference
    [78] ISO/TS. 2011. ISO/TS 8000-1:2011 - Data Quality - Part 1: Overview. Standard.
    ISO/TS. Retrieved from https://www.iso.org/standard/50798.html. Reference [79]
    Iverson Michael A., Ozguner Fusun, and Potter Lee C.. 1999. Statistical prediction
    of task execution times through analytic benchmarking for scheduling in a heterogeneous
    environment. In Proceedings Eighth Heterogeneous Computing Workshop (HCW’99).
    99–111. Reference [80] Ji Changqing, Li Yu, Qiu Wenming, Awada Uchechukwu, and
    Li Keqiu. 2012. Big data processing in cloud computing environments. In 2012 12th
    International Symposium on Pervasive Systems, Algorithms and Networks (2012),
    17–23. Reference 1Reference 2 [81] Kadadi Anirudh, Agrawal Rajeev, Nyamful Christopher,
    and Atiq Rahman. 2014. Challenges of data integration and interoperability in
    big data. In 2014 IEEE International Conference on Big Data (big data) (2014),
    38–40. Reference [82] Kaiser Jiří. 2014. Dealing with missing values in data.
    J. Syst. Integr. 5, 1 (2014) 42–51. Reference [83] Karami Amir, Gangopadhyay Aryya,
    Zhou Bin, and Kharrazi Hadi. 2015. A fuzzy approach model for uncovering hidden
    latent semantic structure in medical text collections. In iConference 2015. Reference
    [84] Karmakar Anurag, Raghuthaman Anaswara, Kote Om Sudhakar, and Jayapandian
    N.. 2022. Cloud computing application: Research challenges and opportunity. In
    International Conference on Sustainable Computing and Data Communication Systems
    (ICSCDS’22). IEEE, 1284–1289. Reference [85] Khayyat Zuhair, Ilyas Ihab F., Jindal
    Alekh, Madden S., Ouzzani M., Papotti Paolo, Quiané-Ruiz Jorge-Arnulfo, Tang Nan,
    and Yin Si. 2015. BigDansing: A system for big data cleansing. In SIGMOD Conference.
    Reference 1Reference 2 [86] Kim Jae Kwang and Wang Zhonglei. 2019. Sampling techniques
    for big data analysis. Int. Statist. Rev. 87 (2019), S177–S191. Reference 1Reference
    2 [87] Kontokostas Dimitris, Zaveri Amrapali, Auer Sören, and Lehmann Jens. 2013.
    TripleCheckMate: A tool for crowdsourcing the quality assessment of linked data.
    In Knowledge Engineering and the Semantic Web: 4th International Conference, KESW
    2013, St. Petersburg, Russia, October 7–9, 2013. Proceedings 4. Springer, 265–272.
    Reference [88] Kumar Pradeep, Bhatnagar Roheet, Gaur Kuntal, and Bhatnagar Anurag.
    2021. Classification of imbalanced data: Review of methods and applications. IOP
    Conference Series: Materials Science and Engineering 1099, 1 (2021), 012077. Reference
    [89] Kusumasari Tien Fabrianti et al. 2016. Data profiling for data quality improvement
    with OpenRefine. In International Conference on Information Technology Systems
    and Innovation (ICITSI’16). 1–6. Reference [90] Leung Hareton K. N.. 2001. Quality
    metrics for intranet applications. Inf. Manag. 38, 3 (2001), 137–152. Reference
    [91] Liu Zhicheng and Zhang Aoqian. 2020. Sampling for big data profiling: A survey.
    IEEE Access 8 (2020), 72713–72726. Navigate to [92] L’Heureux Alexandra, Grolinger
    Katarina, Elyamany Hany F., and Capretz Miriam A. M.. 2017. Machine learning with
    big data: Challenges and approaches. IEEE Access 5 (2017), 7776–7797. Reference
    [93] Malhotra Jyoti and Bakal Jagdish. 2015. A survey and comparative study of
    data deduplication techniques. In International Conference on Pervasive Computing
    (ICPC’15). 1–5. Reference [94] McKelvey Nigel, Curran Kevin, and Toland Luke.
    2016. The Challenges of Data Cleansing with Data Warehouses. 77–82. DOI: Reference
    [95] Mehrtak Mohammad, SeyedAlinaghi SeyedAhmad, MohsseniPour Mehrzad, Noori Tayebeh,
    Karimi Amirali, Shamsabadi Ahmadreza, Heydari Mohammad, Barzegary Alireza, Mirzapour
    Pegah, Soleymanzadeh Mahdi, et al. 2021. Security challenges and solutions using
    healthcare cloud computing. J. Med. Life 14, 4 (2021), 448. Reference [96] Merino
    Jorge, Caballero Ismael, Rivas Bibiano, Serrano Manuel, and Piattini Mario. 2016.
    A data quality in use model for big data. Fut. Gen. Comput. Syst. 63 (2016), 123–130.
    Navigate to [97] Mihindukulasooriya Nandana, García-Castro Raúl, Priyatna Freddy,
    Ruckhaus Edna, and Saturno Nelson. 2017. A linked data profiling service for quality
    assessment. In The Semantic Web: ESWC 2017 Satellite Events: ESWC 2017 Satellite
    Events, Portorož, Slovenia, May 28–June 1, 2017, Revised Selected Papers 14. Springer,
    335–340. Reference [98] Missier Paolo, Embury Suzanne, Greenwood Mark, Preece
    Alun, and Jin Binling. 2006. Quality views: Capturing and exploiting the user
    perspective on data quality. In International Conference on Very Large Data Bases.
    Reference 1Reference 2Reference 3 [99] Mousannif Hajar, Sabah Hasna, Douiji Yasmina,
    and Sayad Younes Oulad. 2014. From big data to big projects: A step-by-step roadmap.
    In 2014 International Conference on Future Internet of Things and Cloud. 373–378.
    Reference [100] Munn Zachary, Peters Micah D. J., Stern Cindy, Tufanaru Catalin,
    McArthur Alexa, and Aromataris Edoardo. 2018. Systematic review or scoping review?
    Guidance for authors when choosing between a systematic or scoping review approach.
    BMC Med. Res. Methodol. 18 (2018), 1–7. Reference [101] Mylavarapu Goutam, Thomas
    Johnson P., and Viswanathan K. Ashwin. 2019. An automated big data accuracy assessment
    tool. In IEEE 4th International Conference on Big Data Analytics (ICBDA’19). 193–197.
    Navigate to [102] Mylavarapu Goutam, Viswanathan K. Ashwin, and Thomas Johnson
    P.. 2019. Assessing context-aware data consistency. In IEEE/ACS 16th International
    Conference on Computer Systems and Applications (AICCSA’19). 1–6. Navigate to
    [103] Najafabadi Maryam M., Villanustre Flavio, Khoshgoftaar Taghi M., Seliya
    Naeem, Wald Randall, and Muharemagic Edin. 2015. Deep learning applications and
    challenges in big data analytics. J. Big Data 2, 1 (2015), 1–21. Reference 1Reference
    2 [104] Nargesian Fatemeh, Zhu Erkang, Miller Renée J., Pu Ken Q., and Arocena
    Patricia C.. 2019. Data lake management: Challenges and opportunities. Proc. VLDB
    Endow. 12, 12 (2019), 1986–1989. Reference 1Reference 2 [105] Naumann Felix. 2014.
    Data profiling revisited. ACM SIGMOD Rec. 42, 4 (2014), 40–49. Reference [106]
    Niemelä Eila, Evesti Antti, and Savolainen Pekka. 2008. Modeling quality attribute
    variability. In International Conference on Evaluation of Novel Approaches to
    Software Engineering (ENASE’08). 169–176. Reference [107] Nikiforova Anastasija
    and Bicevskis Janis. 2019. An extended data object-driven approach to data quality
    evaluation: Contextual data quality analysis. In International Conference on Enterprise
    Information Systems (ICEIS’19). 274–281. Navigate to [108] Nikiforova Anastasija,
    Bicevskis Janis, Bicevska Zane, and Oditis Ivo. 2020. User-oriented approach to
    data quality evaluation. J. Univers. Comput. Sci. 26, 1 (2020), 107–126. Navigate
    to [109] Pääkkönen Pekka and Pakkala Daniel. 2015. Reference architecture and
    classification of technologies, products and services for big data systems. Big
    Data Res. 2, 4 (2015), 166–186. Navigate to [110] Patel-Schneider Peter F.. 2015.
    Towards large-scale schema and ontology matching. Retrieved from https://www.semanticscholar.org/paper/Towards-Large-scale-Schema-And-Ontology-Matching-Patel-Schneider/ceee2bdaef83a0f09480fa6fb191cf3372137152.
    Reference 1Reference 2 [111] Pérez Beatriz, Rubio Julio, and Sáenz-Adán Carlos.
    2018. A systematic review of provenance systems. Knowl. Inf. Syst. 57 (2018),
    495–543. Reference [112] Pipino Leo L., Lee Yang W., and Wang Richard Y.. 2002.
    Data quality assessment. Commun. ACM 45, 4 (2002), 211–218. Reference [113] Price
    Rosanne, Neiger Dina, and Shanks Graeme. 2008. Developing a measurement instrument
    for subjective aspects of information quality. Commun. Assoc. Inf. Syst. 22, 1
    (2008), 3. Reference [114] Rahul Kumar and Banyal R. K.. 2019. Data cleaning mechanism
    for big data and cloud computing. In 6th International Conference on Computing
    for Sustainable Global Development (INDIACom’19). 195–198. Reference [115] Ramaswamy
    Lakshmish, Lawson Victor, and Gogineni Siva Venkat. 2013. Towards a quality-centric
    big data architecture for federated sensor services. In 2013 IEEE International
    Congress on Big Data. 86–93. Navigate to [116] Rawat R. and Yadav R.. 2021. Big
    data: Big data analysis, issues and challenges and technologies. IOP Conference
    Series: Materials Science and Engineering 1022, 1 (2021), 012014. Reference [117]
    Sadineni Praveen Kumar. 2020. Sampling based join-aggregate query processing technique
    for big data. Indian J. Comput. Sci. Eng. 11, 5, 532–546. Reference 1Reference
    2 [118] Saha Barna and Srivastava Divesh. 2014. Data quality: The other face of
    big data. In 2014 IEEE 30th International Conference on Data Engineering. 1294–1297.
    Reference 1Reference 2 [119] Schelter Sebastian, Lange Dustin, Schmidt Philipp,
    Celikel Meltem, Biessmann Felix, and Grafberger Andreas. 2018. Automating large-scale
    data quality verification. Proc. VLDB Endow. 11, 12 (2018), 1781–1794. Navigate
    to [120] Sharma Gaurav. 2021. Data Quality. Retrieved from https://www.computer.org/publications/tech-news/trends/big-data-and-cloud-computing.
    Reference [121] Siegmund Norbert, Rosenmüller Marko, Kuhlemann Martin, Kästner
    Christian, Apel Sven, Duchateau Fabien, and Fagnan Justin. 2015. Schema matching
    bibtex. In Proceedings of the VLDB Endowment. Reference 1Reference 2 [122] Software
    Calidad. 2022. ISO/IEC 25012. Retrieved from https://iso25000.com/index.php/en/iso-25000-standards/iso-25012.
    Reference 1Reference 2Reference 3 [123] Stojanović Dragan, Stojanović Natalija,
    and Turanjanin Jovan. 2015. Processing big trajectory and Twitter data streams
    using Apache STORM. (2015), 301–304. Retrieved from https://www.semanticscholar.org/paper/Schema-Matching-Bibtex-Siegmund-Rosenm%C3%BCller/a4d94ddaab429e5874386dd29822e470b57d6ee4.
    Reference [124] Strong Diane M., Lee Yang W., and Wang Richard Y.. 1997. Data
    quality in context. Commun. ACM 40, 5 (1997), 103–110. Navigate to [125] Taher
    Yehia, Haque Rafiqul, AlShaer Mohammed, Heuvel Willem Jan van den, Hacid Mohand-Saïd,
    and Dbouk Mohamed. 2016. A context-aware analytics for processing tweets and analysing
    sentiment in realtime (short paper). In On the Move to Meaningful Internet Systems:
    OTM 2016 Conferences: Confederated International Conferences: CoopIS, C&TC, and
    ODBASE 2016, Rhodes, Greece, October 24–28, 2016, Proceedings. Springer, 910–917.
    Reference 1Reference 2Reference 3 [126] Taher Yehia, Haque Rafiqul, and Hacid
    Mohand-Said. 2017. BDLaaS: Big data lab as a service for experimenting big data
    solution. In IEEE 2nd International Workshops on Foundations and Applications
    of Self* Systems (FAS* W’17). 155–159. Reference [127] Taleb Ikbal, Dssouli Rachida,
    and Serhani Mohamed Adel. 2015. Big data pre-processing: A quality framework.
    (2015), 191–198. Navigate to [128] Taleb Ikbal, Serhani Mohamed Adel, and Dssouli
    Rachida. 2018. Big data quality assessment model for unstructured data. In International
    Conference on Innovations in Information Technology (IIT’18). 69–74. Navigate
    to [129] Taleb Ikbal, Serhani Mohamed Adel, and Dssouli Rachida. 2019. Big data
    quality: A data quality profiling model. In Services–SERVICES 2019: 15th World
    Congress, Held as Part of the Services Conference Federation, SCF 2019, San Diego,
    CA, USA, June 25–30, 2019, Proceedings 15. Springer, 61–77. Reference [130] Talend.
    2020. How to Manage Modern Data Quality [White Paper]. Technical Report. Talend.
    Retrieved from https://www.talend.com/resources/definitive-guide-data-quality-how-to-manage.
    Reference [131] Talha Mohamed, Elmarzouqi Nabil, and Kalam Anas Abou El. 2020.
    Towards a powerful solution for data accuracy assessment in the big data context.
    Int. J. Advanc. Comput. Sci. Applic. 11, 2 (2020). Navigate to [132] Venkataraman
    Shivaram, Yang Zongheng, Franklin Michael, Recht Benjamin, and Stoica Ion. 2016.
    Ernest: Efficient performance prediction for large-scale advanced analytics. In
    13th USENIX Symposium on Networked Systems Design and Implementation (NSDI’16).
    363–378. Reference [133] Wang Lidong and Alexander Cheryl Ann. 2016. Machine learning
    in big data. Int. J. Math., Eng. Manag. Sci. 1, 2 (2016), 52–61. Reference [134]
    Wang Richard Y.. 1998. A product perspective on total data quality management.
    Commun. ACM 41, 2 (1998), 58–65. Reference 1Reference 2 [135] Wang Richard Y.
    and Strong Diane. 1996. Beyond accuracy: What data quality means to data consumers.
    J. Manag. Inf. Syst. 12 (1996), 5–33. Navigate to [136] Wang Xinxin, Dang Depeng,
    and Guo Zixian. 2020. Evaluating the crowd quality for subjective questions based
    on a Spark computing environment. Fut. Gen. Comput. Syst. 106 (2020), 426–437.
    Reference [137] Wei-Liang Chen, Shi-Dong Zhang, and Xiang Gao. 2009. Anchoring
    the consistency dimension of data quality using ontology in data integration.
    (2009), 201–205. Reference 1Reference 2 [138] Woodall Philip, Oberhofer Martin,
    and Borek Alexander. 2014. A classification of data quality assessment and improvement
    methods. Int. J. Inf. Qual. 3, 4 (2014), 298–321. Reference 1Reference 2 [139]
    Zaslavsky Arkady, Perera Charith, and Georgakopoulos Dimitrios. 2013. Sensing
    as a service and big data. arXiv preprint arXiv:1301.0159 (2013). Reference [140]
    Zaveri Amrapali, Kontokostas Dimitris, Sherif Mohamed A., Bühmann Lorenz, Morsey
    Mohamed, Auer Sören, and Lehmann Jens. 2013. User-driven quality evaluation of
    DBpedia. In 9th International Conference on Semantic Systems. 97–104. Reference
    [141] Zhang Pengcheng, Zhou Xuewu, Li Wenrui, and Gao Jerry. 2017. A survey on
    quality assurance techniques for big data applications. (2017), 313–319. Reference
    [142] Zhang Zhenrong, Zhang Jianshu, Du Jun, and Wang Fengren. 2022. Split, embed
    and merge: An accurate table structure recognizer. Pattern Recognit. 126 (2022),
    108565. Reference [143] Zhou Lina, Pan Shimei, Wang Jianwu, and Vasilakos Athanasios
    V.. 2017. Machine learning on big data: Opportunities and challenges. Neurocomputing
    237 (2017), 350–361. Reference 1Reference 2 Figures Fig. 1. Articles distribution
    over the years. Open in Figure Viewer Fig. 2. Methodological framework architecture.
    Open in Figure Viewer Fig. 3. Methodological framework components mapped to the
    ISO/IEC 20547 big data reference architecture. Open in Figure Viewer Table 1.
    Classification of the Publications Discussed in This Review Open in Table Viewer
    Table 2. Literature Summarization Open in Table Viewer Table 3. Classification
    Approaches Used in Data Quality Models Open in Table Viewer Table 4. Data Quality
    Characteristics Used in the Literature Open in Table Viewer Table 5. Knowledge
    Extraction Techniques Based on the Data Format Open in Table Viewer Share this
    Publication link https://dl.acm.org/doi/10.1145/3603707 Copy Link Share on Social
    Media Share on Twitter LinkedIn Reddit Facebook Email 143 References View Issue’s
    Table of Contents Footer Categories Journals Magazines Books Proceedings SIGs
    Conferences Collections People About About ACM Digital Library ACM Digital Library
    Board Subscription Information Author Guidelines Using ACM Digital Library All
    Holdings within the ACM Digital Library ACM Computing Classification System Digital
    Library Accessibility Join Join ACM Join SIGs Subscribe to Publications Institutions
    and Libraries Connect Contact Facebook Twitter Linkedin Feedback Bug Report The
    ACM Digital Library is published by the Association for Computing Machinery. Copyright
    © 2024 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics'
  inline_citation: '>'
  journal: ACM journal of data and information quality (Online)
  limitations: '>'
  pdf_link: null
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: 'Context-aware Big Data Quality Assessment: A Scoping Review'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/s22051693
  analysis: '>'
  authors:
  - Leonildo de Melo de José Azevedo
  - Júlio Cézar Estrella
  - Alexandre C. B. Delbem
  - Rodolfo I. Meneguette
  - Stephan Reiff-Marganiec
  - Sidgley Camargo de Andrade
  citation_count: 0
  full_citation: '>'
  full_text: ">\n\x01\x02\x03\x01\x04\x05\x06\a\b\x01\n\x01\x02\x03\x04\x05\x06\a\n\
    Citation: de Azevedo, L.J.d.M.;\nEstrella, J.C.; Delbem, A.C.B.;\nMeneguette,\
    \ R.I.; Reiff-Marganiec, S.;\nde Andrade, S.C. Analysis of\nSpatially Distributed\
    \ Data in Internet\nof Things in the Environmental\nContext. Sensors 2022, 22,\
    \ 1693.\nhttps://doi.org/10.3390/s22051693\nAcademic Editors: Fangyu Li and\n\
    Naveen Chilamkurti\nReceived: 17 October 2021\nAccepted: 21 December 2021\nPublished:\
    \ 22 February 2022\nPublisher’s Note: MDPI stays neutral\nwith regard to jurisdictional\
    \ claims in\npublished maps and institutional afﬁl-\niations.\nCopyright:\n© 2022\
    \ by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an open\
    \ access article\ndistributed\nunder\nthe\nterms\nand\nconditions of the Creative\
    \ Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n\
    4.0/).\nsensors\nArticle\nAnalysis of Spatially Distributed Data in Internet of\
    \ Things in\nthe Environmental Context\nLeonildo José de Melo de Azevedo 1,*\n\
    , Júlio Cezar Estrella 1\n, Alexandre C. B. Delbem 1\n,\nRodolfo Ipolito Meneguette\
    \ 1\n, Stephan Reiff-Marganiec 2\nand Sidgley Camargo de Andrade 3\n1\nInstitute\
    \ of Mathematics and Computer Science, University of São Paulo, Sao Paulo 13560-970,\
    \ SP, Brazil;\njcezar@icmc.usp.br (J.C.E.); acbd@icmc.usp.br (A.C.B.D.); meneguette@icmc.usp.br\
    \ (R.I.M.)\n2\nSchool of Electronics, Computing and Maths, University of Derby,\
    \ Kedleston Rd., Derby DE22 1GB, UK;\nS.Reiff-Marganiec@derby.ac.uk\n3\nComputing\
    \ Department, Federal University of Technology—Paraná, R. Cristo Rei, 19,\nToledo\
    \ 85902-490, PR, Brazil; sidgleyandrade@utfpr.edu.br\n*\nCorrespondence: leonildo.azevedo@usp.br\n\
    Abstract: The Internet of Things consists of “things” made up of small sensors\
    \ and actuators capable\nof interacting with the environment. The combination\
    \ of devices with sensor networks and Internet\naccess enables the communication\
    \ between the physical world and cyberspace, enabling the develop-\nment of solutions\
    \ to many real-world problems. However, most existing applications are dedicated\n\
    to solving a speciﬁc problem using only private sensor networks, which limits\
    \ the actual capacity\nof the Internet of Things. In addition, these applications\
    \ are concerned with the quality of service\noffered by the sensor network or\
    \ the correct analysis method that can lead to inaccurate or irrelevant\nconclusions,\
    \ which can cause signiﬁcant harm for decision makers. In this context, we propose\
    \ two\nsystematic methods to analyze spatially distributed data Internet of Things.\
    \ We show with the results\nthat geostatistics and spatial statistics are more\
    \ appropriate than classical statistics to do this analysis.\nKeywords: Internet\
    \ of Things; quality of data; data analyze; geostatistics; spatial statistics\n\
    1. Introduction\nNowadays, it is possible to easily access services and data through\
    \ the Internet from\nany place and at any moment. It can be observed from recent\
    \ decades that computational re-\nsources are becoming increasingly accessible\
    \ and more powerful. Furthermore, the number\nof devices connected at the Internet\
    \ has increased exponentially increase and is projected\nto amount to 75.44 billion\
    \ worldwide by 2025 (https://www.statista.com/statistics/47\n1264/iot-number-of-connected-devices-worldwide/\
    \ (23 November 2020)). According to\nCisco Annual Internet Report (2018–2023)\
    \ (https://www.cisco.com/c/en/us/solutions/\ncollateral/executive-perspectives/annual-internet-report/white-paper-c11-741490.html),\n\
    the number of devices connected to Internet Protocol (IP) networks will be more\
    \ than\nthree times the global population by 2023. However, these numbers only\
    \ refer to devices\nsuch as computers, smartphones, and tablets; if considered\
    \ other devices such as sensors,\nthis number would be double easily. With many\
    \ connections, devices communicating with\nhumans and other devices have enabled\
    \ the development of a paradigm called the Internet\nof Things (IoT) [1].\nIoT\
    \ involves anything with network access, for instance, sensors to advise on localized\n\
    fertilizer amounts or targeted pesticide use, self-monitoring health systems,\
    \ air quality,\nand trafﬁc routing [2,3]. These sensors have the ability to transfer\
    \ data over a network\nwith or without requiring humans, and these data can be\
    \ provided in many forms, such as\nstreaming and discrete data, images, and social\
    \ media, among others. The combination of\nsensors network with the Internet enables\
    \ the communication between the virtual and the\nreal world, allowing the decision-making\
    \ without human intervention.\nSensors 2022, 22, 1693. https://doi.org/10.3390/s22051693\n\
    https://www.mdpi.com/journal/sensors\nSensors 2022, 22, 1693\n2 of 21\nAccording\
    \ to economic analysis from Cisco, “IoT will generate $8 trillion worldwide\n\
    in Value at Stake over the next decade. This will come from ﬁve primary drivers:\
    \ innova-\ntion and revenue ($2.1 trillion); asset utilization ($2.1 trillion);\
    \ supply chain and logistics\n($1.9 trillion); employee productivity improvements\
    \ ($1.2 trillion); and enhanced customer\nand citizen experience ($700 billion)”\
    \ (https://newsroom.cisco.com/press-release-content?\narticleId=1621819). By not\
    \ considering many factors that involve quality of service or even\na correct\
    \ data analysis, it can probably cause ﬁnancial losses to organizations. Some\
    \ real\ncases can be cited, such as the following: (1) Gartner has an annual cost\
    \ because of poor\ndata in 2014 on average of $13.3 million dollars [4]; (2) The\
    \ US Postal Service has ﬁnance\nlosses over $1.5 billion due to mail with wrong\
    \ data [5]. The US economy has ﬁnance losses\nof over $3 trillion a year [6].\n\
    The problem of data quality becomes complex and controversial with technology\n\
    evolution. With signiﬁcant ﬁnancial losses caused by weak data, these problems\
    \ have\nbecome the focus of much research from many perspectives. However, most\
    \ of these works\nare dedicated to solving a speciﬁc problem in a particular environment.\
    \ With close ﬂow,\nit is difﬁcult to consider the real capacity of IoT, since\
    \ there is no sharing of information.\nFurthermore, another problem is the accuracy\
    \ of data quality in decision-making.\nThe data quality and data accuracy are\
    \ also related to the data analysis [7–9]; i.e., an\nincorrect data visualization\
    \ or wrong method analysis could lead to misinterpretations\nor wrong decision\
    \ making, even if the data are collected correctly. In this context, this\narticle\
    \ puts forward a systematic approach to support the data analysis by considering\n\
    the sensor spatiality factor and geographic aspects. To validate this approach,\
    \ we applied\nthe methods on an extensive real-world database from the United\
    \ States Environmental\nProtection Agency (US EPA), speciﬁcally involving air\
    \ quality data; we describe the dataset\nin Section 4. The main contributions\
    \ of the paper are as follows:\n•\nA data analysis approach for outdoor sensors\
    \ based on geostatistic data: a non-classic\nstatistical approach to IoT data\
    \ analysis, which it is not used on the majority works,\ndue to the data limitation,\
    \ the scenario space of the analysis, and the fact that the data\nare not from\
    \ the real world;\n•\nA data analysis approach for outdoor sensors based on spatial\
    \ statistics: like the above-\nmentioned approach, however, here we analyze data\
    \ in a discrete space (delimited by\na boundary), and in geostatistic data, it\
    \ considers a continuous geographic area;\n•\nA structuring of several methods\
    \ from geostatistics and spatial statistics aggregated\nwith a multicriteria analysis\
    \ to compose a systematic data analysis on outdoor sensors:\nthis is our main\
    \ contribution, where we structured an outdoor sensors’ data analysis\napproach\
    \ considering the geographic data dispersion and conﬂicted indicators;\n•\nAn\
    \ assessment of the proposed method and comparing other works that apply classi-\n\
    cal statistics.\nThe rest of the paper is organized as follows. In Section 2,\
    \ is works related to IoT\ndata quality and data analysis. Section 3 introduces\
    \ essential concepts to the method.\nThe proposed method analysis is described\
    \ in Section 4. A case study to apply the methods\nis presented in Section 5.\
    \ The application and comparison with the existing techniques are\ndescribed in\
    \ Section 6. Finally, Section 7 discusses the outcomes and recommendations for\n\
    further work.\n2. Related Works\nThe Internet of Things is a highly scalable environment\
    \ in which the data generated\nare tremendous. Thus, the quality of information\
    \ is becoming an issue of great interest\nin both the academic and the industrial\
    \ worlds. In this section, we discuss some of the\nworks related to data quality\
    \ in IoT. Moreover, we also discuss the practices related to the\napplication\
    \ domain of this paper and the related works to the methods that we proposed\n\
    as a solution to make the best data analysis with spatially distributed data.\n\
    Sensors 2022, 22, 1693\n3 of 21\n2.1. Data Quality in Internet of Things\nThere\
    \ are many works in the literature that address quality of service and data ma-\n\
    nipulation in IoT. For instance, some works apply a publish–subscribe methodology\
    \ to\nsimplify the integration between sensors and the cloud [10–12]. However,\
    \ these solutions\ndo not assess the accuracy of the data or the analysis.\nOther\
    \ works try to apply particular solutions, such as a model-driven framework, to\n\
    data quality management [13], and a Blockchain-based approach was attempted in\
    \ [14].\nThese solutions aim to improve IoT data quality and false data detection.\
    \ On the other\nhand, the solutions are applied in speciﬁc architectures and do\
    \ not present a robust analysis\nof the generated data.\nThere are some authors\
    \ who propose solutions on ontology-based [15,16], where they\nhad a focus on\
    \ identifying missing data or using the quality of information as an indicator\n\
    of IoT trust [15]. Although these solutions even present a math solution model,\
    \ they do\nnot present an assessment or application evaluation of the real-world\
    \ environment or even\nreal data.\nIn [17], the authors propose an attractive\
    \ solution for data cleaning by an incorrect\ndata detection method based on an\
    \ improved local outlier factor. Although the proposed\nmethod was used to detect\
    \ inaccurate data from ofﬂine data, the solution achieved excellent\nperformance\
    \ to identify poor data. However, this solution identiﬁes the incorrect data only\n\
    from the collection point and does not consider the visualization or analysis\
    \ method.\nAnother work with a similar proposal is [18], where the authors developed\
    \ a data\nquality analysis and cleaning strategy for wireless sensor networks.\
    \ For this, the authors\nstudied the impact of the relationship between different\
    \ indicators on the quality assessment\nduring data cleaning. Although the authors\
    \ performed some simulations, they did not\nevaluate the solution in a real-world\
    \ environment; moreover, just like the previous work,\nthey considered only the\
    \ data from the sensor’s point.\nThere are also several other works related to\
    \ the quality of data originating from the\nsensors [19–21]. In [19], the authors\
    \ designed a prototypical implementation of a distributed\nIoT middleware layer\
    \ to manage heterogeneous data sources. In [20], the authors propose\nan altruistic\
    \ approach to data quality assessment for sensor data. Furthermore, in [21],\n\
    the authors present a framework to evaluate and control data quality aspects when\
    \ dealing\nwith social and sensor data. However, all of these works address only\
    \ the data quality in\nthe collection point and speciﬁc scenarios; our proposal\
    \ aims to show how to visualize and\nbuild a correct analysis with IoT spatially\
    \ distributed data.\nThe authors of [7], speciﬁcally disucss the state of the\
    \ art of the data quality of the\nInternet of Things. According to [7], the data\
    \ generated in global scale deployment are\ntremendous, and there are many open\
    \ challenges related to data quality. The authors also\npresented a detailed survey\
    \ about quality features and the signiﬁcance of a robust and\naccurate data analysis.\
    \ In this paper, we apply geostatistics and spatial statistics to make a\nprecise\
    \ data analysis in IoT on the environmental context.\n2.2. Environment and Pollution\
    \ Context in IoT\nTo evaluate our proposal, we applied the methods on an extensive\
    \ real-world IoT\ndatabase from the United States Environmental Protection Agency\
    \ (USEPA), which we\ndescribed in Section 4. Notably, the environment subject\
    \ is also a relevant research topic.\nFor this reason, we also researched in the\
    \ literature on how the data are analyzed in\nthis ﬁeld.\nExciting work in this\
    \ ﬁeld analyzed the impact of COVID-19 on people’s lives and\nthe natural environment\
    \ [22]. For this purposed, the authors investigate the spatial and\ntemporal characteristics\
    \ of the Air Quality Index (AQI) before and during the pandemic in\nmainland China.\
    \ The authors present several analyses with respect to this theme; however,\n\
    all of them apply classical statistical analysis. In this paper, we show that\
    \ IoT spatially\ndistributed data request a different interpretation.\nSensors\
    \ 2022, 22, 1693\n4 of 21\nThere also other works that utilized the USEPA dataset\
    \ to analyze the environmental\ncontext [23,24]. In [23], the authors conducted\
    \ a comparative study of AQI based on factor\nanalysis and USEPA methods for an\
    \ urban environment. Furthermore, in [23], the authors\ndid not use the USEPA\
    \ but used the same recommended method for health risk assessment\nin a similar\
    \ dataset in China. In both works, the authors used traditional statistics to\
    \ analyze\nspeciﬁc points, which could not show the real context of the region.\n\
    In the same ﬁeld, there is a project being conducted at the Alan Turin Institute\
    \ called\nLondon Air Quality (https://www.turing.ac.uk/research/research-projects/london-air-\n\
    quality). This project utilizes city-wide air quality sensors to develop solutions\
    \ to un-\nderstand and improve air quality over London. This group’s research\
    \ has achieved im-\npressive results by applying machine learning algorithms and\
    \ proposing data science\nplatforms [25–30]. In this paper, we propose a different\
    \ solution by spatial autocorrelation\nanalysis, focusing on data analysis and\
    \ data visualization.\n2.3. Spatial Autocorrelation\nSpatial autocorrelation is\
    \ an association indicator from Geographic Information Science\n(GIScience) [31,32];\
    \ we discuss this in Section III. This theme has been subject of many\nstudies\
    \ [33]. In [34], the authors discuss the big spatiotemporal data analytics as\
    \ a research\nand innovation frontier, and one of the ﬁelds that is considered\
    \ promising is the IoT.\nThere are in the literature some authors who propose\
    \ applying geostatistics in the IoT\nenvironment in many different ways [35–37].\
    \ However, these works do not demonstrate\nthe application method with concrete\
    \ results, and they also do not propose a systematic\nway to apply the techniques—some\
    \ of them only discuss the potential.\nIn a recent study [38], the authors investigated\
    \ rainfall-related tweets to determine\nthe areal units that optimize spatial\
    \ autocorrelation patterns through the combined use of\nindicators of global spatial\
    \ autocorrelation and the variance of local spatial autocorrelation.\nIn our study,\
    \ we propose using the same technique to scale the ideal areal units to analyze\n\
    the data.\nIn this paper, we propose a systematic approach to support the data\
    \ analysis and the\ndecision makers by considering the sensor spatiality factor\
    \ and geographic aspects. For this\npurpose, we applied methods from the spatial\
    \ statistics and geostatistic ﬁelds.\n2.4. Proposal Highlight\nTo highlight our\
    \ contribution, we present in Table 1 the main features of the related\nworks,\
    \ with the following columns:\n•\nRelated work: reference to the related work\
    \ addressed;\n•\nEnvironment: the experimental environment, either Real world\
    \ (e.g., a prototype) or\nSimulator (i.e., a simulated experiments in a ﬁctitious\
    \ environment);\n•\nSpatial: whether the approach considers the spatial dispersion\
    \ in the analysis;\n•\nQoD: whether the approach considers the QoD attributes\
    \ in the data analysis;\n•\nMulti-criteria analysis: whether the approach treats\
    \ the problem as a multi-objective\nproblem and/or considers any conﬂicting objectives.\n\
    By analyzing Table 1, we can observe that our proposal focuses on accurate analysis.\n\
    For this purpose, we use only real-world data to validate our method, geostatistics\
    \ and\nspatial statistics to consider the spatial data dispersion, and a multicriteria\
    \ analysis to\nresolve the conﬂicting objectives. We present the results below.\n\
    Sensors 2022, 22, 1693\n5 of 21\nTable 1. Main features of the related works.\n\
    Related Work\nEnvironment\nQoD\nMulti-Criteria Analysis\nSpatial\nAntonic, A.\
    \ et al. [10]\nSimulator\nX\nX\nX\nAlam, S. and Noll, J. A. [11]\nSimulator\n\
    X\nX\nX\nKothari, A. et al. [12]\nSimulator\n√\nX\nX\nKarkouch, A. et al. [13]\n\
    Simulator\nX\nX\nX\nXu, X.; Lei, Y.; and Li, Z. [17]\nReal World\n√\nX\nX\nCheng,\
    \ H. et al. [18]\nSimulator\n√\nX\nX\nLiu, Q. [22]\nReal World\nX\nX\nX\nLi, Z.\
    \ et al. [24]\nReal World\nX\nX\nX\nHabibia, R. [37]\nSimulator\nX\nX\n√\nde Andrade,\
    \ S.C. et al. [38]\nReal World\nX\n√\n√\nThis paper\nReal world\n√\n√\n√\n3. Geographic\
    \ Information Science\nSpatial statistics and geostatistics are methods from the\
    \ Geographic Information\nScience (GIScience) ﬁeld that encompass a wide array\
    \ of disciplines, such as geography,\ncartography, geodesy, statistics, and computer\
    \ science. GIScience considers the nature of\ngeographic information to develop\
    \ theories and methods for understanding geographic\nprocesses, relationships,\
    \ and patterns at different geographical scales [31,32]. GIScience\nalso includes\
    \ social disciplines that address issues and impacts on society.\n3.1. Spatial\
    \ Data Analysis\nIn the GIScience ﬁeld, the spatial data analysis is consider\
    \ a central topic. It deals\nwith “a collection of techniques and models that\
    \ explicitly use the spatial referencing asso-\nciated with each data value or\
    \ object that is speciﬁed within the system under study” [39].\nThese methods\
    \ are crucial to assess spatial relationships and assumptions in spatially\ndistributed\
    \ data.\nThere are two fundamental concepts in spatial data analysis: (1) spatial\
    \ autocorrelation,\nwhich refers to the degree of dependence from similar objects\
    \ near to others, and (2) spatial\nheterogeneity, which is related to structure\
    \ of these objects [40]. Analyzing these concepts\nmakes it possible to answer\
    \ questions such as “how much does the economics of one\nneighborhood inﬂuence\
    \ another?” and we also hope to answer the questions “what is the\ncorrect areal\
    \ unit to analyze a set of sensors?” and “How can spatially distributed data be\n\
    analyzed?”\n3.2. Spatial Autocorrelation\nThe geography scale, aggregation, and\
    \ detail level are essential to construct an appro-\npriate representation of\
    \ the world, i.e., according to the process of handling the aggregation\nof delimited\
    \ the unit spaces, the data could show different values and interpretations [40].\n\
    In this context, different measures from the real world can covariate, and understanding\n\
    the spatial correlation essence could help to understand the analyzed phenomena\
    \ better.\nSpatial autocorrelation is directly related with the ﬁrst law of geography\
    \ or Tobler’s\nlaw, which says “everything is related to everything else, but\
    \ near things are more related\nthan distant things” [41]. This law is a fundamental\
    \ premise for spatial statistics, and could\nalso be interpreted as a deﬁnition\
    \ for the positive spatial autocorrelation. The opposite of\nthe law implies a\
    \ negative spatial autocorrelation when places close to each other have\nhigh\
    \ spatial heterogeneity.\nThe interrelation between the features of a location\
    \ is an essential aspect of the geogra-\nphy data, which is crucial for real-world\
    \ comprehension [42]. However, this interrelation is\na challenge for classic\
    \ statistics due to the majority method to consider the independence of\nthe observations\
    \ without spatial correlation.\nSensors 2022, 22, 1693\n6 of 21\n4. Methods\n\
    To analyze spatially distributed data in IoT, we propose the use of two methods\
    \ from\nthe GIScience ﬁeld. The ﬁrst one (statistical spatial) is a framework\
    \ proposed by [38] based\non Moran’s index [43], and the second one (geostatistic)\
    \ is an interpolation method for a\ncorrect data visualization [44]. Table 2 describes\
    \ the main variables used in this work.\nTable 2. List of important notation.\n\
    Term\nDescription\nwij\nmatrix unit weight\nyi\nthe value of interest on location\n\
    y\nthe mean of interest on location\nn\nthe total observations\nI\nthe Moran’s\
    \ index\nIi\nthe Moran’s LISA for each map unit\nX\na set of any areal units with\
    \ different levels of data aggregation\nφ\nobjective functions\nZ(Si)\na known\
    \ value at the location\nλi\nan unknown weight for the measured value at the location\n\
    S0\nthe location with data unknown to prediction\nN\nthe number of measured values\n\
    4.1. A Framework to Deﬁnition of the Spatial Granularity\nTo measure the spatial\
    \ autocorrelation level, it is possible to use an index that may\nvary between\
    \ 1 and −1: 1 for the high positive spatial autocorrelation, −1 for high negative\n\
    spatial autocorrelation, and 0 for the absence of spatial autocorrelation [45].\n\
    There are two types of indexes for this association: a global and other local.\
    \ The global\ncoefﬁcient correlation measures the overall spatial autocorrelation\
    \ of the data set, with only\none index value. On the other hand, the local indicator\
    \ of spatial autocorrelation (LISA)\nmeasures different levels of spatial relationships;\
    \ it depends on the scale deﬁned, such as\ndistrict, county, state, country, etc.\n\
    The most common global and local indexes are calculated by Moran’s I. The global\n\
    Moran’s I is the result of the Equation (1) [46].\nI =\nn\n∑n\ni ∑n\nj wij\n·\n\
    ∑n\ni ∑n\nj wij(yi − y)(yj − y)\n∑n\ni (yi − y)2\n(1)\nwhere\nwij, is the matrix\
    \ unit weight, wij = 1 if i and j are neighbors, and wij = 0 otherwise;\nyi and\
    \ y represent the value and the mean of interest on location i;\nn is the total\
    \ observations; and, I is the Moran’s index, a metric used to test the hypothesis\n\
    about spatial autocorrelation.\nThe Moran’s I aims to test the spatial independence\
    \ (null hypothesis). In this context,\nthe null hypothesis is true if its value\
    \ is zero. Positive values, between 0 and 1, point to a\npositive autocorrelation,\
    \ and negative values, between 0 and −1, indicate negative autocor-\nrelation.\n\
    This local indicator utilization together with the global index improves knowledge\n\
    about the process from which the spatial dependence originates. The LISA makes\
    \ a speciﬁc\nvalue for each object, which can identify clusters, outliers, and\
    \ the existence of more than\none spatial pattern.\nSensors 2022, 22, 1693\n7\
    \ of 21\nAccording to [46], a LISA should adhere to two objectives: (1) to allow\
    \ the identiﬁcation\nof signiﬁcant spatial associate patterns and (2) to be a\
    \ decomposition from the global spatial\nassociation index. Equation (2) show\
    \ Moran’s LISA calculation.\nIi =\n(yi − y) ∑n\nj=1 wij(yj − y)\n∑n\ni=1(yi−y)2\n\
    n\n(2)\nwhere\nwij, is the matrix unit weight, wij = 1 if i and j are neighbors,\
    \ and wij = 0 otherwise;\nyi and y represent the value and the mean of interest\
    \ on location i;\nn is the total observations; and, Ii is the Moran’s LISA for\
    \ each map unit.\nIn Equation (2), an Ii > 0 means that i has values very similar\
    \ to its neighbors (positive\nspatial autocorrelation), and Ii < 0 means that\
    \ i has different values from the neighbors\n(negative spatial autocorrelation).\
    \ Furthermore, analogously to the global indicators,\nthe Moran’s LISA should\
    \ be evaluated by the pseudo-signiﬁcance test.\nAs demonstrated in [38], the determination\
    \ of an optimal areal unit for spatial analysis\nis a complex task owing to the\
    \ Modiﬁable Areal Unit Problem (MAUP) effects, differences in\nthe ﬁelds of application,\
    \ and uncertainties and conﬂicts arising from the different potential\nspatial\
    \ indicators to be used. For this reason, it is necessary to select the candidate\
    \ solution\n(optimal areal unit) by a Pareto ranking [47].\nTo apply Pareto ranking\
    \ in this framework [38], in order to model a solution, let X be\na set of any\
    \ areal units with different levels of data aggregation. Each spatial granularity\n\
    of aggregation x ∈ X is characterized by different criteria that will be optimized\
    \ by a set\nof objective functions; in this case, the global and local indexes.\
    \ A vector containing m\nobjective functions φm can be represented by\nΦ(x) =\
    \ [φ1(x), φ2(x), · · · , φm(x)] ∈ Rm\n(3)\nA Pareto-optimal solution only contains\
    \ areal units that are not Pareto-dominated by\nany other areal unit [38]. In\
    \ general terms, an areal unit xi ∈ X dominates another xj ∈ X\nwhen it has satisﬁed\
    \ the following two constraints:\n(i)\n∀φ ∈ Φ : φ(xi) ⪯ φ(xj), and\n(ii)\n∃φ ∈\
    \ Φ : φ(xi) ≺ φ(xj)\nwhere ≺ and ⪯ correspond to the ‘general better’ and ‘better\
    \ or equal’ relations, depending\non whether the objective function refers to\
    \ maximization or minimization. It is possible\nto obtain more than one Pareto\
    \ Frontier according to the ranking or even two or more\nsolutions in the Pareto-optimal\
    \ areal units; in this case, additional human expertise is\nrequired for the selection\
    \ of a proper areal unit.\nIn Algorithm 1, we present a systematic way to use\
    \ this framework. First, we provide\nthe input data (line 1); in this paper, we\
    \ use a pollution data set described in Section 5.\nThe ﬁrst step of the method\
    \ is to model the candidate’s areal unit solution, and here it\ndeﬁnes the size\
    \ of the areal unit to make the data aggregation (line 3). In the second step\n\
    (line 4), it assesses the candidate’s areal unit by the deﬁned criteria; in this\
    \ case, they are\nthe global and local autocorrelation index (Global Moran’s I\
    \ and the coefﬁcient of variation\nof Local Moran’s I, respectively). The last\
    \ step is to select an “optimal” areal unit from the\nnon-dominated Pareto frontier\
    \ (line 5).\n4.2. Data Interpolation\nFor a coherent data visualization and correct\
    \ data measure, we apply a data interpola-\ntion method, namely Kriging [44].\
    \ This technique is a regression method from geostatistic\nto data interpolation,\
    \ i.e., to estimate values in unknown data points. In Figure 1, we show\nan example\
    \ situation, where we would like to know the temperature from a local that does\n\
    not have spatial information available.\nSensors 2022, 22, 1693\n8 of 21\nAlgorithm\
    \ 1 Multicriteria for the selection of an optimal areal unit\n1: Input data: pollution\
    \ data at an individual level (the pollution data in our application)\n2: for\
    \ each areal unit on set of criteria, do\n3:\nModeling of candidate areal unit\n\
    4:\nEvaluation of an candidate areal unit (MCDA)\n5:\nSelection of the optimal\
    \ areal unit (non-dominated solution)\n6: end for\n7: return Optimal areal unit\n\
    Figure 1. Example of the need to estimate a value that does not have spatial information\
    \ available.\nThere are many other data interpolation techniques in the GIScience\
    \ ﬁeld [42]. How-\never, the Kriging method allows for incorporating three factors\
    \ to improve the estimation\naccuracy: (1) local ﬂuctuation, which makes it possible\
    \ to analyze the spatial autocorrela-\ntion during the data interpolation; (2)\
    \ noise, which makes it possible to identify random\nchanges space independent,\
    \ i.e., detect errors in the collected data; and (3) incorporating\ngeneral trends\
    \ as an auxiliary variable, e.g., using a model with similar behavior to help\
    \ in\nthe estimation. More details about any of those factors can be found in\
    \ [42].\nKriging’s technique measures the surrounding values to derive a prediction\
    \ for a\nlocation with unknown data. The Kriging interpolation formula is formed\
    \ as a weighted\nsum of the data, as described in Equation (4).\nˆZ(S0) =\nN\n\
    ∑\ni=1\nλiZ(Si)\n(4)\nwhere\nZ(Si) is a known value at the location i,\nλi is\
    \ an unknown weight for the measured value at the location i,\nS0 is the location\
    \ with data unknown to the prediction, and\nN is the number of measured values.\n\
    In the Kriging method, the λi is dependent on a ﬁtted model to the value locations,\n\
    the spatial relationship among the known values that surround the prediction location,\n\
    and the distance from the known points to the prediction location. Therefore,\
    \ it is necessary\nto create the variograms and covariance functions to estimate\
    \ the statistical dependence to\nmake a ﬁtted model to the measured points. Details\
    \ about the ﬁtted model features, as well\nthe variograms and covariance functions,\
    \ can be found in [42].\nWe show in Figure 2 the systematic way that apply the\
    \ Kriging interpolation in\nthe IoT context. First, we normalize the input data\
    \ and build a shapeﬁle from the local\narea; the map is only for visualization.\
    \ The second step is to model the variogram (i.e.,\nSensors 2022, 22, 1693\n9\
    \ of 21\nto construct the ﬁtted model) and then apply the Kriging method. The\
    \ last step is to make\nthe map interpolation.\nTo normalize the data values,\
    \ we use the bestNormalize (https://cran.r-project.org/\nweb/packages/bestNormalize/index.html)\
    \ package from the R language. Furthermore,\nwe developed all of the systematic\
    \ methods in R, which are available in https://github.\ncom/Leonild/SpatialDataAnalysis.\n\
    To normalize the\nvalues\nTo create a map\nfrom the location\nTo build the fitted\n\
    model\nTo make the map\ninterpolation\nTo apply the\nKriging method\nFigure 2.\
    \ A systematic way that we use to apply the Kriging interpolation on the IoT context.\n\
    5. Case Study\nIn recent years, high levels of pollution in speciﬁc dry periods\
    \ of the year have\nforced authorities to rethink the organizational strategy\
    \ of cities and propose drastic\nchanges in urban centers. According to the World\
    \ Health Organization (WHO) (https:\n//www.who.int/), half of the world’s population\
    \ lives in urban centers, and the estimate\nfor 2050 is that 70% of the population\
    \ will be urban [48]. This means that urban development\nwill have a direct impact\
    \ on human health.\nHuman health is affected by several correlated factors, factors\
    \ that go beyond the\npower of health agencies. These include residences, sanitation,\
    \ transportation, the energy\nsystem, and parks with green spaces, in addition\
    \ to decent jobs, education, and healthy\nfood [49].\nWith population growth,\
    \ by 2050, it is estimated that 2.5 billion people will inhabit\ncities in addition\
    \ to those who already inhabit them. This presents a unique opportunity to\nplan\
    \ cities that protect and promote public health through well-structured organization.\n\
    In this context, pollution has drawn a great deal of attention, causing irreversible\
    \ damage to\nthe planet, as well as global warming, respiratory diseases, and\
    \ extinction of microbiomes,\namong others [50,51].\nTo assess our approach in\
    \ this context, we chose an extensive real-world IoT database\nto analyze. This\
    \ database is from the United States Environmental Protection Agency\n(US-EPA)\
    \ (https://www.epa.gov/) (download available at aqs.epa.gov/aqsweb/airdata/\n\
    download_ﬁles.html), which has millions of records (updated daily with new data)\
    \ to\nfour pollutants, Nitrogen Dioxide (NO2), Sulfur Dioxide (SO2), Carbon Monoxide\
    \ (CO),\nand Ozone (O3). The database contains 28 ﬁelds described in Table 3.\
    \ These data come\nSensors 2022, 22, 1693\n10 of 21\nfrom sensors around all US\
    \ countries from the years 2000 until the present. We show in\nFigure 3 the position\
    \ of the sensors in 2020, including information about SO2.\nFigure 3. Positions\
    \ of sensors, which collect information about SO2. Source: epa.gov/outdoor-air-\n\
    quality-data/interactive-map-air-quality-monitors.\nTable 3. Description of the\
    \ EPA database 28 ﬁelds.\nDatabase Fields\n1\nIndex\n15\nO3 Unit\n2\nState Code\n\
    16\nO3 1st Max Value\n3\nCounty Code\n17\nO3 1st Max Hourn\n4\nSite Num (Local\
    \ in a county)\n18\nO3 AQI\n5\nAdress (Street, number. . . )\n19\nSO2 Units (description)\n\
    6\nState (name)\n20\nSO2 Mean\n7\nCounty (name)\n21\nSO2 1st Max Value\n8\nCity\
    \ (name)\n22\nSO2 1st Max Hourn\n9\nDate Local\n23\nSO2 AQI\n10\nNO2 Units (description)\n\
    24\nCO Units (description)\n11\nNO2 Mean\n25\nCO Mean\n12\nNO2 1st Max Value\n\
    26\nCO 1st Max Value\n13\nNO2 1st Max Hourn\n27\nCO 1st Max Hourn\n14\nNO2 AQI\n\
    28\nCO AQI\nIn this study, we use the Air Quality Index (AQI) as the observation\
    \ variable. The AQI\nindicates how harmful the air is to human health. We show\
    \ in Table 4 the AQI basics for\nozone and particle pollution. In Table 4, the\
    \ meaning of the colors is as follows: green,\nair quality is satisfactory, and\
    \ air pollution poses little or no risk; yellow, air quality is\nacceptable, but\
    \ there may be a risk for some people, particularly those who are unusually\n\
    sensitive to air pollution; orange, members of vulnerable groups may experience\
    \ health\neffects (the general public is less likely to be affected); red, some\
    \ members of the general\npublic may experience health effects, and members of\
    \ sensitive groups may experience\nmore serious health effects; purple, the risk\
    \ of health effects is increased for everyone;\nmaroon, health warning of emergency\
    \ conditions, everyone is more likely to be affected.\nSensors 2022, 22, 1693\n\
    11 of 21\nTable 4. AQI basics for Ozone and Particle Pollution. Source: www.airnow.gov/aqi/aqi-basics.\n\
    AQI Color\nLevels of Concern\nValues of Index\nGreen\nGood\n0 to 50\nYellow\n\
    Moderate\n51 to 100\nOrange\nUnhealthy for Sensitive Groups\n101 to 150\nRed\n\
    Unhealthy\n151 to 200\nPurple\nVery Unhealthy\n201 to 300\nMaroon\nHazardous\n\
    301 and higher\nThe index for a pollutant is calculated using the mathematical\
    \ expression of the\nEquation (5) [23].\nIP =\nIHi − ILO\nBPHi − BPLO\n(CP − BPLO)\
    \ + ILO\n(5)\nwhere,\nIP is the index value for pollutant, P;\nCP is the truncated\
    \ concentration of pollutant, P;\nBPHi is the breakpoint that is ≥CP;\nBPLO is\
    \ the breakpoint that is ≤CP;\nIHi is the AQI value corresponding to BPHi;\nand,\
    \ ILO is the AQI value corresponding to BPLO.\nIn this context, we executed experiments\
    \ aim to determine the areal units that optimize\nspatial autocorrelation patterns\
    \ through the combined use of indicators of global spatial\nautocorrelation and\
    \ the variance of local spatial autocorrelation. Furthermore, we applied\nthe\
    \ Kriging interpolation method for data visualization. Thus, we validate our approach,\n\
    and at the same time, we contribute to solving a real-world problem.\nStudy Areal\
    \ Description\nTo evaluate the methods in these data, we chose two areal unit\
    \ dimensions: a large\none that involves the whole sensors described in Figure\
    \ 3, and a small one, which includes\nthe entire sensors in the state of California.\
    \ We choose California due to the high variability\nbetween sensors’ values and\
    \ the considerable number and distribution of sensors.\nAccording to United Nations\
    \ Statistics Division [52], the United States of America\n(USA) has a total area\
    \ of 9,629,091 km2, and California is the third-largest by area at\n423,970 km2\
    \ (it is also the most populous USA state). The surface in both areal unit\ndimensions\
    \ were partitioned into hexagonal areal units, where each spatial unit aggregated\n\
    the AQI’s pollutants. Furthermore, the hexagonal shape reduced the visual ﬁeld\
    \ bias when\ncompared with the square units [53].\n6. Computational Results\n\
    We implemented the experimental programs in Python (data prepossessing), and we\n\
    made the geostatistic and spatial statistical methods in the R language; this\
    \ made it possible\nto ﬁnd all code and experimental data in our public repository\
    \ (https://github.com/\nLeonild/SpatialDataAnalysis).\nTo evaluate our approach,\
    \ ﬁrst, we applied the framework described on Section 4.1\nto determine the areal\
    \ units that optimize the spatial autocorrelation patterns through the\ncombined\
    \ use of indicators of global and local spatial autocorrelation; this returns\
    \ what\nthe best areal unit to make data analysis is. Then, we applied the interpolation\
    \ method\ndescribed in Section 4.2, to an accurate data visualization. Furthermore,\
    \ we compared the\nresults with the works that use the classical statistics, to\
    \ provide evidence that the analysis\nmethod could lead to wrong interpretations.\n\
    Sensors 2022, 22, 1693\n12 of 21\n6.1. Spatial Statistics Analysis\nFollowing\
    \ Algorithm 1, we modeled the candidates’ areal units by regular hexagon\nshape,\
    \ and we determined the length of the sides in ﬁve scales: 100 km, 200 km, 300\
    \ km,\n400 km, and 500 km. Furthermore, we analyzed for all the pollutants, but\
    \ here, due to\nthe number of the images and very similar characteristics, we\
    \ present results for only one\npollutant (O3).\nFigure 4 shows Global Moran’s\
    \ I coefﬁcient and the coefﬁcient of variation of Local\nMoran’s I for the areal\
    \ units. Only some of the areal units show an improvement, with\nhigher Global\
    \ Moran’s I and lower coefﬁcient of variation of Local Moran’s I. The other\n\
    areal units just keep values that represent the absence of spatial autocorrelation\
    \ and with\nhigh variation of Local Moran’s I. In this experiment, an areal unit\
    \ of 200 km is linked to a\nhigher pattern of spatial association and lower spatial\
    \ heterogeneity than the other areal\nunits; i.e., the former provides more consistent\
    \ spatial patterns and is thus likely to reﬂect\nmore reliable analytical results.\n\
    To analyze the chart from Figure 5, we should remember the conﬂicting objectives\
    \ that\nwe considered; in this case, the ideal solution should have a higher Global\
    \ Moran’s I (GM)\nand a lower coefﬁcient of variation of Local Moran’s I (LM).\
    \ Let us look at Figure 5. We\nhave ﬁve possible areal units of data aggregated\
    \ to choose for analyzing: (1) 100 km with\na low LM and less high GM; (2) 300\
    \ km in the same context; (3) 500 km, which, however,\nhas a low LM but also has\
    \ a low GM; (4) the worst solution, 400 km, with a lower GM\nand a higher LM;\
    \ and (5) the areal unit of 200 km with the higher GM and the lower LM.\nTherefore,\
    \ according to the results of the multicriteria optimization framework in Figure\
    \ 5,\nthe Pareto-optimal solution is the areal units of 200 km. These areal units\
    \ dominate the\nother ones because their criteria are better; i.e., they are combined\
    \ with a higher Global\nMoran’s I and a lower coefﬁcient of variation of Local\
    \ Moran’s I. This means that the data\naggregated inside the 200 km areal unit\
    \ have a higher correlation than the others.\nFigure 4. Trade-off between the\
    \ global indicator of spatial association (Global Moran’s I) and the\noverall\
    \ degree of structural (in)stability (coefﬁcient of variation of Local Moran’s\
    \ I normalized by\nscaling between the minimum and maximum values of the Global\
    \ Moran’s I coefﬁcients. Both global\nand local spatial statistics were computed\
    \ for a row-standardized spatial weights matrix based on\nﬁrst-order rook contiguity.\n\
    Sensors 2022, 22, 1693\n13 of 21\nFigure 5. Pareto frontier and trade-off between\
    \ Global Moran’s I and the coefﬁcient of variation of\nLocal Moran’s I.\nFigure\
    \ 6 shows the spatial patterns of the O3 collected data from the geographic\n\
    coordinates data sensors on the maps of the regular hexagons with the side lengths\
    \ of\n200 km, 300 km, 400 km, and 500 km. When we chose an arbitrary areal unit,\
    \ such as\n400 km or 500 km, we obtained different and discordant spatial patterns\
    \ when compared\nwith the Pareto-optimal areal units. In practice, this affects\
    \ the conclusions and may lead to\nmisunderstandings and mistakes by decision-makers\
    \ when applying the strategy to the\nIoT infrastructure planning.\nFigure 6. Comparison\
    \ of spatial patterns of Pareto-optimal areal units with others arbitrary areal\n\
    units. The patterns correspond to the ‘odds ratio measure’ of the frequency of\
    \ geographic coordinates’\nO3 data [54].\nTo analyze the method in another order\
    \ of magnitude, we replicated the experiment to\na smaller area, in which we used\
    \ the same data but considered only the state of California.\nIn this new experiment,\
    \ we also modeled the candidates’ areal units by a regular hexagons\nshape; however,\
    \ we determined the length of the sides in scales of 100 km, 90 km, 80 km,\n70\
    \ km, 60 km, and 50 km.\nSensors 2022, 22, 1693\n14 of 21\nFigure 7 shows Global\
    \ Moran’s I coefﬁcient and the coefﬁcient of variation of Local\nMoran’s I for\
    \ the areal units in the California states. This makes it possible to observe\
    \ that\nall the areal units show different patterns from each other. In this experiment,\
    \ the areal unit\nof 80 km is linked to a higher pattern of spatial association\
    \ and lower spatial heterogeneity\nthan the other areal units; i.e., the former\
    \ provides more consistent spatial patterns and is\nthus likely to reﬂect more\
    \ reliable analytical results.\nFigure 7. Trade-off between the global indicator\
    \ of spatial association (Global Moran’s I) and the\noverall degree of structural\
    \ (in)stability (coefﬁcient of variation of Local Moran’s I normalized by\nscaling\
    \ between the minimum and maximum values of the Global Moran’s I coefﬁcients)\
    \ considering\nthe California states.\nTo conﬁrm the conclusion above, we present\
    \ in Figure 8 the results of the multicriteria\noptimization framework, where\
    \ the 80 km areal unit is alone in the ﬁrst Pareto frontier.\nMoreover, it is\
    \ also possible to observe that the 50 km areal unit is isolated in the last Pareto\n\
    frontier; this means the lower pattern of spatial association and higher spatial\
    \ heterogeneity\nthan the other areal unit.\nFigure 8. Pareto frontier and trade-off\
    \ between Global Moran’s I and the coefﬁcient of variation of\nLocal Moran’s I\
    \ for the O3 pollutant in California state.\nSensors 2022, 22, 1693\n15 of 21\n\
    Like Figure 9, Figure 8 shows the spatial patterns of the O3 collected data from\
    \ the\ngeographic coordinates data sensors on the maps of the regular hexagons\
    \ with the side\nlength of 100 km, 90 km, 80 km, and 50 km. If we chose an arbitrary\
    \ areal unit, such as\n50 km, we obtained different spatial patterns when compared\
    \ with the Pareto-optimal\nareal units. It is essential to highlight that this\
    \ affects the conclusions and may lead to\nmisunderstandings and mistakes by decision-makers\
    \ when applying the strategy to the\nIoT infrastructure planning.\nFigure 9. Comparison\
    \ of spatial patterns of Pareto-optimal areal units with other arbitrary areal\
    \ units\nin the state of California. The patterns correspond to the ‘odds ratio\
    \ measure’ of the frequency of\ngeographic coordinates O3 data [54].\n6.2. Data\
    \ Interpolation\nTo compare the results of the data interpolation with works that\
    \ utilize classical\nstatistics in the same context, we used data from 2015 related\
    \ to O3 pollutants. Following\nthe systematic method presented in Figure 2, ﬁrst,\
    \ we normalize the data, and then we\nbuild the ﬁtted model. It is essential to\
    \ remember that the map from the location is only for\nvisualization.\nWe show\
    \ in Figure 10 the ﬁtted model used to apply the Kriging method. It can be\nobserved\
    \ that this variogram represents an exponential model; i.e., the spatial autocorre-\n\
    lation disappears entirely only at an inﬁnite distance, which means that the near\
    \ data are\nstrongly autocorrelated.\nSensors 2022, 22, 1693\n16 of 21\nFigure\
    \ 10. Variogram from the ﬁtted model to O3 data in the United States in 2015.\n\
    This ﬁtted model is the input for Kriging interpolation. Figure 11 shows the result\
    \ of\nKriging interpolation to O3 data in the United States in 2015, where the\
    \ gradient color repre-\nsents the O3 AQI. If we chose an classical statistics\
    \ methods to represent the same data (e.g.,\na simple average) like other literature\
    \ works [23,24], we could obtain a map visualization\nlike Figure 12; the colors\
    \ in the map from Figure 12 follow the Table 4 deﬁnition.\nFigure 11. Kriging\
    \ method interpolation applied to O3 AQI in the United States (2015).\nSensors\
    \ 2022, 22, 1693\n17 of 21\nFigure 12. O3 AQI peer state in the United States\
    \ in 2015 using classical statistics (average); the\ncolors in the map follow\
    \ the deﬁnitions in Table 4, and white means that the area does not have\ndata\
    \ information.\nIt is possible to observe that if we consider only the mean by\
    \ state (Figure 12), we can\nmake incorrect interpretations about the data. For\
    \ example, considering the average by\ncountry, we can conclude that entire state\
    \ of California has air that could be a risk for some\npeople, particularly those\
    \ who are unusually sensitive to air pollution, which is not valid if\nwe look\
    \ to the interpolation data (Figure 10).\nAnother good example is the state of\
    \ Arizona, which looks like a state with totally\nhealthy air if we considered\
    \ the map in Figure 12 (data collected in few points). However,\nwe see in the\
    \ interpolation map from Figure 11 that it is entirely incorrect to consider the\n\
    Arizona state with entirely healthy air.\nWith the geostatistics in our proposal\
    \ (Kriging method), we can also estimate a pre-\ndiction value; i.e., we can analyze\
    \ the possibility of a factor that exceeds a predetermined\namount. Figure 13\
    \ shows the probability prediction of the O3 pollutant overtaking an AQI\nof 50.\
    \ The estimate ﬂoats from 0 (0%) to 1 (100%).\nFigure 13. Kriging method indicative\
    \ applied to O3 AQI in the United States (2015); the probability\nprediction that\
    \ the O3 pollutant overtakes an AQI of 50.\n6.3. Discussion\nBy summarizing our\
    \ results, we can observe that a classical statistical method is\ninadequate for\
    \ data analysis of outdoor sensors. Furthermore, only a geostatistic or spatial\n\
    static analysis may not be enough either. For this reason, we propose structuring\
    \ several\nSensors 2022, 22, 1693\n18 of 21\nmethods from geostatistics and spatial\
    \ statistic aggregated with a multicriteria analysis to\ncompose a systematic\
    \ data analysis on outdoor sensors.\nAlthough we present results only for the\
    \ environmental context, our proposal is\npromising for a free contextual application\
    \ in outdoor sensors’ data analysis. In the next\nsection, we discuss our proposal’s\
    \ limitation and future work.\n7. Conclusions\nThe combination of devices with\
    \ sensor networks and Internet access enables the\ncommunication between the physical\
    \ world and cyberspace, providing the development of\nsolutions to many real-world\
    \ problems through the IoT.\nIoT involves anything with network access with or\
    \ without human interaction re-\nquired, and the data from these “things” can\
    \ be provided in many forms, such as streaming\nand discrete data, images, and\
    \ social media, among others. The combination of the network\nof sensors with\
    \ the Internet enables the communication between the virtual and real world,\n\
    allowing the decision making without human intervention. However, a wrong decision\n\
    due to poor data quality or erroneous data interpretation can cause signiﬁcant\
    \ ﬁnancial\nharm to companies and institutions.\nThe problem of data quality becomes\
    \ complex and controversial with the evolution of\ntechnology. The data quality\
    \ and data accuracy are also related to the data analysis [7–9].\nIn this context,\
    \ we presented in this paper a systematic approach to support the data analysis\n\
    by considering the sensor spatiality factor and geographic aspects. Moreover,\
    \ we applied\nthe methods on an extensive real-world database from the United\
    \ States Environmental\nProtection Agency (US EPA).\nFirst, we determined the\
    \ areal units that optimize the spatial autocorrelation patterns\nthrough the\
    \ combined use of indicators of global and local spatial autocorrelation, which\n\
    showed what the best areal unit to make data analysis is. Next, we applied the\
    \ Kriging\ninterpolation to an accurate data visualization, and we also provided\
    \ evidence that the\nreport given only by the classical statistics could lead\
    \ to wrong interpretations.\nAlthough we validate our proposed method only in\
    \ the environmental context, we\ncould apply this analysis in any context, including\
    \ a free-context method. However,\nto validate it as it would be validated with\
    \ a free-context method, we would need to realize\nthese speciﬁc analyses. Furthermore,\
    \ it is important to highlight some limitations in the\nexperiments:\n•\nWe only\
    \ did ofﬂine experiments.\n•\nDue to the analysis time, we could not use this\
    \ method in critical applications without\nsubstantial modiﬁcations.\n•\nIt is\
    \ necessary to validate this method in other contexts to ensure that our proposals\n\
    have a free context application.\nIn future work, we intend to perform experiments\
    \ and analysis in micro-regions with\nother study cases, where we hope to evaluate\
    \ the decision-making as well. Furthermore,\nwe also aimed to apply the spatial\
    \ autocorrelation to deduce the correct spatial distributed\nsensor dimensions.\
    \ In another context, we intend to do a performance evaluation to\nconclude if\
    \ it is feasible to use our approach in real-time execution for critical applications.\n\
    Author Contributions: Conceptualization, L.J.d.M.d.A., J.C.E. and A.C.B.D.; methodology\
    \ L.J.d.M.d.A.,\nS.C.d.A. and A.C.B.D.; software, L.J.d.M.d.A. and S.C.d.A.; validation,\
    \ L.J.d.M.d.A., S.C.d.A., A.C.B.D.\nand J.C.E.; formal analysis, L.J.d.M.d.A.,\
    \ S.C.d.A., A.C.B.D., J.C.E. and R.I.M..; investigation, L.J.d.M.d.A.,\nA.C.B.D.,\
    \ J.C.E. and S.R.-M.; resources, J.C.E. and S.R.-M.; data curation, L.J.d.M.d.A.\
    \ and J.C.E.; writing—\noriginal draft preparation, L.J.d.M.d.A., J.C.E., A.C.B.D.,\
    \ R.I.M., S.R.-M. and S.C.d.A.; writing—review\nand editing, L.J.d.M.d.A., J.C.E.,\
    \ A.C.B.D., R.I.M., S.R.-M. and S.C.d.A.; visualization, L.J.d.M.d.A.,\nS.C.d.A.,\
    \ A.C.B.D. and R.I.M.; supervision, J.C.E., A.C.B.D. and S.R.-M.; project administration,\
    \ J.C.E.\nand L.J.d.M.d.A.; funding acquisition, R.I.M. and J.C.E. All authors\
    \ have read and agreed to the published\nversion of the manuscript.\nSensors 2022,\
    \ 22, 1693\n19 of 21\nFunding: This research was funded by Fundação de Amparo\
    \ à Pesquisa do Estado de São Paulo\ngrant number 2020/07162-0.\nInstitutional\
    \ Review Board Statement: Not applicable.\nInformed Consent Statement: Not applicable.\n\
    Data Availability Statement: Publicly available datasets were analyzed in this\
    \ study. This data can\nbe found here: aqs.epa.gov/aqsweb/airdata/download_ﬁles.html.\n\
    Acknowledgments: This work was developed using the computational infrastructure\
    \ of the Dis-\ntributed Computing Lab of ICMC-USP - University of São Paulo present\
    \ in http://infra.lasdpc.icmc.\nusp.br/ and also with resources from the Center\
    \ for Mathematical Sciences Applied to Industry\n(CeMEAI http://www.cemeai.icmc.usp.br/)\
    \ funded by the São Paulo Research Foundation FAPESP\n(grant #2013/07375-0 and\
    \ #11/09524-7). FAPESP under grant #2020/05126-6 and FAPEMIG under\ngrant #APQ-03120-17.\
    \ Rodolfo Ipolito Meneguette would like to thank the FAPESP for the ﬁnancial\n\
    support through grant #2020/07162-0 in his research.\nConﬂicts of Interest: The\
    \ authors declare no conﬂict of interest. The funders had no role in the design\n\
    of the study; in the collection, analyses, or interpretation of data; in the writing\
    \ of the manuscript, or\nin the decision to publish the results.\nReferences\n\
    1.\nXia, F.; Yang, L.T.; Wang, L.; Vinel, A. Internet of things. Int. J. Commun.\
    \ Syst. 2012, 25, 1101. [CrossRef]\n2.\nMaschi, L.F.C.; Pinto, A.S.R.; Meneguette,\
    \ R.I.; Baldassin, A. Data Summarization in the Node by Parameters (DSNP): Local\
    \ Data\nFusion in an IoT Environment. Sensors 2018, 18, 799. [CrossRef]\n3.\n\
    Andreazi, G.T.; Estrella, J.C.; Bruschi, S.M.; Immich, R.; Guidoni, D.; Alves\
    \ Pereira Júnior, L.; Meneguette, R.I. MoHRiPA—An\nArchitecture for Hybrid Resources\
    \ Management of Private Cloud Environments. Sensors 2021, 21, 6857. [CrossRef]\
    \ [PubMed]\n4.\nFriedman, T.; Bitterer, A. Magic Quadrant for Data Quality Tools;\
    \ Gartner: Stamford, CT, USA, 2014.\n5.\nKarel, R. The ‘All In’ Costs of Poor\
    \ Data Quality; IDG Communications, Inc.: Needham, MA, USA, 2015.\n6.\nKarel,\
    \ R. Fixing a $3 Trillion Dirty Data Problem with “Crowd Computing”, 2015. Available\
    \ online: https://www.inzata.com/\nthe-ﬁve-ways-dirty-data-costs-businesses-money/\
    \ (accessed on 16 October 2021).\n7.\nKarkouch, A.; Mousannif, H.; Al Moatassime,\
    \ H.; Noel, T. Data quality in internet of things: A state-of-the-art survey.\
    \ J. Netw.\nComput. Appl. 2016, 73, 57–81. [CrossRef]\n8.\nLaranjeiro, N.; Soydemir,\
    \ S.N.; Bernardino, J. A survey on data quality: Classifying poor data. In Proceedings\
    \ of the 2015\nIEEE 21st Paciﬁc Rim International Symposium on Dependable Computing\
    \ (PRDC), Zhangjiajie, China, 18–20 November 2015;\npp. 179–188.\n9.\nBanerjee,\
    \ T.; Sheth, A. Iot quality control for data and application needs. IEEE Intell.\
    \ Syst. 2017, 32, 68–73. [CrossRef]\n10.\nAntonic, A.; Roankovic, K.; Marjanovic,\
    \ M.; Pripuic, K.; Zarko, I.P. A mobile crowdsensing ecosystem enabled by a cloud-based\n\
    publish/subscribe middleware. In Proceedings of the 2014 International Conference\
    \ on Future Internet of Things and Cloud,\nBarcelona, Spain, 27–29 August 2014;\
    \ pp. 107–114.\n11.\nAlam, S.; Noll, J. A semantic enhanced service proxy framework\
    \ for internet of things. In Proceedings of the 2010 IEEE/ACM Int’l\nConference\
    \ on Green Computing and Communications & Int’l Conference on Cyber, Physical\
    \ and Social Computing, Hangzhou,\nChina, 18–20 December 2010; pp. 488–495.\n\
    12.\nKothari, A.; Boddula, V.; Ramaswamy, L.; Abolhassani, N. Dqs-cloud: A data\
    \ quality-aware autonomic cloud for sensor\nservices. In Proceedings of the 10th\
    \ IEEE International Conference on Collaborative Computing: Networking, Applications\
    \ and\nWorksharing, Miami, FL, USA, 22–25 October 2014; pp. 295–303.\n13.\nKarkouch,\
    \ A.; Mousannif, H.; Al Moatassime, H.; Noel, T. A model-driven framework for\
    \ data quality management in the\nInternet of Things. J. Ambient Intell. Humaniz.\
    \ Comput. 2018, 9, 977–998. [CrossRef]\n14.\nCasado-Vara, R.; de la Prieta, F.;\
    \ Prieto, J.; Corchado, J.M. Blockchain framework for IoT data quality via edge\
    \ computing.\nIn Proceedings of the 1st Workshop on Blockchain-Enabled Networked\
    \ Sensor Systems, Shenzhen, China, 4 November 2018;\npp. 19–24.\n15.\nBaqa, H.;\
    \ Truong, N.B.; Crespi, N.; Lee, G.M.; Le Gall, F. Quality of Information as an\
    \ indicator of Trust in the Internet of Things.\nIn Proceedings of the 2018 17th\
    \ IEEE International Conference On Trust, Security And Privacy In Computing Furthermore,\n\
    Communications/12th IEEE International Conference On Big Data Science Furthermore,\
    \ Engineering (TrustCom/BigDataSE),\nNew York, NY, USA, 1–3 August 2018; pp. 204–211.\n\
    16.\nBamgboye, O.; Liu, X.; Cruickshank, P. Towards modelling and reasoning about\
    \ uncertain data of sensor measurements for\ndecision support in smart spaces.\
    \ In Proceedings of the 2018 IEEE 42nd Annual Computer Software and Applications\
    \ Conference\n(COMPSAC), Tokyo, Japan, 23–27 July 2018; Volume 2, pp. 744–749.\n\
    17.\nXu, X.; Lei, Y.; Li, Z. An incorrect data detection method for big data cleaning\
    \ of machinery condition monitoring. IEEE Trans.\nInd. Electron. 2019, 67, 2326–2336.\
    \ [CrossRef]\nSensors 2022, 22, 1693\n20 of 21\n18.\nCheng, H.; Feng, D.; Shi,\
    \ X.; Chen, C. Data quality analysis and cleaning strategy for wireless sensor\
    \ networks. EURASIP J. Wirel.\nCommun. Netw. 2018, 2018, 1–11. [CrossRef]\n19.\n\
    Sicari, S.; Rizzardi, A.; Cappiello, C.; Miorandi, D.; Coen-Porisini, A. Toward\
    \ data governance in the internet of things. In New\nAdvances in the Internet\
    \ of Things; Springer: Berlin/Heidelberg, Germany, 2018; pp. 59–74.\n20.\nFerreira,\
    \ E.; Ferreira, D. Towards altruistic data quality assessment for mobile sensing.\n\
    In Proceedings of the 2017 ACM\nInternational Joint Conference on Pervasive and\
    \ Ubiquitous Computing and Proceedings of the 2017 ACM International\nSymposium\
    \ on Wearable Computers, Maui, HI, USA, 11–15 September 2017; pp. 464–469.\n21.\n\
    de Aquino, G.R.C.; de Farias, C.M.; Pirmez, L. Data Quality Assessment and Enhancement\
    \ on Social and Sensor Data; BiDu-\nPosters@VLDB: Rio de Janeiro, Brazil, 2018.\n\
    22.\nLiu, Q.; Sha, D.; Liu, W.; Houser, P.; Zhang, L.; Hou, R.; Lan, H.; Flynn,\
    \ C.; Lu, M.; Hu, T.; et al. Spatiotemporal Patterns of\nCOVID-19 Impact on Human\
    \ Activities and Environment in Mainland China Using Nighttime Light and Air Quality\
    \ Data.\nRemote Sens. 2020, 12, 1576. [CrossRef]\n23.\nBishoi, B.; Prakash, A.;\
    \ Jain, V. A comparative study of air quality index based on factor analysis and\
    \ US-EPA methods for an\nurban environment. Aerosol Air Qual. Res. 2009, 9, 1–17.\
    \ [CrossRef]\n24.\nLi, Z.; Ma, Z.; van der Kuijp, T.J.; Yuan, Z.; Huang, L. A\
    \ review of soil heavy metal pollution from mines in China: Pollution and\nhealth\
    \ risk assessment. Sci. Total Environ. 2014, 468, 843–853. [CrossRef] [PubMed]\n\
    25.\nKnoblauch, J.; Damoulas, T.\nSpatio-temporal Bayesian on-line changepoint\
    \ detection with model selection.\narXiv 2018,\narXiv:1805.05383.\n26.\nKnoblauch,\
    \ J.; Jewson, J.E.; Damoulas, T. Doubly Robust Bayesian Inference for Non-Stationary\
    \ Streaming Data with β-\nDivergences. Adv. Neural Inf. Process. Syst. 2018, 31,\
    \ 64–75.\n27.\nAglietti, V.; Bonilla, E.V.; Damoulas, T.; Cripps, S. Structured\
    \ Variational Inference in Continuous Cox Process Models. Adv.\nNeural Inf. Process.\
    \ Syst. 2019, 32, 12437–12447.\n28.\nHamelijnck, O.; Damoulas, T.; Wang, K.; Girolami,\
    \ M. Multi-resolution multi-task Gaussian processes. Adv. Neural Inf. Process.\n\
    Syst. 2019, 32, 14025–14035.\n29.\nAkyildiz, Ö.D.; Míguez, J. Nudging the particle\
    \ ﬁlter. Stat. Comput. 2020, 30, 305–330. [CrossRef]\n30.\nAkyildiz, Ö.D.; Chouzenoux,\
    \ E.; Elvira, V.; Míguez, J. A probabilistic incremental proximal gradient method.\
    \ IEEE Signal Process.\nLett. 2019, 26, 1257–1261. [CrossRef]\n31.\nMark, D.M.\
    \ Geographic Information Science: Deﬁning the Field. In Foundations of Geographic\
    \ Information Science; Duckham, M.,\nGoodchild, M.F., Worboys, M., Eds.; Taylor\
    \ & Francis: Abingdon, UK, 2003; pp. 3–18. [CrossRef]\n32.\nGoodchild, M.F. Geographical\
    \ information science. Int. J. Geogr. Inf. Syst. 1992, 6, 31–45. [CrossRef]\n\
    33.\nGotway, C.A.; Young, L.J. Combining Incompatible Spatial Data. J. Am. Stat.\
    \ Assoc. 2002, 97, 632–648. [CrossRef]\n34.\nYang, C.; Clarke, K.; Shekhar, S.;\
    \ Tao, C.V. Big Spatiotemporal Data Analytics: A research and innovation frontier.\
    \ Int. J. Geogr. Inf.\nSci. 2020, 34, 1075–1088. [CrossRef]\n35.\nLavrova, D.;\
    \ Pechenkin, A.; Gluhov, V. Applying correlation analysis methods to control ﬂow\
    \ violation detection in the internet\nof things. Autom. Control Comput. Sci.\
    \ 2015, 49, 735–740. [CrossRef]\n36.\nZhang, D.; Zhao, C.P.; Liang, Y.P.; Liu,\
    \ Z.J. A new medium access control protocol based on perceived data reliability\
    \ and spatial\ncorrelation in wireless sensor network. Comput. Electr. Eng. 2012,\
    \ 38, 694–702. [CrossRef]\n37.\nHabibia, R.; Alesheikha, A.A. Managing coverage\
    \ holes in IoT monitoring sensor networks. IEEE Commun. Mag. 2017, 55, 70–78.\n\
    [CrossRef]\n38.\nde Andrade, S.C.; Restrepo-Estrada, C.; Nunes, L.H.; Rodriguez,\
    \ C.A.M.; Estrella, J.C.; Delbem, A.C.B.; de Albuquerque, J.P. A\nmulticriteria\
    \ optimization framework for the deﬁnition of the spatial granularity of urban\
    \ social media analytics. Int. J. Geogr. Inf.\nSci. 2020, 35, 43–62. [CrossRef]\n\
    39.\nHaining, R. Spatial Data Analysis: Theory and Practice; Cambridge University\
    \ Press: Cambridge, UK, 2003.\n40.\nAnselin, L. Spatial Econometrics: Methods\
    \ and Models; Kluwer Academic Publishers: Dordrecht, The Neatherland, 1988.\n\
    41.\nTobler, W.R. A computer movie simulating urban growth in the Detroit region.\
    \ Econ. Geogr. 1970, 46, 234–240. [CrossRef]\n42.\nO’sullivan, D.; Unwin, D. Geographic\
    \ Information Analysis; John Wiley & Sons: Hoboken, NJ, USA, 2014.\n43.\nMoran,\
    \ P.A. The interpretation of statistical maps. J. R. Stat. Soc. Ser. B 1948, 10,\
    \ 243–251. [CrossRef]\n44.\nCressie, N. The origins of kriging. Math. Geol. 1990,\
    \ 22, 239–252. [CrossRef]\n45.\nGetis, A. Reﬂections on spatial autocorrelation.\
    \ Reg. Sci. Urban Econ. 2007, 37, 491–496. [CrossRef]\n46.\nAnselin, L. Local\
    \ Indicators of Spatial Association—LISA. Geogr. Anal. 1995, 27, 93–115. [CrossRef]\n\
    47.\nPareto, V. Cours d’Économie Politique; Librairie Droz: Geneva, Switzerland,\
    \ 1964; Volume 1.\n48.\nHerrmann, C.; Juraschek, M.; Burggräf, P.; Kara, S. Urban\
    \ production: State of the art and future trends for urban factories. CIRP\nAnn.\
    \ 2020, 69, 764–787. [CrossRef]\n49.\nSarkar, C.; Webster, C. Urban environments\
    \ and human health: Current trends and future directions. Curr. Opin. Environ.\
    \ Sustain.\n2017, 25, 33–44. [CrossRef]\n50.\nKampa, M.; Castanas, E. Human health\
    \ effects of air pollution. Environ. Pollut. 2008, 151, 362–367. [CrossRef] [PubMed]\n\
    51.\nNowak, D.J.; Hirabayashi, S.; Doyle, M.; McGovern, M.; Pasher, J. Air pollution\
    \ removal by urban forests in Canada and its effect\non air quality and human\
    \ health. Urban For. Urban Green. 2018, 29, 40–48. [CrossRef]\n52.\nUnited Nations\
    \ Statistics Division. Available online: https://unstats.un.org/home/ (accessed\
    \ on 21 July 2020).\nSensors 2022, 22, 1693\n21 of 21\n53.\nCarr, D.B.; Olsen,\
    \ A.R.; White, D. Hexagon mosaic maps for display of univariate and bivariate\
    \ geographical data. Cartogr. Geogr.\nInf. Syst. 1992, 19, 228–236. [CrossRef]\n\
    54.\nPoorthuis, A.; Zook, M.; Shelton, T.; Graham, M.; Stephens, M. Using Geotagged\
    \ Digital Social Data in Geographic Research;\nPre-Publication Version of Chapter\
    \ Submitted to: Key Methods in Geography; Clifford, N., French, S., Cope, M.,\
    \ Gillespie, S.,\nEds.; Sage: London, UK, 2014.\n"
  inline_citation: '>'
  journal: Sensors (Basel)
  limitations: '>'
  pdf_link: https://www.mdpi.com/1424-8220/22/5/1693/pdf?version=1645503810
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: Analysis of Spatially Distributed Data in Internet of Things in the Environmental
    Context
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'

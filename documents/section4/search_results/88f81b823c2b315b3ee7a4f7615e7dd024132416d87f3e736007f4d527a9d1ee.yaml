- DOI: https://doi.org/10.1049/cp:19970414
  analysis: '>'
  authors:
  - Claude C. Chibelushi
  - Farzin Deravi
  - John S. Mason
  citation_count: 13
  full_citation: '>'
  full_text: '>

    Audio-visual person recognition: an evaluation of data fusion strategies Publication
    European Conference on Security and Detection - ECOS97 Incorporating the One Day
    Symposium on Technology Used for Combatting Fraud Published 1997 Authors C.C.
    Chibelushi DOI https://doi.org/10.1049/cp:19970414 The publisher of this work
    supports multiple resolution. The work is available from the following locations:  theiet.org
    ieee.org Logos provided by Clearbit Crossref Privacy Policy'
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: null
  publication_year: 1997
  relevance_score1: 0
  relevance_score2: 0
  title: 'Audio-visual person recognition: an evaluation of data fusion strategies'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1155/2013/704504
  analysis: '>'
  authors:
  - Federico Castanedo
  citation_count: 639
  full_citation: '>'
  full_text: ">\nHindawi Publishing Corporation\nThe Scientific World Journal\nVolume\
    \ 2013, Article ID 704504, 19 pages\nhttp://dx.doi.org/10.1155/2013/704504\nReview\
    \ Article\nA Review of Data Fusion Techniques\nFederico Castanedo\nDeusto Institute\
    \ of Technology, DeustoTech, University of Deusto, Avenida de las Universidades\
    \ 24, 48007 Bilbao, Spain\nCorrespondence should be addressed to Federico Castanedo;\
    \ castanedofede@gmail.com\nReceived 9 August 2013; Accepted 11 September 2013\n\
    Academic Editors: Y. Takama and D. Ursino\nCopyright © 2013 Federico Castanedo.\
    \ This is an open access article distributed under the Creative Commons Attribution\
    \ License,\nwhich permits unrestricted use, distribution, and reproduction in\
    \ any medium, provided the original work is properly cited.\nThe integration of\
    \ data and knowledge from several sources is known as data fusion. This paper\
    \ summarizes the state of the data\nfusion field and describes the most relevant\
    \ studies. We first enumerate and explain different classification schemes for\
    \ data fusion.\nThen, the most common algorithms are reviewed. These methods and\
    \ algorithms are presented using three different categories: (i)\ndata association,\
    \ (ii) state estimation, and (iii) decision fusion.\n1. Introduction\nIn general,\
    \ all tasks that demand any type of parameter\nestimation from multiple sources\
    \ can benefit from the use\nof data/information fusion methods. The terms information\n\
    fusion and data fusion are typically employed as synonyms;\nbut in some scenarios,\
    \ the term data fusion is used for\nraw data (obtained directly from the sensors)\
    \ and the term\ninformation fusion is employed to define already processed\ndata.\
    \ In this sense, the term information fusion implies a\nhigher semantic level\
    \ than data fusion. Other terms associ-\nated with data fusion that typically\
    \ appear in the literature\ninclude decision fusion, data combination, data aggregation,\n\
    multisensor data fusion, and sensor fusion.\nResearchers in this field agree that\
    \ the most accepted\ndefinition of data fusion was provided by the Joint Directors\n\
    of Laboratories (JDL) workshop [1]: “A multi-level process\ndealing with the association,\
    \ correlation, combination of data\nand information from single and multiple sources\
    \ to achieve\nrefined position, identify estimates and complete and timely\nassessments\
    \ of situations, threats and their significance.”\nHall and Llinas [2] provided\
    \ the following well-known\ndefinition of data fusion: “data fusion techniques\
    \ combine data\nfrom multiple sensors and related information from associated\n\
    databases to achieve improved accuracy and more specific\ninferences than could\
    \ be achieved by the use of a single sensor\nalone.”\nBriefly, we can define data\
    \ fusion as a combination of\nmultiple sources to obtain improved information;\
    \ in this\ncontext, improved information means less expensive, higher\nquality,\
    \ or more relevant information.\nData fusion techniques have been extensively\
    \ employed\non multisensor environments with the aim of fusing and\naggregating\
    \ data from different sensors; however, these tech-\nniques can also be applied\
    \ to other domains, such as text\nprocessing. The goal of using data fusion in\
    \ multisensor envi-\nronments is to obtain a lower detection error probability\
    \ and\na higher reliability by using data from multiple distributed\nsources.\n\
    The available data fusion techniques can be classified into\nthree nonexclusive\
    \ categories: (i) data association, (ii) state\nestimation, and (iii) decision\
    \ fusion. Because of the large\nnumber of published papers on data fusion, this\
    \ paper does\nnot aim to provide an exhaustive review of all of the studies;\n\
    instead, the objective is to highlight the main steps that are\ninvolved in the\
    \ data fusion framework and to review the most\ncommon techniques for each step.\n\
    The remainder of this paper continues as follows. The\nnext section provides various\
    \ classification categories for data\nfusion techniques. Then, Section 3 describes\
    \ the most com-\nmon methods for data association tasks. Section 4 provides\n\
    a review of techniques under the state estimation category.\nNext, the most common\
    \ techniques for decision fusion are\nenumerated in Section 5. Finally, the conclusions\
    \ obtained\n2\nThe Scientific World Journal\nfrom reviewing the different methods\
    \ are highlighted in\nSection 6.\n2. Classification of Data Fusion Techniques\n\
    Data fusion is a multidisciplinary area that involves several\nfields, and it\
    \ is difficult to establish a clear and strict classifi-\ncation. The employed\
    \ methods and techniques can be divided\naccording to the following criteria:\n\
    (1) attending to the relations between the input data\nsources, as proposed by\
    \ Durrant-Whyte [3]. These\nrelations can be defined as (a) complementary, (b)\n\
    redundant, or (3) cooperative data;\n(2) according to the input/output data types\
    \ and their\nnature, as proposed by Dasarathy [4];\n(3) following an abstraction\
    \ level of the employed data:\n(a) raw measurement, (b) signals, and (c) characteris-\n\
    tics or decisions;\n(4) based on the different data fusion levels defined by the\n\
    JDL;\n(5) Depending on the architecture type: (a) centralized,\n(b) decentralized,\
    \ or (c) distributed.\n2.1. Classification Based on the Relations between the\
    \ Data\nSources. Based on the relations of the sources (see Figure 1),\nDurrant-Whyte\
    \ [3] proposed the following classification\ncriteria:\n(1) complementary: when\
    \ the information provided by\nthe input sources represents different parts of\
    \ the\nscene and could thus be used to obtain more complete\nglobal information.\
    \ For example, in the case of visual\nsensor networks, the information on the\
    \ same target\nprovided by two cameras with different fields of view\nis considered\
    \ complementary;\n(2) redundant: when two or more input sources provide\ninformation\
    \ about the same target and could thus be\nfused to increment the confidence.\
    \ For example, the\ndata coming from overlapped areas in visual sensor\nnetworks\
    \ are considered redundant;\n(3) cooperative: when the provided information is\
    \ com-\nbined into new information that is typically more\ncomplex than the original\
    \ information. For example,\nmulti-modal (audio and video) data fusion is consid-\n\
    ered cooperative.\n2.2. Dasarathy’s Classification. One of the most well-known\n\
    data fusion classification systems was provided by Dasarathy\n[4] and is composed\
    \ of the following five categories (see\nFigure 2):\n(1) data in-data out (DAI-DAO):\
    \ this type is the most\nbasic or elementary data fusion method that is con-\n\
    sidered in classification. This type of data fusion\nprocess inputs and outputs\
    \ raw data; the results\nare typically more reliable or accurate. Data fusion\
    \ at\nthis level is conducted immediately after the data are\ngathered from the\
    \ sensors. The algorithms employed\nat this level are based on signal and image\
    \ processing\nalgorithms;\n(2) data in-feature out (DAI-FEO): at this level, the\
    \ data\nfusion process employs raw data from the sources\nto extract features\
    \ or characteristics that describe an\nentity in the environment;\n(3) feature\
    \ in-feature out (FEI-FEO): at this level, both\nthe input and output of the data\
    \ fusion process are\nfeatures. Thus, the data fusion process addresses a\nset\
    \ of features with to improve, refine or obtain new\nfeatures. This process is\
    \ also known as feature fusion,\nsymbolic fusion, information fusion or intermediate-\n\
    level fusion;\n(4) feature in-decision out (FEI-DEO): this level obtains a\nset\
    \ of features as input and provides a set of decisions\nas output. Most of the\
    \ classification systems that\nperform a decision based on a sensor’s inputs fall\
    \ into\nthis category of classification;\n(5) Decision In-Decision Out (DEI-DEO):\
    \ This type of\nclassification is also known as decision fusion. It fuses\ninput\
    \ decisions to obtain better or new decisions.\nThe main contribution of Dasarathy’s\
    \ classification is the\nspecification of the abstraction level either as an input\
    \ or an\noutput, providing a framework to classify different methods\nor techniques.\n\
    2.3. Classification Based on the Abstraction Levels. Luo et al.\n[5] provided\
    \ the following four abstraction levels:\n(1) signal level: directly addresses\
    \ the signals that are\nacquired from the sensors;\n(2) pixel level: operates\
    \ at the image level and could be\nused to improve image processing tasks;\n(3)\
    \ characteristic: employs features that are extracted\nfrom the images or signals\
    \ (i.e., shape or velocity),\n(4) symbol: at this level, information is represented\
    \ as\nsymbols; this level is also known as the decision level.\nInformation fusion\
    \ typically addresses three levels of\nabstraction: (1) measurements, (2) characteristics,\
    \ and (3)\ndecisions. Other possible classifications of data fusion based\non\
    \ the abstraction levels are as follows:\n(1) low level fusion: the raw data are\
    \ directly provided\nas an input to the data fusion process, which provide\nmore\
    \ accurate data (a lower signal-to-noise ratio)\nthan the individual sources;\n\
    (2) medium level fusion: characteristics or features\n(shape, texture, and position)\
    \ are fused to obtain\nfeatures that could be employed for other tasks. This\n\
    level is also known as the feature or characteristic\nlevel;\nThe Scientific World\
    \ Journal\n3\nS1\nS2\nS3\nS4\nS5\nComplementary\nfusion\nRedundant\nfusion\nCooperative\n\
    fusion\nFused\ninformation\nSources\nInformation\n(a + b)\n(b)\n(c)\nA\nB\nA\n\
    B\nB\nC\nC\nC\U000F3C00\nFigure 1: Whyte’s classification based on the relations\
    \ between the data sources.\nData\nData\nFeatures\nFeatures\nDecisions\nData\n\
    Features\nFeatures\nDecisions\nDecisions\nData in-data out\n(DAI-DAO)\nData in-feature\
    \ out\n(DAI-FEO)\nFeature in-decision out\n(FEI-DEO)\nDecision in-decision out\n\
    (DEI-DEO)\nFeature in-feature out\n(FEI-FEO)\nFigure 2: Dasarathy’s classification.\n\
    (3) high level fusion: this level, which is also known\nas decision fusion, takes\
    \ symbolic representations as\nsources and combines them to obtain a more accurate\n\
    decision. Bayesian’s methods are typically employed at\nthis level;\n(4) multiple\
    \ level fusion: this level addresses data pro-\nvided from different levels of\
    \ abstraction (i.e., when\na measurement is combined with a feature to obtain\
    \ a\ndecision).\n2.4. JDL Data Fusion Classification. This classification is the\n\
    most popular conceptual model in the data fusion commu-\nnity. It was originally\
    \ proposed by JDL and the American\nDepartment of Defense (DoD) [1]. These organizations\
    \ clas-\nsified the data fusion process into five processing levels, an\nassociated\
    \ database, and an information bus that connects\nthe five components (see Figure\
    \ 3). The five levels could be\ngrouped into two groups, low-level fusion and\
    \ high-level\nfusion, which comprise the following components:\n(i) sources: the\
    \ sources are in charge of providing\nthe input data. Different types of sources\
    \ can be\nemployed, such as sensors, a priori information (ref-\nerences or geographic\
    \ data), databases, and human\ninputs;\n(ii) human-computer interaction (HCI):\
    \ HCI is an inter-\nface that allows inputs to the system from the oper-\nators\
    \ and produces outputs to the operators. HCI\nincludes queries, commands, and\
    \ information on the\nobtained results and alarms;\n(iii) database management\
    \ system: the database manage-\nment system stores the provided information and\n\
    the fused results. This system is a critical component\nbecause of the large amount\
    \ of highly diverse infor-\nmation that is stored.\nIn contrast, the five levels\
    \ of data processing are defined as\nfollows:\n(1) level 0—source preprocessing:\
    \ source preprocessing\nis the lowest level of the data fusion process, and\n\
    it includes fusion at the signal and pixel levels. In\nthe case of text sources,\
    \ this level also includes the\ninformation extraction process. This level reduces\
    \ the\namount of data and maintains useful information for\nthe high-level processes;\n\
    (2) level 1—object refinement: object refinement employs\nthe processed data from\
    \ the previous level. Com-\nmon procedures of this level include spatio-temporal\n\
    alignment, association, correlation, clustering or\ngrouping techniques, state\
    \ estimation, the removal of\nfalse positives, identity fusion, and the combining\
    \ of\nfeatures that were extracted from images. The output\n4\nThe Scientific\
    \ World Journal\nFusion domain\nLevel 0\nLevel 1\nLevel 2\nLevel 3\nSource\npreprocessing\n\
    Object\nrefinement\nSituation\nassessment\nThreat\nassessment\nInformation bus\n\
    Sources\nSensors\nDatabases\nKnowledge\nLevel 4\nDatabase\nmanagement\nProcess\n\
    refinement\nUser\ninterface\nFigure 3: The JDL data fusion framework.\nresults\
    \ of this stage are the object discrimination\n(classification and identification)\
    \ and object track-\ning (state of the object and orientation). This stage\ntransforms\
    \ the input information into consistent data\nstructures;\n(3) level 2—situation\
    \ assessment: this level focuses on\na higher level of inference than level 1.\
    \ Situation\nassessment aims to identify the likely situations given\nthe observed\
    \ events and obtained data. It establishes\nrelationships between the objects.\
    \ Relations (i.e.,\nproximity, communication) are valued to determine\nthe significance\
    \ of the entities or objects in a specific\nenvironment. The aim of this level\
    \ includes perform-\ning high-level inferences and identifying significant\nactivities\
    \ and events (patterns in general). The output\nis a set of high-level inferences;\n\
    (4) level 3—impact assessment: this level evaluates the\nimpact of the detected\
    \ activities in level 2 to obtain a\nproper perspective. The current situation\
    \ is evaluated,\nand a future projection is performed to identify\npossible risks,\
    \ vulnerabilities, and operational oppor-\ntunities. This level includes (1) an\
    \ evaluation of the\nrisk or threat and (2) a prediction of the logical\noutcome;\n\
    (5) level 4—process refinement: this level improves the\nprocess from level 0\
    \ to level 3 and provides resource\nand sensor management. The aim is to achieve\
    \ effi-\ncient resource management while accounting for task\npriorities, scheduling,\
    \ and the control of available\nresources.\nHigh-level fusion typically starts\
    \ at level 2 because the\ntype, localization, movement, and quantity of the objects\n\
    are known at that level. One of the limitations of the JDL\nmethod is how the\
    \ uncertainty about previous or subsequent\nresults could be employed to enhance\
    \ the fusion process\n(feedback loop). Llinas et al. [6] propose several refinements\n\
    and extensions to the JDL model. Blasch and Plano [7]\nproposed to add a new level\
    \ (user refinement) to support a\nhuman user in the data fusion loop. The JDL\
    \ model represents\nthe first effort to provide a detailed model and a common\n\
    terminology for the data fusion domain. However, because\ntheir roots originate\
    \ in the military domain, the employed\nterms are oriented to the risks that commonly\
    \ occur in\nthese scenarios. The Dasarathy model differs from the JDL\nmodel with\
    \ regard to the adopted terminology and employed\napproach. The former is oriented\
    \ toward the differences\namong the input and output results, independent of the\n\
    employed fusion method. In summary, the Dasarathy model\nprovides a method for\
    \ understanding the relations between\nthe fusion tasks and employed data, whereas\
    \ the JDL model\npresents an appropriate fusion perspective to design data\nfusion\
    \ systems.\n2.5. Classification Based on the Type of Architecture. One of\nthe\
    \ main questions that arise when designing a data fusion\nsystem is where the\
    \ data fusion process will be performed.\nBased on this criterion, the following\
    \ types of architectures\ncould be identified:\n(1) centralized architecture:\
    \ in a centralized architecture,\nthe fusion node resides in the central processor\
    \ that\nreceives the information from all of the input sources.\nTherefore, all\
    \ of the fusion processes are executed\nin a central processor that uses the provided\
    \ raw\nmeasurements from the sources. In this schema, the\nsources obtain only\
    \ the observationas measurements\nand transmit them to a central processor, where\
    \ the\ndata fusion process is performed. If we assume that\ndata alignment and\
    \ data association are performed\ncorrectly and that the required time to transfer\
    \ the\ndata is not significant, then the centralized scheme is\ntheoretically\
    \ optimal. However, the previous assump-\ntions typically do not hold for real\
    \ systems. Moreover,\nthe large amount of bandwidth that is required to send\n\
    raw data through the network is another disadvantage\nfor the centralized approach.\
    \ This issue becomes a\nbottleneck when this type of architecture is employed\n\
    for fusing data in visual sensor networks. Finally,\nthe time delays when transferring\
    \ the information\nbetween the different sources are variable and affect\nThe\
    \ Scientific World Journal\n5\nthe results in the centralized scheme to a greater\n\
    degree than in other schemes;\n(2) decentralized architecture: a decentralized\
    \ architec-\nture is composed of a network of nodes in which each\nnode has its\
    \ own processing capabilities and there is\nno single point of data fusion. Therefore,\
    \ each node\nfuses its local information with the information that\nis received\
    \ from its peers. Data fusion is performed\nautonomously, with each node accounting\
    \ for its local\ninformation and the information received from its\npeers. Decentralized\
    \ data fusion algorithms typically\ncommunicate information using the Fisher and\
    \ Shan-\nnon measurements instead of the object’s state [8];\nThe main disadvantage\
    \ of this architecture is the\ncommunication cost, which is \U0001D442(\U0001D45B\
    2) at each com-\nmunication step, where \U0001D45B is the number of nodes;\nadditionally,\
    \ the extreme case is considered, in which\neach node communicates with all of\
    \ its peers. Thus,\nthis type of architecture could suffer from scalability\n\
    problems when the number of nodes is increased;\n(3) distributed architecture:\
    \ in a distributed architecture,\nmeasurements from each source node are processed\n\
    independently before the information is sent to the\nfusion node; the fusion node\
    \ accounts for the infor-\nmation that is received from the other nodes. In other\n\
    words, the data association and state estimation are\nperformed in the source\
    \ node before the information\nis communicated to the fusion node. Therefore,\
    \ each\nnode provides an estimation of the object state based\non only their local\
    \ views, and this information is\nthe input to the fusion process, which provides\
    \ a\nfused global view. This type of architecture provides\ndifferent options\
    \ and variations that range from only\none fusion node to several intermediate\
    \ fusion nodes;\n(4) hierarchical architecture: other architectures com-\nprise\
    \ a combination of decentralized and distributed\nnodes, generating hierarchical\
    \ schemes in which the\ndata fusion process is performed at different levels in\n\
    the hierarchy.\nIn principle, a decentralized data fusion system is more\ndifficult\
    \ to implement because of the computation and\ncommunication requirements. However,\
    \ in practice, there is\nno single best architecture, and the selection of the\
    \ most\nappropriate architecture should be made depending on the\nrequirements,\
    \ demand, existing networks, data availability,\nnode processing capabilities,\
    \ and organization of the data\nfusion system.\nThe reader might think that the\
    \ decentralized and\ndistributed architectures are similar; however, they have\n\
    meaningful differences (see Figure 4). First, in a distributed\narchitecture,\
    \ a preprocessing of the obtained measurements is\nperformed, which provides a\
    \ vector of features as a result (the\nfeatures are fused thereafter). In contrast,\
    \ in the decentralized\narchitecture, the complete data fusion process is conducted\n\
    in each node, and each of the nodes provides a globally\nfused result. Second,\
    \ the decentralized fusion algorithms\ntypically communicate information, employing\
    \ the Fisher\nand Shannon measurements. In contrast, distributed algo-\nrithms\
    \ typically share a common notion of state (position,\nvelocity, and identity)\
    \ with their associated probabilities,\nwhich are used to perform the fusion process\
    \ [9]. Third,\nbecause the decentralized data fusion algorithms exchange\ninformation\
    \ instead of states and probabilities, they have\nthe advantage of easily separating\
    \ old knowledge from new\nknowledge. Thus, the process is additive, and the associative\n\
    meaning is not relevant when the information is received\nand fused. However,\
    \ in the distributed data fusion algorithms\n(i.e., distributed by Kalman Filter),\
    \ the state that is going\nto be fused is not associative, and when and how the\
    \ fused\nestimates are computed is relevant. Nevertheless, in contrast\nto the\
    \ centralized architectures, the distributed algorithms\nreduce the necessary\
    \ communication and computational\ncosts because some tasks are computed in the\
    \ distributed\nnodes before data fusion is performed in the fusion node.\n3. Data\
    \ Association Techniques\nThe data association problem must determine the set\
    \ of\nmeasurements that correspond to each target (see Figure 5).\nLet us suppose\
    \ that there are \U0001D442 targets that are being tracked\nby only one sensor\
    \ in a cluttered environment (by a cluttered\nenvironment, we refer to an environment\
    \ that has several\ntargets that are to close each other). Then, the data association\n\
    problem can be defined as follows:\n(i) each sensor’s observation is received\
    \ in the fusion\nnode at discrete time intervals;\n(ii) the sensor might not provide\
    \ observations at a specific\ninterval;\n(iii) some observations are noise, and\
    \ other observations\noriginate from the detected target;\n(iv) for any specific\
    \ target and in every time interval, we\ndo not know (a priori) the observations\
    \ that will be\ngenerated by that target.\nTherefore, the goal of data association\
    \ is to establish the\nset of observations or measurements that are generated\
    \ by\nthe same target over time. Hall and Llinas [2] provided the\nfollowing definition\
    \ of data association: “The process of assign\nand compute the weights that relates\
    \ the observations or tracks\n(A track can be defined as an ordered set of points\
    \ that follow\na path and are generated by the same target.) from one set to\n\
    the observation of tracks of another set.”\nAs an example of the complexity of\
    \ the data association\nproblem, if we take a frame-to-frame association and assume\n\
    that \U0001D440 possible points could be detected in all \U0001D45B frames, then\n\
    the number of possible sets is (\U0001D440!)\U0001D45B−1. Note that from all\n\
    of these possible solutions, only one set establishes the true\nmovement of the\
    \ \U0001D440 points.\nData association is often performed before the state\nestimation\
    \ of the detected targets. Moreover, it is a key\nstep because the estimation\
    \ or classification will behave\nincorrectly if the data association phase does\
    \ not work\ncoherently. The data association process could also appear in\nall\
    \ of the fusion levels, but the granularity varies depending\non the objective\
    \ of each level.\n6\nThe Scientific World Journal\nPreprocessing\nPreprocessing\n\
    Preprocessing\nAlignment\nAssociation\nEstimation\nState\nof the\nobject\nCentralized\
    \ architecture\nDecentralized architecture\nDistributed architecture\nS1\nS2\n\
    Fusion node\nPreprocessing\nState\nof the\nobject\nState\nof the\nobject\nState\n\
    of the\nobject\nS1\nS2\nS1\nS2\nPreprocessing\nPreprocessing\nPreprocessing\n\
    Preprocessing\nPreprocessing\nAlignment\nAlignment\nAlignment\nAlignment\nAlignment\n\
    Alignment\nAlignment\nAssociation\nAssociation\nAssociation\nAssociation\nAssociation\n\
    Association\nAssociation\nEstimation\nEstimation\nEstimation\nEstimation\nEstimation\n\
    Estimation\nEstimation\nSn\nSn\nSn\nState\nof the\nobject\nFigure 4: Classification\
    \ based on the type of architecture.\nIn general, an exhaustive search of all\
    \ possible combina-\ntions grows exponentially with the number of targets; thus,\n\
    the data association problem becomes NP complete. The\nmost common techniques\
    \ that are employed to solve the data\nassociation problem are presented in the\
    \ following sections\n(from Sections 3.1 to 3.7).\n3.1. Nearest Neighbors and\
    \ K-Means. Nearest neighbor\n(NN) is the simplest data association technique.\
    \ NN is\na well-known clustering algorithm that selects or groups\nthe most similar\
    \ values. How close the one measurement is\nto another depends on the employed\
    \ distance metric and\ntypically depends on the threshold that is established\
    \ by the\ndesigner. In general, the employed criteria could be based on\n(1) an\
    \ absolute distance, (2) the Euclidean distance, or (3) a\nstatistical function\
    \ of the distance.\nNN is a simple algorithm that can find a feasible (approx-\n\
    imate) solution in a small amount of time. However, in a\ncluttered environment,\
    \ it could provide many pairs that have\nthe same probability and could thus produce\
    \ undesirable\nThe Scientific World Journal\n7\nTargets\nSensors\nObservations\n\
    Tracks\nTrack 1\nTrack 2\nFalse alarms\nAssociation\nS1\nS2\n...\nSn\nTrack n\n\
    y1, y2, . . . , yn\nFigure 5: Conceptual overview of the data association process\
    \ from multiple sensors and multiple targets. It is necessary to establish the\
    \ set\nof observations over time from the same object that forms a track.\nerror\
    \ propagation [10]. Moreover, this algorithm has poor\nperformance in environments\
    \ in which false measurements\nare frequent, which are in highly noisy environments.\n\
    All neighbors use a similar technique, in which all of the\nmeasurements inside\
    \ a region are included in the tracks.\n\U0001D43E-Means [11] method is a well-known\
    \ modification of\nthe NN algorithm. \U0001D43E-Means divides the dataset values\
    \ into\n\U0001D43E different clusters. \U0001D43E-Means algorithm finds the best\
    \ local-\nization of the cluster centroids, where best means a centroid\nthat\
    \ is in the center of the data cluster. \U0001D43E-Means is an iterative\nalgorithm\
    \ that can be divided into the following steps:\n(1) obtain the input data and\
    \ the number of desired\nclusters (\U0001D43E);\n(2) randomly assign the centroid\
    \ of each cluster;\n(3) match each data point with the centroid of each\ncluster;\n\
    (4) move the cluster centers to the centroid of the cluster;\n(5) if the algorithm\
    \ does not converge, return to step (3).\n\U0001D43E-Means is a popular algorithm\
    \ that has been widely\nemployed; however, it has the following disadvantages:\n\
    (i) the algorithm does not always find the optimal solu-\ntion for the cluster\
    \ centers;\n(ii) the number of clusters must be known a priori and\none must assume\
    \ that this number is the optimum;\n(iii) the algorithm assumes that the covariance\
    \ of the\ndataset is irrelevant or that it has been normalized\nalready.\nThere\
    \ are several options for overcoming these limita-\ntions. For the first one,\
    \ it is possible to execute the algorithm\nseveral times and obtain the solution\
    \ that has less variance.\nFor the second one, it is possible to start with a\
    \ low value\nof \U0001D43E and increment the values of \U0001D43E until an adequate\
    \ result\nis obtained. The third limitation can be easily overcome by\nmultiplying\
    \ the data with the inverse of the covariance matrix.\nMany variations have been\
    \ proposed to Lloyd’s basic\n\U0001D43E-Means algorithm [11], which has a computational\
    \ upper\nbound cost of \U0001D442(\U0001D43E\U0001D45B), where \U0001D45B is the\
    \ number of input points\nand \U0001D43E is the number of desired clusters. Some\
    \ algorithms\nmodify the initial cluster assignments to improve the separa-\n\
    tions and reduce the number of iterations. Others introduce\nsoft or multinomial\
    \ clustering assignments using fuzzy logic,\nprobabilistic, or the Bayesian techniques.\
    \ However, most of\nthe previous variations still must perform several iterations\n\
    through the data space to converge to a reasonable solution.\nThis issue becomes\
    \ a major disadvantage in several real-\ntime applications. A new approach that\
    \ is based on having\na large (but still affordable) number of cluster candidates\n\
    compared to the desired \U0001D43E clusters is currently gaining\nattention. The\
    \ idea behind this computational model is that\nthe algorithm builds a good sketch\
    \ of the original data while\nreducing the dimensionality of the input space significantly.\n\
    In this manner, a weighted \U0001D43E-Means can be applied to the\nlarge candidate\
    \ clusters to derive a good clustering of the\noriginal data. Using this idea,\
    \ [12] presented an efficient\nand scalable \U0001D43E-Means algorithm that is\
    \ based on random\nprojections. This algorithm requires only one pass through\n\
    the input data to build the clusters. More specifically, if the\ninput data distribution\
    \ holds some separability requirements,\nthen the number of required candidate\
    \ clusters grows only\naccording to \U0001D442(log \U0001D45B), where \U0001D45B\
    \ is the number of observations\nin the original data. This salient feature makes\
    \ the algorithm\nscalable in terms of both the memory and computational\nrequirements.\n\
    3.2. Probabilistic Data Association. The probabilistic data\nassociation (PDA)\
    \ algorithm was proposed by Bar-Shalom\nand Tse [13] and is also known as the\
    \ modified filter of all\nneighbors. This algorithm assigns an association probability\n\
    to each hypothesis from a valid measurement of a target.\nA valid measurement\
    \ refers to the observation that falls in\nthe validation gate of the target at\
    \ that time instant. The\nvalidation gate, \U0001D6FE, which is the center around\
    \ the predicted\nmeasurements of the target, is used to select the set of basic\n\
    measurements and is defined as\n\U0001D6FE ≥ (\U0001D44D (\U0001D458) − ̂\U0001D467\
    \ (\U0001D458 | \U0001D458 − 1))\U0001D447\U0001D446−1 (\U0001D458) (\U0001D467\
    \ (\U0001D458) − \U0001D467 (\U0001D458 | \U0001D458 − 1)) ,\n(1)\nwhere \U0001D43E\
    \ is the temporal index, \U0001D446(\U0001D458) is the covariance gain,\nand \U0001D6FE\
    \ determines the gating or window size. The set of valid\nmeasurements at time\
    \ instant \U0001D458 is defined as\n\U0001D44D (\U0001D458) = \U0001D467\U0001D456\
    \ (\U0001D458) ,\n\U0001D456 = 1, . . . , \U0001D45A\U0001D458,\n(2)\n8\nThe Scientific\
    \ World Journal\nwhere \U0001D467\U0001D456(\U0001D458) is the \U0001D456-measurement\
    \ in the validation region at\ntime instant \U0001D458. We give the standard equations\
    \ of the PDA\nalgorithm next. For the state prediction, consider\n̂\U0001D465\
    \ (\U0001D458 | \U0001D458 − 1) = \U0001D439 (\U0001D458 − 1) ̂\U0001D465 (\U0001D458\
    \ − 1 | \U0001D458 − 1) ,\n(3)\nwhere \U0001D439(\U0001D458 − 1) is the transition\
    \ matrix at time instant \U0001D458 − 1.\nTo calculate the measurement prediction,\
    \ consider\n̂\U0001D467 (\U0001D458 | \U0001D458 − 1) = \U0001D43B (\U0001D458\
    ) ̂\U0001D465 (\U0001D458 | \U0001D458 − 1) ,\n(4)\nwhere \U0001D43B(\U0001D458\
    ) is the linearization measurement matrix. To\ncompute the gain or the innovation\
    \ of the \U0001D456-measurement,\nconsider\nV\U0001D456 (\U0001D458) = \U0001D467\
    \U0001D456 (\U0001D458) − ̂\U0001D467 (\U0001D458 | \U0001D458 − 1) .\n(5)\nTo\
    \ calculate the covariance prediction, consider\n̂\U0001D443 (\U0001D458 | \U0001D458\
    \ − 1) = \U0001D439 (\U0001D458 − 1) ̂\U0001D443 (\U0001D458 − 1 | \U0001D458\
    \ − 1) \U0001D439(\U0001D458 − 1)\U0001D447 + \U0001D444 (\U0001D458) ,\n(6)\n\
    where \U0001D444(\U0001D458) is the process noise covariance matrix. To com-\n\
    pute the innovation covariance (\U0001D446) and the Kalman gain (\U0001D43E)\n\
    \U0001D446 (\U0001D458) = \U0001D43B (\U0001D458) ̂\U0001D443 (\U0001D458 | \U0001D458\
    \ − 1) \U0001D43B(\U0001D458)\U0001D447 + \U0001D445,\n\U0001D43E (\U0001D458\
    ) = ̂\U0001D443 (\U0001D458 | \U0001D458 − 1) \U0001D43B(\U0001D458)\U0001D447\
    \U0001D446(\U0001D458)−1.\n(7)\nTo obtain the covariance update in the case in\
    \ which the mea-\nsurements originated by the target are known, consider\n\U0001D443\
    0 (\U0001D458 | \U0001D458) = ̂\U0001D443 (\U0001D458 | \U0001D458 − 1) − \U0001D43E\
    \ (\U0001D458) \U0001D446 (\U0001D458) \U0001D43E(\U0001D458)\U0001D447.\n(8)\n\
    The total update of the covariance is computed as\nV (\U0001D458) =\n\U0001D45A\
    \U0001D458\n∑\n\U0001D456=1\n\U0001D6FD\U0001D456 (\U0001D458) V\U0001D456 (\U0001D458\
    ) ,\n\U0001D443 (\U0001D458) = \U0001D43E (\U0001D458) [\n\U0001D45A\U0001D458\
    \n∑\n\U0001D456=1\n(\U0001D6FD\U0001D456 (\U0001D458) V\U0001D456 (\U0001D458\
    ) V\U0001D456(\U0001D458)\U0001D447) − V (\U0001D458) V(\U0001D458)\U0001D447\
    ] \U0001D43E\U0001D447 (\U0001D458) ,\n(9)\nwhere \U0001D45A\U0001D458 is the\
    \ number of valid measurements in the instant\n\U0001D458. The equation to update\
    \ the estimated state, which is formed\nby the position and velocity, is given\
    \ by\n̂\U0001D465 (\U0001D458 | \U0001D458) = ̂\U0001D465 (\U0001D458 | \U0001D458\
    \ − 1) + \U0001D43E (\U0001D458) V (\U0001D458) .\n(10)\nFinally, the association\
    \ probabilities of PDA are as follows:\n\U0001D6FD\U0001D456 (\U0001D458) =\n\U0001D45D\
    \U0001D456 (\U0001D458)\n∑\U0001D45A\U0001D458\n\U0001D456=0 \U0001D45D\U0001D456\
    \ (\U0001D458),\n(11)\nwhere\n\U0001D45D\U0001D456 (\U0001D458) =\n{\n{\n{\n{\n\
    {\n{\n{\n{\n{\n{\n{\n{\n{\n(2Π)\U0001D440/2\U0001D706√\U000F5128\U000F5128\U000F5128\
    \U000F5128\U0001D446\U0001D456 (\U0001D458)\U000F5128\U000F5128\U000F5128\U000F5128\
    \ (1 − \U0001D443\U0001D451\U0001D443\U0001D454)\n\U0001D443\U0001D451\nif \U0001D456\
    \ = 0\nexp [−1\n2 V\U0001D447 (\U0001D458) \U0001D446−1 (\U0001D458) V (\U0001D458\
    )]\nif \U0001D456 ̸= 0\n0\nin other cases,\n(12)\nwhere \U0001D440 is the dimension\
    \ of the measurement vector, \U0001D706 is the\ndensity of the clutter environment,\
    \ \U0001D443\U0001D451 is the detection prob-\nability of the correct measurement,\
    \ and \U0001D443\U0001D454 is the validation\nprobability of a detected value.\n\
    In the PDA algorithm, the state estimation of the target is\ncomputed as a weighted\
    \ sum of the estimated state under all\nof the hypotheses. The algorithm can associate\
    \ different mea-\nsurements to one specific target. Thus, the association of the\n\
    different measurements to a specific target helps PDA to\nestimate the target\
    \ state, and the association probabilities\nare used as weights. The main disadvantages\
    \ of the PDA\nalgorithm are the following:\n(i) loss of tracks: because PDA ignores\
    \ the interference\nwith other targets, it sometimes could wrongly clas-\nsify\
    \ the closest tracks. Therefore, it provides a poor\nperformance when the targets\
    \ are close to each other\nor crossed;\n(ii) the suboptimal Bayesian approximation:\
    \ when the\nsource of information is uncertain, PDA is the sub-\noptimal Bayesian\
    \ approximation to the association\nproblem;\n(iii) one target: PDA was initially\
    \ designed for the asso-\nciation of one target in a low-cluttered environment.\n\
    The number of false alarms is typically modeled with\nthe Poisson distribution,\
    \ and they are assumed to be\ndistributed uniformly in space. PDA behaves incor-\n\
    rectly when there are multiple targets because the false\nalarm model does not\
    \ work well;\n(iv) track management: because PDA assumes that the\ntrack is already\
    \ established, algorithms must be pro-\nvided for track initialization and track\
    \ deletion.\nPDA is mainly good for tracking targets that do not\nmake abrupt\
    \ changes in their movement patterns. PDA will\nmost likely lose the target if\
    \ it makes abrupt changes in its\nmovement patterns.\n3.3. Joint Probabilistic\
    \ Data Association. Joint probabilistic\ndata association (JPDA) is a suboptimal\
    \ approach for tracking\nmultiple targets in cluttered environments [14]. JPDA\
    \ is\nsimilar to PDA, with the difference that the association\nprobabilities\
    \ are computed using all of the observations\nand all of the targets. Thus, in\
    \ contrast to PDA, JPDA\nconsiders various hypotheses together and combines them.\n\
    JPDA determines the probability \U0001D6FD\U0001D461\n\U0001D456(\U0001D458) that\
    \ measurement \U0001D456 is\noriginated from target \U0001D461, accounting for\
    \ the fact that under\nthis hypothesis, the measurement cannot be generated by\n\
    other targets. Therefore, for a known number of targets, it\nevaluates the different\
    \ options of the measurement-target\nassociation (for the most recent set of measurements)\
    \ and\ncombines them into the corresponding state estimation. If\nthe association\
    \ probability is known, then the Kalman filter\nupdating equation of the track\
    \ \U0001D461 can be written as\n̂\U0001D465\U0001D461 (\U0001D458 | \U0001D458\
    ) = ̂\U0001D465\U0001D461 (\U0001D458 | \U0001D458 − 1) + \U0001D43E (\U0001D458\
    ) V\U0001D461 (\U0001D458) ,\n(13)\nwhere ̂\U0001D465\U0001D461(\U0001D458 | \U0001D458\
    ) and ̂\U0001D465\U0001D461(\U0001D458 | \U0001D458 − 1) are the estimation and\n\
    prediction of target \U0001D461, and \U0001D43E(\U0001D458) is the filter gain.\
    \ The weighted\nThe Scientific World Journal\n9\nsum of the residuals associated\
    \ with the observation \U0001D45A(\U0001D458) of\ntarget \U0001D461 is as follows:\n\
    V\U0001D461 (\U0001D458) =\n\U0001D45A(\U0001D458)\n∑\n\U0001D456=1\n\U0001D6FD\
    \U0001D461\n\U0001D456 (\U0001D458) V\U0001D461\n\U0001D456 (\U0001D458) ,\n(14)\n\
    where V\U0001D461\n\U0001D456 = \U0001D467\U0001D456(\U0001D458) − \U0001D43B\U0001D465\
    \U0001D461(\U0001D458 | \U0001D458 − 1). Therefore, this method\nincorporates\
    \ all of the observations (inside the neighborhood\nof the target’s predicted\
    \ position) to update the estimated\nposition by using a posterior probability\
    \ that is a weighted\nsum of residuals.\nThe main restrictions of JPDA are the\
    \ following:\n(i) a measurement cannot come from more than one\ntarget;\n(ii)\
    \ two measurements cannot be originated by the same\ntarget (at one time instant);\n\
    (iii) the sum of all of the measurements’ probabilities that\nare assigned to\
    \ one target must be 1: ∑\U0001D45A(\U0001D458)\n\U0001D456=0 \U0001D6FD\U0001D461\
    \n\U0001D456(\U0001D458) = 1.\nThe main disadvantages of JPDA are the following:\n\
    (i) it requires an explicit mechanism for track initial-\nization. Similar to\
    \ PDA, JPDA cannot initialize new\ntracks or remove tracks that are out of the\
    \ observation\narea;\n(ii) JPDA is a computationally expensive algorithm when\n\
    it is applied in environments that have multiple targets\nbecause the number of\
    \ hypotheses is incremented\nexponentially with the number of targets.\nIn general,\
    \ JPDA is more appropriate than MHT in\nsituations in which the density of false\
    \ measurements is high\n(i.e., sonar applications).\n3.4. Multiple Hypothesis\
    \ Test. The underlying idea of the\nmultiple hypothesis test (MHT) is based on\
    \ using more than\ntwo consecutive observations to make an association with\n\
    better results. Other algorithms that use only two consecutive\nobservations have\
    \ a higher probability of generating an error.\nIn contrast to PDA and JPDA, MHT\
    \ estimates all of the\npossible hypotheses and maintains new hypotheses in each\n\
    iteration.\nMHT was developed to track multiple targets in cluttered\nenvironments;\
    \ as a result, it combines the data association\nproblem and tracking into a unified\
    \ framework, becoming\nan estimation technique as well. The Bayes rule or the\n\
    Bayesian networks are commonly employed to calculate the\nMHT hypothesis. In general,\
    \ researchers have claimed that\nMHT outperforms JPDA for the lower densities\
    \ of false\npositives. However, the main disadvantage of MHT is the\ncomputational\
    \ cost when the number of tracks or false\npositives is incremented. Pruning the\
    \ hypothesis tree using\na window could solve this limitation.\nThe Reid [15]\
    \ tracking algorithm is considered the stan-\ndard MHT algorithm, but the initial\
    \ integer programming\nformulation of the problem is due to Morefield [16]. MHT\
    \ is\nan iterative algorithm in which each iteration starts with a set\nof correspondence\
    \ hypotheses. Each hypothesis is a collec-\ntion of disjoint tracks, and the prediction\
    \ of the target in the\nnext time instant is computed for each hypothesis. Next,\
    \ the\npredictions are compared with the new observations by using\na distance\
    \ metric. The set of associations established in each\nhypothesis (based on a\
    \ distance) introduces new hypotheses\nin the next iteration. Each new hypothesis\
    \ represents a new\nset of tracks that is based on the current observations.\n\
    Note that each new measurement could come from (i) a\nnew target in the visual\
    \ field of view, (ii) a target being tracked,\nor (iii) noise in the measurement\
    \ process. It is also possible\nthat a measurement is not assigned to a target\
    \ because the\ntarget disappears, or because it is not possible to obtain a\n\
    target measurement at that time instant.\nMHT maintains several correspondence\
    \ hypotheses for\neach target in each frame. If the hypothesis in the instant\n\
    \U0001D458 is represented by \U0001D43B(\U0001D458)\n=\n[ℎ\U0001D459(\U0001D458\
    ), \U0001D458\n=\n1, . . . , \U0001D45B], then\nthe probability of the hypothesis\
    \ ℎ\U0001D459(\U0001D458) could be represented\nrecursively using the Bayes rule\
    \ as follows:\n\U0001D443 (ℎ\U0001D459 (\U0001D458) | \U0001D44D (\U0001D458))\
    \ = \U0001D443 (ℎ\U0001D454 (\U0001D458 − 1) , \U0001D44E\U0001D456 (\U0001D458\
    ) | \U0001D44D (\U0001D458))\n= 1\n\U0001D450 \U0001D443 (\U0001D44D (\U0001D458\
    ) | ℎ\U0001D454 (\U0001D458 − 1) , \U0001D44E\U0001D456 (\U0001D458))\n∗ \U0001D443\
    \ (\U0001D44E\U0001D456 (\U0001D458) | ℎ\U0001D454 (\U0001D458 − 1)) ∗ \U0001D443\
    \ (ℎ\U0001D454 (\U0001D458 − 1)) ,\n(15)\nwhere ℎ\U0001D454(\U0001D458 − 1) is\
    \ the hypothesis \U0001D454 of the complete set until\nthe time instant \U0001D458\
    −1; \U0001D44E\U0001D456(\U0001D458) is the \U0001D456th possible association\
    \ of the\ntrack to the object; \U0001D44D(\U0001D458) is the set of detections\
    \ of the current\nframe, and \U0001D450 is a normal constant.\nThe first term\
    \ on the right side of the previous equation\nis the likelihood function of the\
    \ measurement set \U0001D44D(\U0001D458) given\nthe joint likelihood and current\
    \ hypothesis. The second term\nis the probability of the association hypothesis\
    \ of the current\ndata given the previous hypothesis ℎ\U0001D454(\U0001D458 −\
    \ 1). The third term\nis the probability of the previous hypothesis from which\
    \ the\ncurrent hypothesis is calculated.\nThe MHT algorithm has the ability to\
    \ detect a new\ntrack while maintaining the hypothesis tree structure. The\nprobability\
    \ of a true track is given by the Bayes decision model\nas\n\U0001D443 (\U0001D706\
    \ | \U0001D44D) = \U0001D443 (\U0001D44D | \U0001D706) ∗ \U0001D443∘ (\U0001D706\
    )\n\U0001D443 (\U0001D44D)\n,\n(16)\nwhere \U0001D443(\U0001D44D | \U0001D706\
    ) is the probability of obtaining the set of\nmeasurements \U0001D44D given \U0001D706\
    , \U0001D443∘(\U0001D706) is the a priori probability of\nthe source signal, and\
    \ \U0001D443(\U0001D44D) is the probability of obtaining the\nset of detections\
    \ \U0001D44D.\nMHT considers all of the possibilities, including both\nthe track\
    \ maintenance and the initialization and removal\nof tracks in an integrated framework.\
    \ MHT calculates the\npossibility of having an object after the generation of\
    \ a set\nof measurements using an exhaustive approach, and the\nalgorithm does\
    \ not assume a fixed number of targets. The key\nchallenge of MHT is the effective\
    \ hypothesis management.\nThe baseline MHT algorithm can be extended as follows:\n\
    (i) use the hypothesis aggregation for missed targets births,\n10\nThe Scientific\
    \ World Journal\ncardinality tracking, and closely spaced objects; (ii) apply\n\
    a multistage MHT for improving the performance and\nrobustness in challenging\
    \ settings; and (iii) use a feature-\naided MHT for extended object surveillance.\n\
    The main disadvantage of this algorithm is the compu-\ntational cost, which grows\
    \ exponentially with the number of\ntracks and measurements. Therefore, the practical\
    \ implemen-\ntation of this algorithm is limited because it is exponential in\n\
    both time and memory.\nWith the aim of reducing the computational cost, [17]\n\
    presented a probabilistic MHT algorithm in which the\nassociations are considered\
    \ to be random variables that\nare statistically independent and in which performing\
    \ an\nexhaustive search enumeration is avoided. This algorithm is\nknown as PMHT.\
    \ The PMHT algorithm assumes that the\nnumber of targets and measurements is known.\
    \ With the\nsame goal of reducing the computational cost, [18] presented\nan efficient\
    \ implementation of the MHT algorithm. This\nimplementation was the first version\
    \ to be applied to perform\ntracking in visual environments. They employed the\
    \ Murty\n[19] algorithm to determine the best set of \U0001D458 hypotheses\nin\
    \ polynomial time, with the goal of tracking the points of\ninterest.\nMHT typically\
    \ performs the tracking process by employ-\ning only one characteristic, commonly\
    \ the position. The\nBayesian combination to use multiple characteristics was\n\
    proposed by Liggins II et al. [20].\nA linear-programming-based relaxation approach\
    \ to the\noptimization problem in MHT tracking was proposed inde-\npendently by\
    \ Coraluppi et al. [21] and Storms and Spieksma\n[22]. Joo and Chellappa [23]\
    \ proposed an association algo-\nrithm for tracking multiple targets in visual\
    \ environments.\nTheir algorithm is based on in MHT modification in which\na measurement\
    \ can be associated with more than one target,\nand several targets can be associated\
    \ with one measurement.\nThey also proposed a combinatorial optimization algorithm\n\
    to generate the best set of association hypotheses. Their\nalgorithm always finds\
    \ the best hypothesis, in contrast to\nother models, which are approximate. Coraluppi\
    \ and Carthel\n[24] presented a generalization of the MHT algorithm using\na recursion\
    \ over hypothesis classes rather than over a single\nhypothesis. This work has\
    \ been applied in a special case of\nthe multi-target tracking problem, called\
    \ cardinality tracking,\nin which they observed the number of sensor measurements\n\
    instead of the target states.\n3.5. Distributed Joint Probabilistic Data Association.\
    \ The dis-\ntributed version of the joint probabilistic data association\n(JPDA-D)\
    \ was presented by Chang et al. [25]. In this tech-\nnique, the estimated state\
    \ of the target (using two sensors)\nafter being associated is given by\n\U0001D438\
    \ {\U0001D465 | \U0001D44D1, \U0001D44D2} =\n\U0001D45A1\n∑\n\U0001D457=0\n\U0001D45A\
    2\n∑\n\U0001D459=0\n\U0001D438 {\U0001D465 | \U0001D7121\n\U0001D457, \U0001D712\
    2\n\U0001D459 , \U0001D44D1, \U0001D44D2}\n∗ \U0001D443 {\U0001D7121\n\U0001D457\
    , \U0001D7122\n\U0001D459 | \U0001D44D1, \U0001D44D2} ,\n(17)\nwhere \U0001D45A\
    \U0001D456, \U0001D456\n=\n1, 2, is the last set of measurements of\nsensor 1\
    \ and 2, \U0001D44D\U0001D456, \U0001D456 = 1, 2, is the set of accumulative data,\n\
    and \U0001D712 is the association hypothesis. The first term of the right\nside\
    \ of the equation is calculated from the associations that\nwere made earlier.\
    \ The second term is computed from the\nindividual association probabilities as\
    \ follows:\n\U0001D443 (\U0001D7121\n\U0001D457, \U0001D7122\n\U0001D459 | \U0001D44D\
    1, \U0001D44D2) = ∑\n\U0001D4651\n∑\n\U0001D4652\n= \U0001D443 (\U0001D7121, \U0001D712\
    2 | \U0001D44D1, \U0001D44D2) ̂\U0001D7141\n\U0001D457 (\U0001D7121) ̂\U0001D714\
    2\n\U0001D459 (\U0001D7122) ,\n\U0001D443 (\U0001D7121, \U0001D7122 | \U0001D44D\
    1, \U0001D44D2) = 1\n\U0001D450 \U0001D443 (\U0001D7121 | \U0001D44D1) \U0001D443\
    \ (\U0001D7122 | \U0001D44D2) \U0001D6FE (\U0001D7121, \U0001D7122) ,\n(18)\n\
    where \U0001D712\U0001D456 are the joint hypotheses involving all of the\nmeasurements\
    \ and all of the objectives, and ̂\U0001D714\U0001D456\n\U0001D457(\U0001D712\U0001D456\
    ) are the\nbinary indicators of the measurement-target association. The\nadditional\
    \ term \U0001D6FE(\U0001D7121, \U0001D7122) depends on the correlation of the\n\
    individual hypothesis and reflects the localization influence\nof the current\
    \ measurements in the joint hypotheses.\nThese equations are obtained assuming\
    \ that commu-\nnication exists after every observation, and there are only\napproximations\
    \ in the case in which communication is\nsporadic and when a substantial amount\
    \ of noise occurs.\nTherefore, this algorithm is a theoretical model that has\
    \ some\nlimitations in practical applications.\n3.6. Distributed Multiple Hypothesis\
    \ Test. The distributed\nversion of the MHT algorithm (MHT-D) [26, 27] follows\
    \ a\nsimilar structure as the JPDA-D algorithm. Let us assume the\ncase in which\
    \ one node must fuse two sets of hypotheses and\ntracks. If the hypotheses and\
    \ track sets are represented by\n\U0001D43B\U0001D456(\U0001D44D\U0001D456) and\
    \ \U0001D447\U0001D456(\U0001D44D\U0001D456) with \U0001D456 = 1, 2, the hypothesis\
    \ probabilities\nare represented by \U0001D706\U0001D456\n\U0001D457; and the\
    \ state distribution of the tracks\n(\U0001D70F\U0001D456\n\U0001D457) is represented\
    \ by \U0001D443(\U0001D706\U0001D456\n\U0001D457) and \U0001D443(\U0001D465 |\
    \ \U0001D44D\U0001D456, \U0001D70F\U0001D456\n\U0001D457); then, the\nmaximum\
    \ available information in the fusion node is \U0001D44D =\n\U0001D44D1 ∪ \U0001D44D\
    2. The data fusion objective of the MHT-D is to\nobtain the set of hypotheses\
    \ \U0001D43B(\U0001D44D), the set of tracks \U0001D447(\U0001D44D), the\nhypothesis\
    \ probabilities \U0001D443(\U0001D706 | \U0001D44D), and the state distribution\n\
    \U0001D45D(\U0001D465 | \U0001D44D, \U0001D70F) for the observed data.\nThe MHT-D\
    \ algorithm is composed of the following\nsteps:\n(1) hypothesis formation: for\
    \ each hypothesis pair \U0001D7061\n\U0001D457 and\n\U0001D7062\n\U0001D458, which\
    \ could be fused, a track \U0001D70F is formed by\nassociating the pair of tracks\
    \ \U0001D70F1\n\U0001D457 and \U0001D70F2\n\U0001D458, where each\npair comes\
    \ from one node and could originate from\nthe same target. The final result of\
    \ this stage is a set\nof hypotheses denoted by \U0001D43B(\U0001D44D) and the\
    \ fused tracks\n\U0001D447(\U0001D44D);\n(2) hypothesis evaluation: in this stage,\
    \ the association\nprobability of each hypothesis and the estimated\nstate of\
    \ each fused track are obtained. The dis-\ntributed estimation algorithm is employed\
    \ to calcu-\nlate the likelihood of the possible associations and\nthe obtained\
    \ estimations at each specific association.\nThe Scientific World Journal\n11\n\
    Using the information model, the probability of each\nfused hypothesis is given\
    \ by\n\U0001D443 (\U0001D706 | \U0001D44D) = \U0001D436−1∏\n\U0001D457∈\U0001D43D\
    \n\U0001D443(\U0001D706(\U0001D457) | \U0001D44D(\U0001D457))\n\U0001D6FC(\U0001D457\
    )∏\n\U0001D70F∈\U0001D706\n\U0001D43F (\U0001D70F | \U0001D44D) ,\n(19)\nwhere\
    \ \U0001D436 is a normalizing constant, and \U0001D43F(\U0001D70F | \U0001D44D\
    ) is the\nlikelihood of each hypothesis pair.\nThe main disadvantage of the MHT-D\
    \ is the high com-\nputational cost that is in the order of \U0001D442(\U0001D45B\
    \U0001D440), where \U0001D45B is the\nnumber of possible associations and \U0001D440\
    \ is the number of\nvariables to be estimated.\n3.7. Graphical Models. Graphical\
    \ models are a formalism for\nrepresenting and reasoning with probabilities and\
    \ indepen-\ndence. A graphical model represents a conditional decom-\nposition\
    \ of the joint probability. A graphical model can be\nrepresented as a graph in\
    \ which the nodes denote random\nvariables; the edges denote the possible dependence\
    \ between\nthe random variables, and the plates denote the replication of\na substructure,\
    \ with the appropriate indexing of the relevant\nvariables. The graph captures\
    \ the joint distribution over the\nrandom variables, which can be decomposed into\
    \ a product\nof factors that each depend on only a subset of variables. There\n\
    are two major classes of graphical models: (i) the Bayesian\nnetworks [28], which\
    \ are also known as the directed graphical\nmodels, and (ii) the Markov random\
    \ fields, which are also\nknown as undirected graphical models. The directed graph-\n\
    ical models are useful for expressing causal relationships\nbetween random variables,\
    \ whereas undirected models are\nbetter suited for expressing soft constraints\
    \ between random\nvariables. We refer the reader to the book of Koller and\nFriedman\
    \ [29] for more information on graphical models.\nA framework based on graphical\
    \ models can solve the\nproblem of distributed data association in synchronized\n\
    sensor networks with overlapped areas and where each sensor\nreceives noisy measurements;\
    \ this solution was proposed\nby Chen et al. [30, 31]. Their work is based on\
    \ graphical\nmodels that are used to represent the statistical dependence\nbetween\
    \ random variables. The data association problem is\ntreated as an inference problem\
    \ and solved by using the\nmax-product algorithm [32]. Graphical models represent\n\
    statistical dependencies between variables as graphs, and\nthe max-product algorithm\
    \ converges when the graph is\na tree structure. Moreover, the employed algorithm\
    \ could\nbe implemented in a distributed manner by exchanging\nmessages between\
    \ the source nodes in parallel. With this\nalgorithm, if each sensor has \U0001D45B\
    \ possible combinations of\nassociations and there are \U0001D440 variables to\
    \ be estimated, it has\na complexity of \U0001D442(\U0001D45B2\U0001D440), which\
    \ is reasonable and less than\nthe \U0001D442(\U0001D45B\U0001D440) complexity\
    \ of the MHT-D algorithm. However,\naspecial attention must be given to the correlated\
    \ variables\nwhen building the graphical model.\n4. State Estimation Methods\n\
    State estimation techniques aim to determine the state of\nthe target under movement\
    \ (typically the position) given\nthe observation or measurements. State estimation\
    \ tech-\nniques are also known as tracking techniques. In their general\nform,\
    \ it is not guaranteed that the target observations are\nrelevant, which means\
    \ that some of the observations could\nactually come from the target and others\
    \ could be only noise.\nThe state estimation phase is a common stage in data fusion\n\
    algorithms because the target’s observation could come from\ndifferent sensors\
    \ or sources, and the final goal is to obtain a\nglobal target state from the\
    \ observations.\nThe estimation problem involves finding the values of the\nvector\
    \ state (e.g., position, velocity, and size) that fits as much\nas possible with\
    \ the observed data. From a mathematical\nperspective, we have a set of redundant\
    \ observations, and\nthe goal is to find the set of parameters that provides the\n\
    best fit to the observed data. In general, these observations\nare corrupted by\
    \ errors and the propagation of noise in the\nmeasurement process. State estimation\
    \ methods fall under\nlevel 1 of the JDL classification and could be divided into\
    \ two\nbroader groups:\n(1) linear dynamics and measurements: here, the esti-\n\
    mation problem has a standard solution. Specifically,\nwhen the equations of the\
    \ object state and the mea-\nsurements are linear, the noise follows the Gaussian\n\
    distribution, and we do not refer to it as a clutter\nenvironment; in this case,\
    \ the optimal theoretical\nsolution is based on the Kalman filter;\n(2) nonlinear\
    \ dynamics: the state estimation problem\nbecomes difficult, and there is not\
    \ an analytical solu-\ntion to solve the problem in a general manner. In prin-\n\
    ciple, there are no practical algorithms available to\nsolve this problem satisfactorily.\n\
    Most of the state estimation methods are based on control\ntheory and employ the\
    \ laws of probability to compute a\nvector state from a vector measurement or\
    \ a stream of vector\nmeasurements. Next, the most common estimation methods\n\
    are presented, including maximum likelihood and maxi-\nmum posterior (Section\
    \ 4.1), the Kalman filter (Section 4.2),\nparticle filter (Section 4.3), the distributed\
    \ Kalman filter\n(Section 4.4), distributed particle filter (Section 4.5) and,\n\
    covariance consistency methods (Section 4.6).\n4.1. Maximum Likelihood and Maximum\
    \ Posterior. The max-\nimum likelihood (ML) technique is an estimation method\n\
    that is based on probabilistic theory. Probabilistic estimation\nmethods are appropriate\
    \ when the state variable follows an\nunknown probability distribution [33]. In\
    \ the context of\ndata fusion, \U0001D465 is the state that is being estimated,\
    \ and \U0001D467 =\n(\U0001D467(1), . . . , \U0001D467(\U0001D458)) is a sequence\
    \ of \U0001D458 previous observations of\n\U0001D465. The likelihood function\
    \ \U0001D706(\U0001D465) is defined as a probability\ndensity function of the\
    \ sequence of \U0001D467 observations given the\ntrue value of the state \U0001D465\
    . Consider\n\U0001D706 (\U0001D465) = \U0001D45D (\U0001D467 | \U0001D465) .\n\
    (20)\nThe ML estimator finds the value of \U0001D465 that maximizes the\nlikelihood\
    \ function:\n̂\U0001D465 (\U0001D458) = arg max\n\U0001D465\n\U0001D45D (\U0001D467\
    \ | \U0001D465) ,\n(21)\n12\nThe Scientific World Journal\nwhich can be obtained\
    \ from the analytical or empirical\nmodels of the sensors. This function expresses\
    \ the probability\nof the observed data. The main disadvantage of this method\n\
    in practice is that it requires the analytical or empirical model\nof the sensor\
    \ to be known to provide the prior distribution\nand compute the likelihood function.\
    \ This method can also\nsystematically underestimate the variance of the distribution,\n\
    which leads to a bias problem. However, the bias of the ML\nsolution becomes less\
    \ significant as the number \U0001D441 of data\npoints increases and is equal\
    \ to the true variance of the\ndistribution that generated the data at the limit\
    \ \U0001D441 → ∞.\nThe maximum posterior (MAP) method is based on the\nBayesian\
    \ theory. It is employed when the parameter \U0001D465 to\nbe estimated is the\
    \ output of a random variable that has a\nknown probability density function \U0001D45D\
    (\U0001D465). In the context of\ndata fusion, \U0001D465 is the state that is\
    \ being estimated and \U0001D467 =\n(\U0001D467(1), . . . , \U0001D467(\U0001D458\
    )) is a sequence of \U0001D458 previous observations of \U0001D465.\nThe MAP estimator\
    \ finds the value of \U0001D465 that maximizes the\nposterior probability distribution\
    \ as follows:\n̂\U0001D465 (\U0001D458) = arg max\n\U0001D465\n\U0001D45D (\U0001D465\
    \ | \U0001D467) .\n(22)\nBoth methods (ML and MAP) aim to find the most likely\n\
    value for the state \U0001D465. However, ML assumes that \U0001D465 is a fixed\n\
    but an unknown point from the parameter space, whereas\nMAP considers \U0001D465\
    \ to be the output of a random variable with\na known a priori probability density\
    \ function. Both of these\nmethods are equivalent when there is no a priori information\n\
    about \U0001D465, that is, when there are only observations.\n4.2. The Kalman\
    \ Filter. The Kalman filter is the most popular\nestimation technique. It was\
    \ originally proposed by Kalman\n[34] and has been widely studied and applied\
    \ since then. The\nKalman filter estimates the state \U0001D465 of a discrete\
    \ time process\ngoverned by the following space-time model:\n\U0001D465 (\U0001D458\
    \ + 1) = Φ (\U0001D458) \U0001D465 (\U0001D458) + \U0001D43A (\U0001D458) \U0001D462\
    \ (\U0001D458) + \U0001D464 (\U0001D458)\n(23)\nwith the observations or measurements\
    \ \U0001D467 at time \U0001D458 of the state\n\U0001D465 represented by\n\U0001D467\
    \ (\U0001D458) = \U0001D43B (\U0001D458) \U0001D465 (\U0001D458) + V (\U0001D458\
    ) ,\n(24)\nwhere Φ(\U0001D458) is the state transition matrix, \U0001D43A(\U0001D458\
    ) is the input\nmatrix transition, \U0001D462(\U0001D458) is the input vector,\
    \ \U0001D43B(\U0001D458) is the\nmeasurement matrix, and \U0001D464 and V are\
    \ the random Gaussian\nvariables with zero mean and covariance matrices of \U0001D444\
    (\U0001D458)\nand \U0001D445(\U0001D458), respectively. Based on the measurements\
    \ and on\nthe system parameters, the estimation of \U0001D465(\U0001D458), which\
    \ is\nrepresented by ̂\U0001D465(\U0001D458), and the prediction of \U0001D465\
    (\U0001D458 + 1), which\nis represented by ̂\U0001D465(\U0001D458 + 1 | \U0001D458\
    ), are given by the following:\n̂\U0001D465 (\U0001D458) = ̂\U0001D465 (\U0001D458\
    \ | \U0001D458 + 1) + \U0001D43E (\U0001D458) [\U0001D467 (\U0001D458) − \U0001D43B\
    \ (\U0001D458) ̂\U0001D465 (\U0001D458 | \U0001D458 − 1)] ,\n̂\U0001D465 (\U0001D458\
    \ + 1 | \U0001D458) = Φ (\U0001D458) ̂\U0001D465 (\U0001D458 | \U0001D458) + \U0001D43A\
    \ (\U0001D458) \U0001D462 (\U0001D458) ,\n(25)\nrespectively, where \U0001D43E\
    \ is the filter gain determined by\n\U0001D43E (\U0001D458) = \U0001D443 (\U0001D458\
    \ | \U0001D458 − 1) \U0001D43B\U0001D447 (\U0001D458)\n× [\U0001D43B (\U0001D458\
    ) \U0001D443 (\U0001D458 | \U0001D458 − 1) \U0001D43B\U0001D447 (\U0001D458) +\
    \ \U0001D445 (\U0001D458)]\n−1,\n(26)\nwhere \U0001D443(\U0001D458 | \U0001D458\
    \ − 1) is the prediction covariance matrix and\ncan be determined by\n\U0001D443\
    \ (\U0001D458 + 1 | \U0001D458) = Φ (\U0001D458) \U0001D443 (\U0001D458) Φ\U0001D447\
    \ (\U0001D458) + \U0001D444 (\U0001D458)\n(27)\nwith\n\U0001D443 (\U0001D458)\
    \ = \U0001D443 (\U0001D458 | \U0001D458 − 1) − \U0001D43E (\U0001D458) \U0001D43B\
    \ (\U0001D458) \U0001D443 (\U0001D458 | \U0001D458 − 1) .\n(28)\nThe Kalman filter\
    \ is mainly employed to fuse low-level\ndata. If the system could be described\
    \ as a linear model and\nthe error could be modeled as the Gaussian noise, then\
    \ the\nrecursive Kalman filter obtains optimal statistical estimations\n[35].\
    \ However, other methods are required to address nonlin-\near dynamic models and\
    \ nonlinear measurements. The modi-\nfied Kalman filter known as the extended\
    \ Kalman filter (EKF)\nis an optimal approach for implementing nonlinear recursive\n\
    filters [36]. The EKF is one of the most often employed\nmethods for fusing data\
    \ in robotic applications. However,\nit has some disadvantages because the computations\
    \ of the\nJacobians are extremely expensive. Some attempts have been\nmade to\
    \ reduce the computational cost, such as linearization,\nbut these attempts introduce\
    \ errors in the filter and make it\nunstable.\nThe unscented Kalman filter (UKF)\
    \ [37] has gained\npopularity, because it does not have the linearization step\
    \ and\nthe associated errors of the EKF [38]. The UKF employs a\ndeterministic\
    \ sampling strategy to establish the minimum set\nof points around the mean. This\
    \ set of points captures the\ntrue mean and covariance completely. Then, these\
    \ points are\npropagated through nonlinear functions, and the covariance\nof the\
    \ estimations can be recuperated. Another advantage of\nthe UKF is its ability\
    \ to be employed in parallel implementa-\ntions.\n4.3. Particle Filter. Particle\
    \ filters are recursive implemen-\ntations of the sequential Monte Carlo methods\
    \ [39]. This\nmethod builds the posterior density function using several\nrandom\
    \ samples called particles. Particles are propagated\nover time with a combination\
    \ of sampling and resampling\nsteps. At each iteration, the sampling step is employed\
    \ to\ndiscard some particles, increasing the relevance of regions\nwith a higher\
    \ posterior probability. In the filtering process,\nseveral particles of the same\
    \ state variable are employed,\nand each particle has an associated weight that\
    \ indicates\nthe quality of the particle. Therefore, the estimation is the\nresult\
    \ of a weighted sum of all of the particles. The standard\nparticle filter algorithm\
    \ has two phases: (1) the predicting\nphase and (2) the updating phase. In the\
    \ predicting phase,\neach particle is modified according to the existing model\n\
    and accounts for the sum of the random noise to simulate\nthe noise effect. Then,\
    \ in the updating phase, the weight of\neach particle is reevaluated using the\
    \ last available sensor\nobservation, and particles with lower weights are removed.\n\
    Specifically, a generic particle filter comprises the following\nsteps.\nThe Scientific\
    \ World Journal\n13\n(1) Initialization of the particles:\n(i) let \U0001D441\
    \ be equal to the number of particles;\n(ii) \U0001D44B(\U0001D456)(1) = [\U0001D465\
    (1), \U0001D466(1), 0, 0]\U0001D447 for \U0001D456 = 1, . . . , \U0001D441.\n\
    (2) Prediction step:\n(i) for each particle \U0001D456 = 1, . . . , \U0001D441\
    , evaluate the state\n(\U0001D458 + 1 | \U0001D458) of the system using the state\
    \ at time\ninstant \U0001D458 with the noise of the system at time \U0001D458\
    .\nConsider\n̂\U0001D44B(\U0001D456) (\U0001D458 + 1 | \U0001D458) = \U0001D439\
    \ (\U0001D458) ̂\U0001D44B(\U0001D456) (\U0001D458)\n+ (cauchy-distribution-noise)(\U0001D458\
    ),\n(29)\nwhere \U0001D439(\U0001D458) is the transition matrix of the sys-\n\
    tem.\n(3) Evaluate the particle weight. For each particle \U0001D456 =\n1, . .\
    \ . , \U0001D441:\n(i) compute the predicted observation state of the\nsystem\
    \ using the current predicted state and the\nnoise at instant \U0001D458. Consider\n\
    ̂\U0001D467(\U0001D456) (\U0001D458 + 1 | \U0001D458) = \U0001D43B (\U0001D458\
    \ + 1) ̂\U0001D44B(\U0001D456) (\U0001D458 + 1 | \U0001D458)\n+ (gaussian-measurement-noise)(\U0001D458\
    +1);\n(30)\n(ii) compute the likelihood (weights) according to\nthe given distribution.\
    \ Consider\nlikelihood(\U0001D456) = \U0001D441 (̂\U0001D467(\U0001D456) (\U0001D458\
    \ + 1 | \U0001D458) ; \U0001D467(\U0001D456) (\U0001D458 + 1) , var) ;\n(31)\n\
    (iii) normalize the weights as follows\ñ\U0001D464(\U0001D456) =\nlikelihood(\U0001D456\
    )\n∑\U0001D441\n\U0001D457=1 likelihood(\U0001D457) .\n(32)\n(4) Resampling/Selection:\
    \ multiply particles with higher\nweights and remove those with lower weights.\
    \ The\ncurrent state must be adjusted using the computed\nweights of the new particles.\n\
    (i) Compute the cumulative weights. Consider\nCum Wt(\U0001D456) =\n\U0001D456\
    \n∑\n\U0001D457=1\ñ\U0001D464(\U0001D457).\n(33)\n(ii) Generate uniform distributed\
    \ random variables\nfrom \U0001D448(\U0001D456) ∼ \U0001D44A(0, 1) with the number\
    \ of steps\nequal to the number of particles.\n(iii) Determine which particles\
    \ should be multiplied\nand which ones removed.\n(5) Propagation phase:\n(i) incorporate\
    \ the new values of the state after the\nresampling of instant \U0001D458 to calculate\
    \ the value at\ninstant \U0001D458 + 1. Consider\n̂\U0001D465(1:\U0001D441) (\U0001D458\
    \ + 1 | \U0001D458 + 1) = ̂\U0001D465 (\U0001D458 + 1 | \U0001D458) ;\n(34)\n\
    (ii) compute the posterior mean. Consider\n̂\U0001D465 (\U0001D458 + 1) = mean\
    \ [\U0001D465\U0001D456 (\U0001D458 + 1 | \U0001D458 + 1)] ,\n\U0001D456 = 1,\
    \ . . . , \U0001D441; (35)\n(iii) repeat steps 2 to 5 for each time instant.\n\
    Particle filters are more flexible than the Kalman filters\nand can cope with\
    \ nonlinear dependencies and non-Gaussian\ndensities in the dynamic model and\
    \ in the noise error.\nHowever, they have some disadvantages. A large number\n\
    of particles are required to obtain a small variance in the\nestimator. It is\
    \ also difficult to establish the optimal number of\nparticles in advance, and\
    \ the number of particles affects the\ncomputational cost significantly. Earlier\
    \ versions of particle\nfilters employed a fixed number of particles, but recent\
    \ studies\nhave started to use a dynamic number of particles [40].\n4.4. The Distributed\
    \ Kalman Filter. The distributed Kalman\nfilter requires a correct clock synchronization\
    \ between each\nsource, as demonstrated in [41]. In other words, to correctly\n\
    use the distributed Kalman filter, the clocks from all of\nthe sources must be\
    \ synchronized. This synchronization is\ntypically achieved through using protocols\
    \ that employ a\nshared global clock, such as the network time protocol (NTP).\n\
    Synchronization problems between clocks have been shown\nto have an effect on\
    \ the accuracy of the Kalman filter,\nproducing inaccurate estimations [42].\n\
    If the estimations are consistent and the cross covariance\nis known (or the estimations\
    \ are uncorrelated), then it is\npossible to use the distributed Kalman filters\
    \ [43]. However,\nthe cross covariance must be determined exactly, or the\nobservations\
    \ must be consistent.\nWe refer the reader to Liggins II et al. [20] for more\
    \ details\nabout the Kalman filter in a distributed and hierarchical\narchitecture.\n\
    4.5. Distributed Particle Filter. Distributed particle filters\nhave gained attention\
    \ recently [44–46]. Coates [45] used a\ndistributed particle filter to monitor\
    \ an environment that\ncould be captured by the Markovian state-space model,\n\
    involving nonlinear dynamics and observations and non-\nGaussian noise.\nIn contrast,\
    \ earlier attempts to solve out-of-sequence\nmeasurements using particle filters\
    \ are based on regenerating\nthe probability density function to the time instant\
    \ of the\nout-of-sequence measurement [47]. In a particle filter, this\nstep requires\
    \ a large computational cost, in addition to the\nnecessary space to store the\
    \ previous particles. To avoid\nthis problem, Orton and Marrs [48] proposed to\
    \ store the\ninformation on the particles at each time instant, saving the\ncost\
    \ of recalculating this information. This technique is close\n14\nThe Scientific\
    \ World Journal\nto optimal, and when the delay increases, the result is only\n\
    slightly affected [49]. However, it requires a very large amount\nof space to\
    \ store the state of the particles at each time instant.\n4.6. Covariance Consistency\
    \ Methods: Covariance Intersec-\ntion/Union. Covariance consistency methods (intersection\n\
    and union) were proposed by Uhlmann [43] and are general\nand fault-tolerant frameworks\
    \ for maintaining covariance\nmeans and estimations in a distributed network.\
    \ These meth-\nods do not comprise estimation techniques; instead, they are\n\
    similar to an estimation fusion technique. The distributed\nKalman filter requirement\
    \ of independent measurements or\nknown cross-covariances is not a constraint\
    \ with this method.\n4.6.1. Covariance Intersection. If the Kalman filter is employ-\n\
    ed to combine two estimations, (\U0001D44E1, \U0001D4341) and (\U0001D44E2, \U0001D434\
    2), then it\nis assumed that the joint covariance is in the following form:\n\
    [\n[\n\U0001D4341\n\U0001D44B\n\U0001D44B\U0001D447 \U0001D4342\n]\n]\n,\n(36)\n\
    where the cross-covariance \U0001D44B should be known exactly so\nthat the Kalman\
    \ filter can be applied without difficulty.\nBecause the computation of the cross-covariances\
    \ is compu-\ntationally intensive, Uhlmann [43] proposed the covariance\nintersection\
    \ (CI) algorithm.\nLet us assume that a joint covariance \U0001D440 can be defined\n\
    with the diagonal blocks \U0001D440\U0001D4341 > \U0001D4341 and \U0001D440\U0001D434\
    2 > \U0001D4342. Consider\n\U0001D440 ⩾ [\n[\n\U0001D4341\n\U0001D44B\n\U0001D44B\
    \U0001D447 \U0001D4342\n]\n]\n(37)\nfor every possible instance of the unknown\
    \ cross-covariance\n\U0001D44B; then, the components of the matrix \U0001D440\
    \ could be employed\nin the Kalman filter equations to provide a fused estimation\n\
    (\U0001D450, \U0001D436) that is considered consistent. The key point of this\n\
    method relies on generating a joint covariance matrix \U0001D440 that\ncan represent\
    \ a useful fused estimation (in this context, useful\nrefers to something with\
    \ a lower associated uncertainty). In\nsummary, the CI algorithm computes the\
    \ joint covariance\nmatrix \U0001D440, where the Kalman filter provides the best\
    \ fused\nestimation (\U0001D450, \U0001D436) with respect to a fixed measurement\
    \ of the\ncovariance matrix (i.e., the minimum determinant).\nSpecific covariance\
    \ criteria must be established because\nthere is not a specific minimum joint\
    \ covariance in the\norder of the positive semidefinite matrices. Moreover, the\n\
    joint covariance is the basis of the formal analysis of the\nCI algorithm; the\
    \ actual result is a nonlinear mixture of the\ninformation stored on the estimations\
    \ being fused, following\nthe following equation.\n\U0001D436 = (\U0001D4641\U0001D43B\
    \U0001D447\n1 \U0001D434−1\n1 \U0001D43B1 + \U0001D4642\U0001D43B\U0001D447\n\
    2 \U0001D434−1\n2 \U0001D43B2 + ⋅ ⋅ ⋅ + \U0001D464\U0001D45B\U0001D43B\U0001D447\
    \n\U0001D45B \U0001D434−1\n\U0001D45B \U0001D43B\U0001D45B)\n−1,\n\U0001D450 =\
    \ \U0001D436(\U0001D4641\U0001D43B\U0001D447\n1 \U0001D434−1\n1 \U0001D44E1 +\
    \ \U0001D4642\U0001D43B\U0001D447\n2 \U0001D434−1\n2 \U0001D44E2 + ⋅ ⋅ ⋅ + \U0001D464\
    \U0001D45B\U0001D43B\U0001D447\n\U0001D45B \U0001D434−1\n\U0001D45B \U0001D44E\
    \U0001D45B)\n−1,\n(38)\nwhere \U0001D43B\U0001D456 is the transformation of the\
    \ fused state-space\nestimation to the space of the estimated state \U0001D456\
    . The values\nof \U0001D464 can be calculated to minimize the covariance determi-\n\
    nant using convex optimization packages and semipositive\nmatrix programming.\
    \ The result of the CI algorithm has\ndifferent characteristics compared to the\
    \ Kalman filter. For\nexample, if two estimations are provided (\U0001D44E, \U0001D434\
    ) and (\U0001D44F, \U0001D435)\nand their covariances are equal \U0001D434 = \U0001D435\
    , since the Kalman\nfilter is based on the statistical independence assumption,\
    \ it\nproduces a fused estimation with covariance \U0001D436 = (1/2)\U0001D434\
    .\nIn contrast, the CI method does not assume independence\nand, thus, must be\
    \ consistent even in the case in which\nthe estimations are completely correlated,\
    \ with the estimated\nfused covariance \U0001D436 = \U0001D434. In the case of\
    \ estimations where\n\U0001D434 < \U0001D435, the CI algorithm does not provide\
    \ information about\nthe estimation (\U0001D44F, \U0001D435); thus, the fused\
    \ result is (\U0001D44E, \U0001D434).\nEvery joint-consistent covariance is sufficient\
    \ to produce\na fused estimation, which guarantees consistency. However,\nit is\
    \ also necessary to guarantee a lack of divergence. Diver-\ngence is avoided in\
    \ the CI algorithm by choosing a specific\nmeasurement (i.e., the determinant),\
    \ which is minimized in\neach fusion operation. This measurement represents a\
    \ non-\ndivergence criterion, because the size of the estimated covari-\nance\
    \ according to this criterion would not be incremented.\nThe application of the\
    \ CI method guarantees consis-\ntency and nondivergence for every sequence of\
    \ mean and\ncovariance-consistent estimations. However, this method\ndoes not\
    \ work well when the measurements to be fused are\ninconsistent.\n4.6.2. Covariance\
    \ Union. CI solves the problem of correlated\ninputs but not the problem of inconsistent\
    \ inputs (inconsistent\ninputs refer to different estimations, each of which has\
    \ a\nhigh accuracy (small variance) but also a large difference\nfrom the states\
    \ of the others); thus, the covariance union\n(CU) algorithm was proposed to solve\
    \ the latter [43]. CU\naddresses the following problem: two estimations (\U0001D44E\
    1, \U0001D4341)\nand (\U0001D44E2, \U0001D4342) relate to the state of an object\
    \ and are mutually\ninconsistent from one another. This issue arises when the\n\
    difference between the average estimations is larger than\nthe provided covariance.\
    \ Inconsistent inputs can be detected\nusing the Mahalanobis distance [50] between\
    \ them, which is\ndefined as\n\U0001D440\U0001D451 = (\U0001D44E1 − \U0001D44E\
    2)\U0001D447(\U0001D4341 + \U0001D4342)−1 (\U0001D44E1 − \U0001D44E2) ,\n(39)\n\
    and detecting whether this distance is larger than a given\nthreshold.\nThe Mahalanobis\
    \ distance accounts for the covariance\ninformation to obtain the distance. If\
    \ the difference between\nthe estimations is high but their covariance is also\
    \ high,\nthe Mahalanobis distance yields a small value. In contrast,\nif the difference\
    \ between the estimations is small and the\ncovariances are small, it could produce\
    \ a larger distance\nvalue. A high Mahalanobis distance could indicate that the\n\
    estimations are inconsistent; however, it is necessary to\nhave a specific threshold\
    \ established by the user or learned\nautomatically.\nThe CU algorithm aims to\
    \ solve the following prob-\nlem: let us suppose that a filtering algorithm provides\
    \ two\nobservations with mean and covariance (\U0001D44E1, \U0001D4341) and (\U0001D44E\
    2, \U0001D4342),\nThe Scientific World Journal\n15\nrespectively. It is known\
    \ that one of the observations is correct\nand the other is erroneous. However,\
    \ the identity of the\ncorrect estimation is unknown and cannot be determined.\n\
    In this situation, if both estimations are employed as an\ninput to the Kalman\
    \ filter, there will be a problem, because\nthe Kalman filter only guarantees\
    \ a consistent output if the\nobservation is updated with a measurement consistent\
    \ with\nboth of them. In the specific case, in which the measurements\ncorrespond\
    \ to the same object but are acquired from two\ndifferent sensors, the Kalman\
    \ filter can only guarantee that\nthe output is consistent if it is consistent\
    \ with both separately.\nBecause it is not possible to know which estimation is\
    \ correct,\nthe only way to combine the two estimations rigorously is\nto provide\
    \ an estimation (\U0001D462, \U0001D448) that is consistent with both\nestimations\
    \ and to obey the following properties:\n\U0001D448 ⪖ \U0001D4341 + (\U0001D462\
    \ − \U0001D44E1) (\U0001D462 − \U0001D4341)\n\U0001D447,\n\U0001D448 ⪖ \U0001D434\
    2 + (\U0001D462 − \U0001D44E2) (\U0001D462 − \U0001D4342)\U0001D447,\n(40)\nwhere\
    \ some measurement of the matrix size \U0001D448 (i.e., the deter-\nminant) is\
    \ minimized.\nIn other words, the previous equations indicate that if the\nestimation\
    \ (\U0001D44E1, \U0001D4341) is consistent, then the translation of the\nvector\
    \ \U0001D44E1 to \U0001D462 requires to increase the covariance by the sum\nof\
    \ a matrix at least as big as the product of (\U0001D462 − \U0001D44E1) in order\
    \ to\nbe consistent. The same situation applies to the measurement\n(\U0001D44E\
    2, \U0001D4342) in order to be consistent.\nA simple strategy is to choose the\
    \ mean of the estimation\nas the input value of one of the measurements (\U0001D462\
    \ = \U0001D44E1). In this\ncase, the value of \U0001D448 must be chosen, such\
    \ that the estimation\nis consistent with the worst case (the correct measurement\
    \ is\n\U0001D44E2). However, it is possible to assign \U0001D462 an intermediate\
    \ value\nbetween \U0001D44E1 and \U0001D44E2 to decrease the value of \U0001D448\
    . Therefore, the\nCU algorithm establishes the mean fused value \U0001D462 that\
    \ has\nthe least covariance \U0001D448 but is sufficiently large for the two\n\
    measurements (\U0001D44E1 and \U0001D44E2) for consistency.\nBecause the matrix\
    \ inequalities presented in previous\nequations are convex, convex optimization\
    \ algorithms must\nbe employed to solve them. The value of \U0001D448 can be computed\n\
    with the iterative method described by Julier et al. [51].\nThe obtained covariance\
    \ could be significantly larger than\nany of the initial covariances and is an\
    \ indicator of the\nexisting uncertainty between the initial estimations. One\
    \ of\nthe advantages of the CU method arises from the fact that\nthe same process\
    \ could be easily extended to \U0001D441 inputs.\n5. Decision Fusion Methods\n\
    A decision is typically taken based on the knowledge of the\nperceived situation,\
    \ which is provided by many sources in\nthe data fusion domain. These techniques\
    \ aim to make a\nhigh-level inference about the events and activities that are\n\
    produced from the detected targets. These techniques often\nuse symbolic information,\
    \ and the fusion process requires to\nreason while accounting for the uncertainties\
    \ and constraints.\nThese methods fall under level 2 (situation assessment) and\n\
    level 4 (impact assessment) of the JDL data fusion model.\n5.1. The Bayesian Methods.\
    \ Information fusion based on the\nBayesian inference provides a formalism for\
    \ combining evi-\ndence according to the probability theory rules. Uncertainty\n\
    is represented using the conditional probability terms that\ndescribe beliefs\
    \ and take on values in the interval [0, 1], where\nzero indicates a complete\
    \ lack of belief and one indicates an\nabsolute belief. The Bayesian inference\
    \ is based on the Bayes\nrule as follows:\n\U0001D443 (\U0001D44C | \U0001D44B\
    ) = \U0001D443 (\U0001D44B | \U0001D44C) \U0001D443 (\U0001D44C)\n\U0001D443 (\U0001D44B\
    )\n,\n(41)\nwhere the posterior probability, \U0001D443(\U0001D44C | \U0001D44B\
    ), represents the\nbelief in the hypothesis \U0001D44C given the information \U0001D44B\
    . This\nprobability is obtained by multiplying the a priori probability\nof the\
    \ hypothesis \U0001D443(\U0001D44C) by the probability of having \U0001D44B given\n\
    that \U0001D44C is true, \U0001D443(\U0001D44B\n|\n\U0001D44C). The value \U0001D443\
    (\U0001D44B) is used as a\nnormalizing constant. The main disadvantage of the\
    \ Bayesian\ninference is that the probabilities \U0001D443(\U0001D44B) and \U0001D443\
    (\U0001D44B | \U0001D44C) must\nbe known. To estimate the conditional probabilities,\
    \ Pan\net al. [52] proposed the use of NNs, whereas Cou´e et al. [53]\nproposed\
    \ the Bayesian programming.\nHall and Llinas [54] described the following problems\n\
    associated with Bayesian inference.\n(i) Difficulty in establishing the value\
    \ of a priori proba-\nbilities.\n(ii) Complexity when there are multiple potential\
    \ hypo-\ntheses and a substantial number of events that depend\non the conditions.\n\
    (iii) The hypothesis should be mutually exclusive.\n(iv) Difficulty in describing\
    \ the uncertainty of the deci-\nsions.\n5.2. The Dempster-Shafer Inference. The\
    \ Dempster-Shafer\ninference is based on the mathematical theory introduced\n\
    by Dempster [55] and Shafer [56], which generalizes the\nBayesian theory. The\
    \ Dempster-Shafer theory provides a\nformalism that could be used to represent\
    \ incomplete knowl-\nedge, updating beliefs, and a combination of evidence and\n\
    allows us to represent the uncertainty explicitly [57].\nA fundamental concept\
    \ in the Dempster-Shafer reason-\ning is the frame of discernment, which is defined\
    \ as follows.\nLet Θ\n=\n{\U0001D7031, \U0001D7032, . . . , \U0001D703\U0001D441\
    } be the set of all possible states\nthat define the system, and let Θ be exhaustive\
    \ and mutually\nexclusive due to the system being only in one state \U0001D703\
    \U0001D456 ∈ Θ,\nwhere 1 ⪕ \U0001D456 ⪕ \U0001D441. The set Θ is called a frame\
    \ of discernment,\nbecause its elements are employed to discern the current state\n\
    of the system.\nThe elements of the set 2Θ are called hypotheses. In\nthe Dempster-Shafer\
    \ theory, based on the evidence \U0001D438, a\nprobability is assigned to each\
    \ hypothesis \U0001D43B ∈ 2Θ according\nto the basic assignment of probabilities\
    \ or the mass function\n\U0001D45A : 2Θ → [0.1], which satisfies\n\U0001D45A (0)\
    \ = 0.\n(42)\n16\nThe Scientific World Journal\nThus, the mass function of the\
    \ empty set is zero. Furthermore,\nthe mass function of a hypothesis is larger\
    \ than or equal to\nzero for all of the hypotheses. Consider\n\U0001D45A (\U0001D43B\
    ) ≥ 0,\n∀\U0001D43B ∈ 2Θ.\n(43)\nThe sum of the mass function of all the hypotheses\
    \ is one.\nConsider\n∑\n\U0001D43B∈2Θ\n\U0001D45A (\U0001D43B) = 1.\n(44)\nTo\
    \ express incomplete beliefs in a hypothesis \U0001D43B, the Demp-\nster-Shafer\
    \ theory defines the belief function bel : 2Θ\n→\n[0, 1] over Θ as\nbel (\U0001D43B\
    ) = ∑\n\U0001D434⊆\U0001D43B\n\U0001D45A (\U0001D434) ,\n(45)\nwhere bel(0) =\
    \ 0, and bel(Θ) = 1. The doubt level in \U0001D43B can be\nexpressed in terms\
    \ of the belief function by\ndou (\U0001D43B) = bel (¬\U0001D43B) = ∑\n\U0001D434\
    ⊆¬\U0001D43B\n\U0001D45A (\U0001D434) .\n(46)\nTo express the plausibility of\
    \ each hypothesis, the function\npl : 2Θ → [0, 1] over Θ is defined as\npl (\U0001D43B\
    ) = 1 − dou (\U0001D43B) =\n∑\n\U0001D434∩\U0001D43B=0\n\U0001D45A (\U0001D434\
    ) .\n(47)\nIntuitive plausibility indicates that there is less uncer-\ntainty\
    \ in hypothesis \U0001D43B if it is more plausible. The confidence\ninterval [bel(\U0001D43B\
    ), pl(\U0001D43B)] defines the true belief in hypothesis\n\U0001D43B. To combine\
    \ the effects of the two mass functions \U0001D45A1 and\n\U0001D45A2, the Dempster-Shafer\
    \ theory defines a rule \U0001D45A1 ⊕ \U0001D45A2 as\n\U0001D45A1 ⊕ \U0001D45A\
    2 (0) = 0,\n\U0001D45A1 ⊕ \U0001D45A2 (\U0001D43B) =\n∑\U0001D44B∩\U0001D44C=\U0001D43B\
    \ \U0001D45A1 (\U0001D44B) \U0001D45A2 (\U0001D44C)\n1 − ∑\U0001D44B∩\U0001D44C\
    =0 \U0001D45A1 (\U0001D44B) \U0001D45A2 (\U0001D44C).\n(48)\nIn contrast to the\
    \ Bayesian inference, a priori probabilities\nare not required in the Dempster-Shafer\
    \ inference, because\nthey are assigned at the instant that the information is\
    \ pro-\nvided. Several studies in the literature have compared the use\nof the\
    \ Bayesian inference and the Dempster-Shafer inference,\nsuch as [58–60]. Wu et\
    \ al. [61] used the Dempster-Shafer\ntheory to fuse information in context-aware\
    \ environments.\nThis work was extended in [62] to dynamically modify the\nassociated\
    \ weights to the sensor measurements. Therefore,\nthe fusion mechanism is calibrated\
    \ according to the recent\nmeasurements of the sensors (in cases in which the\
    \ ground-\ntruth is available). In the military domain [63], the Dempster-\nShafer\
    \ reasoning is used with the a priori information stored\nin a database for classifying\
    \ military ships. Morbee et al. [64]\ndescribed the use of the Dempster-Shafer\
    \ theory to build 2D\noccupancy maps from several cameras and to evaluate the\n\
    contribution of subsets of cameras to a specific task. Each task\nis the observation\
    \ of an event of interest, and the goal is to\nassess the validity of a set of\
    \ hypotheses that are fused using\nthe Dempster-Shafer theory.\n5.3. Abductive\
    \ Reasoning. Abductive reasoning, or inferring\nthe best explanation, is a reasoning\
    \ method in which a\nhypothesis is chosen under the assumption that in case it\n\
    is true, it explains the observed event most accurately [65].\nIn other words,\
    \ when an event is observed, the abduction\nmethod attempts to find the best explanation.\n\
    In the context of probabilistic reasoning, abductive infer-\nence finds the posterior\
    \ ML of the system variables given\nsome observed variables. Abductive reasoning\
    \ is more a\nreasoning pattern than a data fusion technique. Therefore,\ndifferent\
    \ inference methods, such as NNs [66] or fuzzy logic\n[67], can be employed.\n\
    5.4. Semantic Methods. Decision fusion techniques that\nemploy semantic data from\
    \ different sources as an input could\nprovide more accurate results than those\
    \ that rely on only\nsingle sources. There is a growing interest in techniques\
    \ that\nautomatically determine the presence of semantic features in\nvideos to\
    \ solve the semantic gap [68].\nSemantic information fusion is essentially a scheme\
    \ in\nwhich raw sensor data are processed such that the nodes\nexchange only the\
    \ resultant semantic information. Semantic\ninformation fusion typically covers\
    \ two phases: (i) build-\ning the knowledge and (ii) pattern matching (inference).\n\
    The first phase (typically offline) incorporates the most\nappropriate knowledge\
    \ into semantic information. Then, the\nsecond phase (typically online or in real-time)\
    \ fuses relevant\nattributes and provides a semantic interpretation of the\nsensor\
    \ data [69–71].\nSemantic fusion could be viewed as an idea for integrating\n\
    and translating sensor data into formal languages. Therefore,\nthe obtained resulting\
    \ language from the observations of\nthe environment is compared with similar\
    \ languages that\nare stored in the database. The key of this strategy is that\n\
    similar behaviors represented by formal languages are also\nsemantically similar.\
    \ This type of method provides savings\nin the cost of transmission, because the\
    \ nodes need only\ntransmit the formal language structure instead of the raw\n\
    data. However, a known set of behaviors must be stored\nin a database in advance,\
    \ which might be difficult in some\nscenarios.\n6. Conclusions\nThis paper reviews\
    \ the most popular methods and tech-\nniques for performing data/information fusion.\
    \ To determine\nwhether the application of data/information fusion methods\nis\
    \ feasible, we must evaluate the computational cost of the\nprocess and the delay\
    \ introduced in the communication.\nA centralized data fusion approach is theoretically\
    \ optimal\nwhen there is no cost of transmission and there are sufficient\ncomputational\
    \ resources. However, this situation typically\ndoes not hold in practical applications.\n\
    The selection of the most appropriate technique depends\non the type of the problem\
    \ and the established assumptions\nof each technique. Statistical data fusion\
    \ methods (e.g., PDA,\nJPDA, MHT, and Kalman) are optimal under specific condi-\n\
    tions [72]. First, the assumption that the targets are moving\nThe Scientific\
    \ World Journal\n17\nindependently and the measurements are normally dis-\ntributed\
    \ around the predicted position typically does not\nhold. Second, because the\
    \ statistical techniques model all\nof the events as probabilities, they typically\
    \ have several\nparameters and a priori probabilities for false measurements\n\
    and detection errors that are often difficult to obtain (at\nleast in an optimal\
    \ sense). For example, in the case of the\nMHT algorithm, specific parameters\
    \ must be established that\nare nontrivial to determine and are very sensitive\
    \ [73]. In\ncontrast, statistical methods that optimize over several frames\n\
    are computationally intensive, and their complexity typically\ngrows exponentially\
    \ with the number of targets. For example,\nin the case of particle filters, tracking\
    \ several targets can be\naccomplished jointly as a group or individually. If\
    \ several\ntargets are tracked jointly, the necessary number of particles\ngrows\
    \ exponentially. Therefore, in practice, it is better to\nperform tracking on\
    \ them individually, with the assumption\nthat targets do not interact between\
    \ the particles.\nIn contrast to centralized systems, the distributed data\nfusion\
    \ methods introduce some challenges in the data fusion\nprocess, such as (i) spatial\
    \ and temporal alignments of the\ninformation, (ii) out-of-sequence measurements,\
    \ and (iii)\ndata correlation reported by Castanedo et al. [74, 75]. The\ninherent\
    \ redundancy of the distributed systems could be\nexploited with distributed reasoning\
    \ techniques and cooper-\native algorithms to improve the individual node estimations\n\
    reported by Castanedo et al. [76]. In addition to the previous\nstudies, a new\
    \ trend based on the geometric notion of a low-\ndimensional manifold is gaining\
    \ attention in the data fusion\ncommunity. An example is the work of Davenport\
    \ et al. [77],\nwhich proposes a simple model that captures the correlation\n\
    between the sensor observations by matching the parameter\nvalues for the different\
    \ obtained manifolds.\nAcknowledgments\nThe author would like to thank Jes´us\
    \ Garc´ıa, Miguel A.\nPatricio, and James Llinas for their interesting and related\n\
    discussions on several topics that were presented in this\npaper.\nReferences\n\
    [1] JDL, Data Fusion Lexicon. Technical Panel For C3, F.E. White,\nSan Diego,\
    \ Calif, USA, Code 420, 1991.\n[2] D. L. Hall and J. Llinas, “An introduction\
    \ to multisensor data\nfusion,” Proceedings of the IEEE, vol. 85, no. 1, pp. 6–23,\
    \ 1997.\n[3] H. F. Durrant-Whyte, “Sensor models and multisensor integra-\ntion,”\
    \ International Journal of Robotics Research, vol. 7, no. 6, pp.\n97–113, 1988.\n\
    [4] B. V. Dasarathy, “Sensor fusion potential exploitation-inno-\nvative architectures\
    \ and illustrative applications,” Proceedings of\nthe IEEE, vol. 85, no. 1, pp.\
    \ 24–38, 1997.\n[5] R. C. Luo, C.-C. Yih, and K. L. Su, “Multisensor fusion and\n\
    integration: approaches, applications, and future research direc-\ntions,” IEEE\
    \ Sensors Journal, vol. 2, no. 2, pp. 107–119, 2002.\n[6] J. Llinas, C. Bowman,\
    \ G. Rogova, A. Steinberg, E. Waltz, and\nF. White, “Revisiting the JDL data fusion\
    \ model II,” Technical\nReport, DTIC Document, 2004.\n[7] E. P. Blasch and S.\
    \ Plano, “JDL level 5 fusion model “user refine-\nment” issues and applications\
    \ in group tracking,” in Proceedings\nof the Signal Processing, Sensor Fusion,\
    \ and Target Recognition\nXI, pp. 270–279, April 2002.\n[8] H. F. Durrant-Whyte\
    \ and M. Stevens, “Data fusion in decen-\ntralized sensing networks,” in Proceedings\
    \ of the 4th Interna-\ntional Conference on Information Fusion, pp. 302–307, Montreal,\n\
    Canada, 2001.\n[9] J. Manyika and H. Durrant-Whyte, Data Fusion and Sensor\nManagement:\
    \ A Decentralized Information-Theoretic Approach,\nPrentice Hall, Upper Saddle\
    \ River, NJ, USA, 1995.\n[10] S. S. Blackman, “Association and fusion of multiple\
    \ sensor data,”\nin Multitarget-Multisensor: Tracking Advanced Applications, pp.\n\
    187–217, Artech House, 1990.\n[11] S. Lloyd, “Least squares quantization in pcm,”\
    \ IEEE Transactions\non Information Theory, vol. 28, no. 2, pp. 129–137, 1982.\n\
    [12] M. Shindler, A. Wong, and A. Meyerson, “Fast and accurate\n\U0001D705-means\
    \ for large datasets,” in Proceedings of the 25th Annual\nConference on Neural\
    \ Information Processing Systems (NIPS ’11),\npp. 2375–2383, December 2011.\n\
    [13] Y. Bar-Shalom and E. Tse, “Tracking in a cluttered environment\nwith probabilistic\
    \ data association,” Automatica, vol. 11, no. 5,\npp. 451–460, 1975.\n[14] T.\
    \ E. Fortmann, Y. Bar-Shalom, and M. Scheffe, “Multi-target\ntracking using joint\
    \ probabilistic data association,” in Pro-\nceedings of the 19th IEEE Conference\
    \ on Decision and Control\nincluding the Symposium on Adaptive Processes, vol.\
    \ 19, pp. 807–\n812, December 1980.\n[15] D. B. Reid, “An algorithm for tracking\
    \ multiple targets,” IEEE\nTransactions on Automatic Control, vol. 24, no. 6,\
    \ pp. 843–854,\n1979.\n[16] C. L. Morefield, “Application of 0-1 integer programming\
    \ to\nmultitarget tracking problems,” IEEE Transactions on Automatic\nControl,\
    \ vol. 22, no. 3, pp. 302–312, 1977.\n[17] R. L. Streit and T. E. Luginbuhl, “Maximum\
    \ likelihood method\nfor probabilistic multihypothesis tracking,” in Proceedings\
    \ of the\nSignal and Data Processing of Small Targets, vol. 2235 of Pro-\nceedings\
    \ of SPIE, p. 394, 1994.\n[18] I. J. Cox and S. L. Hingorani, “Efficient implementation\
    \ of Reid’s\nmultiple hypothesis tracking algorithm and its evaluation for\nthe\
    \ purpose of visual tracking,” IEEE Transactions on Pattern\nAnalysis and Machine\
    \ Intelligence, vol. 18, no. 2, pp. 138–150,\n1996.\n[19] K. G. Murty, “An algorithm\
    \ for ranking all the assignments in\norder of increasing cost,” Operations Research,\
    \ vol. 16, no. 3, pp.\n682–687, 1968.\n[20] M. E. Liggins II, C.-Y. Chong, I.\
    \ Kadar et al., “Distributed fusion\narchitectures and algorithms for target tracking,”\
    \ Proceedings of\nthe IEEE, vol. 85, no. 1, pp. 95–106, 1997.\n[21] S. Coraluppi,\
    \ C. Carthel, M. Luettgen, and S. Lynch, “All-\nsource track and identity fusion,”\
    \ in Proceedings of the National\nSymposium on Sensor and Data Fusion, 2000.\n\
    [22] P. Storms and F. Spieksma, “An lp-based algorithm for the data\nassociation\
    \ problem in multitarget tracking,” in Proceedings of\nthe 3rd IEEE International\
    \ Conference on Information Fusion,\nvol. 1, 2000.\n[23] S.-W. Joo and R. Chellappa,\
    \ “A multiple-hypothesis approach\nfor multiobject visual tracking,” IEEE Transactions\
    \ on Image\nProcessing, vol. 16, no. 11, pp. 2849–2854, 2007.\n[24] S. Coraluppi\
    \ and C. Carthel, “Aggregate surveillance: a cardinal-\nity tracking approach,”\
    \ in Proceedings of the 14th International\nConference on Information Fusion (FUSION\
    \ ’11), July 2011.\n18\nThe Scientific World Journal\n[25] K. C. Chang, C. Y.\
    \ Chong, and Y. Bar-Shalom, “Joint proba-\nbilistic data association in distributed\
    \ sensor networks,” IEEE\nTransactions on Automatic Control, vol. 31, no. 10,\
    \ pp. 889–897,\n1986.\n[26] Y. Chong, S. Mori, and K. C. Chang, “Information lusion\
    \ in\ndistributed sensor networks,” in Proceedings of the 4th American\nControl\
    \ Conference, Boston, Mass, USA, June 1985.\n[27] Y. Chong, S. Mori, and K. C.\
    \ Chang, “Distributed multitar-\nget multisensor tracking,” in Multitarget-Multisensor\
    \ Tracking:\nAdvanced Applications, vol. 1, pp. 247–295, 1990.\n[28] J. Pearl,\
    \ Probabilistic Reasoning in Intelligent Systems: Networks\nof Plausible Inference,\
    \ Morgan Kaufmann, San Mateo, Calif,\nUSA, 1988.\n[29] Koller and N. Friedman,\
    \ Probabilistic Graphical Models: Princi-\nples and Techniques, MIT press, 2009.\n\
    [30] L. Chen, M. C¸etin, and A. S. Willsky, “Distributed data associ-\nation for\
    \ multi-target tracking in sensor networks,” in Proceed-\nings of the 7th International\
    \ Conference on Information Fusion\n(FUSION ’05), pp. 9–16, July 2005.\n[31] L.\
    \ Chen, M. J. Wainwright, M. Cetin, and A. S. Willsky, “Data\nassociation based\
    \ on optimization in graphical models with\napplication to sensor networks,” Mathematical\
    \ and Computer\nModelling, vol. 43, no. 9-10, pp. 1114–1113, 2006.\n[32] Y. Weiss\
    \ and W. T. Freeman, “On the optimality of solutions\nof the max-product belief-propagation\
    \ algorithm in arbitrary\ngraphs,” IEEE Transactions on Information Theory, vol.\
    \ 47, no. 2,\npp. 736–744, 2001.\n[33] C. Brown, H. Durrant-Whyte, J. Leonard,\
    \ B. Rao, and B. Steer,\n“Distributed data fusion using Kalman filtering: a robotics\n\
    application,” in Data, Fusion in Robotics and Machine Intelli-\ngence, M. A. Abidi\
    \ and R. C. Gonzalez, Eds., pp. 267–309, 1992.\n[34] R. E. Kalman, “A new approach\
    \ to linear filtering and prediction\nproblems,” Journal of Basic Engineering,\
    \ vol. 82, no. 1, pp. 35–45,\n1960.\n[35] R. C. Luo and M. G. Kay, “Data fusion\
    \ and sensor integration:\nstate-of-the-art 1990s,” in Data Fusion in Robotics\
    \ and Machine\nIntelligence, pp. 7–135, 1992.\n[36] Welch and G. Bishop, An Introduction\
    \ to the Kalman Filter,\nACM SIC-CRAPH, 2001 Course Notes, 2001.\n[37] S. J. Julier\
    \ and J. K. Uhlmann, “A new extension of the Kalman\nfilter to nonlinear systems,”\
    \ in Proceedings of the International\nSymposium on Aerospace/Defense Sensing,\
    \ Simulation and Con-\ntrols, vol. 3, 1997.\n[38] A. Wan and R. Van Der Merwe,\
    \ “The unscented kalman filter\nfor nonlinear estimation,” in Proceedings of the\
    \ Adaptive Systems\nfor Signal Processing, Communications, and Control Symposium\n\
    (AS-SPCC ’00), pp. 153–158, 2000.\n[39] D. Crisan and A. Doucet, “A survey of\
    \ convergence results on\nparticle filtering methods for practitioners,” IEEE\
    \ Transactions\non Signal Processing, vol. 50, no. 3, pp. 736–746, 2002.\n[40]\
    \ J. Martinez-del Rincon, C. Orrite-Urunuela, and J. E. Herrero-\nJaraba, “An\
    \ efficient particle filter for color-based tracking in\ncomplex scenes,” in Proceedings\
    \ of the IEEE Conference on\nAdvanced Video and Signal Based Surveillance, pp.\
    \ 176–181, 2007.\n[41] S. Ganeriwal, R. Kumar, and M. B. Srivastava, “Timing-sync\n\
    protocol for sensor networks,” in Proceedings of the 1st Inter-\nnational Conference\
    \ on Embedded Networked Sensor Systems\n(SenSys ’03), pp. 138–149, November 2003.\n\
    [42] M. Manzo, T. Roosta, and S. Sastry, “Time synchronization in\nnetworks,”\
    \ in Proceedings of the 3rd ACM Workshop on Security\nof Ad Hoc and Sensor Networks\
    \ (SASN ’05), pp. 107–116,\nNovember 2005.\n[43] J. K. Uhlmann, “Covariance consistency\
    \ methods for fault-\ntolerant distributed data fusion,” Information Fusion, vol.\
    \ 4, no.\n3, pp. 201–215, 2003.\n[44] S. Bashi, V. P. Jilkov, X. R. Li, and H.\
    \ Chen, “Distributed imple-\nmentations of particle filters,” in Proceedings of\
    \ the 6th Interna-\ntional Conference of Information Fusion, pp. 1164–1171, 2003.\n\
    [45] M. Coates, “Distributed particle filters for sensor networks,” in\nProceedings\
    \ of the 3rd International symposium on Information\nProcessing in Sensor Networks\
    \ (ACM ’04), pp. 99–107, New York,\nNY, USA, 2004.\n[46] D. Gu, “Distributed particle\
    \ filter for target tracking,” in Pro-\nceedings of the IEEE International Conference\
    \ on Robotics and\nAutomation (ICRA ’07), pp. 3856–3861, April 2007.\n[47] Y.\
    \ Bar-Shalom, “Update with out-of-sequence measurements in\ntracking: exact solution,”\
    \ IEEE Transactions on Aerospace and\nElectronic Systems, vol. 38, no. 3, pp.\
    \ 769–778, 2002.\n[48] M. Orton and A. Marrs, “A Bayesian approach to multi-target\n\
    tracking and data fusion with Out-of-Sequence Measurements,”\nIEE Colloquium,\
    \ no. 174, pp. 15/1–15/5, 2001.\n[49] M. L. Hernandez, A. D. Marrs, S. Maskell,\
    \ and M. R. Orton,\n“Tracking and fusion for wireless sensor networks,” in Proceed-\n\
    ings of the 5th International Conference on Information Fusion,\n2002.\n[50] P.\
    \ C. Mahalanobis, “On the generalized distance in statistics,”\nProceedings National\
    \ Institute of ScienceIndia, vol. 2, no. 1, pp.\n49–55, 1936.\n[51] S. J. Julier,\
    \ J. K. Uhlmann, and D. Nicholson, “A method\nfor dealing with assignment ambiguity,”\
    \ in Proceedings of the\nAmerican Control Conference (AAC ’04), vol. 5, pp. 4102–4107,\n\
    July 2004.\n[52] H. Pan, Z.-P. Liang, T. J. Anastasio, and T. S. Huang, “Hybrid\n\
    NN-Bayesian architecture for information fusion,” in Proceed-\nings of the International\
    \ Conference on Image Processing (ICIP\n’98), pp. 368–371, October 1998.\n[53]\
    \ C. Cou´e, T. Fraichard, P. Bessi`ere, and E. Mazer, “Multi-sensor\ndata fusion\
    \ using Bayesian programming: an automotive appli-\ncation,” in Proceedings of\
    \ the IEEE/RSJ International Conference\non Intelligent Robots and Systems, pp.\
    \ 141–146, October 2002.\n[54] D. L. Hall and J. Llinas, Handbook of Multisensor\
    \ Data Fusion,\nCRC Press, Boca Raton, Fla, USA, 2001.\n[55] P. Dempster, “A Generalization\
    \ of Bayesian Inference,” Journal\nof the Royal Statistical Society B, vol. 30,\
    \ no. 2, pp. 205–247, 1968.\n[56] A. Shafer, Mathematical Theory of Evidence ,\
    \ Princeton Univer-\nsity Press, Princeton, NJ, USA, 1976.\n[57] G. M. Provan,\
    \ “The validity of Dempster-Shafer belief func-\ntions,” International Journal\
    \ of Approximate Reasoning, vol. 6,\nno. 3, pp. 389–399, 1992.\n[58] D. M. Buede,\
    \ “Shafer-Dempster and Bayesian reasoning: a\nresponse to ‘Shafer-Dempster reasoning\
    \ with applications to\nmultisensor target identification systems’,” IEEE Transactions\
    \ on\nSystems, Man and Cybernetics, vol. 18, no. 6, pp. 1009–1011, 1988.\n[59]\
    \ Y. Cheng and R. L. Kashyap, “Comparisonol Bayesian and\nDempster’s rules in\
    \ evidence combination,” in Maximum-\nEntropy and Bayesian Methods in Science\
    \ and Engineering, 1988.\n[60] B. R. Cobb and P. P. Shenoy, “A comparison of Bayesian\
    \ and\nbelief function reasoning,” Information Systems Frontiers, vol. 5,\nno.\
    \ 4, pp. 345–358, 2003.\n[61] H. Wu, M. Siegel, R. Stiefelhagen, and J. Yang,\
    \ “Sensor fusion\nusing Dempster-Shafer theory,” in Proceedings of the 19th\n\
    IEEE Instrumentation and Measurement Technology Conference\n(TMTC ’02), pp. 7–11,\
    \ May 2002.\nThe Scientific World Journal\n19\n[62] H. Wu, M. Siegel, and S. Ablay,\
    \ “Sensor fusion using dempster-\nshafer theory II: static weighting and Kalman\
    \ filter-like dynamic\nweighting,” in Proceedings of the 20th IEEE Information\
    \ and\nMeasurement Technology Conference (TMTC ’03), pp. 907–912,\nMay 2003.\n\
    [63] ´E. Boss´e, P. Valin, A.-C. Boury-Brisset, and D. Grenier, “Ex-\nploitation\
    \ of a priori knowledge for information fusion,” Infor-\nmation Fusion, vol. 7,\
    \ no. 2, pp. 161–175, 2006.\n[64] M. Morbee, L. Tessens, H. Aghajan, and W. Philips,\
    \ “Dempster-\nShafer based multi-view occupancy maps,” Electronics Letters,\n\
    vol. 46, no. 5, pp. 341–343, 2010.\n[65] C. S. Peirce, Abduction and Induction.\
    \ Philosophical Writings of\nPeirce, vol. 156, Dover, New York, NY, USA, 1955.\n\
    [66] A. M. Abdelbar, E. A. M. Andrews, and D. C. Wunsch II,\n“Abductive reasoning\
    \ with recurrent neural networks,” Neural\nNetworks, vol. 16, no. 5-6, pp. 665–673,\
    \ 2003.\n[67] J. R. Ag¨uero and A. Vargas, “Inference of operative configu-\n\
    ration of distribution networks using fuzzy logic techniques.\nPart II: extended\
    \ real-time model,” IEEE Transactions on Power\nSystems, vol. 20, no. 3, pp. 1562–1569,\
    \ 2005.\n[68] A. W. M. Smeulders, M. Worring, S. Santini, A. Gupta, and R.\nJain,\
    \ “Content-based image retrieval at the end of the early\nyears,” IEEE Transactions\
    \ on Pattern Analysis and Machine\nIntelligence, vol. 22, no. 12, pp. 1349–1380,\
    \ 2000.\n[69] D. S. Friedlander and S. Phoha, “Semantic information fusion\nfor\
    \ coordinated signal processing in mobile sensor networks,”\nInternational Journal\
    \ of High Performance Computing Applica-\ntions, vol. 16, no. 3, pp. 235–241,\
    \ 2002.\n[70] S. Friedlander, “Semantic information extraction,” in Dis-\ntributed\
    \ Sensor Networks, 2005.\n[71] K. Whitehouse, J. Liu, and F. Zhao, “Semantic Streams:\
    \ a frame-\nwork for composable inference over sensor data,” in Proceedings\n\
    of the 3rd European Workshop on Wireless Sensor Networks,\nLecture Notes in Computer\
    \ Science, Springer, February 2006.\n[72] J. Cox, “A review of statistical data\
    \ association techniques for\nmotion correspondence,” International Journal of\
    \ Computer\nVision, vol. 10, no. 1, pp. 53–66, 1993.\n[73] C. J. Veenman, M. J.\
    \ T. Reinders, and E. Backer, “Resolving\nmotion correspondence for densely moving\
    \ points,” IEEE\nTransactions on Pattern Analysis and Machine Intelligence, vol.\n\
    23, no. 1, pp. 54–72, 2001.\n[74] F. Castanedo, M. A. Patricio, J. Garc´ıa, and\
    \ J. M. Molina,\n“Bottom-up/top-down coordination in a multiagent visual\nsensor\
    \ network,” in Proceedings of the IEEE Conference on\nAdvanced Video and Signal\
    \ Based Surveillance (AVSS ’07), pp.\n93–98, September 2007.\n[75] F. Castanedo,\
    \ J. Garc´ıa, M. A. Patricio, and J. M. Molina,\n“Analysis of distributed fusion\
    \ alternatives in coordinated vision\nagents,” in Proceedings of the 11th International\
    \ Conference on\nInformation Fusion (FUSION ’08), July 2008.\n[76] F. Castanedo,\
    \ J. Garc´ıa, M. A. Patricio, and J. M. Molina, “Data\nfusion to improve trajectory\
    \ tracking in a cooperative surveil-\nlance multi-agent architecture,” Information\
    \ Fusion, vol. 11, no.\n3, pp. 243–255, 2010.\n[77] M. A. Davenport, C. Hegde,\
    \ M. F. Duarte, and R. G. Baraniuk,\n“Joint manifolds for data fusion,” IEEE Transactions\
    \ on Image\nProcessing, vol. 19, no. 10, pp. 2580–2594, 2010.\nSubmit your manuscripts\
    \ at\nhttp://www.hindawi.com\nComputer Games \n Technology\nInternational Journal\
    \ of\nHindawi Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\nHindawi\
    \ Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\nDistributed \n\
    \ Sensor Networks\nInternational Journal of\nAdvances in\nFuzzy\nSystems\nHindawi\
    \ Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\nInternational Journal\
    \ of\nReconfigurable\nComputing\nHindawi Publishing Corporation \nhttp://www.hindawi.com\n\
    Volume 2014\nHindawi Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\n\
    \ Applied \nComputational \nIntelligence and Soft \nComputing\n Advances in \n\
    Artificial \nIntelligence\nHindawi Publishing Corporation\nhttp://www.hindawi.com\n\
    Volume 2014\nAdvances in\nSoftware Engineering\nHindawi Publishing Corporation\n\
    http://www.hindawi.com\nVolume 2014\nHindawi Publishing Corporation\nhttp://www.hindawi.com\n\
    Volume 2014\nElectrical and Computer \nEngineering\nJournal of\nJournal of\nComputer\
    \ Networks \nand Communications\nHindawi Publishing Corporation\nhttp://www.hindawi.com\n\
    Volume 2014\nHindawi Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\n\
    \ Advances in \nMultimedia\n International Journal of \nBiomedical Imaging\nHindawi\
    \ Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\nArtificial\nNeural\
    \ Systems\nAdvances in\nHindawi Publishing Corporation\nhttp://www.hindawi.com\n\
    Volume 2014\nRobotics\nJournal of\nHindawi Publishing Corporation\nhttp://www.hindawi.com\n\
    Volume 2014\nHindawi Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\n\
    Computational \nIntelligence and \nNeuroscience\nIndustrial Engineering\nJournal\
    \ of\nHindawi Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\nModelling\
    \ & \nSimulation \nin Engineering\nHindawi Publishing Corporation \nhttp://www.hindawi.com\n\
    Volume 2014\nThe Scientific \nWorld Journal\nHindawi Publishing Corporation \n\
    http://www.hindawi.com\nVolume 2014\nHindawi Publishing Corporation\nhttp://www.hindawi.com\n\
    Volume 2014\nHuman-Computer\nInteraction\nAdvances in\nComputer Engineering\n\
    Advances in\nHindawi Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\n"
  inline_citation: '>'
  journal: The Scientific World Journal
  limitations: '>'
  pdf_link: https://downloads.hindawi.com/journals/tswj/2013/704504.pdf
  publication_year: 2013
  relevance_score1: 0
  relevance_score2: 0
  title: A Review of Data Fusion Techniques
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3233/ifs-141120
  analysis: '>'
  authors:
  - Yong Lin
  - Jiang Xu
  - Fillia Makedon
  citation_count: 2
  full_citation: '>'
  full_text: '>

    Help About us Contact us Home Journals Cart Log in / Register Search Search Published
    between: Published from year: and Published to year: Search syntax help   Cite
    Evidence equilibrium: Nash equilibrium in judgment processes Article type: Research
    Article Authors: Lin, Yong | Xu, Jiaqing | Makedon, Fillia Affiliations: College
    of Science, Ningbo University of Technology, Ningbo, Zhejiang, China | Computer
    Science & Engineering, University of Texas at Arlington, Arlington, TX, USA Note:
    [] Corresponding author. Yong Lin, College of Science, Ningbo University of Technology,
    Ningbo, Zhejiang 315211, China. E-mails: ylin@nbut.edu.cn (Yong Lin); xjq@nbut.edu.cn
    (Jiaqing Xu); makedon@uta.edu (Fillia Makedon). Abstract: The purpose of evidence
    inference is to judge truth values of the environment states under uncertain observations.
    This has been modeled as mathematical problems, using Bayesian inference, Dempster-Shafer
    theory, etc. After formalizing judgment processes in evidence inference, we found
    that the judgment process under uncertainty can be modeled as a Bayesian game
    of subjective belief and objective evidence. Another, the rational judgment involves
    a perfect Nash equilibrium. Evidence equilibrium is the Nash equilibrium in judgment
    processes. It helps us to maximize the possibility to avoid bias, and minimize
    the requirement for evidence. This will be helpful for the dynamic analysis of
    uncertain data. In this paper, we provide an Expected k-Conviction (EkC) algorithm
    for the dynamic data analysis based on evidence equilibrium. The algorithm uses
    dynamic evidence election and combination to resolve the estimation of uncertainty
    with time constraint. Our experimental results demonstrate that the EkC algorithm
    has better efficiency compared with the static evidence combination approach,
    which will benefit realtime decision making and data fusion under uncertainty.
    Keywords: Bayesian game, Dempster-Shafer, Nash equilibrium, data fusion DOI: 10.3233/IFS-141120
    Journal: Journal of Intelligent & Fuzzy Systems, vol. 27, no. 3, pp. 1533-1543,
    2014 Published: 2014 Price: EUR 27.50 Add to cart Log in or register to view or
    purchase instant access Share this: Twitter share Facebook share Linked in share
    Volume Pre-press Volume 46 Volume 45 Volume 44 Volume 43 Volume 42 Volume 41 Volume
    40 Volume 39 Volume 38 Volume 37 Volume 36 Volume 35 Volume 34 Volume 33 Volume
    32 Volume 31 Volume 30 Volume 29 Volume 28 Volume 27 Issue 6 Issue 5 Issue 4 Issue
    3 Issue 2 Issue 1 Show more  We recommend A novel method to compute Nash equilibrium
    in non-cooperative n-person games based on differential evolutionary algorithm
    Li, Changbing, Intelligent Decision Technologies, 2014 The investigation of two
    competitive systems Tiešis, Vytautas et al., Informatica, 1994 Using directional
    bit sequences to reveal the property-liability underwriting cycle as an Algorithmic
    Process Haley, Joseph D. et al., Algorithmic Finance A multi-risks group evaluation
    method for the informatization project under linguistic environment Cun-Bin Li
    et al., Journal of Intelligent & Fuzzy Systems, 2014 Asymptotic analysis of mean
    field games with small common noise Ahuja, Saran et al., Asymptotic Analysis,
    2018 Equilibrium selection under cyclical disequilibrium dynamics Franke et al.,
    Oxford Economic Papers, 2001 Dynamic simulation and environmental policy analysis:
    beyond comparative statics and the environmental Kuznets curve Anderson et al.,
    Oxford Economic Papers, 2001 Game theory, rationality and evolution of the social
    contract Skyrms, B. et al., Journal of Consciousness Studies, 2000 Subspace and
    Bootstrap-Based Techniques for Helicopter Model Identification Li, Ping et al.,
    Journal of the American Helicopter Society Steps to an Ecology of Emergence Malloy,
    Thomas E. et al., Cybernetics & Human Knowing, 2005 Powered by Log out of ''University
    of Nebraska-Lincoln Libraries'' Journals Help About us Contact us Terms & conditions
    Privacy policy Copyright ©2024 IOS Press All rights reserved. Join our network:
    Twitter Facebook LinkedIn North America IOS Press, Inc. 6751 Tepper Drive Clifton,
    VA 20124 USA Tel: +1 703 830 6300 Fax: +1 703 830 2300 sales@iospress.com For
    editorial issues, like the status of your submitted paper or proposals, write
    to editorial@iospress.nl Europe IOS Press Nieuwe Hemweg 6B 1013 BG Amsterdam The
    Netherlands Tel: +31 20 688 3355 Fax: +31 20 687 0091 info@iospress.nl For editorial
    issues, permissions, book requests, submissions and proceedings, contact the Amsterdam
    office info@iospress.nl Asia Inspirees International (China Office) Ciyunsi Beili
    207(CapitaLand), Bld 1, 7-901 100025, Beijing China  Free service line: 400 661
    8717 Fax: +86 10 8446 7947 china@iospress.cn For editorial issues, like the status
    of your submitted paper or proposals, write to editorial@iospress.nl 如果您在出版方面需要帮助或有任何建,
    件至: editorial@iospress.nl Built on the Scolaris platform by:'
  inline_citation: '>'
  journal: Journal of intelligent & fuzzy systems
  limitations: '>'
  pdf_link: null
  publication_year: 2014
  relevance_score1: 0
  relevance_score2: 0
  title: 'Evidence equilibrium: Nash equilibrium in judgment processes'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/3468.477860
  analysis: '>'
  authors:
  - Isabelle Bloch
  citation_count: 571
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences Loading
    [MathJax]/extensions/MathZoom.js IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More
    Sites Donate Cart Create Account Personal Sign In Browse My Settings Help Access
    provided by: University of Nebraska - Lincoln Sign Out All Books Conferences Courses
    Journals & Magazines Standards Authors Citations ADVANCED SEARCH Journals & Magazines
    >IEEE Transactions on Systems,... >Volume: 26 Issue: 1 Information combination
    operators for data fusion: a comparative review with classification Publisher:
    IEEE Cite This PDF I. Bloch All Authors 444 Cites in Papers 3 Cites in Patents
    1669 Full Text Views Abstract Authors References Citations Keywords Metrics Abstract:
    In most data fusion systems, the information extracted from each sensor (either
    numerical or symbolic) is represented as a degree of belief in an event with real
    values, taking in this way into account the imprecise, uncertain, and incomplete
    nature of the information. The combination of such degrees of belief is performed
    through numerical fusion operators. A very large variety of such operators has
    been proposed in the literature. We propose in this paper a classification of
    these operators issued from the different data fusion theories with respect to
    their behavior. Three classes are thus defined. This classification provides a
    guide for choosing an operator in a given problem. This choice can then be refined
    from the desired properties of the operators, from their decisiveness, and by
    examining how they deal with conflictive situations. Published in: IEEE Transactions
    on Systems, Man, and Cybernetics - Part A: Systems and Humans ( Volume: 26, Issue:
    1, January 1996) Page(s): 52 - 67 Date of Publication: January 1996 ISSN Information:
    DOI: 10.1109/3468.477860 Publisher: IEEE Authors References Citations Keywords
    Metrics More Like This Modeling Spatial Relationships for Remote Sensing Image
    Processing Based on Fuzzy Set Theory 2008 International Conference on Computer
    Science and Software Engineering Published: 2008 Experimental study of uncertainty
    measures with sensor fusion techniques 2010 2nd International Asia Conference
    on Informatics in Control, Automation and Robotics (CAR 2010) Published: 2010
    Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT
    OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES
    PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678
    4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact
    Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics
    Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE
    is the world''s largest technical professional organization dedicated to advancing
    technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE transactions on systems, man and cybernetics. Part A. Systems and
    humans
  limitations: '>'
  pdf_link: null
  publication_year: 1996
  relevance_score1: 0
  relevance_score2: 0
  title: 'Information combination operators for data fusion: a comparative review
    with classification'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/36.602544
  analysis: '>'
  authors:
  - Sylvie Le Hégarat‐Mascle
  - Isabelle Bloch
  - D. Vidal-Madjar
  citation_count: 302
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Journals & Magazines >IEEE Transactions on Geoscien...
    >Volume: 35 Issue: 4 Application of Dempster-Shafer evidence theory to unsupervised
    classification in multisource remote sensing Publisher: IEEE Cite This PDF S.
    Le Hegarat-Mascle; I. Bloch; D. Vidal-Madjar All Authors 258 Cites in Papers 2
    Cites in Patents 1264 Full Text Views Abstract Authors References Citations Keywords
    Metrics Abstract: The aim of this paper is to show that Dempster-Shafer evidence
    theory may be successfully applied to unsupervised classification in multisource
    remote sensing. Dempster-Shafer formulation allows for consideration of unions
    of classes, and to represent both imprecision and uncertainty, through the definition
    of belief and plausibility functions. These two functions, derived from mass function,
    are generally chosen in a supervised way. In this paper, the authors describe
    an unsupervised method, based on the comparison of monosource classification results,
    to select the classes necessary for Dempster-Shafer evidence combination and to
    define their mass functions. Data fusion is then performed, discarding invalid
    clusters (e.g. corresponding to conflicting information) thank to an iterative
    process. Unsupervised multisource classification algorithm is applied to MAC-Europe''91
    multisensor airborne campaign data collected over the Orgeval French site. Classification
    results using different combinations of sensors (TMS and AirSAR) or wavelengths
    (L- and C-bands) are compared. Performance of data fusion is evaluated in terms
    of identification of land cover types. The best results are obtained when all
    three data sets are used. Furthermore, some other combinations of data are tried,
    and their ability to discriminate between the different land cover types is quantified.
    Published in: IEEE Transactions on Geoscience and Remote Sensing ( Volume: 35,
    Issue: 4, July 1997) Page(s): 1018 - 1031 Date of Publication: July 1997 ISSN
    Information: DOI: 10.1109/36.602544 Publisher: IEEE Authors References Citations
    Keywords Metrics More Like This Remote sensing image classification based on dot
    density function weighted FCM clustering algorithm 2007 IEEE International Geoscience
    and Remote Sensing Symposium Published: 2007 Multispectral remote sensing image
    classification algorithm based on rough set theory 2009 IEEE International Conference
    on Systems, Man and Cybernetics Published: 2009 Show More IEEE Personal Account
    CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS
    Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL
    INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT
    & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms
    of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy
    Policy A not-for-profit organization, IEEE is the world''s largest technical professional
    organization dedicated to advancing technology for the benefit of humanity. ©
    Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE transactions on geoscience and remote sensing
  limitations: '>'
  pdf_link: null
  publication_year: 1997
  relevance_score1: 0
  relevance_score2: 0
  title: Application of Dempster-Shafer evidence theory to unsupervised classification
    in multisource remote sensing
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1016/0167-8655(96)00039-6
  analysis: '>'
  authors:
  - Isabelle Bloch
  citation_count: 218
  full_citation: '>'
  full_text: '>

    Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Abstract Keywords References Cited by (205) Pattern Recognition Letters
    Volume 17, Issue 8, 1 July 1996, Pages 905-919 Some aspects of Dempster-Shafer
    evidence theory for classification of multi-modality medical images taking partial
    volume effect into account Author links open overlay panel Isabelle Bloch Show
    more Add to Mendeley Share Cite https://doi.org/10.1016/0167-8655(96)00039-6 Get
    rights and content Abstract This paper points out some key features of Dempster-Shafer
    evidence theory for data fusion in medical imaging. Examples are provided to show
    its ability to take into account a large variety of situations, which actually
    often occur and are not always well managed by classical approaches nor by previous
    applications of Dempster-Shafer theory in medical imaging. The modelization of
    both uncertainty and imprecision, the introduction of possible partial or global
    ignorance, the computation of conflict between images, the possible introduction
    of a priori information are all powerful aspects of this theory, which deserve
    to be more exploited in medical image processing. They may be of great influence
    on the final decision. They are illustrated on a simple example for classifying
    brain tissues in pathological dual echo MR images. In particular, partial volume
    effect can be properly managed by this approach. Previous article in issue Next
    article in issue Keywords Data fusionDempster-Shafer evidence theoryDecisionMulti-modality
    imagingClassificationImprecisionUncertaintyConflictIgnorance View PDF References
    Andress and Kak, 1988 K.M. Andress, A.C. Kak Evidence accumulation and flow control
    in a hierarchical spatial reasoning system AI Magazine (1988), pp. 75-94 Google
    Scholar Appriou, 1991 A. Appriou Probabilités et incertitude en fusion de données
    multi-senseurs Revue Scientifique et Technique de la Défense (1991), pp. 27-40
    Google Scholar Appriou, 1993 A. Appriou Formulation et traitement de l''incertain
    en analyse multi-senseurs Quatorzième Colloque GRETSI, Juan les Pins (1993), pp.
    951-954 Google Scholar Aubourg et al., 1992 P. Aubourg, C. Adamsbaum, M.C. Lavallard-Rosseau,
    A. Lemaitre, F. Boureau, M. Mayer, G. Kalifa Brain MRI and electrophysiologic
    abnormalities in preclinical and clinical adrenomyeloneuropathy Neurology, 42
    (1992), pp. 85-91 View in ScopusGoogle Scholar Aurdal et al., 1995 L. Aurdal,
    X. Descombes, H. Maître, I. Bloch, C. Adamsbaum Analysis of adrenoleukodystrophy
    from dual echo MR images: Automatic segmentation and quantification Computer Assisted
    Radiology CAR''95, Berlin, June 1995 (1995), pp. 35-40 Google Scholar Baldwin,
    1991 J.F. Baldwin A new approach to inference under uncertainty for knowledge
    based systems R. Kruse, P. Siegel (Eds.), Symbolic and Quantitative Approaches
    to Uncertainty, Marseille, 1991, Springer, Berlin (1991), pp. 107-114 CrossRefGoogle
    Scholar Baldwin, 1992 J.F. Baldwin Inference for information systems containing
    probabilistic and fuzzy uncertainties L. Zadeh, J. Kacprzyk (Eds.), Fuzzy Logic
    and the Management of Uncertainty, Wiley, New York (1992), pp. 353-375 Google
    Scholar Barnett, 1981 J.A. Barnett Computational methods for a mathematical theory
    of evidence Proc. 7th IJCAI, Vancouver, 1981 (1981), pp. 868-875 View in ScopusGoogle
    Scholar Bloch, 1996 I. Bloch Information combination operators for data fusion:
    A comparative review with classification IEEE Trans. Syst. Man Cybernet., 26 (1996),
    pp. 52-67 View in ScopusGoogle Scholar Bloch and Maître, 1994 I. Bloch, H. Maître
    Fusion de données en traitement d''images: Modèles d''information et décisions
    Traitement du Signal, 11 (1994), pp. 435-446 View in ScopusGoogle Scholar Chen
    et al., 1993 S.Y. Chen, W.C. Lin, C.T. Chen Evidential reasoning based on Dempster-Shafer
    theory and its application to medical image analysis SPIE 2032 (1993), pp. 35-46
    CrossRefView in ScopusGoogle Scholar Clarke and Wilson, 1991 M. Clarke, N. Wilson
    Efficient algorithms for belief functions based on the relationship between belief
    and probability R. Kruse, P. Siegel (Eds.), Symbolic and Quantitative Approaches
    to Uncertainty, Marseille, 1991, Springer, Berlin (1991), pp. 48-52 CrossRefView
    in ScopusGoogle Scholar Coatrieux et al., 1991 J.L. Coatrieux, C. Roux, R. Collorec
    Fusion d''informations en imagerie médicale tridimensionnelle Bull. de Liaison
    de la Recherche en Informatique et Automatique, 132 (1991), pp. 12-16 Google Scholar
    Cucka and Rosenfeld, May 1992 P. Cucka, A. Rosenfeld Evidence-based pattern matching
    relaxation Technical Report CAR-TR-623, Center of Automation Research, University
    of Maryland (1992) Google Scholar De Maertelaere et al., 1993 P. De Maertelaere,
    P. Ravazzola, P. Ghesquière, A. Beltrando Architectures et méthodes de fusion
    pour la classification multi-sources Actes du Quatorzième Colloque GRETSI, Juan-les-Pins,
    1993 (1993), pp. 983-986 Google Scholar Denœux, 1995 T. Denœux A k-nearest neighbor
    classification rule based on Dempster-Shafer theory IEEE Trans. Syst. Man Cybernet.,
    25 (1995) Google Scholar Dubois and Prade, 1988 D. Dubois, H. Prade Representation
    and combination of uncertainty with belief functions and possibility measures
    Comput. Intell., 4 (1988), pp. 244-264 CrossRefView in ScopusGoogle Scholar Garvey,
    1986 T.D. Garvey Evidential reasoning for land-use classification Analytical Methods
    in Remote Sensing for Geographic Information Systems, Internat. Assoc. Pattern
    Recognition, Technical Committee 7 Workshop, Paris, October 1986 (1986) Google
    Scholar Garvey et al., 1981 T.D. Garvey, J.D. Lowrance, M.A. Fishler An inference
    technique for integrating knowledge from disparate sources Internat. Joint Conf.
    on Artificial Intelligence, 1981 (1981), pp. 319-325 View in ScopusGoogle Scholar
    Géraud et al., 1995 T. Géraud, L. Aurdal, H. Maître, I. Bloch, C. Adamsbaum Estimation
    of partial volume effect using spatial context. Application to morphometry in
    cerebral imaging IEEE Medical Imaging Conf., San Francisco, CA, October 1995 (1995)
    Google Scholar Gordon and Shortliffe, 1985 J. Gordon, E.H. Shortliffe A method
    for managing evidential reasoning in a hierarchical hypothesis space Artificial
    Intelligence, 26 (1985), pp. 323-357 View PDFView articleView in ScopusGoogle
    Scholar Guan and Bell, 1991 J. Guan, D.A. Bell Evidence Theory and its Applications
    North-Holland, Amsterdam (1991) Google Scholar Ip and Ng, 1994 H.H.S. Ip, J.M.C.
    Ng Human face recognition using Dempster-Shafer theory ICIP, Vol. II (1994), pp.
    292-295 Austin, TX, 1994 View in ScopusGoogle Scholar Lee and Leahy, 1990 R.H.
    Lee, R. Leahy Multi-spectral classification of MR images using sensor fusion approaches
    SPIE Medical Imaging IV: Image Processing, 1233 (1990), pp. 149-157 CrossRefView
    in ScopusGoogle Scholar Lee et al., 1987 T. Lee, J.A. Richards, P.H. Swain Probabilistic
    and evidential approaches for multisource data analysis IEEE Trans. Geoscience
    Remote Sensing, 25 (1987), pp. 283-293 CrossRefView in ScopusGoogle Scholar Lowrance,
    1988 J.D. Lowrance Automatic multisource data analysis Internat. Lithosphere Project
    Research Conf. on Advanced Data Integration in Mineral and Energy Resource Studies,
    Sotogrande, Spain, December 1988 (1988) Google Scholar Lowrance et al., 1991 J.D.
    Lowrance, T.M. Strat, L.P. Wesleyy, T.D. Garvey, E.H. Ruspini, D.E. Wilkins The
    theory, implementation and practice of evidential reasoning SRI project 5701 final
    report, SRI, Palo Alto, CA (1991) June 1991 Google Scholar Mascle et al., 1995
    S. Mascle, I. Bloch, D. Vidal-Madjar Unsupervised multisource remote sensing classification
    using Dempster-Shafer evidence theory SPIE/EUROPTO Synthetic Aperture Radar and
    Passive Microwave Sensing 2584 (1995), pp. 200-211 Paris, September 1995 CrossRefView
    in ScopusGoogle Scholar Neapolitan, 1992 R.E. Neapolitan A survey of uncertain
    and approximate inference L. Zadeh, J. Kaprzyk (Eds.), Fuzzy Logic for the Management
    of Uncertainty, Wiley, New York (1992), pp. 55-82 Google Scholar Rasoulian et
    al., 1990 H. Rasoulian, W.E. Thompson, L.F. Kazda, R. Parra-Loera Application
    of the mathematical theory of evidence to the image cueing and image segmentation
    problem SPIE Signal and Image Processing Systems Performance Evaluation 1310 (1990),
    pp. 199-206 CrossRefView in ScopusGoogle Scholar Shafer, 1976 G. Shafer A Mathematical
    Theory of Evidence Princeton University Press, Princeton, NJ (1976) Google Scholar
    Smets, 1978 P. Smets Medical diagnosis: Fuzzy sets and degree of belief Colloque
    Internat. sur la Théorie et les Applications des Sous-Ensembles Flous, Marseille,
    September 1978 (1978) Google Scholar Strat, 1989 T.M. Strat Decision analysis
    using belief functions Technical Note 472, SRI (1989) September 1989 Google Scholar
    Suh et al., 1990 D.Y. Suh, R.M. Mersereau, R.L. Eisner, R.I. Pettigrew Automatic
    boundary detection on cardiac magnetic resonance image sequences for four dimensional
    visualization of the left ventricle First Conf. on Visualization in Biomedical
    Computing, Atlanta, GA, 1990 (1990), pp. 149-156 View in ScopusGoogle Scholar
    Van Cleynenbreugel et al., 1991 J. Van Cleynenbreugel, S.A. Osinga, F. Fierens,
    P. Suetens, A. Oosterlinck Road extraction from multi-temporal satellite images
    by an evidential reasoning approach Pattern Recognition Lett., 12 (1991), pp.
    371-380 View PDFView articleView in ScopusGoogle Scholar Wesley, 1986 L.P. Wesley
    Evidential knowledge-based computer vision Opt. Engrg., 25 (1986), pp. 363-379
    View in ScopusGoogle Scholar Zahzah, 1992 E. Zahzah Contribution à la représentation
    des connaissances et à leur utilisation pour l''interprétation automatique des
    images satellites Thèse de Doctorat, Université Paul Sabatier, Toulouse (1992)
    1992 Google Scholar Cited by (205) Application of belief functions to medical
    image segmentation: A review 2023, Information Fusion Citation Excerpt : Table
    3 summarizes the segmentation methods with multimodal inputs and a single classifier/cluster
    with the main focus on modality-level evidence fusion. In [109], Bloch first proposed
    a BFT-based dual-echo MR pathological brains tissue segmentation model with uncertainty
    and imprecision quantification. The author assigned mass functions based on a
    reasoning approach that uses gray-level histograms provided by each image to choose
    focal elements. Show abstract Risk assessment of an oil depot using the improved
    multi-sensor fusion approach based on the cloud model and the belief Jensen-Shannon
    divergence 2020, Journal of Loss Prevention in the Process Industries Show abstract
    Sparse Reconstructive Evidential Clustering for Multi-View Data 2024, IEEE/CAA
    Journal of Automatica Sinica A Systematic Review of Brain MRI Segmentation and
    Uncertainty Modeling Using Evidence Theory with Implementation of Fuzzy Clustering
    and Fuzzy Inference Systems Methods 2023, Revue d''Intelligence Artificielle Medical
    Image Segmentation with Belief Function Theory and Deep Learning 2023, arXiv Model-free
    generalized fiducial inference 2023, arXiv View all citing articles on Scopus
    View Abstract Copyright © 1996 Published by Elsevier B.V. Recommended articles
    Accelerated electron paramagnetic resonance imaging using partial Fourier compressed
    sensing reconstruction Magnetic Resonance Imaging, Volume 37, 2017, pp. 90-99
    Chia-Chu Chou, …, Jiachen Zhuo View PDF Derivation of a measure of systolic blood
    pressure mutability: a novel information theory-based metric from ambulatory blood
    pressure tests Journal of the American Society of Hypertension, Volume 10, Issue
    3, 2016, pp. 217-223.e2 Danitza J. Contreras, …, Benjamin Stockins Hidden Markov
    models with set-valued parameters Neurocomputing, Volume 180, 2016, pp. 94-107
    Denis Deratani Mauá, …, Cassio Polpo de Campos View PDF Show 3 more articles Article
    Metrics Citations Citation Indexes: 195 Captures Readers: 47 View details About
    ScienceDirect Remote access Shopping cart Advertise Contact and support Terms
    and conditions Privacy policy Cookies are used by this site. Cookie settings |
    Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V.,
    its licensors, and contributors. All rights are reserved, including those for
    text and data mining, AI training, and similar technologies. For all open access
    content, the Creative Commons licensing terms apply.'
  inline_citation: '>'
  journal: Pattern recognition letters
  limitations: '>'
  pdf_link: null
  publication_year: 1996
  relevance_score1: 0
  relevance_score2: 0
  title: Some aspects of Dempster-Shafer evidence theory for classification of multi-modality
    medical images taking partial volume effect into account
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.15837/ijccc.2013.1.170
  analysis: '>'
  authors:
  - Alina Mădălina Lonea
  - Daniela Elena Popescu
  - Huaglory Tianfield
  citation_count: 72
  full_citation: '>'
  full_text: '>

    INT J COMPUT COMMUN, ISSN 1841-9836

    8(1):70-78, February, 2013.

    Detecting DDoS Attacks in Cloud Computing Environment

    A.M. Lonea, D.E. Popescu, H. Tianﬁeld

    Alina Madalina Lonea

    "Politehnica" University of Timisoara,

    Faculty of Automation and Computers

    B-dul Vasile Parvan, nr. 2, 300223, Timisoara, Romania

    E-mail: madalina _ lonea@yahoo.com

    Daniela Elena Popescu

    University of Oradea, Faculty of Electrical Eng. and Information Tech.

    Universitatii street, nr. 1, 410087, Oradea, Romania

    E-mail: depopescu@uoradea.ro

    Huaglory Tianﬁeld

    School of Engineering and Built Environment,

    Glasgow Caledonian University

    Cowcaddens Road, Glasgow G4 0BA, United Kingdom

    E-mail: h.tianﬁeld@gcu.ac.uk

    Abstract:

    This paper is focused on detecting and analyzing the Distributed Denial of Service

    (DDoS) attacks in cloud computing environments. This type of attacks is often
    the

    source of cloud services disruptions. Our solution is to combine the evidences
    obtained

    from Intrusion Detection Systems (IDSs) deployed in the virtual machines (VMs)
    of

    the cloud systems with a data fusion methodology in the front-end. Speciﬁcally,
    when

    the attacks appear, the VM-based IDS will yield alerts, which will be stored into
    the

    Mysql database placed within the Cloud Fusion Unit (CFU) of the front-end server.

    We propose a quantitative solution for analyzing alerts generated by the IDSs,
    using

    the Dempster-Shafer theory (DST) operations in 3-valued logic and the fault-tree

    analysis (FTA) for the mentioned ﬂooding attacks. At the last step, our solution
    uses

    the Dempsters combination rule to fuse evidence from multiple independent sources.

    Keywords: cloud computing, cloud security, Distributed Denial of Service (DDoS)

    attacks, Intrusion Detection Systems, data fusion, Dempster-Shafer theory.

    1

    Introduction

    Cloud computing technology is in continuous development and with numerous challenges

    regarding security. In this context, one of the main concerns for cloud computing
    is represented by

    the trustworthiness of cloud services. This problem requires prompt resolution
    because otherwise

    organizations adopting cloud services would be exposed to increased expenditures
    while at a

    greater risk.

    A survey conducted by International Data Corporation (IDC) in August 2008

    conﬁrms that security is the major barrier for the cloud users.

    There are two things that cloud service providers should guarantee all the time:
    connectivity

    and availability, and if there are not met, the entire organizations will suﬀer
    high costs [1].

    This paper is focused on detecting and analyzing Distributed Denial of Service
    (DDoS) attacks

    in cloud computing environment.

    This type of attacks is often the source of cloud services

    disruptions. One of the eﬃcient methods for detecting DDoS is to use the Intrusion
    Detection

    Systems (IDS), in order to assure usable cloud computing services [2]. However,
    IDS sensors

    have the limitations that they yield massive amount of alerts and produce high
    false positive

    rates and false negative rates [3].

    Copyright c⃝ 2006-2013 by CCC Publications

    Detecting DDoS Attacks in Cloud Computing Environment

    71

    With regards to these IDS issues, our proposed solution aims to detect and analyze
    Dis-

    tributed Denial of Service (DDoS) attacks in cloud computing environments, using
    Dempster-

    Shafer Theory (DST) operations in 3-valued logic and Fault-Tree Analysis (FTA)
    for each VM-

    based Intrusion Detection System (IDS). The basic idea is to obtain information
    from multiple

    sensors, which are deployed and conﬁgured in each virtual machine (VM). The obtained
    infor-

    mation is integrated in a data fusion unit, which takes the alerts from multiple
    heterogeneous

    sources and combines them using the Dempster’s combination rule. Our approach
    quantitatively

    represents the imprecision and eﬃciently utilizes it in IDS to reduce the false
    alarm rates.

    Speciﬁcally, our solution combines the evidences obtained from Intrusion Detection
    Systems

    (IDSs) deployed in the virtual machines (VMs) of the cloud system with a data
    fusion method-

    ology within the front-end.

    Our proposed solution can also solve the problem of analysing the logs generated
    by sensors,

    which seems to be a big issue [4].

    The remainder of this paper is organized as follows: section 2 introduces Dempster-Shafer

    Theory. Section 3 presents the related work of IDS in Cloud Computing and the
    related work of

    IDS using data fusion. Section 4 introduces the proposed solution of detecting
    DDoS attacks in

    Cloud Computing. Finally, in section 5 the paper presents the concluding remarks.

    2

    Dempster-Shafer Theory (DST)

    Dempster-Shafer Theory is established by two persons: Arthur Dempster, who introduced
    it

    in the 1960’s and Glenn Shafer, who developed it in the 1970’s [5].

    As an extension of Bayesian inference, Dempster-Shafer Theory (DST) of Evidence
    is a

    powerful method in statistical inference, diagnostics, risk analysis and decision
    analysis. While

    in the Bayesian method probabilities are assigned only for single elements of
    the state space

    (Ω),in DST probabilities are assigned on mutually exclusive elements of the power
    sets of possible

    states [6], [7].

    According to DST method, for a given state space (Ω) the probability (called mass)
    is allo-

    cated for the set of all possible subsets of Ω, namely 2Ω elements.

    Consequently, the state space (Ω) is also called frame of discernment, whereas
    the assignment

    procedure of probabilities is called basic probability assignment (bpa) [6], [7],
    [8].

    We will apply the particular case of DST, i.e., the DST operations in 3-valued
    logic using the

    fault-tree analysis (FTA), adopted by Guth (1991) and also used in Popescu, et
    al. (2010).

    Thus, if a standard state space Ω is (True, False), then 2Ω should have 4 elements:
    { ϕ,

    True, False, (True, False) }. The (True, False) element describes the imprecision
    component

    introduced by DST, which refers to the fact of being either true or false, but
    not both. DST is a

    useful method for fault-tree analysts in quantitatively representing the imprecision
    [8]. Another

    advantage of DST is it can eﬃciently be utilized in IDS to reduce the false alarm
    rates by the

    representation of ignorance [6], [7], [10].

    For the reason that in DST the [sum of all masses] = 1 and m(ϕ) = 0,we have the
    following

    relation:

    m(True) + m(False) + m(True, False) = 1

    (1)

    In order to analyze the results of each sensor we’ll use the fault tree analysis,
    which can be

    realized by boolean OR gate. Table 1 describes the Boolean truth table for the
    OR gate.

    From Table 1 we have:

    m(A) = (a1, a2, a3) = {m(T), m(F), m(T, F)}

    (2)

    72

    A.M. Lonea, D.E. Popescu, H. Tianﬁeld

    Table 1: BOOLEAN TRUTH TABLE FOR THE OR GATE

    b1

    b2

    b3

    ∨

    T

    F

    (T,F)

    a1

    T

    T

    T

    T

    a2

    F

    T

    F

    (T,F)

    a3

    (T,F)

    T

    (T,F)

    (T,F)

    m(B) = (b1, b2, b3) = {m(T), m(F), m(T, F)}

    (3)

    ⇒ m(A ∨ B) = (a1b1 + a1b2 + a1b3 + a2b1 + a3b1; a2b2; a2b3 + a3b2 + a3b3)

    (4)

    m(A ∨ B) = (a1 + a2b1 + a3b1; a2b2; a2b3 + a3b2 + a3b3)

    (5)

    At the last step, our solution applies the Dempster’s combination rule, which
    allows fusing

    evidences from multiple independent sources using a conjunctive operation (AND)
    between two

    bpa’s m1 and m2 , called the joint m12 [11]:

    m12(A) =

    ∑

    B ∩ C=A m1(B)m2(C)

    1 − K

    ,

    (6)

    when : A ̸= ϕ

    m12(ϕ) = 0

    and K = ∑

    B ∩ C=ϕ m1(B)m2(C)

    The factor 1-K, called normalization factor, is constructive for entirely avoiding
    the conﬂict

    evidence.

    Data fusion is also applied in real world examples: robotics, manufacturing, remote
    sensing

    and medical diagnosis, as well in military threat assessment and weather forecast
    systems [12].

    Sentz and Ferson (2002) demonstrated in their study that Dempster’s combination
    rule is

    suitable for the case that the sources of evidences are reliable and a minimal
    conﬂict or irrelevant

    conﬂict is generated.

    3

    Related Work

    3.1

    Intrusion Detection Systems (IDS) in Cloud Computing

    One of the IDS strategies proved reliable in cloud computing environments is its
    applicability

    to each virtual machine. This is the method we’ll choose for our proposed solution.
    Mazzariello,

    et al. (2010) presented and evaluated this method in comparison with another IDS
    deployment

    strategy, which uses single IDS near the cluster controller. IDS applied to each
    virtual machine

    in cloud computing platform eliminates the overloading problem, because in a way
    the network

    traﬃc is split to all IDSs. Thus, applying IDS to each virtual machine gets rid
    of the issue of the

    IDS strategy near the cluster controller, which tends to be overloaded because
    of its necessity to

    monitor all the supposed traﬃc from the cloud computing infrastructure. Another
    advantage of

    this strategy as described by Roschke, et al. (2009) is the beneﬁt of reducing
    the impact of the

    possible attacks by the IDS Sensor VMs.

    However, the limitation of IDS strategy applied to each virtual machine is the
    missing of the

    correlation phase, which is suggested in the future work by Mazzariello, et al.
    (2010).

    Detecting DDoS Attacks in Cloud Computing Environment

    73

    The correlation phase will be included in our proposed solution, because beside
    the IDS for

    each virtual machine, our IDS cloud topology will include a Cloud Fusion Unit
    (CFU) on the

    front-end, with the purpose of obtaining and controlling the alerts received from
    the IDS sensor

    VMs as presented by Roschke, et al. (2009) in their theoretical IDS architecture
    for cloud, which

    utilizing an IDS Management Unit.

    Compared to Roschke, et al.

    (2009) who suggested the utilization of IDMEF (Intrusion

    Detection Message Exchange) standard, a useful component for storage and exchange
    of the

    alerts from the management unit, the alerts in our proposed solution will be stored
    into the

    Mysql database of Cloud Fusion Unit. The Cloud Fusion Unit will add the capacity
    to analyze

    the results using the Dempster-Shafer theory (DST) of evidence in 3-valued logic
    and the Fault-

    Tree Analysis for the IDS of each virtual machine and at the end the results of
    the sensors will

    be fused using Dempster’s combination rule.

    A similar method of using a IDS Management Unit is proposed in Dhage, et al. (2011),

    who presented a theoretical model of an IDS model in cloud computing, by using
    a single IDS

    controller, which creates a single mini IDS instance for each user. This IDS instance
    can be

    used in multiple Node controllers and a node controller can contain IDS instances
    of multiple

    users. The analysis phase of the mini IDS instance for each user takes place in
    the IDS controller.

    Compared with Roschke, et al. (2009) where the emphasis is on how to realize the
    synchronization

    and integration of the IDS Sensor VMs, in Dhage, et al. (2011) the focus is to
    provide a clear

    understanding of the cardinality used in the basic architecture of IDS in cloud
    infrastructure.

    Applying the IDS for each virtual machine is an idea suggested also by Lee, et
    al. (2011), who

    increases the eﬀectiveness of IDS by assigning a multi-level intrusion detection
    system and the log

    management analysis in cloud computing. In this sense the users will receive appropriate
    level

    of security, which will be emphasized on the degree of the IDS applied to the
    virtual machine,

    and as well on the prioritization stage of the log analysis documents. This multi-level
    security

    model solves the issue of using eﬀective resources.

    Lo, et al. (2010) proposed a cooperative IDS system for detecting the DoS attacks
    in Cloud

    Computing networks, which has the advantage of preventing the system from single
    point of

    failure attack, even if it is a slower IDS solution than a pure Snort based IDS.
    Thus, the framework

    proposed by Lo, et al. (2010) is a distributed IDS system, where each IDS is composed
    of three

    additional modules: block, communication and cooperation, which are added into
    the Snort IDS

    system.

    3.2

    IDS using Dempster-Shafer theory

    Dempster-Shafer Theory (DST) is an eﬀective solution for assessing the likelihood
    of DDoS

    attacks, which was demonstrated by several research papers in the context of network
    intrusion

    detection systems. Dissanayake (2008) presented a survey upon intrusion detection
    using DST.

    Our study is to detect DDoS attacks in cloud computing environments. Dempster-Shafer

    Theory (DST) is used to analyze the results received from each sensor (i.e. VM-based
    IDS).

    Data used in experiments using DST vary: Yu and Frincke (2005) used DARPA DDoS

    intrusion detection evaluation datasets, Chou et al.

    (2008) used DARPA KDD99 intrusion

    detection evaluation dataset, Chen and Aickelin (2006) used the Wisconsin Breast
    cancer dataset

    and IRIS plant data, while others scientists generated their own data [7]. The
    data to be used in

    our proposed solution will be generated by ourselves, by performing DDoS attacks
    using speciﬁc

    tools against the VM-based IDS.

    Siaterlis, et al. (2003) and Siaterlis and Maglaris (2005) performed a similar
    study of detecting

    DDoS using data fusion and their ﬁeld was an operational university campus network,
    while in

    our solution the DDoS attacks are proposed to be detected and analyzed in our
    private cloud

    74

    A.M. Lonea, D.E. Popescu, H. Tianﬁeld

    computing environment.

    Additionally, we consider to analyze the attacks generated against the TCP, UDP,
    ICMP

    packets, like Siaterlis, et al.

    (2003) and Siaterlis and Maglaris (2005).

    However, instead of

    applying DST on the state space Ω = {Normal, UDP − flood, SY N − flood, ICMP −
    flood},

    our study uses DST operations in 3-valued logic as suggested by Guth (1991) for
    the same

    ﬂooding attacks: TCP-ﬂood, UDP-ﬂood, ICMP-ﬂood, for each VM-based IDS. Like Siaterlis

    and Maglaris (2005), Chatzigiannakis, et al., (2007) chosen the same frame of
    discernment, while

    Hu, et al. (2006) used a state space: {Normal, TCP, UDP and ICMP}.

    Furthermore, compared with the study performed by Siaterlis, at al. (2003) and
    Siaterlis and

    Maglaris (2005), who use a minimal neural network at the sensor level, our proposed
    solution will

    assign the probabilities using: DST in 3-valued logic, the pseudocode and the
    fault tree analysis.

    Whilst the computational complexity of DST is increasing exponentially with the
    number of

    elements in the frame of discernment [12], the DST 3-valued logic proposed to
    be used in our

    research will not encounter this issue, which will meet the eﬃciency requirements
    in terms of

    both detection rate and computation time [15].

    Finally, the data fusion of the evidences obtained from sensors studied by Siaterlis
    and

    Maglaris (2005) will be used in our study. The data fusion will be realized using
    the Dempster-

    Shafer combination rule, which was demonstrated in Siaterlis and Maglaris (2005)
    for its ad-

    vantages, i.e., maximization of DDoS true positive rates and minimization of the
    false positive

    alarm rate, by combining the evidence received from sensors.

    Therefore, the work of cloud

    administrators will be alleviated, whereas the number of alerts will decrease.

    4

    Proposed Solution

    In order to detect and analyze Distributed Denial of Service (DDoS) attacks in
    cloud com-

    puting environments we propose a solution as presented in Figure 1. For illustration
    purpose, a

    private cloud with a front-end and three nodes is set up. Whilst the detection
    stage is executed

    within the nodes, more precisely inside the virtual machines (VMs), where the
    Intrusion Detec-

    tion Systems (IDSs) are installed and conﬁgured; the attacks assessment phase
    is handled inside

    the front-end server, in the Cloud Fusion Unit (CFU).

    The ﬁrst step in our solution includes the deployment stage of a private cloud
    using Euca-

    lyptus open-source version 2.0.3. The topology of the implemented private cloud
    is: a front-end

    (with Cloud Controller, Walrus, Cluster Controller, Storage Controller) and a
    back-end (i.e.

    three nodes). The Managed networking mode is chosen because of the advanced features
    that it

    provides and Xen hypervisor is used for virtualization.

    Then, the VM-based IDS are created, by installing and conﬁguring Snort into each
    VM. The

    reason of using this IDS location is because the overloading problems can be avoided
    and the

    impact of possible attacks can be reduced [2], [13].

    These IDSs will yield alerts, which will be stored into the Mysql database placed
    within the

    Cloud Fusion Unit (CFU) of the front-end server. A single database is suggested
    to be used

    in order to reduce the risk of losing data, to maximize the resource usage inside
    the VMs and

    to simplify the work of cloud administrator, who will have all the alerts situated
    in the same

    place. A similar idea of obtaining and controlling the alerts received from the
    IDS Sensor VMs

    using an IDS Management Unit was presented by Roschke, et al. (2009) as a theoretical
    IDS

    architecture for cloud.

    A similar method of using an IDS Management Unit is proposed in

    Dhage, et al. (2011). However, our solution adds the capacity to analyse the results
    using the

    Dempster-Shafer theory of evidence in 3-valued logic.

    As showed in Figure 1, the Cloud Fusion Unit (CFU) comprises 3 components: Mysql

    database, bpas calculation and attacks assessment.

    Detecting DDoS Attacks in Cloud Computing Environment

    75

    Figure 1: IDS Cloud Topology

    I. Mysql database

    The Mysql database is introduced with the purpose of storing the alerts received
    from the

    VM-based IDS. Furthermore, these alerts will be converted into Basic Probabilities
    Assignments

    (bpas), which will be calculated using the pseudocode below.

    II. Basic probabilities assignment (bpa’s) calculation

    For calculating the basic probabilities assignment, ﬁrst we decide on the state
    space Ω. In this

    paper we use DST operations in 3-valued logic {True, False, (True, False)} Guth
    (1991) for the

    following ﬂooding attacks: TCP-ﬂood, UDP-ﬂood, ICMP-ﬂood, for each VM-based IDS.
    Thus,

    the analyzed packets will be: TCP, UDP and ICMP. Further, a pseudocode for converting
    the

    alerts received from the VM-based IDS into bpas is provided. The purpose of this
    pseudocode

    is to obtain the following probabilities of the alerts received from each VM-based
    IDS:

    (mUDP (T), mUDP (F), mUDP (T, F))

    (mTCP (T), mTCP (F), mTCP (T, F))

    (mICMP (T), mICMP (F), mICMP (T, F))

    76

    A.M. Lonea, D.E. Popescu, H. Tianﬁeld

    Figure 2: BPA’s calculation

    Pseudocode for converting the alerts into bpa’s:

    For each node

    Begin

    For each X ∈ {UDP; TCP; ICMP}:

    Begin

    1: Query the alerts from the database when a X attack occurs for the speciﬁed
    hostname

    2: Query the total number of possible X alerts for each hostname

    3: Query the alerts from the database when X attack is unknown

    4: Calculate the Belief (True) for X, by dividing the result obtained at step
    1 with the result

    obtained at step 2

    5: Calculate the Belief (True, False) for X, by dividing the result obtained at
    step 3 with the

    result obtained at step 2

    6: Calculates Belief (False) for X: 1- Belief (True) - Belief (True, False)

    end

    end

    Furthermore, after obtaining the probabilities for each attack packet (i.e. UDP,
    TCP, ICMP)

    for each VM-based IDS, the probabilities for each VM-based IDS should be calculated
    following

    the fault-tree as shows in Figure 2. Figure 2 reveals only the calculation of
    the probabilities (i.e.

    mS1(T), mS1(F), mS1(T, F)) for the ﬁrst VM-based IDS.

    Thus, using the DST with fault-tree analysis we can calculate the belief (Bel)
    and plausibility

    (Pl) values for each VM-based IDS:

    Bel(S1) = mS1(T)

    (7)

    Pl(S1) = mS1(T) + mS1(T, F)

    (8)

    III. Attacks assessment

    The attacks assessment consists of data fusion of the evidences obtained from
    sensors by

    using the Dempster’s combination rule, with the purpose of maximizing the DDoS
    true positive

    rates and minimizing the false positive alarm rate. mS1,S2(T) can be calculated
    using Table 2

    and equation (6).

    Detecting DDoS Attacks in Cloud Computing Environment

    77

    Table 2: BOOLEAN TRUTH TABLE FOR THE OR GATE

    mS1(T)

    mS1(F)

    mS1(T,F)

    mS2(T)

    mS1(T) mS2(T)

    mS1(F) mS2(T)

    mS1(T,F) mS2(T)

    mS2(F)

    mS1(T) mS2(F)

    mS1(F) mS2(F)

    mS1(T,F) mS2(F)

    mS2(T,F)

    mS1(T) mS2(T,F)

    mS1(F) mS2(T,F)

    mS1(T,F) mS2(T,F)

    5

    Conclusions

    To detect and analyze Distributed Denial of Service (DDoS) attacks in cloud computing

    environments we have proposed a solution using Dempster-Shafer Theory (DST) operations
    in

    3-valued logic and the Fault-Tree Analysis (FTA) for each VM-based Intrusion Detection
    System

    (IDS). Our solution quantitatively represents the imprecision and eﬃciently utilizes
    it in IDS to

    reduce the false alarm rates by the representation of the ignorance.

    Whilst the computational complexity of DST is increasing exponentially with the
    number of

    elements in the frame of discernment [12], the DST 3-valued logic in our solution
    does not have

    this issue, which meets the eﬃciency requirements in terms of both detection rate
    and computa-

    tion time. At the same time, the usability requirement has been accomplished,
    because the work

    of cloud administrators will be alleviated by using the Dempster rule of evidence
    combination

    whereas the number of alerts will decrease and the conﬂict generated by the combination
    of

    information provided by multiple sensors is entirely eliminated.

    To sum up, by using DST our proposed solution has the following advantages: to
    accom-

    modate the uncertain state, to reduce the false negative rates, to increase the
    detection rate, to

    resolve the conﬂicts generated by the combination of information provided by multiple
    sensors

    and to alleviate the work for cloud administrators.

    Acknowledgment

    This work was partially supported by the strategic grant POSDRU/88/1.5/S/50783,
    Project

    ID50783 (2009), co-ﬁnanced by the European Social Fund - Investing in People,
    within the

    Sectoral Operational Programme Human Resources Development 2007-2013.

    Bibliography

    [1] Perry,

    G.,

    Minimizing public cloud disruptions,

    TechTarget,

    [online]. Available at:

    http://searchdatacenter.techtarget.com/tip/Minimizing-public-cloud-disruptions,
    2011.

    [2] Roschke, S., Cheng, F. and Meinel, C.,Intrusion Detection in the Cloud. In
    Eighth IEEE

    International Conference on Dependable, Autonomic and Secure Computing, pp. 729-734,

    2009.

    [3] Yu, D. and Frincke, D.,A Novel Framework for Alert Correlation and Understanding.
    In-

    ternational Conference on Applied Cryptography and Network Security (ACNS) 2004,

    Springer’s LNCS series, 3089, pp. 452-466, 2004.

    [4] Lee, J-H., Park, M-W., Eom, J-H. And Chung, T-M., Multi-level Intrusion Detection
    System

    and Log Management in Cloud Computing. In 13th International Conference on Advanced

    Communication Technology (ICACT) ICACT 2011, Seoul, 13- 16 February, pp.552- 555,

    2011.

    [5] Chen, Q. and Aickelin, U., Dempster-Shafer for Anomaly Detection. In Proceedings
    of the

    International Conference on Data Mining (DMIN 2006), Las Vegas, USA, pp. 232-238,
    2006.

    78

    A.M. Lonea, D.E. Popescu, H. Tianﬁeld

    [6] Siaterlis, C., Maglaris, B. and Roris, P., A novel approach for a Distributed
    Denial of Service

    Detection Engine. National Technical University of Athens. Athens, Greece, 2003.

    [7] Siaterlis, C. And Maglaris, B., One step ahead to Multisensor Data Fusion
    for DDoS De-

    tection. Journal of Computer Security, 13(5):779-806, 2005.

    [8] Guth, M.A.S., A Probabilistic Foundation for Vagueness & Imprecision in Fault-Tree
    Anal-

    ysis. IEEE Transactions on Reliability, 40(5), pp.563-569, 1991.

    [9] Popescu D.E., Lonea A.M., Zmaranda D.,Vancea C. and Tiurbe C. , Some Aspects
    about

    Vagueness & Imprecision in Computer Network Fault-Tree Analysis. INT J COMPUT

    COMMUN, ISSN: 1841-9836, 5(4):558-566, 2010.

    [10] Esmaili, M., Dempster-Shafer Theory and Network Intrusion Detection Systems.
    Scientia

    Iranica, Vol. 3, No. 4, Sharif University of Technology, 1997.

    [11] Sentz, K. and Ferson, S., Combination of Evidence in Dempster-Shafer Theory.
    Sandia

    National Laboratories, Sandia Report, 2002.

    [12] Dissanayake, A., Intrusion Detection Using the Dempster-Shafer Theory. 60-510
    Literature

    Review and Survey, School of Computer Science, University of Windsor, 2008.

    [13] Mazzariello, C., Bifulco, R. and Canonico, R., Integrating a Network IDS
    into an Open

    Source Cloud Computing Environment. In Sixth International Conference on Information

    Assurance and Security, pp. 265-270, 2010.

    [14] Dhage, S. N., et al., Intrusion Detection System in Cloud Computing Environment.
    In In-

    ternational Conference and Workshop on Emerging Trends in Technology (ICWET 2011)
    ’

    TCET, Mumbai, India, pp. 235-239, 2011.

    [15] Lo, C-C. , Huang, C-C. And Ku, J., A Cooperative Intrusion Detection System
    Framework

    for Cloud Computing Networks. In 39th International Conference on Parallel Processing

    Workshops, pp.280-284, 2010.

    [16] Yu, D. and Frincke, D., Alert Conﬁdence Fusion in Intrusion Detection Systems
    with Ex-

    tended Dempster-Shafer Theory. ACM-SE 43: Proceedings of the 43rd ACM Southeast
    Con-

    ference, pp. 142-147, 2005.

    [17] Chou, T., Yen, K.K., Luo, J., Network intrusion detection design using feature
    selection of

    soft computing paradigms. International Journal of Computational Intelligence,
    4(3):102-

    105, 2008.

    [18] Chatzigiannakis, V., et al., Data fusion algorithms for network anomaly detection:
    classi-

    ﬁcation and evaluation. Proceedings of the Third International Conference on Networking

    and Services (ICNS’07), 2007.

    [19] Hu, W., Li, J. and Gao, Q., Intrusion Detection Engine Based on Dempster-Shafer’s
    The-

    ory of Evidence. Communications, Circuits and Systems Proceedings, 2006 International

    Conference, 3:1627-1631, 2006.

    '
  inline_citation: '>'
  journal: International Journal of Computers Communications & Control
  limitations: '>'
  pdf_link: https://univagora.ro/jour/index.php/ijccc/article/download/170/pdf_14
  publication_year: 2012
  relevance_score1: 0
  relevance_score2: 0
  title: Detecting DDoS Attacks in Cloud Computing Environment
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1016/s0169-7439(02)00111-9
  analysis: '>'
  authors:
  - Sylvie Roussel
  - Véronique Bellon Maurel
  - Jean‐Michel Roger
  - Pierre Grenier
  citation_count: 79
  full_citation: '>'
  full_text: '>

    Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Chemometrics and Intelligent Laboratory Systems Volume 65, Issue 2, 28 February
    2003, Pages 209-219 Fusion of aroma, FT-IR and UV sensor data based on the Bayesian
    inference. Application to the discrimination of white grape varieties Author links
    open overlay panel Sylvie Roussel, Véronique Bellon-Maurel, Jean-Michel Roger,
    Pierre Grenier Show more Share Cite https://doi.org/10.1016/S0169-7439(02)00111-9
    Get rights and content Abstract The objective of this study is to present a fusion
    method based on the Bayesian inference to combine the outputs of various sensors.
    The sensors studied here are aroma sensors, FT-IR and UV spectrometers. The application
    deals with classifying musts of white grapes according to their variety. The fusion
    procedure is not based on the combination of the signals, but of the class assignments
    provided individually by each sensor. Two methods have been developed based on
    the Bayesian inference: the Bayesian minimum error fusion rule and the minimum
    risk rule. The latter involves both experimental knowledge, in computing error
    probability values, and expert knowledge, through the level of error costs. The
    paper presents the mathematical theory concerning the Bayesian approach and the
    results obtained on white grape classification. This effective fusion method leads
    to a significant improvement in the grape variety discrimination: the final misclassification
    error is 4.7%, whereas the best individual sensor (FT-IR) gave a misclassification
    error twice as high, i.e. 9.6%. Bayesian fusion proved to be very well suited
    to the combination of all kinds of analytical measurements or sensors (curves
    or single value outputs), as long as they provide individual classification outputs.
    Furthermore, Bayesian fusion is able to cope with sensors providing large, noisy
    and redundant data as well as sensors showing very dissimilar efficiency levels.
    Previous article in issue Next article in issue Keywords Sensor fusionBayesian
    inferenceClassificationGrape varietyAroma sensorFT-IR spectrometryUV spectrometry
    1. Introduction Due to increasing consumer demand for information on food product
    quality and origin, food industry operators are increasingly anxious to guarantee
    the authenticity of their products. This is even more important for food products
    that are guaranteed to come from a precise geographic origin or to belong to a
    specific vegetal variety. In wine production, variety-based wine is increasingly
    popular with consumers. The ability to guarantee that a grape is, or is not, from
    an expected variety is of prime interest to wine makers. To certify the origin
    or the variety of products, Polymerase Chain Reaction (PCR)-based technology can
    be used, which gives highly accurate results but is time consuming and costly.
    The alternative is to use several high-speed non-specific techniques and to combine
    their outputs [1]. This alternative is also called sensor or data fusion. Sensor
    fusion is analogous to the cognitive process used by humans to constantly integrate
    data given by their senses to make inferences about the external world. So far,
    in agriculture and food areas, it has been widely applied to robotics [2], [3]
    or remote sensing [4], [5]. Less common is sensor or data fusion applied to food
    quality control [6], [7], [8], [9], [10]. Ref. [7] propose to organise data fusion
    methods in three levels. 1. The first and most basic level involves concatenating
    raw sensor outputs and then processing them as if they were a single signal. This
    method, called low-level fusion, was applied beforehand to the data presented
    here and did not lead to significant improvement [11]. At present, the main difficulty
    in the application of the low-level fusion method concerns the manipulation of
    raw signals, frequently made up of noisy and redundant data, and which have an
    adverse effect on the classification results. 2. Mid-level fusion consists of
    extracting features from the signal of each sensor and in processing them. Mid-level
    fusion has been quite thoroughly explored [12], [13], [14]. It is particularly
    pertinent when few features are sufficient to provide all the information, for
    instance, when a curve can be modelled by a simple function. Spectra cannot be
    easily modelled using few features. However, “feature extraction” can be carried
    out, for instance, through wavelength selection. We have successfully applied
    it on this databank to FT-IR spectra [11]. 3. High-level fusion is carried out
    on the classification outputs of all the individual sensors. The classification
    output, i.e. the quality class that is assigned to the measured product based
    on the sensor signal, is called the “identity declaration”. In high level fusion,
    the identity declarations of each sensor are combined in order to give the final
    identity declaration. This method can be applied to all types of analytical measurements,
    since it combines class assignments and not analytical signals. Various techniques
    are used in high-level fusion [15]. They are either heuristic (elementary voting
    techniques), based on probability estimation such as the Bayesian inference [16],
    or methods based on possibility (or evidence theory), like the Dempster–Shafer
    theory [17], which is a generalization of Bayesian techniques applied to data
    with a high level of uncertainty. The Bayesian approach has been adopted in this
    study because probability values can be directly computed from the results of
    individual sensor classifications. Thus, this method is particularly well suited
    to pattern recognition issues. However, the Bayesian approach has rarely been
    applied to multisensor fusion [5], [18], [19]. The objective is to present two
    data fusion methods derived from the Bayesian inference. The application deals
    with classifying musts of white grapes according to their variety. The devices
    used are aroma sensors, FT-IR and UV spectrometers. The first step of these research
    studies has been published previously [11]. After a rapid description of material
    and classification methods—which can be fully retrieved in Ref. [11]—this paper
    presents the Bayesian inference used to establish the two multisensor fusion rules:
    the Bayesian minimum error fusion rule and the Bayesian minimum risk fusion rule.
    These high-level fusion procedures are then applied to the identity declarations
    given by the individual sensors. Finally, these results are compared to those
    produced by each individual sensor and the low-level fusion (tested in Ref. [11]);
    a discussion is proposed on the potential of high-level fusion rules to deal with
    an array of sensors capable of generating individual identity declarations. 2.
    Experimental This part is not thoroughly detailed as every experimental point
    has been described in Ref. [11]. 2.1. Samples Must samples (107) of white grapes
    have been collected and divided in four classes with regards to variety: 44 “Sauvignon”,
    14 “Mauzac”, 14 “Colombard” and a fourth class made of 35 samples of various other
    white varieties (“Chardonnay”,“Loin de l''œil”, “Riesling”, etc.). This class
    distribution mirrors the grape population distribution in the south of France.
    Each must sample has been prepared following the French Technical Institute for
    Wines (ITV) methodology [20]. 2.2. Materials 2.2.1. Aroma sensors The aroma sensor
    device was an upgraded LCA 1000 prototype (Midivaleur, Toulouse, France) based
    on five SnO2 gas sensors; the apparatus and the optimal experimental conditions
    used were described in a previous study [21]. The temperature of both measurement
    cell and headspace was set at 60 °C; 50-ml headspace was injected with a syringe
    into the 500-ml cell; then, each sample was measured. The cell was cleaned using
    desiccated and filtered air at a 500 ml min−1 flow rate. The five output curves
    were concatenated after removing the baseline value in order to create a unique
    aroma sensor curve. 2.2.2. FT-IR spectrometer The absorbance signal was acquired
    in the 4000–800 cm−1 range, with a 4 cm−1 acquisition step, using a Fourier-Transform
    mid-Infrared spectrometer (Bruker IFS 25, Bruker, Wissembourg, France). The samples
    were analyzed in an ATR cell (ZnSe, 10 reflections). The reference was distilled
    water. A triangular apodisation function was applied. Spectra were pre-processed
    using genetic algorithms (GA) to select the most suitable wavelengths for pattern
    recognition. 2.2.3. UV spectrometer The UV spectrometer (Secomam S1000, Secomam,
    Ales, F) measures the UV absorbance between 200 and 500 nm, including parts of
    UV and visible bands with a 1-nm resolution. Spectra were pre-processed using
    genetic algorithms. 2.3. Pre-processing and pattern recognition methods In a previous
    work [11], different pre-processing and pattern recognition methods were tested
    to provide the best classification results based on the outputs of each sensor.
    The FT-IR and UV spectra were pre-processed using Genetic Algorithms (GA) in order
    to select the most discriminant wavelength subset from the whole spectra. GA is
    now a well-known evolutionary-based technique used for feature (wavelength) selection
    to improve the robustness and the accuracy of multivariate models based on numerous
    correlated data [22], [23], [24]. A population of chromosomes, representing the
    various selected variable subsets, evolves using crossover during reproduction
    and mutations to produce the feature selection producing the best classification
    model. The genetic algorithm selection procedure as well as the parameters used
    in this application (population size, mutation rate, stop criterion, etc.) have
    been detailed in a previous paper [11]. The most accurate classification technique
    was based on Partial Least Squares (PLS) regression technique, adapted to pattern
    recognition by predicting the four classes of grapes using PLS2 algorithm with
    an exclusive binary coding scheme (four columns with 0:1): PLS-Discriminant Analysis
    (PLS-DA) [25]. For each sample, the PLS-DA model provides four figures, i.e. prediction
    values for the four grape variety classes; the sample is then assigned to the
    class predicted with the highest rate. For each sensor, the global classification
    error rate is computed using a leave-one-out cross-validation. 3. Theory In order
    to combine the information coming from each sensor, Bayesian inference is employed.
    Bayesian methods explicitly use probabilities for quantifying uncertainty in inference
    based on statistical data analysis. In this paper, the Bayesian inference method
    will first be described using one sensor, and then generalized for multisensor
    fusion. The population of the white grape samples is divided into g classes (or
    hypotheses) (k∈G={1,…,g=4} varieties), which are mutually exclusive and exhaustive.
    3.1. Bayesian minimum error fusion 3.1.1. Bayesian minimum error rule The Bayesian
    minimum error rule (Eq. (1)) aims at classifying the sample x into the most probable
    class k, based on its description Pr(k∣x), that is the conditional posterior probability
    of the hypothesis k, after considering the effect of evidence x: (1) This expression
    means that Ŷ(x)=k, for the hypothesis k which maximizes Pr(k∣x), i.e. the sample
    x is assigned to the most probable class (with the highest probability Pr(k∣x)).
    However, the conditional posterior probability Pr(k∣x) is not a direct output
    of the experiments. The aim of Bayes'' theorem is to express it using probability
    values that can be determined from the experiment. Thus, the posterior probability
    Pr(k∣x) is expressed using the probability of evidence x assuming the hypothesis
    k, Pr(x∣k) (also called likelihood function or conditional prior probability),
    the prior probability of the hypothesis k independent of the evidence x, pk and
    the evidence x probability Pr(x), which is independent from the hypotheses. (2)
    Using Bayes'' theorem (Eq. (2)), Eq. (1) becomes: (3) ∀k∈G Pr(x) is constant,
    being independent from the hypotheses.Thus, Eq. (3) gives: (4) As we will see
    in the “Application paragraph” (Section 3.3), Pr(x∣k) can be directly computed
    from the confusion matrix experimentally obtained for each sensor and pk depends
    on the sample population. 3.1.2. Bayesian minimum error fusion rule As far as
    N sensors are concerned, Eq. (4) can be generalized as the Bayesian minimum error
    fusion rule (Eq. (5)). It deals with a set of N identity declarations for sample
    Xt={X1,…,XN}. (5) To express the joint probability of N identity declarations
    (Pr(X1,…, XN)), several aggregation operators can be used (AND, OR, MAX, MIN,
    etc.). Following previous studies [18], [19], we have adopted the intersection
    operator AND. (6) The joint probability can be broken down into conditional probabilities,
    as shown in the following equation: (7) However, if the sensor independence hypothesis
    is assumed, the joint probability is the simple product of the individual probabilities,
    as shown in the following equation: (8) The independence hypothesis between sensors
    measuring similar characteristics of the same samples is difficult to ascertain.
    Nevertheless, Eq. (8) will be used to design a simplified Bayesian model, based
    on the independence assumption. If this model is not efficient enough, a more
    complex model could be built, taking into account conditional probabilities (Eq.
    (7)). Following Eq. (8) which states the sensor independence, Eq. (6) becomes
    the Bayesian minimum error fusion rule: (9) 3.2. Bayesian minimum risk fusion
    rule 3.2.1. Bayesian minimum risk rule The assignment rule based on Bayesian minimum
    risk does not attempt to minimize the classification error but the consequence
    of this error, i.e. the risk induced by the error. For instance, if you classify
    mushrooms in toxic/non-toxic classes, the risk is very high when a toxic mushroom
    is assigned to the nontoxic class. The more serious the consequence of affecting
    a sample belonging to class k, to class h, the higher the risk value C(k,h). The
    risk function is defined as follows: (10) The Bayesian minimum risk rule consists
    of minimizing the error risk average on the g classes: (11) When applying Bayes''
    Theorem (Eq. (2)), Eq. (11) leads to the Bayesian minimum risk classification
    rule involving prior probabilities, able to be applied: (12) where Pr(x∣k) is
    obtained with the confusion matrix and ph is determined by the structure of the
    population. 3.2.2. Bayesian minimum risk fusion rule In the same way as before,
    Eq. (12) can be generalized to N sensor measurements. If the same intersection
    operator is used to combine the conditional probabilities, Eq. (12) becomes: (13)
    The error risk C(k,h) is the same whatever the sensor used. Assuming the sensor
    independence, Eq. (8) stands and then Eq. (13) is changed into Eq. (14), i.e.
    the Bayesian minimum risk fusion rule: (14) 3.3. Application example 3.3.1. Conditional
    probability assessment To apply the Bayesian rules, the class probabilities pk
    and the likelihood values Pr(h∣k) must be assessed. Pr(h∣k) is based on the error
    frequency supplied by the individual sensor classification results. These results
    are gathered in a “confusion matrix”, in which each element (h,k) is the number
    of samples belonging to the class k and assigned to the class h for each of the
    three sensors (aroma sensors, FT-IR and UV spectrometers); these confusion matrices
    are given in Ref. [11]. All the likelihood values are computed by dividing the
    value of (h,k) by the class size. They are all assembled in a “Causality Matrix”
    Mi={Pr(Xi∣k)}; an example is shown in Table 1. The causality matrices computed
    for the three sensors are given in Table 2, Table 3, Table 4 based on the results
    of Ref. [11]. Table 1. Causality matrix Mi, for the sensor i Empty Cell Real classes
    (N samples) Predicted classes “Sauvignon” (Sa) “Mauzac” (Ma) “Colombard” (Co)
    “Other varieties” (Ov) Sample number NSa=n+1 NMa=n+2 NCo=n+3 NAu=n+4 pk pSa=p1=n+1/N
    pMa=p2=n+2/N pCo=p3=n+3/N pAu=p4=n+4/N Pr( i∣Sa)=n11/NSa Pr( i∣Ma)=n12/NMa Pr(
    i∣Co)=n13/NCo Pr( i∣Au)=n14/NAu Pr( i∣Sa)=n21/NSa Pr( i∣Ma)=n22/NMa Pr( i∣Co)=n23/NCo
    Pr( i∣Au)=n24/NAu Pr( i∣Sa)=n31/NSa Pr( i∣Ma)=n32/NMa Pr( i∣Co)=n33/NCo Pr( i∣Au)=n34/NAu
    Pr( i∣Sa)=n41/NSa Pr( i∣Ma)=n42/NMa Pr( i∣Co)=n43/NCo Pr( i∣Au)=n44/NAu nij is
    the number of samples belonging to the class j and classified in the class i,
    i.e. an element of the confusion matrix. The four variety classes are “Sauvignon”
    (Sa), “Mauzac” (Ma), “Colombard” (Co) and “Other varieties” (Ov), numbered 1 to
    4. n+j is the size of the class j. Table 2. Causality matrix provided by a PLS-DA
    (12 latent variables) performed on the FT-IR pre-processed spectra Empty Cell
    Real classes Predicted classes “Sauvignon” “Mauzac” “Colombard” “Other varieties”
    pk 0.41 0.13 0.13 0.33 0.98 0 0 0.09 0.02 0.86 0 0.17 0 0.14 1 0 0 0 0 0.74 Table
    3. Causality matrix provided by a PLS-DA (10 latent variables) performed on UV
    pre-processed spectra Empty Cell Real classes Predicted classes “Sauvignon” “Mauzac”
    “Colombard” “Other varieties” 0.82 0.07 0.29 0.11 0.09 0.86 0.14 0.09 0.02 0.07
    0.57 0.03 0.07 0 0 0.77 Table 4. Causality matrix provided by a PLS-DA (6 latent
    variables) performed on aroma sensors Empty Cell Real classes Predicted classes
    “Sauvignon” “Mauzac” “Colombard” “Other varieties” 0.61 0.93 0.43 0.37 0 0.07
    0 0 0.18 0 0.50 0.11 0.20 0 0.07 0.51 3.3.2. Risk assessment The application of
    the Bayesian minimum risk fusion rule (Eq. (14)) requires the definition of classification
    error risks C(k,h). These risks, also called costs, are determined using the expert
    knowledge about the problem being considered. The main goal of this classification
    is to distinguish the “Sauvignon” variety from all the others, since it is the
    most appetizing and expensive of all the grape varieties tested. Thus, the most
    important point is to avoid mistaking grapes from all other varieties ( ) with
    that of the “Sauvignon” (Sa); therefore, the risk is very high =100 in Eq. (14).
    But it is also important to recognize the “Sauvignon” samples (cost effectiveness),
    i.e. it is risky to misclassify them: =10. It is less important to misclassify
    varieties that are not “Sauvignon”: C(h/k)=1/. All the error risks are detailed
    in Eq. (15) and can be compiled in a risk matrix C for further mathematical computations
    (cf. Table 5). (15) Table 5. The risk matrix C Empty Cell Real classes Predicted
    classes “Sauvignon” (Sa) “Mauzac” (Ma) “Colombard” (Co) “Other varieties” (Ov)
    C( /Sa)=0 C( /Ma)=100 C( /Co)=100 C( /Au)=100 C( /Sa)=10 C( /Ma)=0 C( /Co)=1 C(
    /Au)=1 C( /Sa)=10 C( /Ma)=1 C( /Co)=0 C( /Au)=1 C( i/Sa)=10 C( i/Ma)=1 C( i/Co)=1
    C( i/Au)=0 4. Results First of all, high-level fusion is applied to the best classification
    results provided by the FT-IR and UV spectrometers, which are the discriminations
    based on the spectra pre-processed by genetic algorithms (cf. Fig. 1). Second,
    the aroma sensor classification is combined with them, whereby three-sensor fusion
    is obtained. All the individual classification results as well as the sensor fusion
    results are gathered in Fig. 1. Download : Download full-size image Fig. 1. White
    grape must variety classification error rates generated by different sensors and
    processing systems. IR: FT-IR spectrometer; UV: ultraviolet spectrometer; AS:
    aroma sensors; +GA: wavelengths selected by genetic algorithms; PLS: Partial Least
    Squares–Discriminant Analysis; post.: a posteriori pre-processed FT-IR and UV
    spectra; minimum error: Bayesian minimum error fusion rule; minimum risk: Bayesian
    minimum risk fusion rule. 4.1. Spectral fusion based on Bayesian minimum error
    rule The Bayesian minimum error fusion rule (Eq. (9)), when applied to the FT-IR
    and UV identity declarations, produces different decisions displayed in the “decision
    matrix” (Table 6). When there is a conflict between their decision, the FT-IR
    judgement is given more weight (10 white boxes) than the UV one (1 gray box).
    This is due to the difference between the individual classification performances:
    the error rate of variety discrimination using FT-IR data is 9.6%, whereas it
    is as high as 22.9% with UV data (cf. Fig. 1). Thus, confidence in the FT-IR decision
    is higher. Table 6. Decision matrix computed by the Bayesian minimum error fusion
    based on FT-IR and UV spectra The empty box (∅) corresponds to a case that never
    happens in this prediction procedure. aAttribution that is altered by the introduction
    of error risks. This Bayesian minimum error fusion obviously improves the grape
    classification, achieving a 6.5% error rate, with seven misclassified samples
    among 107 (cf. Table 7). Table 7. Confusion matrix of the FT-IR and UV spectra
    fusion based on Bayesian minimum error rule 4.2. Spectral fusion based on Bayesian
    minimum risk rule Even though sensor fusion leads to a significant improvement
    compared to individual classification error rates, there remains one “Sauvignon”
    sample misclassification and three “Other varieties” samples which are affected
    to the “Sauvignon” class. The involvement of classification error costs in the
    Bayesian minimum risk fusion rule (Eq. (14)) should rule out this type of error,
    which induces severe consequences (and thus high error costs, cf. Eq. (15)). In
    fact, the introduction of risks in the decision rule alters only one assignment:
    when the FT-IR measurement assigns the sample to the “Sauvignon” class and the
    UV indicates that it belongs to the “Other varieties” class, then the decision
    based on the sensor fusion agrees now with the UV spectra (* in Table 6). The
    misclassification of non-“Sauvignon” samples to the “Sauvignon” class is therefore
    diminished. Table 8 shows the difference induced by this decision change in the
    grape classification: the global error rate is the same, but no “Other varieties”
    sample is attributed to the “Sauvignon” class (gray box); on the contrary, three
    “Sauvignon” samples are not recognized any longer (black box). Table 8. Confusion
    matrix of the FT-IR and UV spectra fusion based on Bayesian minimum risk rule
    In conclusion, in the classifications established by the two Bayesian rules, six
    samples appear to be ambiguous (black boxes in Table 7, Table 8). In reality,
    three samples belong to the “Sauvignon” class and the three others to the “Other
    varieties” class; they are all assigned to the “Sauvignon” class by the FT-IR
    sensor and to the “Other varieties” class by the UV one. Thus, the present Bayesian
    rules will inevitably misclassify three samples (whatever the sensor fusion decision).
    4.3. Spectral and aroma sensor fusion based on Bayesian minimum error Although
    insufficient for grape variety classification, aroma sensors might improve the
    high-level fusion decision based on FT-IR and UV sensors. Introducing aroma sensor
    identity declaration in the final decision alters only two decision cases which
    concern the fusion carried out on the spectral data alone (Table 9). These two
    changes slightly improve the classification error rate, which falls to 4.7%, thanks
    to two additional samples correctly classified. Table 9. Confusion matrix of the
    aroma sensor, FT-IR and UV data fusion based on Bayesian minimum error rule All
    the “Sauvignon” and “Mauzac” samples are now accurately identified. However, three
    samples belonging to “Other varieties” are still affected to the “Sauvignon” class,
    as in the case where only the spectrometer results and the Bayesian minimum error
    rule were combined (Section 4.2). This problem should be overcome when the minimum
    risk rule is applied. 4.4. Spectral and aroma sensor fusion based on Bayesian
    minimum risk The aroma sensor introduction in the Bayesian minimum risk classification
    leads to a 5.6% error rate (cf. Table 10). Table 10. Confusion matrix of the aroma
    sensor, FT-IR and UV data fusion based on Bayesian minimum risk rule The introduction
    of classification error costs alters some sample attributions with respect to
    the Bayesian minimum error decision. No sample is misclassified in the “Sauvignon”
    variety, thanks to the high cost associated with this kind of mistake, whereas
    four “Sauvignon” samples are affected to the “Other varieties” class. 5. Discussion
    and conclusion High-level multi-sensor fusion significantly improves the white
    grape must variety classification with regards to individual discriminations.
    The error rate falls to 4.7% or 5.6%, respectively, for the Bayesian minimum error
    fusion or the Bayesian minimum risk fusion. Although olfaction does not seem to
    be the best way to discriminate grape varieties—and therefore the “Sauvignon”
    flavour—the adjunction of the aroma sensor identity declaration slightly improves
    FT-IR and UV spectral classification efficiency. Thus, unlike with low-level fusion,
    the combination of data coming from rather inefficient sensors (in this case,
    aroma sensors) does not worsen the overall performance (cf. Fig. 1). The aroma
    sensor even improves (although only slightly) fusion results, whereas the addition
    of its signals in low-level fusion completely disabled the discrimination outputs.
    Accordingly, this high-level fusion procedure is very well suited to combining
    the outputs of all sensors, even those with very divergent performance levels,
    since the probability assessment reflects the confidence attached to each sensor
    (the more accurate the sensor, the more the fusion process relies on its classification
    results). High-level fusion is definitively better suited to white grape variety
    classification than the low-level one; this assumption can be generalized to most
    of the discrimination problems based on analytical methods or sensors providing
    numerous noisy and redundant data as well as dissimilar efficiency levels. In
    this pattern recognition application, the unbalanced class size might have enhanced
    the problems linked to noise and redundancy. Furthermore, the high-level fusion
    process can be applied to all kinds of analytical measurements capable of providing
    identity declarations. Moreover, the introduction of expert knowledge using classification
    error costs is an original and important step forward, which combines experimental
    and expert information. The Bayesian minimum risk rule makes the discrimination
    more specific, by allowing some kinds of errors and forbidding others. This risk
    assessment is based on expert knowledge. This would be particularly suited for
    an authentication process using different analytical techniques. For instance,
    when dealing with white grape variety classification, “Sauvignon” was the most
    important variety; thus, the first- and second-order errors in “Sauvignon” variety
    discrimination had to be avoided. The risk values must be carefully adjusted,
    since a too high-risk value can lead to systematically avoiding assigning grapes
    to the “Sauvignon” class. During the Bayesian inference development, the sensor
    independence hypothesis has been assumed in order to simplify the joint probability
    computation of the different sensor measurements. Data correlation analysis showed
    that small wavelength bands of UV and FT-IR spectra are redundant. However, since
    the classification results based on this “simplified” model are very satisfying
    (4.7% error rate), only slight improvements could be expected from a more complex
    model. In a further study, Bayesian inference application to fusion processes
    might be somewhat improved in three ways: 1. in taking into account the conditional
    probability values with regards to all the sensors involved in the fusion to express
    the joint probability; 2. in adjusting more accurately the decision to each sample.
    The current sensor–fusion decisions were established in a global and Boolean way
    by using the whole database with a 0:1 classification, once and for all the samples.
    However, every sample is assigned to a class by each sensor with a decimal number
    prediction (not a 0:1, but for e.g. 0.2 or 0.8). Consequently, it would make good
    sense to allow for the sensor classification confidence for each sample, that
    is the membership level to every class instead of a simple Boolean assignment;
    3. in selecting the best suited aggregation operator used to combine the likelihood
    values of the different sensors , with regards to the classification problem.
    These different generalization procedures of the current Bayesian fusion rules
    can help in improving the classification results in very complex discrimination
    issues. Acknowledgements This work received financial support from Association
    de Coordination Technique pour l''Industrie Agro-alimentaire (ACTIA). The authors
    thank the ITV, especially from Gaillac, Pech-Rouge and Nı̂mes, for helping them
    obtain the grape samples. L. Vidié and M. Baguelin, students from Ecole des Mines
    d''Alès (EMA), under the responsibility of Ms. Gonzales, are thanked for providing
    UV spectra and carrying out FT-IR measurements at Cemagref. References [1] J.M.
    Fildes, A. Cinar Food Processing Automation II Proceedings of the 1992 Conference,
    Food and Processing Engineering Institute, ASAE, Lexington, KY, USA (1992), pp.
    65-72 Google Scholar [2] H. Matsuura, K. Hatou, J. Yamashita, Y. Hashimoto J.
    Soc. High Technol. Agric., 9 (1997), pp. 132-138 CrossRef [3] T. Hague, J.A. Marchant,
    N.D. Tillett Comput. Electron. Agric., 25 (2000), pp. 11-28 View PDFView articleView
    in Scopus [4] R.S. Lunetta, C.D. Elvidge (Eds.), Remote Sensing Change Detection:
    Environmental Monitoring Methods and Applications, Taylor and Francis, London,
    UK (1999), p. 318 xviii [5] C.M. Onyango, J.A. Marchant, R. Zwiggelaar Comput.
    Electron. Agric., 17 (1997), pp. 295-305 View PDFView articleView in Scopus [6]
    V. Steinmetz, M. Crochon, V. Bellon-Maurel, J. Garcia Fernandez, P. Barreiro Elorza,
    L. Verstreken J. Agric. Eng. Res., 64 (1996), pp. 15-28 View in Scopus [7] V.
    Steinmetz, F. Sévila, V. Bellon-Maurel J. Agric. Eng. Res., 74 (1999), pp. 21-31
    View PDFView articleView in Scopus [8] V. Steinmetz, J.M. Roger, E. Molto, J.
    Blasco J. Agric. Eng. Res., 73 (1999), pp. 207-216 View PDFView articleView in
    Scopus [9] N. Ozer, B.A. Engel, J.E. Simon Trans. ASAE, 38 (1995), pp. 1927-1934
    View in Scopus [10] S.P. Xia, Z.S. Teng, W.X. Yu Res. Agric. Mod., 21 (2000),
    pp. 24-27 [11] S. Roussel, V. Bellon-Maurel, J.M. Roger, P. Grenier J. Food Eng.
    (2001) (submitted for publication) [12] Y. Edan, H. Pasternak, D. Guedalia, N.
    Ozer, I. Shmulevitch, D. Rachmani, E. Fallik, S. Grinberg Am. Soc. Agric. Eng.,
    Intern. Summer Meeting, Kansas city, US, June 19–22 (1994), pp. 1-19 [13] N. Ozer,
    B.A. Engel, J.E. Simon Trans. ASAE, 38 (1995), pp. 1927-1934 View in Scopus [14]
    V. Steinmetz, M. Crochon, V. Bellon-Maurel, J. Garcia Fernandez, P. Barreiro Elorza,
    L. Verstreken J. Agric. Eng. Res., 64 (1996), pp. 15-28 View in Scopus [15] D.L.
    Hall, Mathematical techniques in multisensor data fusion. Boston Artech House,
    Series: Electronic Warfare/radar Library, USA, 1992, p. 301. Google Scholar [16]
    G. Caraux, Y. Lechevallier Artif. Intell. Rev., 10 (1996), pp. 219-284 View in
    Scopus [17] G. Shafer A Mathematical Theory of Evidence Princeton Univ. Press,
    Princeton, NJ (1976) Google Scholar [18] A. Dromigny, Y.M. Zhu J. Nondestr. Eval.,
    16 (1997), pp. 147-160 View in Scopus [19] R. Chatila, In Support de cours de
    stage: “Pour les systèmes multicapteurs: la fusion de données”, Polytechnique,
    Palaiseau, F, 1996, pp. 1–38. Google Scholar [20] L. Cayla, in: ITV (Ed.), Recueil
    des techniques de prélèvements et d''analyses. Méthodologie interne ITV, Station
    régionale ITV Midi-Pyrénées, Gaillac, F, 1998, p. 10. Google Scholar [21] S. Roussel,
    G. Forsberg, P. Grenier, V. Bellon-Maurel J. Food Eng., 39 (1998), pp. 9-15 [22]
    W. Siedlecki, J. Sklansky Int. J. Pattern Recogn. Artif. Intell., 2 (1988), pp.
    197-220 [23] D. Jouan-Rimbaud, D.L. Massart, R. Leardi, O.E. De Noord Anal. Chem.,
    68 (1995), pp. 4295-4301 CrossRefView in Scopus [24] J.-M. Roger, V. Bellon-Maurel
    Appl. Spectrosc., 54 (2000), pp. 1313-1320 CrossRefView in Scopus [25] H. Martens,
    T. Naes B.R. Kowalski (Ed.), Chemometrics, Mathematics and Statistics in Chemistry,
    NATO ASI Ser., Ser. C: Math. Phys Sci., vol. 138, Reidel Publishing, Dordrecht,
    The Netherlands (1984), p. 485 Google Scholar Cited by (0) View Abstract Copyright
    © 2002 Elsevier Science B.V. All rights reserved. Recommended articles Discrimination
    of Radix Astragali according to geographical regions by data fusion of laser induced
    breakdown spectroscopy (LIBS) and infrared spectroscopy (IR) combined with random
    forest (RF) Chinese Journal of Analytical Chemistry, Volume 50, Issue 3, 2022,
    Article 100057 Yang WANG, …, Hua LI View PDF Recent Advances in High-Level Fusion
    Methods to Classify Multiple Analytical Chemical Data Data Handling in Science
    and Technology, Volume 31, 2019, pp. 129-155 D. Ballabio, …, V. Consonni Geographical
    discrimination of red garlic (Allium sativum L.) using fast and non-invasive Attenuated
    Total Reflectance-Fourier Transformed Infrared (ATR-FTIR) spectroscopy combined
    with chemometrics Journal of Food Composition and Analysis, Volume 86, 2020, Article
    103351 Alessandra Biancolillo, …, Angelo Antonio D’Archivio View PDF Show 3 more
    articles Article Metrics Citations Citation Indexes: 79 Captures Readers: 57 View
    details About ScienceDirect Remote access Shopping cart Advertise Contact and
    support Terms and conditions Privacy policy Cookies are used by this site. Cookie
    settings | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier
    B.V., its licensors, and contributors. All rights are reserved, including those
    for text and data mining, AI training, and similar technologies. For all open
    access content, the Creative Commons licensing terms apply.'
  inline_citation: '>'
  journal: Chemometrics and Intelligent Laboratory Systems
  limitations: '>'
  pdf_link: null
  publication_year: 2003
  relevance_score1: 0
  relevance_score2: 0
  title: Fusion of aroma, FT-IR and UV sensor data based on the Bayesian inference.
    Application to the discrimination of white grape varieties
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1186/s40537-020-0285-1
  analysis: '>'
  authors:
  - Hui Yie Teh
  - Andreas W. Kempa-Liehr
  - Kevin I‐Kai Wang
  citation_count: 95
  full_citation: '>'
  full_text: ">\nSensor data quality: a systematic review\nHui Yie Teh1, Andreas W.\
    \ Kempa‑Liehr2,3*  and Kevin I‑Kai Wang1\nIntroduction\nWith the emergence of\
    \ the Internet of Things (IoT) and wireless sensor networks \n(WSNs), sensor devices\
    \ are deployed across the globe in a variety of fields such as \nhealthcare, industry,\
    \ agriculture, home, and transport [1]. Recently, Cisco [2] estimated \nthat there\
    \ would be approximately 850 zettabytes (1 zettabyte is 1021 bytes) of data gen-\n\
    erated from devices. An IoT application may have hundreds or thousands of sensors\
    \ \nwhich produces vast amounts of data, but the data is rendered useless if it\
    \ is riddled \nwith errors as poor sensor data quality caused by the errors may\
    \ lead to wrong deci-\nsion-making results. In this paper, the term sensor refers\
    \ to a physical sensor [3, Chap 3], \nwhich measures the changes in physical quantity\
    \ e.g. temperature, humidity, and light \nAbstract \nSensor data quality plays\
    \ a vital role in Internet of Things (IoT) applications as they are \nrendered\
    \ useless if the data quality is bad. This systematic review aims to provide an\
    \ \nintroduction and guide for researchers who are interested in quality‑related\
    \ issues of \nphysical sensor data. The process and results of the systematic\
    \ review are presented \nwhich aims to answer the following research questions:\
    \ what are the different types of \nphysical sensor data errors, how to quantify\
    \ or detect those errors, how to correct them \nand what domains are the solutions\
    \ in. Out of 6970 literatures obtained from three \ndatabases (ACM Digital Library,\
    \ IEEE Xplore and ScienceDirect) using the search string \nrefined via topic modelling,\
    \ 57 publications were selected and examined. Results show \nthat the different\
    \ types of sensor data errors addressed by those papers are mostly \nmissing data\
    \ and faults e.g. outliers, bias and drift. The most common solutions for \nerror\
    \ detection are based on principal component analysis (PCA) and artificial neural\
    \ \nnetwork (ANN) which accounts for about 40% of all error detection papers found\
    \ in the \nstudy. Similarly, for fault correction, PCA and ANN are among the most\
    \ common, along \nwith Bayesian Networks. Missing values on the other hand, are\
    \ mostly imputed using \nAssociation Rule Mining. Other techniques include hybrid\
    \ solutions that combine \nseveral data science methods to detect and correct\
    \ the errors. Through this systematic \nreview, it is found that the methods proposed\
    \ to solve physical sensor data errors can‑\nnot be directly compared due to the\
    \ non‑uniform evaluation process and the high use \nof non‑publicly available\
    \ datasets. Bayesian data analysis done on the 57 selected pub‑\nlications also\
    \ suggests that publications using publicly available datasets for method \nevaluation\
    \ have higher citation rates.\nKeywords: Systematic review, Sensor data quality,\
    \ Sensor data error detection, Sensor \ndata error correction, Datasets\nOpen\
    \ Access\n© The Author(s) 2020. This article is licensed under a Creative Commons\
    \ Attribution 4.0 International License, which permits use, sharing, \nadaptation,\
    \ distribution and reproduction in any medium or format, as long as you give appropriate\
    \ credit to the original author(s) and \nthe source, provide a link to the Creative\
    \ Commons licence, and indicate if changes were made. The images or other third\
    \ party material \nin this article are included in the article’s Creative Commons\
    \ licence, unless indicated otherwise in a credit line to the material. If material\
    \ \nis not included in the article’s Creative Commons licence and your intended\
    \ use is not permitted by statutory regulation or exceeds the \npermitted use,\
    \ you will need to obtain permission directly from the copyright holder. To view\
    \ a copy of this licence, visit http://creat iveco \nmmons .org/licen ses/by/4.0/.\n\
    SURVEY PAPER\nTeh et al. J Big Data            (2020) 7:11  \nhttps://doi.org/10.1186/s40537-020-0285-1\n\
    *Correspondence:   \nkempa‑liehr@fmf.\nuni‑freiburg.de \n2 Freiburg Materials\
    \ Research \nCenter, University of Freiburg, \nFreiburg, Germany\nFull list of\
    \ author information \nis available at the end of the \narticle\nPage 2 of 49\n\
    Teh et al. J Big Data            (2020) 7:11 \nintensity of the sample or surroundings.\
    \ Furthermore, the term error relates to the soft \nfaults that occur in sensor\
    \ data found commonly in the systematic review such as outli-\ners, bias, drifts,\
    \ missing values, and uncertainty, which should be detected or quantified \nand\
    \ removed or corrected in order to improve sensor data quality.\nThis is slightly\
    \ different from the data quality (DQ) dimensions introduced by Wang \nand Strong [4],\
    \ which categorize the quality of data in databases or high-level application\
    \ \narchitecture (Application Layer in Fig. 1) that are important to data consumers.\
    \ They are \nmostly used to describe data in enterprise-level systems and are\
    \ used for modelling how \ndata errors propagate to the consumer’s end. Therefore,\
    \ apart from incomplete (miss-\ning data) and inaccurate data (uncertainty), which\
    \ are sensor data quality-related issues, \nother DQ dimensions such as inconsistent\
    \ data and timeliness are not considered in this \nreview paper as they are more\
    \ specific to the topics of database design or communica-\ntion data quality.\
    \ A survey related to DQ dimensions is presented in the works of Kark-\nouch et al. [5].\n\
    Figure 1 shows an overview of the data flow of a typical IoT application. A physical\
    \ sen-\nsor such as a temperature or humidity sensor measures and collects readings\
    \ (changes \nin the observed property) in the Perception layer. The readings are\
    \ then transmitted \nthrough the Network layer, which determines the routes to\
    \ send the sensor data and is \nimplemented using wireless technologies such as\
    \ WiFi, 2G/3G/4G, Bluetooth, and LoRa. \nNext, the Application layer receives\
    \ data from the network layer and it is where the data \nprocessing, predictive\
    \ analytics  [6], and storage takes place. The application layer is \ndesigned\
    \ and implemented using big data architectures such as Apache Hadoop, Spark, \n\
    or Kafka. The added complexity of the architecture causes new errors to be potentially\
    \ \nintroduced in each layer. For example, in the Network Layer, poor data quality\
    \ arises \nfrom congested and unstable wireless communication links in sensor\
    \ networks which \ncauses data loss and corruption [7]. In the Perception Layer,\
    \ damage or exhaustion of \nbattery in sensor devices also causes data quality\
    \ to degrade, as towards the end of its \nbattery life, sensors tend to produce\
    \ unstable readings [8]. The hostile environment in \nwhich in-situ sensors are\
    \ deployed also plays a big part in the quality of the transmitted \ndata. For\
    \ example, sensors for temperature, light, or humidity measurements are often\
    \ \nplaced outdoors and are subjected to extreme local weather conditions such\
    \ as strong \nwinds and snow, which might affect the operation of the sensor.\n\
    Fig. 1 IoT architecture. A high‑level view of a typical IoT architecture which\
    \ shows the data flow\nPage 3 of 49\nTeh et al. J Big Data            (2020) 7:11\
    \ \n \nAlthough the factors that cause errors and affect sensor data quality are\
    \ known, sim-\nple strategies to overcome data quality problems, such as using\
    \ industry grade sensors, \nwhich are more accurate, stable and robust, are not\
    \ feasible for applications that require \nthe deployment of large and dense sensors\
    \ networks, which is the case for many IoT \napplications. For example, in horticulture,\
    \ sensors need to be deployed such that they \nhave high coverage and accuracy\
    \ through large and dense sensor networks. Having to \ndeploy many highly accurate\
    \ but expensive sensors will incur higher deployment costs. \nTherefore, most\
    \ IoT applications use low-cost sensors, though at the expense of data \nquality.\
    \ The use of both industry grade or low-cost sensors also results in high time\
    \ and \nmaintenance cost as experts would have to go out to the field themselves\
    \ to test and \ncalibrate the entire network of in-situ sensors to ensure data\
    \ quality. Other than that, \nre-transmitting the data when experiencing data\
    \ quality errors (e.g. missing data) also \ndoes not work well in an IoT application.\
    \ This is because the nodes in the network are \npowered on limited battery and\
    \ memory which makes it expensive in terms of power \nand computational resources\
    \ to resend the missing data across the network, especially \nif there is a big\
    \ load of data to re-transmit. Retransmission also delays decision-making \nwhich\
    \ in turn may lead to inaccurate results [9].\nOther than that, though studies\
    \ in previous years tend to focus on high-level solutions \nin the Application\
    \ Layer for solving data quality issues [4, 10], it is not possible nowadays \n\
    due to the separation of the layers and complexity of the architecture. The advance\
    \ of \nBig Data where the sheer volume of data hinders the transport to the central\
    \ system [1] \nalso encourages edge computing, or a decentralized solution, where\
    \ the processing of \ndata quality is done in the Perception Layer i.e. in the\
    \ sensor devices themselves and only \ndata with good quality is passed to the\
    \ central server. Since sensor data errors may be \npresent and propagated in\
    \ all layers, this review paper focuses on algorithms that solves \nthe fundamental\
    \ issue of sensor data quality by detecting and correcting those errors \nregardless\
    \ of the IoT (or big data) architecture and layers. As such, the high-level design\
    \ \nand decision of the IoT architecture is not discussed in this paper, however,\
    \ it is available \nin [5, 11–13].\nTherefore, the purpose of this systematic\
    \ review paper is to investigate the different \ntypes of sensor data errors which\
    \ contribute to the degradation of sensor data quality \nand the existing solutions\
    \ to detect and correct those errors which can be applied in any \nlayer of the\
    \ IoT architecture. The different domains the solutions are presented in and \n\
    the datasets used for evaluation are also studied. This systematic review acts\
    \ as an intro-\nduction for new researchers to the field of sensor data quality\
    \ or as a guide for research-\ners who are interested in the techniques used to\
    \ solve problems related to the sensor \ndata quality topic. In short, a systematic\
    \ review is a rigorous and structured way of con-\nducting a literature review\
    \ which allows it to be reproducible. It also helps researchers \nidentify knowledge\
    \ gaps in the area of interest by extracting and analysing existing solu-\ntions.\
    \ Other review papers about sensor data quality are present, such as the works\
    \ of \nLi et al. [14] and Prathiba et al. [15]. However, those review papers do\
    \ not mention the \nmethods used with respect to the different type of sensor\
    \ errors and are not systematic \nreviews.\nThis systematic review also focuses\
    \ on stationary wireless sensor networks. This \nis because many of the mobile\
    \ sensor network problems are related to network \nPage 4 of 49\nTeh et al. J\
    \ Big Data            (2020) 7:11 \nconnectivity issues rather than sensor data\
    \ quality. The field of imaging has also been \nexcluded as it is found that the\
    \ methods used to improve image data quality varies sig-\nnificantly compared\
    \ to other physical sensor data. The remainder of this paper is organ-\nized as\
    \ follows: “Research methodology” section describes the methodology used in the\
    \ \nsystematic review and the results from the review are provided in “Results”\
    \ section. A \ndiscussion about the challenges found in the research area is presented\
    \ in “Discussion” \nsection. Lastly, “Conclusion” section concludes the study.\n\
    Research methodology\nA systematic review is a standardized way of extracting\
    \ and synthesizing information \navailable from existing primary studies with\
    \ respect to a set of defined research ques-\ntions. It helps researchers focus\
    \ on the topic at hand and to identify knowledge gaps in \na research area. It\
    \ is frequently used in the field of medicine and though not as common \nin the\
    \ field of computer science [16], a systematic review is still applicable and\
    \ beneficial \nin terms of providing a formal way of conducting a computer science-related\
    \ literature \nreview.\nThe systematic review in this paper follows the guidelines\
    \ of Kofod-Petersen [16] and \nSilva and Neiva [17] for conducting a systematic\
    \ review in computer science-related \nfields. It is also done in accordance with\
    \ the PRISMA [18] (Preferred Reporting Items \nfor Systematic Reviews and Meta-Analyses)\
    \ checklist which is an “evidence-based \nminimum set of items for reporting in\
    \ systematic reviews and meta-analyses”. Since the \nPRISMA checklist is constructed\
    \ mostly for medical review literature, some of the items \nsuch as the meta-analyses\
    \ criteria are not considered in this review paper.\nThe systematic review process\
    \ is broken down to several steps, starting with the defi-\nnition of research\
    \ questions in which this paper aims to answer. Next, the search pro-\ncess and\
    \ strategy are described, which specifies the keywords and search string used\
    \ to \nfind the relevant and available publications literature databases. The\
    \ search strategy also \ninvolves a topic modelling step which was carried out\
    \ to help refine the keywords and \nsearch string. The inclusion and exclusion\
    \ criteria, as well as the quality criteria, are then \ndefined to assist with\
    \ the selection of relevant literature. Next, data extraction is carried \nout\
    \ which extracts data such as the title, abstract and publication year of the\
    \ literature as \nwell as the types of sensor errors addressed, types of methods\
    \ for detecting or correcting \nerrors and the domain from the selected studies\
    \ after screening which is then synthe-\nsized and presented in the next section,\
    \ “Results”. Finally, the risk of bias or limitations of \nthis review process\
    \ is discussed. The steps for the systematic review and its risk of bias \nare\
    \ described in detail in the following subsections.\nResearch questions\nThe motivation\
    \ for this systematic review is to provide new researchers an introduc-\ntion\
    \ to the field of sensor data quality and the errors that might occur, or as a\
    \ guide for \nresearchers who are interested in solving sensor data quality related\
    \ issues. Thus, the fol-\nlowing research questions (RQs) are designed in which\
    \ this paper aims to answer:\n• RQ1: What are the different types of errors in\
    \ sensor data?\n• RQ2: How to quantify or detect errors in sensor data?\nPage\
    \ 5 of 49\nTeh et al. J Big Data            (2020) 7:11 \n \n• RQ3: How to correct\
    \ the errors in sensor data?\n• RQ4: What domains are the different types of methods\
    \ proposed in?\nWith RQ1, we are able to investigate the common errors that leads\
    \ to the degradation \nof sensor data quality in this field. Moreover, RQ2 allows\
    \ us to find existing solutions to \nquantify or detect the aforementioned errors\
    \ and RQ3 takes it one step further by find-\ning techniques to correct them.\
    \ RQ4 on the other hand, gives an insight to how various \ndomains use different\
    \ (or similar) techniques to solve sensor data quality problems and \nthe datasets\
    \ used to evaluate the methods.\nSearch process\nFor this review paper, three\
    \ computer science-related literature databases are used to \nsearch for relevant\
    \ literature about sensor data quality. The three databases are:\n• ACM Digital\
    \ Library1\n• IEEE Xplore2\n• ScienceDirect3\nThese databases are last searched\
    \ on the September 27th 2018 and the search results \nare exported into BibTeX\
    \ format which is then downloaded and stored in the reference \nmanager Zotero.\
    \ 4 For ACM Digital Library, the export function for BibTeX format only \nexports\
    \ the citation data of the literature, but not the abstracts. Thus, Zotero’s Google\
    \ \nChrome plugin is used which allows the citation information, including the\
    \ abstract, to \nbe imported directly into Zotero.\nImproving search strategy\
    \ by topic modelling\nAt the start of the search process, the keywords defined\
    \ are “sensor data” and “data qual-\nity” which are used in the initial search\
    \ string:\nThe initial search results using query (1) returned 13,057 publications\
    \ from three data-\nbases, ACM Digital Library, IEEE Xplore, and ScienceDirect.\
    \ In order to check, if this \ninitial search query retrieves publications which\
    \ match the scope of this review, we are \nusing a text mining approach from natural\
    \ language processing known as topic mod-\nelling. Topic models are “probabilistic\
    \ models for uncovering the underlying semantic \nstructure of a document collection\
    \ based on a hierarchical Bayesian analysis of the origi-\nnal texts” [19, p.\
    \ 71]. The idea of the topic modelling step is to identify keywords and \ngroups\
    \ of keywords that describe the content of the initial set of publications returned\
    \ \nby search query (1). In order to do so, topic modelling via Latent Dirichlet\
    \ Allocation \n(LDA) [20] is used to find groups of words that are likely to occur\
    \ together and represent \n(1)\n“sensor data′′ AND (quality OR “data quality′′\
    \ OR “sensor data quality′′)\n1 https ://dl.acm.org.\n2 https ://ieeex plore .ieee.org/Xplor\
    \ e.\n3 https ://www.scien cedir ect.com.\n4 https ://www.zoter o.org.\nPage 6\
    \ of 49\nTeh et al. J Big Data            (2020) 7:11 \na specific topic. For\
    \ example, assume that the researcher decides to model three topics, \nnamed Topic\
    \ A, B, and C for convenience. After fitting, the LDA model assigns each \ndocument\
    \ the probability of it covering a specific topic, e.g. Document 1 has a 20% prob-\n\
    ability of being in Topic A, 75% being in Topic B and 5% being in Topic C. The\
    \ LDA \nlearns these topic models by going through each document and cluster words\
    \ that have a \nhigh likelihood of term co-occurrence. By analysing the words\
    \ that describe the cluster, \nthe researcher can then interpret the topic for\
    \ each cluster.\nHere, the LDA model is implemented using scikit-learn’s [21]\
    \ estimator Latent-\nDirichletAllocation. For the purpose of this analysis, the\
    \ title and abstract \nof the publications, which have been identified from search\
    \ query (1), are used for \nmodelling the underlying topics. The visualization\
    \ of the LDA model with 12 top-\nics obtained from the 13,057 documents (title\
    \ and abstracts) of search string (1) is \nshown in Fig.  2a with the intertopic\
    \ distance showing the marginal topic distribu-\ntion. Figure 2b–d lists the top\
    \ 30 most relevant terms for Topic 1, Topic 2 and Topic \nFig. 2 Topic modelling\
    \ with LDA. Topic model of 13,057 titles and abstracts found from the search string\
    \ 1. \nTopic modelling is performed using a LDA model with 12 topics: a intertopic\
    \ distance showing the marginal \ntopic distribution of each topic, b–d top 30\
    \ most relevant terms for Topic 1, 2 and 8 respectively, along with \nits estimated\
    \ term frequencies. Topic 1 and 2 have terms related to sensor and data, but Topic\
    \ 1 is more \nfocused on systems and applications whereas Topic 2 is associated\
    \ with methods and algorithms. Topic 8 \nconsists mostly of keywords related to\
    \ imaging and satellite imaging\nPage 7 of 49\nTeh et al. J Big Data         \
    \   (2020) 7:11 \n \n8 respectively. Topic 1 and Topic 2 both have top terms related\
    \ to sensor and data. \nHowever, Topic 1 seems to be more focused on systems and\
    \ applications, whereas \nTopic 2 is more related to methods and algorithms. Looking\
    \ at the top 30 keywords of \nTopic 8, one might classify that topic as “Imaging”\
    \ or “Satellite Imaging” since words \nsuch as “image”, “video”, “resolution”,\
    \ “camera”, “satellite” and “pixel” occur in that \ncluster. Through this topic\
    \ modelling step, it can be seen that there are a handful of \npapers related\
    \ to “imaging” in the initial search results. Because imaging is a topic we \n\
    do not want to focus on, we are using the terms of Topic 8 to refine the search\
    \ string \nand set them to be one of the exclusion criteria in this paper.\nThrough\
    \ the topic modelling, we decided that the field of imaging is not to be con-\n\
    sidered in this paper as the techniques used for improving image data quality\
    \ is very \ndifferent compared to other physical sensor data. It is made an exclusion\
    \ criterion \n(see “Inclusion and exclusion criteria”) and the final search string\
    \ used to search the \nliterature databases is defined as:\nHowever, readers interested\
    \ in that field of research can look at review papers [22–24] \nthat investigates\
    \ data quality in imaging, e.g. camera captured document images and \nhealthcare\
    \ imaging.\nInclusion and exclusion criteria\nThe eligibility criteria are criteria\
    \ used for screening and selecting relevant literature \nfrom the search results.\
    \ The eligibility criteria are composed of the inclusion and \nexclusion criteria.\
    \ As mentioned in “Introduction” section, this systematic review \nfocuses on\
    \ stationary wireless sensor networks as mobile sensor networks tend to \nlean\
    \ towards network connectivity issues. Moreover, the field of imaging is to be\
    \ \nexcluded as the techniques used for improving data quality for images vary\
    \ signifi-\ncantly from physical sensor data.\nInclusion criteria (IC): \nIC1\
    \ \n Papers that involve sensor data,\nIC2 \n Papers that mainly focus on data\
    \ quality of sensor data,\nIC3 \n Papers about stationary wireless sensor network,\n\
    IC4 \n Papers that consider different types of sensors.\n Exclusion criteria (EC):\
    \ \nEC1 \n Papers that are duplicates,\nEC2 \n Papers not in English,\nEC3 \n\
    \ Papers without methodology,\nEC4 \n Papers that are secondary studies (e.g.\
    \ survey, reviews, demos, posters, \ntutorials),\nEC5 \n Papers about imaging\
    \ (camera images, 3D images, video streams) or satellite \nimaging.\n(2)\nsensor\
    \ data AND (quality OR “data quality\" OR “sensor data quality\")\nAND NOT (“imaging\"\
    ) AND NOT (“satellite imaging\")\nPage 8 of 49\nTeh et al. J Big Data        \
    \    (2020) 7:11 \n Even though imaging-related publications are directly filtered\
    \ from the search query (2), \nEC5 is added as an exclusion criterion because\
    \ there are still publications with imag-\ning-related topics present in the result\
    \ obtained from the search. This is due to the use \nof the same search string\
    \ for all databases, which produces different results in different \ndatabases.\
    \ For example, in the substring “ ...AND NOT (“imaging”) ...” of search string\
    \ \n(2), ACM Digital Library removes all lemmatized terms related to “imaging”\
    \ e.g. images, \nimage, imaging but IEEE Xplore removes only the specified word\
    \ “imaging”.\nStudy quality assessment\nIn addition to the inclusion and exclusion\
    \ criteria, the quality criteria are defined to \nevaluate the quality of papers\
    \ selected after full-text screening. Using these criteria, the \nquality of the\
    \ selected literature can be assessed to see if they are fully appropriate for\
    \ \nthis systematic review, based on their importance with respect to answering\
    \ the research \nquestions. The following are the quality criteria (QC): \nQC1\
    \ \n Does the study contain validation?\nQC2 \n Does the study propose a way to\
    \ quantify/detect uncertainty?\nQC3 \n Does it propose a solution to correct the\
    \ uncertainty/erroneous data?\n The papers are scored according to whether they\
    \ are able to meet the above quality \ncriteria i.e. Yes, No, or Partially. The\
    \ scores are Yes = 1, No = 0 and Partially = 0.5. It is \nseen that 54 out of\
    \ 57 publications have a QC score of two or above and only three pub-\nlications [25–27]\
    \ have QC scores of one, which shows that the quality of the majority of \nthe\
    \ selected literature is of good quality and they are relevant to the systematic\
    \ review. \nThe three publications with a QC score of one are still included in\
    \ this systematic review \nas two of them are related to enterprise-level systems,\
    \ which gives an insight into how \nexisting methods are integrated into practice.\
    \ The third paper, which is one of the earli-\nest publications that presented\
    \ a PCA-based solution for sensor fault detection, is also \nincluded as it is\
    \ highly cited by other papers that proposed PCA-based methods.\nStudy selection\n\
    The initial search query (1) returned 13,057 publications. After the process of\
    \ topic mod-\nelling, the refined search query (2) resulted in 6970 publications.\
    \ The 6970 publications \nobtained from the three literature databases are then\
    \ screened to remove duplicates. \nThere are 107 duplicates which are removed.\
    \ Next, the duplicate-free set of papers are \nscreened based on their title and\
    \ abstract. Irrelevant papers, based on the inclusion and \nexclusion criteria,\
    \ are excluded and this resulted in the selection of 285 papers. Those \nscreened\
    \ papers are then read and evaluated in full-text to assess based on their abil-\n\
    ity and contribution to answering the research questions. About 228 papers are\
    \ consid-\nered irrelevant and are rejected and the other 57 papers that are eligible\
    \ are chosen to be \nincluded in the study.\nThe selection process is visualized\
    \ in Fig. 3 as a PRISMA flow diagram [28], showing \nthe number of papers obtained\
    \ from each stage of the review process i.e. search results, \nduplicate removal,\
    \ title and abstract screening, full-text screening, and final selected \npapers.\n\
    Page 9 of 49\nTeh et al. J Big Data            (2020) 7:11 \n \nData extraction\n\
    Data extraction is carried out for all 57 selected publications and the results\
    \ are tabu-\nlated using an Excel spreadsheet. The data extracted from the selected\
    \ literature are:\n• Title and abstract of literature,\n• Authors’ names,\n• Database,\n\
    • Publication year,\n• Types of sensor data errors addressed (RQ1),\n• Types of\
    \ methods for detecting or mitigating errors (RQ2 and RQ3),\n• The domain in which\
    \ the methods have been developed (RQ4).\nFig. 3 PRISMA flow diagram. Extended\
    \ PRISMA flow diagram visualizing the selection process starting from \nthe 13,057\
    \ publications from the initial topic model to the 6970 publications obtained\
    \ from search query (2) \nand the subsequent selection process resulting in the\
    \ final number of 57 considered publications\nPage 10 of 49\nTeh et al. J Big\
    \ Data            (2020) 7:11 \nData synthesis\nAfter the data extraction step,\
    \ the extracted data is analysed to answer the research ques-\ntions. For RQ1,\
    \ the definitions of the different types of errors addressed in the papers \n\
    were analysed as they might have been termed differently in different publications\
    \ but \nreferred to the same type of error (“Types of errors in sensor data”).\
    \ Once establishing \nthe definitions of each error, they are then classified\
    \ so that the errors with the same def-\ninition are in the same category. For\
    \ RQ2 and RQ3, the different types of methods pro-\nposed in the literature are\
    \ analysed and their state-of-the-art techniques are categorized \nand studied\
    \ (“Methods for detecting and quantifying errors in sensor data”, “Methods \n\
    for correcting errors in sensor data” and “Methods for detecting and correcting\
    \ errors \nin sensor data”). The extracted domains are extracted along with publicly\
    \ available data-\nsets used for method evaluation in those domains to answer\
    \ RQ4 (“Types of domains”). \nMoreover, for literature with validation, the evaluation\
    \ conditions and results of the \nmethods are also analysed to compare and identify\
    \ the gaps in knowledge (“Discussion”).\nRisk of bias\nThis systematic review\
    \ is not without bias. Firstly, there is a risk of bias in the review \nprocess\
    \ as only one reviewer screening the literature where the subjectivity of the\
    \ inclu-\nsion and exclusion criteria may affect the selection of relevant publications.\
    \ Moreover, \nthe year range was not specified during the search process. This\
    \ means that the search \nresults returned are from all available years, that\
    \ is from the earliest publication found \nin the respective databases until recently\
    \ (September 2018). The databases returned dif-\nferent earliest start years e.g.,\
    \ the earliest publication from ACM Digital Library is from \n1998, IEEE Xplore\
    \ is from 1979, and ScienceDirect is from 1995.\nFurthermore, there are publications\
    \ missed in the search process because the search \nwas done only on three databases,\
    \ and there are many more databases (e.g., Google \nScholar, Scopus, SpringerLink)\
    \ that might have other literature addressing the men-\ntioned sensor data quality\
    \ problems. Thus, this systematic review paper is not an exhaus-\ntive list of\
    \ methods available for detecting and correcting sensor data errors. Other than\
    \ \nthat, there was no snowballing done in this systematic review, i.e. the review\
    \ process \ndid not include searching and extracting information from the references\
    \ of the selected \npapers for the purposes of this systematic review.\nResults\n\
    This section presents the findings from the extracted data with respect to the\
    \ research \nquestions formulated in “Research questions” section. In “Types of\
    \ errors in sensor data” \nsection, RQ1 is addressed to discuss the different\
    \ types of errors that exist in sensor data \nwhich leads to the degradation of\
    \ sensor data quality. Next, in “Methods for detecting \nand quantifying errors\
    \ in sensor data”, “Methods for correcting errors in sensor data”, and \n“Methods\
    \ for detecting and correcting errors in sensor data” sections, RQ2 and RQ3 are\
    \ \nanswered with respect to the type of errors. The nomenclature in Table 1 is\
    \ used in those \nthree subsections. “Methods for detecting and quantifying errors\
    \ in sensor data” sec-\ntion addresses methods proposed only for fault detection\
    \ and uncertainty quantification \n(RQ2) and “Methods for correcting errors in\
    \ sensor data” section discusses solutions \nPage 11 of 49\nTeh et al. J Big Data\
    \            (2020) 7:11 \n \nfor missing data imputation and de-noising (RQ3).\
    \ As for methods that address both \nresearch questions simultaneously i.e. fault\
    \ detection and correction (RQ2 and RQ3), \nthe results are presented in “Methods\
    \ for detecting and correcting errors in sensor data” \nsection. This is followed\
    \ by “Types of domains” section where the domains in which the \nmethods are proposed\
    \ in (RQ4) are detailed.\nTypes of errors in sensor data\nAccording to the International\
    \ Standardization Organization (ISO) [29], an error is \ndefined as “the result\
    \ of a measurement minus the true value of the measurand”. There \nare several\
    \ types of errors related to sensor data quality. Table 2 shows the different\
    \ types \nof errors extracted from the selected literature (RQ1), along with the\
    \ papers that address \nTable 1 Nomenclature used for “Methods for detecting and\
    \ quantifying errors in sensor \ndata”,“Methods for correcting errors in sensor\
    \ data” and  “Methods for detecting and \ncorrecting errors in sensor data” sections\n\
    Depending on how the samples are obtained, the variables in sensor data vector\
    \ ⃗x might be produced by more than one \nsensor. For example, in environmental\
    \ monitoring, the data may be produced by several sensors, each measuring one\
    \ \nvariable e.g. temperature and humidity. On the other hand, some variables\
    \ are produced by one sensor alone, such as an \naccelerometer which produces\
    \ readings for three variables i.e. the acceleration in the direction x, y, and\
    \ z\nSymbol\nDescription\nxi(tj)\nMeasured data value xi of sensor i at a specific\
    \ point in time tj\nˆx\nEstimated sensor data value\n⃗x\nSensor data vector, where\
    \ \x1Fx = (x1, . . . , xi, . . . , xV) is a row vector obtained at the \nsame\
    \ point in time\nt\nTime in sensor data stream, e.g xt is the observed sensor\
    \ data value at time t\ni\nColumn index i = 1, . . . , V\nj\nRow index j = 1,\
    \ . . . , N\nf\nFeature\nq\nSize of moving window\nN\nNumber of samples\nV\nNumber\
    \ of variables e.g. temperature, humidity, voltage\nM\nNumber of sensor unit\n\
    F\nNumber of features\nZ\nSensor data stream in the form of a time series, Z =\n\
    \x1F\n. . . , \x1Ext−1, \x1Ext, \x1Ext+1, . . .\n\x1E\nX\nSensor data matrix where\
    \ X ∈ RN×V , X =\n\x1F\x1Ex1, . . . , \x1Exj, . . . , \x1ExN\n\x1E\nTable 2 Types\
    \ of  errors addressed, along  with  its respective papers and  total number \n\
    of papers that address that error\nType of error\nPapers\nTotal\nOutliers\n[7,\
    \ 30–60]\n32\nMissing data\n[7, 9, 25, 26, 31, 38, 46, 51, 61–68]\n16\nBias\n\
    [30–32, 41, 43, 59, 60, 69–73]\n12\nDrift\n[31, 32, 34, 35, 54, 60, 69, 70, 72–75]\n\
    12\nNoise\n[35, 52, 53, 72, 73, 75–77]\n8\nConstant value\n[30, 35, 52, 53, 72,\
    \ 73, 78]\n7\nUncertainty\n[25, 26, 68, 79–81]\n6\nStuck‑at‑zero\n[30, 32, 53,\
    \ 72, 73, 78]\n6\nPage 12 of 49\nTeh et al. J Big Data            (2020) 7:11\
    \ \nthem and the total number of papers. Note that some literature address different\
    \ types of \nerrors in the same paper, for example, [30–32] addressed both outliers\
    \ and bias in their \nproposed solution.\nThe type of error that is most commonly\
    \ addressed in publications related to sensor \ndata quality is outliers and is\
    \ addressed by 32 papers, which is more than half of the total \nnumber of selected\
    \ studies. Outliers, also known as anomalies [82] and spikes [36, 83], \nare values\
    \ that exceed thresholds or largely deviate from the normal behaviour provided\
    \ \nby the model. A sensor data measurement is also considered an outlier if it\
    \ is signif-\nicantly different from its previous and next observations or observations\
    \ from neigh-\nbouring sensor nodes [38, 45, 48]. Outliers are also known as faults,\
    \ though faults also \ninclude other types of errors such as bias, drifts, noise,\
    \ constant value, and stuck-at-zero. \nThough some papers [50, 55] might not have\
    \ specified the type of fault, most of them \nbreakdown the fault error to the\
    \ different types of errors as mentioned previously.\nThe second most commonly\
    \ found error in sensor data is missing data, which is \naddressed in 16 publications.\
    \ It is also known as incomplete data, and it is one of the \ndata quality (DQ)\
    \ dimensions introduced by Wang and Strong [4]. DQ dimensions cat-\negorize the\
    \ quality of data in databases that are important to data consumers. They are\
    \ \nmostly used to describe data in enterprise-level systems and are used for\
    \ modelling how \ndata errors propagate to the consumer’s end. However, apart\
    \ from incomplete (missing \ndata) and inaccurate data (uncertainty), which are\
    \ sensor data quality-related issues, \nother DQ dimensions such as inconsistent\
    \ data and timeliness are not considered in this \nreview paper as they are more\
    \ related to the topics of database design or communication \ndata quality. According\
    \ to Li and Parker [9], missing data is caused by various factors \nsuch as unstable\
    \ wireless connection due to network congestion, sensor device outages \ndue to\
    \ its limited battery life, environmental interferences e.g. human blockage, walls,\
    \ \nand weather conditions, and malicious attacks. There are cases where sensor\
    \ data is \nmissing for extended periods of time, which might lead to incorrect\
    \ decision making on \nthe consumer side. Though the simplest way to solve this\
    \ problem is to re-transmit the \ndata, most IoT applications are in real-time,\
    \ which would render the data useless if there \nis a delay. Besides that, the\
    \ computational and energy cost causes it to be inefficient as \nthese sensor\
    \ devices are usually limited in terms of battery, memory, and computational \n\
    resources.\nBias, also known as an offset, is a fault with a constant offset or\
    \ as Rabatel et al. [84] \ndefines, “a value that is shifted in comparison with\
    \ the normal behaviour of a sensor”. \nThis type of error would usually require\
    \ calibration to subtract the offset from the \nobserved reading to get its true\
    \ value. Drifts are readings that deviate from its true value \nover time due\
    \ to the degradation of sensing material which is an irreversible chemi-\ncal\
    \ reaction [60] whereas constant values are readings with a constant value over\
    \ time, \nthough it might belong to a normal range. It is usually caused by a\
    \ faulty sensor or trans-\nmission problems [84]. Another type of fault is a stuck-at-zero\
    \ or dead sensor fault. As \nits name implies, it refers to values that are constantly\
    \ at zero over an extended period \nof time. Lastly, noise is also a type of fault,\
    \ and they are small variations in the data-\nset. Noise is similar to uncertainty,\
    \ which is another type of error and DQ dimension. \nAccording to the ISO [29],\
    \ the definition of uncertainty is, “a parameter, associated with \nthe result\
    \ of a measurement, that characterizes the dispersion of the values that could\
    \ \nPage 13 of 49\nTeh et al. J Big Data            (2020) 7:11 \n \nreasonably\
    \ be attributed to the measurement”. Thus, uncertainty can also be seen as the\
    \ \nquantification of an error in statistical terms. Moreover, Mansouri et al.\
    \ [47] states that \nsensor data uncertainty includes “measurement noise, sensor\
    \ imprecision and variabil-\nity of measured quantity”. According to that definition,\
    \ noise contributes to uncertainty. \nHowever, the methods of correcting those\
    \ two errors are relatively different where noise \ncorrection techniques mostly\
    \ includes signal processing solutions whereas uncertainty \nquantification and\
    \ correction involves ontology-based methods (refer to “Methods for \ndetecting\
    \ and quantifying errors in sensor data”, “Methods for correcting errors in sen-\n\
    sor data” and “Methods for detecting and correcting errors in sensor data” sections).\n\
    Methods for detecting and quantifying errors in sensor data\nMost solutions suggest\
    \ ways to quantify or detect errors in existing literature either address \nthe\
    \ detection of faults i.e. outliers, bias, drifts, constant values, or to quantify\
    \ the uncertainty \nin the sensor data. These publications only address the problem\
    \ of detecting those errors, \nbut not correcting them. There are 32 publications\
    \ that proposed methods to solve this \nproblem, which is 56% of the total number\
    \ of selected literature. Table 3 obtained from the \ndata extraction process\
    \ of the 32 papers shows the different existing methods to quantify \nor detect\
    \ sensor data errors (RQ2), along with the errors addressed, the respective papers\
    \ \nthat presented the method and the total number of papers. It can be seen that\
    \ the three \nmost common approaches are principal component analysis, artificial\
    \ neural network and \nEnsemble Classifiers, which constitutes more than half\
    \ of the reviewed publications which \nTable 3 Types of  methods addressing error\
    \ detection and  quantification (RQ2) only, \nalong  with  its addressed errors,\
    \ respective papers, and  the  total number of  papers \nthat proposed that method\n\
    Method\nErrors addressed\nPapers\nTotal\nPrincipal component analysis\nOutliers,\
    \ bias, drift, stuck‑at‑zero\n[27, 32, 47, 48, 50, 59, 69]\n7\nArtificial neural\
    \ network\nOutliers, bias, drift, constant values, \nnoise, stuck‑at‑zero, uncertainty\n\
    [34, 36, 54, 70, 78, 81]\n6\nEnsemble classifiers\nOutliers, drift, constant values,\
    \ noise, \nuncertainty\n[33, 35, 37, 79]\n4\nSupport vector machine\nOutliers\n\
    [57, 58]\n2\nClustering\nOutliers\n[39, 45]\n2\nOntology/knowledge‑based systems\n\
    Uncertainty (inaccurate data), missing \ndata (incomplete data)\n[25, 26]\n2\n\
    Univariate autoregressive models\nOutliers\n[40]\n1\nStatistical generative models\n\
    Outliers\n[49]\n1\nGrey prediction model\nOutliers, noise, constant values\n[52]\n\
    1\nParticle filtering\nBias, scaling\n[71]\n1\nAssociation rule mining\nOutliers\n\
    [56]\n1\nBayesian network\nOutliers, noise\n[44]\n1\nEuclidean distance\nOutliers\n\
    [42]\n1\nHybrid methods\n Polynomial predictive filter and fuzzy \nrules\nOutliers\n\
    [53]\n1\n Dempster–Shafer theory and math‑\nematical modelling\nDrift, noise\n\
    [75]\n1\nPage 14 of 49\nTeh et al. J Big Data            (2020) 7:11 \nproposed\
    \ error detection and quantification methods, with 7, 6 and 4 papers proposing\
    \ \nthose methods respectively. There are also hybrid approaches, which incorporates\
    \ more \nthan one type of method in detecting sensor data errors. The following\
    \ is a brief overview \nof each method, where “Anomaly/fault detection” section\
    \ discusses methods for detecting \nanomalies or faults in the sensor data and\
    \ “Uncertainty quantification” section presents \napproaches for quantifying the\
    \ quality of the data.\nAnomaly/fault detection\nFirstly, to detect faults, several\
    \ methods such as statistical and machine learning, clustering, \nontology, and\
    \ hybrid approaches have been suggested.\nPrincipal component analysis (PCA) Principal\
    \ component analysis (PCA) [27] is com-\nmonly used to find patterns in the data\
    \ i.e. the correlation between variables, by gener-\nating orthogonal principal\
    \ components. Therefore, other than being used as a feature \nreduction technique,\
    \ PCA can also be used for fault detection. In sensor data matrix X \nwith N rows\
    \ (measurements at different points in time) and V columns (measurement of \n\
    different sensors), PCA is done by firstly standardizing the matrix X if the variables\
    \ are \nof different units of measurements (e.g. oC , lux, km/h) or if each variable\
    \ is to receive \nequal weight in the analysis. To standardize the matrix, each\
    \ data point xj,i of matrix X \nis subtracted by the mean of the respective column\
    \ µi and the differences (xj,i − µi) are \ndivided by the column’s standard deviation\
    \ σi . This process is known as whitening in sta-\ntistics. Next, the covariance\
    \ matrix XTX , which quantifies the correlation between each \nof the variables,\
    \ is calculated by multiplying the transpose of the standardized sensor data \n\
    matrix with itself. The eigenvectors and their corresponding eigenvalues of the\
    \ covari-\nance matrix are calculated [85, Chap 11], which produces two matrices:\
    \ P , which is the \nmodal matrix where the columns are eigenvectors and D = P−1XTXP\
    \ , which is the spec-\ntral matrix where the diagonal elements are the eigenvalues.\
    \ The pairs of eigenvalues and \neigenvectors are sorted from largest to smallest\
    \ eigenvalue, such that the first eigenvector \n(or principal component) accounts\
    \ for the largest amount of variance, which is given by \nthe corresponding eigenvalue.\
    \ The orthogonal transformation\nconverts the sensor data matrix X into a set\
    \ of values from linearly uncorrelated vari-\nables, the so-called principal components.\
    \ The top few principal components capture \nmost of the variability in the dataset.\
    \ This is also how it is used as a dimension-reduction \ntechnique, because it\
    \ projects the dataset into a lower-dimensional subspace.\nFollowing the steps\
    \ for PCA, two orthogonal projection subspaces are obtained from \nthe selection\
    \ of the top few principal components and the standardized data matrix X \ncan\
    \ then be decomposed into the following:\nwhere ˆX is the principal component\
    \ subspace which is the modelled variations of X \nand includes the signal in\
    \ the dataset, containing the first l eigenvectors i.e. the first \nl columns\
    \ of P (where l is the number of selected principal components) and E is the \n\
    T = XP\nX = ˆX + E ,\nPage 15 of 49\nTeh et al. J Big Data            (2020) 7:11\
    \ \n \nunmodelled variations of X , also known as the residual matrix which includes\
    \ mainly \nnoise and useless information and consist of the last V − l columns\
    \ of P . They are repre-\nsented as the following:\nwhere C = PPT and similarly,\n\
    Therefore, a new sample vector, ⃗x can be projected into the principal component\
    \ \nsubspace:\nand into the residual subspace:\nC and (I − C) are also known as\
    \ the model projection matrix and residual projection \nmatrix respectively. Fault\
    \ detection can be done by monitoring the residual subspace of \nthe PCA as it\
    \ increases in magnitude when there is a change in the correlation among \nthe\
    \ variables in x. The squared prediction error, also known as Q-statistic, defined\
    \ as:\nwhere Qa is the Q-statistic threshold. Details on how to obtain Qa is found\
    \ in [32, 42, 69].\nDunia et al. [27] proposed a Sensor Validation Index (SVI)\
    \ as a means for fault detec-\ntion and isolation (identifying faulty sensors)\
    \ through an iterative reconstruction process \nthat assumes each sensor fails,\
    \ reconstructs the faulty sensor and compare the Q-statis-\ntics before and after\
    \ reconstruction. The SVI, which ranges from 0 to 1, shows that when \na sensor\
    \ is faulty, it is close to zero and vice versa. Alawi et al. [69], on the other\
    \ hand, \nintroduced a combined contributions index using the Q-statistics, which\
    \ measures the \nvariance of random noise in the residual subspace and Hotelling’s\
    \ T 2-statistics, which \nrepresents the variance in the model subspace. This\
    \ is because an occurrence of a fault \n(bias and constant value mentioned in\
    \ this paper) usually leads to changes in either sta-\ntistical metric.\nRassam\
    \ et al. [48] proposed a variation of PCA called the One-Class Principal Com-\n\
    ponent Classifier for local and unsupervised anomaly detection. The approach is\
    \ divided \ninto two parts, with the first being the offline training phase which\
    \ trains a PCA model \nusing normal data collected from each sensor to build the\
    \ normal behaviour model and \nit is stored locally in each sensor node. The dissimilarity\
    \ measure is calculated using \nthe sum of squares of the normalized principal\
    \ components, and this represents the \nˆX = TPT\nℓ =\nl\n\x1F\ni=1\ntipT\ni =\
    \ XC ,\nE = TePT\ne =\nV\n\x1F\ni=l+1\ntipT\ni .\n\x1Fx = ˆ\x1Fx + \x1Fe\nˆ\x1F\
    x = \x1FxPPT = \x1FxC\n\x1Fe = \x1Fx − ˆ\x1Fx ,\n\x1Fe = \x1Fx − \x1FxPPT = \x1F\
    x(I − C).\nQ = ||\x1De||2 < Qa ,\nPage 16 of 49\nTeh et al. J Big Data       \
    \     (2020) 7:11 \nmaximum and minimum thresholds for anomaly detection. The\
    \ second phase is the \nonline detection phase where current observations would\
    \ be projected into the fea-\nture subspace and compared with normal behaviour\
    \ model based on its the dissimilar-\nity matrix. The normal PCA model is also\
    \ updated and retrained with new mean and \nstandard deviation of the new data.\
    \ In order to deal with non-linear systems, Sharifi and \nLangari  [50], suggested\
    \ a Mixture Probabilistic PCA model for fault diagnosis which \nseparates the\
    \ input space into several local linear regions and subsequently has linear \n\
    sensor fault diagnosis applied to each linear region.\nMoreover, Zhao and Fu [59]\
    \ have also proposed a sensor fault detection for outliers \nand bias using PCA\
    \ by modelling the normal behaviour for continuous glucose moni-\ntoring applications.\
    \ Harkat et al. [32] also applied the PCA technique to detect outliers, \ndrifts,\
    \ bias, stuck-at-zero faults. However, rather than just using the SVI [27], a\
    \ test on \nthe sum of squares of the residual matrix, i.e. the last (V − l) principal\
    \ components is \ndone to detect faults. Recently, Mansouri et al. [47] came up\
    \ with another variation of \nPCA called the Midpoint-radii PCA for fault detection.\
    \ The Midpoint-radii PCA allows \ninterval-valued data, which considers the uncertainty\
    \ in the data, to be modelled.\nPCA is a powerful technique used for many applications,\
    \ including fault detection in \nwhich 7 out of 32 methods proposed are based\
    \ on. It can be adapted to multiple varia-\ntions, which have their own advantages\
    \ such as the One-Class PCA classifier, which is \nable to perform locally with\
    \ no extra communication overhead, making it suitable for \nEdge Computing applications.\
    \ However, PCA requires fault-free training data which is \nrare and difficult\
    \ to obtain. There is also a need to choose the optimal number of princi-\npal\
    \ components, which differs from one application to another.\nArtificial neural\
    \ network An artificial neural network (ANN) is a framework that is \nvaguely\
    \ modelled upon the biological neural network of a brain. It is mainly used to\
    \ learn \npatterns or models from complex processes such as pattern recognition.\
    \ ANNs consist of \na densely interconnected set of neurons, also known as perceptrons,\
    \ whereby each unit \ntakes several real-valued inputs (combined using an input\
    \ function), runs it through its \nactivation function e.g. linear, sigmoid and\
    \ rectified linear unit, and produces a single \nreal-valued output. Each input\
    \ has a weight related to it, which determines the contri-\nbution of the inputs\
    \ to the output. Learning the weights of the input values such that it \nproduces\
    \ the correct output value is the basis that trains an ANN to learn. There are\
    \ also \nmany ways of doing so, such as the perceptron rule for linearly-separable\
    \ datasets, gradi-\nent descent for non-linear datasets and backpropagation.\n\
    Jäger et al. [78] introduced a framework to detect four different types of fault:\
    \ outliers, \noffset, noise and stuck-at-zero, using a supervised time-delay neural\
    \ network (TDNN). \nIt is a type of multi-layer feed-forward ANN that allows the\
    \ mapping between past and \npresent values by analysing the sliding windows of\
    \ a signal. The difference between \nTDNN and the classic multilayer perceptron\
    \ is that the neurons receive not only the \noutput from the neurons below but\
    \ also the delayed (past) outputs of those neurons. \nHowever, it is seen that\
    \ TDNN is only able to detect 2 out of the 4 fault types reliably, \nnamely the\
    \ offset and stuck-at-zero. Bosman et al. [36] proposed a decentralized learn-\n\
    ing approach for fault detection i.e. for anomalies such as outliers, drift, noise,\
    \ and con-\nstant values, which learns the normal sensor behaviour model in each\
    \ sensor node, while \nPage 17 of 49\nTeh et al. J Big Data            (2020)\
    \ 7:11 \n \nincorporating neighbourhood information. The approach uses Recursive\
    \ Least Squares \nto learn linear models and so-called Extreme Learning Machines\
    \ (see “Artificial neural \nnetwork” section) for learning non-linear models.\n\
    Smarsly and Law [70] suggested a decentralized fault detection and isolation software\
    \ \npackage framework for bias and drifts using backpropagation feedforward neural\
    \ net-\nwork, which is embedded in each wireless sensor nodes of the system. Once\
    \ again, the \nNeural Network learns the normal behaviour model of the system\
    \ and outputs an esti-\nmated value in which the current observed value will be\
    \ compared against and detected \nif it is anomalous. Xiao et al. [54], on the\
    \ other hand, introduced an Auto-associative \nNeural Network (AANN) solution\
    \ for fault detection and prognosis for outliers and \ndrifts. AANN is a feedforward\
    \ neural network with an odd number of hidden layers that \nare used to produce\
    \ an approximation of the identity mapping between input and output \nlayers (auto-encoder)\
    \ [86]. It has a bottleneck hidden layer which compresses informa-\ntion, which\
    \ forces it to eliminate redundancy and capture the input patterns. The faults\
    \ \nare detected using shallow and deep AANN, and the prognosis is done using\
    \ Autore-\ngressive Moving Average.\nAhmad et  al.  [34] proposed a framework\
    \ for anomaly detection using hierarchical \ntemporal memory (HTM), a type of\
    \ unsupervised artificial intelligence learning method \nbased on neuroscience\
    \ research. It is similar to an artificial neural network, but unlike \nmost neural\
    \ networks, HTM can learn time-based patterns in an unlabeled data stream. \n\
    It is firstly described in the book “On Intelligence” by Hawkins and Blakeslee\
    \ [87] in 2004 \nand has since been continuously developed by his company, Numenta [88].\
    \ Numenta \nalso provides an open-source anomaly detection benchmark, numenta\
    \ anomaly bench-\nmark (NAB) for evaluating anomaly detection algorithms in real-world\
    \ streaming data \nwhich consists of labelled anomalies. The steps of a HTM is\
    \ seen in Fig. 4, where the \ninput of the data stream, ⃗xt which is an observed\
    \ data vector at time t is sent to the HTM \nsystem. Then, the HTM returns a sparse\
    \ binary vector representing the current input, \n⃗a(⃗xt) and the prediction for\
    \ the next time step, ⃗π(⃗xt) , which is the estimation of \x1Fa(\x1Fxt+1) \n\
    in sparse binary vector form. The prediction error, st is calculated and the probabilistic\
    \ \nmodel of it is used to compute the likelihood of the data being an anomaly,\
    \ Lt.\nAlong with PCA, ANN is also another common technique for fault detection\
    \ and it \nalso has multiple variations such as TDNN, AANN and HTM. There are\
    \ 6 out of 32 \npapers that have presented an ANN-based approach, which has its\
    \ own pros and cons. \nThe advantages and disadvantages depend heavily on the\
    \ type of Neural Network \napplied. For example, TDNN has several disadvantages\
    \ such as not being able to detect \nFig. 4 Framework of HTM for anomaly detection\
    \ [34, Fig 3(a)] Input vector ⃗xt of the data stream is sent to \nthe HTM where\
    \ it produces a sparse binary vector representing the current input, a(⃗xt) and\
    \ prediction for \nthe next time step, ⃗π(⃗xt) . The prediction error, st is calculated\
    \ and is used to obtain the anomaly likelihood, Lt . \nImage obtained under the\
    \ Creative Commons license. No revisions were made to the image. \nPage 18 of\
    \ 49\nTeh et al. J Big Data            (2020) 7:11 \nnoise and outliers reliably\
    \ and requires many parameter decisions, whereas AANN is \nrobust against training\
    \ data with missing values.\nEnsemble classifiers Ensemble learning use multiple\
    \ machine learning classifiers to \narrive at a better predictive performance\
    \ compared to when using those algorithms \nindividually by aggregating the results\
    \ of the classifiers. Bosman et al. [35] proposed a \ndecentralized, online fault\
    \ detection for anomalies, drifts, noise and constant value using \nensemble classifiers\
    \ where each classifier will learn a normal behaviour model and com-\npare it\
    \ with the current reading to identify if it is an anomaly. The results are then\
    \ aggre-\ngated using simple heuristic rules or applying algebraic combiners e.g.\
    \ median or Fisher’s \nmethod [89]. The classifiers mentioned in the paper are\
    \ Sliding Window Mean, Recur-\nsive Least Squares, Extreme Learning Machines,\
    \ Polynomial Function Approximation. \nCuriac and Volosencu [37] also suggested\
    \ an anomaly detection technique using ensem-\nble-based classifiers which models\
    \ the normal behaviour of the sensors whose votes (if a \nsensor reading is anomalous\
    \ or not as compared with the normal behaviour model) are \nthen collected and\
    \ aggregated. The types of classifiers used in the paper are the Average-\nbased\
    \ classifier, Auto-Regressive Linear Predictor-based classifier, Neural Network-based\
    \ \nclassifier, Neural Network Auto-Regressive Predictor-based classifier and\
    \ the Adaptive \nNeuro-Fuzzy Inference System-based classifier.\nAbuaitah and\
    \ Wang  [33] introduced a distributed anomaly detection framework \nto detect\
    \ anomalies using feature extraction and classification algorithms. The feature\
    \ \nextraction is carried out on the child nodes, which incrementally learns new\
    \ statistical \nsummaries. The features proposed that can be useful to detect\
    \ anomalies are mean, vari-\nance, rate of change, spatial distance, temporal\
    \ and spatial correlations. The statistical \nsummaries are then sent to the base\
    \ station (parent node) instead of raw data. There, \na classification algorithm\
    \ such as AdaBoost, Support Vector Machines or simple deci-\nsion trees is applied\
    \ to the set of feature vectors received from child nodes. The study \nshowed\
    \ that AdaBoost performs the best (lowest false positives and negatives) for anom-\n\
    aly detection in their case study. Adaboost converts a collection of weak classifiers\
    \ (error \nrate slightly better than random guessing) into a strong one by the\
    \ weighted combina-\ntion of the weak classifiers. During classification, the\
    \ child node is labelled as “normal” \nor “misbehaving”, and the parent nodes\
    \ will stop using data from “misbehaving” child \nnodes.\nEnsemble classifier\
    \ is a supervised method and though it mostly achieves better pre-\ndictive performance\
    \ than its individual classifiers, it is a complex task to build an ensem-\nble\
    \ classifier. This is due to the need to choose suitable base classifiers, which\
    \ may be \ndifficult and complicated, depending on the type of application. Also,\
    \ based on the indi-\nvidual classifiers chosen, some may require feature extraction\
    \ and fault-free training \nexamples. Large datasets are also needed to train\
    \ the supervised classifiers.\nSupport vector machine A support vector machine\
    \ (SVM) is a machine learning \nalgorithm that aims to find a hyperplane to separate\
    \ and classify the data points in an \nF-dimensional space, where F is the number\
    \ of features. The features are obtained either \ndirectly as the variables themselves,\
    \ or via a process called feature engineering, which \nproduces new features based\
    \ on the data and its set of variables. The hyperplane (a line in \nPage 19 of\
    \ 49\nTeh et al. J Big Data            (2020) 7:11 \n \n2D, a plane in 3D, and\
    \ so on) is a decision boundary in which data points on one side of \nthe hyperplane\
    \ belong to one class, and data points on the other side belong to another \n\
    class. The objective is to find a hyperplane that has the widest margin, i.e.\
    \ the maximum \ndistance between the two data points from the two different classes.\
    \ Support vectors \nare data points that are close to the hyperplane and they\
    \ are the data points that deter-\nmine the hyperplane by maximizing the margin\
    \ of the classifier. For anomaly detection, \nthe decision boundary or hyperplane\
    \ of the normal data is found such that it encom-\npasses most of the data in\
    \ the feature space. Then, newly observed data that fall out of the \nboundary\
    \ are classified as outliers.\nIn 2009, Zhang et al. [57] proposed an online outlier\
    \ detection technique using One-\nClass (unsupervised) Centered Quarter-Sphere\
    \ SVM which updates the normal behav-\niour model of the sensed data based on\
    \ three time windows. The quadratic optimization \nproblem of modelling the SVM\
    \ is converted into a linear optimization problem by fixing \nthe center of the\
    \ mapped data at the origin in the feature space. Here, the data vectors \n⃗x\
    \ in sensor data matrix X is mapped into a feature space using a non-linear mapping\
    \ \nfunction such as PCA, which returns the top few principal components that\
    \ can be used \nas features. Other than that, a Python package for feature engineering\
    \ and selection, \ntsfresh [90] can also be used to obtain time series features.\
    \ The normal behaviour at \neach time window is learned using One-Class Centered\
    \ Quarter-Sphere SVM to find the \nminimum radius (hyperplane), which helps detect\
    \ temporal anomalies. Then, the radius \nis broadcasted to all spatially neighbouring\
    \ nodes i.e. sensor nodes that are within com-\nmunication range, and the median\
    \ radius is calculated. The online characteristic allows \nthe data can be checked\
    \ against other neighbouring nodes to identify if the temporal \nanomaly is also\
    \ spatially anomalous, thus confirming the detection of an actual anomaly.\nIn\
    \ 2013, Zhang et al. [58] presented another type of SVM called the One-Class Cen-\n\
    tered Hyper-Ellipsoidal SVM for anomaly detection. The difference between the\
    \ Quar-\nter-Sphere and Hyper-Ellipsoidal SVM is that the former uses Euclidean\
    \ distance as a \ndistance measure, whereas the latter uses the Mahalanobis distance\
    \ to model the SVM. \nThose two types of distance measures are commonly used to\
    \ measure the similarity of \nthe data points. However, the Euclidean distance\
    \ does not take into account the correla-\ntion between variables and only calculates\
    \ the distance in terms of individual variables. \nOn the other hand, the Mahalanobis\
    \ distance takes into account the correlation between \nvariables and calculates\
    \ the distance by combining all variables together, forming a \ncovariance matrix.\
    \ It is also scale-insensitive, but it comes with a higher computational \ncomplexity\
    \ compared to Euclidean distance. The two variations of SVM are unsuper-\nvised,\
    \ adaptive and distributed.\nClustering Clustering is an unsupervised technique\
    \ for fault detection which has the \nadvantage of not requiring prior knowledge\
    \ of the system model or underlying data dis-\ntribution. However, the optimal\
    \ number of clusters or cluster width has to be determined \nby the user. One\
    \ of the clustering-based outlier detection technique is proposed by Fawzy \n\
    et al. [39] for WSNs. The algorithm uses an in-network fixed-width clustering\
    \ algorithm \nalong with nearest neighbor and timestamps which helps to identify\
    \ if it is an erroneous \ndata or an actual event. It consists of a few steps,\
    \ starting with pre-processing, where the \nfixed-width clustering algorithm is\
    \ applied to the dataset to separate and group the data. \nPage 20 of 49\nTeh et al.\
    \ J Big Data            (2020) 7:11 \nIn the fixed-width clustering algorithm,\
    \ each data point is assigned to a cluster and the \ndata point is within a pre-defined\
    \ distance from the cluster’s center. If there is no such \ncluster, then a new\
    \ cluster is created with that data point being its center. Next, the outlier\
    \ \ndetection step labels each cluster formed as “normal” or “outlier”. This is\
    \ done by calculat-\ning the Euclidean distance between one cluster to the other\
    \ clusters. A cluster is detected \nas an outlier if its average inter-cluster\
    \ distance is more than one standard deviation away \nfrom the mean inter-cluster\
    \ distance. The data points in the outlier clusters are then fur-\nther examined\
    \ by looking at the neighbouring nodes and timestamps to see if those data \n\
    points are events or actual anomalies.\nLiu et al. [45] presented another example\
    \ of the clustering method used for outlier \ndetection using Time-Relevant k-Means\
    \ clustering for electric power sensor data. The \nk-means clustering algorithm\
    \ is used to form initial clusters. The k-means algorithm can \nbe done in the\
    \ following steps, for an input k, which is the user-defined number of clus-\n\
    ters and a dataset, X = { \x1Dx1, \x1Dx2, . . . , \x1D\nxN} where N is the number\
    \ of samples: \n1. Set centroids (centers of clusters), c1, c2, . . . , ck at\
    \ random locations.\n2. Repeat until convergence: \n(a) For each sample ⃗xj ,\
    \ assign the sample to the cluster, s with the nearest centroid, \ncs : \n where\
    \ D is the distance function.\n(b) Update the centroids of each cluster cs , where\
    \ s = 1, . . . , k after adding the new \nsample in the cluster: \n where ns is\
    \ the number of points in that cluster s.\n3. Stop when none of the cluster assignments\
    \ change, i.e. converge.\nIn order to choose the appropriate k number of clusters,\
    \ the quality of the clusters is \nmeasured by the Mean Index Adequacy, which\
    \ calculates the average distance between \nthe cluster center and all the other\
    \ data points in that cluster. The smaller the Mean \nIndex Adequacy, the better\
    \ the clustering results. After performing k-means clustering \nusing the appropriate\
    \ number of clusters, the data within each cluster are re-clustered \naccording\
    \ to the temporal attribute of the data. Outliers are then detected by comparing\
    \ \nthe current value with the minimum and maximum data value from each refined\
    \ cluster. \nAn outlier correction method is also considered in that framework,\
    \ though it is by sim-\nple statistical approaches such as imputing the erroneous\
    \ data using the mean, median \nand mode values.\nUnivariate autoregressive models\
    \ A univariate autoregressive model is a time series \nmodel which, using sensor\
    \ measurements from the previous time step in a moving win-\narg min\ns\nD( ⃗xj,\
    \ cs) ,\ncs = 1\nns\nns\n\x1F\nj=1\n\x1Exj ,\nPage 21 of 49\nTeh et al. J Big\
    \ Data            (2020) 7:11 \n \ndow, Z = {xt−q+1, . . . , xt} as input, predicts\
    \ the value at the next time step, ˆxt+1 . Hill and \nMinsker [40] proposed an\
    \ anomaly detection technique using univariate autoregressive \nmodels to model\
    \ environmental data streams. The different models used and compared \nare the\
    \ nearest cluster, single-layer linear network, and multilayer perceptron. The\
    \ near-\nest cluster estimates the next value as the average of k most similar\
    \ (based on Euclidean \ndistance) sensor measurements in the dataset, whereas\
    \ the single-layer linear network \npredicts the next value based on the linear\
    \ combination of the q previous measurements. \nAfter the predictive modelling,\
    \ the next sensor data observation can be classified as \nanomalous by comparing\
    \ it with the threshold calculated by the prediction interval value. \nThough\
    \ it is found that the multilayer perceptron works best in their case study, it\
    \ might \nnot be the case for other applications.\nStatistical generative models\
    \ Statistical generative models are probabilistic models that \nattempt to describe\
    \ how data is generated by learning the statistical distribution of the \ndataset.\
    \ For anomaly detection, Sallans et al. [49] presented a statistical generative\
    \ mod-\nelling technique in which new observations will be compared against, and\
    \ if that new \nobservation has a low probability in that model, then it is counted\
    \ as anomalous. Exam-\nples of statistical generative models used in the paper\
    \ are the Gaussian model, Hidden \nMarkov model, and Histogram.\nGrey prediction\
    \ model Grey systems theory, initially proposed by Deng [91] in 1982, is \ndeveloped\
    \ to cope with the uncertainty of a system and has the advantage of being able\
    \ to \nmodel a discrete time series with a small sample size. It does not require\
    \ prior knowledge \nof the underlying data distribution and requires only a small\
    \ set of training data. In grey \nsystems, some part of the information is known\
    \ and some part is unknown, thus having \nincomplete information. The subsequence\
    \ of the original time series data Z helps predict \nthe future value and can\
    \ be defined as:\nwhere Z(0) consist of the q subsequent observed values up to\
    \ time t and c is a constant \nthat satisfies x(0)(u) + c ≥ 0.\nThe original subsequence\
    \ is firstly smoothed by an accumulate generating operation \n(AGO). The first-order\
    \ AGO is defined as:\nThe data series obtained after AGO smoothing can be modelled\
    \ by a simple first-order \ndifferential equation to give a grey system model\
    \ GM(1,1). The grey differential equation \nis as follows:\nwhere a and b are\
    \ parameters and z(1)(u) is the adjacent mean generating operation. \nThe papers\
    \ [30, 52, 60] provide detailed explanation on how to derive the differential\
    \ \nZ(0) = {x(0)(u) + c}, u = t − q + 1, t − q + 2, . . . , t; t ≥ q; q ≥ 3 ,\n\
    Z(1) = {x(1)(u)} =\n\x1F\nu\n\x1E\ni=t−q+1\nx(0)(i)\n\x1D\n, u = t − q + 1, t\
    \ − q + 2, . . . , t; t ≥ q.\ndx(1)(u)\ndu\n+ az(1)(u) = b\nPage 22 of 49\nTeh et al.\
    \ J Big Data            (2020) 7:11 \nequation. Tsang [52] introduced a sensor\
    \ data validation technique involving outliers, \nnoise and constant values using\
    \ grey models where sensor values are compared to the \npredicted value of the\
    \ grey model. The parameters, a and b of the GM(1,1) model is esti-\nmated using\
    \ the recursive orthogonal least-squares estimation algorithm.\nParticle filtering\
    \ Particle filtering is a state estimation technique given partial and noisy \n\
    observations in a dynamic system. It is a Monte Carlo algorithm which uses a set\
    \ of sam-\nples called particles, to represent the posterior probability distribution\
    \ of a stochastic \nprocess. Essentially, the samples from the distribution are\
    \ rendered as particles and each \nparticle has a weight assigned to it that represents\
    \ the probability of drawing that particle \nsuch that it is close to the actual\
    \ observed value. It is thus able to model non-linear or \nnon-Gaussian data.\n\
    Tadić and Ðurović [71] proposed a sensor fault diagnosis technique for bias and\
    \ scal-\ning errors using particle filtering. Particle filtering is used to estimate\
    \ the states of the \nnon-linear model, and new observations are compared with\
    \ the estimated particle to \ndetect whether it is a calibration (bias and scaling)\
    \ fault. This is done by calculating the \nresiduals, which is the difference\
    \ between the particle filter’s estimate and the current \nobserved data and a\
    \ fault is detected if it is more than a user-specified threshold, since \nthe\
    \ residuals are expected to stay close to zero.\nAssociation rule mining Association\
    \ rule mining is a rule-based machine learning algo-\nrithm which can be used\
    \ for error detection and also missing data imputation (see sub-\nsection “Methods\
    \ for correcting errors in sensor data”). Association rule mining detects \nfrequent\
    \ patterns, correlations, or causal structures by revealing how items are associ-\n\
    ated with each other. It helps in predicting the occurrence of a specific item\
    \ based on the \noccurrence of other items and is traditionally used for transactional\
    \ items e.g. product \nplacements in supermarkets. It comprises of the antecedent\
    \ which is something that is \nfound in the dataset, A, and the consequent, B,\
    \ which is something that is found in com-\nbination with the antecedent. In time\
    \ series analysis, an association rule A =⇒ B means \nthat if event A occurs somewhere\
    \ in the dataset, it will most likely be followed by B. \nHowever, to use association\
    \ rule mining in time series analysis, the data has to firstly be \ndiscretized\
    \ into a pattern e.g. a string of symbols.\nThere are many different ways to measure\
    \ association and the most used ones are sup-\nport and confidence. Support is\
    \ the measure of how frequent an itemset (or an event fol-\nlowed by another event)\
    \ is in the dataset whereas the confidence of a rule is the measure \nof how likely\
    \ an event A occurs when event B occurs. For time-series analysis, the sup-\n\
    port of a rule is calculated by:\nwhere k is the length of the discretized pattern\
    \ and |AB| is the length of the pattern AB \n(A followed by B). The confidence\
    \ of a rule is:\nsup(A =⇒ B) = Count of A followed by B occuring\n(k − |AB| +\
    \ 1)\n,\nconf (A =⇒ B) = sup(A =⇒ B)\nsup(A)\n,\nPage 23 of 49\nTeh et al. J Big\
    \ Data            (2020) 7:11 \n \nwhich tells us the number of times the relationship\
    \ is found to be true.\nYu et al. [56] presented an Apriori Association Rule Mining\
    \ method to improve data \nquality by detecting anomalies (unusual change in time\
    \ series patterns) in soil moisture \nprobes. The events are discretized and Dynamic\
    \ Time Warping is used firstly to align \nand compare the events of different\
    \ lengths. The Apriori algorithm is a method that \nreduces the computational\
    \ complexity of finding rules that are above the support and \nconfidence thresholds\
    \ (strong rules) by reducing the number of candidate itemsets. The \nApriori principle\
    \ states that if an itemset is frequent, then all of its subsets must also be\
    \ \nfrequent, and vice versa. By comparing the current observed event to historical\
    \ records \nvia association rules, anomalies are detected.\nBayesian network A\
    \ Bayesian network, also known as a belief network, is a probabil-\nistic graphical\
    \ model that uses a directed acyclic graph to model a set of variables and \n\
    their conditional dependencies based on Bayesian inference. It can be used to\
    \ obtain the \nposterior probabilities of an unknown variable given evidence from\
    \ other measured vari-\nables. The joint probability distribution of the variables,\
    \ A, B, C, and D is represented as, \naccording to the Chain Rule of probability:\n\
    It also follows the Local Markov property, which states that each variable is\
    \ condition-\nally independent of its non-descendants given its parent variables,\
    \ which simplifies the \nChain Rule into a simpler form.\nIbarguengoytia et al. [44]\
    \ proposed a Bayesian network approach for detecting and \nisolating faults e.g.\
    \ outliers in sensor networks for a gas turbine using two Bayesian net-\nworks,\
    \ one for validation and another one for isolation. For validation i.e. detection\
    \ of \nfaults, the fitted Bayesian network model is used to produce an estimate.\
    \ This is done \nby taking the particular sensor as a hypothesis while the other\
    \ related sensors act as the \nevidence. The output, which is the posterior probability\
    \ distribution of the specific vari-\nable, is used to estimate the probability\
    \ of measuring the recorded sensor data value. If \nthe probability is less than\
    \ a user-defined threshold, then it is identified as anomalous. \nIn this case,\
    \ another Bayesian network is created to isolate the fault i.e. to evaluate if\
    \ it \nis an event or an actual anomaly. When a faulty sensor actually exists,\
    \ the fault will be \nmanifested in all the related variables. This can be detected\
    \ in its Markov blanket, which \nis the set of variables that makes the variable\
    \ independent from the others, such as the \nparents, children, and spouses of\
    \ the variable. However, the downside to Bayesian Net-\nworks is that it requires\
    \ expert knowledge to form the probabilistic model of the rela-\ntions between\
    \ the variables.\nEuclidean distance For systems which use PCA for fault detection,\
    \ Hu et al. [42] pro-\nposed a data-cleaning solution using an Euclidean distance\
    \ approach. The data-clean-\ning solution aims to remove outliers in the training\
    \ data as they can strongly affect the \ncovariance structure of the PCA method,\
    \ which in turn affects the performance of the \nPCA-based fault detection. This\
    \ can be done by calculating the z-score of the Euclidean \ndistances of the samples,\
    \ which converts the multivariate problem into a univariate data \ncomparison.\
    \ After standardizing the original data matrix, X , the training data is now \n\
    P(A, B, C, D) = P(A) ∗ P(B|A) ∗ P(C|B, A) ∗ P(D|C, B, A).\nPage 24 of 49\nTeh et al.\
    \ J Big Data            (2020) 7:11 \na N × V standardized matrix, with N being\
    \ the number of training samples and V the \nnumber of variables. The Euclidean\
    \ distance of the jth row, Dj is defined as:\nwhere xj,i is the ith variable of\
    \ the jth sample in the normalized data matrix. The mean of \nthe Euclidean distance\
    \ of all samples, µD is:\nand the standard deviation of all samples, σD is:\n\
    The z-score, which is used to identify outliers in the dataset, is calculated\
    \ as:\nIf the z-score of the Euclidean distance of a sample is more than two standard\
    \ deviations \naway from the mean, then it is classified as an outlier and is\
    \ removed.\nHybrid methods Tsang and Chan [53] came up with a sensor validation\
    \ technique using \npredictive polynomial filters to model the behaviour of normal\
    \ sensor data and fuzzy rules \nto detect faults such as outliers, random error\
    \ and sensor failure from the error sequence \ngenerated from the model. Predictive\
    \ polynomial filters divide the signal into small seg-\nments and the small segments\
    \ are modelled by low degree polynomials. Another hybrid \napproach for fault\
    \ detection uses mathematical modelling and Dempster–Shafer Theory, \nproposed\
    \ by Zahedi et al. [75]. It is an online approach for detection drifts and noise,\
    \ \nwhich consist of local and global tiers. For local tiers, fault analysis is\
    \ done and fault vec-\ntors are generated by First Order Linear model. For global\
    \ tiers, fault analysis is done by \nrefining the result from local tiers using\
    \ the spatial correlation between sensors, Demp-\nster–Shafer theory for sensor\
    \ fusion which uses the faulty behaviour information to gen-\nerate a robust estimate\
    \ of the event of interest. The generated reference signal (ground \ntruth) is\
    \ fed back to the local tier.\nUncertainty quantification\nIn order to quantify\
    \ the uncertainty in the sensor data, the following approaches have \nbeen introduced.\n\
    Artificial neural network For the purpose of uncertainty quantification, Wang\
    \ et al. [81] \nused a special type of learning algorithm for artificial neural\
    \ networks called Extreme \nLearning Machines (ELM). This term refers to a new\
    \ learning algorithm for single hidden \nDj =\n\x1F\n\x1E\n\x1E\n\x1D\nV\n\x1C\
    \ni=1\n(xj,i)2\nµD = 1\nN\nN\n\x1F\nj=1\nDj,\nσD =\n\x1F\n\x1E\n\x1E\n\x1D\n1\n\
    (N − 1)\nN\n\x1C\nj=1\n(Dj − µD)2.\nzj = |Dj − µD|\nσD\n.\nPage 25 of 49\nTeh et al.\
    \ J Big Data            (2020) 7:11 \n \nlayer feedforward neural networks (SLFNs)\
    \ proposed by Guang-Bin Huang et al. [92], \nwhich randomly assigns input weights\
    \ and analytically determines the output weights of \nSLFNs. For an SLFN, the\
    \ output function of the kth hidden node, hk is\nwhere wk and bk are the parameters,\
    \ i.e. the weight and the bias or impact factor of the \nkth hidden node from\
    \ the input node. The activation function, G is a non-linear piece-\nwise continuous\
    \ function such as the Sigmoid function and Fourier function. Thus, the \noutput\
    \ vector of the SLFN with respect to xj , ⃗o(xj) is:\nwhere L is the number of\
    \ hidden nodes and βk is the output weight of node k in the hid-\nden layer to\
    \ the output layer. Eq. 3 can be re-written as:\nwhere O is the output matrix\
    \ of the SLFN, β is the weight matrix of the hidden layer \nnodes to the output\
    \ layer nodes and H is the the hidden layer output matrix. H, given N \ntraining\
    \ samples is composed of the following:\nThe purpose of the SLFN is to minimize\
    \ the cost function ||O − T|| where T is the target \nlabel matrix for the respective\
    \ samples. This allows us to approximate the target class as \naccurately as possible,\
    \ given the samples. However, conventional methods for building \nand training\
    \ neural networks involves gradient-based learning algorithms and the tuning \n\
    of parameters e.g. the learning rate and the number of iterations, which are time-con-\n\
    suming. ELM, on the other hand, is claimed to be able to learn at a much faster\
    \ speed. It \nstarts by randomly assigning values to the weight and bias parameters\
    \ of the input nodes \nto the hidden layer nodes, wk and bk . Then, the hidden\
    \ layer output matrix, H of the \nSLFN is calculated and finally, the output weight\
    \ of the hidden layer nodes to the output \nlayer, β can be mathematically determined\
    \ by finding the least-squares solutions of the \nlinear system:\nwhere H† is\
    \ the Moore–Penrose generalized inverse of H. This removes the need for the \n\
    tuning of parameters and slow learning algorithms, thus speeding up the training\
    \ pro-\ncess of the SLFN.\nWang et al. [81] used this ELM method to evaluate the\
    \ uncertainty in sensor measure-\nments. The ELM model the process in which the\
    \ input values not only consist of raw \nsensor data but also the system state,\
    \ which affects the “ground truth” value. The paper \nstates that the approximation\
    \ of “ground truth” value can be calculated as p(ˆxt|st)p(st|xt) \nhk(xj) = G(wk,\
    \ bk, xj),\n(3)\n\x1Fo(xj) =\nL\n\x1F\nk=1\nβkhk(xj)\nHβ = O,\nH =\n\n\n\x1E\
    h(x1)\n...\n\x1Eh(xN)\n\n =\n\n\nh1(x1) . . . hL(x1)\n...\n...\n...\nh1(xN)\
    \ . . . hL(xN)\n\n =\n\n\nG(w1, b1, x1) . . . G(wL, bL, x1)\n...\n...\n\
    ...\nG(w1, b1, xN) . . . G(wL, bL, xN)\n\n.\nβ = H†T\nPage 26 of 49\nTeh et al.\
    \ J Big Data            (2020) 7:11 \nwhere p(ˆxt|st) denotes the occurrence probability\
    \ of an individual measurement condi-\ntioned on another, xt and ˆxt are the observed\
    \ measurement and approximate “ground \ntruth” respectively and st is the system\
    \ process state. Thus, using two networks of ELM, \na measurement model that represents\
    \ the measurements and system state is built in the \nfirst ELM to find p(st|xt)\
    \ . Then, the second ELM is established to estimate p(ˆxt|st) given \nthe estimated\
    \ part quality from the first ELM.\nEnsemble classifiers Rahman et al. [79] proposed\
    \ a supervised classification framework \nfor automatic quality assessment through\
    \ ensemble Decision Trees and Bayesian Net-\nwork classifiers. The uncertainty\
    \ in the data is represented as quality flags, e.g. “Good \ndata”, “Bad data”,\
    \ “Probably good data” and “Bad but correctable data”. The classifier is \ntrained\
    \ on training data labelled with quality flags by domain experts. However, since\
    \ \nclass imbalance exists (a small number of anomalies), it is trained on under-sampled\
    \ data \nwhich is sampled on clusters obtained from k-means clustering. The sampling\
    \ from the \nclusters formed by the k-means clustering algorithm ensures that\
    \ it is representative of \nthe significant areas of the data. The decisions by\
    \ the base classifiers are fused using a \nmajority voting fusion rule based on\
    \ the mode of the decisions.\nOntology/knowledge-based systems Kuka and Nicklas [26]\
    \ proposed a framework for \nquality indicators for inaccurate and incomplete\
    \ data, and also other quality indicators \nsuch as inconsistent data and timeliness\
    \ using ontology (Sensor Network Ontology) to \nenrich sensor data streams by\
    \ propagating quality semantics. The paper defines the qual-\nity indicators as:\
    \ \n1. Timeliness—the timestamp (start timestamp of the measured data to the time\
    \ when \nthe data reaches the system) divided by the frequency of sensing device.\n\
    2. Accuracy—the variance of the observation and uncertainty, modelled as a mixture\
    \ of \nGaussian models with mean and variance.\n3. Completeness—the number of\
    \ attribute values that are not null, for probabilistic \nattributes i.e. ones\
    \ with the Accuracy property, Cumulative distribution functions are \nused.\n\
    4. Consistency—the similarity of two observations measuring the same variable\
    \ from \ndifferent sensing devices are valid at the same time.\nBamgboye et al. [25]\
    \ also suggested a software architecture solution based on semantic \ntechnology\
    \ for Smart Spaces applications, a part of the Smart Cities ecosystem, which \n\
    improves data stream quality by quantifying inaccurate and incomplete data, (along\
    \ with \nother DQ dimensions e.g. inconsistent data, availability, and timeliness)\
    \ based on expert \nknowledge. The semantic framework aims at homogenizing, annotating\
    \ and reasoning \nover the sensor data and it consists of 4 layers: \n1. Data\
    \ abstraction layer—collects raw data from sensor devices using the Global Sen-\n\
    sor Network middleware and uses static knowledge base to perform filtering of\
    \ data \npoints with quality related problems.\nPage 27 of 49\nTeh et al. J Big\
    \ Data            (2020) 7:11 \n \n2. Modelling and integration layer—Provides\
    \ a platform for interoperability and inte-\ngration for the heterogeneous data\
    \ from different types of sensor devices by imple-\nmenting domain ontology from\
    \ semantic sensor network.\n3. Reasoning layer—consists of predefined rules obtained\
    \ from domain expert knowl-\nedge and semantically annotated data streams from\
    \ the second layer to perform rea-\nsoning.\n4. Application layer—contains application\
    \ programs that rely on the sensor generated \ndata streams and relies on the\
    \ previous lower layers.\nMethods for correcting errors in sensor data\nOut of\
    \ the 57 publications found in this systematic review, there are ten publications\
    \ \nwhich presented approaches focused on correcting errors in sensor data. The\
    \ methods \nsuggested focus only on correcting errors such as missing data and\
    \ noise but do not \nattempt to detect or quantify them. The correctional methods\
    \ can be termed as missing \ndata imputation, which tries to estimate sensor measurement\
    \ values that are missing \nand de-noising, which tries to remove the noise associated\
    \ with a measurement signal. \nTable  4 shows the different existing methods proposed\
    \ to correct sensor data errors \n(RQ3), which consists of missing data and noise,\
    \ along with the errors addressed, the \ncorresponding papers that proposed the\
    \ method and the total number of papers. The \nmost common method for missing\
    \ data imputation is Association Rule Mining, which \nis addressed by half of\
    \ the papers that deals with missing data estimation techniques. \nThere are also\
    \ two clustering techniques presented, though one of them is a hybrid \napproach\
    \ with Probabilistic Matrix Factorization. There are also only two de-noising\
    \ \nmethods found in the selected studies, which is the Empirical Mode Decomposition\
    \ and \nSavitzky–Golay Filter.\nMissing data imputation\nFor missing data error,\
    \ Association rule mining, Clustering, k-Nearest Neighbour, and \nsingular value\
    \ decomposition solutions have been proposed to estimate the missing sen-\nsor\
    \ values.\nTable 4 Methods for  error correction (RQ3), along  with  its addressed\
    \ errors, respective \npapers, and the total number of papers that proposed that method\n\
    Method\nErrors addressed\nPapers\nTotal\nAssociation rule mining\nMissing data\n\
    [61, 62, 64, 66]\n4\nClustering\nMissing data\n[65]\n1\nk‑Nearest Neighbour\n\
    Missing data\n[9]\n1\nSingular value decomposition\nMissing data\n[67]\n1\nEmpirical\
    \ mode decomposition\nNoise\n[76]\n1\nSavitzky–Golay filter and multivariate thresholding\n\
    Noise\n[77]\n1\nHybrid methods\n Clustering and probabilistic matrix factorization\n\
    Missing data\n[63]\n1\nPage 28 of 49\nTeh et al. J Big Data            (2020)\
    \ 7:11 \nAssociation rule mining Gruenwald et al. [64] came up with an association\
    \ rule mining \napproach called FARM (Freshness Association Rule Mining) to estimate\
    \ missing values in \nsensor data. The central idea of this approach is that more\
    \ recent sensor data values should \nhave a higher contribution to the association\
    \ rule, that will be used for imputing missing \ndata at a specific point in time.\
    \ This is because usually, the current state of a sensed physi-\ncal environment\
    \ is more dependent on its nearest previous states, rather than historical \n\
    states that are obtained long ago. For this purpose, round weights are added to\
    \ each row \nof data. The FARM approach also uses the Apriori Association Rule\
    \ mining algorithm to \nestimate the missing sensor value based on the weighted\
    \ average of the current reading \nof the sensors related to the sensor with the\
    \ missing readings (obtained by the Associa-\ntion Rule Mining). Since the freshness\
    \ concept is introduced, the weighted support and \nconfidence measure is modified\
    \ to the following:\nIn 2009, Chok and Gruenwald [61] refined the approach to\
    \ cope with the complexity \nof data streaming environments using a MASTER-Tree\
    \ data structure. Moreover, Wang \net al. [66] proposed the Time-Space relationship\
    \ and Association Rule Mining method \nfor interpolating missing data in activity\
    \ recognition applications. This differs from the \nFARM approach  [64] as it\
    \ incorporates the spatial correlation between sensor nodes \nusing Pearson’s\
    \ correlation coefficient. This reduces complexity for the Association Rule \n\
    Mining algorithm as it only needs to search for rules from sensors that have a\
    \ correlation \ncoefficient above a certain user-defined threshold.\nD’Aniello\
    \ et al. [62] incorporated association rule mining in their virtual sensor frame-\n\
    work to impute missing data values. Their framework also uses ontology to represent\
    \ \nsensors and data quality along with fuzzy logic to evaluate the quality of\
    \ data received. \nFor example, the sensor is characterized by several quality\
    \ criteria such as those declared \nin the manufacturer specifications e.g. accuracy,\
    \ precision and time since last calibra-\ntion. Users can also specify their quality\
    \ requirements, e.g. requiring response time ≤ \n30 ms ± 2 ms, which can be expressed\
    \ in fuzzy sets, e.g. low response time. The virtual \nsensor thus attempts to\
    \ meet those quality requirements of the users by providing the \nreal reading\
    \ if it meets those criteria or the reconstructed value if the value is missing\
    \ or \nif it does not meet the criteria. The reconstructed value is computed using\
    \ association \nrule mining, which exploits the spatio-temporal correlation among\
    \ sensor readings to \nestimate missing data.\nClustering Tang et  al.  [65] introduced\
    \ a method for missing data imputation using \nfuzzy C-means clustering, which\
    \ has its parameter optimized using Genetic Algorithm. \nThe fuzzy C-means clustering\
    \ algorithm aims to classify data into different clusters to \nmaximize their\
    \ similarity. The weekly traffic volume data from sensors are analysed and \n\
    converted from a vector-based data structure into a matrix data structure. The\
    \ Fuzzy \nC-means clustering model is then built using Genetic Algorithm to optimize\
    \ the mem-\nbership degrees and cluster centers.\nsupw(A =⇒ B) =\n\x1F round weights\
    \ where A and B report the same state, e\n\x1F round weights\n,\nconfw(A =⇒ B)\
    \ =\n\x1F round weights where A and B report the same state, e\n\x1F round weights\
    \ where e is reported by X\n.\nPage 29 of 49\nTeh et al. J Big Data          \
    \  (2020) 7:11 \n \nk-Nearest Neighbour Li and Parker [9] proposed an imputation\
    \ technique for missing \ndata using the Nearest Neighbour approach which takes\
    \ advantage of spatio-temporal \ncorrelations in the sensor data. The method uses\
    \ a kd-tree structure to search for the \nnearest neighbours, formed using weighted\
    \ Euclidean metric which takes into account \nthe percentage of missing data for\
    \ each sensor. Then, the algorithm searches the tree to \nfind the nearest neighbours\
    \ and impute missing values based on the values obtained from \nits neighbours\
    \ (hot deck imputation).\nSingular value decomposition Xu et  al. [67] presented\
    \ a mathematical approach for \nrecovering missing data by representing the spatio-temporal\
    \ sensor data as a multi-\ndimensional tensor (tensors are a multi-dimensional\
    \ extension of a matrix) and intro-\nduced a tensor-based recovery method i.e.\
    \ tensor singular value decomposition (t-SVD) \nto recover the missing values.\
    \ One of the advantages of this method is that it does not \nrequire non-missing\
    \ training data. The spatial correlations between the sensors are \nfirstly obtained\
    \ using Nearest Neighbour search, which forms a two-dimensional, \nlat × long\
    \ matrix, which represents its latitude and longitude. Apart from the spa-\ntial\
    \ correlation, the temporal correlation is also represented in the same tensor.\
    \ This is \ndone by either formulating it as a three-order, lat × long × hour\
    \ tensor, or a four-order, \nlat × long × hour × day tensor which includes the\
    \ models of the same hours in a day, \nor a five-order, lat × long × hour × day\
    \ × week tensor, which models the similarity of \nthe same hours in different\
    \ days, and the same day in different weeks. After having the \nappropriate tensor\
    \ representation of the data, t-SVD is applied, which recovers the miss-\ning\
    \ values.\nHybrid methods Fekade et  al. [63] proposed a k-means clustering and\
    \ Probabilistic \nMatrix Factorization (PMF) approach to recover missing values.\
    \ Firstly, k-means cluster-\ning is done to divide the data into clusters, and\
    \ within each cluster, PMF is applied. PMF \ndecomposes a single matrix into a\
    \ product of two matrices, which has the property to \nobtain the original matrix\
    \ by computing the product of two matrices, thus enables the \nrecovery of missing\
    \ values in the original matrix.\nDe‑noising\nOther than handling missing data,\
    \ there are two publications found in the 57 selected \nstudies that presented\
    \ noise error correction (de-noising).\nSignal processing Omitaomu et al. [76]\
    \ suggested an approach for de-noising sensor \nsignals using the shrinkage method\
    \ (thresholding) to de-noise high-frequency intrinsic \nmode functions (IMF).\
    \ IMF is an oscillatory signal which is a subset of the frequency \ncomponents\
    \ from the original signal. It can be obtained by applying Empirical Mode \nDecomposition,\
    \ which forms low-frequency and high-frequency IMFs. They can then be \nseparated\
    \ by mutual information. The method studied in this paper only considers appli-\n\
    cations with signals that are corrupted by high-frequency noise, whereby de-noising\
    \ the \nlow-frequency IMF can lead to loss of signal information.\nPage 30 of\
    \ 49\nTeh et al. J Big Data            (2020) 7:11 \nSavitzky–Golay filter and \
    \ multivariate thresholding Sadıkoglu and Kavalcıoğlu [77] \npresented a de-noising\
    \ approach for a healthcare application, specifically continuous glu-\ncose monitoring\
    \ systems, using Savitzky–Golay Filter and Simple Multivariate Thresh-\nolding.\
    \ The Savitzky–Golay Filter is a method of data smoothing based on local least-\n\
    squares polynomial approximation whereas the Simple Multivariate Thresholding\
    \ is a \nmultivariate extension of a wavelet de-noising strategy which combines\
    \ univariate (one-\ndimensional) wavelets de-noising algorithms and PCA for dimensionality\
    \ reduction.\nMethods for detecting and correcting errors in sensor data\nThere\
    \ are 15 out of 57 publications that answer both RQ2 and RQ3 simultaneously by\
    \ \ndetecting the error and correcting them. They are usually termed as fault\
    \ detection, iso-\nlation, and recovery. Those introduced methods usually come\
    \ in the form of building a \nnormal behaviour model of the system and comparing\
    \ the new observed values with the \nnormal model. If the current observed data\
    \ is significantly different from the estimated \nvalue, it is identified as anomalous\
    \ and is imputed with the estimated value from the \nmodel. Table 5 shows the\
    \ different existing methods presented to detect and correct sen-\nsor data errors\
    \ (RQ2 and RQ3), along with the errors addressed, the respective papers \nthat\
    \ proposed the method and the total number of papers. The six hybrid methods sug-\n\
    gested for fault detection and correction can be classified into PCA-based hybrid\
    \ meth-\nods, Kalman filter-based hybrid methods, and Dempster–Shafer Theory-based\
    \ methods. \nIt is seen that PCA-based methods are most commonly found in this\
    \ area, which con-\nsists of one-third of the total papers addressing the fault\
    \ detection, isolation, and recov-\nery problem.\nFault detection, isolation and recovery\n\
    The following are the different approaches proposed to detect, isolate (identify)\
    \ and cor-\nrect errors in sensor data.\nTable 5 Methods combining error detection\
    \ and correction (RQ2 and RQ3), along with its \naddressed errors, respective\
    \ papers, and  the  total number of  papers that  proposed \nthat method\nMethod\n\
    Errors addressed\nPapers\nTotal\nPrincipal component analysis\nOutliers, bias,\
    \ drift, constant values, noise, \nstuck‑at‑zero\n[46, 55]\n2\nArtificial neural\
    \ network\nOutliers, bias\n[41, 43]\n2\nBayesian network\nOutliers, missing data\n\
    [7, 38]\n2\nGrey prediction model\nOutliers, bias, constant values, stuck‑at‑zero\n\
    [30]\n1\nDempster–Shafer theory\nUncertainty\n[80]\n1\nCalibration‑based method\n\
    Bias, drift, noise, stuck‑at‑zero\n[73]\n1\nHybrid methods\n Principal component\
    \ analysis‑based \nmethods\nOutliers, bias, drift, noise, constant values, \n\
    stuck‑at‑zero\n[60, 72, 74]\n3\n Kalman filter‑based methods\nOutliers, bias,\
    \ drift, missing data\n[31, 51]\n2\n Dempster–Shafer theory & Ontology\nUncertainty\
    \ (inaccurate data), missing data \n(incomplete data)\n[68]\n1\nPage 31 of 49\n\
    Teh et al. J Big Data            (2020) 7:11 \n \nPrincipal component analysis\
    \ Liu et  al. [55] presented a PCA-based self-validating \nsensor approach for\
    \ wastewater treatment plants which is able to identify faulty sensors \nbefore\
    \ soft sensor prediction, using the Squared Prediction Error (Q-statistic) and\
    \ Sen-\nsor Validity Index (SVI) [27]. The reconstructed vector, \x1Fx∗ of a faulty\
    \ sensor data can be \nobtained by subtracting the fault from the observed data,\
    \ ⃗x:\nwhere fi is the magnitude of the fault and ⃗ǫi is the direction of the\
    \ fault. Thus, the goal is \nto find fi such that Eq. 4 is most consistent with\
    \ the PCA model. The approach is further \nrefined in [46] where another variation\
    \ of PCA called the Variable Bayesian PCA is sug-\ngested to handle missing data\
    \ in the training set, which can cause over-fitting and locally \nbad optimal\
    \ solutions.\nArtificial neural network Huang [43] introduced a technique for\
    \ sensor fault e.g. outliers \nand bias diagnosis and reconstruction using auto-associative\
    \ neural networks (AANN) \nwhich learn the internal relationship between all inputs\
    \ by encoding (compressing) and \ndecoding (decompressing) the data. Moreover,\
    \ Hou et al. [41] came up with a technique \nfor sensor fault diagnosis and validation\
    \ using rough sets for pre-processing (for dimen-\nsionality reduction and to\
    \ learn classification rules) and artificial neural networks to learn \nthe normal\
    \ behaviour model.\nBayesian network Dereszynski and Dietterich [38] proposed\
    \ a data imputation method \nfor missing values and anomalies based on a dynamic\
    \ Bayesian network which learns the \nnormal behaviour model of sensor measurements.\
    \ The discrepancy between the current \nestimate from the Bayesian network model\
    \ and the current observed reading detects if \nthe reading is anomalous. Since\
    \ a normal static Bayesian network only models the spatial \ncorrelation in the\
    \ dataset, a dynamic Bayesian network is used to also incorporate the \ntemporal\
    \ correlations, since environmental data tend to be temporally correlated e.g.\
    \ pat-\nterns for the 24-h cycle is relatively similar. It relates variables to\
    \ each other over adjacent \ntime steps. Zhang et al. [7], also suggested a data\
    \ reconstruction technique for missing \ndata and inaccurate values in medical\
    \ body sensor networks by learning a Bayesian net-\nwork. The Bayesian network\
    \ learns the probabilistic graphical model and estimates the \nsensor value by\
    \ calculating its conditional probability.\nGrey prediction model Chen et al.\
    \ [30] proposed a self-validating strategy for multi-\nfunctional sensors using\
    \ the Grey Bootstrap model (GM(1,1) with bootstrap) which pro-\nduces a prediction\
    \ model. Current observations will then be compared to the predicted \nvalue to\
    \ detect, isolate, and recover faults such as outliers, bias, constant value,\
    \ and near-\nzero values. Bootstrapping can be done by drawing random samples\
    \ from the dataset \nwith replacement to generate B bootstrap samples and calculate\
    \ the estimate for each \nresample, which gives the approximation of uncertainty.\
    \ The bootstrap method allows \nthe uncertainty to be estimated without having\
    \ prior information about the probability \ndistribution of the measurements.\
    \ For each bootstrap sample, a grey predictive model, \nGM(1,1) is used to predict\
    \ the next value.\n(4)\n\x1Fx∗\ni = \x1Fx − fi\x1Fǫi ,\nPage 32 of 49\nTeh et al.\
    \ J Big Data            (2020) 7:11 \nDempster–Shafer theory Richter [80] presented\
    \ a method for assessing uncertainty and \nincreasing reliability for context-based\
    \ applications (activity recognition). The reliabil-\nity assessment is done via\
    \ mean squared error and to increase reliability, data fusion by \nDempster–Shafer\
    \ theory of evidence is used in which measurement result is combined \nwith other\
    \ sensor events that have higher reliability and are spatio-temporally related.\
    \ \nThe Dempster–Shafer theory combines evidence gathered from multiple sources\
    \ to \nderive a new degree of belief, also known as belief mass, by data fusion\
    \ and calculates \nthe confidence interval which includes the exact probability\
    \ without needing prior infor-\nmation. Thus, it provides more flexibility compared\
    \ to Bayesian Networks as it requires \nweaker conditions.\nCalibration-based\
    \ method Yu and Li [73] introduced an online in-situ calibration tech-\nnique\
    \ based on a calibration method. The calibration technique corrects faults such\
    \ as \nbias, drifts, noise, and sensor failure. An environment evaluation is firstly\
    \ carried out, in \nwhich a benchmark is established and measured values can be\
    \ compared to the bench-\nmark and calibrated via a mapping to the benchmark.\
    \ However, this method requires an \naccurate environment evaluation.\nPrincipal\
    \ component analysis-based hybrid methods Wang et al. [74] presented methods \n\
    for online blind detection and automatic calibration of sensor drifts via signal\
    \ space pro-\njection using Principal component analysis to learn the normal sensor\
    \ behaviour model \nand detect the sensor drifts. Then, Kalman filter is applied\
    \ to estimate the sensor drift \nvalue and the drift value is subtracted from\
    \ the sensor reading to give a better estimate of \nthe true value. Yang et al. [60]\
    \ suggested a data validation technique to detect, identify and \ncorrect faults\
    \ such as bias, drifts, and impacts in a multifunctional sensor. The technique\
    \ \nseparates (using Maximal Information Coefficient) the variables into independent\
    \ and \ndependent variables. Different fault detection, identification, and correction\
    \ techniques \nare used for the two types of variables. For independent variables,\
    \ k-Nearest Neighbour is \nused for fault detection and identification and a Grey\
    \ Predictive Model GM(1,1) is used \nfor fault correction. For related variables,\
    \ kernel Principal component analysis is used for \nfault detection. Iterative\
    \ Reconstruction-Based Contribution is used for fault identifica-\ntion which\
    \ assumes that the sensors are faulty and iteratively reconstruct the data until\
    \ its \nSquared Prediction Error (Q-statistics) is below a certain threshold and\
    \ finally, variables \nin the estimated fault direction are deemed to be faulty.\
    \ For fault correction of the related \nvariables, fuzzy similarity is used, which\
    \ involves reconstructing the faulty variable based \non the relationships between\
    \ the related variables. Furthermore, Uren et al. [72] proposed \na PCA-based\
    \ sensor fault detection, isolation, and reconstruction for bias, drifts, noise,\
    \ \nconstant value, and stuck-at-zero errors. For fault detection, non-temporal\
    \ parity space \nis used to check for inconsistencies among a set of redundant\
    \ sensors. With the assump-\ntion that not all sensors may fail simultaneously\
    \ in a particular channel, the non-temporal \nparity space technique compares\
    \ and validates the sensor measurements with a set of \nredundant measurements.\
    \ An estimate is obtained from the most consistent subset of \nredundant measurements\
    \ of a process variable and the faulty sensor can be identified via \nparity checks.\
    \ Fuzzy rule base is then used for fault isolation and Principal Component \n\
    Analysis is used to model and reconstruct the sensor measurements.\nPage 33 of\
    \ 49\nTeh et al. J Big Data            (2020) 7:11 \n \nKalman filter-based hybrid\
    \ methods Solomakhina et  al.  [51] suggested an approach \nfor detecting and\
    \ correcting anomalous sensor data using Kalman Filter, Autoregressive \nIntegrated\
    \ Moving Average (ARIMA), smoothing operators and knowledge-based systems. \n\
    The errors, e.g. missing data and outliers, are detected using the ARIMA and Kalman\
    \ fil-\nter, and the Knowledge-based system is consulted to confirm the error.\
    \ In the healthcare \ndomain, Feng et al. [31] also introduced a Kalman filter-based\
    \ hybrid approach for sensor \nfault identification and correction for missing\
    \ data, bias, drifts and outliers. The method \nuses Outlier Robust Kalman filter\
    \ (ORKF) and locally-weighted partial least squares (LW-\nPLS) for artificial\
    \ pancreas control systems. Both algorithms are used to model the nor-\nmal sensor\
    \ behaviour to provide a more robust fault detection since one might report an\
    \ \nerror, but the other might not. The ORKF has the advantage of fast detection\
    \ and online \nauto-smoothing i.e. de-noising ability, which works well for short-duration\
    \ errors such as \noutliers. For long-duration errors, such as drifts, LW-PLS\
    \ is more advantageous as it is \nbased on historical data. The errors are then\
    \ replaced by the estimated value which has \nthe highest performance score e.g.\
    \ model accuracy, smoothness from the models.\nDempster–Shafer theory-based hybrid\
    \ method To evaluate the quality of sensor data \nbased on inaccurate and incomplete\
    \ data, (as well as inconsistent data and timeliness), \nHermans et al. [68] presented\
    \ a framework using heuristics in the local and cluster heads, \nand an inference\
    \ engine in the cluster head which fuses correlated sensor readings using \nDempster–Shafer\
    \ theory to arrive at a more accurate estimate.\nTypes of domains\nThe domains\
    \ of the applications (RQ4) in the 57 selected papers are extracted and the \n\
    results are tabulated in Table 6. About half of the publications suggested methods\
    \ that \ngenerally apply to WSNs or IoT applications without a specific application\
    \ domain. \nHowever, some publications solve data quality problems in specific\
    \ areas such as indus-\ntrial processes, environmental sensing, and smart city\
    \ solutions. Other domains also \nTable 6 Domains of  sensor data quality application\
    \ from  the  57 selected papers, \nalong with its respective papers and total\
    \ number of papers that solve sensor data errors \nin that domain\nDomain\nPapers\n\
    Total\nGeneral\n e.g. WSNs, IoT, streaming data\n[26, 27, 33–37, 39, 46, 48–53,\
    \ \n57, 58, 60–64, 67–69, 74–76, \n78]\n29\nIndustrial processes\n e.g. Chemical\
    \ gas process monitoring, power plants, part injection \nmolding\n[30, 43, 44,\
    \ 70–72, 81]\n7\nEnvironmental sensing\n e.g. air quality monitoring, marine environment,\
    \ soil moisture\n[32, 38, 40, 47, 56, 79]\n6\nSmart city\n e.g. Smart Spaces,\
    \ Smart Grid, Wastewater treatment, Traffic flow\n[25, 45, 46, 54, 55, 65]\n6\n\
    Healthcare\n e.g. body sensor networks, artificial pancreas, continuous glucose\
    \ moni‑\ntor\n[7, 31, 59, 77]\n4\nHVAC systems\n[41, 42, 73]\n3\nContext‑based\
    \ application / activity recognition\n[66, 80]\n2\nPage 34 of 49\nTeh et al. J\
    \ Big Data            (2020) 7:11 \ninclude healthcare, heating, ventilation,\
    \ and air conditioning (HVAC) systems, and \nactivity recognition applications.\n\
    There are several publicly available datasets that are used in method evaluation\
    \ and \nare domain-specific. The nine publicly available datasets are: SensorScope\
    \ dataset [93, \n94], which includes the Grand St. Bernard (GSB), FishNet and\
    \ Lausanne Urban Canopy \nExperiment (LUCE) deployments, Intel Berkeley dataset\
    \ [95], University of California \nIrvine (UCI) Machine Learning Repository’s\
    \ water treatment plant dataset [96], Net-\nworked aquatic microbial observing\
    \ system (NAMOS) dataset [97] from the University \nof Southern California, numenta\
    \ anomaly benchmark dataset (NAB) [88, 98], California’s \nDepartment of Transportation\
    \ (Caltrans) Performance Measurement System (PeMS) \ntraffic monitoring dataset [99],\
    \ Tasmania Marine Analysis Network (TasMAN) Sullivans \nCove CSIRO Wharf marine\
    \ dataset [100], US Mitsubishi Electric Research Laboratories \nMERLSense dataset [101,\
    \ 102], and PhysioNet [103]. The datasets and papers that used \nthem for method\
    \ evaluation and the total number of papers are listed in Table 7. These \ndatasets\
    \ are last searched on May 8th 2019.\nThe following are brief descriptions of\
    \ the publicly available datasets. SensorScope \nhas deployed many outdoor networks\
    \ for environmental monitoring which produced \ndatasets, three of which have\
    \ been used by seven of the selected papers for method \nevaluation. Those publications\
    \ include ones without a specific domain (general \npapers) such as [57] or papers\
    \ that are environmental sensing domain-specific such as \n[38]. The GSB SensorScope\
    \ network has been deployed at the Grand St. Bernard pass, \nlocated at the border\
    \ of Switzerland and Italy, in late 2007 for approximately 1 month \n(September–October).\
    \ It comprises of 23 stations. Another SensorScope network is \nthe FishNet deployment,\
    \ which is deployed 1 month before GSB (August–September) \nfor around a month\
    \ as well, but only with six stations. It is used to monitor a river to \nimprove\
    \ its quality. The last SensorScope dataset seen in the selected literature is\
    \ the \nLUCE dataset, which is a more extensive dataset, with 97 stations deployed\
    \ for almost \nTable 7 Real-world publicly available datasets and its respective\
    \ domains, along with the \nrespective papers and total number of papers which\
    \ used the datasets for performance \nevaluation\nDataset\nDomain\nPapers\nTotal\n\
    SensorScope\n(GSB, LUCE, FishNet)\nEnvironmental sensing\n[35, 57, 58]\n[38] (GSB\
    \ and FishNet)\n[48] (GSB and LUCE)\n7\nIntel Berkeley\nEnvironmental sensing\n\
    [35, 36, 39, 48, 62, 63]\n6\nUCI machine learning repository water \ntreatment\
    \ plant dataset\nSmart city\n(wastewater treatment)\n[46, 55]\n2\nNumenta anomaly\
    \ benchmark\nGeneral\n(streaming data)\n[34]\n1\nNetworked aquatic microbial observing\
    \ \nsystem (NAMOS)\nEnvironmental sensing\n(marine environment)\n[48]\n1\nTasMAN\
    \ Sullivans Cove Marine\nEnvironmental sensing\n(marine environment)\n[79]\n1\n\
    MERLSense\nEnvironmental sensing\n[66]\n1\nCaltrans PeMS traffic monitoring\n\
    Smart city\n(traffic flow monitoring)\n[9]\n1\nPhysioNet\nHealthcare\n[7]\n1\n\
    Page 35 of 49\nTeh et al. J Big Data            (2020) 7:11 \n \na year from July\
    \ 2006 to May 2007, which aims to understand the atmospheric behav-\niour in urban\
    \ environments better.\nAnother dataset related to indoor environmental monitoring\
    \ is the Intel Berkeley \nResearch Lab dataset. There are six papers in total\
    \ that have used this dataset to test \ntheir proposed methods. The Intel Lab\
    \ data has 54 sensors deployed indoors in the \nlab itself, collecting data about\
    \ the environment such as the temperature, humid-\nity, and light. It also consists\
    \ of the date, time, epoch, sensor ID, and voltage values. \nThe units for the\
    \ data types are also specified, where the temperature is recorded in \ndegrees\
    \ Celsius ( oC ), the humidity is in percentage ( % ), which is the relative humid-\n\
    ity, and the light intensity is measured in Lux. The dataset consists of 2.3 million\
    \ \nreadings, obtained every 30 seconds from the sensors for about a month (February\
    \ \n28th to April 5th 2004). MERLSense is also another environmental sensing dataset,\
    \ \nwhere it captured and recorded motion data. It is also deployed in a research\
    \ lab, and \ndata of the people working in the lab is collected for 2 years from\
    \ March 2006 and \nMarch 2008, totalling up to 50 million raw records from 200\
    \ sensors. However, Wang \net al. [66] has used the temperature attribute to evaluate\
    \ their missing data imputa-\ntion technique.\nThe NAMOS and TasMAN datasets are\
    \ both marine datasets, collected to moni-\ntor marine environments. NAMOS consists\
    \ of several datasets from devices deployed \nby the University of Southern California\
    \ at different locations e.g. buoys, boats and \nweather stations around California.\
    \ It is one of the three datasets, along with the Intel \nLab and SensorScope\
    \ LUCE datasets that Rassam et al. [48] used to evaluate their \nmethod for outlier\
    \ detection. The NAMOS dataset used is from the buoy no. 103 col-\nlected in August\
    \ 2006 in Lake Fulmor. The TasMAN dataset, on the other hand, is \nfrom Sullivans\
    \ Cove, Hobart, Tasmania. The dataset consists of the seawater tempera-\nture\
    \ and conductivity from February 2008 to July 2012. Numenta anomaly benchmark\
    \ \n(NAB) is an open-sourced benchmark for evaluating techniques for anomaly detec-\n\
    tion for streaming data. It provides numerous real-world streaming datasets such\
    \ as \nAmazon’s AWS server metrics, online advertisement clicking rates, temperature\
    \ sens-\ning, and traffic monitoring datasets. The datasets provided by NAB are\
    \ the only ones, \namong the other datasets found in this systematic review, complete\
    \ with labelled \nstreaming data comprising of normal and erroneous measurements\
    \ e.g. spatio-tem-\nporal outliers, noise and drift. It also has a novel scoring\
    \ system called the NAB score, \nwhich takes into account true positives, true\
    \ negatives, false positives, false negatives, \nand windows to reward early detection.\n\
    Moreover, another publicly available dataset comes from the University of Cali-\n\
    fornia, Irvine (UCI) Machine Learning Repository. The repository contains a wide\
    \ \nrange of 468 different datasets, from healthcare to games, robotics to social\
    \ science, \nenvironmental sensing and many more. There are two of the selected\
    \ papers [46, 55] \nthat have used water treatment plant dataset from this repository.\
    \ It has 527 sam-\nples and 38 attributes, which consists of the daily measurement\
    \ from sensors in an \nurban wastewater treatment plant. It is a relatively complex\
    \ system, where the aim is \nto predict faults through the operational state of\
    \ the process. Another publicly avail-\nable smart city dataset comes from California’s\
    \ Department of Transportation, who \nreleased their traffic monitoring datasets.\
    \ However, a user has to sign up for a free \nPage 36 of 49\nTeh et al. J Big\
    \ Data            (2020) 7:11 \naccount to access those datasets. It provides\
    \ an extensive traffic monitoring dataset, \nwhere users can choose to obtain\
    \ data from up to almost 100 freeways in Califor-\nnia gathered by 18,305 stations.\
    \ The website also provides real-time information dis-\nplayed on a dashboard.\
    \ The last publicly available dataset found to be used for method \nevaluation\
    \ for one of the 57 selected papers is PhysioNet. It provides healthcare-based\
    \ \nsets of data, which is split into two categories: clinical databases and waveform\
    \ data-\nbases. The former provides data such as demographics, images and vital\
    \ sign meas-\nurements where Zhanget al. [7] used one of the datasets, whereas\
    \ the latter presents \na digitalized signal or waveforms of physiologic data,\
    \ such as the heart monitoring \nelectrocardiogram device signal.\nDiscussion\n\
    In this section, we discuss the challenges found through the systematic review,\
    \ which \naffects the comparability of methods introduced in this research area.\
    \ The evaluation \nof the performances of methods presented in the selected studies\
    \ are done on a wide \nrange of datasets and have different dataset pre-processing\
    \ conditions. This makes it \nimpossible to compare the efficiency of these methods\
    \ just by reading the respective \npublications. Furthermore, there are various\
    \ evaluation metrics used in the literature \nand even within the same problem,\
    \ e.g. outlier detection, the evaluation metrics used \nare different. This shows\
    \ that there is no generally accepted way of comparing differ-\nent methods. An\
    \ analysis of the problems is detailed in the subsections that follow. \n“Datasets\
    \ and error imputation and labelling” section discusses the different datasets\
    \ \nused and their availability online or reproducibility, and the preparation\
    \ or pre-pro-\ncessing of the dataset which includes error introduction for evaluating\
    \ the methods. \n“Evaluation metrics” section, on the other hand, details the\
    \ different evaluation met-\nrics used and the situations they are used in.\n\
    Datasets and error imputation and labelling\nThere are many different datasets\
    \ used in the performance evaluation of methods found \nin the literature. They\
    \ can be categorized into two types of datasets: real-world datasets \nand simulated\
    \ datasets. Real-world datasets consist of data from real-world experiments \n\
    Table 8 Types of  datasets used in  method evaluation and  their availability\
    \ online \nor  reproducibility, the  total number of  datasets used for  each\
    \ type of  dataset \nand the respective papers and the total number of papers\
    \ that used those datasets\nDataset type\nAvailability\nNo. datasets\nPapers\n\
    No. papers\nReal‑world datasets\nPublished and currently \navailable\n21\n[7,\
    \ 9, 34–36, 38, 39, 46, 48, 55, \n57, 58, 62, 63, 66, 79]\n16\nUnpublished or\
    \ currently not \navailable\n33\n[9, 30, 31, 33, 35–37, 40–42, \n44, 45, 47, 49,\
    \ 50, 52–54, 56, \n60, 61, 64, 65, 67–70, 72, 73, \n75, 76, 81]\n32\nSimulated\
    \ datasets\nPublished or reproducible\n2\n[46, 54]\n2\nNot reproducible\n16\n\
    [35, 37, 39, 43, 47, 51, 57–59, \n69, 71, 74, 76–78]\n15\nPage 37 of 49\nTeh et al.\
    \ J Big Data            (2020) 7:11 \n \nor deployments, whereas simulated datasets\
    \ contain data that have been synthetically \nproduced. Within those two categories,\
    \ the datasets can be further split into published \nor unpublished datasets.\
    \ Published datasets are datasets that are currently publicly avail-\nable (last\
    \ checked on May 8th 2019) or reproducible datasets, by having the dataset \n\
    itself or source code published online. The published datasets are described in\
    \ “Types of \ndomains” section with respect to their domains. Unpublished datasets\
    \ refer to the data-\nsets that are not currently available publicly or cannot\
    \ be reproduced. Table 8 shows the \ndifferent types of datasets and the number\
    \ of papers that used them for evaluation. Out \nof the 57 final selected publications,\
    \ 52 publications have proper validation and from \nthese, there are a total of\
    \ 72 datasets used for evaluating the introduced algorithms. \nFrom these 72 datasets,\
    \ there are 54 real-world datasets of which only 21 of them are \npublished datasets.\
    \ Furthermore, among the 18 simulated datasets, only two can be \nreproduced as\
    \ the simulator is publicly available. Note, that some papers evaluated their\
    \ \nmethods on more than one dataset, such as the work of Bosman et al. [35],\
    \ who used \nfour datasets: the published real-world datasets Intel Lab and SensorScope\
    \ GSB, an \nunpublished real-world dataset, and a simulated dataset.\nFrom the\
    \ 72 datasets used for method evaluation, it is seen that around 68% of the \n\
    datasets are not published nor reproducible, consisting of both real-world and\
    \ simulated \ndatasets. This makes it hard for the comparison of different methods\
    \ in this research \narea. Besides that, even for literature working on publicly\
    \ available datasets, they have \ndifferent techniques of imputing errors to evaluate\
    \ their suggested methods. For exam-\nple, in anomaly detection, Bosman et al. [35]\
    \ labelled the errors in the Intel Lab and Sen-\nsorScope GSB datasets using a\
    \ semi-automated approach. Anomalies were identified by \nheuristics (e.g. a value\
    \ that is not changing for over ten samples is labelled as a con-\nstant-value\
    \ error), which will then be corrected manually by a person. Rassam et al. [48],\
    \ \non the other hand, also used the Intel Lab dataset and the SensorScope dataset\
    \ (LUCE, \nNAMOS) to evaluate their proposed method but have a different heuristics\
    \ of histo-\ngram-based labelling. They assessed their solution on simulated errors\
    \ whereby they \nartificially injected 100 anomalies. For missing data imputation,\
    \ the Intel Lab dataset has \nalso been used by D’Aniello et al. [62] and Fekade\
    \ et al. [63], where the former simulated \nthe missing errors at 5%, 10%, 20%,\
    \ 30%, 40% and 50% rates and the latter simulated the \nmissing error by making\
    \ 10% of the total data empty.\nOther than having different error injection and\
    \ labelling methods, though even if two \npublications might use the same online\
    \ dataset, it is still not directly comparable as \nthey might have pre-processed\
    \ the dataset. For example, Bosman et al. [36] and Fawzy \net al. [39] both used\
    \ the entire Intel lab dataset for evaluation, though with different \nerror introduction\
    \ techniques, whereas Rassam et al. [48] only used 3 out of the total 54 \nsensor\
    \ nodes. D’Aniello et al. [62] also removed known errors from the dataset before\
    \ \nproceeding to test their missing data imputation methods on a subset (March\
    \ 1st–14th) \nof the Intel Lab dataset. Although the NAB is a unified benchmark\
    \ that provides publicly \navailable datasets complete with labelled errors, it\
    \ is only for the comparison of anomaly \ndetection algorithms. It does not provide\
    \ a benchmarking system for missing data impu-\ntation and fault correction, which\
    \ is the other two main types of errors found in the liter-\nature. There is also\
    \ only one publication [34] among the 52 publications with validation \nthat has\
    \ used this benchmarking system.\nPage 38 of 49\nTeh et al. J Big Data       \
    \     (2020) 7:11 \nIn order to analyse the problem of the availability of the\
    \ datasets used in the literature, \nwe are introducing two data set metrics,\
    \ which are retrieved for each of the 57 reviewed \npublications. The first metric\
    \ is the number Pk of publicly available data sets, which \nhave been used for\
    \ evaluating purposes in the kth paper. The second metric is the total \nnumber\
    \ of data sets Dk , which have been used for the evaluation of algorithms in the\
    \ \nkth paper. Consequently, the difference (Dk − Pk) is the number of datasets,\
    \ which have \nbeen evaluated in the kth paper but are not publicly available.\
    \ However, up to this point, \nour model does not take into account the possible\
    \ influence of open access publications \nof the respective papers on its citation\
    \ rate.\nFigure 5a shows a heatmap of the number of publicly available datasets\
    \ Pk against the \ntotal number of datasets Dk used in the sensor data quality\
    \ literature. The heatmap vis-\nualizes the joint distribution of P = (P1, . .\
    \ . , P57) and D = (D1, . . . , D57) : The numbers \nin each cell corresponds\
    \ to the number of publications that have used the respective \nnumber of publicly\
    \ available datasets P and the total number of datasets D to evaluate \nFig. 5\
    \ Heatmap of dataset availability. The two heatmaps describing the problem of\
    \ availability of the \ndatasets used in sensor data quality literature. Both\
    \ heatmaps show the number of available datasets, P \nagainst the total number\
    \ of datasets, D used for method evaluation in the 57 selected papers where the\
    \ \nnumber in each cell represents: a the number of papers that have used P publicly\
    \ available datasets out of \nits D total number of datasets for method evaluation\
    \ and b the average citation rate for the papers that have \nused P publicly available\
    \ datasets out of its D total number of datasets for method evaluation\nPage 39\
    \ of 49\nTeh et al. J Big Data            (2020) 7:11 \n \ntheir methods. The\
    \ darker colour (higher numbers) in the lower quadrant shows that \nthe majority\
    \ of the reviewed sensor data quality publications evaluate their methods on \n\
    fewer datasets and more importantly, on datasets that are not publicly available.\
    \ How-\never, a problem found through this systematic review, which is the direct\
    \ comparabil-\nity of the methods introduced, can only be solved if researchers\
    \ in the research area \nevaluate their techniques on the same datasets (given\
    \ the same error injection and pre-\nprocessing conditions). Thus, having used\
    \ publicly available datasets might prove to be \nbeneficial to the research area.\
    \ This prompts for a need to further analyse the effects of \nusing publicly available\
    \ datasets for method evaluation.\nIn order to do so, we are analysing the citation\
    \ rate Rk of the reviewed publications. The \ncitation rate Rk is computed as\
    \ the quotient of the number of citations of the kth paper \nand its years since\
    \ publication. The number of citations for each publication has been \nobtained\
    \ from Google Scholar5 on April 5th 2019. Google scholar was chosen because it\
    \ \ncan be accessed without a license fee. Note, that Google Scholar’s citation\
    \ count includes \ncitations from various sources including self-citations and\
    \ preprint repositories. Thus, \nthe citation count might differ from other citation\
    \ databases, e.g. Web of Science. The \ncitation rates Rk are binned with respect\
    \ to their total number of datasets Di and number \nof publicly available data\
    \ sets Pj and are averaged for each bin:\nFrom this observation, the heatmap in\
    \ Fig. 5b is plotted to study the effects of using \npublicly or non-publicly\
    \ available datasets on the citation rate of a publication. The cita-\ntion rate\
    \ is used to study the effects of using publicly or non-publicly available datasets\
    \ \nas a high citation rate might imply that researchers working on the same research\
    \ area \ncan compare their results with those studies using the same dataset.\
    \ If the dataset is not \npublicly available, it makes it hard for comparison.\
    \ The heatmap shows that the average \ncitation rate for the literature involving\
    \ publicly available datasets tends to be higher. \nTo confirm this observation,\
    \ a Bayesian analysis [104] is carried out to test if there is a \nsignificant\
    \ difference in the citation rate between two groups: the available group, which\
    \ \nconsists of papers that evaluated their methods on publicly available datasets\
    \ and the \nnon-available group, which consists of papers that evaluated their\
    \ methods on non-pub-\nlicly available datasets.\nShown in Fig.  6, the Bayesian\
    \ estimation is carried out using the Python module \nPyMC  [105], which is designed\
    \ to implement Bayesian statistical models. A Bayesian \nestimation is done instead\
    \ of the classical t-test, as it shows the complete distributional \ninformation,\
    \ i.e. the probability of every possible difference of means and every possible\
    \ \ndifference of standard deviations which allows the estimation of the difference\
    \ between \nthe two groups rather than simply testing whether the two groups are\
    \ different based \non the observed data [104]. Figure 6a, b show the posterior\
    \ distribution of the mean \ncitation rates for both groups, i.e. the available\
    \ group and the non-available group. The \n(5)\n5 https ://schol ar.googl e.com.\n\
    Page 40 of 49\nTeh et al. J Big Data            (2020) 7:11 \nFig. 6 Bayesian\
    \ analysis. Bayesian analysis which shows a significant difference in the citation\
    \ rate between \nthe available group, and the non-available group: a the mean\
    \ citation rate, 6.79 of the available group which \nconsists of the collection\
    \ of papers that used publicly available datasets to evaluate their methods whereas\
    \ \nb the mean citation rate, 2.16 of the non-available group which involves the\
    \ group of papers that did not use \npublicly available datasets for method evaluation.\
    \ c The difference of means from both groups. The papers in \nthe available group\
    \ has a 99.9% posterior probability of having higher number of citations compared\
    \ to the \npapers from the non-available group\nPage 41 of 49\nTeh et al. J Big\
    \ Data            (2020) 7:11 \n \nmean of the available group, available_mean\
    \ is approximately 6.87 whereas the mean of \nthe non-available group, non_available_mean\
    \ is 2.16. In order to compare the means of \nboth groups, Fig. 6c shows the posterior\
    \ distribution of the difference of means of both \ngroups. There is a 99.9% probability\
    \ that the mean citation rate of publications, which \nare using public datasets,\
    \ is larger than the mean citation rate of publications, which \nare not using\
    \ public datasets. This suggests that the publicly available datasets are easier\
    \ \nto access, which leads to a higher citation rate for papers that involve publicly\
    \ available \ndatasets for method evaluation. Moreover, the ease of access for\
    \ publicly available data-\nsets allows researchers to directly test and compare\
    \ their methods with other existing \nsolutions for solving sensor data quality\
    \ problems which are done on the same dataset.\nEvaluation metrics\nApart from\
    \ the different datasets used, various evaluation metrics are also seen in the\
    \ \nselected literature. This is due to the different sensor data quality problems,\
    \ for exam-\nple, methods for detecting errors and methods for missing data imputation\
    \ would have \nused different evaluation metrics to quantify its performance.\
    \ The former uses classifica-\ntion metrics such as recall and precision and is\
    \ based on the confusion matrix (Table 9) \nTable 9 Confusion matrix where  the \
    \ positive class are faults and  the  negative class are \nnormal data points\n\
    Thus, TP faults correctly predicted as faults, FP normal data point incorrectly\
    \ predicted as fault (Type I error), FN fault \nincorrectly predicted as normal\
    \ data point (Type II error) and TN normal data point correctly predicted as normal\
    \ data point\nActual positive\nActual negative\nPredicted positive\nTrue positive\
    \ (TP)\nFalse positive (FP)\nPredicted negative\nFalse negative (FN)\nTrue negative\
    \ (TN)\nTable 10 Types of  performance measures used in  method evaluation for \
    \ the  39 papers \nwhich has  quantitative performance values and  their respective\
    \ formulas, papers \nand  total number of  papers, where  TP = true positive,\
    \ TN = true negative, FP = false \npositive, FN = false negative, xi = observed\
    \ value or  ground truth of  sample i, ˆxi = \npredicted value of sample i and n\
    \ = number of samples\nEvaluation metric\nFormula\nPapers\nTotal\nRecall\nTP\n\
    TP+FN\n[31, 35, 36, 38, 39, 42, 45, 48, 51, 57, \n58, 60, 78]\n13\nFalse positive\
    \ rate (FPR)\nFP\nTN+FP\n[31, 33, 38–40, 44, 47, 54, 57–59, 71]\n12\nFalse negative\
    \ rate (FNR)\nFN\nTP+FN\n[40, 44, 47, 48, 54, 71]\n6\nPrecision\nTP\nTP+FP\n[35,\
    \ 36, 38, 51, 78]\n5\nAccuracy\nTP+TN\nTP+TN+FP+FN\n[37, 48, 51, 79]\n4\nF‑score\n\
    2 × precision×recall\nprecision+recall\n[35, 36]\n2\nMatthew’s correlation coefficient\
    \ \n(MCC)\nTP×TN−FP×FN\n√(TP+FP)(TP+FN)(TN+FP)(TN+FN)\n[65]\n1\nRegression metrics\n\
    \ Root mean squared error (RMSE)\n√\nMSE\n[46, 62, 64, 66]\n4\n Mean squared error\
    \ (MSE)\n1\nn\n\x1Fn\ni=1(xi − ˆxi)2\n[72, 76]\n2\n Mean absolute error (MAE)\n\
    1\nn\n\x1Fn\ni=1 |xi − ˆxi|\n[61, 67]\n2\n Mean relative error (MRE)\n1\nn\n\x1F\
    n\ni=1\n|xi−ˆxi|\nxi\n[30, 67]\n2\nPage 42 of 49\nTeh et al. J Big Data      \
    \      (2020) 7:11 \nwhereas the latter uses a regression metrics such as root\
    \ mean squared error and mean \nabsolute error that would quantify the difference\
    \ in the estimated value and actual value. \nIn the 39 papers out of the 57 papers\
    \ that have quantitative measurements, Table 10 \nshows the different evaluation\
    \ metrics used in those 39 papers.\nClassification metrics\nRecall, also known\
    \ as sensitivity or true positive rate (TPR), is commonly used in error \ndetection\
    \ to calculate the number of correctly detected faults (TP) over all faults, which\
    \ \nincludes both faults that are correctly detected (TP) and faults that are\
    \ incorrectly \ndetected as a normal data point (FN). It is used as an indication\
    \ of the method’s abil-\nity to detect faults, which places more importance on\
    \ false classification of normal data \npoints, which are supposed to be faults,\
    \ i.e. false negatives. For example, if fault detec-\ntion is being used as a\
    \ data-cleaning solution for the training dataset which will then be \nused for\
    \ some other machine learning methods e.g. for prediction or analysis [31, 42],\
    \ \nincorrectly labelling a fault as a normal data point (FN) might have some\
    \ adverse effect \non the next machine learning model. Other than that, precision\
    \ is also used as a classifi-\ncation metric for fault detection. It is the number\
    \ of correctly identified faults (TP) over \nthe total faults identified, which\
    \ includes both faults that are correctly detected (TP) and \nincorrectly detected\
    \ (FP). It shows how precise the model is, by measuring in terms of \nall the\
    \ detected faults, how many of them are actual faults. Precision differs from\
    \ recall \nas it places more weight on the false positives instead, which is the\
    \ incorrect detection \nof faults. This metric might be used for example, in environmental\
    \ sensing applications \n[38] where it penalizes incorrect fault detection as\
    \ this might lead to waste of manpower, \ncost and time, as a technician might\
    \ be sent out to the deployed sensor to test and cali-\nbrate the sensor device.\n\
    The False Positive Rate (FPR), also known as the Type I error rate, is the probability\
    \ \nof a false alarm. It is the ratio of incorrectly labelling a normal data point\
    \ as a fault (FP), \nover all normal data points, either correctly or incorrectly\
    \ labelled (TN, FP). This metric \nis used when Type I errors (FP) should be given\
    \ higher weights. For example, in [59], \nFPR is used in evaluating a method for\
    \ fault detection of a continuous glucose monitor-\ning device used an artificial\
    \ pancreas system. A continuous glucose monitor should not \nraise too many false\
    \ alarms (FP) as it might cause a panic, or increase the level of distrust \n\
    towards the device. False Negative Rate (FNR), on the other hand, is known as\
    \ a Type \nII error rate or miss rate and it is the number of incorrectly labelled\
    \ faults (FN) over all \nfaults, either correctly or incorrectly labelled (TP,\
    \ FN). For applications which penalize \nType II errors (FN), this metric is used\
    \ to evaluate the proposed method. In industrial \npower plants, faults that are\
    \ incorrectly classified as normal data points (FN) might be \ndetrimental to\
    \ the system, as it might lead to a complete system failure. Thus, papers \nsuch\
    \ as [44] have used FNR as a performance metric for their method, along with FPR.\n\
    Other performance metrics for fault detection includes accuracy, F-score, and\
    \ Mat-\nthew’s correlation coefficient. The accuracy takes into account all four\
    \ categories of \nthe confusion matrix: true positives, true negatives, false\
    \ positives, and false negatives. \nHowever, for imbalanced datasets where the\
    \ class distribution is uneven, the accuracy \nmetric is not an ideal performance\
    \ measure of a model. In sensor data, there might be \nmore normal data points\
    \ than anomalous one, contributing to the true negatives, thus \nPage 43 of 49\n\
    Teh et al. J Big Data            (2020) 7:11 \n \nmaking the accuracy metrics\
    \ unfair for performance evaluation. F-score, on the other \nhand, is a function\
    \ of precision and recall which balances between the two and does not \ntake into\
    \ account the number of true negatives. However, this is also a down-side to the\
    \ \nF-score, as not including the true negatives in the calculation might give\
    \ a misleading \nresult. Moreover, both of the metrics i.e. accuracy and F-score,\
    \ do not take into account \nthe proportion of each category in the confusion\
    \ matrix.\nTo solve this, Matthew’s correlation coefficient (MCC) is a metric\
    \ that correctly con-\nsiders the ratio of the size of all four confusion matrix\
    \ categories, allowing a higher score \nonly if the model does well on both positive\
    \ and negative categories [106]. It ranges \nfrom −1 to 1, which indicates perfect\
    \ disagreement and agreement between the pre-\ndiction and actual class respectively.\
    \ An MCC score of 0 indicates a by chance result, \nwhich could be achieved by\
    \ simply guessing that there are not any faults at all. Based \non the example\
    \ discussed by Chicco [106], assume that a classifier is trained on a heav-\n\
    ily imbalanced dataset with 95 normal data and 5 anomalous data. Let the normal\
    \ data \nbe the positive class and the anomalous data be the negative class. Thus,\
    \ TP = correct \ndetection of normal data, FP = incorrect detection of fault as\
    \ normal data, TN = correct \ndetection of fault and FN = incorrect detection\
    \ of normal data as fault. Suppose a model \nthat randomly guesses all data points\
    \ as normal is built. Thus, it classifies all points as \npositive and we have\
    \ TP = 95 , FP = 5 , TN = 0 and FN = 0 . Following the formulas for \naccuracy\
    \ and F-score in Table  10, we have Accuracy = 95% and F − score = 97.44% . \n\
    However, this random guessing will be detected by MCC as it will be undefined\
    \ (since \nthe denominator will return 0), giving an indication that the classifier\
    \ is not working as \nintended, opposed to the accuracy and F-score, which gave\
    \ a false illusion that the clas-\nsifier is doing well. In another example, suppose\
    \ now the classifier does classify some \npoints as faults, where TP = 90 , FP\
    \ = 4 , TN = 1 and FN = 5 , but it poorly classifies the \nfaults as it only correctly\
    \ detects 1 out of 5 faults. The accuracy and F-score are still high, \nresulting\
    \ in Accuracy = 91% and F − score = 95.24% . However, the MCC has a value of \n\
    MCC = 0.14 , which shows that it is performing poorly and there is a low correlation\
    \ \nbetween the predicted class and the actual class. Thus, MCC is evidently more\
    \ robust \nthan the other two metrics and should be used more frequently to quantify\
    \ fault detec-\ntion method performance.\nRegression metrics\nThese metrics are\
    \ used in order to quantify the performance of methods for fault correc-\ntion\
    \ or missing data imputation. These metrics include the Mean Squared Error (MSE),\
    \ \nRoot Mean Squared Error (RMSE), Mean Absolute Error (MAE), and Mean Relative\
    \ \nError (MRE). MSE measures the average squared errors of the predicted values\
    \ com-\npared to the true values. However, squaring the error gives more weight\
    \ to large errors. \nIt is more useful when large errors are particularly unacceptable,\
    \ but might underesti-\nmate the model’s accuracy, because one large error might\
    \ increase the MSE significantly. \nRSME is the square root of MSE, which has\
    \ the same units as the quantity plotted on \nthe vertical axis, making it more\
    \ interpretable. Another metric used to evaluate the pre-\ndiction of the model\
    \ is the MAE and MRE. MAE measures the average of the absolute \nerrors between\
    \ the predicted values and true values. It is less sensitive to huge differ-\n\
    ences, unlike MSE or RMSE, as it takes the absolute value, not the square, of\
    \ the errors. \nPage 44 of 49\nTeh et al. J Big Data            (2020) 7:11 \n\
    MRE is similar to MAE, however, every data point is divided by its true value.\
    \ Thus, it \nindicates how large the absolute error is with respect to the size\
    \ of the actual data point. \nHowever, the MRE is problematic for sensor data,\
    \ for which the true measurement value \nmight be zero.\nConclusion\nThis paper\
    \ presents the results of a systematic review of sensor data quality problems.\
    \ \nIt aims to answer the following research questions: what are the different\
    \ types of errors \nin sensor data, how to quantify or detect and correct those\
    \ errors and what domains are \nthe different types of methods proposed in. The\
    \ initial search process resulted in 13,057 \npublications, and by refining the\
    \ search string through topic modelling, the final search \nstring returned 6970\
    \ publications. Through the screening of these 6970 publications, 57 \npapers\
    \ have been selected for data extraction and synthesis. The analysed publications\
    \ \ndiscuss sensor data quality problems that are caused by errors in sensor data\
    \ such as \nmissing data, uncertainty, and faults, which include outliers, bias,\
    \ constant values, stuck-\nat-zeros, and noise.\nResults also show that there\
    \ is a huge variety of methods suggested to detect or \nquantify those errors,\
    \ as well as to correct them. There are 16 different types of meth-\nods presented\
    \ for error detection, which are obtained from 32 papers out of the 57 \nselected\
    \ papers that introduced techniques for the respective problem. The two most \n\
    common approaches are principal component analysis (PCA) and artificial neural\
    \ net-\nworks (ANN). They are both used to model the normal sensor behaviour and\
    \ the newly \nobserved readings will be compared to the model to determine if\
    \ it is anomalous. Other \ntechniques for fault detection include Ensemble Classifiers,\
    \ Support Vector Machines, \nClustering, and hybrid methods.\nFor error correction,\
    \ there are ten publications that proposed methods for missing \ndata imputation\
    \ and noise correction. The most common missing data imputation tech-\nnique is\
    \ Association Rule Mining, with half of the respective papers proposing variations\
    \ \nof that approach. Other approaches comprise of k-Nearest Neighbor, clustering,\
    \ ten-\nsor-based singular value decomposition, and Probabilistic Matrix Factorization\
    \ (PMF). \nOn the other hand, 15 publications simultaneously address error detection\
    \ and correc-\ntion problems, usually termed as Fault Detection, Isolation, and\
    \ Recovery (FDIR). The \nPCA-based approach is the most common technique for FDIR,\
    \ though there are other \napproaches such as ANN, Bayesian Network, and hybrid\
    \ methods involving Kalman fil-\nter and Dempster–Shafer theory with Ontology.\n\
    However, through this systematic review, there are several challenges that are\
    \ found in \nthis research area. From the two subsections, “Datasets and error\
    \ imputation and label-\nling” and “Evaluation metrics”, it is seen that methods\
    \ from the selected literature were \nevaluated on different datasets, along with\
    \ different pre-processing conditions and fault \ninjection processes. The availability\
    \ and ease of access of the datasets also play an essen-\ntial part in helping\
    \ researchers compare and evaluate their methods with other existing \ntechniques\
    \ for a particular sensor data quality problem. The Bayesian analysis of citation\
    \ \nrates done on the 57 selected papers shows the effects of using publicly available\
    \ datasets \nfor method evaluation. There is a 99.9% probability that papers that\
    \ use publicly availa-\nble datasets have a higher citation rate than those that\
    \ used datasets that are not publicly \nPage 45 of 49\nTeh et al. J Big Data \
    \           (2020) 7:11 \n \navailable, which suggests that more people are able\
    \ to cite and compare their methods \nwith those papers due to their availability\
    \ online and easy access.\nHowever, about 68% of the datasets used for evaluation\
    \ are not publicly available nor \nreproducible. Even for the remaining 23 datasets\
    \ that are used from nine publicly avail-\nable sources, the data pre-processing\
    \ and the error introduction step, whether by man-\nual labelling or simulating\
    \ faults artificially, are done differently. Furthermore, even for \nthe same\
    \ problem domain e.g. fault detection, fault correction, or missing data impu-\n\
    tation, different classification and regression evaluation metrics are being used\
    \ to pro-\nduce a quantifiable performance measure. This provides no formal way\
    \ of comparing the \nmethods. Other than that, the use of Matthew’s correlation\
    \ coefficient is also shown to \nbe more robust towards imbalanced datasets and\
    \ optimistic misinterpretations. How-\never, only one paper from the 57 selected\
    \ papers is seen to have used that performance \nmetric.\nBoth challenges pose\
    \ a problem for this research area as they make it more difficult \nfor researchers\
    \ to compare their proposed methods with existing techniques, which \nmay lead\
    \ to counterproductive results. These two challenges show the need for an open\
    \ \nsource benchmarking system for techniques that solve sensor data quality problems.\
    \ \nThe benchmark should provide datasets complete with all the different types\
    \ of errors \n(that is either labelled or injected artificially) and a proper\
    \ scoring system that uses the \nappropriate evaluation metrics to allow comparability\
    \ of methods in terms of their per-\nformance to solve sensor data quality issues.\n\
    Abbreviations\nIoT: Internet of Things; WSNs: wireless sensor networks; PCA: principal\
    \ component analysis; PRISMA: Preferred Reporting \nItems for Systematic Reviews\
    \ and Meta‑Analyses; RQ: research question; LDA: Latent Dirichlet Allocation;\
    \ IC: inclusion \ncriteria; EC: exclusion criteria; QC: quality criteria; ISO:\
    \ International Standardization Organization; DQ: data quality; SVI: \nSensor\
    \ Validity Index; ANN: artificial neural network; TDNN: time‑delay neural network;\
    \ AANN: auto‑associative neural \nnetwork; HTM: hierarchical temporal memory;\
    \ NAB: numenta anomaly benchmark; SVM: support vector machine; \nAGO: accumulate\
    \ generating operation; ELM: extreme learning machines; SLFN: single hidden layer\
    \ feedforward neural \nnetwork; FARM: freshness association rule mining; t‑SVD:\
    \ tensor singular value decomposition; PMF: probabilistic matrix \nfactorization;\
    \ IMF: intrinsic mode functions; ARIMA: autoregressive integrated moving average;\
    \ ORKF: Outlier Robust \nKalman filter; LW‑PLS: locally‑weighted partial least\
    \ squares; HVAC: heating, ventilation, and air conditioning; GSB: Grand \nSt.\
    \ Bernard; LUCE: Lausanne Urban Canopy Experiment; UCI: University of California\
    \ Irvine; NAMOS: networked aquatic \nmicrobial observing system; PeMS: Performance\
    \ Measurement System; TasMAN: Tasmania Marine Analysis Network; TP: \ntrue positive;\
    \ TN: true negative; FP: false positive; FN: false negative; TPR: true positive\
    \ rate; FPR: false positive rate; MCC: \nMatthew’s correlation coefficient; MSE:\
    \ mean squared error; RMSE: root mean squared error; MAE: mean absolute error;\
    \ \nMRE: mean relative error.\nAcknowledgements\nThe article processing charge\
    \ was funded by the German Research Foundation (DFG) and the University of Freiburg\
    \ in \nthe funding programme Open Access Publishing.\nAuthors’ contributions\n\
    HYT conducted the systematic review which includes gathering and extracting data\
    \ from all the papers from various \ndatabases that were used for the manuscript\
    \ and wrote the first revision of the manuscript. AKL developed the data \nanalysis\
    \ model. KIW proposed the systematic review topic and research questions. KIW\
    \ and AKL provided direction for \nthe literature‑based review, structuring of\
    \ the review, and revision of the manuscript. All authors read and approved the\
    \ \nfinal manuscript.\nFunding\nNot applicable.\nAvailability of data and materials\n\
    All papers analysed in this systematic review are available in ACM Digital Library,\
    \ IEEE Xplore and ScienceDirect. All data‑\nsets mentioned are publicly available\
    \ and their links can be found as cited.\nEthics approval and consent to participate\n\
    Not applicable.\nPage 46 of 49\nTeh et al. J Big Data            (2020) 7:11 \n\
    Consent for publication\nNot applicable.\nCompeting interests\nThe authors declare\
    \ that they have no competing interests.\nAuthor details\n1 Department of Electrical,\
    \ Computer, and Software Engineering, The University of Auckland, Auckland, New\
    \ Zealand. \n2 Freiburg Materials Research Center, University of Freiburg, Freiburg,\
    \ Germany. 3 Department of Engineering Science, The \nUniversity of Auckland,\
    \ Auckland, New Zealand. \nReceived: 20 September 2019   Accepted: 12 January\
    \ 2020\nReferences\n \n1. Gubbi J, Buyya R, Marusic S, Palaniswami M. Internet\
    \ of Things (IoT): a vision, architectural elements, and future \ndirections.\
    \ Future Gener Comput Syst. 2013;29(7):1645–60. https ://doi.org/10.1016/j.futur\
    \ e.2013.01.010.\n \n2. Cisco: Cisco global cloud index: Forecast and methodology,\
    \ 2016‑2021. Whitepaper c11‑738085, Cisco Systems \nInc., San Jose, CA (2018).\
    \ https ://www.cisco .com/c/en/us/solut ions/colla teral /servi ce‑provi der/globa\
    \ l‑cloud ‑index \n‑gci/white ‑paper ‑c11‑73808 5.pdf\n \n3. Zhang P. Advanced\
    \ industrial control technology. Oxford: William Andrew Publishing; 2010. https\
    \ ://doi.\norg/10.1016/B978‑1‑4377‑7807‑6.10003 ‑8.\n \n4. Wang RY, Strong DM.\
    \ Beyond accuracy: what data quality means to data consumers. J Manag Inform Syst.\
    \ \n1996;12(4):5–33.\n \n5. Karkouch A, Mousannif H, Al Moatassime H, Noel T.\
    \ Data quality in internet of things: a state‑of‑the‑art survey. J \nNetw Comput\
    \ Appl. 2016;73:57–81. https ://doi.org/10.1016/j.jnca.2016.08.002.\n \n6. Christ\
    \ M, Krumeich J, Kempa‑Liehr AW. Integrating predictive analytics into complex\
    \ event processing by using \nconditional density estimations. In: IEEE 20th international\
    \ enterprise distributed object computing workshop \n(EDOCW). In: IEEE computer\
    \ society, Los Alamitos, CA, USA; 2016. pp. 1–8. https ://doi.org/10.1109/EDOCW\
    \ \n.2016.75843 63.\n \n7. Zhang H, Liu J, Pang A‑C. A Bayesian network model\
    \ for data losses and faults in medical body sensor networks. \nComput Netw. 2018;143:166–75.\
    \ https ://doi.org/10.1016/j.comne t.2018.07.009.\n \n8. Ye J, Stevenson G, Dobson\
    \ S. Detecting abnormal events on binary sensors in smart home environments. Perva‑\n\
    sive Mobile Comput. 2016;33:32–49. https ://doi.org/10.1016/j.pmcj.2016.06.012.\n\
    \ \n9. Li Y, Parker LE. Nearest neighbor imputation using spatial‑temporal correlations\
    \ in wireless sensor networks. \nInform Fusion. 2014;15:64–79. https ://doi.org/10.1016/j.inffu\
    \ s.2012.08.007.\n 10. Cheng R, Chen J, Xie X. Cleaning uncertain data with quality\
    \ guarantees. Proc VLDB Endow. 2008;1(1):722–35. \nhttps ://doi.org/10.14778 /14538\
    \ 56.14539 35.\n 11. Ray PP. A survey on Internet of Things architectures. J King\
    \ Saud Univ Comput Inform Sci. 2018;30(3):291–319.\n 12. Lin J, Yu W, Zhang N,\
    \ Yang X, Zhang H, Zhao W. A Survey on Internet of Things: architecture, enabling\
    \ technolo‑\ngies, security and privacy, and applications. IEEE Intern Things\
    \ J. 2017;4(5):1125–42. https ://doi.org/10.1109/\nJIOT.2017.26832 00.\n 13. Ahmed\
    \ E, Yaqoob I, Hashem IAT, Khan I, Ahmed AIA, Imran M, Vasilakos AV. The role\
    \ of big data analytics in Internet \nof Things. Comput Netw. 2017;129:459–71.\
    \ https ://doi.org/10.1016/j.comne t.2017.06.013.\n 14. Li Y, Chen J, Feng L.\
    \ Dealing with uncertainty: a survey of theories and practices. IEEE Trans Knowl\
    \ Data Eng. \n2013;25(11):2463–82. https ://doi.org/10.1109/TKDE.2012.179.\n 15.\
    \ Prathiba B, Sankar KJ, Sumalatha V. Enhancing the data quality in wireless sensor\
    \ networks ‑ a review. In: 2016 \ninternational conference on automatic control\
    \ and dynamic optimization techniques (ICACDOT). 2016;448–454. \nhttps ://doi.org/10.1109/ICACD\
    \ OT.2016.78776 26.\n 16. Kofod‑Petersen A. How to do a structured literature\
    \ review in computer science. (2015).\n 17. Silva R, Neiva F. Systematic literature\
    \ review in computer science—a practical guide. (2016). https ://doi.\norg/10.13140\
    \ /RG.2.2.35453 .87524 .\n 18. PRISMA: PRISMA—transparent reporting of systematic\
    \ reviews and meta‑analyses (2015). http://www.prism \na‑state ment.org/ Accessed\
    \ 08 Jan 2019.\n 19. Blei DM, Lafferty JD. Topic models. In: Ashok N, Srivastava\
    \ MS, editors. Text mining. Classification, clustering, and \napplications. Chapman\
    \ and Hall/CRC: New York; 2009. p. 71–93.\n 20. Zhai C. Statistical language models\
    \ for information retrieval. Synth Lectures Human Lang Technol. 2008;1(1):1–41.\n\
    \ 21. Pedregosa F, Varoquaux G, Gramfort A, Michel V, Thirion B, Grisel O, Blondel\
    \ M, Prettenhofer P, Weiss R, Dubourg V, \nVanderplas J, Passos A, Cournapeau\
    \ D, Brucher M, Perrot M, Duchesnay E. Scikit‑learn: machine learning in Python.\
    \ \nJ Mach Learn Res. 2011;12:2825–30.\n 22. Chow LS, Paramesran R. Review of\
    \ medical image quality assessment. Biomed Sign Process Contr. 2016;27:145–54.\
    \ \nhttps ://doi.org/10.1016/j.bspc.2016.02.006.\n 23. Lapini A, Argenti F, Piva\
    \ A, Bencini L. Comparison of super‑resolution methods for quality enhancement\
    \ of digital \nbiomedical images. In: 2014 8th International symposium on medical\
    \ information and communication technol‑\nogy (ISMICT). 2014. https ://doi.org/10.1109/ISMIC\
    \ T.2014.68252 43. pp. 1–5.\n 24. Sharma P, Sharma S. An analysis of vision based\
    \ techniques for quality assessment and enhancement of camera \ncaptured document\
    \ images. In: 2016 6th international conference—cloud system and Big Data engineering\
    \ \n(Confluence). 2016. pp. 425–28. https ://doi.org/10.1109/CONFL UENCE .2016.75081\
    \ 57.\nPage 47 of 49\nTeh et al. J Big Data            (2020) 7:11 \n \n 25. Bamgboye\
    \ O, Liu X, Cruickshank P. Towards modelling and reasoning about uncertain data\
    \ of sensor measure‑\nments for decision support in smart spaces. In: 2018 IEEE\
    \ 42nd annual computer software and applications \nconference (COMPSAC), 2018.\
    \ pp. 744–49. https ://doi.org/10.1109/COMPS AC.2018.10330 .\n 26. Kuka C, Nicklas\
    \ D. Enriching sensor data processing with quality semantics. In: 2014 IEEE international\
    \ conference \non pervasive computing and communication workshops (PERCOM WORKSHOPS).\
    \ 2014. pp. 437–42. https ://doi.\norg/10.1109/PerCo mW.2014.68152 46.\n 27. Dunia\
    \ R, Joe Qin S, Edgar TF, McAvoy TJ. Use of principal component analysis for sensor\
    \ fault identification. Com‑\nput Chem Eng. 1996;20:713–8. https ://doi.org/10.1016/0098‑1354(96)00128\
    \ ‑7.\n 28. Moher D, Liberati A, Tetzlaff J, Altman DG, Group TP. Preferred reporting\
    \ items for systematic reviews and meta‑\nanalyses: the prisma statement. PLoS\
    \ Med. 2009;6(7):1–6. https ://doi.org/10.1371/journ al.pmed.10000 97.\n 29. Joint\
    \ Committee Guides Metrology: evaluation of measurement data‑guide to the expression\
    \ of uncertainty in \nmeasurement (GUM 2008). 2008.\n 30. Chen Y, Jiang S, Yang\
    \ J, Song K, Wang Q. Grey bootstrap method for data validation and dynamic uncertainty\
    \ \nestimation of self‑validating multifunctional sensors. Chemometr Intell Lab\
    \ Syst. 2015;146:63–76. https ://doi.\norg/10.1016/j.chemo lab.2015.05.003.\n\
    \ 31. Feng J, Hajizadeh I, Samadi S, Sevil M, Hobbs N, Brandt R, Lazaro C, Maloney\
    \ Z, Yu X, Littlejohn E, Quinn L, Cinar A. \nHybrid online multi‑sensor error\
    \ detection and functional redundancy for artificial pancreas control systems.\
    \ IFAC‑\nPapersOnLine. 2018;51(18):138–43. https ://doi.org/10.1016/j.ifaco l.2018.09.289.\n\
    \ 32. Harkat MF, Mourot G, Ragot J. Sensor failure detection of air quality monitoring\
    \ network. IFAC Proc Vol. \n2000;33(11):529–34. https ://doi.org/10.1016/S1474\
    \ ‑6670(17)37413 ‑X.\n 33. Abuaitah GR, Wang B. Data‑centric anomalies in sensor\
    \ network deployments: analysis and detection. In: 2012 \nIEEE 9th international\
    \ conference on mobile Ad‑Hoc and sensor systems (MASS 2012), vol. Supplement.\
    \ 2012. pp. \n1–6. https ://doi.org/10.1109/MASS.2012.67085 14.\n 34. Ahmad S,\
    \ Lavin A, Purdy S, Agha Z. Unsupervised real‑time anomaly detection for streaming\
    \ data. Neurocomput‑\ning. 2017;262:134–47. https ://doi.org/10.1016/j.neuco m.2017.04.070.\n\
    \ 35. Bosman HHWJ, Iacca G, Tejada A, Wörtche HJ, Liotta A. Ensembles of incremental\
    \ learners to detect anomalies in \nad hoc sensor networks. Ad Hoc Netw. 2015;35:14–36.\
    \ https ://doi.org/10.1016/j.adhoc .2015.07.013.\n 36. Bosman HH, Iacca G, Tejada\
    \ A, Wörtche HJ, Liotta A. Spatial anomaly detection in sensor networks using\
    \ neighbor‑\nhood information. Inform Fusion. 2017;33:41–56. https ://doi.org/10.1016/j.inffu\
    \ s.2016.04.007.\n 37. Curiac D‑I, Volosencu C. Ensemble based sensing anomaly\
    \ detection in wireless sensor networks. Exp Syst Appl. \n2012;39(10):9087–96.\
    \ https ://doi.org/10.1016/j.eswa.2012.02.036.\n 38. Dereszynski EW, Dietterich\
    \ TG. Spatiotemporal models for data‑anomaly detection in dynamic environmental\
    \ \nmonitoring campaigns. ACM Trans Sen Netw. 2011;8(1):3–1336. https ://doi.org/10.1145/19930\
    \ 42.19930 45.\n 39. Fawzy A, Mokhtar HMO, Hegazy O. Outliers detection and classification\
    \ in wireless sensor networks. Egypt Inform \nJ. 2013;14(2):157–64. https ://doi.org/10.1016/j.eij.2013.06.001.\n\
    \ 40. Hill DJ, Minsker BS. Anomaly detection in streaming environmental sensor\
    \ data: a data‑driven modeling approach. \nEnviron Model Softw. 2010;25(9):1014–22.\
    \ https ://doi.org/10.1016/j.envso ft.2009.08.010.\n 41. Hou Z, Lian Z, Yao Y,\
    \ Yuan X. Data mining based sensor fault diagnosis and validation for building\
    \ air conditioning \nsystem. Energy Convers Manag. 2006;47(15):2479–90. https\
    \ ://doi.org/10.1016/j.encon man.2005.11.010.\n 42. Hu Y, Chen H, Li G, Li H,\
    \ Xu R, Li J. A statistical training data cleaning strategy for the PCA‑based\
    \ chiller sensor fault \ndetection, diagnosis and data reconstruction method.\
    \ Energy Build. 2016;112:270–8. https ://doi.org/10.1016/j.\nenbui ld.2015.11.066.\n\
    \ 43. Huang X‑h. Sensor fault diagnosis and reconstruction of engine control system\
    \ based on autoassociative neural \nnetwork. Chin J Aeronaut. 2004;17(1):23–7.\
    \ https ://doi.org/10.1016/S1000 ‑9361(11)60198 ‑2.\n 44. Ibarguengoytia PH, Sucar\
    \ LE, Vadera S. Real time intelligent sensor validation. IEEE Trans Power Syst.\
    \ \n2001;16(4):770–5. https ://doi.org/10.1109/59.96242 5.\n 45. Liu H, Chen J,\
    \ Huang F, Li H. An electric power sensor data oriented data cleaning solution.\
    \ In: 2017 14th interna‑\ntional symposium on pervasive systems, algorithms and\
    \ networks 2017 11th international conference on frontier \nof computer science\
    \ and technology 2017 Third international symposium of creative computing (ISPAN‑FCST‑\n\
    ISCC). 2017. pp. 430–5. https ://doi.org/10.1109/ISPAN ‑FCST‑ISCC.2017.29.\n 46.\
    \ Liu Y, Chen J, Sun Z, Li Y, Huang D. A probabilistic self‑validating soft‑sensor\
    \ with application to wastewater treat‑\nment. Comput Chem Eng. 2014;71:263–80.\
    \ https ://doi.org/10.1016/j.compc hemen g.2014.08.008.\n 47. Mansouri M, Harkat\
    \ M‑F, Nounou M, Nounou H. Midpoint‑radii principal component analysis—based EWMA\
    \ \nand application to air quality monitoring network. Chemometr Intell Lab Syst.\
    \ 2018;175:55–64. https ://doi.\norg/10.1016/j.chemo lab.2018.01.016.\n 48. Rassam\
    \ MA, Maarof MA, Zainal A. Adaptive and online data anomaly detection for wireless\
    \ sensor systems. Knowl \nSyst. 2014;60:44–57. https ://doi.org/10.1016/j.knosy\
    \ s.2014.01.003.\n 49. Sallans B, Bruckner D, Russ G. Statistical model‑based\
    \ sensor diagnostics for automation systems. In: Chávez, M.L., \ned. Fieldbus\
    \ systems and their applications Elsevier: Oxford; 2006. pp. 239–46.https ://doi.org/10.1016/B978‑00804\
    \ \n5364‑4/50073 ‑3. http://www.scien cedir ect.com/scien ce/artic le/pii/B9780\
    \ 08045 36445 00733 .\n 50. Sharifi R, Langari R. Nonlinear sensor fault diagnosis\
    \ using mixture of probabilistic PCA models. Mech Syst Sign \nProcess. 2017;85:638–50.\
    \ https ://doi.org/10.1016/j.ymssp .2016.08.028.\n 51. Solomakhina N, Hubauer\
    \ T, Lamparter S, Roshchin M, Grimm S. Extending statistical data quality improvement\
    \ \nwith explicit domain models. In: 2014 12th IEEE international conference on\
    \ industrial informatics (INDIN). 2014. \npp. 720–5. https ://doi.org/10.1109/INDIN\
    \ .2014.69456 02.\n 52. Tsang KM. Sensor data validation using gray models. ISA\
    \ Trans. 2003;42(1):9–17. https ://doi.org/10.1016/S0019 \n‑0578(07)60109 ‑8.\n\
    \ 53. Tsang KM, Chan WL. Data validation of intelligent sensor using predictive\
    \ filters and fuzzy logic. Sens Actuat A. \n2010;159(2):149–56. https ://doi.org/10.1016/j.sna.2010.03.013.\n\
    Page 48 of 49\nTeh et al. J Big Data            (2020) 7:11 \n 54. Xiao H, Huang\
    \ D, Pan Y, Liu Y, Song K. Fault diagnosis and prognosis of wastewater processes\
    \ with incomplete data \nby the auto‑associative neural networks and ARMA model.\
    \ Chemometr Intell Lab Syst. 2017;161:96–107. https ://\ndoi.org/10.1016/j.chemo\
    \ lab.2016.12.009.\n 55. Liu Y, Daoping H, Zhifu L. A SEVA soft sensor method\
    \ based on self‑calibration model and uncertainty description \nalgorithm. Chemometr\
    \ Intell Lab Syst. 2013;126:38–49. https ://doi.org/10.1016/j.chemo lab.2013.04.009.\n\
    \ 56. Yu Z, Bedig A, Montalto F, Quigley M. Automated detection of unusual soil\
    \ moisture probe response patterns with \nassociation rule learning. Environ Modell\
    \ Softw. 2018;105:257–69. https ://doi.org/10.1016/j.envso ft.2018.04.001.\n 57.\
    \ Zhang Y, Meratnia N, Havinga P. Adaptive and online one‑class support vector\
    \ machine‑based outlier detection \ntechniques for wireless sensor networks. In:\
    \ 2009 international conference on advanced information networking \nand applications\
    \ workshops. 2009. pp. 990–5. https ://doi.org/10.1109/WAINA .2009.200.\n 58.\
    \ Zhang Y, Meratnia N, Havinga PJM. Distributed online outlier detection in wireless\
    \ sensor networks using ellipsoi‑\ndal support vector machine. Ad Hoc Netw. 2013;11(3):1062–74.\
    \ https ://doi.org/10.1016/j.adhoc .2012.11.001.\n 59. Zhao C, Fu Y. Statistical\
    \ analysis based online sensor failure detection for continuous glucose monitoring\
    \ in type I \ndiabetes. Chemometr Intell Lab Syst. 2015;144:128–37. https ://doi.org/10.1016/j.chemo\
    \ lab.2015.04.001.\n 60. Yang J, Lin L, Sun Z, Chen Y, Jiang S. Data validation\
    \ of multifunctional sensors using independent and related vari‑\nables. Sens\
    \ Actuat A. 2017;263:76–90. https ://doi.org/10.1016/j.sna.2017.05.015.\n 61.\
    \ Chok H, Gruenwald L. Spatio‑temporal association rule mining framework for real‑time\
    \ sensor network applica‑\ntions. In: Proceedings of the 18th ACM conference on\
    \ information and knowledge management. CIKM ’09. ACM: \nNew York; 2009. pp. 1761–4.\
    \ https ://doi.org/10.1145/16459 53.16462 24. Accessed 31 Aug 2018.\n 62. D’Aniello\
    \ G, Gaeta M, Hong TP. Effective quality‑aware sensor data management. IEEE Trans\
    \ Emerg Top Comput \nIntell. 2018;2(1):65–77. https ://doi.org/10.1109/TETCI .2017.27828\
    \ 00.\n 63. Fekade B, Maksymyuk T, Kyryk M, Jo M. Probabilistic recovery of incomplete\
    \ sensed data in IoT. IEEE Intern Things J. \n2017;. https ://doi.org/10.1109/JIOT.2017.27303\
    \ 60.\n 64. Gruenwald L, Chok H, Aboukhamis M. Using data mining to estimate missing\
    \ sensor data. In: Seventh IEEE inter‑\nnational conference on data mining workshops\
    \ (ICDMW 2007), 2007. pp. 207–12. https ://doi.org/10.1109/ICDMW \n.2007.103.\n\
    \ 65. Tang J, Zhang G, Wang Y, Wang H, Liu F. A hybrid approach to integrate fuzzy\
    \ C‑means based imputation method \nwith genetic algorithm for missing traffic\
    \ volume data estimation. Transport Res C. 2015;51:29–40. https ://doi.\norg/10.1016/j.trc.2014.11.003.\n\
    \ 66. Wang Y, Wang J, Li H. An interpolation approach for missing context data\
    \ based on the time‑space relationship \nand association rule mining. In: 2011\
    \ third international conference on multimedia information networking and \nsecurity,\
    \ 2011. pp. 623–7. https ://doi.org/10.1109/MINES .2011.78.\n 67. Xu P, Ruan W,\
    \ Sheng QZ, Gu T, Yao L. Interpolating the missing values for multi‑dimensional\
    \ spatial‑temporal \nsensor data: a tensor SVD approach. In: Proceedings of the\
    \ 14th EAI international conference on mobile and ubiq‑\nuitous systems: computing,\
    \ networking and services. MobiQuitous 2017. pp. 442–51. ACM: New York; 2017.\
    \ https \n://doi.org/10.1145/31444 57.31444 74.\n 68. Hermans F, Dziengel N, Schiller\
    \ J. Quality estimation based data fusion in wireless sensor networks. In: 2009\
    \ IEEE \n6th international conference on mobile adhoc and sensor systems. 2009.\
    \ pp. 1068–70. https ://doi.org/10.1109/\nMOBHO C.2009.53370 06.\n 69. Alawi A,\
    \ Choi SW, Martin E, Morris J. Sensor fault identification using weighted combined\
    \ contribution plots. In: \nZhang H‑Y, ed. Fault detection, supervision and safety\
    \ of technical processes 2006. 2007. pp. 908–13. https ://doi.\norg/10.1016/B978‑00804\
    \ 4485‑7/50153 ‑6. http://www.scien cedir ect.com/scien ce/artic le/pii/B9780\
    \ 08044 48575 \n01536 .\n 70. Smarsly K, Law KH. Decentralized fault detection\
    \ and isolation in wireless structural health monitoring systems \nusing analytical\
    \ redundancy. Adv Eng Softw. 2014;73:1–10. https ://doi.org/10.1016/j.adven gsoft\
    \ .2014.02.005.\n 71. Tadić P, Durović Z. Particle filtering for sensor fault\
    \ diagnosis and identification in nonlinear plants. J Process Con‑\ntrol. 2014;24(4):401–9.\
    \ https ://doi.org/10.1016/j.jproc ont.2014.02.009.\n 72. Uren KR, Schoor Gv,\
    \ Rand CPd, Botha A. An integrated approach to sensor FDI and signal reconstruction\
    \ in \nHTGRs—Part I: theoretical framework. Ann Nucl Energy. 2016;87:750–60. https\
    \ ://doi.org/10.1016/j.anuce \nne.2015.06.010.\n 73. Yu Y, Li H. Virtual in‑situ\
    \ calibration method in building systems. Autom Constr. 2015;59:59–67. https ://doi.\n\
    org/10.1016/j.autco n.2015.08.003.\n 74. Wang Y, Yang A, Li Z, Wang P, Yang H.\
    \ Blind drift calibration of sensor networks using signal space projection and\
    \ \nKalman filter. In: 2015 IEEE tenth international conference on intelligent\
    \ sensors, sensor networks and information \nprocessing (ISSNIP). 2015. pp. 1–6.\
    \ https ://doi.org/10.1109/ISSNI P.2015.71069 04.\n 75. Zahedi S, Szczodrak M,\
    \ Ji P, Mylaraswamy D, Srivastava M, Young R. Tiered architecture for on‑line\
    \ detection, \nisolation and repair of faults in wireless sensor networks. In:\
    \ MILCOM 2008–2008 In: IEEE military communications \nconference. 2008. pp. 1–7.\
    \ https ://doi.org/10.1109/MILCO M.2008.47536 34.\n 76. Omitaomu OA, Protopopescu\
    \ VA, Ganguly AR. Empirical mode decomposition technique with conditional mutual\
    \ \ninformation for denoising operational sensor data. IEEE Sens J. 2011;11(10):2565–75.\
    \ https ://doi.org/10.1109/\nJSEN.2011.21423 02.\n 77. Sadıkoglu F, Kavalcıoğlu\
    \ C. Filtering continuous glucose monitoring signal using Savitzky–Golay filter\
    \ and simple \nmultivariate thresholding. Proc Comput Sci. 2016;102:342–50. https\
    \ ://doi.org/10.1016/j.procs .2016.09.410.\n 78. Jäger G, Zug S, Brade T, Dietrich\
    \ A, Steup C, Moewes C, Cretu AM. Assessing neural networks for sensor fault detec‑\n\
    tion. In: 2014 IEEE international conference on computational intelligence and\
    \ virtual environments for measure‑\nment systems and applications (CIVEMSA).\
    \ 2014. pp. 70–5. https ://doi.org/10.1109/CIVEM SA.2014.68414 41.\n 79. Rahman\
    \ A, Smith DV, Timms G. A novel machine learning approach toward quality assessment\
    \ of sensor data. IEEE \nSens J. 2014;14(4):1035–47. https ://doi.org/10.1109/JSEN.2013.22918\
    \ 55.\n 80. Richter C. Reliability assessment in everyday‑objects based physical‑activity\
    \ sensing using personal information. \nIn: Proceedings of the 8th ACM international\
    \ conference on pervasive technologies related to assistive environ‑\nments. PETRA\
    \ ’15, pp. 39–1394. ACM: New York; 2015. https ://doi.org/10.1145/27694 93.27695\
    \ 48.\nPage 49 of 49\nTeh et al. J Big Data            (2020) 7:11 \n \n 81. Wang\
    \ P, Gao RX, Tang X, Fan Z. Sensing uncertainty evaluation for product quality.\
    \ Proc CIRP. 2016;41:706–11. https \n://doi.org/10.1016/j.proci r.2015.12.105.\n\
    \ 82. Aggarwal CC. An introduction to outlier analysis. Outlier analysis. Springer:\
    \ New York; 2013. p. 1–40. https ://doi.\norg/10.1007/978‑1‑4614‑6396‑2_1.\n 83.\
    \ Ahmad NF, Hoang DB, Phung MH. Robust preprocessing for health care monitoring\
    \ framework. In: 2009 11th \ninternational conference on e‑Health networking,\
    \ applications and services (Healthcom). 2009. pp. 169–74. https \n://doi.org/10.1109/HEALT\
    \ H.2009.54061 96.\n 84. Rabatel J, Bringay S, Poncelet P. Anomaly detection in\
    \ monitoring sensor data for preventive maintenance. Expert \nSyst Appl. 2011;38(6):7003–15.\
    \ https ://doi.org/10.1016/j.eswa.2010.12.014.\n 85. Press WH, Teukolsky SA, Vetterling\
    \ WT, Flannery BP. Numerical recipes. The art of scientific computing. 3rd ed.\
    \ \nCambridge: Cambridge University Press; 2007.\n 86. Kramer MA. Autoassociative\
    \ neural networks. Comput Chem Eng. 1992;16(4):313–28. https ://doi.\norg/10.1016/0098‑1354(92)80051\
    \ ‑A.\n 87. Hawkins J, Blakeslee S. On intelligence. New York: Times Books; 2004.\n\
    \ 88. Numenta: Numenta—Home of the HTM Community (2019). https ://numen ta.org/.\
    \ Accessed 08 Jan 2019.\n 89. Fisher RA. Statistical methods for research workers.\
    \ In: Kotz S, Johnson NL, editors. Breakthroughs in statistics: \nmethodology\
    \ and distribution Springer series in statistics. Springer: New York; 1992. p.\
    \ 66–70. https ://doi.\norg/10.1007/978‑1‑4612‑4380‑9_6.\n 90. Christ M, Braun\
    \ N, Neuffer J, Kempa‑Liehr AW. Time series featuRe extraction on basis of scalable\
    \ hypothesis tests \n(tsfresh—a python package). Neurocomputing. 2018;307:72–7.\
    \ https ://doi.org/10.1016/j.neuco m.2018.03.067.\n 91. Deng J‑L. Control problems\
    \ of grey systems. Syst Contr Lett. 1982;1(5):288–94. https ://doi.org/10.1016/S0167\
    \ \n‑6911(82)80025 ‑X.\n 92. Huang G‑B, Zhu Q‑Y, Siew C. Extreme learning machine:\
    \ a new learning scheme of feedforward neural networks. \nNeural Netw. 2004;2:985–9902.\
    \ https ://doi.org/10.1109/IJCNN .2004.13800 68.\n 93. Ingelrest F, Barrenetxea\
    \ G, Schaefer G, Vetterli M, Couach O, Parlange M. Sensorscope: application‑specific\
    \ sensor \nnetwork for environmental monitoring. ACM Trans Sens Netw. 2010;6(2):17.\n\
    \ 94. Barrenetxea G. Sensorscope: Sensor Networks for Environmental Monitoring\
    \ (2018). https ://doi.org/10.5281/\nzenod o.26547 26. https ://lcav.epfl.ch/resea\
    \ rch/resea rch‑archi ves/resea rch‑archi ves‑commu nicat ions_and_senso \nr_netwo\
    \ rks_archi ve‑html/senso rscop e‑en/page‑14518 0‑en‑html/. Accessed 08 May 2019.\n\
    \ 95. Madden S. Intel Lab Data (2004). http://db.csail .mit.edu/labda ta/labda\
    \ ta.html. Accessed 08 May 2019.\n 96. Dua D, Graff C. UCI machine learning repository\
    \ (2017). http://archi ve.ics.uci.edu/ml Accessed 08 May 2019.\n 97. University\
    \ of Southern California: Networked Aquatic Microbial Observing System (NAMOS).\
    \ http://robot ics.usc.\nedu/~namos /data.html. 2002.\n 98. Numenta: the numenta\
    \ anomaly benchmark. 2019. https ://githu b.com/numen ta/NAB. Accessed 08 May\
    \ 2019.\n 99. of California S. California department of transportation: caltrans\
    \ performance measurement system; 2019. http://\npems.dot.ca.gov/. Accessed 08\
    \ May 2019.\n 100. Timms G, Sharman C, Howell B, McCulloch J, Hugo D. Tasmanian\
    \ marine analysis network—Sullivans Cove CSIRO \nWharf Sensor. 2012;. https ://doi.org/10.4225/08/50613\
    \ AE767 787. https ://data.csiro .au/colle ction s/#colle ction /\nCIcsi ro:5604v\
    \ 1. Accessed 08 May 2019.\n 101. Wren CR, Ivanov YA, Leigh D, Westhues J. The\
    \ merl motion detector dataset. In: Workshop on massive datasets \n(MD). 2007.\
    \ pp. 10–14. http://www.merl.com/publi catio ns/TR200 7‑069.\n 102. Wren C, Ivanov\
    \ Y. MERLSense Data (2009). https ://sites .googl e.com/a/drwre n.com/wmd/home.\
    \ Accessed 08 May \n2019.\n 103. PhysioNet: PhysioNet: the research resource for\
    \ complex physiologic signals (2019). https ://physi onet.org/. \nAccessed 08\
    \ May 2019.\n 104. Kruschke J. Bayesian estimation supersedes the t test. J Exp\
    \ Psychol Gen. 2012;. https ://doi.org/10.1037/a0029 146.\n 105. Salvatier J,\
    \ V Wiecki T, Fonnesbeck C. Probabilistic programming in python using pymc3. 2016.\
    \ https ://doi.\norg/10.7287/PEERJ .PREPR INTS.1686V 1.\n 106. Chicco D. Ten quick\
    \ tips for machine learning in computational biology. BioData Mining. 2017. p.\
    \ 10. https ://doi.\norg/10.1186/s1304 0‑017‑0155‑3. Accessed 17 Mar 2019.\nPublisher’s\
    \ Note\nSpringer Nature remains neutral with regard to jurisdictional claims in\
    \ published maps and institutional affiliations.\n"
  inline_citation: '>'
  journal: Journal of big data
  limitations: '>'
  pdf_link: https://journalofbigdata.springeropen.com/track/pdf/10.1186/s40537-020-0285-1
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: 'Sensor data quality: a systematic review'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.5565/rev/elcvia.68
  analysis: '>'
  authors:
  - Abdel-Ouahab Boudraa
  - Ayachi Bentabet
  - F. Salzenstein
  citation_count: 57
  full_citation: '>'
  full_text: '>

    Web Store Add shortcut Name URL Customize Chrome'
  inline_citation: '>'
  journal: Electronic Letters on Computer Vision and Image Analysis
  limitations: '>'
  pdf_link: https://elcvia.cvc.uab.cat/article/download/v4-n1-boudraa-bentabet-salzenstein/49
  publication_year: 2004
  relevance_score1: 0
  relevance_score2: 0
  title: Dempster-Shafer's Basic Probability Assignment Based on Fuzzy Membership
    Functions
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/tie.2019.2891453
  analysis: '>'
  authors:
  - Anna Stief
  - James R. Ottewill
  - Jerzy Baranowski
  - Michał Orkisz
  citation_count: 80
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Journals & Magazines >IEEE Transactions on Industri...
    >Volume: 66 Issue: 12 A PCA and Two-Stage Bayesian Sensor Fusion Approach for
    Diagnosing Electrical and Mechanical Faults in Induction Motors Publisher: IEEE
    Cite This PDF Anna Stief; James R. Ottewill; Jerzy Baranowski; Michal Orkisz All
    Authors 76 Cites in Papers 2727 Full Text Views Open Access Under a Creative Commons
    License Abstract Document Sections I. Introduction II. Methods III. Experimental
    Data IV. Implementation of the Method V. Results Show Full Outline Authors Figures
    References Citations Keywords Metrics Abstract: Induction motors are widely used
    in industrial plants for critical operations. Stator faults, bearing faults, or
    rotor faults can lead to unplanned downtime with associated cost and safety implications.
    Different sensors may be used to monitor the health state of induction motors
    with each sensor typically being better suited for diagnosing different faults.
    Condition monitoring approaches that fuse data from multiple sensors have the
    potential to diagnose a greater number of faults. In this paper, a sensor fusion
    approach based on the combination of a two-stage Bayesian method and principal
    component analysis (PCA) is proposed for diagnosing both electrical and mechanical
    faults in induction motors. Acoustic, electric, and vibration signals are gathered
    from motors operating under different loading conditions and health states. The
    inclusion of the PCA step ensures robustness to varying loading conditions. The
    obtained results highlight that the proposed method performs better than the equivalent
    single-stage or feature-based Bayesian methods. Published in: IEEE Transactions
    on Industrial Electronics ( Volume: 66, Issue: 12, December 2019) Page(s): 9510
    - 9520 Date of Publication: 13 January 2019 ISSN Information: DOI: 10.1109/TIE.2019.2891453
    Publisher: IEEE Funding Agency: CCBY - IEEE is not the copyright holder of this
    material. Please follow the instructions via https://creativecommons.org/licenses/by/4.0/
    to obtain full-text articles and stipulations in the API documentation. SECTION
    I. Introduction Induction motors are widely used in industrial plants for critical
    operations, where a failure could result in a partial or complete shutdown of
    the production process. Unplanned maintenance, downtime, or replacements can result
    in high costs and, furthermore, critical failures can have serious safety implications.
    Induction motor faults may be categorized as electrical related, mechanical related,
    or environmental related [1]. The range of possible faults is numerous, with stator,
    bearing, and rotor faults being the most prevalent [2]–[4]. These faults will
    impact the mechanical, magnetic, and electrical characteristics of the induction
    motor in different ways. As a result, the optimal sensor type for diagnosing one
    type of fault mode may not be the same as the optimal sensor to diagnose another
    fault mode. It has previously been shown that specific induction motor faults
    can be diagnosed using different sensors [5]–[8]. Vibration, acoustic, and electric
    signals are among the most commonly used sensor types for rotor and stator faults
    detection, however some sensors are more suitable for detecting specific faults
    than others [7], [8]. Nandi [5] observed that acoustic and vibration signals are
    the most sensitive for bearing fault detection, whereas electric signals are more
    sensitive to broken rotor bar faults. It has recently been shown that acoustic
    signals are suitable for bearing, stator, and rotor fault diagnostics of single-phase
    and three-phase induction motors [9], [10]. Additionally, sensors that are responsive
    to a specific fault can also provide information about other faults [6]. Hence,
    a condition-monitoring system that fuses information obtained from multiple sensor
    types can ensure that a comprehensive range of fault modes may potentially be
    detected quickly and accurately. Various condition-monitoring methods that aim
    to increase the accuracy and robustness of fault detection via sensor fusion have
    been reported. In [11], neural networks were used to fuse vibration and current
    signals in order to diagnose mechanical and electrical faults. It was shown that
    these signal types are complementary to one another and that their fusion using
    the Dempster–Shafer theory at the decision level increases the accuracy of the
    classification. A K-nearest neighbor classifier was applied in [12] using an accelerometer
    and load signals in order to diagnose bearing faults, showing that, whereas load
    signals are more useful in distinguishing healthy bearings from faulty ones and
    accelerometer signals are better at detecting the location of the fault, the best
    performance was achieved when the two signals were fused together. In [13], vibration
    and acoustic signals were fused using the Dempster–Shafer theory at the decision
    level to diagnose faults in planetary gearboxes, with the fusion resulting in
    more precise diagnostics along with reduced false and missed alarm rates. In [14],
    vibration, acoustic, and oil debris signals were fused at the feature level to
    diagnose faults in gears with principal component analysis (PCA) and independent
    component analysis. In each aforementioned case, the sensor fusion proved to increase
    the accuracy, robustness, and missed or false alarm rate of the system. Sensor
    fusion can be implemented at the data level, the feature level, and at the decision
    level. The decision on the abstraction level depends on the information carried
    by the different signals. If the signal types are significantly different and
    carry complementary information, it is advised to use decision-level fusion [11],
    [15]. A typical challenge encountered when creating decision-level fusion algorithms
    is that there are often a large number of features relative to the number of observations.
    These features can be highly correlated, which ultimately can bias the results
    of the fault detection algorithm. A common method to reduce the correlation and
    the dimensionality of the features is PCA [16], [17]. For example, in [18], the
    dimensionality of features extracted from vibration and current signals was reduced
    by PCA before applying genetic algorithms and an artificial neural network for
    classifying faults in an induction motor. It was found that the performance of
    the fault classifier was improved by adding PCA as a feature preprocessing step.
    In [19], several feature reduction and transformation methods including neighborhood
    component analysis, linear discriminant analysis (LDA), locally linear coordination,
    and PCA were compared with maximally collapsing metric learning for multiple bearing
    fault diagnosis in induction motors with particular focus given to the dimensionality
    reduction aspect. Feature reduction is also found in multistage frameworks for
    the induction motor diagnosis, for example, a recent work [20] applied PCA, LDA,
    a genetic algorithm, and the Fisher score in a hybrid strategy to obtain a reduced
    and optimized feature set from vibration signals. Another regularly observed fault
    detection problem is the varying operating conditions of the machines, which can
    originate from a change in the load or environmental conditions. In [21], it was
    concluded that the prediction performance of a support vector machine (SVM) based
    fault detection algorithm for mechanical and electrical fault detections in induction
    motors is load dependent. Different severities of stator faults were monitored
    in induction motors under changing load torque and supply voltage unbalances in
    [22], finding that the performance of a multiagent system and neural estimator
    depends on the severity of the fault. Diagnostics and prognostics methods of rotating
    machinery were reviewed in [23], highlighting the operating condition dependence
    of algorithms as an existing but an understudied area. Bayesian inference has
    been described as a suitable method for fault detection and fault classification
    in condition-monitoring systems [23], [24]. Recently, Jaramillo et al. [25] proposed
    a two-stage Bayesian inference approach to monitor the condition of a system composed
    of several subsystems. The first stage of the sensor fusion takes place at the
    subsystem level, whereas the second stage fuses the result of the first stage
    at the decision level in order to determine the health state of the whole system.
    The method was efficient in diagnosing faults in complex systems composed of interacting
    components. Existing two-stage Bayesian sensor fusion frameworks described in
    the literature [25], [26] typically set alarm thresholds according to the probability
    distributions of features and control limits. Properly tuning alarm thresholds
    can be challenging, particularly when there are a large number of features in
    the data set, or when the thresholds themselves might optimally be described as
    a function of other parameters (e.g., operating conditions). This paper is an
    extension of the previous work in which a two-stage Bayesian sensor fusion method
    was applied to the diagnosis of mechanical faults in induction motors [26]. It
    was shown that, by fusing independent diagnoses of different sensor types at the
    decision level, the false and missed alarm rates of a fault classification algorithm
    could be significantly reduced. In [26], simple linear models of expected feature
    values relative to load values were applied to account for the load dependence
    of features. Such an approach limits the generality of the solution as the loading
    of the system is also required as an input to the algorithm during training and
    testing. It was also observed that the features used for training the Naïve Bayes
    classifier were highly correlated. As previously noted, such correlations between
    features can potentially bias the fault detection algorithm toward certain diagnoses.
    In this paper, a two-stage (local and global) Bayesian method combined with PCA
    is proposed as a method for diagnosing not only mechanical but also electrical
    faults in induction motors operating under varying load and environmental conditions.
    Stator, rotor, and bearing faults are all considered. Features are extracted from
    acoustic, electric, and vibration signals recorded from an experimental system.
    PCA is used to remove the correlations that are present in the extracted features
    and reduce the influence of load conditions. At the local Bayesian stage, principal
    components of the features are fused with a Gaussian Naïve Bayes (GNB) classifier.
    At the global Bayesian stage, the results of the local stages are fused in order
    to create a final diagnosis. The generality of the algorithm is investigated by
    omitting data recorded at selected operating and environmental conditions from
    the training set and subsequently testing the trained model using the omitted
    data. The novelties of this paper are as follows. A two-stage Bayesian sensor
    fusion approach is extended by integrating PCA and GNB classifiers into the framework.
    It is known that many fault indicators are dependent on loading conditions. By
    incorporating a multivariate statistical approach into the analysis, the correlations
    between operating conditions and feature level are accounted for. It is shown
    that the resulting method is able to accurately diagnose faults even for loading
    conditions not present in the training set. In this paper, additional data addressing
    stator faults with varying severity are included into the analysis. This data
    is used to illustrate how, by fusing the different signals, it is possible to
    achieve a holistic monitoring solution that both provide greater coverage and
    greater monitoring accuracy compared to considering each sensor independently.
    Through the addition of PCA and the GNB classifier, the approach introduced in
    this paper does not require monitoring thresholds to be defined, as the posterior
    fault class probabilities are directly calculated. This paper is organized as
    follows. In Section II, the methods are introduced. In Section III, the experimental
    data are described, which were used for the validation of the methods. Section
    IV describes the implementation of the methods using the experimental data. The
    results of the proposed fault diagnosis method are presented in Section V with
    a discussion in Section VI. Finally, in Section VII, conclusions are drawn, pointing
    out the advantages, limitations of the method, and possible future work. SECTION
    II. Methods A. Principal Component Analysis PCA is a well-established method for
    feature extraction, dimensionality reduction, data compression, and data visualization
    [27]. It is a common problem in data analysis that the features or attributes
    of the observation data are highly correlated. PCA transforms the correlated features
    to a linear space where the transformed features are uncorrelated and are ordered
    in a way that the first features retain most of the variation in the data. Singular
    value decomposition or eigenvalue decomposition (EIG) are popular algorithms for
    performing PCA. Here, SVD is considered, as it is numerically more robust when
    matrices are either singular or numerically very close to singular. Furthermore,
    SVD directly provides the required scores and loadings. If X is an n × m matrix
    with rank r, with n observations and m features, SVD is defined as follows: X=UL
    A T (1) View Source where U is an n × r orthonormal matrix, L is an r × r diagonal
    matrix, and A is an m × r orthonormal matrix. UL is an n × r matrix, containing
    the transformed uncorrelated features in the principal component space, usually
    referenced as scores. A contains the principal components, sometimes called loadings.
    For further information on PCA and SVD, readers are guided to [27]. B. GNB Classifiers
    A GNB classifier is a probabilistic classifier, which assumes conditional independence
    between data that are distributed according to a Gaussian distribution. The classifier
    uses the Bayes theorem to calculate the posterior probabilities that an observation
    x t ={ x 1 , x 2 ,…, x m } belongs to class c i out of classes C={ c 1 , c 2 ,…,
    c p } in the following way: P( c i | x t )= P( c i )⋅ ∏ m j=1 P( x j | c i ) ∑
    n k=1 P( c k )⋅ ∏ m j=1 P( x j | c k ) (2) View Source where P( c i ) is the prior
    probability of an observation belonging to class c i . The classifier learns the
    P( x j | c i ) conditional probabilities that a given feature value x j belongs
    to class c i from a training dataset. By assuming a Gaussian distribution of the
    features, the conditional probabilities may be obtained using the values of mean
    and standard deviation of the labeled training data for each class as follows:
    P( x j | c i ( μ i,j , σ i,j ))= 1 σ i,j 2π − − √ ⋅ e − ( x j − μ i,j ) 2 2 σ
    i,j 2 . (3) View Source Once the posterior probabilities are calculated for all
    of the classes, the observation x t will be classified into the class that has
    the highest posterior probability. Equation (2) can be simplified by omitting
    the normalization factor in the denominator, as only the index of the maximum
    a posteriori (MAP) class is important for the classification P( c i | x t )∝ c
    predicted = P( c i )⋅ ∏ j=1 m P( x j | c i ) argmax{P( C ¯ ¯ ¯ ¯ | x t ¯ ¯ ¯ ¯
    ¯ )}. (4) (5) View Source For further reference regarding GNB classifiers, readers
    are guided to, for example, [28]–[30]. C. PCA and Two-Stage Bayesian Sensor Fusion
    The proposed two-stage Bayesian sensor fusion method combined with PCA is an extension
    of a previous work [26]. In this paper, the algorithm is updated to include a
    preprocessing PCA step. PCA was selected as it is able to mitigate feature correlation
    that can bias the likelihood calculations. It is a linear method that yields a
    reduced and uncorrelated feature set. Instead of the original features, uncorrelated
    principal components are fused using a GNB classifier. The number of principal
    components considered for each signal type is calculated using the validation
    set in a way that the performance of the algorithm is maximized while the false
    and missed alarm rates are reduced, using the detection accuracy as an optimization
    parameter. The method retains the structure of the global fusion stage on the
    decision level, as described in [26]. The advantage of applying the GNB classifier
    at the local stage is that there is no need to determine alarm thresholds and
    confidence intervals, as the GNB classifier calculates the fault class probabilities
    directly. D. Description of the Local Stage The proposed algorithm is suited for
    condition-monitoring problems where N different sensors provide measurement data
    for the determination of the health state of the system. For training, the algorithm
    requires data that has been labeled with M fault conditions. If there is a test
    set available, the data has to be split into two separate datasets for training:
    the training set and the validation set. The training set will be used for the
    training of the GNB classifiers at the local stage, whereas the validation set
    will produce the confusion matrices for the different sensor types at the global
    fusion stage. Once the data are cleaned and selected features are extracted, the
    features are split by sensor type. At this stage, the training set takes the form
    of an n × m matrix, where n is the number of observations and m is the number
    of features. The μ Ai,Sj means and σ Ai,Sj standard deviations are calculated
    for each A i feature and S j sensor type. A normalization step transforms the
    features such that the means are 0 and the standard deviations are 1. PCA calculates
    the S C Sj scores and L O Sj loadings for each sensor type. The scores, which
    might also be considered as the new “features,” are uncorrelated. The L O Sj loadings
    are calculated using the whole training set containing both healthy and faulty
    data. To calculate the conditional probabilities of the GNB according to (3),
    the μ Ai,Sj,Ck means and σ Ai,Sj,Ck standard deviations of the principal components
    are calculated for each C k fault type in the labeled data. Next, the validation
    set is used in both to find the optimal number of principal components and to
    calculate the confusion matrices using μ Ai,Sj , σ Ai,Sj , μ Ai,Sj,Ck , σ Ai,Sj,Ck
    , and L O Sj from the training data. The features in the validation set are normalized
    using μ Ai,Sj and σ Ai,Sj . The normalized features are transformed to the principal
    components space using the L O Sj loadings. To find the number of principal components
    for each S j sensor type, an iterative step is considered as follows. The first
    i principal components are used as features, calculating the posterior probabilities
    and class predictions for each observation in the validation set using (3)–(5).
    Count the correct predictions and save it for i. Once the iteration has finished,
    the value of i resulting in the highest number of correct predictions is chosen
    for the number of principal components used to calculate the predictions for each
    observation in the validation set. E. Description of the Global Stage The prediction
    counts for each fault type are organized in an M × M global confusion matrix G
    Si for each sensor type S i where the rows represent the actual condition, the
    columns represent the diagnosed condition, and the prediction counts by rows are
    divided by the total number of actual conditions for the fault type. The matrix
    elements can be interpreted as P( F i | F j ) conditional probabilities; given
    that the algorithm predicted F j , what is the probability that the actual fault
    condition is F i ? The P( F i | F i ) probabilities, located along the diagonal
    of the confusion matrix for each sensor type, represent the probability that the
    sensor diagnosed the corresponding fault correctly G S i = ⎡ ⎣ ⎢ P( F 1 | F 1
    ) … P( F M | F 1 ) … P( F i | F i ) … P( F 1 | F M ) … P( F M | F M ) ⎤ ⎦ ⎥ .
    (6) View Source The test set is separate from the training set and is divided
    by sensor type into N sets, with observations in rows and features in columns.
    The test set is normalized and the GNB classifier is calculated with the optimized
    number of principal components. The fault class predictions of the GNB classifier
    for an observation are fused by (7) and (8) using the appropriate columns from
    the global confusion matrices for each sensor type. P( c i ) represents a priori
    knowledge; if no prior distribution is available, a uniform distribution is supposed.
    If the fault class predicted by S1 is F i and fault class predicted by S M is
    F j , then columns have to be selected in the following way from the corresponding
    confusion matrices: G S 1, F i = c predicted = ⎡ ⎣ ⎢ P( F 1 | F i ) … P( F M |
    F i ) ⎤ ⎦ ⎥ ,…, G S M , F j = ⎡ ⎣ ⎢ P( F 1 | F j ) … P( F M | F j ) ⎤ ⎦ ⎥ argmax{P(
    c i )⋅ ∏ i=1,j=1 M,N G S i, F j }. (7) (8) View Source For each fault class, the
    output of the global fusion step is a posterior probability giving the likelihood
    of that fault class being present in the system. For the purposes of evaluating
    the performance of the algorithm, we consider the final prediction as being the
    fault class that has the highest posterior probability after the global fusion
    step (8). F. Testing an Observation The overall flow diagram of the proposed two-stage
    Bayesian sensor fusion method for testing an observation is shown in Fig. 1. At
    the local stage, each type of sensor is handled separately. For a given sensor
    type, features are fused in order to obtain a prediction of the most likely health
    state of the system, given the data recorded by that sensor type. At the global
    stage, the predictions of the most likely health state for each sensor type are
    fused using the global confusion matrix to create the global diagnosis result.
    Fig. 1. Structure of the PCA and two-stage Bayesian algorithm. Show All SECTION
    III. Experimental Data The measurement set up for the experiment is shown in Fig.
    2. Experimental data were collected from three identical induction motors, differing
    only in terms of health state: one motor was healthy, one had two broken rotor
    bars, and one had an outer raceway fault in a bearing. It was also possible to
    seed stator faults into the nominally healthy motor, as described in [31]. The
    test motors were 0.8 kW, four-pole SZJKe 14a induction motors manufactured by
    TAMEL with a nominal rotor speed of 1400 r/min. The nominal values of voltage,
    current, rated torque, and power factor for these motors were 380 V, 2.2 A, 5.45
    N·m, and 0.74, respectively. The motor had a Y winding configuration with 4 coils
    per phase, 22 rotor bars, and 24 stator slots. The rotor inertia was 0.0025 kg·m2
    and the motor bearings were SKF type 6304 ZZ CXSQ. An eddy current brake was used
    to load the motor. The measurements were conducted at steady-state operation under
    different loading conditions. For each fault case between three and five loading
    conditions were tested, resulting in stator currents of 68%, 81%, 90%, 100%, and
    113% of nominal values. Measurements were recorded both with and without background
    noise generated by a separate shaker. Datasets for eight different health conditions
    were recorded, denoted as F0–F7, as follows: F0—Healthy motor; F1—Stator fault:
    Phase one bypassed in the first phase; F2—Stator fault: Phase one bypassed in
    half of the first phase; F3—Stator fault: Phase–phase short circuit; F4—Stator
    fault: Phase–phase short circuit with an offset point; F5—Stator fault: Break
    of half of the phase one; F6—Rotor fault: Two broken rotor bars; F7—Bearing fault:
    Outer raceway defect. Fig. 2. Schematic of the experimental system. Show All The
    tested motor was rewound in such a way that instead of coils for a given phase
    being directly connected to one another, the individual coils were connected to
    a switchboard allowing the winding configuration to be quickly changed. Furthermore,
    in six coils, special taps were created in order to allow different short circuits
    to be seeded. Such a configuration allows various stator faults to be seeded,
    as was investigated in [29] for the same SZJKe 14a induction motor. For F1 and
    F2, the first phase was bypassed by a 15 Ω resistance causing a short circuit
    in the first phase winding. For F3 and F4, a short circuit of two stator phases
    in the taps connected in the middle of the first coils was seeded by adding a
    115 Ω resistance. In the case of F5, part of the coil was not connected causing
    asymmetry in the winding, so that the current did not flow through a part of the
    winding. The two broken rotor bars (F6) were located next to one another. The
    bearing fault (F7) was caused by an incision through the outer ring of the bearing.
    Acoustic, electric, and vibration signals were collected using five different
    sensor types. Three G.R.A.S. 46AE microphones were used to measure the sound pressure
    levels. A Model USP regular three-dimensional Sound Intensity Microflown probe
    was also used to collect acoustic signals from the motors. The probe provided
    four measurement signals, three particle velocity signals in three orthogonal
    directions and a sound pressure signal. The vibration signals were measured by
    a three-axis PCB ICP accelerometer Model No. 356B18 and a one-axis PCB ICP accelerometer
    Model No. 353B32, providing four signals in total in unit g. The three phase voltages
    were measured by LV 25-P voltage transducers providing signals directly for analysis
    of voltage characteristics. The motor currents were measured by LTS-6NP and LEM
    HY 5-P current transducers. The following signals were collected using a 16-channel
    LMS Scada Mobile System: 4 microflown signals, 3 microphone signals, 2 current
    signals, 4 vibration signals, and 3 voltage signals. Data were collected with
    a 51.2-kHz sampling rate to capture all frequencies of interest with 30 s of data
    being recorded for each configuration to capture a sufficiently long steady-state
    periods for analysis. 58 datasets were obtained: one for each tested loading condition,
    both with and without additional background noise. The same background noise was
    applied over the tests. The microflown axis X probe has measured an average 47.26
    m/s particle velocity with no noise, whereas it has measured an average 88.69
    m/s particle velocity with noise for the healthy motor under nominal load. SECTION
    IV. Implementation of the Method The 58 datasets were split into 0.5-s observations
    resulting in 60 observations for 1 dataset and 3480 observations in total. For
    each signal, and for each 0.5-s observation, the following time-domain features
    were extracted: root mean square (rms), skewness, kurtosis, maximum peak, peak-to-peak,
    and crest factor. Features were also extracted from both the amplitude spectrum
    and the envelope spectrum of the signal: the frequency center, spectrum area,
    the amplitude of the components at the first two harmonics of the supply frequency
    (50, 100), the first three harmonics of the rotation speed (1×, 2×, 3×), the amplitude
    ratios (2×/1×, 3×/1×), and the amplitude at the sidebands of the supply frequency
    (50 Hz ± 2 × slip, 50 Hz ± rotation speed). The 0.5-s window length provided a
    2-Hz spectral resolution. While no windowing functions were applied in the calculation
    of the spectra, edge effects were found to be minimal. In total, 30 features were
    extracted for the 16 signals, resulting in 480 features in total. These time-
    and frequency-domain features are standard metrics, commonly used for the condition
    monitoring of induction motors [11], [21], [32]. It should be noted that for all
    signal types, all of the above-mentioned feature types were extracted. No additional
    feature selection approaches were applied. Fig. 3 shows the relative rms values
    of five different signal types extracted from 0.5-s measurement windows, for all
    observations through the 58 datasets. It may be observed that the sensors reacted
    to the fault modes and loading conditions in different ways. For example, the
    rms current is increased for stator fault modes F3 and F4, whereas the rms vibration
    did not significantly react. Conversely, in the case of the rotor fault F6, the
    vibration signal exhibited increased rms values, whereas the rms current did not
    show significant increases. This further illustrates that different faults are
    more easily diagnosed by different sensors. The 480 features of the 3480 observations
    were grouped by signal types into five groups, namely vibration features, current
    features, microflown features, microphone features, and voltage features. The
    data were then split into a training set, a validation set, and a test set, in
    the same way for the five signal types. The division is described in Section V.
    The training sets were used to train the local stage, the validation sets were
    used to calculate the global confusion matrices for the global fusion stage, and
    finally, the test sets were used to test the performance of the algorithm. All
    analyses were conducted in MATLAB. Fig. 3. Relative rms values of 5 different
    signal types extracted from 0.5-s measurement windows, for all observations through
    the 58 datasets. Show All SECTION V. Results In order to illustrate the performance
    of the described algorithm with respect to different loading and environmental
    noise conditions, the experimental data were divided into different training,
    validation, and test sets. In Test Case A, a random split was applied. In Test
    Cases B and C, eight entire datasets (one from each fault case) were included
    in the test set with no datasets from experiments conducted at this loading condition
    being considered in the training or validation sets. In Test Case B, the lowest
    load datasets with no background noise are the test set. In Test Case D, the highest
    load datasets with background noise are the test set. The aim of testing different
    divisions for testing, validation, and training is to observe the performance
    of the algorithm under different operating conditions, particularly under loading
    conditions that were not considered during model training. A. Test Case A: Random
    Split Test Case A was used to evaluate the overall performance of the algorithm.
    The total 3480 observations were randomly split into training set, validation
    set, and test set with a respective ratio of 60-20-20%. The random split was applied
    100 times and the averaged results are shown in Table I. The columns represent
    the conditions diagnosed by the algorithm, whereas the rows represent the actual
    fault conditions of the motors. The healthy motor was correctly diagnosed in 94%
    of the cases with a 6% false alarm rate in case of F2 stator fault. Missed alarms
    are present for F2, however it is only 2%. F2 is the least severe fault among
    the seven seeded faults, which explains this behavior. The successful detection
    rate is above 98% for all fault cases, with 100% success rate for F1, F5, F6,
    and F7. Among the stator faults, the following scenario can be observed: F3 and
    F4 are sometimes misdiagnosed as each other, as they are the variations of the
    same fault: F3 is the phase–phase short-circuit, whereas F4 is the phase–phase
    short circuit with an offset point. To give an overall measure of the test accuracy,
    the F1 score is calculated to be 99.32%. TABLE I Test Case A: Random Split B.
    Test Case B: Lowest Load and No Noise In Test Case B, the test set was formed
    of data taken from the lowest loading conditions, with no datasets from experiments
    conducted at this loading condition being considered in the training or validation
    sets. The aim was to test the performance of the algorithm under load conditions
    that are lower than those contained within the training and validation sets. The
    results are shown in Table II. The accuracy of the algorithm was 100% when diagnosing
    the healthy condition (F0); there were no false alarms. When diagnosing broken
    rotor bars and bearing faults (F6 and F7), the algorithm performed with 100% accuracy.
    However, the performance for the stator faults needs further analysis: while faults
    F1 and F3 are diagnosed with the success rates of 97% and 100%, faults F2, F4,
    and F5 were identified less reliably. The algorithm was able to diagnose the F2
    stator fault in only 57% of the cases. In 43% of the cases, the algorithm misdiagnosed
    F2, either as healthy or as the other similar stator faults F1 and F5. This was
    because F2, as the least severe fault, was the most difficult to diagnose. The
    algorithm was also unable to distinguish between fault modes F4 and F5, in 20%
    and 13% of the cases, respectively. F5 was also mistakenly diagnosed as other
    stator faults phase one bypassed in 10% of the cases. This result indicates that
    in the case of loading conditions lower than those seen in the training datasets,
    the algorithm can accurately determine the type of fault, however it is unable
    to accurately ascertain the severity of the fault. TABLE II Test Case B: Lowest
    Load and No Noise C. Test Case C: Highest Load With Noise Test Case C used datasets
    recorded for the highest loading conditions with background noise as the test
    set, with no data from this loading condition being considered in the training.
    This test case investigates the performance of the algorithm for loading conditions
    exceeding those considered in the training set and for unique environmental conditions,
    specifically when the background noise is at increased levels. The results are
    shown in Table III. The correct diagnosis of the healthy motor was 100%, as well
    as the diagnosis for F1, F4, F5, F6, and F7. In case of stator fault F2, there
    is a 2% missed alarm rate. In case of stator fault F3, the algorithm misdiagnoses
    F3 as F4 in 8% of the cases. These phenomena are similar to those observed in
    Test Case A: the stator faults are less severe and less easy to diagnose. Due
    to fault similarities, the algorithm can sometimes misdiagnose stator fault severities
    or confuse them with the healthy motor. The F1 score is 99.88%, which is even
    higher than the random split test case. TABLE III Test Case C: Highest Load With
    Noise D. Principal Components The number of principal components is shown in Table
    IV for each signal type together with the variance explained to complement the
    results in the above-presented test cases. In case of the random split in Test
    Case A, the variance explained by the chosen principal components is always above
    90%. In case of Test Case B and C, the number of chosen principal components is
    less than for Test Case A. This is due to the specific loading and noise conditions
    chosen for the test sets. TABLE IV Number of Principal Components and Variance
    Explained The first few principal components have been analyzed for all signal
    types to determine if there is any feature that dominates the principal component
    coefficients in the loading matrix. It was found that there was no single feature
    that would stand out for any signal type, therefore the importance of PCA for
    correlation reduction is further confirmed. Fig. 4 shows the first principal components
    of the five signal types, for all observations through the 58 datasets. The principal
    component values were obtained from the normalized feature values as described
    in Section II-D. In comparison to Fig. 3, where the rms of the five signal types
    are shown, it may be observed that the load dependence of the signals is less
    evident in the principal components. This further justifies the application of
    PCA for problems where the analyzed problem contains data from several loading
    conditions. Fig. 4. First principal components of the 5 different signal types,
    for all observations through the 58 datasets, the rms of the current is given
    as reference for the loading conditions. Show All Fig. 5 presents the histograms
    and underlying Gaussian distributions of the first principal component of the
    vibration signal by fault conditions. The distributions for each fault types have
    distinct mean and variance values and are not significantly different from Gaussian
    distributions. It can be observed that F6 and F7 are the most distinguishable
    from F0, whereas the other stator faults have overlaps with F0. It should be noted
    that F0 shows the evidence of multimodal behavior. This is due to the additional
    background noise incorporated to investigate the influence of different environmental
    conditions on the accuracy of diagnosis. However, as shown in Sections V-A–V-C,
    this noise did not significantly influence the resulting likelihood calculations.
    Fig. 5. Histograms and underlying normal distributions of the first principal
    component of the vibration signal by fault conditions. Show All E. Single-Stage
    Data Fusion A comparison of the performance of the two-stage approach relative
    to a more standard single-stage approach, where sensors are not separated according
    to type, but instead all fused in a single stage, was performed. The total 3480
    observations were randomly split according to the conventional 70–30% partition
    to training set and test set. The random split was applied 100 times to a single-stage
    approach and the averaged results are shown in Table V. The results show that
    the performance of the single-stage algorithm significantly drops compared to
    the results of the two-stage method shown in Table I. The most significant difference
    appears in the reduced successful detection of the healthy motor, with the single-stage
    approach yielding false alarms in 91% of test cases. The F1 score is 92%. TABLE
    V Single-Stage Data Fusion F. Comparison of Results With SVM To provide a quantitative
    comparison with another classifier, the proposed PCA and two-stage Bayesian method
    is compared with the well-known SVM. Test Case A, B, and C are repeated using
    the default fitcecoc MATLAB implementation of the SVM for multiclass problems
    with one against one classification strategy and a linear kernel function. The
    F1 scores are compared. Similarly to the investigation described in Section V-F,
    the SVM was applied in a single stage. A 70-30% data split was applied and repeated
    100 times resulting in a 99.96% F1 score for Test Case A. This result is 0.64%
    better than that of the proposed method. For Test Case B, the F1 score for the
    SVM was 96.15%, which is 1.84% below than what was achieved with the newly proposed
    method. For Test Case C, the F1 score for the SVM was 97.8%, which is 2.08% below
    than what was achieved with the newly proposed method. While the performance of
    the two approaches is comparable, an advantage of PCA and two-stage Bayesian method
    lies in its transparency and modularity. Furthermore, the method also provided
    a marginally improved performance in the case of environmental and loading conditions
    not contained in the training set, as shown in Test Cases B and C. G. Signal Types
    Separately Versus Two-Stage Fusion Table VI shows the performance of only considering
    a single-stage fusion of features from a single-signal type, for the random split
    Test Case A. For comparison, the equivalent performance from the two-stage approach,
    which fuses the data from all sensors types in the global fusion stage, is also
    given. Results are given in terms of proportion of correct diagnoses, which are
    equivalent to the values on the diagonal of the previously presented results (see
    Tables I–III). It is evident that the two-stage data fusion of multiple signal
    types outperforms the equivalent results when only considering a single-signal
    type. This is due to the fact that the different sensor types have different strengths
    and weaknesses. For example, it may be observed that the analysis based only on
    vibration signals accurately diagnosed the mechanical bearing fault F7 in 100%
    of test cases, but was only able to diagnose an electrical stator fault, such
    as F1, in 92% of cases. In contrast, when only current signals were considered,
    stator fault F1 was diagnosed correctly in 98% of cases, but bearing fault F7
    was only diagnosed correctly in 96% of cases. When the two signals are fused,
    the conditional probabilities in the global confusion matrix effectively gives
    greater weight to vibration signals and less weight to current signals when diagnosing
    mechanical faults and vice versa in the case of diagnosing electrical faults.
    This leverages the strengths of each sensor type for fault monitoring and minimizes
    the impact of the weaknesses. TABLE VI Proportion of Correct Diagnoses for Each
    Fault Type When Considering Each Signal Individually and After Two-Stage Fusion
    SECTION VI. Discussion In this section, the results and the structure of the algorithm
    are discussed further, highlighting the observed strengths and weaknesses of the
    algorithm. A. Implementation and Constraints The training of the method takes
    place offline using historical datasets containing healthy and faulty data. Once
    the model is trained, diagnosis can be performed either online or offline. By
    applying a sliding window of the same size as used for training, the new sensor
    measurements can be fed into the two-stage Bayesian classifier online after the
    feature extraction and PCA steps have been performed. The width of the window
    could be different based on the nature of the monitored system, the extracted
    features, and the data available. The computational complexity of the classifier
    is proportional to the number of principal components retained and the number
    of fault modes monitored. The computational complexity of the feature extraction
    and PCA step depends on the number of features extracted and the size of the sliding
    window. For a better representation of the original feature space, nonlinear multivariate
    methods, such as kernel PCA [33], could be explored in the future instead of the
    currently used linear PCA. While it falls out of the scope of this paper, it should
    also be noted that the features used as inputs to the method may also be refined
    according to state of the art signal processing and feature extraction methods
    so that they may better discriminate between different health states. Thus, the
    accuracy and reliability of the approach would likely be improved further. In
    (4) and (8), the likelihoods might result in very small values if the number of
    features m, the number of sensors N, or the number of fault cases M is large.
    To avoid numerical problems, a logarithmic formulation might be considered. B.
    Algorithm Validation In Section V, three different algorithm validation test cases
    were presented by splitting the data into different training sets, test sets,
    and validation sets. It has been shown that for small datasets, the simple split-sample
    estimates can be biased and cross validation is more suitable for the prediction
    assessment of the classifiers [34]. In the case of a two-stage method, cross validation
    is unfeasible due to the increase in the number of computational steps associated
    with the addition of the global fusion stage and the use of a validation set.
    Specifically, relative to a simple single-stage fusion, when implementing cross
    validation on a two-stage approach, the method becomes n2 more computationally
    expensive, where n is the number of the observations, as both the local and the
    global stages have to be trained using separate training sets. In this paper,
    a pragmatic split-sample method was considered. It is also foreseen that such
    an approach would be applicable for applications of the method with larger volumes
    of datasets available. In the future, increases in computing power might also
    allow the cross-validation approach to be feasibly applied. C. Naïve Bayes Classifier
    Using Kernel Density Estimate (KDE) The GNB classifier is a parametric method
    that assumes a normal distribution of the observation variables. The more the
    distribution of the observation variables differs from the normal distribution,
    the less accurate the method is. One possible way to eliminate this Gaussian assumption
    is to use a naïve Bayes classifier with KDE, where the probability density function
    of the features are estimated using a nonparametric kernel distribution. Such
    an approach can be used when there is no prior knowledge regarding the distribution
    of the data, no assumptions are made, or a parametric distribution cannot describe
    the data. Tests conducted using such a naïve Bayes classifier with KDE, with the
    same random split as described in Test Case A, yielded comparable results to the
    GNB classifier. The naïve Bayes classifier with KDE resulted in correct classification
    rates in the ±2% range compared to the results in Table I, whereas the F1 score
    is 99.64%, which is 0.32% better compared to the results in Table I. However,
    when applying KDE, the computation time was two magnitudes greater for the local
    stage than for the case of the GNB classifier. It took 4.277 s for the original
    method to train the local stage and obtain the confusion matrixes for the vibration
    signals, whereas the same computation took 351.78 s with KDE. The processing hardware
    was an Intel Core i5-4300U, 1.9 GHz. D. Two-Stage Data Fusion Without PCA While
    not the primary focus of this paper, it is worth noting that an investigation
    into the importance of incorporating the PCA step into the algorithm was also
    performed. It was observed that when the PCA step was omitted from the algorithm,
    all test cases, including fault cases, were subsequently diagnosed as being healthy
    (F0). This was due to the load dependence of the features. This observation indicates
    that a PCA step, or similar, ensures that the algorithm is robust against changing
    loading and environmental conditions. E. Advantages of the Method The preceding
    sections provide quantifiable comparisons of the performance of the algorithm
    when including the novel steps of applying a GNB classifier and splitting the
    approach into two stages, relative to the cases when the steps are omitted. Due
    to the multitude of ways of properly designing and tuning various algorithms,
    it is unfeasible to perform similarly rigorous quantitative comparisons to benchmark
    the method relative to other data-driven fault detection methods. However, qualitative
    comparisons, which can guide design decisions at an early stage of the analytics
    development process, can be made. The main advantages of the proposed method are
    its transparency and modularity. In contrast to many other data-driven fault diagnosis
    methods, such as SVMs or neural networks, the decision-making process of the algorithm
    is easily back traceable from the global predictions to the inputs of the local
    stage to identify how the different sensors reacted to a fault. Such transparency
    is important for cases where the algorithm will be used to support maintenance
    decisions. While in this paper, only MAP probabilities were considered, in practice,
    the Bayesian sensor fusion approach allows the results to be presented in the
    form of likelihoods, showing the probability of each fault condition being present.
    Again, this additional insight can support maintenance decisions. The modularity
    of the approach, achieved by splitting the data fusion into two stages, also offers
    further advantages when considering practical implementation. In the case of a
    sensor being removed from a system, there is no need to retrain the whole model,
    as the removed sensor type can easily be omitted from the decision-level fusion.
    This is not possible for other fault diagnosis methods that only consider feature-level
    data fusion. Similarly, additional sensor types may be readily incorporated into
    the analysis with limited requirements for retraining. Recently, a trend of monitoring
    the health of components via signals recorded from connected elements, for example,
    monitoring gearboxes and bearings via electrical signals recorded from connected
    electrical motors, has emerged [35], [36]. Such emerging methods could also easily
    be incorporated into the algorithm, serving as an additional source of information
    for further improving the accuracy of diagnosis. SECTION VII. Conclusion In this
    paper, the performance of a newly proposed PCA and two-stage Bayesian sensor fusion
    method was evaluated under various test scenarios. The algorithm was shown to
    be able to diagnose stator faults, broken rotor bar faults, and bearing faults
    in induction motors, with low false and missed alarm rates. The algorithm also
    proved its ability to diagnose faults under different loading and environmental
    conditions. In addition to discussing the several advantages of the presented
    method, the limitations of the method were also highlighted. For example, it was
    shown that the method is capable of correctly distinguishing different types of
    fault, however, to consistently distinguish between different fault severities,
    adequate training sets are required at comparable loading conditions. In the future,
    the algorithm can potentially be extended so that it may be used not only with
    steady-state signals. Additionally, the performance of the method may be refined
    by further tailoring the extracted features to the monitored system. It was shown
    that by fusing data recorded from different sensor types, the proposed method
    is capable of diagnosing both mechanical and electrical faults. In the future,
    the algorithm should also be tested for other fault detection and condition-monitoring
    scenarios, for example, in process-monitoring applications. ACKNOWLEDGMENT The
    authors would like to thank M. Sułowicz, K. Weinreb, J. Petryna, and A. Dziechciarz,
    from Cracow University of Technology, and W. Batko, M. Kłaczyński, J. Wierzbicki,
    T. Wszołek, and J. Frączek, from AGH University of Science and Technology, for
    carrying out the measurement campaign. Authors Figures References Citations Keywords
    Metrics More Like This Fault detection and diagnosis using Principal Component
    Analysis of vibration data from a reciprocating compressor Proceedings of 2012
    UKACC International Conference on Control Published: 2012 Rotating machine fault
    detection using principal component analysis of vibration signal 2016 IEEE AUTOTESTCON
    Published: 2016 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase
    Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS
    PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA:
    +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE
    Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE transactions on industrial electronics (1982. Print)
  limitations: '>'
  pdf_link: https://ieeexplore.ieee.org/ielx7/41/8784422/08611306.pdf
  publication_year: 2019
  relevance_score1: 0
  relevance_score2: 0
  title: A PCA and Two-Stage Bayesian Sensor Fusion Approach for Diagnosing Electrical
    and Mechanical Faults in Induction Motors
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1016/j.medengphy.2016.12.011
  analysis: '>'
  authors:
  - Rachel King
  - Emma Villeneuve
  - Ruth White
  - R. Simon Sherratt
  - William Holderbaum
  - William Harwin
  citation_count: 129
  full_citation: '>'
  full_text: '>

    Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords 1. Introduction 2. Wearable sensors 3. Data
    fusion 4. Data fusion algorithm overview 5. Applications of data fusion for health
    monitoring 6. Discussion and further considerations 7. Conclusions Conflict of
    interest Acknowledgements References Show full outline Cited by (129) Figures
    (1) Tables (4) Table 1 Table 2 Table 3 Table 4 Medical Engineering & Physics Volume
    42, April 2017, Pages 1-12 Application of data fusion techniques and technologies
    for wearable health monitoring Author links open overlay panel Rachel C. King
    a, Emma Villeneuve b, Ruth J. White a, R. Simon Sherratt a, William Holderbaum
    a, William S. Harwin a Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.medengphy.2016.12.011
    Get rights and content Under a Creative Commons license open access Highlights
    • This paper emphasises the growth of interest in wearable technologies that are
    leading to a paradigm shift in personalised healthcare through continuous monitoring
    using body worn sensors. • Data fusion techniques are discussed that provide the
    means to combine data from wearable sensors to infer our activities, at varying
    levels of detail. • This paper studies the attributes of commercial devices in
    light of a continuously changing landscape. • The key challenges that still need
    to be addressed are discussed so as to advance the understanding of what is needed
    to create truly pervasive and invisible wearable health sensing systems. Abstract
    Technological advances in sensors and communications have enabled discrete integration
    into everyday objects, both in the home and about the person. Information gathered
    by monitoring physiological, behavioural, and social aspects of our lives, can
    be used to achieve a positive impact on quality of life, health, and well-being.
    Wearable sensors are at the cusp of becoming truly pervasive, and could be woven
    into the clothes and accessories that we wear such that they become ubiquitous
    and transparent. To interpret the complex multidimensional information provided
    by these sensors, data fusion techniques are employed to provide a meaningful
    representation of the sensor outputs. This paper is intended to provide a short
    overview of data fusion techniques and algorithms that can be used to interpret
    wearable sensor data in the context of health monitoring applications. The application
    of these techniques are then described in the context of healthcare including
    activity and ambulatory monitoring, gait analysis, fall detection, and biometric
    monitoring. A snap-shot of current commercially available sensors is also provided,
    focusing on their sensing capability, and a commentary on the gaps that need to
    be bridged to bring research to market. Previous article in issue Next article
    in issue Keywords Wearable technologyData fusionHealth monitoringSensors 1. Introduction
    Many countries, including the United Kingdom, have an ageing population, with
    an increase in the average age and proportion of older people [1]. In 2010, there
    were approximately 10 million people over the age of 65 in the United Kingdom,
    with this number projected to rise by over 50% by 2020 [2]. One consequence of
    the ageing population is an increase in life expectancy implying greater healthcare
    needs. However, the relationship between age and dependency is complicated and
    not determined by age alone. Indeed, the risk factor profile of those born more
    recently is worse than previous generations [3]. This can be attributed, in part,
    to the link between economic development and increased risky behaviours [4]. Risk
    factors such as tobacco and alcohol use, inactivity, and poor diet choices are
    associated with chronic diseases including obesity, cardiovascular disease, and
    diabetes [4]. Recent advances in wearable technology including microelectromechanical
    (MEM) devices, physiological sensors, low-power wireless communications, and energy
    harvesting, have set the stage for a significant change in health monitoring.
    Technology can be discreetly worn and used as a means to monitor health and potentially
    enable older adults to live safely and independently at home. Early detection
    of key health risk factors enables more effective interventions to reduce the
    impact of, or even avoid, serious or chronic illness. Inertial measurement devices,
    such as accelerometers, represent a range of sensors that can be used for healthcare
    monitoring and are being extensively investigated for the monitoring of human
    movement [5] and daily activity [6]. Another application for wearable systems
    is rehabilitation [7]. There are also currently many systems commercially available
    for the monitoring of sports and some aspects of health. The richness of data
    available using wearable sensors presents challenges in the way that it is processed
    to provide accurate and relevant outputs. To fully exploit this data for the purposes
    of healthcare monitoring, data fusion techniques can be employed to make inferences
    and improve the accuracy of the output. Hall and Llinas [8] provide a detailed
    introduction and discussion to multisensor data fusion. A review of data fusion
    techniques is also provided by Castanedo [9] including the different categories
    of data fusion techniques. With a focus on body sensor networks, Fortino et al.
    [10] discuss wearable multisensor fusion with an emphasis on collaborative computing.
    This paper introduces wearable sensors for human monitoring in the context of
    health and well-being, including a snap shot of current commercial wearable sensor
    systems. An overview of data fusion techniques and algorithms is offered, including
    data fusion architecture, feature selection, and inference algorithms. These are
    put into the context of wearable technology for healthcare applications including
    activity recognition, falls detection, gait and ambulation, biomechanical modelling,
    and physiological sensing. Related challenges of data fusion for healthcare are
    presented and discussed. 2. Wearable sensors Wearable sensors can be considered
    in three categories: motion, biometric, and environmental sensors. Sensors used
    to capture human motions include inertial sensors such as accelerometers, gyroscopes,
    and magnetometers. By combining a tri-axial accelerometer, gyroscope, and magnetometer,
    inertial measurement units can be made for 9 degree of freedom tracking and are
    used for biomechanical modelling. Common biometric sensors are used to measure
    heart rate, muscle activation, respiration, oximetry, blood pressure, galvanic
    skin response, heat flux, perspiration, and hydration level. Electrocardiogram
    (ECG) and electromyography (EMG) detect the electrical activity produced by the
    heart and muscles respectively and are interpreted into heart rate and muscle
    activation. For a wearable monitoring system to be practical it needs to meet
    several key criteria: to be non-invasive, intuitive to use, reliable, and provide
    relevant feedback to the wearer. The number of devices, location, and attachment
    method would be considered during design, and are usually application specific.
    Wearable sensor systems also have to take the target users’ needs, such as dexterity
    or cognitive ability, into account. Devices can be either attached directly to
    the skin using some form of adhesive, mechanically using a clip, strap or belt,
    or incorporated directly into clothing or shoes. Advanced fabrication techniques
    can now create ‘flexible/stretchable electronics’ for integrated circuits, electronics
    and sensors [11]. Such systems can be applied directly to the skin enabling discrete
    sensing possibilities e.g. devices developed by MC10 Inc. [12]. It is essential
    the system is reliable and measures with acceptable accuracy, providing the user
    with relevant feedback. In the research literature this is often presented as
    the accuracy of identifying specific events or health aspects, or in terms of
    selectivity and specificity, the proportion of the data that is positively identified
    correctly and the proportion of the data that is negatively identified correctly,
    respectively. The past decade has seen major advances in sensing technologies,
    including MEMs and physiological sensors. Wireless low power communications, such
    as BLE, enable sensing technology to be integrated into wearable devices, clothing,
    and in the future embedded about the person without the restrictions of wires
    or the need to download data. Low power sensing and communications also enable
    wearable energy harvesting to be a viable option for powering and recharging these
    systems. Commercially, wearable sensor systems are available for human monitoring
    and some of their output features are tabulated in Table 2. Much of the software
    developed for commercial devices is proprietary; however, some systems are able
    to provide raw data, or have been explicitly designed for the purposes of research.
    Table 3 describes wearable devices that are commercially available for activity,
    physiological, and biomechanical monitoring, including both consumer and research
    devices. The table presented gives a snapshot overview of commercial wearable
    devices as this is a wide and rapidly changing landscape, with the features monitored
    and the sensors used for daily monitoring, including a few examples for specific
    applications. Devices that only provide step count have not been included. A large
    proportion of these sensors target the health and fitness industry, and track
    the amount and intensity of activity performed including measures such as an estimate
    of energy expenditure and calories burned. For purposes of research however, a
    much broader range of outputs are being investigated and will be described in
    greater detail, including the techniques used to achieve them, in Section 5. Table
    1. Table of abbreviations. Abbreviation Definition Terminology ADL Activities
    of daily living Medical ANN Artificial neural networks Technical BLE Bluetooth
    low energy Technical COPD Chronic obstructive Pulmonary disease Medical DT Decision
    tree Technical ECG Electrocardiogram Medical EEG Electroencephalogram Medical
    EMG Electromyography Medical GMM Gaussian mixture models Technical HR Heart rate
    Medical HRV Heart rate variability Medical KF Kalman filter Technical k-NN k-nearest
    neighbour Technical MEM Microelectromechanical Technical PF Particle filter Technical
    QoL Quality of life Medical SpO2 Capillary oxygen saturation Medical SVM Support
    vector machines Technical Table 2. Output features from commercial health monitoring
    systems. Activity features Biometric features Steps Activity Sleep Heart Breath
    Head Other Step count Lying, sitting, standing, stepping, walking, running Duration
    Heart rate (HR) /sec or min Blood pressure Cadence Latency HR (R-R intervals)
    Number of impacts to the head Glucose level Average steps/day Intensity: low,
    moderate, high REM sleep duration HR variability Respiratory rate Skin temperature
    Number of steps at moderate/ high intensity Duration and percentage of time at
    each intensity level Light sleep duration HR zone Intensity of head impacts Perspireation
    Deep sleep duration ECG Blood oxygen level (SpO2) EEG (Electroencephalography
    Distance Total exercise time Toss and turn count 20 mincardiovascular score Head
    injury criteria Elevations Energy expenditure: kcal / MET.hr Efficiency 60 minendurance
    score EMG (Electromyography Stress level Table 3. Consumer and research commercial
    wearable sensor systems. Older versions have been replaced by those that supersede
    them. Abbreviations: RD Raw Data; EE Energy Expenditure; HR Heart Rate; ✓ featured;
    not featured; * optional. 2.1. Sensor placement The placement of wearable sensors
    for health monitoring is motivated by three main driving forces: (1) what data
    is required or provided by the sensors; (2) where it is considered acceptable
    to wear the sensors; and (3) the number of sensors the user is willing to wear.
    For commercial systems the most common place to wear a sensor is on the wrist
    or arm although many systems can be worn at multiple locations, such as on the
    chest using a clip or as a pendent, and the thigh and ankle (Table 3). The waist
    and wrist are intuitive and unobtrusive places to wear sensors as many people
    are already accustomed to wearing watches or belts. In a study conducted by van
    Hess et al. [13] to investigate the estimation of daily energy expenditure using
    a wrist-worn accelerometer, the acceptability of wearing the device on the hip
    or wrist was also examined. It was found that both sensor placements were rated
    as highly acceptable, however, men on average preferred wearing the sensor on
    the wrist. Systems with more niche applications need to be worn at more specific
    locations relevant to the information being acquired, e.g. the Reebok Checklight
    with MC10 helmet [14] that determines the number and severity of impacts to the
    head while participating in sports. Sensor placement for activity recognition
    has been investigated in several studies. Atallah et al. [15] investigated the
    most relevant features and sensor locations for discriminating activity levels,
    demonstrating the dependence of sensor location on the activities being monitored.
    Liu et al. [16] investigated different combinations of sensors and locations for
    physical activity assessment. The “best” results, i.e. the ones giving the highest
    activity recognition accuracy, were obtained using all the sensors, followed by
    a combination of the wrist and waist worn sensors. Patel et al. [17] also investigated
    the different combinations of sensors for monitoring patients with chronic obstructive
    pulmonary disease (COPD) and again found the “best” results were obtained using
    all the sensors (in this case 10 accelerometers distributed about the body). The
    “best” single sensor location was found to be on the left or right thigh. Pärkkä
    et al. [18] conducted a study to determine which sensors are most information
    rich for activity classification and included both motion and physiological sensors.
    Accelerometers were found to be most informative for activity monitoring, however
    the position of the sensors (on the wrists) did not enable the separation of sitting
    and standing. Interestingly, physiological sensors did not prove as useful for
    activity monitoring due to the delay in physiological reactions to activity changes,
    whereas accelerometers react immediately. Sensor orientation can also effect classification
    accuracy. Thiemjarus et al. [19] compared the performance of the k-NN (k-nearest
    neighbour) classifier using accelerometry data of activities with the sensor orientated
    in different directions. By transforming the signal to eliminate the orientation
    of the sensor an overall accuracy of 91% was achieved. 3. Data fusion This section
    discusses data fusion models and the different levels of data fusion. A description
    of the possible types of features that can be extracted to characterise the data
    and techniques to select them are also described. 3.1. Data fusion models A useful
    data fusion model is The Joint Directors of Laboratory model described by Hall
    and Llinas [8] that was developed to improve communications among military researchers
    and system developers. Work by Luo and Kay [20] define a hierarchical model consisting
    of four levels of abstraction at which fusion can take place; signal level fusion,
    pixel level fusion (for image data), feature level fusion, and symbol level fusion.
    Dasarathy [21] expanded on the hierarchical data fusion models by defining five
    fusion processes characterised by each processes input-output mode, e.g. data
    in - feature out fusion. For the application of healthcare many models have been
    suggested. Lee et al. [22] proposed a hierarchical model for the application of
    pervasive healthcare to minimise the probability of unacceptable error. Fortino
    et al. [10] described a framework for collaborative body sensor networks, C-SPINE.
    Gong et al. [23] proposed a multi preference-driven data fusion model and demonstrated
    its application for a wireless sensor network healthcare monitoring system. Fig.
    1 describes a generic centralised hierarchical data fusion architecture for a
    wearable health monitoring systems, drawing on three of the data fusion levels
    of abstraction (signal, feature, and decision) and elements from the previously
    described models. Data is sampled from the sensors (at a frequency appropriate
    to the sensor type and application) and transferred to the fusion centre which
    may reside on a smart phone or a gateway. An obvious way to do this is by using
    wireless radio communications, such as Low Energy Bluetooth (BLE) or Zigbee. Alignment
    and cleaning of the data takes place at the pre-processing stage to take into
    account differences in sampling rates, timing offsets, and lost or corrupt data.
    Filtering would also take place at this stage. Data can then be processed at the
    appropriate level of fusion. Additionally, some sensors may operate by being activated
    by an event trigger which may be the result of the systems output. Potentially,
    in the case of a suspected fall detected using body worn accelerometry, a camera
    could be activated to gain additional context of the event. Download : Download
    high-res image (178KB) Download : Download full-size image Fig. 1. A data fusion
    architecture for wearable health monitoring systems incorporating concepts from
    [8] and [20]. To interpret the sensor data three main hierarchical levels at which
    data fusion takes place are commonly used: signal level data fusion (sometimes
    referred to as direct or raw data fusion), feature level fusion, and decision
    (symbolic or inference) level fusion [8]. Signal level fusion can be applied to
    combine commensurate data i.e. data measuring the same property, directly. For
    example, to deduce kinematic parameters for biomechanical modelling, the Kalman
    filter (KF) can be used to estimate the state. For data that is non-commensurate,
    fusion takes place at the feature level [8]. Features are extracted from the sensor
    data and used to form a feature vector that, after fusion, will result in a higher
    level representation of the data. If appropriate, output from the signal level
    fusion can be used as part of the feature vector. There are a wide range of parametric
    and non-parametric algorithms that can be used to classify the data into higher
    levels of abstraction, which will be described in further detail in Section 4.
    Decision level fusion is performed at the highest level of abstraction from sensor
    data and can be based on raw data, features extracted from the raw data, and symbols
    defined at the feature level fusion to make higher level deductions. Probabilistic
    methods are commonly used at the decision level due to the high levels of uncertainty;
    however other methods that are also tolerant of uncertainty can also be used including
    artificial intelligence, fuzzy logic and genetic algorithms. 3.2. Feature extraction
    and selection To combine data for the classification or detection of an activity
    or event characteristics, or features, are extracted from the sensor data as input
    for the data fusion algorithm. The features represent the information in the original
    signal and are usually calculated over fixed time windows that can range from
    0.5 to 10 s long. Using a fixed window, an overlap in the data can be applied,
    with the effect of smoothing the output. Typically, a 1 s window is sufficient,
    with a 50% overlap with the previous window, however this is application dependent
    and a longer or shorter window maybe more appropriate. Features can be summarised
    into two main domains: time and frequency, however some features incorporate both
    temporal and frequency elements, such as wavelets [24]. A summary of some of these
    features can be found in Table 4. Table 4. Example features that can be extracted
    from sensor data. Domain Type Feature Time Signal characteristics Absolute value
    Range Maximum/minimum Zero crossings Derivative Integral Jerk Root mean square
    Root-sum-of-squares (or signal magnitude vector) Surface magnitude area Statistical
    characteristics Mean Median Variance Standard deviation Skew Kurtosis Interquartile
    range Percentiles Pearson coefficients Cumulative histograms Cross correlation
    Entropy Frequency Fourier coefficients Energy Power Wavelet features Power spectral
    density Feature selection describes the process by which features are chosen.
    This is sometimes based on empirical observation, however, search strategies can
    provide an objective means to select appropriate features. Search strategies fall
    broadly under two types; filter based, where the properties of the data are examined
    without knowledge of the inference algorithms to be used; and wrapper based that
    use the performance of the target learning algorithm to inform the set of features
    [25]. An introduction to feature selection has been provided by Guyon and Elisseeff
    [26]. For wearable sensor applications, selecting the most appropriate features
    can make a great difference to the quality of the inference. Atallah et al. [15]
    compared feature sets for activity recognition compiled using several filter based
    feature selection algorithms including Relief and Simba, that aim to maximise
    the margins between decision boundaries, and minimum redundancy maximum relevance.
    A common problem for multi-sensory systems is high dimensionality feature space
    which leads to increased computational costs and higher demands on memory. Algorithms
    such as independent component analysis and principal component analysis [24] can
    be used to reduce the dimensionality of feature space. Deep learning, offers an
    alternative approach building features at multiple levels of a deep network. While
    deep learning has often been applied to static data, Längkvist et al. [27] provided
    a review of deep learning for time-series data. Plötz et al. [28] compared different
    types of features used to represent human activity data including: statistical
    metrics, fast Fourier transform coefficients, principal component analysis based
    features, and those derived using deep learning methods. A standard nearest neighbour
    classifier, which will be described later, was used to demonstrate the effectiveness
    of the features. For systems reliant on wireless communications, including body
    worn systems, power consumption also requires consideration i.e. the trade-off
    between transmitting raw data to the fusion centre vs. extracting features for
    transmission on the sensing device. 4. Data fusion algorithm overview In the following
    sections an overview of the different types of data fusion algorithms are presented
    and examples given from the research literature. For feature level data fusion,
    non-parametric algorithms (that do not make assumptions regarding the distribution
    of the data) and parametric algorithms are presented. At the decision level, algorithms
    including Bayesian approaches, fuzzy logic, and topic models will be described.
    4.1. Signal level algorithms • Weighted averages - is a simple signal level fusion
    method for combining commensurate information by taking an average of all the
    sensor readings [20]. The contribution of the “worst” sensor’s error will be alleviated
    in the final estimate, although not eliminate it completely. To reduce the impact
    of large erroneous sensor readings weighted averages can be used [24]. For example,
    the weighted average of physiological temperature measurements could be taken
    from an array of body worn thermistors to find a single best estimate. • The Kalman
    filter (KF) - is a popular statistical state estimation method that can be used
    to fuse dynamic signal level data. The state estimates of the system are determined
    based on a recursively applied prediction and update algorithm and assumes the
    state of a system at the current time is based on the state of the system at the
    previous time interval. One of the main advantages of the KF is that it is computationally
    efficient [29]. The KF is often used to fuse accelerometer and gyroscope information
    to provide better estimates, an example of which is the use of the KF to detect
    postural sway during quiet standing (standing in one spot with out performing
    any other activity or leaning on anything) [30] . For non-linear filtering the
    extended KF or unscented KF can be used. • Particle filtering (PF) - Particle
    filtering is a stochastic method to estimate moments of a target probability density,
    when they can’t be computed analytically. The principle is to generate random
    numbers called particles, from an “importance” distribution that can be easily
    sampled. Then, each particle is associated a weight that corrects the dissimilarity
    between the target and the importance probabilities. In the Bayesian context,
    particle filters are often used to estimate the mean of the posterior density.
    They have the benefit of estimating the full target distribution without any assumption,
    which makes them particularly useful for nonlinear /non-Gaussian systems. Djurić
    et al. [31] and Arulampalam [32] both provided a tutorial of PF theory. The PF
    can be used for biomechanical state estimation based on accelerometer and gyroscope
    data. 4.2. Feature level non-parametric algorithms • k-Nearest Neighbour (k-NN)
    - One of the simplest classification algorithms, k-NN measures the distance between
    the unlabelled observations and the training samples to infer which class they
    belong to. The unlabelled observation is assigned the label of its nearest neighbours
    where k is the number of training observations to be taken into account. Distance
    measures include the Euclidean and Manhattan distance. Use of k-NN has been widely
    used and reported in the literature for activity classification applications [15],
    [16], [19], [33], [34], [35], [36], [37]. Bicocchi et al. [37], in particular,
    compared k-NN to several other instance based learning algorithms using a real-life
    activity set and achieved a precision of about 75% with k equal to 1. • Decision
    Trees (DT) - DT or rule-based algorithms are a popular method used for classification.
    Rules are defined in the form of a “tree”, starting at the root that is split
    into decision nodes which refine the class prediction with each level of decision
    nodes. Leaf nodes represent the predicated class of the unknown data [5]. DT can
    be constructed manually by empirically defining rules; however, algorithms are
    available to automatically generate trees based on the data such as ID3 and C4.5.
    Other DT algorithms include CART, random tree, random forest, and J48. Examples
    of the use of DT for activity recognition include [17], [18], [34], [35], [38],
    [39], [40], [41]. • Support Vector Machines (SVM) - SVM have been extensively
    used for human activity classification [16], [17], [36], [39], [42], [43] and
    can be used for both linear and non-linear classification problems. SVM is a binary
    classifier finding separation between two classes. The data is mapped into a high
    dimensional space using a kernel function (such as a Gaussian, sigmoid, or radial
    basis function). A hyperplane is then found that maximises the decision boundary
    between the examples of the classes [44]. In a comparative study by Liu et al
    [16] to determine the best sensor configuration to recognise activities, SVM performed
    better than the k-NN and Naive Bayes classifiers with an accuracy of 76% using
    a single hip worn accelerometer, to 88% using a hip and wrist worn accelerometer
    and a ventilation sensor that measures features associated with breathing. • Artificial
    Neural Network (ANN) and Deep Learning - An ANN is a biologically inspired computational
    model to describe functions consisting of a network of simple computing elements,
    or nodes [45]. An ANN structure is composed of several layers of nodes connected
    by weighted links. Inputs into the ANN are propagated forward through the layers
    to compute the output of the network, as follows: for each node, the sum of the
    weights multiplied by the input value of all inputs is found. The output for this
    node is then calculated by the activation function, such as the sigmoid function.
    To train the network, the internal connective weights are adjusted using techniques
    such as back propagation which minimises the error between the network’s output
    and the target output [45]. ANN have been applied to the problem of classifying
    human activity recognition; some examples include [18], [36], [46], [47]. Pärkkä
    et al. [18], Roy et al. [46], and Altun et al. [36] conducted studies to compare
    the performance of ANN to other algorithms. Yang et al. [47] implemented an activity
    recognition strategy based on two phase neural classification. During the first
    phase, activities are classified as either static or dynamic activities, then
    during the second phase more detailed activity recognition is performed. Recently,
    success with deep learning methods, based on neural networks, have attracted interest
    from many domains including image classification and natural language processing
    [48]. As mentioned previously, deep learning can be used to learn features for
    activity recognition [28], and as well as perform classification. 4.3. Feature
    level parametric algorithms • Gaussian mixture model (GMM) – GMM can be used as
    a parametric classifier by modelling the probability distribution of continuous
    measurements or features. A GMM consists of a weighted sum of Gaussian distributions
    that can be trained with example data using algorithms such as expectation-maximisation
    (EM) [38], [49]. A GMM is trained for each class, then the new data examples are
    classified by determining the GMM that provides the highest likelihood of producing
    the data. Allen et al. [38] used GMM to distinguish postures and movements for
    the monitoring of older patients based on accelerometer data, comparing it to
    the performance of a heuristic DT system. Wang et al. [49] classified five gait
    patterns using GMM. • k-Means – k-means is an unsupervised iterative distance-based
    clustering algorithm. It aims to classify data based on the distance of a data
    point to the mean centroid of each cluster. The classifier is trained by defining
    k centroids, one for each cluster. These can be defined randomly or by defining
    the initial centroid based on all the training data and subsequent centroids using
    the data points furthest away from the initial centre [24]. An iterative process
    is then used to minimise the distance of the centroids from the data points. Each
    data point is assigned to the nearest centroid, after which the centroid is recalculated
    based on the clusters that are formed. This process is repeated until the criteria
    to stop have been met. After this process, data for classification is assigned
    to the closest centroid. Ghassemzadeh et al. [33] used k-means clustering to define
    motion primitives which, in combination, form transcripts that can be used for
    activity recognition. Machado et al. [50] applied k-means clustering to the problem
    of activity recognition using accelerometry successfully predicting activities
    with an accuracy of 89% for the user independent case. 4.4. Decision level algorithms
    • Bayesian inference - Approaches, based on Bayes theorem, relate the posterior
    probability, i.e. the probability of the hypothesis occurring given the observations
    (or features), the prior probability of the hypothesis, and the likelihood, i.e.
    the probability of the observations given the hypothesis. Bayesian methods enable
    the inclusion of prior probabilities that can take into account known information
    and can be updated based on the observations. The Naive Bayes classifier is a
    popular method for inferring activity from sensor data. Despite the assumption
    of independence between features, which is often considered poor, it can perform
    well. Atallah et al. [51] used Bayesian classification for activity recognition
    from an ear worn accelerometer based device. One drawback of Bayesian inference
    is the requirement that competing hypotheses are mutually exclusive, however,
    this is not generally compatible with the way humans assign belief [24]. Dempster–Shafer
    theory, also known as belief function theory or evidential reasoning, provides
    a framework for reasoning with uncertainty by extending the Bayesian approach
    [24]. • Fuzzy logic - or fuzzy set theory, is a fusion technique that can be applied
    at the decision level and have been used for the recognition of human activities
    using both wearable and ambient sensors [52], [53]. Fuzzy logic describes input
    data in terms of possibility, i.e. the possibility the input data describes some
    property [24]. Medjahed et al. [53] describe three main steps for the application
    of fuzzy logic. First, fuzzification takes place converting the data into fuzzy
    sets. Secondly, a fuzzy inference system is applied which consists of fuzzy rules
    that take the IF/THEN form and fuzzy set operators including the union, complement
    and intersection [24]. Finally, defuzzification is applied to convert fuzzy variables
    generated by the process into real values. • Topic models - are an unsupervised
    machine learning algorithm originally designed for aiding understanding of large
    corpuses of text. They allow hidden thematic patterns in a dataset to be discovered
    using latent Dirichlet allocation. Huynh et al. [54] showed that Topic Models
    could be used to discover routine behaviours (e.g. lunch) from other activities
    (e.g. queuing, eating). Seiter et al. [55] further investigated the robustness
    of Topic Models for daily routine discovery by varying the characteristics of
    simulated datasets based on the original data collected by Huynh et al. and identified
    optimal values of dataset properties required to achieve good performance stability.
    5. Applications of data fusion for health monitoring 5.1. Activity recognition
    Activity monitoring using wearable technology has received a vast amount of attention.
    A person’s level of functional mobility can directly reflect quality of life (QoL)
    and overall health. From information provided by wearable sensors, feature level
    data fusion techniques and inference methods can be used for activity recognition
    at different levels of detail: activity intensity levels, static and dynamic postures,
    and activities of daily living (ADL). Static postures refer to activities which
    are globally still, such as lying and sitting, where as dynamic postures refer
    to activities during which someone is actively moving, such as bipedal activities
    and during transitions, e.g. moving from sitting to standing. Standing can be
    referred to as a dynamic activity, e.g. [19], or a static activity, e.g. [56],
    depending on the perspective and application. Standing is a globally stationary
    activity, however, to maintain a standing posture active work is required on the
    part of the person. Corrective movements are continuously made which can be detected
    using a trunk worn accelerometer and have been used to investigate standing balance
    [57]. In contrast to maintain static postures such as sitting or lying, no active
    work is required on the part of the person. There are links between health and
    the amount of dynamic activity a person performs in the form of physical activity,
    such as walking, thus, even simple measures can provide insight into well-being
    [58]. Static and dynamic postural information can be used to determine the time
    spent in various positions and the amount of dynamic activity being carried out.
    ADL describe in greater detail the essential tasks of daily living. The ability
    with which individuals can perform these tasks are commonly assessed using questionnaires
    [59]. The research literature reflects the interest in using body-worn sensors
    to identify these activities, which can be treated either as individual activities
    [37] or by dividing the ADL into the levels of physical intensity each activity
    requires [51]. It can be seen from the research literature that accelerometers
    are the most widely used sensors for these applications. Exceptions include Pawar
    et al. [60], who performed body movement classification using artifacts present
    in wearable ECG signals, and Roy et al. [46] who combined surface EMG with accelerometers
    for activity recognition. Gyroscopes are also used for activity recognition, although
    not as frequently. Potentially this is due to their high power consumption while
    accelerometers can operate at very low power making them attractive for battery
    powered systems. An in-depth review of the technology used in wearable systems
    for health applications can be found in a review by Lowe and OLaighin [61]. It
    is worth noting that heuristic algorithms are often employed and used to great
    effect for activity recognition. These can be used alone or in conjunction with
    other data fusion techniques. For example, thresholds can be used to define the
    limits between one state and another, distinguish between periods of static and
    dynamic activity, and identify posture [19], [56], [62], [63], [64], [65]. Culhane
    et al. [64] used two bi-axial accelerometers attached to the thigh and sternum
    and by applying a threshold to the standard deviation of the sensor data, it could
    be determined if the wearer was static or dynamic. During static activities, posture
    was inferred using the accelerometer by measuring the tilt of the trunk and thigh.
    Dalton et al. [65] compared the mean of accelerometer data to thresholds that
    had been pre-defined to differentiate between activities. There are a wide range
    of approaches used for general activity recognition, however some studies are
    more disease specific. Tsipouras et al. [66] developed a method for the automatic
    assessment of levodopa-induced dyskinesia for patients living with Parkinson’s
    disease. Using data from body worn accelerometers and gyroscopes, levodopa-induced
    dyskinesia could be detected and the severity assessed. Salarian et al. [67] and
    Rodriguez-Martin et al. [43] also investigated the use of activity classification
    for Parkinson’s disease using fuzzy classification and SVM, respectively. Other
    participant cohorts that were the focus of different studies include: those who
    had recently been in hospital [62], rehabilitation [64], stroke [46], and COPD
    [17], [68]. 5.2. Fall detection and prediction Fall detection, often performed
    in conjunction with activity recognition [63], [69], [70], is another widely researched
    application for wearable sensing technology. The incidence of falls and the risk
    of injury due to a fall increases as people age, affecting QoL and confidence.
    After a fall, it may not be possible to call for help or attract attention which
    could result in a sustained period of time without assistance. During this time,
    dehydration, hunger, and injuries sustained during the fall can lead to prolonged
    hospital stays and potentially prove fatal. Heuristics are often employed for
    fall detection including work by Bourke et al. [71] who investigated fall detection
    using 2 tri-axial trunk and thigh worn accelerometers. The resultant was calculated
    for both accelerometers and an upper falls thresholds applied capable of identifying
    100% of falls from normal activities. In subsequent work, Bourke et al. [72] applied
    thresholds to the resultant of the angular velocity from a trunk mounted gyroscope.
    Karantonis et al. [63] used a single waist worn accelerometer and thresholds to
    determine activity, rest, posture and falls. Benocci et al. [73] also conducted
    falls detection using an accelerometer attached to the sacrum and simulated falls
    from standing, walking, out of bed, and sliding down a wall. Wang et al. [74]
    described a three-fold threshold system that combine a trunk worn accelerometer
    and cardiotachometer to detect falls. The thresholds test for high accelerometer
    values, angle of the trunk, and heart rate to detect a fall. One of the greatest
    predictors of a fall is having fallen previously, therefore it is of equal importance
    to be able to predict a fall such that preventative measures can be put in place.
    As well as the detection of falls, work by Giansanti et al. [75] used wearable
    sensors to determine the risk of falls using 60 s balance tests. An accelerometer
    and gyroscope were worn on the trunk and a four layer ANN were used to classify
    participants into fall risk levels. 5.3. Gait and ambulatory monitoring Gait analysis
    can provide insight into functional mobility, ranging from the ability to perform
    various bipedal activities to a detailed account of the gait cycle. Gait analysis
    and biomechanical modelling are traditionally performed in laboratory environments
    using optical motion capture to track body segment motion. More recently body
    worn inertial devices have been investigated as an alternative, eliminating the
    need to collect data in specialised laboratories. Biomechanical modelling of the
    lower body could be used to build unique gait models such that deviations from
    the norm could indicate the need for treatment or intervention. Moe-Nilssen and
    Helbostad [76] used a low back mounted accelerometer to monitor gait variability
    in the anterior-posterior and mediolateral plane, and estimate cadence, step,
    and stride length over a known distance and was used to differentiate between
    fit and frail older adults. Xu et al. [77] examined the walking parameters of
    those recovering from stroke with a hemiparetic gait for rehabilitation purposes.
    A hierarchical approach using Naïve Bayes and dynamic time warping methods were
    used to classify walking, then gait parameters are computed including walking
    speed, cadence, stride length, and distance travelled. In the clinical environment,
    gait has been used to predict the risk of falling using tools such as the Tinetti
    gait and balance assessment [78]. Body-worn sensors could be used as an alternative
    or complementary assessment. Caby et al. [79] collected accelerometry data from
    10 sensors during a walking test and the Timed Up-and-Go for the objective classification
    of fallers and non-fallers. Accelerometry and force sensitive resistors have also
    been used to distinguish between normal and abnormal gait [80]. Ishigaki et al.
    [81] determined pelvic movement from an accelerometer and gyroscope mounted on
    the sacrum during 10m of free walking to find correlations with stability in older
    adults. Less pelvic motion was found for those classed as unstable based on a
    single leg balance test. The differences in bipedal locomotion styles imposed
    by environmental conditions such as a flat or sloped surface, and stairs are subtle.
    The ability to negotiate these conditions can be an indication of physical well-being
    and used to monitor those with limited mobility. To this end, Wang et al. [82]
    decomposed the acceleration data from a single waist mounted sensor into frequency
    features using wavelets to classify the different walking patterns using a multilayer
    perceptron neural network. In further work, Wang et al. [83] included walking
    up and down two different gradients and used GMM for classification. Lau et al.
    [84] focused on walking conditions for those with uni-lateral drop foot and deployed
    two accelerometers and a single gyroscope on the affected side to distinguish
    the aforementioned conditions and compare classification results from several
    data fusion methods. Muscillo et al. [85] adopted an adaptive Kalman-based Bayes
    estimation method to differentiate between locomotor conditions for both young
    and older adults. By analysing gait events, such as heel contact, heel-off, and
    toe-off, body-worn sensors can be used to characterise gait for applications such
    as drop foot stimulation [86]. Kotiadis et al. [87] investigated gait phase detection
    for drop foot, exploring trigger timings for a stimulator. For those suffering
    from Parkinson’s disease and multiple sclerosis gait disturbances, such as freezing
    of gait, can be an indication of a higher risk of a fall. Tripoliti et al. [88]
    used body worn accelerometers and gyroscopes for the automatic detection of freezing
    of gait. Accelerometers can also be used to recognise an individual’s gait [89]
    which in a multi-resident home or scenario where sensors are shared could aid
    identification of the wearer. 5.4. Biomechanical modelling Parametric state estimation
    algorithms, such as the KF and PF, can be used to measure biomechanical motions
    by combining accelerometer and gyroscope data to estimate the kinematic parameters.
    These algorithms come under the banner of signal level fusion methods as they
    combine commensurate data to achieve the best estimation of a parameter. Musić
    et al [90] used an extended KF to fuse inertial sensor data for the reconstruction
    of body segment trajectories in the sagittal plane of sit-to-stand motions. Takeda
    et al. [91] presented a method for gait analysis by calculating the 3-dimensional
    position of each lower body segment using 7 tri-axial accelerometers and gyroscopes,
    joint-range-of-motion, the contribution of gravity to the accelerometer signals,
    and frequency features that describing the cyclic nature of walking. Due to the
    high power consumption of gyroscopes other methods using multiple accelerometers
    are being developed such as the double-sensor difference algorithm presented by
    Liu et al. [92] for the measurement of rotational angles of human segments. Djurić-Jovičić
    et al. [93] used pairs of tri-axial accelerometers for the estimation of leg segment
    angles and trajectories in the sagittal plane through the removal of sensor drift.
    5.5. Physiological monitoring By monitoring physiological aspects of health, an
    insight can be gained into how well our bodies are functioning, and can be used
    to monitor cardiovascular health, and the potential onset of illness (i.e. body
    temperature). A novel use of accelerometers was presented by Lapi et al. [94]
    to detect respiratory rate by positioning sensors on opposite sides of the chest
    wall. Li and Kim [95] developed a patch style sensor for wireless heart rate monitoring
    and movement index incorporating a HR monitor and accelerometer. Stress is another
    area of well-being that has drawn interest by the research community due to its
    impact on health and well-being. A system presented by Healey and Picard [96]
    was able to classify stress during real-world driving tasks into three levels
    based on wearable sensors including two skin conductivity sensors, ECG, EMG, chest
    expansion respiration sensor. Ikehara and Crosby [97] used physiological sensors
    to assess cognitive load. Sensors used in this study included those to measure
    electrodermal temperature and blood flow, an eye tracker extracting related features,
    and an oximeter. Luprano et al. [98] incorporated textile electrodes and an accelerometer
    into a shirt to measure ECG and perform activity recognition. Fletcher et al.
    [99] developed a system for cognitive behavioural therapy for drug addiction that
    monitors for unusual arousal patterns using accelerometer, temperature, and electrodermal
    activity sensors (with optional ECG). When specific arousal events are detected
    a message was automatically sent to the wearer’s phone with an empathetic message.
    Bandodkar et al. [100] described sodium sweat sensors applied as a temporary stick
    on ‘tattoo’ sensor. These sensors were tested in a laboratory during stationary
    cycling activities. Indeed there are many biological MEMs sensors being developed
    that can be applied to physiological monitoring such as the triglyceride biosensor,
    C-reactive protein detector to monitor increases which may cause heart attacks
    or cardiovascular disease, and membrane-based glucose sensors for diabetics [101].
    6. Discussion and further considerations 6.1. Wearable sensors Energy remains
    a dilemma for long term wearable research as it dictates not only how the wearable
    is used by the individual, but also the quality and availability of the data.
    For the application of activity recognition, inertial sensors such as accelerometers
    and gyroscopes provide the most appropriate data. The number of sensors required
    depends largely on the application. If we consider the use of one to five sensors,
    for the purpose of identifying fundamental static and dynamic postures a single
    sensing device can be sufficient. Wrist worn devices, as favoured commercially,
    are not well placed to accurately distinguish between sitting and standing postures
    but can detect overall activity level. For the general population, measuring activity
    intensity may be sufficient, however, for those that live with chronic disease
    or have restricted movement, the distinction between sitting and standing would
    provide further insight into their well-being and health. A single waist or trunk
    worn sensor will provide information on the transitions between sitting and standing
    and the global pose of the body, improving activity recognition accuracy. A single
    waist worn sensor can also be used to monitor gait variability, cadence, step
    and stride length [76] as described in Section 5.3. However, these methods were
    developed for walking in a straight line using a known distance and would not
    be suitable for free living monitoring. A two-sensor scenario would include a
    sensor on the wrist which would provide information related to ADL, e.g. cooking,
    eating and drinking. With the addition of a third sensor on an ankle or foot,
    more detailed parameters regarding gait can be extracted such as unilateral step
    length and height. An optional sensor positioned on the thigh would provide more
    definitive information regarding body posture, however maybe redundant if used
    in conjunction with a waist worn sensor. Five sensors, worn at the waist, wrists
    and ankles, would provide even greater levels of detail regarding both leg and
    arm movement that can be used for bilateral gait analysis and increase the accuracy
    of activity recognition algorithms. For applications that require data from many
    sensors to address specific diseases or conditions, the benefits of an improved
    QoL may well outweigh the inconvenience of wearing multiple sensors. This presents
    several challenges regarding the usability of the system, such as taking the sensors
    on and off, recharging the sensors, and overall adherence of wearing the system.
    With the wide availability of small, cheap, low powered sensors, incorporating
    them directly into clothing where needed could address some of these challenges.
    Further, near field charging would negate the need to directly connect the system
    to a power source. 6.2. Data fusion models and algorithms The data fusion model
    presented in this paper is based on a centralised hierarchical data fusion model
    and can be seen to be the most commonly used model for most commercial health
    monitoring and many research systems. Most of these systems are aimed at personal
    health and well-being monitoring and focus on determining specific features related
    to that individual. For more complex environments and scenarios, this type of
    architecture can be extended, such that the output, i.e. the local view, can be
    used to contribute towards the global view. This is similar to a distributed architecture
    [9] and could be used in the study of epidemiology, e.g. disease surveillance
    in hospitals. This architecture also naturally lends itself towards a decentralised
    architecture where data fusion takes place at each node and does not rely on a
    single fusion centre making it more robust to intermittent or unreliable communications
    services [9]. In this case each personal system becomes part of a community of
    nodes, each contributing information as and when it can and could be implemented
    in situations such as disaster sites. The choice of data fusion algorithm used
    depends on the target application. Influences include the required output, system
    accuracy, computational complexity, available processing power, battery power
    available, and expected operational time. Many of these aspects constitute a direct
    trade off. Low complexity data fusion algorithms, such as heuristic thresholds,
    weighted averages, k-NN, and k-means, are well suited to simple activity recognition
    applications. These include estimating activity intensity and fundamental static
    and dynamic postures. These are ideal for applications where a long battery life
    is expected and on-wearable user feedback is given. These algorithms can be trained
    in advance and could be implemented on the wearable using simple features extracted
    from the sensor data. These type of algorithms are well suited to everyday free
    living situations as targeted by many commercial systems. Medium complexity data
    fusion algorithms, require more computational power, and in turn more energy to
    run. The data can be treated in two ways, (1) implement the algorithm on-wearable,
    or, (2) transmit the data off-wearable to the fusion centre. Both methods require
    more energy and will shorten the battery life of the wearable system. These algorithms
    include activity recognition algorithms that can infer more complex ADL such as
    Naive Bayes, GMM, DT, and NN. Kinematic estimation algorithms such as the KF which
    can be used towards biomechanical and gait analysis, however, require a high sampling
    frequency of typically 50-100Hz, higher than many sampling frequencies required
    for activity recognition. For research applications, data is often collected using
    wearable sensor nodes and then post-processed. Medium complexity, as previously
    mentioned, to high complexity algorithms have been used for activity recognition
    including SVM, deep learning, and Bayesian networks. To extract and process the
    the relevant data for biomechanical and gait analysis, as previously described,
    KF, extended KF, and PF can be used for the kinematic state estimation. Feature
    level algorithms can then be used to extract features such as clinically relevant
    outputs. Depending on the algorithm, there is more or less transparency of how
    the algorithm maps the sensor data to the output features. Algorithms based on
    neural networks and deep learning provide little insight into this process and
    requires training with large example data sets. Where as model based algorithms,
    for example the KF, control how the sensor data maps to the features but requires
    a predefined model. 6.3. Annotation and system validation Collecting accurately
    labelled activity data in a natural environment to apply to machine learning techniques
    is time consuming and expensive. To reduce the amount of labelled data needed
    to train activity recognition algorithms, techniques can be used such as semi-supervised
    training and active learning [102], [103], [104], [105]. Semi-supervised training
    approaches use small amounts of labelled training data to initially train the
    activity recognition algorithms which are then used to label the unlabelled data.
    Stikic et al. [102] demonstrated two approaches to semi-supervised training, self-training
    (the classification model is updated iteratively based on the most confidently
    predicted newly labelled data) and co-training (the same as self-training but
    uses additional information to augment the process). Active learning finds the
    unlabeled data with the most information and queries the user to label them. Various
    strategies can be used to decide what data has the most information such as the
    data that is classified with the least confidence, or the amount of disagreement
    between two classifiers [102]. This reduces the cost of annotating all the data
    and is a good alternative to manual annotation. Hoque and Stankovic [104] used
    a clustering technique to group activities based on data from a smart home environment
    and asked users to label each cluster rather than label all data. Active learning
    techniques can also be used to update a classifier after deployment. Longstaff
    et al. [105] explored active learning as a means to dynamically augment mobile
    activity classifiers. Diethe et al. [106] proposed a Bayesian active transfer
    learning framework for smart home environments. Although there is a wealth of
    research being carried out in the area of body worn sensors for health applications,
    further validation for many of the methods developed is needed using realistic
    conditions such as: matched participant cohorts, target environments, and natural
    behavioural conditions. This is especially true of fall detection where the algorithms
    used are often developed using simulated data from young healthy participants
    by tripping onto a crash mat or mattress. Algorithms based solely on laboratory
    data have been shown to fail and lead to unacceptably high rates of false alarms
    [107]. In a similar way, people rarely perform activities and ambulation in the
    same way as they would naturally when being cued to do it, or carrying out a script.
    Although features and data fusion algorithms may appear to be successful based
    on laboratory training and testing data, they may fail when used in real-world
    situations or from one person to the next. 6.4. Data loss and synchronisation
    Another challenge for data fusion for health monitoring is the imperfection introduced
    throughout the data fusion health monitoring system. Khaleghi et al. [108], in
    an in-depth review of the state-of-the-art in multisensor data fusion, provided
    a taxonomy of data imperfection including uncertainty, imprecision (vagueness,
    ambiguity and incompleteness), and granularity. Transferable belief models could
    be used as a method for modelling sensor reliability [109]. As well as error introduced
    by the sensors, wireless communications present another source of system error.
    For the application of body worn sensors, wireless transmission of data to a fusion
    centre is a desirable and practical option allowing it to be analysed continuously
    without unnecessary user interaction. Disruption in the communication of data
    to the fusion centre could severally affect the quality of the received data and
    be caused by: operation outside the range of the receiver; loss of power; receiver
    error, and packet loss. Retransmission of lost or corrupted packets can increase
    data reliability using two way communications, i.e. acknowledgement of received
    packets [69], however, there is a power trade off associated with receiving and
    resending packets and there will be a time delay introduced. Data transmitted
    from different sources will arrive to the fusion centre at different times and
    need to be aligned prior to analysis. This raises the issue of data synchronisation.
    Sensor data that is collected using more than one stand alone module can be synchronised
    by providing an input that each sensor can pick up, e.g. a series of taps made
    during recording. Any drift can then be calculated and the data resampled. Systems
    employing wireless communications can correct for clock drift by broadcasting
    a regular beacon from a master clock which can be used determine drift. Including
    this additional information with the time stamp of when the data was received
    can be used to reorder the data before fusion. The synchronisation of sensors
    is an open and often overlooked area of research and methods are restrained by
    the target application requirements, power consumption, sampling and transmission
    frequency, and robustness to data loss. Alemdar and Ersoy [110] presented a survey
    on wireless sensor networks for healthcare and discussed design considerations.
    The wireless sensor network system was broken down into five subsystems including:
    body area network, personal area network, gateway to the wide area network, and
    the end-user healthcare monitoring application. Each subsystem has a different
    set of design considerations. Gravina et al. [111] presented a framework called
    SPINE that can be used for multiple body worn sensor applications. Baker et al.
    [112] described wireless sensor network prototypes for home healthcare. 7. Conclusions
    This paper outlined the state-of-the-art and future concepts for using wearable
    sensors in healthcare applications. It describes some principles of data fusion
    and many of the foundation techniques that can be used to perform data fusion
    on wearable sensor data. The commercial landscape of wearable sensors is constantly
    changing, however a snap shot of some of the currently available products has
    been given, providing context for an overview of the research literature conducted
    in the area of wearable sensors for healthcare applications. Applications of wearable
    technology for healthcare has been described including activity recognition, falls
    detection, ambulatory monitoring, and biomechanical monitoring. A discussion of
    other considerations that need to be addressed to augment wearable sensor technology
    has been provided, highlighting potential directions for research and issues such
    as data collection, algorithm training, quality of data, infrastructure and the
    potential fusion of wearable sensors with other external data sources. Conflict
    of interest There are no known conflicts of interest. Acknowledgements This work
    was performed under the SPHERE IRC funded by the UK Engineering and Physical Sciences
    Research Council (EPSRC), Grant EP/K031910/1. This study did not involve human
    subjects. References [1] Office of National Statistics Population ageing in the
    united kingdom, its constituent countries and the european union. 2012. www.ons.gov.uk.
    Google Scholar [2] Cracknell R. The ageing population. House of Commons Library
    2010. pp. 44–45. Google Scholar [3] J. Spijker, J. MacInnes Population ageing:
    the timebomb that isn’t? BMJ, 347 (2013), p. f6598 CrossRefView in ScopusGoogle
    Scholar [4] D. Yach, C. Hawkes, C.L. Gould, K.J. Hofman The global burden of chronic
    diseases: overcoming impediments to prevention and control JAMA, 291 (2004), pp.
    2616-2622 View in ScopusGoogle Scholar [5] A. Godfrey, R. Conway, D. Meagher,
    G. OLaighin Direct measurement of human movement by accelerometry Med Eng Phy,
    3 (10) (2008), pp. 1364-1386 View PDFView articleView in ScopusGoogle Scholar
    [6] Cheung V.H., L. Gray, M. Karunanithi Review of accelerometry for determining
    daily activity among elderly patients Arch Phys Med Rehabil, 92 (6) (2011), pp.
    998-1014 View PDFView articleView in ScopusGoogle Scholar [7] S. Patel, Park H.,
    P. Bonato, Chan L., M. Rodgers A review of wearable sensors and systems with application
    in rehabilitation J Neuroeng Rehabil, 9 (2012), p. 21 CrossRefGoogle Scholar [8]
    D.L. Hall, J. Llinas An introduction to multisensor data fusion Proc IEEE, vol.
    85 (1997), pp. 6-23 View in ScopusGoogle Scholar [9] F. Castanedo A review of
    data fusion techniques Sci World J, 2013 (2013), pp. 1-19 CrossRefGoogle Scholar
    [10] G. Fortino, S. Galzarano, R. Gravina, Li W. A framework for collaborative
    computing and multi-sensor data fusion in body sensor networks Inf Fus, 22 (2015),
    pp. 50-70 View PDFView articleView in ScopusGoogle Scholar [11] R. Ghaffari, B.L.
    Schlatka, G. Balooch, Huang Y., J.A. Rogers Reinventing biointegrated devices
    Mater Today, 16 (5) (2013), pp. 156-157 View PDFView articleView in ScopusGoogle
    Scholar [12] MC10 Inc. MC10 Reshaping electronics. 2014 http://www.mc10inc.com/.
    [accessed 13.11.14]. Google Scholar [13] V.T. van Hees, F. Renström, A. Wright,
    A. Gradmark, M. Catt, Chen K.Y., et al. Estimation of daily energy expenditure
    in pregnant and non-pregnant women using a wrist-worn tri-axial accelerometer
    PLoS ONE, 6 (7) (2011) Google Scholar [14] Checklight. 2014 http://www.mc10inc.com/consumer-products/sports/checklight/.
    [accessed 18.12.14]. Google Scholar [15] L. Atallah, Lo B., R. King, Yang G.-Z.
    Sensor positioning for activity recognition using wearable accelerometers IEEE
    Trans Biomed Circ Syst, 5 (4) (2011), pp. 320-329 View in ScopusGoogle Scholar
    [16] Liu S., Gao R.X., D. John, J.W. Staudenmayer, P.S. Freedson Multisensor data
    fusion for physical activity assessment IEEE Trans Biomed Eng, 59 (3) (2012),
    pp. 687-696 View in ScopusGoogle Scholar [17] S. Patel, C. Mancinelli, J. Healey,
    M. Moy, P. Bonato Using wearable sensors to monitor physical activities of patients
    with COPD: a comparison of classifier performance Proceedings of the sixth international
    workshop on wearable and implantable body sensor networks, IEEE (2009), pp. 234-239
    View in ScopusGoogle Scholar [18] J. Pärkkä, M. Ermes, P. Korpipää, J. Mäntyjärvi,
    J. Peltola, I. Korhonen Activity classification using realistic data from wearable
    sensors IEEE Trans Inf Technol Biomed, 10 (2006), pp. 119-128 View in ScopusGoogle
    Scholar [19] S. Thiemjarus A device-orientation independent method for activity
    recognition Proceedings of the 2010 international conference on body sensor networks,
    IEEE (2010), pp. 19-23 View in ScopusGoogle Scholar [20] Luo R.C., M.G. Kay A
    tutorial on multisensor integration and fusion Proceedings of the 16th annual
    conference of the IEEE IECON’90, Industrial Electronics Society (1990), pp. 707-722
    View in ScopusGoogle Scholar [21] B.V. Dasarathy Sensor fusion potential exploitation-innovative
    architectures and illustrative applications Proc IEEE, 85 (1) (1997), pp. 24-38
    View in ScopusGoogle Scholar [22] Lee H., Park K., Lee B., Choi J., R. Elmasri
    Issues in data fusion for healthcare monitoring. Proceedings of the PETRA ’08
    (2008) Google Scholar [23] Gong J., Cui L., Xiao K., Wang R., N. Sens MPD-Model:
    A distributed multipreference-driven data fusion model and its application in
    a WSNs-based healthcare monitoring system Int J Distr ib, 2012 (2012), pp. 1-13
    Google Scholar [24] Yang G.-Z. Body Sensor Networks (2nd ed.), Springer, London
    (2014) Google Scholar [25] S. Das Filters, wrappers and a boosting-based hybrid
    for feature selection. Proceedings of the eighteenth international conference
    on machine learning (2001), pp. 74-81 Google Scholar [26] I. Guyon, A. Elisseeff
    An introduction to variable and feature selection J Mach Learn Res, 3 (2003),
    pp. 1157-1182 Google Scholar [27] M. Längkvist, L. Karlsson, A. Loutfi A review
    of unsupervised feature learning and deep learning for time-series modeling Pattern
    Recogn Lett, 42 (C) (2014), pp. 11-24 View PDFView articleView in ScopusGoogle
    Scholar [28] T. Plötz, N.Y. Hammerla, P. Olivier Feature learning for activity
    recognition in ubiquitous computing. Proceedings of IJCAI-11 (2011), pp. 1729-1734
    View in ScopusGoogle Scholar [29] Luo R.C., Chang C.C., Lai C.C. Multisensor fusion
    and integration: theories, applications, and its perspectives IEEE Sens J, 11
    (12) (2011), pp. 3122-3138 View in ScopusGoogle Scholar [30] A. Al-Jawad, A. Barlit,
    M. Romanovas, M. Traechtler, Y. Manoli The use of an orientation Kalman filter
    for the static postural sway analysis APCBEE Procedia, 7 (2013), pp. 93-102 View
    PDFView articleGoogle Scholar [31] P.M. Djurić, J.H. Kotecha, Zhang J., Huang
    Y., T. Ghirmai, M.F. Bugallo, et al. Particle filtering IEEE Signal Process Mag,
    20 (5) (2003), pp. 19-38 View in ScopusGoogle Scholar [32] M.S. Arulampalam A
    tutorial on particle filters for online nonlinear/non-Gaussian Bayesian tracking
    IEEE Trans Signal Process, 50 (2) (2002), pp. 174-188 View in ScopusGoogle Scholar
    [33] H. Ghassemzadeh, E. Guenterberg, S. Ostadabbas, R. Jafari A motion sequence
    fusion technique based on PCA for activity analysis in body sensor networks 2009
    Conf Proc IEEE Eng Med Biol Soc IEEE (2009), pp. 3146-3149 CrossRefView in ScopusGoogle
    Scholar [34] U. Maurer, A. Smailagic, D.P. Siewiorek, M. Deisher Activity recognition
    and monitoring using multiple sensors on different body positions. Proceedings
    of the BSN’06. IEEE (2006), pp. 113-116 CrossRefView in ScopusGoogle Scholar [35]
    L.C. Jatobá, U. Großmann, C. Kunze, J. Ottenbacher, W. Stork Context-aware mobile
    health monitoring: Evaluation of different pattern recognition methods for classification
    of physical activity. Proceedings off the IEEE conference on engineering in medicine
    and biology society (2008), pp. 5250-5253 CrossRefView in ScopusGoogle Scholar
    [36] K. Altun, B. Barshan, O. Tunç el Comparative study on classifying human activities
    with miniature inertial and magnetic sensors Pattern Recogn, 43 (10) (2010), pp.
    3605-3620 View PDFView articleView in ScopusGoogle Scholar [37] N. Bicocchi, M.
    Mamei, F. Zambonelli Detecting activities from body-worn accelerometers via instance-based
    algorithms Pervasive Mob Comput, 6 (4) (2010), pp. 482-495 View PDFView articleView
    in ScopusGoogle Scholar [38] F.R. Allen, E. Ambikairajah, N.H. Lovell, B.G. Celler
    Classification of a known sequence of motions and postures from accelerometry
    data using adapted Gaussian mixture models Physiol Meas, 27 (10) (2006), pp. 935-951
    CrossRefView in ScopusGoogle Scholar [39] O. Banos, M. Damas, H. Pomares, A. Prieto,
    I. Rojas Daily living activity recognition based on statistical feature quality
    group selection Expert Syst Appl, 39 (9) (2012), pp. 8013-8021 View PDFView articleView
    in ScopusGoogle Scholar [40] S. Suzuki, Y. Mitsukura, H. Igarashi, H. Kobayashi,
    F. Harashima Activity recognition for children using self-organizing map. Proceedings
    of the 21st IEEE international symposium on robot and human interactive communication,
    IEEE (2012), pp. 653-658 CrossRefView in ScopusGoogle Scholar [41] L. Bao, S.S.
    Intille, A. Ferscha, F. Mattern Activity recognition from user-annotated acceleration
    data. pervasive computing Lecture notes in computer science, vol. 3001, Springer,
    Berlin Heidelberg (2014) Google Scholar [42] A. Mannini, A.M. Sabatini On-line
    classification of human activity and estimation of walk-run speed from acceleration
    data using support vector machines. Proceedings of the IEEE conference on engineering
    in medicine and biology society (2011), pp. 3302-3305 CrossRefView in ScopusGoogle
    Scholar [43] D. Rodriguez-Martin, A. Samà, C. Perez-Lopez, A. Català, J. Cabestany,
    A. Rodriguez-Molinero SVM-based posture identification with a single waist-located
    triaxial accelerometer Expert Syst Appl, 40 (18) (2013), pp. 7203-7211 View PDFView
    articleView in ScopusGoogle Scholar [44] B. Schölkopf, Sung K., C.J.C. Burges,
    F. Girosi, P. Niyogi, T. Poggio, et al. Comparing support vector machines with
    Gaussian kernels to radial basis function classifiers IEEE Trans Signal Process,
    45 (11) (1997), pp. 2758-2765 View in ScopusGoogle Scholar [45] S. Russell, P.
    Norvig Artificial intelligence a modern approach, Prentice Hall, Inc, Upper Saddle
    River, NJ (1995) Google Scholar [46] S.H. Roy, Cheng M.S., Chang S.-S., J. Moore,
    G. De Luca, S.H. Nawab, et al. A combined sEMG and accelerometer system for monitoring
    functional activity in stroke IEEE Trans Neural Syst Rehabil Eng, 17 (6) (2009),
    pp. 585-594 View in ScopusGoogle Scholar [47] Yang J.-Y., Wang J.-S., Chen Y.-P.
    Using acceleration measurements for activity recognition: an effective learning
    algorithm for constructing neural classifiers Pattern Recogn Lett, 29 (16) (2008),
    pp. 2213-2220 View PDFView articleView in ScopusGoogle Scholar [48] LeCun Y.,
    Y. Bengio, G. Hinton Deep learning Nature, 521 (7553) (2015), pp. 436-444 CrossRefView
    in ScopusGoogle Scholar [49] Wang N., E. Ambikairajah, B.G. Celler, N.H. Lovell
    Feature extraction using an AM-FM model for gait pattern classification. Proceedings
    of the IEEE conference on biomedical circuits and systems (2008), pp. 25-28 View
    in ScopusGoogle Scholar [50] I.P. Machado, A.L. Gomes, H. Gamboa, V. Paixão, R.M.
    Costa Human activity data discovery from triaxial accelerometer sensor: non-supervised
    learning sensitivity to feature extraction parameterization Inf Process Manag,
    51 (2) (2015), pp. 204-214 View PDFView articleView in ScopusGoogle Scholar [51]
    L. Atallah, B. Lo, R. Ali, R. King, Yang G.-Z. Real-time activity classification
    using ambient and wearable sensors IEEE Trans Inf Technol Biomed, 13 (6) (2009),
    pp. 1031-1038 View in ScopusGoogle Scholar [52] Yuan B., J. Herbert Fuzzy CARA
    - a fuzzy-based context reasoning system for pervasive healthcare Procedia Comput
    Sci, 10 (2012), pp. 357-365 View PDFView articleView in ScopusGoogle Scholar [53]
    H. Medjahed, D. Istrate, J. Boudy, B. Dorizzi Human activities of daily living
    recognition using fuzzy logic for elderly home monitoring. Proceedings of the
    IEEE international conference on fuzzy systems, IEEE (2009), pp. 2001-2006 CrossRefView
    in ScopusGoogle Scholar [54] T. Huynh, M. Fritz, B. Schiele Discovery of activity
    patterns using topic models. Proceedings of the UbiComp ’08, ACM Press (2008),
    pp. 10-19 CrossRefView in ScopusGoogle Scholar [55] J. Seiter, O. Amft, G. Tröster
    Assessing topic models: How to obtain robustness? Proceedings of the AwareCast
    2012: workshop on recent advances in behaviour prediction and pro-active pervasive
    computing (2012), pp. 1-12 Google Scholar [56] G.M. Lyons, K.M. Culhane, D. Hilton,
    P.A. Grace, D. Lyons A description of an accelerometer-based mobility monitoring
    technique Med Eng Phys, 27 (6) (2005), pp. 497-504 View PDFView articleView in
    ScopusGoogle Scholar [57] M.F. Gago, V. Fernandes, J. Ferreira, H. Silva, L. Rocha,
    E. Bicho, et al. Postural stability analysis with inertial measurement units in
    alzheimer’s disease Dement Geriatr Cogn Disord Extra, 4 (2014), pp. 22-30 CrossRefGoogle
    Scholar [58] F.B. Gillison, S.M. Skevington, A. Sato, M. Standage, S. Evangelidou
    The effects of exercise interventions on quality of life in clinical and healthy
    populations; a meta-analysis Soc Sci Med, 68 (9) (2009), pp. 1700-1710 View PDFView
    articleView in ScopusGoogle Scholar [59] P. Fox, P. Ford Nursing assessment and
    older people - a royal college of nursing toolkit Royal College of Nursing, London
    (2004) Google Scholar [60] T. Pawar, S. Chaudhuri, S.P. Duttagupta Body movement
    activity recognition for ambulatory cardiac monitoring IEEE Trans Biomed Eng,
    54 (5) (2007), pp. 874-882 View in ScopusGoogle Scholar [61] S. Lowe, G. ÓLaighin
    Monitoring human health behaviour in one’s living environment: A technological
    review Med Eng Phys, 36 (2) (2014), pp. 147-168 View PDFView articleView in ScopusGoogle
    Scholar [62] S. Choquette, M. Hamel, P. Boissy Accelerometer-based wireless body
    area network to estimate intensity of therapy in post-acute rehabilitation J Neuroeng
    Rehabil, 5 (2) (2008), p. 20 View in ScopusGoogle Scholar [63] D.M. Karantonis,
    M.R. Narayanan, M. Mathie, N.H. Lovell, B.G. Celler Implementation of a real-time
    human movement classifier using a triaxial accelerometer for ambulatory monitoring
    IEEE Trans Inf Technol Biomed, 10 (1) (2006), pp. 156-167 View in ScopusGoogle
    Scholar [64] K.M. Culhane, G.M. Lyons, D. Hilton, P.A. Grace, D. Lyons Long-term
    mobility monitoring of older adults using accelerometers in a clinical environment
    Clin Rehabil, 18 (3) (2004), pp. 335-343 View in ScopusGoogle Scholar [65] A.F.
    Dalton, C.N. Scanaill, S. Carew, D. Lyons, G. ÓLaighin A clinical evaluation of
    a remote mobility monitoring system based on SMS messaging. Proceedings of the
    annual international conference of the IEEE engineering in medicine and biology
    society, IEEE (2007), pp. 2327-2330 View in ScopusGoogle Scholar [66] M.G. Tsipouras,
    A.T. Tzallas, G. Rigas, S. Tsouli, D.I. Fotiadis, S. Konitsiotis An automated
    methodology for Levodopa-induced dyskinesia: assessment based on gyroscope and
    accelerometer signals Artif Intell Med, 55 (2) (2012), pp. 127-135 View PDFView
    articleView in ScopusGoogle Scholar [67] A. Salarian, H. Russmann, F.J.G. Vingerhoets,
    P.R. Burkhard, K. Aminian Ambulatory monitoring of physical activities in patients
    with Parkinson’s disease IEEE Trans Biomed Eng, 54 (12) (2007), pp. 2296-2299
    View in ScopusGoogle Scholar [68] D.M. Sherrill, M.L. Moy, J.J. Reilly, P. Bonato
    Using hierarchical clustering methods to classify motor activities of COPD patients
    from wearable sensor data J Neuroeng Rehabil, 2 (16) (2005) Google Scholar [69]
    Chan H.-L., Chao P.-K., Chen Y.-C., Kao W.-J. Wireless body area network for physical-activity
    classification and fall detection. Proceedings of the 5th international summer
    school and symposium on medical devices and biosensors, IEEE (2008), pp. 157-160
    View in ScopusGoogle Scholar [70] Wang J., Chen R., Sun X., M.F.H. She, Y. Wu
    Recognizing human daily activities from accelerometer signal Procedia Eng, 15
    (2011), pp. 1780-1786 View PDFView articleView in ScopusGoogle Scholar [71] A.K.
    Bourke, J.V. O’Brien, G.M. Lyons Evaluation of a threshold-based tri-axial accelerometer
    fall detection algorithm Gait Posture, 26 (2) (2007), pp. 194-199 View PDFView
    articleView in ScopusGoogle Scholar [72] A.K. Bourke, G.M. Lyons A threshold-based
    fall-detection algorithm using a bi-axial gyroscope sensor Med Eng Phys, 30 (1)
    (2008), pp. 84-90 View PDFView articleView in ScopusGoogle Scholar [73] M. Benocci,
    C. Tacconi, E. Farella, L. Benini, L. Chiari, L. Vanzago Accelerometer-based fall
    detection using optimized Zigbee data streaming Microelectron J, 41 (11) (2010),
    pp. 703-710 View PDFView articleView in ScopusGoogle Scholar [74] Wang J., Zhang
    Z., Li B., Lee S., R.S. Sherratt An enhanced fall detection system for elderly
    person monitoring using consumer home networks IEEE Trans Consum Electron, 60
    (1) (2014), pp. 23-29 View PDFView articleGoogle Scholar [75] D. Giansanti, G.
    Maccioni, S. Cesinaro, F. Benvenuti, V. Macellari Assessment of fall-risk by means
    of a neural network based on parameters assessed by a wearable device during posturography
    Med Eng Phys, 30 (3) (2008), pp. 367-372 View PDFView articleView in ScopusGoogle
    Scholar [76] R. Moe-Nilssen, J.L. Helbostad Interstride trunk acceleration variability
    but not step width variability can differentiate between fit and frail older adults
    Gait Posture, 21 (2) (2005), pp. 164-170 View PDFView articleView in ScopusGoogle
    Scholar [77] Xu X., M.A. Batalin, W.J. Kaiser, B. Dobkin Robust hierarchical system
    for classification of complex human mobility characteristics in the presence of
    neurological disorders. Proceedings of the international conference on body sensor
    networks, IEEE (2011), pp. 65-70 View in ScopusGoogle Scholar [78] A. Yelnik,
    I. Bonan Clinical tools for assessing balance disorders Clin Neurophysiol, 38
    (6) (2008), pp. 439-445 View PDFView articleView in ScopusGoogle Scholar [79]
    B. Caby, S. Kieffer, H.M. de Saint, G. Cremer, B. Macq Feature extraction and
    selection for objective gait analysis and fall risk assessment by accelerometry
    Biomed Eng Online (2011), pp. 1-19 CrossRefView in ScopusGoogle Scholar [80] C.
    Senanayake, S.M.N.A. Senanayake Human assisted tools for gait analysis and intelligent
    gait phase detection. Proceedings of the innovative technologies in intelligent
    systems and industrial applications, IEEE (2009), pp. 230-235 View in ScopusGoogle
    Scholar [81] N. Ishigaki, T. Kimura, Y. Usui, K. Aoki, N. Narita, M. Shimizu,
    et al. Analysis of pelvic movement in the elderly during walking using a posture
    monitoring system equipped with a triaxial accelerometer and a gyroscope J Biomech,
    44 (9) (2011), pp. 1788-1792 View PDFView articleView in ScopusGoogle Scholar
    [82] N. Wang, E. Ambikairajah, N.H. Lovell, B.G. Celler Accelerometry based classification
    of walking patterns using time-frequency analysis. Proceedings of the annual international
    conference of the IEEE engineering in medicine and biology society, IEEE (2007),
    pp. 4899-4902 CrossRefView in ScopusGoogle Scholar [83] Wang N., E. Ambikairajah,
    S.J. Redmond, B.G. Celler, N.H. Lovell Classification of walking patterns on inclined
    surfaces from accelerometry data. Proceedings of the 16th international conference
    on digital signal processing, IEEE (2009), pp. 1-4 Google Scholar [84] Lau H.,
    Tong K., Zhu H. Support vector machine for classification of walking conditions
    of persons after stroke with dropped foot Hum Mov Sci, 28 (4) (2009), pp. 504-514
    View PDFView articleView in ScopusGoogle Scholar [85] R. Muscillo, M. Schmid,
    S. Conforto, T. D’Alessio An adaptive Kalman-based Bayes estimation technique
    to classify locomotor activities in young and elderly adults through accelerometers
    Med Eng Phys, 32 (8) (2010), pp. 849-859 View PDFView articleView in ScopusGoogle
    Scholar [86] Lau H., Tong K. The reliability of using accelerometer and gyroscope
    for gait event identification on persons with dropped foot Gait Posture, 27 (2)
    (2008), pp. 248-257 View PDFView articleView in ScopusGoogle Scholar [87] D. Kotiadis,
    H.J. Hermens, P.H. Veltink Inertial gait phase detection for control of a drop
    foot stimulator inertial sensing for gait phase detection Med Eng Phys, 32 (4)
    (2010), pp. 287-297 View PDFView articleView in ScopusGoogle Scholar [88] E.E.
    Tripoliti, A.T. Tzallas, M.G. Tsipouras, G. Rigas, P. Bougia, M. Leontiou, et
    al. Automatic detection of freezing of gait events in patients with Parkinson’s
    disease Comput Methods Programs Biomed, 110 (1) (2013), pp. 12-26 View PDFView
    articleView in ScopusGoogle Scholar [89] D. Gafurov, K. Helkala, T. Soendrol Gait
    recognition using acceleration from MEMS. Proceedings of the first international
    conference on availability, reliability and security (ARES’06) IEEE (2006), pp.
    1-6 Google Scholar [90] J. Musić, R. Kamnik, M. Munih Model based inertial sensing
    of human body motion kinematics in sit-to-stand movement Simul Model Pract Theory,
    16 (8) (2008), pp. 933-944 View PDFView articleView in ScopusGoogle Scholar [91]
    R. Takeda, S. Tadano, M. Todoh, M. Morikawa, M. Nakayasu, S. Yoshinari Gait analysis
    using gravitational acceleration measured by wearable sensors J Biomech, 42 (3)
    (2009), pp. 223-233 View PDFView articleView in ScopusGoogle Scholar [92] Liu
    K., Liu T., K. Shibata, Y. Inoue, Zheng R. Novel approach to ambulatory assessment
    of human segmental orientation on a wearable sensor system J Biomech, 42 (16)
    (2009), pp. 2747-2752 View PDFView articleView in ScopusGoogle Scholar [93] M.D.
    Djurić-Jovičić, N.S. Jovičić, D.B. Popović, A.R. Djordjević Nonlinear optimization
    for drift removal in estimation of gait kinematics based on accelerometers J Biomech,
    45 (16) (2012), pp. 2849-2854 View PDFView articleView in ScopusGoogle Scholar
    [94] S. Lapi, F. Lavorini, G. Borgioli, M. Calzolai, L. Masotti, M. Pistolesi,
    et al. Respiratory rate assessments using a dual-accelerometer device Respir Physiol
    Neurobiol, 191 (2014), pp. 60-66 View PDFView articleView in ScopusGoogle Scholar
    [95] Li M., Kim Y.T. Development of patch-type sensor module for wireless monitoring
    of heart rate and movement index Sens Actuators, 173 (2012), pp. 277-283 View
    PDFView articleView in ScopusGoogle Scholar [96] J.A. Healey, R.W. Picard Detecting
    stress during real-world driving tasks using physiological sensors IEEE Trans
    Intell Transp Syst, 6 (2) (2005), pp. 156-166 View in ScopusGoogle Scholar [97]
    C.S. Ikehara, M.E. Crosby Assessing cognitive load with physiological sensors.
    Proceedings of the 38th annual Hawaii international conference on system sciences,
    IEEE (2005), pp. 1-9 View in ScopusGoogle Scholar [98] J. Luprano, J. Sola, S.
    Dasen, J.M. Koller, O. Chetelat Combination of body sensor networks and on-body
    signal processing algorithms: the practical case of myheart project. Proceedings
    of the international workshop on wearable and implantable body sensor networks
    (BSN’06), IEEE (2007), pp. 76-79 Google Scholar [99] R.R. Fletcher, S. Tam, O.
    Omojola, R. Redemske, J. Kwan Wearable sensor platform and mobile application
    for use in cognitive behavioural therapy for drug addiction and PTSD. Proceedings
    of the annual international conference of the IEEE engineering in medicine and
    biology society, IEEE (2011), pp. 1802-1805 View in ScopusGoogle Scholar [100]
    A.J. Bandodkar, D. Molinnus, O. Mirza, T. Guinovart, J.R. Windmiller, G. Valdés-Ramírez,
    et al. Epidermal tattoo potentiometric sodium sensors with wireless signal transduction
    for continuous non-invasive sweat monitoring Biosens Bioelectron, 54 (2014), pp.
    603-609 View PDFView articleView in ScopusGoogle Scholar [101] F. Khoshnoud, C.W.
    de Silva Recent advances in MEMS sensor technology-biomedical applications IEEE
    Instrum Meas Mag, 15 (1) (2012), pp. 8-14 View in ScopusGoogle Scholar [102] M.
    Stikic, K. Van Laerhoven, B. Schiele Exploring semi-supervised and active learning
    for activity recognition Proceedings of the 12th IEEE international symposium
    on wearable computers, IEEE (2008), pp. 81-88 View in ScopusGoogle Scholar [103]
    Liu R., Chen T., Huang L. Research on human activity recognition based on active
    learning. Proceedings of the international conference on machine learning and
    cybernetics (ICMLC), 2010 (Volume:1) (2010), pp. 285-290 View in ScopusGoogle
    Scholar [104] E. Hoque, J. Stankovic AALO: Activity recognition in smart homes
    using active learning in the presence of overlapped activities. Proceedings of
    the 6th international conference on pervasive computing technologies for healthcare,
    IEEE (2012), pp. 139-146 View in ScopusGoogle Scholar [105] B. Longstaff, S. Reddy,
    D. Estrin Improving activity classification for health applications on mobile
    devices using active and semi-supervised learning. Proceedings of the 4th International
    ICST Conference on Pervasive Computing Technologies for Healthcare, IEEE (2010),
    pp. 1-7 CrossRefGoogle Scholar [106] T. Diethe, N. Twomey, P. Flach Bayesian active
    transfer learning in smart homes. Proceedings of the ICML active learning workshop
    (2015), pp. 1-6 CrossRefGoogle Scholar [107] F. Feldwieser, M. Gietzelt, M. Goevercin,
    M. Marschollek, M. Meis, S. Winkelbach, et al. Multimodal sensor-based fall detection
    within the domestic environment of elderly people Zeitschrift für Gerontologie
    und Geriatrie, 47 (2014), pp. 661-665 CrossRefView in ScopusGoogle Scholar [108]
    B. Khaleghi, A. Khamis, F.O. Karray, S.N. Razavi Multisensor data fusion: A review
    of the state-of-the-art Inf Fus, 14 (2013), pp. 28-44 View PDFView articleView
    in ScopusGoogle Scholar [109] Z. Elouedi, K. Mellouli, P. Smets Assessing sensor
    reliability for multisensor data fusion within the transferable belief model IEEE
    Trans Syst Man Cybern B Cybern, 34 (1) (2004), pp. 782-787 View in ScopusGoogle
    Scholar [110] H. Alemdar, C. Ersoy Wireless sensor networks for healthcare: a
    survey Comput Netw, 54 (15) (2010), pp. 2688-2710 View PDFView articleView in
    ScopusGoogle Scholar [111] R. Gravina, A. Alessandro, A. Salmeri, L. Buondonno,
    N. Raveendranathan, V. Loseu, et al. Enabling multiple BSN applications using
    the SPINE framework. Proceedings of the international conference on body sensor
    networks, IEEE (2010), pp. 228-233 CrossRefView in ScopusGoogle Scholar [112]
    C.R. Baker, K. Armijo, S. Belka, M. Benhabib, V. Bhargava, N. Burkhart, et al.
    Wireless sensor networks for home health care. Proceedings of the 21st international
    conference on advanced information networking and applications workshops (AINAW’07),
    IEEE (2007), pp. 832-837 CrossRefView in ScopusGoogle Scholar Cited by (129) A
    systematic review of data fusion techniques for optimized structural health monitoring
    2024, Information Fusion Show abstract Real-time automatic integrated monitoring
    of barn environment and dairy cattle behaviour: Technical implementation and evaluation
    on three commercial farms 2024, Computers and Electronics in Agriculture Show
    abstract Multimodal image fusion: A systematic review 2023, Decision Analytics
    Journal Show abstract Human reliability modeling in occupational environments
    toward a safe and productive operator 4.0 2023, International Journal of Industrial
    Ergonomics Show abstract Wearable technology and the cardiovascular system: the
    future of patient assessment 2023, The Lancet Digital Health Show abstract Application
    of Braided Piezoelectric Poly-l-Lactic Acid Cord Sensor to Sleep Bruxism Detection
    System with Less Physical or Mental Stress 2024, Micromachines View all citing
    articles on Scopus © 2017 The Authors. Published by Elsevier Ltd on behalf of
    IPEM. Recommended articles Administrative Database Research—It Is Here to Stay
    The Journal of Hand Surgery, Volume 44, Issue 9, 2019, pp. 717-719 Brent Graham
    View PDF Restoring standing capabilities with feedback control of functional neuromuscular
    stimulation following spinal cord injury Medical Engineering & Physics, Volume
    42, 2017, pp. 13-25 Raviraj Nataraj, …, Ronald J. Triolo View PDF A survey of
    sensor fusion methods in wearable robotics Robotics and Autonomous Systems, Volume
    73, 2015, pp. 155-170 Domen Novak, Robert Riener View PDF Show 3 more articles
    Article Metrics Citations Citation Indexes: 122 Policy Citations: 1 Captures Readers:
    431 Mentions News Mentions: 1 View details About ScienceDirect Remote access Shopping
    cart Advertise Contact and support Terms and conditions Privacy policy Cookies
    are used by this site. Cookie settings | Your Privacy Choices All content on this
    site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights
    are reserved, including those for text and data mining, AI training, and similar
    technologies. For all open access content, the Creative Commons licensing terms
    apply.'
  inline_citation: '>'
  journal: Medical Engineering & Physics
  limitations: '>'
  pdf_link: null
  publication_year: 2017
  relevance_score1: 0
  relevance_score2: 0
  title: Application of data fusion techniques and technologies for wearable health
    monitoring
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1016/j.inffus.2019.05.004
  analysis: '>'
  authors:
  - Billy Pik Lik Lau
  - Sumudu Hasala Marakkalage
  - Yuren Zhou
  - Naveed Ul Hassan
  - Chau Yuen
  - Meng Zhang
  - U-Xuan Tan
  citation_count: 202
  full_citation: '>'
  full_text: '>

    Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords 1. Introduction 2. Data fusion classification
    using multi-perspectives 3. Smart city applications overview 4. Challenges and
    open research directions 5. Conclusion Acknowledgement References Show full outline
    Cited by (211) Figures (2) Tables (3) Table 1 Table 2 Table 3 Information Fusion
    Volume 52, December 2019, Pages 357-374 Full Length Article A survey of data fusion
    in smart city applications Author links open overlay panel Billy Pik Lik Lau a,
    Sumudu Hasala Marakkalage a, Yuren Zhou a, Naveed Ul Hassan a b, Chau Yuen a,
    Meng Zhang c, U-Xuan Tan a Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.inffus.2019.05.004
    Get rights and content Highlights • Establish a multi-perspectives classification
    for smart city data fusion. • Review the smart city applications data fusion techniques
    for each domain. • List down current research trend within sub-domains in the
    smart city. • Discuss future challenges for implementing data fusion in the smart
    city. Abstract The advancement of various research sectors such as Internet of
    Things (IoT), Machine Learning, Data Mining, Big Data, and Communication Technology
    has shed some light in transforming an urban city integrating the aforementioned
    techniques to a commonly known term - Smart City. With the emergence of smart
    city, plethora of data sources have been made available for wide variety of applications.
    The common technique for handling multiple data sources is data fusion, where
    it improves data output quality or extracts knowledge from the raw data. In order
    to cater evergrowing highly complicated applications, studies in smart city have
    to utilize data from various sources and evaluate their performance based on multiple
    aspects. To this end, we introduce a multi-perspectives classification of the
    data fusion to evaluate the smart city applications. Moreover, we applied the
    proposed multi-perspectives classification to evaluate selected applications in
    each domain of the smart city. We conclude the paper by discussing potential future
    direction and challenges of data fusion integration. Previous article in issue
    Next article in issue Keywords Data fusionSensor fusionSmart cityBig dataInternet
    of thingsMulti-perspectives classification 1. Introduction According to UN estimates
    [1], 68% of the world population would be living in cities by 2050. Hence, managing
    the existing resources and infrastructure to cater sustainable urban living conditions
    for the growing needs of the urban population has become ever more challenging.
    Fortunately, the advancement in Information and Communication Technologies (ICT),
    Internet of Things (IoT), Big Data, Data Mining, and Data Fusion is gradually
    paving path for the emergence of smart cities [2], [3], [4]. In this paper, we
    adopt the following definition of smart city [5]: “A city combining ICT and Web
    2.0 technology with other organizational, design and planning efforts to de-materialize
    and speed up bureaucratic processes and help to identify new, innovative solutions
    to city management complexity, in order to improve sustainability and livability”
    The integration of aforementioned technologies into various urban domains enables
    city managers to equip with the necessary information for better planning and
    resource management. Several cities around the world have already been leveraging
    these technologies to improve the comfort, security, mobility, health, and well-being
    of their citizens. To better evaluate rapid progress and to recognize the efforts
    of urban planners, smart city ranking systems have been established. For instance,
    IESE cities in motion index [6] has suggested 83 indicators to rank 165 cities
    over 80 countries. New York, London, and Paris are the top three smart cities
    in 2018. Smart city projects in New York [7] aim to consistently improve the quality
    of residents’ life, reduce the environmental impacts, increase the street light
    efficiency, and enhance the water quality. Meanwhile, the focus of Smart London
    Projects [8] is to collect city wide data to provide world class connectivity,
    security, and smarter streets to its residents. Digital transformation, sustainability,
    and urbanization for improving citizen services are at the cores of Paris Smart
    City Projects [9]. The following up of the top smart city list includes Singapore
    and Tokyo, which are some other notable smart cities in the world. In Singapore,
    Smart Nation Project [10] has been proposed, which includes e-payment systems,
    smart nation sensor platform, smart urban mobility, and smart community initiatives,
    with the aim to enhance the national digital identity of its citizens. On the
    other hand, Tokyo [11] aims to become the greenest city in Asia Pacific by improving
    the transportation and other sectors of their economy. Local governments in several
    Chinese cities [12], such as, Shenzhen, Shanghai, Hangzhou, and Beijing are also
    shaping up their cities to facilitate economic and social development to build
    high income smart cities. In addition, there are several research institutes and
    laboratories focusing on developing smart city applications, which are currently
    leading the worldwide effort in smart domains. These include MIT Senseable Lab
    [13], Future Cities Laboratory [14], SINTEF Smart Cities [15], SMART [16], etc.
    Nowadays, communication technology is the backbone for the smart city applications
    as it provides a channel for applications to transfer data effortlessly. The ongoing
    quest for novel, more efficient, low-latency, and cost-effective communication
    technologies and networks, such as, 5G [27], [28], [29], wireless sensor networks
    (WSN) [30], [31], [32], Low Power Wide Area Network (LPWAN) [33], [34], and Narrow
    Band IoT (NB-IoT) [35], [36] and their integration in smart city projects is also
    relentless. These advancement has made many data sources available due to the
    potential of sensors collecting data with better coverage and power efficiency
    of the communication platform. With the large amounts of data becoming readily
    available in a smart city, data mining techniques [37], [38] are commonly used
    in the collected data. It helps in identifying the essential and important data
    sources in the smart city applications such as monitoring, control, resource management,
    anomaly detection, etc. With the availability of parallel data sources in various
    smart city domains, data fusion techniques that combine multiple data sources,
    lie at the heart of smart city platform integration. The major objectives of data
    fusion are to address problematic data while enhancing the data reliability and
    extracting knowledge from multiple data sources. The existing survey papers related
    to smart city applications or data fusion classification are summarized in Table
    1. Majority of these review papers [18], [39], [40], [41] strictly focus on one
    particular smart city domain or one genre of classification perspective. In [19],
    Alam et al. have conducted a review on data fusion technique based on mathematical
    model in IoT environment. Alternately in [20], Wang et al. have described the
    frameworks of data fusion within the smart city application. Interested readers
    can follow these references for additional technical details. However, there is
    only a handful of limited work to provide a multi-perspectives approach for data
    fusion problems in smart cities and this literature gap further motivates our
    study. Table 1. Literature review for data fusion on smart city. Surveys Objectives
    and topics covered Khaledgi et al. [17] Provides insights on the different types
    of data fusion techniques by exploring their concept, benefits, and challenges.
    Castanedo [18] Provides an overall view on the different data fusion techniques
    and methods. The author also reviewed common algorithms such as data association,
    state estimation, and decision fusion. Alam et al. [19] Provides a comprehensive
    survey on the mathematical model used in data fusion for specific IoT environments.
    Wang et al. [20] Proposes an IoT architecture concept to survey on the different
    sensor data fusion techniques and also provides an overall view on their evaluation
    framework. Zheng [21] Discusses about differences on fusing sources and varying
    techniques for cross domain data fusion. El et al. [22] Provides a survey on the
    intelligent transportation systems, which use data fusion techniques. Esmaeilian,
    B. et al. [23] Provides a throughout study on waste management for smart city
    aspects with three categories: (1) infrastructure for the collection of product
    lifecycle data, (2) new adapting business model, and (3) waste upstream separation
    techniques. Da Xu et al. [24] Provides an overall view on the current state of
    the industries for IoT and discusses key enabling technologies such as communication
    platforms, sensing technologies, and services. Chen et al. [25] Reviews the building
    occupancy estimation and detection techniques while providing a comparison between
    different sensor types for cost, detection and estimation accuracy, and privacy
    issues. Qin and Gu [26] Introduces the data fusion algorithms in IoT domains and
    data acquisition characteristics. Therefore, a different perspective to look at
    data fusion in smart city domains is necessitated by the expanding scale and scope
    of data sources, data collection techniques, and data processing system architectures.
    In order to cater evergrowing highly complicated applications, studies in smart
    city have to utilize data from various sources and evaluate their performance
    based on multiple aspects. To this end, we propose multiple generic perspectives
    with the ability to cover the entire depth and breadth of data fusion problems
    in smart city. These perspectives include data fusion objectives, data fusion
    techniques, data input and data output types, data sources, data fusion scales,
    and platform architectures for data processing. Utilizing proposed perspectives,
    we provide an overall view of classification techniques found in the seven domains
    of smart city applications such as: Smart Living, Smart Urban Area Management,
    Smart Environment, Smart Industry, Smart Economics, Smart Human Mobility, and
    Smart Infrastructure. A simple illustration of seven application domains discussed
    in this paper can be found in the Fig. 1. In each domain, we only select notable
    papers to demonstrate the universality and effectiveness of our multi-perspective
    approach on evaluating the data fusion techniques. Please note that we do not
    provide a comprehensive review of all the smart city applications. Afterwards,
    we talk about emerging data fusion trends in smart cities, while outlining the
    best practices for deploying a smart city application. In addition, data fusion
    challenges in different smart city applications are also identified and discussed.
    Download : Download high-res image (1MB) Download : Download full-size image Fig.
    1. List of smart city applications domain, where data fusion is commonly applied
    (each domain is enclosed in the dotted pink box). To summarize, our novel contributions
    in this paper are three-fold as shown below: • We propose a multi-perspectives
    classification to evaluate common data fusion techniques in smart city applications.
    • We provide an overview of smart city application domains and discuss the common
    trend of data fusion techniques in each domain utilizing proposed multi-perspectives
    classification. • We list down the future challenges and the ideal scenario for
    deploying data fusion techniques in a smart city application. Overall, we believe
    that with these contributions, the readers would have a quick grasp on the current
    data fusion trends in smart city research without extensively going through all
    the details. The rest of the paper is organized as follows: in Section 2, we define
    the data fusion classification using multi-perspectives to evaluate a smart city
    application. This lays a foundation for evaluating the smart city applications
    leveraging data fusion techniques. In Section 3, different application domains
    of smart city based on data fusion techniques are evaluated using the proposed
    multi-perspectives classification of data fusion. In addition, a brief overall
    view of the current research trend of respective domain is presented. Subsequently
    in Section 4, we discuss the ideal data fusion scenario along with potential research
    directions/opportunities based on speculations of smart city applications from
    previous section. Lastly, we conclude our works in Section 5. 2. Data fusion classification
    using multi-perspectives In this section, we identify multiple generic perspectives
    with the ability to cover the entire depth and breadth of data fusion literature
    in smart city applications. We use smart city single perspective data fusion review
    papers [19], [26] and non-smart city data fusion classification papers [18], [39],
    [40], [41] as references. In non-smart city literature, there are four well-known
    data fusion classification techniques, which are Dasarathy’s Classification [39],
    Whyte’s Classification [40], Fusion Architecture’s Classification [18], and US
    Joint Directories of Laboratories (JDL) data fusion classification [41]. Dasarathy’s
    Classification is based on the data input and output types between data, where
    Whyte’s Classification focuses on the relationship between the data. JDL focuses
    on classifying the fusion process according to five processing levels. Meanwhile,
    the architecture-based classification only captures the system design level and
    does not consider data relationships and types. Most of the aforementioned classification
    of the data fusion techniques are not suitable for evaluating the applications
    of a smart city. Our proposed data fusion classification approach for smart city
    comprises of six different perspectives (also called categories): i) data fusion
    objectives (O), ii) data fusion techniques (T), iii) data input and output types
    (D), iv) data source types (S), v) system scales (L), and vi) platform architectures
    (P). Within each category, we further identify various sub-categories (also called
    classes). Overall, there are 30 different classes. The complete list of the adopted
    classification indicating all the categories and their classes is shown in Table
    2. Short reference codes (O, T, D, S, L, P) for each class are also included in
    the table for further use in the paper. For example, O1 refers to the data fusion
    objective category and problematic data fusion class. Similarly, S3 refers to
    data source types category and participatory class. Table 2. Data fusion classifications
    for smart city applications using multi-perspectives. Perspective/Category Code
    Classes Data Fusion Objectives O1 Fixing Problematic Data O2 Improving Data Reliability
    O3 Extracting Higher Level Information O4 Increasing Data Completeness Data Fusion
    Techniques T1 Data Association T2 State Estimation T3 Decision Fusion T4 Classification
    T5 Prediction / Regression T6 Unsupervised Machine Learning T7 Dimension Reduction
    T8 Statistical Inference and Analytics T9 Visualization Data Input and Output
    Types D1 Data in Data Out (DAI-DAO) D2 Data In Feature Out (DAI-FEO) D3 Feature
    in Feature Out (FEI-FEO) D4 Feature in Decision Out (FEI-DEO) D5 Decision in Decision
    Out (DEI-DEO) Data Source Types S1 Physical Data Sources S2 Cyber Data Sources
    S3 Participatory Data Sources S4 Hybrid Data Sources Data Fusion Scales L1 Sensor
    Level Fusion L2 Building Wide Fusion L3 Inter-Building Fusion L4 City Wide Fusion
    L5 Inter-City Fusion (or Larger) Platform Architectures P1 Edge Computation P2
    Fog / Mist Computation P3 Cloud Computation P4 Hybrid Computation Note that, there
    could be potentially more than one perspectives (other than data sources, fusion
    scales, and platform architecture) for smart city application depending on the
    complexity and fusion objective itself. Below, we provide further details of all
    the perspectives and classes adopted in this paper. 2.1. Data fusion objectives
    (O) The data fusion techniques deployed in a smart city project is influenced
    by the objective of applications. In this paper, we have summarized the four objectives
    as follows: • O1: Fixing Problematic Data ‘Problematic Data’ class refers to the
    case when the data source is having quality issues such as, inconsistency, imperfection,
    disparateness, etc. Data fusion could be used as an easy approach to overcome
    such problems. Examples of O1 can be found in [27], [42], [43], [44]. • O2: Improving
    Data Reliability Data may suffer from reliability issues when it is collected
    in a less ideal (less controlled) environment with high presence of noise. In
    such situation, additional data sources are required to add redundancy for increasing
    data quality to enhance data reliability. Such situations are identified as ‘Data
    Reliability’ class and [45], [46], [47], [48] exhibits such pattern. In addition,
    security enhancement through the data fusion also belongs to this category and
    examples of such objectives can be found in [49], [50], [51]. • O3: Extracting
    Higher Level Information Data mining advancement has contributed to many different
    architectures of data fusion in order to obtain knowledge from multiple data sources.
    For instance, the occupancy of a building can be detected using a combination
    of few ambient sensors with data fusion, where occupancy information cannot be
    directly inferred from the raw data sources. We classify these approaches as ‘Higher
    Level Information Extraction’ class and examples can be found in [52], [53], [54].
    • O4: Increasing Data Completeness In a situation of coverage limitations, an
    individual data source is insufficient to provide complete details of the desired
    output. Therefore, in ‘Data Completeness’ class, data fusion is performed across
    multiple data sources to obtain a complete picture of the overall system such
    as [55], [56], [57]. 2.2. Data fusion techniques (T) In this category, we present
    the data fusion techniques in two different information enrichment obtained after
    data fusion. The T1 until T3 are the common data fusion techniques and the further
    details can be found in [19], [39], where it describes the lower level information
    being fused to generate identical level of information. The techniques are associated
    with data mining [38], [58], where simple input data from multiple sources is
    fused to generate higher level information enrichment. Brief description of these
    classes is given below: • T1: Data Association Data association refers to data
    fusion technique that fuse data based on similarity between at least two or more
    data sources. Common techniques for data association include Nearest Neighbors
    [59], Probabilistic Data Association [60], and Multiple Hypothesis Test [61].
    • T2: State Estimation State estimation indicates the usage of multiple data sources
    to achieve higher sate estimation accuracy. Common techniques under this category
    are Maximum Likelihood [62], Kalman Filter [63], Particle Filter [64], and Covariance
    Consistency Model [65]. • T3: Decision Fusion Decision fusion is a technique that
    is used to fuse the decisions made by various sub-components of a system to achieve
    a certain overall objective. For instance, a robot can fuse different decisions
    from the modules to perform an actuation (direction, events, or actions). General
    techniques include Bayesian inference [66], Dempster–Shafer Inference [67], and
    semantic approaches [68]. • T4: Classification Classification technique denotes
    methodology of grouping objects into different classes based on their unique characteristics.
    In-depth details of generic classification techniques can be found in [38], [58].
    • T5: Prediction Prediction techniques are used to forecast output based on single
    or multiple different data sources. Note that, this covers simple methods such
    as regression and as well as complicated methods such as forecast modeling. Examples
    of such can be found in [69], [70], [71] • T6: Unsupervised Machine Learning Unsupervised
    machine learning tries to automate the knowledge discovery without relying on
    the data labels. Examples of such methods involves clustering [72], anomaly detection
    [73] and others [38]. Note that, semi-supervised machine learning approach [74]
    is also categorized under this class. • T7: Dimension Reduction Dimension reduction
    refers to the method of reducing data sources’ dimensions for features extraction
    or visualization purposes. Examples of dimension reduction techniques are Principal
    Component Analysis (PCA) [75], and others [38]. The aim is to preserve the characteristic
    of the data sources while reducing the complexity of processing high dimensional
    data. • T8: Statistical Inference and Analysis Statistical inference and analysis
    is used for outlining certain information along with some common knowledge / hypothesis
    from the input data sources. Examples of papers using such approaches can be found
    in [76], [77] • T9: Visualization Visualization is a technique used for the presentation
    of output to the end users via some platform. The end result often requires human
    intervention. Examples of such techniques can be referred to the following papers
    [78], [79], [80]. 2.3. Data input and output types (D) Dasarathy’s classification
    [39] is based on input and output of fusion technique to determine the relation
    between input and output data. There are five classes in data input and output
    perspective. Brief details are given below: • D1: Data In Data Out (DAI-DAO) Data
    In Data Out (DAI-DAO) refers to the situation when multiple raw data sources are
    fused to increase data reliability and the output after fusion is still a raw
    data. • D2: Data In Feature Out (DAI-FEO) Data In Feature Out (DAI-FEO) refers
    to the situation when multiple raw data sources are fused to extract some unique
    feature of the observed system. The output feature describes certain aspect of
    the system and it could be further used for more feature extraction or to make
    certain decisions. • D3: Feature In Feature Out (FEI-FEO) Feature In Feature Out
    (FEI-FEO) refers to the situation when multiple unique features from different
    sensors are combined to generate new features. This class is commonly known as
    feature fusion. • D4: Feature In Decision Out (FEI-DEO) Feature In Decision Out
    (FEI-DEO) refers to the situation when certain features of the system are fused
    to make certain decisions, e.g. actuation of various system components. • D5:
    Decision In Decision Out (DEI-DEO) Decision In Decision Out (DEI-DEO) refers to
    the situation when different decision sources (maintenance status, events, etc.)
    are combined to obtain a final output decision. 2.4. Data source types (S) There
    are four types of generic data sources in smart city applications and we categorize
    them based on the data sources regardless of the communication medium. Details
    of each category can be found as follows: • S1: Physical Data Sources The physical
    data sources are collected from sensors that are being deployed to capture information
    of a particular space, area, or even city wide. Examples of the physical sensors
    include temperature [81], air quality [82], camera [83], ultrasonic [84], LiDAR
    [85], and etc. Note that, we categorize smart city application based on the data
    sources rather than the method they are acquired. For instance, a temperature
    probe in a sensor nodes of a wireless sensor network (WSN) transmits data through
    gateway to cloud database is considered as physical data source, S1. • S2: Cyber
    Data Sources Cyber data sources denote datasets which are commonly obtained from
    the Internet domain such as social media information [76], [86], web access data
    [87], [88], and opinion based datasets [89]. Social media information involves
    major social media platforms such as Twitter, Facebook, LinkedIn, Weibo, and others.
    Note that, usually the data is acquired through data mining techniques. Meanwhile,
    the web access data can be obtained from web applications programming interface
    (API), such as transportation tickets information and online customer records.
    Apart from that, open datasets refer to data from third party vendors such as
    telecom operator or a company with readily available data. • S3: Participatory
    Data Sources Participatory data sources include crowdsensing [90], [91] and crowdsourcing
    [92], [93] data contributed by the personal devices, e.g. mobile phones, wearable
    devices, tablets, etc. of the users in smart city. Users provide the data voluntarily
    or through some incentive mechanisms. • S4: Hybrid Data Sources The hybrid data
    sources include data obtained from mixed data sources [94], [95], e.g. by combining
    the participatory and physical sensor data. As pointed in [21], hybrid data sources
    can achieve more insights as compared to single data sources. 2.5. Data fusion
    scales (L) The scale of data fusion is also an important classification perspective.
    Please note that data fusion scale is based on sensor coverage rather than sensor
    deployment. There are four different classes, which are described below: • L1:
    Sensor Level Fusion At the sensor scale, data from various physical sensors is
    fused to form an output such as [53], [96]. For instance, fusion of data collected
    by various smartphone sensors is an example of data fusion at sensor level. •
    L2: Building Wide Fusion At the building wide scale, data sources collected within
    a premise or building is fused to form an output. For instance, fusion of building
    energy and building security data to develop a building management system [97],
    [98], [99] is an example of data fusion at building level. • L3: Inter-Building
    Fusion In the inter-building scale, the data sources collected over several buildings
    are fused to form an output, where the scale of deployment normally includes small
    area. For example, data sources of several buildings within a university are used
    to generate a particular output is considered as inter-building scale. Other examples
    of this data fusion scale also can be found in [100], [101]. • L4: City Wide Fusion
    In the case of city wide fusion, data sources that involve whole city’s area as
    input for the data fusion architecture fall under this class such as [102], [103],
    [104]. For instance, the study of citizen behavior involves fusion of data gathered
    in different areas of the city is considered city wide data. • L5: Inter-City
    Fusion (or larger) At the inter-city fusion (or larger) scale, data from large
    areas involving one or more cities or terrains (mountains, sea, forests, etc.)
    is fused to form an output. Examples of this scale involve comparing one smart
    city to another city or data of a city outskirts and its surrounding areas. More
    examples of inter-city fusion (or larger) can be referred to [43], [105], [106].
    2.6. Platform architectures (P) The architecture of computational platform involved
    in data fusion is another important classification perspective. In this category,
    we identify four generic classes: • P1: Edge Computation Platform In edge computation
    platform, data sources are processed and fused at the edge (i.e. very close to
    the physical location, where data is actually collected). Edge computation devices
    include micro-controller, computing devices (Raspberry pi), computers, etc. Such
    architecture can be found in works such as [96], [99], [101]. With this architecture,
    communication overheads and latency can be significantly reduced. • P2: Fog Computation
    Platform In fog computation platform, data sources are processed and fused at
    the middle layer, i.e. between the edge and the cloud. In this architecture, data
    is periodically or continuously sampled at the edge (without processing) and is
    then forwarded to a gateway (that acts as a fog device). At the gateway, computing
    resources are provided for data processing. Both fog computing and edge computing
    platforms provide similar benefits of offloading computation as shown in [102],
    [107], [108]. However, fog computing architecture should be preferred when it
    is difficult to find stable power sources at the edge. • P3: Cloud Computation
    Platform In cloud computation platform, data sources are processed and fused in
    the cloud. This is the most common technique practiced by industry and research
    institutes for processing big data. Examples of this architecture being used are
    [56], [87], [109]. The advantages of cloud computing architecture includes ready
    access to the data and both online and offline for further processing or fusing.
    The disadvantages include increased communication overheads and costs. • P4: Hybrid
    Computation Platform In hybrid computation platform, processing is distributed
    among two or more layers (edge, fog and cloud) as shown in [105], [110], [111].
    In this architecture, depending on the available resources or application objectives,
    some low level data fusion and processing is done at the edge or fog, while high
    level information is extracted in the cloud. 3. Smart city applications overview
    Smart city applications tend to have extremely diverse requirements, which contribute
    to a large variety of different techniques and requirements as stated previously
    in Section 2 for different domains. Thus, it is necessary to evaluate the smart
    city applications from a more generic perspectives rather than one specific perspective.
    In this section, we select smart city applications with data fusion techniques
    from different domains listed in Fig. 1, and evaluate them based on multi-perspectives
    from the Section 2. Note that, there exist some literatures that are cross-disciplinary,
    which may involve more than one domain. In order to address the cross-disciplinary
    smart city applications, we have grouped them into their closest relevant domain.
    In each application domain, we outline sub-domains and present works related to
    data fusion techniques. Using the proposed data fusion classification based on
    multi-perspectives, we discuss the common data sources and fusion techniques,
    along with the current research trends in each domain. 3.1. Smart living Smart
    living concerns with the life of the urban citizens and revolves around the concept
    of improving live-ability in urban area. In the literature, the general objectives
    of utilizing the smart living domain involve data being used to extract higher
    level information or increasing the data completeness. In addition, smart city
    applications in this domain often leverage the cloud or hybrid platform architecture.
    In this domains, we have studied three different aspects of smart living, namely,
    (1) Smart Health, (2) Smart Home, and (3) Smart Community (Table 3). Table 3.
    List of smart city applications using data fusion technique(s). Domain Sources
    O S D T L P Remarks Smart Living [52] 3 1 2 4 1 4 Smart Healthcare [112] 3 1 1
    4 4 4 Voice Pathology Detection [113] 3 3 4 3 2 4 Smart Home Healthcare Monitoring
    [110] 3 1 2 4 1 4 Daily Activity Classification [45] 2 1 2 4 2 4 Smart Home Activity
    Recognition [111] 3 1 3 4 2 4 Tele-Rehabilitation [114] 4 4 4 3 2 4 Smart Home
    Control System [79] 3 4 3 9 4 4 Intelligent Video Surveillance [115] 3 3,4 4,5
    4,5 5 3 Distance Learning [116] 3 2 3 1 4 3 Smart Community Smart Urban Area Management
    [94] 4 4 4 5 2 3 Building Management [117] 4 1 2 2 1 1 Fire Detection System [118]
    3 3 4 3 5 3 Lean Government [43] 1 1 1 1 5 1 Urban Planning with Satellite Images
    [95], [119] 3 4 1,2 8,9 4 3 Urban Space Utilization Detection [56] 4 3 1 9 4 3
    Fault Reporting Platform [76] 3 4 3 8,9 5 3 Landscape Rating Systems Smart Environment
    [106] 3 1 1 9 5 3 City Environment Monitoring [78] 3 1 2 2,9 1 1 City Building
    Map Modeling [120] 3 4 4 4 5 1 Forest Types Classification [46] 2 1 1 1 5 1 Long
    Term Landscape Monitoring [121] 4 1 4 4 5 1 Forest Species Classification [122]
    3 4 2 4 1 1 Waste Water Treatment [102] 4 1 2,3 2,9 4 2 Urban Solid Waste Management
    Smart Industry [96], [123] 4 1 2,4 2,4 1 1 Fault Detection [124], [125] 3,4 1
    3,4 5 1 1 Tools Life Prediction [98] 2 4 4,5 3 2 1 Decision Support in Manufacturing
    [51] 2 1 2,4 2,3 1 1 Autonomous Robots and Security [126] 3 1 2,4 4,7 1 1 Seafood
    Freshness Classification [127], [128] 3,4 1 2,4 2,4,5 1 1 Agriculture Plant Disease
    Classification Smart Economics [87] 4 2,3 1,3 1,8 5 3 Customer Profiling [129]
    4 4 1,4 5 5 3 Consumer Awareness [107] 4 4 1 9 5 2 Blockchain and Supply Chain
    [130] 3,4 4 2,4 1,5,8 5 3 Supply Chain Management [77] 3 2,3 2,3 5,8 4 3 Tourist
    Behavior Analysis [57] 4 4 2,3 6 4 3 Travel Recommendation System [131] 3 1,2,3
    2 1,4 4 1,3 Tourist Tracking Application Smart Human Mobility [132], [133] 2,3
    1 1 5,1 4 3 Outdoor Positioning [134], [135] 2,4 1 1 1,2 2 3 Indoor Positioning
    [136], [137] 4 1 4 5,1 4,2 3 Location-based Services [103] 3 3 2 1 4 3 Obtaining
    Origin-Destination Matrices [54] 3 3 2 4 4 3 Identifying Transportation Modes
    [138] 3 3 2 1 2 3 Monitoring Visitors Inside a Building [109] 4 1 4 3 4 3 Traffic
    Signal Controlling [139] 3 3 2 1 4 3 Analyzing Public Transport Services [140]
    4 1 4 4 1 3 Autonomous Vehicle Controlling Smart Infrastructure [55], [88] 3,4
    1 2,4 5 4,1 1 Smart Grid and Power Utilities [101], [141] 3 1,4 1 4,5 3 1 Solar
    Farm [105] 3 3 2 2 5 4 Smart Metering [27], [42] 1,2 1 1 1,2 1 1,3 Communication
    (5G) [47], [48] 2 1 1 1,5 1 1 Communication (WSN) [142] 4 1 2,3 4 1 1 Drone Detection
    [143] 3 4 1,2 2 4 3 Smart Parking System [99] 4 1 1 2 2 1 Bridge Monitoring Platform
    [104] 3 1 2,3 4,5 4 3 Water Distribution System 3.1.1. Smart health Healthcare
    is a crucial component in everyday life concerning medical and public practices
    using devices as defined by Lee and Co-authors [144], [145]. The rapid development
    of technology (e.g. smartphones and their in-built sensing devices such as heart
    rate sensors) provides more opportunities to adopt technology in healthcare applications
    pervasively. For telehealth application in smart city, Hossain et al. [112] have
    used electroencephalographic (EGG) signals and voice to monitor a specific user’s
    health with the support of cloud technology and doctor’s advices. In [113], work
    has shown to monitor elderly at home based on fuzzy fusion model using behavioral
    and acoustical environment data. Similarly, Noury [146] also monitors the activities
    and fall detection of elderly through fuzzy logic by fusing accelerometer, vibration,
    and orientation sensor. In [91], Marakkalage et al. have used crowd-sensing data
    from a smartphone application (location, noise, light, etc.) and introduced sensor
    fusion based environment classification (SFEC) to profile elderly people for understanding
    their daily lifestyle. In addition, Dawar and Kehtarnavaz [52] have implemented
    a Convolution Neural Network (CNN) to combine both depth camera and wearable devices
    to detect the transition of movements to fall. Apart from that, Hondori et al.
    [111] have proposed using sensor fusion between depth images and inertia to perform
    tele-rehab in the home. The main challenge occurs in pervasive smart healthcare
    data fusion is discussed in [147] as the need of a higher accuracy to improve
    sensing robustness against uncertainty and unreliable integration. 3.1.2. Smart
    home The concept of Smart Homes plays an important role nowadays in contemporary
    urban areas. According to Jiang et al. [148], the definition of a smart home provides
    the capability of controlling, monitoring, and accessed appliances & services
    through implementation of ICT. There are currently many big players in developing
    the smart home appliances such as Amazon, Google, Apple, IBM, Intel, Microsoft,
    Xiaomi, and others. The challenge faced by manufacturers are related with service
    integration and formulating software ontology platform. These are necessary for
    implementing the services through different vendors and allow for a better integration.
    Meanwhile in [114], physical sensors (soil moisture) and cyber (weather, traffic)
    have been fused to control home appliances such as alarm clock and water sprinkle.
    The study of user daily activity is yet another important aspect to understand
    urban citizen well-being. In [45], Hong et al. have combined series of life activities
    to understand the lifestyle pattern depends on the equally weighted sum operation
    and Dempster-Shafer theory. Also, similar study on the user daily activity patterns
    can be found in [110]. Combination of house environmental sensor (infrared, door
    contact, temperature, hygrometry sensor, microphone) and wearable devices (kinematic
    sensors) using support vector machine (SVM) can be used to identify the user activity
    patterns. In addition, the modeling of human behavior in a smart home [149] in
    order to generate learning situation models have proven the efficiency of context-aware
    services. In addition, smart home security is yet another study field for many
    researchers [150], [151], [152] due to increased usage of IoT devices in normal
    household. The research challenges is to develop the applications for the smart
    houses while retaining the privacy and security of the end user. 3.1.3. Smart
    community According to Smart Communities Guidebook [153], a smart community is
    described as “a geographical area ranging in size from neighborhood to a multi-county
    region whose residents, organizations, and governing institutions are using information
    technology to transform their region in significant ways”. There is only a handful
    of cities focus on this aspect as majority are still in the stage of transforming
    from facility to community welfare. First world countries such as USA, Canada,
    Australia, European Union, and Singapore shown in [154] have started up initiatives
    to create smart communities. Information fusion for smart community video surveillance
    system is performed in [79] to aid neighborhood in terms of security. The combination
    of the different modal surveillance camera provides a vast amount of visual information
    extraction such as video summarization for highlighting certain events. A distance
    learning framework is proposed in [115], which enables personalized learning to
    cater what is best for each individual user. It uses data fusion to understand
    user environment and their activities by means of hybrid data sources. Real-time
    community monitoring also helps to prevent emergency situations and it ensures
    the safety of community citizens. A good example for a smart community application
    in large-scale is the Social Credit System in China [155]. It is a state-owned
    system to collect data from both public (traffic cameras, transit data etc.) and
    private (online shopping, fitness trackers etc.) data sources to monitor and analyze
    user behaviour to generate a single ”credit score” for each person, which helps
    in community well-being. The techniques fuse these data sources and remains a
    back box to the general public. However, the effect on user privacy with the rise
    of “data state” remains a debate for some [156]. A mature citizen should be on
    alert and always responds to any potential threat, while spreading the awareness
    to build a safer community in the urban city. 3.2. Smart urban area management
    Smart urban area management denotes the managing of urban area using ICT. Sub-domains
    in this regime composed of urban planning, governance, and smart buildings. For
    an application to fit into this definition, the minimum scale would be at the
    building level (e.g. a building management system). The main trend of data fusion
    techniques being applied in this domain mostly consists of objectives of extracting
    higher level information or increasing the data completeness. The end product
    of data fusion include visualization of information for respective authorities.
    3.2.1. Smart governance In smart governance, managing a city is considered as
    a complex task as the integration of different domains and services is proven
    to be challenging. Transparent services integration is an example of why many
    governance authorities are having difficulties to sort it out. It is hard to strike
    a balance in developing a transparent governance policy with consideration of
    sensitive information. Therefore, there is only limited study materials available
    to the best of our knowledge. Janssen and Estevez [118] have proposed a centralized
    platform for cutting down government staff by shifting existing organization to
    rely on integration of platforms. The disaster response management is also considered
    as another vital element for a smart city to carry out any potential counter measurements
    towards disaster as shown in [157]. Apart from that, urban reporting system [56]
    has collected report from the city wide region on the faulty infrastructure so
    that immediate actions can be taken to remedy the situation. It uses cloud technology
    and focuses on the display of fused data report, which it also describes the location
    and types of infrastructure. Example of research challenges is to remove any potential
    fake report to prevent misuse of the reporting platform. Another example of smart
    governance that involves city safety can be found in [158], where it can act as
    an emergency aid application (light pulse on emergency through mesh network) while
    providing energy efficient lighting to urban area. Moreover, there are cities
    also working on governance platform such as New York [7], Singapore [10], Tokyo
    [11], Oslo [159], and others. The potential research opportunity is to propose
    consensus protocols within the city for better integration of services. 3.2.2.
    Smart urban planning Urban planning plays an important role in developing the
    city economy by taking account of well-being of the urban residents. Traditionally
    in urban planning, aerial photography and statistical data sources (building size,
    population number, public amenities, etc.) are combined to understand the current
    development state of the city. The downside of such method is data sources frequently
    lacks of fine details, which resulting the output result is not representative.
    To address such issue, Cheng and Toutin [43] have combined various satellite and
    aerial images to generate details for the exiting urban structures. Alternately,
    low power sensors are capable to provide a larger coverage with lower deployment
    cost, which give researchers the opportunity to study different points of interest
    in the urban area. In [81], [95], [119], a bottom up urban planning method is
    implemented, where sensors are installed in a designated region to capture space
    utilization. From the collected data, urban planners can study public space utilization
    pattern using an integrated portal. Here, a hybrid processing method is proposed,
    where the data processing and fusion occur in different stages of data pipeline.
    In addition, a large variety of data sources can be used for urban planning such
    as physical sensors [160], photography [76], [161], or hybrid data sources [85].
    Despite wide variety of data sources, human interpretation is required when it
    comes to make decision on a proposed urban design. The need of full automated
    planning system would further benefit the urban planners to combine different
    data sources in order to achieve a more ideal city planning. 3.2.3. Smart building
    Urban building management provides building owner a platform to understand building’s
    energy consumption rate while automating building resources management. It has
    been extensively studied in [25], [162], [163], [164] and the current trend is
    to optimize the building resources such as hot water systems, electrical consumption,
    and heating ventilation & air conditioning (HVAC). In [94], Aftab et al. have
    combined four different parameters to predict building occupancy to control HVAC
    using low-cost embedded systems. Some other works such as [97], [165], [166] also
    have the same objectives but using different types of data sources. The potential
    solution for better building management system is to rely on fusing weather, human
    feedback, and electricity price to fine tune the building resources in order to
    maximize human comfort, while minimizing the energy consumption. Apart from that,
    fire alarm system is considered another important features of the smart building
    management system. Luo and Su [117] have fused three different data sources (flame,
    smoke, and temperature sensor) to detect any potential fire outbreak and reduce
    false alarms. In addition, a notification-based system is implemented to notify
    the property owner and manager in case of emergency. In future, potential building
    safety features may include a group of robots to deal with fire hazards and double
    duty as building security patrols. 3.3. Smart environment Smart environment studies
    the surrounding of a given area of interest, which covers the internal and external
    surrounding of a city. From the literature, we observed that majority of the data
    sources consist of physical and hybrid data sources, while the data scale often
    represent a large spatial coverage. Nowadays, the most common surrounding effects
    studied in the smart city include urban heat island (UHI), green house effect,
    and global warming. In addition, we have grouped urban waste management under
    this domain because it also has an environmental impact. 3.3.1. Landscape monitoring
    The main challenge of landscape monitoring in smart city is the sensing coverage
    of the data sources. To address such issue, two different sensing approaches have
    been used such as relying on mobile sensing or satellite-based data. Mobile sensing
    [106], [167] offers greater sensing capability by leveraging the mobility of moving
    objects (vehicles or humans). The mobile sensing technique provides a large spatial
    coverage, but it is not suitable for real-time applications unless there are multiple
    data sources to compensate the lack of spatial resolution concurrently. The output
    type of this mobile sensing includes combination of different spatial data in
    order to complete the data sources before proceed to data processing stage. Mobile
    sensing works such as [82], [168] utilized different data sources to complete
    spatial resolution and visualized the ambient changes across the city. The common
    characteristic of aforementioned works is feature extraction, which they visualize
    the processed features from the raw data sources. Majority of data input and output
    types in this domain are DAI-DAO and DAI-FEO since physical sensors are the common
    data sources. Using the satellite-based data sources, Shen et al. [46] have studied
    the UHI effect in a city using data sources collected over 26 years. The UHI index
    changes are measured through the combination of Landsat and MODIS images data.
    Mobile sensing offers a lower deployment cost, where it sacrifice the spatial
    resolution given there is limited number of sensors. Also, it has a lower coverage
    compared to satellite data sources. In contrast, satellite data has a wider coverage
    of spatial resolution but it frequently needs data enhancement and lacks of finer
    details. 3.3.2. Urban city modeling The surrounding natural resources of an urban
    city such as mountains and forests are considered as important assets of a city.
    The most common data sources in modeling the city area are satellite images, which
    as stated before, it requires data enhancement such as [169], [170] before using
    it. Therefore, prior work of data fusion [171] was focused on improving the satellite
    images quality. Only until recently, the emergence of machine learning algorithms
    and faster computers have created new ways to extract large variety of satellite
    image features. For instance in [120] and [121], forest types classification have
    been conducted in order to understand the variety of tree species in a specific
    region of interest. Both methods involve region-wide data sources and classification
    techniques, which are used to identify the tree species based on the forest types.
    With a lower deployment cost, small satellite (smallsat) and nano satellite (nanosat)
    could improve spatial coverage to generate a better data sources. Smart city applications
    leveraging satellite data will also beneficial from these deployment. 3.3.3. Waste
    management With astonishing rate of garbage being generated daily, waste management
    for an urban city can be rather challenging. Thus, it is essential to handle the
    waste efficiently to improve on sustainability of a city. An example of such effort
    could be found in [23], where they have proposed three new aspects of a smart
    waste management system such as: (1) infrastructure to overlook the overall life
    cycle of the product, (2) new business models revolving the product life cycle
    for preventing any waste generation, and (3) intelligent sensor networks for waste
    management facilities. In [102], Catania and Ventura have combined the proximity
    reading and weight sensor from garbage bin to estimate the garbage capacity of
    a typical household. Afterwards, rubbish categories collected from user mobile
    devices and garbage trucks are combined to keep track of residential participation
    in recycling scheme. On the other hand, waste water treatment helps to manage
    liquid waste of urban city before discharging to river or reuse. Chang et al.
    [122] have combined landsat and MODIS dataset in order to trace the water pollution
    level of a lake. On top of that, a web portal has been deployed to visualize and
    monitor the water pollution region over the time. Currently, many researchers
    are working together to develop an efficient waste management system since there
    is only limited resources available on earth. The goal is to adopt the 3R (Reduce,
    Reuse, and Recycle) concept with the help of ICT to improve city resource sustainability.
    3.4. Smart industry With the upcoming Industry 4.0 standards [172] touted as the
    gold standard of the future, various industries have been experiencing transformation
    with automation and data driven approaches. The majority of smart industry applications
    often leverage data collected from physical sensors while data fusion techniques
    are often performed at sensor or building level. Here, smart industry can be divided
    into three sub-domains, which are Smart Manufacturing, Smart Maintenance, and
    Smart Agriculture. 3.4.1. Smart manufacturing Smart manufacturing denotes the
    factory that depends on ICT to optimize the manufacturing process by increasing
    the production throughput. In [98], De Vin et al. have proposed a simulation tool
    to test out the management decision support by fusing undisclosed data entries
    and manufacturing process events. Similar to the aforementioned approach, decision
    based fusion can also be seen in [173], [174], which combines different machinery
    sensors data and data warehouse entries. The data fusion integration also considers
    supply chain demand in order to further optimize the manufacturing process. The
    challenge in this domain is to develop a self-optimizing manufacturing process
    while delivering the products to meet the demand of supply chain. Therefore, smart
    manufacturing frequently has a high correlation with the supply chain and attempts
    to deliver the market needs. In addition, the robotics usage in the smart manufacturing
    domain is nothing new. Guo et al. [51] have proposed an anomaly detection to combat
    potential security aspects in the robots using sensor fusion technique such as
    state estimation. 3.4.2. Smart maintenance The reliability and stability of the
    equipment and machinery is vital to all the industries to ensure smooth operation
    in production. Without the guarantee of smooth operation, any downtime can cost
    damages to reputation and also loses profit. Thus, preventive maintenance has
    been studied in [124], [125], [175], [176] and attempts to predict the remaining
    useful life (RUL) of a machine accurately. By accurately predicting the RUL, maintenance
    can be carried out on time to save cost only when needed. The common data fusion
    techniques for predicting RUL are neural network (NN) based model such as CNN
    and Deep NN (DNN). Please note that, common data source in this sub-domain is
    physical data source such as machine states, sensors readings, and related parameters.
    Nonetheless on the fault detection domain, machine fault detection can be found
    in [96], [123], where they describe the problem of fault diagnosis and apply data
    fusion techniques to overcome. State estimation and classification have been used
    to detect the current state of the machinery. The data sources share some similarity
    with the preventive maintenance, where lower level of data information is preferred.
    This yields a faster fault detection when compared to a complex data pipeline.
    The research challenge here is to develop a generic and a flexible maintenance
    system for different scale of applications adhering to the goal of accurate fault
    detection. 3.4.3. Smart agriculture In order to produce sustainable food resources
    in smart city, smart farming [177], [178] has become a trend to meet the food
    supply demand in a smart city. There are two different sub-domains in smart farming
    such as land and sea agriculture. In the land agriculture aspect, planting crops
    using controlled environment has shed some light in fulfilling the city needs
    of fresh supplies. However, plant disease remains a potential threat to a highly-dense
    plantation crop framing. In [127], Moshou et al. have classified the plant disease
    infection through Self Organizing Map (SOM) by fusing the spectral reflection
    and fluorescence imaging data. This helps to isolate infected crops while it focuses
    on the production of healthy plants. Apart from that, electromagnetic induction
    sensors, vegetarian index, water stress level, and radiance data are combined
    in [179] to better determine the partition of the crop field. Similar work also
    can be found in [128], where Khanum et al. propose an ontology-based fuzzy logic
    to classify plant disease. The research gaps in this domain involve improving
    live stock management as well as optimizing smart farm. On the other hand, sea
    agriculture is responsible for supplying the seafood supplies in a city. Obtaining
    fresh seafood supplies in an urban city sometimes can be rather difficult due
    to various factors such as delivery, city location, weather, seasonal pricing,
    etc. Therefore, a fresh seafood supply in a city is often not guaranteed. In order
    to address such issue, Huang et al. [126] have provided a solution by integrating
    two types of cameras for seafood freshness inspection. Camera and near infrared
    spectroscopy are fused through PCA and use NN to classify the freshness index.
    The research gaps in this domain involve developing large scale fish breeding
    and also wide varieties of seafood product such as calm, mussels, abalone, etc.
    A potential solution such as smart fish breeding with IoT has been proposed in
    [180], where it suggests using a moving pod to breed fishes while transporting
    them to destination in a particular destination simultaneously. 3.5. Smart economics
    Smart economics can be defined as the generic commercial activities in an urban
    city ranging from supply chain, logistic, finance center, to tourism. All these
    activities yield potential commercial value to a city, which it depends on the
    unilateral or bilateral trading relationship. In this subsection, we discuss smart
    economics in three major sub-domains, namely, (1) Smart Commerce, (2) Smart Supply
    Chain, and (3) Smart Tourism. 3.5.1. Smart commerce Today, modern e-commerce platforms
    use multi modal data sources to reach and better understand their customers. This
    helps e-commerce vendors to give better product recommendations for their customers
    and it helps customers to make their decisions easily. Fusing customer data such
    as mobility, credit card purchases, and social media interactions is commonly
    used in modern recommender systems. In [87], Breur introduced the fusion of customer
    behavior data and market research data to obtain a holistic picture of the customer.
    Investors can leverage financial data to make investment decisions, as Hassan
    et al. [181] have introduced a fusion model of Hidden Markov Model (HMM), NN,
    and Genetic Algorithm (GA) for stock market prediction. Improving the consumer
    awareness is conducted in [129], by fusing real world (weather, geographical)
    and cyber world (Twitter, Facebook) data. The proposed system has two levels of
    fusion, which relies on hierarchical-based processing architecture. The data combined
    bottom level input and fed it into upper level for further processing to achieve
    its objectives. 3.5.2. Smart supply chain In a smart supply chain, it often involves
    sources and destination tracking in order to understand the flow / processing
    of the objects. As discussed in [182], supply chain management and logistic are
    the fundamental of modern supplies on fulfilling the needs of an urban city. For
    instance in food supply chain, three tiers information fusion framework is proposed
    in [130] such as: (1) to accelerate data processing, (2) shelf life prediction,
    and (3) real-time supply chain planning. The proposed hierarchical information
    fusion architecture (HIFA) includes a process that is intelligently transforming
    the sensor’s data sources into usable decision-making information. Recently, combination
    of blockchain technology has paved a new way for revolutionizing the existing
    supply chain. In [107], Tian has shown the integration of blockchain and supply
    chain in the agri-food supply application. It aids consumers to trace the origin
    of food using Radio Frequency Identification (RFID) along with database or WSN.
    The information also includes food origin to help consumers to identify the brand
    authenticity and avoids consuming counterfeit products. The research gap in this
    sub domain concerns with the implementation of smart supply and it needs the involvement
    from various commercial organizations. The consensus and national regulations
    are also parts of the critical factors of smart supply implementation. 3.5.3.
    Smart tourism The advancement of transportation technology has granted accessibility
    for the humans to move around the globe with ease. This phenomenon has caused
    rapid expansion of the tourism commercial values contributed to a city side income.
    Since then, Internet resources such as travel blogs and recommendation systems
    have influenced public to venture different locations. For instance, recommendation
    system [57] has been developed to recommend the place to travel based on user’s
    information such as socioeconomic (e.g. age, education, and income) and psychological
    and cognitive (experience, personality, involvement, and so forth) groups. User
    choices are used as feedback to further fine-tune the recommendation system using
    Rocchio’s method. Apart from that, Miah et al. [77] have combined social media-generated
    big data (geo-tagged photos of tourist attraction places) to predict tourist behavioral
    patterns. Alternately, Viswanath et al. [131] used a smartphone based mobile application
    to passively track tourist location data and obtain user ratings for tourist attraction
    places to better understand the preferences of tourists when they visit tourist
    attractions. The potential research development for smart travel is to focus on
    using a smartphone application for improving travel experience by relying on real-time
    translation and augmented reality (AR) navigation. 3.6. Smart human mobility Human
    mobility has been an important research area as commuting and traveling play big
    roles in modern life. With the help of advanced ICT, plentiful data sources related
    to human mobility have been collected and accessible to researchers, which yields
    deeper insights into the nature of human mobility as well as better improvement
    strategies for transportation systems. Smart human mobility, therefore, means
    collecting, managing, and analyzing (fusing) various data sources related to different
    aspects of residents’ movement in order to better understand and improve the way
    people move. Depending on the purpose of different applications, smart human mobility
    domain can be further divided into three sub-domains:(1) Smart Location-Based
    Services, (2) Human Mobility Understanding, and (3) Smart Transportation Systems.
    3.6.1. Smart location-based services This sub-domain aims to get the accurate
    position of individuals and further to provide services, such as route planning
    and navigation, to help them travel efficiently and comfortably, in both outdoor
    and indoor environments. For outdoor positioning, Global Positioning System (GPS)
    has been the most accurate, reliable and dominant technology since it was allowed
    for civilian use in 1980s [183], [184]. Less-accurate non-GPS positioning approaches,
    such as wifi-based localization and cell-tower triangulation, are sometimes used
    instead of (or together with) GPS, because they consume less energy [132], [133].
    For indoor positioning, since GPS does not work well indoors, other positioning
    approaches have been proposed. The data collection technologies used for these
    approaches mainly include Wi-Fi (WLAN), inertial measurement unit (IMU), RFID
    tags, Bluetooth, global system for mobile communications (GSM), frequency modulation
    (FM), and ultra-wide band (UWB) [185], [186]. Meanwhile, multiple data sources
    are often fused to achieve more accurate localization results [134], [135]. Once
    accurate locations are obtained, either indoors or outdoors, location-based services
    (e.g. route planning and navigation) can be provided to end users by fusing the
    location sequences with other information sources such as geographic information
    system (GIS) data, real-time traffic data, and user preference data [136], [137],
    [187], [188], [189], [190]. Since the outdoor positioning and location-based services
    have been well developed and commercialized, the current research trend in this
    field is mainly focused on improving the performance (accuracy, deployment cost,
    and energy cost) of indoor systems and services. 3.6.2. Human mobility understanding
    Positioning systems not only enable the location-based services for individuals
    but also provide data sources for further monitoring and understanding human mobility
    in a larger and more comprehensive scale. By aggregating and analyzing (fusing)
    the location data of residents along with GIS data of the environment, various
    aspects of human mobility can be monitored and the hidden patterns can be obtained.
    As summarized in [100], the most common subjects of monitoring and understanding
    human mobility include distance and duration distributions [191], origin-destination
    matrices [103], individual activity-based mobility patterns [192], transportation
    mode identification [54], and densities and flows within a building (or a cluster
    of buildings) [138], [193]. Results obtained from these subjects provide clues
    for improving transportation system [194], urban planning [195], and communication
    network [196]. Typical studies in this sub-domain usually fuse one data source
    of people’s movement trajectories with the environment information, such as GIS
    data of the city or floor plan of a building. Although this type of approach has
    produced much deeper insights compared with traditional approach relied on survey
    data, there is a trend to fuse multiple data sources related to people’s movement
    and obtain a more comprehensive picture of human mobility [197], [198]. Moreover,
    social media data sources. such as Tweets, also bring in more information regarding
    the mobility status in cities due to the combination of spatio-temporal data and
    descriptive text [86], [199]. 3.6.3. Smart transportation systems Another large
    part of smart mobility is the improvement of transportation systems, which mainly
    comes from three aspects: relieving traffic congestion, improving public transportation,
    and introducing new transport systems. To relieve traffic congestion, effective
    light control plays an important role. While existing light control systems are
    usually based on hand-crafted rules and do not adjust to the rapid dynamics of
    traffic flows, intelligent light control approaches have been proposed using different
    data sources, data fusion techniques, and decision making (optimization and control)
    algorithms [109], [200]. Challenges in this aspect mainly come from the implementation
    of such intelligent light control approaches. Improvement of the public transportation
    system is mainly conducted through the network and schedule optimization [201].
    Although these two topics have been thoroughly discussed in the literature, new
    insights related to the public transit system (e.g. origin-destination matrices
    and service level obtained from big data) [139], [202] and more advanced transport
    modeling tools enabled by big data [203] have brought new opportunities. Even
    if the existing transportation manner has been optimized, there are still problems
    that cannot be solved, such as last mile issue and driving accidents. Therefore,
    new transport systems, such as bike sharing systems and autonomous vehicle systems,
    are introduced. Advanced ICT and data fusion techniques are the core of the realization
    of these systems. For a bike sharing system, data fusion and analysis helps to
    understand how the system works and evaluate different operational strategies
    [204], [205]. As for the autonomous vehicle system, the control of an autonomous
    vehicle itself is a complex data fusion process, fusing various data sources about
    the vehicle and the road by advanced machine learning and control algorithms [140],
    [206]. Security plays an important role in the autonomous vehicles deployment
    to ensure reliability of the autonomous driving. Examples of such techniques can
    be found in [50], [207]. 3.7. Smart infrastructure In a smart city, infrastructure
    aims to provide convenience for the public by supplying resources (electricity,
    gas, and water) or providing services (public facility or communication systems).
    Here, we outline four different sub-domains for discussion, which are (1) Smart
    Grid, (2) Smart Energy, (3) Smart Facility, and (4) Smart Communication. 3.7.1.
    Smart grid The electrical grid provides an intermediate platform for relaying
    the electricity from the power plant to residential and industrial area. The common
    goal in this sub-domain is to provide reliable and stable electricity supply with
    the integration of ICT, which is commonly known as smart grid. Smart grid has
    been extensively studied in [55], [208], [209], [210] and the goal is to address
    on load and demand balancing of electricity in a particular area, building, or
    even household. Common technique applied in this sub-domain is forecasting, and
    example of such application can be found in [55], which it combines the information
    received from residential meters and predicts the electricity consumption load.
    Wang et al. [88] have proposed a different approach, where the concept of multi
    agent systems (MAS) is used to predict building energy consumption by denoting
    each meter as an agent. The common goal is to use a higher information extraction
    technique such as prediction, where it allows grid operators to forecast the grid
    demand to ensure sufficient electricity load. Test bed currently is the common
    method for testing out the smart grid use case and has been studied in [211].
    Another common research topic is security and reliability of the smart grid system.
    Li et al. [49] have proposed a secure state estimation, which it can be used to
    address single sensor or multi-sensor scenarios. Similar works addressing smart
    grid security also can be found in [212], [213]. On the other hand, advanced metering
    infrastructure (AMI) has been studied along with the smart grid to ensure the
    electrical metering is tamper-proof while able to accurately measure energy consumption.
    For instance, work in [214] uses the clustering algorithm to identify energy theft
    accurately while reducing potential false positives. Meanwhile, work in [105]
    has presented a real-time price estimation by fusing local power and global power
    consumption to understand real-time electric load of the grid. In future, prosumers
    (producer and consumer) will emerge in the smart grid market and sole distributor
    paradigm will be no longer valid. This scenario greatly increase the difficulty
    of the energy demand and load when accounting the energy as a live market 3.7.2.
    Smart energy The search for clean energy resources has been an ongoing effort
    for many researchers in order to cut down the dependency on the fossil fuels.
    Therefore, the clean energy research direction mostly focuses on renewable energy,
    which propose to go for a green and less carbon footprint energy producing approach.
    Nowadays, the most common renewable energy sources emerged in the market are solar
    farm [101], [141] and wind power [215], [216]. Solar energy is generated based
    on the conversion of the sunlight into electricity, but the energy harvesting
    technique suffers from limited energy harvesting time. Thus, solar irradiance
    prediction is crucial to ensure maximum energy throughput in the solar farm within
    the limited time. Huang et al. [141] have proposed to use data driven algorithms
    such as ABB, SVM, BRT, and Lasso, in which the information from neighboring solar
    plants are combined to accurately predict the solar irradiance. Meanwhile in [217],
    Jung and Broadwater have implemented a statistical model to fuse wind speed, direction,
    temperature from forecast station and online measurement to determine the total
    power output of the wind farm. Most of the aforementioned methods focus on improving
    efficiency of the existing energy harvesting methodology. Future research on the
    clean energy relies on various data and energy sources in order to construct a
    high efficiency energy harvesting model. 3.7.3. Smart facility Smart facility
    denotes access of physical facility that provides services to the public such
    as parking facility, water supply, etc. The most vital facility in a smart city
    would be water treatment center as clean water is an important necessity for the
    urban citizens. Any potential leakage or downtime of water supply in a city would
    be proven troublesome. Mounce et al. [104] propose a water leakage detection using
    classification technique, which combines all the district water meter data. Similar
    concept can be applied on other resources such as gas pipe leakage detection or
    electricity theft in smart grid. In the public facility, the wear and tear of
    structures can be a major issue due to the frequent rate of public usage. Hence
    in [99], Park et al. have combined multi-metric sensors to estimate the bridge
    displacement. Through this, a rough estimation of the structural health can be
    determined. Alternately, Khoa et al. [218] have proposed a tensor decomposition
    approach using the facility data sources in order to understand the facility usage
    details. In addition, the emergence of data centers providing various functionalities
    to the smart city applications such as [219], [220], [221] also one of the focuses
    for the ongoing efforts of smart city. There is also a few domains that is highly
    correlated with smart facility such as Smart Maintenance and Governance [56],
    where integration of a web portal is used to report potential damages. 3.7.4.
    Smart communication Communication in an urban city remains an essential infrastructure
    for various application platforms to communicate with each other. Not all communication
    platforms and standards are designed equally as each of them serve different purposes.
    Therefore, different standards and protocols to meet varying requirements have
    been established. Currently, the upcoming 5G technology [28], [222] has promised
    to bring integration of 5G interface with support for older generation spectrum
    such as LTE and Wi-Fi in order to provide seamless user experience. The common
    data source in 5G standards is raw signal, and that is the reason why data fusion
    only happens at the edge level. For example, Huang et al. [27] and Rappaport et
    al. [222] have fused raw signals that are divided through multiple antenna during
    transmission. The receivers will receive multiple signal sources and reconstruct
    the original information being transferred. Further discussion of the energy efficient
    trade-off in wireless communication technology can be found in [223], [224]. In
    the IoT domain, wireless sensor network (WSN) is considered a common communication
    platform because of its wide coverage and low power consumption. WSN is built
    on top of nodes’ network, which is smaller than a wireless ad hoc network. Hence,
    multiple nodes can be combined for encoding and decoding the packets received.
    Kreibich and Co-authors Kreibich et al. [47] and Luo et al. [48] have proposed
    approaches to improve communication between WSN focusing on the communication
    mechanism between nodes. The main objective is to focus on the reliability of
    communication channel while maintaining the coverage (from relay to sink nodes)
    and also low power consumption. The research significance of communication is
    undoubtedly a necessity in smart city as it benefits all domains leveraging communication
    technology. The main goal is to design efficient and reliable communication protocols
    to meet different requirements of applications. Alternately, low power communication
    is yet another goal for IoT in order to achieve long sensing operation. 4. Challenges
    and open research directions After outlining the applications of the smart city
    that use data fusion, we discuss the potential aspects to improve the data fusion
    in the smart city applications observed from previous section. These aspects include
    potential categories or perspectives that are not discussed in Sections 2 and
    3. As shown in Fig. 2, we identify four major research directions, which are (1)
    data quality, (2) data representation, (3) data privacy and security, and (4)
    data fusion technique. Download : Download high-res image (137KB) Download : Download
    full-size image Fig. 2. Open Research Directions for Data Fusion in Smart City
    Applications. 4.1. Data quality Quality of the data sources directly determine
    the quality of output results since processing module follows the “garbage in
    and garbage out” theorem in fusing data sources. Thus, we discuss two aspects
    to improve the data sources in the smart city applications, which are sensing
    coverage and sensing longevity. 4.1.1. Sensing coverage Sensing coverage is one
    of the important factors to determine the quality of data sources. Insufficient
    data coverage will generate a result that is not representative, and often it
    implies more sensors need to be installed to increase the sensing coverage. This
    indirectly affects the deployment cost since more physical hardware is required
    to compensate the sensing coverage. Apart from that, it also affects the design
    of communication architecture because more physical sensors are required to transmit
    data, and thus potentially congests the communication platform. These factors
    are common obstacles for a large-scale deployment in smart city applications and
    getting worse when increasing the deployment scale. There are two commonly used
    approaches to address the aforementioned issues, which are crowdsensing and mobile
    sensing platform. As shown in [225], crowdsensing is one of the most cost-efficient
    method as personal mobile devices such as smartphones. Smartphones offer wide
    variety of sensors such as vibration, magnetic field, IMU, GPS, and others. The
    problems with crowdsensing are related to user privacy intrusion and high battery
    consumption when actively collecting data. User privacy is a challenge in collecting
    data as regulations in many countries have been facilitated to prevent applications
    to collect any sensitive information. This issue will be further discussed in
    user privacy and security sub-section. Another problems with crowdsensing are
    the unavailability of geolocations information or random distribution of geographical
    located data. These scenarios lead to inconsistent data quality. Potential way
    to resolve this limitation is to collect data at a fixed time and location only
    when needed, where incentive is provided for valid participants. Also, the trade-off
    problem of the mobile sensing can be further found in [226]. Through this method,
    only qualified data will be included as data sources, while invalid information
    will be automatically filtered. Using similar concept as crowdsensing, mobile
    sensing has offered the same data sensing approach but only follows designated
    route to collect data. The idea is to leverage the mobility of the transportation
    (normally public transports, cabs, and garbage trucks) to conduct data collection,
    where the vehicles are traveling across the city. Example of mobile sensing platform
    can be found in [106], where garbage trucks on duty will collect the ambient data
    across different parts of the city weekly. An identical concept can also be implemented
    with the public transport systems, since majority of them follow fixed schedules.
    The challenge with the mobile sensing is that spatial resolution of the data may
    not have a finer detail when compared to crowdsensing due to fixed data collection
    schedule. The main cause is due to the limited accessibility of the vehicles in
    certain areas (pedestrian path and residential area). Potential workaround of
    this limitation would be combining the mobile sensing and crowdsensing data sources
    to generate data that covers large area within the urban city. Services integration
    also plays an important role in supplying platforms alternate data sources to
    perform data enrichment. By simulating the different IoT services in smart city
    as shown in [227], potential limitation or bottlenecks of smart services can be
    avoided in order to design a better smart city application. 4.1.2. Data sensing
    longevity Long term data collection offers different aspects of knowledge discovery
    as data is able to cover more detail in a larger temporal resolution. The advancement
    of miniaturization has greatly reduced the power consumption of the sensors and
    IoT devices while maintaining the same sensing performance. As a result, combining
    both energy harvesting techniques and low energy devices are able to create a
    long self-sustaining sensing approach. This breakthrough allows physical sensors
    to run independently without the need of external power sources. In order to preserve
    the longevity of physical sensors’ sensing capability, energy harvesting is one
    of the common approach in large area networks. It allows sensors to draw energy
    from solar energy, vibration, or temperature difference. The most widely available
    energy harvesting technique is solar panels and it can be easily obtained. Solar
    panel is affected by the presence of solar irradiance, where the energy harvested
    varies throughout the different time of the day. Contrast to solar farm, the goal
    here is to conserve as much energy, while maintaining the sensing capability of
    the physical sensors. The most notable influence would be the energy management
    architecture as well as the battery capacity and the solar panel efficiency. Apart
    from that, although temperature difference and sensor vibration are capable of
    harvesting energy but it is limited to certain use case and not suitable for general
    usage. Alternately, potential replacement of the traditional energy harvesting
    technique is wireless power transfer. As shown in [228], [229], this method offers
    power to be transferred wirelessly without battery and energy harvesting module.
    Currently, there are different types of wireless power transfer technologies such
    as inductive coupling, capacitive coupling, magnetodynamics coupling, microwaves,
    and light-waves. Each of them has their limitation such as inductive coupling
    only has limited range of transferring energy. That being said, this technology
    is still relatively new, and it requires further investigation in order to guarantee
    its minimum working efficiency for smart city applications. Other than using external
    power sources, low power sensing for carrying out the sensing tasks. In order
    to drive different smart city applications, various standards have been proposed
    for LPWAN, such as LoRaWAN by LoRa Alliance and NB-IoT Release 13 by 3GPP. LoRaWAN
    focuses on the long range IoT connectivity for industrial applications while the
    NB-IoT focuses on the indoor coverage, low cost, long battery life, and stable
    communication in high density communication channel. The main reason to use low
    power sensing approach is due to the high compatibility with large scale deployment
    relying on the low bit rate communication channel usage. However, standardization
    of these protocols remains a challenge in LPWAN due to the possibly of using unlicensed
    spectrum, where organizations may choose not to follow the agreed spectrum. In
    future, low power communication will ensure the long term sensing capability of
    physical sensors in the smart city applications and therefore will improve data
    sources quality. 4.2. Data representation A high speed Internet connection provides
    easy access to many genres of data sources and creates opportunity to study wide
    variety of different data sources. However, large variety of data sources frequently
    indicate the incompatibility of data formats. The problem becomes more obvious
    when there is no standardization on the data format. To tackle such problem, data
    ontology is the building block to represent the data sources to connect different
    sources of data for seamless services integration. If the format of the data source
    cannot be interpreted, it will be marked as useless for the platform integrator.
    Therefore, semantic web has been proposed as an extension to WWW web services
    utilizing Resource Description Framework (RDF) to provide standard data exchange
    formats. It opens the path to create different solutions for the IoT applications
    and it supports the Open Government Data (OGD) principles [230]. To date, there
    are few common ontology languages have been developed such as Delivery Context
    (DCN) [231], Web Ontology Language (OWL) [232], Resource Description Framework
    Schema (RDFS) [233], Semantic Sensor Network (SSN) [234], and others. Majority
    of the ontology languages only focus on one application domain because they are
    not suitable for representing the metadata from other domains. This causes data
    segmentation in the smart city applications, where further increases the gap between
    different smart city domains. Thus, DBpedia [235] is designed to address the aforementioned
    issue using public and private stocks of semantic web. DBpedia has provided solutions
    for the ontology software as it offers different classes and types that are available
    on the Wikipedia. That being said, not all applications adopt the idea of DBpedia
    and there is a fraction of applications remain conservative using proprietary
    data representation. Apart from that, Message Queuing Telemetry Transport (MQTT)
    [236] v3.1 protocol has been introduced as one of the protocols to address ontology
    problems between brokers. It offers machine to machine (M2M) communication by
    providing lightweight publish and subscribe messaging services, where network
    bandwidth limitation is one of the main constraint. It is possible to combine
    the aforementioned technologies in order to generate a better data integration
    for data fusion purposes across different domains. Therefore, the future agenda
    for the ontology language is to encourage integration of different levels of data
    sources using different system architecture such as edge, fog, and cloud computing.
    4.3. Privacy and security 4.3.1. Privacy Collecting urban residents’ data in a
    smart city application can be challenging due the nature of sensitive data that
    can be misused if poorly managed. As privacy issue has been discussed extensively
    by the authors in [116], [237], [238], misuse of private information may lead
    to catastrophic events such as information theft, or identity fraud. Currently
    in Europe, General Data Protection Regulation (GDPR) as discussed in [239], [240]
    has been proposed to better address the data privacy concern of the Internet.
    In other countries, there are also similar efforts to enforce data privacy protection
    such as Canada’s Personal Information Protection and Electronic Documents Act
    (PIPEDA), China’s China Data Protection Regulations (CDPR), Singapore’s Personal
    Data Protection Act (PDPA), Japan’s Personal Information Protection Commission
    (PIPC), etc. Meanwhile in USA, Health Insurance Portability and Accountability
    Act of 1996 (HIPAA), the Children’s Online Privacy Protection Act of 1998 (COPPA),
    and the Fair and Accurate Credit Transactions Act of 2003 (FACTA) have been introduced
    to improve with the information flow efficiency across agencies. This is also
    a part of the efforts to prevent sensitive information being available for unauthorized
    parties. Majority of the policies and regulations emphasize on the users’ consent
    for collecting personal data and this can be problematic as not all platforms
    provide ample security for data storage. With insufficient security measurements,
    the data collected may be compromised, which may lead to tainted reputation and
    loss of public faith. For instance, Facebook and Cambridge Analytica scandal [241]
    has shown potential misuse of user data collected. With that in mind, potential
    right of accessing data sources could be revoked if the data source is not handled
    properly by the right person. Hence, privacy and security should be the responsibility
    for both platforms and users. A thorough review has been conducted in [242], which
    works on the IoT requirements to address privacy issues. Potential solution for
    the aforementioned problem is to use hybrid data fusion technique in a smart city
    application. The idea here is to locally fuse the sensitive information (user
    identity, phone number, bank account number) into generic information, before
    uploading to the cloud for further processing. The benefits of such approach are
    two-folds, which are the ability to offload computational cost and to preserve
    sensitive information at the physical sensor only. In addition, we can leverage
    machine learning approaches such as [243], [244] to generate synthetic datasets
    with identical data characteristic for study purpose. This eliminates the chances
    of private data been leaked out and encourage the openness of datasets to be studied
    by different researchers and data scientists. To draw a clear line between generic
    and sensitive data remains a debate among researchers. In future, the data fusion
    can be applied at the lower level to remove any potential sensitive data. 4.3.2.
    Security According to Kitchin [245], there are two general security concerns in
    the smart city applications, which are security of technology/infrastructure (data
    center, services, and system architecture) and data security (data generation,
    storage, and communication). The security of the technology and infrastructure
    highly relies on the design architecture of the system being deployed. Depending
    on the application requirements, it varies from traditional client server architecture
    to decentralized architecture. The main objective is to deploy a hack-proof/exploit-less
    system architecture. Alternately, there are also ways of improving security of
    system architecture such as incentive/bounty for reporting flaws, simulating injection
    attacks, security assessment from third party, etc. Nowadays, the security enhancement
    focuses towards continuous effort as the technology has been changing rapidly.
    For instance, different security strategies [246], [247], [248] try to enhance
    security of the smart city application''s architecture by focusing on the common
    security standards/practices/protocols. This shows that as the number of smart
    city applications increase rapidly, system architectures implemented with the
    security design in mind become apparent with good practices and standard architecture
    design. Subsequently, regular security assessment and auditing also pave way for
    a safer smart city applications deployment. Meanwhile, data security also contributes
    to the significant part of smart city applications ecosystem from generation,
    storage, and communication. The common method to combat such issue is leveraging
    encryption techniques, where it encodes the data so that only the authorized parties
    have access to it. For instance in [249], Wang et al. have introduced an attribute
    based encryption scheme, which it allows fine-grained access control, scalable
    key management, and flexible data distribution. In addition, encryption also can
    be used in the communication platform between IoT devices in smart city application
    as shown in [250], [251] to prevent information hijacking. Despite constant effort
    of cyber security researchers developing new security schemes, the numbers of
    data breaches and cyber threats increase every year according to David et al.
    [252]. The main culprit of such occurrence is due to negligence of data security
    practices/implementation. Security often appears to be an afterthought in deployment
    of a smart city application. Thus, in order to combat such threat, the smart city
    application should comply with security standards as shown in [253] to mitigate
    the chances of becoming a victim. 4.4. Data fusion techniques Extracting knowledge
    from a smart city application frequently involves data mining techniques in order
    to fuse different data sources. Lower tier data fusion techniques have been well
    explored in [39] and the current research trend focuses more on the machine learning
    approach. The main reason why machine learning approach has gained so much attention
    is due to its capability of handling high dimensional data. The problem of high
    dimensional data is also known as curse of dimensionality as described by Bellman
    [254]. In this context, we discuss two research trends on applying machine learning
    techniques in data fusion as follows: 4.4.1. Explainable deep neural network Lately,
    supervised machine learning techniques focus on the DNN, where the in-depth reviews
    of the recent development can be found in [255], [256], [257]. Major research
    efforts aim to increase the explainability of the model such as NN, CNN, and DNN
    rather than using them as black box models. To this end, explainable AI (XAI)
    [258] is the new motivation for data scientists to explore the interpretable learning
    paradigm of the modeling in order to provide a semantic meaning behind modeling
    logic. This new learning process has driven three big fields in the deep learning
    domains, which are (1) Deep Explanation, (2) Interpretable Model, and (3) Model
    Induction. To develop a deep explanation on the model interpretation, the cognitive
    layers will act as an intermediate layer between learning and explanation layer
    in order to cast the learned abstractions, policies, and clusters information
    into an explainable format. Subsequently, the interpretable model such as Bayesian
    learning [259] can be built to explain the uncertainties required when developing
    the deep learning models to learn the choices of a learning process. Alternate
    approach has proposed to use subspace approximation with an adjusted bias technique
    [260] to build interpretable CNN, which uses feed forward design to better explain
    the model’s choice in allocating certain hyper-parameters. Meanwhile, model induction
    refers to the technique used for inferring the model’s decision and learning progress.
    Through a thorough understanding of the model, parameters can be fine-tuned to
    increase the learning optimization rate in a long-term application deployment.
    Hence, the search of XAI is an important milestone for the data scientists, which
    can be used to explain the learning process and the decision machine learning
    made. An example of potential use case would be trying to understand the reason
    behind (also known as reasoning in some literatures) the predictive maintenance
    decision machine learning rather than performing maintenance due to the result
    of predictive algorithm. 4.4.2. Unsupervised data fusion In the smart city applications,
    collecting the ground truth could be proven challenging due to the uncertainties
    and errors in the collected data sources. Hence, obtaining labels or data annotation
    are another problems with certain data sources. Despite the rapid development
    of advanced modeling tools like DNN, it still requires labels and data annotation
    in order to achieve objectives of extracting higher information. There are a few
    approaches that address the lack of labels such as manual annotation, crowd labeling,
    software annotation, and pattern labeling. However, manual annotation only works
    well with a small dataset while other approaches do not guarantee the correctness
    of end result. This shows a big research gap to seek a better way to label data
    sources accurately. Research works such as Zhou et al. [261], [262] have attempted
    to fix unlabeled data by transforming them into useful features to achieve certain
    objectives. Traditionally, raw data is required to be preprocessed into something
    meaningful, but it still suffers from the need of data cleansing and amputation.
    The simplest method would be to solely depend on the filtering technique. However,
    aggressive filtering may remove large amount of raw data resulting potential loss
    of knowledge. Another simple solution is to increase the number of reliable data
    sources to be fused to create potential annotation. Increasing data sources often
    indicates an increment of the overall deployment cost. Alternative solution to
    the increased deployment cost is to use transfer learning [263], where the knowledge
    from existing domain can be transferred to other domain to learn from it. 4.4.3.
    Emergence of hybrid model The emergence of the hybrid models has become common
    due to wide variety of data sources available. It allows different levels of data
    sources (high, low, or both) to combine in order to create potential insights
    in a particular domain. It also helps to solve the data privacy problem along
    with machine learning technique, which has opened up many opportunities for researchers
    and data scientist to study on these big data collected. One example of the hybrid
    model is shown as follows: an urban planning system has different data sources
    as input such as human comfort factor index (environmental ambient sensors), positive
    urban city factor (feedback data on urban area such as greenery, surrounding amenities,
    recreational parks, and others), and cyber data (social media input) to design
    a fully automated urban planning system by fulfilling predefined criteria. The
    result from the data fusion needs to be explainable as discussed in the previous
    XAI for understanding choices made by the automation software. In this example,
    different tiers of data sources are fused using data sources types (D1, D2) and
    the result is some features. Eventually, these features will be combined to generate
    a potential plan for city through computation modeling (D3, D4). By joining different
    data sources, simulation can be used concurrently to verify the performance of
    urban planning system before deploying to the city. In future, implementation
    of the hybrid model will become a general trend due to wide availability of the
    data sources and processing platforms. As mentioned in the discussion, data ontology
    is another key factor to allow data sources to be connected from different platforms
    to provide knowledge for the smart city applications. 5. Conclusion This paper
    presents an overall view of the data fusion techniques found in the smart city
    applications. Easy accessibility of the data sources has paved way for data fusion
    in different smart city applications in various forms. The increasing trends of
    data fusion in the smart city applications create the need for a new evaluation
    method. Therefore, we propose a multi-perspectives classification for the smart
    city applications that involve data fusion techniques. The data fusion classification
    based on multi-perspectives introduced in this paper are: (1) Fusion Objectives,
    (2) Fusion Techniques, (3) Data Input and Output Types, (4) Data Source Types,
    (5) Data Fusion Scales, and (6) System Architecture. Using the proposed multi-perspectives,
    we evaluated some selected works in the smart city applications and we also discussed
    the research trend for each domain respectively. Next, we also discuss four open
    research directions of data fusion in a smart city application such as data quality,
    data representation, data privacy & security, and data fusion technique. Overall,
    we are certain that generic nature of the multi-perspectives classification is
    able to perform well with various smart city applications for different domains
    that leverage the data fusion techniques. In addition, an in-depth analysis can
    be further extended onto individual domain to study the common requirements and
    techniques applied, which we do not include in this paper due to limited paper
    length. A successful smart city application is built on top of the data (also
    known as data-driven architecture) and data fusion has provided a wide variety
    of techniques to improve the input data for an application. Therefore, data fusion
    has opened the path for various applications to gain insights about the city.
    This also holds the key for a smart city to further understand and improve the
    domains that it is lacking. Acknowledgement The research work was supported in
    part by the National Research Foundation (NRF) of Singapore via the Green Buildings
    Innovation Cluster (GBIC) administered by the Building and Construction Authority
    (BCA)-Green Building Innovation Cluster (GBIC) Program Office; in part, by the
    SUTD-MIT International Design Center (IDC; idc.sutd.edu.sg); in part by Natural
    Science Foundation of China (NSFC) through Project No. 61750110529, 61850410535
    and Higher Education Commission (HEC) Pakistan through grant number NRPU P#5913.
    We thank our colleagues and reviewers, who have provided insight and expertise
    that greatly assisted with improving the context of this survey paper. References
    [1] UN 68% of the World Population Projected to Live in Urban Areas by 2050, Says
    UN UN (2018) Google Scholar https://www.un.org/development/desa/en/news/population/2018-revision-of-world-urbanization-prospects.html.
    [2] A. Boulton, S.D. Brunn, L. Devriendt 18 Cyber-infrastructures and smartworld
    cities: physical, human and soft infrastructures International Handbook of Globalization
    and World Cities (2011), p. 198 View in ScopusGoogle Scholar [3] R.G. Hollands
    Will the real smart city please stand up? Intelligent, progressive or entrepreneurial?
    City, 12 (3) (2008), pp. 303-320 CrossRefView in ScopusGoogle Scholar [4] T. Nam,
    T.A. Pardo Smart city as urban innovation: focusing on management, policy, and
    context 2011 Proceedings of the 5th International Conference on Theory and Practice
    of Electronic Governance, ACM (2011), pp. 185-194 CrossRefView in ScopusGoogle
    Scholar [5] D. Toppeta The smart city vision: how innovation and ICT can build
    smart, livable, sustainable cities Innov. Knowl. Found., 5 (2010), pp. 1-9 Google
    Scholar [6] P. Berrone, J. Enric IESE Cities in Motion Index 2018 IESE Business
    School, University of Navarra, España (2018) Google Scholar [7] City of New York
    Nyc Sustainability (2018) Google Scholar https://www1.nyc.gov/site/sustainability/index.page.
    [8] Greater London Authority Smart London (2018) Google Scholar https://www.london.gov.uk/what-we-do.
    [9] Mairie de Paris Paris Smart and Sustainable (2018) Google Scholar https://api-site-cdn.paris.fr/images/99354.
    [10] New Smart Nation, Digital Government Office Smart Nation Singapore (2018)
    Google Scholar https://www.smartnation.sg/. [11] Tokyo Metropolitan Government
    New Tokyo. New Tomorrow. The Action Plan for 2020 (2016) Google Scholar http://www.metro.tokyo.jp/english/about/plan/documents/pocketenglish.pdf.
    [12] Deloitte Touche Tohmatsu Limited Super Smart City - Happier Society with
    Higher Quality Deloitte CN Public Sector (2018) Google Scholar https://www2.deloitte.com/cn/en/pages/public-sector/1280articles/super-smart-city.html.
    [13] MIT MIT Senseable City Laboratory (2018) Google Scholar http://senseable.mit.edu/.
    [14] E. Zurich Future Cities Laboratory (2018) Google Scholar http://www.fcl.ethz.ch/.
    [15] SINTEF Sintef Smart Cities (2018) Google Scholar https://www.sintef.no/en/smartcities/#/.
    [16] SMART Future Urban Mobilty (2018) Google Scholar https://fm.smart.mit.edu/.
    [17] B. Khaleghi, A. Khamis, F.O. Karray, S.N. Razavi Multisensor data fusion:
    a review of the state-of-the-art Information Fusion, 14 (1) (2013), pp. 28-44
    View PDFView articleView in ScopusGoogle Scholar [18] F. Castanedo A review of
    data fusion techniques Sci. World J., 2013 (2013) Google Scholar [19] F. Alam,
    R. Mehmood, I. Katib, N.N. Albogami, A. Albeshri Data fusion and IoT for smart
    ubiquitous environments: a survey IEEE Access, 5 (2017), pp. 9533-9554 View in
    ScopusGoogle Scholar [20] M. Wang, C. Perera, P.P. Jayaraman, M. Zhang, P. Strazdins,
    R. Shyamsundar, R. Ranjan City data fusion: Sensor data fusion in the internet
    of things Int. J. Distrib. Syst.Technol., 7 (1) (2016), pp. 15-36 View in ScopusGoogle
    Scholar [21] Y. Zheng, et al. Methodologies for cross-domain data fusion: an overview.
    IEEE Trans. Big Data, 1 (1) (2015), pp. 16-34 Google Scholar [22] N.-E. El Faouzi,
    H. Leung, A. Kurian Data fusion in intelligent transportation systems: progress
    and challenges–a survey Inf. Fusion, 12 (1) (2011), pp. 4-10 Google Scholar [23]
    B. Esmaeilian, B. Wang, K. Lewis, F. Duarte, C. Ratti, S. Behdad The future of
    waste management in smart and sustainable cities: a review and concept paper Waste
    Manag., 81 (2018), pp. 177-195 View PDFView articleView in ScopusGoogle Scholar
    [24] L. Da Xu, W. He, S. Li Internet of things in industries: a survey IEEE Trans.
    Ind. Inform., 10 (4) (2014), pp. 2233-2243 Google Scholar [25] Z. Chen, C. Jiang,
    L. Xie Building occupancy estimation and detection: a review Energy Build. (2018)
    Google Scholar [26] X. Qin, Y. Gu Data fusion in the internet of things Procedia
    Eng., 15 (2011), pp. 3023-3026 View PDFView articleView in ScopusGoogle Scholar
    [27] C. Huang, L. Liu, C. Yuen, S. Sun Iterative channel estimation using LSE
    and sparse message passing for mmwave mimo systems IEEE Trans. Signal Process.,
    67 (1) (2019), pp. 245-259 CrossRefGoogle Scholar [28] J.G. Andrews, S. Buzzi,
    W. Choi, S.V. Hanly, A. Lozano, A.C. Soong, J.C. Zhang What will 5g be? IEEE J.
    Sel. Areas Commun., 32 (6) (2014), pp. 1065-1082 View in ScopusGoogle Scholar
    [29] F. Boccardi, R.W. Heath, A. Lozano, T.L. Marzetta, P. Popovski Five disruptive
    technology directions for 5g IEEE Commun. Mag., 52 (2) (2014), pp. 74-80 View
    in ScopusGoogle Scholar [30] M. Erol-Kantarci, H.T. Mouftah Wireless sensor networks
    for cost-efficient residential energy management in the smart grid IEEE Trans.
    Smart Grid, 2 (2) (2011), pp. 314-325 View in ScopusGoogle Scholar [31] A.A. Sreesha,
    S. Somal, I.-T. Lu Cognitive radio based wireless sensor network architecture
    for smart grid utility 2011 IEEE Long Island Systems, Applications and Technology
    Conference, IEEE (2011), pp. 1-7 CrossRefGoogle Scholar [32] Y.-G. Yue, P. He
    A comprehensive survey on the reliability of mobile wireless sensor networks:
    taxonomy, challenges, and future directions Inf. Fusion, 44 (2018), pp. 188-204
    View PDFView articleView in ScopusGoogle Scholar [33] O. Georgiou, U. Raza Low
    power wide area network analysis: can lora scale? IEEE Wirel. Commun. Lett., 6
    (2) (2017), pp. 162-165 View in ScopusGoogle Scholar [34] U. Raza, P. Kulkarni,
    M. Sooriyabandara Low power wide area networks: an overview IEEE Commun. Surv.
    Tut., 19 (2) (2017), pp. 855-873 View in ScopusGoogle Scholar [35] M. Chen, Y.
    Miao, Y. Hao, K. Hwang Narrow band internet of things IEEE Access, 5 (2017), pp.
    20557-20577 View in ScopusGoogle Scholar [36] Y.-P.E. Wang, X. Lin, A. Adhikary,
    A. Grovlen, Y. Sui, Y. Blankenship, J. Bergman, H.S. Razaghi A primer on 3gpp
    narrowband internet of things IEEE Commun. Mag., 55 (3) (2017), pp. 117-123 View
    in ScopusGoogle Scholar [37] I.A.T. Hashem, V. Chang, N.B. Anuar, K. Adewole,
    I. Yaqoob, A. Gani, E. Ahmed, H. Chiroma The role of big data in smart city Int.
    J. Inf. Manag. (2016) Google Scholar [38] J. Han, J. Pei, M. Kamber Data Mining:
    Concepts and Techniques Elsevier (2011) Google Scholar [39] B.V. Dasarathy Sensor
    fusion potential exploitation-innovative architectures and illustrative applications
    Proc. IEEE, 85 (1) (1997), pp. 24-38 View in ScopusGoogle Scholar [40] H.F. Durrant
    Whyte Sensor models and multisensor integration Int. J. Robot. Res., 7 (6) (1988),
    pp. 97-113 CrossRefView in ScopusGoogle Scholar [41] A.N. Steinberg, C.L. Bowman
    Revisions to the jdl data fusion model Handbook of Multisensor Data Fusion, CRC
    Press (2008), pp. 65-88 Google Scholar [42] S. Grime, H.F. Durrant-Whyte Data
    fusion in decentralized sensor networks Control Eng. Pract., 2 (5) (1994), pp.
    849-863 View PDFView articleView in ScopusGoogle Scholar [43] P. Cheng, T. Toutin
    Urban planning using data fusion of satellite and aerial photo images 1997 IEEE
    International Geoscience and Remote Sensing, 1997. IGARSS’97. Remote Sensing-A
    Scientific Vision for Sustainable Development., vol. 2, IEEE (1997), pp. 839-841
    Google Scholar [44] C. Huang, G.C. Alexandropoulos, C. Yuen, M. Debbah Deep Learning
    for UL/DL Channel Calibration in Generic Massive Mimo Systems Large Intelligent
    Surfaces (2019), pp. 1-6 Google Scholar https://arxiv.org/abs/1903.02875;toappearICC2019.
    [45] X. Hong, C. Nugent, M. Mulvenna, S. McClean, B. Scotney, S. Devlin Evidential
    fusion of sensor data for activity recognition in smart homes Pervas. Mob. Comput.,
    5 (3) (2009), pp. 236-252 View PDFView articleView in ScopusGoogle Scholar [46]
    H. Shen, L. Huang, L. Zhang, P. Wu, C. Zeng Long-term and fine-scale satellite
    monitoring of the urban heat island effect by the fusion of multi-temporal and
    multi-sensor remote sensed data: a 26-year case study of the city of wuhan in
    china Remote Sens. Environ., 172 (2016), pp. 109-125 View PDFView articleView
    in ScopusGoogle Scholar [47] O. Kreibich, J. Neuzil, R. Smid Quality-based multiple-sensor
    fusion in an industrial wireless sensor network for MCM IEEE Trans. Ind. Electron.,
    61 (9) (2014), pp. 4903-4911 View in ScopusGoogle Scholar [48] X. Luo, D. Zhang,
    L.T. Yang, J. Liu, X. Chang, H. Ning A kernel machine-based secure data sensing
    and fusion scheme in wireless sensor networks for the cyber-physical systems Fut.
    Gener. Comput. Syst., 61 (2016), pp. 85-96 View PDFView articleView in ScopusGoogle
    Scholar [49] H. Li, L. Lai, W. Zhang Communication requirement for reliable and
    secure state estimation and control in smart grid IEEE Trans. Smart Grid, 2 (3)
    (2011), pp. 476-486 View in ScopusGoogle Scholar [50] J. Petit, B. Stottelaar,
    M. Feiri, F. Kargl Remote attacks on automated vehicles sensors: experiments on
    camera and lidar Black Hat Europe, 11 (2015), p. 2015 Google Scholar [51] P. Guo,
    H. Kim, N. Virani, J. Xu, M. Zhu, P. Liu Roboads: anomaly detection against sensor
    and actuator misbehaviors in mobile robots 2018 48th Annual IEEE/IFIP International
    Conference on Dependable Systems and Networks (DSN), IEEE (2018), pp. 574-585
    View in ScopusGoogle Scholar [52] N. Dawar, N. Kehtarnavaz A convolutional neural
    network-based sensor fusion system for monitoring transition movements in healthcare
    applications 2018 IEEE 14th International Conference on Control and Automation
    (ICCA), IEEE (2018), pp. 482-485 CrossRefView in ScopusGoogle Scholar [53] L.
    Jayasinghe, N. Wijerathne, C. Yuen, M. Zhang Feature learning and analysis for
    cleanliness classification in restrooms IEEE Access, 7 (2019), pp. 14871-14882
    CrossRefView in ScopusGoogle Scholar [54] A. Ghorpade, F.C. Pereira, F. Zhao,
    C. Zegras, M. Ben-Akiva An integrated stop-mode detection algorithm for real world
    smartphone-based travel survey Transportation Research Board 94th Annual Meeting,
    15–6021 (2015), pp. 1-16 CrossRefGoogle Scholar [55] W. Luan, D. Sharp, S. Lancashire
    Smart grid communication network capacity planning for power utilities 2010 IEEE
    PES Transmission and Distribution Conference and Exposition, IEEE (2010), pp.
    1-4 CrossRefGoogle Scholar [56] S. Consoli, D. Reforgiato Recupero, M. Mongiovi,
    V. Presutti, G. Cataldi, W. Patatu An urban fault reporting and management platform
    for smart cities 2015 Proceedings of the 24th International Conference on World
    Wide Web, ACM (2015), pp. 535-540 CrossRefView in ScopusGoogle Scholar [57] F.
    Ricci Travel recommender systems IEEE Intell. Syst., 17 (6) (2002), pp. 55-57
    Google Scholar [58] S.B. Kotsiantis, I. Zaharakis, P. Pintelas Supervised machine
    learning: a review of classification techniques Emerg. Artif. Intell. Appl.Comput.
    Eng., 160 (2007), pp. 3-24 Google Scholar [59] T.M. Cover, P.E. Hart, et al. Nearest
    neighbor pattern classification IEEE Trans. Inf. Theory, 13 (1) (1967), pp. 21-27
    Google Scholar [60] Y. Bar-Shalom, F. Daum, J. Huang The probabilistic data association
    filter IEEE Control Syst. Mag., 29 (6) (2009), pp. 82-100 CrossRefView in ScopusGoogle
    Scholar [61] J.P. Shaffer Multiple hypothesis testing Ann. Rev. Psychol., 46 (1)
    (1995), pp. 561-584 CrossRefView in ScopusGoogle Scholar [62] I.J. Myung Tutorial
    on maximum likelihood estimation J. Math. Psychol., 47 (1) (2003), pp. 90-100
    View PDFView articleView in ScopusGoogle Scholar [63] G. Welch, G. Bishop, et
    al. An Introduction to the Kalman Filter (1995) Google Scholar [64] B. Ristic,
    S. Arulampalam, N. Gordon Beyond the Kalman filter IEEE Aerosp. Electron. Syst.
    Mag., 19 (7) (2004), pp. 37-38 Google Scholar [65] J.K. Uhlmann Covariance consistency
    methods for fault-tolerant distributed data fusion Inf. Fusion, 4 (3) (2003),
    pp. 201-215 View PDFView articleView in ScopusGoogle Scholar [66] G.E. Box, G.C.
    Tiao Bayesian Inference in Statistical Analysis vol. 40, John Wiley & Sons (2011)
    Google Scholar [67] H. Wu, M. Siegel, R. Stiefelhagen, J. Yang Sensor fusion using
    Dempster-Shafer theory [for context-aware HCI] IMTC/2002. Proceedings of the 19th
    IEEE Instrumentation and Measurement Technology Conference (IEEE Cat. No. 00CH37276),
    vol. 1, IEEE (2002), pp. 7-12 CrossRefGoogle Scholar [68] F. Herrera, E. Herrera-Viedma,
    L. Martnez A fusion approach for managing multi-granularity linguistic term sets
    in decision making Fuzzy Sets Syst., 114 (1) (2000), pp. 43-58 View PDFView articleView
    in ScopusGoogle Scholar [69] D.A. Pacyga Applied Linear Regression Models University
    of Chicago Press, Chicago (1996) Google Scholar [70] J. Makhoul Linear prediction:
    a tutorial review Proc. IEEE, 63 (4) (1975), pp. 561-580 View in ScopusGoogle
    Scholar [71] C. Lork, B. Rajasekhar, C. Yuen, N.M. Pindoriya How many watts: a
    data driven approach to aggregated residential air-conditioning load forecasting
    2017 IEEE International Conference on Pervasive Computing and Communications Workshops
    (PerCom Workshops), IEEE (2017), pp. 285-290 View in ScopusGoogle Scholar [72]
    A.K. Jain, M.N. Murty, P.J. Flynn Data clustering: a review ACM Comput. Surv.,
    31 (3) (1999), pp. 264-323 View in ScopusGoogle Scholar [73] H.-J. Liao, C.-H.R.
    Lin, Y.-C. Lin, K.-Y. Tung Intrusion detection system: a comprehensive review
    J.Netw. Comput. Appl., 36 (1) (2013), pp. 16-24 View PDFView articleView in ScopusGoogle
    Scholar [74] X.J. Zhu Semi-Supervised Learning Literature Survey Technical Report,
    University of Wisconsin-Madison Department of Computer Sciences (2005) Google
    Scholar [75] I. Jolliffe Principal Component Analysis Springer (2011) Google Scholar
    [76] F. Zhang, B. Zhou, L. Liu, Y. Liu, H.H. Fung, H. Lin, C. Ratti Measuring
    human perceptions of a large-scale urban region using machine learning Landsc.
    Urban Plann., 180 (2018), pp. 148-160 View PDFView articleView in ScopusGoogle
    Scholar [77] S.J. Miah, H.Q. Vu, J. Gammack, M. McGrath A big data analytics method
    for tourist behaviour analysis Inf. Manag., 54 (6) (2017), pp. 771-785 View PDFView
    articleView in ScopusGoogle Scholar [78] J. Nichol, M.S. Wong Modeling urban environmental
    quality in a tropical city Landsc. Urban Plann., 73 (1) (2005), pp. 49-58 View
    PDFView articleView in ScopusGoogle Scholar [79] C.-T. Fan, Y.-K. Wang, C.-R.
    Huang Heterogeneous information fusion and visualization for a large-scale intelligent
    video surveillance system IEEE Trans. Syst. Man Cybern., 47 (4) (2017), pp. 593-604
    View in ScopusGoogle Scholar [80] C. Ware Information Visualization: Perception
    for Design Elsevier (2012) Google Scholar [81] B.P.L. Lau, T. Chaturvedi, B.K.K.
    Ng, K. Li, M.S. Hasala, C. Yuen Spatial and temporal analysis of urban space utilization
    with renewable wireless sensor network 2016 IEEE/ACM 3rd International Conference
    on Big Data Computing, Applications and Technologies, ACM (2016), pp. 133-142
    CrossRefView in ScopusGoogle Scholar [82] Y. Zheng, F. Liu, H.-P. Hsieh U-air:
    when urban air quality inference meets big data 2013 ACM SIGKDD Proceedings of
    the 19th International Conference on Knowledge Discovery and Data Mining, ACM
    (2013), pp. 1436-1444 CrossRefView in ScopusGoogle Scholar [83] L. Spinello, K.O.
    Arras People detection in RGB-d data 2011 IEEE/RSJ International Conference on
    Intelligent Robots and Systems, IEEE (2011), pp. 3838-3843 View in ScopusGoogle
    Scholar [84] S. Lee, D. Yoon, A. Ghosh Intelligent parking lot application using
    wireless sensor networks 2008 International Symposium on Collaborative Technologies
    and Systems, IEEE (2008), pp. 48-57 CrossRefView in ScopusGoogle Scholar [85]
    L.-C. Chen, T.-A. Teo, Y.-C. Shao, Y.-C. Lai, J.-Y. Rau Fusion of lidar data and
    optical imagery for building modeling Int. Arch. Photogram. Remote Sens., 35 (B4)
    (2004), pp. 732-737 CrossRefView in ScopusGoogle Scholar [86] S. Suma, R. Mehmood,
    A. Albeshri Automatic event detection in smart cities using big data analytics
    International Conference on Smart Cities, Infrastructure, Technologies and Applications,
    Springer (2017), pp. 111-122 Google Scholar [87] T. Breur Data analysis across
    various media: data fusion, direct marketing, clickstream data and social media
    J. Direct Data Digital Market.Pract., 13 (2) (2011), pp. 95-105 CrossRefView in
    ScopusGoogle Scholar [88] Z. Wang, L. Wang, A.I. Dounis, R. Yang Multi-agent control
    system with information fusion based comfort model for smart buildings Appl. Energy,
    99 (2012), pp. 247-254 View PDFView articleGoogle Scholar [89] J.A. Balazs, J.D.
    Velásquez Opinion mining and information fusion: a survey Inf. Fusion, 27 (2016),
    pp. 95-110 View PDFView articleView in ScopusGoogle Scholar [90] B. Guo, Z. Wang,
    Z. Yu, Y. Wang, N.Y. Yen, R. Huang, X. Zhou Mobile crowd sensing and computing:
    the review of an emerging human-powered sensing paradigm ACM Comput. Surv., 48
    (1) (2015), pp. 1-31, 10.1145/2794400 Google Scholar [91] S.H. Marakkalage, S.
    Sarica, B.P.L. Lau, S.K. Viswanath, T. Balasubramaniam, C. Yuen, B. Yuen, J. Luo,
    R. Nayak Understanding the lifestyle of older population: mobile crowdsensing
    approach IEEE Trans. Comput. Soc. Syst., 6 (1) (2019), pp. 82-95 CrossRefView
    in ScopusGoogle Scholar [92] E. Estellés-Arolas, F. González-Ladrón-De-Guevara
    Towards an integrated crowdsourcing definition J. Inf. Sci., 38 (2) (2012), pp.
    189-200 CrossRefView in ScopusGoogle Scholar [93] J. Howe The rise of crowdsourcing
    Wired Mag., 14 (6) (2006), pp. 1-4 CrossRefView in ScopusGoogle Scholar [94] M.
    Aftab, C. Chen, C.-K. Chau, T. Rahwan Automatic HVAC control with real-time occupancy
    recognition and simulation-guided model predictive control in low-cost embedded
    system Energy Build., 154 (2017), pp. 141-156 View PDFView articleView in ScopusGoogle
    Scholar [95] L. You, B. Tunçer, H. Xing Harnessing multi-source data about public
    sentiments and activities for informed design IEEE Trans. Knowl. Data Eng., 31
    (2) (2018), pp. 343-356, 10.1109/TKDE.2018.2828431 Google Scholar [96] F. Serdio,
    E. Lughofer, K. Pichler, T. Buchegger, M. Pichler, H. Efendic Fault detection
    in multi-sensor networks based on multivariate time-series models and orthogonal
    transformations Inf. Fusion, 20 (2014), pp. 272-291 View PDFView articleView in
    ScopusGoogle Scholar [97] W. Tushar, N. Wijerathne, W.-T. Li, C. Yuen, H.V. Poor,
    T.K. Saha, K.L. Wood Internet of things for green building management: disruptive
    innovations through low-cost sensor technology and artificial intelligence IEEE
    Signal Process. Mag., 35 (5) (2018), pp. 100-110 CrossRefView in ScopusGoogle
    Scholar [98] L.J. De Vin, A.H. Ng, J. Oscarsson, S.F. Andler Information fusion
    for simulation based decision support in manufacturing Robot. Comput. Integr.
    Manuf., 22 (5–6) (2006), pp. 429-436 View PDFView articleView in ScopusGoogle
    Scholar [99] J.-W. Park, S.-H. Sim, H.-J. Jung Wireless displacement sensing system
    for bridges using multi-sensor fusion Smart Mater. Struct., 23 (4) (2014), p.
    045022 CrossRefView in ScopusGoogle Scholar [100] Y. Zhou, B.P.L. Lau, C. Yuen,
    B. Tuncer, E. Wilhelm Understanding urban human mobility through crowdsensed data
    IEEE Commun. Mag., 56 (11) (2018), pp. 52-59 View PDFView articleCrossRefGoogle
    Scholar [101] S. Katoch, G. Muniraju, S. Rao, A. Spanias, P. Turaga, C. Tepedelenlioglu,
    M. Banavar, D. Srinivasan Shading prediction, fault detection, and consensus estimation
    for solar array control 2018 IEEE Industrial Cyber-Physical Systems (ICPS), IEEE
    (2018), pp. 217-222 View in ScopusGoogle Scholar [102] V. Catania, D. Ventura
    An approach for monitoring and smart planning of urban solid waste management
    using smart-m3 platform 2014 Proceedings of 15th Conference of Open Innovations
    Association FRUCT, IEEE (2014), pp. 24-31 CrossRefView in ScopusGoogle Scholar
    [103] J.L. Toole, S. Colak, B. Sturt, L.P. Alexander, A. Evsukoff, M.C. González
    The path most traveled: travel demand estimation using big data resources Transport.
    Res. Part C, 58 (2015), pp. 162-177 View PDFView articleView in ScopusGoogle Scholar
    [104] S.R. Mounce, A. Khan, A.S. Wood, A.J. Day, P.D. Widdop, J. Machell Sensor-fusion
    of hydraulic data for burst detection and location in a treated water distribution
    system Inf. Fusion, 4 (3) (2003), pp. 217-229 View PDFView articleView in ScopusGoogle
    Scholar [105] S. Izumi, S.-i. Azuma Real-time pricing by data fusion on networks
    IEEE Trans. Ind. Inform., 14 (3) (2018), pp. 1175-1185 CrossRefView in ScopusGoogle
    Scholar [106] A. Anjomshoaa, F. Duarte, D. Rennings, T. Matarazzo, P. de Souza,
    C. Ratti City scanner: building and scheduling a mobile sensing platform for smart
    city services IEEE Internet Things J., 5 (6) (2018), pp. 4567-4579, 10.1109/JIOT.2018.2839058
    View in ScopusGoogle Scholar [107] F. Tian An agri-food supply chain traceability
    system for china based on RFID & blockchain technology 2016 13th International
    Conference on Service Systems and Service Management, IEEE (2016), pp. 1-6 Google
    Scholar [108] R. Mehmood, M.A. Faisal, S. Altowaijri Future networked healthcare
    systems: a review and case study Handbook of Research on Redesigning the Future
    of Internet Architectures, IGI Global (2015), pp. 531-558 CrossRefGoogle Scholar
    [109] F. Ahmed, Y. Hawas An integrated real-time traffic signal system for transit
    signal priority, incident detection and congestion management Transport. Res.
    Part C, 60 (2015), pp. 52-76 View PDFView articleView in ScopusGoogle Scholar
    [110] A. Fleury, M. Vacher, N. Noury Svm-based multimodal classification of activities
    of daily living in health smart homes: sensors, algorithms, and first experimental
    results IEEE Trans. Inf. Technol.Biomed., 14 (2) (2010), pp. 274-283 View in ScopusGoogle
    Scholar [111] H.M. Hondori, M. Khademi, C.V. Lopes Monitoring intake gestures
    using sensor fusion (microsoft kinect and inertial sensors) for smart home tele-rehab
    setting 2012 IEEE 1st Annual Healthcare Innovation Conference (2012), pp. 36-39
    Google Scholar [112] M.S. Hossain, G. Muhammad, A. Alamri Smart healthcare monitoring:
    a voice pathology detection paradigm for smart cities Multimed. Syst. (2017),
    pp. 1-11 Google Scholar [113] H. Medjahed, D. Istrate, J. Boudy, J.-L. Baldinger,
    B. Dorizzi A pervasive multi-sensor data fusion for smart home healthcare monitoring
    2011 IEEE International Conference on Fuzzy Systems, IEEE (2011), pp. 1466-1473
    View in ScopusGoogle Scholar [114] L. Zhang, H. Leung, K.C.C. Chan Information
    fusion based smart home control system and its application IEEE Trans. Consum.
    Electron., 54 (3) (2008), pp. 1157-1165, 10.1109/TCE.2008.4637601 View in ScopusGoogle
    Scholar [115] R. Mehmood, F. Alam, N.N. Albogami, I. Katib, A. Albeshri, S.M.
    Altowaijri Utilearn: a personalised ubiquitous teaching and learning system for
    smart societies IEEE Access, 5 (2017), pp. 2615-2635 View in ScopusGoogle Scholar
    [116] A.B. Chan, Z.-S.J. Liang, N. Vasconcelos Privacy preserving crowd monitoring:
    counting people without people models or tracking 2008 IEEE Conference on Computer
    Vision and Pattern Recognition, IEEE (2008), pp. 1-7 CrossRefGoogle Scholar [117]
    R.C. Luo, K.L. Su Autonomous fire-detection system using adaptive sensory fusion
    for intelligent security robot IEEE/ASME Trans. Mechatron., 12 (3) (2007), pp.
    274-281 View in ScopusGoogle Scholar [118] M. Janssen, E. Estevez Lean government
    and platform-based governance-doing more with less Govern. Inf. Quart., 30 (2013),
    pp. S1-S8 View PDFView articleView in ScopusGoogle Scholar [119] B.P.L. Lau, N.
    Wijerathne, B.K.K. Ng, C. Yuen Sensor fusion for public space utilization monitoring
    in a smart city IEEE Internet Things J., 5 (2) (2018), pp. 473-481 CrossRefView
    in ScopusGoogle Scholar [120] M. Lu, B. Chen, X. Liao, T. Yue, H. Yue, S. Ren,
    X. Li, Z. Nie, B. Xu Forest types classification based on multi-source data fusion
    Remote Sens., 9 (11) (2017), p. 1153 CrossRefView in ScopusGoogle Scholar [121]
    P.T. Wolter, P.A. Townsend Multi-sensor data fusion for estimating forest species
    composition and abundance in northern minnesota Remote Sens. Environ., 115 (2)
    (2011), pp. 671-691 View PDFView articleView in ScopusGoogle Scholar [122] N.-B.
    Chang, C. Mostafiz, Z. Sun, W. Gao, C.-F. Chen Developing a prototype satellite-based
    cyber-physical system for smart wastewater treatment 2017 IEEE 14th International
    Conference on Networking, Sensing and Control, IEEE (2017), pp. 339-344 View in
    ScopusGoogle Scholar [123] H. Zhang, Y. Deng Engine fault diagnosis based on sensor
    data fusion considering information quality and evidence theory Adv. Mech. Eng.,
    10 (11) (2018) Google Scholar 1687814018809184. [124] L. Jayasinghe, T. Samarasinghe,
    C. Yuen, S.S. Ge Temporal convolutional memory networks for remaining useful life
    estimation of industrial machinery 2019 IEEE International Conference on Industrial
    Technology (2018), pp. 1-6 CrossRefGoogle Scholar [125] N. Ghosh, Y. Ravi, A.
    Patra, S. Mukhopadhyay, S. Paul, A. Mohanty, A. Chattopadhyay Estimation of tool
    wear during CNC milling using neural network-based sensor fusion Mech. Syst. Signal
    Process., 21 (1) (2007), pp. 466-479 View PDFView articleView in ScopusGoogle
    Scholar [126] X. Huang, H. Xu, L. Wu, H. Dai, L. Yao, F. Han A data fusion detection
    method for fish freshness based on computer vision and near-infrared spectroscopy
    Anal. Methods, 8 (14) (2016), pp. 2929-2935 CrossRefView in ScopusGoogle Scholar
    [127] D. Moshou, C. Bravo, R. Oberti, J. West, L. Bodria, A. McCartney, H. Ramon
    Plant disease detection based on data fusion of hyper-spectral and multi-spectral
    fluorescence imaging using Kohonen maps Real-Time Imag., 11 (2) (2005), pp. 75-83
    View PDFView articleView in ScopusGoogle Scholar [128] A. Khanum, A. Alvi, R.
    Mehmood Towards a semantically enriched computational intelligence (SECI) framework
    for smart farming International Conference on Smart Cities, Infrastructure, Technologies
    and Applications, Springer (2017), pp. 247-257 Google Scholar [129] A. Sato, R.
    Huang, N.Y. Yen Design of fusion technique-based mining engine for smart business
    Hum. Centric Comput. Inf. Sci., 5 (1) (2015), p. 23 View in ScopusGoogle Scholar
    [130] Z. Pang, Q. Chen, W. Han, L. Zheng Value-centric design of the internet-of-things
    solution for food supply chain: value creation, sensor portfolio and information
    fusion Inf. Syst. Front., 17 (2) (2015), pp. 289-319, 10.1007/s10796-012-9374-9
    View in ScopusGoogle Scholar [131] S.K. Viswanath, C. Yuen, X. Ku, X. Liu Smart
    tourist-passive mobility tracking through mobile application International Internet
    of Things Summit, Springer (2014), pp. 183-191 Google Scholar [132] K. Lin, A.
    Kansal, D. Lymberopoulos, F. Zhao Energy-accuracy trade-off for continuous mobile
    device location 2010 Proceedings of the 8th International Conference on Mobile
    Systems, Applications, and Services, ACM (2010), pp. 285-298 CrossRefGoogle Scholar
    [133] E. Wilhelm, S. Siby, Y. Zhou, X.J.S. Ashok, M. Jayasuriya, S. Foong, J.
    Kee, K.L. Wood, N.O. Tippenhauer Wearable environmental sensors and infrastructure
    for mobile large-scale urban deployment IEEE Sens. J., 16 (22) (2016), pp. 8111-8123
    View in ScopusGoogle Scholar [134] R. Liu, C. Yuen, T.-N. Do, U.-X. Tan Fusing
    similarity-based sequence and dead reckoning for indoor positioning without training
    IEEE Sens. J., 17 (13) (2017), pp. 4197-4207 View in ScopusGoogle Scholar [135]
    R. Liu, C. Yuen, T.-N. Do, D. Jiao, X. Liu, U.-X. Tan Cooperative relative positioning
    of mobile users by fusing IMU inertial and UWB ranging information 2017 IEEE International
    Conference on Robotics and Automation, IEEE (2017), pp. 5623-5629 View in ScopusGoogle
    Scholar [136] T. Liebig, N. Piatkowski, C. Bockermann, K. Morik Dynamic route
    planning with real-time traffic predictions Inf. Syst., 64 (2017), pp. 258-265
    View PDFView articleView in ScopusGoogle Scholar [137] T.-A. Teo, K.-H. Cho Bim-oriented
    indoor network model for indoor and outdoor combined route planning Adv. Eng.
    Inform., 30 (3) (2016), pp. 268-282 View PDFView articleView in ScopusGoogle Scholar
    [138] Y. Yoshimura, S. Sobolevsky, C. Ratti, F. Girardin, J.P. Carrascal, J. Blat,
    R. Sinatra An analysis of visitors’ behavior in the louvre museum: a study using
    bluetooth data Environ. Plann., 41 (6) (2014), pp. 1113-1131 CrossRefView in ScopusGoogle
    Scholar [139] H. Poonawala, V. Kolar, S. Blandin, L. Wynter, S. Sahu Singapore
    in motion: insights on public transport service level through farecard and mobile
    data analytics 2016 ACM SIGKDD Proceedings of the 22nd International Conference
    on Knowledge Discovery and Data Mining, ACM (2016), pp. 589-598 CrossRefView in
    ScopusGoogle Scholar [140] Q. Li, L. Chen, M. Li, S.-L. Shaw, A. Nüchter A sensor-fusion
    drivable-region and lane-detection system for autonomous vehicle navigation in
    challenging road scenarios IEEE Trans. Veh. Technol., 63 (2) (2014), pp. 540-555
    View in ScopusGoogle Scholar [141] C. Huang, L. Wang, L. Lai Data-driven short-term
    solar irradiance forecasting based on information of neighboring sites IEEE Trans.
    Ind. Electron. (2018) Google Scholar [142] S. Abeywickrama, L. Jayasinghe, H.
    Fu, S. Nissanka, C. Yuen RF-based direction finding of UAVs using DNN 2018 IEEE
    International Conference on Communication Systems (2018), pp. 157-161 CrossRefView
    in ScopusGoogle Scholar [143] R. Salpietro, L. Bedogni, M. Di Felice, L. Bononi
    Park here! A smart parking system based on smartphones’ embedded sensors and short
    range communication technologies 2015 IEEE 2nd World Forum on Internet of Things,
    IEEE (2015), pp. 18-23 CrossRefView in ScopusGoogle Scholar [144] J.H. Lee Smart
    health: concepts and status of ubiquitous health with smartphone 2011 International
    Conference on ICT Convergence (2011), pp. 388-389 CrossRefView in ScopusGoogle
    Scholar [145] T. Muhammed, R. Mehmood, A. Albeshri, I. Katib Ubehealth: a personalized
    ubiquitous cloud and edge-enabled networked healthcare system for smart cities
    IEEE Access, 6 (2018), pp. 32258-32285 CrossRefView in ScopusGoogle Scholar [146]
    N. Noury A smart sensor for the remote follow up of activity and fall detection
    of the elderly IEEE-EMB Special Topic 2nd Annual International Conference on Microtechnologies
    in Medicine & Biology, IEEE (2002), pp. 314-317 View in ScopusGoogle Scholar [147]
    H. Lee, K. Park, B. Lee, J. Choi, R. Elmasri Issues in data fusion for healthcare
    monitoring 2008 Proceedings of the 1st International Conference on Pervasive Technologies
    Related to Assistive Environments, ACM (2008), p. 3 CrossRefGoogle Scholar [148]
    L. Jiang, D.-Y. Liu, B. Yang Smart home research 2004 International Conference
    on Machine Learning and Cybernetics, vol. 2, IEEE (2004), pp. 659-663 View in
    ScopusGoogle Scholar [149] O. Brdiczka, J.L. Crowley, P. Reignier Learning situation
    models in a smart home IEEE Trans. Syst. Man Cybern.Part B (Cybernetics), 39 (1)
    (2009), pp. 56-63 View in ScopusGoogle Scholar [150] E. Fernandes, J. Jung, A.
    Prakash Security analysis of emerging smart home applications 2016 IEEE Symposium
    on Security and Privacy (SP), IEEE (2016), pp. 636-654 View in ScopusGoogle Scholar
    [151] N. Komninos, E. Philippou, A. Pitsillides Survey in smart grid and smart
    home security: issues, challenges and countermeasures IEEE Commun. Surv. Tut.,
    16 (4) (2014), pp. 1933-1954 View in ScopusGoogle Scholar [152] A. Dorri, S.S.
    Kanhere, R. Jurdak, P. Gauravaram Blockchain for IoT security and privacy: the
    case study of a smart home 2017 IEEE International Conference on Pervasive Computing
    and Communications Workshops (PerCom Workshops), IEEE (2017), pp. 618-623 View
    in ScopusGoogle Scholar [153] San Diego State University, International Center
    for Communications, California Department of Transportation Smart Communities
    Guidebook: Building Smart Communities, How California’s Communities Can Thrive
    in the Digital Age International Center for Communications, College of Professional
    Studies and Fine Arts, San Diego State University (1997) Google Scholar [154]
    H. Lindskog Smart communities initiatives Proceedings of the 3rd ISOneWorld Conference,
    vol. 16 (2004), pp. 14-16 Google Scholar [155] F. Liang, V. Das, N. Kostyuk, M.M.
    Hussain Constructing a data-driven society: China’s social credit system as a
    state surveillance infrastructure Policy Internet (2018) Google Scholar [156]
    A. Cheung, Y. Chen The rise of the data state: Chinas social credit system Emerging
    Technologies and the Future of Citizenship Workshop, Berlin Social Science Centre.
    (2018) Google Scholar [157] Z. Alazawi, O. Alani, M.B. Abdljabar, S. Altowaijri,
    R. Mehmood A smart disaster management system for future cities Proceedings of
    the 2014 ACM International Workshop on Wireless and Mobile Technologies for Smart
    Cities, ACM (2014), pp. 1-10 CrossRefView in ScopusGoogle Scholar [158] D. Jin,
    C. Hannon, Z. Li, P. Cortes, S. Ramaraju, P. Burgess, N. Buch, M. Shahidehpour
    Smart street lighting system: a platform for innovative smart city applications
    and a new frontier for cyber-security Electr. J., 29 (10) (2016), pp. 28-35 View
    PDFView articleView in ScopusGoogle Scholar [159] The City of Oslo: Oslo Smart
    City Strategy (2018) Google Scholar https://www.oslo.kommune.no/nprotectnunhboxnvoidb@xnhboxenglish/1735politics-and-administration/smart-oslo/smart-oslo-strategy/.
    [160] G. Sohn, I. Dowman Data fusion of high-resolution satellite imagery and
    lidar data for automatic building extraction ISPRS J. Photogram. Remote Sens.,
    62 (1) (2007), pp. 43-63 View PDFView articleView in ScopusGoogle Scholar [161]
    P. Xu, F. Davoine, J.-B. Bordes, H. Zhao, T. Denœux Multimodal information fusion
    for urban scene understanding Mach. Vis. Appl., 27 (3) (2016), pp. 331-349 CrossRefView
    in ScopusGoogle Scholar [162] M.Q. Raza, A. Khosravi A review on artificial intelligence
    based load demand forecasting techniques for smart grid and buildings Renew. Sustain.
    Energy Rev., 50 (2015), pp. 1352-1372 View PDFView articleView in ScopusGoogle
    Scholar [163] R. Baetens, B.P. Jelle, A. Gustavsen Properties, requirements and
    possibilities of smart windows for dynamic daylight and solar energy control in
    buildings: astate-of-the-art review Solar Energy Mater. Solar Cells, 94 (2) (2010),
    pp. 87-105 View PDFView articleView in ScopusGoogle Scholar [164] W.-T. Li, K.
    Thirugnanam, W. Tushar, C. Yuen, K.L. Wood Optimizing energy consumption of hot
    water system in buildings with solar thermal systems. SMARTGREENS (2017), pp.
    266-273 CrossRefView in ScopusGoogle Scholar [165] E. McKenna, M. Krawczynski,
    M. Thomson Four-state domestic building occupancy model for energy demand simulations
    Energy Build., 96 (2015), pp. 30-39 View PDFView articleView in ScopusGoogle Scholar
    [166] H. Chen, P. Chou, S. Duri, H. Lei, J. Reason The design and implementation
    of a smart building control system 2009 IEEE International Conference on E-Business
    Engineering, IEEE (2009), pp. 255-262 View PDFView articleGoogle Scholar [167]
    G. Cardone, A. Cirri, A. Corradi, L. Foschini The participact mobile crowd sensing
    living lab: the testbed for smart cities IEEE Commun. Mag., 52 (10) (2014), pp.
    78-85 View in ScopusGoogle Scholar [168] A. Antonić, V. Bilas, M. Marjanović,
    M. Matijašević, D. Oletić, M. Pavelić, I.P. Žarko, K. Pripužić, L. Skorin-Kapov
    Urban crowd sensing demonstrator: Sense the zagreb air International Conference
    on Software, Telecommunications and Computer Networks, IEEE (2014), pp. 423-424
    CrossRefView in ScopusGoogle Scholar [169] T.-M. Tu, S.-C. Su, H.-C. Shyu, P.S.
    Huang A new look at IHS-like image fusion methods Inf. Fusion, 2 (3) (2001), pp.
    177-186 View PDFView articleView in ScopusGoogle Scholar [170] M. Wu, C. Wu, W.
    Huang, Z. Niu, C. Wang, W. Li, P. Hao An improved high spatial and temporal data
    fusion approach for combining landsat and modis data to generate daily synthetic
    landsat imagery Inf. Fusion, 31 (2016), pp. 14-25 View PDFView articleView in
    ScopusGoogle Scholar [171] Y. Zeng, W. Huang, M. Liu, H. Zhang, B. Zou Fusion
    of satellite images in urban area: assessing the quality of resulting images 2010
    18th International Conference on Geoinformatics, IEEE (2010), pp. 1-4 Google Scholar
    [172] S. Wang, J. Wan, D. Zhang, D. Li, C. Zhang Towards smart factory for industry
    4.0: a self-organized multi-agent system with big data based feedback and coordination
    Comput. Netw., 101 (2016), pp. 158-168 View PDFView articleGoogle Scholar [173]
    C. Gröger, F. Niedermann, B. Mitschang Data mining-driven manufacturing process
    optimization Proceedings of the World Congress on Engineering, 3 (2012), pp. 4-6
    Google Scholar [174] J. Lee E-manufacturing – fundamental, tools, and transformation
    Robot. Comput. Integr. Manuf., 19 (6) (2003), pp. 501-507 View PDFView articleView
    in ScopusGoogle Scholar [175] G. Niu, B.-S. Yang, M. Pecht Development of an optimized
    condition-based maintenance system by data fusion and reliability-centered maintenance
    Reliabil. Eng. Syst. Saf., 95 (7) (2010), pp. 786-796 View PDFView articleView
    in ScopusGoogle Scholar [176] B. Schmidt, L. Wang Cloud-enhanced predictive maintenance
    Int J Adv ManufTechnol, 99 (1–4) (2018), pp. 5-13 CrossRefView in ScopusGoogle
    Scholar [177] S. Wolfert, L. Ge, C. Verdouw, M.-J. Bogaardt Big data in smart
    farming–a review Agric Syst, 153 (2017), pp. 69-80 View PDFView articleView in
    ScopusGoogle Scholar [178] A. Walter, R. Finger, R. Huber, N. Buchmann Opinion:
    smart farming is key to developing sustainable agriculture Proc. Natl. Acad. Sci.,
    114 (24) (2017), pp. 6148-6150 CrossRefView in ScopusGoogle Scholar [179] D. De
    Benedetto, A. Castrignano, M. Diacono, M. Rinaldi, S. Ruggieri, R. Tamborrino
    Field partition by proximal and remote sensing data fusion Biosyst. Eng., 114
    (4) (2013), pp. 372-383 View PDFView articleView in ScopusGoogle Scholar [180]
    Atlas Free-Range Fish Farming - Aquapod (2018) Google Scholar https://atlasofthefuture.org/project/aquapod-fish-farm/.
    [181] M.R. Hassan, B. Nath, M. Kirley A fusion model of hmm, ann and ga for stock
    market forecasting Expert Syst. Appl., 33 (1) (2007), pp. 171-180 View PDFView
    articleView in ScopusGoogle Scholar [182] M. Christopher Logistics & Supply Chain
    Management Pearson UK (2016) Google Scholar [183] B.W. Parkinson, P. Enge, P.
    Axelrad, J.J. Spilker Jr Global Positioning System: Theory and Applications, Volume
    II American Institute of Aeronautics and Astronautics (1996) Google Scholar [184]
    P. Misra, P. Enge Global Positioning System: Signals, Measurements and Performance
    (second ed.), Ganga-Jamuna Press, Massachusetts (2006) Google Scholar [185] A.
    Yassin, Y. Nasser, M. Awad, A. Al-Dubai, R. Liu, C. Yuen, R. Raulefs, E. Aboutanios
    Recent advances in indoor localization: a survey on theoretical approaches and
    applications IEEE Commun. Surv. Tut., 19 (2) (2016), pp. 1327-1346 Google Scholar
    [186] Z.B. Tariq, D.M. Cheema, M.Z. Kamran, I.H. Naqvi Non-GPS positioning systems:
    a survey ACM Comput. Surv., 50 (4) (2017), pp. 57:1-57:34, 10.1145/3098207 Google
    Scholar [187] J. Schlingensiepen, F. Nemtanu, R. Mehmood, L. McCluskey Autonomic
    transport management systemsenabler for smart cities, personalized medicine, participation
    and industry grid/industry 4.0 Intelligent Transportation Systems–Problems and
    Perspectives, Springer (2016), pp. 3-35 CrossRefView in ScopusGoogle Scholar [188]
    D. Delling, M. Goldszmidt, A.V. Goldberg, J. Krumm, R.F.F. Werneck, Controlling
    Travel Route Planning Module Based Upon User Travel Preference, 2017. US Patent
    9,612,128. Google Scholar [189] D. Han, S. Jung, M. Lee, G. Yoon Building a practical
    wi-fi-based indoor navigation system IEEE Pervas. Comput., 13 (2) (2014), pp.
    72-79 CrossRefView in ScopusGoogle Scholar [190] Y. Arfat, R. Mehmood, A. Albeshri
    Parallel shortest path graph computations of united states road network data on
    apache spark International Conference on Smart Cities, Infrastructure, Technologies
    and Applications, Springer (2017), pp. 323-336 Google Scholar [191] M.C. Gonzalez,
    C.A. Hidalgo, A.-L. Barabasi Understanding individual human mobility patterns
    Nature, 453 (7196) (2008), p. 779, 10.1038/nature06958 View in ScopusGoogle Scholar
    [192] S. Jiang, J. Ferreira, M.C. González Activity-based human mobility patterns
    inferred from mobile phone data: a case study of singapore IEEE Trans. Big Data,
    3 (2) (2017), pp. 208-219 Google Scholar [193] T.S. Prentow, A.J. Ruiz-Ruiz, H.
    Blunck, A. Stisen, M.B. Kjærgaard Spatio-temporal facility utilization analysis
    from exhaustive wifi monitoring Pervas. Mob. Comput., 16 (2015), pp. 305-316 View
    PDFView articleView in ScopusGoogle Scholar [194] M.G. Demissie, S. Phithakkitnukoon,
    T. Sukhvibul, F. Antunes, R. Gomes, C. Bento Inferring passenger travel demand
    to improve urban mobility in developing countries using cell phone data: a case
    study of senegal IEEE Trans. Intell. Transport.Syst., 17 (9) (2016), pp. 2466-2478
    View in ScopusGoogle Scholar [195] M.W. Horner, M.E. O’Kelly Embedding economies
    of scale concepts for hub network design J. Transport Geogr., 9 (4) (2001), pp.
    255-265 View PDFView articleView in ScopusGoogle Scholar [196] D. Karamshuk, C.
    Boldrini, M. Conti, A. Passarella Human mobility models for opportunistic networks
    IEEE Commun. Mag., 49 (12) (2011), pp. 157-165 View in ScopusGoogle Scholar [197]
    D. Zhang, J. Huang, Y. Li, F. Zhang, C. Xu, T. He Exploring human mobility with
    multi-source data at extremely large metropolitan scales 2014 Proceedings of the
    20th Annual International Conference on Mobile Computing and Networking, ACM (2014),
    pp. 201-212 CrossRefView in ScopusGoogle Scholar [198] D. Zhang, J. Zhao, F. Zhang,
    T. He coMobile: real-time human mobility modeling at urban scale using multi-view
    learning 2015 SIGSPATIAL Proceedings of the 23rd International Conference on Advances
    in Geographic Information Systems, ACM, ACM (2015), pp. 40:1-40:10, 10.1145/2820783.2820821
    Google Scholar [199] E. Alomari, R. Mehmood Analysis of tweets in arabic language
    for detection of road traffic conditions International Conference on Smart Cities,
    Infrastructure, Technologies and Applications, Springer (2017), pp. 98-110 Google
    Scholar [200] H. Wei, G. Zheng, H. Yao, Z. Li Intellilight: a reinforcement learning
    approach for intelligent traffic light control 2018 ACM SIGKDD Proceedings of
    the 24th International Conference on Knowledge Discovery & Data Mining, ACM (2018),
    pp. 2496-2505 CrossRefGoogle Scholar [201] B. Yao, P. Hu, X. Lu, J. Gao, M. Zhang
    Transit network design based on travel time reliability Transp. Res. Part C, 43
    (2014), pp. 233-248 View PDFView articleView in ScopusGoogle Scholar [202] M.A.
    Munizaga, C. Palma Estimation of a disaggregate multimodal public transport origin–destination
    matrix from passive smartcard data from santiago, chile Transp. Res. Part C, 24
    (2012), pp. 9-18 View PDFView articleView in ScopusGoogle Scholar [203] R. Mehmood,
    R. Meriton, G. Graham, P. Hennelly, M. Kumar Exploring the influence of big data
    on city transport operations: a markovian approach Int. J. Oper. Prod.Manag.,
    37 (1) (2017), pp. 75-104 View in ScopusGoogle Scholar [204] S.A. Shaheen, H.
    Zhang, E. Martin, S. Guzman China’s Hangzhou public bicycle: understanding early
    adoption and behavioral response to bikesharing Transport. Res. Rec., 2247 (1)
    (2011), pp. 33-41 CrossRefView in ScopusGoogle Scholar [205] J. Schuijbroek, R.C.
    Hampshire, W.-J. Van Hoeve Inventory rebalancing and vehicle routing in bike sharing
    systems Eur. J. Oper. Res., 257 (3) (2017), pp. 992-1004 View PDFView articleView
    in ScopusGoogle Scholar [206] P. Falcone, F. Borrelli, J. Asgari, H.E. Tseng,
    D. Hrovat Predictive active steering control for autonomous vehicle systems IEEE
    Trans. Control Syst. Technol., 15 (3) (2007), pp. 566-580 View in ScopusGoogle
    Scholar [207] A. Ferdowsi, U. Challita, W. Saad, N.B. Mandayam Robust deep reinforcement
    learning for security and safety in autonomous vehicle systems 2018 21st International
    Conference on Intelligent Transportation Systems (ITSC), IEEE (2018), pp. 307-312
    CrossRefView in ScopusGoogle Scholar [208] J. Gao, Y. Xiao, J. Liu, W. Liang,
    C.P. Chen A survey of communication/networking in smart grids Fut. Gener. Comput.
    Syst., 28 (2) (2012), pp. 391-404 View PDFView articleView in ScopusGoogle Scholar
    [209] M. Kordestani, M. Saif Data fusion for fault diagnosis in smart grid power
    systems 2017 IEEE 30th Canadian Conference on Electrical and Computer Engineering
    (CCECE), IEEE (2017), pp. 1-6 Google Scholar [210] K. Thirugnanam, S.K. Kerk,
    C. Yuen, N. Liu, M. Zhang Energy management for renewable microgrid in reducing
    diesel generators usage with multiple types of battery IEEE Trans. Ind. Electron.,
    65 (8) (2018), pp. 6772-6786 CrossRefView in ScopusGoogle Scholar [211] W. Tushar,
    C. Yuen, B. Chai, S. Huang, K.L. Wood, S.G. Kerk, Z. Yang Smart grid testbed for
    demand focused energy management in end user environments IEEE Wirel. Commun.,
    23 (6) (2016), pp. 70-80 View in ScopusGoogle Scholar [212] Y.-F. Huang, S. Werner,
    J. Huang, N. Kashyap, V. Gupta State estimation in electric power grids: meeting
    new challenges presented by the requirements of the future grid IEEE Signal Process.
    Mag., 29 (5) (2012), pp. 33-43 Google Scholar [213] T. Liu, Y. Sun, Y. Liu, Y.
    Gui, Y. Zhao, D. Wang, C. Shen Abnormal traffic-indexed state estimation: acyber–physical
    fusion approach for smart grid attack detection Fut. Gener. Comput. Syst., 49
    (2015), pp. 94-103 View PDFView articleView in ScopusGoogle Scholar [214] S. McLaughlin,
    B. Holbert, A. Fawaz, R. Berthier, S. Zonouz A multi-sensor energy theft detection
    framework for advanced metering infrastructures IEEE J. Sel. Areas Commun., 31
    (7) (2013), pp. 1319-1330 View in ScopusGoogle Scholar [215] G. Sideratos, N.D.
    Hatziargyriou An advanced statistical method for wind power forecasting IEEE Trans.
    Power Syst., 22 (1) (2007), pp. 258-265 View in ScopusGoogle Scholar [216] A.M.
    Foley, P.G. Leahy, A. Marvuglia, E.J. McKeogh Current methods and advances in
    forecasting of wind power generation Renew. Energy, 37 (1) (2012), pp. 1-8 View
    PDFView articleView in ScopusGoogle Scholar [217] J. Jung, R.P. Broadwater Current
    status and future advances for wind speed and power forecasting Renew. Sustain.
    Energy Rev., 31 (2014), pp. 762-777 View PDFView articleView in ScopusGoogle Scholar
    [218] N.L.D. Khoa, A. Anaissi, Y. Wang Smart infrastructure maintenance using
    incremental tensor analysis 2017 ACM Proceedings of the on Conference on Information
    and Knowledge Management, ACM (2017), pp. 959-967 CrossRefView in ScopusGoogle
    Scholar [219] T. Cioara, I. Anghel, I. Salomie, M. Antal, C. Pop, M. Bertoncini,
    D. Arnone, F. Pop Exploiting data centres energy flexibility in smart cities:
    business scenarios Inf. Sci., 476 (2019), pp. 392-412 View PDFView articleView
    in ScopusGoogle Scholar [220] Y. Li, Y. Zhang, K. Luo, T. Jiang, Z. Li, W. Peng
    Ultra-dense hetnets meet big data: green frameworks, techniques, and approaches
    IEEE Commun. Mag., 56 (6) (2018), pp. 56-63 Google Scholar [221] F. Kong, X. Liu
    A survey on green-energy-aware power management for datacenters ACM Comput. Surv.,
    47 (2) (2015), pp. 30:1-30:38, 10.1145/2642708 Google Scholar [222] T.S. Rappaport,
    S. Sun, R. Mayzus, H. Zhao, Y. Azar, K. Wang, G.N. Wong, J.K. Schulz, M. Samimi,
    F. Gutierrez Jr Millimeter wave mobile communications for 5g cellular: it will
    work! IEEE Access, 1 (1) (2013), pp. 335-349 View in ScopusGoogle Scholar [223]
    R. Mahapatra, Y. Nijsure, G. Kaddoum, N.U. Hassan, C. Yuen Energy efficiency tradeoff
    mechanism towards wireless green communication: a survey. IEEE Commun. Surv. Tut.,
    18 (1) (2016), pp. 686-705 View in ScopusGoogle Scholar [224] S. Wang, X. Zhang,
    Y. Zhang, L. Wang, J. Yang, W. Wang A survey on mobile edge networks: convergence
    of computing, caching and communications IEEE Access, 5 (2017), pp. 6757-6779
    Google Scholar [225] H. Ma, D. Zhao, P. Yuan Opportunities in mobile crowd sensing
    IEEE Commun. Mag., 52 (8) (2014), pp. 29-35 View in ScopusGoogle Scholar [226]
    X. Wang, Y. Sui, J. Wang, C. Yuen, W. Wu A distributed truthful auction mechanism
    for task allocation in mobile cloud computing IEEE Trans. Serv. Comput. (2018),
    10.1109/TSC.2018.2818147 Google Scholar 1–1. [227] D.N. Jha, S. Garg, P.P. Jayaraman,
    R. Buyya, Z. Li, R. Ranjan A holistic evaluation of docker containers for interfering
    microservices 2018 IEEE International Conference on Services Computing (SCC),
    IEEE (2018), pp. 33-40 CrossRefView in ScopusGoogle Scholar [228] S. Bi, C.K.
    Ho, R. Zhang Wireless powered communication: opportunities and challenges IEEE
    Commun. Mag., 53 (4) (2015), pp. 117-125 View in ScopusGoogle Scholar [229] T.
    Sekitani, M. Takamiya, Y. Noguchi, S. Nakano, Y. Kato, T. Sakurai, T. Someya A
    large-area wireless power-transmission sheet using printed organic transistors
    and plastic MEMS switches Nat. Mater., 6 (6) (2007), p. 413, 10.1038/nmat1903
    View in ScopusGoogle Scholar [230] B. Ubaldi Open Government Data 2013 (2013)
    Google Scholar [231] J.M. Cantera, R. Lewis Delivery Context Ontology (2010) Google
    Scholar W3C Working Group Note. [232] G. Antoniou, F. Van Harmelen Web ontology
    language: Owl Handbook on Ontologies, Springer (2004), pp. 67-92 CrossRefGoogle
    Scholar [233] D. Brickley Resource Description Framework (RDF) Schema Specification
    1.0 (2000) Google Scholar http://www.w3.org/TR/rdf-schema. [234] H. Neuhaus, M.
    Compton The semantic sensor network ontology AGILE Workshop on Challenges in Geospatial
    Data Harmonisation, Hannover, Germany (2009), pp. 1-33 CrossRefGoogle Scholar
    [235] S. Auer, C. Bizer, G. Kobilarov, J. Lehmann, R. Cyganiak, Z. Ives Dbpedia:
    a nucleus for a web of open data The Semantic Web, Springer (2007), pp. 722-735
    CrossRefGoogle Scholar [236] M. Organization Message Queuing Telemetry Transport
    (2018) Google Scholar [237] A. Martínez-Ballesté, P.A. Pérez-Martínez, A. Solanas
    The pursuit of citizens’ privacy: a privacy-aware smart city is possible IEEE
    Commun. Mag., 51 (6) (2013), pp. 136-141 View in ScopusGoogle Scholar [238] Y.
    Li, W. Dai, Z. Ming, M. Qiu Privacy protection for preventing data over-collection
    in smart city IEEE Trans. Comput., 65 (5) (2016), pp. 1339-1350 View in ScopusGoogle
    Scholar [239] C. Tankard What the GDPR means for businesses Netw. Secur., 2016
    (6) (2016), pp. 5-8 View PDFView articleCrossRefView in ScopusGoogle Scholar [240]
    J.P. Albrecht How the GDPR will change the world Eur. Data Prot. Law Rev., 2 (2016),
    p. 287 CrossRefGoogle Scholar [241] C. Cadwalladr, E. Graham-Harrison Revealed:
    50 million facebook profiles harvested for cambridge analytica in major data breach
    Guardian, 17 (2018) Google Scholar [242] W. Ding, X. Jing, Z. Yan, L.T. Yang A
    survey on data fusion in internet of things: towards secure and privacy-preserving
    fusion Inf. Fusion (2018) Google Scholar [243] B.K. Beaulieu-Jones, Z.S. Wu, C.
    Williams, C.S. Greene Privacy-preserving generative deep neural networks support
    clinical data sharing BioRxiv (2017), p. 159756 Google Scholar [244] C. Esteban,
    S.L. Hyland, G. Rätsch, Real-valued (medical) time series generation with recurrent
    conditional GANs, arXiv preprint arXiv:1706.02633 (2017). Google Scholar [245]
    R. Kitchin Getting Smarter About Smart Cities: Improving Data Privacy and Data
    Security (2016) Google Scholar Data Protection Unit, Department of the Taoiseach,
    Dublin, Ireland. [246] S. Chakrabarty, D.W. Engels A secure IoT architecture for
    smart cities 2016 13th IEEE annual consumer communications & networking conference
    (CCNC), IEEE (2016), pp. 812-813 Google Scholar [247] B. Mocanu, F. Pop, A. Mihaita,
    C. Dobre, A. Castiglione Data fusion technique in spider peer-to-peer networks
    in smart cities for security enhancements Inf. Sci., 479 (2019), pp. 607-621 Google
    Scholar [248] A. Talaş, F. Pop, G. Neagu Elastic stack in action for smart cities:
    making sense of big data 2017 13th IEEE International Conference on Intelligent
    Computer Communication and Processing (ICCP), IEEE (2017), pp. 469-476 Google
    Scholar [249] X. Wang, J. Zhang, E.M. Schooler, M. Ion Performance evaluation
    of attribute-based encryption: toward data privacy in the IoT 2014 IEEE International
    Conference on Communications (ICC), IEEE (2014), pp. 725-730 Google Scholar [250]
    M. Singh, M. Rajan, V. Shivraj, P. Balamuralidhar Secure MQTT for internet of
    things (IoT) 2015 Fifth International Conference on Communication Systems and
    Network Technologies, IEEE (2015), pp. 746-751 Google Scholar [251] M. Elhoseny,
    G. Ramírez-González, O.M. Abu-Elnasr, S.A. Shawkat, N. Arunkumar, A. Farouk Secure
    medical data transmission model for IoT-based healthcare systems IEEE Access,
    6 (2018), pp. 20596-20608 Google Scholar [252] M. David, E. Tom, B. Paul, T. Stephanie
    World’s Biggest Data Breaches & Hacks (2019) Google Scholar https://informationisbeautiful.net/visualizations/worlds-biggest-data-breaches-hacks/.
    [253] A. Bartoli, J. Hernández-Serrano, M. Soriano, M. Dohler, A. Kountouris,
    D. Barthel Security and privacy in your smart city Proceedings of the Barcelona
    Smart Cities Congress, 292 (2011), pp. 1-3 Google Scholar [254] R. Bellman Dynamic
    Programming Courier Corporation (2013) Google Scholar [255] Q. Zhang, L.T. Yang,
    Z. Chen, P. Li A survey on deep learning for big data Inf. Fusion, 42 (2018),
    pp. 146-157 Google Scholar [256] R. Miikkulainen, J. Liang, E. Meyerson, A. Rawal,
    D. Fink, O. Francon, B. Raju, H. Shahrzad, A. Navruzyan, N. Duffy, et al. Evolving
    deep neural networks Artificial Intelligence in the Age of Neural Networks and
    Brain Computing, Elsevier (2019), pp. 293-312 Google Scholar [257] W. Liu, Z.
    Wang, X. Liu, N. Zeng, Y. Liu, F.E. Alsaadi A survey of deep neural network architectures
    and their applications Neurocomputing, 234 (2017), pp. 11-26 Google Scholar [258]
    D. Gunning Explainable Artificial Intelligence (XAI) (2017) Google Scholar Defense
    Advanced Research Projects Agency (DARPA). [259] A. Kendall, Y. Gal What uncertainties
    do we need in Bayesian deep learning for computer vision? Advances in Neural Information
    Processing Systems (2017), pp. 5574-5584 Google Scholar [260] C.-C.J. Kuo, M.
    Zhang, S. Li, J. Duan, Y. Chen Interpretable convolutional neural networks via
    feedforward design J. Visual Commun. Image Represent., 60 (2019), pp. 346-359
    Google Scholar [261] Q. Da, Y. Yu, Z.-H. Zhou Learning with augmented class by
    exploiting unlabeled data Proceedings of the Twenty-Eighth AAAI Conference on
    Artificial Intelligence (2014), pp. 1760-1766 Google Scholar [262] Y.-F. Li, Z.-H.
    Zhou Towards making unlabeled data never hurt IEEE Trans. Pattern Anal. Mach.Intell.,
    37 (1) (2015), pp. 175-188 Google Scholar [263] S. Hoo-Chang, H.R. Roth, M. Gao,
    L. Lu, Z. Xu, I. Nogues, J. Yao, D. Mollura, R.M. Summers Deep convolutional neural
    networks for computer-aided detection: CNN architectures, dataset characteristics
    and transfer learning IEEE Trans. Med. Imag., 35 (5) (2016), p. 1285 Google Scholar
    Cited by (211) Identifying, Analyzing, and forecasting commuting patterns in urban
    public Transportation: A review 2024, Expert Systems with Applications Show abstract
    Reliable IoT analytics at scale 2024, Journal of Parallel and Distributed Computing
    Show abstract Deep learning and multi-modal fusion for real-time multi-object
    tracking: Algorithms, challenges, datasets, and comparative study 2024, Information
    Fusion Show abstract Clustering pipeline for vehicle behavior in smart villages
    2024, Information Fusion Show abstract Data fabric and digital twins: An integrated
    approach for data fusion design and evaluation of pervasive systems 2024, Information
    Fusion Show abstract A systematic review of data fusion techniques for optimized
    structural health monitoring 2024, Information Fusion Show abstract View all citing
    articles on Scopus View Abstract © 2019 Elsevier B.V. All rights reserved. Recommended
    articles Consensus evolution networks: A consensus reaching tool for managing
    consensus thresholds in group decision making Information Fusion, Volume 52, 2019,
    pp. 375-388 Wu Tong, …, Francisco Herrera View PDF Data fusion and transfer learning
    empowered granular trust evaluation for Internet of Things Information Fusion,
    Volume 78, 2022, pp. 149-157 Hui Lin, …, M. Shamim Hossain View PDF Smart city
    as a distributed platform: Toward a system for citizen-oriented management Computer
    Communications, Volume 152, 2020, pp. 323-332 Pablo Chamoso, …, Juan M. Corchado
    View PDF Show 3 more articles Article Metrics Citations Citation Indexes: 184
    Captures Readers: 1321 Social Media Shares, Likes & Comments: 19 View details
    About ScienceDirect Remote access Shopping cart Advertise Contact and support
    Terms and conditions Privacy policy Cookies are used by this site. Cookie settings
    | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V.,
    its licensors, and contributors. All rights are reserved, including those for
    text and data mining, AI training, and similar technologies. For all open access
    content, the Creative Commons licensing terms apply.'
  inline_citation: '>'
  journal: Information fusion (Print)
  limitations: '>'
  pdf_link: null
  publication_year: 2019
  relevance_score1: 0
  relevance_score2: 0
  title: A survey of data fusion in smart city applications
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1016/j.chemosphere.2004.11.087
  analysis: '>'
  authors:
  - Rehan Sadiq
  - Manuel J Rodrı́guez
  citation_count: 30
  full_citation: '>'
  full_text: '>

    Typesetting math: 64% Skip to main content Skip to article Journals & Books Search
    Register Sign in Brought to you by: University of Nebraska-Lincoln View PDF Download
    full issue Outline Abstract Keywords 1. Introduction 2. Dempster–Shafer theory
    for interpreting water quality monitoring data 3. Dempster–Shafer theory application
    for developing water quality index 4. Summary and conclusions References Show
    full outline Cited by (34) Figures (4) Tables (9) Table Table Table Table Table
    Table Show all tables Chemosphere Volume 59, Issue 2, April 2005, Pages 177-188
    Interpreting drinking water quality in the distribution system using Dempster–Shafer
    theory of evidence Author links open overlay panel Rehan Sadiq a, Manuel J. Rodriguez
    b Show more Share Cite https://doi.org/10.1016/j.chemosphere.2004.11.087 Get rights
    and content Abstract Interpreting water quality data routinely generated for control
    and monitoring purposes in water distribution systems is a complicated task for
    utility managers. In fact, data for diverse water quality indicators (physico-chemical
    and microbiological) are generated at different times and at different locations
    in the distribution system. To simplify and improve the understanding and the
    interpretation of water quality, methodologies for aggregation and fusion of data
    must be developed. In this paper, the Dempster–Shafer theory also called theory
    of evidence is introduced as a potential methodology for interpreting water quality
    data. The conceptual basis of this methodology and the process for its implementation
    are presented by two applications. The first application deals with the interpretation
    of spatial water quality data fusion, while the second application deals with
    the development of water quality index based on key monitored indicators. Based
    on the obtained results, the authors discuss the potential contribution of theory
    of evidence as a decision-making tool for water quality management. Previous article
    in issue Next article in issue Keywords Water qualityData fusionTheory of evidenceAggregation
    operatorsWater distribution system 1. Introduction Monitoring and inspection of
    a system or a process may use more than one type of measurements and/or observations
    to describe the overall Condition State. The credibility of measurements to assess
    overall Condition State is important to be quantified for reliable decision-making.
    The data fusion is useful for an objective aggregation that can be reproducible
    and interpretable. Many infrastructure engineering problems, e.g., condition assessment
    of assets, production process quality control, and water quality monitoring require
    more than one performance indicator to define the Condition State. In addition,
    the aggregation of spatial or temporal observations of one (or more) performance
    indicator(s) is generally performed for reliable predictions. The data fusion
    refers to the scientific aggregation of the observations and measurements. In
    some cases, different data sets (e.g., measured by different types of sensors
    and probes, various water quality indicators) give information on various aspects
    of the system or a process by complementing each other. Therefore, the motivation
    is to collect more information for accurate prediction of Condition State. It
    is also possible that the information collected by various data sets can also
    be redundant if it deals with the same aspect of the problem, but it improves
    the reliability as one measurement/observation is confirmed by the other. Complementing
    information and redundancy of data sets are the basis of data fusion applications
    in condition assessment of assets and water quality monitoring. Regular monitoring
    of raw water quality, treatment processes and water quality in the distribution
    systems are integral parts of total drinking water quality management for the
    implementation of a multi-barrier approach for maintaining high-quality tap water
    for consumers. Water distribution systems are subjected to adverse reactions and
    events that can change the high-quality water to unpalatable and unsafe for human
    consumption by the time it arrives at the tap of the consumer (LeChevallier et
    al., 1996). As water quality can change significantly in the distribution system,
    regular monitoring is even more essential to ensure that high-quality drinking
    water reaches the consumer. To monitor the quality of water in the distribution
    system, physical, chemical, and biological indicators are recorded from routine
    grab sampling, followed by an analysis in the laboratory or using portable kits
    in the field (APHA, AWWA, WPCF, 1995). Sensor technology exists that enables capturing
    some indicators through online monitoring rather than grab samples. This technology
    is continually evolving to encompass more types of water quality indicators. Some
    common water quality indicators used for water distribution are turbidity, residual
    disinfectant, pH, nitrates, phosphates, organic compounds, total/fecal coliforms,
    and heterotrophic bacteria (HPC) (Clark, 1994, Hunsinger and Zioglio, 2002, Coulibaly
    and Rodriguez, 2003). Water uses generate a large amount of water quality data
    by routine sampling to control and maintain the acceptable Condition State of
    water quality in the system. Information is gathered on diverse water quality
    indicators using different techniques (manual sampling or auto-samplers and subsequent
    laboratory analysis, or online monitoring with automatic analyzer equipment).
    To better understand and interpret the water quality data, the use of novel techniques
    that favour the fusion and the aggregation of data is required to be explored.
    In this paper, the application of Dempster–Shafer (D–S) theory or theory of evidence
    for interpretation of water quality in the distribution system is demonstrated
    with the help of two examples. The first example discusses the application of
    theory of evidence for water quality data fusion for the case of water samples
    collected at different locations in the distribution system at a given time (interpreting
    spatial information), which is equally valid for fusion of temporal data or combining
    both. The second example briefly discusses the application of D–S theory for developing
    water quality index (WQI) that helps in aggregating and interpreting water quality
    linguistically, but in a rational manner. 2. Dempster–Shafer theory for interpreting
    water quality monitoring data There are numerous techniques available for conducting
    data and knowledge and information fusion, and most common among them are Bayesian
    inference, Dempster–Shafer rule of combination, fuzzy rule-based inference, and
    neural networks (Roemer et al., 2001). The idea of evidence integration and accumulation
    of beliefs are commonly used in Bayesian inference, which implies that p(A) +
    p(¬A) = 1, i.e., the belief in a hypothesis A can be used to derive the belief
    in its complement (Alim, 1988). But “NOT A” is the missing evidence (lack of knowledge)
    that is dealt as equal noninformative priors (Principle of Insufficient Reason)
    in Bayesian inference instead of ignorance. Alim (1988) argued that “No evidence”
    is different from having the same degree of confidence in all hypotheses, which
    is the basic motivation behind D–S theory. Dempster–Shafer theory is a theory
    of evidence, which is based on classic work by Dempster (1968) and Shafer (1976).
    The D–S theory can be interpreted as a generalization of probability theory where
    probabilities are assigned to subsets as opposed to mutually exclusive singletons.
    The probability theory can associate evidence to only one possible event, whereas
    D–S theory determines the evidence to sets of events, i.e., if the evidence is
    sufficient enough to permit the assignment of probabilities to single event (singleton),
    the D–S theory inference reduces to the probabilistic formulation (Sentz and Ferson,
    2002). The D–S theory applications in civil and environmental engineering vary
    from slope stability (Binaghi et al., 1998), environmental decision-making (Chang
    and Wright, 1996, Attoh-Okine and Gibbons, 2001), seismic analysis (Alim, 1988),
    failure detection (Tanaka and Klir, 1999), biological surveillance of river water
    quality (Boyd et al., 1993), and remote sensing (Wang and Civco, 1994) to climate
    change (Luo and Caselton, 1997). Many more applications of D–S theory can be seen
    in detailed bibliography reported by Sentz and Ferson (2002). However, the potential
    for application of D–S theory in the drinking water industry, in particular for
    fusion and aggregation of water quality monitoring data in the distribution system,
    has not been investigated until now. In the following section, the concepts of
    D–S theory application will be introduced by means of an example of data fusion
    of monitoring information on water quality in the distribution system. 2.1. Basic
    concepts of Dempster–Shafer theory and application The frame of discernment Θ
    (also called universe of discourse) is defined as a set of mutually exclusive
    alternatives, which has 2Θ subsets in the domain. For example, if the frame of
    discernment Θ is a set {L, M, H} it may have 8 (=23) subsets. Three important
    concepts, namely, basic probability assignment (m or bpa), belief (bel), and plausibility
    (pl) functions are used in D–S theory. Alim (1988) summarized some basic features
    of the D–S theory as follows: • Evidence in the form of belief (or disbelief)
    is attributed to subsets in Θ; • As evidence accumulates, the hypothesis set tends
    to narrow down toward precise estimation of probability; and • Ignorance does
    not assume equal priors or uniformly distributed, rather it is assigned to frame
    of discernment Θ. For example, if some evidence “a” is attributed to subset “L”
    in Θ, the ignorance “1 − a” will not be equally distributed to “M” and “H”, rather
    it is assigned to Θ = {L, M, H}. Example 1 In this example, it is assumed that
    water quality in the distribution is reported qualitatively using three risk levels––low
    (L), medium (M) and high (H) from consumption viewpoint based on compliance of
    drinking water regulations. The frame of discernment, Θ = {L, M, H} contains 8
    subsets ϕ (a null set) {L}, {M}, {H}, {L, M}, {M, H}, {L, H}, and {L, M, H}. Therefore,
    depending on the evidence, water could be rated as low, medium, high, low or medium,
    low or high, medium or high, and low or medium or high (in case of complete ignorance).
    2.2. Basic probability assignment The basic probability assignment (bpa or m)
    is different from classical definition of probability and is defined by mapping
    over the interval [0, 1], where the null set m(ϕ) is “0” and the sum of the basic
    probability assignments m(A) in a given set A is “1”. The m(A) expresses the proportion
    of all relevant and available evidence that supports the claim that a particular
    element of Θ belongs to the set A but to no particular subset of A (Klir, 1995).
    For a given basic probability assignment m, every set for which m(A) ≠ 0 is called
    focal element. Formally, this description of m can be represented with the following
    equation: (1) Example 1 (Contd.): If the water utility manager reports with 60%
    confidence that water is of low risk quality and with 30% confidence that it is
    low or medium risk, the ignorance is therefore 10%. The focal elements of hypothesis
    A can be written as The basic probability assignments for remaining subsets will
    be zero. 2.3. Belief function The lower and upper bounds of an interval can be
    determined from the basic probability assignment, which contains the probability
    set bounded by two nonadditive measures belief and plausibility. The lower bound
    belief (bl) for a set A is defined as the sum of all the basic probability assignments
    of the proper subsets (B) of the set of interest A, i.e., B ⊆ A. The general relation
    between bpa and belief can be written as (2) The belief functions also follow
    these relationships (3) Example 1 (Contd.): The belief functions can be derived
    as 2.4. Plausibility function The upper bound, plausibility, is the summation
    of basic probability assignment of the sets B that intersect with the set of interest
    A, i.e., B ∩ (A) ≠ ϕ, and therefore it can be written as (4) The plausibility
    function can be related to belief function through a function called doubt, which
    is defined as the compliment of belief (5) In addition, the following relationships
    for belief and plausibility functions hold true in all circumstances (6) pl (
    A ) ⩾ bl ( A ) pl ( ϕ ) = 0 pl ( Θ ) = 1 pl ( ¬ A ) = 1 - bel ( A ) Example 1
    (Contd.): Continuing on the example, the plausibility function can be derived
    as follows pl ( A ) L = m ( A ) L + m ( A ) L , M + m ( A ) L , H + m ( A ) Θ
    = 1.0 pl ( A ) M = m ( A ) M + m ( A ) L , M + m ( A ) M , H + m ( A ) Θ = 0.4
    pl ( A ) H = m ( A ) H + m ( A ) L , H + m ( A ) M , H + m ( A ) Θ = 0.1 pl (
    A ) L , M = m ( A ) L + m ( A ) M + m ( A ) L , M + m ( A ) L , H + m ( A ) M
    , H + m ( A ) Θ = 1.0 pl ( A ) L , H = m ( A ) L + m ( A ) H + m ( A ) L , M +
    m ( A ) L , H + m ( A ) M , H + m ( A ) Θ = 1.0 pl ( A ) M , H = m ( A ) M + m
    ( A ) H + m ( A ) L , M + m ( A ) L , H + m ( A ) M , H + m ( A ) Θ = 0.4 pl (
    A ) L , M , H = m ( A ) M + m ( A ) M + m ( A ) H + m ( A ) L , M + m ( A ) L
    , H + m ( A ) M , H + m ( A ) Θ = 1.0 2.5. Belief interval The belief interval
    (U) represents a range in which true probability may lie. It can be determined
    by subtracting belief from plausibility. The narrow uncertainty band represents
    more precise probabilities. The probability is uniquely determined if bel(A) =
    pl(A) and for classical probability theory all probabilities are unique (Yager,
    1987). If U(A) has an interval [0, 1], it means that no information is available,
    but if the interval is [1, 1], then it means that A has been completely confirmed
    by m(A). Example 1 (Contd.): The uncertainty interval for the case at hand is
    U ( A ) L = [ 0.6 , 1.0 ] ; U ( A ) M = [ 0.0 , 0.4 ] ; U ( A ) H = [ 0.0 , 0.1
    ] U ( A ) L , M = [ 0.9 , 1.0 ] ; U ( A ) L , H = [ 0.6 , 1.0 ] ; U ( A ) M ,
    H = [ 0.0 , 0.4 ] ; and U ( A ) Θ = [ 1.0 , 1.0 ] 2.6. Dempster–Shafer rule of
    combination The purpose of data fusion is to summarize and simplify information
    rationally. The D–S theory assumes sources of information are independent. The
    multiple sources of information in our context could be water quality samples
    collected at various points Sis in the distribution system at a given time “tj”.
    The D–S rule of combination can help in providing an overall picture of water
    quality at a given time “tj” in the distribution system. Similarly, evidences
    about the water quality can be aggregated temporally (samples collected at various
    times tjs) at a given sampling point Si using D–S rule of combination. Alim (1988)
    described that the “combined” belief represents not only the total belief in a
    set A and all of its subsets but also takes into account the contribution of different
    sources of evidence that focus on A. The D–S inference uses trade-off type combination
    operators and less information is assumed than that of Bayesian inference by compromising
    on precision, but Bayesian theory does not express any uncertainty associated
    with it and uses Principle of Insufficient Reason for inference (Sentz and Ferson,
    2002). The D–S rule of combination strictly emphasizes on the agreement between
    multiple sources and ignores all the conflicting evidence through normalization.
    A strict conjunctive logic through AND operator (estimated by a product of two
    probabilities) is employed in combination of evidence. The D–S combination rule
    determines the joint m1–2 from the aggregation of two basic probability assignments
    m1 and m2 by following equation: (7) m 1 – 2 ( A ) = ∑ B ∩ C = A m 1 ( B ) m 2
    ( C ) 1 - K when A ≠ ϕ ; and m 1 – 2 ( ϕ ) = 0 where (8) K = ∑ B ∩ C = ϕ m 1 (
    B ) m 2 ( C ) where K is the degree of conflict in two sources of evidences. The
    denominator (1 − K) in Eq. (7) is a normalization factor, which helps aggregation
    by completely ignoring the conflicting evidence. The above equations can also
    written as (9) m 1 – 2 ( A ) = ∑ B ∩ C = A m 1 ( B ) m 2 ( C ) ∑ B ∩ C ≠ ϕ m 1
    ( B ) m 2 ( C ) Example 1 (Contd.): Water quality is monitored at two locations
    Si (i = 1, 2) in the distribution system at a given time tj. The utility manager
    is interested in overall water quality in the distribution system at tj based
    on these two observations S1 and S2 m1(B)L = 0.6 m2(C)M = 0.4 m1(B)L,M = 0.3 and
    m2(C)M,H = 0.2 m1(B)Θ = 0.1 m2(C)Θ = 0.4 By applying D–S rule of combination on
    sources of information B and C, the following data is generated: Degree of conflict
    = K = 0.24 + 0.12 = 0.36, therefore normalization factor = 1 − K = 0.64 m 1 –
    2 ( A ) L = 0.24 / 0.64 = 0.38 ; m 1 – 2 ( A ) M = ( 0.12 + 0.06 + 0.04 ) / 0.64
    = 0.34 ; m 1 – 2 ( A ) H = 0.0 ; m 1 – 2 ( A ) L , M = 0.12 / 0.64 = 0.19 ; m
    1 – 2 ( A ) L , H = 0.0 ; m 1 – 2 ( A ) M , H = 0.02 / 0.64 = 0.03 ; m 1 – 2 (
    A ) Θ = 0.04 / 0.64 = 0.06 Similarly, belief and plausibility functions and belief
    interval can be determined by using corresponding equation described earlier.
    Subsets m1–2(A) bel1–2(A) pl1–2(A) U1–2(A) ϕ 0.0 0.0 1.0 [0.0, 1.0] {L} 0.38 0.38
    0.63 [0.38, 0.63] {M} 0.34 0.34 0.62 [0.34, 0.62] {H} 0.0 0.0 0.09 [0.0, 0.09]
    {L, M} 0.19 0.91 1.0 [0.91, 1.0] {L, H} 0.0 0.38 0.66 [0.38, 0.66] {M, H} 0.03
    0.34 0.62 [0.34, 0.62] Θ 0.06 1.0 1.0 [1.0, 1.0] From the above analysis it can
    be noticed that based on evidence from two samples, the water quality can be rated
    as low or medium. 2.7. Modified combination rules Serious drawbacks have been
    identified in D–S rule of combination. Zadeh (1984) presented an intriguing example
    of a patient who is diagnosed by two physicians A and B. The physician A diagnosed
    that the patient has a disease x with the 99% probability (confidence) and has
    only 1% probability of disease y. The physician B diagnosed that the patient has
    a disease z with the 99% probability and has only 1% probability of disease y.
    The frame of discernment for the diseases is Θ = {x, y, z}. Using D–S rule of
    combination, following results will be obtained: Degree of conflict = K = 0.9999
    ∴ Normalization factor = 1 - K = 0.0001 m x ( disease ) = 0.0 ; m y ( disease
    ) = 1.0 ; and m z ( disease ) = 0.0 These results are counterintuitive, as 99.99%
    evidence was neglected due to conflict. Sentz and Ferson (2002) have provided
    an excellent review of various methods and techniques to resolve this discrepancy.
    Most common methods are Yager’s modified Dempster’s rule (1987), Inagaki’s Unified
    Combination rule (1991), and Zhang’s Center Combination rule (Zhang, 1994). 2.8.
    Aggregation operators The triangular norms (t-norms) are a class of operators
    introduced for the development of a probabilistic generalization of the theory
    of metric spaces (Ramik and Vlach, 2001). The t-norms are used extensively in
    fuzzy set theory. They provide a tool for defining various types of intersection
    of fuzzy sets and expressing conjunctive logic. The t-norms, satisfy the axioms
    of commutativity, associativity, monotonicity, and boundary condition (Ramik and
    Vlach, 2001). Triangular conorms (t-conorms) provide a tool for defining various
    types of union of fuzzy sets and expressing conjunctive logic. These operators
    also satisfy all the axioms of commutativity, associativity, monotonicity, and
    boundary condition (Ramik and Vlach, 2001). The t-norms and t-conorms provide
    a range of operations for the aggregation of fuzzy sets (and probability theory).
    Aggregation or fusion is done through satisfying several or few criteria (performance
    indicators). When the requirement is such that all (or several) criteria have
    to be met, t-norms (and-type operators) are typically used; but when the requirement
    is such that only few criteria have to be met (out of many), t-conorms (or-type
    operators) are typically used. Consequently, on the scale of strictness of criteria,
    the t-norms represent the more strict criteria because being intersection-based
    they require conjunction (and-type operator) of aggregation, while the t-conorms
    represent more relaxed criteria, as being union-based they require disjunction
    (or-type operator) of aggregation (Sentz and Ferson, 2002). Fig. 1 illustrates
    the entire range of aggregation operators from very strict to very relaxed. Note
    that t-norms and t-conorms are only two classes out of an entire range of aggregation
    operations. Average-type (e.g., arithmetic mean, ordered weighted average (OWA)
    operators) or compromising/compensatory operators lie in between two extremes.
    Download : Download full-size image Fig. 1. Aggregation operators (after Larsen,
    2002). 2.9. Disjunctive operator for Dempster–Shafer rule Traditional D–S rule
    of combination does not all allow to fuse the information from completely conflicting
    sources because the normalization factor (1 − K) becomes zero in Eq. (7). Yager
    (2004) addressed this issue and proposed the use of disjunctive operators. Eq.
    (9) can be modified as (10) m 1 – 2 ( A ) = ∑ B ∩ C = A max [ m 1 ( B ) , m 2
    ( C ) ] ∑ B ∩ C ≠ ϕ max [ m 1 ( B ) , m 2 ( C ) ] Other disjunctive operators
    (see Fig. 1) than “max” can also be used in Eq. (10). In the physician–patient
    example discussed by Zadeh (1984), the new diagnosis will be mx(disease) = 0.497,
    my(disease) = 0.005, and mz(disease) = 0.497. Example 1 (Contd.): The disjunctive
    (maximum) operator (Eq. (10)) is used in modified combination rule. After estimating
    the basic probability assignments, the belief and plausibility functions are determined
    as described before in Eqs. (2), (4), respectively. Subsets m1–2(A) bel1–2(A)
    pl1–2(A) U1–2(A) ϕ 0.0 0.0 1.0 [0.0, 1.0] {L} 0.35 0.35 0.53 [0.35, 0.53] {M}
    0.28 0.28 0.50 [0.28, 0.50] {H} 0.10 0.10 0.28 [0.10, 0.28] {L, M} 0.09 0.72 0.90
    [0.72, 0.90] {L, H} 0.05 0.50 0.72 [0.50, 0.72] {M, H} 0.09 0.47 0.65 [0.47, 0.65]
    Θ 0.04 1.00 1.00 [1.0, 1.0] From the above analysis it can be noticed that based
    on evidence from two samples, the water quality can be rated as low or medium.
    2.10. Combining sources of varying credibility The approaches described before
    implicitly assume that all sources of information are equally credible. Sampling
    locations for monitoring water quality may be representative of a part of water
    distribution system, e.g., if one sample is collected from main distribution line
    and the other is collected from a minor line, the influence zones of both samples
    are different. Similarly, if the samples are collected at the same point when
    two different flow conditions prevail, the evidence of water quality also needs
    to be adjusted based on flow conditions. Similarly, if water utility staff with
    different levels of expertise collects water samples, the observations need to
    be adjusted based on their credibility. Yager (2004) discussed the credibility
    issue in detail and suggested a credibility transformation function. This approach
    discounts the evidence with a credibility factor (α) and distributes remaining
    evidence (1 − α) equally among elements (n) of frame of discernment. (11) m (
    A ) a = m ( A ) • α + 1 - α n where α is the Credibility factor and n is the focal
    elements in frame of discernment. Example 1 (Contd.): Assume that credibility
    adjustment factors assigned to two samples collected at different locations in
    the distribution are αB = 1.0 and αC = 0.5. These factors represent the confidence
    of the collected information. The modified evidences will be m1(B)L = 0.6 m2(C)M
    = 0.36 m1(B)L,M = 0.3 and m2(C)M,H = 0.1 m1(B)Θ = 0.1 m2(C)L = 0.17 m2(C)H = 0.17
    and m2(C)Θ = 0.2 As credibility of first evidence is 100%, therefore no adjustment
    is required for m1(B), but evidence m2(C) is only 50% credible, the evidence is
    adjusted as below: m 2 ( C ) M = 0.4 • 0.5 + ( 1 - 0.5 ) / 3 = 0.36 m 2 ( C )
    L = 0.0 • 0.5 + ( 1 - 0.5 ) / 3 = 0.17 m 2 ( C ) H = 0.0 • 0.5 + ( 1 - 0.5 ) /
    3 = 0.17 m 2 ( C ) M , H = 0.2 • 0.5 = 0.1 m 2 ( C ) Θ = 0.4 • 0.5 = 0.2 It is
    important to note that as α → 0 (i.e., confidence for given evidence), the inference
    tends to become Baysian, i.e., Principle of Insufficient Reason is applied. A
    limiting case for evidence is m2(C)Θ = 1.0, i.e., complete ignorance in D–S framework.
    If the credibility factor α = 0, the adjusted evidence will become m 2 ( C ) L
    = 0 • 0 + ( 1 - 0 ) / 3 = 0.33 , similarly m 2 ( C ) M = 0.33 and m 2 ( C ) H
    = 0.33 The adjusted evidences can be combined using modified D–S rule of combination
    as described earlier. Subsets m1–2(A)a bel1–2(A)a pl1–2(A)a U1–2(A)a ϕ 0.0 0.0
    1.0 [0.0, 1.0] {L} 0.42 0.42 0.61 [0.42, 0.61] {M} 0.26 0.26 0.42 [0.26, 0.42]
    {H} 0.13 0.13 0.24 [0.13, 0.24] {L, M} 0.08 0.76 0.87 [0.76, 0.87] {L, H} 0.03
    0.58 0.74 [0.58, 0.74] {M, H} 0.05 0.44 0.58 [0.44, 0.58] Θ 0.03 1.00 1.00 [1.0,
    1.0] As noticed from the above analysis that belief of water quality being low
    is the highest among other Condition States (medium and high), therefore based
    on the available information the utility manager (or decision-maker) may conclude
    that water quality in the distribution is acceptable. But if the utility manager
    wants to be more confident about his judgement, he (she) will conclude that water
    quality is low or medium because the belief of subset {L, M} is 76%. In the above
    example, we allowed a subset {L, H}, that does not contain two contiguous states.
    But in reality, generally only two contiguous states are possible, i.e., in our
    case {L, M} or {M, H}. If the decision-maker wants to increase the confidence
    for his (her) judgement concerning water quality Condition State he (she) will
    collect more sample (evidence). In this way he (she) can narrow down the uncertainty
    and increase the confidence in his (her) judgment. 3. Dempster–Shafer theory application
    for developing water quality index Water quality is generally defined by a collection
    of upper and lower limits on selected possible contaminants (Maier, 1999). Water
    quality indicators can be classified into three broad categories: physical, chemical,
    and microbiological contaminants. Within each class, a number of quality indicators
    are considered. The acceptability of water quality for its intended use depends
    on the magnitude of these indicators (Swamee and Tyagi, 2000) and is often governed
    by regulations (US EPA, 2001). The physical, chemical, and microbiological processes
    occurring in drinking water distribution pipes are numerous and complex. A wealth
    of literature is available on water quality represented by an aggregate index
    using various statistical and mathematical techniques. Swamee and Tyagi (2000)
    have discussed in detail the pros and cons of different techniques and approaches
    available for evaluating the overall water quality index (WQI). Sinha et al. (1994)
    combined pH, chloride concentration, turbidity, residual chlorine, conductivity,
    and MPN (most probable number––a bacterial counting technique) into a single water
    quality index through a weighting technique to represent an overall water quality
    at various nodes in the distribution system. Sadiq et al. (2004) have suggested
    a fuzzy-based framework for aggregative risk analysis of water quality failure
    in the distribution system. Recently, Sadiq and Rodriguez (2004a) proposed a risk-based
    fuzzy synthetic evaluation technique for aggregating effects of disinfection byproducts
    found in drinking water. The WQI is a systematic way of interpreting measurements
    and (or) observations of water quality, which helps managers to describe a Condition
    State or to share and communicate with the public in a consistent manner. The
    WQI provides a general means of comparing and ranking water quality. Traditionally,
    WQI encompasses factors like number of indicators not meeting the regulation,
    frequency of a particular indicator by which it is not meeting the requirement
    in a given sampling protocol, and amount by which indicators are violating the
    regulatory requirements. These three factors are combined to form the WQI, which
    can be interpreted by predefined qualitative ranking system. For overall water
    quality based on various indicators, credibility adjustment is required for each
    indicator for its contribution. For example, if the water quality is defined by
    turbidity, total coliforms, residual chlorine, and aesthetic indicators (taste,
    odour, colour), the violation of turbidity from its threshold value has lesser
    consequences and impacts with respect to microbial violations. Different credibility
    weights need to be defined for each indicator representing its body of evidence
    in defining overall water quality. Another useful application of D–S rule of combination
    is to develop a WQI that integrates various water quality indicators (of noncommensurate
    units) as a single entity. Example 2 will illustrate such application for the
    case of aggregation of three important physico-chemical and microbiological indicators
    of water quality in the distribution system. Example 2 The application of disinfection
    agents in drinking water reduces the microbial risk but poses chemical risk in
    the form of their byproducts. A risk–risk trade-off is required to optimize the
    dose and type of disinfection practices. Three water quality indicators––trihalomethanes
    (THMs), residual chlorine (RC), and heterotrophic plate counts (HPCs) (indicator
    for microbial presence)––are identified for evaluating the overall water quality
    in the distribution system. The water quality is defined by five risk classes––very
    low (VL), low (L), medium (M), high (H), and very high (VH). Therefore, the frame
    of discernment is Θ = {VL, L, M, H, VH}. These water quality indicators are defined
    by these five classes of risk (Fig. 2). The thresholds shown in Fig. 2 for Example
    2 were established based on water quality standards and based on authors’ experience
    with the water quality in Canadian distribution systems. Download : Download full-size
    image Fig. 2. Basic probability assignments for water quality indicators.  • The
    bpa for a given water quality indicator is determined by mapping on corresponding
    triangular functions as shown in Fig. 2. The qualitative scale is defined in such
    a way that bpa for only two risk classes are obtained. Therefore, for any value
    of water quality indicator, maximum two focal elements are possible. In this setting,
    subsets with two or more elements are not allowed. For a water quality indicator,
    bpa is represented by a 5-tuple set {VL, L, M, H, VH}. • For a given water sample,
    the bpa for three indicators are represented as follow: m(RC)VL m(HPC)VL m(THM)VL
    m(RC)L m(HPC)L m(THM)L m(RC)M m(HPC)M m(THM)M m(RC)H m(HPC)H m(THM)H m(RC)VH m(HPC)VH
    m(THM)VH • The credibility factors α are assigned to these indicators based on
    expert judgement α RC = 0.9 α HPC = 0.5 α THM = 0.8 • The bpa for each water quality
    indicator is adjusted by credibility factors α using Eq. (11). The adjusted bpa
    for water quality indicators are aggregated using modified disjunctive operator
    D–S rule of combination. • The belief and plausibility functions and belief interval
    are determined.  Example 2 (Contd.): A water sample was collected from distribution
    system and tested for residual chlorine, THMs, and HPCs. RC = 0.09 mg / l ; HPC
    = 62 / 100 ml ; and THM = 118 ppb The bpa for each water quality indicator is
    derived from Fig. 2 m(RC)VL = 0.0 m(HPC)VL = 0.0 m(THM)VL = 0.0 m(RC)L = 0.0 m(HPC)L
    = 0.48 m(THM)L = 0.0 m(RC)M = 0.0 m(HPC)M = 0.52 m(THM)M = 0.0 m(RC)H = 0.87 m(HPC)H
    = 0.0 m(THM)H = 0.0 m(RC)VH = 0.13 m(HPC)VH = 0.0 m(THM)VH = 1.0 The bpa is adjusted
    with respect to their credibility factors. The evidence is modified to m(RC)VL
    = 0.02 m(HPC)VL = 0.10 m(THM)VL = 0.04 m(RC)L = 0.02 m(HPC)L = 0.34 m(THM)L =
    0.04 m(RC)M = 0.02 m(HPC)M = 0.36 m(THM)M = 0.04 m(RC)H = 0.80 m(HPC)H = 0.10
    m(THM)H = 0.04 m(RC)VH = 0.14 m(HPC)VH = 0.10 m(THM)VH = 0.84 The adjusted bpa
    for water quality indicators can be aggregated using disjunctive operator D–S
    rule of combination. bpa Belief Plausibility m(WQ)VL = 0.04 bl(WQ)VL = 0.04 pl(WQ)VL
    = 0.04 m(WQ)L = 0.14 bl(WQ)L = 0.14 pl(WQ)L = 0.14 m(WQ)M = 0.15 bl(WQ)M = 0.15
    pl(WQ)M = 0.15 m(WQ)H = 0.33 bl(WQ)H = 0.33 pl(WQ)H = 0.33 m(WQ)VH = 0.34 bl(WQ)VH
    = 0.34 pl(WQ)VH = 0.34 The probability mass function of risk can be plotted using
    belief function. The universe of discourse of risk scale is soft in nature (Fig.
    3). Download : Download full-size image Fig. 3. Probability mass function of risk.
    Utility values can be assigned to soft items to determine the water quality index
    as a crisp output. Yang and Xu (2002) discussed a probabilistic method to determine
    the utility values for soft items in a heuristic way. These values can also be
    determined through linear optimization based on expert judgement. Here, an arbitrary
    linear function is proposed to estimate the crisp WQI (a surrogate for representing
    risk) and all five classes of risk are assigned utility values as follow: (12)
    WQI = u 2 0 [ bl ( WQ ) VH ] + u 2 1 [ bl ( WQ ) H ] + u 2 2 [ bl ( WQ ) M ] +
    u 2 3 [ bl ( WQ ) L ] + u 2 4 [ bl ( WQ ) VL ] where utility coefficient u is
    assumed ≈1.3. New regulations for the allowable concentrations of disinfection
    byproducts are being developed in the US and elsewhere for drinking water supplies.
    Disinfection reduces the risk from microbial infections, but may pose cancer and
    other risks from the DBPs (THMs are the most commonly identified DBPs). Many other
    DBPs, however, remain to be identified and the public health significance of these
    is unknown. Society is facing a difficult trade-off between established (known)
    microbial risks due to pathogens and more uncertain (unknown) risks from DBPs.
    In the case of evaluating the risk–risk trade-offs in drinking water, the competing
    risks must be assessed within a common framework. Example 2 (Contd.): The risk–risk
    trade-off for HPCs (a microbial indicator) and THMs (representative DBP) is established
    at different levels of residual chlorine concentration in Fig. 4a–d. The WQI is
    used as a surrogate for risk, estimated using Eq. (12). Download : Download full-size
    image Fig. 4. Water quality index (WQI) representing risk profiles at various
    residual chlorine levels. The analysis is performed for 0, 0.2, 0.5, and 4 mg/l
    residual chlorine concentrations. When levels of residual chlorine are not detectable,
    the WQI varied approximately from 0.6 to 1.0. Higher risks were observed for even
    very low HPC and THM concentrations (Fig. 4a), because the minimal levels of residual
    chlorine are necessary to provide safeguard against microbial contamination. But
    when the residual concentration is increased to 0.2, 0.5, and 4.0 mg/l, the WQI
    varied from 0.2 to approximately 0.8 (Fig. 4b–d), which is comparatively lower
    than the first case. The three-dimensional characteristic risk curves (e.g. Fig.
    4) can be established for various water quality indicators, which are able to
    predict levels of any particular indicator (e.g., HPCs) that are required to achieve
    acceptable risk under given conditions. For example, for an acceptable risk (WQI)
    of 0.25, the residual chlorine in the distribution system is reported to be in
    the range of 0.2–0.5 mg/l and THM potential is estimated (using regression or
    kinetic models, see Sadiq and Rodriguez, 2004b) to be in the range of 25–50 ppb,
    and the HPC levels should not exceed 200/100 ml. This concept can be extended
    to more water quality indicators. 4. Summary and conclusions In this paper, the
    evidence theory was introduced as an innovative methodology that can be used for
    simplifying and improving the understanding of data generated through routine
    water quality monitoring in distribution systems. Two examples were presented
    that support the potential application of theory of evidence for data fusion,
    namely, interpretation of overall water quality in the distribution system based
    on spatial data collected at different sampling locations and development of WQI.
    For the first example, additional aspects should be investigated in the future,
    such as the impact of the uncertainty on the confidence of the decision-maker’s
    judgement (according to the amount of information available, in this case the
    number and the frequency of spatial distribution of samples collected). For the
    second example, additional information should be considered in the future to develop
    more robust indices, i.e., additional water quality indicators (e.g., pathogenic
    indicators such as coliforms and other disinfection byproducts like haloacetic
    acids), operational parameters (e.g., pressures, flow rates, reservoir level control,
    etc.), and data on the distribution system infrastructure (e.g., pipe breakage
    rate and replacement, pipe flushing etc.). Theory of evidence can efficiently
    deal with the difficulties related to host of indicators describing water quality,
    with spatial and temporal dimensions of distribution system, where redundancy
    of information is routinely observed as well as the credibility of available data
    is varied. Future research must focus on the implementation of decision-making
    tools using theory of evidence that can be adapted to specific water utility conditions
    and manager’s needs. The potential combination of theory of evidence with modeling
    techniques, such as linear and nonlinear time-series analysis, neural networks,
    and genetic algorithms, to predict the condition state of water quality must also
    be evaluated through future research efforts to implement more powerful decision-making
    tools. References Alim, 1988 S. Alim Application of Dempster–Shafer theory for
    interpretation of seismic parameters ASCE Journal of Structural Engineering, 114
    (9) (1988), pp. 2070-2084 View in ScopusGoogle Scholar APHA, AWWA, WPCF, 1995
    APHA, AWWA, WPCF Standard Methods for the Examination of Water and Wastewater
    (19th ed.), APHA, AWWA, WPCF, Washington, DC (1995) Google Scholar Attoh-Okine
    and Gibbons, 2001 N.O. Attoh-Okine, J. Gibbons Use of belief function in brownfield
    infrastructure redevelopment decision making ASCE Journal of Urban Planning and
    Development, 127 (3) (2001), pp. 126-143 View in ScopusGoogle Scholar Binaghi
    et al., 1998 E. Binaghi, L. Luzi, P. Madella, F. Pergalani, A. Rampini Slope instability
    zonation: a comparison between certainty factor and fuzzy Dempster–Shafer approaches
    Natural Hazards, 17 (1998), pp. 77-97 View in ScopusGoogle Scholar Boyd et al.,
    1993 Boyd, M., Walley, W.J., Hawkes, H.A., 1993. Dempster–Shafer reasoning for
    the biological surveillance of river water quality. In: Water Pollution 93, Milan,
    Italy Google Scholar Chang and Wright, 1996 Y.C. Chang, J.R. Wright Evidential
    reasoning for assessing environmental impact Civil Engineering Systems, 14 (1)
    (1996), pp. 55-77 CrossRefView in ScopusGoogle Scholar Clark, 1994 R.M. Clark
    Modelling water quality changes and contaminant propagation in drinking water
    distribution systems: a US perspective Journal Water SRT-Aqua, 43 (3) (1994),
    pp. 133-143 View in ScopusGoogle Scholar Coulibaly and Rodriguez, 2003 H. Coulibaly,
    M.J. Rodriguez Spatial and temporal variation of drinking water quality in ten
    Quebec small utilities Journal of Environmental Engineering & Science, 2 (1) (2003),
    pp. 47-61 View in ScopusGoogle Scholar Dempster, 1968 A. Dempster A generalisation
    of Bayesian inference Journal of Royal Statistical Society, Series B, 30 (1968),
    pp. 205-247 View in ScopusGoogle Scholar Hunsinger and Zioglio, 2002 R.B. Hunsinger,
    G. Zioglio Rationale for online monitoring E. Hargesheimer, O. Conio, J. Popovicova
    (Eds.), Online Monitoring for Drinking Water Utilities Co-operative Research Report,
    American Water Works Association Research Foundation, CO (2002) Google Scholar
    Inagaki, 1991 T. Inagaki Interdependence between safety-control policy and multiple
    sensor scheme via Dempster–Shafer theory IEEE Transactions on Reliability, 40
    (2) (1991), pp. 182-188 View in ScopusGoogle Scholar Klir, 1995 J.G. Klir Principles
    of uncertainty: what are they? why do we need them? Fuzzy Sets and Systems, 74
    (1995), pp. 15-31 View in ScopusGoogle Scholar Larsen, 2002 Larsen, H.L., 2002.
    Fundamentals of fuzzy sets and fuzzy logic. Available from <http://www.cs.aue.auc.dk/~legind/FL%20E2002/FL-01/FL-01%20Introduction.pdf>
    Google Scholar LeChevallier et al., 1996 M.W. LeChevallier, N.J. Welch, D.B. Smith
    Full-scale studies of factors related to coliform regrowth in drinking water Applied
    Environmental Microbiology, 62 (7) (1996), pp. 2201-2211 CrossRefView in ScopusGoogle
    Scholar Luo and Caselton, 1997 W.B. Luo, B. Caselton Using Dempster–Shafer theory
    to represent climate change uncertainties Journal of Environmental Management,
    49 (1) (1997), pp. 73-93 View PDFView articleView in ScopusGoogle Scholar Maier,
    1999 Maier, S.H., 1999. Modeling Water Quality for Water Distribution Systems.
    Ph.D. thesis, Brunel University, Uxbridge Google Scholar Ramik and Vlach, 2001
    J. Ramik, M. Vlach Generalized Concavity in Fuzzy Optimization and Decision Analysis
    Kluwer Academic Publishers, Boston (2001) Google Scholar Roemer et al., 2001 Roemer,
    M.J., Kacprzynski, G.J., Scholler, M.H., 2001. Improved diagnostic and prognostic
    assessments using health management information fusion. In: 2001 IEEE, pp. 365–377
    Google Scholar Sadiq and Rodriguez, 2004a R. Sadiq, M.J. Rodriguez Fuzzy synthetic
    evaluation of disinfection by-products––a risk-based indexing system Journal of
    Environmental Management, 73 (1) (2004), pp. 1-13 View PDFView articleView in
    ScopusGoogle Scholar Sadiq and Rodriguez, 2004b R. Sadiq, M.J. Rodriguez Disinfection
    by-products (DBPs) in drinking water and the predictive models for their occurrence:
    a review The Science of the Total Environment, 321 (1–3) (2004), pp. 21-46 View
    PDFView articleView in ScopusGoogle Scholar Sadiq et al., 2004 R. Sadiq, Y. Kleiner,
    B.B. Rajani Aggregative risk analysis for water quality failure in distribution
    networks AQUA––Journal of Water Supply: Research & Technology, 53 (4) (2004),
    pp. 241-261 View in ScopusGoogle Scholar Sentz and Ferson, 2002 Sentz, K., Ferson,
    S., 2002. Combination of evidence in Dempster–Shafer theory, SAND 2002-0835 Google
    Scholar Shafer, 1976 G. Shafer A Mathematical Theory of Evidence Princeton University
    Press, Princeton, NJ (1976) Google Scholar Sinha et al., 1994 R. Sinha, P. Gupta,
    P.K. Jain Water quality modeling of a city water distribution system Indian Journal
    of Environmental Health, 36 (4) (1994), pp. 258-262 View in ScopusGoogle Scholar
    Swamee and Tyagi, 2000 P.K. Swamee, A. Tyagi Describing water quality with aggregate
    index ASCE Journal of Environmental Engineering, 126 (5) (2000), pp. 451-455 View
    in ScopusGoogle Scholar Tanaka and Klir, 1999 K. Tanaka, G.J. Klir Design condition
    for incorporating human judgement into monitoring systems Reliability Engineering
    and System Safety, 65 (1999), pp. 251-258 View PDFView articleView in ScopusGoogle
    Scholar US EPA, 2001 US EPA, 2001. National primary drinking water standards.
    United States Environmental Protection Agency, EPA 816-F-01-007 Google Scholar
    Wang and Civco, 1994 Y. Wang, D.L. Civco Evidential reasoning-based classification
    of multi-source spatial data for improved land cover mapping Canadian Journal
    of Remote Sensing, 20 (1994), pp. 381-395 CrossRefView in ScopusGoogle Scholar
    Yager, 1987 R.R. Yager On the Dempster–Shafer framework and new combination rules
    Information Sciences, 41 (1987), pp. 93-137 View PDFView articleView in ScopusGoogle
    Scholar Yager, 2004 R.R. Yager On the determination of strength of belief for
    decision support under uncertainty––Part II: fusing strengths of belief Fuzzy
    Sets and Systems, 142 (2004), pp. 129-142 View PDFView articleView in ScopusGoogle
    Scholar Yang and Xu, 2002 J.-B. Yang, D.-L. Xu On the evidential reasoning algorithm
    of multiple attribute decision analysis under uncertainty IEEE Transactions on
    Systems Man and Cybernetics––Part A: Systems and Humans, 32 (3) (2002), pp. 289-304
    View in ScopusGoogle Scholar Zadeh, 1984 L.A. Zadeh Review of books: a mathematical
    theory of evidence The AI Magazine, 5 (3) (1984), pp. 81-83 Google Scholar Zhang,
    1994 L. Zhang Representation independence and combination of evidence in the Dempster–Shafer
    theory R.R. Yager, J. Kacprzyk, M. Fedrizzi (Eds.), Advances in Dempster–Shafer
    Theory of Evidence, John Wiley and Sons, NY (1994), pp. 51-69 CrossRefGoogle Scholar
    Cited by (34) Overall reliability assessment of water distribution system 2014,
    Procedia Engineering Show abstract Application of data fusion in human health
    risk assessment for hydrocarbon mixtures on contaminated sites 2013, Toxicology
    Show abstract Research and design of distributed fault diagnosis system in nuclear
    power plant 2013, Progress in Nuclear Energy Citation Excerpt : Misdiagnosis should
    be allowed in the pre-diagnosis result while missing diagnosis should be completely
    avoided. If the pre-diagnosis result from FNN has weak reliability, from the view
    point of system, we can take global diagnosis which applied data fusion diagnosis
    method, and the data fusion method is based on Dempster–Shafer (D-S) evidence
    theory (Bahador et al., 2013; Rehan et al., 2005; Belur, 1994). In this way, the
    NPP operation status can be better evaluated as a whole, thus reducing misdiagnosis
    or eliminating it thoroughly. Show abstract Empirical Models to Predict Disinfection
    By-products (DBPs) in Drinking Water 2011, Encyclopedia of Environmental Health
    Show abstract Water quality indicators: Comparison of a probabilistic index and
    a general quality index. The case of the Confederación Hidrográfica del Júcar
    (Spain) 2010, Ecological Indicators Show abstract Chemometrics based on fuzzy
    logic principles in environmental studies 2007, Talanta Show abstract View all
    citing articles on Scopus View Abstract Crown copyright © 2004 Published by Elsevier
    Ltd. All rights reserved. Recommended articles Non-invasive assessment of liver
    fibrosis by magnetic resonance elastography in patients with congenital heart
    disease undergoing the Fontan procedure and intracardiac repair Journal of Cardiology,
    Volume 68, Issue 3, 2016, pp. 202-208 Masaya Sugimoto, …, Hiroshi Azuma View PDF
    A biofilm model for assessing perchlorate reduction in a methane-based membrane
    biofilm reactor Chemical Engineering Journal, Volume 327, 2017, pp. 555-563 Jing
    Sun, …, Bing-Jie Ni View PDF Radiation induced cardiovascular disease: An odyssey
    of bedside-bench-bedside approach Life Sciences in Space Research, Volume 27,
    2020, pp. 49-55 Rishi Rikhi, …, Rohit Moudgil View PDF Show 3 more articles Article
    Metrics Citations Citation Indexes: 33 Captures Readers: 37 View details About
    ScienceDirect Remote access Shopping cart Advertise Contact and support Terms
    and conditions Privacy policy Cookies are used by this site. Cookie settings |
    Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V.,
    its licensors, and contributors. All rights are reserved, including those for
    text and data mining, AI training, and similar technologies. For all open access
    content, the Creative Commons licensing terms apply.'
  inline_citation: '>'
  journal: Chemosphere
  limitations: '>'
  pdf_link: null
  publication_year: 2005
  relevance_score1: 0
  relevance_score2: 0
  title: Interpreting drinking water quality in the distribution system using Dempster–Shafer
    theory of evidence
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1016/s0031-3203(98)00051-x
  analysis: '>'
  authors:
  - Sylvie Le Hégarat‐Mascle
  - Isabelle Bloch
  - D. Vidal-Madjar
  citation_count: 79
  full_citation: '>'
  full_text: '>

    Typesetting math: 100% Skip to main content Skip to article Journals & Books Search
    Register Sign in Brought to you by: University of Nebraska-Lincoln View PDF Download
    full issue Outline Abstract Keywords Cited by (74) Pattern Recognition Volume
    31, Issue 11, November 1998, Pages 1811-1823 INTRODUCTION OF NEIGHBORHOOD INFORMATION
    IN EVIDENCE THEORY AND APPLICATION TO DATA FUSION OF RADAR AND OPTICAL IMAGES
    WITH PARTIAL CLOUD COVER Author links open overlay panel S. LE HÉGARAT-MASCLE
    †, I. BLOCH ‡, D. VIDAL-MADJAR † Show more Add to Mendeley Share Cite https://doi.org/10.1016/S0031-3203(98)00051-X
    Get rights and content Abstract Two ways of introducing spatial information in
    Dempster–Shafer evidence theory are examined: in the definition of the monosource
    mass functions, and, during data fusion. In the latter case, a “neighborhood”
    mass function is derived from the label image and combined with the “radiometric”
    masses, according to the Dempster orthogonal sum. The main advantage of such a
    combination law is to adapt the importance of neighborhood information to the
    level of radiometric missing information. The importance of introducing neighborhood
    information has been illustrated through the following application: forest area
    detection using radar and optical images showing a partial cloud cover. Previous
    article in issue Next article in issue Keywords Data fusionMultisource classificationEvidence
    theoryMissing informationSpatial neighborhoodRemote sensing Cited by (74) Unsupervised
    segmentation of hidden Markov fields corrupted by correlated non-Gaussian noise
    2018, International Journal of Approximate Reasoning Citation Excerpt : Magnetic
    images are mainly used for medical purposes in diagnoses, or to assist a surgeon
    [5–8]. Many studies have been carried out to take full use of such data [9], especially
    in the frame of statistical data analysis covering image classification, image
    segmentation and image change detection, all of which can be perceived as pixel
    labeling problems where one has to recover a label “field” from an observable
    image. In the probabilistic framework of this paper, the latter is considered
    as a noisy version of the label field. Show abstract A manifold learning approach
    to urban land cover classification with optical and radar data 2018, Landscape
    and Urban Planning Citation Excerpt : For instance, Landsat TM/ETM+ and ERS-1/2
    have been frequently employed and fused using Bayesian theory, the Markov Random
    Field (MRF) model, an artificial neural network and generalized intensity modulation
    (Alparone, Baronti, Garzelli, & Nencini, 2004; Bruzzone, Prieto, & Serpico, 1999;
    Hong & Schowengerdt, 2005; Solberg, Jain, & Taxt, 1994; Solberg, Taxt, & Jain,
    1996; Zhang, Pulliainen, Koponen, & Hallikainen, 2002). SPOT data have often also
    been employed as optical data fused with various SAR data, such as ERS-1/2 data
    (Le Hegarat-Mascle, Bloch, & Vidal-Madjar, 1998; Waske & Benediktsson, 2007),
    ENVISAT ASAR data (Corbane, Faure, Baghdadi, Villeneuve, & Petit, 2008; Gamba
    & Dell''Acqua, 2008; Zhang et al., 2014), and airborne SAR data (Zhang, Yang,
    Zhao, Li, & Zhang, 2010). More recently, Landsat TM/ETM+ and MODIS data were fused
    with ALOS PALSAR data to monitor forests (Dong et al., 2013; Kou et al., 2015;
    Qin et al., 2016). Show abstract Dempster-Shafer fusion of evidential pairwise
    Markov fields 2016, International Journal of Approximate Reasoning Citation Excerpt
    : Some extensions of the standard HMFs using the theory of evidence are proposed
    to segment images in [13]. The problem of data fusion of radar and optical images
    with cloud cover is considered in [14]. Tupin et al. use DS fusion of several
    structure detectors for automatic interpretation of SAR images [15]. Show abstract
    Evaluating total inorganic nitrogen in coastal waters through fusion of multi-temporal
    RADARSAT-2 and optical imagery using random forest algorithm 2014, International
    Journal of Applied Earth Observation and Geoinformation Citation Excerpt : Therefore,
    the development of a method to effectively integrate SAR and optical imagery is
    of great interest for evaluating TIN concentrations in seawater. Several advanced
    techniques for the fusion of SAR and optical images have been developed for classification,
    object recognition and quantitative estimation, including image segmentation,
    filtering and transformation techniques (Macri-Pellizzeri et al., 2002; Pardo-Iguzquiza
    et al., 2011; Soria-Ruiz et al., 2010), neural network algorithm (Cutler et al.,
    2012; Dong et al., 2012; Vaglio Laurin et al., 2013; Zhang et al., 2002), statistical
    analysis (Li et al., 2011; Moghaddam et al., 2002), and the Dempster–Shafer theory
    (Le Hegarat-Mascle et al., 1998; Poulain et al., 2011). However, the conventional
    fusion techniques may overfit, run slowly, have a long training time and require
    assumptions on the distribution of the data (Poulain et al., 2011; Cutler et al.,
    2012). Show abstract Dealing with uncertainty and imprecision in image segmentation
    using belief function theory 2014, International Journal of Approximate Reasoning
    Show abstract Large gap imputation in remote sensed imagery of the environment
    2012, Computational Statistics and Data Analysis Show abstract View all citing
    articles on Scopus View Abstract Copyright © 1998 Pattern Recognition Society.
    Published by Elsevier B.V. All rights reserved. Recommended articles Analysis
    of thermal anomalies at Copahue Volcano between October 2011 and the December
    2012 eruption with MODIS Journal of South American Earth Sciences, Volume 110,
    2021, Article 103310 César A. Suárez-Herrera, …, Mariano Agusto View PDF Additional
    Contribution of the Malnutrition–Inflammation Score to Predict Mortality and Patient-Reported
    Outcomes as Compared With Its Components in a Cohort of African Descent Hemodialysis
    Patients Journal of Renal Nutrition, Volume 27, Issue 1, 2017, pp. 45-52 Marcelo
    Barreto Lopes, …, Antonio Alberto Lopes View PDF On the effects of hot spot formation
    during MW-assisted synthesis of Cf/SiC composites by reactive melt infiltration:
    Experimental simulations through high temperature treatments Journal of the European
    Ceramic Society, Volume 40, Issue 1, 2020, pp. 28-35 M. Caccia, J. Narciso View
    PDF Show 3 more articles Article Metrics Citations Citation Indexes: 73 Captures
    Readers: 23 View details About ScienceDirect Remote access Shopping cart Advertise
    Contact and support Terms and conditions Privacy policy Cookies are used by this
    site. Cookie settings | Your Privacy Choices All content on this site: Copyright
    © 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved,
    including those for text and data mining, AI training, and similar technologies.
    For all open access content, the Creative Commons licensing terms apply.'
  inline_citation: '>'
  journal: Pattern Recognition
  limitations: '>'
  pdf_link: null
  publication_year: 1998
  relevance_score1: 0
  relevance_score2: 0
  title: INTRODUCTION OF NEIGHBORHOOD INFORMATION IN EVIDENCE THEORY AND APPLICATION
    TO DATA FUSION OF RADAR AND OPTICAL IMAGES WITH PARTIAL CLOUD COVER
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/rs10020236
  analysis: '>'
  authors:
  - Giuseppe Scarpa
  - Massimiliano Gargiulo
  - A Mazza
  - Raffaele Gaetano
  citation_count: 123
  full_citation: '>'
  full_text: ">\nremote sensing  \nArticle\nA CNN-Based Fusion Method for Feature\
    \ Extraction\nfrom Sentinel Data\nGiuseppe Scarpa 1,*\nID , Massimiliano Gargiulo\
    \ 1, Antonio Mazza 1 and Raffaele Gaetano 2,3\n1\nDepartment of Electrical Engineering\
    \ and Information Technology (DIETI), University Federico II,\n80125 Naples, Italy;\
    \ massimiliano.gargiulo@unina.it (M.G.); antonio.mazza@unina.it (A.M.)\n2\nCentre\
    \ International de Recherche Agronomique pour le Développement (CIRAD), Unité\
    \ Mixte de\nRecherche Territoires, Environnement, Télédétéction et Information\
    \ Spatiale (UMR TETIS),\nMaison de la Télédétéction, 34000 Montpellier, France;\
    \ raffaele.gaetano@cirad.fr\n3\nUMR TETIS, University of Montpellier, 34000 Montpellier,\
    \ France\n*\nCorrespondence: giscarpa@unina.it; Tel.: +39-081-768-3768\nReceived:\
    \ 21 December 2017; Accepted: 30 January 2018; Published: 3 February 2018\nAbstract:\n\
    Sensitivity to weather conditions, and specially to clouds, is a severe limiting\
    \ factor\nto the use of optical remote sensing for Earth monitoring applications.\
    \ A possible alternative is\nto beneﬁt from weather-insensitive synthetic aperture\
    \ radar (SAR) images. In many real-world\napplications, critical decisions are\
    \ made based on some informative optical or radar features related\nto items such\
    \ as water, vegetation or soil. Under cloudy conditions, however, optical-based\
    \ features\nare not available, and they are commonly reconstructed through linear\
    \ interpolation between\ndata available at temporally-close time instants. In\
    \ this work, we propose to estimate missing\noptical features through data fusion\
    \ and deep-learning. Several sources of information are taken\ninto account—optical\
    \ sequences, SAR sequences, digital elevation model—so as to exploit both\ntemporal\
    \ and cross-sensor dependencies. Based on these data and a tiny cloud-free fraction\
    \ of the\ntarget image, a compact convolutional neural network (CNN) is trained\
    \ to perform the desired\nestimation. To validate the proposed approach, we focus\
    \ on the estimation of the normalized\ndifference vegetation index (NDVI), using\
    \ coupled Sentinel-1 and Sentinel-2 time-series acquired\nover an agricultural\
    \ region of Burkina Faso from May–November 2016. Several fusion schemes are\n\
    considered, causal and non-causal, single-sensor or joint-sensor, corresponding\
    \ to different operating\nconditions. Experimental results are very promising,\
    \ showing a signiﬁcant gain over baseline methods\naccording to all performance\
    \ indicators.\nKeywords: coregistration; pansharpening; multi-sensor fusion; multitemporal\
    \ images; deep learning;\nnormalized difference vegetation index (NDVI)\n1. Introduction\n\
    The recent launch of coupled optical/SAR (synthetic aperture radar) Sentinel satellites,\
    \ in the\ncontext of the Copernicus program, opens unprecedented opportunities\
    \ for end users, both industrial\nand institutional, and poses new challenges\
    \ to the remote sensing research community. The policy\nof free distribution of\
    \ data allows large-scale access to a very rich source of information. Besides\n\
    this, the technical features of the Sentinel constellation make it a valuable\
    \ tool for a wide array of\nremote sensing applications. With revisit time ranging\
    \ from two days to about a week, depending\non the geographic location, spatial\
    \ resolution from 5–60 m and wide coverage of the spectrum, from\nvisible to short-wave\
    \ infrared (~440–2200 nm), Sentinel data may decisively impact a number of Earth\n\
    monitoring applications, such as climate change monitoring, map updating, agriculture\
    \ and forestry\nplanning, ﬂood monitoring, ice monitoring, and so forth.\nRemote\
    \ Sens. 2018, 10, 236; doi:10.3390/rs10020236\nwww.mdpi.com/journal/remotesensing\n\
    Remote Sens. 2018, 10, 236\n2 of 20\nEspecially valuable is the diversity of information\
    \ guaranteed by the coupled SAR and\noptical sensors, a key element for boosting\
    \ the monitoring capability of the constellation. In fact,\nthe information conveyed\
    \ by the Sentinel-2 (S2) multi-resolution optical sensor depends on the spectral\n\
    reﬂectivity of the target illuminated by sunlight, while the backscattered signal\
    \ acquired by the\nSentinel-1 (S1) SAR sensor depends on both the target’s characteristics\
    \ and the illuminating signal.\nThe joint processing of optical and radar temporal\
    \ sequences offers the opportunity to extract the\ninformation of interest with\
    \ an accuracy that could not be achieved using only one of them. Of course,\n\
    with this potential comes the scientiﬁc challenge of how to exploit these complementary\
    \ pieces of\ninformation in the most effective way.\nIn this work, we focus on\
    \ the estimation of the normalized difference vegetation index (NDVI)\nin critical\
    \ weather conditions, fusing the information provided by temporal sequences of\
    \ S1 and S2\nimages. In fact, the typical processing pipelines of many land monitoring\
    \ applications rely, among other\nfeatures, on the NDVI for a single date or a\
    \ whole temporal series. Unfortunately, the NDVI, as well\nas other spectral features\
    \ are unavailable under cloudy weather conditions. The commonly-adopted\nsolution\
    \ consists of interpolating between temporally-adjacent images where the target\
    \ feature is\npresent. However, given the availability of weather-insensitive\
    \ SAR data of the scene, it makes sense\nto pursue fusion-based solutions, exploiting\
    \ SAR images that may be temporally very close to the\ntarget date, as it is well\
    \ known that radar images can provide valuable information on vegetation [1–4].\n\
    Even if this holds true, however, it is by no means obvious how to exploit such\
    \ dependency. To address\nthis problem, beneﬁting from the powerful learning capability\
    \ of deep learning methods, we designed\na three-layer convolutional neural network\
    \ (CNN), training it to account for both temporal and\ncross-sensor dependencies.\
    \ Note that the same approach, with minimal adaptations, can be extended\nto estimate\
    \ many other spectral indices, commonly used for water, soil, and so on. Therefore,\
    \ besides\nsolving the speciﬁc problem, we demonstrate the potential of deep learning\
    \ for data fusion in\nremote sensing.\nAccording to the taxonomy given in [5]\
    \ data fusion methods, i.e., processing dealing with data\nand information from\
    \ multiple sources to achieve improved information for decision making can be\n\
    grouped into three main categories:\n–\npixel-level: the pixel values of the sources\
    \ to be fused are jointly processed [6–9];\n–\nfeature-level: features like lines,\
    \ regions, keypoints, maps, and so on, are ﬁrst extracted\nindependently from\
    \ each source image and subsequently combined to produce higher-level\ncross-source\
    \ features, which may represent the desired output or be further processed [10–17];\n\
    –\ndecision-level: the high-level information extracted independently from each\
    \ source is combined\nto provide the ﬁnal outcome, for example using fuzzy logic\
    \ [18,19], decision trees [20],\nBayesian inference [21], Dempster–Shafer theory\
    \ [22], and so forth.\nIn the context of remote sensing, with reference to the\
    \ sources to be fused, fusion methods can be\nroughly gathered for the most part\
    \ into the following categories:\n–\nmulti-resolution: concerns a single sensor\
    \ with multiple resolution bands. One of the most\nfrequent applications is pansharpening\
    \ [6,23,24], although many other tasks can be solved under\na multi-resolution\
    \ paradigm, such as segmentation [25] or feature extraction [26], to mention\n\
    a few.\n–\nmulti-temporal: is one of the most investigated forms of fusion in\
    \ remote sensing due to the\nrich information content hidden in the temporal dimension.\
    \ In particular, it can be applied to\nstrictly time-related tasks, like prediction\
    \ [13], change detection [27–29] and co-registration [30],\nand general-purpose\
    \ tasks, like segmentation [7], despeckling [31] and feature extraction [32–34],\n\
    which do not necessarily need a joint processing of the temporal sequence, but\
    \ can beneﬁt from it.\n–\nmulti-sensor: is gaining an ever growing importance\
    \ due both to the recent deployment of many\nnew satellites and to the increasing\
    \ tendency of the community to share data. It represents also the\nmost challenging\
    \ case because of the several sources of mismatch (temporal, geometrical, spectral,\n\
    Remote Sens. 2018, 10, 236\n3 of 20\nradiometric) among the involved data. As\
    \ for other categories, a number of typical remote\nsensing problems can ﬁt this\
    \ paradigm, such as classiﬁcation [10,16,35–37], coregistration [15],\nchange\
    \ detection [38] and feature estimation [4,39–41].\n–\nmixed: the above cases\
    \ may also occur jointly, generating mixed situations. For example,\nhyperspectral\
    \ and multiresolution images can be fused to produce a spatial-spectral\nfull-resolution\
    \ datacube [9,42]. Likewise, low-resolution temporally-dense series can be fused\
    \ with\nhigh-resolution, but temporally sparse ones to simulate a temporal-spatial\
    \ full-resolution sequence\n[43]. The monitoring of forests [21], soil moisture\
    \ [2], environmental hazards [12] and other\nprocesses can be also carried out\
    \ effectively by fusing SAR and optical time series. Finally, works\nthat mix\
    \ all three aspects, resolution, time and sensor, can also be found in the literature\
    \ [11,22,44].\nTurning to multi-sensor SAR-optical fusion for the purpose of vegetation\
    \ monitoring, a number\nof contributions can be found in the literature [4,11,16,21,45].\
    \ In [11], ALOS POLSAR and Landsat\ntime-series were combined at the feature level\
    \ for forest mapping and monitoring. The same problem\nwas addressed in [21] through\
    \ a decision-level approach. In [45], the fusion of single-date S1 and\nsimulated\
    \ S2 was presented for the purpose of classiﬁcation. In [4], instead, RADARSAT-2\
    \ and\nLandsat-7/8 images were fused, by means of an artiﬁcial neural network,\
    \ to estimate soil moisture\nand leaf area index. The NDVI obtained from the Landsat\
    \ source was combined with different SAR\npolarization subsets for feeding ad\
    \ hoc artiﬁcial networks. A similar feature-level approach, based on\nSentinel\
    \ data, was followed in [16] for the purpose of land cover mapping. To this end,\
    \ the texture\nmaps extracted from the SAR image were combined with several indices\
    \ drawn from the optical bands.\nAlthough\nsome\nfusion\ntechniques\nhave\nbeen\n\
    proposed\nfor\nspatio-temporal\nNDVI\nsuper-resolution [43] or prediction [13],\
    \ they use exclusively optical data. None of these papers\nattempts to directly\
    \ estimate a pure multispectral feature, NDVI or the like, from SAR data. In most\n\
    cases, the fusion, occurring already at the feature level, is intended to provide\
    \ high-level information,\nlike the classiﬁcation or detection of some physical\
    \ item. Conversely, we can register some notable\nexamples of indices directly\
    \ related to physical items of interest, like soil moisture or the area leaf\n\
    index, which have been estimated by fusing SAR and optical data [4,39].\nIn this\
    \ work, we propose several CNN-based algorithms to estimate the NDVI through the\n\
    fusion of optical and SAR Sentinel data. With reference to a speciﬁc case study,\
    \ we acquired temporal\nsequences of S1 SAR data and S2 optical data, covering\
    \ the same time lapse, with the latter partially\ncovered by clouds. Both temporal\
    \ and cross-sensor (S1-S2) dependencies are used to obtain the\nmost effective\
    \ estimation protocol. From the experimental analysis, very interesting results\
    \ emerge.\nOn the one hand, when only optical data are used, CNN-based methods\
    \ outperform consistently the\nconventional temporal interpolators. On the other\
    \ hand, when also SAR data are considered, a further\nsigniﬁcant improvement of\
    \ performance is observed, despite the very different nature of the involved\n\
    signals. It is worth underlining that no peculiar property of the NDVI was exploited,\
    \ and therefore,\nthese results have a wider signiﬁcance, suggesting that other\
    \ image features can be better estimated by\ncross-sensor CNN-based fusion.\n\
    The rest of the paper is organized as follows. In Section 2, we present the dataset\
    \ and describe\nthe problem under investigation. In Section 3, the basics of the\
    \ CNN methodology are recalled.\nThen, the speciﬁc prediction architectures are\
    \ detailed in Section 4. In Section 5, we present fusion\nresults and related\
    \ numerical accuracy evaluation. Finally, a detailed discussion of the results\
    \ and\nfuture perspectives is given in Section 6, while conclusions are drawn\
    \ in Section 7.\n2. Dataset and Problem Statement\nThe objective of this work\
    \ is to propose and test a set of solutions to estimate a target optical\nfeature\
    \ at a given date from images acquired at adjacent dates, or even from the temporally-closest\n\
    SAR image. Such different solutions also reﬂect the different operating conditions\
    \ found in practice.\nThe main application is the reconstruction of a feature\
    \ of interest in a target image, which is available,\nRemote Sens. 2018, 10, 236\n\
    4 of 20\nbut partially or totally cloudy. However, one may also consider the case\
    \ in which the feature is built\nand used on a date for which no image is actually\
    \ available.\nIn this work, we focus on the estimation of the normalized difference\
    \ vegetation index, but it\nis straightforward to apply the same framework to\
    \ other optical features. With reference to Sentinel\nimages, the NDVI is obtained\
    \ at a 10-m spatial resolution by combining, pixel-by-pixel, two bands,\nnear\
    \ infrared (NIR, 8th band) and red (Red, 4th band), as:\nNDVI ≜ NIR − Red\nNIR\
    \ + Red ∈ [−1, 1]\n(1)\nThe area under study is located in the province of Tuy,\
    \ Burkina Faso, around the commune\nof Koumbia. This area is particularly representative\
    \ of West African semiarid agricultural landscapes,\nfor which the Sentinel missions\
    \ offer new opportunities in monitoring vegetation, notably in the\ncontext of\
    \ climate change adaptation and food security. The use of SAR data in conjunction\
    \ with\noptical images is particularly appropriate in these areas, since most\
    \ of the vegetation dynamics take\nplace during the rainy season, especially over\
    \ the cropland, as smallholder rainfed agriculture is\ndominant. This strongly\
    \ reduces the availability of usable optical images in the critical phase of\n\
    vegetation growth, due to the signiﬁcant cloud coverage [46] by which SAR data\
    \ are only loosely\naffected. The 5253 × 4797 pixels scene is monitored from 5\
    \ May–1 November 2016, which corresponds\nto a regular agricultural season in\
    \ the area.\nFigure 1 indicates the available S1 and S2 acquisitions in this period.\
    \ In the case of S2 images,\nthe bar height indicates the percentage of data that\
    \ are not cloudy. It is clear that some dates provide\nlittle or no information.\
    \ Note that, during the rainy season, the lack of sufﬁcient cloud-free optical\n\
    data may represent a major issue, preventing the extraction of spatio-temporal\
    \ optical-based features,\nlike time-series of vegetation, water or soil indices,\
    \ and so on. S1 images, instead, are always completely\navailable, as SAR data\
    \ are insensitive to meteorological conditions.\nmay-05\nmay-15\njun-04\naug-03\n\
    sep-02\noct-12\nnov-01\n100\ntime line\n% available data (cloud free)\nS1 - selected\n\
    S1 - discarded\nS2 - selected\nS2 - discarded\nFigure 1. Available S1 (black)\
    \ and S2 (green) images over the period of interest. The bar height indicates\n\
    the fraction of usable data. Solid bars mark selected images; boldface dates mark\
    \ test images.\nFor the purpose of training, validation and testing of the proposed\
    \ methods, we kept only\nS2 images that were cloud-free or such that the spatial\
    \ distribution of clouds did not prevent the\nselection of sufﬁciently large training\
    \ and test areas. For the selected S2 images (solid bars in Figure 1),\nthe corresponding\
    \ dates are indicated on the x-axis. Our dataset was then completed by including\
    \ also\nthe S1 images (solid bars), which are temporally closest to the selected\
    \ S2 counterparts. The general\nidea of the proposal is to use the closest cloud-free\
    \ S2 and S1 images to estimate the desired feature\nRemote Sens. 2018, 10, 236\n\
    5 of 20\non the target date of interest. Therefore, among the seven selected dates,\
    \ only the ﬁve inner ones are\nused as targets. Observe, also, that the resulting\
    \ temporal sampling is rather variable, with intervals\nranging from ten days\
    \ to a couple of months, allowing us to test our methods in different conditions.\n\
    To allow temporal analyses, we chose a test area, of a size of 470 × 450, which\
    \ is cloud-free\nin all the selected dates, hence with the available reference\
    \ ground-truth for any possible optical\nfeature. Figure 2 shows the RGB representation\
    \ of a complete image of the Koumbia dataset (3 August),\ntogether with a zoom\
    \ of the selected test area. Even after discarding the test area, a quite large\
    \ usable\narea remains, from which a sufﬁciently large number of small (33 × 33)\
    \ cloud-free patches is randomly\nextracted for training and validation.\n11°18ʹ0″N\n\
    11°9ʹ36″N\n11°1ʹ12″N\n3°48ʹ0″W\n3°48ʹ0″W\n3°39ʹ36″W\n3°39ʹ36″W\n3°31ʹ12″W\n3°31ʹ12″W\n\
    11°20ʹ28″N\n11°19ʹ23″N\n11°18ʹ18″N\n3°29ʹ33″W\n3°28ʹ21″W\n0\n1\n2\n3 Km\nFigure\
    \ 2. RGB representation of the 5253 × 4797 S2-Koumbia dataset (3 August 2016),\
    \ with a zoom on\nthe area selected for testing.\nFor this work, we used Sentinel-1\
    \ data acquired in interferometric wide swath (IW) mode, in the\nhigh-resolution\
    \ Ground Range Detected (GRD) format as provided by ESA. Such Level-1 products\
    \ are\ngenerally available for most data users and consist of focused SAR data\
    \ detected in magnitude, with a\nnative range by azimuth resolution estimated\
    \ as 20 × 22 meters and a 10 × 10 meter pixel spacing.\nA proper multi-looking\
    \ and ground range projection is applied to provide the ﬁnal GRD product at a\n\
    nominal 10 m spatial resolution. On our side, all images have been calibrated\
    \ (VH/VV intensities to\nsigma naught) and terrain corrected using ancillary data\
    \ and co-registered to provide a 10-m resolution,\nspatially-coherent time series,\
    \ using the ofﬁcial European Space Agency (ESA) Sentinel Application\nPlatform\
    \ (SNAP) software [47]. No optical/SAR co-registration has been performed, assuming\
    \ that the\nco-location precision provided by the independent orthorectiﬁcation\
    \ of each product is sufﬁcient for\nthe application. Sentinel-2 data are provided\
    \ by the French Pole Thématique Surfaces Continentales\n(THEIA) [48] and preprocessed\
    \ using the Multi-sensor Atmospheric Correction and Cloud Screening\n(MACCS) Level-2A\
    \ processor [49] developed at the French National Space Agency (CNES) to provide\n\
    surface reﬂectance products, as well as precise cloud masks.\nIn addition to the\
    \ Sentinel data, we assume the availability of two more features, the cloud masks\n\
    for each S2 image and a digital elevation model (DEM). Cloud masks are obviously\
    \ necessary to\nestablish when the prediction is needed and which adjacent dates\
    \ should be involved. The DEM is\na complementary feature that integrates the\
    \ information carried by SAR data and may be useful to\nimprove estimation. It\
    \ was gathered from the Shuttle Radar Topographic Mission (SRTM) 1 Arc-Second\n\
    Global, with 30-m resolution resampled at 10 m to match the spatial resolution\
    \ of Sentinel data.\nRemote Sens. 2018, 10, 236\n6 of 20\n3. Convolutional Neural\
    \ Networks\nBefore moving to the speciﬁc solutions for NDVI estimation, in this\
    \ section, we provide some\nbasic notions and terminology about convolutional\
    \ neural networks.\nIn the last few years, CNNs have been successfully applied\
    \ to many classical image processing\nproblems, such as denoising [50], super-resolution\
    \ [51], pansharpening [8,24], segmentation [52],\nobject detection [53,54], change\
    \ detection [27] and classiﬁcation [17,55–57]. The main strengths of\nCNNs are\
    \ (i) an extreme versatility that allows them to approximate any sort of linear\
    \ or non-linear\ntransformation, including scaling or hard thresholding; (ii)\
    \ no need to design handcrafted ﬁlters,\nreplaced by machine learning; (iii) high-speed\
    \ processing, thanks to parallel computing. On the\ndownside, for correct training,\
    \ CNNs require the availability of a large amount of data with the\nground-truth\
    \ (examples). In our speciﬁc case, data are not a problem, given the unlimited\
    \ quantity of\ncloud-free Sentinel-2 time-series that can be downloaded from the\
    \ web repositories. However, using\nlarge datasets has a cost in terms of complexity\
    \ and may lead to unreasonably long training times.\nUsually, a CNN is a chain\
    \ (parallels, loops or other combinations are also possible) of different layers,\n\
    like convolution, nonlinearities, pooling and deconvolution. For image processing\
    \ tasks in which the\ndesired output is an image at the same resolution of the\
    \ input, as in this work, only convolutional\nlayers interleaved with nonlinear\
    \ activations are typically employed.\nThe generic l-th convolutional layer, with\
    \ N-band input x(l), yields an M-band stack z(l) computed as:\nz(l) = w(l) ∗ x(l)\
    \ + b(l),\nwhose m-th component can be written in terms of ordinary 2D convolutions:\n\
    z(l)(m, ·, ·) =\nN\n∑\nn=1\nw(l)(m, n, ·, ·) ∗ x(l)(n, ·, ·) + b(l)(m).\nThe tensor\
    \ w is a set of M convolutional N × (K × K) kernels, with a K × K spatial support\n\
    (receptive ﬁeld), while b is an M-vector bias. These parameters, compactly, Φl\
    \ ≜\n\x10\nw(l), b(l)\x11\n, are\nlearned during the training phase. If the convolution\
    \ is followed by a pointwise activation function\ngl(·), then the overall layer\
    \ output is given by:\ny(l) = gl(z(l)) = gl(w(l) ∗ x(l) + b(l)) ≜ fl(x(l), Φl).\n\
    (2)\nDue to the good convergence properties it ensures [55], the rectiﬁed linear\
    \ unit (ReLU), deﬁned as\ng(·) ≜ max(0, ·), is a typical activation function of\
    \ choice for input or hidden layers.\nAssuming a simple L-layer cascade architecture,\
    \ the overall processing will be:\nf (x, Φ) = fL( fL−1(. . . f1(x, Φ1), . . .\
    \ , ΦL−1), ΦL),\n(3)\nwhere Φ ≜ (Φ1, . . . , ΦL) is the whole set of parameters\
    \ to learn. In this chain, each layer l provides\na set of so-called feature maps,\
    \ y(l), which activate on local cues in the early stages (small l), to become\n\
    more and more representative of abstract and global phenomena in subsequent ones\
    \ (large l). In this\nwork, all proposed solutions are based on a simple three-layer\
    \ architecture, and differ only in the input\nlayer, as different combinations\
    \ of input bands are considered.\nOnce the architecture has been chosen, its parameters\
    \ are learned by means of some optimization\nstrategy. An example is the stochastic\
    \ gradient descent (SGD) algorithm, specifying the cost to be\nminimized over\
    \ a properly-selected training dataset. Details on training will be given below\
    \ for our\nspeciﬁc solution.\nRemote Sens. 2018, 10, 236\n7 of 20\n4. Proposed\
    \ Prediction Architectures\nIn the following developments, with reference to a\
    \ given target S2 image acquired at time t,\nwe will consider the items deﬁned\
    \ below:\n•\nF: unknown feature (NDVI in this work) at time t;\n•\nF− and F+:\
    \ feature F at the previous and next useful times, respectively;\n•\nS ≜ (SVV,\
    \ SVH): double polarized SAR image closest to F (within ±5 days for our dataset);\n\
    •\nS− and S+: SAR images closest to F− and F+, respectively;\n•\nD: DEM.\nThe\
    \ several models considered here differ in the composition of the input stack\
    \ x, while the output\nis always the NDVI at the target date, that is y = F. Apart\
    \ from the input layer, the CNN architecture\nis always the same, depicted in\
    \ Figure 3, with hyper-parameters summarized in Table 1. The focus on\nthe choice\
    \ of this conﬁguration is postponed to the end of this section. This relatively\
    \ shallow CNN\nis characterized by a rather small number of weights (as CNNs go),\
    \ counted in Table 1, and hence\ncan be trained with a small amount of data. Moreover,\
    \ slightly different architectures have proven to\nachieve state-of-the-art performance\
    \ in closely-related applications, such as super-resolution [51] and\ndata fusion\
    \ [8,24].\nS− F−\nS\nS+ F+\nDEM\ninput\nstack\n|\n|\n|\n|\nmay-15\njun-04\naug-03\n\
    Sentinel-1\nSentinel-2\ny(1) = f1 (x, Φ1)\ny(2) = f2\n\0y(1), Φ2\n\x01\ny = f3\n\
    \0y(2), Φ3\n\x01\n48\n32\nhidden\nlayer\nhidden\nlayer\noutput\nlayer\nF\nFigure\
    \ 3. Proposed CNN architecture. The depicted input corresponds to the Optical-SAR+\
    \ case.\nOther cases use a reduced set of inputs.\nTable 1. CNN hyper-parameters:\
    \ # of features, M; kernel shape for each feature N×(K × K); # of\nparameters\
    \ to learn for each layer given by MNK2 (for w) + M (for b). In addition, in the\
    \ last row is\nshown an example of the feature layer shape for a sample input\
    \ x of size bx × (33 × 33).\nConvLayer1\ng1(·)\nConvLayer 2\ng2(·)\nConvLayer\
    \ 3\nM\n48\n32\n1\nN × (K × K)\nbx × (9 × 9)\nReLU\n48 ×(5 × 5)\nReLU\n32 × (5\
    \ × 5)\n# parameters\n~3888·bx\n~38,400\n~800\nShape of y(i)\n48 × (25 × 25)\n\
    32 × (21 × 21)\n1 × (17 × 17)\nThe number bx of input bands depends on the speciﬁc\
    \ solution and will be made explicit below.\nIn order to provide output values\
    \ falling in the compact interval [−1,1], as required by the NDVI\nsemantics (Equation\
    \ (1)), one can include a suitable nonlinear activation, like tanh(·), to complete\
    \ the\noutput layer. In such a case, it is customary to use a cross-entropy loss\
    \ for training. As an alternative,\none may remove the nonlinear output mapping\
    \ altogether and simply take the result of the convolution,\nwhich can be optimized\
    \ using, for example, a Ln-norm. Obviously, in this case, a hard clipping of\n\
    the output is still needed, but this additional transformation does not participate\
    \ in the error back\npropagation, hence it should be considered external to the\
    \ network. Through preliminary experiments,\nRemote Sens. 2018, 10, 236\n8 of\
    \ 20\nwe have found this latter solution more effective than the former, for our\
    \ task, and therefore, we train\nthe CNN considering a linear activation in the\
    \ last layer, g3(z(3)) = z(3).\nWe now describe brieﬂy the different solutions\
    \ considered here, which depend on the available\ninput data and the required\
    \ response time.\nConcerning data, we will consider estimation based on optical-only,\
    \ SAR-only and optical + SAR\ndata. When using SAR images, we will also test the\
    \ inclusion of the DEM, which may convey relevant\ninformation about them. Instead,\
    \ the DEM is useless, and hence neglected, when only optical data\nare used. All\
    \ these cases are of interest, for the following reasons.\n–\nThe optical-only\
    \ case allows for a direct comparison, with the same input data, between the\n\
    proposed CNN-based solution and the current baseline, which relies on temporal\
    \ linear\ninterpolation. Therefore, it will provide us with a measure of the net\
    \ performance gain guaranteed\nby deep learning over conventional processing.\n\
    –\nAlthough SAR and optical data provide complementary information, the occurrence\
    \ of a given\nphysical item, like water or vegetation, can be detected by means\
    \ of both scattering properties and\nspectral signatures. The analysis of the\
    \ SAR-only case will allow us to understand if signiﬁcant\ndependencies exist\
    \ between the NDVI and SAR images and if a reasonable quality can be achieved\n\
    even when only this source is used for estimation. To this aim, we do not count\
    \ on the temporal\ndependencies in this case, trying to estimate a S2 feature\
    \ from the closest S1 image only.\n–\nThe optical-SAR fusion is the case of highest\
    \ interest for us. Given the most complete set of relevant\ninput and an adequate\
    \ training set, the proposed CNN will synthesize expressive features and is\n\
    expected to provide a high-quality NDVI estimate.\nTurning to response time, except\
    \ for the SAR-only case, we will distinguish between “nearly”\ncausal estimation,\
    \ in which only data already available at time t, for example D, F−, S−, or shortly\n\
    later, can be used, and non-causal estimation, when the whole time series is supposed\
    \ to be available,\nand so future images (F+ and/or S+) are involved. In the former\
    \ case causality can be violated only by\nS and this happens only in two dates\
    \ out of ﬁve, 15 May (three-day delay) and 2 September (one-day\ndelay), in our\
    \ experiments.\n–\nCausal estimation is of interest whenever the data must be\
    \ used right away for the application\nof interest. This is the case, for example,\
    \ of early warning systems for food security. We will\ninclude here also the case\
    \ in which the closest SAR image becomes available after time t, since\nthe maximum\
    \ delay is at most ﬁve days. Hereinafter, we will refer to this “nearly” causal\
    \ case as\ncausal for short.\n–\nOn the other hand, in the absence of temporal\
    \ constraints, all relevant data should be taken into\naccount to obtain the best\
    \ possible quality, therefore using non-causal estimation.\nTable 2 summarizes\
    \ all these different solutions.\nTable 2. Proposed models. The naming reﬂects\
    \ the input stacking, explicated on the right. “SAR” refers\nto S1 images and\
    \ “Optical” to S2 products (F±). “+” marks the inclusion of the DEM. Moreover,\
    \ “C”\nstands for causal.\nInput Bands\nModel Name\nbx\nOptical\nSAR\nDEM\nSAR\n\
    2\nS\nSAR+\n3\nS\nD\nOptical/C\n1\nF−\nOptical-SAR/C\n5\nF−\nS−, S\nOptical-SAR+/C\n\
    6\nF−\nS−, S\nD\nOptical\n2\nF−, F+\nOptical-SAR\n8\nF−, F+\nS−, S, S+\nOptical-SAR+\n\
    9\nF−, F+\nS−, S, S+\nD\nRemote Sens. 2018, 10, 236\n9 of 20\nLearning\nIn order\
    \ to learn the network parameters, a sufﬁciently large training set, say T, of\
    \ input-output\nexamples t is needed:\nT ≜ {t1, . . . , tQ},\nt ≜ (x, yref)\n\
    In our speciﬁc case, x will be a sample of the concatenated images from which\
    \ we want to estimate\nthe target NDVI map, with yref the desired output. Of course,\
    \ all involved optical images must be\ncloud-free over the selected patches.\n\
    Formally, the objective of the training phase is to ﬁnd:\nΦ = arg min\nΦ\nJ (T,\
    \ Φ) ≜ arg min\nΦ\n1\nQ ∑\nt∈T\nL(t, Φ)\nwhere L(t, Φ) is a suitable loss function.\
    \ Several losses can be found in the literature, like Ln norms,\ncross-entropy\
    \ and negative log-likelihood. The choice depends on the domain of the output\
    \ and\naffects the convergence properties of the networks [58]. Our experiments\
    \ have shown the L1-norm\n(Equation (4)) to be more effective than other options\
    \ for training; therefore, we keep this choice, which\nproved effective also in\
    \ other generative problems [24]:\nL(t, Φ) ∝ || f (x, Φ) − yref||1.\n(4)\nAs for\
    \ minimization, the most widespread procedure, adopted also in this work, is the\
    \ SGD with\nmomentum [59]. The training set is partitioned into batches of samples,\
    \ T = {B1, . . . , BP}. At each\niteration, a new batch is used to estimate the\
    \ gradient and update parameters as:\nν(n+1) ← µν(n) + α∇ΦJ\n\x10\nBjn, Φ(n)\x11\
    \nΦ(n+1) ← Φ(n) − ν(n+1)\nA whole scan of the training set is called an epoch,\
    \ and training a deep network may require from\ndozens of epochs, for simpler\
    \ problems like handwritten character recognition [60], to thousands of\nepochs\
    \ for complex classiﬁcation tasks [55]. The accuracy and speed of training depend\
    \ on both the\ninitialization of Φ and the setting of hyperparameters like learning\
    \ rate α and momentum µ, with α\nbeing the most critical, impacting heavily on\
    \ stability and convergence time. In particular, we have\nfound experimentally\
    \ optimal values for these parameters, which are α = 0.5 × 10−3 and µ = 0.9.\n\
    For an effective training of the networks, a large cloud-free dataset is necessary,\
    \ with geophysical\nproperties as close as possible to those of the target data.\
    \ This is readily guaranteed whenever all\nimages involved in the process, for\
    \ example F−, F and F+, share a relatively large cloud-free area.\nPatches will\
    \ be extracted from this area to train the network, which, afterwards, will be\
    \ used to estimate\nF also on the clouded area, obtaining a complete coverage\
    \ at the target date.\nFor our relatively small networks (~7 × 104 weights to\
    \ learn in the worst case; see Table 1), a set\nof 19,000 patches is sufﬁcient\
    \ for accurate training, as already observed for other generative tasks\nlike\
    \ super-resolution [51] or pansharpening [8] addressed with CNNs of a similar\
    \ size. With our\npatch extraction process, this number requires an overall cloud-free\
    \ area of about 1000 × 1000 pixels,\nnamely about 4% of our 5253 × 4797 target\
    \ scene (Figure 2). If the unclouded regions are more\nscattered, this percentage\
    \ may somewhat grow, but remains always quite limited. Therefore, a perfectly\n\
    ﬁt training set will be available most of the times (always, in our experiments).\
    \ However, if the scene is\nalmost completely covered by clouds at the target\
    \ date, one may build a good training set by searching\nfor data that are spatially\
    \ and/or temporally close, characterized by similar landscape dynamics,\nor resorting\
    \ to data collected at other similar sites. This case will be discussed in more\
    \ detail with the\nhelp of a temporal transfer learning example in Section 6.\
    \ In the present case, instead, for each date,\na dataset composed of 15,200 33\
    \ × 33 examples for training, plus 3800 more for validation, was created\nRemote\
    \ Sens. 2018, 10, 236\n10 of 20\nby sampling the target scene with an eight-pixel\
    \ stride in both spatial directions, always skipping test\narea and cloudy regions.\
    \ Then, the whole collection was shufﬂed to avoid biases when creating the\n128-example\
    \ mini-batches used in the SGD algorithm.\nTo conclude this section, we present\
    \ in Figure 4 some preliminary results about the evolution\nof the loss computed\
    \ on the validation dataset during the training process for a sample proposed\n\
    architecture and for some deviations from it. Although the L1 loss (or mean absolute\
    \ error) has not\nbeen directly considered for the accuracy evaluation presented\
    \ in the next section, which refers to\nwidespread measures of quality, it is\
    \ strictly related to them and can provide a rough preview of the\nperformance.\
    \ For the sake of simplicity, we gather in Figure 4 only a subset of meaningful\
    \ orthogonal\nhyperparameter variations. The ﬁrst observation is that after 500\
    \ training epochs, all models are about\nto converge, and doubling such a number\
    \ would provide a negligible gain as tested experimentally.\nDecreasing the number\
    \ of layers w.r.t. the reference architecture implies a considerable performance\n\
    drop. On the other side, increasing the network complexity with an additional\
    \ layer does not bring\nany gain. The number of features is also a factor that\
    \ can impact on accuracy. Figure 4 reports the\ncases when the number of features\
    \ for the ﬁrst layer is changed from 48 (proposed) to either 32 or 64.\nIn this\
    \ case, however, the losses are very close to each other, with the proposed and\
    \ the 64-feature\ncase almost coincident at the end of the training. The last\
    \ two plots show the impact of the learning\nrate α, and again, the proposed setting\
    \ (5 × 10−3) is “optimal” if compared with neighboring choices\n(10−3 and 10−2).\
    \ It is also worth underlining that using an higher learning rate, e.g., 10−2,\
    \ one can\ninduce a steep decay in the early phase of training, which can be paid\
    \ with a premature convergence.\n0\n100\n200\n300\n400\n500\n5\n6\n7 ·10−2\nepochs\n\
    Mean Absolute Error (L1)\nProposed: 3; 48; 5·10−3\n↑ layers: 4\n↓ layers: 2\n\
    ↑ features: 64\n↓ features: 32\n↑ α: 10−2\n↓ α: 10−3\nFigure 4. Loss functions\
    \ for the validation dataset of 3 August. The proposed Optical-SAR model (with\n\
    3 layers, 48 features in the 1st layer, and α = 5 × 10−3) is compared to several\
    \ variants obtained by\nchanging one hyper-parameter at time.\nBesides accuracy,\
    \ complexity is also affected by architectural choices. For the same variants\n\
    compared in Figure 4, we report the average training time in Table 3, registered\
    \ using an NVIDIA GPU,\nGeForce GTX TITAN X. The test time is instead negligible\
    \ in comparison with that of training and is\ntherefore neglected. For all models,\
    \ the total cost for training is in the order of one hour. However,\nas expected,\
    \ increasing the number of network parameters adding layers or features impacts\
    \ the\ncomputational cost. Eventually, the proposed architecture is the result\
    \ of a tradeoff between accuracy\nand complexity.\nRemote Sens. 2018, 10, 236\n\
    11 of 20\nTable 3.\nTraining time in seconds for a single epoch and for the overall\
    \ training (500 epochs),\nfor different hyperparameter settings.\nProposed\n↑\
    \ Layers\n↓ Layers\n↑ Features\n↓ Features\n↑ α\n↓ α\nTime per epoch\n6.548\n\
    7.972\n4.520\n7.224\n5.918\n6.526\n6.529\nOverall\n3274\n3986\n2260\n3612\n2959\n\
    3263\n3264\n5. Experimental Results\nIn order to assess the accuracy of the proposed\
    \ solutions, we consider two reference methods for\ncomparison, a deterministic\
    \ linear interpolator (temporal gap-ﬁlling), which can be regarded as the\nbaseline,\
    \ and afﬁne regression, both in causal and non-causal conﬁgurations. Temporal\
    \ gap ﬁlling\nwas proposed in [46] in the context of the development of a national-scale\
    \ crop mapping processor\nbased on Sentinel-2 time series and implemented as a\
    \ remote module of the Orfeo Toolbox [61]. This is\na practical solution used\
    \ by analysts [46] to monitor vegetation processes through NDVI time-series.\n\
    Besides being simple, it is also more generally applicable and robust than higher-order\
    \ models, which\nrequire a larger number of points to interpolate and may overﬁt\
    \ the data. Since temporal gap ﬁlling is\nnon-causal, we add a further causal\
    \ interpolator for completeness, a simple zero-order hold. Of course,\ndeterministic\
    \ interpolation does not take into account the correlation between available and\
    \ target\ndata, which can help in performing a better estimate and can be easily\
    \ computed based on a tiny\ncloud-free fraction of the target image. Therefore,\
    \ for a fairer comparison, we consider as a further\nreference the afﬁne regressors,\
    \ both causal and non-causal, optimized using the least square method.\nIf suitable,\
    \ post-processing may be included for spatial regularization, both for the reference\
    \ and\nproposed methods. This option is not pursued here. In summary, the following\
    \ alternatives are\nconsidered for comparison:\nbF =\n\n\n\n\n\n\n\n\n\
    \n\n\n\n\nF−\nInterpolator/C\n∆+\n∆−+∆+ F− +\n∆−\n∆−+∆+ F+\nInterpolator\
    \ ([46])\na−F− + b\nRegressor/C\na−F− + a+F+ + b\nRegressor\nwhere ∆− and ∆+ are\
    \ the left and right temporal gaps, respectively, and a−, a+ and b satisfy:\n\
    (a−, (a+), b) = arg min E\nh\n∥ F − bF ∥2i\n.\nThe numerical assessment is carried\
    \ out on the basis of three commonly-used indicators,\nthe correlation coefﬁcient\
    \ (ρ), the peak signal-to-noise ratio (PSNR), and the structural similarity\n\
    measure (SSIM). These are gathered in Tables 4–6, respectively, for all proposed\
    \ and reference methods\nand for all dates. The target dates are shown in the\
    \ ﬁrst row, while the second row gives the temporal\ngaps (days) between the target\
    \ and the previous and next dates used for prediction, respectively.\nThe following\
    \ two lines show results for fully-cross-sensor, that is, SAR-only estimation,\
    \ while in the\nrest of the table, we group together all causal (top) and non-causal\
    \ (bottom) models, highlighting the\nbest performance in each group with bold\
    \ text. For a complementary subjective assessment by visual\ninspection some meaningful\
    \ sample results are shown in Figures 5 and 6.\nRemote Sens. 2018, 10, 236\n12\
    \ of 20\nTable 4. Correlation index, ρ ∈ [−1, 1].\n15 May\n4 June\n3 August\n\
    2 September\n12 October\nAverage\nGaps (before/after)\n10/20\n20/60\n60/30\n30/40\n\
    40/20\nCross-sensor\nSAR\n0.8243\n0.8161\n0.5407\n0.4219\n0.4561\n0.6118\nSAR+\n\
    0.8254\n0.7423\n0.3969\n0.4963\n0.6428\n0.6207\nCausal\nInterpolator/C\n0.9760\n\
    0.8925\n0.6566\n0.6704\n0.6098\n0.7611\nRegressor/C\n0.9760\n0.8925\n0.6566\n\
    0.6704\n0.6098\n0.7611\nOptical/C\n0.9811\n0.9407\n0.7245\n0.7280\n0.7302\n0.8209\n\
    Optical-SAR/C\n0.9797\n0.9432\n0.7716\n0.7880\n0.7546\n0.8474\nOptical-SAR+/C\n\
    0.9818\n0.9424\n0.7738\n0.7855\n0.7792\n0.8525\nNon-causal\nInterpolator\n0.9612\n\
    0.8915\n0.7643\n0.7288\n0.8838\n0.8459\nRegressor\n0.9708\n0.9004\n0.7618\n0.7294\n\
    0.8930\n0.8511\nOptical\n0.9814\n0.9524\n0.8334\n0.758\n0.9115\n0.8874\nOptical-SAR\n\
    0.9775\n0.9557\n0.8567\n0.8194\n0.9002\n0.9019\nOptical-SAR+\n0.9781\n0.9536\n\
    0.8550\n0.8220\n0.9289\n0.9075\nTable 5. Peak signal-to-noise ratio (PSNR) (dB).\n\
    15 May\n4 June\n3 August\n2 September\n12 October\nAverage\nGaps (before/after)\n\
    10/20\n20/60\n60/30\n30/40\n40/20\nCross-sensor\nSAR\n24.30\n19.52\n12.34\n17.30\n\
    10.70\n16.83\nSAR+\n23.49\n17.96\n14.78\n16.12\n19.01\n18.27\nCausal\nInterpolator/C\n\
    30.11\n19.48\n10.62\n17.70\n14.59\n18.50\nRegressor/C\n30.86\n22.60\n18.30\n20.39\n\
    20.02\n22.44\nOptical/C\n30.85\n24.92\n18.74\n21.01\n21.22\n23.35\nOptical-SAR/C\n\
    31.24\n25.07\n19.96\n21.56\n20.71\n23.71\nOptical-SAR+/C\n32.81\n24.90\n19.79\n\
    21.76\n21.91\n24.24\nNon-causal\nInterpolator\n27.91\n21.97\n19.12\n17.41\n23.61\n\
    22.00\nRegressor\n30.26\n22.86\n20.01\n21.14\n24.67\n23.79\nOptical\n32.61\n26.09\n\
    21.41\n21.53\n24.74\n25.28\nOptical-SAR\n29.72\n26.29\n22.01\n22.48\n23.89\n24.88\n\
    Optical-SAR+\n31.62\n25.65\n21.84\n22.30\n25.24\n25.33\nTable 6. Structural similarity\
    \ measure (SSIM) [−1,1].\n15 May\n4 June\n3 August\n2 September\n12 October\n\
    Average\nGaps (before/after)\n10/20\n20/60\n60/30\n30/40\n40/20\nCross-sensor\n\
    SAR\n0.5565\n0.4766\n0.3071\n0.3511\n0.2797\n0.3942\nSAR+\n0.5758\n0.4534\n0.3389\n\
    0.3601\n0.3808\n0.4218\nCausal\nInterpolator/C\n0.9128\n0.7115\n0.3481\n0.6597\n\
    0.6335\n0.6531\nRegressor/C\n0.9168\n0.7364\n0.4161\n0.6425\n0.6001\n0.6624\n\
    Optical/C\n0.9557\n0.8583\n0.6057\n0.7265\n0.6671\n0.7627\nOptical-SAR/C\n0.9543\n\
    0.8600\n0.6280\n0.7539\n0.6918\n0.7776\nOptical-SAR+/C\n0.9565\n0.8602\n0.6365\n\
    0.7545\n0.6989\n0.7813\nNon-causal\nInterpolator\n0.8801\n0.6798\n0.6696\n0.7177\n\
    0.8249\n0.7544\nRegressor\n0.9067\n0.7330\n0.6693\n0.7218\n0.8032\n0.7668\nOptical\n\
    0.9589\n0.8788\n0.7623\n0.7618\n0.8470\n0.8418\nOptical-SAR\n0.9541\n0.8835\n\
    0.7780\n0.7841\n0.8339\n0.8467\nOptical-SAR+\n0.9571\n0.8788\n0.7757\n0.7834\n\
    0.8559\n0.8502\nRemote Sens. 2018, 10, 236\n13 of 20\n0.8925 ←− ρ −→ 0.6566\n\
    F sequence\nF− (15 May)\nTarget GT: F (4 June)\nF+ (3 August)\nEstimated features\n\
    SAR+ (30 May)\nRegressor/C\nOptical/C\nOptical-SAR+/C\nInterpolator\nRegressor\n\
    Optical\nOptical-SAR+\nAbsolute error maps\nSAR+ (30 May)\nRegressor/C\nOptical/C\n\
    Optical-SAR+/C\nInterpolator\nRegressor\nOptical\nOptical-SAR+\nFigure 5. Sample\
    \ results for the 4 June target date. Top row: previous, target and next NDVI\
    \ maps of\nthe crop selected for testing. Second/third rows: NDVI maps estimated\
    \ by causal/non-causal methods.\nLast two rows: corresponding absolute error images.\n\
    Remote Sens. 2018, 10, 236\n14 of 20\n0.6566 ←− ρ −→ 0.6704\nF sequence\nF− (4\
    \ June)\nTarget GT: F (3 August)\nF+ (2 September)\nEstimated features\nSAR+ (29\
    \ July)\nRegressor/C\nOptical/C\nOptical-SAR+/C\nInterpolator\nRegressor\nOptical\n\
    Optical-SAR+\nAbsolute error maps\nSAR+ (29 July)\nRegressor/C\nOptical/C\nOptical-SAR+/C\n\
    Interpolator\nRegressor\nOptical\nOptical-SAR+\nFigure 6. Sample results for the\
    \ 3 August target date. Top row: previous, target and next NDVI maps of\nthe crop\
    \ selected for testing. Second/third rows: NDVI maps estimated by causal/non-causal\
    \ methods.\nLast two rows: corresponding absolute error images.\n6. Discussion\
    \ and Future Perspective\nIn this section, we will discuss the accuracy of the\
    \ proposed methods both objectively, through\nthe numerical results gathered in\
    \ Tables 4–6, and subjectively by visually inspecting Figures 5 and 6.\nThen,\
    \ we conclude the section discussing critical conditions when training data cannot\
    \ be retrieved\nfrom the target.\nLet us start with the numerical evaluation focusing\
    \ for the time being on the ρ Table 4 and in\nparticular on the last column with\
    \ average values, which accounts well for the main trends. First of\nRemote Sens.\
    \ 2018, 10, 236\n15 of 20\nall, the fully-cross-sensor solutions, based on only-SAR\
    \ or SAR + DEM data, respectively, are not\ncompetitive with methods exploiting\
    \ optical data, with a correlation index barely exceeding 0.6.\nNonetheless, they\
    \ allow one to obtain a rough estimate of the NDVI in the absence of optical coverage,\n\
    proving that even a pure spectral feature can be inferred from SAR images, thanks\
    \ to the dependencies\nexisting between the geometrical and spectral properties\
    \ of the scene. Moreover, SAR images provide\ninformation on the target, which\
    \ is not available in optical images, and complementary to it. Hence,\ntheir inclusion\
    \ can help with boosting the performance of methods relying on optical data.\n\
    Turning to the latter, we observe, as expected, that non-causal models largely\
    \ outperform the\ncorresponding causal counterparts. As an example, for the baseline\
    \ interpolator, ρ grows from\n0.761 (causal) to 0.846 (non-causal), showing that\
    \ the constraint of near real-time processing has\na severe impact on estimation\
    \ quality.\nHowever, even with the constraint of causality, most of this gap can\
    \ be ﬁlled by resorting to\nCNN-based methods. By using the very same data for\
    \ prediction, that is, only F−, the optical/C\nmodel reaches already ρ = 0.821.\
    \ This grows to 0.847 (like the non-causal interpolator) when also\nSAR data are\
    \ used and to 0.852 when also the DEM is included. Therefore, both the use CNN-based\n\
    estimation and the inclusion of SAR data guarantee a clear improvement. On the\
    \ contrary, using\na simple statistical regressor is of little or no help (causal\
    \ interpolator and regressor behave equally\nw.r.t. ρ by deﬁnition). Looking at\
    \ the individual dates, a clear dependence on the time gaps emerges.\nFor the\
    \ causal baseline, in particular, the ρ varies wildly, from 0.610–0.976. Indeed,\
    \ when the previous\nimage is temporally close to the target, like for 15 May,\
    \ and hence strongly correlated with it, even this\ntrivial method provides a\
    \ very good estimation, and more sophisticated methods cannot give much of\nan\
    \ improvement. However, things change radically when the previous available image\
    \ is acquired\nlong before the target, like for the 3 August or 12 October dates.\
    \ In these cases, the baseline does\nnot provide acceptable estimates anymore,\
    \ and CNN-based methods give a large performance gain,\nensuring a ρ always close\
    \ to 0.8 even in the worst cases.\nMoving now to non-causal estimation, we observe\
    \ a similar trend. Both reference methods\nare signiﬁcantly outperformed by the\
    \ CNN-based solutions working on the same data, and further\nimprovements are\
    \ obtained by including SAR and DEM. The overall average gain, from 0.851–0.907,\n\
    is not as large as before, since we start from a much better baseline, but still\
    \ quite signiﬁcant. Examining\nthe individual dates, similar considerations as\
    \ before arise, with the difference that now, two time gaps\nmust be taken into\
    \ account, with previous and next images. As expected, the CNN-based methods\n\
    provide the largest improvements when both gaps are rather large, that is, 30\
    \ days or more, like for the\n3 August and 2 September images.\nThe very same\
    \ trends outlined for the ρ are observed also with reference to the PSNR and SSIM\n\
    data, shown in Tables 5 and 6. Note that, unlike ρ and SSIM, the PSNR is quite\
    \ sensitive to biases on\nthe mean, which is why, in this case, the statistical\
    \ afﬁne regressor provides signiﬁcant gains over the\nlinear interpolator. In\
    \ any case, the best performance is always obtained using CNN-based methods\n\
    relying on both optical and SAR data, with large improvements with respect to\
    \ the reference methods.\nFurther insight into the behavior of the compared methods\
    \ can be gained by visual inspection of\nsome sample results. To this end, we\
    \ consider two target dates, 4 June and 3 August, characterized by\nsigniﬁcant\
    \ temporal changes in spectral features with respect to the closest available\
    \ dates. In the ﬁrst\ncase, a high correlation exists with the previous date ρ\
    \ = 0.8925, but not with the next ρ = 0.6566.\nIn the second, both correlation\
    \ indexes are quite low, 0.6566 and 0.6704, respectively. These changes\ncan be\
    \ easily appreciated in the images, shown in the top row of Figures 5 and 6, respectively.\
    \ In both\nﬁgures, the results of most of the methods described before are reported,\
    \ omitting less informative\ncases for the sake of clarity. To allow easy interpretation\
    \ of results, images are organized for increasing\ncomplexity from left to right,\
    \ with causal and non-causal versions shown in the second and third row,\nrespectively.\
    \ As the only exception, the first column shows results for SAR+ and non-causal\
    \ interpolator.\nMoreover, in the last two rows, the corresponding absolute error\
    \ images are shown, suitably magnified,\nwith the same stretching and reverse\
    \ scale (white means no error) for better visibility.\nRemote Sens. 2018, 10,\
    \ 236\n16 of 20\nFor 4 June, the estimation task is much simpliﬁed by the availability\
    \ of the highly correlated\n15 May image. Since this precedes the target, causal\
    \ estimators work almost as well as non-causal ones.\nModerate gradual improvements\
    \ are observed going from left to right. Nonetheless, by comparing\nthe ﬁrst (interpolator)\
    \ and last (optical-SAR+) non-causal solutions, a signiﬁcant accumulated\nimprovement\
    \ can be perceived, which becomes obvious in the error images. In this case, the\
    \ SAR-only\nestimate is also quite good, and the joint use of optical and SAR\
    \ data (fourth column) provides\nsome improvements.\nFor the 3 August image, the\
    \ task is much harder; no good predictor images are available, especially\nthe\
    \ previous image, 60 days old. In these conditions, there is clear improvement\
    \ when going from\ncausal to non-causal methods, even more visible in the error\
    \ images. Likewise, the left-to-right\nimprovements are very clear, both in the\
    \ predicted images (compare for example the sharp estimate of\noptical-SAR+ with\
    \ the much smoother output of the regressor) and in the error images, which become\n\
    generally brighter (smaller errors) and have fewer black patches. In this case,\
    \ the SAR-only estimate is\ntoo noisy, while the joint solution (fourth column)\
    \ provides a sensible gain over the others.\nTable 7. Temporal transfer learning\
    \ results for model “Optical-SAR+”. The (i, j) table entry corresponds\nto the\
    \ accuracy (ρ) obtained on the j-th date (column) when training is carried out\
    \ on the i-th date (row).\n15 May\n4 June\n3 August\n2 September\n12 October\n\
    15 May\n0.9781\n0.9111\n0.5782\n0.4907\n0.6199\n4 June\n0.9542\n0.9536\n0.8461\n\
    0.6612\n0.5285\n3 August\n0.9055\n0.9661\n0.8550\n0.8602\n0.5728\n2 September\n\
    0.5535\n0.6892\n0.6748\n0.8220\n0.9387\n12 October\n0.3357\n0.5090\n0.3966\n0.8981\n\
    0.9289\nTo conclude this discussion, let us now focus on the learning-related\
    \ issues. In particular,\na fundamental question is how to proceed when no training\
    \ data can be collected from the target\nimage at a given time (fully cloudy condition).\
    \ To what extent we can use a machine learning model\ntrained elsewhere? This\
    \ is a key problem in machine learning and is very relevant for a number of\n\
    remote sensing applications, such as coregistration [62] or pansharpening [24].\
    \ In [62], the importance\nof selecting training data which are homogeneous with\
    \ the target has been underlined. In [24], it is\nshown that the performance of\
    \ a CNN can drop dramatically without a proper domain adaptation\nstrategy, and\
    \ the target-adaptive solution is proposed.\nTo gain insight into this critical\
    \ point, we beneﬁt from a simple test that gives an idea of the scale\nof the\
    \ problem. In particular, we have considered several training-test mismatches\
    \ by transferring\ntemporally the learned models. The accuracy assessed in terms\
    \ of the correlation index (similar results\nare obtained for PSNR and SSIM) for\
    \ all transfer combinations is shown in Table 7. The i-th row collects\nthe results\
    \ obtained on all dates by the model trained on the i-th date. Surprisingly, given\
    \ a target date,\nthe best model does not necessarily lie on the matrix diagonal,\
    \ as in three out of ﬁve cases, a model\ntransferred from a neighboring date outperforms\
    \ the model trained on the target date. More in general,\nwith one exception,\
    \ entry (2 September, 3 August), diagonal-adjacent values are relatively high,\
    \ while\nmoving away from diagonal (toward cross-season transfer), the accuracy\
    \ deteriorates progressively.\nIn other words, this table suggests that when weather\
    \ conditions are such that no training data can be\ncollected from the target,\
    \ one can resort to some extent to models trained in the same period of the year\n\
    as the spatio-temporal landscape dynamics are likely very similar. This means\
    \ also that one can refer\nfor training to acquisitions of previous years in similar\
    \ periods. It is also worth visually inspecting\nsome related estimates. In Figure\
    \ 7, for two sample target dates, we show the results obtained in\nnormal conditions\
    \ or by transferring the learning from different dates, the best (same season)\
    \ and the\nworst (cross-season) cases. Again it can be observed that models trained\
    \ within the season of the target\ncan work pretty well. On the contrary, although\
    \ preserving spatial details, when crossing the season,\nover- or under-estimate\
    \ phenomena can occur. In particular, if the model is trained in the rainy season\n\
    Remote Sens. 2018, 10, 236\n17 of 20\n(rich vegetation) and tested in the dry\
    \ season (poor vegetation), we get over-estimation, while in the\nopposite case,\
    \ we get under-estimation.\nGround-truth\nno transfer: ρ = 0.978\nbest transfer:\
    \ ρ = 0.954\nworst transfer: ρ = 0.336\n(15 May)\n(15 May)\n(4 June)\n(12 October)\n\
    Ground-truth\nno transfer: ρ = 0.822\nbest transfer: ρ = 0.898\nworst transfer:\
    \ ρ = 0.491\n(2 September)\n(2 September)\n(12 October)\n(15 May)\nFigure 7. Temporal\
    \ transfer learning tested on 15 May (top) and 2 September (bottom). From left\
    \ to\nright is the target F followed by estimates provided by the model optical-SAR+\
    \ trained on the target\ndate (no transfer) and on two alternative dates (best\
    \ and worst cases).\n7. Conclusions\nWe have proposed and analyzed CNN-based methods\
    \ for the estimation of spectral features when\noptical data are missing. Several\
    \ models have been considered, causal and non-causal, single-sensor\nand joint-sensor,\
    \ to take into account various situations of practical interest. Validation has\
    \ been\nconducted with reference to NDVI maps, using Sentinel-1 and Sentinel-2\
    \ time-series, but the proposed\nframework is quite general and can be readily\
    \ extended to the estimation of other spectral features.\nIn all cases, the proposed\
    \ methods outperform largely the conventional references, especially in the\n\
    presence of large temporal gaps. Besides proving the potential of deep learning\
    \ for remote sensing,\nexperiments have shown that SAR images can be used to obtain\
    \ a meaningful estimate of spectral\nindexes when other sources of information\
    \ are not available.\nSuch encouraging results suggest further investigation on\
    \ these topics. First of all, very deep\nCNN architectures should be tested, as\
    \ they proved extremely successful in other ﬁelds. However,\nthis requires the\
    \ creation of a large representative dataset for training. In addition, more advanced\n\
    deep learning solutions for generative problems should be considered, such as\
    \ the recently-proposed\ngenerative adversarial networks [63]. Finally, cross-sensor\
    \ estimation from SAR data is a stimulating\nresearch theme and certainly deserves\
    \ further study.\nSupplementary Materials: The software, developed in Python 2.7,\
    \ using Theano and Lasagne packages, will be\ndisclosed through our website http://www.grip.unina.it/\
    \ to ensure full reproducibility.\nAuthor Contributions: G.S. proposed the research\
    \ topic, wrote the paper and coordinated the activities. M.G. and\nA.M. have equally\
    \ contributed to developing and implementing the proposed solutions and validated\
    \ them\nexperimentally. R.G. provided and preprocessed the dataset and contributed\
    \ ideas from an application-oriented\nperspective.\nConﬂicts of Interest: The\
    \ authors declare no conﬂict of interest.\nRemote Sens. 2018, 10, 236\n18 of 20\n\
    References\n1.\nWu, S.T.; Sader, S.A. Multipolarization SAR data for surface feature\
    \ delineation and forest vegetation\ncharacterization. IEEE Trans. Geosci. Remote\
    \ Sens. 1987, GE-25, 67–76.\n2.\nMoran, M.S.; Hymer, D.C.; Qi, J.; Sano, E.E.\
    \ Soil moisture evaluation using multi-temporal synthetic aperture\nradar (SAR)\
    \ in semiarid rangeland. Agric. For. Meteorol. 2000, 105, 69–80.\n3.\nSano, E.E.;\
    \ Ferreira, L.G.; Huete, A.R. Synthetic Aperture Radar (L band) and Optical Vegetation\
    \ Indices for\nDiscriminating the Brazilian Savanna Physiognomies: A Comparative\
    \ Analysis. Earth Interact. 2005, 9, 1–15.\n4.\nBaghdadi, N.N.; Hajj, M.E.; Zribi,\
    \ M.; Fayad, I. Coupling SAR C-Band and Optical Data for Soil Moisture\nand Leaf\
    \ Area Index Retrieval Over Irrigated Grasslands. IEEE J. Sel. Top. Appl. Earth\
    \ Obs. Remote Sens.\n2016, 9, 1229–1243.\n5.\nPohl, C.; Genderen, J.L.V. Review\
    \ article Multisensor image fusion in remote sensing: Concepts, methods\nand applications.\
    \ Int. J. Remote Sens. 1998, 19, 823–854.\n6.\nAlparone, L.; Aiazzi, B.; Baronti,\
    \ S.; Garzelli, A.; Nencini, F.; Selva, M. Multispectral and panchromatic data\n\
    fusion assessment without reference. Photogramm. Eng. Remote Sens. 2008, 74, 193–200.\n\
    7.\nGaetano, R.; Amitrano, D.; Masi, G.; Poggi, G.; Ruello, G.; Verdoliva, L.;\
    \ Scarpa, G.\nExploration of\nMultitemporal COSMO-SkyMed Data via Interactive\
    \ Tree-Structured MRF Segmentation. IEEE J. Sel. Top.\nAppl. Earth Obs. Remote\
    \ Sens. 2014, 7, 2763–2775.\n8.\nMasi, G.; Cozzolino, D.; Verdoliva, L.; Scarpa,\
    \ G. Pansharpening by Convolutional Neural Networks.\nRemote Sens. 2016, 8, 594.\n\
    9.\nPalsson, F.; Sveinsson, J.R.; Ulfarsson, M.O.\nMultispectral and Hyperspectral\
    \ Image Fusion Using\na 3-D-Convolutional Neural Network. IEEE Geosci. Remote\
    \ Sens. Lett. 2017, 14, 639–643.\n10.\nGaetano, R.; Moser, G.; Poggi, G.; Scarpa,\
    \ G.; Serpico, S.B. Region-Based Classiﬁcation of Multisensor\nOptical-SAR Images.\
    \ In Proceedings of the IGARSS 2008 IEEE International Geoscience and Remote Sensing\n\
    Symposium, Boston, MA, USA, 6–11 July 2008; Volume 4, pp. 81–84.\n11.\nReiche,\
    \ J.; Souza, C.M.; Hoekman, D.H.; Verbesselt, J.; Persaud, H.; Herold, M. Feature\
    \ Level Fusion of\nMulti-Temporal ALOS PALSAR and Landsat Data for Mapping and\
    \ Monitoring of Tropical Deforestation\nand Forest Degradation. IEEE J. Sel. Top.\
    \ Appl. Earth Obs. Remote Sens. 2013, 6, 2159–2173.\n12.\nErrico, A.; Angelino,\
    \ C.V.; Cicala, L.; Persechino, G.; Ferrara, C.; Lega, M.; Vallario, A.; Parente,\
    \ C.; Masi, G.;\nGaetano, R.; et al. Detection of environmental hazards through\
    \ the feature-based fusion of optical and SAR\ndata: A case study in southern\
    \ Italy. Int. J. Remote Sens. 2015, 36, 3345–3367.\n13.\nDas, M.; Ghosh, S.K.\
    \ Deep-STEP: A Deep Learning Approach for Spatiotemporal Prediction of Remote\n\
    Sensing Data. IEEE Geosci. Remote Sens. Lett. 2016, 13, 1984–1988.\n14.\nSukawattanavijit,\
    \ C.; Chen, J.; Zhang, H. GA-SVM Algorithm for Improving Land-Cover Classiﬁcation\n\
    Using SAR and Optical Remote Sensing Data. IEEE Geosci. Remote Sens. Lett. 2017,\
    \ 14, 284–288.\n15.\nMa, W.; Wen, Z.; Wu, Y.; Jiao, L.; Gong, M.; Zheng, Y.; Liu,\
    \ L.\nRemote Sensing Image Registration\nWith Modiﬁed SIFT and Enhanced Feature\
    \ Matching. IEEE Geosci. Remote Sens. Lett. 2017, 14, 3–7.\n16.\nClerici, N.;\
    \ Calderón, C.A.V.; Posada, J.M. Fusion of Sentinel-1A and Sentinel-2A data for\
    \ land cover\nmapping: a case study in the lower Magdalena region, Colombia. J.\
    \ Maps 2017, 13, 718–726.\n17.\nJahan, F.; Awrangjeb, M. Pixel-Based Land Cover\
    \ Classiﬁcation by Fusing Hyperspectral and LIDAR Data.\nISPRS Int. Arch. Photogramm.\
    \ Remote Sens. Spat. Inf. Sci. 2017, 711–718.\n18.\nFauvel, M.; Chanussot, J.;\
    \ Benediktsson, J.A. Decision Fusion for the Classiﬁcation of Urban Remote Sensing\n\
    Images. IEEE Trans. Geosci. Remote Sens. 2006, 44, 2828–2838.\n19.\nMárquez, C.;\
    \ López, M.I.; Ruisánchez, I.; Callao, M.P. FT-Raman and NIR spectroscopy data\
    \ fusion strategy\nfor multivariate qualitative analysis of food fraud. Talanta\
    \ 2016, 161, 80–86.\n20.\nWaske, B.; Van der Linden, S. Classifying Multilevel\
    \ Imagery From SAR and Optical Sensors by Decision\nFusion. IEEE Trans. Geosci.\
    \ Remote Sens. 2008, 46, 1457–1466.\n21.\nReiche, J.; De Bruin, S.; Hoekman, D.;\
    \ Verbesselt, J.; Herold, M. A Bayesian approach to combine Landsat\nand ALOS\
    \ PALSAR time series for near real-time deforestation detection. Remote Sens.\
    \ 2015, 7, 4973–4996.\n22.\nDu, P.; Liu, S.; Xia, J.; Zhao, Y. Information fusion\
    \ techniques for change detection from multi-temporal\nremote sensing images.\
    \ Inf. Fusion 2013, 14, 19–27.\nRemote Sens. 2018, 10, 236\n19 of 20\n23.\nMasi,\
    \ G.; Cozzolino, D.; Verdoliva, L.; Scarpa, G.\nCNN-based Pansharpening of Multi-Resolution\n\
    Remote-Sensing Images.\nIn Proceedings of the Joint Urban Remote Sensing Event\
    \ 2017, Dubai,\nUnited Arab Emirates, 6–8 March 2017.\n24.\nScarpa,\nG.;\nVitale,\n\
    S.;\nCozzolino,\nD. Target-adaptive CNN-based pansharpening. ArXiv 2017,\narXiv:cs.CV/1709.06054.\n\
    25.\nGaetano, R.; Masi, G.; Poggi, G.; Verdoliva, L.; Scarpa, G. Marker controlled\
    \ watershed based segmentation\nof multi-resolution remote sensing images. IEEE\
    \ Trans. Geosci. Remote Sens. 2015, 53, 1987–3004.\n26.\nDu, Y.; Zhang, Y.; Ling,\
    \ F.; Wang, Q.; Li, W.; Li, X. Water Bodies’ Mapping from Sentinel-2 Imagery with\n\
    Modiﬁed Normalized Difference Water Index at 10-m Spatial Resolution Produced\
    \ by Sharpening the SWIR\nBand. Remote Sens. 2016, 8, 354.\n27.\nDing, A.; Zhang,\
    \ Q.; Zhou, X.; Dai, B. Automatic recognition of landslide based on CNN and texture\
    \ change\ndetection. In Proceedings of the 2016 31st Youth Academic Annual Conference\
    \ of Chinese Association of\nAutomation (YAC), Wuhan, China, 11–13 November 2016;\
    \ pp. 444–448.\n28.\nZanetti, M.; Bruzzone, L. A Theoretical Framework for Change\
    \ Detection Based on a Compound Multiclass\nStatistical Model of the Difference\
    \ Image. IEEE Trans. Geosci. Remote Sens. 2018, 56, 1129–1143.\n29.\nLiu, W.;\
    \ Yang, J.; Zhao, J.; Yang, L. A Novel Method of Unsupervised Change Detection\
    \ Using Multi-Temporal\nPolSAR Images. Remote Sens. 2017, 9, 1135.\n30.\nHan,\
    \ Y.; Bovolo, F.; Bruzzone, L.\nSegmentation-Based Fine Registration of Very High\
    \ Resolution\nMultitemporal Images. IEEE Trans. Geosci. Remote Sens. 2017, 55,\
    \ 2884–2897.\n31.\nChierchia, G.; Gheche, M.E.; Scarpa, G.; Verdoliva, L. Multitemporal\
    \ SAR Image Despeckling Based on\nBlock-Matching and Collaborative Filtering.\
    \ IEEE Trans. Geosci. Remote Sens. 2017, 55, 5467–5480.\n32.\nMaity, S.; Patnaik,\
    \ C.; Chakraborty, M.; Panigrahy, S. Analysis of temporal backscattering of cotton\
    \ crops\nusing a semiempirical model. IEEE Trans. Geosci. Remote Sens. 2004, 42,\
    \ 577–587.\n33.\nManninen, T.; Stenberg, P.; Rautiainen, M.; Voipio, P. Leaf Area\
    \ Index Estimation of Boreal and Subarctic\nForests Using VV/HH ENVISAT/ASAR Data\
    \ of Various Swaths.\nIEEE Trans. Geosci. Remote Sens.\n2013, 51, 3899–3909.\n\
    34.\nBorges, E.F.; Sano, E.E.; Medrado, E. Radiometric quality and performance\
    \ of TIMESAT for smoothing\nmoderate resolution imaging spectroradiometer enhanced\
    \ vegetation index time series from western Bahia\nState, Brazil. J. Appl. Remote\
    \ Sens. 2014, 8, doi:10.1117/1.JRS.8.083580.\n35.\nZhang, H.; Lin, H.; Li, Y.\
    \ Impacts of Feature Normalization on Optical and SAR Data Fusion for Land\nUse/Land\
    \ Cover Classiﬁcation. IEEE Geosci. Remote Sens. Lett. 2015, 12, 1061–1065.\n\
    36.\nMan, Q.; Dong, P.; Guo, H. Pixel-and feature-level fusion of hyperspectral\
    \ and lidar data for urban land-use\nclassiﬁcation. Int. J. Remote Sens. 2015,\
    \ 36, 1618–1644.\n37.\nLu, M.; Chen, B.; Liao, X.; Yue, T.; Yue, H.; Ren, S.;\
    \ Li, X.; Nie, Z.; Xu, B. Forest Types Classiﬁcation Based on\nMulti-Source Data\
    \ Fusion. Remote Sens. 2017, 9, 1153.\n38.\nPal, S.K.; Majumdar, T.J.; Bhattacharya,\
    \ A.K. ERS-2 SAR and IRS-1C LISS III data fusion: A PCA approach to\nimprove remote\
    \ sensing based geological interpretation. ISPRS J. Photogramm. Remote Sens. 2007,\
    \ 61, 281–297.\n39.\nBolten, J.D.; Lakshmi, V.; Njoku, E.G. Soil moisture retrieval\
    \ using the passive/active L- and S-band\nradar/radiometer. IEEE Trans. Geosci.\
    \ Remote Sens. 2003, 41, 2792–2801.\n40.\nSanti, E.; Paloscia, S.; Pettinato,\
    \ S.; Entekhabi, D.; Alemohammad, S.H.; Konings, A.G. Integration of passive\n\
    and active microwave data from SMAP, AMSR2 and Sentinel-1 for Soil Moisture monitoring.\
    \ In Proceedings\nof the 2016 IEEE International Geoscience and Remote Sensing\
    \ Symposium (IGARSS), Beijing, China,\n10–15 July 2016; pp. 5252–5255.\n41.\n\
    Addabbo, P.; Focareta, M.; Marcuccio, S.; Votto, C.; Ullo, S.L. Land cover classiﬁcation\
    \ and monitoring\nthrough multisensor image and data combination. In Proceedings\
    \ of the 2016 IEEE International Geoscience\nand Remote Sensing Symposium (IGARSS),\
    \ Beijing, China, 10–15 July 2016; pp. 902–905.\n42.\nJelének, J.; Kopaˇcková,\
    \ V.; Koucká, L.; Mišurec, J. Testing a Modiﬁed PCA-Based Sharpening Approach\
    \ for\nImage Fusion. Remote Sens. 2016, 8, 794.\n43.\nBisquert, M.; Bordogna,\
    \ G.; Boschetti, M.; Poncelet, P.; Teisseire, M. Soft Fusion of heterogeneous\
    \ image\ntime series. In Proceedings of the International Conference on Information\
    \ Processing and Management\nof Uncertainty in Knowledge-Based Systems, Montpellier,\
    \ France, 15–19 July 2014; Springer International\nPublishing AG: Cham, Switzerland,\
    \ 2014; pp. 67–76.\nRemote Sens. 2018, 10, 236\n20 of 20\n44.\nWang, Q.; Blackburn,\
    \ G.A.; Onojeghuo, A.O.; Dash, J.; Zhou, L.; Zhang, Y.; Atkinson, P.M. Fusion\
    \ of Landsat\n8 OLI and Sentinel-2 MSI Data. IEEE Trans. Geosci. Remote Sens.\
    \ 2017, 55, 3885–3899.\n45.\nHaas, J.; Ban, Y. Sentinel-1A SAR and sentinel-2A\
    \ MSI data fusion for urban ecosystem service mapping.\nRemote Sens. Appl. Soc.\
    \ Environ. 2017, 8, 41–53.\n46.\nInglada, J.; Arias, M.; Tardy, B.; Hagolle, O.;\
    \ Valero, S.; Morin, D.; Dedieu, G.; Sepulcre, G.; Bontemps, S.;\nDefourny, P.;\
    \ et al. Assessment of an Operational System for Crop Type Map Production Using\
    \ High\nTemporal and Spatial Resolution Satellite Optical Imagery. Remote Sens.\
    \ 2015, 7, 12356–12379.\n47.\nESA. ESA Sentinel Application Platform (SNAP) Software.\
    \ Available online: http://step.esa.int/main/\ntoolboxes/snap (accessed on 13\
    \ December 2017).\n48.\nTHEIA Home Page. Available online: http://www.theia-land.fr\
    \ (accessed on 13 December 2017).\n49.\nHagolle, O.; Huc, M.; Villa Pascual, D.;\
    \ Dedieu, G. A Multi-Temporal and Multi-Spectral Method to Estimate\nAerosol Optical\
    \ Thickness over Land, for the Atmospheric Correction of FormoSat-2, LandSat,\
    \ VENµS and\nSentinel-2 Images. Remote Sens. 2015, 7, 2668–2691.\n50.\nZhang,\
    \ K.; Zuo, W.; Chen, Y.; Meng, D.; Zhang, L. Beyond a Gaussian Denoiser: Residual\
    \ Learning of Deep\nCNN for Image Denoising. IEEE Trans. Image Process. 2017,\
    \ 26, 3142–3155.\n51.\nDong, C.; Loy, C.; He, K.; Tang, X. Image Super-Resolution\
    \ Using Deep Convolutional Networks. IEEE Trans.\nPattern Anal. Mach. Intell.\
    \ 2016, 38, 295–307.\n52.\nLong, J.; Shelhamer, E.; Darrell, T. Fully convolutional\
    \ networks for semantic segmentation. In Proceedings\nof the 2015 IEEE Conference\
    \ on Computer Vision and Pattern Recognition (CVPR), Boston, MA, USA,\n7–12 June\
    \ 2015; pp. 3431–3440.\n53.\nZhang, N.; Donahue, J.; Girshick, R.; Darrell, T.\
    \ Part-Based R-CNNs for Fine-Grained Category Detection.\nIn Proceedings of the\
    \ European Conference on Computer Vision, Zurich, Switzerland, 6–12 September\
    \ 2014.\n54.\nMaltezos, E.; Doulamis, N.; Doulamis, A.; Ioannidis, C. Deep convolutional\
    \ neural networks for building\nextraction from orthoimages and dense image matching\
    \ point clouds.\nJ. Appl. Remote Sens. 2017, 11,\ndoi:10.1117/1.JRS.11.042620.\n\
    55.\nKrizhevsky, A.; Sutskever, I.; Hinton, G.E.\nImagenet classiﬁcation with\
    \ deep convolutional neural\nnetworks. In Proceedings of the Advances in Neural\
    \ Information Processing Systems, Lake Tahoe, NV, USA,\n3–6 December 2012; pp.\
    \ 1106–1114.\n56.\nJiao, L.; Liang, M.; Chen, H.; Yang, S.; Liu, H.; Cao, X.\n\
    Deep Fully Convolutional Network-Based\nSpatial Distribution Prediction for Hyperspectral\
    \ Image Classiﬁcation. IEEE Trans. Geosci. Remote Sens.\n2017, 55, 5585–5599.\n\
    57.\nFotiadou, K.; Tsagkatakis, G.; Tsakalides, P. Deep Convolutional Neural Networks\
    \ for the Classiﬁcation of\nSnapshot Mosaic Hyperspectral Imagery. Electron. Imaging\
    \ 2017, 2017, 185–190.\n58.\nGoodfellow, I.; Bengio, Y.; Courville, A. Deep Learning;\
    \ MIT Press: Cambridge, MA, USA, 2016. Available\nonline: http://www.deeplearningbook.org\
    \ (accessed on 13 December 2017).\n59.\nSutskever, I.; Martens, J.; Dahl, G.E.;\
    \ Hinton, G.E. On the importance of initialization and momentum in\ndeep learning.\
    \ In Proceedings of the 30th International Conference on Machine Learning, Atlanta,\
    \ GA, USA,\n16–21 June 2013; Volume 28, pp. 1139–1147.\n60.\nCire¸san, D.C.; Gambardella,\
    \ L.M.; Giusti, A.; Schmidhuber, J. Deep neural networks segment neuronal\nmembranes\
    \ in electron microscopy images. In Proceedings of Advances in Neural Information\
    \ Processing\nSystems 25 (NIPS 2012); Lake Tahoe, Nevada, USA, 3–8 December 2012;\
    \ pp. 2852–2860.\n61.\nOrfeo Toolbox: Temporal Gap-Filling. Available online:\
    \ http://tully.ups-tlse.fr/jordi/temporalgapﬁlling\n(accessed on 13 December 2017).\n\
    62.\nZhang, H.; Huang, B. Support Vector Regression-Based Downscaling for Intercalibration\
    \ of Multiresolution\nSatellite Images. IEEE Trans. Geosci. Remote Sens. 2013,\
    \ 51, 1114–1123.\n63.\nGoodfellow, I.; Pouget-Abadie, J.; Mirza, M.; Xu, B.; Warde-Farley,\
    \ D.; Ozair, S.; Courville, A.; Bengio, Y.\nGenerative Adversarial Nets. In Proceedings\
    \ of the Advances in Neural Information Processing Systems 27\n(NIPS 2014); Montréal,\
    \ Canada, 8–13 December 2014; pp. 2672–2680.\nc⃝ 2018 by the authors. Licensee\
    \ MDPI, Basel, Switzerland. This article is an open access\narticle distributed\
    \ under the terms and conditions of the Creative Commons Attribution\n(CC BY)\
    \ license (http://creativecommons.org/licenses/by/4.0/).\n"
  inline_citation: '>'
  journal: Remote sensing (Basel)
  limitations: '>'
  pdf_link: https://www.mdpi.com/2072-4292/10/2/236/pdf?version=1518006760
  publication_year: 2018
  relevance_score1: 0
  relevance_score2: 0
  title: A CNN-Based Fusion Method for Feature Extraction from Sentinel Data
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1155/2016/3954573
  analysis: '>'
  authors:
  - Fang Ye
  - Jie Chen
  - Yibing Li
  - Jian Kang
  citation_count: 44
  full_citation: '>'
  full_text: ">\nResearch Article\nDecision-Making Algorithm for Multisensor Fusion\
    \ Based on\nGrey Relation and DS Evidence Theory\nFang Ye, Jie Chen, Yibing Li,\
    \ and Jian Kang\nCollege of Information and Communication Engineering, Harbin\
    \ Engineering University, Harbin 150001, China\nCorrespondence should be addressed\
    \ to Yibing Li; liyibing0920@sina.cn\nReceived 12 May 2016; Accepted 22 September\
    \ 2016\nAcademic Editor: Biswajeet Pradhan\nCopyright © 2016 Fang Ye et al. This\
    \ is an open access article distributed under the Creative Commons Attribution\
    \ License, which\npermits unrestricted use, distribution, and reproduction in\
    \ any medium, provided the original work is properly cited.\nDecision-making algorithm,\
    \ as the key technology for uncertain data fusion, is the core to obtain reasonable\
    \ multisensor\ninformation fusion results. DS evidence theory is a typical and\
    \ widely applicable decision-making method. However, DS evidence\ntheory makes\
    \ decisions without considering the sensors’ difference, which may lead to illogical\
    \ results. In this paper, we present\na novel decision-making algorithm for uncertain\
    \ fusion based on grey relation and DS evidence theory. The proposed algorithm\n\
    comprehensively takes consideration of sensor’s credibility and evidence’s overall\
    \ discriminability, which can solve the uncertainty\nproblems caused by inconsistence\
    \ of sensors themselves and complexity of monitoring environment and simultaneously\
    \ ensure the\nvalidity and accuracy of fusion results. The innovative decision-making\
    \ algorithm firstly obtains the sensor’s credibility through the\nintroduction\
    \ of grey relation theory and then defines two impact factors as sensor’s credibility\
    \ and evidence’s overall discriminability\naccording to the focal element analyses\
    \ and evidence’s distance analysis, respectively; after that, it uses the impact\
    \ factors to modify\nthe evidences and finally gets more reasonable and effective\
    \ results through DS combination rule. Simulation results and analyses\ndemonstrate\
    \ that the proposed algorithm can overcome the trouble caused by large evidence\
    \ conflict and one-vote veto, which\nindicates that it can improve the ability\
    \ of target judgment and enhance precision of uncertain data fusion. Thus the\
    \ novel decision-\nmaking method has a certain application value.\n1. Introduction\n\
    In practical applications, single sensor is difficult to meet\nthe requirements\
    \ like target accuracy and identification\nperformance. Thus, there is a broad\
    \ application of decision-\nmaking algorithm on data fusion about target’s attributes,\n\
    characteristics, and types through comprehensive processing\nof information obtained\
    \ from multisensor. Currently, data\ndecision-making technology [1–3] based on\
    \ multisensor is\nhighly valued by scholars at home and abroad. In addition,\n\
    a lot of theorems and algorithms emerge in the area of\ndata decision-making.\
    \ However, due to constraints on the\nattributes as well as the types of data,\
    \ there is still no unified\ntheoretical framework or unique algorithm for classification\n\
    issue of multisensor data decision-making.\nFor multisensor decision-making field,\
    \ the traditional\nalgorithms are statistical method [4], empirical reasoning\
    \ [5],\nvoting method [6], Bayesian inference [7], template method\n[5], and adaptive\
    \ neural network [8], among others. These\ntypical methods all can settle the\
    \ decision fusion of multisen-\nsor information to some extent, whereas they all\
    \ have some\ndefects. Statistical method, empirical reasoning, and voting\nmethod\
    \ are too simple to achieve the reliable decision results\nfor multisensor information\
    \ fusion. Bayesian inference needs\nthe prior knowledge of environment to finish\
    \ the reasoning,\nwhich cannot be guaranteed in actual applications. And\ntemplate\
    \ method would waste time and energy of system\nwhen selecting the suitable template\
    \ according to certain\nrules. Although adaptive neural network can fulfill a\
    \ reason-\nable decision fusion, it is usually not adopted in practical\napplications\
    \ because of its large computation complexity. DS\nevidence theory [9, 10] is\
    \ favored for its ability of dealing with\nuncertainty, integration of measurement\
    \ information, and\nreasonable theoretical derivation. Thus, DS evidence theory\n\
    has become the mainstream method in multisensor decision-\nmaking field.\nAs a\
    \ wildly used decision-making algorithm for uncertain\ndata fusion, DS evidence\
    \ theory is able to deal with the uncer-\ntainty and imprecision of multisensor\
    \ information fusion.\nHindawi Publishing Corporation\nJournal of Sensors\nVolume\
    \ 2016, Article ID 3954573, 11 pages\nhttp://dx.doi.org/10.1155/2016/3954573\n\
    2\nJournal of Sensors\nHence, DS evidence theory can properly handle the incon-\n\
    sistency of sensor conditions and complexity of monitoring\nenvironment. With\
    \ its introduction and perfection put for-\nward by Dempster and Shafer, respectively,\
    \ DS evidence the-\nory occupies a lot in the development of intelligent computing\n\
    and identification theory for multisensor information fusion.\nAlong with its\
    \ development, DS evidence theory has been\nwidely applied in various fields,\
    \ like pattern recognition [11],\ntarget identification [12], cognitive radio\
    \ network [13], fault\ndiagnosis [14], signal recognition [15], and decision-making\n\
    [16], among others. Although there are some problems of\nDS evidence theory itself,\
    \ these problems can be effectively\nsolved through rigorous theoretical derivation,\
    \ scientific\nimprovements, and combination with other methods. For\nexample,\
    \ a new entropy, named as Deng entropy, is proposed\nin [17] to handle the uncertain\
    \ measure of BPA, which is\nthe generalization of Shannon entropy. The new entropy\n\
    provides a promising way to measure the uncertainty of\nmultisensor fusion system.\
    \ Besides, Deng entropy is applied\nin [18] to realize the measurement of information\
    \ volume\nof the evidence. This improvement makes the application\nof DS evidence\
    \ theory with more validity and robustness.\nDue to limit space, the classic modified\
    \ methods [19–31]\nare exhibited in references and partially taken as compared\n\
    methods in Section 5.2.\nIn this paper, systematic research is implemented on\n\
    DS evidence theory, and the multisensor decision-making\nalgorithm is realized\
    \ by the combination of DS evidence\ntheory and grey relation analysis [32, 33].\
    \ The proposed\ndecision-making algorithm for uncertain data fusion firstly\n\
    utilizes sensors’ report generator to settle the acquisition\nprocessing of sensor’s\
    \ credibility by the introduction of grey\nrelation theory. Then, the sensor’s\
    \ credibility is consecutively\nadjusted by two different processes of consistency\
    \ and conflict\nanalysis in focal elements. At the same time, the novel method\n\
    defines the evidence’s overall discriminability according to\nthe concept of evidence’s\
    \ distance function. Finally, the\noriginal evidences are modified by two impact\
    \ factors as\nsensor’s credibility and evidence’s overall discriminability,\n\
    which can ensure getting more reasonable and effective\ndecision-making results\
    \ after evidences combine.\nThis paper is organized as follows. The theoretical\
    \ theo-\nrem and derivation of DS evidence theory and grey relation\ntheory are\
    \ briefly introduced in the next section. And the\nimplementation diagram and\
    \ flow chart of uncertain data\nfusion system are given in Section 3. Then, Section\
    \ 4 high-\nlights the implementation method and specific steps of the\nnew decision-making\
    \ algorithm for uncertain data fusion,\nand Section 5 presents the simulation\
    \ results and comparative\nanalyses. Concluding remarks are given in the last\
    \ section of\nthis paper.\n2. Theoretical Foundations\nDS evidence theory and\
    \ grey relation theory are separately\npresented in this section, which are the\
    \ foundations of the\nnovel decision-making algorithm in this paper.\n2.1. DS\
    \ Evidence Theory. DS evidence theory, also called\nDempster-Shafer theory, is\
    \ an effective data decision-making\nmethod to deal with the uncertainty of multisensor\
    \ infor-\nmation fusion system. Relative to probability theory [5], DS\nevidence\
    \ theory can settle imprecise data and has a more\nextensive application area.\
    \ Similar to Bayesian inference [7],\nDS evidence theory uses the prior probability\
    \ to represent the\nevidence interval of posterior probability, which can quantify\n\
    the credible degree and plausibility degree of propositions. DS\nevidence theory\
    \ is briefly comprised by the following four key\npoints.\n2.1.1. Frame of Discernment\
    \ and the Power Set. In DS model,\nthe frame of discernment (FoD) denoted by Θ\
    \ indicates a set\nof \U0001D441 mutually exclusive and exhaustive hypotheses,\
    \ which\nrepresents all interested propositions. And FoD is defined as\nthe form\
    \ of function set as\nΘ = {\U0001D43B1, \U0001D43B2, . . . , \U0001D43B\U0001D441\
    } = {\U0001D43B\U0001D456 | \U0001D456 = 1, 2, . . . , \U0001D441} ,\n(1)\nwhere\
    \ \U0001D43B\U0001D456 is the \U0001D456th hypothesis belonging to Θ and \U0001D441\
    \ is the\nnumber of hypotheses.\nOn the basis of FoD, we can derive 2Θ as the\
    \ power set,\nwhich is composed of 2\U0001D441 propositions of Θ (all subsets\
    \ of\nFoD).\n2Θ = {0, {\U0001D43B1} , {\U0001D43B2} , . . . , {\U0001D43B\U0001D441\
    } , {\U0001D43B1, \U0001D43B2} , {\U0001D43B1, \U0001D43B3} , . . . ,\n{\U0001D43B\
    1, \U0001D43B\U0001D441} , . . . , {\U0001D43B1, \U0001D43B2, . . . , \U0001D43B\
    \U0001D441}} ,\n(2)\nwhere 0 is the empty set, which belongs to any propositions.\n\
    2.1.2. Basic Probability Assignment. The basic probability\nassignment (BPA) is\
    \ a mass function \U0001D45A : 2Θ → [0, 1] defined\non 2Θ, which should satisfy\
    \ the following demands:\n\U0001D45A (0) = 0,\n∑\n\U0001D434⊆Θ\n\U0001D45A (\U0001D434\
    ) = 1,\n(3)\n∀\U0001D434 ∈ 2Θ. \U0001D45A(\U0001D434) is called the mass function\
    \ of proposition\n\U0001D434 that represents the basic belief degree and initial\
    \ support\ndegree strictly assigned to proposition \U0001D434 [17].\nDue to the\
    \ lack of further knowledge, \U0001D45A(\U0001D434) cannot be\nsubdivided. Any\
    \ proposition satisfying that \U0001D45A(\U0001D434) > 0 (\U0001D434 ∈\n2Θ) is\
    \ called the focal element, and the set of all focal elements\nis named as the\
    \ core of BPA.\n2.1.3. Belief Function and Plausibility Function. DS evidence\n\
    theory designates two uncertain measurements as the belief\nfunction (Bel) and\
    \ plausibility function (Pl). Similar to the\ndefinition of BPA, Bel and Pl can\
    \ be defined, respectively, as\nBel (\U0001D434) = ∑\n\U0001D435⊆\U0001D434\n\U0001D45A\
    \ (\U0001D435) ,\n(4)\nPl (\U0001D434) =\n∑\n\U0001D435∩\U0001D434 ̸=0\n\U0001D45A\
    \ (\U0001D435) ,\n(5)\nJournal of Sensors\n3\n0\n1\nBel(A)\nPl(A)\nUncertainty\n\
    interval\nSupporting\ninterval\nRejecting\ninterval\nPlausible\ninterval\nFigure\
    \ 1: Relationship diagram of Bel(\U0001D434) and Pl(\U0001D434).\n∀\U0001D434\
    \ ∈ 2Θ, where Bel(\U0001D434) is interpreted as the low probability\nof \U0001D434\
    , while Pl(\U0001D434) is interpreted as the upper probability of\n\U0001D434\
    . The relationship between Bel(\U0001D434) and Pl(\U0001D434) is derived as\n\
    follows:\nBel (\U0001D434) ≤ Pl (\U0001D434) ,\nPl (\U0001D434) = 1 − Bel (\U0001D434\
    ) ,\n(6)\nwhere \U0001D434 is the complement set of \U0001D434.\nAccording to\
    \ the relationship between Bel(\U0001D434) and Pl(\U0001D434),\nDS evidence theory\
    \ also divides the evidence interval into\nsupporting interval, uncertainty interval,\
    \ and rejecting inter-\nval, which are shown in Figure 1.\nThe interval [Bel(\U0001D434\
    ), Pl(\U0001D434)] is named the uncertainty\ninterval, which represents the uncertainty\
    \ and imprecision of\nmultisensor fusion system.\nThe concept of uncertainty interval\
    \ is similar to prob-\nability, but not entirely expressed as probability. The\
    \ inter-\nval makes the proposition possibly real; that is, it does\nnot directly\
    \ support or reject the proposition. That feature\ndemonstrates that DS evidence\
    \ theory needs weaker axiom\nthan probability theory and can represent the difference\n\
    between uncertainty and unknown of proposition [9]. Thus,\nDS evidence theory\
    \ is the generalization of probability theory\nand is an effective solution method\
    \ when the prior knowledge\nis absent.\n2.1.4. DS Combination Rule. DS evidence\
    \ theory provides a\nuseful evidence combination function. Suppose that there\n\
    are 2 independent and not completely conflict evidences that\nexist on the same\
    \ FoD in system; we can get a synthesis\nsupport degree for propositions by DS\
    \ combination rule. The\ncombination rule can be computed by the orthogonal sum\
    \ of\ntheir mass functions; that is,\n\U0001D45A (\U0001D434) = [\U0001D45A1 ⊕\
    \ \U0001D45A2] (\U0001D434)\n=\n1\n1 − \U0001D458\n∑\n\U0001D434\U0001D456∩\U0001D435\
    \U0001D457=\U0001D434\n\U0001D45A1 (\U0001D434\U0001D456) ⋅ \U0001D45A2 (\U0001D435\
    \U0001D457) ,\n(7)\n∀\U0001D434 ∈ 2Θ, where ⊕ represents the orthogonal sum operator.\
    \ \U0001D458\nis the global conflict factor, which demonstrates the conflict\n\
    degree between \U0001D45A1 and \U0001D45A2:\n\U0001D458 = 1 −\n∑\n\U0001D434\U0001D456\
    ∩\U0001D435\U0001D457=0\n\U0001D45A1 (\U0001D434\U0001D456) ⋅ \U0001D45A2 (\U0001D435\
    \U0001D457) .\n(8)\nIf \U0001D458 is close to 0, 2 evidences are on the verge\
    \ of\nconformity. While \U0001D458 is close to 1, 2 evidences are totally\nconflict.\
    \ The denominator 1/(1−\U0001D458) is the normalization factor\nwhich ensures\
    \ that (3) are contented.\nThe equations and properties of DS combination rules\n\
    based on 2 evidences are exhibited here; readers can deduce\nthe equations and\
    \ properties of multiple evidences’ synthesis\nwith similar principle.\nObviously,\
    \ the DS combination rule satisfies both com-\nmutative law and associate law.\n\
    \U0001D45A1 ⊕ \U0001D45A2 = \U0001D45A2 ⊕ \U0001D45A1,\n(\U0001D45A1 ⊕ \U0001D45A\
    2) ⊕ \U0001D45A3 = \U0001D45A1 ⊕ (\U0001D45A2 ⊕ \U0001D45A3) .\n(9)\n2.2. Grey\
    \ Relation Theory. Grey relation theory [34] is the\nquantity processing and ordering\
    \ procedure of systems with\nincomplete information or uncertain data. It can\
    \ be seen\nas a global analysis of system. Since appropriate reference\nis essential\
    \ to obtain reasonable sensor credibility result, a\ncertain sensor is used as\
    \ a comparative standard to determine\nthe credibility degree of multisensor [35].\n\
    2.2.1. Grey Relation Factor. Grey relation factor is the basis of\ngrey relation\
    \ analysis [32]. The space of Grey relation factors is\ndetermined by sequence\
    \ that has properties as comparability,\naccessibility, and extreme consistency.\n\
    Suppose that the sequences of system are \U0001D465\U0001D456 = [\U0001D465\U0001D456\
    (1),\n\U0001D465\U0001D456(2), . . . , \U0001D465\U0001D456(\U0001D45B)], \U0001D456\
    \ = 0, 1, 2, . . . , \U0001D45A, where \U0001D4650 is the reference\nsequence\
    \ and \U0001D465\U0001D456, \U0001D456 = 1, 2, . . . , \U0001D45A, is the comparison\
    \ sequence.\n\U0001D6FE(\U0001D4650(\U0001D458), \U0001D465\U0001D456(\U0001D458\
    )) represents the comparison measurement of \U0001D4650\nand \U0001D465\U0001D456\
    \ at the \U0001D458th point in grey relation factors’ space. Then we\ndefine the\
    \ grey relation factor of \U0001D465\U0001D456 as \U0001D6FE(\U0001D4650, \U0001D465\
    \U0001D456), which is the\naverage value of \U0001D6FE(\U0001D4650(\U0001D458\
    ), \U0001D465\U0001D456(\U0001D458)) at all points. Hence, the degree\nof grey\
    \ relation factor is defined as\n\U0001D6FE (\U0001D465\U0001D456, \U0001D465\
    0) = 1\n\U0001D45B\n\U0001D45B\n∑\n\U0001D458=1\n\U0001D6FE (\U0001D4650 (\U0001D458\
    ) , \U0001D465\U0001D456 (\U0001D458)) ,\n(10)\nwhere the comparison measurement\
    \ of \U0001D4650 and \U0001D465\U0001D456 is expressed\nas\n\U0001D6FE (\U0001D465\
    0 (\U0001D458) , \U0001D465\U0001D456 (\U0001D458))\n= min\U0001D456min\U0001D458\
    Δ 0\U0001D456 (\U0001D458) + \U0001D701max\U0001D456max\U0001D458Δ 0\U0001D456\
    \ (\U0001D458)\nΔ 0\U0001D456 (\U0001D458) + \U0001D701max\U0001D456max\U0001D458\
    Δ 0\U0001D456 (\U0001D458)\n,\n(11)\nwhere \U0001D701 ∈ [0, 1] is the resolution\
    \ index and Δ 0\U0001D456(\U0001D458) is the\ndiscriminative information.\n2.2.2.\
    \ Properties of Grey Relation Factor. It is apparent that the\ngrey relation factor\
    \ has the following elementary properties\n[34]:\n(1) Normativity:\n0 ≤ \U0001D6FE\
    \ (\U0001D4650, \U0001D465\U0001D456) ≤ 1,\n\U0001D6FE (\U0001D4650, \U0001D465\
    \U0001D456) = 1 ⇐⇒\n\U0001D4650 = \U0001D465\U0001D456,\n4\nJournal of Sensors\n\
    Sensor 1\nSensor 2\nSensor n\nBPA\ngenerator\nbased on\nmultisensor\nacquisition\n\
    Sensor’s\nreport\ngenerator\nbased on\ngray\nrelation\nModifying\nprocessing for\n\
    evidences based\non sensor\ncredibility and\nevidence’s\noverall\ndiscriminability\n\
    \ \nOverall weighted\nProportional factor\nof focal element\nEvidence’s\ndistance\n\
    analysis\nEvidence's overall discriminability D\nDS combination rule\nDecision-making\
    \ rule\nDecision\nresults\nMultisensor\ninformation\nFocal element\nanalyses\n\
    Evidences\nm = {m1, m2, . . ., mn}\nSensor credibility\nbased on\nTwo\nconsecutive\n\
    adjustments\nand\nS1\nS2\nSn\n...\nevidences m\U000F3C00\nModified\nAdjusted sensor\
    \ credibility W2\nW = {\U0001D7141, \U0001D7142, . . ., \U0001D714n}\n\U0001D714\
    i1, \U0001D714i2\n\U0001D714i1, \U0001D714i2\nfactor \U0001D714∗\n\U0001D714∗\n\
    Figure 2: Implementation diagram of uncertain data fusion system.\n\U0001D6FE\
    \ (\U0001D4650, \U0001D465\U0001D456) = 0 ⇐⇒\n\U0001D4650, \U0001D465\U0001D456\
    \ ∈ 0.\n(12)\n(2) Symmetry:\n\U0001D6FE (\U0001D4650, \U0001D465\U0001D456) =\
    \ \U0001D6FE (\U0001D465\U0001D456, \U0001D4650) .\n(13)\n(3) Accessibility:\n\
    Δ 0\U0001D456 (\U0001D458) ↓= \U0001D6FE (\U0001D4650 (\U0001D458) , \U0001D465\
    \U0001D456 (\U0001D458)) ↑ .\n(14)\nNamely, the smaller the discriminative information\
    \ Δ 0\U0001D456(\U0001D458)\nis, the bigger the comparison measurement \U0001D6FE\
    (\U0001D4650(\U0001D458), \U0001D465\U0001D456(\U0001D458)) is.\n3. The Implementation\
    \ Diagram of\nUncertain Data Fusion System\nAccording to the proposed decision-making\
    \ algorithm, the\nimplementation diagram of uncertain data fusion system is\n\
    defined in Figure 2.\nThe structure of the proposed decision-making algorithm\n\
    is marked by the rectangular block with imaginary lines in\nFigure 2. It is evident\
    \ that the new decision-making method\nis comprised of four parts. Thus, we can\
    \ get the flow chart in\nFigure 3.\nThe new method is realized by the following\
    \ four steps.\nStep 1. Obtain sensor’s credibility through sensors’ report\ngenerator\
    \ based on grey relation theory and consecu-\ntively adjust sensor’s credibility,\
    \ respectively, through overall\nweighted factor analysis and proportional factor\
    \ analysis.\nThen, filtrate the evidences according to sensor’s credibility’s\n\
    value.\nStep 2. Define evidence’s overall discriminability by evi-\ndences’ distance\
    \ analysis.\nStep 3. Modify the original evidences by two impact factors\nas sensor’s\
    \ credibility and evidence’s overall discriminability.\nStep 4. Combine the modified\
    \ evidences by proper DS\ncombination rule, and put the synthetic results into\
    \ decision-\nmaking rule to get the final decision results.\n4. The New Decision-Making\
    \ Method Based on\nGrey Relation and DS Evidence Theory\nAs described last section,\
    \ the particular procedures of the new\nmethod are presented. The novel decision-making\
    \ algorithm\ntakes two impact factors as sensor’s credibility and evidence’s\n\
    overall discriminability to modify the original evidences,\nrespectively, by focal\
    \ element analyses and evidences’ dis-\ntance analysis. The proposed algorithm\
    \ can settle system’s\nuncertainty caused by inconsistency of sensor conditions\
    \ and\ncomplexity of monitoring environment. Therefore, the new\nmethod is able\
    \ to guarantee the decision accuracy of data\nfusion.\n4.1. Two Consecutive Adjustments\
    \ of Sensor’s Credibility\n4.1.1. Generation of Sensor’s Credibility Based on\
    \ Grey Relation.\nIn this part, the concept of grey relation theory is utilized\
    \ to\nanalyze sensor’s credibility by generating sensor’s report.\nFor multisensor\
    \ information fusion system, let us denote\nthe exclusive and exhaustive FoD as\
    \ Θ = {\U0001D43B1, \U0001D43B2, . . . , \U0001D43B\U0001D45A},\nwhere \U0001D45A\
    \ is the number of hypotheses. Taking a sensor as\ntemplate, we can associate\
    \ the measurement information\nprovided by each sensor with the template sensor.\
    \ Then\nsensor’s credibility report is built.\nSuppose X0 = {X0(\U0001D457) |\
    \ \U0001D457 = 1, 2, . . . , \U0001D440} is the measure-\nment information of\
    \ the reference sensor, X\U0001D456 = {X\U0001D456(\U0001D457) | \U0001D457 =\n\
    1, 2, . . . , \U0001D440} is the measurement information of multisensor,\nwhere\
    \ the index \U0001D456 = 1, 2, . . . , \U0001D45B represents the \U0001D456th\
    \ sensor, \U0001D45B\nJournal of Sensors\n5\nMultisensor\ninformation\nBPA generator\
    \ based on \nmultisensor acquisition\nSensor’s report generator\nbased on gray\
    \ relation \nEvidences’\ndistance analysis\nFocal element \nanalyses\nOverall\
    \ weighted \nfactor analysis\nProportional \nfactor analysis\nEvidence’s overall\
    \ \ndiscriminability processing\nDecision \nresults\nNormalized evidence’s\noverall\
    \ discriminability D\nModifying processing for evidences based on sensor \ncredibility\
    \ and evidences’ overall discriminability\nDS combination rule\nDecision-making\
    \ rule\nDelete the \ncorresponding \nevidence\nNo\nYes\nEvidence \ndistance dij\n\
    Adjusted sensor\ncredibility W2\nW2 ≥ 0.5\nModified evidences m\U000F3C00\nEvidences\
    \ \nm = {m1, m2, . . ., mn}\nSensor credibility\nFirst adjustment \nbased on\n\
    Second adjustment \nbased on\nW = {\U0001D7141, \U0001D7142, . . ., \U0001D714\
    n}\n\U0001D714i1, \U0001D714i2\n\U0001D714i1, \U0001D714i2\n\U0001D714∗\n\U0001D714\
    ∗\nFigure 3: Flow chart of the novel decision-making algorithm.\nis the number\
    \ of targets, and \U0001D457 indicates the characteristic\ninformation of each\
    \ sensor. Under these assumptions, we can\nacquire sensor’s credibility with following\
    \ steps.\nFirstly, calculate the absolute difference of attributes as\n\U0001D714\
    \U0001D456 (\U0001D457) = \U000F5128\U000F5128\U000F5128\U000F5128X0 (\U0001D457\
    ) − X\U0001D456 (\U0001D457)\U000F5128\U000F5128\U000F5128\U000F5128 ,\n(15)\n\
    where | ⋅ | represents the absolute index and \U0001D714\U0001D456(\U0001D457\
    ) indicates\nthe absolute difference between X0 and X\U0001D456 in sensor’s \U0001D457\
    th\nattribute.\nSecondly, use the classic grey relation theory to calculate\n\
    relation coefficient of the \U0001D456th sensor.\n\U0001D709\U0001D456 (\U0001D457\
    ) =\nmin\U0001D456min\U0001D457\U0001D714\U0001D456 (\U0001D457) + \U0001D70C\
    \ max\U0001D456max\U0001D457\U0001D714\U0001D456 (\U0001D457)\n\U0001D714\U0001D456\
    \ (\U0001D457) + \U0001D70C max max\U0001D457\U0001D714\U0001D456 (\U0001D457\
    )\n,\n(16)\nwhere min\U0001D456min\U0001D457\U0001D714\U0001D456(\U0001D457) is\
    \ the minimum absolute difference and\nthe max\U0001D456max\U0001D457\U0001D714\
    \U0001D456(\U0001D457) is the maximum absolute difference. And\nthe resolution\
    \ index \U0001D70C is a constant as \U0001D70C = 0.5 in this paper.\nThen, obtain\
    \ the grey relation factor of the \U0001D456th sensor with\naverage processing.\n\
    \U0001D6FE\U0001D456 = 1\n\U0001D440\n\U0001D440\n∑\n\U0001D457=1\n\U0001D709\U0001D456\
    \ (\U0001D457) ⋅ \U0001D44E (\U0001D457) .\n(17)\nAt last, the sensor’s credibility\
    \ of the \U0001D456th sensor is shown\nas\n\U0001D714\U0001D456 =\n\U0001D6FE\U0001D456\
    \nmax\U0001D456 (\U0001D6FE\U0001D456).\n(18)\n6\nJournal of Sensors\n4.1.2. Two\
    \ Consecutive Adjustments of Sensor’s Credibility\nBased on Focal Element Analysis.\
    \ In order to guarantee the\nnormalization of the synthetic results, the sum of\
    \ all sensors’\ncredibility should be unit. However, due to the influence of\n\
    noise and imprecise device, the sum of sensors’ credibility is\nnot always unit.\
    \ To make the final decision for information\nfusion obtained from such sensors,\
    \ sensor’s credibility and\nthe information provided by sensors should be considered\n\
    simultaneously. In this section, we discuss how to combine\nsensor’s credibility\
    \ with focal element analyses to make the\nfinal decision.\nFrom what is mentioned\
    \ above, we suppose that Θ =\n{\U0001D45A\U0001D456(\U0001D43B\U0001D457) | \U0001D456\
    \ = 1, 2, . . . , \U0001D45B, \U0001D457 = 1, 2, . . . , \U0001D45A} is the FoD\
    \ of system,\nand \U0001D45A\U0001D456(\U0001D43B\U0001D457) are BPAs of focal\
    \ element. \U0001D456 is the number of\nsensors and \U0001D43B\U0001D457 represents\
    \ the \U0001D457th focal element.\nTo begin with, sensors’ credibility is obtained\
    \ through\ngrey relation algorithm as\n\U0001D44A = {\U0001D7141, \U0001D7142,\
    \ . . . , \U0001D714\U0001D45B} .\n(19)\nThe consecutive adjustments are based\
    \ on the compati-\nbility and conflict processing of focal elements.\nPrimarily,\
    \ the similarity and conflict between two evi-\ndences can be defined separately\
    \ as\n\U0001D438\U0001D456\U0001D457 =\n\U0001D45A\n∑\n\U0001D45D=\U0001D45E=1\n\
    \U0001D45A\U0001D456 (\U0001D439\U0001D45D) ⋅ \U0001D45A\U0001D457 (\U0001D439\
    \U0001D45E) ,\n\U0001D436\U0001D456\U0001D457 =\n\U0001D45A\n∑\n\U0001D45D=\U0001D45E\
    =1,\U0001D45D ̸=\U0001D45E\n\U0001D45A\U0001D456 (\U0001D439\U0001D45D) ⋅ \U0001D45A\
    \U0001D457 (\U0001D439\U0001D45E) .\n(20)\nWith the introduction of similarity\
    \ and conflict concepts,\nthe proportional conflict factor of the \U0001D456th\
    \ sensor can be\nconfirmed, which reflects the conflict level of the \U0001D456\
    th evidence.\n\U0001D458\U0001D456 =\n∑\U0001D45B\n\U0001D457=1,\U0001D457 ̸=\U0001D456\
    \ \U0001D436\U0001D456\U0001D457 − ∑\U0001D45B\n\U0001D457=1,\U0001D457 ̸=\U0001D456\
    \ \U0001D438\U0001D456\U0001D457\n∑\U0001D45B\n\U0001D457=1,\U0001D457 ̸=\U0001D456\
    \ \U0001D436\U0001D456\U0001D457 + ∑\U0001D45B\n\U0001D457=1,\U0001D457 ̸=\U0001D456\
    \ \U0001D438\U0001D456\U0001D457\n.\n(21)\nThen, the average conflict coefficient\
    \ \U0001D458∗ of all evidences\ncan be calculated as\n\U0001D458∗ = 1\n2 (1 +\
    \ 1\n\U0001D45B\n\U0001D45B\n∑\n\U0001D456=1\n\U0001D458\U0001D456) .\n(22)\n\
    After that, define the overall weight factor of all evidences\n\U0001D714∗ according\
    \ to \U0001D458∗.\n\U0001D714∗ = \U0001D45B ⋅ (\U0001D458∗)\n\U0001D6FC ⋅ min\
    \ {\U0001D714\U0001D456 | \U0001D456 = 1, 2, . . . , \U0001D45B} ,\n(23)\nwhere\
    \ \U0001D6FC is the regulatory factor, and the related analysis is\ndiscussed\
    \ in Section 5.1.\nFinally, the adjustments of sensors’ credibility are based\n\
    on different processing of \U0001D714∗. One is based on \U0001D714∗ itself, and\n\
    the other is based on two parts of \U0001D714∗ as the proportion of\ncompatible\
    \ focal elements and the proportion of conflict focal\nelements. Thus, the first\
    \ and the second adjustment for all\nsensors’ credibility are, respectively,\n\
    \U0001D44A1 = {\U0001D7141 − 1\n\U0001D45B\U0001D714∗, \U0001D7142 − 1\n\U0001D45B\
    \U0001D714∗, . . . , \U0001D714\U0001D45B − 1\n\U0001D45B\U0001D714∗} ,\n(24)\n\
    \U0001D44A2 = {\U0001D7141 − 1\n\U0001D45B\U0001D714∗ + \U0001D71411 + \U0001D714\
    12, \U0001D7142 − 1\n\U0001D45B\U0001D714∗ + \U0001D71421\n+ \U0001D71422, . .\
    \ . , \U0001D714\U0001D45B − 1\n\U0001D45B\U0001D714∗ + \U0001D714\U0001D45B1\
    \ + \U0001D714\U0001D45B2} ,\n(25)\nwhere \U0001D714\U0001D4561, \U0001D714\U0001D456\
    2 separately represent the proportion of com-\npatible focal elements and the\
    \ proportion of conflict focal\nelements, which are defined as\n\U0001D714\U0001D456\
    1 =\n\U0001D438\U0001D456\n∑\U0001D45B\n\U0001D456=1 \U0001D438\U0001D456\n\U0001D714\
    ∗\n1 ,\n\U0001D714\U0001D4562 =\n1/\U0001D436\U0001D456\n∑\U0001D45B\n\U0001D456\
    =1 (1/\U0001D436\U0001D456)\U0001D714∗\n2 .\n(26)\n\U0001D44A2 is the modified\
    \ sensors’ credibility, in which the\nconflict among evidences can be reflected.\
    \ When the sensor’s\ncredibility of certain evidence is very small, it indicates\
    \ that\nthis evidence has big conflict with all the other evidences.\nThus, a\
    \ threshold is indispensable for dealing with sensor’s\ncredibility which can\
    \ help system to delete those evidences\nwith low sensor’s credibility. In this\
    \ paper, the threshold is set\nto 0.5.\n4.2. Establishment of Evidence’s Overall\
    \ Discriminability Based\non Evidences’ Distance Processing. Firstly, the form\
    \ of evi-\ndences’ distance function is introduced, which can distin-\nguish the\
    \ evidences’ difference.\n\U0001D451 (m1, m2)\n= √ 1\n2 (⟨m1, m1⟩ + ⟨m2, m2⟩ −\
    \ 2 × ⟨m1, m2⟩)\n(27)\nin which\n⟨m1, m2⟩ =\n2\U0001D441\n∑\n\U0001D456=1\n2\U0001D441\
    \n∑\n\U0001D457=1\nm1 (\U0001D434\U0001D456) m2 (\U0001D434\U0001D457)\n\U000F5128\
    \U000F5128\U000F5128\U000F5128\U000F5128\U0001D434\U0001D456 ∩ \U0001D434\U0001D457\
    \n\U000F5128\U000F5128\U000F5128\U000F5128\U000F5128\n\U000F5128\U000F5128\U000F5128\
    \U000F5128\U000F5128\U0001D434\U0001D456 ∪ \U0001D434\U0001D457\n\U000F5128\U000F5128\
    \U000F5128\U000F5128\U000F5128\n,\n(28)\nwhere | ⋅ | indicates the number of focal\
    \ elements.\nAccording to the property that two evidences are more\nsimilar with\
    \ smaller distance function, we can define evi-\ndences’ overall discriminability\
    \ as\n\U0001D437\U0001D456 =\n\U0001D45A\n∑\n\U0001D457=1\n\U0001D451\U0001D456\
    \U0001D457.\n(29)\nAnd for the normalization feature of the synthetic results,\n\
    \U0001D437\U0001D456 should be normalized.\n\U0001D437\U0001D456 (norm) =\n((1/\U0001D437\
    \U0001D456) / ∑\U0001D45A\n\U0001D456=1 (1/\U0001D437\U0001D456))\n∑ ((1/\U0001D437\
    \U0001D456) / ∑\U0001D45A\n\U0001D456=1 (1/\U0001D437\U0001D456)).\n(30)\nIt can\
    \ be easily proved that \U0001D437\U0001D456 reflects the incompatibility\ndegree\
    \ between the \U0001D456th evidence and all the other evidences.\nThat is, the\
    \ larger \U0001D437\U0001D456 is, the less the support degree can be\nobtained,\
    \ and the worse the evidence’s credibility will be.\nJournal of Sensors\n7\n4.3.\
    \ Modification of Evidences. Taking sensor’s credibility\nand evidence’s overall\
    \ discriminability simultaneously into\nconsideration, the modified evidences\
    \ can be expressed as\n\U0001D45A\U0001D456 (\U0001D43B\U0001D457) = \U0001D44A\
    2 (\U0001D456) \U0001D45A\U0001D456 (\U0001D43B\U0001D457)\n+ \U0001D452−\U0001D458\
    \ (1 − \U0001D437\U0001D456) (\U0001D44A2 (\U0001D456) − \U0001D437\U0001D456\
    ) ,\n\U0001D45A\U0001D456 (Θ) = 1 −\n\U0001D45A\n∑\n\U0001D457=1\n\U0001D45A\U0001D456\
    \ (\U0001D43B\U0001D457) ,\n(31)\nwhere \U0001D458 is the global conflict factor.\n\
    The modification of evidences takes full advantage of\nsensor’s credibility and\
    \ real-time information provided by\nsensors to ameliorate evidences. If one modified\
    \ evidence\nhas zero focal element, we choose to delete the evidence\nand replace\
    \ it with the average of other evidences. This\nprocedure will not only guarantee\
    \ a reasonable fusion results,\nbut also effectively avoid the occurrence of one-vote\
    \ veto\nwhen evidences combine.\n4.4. Combination of Modified Evidences. Finally,\
    \ the modified\nevidence is integrated with the comprehensive DS combina-\ntion\
    \ rule to make the final judgment.\nConsider that the combination results satisfy\n\
    \U0001D45A (\U0001D43B1) = max {\U0001D45A (\U0001D43B\U0001D456) , \U0001D43B\
    \U0001D456 ⊂ Θ} ,\n\U0001D45A (\U0001D43B2) = max {\U0001D45A (\U0001D43B\U0001D457\
    ) , \U0001D43B\U0001D457 ⊂ Θ, \U0001D43B\U0001D457\n̸= \U0001D43B1} ,\n\U0001D45A\
    \ (\U0001D43B1) ≥ \U0001D7001,\n\U0001D45A (\U0001D43B1) − \U0001D45A (\U0001D43B\
    2) ≥ \U0001D7002.\n(32)\n\U0001D43B1 is the decision-making result through the\
    \ novel algo-\nrithm, where \U0001D7001 and \U0001D7002 are preset threshold values.\
    \ Otherwise,\nΘ is the result, which means that the system cannot be\nidentified\
    \ rationally.\n5. Simulation and Comparative Analyses\nThis section is divided\
    \ into two parts. One is the experiment\npreparation that discusses the value\
    \ of the regulatory factor \U0001D6FC,\nand the other is effectiveness validation\
    \ of the new decision-\nmaking method.\n5.1. Experiment Preparation. Prior to\
    \ the experiment, the\nanalysis about the accurate expression of evidences’ conflict\n\
    and the selection of the regulatory factor are described in this\nsection.\n5.1.1.\
    \ Precise Expression of Conflict. An experiment is carried\nout to prove the effectiveness\
    \ of the improved algorithm in\nexpressing evidences’ conflict.\nAssume that FoD\
    \ is Θ\n=\n{\U0001D434, \U0001D435, \U0001D436}, where \U0001D434, \U0001D435\
    , \U0001D436\nare mutually exclusive. The standard and reference sensor’s\njudgment\
    \ value is \U0001D45A0 = {0.5, 0.3, 0.2}. Ten groups of sensor’s\njudgment values\
    \ obtained by multisensor data fusion system\nTable 1: Ten sensors' BPAs and their\
    \ credibility.\nSensors\nSensor’s credibility\nPropositions\n\U0001D434\n\U0001D435\
    \n\U0001D436\nSensor 1\n0.7094\n0.5853\n0.3791\n0.0357\nSensor 2\n0.5777\n0.1680\n\
    0.5756\n0.2565\nSensor 3\n0.6266\n0.2591\n0.3936\n0.3473\nSensor 4\n0.5781\n0.3938\n\
    0.5982\n0.0080\nSensor 5\n0.6304\n0.7387\n0.1461\n0.1151\nSensor 6\n0.8882\n0.5560\n\
    0.2960\n0.1480\nSensor 7\n0.5953\n0.2870\n0.5881\n0.1249\nSensor 8\n0.4556\n0.0120\n\
    0.5957\n0.3923\nSensor 9\n0.9040\n0.5462\n0.2728\n0.1810\nSensor 10\n0.6018\n\
    0.2893\n0.5814\n0.1293\n2\n3\n4\n5\n6\n7\n8\n9\n10\n0.65\n0.7\n0.75\n0.85\n0.8\n\
    0.9\n0.95\n1\nThe number of evidences\nExpression of conflict\nThe global conflict\
    \ factor\nThe average conflict coefficient\nFigure 4: Comparison between the global\
    \ conflict factor and the\naverage conflict coefficient.\nand the corresponding\
    \ sensor’s credibility are shown in\nTable 1.\nAccording to Table 1, the comparison\
    \ between the global\nconflict factor \U0001D458 in DS evidence theory and the\
    \ average\nconflict coefficient \U0001D458∗ in the novel method is shown in\n\
    Figure 4.\nIt is obvious in Figure 4 that \U0001D458 in DS evidence theory is\n\
    getting larger along with the increasing of evidences’ number.\nHowever, the acquisition\
    \ of evidences is the processing to\nget support for propositions, not the processing\
    \ to get more\nconflict. Thus, \U0001D458 is not able to accurately represent\
    \ the conflict\nsituation. However, \U0001D458∗ in the novel method is the effective\n\
    expression of actual evidences’ conflict. Thus, Figure 4 indi-\nrectly illustrates\
    \ the rationality of the new decision-making\nmethod.\n5.1.2. Analysis of the\
    \ Regulatory Factor. During the consec-\nutive adjustments of sensor’s credibility,\
    \ there is an indis-\npensable index as the regulatory factor \U0001D6FC. To analyze\
    \ the\nnumerical selection of \U0001D6FC, statistical methods are adopted. As\n\
    the modified sensor’s credibility \U0001D44A2 is partially determined by\n8\n\
    Journal of Sensors\n0\n5\n10\n0.58\n0.62\n0.6\n0.64\n0.66\n0.68\n0.7\n0.72\n0.74\n\
    The regulatory factor\nSensor’s credibility\nSensor 1\nSensor 2\n−5\nFigure 5:\
    \ Relationship of sensor’s credibility and the regulatory\nfactor with two evidences.\n\
    0\n5\n10\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nThe regulatory factor\nSensor’s credibility\n\
    −5\nSensor 1\nSensor 2\nSensor 3\nSensor 4\nFigure 6: Relationship of sensor’s\
    \ credibility and the regulatory\nfactor with four evidences.\n\U0001D6FC, the\
    \ relationship between the regulatory factor and sensor’s\ncredibility with 2\
    \ evidences is indicated in Figure 5.\nAs can be seen from Figure 5, with the\
    \ increasing of\nthe regulatory factor \U0001D6FC, sensor’s credibility gradually\
    \ tends to\nbe stable. It proves that the perfect regulatory factor can be\nconfirmed.\n\
    In order to further reflect the numerical range of \U0001D6FC,\nthe number of\
    \ sensors is increased to finish the simulation.\nFigure 6 shows the relationship\
    \ of sensor’s credibility and the\nregulatory factor with 4 evidences.\nFrom Figure\
    \ 6, it is clear that sensor’s credibility tends to\nbe relatively stable when\
    \ the regulatory factor reaches 5. Thus,\nthe regulatory factor value is set to\
    \ 5 in the next experiment.\n5.2. Effectiveness Validation of the New Decision-Making\n\
    Method. In this experiment, the proposed algorithm is\nTable 2: Four sensors'\
    \ BPAs and their credibility.\nSensors\nSensor’s credibility\nPropositions\n\U0001D434\
    \n\U0001D435\n\U0001D436\nSensor 1\n0.7563\n0.5853\n0.3791\n0.0357\nSensor 2\n\
    0.6182\n0.3938\n0.5982\n0.0080\nSensor 3\n0.4792\n0.0000\n0.5756\n0.4244\nSensor\
    \ 4\n0.9595\n0.5462\n0.2728\n0.1810\nTable 3: The fusion result of 2 sensors.\n\
    Algorithms\nPropositions\n\U0001D434\n\U0001D435\n\U0001D436\nΘ\nLIU\n0.5004\n\
    0.4986\n0.0010\n0.0000\nYAGER\n0.5037\n0.4956\n0.0006\n0.0000\nGUO\n0.4972\n0.5000\n\
    0.0028\n0.0000\nLI\n0.5041\n0.4727\n0.0001\n0.0231\nTAN\n0.4794\n0.4653\n0.0008\n\
    0.0546\nCHENG\n0.5018\n0.4982\n0.0000\n0.5018\nCHEN\n0.5018\n0.4982\n0.0000\n\
    0.5018\nHE\n0.3258\n0.3206\n0.0004\n0.3532\nYE\n0.3864\n0.2652\n0.2955\n0.0530\n\
    YAO\n0.4960\n0.4918\n0.0121\n0.0000\nFLOREA\n0.3263\n0.3257\n0.0146\n0.3334\n\
    MURPHY\n0.5004\n0.4986\n0.0010\n0.0000\nProposed method\n0.5079\n0.4786\n0.0134\n\
    0.0000\ncompared with other methods to prove its priority in over-\ncoming problems\
    \ such as high conflict and one-vote veto and\nulteriorly realizing uncertain\
    \ data fusion correctly.\nAssume that FoD is Θ = {\U0001D434, \U0001D435, \U0001D436\
    }, where \U0001D434, \U0001D435, \U0001D436 are\nmutually exclusive. The standard\
    \ and reference sensor’s judg-\nment value is \U0001D45A0 = {0.5, 0.3, 0.2}.\n\
    Four groups of sensor’s judgment values obtained by mul-\ntisensor data fusion\
    \ system and the corresponding sensor’s\ncredibility are shown in Table 2.\nIt\
    \ is checked in Table 2 that the commonsensical fusion\nresult should give proposition\
    \ \U0001D434 the largest support as two\nsensors with big credibility both support\
    \ proposition \U0001D434 to a\ngreat extent. With similar principle, proposition\
    \ \U0001D436 in fusion\nresult should own the minimum support.\nThe data fusion\
    \ of 4 sensors is divided into 3 steps.\nAnd we take 12 common improved methods\
    \ in [20–31]\nas the compared algorithms. These methods are separately\nabbreviated\
    \ as LIU [20], YAGER [21], GUO [22], LI [23], TAN\n[24], CHENG [25], CHEN [26],\
    \ HE [27], YE [28], YAO [29],\nFLOREA [30], and MURPHY [31].\nFirstly, the data\
    \ fusion of sensor 1 and sensor 2 is achieved\nand the result is shown in Table\
    \ 3.\nFrom Table 3, we can see that all methods give proposition\n\U0001D434 the\
    \ largest support except GUO, which demonstrates that\nGUO makes the wrong decision.\
    \ Moreover, CHENG, CHEN,\nand FLOREA allocate Θ a lot of support, which is not\n\
    conducive to final judgment. Concerning method YE, the\nfusion result is averagely\
    \ allocated to each proposition, in\nwhich the support to proposition \U0001D436\
    \ mismatches with the\nJournal of Sensors\n9\nTable 4: The fusion result of 3\
    \ sensors.\nAlgorithms\nPropositions\n\U0001D434\n\U0001D435\n\U0001D436\nΘ\n\
    LIU\n0.1660\n0.8299\n0.0041\n0.0000\nYAGER\n0.0000\n0.9991\n0.0009\n0.0000\nGUO\n\
    0.3813\n0.4548\n0.1639\n0.0000\nLI\n0.0000\n0.7451\n0.0000\n0.2549\nTAN\n0.0000\n\
    0.6707\n0.0008\n0.3285\nCHENG\n0.2623\n0.7301\n0.0076\n0.0000\nCHEN\n0.0000\n\
    1.0000\n0.0000\n0.0000\nHE\n0.0000\n0.5756\n0.4244\n0.0000\nYE\n0.2864\n0.3652\n\
    0.2955\n0.0530\nYAO\n0.3282\n0.5856\n0.0862\n0.0000\nFLOREA\n0.1399\n0.2218\n\
    0.0669\n0.5714\nMURPHY\n0.2671\n0.6719\n0.0610\n0.0000\nProposed method\n0.5193\n\
    0.4797\n0.0010\n0.0000\nsupporting degree proved by original evidences. Although\n\
    LIU, YAGER, LI, TAN, HE, YAO, and MURPHY offer\nproposition A the largest support,\
    \ the numerical difference\nof support to propositions \U0001D434 and \U0001D435\
    \ is too tiny to facilitate\ndecision-making fusion. Thus, only the improved method\
    \ can\nget the proper fusion result.\nIn addition, sensor 3 is added in uncertain\
    \ data fusion\nto strengthen effectiveness validation of the new decision-\nmaking\
    \ method. Table 4 is the fusion result of 3 sensors.\nAs can be seen from Table\
    \ 2, sensor 3 is significantly\ndifferent from others which leads to high conflict,\
    \ and the\nsupport to proposition \U0001D434 is zero which leads to zero focal\n\
    element. In view of the particularity properties of sensor\n3, we can see in Table\
    \ 4 that one-vote veto phenomenon\nexists in YAGER, LI, TAN, CHEN, and HE. It\
    \ reveals that\nthe appearance of zero focal element directly deteriorates\nthe\
    \ fusion result. FLOREA still assigns a lot of support\nto Θ and increases the\
    \ uncertainty in fusion result. LIU,\nGUO, CHENG, YE, FLOREA, and MURPHY are unable\n\
    to reasonably handle zero focal element and utilize sensor’s\ncredibility. The\
    \ fusion results of them all give proposition\n\U0001D435 the excessive support\
    \ as the incorporation of sensor 3.\nThe proposed algorithm modifies the 3rd evidence\
    \ via taking\nsensor’s credibility into account as well as the overall situation\n\
    of all evidence’s discriminability, which reduces its influence\non fusion result.\
    \ Thus, in the fusion of 3 sensors, the proposed\nmethod is still the optimal\
    \ resolution for uncertain data\nfusion.\nFinally, in order to verify the priority\
    \ of the proposed\nmethod, evidence with relatively higher sensor credibility\
    \ is\nimported, and the data fusion is accomplished with 4 sensors.\nThe decision-making\
    \ processing is also completed, whose\nresult is displayed in Table 5. The threshold\
    \ values in decision-\nmaking rule are \U0001D7001 = 0.40 and \U0001D7002 = 0.15.\n\
    We can see from Table 5 that the occurrence of zero focal\nelement in sensor 3\
    \ seriously affects the data fusion. Even\nsensor 4 with large sensor’s credibility\
    \ supports proposition \U0001D434\nexplicitly, one-vote veto phenomenon still\
    \ exists in YAGER,\nLI, TAN, CHEN, and HE, and the decision fusions of LIU and\n\
    Table 5: The decision result of 4 sensors.\nAlgorithms\nPropositions\nDecision\
    \ result\n\U0001D434\n\U0001D435\n\U0001D436\nΘ\nLIU\n0.3136 0.6863 0.0001 0.0000\n\
    \U0001D435\nYAGER\n0.0000 0.9994 0.0006 0.0000\n\U0001D435\nGUO\n0.4414 0.4055\n\
    0.1531\n0.4414\nΘ\nLI\n0.0000 0.7506 0.0000 0.2494\n\U0001D435\nTAN\n0.0000 0.8664\
    \ 0.0004 0.1332\n\U0001D435\nCHENG\n0.4520 0.5401 0.0079 0.4520\nΘ\nCHEN\n0.0000\
    \ 1.0000 0.0000 0.0000\n\U0001D435\nHE\n0.0000 0.1013\n0.0001 0.8986\nΘ\nYE\n\
    0.5462 0.2728\n0.1810 0.0000\n\U0001D434\nYAO\n0.4339 0.4617 0.1045 0.4339\nΘ\n\
    FLOREA\n0.1173\n0.1404 0.0499 0.6923\nΘ\nMURPHY\n0.3826 0.5481 0.0693 0.0000\n\
    \U0001D435\nProposed method 0.7137 0.2860 0.0003 0.0000\n\U0001D434\nMURPHY give\
    \ the wrong decision results to proposition \U0001D435,\nwhile the decision fusion\
    \ of FLOREA sequentially regards Θ\nas the decision result. Secondly, due to the\
    \ preset of threshold\nvalues in decision-making rule, GUO, CHENG, and YAO\nconsider\
    \ Θ as the decision result. Moreover, only YE and the\nproposed method generate\
    \ reasonable decision results as they\ntake proposition \U0001D434 as the final\
    \ decision. Compared with YE,\nthe proposed method assigns larger support to proposition\
    \ \U0001D434,\nwhich is beneficial to get the precise decision result. Thus, the\n\
    proposed method is more rational and reliable.\nThe data fusion of 4 sensors above\
    \ reflects that the\nproposed method makes the reliable and accurate decision\n\
    in comprehensive consideration of sensor’s credibility and\noverall evidence’s\
    \ discriminability. Besides, the decision result\nreveals that the proposed method\
    \ will not only give accurate\ndecision, but also avoid harmful effects caused\
    \ by sensors\nwith low credibility and zero focal elements.\n6. Conclusion\nAs\
    \ multisensor information fusion is broadly applied in many\ncivil and military\
    \ areas, the valid decision-making method for\nuncertain information fusion is\
    \ under great attention. This\npaper raises a neoteric decision-making algorithm\
    \ based on\ngrey relation and DS evidence theory to solve the uncertainty\ncaused\
    \ by inconsistence of sensors itself and complexity of\nmonitoring environment.\
    \ The new algorithm is carried out\nwith three innovative treatments: generation\
    \ of sensor’s cred-\nibility based on grey relation theory, focal element analyses\n\
    as overall weighted factor analysis and proportional factor\nanalysis, and evidences’\
    \ overall discriminability processing.\nSimulation results and analyses show that\
    \ the proposed\nalgorithm can make precise decision without worrying about\nsensors’\
    \ unreliability and evidence’s high conflict. Thus, it\nhas great application\
    \ significance and excellent engineering\nprospect.\nIn further study, the decision-making\
    \ method for uncer-\ntain data fusion should pay close attention to relieve the\
    \ huge\ncomputation burden for system as the increasing number of\n10\nJournal\
    \ of Sensors\nsensors and try to realize the on-time and on-line decision-\nmaking\
    \ system.\nCompeting Interests\nThe authors declare that there is no conflict\
    \ of interests\nregarding the publication of this paper.\nAcknowledgments\nThe\
    \ paper is funded by the National Key Research and Devel-\nopment Program of China\
    \ (Grant no. 2016YFF0102806), the\nNational Natural Science Foundation of China\
    \ (Grant no.\n51509049), the Natural Science Foundation of Heilongjiang\nProvince,\
    \ China (Grant no. F201345), and the Fundamental\nResearch Funds for the Central\
    \ Universities of China (no.\nGK2080260140).\nReferences\n[1] J. A. Benediktsson\
    \ and I. Kanellopoulos, “Classification of\nmultisource and hyperspectral data\
    \ based on decision fusion,”\nIEEE Transactions on Geoscience and Remote Sensing,\
    \ vol. 37, no.\n3, pp. 1367–1377, 1999.\n[2] M. Daniel, “Distribution of contradictive\
    \ belief masses in\ncombination of belief functions,” in Information, Uncertainty\n\
    and Fusion, pp. 431–446, Springer, Berlin, Germany, 2000.\n[3] L. Dymova and P.\
    \ Sevastjanov, “An interpretation of intuition-\nistic fuzzy sets in terms of\
    \ evidence theory: decision making\naspect,” Knowledge-Based Systems, vol. 23,\
    \ no. 8, pp. 772–782,\n2010.\n[4] P. A. Samara, G. N. Fouskitakis, J. S. Sakallariou,\
    \ and S. D.\nFassois, “A statistical method for the detection of sensor abrupt\n\
    faults in aircraft control systems,” IEEE Transactions on Control\nSystems Technology,\
    \ vol. 16, no. 4, pp. 789–798, 2008.\n[5] X. L. Zhu, Fundamentals of Applied Information\
    \ Theory,\nTsinghua University Press, Beijing, China, 2001.\n[6] M. Truchon, “Borda\
    \ and the maximum likelihood approach to\nvote aggregation,” Mathematical Social\
    \ Sciences, vol. 55, no. 1,\npp. 96–102, 2008.\n[7] Z.-J. Zhou, C.-H. Hu, D.-L.\
    \ Xu, J.-B. Yang, and D.-H. Zhou,\n“Bayesian reasoning approach based recursive\
    \ algorithm for\nonline updating belief rule based expert system of pipeline leak\n\
    detection,” Expert Systems with Applications, vol. 38, no. 4, pp.\n3937–3943,\
    \ 2011.\n[8] S.-H. Oh, “Improving the error backpropagation algorithm\nwith a\
    \ modified error function,” IEEE Transactions on Neural\nNetworks, vol. 8, no.\
    \ 3, pp. 799–803, 1997.\n[9] Y. Deng, “Generalized evidence theory,”Applied Intelligence,\
    \ vol.\n43, no. 3, pp. 530–543, 2015.\n[10] H. Li, G. Wen, Z. Yu, and T. Zhou,\
    \ “Random subspace evidence\nclassifier,” Neurocomputing, vol. 110, pp. 62–69,\
    \ 2013.\n[11] Z. He, H. Zhang, J. Zhao, and Q. Qian, “Classification of power\n\
    quality disturbances using quantum neural network and DS\nevidence fusion,” European\
    \ Transactions on Electrical Power,\nvol. 22, no. 4, pp. 533–547, 2012.\n[12]\
    \ G. Dong and G. Kuang, “Target recognition via information\naggregation through\
    \ Dempster-Shafer’s evidence theory,” IEEE\nGeoscience and Remote Sensing Letters,\
    \ vol. 12, no. 6, pp. 1247–\n1251, 2015.\n[13] F. Ye, Y. Li, R. Yang, and Z. Sun,\
    \ “The user requirement based\ncompetitive price model for spectrum sharing in\
    \ cognitive radio\nnetworks,” International Journal of Distributed Sensor Networks,\n\
    vol. 9, no. 11, Article ID 724581, 2013.\n[14] X. Fan and M. J. Zuo, “Fault diagnosis\
    \ of machines based\non D-S evidence theory—part 1: D-S evidence theory and its\n\
    improvement,” Pattern Recognition Letters, vol. 27, no. 5, pp.\n366–376, 2006.\n\
    [15] J.-C. Li, Y.-B. Li, S. Kidera, and T. Kirimoto, “A robust signal\nrecognition\
    \ method for communication system under time-\nvarying SNR environment,” IEICE\
    \ Transactions on Information\nand Systems, vol. E96-D, no. 12, pp. 2814–2819,\
    \ 2013.\n[16] M. Beynon, D. Cosker, and D. Marshall, “An expert system for\nmulti-criteria\
    \ decision making using Dempster-Shafer theory,”\nExpert Systems with Applications,\
    \ vol. 20, no. 4, pp. 357–367,\n2001.\n[17] Y. Deng, “Deng entropy,” Chaos, Solitons\
    \ and Fractals, vol. 91,\npp. 549–553, 2016.\n[18] W. Jiang, B. Wei, C. Xie et\
    \ al., “An evidential sensor fusion\nmethod in fault diagnosis,” Advances in Mechanical\
    \ Engineering,\nvol. 8, no. 3, pp. 1–7, 2016.\n[19] A.-L. Jousselme, D. Grenier,\
    \ and ´E. Boss´e, “A new distance\nbetween two bodies of evidence,” Information\
    \ Fusion, vol. 2, no.\n2, pp. 91–101, 2001.\n[20] Y.-Z. Liu, Y.-C. Jiang, and\
    \ J.-K. Zhang, “Utility analysis of belief\nin evidence theory,” System Engineering\
    \ Theory and Practice, vol.\n28, no. 3, pp. 103–110, 2008.\n[21] R. R. Yager,\
    \ “On the dempster-shafer framework and new\ncombination rules,” Information Sciences,\
    \ vol. 41, no. 2, pp. 93–\n137, 1987.\n[22] H. Guo, W. Shi, Q. Liu et al., “A\
    \ new combination rule of\nevidence,” Journal of Shanghai Jiao-Tong University-Chinese\n\
    Edition, vol. 40, no. 11, pp. 1895–1900, 2006.\n[23] L. Li, D. Ma, C. Wang et\
    \ al., “New method for conflict evidence\nprocessing in DS theory,” Application\
    \ Research of Computers,\nvol. 28, no. 12, pp. 4528–4531, 2011.\n[24] Q. Tan and\
    \ Y.-H. Xiang, “Application of weighted evidential\ntheory and its information\
    \ fusion method in fault diagnosis,”\nJournal of Vibration and Shock, vol. 27,\
    \ no. 4, pp. 112–116, 2008.\n[25] H. Cheng, S.-W. Du, C.-H. Xu, and J.-J. Lin,\
    \ “A DS-based multi-\nindex fusion of information fusion algorithm,” Journal of\
    \ East\nChina University of Science and Technology, vol. 37, no. 4, pp.\n483–486,\
    \ 2011.\n[26] B. Chen and S. H. Wan, “Study on ship detection with improved\n\
    Dempster-Shafer theory,” Computer Engineering and Applica-\ntions, vol. 46, no.\
    \ 28, pp. 222–224, 2010.\n[27] B. He and H.-L. Hu, “Modified DS evidence combination\n\
    strategy,” Acta Aeronautica et Astronautica Sinica, vol. 24, no.\n6, pp. 559–562,\
    \ 2003.\n[28] Q. Ye, X.-P. Wu, and D.-J. Zhai, “Combination algorithm for\nevidence\
    \ theory utilizing energy function,” Systems Engineering\nand Electronics, vol.\
    \ 32, no. 3, pp. 566–569, 2010.\n[29] J. Yao, C. Wu, X. Xie, K. Qian, G. Ji, and\
    \ P. Bhattacharya, “A new\nmethod of information decision-making based on D-S\
    \ evidence\ntheory,” in Proceedings of the IEEE International Conference on\n\
    Systems, Man and Cybernetics (SMC ’10), pp. 1804–1811, Istanbul,\nTurkey, October\
    \ 2010.\n[30] M. C. Florea, A.-L. Jousselme, ´E. Boss´e, and D. Grenier, “Robust\n\
    combination rules for evidence theory,” Information Fusion, vol.\n10, no. 2, pp.\
    \ 183–197, 2009.\nJournal of Sensors\n11\n[31] C. K. Murphy, “Combining belief\
    \ functions when evidence\nconflicts,” Decision Support Systems, vol. 29, no.\
    \ 1, pp. 1–9, 2000.\n[32] Q. Zhang, Y. F. Tian, and Y. Liu, “Grey-relation based\
    \ approach\nto uncertain multiple attribute decision making,” in Proceedings\n\
    of the IEEE International Conference on Computational Intelli-\ngence and Natural\
    \ Computing (CINC ’09), vol. 2, pp. 456–458,\nIEEE, Wuhan, China, June 2009.\n\
    [33] X. Xia, F. Meng, and T. Lv, “Grey relation method for calcula-\ntion of embedding\
    \ dimension and delay time in phase space\nreconstruction,” Journal of Grey System,\
    \ vol. 22, no. 2, pp. 105–\n116, 2010.\n[34] Y. Li, C. Shao, and X. Hou, “A novel\
    \ grey relation analysis\nalgorithm: uniform incidence degree,” Information and\
    \ Control-\nShenyang, vol. 35, no. 4, p. 462, 2006.\n[35] J. L. Deng, The Basis\
    \ of Grey Theory, Press of Huazhong\nUniversity of Science and Technology, Wuhan,\
    \ China, 2002.\nInternational Journal of\nAerospace\nEngineering\nHindawi Publishing\
    \ Corporation\nhttp://www.hindawi.com\nVolume 2014\nRobotics\nJournal of\nHindawi\
    \ Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\nHindawi Publishing\
    \ Corporation\nhttp://www.hindawi.com\nVolume 2014\n Active and Passive  \nElectronic\
    \ Components\nControl Science\nand Engineering\nJournal of\nHindawi Publishing\
    \ Corporation\nhttp://www.hindawi.com\nVolume 2014\n International Journal of\n\
    \ Rotating\nMachinery\nHindawi Publishing Corporation\nhttp://www.hindawi.com\n\
    Volume 2014\nHindawi Publishing Corporation \nhttp://www.hindawi.com\n Journal\
    \ of\nEngineering\nVolume 2014\nSubmit your manuscripts at\nhttp://www.hindawi.com\n\
    VLSI Design\nHindawi Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\n\
    Hindawi Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\nShock and\
    \ Vibration\nHindawi Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\n\
    Civil Engineering\nAdvances in\nAcoustics and Vibration\nAdvances in\nHindawi\
    \ Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\nHindawi Publishing\
    \ Corporation\nhttp://www.hindawi.com\nVolume 2014\nElectrical and Computer \n\
    Engineering\nJournal of\nAdvances in\nOptoElectronics\nHindawi Publishing Corporation\
    \ \nhttp://www.hindawi.com\nVolume 2014\nThe Scientific \nWorld Journal\nHindawi\
    \ Publishing Corporation \nhttp://www.hindawi.com\nVolume 2014\nSensors\nJournal\
    \ of\nHindawi Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\nModelling\
    \ & \nSimulation \nin Engineering\nHindawi Publishing Corporation \nhttp://www.hindawi.com\n\
    Volume 2014\nHindawi Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\n\
    Chemical Engineering\nInternational Journal of\n Antennas and\nPropagation\nInternational\
    \ Journal of\nHindawi Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\n\
    Hindawi Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\nNavigation\
    \ and \n Observation\nInternational Journal of\nHindawi Publishing Corporation\n\
    http://www.hindawi.com\nVolume 2014\nDistributed\nSensor Networks\nInternational\
    \ Journal of\n"
  inline_citation: '>'
  journal: Journal of Sensors
  limitations: '>'
  pdf_link: https://downloads.hindawi.com/journals/js/2016/3954573.pdf
  publication_year: 2016
  relevance_score1: 0
  relevance_score2: 0
  title: Decision-Making Algorithm for Multisensor Fusion Based on Grey Relation and
    DS Evidence Theory
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/mdm.2009.22
  analysis: '>'
  authors:
  - Wenjia Li
  - Anupam Joshi
  citation_count: 35
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >2009 Tenth International Conf... Outlier
    Detection in Ad Hoc Networks Using Dempster-Shafer Theory Publisher: IEEE Cite
    This PDF Wenjia Li; Anupam Joshi All Authors 30 Cites in Papers 254 Full Text
    Views Abstract Document Sections 1. Introduction 2. Related work 3. Gossip-based
    outlier detection algorithm 4. Performance evaluation 5. Conclusion Authors Figures
    References Citations Keywords Metrics Abstract: Mobile Ad-hoc NETworks (MANETs)
    are known to be vulnerable to a variety of attacks due to lack of central authority
    or fixed network infrastructure. Many security schemes have been proposed to identify
    misbehaving nodes. Most of these security schemes rely on either a predefined
    threshold, or a set of well-defined training data to build up the detection mechanism
    before effectively identifying the malicious peers. However, it is generally difficult
    to set appropriate thresholds, and collecting training datasets representative
    of an attack ahead of time is also problematic. We observe that the malicious
    peers generally demonstrate behavioral patterns different from all the other normal
    peers, and argue that outlier detection techniques can be used to detect malicious
    peers in ad hoc networks. A problem with this approach is combining evidence from
    potentially untrustworthy peers to detect the outliers. In this paper, an outlier
    detection algorithm is proposed that applies the Dempster-Shafer theory to combine
    observation results from multiple nodes because it can appropriately reflect uncertainty
    as well as unreliability of the observations. The simulation results show that
    the proposed scheme is highly resilient to attackers and it can converge stably
    to a common outlier view amongst distributed nodes with a limited communication
    overhead. Published in: 2009 Tenth International Conference on Mobile Data Management:
    Systems, Services and Middleware Date of Conference: 18-20 May 2009 Date Added
    to IEEE Xplore: 19 June 2009 ISBN Information: ISSN Information: DOI: 10.1109/MDM.2009.22
    Publisher: IEEE Conference Location: Taipei, Taiwan SECTION 1. Introduction A
    Mobile Ad-hoc NETwork (MANET), as its name suggests, has no fixed infrastructure,
    and is generally composed of a dynamic set of cooperative peers, which are willing
    to share their wireless transmission power with other peers so that indirect communication
    can be possible between nodes that are not in the radio range of each other. The
    nature of MANETs, such as node mobility, unreliable transmission medium and restricted
    battery power, makes them extremely vulnerable to a variety of attacks [1] [2].
    Wireless links, for instance, are generally prone to both passive eavesdropping
    and active intrusion. Moreover, there are various sophisticated attacks that are
    difficult to identify, such as greyhole attacks [3], blackhole attacks [4], wormhole
    attacks [5], and Sybil attacks [6]. Another security concern in ad hoc networks
    is caused by the cooperative nature of the nodes. Attacks from external adversaries
    may disturb communications, but the external intruder generally cannot directly
    participate in the cooperative activities among the nodes, such as routing, because
    they do not possess the proper secure credentials, such as shared keys. However,
    compromised nodes, which are taken over by an adversary, are capable of presenting
    the proper secure credentials, and consequently can interfere with almost all
    of the network operations, such as route discovery, key management and distribution,
    and packet forwarding. Misbehavior surveillance and detection is a crucial method
    that has been used in MANETs to protect them from both external adversaries and
    internal malicious nodes. The misbehaviors observed by neighboring peers typically
    include dropping, modification, misrouting of packets at the network layer, as
    well as false Request/Clears in the MAC layer etc. Nevertheless, many of these
    events may occur due to environmental and mobility related reasons, not just malicious
    intent. For instance, a packet may get dropped when a node''s buffer gets full
    because of its inability to forward packets on a noisy channel. Most of the current
    misbehavior detection schemes rely on either a predefined threshold, or a set
    of well-defined training data to infer thresholds. This threshold is used in the
    detection mechanism to separate malicious behaviors from what is normal given
    the conditions. However, it is generally difficult to set appropriate thresholds,
    because the network is quite dynamic and unpredictable, and environmental conditions
    such as ambient RF noise can vary. Moreover, collecting training datasets representative
    of an attack ahead of time is also problematic. Since the adversaries can constantly
    modify their attack patterns, which may contain location (attack target), type,
    and degree (amount of packets affected) of the attack, it is also difficult to
    gather the training dataset that can appropriately predict the attack pattern
    of the adversaries. On the contrary, we do not need to rely on any previous knowledge
    to find a node that is an outlier with respect to a given observable. In order
    to disrupt communications or launch some other attack, the malicious node will
    have to behave in a way distinct from the “good” nodes. So we can detect node
    misbehaviors by means of outlier detection. Outlier detection is generally an
    important step prior to almost all kinds of data analysis routines. Outliers are
    normally defined as data points that have significant difference from the rest
    of the data according to a certain measure [7], [8]. Outlier detection is used
    to either eliminate or amplify outliers: the first is to reduce the noise in the
    data; the second is to expose the outliers for further analysis. In this paper,
    we develop and evaluate a gossip-based outlier detection algorithm for mobile
    ad hoc networks. In our approach, all the peers in MANETs observe and record the
    abnormal behaviors of their neighbors in a manner similar to existing methods
    such as [9], [10], [11], [12]. In contrast to most existing approaches, each peer
    will then calculate its local version of outliers based on its own observations.
    In the next stage, the peers exchange their local views with their immediate neighbors,
    and they update the local views if the received views are more accurate than their
    own views. The updated local views will be further broadcast to the immediate
    neighbors. The process continues, and it will not halt until there is no more
    view update amongst the peers. The most important step in the proposed outlier
    detection algorithm is the local view update step. In this step, we need to derive
    the updated local view of outliers from multiple local views provided by our (one
    hop) peers. However, the peers may be giving us inaccurate data, either from malicious
    intent or out of ignorance. The contribution of this paper is to see if correct
    outlier decisions can be made in presence of potentially unreliable views. We
    use both the weighted voting method and the Dempster-Shafer Theory (DST) [38]
    of evidence to combine the local views from multiple neighbors. The Dempster-Shafer
    theory of evidence is particularly well suited for this type of problem because
    it can capture uncertainty. Furthermore, Dempster''s rule for combination can
    be used to fuse together multiple pieces of views from both reliable and unreliable
    observers. Some important features of our algorithm are: (1) its deployment does
    not rely on any priori knowledge, such as pre-classified training dataset or pre-defined
    security threshold; (2) it is compatible with different outlier detection heuristics;
    (3) it is resilient to attempts by misbehaving nodes to defeat it; (4) it is resilient
    to the motion and failure of nodes in MANETs; (5) it is efficient in terms of
    communication overhead; and (6) all the nodes will stably converge to a common
    view of outliers as long as these nodes do not change their behaviors significantly
    during the convergence time of the algorithm. In the rest of this paper, we give
    a survey of related work in Sec. 2. In Sec. 3, we present our outlier detection
    algorithm. We evaluate the effectiveness of our scheme through simulation in Sec.
    4, and conclude in Sec. 5. SECTION 2. Related work 2.1. Outlier detection Outlier
    detection is a long studied topic in the data mining research, and a variety of
    outlier detection approaches have been proposed for different application domains,
    such as large-scale databases [13], [14], [15], high-dimensional datasets [16],
    [17], [18], and wireless sensor networks [19], [20], [21], [22]. Notably, Branch
    et al. [22] propose an in-network outlier detection scheme to detect the outliers
    in wireless sensor networks. In this scheme, all the sensor nodes will first calculate
    the local outlier(s). Then some messages, which contain the local outlier(s) as
    well as some other supportive information, will be exchanged amongst all the nodes.
    The message exchanging process will not halt until all the nodes have the same
    global view of outlier(s). Our proposed outlier detection algorithm is somewhat
    similar to the method proposed by Branch et al. However, there are three significant
    differences between the two methods. First, the method by Branch et al. does not
    consider the mobility of the nodes, whereas our proposed method takes the mobility
    issue into consideration. Second, there is no malicious behaviors in the discussion
    of the method by Branch et al., i.e., the nodes will not deliberately fabricate
    fake local views or alter incoming local views in their method. On the contrary,
    we have considered the malicious behaviors of the nodes, and applied the knowledge
    of trust and reputation as the countermeasure to the malicious behaviors. Third,
    the method by Branch et al. has not taken uncertainty of the local views into
    consideration: they assume that the information exchange and dissemination process
    amongst the nodes is reliable, and no uncertainty will be introduced to the local
    views during this message exchange process. On the contrary, we have considered
    uncertainty of the local views that may be introduced during the message exchange
    process. 2.2. Misbehavior detection in mobile ad hoc networks Work on misbehavior
    detection (may also be called as intrusion detection) has produced very rich literature
    in traditional, P2P and ad hoc networks. In the latter, most contributions assume
    that there is no fixed network and security infrastructure that misbehavior detection
    mechanism can rely on. Four types of misbehaviors in ad hoc networks are identified
    and discussed in [23], which are failed node behaviors, badly failed node behaviors,
    selfish attacks, and malicious attacks. These four types of node misbehaviors
    are classified with respect to the node''s intent and action. Remarkably, selfish
    attacks are intentional passive misbehaviors, where nodes choose not to fully
    participate in the packet forwarding functionality to conserve their resources,
    such as battery power; malicious attacks are intentional active misbehaviors,
    where the malicious node aims to purposely interrupt network operations. The existence
    of selfishness and malicious behaviors has motivated research in the area of misbehavior
    detection for mobile ad hoc networks. Intrusion Detection System (IDS) is an essential
    means to detect various node misbehaviors. Several approaches have been proposed
    to build IDS on each individual peer due to the lack of a fixed infrastructure
    [10], [24], [25], [26]. In these approaches, every node is equipped with an IDS
    sensor, and each IDS sensor is assumed to be always on, which is apparently not
    energy efficient given the limited battery power of nodes in ad hoc networks.
    In contrast, Huang et al. [27] propose a cooperative intrusion detection framework,
    in which clusters are formed in ad hoc networks and all the nodes in each cluster
    will take over the intrusion detection operations in turn. This cluster-based
    approach can definitely reduce the power consumption for each node. Routing misbehavior
    is another kind of malicious activity that is common in ad hoc networks. If an
    attacker aims to degrade the network service of ad hoc network, then he can try
    to compromise some nodes in the ad hoc network, and use them to disturb the routing
    services so as to make part of or the entire network unreachable. Marti et al.
    [28] introduce two related techniques, namely watchdog and pathrater, to detect
    and isolate misbehaving nodes, which are nodes that do not forward packets. There
    are also some other proposed solutions that aim to cope with the routing misbehaviors
    [29], [30], [31]. There is little work in which the Dempster-Shafer Theory has
    been applied to MANETs. The two most relevant research efforts are discussed in
    [40] and [41]. In [40], DST is utilized to combine the direct observation results
    from each IDS sensor, whereas we are using DST to combine views of outliers. Raya
    et al. [41] proposed a trust management scheme for VANET, in which DST is used
    to combine multiple evidences for trust. Nevertheless, there are two major differences
    between our work and theirs. First, there are strong logical relationships among
    the local views in our work, because an updated local view is always derived from
    the previous local views. On the contrary, the report of evidence in [41] may
    be independent. Second, DST is used to combine the local views in real-time in
    our approach. On the other hand, in [41], DST is not applied to combine evidences
    in real-time. In our previous work [32], we have done a preliminary study where
    outlier detection method is adopted to identify node misbehaviors. However, we
    merely utilize weighted voting method to fuse together multiple pieces of local
    views, which may not perfectly reflect uncertainty in the local views. Here we
    apply the Dempster-Shafer theory of evidence to combine multiple local views,
    and compare their performances under different criteria in simulation. SECTION
    3. Gossip-based outlier detection algorithm The aim of our gossip-based outlier
    detection algorithm is to identify the top k outliers in terms of some abnormal
    behaviors observed by neighbors, such as packet drops or modifications. Here k
    is a user-defined parameter, and it can be assigned any positive integer value.
    Gossiping in MANETs generally refers to the repetitive probabilistic exchange
    of messages between two peers in MANETs. By the utilization of restricted gossiping
    method in the outlier detection algorithm, the communication overhead of our algorithm
    can be noticeably bounded. 3.1. Preliminaries We denote node as a system entity
    in mobile ad hoc networks that is capable of observing the behaviors of other
    entities within its radio transmission range, and exchanging these observations
    with other entities in its radio transmission range. A neighbor of a node A is
    defined as a node that resides within A''s radio transmission range. The type
    of abnormal behaviors that each node constantly observes can be fully user- defined
    as long as all the nodes observe the same set of abnormal behaviors. While a node
    observes and records the abnormal behaviors that its neighbors demonstrate, it
    also keeps track of the total amount of incoming packets it has observed for each
    neighbor. When a node needs to summarize its observation and thereby form its
    local view of outliers, it will calculate the rate of abnormal behaviors over
    the all behaviors it has observed for the node. For example, if all the nodes
    choose to observe the behaviors of packet drop, modification and misroute, then
    the packet drop rate (PDR), packet modification rate (PMOR) and packet misroute
    rate (PMIR) can be defined as follows, respectively. PDR= Number of Packets Dropped
    Total Number of Incoming Packets PMOR= Number of Packets Modified Total Numer
    of Incoming Packets PMIR= Number of Packets Misrouted Total Number of Incoming
    Packets View Source We define the trustworthiness of a node N k as a real value
    θ k that can properly reflect the probability with which the node will perform
    the exact actions that it is supposed to take. θ k can be assigned any real value
    in the range [0], [1], and the higher the value of θ k , the node N k is more
    reliable and has a higher probability to take the correct actions. For instance,
    some nodes are deployed with stronger encryption mechanisms, closely monitored
    by certain security surveillance system, and better protected against various
    attacks. Given that they are generally less likely to perform faulty actions,
    they are regarded as more trustworthy. The trustworthiness θ k of a node N k is
    defined as a function of all misbehaviors that other nodes have observed for the
    node N k . Namely, the trustworthiness θ k is calculated as follow. θ k =1− ∑
    i P i ∗ M ki View Source Here P i denotes the punishment factor for the i -th
    misbehavior, which indicates the severity degree of its outcome. M ki represents
    the rate of this misbehavior over the total observed behaviors. For example, if
    packet drop, packet modification, and packet misroute are the three exact misbehaviors
    we are observing, then θ k can be derived as follow. θ k =1− P drop ∗PDR− P modification
    ∗ PMOR − P misroute ∗PMIR View Source In our outlier detection framework, trustworthiness
    of nodes is initialized and updated by a trust management scheme described in
    Sec. 3.3. 3.2. Framework description The outlier detection algorithm has the following
    four steps, viz. local view formation, local view exchange, view combination,
    and global view formation. In this algorithm, we have utilized two methods to
    properly combine multiple local views, which are weighted voting and the Dempster-Shafer
    theory of evidence, respectively. Fig. 1 illustrates our framework. Figure 1.
    Gossip-based outlier detection framework Show All Prior to the local view formation,
    each node observes and record the behaviors of their neighbors, and also keeps
    track of the total number of incoming packets each of their neighbors has. Based
    on their observations, the initial local view of outliers is generated. We may
    note that there are a variety of definitions for outliers. Here we adopt two well-known
    distance-based definitions: (1) distance to the nearest neighbor (NN), and (2)
    average distance to k nearest neighbors (k-NN ) [13]. Once all the nodes form
    their initial local views, they broadcast their initial local views to all of
    their immediate neighbors, i.e., all the nodes that are within their direct radio
    transmission ranges. When a node receives a local view from one of its neighbors,
    it then checks whether the incoming view differs from its own local view. If so,
    it combines the two views, and rebroadcasts the combined view to its immediate
    neighbors. If not, it simply retains its local view and keeps silent. Unlike the
    traditional gossiping method, the more the number of nodes that accept the same
    view of outliers, the less the number of new view updates that are sent out. Here,
    we assume that all the nodes will not add any new observation results of their
    own to their own local views once they start exchanging local views with their
    neighbors. Ultimately, the algorithm converges to a global view that all the nodes
    hold. The global view is regarded as a snapshot that can properly illustrate the
    comprehensive observation results of all nodes at the time spot when the nodes
    start exchanging their views. Due to node mobility and changing network topology,
    the status of nodes and the network changes over time. Therefore, the global views
    will get outdated. To address this problem, we can periodically repeat the outlier
    detection process in order to keep the global views up-to-date. The repeat interval
    can be determined by both the availability of resources (bandwidth, battery power,
    etc.) and the levels of node mobility as well as topology change. 3.3. Trust management
    A variety of trust and reputation management approaches have been studied during
    the past decades for instance [33], [34], [35]. All of these trust management
    approaches can fit our system. For the experiments presented in this paper, we
    adopt a simple but well-defined trust management scheme, in which each nodes trustworthiness
    θ k is initially set to a default value. A peers θ k is modified whenever we obtain
    any novel information regarding its trustworthiness in terms of both direct observation
    results from the node itself and indirect observation results from other nodes.
    Direct observation results and indirect observation results are generally called
    first-hand information and second-hand information, respectively [36]. First let
    us see how the direct observation results are obtained and utilized in our trust
    management scheme. As we have mentioned, trustworthiness θ k is initially set
    as 1. Whenever a node observes any misbehavior of its neighbor k ) it reduces
    θ k according to the punishment factors. These can vary for different misbehaviors.
    For instance, packet drop and packet misroute are both misbehaviors. Nevertheless,
    packet drop may be caused by either intentional malicious behavior or power failure.
    On the contrary, if we observe packet misroute by a node, it is more likely that
    this is a deliberate act. This observation is also true for packet modification.
    Therefore, we set a higher punishment factor for both packet modification and
    packet misroute than for packet drop. With the limited radio transmission range
    as well as the mobility of the nodes, it is highly unlikely that a node can have
    the opportunity to observe the behaviors of all other nodes in MANETs. Hence,
    it is essential to integrate second-hand information obtained from other nodes
    to our trust management scheme. However, since malicious nodes can intentionally
    disseminate falsified second-hand information to their neighbors so as to disturb
    the trust management scheme as well as protect themselves from being disclosed,
    second-hand information from other nodes may not be trustworthy at all times.
    Therefore, it is necessary to adopt a proper method to combine multiple pieces
    of second-hand information from both trustworthy and untrustworthy neighbors.
    In our trust management scheme, we may utilize either weighted voting or the Dempster-Shafer
    theory to appropriately integrate multiple pieces of second-hand information into
    the first-hand information that each node directly observes. Fig. 2 shows the
    trust management scheme. Figure 2. Trust Management Scheme Show All 3.4. View
    combination View combination is the most important step in our outlier detection
    algorithm. Because some of the incoming views are not reliable, it is essential
    to find a view combination technique to properly fuse together multiple pieces
    of views. Among the various data fusion techniques, Bayesian approaches [37] and
    Dempster-Shafer theory of evidence [38] are two of the most frequently used techniques.
    There are two fundamental differences between DST and Bayesian theorem. First,
    unlike the definition in the Bayesian theorem, the lack of knowledge about an
    incident is not regarded as a negative evidence for that incident in DST. Second,
    given that there are two incidents in DST that are inconsistent with each other,
    the uncertainty about one of them may be viewed as the positive evidence for the
    other incident. In one word, in DST a node can hold either supportive or uncertain
    opinion toward an event, whereas a node must pick either positive or negative
    attitude toward an event in Bayesian theorem. For instance, suppose a node A observes
    that its neighbor B has dropped 10% of its incoming packets. Then according to
    our definition of PDR in Sec. 3.1, the PDR for node B is 0.1. If we apply the
    Bayesian approach in this example, then we may draw a conclusion that node B has
    90% probability to properly forward the incoming packets, with which we can easily
    conclude that node B is a good node. However, if node A observes 10% packet drops
    because of node movement and attack pattern change (e.g. switch from packet drop
    to packet modification), then we should not have drawn the conclusion that node
    B is good. On the contrary, in DST, we still compute PDR as 10%, but we will mark
    the rest 90% as “uncertain” instead of a refutal of evidence, which makes the
    decision process more realistic. Hence, the Dempster-Shafer theory is more suitable
    when there is uncertainty or even no priori knowledge for the event. In our outlier
    detection framework, each node initially builds its local view for its neighbors
    based on its own observations. Due to the node mobility and limited radio range,
    each node may only observe a part of its neighbors'' behaviors. As a result, the
    initial local views may be biased, and they definitely contain uncertainty. In
    this light, we believe that DST fits well in our framework. In DST, probability
    is replaced by an uncertainty interval bounded by belief and plausibility. Belief
    is the lower bound of this interval and represents supporting evidence. Plausibility
    is the upper bound of the interval and represents non-refuting evidence. For instance,
    if a node N observes that one of its neighbors, say node M , has dropped packets
    with probability p , then node N has p degree of belief in the packet dropping
    behavior of node M and 0 degree of belief in its absence. The belief value with
    respect to an event α i and observed by node N can be computed as the following.
    be l N ( α i )= ∑ e: α e ⊂ α i m N ( α e ) View Source Here α e are all the basic
    events that compose the event α i , and m N ( α e ) represents the view of the
    event α e by node N In our case, since node N only get a single report of node
    M from itself, i.e., α i ⊂ α i . Thus, we can conclude that be l N ( α i )= m
    N ( α i ) . The equation pls( α i )=1−bel( α i ¯ ¯ ¯ ¯ ¯ ) holds for belief and
    plausibility. Therefore, in our example, we can get the following: be l N (M)=
    m N (M)=p and pl s N (M)=1−be l N ( M ¯ )=1 . Given that belief indicates the
    lower bound of the uncertainty interval and represents supportive evidence, we
    define the combined packet dropping level of node A as the following. p d A =bel(A)=m(A)=
    ⨁ k=1 K m k (A) View Source Here m k (A) denotes the view of node k on another
    node A . We can combine reports from different nodes by applying the Dempster''s
    rule, which is defined as following. m B (A)⊕ m C (A)= ∑ q,r: α q ∩ α r =A m B
    ( α q ) m C ( α r ) 1− ∑ q,r: α q ∩ α r =Φ m B ( α q ) m C ( α r ) View Source
    As a comparator, we consider the Weighted Voting method (WV) in our framework.
    As the name suggests, weighted voting method adds up the multiple pieces of views
    with each view weighted by the corresponding trustworthiness to yield the updated
    view of outliers. The weighted voting method can be expressed as: V= ∑ i=1 N w
    i ∗ V i View Source SECTION 4. Performance evaluation In this section, we examine
    the performance of our outlier detection framework. We compare the two view combination
    techniques: DST and WV (which we have recently proposed [32]) against the baseline
    scheme, which utilizes the siMple aVerging method (MV). 4.1. Simulation setup
    We use GloMoSim 2.03 [39] as the simulation platform, and table 1 lists the parameters
    used in the simulation scenarios. Table 1. Simulation parameters Parameter Value
    Simulation area 150m × 150m, 300m × 300m, 450m × 450m, 600m × 600m Number of nodes
    15, 25, 50, 100, 150, 200 Transmission range 45m, 60m, 90m, 120m Mobility pattern
    Random waypoint Node motion speed 5m/s, 10m/s, 20m/s Number of malicious nodes
    5, 10, 15, 20 Simulation time 900 s We use three parameters to evaluate the correctness
    and efficiency of our algorithm: Correctness Rate (CR), Communication Overhead
    (CO), and Convergence Time (CT). They are defined as follows. CR= Number of True
    Outliers Found Total Number of Outliers CO= Number of Packets for Outlier Detection
    Total Number of Packets in network CT=Time taken to form a consistent global view
    View Source Each simulation scenario has 30 runs with distinct random seed, which
    ensures a unique initial node placement for each run. 4.2. Adversary Model In
    our simulation, nodes either abide by various MANET protocols, such as AODV routing
    protocol, or their behaviors deviate from the protocol definition either intentionally
    (i.e. attackers) or unintentionally (i.e. faulty nodes). Both attackers and faulty
    nodes can do harm to the network functionalities, and consequently we regard them
    both as adversaries. In general, adversaries can partially or completely drop,
    modify or misroute any packet that is sent to them. We also assume that they can
    deploy the Denial-of-Service (DoS) attack by continuously sending out Request-To-Send
    (RTS) packets so as to improperly occupy the communication channel all the time,
    which is also regarded as the RTS flood attack. The adversaries may mix all these
    misbehaviors so that it will be more difficult to identify their misbehaviors
    if observed only from one or two perspectives. More importantly, the adversaries
    are capable of deliberately injecting faulty data and spreading these fake data
    to other benign nodes. In this way, the benign nodes may be induced to generate
    faulty reports in which benign nodes can be misclassified as misbehaving nodes.
    4.3. Simulation results The goal of the simulations is to observe the performance
    of our algorithm under different parameter configurations. We have compared the
    performance of our algorithm under the following five conditions: different number
    of nodes, different simulation areas, different radio ranges, different percentage
    of malicious nodes, and different node motion speeds. The simulation results are
    showed in the following Fig. 3 through Fig. 7. Figure 3. CR, CO, CT with different
    number of nodes (number of malicious nodes: 5, area: 600m ×600m, radio range:
    120m, motion speed: 5m/s) Show All Figure 4. CR, CO, CT with different simulation
    areas (number of nodes: 50, number of malicious nodes: 5, radio range: 60m, Motion
    Speed: 5m/s) Show All Figure 5. CR, CO, CT with different node motion speeds (number
    of nodes: 100, number of malicious nodes: 5, radio range: 120m, area: 600m×600m)
    Show All Figure 6. CR, CO, CT with different transmission ranges (number of nodes:
    100, number of malicious nodes: 5, area: 600m×600m, node motion speed: 5m/s Show
    All Figure 7. CR, CO, CT with different percentage of malicious nodes (number
    of nodes: 100, radio range: 120m, area: 600m×600m, node motion speed: 5m/s) Show
    All Fig. 3 exhibits the performance of our algorithm with different number of
    nodes in the network. From Fig. 3 we find that when the number of nodes is increased,
    the algorithm yields a higher correctness rate, but it also introduces more communication
    overhead. This is consistent with our analysis because the information gathered
    to identify the outliers is generally more accurate if there are more observers.
    At the same time, more messages need to be exchanged amongst all the nodes to
    reach a consistent view when there are more nodes. We also note that the both
    DST and WV demonstrate better performance than MV. Moreover, DST has better performance
    over WV in terms of higher correctness rate, lower communication overhead, and
    shorter convergence time. In Fig. 4, we can find the different performance of
    our algorithm with different simulation areas. It is clear that the correctness
    rate decreases as we increase the simulation area for all three methods. We also
    find that the communication overhead is reduced as the simulation area becomes
    larger. Since the nodes have a lower probability to communicate with other nodes
    if the simulation area becomes larger, the correctness rate will surely become
    lower. Moreover, there will also be less communication overhead, and it will generally
    take longer time for all the nodes to reach an agreement on the global view of
    outliers. Similarly as Fig. 3 implies, we can find that both DST and WV produce
    better performance that MV. Moreover, we also note that DST always wins over WV
    in terms of correctness and convergence time when simulation area enlarges. However,
    there is no significant difference between DST and WV in terms of communication
    overhead. The simulation results with different motion speeds are shown in Fig.
    5. We may conclude from Fig. 5 that while the nodes travel in a higher speed,
    the performance for all the methods become worse. This is true because it is harder
    for the nodes to exchange their views when they are traveling in a higher speed.
    However, in spite of the performance downgrade for all the methods, DST still
    achieves a far better performance than both WV and MV when the nodes move fast.
    With a higher mobility of the nodes, it is more difficult for the nodes to exchange
    their views. Hence, there is higher uncertainty in the network. Since DST is suitable
    to deal with the problems with uncertainty, the performance downgrade introduced
    by node mobility is minimized for DST. Fig. 6 illustrates how the simulation results
    differ with different transmission ranges. We find that with a smaller radio range,
    all the three methods suffer from a performance degradation. When it is more difficult
    for the nodes to exchange the local views, the correctness rate of the final global
    view will surely be degraded. Fig. 7 shows the simulation results with different
    percentage of malicious nodes. It is obvious that DST can yield a much better
    performance than WV and MV with a higher percentage of malicious nodes. This is
    true because both WV and MV rely on enough trustworthy information to make a correct
    decision: MV simply follows the decision from the majority of nodes, and the weights
    in WV are also significantly determined by the second-hand information sent by
    other nodes. Hence, when there are a higher percentage of malicious nodes, the
    performances of both WV and MV degrade noticeably. On the other hand, DST can
    properly handle the outlier detection problem even in a more hostile environment
    because it can well deal with unreliability. SECTION 5. Conclusion In this paper,
    an outlier detection framework is proposed that aims to reveal the malicious nodes
    in a MANET environment. We apply both the Dempster-Shafer theory of evidence and
    the weighted voting method to combine observation results from multiple nodes.
    The simulation results show that the proposed framework is highly resilient to
    attackers and it can converge stably to a common outlier view amongst distributed
    nodes with a limited communication overhead. One possible future work is to apply
    the Bayesian inference (BI) method to the view combination process, and compare
    the performance of DST with that of BI. Since BI has been widely used to fuse
    together various pieces of evidence, each of these two methods should outperform
    the other in some circumstances. Moreover, some of the misbehaviors, such as packet
    dropping, may result from both intentional denial of forwarding and mobility or
    channel effect. Hence, it will be valuable to try to discriminate malicious nodes
    from faulty nodes. Authors Figures References Citations Keywords Metrics More
    Like This When peer-to-peer comes face-to-face: collaborative peer-to-peer computing
    in mobile ad-hoc networks Proceedings First International Conference on Peer-to-Peer
    Computing Published: 2001 A routing protocol based on trusted and shortest path
    selection for mobile ad hoc network 2009 IEEE 9th Malaysia International Conference
    on Communications (MICC) Published: 2009 Show More IEEE Personal Account CHANGE
    USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile
    Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS
    Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT
    Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use |
    Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy
    A not-for-profit organization, IEEE is the world''s largest technical professional
    organization dedicated to advancing technology for the benefit of humanity. ©
    Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: null
  publication_year: 2009
  relevance_score1: 0
  relevance_score2: 0
  title: Outlier Detection in Ad Hoc Networks Using Dempster-Shafer Theory
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/icns.2007.49
  analysis: '>'
  authors:
  - Vassilis Chatzigiannakis
  - Georgios Androulidakis
  - Konstantinos Pelechrinis
  - Symeon Papavassiliou
  - Vasilis Maglaris
  citation_count: 27
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >International Conference on N... Data fusion
    algorithms for network anomaly detection: classification and evaluation Publisher:
    IEEE Cite This PDF V. Chatzigiannakis; G. Androulidakis; K. Pelechrinis; S. Papavassiliou;
    V. Maglaris All Authors 17 Cites in Papers 1 Cites in Patent 343 Full Text Views
    Abstract Document Sections 1. Introduction 2. Data Fusion Algorithm Classification
    3. Representative algorithms description 4. Performance Evaluation 5. Conclusions
    Authors Figures References Citations Keywords Metrics Abstract: In this paper,
    the problem of discovering anomalies in a large-scale network based on the data
    fusion of heterogeneous monitors is considered. We present a classification of
    anomaly detection algorithms based on data fusion, and motivated by this classification,
    the operational principles and characteristics of two different representative
    approaches, one based on the Demster-Shafer theory of evidence and one based on
    principal component analysis, are described. The detection effectiveness of these
    strategies are evaluated and compared under different attack scenarios, based
    on both real data and simulations. Our study and corresponding numerical results
    revealed that in principle the conditions under which they operate efficiently
    are complementary, and therefore could be used effectively in an integrated way
    to detect a wider range of attacks.. Published in: International Conference on
    Networking and Services (ICNS ''07) Date of Conference: 19-25 June 2007 Date Added
    to IEEE Xplore: 22 January 2008 Electronic ISBN:978-1-5090-8837-9 DOI: 10.1109/ICNS.2007.49
    Publisher: IEEE Conference Location: Athens, Greece SECTION 1. Introduction One
    of the main challenges in security management of large scale high speed networks
    is the detection of suspicious anomalies in network traffic patterns due to Distributed
    Denial of Service (DDoS) attacks or worm propagation [1] [2]. Network anomaly
    detection is one of the most frequently suggested methods for detecting network
    abuse. Anomaly detection can be uniformly applied in order to detect network attacks,
    even in cases where novel attacks are present and the nature of the intrusion
    is unknown [3]. Usually network anomaly detection methodologies rely on the analysis
    of network traffic and the characterization of the dynamic statistical properties
    of traffic normality, in order to accurately and timely detect network anomalies.
    Anomaly detection is based on the concept that perturbations of normal behavior
    suggest the presence of anomalies, faults, attacks, etc. The goal of this paper
    is twofold: firstly, it provides a review and classification of data fusion algorithms
    inspired from the taxonomy presented in [4] but addressing specifically the problem
    of anomaly detection; and secondly, it focuses on the study and evaluation of
    two representative anomaly detection techniques, one based on the Dempster-Shafer
    theory of evidence and one based on Principal Component Analysis (PCA). Among
    the main objectives of this work is not only to evaluate the detection effectiveness
    of each one of these methodologies, but also to identify and study the conditions
    under which they operate efficiently. The remaining of this paper is organized
    as follows. In section 2 we present a classification of some widely used anomaly
    detection approaches. Then, in section 3 we present the operational principles
    of two different representative data fusion algorithms, while in section 4 their
    performances under different attack scenarios are evaluated and compared based
    on real experiments and simulations. Finally section 5 concludes the paper. SECTION
    2. Data Fusion Algorithm Classification Multisensor data fusion, or distributed
    sensing, is a relatively new engineering discipline used to combine data from
    multiple and diverse sensors and sources in order to make inferences about events,
    activities, and situations [5]. These systems are often compared to the human
    cognitive process where the brain fuses sensory information from the various sensory
    organs, evaluates situations, makes decisions, and directs action. Among the most
    common examples where such systems have been developed and widely used, are military
    systems for threat assessment and weather forecast systems. Generally, data fusion
    is a process performed on multi-source data towards detection, association, correlation,
    estimation and combination of several data streams into one with a higher level
    of abstraction and greater meaningfulness. In the following we present a classification
    and brief description of some widely used methods, motivated by the taxonomy that
    was originally proposed by Hall [4]. However our presentation and arguments are
    specifically targeted towards anomaly detection. 2.1. Physical Models Physical
    models attempt to create an accurate model of the observed environment and make
    appropriate estimations, by matching predicted (modeled) data to actual observations.
    Included in this category are also methods that try to decompose the observed
    object (the network or a network element, such as a link) in descriptive components
    (or “primitives”). Such a method is M3L [6] (described in more detail in section
    3.1) that relies on PCA approach to decompose the network state in primitives
    (i.e. Principal Components) that capture the important interrelations and traffic
    patterns among network elements and therefore create a model of the monitored
    network 2.2. Parametric Classification The algorithms that belong to this category
    make a direct mapping of parametric data to the classification space (e.g. the
    state of the system). These may be further divided into statistically based algorithms,
    such as Bayesian Inference and/or the Dempster-Shafer (D-S) methodologies, and
    information theoretic techniques such as neural networks and entropy based methods.
    Bayesian Inference computes the probability of an observation given the assumption
    of an a priori hypothesis. Dempster-Shafer Theory of Evidence is a mathematical
    theory of evidence [7] based on belief functions and plausible reasoning, which
    is used to combine separate pieces of information (evidence) to calculate the
    probability of an event. In [8], D-S has been thoroughly tested for anomaly detection
    in an operational university campus network. Adaptive Neural Networks provide
    an interesting and generic method that does not assume a model for the observed
    system, but bases its output on the successful training of its nodes (neurons)
    using training data. The different kinds of neural networks differ in the number
    of nodes and layers used, as well as the processing function that is performed
    in each node. These methods have been used in the context of Intrusion Detection
    Systems but require training data that are representative of the normal traffic
    data, which in general are quite hard to gather or generate [9]. Finally, entropy
    based methods use the concept of information entropy to describe the inherent
    randomness of a communication system. The entropy measure reflects and quantifies
    the information in a generalized “message” on the basis of its probability of
    occurrence. The basic idea is that frequent “messages” are of low entropy value
    and rare messages have greater value. In [10] the authors have developed an entropy-based
    approach that determines and reports entropy contents of traffic parameters such
    as IP addresses. Changes in the entropy content indicate a massive network event.
    2.3. Cognitive Algorithms Members of the third category, namely the cognitive
    based algorithms, try to mimic the human brain cognitive process for object identification.
    Two representative approaches that belong to this class are: expert systems and
    techniques based on fuzzy set theory. Expert systems consist of a knowledge base
    that represents the knowledge of some “field expert” usually in a production rule
    form. This knowledge can be facts, algorithms, heuristics etc. Expert systems
    have been widely used for Intrusion Detection purposes. For example, NIDES [11]
    has a rule database that employs expert rules to characterize known intrusive
    activity represented in activity logs, and raises alarms as matches are identified
    between the observed activity logs and the rule encodings. Fuzzy set theory is
    the fundamental theory that supports fuzzy logic, which is in turn used as an
    alternative to logical reasoning. In fuzzy logic, a statement is not just true
    or false but is rather a proposition with an associated value between 0, that
    represents a completely false proposition, and 1 - completely true (this is the
    membership value to the truthfulness set) [12]. SECTION 3. Representative algorithms
    description 3.1. M3L: a network-wide anomaly detection PCA-based approach The
    objective of Multi-Metric-Multi-Link PCA-based method [6] is to provide a methodology
    of fusing and combining data of heterogeneous monitors spread throughout the network.
    This is achieved by applying a PCA-based approach simultaneously on several metrics
    of one or more links. Principal Component Analysis aims at the reduction of the
    dimensionality of a data set in which there are a large number of interrelated
    variables, while retaining as much as possible of the variation present in the
    data set [13]. The extracted non-correlated components are called Principal Components
    (PCs) and are estimated from the eigenvectors of the covariance matrix or the
    correlation matrix of the original variables. The overall procedure of this method
    may be divided into two different parts: the offline analysis, that creates a
    model of the normal traffic, and the real time analysis that detects anomalies
    by comparing the current (actual) with the modeled traffic patterns. The input
    of the offline analysis is a data set that contains only normal traffic. During
    the offline analysis, PCA is applied on this data set and then the first few most
    important derived Principal Components (PCs) are selected. Their number depends
    on the network and the number of metrics per link, and it represents the number
    of PCs required for capturing the percentage of variance that the system needs
    to model normal traffic. The output of the offline analysis is the PCs to be used
    in the Subspace Method. The goal of the Subspace Method is to divide current traffic
    data in two different spaces: one containing traffic considered normal ( y norm
    ) and resembles to the modeled traffic patterns and one containing the residual
    ( y res ) . In general, anomalies tend to result in great variations in the residual,
    since they present different characteristics from the modeled traffic. When an
    anomaly occurs, the residual vector presents great variation in some of its variables
    and the system detects the network path containing the anomaly by selecting these
    variables. The interested reader may refer to [6] for a more detailed description
    of PCA-based anomaly detection strategies. 3.2. D-S based anomaly detection Dempster-Shafer''s
    Theory of Evidence can be considered an extension of Bayesian inference. The goal
    of D-S is to infer the true system state without having an explicit model of the
    system, based only on some observations that can be considered as hints (with
    some uncertainty) towards some system states. Based on these observations D-S
    calculates two functions: Belief Bel(H) and Plausibility Pl(H) , where H is the
    hypothesis for the current state. Generally we can characterize Bel(H) as a quantitative
    measure of all our supportive evidence and Pl(H) as a measure of how compatible
    our evidence is with H in terms of doubt. The true belief in the hypothesis for
    the current system state lies in the interval between. Our degree of ignorance
    is represented by the difference Bel(H)−Pl(H) . Theory of Evidence makes the distinction
    between uncertainty and ignorance, so it is a very useful way to reason with uncertainty
    based on incomplete and possibly contradictory information extracted from a stochastic
    environment. It does not need “a priori” knowledge or probability distributions
    on the possible system states like the Bayesian approach and as such it is mostly
    useful when we do not have a model of our system. Theory of Evidence has a definite
    advantage in a vague and unknown environment especially when compared to other
    inference processes like first order logic that assumes complete and consistent
    knowledge exhibits monotonicity, or probability theory that requires knowledge
    in terms of probability distributions and exhibits non-monotonicity. The main
    disadvantage of Dempster-Shafer''s theory is the assumption that the evidence
    is statistically independent from each other, since sources of information are
    often linked with some sort of dependence. The interested reader may refer to
    [8] for a detailed discussion about the application of D-S theory in network anomaly
    detection. SECTION 4. Performance Evaluation 4.1. Network Topology and experiments
    In this section the performances of the two representative anomaly detection techniques
    - D-S and M3L techniques - described in section 3, are evaluated and compared
    under various attack scenarios. The results and corresponding observations presented
    in this section are based on real data collected from an operational campus network.
    Specifically, we monitored the link between the National Technical University
    of Athens (NTUA) and the Greek Research and Technology Network (GRNET), which
    connects the university campus with the Internet. This link has an average traffic
    of 700–800Mbit/sec. It contains a rich network traffic mix, that carries standard
    network services like web, mail, ftp and p2p application traffic. In our study,
    in order to evaluate the D-S algorithm we defined four possible states for the
    network: NORMAL, SYN-attack, ICMP-flood and UDP-flood. For the application of
    the D-S algorithm we used the following metrics: UDP packets in/out ratio, ICMP
    packets out/in ratio, TCP-SYN in/TCP-FIN out ratio. In order to transform the
    sensor measurements (metrics) to basic probability assignments (bpa) we used multiple
    thresholds per sensor measurement that were set manually after studying the “normal”
    data set. In order to evaluate the PCA-based approach we implemented a single-link-multi-metric
    algorithm based on M3L and used the following metrics: number of UDP packets in,
    UDP packets out, ICMP packets out, ICMP packets in, TCP-SYN packets, TCP-FIN packets,
    TCP packets out, TCP packets in, TCP flows out, TCP flows in. The sample dataset
    required to train the system and create the network model was a part of the recorded
    traffic that was relatively flat and considered to be normal. SYN-attack was performed
    using a real DoS attack tool. The target of the attack was a host situated in
    the NTUA network at a 10 Mbps link and there were 3 attackers distributed at GRNET.
    Every one of the attackers was connected at a 100Mbps interface and was running
    the TFN2K tool that is used for DoS attacks. These attackers were sending TCP
    SYN packets towards the victim, using spoofed IP addresses from the C class network
    that they were part of. In that manner the three attackers managed an attack from
    256 sources. The trace file of the attack lasts 8 minutes with the attack lasting
    for 60 seconds. In the next section we provide some representative numerical results
    of our experiments, starting with the performance of each algorithm under various
    scenarios, and then conclude our experimental results by comparing their performance
    under common experiments. In the following experiments, ICMP-flood and UDP-flood
    attacks were injected manually in the network traces of the collected data 4.2.
    Performance Evaluation 4.2.1. D-S algorithm Detection Effectiveness In Figure
    1, an ICMP-flood attack, as detected by the D-S algorithm, is presented. In this
    scenario, the attack packets correspond to 5% of the background traffic. The four
    different diagrams correspond to each one of the four defined states (NORMAL,
    UDP-flood, ICMP-flood and SYN-ATTACK). As observed by this figure, during the
    attack, the belief and plausibility functions of ICMP-flood state have increased
    - together with the decrease of the respective functions for the NORMAL state
    - in a way that implies that the most likely state of our network is ICMP-flood.
    In Figure 2 we present the corresponding results of a real SYN-attack scenario.
    In this case, the attack packets represent only 2% of the background traffic.
    As we can observe from the four diagrams given for the four possible states of
    the network, the belief and plausibility functions of SYN-attack state have not
    increased during this attack. Therefore based on the D-S algorithm we erroneously
    conclude that the network was always in NORMAL state. Figure 1. ICMP-flood of
    5% rate detected by D-S algorithm Show All Figure 2. SYN-attack of 2% rate not-detected
    by D-S algorithm Show All In Figure 3 we depict the corresponding results for
    the D-S algorithm using a 20% SYN-attack rate. As we can observe there is a noticeable
    alteration of the belief and plausibility functions of the NORMAL and SYN-attack
    state, which increases our belief that the network is in SYN-attack state. Figure
    3. SYN-attack of 20% rate detected by D-S algorithm (real attack) Show All 4.2.2.
    M3L algorithm Detection Effectiveness In the following, the detection effectiveness
    of the M3L algorithm is evaluated. As observed by the results presented in the
    following figures, the behavior of the PCA algorithm differs significantly from
    the one of the D-S algorithm. In Figure 4 we present the corresponding Squared
    Prediction Error (SPE) for a simulated ICMP - flood attack. The attack packets
    correspond to 20% of the total background traffic. Figure 4. ICMP-flood attack
    of rate 20% not detected by PCA algorithm Show All As we can observe from figure
    4, there is not any significant change at the SPE, and as a result one can imply
    that the network was always at the NORMAL state. In this case M3L fails to detect
    the attack because the selection of metrics is inappropriate, namely the metrics
    utilized are uncorrelated and thus the algorithm cannot create a precise model
    of the network. On the other hand, figure 5 presents the SPE for a number of different
    rates of SYN attack. In this figure we present various volumes of the attack,
    ranging from 1% attack rate up to 20%. We observe that even for a 2% attack rate
    the SPE changes significantly compared to the SPE for the NORMAL state of the
    network. Figure 5. The SPE of the PCA algorithm for various rates of the SYN-attack
    Show All 4.2.3. Comparative Results In the following figures we present in common
    axes the discrete differential of the “alarm” function of each algorithm for the
    same attack. Along with D-S and M3L we study the performance of another parametric
    classification algorithm: the Bayesian inference. The Bayesian inference simply
    utilizes a function for each one of the four possible states of the network that
    estimates the probability of the system being in each state. Referring to Figures
    6 & 7 for the Bayesian Inference the “alarm” function is the probability function
    of the corresponding state, while for the D-S algorithm is either the belief function
    or the plausibility function, and for the PCA based algorithm (M3L) is the SPE
    function. More specifically, in Figure 6 we present the corresponding results
    for a simulated ICMP-flood, where the attack packets correspond to 10% of the
    background traffic. The attack was manually inserted in the corresponding traffic
    dump, starting at time bin 75 and ending at time bin 90 sec. In the differential
    diagram the large positive values indicate a large increase whereas the negative
    values indicate respective decrease. The change rate is significantly large for
    the parametric classification algorithms - Bayesian inference and DS theory of
    evidence. On the other hand M3L fails to detect the attack and presents false
    positives between time bins 120 and 140. Figure 6. The deferential of the alarm
    metric of every algorithm for the same simulated ICMP-flood of 10% attack rate
    Show All Figure 7. The deferential of the alarm metric of every algorithm for
    the real SYN-attack of 10% rate Show All The situation however is different in
    Figure 7, where we present the corresponding analysis for a 10% rate SYN-attack.
    The corresponding results verify that the PCA based algorithm is much more sensitive
    at the detection of such attacks. The attack was emulated according to the scenario
    described in section 4, starting at time bin 12 and ending at time bin 18 sec.
    Also in this differential diagram the large positive values indicate a large increase
    and the peaks at time bin 12 reveal the beginning of the attack whereas the negative
    peaks in time bin 18 denote its end. 4.2.4. Metric Correlation and Discussion
    The explanation of the difference in the performance of the algorithms lies in
    the correlation of the metrics used. The D-S Theory of Evidence performs well
    on the detection of attacks that can be sensed by uncorrelated metrics because
    it requires that evidence originating from different sensors is indenendent. On
    the other hand, M3L requires that the metrics fed into the fusion algorithm present
    some degree of correlation. The method models traffic patterns and interrelations
    by extracting the eigenvectors from the correlation matrix of a sample data set.
    If there is no correlation among the utilized metrics then the model is not efficient.
    The test for determining whether or not two sets of series are correlated is to
    calculate their correlation coefficient Rx, Y. Variables with correlation coefficient
    close to 1 vary together in the same direction; whereas variables with correlation
    close to −1 vary together in opposite directions. R X,Y = Cov(X,Y) S X ⋅ S Y View
    Source In our experiments, based on data gathered by GRNET, we have confirmed
    that neighboring virtual links are highly correlated, as their correlation matrix
    comprises of elements that have value close to 1. Metrics such as TCP SYN packets,
    TCP FIN packets, TCP in flows and TCP out flows are highly correlated and should
    be utilized in M3L, whereas the combination of UDP in/out packets, ICMP in/out
    packets, TCP in/out packets are uncorrelated and should be used in D-S. This can
    be further analyzed and mapped to the detection capabilities of these methodologies
    with respect to different attack types. For instance, attacks that involve alteration
    in the percentage of UDP packets in traffic composition such as UDP flooding are
    better detected by D-S method. On the other hand, attacks such as SYN attacks,
    worms spreading, port scanning which affect the proportion of correlated metrics
    such as TCP in/out, SYN/FIN packets and TCP in/out flows are better detected with
    M3L. SECTION 5. Conclusions With the advent and explosive growth of the global
    Internet and the electronic commerce infrastructures, timely and proactive detection
    of network anomalies is a prerequisite for the operational and functional effectiveness
    of secure wide area networks. If the next generation of network technology is
    to operate beyond the levels of current networks, it will require a set of well-designed
    tools for its management that will provide the capability of dynamically and reliably
    identifying network anomalies. In this paper, we studied the problem of discovering
    anomalies in a large-scale network based on the data fusion of heterogeneous monitors.
    We first presented and discussed taxonomy of anomaly detection algorithms based
    on the data fusion aspect. Moreover, we focused on the study of two different
    representative anomaly detection techniques, one based on the Demster-Shafer Theory
    of Evidence and one based on Principal Component Analysis. The two techniques
    that belong to different categories of data fusion algorithms were evaluated via
    emulation and simulation. Our study and corresponding numerical results revealed
    that in principle the conditions under which they operate efficiently are complementary,
    and therefore could be used effectively in an integrated way to detect a wide
    range of possible attacks. ACKNOWLEDGEMENTS This work was partially supported
    by the European Commission, GridCC Project (IST 511382). Authors Figures References
    Citations Keywords Metrics More Like This Financial evaluation of listed companies
    based on entropy method and principal component analysis 2010 International Conference
    on Financial Theory and Engineering Published: 2010 Enhancing performance of anomaly
    based intrusion detection systems through dimensionality reduction using principal
    component analysis 2016 IEEE International Conference on Advanced Networks and
    Telecommunications Systems (ANTS) Published: 2016 Show More IEEE Personal Account
    CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS
    Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL
    INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT
    & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms
    of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy
    Policy A not-for-profit organization, IEEE is the world''s largest technical professional
    organization dedicated to advancing technology for the benefit of humanity. ©
    Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: null
  publication_year: 2007
  relevance_score1: 0
  relevance_score2: 0
  title: 'Data fusion algorithms for network anomaly detection: classification and
    evaluation'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1080/09349849509409560
  analysis: '>'
  authors:
  - X. E. Gros
  - Peter A. Strachan
  - D. W. Lowden
  citation_count: 15
  full_citation: '>'
  full_text: '>

    Access provided by University of Nebraska, Lincoln Log in  |  Register Cart Home
    All Journals Research in Nondestructive Evaluation List of Issues Volume 6, Issue
    4 Theory and Implementation of NDT Data Fu .... Search in:                                        This
    Journal                                                                                Anywhere                                                                  Advanced
    search Research in Nondestructive Evaluation Volume 6, 1995 - Issue 4 Submit an
    article Journal homepage Full access 30 Views 14 CrossRef citations to date 0
    Altmetric Original Articles Theory and Implementation of NDT Data Fusion X. E.
    Gros, P. Strachan & D. W. Lowden Pages 227-236 | Published online: 21 Apr 2009
    Cite this article   References Citations Metrics Reprints & Permissions View PDF
    Abstract Scientific measurements from single or multiple sensors are usually incomplete
    and uncertain. A process making use of the concept of data fusion has been developed
    to try to encompass this problem by combining information from multiple sensors.
    The objective to synergistic use of information from multiple sources is to reduce
    uncertainty and increase the confidence level of a measurand. The implementation
    of data fusion to the field of NDT is relatively new. This paper summarizes the
    achievements of current research on data fusion applied to NDT. A theoretical
    data fusion strategy is described and experimental results generated from weld
    inspection are presented. Previous article View issue table of contents Next article
    Download PDF X Facebook LinkedIn Email Share Related research  Recommended articles
    Cited by 14 Towards data fusion-based big data analytics for intrusion detection
    Farah Jemili Journal of Information and Telecommunication Published online: 24
    May 2023 NDT spatial data integration for monumental buildings: technical information
    management for the Royal Alcazar of Seville Francisco M. Hidalgo-Sánchez et al.
    Building Research & Information Published online: 2 Feb 2023 Multimodal data fusion
    for systems improvement: A review Nathan Gaw et al. IISE Transactions Published
    online: 3 Dec 2021 View more Information for Authors R&D professionals Editors
    Librarians Societies Open access Overview Open journals Open Select Dove Medical
    Press F1000Research Opportunities Reprints and e-prints Advertising solutions
    Accelerated publication Corporate access solutions Help and information Help and
    contact Newsroom All journals Books Keep up to date Register to receive personalised
    research and resources by email Sign me up Copyright © 2024 Informa UK Limited
    Privacy policy Cookies Terms & conditions Accessibility Registered in England
    & Wales No. 3099067 5 Howick Place | London | SW1P 1WG     Cookies Button About
    Cookies On This Site We and our partners use cookies to enhance your website experience,
    learn how our site is used, offer personalised features, measure the effectiveness
    of our services, and tailor content and ads to your interests while you navigate
    on the web or interact with us across devices. By clicking "Continue" or continuing
    to browse our site you are agreeing to our and our partners use of cookies. For
    more information seePrivacy Policy CONTINUE'
  inline_citation: '>'
  journal: Research in Nondestructive Evaluation
  limitations: '>'
  pdf_link: null
  publication_year: 1995
  relevance_score1: 0
  relevance_score2: 0
  title: Theory and Implementation of NDT Data Fusion
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/s18051487
  analysis: '>'
  authors:
  - Fuyuan Xiao
  - Bowen Qin
  citation_count: 66
  full_citation: '>'
  full_text: ">\nsensors\nArticle\nA Weighted Combination Method for Conﬂicting\n\
    Evidence in Multi-Sensor Data Fusion\nFuyuan Xiao * ID and Bowen Qin\nSchool of\
    \ Computer and Information Science, Southwest University, No.2 Tiansheng Road,\
    \ BeiBei District,\nChongqing 400715, China; qinbowen_swu@163.com\n* Correspondence:\
    \ xiaofuyuan@swu.edu.cn\nReceived: 30 March 2018; Accepted: 1 May 2018; Published:\
    \ 9 May 2018\n\x01\x02\x03\x01\x04\x05\x06\a\b\x01\n\x01\x02\x03\x04\x05\x06\a\
    \nAbstract: Dempster–Shafer evidence theory is widely applied in various ﬁelds\
    \ related to information\nfusion. However, how to avoid the counter-intuitive\
    \ results is an open issue when combining highly\nconﬂicting pieces of evidence.\
    \ In order to handle such a problem, a weighted combination method\nfor conﬂicting\
    \ pieces of evidence in multi-sensor data fusion is proposed by considering both\
    \ the\ninterplay between the pieces of evidence and the impacts of the pieces\
    \ of evidence themselves. First,\nthe degree of credibility of the evidence is\
    \ determined on the basis of the modiﬁed cosine similarity\nmeasure of basic probability\
    \ assignment. Then, the degree of credibility of the evidence is adjusted\nby\
    \ leveraging the belief entropy function to measure the information volume of\
    \ the evidence. Finally,\nthe ﬁnal weight of each piece of evidence generated\
    \ from the above steps is obtained and adopted to\nmodify the bodies of evidence\
    \ before using Dempster’s combination rule. A numerical example is\nprovided to\
    \ illustrate that the proposed method is reasonable and efﬁcient in handling the\
    \ conﬂicting\npieces of evidence. In addition, applications in data classiﬁcation\
    \ and motor rotor fault diagnosis\nvalidate the practicability of the proposed\
    \ method with better accuracy.\nKeywords: multi-sensor data fusion; conﬂicting\
    \ evidence; Dempster–Shafer evidence theory; belief\nentropy; similarity measure;\
    \ data classiﬁcation; fault diagnosis\n1. Introduction\nMulti-sensor data fusion\
    \ technology has received signiﬁcant attention in a variety of ﬁelds, as\nit combines\
    \ the collected information from multi-sensors, which can enhance the robustness\
    \ and\nsafety of a system. In wireless sensor networks applications, however,\
    \ the data that are collected\nfrom the sensors are often imprecise and uncertain\
    \ [1]. How to model and handle the uncertainty\ninformation is still an open issue.\
    \ To address this problem, many mathematical approaches have been\npresented,\
    \ such as the fuzzy sets theory [2,3], that focuses on the intuitive reasoning\
    \ by taking into\naccount human subjectivity and imprecision; the intuitionistic\
    \ fuzzy sets theory [4] which generalizes\nfuzzy sets by considering the uncertainty\
    \ in the assignment of membership degree known as the\nhesitation degree; evidence\
    \ theory [5–7], as a general framework for reasoning with uncertainty,\nwith understood\
    \ connections to other frameworks such as probability, possibility, and imprecise\n\
    probability theories; rough sets theory [8,9] where its methodology is concerned\
    \ with the classiﬁcation\nand analysis of imprecise, uncertain, or incomplete\
    \ information and knowledge, which is considered\none of the ﬁrst non-statistical\
    \ approaches in data analysis; evidential reasoning [10,11] which is a\ngeneric\
    \ evidence-based multi-criteria decision analysis (MCDA) approach for dealing\
    \ with problems\nhaving both quantitative and qualitative criteria under various\
    \ uncertainties including ignorance\nand randomness; Z numbers [12,13], that intend\
    \ to provide a basis for computation with numbers\nwhich are not totally reliable;\
    \ D numbers theory [14–17] which is a generalization of Dempster–Shafer\ntheory,\
    \ but does not follow the commutative law; and so on [18–21]. In addition, mixed\
    \ intelligent\nSensors 2018, 18, 1487; doi:10.3390/s18051487\nwww.mdpi.com/journal/sensors\n\
    Sensors 2018, 18, 1487\n2 of 20\nmethods have been applied in decision making\
    \ [22], risk analysis [23], supplier selection [24], pattern\nrecognition [25],\
    \ classiﬁcation [26], human reliability analysis [27], and fault diagnosis [28],\
    \ etc. In this\npaper, we focus on evidence theory to deal with the uncertain\
    \ problem of multi-sensor data fusion.\nDempster–Shafer evidence theory was ﬁrstly\
    \ presented by Dempster [5] in 1967; later, it was\nextended by Shafer [6] in\
    \ 1976. Dempster–Shafer evidence theory is effective to model both of the\nuncertainty\
    \ and imprecision without prior information, so it is widely applied in various\
    \ ﬁelds for\ninformation fusion [29–32]. Nevertheless, it may result in counter-intuitive\
    \ results when combining\nhighly conﬂicting pieces of evidence [33]. To address\
    \ this issue, many methods have been presented in\nrecent years [34–36]. On the\
    \ one hand, some researchers focused on amending Dempster’s combination\nrule.\
    \ On the other hand, some researchers tried to pretreat the bodies of evidence\
    \ before using\nDempster’s combination rule. In terms of of amending Dempster’s\
    \ combination rule, the major works\ncontain Smets’s unnormalized combination\
    \ rule [37], Dubois and Prade’s disjunctive combination\nrule [38], and Yager’s\
    \ combination rule [39]. However, the modiﬁcation of combination rule often\n\
    breaks the good properties, like commutativity and associativity. Furthermore,\
    \ if the sensor failure\ngives rise to the counter-intuitive results, the modiﬁcation\
    \ of combination rule is considered to\nbe unreasonable. Therefore, in order to\
    \ resolve the fusion problem of highly conﬂicting pieces of\nevidence, researchers\
    \ prefer to pretreat the bodies of evidence. With respect to pretreating the bodies\n\
    of evidence, the main works contain Murphy’s simple average approach of the bodies\
    \ of evidence [40],\nand Deng et al.’s weighted average of the masses based on\
    \ distance of evidence [41]. Deng et al.’s\nmethod [41] conquered the deﬁciency\
    \ of the method in [40]. However, the impact of evidence itself\nwas neglected\
    \ in the decision-making process.\nHence, in this paper, a weighted combination\
    \ method for conﬂicting pieces of evidence in\nmulti-sensor data fusion is proposed\
    \ to resolve fusion problem of highly conﬂicting evidence. First,\nthe credibility\
    \ degree of each piece of evidence is determined on the basis of the modiﬁed cosine\n\
    similarity measure of basic probability assignment [42]. Then, credibility degree\
    \ of each piece of\nevidence is modiﬁed by adopting the belief entropy function\
    \ [43] to measure the information volume\nof the evidence. Finally, the modiﬁed\
    \ credibility degree of each piece of evidence is used to adjust its\ncorresponding\
    \ body of evidence to obtain the weighted averaging evidence before using Dempster’s\n\
    combination rule. A numerical example is given to illustrate the feasibility and\
    \ effectiveness of the\nproposed method. Additionally, the proposed method is\
    \ applied in data classiﬁcation and motor rotor\nfault diagnosis, which validates\
    \ the practicability of it.\nThe rest of this paper is organized as follows. Section\
    \ 2 brieﬂy introduces the preliminaries of\nthis paper. After that, Section 3\
    \ proposes the novel method, which is based on the similarity measure\nof evidence\
    \ and belief function entropy. Then, Section 4 gives a numerical example to show\
    \ the\neffectiveness of the proposed method. A statistical experiment is carried\
    \ out in Section 5. Afterwards,\nthe proposed method is applied to Iris data set\
    \ classiﬁcation, and motor rotor fault diagnosis is\nperformed in Section 6. Finally,\
    \ Section 7 gives the conclusions.\n2. Preliminaries\n2.1. Data Fusion\nData fusion\
    \ can be identiﬁed as a combination of multiple sources to obtain improved information\n\
    with less expensive, higher quality, or more relevant information [44]. General\
    \ data fusion structure can\nbe classiﬁed into three types based on the different\
    \ stages: data-level, feature-level, and decision-level,\nas referred in [45].\n\
    In the data-level fusion, all raw data from sensors for a measured object are\
    \ combined directly.\nThen, a feature vector is extracted from the fused data.\
    \ Fusion of data at this level consists of the\nmaximum information so that it\
    \ can generate good results. However, sensors used in the data-level\nfusion,\
    \ such as the sensors reporting vibration signals, must be homogeneous. As a consequence,\n\
    the data-level fusion is limited in the actual application environment, because\
    \ many physical quantities\nSensors 2018, 18, 1487\n3 of 20\ncan be measured for\
    \ a more comprehensive analysis. In the feature-level fusion, heterogeneous\n\
    sensors can be used to report the data. According to the types of collected raw\
    \ data, the features are\nextracted from the sensors. Then, these heterogeneous\
    \ sensor data are combined at the feature-level\nstage. All of the feature vectors\
    \ are combined into a single feature vector, which is then utilized in a\nspecial\
    \ classiﬁcation model for decision-making. In the decision-level fusion, the processes\
    \ of feature\nextraction and pattern recognition are sequentially conducted for\
    \ the data collected from each sensor.\nThen, the produced decision vectors are\
    \ combined by using decision-level fusion techniques such as\nthe Bayesian method,\
    \ Dempster–Shafer evidence theory, or behavior knowledge space.\nBecause of the\
    \ advantages of multi-sensor data fusion technology, it has been widely applied\
    \ in\nvarious ﬁelds, such as in fault diagnosis [46–48], target tracking [49,50],\
    \ health care analysis [51,52],\nimage processing [53], attack detection [54],\
    \ estimation of ship dynamics [55], and characterization of\nbuilt environments\
    \ [56].\nIn this paper, we focus on decision-level fusion, and try to improve\
    \ the performance of the system\nbased on Dempster–Shafer evidence theory.\n2.2.\
    \ Dempster-Shafer Evidence Theory\nDempster–Shafer evidence theory was ﬁrstly\
    \ proposed by Dempster [5] and was then further\ndeveloped by Shafer [6]. Dempster–Shafer\
    \ evidence theory, as a generalization of Bayesian inference,\nasks for weaker\
    \ conditions, which makes it more ﬂexible and effective to model both the uncertainty\n\
    and imprecision. The basic concepts are introduced as below.\nDeﬁnition 1. Let\
    \ U be a set of mutually exclusive and collectively exhaustive events, indicated\
    \ by\nU = {C1, C2, . . . , Ci, . . . , CN}.\n(1)\nThe set U is called frame of\
    \ discernment. The power set of U is indicated by 2U, where\n2U = {∅, {C1}, {C2},\
    \ . . . , {CN}, {C1, C2}, . . . , {C1, C2, . . . , Ci}, . . . , U},\n(2)\nand\
    \ ∅ is an empty set. If A ∈ 2U, A is called a proposition or hypothesis.\nDeﬁnition\
    \ 2. For a frame of discernment U, a mass function is a mapping m from 2U to [0,\
    \ 1], formally defined by\nm : 2U → [0, 1],\n(3)\nwhich satisﬁes the following\
    \ condition:\nm(∅) = 0 and ∑\nA∈2U\nm(A) = 1.\n(4)\nIn Dempster–Shafer evidence\
    \ theory, a mass function can be also called as a basic probability\nassignment\
    \ (BPA). If m(A) is greater than 0, A will be called as a focal element, and the\
    \ union of all of\nthe focal elements is known as the core of the mass function.\n\
    Deﬁnition 3. For a proposition A ⊆ U, the belief function Bel : 2U → [0, 1] is\
    \ deﬁned as\nBel(A) = ∑\nB⊆A\nm(B).\n(5)\nThe plausibility function Pl : 2U →\
    \ [0, 1] is deﬁned as\nPl(A) = 1 − Bel( ¯A) =\n∑\nB∩A̸=∅\nm(B),\n(6)\nSensors\
    \ 2018, 18, 1487\n4 of 20\nwhere ¯A = U − A.\nApparently, Pl(A) is equal or greater\
    \ than Bel(A), where the function Bel is the lower limit\nfunction of proposition\
    \ A and the function Pl is the upper limit function of proposition A.\nDeﬁnition\
    \ 4. Let the two BPAs be m1 and m2 on the frame of discernment U. Assuming that\
    \ these BPAs\nare independent, Dempster’s rule of combination, denoted by m =\
    \ m1 ⊕ m2, known as the orthogonal sum, is\ndeﬁned as below:\nm(A) =\n\n\n\n\
    1\n1−K\n∑\nB∩D=A\nm1(B)m2(D),\nA ̸= ∅,\n0,\nA = ∅,\n(7)\nwith\nK =\n∑\nB∩D=∅\n\
    m1(B)m2(D),\n(8)\nwhere B and D are also the elements of 2U, and K is a constant\
    \ that presents the conﬂict between the two BPAs.\nNote that Dempster’s combination\
    \ rule is only practicable for the two BPAs with the condition\nK < 1.\n2.3. Modiﬁed\
    \ Cosine Similarity Measure of BPAs\nA modiﬁed cosine similarity measure is proposed\
    \ by Jiang [42]. Because it considers three\nimportant factors, namely, angle,\
    \ distance, and vector norm, the modiﬁed cosine similarity measure is\nan efﬁcient\
    \ approach to measure the similarity between vectors more precisely. The modiﬁed\
    \ cosine\nsimilarity measure among the BPAs can determine whether the pieces of\
    \ evidence conﬂict with each\nother. A large similarity indicates that this piece\
    \ of evidence has more support from another piece of\nevidence, while a small\
    \ similarity indicates that this piece of evidence has less support from another\n\
    piece of evidence.\nDeﬁnition 5. Let E = [e1, e2, . . . , en] and F = [ f1, f2,\
    \ . . . , fn] be two vectors of Rn. The modiﬁed cosine\nsimilarity between vectors\
    \ E and F is deﬁned as\nSI(E, F) =\n(\n1\n2{α−P + min( |E|\n|F|, |F|\n|E|)}sicos(E,\
    \ F),\nE ̸= 0, F ̸= 0,\n0,\nE = 0 or F = 0,\n(9)\nwhere α is a constant whose\
    \ value is greater than 1, P is the Euclidean distance between the two vectors\
    \ E and F,\nα−P is the distance-based similarity measure, min( |E|\n|F|, |F|\n\
    |E|) is the minimum of |E|\n|F| and |F|\n|E|, and sicos(E, F) is the\ncosine similarity.\
    \ The larger the α is, the greater the distance impact on vector similarity will\
    \ be.\nDeﬁnition 6. Let m1 and m2 be the BPAs in the frame of discernment U =\
    \ {C1, C2, . . . , CN}. The two vectors\nare expressed as\nBeli = [Beli(C1), Beli(C2),\
    \ . . . , Beli(CN)],\ni = 1, 2,\nPli = [Pli(C1), Pli(C2), . . . , Pli(CN)],\n\
    i = 1, 2.\n(10)\nThen, the belief function vector similarity SI(Bel1, Bel2) and\
    \ the plausibility function vector similarity\nSI(Pl1, Pl2) can be calculated.\
    \ The new similarity of BPAs is deﬁned as\nSIBPA = (1 − λ) ∗ SI(Bel1, Bel2) +\
    \ λ ∗ SI(Pl1, Pl2),\n(11)\nwith\n0 ≤ λ ≤ 1,\n(12)\nSensors 2018, 18, 1487\n5 of\
    \ 20\nwhere λ is the total uncertainty of BPAs, which is deﬁned as\nλ =\n2\n∑\n\
    i=1\nN\n∑\nj=1\n(Pli(Cj) − Beli(Cj))\n2\n∑\ni=1\nN\n∑\nj=1\n(Pli(Cj))\n.\n(13)\n\
    Because Pli(Cj) ≥ Beli(Cj) and Bel ≥ 0, if Pli(Cj) = Beli(Cj), then λ = 0. Otherwise,\
    \ if Beli(Cj) =\n0, then λ = 1. The larger the uncertainty λ is, the greater the\
    \ inﬂuence on the similarity of BPA will be.\n2.4. Belief Entropy\nA novel type\
    \ of belief entropy, known as the Deng entropy, was ﬁrst proposed by Deng [43].\n\
    When the uncertain information is expressed by probability, the Deng entropy degenerates\
    \ to the\nShannon entropy. Hence, the Deng entropy is regarded as a generalization\
    \ of the Shannon entropy.\nIt is an efﬁcient mathematical tool to measure the\
    \ uncertain information, especially when the uncertain\ninformation is expressed\
    \ by the BPA. Because of its advantage in measuring the uncertain information,\n\
    the Deng entropy is applied in a variety of areas [57,58]. The basic concepts\
    \ are introduced below.\nDeﬁnition 7. Let B be a hypothesis or proposition of\
    \ the BPA m in the frame of discernment U and |B| be the\ncardinality of B. The\
    \ Deng entropy of the BPA m is deﬁned as follows:\nEd(m) = − ∑\nB⊆U\nm(B) log\n\
    m(B)\n2|B| − 1.\n(14)\nWhen the belief value is only allocated to the singleton,\
    \ the Deng entropy degenerates to the Shannon\nentropy, i.e.,\nEd(m) = − ∑\nB∈U\n\
    m(B) log\nm(B)\n2|B| − 1 = − ∑\nB∈U\nm(B) log m(B).\n(15)\nThe larger the value\
    \ of the cardinality of the hypothesis or proposition, the larger the value\n\
    the Deng entropy of evidence, which means that the piece of evidence involves\
    \ more information.\nTherefore, if a piece of evidence has a large Deng entropy\
    \ value, it has more support from other pieces\nof evidence, indicating that this\
    \ piece of evidence plays an important role in the evidence combination.\n3. The\
    \ Proposed Method\nIn this paper, a weighted combination method for conﬂicting\
    \ pieces of evidence multi-sensor data\nfusion is proposed by combining the modiﬁed\
    \ cosine similarity measure of evidence with the belief\nentropy function. In\
    \ contrast to the method of Jiang et al. [42], in the proposed method, the impact\
    \ of\nevidence itself is considered in the process of fusion of multiple pieces\
    \ of evidence by leveraging the\nbelief entropy [43], i.e., a useful uncertainty\
    \ measure tool, to measure the information volume of each\npiece of evidence,\
    \ so that the proposed method can combine multiple pieces of evidence with greater\n\
    accuracy. This will be discussed further in the next section.\n3.1. Process Steps\n\
    The proposed method is composed of the following procedures. The credibility degree\
    \ of the\npieces of evidence is ﬁrst determined on the basis of the similarity\
    \ measure among the BPAs. Then,\nthe credibility degree is modiﬁed by leveraging\
    \ the belief entropy function to measure the information\nvolume of the evidence.\
    \ Afterwards, the ﬁnal weight of each piece of evidence is obtained and adopted\n\
    to adjust the body of evidence before using Dempster’s combination rule. The speciﬁc\
    \ calculation\nprocesses are listed as follows. The ﬂowchart of the proposed method\
    \ is shown in Figure 1.\nSensors 2018, 18, 1487\n6 of 20\nStep 3: Calculate the\
    \ credibility degrees of the pieces of evidence.\nStep 1: Measure the similarities\
    \ between the pieces of evidence.\nStep 2: Obtain the support degrees of the pieces\
    \ of evidence.\nStep 4: Measure the information volume of the pieces of evidence.\n\
    Step 7: Normalise the modified credibility degrees of the pieces of evidence.\n\
    Step 5:  Normalise the information volume of the pieces of evidence.\nStep 6:\
    \ Modify the credibility degrees of the pieces of evidence.\nStep 8:  Obtain the\
    \ weighted average evidence.\nStep 9: Fuse the multiple weighted average pieces\
    \ of evidence.\nFigure 1. The ﬂowchart of the proposed method.\nStep 1: Measure\
    \ the similarities between the pieces of evidence.\nThe similarity measure SIBPA(ij)\
    \ between the BPAs mi and mj can be obtained by\nEquations (11)–(13). Then, a\
    \ similarity measure matrix (SMM) can be constructed as follows:\nSMM =\n\n\n\
    SIBPA(11)\n· · ·\nSIBPA(1i)\n· · ·\nSIBPA(1k)\n...\n...\n...\n...\n...\nSIBPA(i1)\n\
    · · ·\nSIBPA(ii)\n· · ·\nSIBPA(ik)\n...\n...\n...\n...\n...\nSIBPA(k1)\n· · ·\n\
    SIBPA(ki)\n· · ·\nSIBPA(kk)\n\n\n.\n(16)\nStep 2: Obtain the support degrees\
    \ of the pieces of evidence.\nThe support degree of the BPA mi (i = 1, . . . ,\
    \ k), denoted as SD(mi), is deﬁned as follows:\nSD(mi) =\nk\n∑\nj=1,j̸=i\nSIBPA(ij).\n\
    (17)\nStep 3: Calculate the credibility degrees of the pieces of evidence.\nThe\
    \ credibility degree of the BPA mi (i = 1, . . . , k), denoted as CD(mi), is deﬁned\
    \ as follows:\nCD(mi) =\nSD(mi)\n∑k\nl=1 SD(ml)\n.\n(18)\nSensors 2018, 18, 1487\n\
    7 of 20\nStep 4: Measure the information volume of the pieces of evidence.\nAccording\
    \ to Equation (14), the belief entropy Ed(mi) of the BPA mi (i = 1, . . . , k)\
    \ can be calculated.\nTo avoid assigning zero weight to the evidence, the information\
    \ volume IV(mi) is used for measuring\nthe uncertain information of mi. It is\
    \ deﬁned as follows:\nIV(mi) = eEd(mi) = e\n− ∑B⊆U m(B) log\nm(B)\n2|B|−1 .\n\
    (19)\nStep 5: Normalize the information volume of the pieces of evidence.\nThe\
    \ information volume of the BPA mi (i = 1, . . . , k) will be normalized as below:\n\
    IV(mi) =\nIV(mi)\n∑k\nl=1 IV(ml)\n.\n(20)\nStep 6: Modify the credibility degrees\
    \ of the pieces of evidence.\nBased on the normalized information volume, the\
    \ credibility degree of the BPA mi (i = 1, . . . , k)\nwill be modiﬁed, denoted\
    \ as MCD(mi):\nMCD(mi) = CD(mi) × IV(mi)(\n∑k\nl=1 CD(ml)\nk\n−CD(mi)).\n(21)\n\
    Step 7: Normalize the modiﬁed credibility degrees of the pieces of evidence.\n\
    The modiﬁed credibility degree MCD(mi) of the BPA mi (i = 1, . . . , k) will be\
    \ normalized as\nbelow, and is considered as the ﬁnal weight to adjust the bodies\
    \ of evidence.\nMCD(mi) =\nMCD(mi)\n∑k\nl=1 MCD(ml)\n.\n(22)\nStep 8: Obtain the\
    \ weighted average evidence.\nBased on the modiﬁed credibility degree of the BPA\
    \ mi (i = 1, . . . , k), the weighted average\nevidence WAE(m) is deﬁned as follows:\n\
    WAE(m) =\nk\n∑\ni=1\n(MCD(mi) × mi).\n(23)\nStep 9: Fuse multiple weighted average\
    \ pieces of evidence.\nWhen k number of pieces of evidence exist, the weighted\
    \ average evidence will be fused through\nDempster’s combination rule Equation\
    \ (7) via k − 1 times as below,\nFus(m) = (((WAE(m) ⊕ WAE(m))1 ⊕ · · · )h ⊕ WAE(m))(k−1).\n\
    (24)\nUltimately, we can obtain the ﬁnal fusion result of the evidence.\n3.2.\
    \ Algorithm\nLet m = {m1, . . . , mi, . . . , mk} be a set of multiple pieces\
    \ of evidence. After receiving k pieces of\nevidence, a fusion result is expected\
    \ to be generated for decision-making support. The weighted fusion\nmethod for\
    \ multiple pieces of evidence is outlined in Algorithm 1.\nAs shown in Algorithm\
    \ 1, it provides a formal expression in terms of the speciﬁc calculation\nprocesses\
    \ of the proposed method listed in Section 3.1. To be speciﬁc, Lines 2–7 explain\
    \ how to measure\nthe similarities between the pieces of evidence and construct\
    \ the similarity measure matrix for k pieces\nof evidence. Lines 9–11 show how\
    \ to obtain the support degrees for k pieces of evidence. Lines 13–15\nrepresent\
    \ how to calculate the credibility degrees for k pieces of evidence. Lines 17–19\
    \ explain how to\nmeasure the information volumes for k pieces of evidence. Lines\
    \ 21–23 express how to normalize the\ninformation volumes for k pieces of evidence.\
    \ Lines 25–27 state how to modify the credibility degrees\nSensors 2018, 18, 1487\n\
    8 of 20\nfor k pieces of evidence. Lines 29–31 show how to normalize the modiﬁed\
    \ credibility degrees for k\npieces of evidence. Line 33 describes how to obtain\
    \ the weighted average evidence based on k pieces\nof evidence. Lines 35–37 depict\
    \ how to generate the fusion result.\nAlgorithm 1: A weighted fusion method for\
    \ multiple pieces of evidence.\nInput: A set of multiple pieces of evidence m\
    \ = {m1, . . . , mi, . . . , mk};\nOutput: Fusion result Fus(m);\n1 /* Step 1\
    \ */\n2 for i = 1; i ≤ k do\n3\nfor j = 1; j ≤ k do\n4\nCalculate SIBPA(ij) with\
    \ Equations (11)–(13);\n5\nend\n6 end\n7 Construct the similarity measure matrix\
    \ SMM;\n8 /* Step 2 */\n9 for i = 1; i ≤ k do\n10\nObtain the support degree SD(mi)\
    \ with Equation (17);\n11 end\n12 /* Step 3 */\n13 for i = 1; i ≤ k do\n14\nCalculate\
    \ the credibility degree CD(mi) with Equation (18);\n15 end\n16 /* Step 4 */\n\
    17 for i = 1; i ≤ k do\n18\nMeasure the information volume IV(mi) with Equation\
    \ (19);\n19 end\n20 /* Step 5 */\n21 for i = 1; i ≤ k do\n22\nNormalise the information\
    \ volume IV(mi) with Equation (20);\n23 end\n24 /* Step 6 */\n25 for i = 1; i\
    \ ≤ k do\n26\nObtain the modiﬁed credibility degree MCD(mi) with Equation (21);\n\
    27 end\n28 /* Step 7 */\n29 for i = 1; i ≤ k do\n30\nNormalise the modiﬁed credibility\
    \ degree MCD(mi) with Equation (22)\n31 end\n32 /* Step 8 */\n33 Obtain the weighted\
    \ average evidence WAE(m) with Equation (23);\n34 /* Step 9 */\n35 for h = 1;\
    \ h ≤ k − 1 do\n36\nCalculate the fusion result Fus(m) by combining WAE(m) with\
    \ Equation (7);\n37 end\n4. Numerical Example\nIn this section, in order to demonstrate\
    \ the feasibility and effectiveness of the proposed method,\na numerical example\
    \ is illustrated.\nSensors 2018, 18, 1487\n9 of 20\nExample 1. Consider the decision-making\
    \ problem of the multi-sensor-based target recognition system from [59]\nassociated\
    \ with ﬁve different kinds of sensors to observe objects, where U = {a, b, c}.\
    \ Here, a, b, and c are the\nthree objects in the frame of discernment U. The\
    \ ﬁve BPAs that are collected by the system are listed as shown in\nTable 1.\n\
    Table 1. The basic probability assignments (BPAs) for the example.\nPieces of\
    \ Evidence\nBPAs\n{a}\n{b}\n{c}\n{a, b, c}\nm1(·)\n0.30\n0.20\n0.10\n0.40\nm2(·)\n\
    0.00\n0.90\n0.10\n0.00\nm3(·)\n0.60\n0.10\n0.10\n0.20\nm4(·)\n0.70\n0.10\n0.10\n\
    0.10\nm5(·)\n0.70\n0.10\n0.10\n0.10\nStep 1:\nThe similarity measure SIBPA(ij)\
    \ (i, j = 1, 2, 3, 4, 5) between the BPAs mi and mj can be\nconstructed as below:\n\
    SMM =\n\n\n\n\n\n\n\n1.0000\n0.3730\n0.8144\n0.7478\n0.7478\n0.3730\n1.0000\n\
    0.1958\n0.1568\n0.1568\n0.8144\n0.1958\n1.0000\n0.9340\n0.9340\n0.7478\n0.1568\n\
    0.9340\n1.0000\n1.0000\n0.7478\n0.1568\n0.9340\n1.0000\n1.0000\n\n\n\n\n\n\
    \n\n.\nStep 2:\nThe support degree SD(m) of the BPA mi (i = 1, 2, 3, 4, 5) is\
    \ calculated as shown in Table 2.\nTable 2. The calculated results in terms of\
    \ support degree, credibility degree, information volume,\nnormalized information\
    \ volume, credibility degree, and modiﬁed credibility degree of BPAs.\nItems\n\
    Pieces of Evidence\nm1\nm2\nm3\nm4\nm5\nSD(m)\n2.6830\n0.8824\n2.8782\n2.8386\n\
    2.8386\nCD(m)\n0.2214\n0.0728\n0.2375\n0.2342\n0.2342\nIV(m)\n19.480\n1.5984\n\
    8.4351\n5.1423\n5.1423\nIV(m)\n0.4895\n0.0402\n0.2119\n0.1292\n0.1292\nMCD(m)\n\
    0.2248\n0.0484\n0.2517\n0.2512\n0.2512\nMCD(m)\n0.2188\n0.0471\n0.2450\n0.2445\n\
    0.2445\nStep 3:\nThe credibility degree CD(m) of the BPA mi (i = 1, 2, 3, 4, 5)\
    \ is obtained as shown in Table 2.\nStep 4:\nThe information volume IV(m) of the\
    \ BPA mi (i = 1, 2, 3, 4, 5) is measured as shown in\nTable 2.\nStep 5:\nThe information\
    \ volume of the BPA mi (i = 1, 2, 3, 4, 5) is normalized as shown in Table 2,\n\
    denoted by IV(m).\nStep 6:\nThe credibility degree MCD(m) of the BPA mi (i = 1,\
    \ 2, 3, 4, 5) is modiﬁed as shown in\nTable 2.\nStep 7:\nThe modiﬁed credibility\
    \ degree MCD(m) of the BPA mi (i = 1, 2, 3, 4, 5) is normalized as\nshown in Table\
    \ 2.\nStep 8:\nThe weighted average evidence WAE(m) is computed as shown in Table\
    \ 3.\nSensors 2018, 18, 1487\n10 of 20\nTable 3. The weighted average evidence\
    \ (WAE(m)) and ﬁnal fusion result (Fus(m)) .\nItems\nBPAs\n{a}\n{b}\n{c}\n{a,\
    \ b, c}\nWAE(m)\n0.5550\n0.1596\n0.1000\n0.1854\nFus(m)\n0.9713\n0.0204\n0.0073\n\
    0.0010\nStep 9:\nBy fusing the weighted average evidence via Dempster’s combination\
    \ rule four times, the\nﬁnal fusion result Fus(m) of evidence can be produced\
    \ as shown in Table 3.\nFrom Example 1, it is obvious that m2 highly conﬂicts\
    \ with other pieces of evidence. The fusing\nresults that are obtained by different\
    \ combination approaches are presented in Table 4. In addition, the\ncomparisons\
    \ of target a’s BPA in terms of different combination rules are shown in Figure\
    \ 2.\nTable 4. Evidence fusion results based on different combination rules.\n\
    Evidences\nMethods\nBPAs\nTarget\n{a}\n{b}\n{c}\n{a, b, c}\nm1, m2\nDempster [5]\n\
    0.0000\n0.9153\n0.0847\n0.0000\nb\nMurphy [40]\n0.1187\n0.7518\n0.0719\n0.0576\n\
    b\nDeng et al. [41]\n0.1187\n0.7518\n0.0719\n0.0576\nb\nQian et al. [59]\n0.1187\n\
    0.7518\n0.0719\n0.0576\nb\nProposed method\n0.1187\n0.7518\n0.0719\n0.0576\nb\n\
    m1, m2, m3\nDempster [5]\n0.0000\n0.9153\n0.0847\n0.0000\nb\nMurphy [40]\n0.3324\n\
    0.5909\n0.0540\n0.0227\nb\nDeng et al. [41]\n0.4477\n0.4546\n0.0644\n0.0333\n\
    -\nQian et al. [59]\n0.6110\n0.2861\n0.0659\n0.0370\na\nProposed method\n0.5779\n\
    0.3070\n0.0714\n0.0438\na\nm1, m2, m3, m4\nDempster [5]\n0.0000\n0.9153\n0.0847\n\
    0.0000\nb\nMurphy [40]\n0.6170\n0.3505\n0.0272\n0.0053\na\nDeng et al. [41]\n\
    0.8007\n0.1640\n0.0283\n0.0070\na\nQian et al. [59]\n0.8472\n0.1221\n0.0249\n\
    0.0058\na\nProposed method\n0.8785\n0.0857\n0.0271\n0.0076\na\nm1, m2, m3, m4,\
    \ m5\nDempster [5]\n0.0000\n0.9153\n0.0847\n0.0000\nb\nMurphy [40]\n0.8389\n0.1502\n\
    0.0099\n0.0010\na\nDeng et al. [41]\n0.9499\n0.0411\n0.0080\n0.0010\na\nQian et\
    \ al. [59]\n0.9525\n0.0393\n0.0074\n0.0008\na\nProposed method\n0.9713\n0.0204\n\
    0.0073\n0.0010\na\nAs shown in Table 4, no matter how many pieces of evidence\
    \ support target a, Dempster’s\ncombination method [5] always generates a counterintuitive\
    \ result. As the number of pieces of evidence\nincreases to three, Murphy’s combination\
    \ method [40] and Deng et al.’s combination method [41]\ncannot deal with the\
    \ highly conﬂicting pieces of evidence very well, because the BPA values of object\
    \ a\ngenerated by Murphy’s method [40] and Deng et al.’s method [41] are 33.24%\
    \ and 44.77%, respectively,\nwhich are smaller than 50%. When the number of pieces\
    \ of evidence increases from four to ﬁve,\nMurphy’s combination method [40] and\
    \ Deng et al.’s combination method [41] work well, and the\nBPA values of object\
    \ a generated by Murphy’s method [40] and Deng et al.’s method [41] increase up\n\
    to 83.89% and 94.99%, respectively.\nOn the other hand, as shown in Table 4, Qian\
    \ et al.’s combination method [59] and the proposed\nmethod show reasonable results\
    \ and can efﬁciently deal with the highly conﬂicting pieces of evidence\nas the\
    \ number of pieces of evidence increases from three to ﬁve. In the face of ﬁve\
    \ pieces of evidence,\nthe BPA value of object a generated by the proposed method\
    \ increases to 97.13% which is much higher\nSensors 2018, 18, 1487\n11 of 20\n\
    than for other combination approaches, as shown in Figure 2. Therefore, it is\
    \ concluded that the\nproposed method is as feasible and effective as related\
    \ approaches.\n0\n0.8389\n0.9499 0.9525 0.9713\n0.00\n0.25\n0.50\n0.75\n1.00\n\
    5\nBPA\nThe number of pieces of evidence\nDempster\nMurphy\nYong et al.\nQian\
    \ et al.\nProposed method\nFigure 2. The comparisons of target a’s BPA in terms\
    \ of different methods.\n5. Statistical Experiment\nIn this section, in order\
    \ to make a sound comparison, a statistical experiment is carried out with\nmultiple\
    \ pieces of initial data for the comparison of the proposed method with other\
    \ related methods.\nThis statistical experiment is implemented based on Example\
    \ 1. In the experimental setting,\nfor generating multiple initial data 100 times,\
    \ we provide a variation range [−0.1, 0.1] for each BPA of\nm1, and vary the values\
    \ of BPAs of m1 randomly.\nThen, the generated multiple pieces of initial data\
    \ are fused by utilizing the different methods,\nnamely, Dempster’s combination\
    \ method [5], Murphy’s combination method [40], Deng et al.’s\ncombination method\
    \ [41], Jiang et al.’s combination method [42], and the proposed method.\nThe\
    \ experimental results of target a’s BPA generated by different combination methods\
    \ are shown\nin Figure 3. From the comparison results, it is obvious that Murphy’s\
    \ combination method [40],\nDeng et al.’s combination method [41], Jiang et al.’s\
    \ combination method [42], and the proposed\nmethod are more efﬁcient than Dempster’s\
    \ combination method [5], because Dempster’s combination\nmethod cannot effectively\
    \ deal with the conﬂicting pieces of evidence, and thus always generates\ncounterintuitive\
    \ results where target a’s BPA value is 0 (under 0.5). In contrast, the other\
    \ methods can\neffectively cope with the conﬂicting evidence and recognize the\
    \ target a, where its corresponding BPA\nvalue is always larger than 0.5 under\
    \ multiple experiments. On the other hand, because Murphy’s\ncombination method\
    \ is a simply average-weighted approach to the bodies of evidence, its overall\n\
    performance is poorer than that of Deng et al.’s combination method, Jiang et\
    \ al.’s combination method,\nand the proposed method to a certain extent.\nFurthermore,\
    \ as shown in Figure 3a, Jiang et al.’s combination method [42] which is based\
    \ on the\nmodiﬁed cosine similarity measure, is more effective than Deng et al.’s\
    \ combination method [41] that\nis based on the Jousselme distance as a whole.\
    \ This is the reason that the modiﬁed cosine similarity\nmeasure is considered\
    \ in this study.\nIn order to improve the performance of Jiang et al.’s combination\
    \ method, we investigate and\nﬁnd that in the process of fusion of multiple pieces\
    \ of evidence, the impact of the evidence itself is\noverlooked in their method.\
    \ Hence, we also take the belief entropy into consideration to measure\nthe information\
    \ volume of each piece of evidence in the course of fusion and design the proposed\n\
    method. Consequently, as shown in Figure 3b, it can be noted that the proposed\
    \ method is superior to\nJiang et al.’s combination method [42] with a higher\
    \ target a BPA value.\nSensors 2018, 18, 1487\n12 of 20\n0\n20\n40\n60\n80\n100\n\
    Experiment times\n0\n0.2\n0.4\n0.6\n0.8\n1\nBPA\nDempster\nMurphy\nDeng et al.\n\
    Jiang et al.\nProposed method\n0\n20\n40\n60\n80\n100\n(a)\n0.9\n0.95\n1\n0\n\
    20\n40\n60\n80\n100\n(b)\n0.9\n0.95\n1\nFigure 3. The comparisons of target a’s\
    \ BPAs obtained by different combination methods where the\nmultiple BPAs are\
    \ generated randomly 100 times. (a) The comparisons of Deng et al.’s combination\n\
    method and Jiang et al.’s combination method; (b) The comparisons of Jiang et\
    \ al.’s combination\nmethod and the proposed method.\n6. Applications\nIn this\
    \ section, the proposed approach is applied to Iris data set classiﬁcation and\
    \ motor rotor\nfault diagnosis, respectively, to validate its practicability,\
    \ in which the experimental data in [48,59] are\nleveraged for the comparison\
    \ among different approaches.\n6.1. Iris Data Set Classiﬁcation\nConsider the\
    \ Iris data set classification problem associated with a frame of discernment\
    \ U consisting of\nthree species of Iris flowers given by U = {setosa, versicolor,\
    \ virginica} = {Se,Ve,Vi} in terms of four numerical\nattributes of Iris flowers\
    \ given by {sepal length (SL), sepal width (SW), petal length (PL), petal width\
    \ (PW)},\nwhere the BPAs of Iris instances are modeled with noisy data and given\
    \ in Table 5 from [59].\nTable 5. The BPAs of Iris ﬂower instances.\nBPAs\nAttributes\n\
    {SL}\n{SW}\n{PL}\n{PW}\nm{Se}\n0.3337\n0.0000\n0.6699\n0.6996\nm{Ve}\n0.3165\n\
    0.9900\n0.2374\n0.2120\nm{Vi}\n0.2816\n0.0100\n0.0884\n0.0658\nm{Se, Ve}\n0.0307\n\
    0.0000\n0.0000\n0.0000\nm{Se, Vi}\n0.0052\n0.0000\n0.0000\n0.0000\nm{Ve, Vi}\n\
    0.0272\n0.0000\n0.0043\n0.0226\nm{Se, Ve, Vi}\n0.0052\n0.0000\n0.0000\n0.0000\n\
    Step 1:\nThe similarity measure SIBPA(ij) (i, j = SL, SW, PL, PW) between the\
    \ BPAs mi and mj can\nbe constructed as below:\nSMM =\n\n\n\n\n\n1.0000\n\
    0.3324\n0.7965\n0.7750\n0.3324\n1.0000\n0.2056\n0.1794\n0.7965\n0.2056\n1.0000\n\
    0.9867\n0.7750\n0.1794\n0.9867\n1.0000\n\n\n\n\n .\nSensors 2018, 18, 1487\n\
    13 of 20\nStep 2:\nThe support degree of the BPA mi (i = SL, SW, PL, PW) is calculated\
    \ as follows:\nSD(mSL) = 1.9039,\nSD(mSW) = 0.7174,\nSD(mPL) = 1.9888,\nSD(mPW)\
    \ = 1.9411.\nStep 3:\nThe credibility degree of the BPA mi (i = SL, SW, PL, PW)\
    \ is obtained as below:\nCD(mSL) = 0.2906,\nCD(mSW) = 0.1095,\nCD(mPL) = 0.3036,\n\
    CD(mPW) = 0.2963.\nStep 4:\nThe information volume of the BPA mi (i = SL, SW,\
    \ PL, PW) is measured as follows:\nIV(mSL) = 7.8287,\nIV(mSW) = 1.0842,\nIV(mPL)\
    \ = 3.4202,\nIV(mPW) = 3.4998.\nStep 5:\nThe information volume of the BPA mi\
    \ (i = SL, SW, PL, PW) is normalised as follows:\nIV(mSL) = 0.4945,\nIV(mSW) =\
    \ 0.0685,\nIV(mPL) = 0.2160,\nIV(mPW) = 0.2210.\nStep 6:\nThe credibility degree\
    \ of the BPA mi (i = SL, SW, PL, PW) is modiﬁed as below:\nMCD(mSL) = 0.2991,\n\
    MCD(mSW) = 0.0751,\nMCD(mPL) = 0.3296,\nMCD(mPW) = 0.3177.\nStep 7:\nThe modiﬁed\
    \ credibility degree of the BPA mi (i = SL, SW, PL, PW) is normalized as\nfollows:\n\
    MCD(mSL) = 0.2928,\nMCD(mSW) = 0.0736,\nMCD(mPL) = 0.3226,\nMCD(mPW) = 0.3111.\n\
    Step 8:\nThe weighted average evidence is computed as below:\nm({Se}) = 0.5314,\n\
    m({Ve}) = 0.3080,\nm({Vi}) = 0.1322,\nm({Se, Ve}) = 0.0090,\nm({Se, Vi}) = 0.0015,\n\
    m({Ve, Vi}) = 0.0164,\nm({Se, Ve, Vi}) = 0.0015.\nStep 9:\nBy fusing the weighted\
    \ average evidence via Dempster’s combination rule four times, the\nﬁnal fusion\
    \ result of the evidence can be produced as follows:\nm({Se}) = 0.8693,\nm({Ve})\
    \ = 0.1254,\nm({Vi}) = 0.0053,\nm({Se, Ve}) = 1 × 10−7,\nm({Se, Vi}) = 7 × 10−10,\n\
    m({Ve, Vi}) = 1 × 10−6,\nm({Se, Ve, Vi}) = 5 × 10−11.\nSensors 2018, 18, 1487\n\
    14 of 20\nThe fusion results based on different combination approaches that were\
    \ applied on the Iris data\nset are presented in Table 6. From the experimental\
    \ results, it can be seen that Dempster’s combination\nmethod [5] and Murphy’s\
    \ combination method [40] always generate counterintuitive results and\nclassify\
    \ the species of Iris ﬂower as versicolor, even when the number of pieces of evidence\
    \ increases\nfrom two (mSL, mSW) to four (mSL, mSW, mPL, mPW). By contrast, Deng\
    \ et al.’s combination method [41]\nworks well when the number of pieces of evidence\
    \ is increased up to four (mSL, mSW, mPL, mPW),\nbecause it can classify the species\
    \ of Iris ﬂower as the target setosa with a belief value of 73.01%.\nTable 6.\
    \ The comparison of different methods applied in the Iris data set classiﬁcation.\n\
    Evidence\nMethods\nBPAs\nTarget\n{Se}\n{Ve}\n{Vi}\n{Se, Ve}\n{Se, Vi}\n{Ve, Vi}\n\
    {Se, Ve, Vi}\nmSL, mSW\nDempster [5]\n0.0000\n0.9916\n0.0084\n0.0000\n0.0000\n\
    0.0000\n0.0000\nVe\nMurphy [40]\n0.0655\n0.8828\n0.0505\n6 × 10−4\n4 × 10−5\n\
    5 × 10−4\n1 × 10−5\nVe\nDeng et al. [41]\n0.0655\n0.8828\n0.0505\n6 × 10−4\n4\
    \ × 10−5\n5 × 10−4\n1 × 10−5\nVe\nQian et al. [59]\n0.0655\n0.8828\n0.0505\n6\
    \ × 10−4\n4 × 10−5\n5 × 10−4\n1 × 10−5\nVe\nProposed method\n0.0655\n0.8828\n\
    0.0505\n6 × 10−4\n4 × 10−5\n5 × 10−4\n1 × 10−5\nVe\nmSL, mSW, mPL\nDempster [5]\n\
    0.0000\n0.9968\n0.0032\n0.0000\n0.0000\n0.0000\n0.0000\nVe\nMurphy [40]\n0.2112\n\
    0.7749\n0.0139\n8 × 10−6\n2 × 10−7\n9 × 10−6\n3 × 10−8\nVe\nDeng et al. [41]\n\
    0.3219\n0.6534\n0.0247\n2 × 10−5\n4 × 10−7\n2 × 10−5\n5 × 10−8\nVe\nQian et al.\
    \ [59]\n0.5678\n0.4036\n0.0287\n2 × 10−5\n4 × 10−7\n2 × 10−5\n5 × 10−8\nSe\nProposed\
    \ method\n0.5206\n0.4421\n0.0372\n2 × 10−5\n5 × 10−7\n2 × 10−5\n7 × 10−8\nSe\n\
    mSL, mSW, mPL, mPW\nDempster [5]\n0.0000\n0.9988\n0.0012\n0.0000\n0.0000\n0.0000\n\
    0.0000\nVe\nMurphy [40]\n0.4422\n0.5546\n0.0032\n8 × 10−8\n5 × 10−10\n6 × 10−7\n\
    3 × 10−11\nVe\nDeng et al. [41]\n0.7301\n0.2652\n0.0047\n1 × 10−7\n7 × 10−10\n\
    9 × 10−7\n5 × 10−11\nSe\nQian et al. [59]\n0.8338\n0.1617\n0.0045\n9 × 10−8\n\
    6 × 10−10\n9 × 10−7\n4 × 10−11\nSe\nProposed method\n0.8693\n0.1254\n0.0053\n\
    1 × 10−7\n7 × 10−10\n1 × 10−6\n5 × 10−11\nSe\nObviously, Qian et al.’s combination\
    \ method [59] and the proposed method show reasonable\nresults and classify the\
    \ species of Iris ﬂower as the target setosa with 83.38% and 86.93% belief values,\n\
    respectively. Therefore, we can conclude that the proposed method is more efﬁcient\
    \ than other related\nmethods with better accuracy of data classiﬁcation, as shown\
    \ in Figure 4. The reason is that the\nproposed method not only takes the interplay\
    \ between the pieces of evidence into account, but also\nconsiders the impacts\
    \ of the pieces of evidence themselves.\n0\n0.4422\n0.7301\n0.8338 0.8693\n0.00\n\
    0.25\n0.50\n0.75\n1.00\n4\nBPA\nThe number of pieces of evidence\nDempster\nMurphy\n\
    Yong et al.\nQian et al.\nProposed method\nFigure 4. The comparisons of target\
    \ Se’s BPA in terms of different methods.\n6.2. Motor Rotor Fault Diagnosis\n\
    Supposing there are three types of faults for a motor rotor given by {F1, F2,\
    \ F3} = {rotor unbalance,\nrotor misalignment, pedestal looseness} in the frame\
    \ of discernment U. We place a set of vibration\nacceleration sensors at different\
    \ places for gathering the vibration signals given by S = {S1, S2, S3}.\nSensors\
    \ 2018, 18, 1487\n15 of 20\nThe acceleration vibration frequency amplitudes at\
    \ 1X, 2X, and 3X frequencies are considered as the\nfault feature variables. The\
    \ collected sensor reports at 1X, 2X, and 3X frequencies modeled as BPAs\nare\
    \ shown in Tables 7–9, respectively, in which m1(·), m2(·), and m3(·) represent\
    \ the BPAs modeled\nfrom the three vibration acceleration sensors S1, S2, and\
    \ S3.\nTable 7. The collected sensor reports at the frequency of 1X modeled as\
    \ BPAs.\nBPA\n{F2}\n{F3}\n{F1, F2}\n{F1, F2, F3}\nm1(·)\n0.8176\n0.0003\n0.1553\n\
    0.0268\nm2(·)\n0.5658\n0.0009\n0.0646\n0.3687\nm3(·)\n0.2403\n0.0004\n0.0141\n\
    0.7452\nTable 8. The collected sensor reports at the frequency of 2X modeled as\
    \ BPAs.\nBPA\n{F2}\n{F1, F2, F3}\nm1(·)\n0.6229\n0.3771\nm2(·)\n0.7660\n0.2341\n\
    m3(·)\n0.8598\n0.1402\nTable 9. The collected sensor reports at the frequency\
    \ of 3X modeled as BPAs.\nBPA\n{F1}\n{F2}\n{F1, F2}\n{F1, F2, F3}\nm1(·)\n0.3666\n\
    0.4563\n0.1185\n0.0586\nm2(·)\n0.2793\n0.4151\n0.2652\n0.0404\nm3(·)\n0.2897\n\
    0.4331\n0.2470\n0.0302\n6.2.1. Motor Rotor Fault Diagnosis at 1X Frequency\nBy\
    \ conducting the steps in Section 3, the weighted average evidence with regard\
    \ to motor rotor\nfault diagnosis at 1X frequency is obtained as below:\nm({F2})\
    \ = 0.5442,\nm({F3}) = 0.0006,\nm({F1, F2}) = 0.0773,\nm({F1, F2, F3}) = 0.3780.\n\
    Then, the final fusion results for motor rotor fault diagnosis at 1X frequency\
    \ are computed as follows:\nm({F2}) = 0.9055,\nm({F3}) = 0.0002,\nm({F1, F2})\
    \ = 0.0404,\nm({F1, F2, F3}) = 0.0541.\n6.2.2. Motor Rotor Fault Diagnosis at\
    \ 2X Frequency\nBy carrying out the steps in Section 3, the weighted average evidence\
    \ with respect to motor rotor\nfault diagnosis at 2X frequency is obtained as\
    \ follows:\nm({F2}) = 0.7387,\nm({F1, F2, F3}) = 0.2613.\nAfterwards, the ﬁnal\
    \ fusion results in terms of motor rotor fault diagnosis at 2X frequency are\n\
    generated as below:\nm({F2}) = 0.9822,\nm({F1, F2, F3}) = 0.0178.\nSensors 2018,\
    \ 18, 1487\n16 of 20\n6.2.3. Motor Rotor Fault Diagnosis at 3X Frequency\nBy applying\
    \ the steps in Section 3, the weighted average evidence with respect to motor\
    \ rotor\nfault diagnosis at 3X frequency is obtained as follows:\nm({F1}) = 0.3111,\n\
    m({F2}) = 0.4346,\nm({F1, F2}) = 0.2115,\nm({F1, F2, F3}) = 0.0428.\nThen, the\
    \ final combination results for motor rotor fault diagnosis at 3X frequency are\
    \ shown below:\nm({F1}) = 0.3345,\nm({F2}) = 0.6321,\nm({F1, F2}) = 0.0333,\n\
    m({F1, F2, F3}) = 0.0001.\nFrom the experimental results as shown in Tables 10–12,\
    \ it can be seen that the proposed method\ndiagnoses the fault type as F2, in\
    \ accordance with Jiang et al.’s method [48].\nFurthermore, the proposed method\
    \ outperforms Jiang et al.’s method [48] in dealing with the\nuncertainty as shown\
    \ in Figures 5–7, because by utilizing the proposed method, the belief degrees\n\
    allocated to the target fault type F2 at 1X frequency, 2X frequency and 3X frequency\
    \ increase up to\n90.55%, 98.22%, and 63.21%, respectively; however, by using\
    \ Jiang et al.’s method [48], the belief\ndegrees allocated to the target F2 at\
    \ 1X frequency, 2X frequency and 3X frequency are 88.61%, 96.21%,\nand 59.04%,\
    \ respectively.\nAdditionally, by utilizing the proposed method, the uncertainty\
    \ {F1, F2} falls from 0.0582 to 0.0541,\nand the uncertainty {F1, F2, F3} falls\
    \ from 0.0555 to 0.0404 at 1X frequency; the uncertainty {F1, F2, F3}\ndecreased\
    \ from 0.0371 to 0.0178 at 2X frequency; the uncertainty {F1, F2} falls from 0.0651\
    \ to 0.0333,\nand the uncertainty {F1, F2, F3} drops from 0.0061 to 0.0001 at\
    \ 3X frequency. As a result, the proposed\nmethod can diagnose motor rotor faults\
    \ more accurately than the related work.\nTable 10. Fusion results by using different\
    \ combination methods at 1X frequency.\nMethod\n{F2}\n{F3}\n{F1, F2}\n{F1, F2,\
    \ F3}\nTarget\nJiang et al. [48]\n0.8861\n0.0002\n0.0582\n0.0555\nF2\nProposed\
    \ method\n0.9055\n0.0002\n0.0404\n0.0541\nF2\nTable 11. Fusion results by using\
    \ different combination methods at 2X frequency.\nMethod\n{F2}\n{F1, F2, F3}\n\
    Target\nJiang et al. [48]\n0.9621\n0.0371\nF2\nProposed method\n0.9822\n0.0178\n\
    F2\nTable 12. Fusion results by using different combination methods at 3X frequency.\n\
    Method\n{F1}\n{F2}\n{F1, F2}\n{F1, F2, F3}\nTarget\nJiang et al. [48]\n0.3384\n\
    0.5904\n0.0651\n0.0061\nF2\nProposed method\n0.3345\n0.6321\n0.0333\n0.0001\n\
    F2\nSensors 2018, 18, 1487\n17 of 20\n0.8861\n0.9055\n0.80\n0.85\n0.90\n0.95\n\
    1.00\n{F2}\nBPA\nJiang et al.\nProposed method\nFigure 5. The comparison of the\
    \ BPA of the target F2 at 1X frequency.\n0.9621\n0.9822\n0.80\n0.85\n0.90\n0.95\n\
    1.00\n{F2}\nBPA\nJiang et al.\nProposed method\nFigure 6. The comparison of the\
    \ BPA of the target F2 at 2X frequency.\n0.5904\n0.6321\n0.00\n0.25\n0.50\n0.75\n\
    1.00\n{F2}\nBPA\nJiang et al.\nProposed method\nFigure 7. The comparison of the\
    \ BPA of the target F2 at 3X frequency.\n7. Conclusions\nIn this paper, a weighted\
    \ combination method for conﬂicting evidence in multi-sensor data\nfusion was\
    \ proposed by combining the modiﬁed cosine similarity measure of the pieces of\
    \ evidence\nwith the belief entropy function. The proposed method was a kind of\
    \ pretreatment of the bodies\nSensors 2018, 18, 1487\n18 of 20\nof evidence, which\
    \ was effective to handle the conﬂicting pieces of evidence in a multi-sensor\n\
    environment. A numerical example was illustrated to show the feasibility and effectiveness\
    \ of the\nproposal. In addition, applications in data classiﬁcation and motor\
    \ rotor fault diagnosis were presented\nto validate the practicability of the\
    \ proposed method, where it outperformed the related methods with\nbetter accuracy.\n\
    Author Contributions:\nF.X. contributed most of the work in this paper. B.Q contributed\
    \ the experiments in\nthis paper.\nFunding:\n“This research was funded by the\
    \ National Natural Science Foundation of China grant numbers\n61672435, 61702427,\
    \ 61702426, and the 1000-Plan of Chongqing by Southwest University grant number\n\
    SWU116007.”\nAcknowledgments: The authors greatly appreciate the reviews’ suggestions\
    \ and the editor’s encouragement.\nConﬂicts of Interest: The authors declare no\
    \ conﬂict of interest.\nReferences\n1.\nJin, X.B.; Sun, Y.X.\nPei-Radman fusion\
    \ estimation algorithm for multisensor system applied in state\nmonitoring. Lect.\
    \ Notes Control Inf. Sci. 2006, 344, 963–968.\n2.\nZadeh, L.A. Fuzzy sets. Inf.\
    \ Control 1965, 8, 338–353. [CrossRef]\n3.\nMardani, A.; Jusoh, A.; Zavadskas,\
    \ E.K.\nFuzzy multiple criteria decision-making techniques and\napplications–Two\
    \ decades review from 1994 to 2014. Expert Syst. Appl. 2015, 42, 4126–4148. [CrossRef]\n\
    4.\nJiang, W.; Wei, B.; Liu, X.; Li, X.; Zheng, H. Intuitionistic fuzzy evidential\
    \ power aggregation operator and\nits application in multiple criteria decision-making.\
    \ Int. J. Syst. Sci. 2018, 49, 582–594. [CrossRef]\n5.\nDempster, A.P. Upper and\
    \ lower probabilities induced by a multivalued mapping. Ann. Math. Stat. 1967,\n\
    38, 325–339. [CrossRef]\n6.\nShafer, G. A mathematical theory of evidence. Technometrics\
    \ 1978, 20, 242. [CrossRef]\n7.\nJiang, W.; Chang, Y.; Wang, S. A method to identify\
    \ the incomplete framework of discernment in evidence\ntheory. Math. Prob. Eng.\
    \ 2017, 2017, doi:10.1155/2017/7635972. [CrossRef]\n8.\nWalczak, B.; Massart,\
    \ D. Rough sets theory. Chem. Intell. Lab. Syst. 1999, 47, 1–16. [CrossRef]\n\
    9.\nGreco, S.; Matarazzo, B.; Slowinski, R. Rough sets theory for multicriteria\
    \ decision analysis. Eur. J. Oper. Res.\n2001, 129, 1–47. [CrossRef]\n10.\nYang,\
    \ J.B.; Xu, D.L. Evidential reasoning rule for evidence combination.\nArtif. Intell.\
    \ 2013, 205, 1–29.\n[CrossRef]\n11.\nFu, C.; Xu, D.L. Determining attribute weights\
    \ to improve solution reliability and its application to selecting\nleading industries.\
    \ Ann. Oper. Res. 2014, 245, 401–426. [CrossRef]\n12.\nZadeh, L.A. A note on Z-numbers.\
    \ Inf. Sci. 2011, 181, 2923–2932. [CrossRef]\n13.\nKang, B.; Chhipi-Shrestha,\
    \ G.; Deng, Y.; Hewage, K.; Sadiq, R. Stable Strategies Analysis Based on the\
    \ Utility\nof Z-number in the Evolutionary Games. Appl. Math. Comput. 2018, 324,\
    \ 202–217. [CrossRef]\n14.\nBian, T.; Zheng, H.; Yin, L.; Deng, Y. Failure mode\
    \ and effects analysis based on D numbers and TOPSIS.\nQual. Reliab. Eng. Int.\
    \ 2018, doi:10.1002/qre.2268. [CrossRef]\n15.\nXiao, F. A novel multi-criteria\
    \ decision making method for assessing health-care waste treatment technologies\n\
    based on D numbers. Eng. Appl. Artif. Intell. 2018, 71, 216–225. [CrossRef]\n\
    16.\nXiao, F. An intelligent complex event processing with D numbers under fuzzy\
    \ environment. Math. Prob. Eng.\n2016, 2016. [CrossRef]\n17.\nDeng, X.; Deng,\
    \ Y. D-AHP method with different credibility of information. Soft Comput. 2018.\
    \ [CrossRef]\n18.\nGao, Y.; Ran, C.J.; Sun, X.J.; Deng, Z.L. Optimal and self-tuning\
    \ weighted measurement fusion Kalman ﬁlters\nand their asymptotic global optimality.\
    \ Int. J. Adapt. Control Signal Process. 2010, 24, 982–1004. [CrossRef]\n19.\n\
    Gao, Y.; Jia, W.J.; Sun, X.J.; Deng, Z.L. Self-tuning multisensor weighted measurement\
    \ fusion Kalman ﬁlter.\nIEEE Trans. Aerosp. Electron. Syst. 2009, 45, 179–191.\n\
    20.\nJin, X.B.; Dou, C.; Su, T.L.; Lian, X.F.; Shi, Y. Parallel irregular fusion\
    \ estimation based on nonlinear ﬁlter for\nindoor RFID tracking system. Int. J.\
    \ Distrib. Sens. Netw. 2016, 2016, 1–11. [CrossRef]\n21.\nZhou, X.; Hu, Y.; Deng,\
    \ Y.; Chan, F.T.S.; Ishizaka, A. A DEMATEL-based completion method for incomplete\n\
    pairwise comparison matrix in AHP. Ann. Oper. Res. 2018. [CrossRef]\nSensors 2018,\
    \ 18, 1487\n19 of 20\n22.\nXu, H.; Deng, Y. Dependent evidence combination based\
    \ on Shearman coefﬁcient and Pearson coefﬁcient.\nIEEE Access 2018, 6, 11634–11640.\
    \ [CrossRef]\n23.\nDutta, P. Uncertainty modeling in risk assessment based on\
    \ Dempster–Shafer theory of evidence with\ngeneralized fuzzy focal elements. Fuzzy\
    \ Inf. Eng. 2015, 7, 15–30. [CrossRef]\n24.\nLiu, T.; Deng, Y.; Chan, F.\nEvidential\
    \ supplier selection based on DEMATEL and game theory.\nInt. J. Fuzzy Syst. 2018,\
    \ 20, 1321–1333. [CrossRef]\n25.\nDenoeux, T. A k-nearest neighbor classiﬁcation\
    \ rule based on Dempster–Shafer theory. IEEE Trans. Syst.\nMan Cybern. 1995, 25,\
    \ 804–813. [CrossRef]\n26.\nLiu, Z.; Quan, P.; Dezert, J.; Han, J.W.; You, H.\
    \ Classiﬁer fusion with contextual reliability evaluation.\nIEEE Trans. Cybern.\
    \ 2017, PP, 1–14. [CrossRef] [PubMed]\n27.\nZheng, X.; Deng, Y. Dependence assessment\
    \ in human reliability analysis based on evidence credibility\ndecay model and\
    \ IOWA operator. Ann. Nuclear Energy 2018, 112, 673–684. [CrossRef]\n28.\nXiao,\
    \ F. A novel evidence theory and fuzzy preference approach-based multi-sensor\
    \ data fusion technique\nfor fault diagnosis. Sensors 2017, 17, 2504. [CrossRef]\
    \ [PubMed]\n29.\nJiang, W.; Wang, S. An uncertainty measure for interval-valued\
    \ evidences. Int. J. Comput. Commun. Control\n2017, 12, 631–644. [CrossRef]\n\
    30.\nXiao, F. An improved method for combining conﬂicting evidences Based on the\
    \ similarity measure and\nbelief function entropy. Int. J. Fuzzy Syst. 2017, 1–11.\
    \ [CrossRef]\n31.\nZheng, H.; Deng, Y. Evaluation method based on fuzzy relations\
    \ between Dempster-Shafer belief structure.\nInt. J. Intell. Syst. 2017, doi:10.1002/int.21956.\
    \ [CrossRef]\n32.\nJiang, W.; Yang, T.; Shou, Y.; Tang, Y.; Hu, W.\nImproved evidential\
    \ fuzzy c-means method.\nJ. Syst. Eng. Electron. 2018, 29, 187–195.\n33.\nZadeh,\
    \ L.A. A simple view of the Dempster–Shafer theory of evidence and its implication\
    \ for the rule of\ncombination. AI Mag. 1986, 7, 85–90.\n34.\nLefevre, E.; Colot,\
    \ O.; Vannoorenberghe, P. Belief function combination and conﬂict management.\
    \ Inf. Fusion\n2002, 3, 149–162. [CrossRef]\n35.\nDeng, X.; Jiang, W. An evidential\
    \ axiomatic design approach for decision making using the evaluation of\nbelief\
    \ structure satisfaction to uncertain target values. Int. J. Intell. Syst. 2018,\
    \ 33, 15–32. [CrossRef]\n36.\nJiang, W.; Hu, W.\nAn improved soft likelihood function\
    \ for Dempster-Shafer belief structures.\nInt. J. Intell. Syst. 2018. [CrossRef]\n\
    37.\nSmets, P. The combination of evidence in the transferable belief model. IEEE\
    \ Trans. Pattern Anal. Mach. Intell.\n1990, 12, 447–458. [CrossRef]\n38.\nDubois,\
    \ D.; Prade, H. Representation and combination of uncertainty with belief functions\
    \ and possibility\nmeasures. Comput. Intell. 1988, 4, 244–264. [CrossRef]\n39.\n\
    Yager, R.R. On the Dempster–Shafer framework and new combination rules. Inf. Sci.\
    \ 1987, 41, 93–137.\n[CrossRef]\n40.\nMurphy, C.K. Combining belief functions\
    \ when evidence conﬂicts.\nDecis. Support Syst. 2000, 29, 1–9.\n[CrossRef]\n41.\n\
    Deng, Y.; Shi, W.; Zhu, Z.; Liu, Q.\nCombining belief functions based on distance\
    \ of evidence.\nDecis. Support Syst. 2004, 38, 489–493.\n42.\nJiang, W.; Wei,\
    \ B.; Qin, X.; Zhan, J.; Tang, Y.\nSensor data fusion based on a new conﬂict measure.\n\
    Math. Prob. Eng. 2016, 2016. [CrossRef]\n43.\nDeng, Y. Deng entropy. Chaos Solitons\
    \ Fractals 2016, 91, 549–553. [CrossRef]\n44.\nKhaleghi, B.; Khamis, A.; Karray,\
    \ F.O.; Razavi, S.N. Multisensor data fusion: A review of the state-of-the-art.\n\
    Inf. Fusion 2013, 14, 28–44. [CrossRef]\n45.\nNiu, G.; Yang, B.S.; Pecht, M. Development\
    \ of an optimized condition-based maintenance system by data\nfusion and reliability-centered\
    \ maintenance. Reliab. Eng. Syst. Saf. 2010, 95, 786–796. [CrossRef]\n46.\nYunusa-Kaltungo,\
    \ A.; Sinha, J.K. Sensitivity analysis of higher order coherent spectra in machine\
    \ faults\ndiagnosis. Struct. Health Monit. 2016, 15, 555–567. [CrossRef]\n47.\n\
    Yunusa-Kaltungo, A.; Sinha, J.K.; Nembhard, A.D.\nA novel fault diagnosis technique\
    \ for enhancing\nmaintenance and reliability of rotating machines. Struct. Health\
    \ Monit. 2015, 14, 231–262. [CrossRef]\n48.\nJiang, W.; Xie, C.; Zhuang, M.; Shou,\
    \ Y.; Tang, Y. Sensor data fusion with Z-numbers and its application in\nfault\
    \ diagnosis. Sensors 2016, 16, 1509. [CrossRef] [PubMed]\nSensors 2018, 18, 1487\n\
    20 of 20\n49.\nAkselrod, D.; Sinha, A.; Kirubarajan, T. Information ﬂow control\
    \ for collaborative distributed data fusion\nand multisensor multitarget tracking.\
    \ IEEE Trans. Syst. Man Cybern. Part C 2012, 42, 501–517. [CrossRef]\n50.\nDallil,\
    \ A.; Oussalah, M.; Ouldali, A. Sensor fusion and target tracking using evidential\
    \ data association.\nIEEE Sens. J. 2013, 13, 285–293. [CrossRef]\n51.\nKashanian,\
    \ H.; Dabaghi, E.\nFeature dimension reduction of multisensor data fusion using\
    \ principal\ncomponent fuzzy analysis. Int. J. Eng. 2017, 30, 493–499.\n52.\n\
    Hernandez-Penaloza, G.; Belmonte-Hernandez, A.; Quintana, M.; Alvarez, F. A Multi-sensor\
    \ Fusion Scheme\nto Increase Life Autonomy of Elderly People with Cognitive Problems.\
    \ IEEE Access 2018, 6, 12775–12789.\n[CrossRef]\n53.\nSantos, E.N.D.; Silva, M.J.D.\
    \ Advanced image processing of wire-mesh sensor data for two-phase ﬂow\ninvestigation.\
    \ IEEE Latin Am. Trans. 2015, 13, 2269–2277. [CrossRef]\n54.\nMohammadi, A.; Yang,\
    \ C.; Chen, Q.W. Attack detection/isolation via a secure multisensor fusion framework\n\
    for cyberphysical systems. Complexity 2018, 2018, 1–8. [CrossRef]\n55.\nSanti,\
    \ F.; Pastina, D.; Bucciarelli, M. Estimation of ship dynamics with a multi-platform\
    \ Radar imaging\nsystem. IEEE Trans. Aerosp. Electron. Syst. 2017, 53, 2769–2788.\
    \ [CrossRef]\n56.\nGeiß, C.; Thoma, M.; Pittore, M.; Wieland, M.; Dech, S.W.;\
    \ Taubenbock, H. Multitask active learning for\ncharacterization of built environments\
    \ with multisensor earth observation data. IEEE J. Sel. Top. Appl. Earth\nObs.\
    \ Remote Sens. 2017, PP, 1–15.\n57.\nZhang, Q.; Li, M.; Deng, Y. Measure the structure\
    \ similarity of nodes in complex networks based on relative\nentropy. Phys. A\
    \ Stat. Mech. Appl. 2018, 491, 749–763. [CrossRef]\n58.\nJiang, W.; Wei, B.; Liu,\
    \ X.; Li, X.; Zheng, H. Intuitionistic fuzzy power aggregation operator based\
    \ on entropy\nand its application in decision making. Int. J. Intell. Syst. 2018,\
    \ 33, 49–67. [CrossRef]\n59.\nQian, J.; Guo, X.; Deng, Y. A novel method for combining\
    \ conﬂicting evidences based on information entropy.\nAppl. Intell. 2017, 46,\
    \ 876–888. [CrossRef]\nc⃝ 2018 by the authors. Licensee MDPI, Basel, Switzerland.\
    \ This article is an open access\narticle distributed under the terms and conditions\
    \ of the Creative Commons Attribution\n(CC BY) license (http://creativecommons.org/licenses/by/4.0/).\n"
  inline_citation: '>'
  journal: Sensors
  limitations: '>'
  pdf_link: https://www.mdpi.com/1424-8220/18/5/1487/pdf?version=1525860529
  publication_year: 2018
  relevance_score1: 0
  relevance_score2: 0
  title: A Weighted Combination Method for Conflicting Evidence in Multi-Sensor Data
    Fusion
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/jsen.2007.894905
  analysis: '>'
  authors:
  - Manish Kumar
  - Devendra P. Garg
  - R. Zachery
  citation_count: 61
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences Typesetting
    math: 100% IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create
    Account Personal Sign In Browse My Settings Help Access provided by: University
    of Nebraska - Lincoln Sign Out All Books Conferences Courses Journals & Magazines
    Standards Authors Citations ADVANCED SEARCH Journals & Magazines >IEEE Sensors
    Journal >Volume: 7 Issue: 5 A Method for Judicious Fusion of Inconsistent Multiple
    Sensor Data Publisher: IEEE Cite This PDF Manish Kumar; Devendra P. Garg; Randy
    A. Zachery All Authors 50 Cites in Papers 1574 Full Text Views Abstract Document
    Sections I. Introduction II. Bayesian Approach for Sensor Fusion III. Multisensor
    Fusion with Spurious Data IV. Fusion of Three Sensors V. Simulation Results Show
    Full Outline Authors Figures References Citations Keywords Metrics Abstract: One
    of the major problems in sensor fusion is that sensors frequently provide spurious
    observations which are difficult to predict and model. The spurious measurements
    from sensors must be identified and eliminated since their incorporation in the
    fusion pool might lead to inaccurate estimation. This paper presents a unified
    sensor fusion strategy based on a modified Bayesian approach that can automatically
    identify the inconsistency in sensor measurements so that the spurious measurements
    can be eliminated from the data fusion process. The proposed method adds a term
    to the commonly used Bayesian formulation. This term is an estimate of the probability
    that the data is not spurious, based upon the measured data and the unknown value
    of the true state. In fusing two measurements, it has the effect of increasing
    the variance of the posterior distribution when measurement from one of the sensors
    is inconsistent with respect to the other. The increase or decrease in variance
    can be estimated using the information theoretic measure "entropy." The proposed
    strategy was verified with the help of extensive computations performed on simulated
    data from three sensors. A comparison was made between two different fusion schemes:
    centralized fusion in which data obtained from all sensors were fused simultaneously,
    and a decentralized or sequential Bayesian scheme that proved useful for identifying
    and eliminating spurious data from the fusion process. The simulations verified
    that the proposed strategy was able to identify spurious sensor measurements and
    eliminate them from the fusion process, thus leading to a better overall estimate
    of the true state. The proposed strategy was also validated with the help of experiments
    performed using stereo vision cameras, one infrared proximity sensor, and one
    laser proximity sensor. The information from these three sensing sources was fused
    to obtain an occupancy profile of the robotic workspace Published in: IEEE Sensors
    Journal ( Volume: 7, Issue: 5, May 2007) Page(s): 723 - 733 Date of Publication:
    16 April 2007 ISSN Information: DOI: 10.1109/JSEN.2007.894905 Publisher: IEEE
    SECTION I. Introduction The principal objective of a multisensor system [1]–[3]
    is to combine information from a variety of sources in a coherent and synergistic
    manner to yield a robust, accurate, and consistent description of quantities of
    interest in the environment. There are several issues that arise when fusing information
    from multiple sources, some of which include data association, sensor uncertainty,
    and data management. The most fundamental of these issues arise from the inherent
    uncertainty in sensor measurement. The uncertainties in sensor measurement are
    not only caused by device impreciseness and noise, but also manifest themselves
    from the ambiguities and inconsistencies present within the environment, and from
    an inability to distinguish between them. The strategies used to fuse data from
    multiple sensors should be capable of handling these uncertainties, and combining
    different types of information to obtain a consistent description of the environment.
    Some of the more popular techniques for sensor fusion that are explored extensively
    in literature include Dempster–Shafer theory for evidential reasoning [4], [5],
    fuzzy logic [6], [7], neural network [8], [9], genetic algorithm [10], [11], Bayesian
    approach [12], and statistical techniques [13] such as Kalman filter [14]–[16].
    Another possible uncertainty that arises in the sensor measurement process occurs
    when the measurements become corrupted and appear spurious in nature. Such corrupted
    measurements are difficult to model because they are not directly attributable
    to the inherent noise or other sources of uncertainty mentioned above. The cause
    of the corruption may be due to events such as permanent sensor failures, short
    duration spike faults, or nascent (slowly developing) failures. Previous attempts
    at developing experimental models usually preclude the use of spurious measurements,
    and represent uncertainties attributable only to sensor noise and inherent limitations.
    Fusion techniques based on these incomplete models provide inaccurate estimation
    that can eventually result in potentially damaging action by the control system.
    Hence, a sensor validation scheme is necessary to identify spurious measurements
    so they can be eliminated before the fusion process. There are several techniques
    reported in the literature for sensor validation and identification of inconsistent
    data. Many of them are limiting because they are based on specific failure models;
    these techniques can work well for events that occur due to known failure modes,
    however, they do not capture all possible failure events and often perform poorly
    when unmodeled failures occur. As a means to detect inconsistency, there should
    be either redundancy in the data, or some availability of a priori information.
    For example, in the case where a priori information is available, researchers
    have used the Nadaraya–Watson Estimator [17] and a priori observations to validate
    sensor measurements. Other researchers have used a model based Kalman filter approach
    [18], while others have used covariance [19], [20], probability [21], [22], fuzzy
    logic [23], and neural network [24] based approaches. Some of these methods are
    explicit model-based, whereas others require tuning and training. In the general
    case where a priori information is often not available, these approaches are typically
    deficient and can often lead to undesirable results. Most of the fusion strategies
    based on Bayesian approaches reported in the literature handle inconsistency in
    data rather poorly. In practical real-world scenarios, where data generated by
    sensors might be incomplete, incoherent or inconsistent, this approach might lead
    to erroneous results. Consequently, the inconsistency in data needs to be dealt
    with accordingly when Bayesian approaches are used. This paper makes use of a
    modified Bayesian approach for fusion that takes into account measurement inconsistency
    and entropy to identify spurious data. Based on the entropy of the posterior distribution
    of a desired quantity, the approach presented in this paper detects whether the
    data from the sensors are spurious or inconsistent. Entropy-based analysis aids
    in determining if the fusion of data from a particular sensor actually improves
    the information content of the fusion. This paper is organized as follows: First,
    it describes a simplified version of the Bayesian approach. Next, it presents
    the analytical formulation of the proposed approach. Finally, the proposed approach
    is applied using two different fusion schemes: 1) centralized Bayesian fusion
    where data from all sensors are fused simultaneously and 2) decentralized Bayesian
    fusion in which data from sensors are fused sequentially so as to provide an opportunity
    to identify and eliminate spurious data. A simulated application is presented
    that makes use of data from three sensors, all with varying probability of providing
    spurious measurements. Finally, the paper demonstrates the proposed technique
    with a real-world application; obtaining the occupancy profile of a robotic workspace
    using three sensory sources: stereo vision, an infrared proximity sensor, and
    a laser proximity sensor. SECTION II. Bayesian Approach for Sensor Fusion Bayesian
    inference [12], [25], [26] is a statistical data fusion algorithm based on Bayes''
    theorem [27] of conditional or a posteriori probability to estimate an n -dimensional
    state vector X , after the observation or measurement denoted by Z has been made.
    The probabilistic information contained in Z about X is described by a probability
    density function (pdf) p(Z|X) , known as likelihood function, or the sensor model,
    which is a sensor dependent objective function based on observation. The likelihood
    function relates the extent to which the a posteriori probability is subject to
    change, and is evaluated either via offline experiments or by utilizing the available
    information about the system. If the information about the state X is made available
    independently before any observation is made, then the likelihood function can
    be improved to provide more accurate results. Such a priori information about
    X can be encapsulated as the prior probability P(X=x) and is regarded as subjective
    because it is not based on observed data. Bayes'' theorem provides the posterior
    conditional distribution of X=x , given Z=z , as p(X=x|Z=z) = p(Z=z|X=x)P(X=x)
    ∫p(Z=z|X=x)P(X=x)dx = p(Z=z|X=x)P(X=x) P(Z=z) . (1) View Source Since the denominator
    depends only on the measurement (the summation is carried out over all possible
    values of state), an intuitive estimation can be made by maximizing this posterior
    distribution, i.e., by maximizing the numerator of (1). This is called maximum
    a posteriori (or MAP) estimate, and is given by x ^ MAP =argmaxp(X=x|Z=z) ∝argmaxp(Z=z|X=x)P(X=x).
    (2) View Source Another popular estimation scheme minimizes the sum of squared
    errors, i.e., it minimizes the Euclidean distance between the true state x and
    the estimate x ^ after the observation z has been made. This estimator, called
    the minimum mean square error (MMSE) estimator, is given by x ^ MMSE =arg min
    x ^ E p(x|z) {( x ^ −x)( x ^ −x ) T } (3) View Source p(X=x| Z ¯ 1…n = z 1 , z
    2 ,… z n )= p(Z= z 1 |X=x)p(Z= z 2 |X=x)…p(Z= z n |X=x)P(X=x) P( Z ¯ 1…n = z 1
    , z 2 ,… z n ) (4) View Source where E p(x|z) is the expected value of a function
    with respect to distribution p(x|z) . Sensor modeling [28]–[31] forms an important
    part of sensor fusion and it deals with developing an understanding of the nature
    of measurements provided by the sensor, the limitations of the sensor, and probabilistic
    understanding of the sensor performance in terms of the uncertainties. The information
    supplied by a sensor is usually modeled as a mean about a true value, with uncertainty
    due to noise represented by a variance that depends on both the measured quantities
    themselves and the operational parameters of the sensor. A probabilistic sensor
    model is particularly useful because it facilitates a determination of the statistical
    characteristics of the data obtained. This probabilistic model is usually expressed
    in the form of pdf p(Z=z|X=x) that captures the probability distribution of measurement
    by the sensor ( z ) when the state of the measured quantity ( x ) is known. This
    distribution is extremely sensor specific and can be experimentally determined.
    The likelihood function relates the extent to which the a posteriori probability
    is subject to change, and is evaluated either via offline experiments or by utilizing
    the information available about the problem. Since the likelihood function is
    obtained from the experimental observations, it is said to be objective. Bayesian
    approaches make use of a priori information about X and fuse that information
    with measurement information from sensors to provide an improved estimate of the
    state. The data from multiple sensors can be fused simultaneously (centralized
    fusion scheme) as shown in Fig. 1, or sequentially (decentralized fusion) as shown
    in Fig. 2. Fusing data from n independent sensors in the centralized scheme using
    the Bayesian approach can be achieved via equation (4) shown at the bottom of
    the page, where z i represents the measurement obtained from sensor i . Similarly,
    the sequential Bayesian approach can be easily implemented in a distributed sensing
    environment and in an online manner where the posterior distribution obtained
    from old measurements becomes the prior distribution. Hence, the addition of new
    sensor measurement z n to the belief obtained from n−1 sensors ( Z ¯ 1…n−1 = z
    1 , z 2 ,… z n−1 ) can be achieved in an incremental manner via (5) shown at the
    bottom of the page. p(X=x| Z ¯ 1…n = z 1 , z 2 ,… z n )= p(Z= z n |X=x)p(X=x|
    Z ¯ 1…n−1 = z 1 , z 2 ,… z n−1 ) P( Z ¯ 1…n = z 1 , z 2 ,… z n ) (5) View Source
    It may be noted that (4) and (5) are valid only when measurements from different
    sensors are independent. This paper assumes the independence of sensors in its
    analysis. However, the analytical approach used in this paper is equally applicable
    when the sensors are not independent with some modifications in its formulation
    that can account for the interdependence of the measurements from different sensors.
    Fig. 1. Centralized sensor fusion scheme using Bayesian approach. Show All Fig.
    2. Decentralized sensor fusion scheme using Bayesian approach. Show All This type
    of decentralized fusion scheme is more robust in terms of individual component
    failure, is more efficient in using communication resources as compared with the
    conventional schemes, and is also scalable. This fusion scheme, based on sequential
    Bayesian estimation, provides a mechanism to identify sensor failure or the presence
    of spurious sensor data, and provides a means to eliminate those measurements.
    One of the major advantages of the Bayesian approach is that it provides an excellent
    mechanism to combine prior information with information obtained from current
    experiments. Since the estimation takes into account available data from all previous
    as well as current experiments, the approach leads to a theoretically optimal
    solution. However, for most practical applications, a lack of priors or use of
    noninformative priors presents difficulties for Bayesian-based sensor fusion approaches.
    Assumptions regarding informative priors creates the possibility of unreasonable
    fusion between priors and likelihood functions. Another major drawback of the
    Bayesian approach is its inability to fuse estimates from various sources that
    are either noncoherent or inconsistent. Thus, inconsistencies in data need to
    be dealt with separately when Bayesian approaches are used. SECTION III. Multisensor
    Fusion with Spurious Data Sensors often provide spurious data due to sensor failure;
    this can be due to some inherent limitation of the sensor and/or some ambiguity
    in the environment. The Bayesian approach described in the previous section is
    inadequate in handling this type of spurious data. The approach does not have
    a mechanism to identify when data from sensors is incorrect. The following paragraphs
    describe the use of a Bayesian-based approach for fusion of data from multiple
    sensors that takes into account measurement inconsistency. While building a stochastic
    sensor model, generally spurious data are identified and eliminated. Hence, these
    experimentally developed sensor models represent uncertainties arising only from
    sensor noise. If the event s=0 represents that the data obtained from a sensor
    is not spurious, then the sensor model developed in this manner actually represents
    the distribution p(Z=z|X=x,s=0) . From Bayes'' theorem, the probability that the
    data z i measured by sensor i is not spurious conditioned upon the actual state
    x , is given by [p(s=0|X=x,Z= z i ) ] i = [P(s=0) ] i [p(Z= z i |X=x,s=0)] ∑ s
    [P(s) ] i [p(Z= z i |X=x,s) ] i (6) View Source [P(s=0) ] i is the sensor specific
    prior probability that the data provided by sensor i is not spurious. The denominator
    of the right-hand side of the above equation is a summation carried over all possible
    values of s which are 0 and 1. The above equation can be rewritten as or [p(s=0|X=x,Z=
    z i ) ] i = [P(s=0) ] i [p(Z= z i |X=x,s=0)] [p(Z= z i |X=x) ] i [p(Z= z i |X=x)
    ] i = [P(s=0) ] i [p(Z= z i |X=x,s=0) ] i [p(s=0|X=x,Z= z i ) ] i . (7) (8) View
    Source Then, from (4), in a centralized fusion scheme, data from n sensors can
    be fused via the following equation: p(X=x|Z= z 1 , z 2 ,… z n ) = [P(s=0) ] 1
    [p(Z= z 1 |X=x,s=0) ] 1 [p(s=0|X=x,Z= z 1 ) ] 1 ×… [P(s=0) ] n [p(Z= z n |X=x,s=0)
    ] n [p(s=0|X=x,Z= z n ) ] n × P(X=x) P(Z= z 1 , z 2 ,… z n ) . (9) View Source
    Note the effect of the additional terms [p(s=0|X=x,Z= z 1 ) ] 1 …[p(s=0|X=x,Z=
    z n ) ] n in the denominator of (9). It will be demonstrated in the next section
    that the term [p(s=0|X=x,Z= z i ) ] i in the denominator results in an increase
    in the variance based on the belief that measurements from sensor i have a greater
    probability of being spurious. This results in less weight applied to the measurement
    from sensor i when fused with measurements from other sensors. Similarly, to combine
    the sensor measurement from sensor n sequentially with the current belief obtained
    from sensors 1,2…n−1 , (5) can be rewritten as (10) shown at the bottom of the
    page. p(X=x| Z ¯ = z 1 , z 2 ,… z n )= [P(s=0) ] n [p(Z= z n |X=x,s=0)]p(X=x|
    Z ¯ 1…n−1 = z 1 , z 2 ,… z z−1 ) P( Z ¯ 1…n = z 1 , z 2 ,… z n )[p(s=0|X=x,Z=
    z n ) ] n (10) View Source Hence, the addition of term [p(s=0|X=x,Z= z n ) ] n
    in the denominator has the effect of increasing the spread (variance) of the posterior
    if the new measurement has a greater probability of being spurious, and decreasing
    the spread of the posterior if the new measurement has a lower probability of
    being spurious. The increase or decrease in the spread of the posterior distribution
    can be easily ascertained by determining the information content given by the
    entropy of distribution obtained from the following equation: H(X)=∫−p(X=x|Z=
    z 1 , z 2 ,… z n ) ×log(p(X=x|Z= z 1 , z 2 ,… z n ))dx.(11) View Source Entropy
    of a variable represents the uncertainty in that variable. A larger value of entropy
    implies more uncertainty and, hence, less information content. The fusion of a
    new measurement should always lead to a decrease in entropy, and fusion should
    always be done in order to reduce entropy. Based on increasing or decreasing the
    entropy of the posterior, this method can identify and eliminate spurious data
    from a sensor. It is noted that the prior probability [P(s=0) ] i has a constant
    value and simply acts as a constant weighting factor in (9) and (10). This value
    does not influence the posterior distribution nor the MAP estimate of the state.
    SECTION IV. Fusion of Three Sensors A. Bayesian Fusion Without Consideration of
    Spuriousness in Data (Method 1) If the spurious nature of the sensor data is not
    considered, and the models of three sensors are given by the following Gaussian
    likelihood function: p(Z= z k |X=x)= 1 σ k 2π − − √ e { −(x− z k ) 2 2 σ 2 k }
    k=1,2,3 (12) View Source where k=1 represents the first sensor, k=2 represents
    the second sensor, and k=3 represents the third sensor. From Bayes'' Theorem,
    the fused MAP estimate is given by x ^ MAP =argmax[p(Z= z 1 |X=x) ×p(Z= z 2 |X=x)p(Z=
    z 3 |X=x)].(13) View Source If three Gaussian distributions (each given by the
    one of three sensors'' model pdfs) are fused, then the posterior distribution
    is jointly Gaussian, and the standard deviation is given by ( σ ′ ) 2 =[( σ 1
    ) −2 +( σ 2 ) −2 +( σ 3 ) −2 ] −1 (14) View Source and the mean (and the MAP estimate)
    are given by x ^ MAP =( σ ′ ) 2 [ z 1 ( σ 1 ) 2 + z 2 ( σ 2 ) 2 + z 3 ( σ 3 )
    2 ]. (15) View Source Hence, if there is no prior information available about
    the quantity to be estimated, the Bayesian approach for fusion of the three sensor
    estimates results in a weighted average dictated by the ratio of standard deviations.
    From (14) we note that the standard deviation of the fused distribution is smaller
    than any of the three individual distributions, representing less uncertainty
    in the fused estimates. B. Bayesian Fusion with Consideration of Spuriousness
    in Data If the spurious nature of the sensor data is considered, then the Gaussian
    sensor model represented by distribution p(Z=z|X=x,s=0) is given by [p(Z=z|X=x,s=0)
    ] k = 1 σ k 2π − − √ e { −(x− z k ) 2 2 σ 2 k } k=1,2,3.(16) View Source The probability
    that the measurement from sensor k is not spurious given the true state x and
    measurement z k , is assumed to be represented by the following equation: [p(s=0|X=x,Z=
    z k ) ] k = e { −(x− z k ) 2 a 2 k } . (17) View Source An advantage of choosing
    the above formulation for representing the probability is that the probability
    is 1 when measurement z k is equal to the true state x , and decreases when the
    measured value moves away from the true state. The rate at which the probability
    decreases when the measured value moves away from the true estimate depends upon
    the parameter a k . The value of the parameter is dependent on the variances of
    the sensor models and the distance between the output of sensor k with respect
    to other sensors. 1. Centralized Fusion Scheme (Method 2) The posterior distribution
    p(X=x|Z= z 1 , z 2 , z 3 ) in the centralized fusion scheme obtained from (9)
    is given by p(X=x|Z= z 1 , z 2 , z 3 ) = P(X=x) P(Z= z 1 , z 2 , z 3 ) × ∏ k=1
    3 [P(s=0) ] k [p(Z= z k |X=x,s=0) ] k [p(s=0|X=x,Z= z k ) ] k . (18) View Source
    The value of parameter a k in (17) is assumed to be given by a 2 k = b 2 k ∏ 3
    l≠k,l=1 ( z k − z l ) 2 . (19) View Source Incorporating this in (18) yields p(X=x|Z=
    z 1 , z 2 , z 3 ) = P(X=x) P(Z= z 1 , z 2 , z 3 ) × ∏ k=1 3 [P(s=0) ] k 1 σ k
    2π − − √ × e −(x− z k ) 2 { 1 2 σ 2 k − ∏ 3 l≠k,l=1 ( z k − z l ) 2 b 2 k } .
    (20) View Source The value of parameter b k is chosen to satisfy the following
    inequality: b 2 k ⩾2 σ 2 k ∏ l≠k,l=1 3 ( z k − z l ) 2 . (21) View Source Satisfaction
    of this inequality ensures that the posterior distribution in (20) remains Gaussian
    and hence has a single peak. The entire process has the effect of increasing the
    variance of the individual distribution (representing belief from one particular
    measurement) if that particular measurement is at a larger distance to other measurements.
    Thus, if two measurements lie close to one another, then weights associated with
    those measurements become larger when compared to those measurements that lie
    farther away. This process yields a mathematical basis to provide more weighting
    to beliefs when they corroborate one another rather than when they contradict
    one another. 2. Decentralized Fusion Scheme (Method 3) In the decentralized or
    sequential fusion scheme, measurements from only two sources are fused at once.
    The belief resulting from the fusion of two sensors is then fused with the next
    sensor, and the process continues henceforth. Fusion of two sensors k and k+1
    using (10) yields p(X=x|Z= z k , z k+1 ) = [P(s=0) ] k [p(Z= z k |X=x,s=0) ] k
    [p(s=0|X=x,Z= z k ) ] k × [P(s=0) ] k+1 [p(Z= z k+1 |X=x,s=0) ] k+1 [p(s=0|X=x,Z=
    z k+1 ) ] k+1 × P(X=x) P(Z= z k , z k+1 ) . (22) View Source The value of parameter
    a k in (17) is assumed to be given by a 2 k = b 2 k ( z k − z k+1 ) 2 (23) View
    Source which leads to w p(X=x|Z= z k , z k+1 ) = P(X=x) P(Z= z k , z k+1 ) ×[P(s=0)
    ] k 1 σ k 2π − − √ × e −(x− z k ) 2 { 1 2 σ 2 k − ( z k − z k+1 ) 2 b 2 k } ×[P(s=0)
    ] k+1 1 σ k+1 2π − − √ × e −(x− z k+1 ) 2 { 1 2 σ 2 k+1 − ( z k − z k+1 ) 2 b
    2 k+1 } . (24) View Source The value of parameter b k is chosen to satisfy the
    following inequality: b 2 k ≥2 σ 2 k ( z k − z k+1 ) 2 . (25) View Source Satisfaction
    of this inequality ensures that the posterior distribution in (24) remains Gaussian,
    and hence has a single peak. The parameter value should be chosen based on maximum
    expected difference (represented by m ) between the sensor readings so that inequality
    (25) is always satisfied. Hence b 2 k =2 σ 2 k m 2 . (26) View Source Substituting
    (26) in (24) gives p(X=x|Z= z k , z k+1 ) = P(X=x) P(Z= z k , z k+1 ) ×[P(s=0)
    ] k 1 σ k 2π − − √ e − (x− z k ) 2 2 σ 2 k { m 2 m 2 −( z k − z k+1 ) 2 } ×[P(s=0)
    ] k+1 1 σ k+1 2π − − √ e − (x− z k+1 ) 2 2 σ 2 k+1 { m 2 m 2 −( z k − z k+1 )
    2 } . (27) View Source It is apparent that the entire process has the effect of
    increasing the value of the variance of individual distribution by a factor of
    {( m 2 / m 2 −( z 1 − z 2 ) 2 )} . Larger differences in sensor measurement imply
    that the variance increases by a bigger factor. Depending on the squared difference
    in measurements from the two sensors, the variance of the posterior distribution
    may increase or decrease as compared with the variance of individual Gaussian
    distributions representing the sensor models. Therefore, the strategy is capable
    of determining if fusion of the two measurements would lead to an increase or
    decrease of the variance of the posterior distribution. In information theoretic
    terms, the strategy is capable of determining if the fusion leads to an increase
    in information content [or entropy given by (11)] or not. Based on increasing
    or decreasing of entropy in the posterior, a decision can be made whether to fuse
    those two sensors or not. This approach provides an opportunity to eliminate sensor
    measurements that are spurious and fuse measurements from only those sensors that
    are consistent, ensuring an increase in information content after fusion. Fig.
    3. Fusion of three sensors. (a) All sensors in agreement. (b) Sensor 1 in disagreement.
    (c) Sensor 2 in disagreement. (d) Sensor 3 in disagreement. Show All SECTION V.
    Simulation Results A simulation study was carried out to validate the effectiveness
    of the proposed strategy in identifying spurious data. A comparative analysis
    was performed to study the efficiency with which the three methods (described
    in previous section) were able to handle inconsistency in data. The following
    parameters were assumed in the simulation. Sensor 1: [P(s=0) ] 1 =0.90 and σ 1
    =3 . Sensor 2: [P(s=0) ] 2 =0.98 and σ 2 =2 . Sensor 3: [P(s=0) ] 3 =0.94 and
    σ 3 =2.5 . True value of state: x=20 . Simulation data was generated so that Sensor
    1 provided 90% of the time normally distributed random data with a mean value
    of 20 and variance 9. It provided incorrect data 10% of the time which was uniformly
    distributed outside the Gaussian distribution. Sensor 2 provided 98% of the time
    normally distributed random data with a mean value of 20 and variance 4, and 2%
    of the time it provided incorrect data. Similarly, Sensor 3 provided 94% of the
    time normally distributed random data with a mean value of 20 and variance 6.25,
    and 6% of the time it provided incorrect data. It may be noted here that the values
    for [P(s=0) ] k have been assumed simply for the purpose of generating simulated
    data. These are not used in the fusion algorithm. Since these values are constants,
    they do not have any effect on the posterior distribution or the MAP estimate.
    Fig. 4. Sample data and fusion from multiple sensors with spurious data. (a) Fusion
    of a sample of 100 data points. (b) A case when two sensors provide spurious measurements.
    Show All Fig. 3(a) illustrates a case when all of the three sensors are in agreement,
    and measurement from none of the sensors is inconsistent with the rest. It can
    be seen that posterior distributions obtained from all three methods coincide
    resulting in the same value of MAP estimate. In Fig. 3(b), measurement from Sensor
    1 is in disagreement from the other two sensors. Method 1, which is a simple Bayesian
    fusion and does not take into account inconsistency of data, results in the weighted
    average of the three measurements given by (15). Method 2, which takes into account
    the inconsistency and weights those sensors more whose measurements are consistent
    (Sensors 2 and 3 in this case) with each other, results in an estimate which is
    closer to the sensors (Sensors 2 and 3) in agreement. Method 3 identifies the
    sensor which provides spurious measurements and eliminates that from the fusion
    process. Hence, it simply considers measurements from Sensors 2 and 3, and fuses
    them appropriately using (27). In a similar manner, Fig. 3(c) and (d), respectively,
    show that measurements from Sensors 2 and 3 are spurious. The figure shows the
    efficiency with which Method 3 identifies and eliminates spurious measurements,
    and results in better estimates (closer to the true value) of the variable. The
    figure also shows that Method 2 is able to appropriately and autonomously weight
    sensors to achieve an estimate which is better as compared to Method 1 which does
    not take inconsistency into consideration at all. A set of 10 000 data points
    were generated in the manner described above and fusion was carried out using
    all three methods. The mean value of the sum of squared error (MSE) between the
    fused value and true value for all 10 000 data points was computed. The values
    of MSE were found as 6.94 for Method 1, 6.03 for Method 2, and 5.50 for Method
    3. Hence, Method 3 was able to reduce the MSE by approximately 21% when compared
    with Method 1, and Method 2 was able to reduce the mean square error by approximately
    13% when compared with Method 1. Fig. 4(a) shows a sample of 100 data points taken
    from the above set of ten thousand data points. Data points represented by asterisks
    (∗) are the fused values obtained via Method 3. The figure shows that the asterisks,
    on an average, lie closer to the dashed line (—) which represents the true value
    of the variable. Method 3 has the built-in mechanism to identify and eliminate
    spurious data. As explained in the previous sections, it does so by comparing
    data from one sensor with those from the other two sensors. This method fails
    when two sensors simultaneously provide spurious data which are close to one another.
    The method wrongfully identifies the measurement from the third sensor as spurious.
    This rarely happens since the probability of two sensors providing spurious data
    at the same time is very low. In Fig. 4(a), for example, it happened for the encircled
    data. Fig. 4(b) shows the details of fusion results for this data point. Sensors
    1 and 2 have both provided spurious data. However, since they are close to each
    other, Method 3 identifies data from Sensor 3 as spurious, and eliminates that
    data from fusion process. This leads to inaccurate estimation. Similarly, Method
    2 provides more weights to data from Sensors 1 and 2, and also results in inaccurate
    estimation. However, since occurrence of such a case is rare, both Method 2 and
    Method 3 generally provide improved accuracy over Method 1. SECTION VI. Experimental
    Validation The theories developed in the previous sections were validated with
    the help of experiments performed in the Robotics and Manufacturing Automation
    (RAMA) Laboratory at Duke University. The objective of the experiment was to obtain
    a three-dimensional occupancy profile of the robotic workspace using three independent
    sensory sources: stereo vision, an infrared proximity sensor, and a laser proximity
    sensor. The occupancy profile was obtained using an occupancy grid framework.
    The occupancy grid [29]–[33] is a multidimensional field (usually of dimension
    two or three) where each cell (or unit of the grid) stores or represents the probabilistic
    estimate of the state of spatial occupancy. Occupancy grids are one of the most
    common low-level models of an environment, which provide an excellent framework
    for robust fusion of uncertain and noisy data. If the state variable (occupancy,
    in this case) associated with a cell, C i , is denoted by s( C i ) , then the
    occupancy probability P[s( C i )] represents the probabilistic estimate of occupancy
    of that particular cell. Fig. 5. Sensor models. (a) Stereo Vision. (b) Infrared
    proximity sensor. (c) Laser proximity sensor. Show All Fig. 6. Images of the worktable
    obtained from left and the right camera. Show All If P[s( C i )=occ]≈0 , then
    the cell is assumed to be empty, while if P[s( C i )=occ]≈1 , then the cell is
    assumed to be occupied. If a single sensor is used to obtain the occupancy grid,
    Bayes'' Theorem can be used in the following manner to determine the state of
    the cell: P[s( C i ) =occ|z]= p[z|s( C i )=occ]P[s( C i )=occ] ∑ s( C i ) p[z|s(
    C i )]P[s( C i )] (28) View Source where z is the sensor measurement. The pdf
    p[z|s( C i )=occ] is dependent on the sensor characteristics and is called the
    sensor model. The probability P[s( C i )=occ] is called prior probability mass
    function and specifies the information made available prior to any observation.
    At first, models of the three sensory sources using Gaussian distributions were
    obtained. These models were obtained using a neural network-based technique that
    established the relationship between the variance of the sensor model with respect
    to certain environmental or algorithmic conditions. The details of the sensor
    modeling process are explained in [28], and the results are shown in the Fig.
    5. Fig. 5(a) shows the graph of standard deviation of Gaussian sensor model plotted
    against the correlation score of stereo-matched templates for stereo vision sensor.
    Similarly, for infrared and laser proximity sensors, the variance of the sensor
    model was found to be dependent on the distance to the detected object, and the
    relationship between the variance and the sensor outputs (which are indicative
    of the distance to the detected object) are shown in Fig. 5(b) and (c), respectively,
    for infrared and laser proximity sensor. Occupancy grids were obtained individually
    for stereo vision, infrared, and laser proximity sensors, and then the individual
    grids were fused using two techniques: 1) Simple Bayesian Fusion and 2) Sequential
    Bayesian Fusion with Proposed Inconsistency Detection and Elimination Strategy.
    The details of the process for obtaining occupancy grids and sensor fusion are
    explained in [29]. In the experiment, a cylindrical object was placed on the robot''s
    worktable. Fig. 6 shows the images of the worktable obtained from the stereo cameras.
    Fig. 7(a) shows the actual occupancy grid of the workspace. This was obtained
    based on the geometric dimensions of the object and its location in the workspace.
    For the occupancy grid developed in this research, each grid is of size 5 mm ×
    5 mm × 5 mm. Fig. 7(b)–(d) shows the occupancy grids independently obtained from
    stereo vision, IR proximity sensor, and laser proximity sensor, respectively.
    Fig. 7(e) shows the occupancy grid obtained from simple Bayesian approach, and
    Fig. 7(f) shows the occupancy grid obtained from the Bayesian approach that utilizes
    the inconsistency detection and elimination technique proposed earlier. To facilitate
    a comparison of the performance of the fusion process via different algorithms,
    a measure of error was formulated which is given by the following equation: Error=
    ∑ C i [|s( C i ) | actual −|s( C i ) | sensor ] 2 (29) View Source Fig. 7. Occupancy
    grids. (a) Actual grid. (b) Grid obtained from stereo vision. (c) Grid obtained
    from IR proximity sensor. (d) Grid obtained from laser proximity sensor. (e) Fused
    grid (simple Bayesian approach). (f) Fused grid (proposed Bayesian fusion with
    inconsistency detection and elimination). Show All Table I Error Associated with
    Occupancy Grids Obtained from Fusion Process where |s( C i ) | actual is the actual
    state of the cell, and |s( C i ) | sensor is the state of the cell obtained from
    the sensor and/or fusion process. The state of the cell is either 1 (for occupied)
    or 0 (for empty). Table I provides the error value associated with the occupancy
    grid obtained from the fusion process described above. The table compares the
    error value obtained via the two approaches. The first approach is based on the
    simple Bayesian fusion scheme, and the second approach is based on the proposed
    Bayesian fusion scheme embedded with the mechanism for inconsistency detection
    and elimination. From the figures as well as from the table of results, it is
    evident that the proposed fusion scheme based on Bayesian approach with an built-in
    mechanism to identify and eliminate spurious/inconsistent measurement presented
    in this paper has been able to reduce the uncertainty inherent in individual sensors.
    The proposed method has been able to reduce the error by approximately 70% as
    compared with stereo vision, 64% as compared with IR proximity sensor, and 4%
    as compared with laser proximity sensor. On the other hand, simple Bayesian technique
    was able to reduce the error by approximately 64% as compared with stereo vision
    and by 56% as compared with IR proximity sensor. The technique based on simple
    Bayesian approach led to an increase in error by approximately 15% as compared
    with laser proximity sensor. The increase in error demonstrates the fact that
    it is not necessary that incorporation of additional sensor data will lead to
    improved accuracy of estimation. This is particularly more evident in cases when
    the accuracy of measurements from sensors differs by a large amount. In this case,
    the measurements from laser proximity are far more accurate (see Fig. 5) than
    measurements from the stereo vision or IR proximity sensor, and fusion of measurements
    from the laser with stereo vision and IR proximity leads to an increase in error.
    However, the proposed technique has a built-in mechanism to determine if the fusion
    process leads to an increase in the information content, and, in this way was
    able to eliminate inconsistent data and improve the overall accuracy of the fusion
    process. Of the 24 000 points (or cells) where the fusion of data from three sensors
    occurred (fusion occurred at 30 × 40 × 20 cells of the occupancy grid), the proposed
    technique detected 393 points where data from IR sensor were inconsistent and
    1028 points where data from stereo vision were inconsistent. None of the data
    from the laser sensor were detected to be inconsistent. This observation is consistent
    with the fact that the laser sensor was far more accurate than the other two sensors.
    One of the limitations of the proposed technique is that when there is a large
    number of sensors supporting an inconsistent measurement, then, based on the beliefs
    of the individual measurements, the technique may consider inconsistent measurements
    to be the correct one, and might disregard the correct measurements obtained by
    fewer numbers of sensors. In psychology, this kind of problem is termed as group
    conformity. For example, when an individual''s opinion differs significantly from
    that of others in a group, the individual is likely to feel extensive pressure
    to align his or her opinion with others. In the case of sensor systems, this kind
    of condition is more likely to occur in adversarial situations, such as the battlefield,
    where events are prone to be camouflaged to escape detection. Hence, a formal
    criterion to establish the difference between spuriousness and opinion difference
    must be developed for the sensor fusion process to be accurately carried out in
    such adversarial situations. For example, in these situations, the technique proposed
    in this paper could be applied if sensor models could be developed that represent
    the possibility/likelihood of events being camouflaged. Real-time implementation
    and scalability aspects of the proposed sequential scheme have to be considered.
    Since the method is based on the information content of the fused belief, novel
    fusion architectures can be designed to introduce parallelism in the process,
    and at the same time minimize the possibility of fused result falling into local
    attractor basins. On the other hand, the technique based on centralized fusion
    scheme is completely scalable and can be easily implemented in real time. SECTION
    VII. Conclusion Sensors often provide spurious measurements. Identification of
    such spurious measurements and their elimination is essential for carrying out
    accurate estimation. This paper proposes a unified and formalized approach to
    fuse data from multiple sources which can automatically identify inconsistency
    in sensor data. The proposed strategy adds a term to the popular Bayesian approach
    corresponding to a belief that the sensor data is not spurious conditioned upon
    the data and true state. An information theoretic measure is utilized to observe
    the information content of the posterior distribution to identify spurious data.
    Three approaches were comparatively studied in this paper. The first approach
    was based on simple Bayesian methods. The second approach adds the new term described
    above fuses all data in a centralized manner. The third method sequentially fuses
    data and eliminates those data which it identifies as spurious. An extensive simulation
    study was performed where data from three sensors was fused. It was observed that
    the third method was very effective in identifying spurious data, and elimination
    of spurious data ensured more accurate results. The second method performed better
    than the first method since it had a built-in mechanism for increasing the weighting
    of consistent measurements, while at the same time decreasing the weighting applied
    to spurious measurements. Finally, the effectiveness of the proposed technique
    to identify and eliminate inconsistent sensor data in sequential Bayesian fusion
    was demonstrated with the help of an experiment performed in a robotic workcell,
    where measurements from stereo vision, infrared proximity, and laser proximity
    senor were fused to obtain three-dimensional occupancy profile of robotic workspace.
    ACKNOWLEDGMENT This research was performed in the Robotics and Manufacturing Automation
    (RAMA) Laboratory at Duke University, while the first author, Dr. M. Kumar, held
    a National Research Council''s Research Associateship Award at the Army Research
    Office. Authors Figures References Citations Keywords Metrics More Like This Entropy
    Minimization SLAM Using Stereo Vision Proceedings of the 2005 IEEE International
    Conference on Robotics and Automation Published: 2005 Robot Vision System based
    on a 3D-TOF Camera 2007 IEEE Instrumentation & Measurement Technology Conference
    IMTC 2007 Published: 2007 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE Sensors Journal
  limitations: '>'
  pdf_link: null
  publication_year: 2007
  relevance_score1: 0
  relevance_score2: 0
  title: A Method for Judicious Fusion of Inconsistent Multiple Sensor Data
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/secon.2017.7925311
  analysis: '>'
  authors:
  - Balasubramaniyan Chandrasekaran
  - Shruti Gangadhar
  - James M. Conrad
  citation_count: 30
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >SoutheastCon 2017 A survey of multisensor
    fusion techniques, architectures and methodologies Publisher: IEEE Cite This PDF
    Balasubramaniyan Chandrasekaran; Shruti Gangadhar; James M. Conrad All Authors
    31 Cites in Papers 2618 Full Text Views Abstract Document Sections I. Introduction
    II. Motivation III. Sensor Fusion Categories IV. Sensor Fusion Topologies V. Multi
    Sensor Fusion Models Show Full Outline Authors Figures References Citations Keywords
    Metrics Abstract: In this paper, an overview of multi-sensor fusion is presented.
    Topics such as sensor fusion types, topologies and basic architectures used for
    multi-sensor fusion are reviewed. Also, fusion methods for signal level processing
    and decision level or symbol level are covered to provide the reader with basic
    understanding and techniques encountered in sensor fusion applications. Published
    in: SoutheastCon 2017 Date of Conference: 30 March 2017 - 02 April 2017 Date Added
    to IEEE Xplore: 11 May 2017 ISBN Information: Electronic ISSN: 1558-058X DOI:
    10.1109/SECON.2017.7925311 Publisher: IEEE Conference Location: Concord, NC, USA
    SECTION I. Introduction Sensor fusion involves combining data from several sensors
    to obtain better information for perception. Humans and animals process multiple
    sensory data to reason and act and the same principle is applied in multi-sensor
    data fusion. Multi-sensor fusion combines data from different sensors into a common
    representation format [1], [2]. In developing robotic systems, multi-sensor fusion
    plays a crucial role since interaction with the environment is instrumental in
    successful execution of the task. Significant applications of multi-sensor fusion
    can be found in applications such as mobile robots [2]–[5], defense systems (such
    as target tracking [2], [6]–[8]), medicine [9], [10], transportation systems [11],
    [12] and industry [13]–[15]. The motivation for sensor fusion is discussed in
    section II. Section III describes the various types of sensor fusion proposed
    in literature. The various topologies and models for sensor fusion is covered
    in sections IV and V. Sections VI, VII provide an overview of signal and decision
    level fusion. SECTION II. Motivation The main goal of multi-sensor fusion is to
    achieve better operation of the system using the collective information from all
    sensors. This is also referred to as the synergistic effect [16]–[18]. Combining
    the data from a single sensor at different time intervals can also produce this
    effect [18]. In order to have better spatial and temporal coverage multiple sensors
    can be used. Also, with multiple sensors there is increased estimation accuracy
    and fault-tolerance [18]. SECTION III. Sensor Fusion Categories Depending upon
    the sensor configuration, there are three main categories of sensor fusion: Complementary,
    Competitive and Co-operative [19]. These are described below as follows: A. Complementary
    In this method, each sensor provides data about different aspects or attributes
    of the environment. By combining the data from each of the sensors we can arrive
    at a more global view of the environment or situation. Since there is no dependency
    between the sensors combining the data is relatively easy [19], [20]. B. Competitive
    In this method, as the name suggests, several sensors measure the same or similar
    attributes. The data from several sensors is used to determine the overall value
    for the attribute under measurement. The measurements are taken independently
    and can also include measurements at different time instants for a single sensor.
    This method is useful in fault tolerant architectures to provide increased reliability
    of the measurement [19], [20]. C. Co-Operative When the data from two or more
    independent sensors in the system is required to derive information, then co-operative
    sensor networks are used since a sensor individually cannot give the required
    information regarding the environment. A common example is stereoscopic vision
    [19], [20]. Several other types of sensor networks exist such as corroborative,
    concordant, redundant etc [18]. Most of them are derived from the above mentioned
    sensor fusion categories. Dasarthy [21], [22] classified sensor fusion types depending
    upon the input/output characteristics. Figure 1 [21], shows the various sensor
    fusion types. Only a few combinations are allowed in Dasarthy''s scheme for the
    inputs and outputs. Fig. 1. Dasarthy''s classification of multi-sensor fusion
    [21]. Show All SECTION IV. Sensor Fusion Topologies There are different topologies
    namely, Centralized, Decentralized and Hybrid [18], [20], [23], [24]. Each of
    these is described as follows: A. Centralized Architecture In this architecture,
    a single node handles the fusion process. The sensors undergo preprocessing before
    they are sent to the central node for the fusion process to take place. Figure
    2 shows a typical centralized architecture [18], [20]. B. Decentralized Architecture
    In this architecture, each of the sensor processes data at its node and there
    is no need for a global or central node. Since the information is processed individually
    at the node, it is used in applications that are large and widespread such as
    huge automated plants, spacecraft health monitoring etc. [20]. Figure 3 shows
    a typical decentralized architecture [18], [20]. C. Hierarchical Architecture
    This architecture is a combination of both centralized and distributed type. When
    there are constraints on the system such as a requirement of less computational
    workload or limitations on the communication bandwidth, distributed scheme can
    be enabled. Centralized fusion can be used when higher accuracy is necessary [20],
    [23]. A simple comparison between the centralized and decentralized topologies
    is shown below in Table I [18], [20]. SECTION V. Multi Sensor Fusion Models The
    application that uses the sensor fusion plays a vital role in determining the
    type of architecture. Hence there is no specific model or architecture that is
    definitive for all applications [25]–[27]. In this section, the two most widely
    used architectures namely, the JDL Fusion architecture and the Waterfall Fusion
    Process Model are discussed. A. Jdl Fusion Architecture JDL stands for the US
    Joint Directors of Laboratories that was established under the guidance of Department
    of Defense and was proposed in 1985. The JDL model is functionality dependent
    and can be customized depending on the application. Varieties of applications
    from sensor networks to human robot interface can be implemented using this model
    [20]. Fig. 2. Centralized topology [23]. Show All Fig. 3. Decentralized topology
    [23]. Show All Table I. Centralized and decentralized topologies [18], [20] The
    model uses five levels for data processing and a database. These components can
    communicate through a bus interface [20], [24], [26]. The JDL model is shown in
    Figure 4 [24], [26]. These levels could be executed sequentially or concurrently
    during the application. Sources, in the JDL model can consist of sensor data or
    data given by the user such as user input, reference data or geographical data.
    The Man-Machine Interaction block, as the name suggests, enables the user to interact
    with the system through user command, reports etc. Furthermore, this block helps
    in providing alert messages and could use multimedia tools such as displays, sounds
    etc. to achieve communication with the user. The Source Pre-Processing also referred
    to as Level 0, performs pre-screening of data and then allocates it to the appropriate
    process [24], [26]. In the Object Refinement or Level 1, the following operations
    are performed namely, alignment of data using frame transformation, data association,
    tracking and estimation of the current and future position of the object. Also,
    Level 1 can be considered to be composed of kinematic and identity fusion [20].
    In kinematic fusion, the velocity, acceleration of the object is determined. In
    identity fusion, the type of the object such as aircraft or missile is determined
    using parametric estimation [20], [24]. After processing the data from Level 1,
    based on the situation the contextual relationship is determined between the event
    and the object under observation. This process of refinement is called as Situation
    Refinement or Level 2. Depending on the a priori data and the future situation
    prediction inferences are drawn in Level 3 or Threat Refinement. The inferences
    are used to identify the vulnerabilities and the opportunities for the operation.
    This level uses game theoretic techniques [24]. Process Refinement or Level 4
    deals with monitoring the system performance (handles real time constraints) and
    sensor allocation to satisfy mission objectives and goals. This level does not
    perform data processing operations and uses sensor management techniques [20],
    [24], [26]. The Database Management System helps monitor, update, add and provide
    information to the fusion process [20], [24], [26]. Although the JDL model helps
    in basic understanding of the sensor fusion process it is data centric and hence
    hard to extend or reuse the applications based on this model. It is abstract and
    interpretation could be difficult [24], [26]. Table II [24] highlights the summary
    of various components used in JDL model. Fig. 4. JDL fusion model [24], [26].
    Show All Table II. Summary of JDL process components [24]. B. Waterfall Fusion
    Process Model The Waterfall fusion process model (WFFM) deals with the low level
    processing of data and is shown in Figure 5 [24], [28]. The Waterfall model has
    a lot of common features as the JDL model. The processing stages of the Waterfall
    models relate to the levels of the JDL model [24], [26], [28] and the comparison
    is shown in Table III. However, similar to the JDL model the Waterfall fusion
    model is abstract and doesn''t have feedback between the stages. It is an acyclic
    model. The modified WFFM is described in [20] that provides for some feedback
    between the stages. This modified model is action oriented and has the provision
    for control loop action or feedback loop as shown in Figure 6 [20]. Several other
    fusion models exist such as the Omnibus model [29], Boyd or OODA model [30], LAAS
    Architecture [31]. Fig. 5. Waterfall fusion process model [28]. Show All Fig.
    6. Modified waterfall fusion model [20]. Show All Table III. JDL and waterfall
    fusion models [24], [26], [28] SECTION VI. Signal Level Fusion In signal level
    fusion, data from multiple sources (sensors) are combined to obtain better quality
    data and higher understanding of the environment being observed. Signal level
    fusion often has either or both of the following goals: Obtain a higher quality
    version of the input signals i.e. higher signal to noise ratio [32]. Sensor measurements
    from several sensors which have same physical properties are combined to determine
    the parameter being measured, more accurately [18]. This minimizes and sometimes
    eliminates any uncertainty or inaccurate predictions caused by measurements from
    faulty sensors, measurement noise and state noise. F or instance, readings from
    multiple temperature sensors in close proximity in a given space can be used for
    this kind of fusion. Obtain a feature or mid-level information about the system
    that a single measuring node cannot reveal. A feature is the first stage in understanding
    the state of the environment that helps the system in formulating a decision.
    Heterogeneous sensors are often employed for this process. For instance, signals
    from radar and images from camera are used in target recognition [24]. For sensor
    data to undergo signal level fusion, it is essential to condition the signals
    in the signal preprocessing phase. The signals have to be in a common representation
    format [18]. The stages involved in this process, as shown in Figure 7, include
    but not limited to: Signal alignment, normalization and scaling [18]. There are
    several methods by which signal level fusion can be achieved. The choice of method
    depends on various factors like the scenario and type of application, type of
    data or signal, relationship between the data or the state representation of the
    system. Fig. 7. Common representation format functions [18]. Show All The following
    are some of the commonly used signal fusion methodologies: A. Weighted Averaging
    Signal fusion can be achieved by taking an average of the various sensor signals
    measuring a particular parameter of the environment. If signals from some sensors
    can be trusted more than the other, a higher weight is assigned to that sensor
    to increase its contribution towards the fused signal. The confidence level is
    a function of variance of the sensor signal. [32] x fused = ∑ i=0 n w i x i (1)
    View Source where, wi = f(variance) B. Kalman Filter The Kalman filter method
    is a common adaptive method of sensor fusion to remove redundancy in the system
    and to predict the state of the system. This is a linear model and the current
    state of the system is dependent on the previous state. The system is represented
    by the following state-space model: x(k)=F x(k−1)+B u+G w z(k)=H x(k)+v View Source
    where, x: state vector, F: state transition matrix, B: Input transition matrix,
    u: Input vector, G: Process noise transition matrix, w: process noise vector,
    H: Measurement matrix, v: measurement noise vector. The covariance matrices of
    wand v are Q(k) and R(k) respectively. There are two phases of state estimation
    with Kalman filter: Predict Phase x ^ k =A  x ^ k−1 +B  u k (2) P k =A  P k−1  A
    T (3) View Source Update Phase K k = P k C T (C P k C T +R ) −1 x ^ k = x ^ k
    + K k ( z k −C x ^ k ) P k =(1− K k C) P k (4) (5) (6) View Source where, P: estimation
    covariance, K: Kalman gain In the update or correction phase, the estimate from
    the predict phase is updated with the observation. If there are two sensors and
    both of them sending data simultaneously, then Z = [z1, z2]. If the sensors are
    sending data one after the other, then the reading from first sensor can be used
    as a priori information before observation from second sensor is used to update
    the prediction. [32] C. Track to Track Fusion Track to track fusion methodology
    has local tracks generated by distinct local sensors. Then at a central node the
    tracks are fused as shown in Figure 8 [33]. The local track can be individual
    Kalman filter nodes that provide state estimation at the local track level. These
    states are then fused into a state vector that has combined information from all
    the local sensor nodes. Sometimes, this new estimate is sent as feedback to the
    local sensor nodes. The new state estimate is obtained by the following formula
    [33]. X ^ k|k = x ^ 1 k|k + [ P 1 k|k − P 12 k|k I P 1 k|k + P 2 k|k + P 12 k|k
    + P 21 k|k ] −1 ( x ^ 2 k|k − x ^ 1 k|k ) (7) View Source where, P m k|k is the
    error covariance matrix of the corresponding state estimation x ∧ m k|k . P 12
    k|k is the cross covariance matrix of the two state vectors where P 12 k|k =(
    P 12 k|k ) T . P 12klk is defined by the following equation: P 12  k|k =(1− K
    1 k H 1 k ) F k−1 P 12 k−1|k−1 F r k−1 (1− K 2 k H 2 k ) +(1− K 1 k H 1 k μ k−1
    Q k−1 G T k−1 (1− K 2 k H 2 k ) T (8) View Source This configuration can be extended
    for multiple sensors. A modified track-to-track fusion and three fusion algorithm
    are explained in detail in [33]. There are other ways to define the track fusion
    algorithm such as taking confidence weighted averaging of the tracks based on
    variance [33]. D. Neural Networks An artificial neural network consists of interconnection
    of processing nodes called neurons. There is a pattern of interconnection between
    the neuronal layers that are weighted and the learning process that updates these
    weights. Data fusion models can be established using neural networks such that
    neurons and interconnecting weights are assigned based on the relationship between
    the multi-sensor data input and the signal output. The neural networks can be
    multilayer feed-forward or recurrent type. [34] Unlike Kalman filters, neural
    networks offer non-linear transfer functions and parallel processing capabilities.
    This can help in performing image fusion. Figure 9 shows a basic structure of
    three layer neural network with nonlinear mapping. Fig. 8. Track to track fusion
    architecture [33]. Show All Fig. 9. Neural network structure for sensor fusion
    [34]. Show All The fused output is a combination of input signal and corresponding
    weights calculated by the equation [34]: y= ∑ i=0 n w i x i (9) View Source where,
    wi is the weight; Xi is the sensor data. Several fusion methodologies are used
    and depending on the input and outputs required the stages in the model can perform
    either signal, feature or decision level fusion. These methods are either used
    as standalone or can be combined with aforementioned signal fusion methods. The
    probabilistic approach for sensor fusion includes the use of joint probability
    distributions and Gaussian distributions [38]. Other fusion methods include Bayesian,
    least-squares for feature extraction [39] and some statistical approaches. [18],
    [32], [40]. In [35]–[37] the authors explain various approaches for modeling sensor
    fusion architecture using neural networks. SECTION VII. Decision Level Fusion
    Also known as Symbol level fusion, the decision level fusion combines several
    sub-decisions or features to yield a final or higher decision that can be used
    to take an action. Symbol could be an input decision. In this case, fusion of
    symbolic information insists the use of reasoning and inference while handling
    uncertainty. Symbol level fusion increases the confidence or truth value and is
    considered as decision fusion [41], [42]. Identity and Knowledge based methods
    form the two categories of decision fusion [20], [42]. Table IV [20], [42] lists
    few of the decision fusion methods or Al techniques for each category. One of
    the most widely used decision or inference method is Dempster-Shafer theory (D-S
    theory). This method is very useful for human-robot interaction based applications
    [41], [42], [45], [46]. We describe in detail the D-S theory in the following
    sub-section followed by a comparison with Bayesian inference which is another
    widely used decision fusion technique. A. Dempster-Shafer Theory of Evidence D-S
    theory is a generalization of the probability theory [41], [43]–[45]. In this
    method, a frame of discernment Ω is defined which is set of elementary hypotheses:
    Ω={ a i },i=1,…,n (10) View Source Table IV. Decision fusion models [20], [42]
    The sum of the mass function of all hypotheses is one. Belief function is used
    to express inaccurate beliefs. Mass values are assigned to the elements of the
    power set 2 Ω of the frame of discernment which hold the following properties:
    belief(null)=0 View Source belief (hypothesis) = Sum of all mass functions for
    all evidence to support the proposition. The confidence interval is upper-bounded
    by the plausibility value to include all observations that don''t rule out the
    proposition supported by the corresponding belief function. In order to combine
    two mass functions m1 and m2 the Dempster-Shafer theory defines the following
    rule [43], [44]: m 1 ⊕ m 2 (∅)=0 m 1 ⊕ m 2 (H)= ∑ X∩Y=H m 1 (X) m 2 (Y) 1− ∑ X∩Y=∅
    m 1 (X) m 2 (Y) (11) (12) View Source B. Dempster-Shafer and Bayesian Fusion Comparison
    Although both these methods are widely used in inference engines there are few
    differences between them [42], [46]. The main difference being the concept of
    support and plausibility to define uncertainty limits in Dempster-Shafer [42]–[44]
    which is not found in Bayesian inference. D-S theory is an evidential reasoning
    method where belief masses can be assigned to elements and sets, and on sets of
    sets [42]. Capturing ignorance or uncertainty is another strong feature of evidential
    reasoning methods which is not achievable in probabilistic methods. It is not
    necessary to have a prori probabilities and data is provided only at the time
    when sensor reads them [42], [46] during observation. Dempster-Shafer theory of
    evidence finds widespread use in human-robot interactive (HRI) applications. A
    review of a few applications of HRI can be found in [47]. By using the power set
    as the frame of discernment beliefs can well represented. However, when the set
    is continuous the number of subsets cannot be measured and hence this is a significant
    limitation that is found in evidential reasoning methods [41], [42] that work
    well with discrete sets. In our current research, we are working on a sensor fusion
    framework for robotic vehicle navigation in an unknown terrain. The framework
    is similar to waterfall fusion model and uses track to track fusion and Dempster-Shafer
    theory of evidence for signal and decision level fusions. SECTION VIII. Conclusion
    In this paper a brief overview of the various concepts of multi-sensor fusion
    was presented. The types of sensor fusion, the sensor fusion topologies and architectures
    were reviewed. Signal level and Decision level fusion was also covered highlighting
    the methods used to achieve each of them. Authors Figures References Citations
    Keywords Metrics More Like This High availability analysis and evaluation of heterogeneous
    dual computer fault-tolerant system 2014 IEEE 5th International Conference on
    Software Engineering and Service Science Published: 2014 Biomedical sensors data
    fusion algorithm for enhancing the efficiency of fault-tolerant systems in case
    of wearable electronics device 2015 Conference Grid, Cloud & High Performance
    Computing in Science (ROLCG) Published: 2015 Show More IEEE Personal Account CHANGE
    USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile
    Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS
    Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT
    Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use |
    Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy
    A not-for-profit organization, IEEE is the world''s largest technical professional
    organization dedicated to advancing technology for the benefit of humanity. ©
    Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: null
  publication_year: 2017
  relevance_score1: 0
  relevance_score2: 0
  title: A survey of multisensor fusion techniques, architectures and methodologies
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1007/bf01606384
  analysis: '>'
  authors:
  - X. E. Gros
  - Peter A. Strachan
  - D. W. Lowden
  citation_count: 11
  full_citation: '>'
  full_text: '>

    Access provided by University of Nebraska, Lincoln Log in  |  Register Cart Home
    All Journals Research in Nondestructive Evaluation List of Issues Volume 6, Issue
    4 Theory and Implementation of NDT Data Fu .... Search in:                                        This
    Journal                                                                                Anywhere                                                                  Advanced
    search Research in Nondestructive Evaluation Volume 6, 1995 - Issue 4 Submit an
    article Journal homepage Full access 30 Views 14 CrossRef citations to date 0
    Altmetric Original Articles Theory and Implementation of NDT Data Fusion X. E.
    Gros, P. Strachan & D. W. Lowden Pages 227-236 | Published online: 21 Apr 2009
    Cite this article   References Citations Metrics Reprints & Permissions View PDF
    Abstract Scientific measurements from single or multiple sensors are usually incomplete
    and uncertain. A process making use of the concept of data fusion has been developed
    to try to encompass this problem by combining information from multiple sensors.
    The objective to synergistic use of information from multiple sources is to reduce
    uncertainty and increase the confidence level of a measurand. The implementation
    of data fusion to the field of NDT is relatively new. This paper summarizes the
    achievements of current research on data fusion applied to NDT. A theoretical
    data fusion strategy is described and experimental results generated from weld
    inspection are presented. Previous article View issue table of contents Next article
    Download PDF X Facebook LinkedIn Email Share Related research  Recommended articles
    Cited by 14 Towards data fusion-based big data analytics for intrusion detection
    Farah Jemili Journal of Information and Telecommunication Published online: 24
    May 2023 NDT spatial data integration for monumental buildings: technical information
    management for the Royal Alcazar of Seville Francisco M. Hidalgo-Sánchez et al.
    Building Research & Information Published online: 2 Feb 2023 Multimodal data fusion
    for systems improvement: A review Nathan Gaw et al. IISE Transactions Published
    online: 3 Dec 2021 View more Information for Authors R&D professionals Editors
    Librarians Societies Open access Overview Open journals Open Select Dove Medical
    Press F1000Research Opportunities Reprints and e-prints Advertising solutions
    Accelerated publication Corporate access solutions Help and information Help and
    contact Newsroom All journals Books Keep up to date Register to receive personalised
    research and resources by email Sign me up Copyright © 2024 Informa UK Limited
    Privacy policy Cookies Terms & conditions Accessibility Registered in England
    & Wales No. 3099067 5 Howick Place | London | SW1P 1WG     Cookies Button About
    Cookies On This Site We and our partners use cookies to enhance your website experience,
    learn how our site is used, offer personalised features, measure the effectiveness
    of our services, and tailor content and ads to your interests while you navigate
    on the web or interact with us across devices. By clicking "Continue" or continuing
    to browse our site you are agreeing to our and our partners use of cookies. For
    more information seePrivacy Policy CONTINUE'
  inline_citation: '>'
  journal: Research in Nondestructive Evaluation
  limitations: '>'
  pdf_link: null
  publication_year: 1995
  relevance_score1: 0
  relevance_score2: 0
  title: Theory and implementation of NDT data fusion
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/s17092010
  analysis: '>'
  authors:
  - Gonçalo de Jesus
  - António Casimiro
  - Anabela Oliveira
  citation_count: 30
  full_citation: '>'
  full_text: '>

    sensors

    Article

    A Survey on Data Quality for Dependable

    Monitoring in Wireless Sensor Networks

    Gonçalo Jesus 1,*

    ID , António Casimiro 2,*

    ID and Anabela Oliveira 1,*

    1

    Hydraulics and Environment Department, LNEC, Lisbon 1700-066, Portugal

    2

    LaSIGE, Faculdade de Ciências, Universidade de Lisboa, Lisbon 1749-016, Portugal

    *

    Correspondence: gjesus@lnec.pt (G.J.); casim@ciencias.ulisboa.pt (A.C.); aoliveira@lnec.pt
    (A.O.)

    Received: 29 June 2017; Accepted: 31 August 2017; Published: 2 September 2017

    Abstract: Wireless sensor networks are being increasingly used in several application
    areas,

    particularly to collect data and monitor physical processes. Non-functional requirements,
    like

    reliability, security or availability, are often important and must be accounted
    for in the application

    development. For that purpose, there is a large body of knowledge on dependability
    techniques for

    distributed systems, which provide a good basis to understand how to satisfy these
    non-functional

    requirements of WSN-based monitoring applications. Given the data-centric nature
    of monitoring

    applications, it is of particular importance to ensure that data are reliable
    or, more generically,

    that they have the necessary quality. In this survey, we look into the problem
    of ensuring the

    desired quality of data for dependable monitoring using WSNs. We take a dependability-oriented

    perspective, reviewing the possible impairments to dependability and the prominent
    existing

    solutions to solve or mitigate these impairments. Despite the variety of components
    that may form a

    WSN-based monitoring system, we give particular attention to understanding which
    faults can affect

    sensors, how they can affect the quality of the information and how this quality
    can be improved

    and quantiﬁed.

    Keywords: wireless sensor networks; dependability; machine learning; monitoring;
    data quality;

    sensor fusion

    1. Introduction

    In order to increase the dependability of monitoring applications in wireless
    sensor network (WSN)

    settings, one must be aware that the quality of monitoring data can be affected
    by faults. In essence,

    there is a problem of data quality assurance, which can be faced taking two main
    perspectives: either

    by deploying dependability techniques to mask faults and enforce the reliability
    of the system or

    by enhancing the system with means to continuously assess and characterize the
    quality of data [1].

    In the former case, the system will not be aware of the quality of data, and hence,
    if a certain quality

    is needed, it must be enforced by design, conﬁning the effects of faults a priori.
    Considering sensors

    to be the main source of data, errors in sensing measurements are handled by procedures
    that are

    established based on a deep understanding of the characteristics of the sensors
    [2]. Missing readings

    may be handled by oversampling, and glitches, like outliers and noise, can be
    masked by averaging.

    In the latter case, given that the system can be aware of the quality of data
    at run-time, it is better

    suited to be used in environments where full knowledge of the operational conditions
    is not known

    in advance. In this case, mitigation techniques must be deployed to handle faults
    and data quality

    problems at run-time, for instance exploiting application semantics to determine
    appropriate data

    corrections and to regain the needed data quality. Given that no system can be
    built to exhibit 100%

    reliability, the two perspectives can be combined. In this paper, we take the
    latter perspective and

    consider that the quality of sensor data can be assessed, providing an indication
    of the overall system

    health, encompassing sensors, the wireless network and the processing tasks.

    Sensors 2017, 17, 2010; doi:10.3390/s17092010

    www.mdpi.com/journal/sensors

    Sensors 2017, 17, 2010

    2 of 23

    Assuring the quality of sensor data for a dependable operation is particularly
    challenging in

    some WSN-based monitoring applications. In fact, it is often the case that the
    sensors and the

    WSN are deployed in harsh environments and exposed to extreme physical conditions,
    thus being

    more likely affected by faults. The problem becomes critical when dependability
    is an important

    application requirement. For instance, in water-related information systems, inaccurate
    information in

    aquatic monitoring may lead to false warnings being issued or harmful situations
    not being detected

    early enough (e.g., ﬂoods or pollution events). As another example, WSNs are deployed
    in data

    centers for ﬂexible temperature monitoring and energy-efﬁcient control of air-cooling
    equipment [3,4].

    Therefore, ensuring the accuracy of collected data is also necessary for effectiveness
    reasons. In these

    examples, the operational conditions are typically hard to accurately predict,
    ensuring that the

    reliability of operations is often hard or costly, and the consequences of inaccurate
    sensor data collection

    can be severe.

    In this survey, we characterize and systematize existing solutions to dependable
    monitoring in

    WSNs by approaching them in two steps. In the ﬁrst step, we look at the root cause
    of dependability

    problems concerning the quality of sensor data, that is we identify and analyze
    several kinds of faults

    that may affect the system operation, in particular at the sensor and network
    levels, describing

    the speciﬁc effect on the sensor data and the relevant failure modes [5] that
    allow abstracting

    particular kinds of faults. When appropriate, we also refer to particular mitigation
    solutions to

    automatically adjust the sensors measurements according to each disturbance. Then,
    we provide a

    comprehensive overview of the solutions to achieve improved sensor data quality
    and dependable

    operation of WSN-based monitoring applications. In addition to detection and correction
    strategies,

    fault-tolerance strategies based on sensor data fusion procedures, exploiting
    the availability of

    redundant measurements or available modeling surrogates, are surveyed. However,
    there is a focus on

    works and solutions related to monitoring in aquatic environments, noting that
    these solutions are also

    applicable in many other contexts, but that the opposite might not be true, in
    particular concerning

    solutions that are not agnostic to the semantics of the monitored data.

    The remainder of the paper is organized as follows. Section 2 exposes a set of
    fundamental ideas

    related to the issue of data quality in WSNs, motivating the need for dependability,
    introducing the

    baseline architecture for a WSN-based monitoring system and referring to the main
    dependability

    strategies that may be employed. Section 3 describes the notion of data quality
    and the main aspects

    that may affect this quality during monitoring. Section 4 presents an overview
    of solutions for

    dependable sensor networks. We will conclude in Section 5, with a discussion of
    the possible results of

    the solutions mentioned herein.

    2. Overview of Key Issues

    2.1. Motivation

    Complex and powerful forecast systems are now able to predict environmental variables
    such as

    storm events with small errors, but they depend on a continuous ﬂow of conﬁrmation
    with real-time

    data for robustness. Real-time monitoring data, such as surface water elevation,
    ﬂow or water quality

    variables depend solely on the sensor hardware deployed in the physical environment
    (oceans, river,

    lakes, etc.) and its proper maintenance.

    The effectiveness of existing emergency warning and forecast procedures for natural
    and

    man-made hazardous events may be limited by several factors, including an often
    sparse and unreliable

    real-time observational network, the use of coarse-resolution prediction models
    and the reliance on

    traditional approaches to convey warning and forecast information.

    In spite of the vast research on the dependability of distributed systems, in
    particular on

    computational architectures/frameworks for reliable and timely operations, monitoring
    systems

    pose new challenges to dependability. The sensory and sensor network technologies,
    which are now

    becoming widely available, are subject to diverse hazards and are not sufﬁciently
    reliable and robust

    Sensors 2017, 17, 2010

    3 of 23

    against harsh exogenous and/or environmental factors. In this ﬁeld, there is still
    a lack of architectural,

    fault-tolerant and system management solutions, which are essential for dependable,
    robust remote

    monitoring, necessary for adequate water management.

    Ensuring the quality of monitoring data is fundamental to avoid false alarms or
    ignoring relevant

    data. However, because these sensors are located in the physical environment,
    they are constantly

    being subjected to factors that directly interfere with the data quality, such
    as potentially strong

    currents, debris accumulation and tough weather conditions. Consequently, there
    is a trust issue

    related to the collected data, which demands an extensive human intervention in
    terms of time and

    knowledge specialization, data validation tasks and periodic maintenance of sensors.
    To deal with this

    problem, it is necessary to continuously and automatically characterize the quality
    of collected data.

    Hence, the application of techniques based in the existence of redundancy at the
    data collection and

    data processing levels is a promising approach.

    2.2. Monitoring and Data Processing

    The process of environment monitoring requires sensor devices to be deployed within
    the system.

    These sensors will be the entities responsible for measuring the parameters of
    interest, like temperature,

    water level or salinity. A sensor essentially converts a physical quantity in
    its input to an electrical

    signal, produced as the output, which is usually proportional to the input. Further
    to the sensor itself,

    additional components are needed to perform signal processing functions, store
    measured values

    and communicate these values to other systems. It is hence usual to refer to these
    more complex

    components as smart sensors or intelligent sensors [6], typically interconnected
    to other smart sensors

    to form wireless sensor networks.

    For monitoring and control purposes, wireless sensor networks have become a subject
    of interest

    in recent years, mostly due to enormous advances in sensing and communication
    technology, which

    has fostered the use of smart sensors, with applications in many ﬁelds: (a) military
    applications;

    (b) environmental monitoring; (c) commerce; (d) human-centric applications; and
    (e) applications to

    robotics (Arampatzis et al. [7]). WSNs are formed by smart sensor nodes, and each
    sensor node may

    have several individual sensors, in which case they are said to be clustered.
    Information collected by

    sensor nodes is typically transmitted to a sink or controller node.

    After the sensors measurement step, performed usually through a WSN, there is
    another layer

    in the overall system that comprises the gathering and analysis of the measurements,
    including

    information fusion (Section 4). This phase is commonly referred to as data processing
    (see Figure 1).

    Our goal is to describe and enumerate the processes involved in each layer of
    the scheme in

    Figure 1. In a bottom-up perspective, the ﬁrst layer is the physical environment
    (it can also be deﬁned

    as the object or the event to be monitored), which can have a great inﬂuence on
    the measurements.

    Although there are many speciﬁc external factors related to perturbation events
    or objects in all of the

    different applications of WSNs, we decided to tackle the problems of the involved
    water body by ﬁrst

    enumerating well-known limitations of sensor devices in Section 3.2.

    On the second layer, we are considering that in terms of faults and validity issues,
    monitoring

    has two abstraction levels: the sensors and communication between them. Each level
    has a particular

    fault model, with faults arising from different sources (see Figure 2). We will
    explore these subjects in

    Sections 3.2 and 3.3 with the respective mitigation solutions.

    Finally, in order to centrally analyze all of the sensing information, a third
    layer appears in the

    system. In the data processing layer, it is possible to infer the quality of the
    gathered information,

    through fusion processes of redundant and related measurements, by multi-sensor
    fusion methods,

    or by expert-knowledge of the system model. In fact, this is where we can ultimately
    handle both

    sensor and network-level problems and apply the mitigation techniques identiﬁed
    already in Figure 2.

    These techniques will be addressed in Section 4.

    Sensors 2017, 17, 2010

    4 of 23

    No Faults

    Validity Model

    Fusion Output

    Quality Factor

    WSN

    Network

    Sensors

    Communication Faults

    Sensor Faults

    Fault Model

    Fault Model

    Validity Model

    Figure 1. Generic view of the WSN-based monitoring system.

    Sensor level

    Network level

    - sensor node crashes

    - message omissions

    - message delays

    - message corruption

    - auto-calibration

    - micro-processing

    - compensation

    - node redundancy

    - message retransmission

    - value estimation

    - integrity verification

    - random errors

    - calibration errors

    - loading errors

    - environmental errors

    - spurious readings

    Impairments

    Mitigation

    Figure 2. Sensor and WSN faults and mitigation solutions.

    2.3. Dependability Strategies

    When designing a fault-tolerant and dependable system, the typical means to deal
    with system

    errors and faults include error detection and error or fault recovery. In this
    context, endowing the

    system with redundant components can be instrumental to compensate existing errors
    or faults

    affecting some component.

    The affected component can be replaced in its tasks by the spare,

    redundancy component, which will ensure that the system function will continue
    to be provided.

    However, redundancy does not refer solely to having multiple similar components,
    which is a form of

    space redundancy. It is also possible to implement forms of redundancy in the
    time (e.g., repeating

    some action multiple times) and in the value domains (e.g., adding extra information)
    [8].

    Some examples of space redundancy include storing information in several disks,
    machines

    or data centers, having multiple nodes performing the same computation (either
    in parallel, called

    active replication, or with some nodes in stand-by mode, called passive replication),
    or sending a

    network message through multiple network paths. Time redundancy is typically explored
    in reliable

    Sensors 2017, 17, 2010

    5 of 23

    communication systems that retransmit messages when they suspect that these messages
    might have

    been lost in previous transmissions. Restarting an aborted transaction or a deadlocked
    computation

    are also examples of time redundancy. Finally, value redundancy is observed in
    data storage and

    communication systems that use error correcting codes associated with the stored
    or transmitted data,

    allowing the original information to be reconstructed when some bits or parts
    of the information

    become corrupted. To deal with malicious forms of information corruption, cryptographic
    signatures

    may be used.

    In the application of these concepts to sensor validation, [9] stated that there
    are two

    classical approaches that are widely used: (a) analytical redundancy and (b) hardware
    redundancy.

    Analytical redundancy uses mathematical relationships between measurements to
    predict or infer a

    sensor’s value. Two disadvantages of this approach are the possible inefﬁciency
    of the mathematical

    processes when we have a large number of sensors and the model complexity increases
    and the fact

    that the mathematical relationships can be very data speciﬁc, and a slight modiﬁcation
    may require

    signiﬁcant efforts to stabilize. Hardware redundancy is not always possible because
    of the costs

    implied by additional sensors and their installation and maintenance operations.

    The right approach to be used depends on several issues, like the assumed fault
    model, the

    criticality of the application, the cost or timeliness requirements. In some cases,
    several dependability

    techniques can be used in a single system to deal with different problems or to
    achieve the needed

    levels of assurance. This is particularly true in complex systems, like aquatic
    systems, in which

    different techniques can be applicable to mitigate faults in the sensing process
    and to handle WSN

    faults. Combinations of the solutions mentioned later in this survey (Section
    4.1) may thus be used in

    the design of a single system.

    3. Sensor Data Quality

    When the quality of sensor data is an important attribute for the dependability
    of the application,

    it becomes necessary to somehow express this quality, which can be done in various
    ways. Additionally,

    a priori knowledge about the possible causes of quality degradation, translated
    into faults and a

    corresponding fault model, is also relevant. It will enable a more accurate characterization
    of the quality

    of sensor data and the possibly of incorporating in the system some techniques
    to mitigate the effects

    of speciﬁc faults assumed in the fault model. These aspects are addressed in the
    following sections.

    3.1. Expressing Data Quality

    The interpretation and modeling of the available information into adequate theoretical

    frameworks is the main means to characterize the quality of the obtained sensor
    data. These qualitative

    interpretations of sensor data can become confusing when different authors introduce
    an array of

    terms for quality (the most generic), including:

    •

    Validity is typically employed when a determined requirement about the quality
    of data is

    available, against which it is possible to compare some quality measure and declare
    if the data

    are valid [1,10].

    •

    Conﬁdence is an attribute that may be elaborated from the continuous observation
    of sensor data,

    without the need for a quality requirement to be available. It is generally used
    when datasets are

    available and can be characterized in a probabilistic way, along with model ﬁtting
    or threshold

    deﬁnition techniques, to yield continuous or multi-level conﬁdence measures [11].

    •

    Reliability is a typical dependability attribute [12], expressing the ability
    of a system to provide

    the correct service (or the correct data, for that matter) over a period of time.
    The term data

    reliability in sensor networks is often considered when transmissions and/or communications

    may be subject to faults like omissions or a total crash [13,14].

    •

    Trustworthiness is mostly employed in connection with security concerns, namely
    when it

    is assumed that data can be altered in a malicious way. In the context of sensor
    networks,

    Sensors 2017, 17, 2010

    6 of 23

    it characterizes the degree to which it is possible to trust that sensor data
    have not been tampered

    with and have thus the needed quality [15].

    •

    Authenticity is also used, in particular in a security context, but to express
    the degree to which it is

    possible to trust the claimed data origin [16]. This is particularly important
    when the overall quality

    of the system or application depends on the correct association of some data to
    their producer.

    This terminology does contain other terms, including other aspects of data quality
    that are

    implicit and brieﬂy approached herein, such as timeliness, precision, tunability,
    completeness, usability,

    accuracy, throughput, affordability and reusability [17]. We will also describe
    herein the diverse

    typologies of data quality and how to obtain a quality parameter, either for each
    individual sensor

    or for the global system, according to several studies. Therefore, in terms of
    applicability, we must

    differentiate single-sensor validity from multi-sensor fusion validity, when several
    sensors exist and

    sensor fusion can be applied.

    In single-sensor situations, there are models or related information that allow
    reasoning about

    an individual sensor’s data quality without requiring other sensors’ data. The
    work in [18] tried

    to identify faulty situations (see Section 3.2) such as noise and outliers in
    chlorophyll concentration

    sensors deployed in lake water, by implementing different fault detection methods:

    •

    Rule-based methods that use expert knowledge about the variables that sensors
    are measuring to

    determine thresholds or heuristics with which the sensors must comply.

    •

    Estimation methods that deﬁne a “normal” behavior by considering spatial and temporal

    correlations from sensor data. A sensor reading is matched alongside its forecasted
    value to

    assess its validity.

    •

    Learning-based methods that deﬁne models for correct and faulty sensor measurements,
    using

    collected data for building the models.

    In the example from [18], all three methods were used to assert the correctness
    (or incorrectness)

    of the collected data, thus adopting a Boolean approach to quality characterization.
    However, the

    same methods may be employed in other ways, as a means to characterize quality
    in a step-wise or

    even continuous way. For instance, and still considering a single-sensor situation,
    [11] employed fuzzy

    logic rules to obtain a qualitative sense of a sensor’s validity based on its
    own historical behavior

    represented by a conﬁdence measure.

    In a multi-sensor situation, the quality of sensor measurements is characterized
    by using

    redundant or correlated data obtained from the different sensors. This redundancy
    allows for data

    fusion methods to be deployed at the network level, resulting in improved (fused)
    sensor data, as

    well as improved data quality characterization. Various quality-oriented network
    meta-models can be

    explored according to the application requirements. For instance, in [17], the
    data quality is calculated

    through the several nodes (and the sink) on the entire WSN structure.

    Sensor data fusion methods will be detailed in Section 4. As for the quality characterization
    process

    when data fusion is performed, the applicable methodology depends on the available
    information

    concerning the quality of individual sensor measurements. In fact, this information
    can also be used in

    the data fusion process itself.

    For instance, in [11], the approach relied on a statistical method (Parzen estimation
    of the

    probability density function) to determine the variance of sensors’ data and to
    calculate the average of

    the sensors, considering just the sensors with a high-quality standard in the
    data fusion process. If all

    sensors are producing high-quality data, then the fusion will also reach the highest
    possible quality.

    Otherwise, better results will be achieved when discarding sensor data with lower
    quality, rather than

    using these data in the fusion process.

    Another example can be found in [19], where reliability estimates are calculated
    for sensor data,

    using Bayesian networks or random forests to obtain reliability coefﬁcients, and
    then, these reliability

    estimates are used in a sensor fusion process to discard sources that are considered
    unreliable if the

    reliability estimate is below a deﬁned threshold.

    Sensors 2017, 17, 2010

    7 of 23

    Regarding the quantiﬁcation of data quality, the two main approaches consist of
    considering

    discrete quality classes or continuous quality values.

    In the discrete approach, it is possible to use binary classes, such as {valid,
    invalid} [20], or to use

    a multi-level class, like {verylow, low, high, veryhigh} [11]. These discrete
    classiﬁcations can be applied

    to each sensor (individual sensor data) or to the whole network of sensors (fused
    data).

    In the continuous approach, a conﬁdence level is usually derived, ranging in a
    well-deﬁned

    continuous interval (often [0, 1] or equivalently [0%, 100%]).

    Therefore, the validity of sensor

    information may not only have the values “true and” “false”, especially if one
    must process

    continuously-valued data [1,9]. For instance, a noisy sensor (internal or external
    noise) may deliver

    useful data within some error margin, but the quality of that data is lower than
    that from a non-noisy

    sensor. In a multi-sensor fusion application, the quality quantiﬁcation can be
    calculated using a

    cumulative association of each sensor quality coefﬁcient [21] or calculating the
    percentage of sensors

    used in the fusion against the sensors in the network.

    3.2. Sensor Level Faults

    In this subsection, we present a systematization of the main types of sensors
    and their

    characteristics, classifying the various data errors that may be produced by sensors.
    From the

    perspective of building modular dependable systems, what is interesting is to
    group the several

    possible faults and the consequent data errors into well-deﬁned sensor failure
    modes. We thus identify

    the relevant failure modes under which a sensor can fail and produce data with
    degraded quality.

    The focus herein is on the sensor level, whereas the next subsection addresses
    network level faults.

    Finally, we also focus on possible mitigation techniques to handle sensor faults.

    3.2.1. Sensor Characteristics

    We begin to dissect sensor faults by exploring the transducing processes, enumerating
    the different

    methods to convert the various physical effects into electric signals, as well
    as each one’s advantages

    and limitations. This enumeration is important to the survey, to understand the
    most basic origins of

    faults in sensors. The sensor material characteristics or the harshness of the
    environmental conditions

    lead to the production of a speciﬁc kind of fault. Some sensors strive to perceive
    an object that is

    moving in dusty environments, while others experience issues reading a correct
    level observation

    in ﬂuids. For instance, capacitive sensors present a considerable sensitivity
    and require low energy

    usage, making them an attractive choice for many areas, but as pointed out by
    [22], the response

    characteristics of these sensors are very nonlinear, and the offset capacitance
    is non-negligible and

    must be handled to correctly detect capacitance variations due to the applied
    pressure and to avoid

    errors. In summary, from a dependability perspective, it is important to distinguish
    sensors in terms of

    their operation and robustness to distinct environment conditions. When a sensor
    is highly sensitive,

    but frequently faulty, a redundancy solution must be considered, possibly using
    a sensor that offers

    the same sensitivity, but is more reliable.

    The main types of sensors according to the exploitation of displacement effects
    are

    the following [23]:

    •

    Resistance: Resistive sensors, also termed potentiometers, are based on an electromechanical

    instrument that transforms a mechanical variation, like a displacement, into an
    electrical signal

    capable of being monitored following conditioning;

    •

    Induction: Inductive sensors are primarily based on the principles of magnetic
    circuits and may

    be categorized as self-generating or passive;

    •

    Capacitance: Capacitive sensors depend on variations in capacitance in reply to
    physical changes.

    A capacitive level pointer uses the changes in the comparative permittivity among
    the plates;

    •

    Piezoelectricity: Piezoelectricity is the term used to determine the capacity
    of speciﬁc materials to

    create an electric charge that is relative to a directly applied mechanical pressure;

    Sensors 2017, 17, 2010

    8 of 23

    •

    Laser: Laser sensors compare changes in optical path length and in the wavelength
    of light, which

    can be determined with very little uncertainty. Laser sensors achieve a high precision
    in the

    length and displacement measurements, where the precision achieved by mechanical
    means is

    not enough;

    •

    Ultrasonic: Uses the time-of-ﬂight method as the standard for the use of ultrasound
    for monitoring

    purposes. A pulse of ultrasound is transmitted in a medium, reﬂecting when it
    reaches another

    medium, and the time from emission to recognition of the reﬂected pulsation is
    read;

    •

    Optical: Optical sensors encompass a variety of parts that use light as the means
    to convert

    kinetics into electrical signals, comprised mostly of two components: a main diffraction
    grating,

    representing the measurement standard (scale); and a detection system. What is
    detected is the

    position of one regarding the other;

    •

    Magnetic: A magnetic sensor is either triggered to function by a magnetic ﬁeld
    or the use of the

    ﬁeld that deﬁnes the properties of the sensor;

    In Table 1, a summary of the relative advantages and disadvantages of each of
    the described

    displacement effects is presented. The goal here is not to choose the best type
    of sensor, but to

    discriminate the strong and weak points of all of the types.

    Table 1. Advantages and disadvantages of the various displacement effects [23–25].

    Displacement Effects

    Advantages

    Disadvantages

    Resistance

    Versatile; inexpensive; easy-to-use; precise.

    Limited bandwidth; limited durability.

    Induction

    Robust; compact; not easily affected by

    external factors.

    A signiﬁcant part of the measurement is

    external, which must be well cleaned and

    calibrated.

    Capacitance

    Low-power consumption; non-contacting;

    resists shocks and intense vibrations;

    tolerant to high temperatures; high

    sensitivity over a wide temperature range.

    Short sensing distance; humidity in

    coastal/water climates can affect sensing

    output; not at all selective for its target;

    non-linearity problems.

    Piezoelectricity

    Ideal for use in low-noise measurement

    systems; high sensitivity; low cost; broad

    frequency range; exceptional linearity;

    excellent repeatability; small size.

    Cannot be used for static measurements;

    high temperatures cause a drop in internal

    resistance and sensitivity (characteristics

    vary with temperature).

    Laser

    Ideal for near real-time applications; low

    uncertainty and high precision in the

    measurements.

    Weather and visual paths affect the sensor

    when measuring distance or related

    variables.

    Ultrasonic

    Independent of the surface color or optical

    reﬂectivity of the sensing object; excellent

    repeatability and sensing accuracy;

    response is linear with distance.

    Requires a hard ﬂat surface; not immune to

    loud noise; slow measurements in

    proximity sensors; changes in the

    environment affect the response; targets

    with low density may absorb sound energy;

    minimum sensing distance required.

    Optical encoding

    Inherently digital (which makes the

    interface easy for control systems); fast

    measurements; long durability.

    Fairly complex; delicate parts; low

    tolerance to mechanical abuse; low

    tolerance to high temperatures.

    Magnetic

    Non-contacting; high durability; high

    sensitivity; small size; output is highly

    linear.

    Very sensitive to fabrication tolerances;

    calibration needed after installation.

    Beyond the limitations of the transducers, [26] explained other causes of measurement
    uncertainty

    and how only an estimation of the observed physical property can be given. When
    considering

    individual sensor measurements, the possible types of errors observed in measurement
    values can be

    classiﬁed as follows:

    •

    Random errors are described by an absence of repeatability in the readings of
    the sensor, for

    instance due to measurement noise. These errors tend to happen on a permanent
    basis, but have a

    stochastic nature;

    Sensors 2017, 17, 2010

    9 of 23

    •

    Systematic errors are described through consistency and repeatability in the temporal
    domain.

    There are three types of systematic errors at the sensor level:

    –

    Calibration errors result from errors in the calibration procedure, often in relation
    to

    linearization procedures;

    –

    Loading errors emerge when the intrusive nature of the sensor modiﬁes the measurand.

    Along with calibration errors, loading errors are caused by internal processes;

    –

    Environmental errors emerge when the sensor experiences the surrounding environment

    and these inﬂuences are not considered. In contrast with the previous two types
    of errors,

    environmental errors are due to external factors;

    •

    Spurious readings are non-systematic reading errors. They occur when some spurious
    physical

    occurrence leads to a measurement value that does not reﬂect the intended reality.
    For instance, a

    light intensity measurement in a room can provide the wrong value if obtained
    precisely when a

    picture of the room is taken and the camera ﬂash is triggered.

    3.2.2. Sensor Failure Modes

    The classiﬁcation presented above builds essentially on the persistence and nature
    of the

    observable value errors. An alternative way to acknowledge and to deal with the
    fact that sensor

    measurements are affected by uncertainties, which is commonly used when building
    modular

    distributed systems, is to identify relevant sensor failure modes. Independently
    of the several factors

    leading to a sensor fault and the consequent measurement error(s), the faulty
    behavior of the sensor

    component is observed through its interface, that is, through the values it produces.
    Therefore, a

    failure mode characterizes a certain deviating behavior, abstracting its causes
    and considering only the

    measurement values produced at the sensor interface.

    The main sensor failures modes, depicted in Figure 3, are the following [1]:

    1.

    Constant or offset failure mode: The observations continuously deviate from the
    expected value

    by a constant offset.

    2.

    Continuous varying or drifting failure mode: The deviation between the observations
    and the

    expected value is continuously changing according to some continuous time-dependent
    function

    (linear or non-linear).

    3.

    Crash or jammed failure mode: The sensor stops providing any readings on its interface
    or gets

    jammed and stuck in some incorrect value.

    4.

    Trimming failure mode: The observations are correct for values within some interval,
    but are

    modiﬁed for values outside that interval. Beyond the interval, the observation
    can be trimmed at

    the interval boundary or may vary proportionally with the expected value.

    5.

    Outliers failure mode: The observations occasionally deviate from the expected
    value, at random

    points in the time domain;

    6.

    Noise failure mode: The observations deviate from the expected value stochastically
    in the value

    domain and permanently in the temporal domain.

    (2)

    (3)

    (1)

    (4)

    (5)

    (6)

    Figure 3. Sensors’ failure modes. The faulty sensor output is represented with
    a ﬁlled line, whereas the

    real values are depicted with a dashed line.

    Sensors 2017, 17, 2010

    10 of 23

    Comparing this classiﬁcation of sensor failure modes with the classiﬁcation of
    sensor errors

    previously introduced, it is interesting to note the direct correspondence between
    the class of random

    errors and the noise failure mode and between the class of spurious errors and
    the outliers failure

    mode. The remaining four failure modes can be seen as specializations of the systematic
    errors class.

    3.2.3. Mitigation Techniques

    Regarding mitigation techniques to address faults and respective value errors,
    we make a

    separation between what can be done at the sensor level and what can be done at
    the distributed

    system level, namely within the application that uses the sensor data, possibly
    exploiting additional

    sources of information. Considering an individual sensor, it is possible to use
    dependability techniques

    to prevent or tolerate the occurrence of faults and achieve an improved behavior,
    possibly even

    removing some failure modes. This can be described as a “basic quality improvement”,
    and in

    what follows, we describe two basic techniques that are usually carried out to
    achieve this objective:

    calibration and measurand reconstruction. The general approaches for improving
    the quality of data

    in WSN monitoring applications are then covered in Section 4.

    Commonly, calibration is deﬁned as a test under speciﬁc conditions in which pre-determined

    known values of the measurand are given to the transducer and the corresponding
    outputs are

    recorded. In a formal way, calibration consists of deﬁning a function f (r, β)
    that, along with a set of

    selected device parameters β ∈ R, will translate real sensor output r to the intended
    output r*.

    Calibration actions are required every time a sensor is deployed in a different
    environment, as

    the physical measurement elements must be adjusted or even dedicated to the monitored
    device or

    process, providing at the start a reduction of measuring uncertainty and minimal
    interference with

    sensor functions. However, periodic calibrations are also needed, since during
    the operation, we can

    assist the change of conditions with respect to those known during the calibration
    process and to

    the impact of various external factors that could be absent in the laboratory
    calibration conditions.

    These factors can be the base cause of many errors and should hence be continuously
    re-evaluated.

    For instance, in aquatic sensors, offset and drifting errors are related to the
    accuracy range becoming

    unbalanced, which is solvable by recalibration. This is done off-ﬁeld (removing
    the sensor of the

    monitoring environment and recalibrating it in a container with water in controlled
    conditions), with

    potential data loss if no redundant way of collecting sensor data is available,
    and with re-deployment

    costs. It can also be done in the ﬁeld, which is a time-consuming task with sometimes
    difﬁcult

    conditions and, especially, exposing the calibration process to environmental
    factors that may affect the

    calibration accuracy.

    As alternatives to manual calibration, two generic options can be considered:
    factory sensor

    calibration, with the advantage of reducing the time consumption efforts of the
    initial manual process,

    but not completely eliminating the problems mentioned before; and auto or self-calibration,
    enabling

    sensors to monitor themselves and recalibrate using a reference. This latter option,
    which, being

    adaptive, is potentially better for dealing with varied and even unpredicted misbehavior,
    is designated

    as measurand reconstruction or sensor compensation.

    Auto-calibration refers to methods aimed at diminishing the effect of the disturbing
    parameters in

    the input/output features of sensors. Preferably, the transduced value must have
    a direct relation with

    the measurand, which should not be sensible to past information, interfering environmental
    factors,

    noise, error gain, etc. To try to compensate all of these disturbances, numerical
    techniques have to be

    used. These techniques are applied after the transformed signal has been quantiﬁed,
    through digital

    signal processing that must transform the sensor output signal (r*) into a corrected
    value ( ˆr*).

    Several auto-calibration techniques have been used with relative success, for
    instance exploiting

    statistical regression based on a priori knowledge [27] or artiﬁcial neural networks
    [28,29]. In the

    statistical regression approach, the goal is to determine the polynomial approximation
    to the

    characteristics of the sensor. In the artiﬁcial neural networks (ANN) approach,
    the inputs are the

    measurements, and the ideal outputs are the measurand. This model inversion is
    the reason why it is

    Sensors 2017, 17, 2010

    11 of 23

    called measurand reconstruction. Other machine-learning algorithms have also been
    applied, such

    as Kalman ﬁlters [30] and support vector machines [31], especially in order to
    overcome the ANN

    disadvantages: neural network training may not converge to the global optimum,
    and training may

    need to be repeated several times, which will be prejudicial with respect to the
    computational cost; and

    the poor generalization capabilities that may arise from insufﬁcient data, from
    over- or under-training

    or from under- or over-ﬁtting.

    3.3. Communication Faults in WSNs

    When connecting individual sensor nodes in a wireless sensor network, additional
    faults affecting

    sensor data can be introduced by the network. In this subsection, we focus on
    the main kinds of

    network faults that may affect the quality of sensor data in order to achieve
    a reliable network operation,

    speciﬁcally considering faults in the time domain and faults in the value domain.

    In the time domain, a crash, omission or delay faults could occur. Crash faults
    (for instance of the

    radio subsystem in a sensor node) lead to data absence and can only be mitigated
    with redundancy (e.g.,

    a dual-radio system). Omissions correspond to missing sensor readings due to lost
    messages. They can

    be prevented by enforcing communication reliability, for instance based on message
    retransmission.

    However, reliable communication protocols are not very common in WSNs due to the
    additional

    resources (namely energy) they require. Therefore, omissions do happen in sensor
    networks and for

    the most part emerge because of sensor failures and packet losses. Heavy packet
    loss and asymmetric

    links occur frequently in WSNs [32,33], for instance due to signal strength fading
    and intermittent or

    continuous environmental interference (e.g., wind or rain). Absent values inﬂuence
    the outcome of

    any query over sensor readings. The resulting inaccuracies can be critical as
    in in-network processing

    and aggregations [33–35]. Several solutions have been suggested to tolerate these
    types of errors such

    as masking lost values through redundant information or estimating using past
    values [34]. Although

    this problem has been studied and solved in many applications, one must be aware
    that it is impossible

    to fully avoid omissions. Finally, delay faults are only relevant when the correctness
    of the application

    depends on the timeliness of sensor data. This is typically the case in real-time
    control, where the

    temporal validity of sensor data is bounded [36]. Sensor data become useless after
    a certain amount of

    time due to not reﬂecting the present reality with sufﬁcient accuracy, possibly
    leading to system failures

    if used in the control process. Existing solutions to avoid timing failures are
    based on techniques from

    the real-time area, namely seizing the needed resources and using synchronized
    clocks to timestamp

    data and discard the outdated data. The existence of redundant sensor nodes can
    also be explored, to

    avoid missing important events.

    In the value domain, a communication fault is translated into a message corruption.

    However, communication protocols typically incorporate data integrity veriﬁcation
    mechanisms

    that allow the detection of corrupted messages, discarding those messages and
    hence transforming

    value faults into omission faults. Therefore, the only chance that received data
    do not correspond to

    what has been sent is when some part of the communication stack in the sending
    or receiving node

    (or both) is affected by an accidental fault not covered by the integrity veriﬁcation
    mechanisms or

    when it has been intentionally corrupted. In fact, WSNs and sensor nodes can be
    subject to attacks

    that may signiﬁcantly affect the quality of sensor data, among other consequences
    for the application.

    Therefore, in critical applications, it is important to deploy security techniques
    to avoid attacks or to

    mitigate their effects. These security techniques are, however, outside the scope
    of this survey.

    4. Solutions for Dependable Data Quality

    Several methods have been proposed in the literature to improve the quality of
    sensor data.

    Our focus is on solutions to mitigate the negative effects of faults on data quality.
    The ones that are

    applicable at the sensor level to mitigate data errors at the sensor interface
    have already been addressed

    in Section 3.2. In this section, we discuss what can be done at sink or processing
    nodes. We start

    by identifying and characterizing the three different forms of redundancy that
    may be explored for

    Sensors 2017, 17, 2010

    12 of 23

    dependable data quality. They are related to the available sources of information,
    to which data

    analysis and processing techniques can be applied: (a) single sensor data stream,
    (b) multi-sensor data

    streams or (c) multi-source data streams.

    Then,

    and given our focus on dependability aspects,

    we present a taxonomy for

    dependability-oriented data quality in WSNs. We identify the relevant dimensions
    to reason about

    dependable data quality, classifying the options within each of these dimensions.
    In this exercise,

    we introduce dependability-related categories concurring with the goal of estimating
    the quality of

    sensor data. In most cases, WSN-based monitoring systems address concerns (sometimes
    implicitly) of

    improving the quality of data, but not of estimating the achieved quality. The
    resulting systematization

    underlies the survey on concrete techniques for data processing, further ahead
    in the section.

    4.1. Exploiting Redundancy

    Redundancy is a fundamental dependability technique to achieve reliability, availability
    and even

    improved performance. Therefore, WSN applications naturally exploit the existence
    of multiple sensor

    nodes and the spatial redundancy they offer. In fact, if information relative
    to a certain environmental

    process is collected through several sensors, then it is possible to apply a range
    of data processing

    techniques to fuse the multiple data streams (from the different sensor nodes).
    This approach permits

    obtaining the resulting data with more quality, masking possible faults affecting
    data provided by

    some of the nodes. In sensor networks, it is also possible to exploit value redundancy
    [8] for improving

    the quality of data. This redundancy is offered, for instance, by environmental
    models describing the

    monitored dynamic process or setting limits to the static or dynamic attributes
    of this process. Finally,

    if sensor data from multiple sensor nodes cannot be correlated, then it is still
    possible to exploit a form

    of temporal redundancy. This temporal redundancy is intrinsic to continuous transmission,
    in a single

    ﬂow, of data samples that can be correlated over time.

    4.1.1. Spatial Redundancy

    The techniques aimed at exploiting spatial redundancy in WSN-based applications
    are known as

    sensor fusion techniques. Sensor fusion deals with sensor data from sensors in
    the same monitoring

    area. Through processes of comparison, combination and/or smart voting schemes,
    it may be

    possible to detect faulty behaviors, erroneous information and derive a corrected
    observation from the

    remaining (considered correct) data samples [37–39].

    Sensor fusion is realized by employing a collection of techniques, such as classical
    Bayesian,

    Dempster–Shafer inference, artiﬁcial neural networks and fuzzy logic. The less
    mature techniques

    are dominated by heuristic and ad hoc methods. The major algorithm categories
    and techniques are

    discussed in Sections 4.2.1 and 4.2.2.

    Sensor fusion is very useful in several situations, in particular in the following:
    (a) when some

    sensors measure correctly the intended phenomena, but others do not, due to failures;
    (b) when all

    sensors measure correctly, but some respond to a different phenomenology; (c)
    when the data of a

    sensor may be masked or counter measured with respect to one sensor, but not to
    another; (d) when

    one sensor may be blocked or unable to measure, but another sensor located elsewhere
    may have the

    correct data. In this case, the data from the sensor with the correct view may
    be combined with past

    information from the blocked sensor to update the overall measurements.

    The work in Reference [40] categorizes multi-sensor data fusion systems regarding
    what is

    observed by several sensors. Data fusion can take place:

    1.

    across sensors when several sensors observe the same variable; for instance, when
    the temperature

    of a particular object is monitored by a set of temperature sensors;

    2.

    across attributes when sensors observe several quantities related with one event;
    for instance,

    when measurements of water temperature and water conductivity are combined to
    deﬁne the

    water salinity;

    Sensors 2017, 17, 2010

    13 of 23

    3.

    across domains when sensors observe one speciﬁc attribute in several places. An
    example

    is when sensors in different places measure the temperature and the measured values
    are

    somehow correlated.

    4.

    across time when new readings are fused with past data. For example, historical
    information from

    a former calibration can be incorporated to make adjustments on current measurements.
    Note

    that this is a particular case that applies to systems with single sensors, which
    we speciﬁcally

    discuss later as a form of temporal redundancy.

    The work in Reference [41] provides a slightly different classiﬁcation of a multi-sensor
    data fusion

    system, which partially overlaps with the previous classiﬁcation. They consider
    that sensor fusion

    can be:

    1.

    competitive when every sensor conveys an autonomous reading of the same variable.
    The purpose

    of this type of fusion is to diminish the effects of uncertain and incorrect monitoring.

    Competitive fusion corresponds to sensor fusion across sensors, in the terminology
    of [40];

    2.

    cooperative when the data measured by many autonomous sensors is utilized to infer
    information

    that would not be accessible through each of the sensors. This corresponds to
    sensor fusion

    across attributes;

    3.

    complementary when sensors are not directly dependent, but might be merged with
    the

    speciﬁc goal of providing a more comprehensive view of what the network is trying
    to observe.

    Thus, complementary fusion can assist in solving the incompleteness problem. This
    category

    does not entirely match the categories by [40]; it is closer to sensor fusion
    across attributes, but

    the idea is not to extract information, but to complement it.

    From the above, it is clear that data fusion can take place in many ways and for
    different purposes,

    some of which are not speciﬁcally concerned with dependability issues, but rather
    functional issues.

    This is the case of cooperative sensor fusion, whose the objective is to derive
    new information rather

    than correcting the existing information.

    Unfortunately, sensor fusion is not always possible. For instance, when considering
    monitoring

    activities over a wide physical area, it may be better or even necessary (namely
    for cost-effectiveness

    reasons) to scatter the sensors in pre-identiﬁed points according to area dynamics
    expertise and local

    knowledge, to cover the most signiﬁcant events. For instance, this is often the
    case when monitoring

    water bodies [42], because of their typically large extension and the involved
    complex water dynamics,

    requiring expert knowledge when determining the deployment locations scattered
    to cover the highly

    variable environmental dynamics. Moreover, water monitoring usually requires costly
    sensors [43],

    which makes it infeasible to have more than one in a conﬁned area. Exploiting
    sensor fusion in these

    conditions is thus very hard or even impossible.

    Even when sensor fusion can be opted as an alternative for achieving increased
    dependability,

    there are a number of technical problems that may have to be addressed. For example,
    when monitoring

    environmental processes with fast dynamics, it may be necessary that all measurements
    are obtained

    at roughly the same time [37] so that they can be correlated. However, timing
    aspects are hard to

    deal with in distributed settings, and issues like network delays or incorrect
    clock synchronization of

    sensor nodes, if not accounted for during system design, can lead to incorrect
    data being produced

    by sensor fusion algorithms. Given the real-time nature of sensor data, there
    is a temporal validity

    interval during which the difference between the measured data value and the real
    value is acceptable

    for the application. After this temporal validity interval, data become outdated
    and must be discarded.

    Therefore, data should be timestamped as soon as they are collected, and the temporal
    validity interval

    must be known at design time. This will allow setting up mechanisms to discard
    outdated data.

    The clocks of the different nodes in the system must be synchronized and the precision
    (the maximum

    difference between all of the clocks) must also be known and taken into account
    when deciding

    whether some sensor data are already outdated. Dependable sensor fusion thus requires
    additional

    design efforts, to adapt the solution to the speciﬁc application characteristics
    and requirements.

    Sensors 2017, 17, 2010

    14 of 23

    4.1.2. Value Redundancy

    While sensor fusion relies on the physical (space) redundancy provided by the
    existence of several

    sensors, it is possible to consider data fusion [44,45] as an alternative approach.
    It does not require

    physically redundant sensor nodes, but relies on the value redundancy provided
    by extra information,

    obtained by other means. The notions of sensor fusion and (multi-sensor) data
    fusion are often used

    interchangeably. In fact, data fusion can be considered a generalization of sensor
    fusion, when data

    fusion is applied to multi-sensor data. Data fusion, in general, is related to
    the fusion of data, no matter

    its source, whereas sensor fusion (or multi-sensor data fusion) describes the
    use of more than one

    sensor in a multi-sensor system to enhance the accuracy of measured data or to
    handle missing data.

    The process of data fusion deals with the identiﬁcation, association, correlation,
    estimation and

    combination of spatially- and temporally-indexed data or information from numerous
    inputs with

    the speciﬁc goal of enhancing the analysis and understanding of this information.
    The techniques

    employed for data fusion are essentially the ones referred to for sensor fusion,
    which are discussed

    below. However, from a dependability perspective, it is important to note that
    data fusion opens new

    perspectives (in comparison to sensor fusion) regarding exploitable redundancy.
    We refer, in particular,

    to two forms of value redundancy that are exploitable with data fusion:

    •

    Signal analysis or analytical redundancy: This is used to monitor parameters such
    as frequency

    response, signal noise and amplitude change velocity among others [46]. It is
    a robust approach in

    the case of strange behavior in a controlled system. If there is a strong variability
    of a variable, then

    a sensor is categorized as faulty (or the system under monitoring has been altered).
    This necessarily

    requires some bounds to be established a priori, against which the parameters
    can be fused to

    perform the intended classiﬁcation.

    •

    Model-based redundancy: With the help of simulation/mathematical models of the
    monitored

    system, it is possible to obtain values to validate the measurements. The author
    in Reference [47]

    was a big promoter of this type of redundancy, where the system model calculates
    the measured

    variable, and then it, is compared to the sensor measurement.

    One potential difﬁculty in applying model-based redundancy is deﬁning relevant
    and accurate

    models. The problem becomes even more difﬁcult when these models characterize
    physical

    processes that change over time, which is often the case when monitoring environmental
    systems.

    Forecasting modeling techniques include simulation, estimation and syntactic methods
    [48]. Simulation

    is used when the physical characteristics to be measured can be accurately and
    predictably modeled.

    These models can be used in all types of scenarios, but most studies present examples
    based on

    terrestrial (indoor) applications [49], whereas the theme of the work herein concentrates
    on the

    complexity of the aquatic environment (e.g., water circulation). It is for this
    exact reason that current

    aquatic systems do not support real-time model-based data fusion [50]. Ideally,
    at run-time, a

    forecasting model represents a reference to validate the sensing data, which can
    also be applied

    for optimization and planning [51].

    4.1.3. Temporal Redundancy

    In WSN applications, sensor nodes continuously send new measurements of the monitored

    network, typically in a periodic way, to satisfy the temporal accuracy requirements
    of the application.

    The sequential measurements arriving at the sink or processing node constitute
    a time series

    to which data processing techniques can be applied with dependability objectives.
    In other words,

    if past measurements are considered historical data, then sensor fusion techniques
    can be applied to

    fuse the historical data with the current measurement. For instance, it is usual
    that noise reduction

    techniques are applied to single data streams, as a preliminary data enhancement
    step before any

    other data processing algorithms are applied. Outlier detection techniques [52]
    are also commonly

    applied to single data streams, detecting a faulty measurement when it deviates
    too much from the

    recent measurement history. Given the deviations caused by intrinsic noise and
    complex failure modes

    Sensors 2017, 17, 2010

    15 of 23

    affecting the transducing process [53], choosing the adequate margins to achieve
    accurate outlier

    detection is usually a difﬁcult problem. One approach to this problem is to use
    detection patterns

    rather than thresholds, applied to the incoming data stream. This approach allows
    detecting other

    phenomena, in addition to or instead of outliers [54]. Interestingly, outlier
    detection is a problem

    common to several areas including network intrusion, fraud detection, performance
    assessment and

    weather forecasting, among others [55].

    The identiﬁcation of outliers contributes to improving the data fusion processes
    and hence the

    quality of the resulting data. If performed by intermediate nodes, it may also
    contribute to enhancing

    the network performance by preventing the transmission of messages containing
    outliers (thus

    transforming outlier faults into omission faults, possibly a good strategy in
    systems with redundant

    information sources).

    We note that temporal redundancy and value redundancy strategies, as described
    here, can be

    combined with spatial redundancy in a single system.

    4.2. A Taxonomy for Dependability-Oriented Data Quality in WSNs

    To help the reader understanding the main dimensions, aspects and techniques that
    are related to

    the problem of achieving data quality and dependability in WSNs, we provide in
    Figure 4 a schema

    with a tree-like organization of the relevant taxonomy. Note that the redundancy
    approaches presented

    earlier serve as a base for the application of the techniques described ahead.

    Dependability-oriented

    data Quality in WSNs

    Goals

    Functions

    Techniques

    Quality estimation

    Quality improvement

    System state oriented

    System data oriented

    Unsupervised

    Supervised

    Fault detection

    Offset

    Drift

    Crash

    Trimm

    Outlier

    Noise

    Calibration

    Filtering

    Correction

    Reconstruction

    Statistical analysis

    Clustering

    PCA

    Inference

    Behavioural

    Bayesian inference

    Fuzzy logic

    Dempster-Shafer theory

    Artificial neural networks

    Rule-based/Decision-tree

    Random set theory

    Event algebra

    Kalman filtering

    Voting

    Figure 4. Schema of the categories of solutions for dependable WSNs.

    We consider three main dimensions that are relevant when addressing the problem
    of data quality

    and dependability improvement: goals to be achieved, functions to be performed
    and techniques to

    be applied.

    We identify two distinct goals. The ﬁrst consists of improving the quality of
    data, which is the

    most common in WSN applications that aim at satisfying non-functional requirements
    (often not

    explicitly speciﬁed), like reliable or safe operation. The second goal is less
    common. It consists of

    estimating the quality of data to enable assessing if non-functional requirements
    are satisﬁed. Although

    it may not be easy to explicitly deﬁne these requirements, the advantage is that
    it becomes possible to

    deﬁne mechanisms to mitigate the negative effects of deviations from the speciﬁcation.
    For instance,

    users can be notiﬁed that the application is not working properly, or the application
    may be stopped in

    a fail-safe state instead of performing some unsafe operation.

    Sensors 2017, 17, 2010

    16 of 23

    To meet these goals, it is necessary to execute speciﬁc functions, which we classify
    into two

    categories: state oriented and data oriented. State-oriented functions are meant
    to evaluate the health

    of system components, in particular sensors (or sensor nodes), on the assumption
    that this health is

    affected by faults. Several fault detection functions are thus considered, to
    deal with the different

    failure modes identiﬁed in Section 3.2. These functions are important to both
    improve and estimate

    the quality of data, respectively by providing information that allows differentiating
    good and bad

    information sources in sensor fusion processes and by allowing distinguishing
    the quality of results

    obtained with source components in different health conditions. Data-oriented
    functions include all

    those that are meant to process sensor data, namely (but not exclusively) to calibrate,
    ﬁlter, correct or

    reconstruct data that are affected by faults. Calibration performs an automatic
    adjustment of values,

    for instance to compensate the effect of an offset. Filtering can be used to remove
    outliers or noise

    effects. Correction allows modifying values, for instance when it is know that
    they are drifting from

    the real values or that they are trimmed. Reconstruction is helpful for instance
    when a value is missing

    or when it is removed due to being an outlier and a replacement value needs to
    be produced. All of

    these functions are meant to improve the quality of data, rather than estimating
    this quality. They can

    be combined with each other and also with state-oriented functions, for better
    results concerning data

    quality improvement.

    There is a vast range of techniques and speciﬁc algorithms that may be employed
    to process sensor

    data and perform the mentioned functions. In this survey, we go through the main
    ones, providing

    illustrating references, and considering the two broad categories of supervised
    and unsupervised

    techniques. No matter the function to which it contributes, when a technique requires
    model training

    and training datasets, it is characterized as a supervised learning technique.
    In this category, the

    constructed and trained models are used at run-time to classify data, estimate
    new values and correct

    existing data, among other. On the other hand, unsupervised techniques are characterized
    by directly

    inferring the possible relations between data, without the need for a correcting
    model output reference.

    In the following sections, we include examples to help the reader understanding
    that for a given

    problem involving data quality issues, it may be possible to use multiple solutions
    or techniques.

    For instance, in [56] Kreibich et al. present two solutions for the evaluation
    of sensor-fusion quality in

    an industrial WSN that suffers from temporary losses of data and interferences
    in data streams, using

    fuzzy logic and Dempster–Shafer theory. Moreover, the authors mention that other
    techniques could

    be used (such as Bayesian, Kalman ﬁlter, artiﬁcial neural network or voting fusion).

    4.2.1. Supervised Techniques

    Since data fusion is a concept that exists in works dated from the 1980s until
    now, many authors

    present data fusion taxonomies for detection, classiﬁcation and identiﬁcation
    algorithms [45,57–59].

    These are low-level processing algorithms that can be applied in sensor nodes
    of a WSN. The goals

    here are to detect if an object is present, to classify the object and to identify
    it as accurately as possible.

    Within the supervised techniques, we group the major algorithm categories into
    feature-based

    inference techniques and techniques based on behavioral models, as illustrated
    in the scheme

    of Figure 4.

    Feature-based inference techniques achieve information mapping through classiﬁcation
    or

    detection. An example is the use of statistical knowledge about an object or information
    about

    its features, as a means for its identiﬁcation.

    These techniques can be further partitioned into

    several classes. In the following paragraphs, we will refer to some of the most
    frequently-used

    techniques, namely parametric such as Bayesian inference, Dempster–Shafer evidential
    theory (DST)

    and Kalman ﬁlters, and artiﬁcial neural networks (ANN), which is a well-known
    information theoretic

    technique. We note that there are many other machine learning techniques that
    may be of use,

    such as entropy-measuring techniques, pattern recognition, parametric templates,
    ﬁgures of merit,

    whose description falls out of the scope of this survey (we refer the interested
    reader, for example, to

    Reference [45], for further details on feature-based methods for information fusion
    in sensor networks).

    Sensors 2017, 17, 2010

    17 of 23

    Bayesian inference techniques use likelihood models applied to collected data
    to make deductions

    about observed quantities and even gain insights about quantities that have not
    been observed.

    Bayesian inference is used to solve the problem of efﬁcient data gathering in
    sensor networks. The work

    in Reference [60] used this approach in a temperature and pressure sensor network
    composed of

    500 nodes, to solve the problem of missing data, and to infer that missing information.
    The work in

    Reference [61] used a Bayesian-network-based approach to detect global outliers
    in an environmental

    monitoring network. Bayesian inference is a computationally-complex process, in
    which learning the

    classiﬁcation model can be challenging, if there is a large number of correlations
    in the WSN.

    The difﬁculty and uncertainty included in integrating sets of data gathered from
    numerous sources

    promoted the development of alternatives to Bayesian inference. Among them, Dempster–Shafer

    theory (DST) has turned out to be one of the more considered [62,63], for the
    most part because of the

    fundamental Dempster’s combination rule [64]. The biggest beneﬁt of this method
    is the simplicity of

    consolidating possibly contradictory evidence, independently of whether it was
    collected as direct or

    indirect data. DST adapts better to the situations than the Bayesian approach
    as no former probabilities

    must be presumed regarding the potential node behavior, and acceptance of a theory
    does not deﬁne

    rejection of the contrasting proposition, which allows handling contradictory
    indications quantitatively.

    In addition, Reference [65] studied a DST approach to evaluate sensor nodes misbehavior.

    Kalman ﬁltering is a well-known estimation-based approach to solve data quality
    problems in

    WSNs. One recent example [66] presents an algorithm to correct rough and missing
    information

    grounded on Kalman ﬁltering to surpass the issue with querying faulty information
    and to enhance

    the exactness of data in a 1000-node WSN in a synthetic environment. Another example
    is presented

    in Reference [67], in the context of an aquatic monitoring application, in which
    Kalman ﬁltering was

    used with forecasting algorithms to assess the quality of the monitoring data
    series.

    Artiﬁcial neural networks (ANN) are hardware or software systems that need a training
    process

    consisting of mapping input information to target values or classes. The conversion
    of this input

    information into the yields is executed by artiﬁcial neurons that try to imitate
    the complicated, nonlinear

    and hugely parallel procedures that happen in natural sensory systems. ANNs have
    been used in WSNs

    for the most varied applications, many of which are related to fault-detection
    [68–70]. In consonance

    with the theme of the work herein, [71] presented an ANN-based approach to detect
    disaster events

    through an environmental sensor network. Additionally, [72] presents another ANN-based
    approach

    to detect biofouling events (thus, fault events) in an aquatic sensor network.

    The behavioral (cognitive-based) models group encompasses techniques that attempt
    to imitate

    and mechanize the decision-making procedures utilized by human analysts. These
    include event

    algebra, rule-based systems and fuzzy logic. The latter technique is the most
    studied and applied,

    which justiﬁes our particular attention to it.

    According to [73], fuzzy set theory allows for imprecise knowledge to be mathematically
    treated

    by making it easier to represent or classify system state variable information.
    The use of fuzzy

    associative memory (also known as production rules) allows a proposition to have
    a membership

    value in a given class ranging from zero (absolutely does not belong in the category)
    to one (absolutely

    belongs in the category). An expert speciﬁes the production rules and fuzzy sets
    that represent the

    characteristics of each input and output variable. Fuzzy data fusion application
    to WSNs has at least

    as much popularity as ANN-based fusion; therefore, its applications range from
    fault detection [74–76]

    to applications in industrial WSNs [77], the environment [78] and aquatic-related
    WSNs [79].

    There are some other mathematical approaches that have been developed in recent
    years, which

    include random set theory, conditional algebra and relational event algebra [48].

    Random set theory complements the existing theories of random vectors and of random
    functions

    serving as a mechanism for modeling observed phenomena, which are sets rather
    than precise points.

    It can be applied to incorporate ambiguous evidence (e.g., natural language reports
    and rules) and

    various expert system methods into multi-sensor estimation. Conditional event
    algebra refers to

    sets with one or more ﬁnitary operations deﬁned on it that satisfy a list of axioms,
    whose domain

    Sensors 2017, 17, 2010

    18 of 23

    consists of logical objects using a type of probabilistic calculus suited for
    contingency problems such

    as knowledge-based rules and contingent decision making. Relational event algebra
    is an extension

    of conditional event algebra where functions of probabilities formally representing
    single event

    probabilities represent actual relational events considering appropriately determined
    larger probability

    spaces, providing a systematic basis for solving problems involving pooling of
    evidence.

    4.2.2. Unsupervised Techniques

    There are several unsupervised data processing techniques (Figure 4), which serve,
    just

    like supervised techniques, to perform the needed functions in WSN-based monitoring
    systems,

    like detection, ﬁltering or correction.

    Various statistical analysis methods can be used as unsupervised techniques for
    data processing.

    For instance, the work in [80] resorts to statistical analysis to identify events,
    recognize observation

    errors and predict absent measurements in ecological WSNs. The proposed method
    requires learning

    statistical distributions of differences between measurements of a sensor and
    those of its neighbors,

    as well as between sequences of single-sensor measurements. According to the author,
    there is a

    large degree of spatiotemporal correlation in scalar physical variables, which
    provides a spectrum

    of oscillations between adjoining or successive readings with little differences.
    Based on successive

    readings, it is possible to learn their distribution and then detect outliers
    when a reading value is lower

    than a determined threshold, in the statistical signiﬁcance test.

    Clustering techniques are quite common in WSN-based applications. The general
    procedure

    is to integrate analogous information into groups with identical comportment.
    Data not belonging

    to these clusters or belonging to a smaller cluster would be considered outliers,
    if this is the goal.

    A simple and well-known clustering algorithm is the nearest neighbor, which associates
    the most

    similar measurements. For example, the approach was used by [81] to handle unsupervised
    outlier

    detection and, in particular, to identify global-wise outliers. Every node utilizes
    distance similitude

    to locally distinguish anomalous readings and transferring those readings to the
    nearby nodes for

    conﬁrmation. These nearby nodes will repeat this process until the entire network
    ultimately agrees

    on the overall anomalous readings. The downside of this method is the lack of
    scalability to large-scale

    networks. The most used method to measure the similarity between two data instances
    is the Euclidean

    distance. For instance, this is used in [82] in the context of target classiﬁcation
    in a multi-channel

    seismic network.

    The spectral decomposition-based approach aims at deﬁning standard behaviors in
    the data by

    utilizing principal component analysis (PCA). PCA allows decreasing the magnitude
    of an information

    set in which there are many interrelated variables, while holding as much as could
    be expected of the

    variety present in the set. The work in Reference [83] proposed a PCA-based method
    to address the

    data integrity arising from the imprecision triggered by faulty sensor nodes.
    The method requires a

    model of the standard behavior to be built a priori, by selecting appropriate
    principal components

    (PCs), and allows the detection of outliers.

    Voting methods are useful to fuse information from several sensors, particularly
    when applied to

    detection and classiﬁcation declarations from multiple sensors. These declarations
    are treated as votes,

    to which majority, plurality or decision-tree rules are applied to obtain a result
    that is more dependable

    than what would be obtained with a single sensor output [48]. This allows, for
    instance, masking false

    alarms when the sensors are used to detect the occurrence of some event, thus
    preventing premature

    reactions or countermeasures. In this sense, voting methods are also appropriate
    for fault-detection, to

    decide which node is the faulty one [84,85]. Finally, they are used in several
    other application contexts,

    such as WSN security [86] and sensor faults in on-body sensor networks [87].

    5. Conclusions

    Assuring the quality of sensor data is important in WSN-based monitoring applications.
    In the

    last decade, this dependability aspect has been explicitly or implicitly addressed
    in many works,

    Sensors 2017, 17, 2010

    19 of 23

    notably by exploiting the redundancy provided by the multiple sensor nodes typically
    existing in

    a WSN. Various speciﬁc problems need to be addressed when aiming at a dependable
    WSN-based

    monitoring solution, from ensuring the reliability of the transducing process
    to achieving a correct

    interpretation of data collected from several correlated sensors.

    In this paper, we present an encompassing perspective of the several facets of
    the problem,

    focusing on dependability aspects speciﬁc to individual sensors, to the network
    that interconnects

    the sensor nodes and the processing nodes and to the processing tasks that are
    performed within the

    processing nodes. This separation of concerns allows one to: (a) clearly expose
    the possible causes

    of data quality loss from the source to the ﬁnal output; (b) describe speciﬁc
    mitigation solutions;

    (c) provide a dependability perspective on what can be explicitly done to achieve
    improved data

    quality and assess this quality. Particular focus is given to the different forms
    of redundancy that may

    be exploited to achieve the dependability objectives: spatial, value and temporal
    redundancy. These are

    intrinsically related to the many sensor and data fusion techniques commonly employed,
    also surveyed

    in the paper. We provide many references on publications with theoretical and
    practical applications

    of the techniques, chosen to illustrate the multitude of options that are studied
    to solve directly or

    indirectly data quality problems. A speciﬁc outlook on data quality issues and
    open problems in water

    monitoring applications is ﬁnally given.

    Acknowledgments: This work was partially supported by the FCT, through the LASIGE
    Research Unit,

    Ref. UID/CEC/00408/2013, PhD Grant SFRH/BD/82489/2011 and by H2020 WADI—EC Grant
    Agreement

    No. 689239.

    Author Contributions: Anabela Oliveira was the main contributor to the section
    addressing data quality in

    aquatic environment monitoring and contributed to sections addressing sensor-speciﬁc
    aspects. António Casimiro

    was the main contributor to the sections related to dependability and redundancy
    aspects. Gonçalo Jesus was the

    main author of the survey.

    Conﬂicts of Interest: The authors declare no conﬂict of interest.

    References

    1.

    Brade, T.; Kaiser, J.; Zug, S. Expressing validity estimates in smart sensor applications.
    In Proceedings of the

    2013 26th International Conference on Architecture of Computing Systems (ARCS),
    Prague, Czech Republic,

    19–22 February 2013; pp. 1–8.

    2.

    Dietrich, A.; Zug, S.; Kaiser, J. Detecting external measurement disturbances
    based on statistical analysis for

    smart sensors. In Proceedings of the 2010 IEEE International Symposium on Industrial
    Electronics (ISIE),

    Bari, Italy, 4–7 July 2010; pp. 2067–2072.

    3.

    Rodriguez, M.; Ortiz Uriarte, L.; Jia, Y.; Yoshii, K.; Ross, R.; Beckman, P. Wireless
    sensor network for

    data-center environmental monitoring. In Proceedings of the 2011 Fifth International
    Conference on Sensing

    Technology (ICST), Palmerston North, New Zealand, 28 November–1 December 2011;
    pp. 533–537.

    4.

    Scherer, T.; Lombriser, C.; Schott, W.; Truong, H.; Weiss, B. Wireless Sensor
    Network for Continuous

    Temperature Monitoring in Air-Cooled Data Centers: Applications and Measurement
    Results. In Ad-hoc,

    Mobile, and Wireless Networks; Li, X.Y., Papavassiliou, S., Ruehrup, S., Eds.;
    Lecture Notes in Computer

    Science; Springer: Berlin/Heidelberg, Germany, 2012; Volume 7363, pp. 235–248.

    5.

    Cristian, F. Understanding Fault-Tolerant Distributed Systems. Commun. ACM 1991,
    34, 56–78.

    6.

    Yick, J.; Mukherjee, B.; Ghosal, D. Wireless sensor network survey. Comput. Netw.
    2008, 52, 2292–2330.

    7.

    Arampatzis, T.; Lygeros, J.; Manesis, S. A Survey of Applications of Wireless
    Sensors and Wireless Sensor

    Networks. In Proceedings of the 2005 IEEE International Symposium on Intelligent
    Control 13th Mediterrean

    Conference on Control and Automation, Limassol, Cyprus, 27–29 June 2005; pp. 719–724.

    8.

    Veríssimo, P.; Rodrigues, L.

    Distributed Systems for System Architects; Springer: New York, NY, USA,

    2001; p. 623.

    9.

    Ibargiengoytia, P.; Sucar, L.; Vadera, S. Real time intelligent sensor validation.
    IEEE Trans. Power Syst.

    2001, 16, 770–775.

    10.

    Rodger, J. Toward reducing failure risk in an integrated vehicle health maintenance
    system: A fuzzy

    multi-sensor data fusion Kalman ﬁlter approach for IVHMS. Expert Syst. Appl. 2012,
    39, 9821–9836.

    Sensors 2017, 17, 2010

    20 of 23

    11.

    Frolik, J.; Abdelrahman, M.; Kandasamy, P. A conﬁdence-based approach to the self-validation,
    fusion and

    reconstruction of quasi-redundant sensor data. IEEE Trans. Instrum. Meas. 2001,
    50, 1761–1769.

    12.

    Avizienis, A.; Laprie, J.C.; Randell, B.; Landwehr, C. Basic Concepts and Taxonomy
    of Dependable and

    Secure Computing. IEEE Trans. Dependable Secur. Comput. 2004, 1, 11–33.

    13.

    Zhang, D.; Zhao, C.; Liang, Y.; Liu, Z. A new medium access control protocol based
    on perceived data

    reliability and spatial correlation in wireless sensor network. Comput. Electr.
    Eng. 2012, 38, 694–702.

    14.

    Luo, H.; Tao, H.; Ma, H.; Das, S. Data Fusion with Desired Reliability in Wireless
    Sensor Networks.

    IEEE Trans. Parallel Distrib. Syst. 2011, 22, 501–513.

    15.

    Tang, L.; Yu, X.; Kim, S.; Gu, Q.; Han, J.; Leung, A.; La Porta, T. Trustworthiness
    analysis of sensor data in

    cyber-physical systems. J. Comput. Syst. Sci. 2013, 79, 383–401.

    16.

    Ayday, E.; Delgosha, F.; Fekri, F. Data Authenticity and Availability in Multihop
    Wireless Sensor Networks.

    ACM Trans. Sens. Netw. 2012, 8, doi:10.1145/2140522.2140523.

    17.

    Prathiba, B.; Sankar, K.J.; Sumalatha, V. Enhancing the data quality in wireless
    sensor networks—A review.

    In Proceedings of the IEEE International Conference on Automatic Control and Dynamic
    Optimization

    Techniques (ICACDOT), Pune, India, 9–10 September 2016; pp. 448–454.

    18.

    Sharma, A.; Golubchik, L.; Govindan, R. Sensor Faults: Detection Methods and Prevalence
    in Real-world

    Datasets. ACM Trans. Sens. Netw. 2010, 6, doi:10.1145/1754414.1754419.

    19.

    Nguyen, T.T.; Spehr, J.; Uhlemann, M.; Zug, S.; Kruse, R. Learning of lane information
    reliability for

    intelligent vehicles. In Proceedings of the 2016 IEEE International Conference
    on Multisensor Fusion and

    Integration for Intelligent Systems (MFI), Baden-Baden, Germany, 19–21 September
    2016; pp. 142–147.

    20.

    Golle, P.; Greene, D.; Staddon, J. Detecting and Correcting Malicious Data in
    VANETs. In Proceedings of the

    1st ACM International Workshop on Vehicular Ad Hoc Networks, Philadelphia, PA,
    USA, 1 October 2004;

    ACM: New York, NY, USA, 2004; pp. 29–37.

    21.

    Nimier, V. Supervised multisensor tracking algorithm. In Proceedings of the 9th
    European Signal Processing

    Conference, Island of Rhodes, Greece, 8–11 September 1998; pp. 1–4.

    22.

    Patra, J.; Chakraborty, G.; Meher, P. Neural-network-based robust linearization
    and compensation technique for

    sensors under nonlinear environmental influences. IEEE Trans. Circuits Syst. I
    Regul. Pap. 2008, 55, 1316–1327.

    23.

    Webster, J.; Eren, H. Measurement, Instrumentation, and Sensors Handbook, 2nd
    ed.; Spatial, Mechanical,

    Thermal, and Radiation Measurement; CRC Press: Boca Raton, FL, USA, 2014; p. 1640.

    24.

    De Silva, C. Control Sensors and Actuators; Prentice Hall: Upper Saddle River,
    NJ, USA, 1989.

    25.

    Tumanski, S. Sensors and Actuators—Control System Instrumentation; de Silva, C.W.,
    Ed.; CRC Press:

    Boca Raton, FL, USA, 2007; Volume 10.

    26.

    Mitchell, H. Multi-Sensor Data Fusion: An Introduction; Springer: Berlin/Heidelberg,
    Germany, 2007.

    27.

    Whitehouse, K.; Culler, D. Calibration As Parameter Estimation in Sensor Networks.
    In Proceedings of

    the 1st ACM International Workshop on Wireless Sensor Networks and Applications,
    Atlanta, GA, USA,

    28 September 2002; ACM: New York, NY, USA, 2002; pp. 59–67.

    28.

    Patra, J.; Meher, P.; Chakraborty, G. Development of Laguerre Neural-Network-Based
    Intelligent Sensors for

    Wireless Sensor Networks. IEEE Trans. Instrum. Meas. 2011, 60, 725–734.

    29.

    Rivera, J.; Carrillo, M.; Chacón, M.; Herrera, G.; Bojorquez, G. Self-Calibration
    and Optimal Response in

    Intelligent Sensors Design Based on Artiﬁcial Neural Networks. Sensors 2007, 7,
    1509.

    30.

    Barwicz, A.; Massicotte, D.; Savaria, Y.; Santerre, M.A.; Morawski, R.

    An integrated structure for

    Kalman-ﬁlter-based measurand reconstruction. IEEE Trans. Instrum. Meas. 1994,
    43, 403–410.

    31.

    Gubian, M.; Marconato, A.; Boni, A.; Petri, D. A Study on Uncertainty-Complexity
    Tradeoffs for Dynamic

    Nonlinear Sensor Compensation. IEEE Trans. Instrum. Meas. 2009, 58, 26–32.

    32.

    Ganesan, D.; Estrin, D.; Heidemann, J. Dimensions: Why do we need a new data handling
    architecture for

    sensor networks. ACM SIGCOMM Comput. Commun. Rev. 2003, 33, 143–148.

    33.

    Zhao, J.; Govindan, R.; Estrin, D.

    Computing aggregates for monitoring wireless sensor networks.

    In Proceedings of the First IEEE International Workshop on Sensor Network Protocols
    and Applications,

    Anchorage, AK, USA, 11 May 2003; pp. 139–148.

    34.

    Madden, S.; Franklin, M.; Hellerstein, J.; Hong, W. TAG: A Tiny Aggregation Service
    for Ad-hoc Sensor

    Networks. SIGOPS Oper. Syst. Rev. 2002, 36, 131–146.

    Sensors 2017, 17, 2010

    21 of 23

    35.

    Krishnamachari, L.; Estrin, D.; Wicker, S. The impact of data aggregation in wireless
    sensor networks.

    In Proceedings of the 22nd International Conference on Distributed Computing Systems
    Workshops,

    Vienna, Austria, 2–5 July 2002.

    36.

    Kopetz, H. Real-Time Systems: Design Principles for Distributed Embedded Applications;
    Real-Time Systems

    Series; Springer: NewYork, NY, USA, 2011.

    37.

    Marzullo, K. Tolerating Failures of Continuous-valued Sensors. ACM Trans. Comput.
    Syst. 1990, 8, 284–304.

    38.

    Koushanfar, F.; Potkonjak, M.; Sangiovanni-Vincentelli, A. In Proceedings of the
    2003 IEEE On-Line Fault

    Detection of Sensor Measurements, Toronto, ON, Canada, 22–24 October 2003; Volume
    2, pp. 974–979.

    39.

    Zhuang, P.; Wang, D.; Shang, Y. Distributed Faulty Sensor Detection. In Proceedings
    of the 2009 IEEE Global

    Telecommunications Conference, Honolulu, HI, USA, 30 November–4 December 2009;
    pp. 1–6.

    40.

    Boudjemaa, R.; Forbes, A. Parameter Estimation Methods for Data Fusion; NPL Report
    CMSC; National Physical

    Laboratory, Great Britain, Centre for Mathematics and Scientiﬁc Computing: Teddington,
    UK, 2004.

    41.

    Grime, S.; Durrant-Whyte, H. Data fusion in decentralized sensor networks. Control
    Eng. Pract. 1994, 2, 849–863.

    42.

    Baptista, A. Environmental Observation and Forecasting Systems. In Encyclopedia
    of Physical Science and

    Technology (Third Edition), Meyers, R.A., Ed.; Academic Press: New York, NY, USA,
    2003; pp. 565–581.

    43.

    Gomes, J.; Jesus, G.; Rodrigues, M.; Rogeiro, J.; Azevedo, A.; Oliveira, A. Managing
    a Coastal Sensors

    Network in a Nowcast-Forecast Information System. In Proceedings of the 2013 Eighth
    International

    Conference on Broadband and Wireless Computing, Communication and Applications
    (BWCCA),

    Compiegne, France, 28–30 October 2013; pp. 518–523.

    44.

    Brooks, R.; Iyengar, S. Multi-Sensor Fusion: Fundamentals and Applications with
    Software; Prentice-Hall, Inc.:

    Upper Saddle River, NJ, USA, 1998.

    45.

    Nakamura, E.; Loureiro, A.; Frery, A. Information Fusion for Wireless Sensor Networks:
    Methods, Models,

    and Classiﬁcations. ACM Comput. Surv. 2007, 39, doi:10.1145/1267070.1267073

    46.

    Worden, K.; Manson, G.; Fieller, N. Damage Detection using Outlier Analysis. J.
    Sound Vib. 2000, 229, 647–667.

    47.

    Isermann, R. Model-based fault-detection and diagnosis—Status and applications.

    Ann. Rev. Control

    2005, 29, 71–85.

    48.

    Klein, L. Sensor and Data Fusion: A Tool for Information Assessment and Decision
    Making; Press Monographs,

    Society of Photo Optical: Bellingham, WA, USA, 2004.

    49.

    Mendonca, R.; Santana, P.; Marques, F.; Lourenco, A.; Silva, J.; Barata, J. Kelpie:
    A ROS-Based Multi-Robot

    Simulator for Water Surface and Aerial Vehicles. In Proceedings of the 2013 IEEE
    International Conference

    on Systems, Man, and Cybernetics (SMC), Manchester, UK, 13–16 October 2013; pp.
    3645–3650.

    50.

    Choi, S.; Yuh, J.; Takashige, G. Development of the Omni Directional Intelligent
    Navigator. IEEE Rob.

    Autom. Mag. 1995, 2, 44–53.

    51.

    Crespi, A.; Ijspeert, A. Online optimization of swimming and crawling in an amphibious
    snake robot.

    IEEE Trans. Rob. 2008, 24, 75–87.

    52.

    Zhang, Y.; Meratnia, N.; Havinga, P. Outlier Detection Techniques for Wireless
    Sensor Networks: A Survey.

    IEEE Commun. Surv. Tutor. 2010, 12, 159–170.

    53.

    Durrant-Whyte, H. Sensor Models and Multisensor Integration. Int. J. Rob. Res.
    1988, 7, 97–113.

    54.

    Zoumboulakis, M.; Roussos, G.

    Escalation: Complex Event Detection in Wireless Sensor Networks.

    In Proceedings of the 2nd European Conference on Smart Sensing and Context (EuroSSC’07),
    Kendal, UK,

    23–25 October 2007; Springer: Berlin/Heidelberg, Germany, 2007; pp. 270–285.

    55.

    Chandola, V.; Banerjee, A.; Kumar, V. Anomaly Detection: A Survey. ACM Comput.
    Surv. 2009,

    41, doi:10.1145/1541880.1541882.

    56.

    Kreibich, O.; Neuzil, J.; Smid, R. Quality-based multiple-sensor fusion in an
    industrial wireless sensor

    network for MCM. IEEE Trans. Ind. Electron. 2014, 61, 4903–4911.

    57.

    Klein, L. Sensor and Data Fusion Concepts and Applications, 2nd ed.; Society of
    Photo-Optical Instrumentation

    Engineers (SPIE): Bellingham, WA, USA, 1999.

    58.

    Khaleghi, B.; Khamis, A.; Karray, F.; Razavi, S. Multisensor data fusion: A review
    of the state-of-the-art.

    Inf. Fusion 2013, 14, 28–44.

    59.

    Hall, D.; McMullen, S. Mathematical Techniques in Multisensor Data Fusion (Artech
    House Information Warfare

    Library); Artech House, Inc.: Norwood, MA, USA, 2004.

    Sensors 2017, 17, 2010

    22 of 23

    60.

    Hartl, G.; Li, B. infer: A Bayesian Inference Approach towards Energy Efﬁcient
    Data Collection in Dense

    Sensor Networks. In Proceedings of the 25th IEEE International Conference on Distributed
    Computing

    Systems (ICDCS 2005), Columbus, OH, USA, 6–10 June 2005; pp. 371–380.

    61.

    Janakiram, D.; Reddy, V.; Kumar, A. Outlier Detection in Wireless Sensor Networks
    using Bayesian Belief

    Networks. In Proceedings of the First International Conference on Communication
    System Software and

    Middleware (Comsware 2006), New Delhi, India, 8–12 January 2006; pp. 1–6.

    62.

    Zhao, W.; Fang, T.; Jiang, Y. Data Fusion Using Improved Dempster-Shafer Evidence
    Theory for Vehicle

    Detection.

    In Proceedings of the Fourth International Conference on Fuzzy Systems and Knowledge

    Discovery (FSKD 2007), Haikou, China, 24–27 August 2007; Volume 1, pp. 487–491.

    63.

    Konorski, J.; Orlikowski, R. Data-Centric Dempster-Shafer Theory-Based Selﬁshness
    Thwarting via Trust

    Evaluation in MANETs and WSNs.

    In Proceedings of the 2009 3rd International Conference on New

    Technologies, Mobility and Security (NTMS), Cairo, Egypt, 20–23 December 2009;
    pp. 1–5.

    64.

    Sentz, K.; Ferson, S.; Laboratories, S.N. Combination of Evidence in Dempster-Shafer
    Theory; Sandia National

    Laboratories: Albuquerque, NM, USA, 2002.

    65.

    Ahmed, M.; Huang, X.; Sharma, D. A Novel Misbehavior Evaluation with Dempster-shafer
    Theory in

    Wireless Sensor Networks. In Proceedings of the Thirteenth ACM International Symposium
    on Mobile Ad

    Hoc Networking and Computing (MobiHoc ’12), Hilton Head, SC, USA, 11–14 June 2012;
    ACM: New York,

    NY, USA, 2012; pp. 259–260.

    66.

    Zhu, R. Efﬁcient Fault-Tolerant Event Query Algorithm in Distributed Wireless
    Sensor Networks. IJDSN

    2010, doi:10.1155/2010/593849.

    67.

    Alferes, J.; Lynggaard-Jensen, A.; Munk-Nielsen, T.; Tik, S.; Vezzaro, L.; Sharma,
    A.; Mikkelsen, P.;

    Vanrolleghem, P. Validating data quality during wet weather monitoring of wastewater
    treatment plant

    inﬂuents. Proc. Water Environ. Fed. 2013, 2013, 4507–4520.

    68.

    Moustapha, A.; Selmic, R. Wireless Sensor Network Modeling Using Modiﬁed Recurrent
    Neural Networks:

    Application to Fault Detection. IEEE Trans. Instrum. Meas. 2008, 57, 981–988.

    69.

    Barron, J.; Moustapha, A.; Selmic, R. Real-Time Implementation of Fault Detection
    in Wireless Sensor

    Networks Using Neural Networks. In Proceedings of the Fifth International Conference
    on Information

    Technology: New Generations (ITNG 2008), Las Vegas, NV, USA, 7–9 April 2008; pp.
    378–383.

    70.

    Obst, O. Poster Abstract: Distributed Fault Detection Using a Recurrent Neural
    Network. In Proceedings

    of the 2009 International Conference on Information Processing in Sensor Networks
    (IPSN ’09),

    San Francisco, CA, USA, 13–16 April 2009; IEEE Computer Society: Washington, DC,
    USA, 2009; pp. 373–374.

    71.

    Bahrepour, M.; Meratnia, N.; Poel, M.; Taghikhaki, Z.; Havinga, P. Distributed
    Event Detection in Wireless

    Sensor Networks for Disaster Management. In Proceedings of the 2010 2nd International
    Conference on

    Intelligent Networking and Collaborative Systems (INCOS), Thessaloniki, Greece,
    24–26 November 2010;

    pp. 507–512.

    72.

    Archer, C.; Baptista, A.; Leen, T. Fault Detection for Salinity Sensors in the
    Columbia Estuary; Technical Report;

    Oregon Graduate Institute School of Science & Engineering: Hillsboro, OR, USA,
    2002.

    73.

    Klein, L.; Mihaylova, L.; El Faouzi, N.E. Sensor and Data Fusion: Taxonomy, Challenges
    and Applications.

    In Handbook on Soft Computing for Video Surveillance, 1st ed.; Pal, S.K., Petrosino,
    A., Maddalena, L., Eds.;

    Chapman & Hall/CRC: Boca Raton, FL, USA, 2012; Chapter 6.

    74.

    Shell, J.; Coupland, S.; Goodyer, E. Fuzzy data fusion for fault detection in
    Wireless Sensor Networks.

    In Proceedings of the 2010 UK Workshop on Computational Intelligence (UKCI), Colchester,
    UK,

    8–10 September 2010; pp. 1–6.

    75.

    Khan, S.; Daachi, B.; Djouani, K. Application of Fuzzy Inference Systems to Detection
    of Faults in Wireless

    Sensor Networks. Neurocomputing 2012, 94, 111–120.

    76.

    Manjunatha, P.; Verma, A.; Srividya, A. Multi-Sensor Data Fusion in Cluster based
    Wireless Sensor Networks

    Using Fuzzy Logic Method. In Proceedings of the IEEE Region 10 and the Third international
    Conference on

    Industrial and Information Systems (ICIIS 2008), Kharagpur, India, 8–10 December
    2008; pp. 1–6.

    77.

    Collotta, M.; Pau, G.; Salerno, V.; Scata, G. A fuzzy based algorithm to manage
    power consumption in

    industrial Wireless Sensor Networks. In Proceedings of the 2011 9th IEEE International
    Conference on

    Industrial Informatics (INDIN), Lisbon, Portugal, 26–29 July 2011; pp. 151–156.

    78.

    Su, I.J.; Tsai, C.C.; Sung, W.T. Area Temperature System Monitoring and Computing
    Based on Adaptive

    Fuzzy Logic in Wireless Sensor Networks. Appl. Soft Comput. 2012, 12, 1532–1541.

    Sensors 2017, 17, 2010

    23 of 23

    79.

    Castillo-Effer, M.; Quintela, D.; Moreno, W.; Jordan, R.; Westhoff, W. Wireless
    sensor networks for ﬂash-ﬂood

    alerting. In Proceedings of the Fifth IEEE International Caracas Conference on
    Devices, Circuits and Systems,

    Punta Cana, Dominican Republic, 3–5 November 2004; Volume 1, pp. 142–146.

    80.

    Bettencourt, L.; Hagberg, A.; Larkey, L.

    Separating the Wheat from the Chaff: Practical Anomaly

    Detection Schemes in Ecological Applications of Distributed Sensor Networks. In
    Distributed Computing in

    Sensor Systems; Aspnes, J., Scheideler, C., Arora, A., Madden, S., Eds.; Lecture
    Notes in Computer Science;

    Springer: Berlin/Heidelberg, Germany, 2007; Volume 4549, pp. 223–239.

    81.

    Branch, J.; Giannella, C.; Szymanski, B.; Wolff, R.; Kargupta, H. In-network outlier
    detection in wireless

    sensor networks. Knowl. Inf. Syst. 2013, 34, 23–54.

    82.

    Zubair, M.; Hartmann, K.

    Target classiﬁcation based on sensor fusion in multi-channel seismic

    network. In Proceedings of the 2011 IEEE International Symposium on Signal Processing
    and Information

    Technology (ISSPIT), Bilbao, Spain, 14–17 December 2011; pp. 438–443.

    83.

    Chatzigiannakis, V.; Papavassiliou, S.; Grammatikou, M.; Maglaris, B. Hierarchical
    Anomaly Detection in

    Distributed Large-Scale Sensor Networks. In Proceedings of the 11th IEEE Symposium
    on Computers and

    Communications (ISCC ’06), Sardinia, Italy, 26–29 June 2006; pp. 761–767.

    84.

    Gao, J.; Xu, Y.; Li, X. Online distributed fault detection of sensor measurements.
    Tsinghua Sci. Technol.

    2007, 12, 192–196.

    85.

    Abid, A.; Kachouri, A.; Kaaniche, H.; Abid, M. Quality of service in wireless
    sensor networks through a

    failure-detector with voting mechanism. In Proceedings of the 2013 International
    Conference on Computer

    Applications Technology (ICCAT), Sousse, Tunisia, 20–22 January 2013; pp. 1–5.

    86.

    Li, F.; Wu, J. A Probabilistic Voting-based Filtering Scheme in Wireless Sensor
    Networks. In Proceedings

    of the 2006 International Conference on Wireless Communications and Mobile Computing
    (IWCMC’06),

    Vancouver, BC, Canada, 3–6 July 2006; ACM: New York, NY, USA, 2006; pp. 27–32.

    87.

    Zappi, P.; Stiefmeier, T.; Farella, E.; Roggen, D.; Benini, L.; Troster, G. Activity
    recognition from on-body

    sensors by classiﬁer fusion: Sensor scalability and robustness.

    In Proceedings of the 3rd International

    Conference on Intelligent Sensors, Sensor Networks and Information (ISSNIP 2007),
    Melbourne, Australia,

    3–6 December 2007; pp. 281–286.

    c⃝ 2017 by the authors. Licensee MDPI, Basel, Switzerland. This article is an
    open access

    article distributed under the terms and conditions of the Creative Commons Attribution

    (CC BY) license (http://creativecommons.org/licenses/by/4.0/).

    '
  inline_citation: '>'
  journal: Sensors (Basel)
  limitations: '>'
  pdf_link: https://www.mdpi.com/1424-8220/17/9/2010/pdf?version=1504340534
  publication_year: 2017
  relevance_score1: 0
  relevance_score2: 0
  title: A Survey on Data Quality for Dependable Monitoring in Wireless Sensor Networks
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
